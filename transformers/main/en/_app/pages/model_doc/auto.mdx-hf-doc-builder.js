import{S as Fxa,i as Txa,s as Mxa,e as a,k as l,w as F,t as o,M as Exa,c as n,d as t,m as i,a as s,x as T,h as r,b as d,G as e,g as b,y as M,q as E,o as C,B as w,v as Cxa,L as q}from"../../chunks/vendor-hf-doc-builder.js";import{T as vfo}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as B}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as oe}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as N}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function wxa($){let g,v,u,f,p,m,h,He,Ad,eg,wt,Ld,yd,ck,og,Qe,Ze,xd,ps,fk,_s,bs,gk,$d,vs,hk,kd,rg,sn;return{c(){g=a("p"),v=o("If your "),u=a("code"),f=o("NewModelConfig"),p=o(" is a subclass of "),m=a("code"),h=o("~transformer.PretrainedConfig"),He=o(`, make sure its
`),Ad=a("code"),eg=o("model_type"),wt=o(" attribute is set to the same key you use when registering the config (here "),Ld=a("code"),yd=o('"new-model"'),ck=o(")."),og=l(),Qe=a("p"),Ze=o("Likewise, if your "),xd=a("code"),ps=o("NewModel"),fk=o(" is a subclass of "),_s=a("a"),bs=o("PreTrainedModel"),gk=o(`, make sure its
`),$d=a("code"),vs=o("config_class"),hk=o(` attribute is set to the same class you use when registering the model (here
`),kd=a("code"),rg=o("NewModelConfig"),sn=o(")."),this.h()},l(Ke){g=n(Ke,"P",{});var ye=s(g);v=r(ye,"If your "),u=n(ye,"CODE",{});var Bq=s(u);f=r(Bq,"NewModelConfig"),Bq.forEach(t),p=r(ye," is a subclass of "),m=n(ye,"CODE",{});var Sd=s(m);h=r(Sd,"~transformer.PretrainedConfig"),Sd.forEach(t),He=r(ye,`, make sure its
`),Ad=n(ye,"CODE",{});var Iq=s(Ad);eg=r(Iq,"model_type"),Iq.forEach(t),wt=r(ye," attribute is set to the same key you use when registering the config (here "),Ld=n(ye,"CODE",{});var Nq=s(Ld);yd=r(Nq,'"new-model"'),Nq.forEach(t),ck=r(ye,")."),ye.forEach(t),og=i(Ke),Qe=n(Ke,"P",{});var Po=s(Qe);Ze=r(Po,"Likewise, if your "),xd=n(Po,"CODE",{});var ln=s(xd);ps=r(ln,"NewModel"),ln.forEach(t),fk=r(Po," is a subclass of "),_s=n(Po,"A",{href:!0});var qq=s(_s);bs=r(qq,"PreTrainedModel"),qq.forEach(t),gk=r(Po,`, make sure its
`),$d=n(Po,"CODE",{});var tg=s($d);vs=r(tg,"config_class"),tg.forEach(t),hk=r(Po,` attribute is set to the same class you use when registering the model (here
`),kd=n(Po,"CODE",{});var jq=s(kd);rg=r(jq,"NewModelConfig"),jq.forEach(t),sn=r(Po,")."),Po.forEach(t),this.h()},h(){d(_s,"href","/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel")},m(Ke,ye){b(Ke,g,ye),e(g,v),e(g,u),e(u,f),e(g,p),e(g,m),e(m,h),e(g,He),e(g,Ad),e(Ad,eg),e(g,wt),e(g,Ld),e(Ld,yd),e(g,ck),b(Ke,og,ye),b(Ke,Qe,ye),e(Qe,Ze),e(Qe,xd),e(xd,ps),e(Qe,fk),e(Qe,_s),e(_s,bs),e(Qe,gk),e(Qe,$d),e($d,vs),e(Qe,hk),e(Qe,kd),e(kd,rg),e(Qe,sn)},d(Ke){Ke&&t(g),Ke&&t(og),Ke&&t(Qe)}}}function Axa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Lxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function yxa($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var He=s(u);f=r(He,"use_auth_token=True"),He.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(m,h){b(m,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(m){m&&t(g)}}}function xxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function $xa($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var He=s(u);f=r(He,"use_auth_token=True"),He.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(m,h){b(m,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(m){m&&t(g)}}}function kxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoImageProcessor

# Download image processor from huggingface.co and cache.
image_processor = AutoImageProcessor.from_pretrained("google/vit-base-patch16-224-in21k")

# If image processor files are in a directory (e.g. image processor was saved using *save_pretrained('./test/saved_model/')*)
image_processor = AutoImageProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoImageProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download image processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>image_processor = AutoImageProcessor.from_pretrained(<span class="hljs-string">&quot;google/vit-base-patch16-224-in21k&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If image processor files are in a directory (e.g. image processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>image_processor = AutoImageProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Sxa($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var He=s(u);f=r(He,"use_auth_token=True"),He.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(m,h){b(m,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(m){m&&t(g)}}}function Rxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Pxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Bxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Ixa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Nxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function qxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function jxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Dxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDepthEstimation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForDepthEstimation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDepthEstimation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Gxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDepthEstimation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDepthEstimation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForDepthEstimation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForDepthEstimation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDepthEstimation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Oxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Vxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Xxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function zxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Qxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Wxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Uxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Hxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Jxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Yxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Zxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Kxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function e$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function o$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function r$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function t$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function a$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = AutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function n$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/layoutlm_tf_model_config.json")
model = AutoModelForDocumentQuestionAnswering.from_pretrained(
    "./tf_model/layoutlm_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/layoutlm_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/layoutlm_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function s$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function l$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function i$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVideoClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function d$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVideoClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function m$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function c$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function f$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function g$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function h$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function u$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function p$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function _$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function b$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function v$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function F$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function T$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function M$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function E$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function C$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function w$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function A$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function L$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function y$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function x$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function $$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function k$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function S$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function R$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function P$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForZeroShotObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function B$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForZeroShotObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function I$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function N$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function q$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function j$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function D$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function G$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function O$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function V$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function X$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function z$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSemanticSegmentation.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Q$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function W$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function U$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function H$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function J$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Y$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Z$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function K$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function eka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function oka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function rka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function tka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function aka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function nka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/layoutlm_pt_model_config.json")
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
    "./pt_model/layoutlm_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/layoutlm_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/layoutlm_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function ska($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function lka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function ika($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function dka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function mka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function cka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function fka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function gka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function hka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function uka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function pka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function _ka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function bka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function vka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Fka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Tka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Mka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Eka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Cka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function wka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Aka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Lka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function yka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function xka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function $ka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function kka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Ska($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Rka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Pka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Bka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Ika($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Nka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function qka($){let g,v,u,f,p,m,h,He,Ad,eg,wt,Ld,yd,ck,og,Qe,Ze,xd,ps,fk,_s,bs,gk,$d,vs,hk,kd,rg,sn,Ke,ye,Bq,Sd,Iq,Nq,Po,ln,qq,tg,jq,Ffo,ylo,Rd,ag,vhe,uk,Tfo,Fhe,Mfo,xlo,Fs,Efo,The,Cfo,wfo,Mhe,Afo,Lfo,$lo,pk,klo,Dq,yfo,Slo,ng,Rlo,Pd,sg,Ehe,_k,xfo,Che,$fo,Plo,Bo,bk,kfo,vk,Sfo,Gq,Rfo,Pfo,Bfo,Fk,Ifo,whe,Nfo,qfo,jfo,Or,Tk,Dfo,Ahe,Gfo,Ofo,Bd,Vfo,Lhe,Xfo,zfo,yhe,Qfo,Wfo,Ufo,A,lg,xhe,Hfo,Jfo,Oq,Yfo,Zfo,Kfo,ig,$he,ego,ogo,Vq,rgo,tgo,ago,dg,khe,ngo,sgo,Xq,lgo,igo,dgo,mg,She,mgo,cgo,zq,fgo,ggo,hgo,cg,Rhe,ugo,pgo,Qq,_go,bgo,vgo,fg,Phe,Fgo,Tgo,Wq,Mgo,Ego,Cgo,gg,Bhe,wgo,Ago,Uq,Lgo,ygo,xgo,hg,Ihe,$go,kgo,Hq,Sgo,Rgo,Pgo,ug,Nhe,Bgo,Igo,Jq,Ngo,qgo,jgo,pg,qhe,Dgo,Ggo,Yq,Ogo,Vgo,Xgo,_g,jhe,zgo,Qgo,Zq,Wgo,Ugo,Hgo,bg,Dhe,Jgo,Ygo,Kq,Zgo,Kgo,eho,vg,Ghe,oho,rho,ej,tho,aho,nho,Fg,Ohe,sho,lho,oj,iho,dho,mho,Tg,Vhe,cho,fho,rj,gho,hho,uho,Mg,Xhe,pho,_ho,tj,bho,vho,Fho,Eg,zhe,Tho,Mho,aj,Eho,Cho,who,Cg,Qhe,Aho,Lho,nj,yho,xho,$ho,wg,Whe,kho,Sho,sj,Rho,Pho,Bho,Ag,Uhe,Iho,Nho,lj,qho,jho,Dho,Lg,Hhe,Gho,Oho,ij,Vho,Xho,zho,yg,Jhe,Qho,Who,dj,Uho,Hho,Jho,xg,Yhe,Yho,Zho,mj,Kho,euo,ouo,$g,Zhe,ruo,tuo,cj,auo,nuo,suo,kg,Khe,luo,iuo,fj,duo,muo,cuo,Sg,eue,fuo,guo,gj,huo,uuo,puo,Rg,oue,_uo,buo,hj,vuo,Fuo,Tuo,Pg,rue,Muo,Euo,uj,Cuo,wuo,Auo,Bg,tue,Luo,yuo,pj,xuo,$uo,kuo,Ig,aue,Suo,Ruo,_j,Puo,Buo,Iuo,Ng,nue,Nuo,quo,bj,juo,Duo,Guo,qg,sue,Ouo,Vuo,vj,Xuo,zuo,Quo,jg,lue,Wuo,Uuo,Fj,Huo,Juo,Yuo,Dg,iue,Zuo,Kuo,Tj,epo,opo,rpo,Gg,due,tpo,apo,Mj,npo,spo,lpo,Og,mue,ipo,dpo,Ej,mpo,cpo,fpo,Vg,cue,gpo,hpo,Cj,upo,ppo,_po,Xg,fue,bpo,vpo,wj,Fpo,Tpo,Mpo,zg,gue,Epo,Cpo,Aj,wpo,Apo,Lpo,Qg,hue,ypo,xpo,Lj,$po,kpo,Spo,Wg,uue,Rpo,Ppo,yj,Bpo,Ipo,Npo,Ug,pue,qpo,jpo,xj,Dpo,Gpo,Opo,Hg,_ue,Vpo,Xpo,$j,zpo,Qpo,Wpo,Jg,bue,Upo,Hpo,kj,Jpo,Ypo,Zpo,Yg,vue,Kpo,e_o,Sj,o_o,r_o,t_o,Zg,Fue,a_o,n_o,Rj,s_o,l_o,i_o,Kg,Tue,d_o,m_o,Pj,c_o,f_o,g_o,eh,Mue,h_o,u_o,Bj,p_o,__o,b_o,oh,Eue,v_o,F_o,Ij,T_o,M_o,E_o,rh,Cue,C_o,w_o,Nj,A_o,L_o,y_o,th,wue,x_o,$_o,qj,k_o,S_o,R_o,ah,Aue,P_o,B_o,jj,I_o,N_o,q_o,nh,Lue,j_o,D_o,Dj,G_o,O_o,V_o,sh,yue,X_o,z_o,Gj,Q_o,W_o,U_o,lh,xue,H_o,J_o,Oj,Y_o,Z_o,K_o,ih,$ue,e1o,o1o,Vj,r1o,t1o,a1o,dh,kue,n1o,s1o,Xj,l1o,i1o,d1o,mh,Sue,m1o,c1o,zj,f1o,g1o,h1o,ch,Rue,u1o,p1o,Qj,_1o,b1o,v1o,fh,Pue,F1o,T1o,Wj,M1o,E1o,C1o,gh,Bue,w1o,A1o,Uj,L1o,y1o,x1o,hh,Iue,$1o,k1o,Hj,S1o,R1o,P1o,uh,Nue,B1o,I1o,Jj,N1o,q1o,j1o,ph,que,D1o,G1o,Yj,O1o,V1o,X1o,_h,jue,z1o,Q1o,Zj,W1o,U1o,H1o,bh,Due,J1o,Y1o,Kj,Z1o,K1o,e2o,vh,Gue,o2o,r2o,eD,t2o,a2o,n2o,Fh,Oue,s2o,l2o,oD,i2o,d2o,m2o,Th,Vue,c2o,f2o,rD,g2o,h2o,u2o,Mh,Xue,p2o,_2o,tD,b2o,v2o,F2o,Eh,zue,T2o,M2o,aD,E2o,C2o,w2o,Ch,Que,A2o,L2o,nD,y2o,x2o,$2o,wh,Wue,k2o,S2o,sD,R2o,P2o,B2o,Ah,Uue,I2o,N2o,lD,q2o,j2o,D2o,Lh,Hue,G2o,O2o,iD,V2o,X2o,z2o,yh,Jue,Q2o,W2o,dD,U2o,H2o,J2o,xh,Yue,Y2o,Z2o,mD,K2o,ebo,obo,$h,Zue,rbo,tbo,cD,abo,nbo,sbo,kh,Kue,lbo,ibo,fD,dbo,mbo,cbo,Sh,epe,fbo,gbo,gD,hbo,ubo,pbo,Rh,ope,_bo,bbo,hD,vbo,Fbo,Tbo,Ph,rpe,Mbo,Ebo,uD,Cbo,wbo,Abo,Bh,tpe,Lbo,ybo,pD,xbo,$bo,kbo,Ih,ape,Sbo,Rbo,_D,Pbo,Bbo,Ibo,Nh,npe,Nbo,qbo,bD,jbo,Dbo,Gbo,qh,spe,Obo,Vbo,vD,Xbo,zbo,Qbo,jh,lpe,Wbo,Ubo,FD,Hbo,Jbo,Ybo,Dh,ipe,Zbo,Kbo,TD,evo,ovo,rvo,Gh,dpe,tvo,avo,MD,nvo,svo,lvo,Oh,mpe,ivo,dvo,ED,mvo,cvo,fvo,Vh,cpe,gvo,hvo,CD,uvo,pvo,_vo,Xh,fpe,bvo,vvo,wD,Fvo,Tvo,Mvo,zh,gpe,Evo,Cvo,AD,wvo,Avo,Lvo,Qh,hpe,yvo,xvo,LD,$vo,kvo,Svo,Wh,upe,Rvo,Pvo,yD,Bvo,Ivo,Nvo,Uh,ppe,qvo,jvo,xD,Dvo,Gvo,Ovo,Hh,_pe,Vvo,Xvo,$D,zvo,Qvo,Wvo,Jh,bpe,Uvo,Hvo,kD,Jvo,Yvo,Zvo,Yh,vpe,Kvo,eFo,SD,oFo,rFo,tFo,Zh,Fpe,aFo,nFo,RD,sFo,lFo,iFo,Kh,Tpe,dFo,mFo,PD,cFo,fFo,gFo,eu,Mpe,hFo,uFo,BD,pFo,_Fo,bFo,ou,Epe,vFo,FFo,ID,TFo,MFo,EFo,ru,Cpe,CFo,wFo,ND,AFo,LFo,yFo,tu,wpe,xFo,$Fo,qD,kFo,SFo,RFo,au,Ape,PFo,BFo,jD,IFo,NFo,qFo,nu,Lpe,jFo,DFo,DD,GFo,OFo,VFo,su,ype,XFo,zFo,GD,QFo,WFo,UFo,lu,xpe,HFo,JFo,OD,YFo,ZFo,KFo,iu,$pe,eTo,oTo,VD,rTo,tTo,aTo,du,kpe,nTo,sTo,XD,lTo,iTo,dTo,mu,Spe,mTo,cTo,zD,fTo,gTo,hTo,cu,Rpe,uTo,pTo,QD,_To,bTo,vTo,fu,Ppe,FTo,TTo,WD,MTo,ETo,CTo,gu,Bpe,wTo,ATo,UD,LTo,yTo,xTo,hu,Ipe,$To,kTo,HD,STo,RTo,PTo,uu,Npe,BTo,ITo,JD,NTo,qTo,jTo,pu,qpe,DTo,GTo,YD,OTo,VTo,XTo,_u,jpe,zTo,QTo,ZD,WTo,UTo,HTo,bu,Dpe,JTo,YTo,KD,ZTo,KTo,eMo,vu,Gpe,oMo,rMo,eG,tMo,aMo,nMo,Fu,Ope,sMo,lMo,oG,iMo,dMo,mMo,Tu,Vpe,cMo,fMo,rG,gMo,hMo,uMo,Mu,Xpe,pMo,_Mo,tG,bMo,vMo,FMo,Eu,zpe,TMo,MMo,aG,EMo,CMo,wMo,Cu,Qpe,AMo,LMo,nG,yMo,xMo,$Mo,wu,Wpe,kMo,SMo,sG,RMo,PMo,BMo,Au,Upe,IMo,NMo,lG,qMo,jMo,DMo,Lu,Hpe,GMo,OMo,iG,VMo,XMo,zMo,yu,Jpe,QMo,WMo,dG,UMo,HMo,JMo,xu,Ype,YMo,ZMo,mG,KMo,eEo,oEo,$u,Zpe,rEo,tEo,cG,aEo,nEo,sEo,ku,Kpe,lEo,iEo,fG,dEo,mEo,cEo,Su,e_e,fEo,gEo,gG,hEo,uEo,pEo,Ru,o_e,_Eo,bEo,hG,vEo,FEo,TEo,Pu,r_e,MEo,EEo,uG,CEo,wEo,AEo,Bu,t_e,LEo,yEo,pG,xEo,$Eo,kEo,Iu,a_e,SEo,REo,_G,PEo,BEo,IEo,Nu,NEo,qu,Mk,qEo,n_e,jEo,Blo,Id,ju,s_e,Ek,DEo,l_e,GEo,Ilo,Io,Ck,OEo,wk,VEo,bG,XEo,zEo,QEo,Ak,WEo,i_e,UEo,HEo,JEo,Vr,Lk,YEo,d_e,ZEo,KEo,dn,e4o,m_e,o4o,r4o,c_e,t4o,a4o,f_e,n4o,s4o,l4o,k,Ts,g_e,i4o,d4o,vG,m4o,c4o,FG,f4o,g4o,h4o,Ms,h_e,u4o,p4o,TG,_4o,b4o,MG,v4o,F4o,T4o,Es,u_e,M4o,E4o,EG,C4o,w4o,CG,A4o,L4o,y4o,Du,p_e,x4o,$4o,wG,k4o,S4o,R4o,Cs,__e,P4o,B4o,AG,I4o,N4o,LG,q4o,j4o,D4o,Gu,b_e,G4o,O4o,yG,V4o,X4o,z4o,Ou,v_e,Q4o,W4o,xG,U4o,H4o,J4o,Vu,F_e,Y4o,Z4o,$G,K4o,eCo,oCo,ws,T_e,rCo,tCo,kG,aCo,nCo,SG,sCo,lCo,iCo,As,M_e,dCo,mCo,RG,cCo,fCo,PG,gCo,hCo,uCo,Ls,E_e,pCo,_Co,BG,bCo,vCo,IG,FCo,TCo,MCo,Xu,C_e,ECo,CCo,NG,wCo,ACo,LCo,zu,w_e,yCo,xCo,qG,$Co,kCo,SCo,Qu,A_e,RCo,PCo,jG,BCo,ICo,NCo,ys,L_e,qCo,jCo,DG,DCo,GCo,GG,OCo,VCo,XCo,Wu,y_e,zCo,QCo,OG,WCo,UCo,HCo,xs,x_e,JCo,YCo,VG,ZCo,KCo,XG,e3o,o3o,r3o,$s,$_e,t3o,a3o,zG,n3o,s3o,QG,l3o,i3o,d3o,ks,k_e,m3o,c3o,WG,f3o,g3o,UG,h3o,u3o,p3o,Ss,S_e,_3o,b3o,HG,v3o,F3o,JG,T3o,M3o,E3o,Rs,R_e,C3o,w3o,YG,A3o,L3o,ZG,y3o,x3o,$3o,Uu,P_e,k3o,S3o,KG,R3o,P3o,B3o,Ps,B_e,I3o,N3o,eO,q3o,j3o,oO,D3o,G3o,O3o,Bs,I_e,V3o,X3o,rO,z3o,Q3o,tO,W3o,U3o,H3o,Is,N_e,J3o,Y3o,aO,Z3o,K3o,nO,e5o,o5o,r5o,Ns,q_e,t5o,a5o,sO,n5o,s5o,lO,l5o,i5o,d5o,qs,j_e,m5o,c5o,iO,f5o,g5o,dO,h5o,u5o,p5o,js,D_e,_5o,b5o,mO,v5o,F5o,cO,T5o,M5o,E5o,Ds,G_e,C5o,w5o,fO,A5o,L5o,gO,y5o,x5o,$5o,Hu,O_e,k5o,S5o,hO,R5o,P5o,B5o,Ju,V_e,I5o,N5o,uO,q5o,j5o,D5o,Gs,X_e,G5o,O5o,pO,V5o,X5o,_O,z5o,Q5o,W5o,Yu,z_e,U5o,H5o,bO,J5o,Y5o,Z5o,Os,Q_e,K5o,e0o,vO,o0o,r0o,FO,t0o,a0o,n0o,Vs,W_e,s0o,l0o,TO,i0o,d0o,MO,m0o,c0o,f0o,Xs,U_e,g0o,h0o,EO,u0o,p0o,CO,_0o,b0o,v0o,Zu,H_e,F0o,T0o,wO,M0o,E0o,C0o,Ku,J_e,w0o,A0o,AO,L0o,y0o,x0o,zs,Y_e,$0o,k0o,LO,S0o,R0o,yO,P0o,B0o,I0o,Qs,Z_e,N0o,q0o,xO,j0o,D0o,$O,G0o,O0o,V0o,Ws,K_e,X0o,z0o,kO,Q0o,W0o,SO,U0o,H0o,J0o,ep,e1e,Y0o,Z0o,RO,K0o,ewo,owo,Us,o1e,rwo,two,PO,awo,nwo,BO,swo,lwo,iwo,op,r1e,dwo,mwo,IO,cwo,fwo,gwo,Hs,t1e,hwo,uwo,NO,pwo,_wo,qO,bwo,vwo,Fwo,Js,a1e,Two,Mwo,jO,Ewo,Cwo,DO,wwo,Awo,Lwo,Ys,n1e,ywo,xwo,GO,$wo,kwo,OO,Swo,Rwo,Pwo,Zs,s1e,Bwo,Iwo,VO,Nwo,qwo,XO,jwo,Dwo,Gwo,Ks,l1e,Owo,Vwo,zO,Xwo,zwo,QO,Qwo,Wwo,Uwo,el,i1e,Hwo,Jwo,WO,Ywo,Zwo,UO,Kwo,eAo,oAo,ol,d1e,rAo,tAo,HO,aAo,nAo,JO,sAo,lAo,iAo,rl,m1e,dAo,mAo,YO,cAo,fAo,ZO,gAo,hAo,uAo,rp,c1e,pAo,_Ao,KO,bAo,vAo,FAo,tl,f1e,TAo,MAo,eV,EAo,CAo,oV,wAo,AAo,LAo,tp,g1e,yAo,xAo,rV,$Ao,kAo,SAo,ap,h1e,RAo,PAo,tV,BAo,IAo,NAo,al,u1e,qAo,jAo,aV,DAo,GAo,nV,OAo,VAo,XAo,nl,p1e,zAo,QAo,sV,WAo,UAo,lV,HAo,JAo,YAo,sl,_1e,ZAo,KAo,iV,e6o,o6o,dV,r6o,t6o,a6o,np,b1e,n6o,s6o,mV,l6o,i6o,d6o,ll,v1e,m6o,c6o,cV,f6o,g6o,fV,h6o,u6o,p6o,il,F1e,_6o,b6o,gV,v6o,F6o,hV,T6o,M6o,E6o,dl,T1e,C6o,w6o,uV,A6o,L6o,pV,y6o,x6o,$6o,ml,M1e,k6o,S6o,_V,R6o,P6o,bV,B6o,I6o,N6o,cl,E1e,q6o,j6o,vV,D6o,G6o,FV,O6o,V6o,X6o,fl,C1e,z6o,Q6o,TV,W6o,U6o,MV,H6o,J6o,Y6o,gl,w1e,Z6o,K6o,EV,e7o,o7o,CV,r7o,t7o,a7o,hl,A1e,n7o,s7o,wV,l7o,i7o,AV,d7o,m7o,c7o,sp,L1e,f7o,g7o,LV,h7o,u7o,p7o,ul,y1e,_7o,b7o,yV,v7o,F7o,xV,T7o,M7o,E7o,pl,x1e,C7o,w7o,$V,A7o,L7o,kV,y7o,x7o,$7o,_l,$1e,k7o,S7o,SV,R7o,P7o,RV,B7o,I7o,N7o,lp,k1e,q7o,j7o,PV,D7o,G7o,O7o,ip,S1e,V7o,X7o,BV,z7o,Q7o,W7o,dp,R1e,U7o,H7o,IV,J7o,Y7o,Z7o,mp,P1e,K7o,e8o,NV,o8o,r8o,t8o,bl,B1e,a8o,n8o,qV,s8o,l8o,jV,i8o,d8o,m8o,cp,I1e,c8o,f8o,DV,g8o,h8o,u8o,vl,N1e,p8o,_8o,GV,b8o,v8o,OV,F8o,T8o,M8o,Fl,q1e,E8o,C8o,VV,w8o,A8o,XV,L8o,y8o,x8o,Tl,j1e,$8o,k8o,zV,S8o,R8o,QV,P8o,B8o,I8o,Ml,D1e,N8o,q8o,WV,j8o,D8o,UV,G8o,O8o,V8o,El,G1e,X8o,z8o,HV,Q8o,W8o,JV,U8o,H8o,J8o,fp,O1e,Y8o,Z8o,YV,K8o,eLo,oLo,Cl,V1e,rLo,tLo,ZV,aLo,nLo,KV,sLo,lLo,iLo,gp,X1e,dLo,mLo,eX,cLo,fLo,gLo,hp,z1e,hLo,uLo,oX,pLo,_Lo,bLo,wl,Q1e,vLo,FLo,rX,TLo,MLo,tX,ELo,CLo,wLo,Al,W1e,ALo,LLo,aX,yLo,xLo,nX,$Lo,kLo,SLo,Ll,U1e,RLo,PLo,sX,BLo,ILo,lX,NLo,qLo,jLo,up,H1e,DLo,GLo,iX,OLo,VLo,XLo,pp,J1e,zLo,QLo,dX,WLo,ULo,HLo,_p,Y1e,JLo,YLo,mX,ZLo,KLo,eyo,yl,Z1e,oyo,ryo,cX,tyo,ayo,fX,nyo,syo,lyo,xl,K1e,iyo,dyo,gX,myo,cyo,hX,fyo,gyo,hyo,bp,e2e,uyo,pyo,uX,_yo,byo,vyo,vp,o2e,Fyo,Tyo,pX,Myo,Eyo,Cyo,Fp,r2e,wyo,Ayo,_X,Lyo,yyo,xyo,Tp,t2e,$yo,kyo,bX,Syo,Ryo,Pyo,$l,a2e,Byo,Iyo,vX,Nyo,qyo,FX,jyo,Dyo,Gyo,kl,n2e,Oyo,Vyo,TX,Xyo,zyo,MX,Qyo,Wyo,Uyo,Mp,s2e,Hyo,Jyo,EX,Yyo,Zyo,Kyo,Ep,l2e,e9o,o9o,CX,r9o,t9o,a9o,Sl,i2e,n9o,s9o,wX,l9o,i9o,AX,d9o,m9o,c9o,Rl,d2e,f9o,g9o,LX,h9o,u9o,yX,p9o,_9o,b9o,Pl,m2e,v9o,F9o,xX,T9o,M9o,$X,E9o,C9o,w9o,Bl,c2e,A9o,L9o,kX,y9o,x9o,SX,$9o,k9o,S9o,Cp,R9o,wp,yk,P9o,f2e,B9o,Nlo,Nd,Ap,g2e,xk,I9o,h2e,N9o,qlo,No,$k,q9o,kk,j9o,RX,D9o,G9o,O9o,Sk,V9o,u2e,X9o,z9o,Q9o,eo,Rk,W9o,p2e,U9o,H9o,mn,J9o,_2e,Y9o,Z9o,b2e,K9o,exo,v2e,oxo,rxo,txo,z,Lp,F2e,axo,nxo,PX,sxo,lxo,ixo,yp,T2e,dxo,mxo,BX,cxo,fxo,gxo,xp,M2e,hxo,uxo,IX,pxo,_xo,bxo,$p,E2e,vxo,Fxo,NX,Txo,Mxo,Exo,kp,C2e,Cxo,wxo,qX,Axo,Lxo,yxo,Sp,w2e,xxo,$xo,jX,kxo,Sxo,Rxo,Rp,A2e,Pxo,Bxo,DX,Ixo,Nxo,qxo,Pp,L2e,jxo,Dxo,GX,Gxo,Oxo,Vxo,Bp,y2e,Xxo,zxo,OX,Qxo,Wxo,Uxo,Ip,x2e,Hxo,Jxo,VX,Yxo,Zxo,Kxo,Np,$2e,e$o,o$o,XX,r$o,t$o,a$o,qp,k2e,n$o,s$o,zX,l$o,i$o,d$o,jp,S2e,m$o,c$o,QX,f$o,g$o,h$o,Dp,R2e,u$o,p$o,WX,_$o,b$o,v$o,Gp,P2e,F$o,T$o,UX,M$o,E$o,C$o,Op,B2e,w$o,A$o,HX,L$o,y$o,x$o,Vp,I2e,$$o,k$o,JX,S$o,R$o,P$o,Xp,N2e,B$o,I$o,YX,N$o,q$o,j$o,zp,q2e,D$o,G$o,ZX,O$o,V$o,X$o,Qp,j2e,z$o,Q$o,KX,W$o,U$o,H$o,Wp,D2e,J$o,Y$o,ez,Z$o,K$o,eko,Up,G2e,oko,rko,oz,tko,ako,nko,Hp,O2e,sko,lko,rz,iko,dko,mko,Jp,V2e,cko,fko,tz,gko,hko,uko,Yp,X2e,pko,_ko,az,bko,vko,Fko,Zp,z2e,Tko,Mko,nz,Eko,Cko,wko,Kp,Q2e,Ako,Lko,sz,yko,xko,$ko,e_,W2e,kko,Sko,lz,Rko,Pko,Bko,o_,U2e,Iko,Nko,iz,qko,jko,Dko,r_,H2e,Gko,Oko,dz,Vko,Xko,zko,t_,J2e,Qko,Wko,mz,Uko,Hko,Jko,a_,Y2e,Yko,Zko,cz,Kko,eSo,oSo,n_,Z2e,rSo,tSo,fz,aSo,nSo,sSo,s_,K2e,lSo,iSo,gz,dSo,mSo,cSo,l_,ebe,fSo,gSo,hz,hSo,uSo,pSo,i_,obe,_So,bSo,uz,vSo,FSo,TSo,d_,rbe,MSo,ESo,pz,CSo,wSo,ASo,m_,tbe,LSo,ySo,_z,xSo,$So,kSo,c_,abe,SSo,RSo,bz,PSo,BSo,ISo,f_,nbe,NSo,qSo,vz,jSo,DSo,GSo,g_,sbe,OSo,VSo,Fz,XSo,zSo,QSo,h_,lbe,WSo,USo,Tz,HSo,JSo,YSo,u_,ibe,ZSo,KSo,Mz,eRo,oRo,rRo,p_,dbe,tRo,aRo,Ez,nRo,sRo,lRo,__,mbe,iRo,dRo,Cz,mRo,cRo,fRo,b_,gRo,v_,hRo,F_,Pk,uRo,cbe,pRo,jlo,qd,T_,fbe,Bk,_Ro,gbe,bRo,Dlo,qo,Ik,vRo,Nk,FRo,wz,TRo,MRo,ERo,qk,CRo,hbe,wRo,ARo,LRo,oo,jk,yRo,ube,xRo,$Ro,cn,kRo,pbe,SRo,RRo,_be,PRo,BRo,bbe,IRo,NRo,qRo,re,M_,vbe,jRo,DRo,Az,GRo,ORo,VRo,E_,Fbe,XRo,zRo,Lz,QRo,WRo,URo,C_,Tbe,HRo,JRo,yz,YRo,ZRo,KRo,w_,Mbe,ePo,oPo,xz,rPo,tPo,aPo,A_,Ebe,nPo,sPo,$z,lPo,iPo,dPo,L_,Cbe,mPo,cPo,kz,fPo,gPo,hPo,y_,wbe,uPo,pPo,Sz,_Po,bPo,vPo,x_,Abe,FPo,TPo,Rz,MPo,EPo,CPo,$_,Lbe,wPo,APo,Pz,LPo,yPo,xPo,k_,ybe,$Po,kPo,Bz,SPo,RPo,PPo,S_,xbe,BPo,IPo,Iz,NPo,qPo,jPo,R_,$be,DPo,GPo,Nz,OPo,VPo,XPo,P_,kbe,zPo,QPo,qz,WPo,UPo,HPo,B_,Sbe,JPo,YPo,jz,ZPo,KPo,eBo,I_,Rbe,oBo,rBo,Dz,tBo,aBo,nBo,N_,Pbe,sBo,lBo,Gz,iBo,dBo,mBo,q_,Bbe,cBo,fBo,Oz,gBo,hBo,uBo,j_,Ibe,pBo,_Bo,Vz,bBo,vBo,FBo,D_,Nbe,TBo,MBo,Xz,EBo,CBo,wBo,G_,qbe,ABo,LBo,zz,yBo,xBo,$Bo,O_,jbe,kBo,SBo,Qz,RBo,PBo,BBo,V_,Dbe,IBo,NBo,Wz,qBo,jBo,DBo,X_,Gbe,GBo,OBo,Uz,VBo,XBo,zBo,z_,Obe,QBo,WBo,Hz,UBo,HBo,JBo,Q_,Vbe,YBo,ZBo,Jz,KBo,eIo,oIo,W_,Xbe,rIo,tIo,Yz,aIo,nIo,sIo,U_,zbe,lIo,iIo,Zz,dIo,mIo,cIo,H_,Qbe,fIo,gIo,Kz,hIo,uIo,pIo,J_,Wbe,_Io,bIo,eQ,vIo,FIo,TIo,Y_,MIo,Z_,EIo,K_,Dk,CIo,Ube,wIo,Glo,jd,e1,Hbe,Gk,AIo,Jbe,LIo,Olo,jo,Ok,yIo,Vk,xIo,oQ,$Io,kIo,SIo,Xk,RIo,Ybe,PIo,BIo,IIo,ro,zk,NIo,Zbe,qIo,jIo,Dd,DIo,Kbe,GIo,OIo,eve,VIo,XIo,zIo,ie,o1,ove,QIo,WIo,rQ,UIo,HIo,JIo,r1,rve,YIo,ZIo,tQ,KIo,eNo,oNo,t1,tve,rNo,tNo,aQ,aNo,nNo,sNo,a1,ave,lNo,iNo,nQ,dNo,mNo,cNo,n1,nve,fNo,gNo,sQ,hNo,uNo,pNo,s1,sve,_No,bNo,lQ,vNo,FNo,TNo,l1,lve,MNo,ENo,iQ,CNo,wNo,ANo,i1,ive,LNo,yNo,dQ,xNo,$No,kNo,d1,dve,SNo,RNo,mQ,PNo,BNo,INo,m1,mve,NNo,qNo,cQ,jNo,DNo,GNo,c1,cve,ONo,VNo,fQ,XNo,zNo,QNo,f1,fve,WNo,UNo,gQ,HNo,JNo,YNo,g1,gve,ZNo,KNo,hQ,eqo,oqo,rqo,h1,hve,tqo,aqo,uQ,nqo,sqo,lqo,u1,uve,iqo,dqo,pQ,mqo,cqo,fqo,p1,pve,gqo,hqo,_Q,uqo,pqo,_qo,_1,_ve,bqo,vqo,bQ,Fqo,Tqo,Mqo,b1,bve,Eqo,Cqo,vQ,wqo,Aqo,Lqo,v1,vve,yqo,xqo,FQ,$qo,kqo,Sqo,F1,Fve,Rqo,Pqo,TQ,Bqo,Iqo,Nqo,T1,Tve,qqo,jqo,MQ,Dqo,Gqo,Oqo,M1,Mve,Vqo,Xqo,EQ,zqo,Qqo,Wqo,E1,Eve,Uqo,Hqo,CQ,Jqo,Yqo,Zqo,C1,Kqo,w1,ejo,A1,Qk,ojo,Cve,rjo,Vlo,Gd,L1,wve,Wk,tjo,Ave,ajo,Xlo,Do,Uk,njo,Od,sjo,wQ,ljo,ijo,AQ,djo,mjo,cjo,Hk,fjo,Lve,gjo,hjo,ujo,At,Jk,pjo,yve,_jo,bjo,Vd,vjo,xve,Fjo,Tjo,LQ,Mjo,Ejo,Cjo,y1,wjo,to,Yk,Ajo,$ve,Ljo,yjo,fn,xjo,kve,$jo,kjo,Sve,Sjo,Rjo,Rve,Pjo,Bjo,Ijo,y,x1,Pve,Njo,qjo,yQ,jjo,Djo,Gjo,$1,Bve,Ojo,Vjo,xQ,Xjo,zjo,Qjo,k1,Ive,Wjo,Ujo,$Q,Hjo,Jjo,Yjo,S1,Nve,Zjo,Kjo,kQ,eDo,oDo,rDo,R1,qve,tDo,aDo,SQ,nDo,sDo,lDo,P1,jve,iDo,dDo,RQ,mDo,cDo,fDo,B1,Dve,gDo,hDo,PQ,uDo,pDo,_Do,I1,Gve,bDo,vDo,BQ,FDo,TDo,MDo,N1,Ove,EDo,CDo,IQ,wDo,ADo,LDo,q1,Vve,yDo,xDo,NQ,$Do,kDo,SDo,j1,Xve,RDo,PDo,qQ,BDo,IDo,NDo,D1,zve,qDo,jDo,jQ,DDo,GDo,ODo,G1,Qve,VDo,XDo,DQ,zDo,QDo,WDo,O1,Wve,UDo,HDo,GQ,JDo,YDo,ZDo,V1,Uve,KDo,eGo,OQ,oGo,rGo,tGo,X1,Hve,aGo,nGo,VQ,sGo,lGo,iGo,z1,Jve,dGo,mGo,XQ,cGo,fGo,gGo,Q1,Yve,hGo,uGo,zQ,pGo,_Go,bGo,W1,Zve,vGo,FGo,QQ,TGo,MGo,EGo,U1,Kve,CGo,wGo,WQ,AGo,LGo,yGo,H1,eFe,xGo,$Go,UQ,kGo,SGo,RGo,J1,oFe,PGo,BGo,HQ,IGo,NGo,qGo,Y1,rFe,jGo,DGo,JQ,GGo,OGo,VGo,Z1,tFe,XGo,zGo,YQ,QGo,WGo,UGo,K1,aFe,HGo,JGo,ZQ,YGo,ZGo,KGo,e2,nFe,eOo,oOo,KQ,rOo,tOo,aOo,o2,sFe,nOo,sOo,eW,lOo,iOo,dOo,r2,lFe,mOo,cOo,oW,fOo,gOo,hOo,t2,iFe,uOo,pOo,rW,_Oo,bOo,vOo,a2,dFe,FOo,TOo,tW,MOo,EOo,COo,n2,mFe,wOo,AOo,aW,LOo,yOo,xOo,s2,cFe,$Oo,kOo,nW,SOo,ROo,POo,l2,fFe,BOo,IOo,sW,NOo,qOo,jOo,i2,gFe,DOo,GOo,lW,OOo,VOo,XOo,d2,hFe,zOo,QOo,iW,WOo,UOo,HOo,m2,uFe,JOo,YOo,dW,ZOo,KOo,eVo,c2,pFe,oVo,rVo,mW,tVo,aVo,nVo,f2,_Fe,sVo,lVo,cW,iVo,dVo,mVo,g2,bFe,cVo,fVo,fW,gVo,hVo,uVo,h2,vFe,pVo,_Vo,gW,bVo,vVo,FVo,Il,FFe,TVo,MVo,hW,EVo,CVo,uW,wVo,AVo,LVo,u2,TFe,yVo,xVo,pW,$Vo,kVo,SVo,p2,MFe,RVo,PVo,_W,BVo,IVo,NVo,_2,EFe,qVo,jVo,bW,DVo,GVo,OVo,b2,CFe,VVo,XVo,vW,zVo,QVo,WVo,v2,wFe,UVo,HVo,FW,JVo,YVo,ZVo,F2,AFe,KVo,eXo,TW,oXo,rXo,tXo,T2,LFe,aXo,nXo,MW,sXo,lXo,iXo,M2,yFe,dXo,mXo,EW,cXo,fXo,gXo,E2,xFe,hXo,uXo,CW,pXo,_Xo,bXo,C2,$Fe,vXo,FXo,wW,TXo,MXo,EXo,w2,kFe,CXo,wXo,AW,AXo,LXo,yXo,A2,SFe,xXo,$Xo,LW,kXo,SXo,RXo,L2,RFe,PXo,BXo,yW,IXo,NXo,qXo,y2,PFe,jXo,DXo,xW,GXo,OXo,VXo,x2,BFe,XXo,zXo,$W,QXo,WXo,UXo,$2,IFe,HXo,JXo,kW,YXo,ZXo,KXo,k2,NFe,ezo,ozo,SW,rzo,tzo,azo,S2,qFe,nzo,szo,RW,lzo,izo,dzo,R2,jFe,mzo,czo,PW,fzo,gzo,hzo,P2,DFe,uzo,pzo,BW,_zo,bzo,vzo,B2,GFe,Fzo,Tzo,IW,Mzo,Ezo,Czo,I2,OFe,wzo,Azo,NW,Lzo,yzo,xzo,N2,VFe,$zo,kzo,qW,Szo,Rzo,Pzo,q2,XFe,Bzo,Izo,jW,Nzo,qzo,jzo,j2,zFe,Dzo,Gzo,DW,Ozo,Vzo,Xzo,D2,QFe,zzo,Qzo,GW,Wzo,Uzo,Hzo,G2,WFe,Jzo,Yzo,OW,Zzo,Kzo,eQo,O2,UFe,oQo,rQo,VW,tQo,aQo,nQo,V2,HFe,sQo,lQo,XW,iQo,dQo,mQo,X2,JFe,cQo,fQo,zW,gQo,hQo,uQo,z2,YFe,pQo,_Qo,QW,bQo,vQo,FQo,Q2,ZFe,TQo,MQo,WW,EQo,CQo,wQo,W2,KFe,AQo,LQo,UW,yQo,xQo,$Qo,U2,eTe,kQo,SQo,HW,RQo,PQo,BQo,H2,oTe,IQo,NQo,JW,qQo,jQo,DQo,J2,rTe,GQo,OQo,YW,VQo,XQo,zQo,Y2,tTe,QQo,WQo,ZW,UQo,HQo,JQo,Z2,aTe,YQo,ZQo,KW,KQo,eWo,oWo,K2,nTe,rWo,tWo,eU,aWo,nWo,sWo,eb,sTe,lWo,iWo,oU,dWo,mWo,cWo,ob,lTe,fWo,gWo,rU,hWo,uWo,pWo,rb,iTe,_Wo,bWo,tU,vWo,FWo,TWo,tb,dTe,MWo,EWo,aU,CWo,wWo,AWo,ab,mTe,LWo,yWo,nU,xWo,$Wo,kWo,nb,cTe,SWo,RWo,sU,PWo,BWo,IWo,sb,fTe,NWo,qWo,lU,jWo,DWo,GWo,lb,gTe,OWo,VWo,iU,XWo,zWo,QWo,ib,hTe,WWo,UWo,dU,HWo,JWo,YWo,db,uTe,ZWo,KWo,mU,eUo,oUo,rUo,mb,pTe,tUo,aUo,cU,nUo,sUo,lUo,cb,_Te,iUo,dUo,fU,mUo,cUo,fUo,fb,bTe,gUo,hUo,gU,uUo,pUo,_Uo,gb,vTe,bUo,vUo,hU,FUo,TUo,MUo,hb,FTe,EUo,CUo,uU,wUo,AUo,LUo,ub,TTe,yUo,xUo,pU,$Uo,kUo,SUo,pb,MTe,RUo,PUo,_U,BUo,IUo,NUo,_b,ETe,qUo,jUo,bU,DUo,GUo,OUo,bb,CTe,VUo,XUo,vU,zUo,QUo,WUo,vb,wTe,UUo,HUo,FU,JUo,YUo,ZUo,Fb,ATe,KUo,eHo,TU,oHo,rHo,tHo,Tb,LTe,aHo,nHo,MU,sHo,lHo,iHo,Mb,yTe,dHo,mHo,EU,cHo,fHo,gHo,Eb,xTe,hHo,uHo,CU,pHo,_Ho,bHo,Cb,$Te,vHo,FHo,wU,THo,MHo,EHo,wb,kTe,CHo,wHo,AU,AHo,LHo,yHo,Ab,STe,xHo,$Ho,LU,kHo,SHo,RHo,Lb,RTe,PHo,BHo,yU,IHo,NHo,qHo,yb,PTe,jHo,DHo,xU,GHo,OHo,VHo,xb,BTe,XHo,zHo,$U,QHo,WHo,UHo,$b,ITe,HHo,JHo,kU,YHo,ZHo,KHo,kb,NTe,eJo,oJo,SU,rJo,tJo,aJo,Sb,qTe,nJo,sJo,RU,lJo,iJo,dJo,Rb,jTe,mJo,cJo,PU,fJo,gJo,hJo,Pb,DTe,uJo,pJo,BU,_Jo,bJo,vJo,Bb,GTe,FJo,TJo,IU,MJo,EJo,CJo,Ib,OTe,wJo,AJo,NU,LJo,yJo,xJo,Nb,VTe,$Jo,kJo,qU,SJo,RJo,PJo,qb,XTe,BJo,IJo,jU,NJo,qJo,jJo,jb,zTe,DJo,GJo,DU,OJo,VJo,XJo,Db,QTe,zJo,QJo,GU,WJo,UJo,HJo,Gb,WTe,JJo,YJo,OU,ZJo,KJo,eYo,Ob,UTe,oYo,rYo,VU,tYo,aYo,nYo,Vb,HTe,sYo,lYo,XU,iYo,dYo,mYo,Xb,JTe,cYo,fYo,zU,gYo,hYo,uYo,zb,YTe,pYo,_Yo,QU,bYo,vYo,FYo,Qb,ZTe,TYo,MYo,WU,EYo,CYo,wYo,Wb,KTe,AYo,LYo,UU,yYo,xYo,$Yo,Ub,eMe,kYo,SYo,HU,RYo,PYo,BYo,Hb,oMe,IYo,NYo,JU,qYo,jYo,DYo,Jb,rMe,GYo,OYo,YU,VYo,XYo,zYo,Yb,tMe,QYo,WYo,ZU,UYo,HYo,JYo,Zb,YYo,aMe,ZYo,KYo,nMe,eZo,oZo,Kb,zlo,Xd,ev,sMe,Zk,rZo,lMe,tZo,Qlo,Go,Kk,aZo,zd,nZo,KU,sZo,lZo,eH,iZo,dZo,mZo,eS,cZo,iMe,fZo,gZo,hZo,Lt,oS,uZo,dMe,pZo,_Zo,Qd,bZo,mMe,vZo,FZo,oH,TZo,MZo,EZo,ov,CZo,ao,rS,wZo,cMe,AZo,LZo,gn,yZo,fMe,xZo,$Zo,gMe,kZo,SZo,hMe,RZo,PZo,BZo,G,rv,uMe,IZo,NZo,rH,qZo,jZo,DZo,tv,pMe,GZo,OZo,tH,VZo,XZo,zZo,av,_Me,QZo,WZo,aH,UZo,HZo,JZo,nv,bMe,YZo,ZZo,nH,KZo,eKo,oKo,sv,vMe,rKo,tKo,sH,aKo,nKo,sKo,lv,FMe,lKo,iKo,lH,dKo,mKo,cKo,iv,TMe,fKo,gKo,iH,hKo,uKo,pKo,dv,MMe,_Ko,bKo,dH,vKo,FKo,TKo,mv,EMe,MKo,EKo,mH,CKo,wKo,AKo,cv,CMe,LKo,yKo,cH,xKo,$Ko,kKo,fv,wMe,SKo,RKo,fH,PKo,BKo,IKo,gv,AMe,NKo,qKo,gH,jKo,DKo,GKo,hv,LMe,OKo,VKo,hH,XKo,zKo,QKo,uv,yMe,WKo,UKo,uH,HKo,JKo,YKo,pv,xMe,ZKo,KKo,pH,eer,oer,rer,_v,$Me,ter,aer,_H,ner,ser,ler,bv,kMe,ier,der,bH,mer,cer,fer,vv,SMe,ger,her,vH,uer,per,_er,Fv,RMe,ber,ver,FH,Fer,Ter,Mer,Tv,PMe,Eer,Cer,TH,wer,Aer,Ler,Mv,BMe,yer,xer,MH,$er,ker,Ser,Ev,IMe,Rer,Per,EH,Ber,Ier,Ner,Cv,NMe,qer,jer,CH,Der,Ger,Oer,wv,qMe,Ver,Xer,wH,zer,Qer,Wer,Av,jMe,Uer,Her,AH,Jer,Yer,Zer,Lv,DMe,Ker,eor,LH,oor,ror,tor,yv,GMe,aor,nor,yH,sor,lor,ior,xv,OMe,dor,mor,xH,cor,gor,hor,$v,VMe,uor,por,$H,_or,bor,vor,kv,XMe,For,Tor,kH,Mor,Eor,Cor,Sv,zMe,wor,Aor,SH,Lor,yor,xor,Rv,QMe,$or,kor,RH,Sor,Ror,Por,Pv,WMe,Bor,Ior,PH,Nor,qor,jor,Bv,UMe,Dor,Gor,BH,Oor,Vor,Xor,Iv,HMe,zor,Qor,IH,Wor,Uor,Hor,Nv,JMe,Jor,Yor,NH,Zor,Kor,err,qv,YMe,orr,rrr,qH,trr,arr,nrr,jv,ZMe,srr,lrr,jH,irr,drr,mrr,Dv,KMe,crr,frr,DH,grr,hrr,urr,Gv,eEe,prr,_rr,GH,brr,vrr,Frr,Ov,oEe,Trr,Mrr,OH,Err,Crr,wrr,Vv,rEe,Arr,Lrr,VH,yrr,xrr,$rr,Xv,tEe,krr,Srr,XH,Rrr,Prr,Brr,zv,aEe,Irr,Nrr,zH,qrr,jrr,Drr,Qv,nEe,Grr,Orr,QH,Vrr,Xrr,zrr,Wv,sEe,Qrr,Wrr,WH,Urr,Hrr,Jrr,Uv,lEe,Yrr,Zrr,UH,Krr,etr,otr,Hv,iEe,rtr,ttr,HH,atr,ntr,str,Jv,dEe,ltr,itr,JH,dtr,mtr,ctr,Yv,ftr,mEe,gtr,htr,cEe,utr,ptr,Zv,Wlo,Wd,Kv,fEe,tS,_tr,gEe,btr,Ulo,Oo,aS,vtr,Ud,Ftr,YH,Ttr,Mtr,ZH,Etr,Ctr,wtr,nS,Atr,hEe,Ltr,ytr,xtr,yt,sS,$tr,uEe,ktr,Str,Hd,Rtr,pEe,Ptr,Btr,KH,Itr,Ntr,qtr,eF,jtr,no,lS,Dtr,_Ee,Gtr,Otr,hn,Vtr,bEe,Xtr,ztr,vEe,Qtr,Wtr,FEe,Utr,Htr,Jtr,W,oF,TEe,Ytr,Ztr,eJ,Ktr,ear,oar,rF,MEe,rar,tar,oJ,aar,nar,sar,tF,EEe,lar,iar,rJ,dar,mar,car,aF,CEe,far,gar,tJ,har,uar,par,nF,wEe,_ar,bar,aJ,Far,Tar,Mar,sF,AEe,Ear,Car,nJ,war,Aar,Lar,lF,LEe,yar,xar,sJ,$ar,kar,Sar,iF,yEe,Rar,Par,lJ,Bar,Iar,Nar,dF,xEe,qar,jar,iJ,Dar,Gar,Oar,mF,$Ee,Var,Xar,dJ,zar,Qar,War,cF,kEe,Uar,Har,mJ,Jar,Yar,Zar,fF,SEe,Kar,enr,cJ,onr,rnr,tnr,gF,REe,anr,nnr,fJ,snr,lnr,inr,hF,PEe,dnr,mnr,gJ,cnr,fnr,gnr,uF,BEe,hnr,unr,hJ,pnr,_nr,bnr,pF,IEe,vnr,Fnr,uJ,Tnr,Mnr,Enr,_F,NEe,Cnr,wnr,pJ,Anr,Lnr,ynr,bF,qEe,xnr,$nr,_J,knr,Snr,Rnr,vF,jEe,Pnr,Bnr,bJ,Inr,Nnr,qnr,FF,DEe,jnr,Dnr,vJ,Gnr,Onr,Vnr,TF,GEe,Xnr,znr,FJ,Qnr,Wnr,Unr,MF,OEe,Hnr,Jnr,TJ,Ynr,Znr,Knr,EF,VEe,esr,osr,MJ,rsr,tsr,asr,CF,XEe,nsr,ssr,EJ,lsr,isr,dsr,wF,zEe,msr,csr,CJ,fsr,gsr,hsr,AF,QEe,usr,psr,wJ,_sr,bsr,vsr,LF,WEe,Fsr,Tsr,AJ,Msr,Esr,Csr,yF,UEe,wsr,Asr,LJ,Lsr,ysr,xsr,xF,HEe,$sr,ksr,yJ,Ssr,Rsr,Psr,$F,JEe,Bsr,Isr,xJ,Nsr,qsr,jsr,kF,YEe,Dsr,Gsr,$J,Osr,Vsr,Xsr,SF,ZEe,zsr,Qsr,kJ,Wsr,Usr,Hsr,RF,KEe,Jsr,Ysr,SJ,Zsr,Ksr,elr,PF,e4e,olr,rlr,RJ,tlr,alr,nlr,BF,o4e,slr,llr,PJ,ilr,dlr,mlr,IF,r4e,clr,flr,BJ,glr,hlr,ulr,NF,t4e,plr,_lr,IJ,blr,vlr,Flr,qF,a4e,Tlr,Mlr,NJ,Elr,Clr,wlr,jF,n4e,Alr,Llr,qJ,ylr,xlr,$lr,DF,s4e,klr,Slr,jJ,Rlr,Plr,Blr,GF,l4e,Ilr,Nlr,DJ,qlr,jlr,Dlr,OF,i4e,Glr,Olr,GJ,Vlr,Xlr,zlr,VF,d4e,Qlr,Wlr,OJ,Ulr,Hlr,Jlr,XF,Ylr,m4e,Zlr,Klr,c4e,eir,oir,zF,Hlo,Jd,QF,f4e,iS,rir,g4e,tir,Jlo,Vo,dS,air,Yd,nir,VJ,sir,lir,XJ,iir,dir,mir,mS,cir,h4e,fir,gir,hir,xt,cS,uir,u4e,pir,_ir,Zd,bir,p4e,vir,Fir,zJ,Tir,Mir,Eir,WF,Cir,so,fS,wir,_4e,Air,Lir,un,yir,b4e,xir,$ir,v4e,kir,Sir,F4e,Rir,Pir,Bir,gS,UF,T4e,Iir,Nir,QJ,qir,jir,Dir,HF,M4e,Gir,Oir,WJ,Vir,Xir,zir,JF,Qir,E4e,Wir,Uir,C4e,Hir,Jir,YF,Ylo,Kd,ZF,w4e,hS,Yir,A4e,Zir,Zlo,Xo,uS,Kir,em,edr,UJ,odr,rdr,HJ,tdr,adr,ndr,pS,sdr,L4e,ldr,idr,ddr,$t,_S,mdr,y4e,cdr,fdr,om,gdr,x4e,hdr,udr,JJ,pdr,_dr,bdr,KF,vdr,lo,bS,Fdr,$4e,Tdr,Mdr,pn,Edr,k4e,Cdr,wdr,S4e,Adr,Ldr,R4e,ydr,xdr,$dr,Y,eT,P4e,kdr,Sdr,YJ,Rdr,Pdr,Bdr,oT,B4e,Idr,Ndr,ZJ,qdr,jdr,Ddr,rT,I4e,Gdr,Odr,KJ,Vdr,Xdr,zdr,tT,N4e,Qdr,Wdr,eY,Udr,Hdr,Jdr,aT,q4e,Ydr,Zdr,oY,Kdr,emr,omr,nT,j4e,rmr,tmr,rY,amr,nmr,smr,sT,D4e,lmr,imr,tY,dmr,mmr,cmr,lT,G4e,fmr,gmr,aY,hmr,umr,pmr,iT,O4e,_mr,bmr,nY,vmr,Fmr,Tmr,dT,V4e,Mmr,Emr,sY,Cmr,wmr,Amr,mT,X4e,Lmr,ymr,lY,xmr,$mr,kmr,cT,z4e,Smr,Rmr,iY,Pmr,Bmr,Imr,fT,Q4e,Nmr,qmr,dY,jmr,Dmr,Gmr,gT,W4e,Omr,Vmr,mY,Xmr,zmr,Qmr,hT,U4e,Wmr,Umr,cY,Hmr,Jmr,Ymr,uT,H4e,Zmr,Kmr,fY,ecr,ocr,rcr,pT,J4e,tcr,acr,gY,ncr,scr,lcr,_T,Y4e,icr,dcr,hY,mcr,ccr,fcr,bT,Z4e,gcr,hcr,uY,ucr,pcr,_cr,vT,K4e,bcr,vcr,pY,Fcr,Tcr,Mcr,FT,eCe,Ecr,Ccr,_Y,wcr,Acr,Lcr,TT,oCe,ycr,xcr,bY,$cr,kcr,Scr,MT,rCe,Rcr,Pcr,vY,Bcr,Icr,Ncr,ET,tCe,qcr,jcr,FY,Dcr,Gcr,Ocr,CT,aCe,Vcr,Xcr,TY,zcr,Qcr,Wcr,wT,nCe,Ucr,Hcr,MY,Jcr,Ycr,Zcr,AT,sCe,Kcr,efr,EY,ofr,rfr,tfr,LT,lCe,afr,nfr,CY,sfr,lfr,ifr,yT,iCe,dfr,mfr,wY,cfr,ffr,gfr,xT,dCe,hfr,ufr,AY,pfr,_fr,bfr,$T,mCe,vfr,Ffr,LY,Tfr,Mfr,Efr,kT,cCe,Cfr,wfr,yY,Afr,Lfr,yfr,ST,fCe,xfr,$fr,xY,kfr,Sfr,Rfr,RT,gCe,Pfr,Bfr,$Y,Ifr,Nfr,qfr,PT,hCe,jfr,Dfr,kY,Gfr,Ofr,Vfr,BT,uCe,Xfr,zfr,pCe,Qfr,Wfr,Ufr,IT,_Ce,Hfr,Jfr,SY,Yfr,Zfr,Kfr,NT,bCe,egr,ogr,RY,rgr,tgr,agr,qT,vCe,ngr,sgr,PY,lgr,igr,dgr,jT,FCe,mgr,cgr,BY,fgr,ggr,hgr,DT,ugr,TCe,pgr,_gr,MCe,bgr,vgr,GT,Klo,rm,OT,ECe,vS,Fgr,CCe,Tgr,eio,zo,FS,Mgr,tm,Egr,IY,Cgr,wgr,NY,Agr,Lgr,ygr,TS,xgr,wCe,$gr,kgr,Sgr,kt,MS,Rgr,ACe,Pgr,Bgr,am,Igr,LCe,Ngr,qgr,qY,jgr,Dgr,Ggr,VT,Ogr,io,ES,Vgr,yCe,Xgr,zgr,_n,Qgr,xCe,Wgr,Ugr,$Ce,Hgr,Jgr,kCe,Ygr,Zgr,Kgr,pe,XT,SCe,ehr,ohr,jY,rhr,thr,ahr,zT,RCe,nhr,shr,DY,lhr,ihr,dhr,QT,PCe,mhr,chr,GY,fhr,ghr,hhr,WT,BCe,uhr,phr,OY,_hr,bhr,vhr,UT,ICe,Fhr,Thr,VY,Mhr,Ehr,Chr,HT,NCe,whr,Ahr,XY,Lhr,yhr,xhr,JT,qCe,$hr,khr,zY,Shr,Rhr,Phr,YT,jCe,Bhr,Ihr,QY,Nhr,qhr,jhr,ZT,DCe,Dhr,Ghr,WY,Ohr,Vhr,Xhr,KT,GCe,zhr,Qhr,UY,Whr,Uhr,Hhr,eM,OCe,Jhr,Yhr,HY,Zhr,Khr,eur,oM,VCe,our,rur,JY,tur,aur,nur,rM,XCe,sur,lur,YY,iur,dur,mur,tM,zCe,cur,fur,ZY,gur,hur,uur,aM,QCe,pur,_ur,KY,bur,vur,Fur,nM,WCe,Tur,Mur,eZ,Eur,Cur,wur,sM,UCe,Aur,Lur,oZ,yur,xur,$ur,lM,HCe,kur,Sur,rZ,Rur,Pur,Bur,iM,JCe,Iur,Nur,tZ,qur,jur,Dur,dM,YCe,Gur,Our,aZ,Vur,Xur,zur,mM,Qur,ZCe,Wur,Uur,KCe,Hur,Jur,cM,oio,nm,fM,e3e,CS,Yur,o3e,Zur,rio,Qo,wS,Kur,sm,epr,nZ,opr,rpr,sZ,tpr,apr,npr,AS,spr,r3e,lpr,ipr,dpr,St,LS,mpr,t3e,cpr,fpr,lm,gpr,a3e,hpr,upr,lZ,ppr,_pr,bpr,gM,vpr,mo,yS,Fpr,n3e,Tpr,Mpr,bn,Epr,s3e,Cpr,wpr,l3e,Apr,Lpr,i3e,ypr,xpr,$pr,I,hM,d3e,kpr,Spr,iZ,Rpr,Ppr,Bpr,uM,m3e,Ipr,Npr,dZ,qpr,jpr,Dpr,pM,c3e,Gpr,Opr,mZ,Vpr,Xpr,zpr,_M,f3e,Qpr,Wpr,cZ,Upr,Hpr,Jpr,bM,g3e,Ypr,Zpr,fZ,Kpr,e_r,o_r,vM,h3e,r_r,t_r,gZ,a_r,n_r,s_r,FM,u3e,l_r,i_r,hZ,d_r,m_r,c_r,TM,p3e,f_r,g_r,uZ,h_r,u_r,p_r,MM,_3e,__r,b_r,pZ,v_r,F_r,T_r,EM,b3e,M_r,E_r,_Z,C_r,w_r,A_r,CM,v3e,L_r,y_r,bZ,x_r,$_r,k_r,wM,F3e,S_r,R_r,vZ,P_r,B_r,I_r,AM,T3e,N_r,q_r,FZ,j_r,D_r,G_r,LM,M3e,O_r,V_r,TZ,X_r,z_r,Q_r,yM,E3e,W_r,U_r,MZ,H_r,J_r,Y_r,xM,C3e,Z_r,K_r,EZ,e1r,o1r,r1r,$M,w3e,t1r,a1r,CZ,n1r,s1r,l1r,kM,A3e,i1r,d1r,wZ,m1r,c1r,f1r,SM,L3e,g1r,h1r,AZ,u1r,p1r,_1r,RM,y3e,b1r,v1r,LZ,F1r,T1r,M1r,PM,x3e,E1r,C1r,yZ,w1r,A1r,L1r,BM,$3e,y1r,x1r,xZ,$1r,k1r,S1r,IM,k3e,R1r,P1r,$Z,B1r,I1r,N1r,NM,S3e,q1r,j1r,kZ,D1r,G1r,O1r,qM,R3e,V1r,X1r,SZ,z1r,Q1r,W1r,jM,P3e,U1r,H1r,RZ,J1r,Y1r,Z1r,DM,B3e,K1r,e2r,PZ,o2r,r2r,t2r,GM,I3e,a2r,n2r,BZ,s2r,l2r,i2r,OM,N3e,d2r,m2r,IZ,c2r,f2r,g2r,VM,q3e,h2r,u2r,NZ,p2r,_2r,b2r,XM,j3e,v2r,F2r,qZ,T2r,M2r,E2r,zM,D3e,C2r,w2r,jZ,A2r,L2r,y2r,QM,G3e,x2r,$2r,DZ,k2r,S2r,R2r,WM,O3e,P2r,B2r,GZ,I2r,N2r,q2r,UM,V3e,j2r,D2r,OZ,G2r,O2r,V2r,HM,X3e,X2r,z2r,VZ,Q2r,W2r,U2r,JM,z3e,H2r,J2r,XZ,Y2r,Z2r,K2r,YM,Q3e,ebr,obr,zZ,rbr,tbr,abr,ZM,W3e,nbr,sbr,QZ,lbr,ibr,dbr,KM,U3e,mbr,cbr,WZ,fbr,gbr,hbr,eE,H3e,ubr,pbr,UZ,_br,bbr,vbr,oE,J3e,Fbr,Tbr,HZ,Mbr,Ebr,Cbr,rE,Y3e,wbr,Abr,JZ,Lbr,ybr,xbr,tE,Z3e,$br,kbr,YZ,Sbr,Rbr,Pbr,aE,K3e,Bbr,Ibr,ZZ,Nbr,qbr,jbr,nE,e5e,Dbr,Gbr,KZ,Obr,Vbr,Xbr,sE,o5e,zbr,Qbr,eK,Wbr,Ubr,Hbr,lE,r5e,Jbr,Ybr,oK,Zbr,Kbr,evr,iE,t5e,ovr,rvr,rK,tvr,avr,nvr,dE,a5e,svr,lvr,tK,ivr,dvr,mvr,mE,n5e,cvr,fvr,aK,gvr,hvr,uvr,cE,s5e,pvr,_vr,nK,bvr,vvr,Fvr,fE,l5e,Tvr,Mvr,sK,Evr,Cvr,wvr,gE,i5e,Avr,Lvr,lK,yvr,xvr,$vr,hE,d5e,kvr,Svr,iK,Rvr,Pvr,Bvr,uE,m5e,Ivr,Nvr,dK,qvr,jvr,Dvr,pE,c5e,Gvr,Ovr,mK,Vvr,Xvr,zvr,_E,Qvr,f5e,Wvr,Uvr,g5e,Hvr,Jvr,bE,tio,im,vE,h5e,xS,Yvr,u5e,Zvr,aio,Wo,$S,Kvr,dm,eFr,cK,oFr,rFr,fK,tFr,aFr,nFr,kS,sFr,p5e,lFr,iFr,dFr,Rt,SS,mFr,_5e,cFr,fFr,mm,gFr,b5e,hFr,uFr,gK,pFr,_Fr,bFr,FE,vFr,co,RS,FFr,v5e,TFr,MFr,vn,EFr,F5e,CFr,wFr,T5e,AFr,LFr,M5e,yFr,xFr,$Fr,K,TE,E5e,kFr,SFr,hK,RFr,PFr,BFr,ME,C5e,IFr,NFr,uK,qFr,jFr,DFr,EE,w5e,GFr,OFr,pK,VFr,XFr,zFr,CE,A5e,QFr,WFr,_K,UFr,HFr,JFr,wE,L5e,YFr,ZFr,bK,KFr,eTr,oTr,AE,y5e,rTr,tTr,vK,aTr,nTr,sTr,LE,x5e,lTr,iTr,FK,dTr,mTr,cTr,yE,$5e,fTr,gTr,TK,hTr,uTr,pTr,xE,k5e,_Tr,bTr,MK,vTr,FTr,TTr,$E,S5e,MTr,ETr,EK,CTr,wTr,ATr,kE,R5e,LTr,yTr,CK,xTr,$Tr,kTr,SE,P5e,STr,RTr,wK,PTr,BTr,ITr,RE,B5e,NTr,qTr,AK,jTr,DTr,GTr,PE,I5e,OTr,VTr,LK,XTr,zTr,QTr,BE,N5e,WTr,UTr,yK,HTr,JTr,YTr,IE,q5e,ZTr,KTr,xK,eMr,oMr,rMr,NE,j5e,tMr,aMr,$K,nMr,sMr,lMr,qE,D5e,iMr,dMr,kK,mMr,cMr,fMr,jE,G5e,gMr,hMr,SK,uMr,pMr,_Mr,DE,O5e,bMr,vMr,RK,FMr,TMr,MMr,GE,V5e,EMr,CMr,PK,wMr,AMr,LMr,OE,X5e,yMr,xMr,BK,$Mr,kMr,SMr,VE,z5e,RMr,PMr,IK,BMr,IMr,NMr,XE,Q5e,qMr,jMr,NK,DMr,GMr,OMr,zE,W5e,VMr,XMr,qK,zMr,QMr,WMr,QE,U5e,UMr,HMr,jK,JMr,YMr,ZMr,WE,H5e,KMr,eEr,DK,oEr,rEr,tEr,UE,J5e,aEr,nEr,GK,sEr,lEr,iEr,HE,Y5e,dEr,mEr,OK,cEr,fEr,gEr,JE,Z5e,hEr,uEr,VK,pEr,_Er,bEr,YE,K5e,vEr,FEr,XK,TEr,MEr,EEr,ZE,e0e,CEr,wEr,zK,AEr,LEr,yEr,KE,o0e,xEr,$Er,QK,kEr,SEr,REr,e4,PEr,r0e,BEr,IEr,t0e,NEr,qEr,o4,nio,cm,r4,a0e,PS,jEr,n0e,DEr,sio,Uo,BS,GEr,fm,OEr,WK,VEr,XEr,UK,zEr,QEr,WEr,IS,UEr,s0e,HEr,JEr,YEr,Pt,NS,ZEr,l0e,KEr,e4r,gm,o4r,i0e,r4r,t4r,HK,a4r,n4r,s4r,t4,l4r,fo,qS,i4r,d0e,d4r,m4r,Fn,c4r,m0e,f4r,g4r,c0e,h4r,u4r,f0e,p4r,_4r,b4r,Ye,a4,g0e,v4r,F4r,JK,T4r,M4r,E4r,n4,h0e,C4r,w4r,YK,A4r,L4r,y4r,s4,u0e,x4r,$4r,ZK,k4r,S4r,R4r,l4,p0e,P4r,B4r,KK,I4r,N4r,q4r,i4,_0e,j4r,D4r,eee,G4r,O4r,V4r,d4,b0e,X4r,z4r,oee,Q4r,W4r,U4r,m4,v0e,H4r,J4r,ree,Y4r,Z4r,K4r,c4,eCr,F0e,oCr,rCr,T0e,tCr,aCr,f4,lio,hm,g4,M0e,jS,nCr,E0e,sCr,iio,Ho,DS,lCr,um,iCr,tee,dCr,mCr,aee,cCr,fCr,gCr,GS,hCr,C0e,uCr,pCr,_Cr,Bt,OS,bCr,w0e,vCr,FCr,pm,TCr,A0e,MCr,ECr,nee,CCr,wCr,ACr,h4,LCr,go,VS,yCr,L0e,xCr,$Cr,Tn,kCr,y0e,SCr,RCr,x0e,PCr,BCr,$0e,ICr,NCr,qCr,U,u4,k0e,jCr,DCr,see,GCr,OCr,VCr,p4,S0e,XCr,zCr,lee,QCr,WCr,UCr,_4,R0e,HCr,JCr,iee,YCr,ZCr,KCr,b4,P0e,e3r,o3r,dee,r3r,t3r,a3r,v4,B0e,n3r,s3r,mee,l3r,i3r,d3r,F4,I0e,m3r,c3r,cee,f3r,g3r,h3r,T4,N0e,u3r,p3r,fee,_3r,b3r,v3r,M4,q0e,F3r,T3r,gee,M3r,E3r,C3r,E4,j0e,w3r,A3r,hee,L3r,y3r,x3r,C4,D0e,$3r,k3r,uee,S3r,R3r,P3r,w4,G0e,B3r,I3r,pee,N3r,q3r,j3r,A4,O0e,D3r,G3r,_ee,O3r,V3r,X3r,L4,V0e,z3r,Q3r,bee,W3r,U3r,H3r,y4,X0e,J3r,Y3r,vee,Z3r,K3r,e5r,x4,z0e,o5r,r5r,Fee,t5r,a5r,n5r,$4,Q0e,s5r,l5r,Tee,i5r,d5r,m5r,k4,W0e,c5r,f5r,Mee,g5r,h5r,u5r,S4,U0e,p5r,_5r,Eee,b5r,v5r,F5r,R4,H0e,T5r,M5r,Cee,E5r,C5r,w5r,P4,J0e,A5r,L5r,wee,y5r,x5r,$5r,B4,Y0e,k5r,S5r,Aee,R5r,P5r,B5r,I4,Z0e,I5r,N5r,Lee,q5r,j5r,D5r,N4,K0e,G5r,O5r,yee,V5r,X5r,z5r,q4,ewe,Q5r,W5r,xee,U5r,H5r,J5r,j4,owe,Y5r,Z5r,$ee,K5r,e0r,o0r,D4,rwe,r0r,t0r,kee,a0r,n0r,s0r,G4,twe,l0r,i0r,See,d0r,m0r,c0r,O4,awe,f0r,g0r,Ree,h0r,u0r,p0r,V4,nwe,_0r,b0r,Pee,v0r,F0r,T0r,X4,swe,M0r,E0r,Bee,C0r,w0r,A0r,z4,lwe,L0r,y0r,Iee,x0r,$0r,k0r,Q4,iwe,S0r,R0r,Nee,P0r,B0r,I0r,W4,dwe,N0r,q0r,qee,j0r,D0r,G0r,U4,mwe,O0r,V0r,jee,X0r,z0r,Q0r,H4,cwe,W0r,U0r,Dee,H0r,J0r,Y0r,J4,fwe,Z0r,K0r,Gee,ewr,owr,rwr,Y4,gwe,twr,awr,Oee,nwr,swr,lwr,Z4,hwe,iwr,dwr,Vee,mwr,cwr,fwr,K4,uwe,gwr,hwr,Xee,uwr,pwr,_wr,eC,pwe,bwr,vwr,zee,Fwr,Twr,Mwr,oC,_we,Ewr,Cwr,Qee,wwr,Awr,Lwr,rC,bwe,ywr,xwr,Wee,$wr,kwr,Swr,tC,Rwr,vwe,Pwr,Bwr,Fwe,Iwr,Nwr,aC,dio,_m,nC,Twe,XS,qwr,Mwe,jwr,mio,Jo,zS,Dwr,bm,Gwr,Uee,Owr,Vwr,Hee,Xwr,zwr,Qwr,QS,Wwr,Ewe,Uwr,Hwr,Jwr,It,WS,Ywr,Cwe,Zwr,Kwr,vm,eAr,wwe,oAr,rAr,Jee,tAr,aAr,nAr,sC,sAr,ho,US,lAr,Awe,iAr,dAr,Mn,mAr,Lwe,cAr,fAr,ywe,gAr,hAr,xwe,uAr,pAr,_Ar,O,lC,$we,bAr,vAr,Yee,FAr,TAr,MAr,iC,kwe,EAr,CAr,Zee,wAr,AAr,LAr,dC,Swe,yAr,xAr,Kee,$Ar,kAr,SAr,mC,Rwe,RAr,PAr,eoe,BAr,IAr,NAr,cC,Pwe,qAr,jAr,ooe,DAr,GAr,OAr,fC,Bwe,VAr,XAr,roe,zAr,QAr,WAr,gC,Iwe,UAr,HAr,toe,JAr,YAr,ZAr,hC,Nwe,KAr,e6r,aoe,o6r,r6r,t6r,uC,qwe,a6r,n6r,noe,s6r,l6r,i6r,pC,jwe,d6r,m6r,soe,c6r,f6r,g6r,_C,Dwe,h6r,u6r,loe,p6r,_6r,b6r,bC,Gwe,v6r,F6r,ioe,T6r,M6r,E6r,vC,Owe,C6r,w6r,doe,A6r,L6r,y6r,FC,Vwe,x6r,$6r,moe,k6r,S6r,R6r,TC,Xwe,P6r,B6r,coe,I6r,N6r,q6r,MC,zwe,j6r,D6r,foe,G6r,O6r,V6r,EC,Qwe,X6r,z6r,goe,Q6r,W6r,U6r,CC,Wwe,H6r,J6r,hoe,Y6r,Z6r,K6r,wC,Uwe,e7r,o7r,uoe,r7r,t7r,a7r,AC,Hwe,n7r,s7r,poe,l7r,i7r,d7r,LC,Jwe,m7r,c7r,_oe,f7r,g7r,h7r,yC,Ywe,u7r,p7r,boe,_7r,b7r,v7r,xC,Zwe,F7r,T7r,voe,M7r,E7r,C7r,$C,Kwe,w7r,A7r,Foe,L7r,y7r,x7r,kC,eAe,$7r,k7r,Toe,S7r,R7r,P7r,SC,oAe,B7r,I7r,Moe,N7r,q7r,j7r,RC,rAe,D7r,G7r,Eoe,O7r,V7r,X7r,PC,tAe,z7r,Q7r,Coe,W7r,U7r,H7r,BC,aAe,J7r,Y7r,woe,Z7r,K7r,e8r,IC,nAe,o8r,r8r,Aoe,t8r,a8r,n8r,NC,sAe,s8r,l8r,Loe,i8r,d8r,m8r,qC,lAe,c8r,f8r,yoe,g8r,h8r,u8r,jC,iAe,p8r,_8r,xoe,b8r,v8r,F8r,DC,dAe,T8r,M8r,$oe,E8r,C8r,w8r,GC,mAe,A8r,L8r,koe,y8r,x8r,$8r,OC,cAe,k8r,S8r,Soe,R8r,P8r,B8r,VC,fAe,I8r,N8r,Roe,q8r,j8r,D8r,XC,gAe,G8r,O8r,Poe,V8r,X8r,z8r,zC,hAe,Q8r,W8r,Boe,U8r,H8r,J8r,QC,uAe,Y8r,Z8r,Ioe,K8r,eLr,oLr,WC,pAe,rLr,tLr,Noe,aLr,nLr,sLr,UC,_Ae,lLr,iLr,qoe,dLr,mLr,cLr,HC,bAe,fLr,gLr,joe,hLr,uLr,pLr,JC,vAe,_Lr,bLr,Doe,vLr,FLr,TLr,YC,FAe,MLr,ELr,Goe,CLr,wLr,ALr,ZC,TAe,LLr,yLr,Ooe,xLr,$Lr,kLr,KC,MAe,SLr,RLr,Voe,PLr,BLr,ILr,e3,EAe,NLr,qLr,Xoe,jLr,DLr,GLr,o3,CAe,OLr,VLr,zoe,XLr,zLr,QLr,r3,WLr,wAe,ULr,HLr,AAe,JLr,YLr,t3,cio,Fm,a3,LAe,HS,ZLr,yAe,KLr,fio,Yo,JS,eyr,Tm,oyr,Qoe,ryr,tyr,Woe,ayr,nyr,syr,YS,lyr,xAe,iyr,dyr,myr,Nt,ZS,cyr,$Ae,fyr,gyr,Mm,hyr,kAe,uyr,pyr,Uoe,_yr,byr,vyr,n3,Fyr,uo,KS,Tyr,SAe,Myr,Eyr,En,Cyr,RAe,wyr,Ayr,PAe,Lyr,yyr,BAe,xyr,$yr,kyr,IAe,s3,NAe,Syr,Ryr,Hoe,Pyr,Byr,Iyr,l3,Nyr,qAe,qyr,jyr,jAe,Dyr,Gyr,i3,gio,Em,d3,DAe,eR,Oyr,GAe,Vyr,hio,Zo,oR,Xyr,Cm,zyr,Joe,Qyr,Wyr,Yoe,Uyr,Hyr,Jyr,rR,Yyr,OAe,Zyr,Kyr,e9r,qt,tR,o9r,VAe,r9r,t9r,wm,a9r,XAe,n9r,s9r,Zoe,l9r,i9r,d9r,m3,m9r,po,aR,c9r,zAe,f9r,g9r,Cn,h9r,QAe,u9r,p9r,WAe,_9r,b9r,UAe,v9r,F9r,T9r,Am,c3,HAe,M9r,E9r,Koe,C9r,w9r,A9r,f3,JAe,L9r,y9r,ere,x9r,$9r,k9r,g3,YAe,S9r,R9r,ore,P9r,B9r,I9r,h3,N9r,ZAe,q9r,j9r,KAe,D9r,G9r,u3,uio,Lm,p3,e6e,nR,O9r,o6e,V9r,pio,Ko,sR,X9r,ym,z9r,rre,Q9r,W9r,tre,U9r,H9r,J9r,lR,Y9r,r6e,Z9r,K9r,exr,jt,iR,oxr,t6e,rxr,txr,xm,axr,a6e,nxr,sxr,are,lxr,ixr,dxr,_3,mxr,_o,dR,cxr,n6e,fxr,gxr,wn,hxr,s6e,uxr,pxr,l6e,_xr,bxr,i6e,vxr,Fxr,Txr,Fe,b3,d6e,Mxr,Exr,nre,Cxr,wxr,Axr,v3,m6e,Lxr,yxr,sre,xxr,$xr,kxr,F3,c6e,Sxr,Rxr,lre,Pxr,Bxr,Ixr,T3,f6e,Nxr,qxr,ire,jxr,Dxr,Gxr,Nl,g6e,Oxr,Vxr,dre,Xxr,zxr,mre,Qxr,Wxr,Uxr,M3,h6e,Hxr,Jxr,cre,Yxr,Zxr,Kxr,ql,u6e,e$r,o$r,fre,r$r,t$r,gre,a$r,n$r,s$r,E3,p6e,l$r,i$r,hre,d$r,m$r,c$r,Dt,_6e,f$r,g$r,ure,h$r,u$r,pre,p$r,_$r,_re,b$r,v$r,F$r,C3,b6e,T$r,M$r,bre,E$r,C$r,w$r,w3,v6e,A$r,L$r,vre,y$r,x$r,$$r,A3,F6e,k$r,S$r,Fre,R$r,P$r,B$r,L3,T6e,I$r,N$r,Tre,q$r,j$r,D$r,y3,M6e,G$r,O$r,Mre,V$r,X$r,z$r,x3,E6e,Q$r,W$r,Ere,U$r,H$r,J$r,$3,C6e,Y$r,Z$r,Cre,K$r,ekr,okr,k3,w6e,rkr,tkr,wre,akr,nkr,skr,S3,A6e,lkr,ikr,Are,dkr,mkr,ckr,R3,fkr,L6e,gkr,hkr,y6e,ukr,pkr,P3,_io,$m,B3,x6e,mR,_kr,$6e,bkr,bio,er,cR,vkr,km,Fkr,Lre,Tkr,Mkr,yre,Ekr,Ckr,wkr,fR,Akr,k6e,Lkr,ykr,xkr,Gt,gR,$kr,S6e,kkr,Skr,Sm,Rkr,R6e,Pkr,Bkr,xre,Ikr,Nkr,qkr,I3,jkr,bo,hR,Dkr,P6e,Gkr,Okr,An,Vkr,B6e,Xkr,zkr,I6e,Qkr,Wkr,N6e,Ukr,Hkr,Jkr,q6e,N3,j6e,Ykr,Zkr,$re,Kkr,eSr,oSr,q3,rSr,D6e,tSr,aSr,G6e,nSr,sSr,j3,vio,Rm,D3,O6e,uR,lSr,V6e,iSr,Fio,or,pR,dSr,Pm,mSr,kre,cSr,fSr,Sre,gSr,hSr,uSr,_R,pSr,X6e,_Sr,bSr,vSr,Ot,bR,FSr,z6e,TSr,MSr,Bm,ESr,Q6e,CSr,wSr,Rre,ASr,LSr,ySr,G3,xSr,vo,vR,$Sr,W6e,kSr,SSr,Ln,RSr,U6e,PSr,BSr,H6e,ISr,NSr,J6e,qSr,jSr,DSr,Y6e,O3,Z6e,GSr,OSr,Pre,VSr,XSr,zSr,V3,QSr,K6e,WSr,USr,e7e,HSr,JSr,X3,Tio,Im,z3,o7e,FR,YSr,r7e,ZSr,Mio,rr,TR,KSr,Nm,eRr,Bre,oRr,rRr,Ire,tRr,aRr,nRr,MR,sRr,t7e,lRr,iRr,dRr,Vt,ER,mRr,a7e,cRr,fRr,qm,gRr,n7e,hRr,uRr,Nre,pRr,_Rr,bRr,Q3,vRr,Fo,CR,FRr,s7e,TRr,MRr,yn,ERr,l7e,CRr,wRr,i7e,ARr,LRr,d7e,yRr,xRr,$Rr,m7e,W3,c7e,kRr,SRr,qre,RRr,PRr,BRr,U3,IRr,f7e,NRr,qRr,g7e,jRr,DRr,H3,Eio,jm,J3,h7e,wR,GRr,u7e,ORr,Cio,tr,AR,VRr,Dm,XRr,jre,zRr,QRr,Dre,WRr,URr,HRr,LR,JRr,p7e,YRr,ZRr,KRr,Xt,yR,ePr,_7e,oPr,rPr,Gm,tPr,b7e,aPr,nPr,Gre,sPr,lPr,iPr,Y3,dPr,To,xR,mPr,v7e,cPr,fPr,xn,gPr,F7e,hPr,uPr,T7e,pPr,_Pr,M7e,bPr,vPr,FPr,Ne,Z3,E7e,TPr,MPr,Ore,EPr,CPr,wPr,K3,C7e,APr,LPr,Vre,yPr,xPr,$Pr,e5,w7e,kPr,SPr,Xre,RPr,PPr,BPr,o5,A7e,IPr,NPr,zre,qPr,jPr,DPr,r5,L7e,GPr,OPr,Qre,VPr,XPr,zPr,t5,y7e,QPr,WPr,Wre,UPr,HPr,JPr,a5,x7e,YPr,ZPr,Ure,KPr,eBr,oBr,n5,$7e,rBr,tBr,Hre,aBr,nBr,sBr,s5,k7e,lBr,iBr,Jre,dBr,mBr,cBr,l5,fBr,S7e,gBr,hBr,R7e,uBr,pBr,i5,wio,Om,d5,P7e,$R,_Br,B7e,bBr,Aio,ar,kR,vBr,Vm,FBr,Yre,TBr,MBr,Zre,EBr,CBr,wBr,SR,ABr,I7e,LBr,yBr,xBr,zt,RR,$Br,N7e,kBr,SBr,Xm,RBr,q7e,PBr,BBr,Kre,IBr,NBr,qBr,m5,jBr,Mo,PR,DBr,j7e,GBr,OBr,$n,VBr,D7e,XBr,zBr,G7e,QBr,WBr,O7e,UBr,HBr,JBr,vt,c5,V7e,YBr,ZBr,ete,KBr,eIr,oIr,f5,X7e,rIr,tIr,ote,aIr,nIr,sIr,g5,z7e,lIr,iIr,rte,dIr,mIr,cIr,h5,Q7e,fIr,gIr,tte,hIr,uIr,pIr,u5,W7e,_Ir,bIr,ate,vIr,FIr,TIr,p5,MIr,U7e,EIr,CIr,H7e,wIr,AIr,_5,Lio,zm,b5,J7e,BR,LIr,Y7e,yIr,yio,nr,IR,xIr,Qm,$Ir,nte,kIr,SIr,ste,RIr,PIr,BIr,NR,IIr,Z7e,NIr,qIr,jIr,Qt,qR,DIr,K7e,GIr,OIr,Wm,VIr,e8e,XIr,zIr,lte,QIr,WIr,UIr,v5,HIr,Eo,jR,JIr,o8e,YIr,ZIr,kn,KIr,r8e,eNr,oNr,t8e,rNr,tNr,a8e,aNr,nNr,sNr,xe,F5,n8e,lNr,iNr,ite,dNr,mNr,cNr,T5,s8e,fNr,gNr,dte,hNr,uNr,pNr,M5,l8e,_Nr,bNr,mte,vNr,FNr,TNr,E5,i8e,MNr,ENr,cte,CNr,wNr,ANr,C5,d8e,LNr,yNr,fte,xNr,$Nr,kNr,w5,m8e,SNr,RNr,gte,PNr,BNr,INr,A5,c8e,NNr,qNr,hte,jNr,DNr,GNr,L5,f8e,ONr,VNr,ute,XNr,zNr,QNr,y5,g8e,WNr,UNr,pte,HNr,JNr,YNr,x5,h8e,ZNr,KNr,_te,eqr,oqr,rqr,$5,tqr,u8e,aqr,nqr,p8e,sqr,lqr,k5,xio,Um,S5,_8e,DR,iqr,b8e,dqr,$io,sr,GR,mqr,Hm,cqr,bte,fqr,gqr,vte,hqr,uqr,pqr,OR,_qr,v8e,bqr,vqr,Fqr,Wt,VR,Tqr,F8e,Mqr,Eqr,Jm,Cqr,T8e,wqr,Aqr,Fte,Lqr,yqr,xqr,R5,$qr,Co,XR,kqr,M8e,Sqr,Rqr,Sn,Pqr,E8e,Bqr,Iqr,C8e,Nqr,qqr,w8e,jqr,Dqr,Gqr,Ym,P5,A8e,Oqr,Vqr,Tte,Xqr,zqr,Qqr,B5,L8e,Wqr,Uqr,Mte,Hqr,Jqr,Yqr,I5,y8e,Zqr,Kqr,Ete,ejr,ojr,rjr,N5,tjr,x8e,ajr,njr,$8e,sjr,ljr,q5,kio,Zm,j5,k8e,zR,ijr,S8e,djr,Sio,lr,QR,mjr,Km,cjr,Cte,fjr,gjr,wte,hjr,ujr,pjr,WR,_jr,R8e,bjr,vjr,Fjr,Ut,UR,Tjr,P8e,Mjr,Ejr,ec,Cjr,B8e,wjr,Ajr,Ate,Ljr,yjr,xjr,D5,$jr,wo,HR,kjr,I8e,Sjr,Rjr,Rn,Pjr,N8e,Bjr,Ijr,q8e,Njr,qjr,j8e,jjr,Djr,Gjr,Ft,G5,D8e,Ojr,Vjr,Lte,Xjr,zjr,Qjr,O5,G8e,Wjr,Ujr,yte,Hjr,Jjr,Yjr,V5,O8e,Zjr,Kjr,xte,eDr,oDr,rDr,X5,V8e,tDr,aDr,$te,nDr,sDr,lDr,z5,X8e,iDr,dDr,kte,mDr,cDr,fDr,Q5,gDr,z8e,hDr,uDr,Q8e,pDr,_Dr,W5,Rio,oc,U5,W8e,JR,bDr,U8e,vDr,Pio,ir,YR,FDr,rc,TDr,Ste,MDr,EDr,Rte,CDr,wDr,ADr,ZR,LDr,H8e,yDr,xDr,$Dr,Ht,KR,kDr,J8e,SDr,RDr,tc,PDr,Y8e,BDr,IDr,Pte,NDr,qDr,jDr,H5,DDr,Ao,eP,GDr,Z8e,ODr,VDr,Pn,XDr,K8e,zDr,QDr,eLe,WDr,UDr,oLe,HDr,JDr,YDr,Bn,J5,rLe,ZDr,KDr,Bte,eGr,oGr,rGr,Y5,tLe,tGr,aGr,Ite,nGr,sGr,lGr,Z5,aLe,iGr,dGr,Nte,mGr,cGr,fGr,K5,nLe,gGr,hGr,qte,uGr,pGr,_Gr,e0,bGr,sLe,vGr,FGr,lLe,TGr,MGr,o0,Bio,ac,r0,iLe,oP,EGr,dLe,CGr,Iio,dr,rP,wGr,nc,AGr,jte,LGr,yGr,Dte,xGr,$Gr,kGr,tP,SGr,mLe,RGr,PGr,BGr,Jt,aP,IGr,cLe,NGr,qGr,sc,jGr,fLe,DGr,GGr,Gte,OGr,VGr,XGr,t0,zGr,Lo,nP,QGr,gLe,WGr,UGr,In,HGr,hLe,JGr,YGr,uLe,ZGr,KGr,pLe,eOr,oOr,rOr,Tt,a0,_Le,tOr,aOr,Ote,nOr,sOr,lOr,n0,bLe,iOr,dOr,Vte,mOr,cOr,fOr,s0,vLe,gOr,hOr,Xte,uOr,pOr,_Or,l0,FLe,bOr,vOr,zte,FOr,TOr,MOr,i0,TLe,EOr,COr,Qte,wOr,AOr,LOr,d0,yOr,MLe,xOr,$Or,ELe,kOr,SOr,m0,Nio,lc,c0,CLe,sP,ROr,wLe,POr,qio,mr,lP,BOr,ic,IOr,Wte,NOr,qOr,Ute,jOr,DOr,GOr,iP,OOr,ALe,VOr,XOr,zOr,Yt,dP,QOr,LLe,WOr,UOr,dc,HOr,yLe,JOr,YOr,Hte,ZOr,KOr,eVr,f0,oVr,yo,mP,rVr,xLe,tVr,aVr,Nn,nVr,$Le,sVr,lVr,kLe,iVr,dVr,SLe,mVr,cVr,fVr,RLe,g0,PLe,gVr,hVr,Jte,uVr,pVr,_Vr,h0,bVr,BLe,vVr,FVr,ILe,TVr,MVr,u0,jio,mc,p0,NLe,cP,EVr,qLe,CVr,Dio,cr,fP,wVr,cc,AVr,Yte,LVr,yVr,Zte,xVr,$Vr,kVr,gP,SVr,jLe,RVr,PVr,BVr,Zt,hP,IVr,DLe,NVr,qVr,fc,jVr,GLe,DVr,GVr,Kte,OVr,VVr,XVr,_0,zVr,xo,uP,QVr,OLe,WVr,UVr,qn,HVr,VLe,JVr,YVr,XLe,ZVr,KVr,zLe,eXr,oXr,rXr,Mt,b0,QLe,tXr,aXr,eae,nXr,sXr,lXr,v0,WLe,iXr,dXr,oae,mXr,cXr,fXr,F0,ULe,gXr,hXr,rae,uXr,pXr,_Xr,T0,HLe,bXr,vXr,tae,FXr,TXr,MXr,M0,JLe,EXr,CXr,aae,wXr,AXr,LXr,E0,yXr,YLe,xXr,$Xr,ZLe,kXr,SXr,C0,Gio,gc,w0,KLe,pP,RXr,eye,PXr,Oio,fr,_P,BXr,hc,IXr,nae,NXr,qXr,sae,jXr,DXr,GXr,bP,OXr,oye,VXr,XXr,zXr,Kt,vP,QXr,rye,WXr,UXr,uc,HXr,tye,JXr,YXr,lae,ZXr,KXr,ezr,A0,ozr,$o,FP,rzr,aye,tzr,azr,jn,nzr,nye,szr,lzr,sye,izr,dzr,lye,mzr,czr,fzr,iye,L0,dye,gzr,hzr,iae,uzr,pzr,_zr,y0,bzr,mye,vzr,Fzr,cye,Tzr,Mzr,x0,Vio,pc,$0,fye,TP,Ezr,gye,Czr,Xio,gr,MP,wzr,_c,Azr,dae,Lzr,yzr,mae,xzr,$zr,kzr,EP,Szr,hye,Rzr,Pzr,Bzr,ea,CP,Izr,uye,Nzr,qzr,bc,jzr,pye,Dzr,Gzr,cae,Ozr,Vzr,Xzr,k0,zzr,ko,wP,Qzr,_ye,Wzr,Uzr,Dn,Hzr,bye,Jzr,Yzr,vye,Zzr,Kzr,Fye,eQr,oQr,rQr,Tye,S0,Mye,tQr,aQr,fae,nQr,sQr,lQr,R0,iQr,Eye,dQr,mQr,Cye,cQr,fQr,P0,zio,vc,B0,wye,AP,gQr,Aye,hQr,Qio,hr,LP,uQr,Fc,pQr,gae,_Qr,bQr,hae,vQr,FQr,TQr,yP,MQr,Lye,EQr,CQr,wQr,oa,xP,AQr,yye,LQr,yQr,Tc,xQr,xye,$Qr,kQr,uae,SQr,RQr,PQr,I0,BQr,Xr,$P,IQr,$ye,NQr,qQr,Gn,jQr,kye,DQr,GQr,Sye,OQr,VQr,Rye,XQr,zQr,QQr,P,N0,Pye,WQr,UQr,pae,HQr,JQr,YQr,q0,Bye,ZQr,KQr,_ae,eWr,oWr,rWr,j0,Iye,tWr,aWr,bae,nWr,sWr,lWr,D0,Nye,iWr,dWr,vae,mWr,cWr,fWr,G0,qye,gWr,hWr,Fae,uWr,pWr,_Wr,O0,jye,bWr,vWr,Tae,FWr,TWr,MWr,V0,Dye,EWr,CWr,Mae,wWr,AWr,LWr,X0,Gye,yWr,xWr,Eae,$Wr,kWr,SWr,z0,Oye,RWr,PWr,Cae,BWr,IWr,NWr,Q0,Vye,qWr,jWr,wae,DWr,GWr,OWr,W0,Xye,VWr,XWr,Aae,zWr,QWr,WWr,U0,zye,UWr,HWr,Lae,JWr,YWr,ZWr,H0,Qye,KWr,eUr,yae,oUr,rUr,tUr,J0,Wye,aUr,nUr,xae,sUr,lUr,iUr,Y0,Uye,dUr,mUr,$ae,cUr,fUr,gUr,Z0,Hye,hUr,uUr,kae,pUr,_Ur,bUr,K0,Jye,vUr,FUr,Sae,TUr,MUr,EUr,ew,Yye,CUr,wUr,Rae,AUr,LUr,yUr,ow,Zye,xUr,$Ur,Pae,kUr,SUr,RUr,rw,Kye,PUr,BUr,Bae,IUr,NUr,qUr,jl,e9e,jUr,DUr,Iae,GUr,OUr,Nae,VUr,XUr,zUr,tw,o9e,QUr,WUr,qae,UUr,HUr,JUr,aw,r9e,YUr,ZUr,jae,KUr,eHr,oHr,nw,t9e,rHr,tHr,Dae,aHr,nHr,sHr,sw,a9e,lHr,iHr,Gae,dHr,mHr,cHr,lw,n9e,fHr,gHr,Oae,hHr,uHr,pHr,iw,s9e,_Hr,bHr,Vae,vHr,FHr,THr,dw,l9e,MHr,EHr,Xae,CHr,wHr,AHr,mw,i9e,LHr,yHr,zae,xHr,$Hr,kHr,cw,d9e,SHr,RHr,Qae,PHr,BHr,IHr,fw,m9e,NHr,qHr,Wae,jHr,DHr,GHr,gw,c9e,OHr,VHr,Uae,XHr,zHr,QHr,hw,f9e,WHr,UHr,Hae,HHr,JHr,YHr,uw,g9e,ZHr,KHr,Jae,eJr,oJr,rJr,pw,h9e,tJr,aJr,Yae,nJr,sJr,lJr,_w,u9e,iJr,dJr,Zae,mJr,cJr,fJr,bw,p9e,gJr,hJr,Kae,uJr,pJr,_Jr,vw,_9e,bJr,vJr,ene,FJr,TJr,MJr,Fw,b9e,EJr,CJr,one,wJr,AJr,LJr,Tw,v9e,yJr,xJr,rne,$Jr,kJr,SJr,Mw,F9e,RJr,PJr,tne,BJr,IJr,NJr,Ew,T9e,qJr,jJr,ane,DJr,GJr,OJr,Cw,M9e,VJr,XJr,nne,zJr,QJr,WJr,ww,E9e,UJr,HJr,sne,JJr,YJr,ZJr,Aw,C9e,KJr,eYr,lne,oYr,rYr,tYr,Lw,w9e,aYr,nYr,ine,sYr,lYr,iYr,yw,A9e,dYr,mYr,dne,cYr,fYr,gYr,xw,L9e,hYr,uYr,mne,pYr,_Yr,bYr,$w,y9e,vYr,FYr,cne,TYr,MYr,EYr,kw,x9e,CYr,wYr,fne,AYr,LYr,yYr,Sw,$9e,xYr,$Yr,gne,kYr,SYr,RYr,Rw,k9e,PYr,BYr,hne,IYr,NYr,qYr,Pw,S9e,jYr,DYr,une,GYr,OYr,VYr,Bw,R9e,XYr,zYr,pne,QYr,WYr,UYr,Iw,P9e,HYr,JYr,_ne,YYr,ZYr,KYr,Nw,B9e,eZr,oZr,bne,rZr,tZr,aZr,qw,I9e,nZr,sZr,vne,lZr,iZr,dZr,jw,N9e,mZr,cZr,Fne,fZr,gZr,hZr,Dw,Wio,Mc,Gw,q9e,kP,uZr,j9e,pZr,Uio,ur,SP,_Zr,Ec,bZr,Tne,vZr,FZr,Mne,TZr,MZr,EZr,RP,CZr,D9e,wZr,AZr,LZr,ra,PP,yZr,G9e,xZr,$Zr,Cc,kZr,O9e,SZr,RZr,Ene,PZr,BZr,IZr,Ow,NZr,zr,BP,qZr,V9e,jZr,DZr,On,GZr,X9e,OZr,VZr,z9e,XZr,zZr,Q9e,QZr,WZr,UZr,de,Vw,W9e,HZr,JZr,Cne,YZr,ZZr,KZr,Xw,U9e,eKr,oKr,wne,rKr,tKr,aKr,zw,H9e,nKr,sKr,Ane,lKr,iKr,dKr,Qw,J9e,mKr,cKr,Lne,fKr,gKr,hKr,Ww,Y9e,uKr,pKr,yne,_Kr,bKr,vKr,Uw,Z9e,FKr,TKr,xne,MKr,EKr,CKr,Hw,K9e,wKr,AKr,$ne,LKr,yKr,xKr,Jw,exe,$Kr,kKr,kne,SKr,RKr,PKr,Yw,oxe,BKr,IKr,Sne,NKr,qKr,jKr,Zw,rxe,DKr,GKr,Rne,OKr,VKr,XKr,Kw,txe,zKr,QKr,Pne,WKr,UKr,HKr,eA,axe,JKr,YKr,Bne,ZKr,KKr,eet,oA,nxe,oet,ret,Ine,tet,aet,net,rA,sxe,set,iet,Nne,det,met,cet,tA,lxe,fet,get,qne,het,uet,pet,aA,ixe,_et,bet,jne,vet,Fet,Tet,nA,dxe,Met,Eet,Dne,Cet,wet,Aet,sA,mxe,Let,yet,Gne,xet,$et,ket,lA,cxe,Set,Ret,One,Pet,Bet,Iet,iA,fxe,Net,qet,Vne,jet,Det,Get,dA,gxe,Oet,Vet,Xne,Xet,zet,Qet,mA,hxe,Wet,Uet,zne,Het,Jet,Yet,cA,uxe,Zet,Ket,Qne,eot,oot,rot,fA,Hio,wc,gA,pxe,IP,tot,_xe,aot,Jio,pr,NP,not,Ac,sot,Wne,lot,iot,Une,dot,mot,cot,qP,fot,bxe,got,hot,uot,ta,jP,pot,vxe,_ot,bot,Lc,vot,Fxe,Fot,Tot,Hne,Mot,Eot,Cot,hA,wot,Qr,DP,Aot,Txe,Lot,yot,Vn,xot,Mxe,$ot,kot,Exe,Sot,Rot,Cxe,Pot,Bot,Iot,Ce,uA,wxe,Not,qot,Jne,jot,Dot,Got,pA,Axe,Oot,Vot,Yne,Xot,zot,Qot,_A,Lxe,Wot,Uot,Zne,Hot,Jot,Yot,bA,yxe,Zot,Kot,Kne,ert,ort,rrt,vA,xxe,trt,art,ese,nrt,srt,lrt,FA,$xe,irt,drt,ose,mrt,crt,frt,TA,kxe,grt,hrt,rse,urt,prt,_rt,MA,Sxe,brt,vrt,tse,Frt,Trt,Mrt,EA,Rxe,Ert,Crt,ase,wrt,Art,Lrt,CA,Pxe,yrt,xrt,nse,$rt,krt,Srt,wA,Bxe,Rrt,Prt,sse,Brt,Irt,Nrt,AA,Ixe,qrt,jrt,lse,Drt,Grt,Ort,LA,Nxe,Vrt,Xrt,ise,zrt,Qrt,Wrt,yA,qxe,Urt,Hrt,dse,Jrt,Yrt,Zrt,xA,Yio,yc,$A,jxe,GP,Krt,Dxe,ett,Zio,_r,OP,ott,xc,rtt,mse,ttt,att,cse,ntt,stt,ltt,VP,itt,Gxe,dtt,mtt,ctt,aa,XP,ftt,Oxe,gtt,htt,$c,utt,Vxe,ptt,_tt,fse,btt,vtt,Ftt,kA,Ttt,Wr,zP,Mtt,Xxe,Ett,Ctt,Xn,wtt,zxe,Att,Ltt,Qxe,ytt,xtt,Wxe,$tt,ktt,Stt,$e,SA,Uxe,Rtt,Ptt,gse,Btt,Itt,Ntt,RA,Hxe,qtt,jtt,hse,Dtt,Gtt,Ott,PA,Jxe,Vtt,Xtt,use,ztt,Qtt,Wtt,Dl,Yxe,Utt,Htt,pse,Jtt,Ytt,_se,Ztt,Ktt,eat,BA,Zxe,oat,rat,bse,tat,aat,nat,IA,Kxe,sat,lat,vse,iat,dat,mat,NA,e$e,cat,fat,Fse,gat,hat,uat,qA,o$e,pat,_at,Tse,bat,vat,Fat,jA,r$e,Tat,Mat,Mse,Eat,Cat,wat,DA,t$e,Aat,Lat,Ese,yat,xat,$at,GA,Kio,kc,OA,a$e,QP,kat,n$e,Sat,edo,br,WP,Rat,Sc,Pat,Cse,Bat,Iat,wse,Nat,qat,jat,UP,Dat,s$e,Gat,Oat,Vat,na,HP,Xat,l$e,zat,Qat,Rc,Wat,i$e,Uat,Hat,Ase,Jat,Yat,Zat,VA,Kat,Ur,JP,ent,d$e,ont,rnt,zn,tnt,m$e,ant,nnt,c$e,snt,lnt,f$e,int,dnt,mnt,Pc,XA,g$e,cnt,fnt,Lse,gnt,hnt,unt,zA,h$e,pnt,_nt,yse,bnt,vnt,Fnt,QA,u$e,Tnt,Mnt,xse,Ent,Cnt,wnt,WA,odo,Bc,UA,p$e,YP,Ant,_$e,Lnt,rdo,vr,ZP,ynt,Ic,xnt,$se,$nt,knt,kse,Snt,Rnt,Pnt,KP,Bnt,b$e,Int,Nnt,qnt,sa,eB,jnt,v$e,Dnt,Gnt,Nc,Ont,F$e,Vnt,Xnt,Sse,znt,Qnt,Wnt,HA,Unt,Hr,oB,Hnt,T$e,Jnt,Ynt,Qn,Znt,M$e,Knt,est,E$e,ost,rst,C$e,tst,ast,nst,ge,JA,w$e,sst,lst,Rse,ist,dst,mst,YA,A$e,cst,fst,Pse,gst,hst,ust,ZA,L$e,pst,_st,Bse,bst,vst,Fst,KA,y$e,Tst,Mst,Ise,Est,Cst,wst,e6,x$e,Ast,Lst,Nse,yst,xst,$st,o6,$$e,kst,Sst,qse,Rst,Pst,Bst,r6,k$e,Ist,Nst,jse,qst,jst,Dst,t6,S$e,Gst,Ost,Dse,Vst,Xst,zst,a6,R$e,Qst,Wst,Gse,Ust,Hst,Jst,n6,P$e,Yst,Zst,Ose,Kst,elt,olt,s6,B$e,rlt,tlt,Vse,alt,nlt,slt,l6,I$e,llt,ilt,Xse,dlt,mlt,clt,i6,N$e,flt,glt,zse,hlt,ult,plt,d6,q$e,_lt,blt,Qse,vlt,Flt,Tlt,m6,j$e,Mlt,Elt,Wse,Clt,wlt,Alt,c6,D$e,Llt,ylt,Use,xlt,$lt,klt,f6,G$e,Slt,Rlt,Hse,Plt,Blt,Ilt,g6,O$e,Nlt,qlt,Jse,jlt,Dlt,Glt,h6,V$e,Olt,Vlt,Yse,Xlt,zlt,Qlt,u6,X$e,Wlt,Ult,Zse,Hlt,Jlt,Ylt,p6,z$e,Zlt,Klt,Kse,eit,oit,rit,_6,tdo,qc,b6,Q$e,rB,tit,W$e,ait,ado,Fr,tB,nit,jc,sit,ele,lit,iit,ole,dit,mit,cit,aB,fit,U$e,git,hit,uit,la,nB,pit,H$e,_it,bit,Dc,vit,J$e,Fit,Tit,rle,Mit,Eit,Cit,v6,wit,Jr,sB,Ait,Y$e,Lit,yit,Wn,xit,Z$e,$it,kit,K$e,Sit,Rit,eke,Pit,Bit,Iit,ke,F6,oke,Nit,qit,tle,jit,Dit,Git,T6,rke,Oit,Vit,ale,Xit,zit,Qit,M6,tke,Wit,Uit,nle,Hit,Jit,Yit,E6,ake,Zit,Kit,sle,edt,odt,rdt,C6,nke,tdt,adt,lle,ndt,sdt,ldt,w6,ske,idt,ddt,ile,mdt,cdt,fdt,A6,lke,gdt,hdt,dle,udt,pdt,_dt,L6,ike,bdt,vdt,mle,Fdt,Tdt,Mdt,y6,dke,Edt,Cdt,cle,wdt,Adt,Ldt,x6,mke,ydt,xdt,fle,$dt,kdt,Sdt,$6,ndo,Gc,k6,cke,lB,Rdt,fke,Pdt,sdo,Tr,iB,Bdt,Oc,Idt,gle,Ndt,qdt,hle,jdt,Ddt,Gdt,dB,Odt,gke,Vdt,Xdt,zdt,ia,mB,Qdt,hke,Wdt,Udt,Vc,Hdt,uke,Jdt,Ydt,ule,Zdt,Kdt,emt,S6,omt,Yr,cB,rmt,pke,tmt,amt,Un,nmt,_ke,smt,lmt,bke,imt,dmt,vke,mmt,cmt,fmt,te,R6,Fke,gmt,hmt,ple,umt,pmt,_mt,P6,Tke,bmt,vmt,_le,Fmt,Tmt,Mmt,B6,Mke,Emt,Cmt,ble,wmt,Amt,Lmt,I6,Eke,ymt,xmt,vle,$mt,kmt,Smt,N6,Cke,Rmt,Pmt,Fle,Bmt,Imt,Nmt,q6,wke,qmt,jmt,Tle,Dmt,Gmt,Omt,j6,Ake,Vmt,Xmt,Mle,zmt,Qmt,Wmt,D6,Lke,Umt,Hmt,Ele,Jmt,Ymt,Zmt,G6,yke,Kmt,ect,Cle,oct,rct,tct,O6,xke,act,nct,wle,sct,lct,ict,V6,$ke,dct,mct,Ale,cct,fct,gct,X6,kke,hct,uct,Lle,pct,_ct,bct,z6,Ske,vct,Fct,yle,Tct,Mct,Ect,Q6,Rke,Cct,wct,xle,Act,Lct,yct,W6,Pke,xct,$ct,$le,kct,Sct,Rct,U6,Bke,Pct,Bct,kle,Ict,Nct,qct,H6,Ike,jct,Dct,Sle,Gct,Oct,Vct,J6,Nke,Xct,zct,Rle,Qct,Wct,Uct,Y6,qke,Hct,Jct,Ple,Yct,Zct,Kct,Z6,jke,eft,oft,Ble,rft,tft,aft,K6,Dke,nft,sft,Ile,lft,ift,dft,e7,Gke,mft,cft,Nle,fft,gft,hft,o7,Oke,uft,pft,qle,_ft,bft,vft,r7,Vke,Fft,Tft,jle,Mft,Eft,Cft,t7,Xke,wft,Aft,Dle,Lft,yft,xft,a7,zke,$ft,kft,Gle,Sft,Rft,Pft,n7,Qke,Bft,Ift,Ole,Nft,qft,jft,s7,Wke,Dft,Gft,Vle,Oft,Vft,Xft,l7,ldo,Xc,i7,Uke,fB,zft,Hke,Qft,ido,Mr,gB,Wft,zc,Uft,Xle,Hft,Jft,zle,Yft,Zft,Kft,hB,egt,Jke,ogt,rgt,tgt,da,uB,agt,Yke,ngt,sgt,Qc,lgt,Zke,igt,dgt,Qle,mgt,cgt,fgt,d7,ggt,Zr,pB,hgt,Kke,ugt,pgt,Hn,_gt,eSe,bgt,vgt,oSe,Fgt,Tgt,rSe,Mgt,Egt,Cgt,Te,m7,tSe,wgt,Agt,Wle,Lgt,ygt,xgt,c7,aSe,$gt,kgt,Ule,Sgt,Rgt,Pgt,f7,nSe,Bgt,Igt,Hle,Ngt,qgt,jgt,g7,sSe,Dgt,Ggt,Jle,Ogt,Vgt,Xgt,h7,lSe,zgt,Qgt,Yle,Wgt,Ugt,Hgt,u7,iSe,Jgt,Ygt,Zle,Zgt,Kgt,eht,p7,dSe,oht,rht,Kle,tht,aht,nht,_7,mSe,sht,lht,eie,iht,dht,mht,b7,cSe,cht,fht,oie,ght,hht,uht,v7,fSe,pht,_ht,rie,bht,vht,Fht,F7,gSe,Tht,Mht,tie,Eht,Cht,wht,T7,hSe,Aht,Lht,aie,yht,xht,$ht,M7,uSe,kht,Sht,nie,Rht,Pht,Bht,E7,pSe,Iht,Nht,sie,qht,jht,Dht,C7,_Se,Ght,Oht,lie,Vht,Xht,zht,w7,bSe,Qht,Wht,iie,Uht,Hht,Jht,A7,vSe,Yht,Zht,die,Kht,eut,out,L7,ddo,Wc,y7,FSe,_B,rut,TSe,tut,mdo,Er,bB,aut,Uc,nut,mie,sut,lut,cie,iut,dut,mut,vB,cut,MSe,fut,gut,hut,ma,FB,uut,ESe,put,_ut,Hc,but,CSe,vut,Fut,fie,Tut,Mut,Eut,x7,Cut,Kr,TB,wut,wSe,Aut,Lut,Jn,yut,ASe,xut,$ut,LSe,kut,Sut,ySe,Rut,Put,But,MB,$7,xSe,Iut,Nut,gie,qut,jut,Dut,k7,$Se,Gut,Out,hie,Vut,Xut,zut,S7,cdo,Jc,R7,kSe,EB,Qut,SSe,Wut,fdo,Cr,CB,Uut,Yc,Hut,uie,Jut,Yut,pie,Zut,Kut,ept,wB,opt,RSe,rpt,tpt,apt,ca,AB,npt,PSe,spt,lpt,Zc,ipt,BSe,dpt,mpt,_ie,cpt,fpt,gpt,P7,hpt,et,LB,upt,ISe,ppt,_pt,Yn,bpt,NSe,vpt,Fpt,qSe,Tpt,Mpt,jSe,Ept,Cpt,wpt,DSe,B7,GSe,Apt,Lpt,bie,ypt,xpt,$pt,I7,gdo,Kc,N7,OSe,yB,kpt,VSe,Spt,hdo,wr,xB,Rpt,ef,Ppt,vie,Bpt,Ipt,Fie,Npt,qpt,jpt,$B,Dpt,XSe,Gpt,Opt,Vpt,fa,kB,Xpt,zSe,zpt,Qpt,of,Wpt,QSe,Upt,Hpt,Tie,Jpt,Ypt,Zpt,q7,Kpt,ot,SB,e_t,WSe,o_t,r_t,Zn,t_t,USe,a_t,n_t,HSe,s_t,l_t,JSe,i_t,d_t,m_t,YSe,j7,ZSe,c_t,f_t,Mie,g_t,h_t,u_t,D7,udo,rf,G7,KSe,RB,p_t,eRe,__t,pdo,Ar,PB,b_t,tf,v_t,Eie,F_t,T_t,Cie,M_t,E_t,C_t,BB,w_t,oRe,A_t,L_t,y_t,ga,IB,x_t,rRe,$_t,k_t,af,S_t,tRe,R_t,P_t,wie,B_t,I_t,N_t,O7,q_t,rt,NB,j_t,aRe,D_t,G_t,Kn,O_t,nRe,V_t,X_t,sRe,z_t,Q_t,lRe,W_t,U_t,H_t,me,V7,iRe,J_t,Y_t,Aie,Z_t,K_t,e1t,X7,dRe,o1t,r1t,Lie,t1t,a1t,n1t,z7,mRe,s1t,l1t,yie,i1t,d1t,m1t,Q7,cRe,c1t,f1t,xie,g1t,h1t,u1t,W7,fRe,p1t,_1t,$ie,b1t,v1t,F1t,U7,gRe,T1t,M1t,kie,E1t,C1t,w1t,H7,hRe,A1t,L1t,Sie,y1t,x1t,$1t,J7,uRe,k1t,S1t,Rie,R1t,P1t,B1t,Y7,pRe,I1t,N1t,Pie,q1t,j1t,D1t,Z7,_Re,G1t,O1t,Bie,V1t,X1t,z1t,K7,bRe,Q1t,W1t,Iie,U1t,H1t,J1t,e8,vRe,Y1t,Z1t,Nie,K1t,e2t,o2t,o8,FRe,r2t,t2t,qie,a2t,n2t,s2t,r8,TRe,l2t,i2t,jie,d2t,m2t,c2t,t8,MRe,f2t,g2t,Die,h2t,u2t,p2t,a8,ERe,_2t,b2t,Gie,v2t,F2t,T2t,n8,CRe,M2t,E2t,Oie,C2t,w2t,A2t,s8,wRe,L2t,y2t,Vie,x2t,$2t,k2t,l8,ARe,S2t,R2t,Xie,P2t,B2t,I2t,i8,LRe,N2t,q2t,zie,j2t,D2t,G2t,d8,yRe,O2t,V2t,Qie,X2t,z2t,Q2t,m8,xRe,W2t,U2t,Wie,H2t,J2t,Y2t,c8,_do,nf,f8,$Re,qB,Z2t,kRe,K2t,bdo,Lr,jB,ebt,sf,obt,Uie,rbt,tbt,Hie,abt,nbt,sbt,DB,lbt,SRe,ibt,dbt,mbt,ha,GB,cbt,RRe,fbt,gbt,lf,hbt,PRe,ubt,pbt,Jie,_bt,bbt,vbt,g8,Fbt,tt,OB,Tbt,BRe,Mbt,Ebt,es,Cbt,IRe,wbt,Abt,NRe,Lbt,ybt,qRe,xbt,$bt,kbt,he,h8,jRe,Sbt,Rbt,Yie,Pbt,Bbt,Ibt,u8,DRe,Nbt,qbt,Zie,jbt,Dbt,Gbt,p8,GRe,Obt,Vbt,Kie,Xbt,zbt,Qbt,_8,ORe,Wbt,Ubt,ede,Hbt,Jbt,Ybt,b8,VRe,Zbt,Kbt,ode,evt,ovt,rvt,v8,XRe,tvt,avt,rde,nvt,svt,lvt,F8,zRe,ivt,dvt,tde,mvt,cvt,fvt,T8,QRe,gvt,hvt,ade,uvt,pvt,_vt,M8,WRe,bvt,vvt,nde,Fvt,Tvt,Mvt,E8,URe,Evt,Cvt,sde,wvt,Avt,Lvt,C8,HRe,yvt,xvt,lde,$vt,kvt,Svt,w8,JRe,Rvt,Pvt,ide,Bvt,Ivt,Nvt,A8,YRe,qvt,jvt,dde,Dvt,Gvt,Ovt,L8,ZRe,Vvt,Xvt,mde,zvt,Qvt,Wvt,y8,KRe,Uvt,Hvt,cde,Jvt,Yvt,Zvt,x8,ePe,Kvt,eFt,fde,oFt,rFt,tFt,$8,oPe,aFt,nFt,gde,sFt,lFt,iFt,k8,rPe,dFt,mFt,hde,cFt,fFt,gFt,S8,tPe,hFt,uFt,ude,pFt,_Ft,bFt,R8,aPe,vFt,FFt,pde,TFt,MFt,EFt,P8,nPe,CFt,wFt,_de,AFt,LFt,yFt,B8,vdo,df,I8,sPe,VB,xFt,lPe,$Ft,Fdo,yr,XB,kFt,mf,SFt,bde,RFt,PFt,vde,BFt,IFt,NFt,zB,qFt,iPe,jFt,DFt,GFt,ua,QB,OFt,dPe,VFt,XFt,cf,zFt,mPe,QFt,WFt,Fde,UFt,HFt,JFt,N8,YFt,at,WB,ZFt,cPe,KFt,eTt,os,oTt,fPe,rTt,tTt,gPe,aTt,nTt,hPe,sTt,lTt,iTt,uPe,q8,pPe,dTt,mTt,Tde,cTt,fTt,gTt,j8,Tdo,ff,D8,_Pe,UB,hTt,bPe,uTt,Mdo,xr,HB,pTt,gf,_Tt,Mde,bTt,vTt,Ede,FTt,TTt,MTt,JB,ETt,vPe,CTt,wTt,ATt,pa,YB,LTt,FPe,yTt,xTt,hf,$Tt,TPe,kTt,STt,Cde,RTt,PTt,BTt,G8,ITt,nt,ZB,NTt,MPe,qTt,jTt,rs,DTt,EPe,GTt,OTt,CPe,VTt,XTt,wPe,zTt,QTt,WTt,KB,O8,APe,UTt,HTt,wde,JTt,YTt,ZTt,V8,LPe,KTt,eMt,Ade,oMt,rMt,tMt,X8,Edo,uf,z8,yPe,eI,aMt,xPe,nMt,Cdo,$r,oI,sMt,pf,lMt,Lde,iMt,dMt,yde,mMt,cMt,fMt,rI,gMt,$Pe,hMt,uMt,pMt,_a,tI,_Mt,kPe,bMt,vMt,_f,FMt,SPe,TMt,MMt,xde,EMt,CMt,wMt,Q8,AMt,st,aI,LMt,RPe,yMt,xMt,ts,$Mt,PPe,kMt,SMt,BPe,RMt,PMt,IPe,BMt,IMt,NMt,ne,W8,NPe,qMt,jMt,$de,DMt,GMt,OMt,U8,qPe,VMt,XMt,kde,zMt,QMt,WMt,H8,jPe,UMt,HMt,Sde,JMt,YMt,ZMt,J8,DPe,KMt,eEt,Rde,oEt,rEt,tEt,Y8,GPe,aEt,nEt,Pde,sEt,lEt,iEt,Z8,OPe,dEt,mEt,Bde,cEt,fEt,gEt,K8,VPe,hEt,uEt,Ide,pEt,_Et,bEt,eL,XPe,vEt,FEt,Nde,TEt,MEt,EEt,oL,zPe,CEt,wEt,qde,AEt,LEt,yEt,rL,QPe,xEt,$Et,jde,kEt,SEt,REt,tL,WPe,PEt,BEt,Dde,IEt,NEt,qEt,aL,UPe,jEt,DEt,Gde,GEt,OEt,VEt,nL,HPe,XEt,zEt,Ode,QEt,WEt,UEt,sL,JPe,HEt,JEt,Vde,YEt,ZEt,KEt,lL,YPe,e4t,o4t,Xde,r4t,t4t,a4t,iL,ZPe,n4t,s4t,zde,l4t,i4t,d4t,dL,KPe,m4t,c4t,Qde,f4t,g4t,h4t,mL,eBe,u4t,p4t,Wde,_4t,b4t,v4t,cL,oBe,F4t,T4t,Ude,M4t,E4t,C4t,fL,rBe,w4t,A4t,Hde,L4t,y4t,x4t,gL,tBe,$4t,k4t,Jde,S4t,R4t,P4t,hL,aBe,B4t,I4t,Yde,N4t,q4t,j4t,uL,nBe,D4t,G4t,Zde,O4t,V4t,X4t,pL,sBe,z4t,Q4t,Kde,W4t,U4t,H4t,_L,lBe,J4t,Y4t,eme,Z4t,K4t,eCt,bL,iBe,oCt,rCt,ome,tCt,aCt,nCt,vL,dBe,sCt,lCt,rme,iCt,dCt,mCt,FL,wdo,bf,TL,mBe,nI,cCt,cBe,fCt,Ado,kr,sI,gCt,vf,hCt,tme,uCt,pCt,ame,_Ct,bCt,vCt,lI,FCt,fBe,TCt,MCt,ECt,ba,iI,CCt,gBe,wCt,ACt,Ff,LCt,hBe,yCt,xCt,nme,$Ct,kCt,SCt,ML,RCt,lt,dI,PCt,uBe,BCt,ICt,as,NCt,pBe,qCt,jCt,_Be,DCt,GCt,bBe,OCt,VCt,XCt,Se,EL,vBe,zCt,QCt,sme,WCt,UCt,HCt,CL,FBe,JCt,YCt,lme,ZCt,KCt,e3t,wL,TBe,o3t,r3t,ime,t3t,a3t,n3t,AL,MBe,s3t,l3t,dme,i3t,d3t,m3t,LL,EBe,c3t,f3t,mme,g3t,h3t,u3t,yL,CBe,p3t,_3t,cme,b3t,v3t,F3t,xL,wBe,T3t,M3t,fme,E3t,C3t,w3t,$L,ABe,A3t,L3t,gme,y3t,x3t,$3t,kL,LBe,k3t,S3t,hme,R3t,P3t,B3t,SL,yBe,I3t,N3t,ume,q3t,j3t,D3t,RL,Ldo,Tf,PL,xBe,mI,G3t,$Be,O3t,ydo,Sr,cI,V3t,Mf,X3t,pme,z3t,Q3t,_me,W3t,U3t,H3t,fI,J3t,kBe,Y3t,Z3t,K3t,va,gI,e5t,SBe,o5t,r5t,Ef,t5t,RBe,a5t,n5t,bme,s5t,l5t,i5t,BL,d5t,it,hI,m5t,PBe,c5t,f5t,ns,g5t,BBe,h5t,u5t,IBe,p5t,_5t,NBe,b5t,v5t,F5t,we,IL,qBe,T5t,M5t,vme,E5t,C5t,w5t,NL,jBe,A5t,L5t,Fme,y5t,x5t,$5t,qL,DBe,k5t,S5t,Tme,R5t,P5t,B5t,jL,GBe,I5t,N5t,Mme,q5t,j5t,D5t,DL,OBe,G5t,O5t,Eme,V5t,X5t,z5t,GL,VBe,Q5t,W5t,Cme,U5t,H5t,J5t,OL,XBe,Y5t,Z5t,wme,K5t,e0t,o0t,VL,zBe,r0t,t0t,Ame,a0t,n0t,s0t,XL,QBe,l0t,i0t,Lme,d0t,m0t,c0t,zL,WBe,f0t,g0t,yme,h0t,u0t,p0t,QL,UBe,_0t,b0t,xme,v0t,F0t,T0t,WL,HBe,M0t,E0t,$me,C0t,w0t,A0t,UL,JBe,L0t,y0t,kme,x0t,$0t,k0t,HL,xdo,Cf,JL,YBe,uI,S0t,ZBe,R0t,$do,Rr,pI,P0t,wf,B0t,Sme,I0t,N0t,Rme,q0t,j0t,D0t,_I,G0t,KBe,O0t,V0t,X0t,Fa,bI,z0t,eIe,Q0t,W0t,Af,U0t,oIe,H0t,J0t,Pme,Y0t,Z0t,K0t,YL,ewt,dt,vI,owt,rIe,rwt,twt,ss,awt,tIe,nwt,swt,aIe,lwt,iwt,nIe,dwt,mwt,cwt,Re,ZL,sIe,fwt,gwt,Bme,hwt,uwt,pwt,KL,lIe,_wt,bwt,Ime,vwt,Fwt,Twt,ey,iIe,Mwt,Ewt,Nme,Cwt,wwt,Awt,oy,dIe,Lwt,ywt,qme,xwt,$wt,kwt,ry,mIe,Swt,Rwt,jme,Pwt,Bwt,Iwt,ty,cIe,Nwt,qwt,Dme,jwt,Dwt,Gwt,ay,fIe,Owt,Vwt,Gme,Xwt,zwt,Qwt,ny,gIe,Wwt,Uwt,Ome,Hwt,Jwt,Ywt,sy,hIe,Zwt,Kwt,Vme,eAt,oAt,rAt,ly,uIe,tAt,aAt,Xme,nAt,sAt,lAt,iy,kdo,Lf,dy,pIe,FI,iAt,_Ie,dAt,Sdo,Pr,TI,mAt,yf,cAt,zme,fAt,gAt,Qme,hAt,uAt,pAt,MI,_At,bIe,bAt,vAt,FAt,Ta,EI,TAt,vIe,MAt,EAt,xf,CAt,FIe,wAt,AAt,Wme,LAt,yAt,xAt,my,$At,mt,CI,kAt,TIe,SAt,RAt,ls,PAt,MIe,BAt,IAt,EIe,NAt,qAt,CIe,jAt,DAt,GAt,Pe,cy,wIe,OAt,VAt,Ume,XAt,zAt,QAt,fy,AIe,WAt,UAt,Hme,HAt,JAt,YAt,gy,LIe,ZAt,KAt,Jme,e6t,o6t,r6t,hy,yIe,t6t,a6t,Yme,n6t,s6t,l6t,uy,xIe,i6t,d6t,Zme,m6t,c6t,f6t,py,$Ie,g6t,h6t,Kme,u6t,p6t,_6t,_y,kIe,b6t,v6t,ece,F6t,T6t,M6t,by,SIe,E6t,C6t,oce,w6t,A6t,L6t,vy,RIe,y6t,x6t,rce,$6t,k6t,S6t,Fy,PIe,R6t,P6t,tce,B6t,I6t,N6t,Ty,Rdo,$f,My,BIe,wI,q6t,IIe,j6t,Pdo,Br,AI,D6t,kf,G6t,ace,O6t,V6t,nce,X6t,z6t,Q6t,LI,W6t,NIe,U6t,H6t,J6t,Ma,yI,Y6t,qIe,Z6t,K6t,Sf,e7t,jIe,o7t,r7t,sce,t7t,a7t,n7t,Ey,s7t,ct,xI,l7t,DIe,i7t,d7t,is,m7t,GIe,c7t,f7t,OIe,g7t,h7t,VIe,u7t,p7t,_7t,Be,Cy,XIe,b7t,v7t,lce,F7t,T7t,M7t,wy,zIe,E7t,C7t,ice,w7t,A7t,L7t,Ay,QIe,y7t,x7t,dce,$7t,k7t,S7t,Ly,WIe,R7t,P7t,mce,B7t,I7t,N7t,yy,UIe,q7t,j7t,cce,D7t,G7t,O7t,xy,HIe,V7t,X7t,fce,z7t,Q7t,W7t,$y,JIe,U7t,H7t,gce,J7t,Y7t,Z7t,ky,YIe,K7t,e8t,hce,o8t,r8t,t8t,Sy,ZIe,a8t,n8t,uce,s8t,l8t,i8t,Ry,KIe,d8t,m8t,pce,c8t,f8t,g8t,Py,Bdo,Rf,By,eNe,$I,h8t,oNe,u8t,Ido,Ir,kI,p8t,Pf,_8t,_ce,b8t,v8t,bce,F8t,T8t,M8t,SI,E8t,rNe,C8t,w8t,A8t,Ea,RI,L8t,tNe,y8t,x8t,Bf,$8t,aNe,k8t,S8t,vce,R8t,P8t,B8t,Iy,I8t,ft,PI,N8t,nNe,q8t,j8t,ds,D8t,sNe,G8t,O8t,lNe,V8t,X8t,iNe,z8t,Q8t,W8t,Ie,Ny,dNe,U8t,H8t,Fce,J8t,Y8t,Z8t,qy,mNe,K8t,eLt,Tce,oLt,rLt,tLt,jy,cNe,aLt,nLt,Mce,sLt,lLt,iLt,Dy,fNe,dLt,mLt,Ece,cLt,fLt,gLt,Gy,gNe,hLt,uLt,Cce,pLt,_Lt,bLt,Oy,hNe,vLt,FLt,wce,TLt,MLt,ELt,Vy,uNe,CLt,wLt,Ace,ALt,LLt,yLt,Xy,pNe,xLt,$Lt,Lce,kLt,SLt,RLt,zy,_Ne,PLt,BLt,yce,ILt,NLt,qLt,Qy,bNe,jLt,DLt,xce,GLt,OLt,VLt,Wy,Ndo,If,Uy,vNe,BI,XLt,FNe,zLt,qdo,Nr,II,QLt,Nf,WLt,$ce,ULt,HLt,kce,JLt,YLt,ZLt,NI,KLt,TNe,eyt,oyt,ryt,Ca,qI,tyt,MNe,ayt,nyt,qf,syt,ENe,lyt,iyt,Sce,dyt,myt,cyt,Hy,fyt,gt,jI,gyt,CNe,hyt,uyt,ms,pyt,wNe,_yt,byt,ANe,vyt,Fyt,LNe,Tyt,Myt,Eyt,We,Jy,yNe,Cyt,wyt,Rce,Ayt,Lyt,yyt,Yy,xNe,xyt,$yt,Pce,kyt,Syt,Ryt,Zy,$Ne,Pyt,Byt,Bce,Iyt,Nyt,qyt,Ky,kNe,jyt,Dyt,Ice,Gyt,Oyt,Vyt,e9,SNe,Xyt,zyt,Nce,Qyt,Wyt,Uyt,o9,RNe,Hyt,Jyt,qce,Yyt,Zyt,Kyt,r9,PNe,e9t,o9t,jce,r9t,t9t,a9t,t9,BNe,n9t,s9t,Dce,l9t,i9t,d9t,a9,jdo,jf,n9,INe,DI,m9t,NNe,c9t,Ddo,qr,GI,f9t,Df,g9t,Gce,h9t,u9t,Oce,p9t,_9t,b9t,OI,v9t,qNe,F9t,T9t,M9t,wa,VI,E9t,jNe,C9t,w9t,Gf,A9t,DNe,L9t,y9t,Vce,x9t,$9t,k9t,s9,S9t,ht,XI,R9t,GNe,P9t,B9t,cs,I9t,ONe,N9t,q9t,VNe,j9t,D9t,XNe,G9t,O9t,V9t,Ue,l9,zNe,X9t,z9t,Xce,Q9t,W9t,U9t,i9,QNe,H9t,J9t,zce,Y9t,Z9t,K9t,d9,WNe,ext,oxt,Qce,rxt,txt,axt,m9,UNe,nxt,sxt,Wce,lxt,ixt,dxt,c9,HNe,mxt,cxt,Uce,fxt,gxt,hxt,f9,JNe,uxt,pxt,Hce,_xt,bxt,vxt,g9,YNe,Fxt,Txt,Jce,Mxt,Ext,Cxt,h9,ZNe,wxt,Axt,Yce,Lxt,yxt,xxt,u9,Gdo,Of,p9,KNe,zI,$xt,eqe,kxt,Odo,jr,QI,Sxt,Vf,Rxt,Zce,Pxt,Bxt,Kce,Ixt,Nxt,qxt,WI,jxt,oqe,Dxt,Gxt,Oxt,Aa,UI,Vxt,rqe,Xxt,zxt,Xf,Qxt,tqe,Wxt,Uxt,efe,Hxt,Jxt,Yxt,_9,Zxt,ut,HI,Kxt,aqe,e$t,o$t,fs,r$t,nqe,t$t,a$t,sqe,n$t,s$t,lqe,l$t,i$t,d$t,iqe,b9,dqe,m$t,c$t,ofe,f$t,g$t,h$t,v9,Vdo,zf,F9,mqe,JI,u$t,cqe,p$t,Xdo,Dr,YI,_$t,Qf,b$t,rfe,v$t,F$t,tfe,T$t,M$t,E$t,ZI,C$t,fqe,w$t,A$t,L$t,La,KI,y$t,gqe,x$t,$$t,Wf,k$t,hqe,S$t,R$t,afe,P$t,B$t,I$t,T9,N$t,pt,eN,q$t,uqe,j$t,D$t,gs,G$t,pqe,O$t,V$t,_qe,X$t,z$t,bqe,Q$t,W$t,U$t,oN,M9,vqe,H$t,J$t,nfe,Y$t,Z$t,K$t,E9,Fqe,ekt,okt,sfe,rkt,tkt,akt,C9,zdo,Uf,w9,Tqe,rN,nkt,Mqe,skt,Qdo,Gr,tN,lkt,Hf,ikt,lfe,dkt,mkt,ife,ckt,fkt,gkt,aN,hkt,Eqe,ukt,pkt,_kt,ya,nN,bkt,Cqe,vkt,Fkt,Jf,Tkt,wqe,Mkt,Ekt,dfe,Ckt,wkt,Akt,A9,Lkt,_t,sN,ykt,Aqe,xkt,$kt,hs,kkt,Lqe,Skt,Rkt,yqe,Pkt,Bkt,xqe,Ikt,Nkt,qkt,$qe,L9,kqe,jkt,Dkt,mfe,Gkt,Okt,Vkt,y9,Wdo;return m=new oe({}),sn=new B({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),uk=new oe({}),pk=new B({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),ng=new vfo({props:{warning:!0,$$slots:{default:[wxa]},$$scope:{ctx:$}}}),_k=new oe({}),bk=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L674"}}),Tk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L697"}}),Nu=new N({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[Axa]},$$scope:{ctx:$}}}),Mk=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L820"}}),Ek=new oe({}),Ck=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L451"}}),Lk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/main/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L465"}}),Cp=new N({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[Lxa]},$$scope:{ctx:$}}}),yk=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L666"}}),xk=new oe({}),$k=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L205"}}),Rk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L219"}}),b_=new vfo({props:{$$slots:{default:[yxa]},$$scope:{ctx:$}}}),v_=new N({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[xxa]},$$scope:{ctx:$}}}),Pk=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L346"}}),Bk=new oe({}),Ik=new R({props:{name:"class transformers.AutoImageProcessor",anchor:"transformers.AutoImageProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/image_processing_auto.py#L189"}}),jk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoImageProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoImageProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained image_processor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a image processor file saved using the
<a href="/docs/transformers/main/en/internal/image_processing_utils#transformers.ImageProcessingMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved image processor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoImageProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model image processor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoImageProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the image processor files and override the cached versions if
they exist.`,name:"force_download"},{anchor:"transformers.AutoImageProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoImageProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoImageProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoImageProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoImageProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final image processor object. If <code>True</code>, then this
functions returns a <code>Tuple(image_processor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not image processor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>image_processor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoImageProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoImageProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are image processor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> image processor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/image_processing_auto.py#L203"}}),Y_=new vfo({props:{$$slots:{default:[$xa]},$$scope:{ctx:$}}}),Z_=new N({props:{anchor:"transformers.AutoImageProcessor.from_pretrained.example",$$slots:{default:[kxa]},$$scope:{ctx:$}}}),Dk=new R({props:{name:"register",anchor:"transformers.AutoImageProcessor.register",parameters:[{name:"config_class",val:""},{name:"image_processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoImageProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoImageProcessor.register.image_processor_class",description:'<strong>image_processor_class</strong> (<a href="/docs/transformers/main/en/internal/image_processing_utils#transformers.ImageProcessingMixin">ImageProcessingMixin</a>) &#x2014; The image processor to register.',name:"image_processor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/image_processing_auto.py#L348"}}),Gk=new oe({}),Ok=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L98"}}),zk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L112"}}),C1=new vfo({props:{$$slots:{default:[Sxa]},$$scope:{ctx:$}}}),w1=new N({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[Rxa]},$$scope:{ctx:$}}}),Qk=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L293"}}),Wk=new oe({}),Uk=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L899"}}),Jk=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegConfig">CLIPSegConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegModel">CLIPSegModel</a> (CLIPSeg model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel">ConditionalDetrModel</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel">DeformableDetrModel</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig">DonutSwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel">DonutSwinModel</a> (DonutSwin model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel">ErnieModel</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmModel">EsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel">GPTNeoXJapaneseModel</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/jukebox#transformers.JukeboxConfig">JukeboxConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/jukebox#transformers.JukeboxModel">JukeboxModel</a> (Jukebox model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltModel">LiltModel</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel">MarkupLMModel</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel">MobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel">OwlViTModel</a> (OWL-ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel">PegasusXModel</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertModel">RoCBertModel</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model">Swinv2Model</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig">TableTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerModel">TableTransformerModel</a> (Table Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig">TimeSeriesTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel">TimeSeriesTransformerModel</a> (Time Series Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel">ViTMSNModel</a> (ViTMSN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel">VideoMAEModel</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel">WhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig">XCLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel">XCLIPModel</a> (X-CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),y1=new N({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[Pxa]},$$scope:{ctx:$}}}),Yk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Kb=new N({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[Bxa]},$$scope:{ctx:$}}}),Zk=new oe({}),Kk=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L906"}}),oS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining">ErnieForPreTraining</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForPreTraining">RoCBertForPreTraining</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining">VideoMAEForPreTraining</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),ov=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[Ixa]},$$scope:{ctx:$}}}),rS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Zv=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[Nxa]},$$scope:{ctx:$}}}),tS=new oe({}),aS=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L921"}}),sS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM">ErnieForCausalLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM">GPTNeoXJapaneseForCausalLM</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForCausalLM">RoCBertForCausalLM</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),eF=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[qxa]},$$scope:{ctx:$}}}),lS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),zF=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[jxa]},$$scope:{ctx:$}}}),iS=new oe({}),dS=new R({props:{name:"class transformers.AutoModelForDepthEstimation",anchor:"transformers.AutoModelForDepthEstimation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1064"}}),cS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDepthEstimation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDepthEstimation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForDepthEstimation">DPTForDepthEstimation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNForDepthEstimation">GLPNForDepthEstimation</a> (GLPN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),WF=new N({props:{anchor:"transformers.AutoModelForDepthEstimation.from_config.example",$$slots:{default:[Dxa]},$$scope:{ctx:$}}}),fS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDepthEstimation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),YF=new N({props:{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.example",$$slots:{default:[Gxa]},$$scope:{ctx:$}}}),hS=new oe({}),uS=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L928"}}),_S=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM">ErnieForMaskedLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForMaskedLM">RoCBertForMaskedLM</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),KF=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[Oxa]},$$scope:{ctx:$}}}),bS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),GT=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[Vxa]},$$scope:{ctx:$}}}),vS=new oe({}),FS=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L935"}}),MS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration">PegasusXForConditionalGeneration</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),VT=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Xxa]},$$scope:{ctx:$}}}),ES=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),cM=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[zxa]},$$scope:{ctx:$}}}),CS=new oe({}),wS=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L944"}}),LS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification">ErnieForSequenceClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification">EsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForSequenceClassification">LiltForSequenceClassification</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification">LukeForSequenceClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification">MarkupLMForSequenceClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification">OPTForSequenceClassification</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForSequenceClassification">RoCBertForSequenceClassification</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),gM=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[Qxa]},$$scope:{ctx:$}}}),yS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),bE=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Wxa]},$$scope:{ctx:$}}}),xS=new oe({}),$S=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1000"}}),SS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice">ErnieForMultipleChoice</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice">LukeForMultipleChoice</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForMultipleChoice">RoCBertForMultipleChoice</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),FE=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[Uxa]},$$scope:{ctx:$}}}),RS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),o4=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[Hxa]},$$scope:{ctx:$}}}),PS=new oe({}),BS=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1007"}}),NS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction">ErnieForNextSentencePrediction</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),t4=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[Jxa]},$$scope:{ctx:$}}}),qS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),f4=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[Yxa]},$$scope:{ctx:$}}}),jS=new oe({}),DS=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L993"}}),OS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification">ErnieForTokenClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification">EsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForTokenClassification">LiltForTokenClassification</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification">LukeForTokenClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification">MarkupLMForTokenClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForTokenClassification">RoCBertForTokenClassification</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),h4=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[Zxa]},$$scope:{ctx:$}}}),VS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),aC=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[Kxa]},$$scope:{ctx:$}}}),XS=new oe({}),zS=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L953"}}),WS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering">BloomForQuestionAnswering</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering">ErnieForQuestionAnswering</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForQuestionAnswering">LiltForQuestionAnswering</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering">LukeForQuestionAnswering</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering">MarkupLMForQuestionAnswering</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForQuestionAnswering">OPTForQuestionAnswering</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForQuestionAnswering">RoCBertForQuestionAnswering</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),sC=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[e$a]},$$scope:{ctx:$}}}),US=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),t3=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[o$a]},$$scope:{ctx:$}}}),HS=new oe({}),JS=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L960"}}),ZS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),n3=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[r$a]},$$scope:{ctx:$}}}),KS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),i3=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[t$a]},$$scope:{ctx:$}}}),eR=new oe({}),oR=new R({props:{name:"class transformers.AutoModelForDocumentQuestionAnswering",anchor:"transformers.AutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L982"}}),tR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering">LayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),m3=new N({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[a$a]},$$scope:{ctx:$}}}),aR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),u3=new N({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[n$a]},$$scope:{ctx:$}}}),nR=new oe({}),sR=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1016"}}),iR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification">MobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification">Swinv2ForImageClassification</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification">ViTMSNForImageClassification</a> (ViTMSN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),_3=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[s$a]},$$scope:{ctx:$}}}),dR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),P3=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[l$a]},$$scope:{ctx:$}}}),mR=new oe({}),cR=new R({props:{name:"class transformers.AutoModelForVideoClassification",anchor:"transformers.AutoModelForVideoClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1071"}}),gR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVideoClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification">VideoMAEForVideoClassification</a> (VideoMAE model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),I3=new N({props:{anchor:"transformers.AutoModelForVideoClassification.from_config.example",$$slots:{default:[i$a]},$$scope:{ctx:$}}}),hR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVideoClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),j3=new N({props:{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.example",$$slots:{default:[d$a]},$$scope:{ctx:$}}}),uR=new oe({}),pR=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1078"}}),bR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),G3=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[m$a]},$$scope:{ctx:$}}}),vR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),X3=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[c$a]},$$scope:{ctx:$}}}),FR=new oe({}),TR=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L971"}}),ER=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Q3=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[f$a]},$$scope:{ctx:$}}}),CR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),H3=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[g$a]},$$scope:{ctx:$}}}),wR=new oe({}),AR=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1085"}}),yR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Y3=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[h$a]},$$scope:{ctx:$}}}),xR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),i5=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[u$a]},$$scope:{ctx:$}}}),$R=new oe({}),kR=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1108"}}),RR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),m5=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[p$a]},$$scope:{ctx:$}}}),PR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),_5=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[_$a]},$$scope:{ctx:$}}}),BR=new oe({}),IR=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1092"}}),qR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),v5=new N({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[b$a]},$$scope:{ctx:$}}}),jR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),k5=new N({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[v$a]},$$scope:{ctx:$}}}),DR=new oe({}),GR=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1099"}}),VR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration">WhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),R5=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[F$a]},$$scope:{ctx:$}}}),XR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),q5=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[T$a]},$$scope:{ctx:$}}}),zR=new oe({}),QR=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1117"}}),UR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),D5=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[M$a]},$$scope:{ctx:$}}}),HR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),W5=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[E$a]},$$scope:{ctx:$}}}),JR=new oe({}),YR=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1124"}}),KR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling">Swinv2ForMaskedImageModeling</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),H5=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[C$a]},$$scope:{ctx:$}}}),eP=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),o0=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[w$a]},$$scope:{ctx:$}}}),oP=new oe({}),rP=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1048"}}),aP=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection">ConditionalDetrForObjectDetection</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection">DeformableDetrForObjectDetection</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig">TableTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection">TableTransformerForObjectDetection</a> (Table Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),t0=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[A$a]},$$scope:{ctx:$}}}),nP=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),m0=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[L$a]},$$scope:{ctx:$}}}),sP=new oe({}),lP=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1023"}}),dP=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),f0=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[y$a]},$$scope:{ctx:$}}}),mP=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),u0=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[x$a]},$$scope:{ctx:$}}}),cP=new oe({}),fP=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1030"}}),hP=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation">MobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),_0=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[$$a]},$$scope:{ctx:$}}}),uP=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),C0=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[k$a]},$$scope:{ctx:$}}}),pP=new oe({}),_P=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1039"}}),vP=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),A0=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[S$a]},$$scope:{ctx:$}}}),FP=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),x0=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[R$a]},$$scope:{ctx:$}}}),TP=new oe({}),MP=new R({props:{name:"class transformers.AutoModelForZeroShotObjectDetection",anchor:"transformers.AutoModelForZeroShotObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1055"}}),CP=new R({props:{name:"from_config",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTForObjectDetection">OwlViTForObjectDetection</a> (OWL-ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),k0=new N({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.example",$$slots:{default:[P$a]},$$scope:{ctx:$}}}),wP=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),P0=new N({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.example",$$slots:{default:[B$a]},$$scope:{ctx:$}}}),AP=new oe({}),LP=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L444"}}),xP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtModel">TFCvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel">TFDeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmModel">TFEsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel">TFGroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model">TFLayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel">TFMobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel">TFSegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperModel">TFWhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel">TFXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),I0=new N({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[I$a]},$$scope:{ctx:$}}}),$P=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Dw=new N({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[N$a]},$$scope:{ctx:$}}}),kP=new oe({}),SP=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L451"}}),PP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Ow=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[q$a]},$$scope:{ctx:$}}}),BP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),fA=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[j$a]},$$scope:{ctx:$}}}),IP=new oe({}),NP=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L466"}}),jP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM">TFXGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),hA=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[D$a]},$$scope:{ctx:$}}}),DP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),xA=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[G$a]},$$scope:{ctx:$}}}),GP=new oe({}),OP=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L482"}}),XP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtForImageClassification">TFCvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification">TFDeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher">TFDeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification">TFMobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification">TFSegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),kA=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[O$a]},$$scope:{ctx:$}}}),zP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),GA=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[V$a]},$$scope:{ctx:$}}}),QP=new oe({}),WP=new R({props:{name:"class transformers.TFAutoModelForSemanticSegmentation",anchor:"transformers.TFAutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L491"}}),HP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation">TFData2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation">TFMobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation">TFSegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),VA=new N({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[X$a]},$$scope:{ctx:$}}}),JP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),WA=new N({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[z$a]},$$scope:{ctx:$}}}),YP=new oe({}),ZP=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L507"}}),eB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForMaskedLM">TFEsmForMaskedLM</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),HA=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[Q$a]},$$scope:{ctx:$}}}),oB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),_6=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[W$a]},$$scope:{ctx:$}}}),rB=new oe({}),tB=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L514"}}),nB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),v6=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[U$a]},$$scope:{ctx:$}}}),sB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),$6=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[H$a]},$$scope:{ctx:$}}}),lB=new oe({}),iB=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L523"}}),mB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForSequenceClassification">TFEsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification">TFLayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),S6=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[J$a]},$$scope:{ctx:$}}}),cB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),l7=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Y$a]},$$scope:{ctx:$}}}),fB=new oe({}),gB=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L570"}}),uB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),d7=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[Z$a]},$$scope:{ctx:$}}}),pB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),L7=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[K$a]},$$scope:{ctx:$}}}),_B=new oe({}),bB=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L577"}}),FB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),x7=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[eka]},$$scope:{ctx:$}}}),TB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),S7=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[oka]},$$scope:{ctx:$}}}),EB=new oe({}),CB=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L550"}}),AB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),P7=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[rka]},$$scope:{ctx:$}}}),LB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),I7=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[tka]},$$scope:{ctx:$}}}),yB=new oe({}),xB=new R({props:{name:"class transformers.TFAutoModelForDocumentQuestionAnswering",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L539"}}),kB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering">TFLayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),q7=new N({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[aka]},$$scope:{ctx:$}}}),SB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),D7=new N({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[nka]},$$scope:{ctx:$}}}),RB=new oe({}),PB=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L561"}}),IB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForTokenClassification">TFEsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification">TFLayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),O7=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[ska]},$$scope:{ctx:$}}}),NB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),c8=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[lka]},$$scope:{ctx:$}}}),qB=new oe({}),jB=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L532"}}),GB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering">TFLayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),g8=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[ika]},$$scope:{ctx:$}}}),OB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),B8=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[dka]},$$scope:{ctx:$}}}),VB=new oe({}),XB=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L500"}}),QB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),N8=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[mka]},$$scope:{ctx:$}}}),WB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),j8=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[cka]},$$scope:{ctx:$}}}),UB=new oe({}),HB=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L586"}}),YB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration">TFWhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),G8=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[fka]},$$scope:{ctx:$}}}),ZB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),X8=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[gka]},$$scope:{ctx:$}}}),eI=new oe({}),oI=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),tI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Q8=new N({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[hka]},$$scope:{ctx:$}}}),aI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),FL=new N({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[uka]},$$scope:{ctx:$}}}),nI=new oe({}),sI=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),iI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),ML=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[pka]},$$scope:{ctx:$}}}),dI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),RL=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[_ka]},$$scope:{ctx:$}}}),mI=new oe({}),cI=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),gI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),BL=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[bka]},$$scope:{ctx:$}}}),hI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),HL=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[vka]},$$scope:{ctx:$}}}),uI=new oe({}),pI=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),bI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),YL=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[Fka]},$$scope:{ctx:$}}}),vI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),iy=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[Tka]},$$scope:{ctx:$}}}),FI=new oe({}),TI=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),EI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),my=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Mka]},$$scope:{ctx:$}}}),CI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Ty=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[Eka]},$$scope:{ctx:$}}}),wI=new oe({}),AI=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),yI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Ey=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[Cka]},$$scope:{ctx:$}}}),xI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Py=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[wka]},$$scope:{ctx:$}}}),$I=new oe({}),kI=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),RI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Iy=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[Aka]},$$scope:{ctx:$}}}),PI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Wy=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[Lka]},$$scope:{ctx:$}}}),BI=new oe({}),II=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),qI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Hy=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[yka]},$$scope:{ctx:$}}}),jI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),a9=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[xka]},$$scope:{ctx:$}}}),DI=new oe({}),GI=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),VI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),s9=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[$ka]},$$scope:{ctx:$}}}),XI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),u9=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[kka]},$$scope:{ctx:$}}}),zI=new oe({}),QI=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),UI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),_9=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[Ska]},$$scope:{ctx:$}}}),HI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),v9=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[Rka]},$$scope:{ctx:$}}}),JI=new oe({}),YI=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),KI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),T9=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[Pka]},$$scope:{ctx:$}}}),eN=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),C9=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[Bka]},$$scope:{ctx:$}}}),rN=new oe({}),tN=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),nN=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),A9=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[Ika]},$$scope:{ctx:$}}}),sN=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),y9=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Nka]},$$scope:{ctx:$}}}),{c(){g=a("meta"),v=l(),u=a("h1"),f=a("a"),p=a("span"),F(m.$$.fragment),h=l(),He=a("span"),Ad=o("Auto Classes"),eg=l(),wt=a("p"),Ld=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),yd=a("code"),ck=o("from_pretrained()"),og=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Qe=l(),Ze=a("p"),xd=o("Instantiating one of "),ps=a("a"),fk=o("AutoConfig"),_s=o(", "),bs=a("a"),gk=o("AutoModel"),$d=o(`, and
`),vs=a("a"),hk=o("AutoTokenizer"),kd=o(" will directly create a class of the relevant architecture. For instance"),rg=l(),F(sn.$$.fragment),Ke=l(),ye=a("p"),Bq=o("will create a model that is an instance of "),Sd=a("a"),Iq=o("BertModel"),Nq=o("."),Po=l(),ln=a("p"),qq=o("There is one class of "),tg=a("code"),jq=o("AutoModel"),Ffo=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),ylo=l(),Rd=a("h2"),ag=a("a"),vhe=a("span"),F(uk.$$.fragment),Tfo=l(),Fhe=a("span"),Mfo=o("Extending the Auto Classes"),xlo=l(),Fs=a("p"),Efo=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),The=a("code"),Cfo=o("NewModel"),wfo=o(", make sure you have a "),Mhe=a("code"),Afo=o("NewModelConfig"),Lfo=o(` then you can add those to the auto
classes like this:`),$lo=l(),F(pk.$$.fragment),klo=l(),Dq=a("p"),yfo=o("You will then be able to use the auto classes like you would usually do!"),Slo=l(),F(ng.$$.fragment),Rlo=l(),Pd=a("h2"),sg=a("a"),Ehe=a("span"),F(_k.$$.fragment),xfo=l(),Che=a("span"),$fo=o("AutoConfig"),Plo=l(),Bo=a("div"),F(bk.$$.fragment),kfo=l(),vk=a("p"),Sfo=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),Gq=a("a"),Rfo=o("from_pretrained()"),Pfo=o(" class method."),Bfo=l(),Fk=a("p"),Ifo=o("This class cannot be instantiated directly using "),whe=a("code"),Nfo=o("__init__()"),qfo=o(" (throws an error)."),jfo=l(),Or=a("div"),F(Tk.$$.fragment),Dfo=l(),Ahe=a("p"),Gfo=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),Ofo=l(),Bd=a("p"),Vfo=o("The configuration class to instantiate is selected based on the "),Lhe=a("code"),Xfo=o("model_type"),zfo=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),yhe=a("code"),Qfo=o("pretrained_model_name_or_path"),Wfo=o(":"),Ufo=l(),A=a("ul"),lg=a("li"),xhe=a("strong"),Hfo=o("albert"),Jfo=o(" \u2014 "),Oq=a("a"),Yfo=o("AlbertConfig"),Zfo=o(" (ALBERT model)"),Kfo=l(),ig=a("li"),$he=a("strong"),ego=o("bart"),ogo=o(" \u2014 "),Vq=a("a"),rgo=o("BartConfig"),tgo=o(" (BART model)"),ago=l(),dg=a("li"),khe=a("strong"),ngo=o("beit"),sgo=o(" \u2014 "),Xq=a("a"),lgo=o("BeitConfig"),igo=o(" (BEiT model)"),dgo=l(),mg=a("li"),She=a("strong"),mgo=o("bert"),cgo=o(" \u2014 "),zq=a("a"),fgo=o("BertConfig"),ggo=o(" (BERT model)"),hgo=l(),cg=a("li"),Rhe=a("strong"),ugo=o("bert-generation"),pgo=o(" \u2014 "),Qq=a("a"),_go=o("BertGenerationConfig"),bgo=o(" (Bert Generation model)"),vgo=l(),fg=a("li"),Phe=a("strong"),Fgo=o("big_bird"),Tgo=o(" \u2014 "),Wq=a("a"),Mgo=o("BigBirdConfig"),Ego=o(" (BigBird model)"),Cgo=l(),gg=a("li"),Bhe=a("strong"),wgo=o("bigbird_pegasus"),Ago=o(" \u2014 "),Uq=a("a"),Lgo=o("BigBirdPegasusConfig"),ygo=o(" (BigBird-Pegasus model)"),xgo=l(),hg=a("li"),Ihe=a("strong"),$go=o("blenderbot"),kgo=o(" \u2014 "),Hq=a("a"),Sgo=o("BlenderbotConfig"),Rgo=o(" (Blenderbot model)"),Pgo=l(),ug=a("li"),Nhe=a("strong"),Bgo=o("blenderbot-small"),Igo=o(" \u2014 "),Jq=a("a"),Ngo=o("BlenderbotSmallConfig"),qgo=o(" (BlenderbotSmall model)"),jgo=l(),pg=a("li"),qhe=a("strong"),Dgo=o("bloom"),Ggo=o(" \u2014 "),Yq=a("a"),Ogo=o("BloomConfig"),Vgo=o(" (BLOOM model)"),Xgo=l(),_g=a("li"),jhe=a("strong"),zgo=o("camembert"),Qgo=o(" \u2014 "),Zq=a("a"),Wgo=o("CamembertConfig"),Ugo=o(" (CamemBERT model)"),Hgo=l(),bg=a("li"),Dhe=a("strong"),Jgo=o("canine"),Ygo=o(" \u2014 "),Kq=a("a"),Zgo=o("CanineConfig"),Kgo=o(" (CANINE model)"),eho=l(),vg=a("li"),Ghe=a("strong"),oho=o("clip"),rho=o(" \u2014 "),ej=a("a"),tho=o("CLIPConfig"),aho=o(" (CLIP model)"),nho=l(),Fg=a("li"),Ohe=a("strong"),sho=o("clipseg"),lho=o(" \u2014 "),oj=a("a"),iho=o("CLIPSegConfig"),dho=o(" (CLIPSeg model)"),mho=l(),Tg=a("li"),Vhe=a("strong"),cho=o("codegen"),fho=o(" \u2014 "),rj=a("a"),gho=o("CodeGenConfig"),hho=o(" (CodeGen model)"),uho=l(),Mg=a("li"),Xhe=a("strong"),pho=o("conditional_detr"),_ho=o(" \u2014 "),tj=a("a"),bho=o("ConditionalDetrConfig"),vho=o(" (Conditional DETR model)"),Fho=l(),Eg=a("li"),zhe=a("strong"),Tho=o("convbert"),Mho=o(" \u2014 "),aj=a("a"),Eho=o("ConvBertConfig"),Cho=o(" (ConvBERT model)"),who=l(),Cg=a("li"),Qhe=a("strong"),Aho=o("convnext"),Lho=o(" \u2014 "),nj=a("a"),yho=o("ConvNextConfig"),xho=o(" (ConvNeXT model)"),$ho=l(),wg=a("li"),Whe=a("strong"),kho=o("ctrl"),Sho=o(" \u2014 "),sj=a("a"),Rho=o("CTRLConfig"),Pho=o(" (CTRL model)"),Bho=l(),Ag=a("li"),Uhe=a("strong"),Iho=o("cvt"),Nho=o(" \u2014 "),lj=a("a"),qho=o("CvtConfig"),jho=o(" (CvT model)"),Dho=l(),Lg=a("li"),Hhe=a("strong"),Gho=o("data2vec-audio"),Oho=o(" \u2014 "),ij=a("a"),Vho=o("Data2VecAudioConfig"),Xho=o(" (Data2VecAudio model)"),zho=l(),yg=a("li"),Jhe=a("strong"),Qho=o("data2vec-text"),Who=o(" \u2014 "),dj=a("a"),Uho=o("Data2VecTextConfig"),Hho=o(" (Data2VecText model)"),Jho=l(),xg=a("li"),Yhe=a("strong"),Yho=o("data2vec-vision"),Zho=o(" \u2014 "),mj=a("a"),Kho=o("Data2VecVisionConfig"),euo=o(" (Data2VecVision model)"),ouo=l(),$g=a("li"),Zhe=a("strong"),ruo=o("deberta"),tuo=o(" \u2014 "),cj=a("a"),auo=o("DebertaConfig"),nuo=o(" (DeBERTa model)"),suo=l(),kg=a("li"),Khe=a("strong"),luo=o("deberta-v2"),iuo=o(" \u2014 "),fj=a("a"),duo=o("DebertaV2Config"),muo=o(" (DeBERTa-v2 model)"),cuo=l(),Sg=a("li"),eue=a("strong"),fuo=o("decision_transformer"),guo=o(" \u2014 "),gj=a("a"),huo=o("DecisionTransformerConfig"),uuo=o(" (Decision Transformer model)"),puo=l(),Rg=a("li"),oue=a("strong"),_uo=o("deformable_detr"),buo=o(" \u2014 "),hj=a("a"),vuo=o("DeformableDetrConfig"),Fuo=o(" (Deformable DETR model)"),Tuo=l(),Pg=a("li"),rue=a("strong"),Muo=o("deit"),Euo=o(" \u2014 "),uj=a("a"),Cuo=o("DeiTConfig"),wuo=o(" (DeiT model)"),Auo=l(),Bg=a("li"),tue=a("strong"),Luo=o("detr"),yuo=o(" \u2014 "),pj=a("a"),xuo=o("DetrConfig"),$uo=o(" (DETR model)"),kuo=l(),Ig=a("li"),aue=a("strong"),Suo=o("distilbert"),Ruo=o(" \u2014 "),_j=a("a"),Puo=o("DistilBertConfig"),Buo=o(" (DistilBERT model)"),Iuo=l(),Ng=a("li"),nue=a("strong"),Nuo=o("donut-swin"),quo=o(" \u2014 "),bj=a("a"),juo=o("DonutSwinConfig"),Duo=o(" (DonutSwin model)"),Guo=l(),qg=a("li"),sue=a("strong"),Ouo=o("dpr"),Vuo=o(" \u2014 "),vj=a("a"),Xuo=o("DPRConfig"),zuo=o(" (DPR model)"),Quo=l(),jg=a("li"),lue=a("strong"),Wuo=o("dpt"),Uuo=o(" \u2014 "),Fj=a("a"),Huo=o("DPTConfig"),Juo=o(" (DPT model)"),Yuo=l(),Dg=a("li"),iue=a("strong"),Zuo=o("electra"),Kuo=o(" \u2014 "),Tj=a("a"),epo=o("ElectraConfig"),opo=o(" (ELECTRA model)"),rpo=l(),Gg=a("li"),due=a("strong"),tpo=o("encoder-decoder"),apo=o(" \u2014 "),Mj=a("a"),npo=o("EncoderDecoderConfig"),spo=o(" (Encoder decoder model)"),lpo=l(),Og=a("li"),mue=a("strong"),ipo=o("ernie"),dpo=o(" \u2014 "),Ej=a("a"),mpo=o("ErnieConfig"),cpo=o(" (ERNIE model)"),fpo=l(),Vg=a("li"),cue=a("strong"),gpo=o("esm"),hpo=o(" \u2014 "),Cj=a("a"),upo=o("EsmConfig"),ppo=o(" (ESM model)"),_po=l(),Xg=a("li"),fue=a("strong"),bpo=o("flaubert"),vpo=o(" \u2014 "),wj=a("a"),Fpo=o("FlaubertConfig"),Tpo=o(" (FlauBERT model)"),Mpo=l(),zg=a("li"),gue=a("strong"),Epo=o("flava"),Cpo=o(" \u2014 "),Aj=a("a"),wpo=o("FlavaConfig"),Apo=o(" (FLAVA model)"),Lpo=l(),Qg=a("li"),hue=a("strong"),ypo=o("fnet"),xpo=o(" \u2014 "),Lj=a("a"),$po=o("FNetConfig"),kpo=o(" (FNet model)"),Spo=l(),Wg=a("li"),uue=a("strong"),Rpo=o("fsmt"),Ppo=o(" \u2014 "),yj=a("a"),Bpo=o("FSMTConfig"),Ipo=o(" (FairSeq Machine-Translation model)"),Npo=l(),Ug=a("li"),pue=a("strong"),qpo=o("funnel"),jpo=o(" \u2014 "),xj=a("a"),Dpo=o("FunnelConfig"),Gpo=o(" (Funnel Transformer model)"),Opo=l(),Hg=a("li"),_ue=a("strong"),Vpo=o("glpn"),Xpo=o(" \u2014 "),$j=a("a"),zpo=o("GLPNConfig"),Qpo=o(" (GLPN model)"),Wpo=l(),Jg=a("li"),bue=a("strong"),Upo=o("gpt2"),Hpo=o(" \u2014 "),kj=a("a"),Jpo=o("GPT2Config"),Ypo=o(" (OpenAI GPT-2 model)"),Zpo=l(),Yg=a("li"),vue=a("strong"),Kpo=o("gpt_neo"),e_o=o(" \u2014 "),Sj=a("a"),o_o=o("GPTNeoConfig"),r_o=o(" (GPT Neo model)"),t_o=l(),Zg=a("li"),Fue=a("strong"),a_o=o("gpt_neox"),n_o=o(" \u2014 "),Rj=a("a"),s_o=o("GPTNeoXConfig"),l_o=o(" (GPT NeoX model)"),i_o=l(),Kg=a("li"),Tue=a("strong"),d_o=o("gpt_neox_japanese"),m_o=o(" \u2014 "),Pj=a("a"),c_o=o("GPTNeoXJapaneseConfig"),f_o=o(" (GPT NeoX Japanese model)"),g_o=l(),eh=a("li"),Mue=a("strong"),h_o=o("gptj"),u_o=o(" \u2014 "),Bj=a("a"),p_o=o("GPTJConfig"),__o=o(" (GPT-J model)"),b_o=l(),oh=a("li"),Eue=a("strong"),v_o=o("groupvit"),F_o=o(" \u2014 "),Ij=a("a"),T_o=o("GroupViTConfig"),M_o=o(" (GroupViT model)"),E_o=l(),rh=a("li"),Cue=a("strong"),C_o=o("hubert"),w_o=o(" \u2014 "),Nj=a("a"),A_o=o("HubertConfig"),L_o=o(" (Hubert model)"),y_o=l(),th=a("li"),wue=a("strong"),x_o=o("ibert"),$_o=o(" \u2014 "),qj=a("a"),k_o=o("IBertConfig"),S_o=o(" (I-BERT model)"),R_o=l(),ah=a("li"),Aue=a("strong"),P_o=o("imagegpt"),B_o=o(" \u2014 "),jj=a("a"),I_o=o("ImageGPTConfig"),N_o=o(" (ImageGPT model)"),q_o=l(),nh=a("li"),Lue=a("strong"),j_o=o("jukebox"),D_o=o(" \u2014 "),Dj=a("a"),G_o=o("JukeboxConfig"),O_o=o(" (Jukebox model)"),V_o=l(),sh=a("li"),yue=a("strong"),X_o=o("layoutlm"),z_o=o(" \u2014 "),Gj=a("a"),Q_o=o("LayoutLMConfig"),W_o=o(" (LayoutLM model)"),U_o=l(),lh=a("li"),xue=a("strong"),H_o=o("layoutlmv2"),J_o=o(" \u2014 "),Oj=a("a"),Y_o=o("LayoutLMv2Config"),Z_o=o(" (LayoutLMv2 model)"),K_o=l(),ih=a("li"),$ue=a("strong"),e1o=o("layoutlmv3"),o1o=o(" \u2014 "),Vj=a("a"),r1o=o("LayoutLMv3Config"),t1o=o(" (LayoutLMv3 model)"),a1o=l(),dh=a("li"),kue=a("strong"),n1o=o("led"),s1o=o(" \u2014 "),Xj=a("a"),l1o=o("LEDConfig"),i1o=o(" (LED model)"),d1o=l(),mh=a("li"),Sue=a("strong"),m1o=o("levit"),c1o=o(" \u2014 "),zj=a("a"),f1o=o("LevitConfig"),g1o=o(" (LeViT model)"),h1o=l(),ch=a("li"),Rue=a("strong"),u1o=o("lilt"),p1o=o(" \u2014 "),Qj=a("a"),_1o=o("LiltConfig"),b1o=o(" (LiLT model)"),v1o=l(),fh=a("li"),Pue=a("strong"),F1o=o("longformer"),T1o=o(" \u2014 "),Wj=a("a"),M1o=o("LongformerConfig"),E1o=o(" (Longformer model)"),C1o=l(),gh=a("li"),Bue=a("strong"),w1o=o("longt5"),A1o=o(" \u2014 "),Uj=a("a"),L1o=o("LongT5Config"),y1o=o(" (LongT5 model)"),x1o=l(),hh=a("li"),Iue=a("strong"),$1o=o("luke"),k1o=o(" \u2014 "),Hj=a("a"),S1o=o("LukeConfig"),R1o=o(" (LUKE model)"),P1o=l(),uh=a("li"),Nue=a("strong"),B1o=o("lxmert"),I1o=o(" \u2014 "),Jj=a("a"),N1o=o("LxmertConfig"),q1o=o(" (LXMERT model)"),j1o=l(),ph=a("li"),que=a("strong"),D1o=o("m2m_100"),G1o=o(" \u2014 "),Yj=a("a"),O1o=o("M2M100Config"),V1o=o(" (M2M100 model)"),X1o=l(),_h=a("li"),jue=a("strong"),z1o=o("marian"),Q1o=o(" \u2014 "),Zj=a("a"),W1o=o("MarianConfig"),U1o=o(" (Marian model)"),H1o=l(),bh=a("li"),Due=a("strong"),J1o=o("markuplm"),Y1o=o(" \u2014 "),Kj=a("a"),Z1o=o("MarkupLMConfig"),K1o=o(" (MarkupLM model)"),e2o=l(),vh=a("li"),Gue=a("strong"),o2o=o("maskformer"),r2o=o(" \u2014 "),eD=a("a"),t2o=o("MaskFormerConfig"),a2o=o(" (MaskFormer model)"),n2o=l(),Fh=a("li"),Oue=a("strong"),s2o=o("mbart"),l2o=o(" \u2014 "),oD=a("a"),i2o=o("MBartConfig"),d2o=o(" (mBART model)"),m2o=l(),Th=a("li"),Vue=a("strong"),c2o=o("mctct"),f2o=o(" \u2014 "),rD=a("a"),g2o=o("MCTCTConfig"),h2o=o(" (M-CTC-T model)"),u2o=l(),Mh=a("li"),Xue=a("strong"),p2o=o("megatron-bert"),_2o=o(" \u2014 "),tD=a("a"),b2o=o("MegatronBertConfig"),v2o=o(" (Megatron-BERT model)"),F2o=l(),Eh=a("li"),zue=a("strong"),T2o=o("mobilebert"),M2o=o(" \u2014 "),aD=a("a"),E2o=o("MobileBertConfig"),C2o=o(" (MobileBERT model)"),w2o=l(),Ch=a("li"),Que=a("strong"),A2o=o("mobilevit"),L2o=o(" \u2014 "),nD=a("a"),y2o=o("MobileViTConfig"),x2o=o(" (MobileViT model)"),$2o=l(),wh=a("li"),Wue=a("strong"),k2o=o("mpnet"),S2o=o(" \u2014 "),sD=a("a"),R2o=o("MPNetConfig"),P2o=o(" (MPNet model)"),B2o=l(),Ah=a("li"),Uue=a("strong"),I2o=o("mt5"),N2o=o(" \u2014 "),lD=a("a"),q2o=o("MT5Config"),j2o=o(" (MT5 model)"),D2o=l(),Lh=a("li"),Hue=a("strong"),G2o=o("mvp"),O2o=o(" \u2014 "),iD=a("a"),V2o=o("MvpConfig"),X2o=o(" (MVP model)"),z2o=l(),yh=a("li"),Jue=a("strong"),Q2o=o("nezha"),W2o=o(" \u2014 "),dD=a("a"),U2o=o("NezhaConfig"),H2o=o(" (Nezha model)"),J2o=l(),xh=a("li"),Yue=a("strong"),Y2o=o("nystromformer"),Z2o=o(" \u2014 "),mD=a("a"),K2o=o("NystromformerConfig"),ebo=o(" (Nystr\xF6mformer model)"),obo=l(),$h=a("li"),Zue=a("strong"),rbo=o("openai-gpt"),tbo=o(" \u2014 "),cD=a("a"),abo=o("OpenAIGPTConfig"),nbo=o(" (OpenAI GPT model)"),sbo=l(),kh=a("li"),Kue=a("strong"),lbo=o("opt"),ibo=o(" \u2014 "),fD=a("a"),dbo=o("OPTConfig"),mbo=o(" (OPT model)"),cbo=l(),Sh=a("li"),epe=a("strong"),fbo=o("owlvit"),gbo=o(" \u2014 "),gD=a("a"),hbo=o("OwlViTConfig"),ubo=o(" (OWL-ViT model)"),pbo=l(),Rh=a("li"),ope=a("strong"),_bo=o("pegasus"),bbo=o(" \u2014 "),hD=a("a"),vbo=o("PegasusConfig"),Fbo=o(" (Pegasus model)"),Tbo=l(),Ph=a("li"),rpe=a("strong"),Mbo=o("pegasus_x"),Ebo=o(" \u2014 "),uD=a("a"),Cbo=o("PegasusXConfig"),wbo=o(" (PEGASUS-X model)"),Abo=l(),Bh=a("li"),tpe=a("strong"),Lbo=o("perceiver"),ybo=o(" \u2014 "),pD=a("a"),xbo=o("PerceiverConfig"),$bo=o(" (Perceiver model)"),kbo=l(),Ih=a("li"),ape=a("strong"),Sbo=o("plbart"),Rbo=o(" \u2014 "),_D=a("a"),Pbo=o("PLBartConfig"),Bbo=o(" (PLBart model)"),Ibo=l(),Nh=a("li"),npe=a("strong"),Nbo=o("poolformer"),qbo=o(" \u2014 "),bD=a("a"),jbo=o("PoolFormerConfig"),Dbo=o(" (PoolFormer model)"),Gbo=l(),qh=a("li"),spe=a("strong"),Obo=o("prophetnet"),Vbo=o(" \u2014 "),vD=a("a"),Xbo=o("ProphetNetConfig"),zbo=o(" (ProphetNet model)"),Qbo=l(),jh=a("li"),lpe=a("strong"),Wbo=o("qdqbert"),Ubo=o(" \u2014 "),FD=a("a"),Hbo=o("QDQBertConfig"),Jbo=o(" (QDQBert model)"),Ybo=l(),Dh=a("li"),ipe=a("strong"),Zbo=o("rag"),Kbo=o(" \u2014 "),TD=a("a"),evo=o("RagConfig"),ovo=o(" (RAG model)"),rvo=l(),Gh=a("li"),dpe=a("strong"),tvo=o("realm"),avo=o(" \u2014 "),MD=a("a"),nvo=o("RealmConfig"),svo=o(" (REALM model)"),lvo=l(),Oh=a("li"),mpe=a("strong"),ivo=o("reformer"),dvo=o(" \u2014 "),ED=a("a"),mvo=o("ReformerConfig"),cvo=o(" (Reformer model)"),fvo=l(),Vh=a("li"),cpe=a("strong"),gvo=o("regnet"),hvo=o(" \u2014 "),CD=a("a"),uvo=o("RegNetConfig"),pvo=o(" (RegNet model)"),_vo=l(),Xh=a("li"),fpe=a("strong"),bvo=o("rembert"),vvo=o(" \u2014 "),wD=a("a"),Fvo=o("RemBertConfig"),Tvo=o(" (RemBERT model)"),Mvo=l(),zh=a("li"),gpe=a("strong"),Evo=o("resnet"),Cvo=o(" \u2014 "),AD=a("a"),wvo=o("ResNetConfig"),Avo=o(" (ResNet model)"),Lvo=l(),Qh=a("li"),hpe=a("strong"),yvo=o("retribert"),xvo=o(" \u2014 "),LD=a("a"),$vo=o("RetriBertConfig"),kvo=o(" (RetriBERT model)"),Svo=l(),Wh=a("li"),upe=a("strong"),Rvo=o("roberta"),Pvo=o(" \u2014 "),yD=a("a"),Bvo=o("RobertaConfig"),Ivo=o(" (RoBERTa model)"),Nvo=l(),Uh=a("li"),ppe=a("strong"),qvo=o("roc_bert"),jvo=o(" \u2014 "),xD=a("a"),Dvo=o("RoCBertConfig"),Gvo=o(" (RoCBert model)"),Ovo=l(),Hh=a("li"),_pe=a("strong"),Vvo=o("roformer"),Xvo=o(" \u2014 "),$D=a("a"),zvo=o("RoFormerConfig"),Qvo=o(" (RoFormer model)"),Wvo=l(),Jh=a("li"),bpe=a("strong"),Uvo=o("segformer"),Hvo=o(" \u2014 "),kD=a("a"),Jvo=o("SegformerConfig"),Yvo=o(" (SegFormer model)"),Zvo=l(),Yh=a("li"),vpe=a("strong"),Kvo=o("sew"),eFo=o(" \u2014 "),SD=a("a"),oFo=o("SEWConfig"),rFo=o(" (SEW model)"),tFo=l(),Zh=a("li"),Fpe=a("strong"),aFo=o("sew-d"),nFo=o(" \u2014 "),RD=a("a"),sFo=o("SEWDConfig"),lFo=o(" (SEW-D model)"),iFo=l(),Kh=a("li"),Tpe=a("strong"),dFo=o("speech-encoder-decoder"),mFo=o(" \u2014 "),PD=a("a"),cFo=o("SpeechEncoderDecoderConfig"),fFo=o(" (Speech Encoder decoder model)"),gFo=l(),eu=a("li"),Mpe=a("strong"),hFo=o("speech_to_text"),uFo=o(" \u2014 "),BD=a("a"),pFo=o("Speech2TextConfig"),_Fo=o(" (Speech2Text model)"),bFo=l(),ou=a("li"),Epe=a("strong"),vFo=o("speech_to_text_2"),FFo=o(" \u2014 "),ID=a("a"),TFo=o("Speech2Text2Config"),MFo=o(" (Speech2Text2 model)"),EFo=l(),ru=a("li"),Cpe=a("strong"),CFo=o("splinter"),wFo=o(" \u2014 "),ND=a("a"),AFo=o("SplinterConfig"),LFo=o(" (Splinter model)"),yFo=l(),tu=a("li"),wpe=a("strong"),xFo=o("squeezebert"),$Fo=o(" \u2014 "),qD=a("a"),kFo=o("SqueezeBertConfig"),SFo=o(" (SqueezeBERT model)"),RFo=l(),au=a("li"),Ape=a("strong"),PFo=o("swin"),BFo=o(" \u2014 "),jD=a("a"),IFo=o("SwinConfig"),NFo=o(" (Swin Transformer model)"),qFo=l(),nu=a("li"),Lpe=a("strong"),jFo=o("swinv2"),DFo=o(" \u2014 "),DD=a("a"),GFo=o("Swinv2Config"),OFo=o(" (Swin Transformer V2 model)"),VFo=l(),su=a("li"),ype=a("strong"),XFo=o("t5"),zFo=o(" \u2014 "),GD=a("a"),QFo=o("T5Config"),WFo=o(" (T5 model)"),UFo=l(),lu=a("li"),xpe=a("strong"),HFo=o("table-transformer"),JFo=o(" \u2014 "),OD=a("a"),YFo=o("TableTransformerConfig"),ZFo=o(" (Table Transformer model)"),KFo=l(),iu=a("li"),$pe=a("strong"),eTo=o("tapas"),oTo=o(" \u2014 "),VD=a("a"),rTo=o("TapasConfig"),tTo=o(" (TAPAS model)"),aTo=l(),du=a("li"),kpe=a("strong"),nTo=o("time_series_transformer"),sTo=o(" \u2014 "),XD=a("a"),lTo=o("TimeSeriesTransformerConfig"),iTo=o(" (Time Series Transformer model)"),dTo=l(),mu=a("li"),Spe=a("strong"),mTo=o("trajectory_transformer"),cTo=o(" \u2014 "),zD=a("a"),fTo=o("TrajectoryTransformerConfig"),gTo=o(" (Trajectory Transformer model)"),hTo=l(),cu=a("li"),Rpe=a("strong"),uTo=o("transfo-xl"),pTo=o(" \u2014 "),QD=a("a"),_To=o("TransfoXLConfig"),bTo=o(" (Transformer-XL model)"),vTo=l(),fu=a("li"),Ppe=a("strong"),FTo=o("trocr"),TTo=o(" \u2014 "),WD=a("a"),MTo=o("TrOCRConfig"),ETo=o(" (TrOCR model)"),CTo=l(),gu=a("li"),Bpe=a("strong"),wTo=o("unispeech"),ATo=o(" \u2014 "),UD=a("a"),LTo=o("UniSpeechConfig"),yTo=o(" (UniSpeech model)"),xTo=l(),hu=a("li"),Ipe=a("strong"),$To=o("unispeech-sat"),kTo=o(" \u2014 "),HD=a("a"),STo=o("UniSpeechSatConfig"),RTo=o(" (UniSpeechSat model)"),PTo=l(),uu=a("li"),Npe=a("strong"),BTo=o("van"),ITo=o(" \u2014 "),JD=a("a"),NTo=o("VanConfig"),qTo=o(" (VAN model)"),jTo=l(),pu=a("li"),qpe=a("strong"),DTo=o("videomae"),GTo=o(" \u2014 "),YD=a("a"),OTo=o("VideoMAEConfig"),VTo=o(" (VideoMAE model)"),XTo=l(),_u=a("li"),jpe=a("strong"),zTo=o("vilt"),QTo=o(" \u2014 "),ZD=a("a"),WTo=o("ViltConfig"),UTo=o(" (ViLT model)"),HTo=l(),bu=a("li"),Dpe=a("strong"),JTo=o("vision-encoder-decoder"),YTo=o(" \u2014 "),KD=a("a"),ZTo=o("VisionEncoderDecoderConfig"),KTo=o(" (Vision Encoder decoder model)"),eMo=l(),vu=a("li"),Gpe=a("strong"),oMo=o("vision-text-dual-encoder"),rMo=o(" \u2014 "),eG=a("a"),tMo=o("VisionTextDualEncoderConfig"),aMo=o(" (VisionTextDualEncoder model)"),nMo=l(),Fu=a("li"),Ope=a("strong"),sMo=o("visual_bert"),lMo=o(" \u2014 "),oG=a("a"),iMo=o("VisualBertConfig"),dMo=o(" (VisualBERT model)"),mMo=l(),Tu=a("li"),Vpe=a("strong"),cMo=o("vit"),fMo=o(" \u2014 "),rG=a("a"),gMo=o("ViTConfig"),hMo=o(" (ViT model)"),uMo=l(),Mu=a("li"),Xpe=a("strong"),pMo=o("vit_mae"),_Mo=o(" \u2014 "),tG=a("a"),bMo=o("ViTMAEConfig"),vMo=o(" (ViTMAE model)"),FMo=l(),Eu=a("li"),zpe=a("strong"),TMo=o("vit_msn"),MMo=o(" \u2014 "),aG=a("a"),EMo=o("ViTMSNConfig"),CMo=o(" (ViTMSN model)"),wMo=l(),Cu=a("li"),Qpe=a("strong"),AMo=o("wav2vec2"),LMo=o(" \u2014 "),nG=a("a"),yMo=o("Wav2Vec2Config"),xMo=o(" (Wav2Vec2 model)"),$Mo=l(),wu=a("li"),Wpe=a("strong"),kMo=o("wav2vec2-conformer"),SMo=o(" \u2014 "),sG=a("a"),RMo=o("Wav2Vec2ConformerConfig"),PMo=o(" (Wav2Vec2-Conformer model)"),BMo=l(),Au=a("li"),Upe=a("strong"),IMo=o("wavlm"),NMo=o(" \u2014 "),lG=a("a"),qMo=o("WavLMConfig"),jMo=o(" (WavLM model)"),DMo=l(),Lu=a("li"),Hpe=a("strong"),GMo=o("whisper"),OMo=o(" \u2014 "),iG=a("a"),VMo=o("WhisperConfig"),XMo=o(" (Whisper model)"),zMo=l(),yu=a("li"),Jpe=a("strong"),QMo=o("xclip"),WMo=o(" \u2014 "),dG=a("a"),UMo=o("XCLIPConfig"),HMo=o(" (X-CLIP model)"),JMo=l(),xu=a("li"),Ype=a("strong"),YMo=o("xglm"),ZMo=o(" \u2014 "),mG=a("a"),KMo=o("XGLMConfig"),eEo=o(" (XGLM model)"),oEo=l(),$u=a("li"),Zpe=a("strong"),rEo=o("xlm"),tEo=o(" \u2014 "),cG=a("a"),aEo=o("XLMConfig"),nEo=o(" (XLM model)"),sEo=l(),ku=a("li"),Kpe=a("strong"),lEo=o("xlm-prophetnet"),iEo=o(" \u2014 "),fG=a("a"),dEo=o("XLMProphetNetConfig"),mEo=o(" (XLM-ProphetNet model)"),cEo=l(),Su=a("li"),e_e=a("strong"),fEo=o("xlm-roberta"),gEo=o(" \u2014 "),gG=a("a"),hEo=o("XLMRobertaConfig"),uEo=o(" (XLM-RoBERTa model)"),pEo=l(),Ru=a("li"),o_e=a("strong"),_Eo=o("xlm-roberta-xl"),bEo=o(" \u2014 "),hG=a("a"),vEo=o("XLMRobertaXLConfig"),FEo=o(" (XLM-RoBERTa-XL model)"),TEo=l(),Pu=a("li"),r_e=a("strong"),MEo=o("xlnet"),EEo=o(" \u2014 "),uG=a("a"),CEo=o("XLNetConfig"),wEo=o(" (XLNet model)"),AEo=l(),Bu=a("li"),t_e=a("strong"),LEo=o("yolos"),yEo=o(" \u2014 "),pG=a("a"),xEo=o("YolosConfig"),$Eo=o(" (YOLOS model)"),kEo=l(),Iu=a("li"),a_e=a("strong"),SEo=o("yoso"),REo=o(" \u2014 "),_G=a("a"),PEo=o("YosoConfig"),BEo=o(" (YOSO model)"),IEo=l(),F(Nu.$$.fragment),NEo=l(),qu=a("div"),F(Mk.$$.fragment),qEo=l(),n_e=a("p"),jEo=o("Register a new configuration for this class."),Blo=l(),Id=a("h2"),ju=a("a"),s_e=a("span"),F(Ek.$$.fragment),DEo=l(),l_e=a("span"),GEo=o("AutoTokenizer"),Ilo=l(),Io=a("div"),F(Ck.$$.fragment),OEo=l(),wk=a("p"),VEo=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),bG=a("a"),XEo=o("AutoTokenizer.from_pretrained()"),zEo=o(" class method."),QEo=l(),Ak=a("p"),WEo=o("This class cannot be instantiated directly using "),i_e=a("code"),UEo=o("__init__()"),HEo=o(" (throws an error)."),JEo=l(),Vr=a("div"),F(Lk.$$.fragment),YEo=l(),d_e=a("p"),ZEo=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),KEo=l(),dn=a("p"),e4o=o("The tokenizer class to instantiate is selected based on the "),m_e=a("code"),o4o=o("model_type"),r4o=o(` property of the config object (either
passed as an argument or loaded from `),c_e=a("code"),t4o=o("pretrained_model_name_or_path"),a4o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f_e=a("code"),n4o=o("pretrained_model_name_or_path"),s4o=o(":"),l4o=l(),k=a("ul"),Ts=a("li"),g_e=a("strong"),i4o=o("albert"),d4o=o(" \u2014 "),vG=a("a"),m4o=o("AlbertTokenizer"),c4o=o(" or "),FG=a("a"),f4o=o("AlbertTokenizerFast"),g4o=o(" (ALBERT model)"),h4o=l(),Ms=a("li"),h_e=a("strong"),u4o=o("bart"),p4o=o(" \u2014 "),TG=a("a"),_4o=o("BartTokenizer"),b4o=o(" or "),MG=a("a"),v4o=o("BartTokenizerFast"),F4o=o(" (BART model)"),T4o=l(),Es=a("li"),u_e=a("strong"),M4o=o("barthez"),E4o=o(" \u2014 "),EG=a("a"),C4o=o("BarthezTokenizer"),w4o=o(" or "),CG=a("a"),A4o=o("BarthezTokenizerFast"),L4o=o(" (BARThez model)"),y4o=l(),Du=a("li"),p_e=a("strong"),x4o=o("bartpho"),$4o=o(" \u2014 "),wG=a("a"),k4o=o("BartphoTokenizer"),S4o=o(" (BARTpho model)"),R4o=l(),Cs=a("li"),__e=a("strong"),P4o=o("bert"),B4o=o(" \u2014 "),AG=a("a"),I4o=o("BertTokenizer"),N4o=o(" or "),LG=a("a"),q4o=o("BertTokenizerFast"),j4o=o(" (BERT model)"),D4o=l(),Gu=a("li"),b_e=a("strong"),G4o=o("bert-generation"),O4o=o(" \u2014 "),yG=a("a"),V4o=o("BertGenerationTokenizer"),X4o=o(" (Bert Generation model)"),z4o=l(),Ou=a("li"),v_e=a("strong"),Q4o=o("bert-japanese"),W4o=o(" \u2014 "),xG=a("a"),U4o=o("BertJapaneseTokenizer"),H4o=o(" (BertJapanese model)"),J4o=l(),Vu=a("li"),F_e=a("strong"),Y4o=o("bertweet"),Z4o=o(" \u2014 "),$G=a("a"),K4o=o("BertweetTokenizer"),eCo=o(" (BERTweet model)"),oCo=l(),ws=a("li"),T_e=a("strong"),rCo=o("big_bird"),tCo=o(" \u2014 "),kG=a("a"),aCo=o("BigBirdTokenizer"),nCo=o(" or "),SG=a("a"),sCo=o("BigBirdTokenizerFast"),lCo=o(" (BigBird model)"),iCo=l(),As=a("li"),M_e=a("strong"),dCo=o("bigbird_pegasus"),mCo=o(" \u2014 "),RG=a("a"),cCo=o("PegasusTokenizer"),fCo=o(" or "),PG=a("a"),gCo=o("PegasusTokenizerFast"),hCo=o(" (BigBird-Pegasus model)"),uCo=l(),Ls=a("li"),E_e=a("strong"),pCo=o("blenderbot"),_Co=o(" \u2014 "),BG=a("a"),bCo=o("BlenderbotTokenizer"),vCo=o(" or "),IG=a("a"),FCo=o("BlenderbotTokenizerFast"),TCo=o(" (Blenderbot model)"),MCo=l(),Xu=a("li"),C_e=a("strong"),ECo=o("blenderbot-small"),CCo=o(" \u2014 "),NG=a("a"),wCo=o("BlenderbotSmallTokenizer"),ACo=o(" (BlenderbotSmall model)"),LCo=l(),zu=a("li"),w_e=a("strong"),yCo=o("bloom"),xCo=o(" \u2014 "),qG=a("a"),$Co=o("BloomTokenizerFast"),kCo=o(" (BLOOM model)"),SCo=l(),Qu=a("li"),A_e=a("strong"),RCo=o("byt5"),PCo=o(" \u2014 "),jG=a("a"),BCo=o("ByT5Tokenizer"),ICo=o(" (ByT5 model)"),NCo=l(),ys=a("li"),L_e=a("strong"),qCo=o("camembert"),jCo=o(" \u2014 "),DG=a("a"),DCo=o("CamembertTokenizer"),GCo=o(" or "),GG=a("a"),OCo=o("CamembertTokenizerFast"),VCo=o(" (CamemBERT model)"),XCo=l(),Wu=a("li"),y_e=a("strong"),zCo=o("canine"),QCo=o(" \u2014 "),OG=a("a"),WCo=o("CanineTokenizer"),UCo=o(" (CANINE model)"),HCo=l(),xs=a("li"),x_e=a("strong"),JCo=o("clip"),YCo=o(" \u2014 "),VG=a("a"),ZCo=o("CLIPTokenizer"),KCo=o(" or "),XG=a("a"),e3o=o("CLIPTokenizerFast"),o3o=o(" (CLIP model)"),r3o=l(),$s=a("li"),$_e=a("strong"),t3o=o("clipseg"),a3o=o(" \u2014 "),zG=a("a"),n3o=o("CLIPTokenizer"),s3o=o(" or "),QG=a("a"),l3o=o("CLIPTokenizerFast"),i3o=o(" (CLIPSeg model)"),d3o=l(),ks=a("li"),k_e=a("strong"),m3o=o("codegen"),c3o=o(" \u2014 "),WG=a("a"),f3o=o("CodeGenTokenizer"),g3o=o(" or "),UG=a("a"),h3o=o("CodeGenTokenizerFast"),u3o=o(" (CodeGen model)"),p3o=l(),Ss=a("li"),S_e=a("strong"),_3o=o("convbert"),b3o=o(" \u2014 "),HG=a("a"),v3o=o("ConvBertTokenizer"),F3o=o(" or "),JG=a("a"),T3o=o("ConvBertTokenizerFast"),M3o=o(" (ConvBERT model)"),E3o=l(),Rs=a("li"),R_e=a("strong"),C3o=o("cpm"),w3o=o(" \u2014 "),YG=a("a"),A3o=o("CpmTokenizer"),L3o=o(" or "),ZG=a("a"),y3o=o("CpmTokenizerFast"),x3o=o(" (CPM model)"),$3o=l(),Uu=a("li"),P_e=a("strong"),k3o=o("ctrl"),S3o=o(" \u2014 "),KG=a("a"),R3o=o("CTRLTokenizer"),P3o=o(" (CTRL model)"),B3o=l(),Ps=a("li"),B_e=a("strong"),I3o=o("data2vec-text"),N3o=o(" \u2014 "),eO=a("a"),q3o=o("RobertaTokenizer"),j3o=o(" or "),oO=a("a"),D3o=o("RobertaTokenizerFast"),G3o=o(" (Data2VecText model)"),O3o=l(),Bs=a("li"),I_e=a("strong"),V3o=o("deberta"),X3o=o(" \u2014 "),rO=a("a"),z3o=o("DebertaTokenizer"),Q3o=o(" or "),tO=a("a"),W3o=o("DebertaTokenizerFast"),U3o=o(" (DeBERTa model)"),H3o=l(),Is=a("li"),N_e=a("strong"),J3o=o("deberta-v2"),Y3o=o(" \u2014 "),aO=a("a"),Z3o=o("DebertaV2Tokenizer"),K3o=o(" or "),nO=a("a"),e5o=o("DebertaV2TokenizerFast"),o5o=o(" (DeBERTa-v2 model)"),r5o=l(),Ns=a("li"),q_e=a("strong"),t5o=o("distilbert"),a5o=o(" \u2014 "),sO=a("a"),n5o=o("DistilBertTokenizer"),s5o=o(" or "),lO=a("a"),l5o=o("DistilBertTokenizerFast"),i5o=o(" (DistilBERT model)"),d5o=l(),qs=a("li"),j_e=a("strong"),m5o=o("dpr"),c5o=o(" \u2014 "),iO=a("a"),f5o=o("DPRQuestionEncoderTokenizer"),g5o=o(" or "),dO=a("a"),h5o=o("DPRQuestionEncoderTokenizerFast"),u5o=o(" (DPR model)"),p5o=l(),js=a("li"),D_e=a("strong"),_5o=o("electra"),b5o=o(" \u2014 "),mO=a("a"),v5o=o("ElectraTokenizer"),F5o=o(" or "),cO=a("a"),T5o=o("ElectraTokenizerFast"),M5o=o(" (ELECTRA model)"),E5o=l(),Ds=a("li"),G_e=a("strong"),C5o=o("ernie"),w5o=o(" \u2014 "),fO=a("a"),A5o=o("BertTokenizer"),L5o=o(" or "),gO=a("a"),y5o=o("BertTokenizerFast"),x5o=o(" (ERNIE model)"),$5o=l(),Hu=a("li"),O_e=a("strong"),k5o=o("esm"),S5o=o(" \u2014 "),hO=a("a"),R5o=o("EsmTokenizer"),P5o=o(" (ESM model)"),B5o=l(),Ju=a("li"),V_e=a("strong"),I5o=o("flaubert"),N5o=o(" \u2014 "),uO=a("a"),q5o=o("FlaubertTokenizer"),j5o=o(" (FlauBERT model)"),D5o=l(),Gs=a("li"),X_e=a("strong"),G5o=o("fnet"),O5o=o(" \u2014 "),pO=a("a"),V5o=o("FNetTokenizer"),X5o=o(" or "),_O=a("a"),z5o=o("FNetTokenizerFast"),Q5o=o(" (FNet model)"),W5o=l(),Yu=a("li"),z_e=a("strong"),U5o=o("fsmt"),H5o=o(" \u2014 "),bO=a("a"),J5o=o("FSMTTokenizer"),Y5o=o(" (FairSeq Machine-Translation model)"),Z5o=l(),Os=a("li"),Q_e=a("strong"),K5o=o("funnel"),e0o=o(" \u2014 "),vO=a("a"),o0o=o("FunnelTokenizer"),r0o=o(" or "),FO=a("a"),t0o=o("FunnelTokenizerFast"),a0o=o(" (Funnel Transformer model)"),n0o=l(),Vs=a("li"),W_e=a("strong"),s0o=o("gpt2"),l0o=o(" \u2014 "),TO=a("a"),i0o=o("GPT2Tokenizer"),d0o=o(" or "),MO=a("a"),m0o=o("GPT2TokenizerFast"),c0o=o(" (OpenAI GPT-2 model)"),f0o=l(),Xs=a("li"),U_e=a("strong"),g0o=o("gpt_neo"),h0o=o(" \u2014 "),EO=a("a"),u0o=o("GPT2Tokenizer"),p0o=o(" or "),CO=a("a"),_0o=o("GPT2TokenizerFast"),b0o=o(" (GPT Neo model)"),v0o=l(),Zu=a("li"),H_e=a("strong"),F0o=o("gpt_neox"),T0o=o(" \u2014 "),wO=a("a"),M0o=o("GPTNeoXTokenizerFast"),E0o=o(" (GPT NeoX model)"),C0o=l(),Ku=a("li"),J_e=a("strong"),w0o=o("gpt_neox_japanese"),A0o=o(" \u2014 "),AO=a("a"),L0o=o("GPTNeoXJapaneseTokenizer"),y0o=o(" (GPT NeoX Japanese model)"),x0o=l(),zs=a("li"),Y_e=a("strong"),$0o=o("gptj"),k0o=o(" \u2014 "),LO=a("a"),S0o=o("GPT2Tokenizer"),R0o=o(" or "),yO=a("a"),P0o=o("GPT2TokenizerFast"),B0o=o(" (GPT-J model)"),I0o=l(),Qs=a("li"),Z_e=a("strong"),N0o=o("groupvit"),q0o=o(" \u2014 "),xO=a("a"),j0o=o("CLIPTokenizer"),D0o=o(" or "),$O=a("a"),G0o=o("CLIPTokenizerFast"),O0o=o(" (GroupViT model)"),V0o=l(),Ws=a("li"),K_e=a("strong"),X0o=o("herbert"),z0o=o(" \u2014 "),kO=a("a"),Q0o=o("HerbertTokenizer"),W0o=o(" or "),SO=a("a"),U0o=o("HerbertTokenizerFast"),H0o=o(" (HerBERT model)"),J0o=l(),ep=a("li"),e1e=a("strong"),Y0o=o("hubert"),Z0o=o(" \u2014 "),RO=a("a"),K0o=o("Wav2Vec2CTCTokenizer"),ewo=o(" (Hubert model)"),owo=l(),Us=a("li"),o1e=a("strong"),rwo=o("ibert"),two=o(" \u2014 "),PO=a("a"),awo=o("RobertaTokenizer"),nwo=o(" or "),BO=a("a"),swo=o("RobertaTokenizerFast"),lwo=o(" (I-BERT model)"),iwo=l(),op=a("li"),r1e=a("strong"),dwo=o("jukebox"),mwo=o(" \u2014 "),IO=a("a"),cwo=o("JukeboxTokenizer"),fwo=o(" (Jukebox model)"),gwo=l(),Hs=a("li"),t1e=a("strong"),hwo=o("layoutlm"),uwo=o(" \u2014 "),NO=a("a"),pwo=o("LayoutLMTokenizer"),_wo=o(" or "),qO=a("a"),bwo=o("LayoutLMTokenizerFast"),vwo=o(" (LayoutLM model)"),Fwo=l(),Js=a("li"),a1e=a("strong"),Two=o("layoutlmv2"),Mwo=o(" \u2014 "),jO=a("a"),Ewo=o("LayoutLMv2Tokenizer"),Cwo=o(" or "),DO=a("a"),wwo=o("LayoutLMv2TokenizerFast"),Awo=o(" (LayoutLMv2 model)"),Lwo=l(),Ys=a("li"),n1e=a("strong"),ywo=o("layoutlmv3"),xwo=o(" \u2014 "),GO=a("a"),$wo=o("LayoutLMv3Tokenizer"),kwo=o(" or "),OO=a("a"),Swo=o("LayoutLMv3TokenizerFast"),Rwo=o(" (LayoutLMv3 model)"),Pwo=l(),Zs=a("li"),s1e=a("strong"),Bwo=o("layoutxlm"),Iwo=o(" \u2014 "),VO=a("a"),Nwo=o("LayoutXLMTokenizer"),qwo=o(" or "),XO=a("a"),jwo=o("LayoutXLMTokenizerFast"),Dwo=o(" (LayoutXLM model)"),Gwo=l(),Ks=a("li"),l1e=a("strong"),Owo=o("led"),Vwo=o(" \u2014 "),zO=a("a"),Xwo=o("LEDTokenizer"),zwo=o(" or "),QO=a("a"),Qwo=o("LEDTokenizerFast"),Wwo=o(" (LED model)"),Uwo=l(),el=a("li"),i1e=a("strong"),Hwo=o("lilt"),Jwo=o(" \u2014 "),WO=a("a"),Ywo=o("LayoutLMv3Tokenizer"),Zwo=o(" or "),UO=a("a"),Kwo=o("LayoutLMv3TokenizerFast"),eAo=o(" (LiLT model)"),oAo=l(),ol=a("li"),d1e=a("strong"),rAo=o("longformer"),tAo=o(" \u2014 "),HO=a("a"),aAo=o("LongformerTokenizer"),nAo=o(" or "),JO=a("a"),sAo=o("LongformerTokenizerFast"),lAo=o(" (Longformer model)"),iAo=l(),rl=a("li"),m1e=a("strong"),dAo=o("longt5"),mAo=o(" \u2014 "),YO=a("a"),cAo=o("T5Tokenizer"),fAo=o(" or "),ZO=a("a"),gAo=o("T5TokenizerFast"),hAo=o(" (LongT5 model)"),uAo=l(),rp=a("li"),c1e=a("strong"),pAo=o("luke"),_Ao=o(" \u2014 "),KO=a("a"),bAo=o("LukeTokenizer"),vAo=o(" (LUKE model)"),FAo=l(),tl=a("li"),f1e=a("strong"),TAo=o("lxmert"),MAo=o(" \u2014 "),eV=a("a"),EAo=o("LxmertTokenizer"),CAo=o(" or "),oV=a("a"),wAo=o("LxmertTokenizerFast"),AAo=o(" (LXMERT model)"),LAo=l(),tp=a("li"),g1e=a("strong"),yAo=o("m2m_100"),xAo=o(" \u2014 "),rV=a("a"),$Ao=o("M2M100Tokenizer"),kAo=o(" (M2M100 model)"),SAo=l(),ap=a("li"),h1e=a("strong"),RAo=o("marian"),PAo=o(" \u2014 "),tV=a("a"),BAo=o("MarianTokenizer"),IAo=o(" (Marian model)"),NAo=l(),al=a("li"),u1e=a("strong"),qAo=o("mbart"),jAo=o(" \u2014 "),aV=a("a"),DAo=o("MBartTokenizer"),GAo=o(" or "),nV=a("a"),OAo=o("MBartTokenizerFast"),VAo=o(" (mBART model)"),XAo=l(),nl=a("li"),p1e=a("strong"),zAo=o("mbart50"),QAo=o(" \u2014 "),sV=a("a"),WAo=o("MBart50Tokenizer"),UAo=o(" or "),lV=a("a"),HAo=o("MBart50TokenizerFast"),JAo=o(" (mBART-50 model)"),YAo=l(),sl=a("li"),_1e=a("strong"),ZAo=o("megatron-bert"),KAo=o(" \u2014 "),iV=a("a"),e6o=o("BertTokenizer"),o6o=o(" or "),dV=a("a"),r6o=o("BertTokenizerFast"),t6o=o(" (Megatron-BERT model)"),a6o=l(),np=a("li"),b1e=a("strong"),n6o=o("mluke"),s6o=o(" \u2014 "),mV=a("a"),l6o=o("MLukeTokenizer"),i6o=o(" (mLUKE model)"),d6o=l(),ll=a("li"),v1e=a("strong"),m6o=o("mobilebert"),c6o=o(" \u2014 "),cV=a("a"),f6o=o("MobileBertTokenizer"),g6o=o(" or "),fV=a("a"),h6o=o("MobileBertTokenizerFast"),u6o=o(" (MobileBERT model)"),p6o=l(),il=a("li"),F1e=a("strong"),_6o=o("mpnet"),b6o=o(" \u2014 "),gV=a("a"),v6o=o("MPNetTokenizer"),F6o=o(" or "),hV=a("a"),T6o=o("MPNetTokenizerFast"),M6o=o(" (MPNet model)"),E6o=l(),dl=a("li"),T1e=a("strong"),C6o=o("mt5"),w6o=o(" \u2014 "),uV=a("a"),A6o=o("MT5Tokenizer"),L6o=o(" or "),pV=a("a"),y6o=o("MT5TokenizerFast"),x6o=o(" (MT5 model)"),$6o=l(),ml=a("li"),M1e=a("strong"),k6o=o("mvp"),S6o=o(" \u2014 "),_V=a("a"),R6o=o("MvpTokenizer"),P6o=o(" or "),bV=a("a"),B6o=o("MvpTokenizerFast"),I6o=o(" (MVP model)"),N6o=l(),cl=a("li"),E1e=a("strong"),q6o=o("nezha"),j6o=o(" \u2014 "),vV=a("a"),D6o=o("BertTokenizer"),G6o=o(" or "),FV=a("a"),O6o=o("BertTokenizerFast"),V6o=o(" (Nezha model)"),X6o=l(),fl=a("li"),C1e=a("strong"),z6o=o("nllb"),Q6o=o(" \u2014 "),TV=a("a"),W6o=o("NllbTokenizer"),U6o=o(" or "),MV=a("a"),H6o=o("NllbTokenizerFast"),J6o=o(" (NLLB model)"),Y6o=l(),gl=a("li"),w1e=a("strong"),Z6o=o("nystromformer"),K6o=o(" \u2014 "),EV=a("a"),e7o=o("AlbertTokenizer"),o7o=o(" or "),CV=a("a"),r7o=o("AlbertTokenizerFast"),t7o=o(" (Nystr\xF6mformer model)"),a7o=l(),hl=a("li"),A1e=a("strong"),n7o=o("openai-gpt"),s7o=o(" \u2014 "),wV=a("a"),l7o=o("OpenAIGPTTokenizer"),i7o=o(" or "),AV=a("a"),d7o=o("OpenAIGPTTokenizerFast"),m7o=o(" (OpenAI GPT model)"),c7o=l(),sp=a("li"),L1e=a("strong"),f7o=o("opt"),g7o=o(" \u2014 "),LV=a("a"),h7o=o("GPT2Tokenizer"),u7o=o(" (OPT model)"),p7o=l(),ul=a("li"),y1e=a("strong"),_7o=o("owlvit"),b7o=o(" \u2014 "),yV=a("a"),v7o=o("CLIPTokenizer"),F7o=o(" or "),xV=a("a"),T7o=o("CLIPTokenizerFast"),M7o=o(" (OWL-ViT model)"),E7o=l(),pl=a("li"),x1e=a("strong"),C7o=o("pegasus"),w7o=o(" \u2014 "),$V=a("a"),A7o=o("PegasusTokenizer"),L7o=o(" or "),kV=a("a"),y7o=o("PegasusTokenizerFast"),x7o=o(" (Pegasus model)"),$7o=l(),_l=a("li"),$1e=a("strong"),k7o=o("pegasus_x"),S7o=o(" \u2014 "),SV=a("a"),R7o=o("PegasusTokenizer"),P7o=o(" or "),RV=a("a"),B7o=o("PegasusTokenizerFast"),I7o=o(" (PEGASUS-X model)"),N7o=l(),lp=a("li"),k1e=a("strong"),q7o=o("perceiver"),j7o=o(" \u2014 "),PV=a("a"),D7o=o("PerceiverTokenizer"),G7o=o(" (Perceiver model)"),O7o=l(),ip=a("li"),S1e=a("strong"),V7o=o("phobert"),X7o=o(" \u2014 "),BV=a("a"),z7o=o("PhobertTokenizer"),Q7o=o(" (PhoBERT model)"),W7o=l(),dp=a("li"),R1e=a("strong"),U7o=o("plbart"),H7o=o(" \u2014 "),IV=a("a"),J7o=o("PLBartTokenizer"),Y7o=o(" (PLBart model)"),Z7o=l(),mp=a("li"),P1e=a("strong"),K7o=o("prophetnet"),e8o=o(" \u2014 "),NV=a("a"),o8o=o("ProphetNetTokenizer"),r8o=o(" (ProphetNet model)"),t8o=l(),bl=a("li"),B1e=a("strong"),a8o=o("qdqbert"),n8o=o(" \u2014 "),qV=a("a"),s8o=o("BertTokenizer"),l8o=o(" or "),jV=a("a"),i8o=o("BertTokenizerFast"),d8o=o(" (QDQBert model)"),m8o=l(),cp=a("li"),I1e=a("strong"),c8o=o("rag"),f8o=o(" \u2014 "),DV=a("a"),g8o=o("RagTokenizer"),h8o=o(" (RAG model)"),u8o=l(),vl=a("li"),N1e=a("strong"),p8o=o("realm"),_8o=o(" \u2014 "),GV=a("a"),b8o=o("RealmTokenizer"),v8o=o(" or "),OV=a("a"),F8o=o("RealmTokenizerFast"),T8o=o(" (REALM model)"),M8o=l(),Fl=a("li"),q1e=a("strong"),E8o=o("reformer"),C8o=o(" \u2014 "),VV=a("a"),w8o=o("ReformerTokenizer"),A8o=o(" or "),XV=a("a"),L8o=o("ReformerTokenizerFast"),y8o=o(" (Reformer model)"),x8o=l(),Tl=a("li"),j1e=a("strong"),$8o=o("rembert"),k8o=o(" \u2014 "),zV=a("a"),S8o=o("RemBertTokenizer"),R8o=o(" or "),QV=a("a"),P8o=o("RemBertTokenizerFast"),B8o=o(" (RemBERT model)"),I8o=l(),Ml=a("li"),D1e=a("strong"),N8o=o("retribert"),q8o=o(" \u2014 "),WV=a("a"),j8o=o("RetriBertTokenizer"),D8o=o(" or "),UV=a("a"),G8o=o("RetriBertTokenizerFast"),O8o=o(" (RetriBERT model)"),V8o=l(),El=a("li"),G1e=a("strong"),X8o=o("roberta"),z8o=o(" \u2014 "),HV=a("a"),Q8o=o("RobertaTokenizer"),W8o=o(" or "),JV=a("a"),U8o=o("RobertaTokenizerFast"),H8o=o(" (RoBERTa model)"),J8o=l(),fp=a("li"),O1e=a("strong"),Y8o=o("roc_bert"),Z8o=o(" \u2014 "),YV=a("a"),K8o=o("RoCBertTokenizer"),eLo=o(" (RoCBert model)"),oLo=l(),Cl=a("li"),V1e=a("strong"),rLo=o("roformer"),tLo=o(" \u2014 "),ZV=a("a"),aLo=o("RoFormerTokenizer"),nLo=o(" or "),KV=a("a"),sLo=o("RoFormerTokenizerFast"),lLo=o(" (RoFormer model)"),iLo=l(),gp=a("li"),X1e=a("strong"),dLo=o("speech_to_text"),mLo=o(" \u2014 "),eX=a("a"),cLo=o("Speech2TextTokenizer"),fLo=o(" (Speech2Text model)"),gLo=l(),hp=a("li"),z1e=a("strong"),hLo=o("speech_to_text_2"),uLo=o(" \u2014 "),oX=a("a"),pLo=o("Speech2Text2Tokenizer"),_Lo=o(" (Speech2Text2 model)"),bLo=l(),wl=a("li"),Q1e=a("strong"),vLo=o("splinter"),FLo=o(" \u2014 "),rX=a("a"),TLo=o("SplinterTokenizer"),MLo=o(" or "),tX=a("a"),ELo=o("SplinterTokenizerFast"),CLo=o(" (Splinter model)"),wLo=l(),Al=a("li"),W1e=a("strong"),ALo=o("squeezebert"),LLo=o(" \u2014 "),aX=a("a"),yLo=o("SqueezeBertTokenizer"),xLo=o(" or "),nX=a("a"),$Lo=o("SqueezeBertTokenizerFast"),kLo=o(" (SqueezeBERT model)"),SLo=l(),Ll=a("li"),U1e=a("strong"),RLo=o("t5"),PLo=o(" \u2014 "),sX=a("a"),BLo=o("T5Tokenizer"),ILo=o(" or "),lX=a("a"),NLo=o("T5TokenizerFast"),qLo=o(" (T5 model)"),jLo=l(),up=a("li"),H1e=a("strong"),DLo=o("tapas"),GLo=o(" \u2014 "),iX=a("a"),OLo=o("TapasTokenizer"),VLo=o(" (TAPAS model)"),XLo=l(),pp=a("li"),J1e=a("strong"),zLo=o("tapex"),QLo=o(" \u2014 "),dX=a("a"),WLo=o("TapexTokenizer"),ULo=o(" (TAPEX model)"),HLo=l(),_p=a("li"),Y1e=a("strong"),JLo=o("transfo-xl"),YLo=o(" \u2014 "),mX=a("a"),ZLo=o("TransfoXLTokenizer"),KLo=o(" (Transformer-XL model)"),eyo=l(),yl=a("li"),Z1e=a("strong"),oyo=o("vilt"),ryo=o(" \u2014 "),cX=a("a"),tyo=o("BertTokenizer"),ayo=o(" or "),fX=a("a"),nyo=o("BertTokenizerFast"),syo=o(" (ViLT model)"),lyo=l(),xl=a("li"),K1e=a("strong"),iyo=o("visual_bert"),dyo=o(" \u2014 "),gX=a("a"),myo=o("BertTokenizer"),cyo=o(" or "),hX=a("a"),fyo=o("BertTokenizerFast"),gyo=o(" (VisualBERT model)"),hyo=l(),bp=a("li"),e2e=a("strong"),uyo=o("wav2vec2"),pyo=o(" \u2014 "),uX=a("a"),_yo=o("Wav2Vec2CTCTokenizer"),byo=o(" (Wav2Vec2 model)"),vyo=l(),vp=a("li"),o2e=a("strong"),Fyo=o("wav2vec2-conformer"),Tyo=o(" \u2014 "),pX=a("a"),Myo=o("Wav2Vec2CTCTokenizer"),Eyo=o(" (Wav2Vec2-Conformer model)"),Cyo=l(),Fp=a("li"),r2e=a("strong"),wyo=o("wav2vec2_phoneme"),Ayo=o(" \u2014 "),_X=a("a"),Lyo=o("Wav2Vec2PhonemeCTCTokenizer"),yyo=o(" (Wav2Vec2Phoneme model)"),xyo=l(),Tp=a("li"),t2e=a("strong"),$yo=o("whisper"),kyo=o(" \u2014 "),bX=a("a"),Syo=o("WhisperTokenizer"),Ryo=o(" (Whisper model)"),Pyo=l(),$l=a("li"),a2e=a("strong"),Byo=o("xclip"),Iyo=o(" \u2014 "),vX=a("a"),Nyo=o("CLIPTokenizer"),qyo=o(" or "),FX=a("a"),jyo=o("CLIPTokenizerFast"),Dyo=o(" (X-CLIP model)"),Gyo=l(),kl=a("li"),n2e=a("strong"),Oyo=o("xglm"),Vyo=o(" \u2014 "),TX=a("a"),Xyo=o("XGLMTokenizer"),zyo=o(" or "),MX=a("a"),Qyo=o("XGLMTokenizerFast"),Wyo=o(" (XGLM model)"),Uyo=l(),Mp=a("li"),s2e=a("strong"),Hyo=o("xlm"),Jyo=o(" \u2014 "),EX=a("a"),Yyo=o("XLMTokenizer"),Zyo=o(" (XLM model)"),Kyo=l(),Ep=a("li"),l2e=a("strong"),e9o=o("xlm-prophetnet"),o9o=o(" \u2014 "),CX=a("a"),r9o=o("XLMProphetNetTokenizer"),t9o=o(" (XLM-ProphetNet model)"),a9o=l(),Sl=a("li"),i2e=a("strong"),n9o=o("xlm-roberta"),s9o=o(" \u2014 "),wX=a("a"),l9o=o("XLMRobertaTokenizer"),i9o=o(" or "),AX=a("a"),d9o=o("XLMRobertaTokenizerFast"),m9o=o(" (XLM-RoBERTa model)"),c9o=l(),Rl=a("li"),d2e=a("strong"),f9o=o("xlm-roberta-xl"),g9o=o(" \u2014 "),LX=a("a"),h9o=o("XLMRobertaTokenizer"),u9o=o(" or "),yX=a("a"),p9o=o("XLMRobertaTokenizerFast"),_9o=o(" (XLM-RoBERTa-XL model)"),b9o=l(),Pl=a("li"),m2e=a("strong"),v9o=o("xlnet"),F9o=o(" \u2014 "),xX=a("a"),T9o=o("XLNetTokenizer"),M9o=o(" or "),$X=a("a"),E9o=o("XLNetTokenizerFast"),C9o=o(" (XLNet model)"),w9o=l(),Bl=a("li"),c2e=a("strong"),A9o=o("yoso"),L9o=o(" \u2014 "),kX=a("a"),y9o=o("AlbertTokenizer"),x9o=o(" or "),SX=a("a"),$9o=o("AlbertTokenizerFast"),k9o=o(" (YOSO model)"),S9o=l(),F(Cp.$$.fragment),R9o=l(),wp=a("div"),F(yk.$$.fragment),P9o=l(),f2e=a("p"),B9o=o("Register a new tokenizer in this mapping."),Nlo=l(),Nd=a("h2"),Ap=a("a"),g2e=a("span"),F(xk.$$.fragment),I9o=l(),h2e=a("span"),N9o=o("AutoFeatureExtractor"),qlo=l(),No=a("div"),F($k.$$.fragment),q9o=l(),kk=a("p"),j9o=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),RX=a("a"),D9o=o("AutoFeatureExtractor.from_pretrained()"),G9o=o(" class method."),O9o=l(),Sk=a("p"),V9o=o("This class cannot be instantiated directly using "),u2e=a("code"),X9o=o("__init__()"),z9o=o(" (throws an error)."),Q9o=l(),eo=a("div"),F(Rk.$$.fragment),W9o=l(),p2e=a("p"),U9o=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),H9o=l(),mn=a("p"),J9o=o("The feature extractor class to instantiate is selected based on the "),_2e=a("code"),Y9o=o("model_type"),Z9o=o(` property of the config object
(either passed as an argument or loaded from `),b2e=a("code"),K9o=o("pretrained_model_name_or_path"),exo=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),v2e=a("code"),oxo=o("pretrained_model_name_or_path"),rxo=o(":"),txo=l(),z=a("ul"),Lp=a("li"),F2e=a("strong"),axo=o("beit"),nxo=o(" \u2014 "),PX=a("a"),sxo=o("BeitFeatureExtractor"),lxo=o(" (BEiT model)"),ixo=l(),yp=a("li"),T2e=a("strong"),dxo=o("clip"),mxo=o(" \u2014 "),BX=a("a"),cxo=o("CLIPFeatureExtractor"),fxo=o(" (CLIP model)"),gxo=l(),xp=a("li"),M2e=a("strong"),hxo=o("clipseg"),uxo=o(" \u2014 "),IX=a("a"),pxo=o("ViTFeatureExtractor"),_xo=o(" (CLIPSeg model)"),bxo=l(),$p=a("li"),E2e=a("strong"),vxo=o("conditional_detr"),Fxo=o(" \u2014 "),NX=a("a"),Txo=o("ConditionalDetrFeatureExtractor"),Mxo=o(" (Conditional DETR model)"),Exo=l(),kp=a("li"),C2e=a("strong"),Cxo=o("convnext"),wxo=o(" \u2014 "),qX=a("a"),Axo=o("ConvNextFeatureExtractor"),Lxo=o(" (ConvNeXT model)"),yxo=l(),Sp=a("li"),w2e=a("strong"),xxo=o("cvt"),$xo=o(" \u2014 "),jX=a("a"),kxo=o("ConvNextFeatureExtractor"),Sxo=o(" (CvT model)"),Rxo=l(),Rp=a("li"),A2e=a("strong"),Pxo=o("data2vec-audio"),Bxo=o(" \u2014 "),DX=a("a"),Ixo=o("Wav2Vec2FeatureExtractor"),Nxo=o(" (Data2VecAudio model)"),qxo=l(),Pp=a("li"),L2e=a("strong"),jxo=o("data2vec-vision"),Dxo=o(" \u2014 "),GX=a("a"),Gxo=o("BeitFeatureExtractor"),Oxo=o(" (Data2VecVision model)"),Vxo=l(),Bp=a("li"),y2e=a("strong"),Xxo=o("deformable_detr"),zxo=o(" \u2014 "),OX=a("a"),Qxo=o("DeformableDetrFeatureExtractor"),Wxo=o(" (Deformable DETR model)"),Uxo=l(),Ip=a("li"),x2e=a("strong"),Hxo=o("deit"),Jxo=o(" \u2014 "),VX=a("a"),Yxo=o("DeiTFeatureExtractor"),Zxo=o(" (DeiT model)"),Kxo=l(),Np=a("li"),$2e=a("strong"),e$o=o("detr"),o$o=o(" \u2014 "),XX=a("a"),r$o=o("DetrFeatureExtractor"),t$o=o(" (DETR model)"),a$o=l(),qp=a("li"),k2e=a("strong"),n$o=o("donut-swin"),s$o=o(" \u2014 "),zX=a("a"),l$o=o("DonutFeatureExtractor"),i$o=o(" (DonutSwin model)"),d$o=l(),jp=a("li"),S2e=a("strong"),m$o=o("dpt"),c$o=o(" \u2014 "),QX=a("a"),f$o=o("DPTFeatureExtractor"),g$o=o(" (DPT model)"),h$o=l(),Dp=a("li"),R2e=a("strong"),u$o=o("flava"),p$o=o(" \u2014 "),WX=a("a"),_$o=o("FlavaFeatureExtractor"),b$o=o(" (FLAVA model)"),v$o=l(),Gp=a("li"),P2e=a("strong"),F$o=o("glpn"),T$o=o(" \u2014 "),UX=a("a"),M$o=o("GLPNFeatureExtractor"),E$o=o(" (GLPN model)"),C$o=l(),Op=a("li"),B2e=a("strong"),w$o=o("groupvit"),A$o=o(" \u2014 "),HX=a("a"),L$o=o("CLIPFeatureExtractor"),y$o=o(" (GroupViT model)"),x$o=l(),Vp=a("li"),I2e=a("strong"),$$o=o("hubert"),k$o=o(" \u2014 "),JX=a("a"),S$o=o("Wav2Vec2FeatureExtractor"),R$o=o(" (Hubert model)"),P$o=l(),Xp=a("li"),N2e=a("strong"),B$o=o("imagegpt"),I$o=o(" \u2014 "),YX=a("a"),N$o=o("ImageGPTFeatureExtractor"),q$o=o(" (ImageGPT model)"),j$o=l(),zp=a("li"),q2e=a("strong"),D$o=o("layoutlmv2"),G$o=o(" \u2014 "),ZX=a("a"),O$o=o("LayoutLMv2FeatureExtractor"),V$o=o(" (LayoutLMv2 model)"),X$o=l(),Qp=a("li"),j2e=a("strong"),z$o=o("layoutlmv3"),Q$o=o(" \u2014 "),KX=a("a"),W$o=o("LayoutLMv3FeatureExtractor"),U$o=o(" (LayoutLMv3 model)"),H$o=l(),Wp=a("li"),D2e=a("strong"),J$o=o("levit"),Y$o=o(" \u2014 "),ez=a("a"),Z$o=o("LevitFeatureExtractor"),K$o=o(" (LeViT model)"),eko=l(),Up=a("li"),G2e=a("strong"),oko=o("maskformer"),rko=o(" \u2014 "),oz=a("a"),tko=o("MaskFormerFeatureExtractor"),ako=o(" (MaskFormer model)"),nko=l(),Hp=a("li"),O2e=a("strong"),sko=o("mctct"),lko=o(" \u2014 "),rz=a("a"),iko=o("MCTCTFeatureExtractor"),dko=o(" (M-CTC-T model)"),mko=l(),Jp=a("li"),V2e=a("strong"),cko=o("mobilevit"),fko=o(" \u2014 "),tz=a("a"),gko=o("MobileViTFeatureExtractor"),hko=o(" (MobileViT model)"),uko=l(),Yp=a("li"),X2e=a("strong"),pko=o("owlvit"),_ko=o(" \u2014 "),az=a("a"),bko=o("OwlViTFeatureExtractor"),vko=o(" (OWL-ViT model)"),Fko=l(),Zp=a("li"),z2e=a("strong"),Tko=o("perceiver"),Mko=o(" \u2014 "),nz=a("a"),Eko=o("PerceiverFeatureExtractor"),Cko=o(" (Perceiver model)"),wko=l(),Kp=a("li"),Q2e=a("strong"),Ako=o("poolformer"),Lko=o(" \u2014 "),sz=a("a"),yko=o("PoolFormerFeatureExtractor"),xko=o(" (PoolFormer model)"),$ko=l(),e_=a("li"),W2e=a("strong"),kko=o("regnet"),Sko=o(" \u2014 "),lz=a("a"),Rko=o("ConvNextFeatureExtractor"),Pko=o(" (RegNet model)"),Bko=l(),o_=a("li"),U2e=a("strong"),Iko=o("resnet"),Nko=o(" \u2014 "),iz=a("a"),qko=o("ConvNextFeatureExtractor"),jko=o(" (ResNet model)"),Dko=l(),r_=a("li"),H2e=a("strong"),Gko=o("segformer"),Oko=o(" \u2014 "),dz=a("a"),Vko=o("SegformerFeatureExtractor"),Xko=o(" (SegFormer model)"),zko=l(),t_=a("li"),J2e=a("strong"),Qko=o("speech_to_text"),Wko=o(" \u2014 "),mz=a("a"),Uko=o("Speech2TextFeatureExtractor"),Hko=o(" (Speech2Text model)"),Jko=l(),a_=a("li"),Y2e=a("strong"),Yko=o("swin"),Zko=o(" \u2014 "),cz=a("a"),Kko=o("ViTFeatureExtractor"),eSo=o(" (Swin Transformer model)"),oSo=l(),n_=a("li"),Z2e=a("strong"),rSo=o("swinv2"),tSo=o(" \u2014 "),fz=a("a"),aSo=o("ViTFeatureExtractor"),nSo=o(" (Swin Transformer V2 model)"),sSo=l(),s_=a("li"),K2e=a("strong"),lSo=o("table-transformer"),iSo=o(" \u2014 "),gz=a("a"),dSo=o("DetrFeatureExtractor"),mSo=o(" (Table Transformer model)"),cSo=l(),l_=a("li"),ebe=a("strong"),fSo=o("van"),gSo=o(" \u2014 "),hz=a("a"),hSo=o("ConvNextFeatureExtractor"),uSo=o(" (VAN model)"),pSo=l(),i_=a("li"),obe=a("strong"),_So=o("videomae"),bSo=o(" \u2014 "),uz=a("a"),vSo=o("VideoMAEFeatureExtractor"),FSo=o(" (VideoMAE model)"),TSo=l(),d_=a("li"),rbe=a("strong"),MSo=o("vilt"),ESo=o(" \u2014 "),pz=a("a"),CSo=o("ViltFeatureExtractor"),wSo=o(" (ViLT model)"),ASo=l(),m_=a("li"),tbe=a("strong"),LSo=o("vit"),ySo=o(" \u2014 "),_z=a("a"),xSo=o("ViTFeatureExtractor"),$So=o(" (ViT model)"),kSo=l(),c_=a("li"),abe=a("strong"),SSo=o("vit_mae"),RSo=o(" \u2014 "),bz=a("a"),PSo=o("ViTFeatureExtractor"),BSo=o(" (ViTMAE model)"),ISo=l(),f_=a("li"),nbe=a("strong"),NSo=o("vit_msn"),qSo=o(" \u2014 "),vz=a("a"),jSo=o("ViTFeatureExtractor"),DSo=o(" (ViTMSN model)"),GSo=l(),g_=a("li"),sbe=a("strong"),OSo=o("wav2vec2"),VSo=o(" \u2014 "),Fz=a("a"),XSo=o("Wav2Vec2FeatureExtractor"),zSo=o(" (Wav2Vec2 model)"),QSo=l(),h_=a("li"),lbe=a("strong"),WSo=o("wav2vec2-conformer"),USo=o(" \u2014 "),Tz=a("a"),HSo=o("Wav2Vec2FeatureExtractor"),JSo=o(" (Wav2Vec2-Conformer model)"),YSo=l(),u_=a("li"),ibe=a("strong"),ZSo=o("whisper"),KSo=o(" \u2014 "),Mz=a("a"),eRo=o("WhisperFeatureExtractor"),oRo=o(" (Whisper model)"),rRo=l(),p_=a("li"),dbe=a("strong"),tRo=o("xclip"),aRo=o(" \u2014 "),Ez=a("a"),nRo=o("CLIPFeatureExtractor"),sRo=o(" (X-CLIP model)"),lRo=l(),__=a("li"),mbe=a("strong"),iRo=o("yolos"),dRo=o(" \u2014 "),Cz=a("a"),mRo=o("YolosFeatureExtractor"),cRo=o(" (YOLOS model)"),fRo=l(),F(b_.$$.fragment),gRo=l(),F(v_.$$.fragment),hRo=l(),F_=a("div"),F(Pk.$$.fragment),uRo=l(),cbe=a("p"),pRo=o("Register a new feature extractor for this class."),jlo=l(),qd=a("h2"),T_=a("a"),fbe=a("span"),F(Bk.$$.fragment),_Ro=l(),gbe=a("span"),bRo=o("AutoImageProcessor"),Dlo=l(),qo=a("div"),F(Ik.$$.fragment),vRo=l(),Nk=a("p"),FRo=o(`This is a generic image processor class that will be instantiated as one of the image processor classes of the
library when created with the `),wz=a("a"),TRo=o("AutoImageProcessor.from_pretrained()"),MRo=o(" class method."),ERo=l(),qk=a("p"),CRo=o("This class cannot be instantiated directly using "),hbe=a("code"),wRo=o("__init__()"),ARo=o(" (throws an error)."),LRo=l(),oo=a("div"),F(jk.$$.fragment),yRo=l(),ube=a("p"),xRo=o("Instantiate one of the image processor classes of the library from a pretrained model vocabulary."),$Ro=l(),cn=a("p"),kRo=o("The image processor class to instantiate is selected based on the "),pbe=a("code"),SRo=o("model_type"),RRo=o(` property of the config object
(either passed as an argument or loaded from `),_be=a("code"),PRo=o("pretrained_model_name_or_path"),BRo=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),bbe=a("code"),IRo=o("pretrained_model_name_or_path"),NRo=o(":"),qRo=l(),re=a("ul"),M_=a("li"),vbe=a("strong"),jRo=o("beit"),DRo=o(" \u2014 "),Az=a("a"),GRo=o("BeitImageProcessor"),ORo=o(" (BEiT model)"),VRo=l(),E_=a("li"),Fbe=a("strong"),XRo=o("clip"),zRo=o(" \u2014 "),Lz=a("a"),QRo=o("CLIPImageProcessor"),WRo=o(" (CLIP model)"),URo=l(),C_=a("li"),Tbe=a("strong"),HRo=o("convnext"),JRo=o(" \u2014 "),yz=a("a"),YRo=o("ConvNextImageProcessor"),ZRo=o(" (ConvNeXT model)"),KRo=l(),w_=a("li"),Mbe=a("strong"),ePo=o("cvt"),oPo=o(" \u2014 "),xz=a("a"),rPo=o("ConvNextImageProcessor"),tPo=o(" (CvT model)"),aPo=l(),A_=a("li"),Ebe=a("strong"),nPo=o("data2vec-vision"),sPo=o(" \u2014 "),$z=a("a"),lPo=o("BeitImageProcessor"),iPo=o(" (Data2VecVision model)"),dPo=l(),L_=a("li"),Cbe=a("strong"),mPo=o("deit"),cPo=o(" \u2014 "),kz=a("a"),fPo=o("DeiTImageProcessor"),gPo=o(" (DeiT model)"),hPo=l(),y_=a("li"),wbe=a("strong"),uPo=o("dpt"),pPo=o(" \u2014 "),Sz=a("a"),_Po=o("DPTImageProcessor"),bPo=o(" (DPT model)"),vPo=l(),x_=a("li"),Abe=a("strong"),FPo=o("flava"),TPo=o(" \u2014 "),Rz=a("a"),MPo=o("FlavaImageProcessor"),EPo=o(" (FLAVA model)"),CPo=l(),$_=a("li"),Lbe=a("strong"),wPo=o("glpn"),APo=o(" \u2014 "),Pz=a("a"),LPo=o("GLPNImageProcessor"),yPo=o(" (GLPN model)"),xPo=l(),k_=a("li"),ybe=a("strong"),$Po=o("groupvit"),kPo=o(" \u2014 "),Bz=a("a"),SPo=o("CLIPImageProcessor"),RPo=o(" (GroupViT model)"),PPo=l(),S_=a("li"),xbe=a("strong"),BPo=o("imagegpt"),IPo=o(" \u2014 "),Iz=a("a"),NPo=o("ImageGPTImageProcessor"),qPo=o(" (ImageGPT model)"),jPo=l(),R_=a("li"),$be=a("strong"),DPo=o("layoutlmv2"),GPo=o(" \u2014 "),Nz=a("a"),OPo=o("LayoutLMv2ImageProcessor"),VPo=o(" (LayoutLMv2 model)"),XPo=l(),P_=a("li"),kbe=a("strong"),zPo=o("layoutlmv3"),QPo=o(" \u2014 "),qz=a("a"),WPo=o("LayoutLMv3ImageProcessor"),UPo=o(" (LayoutLMv3 model)"),HPo=l(),B_=a("li"),Sbe=a("strong"),JPo=o("levit"),YPo=o(" \u2014 "),jz=a("a"),ZPo=o("LevitImageProcessor"),KPo=o(" (LeViT model)"),eBo=l(),I_=a("li"),Rbe=a("strong"),oBo=o("mobilevit"),rBo=o(" \u2014 "),Dz=a("a"),tBo=o("MobileViTImageProcessor"),aBo=o(" (MobileViT model)"),nBo=l(),N_=a("li"),Pbe=a("strong"),sBo=o("perceiver"),lBo=o(" \u2014 "),Gz=a("a"),iBo=o("PerceiverImageProcessor"),dBo=o(" (Perceiver model)"),mBo=l(),q_=a("li"),Bbe=a("strong"),cBo=o("poolformer"),fBo=o(" \u2014 "),Oz=a("a"),gBo=o("PoolFormerImageProcessor"),hBo=o(" (PoolFormer model)"),uBo=l(),j_=a("li"),Ibe=a("strong"),pBo=o("regnet"),_Bo=o(" \u2014 "),Vz=a("a"),bBo=o("ConvNextImageProcessor"),vBo=o(" (RegNet model)"),FBo=l(),D_=a("li"),Nbe=a("strong"),TBo=o("resnet"),MBo=o(" \u2014 "),Xz=a("a"),EBo=o("ConvNextImageProcessor"),CBo=o(" (ResNet model)"),wBo=l(),G_=a("li"),qbe=a("strong"),ABo=o("segformer"),LBo=o(" \u2014 "),zz=a("a"),yBo=o("SegformerImageProcessor"),xBo=o(" (SegFormer model)"),$Bo=l(),O_=a("li"),jbe=a("strong"),kBo=o("swin"),SBo=o(" \u2014 "),Qz=a("a"),RBo=o("ViTImageProcessor"),PBo=o(" (Swin Transformer model)"),BBo=l(),V_=a("li"),Dbe=a("strong"),IBo=o("swinv2"),NBo=o(" \u2014 "),Wz=a("a"),qBo=o("ViTImageProcessor"),jBo=o(" (Swin Transformer V2 model)"),DBo=l(),X_=a("li"),Gbe=a("strong"),GBo=o("van"),OBo=o(" \u2014 "),Uz=a("a"),VBo=o("ConvNextImageProcessor"),XBo=o(" (VAN model)"),zBo=l(),z_=a("li"),Obe=a("strong"),QBo=o("videomae"),WBo=o(" \u2014 "),Hz=a("a"),UBo=o("VideoMAEImageProcessor"),HBo=o(" (VideoMAE model)"),JBo=l(),Q_=a("li"),Vbe=a("strong"),YBo=o("vilt"),ZBo=o(" \u2014 "),Jz=a("a"),KBo=o("ViltImageProcessor"),eIo=o(" (ViLT model)"),oIo=l(),W_=a("li"),Xbe=a("strong"),rIo=o("vit"),tIo=o(" \u2014 "),Yz=a("a"),aIo=o("ViTImageProcessor"),nIo=o(" (ViT model)"),sIo=l(),U_=a("li"),zbe=a("strong"),lIo=o("vit_mae"),iIo=o(" \u2014 "),Zz=a("a"),dIo=o("ViTImageProcessor"),mIo=o(" (ViTMAE model)"),cIo=l(),H_=a("li"),Qbe=a("strong"),fIo=o("vit_msn"),gIo=o(" \u2014 "),Kz=a("a"),hIo=o("ViTImageProcessor"),uIo=o(" (ViTMSN model)"),pIo=l(),J_=a("li"),Wbe=a("strong"),_Io=o("xclip"),bIo=o(" \u2014 "),eQ=a("a"),vIo=o("CLIPImageProcessor"),FIo=o(" (X-CLIP model)"),TIo=l(),F(Y_.$$.fragment),MIo=l(),F(Z_.$$.fragment),EIo=l(),K_=a("div"),F(Dk.$$.fragment),CIo=l(),Ube=a("p"),wIo=o("Register a new image processor for this class."),Glo=l(),jd=a("h2"),e1=a("a"),Hbe=a("span"),F(Gk.$$.fragment),AIo=l(),Jbe=a("span"),LIo=o("AutoProcessor"),Olo=l(),jo=a("div"),F(Ok.$$.fragment),yIo=l(),Vk=a("p"),xIo=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),oQ=a("a"),$Io=o("AutoProcessor.from_pretrained()"),kIo=o(" class method."),SIo=l(),Xk=a("p"),RIo=o("This class cannot be instantiated directly using "),Ybe=a("code"),PIo=o("__init__()"),BIo=o(" (throws an error)."),IIo=l(),ro=a("div"),F(zk.$$.fragment),NIo=l(),Zbe=a("p"),qIo=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),jIo=l(),Dd=a("p"),DIo=o("The processor class to instantiate is selected based on the "),Kbe=a("code"),GIo=o("model_type"),OIo=o(` property of the config object (either
passed as an argument or loaded from `),eve=a("code"),VIo=o("pretrained_model_name_or_path"),XIo=o(" if possible):"),zIo=l(),ie=a("ul"),o1=a("li"),ove=a("strong"),QIo=o("clip"),WIo=o(" \u2014 "),rQ=a("a"),UIo=o("CLIPProcessor"),HIo=o(" (CLIP model)"),JIo=l(),r1=a("li"),rve=a("strong"),YIo=o("clipseg"),ZIo=o(" \u2014 "),tQ=a("a"),KIo=o("CLIPSegProcessor"),eNo=o(" (CLIPSeg model)"),oNo=l(),t1=a("li"),tve=a("strong"),rNo=o("flava"),tNo=o(" \u2014 "),aQ=a("a"),aNo=o("FlavaProcessor"),nNo=o(" (FLAVA model)"),sNo=l(),a1=a("li"),ave=a("strong"),lNo=o("groupvit"),iNo=o(" \u2014 "),nQ=a("a"),dNo=o("CLIPProcessor"),mNo=o(" (GroupViT model)"),cNo=l(),n1=a("li"),nve=a("strong"),fNo=o("layoutlmv2"),gNo=o(" \u2014 "),sQ=a("a"),hNo=o("LayoutLMv2Processor"),uNo=o(" (LayoutLMv2 model)"),pNo=l(),s1=a("li"),sve=a("strong"),_No=o("layoutlmv3"),bNo=o(" \u2014 "),lQ=a("a"),vNo=o("LayoutLMv3Processor"),FNo=o(" (LayoutLMv3 model)"),TNo=l(),l1=a("li"),lve=a("strong"),MNo=o("layoutxlm"),ENo=o(" \u2014 "),iQ=a("a"),CNo=o("LayoutXLMProcessor"),wNo=o(" (LayoutXLM model)"),ANo=l(),i1=a("li"),ive=a("strong"),LNo=o("markuplm"),yNo=o(" \u2014 "),dQ=a("a"),xNo=o("MarkupLMProcessor"),$No=o(" (MarkupLM model)"),kNo=l(),d1=a("li"),dve=a("strong"),SNo=o("owlvit"),RNo=o(" \u2014 "),mQ=a("a"),PNo=o("OwlViTProcessor"),BNo=o(" (OWL-ViT model)"),INo=l(),m1=a("li"),mve=a("strong"),NNo=o("sew"),qNo=o(" \u2014 "),cQ=a("a"),jNo=o("Wav2Vec2Processor"),DNo=o(" (SEW model)"),GNo=l(),c1=a("li"),cve=a("strong"),ONo=o("sew-d"),VNo=o(" \u2014 "),fQ=a("a"),XNo=o("Wav2Vec2Processor"),zNo=o(" (SEW-D model)"),QNo=l(),f1=a("li"),fve=a("strong"),WNo=o("speech_to_text"),UNo=o(" \u2014 "),gQ=a("a"),HNo=o("Speech2TextProcessor"),JNo=o(" (Speech2Text model)"),YNo=l(),g1=a("li"),gve=a("strong"),ZNo=o("speech_to_text_2"),KNo=o(" \u2014 "),hQ=a("a"),eqo=o("Speech2Text2Processor"),oqo=o(" (Speech2Text2 model)"),rqo=l(),h1=a("li"),hve=a("strong"),tqo=o("trocr"),aqo=o(" \u2014 "),uQ=a("a"),nqo=o("TrOCRProcessor"),sqo=o(" (TrOCR model)"),lqo=l(),u1=a("li"),uve=a("strong"),iqo=o("unispeech"),dqo=o(" \u2014 "),pQ=a("a"),mqo=o("Wav2Vec2Processor"),cqo=o(" (UniSpeech model)"),fqo=l(),p1=a("li"),pve=a("strong"),gqo=o("unispeech-sat"),hqo=o(" \u2014 "),_Q=a("a"),uqo=o("Wav2Vec2Processor"),pqo=o(" (UniSpeechSat model)"),_qo=l(),_1=a("li"),_ve=a("strong"),bqo=o("vilt"),vqo=o(" \u2014 "),bQ=a("a"),Fqo=o("ViltProcessor"),Tqo=o(" (ViLT model)"),Mqo=l(),b1=a("li"),bve=a("strong"),Eqo=o("vision-text-dual-encoder"),Cqo=o(" \u2014 "),vQ=a("a"),wqo=o("VisionTextDualEncoderProcessor"),Aqo=o(" (VisionTextDualEncoder model)"),Lqo=l(),v1=a("li"),vve=a("strong"),yqo=o("wav2vec2"),xqo=o(" \u2014 "),FQ=a("a"),$qo=o("Wav2Vec2Processor"),kqo=o(" (Wav2Vec2 model)"),Sqo=l(),F1=a("li"),Fve=a("strong"),Rqo=o("wav2vec2-conformer"),Pqo=o(" \u2014 "),TQ=a("a"),Bqo=o("Wav2Vec2Processor"),Iqo=o(" (Wav2Vec2-Conformer model)"),Nqo=l(),T1=a("li"),Tve=a("strong"),qqo=o("wavlm"),jqo=o(" \u2014 "),MQ=a("a"),Dqo=o("Wav2Vec2Processor"),Gqo=o(" (WavLM model)"),Oqo=l(),M1=a("li"),Mve=a("strong"),Vqo=o("whisper"),Xqo=o(" \u2014 "),EQ=a("a"),zqo=o("WhisperProcessor"),Qqo=o(" (Whisper model)"),Wqo=l(),E1=a("li"),Eve=a("strong"),Uqo=o("xclip"),Hqo=o(" \u2014 "),CQ=a("a"),Jqo=o("XCLIPProcessor"),Yqo=o(" (X-CLIP model)"),Zqo=l(),F(C1.$$.fragment),Kqo=l(),F(w1.$$.fragment),ejo=l(),A1=a("div"),F(Qk.$$.fragment),ojo=l(),Cve=a("p"),rjo=o("Register a new processor for this class."),Vlo=l(),Gd=a("h2"),L1=a("a"),wve=a("span"),F(Wk.$$.fragment),tjo=l(),Ave=a("span"),ajo=o("AutoModel"),Xlo=l(),Do=a("div"),F(Uk.$$.fragment),njo=l(),Od=a("p"),sjo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),wQ=a("a"),ljo=o("from_pretrained()"),ijo=o(" class method or the "),AQ=a("a"),djo=o("from_config()"),mjo=o(` class
method.`),cjo=l(),Hk=a("p"),fjo=o("This class cannot be instantiated directly using "),Lve=a("code"),gjo=o("__init__()"),hjo=o(" (throws an error)."),ujo=l(),At=a("div"),F(Jk.$$.fragment),pjo=l(),yve=a("p"),_jo=o("Instantiates one of the base model classes of the library from a configuration."),bjo=l(),Vd=a("p"),vjo=o(`Note:
Loading a model from its configuration file does `),xve=a("strong"),Fjo=o("not"),Tjo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LQ=a("a"),Mjo=o("from_pretrained()"),Ejo=o(" to load the model weights."),Cjo=l(),F(y1.$$.fragment),wjo=l(),to=a("div"),F(Yk.$$.fragment),Ajo=l(),$ve=a("p"),Ljo=o("Instantiate one of the base model classes of the library from a pretrained model."),yjo=l(),fn=a("p"),xjo=o("The model class to instantiate is selected based on the "),kve=a("code"),$jo=o("model_type"),kjo=o(` property of the config object (either
passed as an argument or loaded from `),Sve=a("code"),Sjo=o("pretrained_model_name_or_path"),Rjo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rve=a("code"),Pjo=o("pretrained_model_name_or_path"),Bjo=o(":"),Ijo=l(),y=a("ul"),x1=a("li"),Pve=a("strong"),Njo=o("albert"),qjo=o(" \u2014 "),yQ=a("a"),jjo=o("AlbertModel"),Djo=o(" (ALBERT model)"),Gjo=l(),$1=a("li"),Bve=a("strong"),Ojo=o("bart"),Vjo=o(" \u2014 "),xQ=a("a"),Xjo=o("BartModel"),zjo=o(" (BART model)"),Qjo=l(),k1=a("li"),Ive=a("strong"),Wjo=o("beit"),Ujo=o(" \u2014 "),$Q=a("a"),Hjo=o("BeitModel"),Jjo=o(" (BEiT model)"),Yjo=l(),S1=a("li"),Nve=a("strong"),Zjo=o("bert"),Kjo=o(" \u2014 "),kQ=a("a"),eDo=o("BertModel"),oDo=o(" (BERT model)"),rDo=l(),R1=a("li"),qve=a("strong"),tDo=o("bert-generation"),aDo=o(" \u2014 "),SQ=a("a"),nDo=o("BertGenerationEncoder"),sDo=o(" (Bert Generation model)"),lDo=l(),P1=a("li"),jve=a("strong"),iDo=o("big_bird"),dDo=o(" \u2014 "),RQ=a("a"),mDo=o("BigBirdModel"),cDo=o(" (BigBird model)"),fDo=l(),B1=a("li"),Dve=a("strong"),gDo=o("bigbird_pegasus"),hDo=o(" \u2014 "),PQ=a("a"),uDo=o("BigBirdPegasusModel"),pDo=o(" (BigBird-Pegasus model)"),_Do=l(),I1=a("li"),Gve=a("strong"),bDo=o("blenderbot"),vDo=o(" \u2014 "),BQ=a("a"),FDo=o("BlenderbotModel"),TDo=o(" (Blenderbot model)"),MDo=l(),N1=a("li"),Ove=a("strong"),EDo=o("blenderbot-small"),CDo=o(" \u2014 "),IQ=a("a"),wDo=o("BlenderbotSmallModel"),ADo=o(" (BlenderbotSmall model)"),LDo=l(),q1=a("li"),Vve=a("strong"),yDo=o("bloom"),xDo=o(" \u2014 "),NQ=a("a"),$Do=o("BloomModel"),kDo=o(" (BLOOM model)"),SDo=l(),j1=a("li"),Xve=a("strong"),RDo=o("camembert"),PDo=o(" \u2014 "),qQ=a("a"),BDo=o("CamembertModel"),IDo=o(" (CamemBERT model)"),NDo=l(),D1=a("li"),zve=a("strong"),qDo=o("canine"),jDo=o(" \u2014 "),jQ=a("a"),DDo=o("CanineModel"),GDo=o(" (CANINE model)"),ODo=l(),G1=a("li"),Qve=a("strong"),VDo=o("clip"),XDo=o(" \u2014 "),DQ=a("a"),zDo=o("CLIPModel"),QDo=o(" (CLIP model)"),WDo=l(),O1=a("li"),Wve=a("strong"),UDo=o("clipseg"),HDo=o(" \u2014 "),GQ=a("a"),JDo=o("CLIPSegModel"),YDo=o(" (CLIPSeg model)"),ZDo=l(),V1=a("li"),Uve=a("strong"),KDo=o("codegen"),eGo=o(" \u2014 "),OQ=a("a"),oGo=o("CodeGenModel"),rGo=o(" (CodeGen model)"),tGo=l(),X1=a("li"),Hve=a("strong"),aGo=o("conditional_detr"),nGo=o(" \u2014 "),VQ=a("a"),sGo=o("ConditionalDetrModel"),lGo=o(" (Conditional DETR model)"),iGo=l(),z1=a("li"),Jve=a("strong"),dGo=o("convbert"),mGo=o(" \u2014 "),XQ=a("a"),cGo=o("ConvBertModel"),fGo=o(" (ConvBERT model)"),gGo=l(),Q1=a("li"),Yve=a("strong"),hGo=o("convnext"),uGo=o(" \u2014 "),zQ=a("a"),pGo=o("ConvNextModel"),_Go=o(" (ConvNeXT model)"),bGo=l(),W1=a("li"),Zve=a("strong"),vGo=o("ctrl"),FGo=o(" \u2014 "),QQ=a("a"),TGo=o("CTRLModel"),MGo=o(" (CTRL model)"),EGo=l(),U1=a("li"),Kve=a("strong"),CGo=o("cvt"),wGo=o(" \u2014 "),WQ=a("a"),AGo=o("CvtModel"),LGo=o(" (CvT model)"),yGo=l(),H1=a("li"),eFe=a("strong"),xGo=o("data2vec-audio"),$Go=o(" \u2014 "),UQ=a("a"),kGo=o("Data2VecAudioModel"),SGo=o(" (Data2VecAudio model)"),RGo=l(),J1=a("li"),oFe=a("strong"),PGo=o("data2vec-text"),BGo=o(" \u2014 "),HQ=a("a"),IGo=o("Data2VecTextModel"),NGo=o(" (Data2VecText model)"),qGo=l(),Y1=a("li"),rFe=a("strong"),jGo=o("data2vec-vision"),DGo=o(" \u2014 "),JQ=a("a"),GGo=o("Data2VecVisionModel"),OGo=o(" (Data2VecVision model)"),VGo=l(),Z1=a("li"),tFe=a("strong"),XGo=o("deberta"),zGo=o(" \u2014 "),YQ=a("a"),QGo=o("DebertaModel"),WGo=o(" (DeBERTa model)"),UGo=l(),K1=a("li"),aFe=a("strong"),HGo=o("deberta-v2"),JGo=o(" \u2014 "),ZQ=a("a"),YGo=o("DebertaV2Model"),ZGo=o(" (DeBERTa-v2 model)"),KGo=l(),e2=a("li"),nFe=a("strong"),eOo=o("decision_transformer"),oOo=o(" \u2014 "),KQ=a("a"),rOo=o("DecisionTransformerModel"),tOo=o(" (Decision Transformer model)"),aOo=l(),o2=a("li"),sFe=a("strong"),nOo=o("deformable_detr"),sOo=o(" \u2014 "),eW=a("a"),lOo=o("DeformableDetrModel"),iOo=o(" (Deformable DETR model)"),dOo=l(),r2=a("li"),lFe=a("strong"),mOo=o("deit"),cOo=o(" \u2014 "),oW=a("a"),fOo=o("DeiTModel"),gOo=o(" (DeiT model)"),hOo=l(),t2=a("li"),iFe=a("strong"),uOo=o("detr"),pOo=o(" \u2014 "),rW=a("a"),_Oo=o("DetrModel"),bOo=o(" (DETR model)"),vOo=l(),a2=a("li"),dFe=a("strong"),FOo=o("distilbert"),TOo=o(" \u2014 "),tW=a("a"),MOo=o("DistilBertModel"),EOo=o(" (DistilBERT model)"),COo=l(),n2=a("li"),mFe=a("strong"),wOo=o("donut-swin"),AOo=o(" \u2014 "),aW=a("a"),LOo=o("DonutSwinModel"),yOo=o(" (DonutSwin model)"),xOo=l(),s2=a("li"),cFe=a("strong"),$Oo=o("dpr"),kOo=o(" \u2014 "),nW=a("a"),SOo=o("DPRQuestionEncoder"),ROo=o(" (DPR model)"),POo=l(),l2=a("li"),fFe=a("strong"),BOo=o("dpt"),IOo=o(" \u2014 "),sW=a("a"),NOo=o("DPTModel"),qOo=o(" (DPT model)"),jOo=l(),i2=a("li"),gFe=a("strong"),DOo=o("electra"),GOo=o(" \u2014 "),lW=a("a"),OOo=o("ElectraModel"),VOo=o(" (ELECTRA model)"),XOo=l(),d2=a("li"),hFe=a("strong"),zOo=o("ernie"),QOo=o(" \u2014 "),iW=a("a"),WOo=o("ErnieModel"),UOo=o(" (ERNIE model)"),HOo=l(),m2=a("li"),uFe=a("strong"),JOo=o("esm"),YOo=o(" \u2014 "),dW=a("a"),ZOo=o("EsmModel"),KOo=o(" (ESM model)"),eVo=l(),c2=a("li"),pFe=a("strong"),oVo=o("flaubert"),rVo=o(" \u2014 "),mW=a("a"),tVo=o("FlaubertModel"),aVo=o(" (FlauBERT model)"),nVo=l(),f2=a("li"),_Fe=a("strong"),sVo=o("flava"),lVo=o(" \u2014 "),cW=a("a"),iVo=o("FlavaModel"),dVo=o(" (FLAVA model)"),mVo=l(),g2=a("li"),bFe=a("strong"),cVo=o("fnet"),fVo=o(" \u2014 "),fW=a("a"),gVo=o("FNetModel"),hVo=o(" (FNet model)"),uVo=l(),h2=a("li"),vFe=a("strong"),pVo=o("fsmt"),_Vo=o(" \u2014 "),gW=a("a"),bVo=o("FSMTModel"),vVo=o(" (FairSeq Machine-Translation model)"),FVo=l(),Il=a("li"),FFe=a("strong"),TVo=o("funnel"),MVo=o(" \u2014 "),hW=a("a"),EVo=o("FunnelModel"),CVo=o(" or "),uW=a("a"),wVo=o("FunnelBaseModel"),AVo=o(" (Funnel Transformer model)"),LVo=l(),u2=a("li"),TFe=a("strong"),yVo=o("glpn"),xVo=o(" \u2014 "),pW=a("a"),$Vo=o("GLPNModel"),kVo=o(" (GLPN model)"),SVo=l(),p2=a("li"),MFe=a("strong"),RVo=o("gpt2"),PVo=o(" \u2014 "),_W=a("a"),BVo=o("GPT2Model"),IVo=o(" (OpenAI GPT-2 model)"),NVo=l(),_2=a("li"),EFe=a("strong"),qVo=o("gpt_neo"),jVo=o(" \u2014 "),bW=a("a"),DVo=o("GPTNeoModel"),GVo=o(" (GPT Neo model)"),OVo=l(),b2=a("li"),CFe=a("strong"),VVo=o("gpt_neox"),XVo=o(" \u2014 "),vW=a("a"),zVo=o("GPTNeoXModel"),QVo=o(" (GPT NeoX model)"),WVo=l(),v2=a("li"),wFe=a("strong"),UVo=o("gpt_neox_japanese"),HVo=o(" \u2014 "),FW=a("a"),JVo=o("GPTNeoXJapaneseModel"),YVo=o(" (GPT NeoX Japanese model)"),ZVo=l(),F2=a("li"),AFe=a("strong"),KVo=o("gptj"),eXo=o(" \u2014 "),TW=a("a"),oXo=o("GPTJModel"),rXo=o(" (GPT-J model)"),tXo=l(),T2=a("li"),LFe=a("strong"),aXo=o("groupvit"),nXo=o(" \u2014 "),MW=a("a"),sXo=o("GroupViTModel"),lXo=o(" (GroupViT model)"),iXo=l(),M2=a("li"),yFe=a("strong"),dXo=o("hubert"),mXo=o(" \u2014 "),EW=a("a"),cXo=o("HubertModel"),fXo=o(" (Hubert model)"),gXo=l(),E2=a("li"),xFe=a("strong"),hXo=o("ibert"),uXo=o(" \u2014 "),CW=a("a"),pXo=o("IBertModel"),_Xo=o(" (I-BERT model)"),bXo=l(),C2=a("li"),$Fe=a("strong"),vXo=o("imagegpt"),FXo=o(" \u2014 "),wW=a("a"),TXo=o("ImageGPTModel"),MXo=o(" (ImageGPT model)"),EXo=l(),w2=a("li"),kFe=a("strong"),CXo=o("jukebox"),wXo=o(" \u2014 "),AW=a("a"),AXo=o("JukeboxModel"),LXo=o(" (Jukebox model)"),yXo=l(),A2=a("li"),SFe=a("strong"),xXo=o("layoutlm"),$Xo=o(" \u2014 "),LW=a("a"),kXo=o("LayoutLMModel"),SXo=o(" (LayoutLM model)"),RXo=l(),L2=a("li"),RFe=a("strong"),PXo=o("layoutlmv2"),BXo=o(" \u2014 "),yW=a("a"),IXo=o("LayoutLMv2Model"),NXo=o(" (LayoutLMv2 model)"),qXo=l(),y2=a("li"),PFe=a("strong"),jXo=o("layoutlmv3"),DXo=o(" \u2014 "),xW=a("a"),GXo=o("LayoutLMv3Model"),OXo=o(" (LayoutLMv3 model)"),VXo=l(),x2=a("li"),BFe=a("strong"),XXo=o("led"),zXo=o(" \u2014 "),$W=a("a"),QXo=o("LEDModel"),WXo=o(" (LED model)"),UXo=l(),$2=a("li"),IFe=a("strong"),HXo=o("levit"),JXo=o(" \u2014 "),kW=a("a"),YXo=o("LevitModel"),ZXo=o(" (LeViT model)"),KXo=l(),k2=a("li"),NFe=a("strong"),ezo=o("lilt"),ozo=o(" \u2014 "),SW=a("a"),rzo=o("LiltModel"),tzo=o(" (LiLT model)"),azo=l(),S2=a("li"),qFe=a("strong"),nzo=o("longformer"),szo=o(" \u2014 "),RW=a("a"),lzo=o("LongformerModel"),izo=o(" (Longformer model)"),dzo=l(),R2=a("li"),jFe=a("strong"),mzo=o("longt5"),czo=o(" \u2014 "),PW=a("a"),fzo=o("LongT5Model"),gzo=o(" (LongT5 model)"),hzo=l(),P2=a("li"),DFe=a("strong"),uzo=o("luke"),pzo=o(" \u2014 "),BW=a("a"),_zo=o("LukeModel"),bzo=o(" (LUKE model)"),vzo=l(),B2=a("li"),GFe=a("strong"),Fzo=o("lxmert"),Tzo=o(" \u2014 "),IW=a("a"),Mzo=o("LxmertModel"),Ezo=o(" (LXMERT model)"),Czo=l(),I2=a("li"),OFe=a("strong"),wzo=o("m2m_100"),Azo=o(" \u2014 "),NW=a("a"),Lzo=o("M2M100Model"),yzo=o(" (M2M100 model)"),xzo=l(),N2=a("li"),VFe=a("strong"),$zo=o("marian"),kzo=o(" \u2014 "),qW=a("a"),Szo=o("MarianModel"),Rzo=o(" (Marian model)"),Pzo=l(),q2=a("li"),XFe=a("strong"),Bzo=o("markuplm"),Izo=o(" \u2014 "),jW=a("a"),Nzo=o("MarkupLMModel"),qzo=o(" (MarkupLM model)"),jzo=l(),j2=a("li"),zFe=a("strong"),Dzo=o("maskformer"),Gzo=o(" \u2014 "),DW=a("a"),Ozo=o("MaskFormerModel"),Vzo=o(" (MaskFormer model)"),Xzo=l(),D2=a("li"),QFe=a("strong"),zzo=o("mbart"),Qzo=o(" \u2014 "),GW=a("a"),Wzo=o("MBartModel"),Uzo=o(" (mBART model)"),Hzo=l(),G2=a("li"),WFe=a("strong"),Jzo=o("mctct"),Yzo=o(" \u2014 "),OW=a("a"),Zzo=o("MCTCTModel"),Kzo=o(" (M-CTC-T model)"),eQo=l(),O2=a("li"),UFe=a("strong"),oQo=o("megatron-bert"),rQo=o(" \u2014 "),VW=a("a"),tQo=o("MegatronBertModel"),aQo=o(" (Megatron-BERT model)"),nQo=l(),V2=a("li"),HFe=a("strong"),sQo=o("mobilebert"),lQo=o(" \u2014 "),XW=a("a"),iQo=o("MobileBertModel"),dQo=o(" (MobileBERT model)"),mQo=l(),X2=a("li"),JFe=a("strong"),cQo=o("mobilevit"),fQo=o(" \u2014 "),zW=a("a"),gQo=o("MobileViTModel"),hQo=o(" (MobileViT model)"),uQo=l(),z2=a("li"),YFe=a("strong"),pQo=o("mpnet"),_Qo=o(" \u2014 "),QW=a("a"),bQo=o("MPNetModel"),vQo=o(" (MPNet model)"),FQo=l(),Q2=a("li"),ZFe=a("strong"),TQo=o("mt5"),MQo=o(" \u2014 "),WW=a("a"),EQo=o("MT5Model"),CQo=o(" (MT5 model)"),wQo=l(),W2=a("li"),KFe=a("strong"),AQo=o("mvp"),LQo=o(" \u2014 "),UW=a("a"),yQo=o("MvpModel"),xQo=o(" (MVP model)"),$Qo=l(),U2=a("li"),eTe=a("strong"),kQo=o("nezha"),SQo=o(" \u2014 "),HW=a("a"),RQo=o("NezhaModel"),PQo=o(" (Nezha model)"),BQo=l(),H2=a("li"),oTe=a("strong"),IQo=o("nllb"),NQo=o(" \u2014 "),JW=a("a"),qQo=o("M2M100Model"),jQo=o(" (NLLB model)"),DQo=l(),J2=a("li"),rTe=a("strong"),GQo=o("nystromformer"),OQo=o(" \u2014 "),YW=a("a"),VQo=o("NystromformerModel"),XQo=o(" (Nystr\xF6mformer model)"),zQo=l(),Y2=a("li"),tTe=a("strong"),QQo=o("openai-gpt"),WQo=o(" \u2014 "),ZW=a("a"),UQo=o("OpenAIGPTModel"),HQo=o(" (OpenAI GPT model)"),JQo=l(),Z2=a("li"),aTe=a("strong"),YQo=o("opt"),ZQo=o(" \u2014 "),KW=a("a"),KQo=o("OPTModel"),eWo=o(" (OPT model)"),oWo=l(),K2=a("li"),nTe=a("strong"),rWo=o("owlvit"),tWo=o(" \u2014 "),eU=a("a"),aWo=o("OwlViTModel"),nWo=o(" (OWL-ViT model)"),sWo=l(),eb=a("li"),sTe=a("strong"),lWo=o("pegasus"),iWo=o(" \u2014 "),oU=a("a"),dWo=o("PegasusModel"),mWo=o(" (Pegasus model)"),cWo=l(),ob=a("li"),lTe=a("strong"),fWo=o("pegasus_x"),gWo=o(" \u2014 "),rU=a("a"),hWo=o("PegasusXModel"),uWo=o(" (PEGASUS-X model)"),pWo=l(),rb=a("li"),iTe=a("strong"),_Wo=o("perceiver"),bWo=o(" \u2014 "),tU=a("a"),vWo=o("PerceiverModel"),FWo=o(" (Perceiver model)"),TWo=l(),tb=a("li"),dTe=a("strong"),MWo=o("plbart"),EWo=o(" \u2014 "),aU=a("a"),CWo=o("PLBartModel"),wWo=o(" (PLBart model)"),AWo=l(),ab=a("li"),mTe=a("strong"),LWo=o("poolformer"),yWo=o(" \u2014 "),nU=a("a"),xWo=o("PoolFormerModel"),$Wo=o(" (PoolFormer model)"),kWo=l(),nb=a("li"),cTe=a("strong"),SWo=o("prophetnet"),RWo=o(" \u2014 "),sU=a("a"),PWo=o("ProphetNetModel"),BWo=o(" (ProphetNet model)"),IWo=l(),sb=a("li"),fTe=a("strong"),NWo=o("qdqbert"),qWo=o(" \u2014 "),lU=a("a"),jWo=o("QDQBertModel"),DWo=o(" (QDQBert model)"),GWo=l(),lb=a("li"),gTe=a("strong"),OWo=o("reformer"),VWo=o(" \u2014 "),iU=a("a"),XWo=o("ReformerModel"),zWo=o(" (Reformer model)"),QWo=l(),ib=a("li"),hTe=a("strong"),WWo=o("regnet"),UWo=o(" \u2014 "),dU=a("a"),HWo=o("RegNetModel"),JWo=o(" (RegNet model)"),YWo=l(),db=a("li"),uTe=a("strong"),ZWo=o("rembert"),KWo=o(" \u2014 "),mU=a("a"),eUo=o("RemBertModel"),oUo=o(" (RemBERT model)"),rUo=l(),mb=a("li"),pTe=a("strong"),tUo=o("resnet"),aUo=o(" \u2014 "),cU=a("a"),nUo=o("ResNetModel"),sUo=o(" (ResNet model)"),lUo=l(),cb=a("li"),_Te=a("strong"),iUo=o("retribert"),dUo=o(" \u2014 "),fU=a("a"),mUo=o("RetriBertModel"),cUo=o(" (RetriBERT model)"),fUo=l(),fb=a("li"),bTe=a("strong"),gUo=o("roberta"),hUo=o(" \u2014 "),gU=a("a"),uUo=o("RobertaModel"),pUo=o(" (RoBERTa model)"),_Uo=l(),gb=a("li"),vTe=a("strong"),bUo=o("roc_bert"),vUo=o(" \u2014 "),hU=a("a"),FUo=o("RoCBertModel"),TUo=o(" (RoCBert model)"),MUo=l(),hb=a("li"),FTe=a("strong"),EUo=o("roformer"),CUo=o(" \u2014 "),uU=a("a"),wUo=o("RoFormerModel"),AUo=o(" (RoFormer model)"),LUo=l(),ub=a("li"),TTe=a("strong"),yUo=o("segformer"),xUo=o(" \u2014 "),pU=a("a"),$Uo=o("SegformerModel"),kUo=o(" (SegFormer model)"),SUo=l(),pb=a("li"),MTe=a("strong"),RUo=o("sew"),PUo=o(" \u2014 "),_U=a("a"),BUo=o("SEWModel"),IUo=o(" (SEW model)"),NUo=l(),_b=a("li"),ETe=a("strong"),qUo=o("sew-d"),jUo=o(" \u2014 "),bU=a("a"),DUo=o("SEWDModel"),GUo=o(" (SEW-D model)"),OUo=l(),bb=a("li"),CTe=a("strong"),VUo=o("speech_to_text"),XUo=o(" \u2014 "),vU=a("a"),zUo=o("Speech2TextModel"),QUo=o(" (Speech2Text model)"),WUo=l(),vb=a("li"),wTe=a("strong"),UUo=o("splinter"),HUo=o(" \u2014 "),FU=a("a"),JUo=o("SplinterModel"),YUo=o(" (Splinter model)"),ZUo=l(),Fb=a("li"),ATe=a("strong"),KUo=o("squeezebert"),eHo=o(" \u2014 "),TU=a("a"),oHo=o("SqueezeBertModel"),rHo=o(" (SqueezeBERT model)"),tHo=l(),Tb=a("li"),LTe=a("strong"),aHo=o("swin"),nHo=o(" \u2014 "),MU=a("a"),sHo=o("SwinModel"),lHo=o(" (Swin Transformer model)"),iHo=l(),Mb=a("li"),yTe=a("strong"),dHo=o("swinv2"),mHo=o(" \u2014 "),EU=a("a"),cHo=o("Swinv2Model"),fHo=o(" (Swin Transformer V2 model)"),gHo=l(),Eb=a("li"),xTe=a("strong"),hHo=o("t5"),uHo=o(" \u2014 "),CU=a("a"),pHo=o("T5Model"),_Ho=o(" (T5 model)"),bHo=l(),Cb=a("li"),$Te=a("strong"),vHo=o("table-transformer"),FHo=o(" \u2014 "),wU=a("a"),THo=o("TableTransformerModel"),MHo=o(" (Table Transformer model)"),EHo=l(),wb=a("li"),kTe=a("strong"),CHo=o("tapas"),wHo=o(" \u2014 "),AU=a("a"),AHo=o("TapasModel"),LHo=o(" (TAPAS model)"),yHo=l(),Ab=a("li"),STe=a("strong"),xHo=o("time_series_transformer"),$Ho=o(" \u2014 "),LU=a("a"),kHo=o("TimeSeriesTransformerModel"),SHo=o(" (Time Series Transformer model)"),RHo=l(),Lb=a("li"),RTe=a("strong"),PHo=o("trajectory_transformer"),BHo=o(" \u2014 "),yU=a("a"),IHo=o("TrajectoryTransformerModel"),NHo=o(" (Trajectory Transformer model)"),qHo=l(),yb=a("li"),PTe=a("strong"),jHo=o("transfo-xl"),DHo=o(" \u2014 "),xU=a("a"),GHo=o("TransfoXLModel"),OHo=o(" (Transformer-XL model)"),VHo=l(),xb=a("li"),BTe=a("strong"),XHo=o("unispeech"),zHo=o(" \u2014 "),$U=a("a"),QHo=o("UniSpeechModel"),WHo=o(" (UniSpeech model)"),UHo=l(),$b=a("li"),ITe=a("strong"),HHo=o("unispeech-sat"),JHo=o(" \u2014 "),kU=a("a"),YHo=o("UniSpeechSatModel"),ZHo=o(" (UniSpeechSat model)"),KHo=l(),kb=a("li"),NTe=a("strong"),eJo=o("van"),oJo=o(" \u2014 "),SU=a("a"),rJo=o("VanModel"),tJo=o(" (VAN model)"),aJo=l(),Sb=a("li"),qTe=a("strong"),nJo=o("videomae"),sJo=o(" \u2014 "),RU=a("a"),lJo=o("VideoMAEModel"),iJo=o(" (VideoMAE model)"),dJo=l(),Rb=a("li"),jTe=a("strong"),mJo=o("vilt"),cJo=o(" \u2014 "),PU=a("a"),fJo=o("ViltModel"),gJo=o(" (ViLT model)"),hJo=l(),Pb=a("li"),DTe=a("strong"),uJo=o("vision-text-dual-encoder"),pJo=o(" \u2014 "),BU=a("a"),_Jo=o("VisionTextDualEncoderModel"),bJo=o(" (VisionTextDualEncoder model)"),vJo=l(),Bb=a("li"),GTe=a("strong"),FJo=o("visual_bert"),TJo=o(" \u2014 "),IU=a("a"),MJo=o("VisualBertModel"),EJo=o(" (VisualBERT model)"),CJo=l(),Ib=a("li"),OTe=a("strong"),wJo=o("vit"),AJo=o(" \u2014 "),NU=a("a"),LJo=o("ViTModel"),yJo=o(" (ViT model)"),xJo=l(),Nb=a("li"),VTe=a("strong"),$Jo=o("vit_mae"),kJo=o(" \u2014 "),qU=a("a"),SJo=o("ViTMAEModel"),RJo=o(" (ViTMAE model)"),PJo=l(),qb=a("li"),XTe=a("strong"),BJo=o("vit_msn"),IJo=o(" \u2014 "),jU=a("a"),NJo=o("ViTMSNModel"),qJo=o(" (ViTMSN model)"),jJo=l(),jb=a("li"),zTe=a("strong"),DJo=o("wav2vec2"),GJo=o(" \u2014 "),DU=a("a"),OJo=o("Wav2Vec2Model"),VJo=o(" (Wav2Vec2 model)"),XJo=l(),Db=a("li"),QTe=a("strong"),zJo=o("wav2vec2-conformer"),QJo=o(" \u2014 "),GU=a("a"),WJo=o("Wav2Vec2ConformerModel"),UJo=o(" (Wav2Vec2-Conformer model)"),HJo=l(),Gb=a("li"),WTe=a("strong"),JJo=o("wavlm"),YJo=o(" \u2014 "),OU=a("a"),ZJo=o("WavLMModel"),KJo=o(" (WavLM model)"),eYo=l(),Ob=a("li"),UTe=a("strong"),oYo=o("whisper"),rYo=o(" \u2014 "),VU=a("a"),tYo=o("WhisperModel"),aYo=o(" (Whisper model)"),nYo=l(),Vb=a("li"),HTe=a("strong"),sYo=o("xclip"),lYo=o(" \u2014 "),XU=a("a"),iYo=o("XCLIPModel"),dYo=o(" (X-CLIP model)"),mYo=l(),Xb=a("li"),JTe=a("strong"),cYo=o("xglm"),fYo=o(" \u2014 "),zU=a("a"),gYo=o("XGLMModel"),hYo=o(" (XGLM model)"),uYo=l(),zb=a("li"),YTe=a("strong"),pYo=o("xlm"),_Yo=o(" \u2014 "),QU=a("a"),bYo=o("XLMModel"),vYo=o(" (XLM model)"),FYo=l(),Qb=a("li"),ZTe=a("strong"),TYo=o("xlm-prophetnet"),MYo=o(" \u2014 "),WU=a("a"),EYo=o("XLMProphetNetModel"),CYo=o(" (XLM-ProphetNet model)"),wYo=l(),Wb=a("li"),KTe=a("strong"),AYo=o("xlm-roberta"),LYo=o(" \u2014 "),UU=a("a"),yYo=o("XLMRobertaModel"),xYo=o(" (XLM-RoBERTa model)"),$Yo=l(),Ub=a("li"),eMe=a("strong"),kYo=o("xlm-roberta-xl"),SYo=o(" \u2014 "),HU=a("a"),RYo=o("XLMRobertaXLModel"),PYo=o(" (XLM-RoBERTa-XL model)"),BYo=l(),Hb=a("li"),oMe=a("strong"),IYo=o("xlnet"),NYo=o(" \u2014 "),JU=a("a"),qYo=o("XLNetModel"),jYo=o(" (XLNet model)"),DYo=l(),Jb=a("li"),rMe=a("strong"),GYo=o("yolos"),OYo=o(" \u2014 "),YU=a("a"),VYo=o("YolosModel"),XYo=o(" (YOLOS model)"),zYo=l(),Yb=a("li"),tMe=a("strong"),QYo=o("yoso"),WYo=o(" \u2014 "),ZU=a("a"),UYo=o("YosoModel"),HYo=o(" (YOSO model)"),JYo=l(),Zb=a("p"),YYo=o("The model is set in evaluation mode by default using "),aMe=a("code"),ZYo=o("model.eval()"),KYo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),nMe=a("code"),eZo=o("model.train()"),oZo=l(),F(Kb.$$.fragment),zlo=l(),Xd=a("h2"),ev=a("a"),sMe=a("span"),F(Zk.$$.fragment),rZo=l(),lMe=a("span"),tZo=o("AutoModelForPreTraining"),Qlo=l(),Go=a("div"),F(Kk.$$.fragment),aZo=l(),zd=a("p"),nZo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),KU=a("a"),sZo=o("from_pretrained()"),lZo=o(" class method or the "),eH=a("a"),iZo=o("from_config()"),dZo=o(` class
method.`),mZo=l(),eS=a("p"),cZo=o("This class cannot be instantiated directly using "),iMe=a("code"),fZo=o("__init__()"),gZo=o(" (throws an error)."),hZo=l(),Lt=a("div"),F(oS.$$.fragment),uZo=l(),dMe=a("p"),pZo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),_Zo=l(),Qd=a("p"),bZo=o(`Note:
Loading a model from its configuration file does `),mMe=a("strong"),vZo=o("not"),FZo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oH=a("a"),TZo=o("from_pretrained()"),MZo=o(" to load the model weights."),EZo=l(),F(ov.$$.fragment),CZo=l(),ao=a("div"),F(rS.$$.fragment),wZo=l(),cMe=a("p"),AZo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),LZo=l(),gn=a("p"),yZo=o("The model class to instantiate is selected based on the "),fMe=a("code"),xZo=o("model_type"),$Zo=o(` property of the config object (either
passed as an argument or loaded from `),gMe=a("code"),kZo=o("pretrained_model_name_or_path"),SZo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hMe=a("code"),RZo=o("pretrained_model_name_or_path"),PZo=o(":"),BZo=l(),G=a("ul"),rv=a("li"),uMe=a("strong"),IZo=o("albert"),NZo=o(" \u2014 "),rH=a("a"),qZo=o("AlbertForPreTraining"),jZo=o(" (ALBERT model)"),DZo=l(),tv=a("li"),pMe=a("strong"),GZo=o("bart"),OZo=o(" \u2014 "),tH=a("a"),VZo=o("BartForConditionalGeneration"),XZo=o(" (BART model)"),zZo=l(),av=a("li"),_Me=a("strong"),QZo=o("bert"),WZo=o(" \u2014 "),aH=a("a"),UZo=o("BertForPreTraining"),HZo=o(" (BERT model)"),JZo=l(),nv=a("li"),bMe=a("strong"),YZo=o("big_bird"),ZZo=o(" \u2014 "),nH=a("a"),KZo=o("BigBirdForPreTraining"),eKo=o(" (BigBird model)"),oKo=l(),sv=a("li"),vMe=a("strong"),rKo=o("bloom"),tKo=o(" \u2014 "),sH=a("a"),aKo=o("BloomForCausalLM"),nKo=o(" (BLOOM model)"),sKo=l(),lv=a("li"),FMe=a("strong"),lKo=o("camembert"),iKo=o(" \u2014 "),lH=a("a"),dKo=o("CamembertForMaskedLM"),mKo=o(" (CamemBERT model)"),cKo=l(),iv=a("li"),TMe=a("strong"),fKo=o("ctrl"),gKo=o(" \u2014 "),iH=a("a"),hKo=o("CTRLLMHeadModel"),uKo=o(" (CTRL model)"),pKo=l(),dv=a("li"),MMe=a("strong"),_Ko=o("data2vec-text"),bKo=o(" \u2014 "),dH=a("a"),vKo=o("Data2VecTextForMaskedLM"),FKo=o(" (Data2VecText model)"),TKo=l(),mv=a("li"),EMe=a("strong"),MKo=o("deberta"),EKo=o(" \u2014 "),mH=a("a"),CKo=o("DebertaForMaskedLM"),wKo=o(" (DeBERTa model)"),AKo=l(),cv=a("li"),CMe=a("strong"),LKo=o("deberta-v2"),yKo=o(" \u2014 "),cH=a("a"),xKo=o("DebertaV2ForMaskedLM"),$Ko=o(" (DeBERTa-v2 model)"),kKo=l(),fv=a("li"),wMe=a("strong"),SKo=o("distilbert"),RKo=o(" \u2014 "),fH=a("a"),PKo=o("DistilBertForMaskedLM"),BKo=o(" (DistilBERT model)"),IKo=l(),gv=a("li"),AMe=a("strong"),NKo=o("electra"),qKo=o(" \u2014 "),gH=a("a"),jKo=o("ElectraForPreTraining"),DKo=o(" (ELECTRA model)"),GKo=l(),hv=a("li"),LMe=a("strong"),OKo=o("ernie"),VKo=o(" \u2014 "),hH=a("a"),XKo=o("ErnieForPreTraining"),zKo=o(" (ERNIE model)"),QKo=l(),uv=a("li"),yMe=a("strong"),WKo=o("flaubert"),UKo=o(" \u2014 "),uH=a("a"),HKo=o("FlaubertWithLMHeadModel"),JKo=o(" (FlauBERT model)"),YKo=l(),pv=a("li"),xMe=a("strong"),ZKo=o("flava"),KKo=o(" \u2014 "),pH=a("a"),eer=o("FlavaForPreTraining"),oer=o(" (FLAVA model)"),rer=l(),_v=a("li"),$Me=a("strong"),ter=o("fnet"),aer=o(" \u2014 "),_H=a("a"),ner=o("FNetForPreTraining"),ser=o(" (FNet model)"),ler=l(),bv=a("li"),kMe=a("strong"),ier=o("fsmt"),der=o(" \u2014 "),bH=a("a"),mer=o("FSMTForConditionalGeneration"),cer=o(" (FairSeq Machine-Translation model)"),fer=l(),vv=a("li"),SMe=a("strong"),ger=o("funnel"),her=o(" \u2014 "),vH=a("a"),uer=o("FunnelForPreTraining"),per=o(" (Funnel Transformer model)"),_er=l(),Fv=a("li"),RMe=a("strong"),ber=o("gpt2"),ver=o(" \u2014 "),FH=a("a"),Fer=o("GPT2LMHeadModel"),Ter=o(" (OpenAI GPT-2 model)"),Mer=l(),Tv=a("li"),PMe=a("strong"),Eer=o("ibert"),Cer=o(" \u2014 "),TH=a("a"),wer=o("IBertForMaskedLM"),Aer=o(" (I-BERT model)"),Ler=l(),Mv=a("li"),BMe=a("strong"),yer=o("layoutlm"),xer=o(" \u2014 "),MH=a("a"),$er=o("LayoutLMForMaskedLM"),ker=o(" (LayoutLM model)"),Ser=l(),Ev=a("li"),IMe=a("strong"),Rer=o("longformer"),Per=o(" \u2014 "),EH=a("a"),Ber=o("LongformerForMaskedLM"),Ier=o(" (Longformer model)"),Ner=l(),Cv=a("li"),NMe=a("strong"),qer=o("luke"),jer=o(" \u2014 "),CH=a("a"),Der=o("LukeForMaskedLM"),Ger=o(" (LUKE model)"),Oer=l(),wv=a("li"),qMe=a("strong"),Ver=o("lxmert"),Xer=o(" \u2014 "),wH=a("a"),zer=o("LxmertForPreTraining"),Qer=o(" (LXMERT model)"),Wer=l(),Av=a("li"),jMe=a("strong"),Uer=o("megatron-bert"),Her=o(" \u2014 "),AH=a("a"),Jer=o("MegatronBertForPreTraining"),Yer=o(" (Megatron-BERT model)"),Zer=l(),Lv=a("li"),DMe=a("strong"),Ker=o("mobilebert"),eor=o(" \u2014 "),LH=a("a"),oor=o("MobileBertForPreTraining"),ror=o(" (MobileBERT model)"),tor=l(),yv=a("li"),GMe=a("strong"),aor=o("mpnet"),nor=o(" \u2014 "),yH=a("a"),sor=o("MPNetForMaskedLM"),lor=o(" (MPNet model)"),ior=l(),xv=a("li"),OMe=a("strong"),dor=o("mvp"),mor=o(" \u2014 "),xH=a("a"),cor=o("MvpForConditionalGeneration"),gor=o(" (MVP model)"),hor=l(),$v=a("li"),VMe=a("strong"),uor=o("nezha"),por=o(" \u2014 "),$H=a("a"),_or=o("NezhaForPreTraining"),bor=o(" (Nezha model)"),vor=l(),kv=a("li"),XMe=a("strong"),For=o("openai-gpt"),Tor=o(" \u2014 "),kH=a("a"),Mor=o("OpenAIGPTLMHeadModel"),Eor=o(" (OpenAI GPT model)"),Cor=l(),Sv=a("li"),zMe=a("strong"),wor=o("retribert"),Aor=o(" \u2014 "),SH=a("a"),Lor=o("RetriBertModel"),yor=o(" (RetriBERT model)"),xor=l(),Rv=a("li"),QMe=a("strong"),$or=o("roberta"),kor=o(" \u2014 "),RH=a("a"),Sor=o("RobertaForMaskedLM"),Ror=o(" (RoBERTa model)"),Por=l(),Pv=a("li"),WMe=a("strong"),Bor=o("roc_bert"),Ior=o(" \u2014 "),PH=a("a"),Nor=o("RoCBertForPreTraining"),qor=o(" (RoCBert model)"),jor=l(),Bv=a("li"),UMe=a("strong"),Dor=o("splinter"),Gor=o(" \u2014 "),BH=a("a"),Oor=o("SplinterForPreTraining"),Vor=o(" (Splinter model)"),Xor=l(),Iv=a("li"),HMe=a("strong"),zor=o("squeezebert"),Qor=o(" \u2014 "),IH=a("a"),Wor=o("SqueezeBertForMaskedLM"),Uor=o(" (SqueezeBERT model)"),Hor=l(),Nv=a("li"),JMe=a("strong"),Jor=o("t5"),Yor=o(" \u2014 "),NH=a("a"),Zor=o("T5ForConditionalGeneration"),Kor=o(" (T5 model)"),err=l(),qv=a("li"),YMe=a("strong"),orr=o("tapas"),rrr=o(" \u2014 "),qH=a("a"),trr=o("TapasForMaskedLM"),arr=o(" (TAPAS model)"),nrr=l(),jv=a("li"),ZMe=a("strong"),srr=o("transfo-xl"),lrr=o(" \u2014 "),jH=a("a"),irr=o("TransfoXLLMHeadModel"),drr=o(" (Transformer-XL model)"),mrr=l(),Dv=a("li"),KMe=a("strong"),crr=o("unispeech"),frr=o(" \u2014 "),DH=a("a"),grr=o("UniSpeechForPreTraining"),hrr=o(" (UniSpeech model)"),urr=l(),Gv=a("li"),eEe=a("strong"),prr=o("unispeech-sat"),_rr=o(" \u2014 "),GH=a("a"),brr=o("UniSpeechSatForPreTraining"),vrr=o(" (UniSpeechSat model)"),Frr=l(),Ov=a("li"),oEe=a("strong"),Trr=o("videomae"),Mrr=o(" \u2014 "),OH=a("a"),Err=o("VideoMAEForPreTraining"),Crr=o(" (VideoMAE model)"),wrr=l(),Vv=a("li"),rEe=a("strong"),Arr=o("visual_bert"),Lrr=o(" \u2014 "),VH=a("a"),yrr=o("VisualBertForPreTraining"),xrr=o(" (VisualBERT model)"),$rr=l(),Xv=a("li"),tEe=a("strong"),krr=o("vit_mae"),Srr=o(" \u2014 "),XH=a("a"),Rrr=o("ViTMAEForPreTraining"),Prr=o(" (ViTMAE model)"),Brr=l(),zv=a("li"),aEe=a("strong"),Irr=o("wav2vec2"),Nrr=o(" \u2014 "),zH=a("a"),qrr=o("Wav2Vec2ForPreTraining"),jrr=o(" (Wav2Vec2 model)"),Drr=l(),Qv=a("li"),nEe=a("strong"),Grr=o("wav2vec2-conformer"),Orr=o(" \u2014 "),QH=a("a"),Vrr=o("Wav2Vec2ConformerForPreTraining"),Xrr=o(" (Wav2Vec2-Conformer model)"),zrr=l(),Wv=a("li"),sEe=a("strong"),Qrr=o("xlm"),Wrr=o(" \u2014 "),WH=a("a"),Urr=o("XLMWithLMHeadModel"),Hrr=o(" (XLM model)"),Jrr=l(),Uv=a("li"),lEe=a("strong"),Yrr=o("xlm-roberta"),Zrr=o(" \u2014 "),UH=a("a"),Krr=o("XLMRobertaForMaskedLM"),etr=o(" (XLM-RoBERTa model)"),otr=l(),Hv=a("li"),iEe=a("strong"),rtr=o("xlm-roberta-xl"),ttr=o(" \u2014 "),HH=a("a"),atr=o("XLMRobertaXLForMaskedLM"),ntr=o(" (XLM-RoBERTa-XL model)"),str=l(),Jv=a("li"),dEe=a("strong"),ltr=o("xlnet"),itr=o(" \u2014 "),JH=a("a"),dtr=o("XLNetLMHeadModel"),mtr=o(" (XLNet model)"),ctr=l(),Yv=a("p"),ftr=o("The model is set in evaluation mode by default using "),mEe=a("code"),gtr=o("model.eval()"),htr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cEe=a("code"),utr=o("model.train()"),ptr=l(),F(Zv.$$.fragment),Wlo=l(),Wd=a("h2"),Kv=a("a"),fEe=a("span"),F(tS.$$.fragment),_tr=l(),gEe=a("span"),btr=o("AutoModelForCausalLM"),Ulo=l(),Oo=a("div"),F(aS.$$.fragment),vtr=l(),Ud=a("p"),Ftr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),YH=a("a"),Ttr=o("from_pretrained()"),Mtr=o(" class method or the "),ZH=a("a"),Etr=o("from_config()"),Ctr=o(` class
method.`),wtr=l(),nS=a("p"),Atr=o("This class cannot be instantiated directly using "),hEe=a("code"),Ltr=o("__init__()"),ytr=o(" (throws an error)."),xtr=l(),yt=a("div"),F(sS.$$.fragment),$tr=l(),uEe=a("p"),ktr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Str=l(),Hd=a("p"),Rtr=o(`Note:
Loading a model from its configuration file does `),pEe=a("strong"),Ptr=o("not"),Btr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),KH=a("a"),Itr=o("from_pretrained()"),Ntr=o(" to load the model weights."),qtr=l(),F(eF.$$.fragment),jtr=l(),no=a("div"),F(lS.$$.fragment),Dtr=l(),_Ee=a("p"),Gtr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Otr=l(),hn=a("p"),Vtr=o("The model class to instantiate is selected based on the "),bEe=a("code"),Xtr=o("model_type"),ztr=o(` property of the config object (either
passed as an argument or loaded from `),vEe=a("code"),Qtr=o("pretrained_model_name_or_path"),Wtr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FEe=a("code"),Utr=o("pretrained_model_name_or_path"),Htr=o(":"),Jtr=l(),W=a("ul"),oF=a("li"),TEe=a("strong"),Ytr=o("bart"),Ztr=o(" \u2014 "),eJ=a("a"),Ktr=o("BartForCausalLM"),ear=o(" (BART model)"),oar=l(),rF=a("li"),MEe=a("strong"),rar=o("bert"),tar=o(" \u2014 "),oJ=a("a"),aar=o("BertLMHeadModel"),nar=o(" (BERT model)"),sar=l(),tF=a("li"),EEe=a("strong"),lar=o("bert-generation"),iar=o(" \u2014 "),rJ=a("a"),dar=o("BertGenerationDecoder"),mar=o(" (Bert Generation model)"),car=l(),aF=a("li"),CEe=a("strong"),far=o("big_bird"),gar=o(" \u2014 "),tJ=a("a"),har=o("BigBirdForCausalLM"),uar=o(" (BigBird model)"),par=l(),nF=a("li"),wEe=a("strong"),_ar=o("bigbird_pegasus"),bar=o(" \u2014 "),aJ=a("a"),Far=o("BigBirdPegasusForCausalLM"),Tar=o(" (BigBird-Pegasus model)"),Mar=l(),sF=a("li"),AEe=a("strong"),Ear=o("blenderbot"),Car=o(" \u2014 "),nJ=a("a"),war=o("BlenderbotForCausalLM"),Aar=o(" (Blenderbot model)"),Lar=l(),lF=a("li"),LEe=a("strong"),yar=o("blenderbot-small"),xar=o(" \u2014 "),sJ=a("a"),$ar=o("BlenderbotSmallForCausalLM"),kar=o(" (BlenderbotSmall model)"),Sar=l(),iF=a("li"),yEe=a("strong"),Rar=o("bloom"),Par=o(" \u2014 "),lJ=a("a"),Bar=o("BloomForCausalLM"),Iar=o(" (BLOOM model)"),Nar=l(),dF=a("li"),xEe=a("strong"),qar=o("camembert"),jar=o(" \u2014 "),iJ=a("a"),Dar=o("CamembertForCausalLM"),Gar=o(" (CamemBERT model)"),Oar=l(),mF=a("li"),$Ee=a("strong"),Var=o("codegen"),Xar=o(" \u2014 "),dJ=a("a"),zar=o("CodeGenForCausalLM"),Qar=o(" (CodeGen model)"),War=l(),cF=a("li"),kEe=a("strong"),Uar=o("ctrl"),Har=o(" \u2014 "),mJ=a("a"),Jar=o("CTRLLMHeadModel"),Yar=o(" (CTRL model)"),Zar=l(),fF=a("li"),SEe=a("strong"),Kar=o("data2vec-text"),enr=o(" \u2014 "),cJ=a("a"),onr=o("Data2VecTextForCausalLM"),rnr=o(" (Data2VecText model)"),tnr=l(),gF=a("li"),REe=a("strong"),anr=o("electra"),nnr=o(" \u2014 "),fJ=a("a"),snr=o("ElectraForCausalLM"),lnr=o(" (ELECTRA model)"),inr=l(),hF=a("li"),PEe=a("strong"),dnr=o("ernie"),mnr=o(" \u2014 "),gJ=a("a"),cnr=o("ErnieForCausalLM"),fnr=o(" (ERNIE model)"),gnr=l(),uF=a("li"),BEe=a("strong"),hnr=o("gpt2"),unr=o(" \u2014 "),hJ=a("a"),pnr=o("GPT2LMHeadModel"),_nr=o(" (OpenAI GPT-2 model)"),bnr=l(),pF=a("li"),IEe=a("strong"),vnr=o("gpt_neo"),Fnr=o(" \u2014 "),uJ=a("a"),Tnr=o("GPTNeoForCausalLM"),Mnr=o(" (GPT Neo model)"),Enr=l(),_F=a("li"),NEe=a("strong"),Cnr=o("gpt_neox"),wnr=o(" \u2014 "),pJ=a("a"),Anr=o("GPTNeoXForCausalLM"),Lnr=o(" (GPT NeoX model)"),ynr=l(),bF=a("li"),qEe=a("strong"),xnr=o("gpt_neox_japanese"),$nr=o(" \u2014 "),_J=a("a"),knr=o("GPTNeoXJapaneseForCausalLM"),Snr=o(" (GPT NeoX Japanese model)"),Rnr=l(),vF=a("li"),jEe=a("strong"),Pnr=o("gptj"),Bnr=o(" \u2014 "),bJ=a("a"),Inr=o("GPTJForCausalLM"),Nnr=o(" (GPT-J model)"),qnr=l(),FF=a("li"),DEe=a("strong"),jnr=o("marian"),Dnr=o(" \u2014 "),vJ=a("a"),Gnr=o("MarianForCausalLM"),Onr=o(" (Marian model)"),Vnr=l(),TF=a("li"),GEe=a("strong"),Xnr=o("mbart"),znr=o(" \u2014 "),FJ=a("a"),Qnr=o("MBartForCausalLM"),Wnr=o(" (mBART model)"),Unr=l(),MF=a("li"),OEe=a("strong"),Hnr=o("megatron-bert"),Jnr=o(" \u2014 "),TJ=a("a"),Ynr=o("MegatronBertForCausalLM"),Znr=o(" (Megatron-BERT model)"),Knr=l(),EF=a("li"),VEe=a("strong"),esr=o("mvp"),osr=o(" \u2014 "),MJ=a("a"),rsr=o("MvpForCausalLM"),tsr=o(" (MVP model)"),asr=l(),CF=a("li"),XEe=a("strong"),nsr=o("openai-gpt"),ssr=o(" \u2014 "),EJ=a("a"),lsr=o("OpenAIGPTLMHeadModel"),isr=o(" (OpenAI GPT model)"),dsr=l(),wF=a("li"),zEe=a("strong"),msr=o("opt"),csr=o(" \u2014 "),CJ=a("a"),fsr=o("OPTForCausalLM"),gsr=o(" (OPT model)"),hsr=l(),AF=a("li"),QEe=a("strong"),usr=o("pegasus"),psr=o(" \u2014 "),wJ=a("a"),_sr=o("PegasusForCausalLM"),bsr=o(" (Pegasus model)"),vsr=l(),LF=a("li"),WEe=a("strong"),Fsr=o("plbart"),Tsr=o(" \u2014 "),AJ=a("a"),Msr=o("PLBartForCausalLM"),Esr=o(" (PLBart model)"),Csr=l(),yF=a("li"),UEe=a("strong"),wsr=o("prophetnet"),Asr=o(" \u2014 "),LJ=a("a"),Lsr=o("ProphetNetForCausalLM"),ysr=o(" (ProphetNet model)"),xsr=l(),xF=a("li"),HEe=a("strong"),$sr=o("qdqbert"),ksr=o(" \u2014 "),yJ=a("a"),Ssr=o("QDQBertLMHeadModel"),Rsr=o(" (QDQBert model)"),Psr=l(),$F=a("li"),JEe=a("strong"),Bsr=o("reformer"),Isr=o(" \u2014 "),xJ=a("a"),Nsr=o("ReformerModelWithLMHead"),qsr=o(" (Reformer model)"),jsr=l(),kF=a("li"),YEe=a("strong"),Dsr=o("rembert"),Gsr=o(" \u2014 "),$J=a("a"),Osr=o("RemBertForCausalLM"),Vsr=o(" (RemBERT model)"),Xsr=l(),SF=a("li"),ZEe=a("strong"),zsr=o("roberta"),Qsr=o(" \u2014 "),kJ=a("a"),Wsr=o("RobertaForCausalLM"),Usr=o(" (RoBERTa model)"),Hsr=l(),RF=a("li"),KEe=a("strong"),Jsr=o("roc_bert"),Ysr=o(" \u2014 "),SJ=a("a"),Zsr=o("RoCBertForCausalLM"),Ksr=o(" (RoCBert model)"),elr=l(),PF=a("li"),e4e=a("strong"),olr=o("roformer"),rlr=o(" \u2014 "),RJ=a("a"),tlr=o("RoFormerForCausalLM"),alr=o(" (RoFormer model)"),nlr=l(),BF=a("li"),o4e=a("strong"),slr=o("speech_to_text_2"),llr=o(" \u2014 "),PJ=a("a"),ilr=o("Speech2Text2ForCausalLM"),dlr=o(" (Speech2Text2 model)"),mlr=l(),IF=a("li"),r4e=a("strong"),clr=o("transfo-xl"),flr=o(" \u2014 "),BJ=a("a"),glr=o("TransfoXLLMHeadModel"),hlr=o(" (Transformer-XL model)"),ulr=l(),NF=a("li"),t4e=a("strong"),plr=o("trocr"),_lr=o(" \u2014 "),IJ=a("a"),blr=o("TrOCRForCausalLM"),vlr=o(" (TrOCR model)"),Flr=l(),qF=a("li"),a4e=a("strong"),Tlr=o("xglm"),Mlr=o(" \u2014 "),NJ=a("a"),Elr=o("XGLMForCausalLM"),Clr=o(" (XGLM model)"),wlr=l(),jF=a("li"),n4e=a("strong"),Alr=o("xlm"),Llr=o(" \u2014 "),qJ=a("a"),ylr=o("XLMWithLMHeadModel"),xlr=o(" (XLM model)"),$lr=l(),DF=a("li"),s4e=a("strong"),klr=o("xlm-prophetnet"),Slr=o(" \u2014 "),jJ=a("a"),Rlr=o("XLMProphetNetForCausalLM"),Plr=o(" (XLM-ProphetNet model)"),Blr=l(),GF=a("li"),l4e=a("strong"),Ilr=o("xlm-roberta"),Nlr=o(" \u2014 "),DJ=a("a"),qlr=o("XLMRobertaForCausalLM"),jlr=o(" (XLM-RoBERTa model)"),Dlr=l(),OF=a("li"),i4e=a("strong"),Glr=o("xlm-roberta-xl"),Olr=o(" \u2014 "),GJ=a("a"),Vlr=o("XLMRobertaXLForCausalLM"),Xlr=o(" (XLM-RoBERTa-XL model)"),zlr=l(),VF=a("li"),d4e=a("strong"),Qlr=o("xlnet"),Wlr=o(" \u2014 "),OJ=a("a"),Ulr=o("XLNetLMHeadModel"),Hlr=o(" (XLNet model)"),Jlr=l(),XF=a("p"),Ylr=o("The model is set in evaluation mode by default using "),m4e=a("code"),Zlr=o("model.eval()"),Klr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c4e=a("code"),eir=o("model.train()"),oir=l(),F(zF.$$.fragment),Hlo=l(),Jd=a("h2"),QF=a("a"),f4e=a("span"),F(iS.$$.fragment),rir=l(),g4e=a("span"),tir=o("AutoModelForDepthEstimation"),Jlo=l(),Vo=a("div"),F(dS.$$.fragment),air=l(),Yd=a("p"),nir=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a depth estimation head) when created
with the `),VJ=a("a"),sir=o("from_pretrained()"),lir=o(" class method or the "),XJ=a("a"),iir=o("from_config()"),dir=o(` class
method.`),mir=l(),mS=a("p"),cir=o("This class cannot be instantiated directly using "),h4e=a("code"),fir=o("__init__()"),gir=o(" (throws an error)."),hir=l(),xt=a("div"),F(cS.$$.fragment),uir=l(),u4e=a("p"),pir=o("Instantiates one of the model classes of the library (with a depth estimation head) from a configuration."),_ir=l(),Zd=a("p"),bir=o(`Note:
Loading a model from its configuration file does `),p4e=a("strong"),vir=o("not"),Fir=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zJ=a("a"),Tir=o("from_pretrained()"),Mir=o(" to load the model weights."),Eir=l(),F(WF.$$.fragment),Cir=l(),so=a("div"),F(fS.$$.fragment),wir=l(),_4e=a("p"),Air=o("Instantiate one of the model classes of the library (with a depth estimation head) from a pretrained model."),Lir=l(),un=a("p"),yir=o("The model class to instantiate is selected based on the "),b4e=a("code"),xir=o("model_type"),$ir=o(` property of the config object (either
passed as an argument or loaded from `),v4e=a("code"),kir=o("pretrained_model_name_or_path"),Sir=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F4e=a("code"),Rir=o("pretrained_model_name_or_path"),Pir=o(":"),Bir=l(),gS=a("ul"),UF=a("li"),T4e=a("strong"),Iir=o("dpt"),Nir=o(" \u2014 "),QJ=a("a"),qir=o("DPTForDepthEstimation"),jir=o(" (DPT model)"),Dir=l(),HF=a("li"),M4e=a("strong"),Gir=o("glpn"),Oir=o(" \u2014 "),WJ=a("a"),Vir=o("GLPNForDepthEstimation"),Xir=o(" (GLPN model)"),zir=l(),JF=a("p"),Qir=o("The model is set in evaluation mode by default using "),E4e=a("code"),Wir=o("model.eval()"),Uir=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),C4e=a("code"),Hir=o("model.train()"),Jir=l(),F(YF.$$.fragment),Ylo=l(),Kd=a("h2"),ZF=a("a"),w4e=a("span"),F(hS.$$.fragment),Yir=l(),A4e=a("span"),Zir=o("AutoModelForMaskedLM"),Zlo=l(),Xo=a("div"),F(uS.$$.fragment),Kir=l(),em=a("p"),edr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),UJ=a("a"),odr=o("from_pretrained()"),rdr=o(" class method or the "),HJ=a("a"),tdr=o("from_config()"),adr=o(` class
method.`),ndr=l(),pS=a("p"),sdr=o("This class cannot be instantiated directly using "),L4e=a("code"),ldr=o("__init__()"),idr=o(" (throws an error)."),ddr=l(),$t=a("div"),F(_S.$$.fragment),mdr=l(),y4e=a("p"),cdr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),fdr=l(),om=a("p"),gdr=o(`Note:
Loading a model from its configuration file does `),x4e=a("strong"),hdr=o("not"),udr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JJ=a("a"),pdr=o("from_pretrained()"),_dr=o(" to load the model weights."),bdr=l(),F(KF.$$.fragment),vdr=l(),lo=a("div"),F(bS.$$.fragment),Fdr=l(),$4e=a("p"),Tdr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Mdr=l(),pn=a("p"),Edr=o("The model class to instantiate is selected based on the "),k4e=a("code"),Cdr=o("model_type"),wdr=o(` property of the config object (either
passed as an argument or loaded from `),S4e=a("code"),Adr=o("pretrained_model_name_or_path"),Ldr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R4e=a("code"),ydr=o("pretrained_model_name_or_path"),xdr=o(":"),$dr=l(),Y=a("ul"),eT=a("li"),P4e=a("strong"),kdr=o("albert"),Sdr=o(" \u2014 "),YJ=a("a"),Rdr=o("AlbertForMaskedLM"),Pdr=o(" (ALBERT model)"),Bdr=l(),oT=a("li"),B4e=a("strong"),Idr=o("bart"),Ndr=o(" \u2014 "),ZJ=a("a"),qdr=o("BartForConditionalGeneration"),jdr=o(" (BART model)"),Ddr=l(),rT=a("li"),I4e=a("strong"),Gdr=o("bert"),Odr=o(" \u2014 "),KJ=a("a"),Vdr=o("BertForMaskedLM"),Xdr=o(" (BERT model)"),zdr=l(),tT=a("li"),N4e=a("strong"),Qdr=o("big_bird"),Wdr=o(" \u2014 "),eY=a("a"),Udr=o("BigBirdForMaskedLM"),Hdr=o(" (BigBird model)"),Jdr=l(),aT=a("li"),q4e=a("strong"),Ydr=o("camembert"),Zdr=o(" \u2014 "),oY=a("a"),Kdr=o("CamembertForMaskedLM"),emr=o(" (CamemBERT model)"),omr=l(),nT=a("li"),j4e=a("strong"),rmr=o("convbert"),tmr=o(" \u2014 "),rY=a("a"),amr=o("ConvBertForMaskedLM"),nmr=o(" (ConvBERT model)"),smr=l(),sT=a("li"),D4e=a("strong"),lmr=o("data2vec-text"),imr=o(" \u2014 "),tY=a("a"),dmr=o("Data2VecTextForMaskedLM"),mmr=o(" (Data2VecText model)"),cmr=l(),lT=a("li"),G4e=a("strong"),fmr=o("deberta"),gmr=o(" \u2014 "),aY=a("a"),hmr=o("DebertaForMaskedLM"),umr=o(" (DeBERTa model)"),pmr=l(),iT=a("li"),O4e=a("strong"),_mr=o("deberta-v2"),bmr=o(" \u2014 "),nY=a("a"),vmr=o("DebertaV2ForMaskedLM"),Fmr=o(" (DeBERTa-v2 model)"),Tmr=l(),dT=a("li"),V4e=a("strong"),Mmr=o("distilbert"),Emr=o(" \u2014 "),sY=a("a"),Cmr=o("DistilBertForMaskedLM"),wmr=o(" (DistilBERT model)"),Amr=l(),mT=a("li"),X4e=a("strong"),Lmr=o("electra"),ymr=o(" \u2014 "),lY=a("a"),xmr=o("ElectraForMaskedLM"),$mr=o(" (ELECTRA model)"),kmr=l(),cT=a("li"),z4e=a("strong"),Smr=o("ernie"),Rmr=o(" \u2014 "),iY=a("a"),Pmr=o("ErnieForMaskedLM"),Bmr=o(" (ERNIE model)"),Imr=l(),fT=a("li"),Q4e=a("strong"),Nmr=o("flaubert"),qmr=o(" \u2014 "),dY=a("a"),jmr=o("FlaubertWithLMHeadModel"),Dmr=o(" (FlauBERT model)"),Gmr=l(),gT=a("li"),W4e=a("strong"),Omr=o("fnet"),Vmr=o(" \u2014 "),mY=a("a"),Xmr=o("FNetForMaskedLM"),zmr=o(" (FNet model)"),Qmr=l(),hT=a("li"),U4e=a("strong"),Wmr=o("funnel"),Umr=o(" \u2014 "),cY=a("a"),Hmr=o("FunnelForMaskedLM"),Jmr=o(" (Funnel Transformer model)"),Ymr=l(),uT=a("li"),H4e=a("strong"),Zmr=o("ibert"),Kmr=o(" \u2014 "),fY=a("a"),ecr=o("IBertForMaskedLM"),ocr=o(" (I-BERT model)"),rcr=l(),pT=a("li"),J4e=a("strong"),tcr=o("layoutlm"),acr=o(" \u2014 "),gY=a("a"),ncr=o("LayoutLMForMaskedLM"),scr=o(" (LayoutLM model)"),lcr=l(),_T=a("li"),Y4e=a("strong"),icr=o("longformer"),dcr=o(" \u2014 "),hY=a("a"),mcr=o("LongformerForMaskedLM"),ccr=o(" (Longformer model)"),fcr=l(),bT=a("li"),Z4e=a("strong"),gcr=o("luke"),hcr=o(" \u2014 "),uY=a("a"),ucr=o("LukeForMaskedLM"),pcr=o(" (LUKE model)"),_cr=l(),vT=a("li"),K4e=a("strong"),bcr=o("mbart"),vcr=o(" \u2014 "),pY=a("a"),Fcr=o("MBartForConditionalGeneration"),Tcr=o(" (mBART model)"),Mcr=l(),FT=a("li"),eCe=a("strong"),Ecr=o("megatron-bert"),Ccr=o(" \u2014 "),_Y=a("a"),wcr=o("MegatronBertForMaskedLM"),Acr=o(" (Megatron-BERT model)"),Lcr=l(),TT=a("li"),oCe=a("strong"),ycr=o("mobilebert"),xcr=o(" \u2014 "),bY=a("a"),$cr=o("MobileBertForMaskedLM"),kcr=o(" (MobileBERT model)"),Scr=l(),MT=a("li"),rCe=a("strong"),Rcr=o("mpnet"),Pcr=o(" \u2014 "),vY=a("a"),Bcr=o("MPNetForMaskedLM"),Icr=o(" (MPNet model)"),Ncr=l(),ET=a("li"),tCe=a("strong"),qcr=o("mvp"),jcr=o(" \u2014 "),FY=a("a"),Dcr=o("MvpForConditionalGeneration"),Gcr=o(" (MVP model)"),Ocr=l(),CT=a("li"),aCe=a("strong"),Vcr=o("nezha"),Xcr=o(" \u2014 "),TY=a("a"),zcr=o("NezhaForMaskedLM"),Qcr=o(" (Nezha model)"),Wcr=l(),wT=a("li"),nCe=a("strong"),Ucr=o("nystromformer"),Hcr=o(" \u2014 "),MY=a("a"),Jcr=o("NystromformerForMaskedLM"),Ycr=o(" (Nystr\xF6mformer model)"),Zcr=l(),AT=a("li"),sCe=a("strong"),Kcr=o("perceiver"),efr=o(" \u2014 "),EY=a("a"),ofr=o("PerceiverForMaskedLM"),rfr=o(" (Perceiver model)"),tfr=l(),LT=a("li"),lCe=a("strong"),afr=o("qdqbert"),nfr=o(" \u2014 "),CY=a("a"),sfr=o("QDQBertForMaskedLM"),lfr=o(" (QDQBert model)"),ifr=l(),yT=a("li"),iCe=a("strong"),dfr=o("reformer"),mfr=o(" \u2014 "),wY=a("a"),cfr=o("ReformerForMaskedLM"),ffr=o(" (Reformer model)"),gfr=l(),xT=a("li"),dCe=a("strong"),hfr=o("rembert"),ufr=o(" \u2014 "),AY=a("a"),pfr=o("RemBertForMaskedLM"),_fr=o(" (RemBERT model)"),bfr=l(),$T=a("li"),mCe=a("strong"),vfr=o("roberta"),Ffr=o(" \u2014 "),LY=a("a"),Tfr=o("RobertaForMaskedLM"),Mfr=o(" (RoBERTa model)"),Efr=l(),kT=a("li"),cCe=a("strong"),Cfr=o("roc_bert"),wfr=o(" \u2014 "),yY=a("a"),Afr=o("RoCBertForMaskedLM"),Lfr=o(" (RoCBert model)"),yfr=l(),ST=a("li"),fCe=a("strong"),xfr=o("roformer"),$fr=o(" \u2014 "),xY=a("a"),kfr=o("RoFormerForMaskedLM"),Sfr=o(" (RoFormer model)"),Rfr=l(),RT=a("li"),gCe=a("strong"),Pfr=o("squeezebert"),Bfr=o(" \u2014 "),$Y=a("a"),Ifr=o("SqueezeBertForMaskedLM"),Nfr=o(" (SqueezeBERT model)"),qfr=l(),PT=a("li"),hCe=a("strong"),jfr=o("tapas"),Dfr=o(" \u2014 "),kY=a("a"),Gfr=o("TapasForMaskedLM"),Ofr=o(" (TAPAS model)"),Vfr=l(),BT=a("li"),uCe=a("strong"),Xfr=o("wav2vec2"),zfr=o(" \u2014 "),pCe=a("code"),Qfr=o("Wav2Vec2ForMaskedLM"),Wfr=o(" (Wav2Vec2 model)"),Ufr=l(),IT=a("li"),_Ce=a("strong"),Hfr=o("xlm"),Jfr=o(" \u2014 "),SY=a("a"),Yfr=o("XLMWithLMHeadModel"),Zfr=o(" (XLM model)"),Kfr=l(),NT=a("li"),bCe=a("strong"),egr=o("xlm-roberta"),ogr=o(" \u2014 "),RY=a("a"),rgr=o("XLMRobertaForMaskedLM"),tgr=o(" (XLM-RoBERTa model)"),agr=l(),qT=a("li"),vCe=a("strong"),ngr=o("xlm-roberta-xl"),sgr=o(" \u2014 "),PY=a("a"),lgr=o("XLMRobertaXLForMaskedLM"),igr=o(" (XLM-RoBERTa-XL model)"),dgr=l(),jT=a("li"),FCe=a("strong"),mgr=o("yoso"),cgr=o(" \u2014 "),BY=a("a"),fgr=o("YosoForMaskedLM"),ggr=o(" (YOSO model)"),hgr=l(),DT=a("p"),ugr=o("The model is set in evaluation mode by default using "),TCe=a("code"),pgr=o("model.eval()"),_gr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),MCe=a("code"),bgr=o("model.train()"),vgr=l(),F(GT.$$.fragment),Klo=l(),rm=a("h2"),OT=a("a"),ECe=a("span"),F(vS.$$.fragment),Fgr=l(),CCe=a("span"),Tgr=o("AutoModelForSeq2SeqLM"),eio=l(),zo=a("div"),F(FS.$$.fragment),Mgr=l(),tm=a("p"),Egr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),IY=a("a"),Cgr=o("from_pretrained()"),wgr=o(" class method or the "),NY=a("a"),Agr=o("from_config()"),Lgr=o(` class
method.`),ygr=l(),TS=a("p"),xgr=o("This class cannot be instantiated directly using "),wCe=a("code"),$gr=o("__init__()"),kgr=o(" (throws an error)."),Sgr=l(),kt=a("div"),F(MS.$$.fragment),Rgr=l(),ACe=a("p"),Pgr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Bgr=l(),am=a("p"),Igr=o(`Note:
Loading a model from its configuration file does `),LCe=a("strong"),Ngr=o("not"),qgr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qY=a("a"),jgr=o("from_pretrained()"),Dgr=o(" to load the model weights."),Ggr=l(),F(VT.$$.fragment),Ogr=l(),io=a("div"),F(ES.$$.fragment),Vgr=l(),yCe=a("p"),Xgr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),zgr=l(),_n=a("p"),Qgr=o("The model class to instantiate is selected based on the "),xCe=a("code"),Wgr=o("model_type"),Ugr=o(` property of the config object (either
passed as an argument or loaded from `),$Ce=a("code"),Hgr=o("pretrained_model_name_or_path"),Jgr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kCe=a("code"),Ygr=o("pretrained_model_name_or_path"),Zgr=o(":"),Kgr=l(),pe=a("ul"),XT=a("li"),SCe=a("strong"),ehr=o("bart"),ohr=o(" \u2014 "),jY=a("a"),rhr=o("BartForConditionalGeneration"),thr=o(" (BART model)"),ahr=l(),zT=a("li"),RCe=a("strong"),nhr=o("bigbird_pegasus"),shr=o(" \u2014 "),DY=a("a"),lhr=o("BigBirdPegasusForConditionalGeneration"),ihr=o(" (BigBird-Pegasus model)"),dhr=l(),QT=a("li"),PCe=a("strong"),mhr=o("blenderbot"),chr=o(" \u2014 "),GY=a("a"),fhr=o("BlenderbotForConditionalGeneration"),ghr=o(" (Blenderbot model)"),hhr=l(),WT=a("li"),BCe=a("strong"),uhr=o("blenderbot-small"),phr=o(" \u2014 "),OY=a("a"),_hr=o("BlenderbotSmallForConditionalGeneration"),bhr=o(" (BlenderbotSmall model)"),vhr=l(),UT=a("li"),ICe=a("strong"),Fhr=o("encoder-decoder"),Thr=o(" \u2014 "),VY=a("a"),Mhr=o("EncoderDecoderModel"),Ehr=o(" (Encoder decoder model)"),Chr=l(),HT=a("li"),NCe=a("strong"),whr=o("fsmt"),Ahr=o(" \u2014 "),XY=a("a"),Lhr=o("FSMTForConditionalGeneration"),yhr=o(" (FairSeq Machine-Translation model)"),xhr=l(),JT=a("li"),qCe=a("strong"),$hr=o("led"),khr=o(" \u2014 "),zY=a("a"),Shr=o("LEDForConditionalGeneration"),Rhr=o(" (LED model)"),Phr=l(),YT=a("li"),jCe=a("strong"),Bhr=o("longt5"),Ihr=o(" \u2014 "),QY=a("a"),Nhr=o("LongT5ForConditionalGeneration"),qhr=o(" (LongT5 model)"),jhr=l(),ZT=a("li"),DCe=a("strong"),Dhr=o("m2m_100"),Ghr=o(" \u2014 "),WY=a("a"),Ohr=o("M2M100ForConditionalGeneration"),Vhr=o(" (M2M100 model)"),Xhr=l(),KT=a("li"),GCe=a("strong"),zhr=o("marian"),Qhr=o(" \u2014 "),UY=a("a"),Whr=o("MarianMTModel"),Uhr=o(" (Marian model)"),Hhr=l(),eM=a("li"),OCe=a("strong"),Jhr=o("mbart"),Yhr=o(" \u2014 "),HY=a("a"),Zhr=o("MBartForConditionalGeneration"),Khr=o(" (mBART model)"),eur=l(),oM=a("li"),VCe=a("strong"),our=o("mt5"),rur=o(" \u2014 "),JY=a("a"),tur=o("MT5ForConditionalGeneration"),aur=o(" (MT5 model)"),nur=l(),rM=a("li"),XCe=a("strong"),sur=o("mvp"),lur=o(" \u2014 "),YY=a("a"),iur=o("MvpForConditionalGeneration"),dur=o(" (MVP model)"),mur=l(),tM=a("li"),zCe=a("strong"),cur=o("nllb"),fur=o(" \u2014 "),ZY=a("a"),gur=o("M2M100ForConditionalGeneration"),hur=o(" (NLLB model)"),uur=l(),aM=a("li"),QCe=a("strong"),pur=o("pegasus"),_ur=o(" \u2014 "),KY=a("a"),bur=o("PegasusForConditionalGeneration"),vur=o(" (Pegasus model)"),Fur=l(),nM=a("li"),WCe=a("strong"),Tur=o("pegasus_x"),Mur=o(" \u2014 "),eZ=a("a"),Eur=o("PegasusXForConditionalGeneration"),Cur=o(" (PEGASUS-X model)"),wur=l(),sM=a("li"),UCe=a("strong"),Aur=o("plbart"),Lur=o(" \u2014 "),oZ=a("a"),yur=o("PLBartForConditionalGeneration"),xur=o(" (PLBart model)"),$ur=l(),lM=a("li"),HCe=a("strong"),kur=o("prophetnet"),Sur=o(" \u2014 "),rZ=a("a"),Rur=o("ProphetNetForConditionalGeneration"),Pur=o(" (ProphetNet model)"),Bur=l(),iM=a("li"),JCe=a("strong"),Iur=o("t5"),Nur=o(" \u2014 "),tZ=a("a"),qur=o("T5ForConditionalGeneration"),jur=o(" (T5 model)"),Dur=l(),dM=a("li"),YCe=a("strong"),Gur=o("xlm-prophetnet"),Our=o(" \u2014 "),aZ=a("a"),Vur=o("XLMProphetNetForConditionalGeneration"),Xur=o(" (XLM-ProphetNet model)"),zur=l(),mM=a("p"),Qur=o("The model is set in evaluation mode by default using "),ZCe=a("code"),Wur=o("model.eval()"),Uur=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),KCe=a("code"),Hur=o("model.train()"),Jur=l(),F(cM.$$.fragment),oio=l(),nm=a("h2"),fM=a("a"),e3e=a("span"),F(CS.$$.fragment),Yur=l(),o3e=a("span"),Zur=o("AutoModelForSequenceClassification"),rio=l(),Qo=a("div"),F(wS.$$.fragment),Kur=l(),sm=a("p"),epr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),nZ=a("a"),opr=o("from_pretrained()"),rpr=o(" class method or the "),sZ=a("a"),tpr=o("from_config()"),apr=o(` class
method.`),npr=l(),AS=a("p"),spr=o("This class cannot be instantiated directly using "),r3e=a("code"),lpr=o("__init__()"),ipr=o(" (throws an error)."),dpr=l(),St=a("div"),F(LS.$$.fragment),mpr=l(),t3e=a("p"),cpr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),fpr=l(),lm=a("p"),gpr=o(`Note:
Loading a model from its configuration file does `),a3e=a("strong"),hpr=o("not"),upr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lZ=a("a"),ppr=o("from_pretrained()"),_pr=o(" to load the model weights."),bpr=l(),F(gM.$$.fragment),vpr=l(),mo=a("div"),F(yS.$$.fragment),Fpr=l(),n3e=a("p"),Tpr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Mpr=l(),bn=a("p"),Epr=o("The model class to instantiate is selected based on the "),s3e=a("code"),Cpr=o("model_type"),wpr=o(` property of the config object (either
passed as an argument or loaded from `),l3e=a("code"),Apr=o("pretrained_model_name_or_path"),Lpr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i3e=a("code"),ypr=o("pretrained_model_name_or_path"),xpr=o(":"),$pr=l(),I=a("ul"),hM=a("li"),d3e=a("strong"),kpr=o("albert"),Spr=o(" \u2014 "),iZ=a("a"),Rpr=o("AlbertForSequenceClassification"),Ppr=o(" (ALBERT model)"),Bpr=l(),uM=a("li"),m3e=a("strong"),Ipr=o("bart"),Npr=o(" \u2014 "),dZ=a("a"),qpr=o("BartForSequenceClassification"),jpr=o(" (BART model)"),Dpr=l(),pM=a("li"),c3e=a("strong"),Gpr=o("bert"),Opr=o(" \u2014 "),mZ=a("a"),Vpr=o("BertForSequenceClassification"),Xpr=o(" (BERT model)"),zpr=l(),_M=a("li"),f3e=a("strong"),Qpr=o("big_bird"),Wpr=o(" \u2014 "),cZ=a("a"),Upr=o("BigBirdForSequenceClassification"),Hpr=o(" (BigBird model)"),Jpr=l(),bM=a("li"),g3e=a("strong"),Ypr=o("bigbird_pegasus"),Zpr=o(" \u2014 "),fZ=a("a"),Kpr=o("BigBirdPegasusForSequenceClassification"),e_r=o(" (BigBird-Pegasus model)"),o_r=l(),vM=a("li"),h3e=a("strong"),r_r=o("bloom"),t_r=o(" \u2014 "),gZ=a("a"),a_r=o("BloomForSequenceClassification"),n_r=o(" (BLOOM model)"),s_r=l(),FM=a("li"),u3e=a("strong"),l_r=o("camembert"),i_r=o(" \u2014 "),hZ=a("a"),d_r=o("CamembertForSequenceClassification"),m_r=o(" (CamemBERT model)"),c_r=l(),TM=a("li"),p3e=a("strong"),f_r=o("canine"),g_r=o(" \u2014 "),uZ=a("a"),h_r=o("CanineForSequenceClassification"),u_r=o(" (CANINE model)"),p_r=l(),MM=a("li"),_3e=a("strong"),__r=o("convbert"),b_r=o(" \u2014 "),pZ=a("a"),v_r=o("ConvBertForSequenceClassification"),F_r=o(" (ConvBERT model)"),T_r=l(),EM=a("li"),b3e=a("strong"),M_r=o("ctrl"),E_r=o(" \u2014 "),_Z=a("a"),C_r=o("CTRLForSequenceClassification"),w_r=o(" (CTRL model)"),A_r=l(),CM=a("li"),v3e=a("strong"),L_r=o("data2vec-text"),y_r=o(" \u2014 "),bZ=a("a"),x_r=o("Data2VecTextForSequenceClassification"),$_r=o(" (Data2VecText model)"),k_r=l(),wM=a("li"),F3e=a("strong"),S_r=o("deberta"),R_r=o(" \u2014 "),vZ=a("a"),P_r=o("DebertaForSequenceClassification"),B_r=o(" (DeBERTa model)"),I_r=l(),AM=a("li"),T3e=a("strong"),N_r=o("deberta-v2"),q_r=o(" \u2014 "),FZ=a("a"),j_r=o("DebertaV2ForSequenceClassification"),D_r=o(" (DeBERTa-v2 model)"),G_r=l(),LM=a("li"),M3e=a("strong"),O_r=o("distilbert"),V_r=o(" \u2014 "),TZ=a("a"),X_r=o("DistilBertForSequenceClassification"),z_r=o(" (DistilBERT model)"),Q_r=l(),yM=a("li"),E3e=a("strong"),W_r=o("electra"),U_r=o(" \u2014 "),MZ=a("a"),H_r=o("ElectraForSequenceClassification"),J_r=o(" (ELECTRA model)"),Y_r=l(),xM=a("li"),C3e=a("strong"),Z_r=o("ernie"),K_r=o(" \u2014 "),EZ=a("a"),e1r=o("ErnieForSequenceClassification"),o1r=o(" (ERNIE model)"),r1r=l(),$M=a("li"),w3e=a("strong"),t1r=o("esm"),a1r=o(" \u2014 "),CZ=a("a"),n1r=o("EsmForSequenceClassification"),s1r=o(" (ESM model)"),l1r=l(),kM=a("li"),A3e=a("strong"),i1r=o("flaubert"),d1r=o(" \u2014 "),wZ=a("a"),m1r=o("FlaubertForSequenceClassification"),c1r=o(" (FlauBERT model)"),f1r=l(),SM=a("li"),L3e=a("strong"),g1r=o("fnet"),h1r=o(" \u2014 "),AZ=a("a"),u1r=o("FNetForSequenceClassification"),p1r=o(" (FNet model)"),_1r=l(),RM=a("li"),y3e=a("strong"),b1r=o("funnel"),v1r=o(" \u2014 "),LZ=a("a"),F1r=o("FunnelForSequenceClassification"),T1r=o(" (Funnel Transformer model)"),M1r=l(),PM=a("li"),x3e=a("strong"),E1r=o("gpt2"),C1r=o(" \u2014 "),yZ=a("a"),w1r=o("GPT2ForSequenceClassification"),A1r=o(" (OpenAI GPT-2 model)"),L1r=l(),BM=a("li"),$3e=a("strong"),y1r=o("gpt_neo"),x1r=o(" \u2014 "),xZ=a("a"),$1r=o("GPTNeoForSequenceClassification"),k1r=o(" (GPT Neo model)"),S1r=l(),IM=a("li"),k3e=a("strong"),R1r=o("gptj"),P1r=o(" \u2014 "),$Z=a("a"),B1r=o("GPTJForSequenceClassification"),I1r=o(" (GPT-J model)"),N1r=l(),NM=a("li"),S3e=a("strong"),q1r=o("ibert"),j1r=o(" \u2014 "),kZ=a("a"),D1r=o("IBertForSequenceClassification"),G1r=o(" (I-BERT model)"),O1r=l(),qM=a("li"),R3e=a("strong"),V1r=o("layoutlm"),X1r=o(" \u2014 "),SZ=a("a"),z1r=o("LayoutLMForSequenceClassification"),Q1r=o(" (LayoutLM model)"),W1r=l(),jM=a("li"),P3e=a("strong"),U1r=o("layoutlmv2"),H1r=o(" \u2014 "),RZ=a("a"),J1r=o("LayoutLMv2ForSequenceClassification"),Y1r=o(" (LayoutLMv2 model)"),Z1r=l(),DM=a("li"),B3e=a("strong"),K1r=o("layoutlmv3"),e2r=o(" \u2014 "),PZ=a("a"),o2r=o("LayoutLMv3ForSequenceClassification"),r2r=o(" (LayoutLMv3 model)"),t2r=l(),GM=a("li"),I3e=a("strong"),a2r=o("led"),n2r=o(" \u2014 "),BZ=a("a"),s2r=o("LEDForSequenceClassification"),l2r=o(" (LED model)"),i2r=l(),OM=a("li"),N3e=a("strong"),d2r=o("lilt"),m2r=o(" \u2014 "),IZ=a("a"),c2r=o("LiltForSequenceClassification"),f2r=o(" (LiLT model)"),g2r=l(),VM=a("li"),q3e=a("strong"),h2r=o("longformer"),u2r=o(" \u2014 "),NZ=a("a"),p2r=o("LongformerForSequenceClassification"),_2r=o(" (Longformer model)"),b2r=l(),XM=a("li"),j3e=a("strong"),v2r=o("luke"),F2r=o(" \u2014 "),qZ=a("a"),T2r=o("LukeForSequenceClassification"),M2r=o(" (LUKE model)"),E2r=l(),zM=a("li"),D3e=a("strong"),C2r=o("markuplm"),w2r=o(" \u2014 "),jZ=a("a"),A2r=o("MarkupLMForSequenceClassification"),L2r=o(" (MarkupLM model)"),y2r=l(),QM=a("li"),G3e=a("strong"),x2r=o("mbart"),$2r=o(" \u2014 "),DZ=a("a"),k2r=o("MBartForSequenceClassification"),S2r=o(" (mBART model)"),R2r=l(),WM=a("li"),O3e=a("strong"),P2r=o("megatron-bert"),B2r=o(" \u2014 "),GZ=a("a"),I2r=o("MegatronBertForSequenceClassification"),N2r=o(" (Megatron-BERT model)"),q2r=l(),UM=a("li"),V3e=a("strong"),j2r=o("mobilebert"),D2r=o(" \u2014 "),OZ=a("a"),G2r=o("MobileBertForSequenceClassification"),O2r=o(" (MobileBERT model)"),V2r=l(),HM=a("li"),X3e=a("strong"),X2r=o("mpnet"),z2r=o(" \u2014 "),VZ=a("a"),Q2r=o("MPNetForSequenceClassification"),W2r=o(" (MPNet model)"),U2r=l(),JM=a("li"),z3e=a("strong"),H2r=o("mvp"),J2r=o(" \u2014 "),XZ=a("a"),Y2r=o("MvpForSequenceClassification"),Z2r=o(" (MVP model)"),K2r=l(),YM=a("li"),Q3e=a("strong"),ebr=o("nezha"),obr=o(" \u2014 "),zZ=a("a"),rbr=o("NezhaForSequenceClassification"),tbr=o(" (Nezha model)"),abr=l(),ZM=a("li"),W3e=a("strong"),nbr=o("nystromformer"),sbr=o(" \u2014 "),QZ=a("a"),lbr=o("NystromformerForSequenceClassification"),ibr=o(" (Nystr\xF6mformer model)"),dbr=l(),KM=a("li"),U3e=a("strong"),mbr=o("openai-gpt"),cbr=o(" \u2014 "),WZ=a("a"),fbr=o("OpenAIGPTForSequenceClassification"),gbr=o(" (OpenAI GPT model)"),hbr=l(),eE=a("li"),H3e=a("strong"),ubr=o("opt"),pbr=o(" \u2014 "),UZ=a("a"),_br=o("OPTForSequenceClassification"),bbr=o(" (OPT model)"),vbr=l(),oE=a("li"),J3e=a("strong"),Fbr=o("perceiver"),Tbr=o(" \u2014 "),HZ=a("a"),Mbr=o("PerceiverForSequenceClassification"),Ebr=o(" (Perceiver model)"),Cbr=l(),rE=a("li"),Y3e=a("strong"),wbr=o("plbart"),Abr=o(" \u2014 "),JZ=a("a"),Lbr=o("PLBartForSequenceClassification"),ybr=o(" (PLBart model)"),xbr=l(),tE=a("li"),Z3e=a("strong"),$br=o("qdqbert"),kbr=o(" \u2014 "),YZ=a("a"),Sbr=o("QDQBertForSequenceClassification"),Rbr=o(" (QDQBert model)"),Pbr=l(),aE=a("li"),K3e=a("strong"),Bbr=o("reformer"),Ibr=o(" \u2014 "),ZZ=a("a"),Nbr=o("ReformerForSequenceClassification"),qbr=o(" (Reformer model)"),jbr=l(),nE=a("li"),e5e=a("strong"),Dbr=o("rembert"),Gbr=o(" \u2014 "),KZ=a("a"),Obr=o("RemBertForSequenceClassification"),Vbr=o(" (RemBERT model)"),Xbr=l(),sE=a("li"),o5e=a("strong"),zbr=o("roberta"),Qbr=o(" \u2014 "),eK=a("a"),Wbr=o("RobertaForSequenceClassification"),Ubr=o(" (RoBERTa model)"),Hbr=l(),lE=a("li"),r5e=a("strong"),Jbr=o("roc_bert"),Ybr=o(" \u2014 "),oK=a("a"),Zbr=o("RoCBertForSequenceClassification"),Kbr=o(" (RoCBert model)"),evr=l(),iE=a("li"),t5e=a("strong"),ovr=o("roformer"),rvr=o(" \u2014 "),rK=a("a"),tvr=o("RoFormerForSequenceClassification"),avr=o(" (RoFormer model)"),nvr=l(),dE=a("li"),a5e=a("strong"),svr=o("squeezebert"),lvr=o(" \u2014 "),tK=a("a"),ivr=o("SqueezeBertForSequenceClassification"),dvr=o(" (SqueezeBERT model)"),mvr=l(),mE=a("li"),n5e=a("strong"),cvr=o("tapas"),fvr=o(" \u2014 "),aK=a("a"),gvr=o("TapasForSequenceClassification"),hvr=o(" (TAPAS model)"),uvr=l(),cE=a("li"),s5e=a("strong"),pvr=o("transfo-xl"),_vr=o(" \u2014 "),nK=a("a"),bvr=o("TransfoXLForSequenceClassification"),vvr=o(" (Transformer-XL model)"),Fvr=l(),fE=a("li"),l5e=a("strong"),Tvr=o("xlm"),Mvr=o(" \u2014 "),sK=a("a"),Evr=o("XLMForSequenceClassification"),Cvr=o(" (XLM model)"),wvr=l(),gE=a("li"),i5e=a("strong"),Avr=o("xlm-roberta"),Lvr=o(" \u2014 "),lK=a("a"),yvr=o("XLMRobertaForSequenceClassification"),xvr=o(" (XLM-RoBERTa model)"),$vr=l(),hE=a("li"),d5e=a("strong"),kvr=o("xlm-roberta-xl"),Svr=o(" \u2014 "),iK=a("a"),Rvr=o("XLMRobertaXLForSequenceClassification"),Pvr=o(" (XLM-RoBERTa-XL model)"),Bvr=l(),uE=a("li"),m5e=a("strong"),Ivr=o("xlnet"),Nvr=o(" \u2014 "),dK=a("a"),qvr=o("XLNetForSequenceClassification"),jvr=o(" (XLNet model)"),Dvr=l(),pE=a("li"),c5e=a("strong"),Gvr=o("yoso"),Ovr=o(" \u2014 "),mK=a("a"),Vvr=o("YosoForSequenceClassification"),Xvr=o(" (YOSO model)"),zvr=l(),_E=a("p"),Qvr=o("The model is set in evaluation mode by default using "),f5e=a("code"),Wvr=o("model.eval()"),Uvr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),g5e=a("code"),Hvr=o("model.train()"),Jvr=l(),F(bE.$$.fragment),tio=l(),im=a("h2"),vE=a("a"),h5e=a("span"),F(xS.$$.fragment),Yvr=l(),u5e=a("span"),Zvr=o("AutoModelForMultipleChoice"),aio=l(),Wo=a("div"),F($S.$$.fragment),Kvr=l(),dm=a("p"),eFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),cK=a("a"),oFr=o("from_pretrained()"),rFr=o(" class method or the "),fK=a("a"),tFr=o("from_config()"),aFr=o(` class
method.`),nFr=l(),kS=a("p"),sFr=o("This class cannot be instantiated directly using "),p5e=a("code"),lFr=o("__init__()"),iFr=o(" (throws an error)."),dFr=l(),Rt=a("div"),F(SS.$$.fragment),mFr=l(),_5e=a("p"),cFr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),fFr=l(),mm=a("p"),gFr=o(`Note:
Loading a model from its configuration file does `),b5e=a("strong"),hFr=o("not"),uFr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gK=a("a"),pFr=o("from_pretrained()"),_Fr=o(" to load the model weights."),bFr=l(),F(FE.$$.fragment),vFr=l(),co=a("div"),F(RS.$$.fragment),FFr=l(),v5e=a("p"),TFr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),MFr=l(),vn=a("p"),EFr=o("The model class to instantiate is selected based on the "),F5e=a("code"),CFr=o("model_type"),wFr=o(` property of the config object (either
passed as an argument or loaded from `),T5e=a("code"),AFr=o("pretrained_model_name_or_path"),LFr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M5e=a("code"),yFr=o("pretrained_model_name_or_path"),xFr=o(":"),$Fr=l(),K=a("ul"),TE=a("li"),E5e=a("strong"),kFr=o("albert"),SFr=o(" \u2014 "),hK=a("a"),RFr=o("AlbertForMultipleChoice"),PFr=o(" (ALBERT model)"),BFr=l(),ME=a("li"),C5e=a("strong"),IFr=o("bert"),NFr=o(" \u2014 "),uK=a("a"),qFr=o("BertForMultipleChoice"),jFr=o(" (BERT model)"),DFr=l(),EE=a("li"),w5e=a("strong"),GFr=o("big_bird"),OFr=o(" \u2014 "),pK=a("a"),VFr=o("BigBirdForMultipleChoice"),XFr=o(" (BigBird model)"),zFr=l(),CE=a("li"),A5e=a("strong"),QFr=o("camembert"),WFr=o(" \u2014 "),_K=a("a"),UFr=o("CamembertForMultipleChoice"),HFr=o(" (CamemBERT model)"),JFr=l(),wE=a("li"),L5e=a("strong"),YFr=o("canine"),ZFr=o(" \u2014 "),bK=a("a"),KFr=o("CanineForMultipleChoice"),eTr=o(" (CANINE model)"),oTr=l(),AE=a("li"),y5e=a("strong"),rTr=o("convbert"),tTr=o(" \u2014 "),vK=a("a"),aTr=o("ConvBertForMultipleChoice"),nTr=o(" (ConvBERT model)"),sTr=l(),LE=a("li"),x5e=a("strong"),lTr=o("data2vec-text"),iTr=o(" \u2014 "),FK=a("a"),dTr=o("Data2VecTextForMultipleChoice"),mTr=o(" (Data2VecText model)"),cTr=l(),yE=a("li"),$5e=a("strong"),fTr=o("deberta-v2"),gTr=o(" \u2014 "),TK=a("a"),hTr=o("DebertaV2ForMultipleChoice"),uTr=o(" (DeBERTa-v2 model)"),pTr=l(),xE=a("li"),k5e=a("strong"),_Tr=o("distilbert"),bTr=o(" \u2014 "),MK=a("a"),vTr=o("DistilBertForMultipleChoice"),FTr=o(" (DistilBERT model)"),TTr=l(),$E=a("li"),S5e=a("strong"),MTr=o("electra"),ETr=o(" \u2014 "),EK=a("a"),CTr=o("ElectraForMultipleChoice"),wTr=o(" (ELECTRA model)"),ATr=l(),kE=a("li"),R5e=a("strong"),LTr=o("ernie"),yTr=o(" \u2014 "),CK=a("a"),xTr=o("ErnieForMultipleChoice"),$Tr=o(" (ERNIE model)"),kTr=l(),SE=a("li"),P5e=a("strong"),STr=o("flaubert"),RTr=o(" \u2014 "),wK=a("a"),PTr=o("FlaubertForMultipleChoice"),BTr=o(" (FlauBERT model)"),ITr=l(),RE=a("li"),B5e=a("strong"),NTr=o("fnet"),qTr=o(" \u2014 "),AK=a("a"),jTr=o("FNetForMultipleChoice"),DTr=o(" (FNet model)"),GTr=l(),PE=a("li"),I5e=a("strong"),OTr=o("funnel"),VTr=o(" \u2014 "),LK=a("a"),XTr=o("FunnelForMultipleChoice"),zTr=o(" (Funnel Transformer model)"),QTr=l(),BE=a("li"),N5e=a("strong"),WTr=o("ibert"),UTr=o(" \u2014 "),yK=a("a"),HTr=o("IBertForMultipleChoice"),JTr=o(" (I-BERT model)"),YTr=l(),IE=a("li"),q5e=a("strong"),ZTr=o("longformer"),KTr=o(" \u2014 "),xK=a("a"),eMr=o("LongformerForMultipleChoice"),oMr=o(" (Longformer model)"),rMr=l(),NE=a("li"),j5e=a("strong"),tMr=o("luke"),aMr=o(" \u2014 "),$K=a("a"),nMr=o("LukeForMultipleChoice"),sMr=o(" (LUKE model)"),lMr=l(),qE=a("li"),D5e=a("strong"),iMr=o("megatron-bert"),dMr=o(" \u2014 "),kK=a("a"),mMr=o("MegatronBertForMultipleChoice"),cMr=o(" (Megatron-BERT model)"),fMr=l(),jE=a("li"),G5e=a("strong"),gMr=o("mobilebert"),hMr=o(" \u2014 "),SK=a("a"),uMr=o("MobileBertForMultipleChoice"),pMr=o(" (MobileBERT model)"),_Mr=l(),DE=a("li"),O5e=a("strong"),bMr=o("mpnet"),vMr=o(" \u2014 "),RK=a("a"),FMr=o("MPNetForMultipleChoice"),TMr=o(" (MPNet model)"),MMr=l(),GE=a("li"),V5e=a("strong"),EMr=o("nezha"),CMr=o(" \u2014 "),PK=a("a"),wMr=o("NezhaForMultipleChoice"),AMr=o(" (Nezha model)"),LMr=l(),OE=a("li"),X5e=a("strong"),yMr=o("nystromformer"),xMr=o(" \u2014 "),BK=a("a"),$Mr=o("NystromformerForMultipleChoice"),kMr=o(" (Nystr\xF6mformer model)"),SMr=l(),VE=a("li"),z5e=a("strong"),RMr=o("qdqbert"),PMr=o(" \u2014 "),IK=a("a"),BMr=o("QDQBertForMultipleChoice"),IMr=o(" (QDQBert model)"),NMr=l(),XE=a("li"),Q5e=a("strong"),qMr=o("rembert"),jMr=o(" \u2014 "),NK=a("a"),DMr=o("RemBertForMultipleChoice"),GMr=o(" (RemBERT model)"),OMr=l(),zE=a("li"),W5e=a("strong"),VMr=o("roberta"),XMr=o(" \u2014 "),qK=a("a"),zMr=o("RobertaForMultipleChoice"),QMr=o(" (RoBERTa model)"),WMr=l(),QE=a("li"),U5e=a("strong"),UMr=o("roc_bert"),HMr=o(" \u2014 "),jK=a("a"),JMr=o("RoCBertForMultipleChoice"),YMr=o(" (RoCBert model)"),ZMr=l(),WE=a("li"),H5e=a("strong"),KMr=o("roformer"),eEr=o(" \u2014 "),DK=a("a"),oEr=o("RoFormerForMultipleChoice"),rEr=o(" (RoFormer model)"),tEr=l(),UE=a("li"),J5e=a("strong"),aEr=o("squeezebert"),nEr=o(" \u2014 "),GK=a("a"),sEr=o("SqueezeBertForMultipleChoice"),lEr=o(" (SqueezeBERT model)"),iEr=l(),HE=a("li"),Y5e=a("strong"),dEr=o("xlm"),mEr=o(" \u2014 "),OK=a("a"),cEr=o("XLMForMultipleChoice"),fEr=o(" (XLM model)"),gEr=l(),JE=a("li"),Z5e=a("strong"),hEr=o("xlm-roberta"),uEr=o(" \u2014 "),VK=a("a"),pEr=o("XLMRobertaForMultipleChoice"),_Er=o(" (XLM-RoBERTa model)"),bEr=l(),YE=a("li"),K5e=a("strong"),vEr=o("xlm-roberta-xl"),FEr=o(" \u2014 "),XK=a("a"),TEr=o("XLMRobertaXLForMultipleChoice"),MEr=o(" (XLM-RoBERTa-XL model)"),EEr=l(),ZE=a("li"),e0e=a("strong"),CEr=o("xlnet"),wEr=o(" \u2014 "),zK=a("a"),AEr=o("XLNetForMultipleChoice"),LEr=o(" (XLNet model)"),yEr=l(),KE=a("li"),o0e=a("strong"),xEr=o("yoso"),$Er=o(" \u2014 "),QK=a("a"),kEr=o("YosoForMultipleChoice"),SEr=o(" (YOSO model)"),REr=l(),e4=a("p"),PEr=o("The model is set in evaluation mode by default using "),r0e=a("code"),BEr=o("model.eval()"),IEr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),t0e=a("code"),NEr=o("model.train()"),qEr=l(),F(o4.$$.fragment),nio=l(),cm=a("h2"),r4=a("a"),a0e=a("span"),F(PS.$$.fragment),jEr=l(),n0e=a("span"),DEr=o("AutoModelForNextSentencePrediction"),sio=l(),Uo=a("div"),F(BS.$$.fragment),GEr=l(),fm=a("p"),OEr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),WK=a("a"),VEr=o("from_pretrained()"),XEr=o(" class method or the "),UK=a("a"),zEr=o("from_config()"),QEr=o(` class
method.`),WEr=l(),IS=a("p"),UEr=o("This class cannot be instantiated directly using "),s0e=a("code"),HEr=o("__init__()"),JEr=o(" (throws an error)."),YEr=l(),Pt=a("div"),F(NS.$$.fragment),ZEr=l(),l0e=a("p"),KEr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),e4r=l(),gm=a("p"),o4r=o(`Note:
Loading a model from its configuration file does `),i0e=a("strong"),r4r=o("not"),t4r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),HK=a("a"),a4r=o("from_pretrained()"),n4r=o(" to load the model weights."),s4r=l(),F(t4.$$.fragment),l4r=l(),fo=a("div"),F(qS.$$.fragment),i4r=l(),d0e=a("p"),d4r=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),m4r=l(),Fn=a("p"),c4r=o("The model class to instantiate is selected based on the "),m0e=a("code"),f4r=o("model_type"),g4r=o(` property of the config object (either
passed as an argument or loaded from `),c0e=a("code"),h4r=o("pretrained_model_name_or_path"),u4r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f0e=a("code"),p4r=o("pretrained_model_name_or_path"),_4r=o(":"),b4r=l(),Ye=a("ul"),a4=a("li"),g0e=a("strong"),v4r=o("bert"),F4r=o(" \u2014 "),JK=a("a"),T4r=o("BertForNextSentencePrediction"),M4r=o(" (BERT model)"),E4r=l(),n4=a("li"),h0e=a("strong"),C4r=o("ernie"),w4r=o(" \u2014 "),YK=a("a"),A4r=o("ErnieForNextSentencePrediction"),L4r=o(" (ERNIE model)"),y4r=l(),s4=a("li"),u0e=a("strong"),x4r=o("fnet"),$4r=o(" \u2014 "),ZK=a("a"),k4r=o("FNetForNextSentencePrediction"),S4r=o(" (FNet model)"),R4r=l(),l4=a("li"),p0e=a("strong"),P4r=o("megatron-bert"),B4r=o(" \u2014 "),KK=a("a"),I4r=o("MegatronBertForNextSentencePrediction"),N4r=o(" (Megatron-BERT model)"),q4r=l(),i4=a("li"),_0e=a("strong"),j4r=o("mobilebert"),D4r=o(" \u2014 "),eee=a("a"),G4r=o("MobileBertForNextSentencePrediction"),O4r=o(" (MobileBERT model)"),V4r=l(),d4=a("li"),b0e=a("strong"),X4r=o("nezha"),z4r=o(" \u2014 "),oee=a("a"),Q4r=o("NezhaForNextSentencePrediction"),W4r=o(" (Nezha model)"),U4r=l(),m4=a("li"),v0e=a("strong"),H4r=o("qdqbert"),J4r=o(" \u2014 "),ree=a("a"),Y4r=o("QDQBertForNextSentencePrediction"),Z4r=o(" (QDQBert model)"),K4r=l(),c4=a("p"),eCr=o("The model is set in evaluation mode by default using "),F0e=a("code"),oCr=o("model.eval()"),rCr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),T0e=a("code"),tCr=o("model.train()"),aCr=l(),F(f4.$$.fragment),lio=l(),hm=a("h2"),g4=a("a"),M0e=a("span"),F(jS.$$.fragment),nCr=l(),E0e=a("span"),sCr=o("AutoModelForTokenClassification"),iio=l(),Ho=a("div"),F(DS.$$.fragment),lCr=l(),um=a("p"),iCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),tee=a("a"),dCr=o("from_pretrained()"),mCr=o(" class method or the "),aee=a("a"),cCr=o("from_config()"),fCr=o(` class
method.`),gCr=l(),GS=a("p"),hCr=o("This class cannot be instantiated directly using "),C0e=a("code"),uCr=o("__init__()"),pCr=o(" (throws an error)."),_Cr=l(),Bt=a("div"),F(OS.$$.fragment),bCr=l(),w0e=a("p"),vCr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),FCr=l(),pm=a("p"),TCr=o(`Note:
Loading a model from its configuration file does `),A0e=a("strong"),MCr=o("not"),ECr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nee=a("a"),CCr=o("from_pretrained()"),wCr=o(" to load the model weights."),ACr=l(),F(h4.$$.fragment),LCr=l(),go=a("div"),F(VS.$$.fragment),yCr=l(),L0e=a("p"),xCr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),$Cr=l(),Tn=a("p"),kCr=o("The model class to instantiate is selected based on the "),y0e=a("code"),SCr=o("model_type"),RCr=o(` property of the config object (either
passed as an argument or loaded from `),x0e=a("code"),PCr=o("pretrained_model_name_or_path"),BCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$0e=a("code"),ICr=o("pretrained_model_name_or_path"),NCr=o(":"),qCr=l(),U=a("ul"),u4=a("li"),k0e=a("strong"),jCr=o("albert"),DCr=o(" \u2014 "),see=a("a"),GCr=o("AlbertForTokenClassification"),OCr=o(" (ALBERT model)"),VCr=l(),p4=a("li"),S0e=a("strong"),XCr=o("bert"),zCr=o(" \u2014 "),lee=a("a"),QCr=o("BertForTokenClassification"),WCr=o(" (BERT model)"),UCr=l(),_4=a("li"),R0e=a("strong"),HCr=o("big_bird"),JCr=o(" \u2014 "),iee=a("a"),YCr=o("BigBirdForTokenClassification"),ZCr=o(" (BigBird model)"),KCr=l(),b4=a("li"),P0e=a("strong"),e3r=o("bloom"),o3r=o(" \u2014 "),dee=a("a"),r3r=o("BloomForTokenClassification"),t3r=o(" (BLOOM model)"),a3r=l(),v4=a("li"),B0e=a("strong"),n3r=o("camembert"),s3r=o(" \u2014 "),mee=a("a"),l3r=o("CamembertForTokenClassification"),i3r=o(" (CamemBERT model)"),d3r=l(),F4=a("li"),I0e=a("strong"),m3r=o("canine"),c3r=o(" \u2014 "),cee=a("a"),f3r=o("CanineForTokenClassification"),g3r=o(" (CANINE model)"),h3r=l(),T4=a("li"),N0e=a("strong"),u3r=o("convbert"),p3r=o(" \u2014 "),fee=a("a"),_3r=o("ConvBertForTokenClassification"),b3r=o(" (ConvBERT model)"),v3r=l(),M4=a("li"),q0e=a("strong"),F3r=o("data2vec-text"),T3r=o(" \u2014 "),gee=a("a"),M3r=o("Data2VecTextForTokenClassification"),E3r=o(" (Data2VecText model)"),C3r=l(),E4=a("li"),j0e=a("strong"),w3r=o("deberta"),A3r=o(" \u2014 "),hee=a("a"),L3r=o("DebertaForTokenClassification"),y3r=o(" (DeBERTa model)"),x3r=l(),C4=a("li"),D0e=a("strong"),$3r=o("deberta-v2"),k3r=o(" \u2014 "),uee=a("a"),S3r=o("DebertaV2ForTokenClassification"),R3r=o(" (DeBERTa-v2 model)"),P3r=l(),w4=a("li"),G0e=a("strong"),B3r=o("distilbert"),I3r=o(" \u2014 "),pee=a("a"),N3r=o("DistilBertForTokenClassification"),q3r=o(" (DistilBERT model)"),j3r=l(),A4=a("li"),O0e=a("strong"),D3r=o("electra"),G3r=o(" \u2014 "),_ee=a("a"),O3r=o("ElectraForTokenClassification"),V3r=o(" (ELECTRA model)"),X3r=l(),L4=a("li"),V0e=a("strong"),z3r=o("ernie"),Q3r=o(" \u2014 "),bee=a("a"),W3r=o("ErnieForTokenClassification"),U3r=o(" (ERNIE model)"),H3r=l(),y4=a("li"),X0e=a("strong"),J3r=o("esm"),Y3r=o(" \u2014 "),vee=a("a"),Z3r=o("EsmForTokenClassification"),K3r=o(" (ESM model)"),e5r=l(),x4=a("li"),z0e=a("strong"),o5r=o("flaubert"),r5r=o(" \u2014 "),Fee=a("a"),t5r=o("FlaubertForTokenClassification"),a5r=o(" (FlauBERT model)"),n5r=l(),$4=a("li"),Q0e=a("strong"),s5r=o("fnet"),l5r=o(" \u2014 "),Tee=a("a"),i5r=o("FNetForTokenClassification"),d5r=o(" (FNet model)"),m5r=l(),k4=a("li"),W0e=a("strong"),c5r=o("funnel"),f5r=o(" \u2014 "),Mee=a("a"),g5r=o("FunnelForTokenClassification"),h5r=o(" (Funnel Transformer model)"),u5r=l(),S4=a("li"),U0e=a("strong"),p5r=o("gpt2"),_5r=o(" \u2014 "),Eee=a("a"),b5r=o("GPT2ForTokenClassification"),v5r=o(" (OpenAI GPT-2 model)"),F5r=l(),R4=a("li"),H0e=a("strong"),T5r=o("ibert"),M5r=o(" \u2014 "),Cee=a("a"),E5r=o("IBertForTokenClassification"),C5r=o(" (I-BERT model)"),w5r=l(),P4=a("li"),J0e=a("strong"),A5r=o("layoutlm"),L5r=o(" \u2014 "),wee=a("a"),y5r=o("LayoutLMForTokenClassification"),x5r=o(" (LayoutLM model)"),$5r=l(),B4=a("li"),Y0e=a("strong"),k5r=o("layoutlmv2"),S5r=o(" \u2014 "),Aee=a("a"),R5r=o("LayoutLMv2ForTokenClassification"),P5r=o(" (LayoutLMv2 model)"),B5r=l(),I4=a("li"),Z0e=a("strong"),I5r=o("layoutlmv3"),N5r=o(" \u2014 "),Lee=a("a"),q5r=o("LayoutLMv3ForTokenClassification"),j5r=o(" (LayoutLMv3 model)"),D5r=l(),N4=a("li"),K0e=a("strong"),G5r=o("lilt"),O5r=o(" \u2014 "),yee=a("a"),V5r=o("LiltForTokenClassification"),X5r=o(" (LiLT model)"),z5r=l(),q4=a("li"),ewe=a("strong"),Q5r=o("longformer"),W5r=o(" \u2014 "),xee=a("a"),U5r=o("LongformerForTokenClassification"),H5r=o(" (Longformer model)"),J5r=l(),j4=a("li"),owe=a("strong"),Y5r=o("luke"),Z5r=o(" \u2014 "),$ee=a("a"),K5r=o("LukeForTokenClassification"),e0r=o(" (LUKE model)"),o0r=l(),D4=a("li"),rwe=a("strong"),r0r=o("markuplm"),t0r=o(" \u2014 "),kee=a("a"),a0r=o("MarkupLMForTokenClassification"),n0r=o(" (MarkupLM model)"),s0r=l(),G4=a("li"),twe=a("strong"),l0r=o("megatron-bert"),i0r=o(" \u2014 "),See=a("a"),d0r=o("MegatronBertForTokenClassification"),m0r=o(" (Megatron-BERT model)"),c0r=l(),O4=a("li"),awe=a("strong"),f0r=o("mobilebert"),g0r=o(" \u2014 "),Ree=a("a"),h0r=o("MobileBertForTokenClassification"),u0r=o(" (MobileBERT model)"),p0r=l(),V4=a("li"),nwe=a("strong"),_0r=o("mpnet"),b0r=o(" \u2014 "),Pee=a("a"),v0r=o("MPNetForTokenClassification"),F0r=o(" (MPNet model)"),T0r=l(),X4=a("li"),swe=a("strong"),M0r=o("nezha"),E0r=o(" \u2014 "),Bee=a("a"),C0r=o("NezhaForTokenClassification"),w0r=o(" (Nezha model)"),A0r=l(),z4=a("li"),lwe=a("strong"),L0r=o("nystromformer"),y0r=o(" \u2014 "),Iee=a("a"),x0r=o("NystromformerForTokenClassification"),$0r=o(" (Nystr\xF6mformer model)"),k0r=l(),Q4=a("li"),iwe=a("strong"),S0r=o("qdqbert"),R0r=o(" \u2014 "),Nee=a("a"),P0r=o("QDQBertForTokenClassification"),B0r=o(" (QDQBert model)"),I0r=l(),W4=a("li"),dwe=a("strong"),N0r=o("rembert"),q0r=o(" \u2014 "),qee=a("a"),j0r=o("RemBertForTokenClassification"),D0r=o(" (RemBERT model)"),G0r=l(),U4=a("li"),mwe=a("strong"),O0r=o("roberta"),V0r=o(" \u2014 "),jee=a("a"),X0r=o("RobertaForTokenClassification"),z0r=o(" (RoBERTa model)"),Q0r=l(),H4=a("li"),cwe=a("strong"),W0r=o("roc_bert"),U0r=o(" \u2014 "),Dee=a("a"),H0r=o("RoCBertForTokenClassification"),J0r=o(" (RoCBert model)"),Y0r=l(),J4=a("li"),fwe=a("strong"),Z0r=o("roformer"),K0r=o(" \u2014 "),Gee=a("a"),ewr=o("RoFormerForTokenClassification"),owr=o(" (RoFormer model)"),rwr=l(),Y4=a("li"),gwe=a("strong"),twr=o("squeezebert"),awr=o(" \u2014 "),Oee=a("a"),nwr=o("SqueezeBertForTokenClassification"),swr=o(" (SqueezeBERT model)"),lwr=l(),Z4=a("li"),hwe=a("strong"),iwr=o("xlm"),dwr=o(" \u2014 "),Vee=a("a"),mwr=o("XLMForTokenClassification"),cwr=o(" (XLM model)"),fwr=l(),K4=a("li"),uwe=a("strong"),gwr=o("xlm-roberta"),hwr=o(" \u2014 "),Xee=a("a"),uwr=o("XLMRobertaForTokenClassification"),pwr=o(" (XLM-RoBERTa model)"),_wr=l(),eC=a("li"),pwe=a("strong"),bwr=o("xlm-roberta-xl"),vwr=o(" \u2014 "),zee=a("a"),Fwr=o("XLMRobertaXLForTokenClassification"),Twr=o(" (XLM-RoBERTa-XL model)"),Mwr=l(),oC=a("li"),_we=a("strong"),Ewr=o("xlnet"),Cwr=o(" \u2014 "),Qee=a("a"),wwr=o("XLNetForTokenClassification"),Awr=o(" (XLNet model)"),Lwr=l(),rC=a("li"),bwe=a("strong"),ywr=o("yoso"),xwr=o(" \u2014 "),Wee=a("a"),$wr=o("YosoForTokenClassification"),kwr=o(" (YOSO model)"),Swr=l(),tC=a("p"),Rwr=o("The model is set in evaluation mode by default using "),vwe=a("code"),Pwr=o("model.eval()"),Bwr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Fwe=a("code"),Iwr=o("model.train()"),Nwr=l(),F(aC.$$.fragment),dio=l(),_m=a("h2"),nC=a("a"),Twe=a("span"),F(XS.$$.fragment),qwr=l(),Mwe=a("span"),jwr=o("AutoModelForQuestionAnswering"),mio=l(),Jo=a("div"),F(zS.$$.fragment),Dwr=l(),bm=a("p"),Gwr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Uee=a("a"),Owr=o("from_pretrained()"),Vwr=o(" class method or the "),Hee=a("a"),Xwr=o("from_config()"),zwr=o(` class
method.`),Qwr=l(),QS=a("p"),Wwr=o("This class cannot be instantiated directly using "),Ewe=a("code"),Uwr=o("__init__()"),Hwr=o(" (throws an error)."),Jwr=l(),It=a("div"),F(WS.$$.fragment),Ywr=l(),Cwe=a("p"),Zwr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Kwr=l(),vm=a("p"),eAr=o(`Note:
Loading a model from its configuration file does `),wwe=a("strong"),oAr=o("not"),rAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Jee=a("a"),tAr=o("from_pretrained()"),aAr=o(" to load the model weights."),nAr=l(),F(sC.$$.fragment),sAr=l(),ho=a("div"),F(US.$$.fragment),lAr=l(),Awe=a("p"),iAr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),dAr=l(),Mn=a("p"),mAr=o("The model class to instantiate is selected based on the "),Lwe=a("code"),cAr=o("model_type"),fAr=o(` property of the config object (either
passed as an argument or loaded from `),ywe=a("code"),gAr=o("pretrained_model_name_or_path"),hAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xwe=a("code"),uAr=o("pretrained_model_name_or_path"),pAr=o(":"),_Ar=l(),O=a("ul"),lC=a("li"),$we=a("strong"),bAr=o("albert"),vAr=o(" \u2014 "),Yee=a("a"),FAr=o("AlbertForQuestionAnswering"),TAr=o(" (ALBERT model)"),MAr=l(),iC=a("li"),kwe=a("strong"),EAr=o("bart"),CAr=o(" \u2014 "),Zee=a("a"),wAr=o("BartForQuestionAnswering"),AAr=o(" (BART model)"),LAr=l(),dC=a("li"),Swe=a("strong"),yAr=o("bert"),xAr=o(" \u2014 "),Kee=a("a"),$Ar=o("BertForQuestionAnswering"),kAr=o(" (BERT model)"),SAr=l(),mC=a("li"),Rwe=a("strong"),RAr=o("big_bird"),PAr=o(" \u2014 "),eoe=a("a"),BAr=o("BigBirdForQuestionAnswering"),IAr=o(" (BigBird model)"),NAr=l(),cC=a("li"),Pwe=a("strong"),qAr=o("bigbird_pegasus"),jAr=o(" \u2014 "),ooe=a("a"),DAr=o("BigBirdPegasusForQuestionAnswering"),GAr=o(" (BigBird-Pegasus model)"),OAr=l(),fC=a("li"),Bwe=a("strong"),VAr=o("bloom"),XAr=o(" \u2014 "),roe=a("a"),zAr=o("BloomForQuestionAnswering"),QAr=o(" (BLOOM model)"),WAr=l(),gC=a("li"),Iwe=a("strong"),UAr=o("camembert"),HAr=o(" \u2014 "),toe=a("a"),JAr=o("CamembertForQuestionAnswering"),YAr=o(" (CamemBERT model)"),ZAr=l(),hC=a("li"),Nwe=a("strong"),KAr=o("canine"),e6r=o(" \u2014 "),aoe=a("a"),o6r=o("CanineForQuestionAnswering"),r6r=o(" (CANINE model)"),t6r=l(),uC=a("li"),qwe=a("strong"),a6r=o("convbert"),n6r=o(" \u2014 "),noe=a("a"),s6r=o("ConvBertForQuestionAnswering"),l6r=o(" (ConvBERT model)"),i6r=l(),pC=a("li"),jwe=a("strong"),d6r=o("data2vec-text"),m6r=o(" \u2014 "),soe=a("a"),c6r=o("Data2VecTextForQuestionAnswering"),f6r=o(" (Data2VecText model)"),g6r=l(),_C=a("li"),Dwe=a("strong"),h6r=o("deberta"),u6r=o(" \u2014 "),loe=a("a"),p6r=o("DebertaForQuestionAnswering"),_6r=o(" (DeBERTa model)"),b6r=l(),bC=a("li"),Gwe=a("strong"),v6r=o("deberta-v2"),F6r=o(" \u2014 "),ioe=a("a"),T6r=o("DebertaV2ForQuestionAnswering"),M6r=o(" (DeBERTa-v2 model)"),E6r=l(),vC=a("li"),Owe=a("strong"),C6r=o("distilbert"),w6r=o(" \u2014 "),doe=a("a"),A6r=o("DistilBertForQuestionAnswering"),L6r=o(" (DistilBERT model)"),y6r=l(),FC=a("li"),Vwe=a("strong"),x6r=o("electra"),$6r=o(" \u2014 "),moe=a("a"),k6r=o("ElectraForQuestionAnswering"),S6r=o(" (ELECTRA model)"),R6r=l(),TC=a("li"),Xwe=a("strong"),P6r=o("ernie"),B6r=o(" \u2014 "),coe=a("a"),I6r=o("ErnieForQuestionAnswering"),N6r=o(" (ERNIE model)"),q6r=l(),MC=a("li"),zwe=a("strong"),j6r=o("flaubert"),D6r=o(" \u2014 "),foe=a("a"),G6r=o("FlaubertForQuestionAnsweringSimple"),O6r=o(" (FlauBERT model)"),V6r=l(),EC=a("li"),Qwe=a("strong"),X6r=o("fnet"),z6r=o(" \u2014 "),goe=a("a"),Q6r=o("FNetForQuestionAnswering"),W6r=o(" (FNet model)"),U6r=l(),CC=a("li"),Wwe=a("strong"),H6r=o("funnel"),J6r=o(" \u2014 "),hoe=a("a"),Y6r=o("FunnelForQuestionAnswering"),Z6r=o(" (Funnel Transformer model)"),K6r=l(),wC=a("li"),Uwe=a("strong"),e7r=o("gptj"),o7r=o(" \u2014 "),uoe=a("a"),r7r=o("GPTJForQuestionAnswering"),t7r=o(" (GPT-J model)"),a7r=l(),AC=a("li"),Hwe=a("strong"),n7r=o("ibert"),s7r=o(" \u2014 "),poe=a("a"),l7r=o("IBertForQuestionAnswering"),i7r=o(" (I-BERT model)"),d7r=l(),LC=a("li"),Jwe=a("strong"),m7r=o("layoutlmv2"),c7r=o(" \u2014 "),_oe=a("a"),f7r=o("LayoutLMv2ForQuestionAnswering"),g7r=o(" (LayoutLMv2 model)"),h7r=l(),yC=a("li"),Ywe=a("strong"),u7r=o("layoutlmv3"),p7r=o(" \u2014 "),boe=a("a"),_7r=o("LayoutLMv3ForQuestionAnswering"),b7r=o(" (LayoutLMv3 model)"),v7r=l(),xC=a("li"),Zwe=a("strong"),F7r=o("led"),T7r=o(" \u2014 "),voe=a("a"),M7r=o("LEDForQuestionAnswering"),E7r=o(" (LED model)"),C7r=l(),$C=a("li"),Kwe=a("strong"),w7r=o("lilt"),A7r=o(" \u2014 "),Foe=a("a"),L7r=o("LiltForQuestionAnswering"),y7r=o(" (LiLT model)"),x7r=l(),kC=a("li"),eAe=a("strong"),$7r=o("longformer"),k7r=o(" \u2014 "),Toe=a("a"),S7r=o("LongformerForQuestionAnswering"),R7r=o(" (Longformer model)"),P7r=l(),SC=a("li"),oAe=a("strong"),B7r=o("luke"),I7r=o(" \u2014 "),Moe=a("a"),N7r=o("LukeForQuestionAnswering"),q7r=o(" (LUKE model)"),j7r=l(),RC=a("li"),rAe=a("strong"),D7r=o("lxmert"),G7r=o(" \u2014 "),Eoe=a("a"),O7r=o("LxmertForQuestionAnswering"),V7r=o(" (LXMERT model)"),X7r=l(),PC=a("li"),tAe=a("strong"),z7r=o("markuplm"),Q7r=o(" \u2014 "),Coe=a("a"),W7r=o("MarkupLMForQuestionAnswering"),U7r=o(" (MarkupLM model)"),H7r=l(),BC=a("li"),aAe=a("strong"),J7r=o("mbart"),Y7r=o(" \u2014 "),woe=a("a"),Z7r=o("MBartForQuestionAnswering"),K7r=o(" (mBART model)"),e8r=l(),IC=a("li"),nAe=a("strong"),o8r=o("megatron-bert"),r8r=o(" \u2014 "),Aoe=a("a"),t8r=o("MegatronBertForQuestionAnswering"),a8r=o(" (Megatron-BERT model)"),n8r=l(),NC=a("li"),sAe=a("strong"),s8r=o("mobilebert"),l8r=o(" \u2014 "),Loe=a("a"),i8r=o("MobileBertForQuestionAnswering"),d8r=o(" (MobileBERT model)"),m8r=l(),qC=a("li"),lAe=a("strong"),c8r=o("mpnet"),f8r=o(" \u2014 "),yoe=a("a"),g8r=o("MPNetForQuestionAnswering"),h8r=o(" (MPNet model)"),u8r=l(),jC=a("li"),iAe=a("strong"),p8r=o("mvp"),_8r=o(" \u2014 "),xoe=a("a"),b8r=o("MvpForQuestionAnswering"),v8r=o(" (MVP model)"),F8r=l(),DC=a("li"),dAe=a("strong"),T8r=o("nezha"),M8r=o(" \u2014 "),$oe=a("a"),E8r=o("NezhaForQuestionAnswering"),C8r=o(" (Nezha model)"),w8r=l(),GC=a("li"),mAe=a("strong"),A8r=o("nystromformer"),L8r=o(" \u2014 "),koe=a("a"),y8r=o("NystromformerForQuestionAnswering"),x8r=o(" (Nystr\xF6mformer model)"),$8r=l(),OC=a("li"),cAe=a("strong"),k8r=o("opt"),S8r=o(" \u2014 "),Soe=a("a"),R8r=o("OPTForQuestionAnswering"),P8r=o(" (OPT model)"),B8r=l(),VC=a("li"),fAe=a("strong"),I8r=o("qdqbert"),N8r=o(" \u2014 "),Roe=a("a"),q8r=o("QDQBertForQuestionAnswering"),j8r=o(" (QDQBert model)"),D8r=l(),XC=a("li"),gAe=a("strong"),G8r=o("reformer"),O8r=o(" \u2014 "),Poe=a("a"),V8r=o("ReformerForQuestionAnswering"),X8r=o(" (Reformer model)"),z8r=l(),zC=a("li"),hAe=a("strong"),Q8r=o("rembert"),W8r=o(" \u2014 "),Boe=a("a"),U8r=o("RemBertForQuestionAnswering"),H8r=o(" (RemBERT model)"),J8r=l(),QC=a("li"),uAe=a("strong"),Y8r=o("roberta"),Z8r=o(" \u2014 "),Ioe=a("a"),K8r=o("RobertaForQuestionAnswering"),eLr=o(" (RoBERTa model)"),oLr=l(),WC=a("li"),pAe=a("strong"),rLr=o("roc_bert"),tLr=o(" \u2014 "),Noe=a("a"),aLr=o("RoCBertForQuestionAnswering"),nLr=o(" (RoCBert model)"),sLr=l(),UC=a("li"),_Ae=a("strong"),lLr=o("roformer"),iLr=o(" \u2014 "),qoe=a("a"),dLr=o("RoFormerForQuestionAnswering"),mLr=o(" (RoFormer model)"),cLr=l(),HC=a("li"),bAe=a("strong"),fLr=o("splinter"),gLr=o(" \u2014 "),joe=a("a"),hLr=o("SplinterForQuestionAnswering"),uLr=o(" (Splinter model)"),pLr=l(),JC=a("li"),vAe=a("strong"),_Lr=o("squeezebert"),bLr=o(" \u2014 "),Doe=a("a"),vLr=o("SqueezeBertForQuestionAnswering"),FLr=o(" (SqueezeBERT model)"),TLr=l(),YC=a("li"),FAe=a("strong"),MLr=o("xlm"),ELr=o(" \u2014 "),Goe=a("a"),CLr=o("XLMForQuestionAnsweringSimple"),wLr=o(" (XLM model)"),ALr=l(),ZC=a("li"),TAe=a("strong"),LLr=o("xlm-roberta"),yLr=o(" \u2014 "),Ooe=a("a"),xLr=o("XLMRobertaForQuestionAnswering"),$Lr=o(" (XLM-RoBERTa model)"),kLr=l(),KC=a("li"),MAe=a("strong"),SLr=o("xlm-roberta-xl"),RLr=o(" \u2014 "),Voe=a("a"),PLr=o("XLMRobertaXLForQuestionAnswering"),BLr=o(" (XLM-RoBERTa-XL model)"),ILr=l(),e3=a("li"),EAe=a("strong"),NLr=o("xlnet"),qLr=o(" \u2014 "),Xoe=a("a"),jLr=o("XLNetForQuestionAnsweringSimple"),DLr=o(" (XLNet model)"),GLr=l(),o3=a("li"),CAe=a("strong"),OLr=o("yoso"),VLr=o(" \u2014 "),zoe=a("a"),XLr=o("YosoForQuestionAnswering"),zLr=o(" (YOSO model)"),QLr=l(),r3=a("p"),WLr=o("The model is set in evaluation mode by default using "),wAe=a("code"),ULr=o("model.eval()"),HLr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),AAe=a("code"),JLr=o("model.train()"),YLr=l(),F(t3.$$.fragment),cio=l(),Fm=a("h2"),a3=a("a"),LAe=a("span"),F(HS.$$.fragment),ZLr=l(),yAe=a("span"),KLr=o("AutoModelForTableQuestionAnswering"),fio=l(),Yo=a("div"),F(JS.$$.fragment),eyr=l(),Tm=a("p"),oyr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Qoe=a("a"),ryr=o("from_pretrained()"),tyr=o(" class method or the "),Woe=a("a"),ayr=o("from_config()"),nyr=o(` class
method.`),syr=l(),YS=a("p"),lyr=o("This class cannot be instantiated directly using "),xAe=a("code"),iyr=o("__init__()"),dyr=o(" (throws an error)."),myr=l(),Nt=a("div"),F(ZS.$$.fragment),cyr=l(),$Ae=a("p"),fyr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),gyr=l(),Mm=a("p"),hyr=o(`Note:
Loading a model from its configuration file does `),kAe=a("strong"),uyr=o("not"),pyr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Uoe=a("a"),_yr=o("from_pretrained()"),byr=o(" to load the model weights."),vyr=l(),F(n3.$$.fragment),Fyr=l(),uo=a("div"),F(KS.$$.fragment),Tyr=l(),SAe=a("p"),Myr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Eyr=l(),En=a("p"),Cyr=o("The model class to instantiate is selected based on the "),RAe=a("code"),wyr=o("model_type"),Ayr=o(` property of the config object (either
passed as an argument or loaded from `),PAe=a("code"),Lyr=o("pretrained_model_name_or_path"),yyr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),BAe=a("code"),xyr=o("pretrained_model_name_or_path"),$yr=o(":"),kyr=l(),IAe=a("ul"),s3=a("li"),NAe=a("strong"),Syr=o("tapas"),Ryr=o(" \u2014 "),Hoe=a("a"),Pyr=o("TapasForQuestionAnswering"),Byr=o(" (TAPAS model)"),Iyr=l(),l3=a("p"),Nyr=o("The model is set in evaluation mode by default using "),qAe=a("code"),qyr=o("model.eval()"),jyr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),jAe=a("code"),Dyr=o("model.train()"),Gyr=l(),F(i3.$$.fragment),gio=l(),Em=a("h2"),d3=a("a"),DAe=a("span"),F(eR.$$.fragment),Oyr=l(),GAe=a("span"),Vyr=o("AutoModelForDocumentQuestionAnswering"),hio=l(),Zo=a("div"),F(oR.$$.fragment),Xyr=l(),Cm=a("p"),zyr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),Joe=a("a"),Qyr=o("from_pretrained()"),Wyr=o(" class method or the "),Yoe=a("a"),Uyr=o("from_config()"),Hyr=o(` class
method.`),Jyr=l(),rR=a("p"),Yyr=o("This class cannot be instantiated directly using "),OAe=a("code"),Zyr=o("__init__()"),Kyr=o(" (throws an error)."),e9r=l(),qt=a("div"),F(tR.$$.fragment),o9r=l(),VAe=a("p"),r9r=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),t9r=l(),wm=a("p"),a9r=o(`Note:
Loading a model from its configuration file does `),XAe=a("strong"),n9r=o("not"),s9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zoe=a("a"),l9r=o("from_pretrained()"),i9r=o(" to load the model weights."),d9r=l(),F(m3.$$.fragment),m9r=l(),po=a("div"),F(aR.$$.fragment),c9r=l(),zAe=a("p"),f9r=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),g9r=l(),Cn=a("p"),h9r=o("The model class to instantiate is selected based on the "),QAe=a("code"),u9r=o("model_type"),p9r=o(` property of the config object (either
passed as an argument or loaded from `),WAe=a("code"),_9r=o("pretrained_model_name_or_path"),b9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),UAe=a("code"),v9r=o("pretrained_model_name_or_path"),F9r=o(":"),T9r=l(),Am=a("ul"),c3=a("li"),HAe=a("strong"),M9r=o("layoutlm"),E9r=o(" \u2014 "),Koe=a("a"),C9r=o("LayoutLMForQuestionAnswering"),w9r=o(" (LayoutLM model)"),A9r=l(),f3=a("li"),JAe=a("strong"),L9r=o("layoutlmv2"),y9r=o(" \u2014 "),ere=a("a"),x9r=o("LayoutLMv2ForQuestionAnswering"),$9r=o(" (LayoutLMv2 model)"),k9r=l(),g3=a("li"),YAe=a("strong"),S9r=o("layoutlmv3"),R9r=o(" \u2014 "),ore=a("a"),P9r=o("LayoutLMv3ForQuestionAnswering"),B9r=o(" (LayoutLMv3 model)"),I9r=l(),h3=a("p"),N9r=o("The model is set in evaluation mode by default using "),ZAe=a("code"),q9r=o("model.eval()"),j9r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),KAe=a("code"),D9r=o("model.train()"),G9r=l(),F(u3.$$.fragment),uio=l(),Lm=a("h2"),p3=a("a"),e6e=a("span"),F(nR.$$.fragment),O9r=l(),o6e=a("span"),V9r=o("AutoModelForImageClassification"),pio=l(),Ko=a("div"),F(sR.$$.fragment),X9r=l(),ym=a("p"),z9r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),rre=a("a"),Q9r=o("from_pretrained()"),W9r=o(" class method or the "),tre=a("a"),U9r=o("from_config()"),H9r=o(` class
method.`),J9r=l(),lR=a("p"),Y9r=o("This class cannot be instantiated directly using "),r6e=a("code"),Z9r=o("__init__()"),K9r=o(" (throws an error)."),exr=l(),jt=a("div"),F(iR.$$.fragment),oxr=l(),t6e=a("p"),rxr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),txr=l(),xm=a("p"),axr=o(`Note:
Loading a model from its configuration file does `),a6e=a("strong"),nxr=o("not"),sxr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),are=a("a"),lxr=o("from_pretrained()"),ixr=o(" to load the model weights."),dxr=l(),F(_3.$$.fragment),mxr=l(),_o=a("div"),F(dR.$$.fragment),cxr=l(),n6e=a("p"),fxr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),gxr=l(),wn=a("p"),hxr=o("The model class to instantiate is selected based on the "),s6e=a("code"),uxr=o("model_type"),pxr=o(` property of the config object (either
passed as an argument or loaded from `),l6e=a("code"),_xr=o("pretrained_model_name_or_path"),bxr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i6e=a("code"),vxr=o("pretrained_model_name_or_path"),Fxr=o(":"),Txr=l(),Fe=a("ul"),b3=a("li"),d6e=a("strong"),Mxr=o("beit"),Exr=o(" \u2014 "),nre=a("a"),Cxr=o("BeitForImageClassification"),wxr=o(" (BEiT model)"),Axr=l(),v3=a("li"),m6e=a("strong"),Lxr=o("convnext"),yxr=o(" \u2014 "),sre=a("a"),xxr=o("ConvNextForImageClassification"),$xr=o(" (ConvNeXT model)"),kxr=l(),F3=a("li"),c6e=a("strong"),Sxr=o("cvt"),Rxr=o(" \u2014 "),lre=a("a"),Pxr=o("CvtForImageClassification"),Bxr=o(" (CvT model)"),Ixr=l(),T3=a("li"),f6e=a("strong"),Nxr=o("data2vec-vision"),qxr=o(" \u2014 "),ire=a("a"),jxr=o("Data2VecVisionForImageClassification"),Dxr=o(" (Data2VecVision model)"),Gxr=l(),Nl=a("li"),g6e=a("strong"),Oxr=o("deit"),Vxr=o(" \u2014 "),dre=a("a"),Xxr=o("DeiTForImageClassification"),zxr=o(" or "),mre=a("a"),Qxr=o("DeiTForImageClassificationWithTeacher"),Wxr=o(" (DeiT model)"),Uxr=l(),M3=a("li"),h6e=a("strong"),Hxr=o("imagegpt"),Jxr=o(" \u2014 "),cre=a("a"),Yxr=o("ImageGPTForImageClassification"),Zxr=o(" (ImageGPT model)"),Kxr=l(),ql=a("li"),u6e=a("strong"),e$r=o("levit"),o$r=o(" \u2014 "),fre=a("a"),r$r=o("LevitForImageClassification"),t$r=o(" or "),gre=a("a"),a$r=o("LevitForImageClassificationWithTeacher"),n$r=o(" (LeViT model)"),s$r=l(),E3=a("li"),p6e=a("strong"),l$r=o("mobilevit"),i$r=o(" \u2014 "),hre=a("a"),d$r=o("MobileViTForImageClassification"),m$r=o(" (MobileViT model)"),c$r=l(),Dt=a("li"),_6e=a("strong"),f$r=o("perceiver"),g$r=o(" \u2014 "),ure=a("a"),h$r=o("PerceiverForImageClassificationLearned"),u$r=o(" or "),pre=a("a"),p$r=o("PerceiverForImageClassificationFourier"),_$r=o(" or "),_re=a("a"),b$r=o("PerceiverForImageClassificationConvProcessing"),v$r=o(" (Perceiver model)"),F$r=l(),C3=a("li"),b6e=a("strong"),T$r=o("poolformer"),M$r=o(" \u2014 "),bre=a("a"),E$r=o("PoolFormerForImageClassification"),C$r=o(" (PoolFormer model)"),w$r=l(),w3=a("li"),v6e=a("strong"),A$r=o("regnet"),L$r=o(" \u2014 "),vre=a("a"),y$r=o("RegNetForImageClassification"),x$r=o(" (RegNet model)"),$$r=l(),A3=a("li"),F6e=a("strong"),k$r=o("resnet"),S$r=o(" \u2014 "),Fre=a("a"),R$r=o("ResNetForImageClassification"),P$r=o(" (ResNet model)"),B$r=l(),L3=a("li"),T6e=a("strong"),I$r=o("segformer"),N$r=o(" \u2014 "),Tre=a("a"),q$r=o("SegformerForImageClassification"),j$r=o(" (SegFormer model)"),D$r=l(),y3=a("li"),M6e=a("strong"),G$r=o("swin"),O$r=o(" \u2014 "),Mre=a("a"),V$r=o("SwinForImageClassification"),X$r=o(" (Swin Transformer model)"),z$r=l(),x3=a("li"),E6e=a("strong"),Q$r=o("swinv2"),W$r=o(" \u2014 "),Ere=a("a"),U$r=o("Swinv2ForImageClassification"),H$r=o(" (Swin Transformer V2 model)"),J$r=l(),$3=a("li"),C6e=a("strong"),Y$r=o("van"),Z$r=o(" \u2014 "),Cre=a("a"),K$r=o("VanForImageClassification"),ekr=o(" (VAN model)"),okr=l(),k3=a("li"),w6e=a("strong"),rkr=o("vit"),tkr=o(" \u2014 "),wre=a("a"),akr=o("ViTForImageClassification"),nkr=o(" (ViT model)"),skr=l(),S3=a("li"),A6e=a("strong"),lkr=o("vit_msn"),ikr=o(" \u2014 "),Are=a("a"),dkr=o("ViTMSNForImageClassification"),mkr=o(" (ViTMSN model)"),ckr=l(),R3=a("p"),fkr=o("The model is set in evaluation mode by default using "),L6e=a("code"),gkr=o("model.eval()"),hkr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),y6e=a("code"),ukr=o("model.train()"),pkr=l(),F(P3.$$.fragment),_io=l(),$m=a("h2"),B3=a("a"),x6e=a("span"),F(mR.$$.fragment),_kr=l(),$6e=a("span"),bkr=o("AutoModelForVideoClassification"),bio=l(),er=a("div"),F(cR.$$.fragment),vkr=l(),km=a("p"),Fkr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),Lre=a("a"),Tkr=o("from_pretrained()"),Mkr=o(" class method or the "),yre=a("a"),Ekr=o("from_config()"),Ckr=o(` class
method.`),wkr=l(),fR=a("p"),Akr=o("This class cannot be instantiated directly using "),k6e=a("code"),Lkr=o("__init__()"),ykr=o(" (throws an error)."),xkr=l(),Gt=a("div"),F(gR.$$.fragment),$kr=l(),S6e=a("p"),kkr=o("Instantiates one of the model classes of the library (with a video classification head) from a configuration."),Skr=l(),Sm=a("p"),Rkr=o(`Note:
Loading a model from its configuration file does `),R6e=a("strong"),Pkr=o("not"),Bkr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xre=a("a"),Ikr=o("from_pretrained()"),Nkr=o(" to load the model weights."),qkr=l(),F(I3.$$.fragment),jkr=l(),bo=a("div"),F(hR.$$.fragment),Dkr=l(),P6e=a("p"),Gkr=o("Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),Okr=l(),An=a("p"),Vkr=o("The model class to instantiate is selected based on the "),B6e=a("code"),Xkr=o("model_type"),zkr=o(` property of the config object (either
passed as an argument or loaded from `),I6e=a("code"),Qkr=o("pretrained_model_name_or_path"),Wkr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N6e=a("code"),Ukr=o("pretrained_model_name_or_path"),Hkr=o(":"),Jkr=l(),q6e=a("ul"),N3=a("li"),j6e=a("strong"),Ykr=o("videomae"),Zkr=o(" \u2014 "),$re=a("a"),Kkr=o("VideoMAEForVideoClassification"),eSr=o(" (VideoMAE model)"),oSr=l(),q3=a("p"),rSr=o("The model is set in evaluation mode by default using "),D6e=a("code"),tSr=o("model.eval()"),aSr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),G6e=a("code"),nSr=o("model.train()"),sSr=l(),F(j3.$$.fragment),vio=l(),Rm=a("h2"),D3=a("a"),O6e=a("span"),F(uR.$$.fragment),lSr=l(),V6e=a("span"),iSr=o("AutoModelForVision2Seq"),Fio=l(),or=a("div"),F(pR.$$.fragment),dSr=l(),Pm=a("p"),mSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),kre=a("a"),cSr=o("from_pretrained()"),fSr=o(" class method or the "),Sre=a("a"),gSr=o("from_config()"),hSr=o(` class
method.`),uSr=l(),_R=a("p"),pSr=o("This class cannot be instantiated directly using "),X6e=a("code"),_Sr=o("__init__()"),bSr=o(" (throws an error)."),vSr=l(),Ot=a("div"),F(bR.$$.fragment),FSr=l(),z6e=a("p"),TSr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),MSr=l(),Bm=a("p"),ESr=o(`Note:
Loading a model from its configuration file does `),Q6e=a("strong"),CSr=o("not"),wSr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Rre=a("a"),ASr=o("from_pretrained()"),LSr=o(" to load the model weights."),ySr=l(),F(G3.$$.fragment),xSr=l(),vo=a("div"),F(vR.$$.fragment),$Sr=l(),W6e=a("p"),kSr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),SSr=l(),Ln=a("p"),RSr=o("The model class to instantiate is selected based on the "),U6e=a("code"),PSr=o("model_type"),BSr=o(` property of the config object (either
passed as an argument or loaded from `),H6e=a("code"),ISr=o("pretrained_model_name_or_path"),NSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J6e=a("code"),qSr=o("pretrained_model_name_or_path"),jSr=o(":"),DSr=l(),Y6e=a("ul"),O3=a("li"),Z6e=a("strong"),GSr=o("vision-encoder-decoder"),OSr=o(" \u2014 "),Pre=a("a"),VSr=o("VisionEncoderDecoderModel"),XSr=o(" (Vision Encoder decoder model)"),zSr=l(),V3=a("p"),QSr=o("The model is set in evaluation mode by default using "),K6e=a("code"),WSr=o("model.eval()"),USr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),e7e=a("code"),HSr=o("model.train()"),JSr=l(),F(X3.$$.fragment),Tio=l(),Im=a("h2"),z3=a("a"),o7e=a("span"),F(FR.$$.fragment),YSr=l(),r7e=a("span"),ZSr=o("AutoModelForVisualQuestionAnswering"),Mio=l(),rr=a("div"),F(TR.$$.fragment),KSr=l(),Nm=a("p"),eRr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),Bre=a("a"),oRr=o("from_pretrained()"),rRr=o(" class method or the "),Ire=a("a"),tRr=o("from_config()"),aRr=o(` class
method.`),nRr=l(),MR=a("p"),sRr=o("This class cannot be instantiated directly using "),t7e=a("code"),lRr=o("__init__()"),iRr=o(" (throws an error)."),dRr=l(),Vt=a("div"),F(ER.$$.fragment),mRr=l(),a7e=a("p"),cRr=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),fRr=l(),qm=a("p"),gRr=o(`Note:
Loading a model from its configuration file does `),n7e=a("strong"),hRr=o("not"),uRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Nre=a("a"),pRr=o("from_pretrained()"),_Rr=o(" to load the model weights."),bRr=l(),F(Q3.$$.fragment),vRr=l(),Fo=a("div"),F(CR.$$.fragment),FRr=l(),s7e=a("p"),TRr=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),MRr=l(),yn=a("p"),ERr=o("The model class to instantiate is selected based on the "),l7e=a("code"),CRr=o("model_type"),wRr=o(` property of the config object (either
passed as an argument or loaded from `),i7e=a("code"),ARr=o("pretrained_model_name_or_path"),LRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d7e=a("code"),yRr=o("pretrained_model_name_or_path"),xRr=o(":"),$Rr=l(),m7e=a("ul"),W3=a("li"),c7e=a("strong"),kRr=o("vilt"),SRr=o(" \u2014 "),qre=a("a"),RRr=o("ViltForQuestionAnswering"),PRr=o(" (ViLT model)"),BRr=l(),U3=a("p"),IRr=o("The model is set in evaluation mode by default using "),f7e=a("code"),NRr=o("model.eval()"),qRr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),g7e=a("code"),jRr=o("model.train()"),DRr=l(),F(H3.$$.fragment),Eio=l(),jm=a("h2"),J3=a("a"),h7e=a("span"),F(wR.$$.fragment),GRr=l(),u7e=a("span"),ORr=o("AutoModelForAudioClassification"),Cio=l(),tr=a("div"),F(AR.$$.fragment),VRr=l(),Dm=a("p"),XRr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),jre=a("a"),zRr=o("from_pretrained()"),QRr=o(" class method or the "),Dre=a("a"),WRr=o("from_config()"),URr=o(` class
method.`),HRr=l(),LR=a("p"),JRr=o("This class cannot be instantiated directly using "),p7e=a("code"),YRr=o("__init__()"),ZRr=o(" (throws an error)."),KRr=l(),Xt=a("div"),F(yR.$$.fragment),ePr=l(),_7e=a("p"),oPr=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),rPr=l(),Gm=a("p"),tPr=o(`Note:
Loading a model from its configuration file does `),b7e=a("strong"),aPr=o("not"),nPr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Gre=a("a"),sPr=o("from_pretrained()"),lPr=o(" to load the model weights."),iPr=l(),F(Y3.$$.fragment),dPr=l(),To=a("div"),F(xR.$$.fragment),mPr=l(),v7e=a("p"),cPr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),fPr=l(),xn=a("p"),gPr=o("The model class to instantiate is selected based on the "),F7e=a("code"),hPr=o("model_type"),uPr=o(` property of the config object (either
passed as an argument or loaded from `),T7e=a("code"),pPr=o("pretrained_model_name_or_path"),_Pr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M7e=a("code"),bPr=o("pretrained_model_name_or_path"),vPr=o(":"),FPr=l(),Ne=a("ul"),Z3=a("li"),E7e=a("strong"),TPr=o("data2vec-audio"),MPr=o(" \u2014 "),Ore=a("a"),EPr=o("Data2VecAudioForSequenceClassification"),CPr=o(" (Data2VecAudio model)"),wPr=l(),K3=a("li"),C7e=a("strong"),APr=o("hubert"),LPr=o(" \u2014 "),Vre=a("a"),yPr=o("HubertForSequenceClassification"),xPr=o(" (Hubert model)"),$Pr=l(),e5=a("li"),w7e=a("strong"),kPr=o("sew"),SPr=o(" \u2014 "),Xre=a("a"),RPr=o("SEWForSequenceClassification"),PPr=o(" (SEW model)"),BPr=l(),o5=a("li"),A7e=a("strong"),IPr=o("sew-d"),NPr=o(" \u2014 "),zre=a("a"),qPr=o("SEWDForSequenceClassification"),jPr=o(" (SEW-D model)"),DPr=l(),r5=a("li"),L7e=a("strong"),GPr=o("unispeech"),OPr=o(" \u2014 "),Qre=a("a"),VPr=o("UniSpeechForSequenceClassification"),XPr=o(" (UniSpeech model)"),zPr=l(),t5=a("li"),y7e=a("strong"),QPr=o("unispeech-sat"),WPr=o(" \u2014 "),Wre=a("a"),UPr=o("UniSpeechSatForSequenceClassification"),HPr=o(" (UniSpeechSat model)"),JPr=l(),a5=a("li"),x7e=a("strong"),YPr=o("wav2vec2"),ZPr=o(" \u2014 "),Ure=a("a"),KPr=o("Wav2Vec2ForSequenceClassification"),eBr=o(" (Wav2Vec2 model)"),oBr=l(),n5=a("li"),$7e=a("strong"),rBr=o("wav2vec2-conformer"),tBr=o(" \u2014 "),Hre=a("a"),aBr=o("Wav2Vec2ConformerForSequenceClassification"),nBr=o(" (Wav2Vec2-Conformer model)"),sBr=l(),s5=a("li"),k7e=a("strong"),lBr=o("wavlm"),iBr=o(" \u2014 "),Jre=a("a"),dBr=o("WavLMForSequenceClassification"),mBr=o(" (WavLM model)"),cBr=l(),l5=a("p"),fBr=o("The model is set in evaluation mode by default using "),S7e=a("code"),gBr=o("model.eval()"),hBr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),R7e=a("code"),uBr=o("model.train()"),pBr=l(),F(i5.$$.fragment),wio=l(),Om=a("h2"),d5=a("a"),P7e=a("span"),F($R.$$.fragment),_Br=l(),B7e=a("span"),bBr=o("AutoModelForAudioFrameClassification"),Aio=l(),ar=a("div"),F(kR.$$.fragment),vBr=l(),Vm=a("p"),FBr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),Yre=a("a"),TBr=o("from_pretrained()"),MBr=o(" class method or the "),Zre=a("a"),EBr=o("from_config()"),CBr=o(` class
method.`),wBr=l(),SR=a("p"),ABr=o("This class cannot be instantiated directly using "),I7e=a("code"),LBr=o("__init__()"),yBr=o(" (throws an error)."),xBr=l(),zt=a("div"),F(RR.$$.fragment),$Br=l(),N7e=a("p"),kBr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),SBr=l(),Xm=a("p"),RBr=o(`Note:
Loading a model from its configuration file does `),q7e=a("strong"),PBr=o("not"),BBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Kre=a("a"),IBr=o("from_pretrained()"),NBr=o(" to load the model weights."),qBr=l(),F(m5.$$.fragment),jBr=l(),Mo=a("div"),F(PR.$$.fragment),DBr=l(),j7e=a("p"),GBr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),OBr=l(),$n=a("p"),VBr=o("The model class to instantiate is selected based on the "),D7e=a("code"),XBr=o("model_type"),zBr=o(` property of the config object (either
passed as an argument or loaded from `),G7e=a("code"),QBr=o("pretrained_model_name_or_path"),WBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O7e=a("code"),UBr=o("pretrained_model_name_or_path"),HBr=o(":"),JBr=l(),vt=a("ul"),c5=a("li"),V7e=a("strong"),YBr=o("data2vec-audio"),ZBr=o(" \u2014 "),ete=a("a"),KBr=o("Data2VecAudioForAudioFrameClassification"),eIr=o(" (Data2VecAudio model)"),oIr=l(),f5=a("li"),X7e=a("strong"),rIr=o("unispeech-sat"),tIr=o(" \u2014 "),ote=a("a"),aIr=o("UniSpeechSatForAudioFrameClassification"),nIr=o(" (UniSpeechSat model)"),sIr=l(),g5=a("li"),z7e=a("strong"),lIr=o("wav2vec2"),iIr=o(" \u2014 "),rte=a("a"),dIr=o("Wav2Vec2ForAudioFrameClassification"),mIr=o(" (Wav2Vec2 model)"),cIr=l(),h5=a("li"),Q7e=a("strong"),fIr=o("wav2vec2-conformer"),gIr=o(" \u2014 "),tte=a("a"),hIr=o("Wav2Vec2ConformerForAudioFrameClassification"),uIr=o(" (Wav2Vec2-Conformer model)"),pIr=l(),u5=a("li"),W7e=a("strong"),_Ir=o("wavlm"),bIr=o(" \u2014 "),ate=a("a"),vIr=o("WavLMForAudioFrameClassification"),FIr=o(" (WavLM model)"),TIr=l(),p5=a("p"),MIr=o("The model is set in evaluation mode by default using "),U7e=a("code"),EIr=o("model.eval()"),CIr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),H7e=a("code"),wIr=o("model.train()"),AIr=l(),F(_5.$$.fragment),Lio=l(),zm=a("h2"),b5=a("a"),J7e=a("span"),F(BR.$$.fragment),LIr=l(),Y7e=a("span"),yIr=o("AutoModelForCTC"),yio=l(),nr=a("div"),F(IR.$$.fragment),xIr=l(),Qm=a("p"),$Ir=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),nte=a("a"),kIr=o("from_pretrained()"),SIr=o(" class method or the "),ste=a("a"),RIr=o("from_config()"),PIr=o(` class
method.`),BIr=l(),NR=a("p"),IIr=o("This class cannot be instantiated directly using "),Z7e=a("code"),NIr=o("__init__()"),qIr=o(" (throws an error)."),jIr=l(),Qt=a("div"),F(qR.$$.fragment),DIr=l(),K7e=a("p"),GIr=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),OIr=l(),Wm=a("p"),VIr=o(`Note:
Loading a model from its configuration file does `),e8e=a("strong"),XIr=o("not"),zIr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lte=a("a"),QIr=o("from_pretrained()"),WIr=o(" to load the model weights."),UIr=l(),F(v5.$$.fragment),HIr=l(),Eo=a("div"),F(jR.$$.fragment),JIr=l(),o8e=a("p"),YIr=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),ZIr=l(),kn=a("p"),KIr=o("The model class to instantiate is selected based on the "),r8e=a("code"),eNr=o("model_type"),oNr=o(` property of the config object (either
passed as an argument or loaded from `),t8e=a("code"),rNr=o("pretrained_model_name_or_path"),tNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a8e=a("code"),aNr=o("pretrained_model_name_or_path"),nNr=o(":"),sNr=l(),xe=a("ul"),F5=a("li"),n8e=a("strong"),lNr=o("data2vec-audio"),iNr=o(" \u2014 "),ite=a("a"),dNr=o("Data2VecAudioForCTC"),mNr=o(" (Data2VecAudio model)"),cNr=l(),T5=a("li"),s8e=a("strong"),fNr=o("hubert"),gNr=o(" \u2014 "),dte=a("a"),hNr=o("HubertForCTC"),uNr=o(" (Hubert model)"),pNr=l(),M5=a("li"),l8e=a("strong"),_Nr=o("mctct"),bNr=o(" \u2014 "),mte=a("a"),vNr=o("MCTCTForCTC"),FNr=o(" (M-CTC-T model)"),TNr=l(),E5=a("li"),i8e=a("strong"),MNr=o("sew"),ENr=o(" \u2014 "),cte=a("a"),CNr=o("SEWForCTC"),wNr=o(" (SEW model)"),ANr=l(),C5=a("li"),d8e=a("strong"),LNr=o("sew-d"),yNr=o(" \u2014 "),fte=a("a"),xNr=o("SEWDForCTC"),$Nr=o(" (SEW-D model)"),kNr=l(),w5=a("li"),m8e=a("strong"),SNr=o("unispeech"),RNr=o(" \u2014 "),gte=a("a"),PNr=o("UniSpeechForCTC"),BNr=o(" (UniSpeech model)"),INr=l(),A5=a("li"),c8e=a("strong"),NNr=o("unispeech-sat"),qNr=o(" \u2014 "),hte=a("a"),jNr=o("UniSpeechSatForCTC"),DNr=o(" (UniSpeechSat model)"),GNr=l(),L5=a("li"),f8e=a("strong"),ONr=o("wav2vec2"),VNr=o(" \u2014 "),ute=a("a"),XNr=o("Wav2Vec2ForCTC"),zNr=o(" (Wav2Vec2 model)"),QNr=l(),y5=a("li"),g8e=a("strong"),WNr=o("wav2vec2-conformer"),UNr=o(" \u2014 "),pte=a("a"),HNr=o("Wav2Vec2ConformerForCTC"),JNr=o(" (Wav2Vec2-Conformer model)"),YNr=l(),x5=a("li"),h8e=a("strong"),ZNr=o("wavlm"),KNr=o(" \u2014 "),_te=a("a"),eqr=o("WavLMForCTC"),oqr=o(" (WavLM model)"),rqr=l(),$5=a("p"),tqr=o("The model is set in evaluation mode by default using "),u8e=a("code"),aqr=o("model.eval()"),nqr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),p8e=a("code"),sqr=o("model.train()"),lqr=l(),F(k5.$$.fragment),xio=l(),Um=a("h2"),S5=a("a"),_8e=a("span"),F(DR.$$.fragment),iqr=l(),b8e=a("span"),dqr=o("AutoModelForSpeechSeq2Seq"),$io=l(),sr=a("div"),F(GR.$$.fragment),mqr=l(),Hm=a("p"),cqr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),bte=a("a"),fqr=o("from_pretrained()"),gqr=o(" class method or the "),vte=a("a"),hqr=o("from_config()"),uqr=o(` class
method.`),pqr=l(),OR=a("p"),_qr=o("This class cannot be instantiated directly using "),v8e=a("code"),bqr=o("__init__()"),vqr=o(" (throws an error)."),Fqr=l(),Wt=a("div"),F(VR.$$.fragment),Tqr=l(),F8e=a("p"),Mqr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Eqr=l(),Jm=a("p"),Cqr=o(`Note:
Loading a model from its configuration file does `),T8e=a("strong"),wqr=o("not"),Aqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Fte=a("a"),Lqr=o("from_pretrained()"),yqr=o(" to load the model weights."),xqr=l(),F(R5.$$.fragment),$qr=l(),Co=a("div"),F(XR.$$.fragment),kqr=l(),M8e=a("p"),Sqr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Rqr=l(),Sn=a("p"),Pqr=o("The model class to instantiate is selected based on the "),E8e=a("code"),Bqr=o("model_type"),Iqr=o(` property of the config object (either
passed as an argument or loaded from `),C8e=a("code"),Nqr=o("pretrained_model_name_or_path"),qqr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),w8e=a("code"),jqr=o("pretrained_model_name_or_path"),Dqr=o(":"),Gqr=l(),Ym=a("ul"),P5=a("li"),A8e=a("strong"),Oqr=o("speech-encoder-decoder"),Vqr=o(" \u2014 "),Tte=a("a"),Xqr=o("SpeechEncoderDecoderModel"),zqr=o(" (Speech Encoder decoder model)"),Qqr=l(),B5=a("li"),L8e=a("strong"),Wqr=o("speech_to_text"),Uqr=o(" \u2014 "),Mte=a("a"),Hqr=o("Speech2TextForConditionalGeneration"),Jqr=o(" (Speech2Text model)"),Yqr=l(),I5=a("li"),y8e=a("strong"),Zqr=o("whisper"),Kqr=o(" \u2014 "),Ete=a("a"),ejr=o("WhisperForConditionalGeneration"),ojr=o(" (Whisper model)"),rjr=l(),N5=a("p"),tjr=o("The model is set in evaluation mode by default using "),x8e=a("code"),ajr=o("model.eval()"),njr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$8e=a("code"),sjr=o("model.train()"),ljr=l(),F(q5.$$.fragment),kio=l(),Zm=a("h2"),j5=a("a"),k8e=a("span"),F(zR.$$.fragment),ijr=l(),S8e=a("span"),djr=o("AutoModelForAudioXVector"),Sio=l(),lr=a("div"),F(QR.$$.fragment),mjr=l(),Km=a("p"),cjr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),Cte=a("a"),fjr=o("from_pretrained()"),gjr=o(" class method or the "),wte=a("a"),hjr=o("from_config()"),ujr=o(` class
method.`),pjr=l(),WR=a("p"),_jr=o("This class cannot be instantiated directly using "),R8e=a("code"),bjr=o("__init__()"),vjr=o(" (throws an error)."),Fjr=l(),Ut=a("div"),F(UR.$$.fragment),Tjr=l(),P8e=a("p"),Mjr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Ejr=l(),ec=a("p"),Cjr=o(`Note:
Loading a model from its configuration file does `),B8e=a("strong"),wjr=o("not"),Ajr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ate=a("a"),Ljr=o("from_pretrained()"),yjr=o(" to load the model weights."),xjr=l(),F(D5.$$.fragment),$jr=l(),wo=a("div"),F(HR.$$.fragment),kjr=l(),I8e=a("p"),Sjr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),Rjr=l(),Rn=a("p"),Pjr=o("The model class to instantiate is selected based on the "),N8e=a("code"),Bjr=o("model_type"),Ijr=o(` property of the config object (either
passed as an argument or loaded from `),q8e=a("code"),Njr=o("pretrained_model_name_or_path"),qjr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j8e=a("code"),jjr=o("pretrained_model_name_or_path"),Djr=o(":"),Gjr=l(),Ft=a("ul"),G5=a("li"),D8e=a("strong"),Ojr=o("data2vec-audio"),Vjr=o(" \u2014 "),Lte=a("a"),Xjr=o("Data2VecAudioForXVector"),zjr=o(" (Data2VecAudio model)"),Qjr=l(),O5=a("li"),G8e=a("strong"),Wjr=o("unispeech-sat"),Ujr=o(" \u2014 "),yte=a("a"),Hjr=o("UniSpeechSatForXVector"),Jjr=o(" (UniSpeechSat model)"),Yjr=l(),V5=a("li"),O8e=a("strong"),Zjr=o("wav2vec2"),Kjr=o(" \u2014 "),xte=a("a"),eDr=o("Wav2Vec2ForXVector"),oDr=o(" (Wav2Vec2 model)"),rDr=l(),X5=a("li"),V8e=a("strong"),tDr=o("wav2vec2-conformer"),aDr=o(" \u2014 "),$te=a("a"),nDr=o("Wav2Vec2ConformerForXVector"),sDr=o(" (Wav2Vec2-Conformer model)"),lDr=l(),z5=a("li"),X8e=a("strong"),iDr=o("wavlm"),dDr=o(" \u2014 "),kte=a("a"),mDr=o("WavLMForXVector"),cDr=o(" (WavLM model)"),fDr=l(),Q5=a("p"),gDr=o("The model is set in evaluation mode by default using "),z8e=a("code"),hDr=o("model.eval()"),uDr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Q8e=a("code"),pDr=o("model.train()"),_Dr=l(),F(W5.$$.fragment),Rio=l(),oc=a("h2"),U5=a("a"),W8e=a("span"),F(JR.$$.fragment),bDr=l(),U8e=a("span"),vDr=o("AutoModelForMaskedImageModeling"),Pio=l(),ir=a("div"),F(YR.$$.fragment),FDr=l(),rc=a("p"),TDr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),Ste=a("a"),MDr=o("from_pretrained()"),EDr=o(" class method or the "),Rte=a("a"),CDr=o("from_config()"),wDr=o(` class
method.`),ADr=l(),ZR=a("p"),LDr=o("This class cannot be instantiated directly using "),H8e=a("code"),yDr=o("__init__()"),xDr=o(" (throws an error)."),$Dr=l(),Ht=a("div"),F(KR.$$.fragment),kDr=l(),J8e=a("p"),SDr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),RDr=l(),tc=a("p"),PDr=o(`Note:
Loading a model from its configuration file does `),Y8e=a("strong"),BDr=o("not"),IDr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Pte=a("a"),NDr=o("from_pretrained()"),qDr=o(" to load the model weights."),jDr=l(),F(H5.$$.fragment),DDr=l(),Ao=a("div"),F(eP.$$.fragment),GDr=l(),Z8e=a("p"),ODr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),VDr=l(),Pn=a("p"),XDr=o("The model class to instantiate is selected based on the "),K8e=a("code"),zDr=o("model_type"),QDr=o(` property of the config object (either
passed as an argument or loaded from `),eLe=a("code"),WDr=o("pretrained_model_name_or_path"),UDr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oLe=a("code"),HDr=o("pretrained_model_name_or_path"),JDr=o(":"),YDr=l(),Bn=a("ul"),J5=a("li"),rLe=a("strong"),ZDr=o("deit"),KDr=o(" \u2014 "),Bte=a("a"),eGr=o("DeiTForMaskedImageModeling"),oGr=o(" (DeiT model)"),rGr=l(),Y5=a("li"),tLe=a("strong"),tGr=o("swin"),aGr=o(" \u2014 "),Ite=a("a"),nGr=o("SwinForMaskedImageModeling"),sGr=o(" (Swin Transformer model)"),lGr=l(),Z5=a("li"),aLe=a("strong"),iGr=o("swinv2"),dGr=o(" \u2014 "),Nte=a("a"),mGr=o("Swinv2ForMaskedImageModeling"),cGr=o(" (Swin Transformer V2 model)"),fGr=l(),K5=a("li"),nLe=a("strong"),gGr=o("vit"),hGr=o(" \u2014 "),qte=a("a"),uGr=o("ViTForMaskedImageModeling"),pGr=o(" (ViT model)"),_Gr=l(),e0=a("p"),bGr=o("The model is set in evaluation mode by default using "),sLe=a("code"),vGr=o("model.eval()"),FGr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lLe=a("code"),TGr=o("model.train()"),MGr=l(),F(o0.$$.fragment),Bio=l(),ac=a("h2"),r0=a("a"),iLe=a("span"),F(oP.$$.fragment),EGr=l(),dLe=a("span"),CGr=o("AutoModelForObjectDetection"),Iio=l(),dr=a("div"),F(rP.$$.fragment),wGr=l(),nc=a("p"),AGr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),jte=a("a"),LGr=o("from_pretrained()"),yGr=o(" class method or the "),Dte=a("a"),xGr=o("from_config()"),$Gr=o(` class
method.`),kGr=l(),tP=a("p"),SGr=o("This class cannot be instantiated directly using "),mLe=a("code"),RGr=o("__init__()"),PGr=o(" (throws an error)."),BGr=l(),Jt=a("div"),F(aP.$$.fragment),IGr=l(),cLe=a("p"),NGr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),qGr=l(),sc=a("p"),jGr=o(`Note:
Loading a model from its configuration file does `),fLe=a("strong"),DGr=o("not"),GGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Gte=a("a"),OGr=o("from_pretrained()"),VGr=o(" to load the model weights."),XGr=l(),F(t0.$$.fragment),zGr=l(),Lo=a("div"),F(nP.$$.fragment),QGr=l(),gLe=a("p"),WGr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),UGr=l(),In=a("p"),HGr=o("The model class to instantiate is selected based on the "),hLe=a("code"),JGr=o("model_type"),YGr=o(` property of the config object (either
passed as an argument or loaded from `),uLe=a("code"),ZGr=o("pretrained_model_name_or_path"),KGr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pLe=a("code"),eOr=o("pretrained_model_name_or_path"),oOr=o(":"),rOr=l(),Tt=a("ul"),a0=a("li"),_Le=a("strong"),tOr=o("conditional_detr"),aOr=o(" \u2014 "),Ote=a("a"),nOr=o("ConditionalDetrForObjectDetection"),sOr=o(" (Conditional DETR model)"),lOr=l(),n0=a("li"),bLe=a("strong"),iOr=o("deformable_detr"),dOr=o(" \u2014 "),Vte=a("a"),mOr=o("DeformableDetrForObjectDetection"),cOr=o(" (Deformable DETR model)"),fOr=l(),s0=a("li"),vLe=a("strong"),gOr=o("detr"),hOr=o(" \u2014 "),Xte=a("a"),uOr=o("DetrForObjectDetection"),pOr=o(" (DETR model)"),_Or=l(),l0=a("li"),FLe=a("strong"),bOr=o("table-transformer"),vOr=o(" \u2014 "),zte=a("a"),FOr=o("TableTransformerForObjectDetection"),TOr=o(" (Table Transformer model)"),MOr=l(),i0=a("li"),TLe=a("strong"),EOr=o("yolos"),COr=o(" \u2014 "),Qte=a("a"),wOr=o("YolosForObjectDetection"),AOr=o(" (YOLOS model)"),LOr=l(),d0=a("p"),yOr=o("The model is set in evaluation mode by default using "),MLe=a("code"),xOr=o("model.eval()"),$Or=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ELe=a("code"),kOr=o("model.train()"),SOr=l(),F(m0.$$.fragment),Nio=l(),lc=a("h2"),c0=a("a"),CLe=a("span"),F(sP.$$.fragment),ROr=l(),wLe=a("span"),POr=o("AutoModelForImageSegmentation"),qio=l(),mr=a("div"),F(lP.$$.fragment),BOr=l(),ic=a("p"),IOr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),Wte=a("a"),NOr=o("from_pretrained()"),qOr=o(" class method or the "),Ute=a("a"),jOr=o("from_config()"),DOr=o(` class
method.`),GOr=l(),iP=a("p"),OOr=o("This class cannot be instantiated directly using "),ALe=a("code"),VOr=o("__init__()"),XOr=o(" (throws an error)."),zOr=l(),Yt=a("div"),F(dP.$$.fragment),QOr=l(),LLe=a("p"),WOr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),UOr=l(),dc=a("p"),HOr=o(`Note:
Loading a model from its configuration file does `),yLe=a("strong"),JOr=o("not"),YOr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Hte=a("a"),ZOr=o("from_pretrained()"),KOr=o(" to load the model weights."),eVr=l(),F(f0.$$.fragment),oVr=l(),yo=a("div"),F(mP.$$.fragment),rVr=l(),xLe=a("p"),tVr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),aVr=l(),Nn=a("p"),nVr=o("The model class to instantiate is selected based on the "),$Le=a("code"),sVr=o("model_type"),lVr=o(` property of the config object (either
passed as an argument or loaded from `),kLe=a("code"),iVr=o("pretrained_model_name_or_path"),dVr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SLe=a("code"),mVr=o("pretrained_model_name_or_path"),cVr=o(":"),fVr=l(),RLe=a("ul"),g0=a("li"),PLe=a("strong"),gVr=o("detr"),hVr=o(" \u2014 "),Jte=a("a"),uVr=o("DetrForSegmentation"),pVr=o(" (DETR model)"),_Vr=l(),h0=a("p"),bVr=o("The model is set in evaluation mode by default using "),BLe=a("code"),vVr=o("model.eval()"),FVr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ILe=a("code"),TVr=o("model.train()"),MVr=l(),F(u0.$$.fragment),jio=l(),mc=a("h2"),p0=a("a"),NLe=a("span"),F(cP.$$.fragment),EVr=l(),qLe=a("span"),CVr=o("AutoModelForSemanticSegmentation"),Dio=l(),cr=a("div"),F(fP.$$.fragment),wVr=l(),cc=a("p"),AVr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Yte=a("a"),LVr=o("from_pretrained()"),yVr=o(" class method or the "),Zte=a("a"),xVr=o("from_config()"),$Vr=o(` class
method.`),kVr=l(),gP=a("p"),SVr=o("This class cannot be instantiated directly using "),jLe=a("code"),RVr=o("__init__()"),PVr=o(" (throws an error)."),BVr=l(),Zt=a("div"),F(hP.$$.fragment),IVr=l(),DLe=a("p"),NVr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),qVr=l(),fc=a("p"),jVr=o(`Note:
Loading a model from its configuration file does `),GLe=a("strong"),DVr=o("not"),GVr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Kte=a("a"),OVr=o("from_pretrained()"),VVr=o(" to load the model weights."),XVr=l(),F(_0.$$.fragment),zVr=l(),xo=a("div"),F(uP.$$.fragment),QVr=l(),OLe=a("p"),WVr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),UVr=l(),qn=a("p"),HVr=o("The model class to instantiate is selected based on the "),VLe=a("code"),JVr=o("model_type"),YVr=o(` property of the config object (either
passed as an argument or loaded from `),XLe=a("code"),ZVr=o("pretrained_model_name_or_path"),KVr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zLe=a("code"),eXr=o("pretrained_model_name_or_path"),oXr=o(":"),rXr=l(),Mt=a("ul"),b0=a("li"),QLe=a("strong"),tXr=o("beit"),aXr=o(" \u2014 "),eae=a("a"),nXr=o("BeitForSemanticSegmentation"),sXr=o(" (BEiT model)"),lXr=l(),v0=a("li"),WLe=a("strong"),iXr=o("data2vec-vision"),dXr=o(" \u2014 "),oae=a("a"),mXr=o("Data2VecVisionForSemanticSegmentation"),cXr=o(" (Data2VecVision model)"),fXr=l(),F0=a("li"),ULe=a("strong"),gXr=o("dpt"),hXr=o(" \u2014 "),rae=a("a"),uXr=o("DPTForSemanticSegmentation"),pXr=o(" (DPT model)"),_Xr=l(),T0=a("li"),HLe=a("strong"),bXr=o("mobilevit"),vXr=o(" \u2014 "),tae=a("a"),FXr=o("MobileViTForSemanticSegmentation"),TXr=o(" (MobileViT model)"),MXr=l(),M0=a("li"),JLe=a("strong"),EXr=o("segformer"),CXr=o(" \u2014 "),aae=a("a"),wXr=o("SegformerForSemanticSegmentation"),AXr=o(" (SegFormer model)"),LXr=l(),E0=a("p"),yXr=o("The model is set in evaluation mode by default using "),YLe=a("code"),xXr=o("model.eval()"),$Xr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ZLe=a("code"),kXr=o("model.train()"),SXr=l(),F(C0.$$.fragment),Gio=l(),gc=a("h2"),w0=a("a"),KLe=a("span"),F(pP.$$.fragment),RXr=l(),eye=a("span"),PXr=o("AutoModelForInstanceSegmentation"),Oio=l(),fr=a("div"),F(_P.$$.fragment),BXr=l(),hc=a("p"),IXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),nae=a("a"),NXr=o("from_pretrained()"),qXr=o(" class method or the "),sae=a("a"),jXr=o("from_config()"),DXr=o(` class
method.`),GXr=l(),bP=a("p"),OXr=o("This class cannot be instantiated directly using "),oye=a("code"),VXr=o("__init__()"),XXr=o(" (throws an error)."),zXr=l(),Kt=a("div"),F(vP.$$.fragment),QXr=l(),rye=a("p"),WXr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),UXr=l(),uc=a("p"),HXr=o(`Note:
Loading a model from its configuration file does `),tye=a("strong"),JXr=o("not"),YXr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lae=a("a"),ZXr=o("from_pretrained()"),KXr=o(" to load the model weights."),ezr=l(),F(A0.$$.fragment),ozr=l(),$o=a("div"),F(FP.$$.fragment),rzr=l(),aye=a("p"),tzr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),azr=l(),jn=a("p"),nzr=o("The model class to instantiate is selected based on the "),nye=a("code"),szr=o("model_type"),lzr=o(` property of the config object (either
passed as an argument or loaded from `),sye=a("code"),izr=o("pretrained_model_name_or_path"),dzr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lye=a("code"),mzr=o("pretrained_model_name_or_path"),czr=o(":"),fzr=l(),iye=a("ul"),L0=a("li"),dye=a("strong"),gzr=o("maskformer"),hzr=o(" \u2014 "),iae=a("a"),uzr=o("MaskFormerForInstanceSegmentation"),pzr=o(" (MaskFormer model)"),_zr=l(),y0=a("p"),bzr=o("The model is set in evaluation mode by default using "),mye=a("code"),vzr=o("model.eval()"),Fzr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cye=a("code"),Tzr=o("model.train()"),Mzr=l(),F(x0.$$.fragment),Vio=l(),pc=a("h2"),$0=a("a"),fye=a("span"),F(TP.$$.fragment),Ezr=l(),gye=a("span"),Czr=o("AutoModelForZeroShotObjectDetection"),Xio=l(),gr=a("div"),F(MP.$$.fragment),wzr=l(),_c=a("p"),Azr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),dae=a("a"),Lzr=o("from_pretrained()"),yzr=o(" class method or the "),mae=a("a"),xzr=o("from_config()"),$zr=o(` class
method.`),kzr=l(),EP=a("p"),Szr=o("This class cannot be instantiated directly using "),hye=a("code"),Rzr=o("__init__()"),Pzr=o(" (throws an error)."),Bzr=l(),ea=a("div"),F(CP.$$.fragment),Izr=l(),uye=a("p"),Nzr=o("Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),qzr=l(),bc=a("p"),jzr=o(`Note:
Loading a model from its configuration file does `),pye=a("strong"),Dzr=o("not"),Gzr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cae=a("a"),Ozr=o("from_pretrained()"),Vzr=o(" to load the model weights."),Xzr=l(),F(k0.$$.fragment),zzr=l(),ko=a("div"),F(wP.$$.fragment),Qzr=l(),_ye=a("p"),Wzr=o("Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),Uzr=l(),Dn=a("p"),Hzr=o("The model class to instantiate is selected based on the "),bye=a("code"),Jzr=o("model_type"),Yzr=o(` property of the config object (either
passed as an argument or loaded from `),vye=a("code"),Zzr=o("pretrained_model_name_or_path"),Kzr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Fye=a("code"),eQr=o("pretrained_model_name_or_path"),oQr=o(":"),rQr=l(),Tye=a("ul"),S0=a("li"),Mye=a("strong"),tQr=o("owlvit"),aQr=o(" \u2014 "),fae=a("a"),nQr=o("OwlViTForObjectDetection"),sQr=o(" (OWL-ViT model)"),lQr=l(),R0=a("p"),iQr=o("The model is set in evaluation mode by default using "),Eye=a("code"),dQr=o("model.eval()"),mQr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Cye=a("code"),cQr=o("model.train()"),fQr=l(),F(P0.$$.fragment),zio=l(),vc=a("h2"),B0=a("a"),wye=a("span"),F(AP.$$.fragment),gQr=l(),Aye=a("span"),hQr=o("TFAutoModel"),Qio=l(),hr=a("div"),F(LP.$$.fragment),uQr=l(),Fc=a("p"),pQr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),gae=a("a"),_Qr=o("from_pretrained()"),bQr=o(" class method or the "),hae=a("a"),vQr=o("from_config()"),FQr=o(` class
method.`),TQr=l(),yP=a("p"),MQr=o("This class cannot be instantiated directly using "),Lye=a("code"),EQr=o("__init__()"),CQr=o(" (throws an error)."),wQr=l(),oa=a("div"),F(xP.$$.fragment),AQr=l(),yye=a("p"),LQr=o("Instantiates one of the base model classes of the library from a configuration."),yQr=l(),Tc=a("p"),xQr=o(`Note:
Loading a model from its configuration file does `),xye=a("strong"),$Qr=o("not"),kQr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uae=a("a"),SQr=o("from_pretrained()"),RQr=o(" to load the model weights."),PQr=l(),F(I0.$$.fragment),BQr=l(),Xr=a("div"),F($P.$$.fragment),IQr=l(),$ye=a("p"),NQr=o("Instantiate one of the base model classes of the library from a pretrained model."),qQr=l(),Gn=a("p"),jQr=o("The model class to instantiate is selected based on the "),kye=a("code"),DQr=o("model_type"),GQr=o(` property of the config object (either
passed as an argument or loaded from `),Sye=a("code"),OQr=o("pretrained_model_name_or_path"),VQr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rye=a("code"),XQr=o("pretrained_model_name_or_path"),zQr=o(":"),QQr=l(),P=a("ul"),N0=a("li"),Pye=a("strong"),WQr=o("albert"),UQr=o(" \u2014 "),pae=a("a"),HQr=o("TFAlbertModel"),JQr=o(" (ALBERT model)"),YQr=l(),q0=a("li"),Bye=a("strong"),ZQr=o("bart"),KQr=o(" \u2014 "),_ae=a("a"),eWr=o("TFBartModel"),oWr=o(" (BART model)"),rWr=l(),j0=a("li"),Iye=a("strong"),tWr=o("bert"),aWr=o(" \u2014 "),bae=a("a"),nWr=o("TFBertModel"),sWr=o(" (BERT model)"),lWr=l(),D0=a("li"),Nye=a("strong"),iWr=o("blenderbot"),dWr=o(" \u2014 "),vae=a("a"),mWr=o("TFBlenderbotModel"),cWr=o(" (Blenderbot model)"),fWr=l(),G0=a("li"),qye=a("strong"),gWr=o("blenderbot-small"),hWr=o(" \u2014 "),Fae=a("a"),uWr=o("TFBlenderbotSmallModel"),pWr=o(" (BlenderbotSmall model)"),_Wr=l(),O0=a("li"),jye=a("strong"),bWr=o("camembert"),vWr=o(" \u2014 "),Tae=a("a"),FWr=o("TFCamembertModel"),TWr=o(" (CamemBERT model)"),MWr=l(),V0=a("li"),Dye=a("strong"),EWr=o("clip"),CWr=o(" \u2014 "),Mae=a("a"),wWr=o("TFCLIPModel"),AWr=o(" (CLIP model)"),LWr=l(),X0=a("li"),Gye=a("strong"),yWr=o("convbert"),xWr=o(" \u2014 "),Eae=a("a"),$Wr=o("TFConvBertModel"),kWr=o(" (ConvBERT model)"),SWr=l(),z0=a("li"),Oye=a("strong"),RWr=o("convnext"),PWr=o(" \u2014 "),Cae=a("a"),BWr=o("TFConvNextModel"),IWr=o(" (ConvNeXT model)"),NWr=l(),Q0=a("li"),Vye=a("strong"),qWr=o("ctrl"),jWr=o(" \u2014 "),wae=a("a"),DWr=o("TFCTRLModel"),GWr=o(" (CTRL model)"),OWr=l(),W0=a("li"),Xye=a("strong"),VWr=o("cvt"),XWr=o(" \u2014 "),Aae=a("a"),zWr=o("TFCvtModel"),QWr=o(" (CvT model)"),WWr=l(),U0=a("li"),zye=a("strong"),UWr=o("data2vec-vision"),HWr=o(" \u2014 "),Lae=a("a"),JWr=o("TFData2VecVisionModel"),YWr=o(" (Data2VecVision model)"),ZWr=l(),H0=a("li"),Qye=a("strong"),KWr=o("deberta"),eUr=o(" \u2014 "),yae=a("a"),oUr=o("TFDebertaModel"),rUr=o(" (DeBERTa model)"),tUr=l(),J0=a("li"),Wye=a("strong"),aUr=o("deberta-v2"),nUr=o(" \u2014 "),xae=a("a"),sUr=o("TFDebertaV2Model"),lUr=o(" (DeBERTa-v2 model)"),iUr=l(),Y0=a("li"),Uye=a("strong"),dUr=o("deit"),mUr=o(" \u2014 "),$ae=a("a"),cUr=o("TFDeiTModel"),fUr=o(" (DeiT model)"),gUr=l(),Z0=a("li"),Hye=a("strong"),hUr=o("distilbert"),uUr=o(" \u2014 "),kae=a("a"),pUr=o("TFDistilBertModel"),_Ur=o(" (DistilBERT model)"),bUr=l(),K0=a("li"),Jye=a("strong"),vUr=o("dpr"),FUr=o(" \u2014 "),Sae=a("a"),TUr=o("TFDPRQuestionEncoder"),MUr=o(" (DPR model)"),EUr=l(),ew=a("li"),Yye=a("strong"),CUr=o("electra"),wUr=o(" \u2014 "),Rae=a("a"),AUr=o("TFElectraModel"),LUr=o(" (ELECTRA model)"),yUr=l(),ow=a("li"),Zye=a("strong"),xUr=o("esm"),$Ur=o(" \u2014 "),Pae=a("a"),kUr=o("TFEsmModel"),SUr=o(" (ESM model)"),RUr=l(),rw=a("li"),Kye=a("strong"),PUr=o("flaubert"),BUr=o(" \u2014 "),Bae=a("a"),IUr=o("TFFlaubertModel"),NUr=o(" (FlauBERT model)"),qUr=l(),jl=a("li"),e9e=a("strong"),jUr=o("funnel"),DUr=o(" \u2014 "),Iae=a("a"),GUr=o("TFFunnelModel"),OUr=o(" or "),Nae=a("a"),VUr=o("TFFunnelBaseModel"),XUr=o(" (Funnel Transformer model)"),zUr=l(),tw=a("li"),o9e=a("strong"),QUr=o("gpt2"),WUr=o(" \u2014 "),qae=a("a"),UUr=o("TFGPT2Model"),HUr=o(" (OpenAI GPT-2 model)"),JUr=l(),aw=a("li"),r9e=a("strong"),YUr=o("gptj"),ZUr=o(" \u2014 "),jae=a("a"),KUr=o("TFGPTJModel"),eHr=o(" (GPT-J model)"),oHr=l(),nw=a("li"),t9e=a("strong"),rHr=o("groupvit"),tHr=o(" \u2014 "),Dae=a("a"),aHr=o("TFGroupViTModel"),nHr=o(" (GroupViT model)"),sHr=l(),sw=a("li"),a9e=a("strong"),lHr=o("hubert"),iHr=o(" \u2014 "),Gae=a("a"),dHr=o("TFHubertModel"),mHr=o(" (Hubert model)"),cHr=l(),lw=a("li"),n9e=a("strong"),fHr=o("layoutlm"),gHr=o(" \u2014 "),Oae=a("a"),hHr=o("TFLayoutLMModel"),uHr=o(" (LayoutLM model)"),pHr=l(),iw=a("li"),s9e=a("strong"),_Hr=o("layoutlmv3"),bHr=o(" \u2014 "),Vae=a("a"),vHr=o("TFLayoutLMv3Model"),FHr=o(" (LayoutLMv3 model)"),THr=l(),dw=a("li"),l9e=a("strong"),MHr=o("led"),EHr=o(" \u2014 "),Xae=a("a"),CHr=o("TFLEDModel"),wHr=o(" (LED model)"),AHr=l(),mw=a("li"),i9e=a("strong"),LHr=o("longformer"),yHr=o(" \u2014 "),zae=a("a"),xHr=o("TFLongformerModel"),$Hr=o(" (Longformer model)"),kHr=l(),cw=a("li"),d9e=a("strong"),SHr=o("lxmert"),RHr=o(" \u2014 "),Qae=a("a"),PHr=o("TFLxmertModel"),BHr=o(" (LXMERT model)"),IHr=l(),fw=a("li"),m9e=a("strong"),NHr=o("marian"),qHr=o(" \u2014 "),Wae=a("a"),jHr=o("TFMarianModel"),DHr=o(" (Marian model)"),GHr=l(),gw=a("li"),c9e=a("strong"),OHr=o("mbart"),VHr=o(" \u2014 "),Uae=a("a"),XHr=o("TFMBartModel"),zHr=o(" (mBART model)"),QHr=l(),hw=a("li"),f9e=a("strong"),WHr=o("mobilebert"),UHr=o(" \u2014 "),Hae=a("a"),HHr=o("TFMobileBertModel"),JHr=o(" (MobileBERT model)"),YHr=l(),uw=a("li"),g9e=a("strong"),ZHr=o("mobilevit"),KHr=o(" \u2014 "),Jae=a("a"),eJr=o("TFMobileViTModel"),oJr=o(" (MobileViT model)"),rJr=l(),pw=a("li"),h9e=a("strong"),tJr=o("mpnet"),aJr=o(" \u2014 "),Yae=a("a"),nJr=o("TFMPNetModel"),sJr=o(" (MPNet model)"),lJr=l(),_w=a("li"),u9e=a("strong"),iJr=o("mt5"),dJr=o(" \u2014 "),Zae=a("a"),mJr=o("TFMT5Model"),cJr=o(" (MT5 model)"),fJr=l(),bw=a("li"),p9e=a("strong"),gJr=o("openai-gpt"),hJr=o(" \u2014 "),Kae=a("a"),uJr=o("TFOpenAIGPTModel"),pJr=o(" (OpenAI GPT model)"),_Jr=l(),vw=a("li"),_9e=a("strong"),bJr=o("opt"),vJr=o(" \u2014 "),ene=a("a"),FJr=o("TFOPTModel"),TJr=o(" (OPT model)"),MJr=l(),Fw=a("li"),b9e=a("strong"),EJr=o("pegasus"),CJr=o(" \u2014 "),one=a("a"),wJr=o("TFPegasusModel"),AJr=o(" (Pegasus model)"),LJr=l(),Tw=a("li"),v9e=a("strong"),yJr=o("regnet"),xJr=o(" \u2014 "),rne=a("a"),$Jr=o("TFRegNetModel"),kJr=o(" (RegNet model)"),SJr=l(),Mw=a("li"),F9e=a("strong"),RJr=o("rembert"),PJr=o(" \u2014 "),tne=a("a"),BJr=o("TFRemBertModel"),IJr=o(" (RemBERT model)"),NJr=l(),Ew=a("li"),T9e=a("strong"),qJr=o("resnet"),jJr=o(" \u2014 "),ane=a("a"),DJr=o("TFResNetModel"),GJr=o(" (ResNet model)"),OJr=l(),Cw=a("li"),M9e=a("strong"),VJr=o("roberta"),XJr=o(" \u2014 "),nne=a("a"),zJr=o("TFRobertaModel"),QJr=o(" (RoBERTa model)"),WJr=l(),ww=a("li"),E9e=a("strong"),UJr=o("roformer"),HJr=o(" \u2014 "),sne=a("a"),JJr=o("TFRoFormerModel"),YJr=o(" (RoFormer model)"),ZJr=l(),Aw=a("li"),C9e=a("strong"),KJr=o("segformer"),eYr=o(" \u2014 "),lne=a("a"),oYr=o("TFSegformerModel"),rYr=o(" (SegFormer model)"),tYr=l(),Lw=a("li"),w9e=a("strong"),aYr=o("speech_to_text"),nYr=o(" \u2014 "),ine=a("a"),sYr=o("TFSpeech2TextModel"),lYr=o(" (Speech2Text model)"),iYr=l(),yw=a("li"),A9e=a("strong"),dYr=o("swin"),mYr=o(" \u2014 "),dne=a("a"),cYr=o("TFSwinModel"),fYr=o(" (Swin Transformer model)"),gYr=l(),xw=a("li"),L9e=a("strong"),hYr=o("t5"),uYr=o(" \u2014 "),mne=a("a"),pYr=o("TFT5Model"),_Yr=o(" (T5 model)"),bYr=l(),$w=a("li"),y9e=a("strong"),vYr=o("tapas"),FYr=o(" \u2014 "),cne=a("a"),TYr=o("TFTapasModel"),MYr=o(" (TAPAS model)"),EYr=l(),kw=a("li"),x9e=a("strong"),CYr=o("transfo-xl"),wYr=o(" \u2014 "),fne=a("a"),AYr=o("TFTransfoXLModel"),LYr=o(" (Transformer-XL model)"),yYr=l(),Sw=a("li"),$9e=a("strong"),xYr=o("vit"),$Yr=o(" \u2014 "),gne=a("a"),kYr=o("TFViTModel"),SYr=o(" (ViT model)"),RYr=l(),Rw=a("li"),k9e=a("strong"),PYr=o("vit_mae"),BYr=o(" \u2014 "),hne=a("a"),IYr=o("TFViTMAEModel"),NYr=o(" (ViTMAE model)"),qYr=l(),Pw=a("li"),S9e=a("strong"),jYr=o("wav2vec2"),DYr=o(" \u2014 "),une=a("a"),GYr=o("TFWav2Vec2Model"),OYr=o(" (Wav2Vec2 model)"),VYr=l(),Bw=a("li"),R9e=a("strong"),XYr=o("whisper"),zYr=o(" \u2014 "),pne=a("a"),QYr=o("TFWhisperModel"),WYr=o(" (Whisper model)"),UYr=l(),Iw=a("li"),P9e=a("strong"),HYr=o("xglm"),JYr=o(" \u2014 "),_ne=a("a"),YYr=o("TFXGLMModel"),ZYr=o(" (XGLM model)"),KYr=l(),Nw=a("li"),B9e=a("strong"),eZr=o("xlm"),oZr=o(" \u2014 "),bne=a("a"),rZr=o("TFXLMModel"),tZr=o(" (XLM model)"),aZr=l(),qw=a("li"),I9e=a("strong"),nZr=o("xlm-roberta"),sZr=o(" \u2014 "),vne=a("a"),lZr=o("TFXLMRobertaModel"),iZr=o(" (XLM-RoBERTa model)"),dZr=l(),jw=a("li"),N9e=a("strong"),mZr=o("xlnet"),cZr=o(" \u2014 "),Fne=a("a"),fZr=o("TFXLNetModel"),gZr=o(" (XLNet model)"),hZr=l(),F(Dw.$$.fragment),Wio=l(),Mc=a("h2"),Gw=a("a"),q9e=a("span"),F(kP.$$.fragment),uZr=l(),j9e=a("span"),pZr=o("TFAutoModelForPreTraining"),Uio=l(),ur=a("div"),F(SP.$$.fragment),_Zr=l(),Ec=a("p"),bZr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Tne=a("a"),vZr=o("from_pretrained()"),FZr=o(" class method or the "),Mne=a("a"),TZr=o("from_config()"),MZr=o(` class
method.`),EZr=l(),RP=a("p"),CZr=o("This class cannot be instantiated directly using "),D9e=a("code"),wZr=o("__init__()"),AZr=o(" (throws an error)."),LZr=l(),ra=a("div"),F(PP.$$.fragment),yZr=l(),G9e=a("p"),xZr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),$Zr=l(),Cc=a("p"),kZr=o(`Note:
Loading a model from its configuration file does `),O9e=a("strong"),SZr=o("not"),RZr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ene=a("a"),PZr=o("from_pretrained()"),BZr=o(" to load the model weights."),IZr=l(),F(Ow.$$.fragment),NZr=l(),zr=a("div"),F(BP.$$.fragment),qZr=l(),V9e=a("p"),jZr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),DZr=l(),On=a("p"),GZr=o("The model class to instantiate is selected based on the "),X9e=a("code"),OZr=o("model_type"),VZr=o(` property of the config object (either
passed as an argument or loaded from `),z9e=a("code"),XZr=o("pretrained_model_name_or_path"),zZr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q9e=a("code"),QZr=o("pretrained_model_name_or_path"),WZr=o(":"),UZr=l(),de=a("ul"),Vw=a("li"),W9e=a("strong"),HZr=o("albert"),JZr=o(" \u2014 "),Cne=a("a"),YZr=o("TFAlbertForPreTraining"),ZZr=o(" (ALBERT model)"),KZr=l(),Xw=a("li"),U9e=a("strong"),eKr=o("bart"),oKr=o(" \u2014 "),wne=a("a"),rKr=o("TFBartForConditionalGeneration"),tKr=o(" (BART model)"),aKr=l(),zw=a("li"),H9e=a("strong"),nKr=o("bert"),sKr=o(" \u2014 "),Ane=a("a"),lKr=o("TFBertForPreTraining"),iKr=o(" (BERT model)"),dKr=l(),Qw=a("li"),J9e=a("strong"),mKr=o("camembert"),cKr=o(" \u2014 "),Lne=a("a"),fKr=o("TFCamembertForMaskedLM"),gKr=o(" (CamemBERT model)"),hKr=l(),Ww=a("li"),Y9e=a("strong"),uKr=o("ctrl"),pKr=o(" \u2014 "),yne=a("a"),_Kr=o("TFCTRLLMHeadModel"),bKr=o(" (CTRL model)"),vKr=l(),Uw=a("li"),Z9e=a("strong"),FKr=o("distilbert"),TKr=o(" \u2014 "),xne=a("a"),MKr=o("TFDistilBertForMaskedLM"),EKr=o(" (DistilBERT model)"),CKr=l(),Hw=a("li"),K9e=a("strong"),wKr=o("electra"),AKr=o(" \u2014 "),$ne=a("a"),LKr=o("TFElectraForPreTraining"),yKr=o(" (ELECTRA model)"),xKr=l(),Jw=a("li"),exe=a("strong"),$Kr=o("flaubert"),kKr=o(" \u2014 "),kne=a("a"),SKr=o("TFFlaubertWithLMHeadModel"),RKr=o(" (FlauBERT model)"),PKr=l(),Yw=a("li"),oxe=a("strong"),BKr=o("funnel"),IKr=o(" \u2014 "),Sne=a("a"),NKr=o("TFFunnelForPreTraining"),qKr=o(" (Funnel Transformer model)"),jKr=l(),Zw=a("li"),rxe=a("strong"),DKr=o("gpt2"),GKr=o(" \u2014 "),Rne=a("a"),OKr=o("TFGPT2LMHeadModel"),VKr=o(" (OpenAI GPT-2 model)"),XKr=l(),Kw=a("li"),txe=a("strong"),zKr=o("layoutlm"),QKr=o(" \u2014 "),Pne=a("a"),WKr=o("TFLayoutLMForMaskedLM"),UKr=o(" (LayoutLM model)"),HKr=l(),eA=a("li"),axe=a("strong"),JKr=o("lxmert"),YKr=o(" \u2014 "),Bne=a("a"),ZKr=o("TFLxmertForPreTraining"),KKr=o(" (LXMERT model)"),eet=l(),oA=a("li"),nxe=a("strong"),oet=o("mobilebert"),ret=o(" \u2014 "),Ine=a("a"),tet=o("TFMobileBertForPreTraining"),aet=o(" (MobileBERT model)"),net=l(),rA=a("li"),sxe=a("strong"),set=o("mpnet"),iet=o(" \u2014 "),Nne=a("a"),det=o("TFMPNetForMaskedLM"),met=o(" (MPNet model)"),cet=l(),tA=a("li"),lxe=a("strong"),fet=o("openai-gpt"),get=o(" \u2014 "),qne=a("a"),het=o("TFOpenAIGPTLMHeadModel"),uet=o(" (OpenAI GPT model)"),pet=l(),aA=a("li"),ixe=a("strong"),_et=o("roberta"),bet=o(" \u2014 "),jne=a("a"),vet=o("TFRobertaForMaskedLM"),Fet=o(" (RoBERTa model)"),Tet=l(),nA=a("li"),dxe=a("strong"),Met=o("t5"),Eet=o(" \u2014 "),Dne=a("a"),Cet=o("TFT5ForConditionalGeneration"),wet=o(" (T5 model)"),Aet=l(),sA=a("li"),mxe=a("strong"),Let=o("tapas"),yet=o(" \u2014 "),Gne=a("a"),xet=o("TFTapasForMaskedLM"),$et=o(" (TAPAS model)"),ket=l(),lA=a("li"),cxe=a("strong"),Set=o("transfo-xl"),Ret=o(" \u2014 "),One=a("a"),Pet=o("TFTransfoXLLMHeadModel"),Bet=o(" (Transformer-XL model)"),Iet=l(),iA=a("li"),fxe=a("strong"),Net=o("vit_mae"),qet=o(" \u2014 "),Vne=a("a"),jet=o("TFViTMAEForPreTraining"),Det=o(" (ViTMAE model)"),Get=l(),dA=a("li"),gxe=a("strong"),Oet=o("xlm"),Vet=o(" \u2014 "),Xne=a("a"),Xet=o("TFXLMWithLMHeadModel"),zet=o(" (XLM model)"),Qet=l(),mA=a("li"),hxe=a("strong"),Wet=o("xlm-roberta"),Uet=o(" \u2014 "),zne=a("a"),Het=o("TFXLMRobertaForMaskedLM"),Jet=o(" (XLM-RoBERTa model)"),Yet=l(),cA=a("li"),uxe=a("strong"),Zet=o("xlnet"),Ket=o(" \u2014 "),Qne=a("a"),eot=o("TFXLNetLMHeadModel"),oot=o(" (XLNet model)"),rot=l(),F(fA.$$.fragment),Hio=l(),wc=a("h2"),gA=a("a"),pxe=a("span"),F(IP.$$.fragment),tot=l(),_xe=a("span"),aot=o("TFAutoModelForCausalLM"),Jio=l(),pr=a("div"),F(NP.$$.fragment),not=l(),Ac=a("p"),sot=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Wne=a("a"),lot=o("from_pretrained()"),iot=o(" class method or the "),Une=a("a"),dot=o("from_config()"),mot=o(` class
method.`),cot=l(),qP=a("p"),fot=o("This class cannot be instantiated directly using "),bxe=a("code"),got=o("__init__()"),hot=o(" (throws an error)."),uot=l(),ta=a("div"),F(jP.$$.fragment),pot=l(),vxe=a("p"),_ot=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),bot=l(),Lc=a("p"),vot=o(`Note:
Loading a model from its configuration file does `),Fxe=a("strong"),Fot=o("not"),Tot=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Hne=a("a"),Mot=o("from_pretrained()"),Eot=o(" to load the model weights."),Cot=l(),F(hA.$$.fragment),wot=l(),Qr=a("div"),F(DP.$$.fragment),Aot=l(),Txe=a("p"),Lot=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),yot=l(),Vn=a("p"),xot=o("The model class to instantiate is selected based on the "),Mxe=a("code"),$ot=o("model_type"),kot=o(` property of the config object (either
passed as an argument or loaded from `),Exe=a("code"),Sot=o("pretrained_model_name_or_path"),Rot=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Cxe=a("code"),Pot=o("pretrained_model_name_or_path"),Bot=o(":"),Iot=l(),Ce=a("ul"),uA=a("li"),wxe=a("strong"),Not=o("bert"),qot=o(" \u2014 "),Jne=a("a"),jot=o("TFBertLMHeadModel"),Dot=o(" (BERT model)"),Got=l(),pA=a("li"),Axe=a("strong"),Oot=o("camembert"),Vot=o(" \u2014 "),Yne=a("a"),Xot=o("TFCamembertForCausalLM"),zot=o(" (CamemBERT model)"),Qot=l(),_A=a("li"),Lxe=a("strong"),Wot=o("ctrl"),Uot=o(" \u2014 "),Zne=a("a"),Hot=o("TFCTRLLMHeadModel"),Jot=o(" (CTRL model)"),Yot=l(),bA=a("li"),yxe=a("strong"),Zot=o("gpt2"),Kot=o(" \u2014 "),Kne=a("a"),ert=o("TFGPT2LMHeadModel"),ort=o(" (OpenAI GPT-2 model)"),rrt=l(),vA=a("li"),xxe=a("strong"),trt=o("gptj"),art=o(" \u2014 "),ese=a("a"),nrt=o("TFGPTJForCausalLM"),srt=o(" (GPT-J model)"),lrt=l(),FA=a("li"),$xe=a("strong"),irt=o("openai-gpt"),drt=o(" \u2014 "),ose=a("a"),mrt=o("TFOpenAIGPTLMHeadModel"),crt=o(" (OpenAI GPT model)"),frt=l(),TA=a("li"),kxe=a("strong"),grt=o("opt"),hrt=o(" \u2014 "),rse=a("a"),urt=o("TFOPTForCausalLM"),prt=o(" (OPT model)"),_rt=l(),MA=a("li"),Sxe=a("strong"),brt=o("rembert"),vrt=o(" \u2014 "),tse=a("a"),Frt=o("TFRemBertForCausalLM"),Trt=o(" (RemBERT model)"),Mrt=l(),EA=a("li"),Rxe=a("strong"),Ert=o("roberta"),Crt=o(" \u2014 "),ase=a("a"),wrt=o("TFRobertaForCausalLM"),Art=o(" (RoBERTa model)"),Lrt=l(),CA=a("li"),Pxe=a("strong"),yrt=o("roformer"),xrt=o(" \u2014 "),nse=a("a"),$rt=o("TFRoFormerForCausalLM"),krt=o(" (RoFormer model)"),Srt=l(),wA=a("li"),Bxe=a("strong"),Rrt=o("transfo-xl"),Prt=o(" \u2014 "),sse=a("a"),Brt=o("TFTransfoXLLMHeadModel"),Irt=o(" (Transformer-XL model)"),Nrt=l(),AA=a("li"),Ixe=a("strong"),qrt=o("xglm"),jrt=o(" \u2014 "),lse=a("a"),Drt=o("TFXGLMForCausalLM"),Grt=o(" (XGLM model)"),Ort=l(),LA=a("li"),Nxe=a("strong"),Vrt=o("xlm"),Xrt=o(" \u2014 "),ise=a("a"),zrt=o("TFXLMWithLMHeadModel"),Qrt=o(" (XLM model)"),Wrt=l(),yA=a("li"),qxe=a("strong"),Urt=o("xlnet"),Hrt=o(" \u2014 "),dse=a("a"),Jrt=o("TFXLNetLMHeadModel"),Yrt=o(" (XLNet model)"),Zrt=l(),F(xA.$$.fragment),Yio=l(),yc=a("h2"),$A=a("a"),jxe=a("span"),F(GP.$$.fragment),Krt=l(),Dxe=a("span"),ett=o("TFAutoModelForImageClassification"),Zio=l(),_r=a("div"),F(OP.$$.fragment),ott=l(),xc=a("p"),rtt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),mse=a("a"),ttt=o("from_pretrained()"),att=o(" class method or the "),cse=a("a"),ntt=o("from_config()"),stt=o(` class
method.`),ltt=l(),VP=a("p"),itt=o("This class cannot be instantiated directly using "),Gxe=a("code"),dtt=o("__init__()"),mtt=o(" (throws an error)."),ctt=l(),aa=a("div"),F(XP.$$.fragment),ftt=l(),Oxe=a("p"),gtt=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),htt=l(),$c=a("p"),utt=o(`Note:
Loading a model from its configuration file does `),Vxe=a("strong"),ptt=o("not"),_tt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fse=a("a"),btt=o("from_pretrained()"),vtt=o(" to load the model weights."),Ftt=l(),F(kA.$$.fragment),Ttt=l(),Wr=a("div"),F(zP.$$.fragment),Mtt=l(),Xxe=a("p"),Ett=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Ctt=l(),Xn=a("p"),wtt=o("The model class to instantiate is selected based on the "),zxe=a("code"),Att=o("model_type"),Ltt=o(` property of the config object (either
passed as an argument or loaded from `),Qxe=a("code"),ytt=o("pretrained_model_name_or_path"),xtt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wxe=a("code"),$tt=o("pretrained_model_name_or_path"),ktt=o(":"),Stt=l(),$e=a("ul"),SA=a("li"),Uxe=a("strong"),Rtt=o("convnext"),Ptt=o(" \u2014 "),gse=a("a"),Btt=o("TFConvNextForImageClassification"),Itt=o(" (ConvNeXT model)"),Ntt=l(),RA=a("li"),Hxe=a("strong"),qtt=o("cvt"),jtt=o(" \u2014 "),hse=a("a"),Dtt=o("TFCvtForImageClassification"),Gtt=o(" (CvT model)"),Ott=l(),PA=a("li"),Jxe=a("strong"),Vtt=o("data2vec-vision"),Xtt=o(" \u2014 "),use=a("a"),ztt=o("TFData2VecVisionForImageClassification"),Qtt=o(" (Data2VecVision model)"),Wtt=l(),Dl=a("li"),Yxe=a("strong"),Utt=o("deit"),Htt=o(" \u2014 "),pse=a("a"),Jtt=o("TFDeiTForImageClassification"),Ytt=o(" or "),_se=a("a"),Ztt=o("TFDeiTForImageClassificationWithTeacher"),Ktt=o(" (DeiT model)"),eat=l(),BA=a("li"),Zxe=a("strong"),oat=o("mobilevit"),rat=o(" \u2014 "),bse=a("a"),tat=o("TFMobileViTForImageClassification"),aat=o(" (MobileViT model)"),nat=l(),IA=a("li"),Kxe=a("strong"),sat=o("regnet"),lat=o(" \u2014 "),vse=a("a"),iat=o("TFRegNetForImageClassification"),dat=o(" (RegNet model)"),mat=l(),NA=a("li"),e$e=a("strong"),cat=o("resnet"),fat=o(" \u2014 "),Fse=a("a"),gat=o("TFResNetForImageClassification"),hat=o(" (ResNet model)"),uat=l(),qA=a("li"),o$e=a("strong"),pat=o("segformer"),_at=o(" \u2014 "),Tse=a("a"),bat=o("TFSegformerForImageClassification"),vat=o(" (SegFormer model)"),Fat=l(),jA=a("li"),r$e=a("strong"),Tat=o("swin"),Mat=o(" \u2014 "),Mse=a("a"),Eat=o("TFSwinForImageClassification"),Cat=o(" (Swin Transformer model)"),wat=l(),DA=a("li"),t$e=a("strong"),Aat=o("vit"),Lat=o(" \u2014 "),Ese=a("a"),yat=o("TFViTForImageClassification"),xat=o(" (ViT model)"),$at=l(),F(GA.$$.fragment),Kio=l(),kc=a("h2"),OA=a("a"),a$e=a("span"),F(QP.$$.fragment),kat=l(),n$e=a("span"),Sat=o("TFAutoModelForSemanticSegmentation"),edo=l(),br=a("div"),F(WP.$$.fragment),Rat=l(),Sc=a("p"),Pat=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Cse=a("a"),Bat=o("from_pretrained()"),Iat=o(" class method or the "),wse=a("a"),Nat=o("from_config()"),qat=o(` class
method.`),jat=l(),UP=a("p"),Dat=o("This class cannot be instantiated directly using "),s$e=a("code"),Gat=o("__init__()"),Oat=o(" (throws an error)."),Vat=l(),na=a("div"),F(HP.$$.fragment),Xat=l(),l$e=a("p"),zat=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Qat=l(),Rc=a("p"),Wat=o(`Note:
Loading a model from its configuration file does `),i$e=a("strong"),Uat=o("not"),Hat=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ase=a("a"),Jat=o("from_pretrained()"),Yat=o(" to load the model weights."),Zat=l(),F(VA.$$.fragment),Kat=l(),Ur=a("div"),F(JP.$$.fragment),ent=l(),d$e=a("p"),ont=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),rnt=l(),zn=a("p"),tnt=o("The model class to instantiate is selected based on the "),m$e=a("code"),ant=o("model_type"),nnt=o(` property of the config object (either
passed as an argument or loaded from `),c$e=a("code"),snt=o("pretrained_model_name_or_path"),lnt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f$e=a("code"),int=o("pretrained_model_name_or_path"),dnt=o(":"),mnt=l(),Pc=a("ul"),XA=a("li"),g$e=a("strong"),cnt=o("data2vec-vision"),fnt=o(" \u2014 "),Lse=a("a"),gnt=o("TFData2VecVisionForSemanticSegmentation"),hnt=o(" (Data2VecVision model)"),unt=l(),zA=a("li"),h$e=a("strong"),pnt=o("mobilevit"),_nt=o(" \u2014 "),yse=a("a"),bnt=o("TFMobileViTForSemanticSegmentation"),vnt=o(" (MobileViT model)"),Fnt=l(),QA=a("li"),u$e=a("strong"),Tnt=o("segformer"),Mnt=o(" \u2014 "),xse=a("a"),Ent=o("TFSegformerForSemanticSegmentation"),Cnt=o(" (SegFormer model)"),wnt=l(),F(WA.$$.fragment),odo=l(),Bc=a("h2"),UA=a("a"),p$e=a("span"),F(YP.$$.fragment),Ant=l(),_$e=a("span"),Lnt=o("TFAutoModelForMaskedLM"),rdo=l(),vr=a("div"),F(ZP.$$.fragment),ynt=l(),Ic=a("p"),xnt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),$se=a("a"),$nt=o("from_pretrained()"),knt=o(" class method or the "),kse=a("a"),Snt=o("from_config()"),Rnt=o(` class
method.`),Pnt=l(),KP=a("p"),Bnt=o("This class cannot be instantiated directly using "),b$e=a("code"),Int=o("__init__()"),Nnt=o(" (throws an error)."),qnt=l(),sa=a("div"),F(eB.$$.fragment),jnt=l(),v$e=a("p"),Dnt=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Gnt=l(),Nc=a("p"),Ont=o(`Note:
Loading a model from its configuration file does `),F$e=a("strong"),Vnt=o("not"),Xnt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Sse=a("a"),znt=o("from_pretrained()"),Qnt=o(" to load the model weights."),Wnt=l(),F(HA.$$.fragment),Unt=l(),Hr=a("div"),F(oB.$$.fragment),Hnt=l(),T$e=a("p"),Jnt=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Ynt=l(),Qn=a("p"),Znt=o("The model class to instantiate is selected based on the "),M$e=a("code"),Knt=o("model_type"),est=o(` property of the config object (either
passed as an argument or loaded from `),E$e=a("code"),ost=o("pretrained_model_name_or_path"),rst=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C$e=a("code"),tst=o("pretrained_model_name_or_path"),ast=o(":"),nst=l(),ge=a("ul"),JA=a("li"),w$e=a("strong"),sst=o("albert"),lst=o(" \u2014 "),Rse=a("a"),ist=o("TFAlbertForMaskedLM"),dst=o(" (ALBERT model)"),mst=l(),YA=a("li"),A$e=a("strong"),cst=o("bert"),fst=o(" \u2014 "),Pse=a("a"),gst=o("TFBertForMaskedLM"),hst=o(" (BERT model)"),ust=l(),ZA=a("li"),L$e=a("strong"),pst=o("camembert"),_st=o(" \u2014 "),Bse=a("a"),bst=o("TFCamembertForMaskedLM"),vst=o(" (CamemBERT model)"),Fst=l(),KA=a("li"),y$e=a("strong"),Tst=o("convbert"),Mst=o(" \u2014 "),Ise=a("a"),Est=o("TFConvBertForMaskedLM"),Cst=o(" (ConvBERT model)"),wst=l(),e6=a("li"),x$e=a("strong"),Ast=o("deberta"),Lst=o(" \u2014 "),Nse=a("a"),yst=o("TFDebertaForMaskedLM"),xst=o(" (DeBERTa model)"),$st=l(),o6=a("li"),$$e=a("strong"),kst=o("deberta-v2"),Sst=o(" \u2014 "),qse=a("a"),Rst=o("TFDebertaV2ForMaskedLM"),Pst=o(" (DeBERTa-v2 model)"),Bst=l(),r6=a("li"),k$e=a("strong"),Ist=o("distilbert"),Nst=o(" \u2014 "),jse=a("a"),qst=o("TFDistilBertForMaskedLM"),jst=o(" (DistilBERT model)"),Dst=l(),t6=a("li"),S$e=a("strong"),Gst=o("electra"),Ost=o(" \u2014 "),Dse=a("a"),Vst=o("TFElectraForMaskedLM"),Xst=o(" (ELECTRA model)"),zst=l(),a6=a("li"),R$e=a("strong"),Qst=o("esm"),Wst=o(" \u2014 "),Gse=a("a"),Ust=o("TFEsmForMaskedLM"),Hst=o(" (ESM model)"),Jst=l(),n6=a("li"),P$e=a("strong"),Yst=o("flaubert"),Zst=o(" \u2014 "),Ose=a("a"),Kst=o("TFFlaubertWithLMHeadModel"),elt=o(" (FlauBERT model)"),olt=l(),s6=a("li"),B$e=a("strong"),rlt=o("funnel"),tlt=o(" \u2014 "),Vse=a("a"),alt=o("TFFunnelForMaskedLM"),nlt=o(" (Funnel Transformer model)"),slt=l(),l6=a("li"),I$e=a("strong"),llt=o("layoutlm"),ilt=o(" \u2014 "),Xse=a("a"),dlt=o("TFLayoutLMForMaskedLM"),mlt=o(" (LayoutLM model)"),clt=l(),i6=a("li"),N$e=a("strong"),flt=o("longformer"),glt=o(" \u2014 "),zse=a("a"),hlt=o("TFLongformerForMaskedLM"),ult=o(" (Longformer model)"),plt=l(),d6=a("li"),q$e=a("strong"),_lt=o("mobilebert"),blt=o(" \u2014 "),Qse=a("a"),vlt=o("TFMobileBertForMaskedLM"),Flt=o(" (MobileBERT model)"),Tlt=l(),m6=a("li"),j$e=a("strong"),Mlt=o("mpnet"),Elt=o(" \u2014 "),Wse=a("a"),Clt=o("TFMPNetForMaskedLM"),wlt=o(" (MPNet model)"),Alt=l(),c6=a("li"),D$e=a("strong"),Llt=o("rembert"),ylt=o(" \u2014 "),Use=a("a"),xlt=o("TFRemBertForMaskedLM"),$lt=o(" (RemBERT model)"),klt=l(),f6=a("li"),G$e=a("strong"),Slt=o("roberta"),Rlt=o(" \u2014 "),Hse=a("a"),Plt=o("TFRobertaForMaskedLM"),Blt=o(" (RoBERTa model)"),Ilt=l(),g6=a("li"),O$e=a("strong"),Nlt=o("roformer"),qlt=o(" \u2014 "),Jse=a("a"),jlt=o("TFRoFormerForMaskedLM"),Dlt=o(" (RoFormer model)"),Glt=l(),h6=a("li"),V$e=a("strong"),Olt=o("tapas"),Vlt=o(" \u2014 "),Yse=a("a"),Xlt=o("TFTapasForMaskedLM"),zlt=o(" (TAPAS model)"),Qlt=l(),u6=a("li"),X$e=a("strong"),Wlt=o("xlm"),Ult=o(" \u2014 "),Zse=a("a"),Hlt=o("TFXLMWithLMHeadModel"),Jlt=o(" (XLM model)"),Ylt=l(),p6=a("li"),z$e=a("strong"),Zlt=o("xlm-roberta"),Klt=o(" \u2014 "),Kse=a("a"),eit=o("TFXLMRobertaForMaskedLM"),oit=o(" (XLM-RoBERTa model)"),rit=l(),F(_6.$$.fragment),tdo=l(),qc=a("h2"),b6=a("a"),Q$e=a("span"),F(rB.$$.fragment),tit=l(),W$e=a("span"),ait=o("TFAutoModelForSeq2SeqLM"),ado=l(),Fr=a("div"),F(tB.$$.fragment),nit=l(),jc=a("p"),sit=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),ele=a("a"),lit=o("from_pretrained()"),iit=o(" class method or the "),ole=a("a"),dit=o("from_config()"),mit=o(` class
method.`),cit=l(),aB=a("p"),fit=o("This class cannot be instantiated directly using "),U$e=a("code"),git=o("__init__()"),hit=o(" (throws an error)."),uit=l(),la=a("div"),F(nB.$$.fragment),pit=l(),H$e=a("p"),_it=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),bit=l(),Dc=a("p"),vit=o(`Note:
Loading a model from its configuration file does `),J$e=a("strong"),Fit=o("not"),Tit=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rle=a("a"),Mit=o("from_pretrained()"),Eit=o(" to load the model weights."),Cit=l(),F(v6.$$.fragment),wit=l(),Jr=a("div"),F(sB.$$.fragment),Ait=l(),Y$e=a("p"),Lit=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),yit=l(),Wn=a("p"),xit=o("The model class to instantiate is selected based on the "),Z$e=a("code"),$it=o("model_type"),kit=o(` property of the config object (either
passed as an argument or loaded from `),K$e=a("code"),Sit=o("pretrained_model_name_or_path"),Rit=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eke=a("code"),Pit=o("pretrained_model_name_or_path"),Bit=o(":"),Iit=l(),ke=a("ul"),F6=a("li"),oke=a("strong"),Nit=o("bart"),qit=o(" \u2014 "),tle=a("a"),jit=o("TFBartForConditionalGeneration"),Dit=o(" (BART model)"),Git=l(),T6=a("li"),rke=a("strong"),Oit=o("blenderbot"),Vit=o(" \u2014 "),ale=a("a"),Xit=o("TFBlenderbotForConditionalGeneration"),zit=o(" (Blenderbot model)"),Qit=l(),M6=a("li"),tke=a("strong"),Wit=o("blenderbot-small"),Uit=o(" \u2014 "),nle=a("a"),Hit=o("TFBlenderbotSmallForConditionalGeneration"),Jit=o(" (BlenderbotSmall model)"),Yit=l(),E6=a("li"),ake=a("strong"),Zit=o("encoder-decoder"),Kit=o(" \u2014 "),sle=a("a"),edt=o("TFEncoderDecoderModel"),odt=o(" (Encoder decoder model)"),rdt=l(),C6=a("li"),nke=a("strong"),tdt=o("led"),adt=o(" \u2014 "),lle=a("a"),ndt=o("TFLEDForConditionalGeneration"),sdt=o(" (LED model)"),ldt=l(),w6=a("li"),ske=a("strong"),idt=o("marian"),ddt=o(" \u2014 "),ile=a("a"),mdt=o("TFMarianMTModel"),cdt=o(" (Marian model)"),fdt=l(),A6=a("li"),lke=a("strong"),gdt=o("mbart"),hdt=o(" \u2014 "),dle=a("a"),udt=o("TFMBartForConditionalGeneration"),pdt=o(" (mBART model)"),_dt=l(),L6=a("li"),ike=a("strong"),bdt=o("mt5"),vdt=o(" \u2014 "),mle=a("a"),Fdt=o("TFMT5ForConditionalGeneration"),Tdt=o(" (MT5 model)"),Mdt=l(),y6=a("li"),dke=a("strong"),Edt=o("pegasus"),Cdt=o(" \u2014 "),cle=a("a"),wdt=o("TFPegasusForConditionalGeneration"),Adt=o(" (Pegasus model)"),Ldt=l(),x6=a("li"),mke=a("strong"),ydt=o("t5"),xdt=o(" \u2014 "),fle=a("a"),$dt=o("TFT5ForConditionalGeneration"),kdt=o(" (T5 model)"),Sdt=l(),F($6.$$.fragment),ndo=l(),Gc=a("h2"),k6=a("a"),cke=a("span"),F(lB.$$.fragment),Rdt=l(),fke=a("span"),Pdt=o("TFAutoModelForSequenceClassification"),sdo=l(),Tr=a("div"),F(iB.$$.fragment),Bdt=l(),Oc=a("p"),Idt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),gle=a("a"),Ndt=o("from_pretrained()"),qdt=o(" class method or the "),hle=a("a"),jdt=o("from_config()"),Ddt=o(` class
method.`),Gdt=l(),dB=a("p"),Odt=o("This class cannot be instantiated directly using "),gke=a("code"),Vdt=o("__init__()"),Xdt=o(" (throws an error)."),zdt=l(),ia=a("div"),F(mB.$$.fragment),Qdt=l(),hke=a("p"),Wdt=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Udt=l(),Vc=a("p"),Hdt=o(`Note:
Loading a model from its configuration file does `),uke=a("strong"),Jdt=o("not"),Ydt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ule=a("a"),Zdt=o("from_pretrained()"),Kdt=o(" to load the model weights."),emt=l(),F(S6.$$.fragment),omt=l(),Yr=a("div"),F(cB.$$.fragment),rmt=l(),pke=a("p"),tmt=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),amt=l(),Un=a("p"),nmt=o("The model class to instantiate is selected based on the "),_ke=a("code"),smt=o("model_type"),lmt=o(` property of the config object (either
passed as an argument or loaded from `),bke=a("code"),imt=o("pretrained_model_name_or_path"),dmt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vke=a("code"),mmt=o("pretrained_model_name_or_path"),cmt=o(":"),fmt=l(),te=a("ul"),R6=a("li"),Fke=a("strong"),gmt=o("albert"),hmt=o(" \u2014 "),ple=a("a"),umt=o("TFAlbertForSequenceClassification"),pmt=o(" (ALBERT model)"),_mt=l(),P6=a("li"),Tke=a("strong"),bmt=o("bert"),vmt=o(" \u2014 "),_le=a("a"),Fmt=o("TFBertForSequenceClassification"),Tmt=o(" (BERT model)"),Mmt=l(),B6=a("li"),Mke=a("strong"),Emt=o("camembert"),Cmt=o(" \u2014 "),ble=a("a"),wmt=o("TFCamembertForSequenceClassification"),Amt=o(" (CamemBERT model)"),Lmt=l(),I6=a("li"),Eke=a("strong"),ymt=o("convbert"),xmt=o(" \u2014 "),vle=a("a"),$mt=o("TFConvBertForSequenceClassification"),kmt=o(" (ConvBERT model)"),Smt=l(),N6=a("li"),Cke=a("strong"),Rmt=o("ctrl"),Pmt=o(" \u2014 "),Fle=a("a"),Bmt=o("TFCTRLForSequenceClassification"),Imt=o(" (CTRL model)"),Nmt=l(),q6=a("li"),wke=a("strong"),qmt=o("deberta"),jmt=o(" \u2014 "),Tle=a("a"),Dmt=o("TFDebertaForSequenceClassification"),Gmt=o(" (DeBERTa model)"),Omt=l(),j6=a("li"),Ake=a("strong"),Vmt=o("deberta-v2"),Xmt=o(" \u2014 "),Mle=a("a"),zmt=o("TFDebertaV2ForSequenceClassification"),Qmt=o(" (DeBERTa-v2 model)"),Wmt=l(),D6=a("li"),Lke=a("strong"),Umt=o("distilbert"),Hmt=o(" \u2014 "),Ele=a("a"),Jmt=o("TFDistilBertForSequenceClassification"),Ymt=o(" (DistilBERT model)"),Zmt=l(),G6=a("li"),yke=a("strong"),Kmt=o("electra"),ect=o(" \u2014 "),Cle=a("a"),oct=o("TFElectraForSequenceClassification"),rct=o(" (ELECTRA model)"),tct=l(),O6=a("li"),xke=a("strong"),act=o("esm"),nct=o(" \u2014 "),wle=a("a"),sct=o("TFEsmForSequenceClassification"),lct=o(" (ESM model)"),ict=l(),V6=a("li"),$ke=a("strong"),dct=o("flaubert"),mct=o(" \u2014 "),Ale=a("a"),cct=o("TFFlaubertForSequenceClassification"),fct=o(" (FlauBERT model)"),gct=l(),X6=a("li"),kke=a("strong"),hct=o("funnel"),uct=o(" \u2014 "),Lle=a("a"),pct=o("TFFunnelForSequenceClassification"),_ct=o(" (Funnel Transformer model)"),bct=l(),z6=a("li"),Ske=a("strong"),vct=o("gpt2"),Fct=o(" \u2014 "),yle=a("a"),Tct=o("TFGPT2ForSequenceClassification"),Mct=o(" (OpenAI GPT-2 model)"),Ect=l(),Q6=a("li"),Rke=a("strong"),Cct=o("gptj"),wct=o(" \u2014 "),xle=a("a"),Act=o("TFGPTJForSequenceClassification"),Lct=o(" (GPT-J model)"),yct=l(),W6=a("li"),Pke=a("strong"),xct=o("layoutlm"),$ct=o(" \u2014 "),$le=a("a"),kct=o("TFLayoutLMForSequenceClassification"),Sct=o(" (LayoutLM model)"),Rct=l(),U6=a("li"),Bke=a("strong"),Pct=o("layoutlmv3"),Bct=o(" \u2014 "),kle=a("a"),Ict=o("TFLayoutLMv3ForSequenceClassification"),Nct=o(" (LayoutLMv3 model)"),qct=l(),H6=a("li"),Ike=a("strong"),jct=o("longformer"),Dct=o(" \u2014 "),Sle=a("a"),Gct=o("TFLongformerForSequenceClassification"),Oct=o(" (Longformer model)"),Vct=l(),J6=a("li"),Nke=a("strong"),Xct=o("mobilebert"),zct=o(" \u2014 "),Rle=a("a"),Qct=o("TFMobileBertForSequenceClassification"),Wct=o(" (MobileBERT model)"),Uct=l(),Y6=a("li"),qke=a("strong"),Hct=o("mpnet"),Jct=o(" \u2014 "),Ple=a("a"),Yct=o("TFMPNetForSequenceClassification"),Zct=o(" (MPNet model)"),Kct=l(),Z6=a("li"),jke=a("strong"),eft=o("openai-gpt"),oft=o(" \u2014 "),Ble=a("a"),rft=o("TFOpenAIGPTForSequenceClassification"),tft=o(" (OpenAI GPT model)"),aft=l(),K6=a("li"),Dke=a("strong"),nft=o("rembert"),sft=o(" \u2014 "),Ile=a("a"),lft=o("TFRemBertForSequenceClassification"),ift=o(" (RemBERT model)"),dft=l(),e7=a("li"),Gke=a("strong"),mft=o("roberta"),cft=o(" \u2014 "),Nle=a("a"),fft=o("TFRobertaForSequenceClassification"),gft=o(" (RoBERTa model)"),hft=l(),o7=a("li"),Oke=a("strong"),uft=o("roformer"),pft=o(" \u2014 "),qle=a("a"),_ft=o("TFRoFormerForSequenceClassification"),bft=o(" (RoFormer model)"),vft=l(),r7=a("li"),Vke=a("strong"),Fft=o("tapas"),Tft=o(" \u2014 "),jle=a("a"),Mft=o("TFTapasForSequenceClassification"),Eft=o(" (TAPAS model)"),Cft=l(),t7=a("li"),Xke=a("strong"),wft=o("transfo-xl"),Aft=o(" \u2014 "),Dle=a("a"),Lft=o("TFTransfoXLForSequenceClassification"),yft=o(" (Transformer-XL model)"),xft=l(),a7=a("li"),zke=a("strong"),$ft=o("xlm"),kft=o(" \u2014 "),Gle=a("a"),Sft=o("TFXLMForSequenceClassification"),Rft=o(" (XLM model)"),Pft=l(),n7=a("li"),Qke=a("strong"),Bft=o("xlm-roberta"),Ift=o(" \u2014 "),Ole=a("a"),Nft=o("TFXLMRobertaForSequenceClassification"),qft=o(" (XLM-RoBERTa model)"),jft=l(),s7=a("li"),Wke=a("strong"),Dft=o("xlnet"),Gft=o(" \u2014 "),Vle=a("a"),Oft=o("TFXLNetForSequenceClassification"),Vft=o(" (XLNet model)"),Xft=l(),F(l7.$$.fragment),ldo=l(),Xc=a("h2"),i7=a("a"),Uke=a("span"),F(fB.$$.fragment),zft=l(),Hke=a("span"),Qft=o("TFAutoModelForMultipleChoice"),ido=l(),Mr=a("div"),F(gB.$$.fragment),Wft=l(),zc=a("p"),Uft=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Xle=a("a"),Hft=o("from_pretrained()"),Jft=o(" class method or the "),zle=a("a"),Yft=o("from_config()"),Zft=o(` class
method.`),Kft=l(),hB=a("p"),egt=o("This class cannot be instantiated directly using "),Jke=a("code"),ogt=o("__init__()"),rgt=o(" (throws an error)."),tgt=l(),da=a("div"),F(uB.$$.fragment),agt=l(),Yke=a("p"),ngt=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),sgt=l(),Qc=a("p"),lgt=o(`Note:
Loading a model from its configuration file does `),Zke=a("strong"),igt=o("not"),dgt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Qle=a("a"),mgt=o("from_pretrained()"),cgt=o(" to load the model weights."),fgt=l(),F(d7.$$.fragment),ggt=l(),Zr=a("div"),F(pB.$$.fragment),hgt=l(),Kke=a("p"),ugt=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),pgt=l(),Hn=a("p"),_gt=o("The model class to instantiate is selected based on the "),eSe=a("code"),bgt=o("model_type"),vgt=o(` property of the config object (either
passed as an argument or loaded from `),oSe=a("code"),Fgt=o("pretrained_model_name_or_path"),Tgt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rSe=a("code"),Mgt=o("pretrained_model_name_or_path"),Egt=o(":"),Cgt=l(),Te=a("ul"),m7=a("li"),tSe=a("strong"),wgt=o("albert"),Agt=o(" \u2014 "),Wle=a("a"),Lgt=o("TFAlbertForMultipleChoice"),ygt=o(" (ALBERT model)"),xgt=l(),c7=a("li"),aSe=a("strong"),$gt=o("bert"),kgt=o(" \u2014 "),Ule=a("a"),Sgt=o("TFBertForMultipleChoice"),Rgt=o(" (BERT model)"),Pgt=l(),f7=a("li"),nSe=a("strong"),Bgt=o("camembert"),Igt=o(" \u2014 "),Hle=a("a"),Ngt=o("TFCamembertForMultipleChoice"),qgt=o(" (CamemBERT model)"),jgt=l(),g7=a("li"),sSe=a("strong"),Dgt=o("convbert"),Ggt=o(" \u2014 "),Jle=a("a"),Ogt=o("TFConvBertForMultipleChoice"),Vgt=o(" (ConvBERT model)"),Xgt=l(),h7=a("li"),lSe=a("strong"),zgt=o("distilbert"),Qgt=o(" \u2014 "),Yle=a("a"),Wgt=o("TFDistilBertForMultipleChoice"),Ugt=o(" (DistilBERT model)"),Hgt=l(),u7=a("li"),iSe=a("strong"),Jgt=o("electra"),Ygt=o(" \u2014 "),Zle=a("a"),Zgt=o("TFElectraForMultipleChoice"),Kgt=o(" (ELECTRA model)"),eht=l(),p7=a("li"),dSe=a("strong"),oht=o("flaubert"),rht=o(" \u2014 "),Kle=a("a"),tht=o("TFFlaubertForMultipleChoice"),aht=o(" (FlauBERT model)"),nht=l(),_7=a("li"),mSe=a("strong"),sht=o("funnel"),lht=o(" \u2014 "),eie=a("a"),iht=o("TFFunnelForMultipleChoice"),dht=o(" (Funnel Transformer model)"),mht=l(),b7=a("li"),cSe=a("strong"),cht=o("longformer"),fht=o(" \u2014 "),oie=a("a"),ght=o("TFLongformerForMultipleChoice"),hht=o(" (Longformer model)"),uht=l(),v7=a("li"),fSe=a("strong"),pht=o("mobilebert"),_ht=o(" \u2014 "),rie=a("a"),bht=o("TFMobileBertForMultipleChoice"),vht=o(" (MobileBERT model)"),Fht=l(),F7=a("li"),gSe=a("strong"),Tht=o("mpnet"),Mht=o(" \u2014 "),tie=a("a"),Eht=o("TFMPNetForMultipleChoice"),Cht=o(" (MPNet model)"),wht=l(),T7=a("li"),hSe=a("strong"),Aht=o("rembert"),Lht=o(" \u2014 "),aie=a("a"),yht=o("TFRemBertForMultipleChoice"),xht=o(" (RemBERT model)"),$ht=l(),M7=a("li"),uSe=a("strong"),kht=o("roberta"),Sht=o(" \u2014 "),nie=a("a"),Rht=o("TFRobertaForMultipleChoice"),Pht=o(" (RoBERTa model)"),Bht=l(),E7=a("li"),pSe=a("strong"),Iht=o("roformer"),Nht=o(" \u2014 "),sie=a("a"),qht=o("TFRoFormerForMultipleChoice"),jht=o(" (RoFormer model)"),Dht=l(),C7=a("li"),_Se=a("strong"),Ght=o("xlm"),Oht=o(" \u2014 "),lie=a("a"),Vht=o("TFXLMForMultipleChoice"),Xht=o(" (XLM model)"),zht=l(),w7=a("li"),bSe=a("strong"),Qht=o("xlm-roberta"),Wht=o(" \u2014 "),iie=a("a"),Uht=o("TFXLMRobertaForMultipleChoice"),Hht=o(" (XLM-RoBERTa model)"),Jht=l(),A7=a("li"),vSe=a("strong"),Yht=o("xlnet"),Zht=o(" \u2014 "),die=a("a"),Kht=o("TFXLNetForMultipleChoice"),eut=o(" (XLNet model)"),out=l(),F(L7.$$.fragment),ddo=l(),Wc=a("h2"),y7=a("a"),FSe=a("span"),F(_B.$$.fragment),rut=l(),TSe=a("span"),tut=o("TFAutoModelForNextSentencePrediction"),mdo=l(),Er=a("div"),F(bB.$$.fragment),aut=l(),Uc=a("p"),nut=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),mie=a("a"),sut=o("from_pretrained()"),lut=o(" class method or the "),cie=a("a"),iut=o("from_config()"),dut=o(` class
method.`),mut=l(),vB=a("p"),cut=o("This class cannot be instantiated directly using "),MSe=a("code"),fut=o("__init__()"),gut=o(" (throws an error)."),hut=l(),ma=a("div"),F(FB.$$.fragment),uut=l(),ESe=a("p"),put=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),_ut=l(),Hc=a("p"),but=o(`Note:
Loading a model from its configuration file does `),CSe=a("strong"),vut=o("not"),Fut=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fie=a("a"),Tut=o("from_pretrained()"),Mut=o(" to load the model weights."),Eut=l(),F(x7.$$.fragment),Cut=l(),Kr=a("div"),F(TB.$$.fragment),wut=l(),wSe=a("p"),Aut=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Lut=l(),Jn=a("p"),yut=o("The model class to instantiate is selected based on the "),ASe=a("code"),xut=o("model_type"),$ut=o(` property of the config object (either
passed as an argument or loaded from `),LSe=a("code"),kut=o("pretrained_model_name_or_path"),Sut=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ySe=a("code"),Rut=o("pretrained_model_name_or_path"),Put=o(":"),But=l(),MB=a("ul"),$7=a("li"),xSe=a("strong"),Iut=o("bert"),Nut=o(" \u2014 "),gie=a("a"),qut=o("TFBertForNextSentencePrediction"),jut=o(" (BERT model)"),Dut=l(),k7=a("li"),$Se=a("strong"),Gut=o("mobilebert"),Out=o(" \u2014 "),hie=a("a"),Vut=o("TFMobileBertForNextSentencePrediction"),Xut=o(" (MobileBERT model)"),zut=l(),F(S7.$$.fragment),cdo=l(),Jc=a("h2"),R7=a("a"),kSe=a("span"),F(EB.$$.fragment),Qut=l(),SSe=a("span"),Wut=o("TFAutoModelForTableQuestionAnswering"),fdo=l(),Cr=a("div"),F(CB.$$.fragment),Uut=l(),Yc=a("p"),Hut=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),uie=a("a"),Jut=o("from_pretrained()"),Yut=o(" class method or the "),pie=a("a"),Zut=o("from_config()"),Kut=o(` class
method.`),ept=l(),wB=a("p"),opt=o("This class cannot be instantiated directly using "),RSe=a("code"),rpt=o("__init__()"),tpt=o(" (throws an error)."),apt=l(),ca=a("div"),F(AB.$$.fragment),npt=l(),PSe=a("p"),spt=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),lpt=l(),Zc=a("p"),ipt=o(`Note:
Loading a model from its configuration file does `),BSe=a("strong"),dpt=o("not"),mpt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_ie=a("a"),cpt=o("from_pretrained()"),fpt=o(" to load the model weights."),gpt=l(),F(P7.$$.fragment),hpt=l(),et=a("div"),F(LB.$$.fragment),upt=l(),ISe=a("p"),ppt=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),_pt=l(),Yn=a("p"),bpt=o("The model class to instantiate is selected based on the "),NSe=a("code"),vpt=o("model_type"),Fpt=o(` property of the config object (either
passed as an argument or loaded from `),qSe=a("code"),Tpt=o("pretrained_model_name_or_path"),Mpt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jSe=a("code"),Ept=o("pretrained_model_name_or_path"),Cpt=o(":"),wpt=l(),DSe=a("ul"),B7=a("li"),GSe=a("strong"),Apt=o("tapas"),Lpt=o(" \u2014 "),bie=a("a"),ypt=o("TFTapasForQuestionAnswering"),xpt=o(" (TAPAS model)"),$pt=l(),F(I7.$$.fragment),gdo=l(),Kc=a("h2"),N7=a("a"),OSe=a("span"),F(yB.$$.fragment),kpt=l(),VSe=a("span"),Spt=o("TFAutoModelForDocumentQuestionAnswering"),hdo=l(),wr=a("div"),F(xB.$$.fragment),Rpt=l(),ef=a("p"),Ppt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),vie=a("a"),Bpt=o("from_pretrained()"),Ipt=o(" class method or the "),Fie=a("a"),Npt=o("from_config()"),qpt=o(` class
method.`),jpt=l(),$B=a("p"),Dpt=o("This class cannot be instantiated directly using "),XSe=a("code"),Gpt=o("__init__()"),Opt=o(" (throws an error)."),Vpt=l(),fa=a("div"),F(kB.$$.fragment),Xpt=l(),zSe=a("p"),zpt=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Qpt=l(),of=a("p"),Wpt=o(`Note:
Loading a model from its configuration file does `),QSe=a("strong"),Upt=o("not"),Hpt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Tie=a("a"),Jpt=o("from_pretrained()"),Ypt=o(" to load the model weights."),Zpt=l(),F(q7.$$.fragment),Kpt=l(),ot=a("div"),F(SB.$$.fragment),e_t=l(),WSe=a("p"),o_t=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),r_t=l(),Zn=a("p"),t_t=o("The model class to instantiate is selected based on the "),USe=a("code"),a_t=o("model_type"),n_t=o(` property of the config object (either
passed as an argument or loaded from `),HSe=a("code"),s_t=o("pretrained_model_name_or_path"),l_t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JSe=a("code"),i_t=o("pretrained_model_name_or_path"),d_t=o(":"),m_t=l(),YSe=a("ul"),j7=a("li"),ZSe=a("strong"),c_t=o("layoutlm"),f_t=o(" \u2014 "),Mie=a("a"),g_t=o("TFLayoutLMForQuestionAnswering"),h_t=o(" (LayoutLM model)"),u_t=l(),F(D7.$$.fragment),udo=l(),rf=a("h2"),G7=a("a"),KSe=a("span"),F(RB.$$.fragment),p_t=l(),eRe=a("span"),__t=o("TFAutoModelForTokenClassification"),pdo=l(),Ar=a("div"),F(PB.$$.fragment),b_t=l(),tf=a("p"),v_t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Eie=a("a"),F_t=o("from_pretrained()"),T_t=o(" class method or the "),Cie=a("a"),M_t=o("from_config()"),E_t=o(` class
method.`),C_t=l(),BB=a("p"),w_t=o("This class cannot be instantiated directly using "),oRe=a("code"),A_t=o("__init__()"),L_t=o(" (throws an error)."),y_t=l(),ga=a("div"),F(IB.$$.fragment),x_t=l(),rRe=a("p"),$_t=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),k_t=l(),af=a("p"),S_t=o(`Note:
Loading a model from its configuration file does `),tRe=a("strong"),R_t=o("not"),P_t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wie=a("a"),B_t=o("from_pretrained()"),I_t=o(" to load the model weights."),N_t=l(),F(O7.$$.fragment),q_t=l(),rt=a("div"),F(NB.$$.fragment),j_t=l(),aRe=a("p"),D_t=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),G_t=l(),Kn=a("p"),O_t=o("The model class to instantiate is selected based on the "),nRe=a("code"),V_t=o("model_type"),X_t=o(` property of the config object (either
passed as an argument or loaded from `),sRe=a("code"),z_t=o("pretrained_model_name_or_path"),Q_t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lRe=a("code"),W_t=o("pretrained_model_name_or_path"),U_t=o(":"),H_t=l(),me=a("ul"),V7=a("li"),iRe=a("strong"),J_t=o("albert"),Y_t=o(" \u2014 "),Aie=a("a"),Z_t=o("TFAlbertForTokenClassification"),K_t=o(" (ALBERT model)"),e1t=l(),X7=a("li"),dRe=a("strong"),o1t=o("bert"),r1t=o(" \u2014 "),Lie=a("a"),t1t=o("TFBertForTokenClassification"),a1t=o(" (BERT model)"),n1t=l(),z7=a("li"),mRe=a("strong"),s1t=o("camembert"),l1t=o(" \u2014 "),yie=a("a"),i1t=o("TFCamembertForTokenClassification"),d1t=o(" (CamemBERT model)"),m1t=l(),Q7=a("li"),cRe=a("strong"),c1t=o("convbert"),f1t=o(" \u2014 "),xie=a("a"),g1t=o("TFConvBertForTokenClassification"),h1t=o(" (ConvBERT model)"),u1t=l(),W7=a("li"),fRe=a("strong"),p1t=o("deberta"),_1t=o(" \u2014 "),$ie=a("a"),b1t=o("TFDebertaForTokenClassification"),v1t=o(" (DeBERTa model)"),F1t=l(),U7=a("li"),gRe=a("strong"),T1t=o("deberta-v2"),M1t=o(" \u2014 "),kie=a("a"),E1t=o("TFDebertaV2ForTokenClassification"),C1t=o(" (DeBERTa-v2 model)"),w1t=l(),H7=a("li"),hRe=a("strong"),A1t=o("distilbert"),L1t=o(" \u2014 "),Sie=a("a"),y1t=o("TFDistilBertForTokenClassification"),x1t=o(" (DistilBERT model)"),$1t=l(),J7=a("li"),uRe=a("strong"),k1t=o("electra"),S1t=o(" \u2014 "),Rie=a("a"),R1t=o("TFElectraForTokenClassification"),P1t=o(" (ELECTRA model)"),B1t=l(),Y7=a("li"),pRe=a("strong"),I1t=o("esm"),N1t=o(" \u2014 "),Pie=a("a"),q1t=o("TFEsmForTokenClassification"),j1t=o(" (ESM model)"),D1t=l(),Z7=a("li"),_Re=a("strong"),G1t=o("flaubert"),O1t=o(" \u2014 "),Bie=a("a"),V1t=o("TFFlaubertForTokenClassification"),X1t=o(" (FlauBERT model)"),z1t=l(),K7=a("li"),bRe=a("strong"),Q1t=o("funnel"),W1t=o(" \u2014 "),Iie=a("a"),U1t=o("TFFunnelForTokenClassification"),H1t=o(" (Funnel Transformer model)"),J1t=l(),e8=a("li"),vRe=a("strong"),Y1t=o("layoutlm"),Z1t=o(" \u2014 "),Nie=a("a"),K1t=o("TFLayoutLMForTokenClassification"),e2t=o(" (LayoutLM model)"),o2t=l(),o8=a("li"),FRe=a("strong"),r2t=o("layoutlmv3"),t2t=o(" \u2014 "),qie=a("a"),a2t=o("TFLayoutLMv3ForTokenClassification"),n2t=o(" (LayoutLMv3 model)"),s2t=l(),r8=a("li"),TRe=a("strong"),l2t=o("longformer"),i2t=o(" \u2014 "),jie=a("a"),d2t=o("TFLongformerForTokenClassification"),m2t=o(" (Longformer model)"),c2t=l(),t8=a("li"),MRe=a("strong"),f2t=o("mobilebert"),g2t=o(" \u2014 "),Die=a("a"),h2t=o("TFMobileBertForTokenClassification"),u2t=o(" (MobileBERT model)"),p2t=l(),a8=a("li"),ERe=a("strong"),_2t=o("mpnet"),b2t=o(" \u2014 "),Gie=a("a"),v2t=o("TFMPNetForTokenClassification"),F2t=o(" (MPNet model)"),T2t=l(),n8=a("li"),CRe=a("strong"),M2t=o("rembert"),E2t=o(" \u2014 "),Oie=a("a"),C2t=o("TFRemBertForTokenClassification"),w2t=o(" (RemBERT model)"),A2t=l(),s8=a("li"),wRe=a("strong"),L2t=o("roberta"),y2t=o(" \u2014 "),Vie=a("a"),x2t=o("TFRobertaForTokenClassification"),$2t=o(" (RoBERTa model)"),k2t=l(),l8=a("li"),ARe=a("strong"),S2t=o("roformer"),R2t=o(" \u2014 "),Xie=a("a"),P2t=o("TFRoFormerForTokenClassification"),B2t=o(" (RoFormer model)"),I2t=l(),i8=a("li"),LRe=a("strong"),N2t=o("xlm"),q2t=o(" \u2014 "),zie=a("a"),j2t=o("TFXLMForTokenClassification"),D2t=o(" (XLM model)"),G2t=l(),d8=a("li"),yRe=a("strong"),O2t=o("xlm-roberta"),V2t=o(" \u2014 "),Qie=a("a"),X2t=o("TFXLMRobertaForTokenClassification"),z2t=o(" (XLM-RoBERTa model)"),Q2t=l(),m8=a("li"),xRe=a("strong"),W2t=o("xlnet"),U2t=o(" \u2014 "),Wie=a("a"),H2t=o("TFXLNetForTokenClassification"),J2t=o(" (XLNet model)"),Y2t=l(),F(c8.$$.fragment),_do=l(),nf=a("h2"),f8=a("a"),$Re=a("span"),F(qB.$$.fragment),Z2t=l(),kRe=a("span"),K2t=o("TFAutoModelForQuestionAnswering"),bdo=l(),Lr=a("div"),F(jB.$$.fragment),ebt=l(),sf=a("p"),obt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Uie=a("a"),rbt=o("from_pretrained()"),tbt=o(" class method or the "),Hie=a("a"),abt=o("from_config()"),nbt=o(` class
method.`),sbt=l(),DB=a("p"),lbt=o("This class cannot be instantiated directly using "),SRe=a("code"),ibt=o("__init__()"),dbt=o(" (throws an error)."),mbt=l(),ha=a("div"),F(GB.$$.fragment),cbt=l(),RRe=a("p"),fbt=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),gbt=l(),lf=a("p"),hbt=o(`Note:
Loading a model from its configuration file does `),PRe=a("strong"),ubt=o("not"),pbt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Jie=a("a"),_bt=o("from_pretrained()"),bbt=o(" to load the model weights."),vbt=l(),F(g8.$$.fragment),Fbt=l(),tt=a("div"),F(OB.$$.fragment),Tbt=l(),BRe=a("p"),Mbt=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Ebt=l(),es=a("p"),Cbt=o("The model class to instantiate is selected based on the "),IRe=a("code"),wbt=o("model_type"),Abt=o(` property of the config object (either
passed as an argument or loaded from `),NRe=a("code"),Lbt=o("pretrained_model_name_or_path"),ybt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qRe=a("code"),xbt=o("pretrained_model_name_or_path"),$bt=o(":"),kbt=l(),he=a("ul"),h8=a("li"),jRe=a("strong"),Sbt=o("albert"),Rbt=o(" \u2014 "),Yie=a("a"),Pbt=o("TFAlbertForQuestionAnswering"),Bbt=o(" (ALBERT model)"),Ibt=l(),u8=a("li"),DRe=a("strong"),Nbt=o("bert"),qbt=o(" \u2014 "),Zie=a("a"),jbt=o("TFBertForQuestionAnswering"),Dbt=o(" (BERT model)"),Gbt=l(),p8=a("li"),GRe=a("strong"),Obt=o("camembert"),Vbt=o(" \u2014 "),Kie=a("a"),Xbt=o("TFCamembertForQuestionAnswering"),zbt=o(" (CamemBERT model)"),Qbt=l(),_8=a("li"),ORe=a("strong"),Wbt=o("convbert"),Ubt=o(" \u2014 "),ede=a("a"),Hbt=o("TFConvBertForQuestionAnswering"),Jbt=o(" (ConvBERT model)"),Ybt=l(),b8=a("li"),VRe=a("strong"),Zbt=o("deberta"),Kbt=o(" \u2014 "),ode=a("a"),evt=o("TFDebertaForQuestionAnswering"),ovt=o(" (DeBERTa model)"),rvt=l(),v8=a("li"),XRe=a("strong"),tvt=o("deberta-v2"),avt=o(" \u2014 "),rde=a("a"),nvt=o("TFDebertaV2ForQuestionAnswering"),svt=o(" (DeBERTa-v2 model)"),lvt=l(),F8=a("li"),zRe=a("strong"),ivt=o("distilbert"),dvt=o(" \u2014 "),tde=a("a"),mvt=o("TFDistilBertForQuestionAnswering"),cvt=o(" (DistilBERT model)"),fvt=l(),T8=a("li"),QRe=a("strong"),gvt=o("electra"),hvt=o(" \u2014 "),ade=a("a"),uvt=o("TFElectraForQuestionAnswering"),pvt=o(" (ELECTRA model)"),_vt=l(),M8=a("li"),WRe=a("strong"),bvt=o("flaubert"),vvt=o(" \u2014 "),nde=a("a"),Fvt=o("TFFlaubertForQuestionAnsweringSimple"),Tvt=o(" (FlauBERT model)"),Mvt=l(),E8=a("li"),URe=a("strong"),Evt=o("funnel"),Cvt=o(" \u2014 "),sde=a("a"),wvt=o("TFFunnelForQuestionAnswering"),Avt=o(" (Funnel Transformer model)"),Lvt=l(),C8=a("li"),HRe=a("strong"),yvt=o("gptj"),xvt=o(" \u2014 "),lde=a("a"),$vt=o("TFGPTJForQuestionAnswering"),kvt=o(" (GPT-J model)"),Svt=l(),w8=a("li"),JRe=a("strong"),Rvt=o("layoutlmv3"),Pvt=o(" \u2014 "),ide=a("a"),Bvt=o("TFLayoutLMv3ForQuestionAnswering"),Ivt=o(" (LayoutLMv3 model)"),Nvt=l(),A8=a("li"),YRe=a("strong"),qvt=o("longformer"),jvt=o(" \u2014 "),dde=a("a"),Dvt=o("TFLongformerForQuestionAnswering"),Gvt=o(" (Longformer model)"),Ovt=l(),L8=a("li"),ZRe=a("strong"),Vvt=o("mobilebert"),Xvt=o(" \u2014 "),mde=a("a"),zvt=o("TFMobileBertForQuestionAnswering"),Qvt=o(" (MobileBERT model)"),Wvt=l(),y8=a("li"),KRe=a("strong"),Uvt=o("mpnet"),Hvt=o(" \u2014 "),cde=a("a"),Jvt=o("TFMPNetForQuestionAnswering"),Yvt=o(" (MPNet model)"),Zvt=l(),x8=a("li"),ePe=a("strong"),Kvt=o("rembert"),eFt=o(" \u2014 "),fde=a("a"),oFt=o("TFRemBertForQuestionAnswering"),rFt=o(" (RemBERT model)"),tFt=l(),$8=a("li"),oPe=a("strong"),aFt=o("roberta"),nFt=o(" \u2014 "),gde=a("a"),sFt=o("TFRobertaForQuestionAnswering"),lFt=o(" (RoBERTa model)"),iFt=l(),k8=a("li"),rPe=a("strong"),dFt=o("roformer"),mFt=o(" \u2014 "),hde=a("a"),cFt=o("TFRoFormerForQuestionAnswering"),fFt=o(" (RoFormer model)"),gFt=l(),S8=a("li"),tPe=a("strong"),hFt=o("xlm"),uFt=o(" \u2014 "),ude=a("a"),pFt=o("TFXLMForQuestionAnsweringSimple"),_Ft=o(" (XLM model)"),bFt=l(),R8=a("li"),aPe=a("strong"),vFt=o("xlm-roberta"),FFt=o(" \u2014 "),pde=a("a"),TFt=o("TFXLMRobertaForQuestionAnswering"),MFt=o(" (XLM-RoBERTa model)"),EFt=l(),P8=a("li"),nPe=a("strong"),CFt=o("xlnet"),wFt=o(" \u2014 "),_de=a("a"),AFt=o("TFXLNetForQuestionAnsweringSimple"),LFt=o(" (XLNet model)"),yFt=l(),F(B8.$$.fragment),vdo=l(),df=a("h2"),I8=a("a"),sPe=a("span"),F(VB.$$.fragment),xFt=l(),lPe=a("span"),$Ft=o("TFAutoModelForVision2Seq"),Fdo=l(),yr=a("div"),F(XB.$$.fragment),kFt=l(),mf=a("p"),SFt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),bde=a("a"),RFt=o("from_pretrained()"),PFt=o(" class method or the "),vde=a("a"),BFt=o("from_config()"),IFt=o(` class
method.`),NFt=l(),zB=a("p"),qFt=o("This class cannot be instantiated directly using "),iPe=a("code"),jFt=o("__init__()"),DFt=o(" (throws an error)."),GFt=l(),ua=a("div"),F(QB.$$.fragment),OFt=l(),dPe=a("p"),VFt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),XFt=l(),cf=a("p"),zFt=o(`Note:
Loading a model from its configuration file does `),mPe=a("strong"),QFt=o("not"),WFt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Fde=a("a"),UFt=o("from_pretrained()"),HFt=o(" to load the model weights."),JFt=l(),F(N8.$$.fragment),YFt=l(),at=a("div"),F(WB.$$.fragment),ZFt=l(),cPe=a("p"),KFt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),eTt=l(),os=a("p"),oTt=o("The model class to instantiate is selected based on the "),fPe=a("code"),rTt=o("model_type"),tTt=o(` property of the config object (either
passed as an argument or loaded from `),gPe=a("code"),aTt=o("pretrained_model_name_or_path"),nTt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hPe=a("code"),sTt=o("pretrained_model_name_or_path"),lTt=o(":"),iTt=l(),uPe=a("ul"),q8=a("li"),pPe=a("strong"),dTt=o("vision-encoder-decoder"),mTt=o(" \u2014 "),Tde=a("a"),cTt=o("TFVisionEncoderDecoderModel"),fTt=o(" (Vision Encoder decoder model)"),gTt=l(),F(j8.$$.fragment),Tdo=l(),ff=a("h2"),D8=a("a"),_Pe=a("span"),F(UB.$$.fragment),hTt=l(),bPe=a("span"),uTt=o("TFAutoModelForSpeechSeq2Seq"),Mdo=l(),xr=a("div"),F(HB.$$.fragment),pTt=l(),gf=a("p"),_Tt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Mde=a("a"),bTt=o("from_pretrained()"),vTt=o(" class method or the "),Ede=a("a"),FTt=o("from_config()"),TTt=o(` class
method.`),MTt=l(),JB=a("p"),ETt=o("This class cannot be instantiated directly using "),vPe=a("code"),CTt=o("__init__()"),wTt=o(" (throws an error)."),ATt=l(),pa=a("div"),F(YB.$$.fragment),LTt=l(),FPe=a("p"),yTt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),xTt=l(),hf=a("p"),$Tt=o(`Note:
Loading a model from its configuration file does `),TPe=a("strong"),kTt=o("not"),STt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Cde=a("a"),RTt=o("from_pretrained()"),PTt=o(" to load the model weights."),BTt=l(),F(G8.$$.fragment),ITt=l(),nt=a("div"),F(ZB.$$.fragment),NTt=l(),MPe=a("p"),qTt=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),jTt=l(),rs=a("p"),DTt=o("The model class to instantiate is selected based on the "),EPe=a("code"),GTt=o("model_type"),OTt=o(` property of the config object (either
passed as an argument or loaded from `),CPe=a("code"),VTt=o("pretrained_model_name_or_path"),XTt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wPe=a("code"),zTt=o("pretrained_model_name_or_path"),QTt=o(":"),WTt=l(),KB=a("ul"),O8=a("li"),APe=a("strong"),UTt=o("speech_to_text"),HTt=o(" \u2014 "),wde=a("a"),JTt=o("TFSpeech2TextForConditionalGeneration"),YTt=o(" (Speech2Text model)"),ZTt=l(),V8=a("li"),LPe=a("strong"),KTt=o("whisper"),eMt=o(" \u2014 "),Ade=a("a"),oMt=o("TFWhisperForConditionalGeneration"),rMt=o(" (Whisper model)"),tMt=l(),F(X8.$$.fragment),Edo=l(),uf=a("h2"),z8=a("a"),yPe=a("span"),F(eI.$$.fragment),aMt=l(),xPe=a("span"),nMt=o("FlaxAutoModel"),Cdo=l(),$r=a("div"),F(oI.$$.fragment),sMt=l(),pf=a("p"),lMt=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Lde=a("a"),iMt=o("from_pretrained()"),dMt=o(" class method or the "),yde=a("a"),mMt=o("from_config()"),cMt=o(` class
method.`),fMt=l(),rI=a("p"),gMt=o("This class cannot be instantiated directly using "),$Pe=a("code"),hMt=o("__init__()"),uMt=o(" (throws an error)."),pMt=l(),_a=a("div"),F(tI.$$.fragment),_Mt=l(),kPe=a("p"),bMt=o("Instantiates one of the base model classes of the library from a configuration."),vMt=l(),_f=a("p"),FMt=o(`Note:
Loading a model from its configuration file does `),SPe=a("strong"),TMt=o("not"),MMt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xde=a("a"),EMt=o("from_pretrained()"),CMt=o(" to load the model weights."),wMt=l(),F(Q8.$$.fragment),AMt=l(),st=a("div"),F(aI.$$.fragment),LMt=l(),RPe=a("p"),yMt=o("Instantiate one of the base model classes of the library from a pretrained model."),xMt=l(),ts=a("p"),$Mt=o("The model class to instantiate is selected based on the "),PPe=a("code"),kMt=o("model_type"),SMt=o(` property of the config object (either
passed as an argument or loaded from `),BPe=a("code"),RMt=o("pretrained_model_name_or_path"),PMt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),IPe=a("code"),BMt=o("pretrained_model_name_or_path"),IMt=o(":"),NMt=l(),ne=a("ul"),W8=a("li"),NPe=a("strong"),qMt=o("albert"),jMt=o(" \u2014 "),$de=a("a"),DMt=o("FlaxAlbertModel"),GMt=o(" (ALBERT model)"),OMt=l(),U8=a("li"),qPe=a("strong"),VMt=o("bart"),XMt=o(" \u2014 "),kde=a("a"),zMt=o("FlaxBartModel"),QMt=o(" (BART model)"),WMt=l(),H8=a("li"),jPe=a("strong"),UMt=o("beit"),HMt=o(" \u2014 "),Sde=a("a"),JMt=o("FlaxBeitModel"),YMt=o(" (BEiT model)"),ZMt=l(),J8=a("li"),DPe=a("strong"),KMt=o("bert"),eEt=o(" \u2014 "),Rde=a("a"),oEt=o("FlaxBertModel"),rEt=o(" (BERT model)"),tEt=l(),Y8=a("li"),GPe=a("strong"),aEt=o("big_bird"),nEt=o(" \u2014 "),Pde=a("a"),sEt=o("FlaxBigBirdModel"),lEt=o(" (BigBird model)"),iEt=l(),Z8=a("li"),OPe=a("strong"),dEt=o("blenderbot"),mEt=o(" \u2014 "),Bde=a("a"),cEt=o("FlaxBlenderbotModel"),fEt=o(" (Blenderbot model)"),gEt=l(),K8=a("li"),VPe=a("strong"),hEt=o("blenderbot-small"),uEt=o(" \u2014 "),Ide=a("a"),pEt=o("FlaxBlenderbotSmallModel"),_Et=o(" (BlenderbotSmall model)"),bEt=l(),eL=a("li"),XPe=a("strong"),vEt=o("clip"),FEt=o(" \u2014 "),Nde=a("a"),TEt=o("FlaxCLIPModel"),MEt=o(" (CLIP model)"),EEt=l(),oL=a("li"),zPe=a("strong"),CEt=o("distilbert"),wEt=o(" \u2014 "),qde=a("a"),AEt=o("FlaxDistilBertModel"),LEt=o(" (DistilBERT model)"),yEt=l(),rL=a("li"),QPe=a("strong"),xEt=o("electra"),$Et=o(" \u2014 "),jde=a("a"),kEt=o("FlaxElectraModel"),SEt=o(" (ELECTRA model)"),REt=l(),tL=a("li"),WPe=a("strong"),PEt=o("gpt2"),BEt=o(" \u2014 "),Dde=a("a"),IEt=o("FlaxGPT2Model"),NEt=o(" (OpenAI GPT-2 model)"),qEt=l(),aL=a("li"),UPe=a("strong"),jEt=o("gpt_neo"),DEt=o(" \u2014 "),Gde=a("a"),GEt=o("FlaxGPTNeoModel"),OEt=o(" (GPT Neo model)"),VEt=l(),nL=a("li"),HPe=a("strong"),XEt=o("gptj"),zEt=o(" \u2014 "),Ode=a("a"),QEt=o("FlaxGPTJModel"),WEt=o(" (GPT-J model)"),UEt=l(),sL=a("li"),JPe=a("strong"),HEt=o("longt5"),JEt=o(" \u2014 "),Vde=a("a"),YEt=o("FlaxLongT5Model"),ZEt=o(" (LongT5 model)"),KEt=l(),lL=a("li"),YPe=a("strong"),e4t=o("marian"),o4t=o(" \u2014 "),Xde=a("a"),r4t=o("FlaxMarianModel"),t4t=o(" (Marian model)"),a4t=l(),iL=a("li"),ZPe=a("strong"),n4t=o("mbart"),s4t=o(" \u2014 "),zde=a("a"),l4t=o("FlaxMBartModel"),i4t=o(" (mBART model)"),d4t=l(),dL=a("li"),KPe=a("strong"),m4t=o("mt5"),c4t=o(" \u2014 "),Qde=a("a"),f4t=o("FlaxMT5Model"),g4t=o(" (MT5 model)"),h4t=l(),mL=a("li"),eBe=a("strong"),u4t=o("opt"),p4t=o(" \u2014 "),Wde=a("a"),_4t=o("FlaxOPTModel"),b4t=o(" (OPT model)"),v4t=l(),cL=a("li"),oBe=a("strong"),F4t=o("pegasus"),T4t=o(" \u2014 "),Ude=a("a"),M4t=o("FlaxPegasusModel"),E4t=o(" (Pegasus model)"),C4t=l(),fL=a("li"),rBe=a("strong"),w4t=o("roberta"),A4t=o(" \u2014 "),Hde=a("a"),L4t=o("FlaxRobertaModel"),y4t=o(" (RoBERTa model)"),x4t=l(),gL=a("li"),tBe=a("strong"),$4t=o("roformer"),k4t=o(" \u2014 "),Jde=a("a"),S4t=o("FlaxRoFormerModel"),R4t=o(" (RoFormer model)"),P4t=l(),hL=a("li"),aBe=a("strong"),B4t=o("t5"),I4t=o(" \u2014 "),Yde=a("a"),N4t=o("FlaxT5Model"),q4t=o(" (T5 model)"),j4t=l(),uL=a("li"),nBe=a("strong"),D4t=o("vision-text-dual-encoder"),G4t=o(" \u2014 "),Zde=a("a"),O4t=o("FlaxVisionTextDualEncoderModel"),V4t=o(" (VisionTextDualEncoder model)"),X4t=l(),pL=a("li"),sBe=a("strong"),z4t=o("vit"),Q4t=o(" \u2014 "),Kde=a("a"),W4t=o("FlaxViTModel"),U4t=o(" (ViT model)"),H4t=l(),_L=a("li"),lBe=a("strong"),J4t=o("wav2vec2"),Y4t=o(" \u2014 "),eme=a("a"),Z4t=o("FlaxWav2Vec2Model"),K4t=o(" (Wav2Vec2 model)"),eCt=l(),bL=a("li"),iBe=a("strong"),oCt=o("xglm"),rCt=o(" \u2014 "),ome=a("a"),tCt=o("FlaxXGLMModel"),aCt=o(" (XGLM model)"),nCt=l(),vL=a("li"),dBe=a("strong"),sCt=o("xlm-roberta"),lCt=o(" \u2014 "),rme=a("a"),iCt=o("FlaxXLMRobertaModel"),dCt=o(" (XLM-RoBERTa model)"),mCt=l(),F(FL.$$.fragment),wdo=l(),bf=a("h2"),TL=a("a"),mBe=a("span"),F(nI.$$.fragment),cCt=l(),cBe=a("span"),fCt=o("FlaxAutoModelForCausalLM"),Ado=l(),kr=a("div"),F(sI.$$.fragment),gCt=l(),vf=a("p"),hCt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),tme=a("a"),uCt=o("from_pretrained()"),pCt=o(" class method or the "),ame=a("a"),_Ct=o("from_config()"),bCt=o(` class
method.`),vCt=l(),lI=a("p"),FCt=o("This class cannot be instantiated directly using "),fBe=a("code"),TCt=o("__init__()"),MCt=o(" (throws an error)."),ECt=l(),ba=a("div"),F(iI.$$.fragment),CCt=l(),gBe=a("p"),wCt=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),ACt=l(),Ff=a("p"),LCt=o(`Note:
Loading a model from its configuration file does `),hBe=a("strong"),yCt=o("not"),xCt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nme=a("a"),$Ct=o("from_pretrained()"),kCt=o(" to load the model weights."),SCt=l(),F(ML.$$.fragment),RCt=l(),lt=a("div"),F(dI.$$.fragment),PCt=l(),uBe=a("p"),BCt=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),ICt=l(),as=a("p"),NCt=o("The model class to instantiate is selected based on the "),pBe=a("code"),qCt=o("model_type"),jCt=o(` property of the config object (either
passed as an argument or loaded from `),_Be=a("code"),DCt=o("pretrained_model_name_or_path"),GCt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bBe=a("code"),OCt=o("pretrained_model_name_or_path"),VCt=o(":"),XCt=l(),Se=a("ul"),EL=a("li"),vBe=a("strong"),zCt=o("bart"),QCt=o(" \u2014 "),sme=a("a"),WCt=o("FlaxBartForCausalLM"),UCt=o(" (BART model)"),HCt=l(),CL=a("li"),FBe=a("strong"),JCt=o("bert"),YCt=o(" \u2014 "),lme=a("a"),ZCt=o("FlaxBertForCausalLM"),KCt=o(" (BERT model)"),e3t=l(),wL=a("li"),TBe=a("strong"),o3t=o("big_bird"),r3t=o(" \u2014 "),ime=a("a"),t3t=o("FlaxBigBirdForCausalLM"),a3t=o(" (BigBird model)"),n3t=l(),AL=a("li"),MBe=a("strong"),s3t=o("electra"),l3t=o(" \u2014 "),dme=a("a"),i3t=o("FlaxElectraForCausalLM"),d3t=o(" (ELECTRA model)"),m3t=l(),LL=a("li"),EBe=a("strong"),c3t=o("gpt2"),f3t=o(" \u2014 "),mme=a("a"),g3t=o("FlaxGPT2LMHeadModel"),h3t=o(" (OpenAI GPT-2 model)"),u3t=l(),yL=a("li"),CBe=a("strong"),p3t=o("gpt_neo"),_3t=o(" \u2014 "),cme=a("a"),b3t=o("FlaxGPTNeoForCausalLM"),v3t=o(" (GPT Neo model)"),F3t=l(),xL=a("li"),wBe=a("strong"),T3t=o("gptj"),M3t=o(" \u2014 "),fme=a("a"),E3t=o("FlaxGPTJForCausalLM"),C3t=o(" (GPT-J model)"),w3t=l(),$L=a("li"),ABe=a("strong"),A3t=o("opt"),L3t=o(" \u2014 "),gme=a("a"),y3t=o("FlaxOPTForCausalLM"),x3t=o(" (OPT model)"),$3t=l(),kL=a("li"),LBe=a("strong"),k3t=o("roberta"),S3t=o(" \u2014 "),hme=a("a"),R3t=o("FlaxRobertaForCausalLM"),P3t=o(" (RoBERTa model)"),B3t=l(),SL=a("li"),yBe=a("strong"),I3t=o("xglm"),N3t=o(" \u2014 "),ume=a("a"),q3t=o("FlaxXGLMForCausalLM"),j3t=o(" (XGLM model)"),D3t=l(),F(RL.$$.fragment),Ldo=l(),Tf=a("h2"),PL=a("a"),xBe=a("span"),F(mI.$$.fragment),G3t=l(),$Be=a("span"),O3t=o("FlaxAutoModelForPreTraining"),ydo=l(),Sr=a("div"),F(cI.$$.fragment),V3t=l(),Mf=a("p"),X3t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),pme=a("a"),z3t=o("from_pretrained()"),Q3t=o(" class method or the "),_me=a("a"),W3t=o("from_config()"),U3t=o(` class
method.`),H3t=l(),fI=a("p"),J3t=o("This class cannot be instantiated directly using "),kBe=a("code"),Y3t=o("__init__()"),Z3t=o(" (throws an error)."),K3t=l(),va=a("div"),F(gI.$$.fragment),e5t=l(),SBe=a("p"),o5t=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),r5t=l(),Ef=a("p"),t5t=o(`Note:
Loading a model from its configuration file does `),RBe=a("strong"),a5t=o("not"),n5t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bme=a("a"),s5t=o("from_pretrained()"),l5t=o(" to load the model weights."),i5t=l(),F(BL.$$.fragment),d5t=l(),it=a("div"),F(hI.$$.fragment),m5t=l(),PBe=a("p"),c5t=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),f5t=l(),ns=a("p"),g5t=o("The model class to instantiate is selected based on the "),BBe=a("code"),h5t=o("model_type"),u5t=o(` property of the config object (either
passed as an argument or loaded from `),IBe=a("code"),p5t=o("pretrained_model_name_or_path"),_5t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NBe=a("code"),b5t=o("pretrained_model_name_or_path"),v5t=o(":"),F5t=l(),we=a("ul"),IL=a("li"),qBe=a("strong"),T5t=o("albert"),M5t=o(" \u2014 "),vme=a("a"),E5t=o("FlaxAlbertForPreTraining"),C5t=o(" (ALBERT model)"),w5t=l(),NL=a("li"),jBe=a("strong"),A5t=o("bart"),L5t=o(" \u2014 "),Fme=a("a"),y5t=o("FlaxBartForConditionalGeneration"),x5t=o(" (BART model)"),$5t=l(),qL=a("li"),DBe=a("strong"),k5t=o("bert"),S5t=o(" \u2014 "),Tme=a("a"),R5t=o("FlaxBertForPreTraining"),P5t=o(" (BERT model)"),B5t=l(),jL=a("li"),GBe=a("strong"),I5t=o("big_bird"),N5t=o(" \u2014 "),Mme=a("a"),q5t=o("FlaxBigBirdForPreTraining"),j5t=o(" (BigBird model)"),D5t=l(),DL=a("li"),OBe=a("strong"),G5t=o("electra"),O5t=o(" \u2014 "),Eme=a("a"),V5t=o("FlaxElectraForPreTraining"),X5t=o(" (ELECTRA model)"),z5t=l(),GL=a("li"),VBe=a("strong"),Q5t=o("longt5"),W5t=o(" \u2014 "),Cme=a("a"),U5t=o("FlaxLongT5ForConditionalGeneration"),H5t=o(" (LongT5 model)"),J5t=l(),OL=a("li"),XBe=a("strong"),Y5t=o("mbart"),Z5t=o(" \u2014 "),wme=a("a"),K5t=o("FlaxMBartForConditionalGeneration"),e0t=o(" (mBART model)"),o0t=l(),VL=a("li"),zBe=a("strong"),r0t=o("mt5"),t0t=o(" \u2014 "),Ame=a("a"),a0t=o("FlaxMT5ForConditionalGeneration"),n0t=o(" (MT5 model)"),s0t=l(),XL=a("li"),QBe=a("strong"),l0t=o("roberta"),i0t=o(" \u2014 "),Lme=a("a"),d0t=o("FlaxRobertaForMaskedLM"),m0t=o(" (RoBERTa model)"),c0t=l(),zL=a("li"),WBe=a("strong"),f0t=o("roformer"),g0t=o(" \u2014 "),yme=a("a"),h0t=o("FlaxRoFormerForMaskedLM"),u0t=o(" (RoFormer model)"),p0t=l(),QL=a("li"),UBe=a("strong"),_0t=o("t5"),b0t=o(" \u2014 "),xme=a("a"),v0t=o("FlaxT5ForConditionalGeneration"),F0t=o(" (T5 model)"),T0t=l(),WL=a("li"),HBe=a("strong"),M0t=o("wav2vec2"),E0t=o(" \u2014 "),$me=a("a"),C0t=o("FlaxWav2Vec2ForPreTraining"),w0t=o(" (Wav2Vec2 model)"),A0t=l(),UL=a("li"),JBe=a("strong"),L0t=o("xlm-roberta"),y0t=o(" \u2014 "),kme=a("a"),x0t=o("FlaxXLMRobertaForMaskedLM"),$0t=o(" (XLM-RoBERTa model)"),k0t=l(),F(HL.$$.fragment),xdo=l(),Cf=a("h2"),JL=a("a"),YBe=a("span"),F(uI.$$.fragment),S0t=l(),ZBe=a("span"),R0t=o("FlaxAutoModelForMaskedLM"),$do=l(),Rr=a("div"),F(pI.$$.fragment),P0t=l(),wf=a("p"),B0t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Sme=a("a"),I0t=o("from_pretrained()"),N0t=o(" class method or the "),Rme=a("a"),q0t=o("from_config()"),j0t=o(` class
method.`),D0t=l(),_I=a("p"),G0t=o("This class cannot be instantiated directly using "),KBe=a("code"),O0t=o("__init__()"),V0t=o(" (throws an error)."),X0t=l(),Fa=a("div"),F(bI.$$.fragment),z0t=l(),eIe=a("p"),Q0t=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),W0t=l(),Af=a("p"),U0t=o(`Note:
Loading a model from its configuration file does `),oIe=a("strong"),H0t=o("not"),J0t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Pme=a("a"),Y0t=o("from_pretrained()"),Z0t=o(" to load the model weights."),K0t=l(),F(YL.$$.fragment),ewt=l(),dt=a("div"),F(vI.$$.fragment),owt=l(),rIe=a("p"),rwt=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),twt=l(),ss=a("p"),awt=o("The model class to instantiate is selected based on the "),tIe=a("code"),nwt=o("model_type"),swt=o(` property of the config object (either
passed as an argument or loaded from `),aIe=a("code"),lwt=o("pretrained_model_name_or_path"),iwt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nIe=a("code"),dwt=o("pretrained_model_name_or_path"),mwt=o(":"),cwt=l(),Re=a("ul"),ZL=a("li"),sIe=a("strong"),fwt=o("albert"),gwt=o(" \u2014 "),Bme=a("a"),hwt=o("FlaxAlbertForMaskedLM"),uwt=o(" (ALBERT model)"),pwt=l(),KL=a("li"),lIe=a("strong"),_wt=o("bart"),bwt=o(" \u2014 "),Ime=a("a"),vwt=o("FlaxBartForConditionalGeneration"),Fwt=o(" (BART model)"),Twt=l(),ey=a("li"),iIe=a("strong"),Mwt=o("bert"),Ewt=o(" \u2014 "),Nme=a("a"),Cwt=o("FlaxBertForMaskedLM"),wwt=o(" (BERT model)"),Awt=l(),oy=a("li"),dIe=a("strong"),Lwt=o("big_bird"),ywt=o(" \u2014 "),qme=a("a"),xwt=o("FlaxBigBirdForMaskedLM"),$wt=o(" (BigBird model)"),kwt=l(),ry=a("li"),mIe=a("strong"),Swt=o("distilbert"),Rwt=o(" \u2014 "),jme=a("a"),Pwt=o("FlaxDistilBertForMaskedLM"),Bwt=o(" (DistilBERT model)"),Iwt=l(),ty=a("li"),cIe=a("strong"),Nwt=o("electra"),qwt=o(" \u2014 "),Dme=a("a"),jwt=o("FlaxElectraForMaskedLM"),Dwt=o(" (ELECTRA model)"),Gwt=l(),ay=a("li"),fIe=a("strong"),Owt=o("mbart"),Vwt=o(" \u2014 "),Gme=a("a"),Xwt=o("FlaxMBartForConditionalGeneration"),zwt=o(" (mBART model)"),Qwt=l(),ny=a("li"),gIe=a("strong"),Wwt=o("roberta"),Uwt=o(" \u2014 "),Ome=a("a"),Hwt=o("FlaxRobertaForMaskedLM"),Jwt=o(" (RoBERTa model)"),Ywt=l(),sy=a("li"),hIe=a("strong"),Zwt=o("roformer"),Kwt=o(" \u2014 "),Vme=a("a"),eAt=o("FlaxRoFormerForMaskedLM"),oAt=o(" (RoFormer model)"),rAt=l(),ly=a("li"),uIe=a("strong"),tAt=o("xlm-roberta"),aAt=o(" \u2014 "),Xme=a("a"),nAt=o("FlaxXLMRobertaForMaskedLM"),sAt=o(" (XLM-RoBERTa model)"),lAt=l(),F(iy.$$.fragment),kdo=l(),Lf=a("h2"),dy=a("a"),pIe=a("span"),F(FI.$$.fragment),iAt=l(),_Ie=a("span"),dAt=o("FlaxAutoModelForSeq2SeqLM"),Sdo=l(),Pr=a("div"),F(TI.$$.fragment),mAt=l(),yf=a("p"),cAt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),zme=a("a"),fAt=o("from_pretrained()"),gAt=o(" class method or the "),Qme=a("a"),hAt=o("from_config()"),uAt=o(` class
method.`),pAt=l(),MI=a("p"),_At=o("This class cannot be instantiated directly using "),bIe=a("code"),bAt=o("__init__()"),vAt=o(" (throws an error)."),FAt=l(),Ta=a("div"),F(EI.$$.fragment),TAt=l(),vIe=a("p"),MAt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),EAt=l(),xf=a("p"),CAt=o(`Note:
Loading a model from its configuration file does `),FIe=a("strong"),wAt=o("not"),AAt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Wme=a("a"),LAt=o("from_pretrained()"),yAt=o(" to load the model weights."),xAt=l(),F(my.$$.fragment),$At=l(),mt=a("div"),F(CI.$$.fragment),kAt=l(),TIe=a("p"),SAt=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),RAt=l(),ls=a("p"),PAt=o("The model class to instantiate is selected based on the "),MIe=a("code"),BAt=o("model_type"),IAt=o(` property of the config object (either
passed as an argument or loaded from `),EIe=a("code"),NAt=o("pretrained_model_name_or_path"),qAt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),CIe=a("code"),jAt=o("pretrained_model_name_or_path"),DAt=o(":"),GAt=l(),Pe=a("ul"),cy=a("li"),wIe=a("strong"),OAt=o("bart"),VAt=o(" \u2014 "),Ume=a("a"),XAt=o("FlaxBartForConditionalGeneration"),zAt=o(" (BART model)"),QAt=l(),fy=a("li"),AIe=a("strong"),WAt=o("blenderbot"),UAt=o(" \u2014 "),Hme=a("a"),HAt=o("FlaxBlenderbotForConditionalGeneration"),JAt=o(" (Blenderbot model)"),YAt=l(),gy=a("li"),LIe=a("strong"),ZAt=o("blenderbot-small"),KAt=o(" \u2014 "),Jme=a("a"),e6t=o("FlaxBlenderbotSmallForConditionalGeneration"),o6t=o(" (BlenderbotSmall model)"),r6t=l(),hy=a("li"),yIe=a("strong"),t6t=o("encoder-decoder"),a6t=o(" \u2014 "),Yme=a("a"),n6t=o("FlaxEncoderDecoderModel"),s6t=o(" (Encoder decoder model)"),l6t=l(),uy=a("li"),xIe=a("strong"),i6t=o("longt5"),d6t=o(" \u2014 "),Zme=a("a"),m6t=o("FlaxLongT5ForConditionalGeneration"),c6t=o(" (LongT5 model)"),f6t=l(),py=a("li"),$Ie=a("strong"),g6t=o("marian"),h6t=o(" \u2014 "),Kme=a("a"),u6t=o("FlaxMarianMTModel"),p6t=o(" (Marian model)"),_6t=l(),_y=a("li"),kIe=a("strong"),b6t=o("mbart"),v6t=o(" \u2014 "),ece=a("a"),F6t=o("FlaxMBartForConditionalGeneration"),T6t=o(" (mBART model)"),M6t=l(),by=a("li"),SIe=a("strong"),E6t=o("mt5"),C6t=o(" \u2014 "),oce=a("a"),w6t=o("FlaxMT5ForConditionalGeneration"),A6t=o(" (MT5 model)"),L6t=l(),vy=a("li"),RIe=a("strong"),y6t=o("pegasus"),x6t=o(" \u2014 "),rce=a("a"),$6t=o("FlaxPegasusForConditionalGeneration"),k6t=o(" (Pegasus model)"),S6t=l(),Fy=a("li"),PIe=a("strong"),R6t=o("t5"),P6t=o(" \u2014 "),tce=a("a"),B6t=o("FlaxT5ForConditionalGeneration"),I6t=o(" (T5 model)"),N6t=l(),F(Ty.$$.fragment),Rdo=l(),$f=a("h2"),My=a("a"),BIe=a("span"),F(wI.$$.fragment),q6t=l(),IIe=a("span"),j6t=o("FlaxAutoModelForSequenceClassification"),Pdo=l(),Br=a("div"),F(AI.$$.fragment),D6t=l(),kf=a("p"),G6t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),ace=a("a"),O6t=o("from_pretrained()"),V6t=o(" class method or the "),nce=a("a"),X6t=o("from_config()"),z6t=o(` class
method.`),Q6t=l(),LI=a("p"),W6t=o("This class cannot be instantiated directly using "),NIe=a("code"),U6t=o("__init__()"),H6t=o(" (throws an error)."),J6t=l(),Ma=a("div"),F(yI.$$.fragment),Y6t=l(),qIe=a("p"),Z6t=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),K6t=l(),Sf=a("p"),e7t=o(`Note:
Loading a model from its configuration file does `),jIe=a("strong"),o7t=o("not"),r7t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sce=a("a"),t7t=o("from_pretrained()"),a7t=o(" to load the model weights."),n7t=l(),F(Ey.$$.fragment),s7t=l(),ct=a("div"),F(xI.$$.fragment),l7t=l(),DIe=a("p"),i7t=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),d7t=l(),is=a("p"),m7t=o("The model class to instantiate is selected based on the "),GIe=a("code"),c7t=o("model_type"),f7t=o(` property of the config object (either
passed as an argument or loaded from `),OIe=a("code"),g7t=o("pretrained_model_name_or_path"),h7t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VIe=a("code"),u7t=o("pretrained_model_name_or_path"),p7t=o(":"),_7t=l(),Be=a("ul"),Cy=a("li"),XIe=a("strong"),b7t=o("albert"),v7t=o(" \u2014 "),lce=a("a"),F7t=o("FlaxAlbertForSequenceClassification"),T7t=o(" (ALBERT model)"),M7t=l(),wy=a("li"),zIe=a("strong"),E7t=o("bart"),C7t=o(" \u2014 "),ice=a("a"),w7t=o("FlaxBartForSequenceClassification"),A7t=o(" (BART model)"),L7t=l(),Ay=a("li"),QIe=a("strong"),y7t=o("bert"),x7t=o(" \u2014 "),dce=a("a"),$7t=o("FlaxBertForSequenceClassification"),k7t=o(" (BERT model)"),S7t=l(),Ly=a("li"),WIe=a("strong"),R7t=o("big_bird"),P7t=o(" \u2014 "),mce=a("a"),B7t=o("FlaxBigBirdForSequenceClassification"),I7t=o(" (BigBird model)"),N7t=l(),yy=a("li"),UIe=a("strong"),q7t=o("distilbert"),j7t=o(" \u2014 "),cce=a("a"),D7t=o("FlaxDistilBertForSequenceClassification"),G7t=o(" (DistilBERT model)"),O7t=l(),xy=a("li"),HIe=a("strong"),V7t=o("electra"),X7t=o(" \u2014 "),fce=a("a"),z7t=o("FlaxElectraForSequenceClassification"),Q7t=o(" (ELECTRA model)"),W7t=l(),$y=a("li"),JIe=a("strong"),U7t=o("mbart"),H7t=o(" \u2014 "),gce=a("a"),J7t=o("FlaxMBartForSequenceClassification"),Y7t=o(" (mBART model)"),Z7t=l(),ky=a("li"),YIe=a("strong"),K7t=o("roberta"),e8t=o(" \u2014 "),hce=a("a"),o8t=o("FlaxRobertaForSequenceClassification"),r8t=o(" (RoBERTa model)"),t8t=l(),Sy=a("li"),ZIe=a("strong"),a8t=o("roformer"),n8t=o(" \u2014 "),uce=a("a"),s8t=o("FlaxRoFormerForSequenceClassification"),l8t=o(" (RoFormer model)"),i8t=l(),Ry=a("li"),KIe=a("strong"),d8t=o("xlm-roberta"),m8t=o(" \u2014 "),pce=a("a"),c8t=o("FlaxXLMRobertaForSequenceClassification"),f8t=o(" (XLM-RoBERTa model)"),g8t=l(),F(Py.$$.fragment),Bdo=l(),Rf=a("h2"),By=a("a"),eNe=a("span"),F($I.$$.fragment),h8t=l(),oNe=a("span"),u8t=o("FlaxAutoModelForQuestionAnswering"),Ido=l(),Ir=a("div"),F(kI.$$.fragment),p8t=l(),Pf=a("p"),_8t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),_ce=a("a"),b8t=o("from_pretrained()"),v8t=o(" class method or the "),bce=a("a"),F8t=o("from_config()"),T8t=o(` class
method.`),M8t=l(),SI=a("p"),E8t=o("This class cannot be instantiated directly using "),rNe=a("code"),C8t=o("__init__()"),w8t=o(" (throws an error)."),A8t=l(),Ea=a("div"),F(RI.$$.fragment),L8t=l(),tNe=a("p"),y8t=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),x8t=l(),Bf=a("p"),$8t=o(`Note:
Loading a model from its configuration file does `),aNe=a("strong"),k8t=o("not"),S8t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vce=a("a"),R8t=o("from_pretrained()"),P8t=o(" to load the model weights."),B8t=l(),F(Iy.$$.fragment),I8t=l(),ft=a("div"),F(PI.$$.fragment),N8t=l(),nNe=a("p"),q8t=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),j8t=l(),ds=a("p"),D8t=o("The model class to instantiate is selected based on the "),sNe=a("code"),G8t=o("model_type"),O8t=o(` property of the config object (either
passed as an argument or loaded from `),lNe=a("code"),V8t=o("pretrained_model_name_or_path"),X8t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iNe=a("code"),z8t=o("pretrained_model_name_or_path"),Q8t=o(":"),W8t=l(),Ie=a("ul"),Ny=a("li"),dNe=a("strong"),U8t=o("albert"),H8t=o(" \u2014 "),Fce=a("a"),J8t=o("FlaxAlbertForQuestionAnswering"),Y8t=o(" (ALBERT model)"),Z8t=l(),qy=a("li"),mNe=a("strong"),K8t=o("bart"),eLt=o(" \u2014 "),Tce=a("a"),oLt=o("FlaxBartForQuestionAnswering"),rLt=o(" (BART model)"),tLt=l(),jy=a("li"),cNe=a("strong"),aLt=o("bert"),nLt=o(" \u2014 "),Mce=a("a"),sLt=o("FlaxBertForQuestionAnswering"),lLt=o(" (BERT model)"),iLt=l(),Dy=a("li"),fNe=a("strong"),dLt=o("big_bird"),mLt=o(" \u2014 "),Ece=a("a"),cLt=o("FlaxBigBirdForQuestionAnswering"),fLt=o(" (BigBird model)"),gLt=l(),Gy=a("li"),gNe=a("strong"),hLt=o("distilbert"),uLt=o(" \u2014 "),Cce=a("a"),pLt=o("FlaxDistilBertForQuestionAnswering"),_Lt=o(" (DistilBERT model)"),bLt=l(),Oy=a("li"),hNe=a("strong"),vLt=o("electra"),FLt=o(" \u2014 "),wce=a("a"),TLt=o("FlaxElectraForQuestionAnswering"),MLt=o(" (ELECTRA model)"),ELt=l(),Vy=a("li"),uNe=a("strong"),CLt=o("mbart"),wLt=o(" \u2014 "),Ace=a("a"),ALt=o("FlaxMBartForQuestionAnswering"),LLt=o(" (mBART model)"),yLt=l(),Xy=a("li"),pNe=a("strong"),xLt=o("roberta"),$Lt=o(" \u2014 "),Lce=a("a"),kLt=o("FlaxRobertaForQuestionAnswering"),SLt=o(" (RoBERTa model)"),RLt=l(),zy=a("li"),_Ne=a("strong"),PLt=o("roformer"),BLt=o(" \u2014 "),yce=a("a"),ILt=o("FlaxRoFormerForQuestionAnswering"),NLt=o(" (RoFormer model)"),qLt=l(),Qy=a("li"),bNe=a("strong"),jLt=o("xlm-roberta"),DLt=o(" \u2014 "),xce=a("a"),GLt=o("FlaxXLMRobertaForQuestionAnswering"),OLt=o(" (XLM-RoBERTa model)"),VLt=l(),F(Wy.$$.fragment),Ndo=l(),If=a("h2"),Uy=a("a"),vNe=a("span"),F(BI.$$.fragment),XLt=l(),FNe=a("span"),zLt=o("FlaxAutoModelForTokenClassification"),qdo=l(),Nr=a("div"),F(II.$$.fragment),QLt=l(),Nf=a("p"),WLt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),$ce=a("a"),ULt=o("from_pretrained()"),HLt=o(" class method or the "),kce=a("a"),JLt=o("from_config()"),YLt=o(` class
method.`),ZLt=l(),NI=a("p"),KLt=o("This class cannot be instantiated directly using "),TNe=a("code"),eyt=o("__init__()"),oyt=o(" (throws an error)."),ryt=l(),Ca=a("div"),F(qI.$$.fragment),tyt=l(),MNe=a("p"),ayt=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),nyt=l(),qf=a("p"),syt=o(`Note:
Loading a model from its configuration file does `),ENe=a("strong"),lyt=o("not"),iyt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Sce=a("a"),dyt=o("from_pretrained()"),myt=o(" to load the model weights."),cyt=l(),F(Hy.$$.fragment),fyt=l(),gt=a("div"),F(jI.$$.fragment),gyt=l(),CNe=a("p"),hyt=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),uyt=l(),ms=a("p"),pyt=o("The model class to instantiate is selected based on the "),wNe=a("code"),_yt=o("model_type"),byt=o(` property of the config object (either
passed as an argument or loaded from `),ANe=a("code"),vyt=o("pretrained_model_name_or_path"),Fyt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LNe=a("code"),Tyt=o("pretrained_model_name_or_path"),Myt=o(":"),Eyt=l(),We=a("ul"),Jy=a("li"),yNe=a("strong"),Cyt=o("albert"),wyt=o(" \u2014 "),Rce=a("a"),Ayt=o("FlaxAlbertForTokenClassification"),Lyt=o(" (ALBERT model)"),yyt=l(),Yy=a("li"),xNe=a("strong"),xyt=o("bert"),$yt=o(" \u2014 "),Pce=a("a"),kyt=o("FlaxBertForTokenClassification"),Syt=o(" (BERT model)"),Ryt=l(),Zy=a("li"),$Ne=a("strong"),Pyt=o("big_bird"),Byt=o(" \u2014 "),Bce=a("a"),Iyt=o("FlaxBigBirdForTokenClassification"),Nyt=o(" (BigBird model)"),qyt=l(),Ky=a("li"),kNe=a("strong"),jyt=o("distilbert"),Dyt=o(" \u2014 "),Ice=a("a"),Gyt=o("FlaxDistilBertForTokenClassification"),Oyt=o(" (DistilBERT model)"),Vyt=l(),e9=a("li"),SNe=a("strong"),Xyt=o("electra"),zyt=o(" \u2014 "),Nce=a("a"),Qyt=o("FlaxElectraForTokenClassification"),Wyt=o(" (ELECTRA model)"),Uyt=l(),o9=a("li"),RNe=a("strong"),Hyt=o("roberta"),Jyt=o(" \u2014 "),qce=a("a"),Yyt=o("FlaxRobertaForTokenClassification"),Zyt=o(" (RoBERTa model)"),Kyt=l(),r9=a("li"),PNe=a("strong"),e9t=o("roformer"),o9t=o(" \u2014 "),jce=a("a"),r9t=o("FlaxRoFormerForTokenClassification"),t9t=o(" (RoFormer model)"),a9t=l(),t9=a("li"),BNe=a("strong"),n9t=o("xlm-roberta"),s9t=o(" \u2014 "),Dce=a("a"),l9t=o("FlaxXLMRobertaForTokenClassification"),i9t=o(" (XLM-RoBERTa model)"),d9t=l(),F(a9.$$.fragment),jdo=l(),jf=a("h2"),n9=a("a"),INe=a("span"),F(DI.$$.fragment),m9t=l(),NNe=a("span"),c9t=o("FlaxAutoModelForMultipleChoice"),Ddo=l(),qr=a("div"),F(GI.$$.fragment),f9t=l(),Df=a("p"),g9t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Gce=a("a"),h9t=o("from_pretrained()"),u9t=o(" class method or the "),Oce=a("a"),p9t=o("from_config()"),_9t=o(` class
method.`),b9t=l(),OI=a("p"),v9t=o("This class cannot be instantiated directly using "),qNe=a("code"),F9t=o("__init__()"),T9t=o(" (throws an error)."),M9t=l(),wa=a("div"),F(VI.$$.fragment),E9t=l(),jNe=a("p"),C9t=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),w9t=l(),Gf=a("p"),A9t=o(`Note:
Loading a model from its configuration file does `),DNe=a("strong"),L9t=o("not"),y9t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Vce=a("a"),x9t=o("from_pretrained()"),$9t=o(" to load the model weights."),k9t=l(),F(s9.$$.fragment),S9t=l(),ht=a("div"),F(XI.$$.fragment),R9t=l(),GNe=a("p"),P9t=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),B9t=l(),cs=a("p"),I9t=o("The model class to instantiate is selected based on the "),ONe=a("code"),N9t=o("model_type"),q9t=o(` property of the config object (either
passed as an argument or loaded from `),VNe=a("code"),j9t=o("pretrained_model_name_or_path"),D9t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),XNe=a("code"),G9t=o("pretrained_model_name_or_path"),O9t=o(":"),V9t=l(),Ue=a("ul"),l9=a("li"),zNe=a("strong"),X9t=o("albert"),z9t=o(" \u2014 "),Xce=a("a"),Q9t=o("FlaxAlbertForMultipleChoice"),W9t=o(" (ALBERT model)"),U9t=l(),i9=a("li"),QNe=a("strong"),H9t=o("bert"),J9t=o(" \u2014 "),zce=a("a"),Y9t=o("FlaxBertForMultipleChoice"),Z9t=o(" (BERT model)"),K9t=l(),d9=a("li"),WNe=a("strong"),ext=o("big_bird"),oxt=o(" \u2014 "),Qce=a("a"),rxt=o("FlaxBigBirdForMultipleChoice"),txt=o(" (BigBird model)"),axt=l(),m9=a("li"),UNe=a("strong"),nxt=o("distilbert"),sxt=o(" \u2014 "),Wce=a("a"),lxt=o("FlaxDistilBertForMultipleChoice"),ixt=o(" (DistilBERT model)"),dxt=l(),c9=a("li"),HNe=a("strong"),mxt=o("electra"),cxt=o(" \u2014 "),Uce=a("a"),fxt=o("FlaxElectraForMultipleChoice"),gxt=o(" (ELECTRA model)"),hxt=l(),f9=a("li"),JNe=a("strong"),uxt=o("roberta"),pxt=o(" \u2014 "),Hce=a("a"),_xt=o("FlaxRobertaForMultipleChoice"),bxt=o(" (RoBERTa model)"),vxt=l(),g9=a("li"),YNe=a("strong"),Fxt=o("roformer"),Txt=o(" \u2014 "),Jce=a("a"),Mxt=o("FlaxRoFormerForMultipleChoice"),Ext=o(" (RoFormer model)"),Cxt=l(),h9=a("li"),ZNe=a("strong"),wxt=o("xlm-roberta"),Axt=o(" \u2014 "),Yce=a("a"),Lxt=o("FlaxXLMRobertaForMultipleChoice"),yxt=o(" (XLM-RoBERTa model)"),xxt=l(),F(u9.$$.fragment),Gdo=l(),Of=a("h2"),p9=a("a"),KNe=a("span"),F(zI.$$.fragment),$xt=l(),eqe=a("span"),kxt=o("FlaxAutoModelForNextSentencePrediction"),Odo=l(),jr=a("div"),F(QI.$$.fragment),Sxt=l(),Vf=a("p"),Rxt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Zce=a("a"),Pxt=o("from_pretrained()"),Bxt=o(" class method or the "),Kce=a("a"),Ixt=o("from_config()"),Nxt=o(` class
method.`),qxt=l(),WI=a("p"),jxt=o("This class cannot be instantiated directly using "),oqe=a("code"),Dxt=o("__init__()"),Gxt=o(" (throws an error)."),Oxt=l(),Aa=a("div"),F(UI.$$.fragment),Vxt=l(),rqe=a("p"),Xxt=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),zxt=l(),Xf=a("p"),Qxt=o(`Note:
Loading a model from its configuration file does `),tqe=a("strong"),Wxt=o("not"),Uxt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),efe=a("a"),Hxt=o("from_pretrained()"),Jxt=o(" to load the model weights."),Yxt=l(),F(_9.$$.fragment),Zxt=l(),ut=a("div"),F(HI.$$.fragment),Kxt=l(),aqe=a("p"),e$t=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),o$t=l(),fs=a("p"),r$t=o("The model class to instantiate is selected based on the "),nqe=a("code"),t$t=o("model_type"),a$t=o(` property of the config object (either
passed as an argument or loaded from `),sqe=a("code"),n$t=o("pretrained_model_name_or_path"),s$t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lqe=a("code"),l$t=o("pretrained_model_name_or_path"),i$t=o(":"),d$t=l(),iqe=a("ul"),b9=a("li"),dqe=a("strong"),m$t=o("bert"),c$t=o(" \u2014 "),ofe=a("a"),f$t=o("FlaxBertForNextSentencePrediction"),g$t=o(" (BERT model)"),h$t=l(),F(v9.$$.fragment),Vdo=l(),zf=a("h2"),F9=a("a"),mqe=a("span"),F(JI.$$.fragment),u$t=l(),cqe=a("span"),p$t=o("FlaxAutoModelForImageClassification"),Xdo=l(),Dr=a("div"),F(YI.$$.fragment),_$t=l(),Qf=a("p"),b$t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),rfe=a("a"),v$t=o("from_pretrained()"),F$t=o(" class method or the "),tfe=a("a"),T$t=o("from_config()"),M$t=o(` class
method.`),E$t=l(),ZI=a("p"),C$t=o("This class cannot be instantiated directly using "),fqe=a("code"),w$t=o("__init__()"),A$t=o(" (throws an error)."),L$t=l(),La=a("div"),F(KI.$$.fragment),y$t=l(),gqe=a("p"),x$t=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),$$t=l(),Wf=a("p"),k$t=o(`Note:
Loading a model from its configuration file does `),hqe=a("strong"),S$t=o("not"),R$t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),afe=a("a"),P$t=o("from_pretrained()"),B$t=o(" to load the model weights."),I$t=l(),F(T9.$$.fragment),N$t=l(),pt=a("div"),F(eN.$$.fragment),q$t=l(),uqe=a("p"),j$t=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),D$t=l(),gs=a("p"),G$t=o("The model class to instantiate is selected based on the "),pqe=a("code"),O$t=o("model_type"),V$t=o(` property of the config object (either
passed as an argument or loaded from `),_qe=a("code"),X$t=o("pretrained_model_name_or_path"),z$t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bqe=a("code"),Q$t=o("pretrained_model_name_or_path"),W$t=o(":"),U$t=l(),oN=a("ul"),M9=a("li"),vqe=a("strong"),H$t=o("beit"),J$t=o(" \u2014 "),nfe=a("a"),Y$t=o("FlaxBeitForImageClassification"),Z$t=o(" (BEiT model)"),K$t=l(),E9=a("li"),Fqe=a("strong"),ekt=o("vit"),okt=o(" \u2014 "),sfe=a("a"),rkt=o("FlaxViTForImageClassification"),tkt=o(" (ViT model)"),akt=l(),F(C9.$$.fragment),zdo=l(),Uf=a("h2"),w9=a("a"),Tqe=a("span"),F(rN.$$.fragment),nkt=l(),Mqe=a("span"),skt=o("FlaxAutoModelForVision2Seq"),Qdo=l(),Gr=a("div"),F(tN.$$.fragment),lkt=l(),Hf=a("p"),ikt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),lfe=a("a"),dkt=o("from_pretrained()"),mkt=o(" class method or the "),ife=a("a"),ckt=o("from_config()"),fkt=o(` class
method.`),gkt=l(),aN=a("p"),hkt=o("This class cannot be instantiated directly using "),Eqe=a("code"),ukt=o("__init__()"),pkt=o(" (throws an error)."),_kt=l(),ya=a("div"),F(nN.$$.fragment),bkt=l(),Cqe=a("p"),vkt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Fkt=l(),Jf=a("p"),Tkt=o(`Note:
Loading a model from its configuration file does `),wqe=a("strong"),Mkt=o("not"),Ekt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dfe=a("a"),Ckt=o("from_pretrained()"),wkt=o(" to load the model weights."),Akt=l(),F(A9.$$.fragment),Lkt=l(),_t=a("div"),F(sN.$$.fragment),ykt=l(),Aqe=a("p"),xkt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),$kt=l(),hs=a("p"),kkt=o("The model class to instantiate is selected based on the "),Lqe=a("code"),Skt=o("model_type"),Rkt=o(` property of the config object (either
passed as an argument or loaded from `),yqe=a("code"),Pkt=o("pretrained_model_name_or_path"),Bkt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xqe=a("code"),Ikt=o("pretrained_model_name_or_path"),Nkt=o(":"),qkt=l(),$qe=a("ul"),L9=a("li"),kqe=a("strong"),jkt=o("vision-encoder-decoder"),Dkt=o(" \u2014 "),mfe=a("a"),Gkt=o("FlaxVisionEncoderDecoderModel"),Okt=o(" (Vision Encoder decoder model)"),Vkt=l(),F(y9.$$.fragment),this.h()},l(c){const _=Exa('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(c),u=n(c,"H1",{class:!0});var lN=s(u);f=n(lN,"A",{id:!0,class:!0,href:!0});var Sqe=s(f);p=n(Sqe,"SPAN",{});var Rqe=s(p);T(m.$$.fragment,Rqe),Rqe.forEach(t),Sqe.forEach(t),h=i(lN),He=n(lN,"SPAN",{});var Pqe=s(He);Ad=r(Pqe,"Auto Classes"),Pqe.forEach(t),lN.forEach(t),eg=i(c),wt=n(c,"P",{});var iN=s(wt);Ld=r(iN,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),yd=n(iN,"CODE",{});var Bqe=s(yd);ck=r(Bqe,"from_pretrained()"),Bqe.forEach(t),og=r(iN,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),iN.forEach(t),Qe=i(c),Ze=n(c,"P",{});var us=s(Ze);xd=r(us,"Instantiating one of "),ps=n(us,"A",{href:!0});var Iqe=s(ps);fk=r(Iqe,"AutoConfig"),Iqe.forEach(t),_s=r(us,", "),bs=n(us,"A",{href:!0});var Nqe=s(bs);gk=r(Nqe,"AutoModel"),Nqe.forEach(t),$d=r(us,`, and
`),vs=n(us,"A",{href:!0});var qqe=s(vs);hk=r(qqe,"AutoTokenizer"),qqe.forEach(t),kd=r(us," will directly create a class of the relevant architecture. For instance"),us.forEach(t),rg=i(c),T(sn.$$.fragment,c),Ke=i(c),ye=n(c,"P",{});var dN=s(ye);Bq=r(dN,"will create a model that is an instance of "),Sd=n(dN,"A",{href:!0});var jqe=s(Sd);Iq=r(jqe,"BertModel"),jqe.forEach(t),Nq=r(dN,"."),dN.forEach(t),Po=i(c),ln=n(c,"P",{});var mN=s(ln);qq=r(mN,"There is one class of "),tg=n(mN,"CODE",{});var Dqe=s(tg);jq=r(Dqe,"AutoModel"),Dqe.forEach(t),Ffo=r(mN," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),mN.forEach(t),ylo=i(c),Rd=n(c,"H2",{class:!0});var cN=s(Rd);ag=n(cN,"A",{id:!0,class:!0,href:!0});var Gqe=s(ag);vhe=n(Gqe,"SPAN",{});var Oqe=s(vhe);T(uk.$$.fragment,Oqe),Oqe.forEach(t),Gqe.forEach(t),Tfo=i(cN),Fhe=n(cN,"SPAN",{});var Vqe=s(Fhe);Mfo=r(Vqe,"Extending the Auto Classes"),Vqe.forEach(t),cN.forEach(t),xlo=i(c),Fs=n(c,"P",{});var Yf=s(Fs);Efo=r(Yf,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),The=n(Yf,"CODE",{});var Xqe=s(The);Cfo=r(Xqe,"NewModel"),Xqe.forEach(t),wfo=r(Yf,", make sure you have a "),Mhe=n(Yf,"CODE",{});var zqe=s(Mhe);Afo=r(zqe,"NewModelConfig"),zqe.forEach(t),Lfo=r(Yf,` then you can add those to the auto
classes like this:`),Yf.forEach(t),$lo=i(c),T(pk.$$.fragment,c),klo=i(c),Dq=n(c,"P",{});var Qqe=s(Dq);yfo=r(Qqe,"You will then be able to use the auto classes like you would usually do!"),Qqe.forEach(t),Slo=i(c),T(ng.$$.fragment,c),Rlo=i(c),Pd=n(c,"H2",{class:!0});var fN=s(Pd);sg=n(fN,"A",{id:!0,class:!0,href:!0});var Wqe=s(sg);Ehe=n(Wqe,"SPAN",{});var Uqe=s(Ehe);T(_k.$$.fragment,Uqe),Uqe.forEach(t),Wqe.forEach(t),xfo=i(fN),Che=n(fN,"SPAN",{});var Hqe=s(Che);$fo=r(Hqe,"AutoConfig"),Hqe.forEach(t),fN.forEach(t),Plo=i(c),Bo=n(c,"DIV",{class:!0});var Et=s(Bo);T(bk.$$.fragment,Et),kfo=i(Et),vk=n(Et,"P",{});var gN=s(vk);Sfo=r(gN,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),Gq=n(gN,"A",{href:!0});var Jqe=s(Gq);Rfo=r(Jqe,"from_pretrained()"),Jqe.forEach(t),Pfo=r(gN," class method."),gN.forEach(t),Bfo=i(Et),Fk=n(Et,"P",{});var hN=s(Fk);Ifo=r(hN,"This class cannot be instantiated directly using "),whe=n(hN,"CODE",{});var Yqe=s(whe);Nfo=r(Yqe,"__init__()"),Yqe.forEach(t),qfo=r(hN," (throws an error)."),hN.forEach(t),jfo=i(Et),Or=n(Et,"DIV",{class:!0});var Ct=s(Or);T(Tk.$$.fragment,Ct),Dfo=i(Ct),Ahe=n(Ct,"P",{});var Zqe=s(Ahe);Gfo=r(Zqe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),Zqe.forEach(t),Ofo=i(Ct),Bd=n(Ct,"P",{});var Zf=s(Bd);Vfo=r(Zf,"The configuration class to instantiate is selected based on the "),Lhe=n(Zf,"CODE",{});var Kqe=s(Lhe);Xfo=r(Kqe,"model_type"),Kqe.forEach(t),zfo=r(Zf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),yhe=n(Zf,"CODE",{});var eje=s(yhe);Qfo=r(eje,"pretrained_model_name_or_path"),eje.forEach(t),Wfo=r(Zf,":"),Zf.forEach(t),Ufo=i(Ct),A=n(Ct,"UL",{});var L=s(A);lg=n(L,"LI",{});var x9=s(lg);xhe=n(x9,"STRONG",{});var oje=s(xhe);Hfo=r(oje,"albert"),oje.forEach(t),Jfo=r(x9," \u2014 "),Oq=n(x9,"A",{href:!0});var rje=s(Oq);Yfo=r(rje,"AlbertConfig"),rje.forEach(t),Zfo=r(x9," (ALBERT model)"),x9.forEach(t),Kfo=i(L),ig=n(L,"LI",{});var $9=s(ig);$he=n($9,"STRONG",{});var tje=s($he);ego=r(tje,"bart"),tje.forEach(t),ogo=r($9," \u2014 "),Vq=n($9,"A",{href:!0});var aje=s(Vq);rgo=r(aje,"BartConfig"),aje.forEach(t),tgo=r($9," (BART model)"),$9.forEach(t),ago=i(L),dg=n(L,"LI",{});var k9=s(dg);khe=n(k9,"STRONG",{});var nje=s(khe);ngo=r(nje,"beit"),nje.forEach(t),sgo=r(k9," \u2014 "),Xq=n(k9,"A",{href:!0});var sje=s(Xq);lgo=r(sje,"BeitConfig"),sje.forEach(t),igo=r(k9," (BEiT model)"),k9.forEach(t),dgo=i(L),mg=n(L,"LI",{});var S9=s(mg);She=n(S9,"STRONG",{});var lje=s(She);mgo=r(lje,"bert"),lje.forEach(t),cgo=r(S9," \u2014 "),zq=n(S9,"A",{href:!0});var ije=s(zq);fgo=r(ije,"BertConfig"),ije.forEach(t),ggo=r(S9," (BERT model)"),S9.forEach(t),hgo=i(L),cg=n(L,"LI",{});var R9=s(cg);Rhe=n(R9,"STRONG",{});var dje=s(Rhe);ugo=r(dje,"bert-generation"),dje.forEach(t),pgo=r(R9," \u2014 "),Qq=n(R9,"A",{href:!0});var mje=s(Qq);_go=r(mje,"BertGenerationConfig"),mje.forEach(t),bgo=r(R9," (Bert Generation model)"),R9.forEach(t),vgo=i(L),fg=n(L,"LI",{});var P9=s(fg);Phe=n(P9,"STRONG",{});var cje=s(Phe);Fgo=r(cje,"big_bird"),cje.forEach(t),Tgo=r(P9," \u2014 "),Wq=n(P9,"A",{href:!0});var fje=s(Wq);Mgo=r(fje,"BigBirdConfig"),fje.forEach(t),Ego=r(P9," (BigBird model)"),P9.forEach(t),Cgo=i(L),gg=n(L,"LI",{});var B9=s(gg);Bhe=n(B9,"STRONG",{});var gje=s(Bhe);wgo=r(gje,"bigbird_pegasus"),gje.forEach(t),Ago=r(B9," \u2014 "),Uq=n(B9,"A",{href:!0});var hje=s(Uq);Lgo=r(hje,"BigBirdPegasusConfig"),hje.forEach(t),ygo=r(B9," (BigBird-Pegasus model)"),B9.forEach(t),xgo=i(L),hg=n(L,"LI",{});var I9=s(hg);Ihe=n(I9,"STRONG",{});var uje=s(Ihe);$go=r(uje,"blenderbot"),uje.forEach(t),kgo=r(I9," \u2014 "),Hq=n(I9,"A",{href:!0});var pje=s(Hq);Sgo=r(pje,"BlenderbotConfig"),pje.forEach(t),Rgo=r(I9," (Blenderbot model)"),I9.forEach(t),Pgo=i(L),ug=n(L,"LI",{});var N9=s(ug);Nhe=n(N9,"STRONG",{});var _je=s(Nhe);Bgo=r(_je,"blenderbot-small"),_je.forEach(t),Igo=r(N9," \u2014 "),Jq=n(N9,"A",{href:!0});var bje=s(Jq);Ngo=r(bje,"BlenderbotSmallConfig"),bje.forEach(t),qgo=r(N9," (BlenderbotSmall model)"),N9.forEach(t),jgo=i(L),pg=n(L,"LI",{});var q9=s(pg);qhe=n(q9,"STRONG",{});var vje=s(qhe);Dgo=r(vje,"bloom"),vje.forEach(t),Ggo=r(q9," \u2014 "),Yq=n(q9,"A",{href:!0});var Fje=s(Yq);Ogo=r(Fje,"BloomConfig"),Fje.forEach(t),Vgo=r(q9," (BLOOM model)"),q9.forEach(t),Xgo=i(L),_g=n(L,"LI",{});var j9=s(_g);jhe=n(j9,"STRONG",{});var Tje=s(jhe);zgo=r(Tje,"camembert"),Tje.forEach(t),Qgo=r(j9," \u2014 "),Zq=n(j9,"A",{href:!0});var Mje=s(Zq);Wgo=r(Mje,"CamembertConfig"),Mje.forEach(t),Ugo=r(j9," (CamemBERT model)"),j9.forEach(t),Hgo=i(L),bg=n(L,"LI",{});var D9=s(bg);Dhe=n(D9,"STRONG",{});var Eje=s(Dhe);Jgo=r(Eje,"canine"),Eje.forEach(t),Ygo=r(D9," \u2014 "),Kq=n(D9,"A",{href:!0});var Cje=s(Kq);Zgo=r(Cje,"CanineConfig"),Cje.forEach(t),Kgo=r(D9," (CANINE model)"),D9.forEach(t),eho=i(L),vg=n(L,"LI",{});var G9=s(vg);Ghe=n(G9,"STRONG",{});var wje=s(Ghe);oho=r(wje,"clip"),wje.forEach(t),rho=r(G9," \u2014 "),ej=n(G9,"A",{href:!0});var Aje=s(ej);tho=r(Aje,"CLIPConfig"),Aje.forEach(t),aho=r(G9," (CLIP model)"),G9.forEach(t),nho=i(L),Fg=n(L,"LI",{});var O9=s(Fg);Ohe=n(O9,"STRONG",{});var Lje=s(Ohe);sho=r(Lje,"clipseg"),Lje.forEach(t),lho=r(O9," \u2014 "),oj=n(O9,"A",{href:!0});var yje=s(oj);iho=r(yje,"CLIPSegConfig"),yje.forEach(t),dho=r(O9," (CLIPSeg model)"),O9.forEach(t),mho=i(L),Tg=n(L,"LI",{});var V9=s(Tg);Vhe=n(V9,"STRONG",{});var xje=s(Vhe);cho=r(xje,"codegen"),xje.forEach(t),fho=r(V9," \u2014 "),rj=n(V9,"A",{href:!0});var $je=s(rj);gho=r($je,"CodeGenConfig"),$je.forEach(t),hho=r(V9," (CodeGen model)"),V9.forEach(t),uho=i(L),Mg=n(L,"LI",{});var X9=s(Mg);Xhe=n(X9,"STRONG",{});var kje=s(Xhe);pho=r(kje,"conditional_detr"),kje.forEach(t),_ho=r(X9," \u2014 "),tj=n(X9,"A",{href:!0});var Sje=s(tj);bho=r(Sje,"ConditionalDetrConfig"),Sje.forEach(t),vho=r(X9," (Conditional DETR model)"),X9.forEach(t),Fho=i(L),Eg=n(L,"LI",{});var z9=s(Eg);zhe=n(z9,"STRONG",{});var Rje=s(zhe);Tho=r(Rje,"convbert"),Rje.forEach(t),Mho=r(z9," \u2014 "),aj=n(z9,"A",{href:!0});var Pje=s(aj);Eho=r(Pje,"ConvBertConfig"),Pje.forEach(t),Cho=r(z9," (ConvBERT model)"),z9.forEach(t),who=i(L),Cg=n(L,"LI",{});var Q9=s(Cg);Qhe=n(Q9,"STRONG",{});var Bje=s(Qhe);Aho=r(Bje,"convnext"),Bje.forEach(t),Lho=r(Q9," \u2014 "),nj=n(Q9,"A",{href:!0});var Ije=s(nj);yho=r(Ije,"ConvNextConfig"),Ije.forEach(t),xho=r(Q9," (ConvNeXT model)"),Q9.forEach(t),$ho=i(L),wg=n(L,"LI",{});var W9=s(wg);Whe=n(W9,"STRONG",{});var Nje=s(Whe);kho=r(Nje,"ctrl"),Nje.forEach(t),Sho=r(W9," \u2014 "),sj=n(W9,"A",{href:!0});var qje=s(sj);Rho=r(qje,"CTRLConfig"),qje.forEach(t),Pho=r(W9," (CTRL model)"),W9.forEach(t),Bho=i(L),Ag=n(L,"LI",{});var U9=s(Ag);Uhe=n(U9,"STRONG",{});var jje=s(Uhe);Iho=r(jje,"cvt"),jje.forEach(t),Nho=r(U9," \u2014 "),lj=n(U9,"A",{href:!0});var Dje=s(lj);qho=r(Dje,"CvtConfig"),Dje.forEach(t),jho=r(U9," (CvT model)"),U9.forEach(t),Dho=i(L),Lg=n(L,"LI",{});var H9=s(Lg);Hhe=n(H9,"STRONG",{});var Gje=s(Hhe);Gho=r(Gje,"data2vec-audio"),Gje.forEach(t),Oho=r(H9," \u2014 "),ij=n(H9,"A",{href:!0});var Oje=s(ij);Vho=r(Oje,"Data2VecAudioConfig"),Oje.forEach(t),Xho=r(H9," (Data2VecAudio model)"),H9.forEach(t),zho=i(L),yg=n(L,"LI",{});var J9=s(yg);Jhe=n(J9,"STRONG",{});var Vje=s(Jhe);Qho=r(Vje,"data2vec-text"),Vje.forEach(t),Who=r(J9," \u2014 "),dj=n(J9,"A",{href:!0});var Xje=s(dj);Uho=r(Xje,"Data2VecTextConfig"),Xje.forEach(t),Hho=r(J9," (Data2VecText model)"),J9.forEach(t),Jho=i(L),xg=n(L,"LI",{});var Y9=s(xg);Yhe=n(Y9,"STRONG",{});var zje=s(Yhe);Yho=r(zje,"data2vec-vision"),zje.forEach(t),Zho=r(Y9," \u2014 "),mj=n(Y9,"A",{href:!0});var Qje=s(mj);Kho=r(Qje,"Data2VecVisionConfig"),Qje.forEach(t),euo=r(Y9," (Data2VecVision model)"),Y9.forEach(t),ouo=i(L),$g=n(L,"LI",{});var Z9=s($g);Zhe=n(Z9,"STRONG",{});var Wje=s(Zhe);ruo=r(Wje,"deberta"),Wje.forEach(t),tuo=r(Z9," \u2014 "),cj=n(Z9,"A",{href:!0});var Uje=s(cj);auo=r(Uje,"DebertaConfig"),Uje.forEach(t),nuo=r(Z9," (DeBERTa model)"),Z9.forEach(t),suo=i(L),kg=n(L,"LI",{});var K9=s(kg);Khe=n(K9,"STRONG",{});var Hje=s(Khe);luo=r(Hje,"deberta-v2"),Hje.forEach(t),iuo=r(K9," \u2014 "),fj=n(K9,"A",{href:!0});var Jje=s(fj);duo=r(Jje,"DebertaV2Config"),Jje.forEach(t),muo=r(K9," (DeBERTa-v2 model)"),K9.forEach(t),cuo=i(L),Sg=n(L,"LI",{});var ex=s(Sg);eue=n(ex,"STRONG",{});var Yje=s(eue);fuo=r(Yje,"decision_transformer"),Yje.forEach(t),guo=r(ex," \u2014 "),gj=n(ex,"A",{href:!0});var Zje=s(gj);huo=r(Zje,"DecisionTransformerConfig"),Zje.forEach(t),uuo=r(ex," (Decision Transformer model)"),ex.forEach(t),puo=i(L),Rg=n(L,"LI",{});var ox=s(Rg);oue=n(ox,"STRONG",{});var Kje=s(oue);_uo=r(Kje,"deformable_detr"),Kje.forEach(t),buo=r(ox," \u2014 "),hj=n(ox,"A",{href:!0});var eDe=s(hj);vuo=r(eDe,"DeformableDetrConfig"),eDe.forEach(t),Fuo=r(ox," (Deformable DETR model)"),ox.forEach(t),Tuo=i(L),Pg=n(L,"LI",{});var rx=s(Pg);rue=n(rx,"STRONG",{});var oDe=s(rue);Muo=r(oDe,"deit"),oDe.forEach(t),Euo=r(rx," \u2014 "),uj=n(rx,"A",{href:!0});var rDe=s(uj);Cuo=r(rDe,"DeiTConfig"),rDe.forEach(t),wuo=r(rx," (DeiT model)"),rx.forEach(t),Auo=i(L),Bg=n(L,"LI",{});var tDe=s(Bg);tue=n(tDe,"STRONG",{});var Xkt=s(tue);Luo=r(Xkt,"detr"),Xkt.forEach(t),yuo=r(tDe," \u2014 "),pj=n(tDe,"A",{href:!0});var zkt=s(pj);xuo=r(zkt,"DetrConfig"),zkt.forEach(t),$uo=r(tDe," (DETR model)"),tDe.forEach(t),kuo=i(L),Ig=n(L,"LI",{});var aDe=s(Ig);aue=n(aDe,"STRONG",{});var Qkt=s(aue);Suo=r(Qkt,"distilbert"),Qkt.forEach(t),Ruo=r(aDe," \u2014 "),_j=n(aDe,"A",{href:!0});var Wkt=s(_j);Puo=r(Wkt,"DistilBertConfig"),Wkt.forEach(t),Buo=r(aDe," (DistilBERT model)"),aDe.forEach(t),Iuo=i(L),Ng=n(L,"LI",{});var nDe=s(Ng);nue=n(nDe,"STRONG",{});var Ukt=s(nue);Nuo=r(Ukt,"donut-swin"),Ukt.forEach(t),quo=r(nDe," \u2014 "),bj=n(nDe,"A",{href:!0});var Hkt=s(bj);juo=r(Hkt,"DonutSwinConfig"),Hkt.forEach(t),Duo=r(nDe," (DonutSwin model)"),nDe.forEach(t),Guo=i(L),qg=n(L,"LI",{});var sDe=s(qg);sue=n(sDe,"STRONG",{});var Jkt=s(sue);Ouo=r(Jkt,"dpr"),Jkt.forEach(t),Vuo=r(sDe," \u2014 "),vj=n(sDe,"A",{href:!0});var Ykt=s(vj);Xuo=r(Ykt,"DPRConfig"),Ykt.forEach(t),zuo=r(sDe," (DPR model)"),sDe.forEach(t),Quo=i(L),jg=n(L,"LI",{});var lDe=s(jg);lue=n(lDe,"STRONG",{});var Zkt=s(lue);Wuo=r(Zkt,"dpt"),Zkt.forEach(t),Uuo=r(lDe," \u2014 "),Fj=n(lDe,"A",{href:!0});var Kkt=s(Fj);Huo=r(Kkt,"DPTConfig"),Kkt.forEach(t),Juo=r(lDe," (DPT model)"),lDe.forEach(t),Yuo=i(L),Dg=n(L,"LI",{});var iDe=s(Dg);iue=n(iDe,"STRONG",{});var eSt=s(iue);Zuo=r(eSt,"electra"),eSt.forEach(t),Kuo=r(iDe," \u2014 "),Tj=n(iDe,"A",{href:!0});var oSt=s(Tj);epo=r(oSt,"ElectraConfig"),oSt.forEach(t),opo=r(iDe," (ELECTRA model)"),iDe.forEach(t),rpo=i(L),Gg=n(L,"LI",{});var dDe=s(Gg);due=n(dDe,"STRONG",{});var rSt=s(due);tpo=r(rSt,"encoder-decoder"),rSt.forEach(t),apo=r(dDe," \u2014 "),Mj=n(dDe,"A",{href:!0});var tSt=s(Mj);npo=r(tSt,"EncoderDecoderConfig"),tSt.forEach(t),spo=r(dDe," (Encoder decoder model)"),dDe.forEach(t),lpo=i(L),Og=n(L,"LI",{});var mDe=s(Og);mue=n(mDe,"STRONG",{});var aSt=s(mue);ipo=r(aSt,"ernie"),aSt.forEach(t),dpo=r(mDe," \u2014 "),Ej=n(mDe,"A",{href:!0});var nSt=s(Ej);mpo=r(nSt,"ErnieConfig"),nSt.forEach(t),cpo=r(mDe," (ERNIE model)"),mDe.forEach(t),fpo=i(L),Vg=n(L,"LI",{});var cDe=s(Vg);cue=n(cDe,"STRONG",{});var sSt=s(cue);gpo=r(sSt,"esm"),sSt.forEach(t),hpo=r(cDe," \u2014 "),Cj=n(cDe,"A",{href:!0});var lSt=s(Cj);upo=r(lSt,"EsmConfig"),lSt.forEach(t),ppo=r(cDe," (ESM model)"),cDe.forEach(t),_po=i(L),Xg=n(L,"LI",{});var fDe=s(Xg);fue=n(fDe,"STRONG",{});var iSt=s(fue);bpo=r(iSt,"flaubert"),iSt.forEach(t),vpo=r(fDe," \u2014 "),wj=n(fDe,"A",{href:!0});var dSt=s(wj);Fpo=r(dSt,"FlaubertConfig"),dSt.forEach(t),Tpo=r(fDe," (FlauBERT model)"),fDe.forEach(t),Mpo=i(L),zg=n(L,"LI",{});var gDe=s(zg);gue=n(gDe,"STRONG",{});var mSt=s(gue);Epo=r(mSt,"flava"),mSt.forEach(t),Cpo=r(gDe," \u2014 "),Aj=n(gDe,"A",{href:!0});var cSt=s(Aj);wpo=r(cSt,"FlavaConfig"),cSt.forEach(t),Apo=r(gDe," (FLAVA model)"),gDe.forEach(t),Lpo=i(L),Qg=n(L,"LI",{});var hDe=s(Qg);hue=n(hDe,"STRONG",{});var fSt=s(hue);ypo=r(fSt,"fnet"),fSt.forEach(t),xpo=r(hDe," \u2014 "),Lj=n(hDe,"A",{href:!0});var gSt=s(Lj);$po=r(gSt,"FNetConfig"),gSt.forEach(t),kpo=r(hDe," (FNet model)"),hDe.forEach(t),Spo=i(L),Wg=n(L,"LI",{});var uDe=s(Wg);uue=n(uDe,"STRONG",{});var hSt=s(uue);Rpo=r(hSt,"fsmt"),hSt.forEach(t),Ppo=r(uDe," \u2014 "),yj=n(uDe,"A",{href:!0});var uSt=s(yj);Bpo=r(uSt,"FSMTConfig"),uSt.forEach(t),Ipo=r(uDe," (FairSeq Machine-Translation model)"),uDe.forEach(t),Npo=i(L),Ug=n(L,"LI",{});var pDe=s(Ug);pue=n(pDe,"STRONG",{});var pSt=s(pue);qpo=r(pSt,"funnel"),pSt.forEach(t),jpo=r(pDe," \u2014 "),xj=n(pDe,"A",{href:!0});var _St=s(xj);Dpo=r(_St,"FunnelConfig"),_St.forEach(t),Gpo=r(pDe," (Funnel Transformer model)"),pDe.forEach(t),Opo=i(L),Hg=n(L,"LI",{});var _De=s(Hg);_ue=n(_De,"STRONG",{});var bSt=s(_ue);Vpo=r(bSt,"glpn"),bSt.forEach(t),Xpo=r(_De," \u2014 "),$j=n(_De,"A",{href:!0});var vSt=s($j);zpo=r(vSt,"GLPNConfig"),vSt.forEach(t),Qpo=r(_De," (GLPN model)"),_De.forEach(t),Wpo=i(L),Jg=n(L,"LI",{});var bDe=s(Jg);bue=n(bDe,"STRONG",{});var FSt=s(bue);Upo=r(FSt,"gpt2"),FSt.forEach(t),Hpo=r(bDe," \u2014 "),kj=n(bDe,"A",{href:!0});var TSt=s(kj);Jpo=r(TSt,"GPT2Config"),TSt.forEach(t),Ypo=r(bDe," (OpenAI GPT-2 model)"),bDe.forEach(t),Zpo=i(L),Yg=n(L,"LI",{});var vDe=s(Yg);vue=n(vDe,"STRONG",{});var MSt=s(vue);Kpo=r(MSt,"gpt_neo"),MSt.forEach(t),e_o=r(vDe," \u2014 "),Sj=n(vDe,"A",{href:!0});var ESt=s(Sj);o_o=r(ESt,"GPTNeoConfig"),ESt.forEach(t),r_o=r(vDe," (GPT Neo model)"),vDe.forEach(t),t_o=i(L),Zg=n(L,"LI",{});var FDe=s(Zg);Fue=n(FDe,"STRONG",{});var CSt=s(Fue);a_o=r(CSt,"gpt_neox"),CSt.forEach(t),n_o=r(FDe," \u2014 "),Rj=n(FDe,"A",{href:!0});var wSt=s(Rj);s_o=r(wSt,"GPTNeoXConfig"),wSt.forEach(t),l_o=r(FDe," (GPT NeoX model)"),FDe.forEach(t),i_o=i(L),Kg=n(L,"LI",{});var TDe=s(Kg);Tue=n(TDe,"STRONG",{});var ASt=s(Tue);d_o=r(ASt,"gpt_neox_japanese"),ASt.forEach(t),m_o=r(TDe," \u2014 "),Pj=n(TDe,"A",{href:!0});var LSt=s(Pj);c_o=r(LSt,"GPTNeoXJapaneseConfig"),LSt.forEach(t),f_o=r(TDe," (GPT NeoX Japanese model)"),TDe.forEach(t),g_o=i(L),eh=n(L,"LI",{});var MDe=s(eh);Mue=n(MDe,"STRONG",{});var ySt=s(Mue);h_o=r(ySt,"gptj"),ySt.forEach(t),u_o=r(MDe," \u2014 "),Bj=n(MDe,"A",{href:!0});var xSt=s(Bj);p_o=r(xSt,"GPTJConfig"),xSt.forEach(t),__o=r(MDe," (GPT-J model)"),MDe.forEach(t),b_o=i(L),oh=n(L,"LI",{});var EDe=s(oh);Eue=n(EDe,"STRONG",{});var $St=s(Eue);v_o=r($St,"groupvit"),$St.forEach(t),F_o=r(EDe," \u2014 "),Ij=n(EDe,"A",{href:!0});var kSt=s(Ij);T_o=r(kSt,"GroupViTConfig"),kSt.forEach(t),M_o=r(EDe," (GroupViT model)"),EDe.forEach(t),E_o=i(L),rh=n(L,"LI",{});var CDe=s(rh);Cue=n(CDe,"STRONG",{});var SSt=s(Cue);C_o=r(SSt,"hubert"),SSt.forEach(t),w_o=r(CDe," \u2014 "),Nj=n(CDe,"A",{href:!0});var RSt=s(Nj);A_o=r(RSt,"HubertConfig"),RSt.forEach(t),L_o=r(CDe," (Hubert model)"),CDe.forEach(t),y_o=i(L),th=n(L,"LI",{});var wDe=s(th);wue=n(wDe,"STRONG",{});var PSt=s(wue);x_o=r(PSt,"ibert"),PSt.forEach(t),$_o=r(wDe," \u2014 "),qj=n(wDe,"A",{href:!0});var BSt=s(qj);k_o=r(BSt,"IBertConfig"),BSt.forEach(t),S_o=r(wDe," (I-BERT model)"),wDe.forEach(t),R_o=i(L),ah=n(L,"LI",{});var ADe=s(ah);Aue=n(ADe,"STRONG",{});var ISt=s(Aue);P_o=r(ISt,"imagegpt"),ISt.forEach(t),B_o=r(ADe," \u2014 "),jj=n(ADe,"A",{href:!0});var NSt=s(jj);I_o=r(NSt,"ImageGPTConfig"),NSt.forEach(t),N_o=r(ADe," (ImageGPT model)"),ADe.forEach(t),q_o=i(L),nh=n(L,"LI",{});var LDe=s(nh);Lue=n(LDe,"STRONG",{});var qSt=s(Lue);j_o=r(qSt,"jukebox"),qSt.forEach(t),D_o=r(LDe," \u2014 "),Dj=n(LDe,"A",{href:!0});var jSt=s(Dj);G_o=r(jSt,"JukeboxConfig"),jSt.forEach(t),O_o=r(LDe," (Jukebox model)"),LDe.forEach(t),V_o=i(L),sh=n(L,"LI",{});var yDe=s(sh);yue=n(yDe,"STRONG",{});var DSt=s(yue);X_o=r(DSt,"layoutlm"),DSt.forEach(t),z_o=r(yDe," \u2014 "),Gj=n(yDe,"A",{href:!0});var GSt=s(Gj);Q_o=r(GSt,"LayoutLMConfig"),GSt.forEach(t),W_o=r(yDe," (LayoutLM model)"),yDe.forEach(t),U_o=i(L),lh=n(L,"LI",{});var xDe=s(lh);xue=n(xDe,"STRONG",{});var OSt=s(xue);H_o=r(OSt,"layoutlmv2"),OSt.forEach(t),J_o=r(xDe," \u2014 "),Oj=n(xDe,"A",{href:!0});var VSt=s(Oj);Y_o=r(VSt,"LayoutLMv2Config"),VSt.forEach(t),Z_o=r(xDe," (LayoutLMv2 model)"),xDe.forEach(t),K_o=i(L),ih=n(L,"LI",{});var $De=s(ih);$ue=n($De,"STRONG",{});var XSt=s($ue);e1o=r(XSt,"layoutlmv3"),XSt.forEach(t),o1o=r($De," \u2014 "),Vj=n($De,"A",{href:!0});var zSt=s(Vj);r1o=r(zSt,"LayoutLMv3Config"),zSt.forEach(t),t1o=r($De," (LayoutLMv3 model)"),$De.forEach(t),a1o=i(L),dh=n(L,"LI",{});var kDe=s(dh);kue=n(kDe,"STRONG",{});var QSt=s(kue);n1o=r(QSt,"led"),QSt.forEach(t),s1o=r(kDe," \u2014 "),Xj=n(kDe,"A",{href:!0});var WSt=s(Xj);l1o=r(WSt,"LEDConfig"),WSt.forEach(t),i1o=r(kDe," (LED model)"),kDe.forEach(t),d1o=i(L),mh=n(L,"LI",{});var SDe=s(mh);Sue=n(SDe,"STRONG",{});var USt=s(Sue);m1o=r(USt,"levit"),USt.forEach(t),c1o=r(SDe," \u2014 "),zj=n(SDe,"A",{href:!0});var HSt=s(zj);f1o=r(HSt,"LevitConfig"),HSt.forEach(t),g1o=r(SDe," (LeViT model)"),SDe.forEach(t),h1o=i(L),ch=n(L,"LI",{});var RDe=s(ch);Rue=n(RDe,"STRONG",{});var JSt=s(Rue);u1o=r(JSt,"lilt"),JSt.forEach(t),p1o=r(RDe," \u2014 "),Qj=n(RDe,"A",{href:!0});var YSt=s(Qj);_1o=r(YSt,"LiltConfig"),YSt.forEach(t),b1o=r(RDe," (LiLT model)"),RDe.forEach(t),v1o=i(L),fh=n(L,"LI",{});var PDe=s(fh);Pue=n(PDe,"STRONG",{});var ZSt=s(Pue);F1o=r(ZSt,"longformer"),ZSt.forEach(t),T1o=r(PDe," \u2014 "),Wj=n(PDe,"A",{href:!0});var KSt=s(Wj);M1o=r(KSt,"LongformerConfig"),KSt.forEach(t),E1o=r(PDe," (Longformer model)"),PDe.forEach(t),C1o=i(L),gh=n(L,"LI",{});var BDe=s(gh);Bue=n(BDe,"STRONG",{});var eRt=s(Bue);w1o=r(eRt,"longt5"),eRt.forEach(t),A1o=r(BDe," \u2014 "),Uj=n(BDe,"A",{href:!0});var oRt=s(Uj);L1o=r(oRt,"LongT5Config"),oRt.forEach(t),y1o=r(BDe," (LongT5 model)"),BDe.forEach(t),x1o=i(L),hh=n(L,"LI",{});var IDe=s(hh);Iue=n(IDe,"STRONG",{});var rRt=s(Iue);$1o=r(rRt,"luke"),rRt.forEach(t),k1o=r(IDe," \u2014 "),Hj=n(IDe,"A",{href:!0});var tRt=s(Hj);S1o=r(tRt,"LukeConfig"),tRt.forEach(t),R1o=r(IDe," (LUKE model)"),IDe.forEach(t),P1o=i(L),uh=n(L,"LI",{});var NDe=s(uh);Nue=n(NDe,"STRONG",{});var aRt=s(Nue);B1o=r(aRt,"lxmert"),aRt.forEach(t),I1o=r(NDe," \u2014 "),Jj=n(NDe,"A",{href:!0});var nRt=s(Jj);N1o=r(nRt,"LxmertConfig"),nRt.forEach(t),q1o=r(NDe," (LXMERT model)"),NDe.forEach(t),j1o=i(L),ph=n(L,"LI",{});var qDe=s(ph);que=n(qDe,"STRONG",{});var sRt=s(que);D1o=r(sRt,"m2m_100"),sRt.forEach(t),G1o=r(qDe," \u2014 "),Yj=n(qDe,"A",{href:!0});var lRt=s(Yj);O1o=r(lRt,"M2M100Config"),lRt.forEach(t),V1o=r(qDe," (M2M100 model)"),qDe.forEach(t),X1o=i(L),_h=n(L,"LI",{});var jDe=s(_h);jue=n(jDe,"STRONG",{});var iRt=s(jue);z1o=r(iRt,"marian"),iRt.forEach(t),Q1o=r(jDe," \u2014 "),Zj=n(jDe,"A",{href:!0});var dRt=s(Zj);W1o=r(dRt,"MarianConfig"),dRt.forEach(t),U1o=r(jDe," (Marian model)"),jDe.forEach(t),H1o=i(L),bh=n(L,"LI",{});var DDe=s(bh);Due=n(DDe,"STRONG",{});var mRt=s(Due);J1o=r(mRt,"markuplm"),mRt.forEach(t),Y1o=r(DDe," \u2014 "),Kj=n(DDe,"A",{href:!0});var cRt=s(Kj);Z1o=r(cRt,"MarkupLMConfig"),cRt.forEach(t),K1o=r(DDe," (MarkupLM model)"),DDe.forEach(t),e2o=i(L),vh=n(L,"LI",{});var GDe=s(vh);Gue=n(GDe,"STRONG",{});var fRt=s(Gue);o2o=r(fRt,"maskformer"),fRt.forEach(t),r2o=r(GDe," \u2014 "),eD=n(GDe,"A",{href:!0});var gRt=s(eD);t2o=r(gRt,"MaskFormerConfig"),gRt.forEach(t),a2o=r(GDe," (MaskFormer model)"),GDe.forEach(t),n2o=i(L),Fh=n(L,"LI",{});var ODe=s(Fh);Oue=n(ODe,"STRONG",{});var hRt=s(Oue);s2o=r(hRt,"mbart"),hRt.forEach(t),l2o=r(ODe," \u2014 "),oD=n(ODe,"A",{href:!0});var uRt=s(oD);i2o=r(uRt,"MBartConfig"),uRt.forEach(t),d2o=r(ODe," (mBART model)"),ODe.forEach(t),m2o=i(L),Th=n(L,"LI",{});var VDe=s(Th);Vue=n(VDe,"STRONG",{});var pRt=s(Vue);c2o=r(pRt,"mctct"),pRt.forEach(t),f2o=r(VDe," \u2014 "),rD=n(VDe,"A",{href:!0});var _Rt=s(rD);g2o=r(_Rt,"MCTCTConfig"),_Rt.forEach(t),h2o=r(VDe," (M-CTC-T model)"),VDe.forEach(t),u2o=i(L),Mh=n(L,"LI",{});var XDe=s(Mh);Xue=n(XDe,"STRONG",{});var bRt=s(Xue);p2o=r(bRt,"megatron-bert"),bRt.forEach(t),_2o=r(XDe," \u2014 "),tD=n(XDe,"A",{href:!0});var vRt=s(tD);b2o=r(vRt,"MegatronBertConfig"),vRt.forEach(t),v2o=r(XDe," (Megatron-BERT model)"),XDe.forEach(t),F2o=i(L),Eh=n(L,"LI",{});var zDe=s(Eh);zue=n(zDe,"STRONG",{});var FRt=s(zue);T2o=r(FRt,"mobilebert"),FRt.forEach(t),M2o=r(zDe," \u2014 "),aD=n(zDe,"A",{href:!0});var TRt=s(aD);E2o=r(TRt,"MobileBertConfig"),TRt.forEach(t),C2o=r(zDe," (MobileBERT model)"),zDe.forEach(t),w2o=i(L),Ch=n(L,"LI",{});var QDe=s(Ch);Que=n(QDe,"STRONG",{});var MRt=s(Que);A2o=r(MRt,"mobilevit"),MRt.forEach(t),L2o=r(QDe," \u2014 "),nD=n(QDe,"A",{href:!0});var ERt=s(nD);y2o=r(ERt,"MobileViTConfig"),ERt.forEach(t),x2o=r(QDe," (MobileViT model)"),QDe.forEach(t),$2o=i(L),wh=n(L,"LI",{});var WDe=s(wh);Wue=n(WDe,"STRONG",{});var CRt=s(Wue);k2o=r(CRt,"mpnet"),CRt.forEach(t),S2o=r(WDe," \u2014 "),sD=n(WDe,"A",{href:!0});var wRt=s(sD);R2o=r(wRt,"MPNetConfig"),wRt.forEach(t),P2o=r(WDe," (MPNet model)"),WDe.forEach(t),B2o=i(L),Ah=n(L,"LI",{});var UDe=s(Ah);Uue=n(UDe,"STRONG",{});var ARt=s(Uue);I2o=r(ARt,"mt5"),ARt.forEach(t),N2o=r(UDe," \u2014 "),lD=n(UDe,"A",{href:!0});var LRt=s(lD);q2o=r(LRt,"MT5Config"),LRt.forEach(t),j2o=r(UDe," (MT5 model)"),UDe.forEach(t),D2o=i(L),Lh=n(L,"LI",{});var HDe=s(Lh);Hue=n(HDe,"STRONG",{});var yRt=s(Hue);G2o=r(yRt,"mvp"),yRt.forEach(t),O2o=r(HDe," \u2014 "),iD=n(HDe,"A",{href:!0});var xRt=s(iD);V2o=r(xRt,"MvpConfig"),xRt.forEach(t),X2o=r(HDe," (MVP model)"),HDe.forEach(t),z2o=i(L),yh=n(L,"LI",{});var JDe=s(yh);Jue=n(JDe,"STRONG",{});var $Rt=s(Jue);Q2o=r($Rt,"nezha"),$Rt.forEach(t),W2o=r(JDe," \u2014 "),dD=n(JDe,"A",{href:!0});var kRt=s(dD);U2o=r(kRt,"NezhaConfig"),kRt.forEach(t),H2o=r(JDe," (Nezha model)"),JDe.forEach(t),J2o=i(L),xh=n(L,"LI",{});var YDe=s(xh);Yue=n(YDe,"STRONG",{});var SRt=s(Yue);Y2o=r(SRt,"nystromformer"),SRt.forEach(t),Z2o=r(YDe," \u2014 "),mD=n(YDe,"A",{href:!0});var RRt=s(mD);K2o=r(RRt,"NystromformerConfig"),RRt.forEach(t),ebo=r(YDe," (Nystr\xF6mformer model)"),YDe.forEach(t),obo=i(L),$h=n(L,"LI",{});var ZDe=s($h);Zue=n(ZDe,"STRONG",{});var PRt=s(Zue);rbo=r(PRt,"openai-gpt"),PRt.forEach(t),tbo=r(ZDe," \u2014 "),cD=n(ZDe,"A",{href:!0});var BRt=s(cD);abo=r(BRt,"OpenAIGPTConfig"),BRt.forEach(t),nbo=r(ZDe," (OpenAI GPT model)"),ZDe.forEach(t),sbo=i(L),kh=n(L,"LI",{});var KDe=s(kh);Kue=n(KDe,"STRONG",{});var IRt=s(Kue);lbo=r(IRt,"opt"),IRt.forEach(t),ibo=r(KDe," \u2014 "),fD=n(KDe,"A",{href:!0});var NRt=s(fD);dbo=r(NRt,"OPTConfig"),NRt.forEach(t),mbo=r(KDe," (OPT model)"),KDe.forEach(t),cbo=i(L),Sh=n(L,"LI",{});var eGe=s(Sh);epe=n(eGe,"STRONG",{});var qRt=s(epe);fbo=r(qRt,"owlvit"),qRt.forEach(t),gbo=r(eGe," \u2014 "),gD=n(eGe,"A",{href:!0});var jRt=s(gD);hbo=r(jRt,"OwlViTConfig"),jRt.forEach(t),ubo=r(eGe," (OWL-ViT model)"),eGe.forEach(t),pbo=i(L),Rh=n(L,"LI",{});var oGe=s(Rh);ope=n(oGe,"STRONG",{});var DRt=s(ope);_bo=r(DRt,"pegasus"),DRt.forEach(t),bbo=r(oGe," \u2014 "),hD=n(oGe,"A",{href:!0});var GRt=s(hD);vbo=r(GRt,"PegasusConfig"),GRt.forEach(t),Fbo=r(oGe," (Pegasus model)"),oGe.forEach(t),Tbo=i(L),Ph=n(L,"LI",{});var rGe=s(Ph);rpe=n(rGe,"STRONG",{});var ORt=s(rpe);Mbo=r(ORt,"pegasus_x"),ORt.forEach(t),Ebo=r(rGe," \u2014 "),uD=n(rGe,"A",{href:!0});var VRt=s(uD);Cbo=r(VRt,"PegasusXConfig"),VRt.forEach(t),wbo=r(rGe," (PEGASUS-X model)"),rGe.forEach(t),Abo=i(L),Bh=n(L,"LI",{});var tGe=s(Bh);tpe=n(tGe,"STRONG",{});var XRt=s(tpe);Lbo=r(XRt,"perceiver"),XRt.forEach(t),ybo=r(tGe," \u2014 "),pD=n(tGe,"A",{href:!0});var zRt=s(pD);xbo=r(zRt,"PerceiverConfig"),zRt.forEach(t),$bo=r(tGe," (Perceiver model)"),tGe.forEach(t),kbo=i(L),Ih=n(L,"LI",{});var aGe=s(Ih);ape=n(aGe,"STRONG",{});var QRt=s(ape);Sbo=r(QRt,"plbart"),QRt.forEach(t),Rbo=r(aGe," \u2014 "),_D=n(aGe,"A",{href:!0});var WRt=s(_D);Pbo=r(WRt,"PLBartConfig"),WRt.forEach(t),Bbo=r(aGe," (PLBart model)"),aGe.forEach(t),Ibo=i(L),Nh=n(L,"LI",{});var nGe=s(Nh);npe=n(nGe,"STRONG",{});var URt=s(npe);Nbo=r(URt,"poolformer"),URt.forEach(t),qbo=r(nGe," \u2014 "),bD=n(nGe,"A",{href:!0});var HRt=s(bD);jbo=r(HRt,"PoolFormerConfig"),HRt.forEach(t),Dbo=r(nGe," (PoolFormer model)"),nGe.forEach(t),Gbo=i(L),qh=n(L,"LI",{});var sGe=s(qh);spe=n(sGe,"STRONG",{});var JRt=s(spe);Obo=r(JRt,"prophetnet"),JRt.forEach(t),Vbo=r(sGe," \u2014 "),vD=n(sGe,"A",{href:!0});var YRt=s(vD);Xbo=r(YRt,"ProphetNetConfig"),YRt.forEach(t),zbo=r(sGe," (ProphetNet model)"),sGe.forEach(t),Qbo=i(L),jh=n(L,"LI",{});var lGe=s(jh);lpe=n(lGe,"STRONG",{});var ZRt=s(lpe);Wbo=r(ZRt,"qdqbert"),ZRt.forEach(t),Ubo=r(lGe," \u2014 "),FD=n(lGe,"A",{href:!0});var KRt=s(FD);Hbo=r(KRt,"QDQBertConfig"),KRt.forEach(t),Jbo=r(lGe," (QDQBert model)"),lGe.forEach(t),Ybo=i(L),Dh=n(L,"LI",{});var iGe=s(Dh);ipe=n(iGe,"STRONG",{});var ePt=s(ipe);Zbo=r(ePt,"rag"),ePt.forEach(t),Kbo=r(iGe," \u2014 "),TD=n(iGe,"A",{href:!0});var oPt=s(TD);evo=r(oPt,"RagConfig"),oPt.forEach(t),ovo=r(iGe," (RAG model)"),iGe.forEach(t),rvo=i(L),Gh=n(L,"LI",{});var dGe=s(Gh);dpe=n(dGe,"STRONG",{});var rPt=s(dpe);tvo=r(rPt,"realm"),rPt.forEach(t),avo=r(dGe," \u2014 "),MD=n(dGe,"A",{href:!0});var tPt=s(MD);nvo=r(tPt,"RealmConfig"),tPt.forEach(t),svo=r(dGe," (REALM model)"),dGe.forEach(t),lvo=i(L),Oh=n(L,"LI",{});var mGe=s(Oh);mpe=n(mGe,"STRONG",{});var aPt=s(mpe);ivo=r(aPt,"reformer"),aPt.forEach(t),dvo=r(mGe," \u2014 "),ED=n(mGe,"A",{href:!0});var nPt=s(ED);mvo=r(nPt,"ReformerConfig"),nPt.forEach(t),cvo=r(mGe," (Reformer model)"),mGe.forEach(t),fvo=i(L),Vh=n(L,"LI",{});var cGe=s(Vh);cpe=n(cGe,"STRONG",{});var sPt=s(cpe);gvo=r(sPt,"regnet"),sPt.forEach(t),hvo=r(cGe," \u2014 "),CD=n(cGe,"A",{href:!0});var lPt=s(CD);uvo=r(lPt,"RegNetConfig"),lPt.forEach(t),pvo=r(cGe," (RegNet model)"),cGe.forEach(t),_vo=i(L),Xh=n(L,"LI",{});var fGe=s(Xh);fpe=n(fGe,"STRONG",{});var iPt=s(fpe);bvo=r(iPt,"rembert"),iPt.forEach(t),vvo=r(fGe," \u2014 "),wD=n(fGe,"A",{href:!0});var dPt=s(wD);Fvo=r(dPt,"RemBertConfig"),dPt.forEach(t),Tvo=r(fGe," (RemBERT model)"),fGe.forEach(t),Mvo=i(L),zh=n(L,"LI",{});var gGe=s(zh);gpe=n(gGe,"STRONG",{});var mPt=s(gpe);Evo=r(mPt,"resnet"),mPt.forEach(t),Cvo=r(gGe," \u2014 "),AD=n(gGe,"A",{href:!0});var cPt=s(AD);wvo=r(cPt,"ResNetConfig"),cPt.forEach(t),Avo=r(gGe," (ResNet model)"),gGe.forEach(t),Lvo=i(L),Qh=n(L,"LI",{});var hGe=s(Qh);hpe=n(hGe,"STRONG",{});var fPt=s(hpe);yvo=r(fPt,"retribert"),fPt.forEach(t),xvo=r(hGe," \u2014 "),LD=n(hGe,"A",{href:!0});var gPt=s(LD);$vo=r(gPt,"RetriBertConfig"),gPt.forEach(t),kvo=r(hGe," (RetriBERT model)"),hGe.forEach(t),Svo=i(L),Wh=n(L,"LI",{});var uGe=s(Wh);upe=n(uGe,"STRONG",{});var hPt=s(upe);Rvo=r(hPt,"roberta"),hPt.forEach(t),Pvo=r(uGe," \u2014 "),yD=n(uGe,"A",{href:!0});var uPt=s(yD);Bvo=r(uPt,"RobertaConfig"),uPt.forEach(t),Ivo=r(uGe," (RoBERTa model)"),uGe.forEach(t),Nvo=i(L),Uh=n(L,"LI",{});var pGe=s(Uh);ppe=n(pGe,"STRONG",{});var pPt=s(ppe);qvo=r(pPt,"roc_bert"),pPt.forEach(t),jvo=r(pGe," \u2014 "),xD=n(pGe,"A",{href:!0});var _Pt=s(xD);Dvo=r(_Pt,"RoCBertConfig"),_Pt.forEach(t),Gvo=r(pGe," (RoCBert model)"),pGe.forEach(t),Ovo=i(L),Hh=n(L,"LI",{});var _Ge=s(Hh);_pe=n(_Ge,"STRONG",{});var bPt=s(_pe);Vvo=r(bPt,"roformer"),bPt.forEach(t),Xvo=r(_Ge," \u2014 "),$D=n(_Ge,"A",{href:!0});var vPt=s($D);zvo=r(vPt,"RoFormerConfig"),vPt.forEach(t),Qvo=r(_Ge," (RoFormer model)"),_Ge.forEach(t),Wvo=i(L),Jh=n(L,"LI",{});var bGe=s(Jh);bpe=n(bGe,"STRONG",{});var FPt=s(bpe);Uvo=r(FPt,"segformer"),FPt.forEach(t),Hvo=r(bGe," \u2014 "),kD=n(bGe,"A",{href:!0});var TPt=s(kD);Jvo=r(TPt,"SegformerConfig"),TPt.forEach(t),Yvo=r(bGe," (SegFormer model)"),bGe.forEach(t),Zvo=i(L),Yh=n(L,"LI",{});var vGe=s(Yh);vpe=n(vGe,"STRONG",{});var MPt=s(vpe);Kvo=r(MPt,"sew"),MPt.forEach(t),eFo=r(vGe," \u2014 "),SD=n(vGe,"A",{href:!0});var EPt=s(SD);oFo=r(EPt,"SEWConfig"),EPt.forEach(t),rFo=r(vGe," (SEW model)"),vGe.forEach(t),tFo=i(L),Zh=n(L,"LI",{});var FGe=s(Zh);Fpe=n(FGe,"STRONG",{});var CPt=s(Fpe);aFo=r(CPt,"sew-d"),CPt.forEach(t),nFo=r(FGe," \u2014 "),RD=n(FGe,"A",{href:!0});var wPt=s(RD);sFo=r(wPt,"SEWDConfig"),wPt.forEach(t),lFo=r(FGe," (SEW-D model)"),FGe.forEach(t),iFo=i(L),Kh=n(L,"LI",{});var TGe=s(Kh);Tpe=n(TGe,"STRONG",{});var APt=s(Tpe);dFo=r(APt,"speech-encoder-decoder"),APt.forEach(t),mFo=r(TGe," \u2014 "),PD=n(TGe,"A",{href:!0});var LPt=s(PD);cFo=r(LPt,"SpeechEncoderDecoderConfig"),LPt.forEach(t),fFo=r(TGe," (Speech Encoder decoder model)"),TGe.forEach(t),gFo=i(L),eu=n(L,"LI",{});var MGe=s(eu);Mpe=n(MGe,"STRONG",{});var yPt=s(Mpe);hFo=r(yPt,"speech_to_text"),yPt.forEach(t),uFo=r(MGe," \u2014 "),BD=n(MGe,"A",{href:!0});var xPt=s(BD);pFo=r(xPt,"Speech2TextConfig"),xPt.forEach(t),_Fo=r(MGe," (Speech2Text model)"),MGe.forEach(t),bFo=i(L),ou=n(L,"LI",{});var EGe=s(ou);Epe=n(EGe,"STRONG",{});var $Pt=s(Epe);vFo=r($Pt,"speech_to_text_2"),$Pt.forEach(t),FFo=r(EGe," \u2014 "),ID=n(EGe,"A",{href:!0});var kPt=s(ID);TFo=r(kPt,"Speech2Text2Config"),kPt.forEach(t),MFo=r(EGe," (Speech2Text2 model)"),EGe.forEach(t),EFo=i(L),ru=n(L,"LI",{});var CGe=s(ru);Cpe=n(CGe,"STRONG",{});var SPt=s(Cpe);CFo=r(SPt,"splinter"),SPt.forEach(t),wFo=r(CGe," \u2014 "),ND=n(CGe,"A",{href:!0});var RPt=s(ND);AFo=r(RPt,"SplinterConfig"),RPt.forEach(t),LFo=r(CGe," (Splinter model)"),CGe.forEach(t),yFo=i(L),tu=n(L,"LI",{});var wGe=s(tu);wpe=n(wGe,"STRONG",{});var PPt=s(wpe);xFo=r(PPt,"squeezebert"),PPt.forEach(t),$Fo=r(wGe," \u2014 "),qD=n(wGe,"A",{href:!0});var BPt=s(qD);kFo=r(BPt,"SqueezeBertConfig"),BPt.forEach(t),SFo=r(wGe," (SqueezeBERT model)"),wGe.forEach(t),RFo=i(L),au=n(L,"LI",{});var AGe=s(au);Ape=n(AGe,"STRONG",{});var IPt=s(Ape);PFo=r(IPt,"swin"),IPt.forEach(t),BFo=r(AGe," \u2014 "),jD=n(AGe,"A",{href:!0});var NPt=s(jD);IFo=r(NPt,"SwinConfig"),NPt.forEach(t),NFo=r(AGe," (Swin Transformer model)"),AGe.forEach(t),qFo=i(L),nu=n(L,"LI",{});var LGe=s(nu);Lpe=n(LGe,"STRONG",{});var qPt=s(Lpe);jFo=r(qPt,"swinv2"),qPt.forEach(t),DFo=r(LGe," \u2014 "),DD=n(LGe,"A",{href:!0});var jPt=s(DD);GFo=r(jPt,"Swinv2Config"),jPt.forEach(t),OFo=r(LGe," (Swin Transformer V2 model)"),LGe.forEach(t),VFo=i(L),su=n(L,"LI",{});var yGe=s(su);ype=n(yGe,"STRONG",{});var DPt=s(ype);XFo=r(DPt,"t5"),DPt.forEach(t),zFo=r(yGe," \u2014 "),GD=n(yGe,"A",{href:!0});var GPt=s(GD);QFo=r(GPt,"T5Config"),GPt.forEach(t),WFo=r(yGe," (T5 model)"),yGe.forEach(t),UFo=i(L),lu=n(L,"LI",{});var xGe=s(lu);xpe=n(xGe,"STRONG",{});var OPt=s(xpe);HFo=r(OPt,"table-transformer"),OPt.forEach(t),JFo=r(xGe," \u2014 "),OD=n(xGe,"A",{href:!0});var VPt=s(OD);YFo=r(VPt,"TableTransformerConfig"),VPt.forEach(t),ZFo=r(xGe," (Table Transformer model)"),xGe.forEach(t),KFo=i(L),iu=n(L,"LI",{});var $Ge=s(iu);$pe=n($Ge,"STRONG",{});var XPt=s($pe);eTo=r(XPt,"tapas"),XPt.forEach(t),oTo=r($Ge," \u2014 "),VD=n($Ge,"A",{href:!0});var zPt=s(VD);rTo=r(zPt,"TapasConfig"),zPt.forEach(t),tTo=r($Ge," (TAPAS model)"),$Ge.forEach(t),aTo=i(L),du=n(L,"LI",{});var kGe=s(du);kpe=n(kGe,"STRONG",{});var QPt=s(kpe);nTo=r(QPt,"time_series_transformer"),QPt.forEach(t),sTo=r(kGe," \u2014 "),XD=n(kGe,"A",{href:!0});var WPt=s(XD);lTo=r(WPt,"TimeSeriesTransformerConfig"),WPt.forEach(t),iTo=r(kGe," (Time Series Transformer model)"),kGe.forEach(t),dTo=i(L),mu=n(L,"LI",{});var SGe=s(mu);Spe=n(SGe,"STRONG",{});var UPt=s(Spe);mTo=r(UPt,"trajectory_transformer"),UPt.forEach(t),cTo=r(SGe," \u2014 "),zD=n(SGe,"A",{href:!0});var HPt=s(zD);fTo=r(HPt,"TrajectoryTransformerConfig"),HPt.forEach(t),gTo=r(SGe," (Trajectory Transformer model)"),SGe.forEach(t),hTo=i(L),cu=n(L,"LI",{});var RGe=s(cu);Rpe=n(RGe,"STRONG",{});var JPt=s(Rpe);uTo=r(JPt,"transfo-xl"),JPt.forEach(t),pTo=r(RGe," \u2014 "),QD=n(RGe,"A",{href:!0});var YPt=s(QD);_To=r(YPt,"TransfoXLConfig"),YPt.forEach(t),bTo=r(RGe," (Transformer-XL model)"),RGe.forEach(t),vTo=i(L),fu=n(L,"LI",{});var PGe=s(fu);Ppe=n(PGe,"STRONG",{});var ZPt=s(Ppe);FTo=r(ZPt,"trocr"),ZPt.forEach(t),TTo=r(PGe," \u2014 "),WD=n(PGe,"A",{href:!0});var KPt=s(WD);MTo=r(KPt,"TrOCRConfig"),KPt.forEach(t),ETo=r(PGe," (TrOCR model)"),PGe.forEach(t),CTo=i(L),gu=n(L,"LI",{});var BGe=s(gu);Bpe=n(BGe,"STRONG",{});var eBt=s(Bpe);wTo=r(eBt,"unispeech"),eBt.forEach(t),ATo=r(BGe," \u2014 "),UD=n(BGe,"A",{href:!0});var oBt=s(UD);LTo=r(oBt,"UniSpeechConfig"),oBt.forEach(t),yTo=r(BGe," (UniSpeech model)"),BGe.forEach(t),xTo=i(L),hu=n(L,"LI",{});var IGe=s(hu);Ipe=n(IGe,"STRONG",{});var rBt=s(Ipe);$To=r(rBt,"unispeech-sat"),rBt.forEach(t),kTo=r(IGe," \u2014 "),HD=n(IGe,"A",{href:!0});var tBt=s(HD);STo=r(tBt,"UniSpeechSatConfig"),tBt.forEach(t),RTo=r(IGe," (UniSpeechSat model)"),IGe.forEach(t),PTo=i(L),uu=n(L,"LI",{});var NGe=s(uu);Npe=n(NGe,"STRONG",{});var aBt=s(Npe);BTo=r(aBt,"van"),aBt.forEach(t),ITo=r(NGe," \u2014 "),JD=n(NGe,"A",{href:!0});var nBt=s(JD);NTo=r(nBt,"VanConfig"),nBt.forEach(t),qTo=r(NGe," (VAN model)"),NGe.forEach(t),jTo=i(L),pu=n(L,"LI",{});var qGe=s(pu);qpe=n(qGe,"STRONG",{});var sBt=s(qpe);DTo=r(sBt,"videomae"),sBt.forEach(t),GTo=r(qGe," \u2014 "),YD=n(qGe,"A",{href:!0});var lBt=s(YD);OTo=r(lBt,"VideoMAEConfig"),lBt.forEach(t),VTo=r(qGe," (VideoMAE model)"),qGe.forEach(t),XTo=i(L),_u=n(L,"LI",{});var jGe=s(_u);jpe=n(jGe,"STRONG",{});var iBt=s(jpe);zTo=r(iBt,"vilt"),iBt.forEach(t),QTo=r(jGe," \u2014 "),ZD=n(jGe,"A",{href:!0});var dBt=s(ZD);WTo=r(dBt,"ViltConfig"),dBt.forEach(t),UTo=r(jGe," (ViLT model)"),jGe.forEach(t),HTo=i(L),bu=n(L,"LI",{});var DGe=s(bu);Dpe=n(DGe,"STRONG",{});var mBt=s(Dpe);JTo=r(mBt,"vision-encoder-decoder"),mBt.forEach(t),YTo=r(DGe," \u2014 "),KD=n(DGe,"A",{href:!0});var cBt=s(KD);ZTo=r(cBt,"VisionEncoderDecoderConfig"),cBt.forEach(t),KTo=r(DGe," (Vision Encoder decoder model)"),DGe.forEach(t),eMo=i(L),vu=n(L,"LI",{});var GGe=s(vu);Gpe=n(GGe,"STRONG",{});var fBt=s(Gpe);oMo=r(fBt,"vision-text-dual-encoder"),fBt.forEach(t),rMo=r(GGe," \u2014 "),eG=n(GGe,"A",{href:!0});var gBt=s(eG);tMo=r(gBt,"VisionTextDualEncoderConfig"),gBt.forEach(t),aMo=r(GGe," (VisionTextDualEncoder model)"),GGe.forEach(t),nMo=i(L),Fu=n(L,"LI",{});var OGe=s(Fu);Ope=n(OGe,"STRONG",{});var hBt=s(Ope);sMo=r(hBt,"visual_bert"),hBt.forEach(t),lMo=r(OGe," \u2014 "),oG=n(OGe,"A",{href:!0});var uBt=s(oG);iMo=r(uBt,"VisualBertConfig"),uBt.forEach(t),dMo=r(OGe," (VisualBERT model)"),OGe.forEach(t),mMo=i(L),Tu=n(L,"LI",{});var VGe=s(Tu);Vpe=n(VGe,"STRONG",{});var pBt=s(Vpe);cMo=r(pBt,"vit"),pBt.forEach(t),fMo=r(VGe," \u2014 "),rG=n(VGe,"A",{href:!0});var _Bt=s(rG);gMo=r(_Bt,"ViTConfig"),_Bt.forEach(t),hMo=r(VGe," (ViT model)"),VGe.forEach(t),uMo=i(L),Mu=n(L,"LI",{});var XGe=s(Mu);Xpe=n(XGe,"STRONG",{});var bBt=s(Xpe);pMo=r(bBt,"vit_mae"),bBt.forEach(t),_Mo=r(XGe," \u2014 "),tG=n(XGe,"A",{href:!0});var vBt=s(tG);bMo=r(vBt,"ViTMAEConfig"),vBt.forEach(t),vMo=r(XGe," (ViTMAE model)"),XGe.forEach(t),FMo=i(L),Eu=n(L,"LI",{});var zGe=s(Eu);zpe=n(zGe,"STRONG",{});var FBt=s(zpe);TMo=r(FBt,"vit_msn"),FBt.forEach(t),MMo=r(zGe," \u2014 "),aG=n(zGe,"A",{href:!0});var TBt=s(aG);EMo=r(TBt,"ViTMSNConfig"),TBt.forEach(t),CMo=r(zGe," (ViTMSN model)"),zGe.forEach(t),wMo=i(L),Cu=n(L,"LI",{});var QGe=s(Cu);Qpe=n(QGe,"STRONG",{});var MBt=s(Qpe);AMo=r(MBt,"wav2vec2"),MBt.forEach(t),LMo=r(QGe," \u2014 "),nG=n(QGe,"A",{href:!0});var EBt=s(nG);yMo=r(EBt,"Wav2Vec2Config"),EBt.forEach(t),xMo=r(QGe," (Wav2Vec2 model)"),QGe.forEach(t),$Mo=i(L),wu=n(L,"LI",{});var WGe=s(wu);Wpe=n(WGe,"STRONG",{});var CBt=s(Wpe);kMo=r(CBt,"wav2vec2-conformer"),CBt.forEach(t),SMo=r(WGe," \u2014 "),sG=n(WGe,"A",{href:!0});var wBt=s(sG);RMo=r(wBt,"Wav2Vec2ConformerConfig"),wBt.forEach(t),PMo=r(WGe," (Wav2Vec2-Conformer model)"),WGe.forEach(t),BMo=i(L),Au=n(L,"LI",{});var UGe=s(Au);Upe=n(UGe,"STRONG",{});var ABt=s(Upe);IMo=r(ABt,"wavlm"),ABt.forEach(t),NMo=r(UGe," \u2014 "),lG=n(UGe,"A",{href:!0});var LBt=s(lG);qMo=r(LBt,"WavLMConfig"),LBt.forEach(t),jMo=r(UGe," (WavLM model)"),UGe.forEach(t),DMo=i(L),Lu=n(L,"LI",{});var HGe=s(Lu);Hpe=n(HGe,"STRONG",{});var yBt=s(Hpe);GMo=r(yBt,"whisper"),yBt.forEach(t),OMo=r(HGe," \u2014 "),iG=n(HGe,"A",{href:!0});var xBt=s(iG);VMo=r(xBt,"WhisperConfig"),xBt.forEach(t),XMo=r(HGe," (Whisper model)"),HGe.forEach(t),zMo=i(L),yu=n(L,"LI",{});var JGe=s(yu);Jpe=n(JGe,"STRONG",{});var $Bt=s(Jpe);QMo=r($Bt,"xclip"),$Bt.forEach(t),WMo=r(JGe," \u2014 "),dG=n(JGe,"A",{href:!0});var kBt=s(dG);UMo=r(kBt,"XCLIPConfig"),kBt.forEach(t),HMo=r(JGe," (X-CLIP model)"),JGe.forEach(t),JMo=i(L),xu=n(L,"LI",{});var YGe=s(xu);Ype=n(YGe,"STRONG",{});var SBt=s(Ype);YMo=r(SBt,"xglm"),SBt.forEach(t),ZMo=r(YGe," \u2014 "),mG=n(YGe,"A",{href:!0});var RBt=s(mG);KMo=r(RBt,"XGLMConfig"),RBt.forEach(t),eEo=r(YGe," (XGLM model)"),YGe.forEach(t),oEo=i(L),$u=n(L,"LI",{});var ZGe=s($u);Zpe=n(ZGe,"STRONG",{});var PBt=s(Zpe);rEo=r(PBt,"xlm"),PBt.forEach(t),tEo=r(ZGe," \u2014 "),cG=n(ZGe,"A",{href:!0});var BBt=s(cG);aEo=r(BBt,"XLMConfig"),BBt.forEach(t),nEo=r(ZGe," (XLM model)"),ZGe.forEach(t),sEo=i(L),ku=n(L,"LI",{});var KGe=s(ku);Kpe=n(KGe,"STRONG",{});var IBt=s(Kpe);lEo=r(IBt,"xlm-prophetnet"),IBt.forEach(t),iEo=r(KGe," \u2014 "),fG=n(KGe,"A",{href:!0});var NBt=s(fG);dEo=r(NBt,"XLMProphetNetConfig"),NBt.forEach(t),mEo=r(KGe," (XLM-ProphetNet model)"),KGe.forEach(t),cEo=i(L),Su=n(L,"LI",{});var eOe=s(Su);e_e=n(eOe,"STRONG",{});var qBt=s(e_e);fEo=r(qBt,"xlm-roberta"),qBt.forEach(t),gEo=r(eOe," \u2014 "),gG=n(eOe,"A",{href:!0});var jBt=s(gG);hEo=r(jBt,"XLMRobertaConfig"),jBt.forEach(t),uEo=r(eOe," (XLM-RoBERTa model)"),eOe.forEach(t),pEo=i(L),Ru=n(L,"LI",{});var oOe=s(Ru);o_e=n(oOe,"STRONG",{});var DBt=s(o_e);_Eo=r(DBt,"xlm-roberta-xl"),DBt.forEach(t),bEo=r(oOe," \u2014 "),hG=n(oOe,"A",{href:!0});var GBt=s(hG);vEo=r(GBt,"XLMRobertaXLConfig"),GBt.forEach(t),FEo=r(oOe," (XLM-RoBERTa-XL model)"),oOe.forEach(t),TEo=i(L),Pu=n(L,"LI",{});var rOe=s(Pu);r_e=n(rOe,"STRONG",{});var OBt=s(r_e);MEo=r(OBt,"xlnet"),OBt.forEach(t),EEo=r(rOe," \u2014 "),uG=n(rOe,"A",{href:!0});var VBt=s(uG);CEo=r(VBt,"XLNetConfig"),VBt.forEach(t),wEo=r(rOe," (XLNet model)"),rOe.forEach(t),AEo=i(L),Bu=n(L,"LI",{});var tOe=s(Bu);t_e=n(tOe,"STRONG",{});var XBt=s(t_e);LEo=r(XBt,"yolos"),XBt.forEach(t),yEo=r(tOe," \u2014 "),pG=n(tOe,"A",{href:!0});var zBt=s(pG);xEo=r(zBt,"YolosConfig"),zBt.forEach(t),$Eo=r(tOe," (YOLOS model)"),tOe.forEach(t),kEo=i(L),Iu=n(L,"LI",{});var aOe=s(Iu);a_e=n(aOe,"STRONG",{});var QBt=s(a_e);SEo=r(QBt,"yoso"),QBt.forEach(t),REo=r(aOe," \u2014 "),_G=n(aOe,"A",{href:!0});var WBt=s(_G);PEo=r(WBt,"YosoConfig"),WBt.forEach(t),BEo=r(aOe," (YOSO model)"),aOe.forEach(t),L.forEach(t),IEo=i(Ct),T(Nu.$$.fragment,Ct),Ct.forEach(t),NEo=i(Et),qu=n(Et,"DIV",{class:!0});var Udo=s(qu);T(Mk.$$.fragment,Udo),qEo=i(Udo),n_e=n(Udo,"P",{});var UBt=s(n_e);jEo=r(UBt,"Register a new configuration for this class."),UBt.forEach(t),Udo.forEach(t),Et.forEach(t),Blo=i(c),Id=n(c,"H2",{class:!0});var Hdo=s(Id);ju=n(Hdo,"A",{id:!0,class:!0,href:!0});var HBt=s(ju);s_e=n(HBt,"SPAN",{});var JBt=s(s_e);T(Ek.$$.fragment,JBt),JBt.forEach(t),HBt.forEach(t),DEo=i(Hdo),l_e=n(Hdo,"SPAN",{});var YBt=s(l_e);GEo=r(YBt,"AutoTokenizer"),YBt.forEach(t),Hdo.forEach(t),Ilo=i(c),Io=n(c,"DIV",{class:!0});var Gl=s(Io);T(Ck.$$.fragment,Gl),OEo=i(Gl),wk=n(Gl,"P",{});var Jdo=s(wk);VEo=r(Jdo,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),bG=n(Jdo,"A",{href:!0});var ZBt=s(bG);XEo=r(ZBt,"AutoTokenizer.from_pretrained()"),ZBt.forEach(t),zEo=r(Jdo," class method."),Jdo.forEach(t),QEo=i(Gl),Ak=n(Gl,"P",{});var Ydo=s(Ak);WEo=r(Ydo,"This class cannot be instantiated directly using "),i_e=n(Ydo,"CODE",{});var KBt=s(i_e);UEo=r(KBt,"__init__()"),KBt.forEach(t),HEo=r(Ydo," (throws an error)."),Ydo.forEach(t),JEo=i(Gl),Vr=n(Gl,"DIV",{class:!0});var Ol=s(Vr);T(Lk.$$.fragment,Ol),YEo=i(Ol),d_e=n(Ol,"P",{});var eIt=s(d_e);ZEo=r(eIt,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),eIt.forEach(t),KEo=i(Ol),dn=n(Ol,"P",{});var tx=s(dn);e4o=r(tx,"The tokenizer class to instantiate is selected based on the "),m_e=n(tx,"CODE",{});var oIt=s(m_e);o4o=r(oIt,"model_type"),oIt.forEach(t),r4o=r(tx,` property of the config object (either
passed as an argument or loaded from `),c_e=n(tx,"CODE",{});var rIt=s(c_e);t4o=r(rIt,"pretrained_model_name_or_path"),rIt.forEach(t),a4o=r(tx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f_e=n(tx,"CODE",{});var tIt=s(f_e);n4o=r(tIt,"pretrained_model_name_or_path"),tIt.forEach(t),s4o=r(tx,":"),tx.forEach(t),l4o=i(Ol),k=n(Ol,"UL",{});var S=s(k);Ts=n(S,"LI",{});var uN=s(Ts);g_e=n(uN,"STRONG",{});var aIt=s(g_e);i4o=r(aIt,"albert"),aIt.forEach(t),d4o=r(uN," \u2014 "),vG=n(uN,"A",{href:!0});var nIt=s(vG);m4o=r(nIt,"AlbertTokenizer"),nIt.forEach(t),c4o=r(uN," or "),FG=n(uN,"A",{href:!0});var sIt=s(FG);f4o=r(sIt,"AlbertTokenizerFast"),sIt.forEach(t),g4o=r(uN," (ALBERT model)"),uN.forEach(t),h4o=i(S),Ms=n(S,"LI",{});var pN=s(Ms);h_e=n(pN,"STRONG",{});var lIt=s(h_e);u4o=r(lIt,"bart"),lIt.forEach(t),p4o=r(pN," \u2014 "),TG=n(pN,"A",{href:!0});var iIt=s(TG);_4o=r(iIt,"BartTokenizer"),iIt.forEach(t),b4o=r(pN," or "),MG=n(pN,"A",{href:!0});var dIt=s(MG);v4o=r(dIt,"BartTokenizerFast"),dIt.forEach(t),F4o=r(pN," (BART model)"),pN.forEach(t),T4o=i(S),Es=n(S,"LI",{});var _N=s(Es);u_e=n(_N,"STRONG",{});var mIt=s(u_e);M4o=r(mIt,"barthez"),mIt.forEach(t),E4o=r(_N," \u2014 "),EG=n(_N,"A",{href:!0});var cIt=s(EG);C4o=r(cIt,"BarthezTokenizer"),cIt.forEach(t),w4o=r(_N," or "),CG=n(_N,"A",{href:!0});var fIt=s(CG);A4o=r(fIt,"BarthezTokenizerFast"),fIt.forEach(t),L4o=r(_N," (BARThez model)"),_N.forEach(t),y4o=i(S),Du=n(S,"LI",{});var nOe=s(Du);p_e=n(nOe,"STRONG",{});var gIt=s(p_e);x4o=r(gIt,"bartpho"),gIt.forEach(t),$4o=r(nOe," \u2014 "),wG=n(nOe,"A",{href:!0});var hIt=s(wG);k4o=r(hIt,"BartphoTokenizer"),hIt.forEach(t),S4o=r(nOe," (BARTpho model)"),nOe.forEach(t),R4o=i(S),Cs=n(S,"LI",{});var bN=s(Cs);__e=n(bN,"STRONG",{});var uIt=s(__e);P4o=r(uIt,"bert"),uIt.forEach(t),B4o=r(bN," \u2014 "),AG=n(bN,"A",{href:!0});var pIt=s(AG);I4o=r(pIt,"BertTokenizer"),pIt.forEach(t),N4o=r(bN," or "),LG=n(bN,"A",{href:!0});var _It=s(LG);q4o=r(_It,"BertTokenizerFast"),_It.forEach(t),j4o=r(bN," (BERT model)"),bN.forEach(t),D4o=i(S),Gu=n(S,"LI",{});var sOe=s(Gu);b_e=n(sOe,"STRONG",{});var bIt=s(b_e);G4o=r(bIt,"bert-generation"),bIt.forEach(t),O4o=r(sOe," \u2014 "),yG=n(sOe,"A",{href:!0});var vIt=s(yG);V4o=r(vIt,"BertGenerationTokenizer"),vIt.forEach(t),X4o=r(sOe," (Bert Generation model)"),sOe.forEach(t),z4o=i(S),Ou=n(S,"LI",{});var lOe=s(Ou);v_e=n(lOe,"STRONG",{});var FIt=s(v_e);Q4o=r(FIt,"bert-japanese"),FIt.forEach(t),W4o=r(lOe," \u2014 "),xG=n(lOe,"A",{href:!0});var TIt=s(xG);U4o=r(TIt,"BertJapaneseTokenizer"),TIt.forEach(t),H4o=r(lOe," (BertJapanese model)"),lOe.forEach(t),J4o=i(S),Vu=n(S,"LI",{});var iOe=s(Vu);F_e=n(iOe,"STRONG",{});var MIt=s(F_e);Y4o=r(MIt,"bertweet"),MIt.forEach(t),Z4o=r(iOe," \u2014 "),$G=n(iOe,"A",{href:!0});var EIt=s($G);K4o=r(EIt,"BertweetTokenizer"),EIt.forEach(t),eCo=r(iOe," (BERTweet model)"),iOe.forEach(t),oCo=i(S),ws=n(S,"LI",{});var vN=s(ws);T_e=n(vN,"STRONG",{});var CIt=s(T_e);rCo=r(CIt,"big_bird"),CIt.forEach(t),tCo=r(vN," \u2014 "),kG=n(vN,"A",{href:!0});var wIt=s(kG);aCo=r(wIt,"BigBirdTokenizer"),wIt.forEach(t),nCo=r(vN," or "),SG=n(vN,"A",{href:!0});var AIt=s(SG);sCo=r(AIt,"BigBirdTokenizerFast"),AIt.forEach(t),lCo=r(vN," (BigBird model)"),vN.forEach(t),iCo=i(S),As=n(S,"LI",{});var FN=s(As);M_e=n(FN,"STRONG",{});var LIt=s(M_e);dCo=r(LIt,"bigbird_pegasus"),LIt.forEach(t),mCo=r(FN," \u2014 "),RG=n(FN,"A",{href:!0});var yIt=s(RG);cCo=r(yIt,"PegasusTokenizer"),yIt.forEach(t),fCo=r(FN," or "),PG=n(FN,"A",{href:!0});var xIt=s(PG);gCo=r(xIt,"PegasusTokenizerFast"),xIt.forEach(t),hCo=r(FN," (BigBird-Pegasus model)"),FN.forEach(t),uCo=i(S),Ls=n(S,"LI",{});var TN=s(Ls);E_e=n(TN,"STRONG",{});var $It=s(E_e);pCo=r($It,"blenderbot"),$It.forEach(t),_Co=r(TN," \u2014 "),BG=n(TN,"A",{href:!0});var kIt=s(BG);bCo=r(kIt,"BlenderbotTokenizer"),kIt.forEach(t),vCo=r(TN," or "),IG=n(TN,"A",{href:!0});var SIt=s(IG);FCo=r(SIt,"BlenderbotTokenizerFast"),SIt.forEach(t),TCo=r(TN," (Blenderbot model)"),TN.forEach(t),MCo=i(S),Xu=n(S,"LI",{});var dOe=s(Xu);C_e=n(dOe,"STRONG",{});var RIt=s(C_e);ECo=r(RIt,"blenderbot-small"),RIt.forEach(t),CCo=r(dOe," \u2014 "),NG=n(dOe,"A",{href:!0});var PIt=s(NG);wCo=r(PIt,"BlenderbotSmallTokenizer"),PIt.forEach(t),ACo=r(dOe," (BlenderbotSmall model)"),dOe.forEach(t),LCo=i(S),zu=n(S,"LI",{});var mOe=s(zu);w_e=n(mOe,"STRONG",{});var BIt=s(w_e);yCo=r(BIt,"bloom"),BIt.forEach(t),xCo=r(mOe," \u2014 "),qG=n(mOe,"A",{href:!0});var IIt=s(qG);$Co=r(IIt,"BloomTokenizerFast"),IIt.forEach(t),kCo=r(mOe," (BLOOM model)"),mOe.forEach(t),SCo=i(S),Qu=n(S,"LI",{});var cOe=s(Qu);A_e=n(cOe,"STRONG",{});var NIt=s(A_e);RCo=r(NIt,"byt5"),NIt.forEach(t),PCo=r(cOe," \u2014 "),jG=n(cOe,"A",{href:!0});var qIt=s(jG);BCo=r(qIt,"ByT5Tokenizer"),qIt.forEach(t),ICo=r(cOe," (ByT5 model)"),cOe.forEach(t),NCo=i(S),ys=n(S,"LI",{});var MN=s(ys);L_e=n(MN,"STRONG",{});var jIt=s(L_e);qCo=r(jIt,"camembert"),jIt.forEach(t),jCo=r(MN," \u2014 "),DG=n(MN,"A",{href:!0});var DIt=s(DG);DCo=r(DIt,"CamembertTokenizer"),DIt.forEach(t),GCo=r(MN," or "),GG=n(MN,"A",{href:!0});var GIt=s(GG);OCo=r(GIt,"CamembertTokenizerFast"),GIt.forEach(t),VCo=r(MN," (CamemBERT model)"),MN.forEach(t),XCo=i(S),Wu=n(S,"LI",{});var fOe=s(Wu);y_e=n(fOe,"STRONG",{});var OIt=s(y_e);zCo=r(OIt,"canine"),OIt.forEach(t),QCo=r(fOe," \u2014 "),OG=n(fOe,"A",{href:!0});var VIt=s(OG);WCo=r(VIt,"CanineTokenizer"),VIt.forEach(t),UCo=r(fOe," (CANINE model)"),fOe.forEach(t),HCo=i(S),xs=n(S,"LI",{});var EN=s(xs);x_e=n(EN,"STRONG",{});var XIt=s(x_e);JCo=r(XIt,"clip"),XIt.forEach(t),YCo=r(EN," \u2014 "),VG=n(EN,"A",{href:!0});var zIt=s(VG);ZCo=r(zIt,"CLIPTokenizer"),zIt.forEach(t),KCo=r(EN," or "),XG=n(EN,"A",{href:!0});var QIt=s(XG);e3o=r(QIt,"CLIPTokenizerFast"),QIt.forEach(t),o3o=r(EN," (CLIP model)"),EN.forEach(t),r3o=i(S),$s=n(S,"LI",{});var CN=s($s);$_e=n(CN,"STRONG",{});var WIt=s($_e);t3o=r(WIt,"clipseg"),WIt.forEach(t),a3o=r(CN," \u2014 "),zG=n(CN,"A",{href:!0});var UIt=s(zG);n3o=r(UIt,"CLIPTokenizer"),UIt.forEach(t),s3o=r(CN," or "),QG=n(CN,"A",{href:!0});var HIt=s(QG);l3o=r(HIt,"CLIPTokenizerFast"),HIt.forEach(t),i3o=r(CN," (CLIPSeg model)"),CN.forEach(t),d3o=i(S),ks=n(S,"LI",{});var wN=s(ks);k_e=n(wN,"STRONG",{});var JIt=s(k_e);m3o=r(JIt,"codegen"),JIt.forEach(t),c3o=r(wN," \u2014 "),WG=n(wN,"A",{href:!0});var YIt=s(WG);f3o=r(YIt,"CodeGenTokenizer"),YIt.forEach(t),g3o=r(wN," or "),UG=n(wN,"A",{href:!0});var ZIt=s(UG);h3o=r(ZIt,"CodeGenTokenizerFast"),ZIt.forEach(t),u3o=r(wN," (CodeGen model)"),wN.forEach(t),p3o=i(S),Ss=n(S,"LI",{});var AN=s(Ss);S_e=n(AN,"STRONG",{});var KIt=s(S_e);_3o=r(KIt,"convbert"),KIt.forEach(t),b3o=r(AN," \u2014 "),HG=n(AN,"A",{href:!0});var eNt=s(HG);v3o=r(eNt,"ConvBertTokenizer"),eNt.forEach(t),F3o=r(AN," or "),JG=n(AN,"A",{href:!0});var oNt=s(JG);T3o=r(oNt,"ConvBertTokenizerFast"),oNt.forEach(t),M3o=r(AN," (ConvBERT model)"),AN.forEach(t),E3o=i(S),Rs=n(S,"LI",{});var LN=s(Rs);R_e=n(LN,"STRONG",{});var rNt=s(R_e);C3o=r(rNt,"cpm"),rNt.forEach(t),w3o=r(LN," \u2014 "),YG=n(LN,"A",{href:!0});var tNt=s(YG);A3o=r(tNt,"CpmTokenizer"),tNt.forEach(t),L3o=r(LN," or "),ZG=n(LN,"A",{href:!0});var aNt=s(ZG);y3o=r(aNt,"CpmTokenizerFast"),aNt.forEach(t),x3o=r(LN," (CPM model)"),LN.forEach(t),$3o=i(S),Uu=n(S,"LI",{});var gOe=s(Uu);P_e=n(gOe,"STRONG",{});var nNt=s(P_e);k3o=r(nNt,"ctrl"),nNt.forEach(t),S3o=r(gOe," \u2014 "),KG=n(gOe,"A",{href:!0});var sNt=s(KG);R3o=r(sNt,"CTRLTokenizer"),sNt.forEach(t),P3o=r(gOe," (CTRL model)"),gOe.forEach(t),B3o=i(S),Ps=n(S,"LI",{});var yN=s(Ps);B_e=n(yN,"STRONG",{});var lNt=s(B_e);I3o=r(lNt,"data2vec-text"),lNt.forEach(t),N3o=r(yN," \u2014 "),eO=n(yN,"A",{href:!0});var iNt=s(eO);q3o=r(iNt,"RobertaTokenizer"),iNt.forEach(t),j3o=r(yN," or "),oO=n(yN,"A",{href:!0});var dNt=s(oO);D3o=r(dNt,"RobertaTokenizerFast"),dNt.forEach(t),G3o=r(yN," (Data2VecText model)"),yN.forEach(t),O3o=i(S),Bs=n(S,"LI",{});var xN=s(Bs);I_e=n(xN,"STRONG",{});var mNt=s(I_e);V3o=r(mNt,"deberta"),mNt.forEach(t),X3o=r(xN," \u2014 "),rO=n(xN,"A",{href:!0});var cNt=s(rO);z3o=r(cNt,"DebertaTokenizer"),cNt.forEach(t),Q3o=r(xN," or "),tO=n(xN,"A",{href:!0});var fNt=s(tO);W3o=r(fNt,"DebertaTokenizerFast"),fNt.forEach(t),U3o=r(xN," (DeBERTa model)"),xN.forEach(t),H3o=i(S),Is=n(S,"LI",{});var $N=s(Is);N_e=n($N,"STRONG",{});var gNt=s(N_e);J3o=r(gNt,"deberta-v2"),gNt.forEach(t),Y3o=r($N," \u2014 "),aO=n($N,"A",{href:!0});var hNt=s(aO);Z3o=r(hNt,"DebertaV2Tokenizer"),hNt.forEach(t),K3o=r($N," or "),nO=n($N,"A",{href:!0});var uNt=s(nO);e5o=r(uNt,"DebertaV2TokenizerFast"),uNt.forEach(t),o5o=r($N," (DeBERTa-v2 model)"),$N.forEach(t),r5o=i(S),Ns=n(S,"LI",{});var kN=s(Ns);q_e=n(kN,"STRONG",{});var pNt=s(q_e);t5o=r(pNt,"distilbert"),pNt.forEach(t),a5o=r(kN," \u2014 "),sO=n(kN,"A",{href:!0});var _Nt=s(sO);n5o=r(_Nt,"DistilBertTokenizer"),_Nt.forEach(t),s5o=r(kN," or "),lO=n(kN,"A",{href:!0});var bNt=s(lO);l5o=r(bNt,"DistilBertTokenizerFast"),bNt.forEach(t),i5o=r(kN," (DistilBERT model)"),kN.forEach(t),d5o=i(S),qs=n(S,"LI",{});var SN=s(qs);j_e=n(SN,"STRONG",{});var vNt=s(j_e);m5o=r(vNt,"dpr"),vNt.forEach(t),c5o=r(SN," \u2014 "),iO=n(SN,"A",{href:!0});var FNt=s(iO);f5o=r(FNt,"DPRQuestionEncoderTokenizer"),FNt.forEach(t),g5o=r(SN," or "),dO=n(SN,"A",{href:!0});var TNt=s(dO);h5o=r(TNt,"DPRQuestionEncoderTokenizerFast"),TNt.forEach(t),u5o=r(SN," (DPR model)"),SN.forEach(t),p5o=i(S),js=n(S,"LI",{});var RN=s(js);D_e=n(RN,"STRONG",{});var MNt=s(D_e);_5o=r(MNt,"electra"),MNt.forEach(t),b5o=r(RN," \u2014 "),mO=n(RN,"A",{href:!0});var ENt=s(mO);v5o=r(ENt,"ElectraTokenizer"),ENt.forEach(t),F5o=r(RN," or "),cO=n(RN,"A",{href:!0});var CNt=s(cO);T5o=r(CNt,"ElectraTokenizerFast"),CNt.forEach(t),M5o=r(RN," (ELECTRA model)"),RN.forEach(t),E5o=i(S),Ds=n(S,"LI",{});var PN=s(Ds);G_e=n(PN,"STRONG",{});var wNt=s(G_e);C5o=r(wNt,"ernie"),wNt.forEach(t),w5o=r(PN," \u2014 "),fO=n(PN,"A",{href:!0});var ANt=s(fO);A5o=r(ANt,"BertTokenizer"),ANt.forEach(t),L5o=r(PN," or "),gO=n(PN,"A",{href:!0});var LNt=s(gO);y5o=r(LNt,"BertTokenizerFast"),LNt.forEach(t),x5o=r(PN," (ERNIE model)"),PN.forEach(t),$5o=i(S),Hu=n(S,"LI",{});var hOe=s(Hu);O_e=n(hOe,"STRONG",{});var yNt=s(O_e);k5o=r(yNt,"esm"),yNt.forEach(t),S5o=r(hOe," \u2014 "),hO=n(hOe,"A",{href:!0});var xNt=s(hO);R5o=r(xNt,"EsmTokenizer"),xNt.forEach(t),P5o=r(hOe," (ESM model)"),hOe.forEach(t),B5o=i(S),Ju=n(S,"LI",{});var uOe=s(Ju);V_e=n(uOe,"STRONG",{});var $Nt=s(V_e);I5o=r($Nt,"flaubert"),$Nt.forEach(t),N5o=r(uOe," \u2014 "),uO=n(uOe,"A",{href:!0});var kNt=s(uO);q5o=r(kNt,"FlaubertTokenizer"),kNt.forEach(t),j5o=r(uOe," (FlauBERT model)"),uOe.forEach(t),D5o=i(S),Gs=n(S,"LI",{});var BN=s(Gs);X_e=n(BN,"STRONG",{});var SNt=s(X_e);G5o=r(SNt,"fnet"),SNt.forEach(t),O5o=r(BN," \u2014 "),pO=n(BN,"A",{href:!0});var RNt=s(pO);V5o=r(RNt,"FNetTokenizer"),RNt.forEach(t),X5o=r(BN," or "),_O=n(BN,"A",{href:!0});var PNt=s(_O);z5o=r(PNt,"FNetTokenizerFast"),PNt.forEach(t),Q5o=r(BN," (FNet model)"),BN.forEach(t),W5o=i(S),Yu=n(S,"LI",{});var pOe=s(Yu);z_e=n(pOe,"STRONG",{});var BNt=s(z_e);U5o=r(BNt,"fsmt"),BNt.forEach(t),H5o=r(pOe," \u2014 "),bO=n(pOe,"A",{href:!0});var INt=s(bO);J5o=r(INt,"FSMTTokenizer"),INt.forEach(t),Y5o=r(pOe," (FairSeq Machine-Translation model)"),pOe.forEach(t),Z5o=i(S),Os=n(S,"LI",{});var IN=s(Os);Q_e=n(IN,"STRONG",{});var NNt=s(Q_e);K5o=r(NNt,"funnel"),NNt.forEach(t),e0o=r(IN," \u2014 "),vO=n(IN,"A",{href:!0});var qNt=s(vO);o0o=r(qNt,"FunnelTokenizer"),qNt.forEach(t),r0o=r(IN," or "),FO=n(IN,"A",{href:!0});var jNt=s(FO);t0o=r(jNt,"FunnelTokenizerFast"),jNt.forEach(t),a0o=r(IN," (Funnel Transformer model)"),IN.forEach(t),n0o=i(S),Vs=n(S,"LI",{});var NN=s(Vs);W_e=n(NN,"STRONG",{});var DNt=s(W_e);s0o=r(DNt,"gpt2"),DNt.forEach(t),l0o=r(NN," \u2014 "),TO=n(NN,"A",{href:!0});var GNt=s(TO);i0o=r(GNt,"GPT2Tokenizer"),GNt.forEach(t),d0o=r(NN," or "),MO=n(NN,"A",{href:!0});var ONt=s(MO);m0o=r(ONt,"GPT2TokenizerFast"),ONt.forEach(t),c0o=r(NN," (OpenAI GPT-2 model)"),NN.forEach(t),f0o=i(S),Xs=n(S,"LI",{});var qN=s(Xs);U_e=n(qN,"STRONG",{});var VNt=s(U_e);g0o=r(VNt,"gpt_neo"),VNt.forEach(t),h0o=r(qN," \u2014 "),EO=n(qN,"A",{href:!0});var XNt=s(EO);u0o=r(XNt,"GPT2Tokenizer"),XNt.forEach(t),p0o=r(qN," or "),CO=n(qN,"A",{href:!0});var zNt=s(CO);_0o=r(zNt,"GPT2TokenizerFast"),zNt.forEach(t),b0o=r(qN," (GPT Neo model)"),qN.forEach(t),v0o=i(S),Zu=n(S,"LI",{});var _Oe=s(Zu);H_e=n(_Oe,"STRONG",{});var QNt=s(H_e);F0o=r(QNt,"gpt_neox"),QNt.forEach(t),T0o=r(_Oe," \u2014 "),wO=n(_Oe,"A",{href:!0});var WNt=s(wO);M0o=r(WNt,"GPTNeoXTokenizerFast"),WNt.forEach(t),E0o=r(_Oe," (GPT NeoX model)"),_Oe.forEach(t),C0o=i(S),Ku=n(S,"LI",{});var bOe=s(Ku);J_e=n(bOe,"STRONG",{});var UNt=s(J_e);w0o=r(UNt,"gpt_neox_japanese"),UNt.forEach(t),A0o=r(bOe," \u2014 "),AO=n(bOe,"A",{href:!0});var HNt=s(AO);L0o=r(HNt,"GPTNeoXJapaneseTokenizer"),HNt.forEach(t),y0o=r(bOe," (GPT NeoX Japanese model)"),bOe.forEach(t),x0o=i(S),zs=n(S,"LI",{});var jN=s(zs);Y_e=n(jN,"STRONG",{});var JNt=s(Y_e);$0o=r(JNt,"gptj"),JNt.forEach(t),k0o=r(jN," \u2014 "),LO=n(jN,"A",{href:!0});var YNt=s(LO);S0o=r(YNt,"GPT2Tokenizer"),YNt.forEach(t),R0o=r(jN," or "),yO=n(jN,"A",{href:!0});var ZNt=s(yO);P0o=r(ZNt,"GPT2TokenizerFast"),ZNt.forEach(t),B0o=r(jN," (GPT-J model)"),jN.forEach(t),I0o=i(S),Qs=n(S,"LI",{});var DN=s(Qs);Z_e=n(DN,"STRONG",{});var KNt=s(Z_e);N0o=r(KNt,"groupvit"),KNt.forEach(t),q0o=r(DN," \u2014 "),xO=n(DN,"A",{href:!0});var eqt=s(xO);j0o=r(eqt,"CLIPTokenizer"),eqt.forEach(t),D0o=r(DN," or "),$O=n(DN,"A",{href:!0});var oqt=s($O);G0o=r(oqt,"CLIPTokenizerFast"),oqt.forEach(t),O0o=r(DN," (GroupViT model)"),DN.forEach(t),V0o=i(S),Ws=n(S,"LI",{});var GN=s(Ws);K_e=n(GN,"STRONG",{});var rqt=s(K_e);X0o=r(rqt,"herbert"),rqt.forEach(t),z0o=r(GN," \u2014 "),kO=n(GN,"A",{href:!0});var tqt=s(kO);Q0o=r(tqt,"HerbertTokenizer"),tqt.forEach(t),W0o=r(GN," or "),SO=n(GN,"A",{href:!0});var aqt=s(SO);U0o=r(aqt,"HerbertTokenizerFast"),aqt.forEach(t),H0o=r(GN," (HerBERT model)"),GN.forEach(t),J0o=i(S),ep=n(S,"LI",{});var vOe=s(ep);e1e=n(vOe,"STRONG",{});var nqt=s(e1e);Y0o=r(nqt,"hubert"),nqt.forEach(t),Z0o=r(vOe," \u2014 "),RO=n(vOe,"A",{href:!0});var sqt=s(RO);K0o=r(sqt,"Wav2Vec2CTCTokenizer"),sqt.forEach(t),ewo=r(vOe," (Hubert model)"),vOe.forEach(t),owo=i(S),Us=n(S,"LI",{});var ON=s(Us);o1e=n(ON,"STRONG",{});var lqt=s(o1e);rwo=r(lqt,"ibert"),lqt.forEach(t),two=r(ON," \u2014 "),PO=n(ON,"A",{href:!0});var iqt=s(PO);awo=r(iqt,"RobertaTokenizer"),iqt.forEach(t),nwo=r(ON," or "),BO=n(ON,"A",{href:!0});var dqt=s(BO);swo=r(dqt,"RobertaTokenizerFast"),dqt.forEach(t),lwo=r(ON," (I-BERT model)"),ON.forEach(t),iwo=i(S),op=n(S,"LI",{});var FOe=s(op);r1e=n(FOe,"STRONG",{});var mqt=s(r1e);dwo=r(mqt,"jukebox"),mqt.forEach(t),mwo=r(FOe," \u2014 "),IO=n(FOe,"A",{href:!0});var cqt=s(IO);cwo=r(cqt,"JukeboxTokenizer"),cqt.forEach(t),fwo=r(FOe," (Jukebox model)"),FOe.forEach(t),gwo=i(S),Hs=n(S,"LI",{});var VN=s(Hs);t1e=n(VN,"STRONG",{});var fqt=s(t1e);hwo=r(fqt,"layoutlm"),fqt.forEach(t),uwo=r(VN," \u2014 "),NO=n(VN,"A",{href:!0});var gqt=s(NO);pwo=r(gqt,"LayoutLMTokenizer"),gqt.forEach(t),_wo=r(VN," or "),qO=n(VN,"A",{href:!0});var hqt=s(qO);bwo=r(hqt,"LayoutLMTokenizerFast"),hqt.forEach(t),vwo=r(VN," (LayoutLM model)"),VN.forEach(t),Fwo=i(S),Js=n(S,"LI",{});var XN=s(Js);a1e=n(XN,"STRONG",{});var uqt=s(a1e);Two=r(uqt,"layoutlmv2"),uqt.forEach(t),Mwo=r(XN," \u2014 "),jO=n(XN,"A",{href:!0});var pqt=s(jO);Ewo=r(pqt,"LayoutLMv2Tokenizer"),pqt.forEach(t),Cwo=r(XN," or "),DO=n(XN,"A",{href:!0});var _qt=s(DO);wwo=r(_qt,"LayoutLMv2TokenizerFast"),_qt.forEach(t),Awo=r(XN," (LayoutLMv2 model)"),XN.forEach(t),Lwo=i(S),Ys=n(S,"LI",{});var zN=s(Ys);n1e=n(zN,"STRONG",{});var bqt=s(n1e);ywo=r(bqt,"layoutlmv3"),bqt.forEach(t),xwo=r(zN," \u2014 "),GO=n(zN,"A",{href:!0});var vqt=s(GO);$wo=r(vqt,"LayoutLMv3Tokenizer"),vqt.forEach(t),kwo=r(zN," or "),OO=n(zN,"A",{href:!0});var Fqt=s(OO);Swo=r(Fqt,"LayoutLMv3TokenizerFast"),Fqt.forEach(t),Rwo=r(zN," (LayoutLMv3 model)"),zN.forEach(t),Pwo=i(S),Zs=n(S,"LI",{});var QN=s(Zs);s1e=n(QN,"STRONG",{});var Tqt=s(s1e);Bwo=r(Tqt,"layoutxlm"),Tqt.forEach(t),Iwo=r(QN," \u2014 "),VO=n(QN,"A",{href:!0});var Mqt=s(VO);Nwo=r(Mqt,"LayoutXLMTokenizer"),Mqt.forEach(t),qwo=r(QN," or "),XO=n(QN,"A",{href:!0});var Eqt=s(XO);jwo=r(Eqt,"LayoutXLMTokenizerFast"),Eqt.forEach(t),Dwo=r(QN," (LayoutXLM model)"),QN.forEach(t),Gwo=i(S),Ks=n(S,"LI",{});var WN=s(Ks);l1e=n(WN,"STRONG",{});var Cqt=s(l1e);Owo=r(Cqt,"led"),Cqt.forEach(t),Vwo=r(WN," \u2014 "),zO=n(WN,"A",{href:!0});var wqt=s(zO);Xwo=r(wqt,"LEDTokenizer"),wqt.forEach(t),zwo=r(WN," or "),QO=n(WN,"A",{href:!0});var Aqt=s(QO);Qwo=r(Aqt,"LEDTokenizerFast"),Aqt.forEach(t),Wwo=r(WN," (LED model)"),WN.forEach(t),Uwo=i(S),el=n(S,"LI",{});var UN=s(el);i1e=n(UN,"STRONG",{});var Lqt=s(i1e);Hwo=r(Lqt,"lilt"),Lqt.forEach(t),Jwo=r(UN," \u2014 "),WO=n(UN,"A",{href:!0});var yqt=s(WO);Ywo=r(yqt,"LayoutLMv3Tokenizer"),yqt.forEach(t),Zwo=r(UN," or "),UO=n(UN,"A",{href:!0});var xqt=s(UO);Kwo=r(xqt,"LayoutLMv3TokenizerFast"),xqt.forEach(t),eAo=r(UN," (LiLT model)"),UN.forEach(t),oAo=i(S),ol=n(S,"LI",{});var HN=s(ol);d1e=n(HN,"STRONG",{});var $qt=s(d1e);rAo=r($qt,"longformer"),$qt.forEach(t),tAo=r(HN," \u2014 "),HO=n(HN,"A",{href:!0});var kqt=s(HO);aAo=r(kqt,"LongformerTokenizer"),kqt.forEach(t),nAo=r(HN," or "),JO=n(HN,"A",{href:!0});var Sqt=s(JO);sAo=r(Sqt,"LongformerTokenizerFast"),Sqt.forEach(t),lAo=r(HN," (Longformer model)"),HN.forEach(t),iAo=i(S),rl=n(S,"LI",{});var JN=s(rl);m1e=n(JN,"STRONG",{});var Rqt=s(m1e);dAo=r(Rqt,"longt5"),Rqt.forEach(t),mAo=r(JN," \u2014 "),YO=n(JN,"A",{href:!0});var Pqt=s(YO);cAo=r(Pqt,"T5Tokenizer"),Pqt.forEach(t),fAo=r(JN," or "),ZO=n(JN,"A",{href:!0});var Bqt=s(ZO);gAo=r(Bqt,"T5TokenizerFast"),Bqt.forEach(t),hAo=r(JN," (LongT5 model)"),JN.forEach(t),uAo=i(S),rp=n(S,"LI",{});var TOe=s(rp);c1e=n(TOe,"STRONG",{});var Iqt=s(c1e);pAo=r(Iqt,"luke"),Iqt.forEach(t),_Ao=r(TOe," \u2014 "),KO=n(TOe,"A",{href:!0});var Nqt=s(KO);bAo=r(Nqt,"LukeTokenizer"),Nqt.forEach(t),vAo=r(TOe," (LUKE model)"),TOe.forEach(t),FAo=i(S),tl=n(S,"LI",{});var YN=s(tl);f1e=n(YN,"STRONG",{});var qqt=s(f1e);TAo=r(qqt,"lxmert"),qqt.forEach(t),MAo=r(YN," \u2014 "),eV=n(YN,"A",{href:!0});var jqt=s(eV);EAo=r(jqt,"LxmertTokenizer"),jqt.forEach(t),CAo=r(YN," or "),oV=n(YN,"A",{href:!0});var Dqt=s(oV);wAo=r(Dqt,"LxmertTokenizerFast"),Dqt.forEach(t),AAo=r(YN," (LXMERT model)"),YN.forEach(t),LAo=i(S),tp=n(S,"LI",{});var MOe=s(tp);g1e=n(MOe,"STRONG",{});var Gqt=s(g1e);yAo=r(Gqt,"m2m_100"),Gqt.forEach(t),xAo=r(MOe," \u2014 "),rV=n(MOe,"A",{href:!0});var Oqt=s(rV);$Ao=r(Oqt,"M2M100Tokenizer"),Oqt.forEach(t),kAo=r(MOe," (M2M100 model)"),MOe.forEach(t),SAo=i(S),ap=n(S,"LI",{});var EOe=s(ap);h1e=n(EOe,"STRONG",{});var Vqt=s(h1e);RAo=r(Vqt,"marian"),Vqt.forEach(t),PAo=r(EOe," \u2014 "),tV=n(EOe,"A",{href:!0});var Xqt=s(tV);BAo=r(Xqt,"MarianTokenizer"),Xqt.forEach(t),IAo=r(EOe," (Marian model)"),EOe.forEach(t),NAo=i(S),al=n(S,"LI",{});var ZN=s(al);u1e=n(ZN,"STRONG",{});var zqt=s(u1e);qAo=r(zqt,"mbart"),zqt.forEach(t),jAo=r(ZN," \u2014 "),aV=n(ZN,"A",{href:!0});var Qqt=s(aV);DAo=r(Qqt,"MBartTokenizer"),Qqt.forEach(t),GAo=r(ZN," or "),nV=n(ZN,"A",{href:!0});var Wqt=s(nV);OAo=r(Wqt,"MBartTokenizerFast"),Wqt.forEach(t),VAo=r(ZN," (mBART model)"),ZN.forEach(t),XAo=i(S),nl=n(S,"LI",{});var KN=s(nl);p1e=n(KN,"STRONG",{});var Uqt=s(p1e);zAo=r(Uqt,"mbart50"),Uqt.forEach(t),QAo=r(KN," \u2014 "),sV=n(KN,"A",{href:!0});var Hqt=s(sV);WAo=r(Hqt,"MBart50Tokenizer"),Hqt.forEach(t),UAo=r(KN," or "),lV=n(KN,"A",{href:!0});var Jqt=s(lV);HAo=r(Jqt,"MBart50TokenizerFast"),Jqt.forEach(t),JAo=r(KN," (mBART-50 model)"),KN.forEach(t),YAo=i(S),sl=n(S,"LI",{});var eq=s(sl);_1e=n(eq,"STRONG",{});var Yqt=s(_1e);ZAo=r(Yqt,"megatron-bert"),Yqt.forEach(t),KAo=r(eq," \u2014 "),iV=n(eq,"A",{href:!0});var Zqt=s(iV);e6o=r(Zqt,"BertTokenizer"),Zqt.forEach(t),o6o=r(eq," or "),dV=n(eq,"A",{href:!0});var Kqt=s(dV);r6o=r(Kqt,"BertTokenizerFast"),Kqt.forEach(t),t6o=r(eq," (Megatron-BERT model)"),eq.forEach(t),a6o=i(S),np=n(S,"LI",{});var COe=s(np);b1e=n(COe,"STRONG",{});var ejt=s(b1e);n6o=r(ejt,"mluke"),ejt.forEach(t),s6o=r(COe," \u2014 "),mV=n(COe,"A",{href:!0});var ojt=s(mV);l6o=r(ojt,"MLukeTokenizer"),ojt.forEach(t),i6o=r(COe," (mLUKE model)"),COe.forEach(t),d6o=i(S),ll=n(S,"LI",{});var oq=s(ll);v1e=n(oq,"STRONG",{});var rjt=s(v1e);m6o=r(rjt,"mobilebert"),rjt.forEach(t),c6o=r(oq," \u2014 "),cV=n(oq,"A",{href:!0});var tjt=s(cV);f6o=r(tjt,"MobileBertTokenizer"),tjt.forEach(t),g6o=r(oq," or "),fV=n(oq,"A",{href:!0});var ajt=s(fV);h6o=r(ajt,"MobileBertTokenizerFast"),ajt.forEach(t),u6o=r(oq," (MobileBERT model)"),oq.forEach(t),p6o=i(S),il=n(S,"LI",{});var rq=s(il);F1e=n(rq,"STRONG",{});var njt=s(F1e);_6o=r(njt,"mpnet"),njt.forEach(t),b6o=r(rq," \u2014 "),gV=n(rq,"A",{href:!0});var sjt=s(gV);v6o=r(sjt,"MPNetTokenizer"),sjt.forEach(t),F6o=r(rq," or "),hV=n(rq,"A",{href:!0});var ljt=s(hV);T6o=r(ljt,"MPNetTokenizerFast"),ljt.forEach(t),M6o=r(rq," (MPNet model)"),rq.forEach(t),E6o=i(S),dl=n(S,"LI",{});var tq=s(dl);T1e=n(tq,"STRONG",{});var ijt=s(T1e);C6o=r(ijt,"mt5"),ijt.forEach(t),w6o=r(tq," \u2014 "),uV=n(tq,"A",{href:!0});var djt=s(uV);A6o=r(djt,"MT5Tokenizer"),djt.forEach(t),L6o=r(tq," or "),pV=n(tq,"A",{href:!0});var mjt=s(pV);y6o=r(mjt,"MT5TokenizerFast"),mjt.forEach(t),x6o=r(tq," (MT5 model)"),tq.forEach(t),$6o=i(S),ml=n(S,"LI",{});var aq=s(ml);M1e=n(aq,"STRONG",{});var cjt=s(M1e);k6o=r(cjt,"mvp"),cjt.forEach(t),S6o=r(aq," \u2014 "),_V=n(aq,"A",{href:!0});var fjt=s(_V);R6o=r(fjt,"MvpTokenizer"),fjt.forEach(t),P6o=r(aq," or "),bV=n(aq,"A",{href:!0});var gjt=s(bV);B6o=r(gjt,"MvpTokenizerFast"),gjt.forEach(t),I6o=r(aq," (MVP model)"),aq.forEach(t),N6o=i(S),cl=n(S,"LI",{});var nq=s(cl);E1e=n(nq,"STRONG",{});var hjt=s(E1e);q6o=r(hjt,"nezha"),hjt.forEach(t),j6o=r(nq," \u2014 "),vV=n(nq,"A",{href:!0});var ujt=s(vV);D6o=r(ujt,"BertTokenizer"),ujt.forEach(t),G6o=r(nq," or "),FV=n(nq,"A",{href:!0});var pjt=s(FV);O6o=r(pjt,"BertTokenizerFast"),pjt.forEach(t),V6o=r(nq," (Nezha model)"),nq.forEach(t),X6o=i(S),fl=n(S,"LI",{});var sq=s(fl);C1e=n(sq,"STRONG",{});var _jt=s(C1e);z6o=r(_jt,"nllb"),_jt.forEach(t),Q6o=r(sq," \u2014 "),TV=n(sq,"A",{href:!0});var bjt=s(TV);W6o=r(bjt,"NllbTokenizer"),bjt.forEach(t),U6o=r(sq," or "),MV=n(sq,"A",{href:!0});var vjt=s(MV);H6o=r(vjt,"NllbTokenizerFast"),vjt.forEach(t),J6o=r(sq," (NLLB model)"),sq.forEach(t),Y6o=i(S),gl=n(S,"LI",{});var lq=s(gl);w1e=n(lq,"STRONG",{});var Fjt=s(w1e);Z6o=r(Fjt,"nystromformer"),Fjt.forEach(t),K6o=r(lq," \u2014 "),EV=n(lq,"A",{href:!0});var Tjt=s(EV);e7o=r(Tjt,"AlbertTokenizer"),Tjt.forEach(t),o7o=r(lq," or "),CV=n(lq,"A",{href:!0});var Mjt=s(CV);r7o=r(Mjt,"AlbertTokenizerFast"),Mjt.forEach(t),t7o=r(lq," (Nystr\xF6mformer model)"),lq.forEach(t),a7o=i(S),hl=n(S,"LI",{});var iq=s(hl);A1e=n(iq,"STRONG",{});var Ejt=s(A1e);n7o=r(Ejt,"openai-gpt"),Ejt.forEach(t),s7o=r(iq," \u2014 "),wV=n(iq,"A",{href:!0});var Cjt=s(wV);l7o=r(Cjt,"OpenAIGPTTokenizer"),Cjt.forEach(t),i7o=r(iq," or "),AV=n(iq,"A",{href:!0});var wjt=s(AV);d7o=r(wjt,"OpenAIGPTTokenizerFast"),wjt.forEach(t),m7o=r(iq," (OpenAI GPT model)"),iq.forEach(t),c7o=i(S),sp=n(S,"LI",{});var wOe=s(sp);L1e=n(wOe,"STRONG",{});var Ajt=s(L1e);f7o=r(Ajt,"opt"),Ajt.forEach(t),g7o=r(wOe," \u2014 "),LV=n(wOe,"A",{href:!0});var Ljt=s(LV);h7o=r(Ljt,"GPT2Tokenizer"),Ljt.forEach(t),u7o=r(wOe," (OPT model)"),wOe.forEach(t),p7o=i(S),ul=n(S,"LI",{});var dq=s(ul);y1e=n(dq,"STRONG",{});var yjt=s(y1e);_7o=r(yjt,"owlvit"),yjt.forEach(t),b7o=r(dq," \u2014 "),yV=n(dq,"A",{href:!0});var xjt=s(yV);v7o=r(xjt,"CLIPTokenizer"),xjt.forEach(t),F7o=r(dq," or "),xV=n(dq,"A",{href:!0});var $jt=s(xV);T7o=r($jt,"CLIPTokenizerFast"),$jt.forEach(t),M7o=r(dq," (OWL-ViT model)"),dq.forEach(t),E7o=i(S),pl=n(S,"LI",{});var mq=s(pl);x1e=n(mq,"STRONG",{});var kjt=s(x1e);C7o=r(kjt,"pegasus"),kjt.forEach(t),w7o=r(mq," \u2014 "),$V=n(mq,"A",{href:!0});var Sjt=s($V);A7o=r(Sjt,"PegasusTokenizer"),Sjt.forEach(t),L7o=r(mq," or "),kV=n(mq,"A",{href:!0});var Rjt=s(kV);y7o=r(Rjt,"PegasusTokenizerFast"),Rjt.forEach(t),x7o=r(mq," (Pegasus model)"),mq.forEach(t),$7o=i(S),_l=n(S,"LI",{});var cq=s(_l);$1e=n(cq,"STRONG",{});var Pjt=s($1e);k7o=r(Pjt,"pegasus_x"),Pjt.forEach(t),S7o=r(cq," \u2014 "),SV=n(cq,"A",{href:!0});var Bjt=s(SV);R7o=r(Bjt,"PegasusTokenizer"),Bjt.forEach(t),P7o=r(cq," or "),RV=n(cq,"A",{href:!0});var Ijt=s(RV);B7o=r(Ijt,"PegasusTokenizerFast"),Ijt.forEach(t),I7o=r(cq," (PEGASUS-X model)"),cq.forEach(t),N7o=i(S),lp=n(S,"LI",{});var AOe=s(lp);k1e=n(AOe,"STRONG",{});var Njt=s(k1e);q7o=r(Njt,"perceiver"),Njt.forEach(t),j7o=r(AOe," \u2014 "),PV=n(AOe,"A",{href:!0});var qjt=s(PV);D7o=r(qjt,"PerceiverTokenizer"),qjt.forEach(t),G7o=r(AOe," (Perceiver model)"),AOe.forEach(t),O7o=i(S),ip=n(S,"LI",{});var LOe=s(ip);S1e=n(LOe,"STRONG",{});var jjt=s(S1e);V7o=r(jjt,"phobert"),jjt.forEach(t),X7o=r(LOe," \u2014 "),BV=n(LOe,"A",{href:!0});var Djt=s(BV);z7o=r(Djt,"PhobertTokenizer"),Djt.forEach(t),Q7o=r(LOe," (PhoBERT model)"),LOe.forEach(t),W7o=i(S),dp=n(S,"LI",{});var yOe=s(dp);R1e=n(yOe,"STRONG",{});var Gjt=s(R1e);U7o=r(Gjt,"plbart"),Gjt.forEach(t),H7o=r(yOe," \u2014 "),IV=n(yOe,"A",{href:!0});var Ojt=s(IV);J7o=r(Ojt,"PLBartTokenizer"),Ojt.forEach(t),Y7o=r(yOe," (PLBart model)"),yOe.forEach(t),Z7o=i(S),mp=n(S,"LI",{});var xOe=s(mp);P1e=n(xOe,"STRONG",{});var Vjt=s(P1e);K7o=r(Vjt,"prophetnet"),Vjt.forEach(t),e8o=r(xOe," \u2014 "),NV=n(xOe,"A",{href:!0});var Xjt=s(NV);o8o=r(Xjt,"ProphetNetTokenizer"),Xjt.forEach(t),r8o=r(xOe," (ProphetNet model)"),xOe.forEach(t),t8o=i(S),bl=n(S,"LI",{});var fq=s(bl);B1e=n(fq,"STRONG",{});var zjt=s(B1e);a8o=r(zjt,"qdqbert"),zjt.forEach(t),n8o=r(fq," \u2014 "),qV=n(fq,"A",{href:!0});var Qjt=s(qV);s8o=r(Qjt,"BertTokenizer"),Qjt.forEach(t),l8o=r(fq," or "),jV=n(fq,"A",{href:!0});var Wjt=s(jV);i8o=r(Wjt,"BertTokenizerFast"),Wjt.forEach(t),d8o=r(fq," (QDQBert model)"),fq.forEach(t),m8o=i(S),cp=n(S,"LI",{});var $Oe=s(cp);I1e=n($Oe,"STRONG",{});var Ujt=s(I1e);c8o=r(Ujt,"rag"),Ujt.forEach(t),f8o=r($Oe," \u2014 "),DV=n($Oe,"A",{href:!0});var Hjt=s(DV);g8o=r(Hjt,"RagTokenizer"),Hjt.forEach(t),h8o=r($Oe," (RAG model)"),$Oe.forEach(t),u8o=i(S),vl=n(S,"LI",{});var gq=s(vl);N1e=n(gq,"STRONG",{});var Jjt=s(N1e);p8o=r(Jjt,"realm"),Jjt.forEach(t),_8o=r(gq," \u2014 "),GV=n(gq,"A",{href:!0});var Yjt=s(GV);b8o=r(Yjt,"RealmTokenizer"),Yjt.forEach(t),v8o=r(gq," or "),OV=n(gq,"A",{href:!0});var Zjt=s(OV);F8o=r(Zjt,"RealmTokenizerFast"),Zjt.forEach(t),T8o=r(gq," (REALM model)"),gq.forEach(t),M8o=i(S),Fl=n(S,"LI",{});var hq=s(Fl);q1e=n(hq,"STRONG",{});var Kjt=s(q1e);E8o=r(Kjt,"reformer"),Kjt.forEach(t),C8o=r(hq," \u2014 "),VV=n(hq,"A",{href:!0});var eDt=s(VV);w8o=r(eDt,"ReformerTokenizer"),eDt.forEach(t),A8o=r(hq," or "),XV=n(hq,"A",{href:!0});var oDt=s(XV);L8o=r(oDt,"ReformerTokenizerFast"),oDt.forEach(t),y8o=r(hq," (Reformer model)"),hq.forEach(t),x8o=i(S),Tl=n(S,"LI",{});var uq=s(Tl);j1e=n(uq,"STRONG",{});var rDt=s(j1e);$8o=r(rDt,"rembert"),rDt.forEach(t),k8o=r(uq," \u2014 "),zV=n(uq,"A",{href:!0});var tDt=s(zV);S8o=r(tDt,"RemBertTokenizer"),tDt.forEach(t),R8o=r(uq," or "),QV=n(uq,"A",{href:!0});var aDt=s(QV);P8o=r(aDt,"RemBertTokenizerFast"),aDt.forEach(t),B8o=r(uq," (RemBERT model)"),uq.forEach(t),I8o=i(S),Ml=n(S,"LI",{});var pq=s(Ml);D1e=n(pq,"STRONG",{});var nDt=s(D1e);N8o=r(nDt,"retribert"),nDt.forEach(t),q8o=r(pq," \u2014 "),WV=n(pq,"A",{href:!0});var sDt=s(WV);j8o=r(sDt,"RetriBertTokenizer"),sDt.forEach(t),D8o=r(pq," or "),UV=n(pq,"A",{href:!0});var lDt=s(UV);G8o=r(lDt,"RetriBertTokenizerFast"),lDt.forEach(t),O8o=r(pq," (RetriBERT model)"),pq.forEach(t),V8o=i(S),El=n(S,"LI",{});var _q=s(El);G1e=n(_q,"STRONG",{});var iDt=s(G1e);X8o=r(iDt,"roberta"),iDt.forEach(t),z8o=r(_q," \u2014 "),HV=n(_q,"A",{href:!0});var dDt=s(HV);Q8o=r(dDt,"RobertaTokenizer"),dDt.forEach(t),W8o=r(_q," or "),JV=n(_q,"A",{href:!0});var mDt=s(JV);U8o=r(mDt,"RobertaTokenizerFast"),mDt.forEach(t),H8o=r(_q," (RoBERTa model)"),_q.forEach(t),J8o=i(S),fp=n(S,"LI",{});var kOe=s(fp);O1e=n(kOe,"STRONG",{});var cDt=s(O1e);Y8o=r(cDt,"roc_bert"),cDt.forEach(t),Z8o=r(kOe," \u2014 "),YV=n(kOe,"A",{href:!0});var fDt=s(YV);K8o=r(fDt,"RoCBertTokenizer"),fDt.forEach(t),eLo=r(kOe," (RoCBert model)"),kOe.forEach(t),oLo=i(S),Cl=n(S,"LI",{});var bq=s(Cl);V1e=n(bq,"STRONG",{});var gDt=s(V1e);rLo=r(gDt,"roformer"),gDt.forEach(t),tLo=r(bq," \u2014 "),ZV=n(bq,"A",{href:!0});var hDt=s(ZV);aLo=r(hDt,"RoFormerTokenizer"),hDt.forEach(t),nLo=r(bq," or "),KV=n(bq,"A",{href:!0});var uDt=s(KV);sLo=r(uDt,"RoFormerTokenizerFast"),uDt.forEach(t),lLo=r(bq," (RoFormer model)"),bq.forEach(t),iLo=i(S),gp=n(S,"LI",{});var SOe=s(gp);X1e=n(SOe,"STRONG",{});var pDt=s(X1e);dLo=r(pDt,"speech_to_text"),pDt.forEach(t),mLo=r(SOe," \u2014 "),eX=n(SOe,"A",{href:!0});var _Dt=s(eX);cLo=r(_Dt,"Speech2TextTokenizer"),_Dt.forEach(t),fLo=r(SOe," (Speech2Text model)"),SOe.forEach(t),gLo=i(S),hp=n(S,"LI",{});var ROe=s(hp);z1e=n(ROe,"STRONG",{});var bDt=s(z1e);hLo=r(bDt,"speech_to_text_2"),bDt.forEach(t),uLo=r(ROe," \u2014 "),oX=n(ROe,"A",{href:!0});var vDt=s(oX);pLo=r(vDt,"Speech2Text2Tokenizer"),vDt.forEach(t),_Lo=r(ROe," (Speech2Text2 model)"),ROe.forEach(t),bLo=i(S),wl=n(S,"LI",{});var vq=s(wl);Q1e=n(vq,"STRONG",{});var FDt=s(Q1e);vLo=r(FDt,"splinter"),FDt.forEach(t),FLo=r(vq," \u2014 "),rX=n(vq,"A",{href:!0});var TDt=s(rX);TLo=r(TDt,"SplinterTokenizer"),TDt.forEach(t),MLo=r(vq," or "),tX=n(vq,"A",{href:!0});var MDt=s(tX);ELo=r(MDt,"SplinterTokenizerFast"),MDt.forEach(t),CLo=r(vq," (Splinter model)"),vq.forEach(t),wLo=i(S),Al=n(S,"LI",{});var Fq=s(Al);W1e=n(Fq,"STRONG",{});var EDt=s(W1e);ALo=r(EDt,"squeezebert"),EDt.forEach(t),LLo=r(Fq," \u2014 "),aX=n(Fq,"A",{href:!0});var CDt=s(aX);yLo=r(CDt,"SqueezeBertTokenizer"),CDt.forEach(t),xLo=r(Fq," or "),nX=n(Fq,"A",{href:!0});var wDt=s(nX);$Lo=r(wDt,"SqueezeBertTokenizerFast"),wDt.forEach(t),kLo=r(Fq," (SqueezeBERT model)"),Fq.forEach(t),SLo=i(S),Ll=n(S,"LI",{});var Tq=s(Ll);U1e=n(Tq,"STRONG",{});var ADt=s(U1e);RLo=r(ADt,"t5"),ADt.forEach(t),PLo=r(Tq," \u2014 "),sX=n(Tq,"A",{href:!0});var LDt=s(sX);BLo=r(LDt,"T5Tokenizer"),LDt.forEach(t),ILo=r(Tq," or "),lX=n(Tq,"A",{href:!0});var yDt=s(lX);NLo=r(yDt,"T5TokenizerFast"),yDt.forEach(t),qLo=r(Tq," (T5 model)"),Tq.forEach(t),jLo=i(S),up=n(S,"LI",{});var POe=s(up);H1e=n(POe,"STRONG",{});var xDt=s(H1e);DLo=r(xDt,"tapas"),xDt.forEach(t),GLo=r(POe," \u2014 "),iX=n(POe,"A",{href:!0});var $Dt=s(iX);OLo=r($Dt,"TapasTokenizer"),$Dt.forEach(t),VLo=r(POe," (TAPAS model)"),POe.forEach(t),XLo=i(S),pp=n(S,"LI",{});var BOe=s(pp);J1e=n(BOe,"STRONG",{});var kDt=s(J1e);zLo=r(kDt,"tapex"),kDt.forEach(t),QLo=r(BOe," \u2014 "),dX=n(BOe,"A",{href:!0});var SDt=s(dX);WLo=r(SDt,"TapexTokenizer"),SDt.forEach(t),ULo=r(BOe," (TAPEX model)"),BOe.forEach(t),HLo=i(S),_p=n(S,"LI",{});var IOe=s(_p);Y1e=n(IOe,"STRONG",{});var RDt=s(Y1e);JLo=r(RDt,"transfo-xl"),RDt.forEach(t),YLo=r(IOe," \u2014 "),mX=n(IOe,"A",{href:!0});var PDt=s(mX);ZLo=r(PDt,"TransfoXLTokenizer"),PDt.forEach(t),KLo=r(IOe," (Transformer-XL model)"),IOe.forEach(t),eyo=i(S),yl=n(S,"LI",{});var Mq=s(yl);Z1e=n(Mq,"STRONG",{});var BDt=s(Z1e);oyo=r(BDt,"vilt"),BDt.forEach(t),ryo=r(Mq," \u2014 "),cX=n(Mq,"A",{href:!0});var IDt=s(cX);tyo=r(IDt,"BertTokenizer"),IDt.forEach(t),ayo=r(Mq," or "),fX=n(Mq,"A",{href:!0});var NDt=s(fX);nyo=r(NDt,"BertTokenizerFast"),NDt.forEach(t),syo=r(Mq," (ViLT model)"),Mq.forEach(t),lyo=i(S),xl=n(S,"LI",{});var Eq=s(xl);K1e=n(Eq,"STRONG",{});var qDt=s(K1e);iyo=r(qDt,"visual_bert"),qDt.forEach(t),dyo=r(Eq," \u2014 "),gX=n(Eq,"A",{href:!0});var jDt=s(gX);myo=r(jDt,"BertTokenizer"),jDt.forEach(t),cyo=r(Eq," or "),hX=n(Eq,"A",{href:!0});var DDt=s(hX);fyo=r(DDt,"BertTokenizerFast"),DDt.forEach(t),gyo=r(Eq," (VisualBERT model)"),Eq.forEach(t),hyo=i(S),bp=n(S,"LI",{});var NOe=s(bp);e2e=n(NOe,"STRONG",{});var GDt=s(e2e);uyo=r(GDt,"wav2vec2"),GDt.forEach(t),pyo=r(NOe," \u2014 "),uX=n(NOe,"A",{href:!0});var ODt=s(uX);_yo=r(ODt,"Wav2Vec2CTCTokenizer"),ODt.forEach(t),byo=r(NOe," (Wav2Vec2 model)"),NOe.forEach(t),vyo=i(S),vp=n(S,"LI",{});var qOe=s(vp);o2e=n(qOe,"STRONG",{});var VDt=s(o2e);Fyo=r(VDt,"wav2vec2-conformer"),VDt.forEach(t),Tyo=r(qOe," \u2014 "),pX=n(qOe,"A",{href:!0});var XDt=s(pX);Myo=r(XDt,"Wav2Vec2CTCTokenizer"),XDt.forEach(t),Eyo=r(qOe," (Wav2Vec2-Conformer model)"),qOe.forEach(t),Cyo=i(S),Fp=n(S,"LI",{});var jOe=s(Fp);r2e=n(jOe,"STRONG",{});var zDt=s(r2e);wyo=r(zDt,"wav2vec2_phoneme"),zDt.forEach(t),Ayo=r(jOe," \u2014 "),_X=n(jOe,"A",{href:!0});var QDt=s(_X);Lyo=r(QDt,"Wav2Vec2PhonemeCTCTokenizer"),QDt.forEach(t),yyo=r(jOe," (Wav2Vec2Phoneme model)"),jOe.forEach(t),xyo=i(S),Tp=n(S,"LI",{});var DOe=s(Tp);t2e=n(DOe,"STRONG",{});var WDt=s(t2e);$yo=r(WDt,"whisper"),WDt.forEach(t),kyo=r(DOe," \u2014 "),bX=n(DOe,"A",{href:!0});var UDt=s(bX);Syo=r(UDt,"WhisperTokenizer"),UDt.forEach(t),Ryo=r(DOe," (Whisper model)"),DOe.forEach(t),Pyo=i(S),$l=n(S,"LI",{});var Cq=s($l);a2e=n(Cq,"STRONG",{});var HDt=s(a2e);Byo=r(HDt,"xclip"),HDt.forEach(t),Iyo=r(Cq," \u2014 "),vX=n(Cq,"A",{href:!0});var JDt=s(vX);Nyo=r(JDt,"CLIPTokenizer"),JDt.forEach(t),qyo=r(Cq," or "),FX=n(Cq,"A",{href:!0});var YDt=s(FX);jyo=r(YDt,"CLIPTokenizerFast"),YDt.forEach(t),Dyo=r(Cq," (X-CLIP model)"),Cq.forEach(t),Gyo=i(S),kl=n(S,"LI",{});var wq=s(kl);n2e=n(wq,"STRONG",{});var ZDt=s(n2e);Oyo=r(ZDt,"xglm"),ZDt.forEach(t),Vyo=r(wq," \u2014 "),TX=n(wq,"A",{href:!0});var KDt=s(TX);Xyo=r(KDt,"XGLMTokenizer"),KDt.forEach(t),zyo=r(wq," or "),MX=n(wq,"A",{href:!0});var eGt=s(MX);Qyo=r(eGt,"XGLMTokenizerFast"),eGt.forEach(t),Wyo=r(wq," (XGLM model)"),wq.forEach(t),Uyo=i(S),Mp=n(S,"LI",{});var GOe=s(Mp);s2e=n(GOe,"STRONG",{});var oGt=s(s2e);Hyo=r(oGt,"xlm"),oGt.forEach(t),Jyo=r(GOe," \u2014 "),EX=n(GOe,"A",{href:!0});var rGt=s(EX);Yyo=r(rGt,"XLMTokenizer"),rGt.forEach(t),Zyo=r(GOe," (XLM model)"),GOe.forEach(t),Kyo=i(S),Ep=n(S,"LI",{});var OOe=s(Ep);l2e=n(OOe,"STRONG",{});var tGt=s(l2e);e9o=r(tGt,"xlm-prophetnet"),tGt.forEach(t),o9o=r(OOe," \u2014 "),CX=n(OOe,"A",{href:!0});var aGt=s(CX);r9o=r(aGt,"XLMProphetNetTokenizer"),aGt.forEach(t),t9o=r(OOe," (XLM-ProphetNet model)"),OOe.forEach(t),a9o=i(S),Sl=n(S,"LI",{});var Aq=s(Sl);i2e=n(Aq,"STRONG",{});var nGt=s(i2e);n9o=r(nGt,"xlm-roberta"),nGt.forEach(t),s9o=r(Aq," \u2014 "),wX=n(Aq,"A",{href:!0});var sGt=s(wX);l9o=r(sGt,"XLMRobertaTokenizer"),sGt.forEach(t),i9o=r(Aq," or "),AX=n(Aq,"A",{href:!0});var lGt=s(AX);d9o=r(lGt,"XLMRobertaTokenizerFast"),lGt.forEach(t),m9o=r(Aq," (XLM-RoBERTa model)"),Aq.forEach(t),c9o=i(S),Rl=n(S,"LI",{});var Lq=s(Rl);d2e=n(Lq,"STRONG",{});var iGt=s(d2e);f9o=r(iGt,"xlm-roberta-xl"),iGt.forEach(t),g9o=r(Lq," \u2014 "),LX=n(Lq,"A",{href:!0});var dGt=s(LX);h9o=r(dGt,"XLMRobertaTokenizer"),dGt.forEach(t),u9o=r(Lq," or "),yX=n(Lq,"A",{href:!0});var mGt=s(yX);p9o=r(mGt,"XLMRobertaTokenizerFast"),mGt.forEach(t),_9o=r(Lq," (XLM-RoBERTa-XL model)"),Lq.forEach(t),b9o=i(S),Pl=n(S,"LI",{});var yq=s(Pl);m2e=n(yq,"STRONG",{});var cGt=s(m2e);v9o=r(cGt,"xlnet"),cGt.forEach(t),F9o=r(yq," \u2014 "),xX=n(yq,"A",{href:!0});var fGt=s(xX);T9o=r(fGt,"XLNetTokenizer"),fGt.forEach(t),M9o=r(yq," or "),$X=n(yq,"A",{href:!0});var gGt=s($X);E9o=r(gGt,"XLNetTokenizerFast"),gGt.forEach(t),C9o=r(yq," (XLNet model)"),yq.forEach(t),w9o=i(S),Bl=n(S,"LI",{});var xq=s(Bl);c2e=n(xq,"STRONG",{});var hGt=s(c2e);A9o=r(hGt,"yoso"),hGt.forEach(t),L9o=r(xq," \u2014 "),kX=n(xq,"A",{href:!0});var uGt=s(kX);y9o=r(uGt,"AlbertTokenizer"),uGt.forEach(t),x9o=r(xq," or "),SX=n(xq,"A",{href:!0});var pGt=s(SX);$9o=r(pGt,"AlbertTokenizerFast"),pGt.forEach(t),k9o=r(xq," (YOSO model)"),xq.forEach(t),S.forEach(t),S9o=i(Ol),T(Cp.$$.fragment,Ol),Ol.forEach(t),R9o=i(Gl),wp=n(Gl,"DIV",{class:!0});var Zdo=s(wp);T(yk.$$.fragment,Zdo),P9o=i(Zdo),f2e=n(Zdo,"P",{});var _Gt=s(f2e);B9o=r(_Gt,"Register a new tokenizer in this mapping."),_Gt.forEach(t),Zdo.forEach(t),Gl.forEach(t),Nlo=i(c),Nd=n(c,"H2",{class:!0});var Kdo=s(Nd);Ap=n(Kdo,"A",{id:!0,class:!0,href:!0});var bGt=s(Ap);g2e=n(bGt,"SPAN",{});var vGt=s(g2e);T(xk.$$.fragment,vGt),vGt.forEach(t),bGt.forEach(t),I9o=i(Kdo),h2e=n(Kdo,"SPAN",{});var FGt=s(h2e);N9o=r(FGt,"AutoFeatureExtractor"),FGt.forEach(t),Kdo.forEach(t),qlo=i(c),No=n(c,"DIV",{class:!0});var Vl=s(No);T($k.$$.fragment,Vl),q9o=i(Vl),kk=n(Vl,"P",{});var emo=s(kk);j9o=r(emo,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),RX=n(emo,"A",{href:!0});var TGt=s(RX);D9o=r(TGt,"AutoFeatureExtractor.from_pretrained()"),TGt.forEach(t),G9o=r(emo," class method."),emo.forEach(t),O9o=i(Vl),Sk=n(Vl,"P",{});var omo=s(Sk);V9o=r(omo,"This class cannot be instantiated directly using "),u2e=n(omo,"CODE",{});var MGt=s(u2e);X9o=r(MGt,"__init__()"),MGt.forEach(t),z9o=r(omo," (throws an error)."),omo.forEach(t),Q9o=i(Vl),eo=n(Vl,"DIV",{class:!0});var xa=s(eo);T(Rk.$$.fragment,xa),W9o=i(xa),p2e=n(xa,"P",{});var EGt=s(p2e);U9o=r(EGt,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),EGt.forEach(t),H9o=i(xa),mn=n(xa,"P",{});var ax=s(mn);J9o=r(ax,"The feature extractor class to instantiate is selected based on the "),_2e=n(ax,"CODE",{});var CGt=s(_2e);Y9o=r(CGt,"model_type"),CGt.forEach(t),Z9o=r(ax,` property of the config object
(either passed as an argument or loaded from `),b2e=n(ax,"CODE",{});var wGt=s(b2e);K9o=r(wGt,"pretrained_model_name_or_path"),wGt.forEach(t),exo=r(ax,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),v2e=n(ax,"CODE",{});var AGt=s(v2e);oxo=r(AGt,"pretrained_model_name_or_path"),AGt.forEach(t),rxo=r(ax,":"),ax.forEach(t),txo=i(xa),z=n(xa,"UL",{});var Q=s(z);Lp=n(Q,"LI",{});var VOe=s(Lp);F2e=n(VOe,"STRONG",{});var LGt=s(F2e);axo=r(LGt,"beit"),LGt.forEach(t),nxo=r(VOe," \u2014 "),PX=n(VOe,"A",{href:!0});var yGt=s(PX);sxo=r(yGt,"BeitFeatureExtractor"),yGt.forEach(t),lxo=r(VOe," (BEiT model)"),VOe.forEach(t),ixo=i(Q),yp=n(Q,"LI",{});var XOe=s(yp);T2e=n(XOe,"STRONG",{});var xGt=s(T2e);dxo=r(xGt,"clip"),xGt.forEach(t),mxo=r(XOe," \u2014 "),BX=n(XOe,"A",{href:!0});var $Gt=s(BX);cxo=r($Gt,"CLIPFeatureExtractor"),$Gt.forEach(t),fxo=r(XOe," (CLIP model)"),XOe.forEach(t),gxo=i(Q),xp=n(Q,"LI",{});var zOe=s(xp);M2e=n(zOe,"STRONG",{});var kGt=s(M2e);hxo=r(kGt,"clipseg"),kGt.forEach(t),uxo=r(zOe," \u2014 "),IX=n(zOe,"A",{href:!0});var SGt=s(IX);pxo=r(SGt,"ViTFeatureExtractor"),SGt.forEach(t),_xo=r(zOe," (CLIPSeg model)"),zOe.forEach(t),bxo=i(Q),$p=n(Q,"LI",{});var QOe=s($p);E2e=n(QOe,"STRONG",{});var RGt=s(E2e);vxo=r(RGt,"conditional_detr"),RGt.forEach(t),Fxo=r(QOe," \u2014 "),NX=n(QOe,"A",{href:!0});var PGt=s(NX);Txo=r(PGt,"ConditionalDetrFeatureExtractor"),PGt.forEach(t),Mxo=r(QOe," (Conditional DETR model)"),QOe.forEach(t),Exo=i(Q),kp=n(Q,"LI",{});var WOe=s(kp);C2e=n(WOe,"STRONG",{});var BGt=s(C2e);Cxo=r(BGt,"convnext"),BGt.forEach(t),wxo=r(WOe," \u2014 "),qX=n(WOe,"A",{href:!0});var IGt=s(qX);Axo=r(IGt,"ConvNextFeatureExtractor"),IGt.forEach(t),Lxo=r(WOe," (ConvNeXT model)"),WOe.forEach(t),yxo=i(Q),Sp=n(Q,"LI",{});var UOe=s(Sp);w2e=n(UOe,"STRONG",{});var NGt=s(w2e);xxo=r(NGt,"cvt"),NGt.forEach(t),$xo=r(UOe," \u2014 "),jX=n(UOe,"A",{href:!0});var qGt=s(jX);kxo=r(qGt,"ConvNextFeatureExtractor"),qGt.forEach(t),Sxo=r(UOe," (CvT model)"),UOe.forEach(t),Rxo=i(Q),Rp=n(Q,"LI",{});var HOe=s(Rp);A2e=n(HOe,"STRONG",{});var jGt=s(A2e);Pxo=r(jGt,"data2vec-audio"),jGt.forEach(t),Bxo=r(HOe," \u2014 "),DX=n(HOe,"A",{href:!0});var DGt=s(DX);Ixo=r(DGt,"Wav2Vec2FeatureExtractor"),DGt.forEach(t),Nxo=r(HOe," (Data2VecAudio model)"),HOe.forEach(t),qxo=i(Q),Pp=n(Q,"LI",{});var JOe=s(Pp);L2e=n(JOe,"STRONG",{});var GGt=s(L2e);jxo=r(GGt,"data2vec-vision"),GGt.forEach(t),Dxo=r(JOe," \u2014 "),GX=n(JOe,"A",{href:!0});var OGt=s(GX);Gxo=r(OGt,"BeitFeatureExtractor"),OGt.forEach(t),Oxo=r(JOe," (Data2VecVision model)"),JOe.forEach(t),Vxo=i(Q),Bp=n(Q,"LI",{});var YOe=s(Bp);y2e=n(YOe,"STRONG",{});var VGt=s(y2e);Xxo=r(VGt,"deformable_detr"),VGt.forEach(t),zxo=r(YOe," \u2014 "),OX=n(YOe,"A",{href:!0});var XGt=s(OX);Qxo=r(XGt,"DeformableDetrFeatureExtractor"),XGt.forEach(t),Wxo=r(YOe," (Deformable DETR model)"),YOe.forEach(t),Uxo=i(Q),Ip=n(Q,"LI",{});var ZOe=s(Ip);x2e=n(ZOe,"STRONG",{});var zGt=s(x2e);Hxo=r(zGt,"deit"),zGt.forEach(t),Jxo=r(ZOe," \u2014 "),VX=n(ZOe,"A",{href:!0});var QGt=s(VX);Yxo=r(QGt,"DeiTFeatureExtractor"),QGt.forEach(t),Zxo=r(ZOe," (DeiT model)"),ZOe.forEach(t),Kxo=i(Q),Np=n(Q,"LI",{});var KOe=s(Np);$2e=n(KOe,"STRONG",{});var WGt=s($2e);e$o=r(WGt,"detr"),WGt.forEach(t),o$o=r(KOe," \u2014 "),XX=n(KOe,"A",{href:!0});var UGt=s(XX);r$o=r(UGt,"DetrFeatureExtractor"),UGt.forEach(t),t$o=r(KOe," (DETR model)"),KOe.forEach(t),a$o=i(Q),qp=n(Q,"LI",{});var eVe=s(qp);k2e=n(eVe,"STRONG",{});var HGt=s(k2e);n$o=r(HGt,"donut-swin"),HGt.forEach(t),s$o=r(eVe," \u2014 "),zX=n(eVe,"A",{href:!0});var JGt=s(zX);l$o=r(JGt,"DonutFeatureExtractor"),JGt.forEach(t),i$o=r(eVe," (DonutSwin model)"),eVe.forEach(t),d$o=i(Q),jp=n(Q,"LI",{});var oVe=s(jp);S2e=n(oVe,"STRONG",{});var YGt=s(S2e);m$o=r(YGt,"dpt"),YGt.forEach(t),c$o=r(oVe," \u2014 "),QX=n(oVe,"A",{href:!0});var ZGt=s(QX);f$o=r(ZGt,"DPTFeatureExtractor"),ZGt.forEach(t),g$o=r(oVe," (DPT model)"),oVe.forEach(t),h$o=i(Q),Dp=n(Q,"LI",{});var rVe=s(Dp);R2e=n(rVe,"STRONG",{});var KGt=s(R2e);u$o=r(KGt,"flava"),KGt.forEach(t),p$o=r(rVe," \u2014 "),WX=n(rVe,"A",{href:!0});var eOt=s(WX);_$o=r(eOt,"FlavaFeatureExtractor"),eOt.forEach(t),b$o=r(rVe," (FLAVA model)"),rVe.forEach(t),v$o=i(Q),Gp=n(Q,"LI",{});var tVe=s(Gp);P2e=n(tVe,"STRONG",{});var oOt=s(P2e);F$o=r(oOt,"glpn"),oOt.forEach(t),T$o=r(tVe," \u2014 "),UX=n(tVe,"A",{href:!0});var rOt=s(UX);M$o=r(rOt,"GLPNFeatureExtractor"),rOt.forEach(t),E$o=r(tVe," (GLPN model)"),tVe.forEach(t),C$o=i(Q),Op=n(Q,"LI",{});var aVe=s(Op);B2e=n(aVe,"STRONG",{});var tOt=s(B2e);w$o=r(tOt,"groupvit"),tOt.forEach(t),A$o=r(aVe," \u2014 "),HX=n(aVe,"A",{href:!0});var aOt=s(HX);L$o=r(aOt,"CLIPFeatureExtractor"),aOt.forEach(t),y$o=r(aVe," (GroupViT model)"),aVe.forEach(t),x$o=i(Q),Vp=n(Q,"LI",{});var nVe=s(Vp);I2e=n(nVe,"STRONG",{});var nOt=s(I2e);$$o=r(nOt,"hubert"),nOt.forEach(t),k$o=r(nVe," \u2014 "),JX=n(nVe,"A",{href:!0});var sOt=s(JX);S$o=r(sOt,"Wav2Vec2FeatureExtractor"),sOt.forEach(t),R$o=r(nVe," (Hubert model)"),nVe.forEach(t),P$o=i(Q),Xp=n(Q,"LI",{});var sVe=s(Xp);N2e=n(sVe,"STRONG",{});var lOt=s(N2e);B$o=r(lOt,"imagegpt"),lOt.forEach(t),I$o=r(sVe," \u2014 "),YX=n(sVe,"A",{href:!0});var iOt=s(YX);N$o=r(iOt,"ImageGPTFeatureExtractor"),iOt.forEach(t),q$o=r(sVe," (ImageGPT model)"),sVe.forEach(t),j$o=i(Q),zp=n(Q,"LI",{});var lVe=s(zp);q2e=n(lVe,"STRONG",{});var dOt=s(q2e);D$o=r(dOt,"layoutlmv2"),dOt.forEach(t),G$o=r(lVe," \u2014 "),ZX=n(lVe,"A",{href:!0});var mOt=s(ZX);O$o=r(mOt,"LayoutLMv2FeatureExtractor"),mOt.forEach(t),V$o=r(lVe," (LayoutLMv2 model)"),lVe.forEach(t),X$o=i(Q),Qp=n(Q,"LI",{});var iVe=s(Qp);j2e=n(iVe,"STRONG",{});var cOt=s(j2e);z$o=r(cOt,"layoutlmv3"),cOt.forEach(t),Q$o=r(iVe," \u2014 "),KX=n(iVe,"A",{href:!0});var fOt=s(KX);W$o=r(fOt,"LayoutLMv3FeatureExtractor"),fOt.forEach(t),U$o=r(iVe," (LayoutLMv3 model)"),iVe.forEach(t),H$o=i(Q),Wp=n(Q,"LI",{});var dVe=s(Wp);D2e=n(dVe,"STRONG",{});var gOt=s(D2e);J$o=r(gOt,"levit"),gOt.forEach(t),Y$o=r(dVe," \u2014 "),ez=n(dVe,"A",{href:!0});var hOt=s(ez);Z$o=r(hOt,"LevitFeatureExtractor"),hOt.forEach(t),K$o=r(dVe," (LeViT model)"),dVe.forEach(t),eko=i(Q),Up=n(Q,"LI",{});var mVe=s(Up);G2e=n(mVe,"STRONG",{});var uOt=s(G2e);oko=r(uOt,"maskformer"),uOt.forEach(t),rko=r(mVe," \u2014 "),oz=n(mVe,"A",{href:!0});var pOt=s(oz);tko=r(pOt,"MaskFormerFeatureExtractor"),pOt.forEach(t),ako=r(mVe," (MaskFormer model)"),mVe.forEach(t),nko=i(Q),Hp=n(Q,"LI",{});var cVe=s(Hp);O2e=n(cVe,"STRONG",{});var _Ot=s(O2e);sko=r(_Ot,"mctct"),_Ot.forEach(t),lko=r(cVe," \u2014 "),rz=n(cVe,"A",{href:!0});var bOt=s(rz);iko=r(bOt,"MCTCTFeatureExtractor"),bOt.forEach(t),dko=r(cVe," (M-CTC-T model)"),cVe.forEach(t),mko=i(Q),Jp=n(Q,"LI",{});var fVe=s(Jp);V2e=n(fVe,"STRONG",{});var vOt=s(V2e);cko=r(vOt,"mobilevit"),vOt.forEach(t),fko=r(fVe," \u2014 "),tz=n(fVe,"A",{href:!0});var FOt=s(tz);gko=r(FOt,"MobileViTFeatureExtractor"),FOt.forEach(t),hko=r(fVe," (MobileViT model)"),fVe.forEach(t),uko=i(Q),Yp=n(Q,"LI",{});var gVe=s(Yp);X2e=n(gVe,"STRONG",{});var TOt=s(X2e);pko=r(TOt,"owlvit"),TOt.forEach(t),_ko=r(gVe," \u2014 "),az=n(gVe,"A",{href:!0});var MOt=s(az);bko=r(MOt,"OwlViTFeatureExtractor"),MOt.forEach(t),vko=r(gVe," (OWL-ViT model)"),gVe.forEach(t),Fko=i(Q),Zp=n(Q,"LI",{});var hVe=s(Zp);z2e=n(hVe,"STRONG",{});var EOt=s(z2e);Tko=r(EOt,"perceiver"),EOt.forEach(t),Mko=r(hVe," \u2014 "),nz=n(hVe,"A",{href:!0});var COt=s(nz);Eko=r(COt,"PerceiverFeatureExtractor"),COt.forEach(t),Cko=r(hVe," (Perceiver model)"),hVe.forEach(t),wko=i(Q),Kp=n(Q,"LI",{});var uVe=s(Kp);Q2e=n(uVe,"STRONG",{});var wOt=s(Q2e);Ako=r(wOt,"poolformer"),wOt.forEach(t),Lko=r(uVe," \u2014 "),sz=n(uVe,"A",{href:!0});var AOt=s(sz);yko=r(AOt,"PoolFormerFeatureExtractor"),AOt.forEach(t),xko=r(uVe," (PoolFormer model)"),uVe.forEach(t),$ko=i(Q),e_=n(Q,"LI",{});var pVe=s(e_);W2e=n(pVe,"STRONG",{});var LOt=s(W2e);kko=r(LOt,"regnet"),LOt.forEach(t),Sko=r(pVe," \u2014 "),lz=n(pVe,"A",{href:!0});var yOt=s(lz);Rko=r(yOt,"ConvNextFeatureExtractor"),yOt.forEach(t),Pko=r(pVe," (RegNet model)"),pVe.forEach(t),Bko=i(Q),o_=n(Q,"LI",{});var _Ve=s(o_);U2e=n(_Ve,"STRONG",{});var xOt=s(U2e);Iko=r(xOt,"resnet"),xOt.forEach(t),Nko=r(_Ve," \u2014 "),iz=n(_Ve,"A",{href:!0});var $Ot=s(iz);qko=r($Ot,"ConvNextFeatureExtractor"),$Ot.forEach(t),jko=r(_Ve," (ResNet model)"),_Ve.forEach(t),Dko=i(Q),r_=n(Q,"LI",{});var bVe=s(r_);H2e=n(bVe,"STRONG",{});var kOt=s(H2e);Gko=r(kOt,"segformer"),kOt.forEach(t),Oko=r(bVe," \u2014 "),dz=n(bVe,"A",{href:!0});var SOt=s(dz);Vko=r(SOt,"SegformerFeatureExtractor"),SOt.forEach(t),Xko=r(bVe," (SegFormer model)"),bVe.forEach(t),zko=i(Q),t_=n(Q,"LI",{});var vVe=s(t_);J2e=n(vVe,"STRONG",{});var ROt=s(J2e);Qko=r(ROt,"speech_to_text"),ROt.forEach(t),Wko=r(vVe," \u2014 "),mz=n(vVe,"A",{href:!0});var POt=s(mz);Uko=r(POt,"Speech2TextFeatureExtractor"),POt.forEach(t),Hko=r(vVe," (Speech2Text model)"),vVe.forEach(t),Jko=i(Q),a_=n(Q,"LI",{});var FVe=s(a_);Y2e=n(FVe,"STRONG",{});var BOt=s(Y2e);Yko=r(BOt,"swin"),BOt.forEach(t),Zko=r(FVe," \u2014 "),cz=n(FVe,"A",{href:!0});var IOt=s(cz);Kko=r(IOt,"ViTFeatureExtractor"),IOt.forEach(t),eSo=r(FVe," (Swin Transformer model)"),FVe.forEach(t),oSo=i(Q),n_=n(Q,"LI",{});var TVe=s(n_);Z2e=n(TVe,"STRONG",{});var NOt=s(Z2e);rSo=r(NOt,"swinv2"),NOt.forEach(t),tSo=r(TVe," \u2014 "),fz=n(TVe,"A",{href:!0});var qOt=s(fz);aSo=r(qOt,"ViTFeatureExtractor"),qOt.forEach(t),nSo=r(TVe," (Swin Transformer V2 model)"),TVe.forEach(t),sSo=i(Q),s_=n(Q,"LI",{});var MVe=s(s_);K2e=n(MVe,"STRONG",{});var jOt=s(K2e);lSo=r(jOt,"table-transformer"),jOt.forEach(t),iSo=r(MVe," \u2014 "),gz=n(MVe,"A",{href:!0});var DOt=s(gz);dSo=r(DOt,"DetrFeatureExtractor"),DOt.forEach(t),mSo=r(MVe," (Table Transformer model)"),MVe.forEach(t),cSo=i(Q),l_=n(Q,"LI",{});var EVe=s(l_);ebe=n(EVe,"STRONG",{});var GOt=s(ebe);fSo=r(GOt,"van"),GOt.forEach(t),gSo=r(EVe," \u2014 "),hz=n(EVe,"A",{href:!0});var OOt=s(hz);hSo=r(OOt,"ConvNextFeatureExtractor"),OOt.forEach(t),uSo=r(EVe," (VAN model)"),EVe.forEach(t),pSo=i(Q),i_=n(Q,"LI",{});var CVe=s(i_);obe=n(CVe,"STRONG",{});var VOt=s(obe);_So=r(VOt,"videomae"),VOt.forEach(t),bSo=r(CVe," \u2014 "),uz=n(CVe,"A",{href:!0});var XOt=s(uz);vSo=r(XOt,"VideoMAEFeatureExtractor"),XOt.forEach(t),FSo=r(CVe," (VideoMAE model)"),CVe.forEach(t),TSo=i(Q),d_=n(Q,"LI",{});var wVe=s(d_);rbe=n(wVe,"STRONG",{});var zOt=s(rbe);MSo=r(zOt,"vilt"),zOt.forEach(t),ESo=r(wVe," \u2014 "),pz=n(wVe,"A",{href:!0});var QOt=s(pz);CSo=r(QOt,"ViltFeatureExtractor"),QOt.forEach(t),wSo=r(wVe," (ViLT model)"),wVe.forEach(t),ASo=i(Q),m_=n(Q,"LI",{});var AVe=s(m_);tbe=n(AVe,"STRONG",{});var WOt=s(tbe);LSo=r(WOt,"vit"),WOt.forEach(t),ySo=r(AVe," \u2014 "),_z=n(AVe,"A",{href:!0});var UOt=s(_z);xSo=r(UOt,"ViTFeatureExtractor"),UOt.forEach(t),$So=r(AVe," (ViT model)"),AVe.forEach(t),kSo=i(Q),c_=n(Q,"LI",{});var LVe=s(c_);abe=n(LVe,"STRONG",{});var HOt=s(abe);SSo=r(HOt,"vit_mae"),HOt.forEach(t),RSo=r(LVe," \u2014 "),bz=n(LVe,"A",{href:!0});var JOt=s(bz);PSo=r(JOt,"ViTFeatureExtractor"),JOt.forEach(t),BSo=r(LVe," (ViTMAE model)"),LVe.forEach(t),ISo=i(Q),f_=n(Q,"LI",{});var yVe=s(f_);nbe=n(yVe,"STRONG",{});var YOt=s(nbe);NSo=r(YOt,"vit_msn"),YOt.forEach(t),qSo=r(yVe," \u2014 "),vz=n(yVe,"A",{href:!0});var ZOt=s(vz);jSo=r(ZOt,"ViTFeatureExtractor"),ZOt.forEach(t),DSo=r(yVe," (ViTMSN model)"),yVe.forEach(t),GSo=i(Q),g_=n(Q,"LI",{});var xVe=s(g_);sbe=n(xVe,"STRONG",{});var KOt=s(sbe);OSo=r(KOt,"wav2vec2"),KOt.forEach(t),VSo=r(xVe," \u2014 "),Fz=n(xVe,"A",{href:!0});var eVt=s(Fz);XSo=r(eVt,"Wav2Vec2FeatureExtractor"),eVt.forEach(t),zSo=r(xVe," (Wav2Vec2 model)"),xVe.forEach(t),QSo=i(Q),h_=n(Q,"LI",{});var $Ve=s(h_);lbe=n($Ve,"STRONG",{});var oVt=s(lbe);WSo=r(oVt,"wav2vec2-conformer"),oVt.forEach(t),USo=r($Ve," \u2014 "),Tz=n($Ve,"A",{href:!0});var rVt=s(Tz);HSo=r(rVt,"Wav2Vec2FeatureExtractor"),rVt.forEach(t),JSo=r($Ve," (Wav2Vec2-Conformer model)"),$Ve.forEach(t),YSo=i(Q),u_=n(Q,"LI",{});var kVe=s(u_);ibe=n(kVe,"STRONG",{});var tVt=s(ibe);ZSo=r(tVt,"whisper"),tVt.forEach(t),KSo=r(kVe," \u2014 "),Mz=n(kVe,"A",{href:!0});var aVt=s(Mz);eRo=r(aVt,"WhisperFeatureExtractor"),aVt.forEach(t),oRo=r(kVe," (Whisper model)"),kVe.forEach(t),rRo=i(Q),p_=n(Q,"LI",{});var SVe=s(p_);dbe=n(SVe,"STRONG",{});var nVt=s(dbe);tRo=r(nVt,"xclip"),nVt.forEach(t),aRo=r(SVe," \u2014 "),Ez=n(SVe,"A",{href:!0});var sVt=s(Ez);nRo=r(sVt,"CLIPFeatureExtractor"),sVt.forEach(t),sRo=r(SVe," (X-CLIP model)"),SVe.forEach(t),lRo=i(Q),__=n(Q,"LI",{});var RVe=s(__);mbe=n(RVe,"STRONG",{});var lVt=s(mbe);iRo=r(lVt,"yolos"),lVt.forEach(t),dRo=r(RVe," \u2014 "),Cz=n(RVe,"A",{href:!0});var iVt=s(Cz);mRo=r(iVt,"YolosFeatureExtractor"),iVt.forEach(t),cRo=r(RVe," (YOLOS model)"),RVe.forEach(t),Q.forEach(t),fRo=i(xa),T(b_.$$.fragment,xa),gRo=i(xa),T(v_.$$.fragment,xa),xa.forEach(t),hRo=i(Vl),F_=n(Vl,"DIV",{class:!0});var rmo=s(F_);T(Pk.$$.fragment,rmo),uRo=i(rmo),cbe=n(rmo,"P",{});var dVt=s(cbe);pRo=r(dVt,"Register a new feature extractor for this class."),dVt.forEach(t),rmo.forEach(t),Vl.forEach(t),jlo=i(c),qd=n(c,"H2",{class:!0});var tmo=s(qd);T_=n(tmo,"A",{id:!0,class:!0,href:!0});var mVt=s(T_);fbe=n(mVt,"SPAN",{});var cVt=s(fbe);T(Bk.$$.fragment,cVt),cVt.forEach(t),mVt.forEach(t),_Ro=i(tmo),gbe=n(tmo,"SPAN",{});var fVt=s(gbe);bRo=r(fVt,"AutoImageProcessor"),fVt.forEach(t),tmo.forEach(t),Dlo=i(c),qo=n(c,"DIV",{class:!0});var Xl=s(qo);T(Ik.$$.fragment,Xl),vRo=i(Xl),Nk=n(Xl,"P",{});var amo=s(Nk);FRo=r(amo,`This is a generic image processor class that will be instantiated as one of the image processor classes of the
library when created with the `),wz=n(amo,"A",{href:!0});var gVt=s(wz);TRo=r(gVt,"AutoImageProcessor.from_pretrained()"),gVt.forEach(t),MRo=r(amo," class method."),amo.forEach(t),ERo=i(Xl),qk=n(Xl,"P",{});var nmo=s(qk);CRo=r(nmo,"This class cannot be instantiated directly using "),hbe=n(nmo,"CODE",{});var hVt=s(hbe);wRo=r(hVt,"__init__()"),hVt.forEach(t),ARo=r(nmo," (throws an error)."),nmo.forEach(t),LRo=i(Xl),oo=n(Xl,"DIV",{class:!0});var $a=s(oo);T(jk.$$.fragment,$a),yRo=i($a),ube=n($a,"P",{});var uVt=s(ube);xRo=r(uVt,"Instantiate one of the image processor classes of the library from a pretrained model vocabulary."),uVt.forEach(t),$Ro=i($a),cn=n($a,"P",{});var nx=s(cn);kRo=r(nx,"The image processor class to instantiate is selected based on the "),pbe=n(nx,"CODE",{});var pVt=s(pbe);SRo=r(pVt,"model_type"),pVt.forEach(t),RRo=r(nx,` property of the config object
(either passed as an argument or loaded from `),_be=n(nx,"CODE",{});var _Vt=s(_be);PRo=r(_Vt,"pretrained_model_name_or_path"),_Vt.forEach(t),BRo=r(nx,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),bbe=n(nx,"CODE",{});var bVt=s(bbe);IRo=r(bVt,"pretrained_model_name_or_path"),bVt.forEach(t),NRo=r(nx,":"),nx.forEach(t),qRo=i($a),re=n($a,"UL",{});var ae=s(re);M_=n(ae,"LI",{});var PVe=s(M_);vbe=n(PVe,"STRONG",{});var vVt=s(vbe);jRo=r(vVt,"beit"),vVt.forEach(t),DRo=r(PVe," \u2014 "),Az=n(PVe,"A",{href:!0});var FVt=s(Az);GRo=r(FVt,"BeitImageProcessor"),FVt.forEach(t),ORo=r(PVe," (BEiT model)"),PVe.forEach(t),VRo=i(ae),E_=n(ae,"LI",{});var BVe=s(E_);Fbe=n(BVe,"STRONG",{});var TVt=s(Fbe);XRo=r(TVt,"clip"),TVt.forEach(t),zRo=r(BVe," \u2014 "),Lz=n(BVe,"A",{href:!0});var MVt=s(Lz);QRo=r(MVt,"CLIPImageProcessor"),MVt.forEach(t),WRo=r(BVe," (CLIP model)"),BVe.forEach(t),URo=i(ae),C_=n(ae,"LI",{});var IVe=s(C_);Tbe=n(IVe,"STRONG",{});var EVt=s(Tbe);HRo=r(EVt,"convnext"),EVt.forEach(t),JRo=r(IVe," \u2014 "),yz=n(IVe,"A",{href:!0});var CVt=s(yz);YRo=r(CVt,"ConvNextImageProcessor"),CVt.forEach(t),ZRo=r(IVe," (ConvNeXT model)"),IVe.forEach(t),KRo=i(ae),w_=n(ae,"LI",{});var NVe=s(w_);Mbe=n(NVe,"STRONG",{});var wVt=s(Mbe);ePo=r(wVt,"cvt"),wVt.forEach(t),oPo=r(NVe," \u2014 "),xz=n(NVe,"A",{href:!0});var AVt=s(xz);rPo=r(AVt,"ConvNextImageProcessor"),AVt.forEach(t),tPo=r(NVe," (CvT model)"),NVe.forEach(t),aPo=i(ae),A_=n(ae,"LI",{});var qVe=s(A_);Ebe=n(qVe,"STRONG",{});var LVt=s(Ebe);nPo=r(LVt,"data2vec-vision"),LVt.forEach(t),sPo=r(qVe," \u2014 "),$z=n(qVe,"A",{href:!0});var yVt=s($z);lPo=r(yVt,"BeitImageProcessor"),yVt.forEach(t),iPo=r(qVe," (Data2VecVision model)"),qVe.forEach(t),dPo=i(ae),L_=n(ae,"LI",{});var jVe=s(L_);Cbe=n(jVe,"STRONG",{});var xVt=s(Cbe);mPo=r(xVt,"deit"),xVt.forEach(t),cPo=r(jVe," \u2014 "),kz=n(jVe,"A",{href:!0});var $Vt=s(kz);fPo=r($Vt,"DeiTImageProcessor"),$Vt.forEach(t),gPo=r(jVe," (DeiT model)"),jVe.forEach(t),hPo=i(ae),y_=n(ae,"LI",{});var DVe=s(y_);wbe=n(DVe,"STRONG",{});var kVt=s(wbe);uPo=r(kVt,"dpt"),kVt.forEach(t),pPo=r(DVe," \u2014 "),Sz=n(DVe,"A",{href:!0});var SVt=s(Sz);_Po=r(SVt,"DPTImageProcessor"),SVt.forEach(t),bPo=r(DVe," (DPT model)"),DVe.forEach(t),vPo=i(ae),x_=n(ae,"LI",{});var GVe=s(x_);Abe=n(GVe,"STRONG",{});var RVt=s(Abe);FPo=r(RVt,"flava"),RVt.forEach(t),TPo=r(GVe," \u2014 "),Rz=n(GVe,"A",{href:!0});var PVt=s(Rz);MPo=r(PVt,"FlavaImageProcessor"),PVt.forEach(t),EPo=r(GVe," (FLAVA model)"),GVe.forEach(t),CPo=i(ae),$_=n(ae,"LI",{});var OVe=s($_);Lbe=n(OVe,"STRONG",{});var BVt=s(Lbe);wPo=r(BVt,"glpn"),BVt.forEach(t),APo=r(OVe," \u2014 "),Pz=n(OVe,"A",{href:!0});var IVt=s(Pz);LPo=r(IVt,"GLPNImageProcessor"),IVt.forEach(t),yPo=r(OVe," (GLPN model)"),OVe.forEach(t),xPo=i(ae),k_=n(ae,"LI",{});var VVe=s(k_);ybe=n(VVe,"STRONG",{});var NVt=s(ybe);$Po=r(NVt,"groupvit"),NVt.forEach(t),kPo=r(VVe," \u2014 "),Bz=n(VVe,"A",{href:!0});var qVt=s(Bz);SPo=r(qVt,"CLIPImageProcessor"),qVt.forEach(t),RPo=r(VVe," (GroupViT model)"),VVe.forEach(t),PPo=i(ae),S_=n(ae,"LI",{});var XVe=s(S_);xbe=n(XVe,"STRONG",{});var jVt=s(xbe);BPo=r(jVt,"imagegpt"),jVt.forEach(t),IPo=r(XVe," \u2014 "),Iz=n(XVe,"A",{href:!0});var DVt=s(Iz);NPo=r(DVt,"ImageGPTImageProcessor"),DVt.forEach(t),qPo=r(XVe," (ImageGPT model)"),XVe.forEach(t),jPo=i(ae),R_=n(ae,"LI",{});var zVe=s(R_);$be=n(zVe,"STRONG",{});var GVt=s($be);DPo=r(GVt,"layoutlmv2"),GVt.forEach(t),GPo=r(zVe," \u2014 "),Nz=n(zVe,"A",{href:!0});var OVt=s(Nz);OPo=r(OVt,"LayoutLMv2ImageProcessor"),OVt.forEach(t),VPo=r(zVe," (LayoutLMv2 model)"),zVe.forEach(t),XPo=i(ae),P_=n(ae,"LI",{});var QVe=s(P_);kbe=n(QVe,"STRONG",{});var VVt=s(kbe);zPo=r(VVt,"layoutlmv3"),VVt.forEach(t),QPo=r(QVe," \u2014 "),qz=n(QVe,"A",{href:!0});var XVt=s(qz);WPo=r(XVt,"LayoutLMv3ImageProcessor"),XVt.forEach(t),UPo=r(QVe," (LayoutLMv3 model)"),QVe.forEach(t),HPo=i(ae),B_=n(ae,"LI",{});var WVe=s(B_);Sbe=n(WVe,"STRONG",{});var zVt=s(Sbe);JPo=r(zVt,"levit"),zVt.forEach(t),YPo=r(WVe," \u2014 "),jz=n(WVe,"A",{href:!0});var QVt=s(jz);ZPo=r(QVt,"LevitImageProcessor"),QVt.forEach(t),KPo=r(WVe," (LeViT model)"),WVe.forEach(t),eBo=i(ae),I_=n(ae,"LI",{});var UVe=s(I_);Rbe=n(UVe,"STRONG",{});var WVt=s(Rbe);oBo=r(WVt,"mobilevit"),WVt.forEach(t),rBo=r(UVe," \u2014 "),Dz=n(UVe,"A",{href:!0});var UVt=s(Dz);tBo=r(UVt,"MobileViTImageProcessor"),UVt.forEach(t),aBo=r(UVe," (MobileViT model)"),UVe.forEach(t),nBo=i(ae),N_=n(ae,"LI",{});var HVe=s(N_);Pbe=n(HVe,"STRONG",{});var HVt=s(Pbe);sBo=r(HVt,"perceiver"),HVt.forEach(t),lBo=r(HVe," \u2014 "),Gz=n(HVe,"A",{href:!0});var JVt=s(Gz);iBo=r(JVt,"PerceiverImageProcessor"),JVt.forEach(t),dBo=r(HVe," (Perceiver model)"),HVe.forEach(t),mBo=i(ae),q_=n(ae,"LI",{});var JVe=s(q_);Bbe=n(JVe,"STRONG",{});var YVt=s(Bbe);cBo=r(YVt,"poolformer"),YVt.forEach(t),fBo=r(JVe," \u2014 "),Oz=n(JVe,"A",{href:!0});var ZVt=s(Oz);gBo=r(ZVt,"PoolFormerImageProcessor"),ZVt.forEach(t),hBo=r(JVe," (PoolFormer model)"),JVe.forEach(t),uBo=i(ae),j_=n(ae,"LI",{});var YVe=s(j_);Ibe=n(YVe,"STRONG",{});var KVt=s(Ibe);pBo=r(KVt,"regnet"),KVt.forEach(t),_Bo=r(YVe," \u2014 "),Vz=n(YVe,"A",{href:!0});var eXt=s(Vz);bBo=r(eXt,"ConvNextImageProcessor"),eXt.forEach(t),vBo=r(YVe," (RegNet model)"),YVe.forEach(t),FBo=i(ae),D_=n(ae,"LI",{});var ZVe=s(D_);Nbe=n(ZVe,"STRONG",{});var oXt=s(Nbe);TBo=r(oXt,"resnet"),oXt.forEach(t),MBo=r(ZVe," \u2014 "),Xz=n(ZVe,"A",{href:!0});var rXt=s(Xz);EBo=r(rXt,"ConvNextImageProcessor"),rXt.forEach(t),CBo=r(ZVe," (ResNet model)"),ZVe.forEach(t),wBo=i(ae),G_=n(ae,"LI",{});var KVe=s(G_);qbe=n(KVe,"STRONG",{});var tXt=s(qbe);ABo=r(tXt,"segformer"),tXt.forEach(t),LBo=r(KVe," \u2014 "),zz=n(KVe,"A",{href:!0});var aXt=s(zz);yBo=r(aXt,"SegformerImageProcessor"),aXt.forEach(t),xBo=r(KVe," (SegFormer model)"),KVe.forEach(t),$Bo=i(ae),O_=n(ae,"LI",{});var eXe=s(O_);jbe=n(eXe,"STRONG",{});var nXt=s(jbe);kBo=r(nXt,"swin"),nXt.forEach(t),SBo=r(eXe," \u2014 "),Qz=n(eXe,"A",{href:!0});var sXt=s(Qz);RBo=r(sXt,"ViTImageProcessor"),sXt.forEach(t),PBo=r(eXe," (Swin Transformer model)"),eXe.forEach(t),BBo=i(ae),V_=n(ae,"LI",{});var oXe=s(V_);Dbe=n(oXe,"STRONG",{});var lXt=s(Dbe);IBo=r(lXt,"swinv2"),lXt.forEach(t),NBo=r(oXe," \u2014 "),Wz=n(oXe,"A",{href:!0});var iXt=s(Wz);qBo=r(iXt,"ViTImageProcessor"),iXt.forEach(t),jBo=r(oXe," (Swin Transformer V2 model)"),oXe.forEach(t),DBo=i(ae),X_=n(ae,"LI",{});var rXe=s(X_);Gbe=n(rXe,"STRONG",{});var dXt=s(Gbe);GBo=r(dXt,"van"),dXt.forEach(t),OBo=r(rXe," \u2014 "),Uz=n(rXe,"A",{href:!0});var mXt=s(Uz);VBo=r(mXt,"ConvNextImageProcessor"),mXt.forEach(t),XBo=r(rXe," (VAN model)"),rXe.forEach(t),zBo=i(ae),z_=n(ae,"LI",{});var tXe=s(z_);Obe=n(tXe,"STRONG",{});var cXt=s(Obe);QBo=r(cXt,"videomae"),cXt.forEach(t),WBo=r(tXe," \u2014 "),Hz=n(tXe,"A",{href:!0});var fXt=s(Hz);UBo=r(fXt,"VideoMAEImageProcessor"),fXt.forEach(t),HBo=r(tXe," (VideoMAE model)"),tXe.forEach(t),JBo=i(ae),Q_=n(ae,"LI",{});var aXe=s(Q_);Vbe=n(aXe,"STRONG",{});var gXt=s(Vbe);YBo=r(gXt,"vilt"),gXt.forEach(t),ZBo=r(aXe," \u2014 "),Jz=n(aXe,"A",{href:!0});var hXt=s(Jz);KBo=r(hXt,"ViltImageProcessor"),hXt.forEach(t),eIo=r(aXe," (ViLT model)"),aXe.forEach(t),oIo=i(ae),W_=n(ae,"LI",{});var nXe=s(W_);Xbe=n(nXe,"STRONG",{});var uXt=s(Xbe);rIo=r(uXt,"vit"),uXt.forEach(t),tIo=r(nXe," \u2014 "),Yz=n(nXe,"A",{href:!0});var pXt=s(Yz);aIo=r(pXt,"ViTImageProcessor"),pXt.forEach(t),nIo=r(nXe," (ViT model)"),nXe.forEach(t),sIo=i(ae),U_=n(ae,"LI",{});var sXe=s(U_);zbe=n(sXe,"STRONG",{});var _Xt=s(zbe);lIo=r(_Xt,"vit_mae"),_Xt.forEach(t),iIo=r(sXe," \u2014 "),Zz=n(sXe,"A",{href:!0});var bXt=s(Zz);dIo=r(bXt,"ViTImageProcessor"),bXt.forEach(t),mIo=r(sXe," (ViTMAE model)"),sXe.forEach(t),cIo=i(ae),H_=n(ae,"LI",{});var lXe=s(H_);Qbe=n(lXe,"STRONG",{});var vXt=s(Qbe);fIo=r(vXt,"vit_msn"),vXt.forEach(t),gIo=r(lXe," \u2014 "),Kz=n(lXe,"A",{href:!0});var FXt=s(Kz);hIo=r(FXt,"ViTImageProcessor"),FXt.forEach(t),uIo=r(lXe," (ViTMSN model)"),lXe.forEach(t),pIo=i(ae),J_=n(ae,"LI",{});var iXe=s(J_);Wbe=n(iXe,"STRONG",{});var TXt=s(Wbe);_Io=r(TXt,"xclip"),TXt.forEach(t),bIo=r(iXe," \u2014 "),eQ=n(iXe,"A",{href:!0});var MXt=s(eQ);vIo=r(MXt,"CLIPImageProcessor"),MXt.forEach(t),FIo=r(iXe," (X-CLIP model)"),iXe.forEach(t),ae.forEach(t),TIo=i($a),T(Y_.$$.fragment,$a),MIo=i($a),T(Z_.$$.fragment,$a),$a.forEach(t),EIo=i(Xl),K_=n(Xl,"DIV",{class:!0});var smo=s(K_);T(Dk.$$.fragment,smo),CIo=i(smo),Ube=n(smo,"P",{});var EXt=s(Ube);wIo=r(EXt,"Register a new image processor for this class."),EXt.forEach(t),smo.forEach(t),Xl.forEach(t),Glo=i(c),jd=n(c,"H2",{class:!0});var lmo=s(jd);e1=n(lmo,"A",{id:!0,class:!0,href:!0});var CXt=s(e1);Hbe=n(CXt,"SPAN",{});var wXt=s(Hbe);T(Gk.$$.fragment,wXt),wXt.forEach(t),CXt.forEach(t),AIo=i(lmo),Jbe=n(lmo,"SPAN",{});var AXt=s(Jbe);LIo=r(AXt,"AutoProcessor"),AXt.forEach(t),lmo.forEach(t),Olo=i(c),jo=n(c,"DIV",{class:!0});var zl=s(jo);T(Ok.$$.fragment,zl),yIo=i(zl),Vk=n(zl,"P",{});var imo=s(Vk);xIo=r(imo,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),oQ=n(imo,"A",{href:!0});var LXt=s(oQ);$Io=r(LXt,"AutoProcessor.from_pretrained()"),LXt.forEach(t),kIo=r(imo," class method."),imo.forEach(t),SIo=i(zl),Xk=n(zl,"P",{});var dmo=s(Xk);RIo=r(dmo,"This class cannot be instantiated directly using "),Ybe=n(dmo,"CODE",{});var yXt=s(Ybe);PIo=r(yXt,"__init__()"),yXt.forEach(t),BIo=r(dmo," (throws an error)."),dmo.forEach(t),IIo=i(zl),ro=n(zl,"DIV",{class:!0});var ka=s(ro);T(zk.$$.fragment,ka),NIo=i(ka),Zbe=n(ka,"P",{});var xXt=s(Zbe);qIo=r(xXt,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),xXt.forEach(t),jIo=i(ka),Dd=n(ka,"P",{});var cfe=s(Dd);DIo=r(cfe,"The processor class to instantiate is selected based on the "),Kbe=n(cfe,"CODE",{});var $Xt=s(Kbe);GIo=r($Xt,"model_type"),$Xt.forEach(t),OIo=r(cfe,` property of the config object (either
passed as an argument or loaded from `),eve=n(cfe,"CODE",{});var kXt=s(eve);VIo=r(kXt,"pretrained_model_name_or_path"),kXt.forEach(t),XIo=r(cfe," if possible):"),cfe.forEach(t),zIo=i(ka),ie=n(ka,"UL",{});var ce=s(ie);o1=n(ce,"LI",{});var dXe=s(o1);ove=n(dXe,"STRONG",{});var SXt=s(ove);QIo=r(SXt,"clip"),SXt.forEach(t),WIo=r(dXe," \u2014 "),rQ=n(dXe,"A",{href:!0});var RXt=s(rQ);UIo=r(RXt,"CLIPProcessor"),RXt.forEach(t),HIo=r(dXe," (CLIP model)"),dXe.forEach(t),JIo=i(ce),r1=n(ce,"LI",{});var mXe=s(r1);rve=n(mXe,"STRONG",{});var PXt=s(rve);YIo=r(PXt,"clipseg"),PXt.forEach(t),ZIo=r(mXe," \u2014 "),tQ=n(mXe,"A",{href:!0});var BXt=s(tQ);KIo=r(BXt,"CLIPSegProcessor"),BXt.forEach(t),eNo=r(mXe," (CLIPSeg model)"),mXe.forEach(t),oNo=i(ce),t1=n(ce,"LI",{});var cXe=s(t1);tve=n(cXe,"STRONG",{});var IXt=s(tve);rNo=r(IXt,"flava"),IXt.forEach(t),tNo=r(cXe," \u2014 "),aQ=n(cXe,"A",{href:!0});var NXt=s(aQ);aNo=r(NXt,"FlavaProcessor"),NXt.forEach(t),nNo=r(cXe," (FLAVA model)"),cXe.forEach(t),sNo=i(ce),a1=n(ce,"LI",{});var fXe=s(a1);ave=n(fXe,"STRONG",{});var qXt=s(ave);lNo=r(qXt,"groupvit"),qXt.forEach(t),iNo=r(fXe," \u2014 "),nQ=n(fXe,"A",{href:!0});var jXt=s(nQ);dNo=r(jXt,"CLIPProcessor"),jXt.forEach(t),mNo=r(fXe," (GroupViT model)"),fXe.forEach(t),cNo=i(ce),n1=n(ce,"LI",{});var gXe=s(n1);nve=n(gXe,"STRONG",{});var DXt=s(nve);fNo=r(DXt,"layoutlmv2"),DXt.forEach(t),gNo=r(gXe," \u2014 "),sQ=n(gXe,"A",{href:!0});var GXt=s(sQ);hNo=r(GXt,"LayoutLMv2Processor"),GXt.forEach(t),uNo=r(gXe," (LayoutLMv2 model)"),gXe.forEach(t),pNo=i(ce),s1=n(ce,"LI",{});var hXe=s(s1);sve=n(hXe,"STRONG",{});var OXt=s(sve);_No=r(OXt,"layoutlmv3"),OXt.forEach(t),bNo=r(hXe," \u2014 "),lQ=n(hXe,"A",{href:!0});var VXt=s(lQ);vNo=r(VXt,"LayoutLMv3Processor"),VXt.forEach(t),FNo=r(hXe," (LayoutLMv3 model)"),hXe.forEach(t),TNo=i(ce),l1=n(ce,"LI",{});var uXe=s(l1);lve=n(uXe,"STRONG",{});var XXt=s(lve);MNo=r(XXt,"layoutxlm"),XXt.forEach(t),ENo=r(uXe," \u2014 "),iQ=n(uXe,"A",{href:!0});var zXt=s(iQ);CNo=r(zXt,"LayoutXLMProcessor"),zXt.forEach(t),wNo=r(uXe," (LayoutXLM model)"),uXe.forEach(t),ANo=i(ce),i1=n(ce,"LI",{});var pXe=s(i1);ive=n(pXe,"STRONG",{});var QXt=s(ive);LNo=r(QXt,"markuplm"),QXt.forEach(t),yNo=r(pXe," \u2014 "),dQ=n(pXe,"A",{href:!0});var WXt=s(dQ);xNo=r(WXt,"MarkupLMProcessor"),WXt.forEach(t),$No=r(pXe," (MarkupLM model)"),pXe.forEach(t),kNo=i(ce),d1=n(ce,"LI",{});var _Xe=s(d1);dve=n(_Xe,"STRONG",{});var UXt=s(dve);SNo=r(UXt,"owlvit"),UXt.forEach(t),RNo=r(_Xe," \u2014 "),mQ=n(_Xe,"A",{href:!0});var HXt=s(mQ);PNo=r(HXt,"OwlViTProcessor"),HXt.forEach(t),BNo=r(_Xe," (OWL-ViT model)"),_Xe.forEach(t),INo=i(ce),m1=n(ce,"LI",{});var bXe=s(m1);mve=n(bXe,"STRONG",{});var JXt=s(mve);NNo=r(JXt,"sew"),JXt.forEach(t),qNo=r(bXe," \u2014 "),cQ=n(bXe,"A",{href:!0});var YXt=s(cQ);jNo=r(YXt,"Wav2Vec2Processor"),YXt.forEach(t),DNo=r(bXe," (SEW model)"),bXe.forEach(t),GNo=i(ce),c1=n(ce,"LI",{});var vXe=s(c1);cve=n(vXe,"STRONG",{});var ZXt=s(cve);ONo=r(ZXt,"sew-d"),ZXt.forEach(t),VNo=r(vXe," \u2014 "),fQ=n(vXe,"A",{href:!0});var KXt=s(fQ);XNo=r(KXt,"Wav2Vec2Processor"),KXt.forEach(t),zNo=r(vXe," (SEW-D model)"),vXe.forEach(t),QNo=i(ce),f1=n(ce,"LI",{});var FXe=s(f1);fve=n(FXe,"STRONG",{});var ezt=s(fve);WNo=r(ezt,"speech_to_text"),ezt.forEach(t),UNo=r(FXe," \u2014 "),gQ=n(FXe,"A",{href:!0});var ozt=s(gQ);HNo=r(ozt,"Speech2TextProcessor"),ozt.forEach(t),JNo=r(FXe," (Speech2Text model)"),FXe.forEach(t),YNo=i(ce),g1=n(ce,"LI",{});var TXe=s(g1);gve=n(TXe,"STRONG",{});var rzt=s(gve);ZNo=r(rzt,"speech_to_text_2"),rzt.forEach(t),KNo=r(TXe," \u2014 "),hQ=n(TXe,"A",{href:!0});var tzt=s(hQ);eqo=r(tzt,"Speech2Text2Processor"),tzt.forEach(t),oqo=r(TXe," (Speech2Text2 model)"),TXe.forEach(t),rqo=i(ce),h1=n(ce,"LI",{});var MXe=s(h1);hve=n(MXe,"STRONG",{});var azt=s(hve);tqo=r(azt,"trocr"),azt.forEach(t),aqo=r(MXe," \u2014 "),uQ=n(MXe,"A",{href:!0});var nzt=s(uQ);nqo=r(nzt,"TrOCRProcessor"),nzt.forEach(t),sqo=r(MXe," (TrOCR model)"),MXe.forEach(t),lqo=i(ce),u1=n(ce,"LI",{});var EXe=s(u1);uve=n(EXe,"STRONG",{});var szt=s(uve);iqo=r(szt,"unispeech"),szt.forEach(t),dqo=r(EXe," \u2014 "),pQ=n(EXe,"A",{href:!0});var lzt=s(pQ);mqo=r(lzt,"Wav2Vec2Processor"),lzt.forEach(t),cqo=r(EXe," (UniSpeech model)"),EXe.forEach(t),fqo=i(ce),p1=n(ce,"LI",{});var CXe=s(p1);pve=n(CXe,"STRONG",{});var izt=s(pve);gqo=r(izt,"unispeech-sat"),izt.forEach(t),hqo=r(CXe," \u2014 "),_Q=n(CXe,"A",{href:!0});var dzt=s(_Q);uqo=r(dzt,"Wav2Vec2Processor"),dzt.forEach(t),pqo=r(CXe," (UniSpeechSat model)"),CXe.forEach(t),_qo=i(ce),_1=n(ce,"LI",{});var wXe=s(_1);_ve=n(wXe,"STRONG",{});var mzt=s(_ve);bqo=r(mzt,"vilt"),mzt.forEach(t),vqo=r(wXe," \u2014 "),bQ=n(wXe,"A",{href:!0});var czt=s(bQ);Fqo=r(czt,"ViltProcessor"),czt.forEach(t),Tqo=r(wXe," (ViLT model)"),wXe.forEach(t),Mqo=i(ce),b1=n(ce,"LI",{});var AXe=s(b1);bve=n(AXe,"STRONG",{});var fzt=s(bve);Eqo=r(fzt,"vision-text-dual-encoder"),fzt.forEach(t),Cqo=r(AXe," \u2014 "),vQ=n(AXe,"A",{href:!0});var gzt=s(vQ);wqo=r(gzt,"VisionTextDualEncoderProcessor"),gzt.forEach(t),Aqo=r(AXe," (VisionTextDualEncoder model)"),AXe.forEach(t),Lqo=i(ce),v1=n(ce,"LI",{});var LXe=s(v1);vve=n(LXe,"STRONG",{});var hzt=s(vve);yqo=r(hzt,"wav2vec2"),hzt.forEach(t),xqo=r(LXe," \u2014 "),FQ=n(LXe,"A",{href:!0});var uzt=s(FQ);$qo=r(uzt,"Wav2Vec2Processor"),uzt.forEach(t),kqo=r(LXe," (Wav2Vec2 model)"),LXe.forEach(t),Sqo=i(ce),F1=n(ce,"LI",{});var yXe=s(F1);Fve=n(yXe,"STRONG",{});var pzt=s(Fve);Rqo=r(pzt,"wav2vec2-conformer"),pzt.forEach(t),Pqo=r(yXe," \u2014 "),TQ=n(yXe,"A",{href:!0});var _zt=s(TQ);Bqo=r(_zt,"Wav2Vec2Processor"),_zt.forEach(t),Iqo=r(yXe," (Wav2Vec2-Conformer model)"),yXe.forEach(t),Nqo=i(ce),T1=n(ce,"LI",{});var xXe=s(T1);Tve=n(xXe,"STRONG",{});var bzt=s(Tve);qqo=r(bzt,"wavlm"),bzt.forEach(t),jqo=r(xXe," \u2014 "),MQ=n(xXe,"A",{href:!0});var vzt=s(MQ);Dqo=r(vzt,"Wav2Vec2Processor"),vzt.forEach(t),Gqo=r(xXe," (WavLM model)"),xXe.forEach(t),Oqo=i(ce),M1=n(ce,"LI",{});var $Xe=s(M1);Mve=n($Xe,"STRONG",{});var Fzt=s(Mve);Vqo=r(Fzt,"whisper"),Fzt.forEach(t),Xqo=r($Xe," \u2014 "),EQ=n($Xe,"A",{href:!0});var Tzt=s(EQ);zqo=r(Tzt,"WhisperProcessor"),Tzt.forEach(t),Qqo=r($Xe," (Whisper model)"),$Xe.forEach(t),Wqo=i(ce),E1=n(ce,"LI",{});var kXe=s(E1);Eve=n(kXe,"STRONG",{});var Mzt=s(Eve);Uqo=r(Mzt,"xclip"),Mzt.forEach(t),Hqo=r(kXe," \u2014 "),CQ=n(kXe,"A",{href:!0});var Ezt=s(CQ);Jqo=r(Ezt,"XCLIPProcessor"),Ezt.forEach(t),Yqo=r(kXe," (X-CLIP model)"),kXe.forEach(t),ce.forEach(t),Zqo=i(ka),T(C1.$$.fragment,ka),Kqo=i(ka),T(w1.$$.fragment,ka),ka.forEach(t),ejo=i(zl),A1=n(zl,"DIV",{class:!0});var mmo=s(A1);T(Qk.$$.fragment,mmo),ojo=i(mmo),Cve=n(mmo,"P",{});var Czt=s(Cve);rjo=r(Czt,"Register a new processor for this class."),Czt.forEach(t),mmo.forEach(t),zl.forEach(t),Vlo=i(c),Gd=n(c,"H2",{class:!0});var cmo=s(Gd);L1=n(cmo,"A",{id:!0,class:!0,href:!0});var wzt=s(L1);wve=n(wzt,"SPAN",{});var Azt=s(wve);T(Wk.$$.fragment,Azt),Azt.forEach(t),wzt.forEach(t),tjo=i(cmo),Ave=n(cmo,"SPAN",{});var Lzt=s(Ave);ajo=r(Lzt,"AutoModel"),Lzt.forEach(t),cmo.forEach(t),Xlo=i(c),Do=n(c,"DIV",{class:!0});var Ql=s(Do);T(Uk.$$.fragment,Ql),njo=i(Ql),Od=n(Ql,"P",{});var ffe=s(Od);sjo=r(ffe,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),wQ=n(ffe,"A",{href:!0});var yzt=s(wQ);ljo=r(yzt,"from_pretrained()"),yzt.forEach(t),ijo=r(ffe," class method or the "),AQ=n(ffe,"A",{href:!0});var xzt=s(AQ);djo=r(xzt,"from_config()"),xzt.forEach(t),mjo=r(ffe,` class
method.`),ffe.forEach(t),cjo=i(Ql),Hk=n(Ql,"P",{});var fmo=s(Hk);fjo=r(fmo,"This class cannot be instantiated directly using "),Lve=n(fmo,"CODE",{});var $zt=s(Lve);gjo=r($zt,"__init__()"),$zt.forEach(t),hjo=r(fmo," (throws an error)."),fmo.forEach(t),ujo=i(Ql),At=n(Ql,"DIV",{class:!0});var sx=s(At);T(Jk.$$.fragment,sx),pjo=i(sx),yve=n(sx,"P",{});var kzt=s(yve);_jo=r(kzt,"Instantiates one of the base model classes of the library from a configuration."),kzt.forEach(t),bjo=i(sx),Vd=n(sx,"P",{});var gfe=s(Vd);vjo=r(gfe,`Note:
Loading a model from its configuration file does `),xve=n(gfe,"STRONG",{});var Szt=s(xve);Fjo=r(Szt,"not"),Szt.forEach(t),Tjo=r(gfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),LQ=n(gfe,"A",{href:!0});var Rzt=s(LQ);Mjo=r(Rzt,"from_pretrained()"),Rzt.forEach(t),Ejo=r(gfe," to load the model weights."),gfe.forEach(t),Cjo=i(sx),T(y1.$$.fragment,sx),sx.forEach(t),wjo=i(Ql),to=n(Ql,"DIV",{class:!0});var Sa=s(to);T(Yk.$$.fragment,Sa),Ajo=i(Sa),$ve=n(Sa,"P",{});var Pzt=s($ve);Ljo=r(Pzt,"Instantiate one of the base model classes of the library from a pretrained model."),Pzt.forEach(t),yjo=i(Sa),fn=n(Sa,"P",{});var lx=s(fn);xjo=r(lx,"The model class to instantiate is selected based on the "),kve=n(lx,"CODE",{});var Bzt=s(kve);$jo=r(Bzt,"model_type"),Bzt.forEach(t),kjo=r(lx,` property of the config object (either
passed as an argument or loaded from `),Sve=n(lx,"CODE",{});var Izt=s(Sve);Sjo=r(Izt,"pretrained_model_name_or_path"),Izt.forEach(t),Rjo=r(lx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rve=n(lx,"CODE",{});var Nzt=s(Rve);Pjo=r(Nzt,"pretrained_model_name_or_path"),Nzt.forEach(t),Bjo=r(lx,":"),lx.forEach(t),Ijo=i(Sa),y=n(Sa,"UL",{});var x=s(y);x1=n(x,"LI",{});var SXe=s(x1);Pve=n(SXe,"STRONG",{});var qzt=s(Pve);Njo=r(qzt,"albert"),qzt.forEach(t),qjo=r(SXe," \u2014 "),yQ=n(SXe,"A",{href:!0});var jzt=s(yQ);jjo=r(jzt,"AlbertModel"),jzt.forEach(t),Djo=r(SXe," (ALBERT model)"),SXe.forEach(t),Gjo=i(x),$1=n(x,"LI",{});var RXe=s($1);Bve=n(RXe,"STRONG",{});var Dzt=s(Bve);Ojo=r(Dzt,"bart"),Dzt.forEach(t),Vjo=r(RXe," \u2014 "),xQ=n(RXe,"A",{href:!0});var Gzt=s(xQ);Xjo=r(Gzt,"BartModel"),Gzt.forEach(t),zjo=r(RXe," (BART model)"),RXe.forEach(t),Qjo=i(x),k1=n(x,"LI",{});var PXe=s(k1);Ive=n(PXe,"STRONG",{});var Ozt=s(Ive);Wjo=r(Ozt,"beit"),Ozt.forEach(t),Ujo=r(PXe," \u2014 "),$Q=n(PXe,"A",{href:!0});var Vzt=s($Q);Hjo=r(Vzt,"BeitModel"),Vzt.forEach(t),Jjo=r(PXe," (BEiT model)"),PXe.forEach(t),Yjo=i(x),S1=n(x,"LI",{});var BXe=s(S1);Nve=n(BXe,"STRONG",{});var Xzt=s(Nve);Zjo=r(Xzt,"bert"),Xzt.forEach(t),Kjo=r(BXe," \u2014 "),kQ=n(BXe,"A",{href:!0});var zzt=s(kQ);eDo=r(zzt,"BertModel"),zzt.forEach(t),oDo=r(BXe," (BERT model)"),BXe.forEach(t),rDo=i(x),R1=n(x,"LI",{});var IXe=s(R1);qve=n(IXe,"STRONG",{});var Qzt=s(qve);tDo=r(Qzt,"bert-generation"),Qzt.forEach(t),aDo=r(IXe," \u2014 "),SQ=n(IXe,"A",{href:!0});var Wzt=s(SQ);nDo=r(Wzt,"BertGenerationEncoder"),Wzt.forEach(t),sDo=r(IXe," (Bert Generation model)"),IXe.forEach(t),lDo=i(x),P1=n(x,"LI",{});var NXe=s(P1);jve=n(NXe,"STRONG",{});var Uzt=s(jve);iDo=r(Uzt,"big_bird"),Uzt.forEach(t),dDo=r(NXe," \u2014 "),RQ=n(NXe,"A",{href:!0});var Hzt=s(RQ);mDo=r(Hzt,"BigBirdModel"),Hzt.forEach(t),cDo=r(NXe," (BigBird model)"),NXe.forEach(t),fDo=i(x),B1=n(x,"LI",{});var qXe=s(B1);Dve=n(qXe,"STRONG",{});var Jzt=s(Dve);gDo=r(Jzt,"bigbird_pegasus"),Jzt.forEach(t),hDo=r(qXe," \u2014 "),PQ=n(qXe,"A",{href:!0});var Yzt=s(PQ);uDo=r(Yzt,"BigBirdPegasusModel"),Yzt.forEach(t),pDo=r(qXe," (BigBird-Pegasus model)"),qXe.forEach(t),_Do=i(x),I1=n(x,"LI",{});var jXe=s(I1);Gve=n(jXe,"STRONG",{});var Zzt=s(Gve);bDo=r(Zzt,"blenderbot"),Zzt.forEach(t),vDo=r(jXe," \u2014 "),BQ=n(jXe,"A",{href:!0});var Kzt=s(BQ);FDo=r(Kzt,"BlenderbotModel"),Kzt.forEach(t),TDo=r(jXe," (Blenderbot model)"),jXe.forEach(t),MDo=i(x),N1=n(x,"LI",{});var DXe=s(N1);Ove=n(DXe,"STRONG",{});var eQt=s(Ove);EDo=r(eQt,"blenderbot-small"),eQt.forEach(t),CDo=r(DXe," \u2014 "),IQ=n(DXe,"A",{href:!0});var oQt=s(IQ);wDo=r(oQt,"BlenderbotSmallModel"),oQt.forEach(t),ADo=r(DXe," (BlenderbotSmall model)"),DXe.forEach(t),LDo=i(x),q1=n(x,"LI",{});var GXe=s(q1);Vve=n(GXe,"STRONG",{});var rQt=s(Vve);yDo=r(rQt,"bloom"),rQt.forEach(t),xDo=r(GXe," \u2014 "),NQ=n(GXe,"A",{href:!0});var tQt=s(NQ);$Do=r(tQt,"BloomModel"),tQt.forEach(t),kDo=r(GXe," (BLOOM model)"),GXe.forEach(t),SDo=i(x),j1=n(x,"LI",{});var OXe=s(j1);Xve=n(OXe,"STRONG",{});var aQt=s(Xve);RDo=r(aQt,"camembert"),aQt.forEach(t),PDo=r(OXe," \u2014 "),qQ=n(OXe,"A",{href:!0});var nQt=s(qQ);BDo=r(nQt,"CamembertModel"),nQt.forEach(t),IDo=r(OXe," (CamemBERT model)"),OXe.forEach(t),NDo=i(x),D1=n(x,"LI",{});var VXe=s(D1);zve=n(VXe,"STRONG",{});var sQt=s(zve);qDo=r(sQt,"canine"),sQt.forEach(t),jDo=r(VXe," \u2014 "),jQ=n(VXe,"A",{href:!0});var lQt=s(jQ);DDo=r(lQt,"CanineModel"),lQt.forEach(t),GDo=r(VXe," (CANINE model)"),VXe.forEach(t),ODo=i(x),G1=n(x,"LI",{});var XXe=s(G1);Qve=n(XXe,"STRONG",{});var iQt=s(Qve);VDo=r(iQt,"clip"),iQt.forEach(t),XDo=r(XXe," \u2014 "),DQ=n(XXe,"A",{href:!0});var dQt=s(DQ);zDo=r(dQt,"CLIPModel"),dQt.forEach(t),QDo=r(XXe," (CLIP model)"),XXe.forEach(t),WDo=i(x),O1=n(x,"LI",{});var zXe=s(O1);Wve=n(zXe,"STRONG",{});var mQt=s(Wve);UDo=r(mQt,"clipseg"),mQt.forEach(t),HDo=r(zXe," \u2014 "),GQ=n(zXe,"A",{href:!0});var cQt=s(GQ);JDo=r(cQt,"CLIPSegModel"),cQt.forEach(t),YDo=r(zXe," (CLIPSeg model)"),zXe.forEach(t),ZDo=i(x),V1=n(x,"LI",{});var QXe=s(V1);Uve=n(QXe,"STRONG",{});var fQt=s(Uve);KDo=r(fQt,"codegen"),fQt.forEach(t),eGo=r(QXe," \u2014 "),OQ=n(QXe,"A",{href:!0});var gQt=s(OQ);oGo=r(gQt,"CodeGenModel"),gQt.forEach(t),rGo=r(QXe," (CodeGen model)"),QXe.forEach(t),tGo=i(x),X1=n(x,"LI",{});var WXe=s(X1);Hve=n(WXe,"STRONG",{});var hQt=s(Hve);aGo=r(hQt,"conditional_detr"),hQt.forEach(t),nGo=r(WXe," \u2014 "),VQ=n(WXe,"A",{href:!0});var uQt=s(VQ);sGo=r(uQt,"ConditionalDetrModel"),uQt.forEach(t),lGo=r(WXe," (Conditional DETR model)"),WXe.forEach(t),iGo=i(x),z1=n(x,"LI",{});var UXe=s(z1);Jve=n(UXe,"STRONG",{});var pQt=s(Jve);dGo=r(pQt,"convbert"),pQt.forEach(t),mGo=r(UXe," \u2014 "),XQ=n(UXe,"A",{href:!0});var _Qt=s(XQ);cGo=r(_Qt,"ConvBertModel"),_Qt.forEach(t),fGo=r(UXe," (ConvBERT model)"),UXe.forEach(t),gGo=i(x),Q1=n(x,"LI",{});var HXe=s(Q1);Yve=n(HXe,"STRONG",{});var bQt=s(Yve);hGo=r(bQt,"convnext"),bQt.forEach(t),uGo=r(HXe," \u2014 "),zQ=n(HXe,"A",{href:!0});var vQt=s(zQ);pGo=r(vQt,"ConvNextModel"),vQt.forEach(t),_Go=r(HXe," (ConvNeXT model)"),HXe.forEach(t),bGo=i(x),W1=n(x,"LI",{});var JXe=s(W1);Zve=n(JXe,"STRONG",{});var FQt=s(Zve);vGo=r(FQt,"ctrl"),FQt.forEach(t),FGo=r(JXe," \u2014 "),QQ=n(JXe,"A",{href:!0});var TQt=s(QQ);TGo=r(TQt,"CTRLModel"),TQt.forEach(t),MGo=r(JXe," (CTRL model)"),JXe.forEach(t),EGo=i(x),U1=n(x,"LI",{});var YXe=s(U1);Kve=n(YXe,"STRONG",{});var MQt=s(Kve);CGo=r(MQt,"cvt"),MQt.forEach(t),wGo=r(YXe," \u2014 "),WQ=n(YXe,"A",{href:!0});var EQt=s(WQ);AGo=r(EQt,"CvtModel"),EQt.forEach(t),LGo=r(YXe," (CvT model)"),YXe.forEach(t),yGo=i(x),H1=n(x,"LI",{});var ZXe=s(H1);eFe=n(ZXe,"STRONG",{});var CQt=s(eFe);xGo=r(CQt,"data2vec-audio"),CQt.forEach(t),$Go=r(ZXe," \u2014 "),UQ=n(ZXe,"A",{href:!0});var wQt=s(UQ);kGo=r(wQt,"Data2VecAudioModel"),wQt.forEach(t),SGo=r(ZXe," (Data2VecAudio model)"),ZXe.forEach(t),RGo=i(x),J1=n(x,"LI",{});var KXe=s(J1);oFe=n(KXe,"STRONG",{});var AQt=s(oFe);PGo=r(AQt,"data2vec-text"),AQt.forEach(t),BGo=r(KXe," \u2014 "),HQ=n(KXe,"A",{href:!0});var LQt=s(HQ);IGo=r(LQt,"Data2VecTextModel"),LQt.forEach(t),NGo=r(KXe," (Data2VecText model)"),KXe.forEach(t),qGo=i(x),Y1=n(x,"LI",{});var eze=s(Y1);rFe=n(eze,"STRONG",{});var yQt=s(rFe);jGo=r(yQt,"data2vec-vision"),yQt.forEach(t),DGo=r(eze," \u2014 "),JQ=n(eze,"A",{href:!0});var xQt=s(JQ);GGo=r(xQt,"Data2VecVisionModel"),xQt.forEach(t),OGo=r(eze," (Data2VecVision model)"),eze.forEach(t),VGo=i(x),Z1=n(x,"LI",{});var oze=s(Z1);tFe=n(oze,"STRONG",{});var $Qt=s(tFe);XGo=r($Qt,"deberta"),$Qt.forEach(t),zGo=r(oze," \u2014 "),YQ=n(oze,"A",{href:!0});var kQt=s(YQ);QGo=r(kQt,"DebertaModel"),kQt.forEach(t),WGo=r(oze," (DeBERTa model)"),oze.forEach(t),UGo=i(x),K1=n(x,"LI",{});var rze=s(K1);aFe=n(rze,"STRONG",{});var SQt=s(aFe);HGo=r(SQt,"deberta-v2"),SQt.forEach(t),JGo=r(rze," \u2014 "),ZQ=n(rze,"A",{href:!0});var RQt=s(ZQ);YGo=r(RQt,"DebertaV2Model"),RQt.forEach(t),ZGo=r(rze," (DeBERTa-v2 model)"),rze.forEach(t),KGo=i(x),e2=n(x,"LI",{});var tze=s(e2);nFe=n(tze,"STRONG",{});var PQt=s(nFe);eOo=r(PQt,"decision_transformer"),PQt.forEach(t),oOo=r(tze," \u2014 "),KQ=n(tze,"A",{href:!0});var BQt=s(KQ);rOo=r(BQt,"DecisionTransformerModel"),BQt.forEach(t),tOo=r(tze," (Decision Transformer model)"),tze.forEach(t),aOo=i(x),o2=n(x,"LI",{});var aze=s(o2);sFe=n(aze,"STRONG",{});var IQt=s(sFe);nOo=r(IQt,"deformable_detr"),IQt.forEach(t),sOo=r(aze," \u2014 "),eW=n(aze,"A",{href:!0});var NQt=s(eW);lOo=r(NQt,"DeformableDetrModel"),NQt.forEach(t),iOo=r(aze," (Deformable DETR model)"),aze.forEach(t),dOo=i(x),r2=n(x,"LI",{});var nze=s(r2);lFe=n(nze,"STRONG",{});var qQt=s(lFe);mOo=r(qQt,"deit"),qQt.forEach(t),cOo=r(nze," \u2014 "),oW=n(nze,"A",{href:!0});var jQt=s(oW);fOo=r(jQt,"DeiTModel"),jQt.forEach(t),gOo=r(nze," (DeiT model)"),nze.forEach(t),hOo=i(x),t2=n(x,"LI",{});var sze=s(t2);iFe=n(sze,"STRONG",{});var DQt=s(iFe);uOo=r(DQt,"detr"),DQt.forEach(t),pOo=r(sze," \u2014 "),rW=n(sze,"A",{href:!0});var GQt=s(rW);_Oo=r(GQt,"DetrModel"),GQt.forEach(t),bOo=r(sze," (DETR model)"),sze.forEach(t),vOo=i(x),a2=n(x,"LI",{});var lze=s(a2);dFe=n(lze,"STRONG",{});var OQt=s(dFe);FOo=r(OQt,"distilbert"),OQt.forEach(t),TOo=r(lze," \u2014 "),tW=n(lze,"A",{href:!0});var VQt=s(tW);MOo=r(VQt,"DistilBertModel"),VQt.forEach(t),EOo=r(lze," (DistilBERT model)"),lze.forEach(t),COo=i(x),n2=n(x,"LI",{});var ize=s(n2);mFe=n(ize,"STRONG",{});var XQt=s(mFe);wOo=r(XQt,"donut-swin"),XQt.forEach(t),AOo=r(ize," \u2014 "),aW=n(ize,"A",{href:!0});var zQt=s(aW);LOo=r(zQt,"DonutSwinModel"),zQt.forEach(t),yOo=r(ize," (DonutSwin model)"),ize.forEach(t),xOo=i(x),s2=n(x,"LI",{});var dze=s(s2);cFe=n(dze,"STRONG",{});var QQt=s(cFe);$Oo=r(QQt,"dpr"),QQt.forEach(t),kOo=r(dze," \u2014 "),nW=n(dze,"A",{href:!0});var WQt=s(nW);SOo=r(WQt,"DPRQuestionEncoder"),WQt.forEach(t),ROo=r(dze," (DPR model)"),dze.forEach(t),POo=i(x),l2=n(x,"LI",{});var mze=s(l2);fFe=n(mze,"STRONG",{});var UQt=s(fFe);BOo=r(UQt,"dpt"),UQt.forEach(t),IOo=r(mze," \u2014 "),sW=n(mze,"A",{href:!0});var HQt=s(sW);NOo=r(HQt,"DPTModel"),HQt.forEach(t),qOo=r(mze," (DPT model)"),mze.forEach(t),jOo=i(x),i2=n(x,"LI",{});var cze=s(i2);gFe=n(cze,"STRONG",{});var JQt=s(gFe);DOo=r(JQt,"electra"),JQt.forEach(t),GOo=r(cze," \u2014 "),lW=n(cze,"A",{href:!0});var YQt=s(lW);OOo=r(YQt,"ElectraModel"),YQt.forEach(t),VOo=r(cze," (ELECTRA model)"),cze.forEach(t),XOo=i(x),d2=n(x,"LI",{});var fze=s(d2);hFe=n(fze,"STRONG",{});var ZQt=s(hFe);zOo=r(ZQt,"ernie"),ZQt.forEach(t),QOo=r(fze," \u2014 "),iW=n(fze,"A",{href:!0});var KQt=s(iW);WOo=r(KQt,"ErnieModel"),KQt.forEach(t),UOo=r(fze," (ERNIE model)"),fze.forEach(t),HOo=i(x),m2=n(x,"LI",{});var gze=s(m2);uFe=n(gze,"STRONG",{});var eWt=s(uFe);JOo=r(eWt,"esm"),eWt.forEach(t),YOo=r(gze," \u2014 "),dW=n(gze,"A",{href:!0});var oWt=s(dW);ZOo=r(oWt,"EsmModel"),oWt.forEach(t),KOo=r(gze," (ESM model)"),gze.forEach(t),eVo=i(x),c2=n(x,"LI",{});var hze=s(c2);pFe=n(hze,"STRONG",{});var rWt=s(pFe);oVo=r(rWt,"flaubert"),rWt.forEach(t),rVo=r(hze," \u2014 "),mW=n(hze,"A",{href:!0});var tWt=s(mW);tVo=r(tWt,"FlaubertModel"),tWt.forEach(t),aVo=r(hze," (FlauBERT model)"),hze.forEach(t),nVo=i(x),f2=n(x,"LI",{});var uze=s(f2);_Fe=n(uze,"STRONG",{});var aWt=s(_Fe);sVo=r(aWt,"flava"),aWt.forEach(t),lVo=r(uze," \u2014 "),cW=n(uze,"A",{href:!0});var nWt=s(cW);iVo=r(nWt,"FlavaModel"),nWt.forEach(t),dVo=r(uze," (FLAVA model)"),uze.forEach(t),mVo=i(x),g2=n(x,"LI",{});var pze=s(g2);bFe=n(pze,"STRONG",{});var sWt=s(bFe);cVo=r(sWt,"fnet"),sWt.forEach(t),fVo=r(pze," \u2014 "),fW=n(pze,"A",{href:!0});var lWt=s(fW);gVo=r(lWt,"FNetModel"),lWt.forEach(t),hVo=r(pze," (FNet model)"),pze.forEach(t),uVo=i(x),h2=n(x,"LI",{});var _ze=s(h2);vFe=n(_ze,"STRONG",{});var iWt=s(vFe);pVo=r(iWt,"fsmt"),iWt.forEach(t),_Vo=r(_ze," \u2014 "),gW=n(_ze,"A",{href:!0});var dWt=s(gW);bVo=r(dWt,"FSMTModel"),dWt.forEach(t),vVo=r(_ze," (FairSeq Machine-Translation model)"),_ze.forEach(t),FVo=i(x),Il=n(x,"LI",{});var $q=s(Il);FFe=n($q,"STRONG",{});var mWt=s(FFe);TVo=r(mWt,"funnel"),mWt.forEach(t),MVo=r($q," \u2014 "),hW=n($q,"A",{href:!0});var cWt=s(hW);EVo=r(cWt,"FunnelModel"),cWt.forEach(t),CVo=r($q," or "),uW=n($q,"A",{href:!0});var fWt=s(uW);wVo=r(fWt,"FunnelBaseModel"),fWt.forEach(t),AVo=r($q," (Funnel Transformer model)"),$q.forEach(t),LVo=i(x),u2=n(x,"LI",{});var bze=s(u2);TFe=n(bze,"STRONG",{});var gWt=s(TFe);yVo=r(gWt,"glpn"),gWt.forEach(t),xVo=r(bze," \u2014 "),pW=n(bze,"A",{href:!0});var hWt=s(pW);$Vo=r(hWt,"GLPNModel"),hWt.forEach(t),kVo=r(bze," (GLPN model)"),bze.forEach(t),SVo=i(x),p2=n(x,"LI",{});var vze=s(p2);MFe=n(vze,"STRONG",{});var uWt=s(MFe);RVo=r(uWt,"gpt2"),uWt.forEach(t),PVo=r(vze," \u2014 "),_W=n(vze,"A",{href:!0});var pWt=s(_W);BVo=r(pWt,"GPT2Model"),pWt.forEach(t),IVo=r(vze," (OpenAI GPT-2 model)"),vze.forEach(t),NVo=i(x),_2=n(x,"LI",{});var Fze=s(_2);EFe=n(Fze,"STRONG",{});var _Wt=s(EFe);qVo=r(_Wt,"gpt_neo"),_Wt.forEach(t),jVo=r(Fze," \u2014 "),bW=n(Fze,"A",{href:!0});var bWt=s(bW);DVo=r(bWt,"GPTNeoModel"),bWt.forEach(t),GVo=r(Fze," (GPT Neo model)"),Fze.forEach(t),OVo=i(x),b2=n(x,"LI",{});var Tze=s(b2);CFe=n(Tze,"STRONG",{});var vWt=s(CFe);VVo=r(vWt,"gpt_neox"),vWt.forEach(t),XVo=r(Tze," \u2014 "),vW=n(Tze,"A",{href:!0});var FWt=s(vW);zVo=r(FWt,"GPTNeoXModel"),FWt.forEach(t),QVo=r(Tze," (GPT NeoX model)"),Tze.forEach(t),WVo=i(x),v2=n(x,"LI",{});var Mze=s(v2);wFe=n(Mze,"STRONG",{});var TWt=s(wFe);UVo=r(TWt,"gpt_neox_japanese"),TWt.forEach(t),HVo=r(Mze," \u2014 "),FW=n(Mze,"A",{href:!0});var MWt=s(FW);JVo=r(MWt,"GPTNeoXJapaneseModel"),MWt.forEach(t),YVo=r(Mze," (GPT NeoX Japanese model)"),Mze.forEach(t),ZVo=i(x),F2=n(x,"LI",{});var Eze=s(F2);AFe=n(Eze,"STRONG",{});var EWt=s(AFe);KVo=r(EWt,"gptj"),EWt.forEach(t),eXo=r(Eze," \u2014 "),TW=n(Eze,"A",{href:!0});var CWt=s(TW);oXo=r(CWt,"GPTJModel"),CWt.forEach(t),rXo=r(Eze," (GPT-J model)"),Eze.forEach(t),tXo=i(x),T2=n(x,"LI",{});var Cze=s(T2);LFe=n(Cze,"STRONG",{});var wWt=s(LFe);aXo=r(wWt,"groupvit"),wWt.forEach(t),nXo=r(Cze," \u2014 "),MW=n(Cze,"A",{href:!0});var AWt=s(MW);sXo=r(AWt,"GroupViTModel"),AWt.forEach(t),lXo=r(Cze," (GroupViT model)"),Cze.forEach(t),iXo=i(x),M2=n(x,"LI",{});var wze=s(M2);yFe=n(wze,"STRONG",{});var LWt=s(yFe);dXo=r(LWt,"hubert"),LWt.forEach(t),mXo=r(wze," \u2014 "),EW=n(wze,"A",{href:!0});var yWt=s(EW);cXo=r(yWt,"HubertModel"),yWt.forEach(t),fXo=r(wze," (Hubert model)"),wze.forEach(t),gXo=i(x),E2=n(x,"LI",{});var Aze=s(E2);xFe=n(Aze,"STRONG",{});var xWt=s(xFe);hXo=r(xWt,"ibert"),xWt.forEach(t),uXo=r(Aze," \u2014 "),CW=n(Aze,"A",{href:!0});var $Wt=s(CW);pXo=r($Wt,"IBertModel"),$Wt.forEach(t),_Xo=r(Aze," (I-BERT model)"),Aze.forEach(t),bXo=i(x),C2=n(x,"LI",{});var Lze=s(C2);$Fe=n(Lze,"STRONG",{});var kWt=s($Fe);vXo=r(kWt,"imagegpt"),kWt.forEach(t),FXo=r(Lze," \u2014 "),wW=n(Lze,"A",{href:!0});var SWt=s(wW);TXo=r(SWt,"ImageGPTModel"),SWt.forEach(t),MXo=r(Lze," (ImageGPT model)"),Lze.forEach(t),EXo=i(x),w2=n(x,"LI",{});var yze=s(w2);kFe=n(yze,"STRONG",{});var RWt=s(kFe);CXo=r(RWt,"jukebox"),RWt.forEach(t),wXo=r(yze," \u2014 "),AW=n(yze,"A",{href:!0});var PWt=s(AW);AXo=r(PWt,"JukeboxModel"),PWt.forEach(t),LXo=r(yze," (Jukebox model)"),yze.forEach(t),yXo=i(x),A2=n(x,"LI",{});var xze=s(A2);SFe=n(xze,"STRONG",{});var BWt=s(SFe);xXo=r(BWt,"layoutlm"),BWt.forEach(t),$Xo=r(xze," \u2014 "),LW=n(xze,"A",{href:!0});var IWt=s(LW);kXo=r(IWt,"LayoutLMModel"),IWt.forEach(t),SXo=r(xze," (LayoutLM model)"),xze.forEach(t),RXo=i(x),L2=n(x,"LI",{});var $ze=s(L2);RFe=n($ze,"STRONG",{});var NWt=s(RFe);PXo=r(NWt,"layoutlmv2"),NWt.forEach(t),BXo=r($ze," \u2014 "),yW=n($ze,"A",{href:!0});var qWt=s(yW);IXo=r(qWt,"LayoutLMv2Model"),qWt.forEach(t),NXo=r($ze," (LayoutLMv2 model)"),$ze.forEach(t),qXo=i(x),y2=n(x,"LI",{});var kze=s(y2);PFe=n(kze,"STRONG",{});var jWt=s(PFe);jXo=r(jWt,"layoutlmv3"),jWt.forEach(t),DXo=r(kze," \u2014 "),xW=n(kze,"A",{href:!0});var DWt=s(xW);GXo=r(DWt,"LayoutLMv3Model"),DWt.forEach(t),OXo=r(kze," (LayoutLMv3 model)"),kze.forEach(t),VXo=i(x),x2=n(x,"LI",{});var Sze=s(x2);BFe=n(Sze,"STRONG",{});var GWt=s(BFe);XXo=r(GWt,"led"),GWt.forEach(t),zXo=r(Sze," \u2014 "),$W=n(Sze,"A",{href:!0});var OWt=s($W);QXo=r(OWt,"LEDModel"),OWt.forEach(t),WXo=r(Sze," (LED model)"),Sze.forEach(t),UXo=i(x),$2=n(x,"LI",{});var Rze=s($2);IFe=n(Rze,"STRONG",{});var VWt=s(IFe);HXo=r(VWt,"levit"),VWt.forEach(t),JXo=r(Rze," \u2014 "),kW=n(Rze,"A",{href:!0});var XWt=s(kW);YXo=r(XWt,"LevitModel"),XWt.forEach(t),ZXo=r(Rze," (LeViT model)"),Rze.forEach(t),KXo=i(x),k2=n(x,"LI",{});var Pze=s(k2);NFe=n(Pze,"STRONG",{});var zWt=s(NFe);ezo=r(zWt,"lilt"),zWt.forEach(t),ozo=r(Pze," \u2014 "),SW=n(Pze,"A",{href:!0});var QWt=s(SW);rzo=r(QWt,"LiltModel"),QWt.forEach(t),tzo=r(Pze," (LiLT model)"),Pze.forEach(t),azo=i(x),S2=n(x,"LI",{});var Bze=s(S2);qFe=n(Bze,"STRONG",{});var WWt=s(qFe);nzo=r(WWt,"longformer"),WWt.forEach(t),szo=r(Bze," \u2014 "),RW=n(Bze,"A",{href:!0});var UWt=s(RW);lzo=r(UWt,"LongformerModel"),UWt.forEach(t),izo=r(Bze," (Longformer model)"),Bze.forEach(t),dzo=i(x),R2=n(x,"LI",{});var Ize=s(R2);jFe=n(Ize,"STRONG",{});var HWt=s(jFe);mzo=r(HWt,"longt5"),HWt.forEach(t),czo=r(Ize," \u2014 "),PW=n(Ize,"A",{href:!0});var JWt=s(PW);fzo=r(JWt,"LongT5Model"),JWt.forEach(t),gzo=r(Ize," (LongT5 model)"),Ize.forEach(t),hzo=i(x),P2=n(x,"LI",{});var Nze=s(P2);DFe=n(Nze,"STRONG",{});var YWt=s(DFe);uzo=r(YWt,"luke"),YWt.forEach(t),pzo=r(Nze," \u2014 "),BW=n(Nze,"A",{href:!0});var ZWt=s(BW);_zo=r(ZWt,"LukeModel"),ZWt.forEach(t),bzo=r(Nze," (LUKE model)"),Nze.forEach(t),vzo=i(x),B2=n(x,"LI",{});var qze=s(B2);GFe=n(qze,"STRONG",{});var KWt=s(GFe);Fzo=r(KWt,"lxmert"),KWt.forEach(t),Tzo=r(qze," \u2014 "),IW=n(qze,"A",{href:!0});var eUt=s(IW);Mzo=r(eUt,"LxmertModel"),eUt.forEach(t),Ezo=r(qze," (LXMERT model)"),qze.forEach(t),Czo=i(x),I2=n(x,"LI",{});var jze=s(I2);OFe=n(jze,"STRONG",{});var oUt=s(OFe);wzo=r(oUt,"m2m_100"),oUt.forEach(t),Azo=r(jze," \u2014 "),NW=n(jze,"A",{href:!0});var rUt=s(NW);Lzo=r(rUt,"M2M100Model"),rUt.forEach(t),yzo=r(jze," (M2M100 model)"),jze.forEach(t),xzo=i(x),N2=n(x,"LI",{});var Dze=s(N2);VFe=n(Dze,"STRONG",{});var tUt=s(VFe);$zo=r(tUt,"marian"),tUt.forEach(t),kzo=r(Dze," \u2014 "),qW=n(Dze,"A",{href:!0});var aUt=s(qW);Szo=r(aUt,"MarianModel"),aUt.forEach(t),Rzo=r(Dze," (Marian model)"),Dze.forEach(t),Pzo=i(x),q2=n(x,"LI",{});var Gze=s(q2);XFe=n(Gze,"STRONG",{});var nUt=s(XFe);Bzo=r(nUt,"markuplm"),nUt.forEach(t),Izo=r(Gze," \u2014 "),jW=n(Gze,"A",{href:!0});var sUt=s(jW);Nzo=r(sUt,"MarkupLMModel"),sUt.forEach(t),qzo=r(Gze," (MarkupLM model)"),Gze.forEach(t),jzo=i(x),j2=n(x,"LI",{});var Oze=s(j2);zFe=n(Oze,"STRONG",{});var lUt=s(zFe);Dzo=r(lUt,"maskformer"),lUt.forEach(t),Gzo=r(Oze," \u2014 "),DW=n(Oze,"A",{href:!0});var iUt=s(DW);Ozo=r(iUt,"MaskFormerModel"),iUt.forEach(t),Vzo=r(Oze," (MaskFormer model)"),Oze.forEach(t),Xzo=i(x),D2=n(x,"LI",{});var Vze=s(D2);QFe=n(Vze,"STRONG",{});var dUt=s(QFe);zzo=r(dUt,"mbart"),dUt.forEach(t),Qzo=r(Vze," \u2014 "),GW=n(Vze,"A",{href:!0});var mUt=s(GW);Wzo=r(mUt,"MBartModel"),mUt.forEach(t),Uzo=r(Vze," (mBART model)"),Vze.forEach(t),Hzo=i(x),G2=n(x,"LI",{});var Xze=s(G2);WFe=n(Xze,"STRONG",{});var cUt=s(WFe);Jzo=r(cUt,"mctct"),cUt.forEach(t),Yzo=r(Xze," \u2014 "),OW=n(Xze,"A",{href:!0});var fUt=s(OW);Zzo=r(fUt,"MCTCTModel"),fUt.forEach(t),Kzo=r(Xze," (M-CTC-T model)"),Xze.forEach(t),eQo=i(x),O2=n(x,"LI",{});var zze=s(O2);UFe=n(zze,"STRONG",{});var gUt=s(UFe);oQo=r(gUt,"megatron-bert"),gUt.forEach(t),rQo=r(zze," \u2014 "),VW=n(zze,"A",{href:!0});var hUt=s(VW);tQo=r(hUt,"MegatronBertModel"),hUt.forEach(t),aQo=r(zze," (Megatron-BERT model)"),zze.forEach(t),nQo=i(x),V2=n(x,"LI",{});var Qze=s(V2);HFe=n(Qze,"STRONG",{});var uUt=s(HFe);sQo=r(uUt,"mobilebert"),uUt.forEach(t),lQo=r(Qze," \u2014 "),XW=n(Qze,"A",{href:!0});var pUt=s(XW);iQo=r(pUt,"MobileBertModel"),pUt.forEach(t),dQo=r(Qze," (MobileBERT model)"),Qze.forEach(t),mQo=i(x),X2=n(x,"LI",{});var Wze=s(X2);JFe=n(Wze,"STRONG",{});var _Ut=s(JFe);cQo=r(_Ut,"mobilevit"),_Ut.forEach(t),fQo=r(Wze," \u2014 "),zW=n(Wze,"A",{href:!0});var bUt=s(zW);gQo=r(bUt,"MobileViTModel"),bUt.forEach(t),hQo=r(Wze," (MobileViT model)"),Wze.forEach(t),uQo=i(x),z2=n(x,"LI",{});var Uze=s(z2);YFe=n(Uze,"STRONG",{});var vUt=s(YFe);pQo=r(vUt,"mpnet"),vUt.forEach(t),_Qo=r(Uze," \u2014 "),QW=n(Uze,"A",{href:!0});var FUt=s(QW);bQo=r(FUt,"MPNetModel"),FUt.forEach(t),vQo=r(Uze," (MPNet model)"),Uze.forEach(t),FQo=i(x),Q2=n(x,"LI",{});var Hze=s(Q2);ZFe=n(Hze,"STRONG",{});var TUt=s(ZFe);TQo=r(TUt,"mt5"),TUt.forEach(t),MQo=r(Hze," \u2014 "),WW=n(Hze,"A",{href:!0});var MUt=s(WW);EQo=r(MUt,"MT5Model"),MUt.forEach(t),CQo=r(Hze," (MT5 model)"),Hze.forEach(t),wQo=i(x),W2=n(x,"LI",{});var Jze=s(W2);KFe=n(Jze,"STRONG",{});var EUt=s(KFe);AQo=r(EUt,"mvp"),EUt.forEach(t),LQo=r(Jze," \u2014 "),UW=n(Jze,"A",{href:!0});var CUt=s(UW);yQo=r(CUt,"MvpModel"),CUt.forEach(t),xQo=r(Jze," (MVP model)"),Jze.forEach(t),$Qo=i(x),U2=n(x,"LI",{});var Yze=s(U2);eTe=n(Yze,"STRONG",{});var wUt=s(eTe);kQo=r(wUt,"nezha"),wUt.forEach(t),SQo=r(Yze," \u2014 "),HW=n(Yze,"A",{href:!0});var AUt=s(HW);RQo=r(AUt,"NezhaModel"),AUt.forEach(t),PQo=r(Yze," (Nezha model)"),Yze.forEach(t),BQo=i(x),H2=n(x,"LI",{});var Zze=s(H2);oTe=n(Zze,"STRONG",{});var LUt=s(oTe);IQo=r(LUt,"nllb"),LUt.forEach(t),NQo=r(Zze," \u2014 "),JW=n(Zze,"A",{href:!0});var yUt=s(JW);qQo=r(yUt,"M2M100Model"),yUt.forEach(t),jQo=r(Zze," (NLLB model)"),Zze.forEach(t),DQo=i(x),J2=n(x,"LI",{});var Kze=s(J2);rTe=n(Kze,"STRONG",{});var xUt=s(rTe);GQo=r(xUt,"nystromformer"),xUt.forEach(t),OQo=r(Kze," \u2014 "),YW=n(Kze,"A",{href:!0});var $Ut=s(YW);VQo=r($Ut,"NystromformerModel"),$Ut.forEach(t),XQo=r(Kze," (Nystr\xF6mformer model)"),Kze.forEach(t),zQo=i(x),Y2=n(x,"LI",{});var eQe=s(Y2);tTe=n(eQe,"STRONG",{});var kUt=s(tTe);QQo=r(kUt,"openai-gpt"),kUt.forEach(t),WQo=r(eQe," \u2014 "),ZW=n(eQe,"A",{href:!0});var SUt=s(ZW);UQo=r(SUt,"OpenAIGPTModel"),SUt.forEach(t),HQo=r(eQe," (OpenAI GPT model)"),eQe.forEach(t),JQo=i(x),Z2=n(x,"LI",{});var oQe=s(Z2);aTe=n(oQe,"STRONG",{});var RUt=s(aTe);YQo=r(RUt,"opt"),RUt.forEach(t),ZQo=r(oQe," \u2014 "),KW=n(oQe,"A",{href:!0});var PUt=s(KW);KQo=r(PUt,"OPTModel"),PUt.forEach(t),eWo=r(oQe," (OPT model)"),oQe.forEach(t),oWo=i(x),K2=n(x,"LI",{});var rQe=s(K2);nTe=n(rQe,"STRONG",{});var BUt=s(nTe);rWo=r(BUt,"owlvit"),BUt.forEach(t),tWo=r(rQe," \u2014 "),eU=n(rQe,"A",{href:!0});var IUt=s(eU);aWo=r(IUt,"OwlViTModel"),IUt.forEach(t),nWo=r(rQe," (OWL-ViT model)"),rQe.forEach(t),sWo=i(x),eb=n(x,"LI",{});var tQe=s(eb);sTe=n(tQe,"STRONG",{});var NUt=s(sTe);lWo=r(NUt,"pegasus"),NUt.forEach(t),iWo=r(tQe," \u2014 "),oU=n(tQe,"A",{href:!0});var qUt=s(oU);dWo=r(qUt,"PegasusModel"),qUt.forEach(t),mWo=r(tQe," (Pegasus model)"),tQe.forEach(t),cWo=i(x),ob=n(x,"LI",{});var aQe=s(ob);lTe=n(aQe,"STRONG",{});var jUt=s(lTe);fWo=r(jUt,"pegasus_x"),jUt.forEach(t),gWo=r(aQe," \u2014 "),rU=n(aQe,"A",{href:!0});var DUt=s(rU);hWo=r(DUt,"PegasusXModel"),DUt.forEach(t),uWo=r(aQe," (PEGASUS-X model)"),aQe.forEach(t),pWo=i(x),rb=n(x,"LI",{});var nQe=s(rb);iTe=n(nQe,"STRONG",{});var GUt=s(iTe);_Wo=r(GUt,"perceiver"),GUt.forEach(t),bWo=r(nQe," \u2014 "),tU=n(nQe,"A",{href:!0});var OUt=s(tU);vWo=r(OUt,"PerceiverModel"),OUt.forEach(t),FWo=r(nQe," (Perceiver model)"),nQe.forEach(t),TWo=i(x),tb=n(x,"LI",{});var sQe=s(tb);dTe=n(sQe,"STRONG",{});var VUt=s(dTe);MWo=r(VUt,"plbart"),VUt.forEach(t),EWo=r(sQe," \u2014 "),aU=n(sQe,"A",{href:!0});var XUt=s(aU);CWo=r(XUt,"PLBartModel"),XUt.forEach(t),wWo=r(sQe," (PLBart model)"),sQe.forEach(t),AWo=i(x),ab=n(x,"LI",{});var lQe=s(ab);mTe=n(lQe,"STRONG",{});var zUt=s(mTe);LWo=r(zUt,"poolformer"),zUt.forEach(t),yWo=r(lQe," \u2014 "),nU=n(lQe,"A",{href:!0});var QUt=s(nU);xWo=r(QUt,"PoolFormerModel"),QUt.forEach(t),$Wo=r(lQe," (PoolFormer model)"),lQe.forEach(t),kWo=i(x),nb=n(x,"LI",{});var iQe=s(nb);cTe=n(iQe,"STRONG",{});var WUt=s(cTe);SWo=r(WUt,"prophetnet"),WUt.forEach(t),RWo=r(iQe," \u2014 "),sU=n(iQe,"A",{href:!0});var UUt=s(sU);PWo=r(UUt,"ProphetNetModel"),UUt.forEach(t),BWo=r(iQe," (ProphetNet model)"),iQe.forEach(t),IWo=i(x),sb=n(x,"LI",{});var dQe=s(sb);fTe=n(dQe,"STRONG",{});var HUt=s(fTe);NWo=r(HUt,"qdqbert"),HUt.forEach(t),qWo=r(dQe," \u2014 "),lU=n(dQe,"A",{href:!0});var JUt=s(lU);jWo=r(JUt,"QDQBertModel"),JUt.forEach(t),DWo=r(dQe," (QDQBert model)"),dQe.forEach(t),GWo=i(x),lb=n(x,"LI",{});var mQe=s(lb);gTe=n(mQe,"STRONG",{});var YUt=s(gTe);OWo=r(YUt,"reformer"),YUt.forEach(t),VWo=r(mQe," \u2014 "),iU=n(mQe,"A",{href:!0});var ZUt=s(iU);XWo=r(ZUt,"ReformerModel"),ZUt.forEach(t),zWo=r(mQe," (Reformer model)"),mQe.forEach(t),QWo=i(x),ib=n(x,"LI",{});var cQe=s(ib);hTe=n(cQe,"STRONG",{});var KUt=s(hTe);WWo=r(KUt,"regnet"),KUt.forEach(t),UWo=r(cQe," \u2014 "),dU=n(cQe,"A",{href:!0});var eHt=s(dU);HWo=r(eHt,"RegNetModel"),eHt.forEach(t),JWo=r(cQe," (RegNet model)"),cQe.forEach(t),YWo=i(x),db=n(x,"LI",{});var fQe=s(db);uTe=n(fQe,"STRONG",{});var oHt=s(uTe);ZWo=r(oHt,"rembert"),oHt.forEach(t),KWo=r(fQe," \u2014 "),mU=n(fQe,"A",{href:!0});var rHt=s(mU);eUo=r(rHt,"RemBertModel"),rHt.forEach(t),oUo=r(fQe," (RemBERT model)"),fQe.forEach(t),rUo=i(x),mb=n(x,"LI",{});var gQe=s(mb);pTe=n(gQe,"STRONG",{});var tHt=s(pTe);tUo=r(tHt,"resnet"),tHt.forEach(t),aUo=r(gQe," \u2014 "),cU=n(gQe,"A",{href:!0});var aHt=s(cU);nUo=r(aHt,"ResNetModel"),aHt.forEach(t),sUo=r(gQe," (ResNet model)"),gQe.forEach(t),lUo=i(x),cb=n(x,"LI",{});var hQe=s(cb);_Te=n(hQe,"STRONG",{});var nHt=s(_Te);iUo=r(nHt,"retribert"),nHt.forEach(t),dUo=r(hQe," \u2014 "),fU=n(hQe,"A",{href:!0});var sHt=s(fU);mUo=r(sHt,"RetriBertModel"),sHt.forEach(t),cUo=r(hQe," (RetriBERT model)"),hQe.forEach(t),fUo=i(x),fb=n(x,"LI",{});var uQe=s(fb);bTe=n(uQe,"STRONG",{});var lHt=s(bTe);gUo=r(lHt,"roberta"),lHt.forEach(t),hUo=r(uQe," \u2014 "),gU=n(uQe,"A",{href:!0});var iHt=s(gU);uUo=r(iHt,"RobertaModel"),iHt.forEach(t),pUo=r(uQe," (RoBERTa model)"),uQe.forEach(t),_Uo=i(x),gb=n(x,"LI",{});var pQe=s(gb);vTe=n(pQe,"STRONG",{});var dHt=s(vTe);bUo=r(dHt,"roc_bert"),dHt.forEach(t),vUo=r(pQe," \u2014 "),hU=n(pQe,"A",{href:!0});var mHt=s(hU);FUo=r(mHt,"RoCBertModel"),mHt.forEach(t),TUo=r(pQe," (RoCBert model)"),pQe.forEach(t),MUo=i(x),hb=n(x,"LI",{});var _Qe=s(hb);FTe=n(_Qe,"STRONG",{});var cHt=s(FTe);EUo=r(cHt,"roformer"),cHt.forEach(t),CUo=r(_Qe," \u2014 "),uU=n(_Qe,"A",{href:!0});var fHt=s(uU);wUo=r(fHt,"RoFormerModel"),fHt.forEach(t),AUo=r(_Qe," (RoFormer model)"),_Qe.forEach(t),LUo=i(x),ub=n(x,"LI",{});var bQe=s(ub);TTe=n(bQe,"STRONG",{});var gHt=s(TTe);yUo=r(gHt,"segformer"),gHt.forEach(t),xUo=r(bQe," \u2014 "),pU=n(bQe,"A",{href:!0});var hHt=s(pU);$Uo=r(hHt,"SegformerModel"),hHt.forEach(t),kUo=r(bQe," (SegFormer model)"),bQe.forEach(t),SUo=i(x),pb=n(x,"LI",{});var vQe=s(pb);MTe=n(vQe,"STRONG",{});var uHt=s(MTe);RUo=r(uHt,"sew"),uHt.forEach(t),PUo=r(vQe," \u2014 "),_U=n(vQe,"A",{href:!0});var pHt=s(_U);BUo=r(pHt,"SEWModel"),pHt.forEach(t),IUo=r(vQe," (SEW model)"),vQe.forEach(t),NUo=i(x),_b=n(x,"LI",{});var FQe=s(_b);ETe=n(FQe,"STRONG",{});var _Ht=s(ETe);qUo=r(_Ht,"sew-d"),_Ht.forEach(t),jUo=r(FQe," \u2014 "),bU=n(FQe,"A",{href:!0});var bHt=s(bU);DUo=r(bHt,"SEWDModel"),bHt.forEach(t),GUo=r(FQe," (SEW-D model)"),FQe.forEach(t),OUo=i(x),bb=n(x,"LI",{});var TQe=s(bb);CTe=n(TQe,"STRONG",{});var vHt=s(CTe);VUo=r(vHt,"speech_to_text"),vHt.forEach(t),XUo=r(TQe," \u2014 "),vU=n(TQe,"A",{href:!0});var FHt=s(vU);zUo=r(FHt,"Speech2TextModel"),FHt.forEach(t),QUo=r(TQe," (Speech2Text model)"),TQe.forEach(t),WUo=i(x),vb=n(x,"LI",{});var MQe=s(vb);wTe=n(MQe,"STRONG",{});var THt=s(wTe);UUo=r(THt,"splinter"),THt.forEach(t),HUo=r(MQe," \u2014 "),FU=n(MQe,"A",{href:!0});var MHt=s(FU);JUo=r(MHt,"SplinterModel"),MHt.forEach(t),YUo=r(MQe," (Splinter model)"),MQe.forEach(t),ZUo=i(x),Fb=n(x,"LI",{});var EQe=s(Fb);ATe=n(EQe,"STRONG",{});var EHt=s(ATe);KUo=r(EHt,"squeezebert"),EHt.forEach(t),eHo=r(EQe," \u2014 "),TU=n(EQe,"A",{href:!0});var CHt=s(TU);oHo=r(CHt,"SqueezeBertModel"),CHt.forEach(t),rHo=r(EQe," (SqueezeBERT model)"),EQe.forEach(t),tHo=i(x),Tb=n(x,"LI",{});var CQe=s(Tb);LTe=n(CQe,"STRONG",{});var wHt=s(LTe);aHo=r(wHt,"swin"),wHt.forEach(t),nHo=r(CQe," \u2014 "),MU=n(CQe,"A",{href:!0});var AHt=s(MU);sHo=r(AHt,"SwinModel"),AHt.forEach(t),lHo=r(CQe," (Swin Transformer model)"),CQe.forEach(t),iHo=i(x),Mb=n(x,"LI",{});var wQe=s(Mb);yTe=n(wQe,"STRONG",{});var LHt=s(yTe);dHo=r(LHt,"swinv2"),LHt.forEach(t),mHo=r(wQe," \u2014 "),EU=n(wQe,"A",{href:!0});var yHt=s(EU);cHo=r(yHt,"Swinv2Model"),yHt.forEach(t),fHo=r(wQe," (Swin Transformer V2 model)"),wQe.forEach(t),gHo=i(x),Eb=n(x,"LI",{});var AQe=s(Eb);xTe=n(AQe,"STRONG",{});var xHt=s(xTe);hHo=r(xHt,"t5"),xHt.forEach(t),uHo=r(AQe," \u2014 "),CU=n(AQe,"A",{href:!0});var $Ht=s(CU);pHo=r($Ht,"T5Model"),$Ht.forEach(t),_Ho=r(AQe," (T5 model)"),AQe.forEach(t),bHo=i(x),Cb=n(x,"LI",{});var LQe=s(Cb);$Te=n(LQe,"STRONG",{});var kHt=s($Te);vHo=r(kHt,"table-transformer"),kHt.forEach(t),FHo=r(LQe," \u2014 "),wU=n(LQe,"A",{href:!0});var SHt=s(wU);THo=r(SHt,"TableTransformerModel"),SHt.forEach(t),MHo=r(LQe," (Table Transformer model)"),LQe.forEach(t),EHo=i(x),wb=n(x,"LI",{});var yQe=s(wb);kTe=n(yQe,"STRONG",{});var RHt=s(kTe);CHo=r(RHt,"tapas"),RHt.forEach(t),wHo=r(yQe," \u2014 "),AU=n(yQe,"A",{href:!0});var PHt=s(AU);AHo=r(PHt,"TapasModel"),PHt.forEach(t),LHo=r(yQe," (TAPAS model)"),yQe.forEach(t),yHo=i(x),Ab=n(x,"LI",{});var xQe=s(Ab);STe=n(xQe,"STRONG",{});var BHt=s(STe);xHo=r(BHt,"time_series_transformer"),BHt.forEach(t),$Ho=r(xQe," \u2014 "),LU=n(xQe,"A",{href:!0});var IHt=s(LU);kHo=r(IHt,"TimeSeriesTransformerModel"),IHt.forEach(t),SHo=r(xQe," (Time Series Transformer model)"),xQe.forEach(t),RHo=i(x),Lb=n(x,"LI",{});var $Qe=s(Lb);RTe=n($Qe,"STRONG",{});var NHt=s(RTe);PHo=r(NHt,"trajectory_transformer"),NHt.forEach(t),BHo=r($Qe," \u2014 "),yU=n($Qe,"A",{href:!0});var qHt=s(yU);IHo=r(qHt,"TrajectoryTransformerModel"),qHt.forEach(t),NHo=r($Qe," (Trajectory Transformer model)"),$Qe.forEach(t),qHo=i(x),yb=n(x,"LI",{});var kQe=s(yb);PTe=n(kQe,"STRONG",{});var jHt=s(PTe);jHo=r(jHt,"transfo-xl"),jHt.forEach(t),DHo=r(kQe," \u2014 "),xU=n(kQe,"A",{href:!0});var DHt=s(xU);GHo=r(DHt,"TransfoXLModel"),DHt.forEach(t),OHo=r(kQe," (Transformer-XL model)"),kQe.forEach(t),VHo=i(x),xb=n(x,"LI",{});var SQe=s(xb);BTe=n(SQe,"STRONG",{});var GHt=s(BTe);XHo=r(GHt,"unispeech"),GHt.forEach(t),zHo=r(SQe," \u2014 "),$U=n(SQe,"A",{href:!0});var OHt=s($U);QHo=r(OHt,"UniSpeechModel"),OHt.forEach(t),WHo=r(SQe," (UniSpeech model)"),SQe.forEach(t),UHo=i(x),$b=n(x,"LI",{});var RQe=s($b);ITe=n(RQe,"STRONG",{});var VHt=s(ITe);HHo=r(VHt,"unispeech-sat"),VHt.forEach(t),JHo=r(RQe," \u2014 "),kU=n(RQe,"A",{href:!0});var XHt=s(kU);YHo=r(XHt,"UniSpeechSatModel"),XHt.forEach(t),ZHo=r(RQe," (UniSpeechSat model)"),RQe.forEach(t),KHo=i(x),kb=n(x,"LI",{});var PQe=s(kb);NTe=n(PQe,"STRONG",{});var zHt=s(NTe);eJo=r(zHt,"van"),zHt.forEach(t),oJo=r(PQe," \u2014 "),SU=n(PQe,"A",{href:!0});var QHt=s(SU);rJo=r(QHt,"VanModel"),QHt.forEach(t),tJo=r(PQe," (VAN model)"),PQe.forEach(t),aJo=i(x),Sb=n(x,"LI",{});var BQe=s(Sb);qTe=n(BQe,"STRONG",{});var WHt=s(qTe);nJo=r(WHt,"videomae"),WHt.forEach(t),sJo=r(BQe," \u2014 "),RU=n(BQe,"A",{href:!0});var UHt=s(RU);lJo=r(UHt,"VideoMAEModel"),UHt.forEach(t),iJo=r(BQe," (VideoMAE model)"),BQe.forEach(t),dJo=i(x),Rb=n(x,"LI",{});var IQe=s(Rb);jTe=n(IQe,"STRONG",{});var HHt=s(jTe);mJo=r(HHt,"vilt"),HHt.forEach(t),cJo=r(IQe," \u2014 "),PU=n(IQe,"A",{href:!0});var JHt=s(PU);fJo=r(JHt,"ViltModel"),JHt.forEach(t),gJo=r(IQe," (ViLT model)"),IQe.forEach(t),hJo=i(x),Pb=n(x,"LI",{});var NQe=s(Pb);DTe=n(NQe,"STRONG",{});var YHt=s(DTe);uJo=r(YHt,"vision-text-dual-encoder"),YHt.forEach(t),pJo=r(NQe," \u2014 "),BU=n(NQe,"A",{href:!0});var ZHt=s(BU);_Jo=r(ZHt,"VisionTextDualEncoderModel"),ZHt.forEach(t),bJo=r(NQe," (VisionTextDualEncoder model)"),NQe.forEach(t),vJo=i(x),Bb=n(x,"LI",{});var qQe=s(Bb);GTe=n(qQe,"STRONG",{});var KHt=s(GTe);FJo=r(KHt,"visual_bert"),KHt.forEach(t),TJo=r(qQe," \u2014 "),IU=n(qQe,"A",{href:!0});var eJt=s(IU);MJo=r(eJt,"VisualBertModel"),eJt.forEach(t),EJo=r(qQe," (VisualBERT model)"),qQe.forEach(t),CJo=i(x),Ib=n(x,"LI",{});var jQe=s(Ib);OTe=n(jQe,"STRONG",{});var oJt=s(OTe);wJo=r(oJt,"vit"),oJt.forEach(t),AJo=r(jQe," \u2014 "),NU=n(jQe,"A",{href:!0});var rJt=s(NU);LJo=r(rJt,"ViTModel"),rJt.forEach(t),yJo=r(jQe," (ViT model)"),jQe.forEach(t),xJo=i(x),Nb=n(x,"LI",{});var DQe=s(Nb);VTe=n(DQe,"STRONG",{});var tJt=s(VTe);$Jo=r(tJt,"vit_mae"),tJt.forEach(t),kJo=r(DQe," \u2014 "),qU=n(DQe,"A",{href:!0});var aJt=s(qU);SJo=r(aJt,"ViTMAEModel"),aJt.forEach(t),RJo=r(DQe," (ViTMAE model)"),DQe.forEach(t),PJo=i(x),qb=n(x,"LI",{});var GQe=s(qb);XTe=n(GQe,"STRONG",{});var nJt=s(XTe);BJo=r(nJt,"vit_msn"),nJt.forEach(t),IJo=r(GQe," \u2014 "),jU=n(GQe,"A",{href:!0});var sJt=s(jU);NJo=r(sJt,"ViTMSNModel"),sJt.forEach(t),qJo=r(GQe," (ViTMSN model)"),GQe.forEach(t),jJo=i(x),jb=n(x,"LI",{});var OQe=s(jb);zTe=n(OQe,"STRONG",{});var lJt=s(zTe);DJo=r(lJt,"wav2vec2"),lJt.forEach(t),GJo=r(OQe," \u2014 "),DU=n(OQe,"A",{href:!0});var iJt=s(DU);OJo=r(iJt,"Wav2Vec2Model"),iJt.forEach(t),VJo=r(OQe," (Wav2Vec2 model)"),OQe.forEach(t),XJo=i(x),Db=n(x,"LI",{});var VQe=s(Db);QTe=n(VQe,"STRONG",{});var dJt=s(QTe);zJo=r(dJt,"wav2vec2-conformer"),dJt.forEach(t),QJo=r(VQe," \u2014 "),GU=n(VQe,"A",{href:!0});var mJt=s(GU);WJo=r(mJt,"Wav2Vec2ConformerModel"),mJt.forEach(t),UJo=r(VQe," (Wav2Vec2-Conformer model)"),VQe.forEach(t),HJo=i(x),Gb=n(x,"LI",{});var XQe=s(Gb);WTe=n(XQe,"STRONG",{});var cJt=s(WTe);JJo=r(cJt,"wavlm"),cJt.forEach(t),YJo=r(XQe," \u2014 "),OU=n(XQe,"A",{href:!0});var fJt=s(OU);ZJo=r(fJt,"WavLMModel"),fJt.forEach(t),KJo=r(XQe," (WavLM model)"),XQe.forEach(t),eYo=i(x),Ob=n(x,"LI",{});var zQe=s(Ob);UTe=n(zQe,"STRONG",{});var gJt=s(UTe);oYo=r(gJt,"whisper"),gJt.forEach(t),rYo=r(zQe," \u2014 "),VU=n(zQe,"A",{href:!0});var hJt=s(VU);tYo=r(hJt,"WhisperModel"),hJt.forEach(t),aYo=r(zQe," (Whisper model)"),zQe.forEach(t),nYo=i(x),Vb=n(x,"LI",{});var QQe=s(Vb);HTe=n(QQe,"STRONG",{});var uJt=s(HTe);sYo=r(uJt,"xclip"),uJt.forEach(t),lYo=r(QQe," \u2014 "),XU=n(QQe,"A",{href:!0});var pJt=s(XU);iYo=r(pJt,"XCLIPModel"),pJt.forEach(t),dYo=r(QQe," (X-CLIP model)"),QQe.forEach(t),mYo=i(x),Xb=n(x,"LI",{});var WQe=s(Xb);JTe=n(WQe,"STRONG",{});var _Jt=s(JTe);cYo=r(_Jt,"xglm"),_Jt.forEach(t),fYo=r(WQe," \u2014 "),zU=n(WQe,"A",{href:!0});var bJt=s(zU);gYo=r(bJt,"XGLMModel"),bJt.forEach(t),hYo=r(WQe," (XGLM model)"),WQe.forEach(t),uYo=i(x),zb=n(x,"LI",{});var UQe=s(zb);YTe=n(UQe,"STRONG",{});var vJt=s(YTe);pYo=r(vJt,"xlm"),vJt.forEach(t),_Yo=r(UQe," \u2014 "),QU=n(UQe,"A",{href:!0});var FJt=s(QU);bYo=r(FJt,"XLMModel"),FJt.forEach(t),vYo=r(UQe," (XLM model)"),UQe.forEach(t),FYo=i(x),Qb=n(x,"LI",{});var HQe=s(Qb);ZTe=n(HQe,"STRONG",{});var TJt=s(ZTe);TYo=r(TJt,"xlm-prophetnet"),TJt.forEach(t),MYo=r(HQe," \u2014 "),WU=n(HQe,"A",{href:!0});var MJt=s(WU);EYo=r(MJt,"XLMProphetNetModel"),MJt.forEach(t),CYo=r(HQe," (XLM-ProphetNet model)"),HQe.forEach(t),wYo=i(x),Wb=n(x,"LI",{});var JQe=s(Wb);KTe=n(JQe,"STRONG",{});var EJt=s(KTe);AYo=r(EJt,"xlm-roberta"),EJt.forEach(t),LYo=r(JQe," \u2014 "),UU=n(JQe,"A",{href:!0});var CJt=s(UU);yYo=r(CJt,"XLMRobertaModel"),CJt.forEach(t),xYo=r(JQe," (XLM-RoBERTa model)"),JQe.forEach(t),$Yo=i(x),Ub=n(x,"LI",{});var YQe=s(Ub);eMe=n(YQe,"STRONG",{});var wJt=s(eMe);kYo=r(wJt,"xlm-roberta-xl"),wJt.forEach(t),SYo=r(YQe," \u2014 "),HU=n(YQe,"A",{href:!0});var AJt=s(HU);RYo=r(AJt,"XLMRobertaXLModel"),AJt.forEach(t),PYo=r(YQe," (XLM-RoBERTa-XL model)"),YQe.forEach(t),BYo=i(x),Hb=n(x,"LI",{});var ZQe=s(Hb);oMe=n(ZQe,"STRONG",{});var LJt=s(oMe);IYo=r(LJt,"xlnet"),LJt.forEach(t),NYo=r(ZQe," \u2014 "),JU=n(ZQe,"A",{href:!0});var yJt=s(JU);qYo=r(yJt,"XLNetModel"),yJt.forEach(t),jYo=r(ZQe," (XLNet model)"),ZQe.forEach(t),DYo=i(x),Jb=n(x,"LI",{});var KQe=s(Jb);rMe=n(KQe,"STRONG",{});var xJt=s(rMe);GYo=r(xJt,"yolos"),xJt.forEach(t),OYo=r(KQe," \u2014 "),YU=n(KQe,"A",{href:!0});var $Jt=s(YU);VYo=r($Jt,"YolosModel"),$Jt.forEach(t),XYo=r(KQe," (YOLOS model)"),KQe.forEach(t),zYo=i(x),Yb=n(x,"LI",{});var eWe=s(Yb);tMe=n(eWe,"STRONG",{});var kJt=s(tMe);QYo=r(kJt,"yoso"),kJt.forEach(t),WYo=r(eWe," \u2014 "),ZU=n(eWe,"A",{href:!0});var SJt=s(ZU);UYo=r(SJt,"YosoModel"),SJt.forEach(t),HYo=r(eWe," (YOSO model)"),eWe.forEach(t),x.forEach(t),JYo=i(Sa),Zb=n(Sa,"P",{});var oWe=s(Zb);YYo=r(oWe,"The model is set in evaluation mode by default using "),aMe=n(oWe,"CODE",{});var RJt=s(aMe);ZYo=r(RJt,"model.eval()"),RJt.forEach(t),KYo=r(oWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),nMe=n(oWe,"CODE",{});var PJt=s(nMe);eZo=r(PJt,"model.train()"),PJt.forEach(t),oWe.forEach(t),oZo=i(Sa),T(Kb.$$.fragment,Sa),Sa.forEach(t),Ql.forEach(t),zlo=i(c),Xd=n(c,"H2",{class:!0});var gmo=s(Xd);ev=n(gmo,"A",{id:!0,class:!0,href:!0});var BJt=s(ev);sMe=n(BJt,"SPAN",{});var IJt=s(sMe);T(Zk.$$.fragment,IJt),IJt.forEach(t),BJt.forEach(t),rZo=i(gmo),lMe=n(gmo,"SPAN",{});var NJt=s(lMe);tZo=r(NJt,"AutoModelForPreTraining"),NJt.forEach(t),gmo.forEach(t),Qlo=i(c),Go=n(c,"DIV",{class:!0});var Wl=s(Go);T(Kk.$$.fragment,Wl),aZo=i(Wl),zd=n(Wl,"P",{});var hfe=s(zd);nZo=r(hfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),KU=n(hfe,"A",{href:!0});var qJt=s(KU);sZo=r(qJt,"from_pretrained()"),qJt.forEach(t),lZo=r(hfe," class method or the "),eH=n(hfe,"A",{href:!0});var jJt=s(eH);iZo=r(jJt,"from_config()"),jJt.forEach(t),dZo=r(hfe,` class
method.`),hfe.forEach(t),mZo=i(Wl),eS=n(Wl,"P",{});var hmo=s(eS);cZo=r(hmo,"This class cannot be instantiated directly using "),iMe=n(hmo,"CODE",{});var DJt=s(iMe);fZo=r(DJt,"__init__()"),DJt.forEach(t),gZo=r(hmo," (throws an error)."),hmo.forEach(t),hZo=i(Wl),Lt=n(Wl,"DIV",{class:!0});var ix=s(Lt);T(oS.$$.fragment,ix),uZo=i(ix),dMe=n(ix,"P",{});var GJt=s(dMe);pZo=r(GJt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),GJt.forEach(t),_Zo=i(ix),Qd=n(ix,"P",{});var ufe=s(Qd);bZo=r(ufe,`Note:
Loading a model from its configuration file does `),mMe=n(ufe,"STRONG",{});var OJt=s(mMe);vZo=r(OJt,"not"),OJt.forEach(t),FZo=r(ufe,` load the model weights. It only affects the
model\u2019s configuration. Use `),oH=n(ufe,"A",{href:!0});var VJt=s(oH);TZo=r(VJt,"from_pretrained()"),VJt.forEach(t),MZo=r(ufe," to load the model weights."),ufe.forEach(t),EZo=i(ix),T(ov.$$.fragment,ix),ix.forEach(t),CZo=i(Wl),ao=n(Wl,"DIV",{class:!0});var Ra=s(ao);T(rS.$$.fragment,Ra),wZo=i(Ra),cMe=n(Ra,"P",{});var XJt=s(cMe);AZo=r(XJt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),XJt.forEach(t),LZo=i(Ra),gn=n(Ra,"P",{});var dx=s(gn);yZo=r(dx,"The model class to instantiate is selected based on the "),fMe=n(dx,"CODE",{});var zJt=s(fMe);xZo=r(zJt,"model_type"),zJt.forEach(t),$Zo=r(dx,` property of the config object (either
passed as an argument or loaded from `),gMe=n(dx,"CODE",{});var QJt=s(gMe);kZo=r(QJt,"pretrained_model_name_or_path"),QJt.forEach(t),SZo=r(dx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hMe=n(dx,"CODE",{});var WJt=s(hMe);RZo=r(WJt,"pretrained_model_name_or_path"),WJt.forEach(t),PZo=r(dx,":"),dx.forEach(t),BZo=i(Ra),G=n(Ra,"UL",{});var V=s(G);rv=n(V,"LI",{});var rWe=s(rv);uMe=n(rWe,"STRONG",{});var UJt=s(uMe);IZo=r(UJt,"albert"),UJt.forEach(t),NZo=r(rWe," \u2014 "),rH=n(rWe,"A",{href:!0});var HJt=s(rH);qZo=r(HJt,"AlbertForPreTraining"),HJt.forEach(t),jZo=r(rWe," (ALBERT model)"),rWe.forEach(t),DZo=i(V),tv=n(V,"LI",{});var tWe=s(tv);pMe=n(tWe,"STRONG",{});var JJt=s(pMe);GZo=r(JJt,"bart"),JJt.forEach(t),OZo=r(tWe," \u2014 "),tH=n(tWe,"A",{href:!0});var YJt=s(tH);VZo=r(YJt,"BartForConditionalGeneration"),YJt.forEach(t),XZo=r(tWe," (BART model)"),tWe.forEach(t),zZo=i(V),av=n(V,"LI",{});var aWe=s(av);_Me=n(aWe,"STRONG",{});var ZJt=s(_Me);QZo=r(ZJt,"bert"),ZJt.forEach(t),WZo=r(aWe," \u2014 "),aH=n(aWe,"A",{href:!0});var KJt=s(aH);UZo=r(KJt,"BertForPreTraining"),KJt.forEach(t),HZo=r(aWe," (BERT model)"),aWe.forEach(t),JZo=i(V),nv=n(V,"LI",{});var nWe=s(nv);bMe=n(nWe,"STRONG",{});var eYt=s(bMe);YZo=r(eYt,"big_bird"),eYt.forEach(t),ZZo=r(nWe," \u2014 "),nH=n(nWe,"A",{href:!0});var oYt=s(nH);KZo=r(oYt,"BigBirdForPreTraining"),oYt.forEach(t),eKo=r(nWe," (BigBird model)"),nWe.forEach(t),oKo=i(V),sv=n(V,"LI",{});var sWe=s(sv);vMe=n(sWe,"STRONG",{});var rYt=s(vMe);rKo=r(rYt,"bloom"),rYt.forEach(t),tKo=r(sWe," \u2014 "),sH=n(sWe,"A",{href:!0});var tYt=s(sH);aKo=r(tYt,"BloomForCausalLM"),tYt.forEach(t),nKo=r(sWe," (BLOOM model)"),sWe.forEach(t),sKo=i(V),lv=n(V,"LI",{});var lWe=s(lv);FMe=n(lWe,"STRONG",{});var aYt=s(FMe);lKo=r(aYt,"camembert"),aYt.forEach(t),iKo=r(lWe," \u2014 "),lH=n(lWe,"A",{href:!0});var nYt=s(lH);dKo=r(nYt,"CamembertForMaskedLM"),nYt.forEach(t),mKo=r(lWe," (CamemBERT model)"),lWe.forEach(t),cKo=i(V),iv=n(V,"LI",{});var iWe=s(iv);TMe=n(iWe,"STRONG",{});var sYt=s(TMe);fKo=r(sYt,"ctrl"),sYt.forEach(t),gKo=r(iWe," \u2014 "),iH=n(iWe,"A",{href:!0});var lYt=s(iH);hKo=r(lYt,"CTRLLMHeadModel"),lYt.forEach(t),uKo=r(iWe," (CTRL model)"),iWe.forEach(t),pKo=i(V),dv=n(V,"LI",{});var dWe=s(dv);MMe=n(dWe,"STRONG",{});var iYt=s(MMe);_Ko=r(iYt,"data2vec-text"),iYt.forEach(t),bKo=r(dWe," \u2014 "),dH=n(dWe,"A",{href:!0});var dYt=s(dH);vKo=r(dYt,"Data2VecTextForMaskedLM"),dYt.forEach(t),FKo=r(dWe," (Data2VecText model)"),dWe.forEach(t),TKo=i(V),mv=n(V,"LI",{});var mWe=s(mv);EMe=n(mWe,"STRONG",{});var mYt=s(EMe);MKo=r(mYt,"deberta"),mYt.forEach(t),EKo=r(mWe," \u2014 "),mH=n(mWe,"A",{href:!0});var cYt=s(mH);CKo=r(cYt,"DebertaForMaskedLM"),cYt.forEach(t),wKo=r(mWe," (DeBERTa model)"),mWe.forEach(t),AKo=i(V),cv=n(V,"LI",{});var cWe=s(cv);CMe=n(cWe,"STRONG",{});var fYt=s(CMe);LKo=r(fYt,"deberta-v2"),fYt.forEach(t),yKo=r(cWe," \u2014 "),cH=n(cWe,"A",{href:!0});var gYt=s(cH);xKo=r(gYt,"DebertaV2ForMaskedLM"),gYt.forEach(t),$Ko=r(cWe," (DeBERTa-v2 model)"),cWe.forEach(t),kKo=i(V),fv=n(V,"LI",{});var fWe=s(fv);wMe=n(fWe,"STRONG",{});var hYt=s(wMe);SKo=r(hYt,"distilbert"),hYt.forEach(t),RKo=r(fWe," \u2014 "),fH=n(fWe,"A",{href:!0});var uYt=s(fH);PKo=r(uYt,"DistilBertForMaskedLM"),uYt.forEach(t),BKo=r(fWe," (DistilBERT model)"),fWe.forEach(t),IKo=i(V),gv=n(V,"LI",{});var gWe=s(gv);AMe=n(gWe,"STRONG",{});var pYt=s(AMe);NKo=r(pYt,"electra"),pYt.forEach(t),qKo=r(gWe," \u2014 "),gH=n(gWe,"A",{href:!0});var _Yt=s(gH);jKo=r(_Yt,"ElectraForPreTraining"),_Yt.forEach(t),DKo=r(gWe," (ELECTRA model)"),gWe.forEach(t),GKo=i(V),hv=n(V,"LI",{});var hWe=s(hv);LMe=n(hWe,"STRONG",{});var bYt=s(LMe);OKo=r(bYt,"ernie"),bYt.forEach(t),VKo=r(hWe," \u2014 "),hH=n(hWe,"A",{href:!0});var vYt=s(hH);XKo=r(vYt,"ErnieForPreTraining"),vYt.forEach(t),zKo=r(hWe," (ERNIE model)"),hWe.forEach(t),QKo=i(V),uv=n(V,"LI",{});var uWe=s(uv);yMe=n(uWe,"STRONG",{});var FYt=s(yMe);WKo=r(FYt,"flaubert"),FYt.forEach(t),UKo=r(uWe," \u2014 "),uH=n(uWe,"A",{href:!0});var TYt=s(uH);HKo=r(TYt,"FlaubertWithLMHeadModel"),TYt.forEach(t),JKo=r(uWe," (FlauBERT model)"),uWe.forEach(t),YKo=i(V),pv=n(V,"LI",{});var pWe=s(pv);xMe=n(pWe,"STRONG",{});var MYt=s(xMe);ZKo=r(MYt,"flava"),MYt.forEach(t),KKo=r(pWe," \u2014 "),pH=n(pWe,"A",{href:!0});var EYt=s(pH);eer=r(EYt,"FlavaForPreTraining"),EYt.forEach(t),oer=r(pWe," (FLAVA model)"),pWe.forEach(t),rer=i(V),_v=n(V,"LI",{});var _We=s(_v);$Me=n(_We,"STRONG",{});var CYt=s($Me);ter=r(CYt,"fnet"),CYt.forEach(t),aer=r(_We," \u2014 "),_H=n(_We,"A",{href:!0});var wYt=s(_H);ner=r(wYt,"FNetForPreTraining"),wYt.forEach(t),ser=r(_We," (FNet model)"),_We.forEach(t),ler=i(V),bv=n(V,"LI",{});var bWe=s(bv);kMe=n(bWe,"STRONG",{});var AYt=s(kMe);ier=r(AYt,"fsmt"),AYt.forEach(t),der=r(bWe," \u2014 "),bH=n(bWe,"A",{href:!0});var LYt=s(bH);mer=r(LYt,"FSMTForConditionalGeneration"),LYt.forEach(t),cer=r(bWe," (FairSeq Machine-Translation model)"),bWe.forEach(t),fer=i(V),vv=n(V,"LI",{});var vWe=s(vv);SMe=n(vWe,"STRONG",{});var yYt=s(SMe);ger=r(yYt,"funnel"),yYt.forEach(t),her=r(vWe," \u2014 "),vH=n(vWe,"A",{href:!0});var xYt=s(vH);uer=r(xYt,"FunnelForPreTraining"),xYt.forEach(t),per=r(vWe," (Funnel Transformer model)"),vWe.forEach(t),_er=i(V),Fv=n(V,"LI",{});var FWe=s(Fv);RMe=n(FWe,"STRONG",{});var $Yt=s(RMe);ber=r($Yt,"gpt2"),$Yt.forEach(t),ver=r(FWe," \u2014 "),FH=n(FWe,"A",{href:!0});var kYt=s(FH);Fer=r(kYt,"GPT2LMHeadModel"),kYt.forEach(t),Ter=r(FWe," (OpenAI GPT-2 model)"),FWe.forEach(t),Mer=i(V),Tv=n(V,"LI",{});var TWe=s(Tv);PMe=n(TWe,"STRONG",{});var SYt=s(PMe);Eer=r(SYt,"ibert"),SYt.forEach(t),Cer=r(TWe," \u2014 "),TH=n(TWe,"A",{href:!0});var RYt=s(TH);wer=r(RYt,"IBertForMaskedLM"),RYt.forEach(t),Aer=r(TWe," (I-BERT model)"),TWe.forEach(t),Ler=i(V),Mv=n(V,"LI",{});var MWe=s(Mv);BMe=n(MWe,"STRONG",{});var PYt=s(BMe);yer=r(PYt,"layoutlm"),PYt.forEach(t),xer=r(MWe," \u2014 "),MH=n(MWe,"A",{href:!0});var BYt=s(MH);$er=r(BYt,"LayoutLMForMaskedLM"),BYt.forEach(t),ker=r(MWe," (LayoutLM model)"),MWe.forEach(t),Ser=i(V),Ev=n(V,"LI",{});var EWe=s(Ev);IMe=n(EWe,"STRONG",{});var IYt=s(IMe);Rer=r(IYt,"longformer"),IYt.forEach(t),Per=r(EWe," \u2014 "),EH=n(EWe,"A",{href:!0});var NYt=s(EH);Ber=r(NYt,"LongformerForMaskedLM"),NYt.forEach(t),Ier=r(EWe," (Longformer model)"),EWe.forEach(t),Ner=i(V),Cv=n(V,"LI",{});var CWe=s(Cv);NMe=n(CWe,"STRONG",{});var qYt=s(NMe);qer=r(qYt,"luke"),qYt.forEach(t),jer=r(CWe," \u2014 "),CH=n(CWe,"A",{href:!0});var jYt=s(CH);Der=r(jYt,"LukeForMaskedLM"),jYt.forEach(t),Ger=r(CWe," (LUKE model)"),CWe.forEach(t),Oer=i(V),wv=n(V,"LI",{});var wWe=s(wv);qMe=n(wWe,"STRONG",{});var DYt=s(qMe);Ver=r(DYt,"lxmert"),DYt.forEach(t),Xer=r(wWe," \u2014 "),wH=n(wWe,"A",{href:!0});var GYt=s(wH);zer=r(GYt,"LxmertForPreTraining"),GYt.forEach(t),Qer=r(wWe," (LXMERT model)"),wWe.forEach(t),Wer=i(V),Av=n(V,"LI",{});var AWe=s(Av);jMe=n(AWe,"STRONG",{});var OYt=s(jMe);Uer=r(OYt,"megatron-bert"),OYt.forEach(t),Her=r(AWe," \u2014 "),AH=n(AWe,"A",{href:!0});var VYt=s(AH);Jer=r(VYt,"MegatronBertForPreTraining"),VYt.forEach(t),Yer=r(AWe," (Megatron-BERT model)"),AWe.forEach(t),Zer=i(V),Lv=n(V,"LI",{});var LWe=s(Lv);DMe=n(LWe,"STRONG",{});var XYt=s(DMe);Ker=r(XYt,"mobilebert"),XYt.forEach(t),eor=r(LWe," \u2014 "),LH=n(LWe,"A",{href:!0});var zYt=s(LH);oor=r(zYt,"MobileBertForPreTraining"),zYt.forEach(t),ror=r(LWe," (MobileBERT model)"),LWe.forEach(t),tor=i(V),yv=n(V,"LI",{});var yWe=s(yv);GMe=n(yWe,"STRONG",{});var QYt=s(GMe);aor=r(QYt,"mpnet"),QYt.forEach(t),nor=r(yWe," \u2014 "),yH=n(yWe,"A",{href:!0});var WYt=s(yH);sor=r(WYt,"MPNetForMaskedLM"),WYt.forEach(t),lor=r(yWe," (MPNet model)"),yWe.forEach(t),ior=i(V),xv=n(V,"LI",{});var xWe=s(xv);OMe=n(xWe,"STRONG",{});var UYt=s(OMe);dor=r(UYt,"mvp"),UYt.forEach(t),mor=r(xWe," \u2014 "),xH=n(xWe,"A",{href:!0});var HYt=s(xH);cor=r(HYt,"MvpForConditionalGeneration"),HYt.forEach(t),gor=r(xWe," (MVP model)"),xWe.forEach(t),hor=i(V),$v=n(V,"LI",{});var $We=s($v);VMe=n($We,"STRONG",{});var JYt=s(VMe);uor=r(JYt,"nezha"),JYt.forEach(t),por=r($We," \u2014 "),$H=n($We,"A",{href:!0});var YYt=s($H);_or=r(YYt,"NezhaForPreTraining"),YYt.forEach(t),bor=r($We," (Nezha model)"),$We.forEach(t),vor=i(V),kv=n(V,"LI",{});var kWe=s(kv);XMe=n(kWe,"STRONG",{});var ZYt=s(XMe);For=r(ZYt,"openai-gpt"),ZYt.forEach(t),Tor=r(kWe," \u2014 "),kH=n(kWe,"A",{href:!0});var KYt=s(kH);Mor=r(KYt,"OpenAIGPTLMHeadModel"),KYt.forEach(t),Eor=r(kWe," (OpenAI GPT model)"),kWe.forEach(t),Cor=i(V),Sv=n(V,"LI",{});var SWe=s(Sv);zMe=n(SWe,"STRONG",{});var eZt=s(zMe);wor=r(eZt,"retribert"),eZt.forEach(t),Aor=r(SWe," \u2014 "),SH=n(SWe,"A",{href:!0});var oZt=s(SH);Lor=r(oZt,"RetriBertModel"),oZt.forEach(t),yor=r(SWe," (RetriBERT model)"),SWe.forEach(t),xor=i(V),Rv=n(V,"LI",{});var RWe=s(Rv);QMe=n(RWe,"STRONG",{});var rZt=s(QMe);$or=r(rZt,"roberta"),rZt.forEach(t),kor=r(RWe," \u2014 "),RH=n(RWe,"A",{href:!0});var tZt=s(RH);Sor=r(tZt,"RobertaForMaskedLM"),tZt.forEach(t),Ror=r(RWe," (RoBERTa model)"),RWe.forEach(t),Por=i(V),Pv=n(V,"LI",{});var PWe=s(Pv);WMe=n(PWe,"STRONG",{});var aZt=s(WMe);Bor=r(aZt,"roc_bert"),aZt.forEach(t),Ior=r(PWe," \u2014 "),PH=n(PWe,"A",{href:!0});var nZt=s(PH);Nor=r(nZt,"RoCBertForPreTraining"),nZt.forEach(t),qor=r(PWe," (RoCBert model)"),PWe.forEach(t),jor=i(V),Bv=n(V,"LI",{});var BWe=s(Bv);UMe=n(BWe,"STRONG",{});var sZt=s(UMe);Dor=r(sZt,"splinter"),sZt.forEach(t),Gor=r(BWe," \u2014 "),BH=n(BWe,"A",{href:!0});var lZt=s(BH);Oor=r(lZt,"SplinterForPreTraining"),lZt.forEach(t),Vor=r(BWe," (Splinter model)"),BWe.forEach(t),Xor=i(V),Iv=n(V,"LI",{});var IWe=s(Iv);HMe=n(IWe,"STRONG",{});var iZt=s(HMe);zor=r(iZt,"squeezebert"),iZt.forEach(t),Qor=r(IWe," \u2014 "),IH=n(IWe,"A",{href:!0});var dZt=s(IH);Wor=r(dZt,"SqueezeBertForMaskedLM"),dZt.forEach(t),Uor=r(IWe," (SqueezeBERT model)"),IWe.forEach(t),Hor=i(V),Nv=n(V,"LI",{});var NWe=s(Nv);JMe=n(NWe,"STRONG",{});var mZt=s(JMe);Jor=r(mZt,"t5"),mZt.forEach(t),Yor=r(NWe," \u2014 "),NH=n(NWe,"A",{href:!0});var cZt=s(NH);Zor=r(cZt,"T5ForConditionalGeneration"),cZt.forEach(t),Kor=r(NWe," (T5 model)"),NWe.forEach(t),err=i(V),qv=n(V,"LI",{});var qWe=s(qv);YMe=n(qWe,"STRONG",{});var fZt=s(YMe);orr=r(fZt,"tapas"),fZt.forEach(t),rrr=r(qWe," \u2014 "),qH=n(qWe,"A",{href:!0});var gZt=s(qH);trr=r(gZt,"TapasForMaskedLM"),gZt.forEach(t),arr=r(qWe," (TAPAS model)"),qWe.forEach(t),nrr=i(V),jv=n(V,"LI",{});var jWe=s(jv);ZMe=n(jWe,"STRONG",{});var hZt=s(ZMe);srr=r(hZt,"transfo-xl"),hZt.forEach(t),lrr=r(jWe," \u2014 "),jH=n(jWe,"A",{href:!0});var uZt=s(jH);irr=r(uZt,"TransfoXLLMHeadModel"),uZt.forEach(t),drr=r(jWe," (Transformer-XL model)"),jWe.forEach(t),mrr=i(V),Dv=n(V,"LI",{});var DWe=s(Dv);KMe=n(DWe,"STRONG",{});var pZt=s(KMe);crr=r(pZt,"unispeech"),pZt.forEach(t),frr=r(DWe," \u2014 "),DH=n(DWe,"A",{href:!0});var _Zt=s(DH);grr=r(_Zt,"UniSpeechForPreTraining"),_Zt.forEach(t),hrr=r(DWe," (UniSpeech model)"),DWe.forEach(t),urr=i(V),Gv=n(V,"LI",{});var GWe=s(Gv);eEe=n(GWe,"STRONG",{});var bZt=s(eEe);prr=r(bZt,"unispeech-sat"),bZt.forEach(t),_rr=r(GWe," \u2014 "),GH=n(GWe,"A",{href:!0});var vZt=s(GH);brr=r(vZt,"UniSpeechSatForPreTraining"),vZt.forEach(t),vrr=r(GWe," (UniSpeechSat model)"),GWe.forEach(t),Frr=i(V),Ov=n(V,"LI",{});var OWe=s(Ov);oEe=n(OWe,"STRONG",{});var FZt=s(oEe);Trr=r(FZt,"videomae"),FZt.forEach(t),Mrr=r(OWe," \u2014 "),OH=n(OWe,"A",{href:!0});var TZt=s(OH);Err=r(TZt,"VideoMAEForPreTraining"),TZt.forEach(t),Crr=r(OWe," (VideoMAE model)"),OWe.forEach(t),wrr=i(V),Vv=n(V,"LI",{});var VWe=s(Vv);rEe=n(VWe,"STRONG",{});var MZt=s(rEe);Arr=r(MZt,"visual_bert"),MZt.forEach(t),Lrr=r(VWe," \u2014 "),VH=n(VWe,"A",{href:!0});var EZt=s(VH);yrr=r(EZt,"VisualBertForPreTraining"),EZt.forEach(t),xrr=r(VWe," (VisualBERT model)"),VWe.forEach(t),$rr=i(V),Xv=n(V,"LI",{});var XWe=s(Xv);tEe=n(XWe,"STRONG",{});var CZt=s(tEe);krr=r(CZt,"vit_mae"),CZt.forEach(t),Srr=r(XWe," \u2014 "),XH=n(XWe,"A",{href:!0});var wZt=s(XH);Rrr=r(wZt,"ViTMAEForPreTraining"),wZt.forEach(t),Prr=r(XWe," (ViTMAE model)"),XWe.forEach(t),Brr=i(V),zv=n(V,"LI",{});var zWe=s(zv);aEe=n(zWe,"STRONG",{});var AZt=s(aEe);Irr=r(AZt,"wav2vec2"),AZt.forEach(t),Nrr=r(zWe," \u2014 "),zH=n(zWe,"A",{href:!0});var LZt=s(zH);qrr=r(LZt,"Wav2Vec2ForPreTraining"),LZt.forEach(t),jrr=r(zWe," (Wav2Vec2 model)"),zWe.forEach(t),Drr=i(V),Qv=n(V,"LI",{});var QWe=s(Qv);nEe=n(QWe,"STRONG",{});var yZt=s(nEe);Grr=r(yZt,"wav2vec2-conformer"),yZt.forEach(t),Orr=r(QWe," \u2014 "),QH=n(QWe,"A",{href:!0});var xZt=s(QH);Vrr=r(xZt,"Wav2Vec2ConformerForPreTraining"),xZt.forEach(t),Xrr=r(QWe," (Wav2Vec2-Conformer model)"),QWe.forEach(t),zrr=i(V),Wv=n(V,"LI",{});var WWe=s(Wv);sEe=n(WWe,"STRONG",{});var $Zt=s(sEe);Qrr=r($Zt,"xlm"),$Zt.forEach(t),Wrr=r(WWe," \u2014 "),WH=n(WWe,"A",{href:!0});var kZt=s(WH);Urr=r(kZt,"XLMWithLMHeadModel"),kZt.forEach(t),Hrr=r(WWe," (XLM model)"),WWe.forEach(t),Jrr=i(V),Uv=n(V,"LI",{});var UWe=s(Uv);lEe=n(UWe,"STRONG",{});var SZt=s(lEe);Yrr=r(SZt,"xlm-roberta"),SZt.forEach(t),Zrr=r(UWe," \u2014 "),UH=n(UWe,"A",{href:!0});var RZt=s(UH);Krr=r(RZt,"XLMRobertaForMaskedLM"),RZt.forEach(t),etr=r(UWe," (XLM-RoBERTa model)"),UWe.forEach(t),otr=i(V),Hv=n(V,"LI",{});var HWe=s(Hv);iEe=n(HWe,"STRONG",{});var PZt=s(iEe);rtr=r(PZt,"xlm-roberta-xl"),PZt.forEach(t),ttr=r(HWe," \u2014 "),HH=n(HWe,"A",{href:!0});var BZt=s(HH);atr=r(BZt,"XLMRobertaXLForMaskedLM"),BZt.forEach(t),ntr=r(HWe," (XLM-RoBERTa-XL model)"),HWe.forEach(t),str=i(V),Jv=n(V,"LI",{});var JWe=s(Jv);dEe=n(JWe,"STRONG",{});var IZt=s(dEe);ltr=r(IZt,"xlnet"),IZt.forEach(t),itr=r(JWe," \u2014 "),JH=n(JWe,"A",{href:!0});var NZt=s(JH);dtr=r(NZt,"XLNetLMHeadModel"),NZt.forEach(t),mtr=r(JWe," (XLNet model)"),JWe.forEach(t),V.forEach(t),ctr=i(Ra),Yv=n(Ra,"P",{});var YWe=s(Yv);ftr=r(YWe,"The model is set in evaluation mode by default using "),mEe=n(YWe,"CODE",{});var qZt=s(mEe);gtr=r(qZt,"model.eval()"),qZt.forEach(t),htr=r(YWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cEe=n(YWe,"CODE",{});var jZt=s(cEe);utr=r(jZt,"model.train()"),jZt.forEach(t),YWe.forEach(t),ptr=i(Ra),T(Zv.$$.fragment,Ra),Ra.forEach(t),Wl.forEach(t),Wlo=i(c),Wd=n(c,"H2",{class:!0});var umo=s(Wd);Kv=n(umo,"A",{id:!0,class:!0,href:!0});var DZt=s(Kv);fEe=n(DZt,"SPAN",{});var GZt=s(fEe);T(tS.$$.fragment,GZt),GZt.forEach(t),DZt.forEach(t),_tr=i(umo),gEe=n(umo,"SPAN",{});var OZt=s(gEe);btr=r(OZt,"AutoModelForCausalLM"),OZt.forEach(t),umo.forEach(t),Ulo=i(c),Oo=n(c,"DIV",{class:!0});var Ul=s(Oo);T(aS.$$.fragment,Ul),vtr=i(Ul),Ud=n(Ul,"P",{});var pfe=s(Ud);Ftr=r(pfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),YH=n(pfe,"A",{href:!0});var VZt=s(YH);Ttr=r(VZt,"from_pretrained()"),VZt.forEach(t),Mtr=r(pfe," class method or the "),ZH=n(pfe,"A",{href:!0});var XZt=s(ZH);Etr=r(XZt,"from_config()"),XZt.forEach(t),Ctr=r(pfe,` class
method.`),pfe.forEach(t),wtr=i(Ul),nS=n(Ul,"P",{});var pmo=s(nS);Atr=r(pmo,"This class cannot be instantiated directly using "),hEe=n(pmo,"CODE",{});var zZt=s(hEe);Ltr=r(zZt,"__init__()"),zZt.forEach(t),ytr=r(pmo," (throws an error)."),pmo.forEach(t),xtr=i(Ul),yt=n(Ul,"DIV",{class:!0});var mx=s(yt);T(sS.$$.fragment,mx),$tr=i(mx),uEe=n(mx,"P",{});var QZt=s(uEe);ktr=r(QZt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),QZt.forEach(t),Str=i(mx),Hd=n(mx,"P",{});var _fe=s(Hd);Rtr=r(_fe,`Note:
Loading a model from its configuration file does `),pEe=n(_fe,"STRONG",{});var WZt=s(pEe);Ptr=r(WZt,"not"),WZt.forEach(t),Btr=r(_fe,` load the model weights. It only affects the
model\u2019s configuration. Use `),KH=n(_fe,"A",{href:!0});var UZt=s(KH);Itr=r(UZt,"from_pretrained()"),UZt.forEach(t),Ntr=r(_fe," to load the model weights."),_fe.forEach(t),qtr=i(mx),T(eF.$$.fragment,mx),mx.forEach(t),jtr=i(Ul),no=n(Ul,"DIV",{class:!0});var Pa=s(no);T(lS.$$.fragment,Pa),Dtr=i(Pa),_Ee=n(Pa,"P",{});var HZt=s(_Ee);Gtr=r(HZt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),HZt.forEach(t),Otr=i(Pa),hn=n(Pa,"P",{});var cx=s(hn);Vtr=r(cx,"The model class to instantiate is selected based on the "),bEe=n(cx,"CODE",{});var JZt=s(bEe);Xtr=r(JZt,"model_type"),JZt.forEach(t),ztr=r(cx,` property of the config object (either
passed as an argument or loaded from `),vEe=n(cx,"CODE",{});var YZt=s(vEe);Qtr=r(YZt,"pretrained_model_name_or_path"),YZt.forEach(t),Wtr=r(cx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FEe=n(cx,"CODE",{});var ZZt=s(FEe);Utr=r(ZZt,"pretrained_model_name_or_path"),ZZt.forEach(t),Htr=r(cx,":"),cx.forEach(t),Jtr=i(Pa),W=n(Pa,"UL",{});var H=s(W);oF=n(H,"LI",{});var ZWe=s(oF);TEe=n(ZWe,"STRONG",{});var KZt=s(TEe);Ytr=r(KZt,"bart"),KZt.forEach(t),Ztr=r(ZWe," \u2014 "),eJ=n(ZWe,"A",{href:!0});var eKt=s(eJ);Ktr=r(eKt,"BartForCausalLM"),eKt.forEach(t),ear=r(ZWe," (BART model)"),ZWe.forEach(t),oar=i(H),rF=n(H,"LI",{});var KWe=s(rF);MEe=n(KWe,"STRONG",{});var oKt=s(MEe);rar=r(oKt,"bert"),oKt.forEach(t),tar=r(KWe," \u2014 "),oJ=n(KWe,"A",{href:!0});var rKt=s(oJ);aar=r(rKt,"BertLMHeadModel"),rKt.forEach(t),nar=r(KWe," (BERT model)"),KWe.forEach(t),sar=i(H),tF=n(H,"LI",{});var eUe=s(tF);EEe=n(eUe,"STRONG",{});var tKt=s(EEe);lar=r(tKt,"bert-generation"),tKt.forEach(t),iar=r(eUe," \u2014 "),rJ=n(eUe,"A",{href:!0});var aKt=s(rJ);dar=r(aKt,"BertGenerationDecoder"),aKt.forEach(t),mar=r(eUe," (Bert Generation model)"),eUe.forEach(t),car=i(H),aF=n(H,"LI",{});var oUe=s(aF);CEe=n(oUe,"STRONG",{});var nKt=s(CEe);far=r(nKt,"big_bird"),nKt.forEach(t),gar=r(oUe," \u2014 "),tJ=n(oUe,"A",{href:!0});var sKt=s(tJ);har=r(sKt,"BigBirdForCausalLM"),sKt.forEach(t),uar=r(oUe," (BigBird model)"),oUe.forEach(t),par=i(H),nF=n(H,"LI",{});var rUe=s(nF);wEe=n(rUe,"STRONG",{});var lKt=s(wEe);_ar=r(lKt,"bigbird_pegasus"),lKt.forEach(t),bar=r(rUe," \u2014 "),aJ=n(rUe,"A",{href:!0});var iKt=s(aJ);Far=r(iKt,"BigBirdPegasusForCausalLM"),iKt.forEach(t),Tar=r(rUe," (BigBird-Pegasus model)"),rUe.forEach(t),Mar=i(H),sF=n(H,"LI",{});var tUe=s(sF);AEe=n(tUe,"STRONG",{});var dKt=s(AEe);Ear=r(dKt,"blenderbot"),dKt.forEach(t),Car=r(tUe," \u2014 "),nJ=n(tUe,"A",{href:!0});var mKt=s(nJ);war=r(mKt,"BlenderbotForCausalLM"),mKt.forEach(t),Aar=r(tUe," (Blenderbot model)"),tUe.forEach(t),Lar=i(H),lF=n(H,"LI",{});var aUe=s(lF);LEe=n(aUe,"STRONG",{});var cKt=s(LEe);yar=r(cKt,"blenderbot-small"),cKt.forEach(t),xar=r(aUe," \u2014 "),sJ=n(aUe,"A",{href:!0});var fKt=s(sJ);$ar=r(fKt,"BlenderbotSmallForCausalLM"),fKt.forEach(t),kar=r(aUe," (BlenderbotSmall model)"),aUe.forEach(t),Sar=i(H),iF=n(H,"LI",{});var nUe=s(iF);yEe=n(nUe,"STRONG",{});var gKt=s(yEe);Rar=r(gKt,"bloom"),gKt.forEach(t),Par=r(nUe," \u2014 "),lJ=n(nUe,"A",{href:!0});var hKt=s(lJ);Bar=r(hKt,"BloomForCausalLM"),hKt.forEach(t),Iar=r(nUe," (BLOOM model)"),nUe.forEach(t),Nar=i(H),dF=n(H,"LI",{});var sUe=s(dF);xEe=n(sUe,"STRONG",{});var uKt=s(xEe);qar=r(uKt,"camembert"),uKt.forEach(t),jar=r(sUe," \u2014 "),iJ=n(sUe,"A",{href:!0});var pKt=s(iJ);Dar=r(pKt,"CamembertForCausalLM"),pKt.forEach(t),Gar=r(sUe," (CamemBERT model)"),sUe.forEach(t),Oar=i(H),mF=n(H,"LI",{});var lUe=s(mF);$Ee=n(lUe,"STRONG",{});var _Kt=s($Ee);Var=r(_Kt,"codegen"),_Kt.forEach(t),Xar=r(lUe," \u2014 "),dJ=n(lUe,"A",{href:!0});var bKt=s(dJ);zar=r(bKt,"CodeGenForCausalLM"),bKt.forEach(t),Qar=r(lUe," (CodeGen model)"),lUe.forEach(t),War=i(H),cF=n(H,"LI",{});var iUe=s(cF);kEe=n(iUe,"STRONG",{});var vKt=s(kEe);Uar=r(vKt,"ctrl"),vKt.forEach(t),Har=r(iUe," \u2014 "),mJ=n(iUe,"A",{href:!0});var FKt=s(mJ);Jar=r(FKt,"CTRLLMHeadModel"),FKt.forEach(t),Yar=r(iUe," (CTRL model)"),iUe.forEach(t),Zar=i(H),fF=n(H,"LI",{});var dUe=s(fF);SEe=n(dUe,"STRONG",{});var TKt=s(SEe);Kar=r(TKt,"data2vec-text"),TKt.forEach(t),enr=r(dUe," \u2014 "),cJ=n(dUe,"A",{href:!0});var MKt=s(cJ);onr=r(MKt,"Data2VecTextForCausalLM"),MKt.forEach(t),rnr=r(dUe," (Data2VecText model)"),dUe.forEach(t),tnr=i(H),gF=n(H,"LI",{});var mUe=s(gF);REe=n(mUe,"STRONG",{});var EKt=s(REe);anr=r(EKt,"electra"),EKt.forEach(t),nnr=r(mUe," \u2014 "),fJ=n(mUe,"A",{href:!0});var CKt=s(fJ);snr=r(CKt,"ElectraForCausalLM"),CKt.forEach(t),lnr=r(mUe," (ELECTRA model)"),mUe.forEach(t),inr=i(H),hF=n(H,"LI",{});var cUe=s(hF);PEe=n(cUe,"STRONG",{});var wKt=s(PEe);dnr=r(wKt,"ernie"),wKt.forEach(t),mnr=r(cUe," \u2014 "),gJ=n(cUe,"A",{href:!0});var AKt=s(gJ);cnr=r(AKt,"ErnieForCausalLM"),AKt.forEach(t),fnr=r(cUe," (ERNIE model)"),cUe.forEach(t),gnr=i(H),uF=n(H,"LI",{});var fUe=s(uF);BEe=n(fUe,"STRONG",{});var LKt=s(BEe);hnr=r(LKt,"gpt2"),LKt.forEach(t),unr=r(fUe," \u2014 "),hJ=n(fUe,"A",{href:!0});var yKt=s(hJ);pnr=r(yKt,"GPT2LMHeadModel"),yKt.forEach(t),_nr=r(fUe," (OpenAI GPT-2 model)"),fUe.forEach(t),bnr=i(H),pF=n(H,"LI",{});var gUe=s(pF);IEe=n(gUe,"STRONG",{});var xKt=s(IEe);vnr=r(xKt,"gpt_neo"),xKt.forEach(t),Fnr=r(gUe," \u2014 "),uJ=n(gUe,"A",{href:!0});var $Kt=s(uJ);Tnr=r($Kt,"GPTNeoForCausalLM"),$Kt.forEach(t),Mnr=r(gUe," (GPT Neo model)"),gUe.forEach(t),Enr=i(H),_F=n(H,"LI",{});var hUe=s(_F);NEe=n(hUe,"STRONG",{});var kKt=s(NEe);Cnr=r(kKt,"gpt_neox"),kKt.forEach(t),wnr=r(hUe," \u2014 "),pJ=n(hUe,"A",{href:!0});var SKt=s(pJ);Anr=r(SKt,"GPTNeoXForCausalLM"),SKt.forEach(t),Lnr=r(hUe," (GPT NeoX model)"),hUe.forEach(t),ynr=i(H),bF=n(H,"LI",{});var uUe=s(bF);qEe=n(uUe,"STRONG",{});var RKt=s(qEe);xnr=r(RKt,"gpt_neox_japanese"),RKt.forEach(t),$nr=r(uUe," \u2014 "),_J=n(uUe,"A",{href:!0});var PKt=s(_J);knr=r(PKt,"GPTNeoXJapaneseForCausalLM"),PKt.forEach(t),Snr=r(uUe," (GPT NeoX Japanese model)"),uUe.forEach(t),Rnr=i(H),vF=n(H,"LI",{});var pUe=s(vF);jEe=n(pUe,"STRONG",{});var BKt=s(jEe);Pnr=r(BKt,"gptj"),BKt.forEach(t),Bnr=r(pUe," \u2014 "),bJ=n(pUe,"A",{href:!0});var IKt=s(bJ);Inr=r(IKt,"GPTJForCausalLM"),IKt.forEach(t),Nnr=r(pUe," (GPT-J model)"),pUe.forEach(t),qnr=i(H),FF=n(H,"LI",{});var _Ue=s(FF);DEe=n(_Ue,"STRONG",{});var NKt=s(DEe);jnr=r(NKt,"marian"),NKt.forEach(t),Dnr=r(_Ue," \u2014 "),vJ=n(_Ue,"A",{href:!0});var qKt=s(vJ);Gnr=r(qKt,"MarianForCausalLM"),qKt.forEach(t),Onr=r(_Ue," (Marian model)"),_Ue.forEach(t),Vnr=i(H),TF=n(H,"LI",{});var bUe=s(TF);GEe=n(bUe,"STRONG",{});var jKt=s(GEe);Xnr=r(jKt,"mbart"),jKt.forEach(t),znr=r(bUe," \u2014 "),FJ=n(bUe,"A",{href:!0});var DKt=s(FJ);Qnr=r(DKt,"MBartForCausalLM"),DKt.forEach(t),Wnr=r(bUe," (mBART model)"),bUe.forEach(t),Unr=i(H),MF=n(H,"LI",{});var vUe=s(MF);OEe=n(vUe,"STRONG",{});var GKt=s(OEe);Hnr=r(GKt,"megatron-bert"),GKt.forEach(t),Jnr=r(vUe," \u2014 "),TJ=n(vUe,"A",{href:!0});var OKt=s(TJ);Ynr=r(OKt,"MegatronBertForCausalLM"),OKt.forEach(t),Znr=r(vUe," (Megatron-BERT model)"),vUe.forEach(t),Knr=i(H),EF=n(H,"LI",{});var FUe=s(EF);VEe=n(FUe,"STRONG",{});var VKt=s(VEe);esr=r(VKt,"mvp"),VKt.forEach(t),osr=r(FUe," \u2014 "),MJ=n(FUe,"A",{href:!0});var XKt=s(MJ);rsr=r(XKt,"MvpForCausalLM"),XKt.forEach(t),tsr=r(FUe," (MVP model)"),FUe.forEach(t),asr=i(H),CF=n(H,"LI",{});var TUe=s(CF);XEe=n(TUe,"STRONG",{});var zKt=s(XEe);nsr=r(zKt,"openai-gpt"),zKt.forEach(t),ssr=r(TUe," \u2014 "),EJ=n(TUe,"A",{href:!0});var QKt=s(EJ);lsr=r(QKt,"OpenAIGPTLMHeadModel"),QKt.forEach(t),isr=r(TUe," (OpenAI GPT model)"),TUe.forEach(t),dsr=i(H),wF=n(H,"LI",{});var MUe=s(wF);zEe=n(MUe,"STRONG",{});var WKt=s(zEe);msr=r(WKt,"opt"),WKt.forEach(t),csr=r(MUe," \u2014 "),CJ=n(MUe,"A",{href:!0});var UKt=s(CJ);fsr=r(UKt,"OPTForCausalLM"),UKt.forEach(t),gsr=r(MUe," (OPT model)"),MUe.forEach(t),hsr=i(H),AF=n(H,"LI",{});var EUe=s(AF);QEe=n(EUe,"STRONG",{});var HKt=s(QEe);usr=r(HKt,"pegasus"),HKt.forEach(t),psr=r(EUe," \u2014 "),wJ=n(EUe,"A",{href:!0});var JKt=s(wJ);_sr=r(JKt,"PegasusForCausalLM"),JKt.forEach(t),bsr=r(EUe," (Pegasus model)"),EUe.forEach(t),vsr=i(H),LF=n(H,"LI",{});var CUe=s(LF);WEe=n(CUe,"STRONG",{});var YKt=s(WEe);Fsr=r(YKt,"plbart"),YKt.forEach(t),Tsr=r(CUe," \u2014 "),AJ=n(CUe,"A",{href:!0});var ZKt=s(AJ);Msr=r(ZKt,"PLBartForCausalLM"),ZKt.forEach(t),Esr=r(CUe," (PLBart model)"),CUe.forEach(t),Csr=i(H),yF=n(H,"LI",{});var wUe=s(yF);UEe=n(wUe,"STRONG",{});var KKt=s(UEe);wsr=r(KKt,"prophetnet"),KKt.forEach(t),Asr=r(wUe," \u2014 "),LJ=n(wUe,"A",{href:!0});var eea=s(LJ);Lsr=r(eea,"ProphetNetForCausalLM"),eea.forEach(t),ysr=r(wUe," (ProphetNet model)"),wUe.forEach(t),xsr=i(H),xF=n(H,"LI",{});var AUe=s(xF);HEe=n(AUe,"STRONG",{});var oea=s(HEe);$sr=r(oea,"qdqbert"),oea.forEach(t),ksr=r(AUe," \u2014 "),yJ=n(AUe,"A",{href:!0});var rea=s(yJ);Ssr=r(rea,"QDQBertLMHeadModel"),rea.forEach(t),Rsr=r(AUe," (QDQBert model)"),AUe.forEach(t),Psr=i(H),$F=n(H,"LI",{});var LUe=s($F);JEe=n(LUe,"STRONG",{});var tea=s(JEe);Bsr=r(tea,"reformer"),tea.forEach(t),Isr=r(LUe," \u2014 "),xJ=n(LUe,"A",{href:!0});var aea=s(xJ);Nsr=r(aea,"ReformerModelWithLMHead"),aea.forEach(t),qsr=r(LUe," (Reformer model)"),LUe.forEach(t),jsr=i(H),kF=n(H,"LI",{});var yUe=s(kF);YEe=n(yUe,"STRONG",{});var nea=s(YEe);Dsr=r(nea,"rembert"),nea.forEach(t),Gsr=r(yUe," \u2014 "),$J=n(yUe,"A",{href:!0});var sea=s($J);Osr=r(sea,"RemBertForCausalLM"),sea.forEach(t),Vsr=r(yUe," (RemBERT model)"),yUe.forEach(t),Xsr=i(H),SF=n(H,"LI",{});var xUe=s(SF);ZEe=n(xUe,"STRONG",{});var lea=s(ZEe);zsr=r(lea,"roberta"),lea.forEach(t),Qsr=r(xUe," \u2014 "),kJ=n(xUe,"A",{href:!0});var iea=s(kJ);Wsr=r(iea,"RobertaForCausalLM"),iea.forEach(t),Usr=r(xUe," (RoBERTa model)"),xUe.forEach(t),Hsr=i(H),RF=n(H,"LI",{});var $Ue=s(RF);KEe=n($Ue,"STRONG",{});var dea=s(KEe);Jsr=r(dea,"roc_bert"),dea.forEach(t),Ysr=r($Ue," \u2014 "),SJ=n($Ue,"A",{href:!0});var mea=s(SJ);Zsr=r(mea,"RoCBertForCausalLM"),mea.forEach(t),Ksr=r($Ue," (RoCBert model)"),$Ue.forEach(t),elr=i(H),PF=n(H,"LI",{});var kUe=s(PF);e4e=n(kUe,"STRONG",{});var cea=s(e4e);olr=r(cea,"roformer"),cea.forEach(t),rlr=r(kUe," \u2014 "),RJ=n(kUe,"A",{href:!0});var fea=s(RJ);tlr=r(fea,"RoFormerForCausalLM"),fea.forEach(t),alr=r(kUe," (RoFormer model)"),kUe.forEach(t),nlr=i(H),BF=n(H,"LI",{});var SUe=s(BF);o4e=n(SUe,"STRONG",{});var gea=s(o4e);slr=r(gea,"speech_to_text_2"),gea.forEach(t),llr=r(SUe," \u2014 "),PJ=n(SUe,"A",{href:!0});var hea=s(PJ);ilr=r(hea,"Speech2Text2ForCausalLM"),hea.forEach(t),dlr=r(SUe," (Speech2Text2 model)"),SUe.forEach(t),mlr=i(H),IF=n(H,"LI",{});var RUe=s(IF);r4e=n(RUe,"STRONG",{});var uea=s(r4e);clr=r(uea,"transfo-xl"),uea.forEach(t),flr=r(RUe," \u2014 "),BJ=n(RUe,"A",{href:!0});var pea=s(BJ);glr=r(pea,"TransfoXLLMHeadModel"),pea.forEach(t),hlr=r(RUe," (Transformer-XL model)"),RUe.forEach(t),ulr=i(H),NF=n(H,"LI",{});var PUe=s(NF);t4e=n(PUe,"STRONG",{});var _ea=s(t4e);plr=r(_ea,"trocr"),_ea.forEach(t),_lr=r(PUe," \u2014 "),IJ=n(PUe,"A",{href:!0});var bea=s(IJ);blr=r(bea,"TrOCRForCausalLM"),bea.forEach(t),vlr=r(PUe," (TrOCR model)"),PUe.forEach(t),Flr=i(H),qF=n(H,"LI",{});var BUe=s(qF);a4e=n(BUe,"STRONG",{});var vea=s(a4e);Tlr=r(vea,"xglm"),vea.forEach(t),Mlr=r(BUe," \u2014 "),NJ=n(BUe,"A",{href:!0});var Fea=s(NJ);Elr=r(Fea,"XGLMForCausalLM"),Fea.forEach(t),Clr=r(BUe," (XGLM model)"),BUe.forEach(t),wlr=i(H),jF=n(H,"LI",{});var IUe=s(jF);n4e=n(IUe,"STRONG",{});var Tea=s(n4e);Alr=r(Tea,"xlm"),Tea.forEach(t),Llr=r(IUe," \u2014 "),qJ=n(IUe,"A",{href:!0});var Mea=s(qJ);ylr=r(Mea,"XLMWithLMHeadModel"),Mea.forEach(t),xlr=r(IUe," (XLM model)"),IUe.forEach(t),$lr=i(H),DF=n(H,"LI",{});var NUe=s(DF);s4e=n(NUe,"STRONG",{});var Eea=s(s4e);klr=r(Eea,"xlm-prophetnet"),Eea.forEach(t),Slr=r(NUe," \u2014 "),jJ=n(NUe,"A",{href:!0});var Cea=s(jJ);Rlr=r(Cea,"XLMProphetNetForCausalLM"),Cea.forEach(t),Plr=r(NUe," (XLM-ProphetNet model)"),NUe.forEach(t),Blr=i(H),GF=n(H,"LI",{});var qUe=s(GF);l4e=n(qUe,"STRONG",{});var wea=s(l4e);Ilr=r(wea,"xlm-roberta"),wea.forEach(t),Nlr=r(qUe," \u2014 "),DJ=n(qUe,"A",{href:!0});var Aea=s(DJ);qlr=r(Aea,"XLMRobertaForCausalLM"),Aea.forEach(t),jlr=r(qUe," (XLM-RoBERTa model)"),qUe.forEach(t),Dlr=i(H),OF=n(H,"LI",{});var jUe=s(OF);i4e=n(jUe,"STRONG",{});var Lea=s(i4e);Glr=r(Lea,"xlm-roberta-xl"),Lea.forEach(t),Olr=r(jUe," \u2014 "),GJ=n(jUe,"A",{href:!0});var yea=s(GJ);Vlr=r(yea,"XLMRobertaXLForCausalLM"),yea.forEach(t),Xlr=r(jUe," (XLM-RoBERTa-XL model)"),jUe.forEach(t),zlr=i(H),VF=n(H,"LI",{});var DUe=s(VF);d4e=n(DUe,"STRONG",{});var xea=s(d4e);Qlr=r(xea,"xlnet"),xea.forEach(t),Wlr=r(DUe," \u2014 "),OJ=n(DUe,"A",{href:!0});var $ea=s(OJ);Ulr=r($ea,"XLNetLMHeadModel"),$ea.forEach(t),Hlr=r(DUe," (XLNet model)"),DUe.forEach(t),H.forEach(t),Jlr=i(Pa),XF=n(Pa,"P",{});var GUe=s(XF);Ylr=r(GUe,"The model is set in evaluation mode by default using "),m4e=n(GUe,"CODE",{});var kea=s(m4e);Zlr=r(kea,"model.eval()"),kea.forEach(t),Klr=r(GUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c4e=n(GUe,"CODE",{});var Sea=s(c4e);eir=r(Sea,"model.train()"),Sea.forEach(t),GUe.forEach(t),oir=i(Pa),T(zF.$$.fragment,Pa),Pa.forEach(t),Ul.forEach(t),Hlo=i(c),Jd=n(c,"H2",{class:!0});var _mo=s(Jd);QF=n(_mo,"A",{id:!0,class:!0,href:!0});var Rea=s(QF);f4e=n(Rea,"SPAN",{});var Pea=s(f4e);T(iS.$$.fragment,Pea),Pea.forEach(t),Rea.forEach(t),rir=i(_mo),g4e=n(_mo,"SPAN",{});var Bea=s(g4e);tir=r(Bea,"AutoModelForDepthEstimation"),Bea.forEach(t),_mo.forEach(t),Jlo=i(c),Vo=n(c,"DIV",{class:!0});var Hl=s(Vo);T(dS.$$.fragment,Hl),air=i(Hl),Yd=n(Hl,"P",{});var bfe=s(Yd);nir=r(bfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a depth estimation head) when created
with the `),VJ=n(bfe,"A",{href:!0});var Iea=s(VJ);sir=r(Iea,"from_pretrained()"),Iea.forEach(t),lir=r(bfe," class method or the "),XJ=n(bfe,"A",{href:!0});var Nea=s(XJ);iir=r(Nea,"from_config()"),Nea.forEach(t),dir=r(bfe,` class
method.`),bfe.forEach(t),mir=i(Hl),mS=n(Hl,"P",{});var bmo=s(mS);cir=r(bmo,"This class cannot be instantiated directly using "),h4e=n(bmo,"CODE",{});var qea=s(h4e);fir=r(qea,"__init__()"),qea.forEach(t),gir=r(bmo," (throws an error)."),bmo.forEach(t),hir=i(Hl),xt=n(Hl,"DIV",{class:!0});var fx=s(xt);T(cS.$$.fragment,fx),uir=i(fx),u4e=n(fx,"P",{});var jea=s(u4e);pir=r(jea,"Instantiates one of the model classes of the library (with a depth estimation head) from a configuration."),jea.forEach(t),_ir=i(fx),Zd=n(fx,"P",{});var vfe=s(Zd);bir=r(vfe,`Note:
Loading a model from its configuration file does `),p4e=n(vfe,"STRONG",{});var Dea=s(p4e);vir=r(Dea,"not"),Dea.forEach(t),Fir=r(vfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),zJ=n(vfe,"A",{href:!0});var Gea=s(zJ);Tir=r(Gea,"from_pretrained()"),Gea.forEach(t),Mir=r(vfe," to load the model weights."),vfe.forEach(t),Eir=i(fx),T(WF.$$.fragment,fx),fx.forEach(t),Cir=i(Hl),so=n(Hl,"DIV",{class:!0});var Ba=s(so);T(fS.$$.fragment,Ba),wir=i(Ba),_4e=n(Ba,"P",{});var Oea=s(_4e);Air=r(Oea,"Instantiate one of the model classes of the library (with a depth estimation head) from a pretrained model."),Oea.forEach(t),Lir=i(Ba),un=n(Ba,"P",{});var gx=s(un);yir=r(gx,"The model class to instantiate is selected based on the "),b4e=n(gx,"CODE",{});var Vea=s(b4e);xir=r(Vea,"model_type"),Vea.forEach(t),$ir=r(gx,` property of the config object (either
passed as an argument or loaded from `),v4e=n(gx,"CODE",{});var Xea=s(v4e);kir=r(Xea,"pretrained_model_name_or_path"),Xea.forEach(t),Sir=r(gx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F4e=n(gx,"CODE",{});var zea=s(F4e);Rir=r(zea,"pretrained_model_name_or_path"),zea.forEach(t),Pir=r(gx,":"),gx.forEach(t),Bir=i(Ba),gS=n(Ba,"UL",{});var vmo=s(gS);UF=n(vmo,"LI",{});var OUe=s(UF);T4e=n(OUe,"STRONG",{});var Qea=s(T4e);Iir=r(Qea,"dpt"),Qea.forEach(t),Nir=r(OUe," \u2014 "),QJ=n(OUe,"A",{href:!0});var Wea=s(QJ);qir=r(Wea,"DPTForDepthEstimation"),Wea.forEach(t),jir=r(OUe," (DPT model)"),OUe.forEach(t),Dir=i(vmo),HF=n(vmo,"LI",{});var VUe=s(HF);M4e=n(VUe,"STRONG",{});var Uea=s(M4e);Gir=r(Uea,"glpn"),Uea.forEach(t),Oir=r(VUe," \u2014 "),WJ=n(VUe,"A",{href:!0});var Hea=s(WJ);Vir=r(Hea,"GLPNForDepthEstimation"),Hea.forEach(t),Xir=r(VUe," (GLPN model)"),VUe.forEach(t),vmo.forEach(t),zir=i(Ba),JF=n(Ba,"P",{});var XUe=s(JF);Qir=r(XUe,"The model is set in evaluation mode by default using "),E4e=n(XUe,"CODE",{});var Jea=s(E4e);Wir=r(Jea,"model.eval()"),Jea.forEach(t),Uir=r(XUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),C4e=n(XUe,"CODE",{});var Yea=s(C4e);Hir=r(Yea,"model.train()"),Yea.forEach(t),XUe.forEach(t),Jir=i(Ba),T(YF.$$.fragment,Ba),Ba.forEach(t),Hl.forEach(t),Ylo=i(c),Kd=n(c,"H2",{class:!0});var Fmo=s(Kd);ZF=n(Fmo,"A",{id:!0,class:!0,href:!0});var Zea=s(ZF);w4e=n(Zea,"SPAN",{});var Kea=s(w4e);T(hS.$$.fragment,Kea),Kea.forEach(t),Zea.forEach(t),Yir=i(Fmo),A4e=n(Fmo,"SPAN",{});var eoa=s(A4e);Zir=r(eoa,"AutoModelForMaskedLM"),eoa.forEach(t),Fmo.forEach(t),Zlo=i(c),Xo=n(c,"DIV",{class:!0});var Jl=s(Xo);T(uS.$$.fragment,Jl),Kir=i(Jl),em=n(Jl,"P",{});var Ffe=s(em);edr=r(Ffe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),UJ=n(Ffe,"A",{href:!0});var ooa=s(UJ);odr=r(ooa,"from_pretrained()"),ooa.forEach(t),rdr=r(Ffe," class method or the "),HJ=n(Ffe,"A",{href:!0});var roa=s(HJ);tdr=r(roa,"from_config()"),roa.forEach(t),adr=r(Ffe,` class
method.`),Ffe.forEach(t),ndr=i(Jl),pS=n(Jl,"P",{});var Tmo=s(pS);sdr=r(Tmo,"This class cannot be instantiated directly using "),L4e=n(Tmo,"CODE",{});var toa=s(L4e);ldr=r(toa,"__init__()"),toa.forEach(t),idr=r(Tmo," (throws an error)."),Tmo.forEach(t),ddr=i(Jl),$t=n(Jl,"DIV",{class:!0});var hx=s($t);T(_S.$$.fragment,hx),mdr=i(hx),y4e=n(hx,"P",{});var aoa=s(y4e);cdr=r(aoa,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),aoa.forEach(t),fdr=i(hx),om=n(hx,"P",{});var Tfe=s(om);gdr=r(Tfe,`Note:
Loading a model from its configuration file does `),x4e=n(Tfe,"STRONG",{});var noa=s(x4e);hdr=r(noa,"not"),noa.forEach(t),udr=r(Tfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),JJ=n(Tfe,"A",{href:!0});var soa=s(JJ);pdr=r(soa,"from_pretrained()"),soa.forEach(t),_dr=r(Tfe," to load the model weights."),Tfe.forEach(t),bdr=i(hx),T(KF.$$.fragment,hx),hx.forEach(t),vdr=i(Jl),lo=n(Jl,"DIV",{class:!0});var Ia=s(lo);T(bS.$$.fragment,Ia),Fdr=i(Ia),$4e=n(Ia,"P",{});var loa=s($4e);Tdr=r(loa,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),loa.forEach(t),Mdr=i(Ia),pn=n(Ia,"P",{});var ux=s(pn);Edr=r(ux,"The model class to instantiate is selected based on the "),k4e=n(ux,"CODE",{});var ioa=s(k4e);Cdr=r(ioa,"model_type"),ioa.forEach(t),wdr=r(ux,` property of the config object (either
passed as an argument or loaded from `),S4e=n(ux,"CODE",{});var doa=s(S4e);Adr=r(doa,"pretrained_model_name_or_path"),doa.forEach(t),Ldr=r(ux,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R4e=n(ux,"CODE",{});var moa=s(R4e);ydr=r(moa,"pretrained_model_name_or_path"),moa.forEach(t),xdr=r(ux,":"),ux.forEach(t),$dr=i(Ia),Y=n(Ia,"UL",{});var Z=s(Y);eT=n(Z,"LI",{});var zUe=s(eT);P4e=n(zUe,"STRONG",{});var coa=s(P4e);kdr=r(coa,"albert"),coa.forEach(t),Sdr=r(zUe," \u2014 "),YJ=n(zUe,"A",{href:!0});var foa=s(YJ);Rdr=r(foa,"AlbertForMaskedLM"),foa.forEach(t),Pdr=r(zUe," (ALBERT model)"),zUe.forEach(t),Bdr=i(Z),oT=n(Z,"LI",{});var QUe=s(oT);B4e=n(QUe,"STRONG",{});var goa=s(B4e);Idr=r(goa,"bart"),goa.forEach(t),Ndr=r(QUe," \u2014 "),ZJ=n(QUe,"A",{href:!0});var hoa=s(ZJ);qdr=r(hoa,"BartForConditionalGeneration"),hoa.forEach(t),jdr=r(QUe," (BART model)"),QUe.forEach(t),Ddr=i(Z),rT=n(Z,"LI",{});var WUe=s(rT);I4e=n(WUe,"STRONG",{});var uoa=s(I4e);Gdr=r(uoa,"bert"),uoa.forEach(t),Odr=r(WUe," \u2014 "),KJ=n(WUe,"A",{href:!0});var poa=s(KJ);Vdr=r(poa,"BertForMaskedLM"),poa.forEach(t),Xdr=r(WUe," (BERT model)"),WUe.forEach(t),zdr=i(Z),tT=n(Z,"LI",{});var UUe=s(tT);N4e=n(UUe,"STRONG",{});var _oa=s(N4e);Qdr=r(_oa,"big_bird"),_oa.forEach(t),Wdr=r(UUe," \u2014 "),eY=n(UUe,"A",{href:!0});var boa=s(eY);Udr=r(boa,"BigBirdForMaskedLM"),boa.forEach(t),Hdr=r(UUe," (BigBird model)"),UUe.forEach(t),Jdr=i(Z),aT=n(Z,"LI",{});var HUe=s(aT);q4e=n(HUe,"STRONG",{});var voa=s(q4e);Ydr=r(voa,"camembert"),voa.forEach(t),Zdr=r(HUe," \u2014 "),oY=n(HUe,"A",{href:!0});var Foa=s(oY);Kdr=r(Foa,"CamembertForMaskedLM"),Foa.forEach(t),emr=r(HUe," (CamemBERT model)"),HUe.forEach(t),omr=i(Z),nT=n(Z,"LI",{});var JUe=s(nT);j4e=n(JUe,"STRONG",{});var Toa=s(j4e);rmr=r(Toa,"convbert"),Toa.forEach(t),tmr=r(JUe," \u2014 "),rY=n(JUe,"A",{href:!0});var Moa=s(rY);amr=r(Moa,"ConvBertForMaskedLM"),Moa.forEach(t),nmr=r(JUe," (ConvBERT model)"),JUe.forEach(t),smr=i(Z),sT=n(Z,"LI",{});var YUe=s(sT);D4e=n(YUe,"STRONG",{});var Eoa=s(D4e);lmr=r(Eoa,"data2vec-text"),Eoa.forEach(t),imr=r(YUe," \u2014 "),tY=n(YUe,"A",{href:!0});var Coa=s(tY);dmr=r(Coa,"Data2VecTextForMaskedLM"),Coa.forEach(t),mmr=r(YUe," (Data2VecText model)"),YUe.forEach(t),cmr=i(Z),lT=n(Z,"LI",{});var ZUe=s(lT);G4e=n(ZUe,"STRONG",{});var woa=s(G4e);fmr=r(woa,"deberta"),woa.forEach(t),gmr=r(ZUe," \u2014 "),aY=n(ZUe,"A",{href:!0});var Aoa=s(aY);hmr=r(Aoa,"DebertaForMaskedLM"),Aoa.forEach(t),umr=r(ZUe," (DeBERTa model)"),ZUe.forEach(t),pmr=i(Z),iT=n(Z,"LI",{});var KUe=s(iT);O4e=n(KUe,"STRONG",{});var Loa=s(O4e);_mr=r(Loa,"deberta-v2"),Loa.forEach(t),bmr=r(KUe," \u2014 "),nY=n(KUe,"A",{href:!0});var yoa=s(nY);vmr=r(yoa,"DebertaV2ForMaskedLM"),yoa.forEach(t),Fmr=r(KUe," (DeBERTa-v2 model)"),KUe.forEach(t),Tmr=i(Z),dT=n(Z,"LI",{});var eHe=s(dT);V4e=n(eHe,"STRONG",{});var xoa=s(V4e);Mmr=r(xoa,"distilbert"),xoa.forEach(t),Emr=r(eHe," \u2014 "),sY=n(eHe,"A",{href:!0});var $oa=s(sY);Cmr=r($oa,"DistilBertForMaskedLM"),$oa.forEach(t),wmr=r(eHe," (DistilBERT model)"),eHe.forEach(t),Amr=i(Z),mT=n(Z,"LI",{});var oHe=s(mT);X4e=n(oHe,"STRONG",{});var koa=s(X4e);Lmr=r(koa,"electra"),koa.forEach(t),ymr=r(oHe," \u2014 "),lY=n(oHe,"A",{href:!0});var Soa=s(lY);xmr=r(Soa,"ElectraForMaskedLM"),Soa.forEach(t),$mr=r(oHe," (ELECTRA model)"),oHe.forEach(t),kmr=i(Z),cT=n(Z,"LI",{});var rHe=s(cT);z4e=n(rHe,"STRONG",{});var Roa=s(z4e);Smr=r(Roa,"ernie"),Roa.forEach(t),Rmr=r(rHe," \u2014 "),iY=n(rHe,"A",{href:!0});var Poa=s(iY);Pmr=r(Poa,"ErnieForMaskedLM"),Poa.forEach(t),Bmr=r(rHe," (ERNIE model)"),rHe.forEach(t),Imr=i(Z),fT=n(Z,"LI",{});var tHe=s(fT);Q4e=n(tHe,"STRONG",{});var Boa=s(Q4e);Nmr=r(Boa,"flaubert"),Boa.forEach(t),qmr=r(tHe," \u2014 "),dY=n(tHe,"A",{href:!0});var Ioa=s(dY);jmr=r(Ioa,"FlaubertWithLMHeadModel"),Ioa.forEach(t),Dmr=r(tHe," (FlauBERT model)"),tHe.forEach(t),Gmr=i(Z),gT=n(Z,"LI",{});var aHe=s(gT);W4e=n(aHe,"STRONG",{});var Noa=s(W4e);Omr=r(Noa,"fnet"),Noa.forEach(t),Vmr=r(aHe," \u2014 "),mY=n(aHe,"A",{href:!0});var qoa=s(mY);Xmr=r(qoa,"FNetForMaskedLM"),qoa.forEach(t),zmr=r(aHe," (FNet model)"),aHe.forEach(t),Qmr=i(Z),hT=n(Z,"LI",{});var nHe=s(hT);U4e=n(nHe,"STRONG",{});var joa=s(U4e);Wmr=r(joa,"funnel"),joa.forEach(t),Umr=r(nHe," \u2014 "),cY=n(nHe,"A",{href:!0});var Doa=s(cY);Hmr=r(Doa,"FunnelForMaskedLM"),Doa.forEach(t),Jmr=r(nHe," (Funnel Transformer model)"),nHe.forEach(t),Ymr=i(Z),uT=n(Z,"LI",{});var sHe=s(uT);H4e=n(sHe,"STRONG",{});var Goa=s(H4e);Zmr=r(Goa,"ibert"),Goa.forEach(t),Kmr=r(sHe," \u2014 "),fY=n(sHe,"A",{href:!0});var Ooa=s(fY);ecr=r(Ooa,"IBertForMaskedLM"),Ooa.forEach(t),ocr=r(sHe," (I-BERT model)"),sHe.forEach(t),rcr=i(Z),pT=n(Z,"LI",{});var lHe=s(pT);J4e=n(lHe,"STRONG",{});var Voa=s(J4e);tcr=r(Voa,"layoutlm"),Voa.forEach(t),acr=r(lHe," \u2014 "),gY=n(lHe,"A",{href:!0});var Xoa=s(gY);ncr=r(Xoa,"LayoutLMForMaskedLM"),Xoa.forEach(t),scr=r(lHe," (LayoutLM model)"),lHe.forEach(t),lcr=i(Z),_T=n(Z,"LI",{});var iHe=s(_T);Y4e=n(iHe,"STRONG",{});var zoa=s(Y4e);icr=r(zoa,"longformer"),zoa.forEach(t),dcr=r(iHe," \u2014 "),hY=n(iHe,"A",{href:!0});var Qoa=s(hY);mcr=r(Qoa,"LongformerForMaskedLM"),Qoa.forEach(t),ccr=r(iHe," (Longformer model)"),iHe.forEach(t),fcr=i(Z),bT=n(Z,"LI",{});var dHe=s(bT);Z4e=n(dHe,"STRONG",{});var Woa=s(Z4e);gcr=r(Woa,"luke"),Woa.forEach(t),hcr=r(dHe," \u2014 "),uY=n(dHe,"A",{href:!0});var Uoa=s(uY);ucr=r(Uoa,"LukeForMaskedLM"),Uoa.forEach(t),pcr=r(dHe," (LUKE model)"),dHe.forEach(t),_cr=i(Z),vT=n(Z,"LI",{});var mHe=s(vT);K4e=n(mHe,"STRONG",{});var Hoa=s(K4e);bcr=r(Hoa,"mbart"),Hoa.forEach(t),vcr=r(mHe," \u2014 "),pY=n(mHe,"A",{href:!0});var Joa=s(pY);Fcr=r(Joa,"MBartForConditionalGeneration"),Joa.forEach(t),Tcr=r(mHe," (mBART model)"),mHe.forEach(t),Mcr=i(Z),FT=n(Z,"LI",{});var cHe=s(FT);eCe=n(cHe,"STRONG",{});var Yoa=s(eCe);Ecr=r(Yoa,"megatron-bert"),Yoa.forEach(t),Ccr=r(cHe," \u2014 "),_Y=n(cHe,"A",{href:!0});var Zoa=s(_Y);wcr=r(Zoa,"MegatronBertForMaskedLM"),Zoa.forEach(t),Acr=r(cHe," (Megatron-BERT model)"),cHe.forEach(t),Lcr=i(Z),TT=n(Z,"LI",{});var fHe=s(TT);oCe=n(fHe,"STRONG",{});var Koa=s(oCe);ycr=r(Koa,"mobilebert"),Koa.forEach(t),xcr=r(fHe," \u2014 "),bY=n(fHe,"A",{href:!0});var era=s(bY);$cr=r(era,"MobileBertForMaskedLM"),era.forEach(t),kcr=r(fHe," (MobileBERT model)"),fHe.forEach(t),Scr=i(Z),MT=n(Z,"LI",{});var gHe=s(MT);rCe=n(gHe,"STRONG",{});var ora=s(rCe);Rcr=r(ora,"mpnet"),ora.forEach(t),Pcr=r(gHe," \u2014 "),vY=n(gHe,"A",{href:!0});var rra=s(vY);Bcr=r(rra,"MPNetForMaskedLM"),rra.forEach(t),Icr=r(gHe," (MPNet model)"),gHe.forEach(t),Ncr=i(Z),ET=n(Z,"LI",{});var hHe=s(ET);tCe=n(hHe,"STRONG",{});var tra=s(tCe);qcr=r(tra,"mvp"),tra.forEach(t),jcr=r(hHe," \u2014 "),FY=n(hHe,"A",{href:!0});var ara=s(FY);Dcr=r(ara,"MvpForConditionalGeneration"),ara.forEach(t),Gcr=r(hHe," (MVP model)"),hHe.forEach(t),Ocr=i(Z),CT=n(Z,"LI",{});var uHe=s(CT);aCe=n(uHe,"STRONG",{});var nra=s(aCe);Vcr=r(nra,"nezha"),nra.forEach(t),Xcr=r(uHe," \u2014 "),TY=n(uHe,"A",{href:!0});var sra=s(TY);zcr=r(sra,"NezhaForMaskedLM"),sra.forEach(t),Qcr=r(uHe," (Nezha model)"),uHe.forEach(t),Wcr=i(Z),wT=n(Z,"LI",{});var pHe=s(wT);nCe=n(pHe,"STRONG",{});var lra=s(nCe);Ucr=r(lra,"nystromformer"),lra.forEach(t),Hcr=r(pHe," \u2014 "),MY=n(pHe,"A",{href:!0});var ira=s(MY);Jcr=r(ira,"NystromformerForMaskedLM"),ira.forEach(t),Ycr=r(pHe," (Nystr\xF6mformer model)"),pHe.forEach(t),Zcr=i(Z),AT=n(Z,"LI",{});var _He=s(AT);sCe=n(_He,"STRONG",{});var dra=s(sCe);Kcr=r(dra,"perceiver"),dra.forEach(t),efr=r(_He," \u2014 "),EY=n(_He,"A",{href:!0});var mra=s(EY);ofr=r(mra,"PerceiverForMaskedLM"),mra.forEach(t),rfr=r(_He," (Perceiver model)"),_He.forEach(t),tfr=i(Z),LT=n(Z,"LI",{});var bHe=s(LT);lCe=n(bHe,"STRONG",{});var cra=s(lCe);afr=r(cra,"qdqbert"),cra.forEach(t),nfr=r(bHe," \u2014 "),CY=n(bHe,"A",{href:!0});var fra=s(CY);sfr=r(fra,"QDQBertForMaskedLM"),fra.forEach(t),lfr=r(bHe," (QDQBert model)"),bHe.forEach(t),ifr=i(Z),yT=n(Z,"LI",{});var vHe=s(yT);iCe=n(vHe,"STRONG",{});var gra=s(iCe);dfr=r(gra,"reformer"),gra.forEach(t),mfr=r(vHe," \u2014 "),wY=n(vHe,"A",{href:!0});var hra=s(wY);cfr=r(hra,"ReformerForMaskedLM"),hra.forEach(t),ffr=r(vHe," (Reformer model)"),vHe.forEach(t),gfr=i(Z),xT=n(Z,"LI",{});var FHe=s(xT);dCe=n(FHe,"STRONG",{});var ura=s(dCe);hfr=r(ura,"rembert"),ura.forEach(t),ufr=r(FHe," \u2014 "),AY=n(FHe,"A",{href:!0});var pra=s(AY);pfr=r(pra,"RemBertForMaskedLM"),pra.forEach(t),_fr=r(FHe," (RemBERT model)"),FHe.forEach(t),bfr=i(Z),$T=n(Z,"LI",{});var THe=s($T);mCe=n(THe,"STRONG",{});var _ra=s(mCe);vfr=r(_ra,"roberta"),_ra.forEach(t),Ffr=r(THe," \u2014 "),LY=n(THe,"A",{href:!0});var bra=s(LY);Tfr=r(bra,"RobertaForMaskedLM"),bra.forEach(t),Mfr=r(THe," (RoBERTa model)"),THe.forEach(t),Efr=i(Z),kT=n(Z,"LI",{});var MHe=s(kT);cCe=n(MHe,"STRONG",{});var vra=s(cCe);Cfr=r(vra,"roc_bert"),vra.forEach(t),wfr=r(MHe," \u2014 "),yY=n(MHe,"A",{href:!0});var Fra=s(yY);Afr=r(Fra,"RoCBertForMaskedLM"),Fra.forEach(t),Lfr=r(MHe," (RoCBert model)"),MHe.forEach(t),yfr=i(Z),ST=n(Z,"LI",{});var EHe=s(ST);fCe=n(EHe,"STRONG",{});var Tra=s(fCe);xfr=r(Tra,"roformer"),Tra.forEach(t),$fr=r(EHe," \u2014 "),xY=n(EHe,"A",{href:!0});var Mra=s(xY);kfr=r(Mra,"RoFormerForMaskedLM"),Mra.forEach(t),Sfr=r(EHe," (RoFormer model)"),EHe.forEach(t),Rfr=i(Z),RT=n(Z,"LI",{});var CHe=s(RT);gCe=n(CHe,"STRONG",{});var Era=s(gCe);Pfr=r(Era,"squeezebert"),Era.forEach(t),Bfr=r(CHe," \u2014 "),$Y=n(CHe,"A",{href:!0});var Cra=s($Y);Ifr=r(Cra,"SqueezeBertForMaskedLM"),Cra.forEach(t),Nfr=r(CHe," (SqueezeBERT model)"),CHe.forEach(t),qfr=i(Z),PT=n(Z,"LI",{});var wHe=s(PT);hCe=n(wHe,"STRONG",{});var wra=s(hCe);jfr=r(wra,"tapas"),wra.forEach(t),Dfr=r(wHe," \u2014 "),kY=n(wHe,"A",{href:!0});var Ara=s(kY);Gfr=r(Ara,"TapasForMaskedLM"),Ara.forEach(t),Ofr=r(wHe," (TAPAS model)"),wHe.forEach(t),Vfr=i(Z),BT=n(Z,"LI",{});var AHe=s(BT);uCe=n(AHe,"STRONG",{});var Lra=s(uCe);Xfr=r(Lra,"wav2vec2"),Lra.forEach(t),zfr=r(AHe," \u2014 "),pCe=n(AHe,"CODE",{});var yra=s(pCe);Qfr=r(yra,"Wav2Vec2ForMaskedLM"),yra.forEach(t),Wfr=r(AHe," (Wav2Vec2 model)"),AHe.forEach(t),Ufr=i(Z),IT=n(Z,"LI",{});var LHe=s(IT);_Ce=n(LHe,"STRONG",{});var xra=s(_Ce);Hfr=r(xra,"xlm"),xra.forEach(t),Jfr=r(LHe," \u2014 "),SY=n(LHe,"A",{href:!0});var $ra=s(SY);Yfr=r($ra,"XLMWithLMHeadModel"),$ra.forEach(t),Zfr=r(LHe," (XLM model)"),LHe.forEach(t),Kfr=i(Z),NT=n(Z,"LI",{});var yHe=s(NT);bCe=n(yHe,"STRONG",{});var kra=s(bCe);egr=r(kra,"xlm-roberta"),kra.forEach(t),ogr=r(yHe," \u2014 "),RY=n(yHe,"A",{href:!0});var Sra=s(RY);rgr=r(Sra,"XLMRobertaForMaskedLM"),Sra.forEach(t),tgr=r(yHe," (XLM-RoBERTa model)"),yHe.forEach(t),agr=i(Z),qT=n(Z,"LI",{});var xHe=s(qT);vCe=n(xHe,"STRONG",{});var Rra=s(vCe);ngr=r(Rra,"xlm-roberta-xl"),Rra.forEach(t),sgr=r(xHe," \u2014 "),PY=n(xHe,"A",{href:!0});var Pra=s(PY);lgr=r(Pra,"XLMRobertaXLForMaskedLM"),Pra.forEach(t),igr=r(xHe," (XLM-RoBERTa-XL model)"),xHe.forEach(t),dgr=i(Z),jT=n(Z,"LI",{});var $He=s(jT);FCe=n($He,"STRONG",{});var Bra=s(FCe);mgr=r(Bra,"yoso"),Bra.forEach(t),cgr=r($He," \u2014 "),BY=n($He,"A",{href:!0});var Ira=s(BY);fgr=r(Ira,"YosoForMaskedLM"),Ira.forEach(t),ggr=r($He," (YOSO model)"),$He.forEach(t),Z.forEach(t),hgr=i(Ia),DT=n(Ia,"P",{});var kHe=s(DT);ugr=r(kHe,"The model is set in evaluation mode by default using "),TCe=n(kHe,"CODE",{});var Nra=s(TCe);pgr=r(Nra,"model.eval()"),Nra.forEach(t),_gr=r(kHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),MCe=n(kHe,"CODE",{});var qra=s(MCe);bgr=r(qra,"model.train()"),qra.forEach(t),kHe.forEach(t),vgr=i(Ia),T(GT.$$.fragment,Ia),Ia.forEach(t),Jl.forEach(t),Klo=i(c),rm=n(c,"H2",{class:!0});var Mmo=s(rm);OT=n(Mmo,"A",{id:!0,class:!0,href:!0});var jra=s(OT);ECe=n(jra,"SPAN",{});var Dra=s(ECe);T(vS.$$.fragment,Dra),Dra.forEach(t),jra.forEach(t),Fgr=i(Mmo),CCe=n(Mmo,"SPAN",{});var Gra=s(CCe);Tgr=r(Gra,"AutoModelForSeq2SeqLM"),Gra.forEach(t),Mmo.forEach(t),eio=i(c),zo=n(c,"DIV",{class:!0});var Yl=s(zo);T(FS.$$.fragment,Yl),Mgr=i(Yl),tm=n(Yl,"P",{});var Mfe=s(tm);Egr=r(Mfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),IY=n(Mfe,"A",{href:!0});var Ora=s(IY);Cgr=r(Ora,"from_pretrained()"),Ora.forEach(t),wgr=r(Mfe," class method or the "),NY=n(Mfe,"A",{href:!0});var Vra=s(NY);Agr=r(Vra,"from_config()"),Vra.forEach(t),Lgr=r(Mfe,` class
method.`),Mfe.forEach(t),ygr=i(Yl),TS=n(Yl,"P",{});var Emo=s(TS);xgr=r(Emo,"This class cannot be instantiated directly using "),wCe=n(Emo,"CODE",{});var Xra=s(wCe);$gr=r(Xra,"__init__()"),Xra.forEach(t),kgr=r(Emo," (throws an error)."),Emo.forEach(t),Sgr=i(Yl),kt=n(Yl,"DIV",{class:!0});var px=s(kt);T(MS.$$.fragment,px),Rgr=i(px),ACe=n(px,"P",{});var zra=s(ACe);Pgr=r(zra,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),zra.forEach(t),Bgr=i(px),am=n(px,"P",{});var Efe=s(am);Igr=r(Efe,`Note:
Loading a model from its configuration file does `),LCe=n(Efe,"STRONG",{});var Qra=s(LCe);Ngr=r(Qra,"not"),Qra.forEach(t),qgr=r(Efe,` load the model weights. It only affects the
model\u2019s configuration. Use `),qY=n(Efe,"A",{href:!0});var Wra=s(qY);jgr=r(Wra,"from_pretrained()"),Wra.forEach(t),Dgr=r(Efe," to load the model weights."),Efe.forEach(t),Ggr=i(px),T(VT.$$.fragment,px),px.forEach(t),Ogr=i(Yl),io=n(Yl,"DIV",{class:!0});var Na=s(io);T(ES.$$.fragment,Na),Vgr=i(Na),yCe=n(Na,"P",{});var Ura=s(yCe);Xgr=r(Ura,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Ura.forEach(t),zgr=i(Na),_n=n(Na,"P",{});var _x=s(_n);Qgr=r(_x,"The model class to instantiate is selected based on the "),xCe=n(_x,"CODE",{});var Hra=s(xCe);Wgr=r(Hra,"model_type"),Hra.forEach(t),Ugr=r(_x,` property of the config object (either
passed as an argument or loaded from `),$Ce=n(_x,"CODE",{});var Jra=s($Ce);Hgr=r(Jra,"pretrained_model_name_or_path"),Jra.forEach(t),Jgr=r(_x,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kCe=n(_x,"CODE",{});var Yra=s(kCe);Ygr=r(Yra,"pretrained_model_name_or_path"),Yra.forEach(t),Zgr=r(_x,":"),_x.forEach(t),Kgr=i(Na),pe=n(Na,"UL",{});var ve=s(pe);XT=n(ve,"LI",{});var SHe=s(XT);SCe=n(SHe,"STRONG",{});var Zra=s(SCe);ehr=r(Zra,"bart"),Zra.forEach(t),ohr=r(SHe," \u2014 "),jY=n(SHe,"A",{href:!0});var Kra=s(jY);rhr=r(Kra,"BartForConditionalGeneration"),Kra.forEach(t),thr=r(SHe," (BART model)"),SHe.forEach(t),ahr=i(ve),zT=n(ve,"LI",{});var RHe=s(zT);RCe=n(RHe,"STRONG",{});var eta=s(RCe);nhr=r(eta,"bigbird_pegasus"),eta.forEach(t),shr=r(RHe," \u2014 "),DY=n(RHe,"A",{href:!0});var ota=s(DY);lhr=r(ota,"BigBirdPegasusForConditionalGeneration"),ota.forEach(t),ihr=r(RHe," (BigBird-Pegasus model)"),RHe.forEach(t),dhr=i(ve),QT=n(ve,"LI",{});var PHe=s(QT);PCe=n(PHe,"STRONG",{});var rta=s(PCe);mhr=r(rta,"blenderbot"),rta.forEach(t),chr=r(PHe," \u2014 "),GY=n(PHe,"A",{href:!0});var tta=s(GY);fhr=r(tta,"BlenderbotForConditionalGeneration"),tta.forEach(t),ghr=r(PHe," (Blenderbot model)"),PHe.forEach(t),hhr=i(ve),WT=n(ve,"LI",{});var BHe=s(WT);BCe=n(BHe,"STRONG",{});var ata=s(BCe);uhr=r(ata,"blenderbot-small"),ata.forEach(t),phr=r(BHe," \u2014 "),OY=n(BHe,"A",{href:!0});var nta=s(OY);_hr=r(nta,"BlenderbotSmallForConditionalGeneration"),nta.forEach(t),bhr=r(BHe," (BlenderbotSmall model)"),BHe.forEach(t),vhr=i(ve),UT=n(ve,"LI",{});var IHe=s(UT);ICe=n(IHe,"STRONG",{});var sta=s(ICe);Fhr=r(sta,"encoder-decoder"),sta.forEach(t),Thr=r(IHe," \u2014 "),VY=n(IHe,"A",{href:!0});var lta=s(VY);Mhr=r(lta,"EncoderDecoderModel"),lta.forEach(t),Ehr=r(IHe," (Encoder decoder model)"),IHe.forEach(t),Chr=i(ve),HT=n(ve,"LI",{});var NHe=s(HT);NCe=n(NHe,"STRONG",{});var ita=s(NCe);whr=r(ita,"fsmt"),ita.forEach(t),Ahr=r(NHe," \u2014 "),XY=n(NHe,"A",{href:!0});var dta=s(XY);Lhr=r(dta,"FSMTForConditionalGeneration"),dta.forEach(t),yhr=r(NHe," (FairSeq Machine-Translation model)"),NHe.forEach(t),xhr=i(ve),JT=n(ve,"LI",{});var qHe=s(JT);qCe=n(qHe,"STRONG",{});var mta=s(qCe);$hr=r(mta,"led"),mta.forEach(t),khr=r(qHe," \u2014 "),zY=n(qHe,"A",{href:!0});var cta=s(zY);Shr=r(cta,"LEDForConditionalGeneration"),cta.forEach(t),Rhr=r(qHe," (LED model)"),qHe.forEach(t),Phr=i(ve),YT=n(ve,"LI",{});var jHe=s(YT);jCe=n(jHe,"STRONG",{});var fta=s(jCe);Bhr=r(fta,"longt5"),fta.forEach(t),Ihr=r(jHe," \u2014 "),QY=n(jHe,"A",{href:!0});var gta=s(QY);Nhr=r(gta,"LongT5ForConditionalGeneration"),gta.forEach(t),qhr=r(jHe," (LongT5 model)"),jHe.forEach(t),jhr=i(ve),ZT=n(ve,"LI",{});var DHe=s(ZT);DCe=n(DHe,"STRONG",{});var hta=s(DCe);Dhr=r(hta,"m2m_100"),hta.forEach(t),Ghr=r(DHe," \u2014 "),WY=n(DHe,"A",{href:!0});var uta=s(WY);Ohr=r(uta,"M2M100ForConditionalGeneration"),uta.forEach(t),Vhr=r(DHe," (M2M100 model)"),DHe.forEach(t),Xhr=i(ve),KT=n(ve,"LI",{});var GHe=s(KT);GCe=n(GHe,"STRONG",{});var pta=s(GCe);zhr=r(pta,"marian"),pta.forEach(t),Qhr=r(GHe," \u2014 "),UY=n(GHe,"A",{href:!0});var _ta=s(UY);Whr=r(_ta,"MarianMTModel"),_ta.forEach(t),Uhr=r(GHe," (Marian model)"),GHe.forEach(t),Hhr=i(ve),eM=n(ve,"LI",{});var OHe=s(eM);OCe=n(OHe,"STRONG",{});var bta=s(OCe);Jhr=r(bta,"mbart"),bta.forEach(t),Yhr=r(OHe," \u2014 "),HY=n(OHe,"A",{href:!0});var vta=s(HY);Zhr=r(vta,"MBartForConditionalGeneration"),vta.forEach(t),Khr=r(OHe," (mBART model)"),OHe.forEach(t),eur=i(ve),oM=n(ve,"LI",{});var VHe=s(oM);VCe=n(VHe,"STRONG",{});var Fta=s(VCe);our=r(Fta,"mt5"),Fta.forEach(t),rur=r(VHe," \u2014 "),JY=n(VHe,"A",{href:!0});var Tta=s(JY);tur=r(Tta,"MT5ForConditionalGeneration"),Tta.forEach(t),aur=r(VHe," (MT5 model)"),VHe.forEach(t),nur=i(ve),rM=n(ve,"LI",{});var XHe=s(rM);XCe=n(XHe,"STRONG",{});var Mta=s(XCe);sur=r(Mta,"mvp"),Mta.forEach(t),lur=r(XHe," \u2014 "),YY=n(XHe,"A",{href:!0});var Eta=s(YY);iur=r(Eta,"MvpForConditionalGeneration"),Eta.forEach(t),dur=r(XHe," (MVP model)"),XHe.forEach(t),mur=i(ve),tM=n(ve,"LI",{});var zHe=s(tM);zCe=n(zHe,"STRONG",{});var Cta=s(zCe);cur=r(Cta,"nllb"),Cta.forEach(t),fur=r(zHe," \u2014 "),ZY=n(zHe,"A",{href:!0});var wta=s(ZY);gur=r(wta,"M2M100ForConditionalGeneration"),wta.forEach(t),hur=r(zHe," (NLLB model)"),zHe.forEach(t),uur=i(ve),aM=n(ve,"LI",{});var QHe=s(aM);QCe=n(QHe,"STRONG",{});var Ata=s(QCe);pur=r(Ata,"pegasus"),Ata.forEach(t),_ur=r(QHe," \u2014 "),KY=n(QHe,"A",{href:!0});var Lta=s(KY);bur=r(Lta,"PegasusForConditionalGeneration"),Lta.forEach(t),vur=r(QHe," (Pegasus model)"),QHe.forEach(t),Fur=i(ve),nM=n(ve,"LI",{});var WHe=s(nM);WCe=n(WHe,"STRONG",{});var yta=s(WCe);Tur=r(yta,"pegasus_x"),yta.forEach(t),Mur=r(WHe," \u2014 "),eZ=n(WHe,"A",{href:!0});var xta=s(eZ);Eur=r(xta,"PegasusXForConditionalGeneration"),xta.forEach(t),Cur=r(WHe," (PEGASUS-X model)"),WHe.forEach(t),wur=i(ve),sM=n(ve,"LI",{});var UHe=s(sM);UCe=n(UHe,"STRONG",{});var $ta=s(UCe);Aur=r($ta,"plbart"),$ta.forEach(t),Lur=r(UHe," \u2014 "),oZ=n(UHe,"A",{href:!0});var kta=s(oZ);yur=r(kta,"PLBartForConditionalGeneration"),kta.forEach(t),xur=r(UHe," (PLBart model)"),UHe.forEach(t),$ur=i(ve),lM=n(ve,"LI",{});var HHe=s(lM);HCe=n(HHe,"STRONG",{});var Sta=s(HCe);kur=r(Sta,"prophetnet"),Sta.forEach(t),Sur=r(HHe," \u2014 "),rZ=n(HHe,"A",{href:!0});var Rta=s(rZ);Rur=r(Rta,"ProphetNetForConditionalGeneration"),Rta.forEach(t),Pur=r(HHe," (ProphetNet model)"),HHe.forEach(t),Bur=i(ve),iM=n(ve,"LI",{});var JHe=s(iM);JCe=n(JHe,"STRONG",{});var Pta=s(JCe);Iur=r(Pta,"t5"),Pta.forEach(t),Nur=r(JHe," \u2014 "),tZ=n(JHe,"A",{href:!0});var Bta=s(tZ);qur=r(Bta,"T5ForConditionalGeneration"),Bta.forEach(t),jur=r(JHe," (T5 model)"),JHe.forEach(t),Dur=i(ve),dM=n(ve,"LI",{});var YHe=s(dM);YCe=n(YHe,"STRONG",{});var Ita=s(YCe);Gur=r(Ita,"xlm-prophetnet"),Ita.forEach(t),Our=r(YHe," \u2014 "),aZ=n(YHe,"A",{href:!0});var Nta=s(aZ);Vur=r(Nta,"XLMProphetNetForConditionalGeneration"),Nta.forEach(t),Xur=r(YHe," (XLM-ProphetNet model)"),YHe.forEach(t),ve.forEach(t),zur=i(Na),mM=n(Na,"P",{});var ZHe=s(mM);Qur=r(ZHe,"The model is set in evaluation mode by default using "),ZCe=n(ZHe,"CODE",{});var qta=s(ZCe);Wur=r(qta,"model.eval()"),qta.forEach(t),Uur=r(ZHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),KCe=n(ZHe,"CODE",{});var jta=s(KCe);Hur=r(jta,"model.train()"),jta.forEach(t),ZHe.forEach(t),Jur=i(Na),T(cM.$$.fragment,Na),Na.forEach(t),Yl.forEach(t),oio=i(c),nm=n(c,"H2",{class:!0});var Cmo=s(nm);fM=n(Cmo,"A",{id:!0,class:!0,href:!0});var Dta=s(fM);e3e=n(Dta,"SPAN",{});var Gta=s(e3e);T(CS.$$.fragment,Gta),Gta.forEach(t),Dta.forEach(t),Yur=i(Cmo),o3e=n(Cmo,"SPAN",{});var Ota=s(o3e);Zur=r(Ota,"AutoModelForSequenceClassification"),Ota.forEach(t),Cmo.forEach(t),rio=i(c),Qo=n(c,"DIV",{class:!0});var Zl=s(Qo);T(wS.$$.fragment,Zl),Kur=i(Zl),sm=n(Zl,"P",{});var Cfe=s(sm);epr=r(Cfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),nZ=n(Cfe,"A",{href:!0});var Vta=s(nZ);opr=r(Vta,"from_pretrained()"),Vta.forEach(t),rpr=r(Cfe," class method or the "),sZ=n(Cfe,"A",{href:!0});var Xta=s(sZ);tpr=r(Xta,"from_config()"),Xta.forEach(t),apr=r(Cfe,` class
method.`),Cfe.forEach(t),npr=i(Zl),AS=n(Zl,"P",{});var wmo=s(AS);spr=r(wmo,"This class cannot be instantiated directly using "),r3e=n(wmo,"CODE",{});var zta=s(r3e);lpr=r(zta,"__init__()"),zta.forEach(t),ipr=r(wmo," (throws an error)."),wmo.forEach(t),dpr=i(Zl),St=n(Zl,"DIV",{class:!0});var bx=s(St);T(LS.$$.fragment,bx),mpr=i(bx),t3e=n(bx,"P",{});var Qta=s(t3e);cpr=r(Qta,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Qta.forEach(t),fpr=i(bx),lm=n(bx,"P",{});var wfe=s(lm);gpr=r(wfe,`Note:
Loading a model from its configuration file does `),a3e=n(wfe,"STRONG",{});var Wta=s(a3e);hpr=r(Wta,"not"),Wta.forEach(t),upr=r(wfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),lZ=n(wfe,"A",{href:!0});var Uta=s(lZ);ppr=r(Uta,"from_pretrained()"),Uta.forEach(t),_pr=r(wfe," to load the model weights."),wfe.forEach(t),bpr=i(bx),T(gM.$$.fragment,bx),bx.forEach(t),vpr=i(Zl),mo=n(Zl,"DIV",{class:!0});var qa=s(mo);T(yS.$$.fragment,qa),Fpr=i(qa),n3e=n(qa,"P",{});var Hta=s(n3e);Tpr=r(Hta,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Hta.forEach(t),Mpr=i(qa),bn=n(qa,"P",{});var vx=s(bn);Epr=r(vx,"The model class to instantiate is selected based on the "),s3e=n(vx,"CODE",{});var Jta=s(s3e);Cpr=r(Jta,"model_type"),Jta.forEach(t),wpr=r(vx,` property of the config object (either
passed as an argument or loaded from `),l3e=n(vx,"CODE",{});var Yta=s(l3e);Apr=r(Yta,"pretrained_model_name_or_path"),Yta.forEach(t),Lpr=r(vx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i3e=n(vx,"CODE",{});var Zta=s(i3e);ypr=r(Zta,"pretrained_model_name_or_path"),Zta.forEach(t),xpr=r(vx,":"),vx.forEach(t),$pr=i(qa),I=n(qa,"UL",{});var D=s(I);hM=n(D,"LI",{});var KHe=s(hM);d3e=n(KHe,"STRONG",{});var Kta=s(d3e);kpr=r(Kta,"albert"),Kta.forEach(t),Spr=r(KHe," \u2014 "),iZ=n(KHe,"A",{href:!0});var eaa=s(iZ);Rpr=r(eaa,"AlbertForSequenceClassification"),eaa.forEach(t),Ppr=r(KHe," (ALBERT model)"),KHe.forEach(t),Bpr=i(D),uM=n(D,"LI",{});var eJe=s(uM);m3e=n(eJe,"STRONG",{});var oaa=s(m3e);Ipr=r(oaa,"bart"),oaa.forEach(t),Npr=r(eJe," \u2014 "),dZ=n(eJe,"A",{href:!0});var raa=s(dZ);qpr=r(raa,"BartForSequenceClassification"),raa.forEach(t),jpr=r(eJe," (BART model)"),eJe.forEach(t),Dpr=i(D),pM=n(D,"LI",{});var oJe=s(pM);c3e=n(oJe,"STRONG",{});var taa=s(c3e);Gpr=r(taa,"bert"),taa.forEach(t),Opr=r(oJe," \u2014 "),mZ=n(oJe,"A",{href:!0});var aaa=s(mZ);Vpr=r(aaa,"BertForSequenceClassification"),aaa.forEach(t),Xpr=r(oJe," (BERT model)"),oJe.forEach(t),zpr=i(D),_M=n(D,"LI",{});var rJe=s(_M);f3e=n(rJe,"STRONG",{});var naa=s(f3e);Qpr=r(naa,"big_bird"),naa.forEach(t),Wpr=r(rJe," \u2014 "),cZ=n(rJe,"A",{href:!0});var saa=s(cZ);Upr=r(saa,"BigBirdForSequenceClassification"),saa.forEach(t),Hpr=r(rJe," (BigBird model)"),rJe.forEach(t),Jpr=i(D),bM=n(D,"LI",{});var tJe=s(bM);g3e=n(tJe,"STRONG",{});var laa=s(g3e);Ypr=r(laa,"bigbird_pegasus"),laa.forEach(t),Zpr=r(tJe," \u2014 "),fZ=n(tJe,"A",{href:!0});var iaa=s(fZ);Kpr=r(iaa,"BigBirdPegasusForSequenceClassification"),iaa.forEach(t),e_r=r(tJe," (BigBird-Pegasus model)"),tJe.forEach(t),o_r=i(D),vM=n(D,"LI",{});var aJe=s(vM);h3e=n(aJe,"STRONG",{});var daa=s(h3e);r_r=r(daa,"bloom"),daa.forEach(t),t_r=r(aJe," \u2014 "),gZ=n(aJe,"A",{href:!0});var maa=s(gZ);a_r=r(maa,"BloomForSequenceClassification"),maa.forEach(t),n_r=r(aJe," (BLOOM model)"),aJe.forEach(t),s_r=i(D),FM=n(D,"LI",{});var nJe=s(FM);u3e=n(nJe,"STRONG",{});var caa=s(u3e);l_r=r(caa,"camembert"),caa.forEach(t),i_r=r(nJe," \u2014 "),hZ=n(nJe,"A",{href:!0});var faa=s(hZ);d_r=r(faa,"CamembertForSequenceClassification"),faa.forEach(t),m_r=r(nJe," (CamemBERT model)"),nJe.forEach(t),c_r=i(D),TM=n(D,"LI",{});var sJe=s(TM);p3e=n(sJe,"STRONG",{});var gaa=s(p3e);f_r=r(gaa,"canine"),gaa.forEach(t),g_r=r(sJe," \u2014 "),uZ=n(sJe,"A",{href:!0});var haa=s(uZ);h_r=r(haa,"CanineForSequenceClassification"),haa.forEach(t),u_r=r(sJe," (CANINE model)"),sJe.forEach(t),p_r=i(D),MM=n(D,"LI",{});var lJe=s(MM);_3e=n(lJe,"STRONG",{});var uaa=s(_3e);__r=r(uaa,"convbert"),uaa.forEach(t),b_r=r(lJe," \u2014 "),pZ=n(lJe,"A",{href:!0});var paa=s(pZ);v_r=r(paa,"ConvBertForSequenceClassification"),paa.forEach(t),F_r=r(lJe," (ConvBERT model)"),lJe.forEach(t),T_r=i(D),EM=n(D,"LI",{});var iJe=s(EM);b3e=n(iJe,"STRONG",{});var _aa=s(b3e);M_r=r(_aa,"ctrl"),_aa.forEach(t),E_r=r(iJe," \u2014 "),_Z=n(iJe,"A",{href:!0});var baa=s(_Z);C_r=r(baa,"CTRLForSequenceClassification"),baa.forEach(t),w_r=r(iJe," (CTRL model)"),iJe.forEach(t),A_r=i(D),CM=n(D,"LI",{});var dJe=s(CM);v3e=n(dJe,"STRONG",{});var vaa=s(v3e);L_r=r(vaa,"data2vec-text"),vaa.forEach(t),y_r=r(dJe," \u2014 "),bZ=n(dJe,"A",{href:!0});var Faa=s(bZ);x_r=r(Faa,"Data2VecTextForSequenceClassification"),Faa.forEach(t),$_r=r(dJe," (Data2VecText model)"),dJe.forEach(t),k_r=i(D),wM=n(D,"LI",{});var mJe=s(wM);F3e=n(mJe,"STRONG",{});var Taa=s(F3e);S_r=r(Taa,"deberta"),Taa.forEach(t),R_r=r(mJe," \u2014 "),vZ=n(mJe,"A",{href:!0});var Maa=s(vZ);P_r=r(Maa,"DebertaForSequenceClassification"),Maa.forEach(t),B_r=r(mJe," (DeBERTa model)"),mJe.forEach(t),I_r=i(D),AM=n(D,"LI",{});var cJe=s(AM);T3e=n(cJe,"STRONG",{});var Eaa=s(T3e);N_r=r(Eaa,"deberta-v2"),Eaa.forEach(t),q_r=r(cJe," \u2014 "),FZ=n(cJe,"A",{href:!0});var Caa=s(FZ);j_r=r(Caa,"DebertaV2ForSequenceClassification"),Caa.forEach(t),D_r=r(cJe," (DeBERTa-v2 model)"),cJe.forEach(t),G_r=i(D),LM=n(D,"LI",{});var fJe=s(LM);M3e=n(fJe,"STRONG",{});var waa=s(M3e);O_r=r(waa,"distilbert"),waa.forEach(t),V_r=r(fJe," \u2014 "),TZ=n(fJe,"A",{href:!0});var Aaa=s(TZ);X_r=r(Aaa,"DistilBertForSequenceClassification"),Aaa.forEach(t),z_r=r(fJe," (DistilBERT model)"),fJe.forEach(t),Q_r=i(D),yM=n(D,"LI",{});var gJe=s(yM);E3e=n(gJe,"STRONG",{});var Laa=s(E3e);W_r=r(Laa,"electra"),Laa.forEach(t),U_r=r(gJe," \u2014 "),MZ=n(gJe,"A",{href:!0});var yaa=s(MZ);H_r=r(yaa,"ElectraForSequenceClassification"),yaa.forEach(t),J_r=r(gJe," (ELECTRA model)"),gJe.forEach(t),Y_r=i(D),xM=n(D,"LI",{});var hJe=s(xM);C3e=n(hJe,"STRONG",{});var xaa=s(C3e);Z_r=r(xaa,"ernie"),xaa.forEach(t),K_r=r(hJe," \u2014 "),EZ=n(hJe,"A",{href:!0});var $aa=s(EZ);e1r=r($aa,"ErnieForSequenceClassification"),$aa.forEach(t),o1r=r(hJe," (ERNIE model)"),hJe.forEach(t),r1r=i(D),$M=n(D,"LI",{});var uJe=s($M);w3e=n(uJe,"STRONG",{});var kaa=s(w3e);t1r=r(kaa,"esm"),kaa.forEach(t),a1r=r(uJe," \u2014 "),CZ=n(uJe,"A",{href:!0});var Saa=s(CZ);n1r=r(Saa,"EsmForSequenceClassification"),Saa.forEach(t),s1r=r(uJe," (ESM model)"),uJe.forEach(t),l1r=i(D),kM=n(D,"LI",{});var pJe=s(kM);A3e=n(pJe,"STRONG",{});var Raa=s(A3e);i1r=r(Raa,"flaubert"),Raa.forEach(t),d1r=r(pJe," \u2014 "),wZ=n(pJe,"A",{href:!0});var Paa=s(wZ);m1r=r(Paa,"FlaubertForSequenceClassification"),Paa.forEach(t),c1r=r(pJe," (FlauBERT model)"),pJe.forEach(t),f1r=i(D),SM=n(D,"LI",{});var _Je=s(SM);L3e=n(_Je,"STRONG",{});var Baa=s(L3e);g1r=r(Baa,"fnet"),Baa.forEach(t),h1r=r(_Je," \u2014 "),AZ=n(_Je,"A",{href:!0});var Iaa=s(AZ);u1r=r(Iaa,"FNetForSequenceClassification"),Iaa.forEach(t),p1r=r(_Je," (FNet model)"),_Je.forEach(t),_1r=i(D),RM=n(D,"LI",{});var bJe=s(RM);y3e=n(bJe,"STRONG",{});var Naa=s(y3e);b1r=r(Naa,"funnel"),Naa.forEach(t),v1r=r(bJe," \u2014 "),LZ=n(bJe,"A",{href:!0});var qaa=s(LZ);F1r=r(qaa,"FunnelForSequenceClassification"),qaa.forEach(t),T1r=r(bJe," (Funnel Transformer model)"),bJe.forEach(t),M1r=i(D),PM=n(D,"LI",{});var vJe=s(PM);x3e=n(vJe,"STRONG",{});var jaa=s(x3e);E1r=r(jaa,"gpt2"),jaa.forEach(t),C1r=r(vJe," \u2014 "),yZ=n(vJe,"A",{href:!0});var Daa=s(yZ);w1r=r(Daa,"GPT2ForSequenceClassification"),Daa.forEach(t),A1r=r(vJe," (OpenAI GPT-2 model)"),vJe.forEach(t),L1r=i(D),BM=n(D,"LI",{});var FJe=s(BM);$3e=n(FJe,"STRONG",{});var Gaa=s($3e);y1r=r(Gaa,"gpt_neo"),Gaa.forEach(t),x1r=r(FJe," \u2014 "),xZ=n(FJe,"A",{href:!0});var Oaa=s(xZ);$1r=r(Oaa,"GPTNeoForSequenceClassification"),Oaa.forEach(t),k1r=r(FJe," (GPT Neo model)"),FJe.forEach(t),S1r=i(D),IM=n(D,"LI",{});var TJe=s(IM);k3e=n(TJe,"STRONG",{});var Vaa=s(k3e);R1r=r(Vaa,"gptj"),Vaa.forEach(t),P1r=r(TJe," \u2014 "),$Z=n(TJe,"A",{href:!0});var Xaa=s($Z);B1r=r(Xaa,"GPTJForSequenceClassification"),Xaa.forEach(t),I1r=r(TJe," (GPT-J model)"),TJe.forEach(t),N1r=i(D),NM=n(D,"LI",{});var MJe=s(NM);S3e=n(MJe,"STRONG",{});var zaa=s(S3e);q1r=r(zaa,"ibert"),zaa.forEach(t),j1r=r(MJe," \u2014 "),kZ=n(MJe,"A",{href:!0});var Qaa=s(kZ);D1r=r(Qaa,"IBertForSequenceClassification"),Qaa.forEach(t),G1r=r(MJe," (I-BERT model)"),MJe.forEach(t),O1r=i(D),qM=n(D,"LI",{});var EJe=s(qM);R3e=n(EJe,"STRONG",{});var Waa=s(R3e);V1r=r(Waa,"layoutlm"),Waa.forEach(t),X1r=r(EJe," \u2014 "),SZ=n(EJe,"A",{href:!0});var Uaa=s(SZ);z1r=r(Uaa,"LayoutLMForSequenceClassification"),Uaa.forEach(t),Q1r=r(EJe," (LayoutLM model)"),EJe.forEach(t),W1r=i(D),jM=n(D,"LI",{});var CJe=s(jM);P3e=n(CJe,"STRONG",{});var Haa=s(P3e);U1r=r(Haa,"layoutlmv2"),Haa.forEach(t),H1r=r(CJe," \u2014 "),RZ=n(CJe,"A",{href:!0});var Jaa=s(RZ);J1r=r(Jaa,"LayoutLMv2ForSequenceClassification"),Jaa.forEach(t),Y1r=r(CJe," (LayoutLMv2 model)"),CJe.forEach(t),Z1r=i(D),DM=n(D,"LI",{});var wJe=s(DM);B3e=n(wJe,"STRONG",{});var Yaa=s(B3e);K1r=r(Yaa,"layoutlmv3"),Yaa.forEach(t),e2r=r(wJe," \u2014 "),PZ=n(wJe,"A",{href:!0});var Zaa=s(PZ);o2r=r(Zaa,"LayoutLMv3ForSequenceClassification"),Zaa.forEach(t),r2r=r(wJe," (LayoutLMv3 model)"),wJe.forEach(t),t2r=i(D),GM=n(D,"LI",{});var AJe=s(GM);I3e=n(AJe,"STRONG",{});var Kaa=s(I3e);a2r=r(Kaa,"led"),Kaa.forEach(t),n2r=r(AJe," \u2014 "),BZ=n(AJe,"A",{href:!0});var ena=s(BZ);s2r=r(ena,"LEDForSequenceClassification"),ena.forEach(t),l2r=r(AJe," (LED model)"),AJe.forEach(t),i2r=i(D),OM=n(D,"LI",{});var LJe=s(OM);N3e=n(LJe,"STRONG",{});var ona=s(N3e);d2r=r(ona,"lilt"),ona.forEach(t),m2r=r(LJe," \u2014 "),IZ=n(LJe,"A",{href:!0});var rna=s(IZ);c2r=r(rna,"LiltForSequenceClassification"),rna.forEach(t),f2r=r(LJe," (LiLT model)"),LJe.forEach(t),g2r=i(D),VM=n(D,"LI",{});var yJe=s(VM);q3e=n(yJe,"STRONG",{});var tna=s(q3e);h2r=r(tna,"longformer"),tna.forEach(t),u2r=r(yJe," \u2014 "),NZ=n(yJe,"A",{href:!0});var ana=s(NZ);p2r=r(ana,"LongformerForSequenceClassification"),ana.forEach(t),_2r=r(yJe," (Longformer model)"),yJe.forEach(t),b2r=i(D),XM=n(D,"LI",{});var xJe=s(XM);j3e=n(xJe,"STRONG",{});var nna=s(j3e);v2r=r(nna,"luke"),nna.forEach(t),F2r=r(xJe," \u2014 "),qZ=n(xJe,"A",{href:!0});var sna=s(qZ);T2r=r(sna,"LukeForSequenceClassification"),sna.forEach(t),M2r=r(xJe," (LUKE model)"),xJe.forEach(t),E2r=i(D),zM=n(D,"LI",{});var $Je=s(zM);D3e=n($Je,"STRONG",{});var lna=s(D3e);C2r=r(lna,"markuplm"),lna.forEach(t),w2r=r($Je," \u2014 "),jZ=n($Je,"A",{href:!0});var ina=s(jZ);A2r=r(ina,"MarkupLMForSequenceClassification"),ina.forEach(t),L2r=r($Je," (MarkupLM model)"),$Je.forEach(t),y2r=i(D),QM=n(D,"LI",{});var kJe=s(QM);G3e=n(kJe,"STRONG",{});var dna=s(G3e);x2r=r(dna,"mbart"),dna.forEach(t),$2r=r(kJe," \u2014 "),DZ=n(kJe,"A",{href:!0});var mna=s(DZ);k2r=r(mna,"MBartForSequenceClassification"),mna.forEach(t),S2r=r(kJe," (mBART model)"),kJe.forEach(t),R2r=i(D),WM=n(D,"LI",{});var SJe=s(WM);O3e=n(SJe,"STRONG",{});var cna=s(O3e);P2r=r(cna,"megatron-bert"),cna.forEach(t),B2r=r(SJe," \u2014 "),GZ=n(SJe,"A",{href:!0});var fna=s(GZ);I2r=r(fna,"MegatronBertForSequenceClassification"),fna.forEach(t),N2r=r(SJe," (Megatron-BERT model)"),SJe.forEach(t),q2r=i(D),UM=n(D,"LI",{});var RJe=s(UM);V3e=n(RJe,"STRONG",{});var gna=s(V3e);j2r=r(gna,"mobilebert"),gna.forEach(t),D2r=r(RJe," \u2014 "),OZ=n(RJe,"A",{href:!0});var hna=s(OZ);G2r=r(hna,"MobileBertForSequenceClassification"),hna.forEach(t),O2r=r(RJe," (MobileBERT model)"),RJe.forEach(t),V2r=i(D),HM=n(D,"LI",{});var PJe=s(HM);X3e=n(PJe,"STRONG",{});var una=s(X3e);X2r=r(una,"mpnet"),una.forEach(t),z2r=r(PJe," \u2014 "),VZ=n(PJe,"A",{href:!0});var pna=s(VZ);Q2r=r(pna,"MPNetForSequenceClassification"),pna.forEach(t),W2r=r(PJe," (MPNet model)"),PJe.forEach(t),U2r=i(D),JM=n(D,"LI",{});var BJe=s(JM);z3e=n(BJe,"STRONG",{});var _na=s(z3e);H2r=r(_na,"mvp"),_na.forEach(t),J2r=r(BJe," \u2014 "),XZ=n(BJe,"A",{href:!0});var bna=s(XZ);Y2r=r(bna,"MvpForSequenceClassification"),bna.forEach(t),Z2r=r(BJe," (MVP model)"),BJe.forEach(t),K2r=i(D),YM=n(D,"LI",{});var IJe=s(YM);Q3e=n(IJe,"STRONG",{});var vna=s(Q3e);ebr=r(vna,"nezha"),vna.forEach(t),obr=r(IJe," \u2014 "),zZ=n(IJe,"A",{href:!0});var Fna=s(zZ);rbr=r(Fna,"NezhaForSequenceClassification"),Fna.forEach(t),tbr=r(IJe," (Nezha model)"),IJe.forEach(t),abr=i(D),ZM=n(D,"LI",{});var NJe=s(ZM);W3e=n(NJe,"STRONG",{});var Tna=s(W3e);nbr=r(Tna,"nystromformer"),Tna.forEach(t),sbr=r(NJe," \u2014 "),QZ=n(NJe,"A",{href:!0});var Mna=s(QZ);lbr=r(Mna,"NystromformerForSequenceClassification"),Mna.forEach(t),ibr=r(NJe," (Nystr\xF6mformer model)"),NJe.forEach(t),dbr=i(D),KM=n(D,"LI",{});var qJe=s(KM);U3e=n(qJe,"STRONG",{});var Ena=s(U3e);mbr=r(Ena,"openai-gpt"),Ena.forEach(t),cbr=r(qJe," \u2014 "),WZ=n(qJe,"A",{href:!0});var Cna=s(WZ);fbr=r(Cna,"OpenAIGPTForSequenceClassification"),Cna.forEach(t),gbr=r(qJe," (OpenAI GPT model)"),qJe.forEach(t),hbr=i(D),eE=n(D,"LI",{});var jJe=s(eE);H3e=n(jJe,"STRONG",{});var wna=s(H3e);ubr=r(wna,"opt"),wna.forEach(t),pbr=r(jJe," \u2014 "),UZ=n(jJe,"A",{href:!0});var Ana=s(UZ);_br=r(Ana,"OPTForSequenceClassification"),Ana.forEach(t),bbr=r(jJe," (OPT model)"),jJe.forEach(t),vbr=i(D),oE=n(D,"LI",{});var DJe=s(oE);J3e=n(DJe,"STRONG",{});var Lna=s(J3e);Fbr=r(Lna,"perceiver"),Lna.forEach(t),Tbr=r(DJe," \u2014 "),HZ=n(DJe,"A",{href:!0});var yna=s(HZ);Mbr=r(yna,"PerceiverForSequenceClassification"),yna.forEach(t),Ebr=r(DJe," (Perceiver model)"),DJe.forEach(t),Cbr=i(D),rE=n(D,"LI",{});var GJe=s(rE);Y3e=n(GJe,"STRONG",{});var xna=s(Y3e);wbr=r(xna,"plbart"),xna.forEach(t),Abr=r(GJe," \u2014 "),JZ=n(GJe,"A",{href:!0});var $na=s(JZ);Lbr=r($na,"PLBartForSequenceClassification"),$na.forEach(t),ybr=r(GJe," (PLBart model)"),GJe.forEach(t),xbr=i(D),tE=n(D,"LI",{});var OJe=s(tE);Z3e=n(OJe,"STRONG",{});var kna=s(Z3e);$br=r(kna,"qdqbert"),kna.forEach(t),kbr=r(OJe," \u2014 "),YZ=n(OJe,"A",{href:!0});var Sna=s(YZ);Sbr=r(Sna,"QDQBertForSequenceClassification"),Sna.forEach(t),Rbr=r(OJe," (QDQBert model)"),OJe.forEach(t),Pbr=i(D),aE=n(D,"LI",{});var VJe=s(aE);K3e=n(VJe,"STRONG",{});var Rna=s(K3e);Bbr=r(Rna,"reformer"),Rna.forEach(t),Ibr=r(VJe," \u2014 "),ZZ=n(VJe,"A",{href:!0});var Pna=s(ZZ);Nbr=r(Pna,"ReformerForSequenceClassification"),Pna.forEach(t),qbr=r(VJe," (Reformer model)"),VJe.forEach(t),jbr=i(D),nE=n(D,"LI",{});var XJe=s(nE);e5e=n(XJe,"STRONG",{});var Bna=s(e5e);Dbr=r(Bna,"rembert"),Bna.forEach(t),Gbr=r(XJe," \u2014 "),KZ=n(XJe,"A",{href:!0});var Ina=s(KZ);Obr=r(Ina,"RemBertForSequenceClassification"),Ina.forEach(t),Vbr=r(XJe," (RemBERT model)"),XJe.forEach(t),Xbr=i(D),sE=n(D,"LI",{});var zJe=s(sE);o5e=n(zJe,"STRONG",{});var Nna=s(o5e);zbr=r(Nna,"roberta"),Nna.forEach(t),Qbr=r(zJe," \u2014 "),eK=n(zJe,"A",{href:!0});var qna=s(eK);Wbr=r(qna,"RobertaForSequenceClassification"),qna.forEach(t),Ubr=r(zJe," (RoBERTa model)"),zJe.forEach(t),Hbr=i(D),lE=n(D,"LI",{});var QJe=s(lE);r5e=n(QJe,"STRONG",{});var jna=s(r5e);Jbr=r(jna,"roc_bert"),jna.forEach(t),Ybr=r(QJe," \u2014 "),oK=n(QJe,"A",{href:!0});var Dna=s(oK);Zbr=r(Dna,"RoCBertForSequenceClassification"),Dna.forEach(t),Kbr=r(QJe," (RoCBert model)"),QJe.forEach(t),evr=i(D),iE=n(D,"LI",{});var WJe=s(iE);t5e=n(WJe,"STRONG",{});var Gna=s(t5e);ovr=r(Gna,"roformer"),Gna.forEach(t),rvr=r(WJe," \u2014 "),rK=n(WJe,"A",{href:!0});var Ona=s(rK);tvr=r(Ona,"RoFormerForSequenceClassification"),Ona.forEach(t),avr=r(WJe," (RoFormer model)"),WJe.forEach(t),nvr=i(D),dE=n(D,"LI",{});var UJe=s(dE);a5e=n(UJe,"STRONG",{});var Vna=s(a5e);svr=r(Vna,"squeezebert"),Vna.forEach(t),lvr=r(UJe," \u2014 "),tK=n(UJe,"A",{href:!0});var Xna=s(tK);ivr=r(Xna,"SqueezeBertForSequenceClassification"),Xna.forEach(t),dvr=r(UJe," (SqueezeBERT model)"),UJe.forEach(t),mvr=i(D),mE=n(D,"LI",{});var HJe=s(mE);n5e=n(HJe,"STRONG",{});var zna=s(n5e);cvr=r(zna,"tapas"),zna.forEach(t),fvr=r(HJe," \u2014 "),aK=n(HJe,"A",{href:!0});var Qna=s(aK);gvr=r(Qna,"TapasForSequenceClassification"),Qna.forEach(t),hvr=r(HJe," (TAPAS model)"),HJe.forEach(t),uvr=i(D),cE=n(D,"LI",{});var JJe=s(cE);s5e=n(JJe,"STRONG",{});var Wna=s(s5e);pvr=r(Wna,"transfo-xl"),Wna.forEach(t),_vr=r(JJe," \u2014 "),nK=n(JJe,"A",{href:!0});var Una=s(nK);bvr=r(Una,"TransfoXLForSequenceClassification"),Una.forEach(t),vvr=r(JJe," (Transformer-XL model)"),JJe.forEach(t),Fvr=i(D),fE=n(D,"LI",{});var YJe=s(fE);l5e=n(YJe,"STRONG",{});var Hna=s(l5e);Tvr=r(Hna,"xlm"),Hna.forEach(t),Mvr=r(YJe," \u2014 "),sK=n(YJe,"A",{href:!0});var Jna=s(sK);Evr=r(Jna,"XLMForSequenceClassification"),Jna.forEach(t),Cvr=r(YJe," (XLM model)"),YJe.forEach(t),wvr=i(D),gE=n(D,"LI",{});var ZJe=s(gE);i5e=n(ZJe,"STRONG",{});var Yna=s(i5e);Avr=r(Yna,"xlm-roberta"),Yna.forEach(t),Lvr=r(ZJe," \u2014 "),lK=n(ZJe,"A",{href:!0});var Zna=s(lK);yvr=r(Zna,"XLMRobertaForSequenceClassification"),Zna.forEach(t),xvr=r(ZJe," (XLM-RoBERTa model)"),ZJe.forEach(t),$vr=i(D),hE=n(D,"LI",{});var KJe=s(hE);d5e=n(KJe,"STRONG",{});var Kna=s(d5e);kvr=r(Kna,"xlm-roberta-xl"),Kna.forEach(t),Svr=r(KJe," \u2014 "),iK=n(KJe,"A",{href:!0});var esa=s(iK);Rvr=r(esa,"XLMRobertaXLForSequenceClassification"),esa.forEach(t),Pvr=r(KJe," (XLM-RoBERTa-XL model)"),KJe.forEach(t),Bvr=i(D),uE=n(D,"LI",{});var eYe=s(uE);m5e=n(eYe,"STRONG",{});var osa=s(m5e);Ivr=r(osa,"xlnet"),osa.forEach(t),Nvr=r(eYe," \u2014 "),dK=n(eYe,"A",{href:!0});var rsa=s(dK);qvr=r(rsa,"XLNetForSequenceClassification"),rsa.forEach(t),jvr=r(eYe," (XLNet model)"),eYe.forEach(t),Dvr=i(D),pE=n(D,"LI",{});var oYe=s(pE);c5e=n(oYe,"STRONG",{});var tsa=s(c5e);Gvr=r(tsa,"yoso"),tsa.forEach(t),Ovr=r(oYe," \u2014 "),mK=n(oYe,"A",{href:!0});var asa=s(mK);Vvr=r(asa,"YosoForSequenceClassification"),asa.forEach(t),Xvr=r(oYe," (YOSO model)"),oYe.forEach(t),D.forEach(t),zvr=i(qa),_E=n(qa,"P",{});var rYe=s(_E);Qvr=r(rYe,"The model is set in evaluation mode by default using "),f5e=n(rYe,"CODE",{});var nsa=s(f5e);Wvr=r(nsa,"model.eval()"),nsa.forEach(t),Uvr=r(rYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),g5e=n(rYe,"CODE",{});var ssa=s(g5e);Hvr=r(ssa,"model.train()"),ssa.forEach(t),rYe.forEach(t),Jvr=i(qa),T(bE.$$.fragment,qa),qa.forEach(t),Zl.forEach(t),tio=i(c),im=n(c,"H2",{class:!0});var Amo=s(im);vE=n(Amo,"A",{id:!0,class:!0,href:!0});var lsa=s(vE);h5e=n(lsa,"SPAN",{});var isa=s(h5e);T(xS.$$.fragment,isa),isa.forEach(t),lsa.forEach(t),Yvr=i(Amo),u5e=n(Amo,"SPAN",{});var dsa=s(u5e);Zvr=r(dsa,"AutoModelForMultipleChoice"),dsa.forEach(t),Amo.forEach(t),aio=i(c),Wo=n(c,"DIV",{class:!0});var Kl=s(Wo);T($S.$$.fragment,Kl),Kvr=i(Kl),dm=n(Kl,"P",{});var Afe=s(dm);eFr=r(Afe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),cK=n(Afe,"A",{href:!0});var msa=s(cK);oFr=r(msa,"from_pretrained()"),msa.forEach(t),rFr=r(Afe," class method or the "),fK=n(Afe,"A",{href:!0});var csa=s(fK);tFr=r(csa,"from_config()"),csa.forEach(t),aFr=r(Afe,` class
method.`),Afe.forEach(t),nFr=i(Kl),kS=n(Kl,"P",{});var Lmo=s(kS);sFr=r(Lmo,"This class cannot be instantiated directly using "),p5e=n(Lmo,"CODE",{});var fsa=s(p5e);lFr=r(fsa,"__init__()"),fsa.forEach(t),iFr=r(Lmo," (throws an error)."),Lmo.forEach(t),dFr=i(Kl),Rt=n(Kl,"DIV",{class:!0});var Fx=s(Rt);T(SS.$$.fragment,Fx),mFr=i(Fx),_5e=n(Fx,"P",{});var gsa=s(_5e);cFr=r(gsa,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),gsa.forEach(t),fFr=i(Fx),mm=n(Fx,"P",{});var Lfe=s(mm);gFr=r(Lfe,`Note:
Loading a model from its configuration file does `),b5e=n(Lfe,"STRONG",{});var hsa=s(b5e);hFr=r(hsa,"not"),hsa.forEach(t),uFr=r(Lfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),gK=n(Lfe,"A",{href:!0});var usa=s(gK);pFr=r(usa,"from_pretrained()"),usa.forEach(t),_Fr=r(Lfe," to load the model weights."),Lfe.forEach(t),bFr=i(Fx),T(FE.$$.fragment,Fx),Fx.forEach(t),vFr=i(Kl),co=n(Kl,"DIV",{class:!0});var ja=s(co);T(RS.$$.fragment,ja),FFr=i(ja),v5e=n(ja,"P",{});var psa=s(v5e);TFr=r(psa,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),psa.forEach(t),MFr=i(ja),vn=n(ja,"P",{});var Tx=s(vn);EFr=r(Tx,"The model class to instantiate is selected based on the "),F5e=n(Tx,"CODE",{});var _sa=s(F5e);CFr=r(_sa,"model_type"),_sa.forEach(t),wFr=r(Tx,` property of the config object (either
passed as an argument or loaded from `),T5e=n(Tx,"CODE",{});var bsa=s(T5e);AFr=r(bsa,"pretrained_model_name_or_path"),bsa.forEach(t),LFr=r(Tx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M5e=n(Tx,"CODE",{});var vsa=s(M5e);yFr=r(vsa,"pretrained_model_name_or_path"),vsa.forEach(t),xFr=r(Tx,":"),Tx.forEach(t),$Fr=i(ja),K=n(ja,"UL",{});var ee=s(K);TE=n(ee,"LI",{});var tYe=s(TE);E5e=n(tYe,"STRONG",{});var Fsa=s(E5e);kFr=r(Fsa,"albert"),Fsa.forEach(t),SFr=r(tYe," \u2014 "),hK=n(tYe,"A",{href:!0});var Tsa=s(hK);RFr=r(Tsa,"AlbertForMultipleChoice"),Tsa.forEach(t),PFr=r(tYe," (ALBERT model)"),tYe.forEach(t),BFr=i(ee),ME=n(ee,"LI",{});var aYe=s(ME);C5e=n(aYe,"STRONG",{});var Msa=s(C5e);IFr=r(Msa,"bert"),Msa.forEach(t),NFr=r(aYe," \u2014 "),uK=n(aYe,"A",{href:!0});var Esa=s(uK);qFr=r(Esa,"BertForMultipleChoice"),Esa.forEach(t),jFr=r(aYe," (BERT model)"),aYe.forEach(t),DFr=i(ee),EE=n(ee,"LI",{});var nYe=s(EE);w5e=n(nYe,"STRONG",{});var Csa=s(w5e);GFr=r(Csa,"big_bird"),Csa.forEach(t),OFr=r(nYe," \u2014 "),pK=n(nYe,"A",{href:!0});var wsa=s(pK);VFr=r(wsa,"BigBirdForMultipleChoice"),wsa.forEach(t),XFr=r(nYe," (BigBird model)"),nYe.forEach(t),zFr=i(ee),CE=n(ee,"LI",{});var sYe=s(CE);A5e=n(sYe,"STRONG",{});var Asa=s(A5e);QFr=r(Asa,"camembert"),Asa.forEach(t),WFr=r(sYe," \u2014 "),_K=n(sYe,"A",{href:!0});var Lsa=s(_K);UFr=r(Lsa,"CamembertForMultipleChoice"),Lsa.forEach(t),HFr=r(sYe," (CamemBERT model)"),sYe.forEach(t),JFr=i(ee),wE=n(ee,"LI",{});var lYe=s(wE);L5e=n(lYe,"STRONG",{});var ysa=s(L5e);YFr=r(ysa,"canine"),ysa.forEach(t),ZFr=r(lYe," \u2014 "),bK=n(lYe,"A",{href:!0});var xsa=s(bK);KFr=r(xsa,"CanineForMultipleChoice"),xsa.forEach(t),eTr=r(lYe," (CANINE model)"),lYe.forEach(t),oTr=i(ee),AE=n(ee,"LI",{});var iYe=s(AE);y5e=n(iYe,"STRONG",{});var $sa=s(y5e);rTr=r($sa,"convbert"),$sa.forEach(t),tTr=r(iYe," \u2014 "),vK=n(iYe,"A",{href:!0});var ksa=s(vK);aTr=r(ksa,"ConvBertForMultipleChoice"),ksa.forEach(t),nTr=r(iYe," (ConvBERT model)"),iYe.forEach(t),sTr=i(ee),LE=n(ee,"LI",{});var dYe=s(LE);x5e=n(dYe,"STRONG",{});var Ssa=s(x5e);lTr=r(Ssa,"data2vec-text"),Ssa.forEach(t),iTr=r(dYe," \u2014 "),FK=n(dYe,"A",{href:!0});var Rsa=s(FK);dTr=r(Rsa,"Data2VecTextForMultipleChoice"),Rsa.forEach(t),mTr=r(dYe," (Data2VecText model)"),dYe.forEach(t),cTr=i(ee),yE=n(ee,"LI",{});var mYe=s(yE);$5e=n(mYe,"STRONG",{});var Psa=s($5e);fTr=r(Psa,"deberta-v2"),Psa.forEach(t),gTr=r(mYe," \u2014 "),TK=n(mYe,"A",{href:!0});var Bsa=s(TK);hTr=r(Bsa,"DebertaV2ForMultipleChoice"),Bsa.forEach(t),uTr=r(mYe," (DeBERTa-v2 model)"),mYe.forEach(t),pTr=i(ee),xE=n(ee,"LI",{});var cYe=s(xE);k5e=n(cYe,"STRONG",{});var Isa=s(k5e);_Tr=r(Isa,"distilbert"),Isa.forEach(t),bTr=r(cYe," \u2014 "),MK=n(cYe,"A",{href:!0});var Nsa=s(MK);vTr=r(Nsa,"DistilBertForMultipleChoice"),Nsa.forEach(t),FTr=r(cYe," (DistilBERT model)"),cYe.forEach(t),TTr=i(ee),$E=n(ee,"LI",{});var fYe=s($E);S5e=n(fYe,"STRONG",{});var qsa=s(S5e);MTr=r(qsa,"electra"),qsa.forEach(t),ETr=r(fYe," \u2014 "),EK=n(fYe,"A",{href:!0});var jsa=s(EK);CTr=r(jsa,"ElectraForMultipleChoice"),jsa.forEach(t),wTr=r(fYe," (ELECTRA model)"),fYe.forEach(t),ATr=i(ee),kE=n(ee,"LI",{});var gYe=s(kE);R5e=n(gYe,"STRONG",{});var Dsa=s(R5e);LTr=r(Dsa,"ernie"),Dsa.forEach(t),yTr=r(gYe," \u2014 "),CK=n(gYe,"A",{href:!0});var Gsa=s(CK);xTr=r(Gsa,"ErnieForMultipleChoice"),Gsa.forEach(t),$Tr=r(gYe," (ERNIE model)"),gYe.forEach(t),kTr=i(ee),SE=n(ee,"LI",{});var hYe=s(SE);P5e=n(hYe,"STRONG",{});var Osa=s(P5e);STr=r(Osa,"flaubert"),Osa.forEach(t),RTr=r(hYe," \u2014 "),wK=n(hYe,"A",{href:!0});var Vsa=s(wK);PTr=r(Vsa,"FlaubertForMultipleChoice"),Vsa.forEach(t),BTr=r(hYe," (FlauBERT model)"),hYe.forEach(t),ITr=i(ee),RE=n(ee,"LI",{});var uYe=s(RE);B5e=n(uYe,"STRONG",{});var Xsa=s(B5e);NTr=r(Xsa,"fnet"),Xsa.forEach(t),qTr=r(uYe," \u2014 "),AK=n(uYe,"A",{href:!0});var zsa=s(AK);jTr=r(zsa,"FNetForMultipleChoice"),zsa.forEach(t),DTr=r(uYe," (FNet model)"),uYe.forEach(t),GTr=i(ee),PE=n(ee,"LI",{});var pYe=s(PE);I5e=n(pYe,"STRONG",{});var Qsa=s(I5e);OTr=r(Qsa,"funnel"),Qsa.forEach(t),VTr=r(pYe," \u2014 "),LK=n(pYe,"A",{href:!0});var Wsa=s(LK);XTr=r(Wsa,"FunnelForMultipleChoice"),Wsa.forEach(t),zTr=r(pYe," (Funnel Transformer model)"),pYe.forEach(t),QTr=i(ee),BE=n(ee,"LI",{});var _Ye=s(BE);N5e=n(_Ye,"STRONG",{});var Usa=s(N5e);WTr=r(Usa,"ibert"),Usa.forEach(t),UTr=r(_Ye," \u2014 "),yK=n(_Ye,"A",{href:!0});var Hsa=s(yK);HTr=r(Hsa,"IBertForMultipleChoice"),Hsa.forEach(t),JTr=r(_Ye," (I-BERT model)"),_Ye.forEach(t),YTr=i(ee),IE=n(ee,"LI",{});var bYe=s(IE);q5e=n(bYe,"STRONG",{});var Jsa=s(q5e);ZTr=r(Jsa,"longformer"),Jsa.forEach(t),KTr=r(bYe," \u2014 "),xK=n(bYe,"A",{href:!0});var Ysa=s(xK);eMr=r(Ysa,"LongformerForMultipleChoice"),Ysa.forEach(t),oMr=r(bYe," (Longformer model)"),bYe.forEach(t),rMr=i(ee),NE=n(ee,"LI",{});var vYe=s(NE);j5e=n(vYe,"STRONG",{});var Zsa=s(j5e);tMr=r(Zsa,"luke"),Zsa.forEach(t),aMr=r(vYe," \u2014 "),$K=n(vYe,"A",{href:!0});var Ksa=s($K);nMr=r(Ksa,"LukeForMultipleChoice"),Ksa.forEach(t),sMr=r(vYe," (LUKE model)"),vYe.forEach(t),lMr=i(ee),qE=n(ee,"LI",{});var FYe=s(qE);D5e=n(FYe,"STRONG",{});var ela=s(D5e);iMr=r(ela,"megatron-bert"),ela.forEach(t),dMr=r(FYe," \u2014 "),kK=n(FYe,"A",{href:!0});var ola=s(kK);mMr=r(ola,"MegatronBertForMultipleChoice"),ola.forEach(t),cMr=r(FYe," (Megatron-BERT model)"),FYe.forEach(t),fMr=i(ee),jE=n(ee,"LI",{});var TYe=s(jE);G5e=n(TYe,"STRONG",{});var rla=s(G5e);gMr=r(rla,"mobilebert"),rla.forEach(t),hMr=r(TYe," \u2014 "),SK=n(TYe,"A",{href:!0});var tla=s(SK);uMr=r(tla,"MobileBertForMultipleChoice"),tla.forEach(t),pMr=r(TYe," (MobileBERT model)"),TYe.forEach(t),_Mr=i(ee),DE=n(ee,"LI",{});var MYe=s(DE);O5e=n(MYe,"STRONG",{});var ala=s(O5e);bMr=r(ala,"mpnet"),ala.forEach(t),vMr=r(MYe," \u2014 "),RK=n(MYe,"A",{href:!0});var nla=s(RK);FMr=r(nla,"MPNetForMultipleChoice"),nla.forEach(t),TMr=r(MYe," (MPNet model)"),MYe.forEach(t),MMr=i(ee),GE=n(ee,"LI",{});var EYe=s(GE);V5e=n(EYe,"STRONG",{});var sla=s(V5e);EMr=r(sla,"nezha"),sla.forEach(t),CMr=r(EYe," \u2014 "),PK=n(EYe,"A",{href:!0});var lla=s(PK);wMr=r(lla,"NezhaForMultipleChoice"),lla.forEach(t),AMr=r(EYe," (Nezha model)"),EYe.forEach(t),LMr=i(ee),OE=n(ee,"LI",{});var CYe=s(OE);X5e=n(CYe,"STRONG",{});var ila=s(X5e);yMr=r(ila,"nystromformer"),ila.forEach(t),xMr=r(CYe," \u2014 "),BK=n(CYe,"A",{href:!0});var dla=s(BK);$Mr=r(dla,"NystromformerForMultipleChoice"),dla.forEach(t),kMr=r(CYe," (Nystr\xF6mformer model)"),CYe.forEach(t),SMr=i(ee),VE=n(ee,"LI",{});var wYe=s(VE);z5e=n(wYe,"STRONG",{});var mla=s(z5e);RMr=r(mla,"qdqbert"),mla.forEach(t),PMr=r(wYe," \u2014 "),IK=n(wYe,"A",{href:!0});var cla=s(IK);BMr=r(cla,"QDQBertForMultipleChoice"),cla.forEach(t),IMr=r(wYe," (QDQBert model)"),wYe.forEach(t),NMr=i(ee),XE=n(ee,"LI",{});var AYe=s(XE);Q5e=n(AYe,"STRONG",{});var fla=s(Q5e);qMr=r(fla,"rembert"),fla.forEach(t),jMr=r(AYe," \u2014 "),NK=n(AYe,"A",{href:!0});var gla=s(NK);DMr=r(gla,"RemBertForMultipleChoice"),gla.forEach(t),GMr=r(AYe," (RemBERT model)"),AYe.forEach(t),OMr=i(ee),zE=n(ee,"LI",{});var LYe=s(zE);W5e=n(LYe,"STRONG",{});var hla=s(W5e);VMr=r(hla,"roberta"),hla.forEach(t),XMr=r(LYe," \u2014 "),qK=n(LYe,"A",{href:!0});var ula=s(qK);zMr=r(ula,"RobertaForMultipleChoice"),ula.forEach(t),QMr=r(LYe," (RoBERTa model)"),LYe.forEach(t),WMr=i(ee),QE=n(ee,"LI",{});var yYe=s(QE);U5e=n(yYe,"STRONG",{});var pla=s(U5e);UMr=r(pla,"roc_bert"),pla.forEach(t),HMr=r(yYe," \u2014 "),jK=n(yYe,"A",{href:!0});var _la=s(jK);JMr=r(_la,"RoCBertForMultipleChoice"),_la.forEach(t),YMr=r(yYe," (RoCBert model)"),yYe.forEach(t),ZMr=i(ee),WE=n(ee,"LI",{});var xYe=s(WE);H5e=n(xYe,"STRONG",{});var bla=s(H5e);KMr=r(bla,"roformer"),bla.forEach(t),eEr=r(xYe," \u2014 "),DK=n(xYe,"A",{href:!0});var vla=s(DK);oEr=r(vla,"RoFormerForMultipleChoice"),vla.forEach(t),rEr=r(xYe," (RoFormer model)"),xYe.forEach(t),tEr=i(ee),UE=n(ee,"LI",{});var $Ye=s(UE);J5e=n($Ye,"STRONG",{});var Fla=s(J5e);aEr=r(Fla,"squeezebert"),Fla.forEach(t),nEr=r($Ye," \u2014 "),GK=n($Ye,"A",{href:!0});var Tla=s(GK);sEr=r(Tla,"SqueezeBertForMultipleChoice"),Tla.forEach(t),lEr=r($Ye," (SqueezeBERT model)"),$Ye.forEach(t),iEr=i(ee),HE=n(ee,"LI",{});var kYe=s(HE);Y5e=n(kYe,"STRONG",{});var Mla=s(Y5e);dEr=r(Mla,"xlm"),Mla.forEach(t),mEr=r(kYe," \u2014 "),OK=n(kYe,"A",{href:!0});var Ela=s(OK);cEr=r(Ela,"XLMForMultipleChoice"),Ela.forEach(t),fEr=r(kYe," (XLM model)"),kYe.forEach(t),gEr=i(ee),JE=n(ee,"LI",{});var SYe=s(JE);Z5e=n(SYe,"STRONG",{});var Cla=s(Z5e);hEr=r(Cla,"xlm-roberta"),Cla.forEach(t),uEr=r(SYe," \u2014 "),VK=n(SYe,"A",{href:!0});var wla=s(VK);pEr=r(wla,"XLMRobertaForMultipleChoice"),wla.forEach(t),_Er=r(SYe," (XLM-RoBERTa model)"),SYe.forEach(t),bEr=i(ee),YE=n(ee,"LI",{});var RYe=s(YE);K5e=n(RYe,"STRONG",{});var Ala=s(K5e);vEr=r(Ala,"xlm-roberta-xl"),Ala.forEach(t),FEr=r(RYe," \u2014 "),XK=n(RYe,"A",{href:!0});var Lla=s(XK);TEr=r(Lla,"XLMRobertaXLForMultipleChoice"),Lla.forEach(t),MEr=r(RYe," (XLM-RoBERTa-XL model)"),RYe.forEach(t),EEr=i(ee),ZE=n(ee,"LI",{});var PYe=s(ZE);e0e=n(PYe,"STRONG",{});var yla=s(e0e);CEr=r(yla,"xlnet"),yla.forEach(t),wEr=r(PYe," \u2014 "),zK=n(PYe,"A",{href:!0});var xla=s(zK);AEr=r(xla,"XLNetForMultipleChoice"),xla.forEach(t),LEr=r(PYe," (XLNet model)"),PYe.forEach(t),yEr=i(ee),KE=n(ee,"LI",{});var BYe=s(KE);o0e=n(BYe,"STRONG",{});var $la=s(o0e);xEr=r($la,"yoso"),$la.forEach(t),$Er=r(BYe," \u2014 "),QK=n(BYe,"A",{href:!0});var kla=s(QK);kEr=r(kla,"YosoForMultipleChoice"),kla.forEach(t),SEr=r(BYe," (YOSO model)"),BYe.forEach(t),ee.forEach(t),REr=i(ja),e4=n(ja,"P",{});var IYe=s(e4);PEr=r(IYe,"The model is set in evaluation mode by default using "),r0e=n(IYe,"CODE",{});var Sla=s(r0e);BEr=r(Sla,"model.eval()"),Sla.forEach(t),IEr=r(IYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),t0e=n(IYe,"CODE",{});var Rla=s(t0e);NEr=r(Rla,"model.train()"),Rla.forEach(t),IYe.forEach(t),qEr=i(ja),T(o4.$$.fragment,ja),ja.forEach(t),Kl.forEach(t),nio=i(c),cm=n(c,"H2",{class:!0});var ymo=s(cm);r4=n(ymo,"A",{id:!0,class:!0,href:!0});var Pla=s(r4);a0e=n(Pla,"SPAN",{});var Bla=s(a0e);T(PS.$$.fragment,Bla),Bla.forEach(t),Pla.forEach(t),jEr=i(ymo),n0e=n(ymo,"SPAN",{});var Ila=s(n0e);DEr=r(Ila,"AutoModelForNextSentencePrediction"),Ila.forEach(t),ymo.forEach(t),sio=i(c),Uo=n(c,"DIV",{class:!0});var ei=s(Uo);T(BS.$$.fragment,ei),GEr=i(ei),fm=n(ei,"P",{});var yfe=s(fm);OEr=r(yfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),WK=n(yfe,"A",{href:!0});var Nla=s(WK);VEr=r(Nla,"from_pretrained()"),Nla.forEach(t),XEr=r(yfe," class method or the "),UK=n(yfe,"A",{href:!0});var qla=s(UK);zEr=r(qla,"from_config()"),qla.forEach(t),QEr=r(yfe,` class
method.`),yfe.forEach(t),WEr=i(ei),IS=n(ei,"P",{});var xmo=s(IS);UEr=r(xmo,"This class cannot be instantiated directly using "),s0e=n(xmo,"CODE",{});var jla=s(s0e);HEr=r(jla,"__init__()"),jla.forEach(t),JEr=r(xmo," (throws an error)."),xmo.forEach(t),YEr=i(ei),Pt=n(ei,"DIV",{class:!0});var Mx=s(Pt);T(NS.$$.fragment,Mx),ZEr=i(Mx),l0e=n(Mx,"P",{});var Dla=s(l0e);KEr=r(Dla,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Dla.forEach(t),e4r=i(Mx),gm=n(Mx,"P",{});var xfe=s(gm);o4r=r(xfe,`Note:
Loading a model from its configuration file does `),i0e=n(xfe,"STRONG",{});var Gla=s(i0e);r4r=r(Gla,"not"),Gla.forEach(t),t4r=r(xfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),HK=n(xfe,"A",{href:!0});var Ola=s(HK);a4r=r(Ola,"from_pretrained()"),Ola.forEach(t),n4r=r(xfe," to load the model weights."),xfe.forEach(t),s4r=i(Mx),T(t4.$$.fragment,Mx),Mx.forEach(t),l4r=i(ei),fo=n(ei,"DIV",{class:!0});var Da=s(fo);T(qS.$$.fragment,Da),i4r=i(Da),d0e=n(Da,"P",{});var Vla=s(d0e);d4r=r(Vla,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Vla.forEach(t),m4r=i(Da),Fn=n(Da,"P",{});var Ex=s(Fn);c4r=r(Ex,"The model class to instantiate is selected based on the "),m0e=n(Ex,"CODE",{});var Xla=s(m0e);f4r=r(Xla,"model_type"),Xla.forEach(t),g4r=r(Ex,` property of the config object (either
passed as an argument or loaded from `),c0e=n(Ex,"CODE",{});var zla=s(c0e);h4r=r(zla,"pretrained_model_name_or_path"),zla.forEach(t),u4r=r(Ex,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f0e=n(Ex,"CODE",{});var Qla=s(f0e);p4r=r(Qla,"pretrained_model_name_or_path"),Qla.forEach(t),_4r=r(Ex,":"),Ex.forEach(t),b4r=i(Da),Ye=n(Da,"UL",{});var bt=s(Ye);a4=n(bt,"LI",{});var NYe=s(a4);g0e=n(NYe,"STRONG",{});var Wla=s(g0e);v4r=r(Wla,"bert"),Wla.forEach(t),F4r=r(NYe," \u2014 "),JK=n(NYe,"A",{href:!0});var Ula=s(JK);T4r=r(Ula,"BertForNextSentencePrediction"),Ula.forEach(t),M4r=r(NYe," (BERT model)"),NYe.forEach(t),E4r=i(bt),n4=n(bt,"LI",{});var qYe=s(n4);h0e=n(qYe,"STRONG",{});var Hla=s(h0e);C4r=r(Hla,"ernie"),Hla.forEach(t),w4r=r(qYe," \u2014 "),YK=n(qYe,"A",{href:!0});var Jla=s(YK);A4r=r(Jla,"ErnieForNextSentencePrediction"),Jla.forEach(t),L4r=r(qYe," (ERNIE model)"),qYe.forEach(t),y4r=i(bt),s4=n(bt,"LI",{});var jYe=s(s4);u0e=n(jYe,"STRONG",{});var Yla=s(u0e);x4r=r(Yla,"fnet"),Yla.forEach(t),$4r=r(jYe," \u2014 "),ZK=n(jYe,"A",{href:!0});var Zla=s(ZK);k4r=r(Zla,"FNetForNextSentencePrediction"),Zla.forEach(t),S4r=r(jYe," (FNet model)"),jYe.forEach(t),R4r=i(bt),l4=n(bt,"LI",{});var DYe=s(l4);p0e=n(DYe,"STRONG",{});var Kla=s(p0e);P4r=r(Kla,"megatron-bert"),Kla.forEach(t),B4r=r(DYe," \u2014 "),KK=n(DYe,"A",{href:!0});var eia=s(KK);I4r=r(eia,"MegatronBertForNextSentencePrediction"),eia.forEach(t),N4r=r(DYe," (Megatron-BERT model)"),DYe.forEach(t),q4r=i(bt),i4=n(bt,"LI",{});var GYe=s(i4);_0e=n(GYe,"STRONG",{});var oia=s(_0e);j4r=r(oia,"mobilebert"),oia.forEach(t),D4r=r(GYe," \u2014 "),eee=n(GYe,"A",{href:!0});var ria=s(eee);G4r=r(ria,"MobileBertForNextSentencePrediction"),ria.forEach(t),O4r=r(GYe," (MobileBERT model)"),GYe.forEach(t),V4r=i(bt),d4=n(bt,"LI",{});var OYe=s(d4);b0e=n(OYe,"STRONG",{});var tia=s(b0e);X4r=r(tia,"nezha"),tia.forEach(t),z4r=r(OYe," \u2014 "),oee=n(OYe,"A",{href:!0});var aia=s(oee);Q4r=r(aia,"NezhaForNextSentencePrediction"),aia.forEach(t),W4r=r(OYe," (Nezha model)"),OYe.forEach(t),U4r=i(bt),m4=n(bt,"LI",{});var VYe=s(m4);v0e=n(VYe,"STRONG",{});var nia=s(v0e);H4r=r(nia,"qdqbert"),nia.forEach(t),J4r=r(VYe," \u2014 "),ree=n(VYe,"A",{href:!0});var sia=s(ree);Y4r=r(sia,"QDQBertForNextSentencePrediction"),sia.forEach(t),Z4r=r(VYe," (QDQBert model)"),VYe.forEach(t),bt.forEach(t),K4r=i(Da),c4=n(Da,"P",{});var XYe=s(c4);eCr=r(XYe,"The model is set in evaluation mode by default using "),F0e=n(XYe,"CODE",{});var lia=s(F0e);oCr=r(lia,"model.eval()"),lia.forEach(t),rCr=r(XYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),T0e=n(XYe,"CODE",{});var iia=s(T0e);tCr=r(iia,"model.train()"),iia.forEach(t),XYe.forEach(t),aCr=i(Da),T(f4.$$.fragment,Da),Da.forEach(t),ei.forEach(t),lio=i(c),hm=n(c,"H2",{class:!0});var $mo=s(hm);g4=n($mo,"A",{id:!0,class:!0,href:!0});var dia=s(g4);M0e=n(dia,"SPAN",{});var mia=s(M0e);T(jS.$$.fragment,mia),mia.forEach(t),dia.forEach(t),nCr=i($mo),E0e=n($mo,"SPAN",{});var cia=s(E0e);sCr=r(cia,"AutoModelForTokenClassification"),cia.forEach(t),$mo.forEach(t),iio=i(c),Ho=n(c,"DIV",{class:!0});var oi=s(Ho);T(DS.$$.fragment,oi),lCr=i(oi),um=n(oi,"P",{});var $fe=s(um);iCr=r($fe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),tee=n($fe,"A",{href:!0});var fia=s(tee);dCr=r(fia,"from_pretrained()"),fia.forEach(t),mCr=r($fe," class method or the "),aee=n($fe,"A",{href:!0});var gia=s(aee);cCr=r(gia,"from_config()"),gia.forEach(t),fCr=r($fe,` class
method.`),$fe.forEach(t),gCr=i(oi),GS=n(oi,"P",{});var kmo=s(GS);hCr=r(kmo,"This class cannot be instantiated directly using "),C0e=n(kmo,"CODE",{});var hia=s(C0e);uCr=r(hia,"__init__()"),hia.forEach(t),pCr=r(kmo," (throws an error)."),kmo.forEach(t),_Cr=i(oi),Bt=n(oi,"DIV",{class:!0});var Cx=s(Bt);T(OS.$$.fragment,Cx),bCr=i(Cx),w0e=n(Cx,"P",{});var uia=s(w0e);vCr=r(uia,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),uia.forEach(t),FCr=i(Cx),pm=n(Cx,"P",{});var kfe=s(pm);TCr=r(kfe,`Note:
Loading a model from its configuration file does `),A0e=n(kfe,"STRONG",{});var pia=s(A0e);MCr=r(pia,"not"),pia.forEach(t),ECr=r(kfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),nee=n(kfe,"A",{href:!0});var _ia=s(nee);CCr=r(_ia,"from_pretrained()"),_ia.forEach(t),wCr=r(kfe," to load the model weights."),kfe.forEach(t),ACr=i(Cx),T(h4.$$.fragment,Cx),Cx.forEach(t),LCr=i(oi),go=n(oi,"DIV",{class:!0});var Ga=s(go);T(VS.$$.fragment,Ga),yCr=i(Ga),L0e=n(Ga,"P",{});var bia=s(L0e);xCr=r(bia,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),bia.forEach(t),$Cr=i(Ga),Tn=n(Ga,"P",{});var wx=s(Tn);kCr=r(wx,"The model class to instantiate is selected based on the "),y0e=n(wx,"CODE",{});var via=s(y0e);SCr=r(via,"model_type"),via.forEach(t),RCr=r(wx,` property of the config object (either
passed as an argument or loaded from `),x0e=n(wx,"CODE",{});var Fia=s(x0e);PCr=r(Fia,"pretrained_model_name_or_path"),Fia.forEach(t),BCr=r(wx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$0e=n(wx,"CODE",{});var Tia=s($0e);ICr=r(Tia,"pretrained_model_name_or_path"),Tia.forEach(t),NCr=r(wx,":"),wx.forEach(t),qCr=i(Ga),U=n(Ga,"UL",{});var J=s(U);u4=n(J,"LI",{});var zYe=s(u4);k0e=n(zYe,"STRONG",{});var Mia=s(k0e);jCr=r(Mia,"albert"),Mia.forEach(t),DCr=r(zYe," \u2014 "),see=n(zYe,"A",{href:!0});var Eia=s(see);GCr=r(Eia,"AlbertForTokenClassification"),Eia.forEach(t),OCr=r(zYe," (ALBERT model)"),zYe.forEach(t),VCr=i(J),p4=n(J,"LI",{});var QYe=s(p4);S0e=n(QYe,"STRONG",{});var Cia=s(S0e);XCr=r(Cia,"bert"),Cia.forEach(t),zCr=r(QYe," \u2014 "),lee=n(QYe,"A",{href:!0});var wia=s(lee);QCr=r(wia,"BertForTokenClassification"),wia.forEach(t),WCr=r(QYe," (BERT model)"),QYe.forEach(t),UCr=i(J),_4=n(J,"LI",{});var WYe=s(_4);R0e=n(WYe,"STRONG",{});var Aia=s(R0e);HCr=r(Aia,"big_bird"),Aia.forEach(t),JCr=r(WYe," \u2014 "),iee=n(WYe,"A",{href:!0});var Lia=s(iee);YCr=r(Lia,"BigBirdForTokenClassification"),Lia.forEach(t),ZCr=r(WYe," (BigBird model)"),WYe.forEach(t),KCr=i(J),b4=n(J,"LI",{});var UYe=s(b4);P0e=n(UYe,"STRONG",{});var yia=s(P0e);e3r=r(yia,"bloom"),yia.forEach(t),o3r=r(UYe," \u2014 "),dee=n(UYe,"A",{href:!0});var xia=s(dee);r3r=r(xia,"BloomForTokenClassification"),xia.forEach(t),t3r=r(UYe," (BLOOM model)"),UYe.forEach(t),a3r=i(J),v4=n(J,"LI",{});var HYe=s(v4);B0e=n(HYe,"STRONG",{});var $ia=s(B0e);n3r=r($ia,"camembert"),$ia.forEach(t),s3r=r(HYe," \u2014 "),mee=n(HYe,"A",{href:!0});var kia=s(mee);l3r=r(kia,"CamembertForTokenClassification"),kia.forEach(t),i3r=r(HYe," (CamemBERT model)"),HYe.forEach(t),d3r=i(J),F4=n(J,"LI",{});var JYe=s(F4);I0e=n(JYe,"STRONG",{});var Sia=s(I0e);m3r=r(Sia,"canine"),Sia.forEach(t),c3r=r(JYe," \u2014 "),cee=n(JYe,"A",{href:!0});var Ria=s(cee);f3r=r(Ria,"CanineForTokenClassification"),Ria.forEach(t),g3r=r(JYe," (CANINE model)"),JYe.forEach(t),h3r=i(J),T4=n(J,"LI",{});var YYe=s(T4);N0e=n(YYe,"STRONG",{});var Pia=s(N0e);u3r=r(Pia,"convbert"),Pia.forEach(t),p3r=r(YYe," \u2014 "),fee=n(YYe,"A",{href:!0});var Bia=s(fee);_3r=r(Bia,"ConvBertForTokenClassification"),Bia.forEach(t),b3r=r(YYe," (ConvBERT model)"),YYe.forEach(t),v3r=i(J),M4=n(J,"LI",{});var ZYe=s(M4);q0e=n(ZYe,"STRONG",{});var Iia=s(q0e);F3r=r(Iia,"data2vec-text"),Iia.forEach(t),T3r=r(ZYe," \u2014 "),gee=n(ZYe,"A",{href:!0});var Nia=s(gee);M3r=r(Nia,"Data2VecTextForTokenClassification"),Nia.forEach(t),E3r=r(ZYe," (Data2VecText model)"),ZYe.forEach(t),C3r=i(J),E4=n(J,"LI",{});var KYe=s(E4);j0e=n(KYe,"STRONG",{});var qia=s(j0e);w3r=r(qia,"deberta"),qia.forEach(t),A3r=r(KYe," \u2014 "),hee=n(KYe,"A",{href:!0});var jia=s(hee);L3r=r(jia,"DebertaForTokenClassification"),jia.forEach(t),y3r=r(KYe," (DeBERTa model)"),KYe.forEach(t),x3r=i(J),C4=n(J,"LI",{});var eZe=s(C4);D0e=n(eZe,"STRONG",{});var Dia=s(D0e);$3r=r(Dia,"deberta-v2"),Dia.forEach(t),k3r=r(eZe," \u2014 "),uee=n(eZe,"A",{href:!0});var Gia=s(uee);S3r=r(Gia,"DebertaV2ForTokenClassification"),Gia.forEach(t),R3r=r(eZe," (DeBERTa-v2 model)"),eZe.forEach(t),P3r=i(J),w4=n(J,"LI",{});var oZe=s(w4);G0e=n(oZe,"STRONG",{});var Oia=s(G0e);B3r=r(Oia,"distilbert"),Oia.forEach(t),I3r=r(oZe," \u2014 "),pee=n(oZe,"A",{href:!0});var Via=s(pee);N3r=r(Via,"DistilBertForTokenClassification"),Via.forEach(t),q3r=r(oZe," (DistilBERT model)"),oZe.forEach(t),j3r=i(J),A4=n(J,"LI",{});var rZe=s(A4);O0e=n(rZe,"STRONG",{});var Xia=s(O0e);D3r=r(Xia,"electra"),Xia.forEach(t),G3r=r(rZe," \u2014 "),_ee=n(rZe,"A",{href:!0});var zia=s(_ee);O3r=r(zia,"ElectraForTokenClassification"),zia.forEach(t),V3r=r(rZe," (ELECTRA model)"),rZe.forEach(t),X3r=i(J),L4=n(J,"LI",{});var tZe=s(L4);V0e=n(tZe,"STRONG",{});var Qia=s(V0e);z3r=r(Qia,"ernie"),Qia.forEach(t),Q3r=r(tZe," \u2014 "),bee=n(tZe,"A",{href:!0});var Wia=s(bee);W3r=r(Wia,"ErnieForTokenClassification"),Wia.forEach(t),U3r=r(tZe," (ERNIE model)"),tZe.forEach(t),H3r=i(J),y4=n(J,"LI",{});var aZe=s(y4);X0e=n(aZe,"STRONG",{});var Uia=s(X0e);J3r=r(Uia,"esm"),Uia.forEach(t),Y3r=r(aZe," \u2014 "),vee=n(aZe,"A",{href:!0});var Hia=s(vee);Z3r=r(Hia,"EsmForTokenClassification"),Hia.forEach(t),K3r=r(aZe," (ESM model)"),aZe.forEach(t),e5r=i(J),x4=n(J,"LI",{});var nZe=s(x4);z0e=n(nZe,"STRONG",{});var Jia=s(z0e);o5r=r(Jia,"flaubert"),Jia.forEach(t),r5r=r(nZe," \u2014 "),Fee=n(nZe,"A",{href:!0});var Yia=s(Fee);t5r=r(Yia,"FlaubertForTokenClassification"),Yia.forEach(t),a5r=r(nZe," (FlauBERT model)"),nZe.forEach(t),n5r=i(J),$4=n(J,"LI",{});var sZe=s($4);Q0e=n(sZe,"STRONG",{});var Zia=s(Q0e);s5r=r(Zia,"fnet"),Zia.forEach(t),l5r=r(sZe," \u2014 "),Tee=n(sZe,"A",{href:!0});var Kia=s(Tee);i5r=r(Kia,"FNetForTokenClassification"),Kia.forEach(t),d5r=r(sZe," (FNet model)"),sZe.forEach(t),m5r=i(J),k4=n(J,"LI",{});var lZe=s(k4);W0e=n(lZe,"STRONG",{});var eda=s(W0e);c5r=r(eda,"funnel"),eda.forEach(t),f5r=r(lZe," \u2014 "),Mee=n(lZe,"A",{href:!0});var oda=s(Mee);g5r=r(oda,"FunnelForTokenClassification"),oda.forEach(t),h5r=r(lZe," (Funnel Transformer model)"),lZe.forEach(t),u5r=i(J),S4=n(J,"LI",{});var iZe=s(S4);U0e=n(iZe,"STRONG",{});var rda=s(U0e);p5r=r(rda,"gpt2"),rda.forEach(t),_5r=r(iZe," \u2014 "),Eee=n(iZe,"A",{href:!0});var tda=s(Eee);b5r=r(tda,"GPT2ForTokenClassification"),tda.forEach(t),v5r=r(iZe," (OpenAI GPT-2 model)"),iZe.forEach(t),F5r=i(J),R4=n(J,"LI",{});var dZe=s(R4);H0e=n(dZe,"STRONG",{});var ada=s(H0e);T5r=r(ada,"ibert"),ada.forEach(t),M5r=r(dZe," \u2014 "),Cee=n(dZe,"A",{href:!0});var nda=s(Cee);E5r=r(nda,"IBertForTokenClassification"),nda.forEach(t),C5r=r(dZe," (I-BERT model)"),dZe.forEach(t),w5r=i(J),P4=n(J,"LI",{});var mZe=s(P4);J0e=n(mZe,"STRONG",{});var sda=s(J0e);A5r=r(sda,"layoutlm"),sda.forEach(t),L5r=r(mZe," \u2014 "),wee=n(mZe,"A",{href:!0});var lda=s(wee);y5r=r(lda,"LayoutLMForTokenClassification"),lda.forEach(t),x5r=r(mZe," (LayoutLM model)"),mZe.forEach(t),$5r=i(J),B4=n(J,"LI",{});var cZe=s(B4);Y0e=n(cZe,"STRONG",{});var ida=s(Y0e);k5r=r(ida,"layoutlmv2"),ida.forEach(t),S5r=r(cZe," \u2014 "),Aee=n(cZe,"A",{href:!0});var dda=s(Aee);R5r=r(dda,"LayoutLMv2ForTokenClassification"),dda.forEach(t),P5r=r(cZe," (LayoutLMv2 model)"),cZe.forEach(t),B5r=i(J),I4=n(J,"LI",{});var fZe=s(I4);Z0e=n(fZe,"STRONG",{});var mda=s(Z0e);I5r=r(mda,"layoutlmv3"),mda.forEach(t),N5r=r(fZe," \u2014 "),Lee=n(fZe,"A",{href:!0});var cda=s(Lee);q5r=r(cda,"LayoutLMv3ForTokenClassification"),cda.forEach(t),j5r=r(fZe," (LayoutLMv3 model)"),fZe.forEach(t),D5r=i(J),N4=n(J,"LI",{});var gZe=s(N4);K0e=n(gZe,"STRONG",{});var fda=s(K0e);G5r=r(fda,"lilt"),fda.forEach(t),O5r=r(gZe," \u2014 "),yee=n(gZe,"A",{href:!0});var gda=s(yee);V5r=r(gda,"LiltForTokenClassification"),gda.forEach(t),X5r=r(gZe," (LiLT model)"),gZe.forEach(t),z5r=i(J),q4=n(J,"LI",{});var hZe=s(q4);ewe=n(hZe,"STRONG",{});var hda=s(ewe);Q5r=r(hda,"longformer"),hda.forEach(t),W5r=r(hZe," \u2014 "),xee=n(hZe,"A",{href:!0});var uda=s(xee);U5r=r(uda,"LongformerForTokenClassification"),uda.forEach(t),H5r=r(hZe," (Longformer model)"),hZe.forEach(t),J5r=i(J),j4=n(J,"LI",{});var uZe=s(j4);owe=n(uZe,"STRONG",{});var pda=s(owe);Y5r=r(pda,"luke"),pda.forEach(t),Z5r=r(uZe," \u2014 "),$ee=n(uZe,"A",{href:!0});var _da=s($ee);K5r=r(_da,"LukeForTokenClassification"),_da.forEach(t),e0r=r(uZe," (LUKE model)"),uZe.forEach(t),o0r=i(J),D4=n(J,"LI",{});var pZe=s(D4);rwe=n(pZe,"STRONG",{});var bda=s(rwe);r0r=r(bda,"markuplm"),bda.forEach(t),t0r=r(pZe," \u2014 "),kee=n(pZe,"A",{href:!0});var vda=s(kee);a0r=r(vda,"MarkupLMForTokenClassification"),vda.forEach(t),n0r=r(pZe," (MarkupLM model)"),pZe.forEach(t),s0r=i(J),G4=n(J,"LI",{});var _Ze=s(G4);twe=n(_Ze,"STRONG",{});var Fda=s(twe);l0r=r(Fda,"megatron-bert"),Fda.forEach(t),i0r=r(_Ze," \u2014 "),See=n(_Ze,"A",{href:!0});var Tda=s(See);d0r=r(Tda,"MegatronBertForTokenClassification"),Tda.forEach(t),m0r=r(_Ze," (Megatron-BERT model)"),_Ze.forEach(t),c0r=i(J),O4=n(J,"LI",{});var bZe=s(O4);awe=n(bZe,"STRONG",{});var Mda=s(awe);f0r=r(Mda,"mobilebert"),Mda.forEach(t),g0r=r(bZe," \u2014 "),Ree=n(bZe,"A",{href:!0});var Eda=s(Ree);h0r=r(Eda,"MobileBertForTokenClassification"),Eda.forEach(t),u0r=r(bZe," (MobileBERT model)"),bZe.forEach(t),p0r=i(J),V4=n(J,"LI",{});var vZe=s(V4);nwe=n(vZe,"STRONG",{});var Cda=s(nwe);_0r=r(Cda,"mpnet"),Cda.forEach(t),b0r=r(vZe," \u2014 "),Pee=n(vZe,"A",{href:!0});var wda=s(Pee);v0r=r(wda,"MPNetForTokenClassification"),wda.forEach(t),F0r=r(vZe," (MPNet model)"),vZe.forEach(t),T0r=i(J),X4=n(J,"LI",{});var FZe=s(X4);swe=n(FZe,"STRONG",{});var Ada=s(swe);M0r=r(Ada,"nezha"),Ada.forEach(t),E0r=r(FZe," \u2014 "),Bee=n(FZe,"A",{href:!0});var Lda=s(Bee);C0r=r(Lda,"NezhaForTokenClassification"),Lda.forEach(t),w0r=r(FZe," (Nezha model)"),FZe.forEach(t),A0r=i(J),z4=n(J,"LI",{});var TZe=s(z4);lwe=n(TZe,"STRONG",{});var yda=s(lwe);L0r=r(yda,"nystromformer"),yda.forEach(t),y0r=r(TZe," \u2014 "),Iee=n(TZe,"A",{href:!0});var xda=s(Iee);x0r=r(xda,"NystromformerForTokenClassification"),xda.forEach(t),$0r=r(TZe," (Nystr\xF6mformer model)"),TZe.forEach(t),k0r=i(J),Q4=n(J,"LI",{});var MZe=s(Q4);iwe=n(MZe,"STRONG",{});var $da=s(iwe);S0r=r($da,"qdqbert"),$da.forEach(t),R0r=r(MZe," \u2014 "),Nee=n(MZe,"A",{href:!0});var kda=s(Nee);P0r=r(kda,"QDQBertForTokenClassification"),kda.forEach(t),B0r=r(MZe," (QDQBert model)"),MZe.forEach(t),I0r=i(J),W4=n(J,"LI",{});var EZe=s(W4);dwe=n(EZe,"STRONG",{});var Sda=s(dwe);N0r=r(Sda,"rembert"),Sda.forEach(t),q0r=r(EZe," \u2014 "),qee=n(EZe,"A",{href:!0});var Rda=s(qee);j0r=r(Rda,"RemBertForTokenClassification"),Rda.forEach(t),D0r=r(EZe," (RemBERT model)"),EZe.forEach(t),G0r=i(J),U4=n(J,"LI",{});var CZe=s(U4);mwe=n(CZe,"STRONG",{});var Pda=s(mwe);O0r=r(Pda,"roberta"),Pda.forEach(t),V0r=r(CZe," \u2014 "),jee=n(CZe,"A",{href:!0});var Bda=s(jee);X0r=r(Bda,"RobertaForTokenClassification"),Bda.forEach(t),z0r=r(CZe," (RoBERTa model)"),CZe.forEach(t),Q0r=i(J),H4=n(J,"LI",{});var wZe=s(H4);cwe=n(wZe,"STRONG",{});var Ida=s(cwe);W0r=r(Ida,"roc_bert"),Ida.forEach(t),U0r=r(wZe," \u2014 "),Dee=n(wZe,"A",{href:!0});var Nda=s(Dee);H0r=r(Nda,"RoCBertForTokenClassification"),Nda.forEach(t),J0r=r(wZe," (RoCBert model)"),wZe.forEach(t),Y0r=i(J),J4=n(J,"LI",{});var AZe=s(J4);fwe=n(AZe,"STRONG",{});var qda=s(fwe);Z0r=r(qda,"roformer"),qda.forEach(t),K0r=r(AZe," \u2014 "),Gee=n(AZe,"A",{href:!0});var jda=s(Gee);ewr=r(jda,"RoFormerForTokenClassification"),jda.forEach(t),owr=r(AZe," (RoFormer model)"),AZe.forEach(t),rwr=i(J),Y4=n(J,"LI",{});var LZe=s(Y4);gwe=n(LZe,"STRONG",{});var Dda=s(gwe);twr=r(Dda,"squeezebert"),Dda.forEach(t),awr=r(LZe," \u2014 "),Oee=n(LZe,"A",{href:!0});var Gda=s(Oee);nwr=r(Gda,"SqueezeBertForTokenClassification"),Gda.forEach(t),swr=r(LZe," (SqueezeBERT model)"),LZe.forEach(t),lwr=i(J),Z4=n(J,"LI",{});var yZe=s(Z4);hwe=n(yZe,"STRONG",{});var Oda=s(hwe);iwr=r(Oda,"xlm"),Oda.forEach(t),dwr=r(yZe," \u2014 "),Vee=n(yZe,"A",{href:!0});var Vda=s(Vee);mwr=r(Vda,"XLMForTokenClassification"),Vda.forEach(t),cwr=r(yZe," (XLM model)"),yZe.forEach(t),fwr=i(J),K4=n(J,"LI",{});var xZe=s(K4);uwe=n(xZe,"STRONG",{});var Xda=s(uwe);gwr=r(Xda,"xlm-roberta"),Xda.forEach(t),hwr=r(xZe," \u2014 "),Xee=n(xZe,"A",{href:!0});var zda=s(Xee);uwr=r(zda,"XLMRobertaForTokenClassification"),zda.forEach(t),pwr=r(xZe," (XLM-RoBERTa model)"),xZe.forEach(t),_wr=i(J),eC=n(J,"LI",{});var $Ze=s(eC);pwe=n($Ze,"STRONG",{});var Qda=s(pwe);bwr=r(Qda,"xlm-roberta-xl"),Qda.forEach(t),vwr=r($Ze," \u2014 "),zee=n($Ze,"A",{href:!0});var Wda=s(zee);Fwr=r(Wda,"XLMRobertaXLForTokenClassification"),Wda.forEach(t),Twr=r($Ze," (XLM-RoBERTa-XL model)"),$Ze.forEach(t),Mwr=i(J),oC=n(J,"LI",{});var kZe=s(oC);_we=n(kZe,"STRONG",{});var Uda=s(_we);Ewr=r(Uda,"xlnet"),Uda.forEach(t),Cwr=r(kZe," \u2014 "),Qee=n(kZe,"A",{href:!0});var Hda=s(Qee);wwr=r(Hda,"XLNetForTokenClassification"),Hda.forEach(t),Awr=r(kZe," (XLNet model)"),kZe.forEach(t),Lwr=i(J),rC=n(J,"LI",{});var SZe=s(rC);bwe=n(SZe,"STRONG",{});var Jda=s(bwe);ywr=r(Jda,"yoso"),Jda.forEach(t),xwr=r(SZe," \u2014 "),Wee=n(SZe,"A",{href:!0});var Yda=s(Wee);$wr=r(Yda,"YosoForTokenClassification"),Yda.forEach(t),kwr=r(SZe," (YOSO model)"),SZe.forEach(t),J.forEach(t),Swr=i(Ga),tC=n(Ga,"P",{});var RZe=s(tC);Rwr=r(RZe,"The model is set in evaluation mode by default using "),vwe=n(RZe,"CODE",{});var Zda=s(vwe);Pwr=r(Zda,"model.eval()"),Zda.forEach(t),Bwr=r(RZe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Fwe=n(RZe,"CODE",{});var Kda=s(Fwe);Iwr=r(Kda,"model.train()"),Kda.forEach(t),RZe.forEach(t),Nwr=i(Ga),T(aC.$$.fragment,Ga),Ga.forEach(t),oi.forEach(t),dio=i(c),_m=n(c,"H2",{class:!0});var Smo=s(_m);nC=n(Smo,"A",{id:!0,class:!0,href:!0});var ema=s(nC);Twe=n(ema,"SPAN",{});var oma=s(Twe);T(XS.$$.fragment,oma),oma.forEach(t),ema.forEach(t),qwr=i(Smo),Mwe=n(Smo,"SPAN",{});var rma=s(Mwe);jwr=r(rma,"AutoModelForQuestionAnswering"),rma.forEach(t),Smo.forEach(t),mio=i(c),Jo=n(c,"DIV",{class:!0});var ri=s(Jo);T(zS.$$.fragment,ri),Dwr=i(ri),bm=n(ri,"P",{});var Sfe=s(bm);Gwr=r(Sfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Uee=n(Sfe,"A",{href:!0});var tma=s(Uee);Owr=r(tma,"from_pretrained()"),tma.forEach(t),Vwr=r(Sfe," class method or the "),Hee=n(Sfe,"A",{href:!0});var ama=s(Hee);Xwr=r(ama,"from_config()"),ama.forEach(t),zwr=r(Sfe,` class
method.`),Sfe.forEach(t),Qwr=i(ri),QS=n(ri,"P",{});var Rmo=s(QS);Wwr=r(Rmo,"This class cannot be instantiated directly using "),Ewe=n(Rmo,"CODE",{});var nma=s(Ewe);Uwr=r(nma,"__init__()"),nma.forEach(t),Hwr=r(Rmo," (throws an error)."),Rmo.forEach(t),Jwr=i(ri),It=n(ri,"DIV",{class:!0});var Ax=s(It);T(WS.$$.fragment,Ax),Ywr=i(Ax),Cwe=n(Ax,"P",{});var sma=s(Cwe);Zwr=r(sma,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),sma.forEach(t),Kwr=i(Ax),vm=n(Ax,"P",{});var Rfe=s(vm);eAr=r(Rfe,`Note:
Loading a model from its configuration file does `),wwe=n(Rfe,"STRONG",{});var lma=s(wwe);oAr=r(lma,"not"),lma.forEach(t),rAr=r(Rfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Jee=n(Rfe,"A",{href:!0});var ima=s(Jee);tAr=r(ima,"from_pretrained()"),ima.forEach(t),aAr=r(Rfe," to load the model weights."),Rfe.forEach(t),nAr=i(Ax),T(sC.$$.fragment,Ax),Ax.forEach(t),sAr=i(ri),ho=n(ri,"DIV",{class:!0});var Oa=s(ho);T(US.$$.fragment,Oa),lAr=i(Oa),Awe=n(Oa,"P",{});var dma=s(Awe);iAr=r(dma,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),dma.forEach(t),dAr=i(Oa),Mn=n(Oa,"P",{});var Lx=s(Mn);mAr=r(Lx,"The model class to instantiate is selected based on the "),Lwe=n(Lx,"CODE",{});var mma=s(Lwe);cAr=r(mma,"model_type"),mma.forEach(t),fAr=r(Lx,` property of the config object (either
passed as an argument or loaded from `),ywe=n(Lx,"CODE",{});var cma=s(ywe);gAr=r(cma,"pretrained_model_name_or_path"),cma.forEach(t),hAr=r(Lx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xwe=n(Lx,"CODE",{});var fma=s(xwe);uAr=r(fma,"pretrained_model_name_or_path"),fma.forEach(t),pAr=r(Lx,":"),Lx.forEach(t),_Ar=i(Oa),O=n(Oa,"UL",{});var X=s(O);lC=n(X,"LI",{});var PZe=s(lC);$we=n(PZe,"STRONG",{});var gma=s($we);bAr=r(gma,"albert"),gma.forEach(t),vAr=r(PZe," \u2014 "),Yee=n(PZe,"A",{href:!0});var hma=s(Yee);FAr=r(hma,"AlbertForQuestionAnswering"),hma.forEach(t),TAr=r(PZe," (ALBERT model)"),PZe.forEach(t),MAr=i(X),iC=n(X,"LI",{});var BZe=s(iC);kwe=n(BZe,"STRONG",{});var uma=s(kwe);EAr=r(uma,"bart"),uma.forEach(t),CAr=r(BZe," \u2014 "),Zee=n(BZe,"A",{href:!0});var pma=s(Zee);wAr=r(pma,"BartForQuestionAnswering"),pma.forEach(t),AAr=r(BZe," (BART model)"),BZe.forEach(t),LAr=i(X),dC=n(X,"LI",{});var IZe=s(dC);Swe=n(IZe,"STRONG",{});var _ma=s(Swe);yAr=r(_ma,"bert"),_ma.forEach(t),xAr=r(IZe," \u2014 "),Kee=n(IZe,"A",{href:!0});var bma=s(Kee);$Ar=r(bma,"BertForQuestionAnswering"),bma.forEach(t),kAr=r(IZe," (BERT model)"),IZe.forEach(t),SAr=i(X),mC=n(X,"LI",{});var NZe=s(mC);Rwe=n(NZe,"STRONG",{});var vma=s(Rwe);RAr=r(vma,"big_bird"),vma.forEach(t),PAr=r(NZe," \u2014 "),eoe=n(NZe,"A",{href:!0});var Fma=s(eoe);BAr=r(Fma,"BigBirdForQuestionAnswering"),Fma.forEach(t),IAr=r(NZe," (BigBird model)"),NZe.forEach(t),NAr=i(X),cC=n(X,"LI",{});var qZe=s(cC);Pwe=n(qZe,"STRONG",{});var Tma=s(Pwe);qAr=r(Tma,"bigbird_pegasus"),Tma.forEach(t),jAr=r(qZe," \u2014 "),ooe=n(qZe,"A",{href:!0});var Mma=s(ooe);DAr=r(Mma,"BigBirdPegasusForQuestionAnswering"),Mma.forEach(t),GAr=r(qZe," (BigBird-Pegasus model)"),qZe.forEach(t),OAr=i(X),fC=n(X,"LI",{});var jZe=s(fC);Bwe=n(jZe,"STRONG",{});var Ema=s(Bwe);VAr=r(Ema,"bloom"),Ema.forEach(t),XAr=r(jZe," \u2014 "),roe=n(jZe,"A",{href:!0});var Cma=s(roe);zAr=r(Cma,"BloomForQuestionAnswering"),Cma.forEach(t),QAr=r(jZe," (BLOOM model)"),jZe.forEach(t),WAr=i(X),gC=n(X,"LI",{});var DZe=s(gC);Iwe=n(DZe,"STRONG",{});var wma=s(Iwe);UAr=r(wma,"camembert"),wma.forEach(t),HAr=r(DZe," \u2014 "),toe=n(DZe,"A",{href:!0});var Ama=s(toe);JAr=r(Ama,"CamembertForQuestionAnswering"),Ama.forEach(t),YAr=r(DZe," (CamemBERT model)"),DZe.forEach(t),ZAr=i(X),hC=n(X,"LI",{});var GZe=s(hC);Nwe=n(GZe,"STRONG",{});var Lma=s(Nwe);KAr=r(Lma,"canine"),Lma.forEach(t),e6r=r(GZe," \u2014 "),aoe=n(GZe,"A",{href:!0});var yma=s(aoe);o6r=r(yma,"CanineForQuestionAnswering"),yma.forEach(t),r6r=r(GZe," (CANINE model)"),GZe.forEach(t),t6r=i(X),uC=n(X,"LI",{});var OZe=s(uC);qwe=n(OZe,"STRONG",{});var xma=s(qwe);a6r=r(xma,"convbert"),xma.forEach(t),n6r=r(OZe," \u2014 "),noe=n(OZe,"A",{href:!0});var $ma=s(noe);s6r=r($ma,"ConvBertForQuestionAnswering"),$ma.forEach(t),l6r=r(OZe," (ConvBERT model)"),OZe.forEach(t),i6r=i(X),pC=n(X,"LI",{});var VZe=s(pC);jwe=n(VZe,"STRONG",{});var kma=s(jwe);d6r=r(kma,"data2vec-text"),kma.forEach(t),m6r=r(VZe," \u2014 "),soe=n(VZe,"A",{href:!0});var Sma=s(soe);c6r=r(Sma,"Data2VecTextForQuestionAnswering"),Sma.forEach(t),f6r=r(VZe," (Data2VecText model)"),VZe.forEach(t),g6r=i(X),_C=n(X,"LI",{});var XZe=s(_C);Dwe=n(XZe,"STRONG",{});var Rma=s(Dwe);h6r=r(Rma,"deberta"),Rma.forEach(t),u6r=r(XZe," \u2014 "),loe=n(XZe,"A",{href:!0});var Pma=s(loe);p6r=r(Pma,"DebertaForQuestionAnswering"),Pma.forEach(t),_6r=r(XZe," (DeBERTa model)"),XZe.forEach(t),b6r=i(X),bC=n(X,"LI",{});var zZe=s(bC);Gwe=n(zZe,"STRONG",{});var Bma=s(Gwe);v6r=r(Bma,"deberta-v2"),Bma.forEach(t),F6r=r(zZe," \u2014 "),ioe=n(zZe,"A",{href:!0});var Ima=s(ioe);T6r=r(Ima,"DebertaV2ForQuestionAnswering"),Ima.forEach(t),M6r=r(zZe," (DeBERTa-v2 model)"),zZe.forEach(t),E6r=i(X),vC=n(X,"LI",{});var QZe=s(vC);Owe=n(QZe,"STRONG",{});var Nma=s(Owe);C6r=r(Nma,"distilbert"),Nma.forEach(t),w6r=r(QZe," \u2014 "),doe=n(QZe,"A",{href:!0});var qma=s(doe);A6r=r(qma,"DistilBertForQuestionAnswering"),qma.forEach(t),L6r=r(QZe," (DistilBERT model)"),QZe.forEach(t),y6r=i(X),FC=n(X,"LI",{});var WZe=s(FC);Vwe=n(WZe,"STRONG",{});var jma=s(Vwe);x6r=r(jma,"electra"),jma.forEach(t),$6r=r(WZe," \u2014 "),moe=n(WZe,"A",{href:!0});var Dma=s(moe);k6r=r(Dma,"ElectraForQuestionAnswering"),Dma.forEach(t),S6r=r(WZe," (ELECTRA model)"),WZe.forEach(t),R6r=i(X),TC=n(X,"LI",{});var UZe=s(TC);Xwe=n(UZe,"STRONG",{});var Gma=s(Xwe);P6r=r(Gma,"ernie"),Gma.forEach(t),B6r=r(UZe," \u2014 "),coe=n(UZe,"A",{href:!0});var Oma=s(coe);I6r=r(Oma,"ErnieForQuestionAnswering"),Oma.forEach(t),N6r=r(UZe," (ERNIE model)"),UZe.forEach(t),q6r=i(X),MC=n(X,"LI",{});var HZe=s(MC);zwe=n(HZe,"STRONG",{});var Vma=s(zwe);j6r=r(Vma,"flaubert"),Vma.forEach(t),D6r=r(HZe," \u2014 "),foe=n(HZe,"A",{href:!0});var Xma=s(foe);G6r=r(Xma,"FlaubertForQuestionAnsweringSimple"),Xma.forEach(t),O6r=r(HZe," (FlauBERT model)"),HZe.forEach(t),V6r=i(X),EC=n(X,"LI",{});var JZe=s(EC);Qwe=n(JZe,"STRONG",{});var zma=s(Qwe);X6r=r(zma,"fnet"),zma.forEach(t),z6r=r(JZe," \u2014 "),goe=n(JZe,"A",{href:!0});var Qma=s(goe);Q6r=r(Qma,"FNetForQuestionAnswering"),Qma.forEach(t),W6r=r(JZe," (FNet model)"),JZe.forEach(t),U6r=i(X),CC=n(X,"LI",{});var YZe=s(CC);Wwe=n(YZe,"STRONG",{});var Wma=s(Wwe);H6r=r(Wma,"funnel"),Wma.forEach(t),J6r=r(YZe," \u2014 "),hoe=n(YZe,"A",{href:!0});var Uma=s(hoe);Y6r=r(Uma,"FunnelForQuestionAnswering"),Uma.forEach(t),Z6r=r(YZe," (Funnel Transformer model)"),YZe.forEach(t),K6r=i(X),wC=n(X,"LI",{});var ZZe=s(wC);Uwe=n(ZZe,"STRONG",{});var Hma=s(Uwe);e7r=r(Hma,"gptj"),Hma.forEach(t),o7r=r(ZZe," \u2014 "),uoe=n(ZZe,"A",{href:!0});var Jma=s(uoe);r7r=r(Jma,"GPTJForQuestionAnswering"),Jma.forEach(t),t7r=r(ZZe," (GPT-J model)"),ZZe.forEach(t),a7r=i(X),AC=n(X,"LI",{});var KZe=s(AC);Hwe=n(KZe,"STRONG",{});var Yma=s(Hwe);n7r=r(Yma,"ibert"),Yma.forEach(t),s7r=r(KZe," \u2014 "),poe=n(KZe,"A",{href:!0});var Zma=s(poe);l7r=r(Zma,"IBertForQuestionAnswering"),Zma.forEach(t),i7r=r(KZe," (I-BERT model)"),KZe.forEach(t),d7r=i(X),LC=n(X,"LI",{});var eKe=s(LC);Jwe=n(eKe,"STRONG",{});var Kma=s(Jwe);m7r=r(Kma,"layoutlmv2"),Kma.forEach(t),c7r=r(eKe," \u2014 "),_oe=n(eKe,"A",{href:!0});var eca=s(_oe);f7r=r(eca,"LayoutLMv2ForQuestionAnswering"),eca.forEach(t),g7r=r(eKe," (LayoutLMv2 model)"),eKe.forEach(t),h7r=i(X),yC=n(X,"LI",{});var oKe=s(yC);Ywe=n(oKe,"STRONG",{});var oca=s(Ywe);u7r=r(oca,"layoutlmv3"),oca.forEach(t),p7r=r(oKe," \u2014 "),boe=n(oKe,"A",{href:!0});var rca=s(boe);_7r=r(rca,"LayoutLMv3ForQuestionAnswering"),rca.forEach(t),b7r=r(oKe," (LayoutLMv3 model)"),oKe.forEach(t),v7r=i(X),xC=n(X,"LI",{});var rKe=s(xC);Zwe=n(rKe,"STRONG",{});var tca=s(Zwe);F7r=r(tca,"led"),tca.forEach(t),T7r=r(rKe," \u2014 "),voe=n(rKe,"A",{href:!0});var aca=s(voe);M7r=r(aca,"LEDForQuestionAnswering"),aca.forEach(t),E7r=r(rKe," (LED model)"),rKe.forEach(t),C7r=i(X),$C=n(X,"LI",{});var tKe=s($C);Kwe=n(tKe,"STRONG",{});var nca=s(Kwe);w7r=r(nca,"lilt"),nca.forEach(t),A7r=r(tKe," \u2014 "),Foe=n(tKe,"A",{href:!0});var sca=s(Foe);L7r=r(sca,"LiltForQuestionAnswering"),sca.forEach(t),y7r=r(tKe," (LiLT model)"),tKe.forEach(t),x7r=i(X),kC=n(X,"LI",{});var aKe=s(kC);eAe=n(aKe,"STRONG",{});var lca=s(eAe);$7r=r(lca,"longformer"),lca.forEach(t),k7r=r(aKe," \u2014 "),Toe=n(aKe,"A",{href:!0});var ica=s(Toe);S7r=r(ica,"LongformerForQuestionAnswering"),ica.forEach(t),R7r=r(aKe," (Longformer model)"),aKe.forEach(t),P7r=i(X),SC=n(X,"LI",{});var nKe=s(SC);oAe=n(nKe,"STRONG",{});var dca=s(oAe);B7r=r(dca,"luke"),dca.forEach(t),I7r=r(nKe," \u2014 "),Moe=n(nKe,"A",{href:!0});var mca=s(Moe);N7r=r(mca,"LukeForQuestionAnswering"),mca.forEach(t),q7r=r(nKe," (LUKE model)"),nKe.forEach(t),j7r=i(X),RC=n(X,"LI",{});var sKe=s(RC);rAe=n(sKe,"STRONG",{});var cca=s(rAe);D7r=r(cca,"lxmert"),cca.forEach(t),G7r=r(sKe," \u2014 "),Eoe=n(sKe,"A",{href:!0});var fca=s(Eoe);O7r=r(fca,"LxmertForQuestionAnswering"),fca.forEach(t),V7r=r(sKe," (LXMERT model)"),sKe.forEach(t),X7r=i(X),PC=n(X,"LI",{});var lKe=s(PC);tAe=n(lKe,"STRONG",{});var gca=s(tAe);z7r=r(gca,"markuplm"),gca.forEach(t),Q7r=r(lKe," \u2014 "),Coe=n(lKe,"A",{href:!0});var hca=s(Coe);W7r=r(hca,"MarkupLMForQuestionAnswering"),hca.forEach(t),U7r=r(lKe," (MarkupLM model)"),lKe.forEach(t),H7r=i(X),BC=n(X,"LI",{});var iKe=s(BC);aAe=n(iKe,"STRONG",{});var uca=s(aAe);J7r=r(uca,"mbart"),uca.forEach(t),Y7r=r(iKe," \u2014 "),woe=n(iKe,"A",{href:!0});var pca=s(woe);Z7r=r(pca,"MBartForQuestionAnswering"),pca.forEach(t),K7r=r(iKe," (mBART model)"),iKe.forEach(t),e8r=i(X),IC=n(X,"LI",{});var dKe=s(IC);nAe=n(dKe,"STRONG",{});var _ca=s(nAe);o8r=r(_ca,"megatron-bert"),_ca.forEach(t),r8r=r(dKe," \u2014 "),Aoe=n(dKe,"A",{href:!0});var bca=s(Aoe);t8r=r(bca,"MegatronBertForQuestionAnswering"),bca.forEach(t),a8r=r(dKe," (Megatron-BERT model)"),dKe.forEach(t),n8r=i(X),NC=n(X,"LI",{});var mKe=s(NC);sAe=n(mKe,"STRONG",{});var vca=s(sAe);s8r=r(vca,"mobilebert"),vca.forEach(t),l8r=r(mKe," \u2014 "),Loe=n(mKe,"A",{href:!0});var Fca=s(Loe);i8r=r(Fca,"MobileBertForQuestionAnswering"),Fca.forEach(t),d8r=r(mKe," (MobileBERT model)"),mKe.forEach(t),m8r=i(X),qC=n(X,"LI",{});var cKe=s(qC);lAe=n(cKe,"STRONG",{});var Tca=s(lAe);c8r=r(Tca,"mpnet"),Tca.forEach(t),f8r=r(cKe," \u2014 "),yoe=n(cKe,"A",{href:!0});var Mca=s(yoe);g8r=r(Mca,"MPNetForQuestionAnswering"),Mca.forEach(t),h8r=r(cKe," (MPNet model)"),cKe.forEach(t),u8r=i(X),jC=n(X,"LI",{});var fKe=s(jC);iAe=n(fKe,"STRONG",{});var Eca=s(iAe);p8r=r(Eca,"mvp"),Eca.forEach(t),_8r=r(fKe," \u2014 "),xoe=n(fKe,"A",{href:!0});var Cca=s(xoe);b8r=r(Cca,"MvpForQuestionAnswering"),Cca.forEach(t),v8r=r(fKe," (MVP model)"),fKe.forEach(t),F8r=i(X),DC=n(X,"LI",{});var gKe=s(DC);dAe=n(gKe,"STRONG",{});var wca=s(dAe);T8r=r(wca,"nezha"),wca.forEach(t),M8r=r(gKe," \u2014 "),$oe=n(gKe,"A",{href:!0});var Aca=s($oe);E8r=r(Aca,"NezhaForQuestionAnswering"),Aca.forEach(t),C8r=r(gKe," (Nezha model)"),gKe.forEach(t),w8r=i(X),GC=n(X,"LI",{});var hKe=s(GC);mAe=n(hKe,"STRONG",{});var Lca=s(mAe);A8r=r(Lca,"nystromformer"),Lca.forEach(t),L8r=r(hKe," \u2014 "),koe=n(hKe,"A",{href:!0});var yca=s(koe);y8r=r(yca,"NystromformerForQuestionAnswering"),yca.forEach(t),x8r=r(hKe," (Nystr\xF6mformer model)"),hKe.forEach(t),$8r=i(X),OC=n(X,"LI",{});var uKe=s(OC);cAe=n(uKe,"STRONG",{});var xca=s(cAe);k8r=r(xca,"opt"),xca.forEach(t),S8r=r(uKe," \u2014 "),Soe=n(uKe,"A",{href:!0});var $ca=s(Soe);R8r=r($ca,"OPTForQuestionAnswering"),$ca.forEach(t),P8r=r(uKe," (OPT model)"),uKe.forEach(t),B8r=i(X),VC=n(X,"LI",{});var pKe=s(VC);fAe=n(pKe,"STRONG",{});var kca=s(fAe);I8r=r(kca,"qdqbert"),kca.forEach(t),N8r=r(pKe," \u2014 "),Roe=n(pKe,"A",{href:!0});var Sca=s(Roe);q8r=r(Sca,"QDQBertForQuestionAnswering"),Sca.forEach(t),j8r=r(pKe," (QDQBert model)"),pKe.forEach(t),D8r=i(X),XC=n(X,"LI",{});var _Ke=s(XC);gAe=n(_Ke,"STRONG",{});var Rca=s(gAe);G8r=r(Rca,"reformer"),Rca.forEach(t),O8r=r(_Ke," \u2014 "),Poe=n(_Ke,"A",{href:!0});var Pca=s(Poe);V8r=r(Pca,"ReformerForQuestionAnswering"),Pca.forEach(t),X8r=r(_Ke," (Reformer model)"),_Ke.forEach(t),z8r=i(X),zC=n(X,"LI",{});var bKe=s(zC);hAe=n(bKe,"STRONG",{});var Bca=s(hAe);Q8r=r(Bca,"rembert"),Bca.forEach(t),W8r=r(bKe," \u2014 "),Boe=n(bKe,"A",{href:!0});var Ica=s(Boe);U8r=r(Ica,"RemBertForQuestionAnswering"),Ica.forEach(t),H8r=r(bKe," (RemBERT model)"),bKe.forEach(t),J8r=i(X),QC=n(X,"LI",{});var vKe=s(QC);uAe=n(vKe,"STRONG",{});var Nca=s(uAe);Y8r=r(Nca,"roberta"),Nca.forEach(t),Z8r=r(vKe," \u2014 "),Ioe=n(vKe,"A",{href:!0});var qca=s(Ioe);K8r=r(qca,"RobertaForQuestionAnswering"),qca.forEach(t),eLr=r(vKe," (RoBERTa model)"),vKe.forEach(t),oLr=i(X),WC=n(X,"LI",{});var FKe=s(WC);pAe=n(FKe,"STRONG",{});var jca=s(pAe);rLr=r(jca,"roc_bert"),jca.forEach(t),tLr=r(FKe," \u2014 "),Noe=n(FKe,"A",{href:!0});var Dca=s(Noe);aLr=r(Dca,"RoCBertForQuestionAnswering"),Dca.forEach(t),nLr=r(FKe," (RoCBert model)"),FKe.forEach(t),sLr=i(X),UC=n(X,"LI",{});var TKe=s(UC);_Ae=n(TKe,"STRONG",{});var Gca=s(_Ae);lLr=r(Gca,"roformer"),Gca.forEach(t),iLr=r(TKe," \u2014 "),qoe=n(TKe,"A",{href:!0});var Oca=s(qoe);dLr=r(Oca,"RoFormerForQuestionAnswering"),Oca.forEach(t),mLr=r(TKe," (RoFormer model)"),TKe.forEach(t),cLr=i(X),HC=n(X,"LI",{});var MKe=s(HC);bAe=n(MKe,"STRONG",{});var Vca=s(bAe);fLr=r(Vca,"splinter"),Vca.forEach(t),gLr=r(MKe," \u2014 "),joe=n(MKe,"A",{href:!0});var Xca=s(joe);hLr=r(Xca,"SplinterForQuestionAnswering"),Xca.forEach(t),uLr=r(MKe," (Splinter model)"),MKe.forEach(t),pLr=i(X),JC=n(X,"LI",{});var EKe=s(JC);vAe=n(EKe,"STRONG",{});var zca=s(vAe);_Lr=r(zca,"squeezebert"),zca.forEach(t),bLr=r(EKe," \u2014 "),Doe=n(EKe,"A",{href:!0});var Qca=s(Doe);vLr=r(Qca,"SqueezeBertForQuestionAnswering"),Qca.forEach(t),FLr=r(EKe," (SqueezeBERT model)"),EKe.forEach(t),TLr=i(X),YC=n(X,"LI",{});var CKe=s(YC);FAe=n(CKe,"STRONG",{});var Wca=s(FAe);MLr=r(Wca,"xlm"),Wca.forEach(t),ELr=r(CKe," \u2014 "),Goe=n(CKe,"A",{href:!0});var Uca=s(Goe);CLr=r(Uca,"XLMForQuestionAnsweringSimple"),Uca.forEach(t),wLr=r(CKe," (XLM model)"),CKe.forEach(t),ALr=i(X),ZC=n(X,"LI",{});var wKe=s(ZC);TAe=n(wKe,"STRONG",{});var Hca=s(TAe);LLr=r(Hca,"xlm-roberta"),Hca.forEach(t),yLr=r(wKe," \u2014 "),Ooe=n(wKe,"A",{href:!0});var Jca=s(Ooe);xLr=r(Jca,"XLMRobertaForQuestionAnswering"),Jca.forEach(t),$Lr=r(wKe," (XLM-RoBERTa model)"),wKe.forEach(t),kLr=i(X),KC=n(X,"LI",{});var AKe=s(KC);MAe=n(AKe,"STRONG",{});var Yca=s(MAe);SLr=r(Yca,"xlm-roberta-xl"),Yca.forEach(t),RLr=r(AKe," \u2014 "),Voe=n(AKe,"A",{href:!0});var Zca=s(Voe);PLr=r(Zca,"XLMRobertaXLForQuestionAnswering"),Zca.forEach(t),BLr=r(AKe," (XLM-RoBERTa-XL model)"),AKe.forEach(t),ILr=i(X),e3=n(X,"LI",{});var LKe=s(e3);EAe=n(LKe,"STRONG",{});var Kca=s(EAe);NLr=r(Kca,"xlnet"),Kca.forEach(t),qLr=r(LKe," \u2014 "),Xoe=n(LKe,"A",{href:!0});var efa=s(Xoe);jLr=r(efa,"XLNetForQuestionAnsweringSimple"),efa.forEach(t),DLr=r(LKe," (XLNet model)"),LKe.forEach(t),GLr=i(X),o3=n(X,"LI",{});var yKe=s(o3);CAe=n(yKe,"STRONG",{});var ofa=s(CAe);OLr=r(ofa,"yoso"),ofa.forEach(t),VLr=r(yKe," \u2014 "),zoe=n(yKe,"A",{href:!0});var rfa=s(zoe);XLr=r(rfa,"YosoForQuestionAnswering"),rfa.forEach(t),zLr=r(yKe," (YOSO model)"),yKe.forEach(t),X.forEach(t),QLr=i(Oa),r3=n(Oa,"P",{});var xKe=s(r3);WLr=r(xKe,"The model is set in evaluation mode by default using "),wAe=n(xKe,"CODE",{});var tfa=s(wAe);ULr=r(tfa,"model.eval()"),tfa.forEach(t),HLr=r(xKe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),AAe=n(xKe,"CODE",{});var afa=s(AAe);JLr=r(afa,"model.train()"),afa.forEach(t),xKe.forEach(t),YLr=i(Oa),T(t3.$$.fragment,Oa),Oa.forEach(t),ri.forEach(t),cio=i(c),Fm=n(c,"H2",{class:!0});var Pmo=s(Fm);a3=n(Pmo,"A",{id:!0,class:!0,href:!0});var nfa=s(a3);LAe=n(nfa,"SPAN",{});var sfa=s(LAe);T(HS.$$.fragment,sfa),sfa.forEach(t),nfa.forEach(t),ZLr=i(Pmo),yAe=n(Pmo,"SPAN",{});var lfa=s(yAe);KLr=r(lfa,"AutoModelForTableQuestionAnswering"),lfa.forEach(t),Pmo.forEach(t),fio=i(c),Yo=n(c,"DIV",{class:!0});var ti=s(Yo);T(JS.$$.fragment,ti),eyr=i(ti),Tm=n(ti,"P",{});var Pfe=s(Tm);oyr=r(Pfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Qoe=n(Pfe,"A",{href:!0});var ifa=s(Qoe);ryr=r(ifa,"from_pretrained()"),ifa.forEach(t),tyr=r(Pfe," class method or the "),Woe=n(Pfe,"A",{href:!0});var dfa=s(Woe);ayr=r(dfa,"from_config()"),dfa.forEach(t),nyr=r(Pfe,` class
method.`),Pfe.forEach(t),syr=i(ti),YS=n(ti,"P",{});var Bmo=s(YS);lyr=r(Bmo,"This class cannot be instantiated directly using "),xAe=n(Bmo,"CODE",{});var mfa=s(xAe);iyr=r(mfa,"__init__()"),mfa.forEach(t),dyr=r(Bmo," (throws an error)."),Bmo.forEach(t),myr=i(ti),Nt=n(ti,"DIV",{class:!0});var yx=s(Nt);T(ZS.$$.fragment,yx),cyr=i(yx),$Ae=n(yx,"P",{});var cfa=s($Ae);fyr=r(cfa,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),cfa.forEach(t),gyr=i(yx),Mm=n(yx,"P",{});var Bfe=s(Mm);hyr=r(Bfe,`Note:
Loading a model from its configuration file does `),kAe=n(Bfe,"STRONG",{});var ffa=s(kAe);uyr=r(ffa,"not"),ffa.forEach(t),pyr=r(Bfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Uoe=n(Bfe,"A",{href:!0});var gfa=s(Uoe);_yr=r(gfa,"from_pretrained()"),gfa.forEach(t),byr=r(Bfe," to load the model weights."),Bfe.forEach(t),vyr=i(yx),T(n3.$$.fragment,yx),yx.forEach(t),Fyr=i(ti),uo=n(ti,"DIV",{class:!0});var Va=s(uo);T(KS.$$.fragment,Va),Tyr=i(Va),SAe=n(Va,"P",{});var hfa=s(SAe);Myr=r(hfa,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),hfa.forEach(t),Eyr=i(Va),En=n(Va,"P",{});var xx=s(En);Cyr=r(xx,"The model class to instantiate is selected based on the "),RAe=n(xx,"CODE",{});var ufa=s(RAe);wyr=r(ufa,"model_type"),ufa.forEach(t),Ayr=r(xx,` property of the config object (either
passed as an argument or loaded from `),PAe=n(xx,"CODE",{});var pfa=s(PAe);Lyr=r(pfa,"pretrained_model_name_or_path"),pfa.forEach(t),yyr=r(xx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),BAe=n(xx,"CODE",{});var _fa=s(BAe);xyr=r(_fa,"pretrained_model_name_or_path"),_fa.forEach(t),$yr=r(xx,":"),xx.forEach(t),kyr=i(Va),IAe=n(Va,"UL",{});var bfa=s(IAe);s3=n(bfa,"LI",{});var $Ke=s(s3);NAe=n($Ke,"STRONG",{});var vfa=s(NAe);Syr=r(vfa,"tapas"),vfa.forEach(t),Ryr=r($Ke," \u2014 "),Hoe=n($Ke,"A",{href:!0});var Ffa=s(Hoe);Pyr=r(Ffa,"TapasForQuestionAnswering"),Ffa.forEach(t),Byr=r($Ke," (TAPAS model)"),$Ke.forEach(t),bfa.forEach(t),Iyr=i(Va),l3=n(Va,"P",{});var kKe=s(l3);Nyr=r(kKe,"The model is set in evaluation mode by default using "),qAe=n(kKe,"CODE",{});var Tfa=s(qAe);qyr=r(Tfa,"model.eval()"),Tfa.forEach(t),jyr=r(kKe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),jAe=n(kKe,"CODE",{});var Mfa=s(jAe);Dyr=r(Mfa,"model.train()"),Mfa.forEach(t),kKe.forEach(t),Gyr=i(Va),T(i3.$$.fragment,Va),Va.forEach(t),ti.forEach(t),gio=i(c),Em=n(c,"H2",{class:!0});var Imo=s(Em);d3=n(Imo,"A",{id:!0,class:!0,href:!0});var Efa=s(d3);DAe=n(Efa,"SPAN",{});var Cfa=s(DAe);T(eR.$$.fragment,Cfa),Cfa.forEach(t),Efa.forEach(t),Oyr=i(Imo),GAe=n(Imo,"SPAN",{});var wfa=s(GAe);Vyr=r(wfa,"AutoModelForDocumentQuestionAnswering"),wfa.forEach(t),Imo.forEach(t),hio=i(c),Zo=n(c,"DIV",{class:!0});var ai=s(Zo);T(oR.$$.fragment,ai),Xyr=i(ai),Cm=n(ai,"P",{});var Ife=s(Cm);zyr=r(Ife,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),Joe=n(Ife,"A",{href:!0});var Afa=s(Joe);Qyr=r(Afa,"from_pretrained()"),Afa.forEach(t),Wyr=r(Ife," class method or the "),Yoe=n(Ife,"A",{href:!0});var Lfa=s(Yoe);Uyr=r(Lfa,"from_config()"),Lfa.forEach(t),Hyr=r(Ife,` class
method.`),Ife.forEach(t),Jyr=i(ai),rR=n(ai,"P",{});var Nmo=s(rR);Yyr=r(Nmo,"This class cannot be instantiated directly using "),OAe=n(Nmo,"CODE",{});var yfa=s(OAe);Zyr=r(yfa,"__init__()"),yfa.forEach(t),Kyr=r(Nmo," (throws an error)."),Nmo.forEach(t),e9r=i(ai),qt=n(ai,"DIV",{class:!0});var $x=s(qt);T(tR.$$.fragment,$x),o9r=i($x),VAe=n($x,"P",{});var xfa=s(VAe);r9r=r(xfa,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),xfa.forEach(t),t9r=i($x),wm=n($x,"P",{});var Nfe=s(wm);a9r=r(Nfe,`Note:
Loading a model from its configuration file does `),XAe=n(Nfe,"STRONG",{});var $fa=s(XAe);n9r=r($fa,"not"),$fa.forEach(t),s9r=r(Nfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zoe=n(Nfe,"A",{href:!0});var kfa=s(Zoe);l9r=r(kfa,"from_pretrained()"),kfa.forEach(t),i9r=r(Nfe," to load the model weights."),Nfe.forEach(t),d9r=i($x),T(m3.$$.fragment,$x),$x.forEach(t),m9r=i(ai),po=n(ai,"DIV",{class:!0});var Xa=s(po);T(aR.$$.fragment,Xa),c9r=i(Xa),zAe=n(Xa,"P",{});var Sfa=s(zAe);f9r=r(Sfa,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),Sfa.forEach(t),g9r=i(Xa),Cn=n(Xa,"P",{});var kx=s(Cn);h9r=r(kx,"The model class to instantiate is selected based on the "),QAe=n(kx,"CODE",{});var Rfa=s(QAe);u9r=r(Rfa,"model_type"),Rfa.forEach(t),p9r=r(kx,` property of the config object (either
passed as an argument or loaded from `),WAe=n(kx,"CODE",{});var Pfa=s(WAe);_9r=r(Pfa,"pretrained_model_name_or_path"),Pfa.forEach(t),b9r=r(kx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),UAe=n(kx,"CODE",{});var Bfa=s(UAe);v9r=r(Bfa,"pretrained_model_name_or_path"),Bfa.forEach(t),F9r=r(kx,":"),kx.forEach(t),T9r=i(Xa),Am=n(Xa,"UL",{});var qfe=s(Am);c3=n(qfe,"LI",{});var SKe=s(c3);HAe=n(SKe,"STRONG",{});var Ifa=s(HAe);M9r=r(Ifa,"layoutlm"),Ifa.forEach(t),E9r=r(SKe," \u2014 "),Koe=n(SKe,"A",{href:!0});var Nfa=s(Koe);C9r=r(Nfa,"LayoutLMForQuestionAnswering"),Nfa.forEach(t),w9r=r(SKe," (LayoutLM model)"),SKe.forEach(t),A9r=i(qfe),f3=n(qfe,"LI",{});var RKe=s(f3);JAe=n(RKe,"STRONG",{});var qfa=s(JAe);L9r=r(qfa,"layoutlmv2"),qfa.forEach(t),y9r=r(RKe," \u2014 "),ere=n(RKe,"A",{href:!0});var jfa=s(ere);x9r=r(jfa,"LayoutLMv2ForQuestionAnswering"),jfa.forEach(t),$9r=r(RKe," (LayoutLMv2 model)"),RKe.forEach(t),k9r=i(qfe),g3=n(qfe,"LI",{});var PKe=s(g3);YAe=n(PKe,"STRONG",{});var Dfa=s(YAe);S9r=r(Dfa,"layoutlmv3"),Dfa.forEach(t),R9r=r(PKe," \u2014 "),ore=n(PKe,"A",{href:!0});var Gfa=s(ore);P9r=r(Gfa,"LayoutLMv3ForQuestionAnswering"),Gfa.forEach(t),B9r=r(PKe," (LayoutLMv3 model)"),PKe.forEach(t),qfe.forEach(t),I9r=i(Xa),h3=n(Xa,"P",{});var BKe=s(h3);N9r=r(BKe,"The model is set in evaluation mode by default using "),ZAe=n(BKe,"CODE",{});var Ofa=s(ZAe);q9r=r(Ofa,"model.eval()"),Ofa.forEach(t),j9r=r(BKe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),KAe=n(BKe,"CODE",{});var Vfa=s(KAe);D9r=r(Vfa,"model.train()"),Vfa.forEach(t),BKe.forEach(t),G9r=i(Xa),T(u3.$$.fragment,Xa),Xa.forEach(t),ai.forEach(t),uio=i(c),Lm=n(c,"H2",{class:!0});var qmo=s(Lm);p3=n(qmo,"A",{id:!0,class:!0,href:!0});var Xfa=s(p3);e6e=n(Xfa,"SPAN",{});var zfa=s(e6e);T(nR.$$.fragment,zfa),zfa.forEach(t),Xfa.forEach(t),O9r=i(qmo),o6e=n(qmo,"SPAN",{});var Qfa=s(o6e);V9r=r(Qfa,"AutoModelForImageClassification"),Qfa.forEach(t),qmo.forEach(t),pio=i(c),Ko=n(c,"DIV",{class:!0});var ni=s(Ko);T(sR.$$.fragment,ni),X9r=i(ni),ym=n(ni,"P",{});var jfe=s(ym);z9r=r(jfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),rre=n(jfe,"A",{href:!0});var Wfa=s(rre);Q9r=r(Wfa,"from_pretrained()"),Wfa.forEach(t),W9r=r(jfe," class method or the "),tre=n(jfe,"A",{href:!0});var Ufa=s(tre);U9r=r(Ufa,"from_config()"),Ufa.forEach(t),H9r=r(jfe,` class
method.`),jfe.forEach(t),J9r=i(ni),lR=n(ni,"P",{});var jmo=s(lR);Y9r=r(jmo,"This class cannot be instantiated directly using "),r6e=n(jmo,"CODE",{});var Hfa=s(r6e);Z9r=r(Hfa,"__init__()"),Hfa.forEach(t),K9r=r(jmo," (throws an error)."),jmo.forEach(t),exr=i(ni),jt=n(ni,"DIV",{class:!0});var Sx=s(jt);T(iR.$$.fragment,Sx),oxr=i(Sx),t6e=n(Sx,"P",{});var Jfa=s(t6e);rxr=r(Jfa,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Jfa.forEach(t),txr=i(Sx),xm=n(Sx,"P",{});var Dfe=s(xm);axr=r(Dfe,`Note:
Loading a model from its configuration file does `),a6e=n(Dfe,"STRONG",{});var Yfa=s(a6e);nxr=r(Yfa,"not"),Yfa.forEach(t),sxr=r(Dfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),are=n(Dfe,"A",{href:!0});var Zfa=s(are);lxr=r(Zfa,"from_pretrained()"),Zfa.forEach(t),ixr=r(Dfe," to load the model weights."),Dfe.forEach(t),dxr=i(Sx),T(_3.$$.fragment,Sx),Sx.forEach(t),mxr=i(ni),_o=n(ni,"DIV",{class:!0});var za=s(_o);T(dR.$$.fragment,za),cxr=i(za),n6e=n(za,"P",{});var Kfa=s(n6e);fxr=r(Kfa,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Kfa.forEach(t),gxr=i(za),wn=n(za,"P",{});var Rx=s(wn);hxr=r(Rx,"The model class to instantiate is selected based on the "),s6e=n(Rx,"CODE",{});var ega=s(s6e);uxr=r(ega,"model_type"),ega.forEach(t),pxr=r(Rx,` property of the config object (either
passed as an argument or loaded from `),l6e=n(Rx,"CODE",{});var oga=s(l6e);_xr=r(oga,"pretrained_model_name_or_path"),oga.forEach(t),bxr=r(Rx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i6e=n(Rx,"CODE",{});var rga=s(i6e);vxr=r(rga,"pretrained_model_name_or_path"),rga.forEach(t),Fxr=r(Rx,":"),Rx.forEach(t),Txr=i(za),Fe=n(za,"UL",{});var Me=s(Fe);b3=n(Me,"LI",{});var IKe=s(b3);d6e=n(IKe,"STRONG",{});var tga=s(d6e);Mxr=r(tga,"beit"),tga.forEach(t),Exr=r(IKe," \u2014 "),nre=n(IKe,"A",{href:!0});var aga=s(nre);Cxr=r(aga,"BeitForImageClassification"),aga.forEach(t),wxr=r(IKe," (BEiT model)"),IKe.forEach(t),Axr=i(Me),v3=n(Me,"LI",{});var NKe=s(v3);m6e=n(NKe,"STRONG",{});var nga=s(m6e);Lxr=r(nga,"convnext"),nga.forEach(t),yxr=r(NKe," \u2014 "),sre=n(NKe,"A",{href:!0});var sga=s(sre);xxr=r(sga,"ConvNextForImageClassification"),sga.forEach(t),$xr=r(NKe," (ConvNeXT model)"),NKe.forEach(t),kxr=i(Me),F3=n(Me,"LI",{});var qKe=s(F3);c6e=n(qKe,"STRONG",{});var lga=s(c6e);Sxr=r(lga,"cvt"),lga.forEach(t),Rxr=r(qKe," \u2014 "),lre=n(qKe,"A",{href:!0});var iga=s(lre);Pxr=r(iga,"CvtForImageClassification"),iga.forEach(t),Bxr=r(qKe," (CvT model)"),qKe.forEach(t),Ixr=i(Me),T3=n(Me,"LI",{});var jKe=s(T3);f6e=n(jKe,"STRONG",{});var dga=s(f6e);Nxr=r(dga,"data2vec-vision"),dga.forEach(t),qxr=r(jKe," \u2014 "),ire=n(jKe,"A",{href:!0});var mga=s(ire);jxr=r(mga,"Data2VecVisionForImageClassification"),mga.forEach(t),Dxr=r(jKe," (Data2VecVision model)"),jKe.forEach(t),Gxr=i(Me),Nl=n(Me,"LI",{});var kq=s(Nl);g6e=n(kq,"STRONG",{});var cga=s(g6e);Oxr=r(cga,"deit"),cga.forEach(t),Vxr=r(kq," \u2014 "),dre=n(kq,"A",{href:!0});var fga=s(dre);Xxr=r(fga,"DeiTForImageClassification"),fga.forEach(t),zxr=r(kq," or "),mre=n(kq,"A",{href:!0});var gga=s(mre);Qxr=r(gga,"DeiTForImageClassificationWithTeacher"),gga.forEach(t),Wxr=r(kq," (DeiT model)"),kq.forEach(t),Uxr=i(Me),M3=n(Me,"LI",{});var DKe=s(M3);h6e=n(DKe,"STRONG",{});var hga=s(h6e);Hxr=r(hga,"imagegpt"),hga.forEach(t),Jxr=r(DKe," \u2014 "),cre=n(DKe,"A",{href:!0});var uga=s(cre);Yxr=r(uga,"ImageGPTForImageClassification"),uga.forEach(t),Zxr=r(DKe," (ImageGPT model)"),DKe.forEach(t),Kxr=i(Me),ql=n(Me,"LI",{});var Sq=s(ql);u6e=n(Sq,"STRONG",{});var pga=s(u6e);e$r=r(pga,"levit"),pga.forEach(t),o$r=r(Sq," \u2014 "),fre=n(Sq,"A",{href:!0});var _ga=s(fre);r$r=r(_ga,"LevitForImageClassification"),_ga.forEach(t),t$r=r(Sq," or "),gre=n(Sq,"A",{href:!0});var bga=s(gre);a$r=r(bga,"LevitForImageClassificationWithTeacher"),bga.forEach(t),n$r=r(Sq," (LeViT model)"),Sq.forEach(t),s$r=i(Me),E3=n(Me,"LI",{});var GKe=s(E3);p6e=n(GKe,"STRONG",{});var vga=s(p6e);l$r=r(vga,"mobilevit"),vga.forEach(t),i$r=r(GKe," \u2014 "),hre=n(GKe,"A",{href:!0});var Fga=s(hre);d$r=r(Fga,"MobileViTForImageClassification"),Fga.forEach(t),m$r=r(GKe," (MobileViT model)"),GKe.forEach(t),c$r=i(Me),Dt=n(Me,"LI",{});var Kf=s(Dt);_6e=n(Kf,"STRONG",{});var Tga=s(_6e);f$r=r(Tga,"perceiver"),Tga.forEach(t),g$r=r(Kf," \u2014 "),ure=n(Kf,"A",{href:!0});var Mga=s(ure);h$r=r(Mga,"PerceiverForImageClassificationLearned"),Mga.forEach(t),u$r=r(Kf," or "),pre=n(Kf,"A",{href:!0});var Ega=s(pre);p$r=r(Ega,"PerceiverForImageClassificationFourier"),Ega.forEach(t),_$r=r(Kf," or "),_re=n(Kf,"A",{href:!0});var Cga=s(_re);b$r=r(Cga,"PerceiverForImageClassificationConvProcessing"),Cga.forEach(t),v$r=r(Kf," (Perceiver model)"),Kf.forEach(t),F$r=i(Me),C3=n(Me,"LI",{});var OKe=s(C3);b6e=n(OKe,"STRONG",{});var wga=s(b6e);T$r=r(wga,"poolformer"),wga.forEach(t),M$r=r(OKe," \u2014 "),bre=n(OKe,"A",{href:!0});var Aga=s(bre);E$r=r(Aga,"PoolFormerForImageClassification"),Aga.forEach(t),C$r=r(OKe," (PoolFormer model)"),OKe.forEach(t),w$r=i(Me),w3=n(Me,"LI",{});var VKe=s(w3);v6e=n(VKe,"STRONG",{});var Lga=s(v6e);A$r=r(Lga,"regnet"),Lga.forEach(t),L$r=r(VKe," \u2014 "),vre=n(VKe,"A",{href:!0});var yga=s(vre);y$r=r(yga,"RegNetForImageClassification"),yga.forEach(t),x$r=r(VKe," (RegNet model)"),VKe.forEach(t),$$r=i(Me),A3=n(Me,"LI",{});var XKe=s(A3);F6e=n(XKe,"STRONG",{});var xga=s(F6e);k$r=r(xga,"resnet"),xga.forEach(t),S$r=r(XKe," \u2014 "),Fre=n(XKe,"A",{href:!0});var $ga=s(Fre);R$r=r($ga,"ResNetForImageClassification"),$ga.forEach(t),P$r=r(XKe," (ResNet model)"),XKe.forEach(t),B$r=i(Me),L3=n(Me,"LI",{});var zKe=s(L3);T6e=n(zKe,"STRONG",{});var kga=s(T6e);I$r=r(kga,"segformer"),kga.forEach(t),N$r=r(zKe," \u2014 "),Tre=n(zKe,"A",{href:!0});var Sga=s(Tre);q$r=r(Sga,"SegformerForImageClassification"),Sga.forEach(t),j$r=r(zKe," (SegFormer model)"),zKe.forEach(t),D$r=i(Me),y3=n(Me,"LI",{});var QKe=s(y3);M6e=n(QKe,"STRONG",{});var Rga=s(M6e);G$r=r(Rga,"swin"),Rga.forEach(t),O$r=r(QKe," \u2014 "),Mre=n(QKe,"A",{href:!0});var Pga=s(Mre);V$r=r(Pga,"SwinForImageClassification"),Pga.forEach(t),X$r=r(QKe," (Swin Transformer model)"),QKe.forEach(t),z$r=i(Me),x3=n(Me,"LI",{});var WKe=s(x3);E6e=n(WKe,"STRONG",{});var Bga=s(E6e);Q$r=r(Bga,"swinv2"),Bga.forEach(t),W$r=r(WKe," \u2014 "),Ere=n(WKe,"A",{href:!0});var Iga=s(Ere);U$r=r(Iga,"Swinv2ForImageClassification"),Iga.forEach(t),H$r=r(WKe," (Swin Transformer V2 model)"),WKe.forEach(t),J$r=i(Me),$3=n(Me,"LI",{});var UKe=s($3);C6e=n(UKe,"STRONG",{});var Nga=s(C6e);Y$r=r(Nga,"van"),Nga.forEach(t),Z$r=r(UKe," \u2014 "),Cre=n(UKe,"A",{href:!0});var qga=s(Cre);K$r=r(qga,"VanForImageClassification"),qga.forEach(t),ekr=r(UKe," (VAN model)"),UKe.forEach(t),okr=i(Me),k3=n(Me,"LI",{});var HKe=s(k3);w6e=n(HKe,"STRONG",{});var jga=s(w6e);rkr=r(jga,"vit"),jga.forEach(t),tkr=r(HKe," \u2014 "),wre=n(HKe,"A",{href:!0});var Dga=s(wre);akr=r(Dga,"ViTForImageClassification"),Dga.forEach(t),nkr=r(HKe," (ViT model)"),HKe.forEach(t),skr=i(Me),S3=n(Me,"LI",{});var JKe=s(S3);A6e=n(JKe,"STRONG",{});var Gga=s(A6e);lkr=r(Gga,"vit_msn"),Gga.forEach(t),ikr=r(JKe," \u2014 "),Are=n(JKe,"A",{href:!0});var Oga=s(Are);dkr=r(Oga,"ViTMSNForImageClassification"),Oga.forEach(t),mkr=r(JKe," (ViTMSN model)"),JKe.forEach(t),Me.forEach(t),ckr=i(za),R3=n(za,"P",{});var YKe=s(R3);fkr=r(YKe,"The model is set in evaluation mode by default using "),L6e=n(YKe,"CODE",{});var Vga=s(L6e);gkr=r(Vga,"model.eval()"),Vga.forEach(t),hkr=r(YKe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),y6e=n(YKe,"CODE",{});var Xga=s(y6e);ukr=r(Xga,"model.train()"),Xga.forEach(t),YKe.forEach(t),pkr=i(za),T(P3.$$.fragment,za),za.forEach(t),ni.forEach(t),_io=i(c),$m=n(c,"H2",{class:!0});var Dmo=s($m);B3=n(Dmo,"A",{id:!0,class:!0,href:!0});var zga=s(B3);x6e=n(zga,"SPAN",{});var Qga=s(x6e);T(mR.$$.fragment,Qga),Qga.forEach(t),zga.forEach(t),_kr=i(Dmo),$6e=n(Dmo,"SPAN",{});var Wga=s($6e);bkr=r(Wga,"AutoModelForVideoClassification"),Wga.forEach(t),Dmo.forEach(t),bio=i(c),er=n(c,"DIV",{class:!0});var si=s(er);T(cR.$$.fragment,si),vkr=i(si),km=n(si,"P",{});var Gfe=s(km);Fkr=r(Gfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),Lre=n(Gfe,"A",{href:!0});var Uga=s(Lre);Tkr=r(Uga,"from_pretrained()"),Uga.forEach(t),Mkr=r(Gfe," class method or the "),yre=n(Gfe,"A",{href:!0});var Hga=s(yre);Ekr=r(Hga,"from_config()"),Hga.forEach(t),Ckr=r(Gfe,` class
method.`),Gfe.forEach(t),wkr=i(si),fR=n(si,"P",{});var Gmo=s(fR);Akr=r(Gmo,"This class cannot be instantiated directly using "),k6e=n(Gmo,"CODE",{});var Jga=s(k6e);Lkr=r(Jga,"__init__()"),Jga.forEach(t),ykr=r(Gmo," (throws an error)."),Gmo.forEach(t),xkr=i(si),Gt=n(si,"DIV",{class:!0});var Px=s(Gt);T(gR.$$.fragment,Px),$kr=i(Px),S6e=n(Px,"P",{});var Yga=s(S6e);kkr=r(Yga,"Instantiates one of the model classes of the library (with a video classification head) from a configuration."),Yga.forEach(t),Skr=i(Px),Sm=n(Px,"P",{});var Ofe=s(Sm);Rkr=r(Ofe,`Note:
Loading a model from its configuration file does `),R6e=n(Ofe,"STRONG",{});var Zga=s(R6e);Pkr=r(Zga,"not"),Zga.forEach(t),Bkr=r(Ofe,` load the model weights. It only affects the
model\u2019s configuration. Use `),xre=n(Ofe,"A",{href:!0});var Kga=s(xre);Ikr=r(Kga,"from_pretrained()"),Kga.forEach(t),Nkr=r(Ofe," to load the model weights."),Ofe.forEach(t),qkr=i(Px),T(I3.$$.fragment,Px),Px.forEach(t),jkr=i(si),bo=n(si,"DIV",{class:!0});var Qa=s(bo);T(hR.$$.fragment,Qa),Dkr=i(Qa),P6e=n(Qa,"P",{});var eha=s(P6e);Gkr=r(eha,"Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),eha.forEach(t),Okr=i(Qa),An=n(Qa,"P",{});var Bx=s(An);Vkr=r(Bx,"The model class to instantiate is selected based on the "),B6e=n(Bx,"CODE",{});var oha=s(B6e);Xkr=r(oha,"model_type"),oha.forEach(t),zkr=r(Bx,` property of the config object (either
passed as an argument or loaded from `),I6e=n(Bx,"CODE",{});var rha=s(I6e);Qkr=r(rha,"pretrained_model_name_or_path"),rha.forEach(t),Wkr=r(Bx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N6e=n(Bx,"CODE",{});var tha=s(N6e);Ukr=r(tha,"pretrained_model_name_or_path"),tha.forEach(t),Hkr=r(Bx,":"),Bx.forEach(t),Jkr=i(Qa),q6e=n(Qa,"UL",{});var aha=s(q6e);N3=n(aha,"LI",{});var ZKe=s(N3);j6e=n(ZKe,"STRONG",{});var nha=s(j6e);Ykr=r(nha,"videomae"),nha.forEach(t),Zkr=r(ZKe," \u2014 "),$re=n(ZKe,"A",{href:!0});var sha=s($re);Kkr=r(sha,"VideoMAEForVideoClassification"),sha.forEach(t),eSr=r(ZKe," (VideoMAE model)"),ZKe.forEach(t),aha.forEach(t),oSr=i(Qa),q3=n(Qa,"P",{});var KKe=s(q3);rSr=r(KKe,"The model is set in evaluation mode by default using "),D6e=n(KKe,"CODE",{});var lha=s(D6e);tSr=r(lha,"model.eval()"),lha.forEach(t),aSr=r(KKe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),G6e=n(KKe,"CODE",{});var iha=s(G6e);nSr=r(iha,"model.train()"),iha.forEach(t),KKe.forEach(t),sSr=i(Qa),T(j3.$$.fragment,Qa),Qa.forEach(t),si.forEach(t),vio=i(c),Rm=n(c,"H2",{class:!0});var Omo=s(Rm);D3=n(Omo,"A",{id:!0,class:!0,href:!0});var dha=s(D3);O6e=n(dha,"SPAN",{});var mha=s(O6e);T(uR.$$.fragment,mha),mha.forEach(t),dha.forEach(t),lSr=i(Omo),V6e=n(Omo,"SPAN",{});var cha=s(V6e);iSr=r(cha,"AutoModelForVision2Seq"),cha.forEach(t),Omo.forEach(t),Fio=i(c),or=n(c,"DIV",{class:!0});var li=s(or);T(pR.$$.fragment,li),dSr=i(li),Pm=n(li,"P",{});var Vfe=s(Pm);mSr=r(Vfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),kre=n(Vfe,"A",{href:!0});var fha=s(kre);cSr=r(fha,"from_pretrained()"),fha.forEach(t),fSr=r(Vfe," class method or the "),Sre=n(Vfe,"A",{href:!0});var gha=s(Sre);gSr=r(gha,"from_config()"),gha.forEach(t),hSr=r(Vfe,` class
method.`),Vfe.forEach(t),uSr=i(li),_R=n(li,"P",{});var Vmo=s(_R);pSr=r(Vmo,"This class cannot be instantiated directly using "),X6e=n(Vmo,"CODE",{});var hha=s(X6e);_Sr=r(hha,"__init__()"),hha.forEach(t),bSr=r(Vmo," (throws an error)."),Vmo.forEach(t),vSr=i(li),Ot=n(li,"DIV",{class:!0});var Ix=s(Ot);T(bR.$$.fragment,Ix),FSr=i(Ix),z6e=n(Ix,"P",{});var uha=s(z6e);TSr=r(uha,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),uha.forEach(t),MSr=i(Ix),Bm=n(Ix,"P",{});var Xfe=s(Bm);ESr=r(Xfe,`Note:
Loading a model from its configuration file does `),Q6e=n(Xfe,"STRONG",{});var pha=s(Q6e);CSr=r(pha,"not"),pha.forEach(t),wSr=r(Xfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Rre=n(Xfe,"A",{href:!0});var _ha=s(Rre);ASr=r(_ha,"from_pretrained()"),_ha.forEach(t),LSr=r(Xfe," to load the model weights."),Xfe.forEach(t),ySr=i(Ix),T(G3.$$.fragment,Ix),Ix.forEach(t),xSr=i(li),vo=n(li,"DIV",{class:!0});var Wa=s(vo);T(vR.$$.fragment,Wa),$Sr=i(Wa),W6e=n(Wa,"P",{});var bha=s(W6e);kSr=r(bha,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),bha.forEach(t),SSr=i(Wa),Ln=n(Wa,"P",{});var Nx=s(Ln);RSr=r(Nx,"The model class to instantiate is selected based on the "),U6e=n(Nx,"CODE",{});var vha=s(U6e);PSr=r(vha,"model_type"),vha.forEach(t),BSr=r(Nx,` property of the config object (either
passed as an argument or loaded from `),H6e=n(Nx,"CODE",{});var Fha=s(H6e);ISr=r(Fha,"pretrained_model_name_or_path"),Fha.forEach(t),NSr=r(Nx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J6e=n(Nx,"CODE",{});var Tha=s(J6e);qSr=r(Tha,"pretrained_model_name_or_path"),Tha.forEach(t),jSr=r(Nx,":"),Nx.forEach(t),DSr=i(Wa),Y6e=n(Wa,"UL",{});var Mha=s(Y6e);O3=n(Mha,"LI",{});var eeo=s(O3);Z6e=n(eeo,"STRONG",{});var Eha=s(Z6e);GSr=r(Eha,"vision-encoder-decoder"),Eha.forEach(t),OSr=r(eeo," \u2014 "),Pre=n(eeo,"A",{href:!0});var Cha=s(Pre);VSr=r(Cha,"VisionEncoderDecoderModel"),Cha.forEach(t),XSr=r(eeo," (Vision Encoder decoder model)"),eeo.forEach(t),Mha.forEach(t),zSr=i(Wa),V3=n(Wa,"P",{});var oeo=s(V3);QSr=r(oeo,"The model is set in evaluation mode by default using "),K6e=n(oeo,"CODE",{});var wha=s(K6e);WSr=r(wha,"model.eval()"),wha.forEach(t),USr=r(oeo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),e7e=n(oeo,"CODE",{});var Aha=s(e7e);HSr=r(Aha,"model.train()"),Aha.forEach(t),oeo.forEach(t),JSr=i(Wa),T(X3.$$.fragment,Wa),Wa.forEach(t),li.forEach(t),Tio=i(c),Im=n(c,"H2",{class:!0});var Xmo=s(Im);z3=n(Xmo,"A",{id:!0,class:!0,href:!0});var Lha=s(z3);o7e=n(Lha,"SPAN",{});var yha=s(o7e);T(FR.$$.fragment,yha),yha.forEach(t),Lha.forEach(t),YSr=i(Xmo),r7e=n(Xmo,"SPAN",{});var xha=s(r7e);ZSr=r(xha,"AutoModelForVisualQuestionAnswering"),xha.forEach(t),Xmo.forEach(t),Mio=i(c),rr=n(c,"DIV",{class:!0});var ii=s(rr);T(TR.$$.fragment,ii),KSr=i(ii),Nm=n(ii,"P",{});var zfe=s(Nm);eRr=r(zfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),Bre=n(zfe,"A",{href:!0});var $ha=s(Bre);oRr=r($ha,"from_pretrained()"),$ha.forEach(t),rRr=r(zfe," class method or the "),Ire=n(zfe,"A",{href:!0});var kha=s(Ire);tRr=r(kha,"from_config()"),kha.forEach(t),aRr=r(zfe,` class
method.`),zfe.forEach(t),nRr=i(ii),MR=n(ii,"P",{});var zmo=s(MR);sRr=r(zmo,"This class cannot be instantiated directly using "),t7e=n(zmo,"CODE",{});var Sha=s(t7e);lRr=r(Sha,"__init__()"),Sha.forEach(t),iRr=r(zmo," (throws an error)."),zmo.forEach(t),dRr=i(ii),Vt=n(ii,"DIV",{class:!0});var qx=s(Vt);T(ER.$$.fragment,qx),mRr=i(qx),a7e=n(qx,"P",{});var Rha=s(a7e);cRr=r(Rha,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),Rha.forEach(t),fRr=i(qx),qm=n(qx,"P",{});var Qfe=s(qm);gRr=r(Qfe,`Note:
Loading a model from its configuration file does `),n7e=n(Qfe,"STRONG",{});var Pha=s(n7e);hRr=r(Pha,"not"),Pha.forEach(t),uRr=r(Qfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Nre=n(Qfe,"A",{href:!0});var Bha=s(Nre);pRr=r(Bha,"from_pretrained()"),Bha.forEach(t),_Rr=r(Qfe," to load the model weights."),Qfe.forEach(t),bRr=i(qx),T(Q3.$$.fragment,qx),qx.forEach(t),vRr=i(ii),Fo=n(ii,"DIV",{class:!0});var Ua=s(Fo);T(CR.$$.fragment,Ua),FRr=i(Ua),s7e=n(Ua,"P",{});var Iha=s(s7e);TRr=r(Iha,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),Iha.forEach(t),MRr=i(Ua),yn=n(Ua,"P",{});var jx=s(yn);ERr=r(jx,"The model class to instantiate is selected based on the "),l7e=n(jx,"CODE",{});var Nha=s(l7e);CRr=r(Nha,"model_type"),Nha.forEach(t),wRr=r(jx,` property of the config object (either
passed as an argument or loaded from `),i7e=n(jx,"CODE",{});var qha=s(i7e);ARr=r(qha,"pretrained_model_name_or_path"),qha.forEach(t),LRr=r(jx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d7e=n(jx,"CODE",{});var jha=s(d7e);yRr=r(jha,"pretrained_model_name_or_path"),jha.forEach(t),xRr=r(jx,":"),jx.forEach(t),$Rr=i(Ua),m7e=n(Ua,"UL",{});var Dha=s(m7e);W3=n(Dha,"LI",{});var reo=s(W3);c7e=n(reo,"STRONG",{});var Gha=s(c7e);kRr=r(Gha,"vilt"),Gha.forEach(t),SRr=r(reo," \u2014 "),qre=n(reo,"A",{href:!0});var Oha=s(qre);RRr=r(Oha,"ViltForQuestionAnswering"),Oha.forEach(t),PRr=r(reo," (ViLT model)"),reo.forEach(t),Dha.forEach(t),BRr=i(Ua),U3=n(Ua,"P",{});var teo=s(U3);IRr=r(teo,"The model is set in evaluation mode by default using "),f7e=n(teo,"CODE",{});var Vha=s(f7e);NRr=r(Vha,"model.eval()"),Vha.forEach(t),qRr=r(teo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),g7e=n(teo,"CODE",{});var Xha=s(g7e);jRr=r(Xha,"model.train()"),Xha.forEach(t),teo.forEach(t),DRr=i(Ua),T(H3.$$.fragment,Ua),Ua.forEach(t),ii.forEach(t),Eio=i(c),jm=n(c,"H2",{class:!0});var Qmo=s(jm);J3=n(Qmo,"A",{id:!0,class:!0,href:!0});var zha=s(J3);h7e=n(zha,"SPAN",{});var Qha=s(h7e);T(wR.$$.fragment,Qha),Qha.forEach(t),zha.forEach(t),GRr=i(Qmo),u7e=n(Qmo,"SPAN",{});var Wha=s(u7e);ORr=r(Wha,"AutoModelForAudioClassification"),Wha.forEach(t),Qmo.forEach(t),Cio=i(c),tr=n(c,"DIV",{class:!0});var di=s(tr);T(AR.$$.fragment,di),VRr=i(di),Dm=n(di,"P",{});var Wfe=s(Dm);XRr=r(Wfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),jre=n(Wfe,"A",{href:!0});var Uha=s(jre);zRr=r(Uha,"from_pretrained()"),Uha.forEach(t),QRr=r(Wfe," class method or the "),Dre=n(Wfe,"A",{href:!0});var Hha=s(Dre);WRr=r(Hha,"from_config()"),Hha.forEach(t),URr=r(Wfe,` class
method.`),Wfe.forEach(t),HRr=i(di),LR=n(di,"P",{});var Wmo=s(LR);JRr=r(Wmo,"This class cannot be instantiated directly using "),p7e=n(Wmo,"CODE",{});var Jha=s(p7e);YRr=r(Jha,"__init__()"),Jha.forEach(t),ZRr=r(Wmo," (throws an error)."),Wmo.forEach(t),KRr=i(di),Xt=n(di,"DIV",{class:!0});var Dx=s(Xt);T(yR.$$.fragment,Dx),ePr=i(Dx),_7e=n(Dx,"P",{});var Yha=s(_7e);oPr=r(Yha,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),Yha.forEach(t),rPr=i(Dx),Gm=n(Dx,"P",{});var Ufe=s(Gm);tPr=r(Ufe,`Note:
Loading a model from its configuration file does `),b7e=n(Ufe,"STRONG",{});var Zha=s(b7e);aPr=r(Zha,"not"),Zha.forEach(t),nPr=r(Ufe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Gre=n(Ufe,"A",{href:!0});var Kha=s(Gre);sPr=r(Kha,"from_pretrained()"),Kha.forEach(t),lPr=r(Ufe," to load the model weights."),Ufe.forEach(t),iPr=i(Dx),T(Y3.$$.fragment,Dx),Dx.forEach(t),dPr=i(di),To=n(di,"DIV",{class:!0});var Ha=s(To);T(xR.$$.fragment,Ha),mPr=i(Ha),v7e=n(Ha,"P",{});var eua=s(v7e);cPr=r(eua,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),eua.forEach(t),fPr=i(Ha),xn=n(Ha,"P",{});var Gx=s(xn);gPr=r(Gx,"The model class to instantiate is selected based on the "),F7e=n(Gx,"CODE",{});var oua=s(F7e);hPr=r(oua,"model_type"),oua.forEach(t),uPr=r(Gx,` property of the config object (either
passed as an argument or loaded from `),T7e=n(Gx,"CODE",{});var rua=s(T7e);pPr=r(rua,"pretrained_model_name_or_path"),rua.forEach(t),_Pr=r(Gx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M7e=n(Gx,"CODE",{});var tua=s(M7e);bPr=r(tua,"pretrained_model_name_or_path"),tua.forEach(t),vPr=r(Gx,":"),Gx.forEach(t),FPr=i(Ha),Ne=n(Ha,"UL",{});var Je=s(Ne);Z3=n(Je,"LI",{});var aeo=s(Z3);E7e=n(aeo,"STRONG",{});var aua=s(E7e);TPr=r(aua,"data2vec-audio"),aua.forEach(t),MPr=r(aeo," \u2014 "),Ore=n(aeo,"A",{href:!0});var nua=s(Ore);EPr=r(nua,"Data2VecAudioForSequenceClassification"),nua.forEach(t),CPr=r(aeo," (Data2VecAudio model)"),aeo.forEach(t),wPr=i(Je),K3=n(Je,"LI",{});var neo=s(K3);C7e=n(neo,"STRONG",{});var sua=s(C7e);APr=r(sua,"hubert"),sua.forEach(t),LPr=r(neo," \u2014 "),Vre=n(neo,"A",{href:!0});var lua=s(Vre);yPr=r(lua,"HubertForSequenceClassification"),lua.forEach(t),xPr=r(neo," (Hubert model)"),neo.forEach(t),$Pr=i(Je),e5=n(Je,"LI",{});var seo=s(e5);w7e=n(seo,"STRONG",{});var iua=s(w7e);kPr=r(iua,"sew"),iua.forEach(t),SPr=r(seo," \u2014 "),Xre=n(seo,"A",{href:!0});var dua=s(Xre);RPr=r(dua,"SEWForSequenceClassification"),dua.forEach(t),PPr=r(seo," (SEW model)"),seo.forEach(t),BPr=i(Je),o5=n(Je,"LI",{});var leo=s(o5);A7e=n(leo,"STRONG",{});var mua=s(A7e);IPr=r(mua,"sew-d"),mua.forEach(t),NPr=r(leo," \u2014 "),zre=n(leo,"A",{href:!0});var cua=s(zre);qPr=r(cua,"SEWDForSequenceClassification"),cua.forEach(t),jPr=r(leo," (SEW-D model)"),leo.forEach(t),DPr=i(Je),r5=n(Je,"LI",{});var ieo=s(r5);L7e=n(ieo,"STRONG",{});var fua=s(L7e);GPr=r(fua,"unispeech"),fua.forEach(t),OPr=r(ieo," \u2014 "),Qre=n(ieo,"A",{href:!0});var gua=s(Qre);VPr=r(gua,"UniSpeechForSequenceClassification"),gua.forEach(t),XPr=r(ieo," (UniSpeech model)"),ieo.forEach(t),zPr=i(Je),t5=n(Je,"LI",{});var deo=s(t5);y7e=n(deo,"STRONG",{});var hua=s(y7e);QPr=r(hua,"unispeech-sat"),hua.forEach(t),WPr=r(deo," \u2014 "),Wre=n(deo,"A",{href:!0});var uua=s(Wre);UPr=r(uua,"UniSpeechSatForSequenceClassification"),uua.forEach(t),HPr=r(deo," (UniSpeechSat model)"),deo.forEach(t),JPr=i(Je),a5=n(Je,"LI",{});var meo=s(a5);x7e=n(meo,"STRONG",{});var pua=s(x7e);YPr=r(pua,"wav2vec2"),pua.forEach(t),ZPr=r(meo," \u2014 "),Ure=n(meo,"A",{href:!0});var _ua=s(Ure);KPr=r(_ua,"Wav2Vec2ForSequenceClassification"),_ua.forEach(t),eBr=r(meo," (Wav2Vec2 model)"),meo.forEach(t),oBr=i(Je),n5=n(Je,"LI",{});var ceo=s(n5);$7e=n(ceo,"STRONG",{});var bua=s($7e);rBr=r(bua,"wav2vec2-conformer"),bua.forEach(t),tBr=r(ceo," \u2014 "),Hre=n(ceo,"A",{href:!0});var vua=s(Hre);aBr=r(vua,"Wav2Vec2ConformerForSequenceClassification"),vua.forEach(t),nBr=r(ceo," (Wav2Vec2-Conformer model)"),ceo.forEach(t),sBr=i(Je),s5=n(Je,"LI",{});var feo=s(s5);k7e=n(feo,"STRONG",{});var Fua=s(k7e);lBr=r(Fua,"wavlm"),Fua.forEach(t),iBr=r(feo," \u2014 "),Jre=n(feo,"A",{href:!0});var Tua=s(Jre);dBr=r(Tua,"WavLMForSequenceClassification"),Tua.forEach(t),mBr=r(feo," (WavLM model)"),feo.forEach(t),Je.forEach(t),cBr=i(Ha),l5=n(Ha,"P",{});var geo=s(l5);fBr=r(geo,"The model is set in evaluation mode by default using "),S7e=n(geo,"CODE",{});var Mua=s(S7e);gBr=r(Mua,"model.eval()"),Mua.forEach(t),hBr=r(geo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),R7e=n(geo,"CODE",{});var Eua=s(R7e);uBr=r(Eua,"model.train()"),Eua.forEach(t),geo.forEach(t),pBr=i(Ha),T(i5.$$.fragment,Ha),Ha.forEach(t),di.forEach(t),wio=i(c),Om=n(c,"H2",{class:!0});var Umo=s(Om);d5=n(Umo,"A",{id:!0,class:!0,href:!0});var Cua=s(d5);P7e=n(Cua,"SPAN",{});var wua=s(P7e);T($R.$$.fragment,wua),wua.forEach(t),Cua.forEach(t),_Br=i(Umo),B7e=n(Umo,"SPAN",{});var Aua=s(B7e);bBr=r(Aua,"AutoModelForAudioFrameClassification"),Aua.forEach(t),Umo.forEach(t),Aio=i(c),ar=n(c,"DIV",{class:!0});var mi=s(ar);T(kR.$$.fragment,mi),vBr=i(mi),Vm=n(mi,"P",{});var Hfe=s(Vm);FBr=r(Hfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),Yre=n(Hfe,"A",{href:!0});var Lua=s(Yre);TBr=r(Lua,"from_pretrained()"),Lua.forEach(t),MBr=r(Hfe," class method or the "),Zre=n(Hfe,"A",{href:!0});var yua=s(Zre);EBr=r(yua,"from_config()"),yua.forEach(t),CBr=r(Hfe,` class
method.`),Hfe.forEach(t),wBr=i(mi),SR=n(mi,"P",{});var Hmo=s(SR);ABr=r(Hmo,"This class cannot be instantiated directly using "),I7e=n(Hmo,"CODE",{});var xua=s(I7e);LBr=r(xua,"__init__()"),xua.forEach(t),yBr=r(Hmo," (throws an error)."),Hmo.forEach(t),xBr=i(mi),zt=n(mi,"DIV",{class:!0});var Ox=s(zt);T(RR.$$.fragment,Ox),$Br=i(Ox),N7e=n(Ox,"P",{});var $ua=s(N7e);kBr=r($ua,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),$ua.forEach(t),SBr=i(Ox),Xm=n(Ox,"P",{});var Jfe=s(Xm);RBr=r(Jfe,`Note:
Loading a model from its configuration file does `),q7e=n(Jfe,"STRONG",{});var kua=s(q7e);PBr=r(kua,"not"),kua.forEach(t),BBr=r(Jfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Kre=n(Jfe,"A",{href:!0});var Sua=s(Kre);IBr=r(Sua,"from_pretrained()"),Sua.forEach(t),NBr=r(Jfe," to load the model weights."),Jfe.forEach(t),qBr=i(Ox),T(m5.$$.fragment,Ox),Ox.forEach(t),jBr=i(mi),Mo=n(mi,"DIV",{class:!0});var Ja=s(Mo);T(PR.$$.fragment,Ja),DBr=i(Ja),j7e=n(Ja,"P",{});var Rua=s(j7e);GBr=r(Rua,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),Rua.forEach(t),OBr=i(Ja),$n=n(Ja,"P",{});var Vx=s($n);VBr=r(Vx,"The model class to instantiate is selected based on the "),D7e=n(Vx,"CODE",{});var Pua=s(D7e);XBr=r(Pua,"model_type"),Pua.forEach(t),zBr=r(Vx,` property of the config object (either
passed as an argument or loaded from `),G7e=n(Vx,"CODE",{});var Bua=s(G7e);QBr=r(Bua,"pretrained_model_name_or_path"),Bua.forEach(t),WBr=r(Vx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O7e=n(Vx,"CODE",{});var Iua=s(O7e);UBr=r(Iua,"pretrained_model_name_or_path"),Iua.forEach(t),HBr=r(Vx,":"),Vx.forEach(t),JBr=i(Ja),vt=n(Ja,"UL",{});var ci=s(vt);c5=n(ci,"LI",{});var heo=s(c5);V7e=n(heo,"STRONG",{});var Nua=s(V7e);YBr=r(Nua,"data2vec-audio"),Nua.forEach(t),ZBr=r(heo," \u2014 "),ete=n(heo,"A",{href:!0});var qua=s(ete);KBr=r(qua,"Data2VecAudioForAudioFrameClassification"),qua.forEach(t),eIr=r(heo," (Data2VecAudio model)"),heo.forEach(t),oIr=i(ci),f5=n(ci,"LI",{});var ueo=s(f5);X7e=n(ueo,"STRONG",{});var jua=s(X7e);rIr=r(jua,"unispeech-sat"),jua.forEach(t),tIr=r(ueo," \u2014 "),ote=n(ueo,"A",{href:!0});var Dua=s(ote);aIr=r(Dua,"UniSpeechSatForAudioFrameClassification"),Dua.forEach(t),nIr=r(ueo," (UniSpeechSat model)"),ueo.forEach(t),sIr=i(ci),g5=n(ci,"LI",{});var peo=s(g5);z7e=n(peo,"STRONG",{});var Gua=s(z7e);lIr=r(Gua,"wav2vec2"),Gua.forEach(t),iIr=r(peo," \u2014 "),rte=n(peo,"A",{href:!0});var Oua=s(rte);dIr=r(Oua,"Wav2Vec2ForAudioFrameClassification"),Oua.forEach(t),mIr=r(peo," (Wav2Vec2 model)"),peo.forEach(t),cIr=i(ci),h5=n(ci,"LI",{});var _eo=s(h5);Q7e=n(_eo,"STRONG",{});var Vua=s(Q7e);fIr=r(Vua,"wav2vec2-conformer"),Vua.forEach(t),gIr=r(_eo," \u2014 "),tte=n(_eo,"A",{href:!0});var Xua=s(tte);hIr=r(Xua,"Wav2Vec2ConformerForAudioFrameClassification"),Xua.forEach(t),uIr=r(_eo," (Wav2Vec2-Conformer model)"),_eo.forEach(t),pIr=i(ci),u5=n(ci,"LI",{});var beo=s(u5);W7e=n(beo,"STRONG",{});var zua=s(W7e);_Ir=r(zua,"wavlm"),zua.forEach(t),bIr=r(beo," \u2014 "),ate=n(beo,"A",{href:!0});var Qua=s(ate);vIr=r(Qua,"WavLMForAudioFrameClassification"),Qua.forEach(t),FIr=r(beo," (WavLM model)"),beo.forEach(t),ci.forEach(t),TIr=i(Ja),p5=n(Ja,"P",{});var veo=s(p5);MIr=r(veo,"The model is set in evaluation mode by default using "),U7e=n(veo,"CODE",{});var Wua=s(U7e);EIr=r(Wua,"model.eval()"),Wua.forEach(t),CIr=r(veo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),H7e=n(veo,"CODE",{});var Uua=s(H7e);wIr=r(Uua,"model.train()"),Uua.forEach(t),veo.forEach(t),AIr=i(Ja),T(_5.$$.fragment,Ja),Ja.forEach(t),mi.forEach(t),Lio=i(c),zm=n(c,"H2",{class:!0});var Jmo=s(zm);b5=n(Jmo,"A",{id:!0,class:!0,href:!0});var Hua=s(b5);J7e=n(Hua,"SPAN",{});var Jua=s(J7e);T(BR.$$.fragment,Jua),Jua.forEach(t),Hua.forEach(t),LIr=i(Jmo),Y7e=n(Jmo,"SPAN",{});var Yua=s(Y7e);yIr=r(Yua,"AutoModelForCTC"),Yua.forEach(t),Jmo.forEach(t),yio=i(c),nr=n(c,"DIV",{class:!0});var fi=s(nr);T(IR.$$.fragment,fi),xIr=i(fi),Qm=n(fi,"P",{});var Yfe=s(Qm);$Ir=r(Yfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),nte=n(Yfe,"A",{href:!0});var Zua=s(nte);kIr=r(Zua,"from_pretrained()"),Zua.forEach(t),SIr=r(Yfe," class method or the "),ste=n(Yfe,"A",{href:!0});var Kua=s(ste);RIr=r(Kua,"from_config()"),Kua.forEach(t),PIr=r(Yfe,` class
method.`),Yfe.forEach(t),BIr=i(fi),NR=n(fi,"P",{});var Ymo=s(NR);IIr=r(Ymo,"This class cannot be instantiated directly using "),Z7e=n(Ymo,"CODE",{});var epa=s(Z7e);NIr=r(epa,"__init__()"),epa.forEach(t),qIr=r(Ymo," (throws an error)."),Ymo.forEach(t),jIr=i(fi),Qt=n(fi,"DIV",{class:!0});var Xx=s(Qt);T(qR.$$.fragment,Xx),DIr=i(Xx),K7e=n(Xx,"P",{});var opa=s(K7e);GIr=r(opa,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),opa.forEach(t),OIr=i(Xx),Wm=n(Xx,"P",{});var Zfe=s(Wm);VIr=r(Zfe,`Note:
Loading a model from its configuration file does `),e8e=n(Zfe,"STRONG",{});var rpa=s(e8e);XIr=r(rpa,"not"),rpa.forEach(t),zIr=r(Zfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),lte=n(Zfe,"A",{href:!0});var tpa=s(lte);QIr=r(tpa,"from_pretrained()"),tpa.forEach(t),WIr=r(Zfe," to load the model weights."),Zfe.forEach(t),UIr=i(Xx),T(v5.$$.fragment,Xx),Xx.forEach(t),HIr=i(fi),Eo=n(fi,"DIV",{class:!0});var Ya=s(Eo);T(jR.$$.fragment,Ya),JIr=i(Ya),o8e=n(Ya,"P",{});var apa=s(o8e);YIr=r(apa,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),apa.forEach(t),ZIr=i(Ya),kn=n(Ya,"P",{});var zx=s(kn);KIr=r(zx,"The model class to instantiate is selected based on the "),r8e=n(zx,"CODE",{});var npa=s(r8e);eNr=r(npa,"model_type"),npa.forEach(t),oNr=r(zx,` property of the config object (either
passed as an argument or loaded from `),t8e=n(zx,"CODE",{});var spa=s(t8e);rNr=r(spa,"pretrained_model_name_or_path"),spa.forEach(t),tNr=r(zx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a8e=n(zx,"CODE",{});var lpa=s(a8e);aNr=r(lpa,"pretrained_model_name_or_path"),lpa.forEach(t),nNr=r(zx,":"),zx.forEach(t),sNr=i(Ya),xe=n(Ya,"UL",{});var qe=s(xe);F5=n(qe,"LI",{});var Feo=s(F5);n8e=n(Feo,"STRONG",{});var ipa=s(n8e);lNr=r(ipa,"data2vec-audio"),ipa.forEach(t),iNr=r(Feo," \u2014 "),ite=n(Feo,"A",{href:!0});var dpa=s(ite);dNr=r(dpa,"Data2VecAudioForCTC"),dpa.forEach(t),mNr=r(Feo," (Data2VecAudio model)"),Feo.forEach(t),cNr=i(qe),T5=n(qe,"LI",{});var Teo=s(T5);s8e=n(Teo,"STRONG",{});var mpa=s(s8e);fNr=r(mpa,"hubert"),mpa.forEach(t),gNr=r(Teo," \u2014 "),dte=n(Teo,"A",{href:!0});var cpa=s(dte);hNr=r(cpa,"HubertForCTC"),cpa.forEach(t),uNr=r(Teo," (Hubert model)"),Teo.forEach(t),pNr=i(qe),M5=n(qe,"LI",{});var Meo=s(M5);l8e=n(Meo,"STRONG",{});var fpa=s(l8e);_Nr=r(fpa,"mctct"),fpa.forEach(t),bNr=r(Meo," \u2014 "),mte=n(Meo,"A",{href:!0});var gpa=s(mte);vNr=r(gpa,"MCTCTForCTC"),gpa.forEach(t),FNr=r(Meo," (M-CTC-T model)"),Meo.forEach(t),TNr=i(qe),E5=n(qe,"LI",{});var Eeo=s(E5);i8e=n(Eeo,"STRONG",{});var hpa=s(i8e);MNr=r(hpa,"sew"),hpa.forEach(t),ENr=r(Eeo," \u2014 "),cte=n(Eeo,"A",{href:!0});var upa=s(cte);CNr=r(upa,"SEWForCTC"),upa.forEach(t),wNr=r(Eeo," (SEW model)"),Eeo.forEach(t),ANr=i(qe),C5=n(qe,"LI",{});var Ceo=s(C5);d8e=n(Ceo,"STRONG",{});var ppa=s(d8e);LNr=r(ppa,"sew-d"),ppa.forEach(t),yNr=r(Ceo," \u2014 "),fte=n(Ceo,"A",{href:!0});var _pa=s(fte);xNr=r(_pa,"SEWDForCTC"),_pa.forEach(t),$Nr=r(Ceo," (SEW-D model)"),Ceo.forEach(t),kNr=i(qe),w5=n(qe,"LI",{});var weo=s(w5);m8e=n(weo,"STRONG",{});var bpa=s(m8e);SNr=r(bpa,"unispeech"),bpa.forEach(t),RNr=r(weo," \u2014 "),gte=n(weo,"A",{href:!0});var vpa=s(gte);PNr=r(vpa,"UniSpeechForCTC"),vpa.forEach(t),BNr=r(weo," (UniSpeech model)"),weo.forEach(t),INr=i(qe),A5=n(qe,"LI",{});var Aeo=s(A5);c8e=n(Aeo,"STRONG",{});var Fpa=s(c8e);NNr=r(Fpa,"unispeech-sat"),Fpa.forEach(t),qNr=r(Aeo," \u2014 "),hte=n(Aeo,"A",{href:!0});var Tpa=s(hte);jNr=r(Tpa,"UniSpeechSatForCTC"),Tpa.forEach(t),DNr=r(Aeo," (UniSpeechSat model)"),Aeo.forEach(t),GNr=i(qe),L5=n(qe,"LI",{});var Leo=s(L5);f8e=n(Leo,"STRONG",{});var Mpa=s(f8e);ONr=r(Mpa,"wav2vec2"),Mpa.forEach(t),VNr=r(Leo," \u2014 "),ute=n(Leo,"A",{href:!0});var Epa=s(ute);XNr=r(Epa,"Wav2Vec2ForCTC"),Epa.forEach(t),zNr=r(Leo," (Wav2Vec2 model)"),Leo.forEach(t),QNr=i(qe),y5=n(qe,"LI",{});var yeo=s(y5);g8e=n(yeo,"STRONG",{});var Cpa=s(g8e);WNr=r(Cpa,"wav2vec2-conformer"),Cpa.forEach(t),UNr=r(yeo," \u2014 "),pte=n(yeo,"A",{href:!0});var wpa=s(pte);HNr=r(wpa,"Wav2Vec2ConformerForCTC"),wpa.forEach(t),JNr=r(yeo," (Wav2Vec2-Conformer model)"),yeo.forEach(t),YNr=i(qe),x5=n(qe,"LI",{});var xeo=s(x5);h8e=n(xeo,"STRONG",{});var Apa=s(h8e);ZNr=r(Apa,"wavlm"),Apa.forEach(t),KNr=r(xeo," \u2014 "),_te=n(xeo,"A",{href:!0});var Lpa=s(_te);eqr=r(Lpa,"WavLMForCTC"),Lpa.forEach(t),oqr=r(xeo," (WavLM model)"),xeo.forEach(t),qe.forEach(t),rqr=i(Ya),$5=n(Ya,"P",{});var $eo=s($5);tqr=r($eo,"The model is set in evaluation mode by default using "),u8e=n($eo,"CODE",{});var ypa=s(u8e);aqr=r(ypa,"model.eval()"),ypa.forEach(t),nqr=r($eo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),p8e=n($eo,"CODE",{});var xpa=s(p8e);sqr=r(xpa,"model.train()"),xpa.forEach(t),$eo.forEach(t),lqr=i(Ya),T(k5.$$.fragment,Ya),Ya.forEach(t),fi.forEach(t),xio=i(c),Um=n(c,"H2",{class:!0});var Zmo=s(Um);S5=n(Zmo,"A",{id:!0,class:!0,href:!0});var $pa=s(S5);_8e=n($pa,"SPAN",{});var kpa=s(_8e);T(DR.$$.fragment,kpa),kpa.forEach(t),$pa.forEach(t),iqr=i(Zmo),b8e=n(Zmo,"SPAN",{});var Spa=s(b8e);dqr=r(Spa,"AutoModelForSpeechSeq2Seq"),Spa.forEach(t),Zmo.forEach(t),$io=i(c),sr=n(c,"DIV",{class:!0});var gi=s(sr);T(GR.$$.fragment,gi),mqr=i(gi),Hm=n(gi,"P",{});var Kfe=s(Hm);cqr=r(Kfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),bte=n(Kfe,"A",{href:!0});var Rpa=s(bte);fqr=r(Rpa,"from_pretrained()"),Rpa.forEach(t),gqr=r(Kfe," class method or the "),vte=n(Kfe,"A",{href:!0});var Ppa=s(vte);hqr=r(Ppa,"from_config()"),Ppa.forEach(t),uqr=r(Kfe,` class
method.`),Kfe.forEach(t),pqr=i(gi),OR=n(gi,"P",{});var Kmo=s(OR);_qr=r(Kmo,"This class cannot be instantiated directly using "),v8e=n(Kmo,"CODE",{});var Bpa=s(v8e);bqr=r(Bpa,"__init__()"),Bpa.forEach(t),vqr=r(Kmo," (throws an error)."),Kmo.forEach(t),Fqr=i(gi),Wt=n(gi,"DIV",{class:!0});var Qx=s(Wt);T(VR.$$.fragment,Qx),Tqr=i(Qx),F8e=n(Qx,"P",{});var Ipa=s(F8e);Mqr=r(Ipa,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Ipa.forEach(t),Eqr=i(Qx),Jm=n(Qx,"P",{});var ege=s(Jm);Cqr=r(ege,`Note:
Loading a model from its configuration file does `),T8e=n(ege,"STRONG",{});var Npa=s(T8e);wqr=r(Npa,"not"),Npa.forEach(t),Aqr=r(ege,` load the model weights. It only affects the
model\u2019s configuration. Use `),Fte=n(ege,"A",{href:!0});var qpa=s(Fte);Lqr=r(qpa,"from_pretrained()"),qpa.forEach(t),yqr=r(ege," to load the model weights."),ege.forEach(t),xqr=i(Qx),T(R5.$$.fragment,Qx),Qx.forEach(t),$qr=i(gi),Co=n(gi,"DIV",{class:!0});var Za=s(Co);T(XR.$$.fragment,Za),kqr=i(Za),M8e=n(Za,"P",{});var jpa=s(M8e);Sqr=r(jpa,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),jpa.forEach(t),Rqr=i(Za),Sn=n(Za,"P",{});var Wx=s(Sn);Pqr=r(Wx,"The model class to instantiate is selected based on the "),E8e=n(Wx,"CODE",{});var Dpa=s(E8e);Bqr=r(Dpa,"model_type"),Dpa.forEach(t),Iqr=r(Wx,` property of the config object (either
passed as an argument or loaded from `),C8e=n(Wx,"CODE",{});var Gpa=s(C8e);Nqr=r(Gpa,"pretrained_model_name_or_path"),Gpa.forEach(t),qqr=r(Wx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),w8e=n(Wx,"CODE",{});var Opa=s(w8e);jqr=r(Opa,"pretrained_model_name_or_path"),Opa.forEach(t),Dqr=r(Wx,":"),Wx.forEach(t),Gqr=i(Za),Ym=n(Za,"UL",{});var oge=s(Ym);P5=n(oge,"LI",{});var keo=s(P5);A8e=n(keo,"STRONG",{});var Vpa=s(A8e);Oqr=r(Vpa,"speech-encoder-decoder"),Vpa.forEach(t),Vqr=r(keo," \u2014 "),Tte=n(keo,"A",{href:!0});var Xpa=s(Tte);Xqr=r(Xpa,"SpeechEncoderDecoderModel"),Xpa.forEach(t),zqr=r(keo," (Speech Encoder decoder model)"),keo.forEach(t),Qqr=i(oge),B5=n(oge,"LI",{});var Seo=s(B5);L8e=n(Seo,"STRONG",{});var zpa=s(L8e);Wqr=r(zpa,"speech_to_text"),zpa.forEach(t),Uqr=r(Seo," \u2014 "),Mte=n(Seo,"A",{href:!0});var Qpa=s(Mte);Hqr=r(Qpa,"Speech2TextForConditionalGeneration"),Qpa.forEach(t),Jqr=r(Seo," (Speech2Text model)"),Seo.forEach(t),Yqr=i(oge),I5=n(oge,"LI",{});var Reo=s(I5);y8e=n(Reo,"STRONG",{});var Wpa=s(y8e);Zqr=r(Wpa,"whisper"),Wpa.forEach(t),Kqr=r(Reo," \u2014 "),Ete=n(Reo,"A",{href:!0});var Upa=s(Ete);ejr=r(Upa,"WhisperForConditionalGeneration"),Upa.forEach(t),ojr=r(Reo," (Whisper model)"),Reo.forEach(t),oge.forEach(t),rjr=i(Za),N5=n(Za,"P",{});var Peo=s(N5);tjr=r(Peo,"The model is set in evaluation mode by default using "),x8e=n(Peo,"CODE",{});var Hpa=s(x8e);ajr=r(Hpa,"model.eval()"),Hpa.forEach(t),njr=r(Peo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$8e=n(Peo,"CODE",{});var Jpa=s($8e);sjr=r(Jpa,"model.train()"),Jpa.forEach(t),Peo.forEach(t),ljr=i(Za),T(q5.$$.fragment,Za),Za.forEach(t),gi.forEach(t),kio=i(c),Zm=n(c,"H2",{class:!0});var eco=s(Zm);j5=n(eco,"A",{id:!0,class:!0,href:!0});var Ypa=s(j5);k8e=n(Ypa,"SPAN",{});var Zpa=s(k8e);T(zR.$$.fragment,Zpa),Zpa.forEach(t),Ypa.forEach(t),ijr=i(eco),S8e=n(eco,"SPAN",{});var Kpa=s(S8e);djr=r(Kpa,"AutoModelForAudioXVector"),Kpa.forEach(t),eco.forEach(t),Sio=i(c),lr=n(c,"DIV",{class:!0});var hi=s(lr);T(QR.$$.fragment,hi),mjr=i(hi),Km=n(hi,"P",{});var rge=s(Km);cjr=r(rge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),Cte=n(rge,"A",{href:!0});var e_a=s(Cte);fjr=r(e_a,"from_pretrained()"),e_a.forEach(t),gjr=r(rge," class method or the "),wte=n(rge,"A",{href:!0});var o_a=s(wte);hjr=r(o_a,"from_config()"),o_a.forEach(t),ujr=r(rge,` class
method.`),rge.forEach(t),pjr=i(hi),WR=n(hi,"P",{});var oco=s(WR);_jr=r(oco,"This class cannot be instantiated directly using "),R8e=n(oco,"CODE",{});var r_a=s(R8e);bjr=r(r_a,"__init__()"),r_a.forEach(t),vjr=r(oco," (throws an error)."),oco.forEach(t),Fjr=i(hi),Ut=n(hi,"DIV",{class:!0});var Ux=s(Ut);T(UR.$$.fragment,Ux),Tjr=i(Ux),P8e=n(Ux,"P",{});var t_a=s(P8e);Mjr=r(t_a,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),t_a.forEach(t),Ejr=i(Ux),ec=n(Ux,"P",{});var tge=s(ec);Cjr=r(tge,`Note:
Loading a model from its configuration file does `),B8e=n(tge,"STRONG",{});var a_a=s(B8e);wjr=r(a_a,"not"),a_a.forEach(t),Ajr=r(tge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ate=n(tge,"A",{href:!0});var n_a=s(Ate);Ljr=r(n_a,"from_pretrained()"),n_a.forEach(t),yjr=r(tge," to load the model weights."),tge.forEach(t),xjr=i(Ux),T(D5.$$.fragment,Ux),Ux.forEach(t),$jr=i(hi),wo=n(hi,"DIV",{class:!0});var Ka=s(wo);T(HR.$$.fragment,Ka),kjr=i(Ka),I8e=n(Ka,"P",{});var s_a=s(I8e);Sjr=r(s_a,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),s_a.forEach(t),Rjr=i(Ka),Rn=n(Ka,"P",{});var Hx=s(Rn);Pjr=r(Hx,"The model class to instantiate is selected based on the "),N8e=n(Hx,"CODE",{});var l_a=s(N8e);Bjr=r(l_a,"model_type"),l_a.forEach(t),Ijr=r(Hx,` property of the config object (either
passed as an argument or loaded from `),q8e=n(Hx,"CODE",{});var i_a=s(q8e);Njr=r(i_a,"pretrained_model_name_or_path"),i_a.forEach(t),qjr=r(Hx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j8e=n(Hx,"CODE",{});var d_a=s(j8e);jjr=r(d_a,"pretrained_model_name_or_path"),d_a.forEach(t),Djr=r(Hx,":"),Hx.forEach(t),Gjr=i(Ka),Ft=n(Ka,"UL",{});var ui=s(Ft);G5=n(ui,"LI",{});var Beo=s(G5);D8e=n(Beo,"STRONG",{});var m_a=s(D8e);Ojr=r(m_a,"data2vec-audio"),m_a.forEach(t),Vjr=r(Beo," \u2014 "),Lte=n(Beo,"A",{href:!0});var c_a=s(Lte);Xjr=r(c_a,"Data2VecAudioForXVector"),c_a.forEach(t),zjr=r(Beo," (Data2VecAudio model)"),Beo.forEach(t),Qjr=i(ui),O5=n(ui,"LI",{});var Ieo=s(O5);G8e=n(Ieo,"STRONG",{});var f_a=s(G8e);Wjr=r(f_a,"unispeech-sat"),f_a.forEach(t),Ujr=r(Ieo," \u2014 "),yte=n(Ieo,"A",{href:!0});var g_a=s(yte);Hjr=r(g_a,"UniSpeechSatForXVector"),g_a.forEach(t),Jjr=r(Ieo," (UniSpeechSat model)"),Ieo.forEach(t),Yjr=i(ui),V5=n(ui,"LI",{});var Neo=s(V5);O8e=n(Neo,"STRONG",{});var h_a=s(O8e);Zjr=r(h_a,"wav2vec2"),h_a.forEach(t),Kjr=r(Neo," \u2014 "),xte=n(Neo,"A",{href:!0});var u_a=s(xte);eDr=r(u_a,"Wav2Vec2ForXVector"),u_a.forEach(t),oDr=r(Neo," (Wav2Vec2 model)"),Neo.forEach(t),rDr=i(ui),X5=n(ui,"LI",{});var qeo=s(X5);V8e=n(qeo,"STRONG",{});var p_a=s(V8e);tDr=r(p_a,"wav2vec2-conformer"),p_a.forEach(t),aDr=r(qeo," \u2014 "),$te=n(qeo,"A",{href:!0});var __a=s($te);nDr=r(__a,"Wav2Vec2ConformerForXVector"),__a.forEach(t),sDr=r(qeo," (Wav2Vec2-Conformer model)"),qeo.forEach(t),lDr=i(ui),z5=n(ui,"LI",{});var jeo=s(z5);X8e=n(jeo,"STRONG",{});var b_a=s(X8e);iDr=r(b_a,"wavlm"),b_a.forEach(t),dDr=r(jeo," \u2014 "),kte=n(jeo,"A",{href:!0});var v_a=s(kte);mDr=r(v_a,"WavLMForXVector"),v_a.forEach(t),cDr=r(jeo," (WavLM model)"),jeo.forEach(t),ui.forEach(t),fDr=i(Ka),Q5=n(Ka,"P",{});var Deo=s(Q5);gDr=r(Deo,"The model is set in evaluation mode by default using "),z8e=n(Deo,"CODE",{});var F_a=s(z8e);hDr=r(F_a,"model.eval()"),F_a.forEach(t),uDr=r(Deo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Q8e=n(Deo,"CODE",{});var T_a=s(Q8e);pDr=r(T_a,"model.train()"),T_a.forEach(t),Deo.forEach(t),_Dr=i(Ka),T(W5.$$.fragment,Ka),Ka.forEach(t),hi.forEach(t),Rio=i(c),oc=n(c,"H2",{class:!0});var rco=s(oc);U5=n(rco,"A",{id:!0,class:!0,href:!0});var M_a=s(U5);W8e=n(M_a,"SPAN",{});var E_a=s(W8e);T(JR.$$.fragment,E_a),E_a.forEach(t),M_a.forEach(t),bDr=i(rco),U8e=n(rco,"SPAN",{});var C_a=s(U8e);vDr=r(C_a,"AutoModelForMaskedImageModeling"),C_a.forEach(t),rco.forEach(t),Pio=i(c),ir=n(c,"DIV",{class:!0});var pi=s(ir);T(YR.$$.fragment,pi),FDr=i(pi),rc=n(pi,"P",{});var age=s(rc);TDr=r(age,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),Ste=n(age,"A",{href:!0});var w_a=s(Ste);MDr=r(w_a,"from_pretrained()"),w_a.forEach(t),EDr=r(age," class method or the "),Rte=n(age,"A",{href:!0});var A_a=s(Rte);CDr=r(A_a,"from_config()"),A_a.forEach(t),wDr=r(age,` class
method.`),age.forEach(t),ADr=i(pi),ZR=n(pi,"P",{});var tco=s(ZR);LDr=r(tco,"This class cannot be instantiated directly using "),H8e=n(tco,"CODE",{});var L_a=s(H8e);yDr=r(L_a,"__init__()"),L_a.forEach(t),xDr=r(tco," (throws an error)."),tco.forEach(t),$Dr=i(pi),Ht=n(pi,"DIV",{class:!0});var Jx=s(Ht);T(KR.$$.fragment,Jx),kDr=i(Jx),J8e=n(Jx,"P",{});var y_a=s(J8e);SDr=r(y_a,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),y_a.forEach(t),RDr=i(Jx),tc=n(Jx,"P",{});var nge=s(tc);PDr=r(nge,`Note:
Loading a model from its configuration file does `),Y8e=n(nge,"STRONG",{});var x_a=s(Y8e);BDr=r(x_a,"not"),x_a.forEach(t),IDr=r(nge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Pte=n(nge,"A",{href:!0});var $_a=s(Pte);NDr=r($_a,"from_pretrained()"),$_a.forEach(t),qDr=r(nge," to load the model weights."),nge.forEach(t),jDr=i(Jx),T(H5.$$.fragment,Jx),Jx.forEach(t),DDr=i(pi),Ao=n(pi,"DIV",{class:!0});var en=s(Ao);T(eP.$$.fragment,en),GDr=i(en),Z8e=n(en,"P",{});var k_a=s(Z8e);ODr=r(k_a,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),k_a.forEach(t),VDr=i(en),Pn=n(en,"P",{});var Yx=s(Pn);XDr=r(Yx,"The model class to instantiate is selected based on the "),K8e=n(Yx,"CODE",{});var S_a=s(K8e);zDr=r(S_a,"model_type"),S_a.forEach(t),QDr=r(Yx,` property of the config object (either
passed as an argument or loaded from `),eLe=n(Yx,"CODE",{});var R_a=s(eLe);WDr=r(R_a,"pretrained_model_name_or_path"),R_a.forEach(t),UDr=r(Yx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oLe=n(Yx,"CODE",{});var P_a=s(oLe);HDr=r(P_a,"pretrained_model_name_or_path"),P_a.forEach(t),JDr=r(Yx,":"),Yx.forEach(t),YDr=i(en),Bn=n(en,"UL",{});var Zx=s(Bn);J5=n(Zx,"LI",{});var Geo=s(J5);rLe=n(Geo,"STRONG",{});var B_a=s(rLe);ZDr=r(B_a,"deit"),B_a.forEach(t),KDr=r(Geo," \u2014 "),Bte=n(Geo,"A",{href:!0});var I_a=s(Bte);eGr=r(I_a,"DeiTForMaskedImageModeling"),I_a.forEach(t),oGr=r(Geo," (DeiT model)"),Geo.forEach(t),rGr=i(Zx),Y5=n(Zx,"LI",{});var Oeo=s(Y5);tLe=n(Oeo,"STRONG",{});var N_a=s(tLe);tGr=r(N_a,"swin"),N_a.forEach(t),aGr=r(Oeo," \u2014 "),Ite=n(Oeo,"A",{href:!0});var q_a=s(Ite);nGr=r(q_a,"SwinForMaskedImageModeling"),q_a.forEach(t),sGr=r(Oeo," (Swin Transformer model)"),Oeo.forEach(t),lGr=i(Zx),Z5=n(Zx,"LI",{});var Veo=s(Z5);aLe=n(Veo,"STRONG",{});var j_a=s(aLe);iGr=r(j_a,"swinv2"),j_a.forEach(t),dGr=r(Veo," \u2014 "),Nte=n(Veo,"A",{href:!0});var D_a=s(Nte);mGr=r(D_a,"Swinv2ForMaskedImageModeling"),D_a.forEach(t),cGr=r(Veo," (Swin Transformer V2 model)"),Veo.forEach(t),fGr=i(Zx),K5=n(Zx,"LI",{});var Xeo=s(K5);nLe=n(Xeo,"STRONG",{});var G_a=s(nLe);gGr=r(G_a,"vit"),G_a.forEach(t),hGr=r(Xeo," \u2014 "),qte=n(Xeo,"A",{href:!0});var O_a=s(qte);uGr=r(O_a,"ViTForMaskedImageModeling"),O_a.forEach(t),pGr=r(Xeo," (ViT model)"),Xeo.forEach(t),Zx.forEach(t),_Gr=i(en),e0=n(en,"P",{});var zeo=s(e0);bGr=r(zeo,"The model is set in evaluation mode by default using "),sLe=n(zeo,"CODE",{});var V_a=s(sLe);vGr=r(V_a,"model.eval()"),V_a.forEach(t),FGr=r(zeo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lLe=n(zeo,"CODE",{});var X_a=s(lLe);TGr=r(X_a,"model.train()"),X_a.forEach(t),zeo.forEach(t),MGr=i(en),T(o0.$$.fragment,en),en.forEach(t),pi.forEach(t),Bio=i(c),ac=n(c,"H2",{class:!0});var aco=s(ac);r0=n(aco,"A",{id:!0,class:!0,href:!0});var z_a=s(r0);iLe=n(z_a,"SPAN",{});var Q_a=s(iLe);T(oP.$$.fragment,Q_a),Q_a.forEach(t),z_a.forEach(t),EGr=i(aco),dLe=n(aco,"SPAN",{});var W_a=s(dLe);CGr=r(W_a,"AutoModelForObjectDetection"),W_a.forEach(t),aco.forEach(t),Iio=i(c),dr=n(c,"DIV",{class:!0});var _i=s(dr);T(rP.$$.fragment,_i),wGr=i(_i),nc=n(_i,"P",{});var sge=s(nc);AGr=r(sge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),jte=n(sge,"A",{href:!0});var U_a=s(jte);LGr=r(U_a,"from_pretrained()"),U_a.forEach(t),yGr=r(sge," class method or the "),Dte=n(sge,"A",{href:!0});var H_a=s(Dte);xGr=r(H_a,"from_config()"),H_a.forEach(t),$Gr=r(sge,` class
method.`),sge.forEach(t),kGr=i(_i),tP=n(_i,"P",{});var nco=s(tP);SGr=r(nco,"This class cannot be instantiated directly using "),mLe=n(nco,"CODE",{});var J_a=s(mLe);RGr=r(J_a,"__init__()"),J_a.forEach(t),PGr=r(nco," (throws an error)."),nco.forEach(t),BGr=i(_i),Jt=n(_i,"DIV",{class:!0});var Kx=s(Jt);T(aP.$$.fragment,Kx),IGr=i(Kx),cLe=n(Kx,"P",{});var Y_a=s(cLe);NGr=r(Y_a,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),Y_a.forEach(t),qGr=i(Kx),sc=n(Kx,"P",{});var lge=s(sc);jGr=r(lge,`Note:
Loading a model from its configuration file does `),fLe=n(lge,"STRONG",{});var Z_a=s(fLe);DGr=r(Z_a,"not"),Z_a.forEach(t),GGr=r(lge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Gte=n(lge,"A",{href:!0});var K_a=s(Gte);OGr=r(K_a,"from_pretrained()"),K_a.forEach(t),VGr=r(lge," to load the model weights."),lge.forEach(t),XGr=i(Kx),T(t0.$$.fragment,Kx),Kx.forEach(t),zGr=i(_i),Lo=n(_i,"DIV",{class:!0});var on=s(Lo);T(nP.$$.fragment,on),QGr=i(on),gLe=n(on,"P",{});var e1a=s(gLe);WGr=r(e1a,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),e1a.forEach(t),UGr=i(on),In=n(on,"P",{});var e$=s(In);HGr=r(e$,"The model class to instantiate is selected based on the "),hLe=n(e$,"CODE",{});var o1a=s(hLe);JGr=r(o1a,"model_type"),o1a.forEach(t),YGr=r(e$,` property of the config object (either
passed as an argument or loaded from `),uLe=n(e$,"CODE",{});var r1a=s(uLe);ZGr=r(r1a,"pretrained_model_name_or_path"),r1a.forEach(t),KGr=r(e$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pLe=n(e$,"CODE",{});var t1a=s(pLe);eOr=r(t1a,"pretrained_model_name_or_path"),t1a.forEach(t),oOr=r(e$,":"),e$.forEach(t),rOr=i(on),Tt=n(on,"UL",{});var bi=s(Tt);a0=n(bi,"LI",{});var Qeo=s(a0);_Le=n(Qeo,"STRONG",{});var a1a=s(_Le);tOr=r(a1a,"conditional_detr"),a1a.forEach(t),aOr=r(Qeo," \u2014 "),Ote=n(Qeo,"A",{href:!0});var n1a=s(Ote);nOr=r(n1a,"ConditionalDetrForObjectDetection"),n1a.forEach(t),sOr=r(Qeo," (Conditional DETR model)"),Qeo.forEach(t),lOr=i(bi),n0=n(bi,"LI",{});var Weo=s(n0);bLe=n(Weo,"STRONG",{});var s1a=s(bLe);iOr=r(s1a,"deformable_detr"),s1a.forEach(t),dOr=r(Weo," \u2014 "),Vte=n(Weo,"A",{href:!0});var l1a=s(Vte);mOr=r(l1a,"DeformableDetrForObjectDetection"),l1a.forEach(t),cOr=r(Weo," (Deformable DETR model)"),Weo.forEach(t),fOr=i(bi),s0=n(bi,"LI",{});var Ueo=s(s0);vLe=n(Ueo,"STRONG",{});var i1a=s(vLe);gOr=r(i1a,"detr"),i1a.forEach(t),hOr=r(Ueo," \u2014 "),Xte=n(Ueo,"A",{href:!0});var d1a=s(Xte);uOr=r(d1a,"DetrForObjectDetection"),d1a.forEach(t),pOr=r(Ueo," (DETR model)"),Ueo.forEach(t),_Or=i(bi),l0=n(bi,"LI",{});var Heo=s(l0);FLe=n(Heo,"STRONG",{});var m1a=s(FLe);bOr=r(m1a,"table-transformer"),m1a.forEach(t),vOr=r(Heo," \u2014 "),zte=n(Heo,"A",{href:!0});var c1a=s(zte);FOr=r(c1a,"TableTransformerForObjectDetection"),c1a.forEach(t),TOr=r(Heo," (Table Transformer model)"),Heo.forEach(t),MOr=i(bi),i0=n(bi,"LI",{});var Jeo=s(i0);TLe=n(Jeo,"STRONG",{});var f1a=s(TLe);EOr=r(f1a,"yolos"),f1a.forEach(t),COr=r(Jeo," \u2014 "),Qte=n(Jeo,"A",{href:!0});var g1a=s(Qte);wOr=r(g1a,"YolosForObjectDetection"),g1a.forEach(t),AOr=r(Jeo," (YOLOS model)"),Jeo.forEach(t),bi.forEach(t),LOr=i(on),d0=n(on,"P",{});var Yeo=s(d0);yOr=r(Yeo,"The model is set in evaluation mode by default using "),MLe=n(Yeo,"CODE",{});var h1a=s(MLe);xOr=r(h1a,"model.eval()"),h1a.forEach(t),$Or=r(Yeo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ELe=n(Yeo,"CODE",{});var u1a=s(ELe);kOr=r(u1a,"model.train()"),u1a.forEach(t),Yeo.forEach(t),SOr=i(on),T(m0.$$.fragment,on),on.forEach(t),_i.forEach(t),Nio=i(c),lc=n(c,"H2",{class:!0});var sco=s(lc);c0=n(sco,"A",{id:!0,class:!0,href:!0});var p1a=s(c0);CLe=n(p1a,"SPAN",{});var _1a=s(CLe);T(sP.$$.fragment,_1a),_1a.forEach(t),p1a.forEach(t),ROr=i(sco),wLe=n(sco,"SPAN",{});var b1a=s(wLe);POr=r(b1a,"AutoModelForImageSegmentation"),b1a.forEach(t),sco.forEach(t),qio=i(c),mr=n(c,"DIV",{class:!0});var vi=s(mr);T(lP.$$.fragment,vi),BOr=i(vi),ic=n(vi,"P",{});var ige=s(ic);IOr=r(ige,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),Wte=n(ige,"A",{href:!0});var v1a=s(Wte);NOr=r(v1a,"from_pretrained()"),v1a.forEach(t),qOr=r(ige," class method or the "),Ute=n(ige,"A",{href:!0});var F1a=s(Ute);jOr=r(F1a,"from_config()"),F1a.forEach(t),DOr=r(ige,` class
method.`),ige.forEach(t),GOr=i(vi),iP=n(vi,"P",{});var lco=s(iP);OOr=r(lco,"This class cannot be instantiated directly using "),ALe=n(lco,"CODE",{});var T1a=s(ALe);VOr=r(T1a,"__init__()"),T1a.forEach(t),XOr=r(lco," (throws an error)."),lco.forEach(t),zOr=i(vi),Yt=n(vi,"DIV",{class:!0});var o$=s(Yt);T(dP.$$.fragment,o$),QOr=i(o$),LLe=n(o$,"P",{});var M1a=s(LLe);WOr=r(M1a,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),M1a.forEach(t),UOr=i(o$),dc=n(o$,"P",{});var dge=s(dc);HOr=r(dge,`Note:
Loading a model from its configuration file does `),yLe=n(dge,"STRONG",{});var E1a=s(yLe);JOr=r(E1a,"not"),E1a.forEach(t),YOr=r(dge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Hte=n(dge,"A",{href:!0});var C1a=s(Hte);ZOr=r(C1a,"from_pretrained()"),C1a.forEach(t),KOr=r(dge," to load the model weights."),dge.forEach(t),eVr=i(o$),T(f0.$$.fragment,o$),o$.forEach(t),oVr=i(vi),yo=n(vi,"DIV",{class:!0});var rn=s(yo);T(mP.$$.fragment,rn),rVr=i(rn),xLe=n(rn,"P",{});var w1a=s(xLe);tVr=r(w1a,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),w1a.forEach(t),aVr=i(rn),Nn=n(rn,"P",{});var r$=s(Nn);nVr=r(r$,"The model class to instantiate is selected based on the "),$Le=n(r$,"CODE",{});var A1a=s($Le);sVr=r(A1a,"model_type"),A1a.forEach(t),lVr=r(r$,` property of the config object (either
passed as an argument or loaded from `),kLe=n(r$,"CODE",{});var L1a=s(kLe);iVr=r(L1a,"pretrained_model_name_or_path"),L1a.forEach(t),dVr=r(r$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SLe=n(r$,"CODE",{});var y1a=s(SLe);mVr=r(y1a,"pretrained_model_name_or_path"),y1a.forEach(t),cVr=r(r$,":"),r$.forEach(t),fVr=i(rn),RLe=n(rn,"UL",{});var x1a=s(RLe);g0=n(x1a,"LI",{});var Zeo=s(g0);PLe=n(Zeo,"STRONG",{});var $1a=s(PLe);gVr=r($1a,"detr"),$1a.forEach(t),hVr=r(Zeo," \u2014 "),Jte=n(Zeo,"A",{href:!0});var k1a=s(Jte);uVr=r(k1a,"DetrForSegmentation"),k1a.forEach(t),pVr=r(Zeo," (DETR model)"),Zeo.forEach(t),x1a.forEach(t),_Vr=i(rn),h0=n(rn,"P",{});var Keo=s(h0);bVr=r(Keo,"The model is set in evaluation mode by default using "),BLe=n(Keo,"CODE",{});var S1a=s(BLe);vVr=r(S1a,"model.eval()"),S1a.forEach(t),FVr=r(Keo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ILe=n(Keo,"CODE",{});var R1a=s(ILe);TVr=r(R1a,"model.train()"),R1a.forEach(t),Keo.forEach(t),MVr=i(rn),T(u0.$$.fragment,rn),rn.forEach(t),vi.forEach(t),jio=i(c),mc=n(c,"H2",{class:!0});var ico=s(mc);p0=n(ico,"A",{id:!0,class:!0,href:!0});var P1a=s(p0);NLe=n(P1a,"SPAN",{});var B1a=s(NLe);T(cP.$$.fragment,B1a),B1a.forEach(t),P1a.forEach(t),EVr=i(ico),qLe=n(ico,"SPAN",{});var I1a=s(qLe);CVr=r(I1a,"AutoModelForSemanticSegmentation"),I1a.forEach(t),ico.forEach(t),Dio=i(c),cr=n(c,"DIV",{class:!0});var Fi=s(cr);T(fP.$$.fragment,Fi),wVr=i(Fi),cc=n(Fi,"P",{});var mge=s(cc);AVr=r(mge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Yte=n(mge,"A",{href:!0});var N1a=s(Yte);LVr=r(N1a,"from_pretrained()"),N1a.forEach(t),yVr=r(mge," class method or the "),Zte=n(mge,"A",{href:!0});var q1a=s(Zte);xVr=r(q1a,"from_config()"),q1a.forEach(t),$Vr=r(mge,` class
method.`),mge.forEach(t),kVr=i(Fi),gP=n(Fi,"P",{});var dco=s(gP);SVr=r(dco,"This class cannot be instantiated directly using "),jLe=n(dco,"CODE",{});var j1a=s(jLe);RVr=r(j1a,"__init__()"),j1a.forEach(t),PVr=r(dco," (throws an error)."),dco.forEach(t),BVr=i(Fi),Zt=n(Fi,"DIV",{class:!0});var t$=s(Zt);T(hP.$$.fragment,t$),IVr=i(t$),DLe=n(t$,"P",{});var D1a=s(DLe);NVr=r(D1a,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),D1a.forEach(t),qVr=i(t$),fc=n(t$,"P",{});var cge=s(fc);jVr=r(cge,`Note:
Loading a model from its configuration file does `),GLe=n(cge,"STRONG",{});var G1a=s(GLe);DVr=r(G1a,"not"),G1a.forEach(t),GVr=r(cge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Kte=n(cge,"A",{href:!0});var O1a=s(Kte);OVr=r(O1a,"from_pretrained()"),O1a.forEach(t),VVr=r(cge," to load the model weights."),cge.forEach(t),XVr=i(t$),T(_0.$$.fragment,t$),t$.forEach(t),zVr=i(Fi),xo=n(Fi,"DIV",{class:!0});var tn=s(xo);T(uP.$$.fragment,tn),QVr=i(tn),OLe=n(tn,"P",{});var V1a=s(OLe);WVr=r(V1a,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),V1a.forEach(t),UVr=i(tn),qn=n(tn,"P",{});var a$=s(qn);HVr=r(a$,"The model class to instantiate is selected based on the "),VLe=n(a$,"CODE",{});var X1a=s(VLe);JVr=r(X1a,"model_type"),X1a.forEach(t),YVr=r(a$,` property of the config object (either
passed as an argument or loaded from `),XLe=n(a$,"CODE",{});var z1a=s(XLe);ZVr=r(z1a,"pretrained_model_name_or_path"),z1a.forEach(t),KVr=r(a$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zLe=n(a$,"CODE",{});var Q1a=s(zLe);eXr=r(Q1a,"pretrained_model_name_or_path"),Q1a.forEach(t),oXr=r(a$,":"),a$.forEach(t),rXr=i(tn),Mt=n(tn,"UL",{});var Ti=s(Mt);b0=n(Ti,"LI",{});var eoo=s(b0);QLe=n(eoo,"STRONG",{});var W1a=s(QLe);tXr=r(W1a,"beit"),W1a.forEach(t),aXr=r(eoo," \u2014 "),eae=n(eoo,"A",{href:!0});var U1a=s(eae);nXr=r(U1a,"BeitForSemanticSegmentation"),U1a.forEach(t),sXr=r(eoo," (BEiT model)"),eoo.forEach(t),lXr=i(Ti),v0=n(Ti,"LI",{});var ooo=s(v0);WLe=n(ooo,"STRONG",{});var H1a=s(WLe);iXr=r(H1a,"data2vec-vision"),H1a.forEach(t),dXr=r(ooo," \u2014 "),oae=n(ooo,"A",{href:!0});var J1a=s(oae);mXr=r(J1a,"Data2VecVisionForSemanticSegmentation"),J1a.forEach(t),cXr=r(ooo," (Data2VecVision model)"),ooo.forEach(t),fXr=i(Ti),F0=n(Ti,"LI",{});var roo=s(F0);ULe=n(roo,"STRONG",{});var Y1a=s(ULe);gXr=r(Y1a,"dpt"),Y1a.forEach(t),hXr=r(roo," \u2014 "),rae=n(roo,"A",{href:!0});var Z1a=s(rae);uXr=r(Z1a,"DPTForSemanticSegmentation"),Z1a.forEach(t),pXr=r(roo," (DPT model)"),roo.forEach(t),_Xr=i(Ti),T0=n(Ti,"LI",{});var too=s(T0);HLe=n(too,"STRONG",{});var K1a=s(HLe);bXr=r(K1a,"mobilevit"),K1a.forEach(t),vXr=r(too," \u2014 "),tae=n(too,"A",{href:!0});var e2a=s(tae);FXr=r(e2a,"MobileViTForSemanticSegmentation"),e2a.forEach(t),TXr=r(too," (MobileViT model)"),too.forEach(t),MXr=i(Ti),M0=n(Ti,"LI",{});var aoo=s(M0);JLe=n(aoo,"STRONG",{});var o2a=s(JLe);EXr=r(o2a,"segformer"),o2a.forEach(t),CXr=r(aoo," \u2014 "),aae=n(aoo,"A",{href:!0});var r2a=s(aae);wXr=r(r2a,"SegformerForSemanticSegmentation"),r2a.forEach(t),AXr=r(aoo," (SegFormer model)"),aoo.forEach(t),Ti.forEach(t),LXr=i(tn),E0=n(tn,"P",{});var noo=s(E0);yXr=r(noo,"The model is set in evaluation mode by default using "),YLe=n(noo,"CODE",{});var t2a=s(YLe);xXr=r(t2a,"model.eval()"),t2a.forEach(t),$Xr=r(noo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ZLe=n(noo,"CODE",{});var a2a=s(ZLe);kXr=r(a2a,"model.train()"),a2a.forEach(t),noo.forEach(t),SXr=i(tn),T(C0.$$.fragment,tn),tn.forEach(t),Fi.forEach(t),Gio=i(c),gc=n(c,"H2",{class:!0});var mco=s(gc);w0=n(mco,"A",{id:!0,class:!0,href:!0});var n2a=s(w0);KLe=n(n2a,"SPAN",{});var s2a=s(KLe);T(pP.$$.fragment,s2a),s2a.forEach(t),n2a.forEach(t),RXr=i(mco),eye=n(mco,"SPAN",{});var l2a=s(eye);PXr=r(l2a,"AutoModelForInstanceSegmentation"),l2a.forEach(t),mco.forEach(t),Oio=i(c),fr=n(c,"DIV",{class:!0});var Mi=s(fr);T(_P.$$.fragment,Mi),BXr=i(Mi),hc=n(Mi,"P",{});var fge=s(hc);IXr=r(fge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),nae=n(fge,"A",{href:!0});var i2a=s(nae);NXr=r(i2a,"from_pretrained()"),i2a.forEach(t),qXr=r(fge," class method or the "),sae=n(fge,"A",{href:!0});var d2a=s(sae);jXr=r(d2a,"from_config()"),d2a.forEach(t),DXr=r(fge,` class
method.`),fge.forEach(t),GXr=i(Mi),bP=n(Mi,"P",{});var cco=s(bP);OXr=r(cco,"This class cannot be instantiated directly using "),oye=n(cco,"CODE",{});var m2a=s(oye);VXr=r(m2a,"__init__()"),m2a.forEach(t),XXr=r(cco," (throws an error)."),cco.forEach(t),zXr=i(Mi),Kt=n(Mi,"DIV",{class:!0});var n$=s(Kt);T(vP.$$.fragment,n$),QXr=i(n$),rye=n(n$,"P",{});var c2a=s(rye);WXr=r(c2a,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),c2a.forEach(t),UXr=i(n$),uc=n(n$,"P",{});var gge=s(uc);HXr=r(gge,`Note:
Loading a model from its configuration file does `),tye=n(gge,"STRONG",{});var f2a=s(tye);JXr=r(f2a,"not"),f2a.forEach(t),YXr=r(gge,` load the model weights. It only affects the
model\u2019s configuration. Use `),lae=n(gge,"A",{href:!0});var g2a=s(lae);ZXr=r(g2a,"from_pretrained()"),g2a.forEach(t),KXr=r(gge," to load the model weights."),gge.forEach(t),ezr=i(n$),T(A0.$$.fragment,n$),n$.forEach(t),ozr=i(Mi),$o=n(Mi,"DIV",{class:!0});var an=s($o);T(FP.$$.fragment,an),rzr=i(an),aye=n(an,"P",{});var h2a=s(aye);tzr=r(h2a,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),h2a.forEach(t),azr=i(an),jn=n(an,"P",{});var s$=s(jn);nzr=r(s$,"The model class to instantiate is selected based on the "),nye=n(s$,"CODE",{});var u2a=s(nye);szr=r(u2a,"model_type"),u2a.forEach(t),lzr=r(s$,` property of the config object (either
passed as an argument or loaded from `),sye=n(s$,"CODE",{});var p2a=s(sye);izr=r(p2a,"pretrained_model_name_or_path"),p2a.forEach(t),dzr=r(s$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lye=n(s$,"CODE",{});var _2a=s(lye);mzr=r(_2a,"pretrained_model_name_or_path"),_2a.forEach(t),czr=r(s$,":"),s$.forEach(t),fzr=i(an),iye=n(an,"UL",{});var b2a=s(iye);L0=n(b2a,"LI",{});var soo=s(L0);dye=n(soo,"STRONG",{});var v2a=s(dye);gzr=r(v2a,"maskformer"),v2a.forEach(t),hzr=r(soo," \u2014 "),iae=n(soo,"A",{href:!0});var F2a=s(iae);uzr=r(F2a,"MaskFormerForInstanceSegmentation"),F2a.forEach(t),pzr=r(soo," (MaskFormer model)"),soo.forEach(t),b2a.forEach(t),_zr=i(an),y0=n(an,"P",{});var loo=s(y0);bzr=r(loo,"The model is set in evaluation mode by default using "),mye=n(loo,"CODE",{});var T2a=s(mye);vzr=r(T2a,"model.eval()"),T2a.forEach(t),Fzr=r(loo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cye=n(loo,"CODE",{});var M2a=s(cye);Tzr=r(M2a,"model.train()"),M2a.forEach(t),loo.forEach(t),Mzr=i(an),T(x0.$$.fragment,an),an.forEach(t),Mi.forEach(t),Vio=i(c),pc=n(c,"H2",{class:!0});var fco=s(pc);$0=n(fco,"A",{id:!0,class:!0,href:!0});var E2a=s($0);fye=n(E2a,"SPAN",{});var C2a=s(fye);T(TP.$$.fragment,C2a),C2a.forEach(t),E2a.forEach(t),Ezr=i(fco),gye=n(fco,"SPAN",{});var w2a=s(gye);Czr=r(w2a,"AutoModelForZeroShotObjectDetection"),w2a.forEach(t),fco.forEach(t),Xio=i(c),gr=n(c,"DIV",{class:!0});var Ei=s(gr);T(MP.$$.fragment,Ei),wzr=i(Ei),_c=n(Ei,"P",{});var hge=s(_c);Azr=r(hge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),dae=n(hge,"A",{href:!0});var A2a=s(dae);Lzr=r(A2a,"from_pretrained()"),A2a.forEach(t),yzr=r(hge," class method or the "),mae=n(hge,"A",{href:!0});var L2a=s(mae);xzr=r(L2a,"from_config()"),L2a.forEach(t),$zr=r(hge,` class
method.`),hge.forEach(t),kzr=i(Ei),EP=n(Ei,"P",{});var gco=s(EP);Szr=r(gco,"This class cannot be instantiated directly using "),hye=n(gco,"CODE",{});var y2a=s(hye);Rzr=r(y2a,"__init__()"),y2a.forEach(t),Pzr=r(gco," (throws an error)."),gco.forEach(t),Bzr=i(Ei),ea=n(Ei,"DIV",{class:!0});var l$=s(ea);T(CP.$$.fragment,l$),Izr=i(l$),uye=n(l$,"P",{});var x2a=s(uye);Nzr=r(x2a,"Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),x2a.forEach(t),qzr=i(l$),bc=n(l$,"P",{});var uge=s(bc);jzr=r(uge,`Note:
Loading a model from its configuration file does `),pye=n(uge,"STRONG",{});var $2a=s(pye);Dzr=r($2a,"not"),$2a.forEach(t),Gzr=r(uge,` load the model weights. It only affects the
model\u2019s configuration. Use `),cae=n(uge,"A",{href:!0});var k2a=s(cae);Ozr=r(k2a,"from_pretrained()"),k2a.forEach(t),Vzr=r(uge," to load the model weights."),uge.forEach(t),Xzr=i(l$),T(k0.$$.fragment,l$),l$.forEach(t),zzr=i(Ei),ko=n(Ei,"DIV",{class:!0});var nn=s(ko);T(wP.$$.fragment,nn),Qzr=i(nn),_ye=n(nn,"P",{});var S2a=s(_ye);Wzr=r(S2a,"Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),S2a.forEach(t),Uzr=i(nn),Dn=n(nn,"P",{});var i$=s(Dn);Hzr=r(i$,"The model class to instantiate is selected based on the "),bye=n(i$,"CODE",{});var R2a=s(bye);Jzr=r(R2a,"model_type"),R2a.forEach(t),Yzr=r(i$,` property of the config object (either
passed as an argument or loaded from `),vye=n(i$,"CODE",{});var P2a=s(vye);Zzr=r(P2a,"pretrained_model_name_or_path"),P2a.forEach(t),Kzr=r(i$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Fye=n(i$,"CODE",{});var B2a=s(Fye);eQr=r(B2a,"pretrained_model_name_or_path"),B2a.forEach(t),oQr=r(i$,":"),i$.forEach(t),rQr=i(nn),Tye=n(nn,"UL",{});var I2a=s(Tye);S0=n(I2a,"LI",{});var ioo=s(S0);Mye=n(ioo,"STRONG",{});var N2a=s(Mye);tQr=r(N2a,"owlvit"),N2a.forEach(t),aQr=r(ioo," \u2014 "),fae=n(ioo,"A",{href:!0});var q2a=s(fae);nQr=r(q2a,"OwlViTForObjectDetection"),q2a.forEach(t),sQr=r(ioo," (OWL-ViT model)"),ioo.forEach(t),I2a.forEach(t),lQr=i(nn),R0=n(nn,"P",{});var doo=s(R0);iQr=r(doo,"The model is set in evaluation mode by default using "),Eye=n(doo,"CODE",{});var j2a=s(Eye);dQr=r(j2a,"model.eval()"),j2a.forEach(t),mQr=r(doo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Cye=n(doo,"CODE",{});var D2a=s(Cye);cQr=r(D2a,"model.train()"),D2a.forEach(t),doo.forEach(t),fQr=i(nn),T(P0.$$.fragment,nn),nn.forEach(t),Ei.forEach(t),zio=i(c),vc=n(c,"H2",{class:!0});var hco=s(vc);B0=n(hco,"A",{id:!0,class:!0,href:!0});var G2a=s(B0);wye=n(G2a,"SPAN",{});var O2a=s(wye);T(AP.$$.fragment,O2a),O2a.forEach(t),G2a.forEach(t),gQr=i(hco),Aye=n(hco,"SPAN",{});var V2a=s(Aye);hQr=r(V2a,"TFAutoModel"),V2a.forEach(t),hco.forEach(t),Qio=i(c),hr=n(c,"DIV",{class:!0});var Ci=s(hr);T(LP.$$.fragment,Ci),uQr=i(Ci),Fc=n(Ci,"P",{});var pge=s(Fc);pQr=r(pge,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),gae=n(pge,"A",{href:!0});var X2a=s(gae);_Qr=r(X2a,"from_pretrained()"),X2a.forEach(t),bQr=r(pge," class method or the "),hae=n(pge,"A",{href:!0});var z2a=s(hae);vQr=r(z2a,"from_config()"),z2a.forEach(t),FQr=r(pge,` class
method.`),pge.forEach(t),TQr=i(Ci),yP=n(Ci,"P",{});var uco=s(yP);MQr=r(uco,"This class cannot be instantiated directly using "),Lye=n(uco,"CODE",{});var Q2a=s(Lye);EQr=r(Q2a,"__init__()"),Q2a.forEach(t),CQr=r(uco," (throws an error)."),uco.forEach(t),wQr=i(Ci),oa=n(Ci,"DIV",{class:!0});var d$=s(oa);T(xP.$$.fragment,d$),AQr=i(d$),yye=n(d$,"P",{});var W2a=s(yye);LQr=r(W2a,"Instantiates one of the base model classes of the library from a configuration."),W2a.forEach(t),yQr=i(d$),Tc=n(d$,"P",{});var _ge=s(Tc);xQr=r(_ge,`Note:
Loading a model from its configuration file does `),xye=n(_ge,"STRONG",{});var U2a=s(xye);$Qr=r(U2a,"not"),U2a.forEach(t),kQr=r(_ge,` load the model weights. It only affects the
model\u2019s configuration. Use `),uae=n(_ge,"A",{href:!0});var H2a=s(uae);SQr=r(H2a,"from_pretrained()"),H2a.forEach(t),RQr=r(_ge," to load the model weights."),_ge.forEach(t),PQr=i(d$),T(I0.$$.fragment,d$),d$.forEach(t),BQr=i(Ci),Xr=n(Ci,"DIV",{class:!0});var wi=s(Xr);T($P.$$.fragment,wi),IQr=i(wi),$ye=n(wi,"P",{});var J2a=s($ye);NQr=r(J2a,"Instantiate one of the base model classes of the library from a pretrained model."),J2a.forEach(t),qQr=i(wi),Gn=n(wi,"P",{});var m$=s(Gn);jQr=r(m$,"The model class to instantiate is selected based on the "),kye=n(m$,"CODE",{});var Y2a=s(kye);DQr=r(Y2a,"model_type"),Y2a.forEach(t),GQr=r(m$,` property of the config object (either
passed as an argument or loaded from `),Sye=n(m$,"CODE",{});var Z2a=s(Sye);OQr=r(Z2a,"pretrained_model_name_or_path"),Z2a.forEach(t),VQr=r(m$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rye=n(m$,"CODE",{});var K2a=s(Rye);XQr=r(K2a,"pretrained_model_name_or_path"),K2a.forEach(t),zQr=r(m$,":"),m$.forEach(t),QQr=i(wi),P=n(wi,"UL",{});var j=s(P);N0=n(j,"LI",{});var moo=s(N0);Pye=n(moo,"STRONG",{});var eba=s(Pye);WQr=r(eba,"albert"),eba.forEach(t),UQr=r(moo," \u2014 "),pae=n(moo,"A",{href:!0});var oba=s(pae);HQr=r(oba,"TFAlbertModel"),oba.forEach(t),JQr=r(moo," (ALBERT model)"),moo.forEach(t),YQr=i(j),q0=n(j,"LI",{});var coo=s(q0);Bye=n(coo,"STRONG",{});var rba=s(Bye);ZQr=r(rba,"bart"),rba.forEach(t),KQr=r(coo," \u2014 "),_ae=n(coo,"A",{href:!0});var tba=s(_ae);eWr=r(tba,"TFBartModel"),tba.forEach(t),oWr=r(coo," (BART model)"),coo.forEach(t),rWr=i(j),j0=n(j,"LI",{});var foo=s(j0);Iye=n(foo,"STRONG",{});var aba=s(Iye);tWr=r(aba,"bert"),aba.forEach(t),aWr=r(foo," \u2014 "),bae=n(foo,"A",{href:!0});var nba=s(bae);nWr=r(nba,"TFBertModel"),nba.forEach(t),sWr=r(foo," (BERT model)"),foo.forEach(t),lWr=i(j),D0=n(j,"LI",{});var goo=s(D0);Nye=n(goo,"STRONG",{});var sba=s(Nye);iWr=r(sba,"blenderbot"),sba.forEach(t),dWr=r(goo," \u2014 "),vae=n(goo,"A",{href:!0});var lba=s(vae);mWr=r(lba,"TFBlenderbotModel"),lba.forEach(t),cWr=r(goo," (Blenderbot model)"),goo.forEach(t),fWr=i(j),G0=n(j,"LI",{});var hoo=s(G0);qye=n(hoo,"STRONG",{});var iba=s(qye);gWr=r(iba,"blenderbot-small"),iba.forEach(t),hWr=r(hoo," \u2014 "),Fae=n(hoo,"A",{href:!0});var dba=s(Fae);uWr=r(dba,"TFBlenderbotSmallModel"),dba.forEach(t),pWr=r(hoo," (BlenderbotSmall model)"),hoo.forEach(t),_Wr=i(j),O0=n(j,"LI",{});var uoo=s(O0);jye=n(uoo,"STRONG",{});var mba=s(jye);bWr=r(mba,"camembert"),mba.forEach(t),vWr=r(uoo," \u2014 "),Tae=n(uoo,"A",{href:!0});var cba=s(Tae);FWr=r(cba,"TFCamembertModel"),cba.forEach(t),TWr=r(uoo," (CamemBERT model)"),uoo.forEach(t),MWr=i(j),V0=n(j,"LI",{});var poo=s(V0);Dye=n(poo,"STRONG",{});var fba=s(Dye);EWr=r(fba,"clip"),fba.forEach(t),CWr=r(poo," \u2014 "),Mae=n(poo,"A",{href:!0});var gba=s(Mae);wWr=r(gba,"TFCLIPModel"),gba.forEach(t),AWr=r(poo," (CLIP model)"),poo.forEach(t),LWr=i(j),X0=n(j,"LI",{});var _oo=s(X0);Gye=n(_oo,"STRONG",{});var hba=s(Gye);yWr=r(hba,"convbert"),hba.forEach(t),xWr=r(_oo," \u2014 "),Eae=n(_oo,"A",{href:!0});var uba=s(Eae);$Wr=r(uba,"TFConvBertModel"),uba.forEach(t),kWr=r(_oo," (ConvBERT model)"),_oo.forEach(t),SWr=i(j),z0=n(j,"LI",{});var boo=s(z0);Oye=n(boo,"STRONG",{});var pba=s(Oye);RWr=r(pba,"convnext"),pba.forEach(t),PWr=r(boo," \u2014 "),Cae=n(boo,"A",{href:!0});var _ba=s(Cae);BWr=r(_ba,"TFConvNextModel"),_ba.forEach(t),IWr=r(boo," (ConvNeXT model)"),boo.forEach(t),NWr=i(j),Q0=n(j,"LI",{});var voo=s(Q0);Vye=n(voo,"STRONG",{});var bba=s(Vye);qWr=r(bba,"ctrl"),bba.forEach(t),jWr=r(voo," \u2014 "),wae=n(voo,"A",{href:!0});var vba=s(wae);DWr=r(vba,"TFCTRLModel"),vba.forEach(t),GWr=r(voo," (CTRL model)"),voo.forEach(t),OWr=i(j),W0=n(j,"LI",{});var Foo=s(W0);Xye=n(Foo,"STRONG",{});var Fba=s(Xye);VWr=r(Fba,"cvt"),Fba.forEach(t),XWr=r(Foo," \u2014 "),Aae=n(Foo,"A",{href:!0});var Tba=s(Aae);zWr=r(Tba,"TFCvtModel"),Tba.forEach(t),QWr=r(Foo," (CvT model)"),Foo.forEach(t),WWr=i(j),U0=n(j,"LI",{});var Too=s(U0);zye=n(Too,"STRONG",{});var Mba=s(zye);UWr=r(Mba,"data2vec-vision"),Mba.forEach(t),HWr=r(Too," \u2014 "),Lae=n(Too,"A",{href:!0});var Eba=s(Lae);JWr=r(Eba,"TFData2VecVisionModel"),Eba.forEach(t),YWr=r(Too," (Data2VecVision model)"),Too.forEach(t),ZWr=i(j),H0=n(j,"LI",{});var Moo=s(H0);Qye=n(Moo,"STRONG",{});var Cba=s(Qye);KWr=r(Cba,"deberta"),Cba.forEach(t),eUr=r(Moo," \u2014 "),yae=n(Moo,"A",{href:!0});var wba=s(yae);oUr=r(wba,"TFDebertaModel"),wba.forEach(t),rUr=r(Moo," (DeBERTa model)"),Moo.forEach(t),tUr=i(j),J0=n(j,"LI",{});var Eoo=s(J0);Wye=n(Eoo,"STRONG",{});var Aba=s(Wye);aUr=r(Aba,"deberta-v2"),Aba.forEach(t),nUr=r(Eoo," \u2014 "),xae=n(Eoo,"A",{href:!0});var Lba=s(xae);sUr=r(Lba,"TFDebertaV2Model"),Lba.forEach(t),lUr=r(Eoo," (DeBERTa-v2 model)"),Eoo.forEach(t),iUr=i(j),Y0=n(j,"LI",{});var Coo=s(Y0);Uye=n(Coo,"STRONG",{});var yba=s(Uye);dUr=r(yba,"deit"),yba.forEach(t),mUr=r(Coo," \u2014 "),$ae=n(Coo,"A",{href:!0});var xba=s($ae);cUr=r(xba,"TFDeiTModel"),xba.forEach(t),fUr=r(Coo," (DeiT model)"),Coo.forEach(t),gUr=i(j),Z0=n(j,"LI",{});var woo=s(Z0);Hye=n(woo,"STRONG",{});var $ba=s(Hye);hUr=r($ba,"distilbert"),$ba.forEach(t),uUr=r(woo," \u2014 "),kae=n(woo,"A",{href:!0});var kba=s(kae);pUr=r(kba,"TFDistilBertModel"),kba.forEach(t),_Ur=r(woo," (DistilBERT model)"),woo.forEach(t),bUr=i(j),K0=n(j,"LI",{});var Aoo=s(K0);Jye=n(Aoo,"STRONG",{});var Sba=s(Jye);vUr=r(Sba,"dpr"),Sba.forEach(t),FUr=r(Aoo," \u2014 "),Sae=n(Aoo,"A",{href:!0});var Rba=s(Sae);TUr=r(Rba,"TFDPRQuestionEncoder"),Rba.forEach(t),MUr=r(Aoo," (DPR model)"),Aoo.forEach(t),EUr=i(j),ew=n(j,"LI",{});var Loo=s(ew);Yye=n(Loo,"STRONG",{});var Pba=s(Yye);CUr=r(Pba,"electra"),Pba.forEach(t),wUr=r(Loo," \u2014 "),Rae=n(Loo,"A",{href:!0});var Bba=s(Rae);AUr=r(Bba,"TFElectraModel"),Bba.forEach(t),LUr=r(Loo," (ELECTRA model)"),Loo.forEach(t),yUr=i(j),ow=n(j,"LI",{});var yoo=s(ow);Zye=n(yoo,"STRONG",{});var Iba=s(Zye);xUr=r(Iba,"esm"),Iba.forEach(t),$Ur=r(yoo," \u2014 "),Pae=n(yoo,"A",{href:!0});var Nba=s(Pae);kUr=r(Nba,"TFEsmModel"),Nba.forEach(t),SUr=r(yoo," (ESM model)"),yoo.forEach(t),RUr=i(j),rw=n(j,"LI",{});var xoo=s(rw);Kye=n(xoo,"STRONG",{});var qba=s(Kye);PUr=r(qba,"flaubert"),qba.forEach(t),BUr=r(xoo," \u2014 "),Bae=n(xoo,"A",{href:!0});var jba=s(Bae);IUr=r(jba,"TFFlaubertModel"),jba.forEach(t),NUr=r(xoo," (FlauBERT model)"),xoo.forEach(t),qUr=i(j),jl=n(j,"LI",{});var Rq=s(jl);e9e=n(Rq,"STRONG",{});var Dba=s(e9e);jUr=r(Dba,"funnel"),Dba.forEach(t),DUr=r(Rq," \u2014 "),Iae=n(Rq,"A",{href:!0});var Gba=s(Iae);GUr=r(Gba,"TFFunnelModel"),Gba.forEach(t),OUr=r(Rq," or "),Nae=n(Rq,"A",{href:!0});var Oba=s(Nae);VUr=r(Oba,"TFFunnelBaseModel"),Oba.forEach(t),XUr=r(Rq," (Funnel Transformer model)"),Rq.forEach(t),zUr=i(j),tw=n(j,"LI",{});var $oo=s(tw);o9e=n($oo,"STRONG",{});var Vba=s(o9e);QUr=r(Vba,"gpt2"),Vba.forEach(t),WUr=r($oo," \u2014 "),qae=n($oo,"A",{href:!0});var Xba=s(qae);UUr=r(Xba,"TFGPT2Model"),Xba.forEach(t),HUr=r($oo," (OpenAI GPT-2 model)"),$oo.forEach(t),JUr=i(j),aw=n(j,"LI",{});var koo=s(aw);r9e=n(koo,"STRONG",{});var zba=s(r9e);YUr=r(zba,"gptj"),zba.forEach(t),ZUr=r(koo," \u2014 "),jae=n(koo,"A",{href:!0});var Qba=s(jae);KUr=r(Qba,"TFGPTJModel"),Qba.forEach(t),eHr=r(koo," (GPT-J model)"),koo.forEach(t),oHr=i(j),nw=n(j,"LI",{});var Soo=s(nw);t9e=n(Soo,"STRONG",{});var Wba=s(t9e);rHr=r(Wba,"groupvit"),Wba.forEach(t),tHr=r(Soo," \u2014 "),Dae=n(Soo,"A",{href:!0});var Uba=s(Dae);aHr=r(Uba,"TFGroupViTModel"),Uba.forEach(t),nHr=r(Soo," (GroupViT model)"),Soo.forEach(t),sHr=i(j),sw=n(j,"LI",{});var Roo=s(sw);a9e=n(Roo,"STRONG",{});var Hba=s(a9e);lHr=r(Hba,"hubert"),Hba.forEach(t),iHr=r(Roo," \u2014 "),Gae=n(Roo,"A",{href:!0});var Jba=s(Gae);dHr=r(Jba,"TFHubertModel"),Jba.forEach(t),mHr=r(Roo," (Hubert model)"),Roo.forEach(t),cHr=i(j),lw=n(j,"LI",{});var Poo=s(lw);n9e=n(Poo,"STRONG",{});var Yba=s(n9e);fHr=r(Yba,"layoutlm"),Yba.forEach(t),gHr=r(Poo," \u2014 "),Oae=n(Poo,"A",{href:!0});var Zba=s(Oae);hHr=r(Zba,"TFLayoutLMModel"),Zba.forEach(t),uHr=r(Poo," (LayoutLM model)"),Poo.forEach(t),pHr=i(j),iw=n(j,"LI",{});var Boo=s(iw);s9e=n(Boo,"STRONG",{});var Kba=s(s9e);_Hr=r(Kba,"layoutlmv3"),Kba.forEach(t),bHr=r(Boo," \u2014 "),Vae=n(Boo,"A",{href:!0});var eva=s(Vae);vHr=r(eva,"TFLayoutLMv3Model"),eva.forEach(t),FHr=r(Boo," (LayoutLMv3 model)"),Boo.forEach(t),THr=i(j),dw=n(j,"LI",{});var Ioo=s(dw);l9e=n(Ioo,"STRONG",{});var ova=s(l9e);MHr=r(ova,"led"),ova.forEach(t),EHr=r(Ioo," \u2014 "),Xae=n(Ioo,"A",{href:!0});var rva=s(Xae);CHr=r(rva,"TFLEDModel"),rva.forEach(t),wHr=r(Ioo," (LED model)"),Ioo.forEach(t),AHr=i(j),mw=n(j,"LI",{});var Noo=s(mw);i9e=n(Noo,"STRONG",{});var tva=s(i9e);LHr=r(tva,"longformer"),tva.forEach(t),yHr=r(Noo," \u2014 "),zae=n(Noo,"A",{href:!0});var ava=s(zae);xHr=r(ava,"TFLongformerModel"),ava.forEach(t),$Hr=r(Noo," (Longformer model)"),Noo.forEach(t),kHr=i(j),cw=n(j,"LI",{});var qoo=s(cw);d9e=n(qoo,"STRONG",{});var nva=s(d9e);SHr=r(nva,"lxmert"),nva.forEach(t),RHr=r(qoo," \u2014 "),Qae=n(qoo,"A",{href:!0});var sva=s(Qae);PHr=r(sva,"TFLxmertModel"),sva.forEach(t),BHr=r(qoo," (LXMERT model)"),qoo.forEach(t),IHr=i(j),fw=n(j,"LI",{});var joo=s(fw);m9e=n(joo,"STRONG",{});var lva=s(m9e);NHr=r(lva,"marian"),lva.forEach(t),qHr=r(joo," \u2014 "),Wae=n(joo,"A",{href:!0});var iva=s(Wae);jHr=r(iva,"TFMarianModel"),iva.forEach(t),DHr=r(joo," (Marian model)"),joo.forEach(t),GHr=i(j),gw=n(j,"LI",{});var Doo=s(gw);c9e=n(Doo,"STRONG",{});var dva=s(c9e);OHr=r(dva,"mbart"),dva.forEach(t),VHr=r(Doo," \u2014 "),Uae=n(Doo,"A",{href:!0});var mva=s(Uae);XHr=r(mva,"TFMBartModel"),mva.forEach(t),zHr=r(Doo," (mBART model)"),Doo.forEach(t),QHr=i(j),hw=n(j,"LI",{});var Goo=s(hw);f9e=n(Goo,"STRONG",{});var cva=s(f9e);WHr=r(cva,"mobilebert"),cva.forEach(t),UHr=r(Goo," \u2014 "),Hae=n(Goo,"A",{href:!0});var fva=s(Hae);HHr=r(fva,"TFMobileBertModel"),fva.forEach(t),JHr=r(Goo," (MobileBERT model)"),Goo.forEach(t),YHr=i(j),uw=n(j,"LI",{});var Ooo=s(uw);g9e=n(Ooo,"STRONG",{});var gva=s(g9e);ZHr=r(gva,"mobilevit"),gva.forEach(t),KHr=r(Ooo," \u2014 "),Jae=n(Ooo,"A",{href:!0});var hva=s(Jae);eJr=r(hva,"TFMobileViTModel"),hva.forEach(t),oJr=r(Ooo," (MobileViT model)"),Ooo.forEach(t),rJr=i(j),pw=n(j,"LI",{});var Voo=s(pw);h9e=n(Voo,"STRONG",{});var uva=s(h9e);tJr=r(uva,"mpnet"),uva.forEach(t),aJr=r(Voo," \u2014 "),Yae=n(Voo,"A",{href:!0});var pva=s(Yae);nJr=r(pva,"TFMPNetModel"),pva.forEach(t),sJr=r(Voo," (MPNet model)"),Voo.forEach(t),lJr=i(j),_w=n(j,"LI",{});var Xoo=s(_w);u9e=n(Xoo,"STRONG",{});var _va=s(u9e);iJr=r(_va,"mt5"),_va.forEach(t),dJr=r(Xoo," \u2014 "),Zae=n(Xoo,"A",{href:!0});var bva=s(Zae);mJr=r(bva,"TFMT5Model"),bva.forEach(t),cJr=r(Xoo," (MT5 model)"),Xoo.forEach(t),fJr=i(j),bw=n(j,"LI",{});var zoo=s(bw);p9e=n(zoo,"STRONG",{});var vva=s(p9e);gJr=r(vva,"openai-gpt"),vva.forEach(t),hJr=r(zoo," \u2014 "),Kae=n(zoo,"A",{href:!0});var Fva=s(Kae);uJr=r(Fva,"TFOpenAIGPTModel"),Fva.forEach(t),pJr=r(zoo," (OpenAI GPT model)"),zoo.forEach(t),_Jr=i(j),vw=n(j,"LI",{});var Qoo=s(vw);_9e=n(Qoo,"STRONG",{});var Tva=s(_9e);bJr=r(Tva,"opt"),Tva.forEach(t),vJr=r(Qoo," \u2014 "),ene=n(Qoo,"A",{href:!0});var Mva=s(ene);FJr=r(Mva,"TFOPTModel"),Mva.forEach(t),TJr=r(Qoo," (OPT model)"),Qoo.forEach(t),MJr=i(j),Fw=n(j,"LI",{});var Woo=s(Fw);b9e=n(Woo,"STRONG",{});var Eva=s(b9e);EJr=r(Eva,"pegasus"),Eva.forEach(t),CJr=r(Woo," \u2014 "),one=n(Woo,"A",{href:!0});var Cva=s(one);wJr=r(Cva,"TFPegasusModel"),Cva.forEach(t),AJr=r(Woo," (Pegasus model)"),Woo.forEach(t),LJr=i(j),Tw=n(j,"LI",{});var Uoo=s(Tw);v9e=n(Uoo,"STRONG",{});var wva=s(v9e);yJr=r(wva,"regnet"),wva.forEach(t),xJr=r(Uoo," \u2014 "),rne=n(Uoo,"A",{href:!0});var Ava=s(rne);$Jr=r(Ava,"TFRegNetModel"),Ava.forEach(t),kJr=r(Uoo," (RegNet model)"),Uoo.forEach(t),SJr=i(j),Mw=n(j,"LI",{});var Hoo=s(Mw);F9e=n(Hoo,"STRONG",{});var Lva=s(F9e);RJr=r(Lva,"rembert"),Lva.forEach(t),PJr=r(Hoo," \u2014 "),tne=n(Hoo,"A",{href:!0});var yva=s(tne);BJr=r(yva,"TFRemBertModel"),yva.forEach(t),IJr=r(Hoo," (RemBERT model)"),Hoo.forEach(t),NJr=i(j),Ew=n(j,"LI",{});var Joo=s(Ew);T9e=n(Joo,"STRONG",{});var xva=s(T9e);qJr=r(xva,"resnet"),xva.forEach(t),jJr=r(Joo," \u2014 "),ane=n(Joo,"A",{href:!0});var $va=s(ane);DJr=r($va,"TFResNetModel"),$va.forEach(t),GJr=r(Joo," (ResNet model)"),Joo.forEach(t),OJr=i(j),Cw=n(j,"LI",{});var Yoo=s(Cw);M9e=n(Yoo,"STRONG",{});var kva=s(M9e);VJr=r(kva,"roberta"),kva.forEach(t),XJr=r(Yoo," \u2014 "),nne=n(Yoo,"A",{href:!0});var Sva=s(nne);zJr=r(Sva,"TFRobertaModel"),Sva.forEach(t),QJr=r(Yoo," (RoBERTa model)"),Yoo.forEach(t),WJr=i(j),ww=n(j,"LI",{});var Zoo=s(ww);E9e=n(Zoo,"STRONG",{});var Rva=s(E9e);UJr=r(Rva,"roformer"),Rva.forEach(t),HJr=r(Zoo," \u2014 "),sne=n(Zoo,"A",{href:!0});var Pva=s(sne);JJr=r(Pva,"TFRoFormerModel"),Pva.forEach(t),YJr=r(Zoo," (RoFormer model)"),Zoo.forEach(t),ZJr=i(j),Aw=n(j,"LI",{});var Koo=s(Aw);C9e=n(Koo,"STRONG",{});var Bva=s(C9e);KJr=r(Bva,"segformer"),Bva.forEach(t),eYr=r(Koo," \u2014 "),lne=n(Koo,"A",{href:!0});var Iva=s(lne);oYr=r(Iva,"TFSegformerModel"),Iva.forEach(t),rYr=r(Koo," (SegFormer model)"),Koo.forEach(t),tYr=i(j),Lw=n(j,"LI",{});var ero=s(Lw);w9e=n(ero,"STRONG",{});var Nva=s(w9e);aYr=r(Nva,"speech_to_text"),Nva.forEach(t),nYr=r(ero," \u2014 "),ine=n(ero,"A",{href:!0});var qva=s(ine);sYr=r(qva,"TFSpeech2TextModel"),qva.forEach(t),lYr=r(ero," (Speech2Text model)"),ero.forEach(t),iYr=i(j),yw=n(j,"LI",{});var oro=s(yw);A9e=n(oro,"STRONG",{});var jva=s(A9e);dYr=r(jva,"swin"),jva.forEach(t),mYr=r(oro," \u2014 "),dne=n(oro,"A",{href:!0});var Dva=s(dne);cYr=r(Dva,"TFSwinModel"),Dva.forEach(t),fYr=r(oro," (Swin Transformer model)"),oro.forEach(t),gYr=i(j),xw=n(j,"LI",{});var rro=s(xw);L9e=n(rro,"STRONG",{});var Gva=s(L9e);hYr=r(Gva,"t5"),Gva.forEach(t),uYr=r(rro," \u2014 "),mne=n(rro,"A",{href:!0});var Ova=s(mne);pYr=r(Ova,"TFT5Model"),Ova.forEach(t),_Yr=r(rro," (T5 model)"),rro.forEach(t),bYr=i(j),$w=n(j,"LI",{});var tro=s($w);y9e=n(tro,"STRONG",{});var Vva=s(y9e);vYr=r(Vva,"tapas"),Vva.forEach(t),FYr=r(tro," \u2014 "),cne=n(tro,"A",{href:!0});var Xva=s(cne);TYr=r(Xva,"TFTapasModel"),Xva.forEach(t),MYr=r(tro," (TAPAS model)"),tro.forEach(t),EYr=i(j),kw=n(j,"LI",{});var aro=s(kw);x9e=n(aro,"STRONG",{});var zva=s(x9e);CYr=r(zva,"transfo-xl"),zva.forEach(t),wYr=r(aro," \u2014 "),fne=n(aro,"A",{href:!0});var Qva=s(fne);AYr=r(Qva,"TFTransfoXLModel"),Qva.forEach(t),LYr=r(aro," (Transformer-XL model)"),aro.forEach(t),yYr=i(j),Sw=n(j,"LI",{});var nro=s(Sw);$9e=n(nro,"STRONG",{});var Wva=s($9e);xYr=r(Wva,"vit"),Wva.forEach(t),$Yr=r(nro," \u2014 "),gne=n(nro,"A",{href:!0});var Uva=s(gne);kYr=r(Uva,"TFViTModel"),Uva.forEach(t),SYr=r(nro," (ViT model)"),nro.forEach(t),RYr=i(j),Rw=n(j,"LI",{});var sro=s(Rw);k9e=n(sro,"STRONG",{});var Hva=s(k9e);PYr=r(Hva,"vit_mae"),Hva.forEach(t),BYr=r(sro," \u2014 "),hne=n(sro,"A",{href:!0});var Jva=s(hne);IYr=r(Jva,"TFViTMAEModel"),Jva.forEach(t),NYr=r(sro," (ViTMAE model)"),sro.forEach(t),qYr=i(j),Pw=n(j,"LI",{});var lro=s(Pw);S9e=n(lro,"STRONG",{});var Yva=s(S9e);jYr=r(Yva,"wav2vec2"),Yva.forEach(t),DYr=r(lro," \u2014 "),une=n(lro,"A",{href:!0});var Zva=s(une);GYr=r(Zva,"TFWav2Vec2Model"),Zva.forEach(t),OYr=r(lro," (Wav2Vec2 model)"),lro.forEach(t),VYr=i(j),Bw=n(j,"LI",{});var iro=s(Bw);R9e=n(iro,"STRONG",{});var Kva=s(R9e);XYr=r(Kva,"whisper"),Kva.forEach(t),zYr=r(iro," \u2014 "),pne=n(iro,"A",{href:!0});var eFa=s(pne);QYr=r(eFa,"TFWhisperModel"),eFa.forEach(t),WYr=r(iro," (Whisper model)"),iro.forEach(t),UYr=i(j),Iw=n(j,"LI",{});var dro=s(Iw);P9e=n(dro,"STRONG",{});var oFa=s(P9e);HYr=r(oFa,"xglm"),oFa.forEach(t),JYr=r(dro," \u2014 "),_ne=n(dro,"A",{href:!0});var rFa=s(_ne);YYr=r(rFa,"TFXGLMModel"),rFa.forEach(t),ZYr=r(dro," (XGLM model)"),dro.forEach(t),KYr=i(j),Nw=n(j,"LI",{});var mro=s(Nw);B9e=n(mro,"STRONG",{});var tFa=s(B9e);eZr=r(tFa,"xlm"),tFa.forEach(t),oZr=r(mro," \u2014 "),bne=n(mro,"A",{href:!0});var aFa=s(bne);rZr=r(aFa,"TFXLMModel"),aFa.forEach(t),tZr=r(mro," (XLM model)"),mro.forEach(t),aZr=i(j),qw=n(j,"LI",{});var cro=s(qw);I9e=n(cro,"STRONG",{});var nFa=s(I9e);nZr=r(nFa,"xlm-roberta"),nFa.forEach(t),sZr=r(cro," \u2014 "),vne=n(cro,"A",{href:!0});var sFa=s(vne);lZr=r(sFa,"TFXLMRobertaModel"),sFa.forEach(t),iZr=r(cro," (XLM-RoBERTa model)"),cro.forEach(t),dZr=i(j),jw=n(j,"LI",{});var fro=s(jw);N9e=n(fro,"STRONG",{});var lFa=s(N9e);mZr=r(lFa,"xlnet"),lFa.forEach(t),cZr=r(fro," \u2014 "),Fne=n(fro,"A",{href:!0});var iFa=s(Fne);fZr=r(iFa,"TFXLNetModel"),iFa.forEach(t),gZr=r(fro," (XLNet model)"),fro.forEach(t),j.forEach(t),hZr=i(wi),T(Dw.$$.fragment,wi),wi.forEach(t),Ci.forEach(t),Wio=i(c),Mc=n(c,"H2",{class:!0});var pco=s(Mc);Gw=n(pco,"A",{id:!0,class:!0,href:!0});var dFa=s(Gw);q9e=n(dFa,"SPAN",{});var mFa=s(q9e);T(kP.$$.fragment,mFa),mFa.forEach(t),dFa.forEach(t),uZr=i(pco),j9e=n(pco,"SPAN",{});var cFa=s(j9e);pZr=r(cFa,"TFAutoModelForPreTraining"),cFa.forEach(t),pco.forEach(t),Uio=i(c),ur=n(c,"DIV",{class:!0});var Ai=s(ur);T(SP.$$.fragment,Ai),_Zr=i(Ai),Ec=n(Ai,"P",{});var bge=s(Ec);bZr=r(bge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Tne=n(bge,"A",{href:!0});var fFa=s(Tne);vZr=r(fFa,"from_pretrained()"),fFa.forEach(t),FZr=r(bge," class method or the "),Mne=n(bge,"A",{href:!0});var gFa=s(Mne);TZr=r(gFa,"from_config()"),gFa.forEach(t),MZr=r(bge,` class
method.`),bge.forEach(t),EZr=i(Ai),RP=n(Ai,"P",{});var _co=s(RP);CZr=r(_co,"This class cannot be instantiated directly using "),D9e=n(_co,"CODE",{});var hFa=s(D9e);wZr=r(hFa,"__init__()"),hFa.forEach(t),AZr=r(_co," (throws an error)."),_co.forEach(t),LZr=i(Ai),ra=n(Ai,"DIV",{class:!0});var c$=s(ra);T(PP.$$.fragment,c$),yZr=i(c$),G9e=n(c$,"P",{});var uFa=s(G9e);xZr=r(uFa,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),uFa.forEach(t),$Zr=i(c$),Cc=n(c$,"P",{});var vge=s(Cc);kZr=r(vge,`Note:
Loading a model from its configuration file does `),O9e=n(vge,"STRONG",{});var pFa=s(O9e);SZr=r(pFa,"not"),pFa.forEach(t),RZr=r(vge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ene=n(vge,"A",{href:!0});var _Fa=s(Ene);PZr=r(_Fa,"from_pretrained()"),_Fa.forEach(t),BZr=r(vge," to load the model weights."),vge.forEach(t),IZr=i(c$),T(Ow.$$.fragment,c$),c$.forEach(t),NZr=i(Ai),zr=n(Ai,"DIV",{class:!0});var Li=s(zr);T(BP.$$.fragment,Li),qZr=i(Li),V9e=n(Li,"P",{});var bFa=s(V9e);jZr=r(bFa,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),bFa.forEach(t),DZr=i(Li),On=n(Li,"P",{});var f$=s(On);GZr=r(f$,"The model class to instantiate is selected based on the "),X9e=n(f$,"CODE",{});var vFa=s(X9e);OZr=r(vFa,"model_type"),vFa.forEach(t),VZr=r(f$,` property of the config object (either
passed as an argument or loaded from `),z9e=n(f$,"CODE",{});var FFa=s(z9e);XZr=r(FFa,"pretrained_model_name_or_path"),FFa.forEach(t),zZr=r(f$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q9e=n(f$,"CODE",{});var TFa=s(Q9e);QZr=r(TFa,"pretrained_model_name_or_path"),TFa.forEach(t),WZr=r(f$,":"),f$.forEach(t),UZr=i(Li),de=n(Li,"UL",{});var fe=s(de);Vw=n(fe,"LI",{});var gro=s(Vw);W9e=n(gro,"STRONG",{});var MFa=s(W9e);HZr=r(MFa,"albert"),MFa.forEach(t),JZr=r(gro," \u2014 "),Cne=n(gro,"A",{href:!0});var EFa=s(Cne);YZr=r(EFa,"TFAlbertForPreTraining"),EFa.forEach(t),ZZr=r(gro," (ALBERT model)"),gro.forEach(t),KZr=i(fe),Xw=n(fe,"LI",{});var hro=s(Xw);U9e=n(hro,"STRONG",{});var CFa=s(U9e);eKr=r(CFa,"bart"),CFa.forEach(t),oKr=r(hro," \u2014 "),wne=n(hro,"A",{href:!0});var wFa=s(wne);rKr=r(wFa,"TFBartForConditionalGeneration"),wFa.forEach(t),tKr=r(hro," (BART model)"),hro.forEach(t),aKr=i(fe),zw=n(fe,"LI",{});var uro=s(zw);H9e=n(uro,"STRONG",{});var AFa=s(H9e);nKr=r(AFa,"bert"),AFa.forEach(t),sKr=r(uro," \u2014 "),Ane=n(uro,"A",{href:!0});var LFa=s(Ane);lKr=r(LFa,"TFBertForPreTraining"),LFa.forEach(t),iKr=r(uro," (BERT model)"),uro.forEach(t),dKr=i(fe),Qw=n(fe,"LI",{});var pro=s(Qw);J9e=n(pro,"STRONG",{});var yFa=s(J9e);mKr=r(yFa,"camembert"),yFa.forEach(t),cKr=r(pro," \u2014 "),Lne=n(pro,"A",{href:!0});var xFa=s(Lne);fKr=r(xFa,"TFCamembertForMaskedLM"),xFa.forEach(t),gKr=r(pro," (CamemBERT model)"),pro.forEach(t),hKr=i(fe),Ww=n(fe,"LI",{});var _ro=s(Ww);Y9e=n(_ro,"STRONG",{});var $Fa=s(Y9e);uKr=r($Fa,"ctrl"),$Fa.forEach(t),pKr=r(_ro," \u2014 "),yne=n(_ro,"A",{href:!0});var kFa=s(yne);_Kr=r(kFa,"TFCTRLLMHeadModel"),kFa.forEach(t),bKr=r(_ro," (CTRL model)"),_ro.forEach(t),vKr=i(fe),Uw=n(fe,"LI",{});var bro=s(Uw);Z9e=n(bro,"STRONG",{});var SFa=s(Z9e);FKr=r(SFa,"distilbert"),SFa.forEach(t),TKr=r(bro," \u2014 "),xne=n(bro,"A",{href:!0});var RFa=s(xne);MKr=r(RFa,"TFDistilBertForMaskedLM"),RFa.forEach(t),EKr=r(bro," (DistilBERT model)"),bro.forEach(t),CKr=i(fe),Hw=n(fe,"LI",{});var vro=s(Hw);K9e=n(vro,"STRONG",{});var PFa=s(K9e);wKr=r(PFa,"electra"),PFa.forEach(t),AKr=r(vro," \u2014 "),$ne=n(vro,"A",{href:!0});var BFa=s($ne);LKr=r(BFa,"TFElectraForPreTraining"),BFa.forEach(t),yKr=r(vro," (ELECTRA model)"),vro.forEach(t),xKr=i(fe),Jw=n(fe,"LI",{});var Fro=s(Jw);exe=n(Fro,"STRONG",{});var IFa=s(exe);$Kr=r(IFa,"flaubert"),IFa.forEach(t),kKr=r(Fro," \u2014 "),kne=n(Fro,"A",{href:!0});var NFa=s(kne);SKr=r(NFa,"TFFlaubertWithLMHeadModel"),NFa.forEach(t),RKr=r(Fro," (FlauBERT model)"),Fro.forEach(t),PKr=i(fe),Yw=n(fe,"LI",{});var Tro=s(Yw);oxe=n(Tro,"STRONG",{});var qFa=s(oxe);BKr=r(qFa,"funnel"),qFa.forEach(t),IKr=r(Tro," \u2014 "),Sne=n(Tro,"A",{href:!0});var jFa=s(Sne);NKr=r(jFa,"TFFunnelForPreTraining"),jFa.forEach(t),qKr=r(Tro," (Funnel Transformer model)"),Tro.forEach(t),jKr=i(fe),Zw=n(fe,"LI",{});var Mro=s(Zw);rxe=n(Mro,"STRONG",{});var DFa=s(rxe);DKr=r(DFa,"gpt2"),DFa.forEach(t),GKr=r(Mro," \u2014 "),Rne=n(Mro,"A",{href:!0});var GFa=s(Rne);OKr=r(GFa,"TFGPT2LMHeadModel"),GFa.forEach(t),VKr=r(Mro," (OpenAI GPT-2 model)"),Mro.forEach(t),XKr=i(fe),Kw=n(fe,"LI",{});var Ero=s(Kw);txe=n(Ero,"STRONG",{});var OFa=s(txe);zKr=r(OFa,"layoutlm"),OFa.forEach(t),QKr=r(Ero," \u2014 "),Pne=n(Ero,"A",{href:!0});var VFa=s(Pne);WKr=r(VFa,"TFLayoutLMForMaskedLM"),VFa.forEach(t),UKr=r(Ero," (LayoutLM model)"),Ero.forEach(t),HKr=i(fe),eA=n(fe,"LI",{});var Cro=s(eA);axe=n(Cro,"STRONG",{});var XFa=s(axe);JKr=r(XFa,"lxmert"),XFa.forEach(t),YKr=r(Cro," \u2014 "),Bne=n(Cro,"A",{href:!0});var zFa=s(Bne);ZKr=r(zFa,"TFLxmertForPreTraining"),zFa.forEach(t),KKr=r(Cro," (LXMERT model)"),Cro.forEach(t),eet=i(fe),oA=n(fe,"LI",{});var wro=s(oA);nxe=n(wro,"STRONG",{});var QFa=s(nxe);oet=r(QFa,"mobilebert"),QFa.forEach(t),ret=r(wro," \u2014 "),Ine=n(wro,"A",{href:!0});var WFa=s(Ine);tet=r(WFa,"TFMobileBertForPreTraining"),WFa.forEach(t),aet=r(wro," (MobileBERT model)"),wro.forEach(t),net=i(fe),rA=n(fe,"LI",{});var Aro=s(rA);sxe=n(Aro,"STRONG",{});var UFa=s(sxe);set=r(UFa,"mpnet"),UFa.forEach(t),iet=r(Aro," \u2014 "),Nne=n(Aro,"A",{href:!0});var HFa=s(Nne);det=r(HFa,"TFMPNetForMaskedLM"),HFa.forEach(t),met=r(Aro," (MPNet model)"),Aro.forEach(t),cet=i(fe),tA=n(fe,"LI",{});var Lro=s(tA);lxe=n(Lro,"STRONG",{});var JFa=s(lxe);fet=r(JFa,"openai-gpt"),JFa.forEach(t),get=r(Lro," \u2014 "),qne=n(Lro,"A",{href:!0});var YFa=s(qne);het=r(YFa,"TFOpenAIGPTLMHeadModel"),YFa.forEach(t),uet=r(Lro," (OpenAI GPT model)"),Lro.forEach(t),pet=i(fe),aA=n(fe,"LI",{});var yro=s(aA);ixe=n(yro,"STRONG",{});var ZFa=s(ixe);_et=r(ZFa,"roberta"),ZFa.forEach(t),bet=r(yro," \u2014 "),jne=n(yro,"A",{href:!0});var KFa=s(jne);vet=r(KFa,"TFRobertaForMaskedLM"),KFa.forEach(t),Fet=r(yro," (RoBERTa model)"),yro.forEach(t),Tet=i(fe),nA=n(fe,"LI",{});var xro=s(nA);dxe=n(xro,"STRONG",{});var eTa=s(dxe);Met=r(eTa,"t5"),eTa.forEach(t),Eet=r(xro," \u2014 "),Dne=n(xro,"A",{href:!0});var oTa=s(Dne);Cet=r(oTa,"TFT5ForConditionalGeneration"),oTa.forEach(t),wet=r(xro," (T5 model)"),xro.forEach(t),Aet=i(fe),sA=n(fe,"LI",{});var $ro=s(sA);mxe=n($ro,"STRONG",{});var rTa=s(mxe);Let=r(rTa,"tapas"),rTa.forEach(t),yet=r($ro," \u2014 "),Gne=n($ro,"A",{href:!0});var tTa=s(Gne);xet=r(tTa,"TFTapasForMaskedLM"),tTa.forEach(t),$et=r($ro," (TAPAS model)"),$ro.forEach(t),ket=i(fe),lA=n(fe,"LI",{});var kro=s(lA);cxe=n(kro,"STRONG",{});var aTa=s(cxe);Set=r(aTa,"transfo-xl"),aTa.forEach(t),Ret=r(kro," \u2014 "),One=n(kro,"A",{href:!0});var nTa=s(One);Pet=r(nTa,"TFTransfoXLLMHeadModel"),nTa.forEach(t),Bet=r(kro," (Transformer-XL model)"),kro.forEach(t),Iet=i(fe),iA=n(fe,"LI",{});var Sro=s(iA);fxe=n(Sro,"STRONG",{});var sTa=s(fxe);Net=r(sTa,"vit_mae"),sTa.forEach(t),qet=r(Sro," \u2014 "),Vne=n(Sro,"A",{href:!0});var lTa=s(Vne);jet=r(lTa,"TFViTMAEForPreTraining"),lTa.forEach(t),Det=r(Sro," (ViTMAE model)"),Sro.forEach(t),Get=i(fe),dA=n(fe,"LI",{});var Rro=s(dA);gxe=n(Rro,"STRONG",{});var iTa=s(gxe);Oet=r(iTa,"xlm"),iTa.forEach(t),Vet=r(Rro," \u2014 "),Xne=n(Rro,"A",{href:!0});var dTa=s(Xne);Xet=r(dTa,"TFXLMWithLMHeadModel"),dTa.forEach(t),zet=r(Rro," (XLM model)"),Rro.forEach(t),Qet=i(fe),mA=n(fe,"LI",{});var Pro=s(mA);hxe=n(Pro,"STRONG",{});var mTa=s(hxe);Wet=r(mTa,"xlm-roberta"),mTa.forEach(t),Uet=r(Pro," \u2014 "),zne=n(Pro,"A",{href:!0});var cTa=s(zne);Het=r(cTa,"TFXLMRobertaForMaskedLM"),cTa.forEach(t),Jet=r(Pro," (XLM-RoBERTa model)"),Pro.forEach(t),Yet=i(fe),cA=n(fe,"LI",{});var Bro=s(cA);uxe=n(Bro,"STRONG",{});var fTa=s(uxe);Zet=r(fTa,"xlnet"),fTa.forEach(t),Ket=r(Bro," \u2014 "),Qne=n(Bro,"A",{href:!0});var gTa=s(Qne);eot=r(gTa,"TFXLNetLMHeadModel"),gTa.forEach(t),oot=r(Bro," (XLNet model)"),Bro.forEach(t),fe.forEach(t),rot=i(Li),T(fA.$$.fragment,Li),Li.forEach(t),Ai.forEach(t),Hio=i(c),wc=n(c,"H2",{class:!0});var bco=s(wc);gA=n(bco,"A",{id:!0,class:!0,href:!0});var hTa=s(gA);pxe=n(hTa,"SPAN",{});var uTa=s(pxe);T(IP.$$.fragment,uTa),uTa.forEach(t),hTa.forEach(t),tot=i(bco),_xe=n(bco,"SPAN",{});var pTa=s(_xe);aot=r(pTa,"TFAutoModelForCausalLM"),pTa.forEach(t),bco.forEach(t),Jio=i(c),pr=n(c,"DIV",{class:!0});var yi=s(pr);T(NP.$$.fragment,yi),not=i(yi),Ac=n(yi,"P",{});var Fge=s(Ac);sot=r(Fge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Wne=n(Fge,"A",{href:!0});var _Ta=s(Wne);lot=r(_Ta,"from_pretrained()"),_Ta.forEach(t),iot=r(Fge," class method or the "),Une=n(Fge,"A",{href:!0});var bTa=s(Une);dot=r(bTa,"from_config()"),bTa.forEach(t),mot=r(Fge,` class
method.`),Fge.forEach(t),cot=i(yi),qP=n(yi,"P",{});var vco=s(qP);fot=r(vco,"This class cannot be instantiated directly using "),bxe=n(vco,"CODE",{});var vTa=s(bxe);got=r(vTa,"__init__()"),vTa.forEach(t),hot=r(vco," (throws an error)."),vco.forEach(t),uot=i(yi),ta=n(yi,"DIV",{class:!0});var g$=s(ta);T(jP.$$.fragment,g$),pot=i(g$),vxe=n(g$,"P",{});var FTa=s(vxe);_ot=r(FTa,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),FTa.forEach(t),bot=i(g$),Lc=n(g$,"P",{});var Tge=s(Lc);vot=r(Tge,`Note:
Loading a model from its configuration file does `),Fxe=n(Tge,"STRONG",{});var TTa=s(Fxe);Fot=r(TTa,"not"),TTa.forEach(t),Tot=r(Tge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Hne=n(Tge,"A",{href:!0});var MTa=s(Hne);Mot=r(MTa,"from_pretrained()"),MTa.forEach(t),Eot=r(Tge," to load the model weights."),Tge.forEach(t),Cot=i(g$),T(hA.$$.fragment,g$),g$.forEach(t),wot=i(yi),Qr=n(yi,"DIV",{class:!0});var xi=s(Qr);T(DP.$$.fragment,xi),Aot=i(xi),Txe=n(xi,"P",{});var ETa=s(Txe);Lot=r(ETa,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),ETa.forEach(t),yot=i(xi),Vn=n(xi,"P",{});var h$=s(Vn);xot=r(h$,"The model class to instantiate is selected based on the "),Mxe=n(h$,"CODE",{});var CTa=s(Mxe);$ot=r(CTa,"model_type"),CTa.forEach(t),kot=r(h$,` property of the config object (either
passed as an argument or loaded from `),Exe=n(h$,"CODE",{});var wTa=s(Exe);Sot=r(wTa,"pretrained_model_name_or_path"),wTa.forEach(t),Rot=r(h$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Cxe=n(h$,"CODE",{});var ATa=s(Cxe);Pot=r(ATa,"pretrained_model_name_or_path"),ATa.forEach(t),Bot=r(h$,":"),h$.forEach(t),Iot=i(xi),Ce=n(xi,"UL",{});var Ae=s(Ce);uA=n(Ae,"LI",{});var Iro=s(uA);wxe=n(Iro,"STRONG",{});var LTa=s(wxe);Not=r(LTa,"bert"),LTa.forEach(t),qot=r(Iro," \u2014 "),Jne=n(Iro,"A",{href:!0});var yTa=s(Jne);jot=r(yTa,"TFBertLMHeadModel"),yTa.forEach(t),Dot=r(Iro," (BERT model)"),Iro.forEach(t),Got=i(Ae),pA=n(Ae,"LI",{});var Nro=s(pA);Axe=n(Nro,"STRONG",{});var xTa=s(Axe);Oot=r(xTa,"camembert"),xTa.forEach(t),Vot=r(Nro," \u2014 "),Yne=n(Nro,"A",{href:!0});var $Ta=s(Yne);Xot=r($Ta,"TFCamembertForCausalLM"),$Ta.forEach(t),zot=r(Nro," (CamemBERT model)"),Nro.forEach(t),Qot=i(Ae),_A=n(Ae,"LI",{});var qro=s(_A);Lxe=n(qro,"STRONG",{});var kTa=s(Lxe);Wot=r(kTa,"ctrl"),kTa.forEach(t),Uot=r(qro," \u2014 "),Zne=n(qro,"A",{href:!0});var STa=s(Zne);Hot=r(STa,"TFCTRLLMHeadModel"),STa.forEach(t),Jot=r(qro," (CTRL model)"),qro.forEach(t),Yot=i(Ae),bA=n(Ae,"LI",{});var jro=s(bA);yxe=n(jro,"STRONG",{});var RTa=s(yxe);Zot=r(RTa,"gpt2"),RTa.forEach(t),Kot=r(jro," \u2014 "),Kne=n(jro,"A",{href:!0});var PTa=s(Kne);ert=r(PTa,"TFGPT2LMHeadModel"),PTa.forEach(t),ort=r(jro," (OpenAI GPT-2 model)"),jro.forEach(t),rrt=i(Ae),vA=n(Ae,"LI",{});var Dro=s(vA);xxe=n(Dro,"STRONG",{});var BTa=s(xxe);trt=r(BTa,"gptj"),BTa.forEach(t),art=r(Dro," \u2014 "),ese=n(Dro,"A",{href:!0});var ITa=s(ese);nrt=r(ITa,"TFGPTJForCausalLM"),ITa.forEach(t),srt=r(Dro," (GPT-J model)"),Dro.forEach(t),lrt=i(Ae),FA=n(Ae,"LI",{});var Gro=s(FA);$xe=n(Gro,"STRONG",{});var NTa=s($xe);irt=r(NTa,"openai-gpt"),NTa.forEach(t),drt=r(Gro," \u2014 "),ose=n(Gro,"A",{href:!0});var qTa=s(ose);mrt=r(qTa,"TFOpenAIGPTLMHeadModel"),qTa.forEach(t),crt=r(Gro," (OpenAI GPT model)"),Gro.forEach(t),frt=i(Ae),TA=n(Ae,"LI",{});var Oro=s(TA);kxe=n(Oro,"STRONG",{});var jTa=s(kxe);grt=r(jTa,"opt"),jTa.forEach(t),hrt=r(Oro," \u2014 "),rse=n(Oro,"A",{href:!0});var DTa=s(rse);urt=r(DTa,"TFOPTForCausalLM"),DTa.forEach(t),prt=r(Oro," (OPT model)"),Oro.forEach(t),_rt=i(Ae),MA=n(Ae,"LI",{});var Vro=s(MA);Sxe=n(Vro,"STRONG",{});var GTa=s(Sxe);brt=r(GTa,"rembert"),GTa.forEach(t),vrt=r(Vro," \u2014 "),tse=n(Vro,"A",{href:!0});var OTa=s(tse);Frt=r(OTa,"TFRemBertForCausalLM"),OTa.forEach(t),Trt=r(Vro," (RemBERT model)"),Vro.forEach(t),Mrt=i(Ae),EA=n(Ae,"LI",{});var Xro=s(EA);Rxe=n(Xro,"STRONG",{});var VTa=s(Rxe);Ert=r(VTa,"roberta"),VTa.forEach(t),Crt=r(Xro," \u2014 "),ase=n(Xro,"A",{href:!0});var XTa=s(ase);wrt=r(XTa,"TFRobertaForCausalLM"),XTa.forEach(t),Art=r(Xro," (RoBERTa model)"),Xro.forEach(t),Lrt=i(Ae),CA=n(Ae,"LI",{});var zro=s(CA);Pxe=n(zro,"STRONG",{});var zTa=s(Pxe);yrt=r(zTa,"roformer"),zTa.forEach(t),xrt=r(zro," \u2014 "),nse=n(zro,"A",{href:!0});var QTa=s(nse);$rt=r(QTa,"TFRoFormerForCausalLM"),QTa.forEach(t),krt=r(zro," (RoFormer model)"),zro.forEach(t),Srt=i(Ae),wA=n(Ae,"LI",{});var Qro=s(wA);Bxe=n(Qro,"STRONG",{});var WTa=s(Bxe);Rrt=r(WTa,"transfo-xl"),WTa.forEach(t),Prt=r(Qro," \u2014 "),sse=n(Qro,"A",{href:!0});var UTa=s(sse);Brt=r(UTa,"TFTransfoXLLMHeadModel"),UTa.forEach(t),Irt=r(Qro," (Transformer-XL model)"),Qro.forEach(t),Nrt=i(Ae),AA=n(Ae,"LI",{});var Wro=s(AA);Ixe=n(Wro,"STRONG",{});var HTa=s(Ixe);qrt=r(HTa,"xglm"),HTa.forEach(t),jrt=r(Wro," \u2014 "),lse=n(Wro,"A",{href:!0});var JTa=s(lse);Drt=r(JTa,"TFXGLMForCausalLM"),JTa.forEach(t),Grt=r(Wro," (XGLM model)"),Wro.forEach(t),Ort=i(Ae),LA=n(Ae,"LI",{});var Uro=s(LA);Nxe=n(Uro,"STRONG",{});var YTa=s(Nxe);Vrt=r(YTa,"xlm"),YTa.forEach(t),Xrt=r(Uro," \u2014 "),ise=n(Uro,"A",{href:!0});var ZTa=s(ise);zrt=r(ZTa,"TFXLMWithLMHeadModel"),ZTa.forEach(t),Qrt=r(Uro," (XLM model)"),Uro.forEach(t),Wrt=i(Ae),yA=n(Ae,"LI",{});var Hro=s(yA);qxe=n(Hro,"STRONG",{});var KTa=s(qxe);Urt=r(KTa,"xlnet"),KTa.forEach(t),Hrt=r(Hro," \u2014 "),dse=n(Hro,"A",{href:!0});var eMa=s(dse);Jrt=r(eMa,"TFXLNetLMHeadModel"),eMa.forEach(t),Yrt=r(Hro," (XLNet model)"),Hro.forEach(t),Ae.forEach(t),Zrt=i(xi),T(xA.$$.fragment,xi),xi.forEach(t),yi.forEach(t),Yio=i(c),yc=n(c,"H2",{class:!0});var Fco=s(yc);$A=n(Fco,"A",{id:!0,class:!0,href:!0});var oMa=s($A);jxe=n(oMa,"SPAN",{});var rMa=s(jxe);T(GP.$$.fragment,rMa),rMa.forEach(t),oMa.forEach(t),Krt=i(Fco),Dxe=n(Fco,"SPAN",{});var tMa=s(Dxe);ett=r(tMa,"TFAutoModelForImageClassification"),tMa.forEach(t),Fco.forEach(t),Zio=i(c),_r=n(c,"DIV",{class:!0});var $i=s(_r);T(OP.$$.fragment,$i),ott=i($i),xc=n($i,"P",{});var Mge=s(xc);rtt=r(Mge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),mse=n(Mge,"A",{href:!0});var aMa=s(mse);ttt=r(aMa,"from_pretrained()"),aMa.forEach(t),att=r(Mge," class method or the "),cse=n(Mge,"A",{href:!0});var nMa=s(cse);ntt=r(nMa,"from_config()"),nMa.forEach(t),stt=r(Mge,` class
method.`),Mge.forEach(t),ltt=i($i),VP=n($i,"P",{});var Tco=s(VP);itt=r(Tco,"This class cannot be instantiated directly using "),Gxe=n(Tco,"CODE",{});var sMa=s(Gxe);dtt=r(sMa,"__init__()"),sMa.forEach(t),mtt=r(Tco," (throws an error)."),Tco.forEach(t),ctt=i($i),aa=n($i,"DIV",{class:!0});var u$=s(aa);T(XP.$$.fragment,u$),ftt=i(u$),Oxe=n(u$,"P",{});var lMa=s(Oxe);gtt=r(lMa,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),lMa.forEach(t),htt=i(u$),$c=n(u$,"P",{});var Ege=s($c);utt=r(Ege,`Note:
Loading a model from its configuration file does `),Vxe=n(Ege,"STRONG",{});var iMa=s(Vxe);ptt=r(iMa,"not"),iMa.forEach(t),_tt=r(Ege,` load the model weights. It only affects the
model\u2019s configuration. Use `),fse=n(Ege,"A",{href:!0});var dMa=s(fse);btt=r(dMa,"from_pretrained()"),dMa.forEach(t),vtt=r(Ege," to load the model weights."),Ege.forEach(t),Ftt=i(u$),T(kA.$$.fragment,u$),u$.forEach(t),Ttt=i($i),Wr=n($i,"DIV",{class:!0});var ki=s(Wr);T(zP.$$.fragment,ki),Mtt=i(ki),Xxe=n(ki,"P",{});var mMa=s(Xxe);Ett=r(mMa,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),mMa.forEach(t),Ctt=i(ki),Xn=n(ki,"P",{});var p$=s(Xn);wtt=r(p$,"The model class to instantiate is selected based on the "),zxe=n(p$,"CODE",{});var cMa=s(zxe);Att=r(cMa,"model_type"),cMa.forEach(t),Ltt=r(p$,` property of the config object (either
passed as an argument or loaded from `),Qxe=n(p$,"CODE",{});var fMa=s(Qxe);ytt=r(fMa,"pretrained_model_name_or_path"),fMa.forEach(t),xtt=r(p$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wxe=n(p$,"CODE",{});var gMa=s(Wxe);$tt=r(gMa,"pretrained_model_name_or_path"),gMa.forEach(t),ktt=r(p$,":"),p$.forEach(t),Stt=i(ki),$e=n(ki,"UL",{});var je=s($e);SA=n(je,"LI",{});var Jro=s(SA);Uxe=n(Jro,"STRONG",{});var hMa=s(Uxe);Rtt=r(hMa,"convnext"),hMa.forEach(t),Ptt=r(Jro," \u2014 "),gse=n(Jro,"A",{href:!0});var uMa=s(gse);Btt=r(uMa,"TFConvNextForImageClassification"),uMa.forEach(t),Itt=r(Jro," (ConvNeXT model)"),Jro.forEach(t),Ntt=i(je),RA=n(je,"LI",{});var Yro=s(RA);Hxe=n(Yro,"STRONG",{});var pMa=s(Hxe);qtt=r(pMa,"cvt"),pMa.forEach(t),jtt=r(Yro," \u2014 "),hse=n(Yro,"A",{href:!0});var _Ma=s(hse);Dtt=r(_Ma,"TFCvtForImageClassification"),_Ma.forEach(t),Gtt=r(Yro," (CvT model)"),Yro.forEach(t),Ott=i(je),PA=n(je,"LI",{});var Zro=s(PA);Jxe=n(Zro,"STRONG",{});var bMa=s(Jxe);Vtt=r(bMa,"data2vec-vision"),bMa.forEach(t),Xtt=r(Zro," \u2014 "),use=n(Zro,"A",{href:!0});var vMa=s(use);ztt=r(vMa,"TFData2VecVisionForImageClassification"),vMa.forEach(t),Qtt=r(Zro," (Data2VecVision model)"),Zro.forEach(t),Wtt=i(je),Dl=n(je,"LI",{});var Pq=s(Dl);Yxe=n(Pq,"STRONG",{});var FMa=s(Yxe);Utt=r(FMa,"deit"),FMa.forEach(t),Htt=r(Pq," \u2014 "),pse=n(Pq,"A",{href:!0});var TMa=s(pse);Jtt=r(TMa,"TFDeiTForImageClassification"),TMa.forEach(t),Ytt=r(Pq," or "),_se=n(Pq,"A",{href:!0});var MMa=s(_se);Ztt=r(MMa,"TFDeiTForImageClassificationWithTeacher"),MMa.forEach(t),Ktt=r(Pq," (DeiT model)"),Pq.forEach(t),eat=i(je),BA=n(je,"LI",{});var Kro=s(BA);Zxe=n(Kro,"STRONG",{});var EMa=s(Zxe);oat=r(EMa,"mobilevit"),EMa.forEach(t),rat=r(Kro," \u2014 "),bse=n(Kro,"A",{href:!0});var CMa=s(bse);tat=r(CMa,"TFMobileViTForImageClassification"),CMa.forEach(t),aat=r(Kro," (MobileViT model)"),Kro.forEach(t),nat=i(je),IA=n(je,"LI",{});var eto=s(IA);Kxe=n(eto,"STRONG",{});var wMa=s(Kxe);sat=r(wMa,"regnet"),wMa.forEach(t),lat=r(eto," \u2014 "),vse=n(eto,"A",{href:!0});var AMa=s(vse);iat=r(AMa,"TFRegNetForImageClassification"),AMa.forEach(t),dat=r(eto," (RegNet model)"),eto.forEach(t),mat=i(je),NA=n(je,"LI",{});var oto=s(NA);e$e=n(oto,"STRONG",{});var LMa=s(e$e);cat=r(LMa,"resnet"),LMa.forEach(t),fat=r(oto," \u2014 "),Fse=n(oto,"A",{href:!0});var yMa=s(Fse);gat=r(yMa,"TFResNetForImageClassification"),yMa.forEach(t),hat=r(oto," (ResNet model)"),oto.forEach(t),uat=i(je),qA=n(je,"LI",{});var rto=s(qA);o$e=n(rto,"STRONG",{});var xMa=s(o$e);pat=r(xMa,"segformer"),xMa.forEach(t),_at=r(rto," \u2014 "),Tse=n(rto,"A",{href:!0});var $Ma=s(Tse);bat=r($Ma,"TFSegformerForImageClassification"),$Ma.forEach(t),vat=r(rto," (SegFormer model)"),rto.forEach(t),Fat=i(je),jA=n(je,"LI",{});var tto=s(jA);r$e=n(tto,"STRONG",{});var kMa=s(r$e);Tat=r(kMa,"swin"),kMa.forEach(t),Mat=r(tto," \u2014 "),Mse=n(tto,"A",{href:!0});var SMa=s(Mse);Eat=r(SMa,"TFSwinForImageClassification"),SMa.forEach(t),Cat=r(tto," (Swin Transformer model)"),tto.forEach(t),wat=i(je),DA=n(je,"LI",{});var ato=s(DA);t$e=n(ato,"STRONG",{});var RMa=s(t$e);Aat=r(RMa,"vit"),RMa.forEach(t),Lat=r(ato," \u2014 "),Ese=n(ato,"A",{href:!0});var PMa=s(Ese);yat=r(PMa,"TFViTForImageClassification"),PMa.forEach(t),xat=r(ato," (ViT model)"),ato.forEach(t),je.forEach(t),$at=i(ki),T(GA.$$.fragment,ki),ki.forEach(t),$i.forEach(t),Kio=i(c),kc=n(c,"H2",{class:!0});var Mco=s(kc);OA=n(Mco,"A",{id:!0,class:!0,href:!0});var BMa=s(OA);a$e=n(BMa,"SPAN",{});var IMa=s(a$e);T(QP.$$.fragment,IMa),IMa.forEach(t),BMa.forEach(t),kat=i(Mco),n$e=n(Mco,"SPAN",{});var NMa=s(n$e);Sat=r(NMa,"TFAutoModelForSemanticSegmentation"),NMa.forEach(t),Mco.forEach(t),edo=i(c),br=n(c,"DIV",{class:!0});var Si=s(br);T(WP.$$.fragment,Si),Rat=i(Si),Sc=n(Si,"P",{});var Cge=s(Sc);Pat=r(Cge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Cse=n(Cge,"A",{href:!0});var qMa=s(Cse);Bat=r(qMa,"from_pretrained()"),qMa.forEach(t),Iat=r(Cge," class method or the "),wse=n(Cge,"A",{href:!0});var jMa=s(wse);Nat=r(jMa,"from_config()"),jMa.forEach(t),qat=r(Cge,` class
method.`),Cge.forEach(t),jat=i(Si),UP=n(Si,"P",{});var Eco=s(UP);Dat=r(Eco,"This class cannot be instantiated directly using "),s$e=n(Eco,"CODE",{});var DMa=s(s$e);Gat=r(DMa,"__init__()"),DMa.forEach(t),Oat=r(Eco," (throws an error)."),Eco.forEach(t),Vat=i(Si),na=n(Si,"DIV",{class:!0});var _$=s(na);T(HP.$$.fragment,_$),Xat=i(_$),l$e=n(_$,"P",{});var GMa=s(l$e);zat=r(GMa,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),GMa.forEach(t),Qat=i(_$),Rc=n(_$,"P",{});var wge=s(Rc);Wat=r(wge,`Note:
Loading a model from its configuration file does `),i$e=n(wge,"STRONG",{});var OMa=s(i$e);Uat=r(OMa,"not"),OMa.forEach(t),Hat=r(wge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ase=n(wge,"A",{href:!0});var VMa=s(Ase);Jat=r(VMa,"from_pretrained()"),VMa.forEach(t),Yat=r(wge," to load the model weights."),wge.forEach(t),Zat=i(_$),T(VA.$$.fragment,_$),_$.forEach(t),Kat=i(Si),Ur=n(Si,"DIV",{class:!0});var Ri=s(Ur);T(JP.$$.fragment,Ri),ent=i(Ri),d$e=n(Ri,"P",{});var XMa=s(d$e);ont=r(XMa,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),XMa.forEach(t),rnt=i(Ri),zn=n(Ri,"P",{});var b$=s(zn);tnt=r(b$,"The model class to instantiate is selected based on the "),m$e=n(b$,"CODE",{});var zMa=s(m$e);ant=r(zMa,"model_type"),zMa.forEach(t),nnt=r(b$,` property of the config object (either
passed as an argument or loaded from `),c$e=n(b$,"CODE",{});var QMa=s(c$e);snt=r(QMa,"pretrained_model_name_or_path"),QMa.forEach(t),lnt=r(b$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f$e=n(b$,"CODE",{});var WMa=s(f$e);int=r(WMa,"pretrained_model_name_or_path"),WMa.forEach(t),dnt=r(b$,":"),b$.forEach(t),mnt=i(Ri),Pc=n(Ri,"UL",{});var Age=s(Pc);XA=n(Age,"LI",{});var nto=s(XA);g$e=n(nto,"STRONG",{});var UMa=s(g$e);cnt=r(UMa,"data2vec-vision"),UMa.forEach(t),fnt=r(nto," \u2014 "),Lse=n(nto,"A",{href:!0});var HMa=s(Lse);gnt=r(HMa,"TFData2VecVisionForSemanticSegmentation"),HMa.forEach(t),hnt=r(nto," (Data2VecVision model)"),nto.forEach(t),unt=i(Age),zA=n(Age,"LI",{});var sto=s(zA);h$e=n(sto,"STRONG",{});var JMa=s(h$e);pnt=r(JMa,"mobilevit"),JMa.forEach(t),_nt=r(sto," \u2014 "),yse=n(sto,"A",{href:!0});var YMa=s(yse);bnt=r(YMa,"TFMobileViTForSemanticSegmentation"),YMa.forEach(t),vnt=r(sto," (MobileViT model)"),sto.forEach(t),Fnt=i(Age),QA=n(Age,"LI",{});var lto=s(QA);u$e=n(lto,"STRONG",{});var ZMa=s(u$e);Tnt=r(ZMa,"segformer"),ZMa.forEach(t),Mnt=r(lto," \u2014 "),xse=n(lto,"A",{href:!0});var KMa=s(xse);Ent=r(KMa,"TFSegformerForSemanticSegmentation"),KMa.forEach(t),Cnt=r(lto," (SegFormer model)"),lto.forEach(t),Age.forEach(t),wnt=i(Ri),T(WA.$$.fragment,Ri),Ri.forEach(t),Si.forEach(t),odo=i(c),Bc=n(c,"H2",{class:!0});var Cco=s(Bc);UA=n(Cco,"A",{id:!0,class:!0,href:!0});var eEa=s(UA);p$e=n(eEa,"SPAN",{});var oEa=s(p$e);T(YP.$$.fragment,oEa),oEa.forEach(t),eEa.forEach(t),Ant=i(Cco),_$e=n(Cco,"SPAN",{});var rEa=s(_$e);Lnt=r(rEa,"TFAutoModelForMaskedLM"),rEa.forEach(t),Cco.forEach(t),rdo=i(c),vr=n(c,"DIV",{class:!0});var Pi=s(vr);T(ZP.$$.fragment,Pi),ynt=i(Pi),Ic=n(Pi,"P",{});var Lge=s(Ic);xnt=r(Lge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),$se=n(Lge,"A",{href:!0});var tEa=s($se);$nt=r(tEa,"from_pretrained()"),tEa.forEach(t),knt=r(Lge," class method or the "),kse=n(Lge,"A",{href:!0});var aEa=s(kse);Snt=r(aEa,"from_config()"),aEa.forEach(t),Rnt=r(Lge,` class
method.`),Lge.forEach(t),Pnt=i(Pi),KP=n(Pi,"P",{});var wco=s(KP);Bnt=r(wco,"This class cannot be instantiated directly using "),b$e=n(wco,"CODE",{});var nEa=s(b$e);Int=r(nEa,"__init__()"),nEa.forEach(t),Nnt=r(wco," (throws an error)."),wco.forEach(t),qnt=i(Pi),sa=n(Pi,"DIV",{class:!0});var v$=s(sa);T(eB.$$.fragment,v$),jnt=i(v$),v$e=n(v$,"P",{});var sEa=s(v$e);Dnt=r(sEa,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),sEa.forEach(t),Gnt=i(v$),Nc=n(v$,"P",{});var yge=s(Nc);Ont=r(yge,`Note:
Loading a model from its configuration file does `),F$e=n(yge,"STRONG",{});var lEa=s(F$e);Vnt=r(lEa,"not"),lEa.forEach(t),Xnt=r(yge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Sse=n(yge,"A",{href:!0});var iEa=s(Sse);znt=r(iEa,"from_pretrained()"),iEa.forEach(t),Qnt=r(yge," to load the model weights."),yge.forEach(t),Wnt=i(v$),T(HA.$$.fragment,v$),v$.forEach(t),Unt=i(Pi),Hr=n(Pi,"DIV",{class:!0});var Bi=s(Hr);T(oB.$$.fragment,Bi),Hnt=i(Bi),T$e=n(Bi,"P",{});var dEa=s(T$e);Jnt=r(dEa,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),dEa.forEach(t),Ynt=i(Bi),Qn=n(Bi,"P",{});var F$=s(Qn);Znt=r(F$,"The model class to instantiate is selected based on the "),M$e=n(F$,"CODE",{});var mEa=s(M$e);Knt=r(mEa,"model_type"),mEa.forEach(t),est=r(F$,` property of the config object (either
passed as an argument or loaded from `),E$e=n(F$,"CODE",{});var cEa=s(E$e);ost=r(cEa,"pretrained_model_name_or_path"),cEa.forEach(t),rst=r(F$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C$e=n(F$,"CODE",{});var fEa=s(C$e);tst=r(fEa,"pretrained_model_name_or_path"),fEa.forEach(t),ast=r(F$,":"),F$.forEach(t),nst=i(Bi),ge=n(Bi,"UL",{});var _e=s(ge);JA=n(_e,"LI",{});var ito=s(JA);w$e=n(ito,"STRONG",{});var gEa=s(w$e);sst=r(gEa,"albert"),gEa.forEach(t),lst=r(ito," \u2014 "),Rse=n(ito,"A",{href:!0});var hEa=s(Rse);ist=r(hEa,"TFAlbertForMaskedLM"),hEa.forEach(t),dst=r(ito," (ALBERT model)"),ito.forEach(t),mst=i(_e),YA=n(_e,"LI",{});var dto=s(YA);A$e=n(dto,"STRONG",{});var uEa=s(A$e);cst=r(uEa,"bert"),uEa.forEach(t),fst=r(dto," \u2014 "),Pse=n(dto,"A",{href:!0});var pEa=s(Pse);gst=r(pEa,"TFBertForMaskedLM"),pEa.forEach(t),hst=r(dto," (BERT model)"),dto.forEach(t),ust=i(_e),ZA=n(_e,"LI",{});var mto=s(ZA);L$e=n(mto,"STRONG",{});var _Ea=s(L$e);pst=r(_Ea,"camembert"),_Ea.forEach(t),_st=r(mto," \u2014 "),Bse=n(mto,"A",{href:!0});var bEa=s(Bse);bst=r(bEa,"TFCamembertForMaskedLM"),bEa.forEach(t),vst=r(mto," (CamemBERT model)"),mto.forEach(t),Fst=i(_e),KA=n(_e,"LI",{});var cto=s(KA);y$e=n(cto,"STRONG",{});var vEa=s(y$e);Tst=r(vEa,"convbert"),vEa.forEach(t),Mst=r(cto," \u2014 "),Ise=n(cto,"A",{href:!0});var FEa=s(Ise);Est=r(FEa,"TFConvBertForMaskedLM"),FEa.forEach(t),Cst=r(cto," (ConvBERT model)"),cto.forEach(t),wst=i(_e),e6=n(_e,"LI",{});var fto=s(e6);x$e=n(fto,"STRONG",{});var TEa=s(x$e);Ast=r(TEa,"deberta"),TEa.forEach(t),Lst=r(fto," \u2014 "),Nse=n(fto,"A",{href:!0});var MEa=s(Nse);yst=r(MEa,"TFDebertaForMaskedLM"),MEa.forEach(t),xst=r(fto," (DeBERTa model)"),fto.forEach(t),$st=i(_e),o6=n(_e,"LI",{});var gto=s(o6);$$e=n(gto,"STRONG",{});var EEa=s($$e);kst=r(EEa,"deberta-v2"),EEa.forEach(t),Sst=r(gto," \u2014 "),qse=n(gto,"A",{href:!0});var CEa=s(qse);Rst=r(CEa,"TFDebertaV2ForMaskedLM"),CEa.forEach(t),Pst=r(gto," (DeBERTa-v2 model)"),gto.forEach(t),Bst=i(_e),r6=n(_e,"LI",{});var hto=s(r6);k$e=n(hto,"STRONG",{});var wEa=s(k$e);Ist=r(wEa,"distilbert"),wEa.forEach(t),Nst=r(hto," \u2014 "),jse=n(hto,"A",{href:!0});var AEa=s(jse);qst=r(AEa,"TFDistilBertForMaskedLM"),AEa.forEach(t),jst=r(hto," (DistilBERT model)"),hto.forEach(t),Dst=i(_e),t6=n(_e,"LI",{});var uto=s(t6);S$e=n(uto,"STRONG",{});var LEa=s(S$e);Gst=r(LEa,"electra"),LEa.forEach(t),Ost=r(uto," \u2014 "),Dse=n(uto,"A",{href:!0});var yEa=s(Dse);Vst=r(yEa,"TFElectraForMaskedLM"),yEa.forEach(t),Xst=r(uto," (ELECTRA model)"),uto.forEach(t),zst=i(_e),a6=n(_e,"LI",{});var pto=s(a6);R$e=n(pto,"STRONG",{});var xEa=s(R$e);Qst=r(xEa,"esm"),xEa.forEach(t),Wst=r(pto," \u2014 "),Gse=n(pto,"A",{href:!0});var $Ea=s(Gse);Ust=r($Ea,"TFEsmForMaskedLM"),$Ea.forEach(t),Hst=r(pto," (ESM model)"),pto.forEach(t),Jst=i(_e),n6=n(_e,"LI",{});var _to=s(n6);P$e=n(_to,"STRONG",{});var kEa=s(P$e);Yst=r(kEa,"flaubert"),kEa.forEach(t),Zst=r(_to," \u2014 "),Ose=n(_to,"A",{href:!0});var SEa=s(Ose);Kst=r(SEa,"TFFlaubertWithLMHeadModel"),SEa.forEach(t),elt=r(_to," (FlauBERT model)"),_to.forEach(t),olt=i(_e),s6=n(_e,"LI",{});var bto=s(s6);B$e=n(bto,"STRONG",{});var REa=s(B$e);rlt=r(REa,"funnel"),REa.forEach(t),tlt=r(bto," \u2014 "),Vse=n(bto,"A",{href:!0});var PEa=s(Vse);alt=r(PEa,"TFFunnelForMaskedLM"),PEa.forEach(t),nlt=r(bto," (Funnel Transformer model)"),bto.forEach(t),slt=i(_e),l6=n(_e,"LI",{});var vto=s(l6);I$e=n(vto,"STRONG",{});var BEa=s(I$e);llt=r(BEa,"layoutlm"),BEa.forEach(t),ilt=r(vto," \u2014 "),Xse=n(vto,"A",{href:!0});var IEa=s(Xse);dlt=r(IEa,"TFLayoutLMForMaskedLM"),IEa.forEach(t),mlt=r(vto," (LayoutLM model)"),vto.forEach(t),clt=i(_e),i6=n(_e,"LI",{});var Fto=s(i6);N$e=n(Fto,"STRONG",{});var NEa=s(N$e);flt=r(NEa,"longformer"),NEa.forEach(t),glt=r(Fto," \u2014 "),zse=n(Fto,"A",{href:!0});var qEa=s(zse);hlt=r(qEa,"TFLongformerForMaskedLM"),qEa.forEach(t),ult=r(Fto," (Longformer model)"),Fto.forEach(t),plt=i(_e),d6=n(_e,"LI",{});var Tto=s(d6);q$e=n(Tto,"STRONG",{});var jEa=s(q$e);_lt=r(jEa,"mobilebert"),jEa.forEach(t),blt=r(Tto," \u2014 "),Qse=n(Tto,"A",{href:!0});var DEa=s(Qse);vlt=r(DEa,"TFMobileBertForMaskedLM"),DEa.forEach(t),Flt=r(Tto," (MobileBERT model)"),Tto.forEach(t),Tlt=i(_e),m6=n(_e,"LI",{});var Mto=s(m6);j$e=n(Mto,"STRONG",{});var GEa=s(j$e);Mlt=r(GEa,"mpnet"),GEa.forEach(t),Elt=r(Mto," \u2014 "),Wse=n(Mto,"A",{href:!0});var OEa=s(Wse);Clt=r(OEa,"TFMPNetForMaskedLM"),OEa.forEach(t),wlt=r(Mto," (MPNet model)"),Mto.forEach(t),Alt=i(_e),c6=n(_e,"LI",{});var Eto=s(c6);D$e=n(Eto,"STRONG",{});var VEa=s(D$e);Llt=r(VEa,"rembert"),VEa.forEach(t),ylt=r(Eto," \u2014 "),Use=n(Eto,"A",{href:!0});var XEa=s(Use);xlt=r(XEa,"TFRemBertForMaskedLM"),XEa.forEach(t),$lt=r(Eto," (RemBERT model)"),Eto.forEach(t),klt=i(_e),f6=n(_e,"LI",{});var Cto=s(f6);G$e=n(Cto,"STRONG",{});var zEa=s(G$e);Slt=r(zEa,"roberta"),zEa.forEach(t),Rlt=r(Cto," \u2014 "),Hse=n(Cto,"A",{href:!0});var QEa=s(Hse);Plt=r(QEa,"TFRobertaForMaskedLM"),QEa.forEach(t),Blt=r(Cto," (RoBERTa model)"),Cto.forEach(t),Ilt=i(_e),g6=n(_e,"LI",{});var wto=s(g6);O$e=n(wto,"STRONG",{});var WEa=s(O$e);Nlt=r(WEa,"roformer"),WEa.forEach(t),qlt=r(wto," \u2014 "),Jse=n(wto,"A",{href:!0});var UEa=s(Jse);jlt=r(UEa,"TFRoFormerForMaskedLM"),UEa.forEach(t),Dlt=r(wto," (RoFormer model)"),wto.forEach(t),Glt=i(_e),h6=n(_e,"LI",{});var Ato=s(h6);V$e=n(Ato,"STRONG",{});var HEa=s(V$e);Olt=r(HEa,"tapas"),HEa.forEach(t),Vlt=r(Ato," \u2014 "),Yse=n(Ato,"A",{href:!0});var JEa=s(Yse);Xlt=r(JEa,"TFTapasForMaskedLM"),JEa.forEach(t),zlt=r(Ato," (TAPAS model)"),Ato.forEach(t),Qlt=i(_e),u6=n(_e,"LI",{});var Lto=s(u6);X$e=n(Lto,"STRONG",{});var YEa=s(X$e);Wlt=r(YEa,"xlm"),YEa.forEach(t),Ult=r(Lto," \u2014 "),Zse=n(Lto,"A",{href:!0});var ZEa=s(Zse);Hlt=r(ZEa,"TFXLMWithLMHeadModel"),ZEa.forEach(t),Jlt=r(Lto," (XLM model)"),Lto.forEach(t),Ylt=i(_e),p6=n(_e,"LI",{});var yto=s(p6);z$e=n(yto,"STRONG",{});var KEa=s(z$e);Zlt=r(KEa,"xlm-roberta"),KEa.forEach(t),Klt=r(yto," \u2014 "),Kse=n(yto,"A",{href:!0});var e4a=s(Kse);eit=r(e4a,"TFXLMRobertaForMaskedLM"),e4a.forEach(t),oit=r(yto," (XLM-RoBERTa model)"),yto.forEach(t),_e.forEach(t),rit=i(Bi),T(_6.$$.fragment,Bi),Bi.forEach(t),Pi.forEach(t),tdo=i(c),qc=n(c,"H2",{class:!0});var Aco=s(qc);b6=n(Aco,"A",{id:!0,class:!0,href:!0});var o4a=s(b6);Q$e=n(o4a,"SPAN",{});var r4a=s(Q$e);T(rB.$$.fragment,r4a),r4a.forEach(t),o4a.forEach(t),tit=i(Aco),W$e=n(Aco,"SPAN",{});var t4a=s(W$e);ait=r(t4a,"TFAutoModelForSeq2SeqLM"),t4a.forEach(t),Aco.forEach(t),ado=i(c),Fr=n(c,"DIV",{class:!0});var Ii=s(Fr);T(tB.$$.fragment,Ii),nit=i(Ii),jc=n(Ii,"P",{});var xge=s(jc);sit=r(xge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),ele=n(xge,"A",{href:!0});var a4a=s(ele);lit=r(a4a,"from_pretrained()"),a4a.forEach(t),iit=r(xge," class method or the "),ole=n(xge,"A",{href:!0});var n4a=s(ole);dit=r(n4a,"from_config()"),n4a.forEach(t),mit=r(xge,` class
method.`),xge.forEach(t),cit=i(Ii),aB=n(Ii,"P",{});var Lco=s(aB);fit=r(Lco,"This class cannot be instantiated directly using "),U$e=n(Lco,"CODE",{});var s4a=s(U$e);git=r(s4a,"__init__()"),s4a.forEach(t),hit=r(Lco," (throws an error)."),Lco.forEach(t),uit=i(Ii),la=n(Ii,"DIV",{class:!0});var T$=s(la);T(nB.$$.fragment,T$),pit=i(T$),H$e=n(T$,"P",{});var l4a=s(H$e);_it=r(l4a,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),l4a.forEach(t),bit=i(T$),Dc=n(T$,"P",{});var $ge=s(Dc);vit=r($ge,`Note:
Loading a model from its configuration file does `),J$e=n($ge,"STRONG",{});var i4a=s(J$e);Fit=r(i4a,"not"),i4a.forEach(t),Tit=r($ge,` load the model weights. It only affects the
model\u2019s configuration. Use `),rle=n($ge,"A",{href:!0});var d4a=s(rle);Mit=r(d4a,"from_pretrained()"),d4a.forEach(t),Eit=r($ge," to load the model weights."),$ge.forEach(t),Cit=i(T$),T(v6.$$.fragment,T$),T$.forEach(t),wit=i(Ii),Jr=n(Ii,"DIV",{class:!0});var Ni=s(Jr);T(sB.$$.fragment,Ni),Ait=i(Ni),Y$e=n(Ni,"P",{});var m4a=s(Y$e);Lit=r(m4a,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),m4a.forEach(t),yit=i(Ni),Wn=n(Ni,"P",{});var M$=s(Wn);xit=r(M$,"The model class to instantiate is selected based on the "),Z$e=n(M$,"CODE",{});var c4a=s(Z$e);$it=r(c4a,"model_type"),c4a.forEach(t),kit=r(M$,` property of the config object (either
passed as an argument or loaded from `),K$e=n(M$,"CODE",{});var f4a=s(K$e);Sit=r(f4a,"pretrained_model_name_or_path"),f4a.forEach(t),Rit=r(M$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eke=n(M$,"CODE",{});var g4a=s(eke);Pit=r(g4a,"pretrained_model_name_or_path"),g4a.forEach(t),Bit=r(M$,":"),M$.forEach(t),Iit=i(Ni),ke=n(Ni,"UL",{});var De=s(ke);F6=n(De,"LI",{});var xto=s(F6);oke=n(xto,"STRONG",{});var h4a=s(oke);Nit=r(h4a,"bart"),h4a.forEach(t),qit=r(xto," \u2014 "),tle=n(xto,"A",{href:!0});var u4a=s(tle);jit=r(u4a,"TFBartForConditionalGeneration"),u4a.forEach(t),Dit=r(xto," (BART model)"),xto.forEach(t),Git=i(De),T6=n(De,"LI",{});var $to=s(T6);rke=n($to,"STRONG",{});var p4a=s(rke);Oit=r(p4a,"blenderbot"),p4a.forEach(t),Vit=r($to," \u2014 "),ale=n($to,"A",{href:!0});var _4a=s(ale);Xit=r(_4a,"TFBlenderbotForConditionalGeneration"),_4a.forEach(t),zit=r($to," (Blenderbot model)"),$to.forEach(t),Qit=i(De),M6=n(De,"LI",{});var kto=s(M6);tke=n(kto,"STRONG",{});var b4a=s(tke);Wit=r(b4a,"blenderbot-small"),b4a.forEach(t),Uit=r(kto," \u2014 "),nle=n(kto,"A",{href:!0});var v4a=s(nle);Hit=r(v4a,"TFBlenderbotSmallForConditionalGeneration"),v4a.forEach(t),Jit=r(kto," (BlenderbotSmall model)"),kto.forEach(t),Yit=i(De),E6=n(De,"LI",{});var Sto=s(E6);ake=n(Sto,"STRONG",{});var F4a=s(ake);Zit=r(F4a,"encoder-decoder"),F4a.forEach(t),Kit=r(Sto," \u2014 "),sle=n(Sto,"A",{href:!0});var T4a=s(sle);edt=r(T4a,"TFEncoderDecoderModel"),T4a.forEach(t),odt=r(Sto," (Encoder decoder model)"),Sto.forEach(t),rdt=i(De),C6=n(De,"LI",{});var Rto=s(C6);nke=n(Rto,"STRONG",{});var M4a=s(nke);tdt=r(M4a,"led"),M4a.forEach(t),adt=r(Rto," \u2014 "),lle=n(Rto,"A",{href:!0});var E4a=s(lle);ndt=r(E4a,"TFLEDForConditionalGeneration"),E4a.forEach(t),sdt=r(Rto," (LED model)"),Rto.forEach(t),ldt=i(De),w6=n(De,"LI",{});var Pto=s(w6);ske=n(Pto,"STRONG",{});var C4a=s(ske);idt=r(C4a,"marian"),C4a.forEach(t),ddt=r(Pto," \u2014 "),ile=n(Pto,"A",{href:!0});var w4a=s(ile);mdt=r(w4a,"TFMarianMTModel"),w4a.forEach(t),cdt=r(Pto," (Marian model)"),Pto.forEach(t),fdt=i(De),A6=n(De,"LI",{});var Bto=s(A6);lke=n(Bto,"STRONG",{});var A4a=s(lke);gdt=r(A4a,"mbart"),A4a.forEach(t),hdt=r(Bto," \u2014 "),dle=n(Bto,"A",{href:!0});var L4a=s(dle);udt=r(L4a,"TFMBartForConditionalGeneration"),L4a.forEach(t),pdt=r(Bto," (mBART model)"),Bto.forEach(t),_dt=i(De),L6=n(De,"LI",{});var Ito=s(L6);ike=n(Ito,"STRONG",{});var y4a=s(ike);bdt=r(y4a,"mt5"),y4a.forEach(t),vdt=r(Ito," \u2014 "),mle=n(Ito,"A",{href:!0});var x4a=s(mle);Fdt=r(x4a,"TFMT5ForConditionalGeneration"),x4a.forEach(t),Tdt=r(Ito," (MT5 model)"),Ito.forEach(t),Mdt=i(De),y6=n(De,"LI",{});var Nto=s(y6);dke=n(Nto,"STRONG",{});var $4a=s(dke);Edt=r($4a,"pegasus"),$4a.forEach(t),Cdt=r(Nto," \u2014 "),cle=n(Nto,"A",{href:!0});var k4a=s(cle);wdt=r(k4a,"TFPegasusForConditionalGeneration"),k4a.forEach(t),Adt=r(Nto," (Pegasus model)"),Nto.forEach(t),Ldt=i(De),x6=n(De,"LI",{});var qto=s(x6);mke=n(qto,"STRONG",{});var S4a=s(mke);ydt=r(S4a,"t5"),S4a.forEach(t),xdt=r(qto," \u2014 "),fle=n(qto,"A",{href:!0});var R4a=s(fle);$dt=r(R4a,"TFT5ForConditionalGeneration"),R4a.forEach(t),kdt=r(qto," (T5 model)"),qto.forEach(t),De.forEach(t),Sdt=i(Ni),T($6.$$.fragment,Ni),Ni.forEach(t),Ii.forEach(t),ndo=i(c),Gc=n(c,"H2",{class:!0});var yco=s(Gc);k6=n(yco,"A",{id:!0,class:!0,href:!0});var P4a=s(k6);cke=n(P4a,"SPAN",{});var B4a=s(cke);T(lB.$$.fragment,B4a),B4a.forEach(t),P4a.forEach(t),Rdt=i(yco),fke=n(yco,"SPAN",{});var I4a=s(fke);Pdt=r(I4a,"TFAutoModelForSequenceClassification"),I4a.forEach(t),yco.forEach(t),sdo=i(c),Tr=n(c,"DIV",{class:!0});var qi=s(Tr);T(iB.$$.fragment,qi),Bdt=i(qi),Oc=n(qi,"P",{});var kge=s(Oc);Idt=r(kge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),gle=n(kge,"A",{href:!0});var N4a=s(gle);Ndt=r(N4a,"from_pretrained()"),N4a.forEach(t),qdt=r(kge," class method or the "),hle=n(kge,"A",{href:!0});var q4a=s(hle);jdt=r(q4a,"from_config()"),q4a.forEach(t),Ddt=r(kge,` class
method.`),kge.forEach(t),Gdt=i(qi),dB=n(qi,"P",{});var xco=s(dB);Odt=r(xco,"This class cannot be instantiated directly using "),gke=n(xco,"CODE",{});var j4a=s(gke);Vdt=r(j4a,"__init__()"),j4a.forEach(t),Xdt=r(xco," (throws an error)."),xco.forEach(t),zdt=i(qi),ia=n(qi,"DIV",{class:!0});var E$=s(ia);T(mB.$$.fragment,E$),Qdt=i(E$),hke=n(E$,"P",{});var D4a=s(hke);Wdt=r(D4a,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),D4a.forEach(t),Udt=i(E$),Vc=n(E$,"P",{});var Sge=s(Vc);Hdt=r(Sge,`Note:
Loading a model from its configuration file does `),uke=n(Sge,"STRONG",{});var G4a=s(uke);Jdt=r(G4a,"not"),G4a.forEach(t),Ydt=r(Sge,` load the model weights. It only affects the
model\u2019s configuration. Use `),ule=n(Sge,"A",{href:!0});var O4a=s(ule);Zdt=r(O4a,"from_pretrained()"),O4a.forEach(t),Kdt=r(Sge," to load the model weights."),Sge.forEach(t),emt=i(E$),T(S6.$$.fragment,E$),E$.forEach(t),omt=i(qi),Yr=n(qi,"DIV",{class:!0});var ji=s(Yr);T(cB.$$.fragment,ji),rmt=i(ji),pke=n(ji,"P",{});var V4a=s(pke);tmt=r(V4a,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),V4a.forEach(t),amt=i(ji),Un=n(ji,"P",{});var C$=s(Un);nmt=r(C$,"The model class to instantiate is selected based on the "),_ke=n(C$,"CODE",{});var X4a=s(_ke);smt=r(X4a,"model_type"),X4a.forEach(t),lmt=r(C$,` property of the config object (either
passed as an argument or loaded from `),bke=n(C$,"CODE",{});var z4a=s(bke);imt=r(z4a,"pretrained_model_name_or_path"),z4a.forEach(t),dmt=r(C$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vke=n(C$,"CODE",{});var Q4a=s(vke);mmt=r(Q4a,"pretrained_model_name_or_path"),Q4a.forEach(t),cmt=r(C$,":"),C$.forEach(t),fmt=i(ji),te=n(ji,"UL",{});var se=s(te);R6=n(se,"LI",{});var jto=s(R6);Fke=n(jto,"STRONG",{});var W4a=s(Fke);gmt=r(W4a,"albert"),W4a.forEach(t),hmt=r(jto," \u2014 "),ple=n(jto,"A",{href:!0});var U4a=s(ple);umt=r(U4a,"TFAlbertForSequenceClassification"),U4a.forEach(t),pmt=r(jto," (ALBERT model)"),jto.forEach(t),_mt=i(se),P6=n(se,"LI",{});var Dto=s(P6);Tke=n(Dto,"STRONG",{});var H4a=s(Tke);bmt=r(H4a,"bert"),H4a.forEach(t),vmt=r(Dto," \u2014 "),_le=n(Dto,"A",{href:!0});var J4a=s(_le);Fmt=r(J4a,"TFBertForSequenceClassification"),J4a.forEach(t),Tmt=r(Dto," (BERT model)"),Dto.forEach(t),Mmt=i(se),B6=n(se,"LI",{});var Gto=s(B6);Mke=n(Gto,"STRONG",{});var Y4a=s(Mke);Emt=r(Y4a,"camembert"),Y4a.forEach(t),Cmt=r(Gto," \u2014 "),ble=n(Gto,"A",{href:!0});var Z4a=s(ble);wmt=r(Z4a,"TFCamembertForSequenceClassification"),Z4a.forEach(t),Amt=r(Gto," (CamemBERT model)"),Gto.forEach(t),Lmt=i(se),I6=n(se,"LI",{});var Oto=s(I6);Eke=n(Oto,"STRONG",{});var K4a=s(Eke);ymt=r(K4a,"convbert"),K4a.forEach(t),xmt=r(Oto," \u2014 "),vle=n(Oto,"A",{href:!0});var eCa=s(vle);$mt=r(eCa,"TFConvBertForSequenceClassification"),eCa.forEach(t),kmt=r(Oto," (ConvBERT model)"),Oto.forEach(t),Smt=i(se),N6=n(se,"LI",{});var Vto=s(N6);Cke=n(Vto,"STRONG",{});var oCa=s(Cke);Rmt=r(oCa,"ctrl"),oCa.forEach(t),Pmt=r(Vto," \u2014 "),Fle=n(Vto,"A",{href:!0});var rCa=s(Fle);Bmt=r(rCa,"TFCTRLForSequenceClassification"),rCa.forEach(t),Imt=r(Vto," (CTRL model)"),Vto.forEach(t),Nmt=i(se),q6=n(se,"LI",{});var Xto=s(q6);wke=n(Xto,"STRONG",{});var tCa=s(wke);qmt=r(tCa,"deberta"),tCa.forEach(t),jmt=r(Xto," \u2014 "),Tle=n(Xto,"A",{href:!0});var aCa=s(Tle);Dmt=r(aCa,"TFDebertaForSequenceClassification"),aCa.forEach(t),Gmt=r(Xto," (DeBERTa model)"),Xto.forEach(t),Omt=i(se),j6=n(se,"LI",{});var zto=s(j6);Ake=n(zto,"STRONG",{});var nCa=s(Ake);Vmt=r(nCa,"deberta-v2"),nCa.forEach(t),Xmt=r(zto," \u2014 "),Mle=n(zto,"A",{href:!0});var sCa=s(Mle);zmt=r(sCa,"TFDebertaV2ForSequenceClassification"),sCa.forEach(t),Qmt=r(zto," (DeBERTa-v2 model)"),zto.forEach(t),Wmt=i(se),D6=n(se,"LI",{});var Qto=s(D6);Lke=n(Qto,"STRONG",{});var lCa=s(Lke);Umt=r(lCa,"distilbert"),lCa.forEach(t),Hmt=r(Qto," \u2014 "),Ele=n(Qto,"A",{href:!0});var iCa=s(Ele);Jmt=r(iCa,"TFDistilBertForSequenceClassification"),iCa.forEach(t),Ymt=r(Qto," (DistilBERT model)"),Qto.forEach(t),Zmt=i(se),G6=n(se,"LI",{});var Wto=s(G6);yke=n(Wto,"STRONG",{});var dCa=s(yke);Kmt=r(dCa,"electra"),dCa.forEach(t),ect=r(Wto," \u2014 "),Cle=n(Wto,"A",{href:!0});var mCa=s(Cle);oct=r(mCa,"TFElectraForSequenceClassification"),mCa.forEach(t),rct=r(Wto," (ELECTRA model)"),Wto.forEach(t),tct=i(se),O6=n(se,"LI",{});var Uto=s(O6);xke=n(Uto,"STRONG",{});var cCa=s(xke);act=r(cCa,"esm"),cCa.forEach(t),nct=r(Uto," \u2014 "),wle=n(Uto,"A",{href:!0});var fCa=s(wle);sct=r(fCa,"TFEsmForSequenceClassification"),fCa.forEach(t),lct=r(Uto," (ESM model)"),Uto.forEach(t),ict=i(se),V6=n(se,"LI",{});var Hto=s(V6);$ke=n(Hto,"STRONG",{});var gCa=s($ke);dct=r(gCa,"flaubert"),gCa.forEach(t),mct=r(Hto," \u2014 "),Ale=n(Hto,"A",{href:!0});var hCa=s(Ale);cct=r(hCa,"TFFlaubertForSequenceClassification"),hCa.forEach(t),fct=r(Hto," (FlauBERT model)"),Hto.forEach(t),gct=i(se),X6=n(se,"LI",{});var Jto=s(X6);kke=n(Jto,"STRONG",{});var uCa=s(kke);hct=r(uCa,"funnel"),uCa.forEach(t),uct=r(Jto," \u2014 "),Lle=n(Jto,"A",{href:!0});var pCa=s(Lle);pct=r(pCa,"TFFunnelForSequenceClassification"),pCa.forEach(t),_ct=r(Jto," (Funnel Transformer model)"),Jto.forEach(t),bct=i(se),z6=n(se,"LI",{});var Yto=s(z6);Ske=n(Yto,"STRONG",{});var _Ca=s(Ske);vct=r(_Ca,"gpt2"),_Ca.forEach(t),Fct=r(Yto," \u2014 "),yle=n(Yto,"A",{href:!0});var bCa=s(yle);Tct=r(bCa,"TFGPT2ForSequenceClassification"),bCa.forEach(t),Mct=r(Yto," (OpenAI GPT-2 model)"),Yto.forEach(t),Ect=i(se),Q6=n(se,"LI",{});var Zto=s(Q6);Rke=n(Zto,"STRONG",{});var vCa=s(Rke);Cct=r(vCa,"gptj"),vCa.forEach(t),wct=r(Zto," \u2014 "),xle=n(Zto,"A",{href:!0});var FCa=s(xle);Act=r(FCa,"TFGPTJForSequenceClassification"),FCa.forEach(t),Lct=r(Zto," (GPT-J model)"),Zto.forEach(t),yct=i(se),W6=n(se,"LI",{});var Kto=s(W6);Pke=n(Kto,"STRONG",{});var TCa=s(Pke);xct=r(TCa,"layoutlm"),TCa.forEach(t),$ct=r(Kto," \u2014 "),$le=n(Kto,"A",{href:!0});var MCa=s($le);kct=r(MCa,"TFLayoutLMForSequenceClassification"),MCa.forEach(t),Sct=r(Kto," (LayoutLM model)"),Kto.forEach(t),Rct=i(se),U6=n(se,"LI",{});var eao=s(U6);Bke=n(eao,"STRONG",{});var ECa=s(Bke);Pct=r(ECa,"layoutlmv3"),ECa.forEach(t),Bct=r(eao," \u2014 "),kle=n(eao,"A",{href:!0});var CCa=s(kle);Ict=r(CCa,"TFLayoutLMv3ForSequenceClassification"),CCa.forEach(t),Nct=r(eao," (LayoutLMv3 model)"),eao.forEach(t),qct=i(se),H6=n(se,"LI",{});var oao=s(H6);Ike=n(oao,"STRONG",{});var wCa=s(Ike);jct=r(wCa,"longformer"),wCa.forEach(t),Dct=r(oao," \u2014 "),Sle=n(oao,"A",{href:!0});var ACa=s(Sle);Gct=r(ACa,"TFLongformerForSequenceClassification"),ACa.forEach(t),Oct=r(oao," (Longformer model)"),oao.forEach(t),Vct=i(se),J6=n(se,"LI",{});var rao=s(J6);Nke=n(rao,"STRONG",{});var LCa=s(Nke);Xct=r(LCa,"mobilebert"),LCa.forEach(t),zct=r(rao," \u2014 "),Rle=n(rao,"A",{href:!0});var yCa=s(Rle);Qct=r(yCa,"TFMobileBertForSequenceClassification"),yCa.forEach(t),Wct=r(rao," (MobileBERT model)"),rao.forEach(t),Uct=i(se),Y6=n(se,"LI",{});var tao=s(Y6);qke=n(tao,"STRONG",{});var xCa=s(qke);Hct=r(xCa,"mpnet"),xCa.forEach(t),Jct=r(tao," \u2014 "),Ple=n(tao,"A",{href:!0});var $Ca=s(Ple);Yct=r($Ca,"TFMPNetForSequenceClassification"),$Ca.forEach(t),Zct=r(tao," (MPNet model)"),tao.forEach(t),Kct=i(se),Z6=n(se,"LI",{});var aao=s(Z6);jke=n(aao,"STRONG",{});var kCa=s(jke);eft=r(kCa,"openai-gpt"),kCa.forEach(t),oft=r(aao," \u2014 "),Ble=n(aao,"A",{href:!0});var SCa=s(Ble);rft=r(SCa,"TFOpenAIGPTForSequenceClassification"),SCa.forEach(t),tft=r(aao," (OpenAI GPT model)"),aao.forEach(t),aft=i(se),K6=n(se,"LI",{});var nao=s(K6);Dke=n(nao,"STRONG",{});var RCa=s(Dke);nft=r(RCa,"rembert"),RCa.forEach(t),sft=r(nao," \u2014 "),Ile=n(nao,"A",{href:!0});var PCa=s(Ile);lft=r(PCa,"TFRemBertForSequenceClassification"),PCa.forEach(t),ift=r(nao," (RemBERT model)"),nao.forEach(t),dft=i(se),e7=n(se,"LI",{});var sao=s(e7);Gke=n(sao,"STRONG",{});var BCa=s(Gke);mft=r(BCa,"roberta"),BCa.forEach(t),cft=r(sao," \u2014 "),Nle=n(sao,"A",{href:!0});var ICa=s(Nle);fft=r(ICa,"TFRobertaForSequenceClassification"),ICa.forEach(t),gft=r(sao," (RoBERTa model)"),sao.forEach(t),hft=i(se),o7=n(se,"LI",{});var lao=s(o7);Oke=n(lao,"STRONG",{});var NCa=s(Oke);uft=r(NCa,"roformer"),NCa.forEach(t),pft=r(lao," \u2014 "),qle=n(lao,"A",{href:!0});var qCa=s(qle);_ft=r(qCa,"TFRoFormerForSequenceClassification"),qCa.forEach(t),bft=r(lao," (RoFormer model)"),lao.forEach(t),vft=i(se),r7=n(se,"LI",{});var iao=s(r7);Vke=n(iao,"STRONG",{});var jCa=s(Vke);Fft=r(jCa,"tapas"),jCa.forEach(t),Tft=r(iao," \u2014 "),jle=n(iao,"A",{href:!0});var DCa=s(jle);Mft=r(DCa,"TFTapasForSequenceClassification"),DCa.forEach(t),Eft=r(iao," (TAPAS model)"),iao.forEach(t),Cft=i(se),t7=n(se,"LI",{});var dao=s(t7);Xke=n(dao,"STRONG",{});var GCa=s(Xke);wft=r(GCa,"transfo-xl"),GCa.forEach(t),Aft=r(dao," \u2014 "),Dle=n(dao,"A",{href:!0});var OCa=s(Dle);Lft=r(OCa,"TFTransfoXLForSequenceClassification"),OCa.forEach(t),yft=r(dao," (Transformer-XL model)"),dao.forEach(t),xft=i(se),a7=n(se,"LI",{});var mao=s(a7);zke=n(mao,"STRONG",{});var VCa=s(zke);$ft=r(VCa,"xlm"),VCa.forEach(t),kft=r(mao," \u2014 "),Gle=n(mao,"A",{href:!0});var XCa=s(Gle);Sft=r(XCa,"TFXLMForSequenceClassification"),XCa.forEach(t),Rft=r(mao," (XLM model)"),mao.forEach(t),Pft=i(se),n7=n(se,"LI",{});var cao=s(n7);Qke=n(cao,"STRONG",{});var zCa=s(Qke);Bft=r(zCa,"xlm-roberta"),zCa.forEach(t),Ift=r(cao," \u2014 "),Ole=n(cao,"A",{href:!0});var QCa=s(Ole);Nft=r(QCa,"TFXLMRobertaForSequenceClassification"),QCa.forEach(t),qft=r(cao," (XLM-RoBERTa model)"),cao.forEach(t),jft=i(se),s7=n(se,"LI",{});var fao=s(s7);Wke=n(fao,"STRONG",{});var WCa=s(Wke);Dft=r(WCa,"xlnet"),WCa.forEach(t),Gft=r(fao," \u2014 "),Vle=n(fao,"A",{href:!0});var UCa=s(Vle);Oft=r(UCa,"TFXLNetForSequenceClassification"),UCa.forEach(t),Vft=r(fao," (XLNet model)"),fao.forEach(t),se.forEach(t),Xft=i(ji),T(l7.$$.fragment,ji),ji.forEach(t),qi.forEach(t),ldo=i(c),Xc=n(c,"H2",{class:!0});var $co=s(Xc);i7=n($co,"A",{id:!0,class:!0,href:!0});var HCa=s(i7);Uke=n(HCa,"SPAN",{});var JCa=s(Uke);T(fB.$$.fragment,JCa),JCa.forEach(t),HCa.forEach(t),zft=i($co),Hke=n($co,"SPAN",{});var YCa=s(Hke);Qft=r(YCa,"TFAutoModelForMultipleChoice"),YCa.forEach(t),$co.forEach(t),ido=i(c),Mr=n(c,"DIV",{class:!0});var Di=s(Mr);T(gB.$$.fragment,Di),Wft=i(Di),zc=n(Di,"P",{});var Rge=s(zc);Uft=r(Rge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Xle=n(Rge,"A",{href:!0});var ZCa=s(Xle);Hft=r(ZCa,"from_pretrained()"),ZCa.forEach(t),Jft=r(Rge," class method or the "),zle=n(Rge,"A",{href:!0});var KCa=s(zle);Yft=r(KCa,"from_config()"),KCa.forEach(t),Zft=r(Rge,` class
method.`),Rge.forEach(t),Kft=i(Di),hB=n(Di,"P",{});var kco=s(hB);egt=r(kco,"This class cannot be instantiated directly using "),Jke=n(kco,"CODE",{});var e3a=s(Jke);ogt=r(e3a,"__init__()"),e3a.forEach(t),rgt=r(kco," (throws an error)."),kco.forEach(t),tgt=i(Di),da=n(Di,"DIV",{class:!0});var w$=s(da);T(uB.$$.fragment,w$),agt=i(w$),Yke=n(w$,"P",{});var o3a=s(Yke);ngt=r(o3a,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),o3a.forEach(t),sgt=i(w$),Qc=n(w$,"P",{});var Pge=s(Qc);lgt=r(Pge,`Note:
Loading a model from its configuration file does `),Zke=n(Pge,"STRONG",{});var r3a=s(Zke);igt=r(r3a,"not"),r3a.forEach(t),dgt=r(Pge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Qle=n(Pge,"A",{href:!0});var t3a=s(Qle);mgt=r(t3a,"from_pretrained()"),t3a.forEach(t),cgt=r(Pge," to load the model weights."),Pge.forEach(t),fgt=i(w$),T(d7.$$.fragment,w$),w$.forEach(t),ggt=i(Di),Zr=n(Di,"DIV",{class:!0});var Gi=s(Zr);T(pB.$$.fragment,Gi),hgt=i(Gi),Kke=n(Gi,"P",{});var a3a=s(Kke);ugt=r(a3a,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),a3a.forEach(t),pgt=i(Gi),Hn=n(Gi,"P",{});var A$=s(Hn);_gt=r(A$,"The model class to instantiate is selected based on the "),eSe=n(A$,"CODE",{});var n3a=s(eSe);bgt=r(n3a,"model_type"),n3a.forEach(t),vgt=r(A$,` property of the config object (either
passed as an argument or loaded from `),oSe=n(A$,"CODE",{});var s3a=s(oSe);Fgt=r(s3a,"pretrained_model_name_or_path"),s3a.forEach(t),Tgt=r(A$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rSe=n(A$,"CODE",{});var l3a=s(rSe);Mgt=r(l3a,"pretrained_model_name_or_path"),l3a.forEach(t),Egt=r(A$,":"),A$.forEach(t),Cgt=i(Gi),Te=n(Gi,"UL",{});var Ee=s(Te);m7=n(Ee,"LI",{});var gao=s(m7);tSe=n(gao,"STRONG",{});var i3a=s(tSe);wgt=r(i3a,"albert"),i3a.forEach(t),Agt=r(gao," \u2014 "),Wle=n(gao,"A",{href:!0});var d3a=s(Wle);Lgt=r(d3a,"TFAlbertForMultipleChoice"),d3a.forEach(t),ygt=r(gao," (ALBERT model)"),gao.forEach(t),xgt=i(Ee),c7=n(Ee,"LI",{});var hao=s(c7);aSe=n(hao,"STRONG",{});var m3a=s(aSe);$gt=r(m3a,"bert"),m3a.forEach(t),kgt=r(hao," \u2014 "),Ule=n(hao,"A",{href:!0});var c3a=s(Ule);Sgt=r(c3a,"TFBertForMultipleChoice"),c3a.forEach(t),Rgt=r(hao," (BERT model)"),hao.forEach(t),Pgt=i(Ee),f7=n(Ee,"LI",{});var uao=s(f7);nSe=n(uao,"STRONG",{});var f3a=s(nSe);Bgt=r(f3a,"camembert"),f3a.forEach(t),Igt=r(uao," \u2014 "),Hle=n(uao,"A",{href:!0});var g3a=s(Hle);Ngt=r(g3a,"TFCamembertForMultipleChoice"),g3a.forEach(t),qgt=r(uao," (CamemBERT model)"),uao.forEach(t),jgt=i(Ee),g7=n(Ee,"LI",{});var pao=s(g7);sSe=n(pao,"STRONG",{});var h3a=s(sSe);Dgt=r(h3a,"convbert"),h3a.forEach(t),Ggt=r(pao," \u2014 "),Jle=n(pao,"A",{href:!0});var u3a=s(Jle);Ogt=r(u3a,"TFConvBertForMultipleChoice"),u3a.forEach(t),Vgt=r(pao," (ConvBERT model)"),pao.forEach(t),Xgt=i(Ee),h7=n(Ee,"LI",{});var _ao=s(h7);lSe=n(_ao,"STRONG",{});var p3a=s(lSe);zgt=r(p3a,"distilbert"),p3a.forEach(t),Qgt=r(_ao," \u2014 "),Yle=n(_ao,"A",{href:!0});var _3a=s(Yle);Wgt=r(_3a,"TFDistilBertForMultipleChoice"),_3a.forEach(t),Ugt=r(_ao," (DistilBERT model)"),_ao.forEach(t),Hgt=i(Ee),u7=n(Ee,"LI",{});var bao=s(u7);iSe=n(bao,"STRONG",{});var b3a=s(iSe);Jgt=r(b3a,"electra"),b3a.forEach(t),Ygt=r(bao," \u2014 "),Zle=n(bao,"A",{href:!0});var v3a=s(Zle);Zgt=r(v3a,"TFElectraForMultipleChoice"),v3a.forEach(t),Kgt=r(bao," (ELECTRA model)"),bao.forEach(t),eht=i(Ee),p7=n(Ee,"LI",{});var vao=s(p7);dSe=n(vao,"STRONG",{});var F3a=s(dSe);oht=r(F3a,"flaubert"),F3a.forEach(t),rht=r(vao," \u2014 "),Kle=n(vao,"A",{href:!0});var T3a=s(Kle);tht=r(T3a,"TFFlaubertForMultipleChoice"),T3a.forEach(t),aht=r(vao," (FlauBERT model)"),vao.forEach(t),nht=i(Ee),_7=n(Ee,"LI",{});var Fao=s(_7);mSe=n(Fao,"STRONG",{});var M3a=s(mSe);sht=r(M3a,"funnel"),M3a.forEach(t),lht=r(Fao," \u2014 "),eie=n(Fao,"A",{href:!0});var E3a=s(eie);iht=r(E3a,"TFFunnelForMultipleChoice"),E3a.forEach(t),dht=r(Fao," (Funnel Transformer model)"),Fao.forEach(t),mht=i(Ee),b7=n(Ee,"LI",{});var Tao=s(b7);cSe=n(Tao,"STRONG",{});var C3a=s(cSe);cht=r(C3a,"longformer"),C3a.forEach(t),fht=r(Tao," \u2014 "),oie=n(Tao,"A",{href:!0});var w3a=s(oie);ght=r(w3a,"TFLongformerForMultipleChoice"),w3a.forEach(t),hht=r(Tao," (Longformer model)"),Tao.forEach(t),uht=i(Ee),v7=n(Ee,"LI",{});var Mao=s(v7);fSe=n(Mao,"STRONG",{});var A3a=s(fSe);pht=r(A3a,"mobilebert"),A3a.forEach(t),_ht=r(Mao," \u2014 "),rie=n(Mao,"A",{href:!0});var L3a=s(rie);bht=r(L3a,"TFMobileBertForMultipleChoice"),L3a.forEach(t),vht=r(Mao," (MobileBERT model)"),Mao.forEach(t),Fht=i(Ee),F7=n(Ee,"LI",{});var Eao=s(F7);gSe=n(Eao,"STRONG",{});var y3a=s(gSe);Tht=r(y3a,"mpnet"),y3a.forEach(t),Mht=r(Eao," \u2014 "),tie=n(Eao,"A",{href:!0});var x3a=s(tie);Eht=r(x3a,"TFMPNetForMultipleChoice"),x3a.forEach(t),Cht=r(Eao," (MPNet model)"),Eao.forEach(t),wht=i(Ee),T7=n(Ee,"LI",{});var Cao=s(T7);hSe=n(Cao,"STRONG",{});var $3a=s(hSe);Aht=r($3a,"rembert"),$3a.forEach(t),Lht=r(Cao," \u2014 "),aie=n(Cao,"A",{href:!0});var k3a=s(aie);yht=r(k3a,"TFRemBertForMultipleChoice"),k3a.forEach(t),xht=r(Cao," (RemBERT model)"),Cao.forEach(t),$ht=i(Ee),M7=n(Ee,"LI",{});var wao=s(M7);uSe=n(wao,"STRONG",{});var S3a=s(uSe);kht=r(S3a,"roberta"),S3a.forEach(t),Sht=r(wao," \u2014 "),nie=n(wao,"A",{href:!0});var R3a=s(nie);Rht=r(R3a,"TFRobertaForMultipleChoice"),R3a.forEach(t),Pht=r(wao," (RoBERTa model)"),wao.forEach(t),Bht=i(Ee),E7=n(Ee,"LI",{});var Aao=s(E7);pSe=n(Aao,"STRONG",{});var P3a=s(pSe);Iht=r(P3a,"roformer"),P3a.forEach(t),Nht=r(Aao," \u2014 "),sie=n(Aao,"A",{href:!0});var B3a=s(sie);qht=r(B3a,"TFRoFormerForMultipleChoice"),B3a.forEach(t),jht=r(Aao," (RoFormer model)"),Aao.forEach(t),Dht=i(Ee),C7=n(Ee,"LI",{});var Lao=s(C7);_Se=n(Lao,"STRONG",{});var I3a=s(_Se);Ght=r(I3a,"xlm"),I3a.forEach(t),Oht=r(Lao," \u2014 "),lie=n(Lao,"A",{href:!0});var N3a=s(lie);Vht=r(N3a,"TFXLMForMultipleChoice"),N3a.forEach(t),Xht=r(Lao," (XLM model)"),Lao.forEach(t),zht=i(Ee),w7=n(Ee,"LI",{});var yao=s(w7);bSe=n(yao,"STRONG",{});var q3a=s(bSe);Qht=r(q3a,"xlm-roberta"),q3a.forEach(t),Wht=r(yao," \u2014 "),iie=n(yao,"A",{href:!0});var j3a=s(iie);Uht=r(j3a,"TFXLMRobertaForMultipleChoice"),j3a.forEach(t),Hht=r(yao," (XLM-RoBERTa model)"),yao.forEach(t),Jht=i(Ee),A7=n(Ee,"LI",{});var xao=s(A7);vSe=n(xao,"STRONG",{});var D3a=s(vSe);Yht=r(D3a,"xlnet"),D3a.forEach(t),Zht=r(xao," \u2014 "),die=n(xao,"A",{href:!0});var G3a=s(die);Kht=r(G3a,"TFXLNetForMultipleChoice"),G3a.forEach(t),eut=r(xao," (XLNet model)"),xao.forEach(t),Ee.forEach(t),out=i(Gi),T(L7.$$.fragment,Gi),Gi.forEach(t),Di.forEach(t),ddo=i(c),Wc=n(c,"H2",{class:!0});var Sco=s(Wc);y7=n(Sco,"A",{id:!0,class:!0,href:!0});var O3a=s(y7);FSe=n(O3a,"SPAN",{});var V3a=s(FSe);T(_B.$$.fragment,V3a),V3a.forEach(t),O3a.forEach(t),rut=i(Sco),TSe=n(Sco,"SPAN",{});var X3a=s(TSe);tut=r(X3a,"TFAutoModelForNextSentencePrediction"),X3a.forEach(t),Sco.forEach(t),mdo=i(c),Er=n(c,"DIV",{class:!0});var Oi=s(Er);T(bB.$$.fragment,Oi),aut=i(Oi),Uc=n(Oi,"P",{});var Bge=s(Uc);nut=r(Bge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),mie=n(Bge,"A",{href:!0});var z3a=s(mie);sut=r(z3a,"from_pretrained()"),z3a.forEach(t),lut=r(Bge," class method or the "),cie=n(Bge,"A",{href:!0});var Q3a=s(cie);iut=r(Q3a,"from_config()"),Q3a.forEach(t),dut=r(Bge,` class
method.`),Bge.forEach(t),mut=i(Oi),vB=n(Oi,"P",{});var Rco=s(vB);cut=r(Rco,"This class cannot be instantiated directly using "),MSe=n(Rco,"CODE",{});var W3a=s(MSe);fut=r(W3a,"__init__()"),W3a.forEach(t),gut=r(Rco," (throws an error)."),Rco.forEach(t),hut=i(Oi),ma=n(Oi,"DIV",{class:!0});var L$=s(ma);T(FB.$$.fragment,L$),uut=i(L$),ESe=n(L$,"P",{});var U3a=s(ESe);put=r(U3a,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),U3a.forEach(t),_ut=i(L$),Hc=n(L$,"P",{});var Ige=s(Hc);but=r(Ige,`Note:
Loading a model from its configuration file does `),CSe=n(Ige,"STRONG",{});var H3a=s(CSe);vut=r(H3a,"not"),H3a.forEach(t),Fut=r(Ige,` load the model weights. It only affects the
model\u2019s configuration. Use `),fie=n(Ige,"A",{href:!0});var J3a=s(fie);Tut=r(J3a,"from_pretrained()"),J3a.forEach(t),Mut=r(Ige," to load the model weights."),Ige.forEach(t),Eut=i(L$),T(x7.$$.fragment,L$),L$.forEach(t),Cut=i(Oi),Kr=n(Oi,"DIV",{class:!0});var Vi=s(Kr);T(TB.$$.fragment,Vi),wut=i(Vi),wSe=n(Vi,"P",{});var Y3a=s(wSe);Aut=r(Y3a,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Y3a.forEach(t),Lut=i(Vi),Jn=n(Vi,"P",{});var y$=s(Jn);yut=r(y$,"The model class to instantiate is selected based on the "),ASe=n(y$,"CODE",{});var Z3a=s(ASe);xut=r(Z3a,"model_type"),Z3a.forEach(t),$ut=r(y$,` property of the config object (either
passed as an argument or loaded from `),LSe=n(y$,"CODE",{});var K3a=s(LSe);kut=r(K3a,"pretrained_model_name_or_path"),K3a.forEach(t),Sut=r(y$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ySe=n(y$,"CODE",{});var e5a=s(ySe);Rut=r(e5a,"pretrained_model_name_or_path"),e5a.forEach(t),Put=r(y$,":"),y$.forEach(t),But=i(Vi),MB=n(Vi,"UL",{});var Pco=s(MB);$7=n(Pco,"LI",{});var $ao=s($7);xSe=n($ao,"STRONG",{});var o5a=s(xSe);Iut=r(o5a,"bert"),o5a.forEach(t),Nut=r($ao," \u2014 "),gie=n($ao,"A",{href:!0});var r5a=s(gie);qut=r(r5a,"TFBertForNextSentencePrediction"),r5a.forEach(t),jut=r($ao," (BERT model)"),$ao.forEach(t),Dut=i(Pco),k7=n(Pco,"LI",{});var kao=s(k7);$Se=n(kao,"STRONG",{});var t5a=s($Se);Gut=r(t5a,"mobilebert"),t5a.forEach(t),Out=r(kao," \u2014 "),hie=n(kao,"A",{href:!0});var a5a=s(hie);Vut=r(a5a,"TFMobileBertForNextSentencePrediction"),a5a.forEach(t),Xut=r(kao," (MobileBERT model)"),kao.forEach(t),Pco.forEach(t),zut=i(Vi),T(S7.$$.fragment,Vi),Vi.forEach(t),Oi.forEach(t),cdo=i(c),Jc=n(c,"H2",{class:!0});var Bco=s(Jc);R7=n(Bco,"A",{id:!0,class:!0,href:!0});var n5a=s(R7);kSe=n(n5a,"SPAN",{});var s5a=s(kSe);T(EB.$$.fragment,s5a),s5a.forEach(t),n5a.forEach(t),Qut=i(Bco),SSe=n(Bco,"SPAN",{});var l5a=s(SSe);Wut=r(l5a,"TFAutoModelForTableQuestionAnswering"),l5a.forEach(t),Bco.forEach(t),fdo=i(c),Cr=n(c,"DIV",{class:!0});var Xi=s(Cr);T(CB.$$.fragment,Xi),Uut=i(Xi),Yc=n(Xi,"P",{});var Nge=s(Yc);Hut=r(Nge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),uie=n(Nge,"A",{href:!0});var i5a=s(uie);Jut=r(i5a,"from_pretrained()"),i5a.forEach(t),Yut=r(Nge," class method or the "),pie=n(Nge,"A",{href:!0});var d5a=s(pie);Zut=r(d5a,"from_config()"),d5a.forEach(t),Kut=r(Nge,` class
method.`),Nge.forEach(t),ept=i(Xi),wB=n(Xi,"P",{});var Ico=s(wB);opt=r(Ico,"This class cannot be instantiated directly using "),RSe=n(Ico,"CODE",{});var m5a=s(RSe);rpt=r(m5a,"__init__()"),m5a.forEach(t),tpt=r(Ico," (throws an error)."),Ico.forEach(t),apt=i(Xi),ca=n(Xi,"DIV",{class:!0});var x$=s(ca);T(AB.$$.fragment,x$),npt=i(x$),PSe=n(x$,"P",{});var c5a=s(PSe);spt=r(c5a,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),c5a.forEach(t),lpt=i(x$),Zc=n(x$,"P",{});var qge=s(Zc);ipt=r(qge,`Note:
Loading a model from its configuration file does `),BSe=n(qge,"STRONG",{});var f5a=s(BSe);dpt=r(f5a,"not"),f5a.forEach(t),mpt=r(qge,` load the model weights. It only affects the
model\u2019s configuration. Use `),_ie=n(qge,"A",{href:!0});var g5a=s(_ie);cpt=r(g5a,"from_pretrained()"),g5a.forEach(t),fpt=r(qge," to load the model weights."),qge.forEach(t),gpt=i(x$),T(P7.$$.fragment,x$),x$.forEach(t),hpt=i(Xi),et=n(Xi,"DIV",{class:!0});var zi=s(et);T(LB.$$.fragment,zi),upt=i(zi),ISe=n(zi,"P",{});var h5a=s(ISe);ppt=r(h5a,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),h5a.forEach(t),_pt=i(zi),Yn=n(zi,"P",{});var $$=s(Yn);bpt=r($$,"The model class to instantiate is selected based on the "),NSe=n($$,"CODE",{});var u5a=s(NSe);vpt=r(u5a,"model_type"),u5a.forEach(t),Fpt=r($$,` property of the config object (either
passed as an argument or loaded from `),qSe=n($$,"CODE",{});var p5a=s(qSe);Tpt=r(p5a,"pretrained_model_name_or_path"),p5a.forEach(t),Mpt=r($$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jSe=n($$,"CODE",{});var _5a=s(jSe);Ept=r(_5a,"pretrained_model_name_or_path"),_5a.forEach(t),Cpt=r($$,":"),$$.forEach(t),wpt=i(zi),DSe=n(zi,"UL",{});var b5a=s(DSe);B7=n(b5a,"LI",{});var Sao=s(B7);GSe=n(Sao,"STRONG",{});var v5a=s(GSe);Apt=r(v5a,"tapas"),v5a.forEach(t),Lpt=r(Sao," \u2014 "),bie=n(Sao,"A",{href:!0});var F5a=s(bie);ypt=r(F5a,"TFTapasForQuestionAnswering"),F5a.forEach(t),xpt=r(Sao," (TAPAS model)"),Sao.forEach(t),b5a.forEach(t),$pt=i(zi),T(I7.$$.fragment,zi),zi.forEach(t),Xi.forEach(t),gdo=i(c),Kc=n(c,"H2",{class:!0});var Nco=s(Kc);N7=n(Nco,"A",{id:!0,class:!0,href:!0});var T5a=s(N7);OSe=n(T5a,"SPAN",{});var M5a=s(OSe);T(yB.$$.fragment,M5a),M5a.forEach(t),T5a.forEach(t),kpt=i(Nco),VSe=n(Nco,"SPAN",{});var E5a=s(VSe);Spt=r(E5a,"TFAutoModelForDocumentQuestionAnswering"),E5a.forEach(t),Nco.forEach(t),hdo=i(c),wr=n(c,"DIV",{class:!0});var Qi=s(wr);T(xB.$$.fragment,Qi),Rpt=i(Qi),ef=n(Qi,"P",{});var jge=s(ef);Ppt=r(jge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),vie=n(jge,"A",{href:!0});var C5a=s(vie);Bpt=r(C5a,"from_pretrained()"),C5a.forEach(t),Ipt=r(jge," class method or the "),Fie=n(jge,"A",{href:!0});var w5a=s(Fie);Npt=r(w5a,"from_config()"),w5a.forEach(t),qpt=r(jge,` class
method.`),jge.forEach(t),jpt=i(Qi),$B=n(Qi,"P",{});var qco=s($B);Dpt=r(qco,"This class cannot be instantiated directly using "),XSe=n(qco,"CODE",{});var A5a=s(XSe);Gpt=r(A5a,"__init__()"),A5a.forEach(t),Opt=r(qco," (throws an error)."),qco.forEach(t),Vpt=i(Qi),fa=n(Qi,"DIV",{class:!0});var k$=s(fa);T(kB.$$.fragment,k$),Xpt=i(k$),zSe=n(k$,"P",{});var L5a=s(zSe);zpt=r(L5a,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),L5a.forEach(t),Qpt=i(k$),of=n(k$,"P",{});var Dge=s(of);Wpt=r(Dge,`Note:
Loading a model from its configuration file does `),QSe=n(Dge,"STRONG",{});var y5a=s(QSe);Upt=r(y5a,"not"),y5a.forEach(t),Hpt=r(Dge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Tie=n(Dge,"A",{href:!0});var x5a=s(Tie);Jpt=r(x5a,"from_pretrained()"),x5a.forEach(t),Ypt=r(Dge," to load the model weights."),Dge.forEach(t),Zpt=i(k$),T(q7.$$.fragment,k$),k$.forEach(t),Kpt=i(Qi),ot=n(Qi,"DIV",{class:!0});var Wi=s(ot);T(SB.$$.fragment,Wi),e_t=i(Wi),WSe=n(Wi,"P",{});var $5a=s(WSe);o_t=r($5a,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),$5a.forEach(t),r_t=i(Wi),Zn=n(Wi,"P",{});var S$=s(Zn);t_t=r(S$,"The model class to instantiate is selected based on the "),USe=n(S$,"CODE",{});var k5a=s(USe);a_t=r(k5a,"model_type"),k5a.forEach(t),n_t=r(S$,` property of the config object (either
passed as an argument or loaded from `),HSe=n(S$,"CODE",{});var S5a=s(HSe);s_t=r(S5a,"pretrained_model_name_or_path"),S5a.forEach(t),l_t=r(S$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JSe=n(S$,"CODE",{});var R5a=s(JSe);i_t=r(R5a,"pretrained_model_name_or_path"),R5a.forEach(t),d_t=r(S$,":"),S$.forEach(t),m_t=i(Wi),YSe=n(Wi,"UL",{});var P5a=s(YSe);j7=n(P5a,"LI",{});var Rao=s(j7);ZSe=n(Rao,"STRONG",{});var B5a=s(ZSe);c_t=r(B5a,"layoutlm"),B5a.forEach(t),f_t=r(Rao," \u2014 "),Mie=n(Rao,"A",{href:!0});var I5a=s(Mie);g_t=r(I5a,"TFLayoutLMForQuestionAnswering"),I5a.forEach(t),h_t=r(Rao," (LayoutLM model)"),Rao.forEach(t),P5a.forEach(t),u_t=i(Wi),T(D7.$$.fragment,Wi),Wi.forEach(t),Qi.forEach(t),udo=i(c),rf=n(c,"H2",{class:!0});var jco=s(rf);G7=n(jco,"A",{id:!0,class:!0,href:!0});var N5a=s(G7);KSe=n(N5a,"SPAN",{});var q5a=s(KSe);T(RB.$$.fragment,q5a),q5a.forEach(t),N5a.forEach(t),p_t=i(jco),eRe=n(jco,"SPAN",{});var j5a=s(eRe);__t=r(j5a,"TFAutoModelForTokenClassification"),j5a.forEach(t),jco.forEach(t),pdo=i(c),Ar=n(c,"DIV",{class:!0});var Ui=s(Ar);T(PB.$$.fragment,Ui),b_t=i(Ui),tf=n(Ui,"P",{});var Gge=s(tf);v_t=r(Gge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Eie=n(Gge,"A",{href:!0});var D5a=s(Eie);F_t=r(D5a,"from_pretrained()"),D5a.forEach(t),T_t=r(Gge," class method or the "),Cie=n(Gge,"A",{href:!0});var G5a=s(Cie);M_t=r(G5a,"from_config()"),G5a.forEach(t),E_t=r(Gge,` class
method.`),Gge.forEach(t),C_t=i(Ui),BB=n(Ui,"P",{});var Dco=s(BB);w_t=r(Dco,"This class cannot be instantiated directly using "),oRe=n(Dco,"CODE",{});var O5a=s(oRe);A_t=r(O5a,"__init__()"),O5a.forEach(t),L_t=r(Dco," (throws an error)."),Dco.forEach(t),y_t=i(Ui),ga=n(Ui,"DIV",{class:!0});var R$=s(ga);T(IB.$$.fragment,R$),x_t=i(R$),rRe=n(R$,"P",{});var V5a=s(rRe);$_t=r(V5a,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),V5a.forEach(t),k_t=i(R$),af=n(R$,"P",{});var Oge=s(af);S_t=r(Oge,`Note:
Loading a model from its configuration file does `),tRe=n(Oge,"STRONG",{});var X5a=s(tRe);R_t=r(X5a,"not"),X5a.forEach(t),P_t=r(Oge,` load the model weights. It only affects the
model\u2019s configuration. Use `),wie=n(Oge,"A",{href:!0});var z5a=s(wie);B_t=r(z5a,"from_pretrained()"),z5a.forEach(t),I_t=r(Oge," to load the model weights."),Oge.forEach(t),N_t=i(R$),T(O7.$$.fragment,R$),R$.forEach(t),q_t=i(Ui),rt=n(Ui,"DIV",{class:!0});var Hi=s(rt);T(NB.$$.fragment,Hi),j_t=i(Hi),aRe=n(Hi,"P",{});var Q5a=s(aRe);D_t=r(Q5a,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Q5a.forEach(t),G_t=i(Hi),Kn=n(Hi,"P",{});var P$=s(Kn);O_t=r(P$,"The model class to instantiate is selected based on the "),nRe=n(P$,"CODE",{});var W5a=s(nRe);V_t=r(W5a,"model_type"),W5a.forEach(t),X_t=r(P$,` property of the config object (either
passed as an argument or loaded from `),sRe=n(P$,"CODE",{});var U5a=s(sRe);z_t=r(U5a,"pretrained_model_name_or_path"),U5a.forEach(t),Q_t=r(P$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lRe=n(P$,"CODE",{});var H5a=s(lRe);W_t=r(H5a,"pretrained_model_name_or_path"),H5a.forEach(t),U_t=r(P$,":"),P$.forEach(t),H_t=i(Hi),me=n(Hi,"UL",{});var ue=s(me);V7=n(ue,"LI",{});var Pao=s(V7);iRe=n(Pao,"STRONG",{});var J5a=s(iRe);J_t=r(J5a,"albert"),J5a.forEach(t),Y_t=r(Pao," \u2014 "),Aie=n(Pao,"A",{href:!0});var Y5a=s(Aie);Z_t=r(Y5a,"TFAlbertForTokenClassification"),Y5a.forEach(t),K_t=r(Pao," (ALBERT model)"),Pao.forEach(t),e1t=i(ue),X7=n(ue,"LI",{});var Bao=s(X7);dRe=n(Bao,"STRONG",{});var Z5a=s(dRe);o1t=r(Z5a,"bert"),Z5a.forEach(t),r1t=r(Bao," \u2014 "),Lie=n(Bao,"A",{href:!0});var K5a=s(Lie);t1t=r(K5a,"TFBertForTokenClassification"),K5a.forEach(t),a1t=r(Bao," (BERT model)"),Bao.forEach(t),n1t=i(ue),z7=n(ue,"LI",{});var Iao=s(z7);mRe=n(Iao,"STRONG",{});var e0a=s(mRe);s1t=r(e0a,"camembert"),e0a.forEach(t),l1t=r(Iao," \u2014 "),yie=n(Iao,"A",{href:!0});var o0a=s(yie);i1t=r(o0a,"TFCamembertForTokenClassification"),o0a.forEach(t),d1t=r(Iao," (CamemBERT model)"),Iao.forEach(t),m1t=i(ue),Q7=n(ue,"LI",{});var Nao=s(Q7);cRe=n(Nao,"STRONG",{});var r0a=s(cRe);c1t=r(r0a,"convbert"),r0a.forEach(t),f1t=r(Nao," \u2014 "),xie=n(Nao,"A",{href:!0});var t0a=s(xie);g1t=r(t0a,"TFConvBertForTokenClassification"),t0a.forEach(t),h1t=r(Nao," (ConvBERT model)"),Nao.forEach(t),u1t=i(ue),W7=n(ue,"LI",{});var qao=s(W7);fRe=n(qao,"STRONG",{});var a0a=s(fRe);p1t=r(a0a,"deberta"),a0a.forEach(t),_1t=r(qao," \u2014 "),$ie=n(qao,"A",{href:!0});var n0a=s($ie);b1t=r(n0a,"TFDebertaForTokenClassification"),n0a.forEach(t),v1t=r(qao," (DeBERTa model)"),qao.forEach(t),F1t=i(ue),U7=n(ue,"LI",{});var jao=s(U7);gRe=n(jao,"STRONG",{});var s0a=s(gRe);T1t=r(s0a,"deberta-v2"),s0a.forEach(t),M1t=r(jao," \u2014 "),kie=n(jao,"A",{href:!0});var l0a=s(kie);E1t=r(l0a,"TFDebertaV2ForTokenClassification"),l0a.forEach(t),C1t=r(jao," (DeBERTa-v2 model)"),jao.forEach(t),w1t=i(ue),H7=n(ue,"LI",{});var Dao=s(H7);hRe=n(Dao,"STRONG",{});var i0a=s(hRe);A1t=r(i0a,"distilbert"),i0a.forEach(t),L1t=r(Dao," \u2014 "),Sie=n(Dao,"A",{href:!0});var d0a=s(Sie);y1t=r(d0a,"TFDistilBertForTokenClassification"),d0a.forEach(t),x1t=r(Dao," (DistilBERT model)"),Dao.forEach(t),$1t=i(ue),J7=n(ue,"LI",{});var Gao=s(J7);uRe=n(Gao,"STRONG",{});var m0a=s(uRe);k1t=r(m0a,"electra"),m0a.forEach(t),S1t=r(Gao," \u2014 "),Rie=n(Gao,"A",{href:!0});var c0a=s(Rie);R1t=r(c0a,"TFElectraForTokenClassification"),c0a.forEach(t),P1t=r(Gao," (ELECTRA model)"),Gao.forEach(t),B1t=i(ue),Y7=n(ue,"LI",{});var Oao=s(Y7);pRe=n(Oao,"STRONG",{});var f0a=s(pRe);I1t=r(f0a,"esm"),f0a.forEach(t),N1t=r(Oao," \u2014 "),Pie=n(Oao,"A",{href:!0});var g0a=s(Pie);q1t=r(g0a,"TFEsmForTokenClassification"),g0a.forEach(t),j1t=r(Oao," (ESM model)"),Oao.forEach(t),D1t=i(ue),Z7=n(ue,"LI",{});var Vao=s(Z7);_Re=n(Vao,"STRONG",{});var h0a=s(_Re);G1t=r(h0a,"flaubert"),h0a.forEach(t),O1t=r(Vao," \u2014 "),Bie=n(Vao,"A",{href:!0});var u0a=s(Bie);V1t=r(u0a,"TFFlaubertForTokenClassification"),u0a.forEach(t),X1t=r(Vao," (FlauBERT model)"),Vao.forEach(t),z1t=i(ue),K7=n(ue,"LI",{});var Xao=s(K7);bRe=n(Xao,"STRONG",{});var p0a=s(bRe);Q1t=r(p0a,"funnel"),p0a.forEach(t),W1t=r(Xao," \u2014 "),Iie=n(Xao,"A",{href:!0});var _0a=s(Iie);U1t=r(_0a,"TFFunnelForTokenClassification"),_0a.forEach(t),H1t=r(Xao," (Funnel Transformer model)"),Xao.forEach(t),J1t=i(ue),e8=n(ue,"LI",{});var zao=s(e8);vRe=n(zao,"STRONG",{});var b0a=s(vRe);Y1t=r(b0a,"layoutlm"),b0a.forEach(t),Z1t=r(zao," \u2014 "),Nie=n(zao,"A",{href:!0});var v0a=s(Nie);K1t=r(v0a,"TFLayoutLMForTokenClassification"),v0a.forEach(t),e2t=r(zao," (LayoutLM model)"),zao.forEach(t),o2t=i(ue),o8=n(ue,"LI",{});var Qao=s(o8);FRe=n(Qao,"STRONG",{});var F0a=s(FRe);r2t=r(F0a,"layoutlmv3"),F0a.forEach(t),t2t=r(Qao," \u2014 "),qie=n(Qao,"A",{href:!0});var T0a=s(qie);a2t=r(T0a,"TFLayoutLMv3ForTokenClassification"),T0a.forEach(t),n2t=r(Qao," (LayoutLMv3 model)"),Qao.forEach(t),s2t=i(ue),r8=n(ue,"LI",{});var Wao=s(r8);TRe=n(Wao,"STRONG",{});var M0a=s(TRe);l2t=r(M0a,"longformer"),M0a.forEach(t),i2t=r(Wao," \u2014 "),jie=n(Wao,"A",{href:!0});var E0a=s(jie);d2t=r(E0a,"TFLongformerForTokenClassification"),E0a.forEach(t),m2t=r(Wao," (Longformer model)"),Wao.forEach(t),c2t=i(ue),t8=n(ue,"LI",{});var Uao=s(t8);MRe=n(Uao,"STRONG",{});var C0a=s(MRe);f2t=r(C0a,"mobilebert"),C0a.forEach(t),g2t=r(Uao," \u2014 "),Die=n(Uao,"A",{href:!0});var w0a=s(Die);h2t=r(w0a,"TFMobileBertForTokenClassification"),w0a.forEach(t),u2t=r(Uao," (MobileBERT model)"),Uao.forEach(t),p2t=i(ue),a8=n(ue,"LI",{});var Hao=s(a8);ERe=n(Hao,"STRONG",{});var A0a=s(ERe);_2t=r(A0a,"mpnet"),A0a.forEach(t),b2t=r(Hao," \u2014 "),Gie=n(Hao,"A",{href:!0});var L0a=s(Gie);v2t=r(L0a,"TFMPNetForTokenClassification"),L0a.forEach(t),F2t=r(Hao," (MPNet model)"),Hao.forEach(t),T2t=i(ue),n8=n(ue,"LI",{});var Jao=s(n8);CRe=n(Jao,"STRONG",{});var y0a=s(CRe);M2t=r(y0a,"rembert"),y0a.forEach(t),E2t=r(Jao," \u2014 "),Oie=n(Jao,"A",{href:!0});var x0a=s(Oie);C2t=r(x0a,"TFRemBertForTokenClassification"),x0a.forEach(t),w2t=r(Jao," (RemBERT model)"),Jao.forEach(t),A2t=i(ue),s8=n(ue,"LI",{});var Yao=s(s8);wRe=n(Yao,"STRONG",{});var $0a=s(wRe);L2t=r($0a,"roberta"),$0a.forEach(t),y2t=r(Yao," \u2014 "),Vie=n(Yao,"A",{href:!0});var k0a=s(Vie);x2t=r(k0a,"TFRobertaForTokenClassification"),k0a.forEach(t),$2t=r(Yao," (RoBERTa model)"),Yao.forEach(t),k2t=i(ue),l8=n(ue,"LI",{});var Zao=s(l8);ARe=n(Zao,"STRONG",{});var S0a=s(ARe);S2t=r(S0a,"roformer"),S0a.forEach(t),R2t=r(Zao," \u2014 "),Xie=n(Zao,"A",{href:!0});var R0a=s(Xie);P2t=r(R0a,"TFRoFormerForTokenClassification"),R0a.forEach(t),B2t=r(Zao," (RoFormer model)"),Zao.forEach(t),I2t=i(ue),i8=n(ue,"LI",{});var Kao=s(i8);LRe=n(Kao,"STRONG",{});var P0a=s(LRe);N2t=r(P0a,"xlm"),P0a.forEach(t),q2t=r(Kao," \u2014 "),zie=n(Kao,"A",{href:!0});var B0a=s(zie);j2t=r(B0a,"TFXLMForTokenClassification"),B0a.forEach(t),D2t=r(Kao," (XLM model)"),Kao.forEach(t),G2t=i(ue),d8=n(ue,"LI",{});var eno=s(d8);yRe=n(eno,"STRONG",{});var I0a=s(yRe);O2t=r(I0a,"xlm-roberta"),I0a.forEach(t),V2t=r(eno," \u2014 "),Qie=n(eno,"A",{href:!0});var N0a=s(Qie);X2t=r(N0a,"TFXLMRobertaForTokenClassification"),N0a.forEach(t),z2t=r(eno," (XLM-RoBERTa model)"),eno.forEach(t),Q2t=i(ue),m8=n(ue,"LI",{});var ono=s(m8);xRe=n(ono,"STRONG",{});var q0a=s(xRe);W2t=r(q0a,"xlnet"),q0a.forEach(t),U2t=r(ono," \u2014 "),Wie=n(ono,"A",{href:!0});var j0a=s(Wie);H2t=r(j0a,"TFXLNetForTokenClassification"),j0a.forEach(t),J2t=r(ono," (XLNet model)"),ono.forEach(t),ue.forEach(t),Y2t=i(Hi),T(c8.$$.fragment,Hi),Hi.forEach(t),Ui.forEach(t),_do=i(c),nf=n(c,"H2",{class:!0});var Gco=s(nf);f8=n(Gco,"A",{id:!0,class:!0,href:!0});var D0a=s(f8);$Re=n(D0a,"SPAN",{});var G0a=s($Re);T(qB.$$.fragment,G0a),G0a.forEach(t),D0a.forEach(t),Z2t=i(Gco),kRe=n(Gco,"SPAN",{});var O0a=s(kRe);K2t=r(O0a,"TFAutoModelForQuestionAnswering"),O0a.forEach(t),Gco.forEach(t),bdo=i(c),Lr=n(c,"DIV",{class:!0});var Ji=s(Lr);T(jB.$$.fragment,Ji),ebt=i(Ji),sf=n(Ji,"P",{});var Vge=s(sf);obt=r(Vge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Uie=n(Vge,"A",{href:!0});var V0a=s(Uie);rbt=r(V0a,"from_pretrained()"),V0a.forEach(t),tbt=r(Vge," class method or the "),Hie=n(Vge,"A",{href:!0});var X0a=s(Hie);abt=r(X0a,"from_config()"),X0a.forEach(t),nbt=r(Vge,` class
method.`),Vge.forEach(t),sbt=i(Ji),DB=n(Ji,"P",{});var Oco=s(DB);lbt=r(Oco,"This class cannot be instantiated directly using "),SRe=n(Oco,"CODE",{});var z0a=s(SRe);ibt=r(z0a,"__init__()"),z0a.forEach(t),dbt=r(Oco," (throws an error)."),Oco.forEach(t),mbt=i(Ji),ha=n(Ji,"DIV",{class:!0});var B$=s(ha);T(GB.$$.fragment,B$),cbt=i(B$),RRe=n(B$,"P",{});var Q0a=s(RRe);fbt=r(Q0a,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Q0a.forEach(t),gbt=i(B$),lf=n(B$,"P",{});var Xge=s(lf);hbt=r(Xge,`Note:
Loading a model from its configuration file does `),PRe=n(Xge,"STRONG",{});var W0a=s(PRe);ubt=r(W0a,"not"),W0a.forEach(t),pbt=r(Xge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Jie=n(Xge,"A",{href:!0});var U0a=s(Jie);_bt=r(U0a,"from_pretrained()"),U0a.forEach(t),bbt=r(Xge," to load the model weights."),Xge.forEach(t),vbt=i(B$),T(g8.$$.fragment,B$),B$.forEach(t),Fbt=i(Ji),tt=n(Ji,"DIV",{class:!0});var Yi=s(tt);T(OB.$$.fragment,Yi),Tbt=i(Yi),BRe=n(Yi,"P",{});var H0a=s(BRe);Mbt=r(H0a,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),H0a.forEach(t),Ebt=i(Yi),es=n(Yi,"P",{});var I$=s(es);Cbt=r(I$,"The model class to instantiate is selected based on the "),IRe=n(I$,"CODE",{});var J0a=s(IRe);wbt=r(J0a,"model_type"),J0a.forEach(t),Abt=r(I$,` property of the config object (either
passed as an argument or loaded from `),NRe=n(I$,"CODE",{});var Y0a=s(NRe);Lbt=r(Y0a,"pretrained_model_name_or_path"),Y0a.forEach(t),ybt=r(I$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qRe=n(I$,"CODE",{});var Z0a=s(qRe);xbt=r(Z0a,"pretrained_model_name_or_path"),Z0a.forEach(t),$bt=r(I$,":"),I$.forEach(t),kbt=i(Yi),he=n(Yi,"UL",{});var be=s(he);h8=n(be,"LI",{});var rno=s(h8);jRe=n(rno,"STRONG",{});var K0a=s(jRe);Sbt=r(K0a,"albert"),K0a.forEach(t),Rbt=r(rno," \u2014 "),Yie=n(rno,"A",{href:!0});var ewa=s(Yie);Pbt=r(ewa,"TFAlbertForQuestionAnswering"),ewa.forEach(t),Bbt=r(rno," (ALBERT model)"),rno.forEach(t),Ibt=i(be),u8=n(be,"LI",{});var tno=s(u8);DRe=n(tno,"STRONG",{});var owa=s(DRe);Nbt=r(owa,"bert"),owa.forEach(t),qbt=r(tno," \u2014 "),Zie=n(tno,"A",{href:!0});var rwa=s(Zie);jbt=r(rwa,"TFBertForQuestionAnswering"),rwa.forEach(t),Dbt=r(tno," (BERT model)"),tno.forEach(t),Gbt=i(be),p8=n(be,"LI",{});var ano=s(p8);GRe=n(ano,"STRONG",{});var twa=s(GRe);Obt=r(twa,"camembert"),twa.forEach(t),Vbt=r(ano," \u2014 "),Kie=n(ano,"A",{href:!0});var awa=s(Kie);Xbt=r(awa,"TFCamembertForQuestionAnswering"),awa.forEach(t),zbt=r(ano," (CamemBERT model)"),ano.forEach(t),Qbt=i(be),_8=n(be,"LI",{});var nno=s(_8);ORe=n(nno,"STRONG",{});var nwa=s(ORe);Wbt=r(nwa,"convbert"),nwa.forEach(t),Ubt=r(nno," \u2014 "),ede=n(nno,"A",{href:!0});var swa=s(ede);Hbt=r(swa,"TFConvBertForQuestionAnswering"),swa.forEach(t),Jbt=r(nno," (ConvBERT model)"),nno.forEach(t),Ybt=i(be),b8=n(be,"LI",{});var sno=s(b8);VRe=n(sno,"STRONG",{});var lwa=s(VRe);Zbt=r(lwa,"deberta"),lwa.forEach(t),Kbt=r(sno," \u2014 "),ode=n(sno,"A",{href:!0});var iwa=s(ode);evt=r(iwa,"TFDebertaForQuestionAnswering"),iwa.forEach(t),ovt=r(sno," (DeBERTa model)"),sno.forEach(t),rvt=i(be),v8=n(be,"LI",{});var lno=s(v8);XRe=n(lno,"STRONG",{});var dwa=s(XRe);tvt=r(dwa,"deberta-v2"),dwa.forEach(t),avt=r(lno," \u2014 "),rde=n(lno,"A",{href:!0});var mwa=s(rde);nvt=r(mwa,"TFDebertaV2ForQuestionAnswering"),mwa.forEach(t),svt=r(lno," (DeBERTa-v2 model)"),lno.forEach(t),lvt=i(be),F8=n(be,"LI",{});var ino=s(F8);zRe=n(ino,"STRONG",{});var cwa=s(zRe);ivt=r(cwa,"distilbert"),cwa.forEach(t),dvt=r(ino," \u2014 "),tde=n(ino,"A",{href:!0});var fwa=s(tde);mvt=r(fwa,"TFDistilBertForQuestionAnswering"),fwa.forEach(t),cvt=r(ino," (DistilBERT model)"),ino.forEach(t),fvt=i(be),T8=n(be,"LI",{});var dno=s(T8);QRe=n(dno,"STRONG",{});var gwa=s(QRe);gvt=r(gwa,"electra"),gwa.forEach(t),hvt=r(dno," \u2014 "),ade=n(dno,"A",{href:!0});var hwa=s(ade);uvt=r(hwa,"TFElectraForQuestionAnswering"),hwa.forEach(t),pvt=r(dno," (ELECTRA model)"),dno.forEach(t),_vt=i(be),M8=n(be,"LI",{});var mno=s(M8);WRe=n(mno,"STRONG",{});var uwa=s(WRe);bvt=r(uwa,"flaubert"),uwa.forEach(t),vvt=r(mno," \u2014 "),nde=n(mno,"A",{href:!0});var pwa=s(nde);Fvt=r(pwa,"TFFlaubertForQuestionAnsweringSimple"),pwa.forEach(t),Tvt=r(mno," (FlauBERT model)"),mno.forEach(t),Mvt=i(be),E8=n(be,"LI",{});var cno=s(E8);URe=n(cno,"STRONG",{});var _wa=s(URe);Evt=r(_wa,"funnel"),_wa.forEach(t),Cvt=r(cno," \u2014 "),sde=n(cno,"A",{href:!0});var bwa=s(sde);wvt=r(bwa,"TFFunnelForQuestionAnswering"),bwa.forEach(t),Avt=r(cno," (Funnel Transformer model)"),cno.forEach(t),Lvt=i(be),C8=n(be,"LI",{});var fno=s(C8);HRe=n(fno,"STRONG",{});var vwa=s(HRe);yvt=r(vwa,"gptj"),vwa.forEach(t),xvt=r(fno," \u2014 "),lde=n(fno,"A",{href:!0});var Fwa=s(lde);$vt=r(Fwa,"TFGPTJForQuestionAnswering"),Fwa.forEach(t),kvt=r(fno," (GPT-J model)"),fno.forEach(t),Svt=i(be),w8=n(be,"LI",{});var gno=s(w8);JRe=n(gno,"STRONG",{});var Twa=s(JRe);Rvt=r(Twa,"layoutlmv3"),Twa.forEach(t),Pvt=r(gno," \u2014 "),ide=n(gno,"A",{href:!0});var Mwa=s(ide);Bvt=r(Mwa,"TFLayoutLMv3ForQuestionAnswering"),Mwa.forEach(t),Ivt=r(gno," (LayoutLMv3 model)"),gno.forEach(t),Nvt=i(be),A8=n(be,"LI",{});var hno=s(A8);YRe=n(hno,"STRONG",{});var Ewa=s(YRe);qvt=r(Ewa,"longformer"),Ewa.forEach(t),jvt=r(hno," \u2014 "),dde=n(hno,"A",{href:!0});var Cwa=s(dde);Dvt=r(Cwa,"TFLongformerForQuestionAnswering"),Cwa.forEach(t),Gvt=r(hno," (Longformer model)"),hno.forEach(t),Ovt=i(be),L8=n(be,"LI",{});var uno=s(L8);ZRe=n(uno,"STRONG",{});var wwa=s(ZRe);Vvt=r(wwa,"mobilebert"),wwa.forEach(t),Xvt=r(uno," \u2014 "),mde=n(uno,"A",{href:!0});var Awa=s(mde);zvt=r(Awa,"TFMobileBertForQuestionAnswering"),Awa.forEach(t),Qvt=r(uno," (MobileBERT model)"),uno.forEach(t),Wvt=i(be),y8=n(be,"LI",{});var pno=s(y8);KRe=n(pno,"STRONG",{});var Lwa=s(KRe);Uvt=r(Lwa,"mpnet"),Lwa.forEach(t),Hvt=r(pno," \u2014 "),cde=n(pno,"A",{href:!0});var ywa=s(cde);Jvt=r(ywa,"TFMPNetForQuestionAnswering"),ywa.forEach(t),Yvt=r(pno," (MPNet model)"),pno.forEach(t),Zvt=i(be),x8=n(be,"LI",{});var _no=s(x8);ePe=n(_no,"STRONG",{});var xwa=s(ePe);Kvt=r(xwa,"rembert"),xwa.forEach(t),eFt=r(_no," \u2014 "),fde=n(_no,"A",{href:!0});var $wa=s(fde);oFt=r($wa,"TFRemBertForQuestionAnswering"),$wa.forEach(t),rFt=r(_no," (RemBERT model)"),_no.forEach(t),tFt=i(be),$8=n(be,"LI",{});var bno=s($8);oPe=n(bno,"STRONG",{});var kwa=s(oPe);aFt=r(kwa,"roberta"),kwa.forEach(t),nFt=r(bno," \u2014 "),gde=n(bno,"A",{href:!0});var Swa=s(gde);sFt=r(Swa,"TFRobertaForQuestionAnswering"),Swa.forEach(t),lFt=r(bno," (RoBERTa model)"),bno.forEach(t),iFt=i(be),k8=n(be,"LI",{});var vno=s(k8);rPe=n(vno,"STRONG",{});var Rwa=s(rPe);dFt=r(Rwa,"roformer"),Rwa.forEach(t),mFt=r(vno," \u2014 "),hde=n(vno,"A",{href:!0});var Pwa=s(hde);cFt=r(Pwa,"TFRoFormerForQuestionAnswering"),Pwa.forEach(t),fFt=r(vno," (RoFormer model)"),vno.forEach(t),gFt=i(be),S8=n(be,"LI",{});var Fno=s(S8);tPe=n(Fno,"STRONG",{});var Bwa=s(tPe);hFt=r(Bwa,"xlm"),Bwa.forEach(t),uFt=r(Fno," \u2014 "),ude=n(Fno,"A",{href:!0});var Iwa=s(ude);pFt=r(Iwa,"TFXLMForQuestionAnsweringSimple"),Iwa.forEach(t),_Ft=r(Fno," (XLM model)"),Fno.forEach(t),bFt=i(be),R8=n(be,"LI",{});var Tno=s(R8);aPe=n(Tno,"STRONG",{});var Nwa=s(aPe);vFt=r(Nwa,"xlm-roberta"),Nwa.forEach(t),FFt=r(Tno," \u2014 "),pde=n(Tno,"A",{href:!0});var qwa=s(pde);TFt=r(qwa,"TFXLMRobertaForQuestionAnswering"),qwa.forEach(t),MFt=r(Tno," (XLM-RoBERTa model)"),Tno.forEach(t),EFt=i(be),P8=n(be,"LI",{});var Mno=s(P8);nPe=n(Mno,"STRONG",{});var jwa=s(nPe);CFt=r(jwa,"xlnet"),jwa.forEach(t),wFt=r(Mno," \u2014 "),_de=n(Mno,"A",{href:!0});var Dwa=s(_de);AFt=r(Dwa,"TFXLNetForQuestionAnsweringSimple"),Dwa.forEach(t),LFt=r(Mno," (XLNet model)"),Mno.forEach(t),be.forEach(t),yFt=i(Yi),T(B8.$$.fragment,Yi),Yi.forEach(t),Ji.forEach(t),vdo=i(c),df=n(c,"H2",{class:!0});var Vco=s(df);I8=n(Vco,"A",{id:!0,class:!0,href:!0});var Gwa=s(I8);sPe=n(Gwa,"SPAN",{});var Owa=s(sPe);T(VB.$$.fragment,Owa),Owa.forEach(t),Gwa.forEach(t),xFt=i(Vco),lPe=n(Vco,"SPAN",{});var Vwa=s(lPe);$Ft=r(Vwa,"TFAutoModelForVision2Seq"),Vwa.forEach(t),Vco.forEach(t),Fdo=i(c),yr=n(c,"DIV",{class:!0});var Zi=s(yr);T(XB.$$.fragment,Zi),kFt=i(Zi),mf=n(Zi,"P",{});var zge=s(mf);SFt=r(zge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),bde=n(zge,"A",{href:!0});var Xwa=s(bde);RFt=r(Xwa,"from_pretrained()"),Xwa.forEach(t),PFt=r(zge," class method or the "),vde=n(zge,"A",{href:!0});var zwa=s(vde);BFt=r(zwa,"from_config()"),zwa.forEach(t),IFt=r(zge,` class
method.`),zge.forEach(t),NFt=i(Zi),zB=n(Zi,"P",{});var Xco=s(zB);qFt=r(Xco,"This class cannot be instantiated directly using "),iPe=n(Xco,"CODE",{});var Qwa=s(iPe);jFt=r(Qwa,"__init__()"),Qwa.forEach(t),DFt=r(Xco," (throws an error)."),Xco.forEach(t),GFt=i(Zi),ua=n(Zi,"DIV",{class:!0});var N$=s(ua);T(QB.$$.fragment,N$),OFt=i(N$),dPe=n(N$,"P",{});var Wwa=s(dPe);VFt=r(Wwa,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Wwa.forEach(t),XFt=i(N$),cf=n(N$,"P",{});var Qge=s(cf);zFt=r(Qge,`Note:
Loading a model from its configuration file does `),mPe=n(Qge,"STRONG",{});var Uwa=s(mPe);QFt=r(Uwa,"not"),Uwa.forEach(t),WFt=r(Qge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Fde=n(Qge,"A",{href:!0});var Hwa=s(Fde);UFt=r(Hwa,"from_pretrained()"),Hwa.forEach(t),HFt=r(Qge," to load the model weights."),Qge.forEach(t),JFt=i(N$),T(N8.$$.fragment,N$),N$.forEach(t),YFt=i(Zi),at=n(Zi,"DIV",{class:!0});var Ki=s(at);T(WB.$$.fragment,Ki),ZFt=i(Ki),cPe=n(Ki,"P",{});var Jwa=s(cPe);KFt=r(Jwa,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Jwa.forEach(t),eTt=i(Ki),os=n(Ki,"P",{});var q$=s(os);oTt=r(q$,"The model class to instantiate is selected based on the "),fPe=n(q$,"CODE",{});var Ywa=s(fPe);rTt=r(Ywa,"model_type"),Ywa.forEach(t),tTt=r(q$,` property of the config object (either
passed as an argument or loaded from `),gPe=n(q$,"CODE",{});var Zwa=s(gPe);aTt=r(Zwa,"pretrained_model_name_or_path"),Zwa.forEach(t),nTt=r(q$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hPe=n(q$,"CODE",{});var Kwa=s(hPe);sTt=r(Kwa,"pretrained_model_name_or_path"),Kwa.forEach(t),lTt=r(q$,":"),q$.forEach(t),iTt=i(Ki),uPe=n(Ki,"UL",{});var eAa=s(uPe);q8=n(eAa,"LI",{});var Eno=s(q8);pPe=n(Eno,"STRONG",{});var oAa=s(pPe);dTt=r(oAa,"vision-encoder-decoder"),oAa.forEach(t),mTt=r(Eno," \u2014 "),Tde=n(Eno,"A",{href:!0});var rAa=s(Tde);cTt=r(rAa,"TFVisionEncoderDecoderModel"),rAa.forEach(t),fTt=r(Eno," (Vision Encoder decoder model)"),Eno.forEach(t),eAa.forEach(t),gTt=i(Ki),T(j8.$$.fragment,Ki),Ki.forEach(t),Zi.forEach(t),Tdo=i(c),ff=n(c,"H2",{class:!0});var zco=s(ff);D8=n(zco,"A",{id:!0,class:!0,href:!0});var tAa=s(D8);_Pe=n(tAa,"SPAN",{});var aAa=s(_Pe);T(UB.$$.fragment,aAa),aAa.forEach(t),tAa.forEach(t),hTt=i(zco),bPe=n(zco,"SPAN",{});var nAa=s(bPe);uTt=r(nAa,"TFAutoModelForSpeechSeq2Seq"),nAa.forEach(t),zco.forEach(t),Mdo=i(c),xr=n(c,"DIV",{class:!0});var ed=s(xr);T(HB.$$.fragment,ed),pTt=i(ed),gf=n(ed,"P",{});var Wge=s(gf);_Tt=r(Wge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Mde=n(Wge,"A",{href:!0});var sAa=s(Mde);bTt=r(sAa,"from_pretrained()"),sAa.forEach(t),vTt=r(Wge," class method or the "),Ede=n(Wge,"A",{href:!0});var lAa=s(Ede);FTt=r(lAa,"from_config()"),lAa.forEach(t),TTt=r(Wge,` class
method.`),Wge.forEach(t),MTt=i(ed),JB=n(ed,"P",{});var Qco=s(JB);ETt=r(Qco,"This class cannot be instantiated directly using "),vPe=n(Qco,"CODE",{});var iAa=s(vPe);CTt=r(iAa,"__init__()"),iAa.forEach(t),wTt=r(Qco," (throws an error)."),Qco.forEach(t),ATt=i(ed),pa=n(ed,"DIV",{class:!0});var j$=s(pa);T(YB.$$.fragment,j$),LTt=i(j$),FPe=n(j$,"P",{});var dAa=s(FPe);yTt=r(dAa,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),dAa.forEach(t),xTt=i(j$),hf=n(j$,"P",{});var Uge=s(hf);$Tt=r(Uge,`Note:
Loading a model from its configuration file does `),TPe=n(Uge,"STRONG",{});var mAa=s(TPe);kTt=r(mAa,"not"),mAa.forEach(t),STt=r(Uge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Cde=n(Uge,"A",{href:!0});var cAa=s(Cde);RTt=r(cAa,"from_pretrained()"),cAa.forEach(t),PTt=r(Uge," to load the model weights."),Uge.forEach(t),BTt=i(j$),T(G8.$$.fragment,j$),j$.forEach(t),ITt=i(ed),nt=n(ed,"DIV",{class:!0});var od=s(nt);T(ZB.$$.fragment,od),NTt=i(od),MPe=n(od,"P",{});var fAa=s(MPe);qTt=r(fAa,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),fAa.forEach(t),jTt=i(od),rs=n(od,"P",{});var D$=s(rs);DTt=r(D$,"The model class to instantiate is selected based on the "),EPe=n(D$,"CODE",{});var gAa=s(EPe);GTt=r(gAa,"model_type"),gAa.forEach(t),OTt=r(D$,` property of the config object (either
passed as an argument or loaded from `),CPe=n(D$,"CODE",{});var hAa=s(CPe);VTt=r(hAa,"pretrained_model_name_or_path"),hAa.forEach(t),XTt=r(D$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wPe=n(D$,"CODE",{});var uAa=s(wPe);zTt=r(uAa,"pretrained_model_name_or_path"),uAa.forEach(t),QTt=r(D$,":"),D$.forEach(t),WTt=i(od),KB=n(od,"UL",{});var Wco=s(KB);O8=n(Wco,"LI",{});var Cno=s(O8);APe=n(Cno,"STRONG",{});var pAa=s(APe);UTt=r(pAa,"speech_to_text"),pAa.forEach(t),HTt=r(Cno," \u2014 "),wde=n(Cno,"A",{href:!0});var _Aa=s(wde);JTt=r(_Aa,"TFSpeech2TextForConditionalGeneration"),_Aa.forEach(t),YTt=r(Cno," (Speech2Text model)"),Cno.forEach(t),ZTt=i(Wco),V8=n(Wco,"LI",{});var wno=s(V8);LPe=n(wno,"STRONG",{});var bAa=s(LPe);KTt=r(bAa,"whisper"),bAa.forEach(t),eMt=r(wno," \u2014 "),Ade=n(wno,"A",{href:!0});var vAa=s(Ade);oMt=r(vAa,"TFWhisperForConditionalGeneration"),vAa.forEach(t),rMt=r(wno," (Whisper model)"),wno.forEach(t),Wco.forEach(t),tMt=i(od),T(X8.$$.fragment,od),od.forEach(t),ed.forEach(t),Edo=i(c),uf=n(c,"H2",{class:!0});var Uco=s(uf);z8=n(Uco,"A",{id:!0,class:!0,href:!0});var FAa=s(z8);yPe=n(FAa,"SPAN",{});var TAa=s(yPe);T(eI.$$.fragment,TAa),TAa.forEach(t),FAa.forEach(t),aMt=i(Uco),xPe=n(Uco,"SPAN",{});var MAa=s(xPe);nMt=r(MAa,"FlaxAutoModel"),MAa.forEach(t),Uco.forEach(t),Cdo=i(c),$r=n(c,"DIV",{class:!0});var rd=s($r);T(oI.$$.fragment,rd),sMt=i(rd),pf=n(rd,"P",{});var Hge=s(pf);lMt=r(Hge,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Lde=n(Hge,"A",{href:!0});var EAa=s(Lde);iMt=r(EAa,"from_pretrained()"),EAa.forEach(t),dMt=r(Hge," class method or the "),yde=n(Hge,"A",{href:!0});var CAa=s(yde);mMt=r(CAa,"from_config()"),CAa.forEach(t),cMt=r(Hge,` class
method.`),Hge.forEach(t),fMt=i(rd),rI=n(rd,"P",{});var Hco=s(rI);gMt=r(Hco,"This class cannot be instantiated directly using "),$Pe=n(Hco,"CODE",{});var wAa=s($Pe);hMt=r(wAa,"__init__()"),wAa.forEach(t),uMt=r(Hco," (throws an error)."),Hco.forEach(t),pMt=i(rd),_a=n(rd,"DIV",{class:!0});var G$=s(_a);T(tI.$$.fragment,G$),_Mt=i(G$),kPe=n(G$,"P",{});var AAa=s(kPe);bMt=r(AAa,"Instantiates one of the base model classes of the library from a configuration."),AAa.forEach(t),vMt=i(G$),_f=n(G$,"P",{});var Jge=s(_f);FMt=r(Jge,`Note:
Loading a model from its configuration file does `),SPe=n(Jge,"STRONG",{});var LAa=s(SPe);TMt=r(LAa,"not"),LAa.forEach(t),MMt=r(Jge,` load the model weights. It only affects the
model\u2019s configuration. Use `),xde=n(Jge,"A",{href:!0});var yAa=s(xde);EMt=r(yAa,"from_pretrained()"),yAa.forEach(t),CMt=r(Jge," to load the model weights."),Jge.forEach(t),wMt=i(G$),T(Q8.$$.fragment,G$),G$.forEach(t),AMt=i(rd),st=n(rd,"DIV",{class:!0});var td=s(st);T(aI.$$.fragment,td),LMt=i(td),RPe=n(td,"P",{});var xAa=s(RPe);yMt=r(xAa,"Instantiate one of the base model classes of the library from a pretrained model."),xAa.forEach(t),xMt=i(td),ts=n(td,"P",{});var O$=s(ts);$Mt=r(O$,"The model class to instantiate is selected based on the "),PPe=n(O$,"CODE",{});var $Aa=s(PPe);kMt=r($Aa,"model_type"),$Aa.forEach(t),SMt=r(O$,` property of the config object (either
passed as an argument or loaded from `),BPe=n(O$,"CODE",{});var kAa=s(BPe);RMt=r(kAa,"pretrained_model_name_or_path"),kAa.forEach(t),PMt=r(O$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),IPe=n(O$,"CODE",{});var SAa=s(IPe);BMt=r(SAa,"pretrained_model_name_or_path"),SAa.forEach(t),IMt=r(O$,":"),O$.forEach(t),NMt=i(td),ne=n(td,"UL",{});var le=s(ne);W8=n(le,"LI",{});var Ano=s(W8);NPe=n(Ano,"STRONG",{});var RAa=s(NPe);qMt=r(RAa,"albert"),RAa.forEach(t),jMt=r(Ano," \u2014 "),$de=n(Ano,"A",{href:!0});var PAa=s($de);DMt=r(PAa,"FlaxAlbertModel"),PAa.forEach(t),GMt=r(Ano," (ALBERT model)"),Ano.forEach(t),OMt=i(le),U8=n(le,"LI",{});var Lno=s(U8);qPe=n(Lno,"STRONG",{});var BAa=s(qPe);VMt=r(BAa,"bart"),BAa.forEach(t),XMt=r(Lno," \u2014 "),kde=n(Lno,"A",{href:!0});var IAa=s(kde);zMt=r(IAa,"FlaxBartModel"),IAa.forEach(t),QMt=r(Lno," (BART model)"),Lno.forEach(t),WMt=i(le),H8=n(le,"LI",{});var yno=s(H8);jPe=n(yno,"STRONG",{});var NAa=s(jPe);UMt=r(NAa,"beit"),NAa.forEach(t),HMt=r(yno," \u2014 "),Sde=n(yno,"A",{href:!0});var qAa=s(Sde);JMt=r(qAa,"FlaxBeitModel"),qAa.forEach(t),YMt=r(yno," (BEiT model)"),yno.forEach(t),ZMt=i(le),J8=n(le,"LI",{});var xno=s(J8);DPe=n(xno,"STRONG",{});var jAa=s(DPe);KMt=r(jAa,"bert"),jAa.forEach(t),eEt=r(xno," \u2014 "),Rde=n(xno,"A",{href:!0});var DAa=s(Rde);oEt=r(DAa,"FlaxBertModel"),DAa.forEach(t),rEt=r(xno," (BERT model)"),xno.forEach(t),tEt=i(le),Y8=n(le,"LI",{});var $no=s(Y8);GPe=n($no,"STRONG",{});var GAa=s(GPe);aEt=r(GAa,"big_bird"),GAa.forEach(t),nEt=r($no," \u2014 "),Pde=n($no,"A",{href:!0});var OAa=s(Pde);sEt=r(OAa,"FlaxBigBirdModel"),OAa.forEach(t),lEt=r($no," (BigBird model)"),$no.forEach(t),iEt=i(le),Z8=n(le,"LI",{});var kno=s(Z8);OPe=n(kno,"STRONG",{});var VAa=s(OPe);dEt=r(VAa,"blenderbot"),VAa.forEach(t),mEt=r(kno," \u2014 "),Bde=n(kno,"A",{href:!0});var XAa=s(Bde);cEt=r(XAa,"FlaxBlenderbotModel"),XAa.forEach(t),fEt=r(kno," (Blenderbot model)"),kno.forEach(t),gEt=i(le),K8=n(le,"LI",{});var Sno=s(K8);VPe=n(Sno,"STRONG",{});var zAa=s(VPe);hEt=r(zAa,"blenderbot-small"),zAa.forEach(t),uEt=r(Sno," \u2014 "),Ide=n(Sno,"A",{href:!0});var QAa=s(Ide);pEt=r(QAa,"FlaxBlenderbotSmallModel"),QAa.forEach(t),_Et=r(Sno," (BlenderbotSmall model)"),Sno.forEach(t),bEt=i(le),eL=n(le,"LI",{});var Rno=s(eL);XPe=n(Rno,"STRONG",{});var WAa=s(XPe);vEt=r(WAa,"clip"),WAa.forEach(t),FEt=r(Rno," \u2014 "),Nde=n(Rno,"A",{href:!0});var UAa=s(Nde);TEt=r(UAa,"FlaxCLIPModel"),UAa.forEach(t),MEt=r(Rno," (CLIP model)"),Rno.forEach(t),EEt=i(le),oL=n(le,"LI",{});var Pno=s(oL);zPe=n(Pno,"STRONG",{});var HAa=s(zPe);CEt=r(HAa,"distilbert"),HAa.forEach(t),wEt=r(Pno," \u2014 "),qde=n(Pno,"A",{href:!0});var JAa=s(qde);AEt=r(JAa,"FlaxDistilBertModel"),JAa.forEach(t),LEt=r(Pno," (DistilBERT model)"),Pno.forEach(t),yEt=i(le),rL=n(le,"LI",{});var Bno=s(rL);QPe=n(Bno,"STRONG",{});var YAa=s(QPe);xEt=r(YAa,"electra"),YAa.forEach(t),$Et=r(Bno," \u2014 "),jde=n(Bno,"A",{href:!0});var ZAa=s(jde);kEt=r(ZAa,"FlaxElectraModel"),ZAa.forEach(t),SEt=r(Bno," (ELECTRA model)"),Bno.forEach(t),REt=i(le),tL=n(le,"LI",{});var Ino=s(tL);WPe=n(Ino,"STRONG",{});var KAa=s(WPe);PEt=r(KAa,"gpt2"),KAa.forEach(t),BEt=r(Ino," \u2014 "),Dde=n(Ino,"A",{href:!0});var e6a=s(Dde);IEt=r(e6a,"FlaxGPT2Model"),e6a.forEach(t),NEt=r(Ino," (OpenAI GPT-2 model)"),Ino.forEach(t),qEt=i(le),aL=n(le,"LI",{});var Nno=s(aL);UPe=n(Nno,"STRONG",{});var o6a=s(UPe);jEt=r(o6a,"gpt_neo"),o6a.forEach(t),DEt=r(Nno," \u2014 "),Gde=n(Nno,"A",{href:!0});var r6a=s(Gde);GEt=r(r6a,"FlaxGPTNeoModel"),r6a.forEach(t),OEt=r(Nno," (GPT Neo model)"),Nno.forEach(t),VEt=i(le),nL=n(le,"LI",{});var qno=s(nL);HPe=n(qno,"STRONG",{});var t6a=s(HPe);XEt=r(t6a,"gptj"),t6a.forEach(t),zEt=r(qno," \u2014 "),Ode=n(qno,"A",{href:!0});var a6a=s(Ode);QEt=r(a6a,"FlaxGPTJModel"),a6a.forEach(t),WEt=r(qno," (GPT-J model)"),qno.forEach(t),UEt=i(le),sL=n(le,"LI",{});var jno=s(sL);JPe=n(jno,"STRONG",{});var n6a=s(JPe);HEt=r(n6a,"longt5"),n6a.forEach(t),JEt=r(jno," \u2014 "),Vde=n(jno,"A",{href:!0});var s6a=s(Vde);YEt=r(s6a,"FlaxLongT5Model"),s6a.forEach(t),ZEt=r(jno," (LongT5 model)"),jno.forEach(t),KEt=i(le),lL=n(le,"LI",{});var Dno=s(lL);YPe=n(Dno,"STRONG",{});var l6a=s(YPe);e4t=r(l6a,"marian"),l6a.forEach(t),o4t=r(Dno," \u2014 "),Xde=n(Dno,"A",{href:!0});var i6a=s(Xde);r4t=r(i6a,"FlaxMarianModel"),i6a.forEach(t),t4t=r(Dno," (Marian model)"),Dno.forEach(t),a4t=i(le),iL=n(le,"LI",{});var Gno=s(iL);ZPe=n(Gno,"STRONG",{});var d6a=s(ZPe);n4t=r(d6a,"mbart"),d6a.forEach(t),s4t=r(Gno," \u2014 "),zde=n(Gno,"A",{href:!0});var m6a=s(zde);l4t=r(m6a,"FlaxMBartModel"),m6a.forEach(t),i4t=r(Gno," (mBART model)"),Gno.forEach(t),d4t=i(le),dL=n(le,"LI",{});var Ono=s(dL);KPe=n(Ono,"STRONG",{});var c6a=s(KPe);m4t=r(c6a,"mt5"),c6a.forEach(t),c4t=r(Ono," \u2014 "),Qde=n(Ono,"A",{href:!0});var f6a=s(Qde);f4t=r(f6a,"FlaxMT5Model"),f6a.forEach(t),g4t=r(Ono," (MT5 model)"),Ono.forEach(t),h4t=i(le),mL=n(le,"LI",{});var Vno=s(mL);eBe=n(Vno,"STRONG",{});var g6a=s(eBe);u4t=r(g6a,"opt"),g6a.forEach(t),p4t=r(Vno," \u2014 "),Wde=n(Vno,"A",{href:!0});var h6a=s(Wde);_4t=r(h6a,"FlaxOPTModel"),h6a.forEach(t),b4t=r(Vno," (OPT model)"),Vno.forEach(t),v4t=i(le),cL=n(le,"LI",{});var Xno=s(cL);oBe=n(Xno,"STRONG",{});var u6a=s(oBe);F4t=r(u6a,"pegasus"),u6a.forEach(t),T4t=r(Xno," \u2014 "),Ude=n(Xno,"A",{href:!0});var p6a=s(Ude);M4t=r(p6a,"FlaxPegasusModel"),p6a.forEach(t),E4t=r(Xno," (Pegasus model)"),Xno.forEach(t),C4t=i(le),fL=n(le,"LI",{});var zno=s(fL);rBe=n(zno,"STRONG",{});var _6a=s(rBe);w4t=r(_6a,"roberta"),_6a.forEach(t),A4t=r(zno," \u2014 "),Hde=n(zno,"A",{href:!0});var b6a=s(Hde);L4t=r(b6a,"FlaxRobertaModel"),b6a.forEach(t),y4t=r(zno," (RoBERTa model)"),zno.forEach(t),x4t=i(le),gL=n(le,"LI",{});var Qno=s(gL);tBe=n(Qno,"STRONG",{});var v6a=s(tBe);$4t=r(v6a,"roformer"),v6a.forEach(t),k4t=r(Qno," \u2014 "),Jde=n(Qno,"A",{href:!0});var F6a=s(Jde);S4t=r(F6a,"FlaxRoFormerModel"),F6a.forEach(t),R4t=r(Qno," (RoFormer model)"),Qno.forEach(t),P4t=i(le),hL=n(le,"LI",{});var Wno=s(hL);aBe=n(Wno,"STRONG",{});var T6a=s(aBe);B4t=r(T6a,"t5"),T6a.forEach(t),I4t=r(Wno," \u2014 "),Yde=n(Wno,"A",{href:!0});var M6a=s(Yde);N4t=r(M6a,"FlaxT5Model"),M6a.forEach(t),q4t=r(Wno," (T5 model)"),Wno.forEach(t),j4t=i(le),uL=n(le,"LI",{});var Uno=s(uL);nBe=n(Uno,"STRONG",{});var E6a=s(nBe);D4t=r(E6a,"vision-text-dual-encoder"),E6a.forEach(t),G4t=r(Uno," \u2014 "),Zde=n(Uno,"A",{href:!0});var C6a=s(Zde);O4t=r(C6a,"FlaxVisionTextDualEncoderModel"),C6a.forEach(t),V4t=r(Uno," (VisionTextDualEncoder model)"),Uno.forEach(t),X4t=i(le),pL=n(le,"LI",{});var Hno=s(pL);sBe=n(Hno,"STRONG",{});var w6a=s(sBe);z4t=r(w6a,"vit"),w6a.forEach(t),Q4t=r(Hno," \u2014 "),Kde=n(Hno,"A",{href:!0});var A6a=s(Kde);W4t=r(A6a,"FlaxViTModel"),A6a.forEach(t),U4t=r(Hno," (ViT model)"),Hno.forEach(t),H4t=i(le),_L=n(le,"LI",{});var Jno=s(_L);lBe=n(Jno,"STRONG",{});var L6a=s(lBe);J4t=r(L6a,"wav2vec2"),L6a.forEach(t),Y4t=r(Jno," \u2014 "),eme=n(Jno,"A",{href:!0});var y6a=s(eme);Z4t=r(y6a,"FlaxWav2Vec2Model"),y6a.forEach(t),K4t=r(Jno," (Wav2Vec2 model)"),Jno.forEach(t),eCt=i(le),bL=n(le,"LI",{});var Yno=s(bL);iBe=n(Yno,"STRONG",{});var x6a=s(iBe);oCt=r(x6a,"xglm"),x6a.forEach(t),rCt=r(Yno," \u2014 "),ome=n(Yno,"A",{href:!0});var $6a=s(ome);tCt=r($6a,"FlaxXGLMModel"),$6a.forEach(t),aCt=r(Yno," (XGLM model)"),Yno.forEach(t),nCt=i(le),vL=n(le,"LI",{});var Zno=s(vL);dBe=n(Zno,"STRONG",{});var k6a=s(dBe);sCt=r(k6a,"xlm-roberta"),k6a.forEach(t),lCt=r(Zno," \u2014 "),rme=n(Zno,"A",{href:!0});var S6a=s(rme);iCt=r(S6a,"FlaxXLMRobertaModel"),S6a.forEach(t),dCt=r(Zno," (XLM-RoBERTa model)"),Zno.forEach(t),le.forEach(t),mCt=i(td),T(FL.$$.fragment,td),td.forEach(t),rd.forEach(t),wdo=i(c),bf=n(c,"H2",{class:!0});var Jco=s(bf);TL=n(Jco,"A",{id:!0,class:!0,href:!0});var R6a=s(TL);mBe=n(R6a,"SPAN",{});var P6a=s(mBe);T(nI.$$.fragment,P6a),P6a.forEach(t),R6a.forEach(t),cCt=i(Jco),cBe=n(Jco,"SPAN",{});var B6a=s(cBe);fCt=r(B6a,"FlaxAutoModelForCausalLM"),B6a.forEach(t),Jco.forEach(t),Ado=i(c),kr=n(c,"DIV",{class:!0});var ad=s(kr);T(sI.$$.fragment,ad),gCt=i(ad),vf=n(ad,"P",{});var Yge=s(vf);hCt=r(Yge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),tme=n(Yge,"A",{href:!0});var I6a=s(tme);uCt=r(I6a,"from_pretrained()"),I6a.forEach(t),pCt=r(Yge," class method or the "),ame=n(Yge,"A",{href:!0});var N6a=s(ame);_Ct=r(N6a,"from_config()"),N6a.forEach(t),bCt=r(Yge,` class
method.`),Yge.forEach(t),vCt=i(ad),lI=n(ad,"P",{});var Yco=s(lI);FCt=r(Yco,"This class cannot be instantiated directly using "),fBe=n(Yco,"CODE",{});var q6a=s(fBe);TCt=r(q6a,"__init__()"),q6a.forEach(t),MCt=r(Yco," (throws an error)."),Yco.forEach(t),ECt=i(ad),ba=n(ad,"DIV",{class:!0});var V$=s(ba);T(iI.$$.fragment,V$),CCt=i(V$),gBe=n(V$,"P",{});var j6a=s(gBe);wCt=r(j6a,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),j6a.forEach(t),ACt=i(V$),Ff=n(V$,"P",{});var Zge=s(Ff);LCt=r(Zge,`Note:
Loading a model from its configuration file does `),hBe=n(Zge,"STRONG",{});var D6a=s(hBe);yCt=r(D6a,"not"),D6a.forEach(t),xCt=r(Zge,` load the model weights. It only affects the
model\u2019s configuration. Use `),nme=n(Zge,"A",{href:!0});var G6a=s(nme);$Ct=r(G6a,"from_pretrained()"),G6a.forEach(t),kCt=r(Zge," to load the model weights."),Zge.forEach(t),SCt=i(V$),T(ML.$$.fragment,V$),V$.forEach(t),RCt=i(ad),lt=n(ad,"DIV",{class:!0});var nd=s(lt);T(dI.$$.fragment,nd),PCt=i(nd),uBe=n(nd,"P",{});var O6a=s(uBe);BCt=r(O6a,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),O6a.forEach(t),ICt=i(nd),as=n(nd,"P",{});var X$=s(as);NCt=r(X$,"The model class to instantiate is selected based on the "),pBe=n(X$,"CODE",{});var V6a=s(pBe);qCt=r(V6a,"model_type"),V6a.forEach(t),jCt=r(X$,` property of the config object (either
passed as an argument or loaded from `),_Be=n(X$,"CODE",{});var X6a=s(_Be);DCt=r(X6a,"pretrained_model_name_or_path"),X6a.forEach(t),GCt=r(X$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bBe=n(X$,"CODE",{});var z6a=s(bBe);OCt=r(z6a,"pretrained_model_name_or_path"),z6a.forEach(t),VCt=r(X$,":"),X$.forEach(t),XCt=i(nd),Se=n(nd,"UL",{});var Ge=s(Se);EL=n(Ge,"LI",{});var Kno=s(EL);vBe=n(Kno,"STRONG",{});var Q6a=s(vBe);zCt=r(Q6a,"bart"),Q6a.forEach(t),QCt=r(Kno," \u2014 "),sme=n(Kno,"A",{href:!0});var W6a=s(sme);WCt=r(W6a,"FlaxBartForCausalLM"),W6a.forEach(t),UCt=r(Kno," (BART model)"),Kno.forEach(t),HCt=i(Ge),CL=n(Ge,"LI",{});var eso=s(CL);FBe=n(eso,"STRONG",{});var U6a=s(FBe);JCt=r(U6a,"bert"),U6a.forEach(t),YCt=r(eso," \u2014 "),lme=n(eso,"A",{href:!0});var H6a=s(lme);ZCt=r(H6a,"FlaxBertForCausalLM"),H6a.forEach(t),KCt=r(eso," (BERT model)"),eso.forEach(t),e3t=i(Ge),wL=n(Ge,"LI",{});var oso=s(wL);TBe=n(oso,"STRONG",{});var J6a=s(TBe);o3t=r(J6a,"big_bird"),J6a.forEach(t),r3t=r(oso," \u2014 "),ime=n(oso,"A",{href:!0});var Y6a=s(ime);t3t=r(Y6a,"FlaxBigBirdForCausalLM"),Y6a.forEach(t),a3t=r(oso," (BigBird model)"),oso.forEach(t),n3t=i(Ge),AL=n(Ge,"LI",{});var rso=s(AL);MBe=n(rso,"STRONG",{});var Z6a=s(MBe);s3t=r(Z6a,"electra"),Z6a.forEach(t),l3t=r(rso," \u2014 "),dme=n(rso,"A",{href:!0});var K6a=s(dme);i3t=r(K6a,"FlaxElectraForCausalLM"),K6a.forEach(t),d3t=r(rso," (ELECTRA model)"),rso.forEach(t),m3t=i(Ge),LL=n(Ge,"LI",{});var tso=s(LL);EBe=n(tso,"STRONG",{});var e7a=s(EBe);c3t=r(e7a,"gpt2"),e7a.forEach(t),f3t=r(tso," \u2014 "),mme=n(tso,"A",{href:!0});var o7a=s(mme);g3t=r(o7a,"FlaxGPT2LMHeadModel"),o7a.forEach(t),h3t=r(tso," (OpenAI GPT-2 model)"),tso.forEach(t),u3t=i(Ge),yL=n(Ge,"LI",{});var aso=s(yL);CBe=n(aso,"STRONG",{});var r7a=s(CBe);p3t=r(r7a,"gpt_neo"),r7a.forEach(t),_3t=r(aso," \u2014 "),cme=n(aso,"A",{href:!0});var t7a=s(cme);b3t=r(t7a,"FlaxGPTNeoForCausalLM"),t7a.forEach(t),v3t=r(aso," (GPT Neo model)"),aso.forEach(t),F3t=i(Ge),xL=n(Ge,"LI",{});var nso=s(xL);wBe=n(nso,"STRONG",{});var a7a=s(wBe);T3t=r(a7a,"gptj"),a7a.forEach(t),M3t=r(nso," \u2014 "),fme=n(nso,"A",{href:!0});var n7a=s(fme);E3t=r(n7a,"FlaxGPTJForCausalLM"),n7a.forEach(t),C3t=r(nso," (GPT-J model)"),nso.forEach(t),w3t=i(Ge),$L=n(Ge,"LI",{});var sso=s($L);ABe=n(sso,"STRONG",{});var s7a=s(ABe);A3t=r(s7a,"opt"),s7a.forEach(t),L3t=r(sso," \u2014 "),gme=n(sso,"A",{href:!0});var l7a=s(gme);y3t=r(l7a,"FlaxOPTForCausalLM"),l7a.forEach(t),x3t=r(sso," (OPT model)"),sso.forEach(t),$3t=i(Ge),kL=n(Ge,"LI",{});var lso=s(kL);LBe=n(lso,"STRONG",{});var i7a=s(LBe);k3t=r(i7a,"roberta"),i7a.forEach(t),S3t=r(lso," \u2014 "),hme=n(lso,"A",{href:!0});var d7a=s(hme);R3t=r(d7a,"FlaxRobertaForCausalLM"),d7a.forEach(t),P3t=r(lso," (RoBERTa model)"),lso.forEach(t),B3t=i(Ge),SL=n(Ge,"LI",{});var iso=s(SL);yBe=n(iso,"STRONG",{});var m7a=s(yBe);I3t=r(m7a,"xglm"),m7a.forEach(t),N3t=r(iso," \u2014 "),ume=n(iso,"A",{href:!0});var c7a=s(ume);q3t=r(c7a,"FlaxXGLMForCausalLM"),c7a.forEach(t),j3t=r(iso," (XGLM model)"),iso.forEach(t),Ge.forEach(t),D3t=i(nd),T(RL.$$.fragment,nd),nd.forEach(t),ad.forEach(t),Ldo=i(c),Tf=n(c,"H2",{class:!0});var Zco=s(Tf);PL=n(Zco,"A",{id:!0,class:!0,href:!0});var f7a=s(PL);xBe=n(f7a,"SPAN",{});var g7a=s(xBe);T(mI.$$.fragment,g7a),g7a.forEach(t),f7a.forEach(t),G3t=i(Zco),$Be=n(Zco,"SPAN",{});var h7a=s($Be);O3t=r(h7a,"FlaxAutoModelForPreTraining"),h7a.forEach(t),Zco.forEach(t),ydo=i(c),Sr=n(c,"DIV",{class:!0});var sd=s(Sr);T(cI.$$.fragment,sd),V3t=i(sd),Mf=n(sd,"P",{});var Kge=s(Mf);X3t=r(Kge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),pme=n(Kge,"A",{href:!0});var u7a=s(pme);z3t=r(u7a,"from_pretrained()"),u7a.forEach(t),Q3t=r(Kge," class method or the "),_me=n(Kge,"A",{href:!0});var p7a=s(_me);W3t=r(p7a,"from_config()"),p7a.forEach(t),U3t=r(Kge,` class
method.`),Kge.forEach(t),H3t=i(sd),fI=n(sd,"P",{});var Kco=s(fI);J3t=r(Kco,"This class cannot be instantiated directly using "),kBe=n(Kco,"CODE",{});var _7a=s(kBe);Y3t=r(_7a,"__init__()"),_7a.forEach(t),Z3t=r(Kco," (throws an error)."),Kco.forEach(t),K3t=i(sd),va=n(sd,"DIV",{class:!0});var z$=s(va);T(gI.$$.fragment,z$),e5t=i(z$),SBe=n(z$,"P",{});var b7a=s(SBe);o5t=r(b7a,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),b7a.forEach(t),r5t=i(z$),Ef=n(z$,"P",{});var ehe=s(Ef);t5t=r(ehe,`Note:
Loading a model from its configuration file does `),RBe=n(ehe,"STRONG",{});var v7a=s(RBe);a5t=r(v7a,"not"),v7a.forEach(t),n5t=r(ehe,` load the model weights. It only affects the
model\u2019s configuration. Use `),bme=n(ehe,"A",{href:!0});var F7a=s(bme);s5t=r(F7a,"from_pretrained()"),F7a.forEach(t),l5t=r(ehe," to load the model weights."),ehe.forEach(t),i5t=i(z$),T(BL.$$.fragment,z$),z$.forEach(t),d5t=i(sd),it=n(sd,"DIV",{class:!0});var ld=s(it);T(hI.$$.fragment,ld),m5t=i(ld),PBe=n(ld,"P",{});var T7a=s(PBe);c5t=r(T7a,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),T7a.forEach(t),f5t=i(ld),ns=n(ld,"P",{});var Q$=s(ns);g5t=r(Q$,"The model class to instantiate is selected based on the "),BBe=n(Q$,"CODE",{});var M7a=s(BBe);h5t=r(M7a,"model_type"),M7a.forEach(t),u5t=r(Q$,` property of the config object (either
passed as an argument or loaded from `),IBe=n(Q$,"CODE",{});var E7a=s(IBe);p5t=r(E7a,"pretrained_model_name_or_path"),E7a.forEach(t),_5t=r(Q$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NBe=n(Q$,"CODE",{});var C7a=s(NBe);b5t=r(C7a,"pretrained_model_name_or_path"),C7a.forEach(t),v5t=r(Q$,":"),Q$.forEach(t),F5t=i(ld),we=n(ld,"UL",{});var Le=s(we);IL=n(Le,"LI",{});var dso=s(IL);qBe=n(dso,"STRONG",{});var w7a=s(qBe);T5t=r(w7a,"albert"),w7a.forEach(t),M5t=r(dso," \u2014 "),vme=n(dso,"A",{href:!0});var A7a=s(vme);E5t=r(A7a,"FlaxAlbertForPreTraining"),A7a.forEach(t),C5t=r(dso," (ALBERT model)"),dso.forEach(t),w5t=i(Le),NL=n(Le,"LI",{});var mso=s(NL);jBe=n(mso,"STRONG",{});var L7a=s(jBe);A5t=r(L7a,"bart"),L7a.forEach(t),L5t=r(mso," \u2014 "),Fme=n(mso,"A",{href:!0});var y7a=s(Fme);y5t=r(y7a,"FlaxBartForConditionalGeneration"),y7a.forEach(t),x5t=r(mso," (BART model)"),mso.forEach(t),$5t=i(Le),qL=n(Le,"LI",{});var cso=s(qL);DBe=n(cso,"STRONG",{});var x7a=s(DBe);k5t=r(x7a,"bert"),x7a.forEach(t),S5t=r(cso," \u2014 "),Tme=n(cso,"A",{href:!0});var $7a=s(Tme);R5t=r($7a,"FlaxBertForPreTraining"),$7a.forEach(t),P5t=r(cso," (BERT model)"),cso.forEach(t),B5t=i(Le),jL=n(Le,"LI",{});var fso=s(jL);GBe=n(fso,"STRONG",{});var k7a=s(GBe);I5t=r(k7a,"big_bird"),k7a.forEach(t),N5t=r(fso," \u2014 "),Mme=n(fso,"A",{href:!0});var S7a=s(Mme);q5t=r(S7a,"FlaxBigBirdForPreTraining"),S7a.forEach(t),j5t=r(fso," (BigBird model)"),fso.forEach(t),D5t=i(Le),DL=n(Le,"LI",{});var gso=s(DL);OBe=n(gso,"STRONG",{});var R7a=s(OBe);G5t=r(R7a,"electra"),R7a.forEach(t),O5t=r(gso," \u2014 "),Eme=n(gso,"A",{href:!0});var P7a=s(Eme);V5t=r(P7a,"FlaxElectraForPreTraining"),P7a.forEach(t),X5t=r(gso," (ELECTRA model)"),gso.forEach(t),z5t=i(Le),GL=n(Le,"LI",{});var hso=s(GL);VBe=n(hso,"STRONG",{});var B7a=s(VBe);Q5t=r(B7a,"longt5"),B7a.forEach(t),W5t=r(hso," \u2014 "),Cme=n(hso,"A",{href:!0});var I7a=s(Cme);U5t=r(I7a,"FlaxLongT5ForConditionalGeneration"),I7a.forEach(t),H5t=r(hso," (LongT5 model)"),hso.forEach(t),J5t=i(Le),OL=n(Le,"LI",{});var uso=s(OL);XBe=n(uso,"STRONG",{});var N7a=s(XBe);Y5t=r(N7a,"mbart"),N7a.forEach(t),Z5t=r(uso," \u2014 "),wme=n(uso,"A",{href:!0});var q7a=s(wme);K5t=r(q7a,"FlaxMBartForConditionalGeneration"),q7a.forEach(t),e0t=r(uso," (mBART model)"),uso.forEach(t),o0t=i(Le),VL=n(Le,"LI",{});var pso=s(VL);zBe=n(pso,"STRONG",{});var j7a=s(zBe);r0t=r(j7a,"mt5"),j7a.forEach(t),t0t=r(pso," \u2014 "),Ame=n(pso,"A",{href:!0});var D7a=s(Ame);a0t=r(D7a,"FlaxMT5ForConditionalGeneration"),D7a.forEach(t),n0t=r(pso," (MT5 model)"),pso.forEach(t),s0t=i(Le),XL=n(Le,"LI",{});var _so=s(XL);QBe=n(_so,"STRONG",{});var G7a=s(QBe);l0t=r(G7a,"roberta"),G7a.forEach(t),i0t=r(_so," \u2014 "),Lme=n(_so,"A",{href:!0});var O7a=s(Lme);d0t=r(O7a,"FlaxRobertaForMaskedLM"),O7a.forEach(t),m0t=r(_so," (RoBERTa model)"),_so.forEach(t),c0t=i(Le),zL=n(Le,"LI",{});var bso=s(zL);WBe=n(bso,"STRONG",{});var V7a=s(WBe);f0t=r(V7a,"roformer"),V7a.forEach(t),g0t=r(bso," \u2014 "),yme=n(bso,"A",{href:!0});var X7a=s(yme);h0t=r(X7a,"FlaxRoFormerForMaskedLM"),X7a.forEach(t),u0t=r(bso," (RoFormer model)"),bso.forEach(t),p0t=i(Le),QL=n(Le,"LI",{});var vso=s(QL);UBe=n(vso,"STRONG",{});var z7a=s(UBe);_0t=r(z7a,"t5"),z7a.forEach(t),b0t=r(vso," \u2014 "),xme=n(vso,"A",{href:!0});var Q7a=s(xme);v0t=r(Q7a,"FlaxT5ForConditionalGeneration"),Q7a.forEach(t),F0t=r(vso," (T5 model)"),vso.forEach(t),T0t=i(Le),WL=n(Le,"LI",{});var Fso=s(WL);HBe=n(Fso,"STRONG",{});var W7a=s(HBe);M0t=r(W7a,"wav2vec2"),W7a.forEach(t),E0t=r(Fso," \u2014 "),$me=n(Fso,"A",{href:!0});var U7a=s($me);C0t=r(U7a,"FlaxWav2Vec2ForPreTraining"),U7a.forEach(t),w0t=r(Fso," (Wav2Vec2 model)"),Fso.forEach(t),A0t=i(Le),UL=n(Le,"LI",{});var Tso=s(UL);JBe=n(Tso,"STRONG",{});var H7a=s(JBe);L0t=r(H7a,"xlm-roberta"),H7a.forEach(t),y0t=r(Tso," \u2014 "),kme=n(Tso,"A",{href:!0});var J7a=s(kme);x0t=r(J7a,"FlaxXLMRobertaForMaskedLM"),J7a.forEach(t),$0t=r(Tso," (XLM-RoBERTa model)"),Tso.forEach(t),Le.forEach(t),k0t=i(ld),T(HL.$$.fragment,ld),ld.forEach(t),sd.forEach(t),xdo=i(c),Cf=n(c,"H2",{class:!0});var efo=s(Cf);JL=n(efo,"A",{id:!0,class:!0,href:!0});var Y7a=s(JL);YBe=n(Y7a,"SPAN",{});var Z7a=s(YBe);T(uI.$$.fragment,Z7a),Z7a.forEach(t),Y7a.forEach(t),S0t=i(efo),ZBe=n(efo,"SPAN",{});var K7a=s(ZBe);R0t=r(K7a,"FlaxAutoModelForMaskedLM"),K7a.forEach(t),efo.forEach(t),$do=i(c),Rr=n(c,"DIV",{class:!0});var id=s(Rr);T(pI.$$.fragment,id),P0t=i(id),wf=n(id,"P",{});var ohe=s(wf);B0t=r(ohe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Sme=n(ohe,"A",{href:!0});var e8a=s(Sme);I0t=r(e8a,"from_pretrained()"),e8a.forEach(t),N0t=r(ohe," class method or the "),Rme=n(ohe,"A",{href:!0});var o8a=s(Rme);q0t=r(o8a,"from_config()"),o8a.forEach(t),j0t=r(ohe,` class
method.`),ohe.forEach(t),D0t=i(id),_I=n(id,"P",{});var ofo=s(_I);G0t=r(ofo,"This class cannot be instantiated directly using "),KBe=n(ofo,"CODE",{});var r8a=s(KBe);O0t=r(r8a,"__init__()"),r8a.forEach(t),V0t=r(ofo," (throws an error)."),ofo.forEach(t),X0t=i(id),Fa=n(id,"DIV",{class:!0});var W$=s(Fa);T(bI.$$.fragment,W$),z0t=i(W$),eIe=n(W$,"P",{});var t8a=s(eIe);Q0t=r(t8a,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),t8a.forEach(t),W0t=i(W$),Af=n(W$,"P",{});var rhe=s(Af);U0t=r(rhe,`Note:
Loading a model from its configuration file does `),oIe=n(rhe,"STRONG",{});var a8a=s(oIe);H0t=r(a8a,"not"),a8a.forEach(t),J0t=r(rhe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Pme=n(rhe,"A",{href:!0});var n8a=s(Pme);Y0t=r(n8a,"from_pretrained()"),n8a.forEach(t),Z0t=r(rhe," to load the model weights."),rhe.forEach(t),K0t=i(W$),T(YL.$$.fragment,W$),W$.forEach(t),ewt=i(id),dt=n(id,"DIV",{class:!0});var dd=s(dt);T(vI.$$.fragment,dd),owt=i(dd),rIe=n(dd,"P",{});var s8a=s(rIe);rwt=r(s8a,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),s8a.forEach(t),twt=i(dd),ss=n(dd,"P",{});var U$=s(ss);awt=r(U$,"The model class to instantiate is selected based on the "),tIe=n(U$,"CODE",{});var l8a=s(tIe);nwt=r(l8a,"model_type"),l8a.forEach(t),swt=r(U$,` property of the config object (either
passed as an argument or loaded from `),aIe=n(U$,"CODE",{});var i8a=s(aIe);lwt=r(i8a,"pretrained_model_name_or_path"),i8a.forEach(t),iwt=r(U$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nIe=n(U$,"CODE",{});var d8a=s(nIe);dwt=r(d8a,"pretrained_model_name_or_path"),d8a.forEach(t),mwt=r(U$,":"),U$.forEach(t),cwt=i(dd),Re=n(dd,"UL",{});var Oe=s(Re);ZL=n(Oe,"LI",{});var Mso=s(ZL);sIe=n(Mso,"STRONG",{});var m8a=s(sIe);fwt=r(m8a,"albert"),m8a.forEach(t),gwt=r(Mso," \u2014 "),Bme=n(Mso,"A",{href:!0});var c8a=s(Bme);hwt=r(c8a,"FlaxAlbertForMaskedLM"),c8a.forEach(t),uwt=r(Mso," (ALBERT model)"),Mso.forEach(t),pwt=i(Oe),KL=n(Oe,"LI",{});var Eso=s(KL);lIe=n(Eso,"STRONG",{});var f8a=s(lIe);_wt=r(f8a,"bart"),f8a.forEach(t),bwt=r(Eso," \u2014 "),Ime=n(Eso,"A",{href:!0});var g8a=s(Ime);vwt=r(g8a,"FlaxBartForConditionalGeneration"),g8a.forEach(t),Fwt=r(Eso," (BART model)"),Eso.forEach(t),Twt=i(Oe),ey=n(Oe,"LI",{});var Cso=s(ey);iIe=n(Cso,"STRONG",{});var h8a=s(iIe);Mwt=r(h8a,"bert"),h8a.forEach(t),Ewt=r(Cso," \u2014 "),Nme=n(Cso,"A",{href:!0});var u8a=s(Nme);Cwt=r(u8a,"FlaxBertForMaskedLM"),u8a.forEach(t),wwt=r(Cso," (BERT model)"),Cso.forEach(t),Awt=i(Oe),oy=n(Oe,"LI",{});var wso=s(oy);dIe=n(wso,"STRONG",{});var p8a=s(dIe);Lwt=r(p8a,"big_bird"),p8a.forEach(t),ywt=r(wso," \u2014 "),qme=n(wso,"A",{href:!0});var _8a=s(qme);xwt=r(_8a,"FlaxBigBirdForMaskedLM"),_8a.forEach(t),$wt=r(wso," (BigBird model)"),wso.forEach(t),kwt=i(Oe),ry=n(Oe,"LI",{});var Aso=s(ry);mIe=n(Aso,"STRONG",{});var b8a=s(mIe);Swt=r(b8a,"distilbert"),b8a.forEach(t),Rwt=r(Aso," \u2014 "),jme=n(Aso,"A",{href:!0});var v8a=s(jme);Pwt=r(v8a,"FlaxDistilBertForMaskedLM"),v8a.forEach(t),Bwt=r(Aso," (DistilBERT model)"),Aso.forEach(t),Iwt=i(Oe),ty=n(Oe,"LI",{});var Lso=s(ty);cIe=n(Lso,"STRONG",{});var F8a=s(cIe);Nwt=r(F8a,"electra"),F8a.forEach(t),qwt=r(Lso," \u2014 "),Dme=n(Lso,"A",{href:!0});var T8a=s(Dme);jwt=r(T8a,"FlaxElectraForMaskedLM"),T8a.forEach(t),Dwt=r(Lso," (ELECTRA model)"),Lso.forEach(t),Gwt=i(Oe),ay=n(Oe,"LI",{});var yso=s(ay);fIe=n(yso,"STRONG",{});var M8a=s(fIe);Owt=r(M8a,"mbart"),M8a.forEach(t),Vwt=r(yso," \u2014 "),Gme=n(yso,"A",{href:!0});var E8a=s(Gme);Xwt=r(E8a,"FlaxMBartForConditionalGeneration"),E8a.forEach(t),zwt=r(yso," (mBART model)"),yso.forEach(t),Qwt=i(Oe),ny=n(Oe,"LI",{});var xso=s(ny);gIe=n(xso,"STRONG",{});var C8a=s(gIe);Wwt=r(C8a,"roberta"),C8a.forEach(t),Uwt=r(xso," \u2014 "),Ome=n(xso,"A",{href:!0});var w8a=s(Ome);Hwt=r(w8a,"FlaxRobertaForMaskedLM"),w8a.forEach(t),Jwt=r(xso," (RoBERTa model)"),xso.forEach(t),Ywt=i(Oe),sy=n(Oe,"LI",{});var $so=s(sy);hIe=n($so,"STRONG",{});var A8a=s(hIe);Zwt=r(A8a,"roformer"),A8a.forEach(t),Kwt=r($so," \u2014 "),Vme=n($so,"A",{href:!0});var L8a=s(Vme);eAt=r(L8a,"FlaxRoFormerForMaskedLM"),L8a.forEach(t),oAt=r($so," (RoFormer model)"),$so.forEach(t),rAt=i(Oe),ly=n(Oe,"LI",{});var kso=s(ly);uIe=n(kso,"STRONG",{});var y8a=s(uIe);tAt=r(y8a,"xlm-roberta"),y8a.forEach(t),aAt=r(kso," \u2014 "),Xme=n(kso,"A",{href:!0});var x8a=s(Xme);nAt=r(x8a,"FlaxXLMRobertaForMaskedLM"),x8a.forEach(t),sAt=r(kso," (XLM-RoBERTa model)"),kso.forEach(t),Oe.forEach(t),lAt=i(dd),T(iy.$$.fragment,dd),dd.forEach(t),id.forEach(t),kdo=i(c),Lf=n(c,"H2",{class:!0});var rfo=s(Lf);dy=n(rfo,"A",{id:!0,class:!0,href:!0});var $8a=s(dy);pIe=n($8a,"SPAN",{});var k8a=s(pIe);T(FI.$$.fragment,k8a),k8a.forEach(t),$8a.forEach(t),iAt=i(rfo),_Ie=n(rfo,"SPAN",{});var S8a=s(_Ie);dAt=r(S8a,"FlaxAutoModelForSeq2SeqLM"),S8a.forEach(t),rfo.forEach(t),Sdo=i(c),Pr=n(c,"DIV",{class:!0});var md=s(Pr);T(TI.$$.fragment,md),mAt=i(md),yf=n(md,"P",{});var the=s(yf);cAt=r(the,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),zme=n(the,"A",{href:!0});var R8a=s(zme);fAt=r(R8a,"from_pretrained()"),R8a.forEach(t),gAt=r(the," class method or the "),Qme=n(the,"A",{href:!0});var P8a=s(Qme);hAt=r(P8a,"from_config()"),P8a.forEach(t),uAt=r(the,` class
method.`),the.forEach(t),pAt=i(md),MI=n(md,"P",{});var tfo=s(MI);_At=r(tfo,"This class cannot be instantiated directly using "),bIe=n(tfo,"CODE",{});var B8a=s(bIe);bAt=r(B8a,"__init__()"),B8a.forEach(t),vAt=r(tfo," (throws an error)."),tfo.forEach(t),FAt=i(md),Ta=n(md,"DIV",{class:!0});var H$=s(Ta);T(EI.$$.fragment,H$),TAt=i(H$),vIe=n(H$,"P",{});var I8a=s(vIe);MAt=r(I8a,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),I8a.forEach(t),EAt=i(H$),xf=n(H$,"P",{});var ahe=s(xf);CAt=r(ahe,`Note:
Loading a model from its configuration file does `),FIe=n(ahe,"STRONG",{});var N8a=s(FIe);wAt=r(N8a,"not"),N8a.forEach(t),AAt=r(ahe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Wme=n(ahe,"A",{href:!0});var q8a=s(Wme);LAt=r(q8a,"from_pretrained()"),q8a.forEach(t),yAt=r(ahe," to load the model weights."),ahe.forEach(t),xAt=i(H$),T(my.$$.fragment,H$),H$.forEach(t),$At=i(md),mt=n(md,"DIV",{class:!0});var cd=s(mt);T(CI.$$.fragment,cd),kAt=i(cd),TIe=n(cd,"P",{});var j8a=s(TIe);SAt=r(j8a,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),j8a.forEach(t),RAt=i(cd),ls=n(cd,"P",{});var J$=s(ls);PAt=r(J$,"The model class to instantiate is selected based on the "),MIe=n(J$,"CODE",{});var D8a=s(MIe);BAt=r(D8a,"model_type"),D8a.forEach(t),IAt=r(J$,` property of the config object (either
passed as an argument or loaded from `),EIe=n(J$,"CODE",{});var G8a=s(EIe);NAt=r(G8a,"pretrained_model_name_or_path"),G8a.forEach(t),qAt=r(J$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),CIe=n(J$,"CODE",{});var O8a=s(CIe);jAt=r(O8a,"pretrained_model_name_or_path"),O8a.forEach(t),DAt=r(J$,":"),J$.forEach(t),GAt=i(cd),Pe=n(cd,"UL",{});var Ve=s(Pe);cy=n(Ve,"LI",{});var Sso=s(cy);wIe=n(Sso,"STRONG",{});var V8a=s(wIe);OAt=r(V8a,"bart"),V8a.forEach(t),VAt=r(Sso," \u2014 "),Ume=n(Sso,"A",{href:!0});var X8a=s(Ume);XAt=r(X8a,"FlaxBartForConditionalGeneration"),X8a.forEach(t),zAt=r(Sso," (BART model)"),Sso.forEach(t),QAt=i(Ve),fy=n(Ve,"LI",{});var Rso=s(fy);AIe=n(Rso,"STRONG",{});var z8a=s(AIe);WAt=r(z8a,"blenderbot"),z8a.forEach(t),UAt=r(Rso," \u2014 "),Hme=n(Rso,"A",{href:!0});var Q8a=s(Hme);HAt=r(Q8a,"FlaxBlenderbotForConditionalGeneration"),Q8a.forEach(t),JAt=r(Rso," (Blenderbot model)"),Rso.forEach(t),YAt=i(Ve),gy=n(Ve,"LI",{});var Pso=s(gy);LIe=n(Pso,"STRONG",{});var W8a=s(LIe);ZAt=r(W8a,"blenderbot-small"),W8a.forEach(t),KAt=r(Pso," \u2014 "),Jme=n(Pso,"A",{href:!0});var U8a=s(Jme);e6t=r(U8a,"FlaxBlenderbotSmallForConditionalGeneration"),U8a.forEach(t),o6t=r(Pso," (BlenderbotSmall model)"),Pso.forEach(t),r6t=i(Ve),hy=n(Ve,"LI",{});var Bso=s(hy);yIe=n(Bso,"STRONG",{});var H8a=s(yIe);t6t=r(H8a,"encoder-decoder"),H8a.forEach(t),a6t=r(Bso," \u2014 "),Yme=n(Bso,"A",{href:!0});var J8a=s(Yme);n6t=r(J8a,"FlaxEncoderDecoderModel"),J8a.forEach(t),s6t=r(Bso," (Encoder decoder model)"),Bso.forEach(t),l6t=i(Ve),uy=n(Ve,"LI",{});var Iso=s(uy);xIe=n(Iso,"STRONG",{});var Y8a=s(xIe);i6t=r(Y8a,"longt5"),Y8a.forEach(t),d6t=r(Iso," \u2014 "),Zme=n(Iso,"A",{href:!0});var Z8a=s(Zme);m6t=r(Z8a,"FlaxLongT5ForConditionalGeneration"),Z8a.forEach(t),c6t=r(Iso," (LongT5 model)"),Iso.forEach(t),f6t=i(Ve),py=n(Ve,"LI",{});var Nso=s(py);$Ie=n(Nso,"STRONG",{});var K8a=s($Ie);g6t=r(K8a,"marian"),K8a.forEach(t),h6t=r(Nso," \u2014 "),Kme=n(Nso,"A",{href:!0});var eLa=s(Kme);u6t=r(eLa,"FlaxMarianMTModel"),eLa.forEach(t),p6t=r(Nso," (Marian model)"),Nso.forEach(t),_6t=i(Ve),_y=n(Ve,"LI",{});var qso=s(_y);kIe=n(qso,"STRONG",{});var oLa=s(kIe);b6t=r(oLa,"mbart"),oLa.forEach(t),v6t=r(qso," \u2014 "),ece=n(qso,"A",{href:!0});var rLa=s(ece);F6t=r(rLa,"FlaxMBartForConditionalGeneration"),rLa.forEach(t),T6t=r(qso," (mBART model)"),qso.forEach(t),M6t=i(Ve),by=n(Ve,"LI",{});var jso=s(by);SIe=n(jso,"STRONG",{});var tLa=s(SIe);E6t=r(tLa,"mt5"),tLa.forEach(t),C6t=r(jso," \u2014 "),oce=n(jso,"A",{href:!0});var aLa=s(oce);w6t=r(aLa,"FlaxMT5ForConditionalGeneration"),aLa.forEach(t),A6t=r(jso," (MT5 model)"),jso.forEach(t),L6t=i(Ve),vy=n(Ve,"LI",{});var Dso=s(vy);RIe=n(Dso,"STRONG",{});var nLa=s(RIe);y6t=r(nLa,"pegasus"),nLa.forEach(t),x6t=r(Dso," \u2014 "),rce=n(Dso,"A",{href:!0});var sLa=s(rce);$6t=r(sLa,"FlaxPegasusForConditionalGeneration"),sLa.forEach(t),k6t=r(Dso," (Pegasus model)"),Dso.forEach(t),S6t=i(Ve),Fy=n(Ve,"LI",{});var Gso=s(Fy);PIe=n(Gso,"STRONG",{});var lLa=s(PIe);R6t=r(lLa,"t5"),lLa.forEach(t),P6t=r(Gso," \u2014 "),tce=n(Gso,"A",{href:!0});var iLa=s(tce);B6t=r(iLa,"FlaxT5ForConditionalGeneration"),iLa.forEach(t),I6t=r(Gso," (T5 model)"),Gso.forEach(t),Ve.forEach(t),N6t=i(cd),T(Ty.$$.fragment,cd),cd.forEach(t),md.forEach(t),Rdo=i(c),$f=n(c,"H2",{class:!0});var afo=s($f);My=n(afo,"A",{id:!0,class:!0,href:!0});var dLa=s(My);BIe=n(dLa,"SPAN",{});var mLa=s(BIe);T(wI.$$.fragment,mLa),mLa.forEach(t),dLa.forEach(t),q6t=i(afo),IIe=n(afo,"SPAN",{});var cLa=s(IIe);j6t=r(cLa,"FlaxAutoModelForSequenceClassification"),cLa.forEach(t),afo.forEach(t),Pdo=i(c),Br=n(c,"DIV",{class:!0});var fd=s(Br);T(AI.$$.fragment,fd),D6t=i(fd),kf=n(fd,"P",{});var nhe=s(kf);G6t=r(nhe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),ace=n(nhe,"A",{href:!0});var fLa=s(ace);O6t=r(fLa,"from_pretrained()"),fLa.forEach(t),V6t=r(nhe," class method or the "),nce=n(nhe,"A",{href:!0});var gLa=s(nce);X6t=r(gLa,"from_config()"),gLa.forEach(t),z6t=r(nhe,` class
method.`),nhe.forEach(t),Q6t=i(fd),LI=n(fd,"P",{});var nfo=s(LI);W6t=r(nfo,"This class cannot be instantiated directly using "),NIe=n(nfo,"CODE",{});var hLa=s(NIe);U6t=r(hLa,"__init__()"),hLa.forEach(t),H6t=r(nfo," (throws an error)."),nfo.forEach(t),J6t=i(fd),Ma=n(fd,"DIV",{class:!0});var Y$=s(Ma);T(yI.$$.fragment,Y$),Y6t=i(Y$),qIe=n(Y$,"P",{});var uLa=s(qIe);Z6t=r(uLa,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),uLa.forEach(t),K6t=i(Y$),Sf=n(Y$,"P",{});var she=s(Sf);e7t=r(she,`Note:
Loading a model from its configuration file does `),jIe=n(she,"STRONG",{});var pLa=s(jIe);o7t=r(pLa,"not"),pLa.forEach(t),r7t=r(she,` load the model weights. It only affects the
model\u2019s configuration. Use `),sce=n(she,"A",{href:!0});var _La=s(sce);t7t=r(_La,"from_pretrained()"),_La.forEach(t),a7t=r(she," to load the model weights."),she.forEach(t),n7t=i(Y$),T(Ey.$$.fragment,Y$),Y$.forEach(t),s7t=i(fd),ct=n(fd,"DIV",{class:!0});var gd=s(ct);T(xI.$$.fragment,gd),l7t=i(gd),DIe=n(gd,"P",{});var bLa=s(DIe);i7t=r(bLa,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),bLa.forEach(t),d7t=i(gd),is=n(gd,"P",{});var Z$=s(is);m7t=r(Z$,"The model class to instantiate is selected based on the "),GIe=n(Z$,"CODE",{});var vLa=s(GIe);c7t=r(vLa,"model_type"),vLa.forEach(t),f7t=r(Z$,` property of the config object (either
passed as an argument or loaded from `),OIe=n(Z$,"CODE",{});var FLa=s(OIe);g7t=r(FLa,"pretrained_model_name_or_path"),FLa.forEach(t),h7t=r(Z$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VIe=n(Z$,"CODE",{});var TLa=s(VIe);u7t=r(TLa,"pretrained_model_name_or_path"),TLa.forEach(t),p7t=r(Z$,":"),Z$.forEach(t),_7t=i(gd),Be=n(gd,"UL",{});var Xe=s(Be);Cy=n(Xe,"LI",{});var Oso=s(Cy);XIe=n(Oso,"STRONG",{});var MLa=s(XIe);b7t=r(MLa,"albert"),MLa.forEach(t),v7t=r(Oso," \u2014 "),lce=n(Oso,"A",{href:!0});var ELa=s(lce);F7t=r(ELa,"FlaxAlbertForSequenceClassification"),ELa.forEach(t),T7t=r(Oso," (ALBERT model)"),Oso.forEach(t),M7t=i(Xe),wy=n(Xe,"LI",{});var Vso=s(wy);zIe=n(Vso,"STRONG",{});var CLa=s(zIe);E7t=r(CLa,"bart"),CLa.forEach(t),C7t=r(Vso," \u2014 "),ice=n(Vso,"A",{href:!0});var wLa=s(ice);w7t=r(wLa,"FlaxBartForSequenceClassification"),wLa.forEach(t),A7t=r(Vso," (BART model)"),Vso.forEach(t),L7t=i(Xe),Ay=n(Xe,"LI",{});var Xso=s(Ay);QIe=n(Xso,"STRONG",{});var ALa=s(QIe);y7t=r(ALa,"bert"),ALa.forEach(t),x7t=r(Xso," \u2014 "),dce=n(Xso,"A",{href:!0});var LLa=s(dce);$7t=r(LLa,"FlaxBertForSequenceClassification"),LLa.forEach(t),k7t=r(Xso," (BERT model)"),Xso.forEach(t),S7t=i(Xe),Ly=n(Xe,"LI",{});var zso=s(Ly);WIe=n(zso,"STRONG",{});var yLa=s(WIe);R7t=r(yLa,"big_bird"),yLa.forEach(t),P7t=r(zso," \u2014 "),mce=n(zso,"A",{href:!0});var xLa=s(mce);B7t=r(xLa,"FlaxBigBirdForSequenceClassification"),xLa.forEach(t),I7t=r(zso," (BigBird model)"),zso.forEach(t),N7t=i(Xe),yy=n(Xe,"LI",{});var Qso=s(yy);UIe=n(Qso,"STRONG",{});var $La=s(UIe);q7t=r($La,"distilbert"),$La.forEach(t),j7t=r(Qso," \u2014 "),cce=n(Qso,"A",{href:!0});var kLa=s(cce);D7t=r(kLa,"FlaxDistilBertForSequenceClassification"),kLa.forEach(t),G7t=r(Qso," (DistilBERT model)"),Qso.forEach(t),O7t=i(Xe),xy=n(Xe,"LI",{});var Wso=s(xy);HIe=n(Wso,"STRONG",{});var SLa=s(HIe);V7t=r(SLa,"electra"),SLa.forEach(t),X7t=r(Wso," \u2014 "),fce=n(Wso,"A",{href:!0});var RLa=s(fce);z7t=r(RLa,"FlaxElectraForSequenceClassification"),RLa.forEach(t),Q7t=r(Wso," (ELECTRA model)"),Wso.forEach(t),W7t=i(Xe),$y=n(Xe,"LI",{});var Uso=s($y);JIe=n(Uso,"STRONG",{});var PLa=s(JIe);U7t=r(PLa,"mbart"),PLa.forEach(t),H7t=r(Uso," \u2014 "),gce=n(Uso,"A",{href:!0});var BLa=s(gce);J7t=r(BLa,"FlaxMBartForSequenceClassification"),BLa.forEach(t),Y7t=r(Uso," (mBART model)"),Uso.forEach(t),Z7t=i(Xe),ky=n(Xe,"LI",{});var Hso=s(ky);YIe=n(Hso,"STRONG",{});var ILa=s(YIe);K7t=r(ILa,"roberta"),ILa.forEach(t),e8t=r(Hso," \u2014 "),hce=n(Hso,"A",{href:!0});var NLa=s(hce);o8t=r(NLa,"FlaxRobertaForSequenceClassification"),NLa.forEach(t),r8t=r(Hso," (RoBERTa model)"),Hso.forEach(t),t8t=i(Xe),Sy=n(Xe,"LI",{});var Jso=s(Sy);ZIe=n(Jso,"STRONG",{});var qLa=s(ZIe);a8t=r(qLa,"roformer"),qLa.forEach(t),n8t=r(Jso," \u2014 "),uce=n(Jso,"A",{href:!0});var jLa=s(uce);s8t=r(jLa,"FlaxRoFormerForSequenceClassification"),jLa.forEach(t),l8t=r(Jso," (RoFormer model)"),Jso.forEach(t),i8t=i(Xe),Ry=n(Xe,"LI",{});var Yso=s(Ry);KIe=n(Yso,"STRONG",{});var DLa=s(KIe);d8t=r(DLa,"xlm-roberta"),DLa.forEach(t),m8t=r(Yso," \u2014 "),pce=n(Yso,"A",{href:!0});var GLa=s(pce);c8t=r(GLa,"FlaxXLMRobertaForSequenceClassification"),GLa.forEach(t),f8t=r(Yso," (XLM-RoBERTa model)"),Yso.forEach(t),Xe.forEach(t),g8t=i(gd),T(Py.$$.fragment,gd),gd.forEach(t),fd.forEach(t),Bdo=i(c),Rf=n(c,"H2",{class:!0});var sfo=s(Rf);By=n(sfo,"A",{id:!0,class:!0,href:!0});var OLa=s(By);eNe=n(OLa,"SPAN",{});var VLa=s(eNe);T($I.$$.fragment,VLa),VLa.forEach(t),OLa.forEach(t),h8t=i(sfo),oNe=n(sfo,"SPAN",{});var XLa=s(oNe);u8t=r(XLa,"FlaxAutoModelForQuestionAnswering"),XLa.forEach(t),sfo.forEach(t),Ido=i(c),Ir=n(c,"DIV",{class:!0});var hd=s(Ir);T(kI.$$.fragment,hd),p8t=i(hd),Pf=n(hd,"P",{});var lhe=s(Pf);_8t=r(lhe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),_ce=n(lhe,"A",{href:!0});var zLa=s(_ce);b8t=r(zLa,"from_pretrained()"),zLa.forEach(t),v8t=r(lhe," class method or the "),bce=n(lhe,"A",{href:!0});var QLa=s(bce);F8t=r(QLa,"from_config()"),QLa.forEach(t),T8t=r(lhe,` class
method.`),lhe.forEach(t),M8t=i(hd),SI=n(hd,"P",{});var lfo=s(SI);E8t=r(lfo,"This class cannot be instantiated directly using "),rNe=n(lfo,"CODE",{});var WLa=s(rNe);C8t=r(WLa,"__init__()"),WLa.forEach(t),w8t=r(lfo," (throws an error)."),lfo.forEach(t),A8t=i(hd),Ea=n(hd,"DIV",{class:!0});var K$=s(Ea);T(RI.$$.fragment,K$),L8t=i(K$),tNe=n(K$,"P",{});var ULa=s(tNe);y8t=r(ULa,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),ULa.forEach(t),x8t=i(K$),Bf=n(K$,"P",{});var ihe=s(Bf);$8t=r(ihe,`Note:
Loading a model from its configuration file does `),aNe=n(ihe,"STRONG",{});var HLa=s(aNe);k8t=r(HLa,"not"),HLa.forEach(t),S8t=r(ihe,` load the model weights. It only affects the
model\u2019s configuration. Use `),vce=n(ihe,"A",{href:!0});var JLa=s(vce);R8t=r(JLa,"from_pretrained()"),JLa.forEach(t),P8t=r(ihe," to load the model weights."),ihe.forEach(t),B8t=i(K$),T(Iy.$$.fragment,K$),K$.forEach(t),I8t=i(hd),ft=n(hd,"DIV",{class:!0});var ud=s(ft);T(PI.$$.fragment,ud),N8t=i(ud),nNe=n(ud,"P",{});var YLa=s(nNe);q8t=r(YLa,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),YLa.forEach(t),j8t=i(ud),ds=n(ud,"P",{});var ek=s(ds);D8t=r(ek,"The model class to instantiate is selected based on the "),sNe=n(ek,"CODE",{});var ZLa=s(sNe);G8t=r(ZLa,"model_type"),ZLa.forEach(t),O8t=r(ek,` property of the config object (either
passed as an argument or loaded from `),lNe=n(ek,"CODE",{});var KLa=s(lNe);V8t=r(KLa,"pretrained_model_name_or_path"),KLa.forEach(t),X8t=r(ek,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iNe=n(ek,"CODE",{});var eya=s(iNe);z8t=r(eya,"pretrained_model_name_or_path"),eya.forEach(t),Q8t=r(ek,":"),ek.forEach(t),W8t=i(ud),Ie=n(ud,"UL",{});var ze=s(Ie);Ny=n(ze,"LI",{});var Zso=s(Ny);dNe=n(Zso,"STRONG",{});var oya=s(dNe);U8t=r(oya,"albert"),oya.forEach(t),H8t=r(Zso," \u2014 "),Fce=n(Zso,"A",{href:!0});var rya=s(Fce);J8t=r(rya,"FlaxAlbertForQuestionAnswering"),rya.forEach(t),Y8t=r(Zso," (ALBERT model)"),Zso.forEach(t),Z8t=i(ze),qy=n(ze,"LI",{});var Kso=s(qy);mNe=n(Kso,"STRONG",{});var tya=s(mNe);K8t=r(tya,"bart"),tya.forEach(t),eLt=r(Kso," \u2014 "),Tce=n(Kso,"A",{href:!0});var aya=s(Tce);oLt=r(aya,"FlaxBartForQuestionAnswering"),aya.forEach(t),rLt=r(Kso," (BART model)"),Kso.forEach(t),tLt=i(ze),jy=n(ze,"LI",{});var elo=s(jy);cNe=n(elo,"STRONG",{});var nya=s(cNe);aLt=r(nya,"bert"),nya.forEach(t),nLt=r(elo," \u2014 "),Mce=n(elo,"A",{href:!0});var sya=s(Mce);sLt=r(sya,"FlaxBertForQuestionAnswering"),sya.forEach(t),lLt=r(elo," (BERT model)"),elo.forEach(t),iLt=i(ze),Dy=n(ze,"LI",{});var olo=s(Dy);fNe=n(olo,"STRONG",{});var lya=s(fNe);dLt=r(lya,"big_bird"),lya.forEach(t),mLt=r(olo," \u2014 "),Ece=n(olo,"A",{href:!0});var iya=s(Ece);cLt=r(iya,"FlaxBigBirdForQuestionAnswering"),iya.forEach(t),fLt=r(olo," (BigBird model)"),olo.forEach(t),gLt=i(ze),Gy=n(ze,"LI",{});var rlo=s(Gy);gNe=n(rlo,"STRONG",{});var dya=s(gNe);hLt=r(dya,"distilbert"),dya.forEach(t),uLt=r(rlo," \u2014 "),Cce=n(rlo,"A",{href:!0});var mya=s(Cce);pLt=r(mya,"FlaxDistilBertForQuestionAnswering"),mya.forEach(t),_Lt=r(rlo," (DistilBERT model)"),rlo.forEach(t),bLt=i(ze),Oy=n(ze,"LI",{});var tlo=s(Oy);hNe=n(tlo,"STRONG",{});var cya=s(hNe);vLt=r(cya,"electra"),cya.forEach(t),FLt=r(tlo," \u2014 "),wce=n(tlo,"A",{href:!0});var fya=s(wce);TLt=r(fya,"FlaxElectraForQuestionAnswering"),fya.forEach(t),MLt=r(tlo," (ELECTRA model)"),tlo.forEach(t),ELt=i(ze),Vy=n(ze,"LI",{});var alo=s(Vy);uNe=n(alo,"STRONG",{});var gya=s(uNe);CLt=r(gya,"mbart"),gya.forEach(t),wLt=r(alo," \u2014 "),Ace=n(alo,"A",{href:!0});var hya=s(Ace);ALt=r(hya,"FlaxMBartForQuestionAnswering"),hya.forEach(t),LLt=r(alo," (mBART model)"),alo.forEach(t),yLt=i(ze),Xy=n(ze,"LI",{});var nlo=s(Xy);pNe=n(nlo,"STRONG",{});var uya=s(pNe);xLt=r(uya,"roberta"),uya.forEach(t),$Lt=r(nlo," \u2014 "),Lce=n(nlo,"A",{href:!0});var pya=s(Lce);kLt=r(pya,"FlaxRobertaForQuestionAnswering"),pya.forEach(t),SLt=r(nlo," (RoBERTa model)"),nlo.forEach(t),RLt=i(ze),zy=n(ze,"LI",{});var slo=s(zy);_Ne=n(slo,"STRONG",{});var _ya=s(_Ne);PLt=r(_ya,"roformer"),_ya.forEach(t),BLt=r(slo," \u2014 "),yce=n(slo,"A",{href:!0});var bya=s(yce);ILt=r(bya,"FlaxRoFormerForQuestionAnswering"),bya.forEach(t),NLt=r(slo," (RoFormer model)"),slo.forEach(t),qLt=i(ze),Qy=n(ze,"LI",{});var llo=s(Qy);bNe=n(llo,"STRONG",{});var vya=s(bNe);jLt=r(vya,"xlm-roberta"),vya.forEach(t),DLt=r(llo," \u2014 "),xce=n(llo,"A",{href:!0});var Fya=s(xce);GLt=r(Fya,"FlaxXLMRobertaForQuestionAnswering"),Fya.forEach(t),OLt=r(llo," (XLM-RoBERTa model)"),llo.forEach(t),ze.forEach(t),VLt=i(ud),T(Wy.$$.fragment,ud),ud.forEach(t),hd.forEach(t),Ndo=i(c),If=n(c,"H2",{class:!0});var ifo=s(If);Uy=n(ifo,"A",{id:!0,class:!0,href:!0});var Tya=s(Uy);vNe=n(Tya,"SPAN",{});var Mya=s(vNe);T(BI.$$.fragment,Mya),Mya.forEach(t),Tya.forEach(t),XLt=i(ifo),FNe=n(ifo,"SPAN",{});var Eya=s(FNe);zLt=r(Eya,"FlaxAutoModelForTokenClassification"),Eya.forEach(t),ifo.forEach(t),qdo=i(c),Nr=n(c,"DIV",{class:!0});var pd=s(Nr);T(II.$$.fragment,pd),QLt=i(pd),Nf=n(pd,"P",{});var dhe=s(Nf);WLt=r(dhe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),$ce=n(dhe,"A",{href:!0});var Cya=s($ce);ULt=r(Cya,"from_pretrained()"),Cya.forEach(t),HLt=r(dhe," class method or the "),kce=n(dhe,"A",{href:!0});var wya=s(kce);JLt=r(wya,"from_config()"),wya.forEach(t),YLt=r(dhe,` class
method.`),dhe.forEach(t),ZLt=i(pd),NI=n(pd,"P",{});var dfo=s(NI);KLt=r(dfo,"This class cannot be instantiated directly using "),TNe=n(dfo,"CODE",{});var Aya=s(TNe);eyt=r(Aya,"__init__()"),Aya.forEach(t),oyt=r(dfo," (throws an error)."),dfo.forEach(t),ryt=i(pd),Ca=n(pd,"DIV",{class:!0});var ok=s(Ca);T(qI.$$.fragment,ok),tyt=i(ok),MNe=n(ok,"P",{});var Lya=s(MNe);ayt=r(Lya,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Lya.forEach(t),nyt=i(ok),qf=n(ok,"P",{});var mhe=s(qf);syt=r(mhe,`Note:
Loading a model from its configuration file does `),ENe=n(mhe,"STRONG",{});var yya=s(ENe);lyt=r(yya,"not"),yya.forEach(t),iyt=r(mhe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Sce=n(mhe,"A",{href:!0});var xya=s(Sce);dyt=r(xya,"from_pretrained()"),xya.forEach(t),myt=r(mhe," to load the model weights."),mhe.forEach(t),cyt=i(ok),T(Hy.$$.fragment,ok),ok.forEach(t),fyt=i(pd),gt=n(pd,"DIV",{class:!0});var _d=s(gt);T(jI.$$.fragment,_d),gyt=i(_d),CNe=n(_d,"P",{});var $ya=s(CNe);hyt=r($ya,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),$ya.forEach(t),uyt=i(_d),ms=n(_d,"P",{});var rk=s(ms);pyt=r(rk,"The model class to instantiate is selected based on the "),wNe=n(rk,"CODE",{});var kya=s(wNe);_yt=r(kya,"model_type"),kya.forEach(t),byt=r(rk,` property of the config object (either
passed as an argument or loaded from `),ANe=n(rk,"CODE",{});var Sya=s(ANe);vyt=r(Sya,"pretrained_model_name_or_path"),Sya.forEach(t),Fyt=r(rk,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LNe=n(rk,"CODE",{});var Rya=s(LNe);Tyt=r(Rya,"pretrained_model_name_or_path"),Rya.forEach(t),Myt=r(rk,":"),rk.forEach(t),Eyt=i(_d),We=n(_d,"UL",{});var So=s(We);Jy=n(So,"LI",{});var ilo=s(Jy);yNe=n(ilo,"STRONG",{});var Pya=s(yNe);Cyt=r(Pya,"albert"),Pya.forEach(t),wyt=r(ilo," \u2014 "),Rce=n(ilo,"A",{href:!0});var Bya=s(Rce);Ayt=r(Bya,"FlaxAlbertForTokenClassification"),Bya.forEach(t),Lyt=r(ilo," (ALBERT model)"),ilo.forEach(t),yyt=i(So),Yy=n(So,"LI",{});var dlo=s(Yy);xNe=n(dlo,"STRONG",{});var Iya=s(xNe);xyt=r(Iya,"bert"),Iya.forEach(t),$yt=r(dlo," \u2014 "),Pce=n(dlo,"A",{href:!0});var Nya=s(Pce);kyt=r(Nya,"FlaxBertForTokenClassification"),Nya.forEach(t),Syt=r(dlo," (BERT model)"),dlo.forEach(t),Ryt=i(So),Zy=n(So,"LI",{});var mlo=s(Zy);$Ne=n(mlo,"STRONG",{});var qya=s($Ne);Pyt=r(qya,"big_bird"),qya.forEach(t),Byt=r(mlo," \u2014 "),Bce=n(mlo,"A",{href:!0});var jya=s(Bce);Iyt=r(jya,"FlaxBigBirdForTokenClassification"),jya.forEach(t),Nyt=r(mlo," (BigBird model)"),mlo.forEach(t),qyt=i(So),Ky=n(So,"LI",{});var clo=s(Ky);kNe=n(clo,"STRONG",{});var Dya=s(kNe);jyt=r(Dya,"distilbert"),Dya.forEach(t),Dyt=r(clo," \u2014 "),Ice=n(clo,"A",{href:!0});var Gya=s(Ice);Gyt=r(Gya,"FlaxDistilBertForTokenClassification"),Gya.forEach(t),Oyt=r(clo," (DistilBERT model)"),clo.forEach(t),Vyt=i(So),e9=n(So,"LI",{});var flo=s(e9);SNe=n(flo,"STRONG",{});var Oya=s(SNe);Xyt=r(Oya,"electra"),Oya.forEach(t),zyt=r(flo," \u2014 "),Nce=n(flo,"A",{href:!0});var Vya=s(Nce);Qyt=r(Vya,"FlaxElectraForTokenClassification"),Vya.forEach(t),Wyt=r(flo," (ELECTRA model)"),flo.forEach(t),Uyt=i(So),o9=n(So,"LI",{});var glo=s(o9);RNe=n(glo,"STRONG",{});var Xya=s(RNe);Hyt=r(Xya,"roberta"),Xya.forEach(t),Jyt=r(glo," \u2014 "),qce=n(glo,"A",{href:!0});var zya=s(qce);Yyt=r(zya,"FlaxRobertaForTokenClassification"),zya.forEach(t),Zyt=r(glo," (RoBERTa model)"),glo.forEach(t),Kyt=i(So),r9=n(So,"LI",{});var hlo=s(r9);PNe=n(hlo,"STRONG",{});var Qya=s(PNe);e9t=r(Qya,"roformer"),Qya.forEach(t),o9t=r(hlo," \u2014 "),jce=n(hlo,"A",{href:!0});var Wya=s(jce);r9t=r(Wya,"FlaxRoFormerForTokenClassification"),Wya.forEach(t),t9t=r(hlo," (RoFormer model)"),hlo.forEach(t),a9t=i(So),t9=n(So,"LI",{});var ulo=s(t9);BNe=n(ulo,"STRONG",{});var Uya=s(BNe);n9t=r(Uya,"xlm-roberta"),Uya.forEach(t),s9t=r(ulo," \u2014 "),Dce=n(ulo,"A",{href:!0});var Hya=s(Dce);l9t=r(Hya,"FlaxXLMRobertaForTokenClassification"),Hya.forEach(t),i9t=r(ulo," (XLM-RoBERTa model)"),ulo.forEach(t),So.forEach(t),d9t=i(_d),T(a9.$$.fragment,_d),_d.forEach(t),pd.forEach(t),jdo=i(c),jf=n(c,"H2",{class:!0});var mfo=s(jf);n9=n(mfo,"A",{id:!0,class:!0,href:!0});var Jya=s(n9);INe=n(Jya,"SPAN",{});var Yya=s(INe);T(DI.$$.fragment,Yya),Yya.forEach(t),Jya.forEach(t),m9t=i(mfo),NNe=n(mfo,"SPAN",{});var Zya=s(NNe);c9t=r(Zya,"FlaxAutoModelForMultipleChoice"),Zya.forEach(t),mfo.forEach(t),Ddo=i(c),qr=n(c,"DIV",{class:!0});var bd=s(qr);T(GI.$$.fragment,bd),f9t=i(bd),Df=n(bd,"P",{});var che=s(Df);g9t=r(che,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Gce=n(che,"A",{href:!0});var Kya=s(Gce);h9t=r(Kya,"from_pretrained()"),Kya.forEach(t),u9t=r(che," class method or the "),Oce=n(che,"A",{href:!0});var e9a=s(Oce);p9t=r(e9a,"from_config()"),e9a.forEach(t),_9t=r(che,` class
method.`),che.forEach(t),b9t=i(bd),OI=n(bd,"P",{});var cfo=s(OI);v9t=r(cfo,"This class cannot be instantiated directly using "),qNe=n(cfo,"CODE",{});var o9a=s(qNe);F9t=r(o9a,"__init__()"),o9a.forEach(t),T9t=r(cfo," (throws an error)."),cfo.forEach(t),M9t=i(bd),wa=n(bd,"DIV",{class:!0});var tk=s(wa);T(VI.$$.fragment,tk),E9t=i(tk),jNe=n(tk,"P",{});var r9a=s(jNe);C9t=r(r9a,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),r9a.forEach(t),w9t=i(tk),Gf=n(tk,"P",{});var fhe=s(Gf);A9t=r(fhe,`Note:
Loading a model from its configuration file does `),DNe=n(fhe,"STRONG",{});var t9a=s(DNe);L9t=r(t9a,"not"),t9a.forEach(t),y9t=r(fhe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Vce=n(fhe,"A",{href:!0});var a9a=s(Vce);x9t=r(a9a,"from_pretrained()"),a9a.forEach(t),$9t=r(fhe," to load the model weights."),fhe.forEach(t),k9t=i(tk),T(s9.$$.fragment,tk),tk.forEach(t),S9t=i(bd),ht=n(bd,"DIV",{class:!0});var vd=s(ht);T(XI.$$.fragment,vd),R9t=i(vd),GNe=n(vd,"P",{});var n9a=s(GNe);P9t=r(n9a,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),n9a.forEach(t),B9t=i(vd),cs=n(vd,"P",{});var ak=s(cs);I9t=r(ak,"The model class to instantiate is selected based on the "),ONe=n(ak,"CODE",{});var s9a=s(ONe);N9t=r(s9a,"model_type"),s9a.forEach(t),q9t=r(ak,` property of the config object (either
passed as an argument or loaded from `),VNe=n(ak,"CODE",{});var l9a=s(VNe);j9t=r(l9a,"pretrained_model_name_or_path"),l9a.forEach(t),D9t=r(ak,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),XNe=n(ak,"CODE",{});var i9a=s(XNe);G9t=r(i9a,"pretrained_model_name_or_path"),i9a.forEach(t),O9t=r(ak,":"),ak.forEach(t),V9t=i(vd),Ue=n(vd,"UL",{});var Ro=s(Ue);l9=n(Ro,"LI",{});var plo=s(l9);zNe=n(plo,"STRONG",{});var d9a=s(zNe);X9t=r(d9a,"albert"),d9a.forEach(t),z9t=r(plo," \u2014 "),Xce=n(plo,"A",{href:!0});var m9a=s(Xce);Q9t=r(m9a,"FlaxAlbertForMultipleChoice"),m9a.forEach(t),W9t=r(plo," (ALBERT model)"),plo.forEach(t),U9t=i(Ro),i9=n(Ro,"LI",{});var _lo=s(i9);QNe=n(_lo,"STRONG",{});var c9a=s(QNe);H9t=r(c9a,"bert"),c9a.forEach(t),J9t=r(_lo," \u2014 "),zce=n(_lo,"A",{href:!0});var f9a=s(zce);Y9t=r(f9a,"FlaxBertForMultipleChoice"),f9a.forEach(t),Z9t=r(_lo," (BERT model)"),_lo.forEach(t),K9t=i(Ro),d9=n(Ro,"LI",{});var blo=s(d9);WNe=n(blo,"STRONG",{});var g9a=s(WNe);ext=r(g9a,"big_bird"),g9a.forEach(t),oxt=r(blo," \u2014 "),Qce=n(blo,"A",{href:!0});var h9a=s(Qce);rxt=r(h9a,"FlaxBigBirdForMultipleChoice"),h9a.forEach(t),txt=r(blo," (BigBird model)"),blo.forEach(t),axt=i(Ro),m9=n(Ro,"LI",{});var vlo=s(m9);UNe=n(vlo,"STRONG",{});var u9a=s(UNe);nxt=r(u9a,"distilbert"),u9a.forEach(t),sxt=r(vlo," \u2014 "),Wce=n(vlo,"A",{href:!0});var p9a=s(Wce);lxt=r(p9a,"FlaxDistilBertForMultipleChoice"),p9a.forEach(t),ixt=r(vlo," (DistilBERT model)"),vlo.forEach(t),dxt=i(Ro),c9=n(Ro,"LI",{});var Flo=s(c9);HNe=n(Flo,"STRONG",{});var _9a=s(HNe);mxt=r(_9a,"electra"),_9a.forEach(t),cxt=r(Flo," \u2014 "),Uce=n(Flo,"A",{href:!0});var b9a=s(Uce);fxt=r(b9a,"FlaxElectraForMultipleChoice"),b9a.forEach(t),gxt=r(Flo," (ELECTRA model)"),Flo.forEach(t),hxt=i(Ro),f9=n(Ro,"LI",{});var Tlo=s(f9);JNe=n(Tlo,"STRONG",{});var v9a=s(JNe);uxt=r(v9a,"roberta"),v9a.forEach(t),pxt=r(Tlo," \u2014 "),Hce=n(Tlo,"A",{href:!0});var F9a=s(Hce);_xt=r(F9a,"FlaxRobertaForMultipleChoice"),F9a.forEach(t),bxt=r(Tlo," (RoBERTa model)"),Tlo.forEach(t),vxt=i(Ro),g9=n(Ro,"LI",{});var Mlo=s(g9);YNe=n(Mlo,"STRONG",{});var T9a=s(YNe);Fxt=r(T9a,"roformer"),T9a.forEach(t),Txt=r(Mlo," \u2014 "),Jce=n(Mlo,"A",{href:!0});var M9a=s(Jce);Mxt=r(M9a,"FlaxRoFormerForMultipleChoice"),M9a.forEach(t),Ext=r(Mlo," (RoFormer model)"),Mlo.forEach(t),Cxt=i(Ro),h9=n(Ro,"LI",{});var Elo=s(h9);ZNe=n(Elo,"STRONG",{});var E9a=s(ZNe);wxt=r(E9a,"xlm-roberta"),E9a.forEach(t),Axt=r(Elo," \u2014 "),Yce=n(Elo,"A",{href:!0});var C9a=s(Yce);Lxt=r(C9a,"FlaxXLMRobertaForMultipleChoice"),C9a.forEach(t),yxt=r(Elo," (XLM-RoBERTa model)"),Elo.forEach(t),Ro.forEach(t),xxt=i(vd),T(u9.$$.fragment,vd),vd.forEach(t),bd.forEach(t),Gdo=i(c),Of=n(c,"H2",{class:!0});var ffo=s(Of);p9=n(ffo,"A",{id:!0,class:!0,href:!0});var w9a=s(p9);KNe=n(w9a,"SPAN",{});var A9a=s(KNe);T(zI.$$.fragment,A9a),A9a.forEach(t),w9a.forEach(t),$xt=i(ffo),eqe=n(ffo,"SPAN",{});var L9a=s(eqe);kxt=r(L9a,"FlaxAutoModelForNextSentencePrediction"),L9a.forEach(t),ffo.forEach(t),Odo=i(c),jr=n(c,"DIV",{class:!0});var Fd=s(jr);T(QI.$$.fragment,Fd),Sxt=i(Fd),Vf=n(Fd,"P",{});var ghe=s(Vf);Rxt=r(ghe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Zce=n(ghe,"A",{href:!0});var y9a=s(Zce);Pxt=r(y9a,"from_pretrained()"),y9a.forEach(t),Bxt=r(ghe," class method or the "),Kce=n(ghe,"A",{href:!0});var x9a=s(Kce);Ixt=r(x9a,"from_config()"),x9a.forEach(t),Nxt=r(ghe,` class
method.`),ghe.forEach(t),qxt=i(Fd),WI=n(Fd,"P",{});var gfo=s(WI);jxt=r(gfo,"This class cannot be instantiated directly using "),oqe=n(gfo,"CODE",{});var $9a=s(oqe);Dxt=r($9a,"__init__()"),$9a.forEach(t),Gxt=r(gfo," (throws an error)."),gfo.forEach(t),Oxt=i(Fd),Aa=n(Fd,"DIV",{class:!0});var nk=s(Aa);T(UI.$$.fragment,nk),Vxt=i(nk),rqe=n(nk,"P",{});var k9a=s(rqe);Xxt=r(k9a,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),k9a.forEach(t),zxt=i(nk),Xf=n(nk,"P",{});var hhe=s(Xf);Qxt=r(hhe,`Note:
Loading a model from its configuration file does `),tqe=n(hhe,"STRONG",{});var S9a=s(tqe);Wxt=r(S9a,"not"),S9a.forEach(t),Uxt=r(hhe,` load the model weights. It only affects the
model\u2019s configuration. Use `),efe=n(hhe,"A",{href:!0});var R9a=s(efe);Hxt=r(R9a,"from_pretrained()"),R9a.forEach(t),Jxt=r(hhe," to load the model weights."),hhe.forEach(t),Yxt=i(nk),T(_9.$$.fragment,nk),nk.forEach(t),Zxt=i(Fd),ut=n(Fd,"DIV",{class:!0});var Td=s(ut);T(HI.$$.fragment,Td),Kxt=i(Td),aqe=n(Td,"P",{});var P9a=s(aqe);e$t=r(P9a,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),P9a.forEach(t),o$t=i(Td),fs=n(Td,"P",{});var sk=s(fs);r$t=r(sk,"The model class to instantiate is selected based on the "),nqe=n(sk,"CODE",{});var B9a=s(nqe);t$t=r(B9a,"model_type"),B9a.forEach(t),a$t=r(sk,` property of the config object (either
passed as an argument or loaded from `),sqe=n(sk,"CODE",{});var I9a=s(sqe);n$t=r(I9a,"pretrained_model_name_or_path"),I9a.forEach(t),s$t=r(sk,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lqe=n(sk,"CODE",{});var N9a=s(lqe);l$t=r(N9a,"pretrained_model_name_or_path"),N9a.forEach(t),i$t=r(sk,":"),sk.forEach(t),d$t=i(Td),iqe=n(Td,"UL",{});var q9a=s(iqe);b9=n(q9a,"LI",{});var Clo=s(b9);dqe=n(Clo,"STRONG",{});var j9a=s(dqe);m$t=r(j9a,"bert"),j9a.forEach(t),c$t=r(Clo," \u2014 "),ofe=n(Clo,"A",{href:!0});var D9a=s(ofe);f$t=r(D9a,"FlaxBertForNextSentencePrediction"),D9a.forEach(t),g$t=r(Clo," (BERT model)"),Clo.forEach(t),q9a.forEach(t),h$t=i(Td),T(v9.$$.fragment,Td),Td.forEach(t),Fd.forEach(t),Vdo=i(c),zf=n(c,"H2",{class:!0});var hfo=s(zf);F9=n(hfo,"A",{id:!0,class:!0,href:!0});var G9a=s(F9);mqe=n(G9a,"SPAN",{});var O9a=s(mqe);T(JI.$$.fragment,O9a),O9a.forEach(t),G9a.forEach(t),u$t=i(hfo),cqe=n(hfo,"SPAN",{});var V9a=s(cqe);p$t=r(V9a,"FlaxAutoModelForImageClassification"),V9a.forEach(t),hfo.forEach(t),Xdo=i(c),Dr=n(c,"DIV",{class:!0});var Md=s(Dr);T(YI.$$.fragment,Md),_$t=i(Md),Qf=n(Md,"P",{});var uhe=s(Qf);b$t=r(uhe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),rfe=n(uhe,"A",{href:!0});var X9a=s(rfe);v$t=r(X9a,"from_pretrained()"),X9a.forEach(t),F$t=r(uhe," class method or the "),tfe=n(uhe,"A",{href:!0});var z9a=s(tfe);T$t=r(z9a,"from_config()"),z9a.forEach(t),M$t=r(uhe,` class
method.`),uhe.forEach(t),E$t=i(Md),ZI=n(Md,"P",{});var ufo=s(ZI);C$t=r(ufo,"This class cannot be instantiated directly using "),fqe=n(ufo,"CODE",{});var Q9a=s(fqe);w$t=r(Q9a,"__init__()"),Q9a.forEach(t),A$t=r(ufo," (throws an error)."),ufo.forEach(t),L$t=i(Md),La=n(Md,"DIV",{class:!0});var lk=s(La);T(KI.$$.fragment,lk),y$t=i(lk),gqe=n(lk,"P",{});var W9a=s(gqe);x$t=r(W9a,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),W9a.forEach(t),$$t=i(lk),Wf=n(lk,"P",{});var phe=s(Wf);k$t=r(phe,`Note:
Loading a model from its configuration file does `),hqe=n(phe,"STRONG",{});var U9a=s(hqe);S$t=r(U9a,"not"),U9a.forEach(t),R$t=r(phe,` load the model weights. It only affects the
model\u2019s configuration. Use `),afe=n(phe,"A",{href:!0});var H9a=s(afe);P$t=r(H9a,"from_pretrained()"),H9a.forEach(t),B$t=r(phe," to load the model weights."),phe.forEach(t),I$t=i(lk),T(T9.$$.fragment,lk),lk.forEach(t),N$t=i(Md),pt=n(Md,"DIV",{class:!0});var Ed=s(pt);T(eN.$$.fragment,Ed),q$t=i(Ed),uqe=n(Ed,"P",{});var J9a=s(uqe);j$t=r(J9a,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),J9a.forEach(t),D$t=i(Ed),gs=n(Ed,"P",{});var ik=s(gs);G$t=r(ik,"The model class to instantiate is selected based on the "),pqe=n(ik,"CODE",{});var Y9a=s(pqe);O$t=r(Y9a,"model_type"),Y9a.forEach(t),V$t=r(ik,` property of the config object (either
passed as an argument or loaded from `),_qe=n(ik,"CODE",{});var Z9a=s(_qe);X$t=r(Z9a,"pretrained_model_name_or_path"),Z9a.forEach(t),z$t=r(ik,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bqe=n(ik,"CODE",{});var K9a=s(bqe);Q$t=r(K9a,"pretrained_model_name_or_path"),K9a.forEach(t),W$t=r(ik,":"),ik.forEach(t),U$t=i(Ed),oN=n(Ed,"UL",{});var pfo=s(oN);M9=n(pfo,"LI",{});var wlo=s(M9);vqe=n(wlo,"STRONG",{});var exa=s(vqe);H$t=r(exa,"beit"),exa.forEach(t),J$t=r(wlo," \u2014 "),nfe=n(wlo,"A",{href:!0});var oxa=s(nfe);Y$t=r(oxa,"FlaxBeitForImageClassification"),oxa.forEach(t),Z$t=r(wlo," (BEiT model)"),wlo.forEach(t),K$t=i(pfo),E9=n(pfo,"LI",{});var Alo=s(E9);Fqe=n(Alo,"STRONG",{});var rxa=s(Fqe);ekt=r(rxa,"vit"),rxa.forEach(t),okt=r(Alo," \u2014 "),sfe=n(Alo,"A",{href:!0});var txa=s(sfe);rkt=r(txa,"FlaxViTForImageClassification"),txa.forEach(t),tkt=r(Alo," (ViT model)"),Alo.forEach(t),pfo.forEach(t),akt=i(Ed),T(C9.$$.fragment,Ed),Ed.forEach(t),Md.forEach(t),zdo=i(c),Uf=n(c,"H2",{class:!0});var _fo=s(Uf);w9=n(_fo,"A",{id:!0,class:!0,href:!0});var axa=s(w9);Tqe=n(axa,"SPAN",{});var nxa=s(Tqe);T(rN.$$.fragment,nxa),nxa.forEach(t),axa.forEach(t),nkt=i(_fo),Mqe=n(_fo,"SPAN",{});var sxa=s(Mqe);skt=r(sxa,"FlaxAutoModelForVision2Seq"),sxa.forEach(t),_fo.forEach(t),Qdo=i(c),Gr=n(c,"DIV",{class:!0});var Cd=s(Gr);T(tN.$$.fragment,Cd),lkt=i(Cd),Hf=n(Cd,"P",{});var _he=s(Hf);ikt=r(_he,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),lfe=n(_he,"A",{href:!0});var lxa=s(lfe);dkt=r(lxa,"from_pretrained()"),lxa.forEach(t),mkt=r(_he," class method or the "),ife=n(_he,"A",{href:!0});var ixa=s(ife);ckt=r(ixa,"from_config()"),ixa.forEach(t),fkt=r(_he,` class
method.`),_he.forEach(t),gkt=i(Cd),aN=n(Cd,"P",{});var bfo=s(aN);hkt=r(bfo,"This class cannot be instantiated directly using "),Eqe=n(bfo,"CODE",{});var dxa=s(Eqe);ukt=r(dxa,"__init__()"),dxa.forEach(t),pkt=r(bfo," (throws an error)."),bfo.forEach(t),_kt=i(Cd),ya=n(Cd,"DIV",{class:!0});var dk=s(ya);T(nN.$$.fragment,dk),bkt=i(dk),Cqe=n(dk,"P",{});var mxa=s(Cqe);vkt=r(mxa,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),mxa.forEach(t),Fkt=i(dk),Jf=n(dk,"P",{});var bhe=s(Jf);Tkt=r(bhe,`Note:
Loading a model from its configuration file does `),wqe=n(bhe,"STRONG",{});var cxa=s(wqe);Mkt=r(cxa,"not"),cxa.forEach(t),Ekt=r(bhe,` load the model weights. It only affects the
model\u2019s configuration. Use `),dfe=n(bhe,"A",{href:!0});var fxa=s(dfe);Ckt=r(fxa,"from_pretrained()"),fxa.forEach(t),wkt=r(bhe," to load the model weights."),bhe.forEach(t),Akt=i(dk),T(A9.$$.fragment,dk),dk.forEach(t),Lkt=i(Cd),_t=n(Cd,"DIV",{class:!0});var wd=s(_t);T(sN.$$.fragment,wd),ykt=i(wd),Aqe=n(wd,"P",{});var gxa=s(Aqe);xkt=r(gxa,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),gxa.forEach(t),$kt=i(wd),hs=n(wd,"P",{});var mk=s(hs);kkt=r(mk,"The model class to instantiate is selected based on the "),Lqe=n(mk,"CODE",{});var hxa=s(Lqe);Skt=r(hxa,"model_type"),hxa.forEach(t),Rkt=r(mk,` property of the config object (either
passed as an argument or loaded from `),yqe=n(mk,"CODE",{});var uxa=s(yqe);Pkt=r(uxa,"pretrained_model_name_or_path"),uxa.forEach(t),Bkt=r(mk,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xqe=n(mk,"CODE",{});var pxa=s(xqe);Ikt=r(pxa,"pretrained_model_name_or_path"),pxa.forEach(t),Nkt=r(mk,":"),mk.forEach(t),qkt=i(wd),$qe=n(wd,"UL",{});var _xa=s($qe);L9=n(_xa,"LI",{});var Llo=s(L9);kqe=n(Llo,"STRONG",{});var bxa=s(kqe);jkt=r(bxa,"vision-encoder-decoder"),bxa.forEach(t),Dkt=r(Llo," \u2014 "),mfe=n(Llo,"A",{href:!0});var vxa=s(mfe);Gkt=r(vxa,"FlaxVisionEncoderDecoderModel"),vxa.forEach(t),Okt=r(Llo," (Vision Encoder decoder model)"),Llo.forEach(t),_xa.forEach(t),Vkt=i(wd),T(y9.$$.fragment,wd),wd.forEach(t),Cd.forEach(t),this.h()},h(){d(g,"name","hf:doc:metadata"),d(g,"content",JSON.stringify(jka)),d(f,"id","auto-classes"),d(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(f,"href","#auto-classes"),d(u,"class","relative group"),d(ps,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig"),d(bs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel"),d(vs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),d(Sd,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),d(ag,"id","extending-the-auto-classes"),d(ag,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ag,"href","#extending-the-auto-classes"),d(Rd,"class","relative group"),d(sg,"id","transformers.AutoConfig"),d(sg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(sg,"href","#transformers.AutoConfig"),d(Pd,"class","relative group"),d(Gq,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),d(Oq,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig"),d(Vq,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartConfig"),d(Xq,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig"),d(zq,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertConfig"),d(Qq,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig"),d(Wq,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig"),d(Uq,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),d(Hq,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig"),d(Jq,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),d(Yq,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig"),d(Zq,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig"),d(Kq,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig"),d(ej,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig"),d(oj,"href","/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegConfig"),d(rj,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig"),d(tj,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig"),d(aj,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig"),d(nj,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig"),d(sj,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig"),d(lj,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig"),d(ij,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),d(dj,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig"),d(mj,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),d(cj,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig"),d(fj,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config"),d(gj,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),d(hj,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig"),d(uj,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig"),d(pj,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig"),d(_j,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig"),d(bj,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig"),d(vj,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig"),d(Fj,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig"),d(Tj,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig"),d(Mj,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),d(Ej,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig"),d(Cj,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig"),d(wj,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig"),d(Aj,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig"),d(Lj,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig"),d(yj,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig"),d(xj,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig"),d($j,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig"),d(kj,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config"),d(Sj,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),d(Rj,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),d(Pj,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig"),d(Bj,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig"),d(Ij,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig"),d(Nj,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig"),d(qj,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig"),d(jj,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig"),d(Dj,"href","/docs/transformers/main/en/model_doc/jukebox#transformers.JukeboxConfig"),d(Gj,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig"),d(Oj,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),d(Vj,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),d(Xj,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDConfig"),d(zj,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig"),d(Qj,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig"),d(Wj,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig"),d(Uj,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config"),d(Hj,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig"),d(Jj,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig"),d(Yj,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config"),d(Zj,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig"),d(Kj,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig"),d(eD,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig"),d(oD,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig"),d(rD,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig"),d(tD,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),d(aD,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig"),d(nD,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig"),d(sD,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig"),d(lD,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config"),d(iD,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig"),d(dD,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig"),d(mD,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig"),d(cD,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),d(fD,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig"),d(gD,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig"),d(hD,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig"),d(uD,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig"),d(pD,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig"),d(_D,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig"),d(bD,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig"),d(vD,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig"),d(FD,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig"),d(TD,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagConfig"),d(MD,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmConfig"),d(ED,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig"),d(CD,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig"),d(wD,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig"),d(AD,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig"),d(LD,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig"),d(yD,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig"),d(xD,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig"),d($D,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig"),d(kD,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig"),d(SD,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig"),d(RD,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig"),d(PD,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),d(BD,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),d(ID,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),d(ND,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig"),d(qD,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),d(jD,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig"),d(DD,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config"),d(GD,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Config"),d(OD,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig"),d(VD,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig"),d(XD,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig"),d(zD,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),d(QD,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),d(WD,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig"),d(UD,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig"),d(HD,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),d(JD,"href","/docs/transformers/main/en/model_doc/van#transformers.VanConfig"),d(YD,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig"),d(ZD,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig"),d(KD,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),d(eG,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),d(oG,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig"),d(rG,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig"),d(tG,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig"),d(aG,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig"),d(nG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),d(sG,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),d(lG,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig"),d(iG,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig"),d(dG,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig"),d(mG,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig"),d(cG,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig"),d(fG,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),d(gG,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),d(hG,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),d(uG,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig"),d(pG,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig"),d(_G,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig"),d(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qu,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ju,"id","transformers.AutoTokenizer"),d(ju,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ju,"href","#transformers.AutoTokenizer"),d(Id,"class","relative group"),d(bG,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),d(vG,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),d(FG,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),d(TG,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizer"),d(MG,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizerFast"),d(EG,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizer"),d(CG,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizerFast"),d(wG,"href","/docs/transformers/main/en/model_doc/bartpho#transformers.BartphoTokenizer"),d(AG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(LG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(yG,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),d(xG,"href","/docs/transformers/main/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),d($G,"href","/docs/transformers/main/en/model_doc/bertweet#transformers.BertweetTokenizer"),d(kG,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizer"),d(SG,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),d(RG,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),d(PG,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),d(BG,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),d(IG,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),d(NG,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),d(qG,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomTokenizerFast"),d(jG,"href","/docs/transformers/main/en/model_doc/byt5#transformers.ByT5Tokenizer"),d(DG,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizer"),d(GG,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizerFast"),d(OG,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineTokenizer"),d(VG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(XG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(zG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(QG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(WG,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizer"),d(UG,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),d(HG,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizer"),d(JG,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),d(YG,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizer"),d(ZG,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizerFast"),d(KG,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLTokenizer"),d(eO,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),d(oO,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(rO,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizer"),d(tO,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizerFast"),d(aO,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),d(nO,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),d(sO,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizer"),d(lO,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),d(iO,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),d(dO,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),d(mO,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizer"),d(cO,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizerFast"),d(fO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(gO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(hO,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmTokenizer"),d(uO,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertTokenizer"),d(pO,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizer"),d(_O,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizerFast"),d(bO,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTTokenizer"),d(vO,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizer"),d(FO,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizerFast"),d(TO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(MO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d(EO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(CO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d(wO,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),d(AO,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseTokenizer"),d(LO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(yO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d(xO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d($O,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(kO,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizer"),d(SO,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizerFast"),d(RO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d(PO,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),d(BO,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(IO,"href","/docs/transformers/main/en/model_doc/jukebox#transformers.JukeboxTokenizer"),d(NO,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),d(qO,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),d(jO,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),d(DO,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),d(GO,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),d(OO,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),d(VO,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),d(XO,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),d(zO,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizer"),d(QO,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizerFast"),d(WO,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),d(UO,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),d(HO,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizer"),d(JO,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizerFast"),d(YO,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),d(ZO,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),d(KO,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeTokenizer"),d(eV,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizer"),d(oV,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),d(rV,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),d(tV,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianTokenizer"),d(aV,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizer"),d(nV,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizerFast"),d(sV,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50Tokenizer"),d(lV,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50TokenizerFast"),d(iV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(dV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(mV,"href","/docs/transformers/main/en/model_doc/mluke#transformers.MLukeTokenizer"),d(cV,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),d(fV,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),d(gV,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizer"),d(hV,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),d(uV,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),d(pV,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),d(_V,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizer"),d(bV,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizerFast"),d(vV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(FV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(TV,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizer"),d(MV,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizerFast"),d(EV,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),d(CV,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),d(wV,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),d(AV,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),d(LV,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(yV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(xV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d($V,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),d(kV,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),d(SV,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),d(RV,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),d(PV,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverTokenizer"),d(BV,"href","/docs/transformers/main/en/model_doc/phobert#transformers.PhobertTokenizer"),d(IV,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartTokenizer"),d(NV,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),d(qV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(jV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(DV,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagTokenizer"),d(GV,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizer"),d(OV,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizerFast"),d(VV,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizer"),d(XV,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizerFast"),d(zV,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizer"),d(QV,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizerFast"),d(WV,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizer"),d(UV,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),d(HV,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),d(JV,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(YV,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertTokenizer"),d(ZV,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizer"),d(KV,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),d(eX,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),d(oX,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),d(rX,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizer"),d(tX,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizerFast"),d(aX,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),d(nX,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),d(sX,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),d(lX,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),d(iX,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasTokenizer"),d(dX,"href","/docs/transformers/main/en/model_doc/tapex#transformers.TapexTokenizer"),d(mX,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),d(cX,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(fX,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(gX,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(hX,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(uX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d(pX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d(_X,"href","/docs/transformers/main/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),d(bX,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperTokenizer"),d(vX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(FX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(TX,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizer"),d(MX,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizerFast"),d(EX,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMTokenizer"),d(CX,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),d(wX,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),d(AX,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),d(LX,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),d(yX,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),d(xX,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizer"),d($X,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),d(kX,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),d(SX,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),d(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(wp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ap,"id","transformers.AutoFeatureExtractor"),d(Ap,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ap,"href","#transformers.AutoFeatureExtractor"),d(Nd,"class","relative group"),d(RX,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),d(PX,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitImageProcessor"),d(BX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPImageProcessor"),d(IX,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(NX,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrFeatureExtractor"),d(qX,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(jX,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(DX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(GX,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitImageProcessor"),d(OX,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrFeatureExtractor"),d(VX,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTImageProcessor"),d(XX,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),d(zX,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutFeatureExtractor"),d(QX,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTImageProcessor"),d(WX,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaImageProcessor"),d(UX,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNImageProcessor"),d(HX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPImageProcessor"),d(JX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(YX,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTImageProcessor"),d(ZX,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ImageProcessor"),d(KX,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor"),d(ez,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitImageProcessor"),d(oz,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),d(rz,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),d(tz,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTImageProcessor"),d(az,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor"),d(nz,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverImageProcessor"),d(sz,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerImageProcessor"),d(lz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(iz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(dz,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerImageProcessor"),d(mz,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),d(cz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(fz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(gz,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),d(hz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(uz,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEImageProcessor"),d(pz,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltImageProcessor"),d(_z,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(bz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(vz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(Fz,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(Tz,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(Mz,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperFeatureExtractor"),d(Ez,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPImageProcessor"),d(Cz,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosFeatureExtractor"),d(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(F_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(T_,"id","transformers.AutoImageProcessor"),d(T_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(T_,"href","#transformers.AutoImageProcessor"),d(qd,"class","relative group"),d(wz,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoImageProcessor.from_pretrained"),d(Az,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitImageProcessor"),d(Lz,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPImageProcessor"),d(yz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(xz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d($z,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitImageProcessor"),d(kz,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTImageProcessor"),d(Sz,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTImageProcessor"),d(Rz,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaImageProcessor"),d(Pz,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNImageProcessor"),d(Bz,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPImageProcessor"),d(Iz,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTImageProcessor"),d(Nz,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ImageProcessor"),d(qz,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor"),d(jz,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitImageProcessor"),d(Dz,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTImageProcessor"),d(Gz,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverImageProcessor"),d(Oz,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerImageProcessor"),d(Vz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(Xz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(zz,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerImageProcessor"),d(Qz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(Wz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(Uz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(Hz,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEImageProcessor"),d(Jz,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltImageProcessor"),d(Yz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(Zz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(Kz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(eQ,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPImageProcessor"),d(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(K_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(e1,"id","transformers.AutoProcessor"),d(e1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(e1,"href","#transformers.AutoProcessor"),d(jd,"class","relative group"),d(oQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),d(rQ,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),d(tQ,"href","/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegProcessor"),d(aQ,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaProcessor"),d(nQ,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),d(sQ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),d(lQ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),d(iQ,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),d(dQ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMProcessor"),d(mQ,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTProcessor"),d(cQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(fQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(gQ,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),d(hQ,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),d(uQ,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRProcessor"),d(pQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(_Q,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(bQ,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltProcessor"),d(vQ,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),d(FQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(TQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(MQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(EQ,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperProcessor"),d(CQ,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPProcessor"),d(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(A1,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(L1,"id","transformers.AutoModel"),d(L1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(L1,"href","#transformers.AutoModel"),d(Gd,"class","relative group"),d(wQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(AQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(LQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(yQ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel"),d(xQ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartModel"),d($Q,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitModel"),d(kQ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),d(SQ,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),d(RQ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel"),d(PQ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),d(BQ,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel"),d(IQ,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),d(NQ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel"),d(qQ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel"),d(jQ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineModel"),d(DQ,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel"),d(GQ,"href","/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegModel"),d(OQ,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel"),d(VQ,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel"),d(XQ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel"),d(zQ,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel"),d(QQ,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel"),d(WQ,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel"),d(UQ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel"),d(HQ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel"),d(JQ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel"),d(YQ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel"),d(ZQ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model"),d(KQ,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),d(eW,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel"),d(oW,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel"),d(rW,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrModel"),d(tW,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel"),d(aW,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel"),d(nW,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder"),d(sW,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel"),d(lW,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel"),d(iW,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel"),d(dW,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmModel"),d(mW,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel"),d(cW,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel"),d(fW,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel"),d(gW,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel"),d(hW,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel"),d(uW,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel"),d(pW,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel"),d(_W,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model"),d(bW,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel"),d(vW,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),d(FW,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel"),d(TW,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel"),d(MW,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel"),d(EW,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel"),d(CW,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel"),d(wW,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel"),d(AW,"href","/docs/transformers/main/en/model_doc/jukebox#transformers.JukeboxModel"),d(LW,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel"),d(yW,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),d(xW,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),d($W,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDModel"),d(kW,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitModel"),d(SW,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltModel"),d(RW,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel"),d(PW,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model"),d(BW,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeModel"),d(IW,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel"),d(NW,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),d(qW,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianModel"),d(jW,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel"),d(DW,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel"),d(GW,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel"),d(OW,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel"),d(VW,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel"),d(XW,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel"),d(zW,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel"),d(QW,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel"),d(WW,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model"),d(UW,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel"),d(HW,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel"),d(JW,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),d(YW,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel"),d(ZW,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),d(KW,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTModel"),d(eU,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel"),d(oU,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel"),d(rU,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel"),d(tU,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel"),d(aU,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel"),d(nU,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel"),d(sU,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel"),d(lU,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel"),d(iU,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel"),d(dU,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel"),d(mU,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel"),d(cU,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel"),d(fU,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),d(gU,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel"),d(hU,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertModel"),d(uU,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel"),d(pU,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel"),d(_U,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWModel"),d(bU,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel"),d(vU,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel"),d(FU,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel"),d(TU,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel"),d(MU,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinModel"),d(EU,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model"),d(CU,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Model"),d(wU,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerModel"),d(AU,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel"),d(LU,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel"),d(yU,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),d(xU,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel"),d($U,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel"),d(kU,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),d(SU,"href","/docs/transformers/main/en/model_doc/van#transformers.VanModel"),d(RU,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel"),d(PU,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel"),d(BU,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),d(IU,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel"),d(NU,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTModel"),d(qU,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel"),d(jU,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel"),d(DU,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),d(GU,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),d(OU,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel"),d(VU,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel"),d(XU,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel"),d(zU,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel"),d(QU,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel"),d(WU,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),d(UU,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),d(HU,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),d(JU,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel"),d(YU,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel"),d(ZU,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel"),d(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ev,"id","transformers.AutoModelForPreTraining"),d(ev,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ev,"href","#transformers.AutoModelForPreTraining"),d(Xd,"class","relative group"),d(KU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(eH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(oH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(rH,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining"),d(tH,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(aH,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining"),d(nH,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),d(sH,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),d(lH,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),d(iH,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),d(dH,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),d(mH,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),d(cH,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),d(fH,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),d(gH,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining"),d(hH,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining"),d(uH,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),d(pH,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining"),d(_H,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining"),d(bH,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),d(vH,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining"),d(FH,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),d(TH,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),d(MH,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),d(EH,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),d(CH,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),d(wH,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining"),d(AH,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),d(LH,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),d(yH,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),d(xH,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),d($H,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining"),d(kH,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),d(SH,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),d(RH,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),d(PH,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForPreTraining"),d(BH,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining"),d(IH,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),d(NH,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),d(qH,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),d(jH,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),d(DH,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),d(GH,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),d(OH,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining"),d(VH,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),d(XH,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),d(zH,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),d(QH,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),d(WH,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(UH,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),d(HH,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),d(JH,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),d(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Kv,"id","transformers.AutoModelForCausalLM"),d(Kv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Kv,"href","#transformers.AutoModelForCausalLM"),d(Wd,"class","relative group"),d(YH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ZH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(KH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(eJ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM"),d(oJ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel"),d(rJ,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),d(tJ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),d(aJ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),d(nJ,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),d(sJ,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),d(lJ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),d(iJ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM"),d(dJ,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM"),d(mJ,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),d(cJ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),d(fJ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM"),d(gJ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM"),d(hJ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),d(uJ,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),d(pJ,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),d(_J,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM"),d(bJ,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM"),d(vJ,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM"),d(FJ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM"),d(TJ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),d(MJ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM"),d(EJ,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),d(CJ,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM"),d(wJ,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM"),d(AJ,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM"),d(LJ,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),d(yJ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),d(xJ,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),d($J,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM"),d(kJ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM"),d(SJ,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForCausalLM"),d(RJ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM"),d(PJ,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),d(BJ,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),d(IJ,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM"),d(NJ,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM"),d(qJ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(jJ,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),d(DJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),d(GJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),d(OJ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),d(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(QF,"id","transformers.AutoModelForDepthEstimation"),d(QF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(QF,"href","#transformers.AutoModelForDepthEstimation"),d(Jd,"class","relative group"),d(VJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(XJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(zJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(QJ,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForDepthEstimation"),d(WJ,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNForDepthEstimation"),d(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ZF,"id","transformers.AutoModelForMaskedLM"),d(ZF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ZF,"href","#transformers.AutoModelForMaskedLM"),d(Kd,"class","relative group"),d(UJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(HJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(JJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(YJ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM"),d(ZJ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(KJ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM"),d(eY,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),d(oY,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),d(rY,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),d(tY,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),d(aY,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),d(nY,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),d(sY,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),d(lY,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM"),d(iY,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM"),d(dY,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),d(mY,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM"),d(cY,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM"),d(fY,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),d(gY,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),d(hY,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),d(uY,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),d(pY,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),d(_Y,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),d(bY,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),d(vY,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),d(FY,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),d(TY,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM"),d(MY,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),d(EY,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),d(CY,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),d(wY,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM"),d(AY,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM"),d(LY,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),d(yY,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForMaskedLM"),d(xY,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),d($Y,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),d(kY,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),d(SY,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(RY,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),d(PY,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),d(BY,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM"),d(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(OT,"id","transformers.AutoModelForSeq2SeqLM"),d(OT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(OT,"href","#transformers.AutoModelForSeq2SeqLM"),d(rm,"class","relative group"),d(IY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(NY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(qY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(jY,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(DY,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),d(GY,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),d(OY,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),d(VY,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),d(XY,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),d(zY,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration"),d(QY,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),d(WY,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),d(UY,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel"),d(HY,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),d(JY,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),d(YY,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),d(ZY,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),d(KY,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),d(eZ,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration"),d(oZ,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),d(rZ,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),d(tZ,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),d(aZ,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),d(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(fM,"id","transformers.AutoModelForSequenceClassification"),d(fM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(fM,"href","#transformers.AutoModelForSequenceClassification"),d(nm,"class","relative group"),d(nZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(sZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(lZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(iZ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification"),d(dZ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification"),d(mZ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification"),d(cZ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),d(fZ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),d(gZ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification"),d(hZ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),d(uZ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification"),d(pZ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),d(_Z,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),d(bZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),d(vZ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),d(FZ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),d(TZ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),d(MZ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification"),d(EZ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification"),d(CZ,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification"),d(wZ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),d(AZ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification"),d(LZ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),d(yZ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),d(xZ,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),d($Z,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),d(kZ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification"),d(SZ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),d(RZ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),d(PZ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),d(BZ,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification"),d(IZ,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForSequenceClassification"),d(NZ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),d(qZ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification"),d(jZ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification"),d(DZ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification"),d(GZ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),d(OZ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),d(VZ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),d(XZ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification"),d(zZ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),d(QZ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),d(WZ,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),d(UZ,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification"),d(HZ,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),d(JZ,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),d(YZ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),d(ZZ,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),d(KZ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),d(eK,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),d(oK,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForSequenceClassification"),d(rK,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),d(tK,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),d(aK,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification"),d(nK,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),d(sK,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification"),d(lK,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),d(iK,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),d(dK,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),d(mK,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification"),d(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(vE,"id","transformers.AutoModelForMultipleChoice"),d(vE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(vE,"href","#transformers.AutoModelForMultipleChoice"),d(im,"class","relative group"),d(cK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(fK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(gK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(hK,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice"),d(uK,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice"),d(pK,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),d(_K,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),d(bK,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice"),d(vK,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),d(FK,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),d(TK,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),d(MK,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),d(EK,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice"),d(CK,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice"),d(wK,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),d(AK,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice"),d(LK,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),d(yK,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice"),d(xK,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),d($K,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice"),d(kK,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),d(SK,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),d(RK,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),d(PK,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),d(BK,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),d(IK,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),d(NK,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),d(qK,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),d(jK,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForMultipleChoice"),d(DK,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),d(GK,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),d(OK,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice"),d(VK,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),d(XK,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),d(zK,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),d(QK,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice"),d(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(r4,"id","transformers.AutoModelForNextSentencePrediction"),d(r4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(r4,"href","#transformers.AutoModelForNextSentencePrediction"),d(cm,"class","relative group"),d(WK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(UK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(HK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(JK,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction"),d(YK,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction"),d(ZK,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),d(KK,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),d(eee,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),d(oee,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),d(ree,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),d(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(g4,"id","transformers.AutoModelForTokenClassification"),d(g4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(g4,"href","#transformers.AutoModelForTokenClassification"),d(hm,"class","relative group"),d(tee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(aee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(nee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(see,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification"),d(lee,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification"),d(iee,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),d(dee,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification"),d(mee,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification"),d(cee,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification"),d(fee,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),d(gee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),d(hee,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification"),d(uee,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),d(pee,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),d(_ee,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification"),d(bee,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification"),d(vee,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification"),d(Fee,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),d(Tee,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification"),d(Mee,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification"),d(Eee,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),d(Cee,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification"),d(wee,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),d(Aee,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),d(Lee,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),d(yee,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForTokenClassification"),d(xee,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification"),d($ee,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification"),d(kee,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification"),d(See,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),d(Ree,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),d(Pee,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),d(Bee,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification"),d(Iee,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),d(Nee,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),d(qee,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification"),d(jee,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification"),d(Dee,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForTokenClassification"),d(Gee,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),d(Oee,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),d(Vee,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification"),d(Xee,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),d(zee,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),d(Qee,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),d(Wee,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification"),d(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(nC,"id","transformers.AutoModelForQuestionAnswering"),d(nC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(nC,"href","#transformers.AutoModelForQuestionAnswering"),d(_m,"class","relative group"),d(Uee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Hee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Jee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Yee,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),d(Zee,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering"),d(Kee,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering"),d(eoe,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),d(ooe,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),d(roe,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering"),d(toe,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),d(aoe,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering"),d(noe,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),d(soe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),d(loe,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),d(ioe,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),d(doe,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),d(moe,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),d(coe,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering"),d(foe,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),d(goe,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),d(hoe,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),d(uoe,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),d(poe,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),d(_oe,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),d(boe,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),d(voe,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering"),d(Foe,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForQuestionAnswering"),d(Toe,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),d(Moe,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering"),d(Eoe,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),d(Coe,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering"),d(woe,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),d(Aoe,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),d(Loe,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),d(yoe,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),d(xoe,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),d($oe,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),d(koe,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),d(Soe,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForQuestionAnswering"),d(Roe,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),d(Poe,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),d(Boe,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),d(Ioe,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),d(Noe,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForQuestionAnswering"),d(qoe,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),d(joe,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),d(Doe,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),d(Goe,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),d(Ooe,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),d(Voe,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),d(Xoe,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),d(zoe,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),d(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(a3,"id","transformers.AutoModelForTableQuestionAnswering"),d(a3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(a3,"href","#transformers.AutoModelForTableQuestionAnswering"),d(Fm,"class","relative group"),d(Qoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Woe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Uoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Hoe,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),d(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(d3,"id","transformers.AutoModelForDocumentQuestionAnswering"),d(d3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(d3,"href","#transformers.AutoModelForDocumentQuestionAnswering"),d(Em,"class","relative group"),d(Joe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Yoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Zoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Koe,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering"),d(ere,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),d(ore,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),d(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(p3,"id","transformers.AutoModelForImageClassification"),d(p3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(p3,"href","#transformers.AutoModelForImageClassification"),d(Lm,"class","relative group"),d(rre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(tre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(are,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(nre,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification"),d(sre,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification"),d(lre,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification"),d(ire,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),d(dre,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification"),d(mre,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),d(cre,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),d(fre,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification"),d(gre,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),d(hre,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification"),d(ure,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),d(pre,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),d(_re,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),d(bre,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),d(vre,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification"),d(Fre,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification"),d(Tre,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification"),d(Mre,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification"),d(Ere,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification"),d(Cre,"href","/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification"),d(wre,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification"),d(Are,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification"),d(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(B3,"id","transformers.AutoModelForVideoClassification"),d(B3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(B3,"href","#transformers.AutoModelForVideoClassification"),d($m,"class","relative group"),d(Lre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(yre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(xre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($re,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification"),d(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(D3,"id","transformers.AutoModelForVision2Seq"),d(D3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(D3,"href","#transformers.AutoModelForVision2Seq"),d(Rm,"class","relative group"),d(kre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Sre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Rre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Pre,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),d(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(z3,"id","transformers.AutoModelForVisualQuestionAnswering"),d(z3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(z3,"href","#transformers.AutoModelForVisualQuestionAnswering"),d(Im,"class","relative group"),d(Bre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ire,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Nre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qre,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),d(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(J3,"id","transformers.AutoModelForAudioClassification"),d(J3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(J3,"href","#transformers.AutoModelForAudioClassification"),d(jm,"class","relative group"),d(jre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Dre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Gre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ore,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),d(Vre,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification"),d(Xre,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification"),d(zre,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),d(Qre,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),d(Wre,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),d(Ure,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),d(Hre,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),d(Jre,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),d(To,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(d5,"id","transformers.AutoModelForAudioFrameClassification"),d(d5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(d5,"href","#transformers.AutoModelForAudioFrameClassification"),d(Om,"class","relative group"),d(Yre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Zre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Kre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ete,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),d(ote,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),d(rte,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),d(tte,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),d(ate,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),d(Mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(b5,"id","transformers.AutoModelForCTC"),d(b5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(b5,"href","#transformers.AutoModelForCTC"),d(zm,"class","relative group"),d(nte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ste,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(lte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ite,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),d(dte,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC"),d(mte,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC"),d(cte,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC"),d(fte,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC"),d(gte,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC"),d(hte,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),d(ute,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),d(pte,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),d(_te,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC"),d(Eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(S5,"id","transformers.AutoModelForSpeechSeq2Seq"),d(S5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(S5,"href","#transformers.AutoModelForSpeechSeq2Seq"),d(Um,"class","relative group"),d(bte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(vte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Fte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Tte,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),d(Mte,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),d(Ete,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration"),d(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(j5,"id","transformers.AutoModelForAudioXVector"),d(j5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(j5,"href","#transformers.AutoModelForAudioXVector"),d(Zm,"class","relative group"),d(Cte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(wte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Ate,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Lte,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),d(yte,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),d(xte,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),d($te,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),d(kte,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector"),d(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(U5,"id","transformers.AutoModelForMaskedImageModeling"),d(U5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(U5,"href","#transformers.AutoModelForMaskedImageModeling"),d(oc,"class","relative group"),d(Ste,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Rte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Pte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Bte,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),d(Ite,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),d(Nte,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling"),d(qte,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),d(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(r0,"id","transformers.AutoModelForObjectDetection"),d(r0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(r0,"href","#transformers.AutoModelForObjectDetection"),d(ac,"class","relative group"),d(jte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Dte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Gte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ote,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection"),d(Vte,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection"),d(Xte,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection"),d(zte,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection"),d(Qte,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection"),d(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(c0,"id","transformers.AutoModelForImageSegmentation"),d(c0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(c0,"href","#transformers.AutoModelForImageSegmentation"),d(lc,"class","relative group"),d(Wte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ute,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Hte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Jte,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation"),d(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(p0,"id","transformers.AutoModelForSemanticSegmentation"),d(p0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(p0,"href","#transformers.AutoModelForSemanticSegmentation"),d(mc,"class","relative group"),d(Yte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Zte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Kte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(eae,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),d(oae,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),d(rae,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),d(tae,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation"),d(aae,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),d(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(w0,"id","transformers.AutoModelForInstanceSegmentation"),d(w0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(w0,"href","#transformers.AutoModelForInstanceSegmentation"),d(gc,"class","relative group"),d(nae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(sae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(lae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(iae,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),d($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($0,"id","transformers.AutoModelForZeroShotObjectDetection"),d($0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d($0,"href","#transformers.AutoModelForZeroShotObjectDetection"),d(pc,"class","relative group"),d(dae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(mae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(cae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(fae,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTForObjectDetection"),d(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(B0,"id","transformers.TFAutoModel"),d(B0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(B0,"href","#transformers.TFAutoModel"),d(vc,"class","relative group"),d(gae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(hae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(uae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(pae,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel"),d(_ae,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel"),d(bae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel"),d(vae,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),d(Fae,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),d(Tae,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel"),d(Mae,"href","/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel"),d(Eae,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel"),d(Cae,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel"),d(wae,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel"),d(Aae,"href","/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtModel"),d(Lae,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),d(yae,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel"),d(xae,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),d($ae,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel"),d(kae,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel"),d(Sae,"href","/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),d(Rae,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel"),d(Pae,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmModel"),d(Bae,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel"),d(Iae,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel"),d(Nae,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel"),d(qae,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model"),d(jae,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel"),d(Dae,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel"),d(Gae,"href","/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel"),d(Oae,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),d(Vae,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model"),d(Xae,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel"),d(zae,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel"),d(Qae,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel"),d(Wae,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel"),d(Uae,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel"),d(Hae,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel"),d(Jae,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel"),d(Yae,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel"),d(Zae,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model"),d(Kae,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),d(ene,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel"),d(one,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel"),d(rne,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel"),d(tne,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel"),d(ane,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel"),d(nne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel"),d(sne,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel"),d(lne,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel"),d(ine,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),d(dne,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel"),d(mne,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model"),d(cne,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel"),d(fne,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),d(gne,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel"),d(hne,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel"),d(une,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),d(pne,"href","/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperModel"),d(_ne,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel"),d(bne,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel"),d(vne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),d(Fne,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel"),d(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Gw,"id","transformers.TFAutoModelForPreTraining"),d(Gw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Gw,"href","#transformers.TFAutoModelForPreTraining"),d(Mc,"class","relative group"),d(Tne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Mne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Ene,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Cne,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining"),d(wne,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),d(Ane,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining"),d(Lne,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),d(yne,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),d(xne,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),d($ne,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining"),d(kne,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),d(Sne,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),d(Rne,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),d(Pne,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),d(Bne,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),d(Ine,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),d(Nne,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),d(qne,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),d(jne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),d(Dne,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),d(Gne,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),d(One,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),d(Vne,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),d(Xne,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(zne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),d(Qne,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),d(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(gA,"id","transformers.TFAutoModelForCausalLM"),d(gA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(gA,"href","#transformers.TFAutoModelForCausalLM"),d(wc,"class","relative group"),d(Wne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Une,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Hne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Jne,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel"),d(Yne,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),d(Zne,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),d(Kne,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),d(ese,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),d(ose,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),d(rse,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM"),d(tse,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),d(ase,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),d(nse,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),d(sse,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),d(lse,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM"),d(ise,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(dse,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),d(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($A,"id","transformers.TFAutoModelForImageClassification"),d($A,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d($A,"href","#transformers.TFAutoModelForImageClassification"),d(yc,"class","relative group"),d(mse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(cse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(fse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(gse,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),d(hse,"href","/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtForImageClassification"),d(use,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),d(pse,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification"),d(_se,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher"),d(bse,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification"),d(vse,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),d(Fse,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification"),d(Tse,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification"),d(Mse,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification"),d(Ese,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification"),d(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(OA,"id","transformers.TFAutoModelForSemanticSegmentation"),d(OA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(OA,"href","#transformers.TFAutoModelForSemanticSegmentation"),d(kc,"class","relative group"),d(Cse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(wse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Ase,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(na,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Lse,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation"),d(yse,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation"),d(xse,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation"),d(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(UA,"id","transformers.TFAutoModelForMaskedLM"),d(UA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(UA,"href","#transformers.TFAutoModelForMaskedLM"),d(Bc,"class","relative group"),d($se,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(kse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Sse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(sa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Rse,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),d(Pse,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM"),d(Bse,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),d(Ise,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),d(Nse,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),d(qse,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),d(jse,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),d(Dse,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM"),d(Gse,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForMaskedLM"),d(Ose,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),d(Vse,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),d(Xse,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),d(zse,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),d(Qse,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),d(Wse,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),d(Use,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),d(Hse,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),d(Jse,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),d(Yse,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),d(Zse,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(Kse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),d(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(b6,"id","transformers.TFAutoModelForSeq2SeqLM"),d(b6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(b6,"href","#transformers.TFAutoModelForSeq2SeqLM"),d(qc,"class","relative group"),d(ele,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ole,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(rle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(la,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(tle,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),d(ale,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),d(nle,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),d(sle,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),d(lle,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),d(ile,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel"),d(dle,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),d(mle,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),d(cle,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),d(fle,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),d(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(k6,"id","transformers.TFAutoModelForSequenceClassification"),d(k6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(k6,"href","#transformers.TFAutoModelForSequenceClassification"),d(Gc,"class","relative group"),d(gle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(hle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(ule,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ia,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ple,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),d(_le,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification"),d(ble,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),d(vle,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),d(Fle,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),d(Tle,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),d(Mle,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),d(Ele,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),d(Cle,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),d(wle,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForSequenceClassification"),d(Ale,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),d(Lle,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),d(yle,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),d(xle,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),d($le,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),d(kle,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification"),d(Sle,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),d(Rle,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),d(Ple,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),d(Ble,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),d(Ile,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),d(Nle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),d(qle,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),d(jle,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),d(Dle,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),d(Gle,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),d(Ole,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),d(Vle,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),d(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(i7,"id","transformers.TFAutoModelForMultipleChoice"),d(i7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(i7,"href","#transformers.TFAutoModelForMultipleChoice"),d(Xc,"class","relative group"),d(Xle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(zle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Qle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(da,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Wle,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),d(Ule,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice"),d(Hle,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),d(Jle,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),d(Yle,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),d(Zle,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),d(Kle,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),d(eie,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),d(oie,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),d(rie,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),d(tie,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),d(aie,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),d(nie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),d(sie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),d(lie,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),d(iie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),d(die,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),d(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(y7,"id","transformers.TFAutoModelForNextSentencePrediction"),d(y7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(y7,"href","#transformers.TFAutoModelForNextSentencePrediction"),d(Wc,"class","relative group"),d(mie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(cie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(fie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(gie,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),d(hie,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),d(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(R7,"id","transformers.TFAutoModelForTableQuestionAnswering"),d(R7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(R7,"href","#transformers.TFAutoModelForTableQuestionAnswering"),d(Jc,"class","relative group"),d(uie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(pie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(_ie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(bie,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),d(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(N7,"id","transformers.TFAutoModelForDocumentQuestionAnswering"),d(N7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(N7,"href","#transformers.TFAutoModelForDocumentQuestionAnswering"),d(Kc,"class","relative group"),d(vie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Fie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Tie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Mie,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering"),d(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(G7,"id","transformers.TFAutoModelForTokenClassification"),d(G7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(G7,"href","#transformers.TFAutoModelForTokenClassification"),d(rf,"class","relative group"),d(Eie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Cie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(wie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ga,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Aie,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),d(Lie,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification"),d(yie,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),d(xie,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),d($ie,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),d(kie,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),d(Sie,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),d(Rie,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification"),d(Pie,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForTokenClassification"),d(Bie,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),d(Iie,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),d(Nie,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),d(qie,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification"),d(jie,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),d(Die,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),d(Gie,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),d(Oie,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),d(Vie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),d(Xie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),d(zie,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),d(Qie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),d(Wie,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),d(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(f8,"id","transformers.TFAutoModelForQuestionAnswering"),d(f8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(f8,"href","#transformers.TFAutoModelForQuestionAnswering"),d(nf,"class","relative group"),d(Uie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Hie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Jie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ha,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Yie,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),d(Zie,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),d(Kie,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),d(ede,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),d(ode,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),d(rde,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),d(tde,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),d(ade,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),d(nde,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),d(sde,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),d(lde,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),d(ide,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering"),d(dde,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),d(mde,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),d(cde,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),d(fde,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),d(gde,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),d(hde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),d(ude,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),d(pde,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),d(_de,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),d(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(I8,"id","transformers.TFAutoModelForVision2Seq"),d(I8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(I8,"href","#transformers.TFAutoModelForVision2Seq"),d(df,"class","relative group"),d(bde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(vde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Fde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ua,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Tde,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),d(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(D8,"id","transformers.TFAutoModelForSpeechSeq2Seq"),d(D8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(D8,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),d(ff,"class","relative group"),d(Mde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ede,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Cde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(pa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(wde,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),d(Ade,"href","/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration"),d(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(z8,"id","transformers.FlaxAutoModel"),d(z8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(z8,"href","#transformers.FlaxAutoModel"),d(uf,"class","relative group"),d(Lde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(yde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(xde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(_a,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($de,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel"),d(kde,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel"),d(Sde,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel"),d(Rde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel"),d(Pde,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),d(Bde,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),d(Ide,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),d(Nde,"href","/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel"),d(qde,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),d(jde,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel"),d(Dde,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model"),d(Gde,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),d(Ode,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel"),d(Vde,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model"),d(Xde,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel"),d(zde,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel"),d(Qde,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model"),d(Wde,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel"),d(Ude,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel"),d(Hde,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel"),d(Jde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel"),d(Yde,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model"),d(Zde,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),d(Kde,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel"),d(eme,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),d(ome,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel"),d(rme,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),d(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(TL,"id","transformers.FlaxAutoModelForCausalLM"),d(TL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(TL,"href","#transformers.FlaxAutoModelForCausalLM"),d(bf,"class","relative group"),d(tme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ame,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(nme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ba,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(sme,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM"),d(lme,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM"),d(ime,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),d(dme,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),d(mme,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),d(cme,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),d(fme,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),d(gme,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),d(hme,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),d(ume,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),d(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(PL,"id","transformers.FlaxAutoModelForPreTraining"),d(PL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(PL,"href","#transformers.FlaxAutoModelForPreTraining"),d(Tf,"class","relative group"),d(pme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(_me,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(bme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(va,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(vme,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),d(Fme,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(Tme,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining"),d(Mme,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),d(Eme,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),d(Cme,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),d(wme,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(Ame,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),d(Lme,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),d(yme,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),d(xme,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),d($me,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),d(kme,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),d(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(JL,"id","transformers.FlaxAutoModelForMaskedLM"),d(JL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(JL,"href","#transformers.FlaxAutoModelForMaskedLM"),d(Cf,"class","relative group"),d(Sme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Rme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Pme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Bme,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),d(Ime,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(Nme,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),d(qme,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),d(jme,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),d(Dme,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),d(Gme,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(Ome,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),d(Vme,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),d(Xme,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),d(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(dy,"id","transformers.FlaxAutoModelForSeq2SeqLM"),d(dy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(dy,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),d(Lf,"class","relative group"),d(zme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Qme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Wme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ume,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(Hme,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),d(Jme,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),d(Yme,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),d(Zme,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),d(Kme,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel"),d(ece,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(oce,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),d(rce,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),d(tce,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),d(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(My,"id","transformers.FlaxAutoModelForSequenceClassification"),d(My,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(My,"href","#transformers.FlaxAutoModelForSequenceClassification"),d($f,"class","relative group"),d(ace,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(nce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(sce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(lce,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),d(ice,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),d(dce,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),d(mce,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),d(cce,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),d(fce,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),d(gce,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),d(hce,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),d(uce,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),d(pce,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),d(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(By,"id","transformers.FlaxAutoModelForQuestionAnswering"),d(By,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(By,"href","#transformers.FlaxAutoModelForQuestionAnswering"),d(Rf,"class","relative group"),d(_ce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(bce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(vce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Fce,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),d(Tce,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),d(Mce,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),d(Ece,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),d(Cce,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),d(wce,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),d(Ace,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),d(Lce,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),d(yce,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),d(xce,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),d(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Uy,"id","transformers.FlaxAutoModelForTokenClassification"),d(Uy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Uy,"href","#transformers.FlaxAutoModelForTokenClassification"),d(If,"class","relative group"),d($ce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(kce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Sce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Rce,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),d(Pce,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),d(Bce,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),d(Ice,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),d(Nce,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),d(qce,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),d(jce,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),d(Dce,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),d(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(n9,"id","transformers.FlaxAutoModelForMultipleChoice"),d(n9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(n9,"href","#transformers.FlaxAutoModelForMultipleChoice"),d(jf,"class","relative group"),d(Gce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Oce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Vce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(wa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Xce,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),d(zce,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),d(Qce,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),d(Wce,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),d(Uce,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),d(Hce,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),d(Jce,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),d(Yce,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),d(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(p9,"id","transformers.FlaxAutoModelForNextSentencePrediction"),d(p9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(p9,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),d(Of,"class","relative group"),d(Zce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Kce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(efe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ofe,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),d(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(F9,"id","transformers.FlaxAutoModelForImageClassification"),d(F9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(F9,"href","#transformers.FlaxAutoModelForImageClassification"),d(zf,"class","relative group"),d(rfe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(tfe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(afe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(La,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(nfe,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),d(sfe,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification"),d(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(w9,"id","transformers.FlaxAutoModelForVision2Seq"),d(w9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(w9,"href","#transformers.FlaxAutoModelForVision2Seq"),d(Uf,"class","relative group"),d(lfe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ife,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(dfe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ya,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(mfe,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),d(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(c,_){e(document.head,g),b(c,v,_),b(c,u,_),e(u,f),e(f,p),M(m,p,null),e(u,h),e(u,He),e(He,Ad),b(c,eg,_),b(c,wt,_),e(wt,Ld),e(wt,yd),e(yd,ck),e(wt,og),b(c,Qe,_),b(c,Ze,_),e(Ze,xd),e(Ze,ps),e(ps,fk),e(Ze,_s),e(Ze,bs),e(bs,gk),e(Ze,$d),e(Ze,vs),e(vs,hk),e(Ze,kd),b(c,rg,_),M(sn,c,_),b(c,Ke,_),b(c,ye,_),e(ye,Bq),e(ye,Sd),e(Sd,Iq),e(ye,Nq),b(c,Po,_),b(c,ln,_),e(ln,qq),e(ln,tg),e(tg,jq),e(ln,Ffo),b(c,ylo,_),b(c,Rd,_),e(Rd,ag),e(ag,vhe),M(uk,vhe,null),e(Rd,Tfo),e(Rd,Fhe),e(Fhe,Mfo),b(c,xlo,_),b(c,Fs,_),e(Fs,Efo),e(Fs,The),e(The,Cfo),e(Fs,wfo),e(Fs,Mhe),e(Mhe,Afo),e(Fs,Lfo),b(c,$lo,_),M(pk,c,_),b(c,klo,_),b(c,Dq,_),e(Dq,yfo),b(c,Slo,_),M(ng,c,_),b(c,Rlo,_),b(c,Pd,_),e(Pd,sg),e(sg,Ehe),M(_k,Ehe,null),e(Pd,xfo),e(Pd,Che),e(Che,$fo),b(c,Plo,_),b(c,Bo,_),M(bk,Bo,null),e(Bo,kfo),e(Bo,vk),e(vk,Sfo),e(vk,Gq),e(Gq,Rfo),e(vk,Pfo),e(Bo,Bfo),e(Bo,Fk),e(Fk,Ifo),e(Fk,whe),e(whe,Nfo),e(Fk,qfo),e(Bo,jfo),e(Bo,Or),M(Tk,Or,null),e(Or,Dfo),e(Or,Ahe),e(Ahe,Gfo),e(Or,Ofo),e(Or,Bd),e(Bd,Vfo),e(Bd,Lhe),e(Lhe,Xfo),e(Bd,zfo),e(Bd,yhe),e(yhe,Qfo),e(Bd,Wfo),e(Or,Ufo),e(Or,A),e(A,lg),e(lg,xhe),e(xhe,Hfo),e(lg,Jfo),e(lg,Oq),e(Oq,Yfo),e(lg,Zfo),e(A,Kfo),e(A,ig),e(ig,$he),e($he,ego),e(ig,ogo),e(ig,Vq),e(Vq,rgo),e(ig,tgo),e(A,ago),e(A,dg),e(dg,khe),e(khe,ngo),e(dg,sgo),e(dg,Xq),e(Xq,lgo),e(dg,igo),e(A,dgo),e(A,mg),e(mg,She),e(She,mgo),e(mg,cgo),e(mg,zq),e(zq,fgo),e(mg,ggo),e(A,hgo),e(A,cg),e(cg,Rhe),e(Rhe,ugo),e(cg,pgo),e(cg,Qq),e(Qq,_go),e(cg,bgo),e(A,vgo),e(A,fg),e(fg,Phe),e(Phe,Fgo),e(fg,Tgo),e(fg,Wq),e(Wq,Mgo),e(fg,Ego),e(A,Cgo),e(A,gg),e(gg,Bhe),e(Bhe,wgo),e(gg,Ago),e(gg,Uq),e(Uq,Lgo),e(gg,ygo),e(A,xgo),e(A,hg),e(hg,Ihe),e(Ihe,$go),e(hg,kgo),e(hg,Hq),e(Hq,Sgo),e(hg,Rgo),e(A,Pgo),e(A,ug),e(ug,Nhe),e(Nhe,Bgo),e(ug,Igo),e(ug,Jq),e(Jq,Ngo),e(ug,qgo),e(A,jgo),e(A,pg),e(pg,qhe),e(qhe,Dgo),e(pg,Ggo),e(pg,Yq),e(Yq,Ogo),e(pg,Vgo),e(A,Xgo),e(A,_g),e(_g,jhe),e(jhe,zgo),e(_g,Qgo),e(_g,Zq),e(Zq,Wgo),e(_g,Ugo),e(A,Hgo),e(A,bg),e(bg,Dhe),e(Dhe,Jgo),e(bg,Ygo),e(bg,Kq),e(Kq,Zgo),e(bg,Kgo),e(A,eho),e(A,vg),e(vg,Ghe),e(Ghe,oho),e(vg,rho),e(vg,ej),e(ej,tho),e(vg,aho),e(A,nho),e(A,Fg),e(Fg,Ohe),e(Ohe,sho),e(Fg,lho),e(Fg,oj),e(oj,iho),e(Fg,dho),e(A,mho),e(A,Tg),e(Tg,Vhe),e(Vhe,cho),e(Tg,fho),e(Tg,rj),e(rj,gho),e(Tg,hho),e(A,uho),e(A,Mg),e(Mg,Xhe),e(Xhe,pho),e(Mg,_ho),e(Mg,tj),e(tj,bho),e(Mg,vho),e(A,Fho),e(A,Eg),e(Eg,zhe),e(zhe,Tho),e(Eg,Mho),e(Eg,aj),e(aj,Eho),e(Eg,Cho),e(A,who),e(A,Cg),e(Cg,Qhe),e(Qhe,Aho),e(Cg,Lho),e(Cg,nj),e(nj,yho),e(Cg,xho),e(A,$ho),e(A,wg),e(wg,Whe),e(Whe,kho),e(wg,Sho),e(wg,sj),e(sj,Rho),e(wg,Pho),e(A,Bho),e(A,Ag),e(Ag,Uhe),e(Uhe,Iho),e(Ag,Nho),e(Ag,lj),e(lj,qho),e(Ag,jho),e(A,Dho),e(A,Lg),e(Lg,Hhe),e(Hhe,Gho),e(Lg,Oho),e(Lg,ij),e(ij,Vho),e(Lg,Xho),e(A,zho),e(A,yg),e(yg,Jhe),e(Jhe,Qho),e(yg,Who),e(yg,dj),e(dj,Uho),e(yg,Hho),e(A,Jho),e(A,xg),e(xg,Yhe),e(Yhe,Yho),e(xg,Zho),e(xg,mj),e(mj,Kho),e(xg,euo),e(A,ouo),e(A,$g),e($g,Zhe),e(Zhe,ruo),e($g,tuo),e($g,cj),e(cj,auo),e($g,nuo),e(A,suo),e(A,kg),e(kg,Khe),e(Khe,luo),e(kg,iuo),e(kg,fj),e(fj,duo),e(kg,muo),e(A,cuo),e(A,Sg),e(Sg,eue),e(eue,fuo),e(Sg,guo),e(Sg,gj),e(gj,huo),e(Sg,uuo),e(A,puo),e(A,Rg),e(Rg,oue),e(oue,_uo),e(Rg,buo),e(Rg,hj),e(hj,vuo),e(Rg,Fuo),e(A,Tuo),e(A,Pg),e(Pg,rue),e(rue,Muo),e(Pg,Euo),e(Pg,uj),e(uj,Cuo),e(Pg,wuo),e(A,Auo),e(A,Bg),e(Bg,tue),e(tue,Luo),e(Bg,yuo),e(Bg,pj),e(pj,xuo),e(Bg,$uo),e(A,kuo),e(A,Ig),e(Ig,aue),e(aue,Suo),e(Ig,Ruo),e(Ig,_j),e(_j,Puo),e(Ig,Buo),e(A,Iuo),e(A,Ng),e(Ng,nue),e(nue,Nuo),e(Ng,quo),e(Ng,bj),e(bj,juo),e(Ng,Duo),e(A,Guo),e(A,qg),e(qg,sue),e(sue,Ouo),e(qg,Vuo),e(qg,vj),e(vj,Xuo),e(qg,zuo),e(A,Quo),e(A,jg),e(jg,lue),e(lue,Wuo),e(jg,Uuo),e(jg,Fj),e(Fj,Huo),e(jg,Juo),e(A,Yuo),e(A,Dg),e(Dg,iue),e(iue,Zuo),e(Dg,Kuo),e(Dg,Tj),e(Tj,epo),e(Dg,opo),e(A,rpo),e(A,Gg),e(Gg,due),e(due,tpo),e(Gg,apo),e(Gg,Mj),e(Mj,npo),e(Gg,spo),e(A,lpo),e(A,Og),e(Og,mue),e(mue,ipo),e(Og,dpo),e(Og,Ej),e(Ej,mpo),e(Og,cpo),e(A,fpo),e(A,Vg),e(Vg,cue),e(cue,gpo),e(Vg,hpo),e(Vg,Cj),e(Cj,upo),e(Vg,ppo),e(A,_po),e(A,Xg),e(Xg,fue),e(fue,bpo),e(Xg,vpo),e(Xg,wj),e(wj,Fpo),e(Xg,Tpo),e(A,Mpo),e(A,zg),e(zg,gue),e(gue,Epo),e(zg,Cpo),e(zg,Aj),e(Aj,wpo),e(zg,Apo),e(A,Lpo),e(A,Qg),e(Qg,hue),e(hue,ypo),e(Qg,xpo),e(Qg,Lj),e(Lj,$po),e(Qg,kpo),e(A,Spo),e(A,Wg),e(Wg,uue),e(uue,Rpo),e(Wg,Ppo),e(Wg,yj),e(yj,Bpo),e(Wg,Ipo),e(A,Npo),e(A,Ug),e(Ug,pue),e(pue,qpo),e(Ug,jpo),e(Ug,xj),e(xj,Dpo),e(Ug,Gpo),e(A,Opo),e(A,Hg),e(Hg,_ue),e(_ue,Vpo),e(Hg,Xpo),e(Hg,$j),e($j,zpo),e(Hg,Qpo),e(A,Wpo),e(A,Jg),e(Jg,bue),e(bue,Upo),e(Jg,Hpo),e(Jg,kj),e(kj,Jpo),e(Jg,Ypo),e(A,Zpo),e(A,Yg),e(Yg,vue),e(vue,Kpo),e(Yg,e_o),e(Yg,Sj),e(Sj,o_o),e(Yg,r_o),e(A,t_o),e(A,Zg),e(Zg,Fue),e(Fue,a_o),e(Zg,n_o),e(Zg,Rj),e(Rj,s_o),e(Zg,l_o),e(A,i_o),e(A,Kg),e(Kg,Tue),e(Tue,d_o),e(Kg,m_o),e(Kg,Pj),e(Pj,c_o),e(Kg,f_o),e(A,g_o),e(A,eh),e(eh,Mue),e(Mue,h_o),e(eh,u_o),e(eh,Bj),e(Bj,p_o),e(eh,__o),e(A,b_o),e(A,oh),e(oh,Eue),e(Eue,v_o),e(oh,F_o),e(oh,Ij),e(Ij,T_o),e(oh,M_o),e(A,E_o),e(A,rh),e(rh,Cue),e(Cue,C_o),e(rh,w_o),e(rh,Nj),e(Nj,A_o),e(rh,L_o),e(A,y_o),e(A,th),e(th,wue),e(wue,x_o),e(th,$_o),e(th,qj),e(qj,k_o),e(th,S_o),e(A,R_o),e(A,ah),e(ah,Aue),e(Aue,P_o),e(ah,B_o),e(ah,jj),e(jj,I_o),e(ah,N_o),e(A,q_o),e(A,nh),e(nh,Lue),e(Lue,j_o),e(nh,D_o),e(nh,Dj),e(Dj,G_o),e(nh,O_o),e(A,V_o),e(A,sh),e(sh,yue),e(yue,X_o),e(sh,z_o),e(sh,Gj),e(Gj,Q_o),e(sh,W_o),e(A,U_o),e(A,lh),e(lh,xue),e(xue,H_o),e(lh,J_o),e(lh,Oj),e(Oj,Y_o),e(lh,Z_o),e(A,K_o),e(A,ih),e(ih,$ue),e($ue,e1o),e(ih,o1o),e(ih,Vj),e(Vj,r1o),e(ih,t1o),e(A,a1o),e(A,dh),e(dh,kue),e(kue,n1o),e(dh,s1o),e(dh,Xj),e(Xj,l1o),e(dh,i1o),e(A,d1o),e(A,mh),e(mh,Sue),e(Sue,m1o),e(mh,c1o),e(mh,zj),e(zj,f1o),e(mh,g1o),e(A,h1o),e(A,ch),e(ch,Rue),e(Rue,u1o),e(ch,p1o),e(ch,Qj),e(Qj,_1o),e(ch,b1o),e(A,v1o),e(A,fh),e(fh,Pue),e(Pue,F1o),e(fh,T1o),e(fh,Wj),e(Wj,M1o),e(fh,E1o),e(A,C1o),e(A,gh),e(gh,Bue),e(Bue,w1o),e(gh,A1o),e(gh,Uj),e(Uj,L1o),e(gh,y1o),e(A,x1o),e(A,hh),e(hh,Iue),e(Iue,$1o),e(hh,k1o),e(hh,Hj),e(Hj,S1o),e(hh,R1o),e(A,P1o),e(A,uh),e(uh,Nue),e(Nue,B1o),e(uh,I1o),e(uh,Jj),e(Jj,N1o),e(uh,q1o),e(A,j1o),e(A,ph),e(ph,que),e(que,D1o),e(ph,G1o),e(ph,Yj),e(Yj,O1o),e(ph,V1o),e(A,X1o),e(A,_h),e(_h,jue),e(jue,z1o),e(_h,Q1o),e(_h,Zj),e(Zj,W1o),e(_h,U1o),e(A,H1o),e(A,bh),e(bh,Due),e(Due,J1o),e(bh,Y1o),e(bh,Kj),e(Kj,Z1o),e(bh,K1o),e(A,e2o),e(A,vh),e(vh,Gue),e(Gue,o2o),e(vh,r2o),e(vh,eD),e(eD,t2o),e(vh,a2o),e(A,n2o),e(A,Fh),e(Fh,Oue),e(Oue,s2o),e(Fh,l2o),e(Fh,oD),e(oD,i2o),e(Fh,d2o),e(A,m2o),e(A,Th),e(Th,Vue),e(Vue,c2o),e(Th,f2o),e(Th,rD),e(rD,g2o),e(Th,h2o),e(A,u2o),e(A,Mh),e(Mh,Xue),e(Xue,p2o),e(Mh,_2o),e(Mh,tD),e(tD,b2o),e(Mh,v2o),e(A,F2o),e(A,Eh),e(Eh,zue),e(zue,T2o),e(Eh,M2o),e(Eh,aD),e(aD,E2o),e(Eh,C2o),e(A,w2o),e(A,Ch),e(Ch,Que),e(Que,A2o),e(Ch,L2o),e(Ch,nD),e(nD,y2o),e(Ch,x2o),e(A,$2o),e(A,wh),e(wh,Wue),e(Wue,k2o),e(wh,S2o),e(wh,sD),e(sD,R2o),e(wh,P2o),e(A,B2o),e(A,Ah),e(Ah,Uue),e(Uue,I2o),e(Ah,N2o),e(Ah,lD),e(lD,q2o),e(Ah,j2o),e(A,D2o),e(A,Lh),e(Lh,Hue),e(Hue,G2o),e(Lh,O2o),e(Lh,iD),e(iD,V2o),e(Lh,X2o),e(A,z2o),e(A,yh),e(yh,Jue),e(Jue,Q2o),e(yh,W2o),e(yh,dD),e(dD,U2o),e(yh,H2o),e(A,J2o),e(A,xh),e(xh,Yue),e(Yue,Y2o),e(xh,Z2o),e(xh,mD),e(mD,K2o),e(xh,ebo),e(A,obo),e(A,$h),e($h,Zue),e(Zue,rbo),e($h,tbo),e($h,cD),e(cD,abo),e($h,nbo),e(A,sbo),e(A,kh),e(kh,Kue),e(Kue,lbo),e(kh,ibo),e(kh,fD),e(fD,dbo),e(kh,mbo),e(A,cbo),e(A,Sh),e(Sh,epe),e(epe,fbo),e(Sh,gbo),e(Sh,gD),e(gD,hbo),e(Sh,ubo),e(A,pbo),e(A,Rh),e(Rh,ope),e(ope,_bo),e(Rh,bbo),e(Rh,hD),e(hD,vbo),e(Rh,Fbo),e(A,Tbo),e(A,Ph),e(Ph,rpe),e(rpe,Mbo),e(Ph,Ebo),e(Ph,uD),e(uD,Cbo),e(Ph,wbo),e(A,Abo),e(A,Bh),e(Bh,tpe),e(tpe,Lbo),e(Bh,ybo),e(Bh,pD),e(pD,xbo),e(Bh,$bo),e(A,kbo),e(A,Ih),e(Ih,ape),e(ape,Sbo),e(Ih,Rbo),e(Ih,_D),e(_D,Pbo),e(Ih,Bbo),e(A,Ibo),e(A,Nh),e(Nh,npe),e(npe,Nbo),e(Nh,qbo),e(Nh,bD),e(bD,jbo),e(Nh,Dbo),e(A,Gbo),e(A,qh),e(qh,spe),e(spe,Obo),e(qh,Vbo),e(qh,vD),e(vD,Xbo),e(qh,zbo),e(A,Qbo),e(A,jh),e(jh,lpe),e(lpe,Wbo),e(jh,Ubo),e(jh,FD),e(FD,Hbo),e(jh,Jbo),e(A,Ybo),e(A,Dh),e(Dh,ipe),e(ipe,Zbo),e(Dh,Kbo),e(Dh,TD),e(TD,evo),e(Dh,ovo),e(A,rvo),e(A,Gh),e(Gh,dpe),e(dpe,tvo),e(Gh,avo),e(Gh,MD),e(MD,nvo),e(Gh,svo),e(A,lvo),e(A,Oh),e(Oh,mpe),e(mpe,ivo),e(Oh,dvo),e(Oh,ED),e(ED,mvo),e(Oh,cvo),e(A,fvo),e(A,Vh),e(Vh,cpe),e(cpe,gvo),e(Vh,hvo),e(Vh,CD),e(CD,uvo),e(Vh,pvo),e(A,_vo),e(A,Xh),e(Xh,fpe),e(fpe,bvo),e(Xh,vvo),e(Xh,wD),e(wD,Fvo),e(Xh,Tvo),e(A,Mvo),e(A,zh),e(zh,gpe),e(gpe,Evo),e(zh,Cvo),e(zh,AD),e(AD,wvo),e(zh,Avo),e(A,Lvo),e(A,Qh),e(Qh,hpe),e(hpe,yvo),e(Qh,xvo),e(Qh,LD),e(LD,$vo),e(Qh,kvo),e(A,Svo),e(A,Wh),e(Wh,upe),e(upe,Rvo),e(Wh,Pvo),e(Wh,yD),e(yD,Bvo),e(Wh,Ivo),e(A,Nvo),e(A,Uh),e(Uh,ppe),e(ppe,qvo),e(Uh,jvo),e(Uh,xD),e(xD,Dvo),e(Uh,Gvo),e(A,Ovo),e(A,Hh),e(Hh,_pe),e(_pe,Vvo),e(Hh,Xvo),e(Hh,$D),e($D,zvo),e(Hh,Qvo),e(A,Wvo),e(A,Jh),e(Jh,bpe),e(bpe,Uvo),e(Jh,Hvo),e(Jh,kD),e(kD,Jvo),e(Jh,Yvo),e(A,Zvo),e(A,Yh),e(Yh,vpe),e(vpe,Kvo),e(Yh,eFo),e(Yh,SD),e(SD,oFo),e(Yh,rFo),e(A,tFo),e(A,Zh),e(Zh,Fpe),e(Fpe,aFo),e(Zh,nFo),e(Zh,RD),e(RD,sFo),e(Zh,lFo),e(A,iFo),e(A,Kh),e(Kh,Tpe),e(Tpe,dFo),e(Kh,mFo),e(Kh,PD),e(PD,cFo),e(Kh,fFo),e(A,gFo),e(A,eu),e(eu,Mpe),e(Mpe,hFo),e(eu,uFo),e(eu,BD),e(BD,pFo),e(eu,_Fo),e(A,bFo),e(A,ou),e(ou,Epe),e(Epe,vFo),e(ou,FFo),e(ou,ID),e(ID,TFo),e(ou,MFo),e(A,EFo),e(A,ru),e(ru,Cpe),e(Cpe,CFo),e(ru,wFo),e(ru,ND),e(ND,AFo),e(ru,LFo),e(A,yFo),e(A,tu),e(tu,wpe),e(wpe,xFo),e(tu,$Fo),e(tu,qD),e(qD,kFo),e(tu,SFo),e(A,RFo),e(A,au),e(au,Ape),e(Ape,PFo),e(au,BFo),e(au,jD),e(jD,IFo),e(au,NFo),e(A,qFo),e(A,nu),e(nu,Lpe),e(Lpe,jFo),e(nu,DFo),e(nu,DD),e(DD,GFo),e(nu,OFo),e(A,VFo),e(A,su),e(su,ype),e(ype,XFo),e(su,zFo),e(su,GD),e(GD,QFo),e(su,WFo),e(A,UFo),e(A,lu),e(lu,xpe),e(xpe,HFo),e(lu,JFo),e(lu,OD),e(OD,YFo),e(lu,ZFo),e(A,KFo),e(A,iu),e(iu,$pe),e($pe,eTo),e(iu,oTo),e(iu,VD),e(VD,rTo),e(iu,tTo),e(A,aTo),e(A,du),e(du,kpe),e(kpe,nTo),e(du,sTo),e(du,XD),e(XD,lTo),e(du,iTo),e(A,dTo),e(A,mu),e(mu,Spe),e(Spe,mTo),e(mu,cTo),e(mu,zD),e(zD,fTo),e(mu,gTo),e(A,hTo),e(A,cu),e(cu,Rpe),e(Rpe,uTo),e(cu,pTo),e(cu,QD),e(QD,_To),e(cu,bTo),e(A,vTo),e(A,fu),e(fu,Ppe),e(Ppe,FTo),e(fu,TTo),e(fu,WD),e(WD,MTo),e(fu,ETo),e(A,CTo),e(A,gu),e(gu,Bpe),e(Bpe,wTo),e(gu,ATo),e(gu,UD),e(UD,LTo),e(gu,yTo),e(A,xTo),e(A,hu),e(hu,Ipe),e(Ipe,$To),e(hu,kTo),e(hu,HD),e(HD,STo),e(hu,RTo),e(A,PTo),e(A,uu),e(uu,Npe),e(Npe,BTo),e(uu,ITo),e(uu,JD),e(JD,NTo),e(uu,qTo),e(A,jTo),e(A,pu),e(pu,qpe),e(qpe,DTo),e(pu,GTo),e(pu,YD),e(YD,OTo),e(pu,VTo),e(A,XTo),e(A,_u),e(_u,jpe),e(jpe,zTo),e(_u,QTo),e(_u,ZD),e(ZD,WTo),e(_u,UTo),e(A,HTo),e(A,bu),e(bu,Dpe),e(Dpe,JTo),e(bu,YTo),e(bu,KD),e(KD,ZTo),e(bu,KTo),e(A,eMo),e(A,vu),e(vu,Gpe),e(Gpe,oMo),e(vu,rMo),e(vu,eG),e(eG,tMo),e(vu,aMo),e(A,nMo),e(A,Fu),e(Fu,Ope),e(Ope,sMo),e(Fu,lMo),e(Fu,oG),e(oG,iMo),e(Fu,dMo),e(A,mMo),e(A,Tu),e(Tu,Vpe),e(Vpe,cMo),e(Tu,fMo),e(Tu,rG),e(rG,gMo),e(Tu,hMo),e(A,uMo),e(A,Mu),e(Mu,Xpe),e(Xpe,pMo),e(Mu,_Mo),e(Mu,tG),e(tG,bMo),e(Mu,vMo),e(A,FMo),e(A,Eu),e(Eu,zpe),e(zpe,TMo),e(Eu,MMo),e(Eu,aG),e(aG,EMo),e(Eu,CMo),e(A,wMo),e(A,Cu),e(Cu,Qpe),e(Qpe,AMo),e(Cu,LMo),e(Cu,nG),e(nG,yMo),e(Cu,xMo),e(A,$Mo),e(A,wu),e(wu,Wpe),e(Wpe,kMo),e(wu,SMo),e(wu,sG),e(sG,RMo),e(wu,PMo),e(A,BMo),e(A,Au),e(Au,Upe),e(Upe,IMo),e(Au,NMo),e(Au,lG),e(lG,qMo),e(Au,jMo),e(A,DMo),e(A,Lu),e(Lu,Hpe),e(Hpe,GMo),e(Lu,OMo),e(Lu,iG),e(iG,VMo),e(Lu,XMo),e(A,zMo),e(A,yu),e(yu,Jpe),e(Jpe,QMo),e(yu,WMo),e(yu,dG),e(dG,UMo),e(yu,HMo),e(A,JMo),e(A,xu),e(xu,Ype),e(Ype,YMo),e(xu,ZMo),e(xu,mG),e(mG,KMo),e(xu,eEo),e(A,oEo),e(A,$u),e($u,Zpe),e(Zpe,rEo),e($u,tEo),e($u,cG),e(cG,aEo),e($u,nEo),e(A,sEo),e(A,ku),e(ku,Kpe),e(Kpe,lEo),e(ku,iEo),e(ku,fG),e(fG,dEo),e(ku,mEo),e(A,cEo),e(A,Su),e(Su,e_e),e(e_e,fEo),e(Su,gEo),e(Su,gG),e(gG,hEo),e(Su,uEo),e(A,pEo),e(A,Ru),e(Ru,o_e),e(o_e,_Eo),e(Ru,bEo),e(Ru,hG),e(hG,vEo),e(Ru,FEo),e(A,TEo),e(A,Pu),e(Pu,r_e),e(r_e,MEo),e(Pu,EEo),e(Pu,uG),e(uG,CEo),e(Pu,wEo),e(A,AEo),e(A,Bu),e(Bu,t_e),e(t_e,LEo),e(Bu,yEo),e(Bu,pG),e(pG,xEo),e(Bu,$Eo),e(A,kEo),e(A,Iu),e(Iu,a_e),e(a_e,SEo),e(Iu,REo),e(Iu,_G),e(_G,PEo),e(Iu,BEo),e(Or,IEo),M(Nu,Or,null),e(Bo,NEo),e(Bo,qu),M(Mk,qu,null),e(qu,qEo),e(qu,n_e),e(n_e,jEo),b(c,Blo,_),b(c,Id,_),e(Id,ju),e(ju,s_e),M(Ek,s_e,null),e(Id,DEo),e(Id,l_e),e(l_e,GEo),b(c,Ilo,_),b(c,Io,_),M(Ck,Io,null),e(Io,OEo),e(Io,wk),e(wk,VEo),e(wk,bG),e(bG,XEo),e(wk,zEo),e(Io,QEo),e(Io,Ak),e(Ak,WEo),e(Ak,i_e),e(i_e,UEo),e(Ak,HEo),e(Io,JEo),e(Io,Vr),M(Lk,Vr,null),e(Vr,YEo),e(Vr,d_e),e(d_e,ZEo),e(Vr,KEo),e(Vr,dn),e(dn,e4o),e(dn,m_e),e(m_e,o4o),e(dn,r4o),e(dn,c_e),e(c_e,t4o),e(dn,a4o),e(dn,f_e),e(f_e,n4o),e(dn,s4o),e(Vr,l4o),e(Vr,k),e(k,Ts),e(Ts,g_e),e(g_e,i4o),e(Ts,d4o),e(Ts,vG),e(vG,m4o),e(Ts,c4o),e(Ts,FG),e(FG,f4o),e(Ts,g4o),e(k,h4o),e(k,Ms),e(Ms,h_e),e(h_e,u4o),e(Ms,p4o),e(Ms,TG),e(TG,_4o),e(Ms,b4o),e(Ms,MG),e(MG,v4o),e(Ms,F4o),e(k,T4o),e(k,Es),e(Es,u_e),e(u_e,M4o),e(Es,E4o),e(Es,EG),e(EG,C4o),e(Es,w4o),e(Es,CG),e(CG,A4o),e(Es,L4o),e(k,y4o),e(k,Du),e(Du,p_e),e(p_e,x4o),e(Du,$4o),e(Du,wG),e(wG,k4o),e(Du,S4o),e(k,R4o),e(k,Cs),e(Cs,__e),e(__e,P4o),e(Cs,B4o),e(Cs,AG),e(AG,I4o),e(Cs,N4o),e(Cs,LG),e(LG,q4o),e(Cs,j4o),e(k,D4o),e(k,Gu),e(Gu,b_e),e(b_e,G4o),e(Gu,O4o),e(Gu,yG),e(yG,V4o),e(Gu,X4o),e(k,z4o),e(k,Ou),e(Ou,v_e),e(v_e,Q4o),e(Ou,W4o),e(Ou,xG),e(xG,U4o),e(Ou,H4o),e(k,J4o),e(k,Vu),e(Vu,F_e),e(F_e,Y4o),e(Vu,Z4o),e(Vu,$G),e($G,K4o),e(Vu,eCo),e(k,oCo),e(k,ws),e(ws,T_e),e(T_e,rCo),e(ws,tCo),e(ws,kG),e(kG,aCo),e(ws,nCo),e(ws,SG),e(SG,sCo),e(ws,lCo),e(k,iCo),e(k,As),e(As,M_e),e(M_e,dCo),e(As,mCo),e(As,RG),e(RG,cCo),e(As,fCo),e(As,PG),e(PG,gCo),e(As,hCo),e(k,uCo),e(k,Ls),e(Ls,E_e),e(E_e,pCo),e(Ls,_Co),e(Ls,BG),e(BG,bCo),e(Ls,vCo),e(Ls,IG),e(IG,FCo),e(Ls,TCo),e(k,MCo),e(k,Xu),e(Xu,C_e),e(C_e,ECo),e(Xu,CCo),e(Xu,NG),e(NG,wCo),e(Xu,ACo),e(k,LCo),e(k,zu),e(zu,w_e),e(w_e,yCo),e(zu,xCo),e(zu,qG),e(qG,$Co),e(zu,kCo),e(k,SCo),e(k,Qu),e(Qu,A_e),e(A_e,RCo),e(Qu,PCo),e(Qu,jG),e(jG,BCo),e(Qu,ICo),e(k,NCo),e(k,ys),e(ys,L_e),e(L_e,qCo),e(ys,jCo),e(ys,DG),e(DG,DCo),e(ys,GCo),e(ys,GG),e(GG,OCo),e(ys,VCo),e(k,XCo),e(k,Wu),e(Wu,y_e),e(y_e,zCo),e(Wu,QCo),e(Wu,OG),e(OG,WCo),e(Wu,UCo),e(k,HCo),e(k,xs),e(xs,x_e),e(x_e,JCo),e(xs,YCo),e(xs,VG),e(VG,ZCo),e(xs,KCo),e(xs,XG),e(XG,e3o),e(xs,o3o),e(k,r3o),e(k,$s),e($s,$_e),e($_e,t3o),e($s,a3o),e($s,zG),e(zG,n3o),e($s,s3o),e($s,QG),e(QG,l3o),e($s,i3o),e(k,d3o),e(k,ks),e(ks,k_e),e(k_e,m3o),e(ks,c3o),e(ks,WG),e(WG,f3o),e(ks,g3o),e(ks,UG),e(UG,h3o),e(ks,u3o),e(k,p3o),e(k,Ss),e(Ss,S_e),e(S_e,_3o),e(Ss,b3o),e(Ss,HG),e(HG,v3o),e(Ss,F3o),e(Ss,JG),e(JG,T3o),e(Ss,M3o),e(k,E3o),e(k,Rs),e(Rs,R_e),e(R_e,C3o),e(Rs,w3o),e(Rs,YG),e(YG,A3o),e(Rs,L3o),e(Rs,ZG),e(ZG,y3o),e(Rs,x3o),e(k,$3o),e(k,Uu),e(Uu,P_e),e(P_e,k3o),e(Uu,S3o),e(Uu,KG),e(KG,R3o),e(Uu,P3o),e(k,B3o),e(k,Ps),e(Ps,B_e),e(B_e,I3o),e(Ps,N3o),e(Ps,eO),e(eO,q3o),e(Ps,j3o),e(Ps,oO),e(oO,D3o),e(Ps,G3o),e(k,O3o),e(k,Bs),e(Bs,I_e),e(I_e,V3o),e(Bs,X3o),e(Bs,rO),e(rO,z3o),e(Bs,Q3o),e(Bs,tO),e(tO,W3o),e(Bs,U3o),e(k,H3o),e(k,Is),e(Is,N_e),e(N_e,J3o),e(Is,Y3o),e(Is,aO),e(aO,Z3o),e(Is,K3o),e(Is,nO),e(nO,e5o),e(Is,o5o),e(k,r5o),e(k,Ns),e(Ns,q_e),e(q_e,t5o),e(Ns,a5o),e(Ns,sO),e(sO,n5o),e(Ns,s5o),e(Ns,lO),e(lO,l5o),e(Ns,i5o),e(k,d5o),e(k,qs),e(qs,j_e),e(j_e,m5o),e(qs,c5o),e(qs,iO),e(iO,f5o),e(qs,g5o),e(qs,dO),e(dO,h5o),e(qs,u5o),e(k,p5o),e(k,js),e(js,D_e),e(D_e,_5o),e(js,b5o),e(js,mO),e(mO,v5o),e(js,F5o),e(js,cO),e(cO,T5o),e(js,M5o),e(k,E5o),e(k,Ds),e(Ds,G_e),e(G_e,C5o),e(Ds,w5o),e(Ds,fO),e(fO,A5o),e(Ds,L5o),e(Ds,gO),e(gO,y5o),e(Ds,x5o),e(k,$5o),e(k,Hu),e(Hu,O_e),e(O_e,k5o),e(Hu,S5o),e(Hu,hO),e(hO,R5o),e(Hu,P5o),e(k,B5o),e(k,Ju),e(Ju,V_e),e(V_e,I5o),e(Ju,N5o),e(Ju,uO),e(uO,q5o),e(Ju,j5o),e(k,D5o),e(k,Gs),e(Gs,X_e),e(X_e,G5o),e(Gs,O5o),e(Gs,pO),e(pO,V5o),e(Gs,X5o),e(Gs,_O),e(_O,z5o),e(Gs,Q5o),e(k,W5o),e(k,Yu),e(Yu,z_e),e(z_e,U5o),e(Yu,H5o),e(Yu,bO),e(bO,J5o),e(Yu,Y5o),e(k,Z5o),e(k,Os),e(Os,Q_e),e(Q_e,K5o),e(Os,e0o),e(Os,vO),e(vO,o0o),e(Os,r0o),e(Os,FO),e(FO,t0o),e(Os,a0o),e(k,n0o),e(k,Vs),e(Vs,W_e),e(W_e,s0o),e(Vs,l0o),e(Vs,TO),e(TO,i0o),e(Vs,d0o),e(Vs,MO),e(MO,m0o),e(Vs,c0o),e(k,f0o),e(k,Xs),e(Xs,U_e),e(U_e,g0o),e(Xs,h0o),e(Xs,EO),e(EO,u0o),e(Xs,p0o),e(Xs,CO),e(CO,_0o),e(Xs,b0o),e(k,v0o),e(k,Zu),e(Zu,H_e),e(H_e,F0o),e(Zu,T0o),e(Zu,wO),e(wO,M0o),e(Zu,E0o),e(k,C0o),e(k,Ku),e(Ku,J_e),e(J_e,w0o),e(Ku,A0o),e(Ku,AO),e(AO,L0o),e(Ku,y0o),e(k,x0o),e(k,zs),e(zs,Y_e),e(Y_e,$0o),e(zs,k0o),e(zs,LO),e(LO,S0o),e(zs,R0o),e(zs,yO),e(yO,P0o),e(zs,B0o),e(k,I0o),e(k,Qs),e(Qs,Z_e),e(Z_e,N0o),e(Qs,q0o),e(Qs,xO),e(xO,j0o),e(Qs,D0o),e(Qs,$O),e($O,G0o),e(Qs,O0o),e(k,V0o),e(k,Ws),e(Ws,K_e),e(K_e,X0o),e(Ws,z0o),e(Ws,kO),e(kO,Q0o),e(Ws,W0o),e(Ws,SO),e(SO,U0o),e(Ws,H0o),e(k,J0o),e(k,ep),e(ep,e1e),e(e1e,Y0o),e(ep,Z0o),e(ep,RO),e(RO,K0o),e(ep,ewo),e(k,owo),e(k,Us),e(Us,o1e),e(o1e,rwo),e(Us,two),e(Us,PO),e(PO,awo),e(Us,nwo),e(Us,BO),e(BO,swo),e(Us,lwo),e(k,iwo),e(k,op),e(op,r1e),e(r1e,dwo),e(op,mwo),e(op,IO),e(IO,cwo),e(op,fwo),e(k,gwo),e(k,Hs),e(Hs,t1e),e(t1e,hwo),e(Hs,uwo),e(Hs,NO),e(NO,pwo),e(Hs,_wo),e(Hs,qO),e(qO,bwo),e(Hs,vwo),e(k,Fwo),e(k,Js),e(Js,a1e),e(a1e,Two),e(Js,Mwo),e(Js,jO),e(jO,Ewo),e(Js,Cwo),e(Js,DO),e(DO,wwo),e(Js,Awo),e(k,Lwo),e(k,Ys),e(Ys,n1e),e(n1e,ywo),e(Ys,xwo),e(Ys,GO),e(GO,$wo),e(Ys,kwo),e(Ys,OO),e(OO,Swo),e(Ys,Rwo),e(k,Pwo),e(k,Zs),e(Zs,s1e),e(s1e,Bwo),e(Zs,Iwo),e(Zs,VO),e(VO,Nwo),e(Zs,qwo),e(Zs,XO),e(XO,jwo),e(Zs,Dwo),e(k,Gwo),e(k,Ks),e(Ks,l1e),e(l1e,Owo),e(Ks,Vwo),e(Ks,zO),e(zO,Xwo),e(Ks,zwo),e(Ks,QO),e(QO,Qwo),e(Ks,Wwo),e(k,Uwo),e(k,el),e(el,i1e),e(i1e,Hwo),e(el,Jwo),e(el,WO),e(WO,Ywo),e(el,Zwo),e(el,UO),e(UO,Kwo),e(el,eAo),e(k,oAo),e(k,ol),e(ol,d1e),e(d1e,rAo),e(ol,tAo),e(ol,HO),e(HO,aAo),e(ol,nAo),e(ol,JO),e(JO,sAo),e(ol,lAo),e(k,iAo),e(k,rl),e(rl,m1e),e(m1e,dAo),e(rl,mAo),e(rl,YO),e(YO,cAo),e(rl,fAo),e(rl,ZO),e(ZO,gAo),e(rl,hAo),e(k,uAo),e(k,rp),e(rp,c1e),e(c1e,pAo),e(rp,_Ao),e(rp,KO),e(KO,bAo),e(rp,vAo),e(k,FAo),e(k,tl),e(tl,f1e),e(f1e,TAo),e(tl,MAo),e(tl,eV),e(eV,EAo),e(tl,CAo),e(tl,oV),e(oV,wAo),e(tl,AAo),e(k,LAo),e(k,tp),e(tp,g1e),e(g1e,yAo),e(tp,xAo),e(tp,rV),e(rV,$Ao),e(tp,kAo),e(k,SAo),e(k,ap),e(ap,h1e),e(h1e,RAo),e(ap,PAo),e(ap,tV),e(tV,BAo),e(ap,IAo),e(k,NAo),e(k,al),e(al,u1e),e(u1e,qAo),e(al,jAo),e(al,aV),e(aV,DAo),e(al,GAo),e(al,nV),e(nV,OAo),e(al,VAo),e(k,XAo),e(k,nl),e(nl,p1e),e(p1e,zAo),e(nl,QAo),e(nl,sV),e(sV,WAo),e(nl,UAo),e(nl,lV),e(lV,HAo),e(nl,JAo),e(k,YAo),e(k,sl),e(sl,_1e),e(_1e,ZAo),e(sl,KAo),e(sl,iV),e(iV,e6o),e(sl,o6o),e(sl,dV),e(dV,r6o),e(sl,t6o),e(k,a6o),e(k,np),e(np,b1e),e(b1e,n6o),e(np,s6o),e(np,mV),e(mV,l6o),e(np,i6o),e(k,d6o),e(k,ll),e(ll,v1e),e(v1e,m6o),e(ll,c6o),e(ll,cV),e(cV,f6o),e(ll,g6o),e(ll,fV),e(fV,h6o),e(ll,u6o),e(k,p6o),e(k,il),e(il,F1e),e(F1e,_6o),e(il,b6o),e(il,gV),e(gV,v6o),e(il,F6o),e(il,hV),e(hV,T6o),e(il,M6o),e(k,E6o),e(k,dl),e(dl,T1e),e(T1e,C6o),e(dl,w6o),e(dl,uV),e(uV,A6o),e(dl,L6o),e(dl,pV),e(pV,y6o),e(dl,x6o),e(k,$6o),e(k,ml),e(ml,M1e),e(M1e,k6o),e(ml,S6o),e(ml,_V),e(_V,R6o),e(ml,P6o),e(ml,bV),e(bV,B6o),e(ml,I6o),e(k,N6o),e(k,cl),e(cl,E1e),e(E1e,q6o),e(cl,j6o),e(cl,vV),e(vV,D6o),e(cl,G6o),e(cl,FV),e(FV,O6o),e(cl,V6o),e(k,X6o),e(k,fl),e(fl,C1e),e(C1e,z6o),e(fl,Q6o),e(fl,TV),e(TV,W6o),e(fl,U6o),e(fl,MV),e(MV,H6o),e(fl,J6o),e(k,Y6o),e(k,gl),e(gl,w1e),e(w1e,Z6o),e(gl,K6o),e(gl,EV),e(EV,e7o),e(gl,o7o),e(gl,CV),e(CV,r7o),e(gl,t7o),e(k,a7o),e(k,hl),e(hl,A1e),e(A1e,n7o),e(hl,s7o),e(hl,wV),e(wV,l7o),e(hl,i7o),e(hl,AV),e(AV,d7o),e(hl,m7o),e(k,c7o),e(k,sp),e(sp,L1e),e(L1e,f7o),e(sp,g7o),e(sp,LV),e(LV,h7o),e(sp,u7o),e(k,p7o),e(k,ul),e(ul,y1e),e(y1e,_7o),e(ul,b7o),e(ul,yV),e(yV,v7o),e(ul,F7o),e(ul,xV),e(xV,T7o),e(ul,M7o),e(k,E7o),e(k,pl),e(pl,x1e),e(x1e,C7o),e(pl,w7o),e(pl,$V),e($V,A7o),e(pl,L7o),e(pl,kV),e(kV,y7o),e(pl,x7o),e(k,$7o),e(k,_l),e(_l,$1e),e($1e,k7o),e(_l,S7o),e(_l,SV),e(SV,R7o),e(_l,P7o),e(_l,RV),e(RV,B7o),e(_l,I7o),e(k,N7o),e(k,lp),e(lp,k1e),e(k1e,q7o),e(lp,j7o),e(lp,PV),e(PV,D7o),e(lp,G7o),e(k,O7o),e(k,ip),e(ip,S1e),e(S1e,V7o),e(ip,X7o),e(ip,BV),e(BV,z7o),e(ip,Q7o),e(k,W7o),e(k,dp),e(dp,R1e),e(R1e,U7o),e(dp,H7o),e(dp,IV),e(IV,J7o),e(dp,Y7o),e(k,Z7o),e(k,mp),e(mp,P1e),e(P1e,K7o),e(mp,e8o),e(mp,NV),e(NV,o8o),e(mp,r8o),e(k,t8o),e(k,bl),e(bl,B1e),e(B1e,a8o),e(bl,n8o),e(bl,qV),e(qV,s8o),e(bl,l8o),e(bl,jV),e(jV,i8o),e(bl,d8o),e(k,m8o),e(k,cp),e(cp,I1e),e(I1e,c8o),e(cp,f8o),e(cp,DV),e(DV,g8o),e(cp,h8o),e(k,u8o),e(k,vl),e(vl,N1e),e(N1e,p8o),e(vl,_8o),e(vl,GV),e(GV,b8o),e(vl,v8o),e(vl,OV),e(OV,F8o),e(vl,T8o),e(k,M8o),e(k,Fl),e(Fl,q1e),e(q1e,E8o),e(Fl,C8o),e(Fl,VV),e(VV,w8o),e(Fl,A8o),e(Fl,XV),e(XV,L8o),e(Fl,y8o),e(k,x8o),e(k,Tl),e(Tl,j1e),e(j1e,$8o),e(Tl,k8o),e(Tl,zV),e(zV,S8o),e(Tl,R8o),e(Tl,QV),e(QV,P8o),e(Tl,B8o),e(k,I8o),e(k,Ml),e(Ml,D1e),e(D1e,N8o),e(Ml,q8o),e(Ml,WV),e(WV,j8o),e(Ml,D8o),e(Ml,UV),e(UV,G8o),e(Ml,O8o),e(k,V8o),e(k,El),e(El,G1e),e(G1e,X8o),e(El,z8o),e(El,HV),e(HV,Q8o),e(El,W8o),e(El,JV),e(JV,U8o),e(El,H8o),e(k,J8o),e(k,fp),e(fp,O1e),e(O1e,Y8o),e(fp,Z8o),e(fp,YV),e(YV,K8o),e(fp,eLo),e(k,oLo),e(k,Cl),e(Cl,V1e),e(V1e,rLo),e(Cl,tLo),e(Cl,ZV),e(ZV,aLo),e(Cl,nLo),e(Cl,KV),e(KV,sLo),e(Cl,lLo),e(k,iLo),e(k,gp),e(gp,X1e),e(X1e,dLo),e(gp,mLo),e(gp,eX),e(eX,cLo),e(gp,fLo),e(k,gLo),e(k,hp),e(hp,z1e),e(z1e,hLo),e(hp,uLo),e(hp,oX),e(oX,pLo),e(hp,_Lo),e(k,bLo),e(k,wl),e(wl,Q1e),e(Q1e,vLo),e(wl,FLo),e(wl,rX),e(rX,TLo),e(wl,MLo),e(wl,tX),e(tX,ELo),e(wl,CLo),e(k,wLo),e(k,Al),e(Al,W1e),e(W1e,ALo),e(Al,LLo),e(Al,aX),e(aX,yLo),e(Al,xLo),e(Al,nX),e(nX,$Lo),e(Al,kLo),e(k,SLo),e(k,Ll),e(Ll,U1e),e(U1e,RLo),e(Ll,PLo),e(Ll,sX),e(sX,BLo),e(Ll,ILo),e(Ll,lX),e(lX,NLo),e(Ll,qLo),e(k,jLo),e(k,up),e(up,H1e),e(H1e,DLo),e(up,GLo),e(up,iX),e(iX,OLo),e(up,VLo),e(k,XLo),e(k,pp),e(pp,J1e),e(J1e,zLo),e(pp,QLo),e(pp,dX),e(dX,WLo),e(pp,ULo),e(k,HLo),e(k,_p),e(_p,Y1e),e(Y1e,JLo),e(_p,YLo),e(_p,mX),e(mX,ZLo),e(_p,KLo),e(k,eyo),e(k,yl),e(yl,Z1e),e(Z1e,oyo),e(yl,ryo),e(yl,cX),e(cX,tyo),e(yl,ayo),e(yl,fX),e(fX,nyo),e(yl,syo),e(k,lyo),e(k,xl),e(xl,K1e),e(K1e,iyo),e(xl,dyo),e(xl,gX),e(gX,myo),e(xl,cyo),e(xl,hX),e(hX,fyo),e(xl,gyo),e(k,hyo),e(k,bp),e(bp,e2e),e(e2e,uyo),e(bp,pyo),e(bp,uX),e(uX,_yo),e(bp,byo),e(k,vyo),e(k,vp),e(vp,o2e),e(o2e,Fyo),e(vp,Tyo),e(vp,pX),e(pX,Myo),e(vp,Eyo),e(k,Cyo),e(k,Fp),e(Fp,r2e),e(r2e,wyo),e(Fp,Ayo),e(Fp,_X),e(_X,Lyo),e(Fp,yyo),e(k,xyo),e(k,Tp),e(Tp,t2e),e(t2e,$yo),e(Tp,kyo),e(Tp,bX),e(bX,Syo),e(Tp,Ryo),e(k,Pyo),e(k,$l),e($l,a2e),e(a2e,Byo),e($l,Iyo),e($l,vX),e(vX,Nyo),e($l,qyo),e($l,FX),e(FX,jyo),e($l,Dyo),e(k,Gyo),e(k,kl),e(kl,n2e),e(n2e,Oyo),e(kl,Vyo),e(kl,TX),e(TX,Xyo),e(kl,zyo),e(kl,MX),e(MX,Qyo),e(kl,Wyo),e(k,Uyo),e(k,Mp),e(Mp,s2e),e(s2e,Hyo),e(Mp,Jyo),e(Mp,EX),e(EX,Yyo),e(Mp,Zyo),e(k,Kyo),e(k,Ep),e(Ep,l2e),e(l2e,e9o),e(Ep,o9o),e(Ep,CX),e(CX,r9o),e(Ep,t9o),e(k,a9o),e(k,Sl),e(Sl,i2e),e(i2e,n9o),e(Sl,s9o),e(Sl,wX),e(wX,l9o),e(Sl,i9o),e(Sl,AX),e(AX,d9o),e(Sl,m9o),e(k,c9o),e(k,Rl),e(Rl,d2e),e(d2e,f9o),e(Rl,g9o),e(Rl,LX),e(LX,h9o),e(Rl,u9o),e(Rl,yX),e(yX,p9o),e(Rl,_9o),e(k,b9o),e(k,Pl),e(Pl,m2e),e(m2e,v9o),e(Pl,F9o),e(Pl,xX),e(xX,T9o),e(Pl,M9o),e(Pl,$X),e($X,E9o),e(Pl,C9o),e(k,w9o),e(k,Bl),e(Bl,c2e),e(c2e,A9o),e(Bl,L9o),e(Bl,kX),e(kX,y9o),e(Bl,x9o),e(Bl,SX),e(SX,$9o),e(Bl,k9o),e(Vr,S9o),M(Cp,Vr,null),e(Io,R9o),e(Io,wp),M(yk,wp,null),e(wp,P9o),e(wp,f2e),e(f2e,B9o),b(c,Nlo,_),b(c,Nd,_),e(Nd,Ap),e(Ap,g2e),M(xk,g2e,null),e(Nd,I9o),e(Nd,h2e),e(h2e,N9o),b(c,qlo,_),b(c,No,_),M($k,No,null),e(No,q9o),e(No,kk),e(kk,j9o),e(kk,RX),e(RX,D9o),e(kk,G9o),e(No,O9o),e(No,Sk),e(Sk,V9o),e(Sk,u2e),e(u2e,X9o),e(Sk,z9o),e(No,Q9o),e(No,eo),M(Rk,eo,null),e(eo,W9o),e(eo,p2e),e(p2e,U9o),e(eo,H9o),e(eo,mn),e(mn,J9o),e(mn,_2e),e(_2e,Y9o),e(mn,Z9o),e(mn,b2e),e(b2e,K9o),e(mn,exo),e(mn,v2e),e(v2e,oxo),e(mn,rxo),e(eo,txo),e(eo,z),e(z,Lp),e(Lp,F2e),e(F2e,axo),e(Lp,nxo),e(Lp,PX),e(PX,sxo),e(Lp,lxo),e(z,ixo),e(z,yp),e(yp,T2e),e(T2e,dxo),e(yp,mxo),e(yp,BX),e(BX,cxo),e(yp,fxo),e(z,gxo),e(z,xp),e(xp,M2e),e(M2e,hxo),e(xp,uxo),e(xp,IX),e(IX,pxo),e(xp,_xo),e(z,bxo),e(z,$p),e($p,E2e),e(E2e,vxo),e($p,Fxo),e($p,NX),e(NX,Txo),e($p,Mxo),e(z,Exo),e(z,kp),e(kp,C2e),e(C2e,Cxo),e(kp,wxo),e(kp,qX),e(qX,Axo),e(kp,Lxo),e(z,yxo),e(z,Sp),e(Sp,w2e),e(w2e,xxo),e(Sp,$xo),e(Sp,jX),e(jX,kxo),e(Sp,Sxo),e(z,Rxo),e(z,Rp),e(Rp,A2e),e(A2e,Pxo),e(Rp,Bxo),e(Rp,DX),e(DX,Ixo),e(Rp,Nxo),e(z,qxo),e(z,Pp),e(Pp,L2e),e(L2e,jxo),e(Pp,Dxo),e(Pp,GX),e(GX,Gxo),e(Pp,Oxo),e(z,Vxo),e(z,Bp),e(Bp,y2e),e(y2e,Xxo),e(Bp,zxo),e(Bp,OX),e(OX,Qxo),e(Bp,Wxo),e(z,Uxo),e(z,Ip),e(Ip,x2e),e(x2e,Hxo),e(Ip,Jxo),e(Ip,VX),e(VX,Yxo),e(Ip,Zxo),e(z,Kxo),e(z,Np),e(Np,$2e),e($2e,e$o),e(Np,o$o),e(Np,XX),e(XX,r$o),e(Np,t$o),e(z,a$o),e(z,qp),e(qp,k2e),e(k2e,n$o),e(qp,s$o),e(qp,zX),e(zX,l$o),e(qp,i$o),e(z,d$o),e(z,jp),e(jp,S2e),e(S2e,m$o),e(jp,c$o),e(jp,QX),e(QX,f$o),e(jp,g$o),e(z,h$o),e(z,Dp),e(Dp,R2e),e(R2e,u$o),e(Dp,p$o),e(Dp,WX),e(WX,_$o),e(Dp,b$o),e(z,v$o),e(z,Gp),e(Gp,P2e),e(P2e,F$o),e(Gp,T$o),e(Gp,UX),e(UX,M$o),e(Gp,E$o),e(z,C$o),e(z,Op),e(Op,B2e),e(B2e,w$o),e(Op,A$o),e(Op,HX),e(HX,L$o),e(Op,y$o),e(z,x$o),e(z,Vp),e(Vp,I2e),e(I2e,$$o),e(Vp,k$o),e(Vp,JX),e(JX,S$o),e(Vp,R$o),e(z,P$o),e(z,Xp),e(Xp,N2e),e(N2e,B$o),e(Xp,I$o),e(Xp,YX),e(YX,N$o),e(Xp,q$o),e(z,j$o),e(z,zp),e(zp,q2e),e(q2e,D$o),e(zp,G$o),e(zp,ZX),e(ZX,O$o),e(zp,V$o),e(z,X$o),e(z,Qp),e(Qp,j2e),e(j2e,z$o),e(Qp,Q$o),e(Qp,KX),e(KX,W$o),e(Qp,U$o),e(z,H$o),e(z,Wp),e(Wp,D2e),e(D2e,J$o),e(Wp,Y$o),e(Wp,ez),e(ez,Z$o),e(Wp,K$o),e(z,eko),e(z,Up),e(Up,G2e),e(G2e,oko),e(Up,rko),e(Up,oz),e(oz,tko),e(Up,ako),e(z,nko),e(z,Hp),e(Hp,O2e),e(O2e,sko),e(Hp,lko),e(Hp,rz),e(rz,iko),e(Hp,dko),e(z,mko),e(z,Jp),e(Jp,V2e),e(V2e,cko),e(Jp,fko),e(Jp,tz),e(tz,gko),e(Jp,hko),e(z,uko),e(z,Yp),e(Yp,X2e),e(X2e,pko),e(Yp,_ko),e(Yp,az),e(az,bko),e(Yp,vko),e(z,Fko),e(z,Zp),e(Zp,z2e),e(z2e,Tko),e(Zp,Mko),e(Zp,nz),e(nz,Eko),e(Zp,Cko),e(z,wko),e(z,Kp),e(Kp,Q2e),e(Q2e,Ako),e(Kp,Lko),e(Kp,sz),e(sz,yko),e(Kp,xko),e(z,$ko),e(z,e_),e(e_,W2e),e(W2e,kko),e(e_,Sko),e(e_,lz),e(lz,Rko),e(e_,Pko),e(z,Bko),e(z,o_),e(o_,U2e),e(U2e,Iko),e(o_,Nko),e(o_,iz),e(iz,qko),e(o_,jko),e(z,Dko),e(z,r_),e(r_,H2e),e(H2e,Gko),e(r_,Oko),e(r_,dz),e(dz,Vko),e(r_,Xko),e(z,zko),e(z,t_),e(t_,J2e),e(J2e,Qko),e(t_,Wko),e(t_,mz),e(mz,Uko),e(t_,Hko),e(z,Jko),e(z,a_),e(a_,Y2e),e(Y2e,Yko),e(a_,Zko),e(a_,cz),e(cz,Kko),e(a_,eSo),e(z,oSo),e(z,n_),e(n_,Z2e),e(Z2e,rSo),e(n_,tSo),e(n_,fz),e(fz,aSo),e(n_,nSo),e(z,sSo),e(z,s_),e(s_,K2e),e(K2e,lSo),e(s_,iSo),e(s_,gz),e(gz,dSo),e(s_,mSo),e(z,cSo),e(z,l_),e(l_,ebe),e(ebe,fSo),e(l_,gSo),e(l_,hz),e(hz,hSo),e(l_,uSo),e(z,pSo),e(z,i_),e(i_,obe),e(obe,_So),e(i_,bSo),e(i_,uz),e(uz,vSo),e(i_,FSo),e(z,TSo),e(z,d_),e(d_,rbe),e(rbe,MSo),e(d_,ESo),e(d_,pz),e(pz,CSo),e(d_,wSo),e(z,ASo),e(z,m_),e(m_,tbe),e(tbe,LSo),e(m_,ySo),e(m_,_z),e(_z,xSo),e(m_,$So),e(z,kSo),e(z,c_),e(c_,abe),e(abe,SSo),e(c_,RSo),e(c_,bz),e(bz,PSo),e(c_,BSo),e(z,ISo),e(z,f_),e(f_,nbe),e(nbe,NSo),e(f_,qSo),e(f_,vz),e(vz,jSo),e(f_,DSo),e(z,GSo),e(z,g_),e(g_,sbe),e(sbe,OSo),e(g_,VSo),e(g_,Fz),e(Fz,XSo),e(g_,zSo),e(z,QSo),e(z,h_),e(h_,lbe),e(lbe,WSo),e(h_,USo),e(h_,Tz),e(Tz,HSo),e(h_,JSo),e(z,YSo),e(z,u_),e(u_,ibe),e(ibe,ZSo),e(u_,KSo),e(u_,Mz),e(Mz,eRo),e(u_,oRo),e(z,rRo),e(z,p_),e(p_,dbe),e(dbe,tRo),e(p_,aRo),e(p_,Ez),e(Ez,nRo),e(p_,sRo),e(z,lRo),e(z,__),e(__,mbe),e(mbe,iRo),e(__,dRo),e(__,Cz),e(Cz,mRo),e(__,cRo),e(eo,fRo),M(b_,eo,null),e(eo,gRo),M(v_,eo,null),e(No,hRo),e(No,F_),M(Pk,F_,null),e(F_,uRo),e(F_,cbe),e(cbe,pRo),b(c,jlo,_),b(c,qd,_),e(qd,T_),e(T_,fbe),M(Bk,fbe,null),e(qd,_Ro),e(qd,gbe),e(gbe,bRo),b(c,Dlo,_),b(c,qo,_),M(Ik,qo,null),e(qo,vRo),e(qo,Nk),e(Nk,FRo),e(Nk,wz),e(wz,TRo),e(Nk,MRo),e(qo,ERo),e(qo,qk),e(qk,CRo),e(qk,hbe),e(hbe,wRo),e(qk,ARo),e(qo,LRo),e(qo,oo),M(jk,oo,null),e(oo,yRo),e(oo,ube),e(ube,xRo),e(oo,$Ro),e(oo,cn),e(cn,kRo),e(cn,pbe),e(pbe,SRo),e(cn,RRo),e(cn,_be),e(_be,PRo),e(cn,BRo),e(cn,bbe),e(bbe,IRo),e(cn,NRo),e(oo,qRo),e(oo,re),e(re,M_),e(M_,vbe),e(vbe,jRo),e(M_,DRo),e(M_,Az),e(Az,GRo),e(M_,ORo),e(re,VRo),e(re,E_),e(E_,Fbe),e(Fbe,XRo),e(E_,zRo),e(E_,Lz),e(Lz,QRo),e(E_,WRo),e(re,URo),e(re,C_),e(C_,Tbe),e(Tbe,HRo),e(C_,JRo),e(C_,yz),e(yz,YRo),e(C_,ZRo),e(re,KRo),e(re,w_),e(w_,Mbe),e(Mbe,ePo),e(w_,oPo),e(w_,xz),e(xz,rPo),e(w_,tPo),e(re,aPo),e(re,A_),e(A_,Ebe),e(Ebe,nPo),e(A_,sPo),e(A_,$z),e($z,lPo),e(A_,iPo),e(re,dPo),e(re,L_),e(L_,Cbe),e(Cbe,mPo),e(L_,cPo),e(L_,kz),e(kz,fPo),e(L_,gPo),e(re,hPo),e(re,y_),e(y_,wbe),e(wbe,uPo),e(y_,pPo),e(y_,Sz),e(Sz,_Po),e(y_,bPo),e(re,vPo),e(re,x_),e(x_,Abe),e(Abe,FPo),e(x_,TPo),e(x_,Rz),e(Rz,MPo),e(x_,EPo),e(re,CPo),e(re,$_),e($_,Lbe),e(Lbe,wPo),e($_,APo),e($_,Pz),e(Pz,LPo),e($_,yPo),e(re,xPo),e(re,k_),e(k_,ybe),e(ybe,$Po),e(k_,kPo),e(k_,Bz),e(Bz,SPo),e(k_,RPo),e(re,PPo),e(re,S_),e(S_,xbe),e(xbe,BPo),e(S_,IPo),e(S_,Iz),e(Iz,NPo),e(S_,qPo),e(re,jPo),e(re,R_),e(R_,$be),e($be,DPo),e(R_,GPo),e(R_,Nz),e(Nz,OPo),e(R_,VPo),e(re,XPo),e(re,P_),e(P_,kbe),e(kbe,zPo),e(P_,QPo),e(P_,qz),e(qz,WPo),e(P_,UPo),e(re,HPo),e(re,B_),e(B_,Sbe),e(Sbe,JPo),e(B_,YPo),e(B_,jz),e(jz,ZPo),e(B_,KPo),e(re,eBo),e(re,I_),e(I_,Rbe),e(Rbe,oBo),e(I_,rBo),e(I_,Dz),e(Dz,tBo),e(I_,aBo),e(re,nBo),e(re,N_),e(N_,Pbe),e(Pbe,sBo),e(N_,lBo),e(N_,Gz),e(Gz,iBo),e(N_,dBo),e(re,mBo),e(re,q_),e(q_,Bbe),e(Bbe,cBo),e(q_,fBo),e(q_,Oz),e(Oz,gBo),e(q_,hBo),e(re,uBo),e(re,j_),e(j_,Ibe),e(Ibe,pBo),e(j_,_Bo),e(j_,Vz),e(Vz,bBo),e(j_,vBo),e(re,FBo),e(re,D_),e(D_,Nbe),e(Nbe,TBo),e(D_,MBo),e(D_,Xz),e(Xz,EBo),e(D_,CBo),e(re,wBo),e(re,G_),e(G_,qbe),e(qbe,ABo),e(G_,LBo),e(G_,zz),e(zz,yBo),e(G_,xBo),e(re,$Bo),e(re,O_),e(O_,jbe),e(jbe,kBo),e(O_,SBo),e(O_,Qz),e(Qz,RBo),e(O_,PBo),e(re,BBo),e(re,V_),e(V_,Dbe),e(Dbe,IBo),e(V_,NBo),e(V_,Wz),e(Wz,qBo),e(V_,jBo),e(re,DBo),e(re,X_),e(X_,Gbe),e(Gbe,GBo),e(X_,OBo),e(X_,Uz),e(Uz,VBo),e(X_,XBo),e(re,zBo),e(re,z_),e(z_,Obe),e(Obe,QBo),e(z_,WBo),e(z_,Hz),e(Hz,UBo),e(z_,HBo),e(re,JBo),e(re,Q_),e(Q_,Vbe),e(Vbe,YBo),e(Q_,ZBo),e(Q_,Jz),e(Jz,KBo),e(Q_,eIo),e(re,oIo),e(re,W_),e(W_,Xbe),e(Xbe,rIo),e(W_,tIo),e(W_,Yz),e(Yz,aIo),e(W_,nIo),e(re,sIo),e(re,U_),e(U_,zbe),e(zbe,lIo),e(U_,iIo),e(U_,Zz),e(Zz,dIo),e(U_,mIo),e(re,cIo),e(re,H_),e(H_,Qbe),e(Qbe,fIo),e(H_,gIo),e(H_,Kz),e(Kz,hIo),e(H_,uIo),e(re,pIo),e(re,J_),e(J_,Wbe),e(Wbe,_Io),e(J_,bIo),e(J_,eQ),e(eQ,vIo),e(J_,FIo),e(oo,TIo),M(Y_,oo,null),e(oo,MIo),M(Z_,oo,null),e(qo,EIo),e(qo,K_),M(Dk,K_,null),e(K_,CIo),e(K_,Ube),e(Ube,wIo),b(c,Glo,_),b(c,jd,_),e(jd,e1),e(e1,Hbe),M(Gk,Hbe,null),e(jd,AIo),e(jd,Jbe),e(Jbe,LIo),b(c,Olo,_),b(c,jo,_),M(Ok,jo,null),e(jo,yIo),e(jo,Vk),e(Vk,xIo),e(Vk,oQ),e(oQ,$Io),e(Vk,kIo),e(jo,SIo),e(jo,Xk),e(Xk,RIo),e(Xk,Ybe),e(Ybe,PIo),e(Xk,BIo),e(jo,IIo),e(jo,ro),M(zk,ro,null),e(ro,NIo),e(ro,Zbe),e(Zbe,qIo),e(ro,jIo),e(ro,Dd),e(Dd,DIo),e(Dd,Kbe),e(Kbe,GIo),e(Dd,OIo),e(Dd,eve),e(eve,VIo),e(Dd,XIo),e(ro,zIo),e(ro,ie),e(ie,o1),e(o1,ove),e(ove,QIo),e(o1,WIo),e(o1,rQ),e(rQ,UIo),e(o1,HIo),e(ie,JIo),e(ie,r1),e(r1,rve),e(rve,YIo),e(r1,ZIo),e(r1,tQ),e(tQ,KIo),e(r1,eNo),e(ie,oNo),e(ie,t1),e(t1,tve),e(tve,rNo),e(t1,tNo),e(t1,aQ),e(aQ,aNo),e(t1,nNo),e(ie,sNo),e(ie,a1),e(a1,ave),e(ave,lNo),e(a1,iNo),e(a1,nQ),e(nQ,dNo),e(a1,mNo),e(ie,cNo),e(ie,n1),e(n1,nve),e(nve,fNo),e(n1,gNo),e(n1,sQ),e(sQ,hNo),e(n1,uNo),e(ie,pNo),e(ie,s1),e(s1,sve),e(sve,_No),e(s1,bNo),e(s1,lQ),e(lQ,vNo),e(s1,FNo),e(ie,TNo),e(ie,l1),e(l1,lve),e(lve,MNo),e(l1,ENo),e(l1,iQ),e(iQ,CNo),e(l1,wNo),e(ie,ANo),e(ie,i1),e(i1,ive),e(ive,LNo),e(i1,yNo),e(i1,dQ),e(dQ,xNo),e(i1,$No),e(ie,kNo),e(ie,d1),e(d1,dve),e(dve,SNo),e(d1,RNo),e(d1,mQ),e(mQ,PNo),e(d1,BNo),e(ie,INo),e(ie,m1),e(m1,mve),e(mve,NNo),e(m1,qNo),e(m1,cQ),e(cQ,jNo),e(m1,DNo),e(ie,GNo),e(ie,c1),e(c1,cve),e(cve,ONo),e(c1,VNo),e(c1,fQ),e(fQ,XNo),e(c1,zNo),e(ie,QNo),e(ie,f1),e(f1,fve),e(fve,WNo),e(f1,UNo),e(f1,gQ),e(gQ,HNo),e(f1,JNo),e(ie,YNo),e(ie,g1),e(g1,gve),e(gve,ZNo),e(g1,KNo),e(g1,hQ),e(hQ,eqo),e(g1,oqo),e(ie,rqo),e(ie,h1),e(h1,hve),e(hve,tqo),e(h1,aqo),e(h1,uQ),e(uQ,nqo),e(h1,sqo),e(ie,lqo),e(ie,u1),e(u1,uve),e(uve,iqo),e(u1,dqo),e(u1,pQ),e(pQ,mqo),e(u1,cqo),e(ie,fqo),e(ie,p1),e(p1,pve),e(pve,gqo),e(p1,hqo),e(p1,_Q),e(_Q,uqo),e(p1,pqo),e(ie,_qo),e(ie,_1),e(_1,_ve),e(_ve,bqo),e(_1,vqo),e(_1,bQ),e(bQ,Fqo),e(_1,Tqo),e(ie,Mqo),e(ie,b1),e(b1,bve),e(bve,Eqo),e(b1,Cqo),e(b1,vQ),e(vQ,wqo),e(b1,Aqo),e(ie,Lqo),e(ie,v1),e(v1,vve),e(vve,yqo),e(v1,xqo),e(v1,FQ),e(FQ,$qo),e(v1,kqo),e(ie,Sqo),e(ie,F1),e(F1,Fve),e(Fve,Rqo),e(F1,Pqo),e(F1,TQ),e(TQ,Bqo),e(F1,Iqo),e(ie,Nqo),e(ie,T1),e(T1,Tve),e(Tve,qqo),e(T1,jqo),e(T1,MQ),e(MQ,Dqo),e(T1,Gqo),e(ie,Oqo),e(ie,M1),e(M1,Mve),e(Mve,Vqo),e(M1,Xqo),e(M1,EQ),e(EQ,zqo),e(M1,Qqo),e(ie,Wqo),e(ie,E1),e(E1,Eve),e(Eve,Uqo),e(E1,Hqo),e(E1,CQ),e(CQ,Jqo),e(E1,Yqo),e(ro,Zqo),M(C1,ro,null),e(ro,Kqo),M(w1,ro,null),e(jo,ejo),e(jo,A1),M(Qk,A1,null),e(A1,ojo),e(A1,Cve),e(Cve,rjo),b(c,Vlo,_),b(c,Gd,_),e(Gd,L1),e(L1,wve),M(Wk,wve,null),e(Gd,tjo),e(Gd,Ave),e(Ave,ajo),b(c,Xlo,_),b(c,Do,_),M(Uk,Do,null),e(Do,njo),e(Do,Od),e(Od,sjo),e(Od,wQ),e(wQ,ljo),e(Od,ijo),e(Od,AQ),e(AQ,djo),e(Od,mjo),e(Do,cjo),e(Do,Hk),e(Hk,fjo),e(Hk,Lve),e(Lve,gjo),e(Hk,hjo),e(Do,ujo),e(Do,At),M(Jk,At,null),e(At,pjo),e(At,yve),e(yve,_jo),e(At,bjo),e(At,Vd),e(Vd,vjo),e(Vd,xve),e(xve,Fjo),e(Vd,Tjo),e(Vd,LQ),e(LQ,Mjo),e(Vd,Ejo),e(At,Cjo),M(y1,At,null),e(Do,wjo),e(Do,to),M(Yk,to,null),e(to,Ajo),e(to,$ve),e($ve,Ljo),e(to,yjo),e(to,fn),e(fn,xjo),e(fn,kve),e(kve,$jo),e(fn,kjo),e(fn,Sve),e(Sve,Sjo),e(fn,Rjo),e(fn,Rve),e(Rve,Pjo),e(fn,Bjo),e(to,Ijo),e(to,y),e(y,x1),e(x1,Pve),e(Pve,Njo),e(x1,qjo),e(x1,yQ),e(yQ,jjo),e(x1,Djo),e(y,Gjo),e(y,$1),e($1,Bve),e(Bve,Ojo),e($1,Vjo),e($1,xQ),e(xQ,Xjo),e($1,zjo),e(y,Qjo),e(y,k1),e(k1,Ive),e(Ive,Wjo),e(k1,Ujo),e(k1,$Q),e($Q,Hjo),e(k1,Jjo),e(y,Yjo),e(y,S1),e(S1,Nve),e(Nve,Zjo),e(S1,Kjo),e(S1,kQ),e(kQ,eDo),e(S1,oDo),e(y,rDo),e(y,R1),e(R1,qve),e(qve,tDo),e(R1,aDo),e(R1,SQ),e(SQ,nDo),e(R1,sDo),e(y,lDo),e(y,P1),e(P1,jve),e(jve,iDo),e(P1,dDo),e(P1,RQ),e(RQ,mDo),e(P1,cDo),e(y,fDo),e(y,B1),e(B1,Dve),e(Dve,gDo),e(B1,hDo),e(B1,PQ),e(PQ,uDo),e(B1,pDo),e(y,_Do),e(y,I1),e(I1,Gve),e(Gve,bDo),e(I1,vDo),e(I1,BQ),e(BQ,FDo),e(I1,TDo),e(y,MDo),e(y,N1),e(N1,Ove),e(Ove,EDo),e(N1,CDo),e(N1,IQ),e(IQ,wDo),e(N1,ADo),e(y,LDo),e(y,q1),e(q1,Vve),e(Vve,yDo),e(q1,xDo),e(q1,NQ),e(NQ,$Do),e(q1,kDo),e(y,SDo),e(y,j1),e(j1,Xve),e(Xve,RDo),e(j1,PDo),e(j1,qQ),e(qQ,BDo),e(j1,IDo),e(y,NDo),e(y,D1),e(D1,zve),e(zve,qDo),e(D1,jDo),e(D1,jQ),e(jQ,DDo),e(D1,GDo),e(y,ODo),e(y,G1),e(G1,Qve),e(Qve,VDo),e(G1,XDo),e(G1,DQ),e(DQ,zDo),e(G1,QDo),e(y,WDo),e(y,O1),e(O1,Wve),e(Wve,UDo),e(O1,HDo),e(O1,GQ),e(GQ,JDo),e(O1,YDo),e(y,ZDo),e(y,V1),e(V1,Uve),e(Uve,KDo),e(V1,eGo),e(V1,OQ),e(OQ,oGo),e(V1,rGo),e(y,tGo),e(y,X1),e(X1,Hve),e(Hve,aGo),e(X1,nGo),e(X1,VQ),e(VQ,sGo),e(X1,lGo),e(y,iGo),e(y,z1),e(z1,Jve),e(Jve,dGo),e(z1,mGo),e(z1,XQ),e(XQ,cGo),e(z1,fGo),e(y,gGo),e(y,Q1),e(Q1,Yve),e(Yve,hGo),e(Q1,uGo),e(Q1,zQ),e(zQ,pGo),e(Q1,_Go),e(y,bGo),e(y,W1),e(W1,Zve),e(Zve,vGo),e(W1,FGo),e(W1,QQ),e(QQ,TGo),e(W1,MGo),e(y,EGo),e(y,U1),e(U1,Kve),e(Kve,CGo),e(U1,wGo),e(U1,WQ),e(WQ,AGo),e(U1,LGo),e(y,yGo),e(y,H1),e(H1,eFe),e(eFe,xGo),e(H1,$Go),e(H1,UQ),e(UQ,kGo),e(H1,SGo),e(y,RGo),e(y,J1),e(J1,oFe),e(oFe,PGo),e(J1,BGo),e(J1,HQ),e(HQ,IGo),e(J1,NGo),e(y,qGo),e(y,Y1),e(Y1,rFe),e(rFe,jGo),e(Y1,DGo),e(Y1,JQ),e(JQ,GGo),e(Y1,OGo),e(y,VGo),e(y,Z1),e(Z1,tFe),e(tFe,XGo),e(Z1,zGo),e(Z1,YQ),e(YQ,QGo),e(Z1,WGo),e(y,UGo),e(y,K1),e(K1,aFe),e(aFe,HGo),e(K1,JGo),e(K1,ZQ),e(ZQ,YGo),e(K1,ZGo),e(y,KGo),e(y,e2),e(e2,nFe),e(nFe,eOo),e(e2,oOo),e(e2,KQ),e(KQ,rOo),e(e2,tOo),e(y,aOo),e(y,o2),e(o2,sFe),e(sFe,nOo),e(o2,sOo),e(o2,eW),e(eW,lOo),e(o2,iOo),e(y,dOo),e(y,r2),e(r2,lFe),e(lFe,mOo),e(r2,cOo),e(r2,oW),e(oW,fOo),e(r2,gOo),e(y,hOo),e(y,t2),e(t2,iFe),e(iFe,uOo),e(t2,pOo),e(t2,rW),e(rW,_Oo),e(t2,bOo),e(y,vOo),e(y,a2),e(a2,dFe),e(dFe,FOo),e(a2,TOo),e(a2,tW),e(tW,MOo),e(a2,EOo),e(y,COo),e(y,n2),e(n2,mFe),e(mFe,wOo),e(n2,AOo),e(n2,aW),e(aW,LOo),e(n2,yOo),e(y,xOo),e(y,s2),e(s2,cFe),e(cFe,$Oo),e(s2,kOo),e(s2,nW),e(nW,SOo),e(s2,ROo),e(y,POo),e(y,l2),e(l2,fFe),e(fFe,BOo),e(l2,IOo),e(l2,sW),e(sW,NOo),e(l2,qOo),e(y,jOo),e(y,i2),e(i2,gFe),e(gFe,DOo),e(i2,GOo),e(i2,lW),e(lW,OOo),e(i2,VOo),e(y,XOo),e(y,d2),e(d2,hFe),e(hFe,zOo),e(d2,QOo),e(d2,iW),e(iW,WOo),e(d2,UOo),e(y,HOo),e(y,m2),e(m2,uFe),e(uFe,JOo),e(m2,YOo),e(m2,dW),e(dW,ZOo),e(m2,KOo),e(y,eVo),e(y,c2),e(c2,pFe),e(pFe,oVo),e(c2,rVo),e(c2,mW),e(mW,tVo),e(c2,aVo),e(y,nVo),e(y,f2),e(f2,_Fe),e(_Fe,sVo),e(f2,lVo),e(f2,cW),e(cW,iVo),e(f2,dVo),e(y,mVo),e(y,g2),e(g2,bFe),e(bFe,cVo),e(g2,fVo),e(g2,fW),e(fW,gVo),e(g2,hVo),e(y,uVo),e(y,h2),e(h2,vFe),e(vFe,pVo),e(h2,_Vo),e(h2,gW),e(gW,bVo),e(h2,vVo),e(y,FVo),e(y,Il),e(Il,FFe),e(FFe,TVo),e(Il,MVo),e(Il,hW),e(hW,EVo),e(Il,CVo),e(Il,uW),e(uW,wVo),e(Il,AVo),e(y,LVo),e(y,u2),e(u2,TFe),e(TFe,yVo),e(u2,xVo),e(u2,pW),e(pW,$Vo),e(u2,kVo),e(y,SVo),e(y,p2),e(p2,MFe),e(MFe,RVo),e(p2,PVo),e(p2,_W),e(_W,BVo),e(p2,IVo),e(y,NVo),e(y,_2),e(_2,EFe),e(EFe,qVo),e(_2,jVo),e(_2,bW),e(bW,DVo),e(_2,GVo),e(y,OVo),e(y,b2),e(b2,CFe),e(CFe,VVo),e(b2,XVo),e(b2,vW),e(vW,zVo),e(b2,QVo),e(y,WVo),e(y,v2),e(v2,wFe),e(wFe,UVo),e(v2,HVo),e(v2,FW),e(FW,JVo),e(v2,YVo),e(y,ZVo),e(y,F2),e(F2,AFe),e(AFe,KVo),e(F2,eXo),e(F2,TW),e(TW,oXo),e(F2,rXo),e(y,tXo),e(y,T2),e(T2,LFe),e(LFe,aXo),e(T2,nXo),e(T2,MW),e(MW,sXo),e(T2,lXo),e(y,iXo),e(y,M2),e(M2,yFe),e(yFe,dXo),e(M2,mXo),e(M2,EW),e(EW,cXo),e(M2,fXo),e(y,gXo),e(y,E2),e(E2,xFe),e(xFe,hXo),e(E2,uXo),e(E2,CW),e(CW,pXo),e(E2,_Xo),e(y,bXo),e(y,C2),e(C2,$Fe),e($Fe,vXo),e(C2,FXo),e(C2,wW),e(wW,TXo),e(C2,MXo),e(y,EXo),e(y,w2),e(w2,kFe),e(kFe,CXo),e(w2,wXo),e(w2,AW),e(AW,AXo),e(w2,LXo),e(y,yXo),e(y,A2),e(A2,SFe),e(SFe,xXo),e(A2,$Xo),e(A2,LW),e(LW,kXo),e(A2,SXo),e(y,RXo),e(y,L2),e(L2,RFe),e(RFe,PXo),e(L2,BXo),e(L2,yW),e(yW,IXo),e(L2,NXo),e(y,qXo),e(y,y2),e(y2,PFe),e(PFe,jXo),e(y2,DXo),e(y2,xW),e(xW,GXo),e(y2,OXo),e(y,VXo),e(y,x2),e(x2,BFe),e(BFe,XXo),e(x2,zXo),e(x2,$W),e($W,QXo),e(x2,WXo),e(y,UXo),e(y,$2),e($2,IFe),e(IFe,HXo),e($2,JXo),e($2,kW),e(kW,YXo),e($2,ZXo),e(y,KXo),e(y,k2),e(k2,NFe),e(NFe,ezo),e(k2,ozo),e(k2,SW),e(SW,rzo),e(k2,tzo),e(y,azo),e(y,S2),e(S2,qFe),e(qFe,nzo),e(S2,szo),e(S2,RW),e(RW,lzo),e(S2,izo),e(y,dzo),e(y,R2),e(R2,jFe),e(jFe,mzo),e(R2,czo),e(R2,PW),e(PW,fzo),e(R2,gzo),e(y,hzo),e(y,P2),e(P2,DFe),e(DFe,uzo),e(P2,pzo),e(P2,BW),e(BW,_zo),e(P2,bzo),e(y,vzo),e(y,B2),e(B2,GFe),e(GFe,Fzo),e(B2,Tzo),e(B2,IW),e(IW,Mzo),e(B2,Ezo),e(y,Czo),e(y,I2),e(I2,OFe),e(OFe,wzo),e(I2,Azo),e(I2,NW),e(NW,Lzo),e(I2,yzo),e(y,xzo),e(y,N2),e(N2,VFe),e(VFe,$zo),e(N2,kzo),e(N2,qW),e(qW,Szo),e(N2,Rzo),e(y,Pzo),e(y,q2),e(q2,XFe),e(XFe,Bzo),e(q2,Izo),e(q2,jW),e(jW,Nzo),e(q2,qzo),e(y,jzo),e(y,j2),e(j2,zFe),e(zFe,Dzo),e(j2,Gzo),e(j2,DW),e(DW,Ozo),e(j2,Vzo),e(y,Xzo),e(y,D2),e(D2,QFe),e(QFe,zzo),e(D2,Qzo),e(D2,GW),e(GW,Wzo),e(D2,Uzo),e(y,Hzo),e(y,G2),e(G2,WFe),e(WFe,Jzo),e(G2,Yzo),e(G2,OW),e(OW,Zzo),e(G2,Kzo),e(y,eQo),e(y,O2),e(O2,UFe),e(UFe,oQo),e(O2,rQo),e(O2,VW),e(VW,tQo),e(O2,aQo),e(y,nQo),e(y,V2),e(V2,HFe),e(HFe,sQo),e(V2,lQo),e(V2,XW),e(XW,iQo),e(V2,dQo),e(y,mQo),e(y,X2),e(X2,JFe),e(JFe,cQo),e(X2,fQo),e(X2,zW),e(zW,gQo),e(X2,hQo),e(y,uQo),e(y,z2),e(z2,YFe),e(YFe,pQo),e(z2,_Qo),e(z2,QW),e(QW,bQo),e(z2,vQo),e(y,FQo),e(y,Q2),e(Q2,ZFe),e(ZFe,TQo),e(Q2,MQo),e(Q2,WW),e(WW,EQo),e(Q2,CQo),e(y,wQo),e(y,W2),e(W2,KFe),e(KFe,AQo),e(W2,LQo),e(W2,UW),e(UW,yQo),e(W2,xQo),e(y,$Qo),e(y,U2),e(U2,eTe),e(eTe,kQo),e(U2,SQo),e(U2,HW),e(HW,RQo),e(U2,PQo),e(y,BQo),e(y,H2),e(H2,oTe),e(oTe,IQo),e(H2,NQo),e(H2,JW),e(JW,qQo),e(H2,jQo),e(y,DQo),e(y,J2),e(J2,rTe),e(rTe,GQo),e(J2,OQo),e(J2,YW),e(YW,VQo),e(J2,XQo),e(y,zQo),e(y,Y2),e(Y2,tTe),e(tTe,QQo),e(Y2,WQo),e(Y2,ZW),e(ZW,UQo),e(Y2,HQo),e(y,JQo),e(y,Z2),e(Z2,aTe),e(aTe,YQo),e(Z2,ZQo),e(Z2,KW),e(KW,KQo),e(Z2,eWo),e(y,oWo),e(y,K2),e(K2,nTe),e(nTe,rWo),e(K2,tWo),e(K2,eU),e(eU,aWo),e(K2,nWo),e(y,sWo),e(y,eb),e(eb,sTe),e(sTe,lWo),e(eb,iWo),e(eb,oU),e(oU,dWo),e(eb,mWo),e(y,cWo),e(y,ob),e(ob,lTe),e(lTe,fWo),e(ob,gWo),e(ob,rU),e(rU,hWo),e(ob,uWo),e(y,pWo),e(y,rb),e(rb,iTe),e(iTe,_Wo),e(rb,bWo),e(rb,tU),e(tU,vWo),e(rb,FWo),e(y,TWo),e(y,tb),e(tb,dTe),e(dTe,MWo),e(tb,EWo),e(tb,aU),e(aU,CWo),e(tb,wWo),e(y,AWo),e(y,ab),e(ab,mTe),e(mTe,LWo),e(ab,yWo),e(ab,nU),e(nU,xWo),e(ab,$Wo),e(y,kWo),e(y,nb),e(nb,cTe),e(cTe,SWo),e(nb,RWo),e(nb,sU),e(sU,PWo),e(nb,BWo),e(y,IWo),e(y,sb),e(sb,fTe),e(fTe,NWo),e(sb,qWo),e(sb,lU),e(lU,jWo),e(sb,DWo),e(y,GWo),e(y,lb),e(lb,gTe),e(gTe,OWo),e(lb,VWo),e(lb,iU),e(iU,XWo),e(lb,zWo),e(y,QWo),e(y,ib),e(ib,hTe),e(hTe,WWo),e(ib,UWo),e(ib,dU),e(dU,HWo),e(ib,JWo),e(y,YWo),e(y,db),e(db,uTe),e(uTe,ZWo),e(db,KWo),e(db,mU),e(mU,eUo),e(db,oUo),e(y,rUo),e(y,mb),e(mb,pTe),e(pTe,tUo),e(mb,aUo),e(mb,cU),e(cU,nUo),e(mb,sUo),e(y,lUo),e(y,cb),e(cb,_Te),e(_Te,iUo),e(cb,dUo),e(cb,fU),e(fU,mUo),e(cb,cUo),e(y,fUo),e(y,fb),e(fb,bTe),e(bTe,gUo),e(fb,hUo),e(fb,gU),e(gU,uUo),e(fb,pUo),e(y,_Uo),e(y,gb),e(gb,vTe),e(vTe,bUo),e(gb,vUo),e(gb,hU),e(hU,FUo),e(gb,TUo),e(y,MUo),e(y,hb),e(hb,FTe),e(FTe,EUo),e(hb,CUo),e(hb,uU),e(uU,wUo),e(hb,AUo),e(y,LUo),e(y,ub),e(ub,TTe),e(TTe,yUo),e(ub,xUo),e(ub,pU),e(pU,$Uo),e(ub,kUo),e(y,SUo),e(y,pb),e(pb,MTe),e(MTe,RUo),e(pb,PUo),e(pb,_U),e(_U,BUo),e(pb,IUo),e(y,NUo),e(y,_b),e(_b,ETe),e(ETe,qUo),e(_b,jUo),e(_b,bU),e(bU,DUo),e(_b,GUo),e(y,OUo),e(y,bb),e(bb,CTe),e(CTe,VUo),e(bb,XUo),e(bb,vU),e(vU,zUo),e(bb,QUo),e(y,WUo),e(y,vb),e(vb,wTe),e(wTe,UUo),e(vb,HUo),e(vb,FU),e(FU,JUo),e(vb,YUo),e(y,ZUo),e(y,Fb),e(Fb,ATe),e(ATe,KUo),e(Fb,eHo),e(Fb,TU),e(TU,oHo),e(Fb,rHo),e(y,tHo),e(y,Tb),e(Tb,LTe),e(LTe,aHo),e(Tb,nHo),e(Tb,MU),e(MU,sHo),e(Tb,lHo),e(y,iHo),e(y,Mb),e(Mb,yTe),e(yTe,dHo),e(Mb,mHo),e(Mb,EU),e(EU,cHo),e(Mb,fHo),e(y,gHo),e(y,Eb),e(Eb,xTe),e(xTe,hHo),e(Eb,uHo),e(Eb,CU),e(CU,pHo),e(Eb,_Ho),e(y,bHo),e(y,Cb),e(Cb,$Te),e($Te,vHo),e(Cb,FHo),e(Cb,wU),e(wU,THo),e(Cb,MHo),e(y,EHo),e(y,wb),e(wb,kTe),e(kTe,CHo),e(wb,wHo),e(wb,AU),e(AU,AHo),e(wb,LHo),e(y,yHo),e(y,Ab),e(Ab,STe),e(STe,xHo),e(Ab,$Ho),e(Ab,LU),e(LU,kHo),e(Ab,SHo),e(y,RHo),e(y,Lb),e(Lb,RTe),e(RTe,PHo),e(Lb,BHo),e(Lb,yU),e(yU,IHo),e(Lb,NHo),e(y,qHo),e(y,yb),e(yb,PTe),e(PTe,jHo),e(yb,DHo),e(yb,xU),e(xU,GHo),e(yb,OHo),e(y,VHo),e(y,xb),e(xb,BTe),e(BTe,XHo),e(xb,zHo),e(xb,$U),e($U,QHo),e(xb,WHo),e(y,UHo),e(y,$b),e($b,ITe),e(ITe,HHo),e($b,JHo),e($b,kU),e(kU,YHo),e($b,ZHo),e(y,KHo),e(y,kb),e(kb,NTe),e(NTe,eJo),e(kb,oJo),e(kb,SU),e(SU,rJo),e(kb,tJo),e(y,aJo),e(y,Sb),e(Sb,qTe),e(qTe,nJo),e(Sb,sJo),e(Sb,RU),e(RU,lJo),e(Sb,iJo),e(y,dJo),e(y,Rb),e(Rb,jTe),e(jTe,mJo),e(Rb,cJo),e(Rb,PU),e(PU,fJo),e(Rb,gJo),e(y,hJo),e(y,Pb),e(Pb,DTe),e(DTe,uJo),e(Pb,pJo),e(Pb,BU),e(BU,_Jo),e(Pb,bJo),e(y,vJo),e(y,Bb),e(Bb,GTe),e(GTe,FJo),e(Bb,TJo),e(Bb,IU),e(IU,MJo),e(Bb,EJo),e(y,CJo),e(y,Ib),e(Ib,OTe),e(OTe,wJo),e(Ib,AJo),e(Ib,NU),e(NU,LJo),e(Ib,yJo),e(y,xJo),e(y,Nb),e(Nb,VTe),e(VTe,$Jo),e(Nb,kJo),e(Nb,qU),e(qU,SJo),e(Nb,RJo),e(y,PJo),e(y,qb),e(qb,XTe),e(XTe,BJo),e(qb,IJo),e(qb,jU),e(jU,NJo),e(qb,qJo),e(y,jJo),e(y,jb),e(jb,zTe),e(zTe,DJo),e(jb,GJo),e(jb,DU),e(DU,OJo),e(jb,VJo),e(y,XJo),e(y,Db),e(Db,QTe),e(QTe,zJo),e(Db,QJo),e(Db,GU),e(GU,WJo),e(Db,UJo),e(y,HJo),e(y,Gb),e(Gb,WTe),e(WTe,JJo),e(Gb,YJo),e(Gb,OU),e(OU,ZJo),e(Gb,KJo),e(y,eYo),e(y,Ob),e(Ob,UTe),e(UTe,oYo),e(Ob,rYo),e(Ob,VU),e(VU,tYo),e(Ob,aYo),e(y,nYo),e(y,Vb),e(Vb,HTe),e(HTe,sYo),e(Vb,lYo),e(Vb,XU),e(XU,iYo),e(Vb,dYo),e(y,mYo),e(y,Xb),e(Xb,JTe),e(JTe,cYo),e(Xb,fYo),e(Xb,zU),e(zU,gYo),e(Xb,hYo),e(y,uYo),e(y,zb),e(zb,YTe),e(YTe,pYo),e(zb,_Yo),e(zb,QU),e(QU,bYo),e(zb,vYo),e(y,FYo),e(y,Qb),e(Qb,ZTe),e(ZTe,TYo),e(Qb,MYo),e(Qb,WU),e(WU,EYo),e(Qb,CYo),e(y,wYo),e(y,Wb),e(Wb,KTe),e(KTe,AYo),e(Wb,LYo),e(Wb,UU),e(UU,yYo),e(Wb,xYo),e(y,$Yo),e(y,Ub),e(Ub,eMe),e(eMe,kYo),e(Ub,SYo),e(Ub,HU),e(HU,RYo),e(Ub,PYo),e(y,BYo),e(y,Hb),e(Hb,oMe),e(oMe,IYo),e(Hb,NYo),e(Hb,JU),e(JU,qYo),e(Hb,jYo),e(y,DYo),e(y,Jb),e(Jb,rMe),e(rMe,GYo),e(Jb,OYo),e(Jb,YU),e(YU,VYo),e(Jb,XYo),e(y,zYo),e(y,Yb),e(Yb,tMe),e(tMe,QYo),e(Yb,WYo),e(Yb,ZU),e(ZU,UYo),e(Yb,HYo),e(to,JYo),e(to,Zb),e(Zb,YYo),e(Zb,aMe),e(aMe,ZYo),e(Zb,KYo),e(Zb,nMe),e(nMe,eZo),e(to,oZo),M(Kb,to,null),b(c,zlo,_),b(c,Xd,_),e(Xd,ev),e(ev,sMe),M(Zk,sMe,null),e(Xd,rZo),e(Xd,lMe),e(lMe,tZo),b(c,Qlo,_),b(c,Go,_),M(Kk,Go,null),e(Go,aZo),e(Go,zd),e(zd,nZo),e(zd,KU),e(KU,sZo),e(zd,lZo),e(zd,eH),e(eH,iZo),e(zd,dZo),e(Go,mZo),e(Go,eS),e(eS,cZo),e(eS,iMe),e(iMe,fZo),e(eS,gZo),e(Go,hZo),e(Go,Lt),M(oS,Lt,null),e(Lt,uZo),e(Lt,dMe),e(dMe,pZo),e(Lt,_Zo),e(Lt,Qd),e(Qd,bZo),e(Qd,mMe),e(mMe,vZo),e(Qd,FZo),e(Qd,oH),e(oH,TZo),e(Qd,MZo),e(Lt,EZo),M(ov,Lt,null),e(Go,CZo),e(Go,ao),M(rS,ao,null),e(ao,wZo),e(ao,cMe),e(cMe,AZo),e(ao,LZo),e(ao,gn),e(gn,yZo),e(gn,fMe),e(fMe,xZo),e(gn,$Zo),e(gn,gMe),e(gMe,kZo),e(gn,SZo),e(gn,hMe),e(hMe,RZo),e(gn,PZo),e(ao,BZo),e(ao,G),e(G,rv),e(rv,uMe),e(uMe,IZo),e(rv,NZo),e(rv,rH),e(rH,qZo),e(rv,jZo),e(G,DZo),e(G,tv),e(tv,pMe),e(pMe,GZo),e(tv,OZo),e(tv,tH),e(tH,VZo),e(tv,XZo),e(G,zZo),e(G,av),e(av,_Me),e(_Me,QZo),e(av,WZo),e(av,aH),e(aH,UZo),e(av,HZo),e(G,JZo),e(G,nv),e(nv,bMe),e(bMe,YZo),e(nv,ZZo),e(nv,nH),e(nH,KZo),e(nv,eKo),e(G,oKo),e(G,sv),e(sv,vMe),e(vMe,rKo),e(sv,tKo),e(sv,sH),e(sH,aKo),e(sv,nKo),e(G,sKo),e(G,lv),e(lv,FMe),e(FMe,lKo),e(lv,iKo),e(lv,lH),e(lH,dKo),e(lv,mKo),e(G,cKo),e(G,iv),e(iv,TMe),e(TMe,fKo),e(iv,gKo),e(iv,iH),e(iH,hKo),e(iv,uKo),e(G,pKo),e(G,dv),e(dv,MMe),e(MMe,_Ko),e(dv,bKo),e(dv,dH),e(dH,vKo),e(dv,FKo),e(G,TKo),e(G,mv),e(mv,EMe),e(EMe,MKo),e(mv,EKo),e(mv,mH),e(mH,CKo),e(mv,wKo),e(G,AKo),e(G,cv),e(cv,CMe),e(CMe,LKo),e(cv,yKo),e(cv,cH),e(cH,xKo),e(cv,$Ko),e(G,kKo),e(G,fv),e(fv,wMe),e(wMe,SKo),e(fv,RKo),e(fv,fH),e(fH,PKo),e(fv,BKo),e(G,IKo),e(G,gv),e(gv,AMe),e(AMe,NKo),e(gv,qKo),e(gv,gH),e(gH,jKo),e(gv,DKo),e(G,GKo),e(G,hv),e(hv,LMe),e(LMe,OKo),e(hv,VKo),e(hv,hH),e(hH,XKo),e(hv,zKo),e(G,QKo),e(G,uv),e(uv,yMe),e(yMe,WKo),e(uv,UKo),e(uv,uH),e(uH,HKo),e(uv,JKo),e(G,YKo),e(G,pv),e(pv,xMe),e(xMe,ZKo),e(pv,KKo),e(pv,pH),e(pH,eer),e(pv,oer),e(G,rer),e(G,_v),e(_v,$Me),e($Me,ter),e(_v,aer),e(_v,_H),e(_H,ner),e(_v,ser),e(G,ler),e(G,bv),e(bv,kMe),e(kMe,ier),e(bv,der),e(bv,bH),e(bH,mer),e(bv,cer),e(G,fer),e(G,vv),e(vv,SMe),e(SMe,ger),e(vv,her),e(vv,vH),e(vH,uer),e(vv,per),e(G,_er),e(G,Fv),e(Fv,RMe),e(RMe,ber),e(Fv,ver),e(Fv,FH),e(FH,Fer),e(Fv,Ter),e(G,Mer),e(G,Tv),e(Tv,PMe),e(PMe,Eer),e(Tv,Cer),e(Tv,TH),e(TH,wer),e(Tv,Aer),e(G,Ler),e(G,Mv),e(Mv,BMe),e(BMe,yer),e(Mv,xer),e(Mv,MH),e(MH,$er),e(Mv,ker),e(G,Ser),e(G,Ev),e(Ev,IMe),e(IMe,Rer),e(Ev,Per),e(Ev,EH),e(EH,Ber),e(Ev,Ier),e(G,Ner),e(G,Cv),e(Cv,NMe),e(NMe,qer),e(Cv,jer),e(Cv,CH),e(CH,Der),e(Cv,Ger),e(G,Oer),e(G,wv),e(wv,qMe),e(qMe,Ver),e(wv,Xer),e(wv,wH),e(wH,zer),e(wv,Qer),e(G,Wer),e(G,Av),e(Av,jMe),e(jMe,Uer),e(Av,Her),e(Av,AH),e(AH,Jer),e(Av,Yer),e(G,Zer),e(G,Lv),e(Lv,DMe),e(DMe,Ker),e(Lv,eor),e(Lv,LH),e(LH,oor),e(Lv,ror),e(G,tor),e(G,yv),e(yv,GMe),e(GMe,aor),e(yv,nor),e(yv,yH),e(yH,sor),e(yv,lor),e(G,ior),e(G,xv),e(xv,OMe),e(OMe,dor),e(xv,mor),e(xv,xH),e(xH,cor),e(xv,gor),e(G,hor),e(G,$v),e($v,VMe),e(VMe,uor),e($v,por),e($v,$H),e($H,_or),e($v,bor),e(G,vor),e(G,kv),e(kv,XMe),e(XMe,For),e(kv,Tor),e(kv,kH),e(kH,Mor),e(kv,Eor),e(G,Cor),e(G,Sv),e(Sv,zMe),e(zMe,wor),e(Sv,Aor),e(Sv,SH),e(SH,Lor),e(Sv,yor),e(G,xor),e(G,Rv),e(Rv,QMe),e(QMe,$or),e(Rv,kor),e(Rv,RH),e(RH,Sor),e(Rv,Ror),e(G,Por),e(G,Pv),e(Pv,WMe),e(WMe,Bor),e(Pv,Ior),e(Pv,PH),e(PH,Nor),e(Pv,qor),e(G,jor),e(G,Bv),e(Bv,UMe),e(UMe,Dor),e(Bv,Gor),e(Bv,BH),e(BH,Oor),e(Bv,Vor),e(G,Xor),e(G,Iv),e(Iv,HMe),e(HMe,zor),e(Iv,Qor),e(Iv,IH),e(IH,Wor),e(Iv,Uor),e(G,Hor),e(G,Nv),e(Nv,JMe),e(JMe,Jor),e(Nv,Yor),e(Nv,NH),e(NH,Zor),e(Nv,Kor),e(G,err),e(G,qv),e(qv,YMe),e(YMe,orr),e(qv,rrr),e(qv,qH),e(qH,trr),e(qv,arr),e(G,nrr),e(G,jv),e(jv,ZMe),e(ZMe,srr),e(jv,lrr),e(jv,jH),e(jH,irr),e(jv,drr),e(G,mrr),e(G,Dv),e(Dv,KMe),e(KMe,crr),e(Dv,frr),e(Dv,DH),e(DH,grr),e(Dv,hrr),e(G,urr),e(G,Gv),e(Gv,eEe),e(eEe,prr),e(Gv,_rr),e(Gv,GH),e(GH,brr),e(Gv,vrr),e(G,Frr),e(G,Ov),e(Ov,oEe),e(oEe,Trr),e(Ov,Mrr),e(Ov,OH),e(OH,Err),e(Ov,Crr),e(G,wrr),e(G,Vv),e(Vv,rEe),e(rEe,Arr),e(Vv,Lrr),e(Vv,VH),e(VH,yrr),e(Vv,xrr),e(G,$rr),e(G,Xv),e(Xv,tEe),e(tEe,krr),e(Xv,Srr),e(Xv,XH),e(XH,Rrr),e(Xv,Prr),e(G,Brr),e(G,zv),e(zv,aEe),e(aEe,Irr),e(zv,Nrr),e(zv,zH),e(zH,qrr),e(zv,jrr),e(G,Drr),e(G,Qv),e(Qv,nEe),e(nEe,Grr),e(Qv,Orr),e(Qv,QH),e(QH,Vrr),e(Qv,Xrr),e(G,zrr),e(G,Wv),e(Wv,sEe),e(sEe,Qrr),e(Wv,Wrr),e(Wv,WH),e(WH,Urr),e(Wv,Hrr),e(G,Jrr),e(G,Uv),e(Uv,lEe),e(lEe,Yrr),e(Uv,Zrr),e(Uv,UH),e(UH,Krr),e(Uv,etr),e(G,otr),e(G,Hv),e(Hv,iEe),e(iEe,rtr),e(Hv,ttr),e(Hv,HH),e(HH,atr),e(Hv,ntr),e(G,str),e(G,Jv),e(Jv,dEe),e(dEe,ltr),e(Jv,itr),e(Jv,JH),e(JH,dtr),e(Jv,mtr),e(ao,ctr),e(ao,Yv),e(Yv,ftr),e(Yv,mEe),e(mEe,gtr),e(Yv,htr),e(Yv,cEe),e(cEe,utr),e(ao,ptr),M(Zv,ao,null),b(c,Wlo,_),b(c,Wd,_),e(Wd,Kv),e(Kv,fEe),M(tS,fEe,null),e(Wd,_tr),e(Wd,gEe),e(gEe,btr),b(c,Ulo,_),b(c,Oo,_),M(aS,Oo,null),e(Oo,vtr),e(Oo,Ud),e(Ud,Ftr),e(Ud,YH),e(YH,Ttr),e(Ud,Mtr),e(Ud,ZH),e(ZH,Etr),e(Ud,Ctr),e(Oo,wtr),e(Oo,nS),e(nS,Atr),e(nS,hEe),e(hEe,Ltr),e(nS,ytr),e(Oo,xtr),e(Oo,yt),M(sS,yt,null),e(yt,$tr),e(yt,uEe),e(uEe,ktr),e(yt,Str),e(yt,Hd),e(Hd,Rtr),e(Hd,pEe),e(pEe,Ptr),e(Hd,Btr),e(Hd,KH),e(KH,Itr),e(Hd,Ntr),e(yt,qtr),M(eF,yt,null),e(Oo,jtr),e(Oo,no),M(lS,no,null),e(no,Dtr),e(no,_Ee),e(_Ee,Gtr),e(no,Otr),e(no,hn),e(hn,Vtr),e(hn,bEe),e(bEe,Xtr),e(hn,ztr),e(hn,vEe),e(vEe,Qtr),e(hn,Wtr),e(hn,FEe),e(FEe,Utr),e(hn,Htr),e(no,Jtr),e(no,W),e(W,oF),e(oF,TEe),e(TEe,Ytr),e(oF,Ztr),e(oF,eJ),e(eJ,Ktr),e(oF,ear),e(W,oar),e(W,rF),e(rF,MEe),e(MEe,rar),e(rF,tar),e(rF,oJ),e(oJ,aar),e(rF,nar),e(W,sar),e(W,tF),e(tF,EEe),e(EEe,lar),e(tF,iar),e(tF,rJ),e(rJ,dar),e(tF,mar),e(W,car),e(W,aF),e(aF,CEe),e(CEe,far),e(aF,gar),e(aF,tJ),e(tJ,har),e(aF,uar),e(W,par),e(W,nF),e(nF,wEe),e(wEe,_ar),e(nF,bar),e(nF,aJ),e(aJ,Far),e(nF,Tar),e(W,Mar),e(W,sF),e(sF,AEe),e(AEe,Ear),e(sF,Car),e(sF,nJ),e(nJ,war),e(sF,Aar),e(W,Lar),e(W,lF),e(lF,LEe),e(LEe,yar),e(lF,xar),e(lF,sJ),e(sJ,$ar),e(lF,kar),e(W,Sar),e(W,iF),e(iF,yEe),e(yEe,Rar),e(iF,Par),e(iF,lJ),e(lJ,Bar),e(iF,Iar),e(W,Nar),e(W,dF),e(dF,xEe),e(xEe,qar),e(dF,jar),e(dF,iJ),e(iJ,Dar),e(dF,Gar),e(W,Oar),e(W,mF),e(mF,$Ee),e($Ee,Var),e(mF,Xar),e(mF,dJ),e(dJ,zar),e(mF,Qar),e(W,War),e(W,cF),e(cF,kEe),e(kEe,Uar),e(cF,Har),e(cF,mJ),e(mJ,Jar),e(cF,Yar),e(W,Zar),e(W,fF),e(fF,SEe),e(SEe,Kar),e(fF,enr),e(fF,cJ),e(cJ,onr),e(fF,rnr),e(W,tnr),e(W,gF),e(gF,REe),e(REe,anr),e(gF,nnr),e(gF,fJ),e(fJ,snr),e(gF,lnr),e(W,inr),e(W,hF),e(hF,PEe),e(PEe,dnr),e(hF,mnr),e(hF,gJ),e(gJ,cnr),e(hF,fnr),e(W,gnr),e(W,uF),e(uF,BEe),e(BEe,hnr),e(uF,unr),e(uF,hJ),e(hJ,pnr),e(uF,_nr),e(W,bnr),e(W,pF),e(pF,IEe),e(IEe,vnr),e(pF,Fnr),e(pF,uJ),e(uJ,Tnr),e(pF,Mnr),e(W,Enr),e(W,_F),e(_F,NEe),e(NEe,Cnr),e(_F,wnr),e(_F,pJ),e(pJ,Anr),e(_F,Lnr),e(W,ynr),e(W,bF),e(bF,qEe),e(qEe,xnr),e(bF,$nr),e(bF,_J),e(_J,knr),e(bF,Snr),e(W,Rnr),e(W,vF),e(vF,jEe),e(jEe,Pnr),e(vF,Bnr),e(vF,bJ),e(bJ,Inr),e(vF,Nnr),e(W,qnr),e(W,FF),e(FF,DEe),e(DEe,jnr),e(FF,Dnr),e(FF,vJ),e(vJ,Gnr),e(FF,Onr),e(W,Vnr),e(W,TF),e(TF,GEe),e(GEe,Xnr),e(TF,znr),e(TF,FJ),e(FJ,Qnr),e(TF,Wnr),e(W,Unr),e(W,MF),e(MF,OEe),e(OEe,Hnr),e(MF,Jnr),e(MF,TJ),e(TJ,Ynr),e(MF,Znr),e(W,Knr),e(W,EF),e(EF,VEe),e(VEe,esr),e(EF,osr),e(EF,MJ),e(MJ,rsr),e(EF,tsr),e(W,asr),e(W,CF),e(CF,XEe),e(XEe,nsr),e(CF,ssr),e(CF,EJ),e(EJ,lsr),e(CF,isr),e(W,dsr),e(W,wF),e(wF,zEe),e(zEe,msr),e(wF,csr),e(wF,CJ),e(CJ,fsr),e(wF,gsr),e(W,hsr),e(W,AF),e(AF,QEe),e(QEe,usr),e(AF,psr),e(AF,wJ),e(wJ,_sr),e(AF,bsr),e(W,vsr),e(W,LF),e(LF,WEe),e(WEe,Fsr),e(LF,Tsr),e(LF,AJ),e(AJ,Msr),e(LF,Esr),e(W,Csr),e(W,yF),e(yF,UEe),e(UEe,wsr),e(yF,Asr),e(yF,LJ),e(LJ,Lsr),e(yF,ysr),e(W,xsr),e(W,xF),e(xF,HEe),e(HEe,$sr),e(xF,ksr),e(xF,yJ),e(yJ,Ssr),e(xF,Rsr),e(W,Psr),e(W,$F),e($F,JEe),e(JEe,Bsr),e($F,Isr),e($F,xJ),e(xJ,Nsr),e($F,qsr),e(W,jsr),e(W,kF),e(kF,YEe),e(YEe,Dsr),e(kF,Gsr),e(kF,$J),e($J,Osr),e(kF,Vsr),e(W,Xsr),e(W,SF),e(SF,ZEe),e(ZEe,zsr),e(SF,Qsr),e(SF,kJ),e(kJ,Wsr),e(SF,Usr),e(W,Hsr),e(W,RF),e(RF,KEe),e(KEe,Jsr),e(RF,Ysr),e(RF,SJ),e(SJ,Zsr),e(RF,Ksr),e(W,elr),e(W,PF),e(PF,e4e),e(e4e,olr),e(PF,rlr),e(PF,RJ),e(RJ,tlr),e(PF,alr),e(W,nlr),e(W,BF),e(BF,o4e),e(o4e,slr),e(BF,llr),e(BF,PJ),e(PJ,ilr),e(BF,dlr),e(W,mlr),e(W,IF),e(IF,r4e),e(r4e,clr),e(IF,flr),e(IF,BJ),e(BJ,glr),e(IF,hlr),e(W,ulr),e(W,NF),e(NF,t4e),e(t4e,plr),e(NF,_lr),e(NF,IJ),e(IJ,blr),e(NF,vlr),e(W,Flr),e(W,qF),e(qF,a4e),e(a4e,Tlr),e(qF,Mlr),e(qF,NJ),e(NJ,Elr),e(qF,Clr),e(W,wlr),e(W,jF),e(jF,n4e),e(n4e,Alr),e(jF,Llr),e(jF,qJ),e(qJ,ylr),e(jF,xlr),e(W,$lr),e(W,DF),e(DF,s4e),e(s4e,klr),e(DF,Slr),e(DF,jJ),e(jJ,Rlr),e(DF,Plr),e(W,Blr),e(W,GF),e(GF,l4e),e(l4e,Ilr),e(GF,Nlr),e(GF,DJ),e(DJ,qlr),e(GF,jlr),e(W,Dlr),e(W,OF),e(OF,i4e),e(i4e,Glr),e(OF,Olr),e(OF,GJ),e(GJ,Vlr),e(OF,Xlr),e(W,zlr),e(W,VF),e(VF,d4e),e(d4e,Qlr),e(VF,Wlr),e(VF,OJ),e(OJ,Ulr),e(VF,Hlr),e(no,Jlr),e(no,XF),e(XF,Ylr),e(XF,m4e),e(m4e,Zlr),e(XF,Klr),e(XF,c4e),e(c4e,eir),e(no,oir),M(zF,no,null),b(c,Hlo,_),b(c,Jd,_),e(Jd,QF),e(QF,f4e),M(iS,f4e,null),e(Jd,rir),e(Jd,g4e),e(g4e,tir),b(c,Jlo,_),b(c,Vo,_),M(dS,Vo,null),e(Vo,air),e(Vo,Yd),e(Yd,nir),e(Yd,VJ),e(VJ,sir),e(Yd,lir),e(Yd,XJ),e(XJ,iir),e(Yd,dir),e(Vo,mir),e(Vo,mS),e(mS,cir),e(mS,h4e),e(h4e,fir),e(mS,gir),e(Vo,hir),e(Vo,xt),M(cS,xt,null),e(xt,uir),e(xt,u4e),e(u4e,pir),e(xt,_ir),e(xt,Zd),e(Zd,bir),e(Zd,p4e),e(p4e,vir),e(Zd,Fir),e(Zd,zJ),e(zJ,Tir),e(Zd,Mir),e(xt,Eir),M(WF,xt,null),e(Vo,Cir),e(Vo,so),M(fS,so,null),e(so,wir),e(so,_4e),e(_4e,Air),e(so,Lir),e(so,un),e(un,yir),e(un,b4e),e(b4e,xir),e(un,$ir),e(un,v4e),e(v4e,kir),e(un,Sir),e(un,F4e),e(F4e,Rir),e(un,Pir),e(so,Bir),e(so,gS),e(gS,UF),e(UF,T4e),e(T4e,Iir),e(UF,Nir),e(UF,QJ),e(QJ,qir),e(UF,jir),e(gS,Dir),e(gS,HF),e(HF,M4e),e(M4e,Gir),e(HF,Oir),e(HF,WJ),e(WJ,Vir),e(HF,Xir),e(so,zir),e(so,JF),e(JF,Qir),e(JF,E4e),e(E4e,Wir),e(JF,Uir),e(JF,C4e),e(C4e,Hir),e(so,Jir),M(YF,so,null),b(c,Ylo,_),b(c,Kd,_),e(Kd,ZF),e(ZF,w4e),M(hS,w4e,null),e(Kd,Yir),e(Kd,A4e),e(A4e,Zir),b(c,Zlo,_),b(c,Xo,_),M(uS,Xo,null),e(Xo,Kir),e(Xo,em),e(em,edr),e(em,UJ),e(UJ,odr),e(em,rdr),e(em,HJ),e(HJ,tdr),e(em,adr),e(Xo,ndr),e(Xo,pS),e(pS,sdr),e(pS,L4e),e(L4e,ldr),e(pS,idr),e(Xo,ddr),e(Xo,$t),M(_S,$t,null),e($t,mdr),e($t,y4e),e(y4e,cdr),e($t,fdr),e($t,om),e(om,gdr),e(om,x4e),e(x4e,hdr),e(om,udr),e(om,JJ),e(JJ,pdr),e(om,_dr),e($t,bdr),M(KF,$t,null),e(Xo,vdr),e(Xo,lo),M(bS,lo,null),e(lo,Fdr),e(lo,$4e),e($4e,Tdr),e(lo,Mdr),e(lo,pn),e(pn,Edr),e(pn,k4e),e(k4e,Cdr),e(pn,wdr),e(pn,S4e),e(S4e,Adr),e(pn,Ldr),e(pn,R4e),e(R4e,ydr),e(pn,xdr),e(lo,$dr),e(lo,Y),e(Y,eT),e(eT,P4e),e(P4e,kdr),e(eT,Sdr),e(eT,YJ),e(YJ,Rdr),e(eT,Pdr),e(Y,Bdr),e(Y,oT),e(oT,B4e),e(B4e,Idr),e(oT,Ndr),e(oT,ZJ),e(ZJ,qdr),e(oT,jdr),e(Y,Ddr),e(Y,rT),e(rT,I4e),e(I4e,Gdr),e(rT,Odr),e(rT,KJ),e(KJ,Vdr),e(rT,Xdr),e(Y,zdr),e(Y,tT),e(tT,N4e),e(N4e,Qdr),e(tT,Wdr),e(tT,eY),e(eY,Udr),e(tT,Hdr),e(Y,Jdr),e(Y,aT),e(aT,q4e),e(q4e,Ydr),e(aT,Zdr),e(aT,oY),e(oY,Kdr),e(aT,emr),e(Y,omr),e(Y,nT),e(nT,j4e),e(j4e,rmr),e(nT,tmr),e(nT,rY),e(rY,amr),e(nT,nmr),e(Y,smr),e(Y,sT),e(sT,D4e),e(D4e,lmr),e(sT,imr),e(sT,tY),e(tY,dmr),e(sT,mmr),e(Y,cmr),e(Y,lT),e(lT,G4e),e(G4e,fmr),e(lT,gmr),e(lT,aY),e(aY,hmr),e(lT,umr),e(Y,pmr),e(Y,iT),e(iT,O4e),e(O4e,_mr),e(iT,bmr),e(iT,nY),e(nY,vmr),e(iT,Fmr),e(Y,Tmr),e(Y,dT),e(dT,V4e),e(V4e,Mmr),e(dT,Emr),e(dT,sY),e(sY,Cmr),e(dT,wmr),e(Y,Amr),e(Y,mT),e(mT,X4e),e(X4e,Lmr),e(mT,ymr),e(mT,lY),e(lY,xmr),e(mT,$mr),e(Y,kmr),e(Y,cT),e(cT,z4e),e(z4e,Smr),e(cT,Rmr),e(cT,iY),e(iY,Pmr),e(cT,Bmr),e(Y,Imr),e(Y,fT),e(fT,Q4e),e(Q4e,Nmr),e(fT,qmr),e(fT,dY),e(dY,jmr),e(fT,Dmr),e(Y,Gmr),e(Y,gT),e(gT,W4e),e(W4e,Omr),e(gT,Vmr),e(gT,mY),e(mY,Xmr),e(gT,zmr),e(Y,Qmr),e(Y,hT),e(hT,U4e),e(U4e,Wmr),e(hT,Umr),e(hT,cY),e(cY,Hmr),e(hT,Jmr),e(Y,Ymr),e(Y,uT),e(uT,H4e),e(H4e,Zmr),e(uT,Kmr),e(uT,fY),e(fY,ecr),e(uT,ocr),e(Y,rcr),e(Y,pT),e(pT,J4e),e(J4e,tcr),e(pT,acr),e(pT,gY),e(gY,ncr),e(pT,scr),e(Y,lcr),e(Y,_T),e(_T,Y4e),e(Y4e,icr),e(_T,dcr),e(_T,hY),e(hY,mcr),e(_T,ccr),e(Y,fcr),e(Y,bT),e(bT,Z4e),e(Z4e,gcr),e(bT,hcr),e(bT,uY),e(uY,ucr),e(bT,pcr),e(Y,_cr),e(Y,vT),e(vT,K4e),e(K4e,bcr),e(vT,vcr),e(vT,pY),e(pY,Fcr),e(vT,Tcr),e(Y,Mcr),e(Y,FT),e(FT,eCe),e(eCe,Ecr),e(FT,Ccr),e(FT,_Y),e(_Y,wcr),e(FT,Acr),e(Y,Lcr),e(Y,TT),e(TT,oCe),e(oCe,ycr),e(TT,xcr),e(TT,bY),e(bY,$cr),e(TT,kcr),e(Y,Scr),e(Y,MT),e(MT,rCe),e(rCe,Rcr),e(MT,Pcr),e(MT,vY),e(vY,Bcr),e(MT,Icr),e(Y,Ncr),e(Y,ET),e(ET,tCe),e(tCe,qcr),e(ET,jcr),e(ET,FY),e(FY,Dcr),e(ET,Gcr),e(Y,Ocr),e(Y,CT),e(CT,aCe),e(aCe,Vcr),e(CT,Xcr),e(CT,TY),e(TY,zcr),e(CT,Qcr),e(Y,Wcr),e(Y,wT),e(wT,nCe),e(nCe,Ucr),e(wT,Hcr),e(wT,MY),e(MY,Jcr),e(wT,Ycr),e(Y,Zcr),e(Y,AT),e(AT,sCe),e(sCe,Kcr),e(AT,efr),e(AT,EY),e(EY,ofr),e(AT,rfr),e(Y,tfr),e(Y,LT),e(LT,lCe),e(lCe,afr),e(LT,nfr),e(LT,CY),e(CY,sfr),e(LT,lfr),e(Y,ifr),e(Y,yT),e(yT,iCe),e(iCe,dfr),e(yT,mfr),e(yT,wY),e(wY,cfr),e(yT,ffr),e(Y,gfr),e(Y,xT),e(xT,dCe),e(dCe,hfr),e(xT,ufr),e(xT,AY),e(AY,pfr),e(xT,_fr),e(Y,bfr),e(Y,$T),e($T,mCe),e(mCe,vfr),e($T,Ffr),e($T,LY),e(LY,Tfr),e($T,Mfr),e(Y,Efr),e(Y,kT),e(kT,cCe),e(cCe,Cfr),e(kT,wfr),e(kT,yY),e(yY,Afr),e(kT,Lfr),e(Y,yfr),e(Y,ST),e(ST,fCe),e(fCe,xfr),e(ST,$fr),e(ST,xY),e(xY,kfr),e(ST,Sfr),e(Y,Rfr),e(Y,RT),e(RT,gCe),e(gCe,Pfr),e(RT,Bfr),e(RT,$Y),e($Y,Ifr),e(RT,Nfr),e(Y,qfr),e(Y,PT),e(PT,hCe),e(hCe,jfr),e(PT,Dfr),e(PT,kY),e(kY,Gfr),e(PT,Ofr),e(Y,Vfr),e(Y,BT),e(BT,uCe),e(uCe,Xfr),e(BT,zfr),e(BT,pCe),e(pCe,Qfr),e(BT,Wfr),e(Y,Ufr),e(Y,IT),e(IT,_Ce),e(_Ce,Hfr),e(IT,Jfr),e(IT,SY),e(SY,Yfr),e(IT,Zfr),e(Y,Kfr),e(Y,NT),e(NT,bCe),e(bCe,egr),e(NT,ogr),e(NT,RY),e(RY,rgr),e(NT,tgr),e(Y,agr),e(Y,qT),e(qT,vCe),e(vCe,ngr),e(qT,sgr),e(qT,PY),e(PY,lgr),e(qT,igr),e(Y,dgr),e(Y,jT),e(jT,FCe),e(FCe,mgr),e(jT,cgr),e(jT,BY),e(BY,fgr),e(jT,ggr),e(lo,hgr),e(lo,DT),e(DT,ugr),e(DT,TCe),e(TCe,pgr),e(DT,_gr),e(DT,MCe),e(MCe,bgr),e(lo,vgr),M(GT,lo,null),b(c,Klo,_),b(c,rm,_),e(rm,OT),e(OT,ECe),M(vS,ECe,null),e(rm,Fgr),e(rm,CCe),e(CCe,Tgr),b(c,eio,_),b(c,zo,_),M(FS,zo,null),e(zo,Mgr),e(zo,tm),e(tm,Egr),e(tm,IY),e(IY,Cgr),e(tm,wgr),e(tm,NY),e(NY,Agr),e(tm,Lgr),e(zo,ygr),e(zo,TS),e(TS,xgr),e(TS,wCe),e(wCe,$gr),e(TS,kgr),e(zo,Sgr),e(zo,kt),M(MS,kt,null),e(kt,Rgr),e(kt,ACe),e(ACe,Pgr),e(kt,Bgr),e(kt,am),e(am,Igr),e(am,LCe),e(LCe,Ngr),e(am,qgr),e(am,qY),e(qY,jgr),e(am,Dgr),e(kt,Ggr),M(VT,kt,null),e(zo,Ogr),e(zo,io),M(ES,io,null),e(io,Vgr),e(io,yCe),e(yCe,Xgr),e(io,zgr),e(io,_n),e(_n,Qgr),e(_n,xCe),e(xCe,Wgr),e(_n,Ugr),e(_n,$Ce),e($Ce,Hgr),e(_n,Jgr),e(_n,kCe),e(kCe,Ygr),e(_n,Zgr),e(io,Kgr),e(io,pe),e(pe,XT),e(XT,SCe),e(SCe,ehr),e(XT,ohr),e(XT,jY),e(jY,rhr),e(XT,thr),e(pe,ahr),e(pe,zT),e(zT,RCe),e(RCe,nhr),e(zT,shr),e(zT,DY),e(DY,lhr),e(zT,ihr),e(pe,dhr),e(pe,QT),e(QT,PCe),e(PCe,mhr),e(QT,chr),e(QT,GY),e(GY,fhr),e(QT,ghr),e(pe,hhr),e(pe,WT),e(WT,BCe),e(BCe,uhr),e(WT,phr),e(WT,OY),e(OY,_hr),e(WT,bhr),e(pe,vhr),e(pe,UT),e(UT,ICe),e(ICe,Fhr),e(UT,Thr),e(UT,VY),e(VY,Mhr),e(UT,Ehr),e(pe,Chr),e(pe,HT),e(HT,NCe),e(NCe,whr),e(HT,Ahr),e(HT,XY),e(XY,Lhr),e(HT,yhr),e(pe,xhr),e(pe,JT),e(JT,qCe),e(qCe,$hr),e(JT,khr),e(JT,zY),e(zY,Shr),e(JT,Rhr),e(pe,Phr),e(pe,YT),e(YT,jCe),e(jCe,Bhr),e(YT,Ihr),e(YT,QY),e(QY,Nhr),e(YT,qhr),e(pe,jhr),e(pe,ZT),e(ZT,DCe),e(DCe,Dhr),e(ZT,Ghr),e(ZT,WY),e(WY,Ohr),e(ZT,Vhr),e(pe,Xhr),e(pe,KT),e(KT,GCe),e(GCe,zhr),e(KT,Qhr),e(KT,UY),e(UY,Whr),e(KT,Uhr),e(pe,Hhr),e(pe,eM),e(eM,OCe),e(OCe,Jhr),e(eM,Yhr),e(eM,HY),e(HY,Zhr),e(eM,Khr),e(pe,eur),e(pe,oM),e(oM,VCe),e(VCe,our),e(oM,rur),e(oM,JY),e(JY,tur),e(oM,aur),e(pe,nur),e(pe,rM),e(rM,XCe),e(XCe,sur),e(rM,lur),e(rM,YY),e(YY,iur),e(rM,dur),e(pe,mur),e(pe,tM),e(tM,zCe),e(zCe,cur),e(tM,fur),e(tM,ZY),e(ZY,gur),e(tM,hur),e(pe,uur),e(pe,aM),e(aM,QCe),e(QCe,pur),e(aM,_ur),e(aM,KY),e(KY,bur),e(aM,vur),e(pe,Fur),e(pe,nM),e(nM,WCe),e(WCe,Tur),e(nM,Mur),e(nM,eZ),e(eZ,Eur),e(nM,Cur),e(pe,wur),e(pe,sM),e(sM,UCe),e(UCe,Aur),e(sM,Lur),e(sM,oZ),e(oZ,yur),e(sM,xur),e(pe,$ur),e(pe,lM),e(lM,HCe),e(HCe,kur),e(lM,Sur),e(lM,rZ),e(rZ,Rur),e(lM,Pur),e(pe,Bur),e(pe,iM),e(iM,JCe),e(JCe,Iur),e(iM,Nur),e(iM,tZ),e(tZ,qur),e(iM,jur),e(pe,Dur),e(pe,dM),e(dM,YCe),e(YCe,Gur),e(dM,Our),e(dM,aZ),e(aZ,Vur),e(dM,Xur),e(io,zur),e(io,mM),e(mM,Qur),e(mM,ZCe),e(ZCe,Wur),e(mM,Uur),e(mM,KCe),e(KCe,Hur),e(io,Jur),M(cM,io,null),b(c,oio,_),b(c,nm,_),e(nm,fM),e(fM,e3e),M(CS,e3e,null),e(nm,Yur),e(nm,o3e),e(o3e,Zur),b(c,rio,_),b(c,Qo,_),M(wS,Qo,null),e(Qo,Kur),e(Qo,sm),e(sm,epr),e(sm,nZ),e(nZ,opr),e(sm,rpr),e(sm,sZ),e(sZ,tpr),e(sm,apr),e(Qo,npr),e(Qo,AS),e(AS,spr),e(AS,r3e),e(r3e,lpr),e(AS,ipr),e(Qo,dpr),e(Qo,St),M(LS,St,null),e(St,mpr),e(St,t3e),e(t3e,cpr),e(St,fpr),e(St,lm),e(lm,gpr),e(lm,a3e),e(a3e,hpr),e(lm,upr),e(lm,lZ),e(lZ,ppr),e(lm,_pr),e(St,bpr),M(gM,St,null),e(Qo,vpr),e(Qo,mo),M(yS,mo,null),e(mo,Fpr),e(mo,n3e),e(n3e,Tpr),e(mo,Mpr),e(mo,bn),e(bn,Epr),e(bn,s3e),e(s3e,Cpr),e(bn,wpr),e(bn,l3e),e(l3e,Apr),e(bn,Lpr),e(bn,i3e),e(i3e,ypr),e(bn,xpr),e(mo,$pr),e(mo,I),e(I,hM),e(hM,d3e),e(d3e,kpr),e(hM,Spr),e(hM,iZ),e(iZ,Rpr),e(hM,Ppr),e(I,Bpr),e(I,uM),e(uM,m3e),e(m3e,Ipr),e(uM,Npr),e(uM,dZ),e(dZ,qpr),e(uM,jpr),e(I,Dpr),e(I,pM),e(pM,c3e),e(c3e,Gpr),e(pM,Opr),e(pM,mZ),e(mZ,Vpr),e(pM,Xpr),e(I,zpr),e(I,_M),e(_M,f3e),e(f3e,Qpr),e(_M,Wpr),e(_M,cZ),e(cZ,Upr),e(_M,Hpr),e(I,Jpr),e(I,bM),e(bM,g3e),e(g3e,Ypr),e(bM,Zpr),e(bM,fZ),e(fZ,Kpr),e(bM,e_r),e(I,o_r),e(I,vM),e(vM,h3e),e(h3e,r_r),e(vM,t_r),e(vM,gZ),e(gZ,a_r),e(vM,n_r),e(I,s_r),e(I,FM),e(FM,u3e),e(u3e,l_r),e(FM,i_r),e(FM,hZ),e(hZ,d_r),e(FM,m_r),e(I,c_r),e(I,TM),e(TM,p3e),e(p3e,f_r),e(TM,g_r),e(TM,uZ),e(uZ,h_r),e(TM,u_r),e(I,p_r),e(I,MM),e(MM,_3e),e(_3e,__r),e(MM,b_r),e(MM,pZ),e(pZ,v_r),e(MM,F_r),e(I,T_r),e(I,EM),e(EM,b3e),e(b3e,M_r),e(EM,E_r),e(EM,_Z),e(_Z,C_r),e(EM,w_r),e(I,A_r),e(I,CM),e(CM,v3e),e(v3e,L_r),e(CM,y_r),e(CM,bZ),e(bZ,x_r),e(CM,$_r),e(I,k_r),e(I,wM),e(wM,F3e),e(F3e,S_r),e(wM,R_r),e(wM,vZ),e(vZ,P_r),e(wM,B_r),e(I,I_r),e(I,AM),e(AM,T3e),e(T3e,N_r),e(AM,q_r),e(AM,FZ),e(FZ,j_r),e(AM,D_r),e(I,G_r),e(I,LM),e(LM,M3e),e(M3e,O_r),e(LM,V_r),e(LM,TZ),e(TZ,X_r),e(LM,z_r),e(I,Q_r),e(I,yM),e(yM,E3e),e(E3e,W_r),e(yM,U_r),e(yM,MZ),e(MZ,H_r),e(yM,J_r),e(I,Y_r),e(I,xM),e(xM,C3e),e(C3e,Z_r),e(xM,K_r),e(xM,EZ),e(EZ,e1r),e(xM,o1r),e(I,r1r),e(I,$M),e($M,w3e),e(w3e,t1r),e($M,a1r),e($M,CZ),e(CZ,n1r),e($M,s1r),e(I,l1r),e(I,kM),e(kM,A3e),e(A3e,i1r),e(kM,d1r),e(kM,wZ),e(wZ,m1r),e(kM,c1r),e(I,f1r),e(I,SM),e(SM,L3e),e(L3e,g1r),e(SM,h1r),e(SM,AZ),e(AZ,u1r),e(SM,p1r),e(I,_1r),e(I,RM),e(RM,y3e),e(y3e,b1r),e(RM,v1r),e(RM,LZ),e(LZ,F1r),e(RM,T1r),e(I,M1r),e(I,PM),e(PM,x3e),e(x3e,E1r),e(PM,C1r),e(PM,yZ),e(yZ,w1r),e(PM,A1r),e(I,L1r),e(I,BM),e(BM,$3e),e($3e,y1r),e(BM,x1r),e(BM,xZ),e(xZ,$1r),e(BM,k1r),e(I,S1r),e(I,IM),e(IM,k3e),e(k3e,R1r),e(IM,P1r),e(IM,$Z),e($Z,B1r),e(IM,I1r),e(I,N1r),e(I,NM),e(NM,S3e),e(S3e,q1r),e(NM,j1r),e(NM,kZ),e(kZ,D1r),e(NM,G1r),e(I,O1r),e(I,qM),e(qM,R3e),e(R3e,V1r),e(qM,X1r),e(qM,SZ),e(SZ,z1r),e(qM,Q1r),e(I,W1r),e(I,jM),e(jM,P3e),e(P3e,U1r),e(jM,H1r),e(jM,RZ),e(RZ,J1r),e(jM,Y1r),e(I,Z1r),e(I,DM),e(DM,B3e),e(B3e,K1r),e(DM,e2r),e(DM,PZ),e(PZ,o2r),e(DM,r2r),e(I,t2r),e(I,GM),e(GM,I3e),e(I3e,a2r),e(GM,n2r),e(GM,BZ),e(BZ,s2r),e(GM,l2r),e(I,i2r),e(I,OM),e(OM,N3e),e(N3e,d2r),e(OM,m2r),e(OM,IZ),e(IZ,c2r),e(OM,f2r),e(I,g2r),e(I,VM),e(VM,q3e),e(q3e,h2r),e(VM,u2r),e(VM,NZ),e(NZ,p2r),e(VM,_2r),e(I,b2r),e(I,XM),e(XM,j3e),e(j3e,v2r),e(XM,F2r),e(XM,qZ),e(qZ,T2r),e(XM,M2r),e(I,E2r),e(I,zM),e(zM,D3e),e(D3e,C2r),e(zM,w2r),e(zM,jZ),e(jZ,A2r),e(zM,L2r),e(I,y2r),e(I,QM),e(QM,G3e),e(G3e,x2r),e(QM,$2r),e(QM,DZ),e(DZ,k2r),e(QM,S2r),e(I,R2r),e(I,WM),e(WM,O3e),e(O3e,P2r),e(WM,B2r),e(WM,GZ),e(GZ,I2r),e(WM,N2r),e(I,q2r),e(I,UM),e(UM,V3e),e(V3e,j2r),e(UM,D2r),e(UM,OZ),e(OZ,G2r),e(UM,O2r),e(I,V2r),e(I,HM),e(HM,X3e),e(X3e,X2r),e(HM,z2r),e(HM,VZ),e(VZ,Q2r),e(HM,W2r),e(I,U2r),e(I,JM),e(JM,z3e),e(z3e,H2r),e(JM,J2r),e(JM,XZ),e(XZ,Y2r),e(JM,Z2r),e(I,K2r),e(I,YM),e(YM,Q3e),e(Q3e,ebr),e(YM,obr),e(YM,zZ),e(zZ,rbr),e(YM,tbr),e(I,abr),e(I,ZM),e(ZM,W3e),e(W3e,nbr),e(ZM,sbr),e(ZM,QZ),e(QZ,lbr),e(ZM,ibr),e(I,dbr),e(I,KM),e(KM,U3e),e(U3e,mbr),e(KM,cbr),e(KM,WZ),e(WZ,fbr),e(KM,gbr),e(I,hbr),e(I,eE),e(eE,H3e),e(H3e,ubr),e(eE,pbr),e(eE,UZ),e(UZ,_br),e(eE,bbr),e(I,vbr),e(I,oE),e(oE,J3e),e(J3e,Fbr),e(oE,Tbr),e(oE,HZ),e(HZ,Mbr),e(oE,Ebr),e(I,Cbr),e(I,rE),e(rE,Y3e),e(Y3e,wbr),e(rE,Abr),e(rE,JZ),e(JZ,Lbr),e(rE,ybr),e(I,xbr),e(I,tE),e(tE,Z3e),e(Z3e,$br),e(tE,kbr),e(tE,YZ),e(YZ,Sbr),e(tE,Rbr),e(I,Pbr),e(I,aE),e(aE,K3e),e(K3e,Bbr),e(aE,Ibr),e(aE,ZZ),e(ZZ,Nbr),e(aE,qbr),e(I,jbr),e(I,nE),e(nE,e5e),e(e5e,Dbr),e(nE,Gbr),e(nE,KZ),e(KZ,Obr),e(nE,Vbr),e(I,Xbr),e(I,sE),e(sE,o5e),e(o5e,zbr),e(sE,Qbr),e(sE,eK),e(eK,Wbr),e(sE,Ubr),e(I,Hbr),e(I,lE),e(lE,r5e),e(r5e,Jbr),e(lE,Ybr),e(lE,oK),e(oK,Zbr),e(lE,Kbr),e(I,evr),e(I,iE),e(iE,t5e),e(t5e,ovr),e(iE,rvr),e(iE,rK),e(rK,tvr),e(iE,avr),e(I,nvr),e(I,dE),e(dE,a5e),e(a5e,svr),e(dE,lvr),e(dE,tK),e(tK,ivr),e(dE,dvr),e(I,mvr),e(I,mE),e(mE,n5e),e(n5e,cvr),e(mE,fvr),e(mE,aK),e(aK,gvr),e(mE,hvr),e(I,uvr),e(I,cE),e(cE,s5e),e(s5e,pvr),e(cE,_vr),e(cE,nK),e(nK,bvr),e(cE,vvr),e(I,Fvr),e(I,fE),e(fE,l5e),e(l5e,Tvr),e(fE,Mvr),e(fE,sK),e(sK,Evr),e(fE,Cvr),e(I,wvr),e(I,gE),e(gE,i5e),e(i5e,Avr),e(gE,Lvr),e(gE,lK),e(lK,yvr),e(gE,xvr),e(I,$vr),e(I,hE),e(hE,d5e),e(d5e,kvr),e(hE,Svr),e(hE,iK),e(iK,Rvr),e(hE,Pvr),e(I,Bvr),e(I,uE),e(uE,m5e),e(m5e,Ivr),e(uE,Nvr),e(uE,dK),e(dK,qvr),e(uE,jvr),e(I,Dvr),e(I,pE),e(pE,c5e),e(c5e,Gvr),e(pE,Ovr),e(pE,mK),e(mK,Vvr),e(pE,Xvr),e(mo,zvr),e(mo,_E),e(_E,Qvr),e(_E,f5e),e(f5e,Wvr),e(_E,Uvr),e(_E,g5e),e(g5e,Hvr),e(mo,Jvr),M(bE,mo,null),b(c,tio,_),b(c,im,_),e(im,vE),e(vE,h5e),M(xS,h5e,null),e(im,Yvr),e(im,u5e),e(u5e,Zvr),b(c,aio,_),b(c,Wo,_),M($S,Wo,null),e(Wo,Kvr),e(Wo,dm),e(dm,eFr),e(dm,cK),e(cK,oFr),e(dm,rFr),e(dm,fK),e(fK,tFr),e(dm,aFr),e(Wo,nFr),e(Wo,kS),e(kS,sFr),e(kS,p5e),e(p5e,lFr),e(kS,iFr),e(Wo,dFr),e(Wo,Rt),M(SS,Rt,null),e(Rt,mFr),e(Rt,_5e),e(_5e,cFr),e(Rt,fFr),e(Rt,mm),e(mm,gFr),e(mm,b5e),e(b5e,hFr),e(mm,uFr),e(mm,gK),e(gK,pFr),e(mm,_Fr),e(Rt,bFr),M(FE,Rt,null),e(Wo,vFr),e(Wo,co),M(RS,co,null),e(co,FFr),e(co,v5e),e(v5e,TFr),e(co,MFr),e(co,vn),e(vn,EFr),e(vn,F5e),e(F5e,CFr),e(vn,wFr),e(vn,T5e),e(T5e,AFr),e(vn,LFr),e(vn,M5e),e(M5e,yFr),e(vn,xFr),e(co,$Fr),e(co,K),e(K,TE),e(TE,E5e),e(E5e,kFr),e(TE,SFr),e(TE,hK),e(hK,RFr),e(TE,PFr),e(K,BFr),e(K,ME),e(ME,C5e),e(C5e,IFr),e(ME,NFr),e(ME,uK),e(uK,qFr),e(ME,jFr),e(K,DFr),e(K,EE),e(EE,w5e),e(w5e,GFr),e(EE,OFr),e(EE,pK),e(pK,VFr),e(EE,XFr),e(K,zFr),e(K,CE),e(CE,A5e),e(A5e,QFr),e(CE,WFr),e(CE,_K),e(_K,UFr),e(CE,HFr),e(K,JFr),e(K,wE),e(wE,L5e),e(L5e,YFr),e(wE,ZFr),e(wE,bK),e(bK,KFr),e(wE,eTr),e(K,oTr),e(K,AE),e(AE,y5e),e(y5e,rTr),e(AE,tTr),e(AE,vK),e(vK,aTr),e(AE,nTr),e(K,sTr),e(K,LE),e(LE,x5e),e(x5e,lTr),e(LE,iTr),e(LE,FK),e(FK,dTr),e(LE,mTr),e(K,cTr),e(K,yE),e(yE,$5e),e($5e,fTr),e(yE,gTr),e(yE,TK),e(TK,hTr),e(yE,uTr),e(K,pTr),e(K,xE),e(xE,k5e),e(k5e,_Tr),e(xE,bTr),e(xE,MK),e(MK,vTr),e(xE,FTr),e(K,TTr),e(K,$E),e($E,S5e),e(S5e,MTr),e($E,ETr),e($E,EK),e(EK,CTr),e($E,wTr),e(K,ATr),e(K,kE),e(kE,R5e),e(R5e,LTr),e(kE,yTr),e(kE,CK),e(CK,xTr),e(kE,$Tr),e(K,kTr),e(K,SE),e(SE,P5e),e(P5e,STr),e(SE,RTr),e(SE,wK),e(wK,PTr),e(SE,BTr),e(K,ITr),e(K,RE),e(RE,B5e),e(B5e,NTr),e(RE,qTr),e(RE,AK),e(AK,jTr),e(RE,DTr),e(K,GTr),e(K,PE),e(PE,I5e),e(I5e,OTr),e(PE,VTr),e(PE,LK),e(LK,XTr),e(PE,zTr),e(K,QTr),e(K,BE),e(BE,N5e),e(N5e,WTr),e(BE,UTr),e(BE,yK),e(yK,HTr),e(BE,JTr),e(K,YTr),e(K,IE),e(IE,q5e),e(q5e,ZTr),e(IE,KTr),e(IE,xK),e(xK,eMr),e(IE,oMr),e(K,rMr),e(K,NE),e(NE,j5e),e(j5e,tMr),e(NE,aMr),e(NE,$K),e($K,nMr),e(NE,sMr),e(K,lMr),e(K,qE),e(qE,D5e),e(D5e,iMr),e(qE,dMr),e(qE,kK),e(kK,mMr),e(qE,cMr),e(K,fMr),e(K,jE),e(jE,G5e),e(G5e,gMr),e(jE,hMr),e(jE,SK),e(SK,uMr),e(jE,pMr),e(K,_Mr),e(K,DE),e(DE,O5e),e(O5e,bMr),e(DE,vMr),e(DE,RK),e(RK,FMr),e(DE,TMr),e(K,MMr),e(K,GE),e(GE,V5e),e(V5e,EMr),e(GE,CMr),e(GE,PK),e(PK,wMr),e(GE,AMr),e(K,LMr),e(K,OE),e(OE,X5e),e(X5e,yMr),e(OE,xMr),e(OE,BK),e(BK,$Mr),e(OE,kMr),e(K,SMr),e(K,VE),e(VE,z5e),e(z5e,RMr),e(VE,PMr),e(VE,IK),e(IK,BMr),e(VE,IMr),e(K,NMr),e(K,XE),e(XE,Q5e),e(Q5e,qMr),e(XE,jMr),e(XE,NK),e(NK,DMr),e(XE,GMr),e(K,OMr),e(K,zE),e(zE,W5e),e(W5e,VMr),e(zE,XMr),e(zE,qK),e(qK,zMr),e(zE,QMr),e(K,WMr),e(K,QE),e(QE,U5e),e(U5e,UMr),e(QE,HMr),e(QE,jK),e(jK,JMr),e(QE,YMr),e(K,ZMr),e(K,WE),e(WE,H5e),e(H5e,KMr),e(WE,eEr),e(WE,DK),e(DK,oEr),e(WE,rEr),e(K,tEr),e(K,UE),e(UE,J5e),e(J5e,aEr),e(UE,nEr),e(UE,GK),e(GK,sEr),e(UE,lEr),e(K,iEr),e(K,HE),e(HE,Y5e),e(Y5e,dEr),e(HE,mEr),e(HE,OK),e(OK,cEr),e(HE,fEr),e(K,gEr),e(K,JE),e(JE,Z5e),e(Z5e,hEr),e(JE,uEr),e(JE,VK),e(VK,pEr),e(JE,_Er),e(K,bEr),e(K,YE),e(YE,K5e),e(K5e,vEr),e(YE,FEr),e(YE,XK),e(XK,TEr),e(YE,MEr),e(K,EEr),e(K,ZE),e(ZE,e0e),e(e0e,CEr),e(ZE,wEr),e(ZE,zK),e(zK,AEr),e(ZE,LEr),e(K,yEr),e(K,KE),e(KE,o0e),e(o0e,xEr),e(KE,$Er),e(KE,QK),e(QK,kEr),e(KE,SEr),e(co,REr),e(co,e4),e(e4,PEr),e(e4,r0e),e(r0e,BEr),e(e4,IEr),e(e4,t0e),e(t0e,NEr),e(co,qEr),M(o4,co,null),b(c,nio,_),b(c,cm,_),e(cm,r4),e(r4,a0e),M(PS,a0e,null),e(cm,jEr),e(cm,n0e),e(n0e,DEr),b(c,sio,_),b(c,Uo,_),M(BS,Uo,null),e(Uo,GEr),e(Uo,fm),e(fm,OEr),e(fm,WK),e(WK,VEr),e(fm,XEr),e(fm,UK),e(UK,zEr),e(fm,QEr),e(Uo,WEr),e(Uo,IS),e(IS,UEr),e(IS,s0e),e(s0e,HEr),e(IS,JEr),e(Uo,YEr),e(Uo,Pt),M(NS,Pt,null),e(Pt,ZEr),e(Pt,l0e),e(l0e,KEr),e(Pt,e4r),e(Pt,gm),e(gm,o4r),e(gm,i0e),e(i0e,r4r),e(gm,t4r),e(gm,HK),e(HK,a4r),e(gm,n4r),e(Pt,s4r),M(t4,Pt,null),e(Uo,l4r),e(Uo,fo),M(qS,fo,null),e(fo,i4r),e(fo,d0e),e(d0e,d4r),e(fo,m4r),e(fo,Fn),e(Fn,c4r),e(Fn,m0e),e(m0e,f4r),e(Fn,g4r),e(Fn,c0e),e(c0e,h4r),e(Fn,u4r),e(Fn,f0e),e(f0e,p4r),e(Fn,_4r),e(fo,b4r),e(fo,Ye),e(Ye,a4),e(a4,g0e),e(g0e,v4r),e(a4,F4r),e(a4,JK),e(JK,T4r),e(a4,M4r),e(Ye,E4r),e(Ye,n4),e(n4,h0e),e(h0e,C4r),e(n4,w4r),e(n4,YK),e(YK,A4r),e(n4,L4r),e(Ye,y4r),e(Ye,s4),e(s4,u0e),e(u0e,x4r),e(s4,$4r),e(s4,ZK),e(ZK,k4r),e(s4,S4r),e(Ye,R4r),e(Ye,l4),e(l4,p0e),e(p0e,P4r),e(l4,B4r),e(l4,KK),e(KK,I4r),e(l4,N4r),e(Ye,q4r),e(Ye,i4),e(i4,_0e),e(_0e,j4r),e(i4,D4r),e(i4,eee),e(eee,G4r),e(i4,O4r),e(Ye,V4r),e(Ye,d4),e(d4,b0e),e(b0e,X4r),e(d4,z4r),e(d4,oee),e(oee,Q4r),e(d4,W4r),e(Ye,U4r),e(Ye,m4),e(m4,v0e),e(v0e,H4r),e(m4,J4r),e(m4,ree),e(ree,Y4r),e(m4,Z4r),e(fo,K4r),e(fo,c4),e(c4,eCr),e(c4,F0e),e(F0e,oCr),e(c4,rCr),e(c4,T0e),e(T0e,tCr),e(fo,aCr),M(f4,fo,null),b(c,lio,_),b(c,hm,_),e(hm,g4),e(g4,M0e),M(jS,M0e,null),e(hm,nCr),e(hm,E0e),e(E0e,sCr),b(c,iio,_),b(c,Ho,_),M(DS,Ho,null),e(Ho,lCr),e(Ho,um),e(um,iCr),e(um,tee),e(tee,dCr),e(um,mCr),e(um,aee),e(aee,cCr),e(um,fCr),e(Ho,gCr),e(Ho,GS),e(GS,hCr),e(GS,C0e),e(C0e,uCr),e(GS,pCr),e(Ho,_Cr),e(Ho,Bt),M(OS,Bt,null),e(Bt,bCr),e(Bt,w0e),e(w0e,vCr),e(Bt,FCr),e(Bt,pm),e(pm,TCr),e(pm,A0e),e(A0e,MCr),e(pm,ECr),e(pm,nee),e(nee,CCr),e(pm,wCr),e(Bt,ACr),M(h4,Bt,null),e(Ho,LCr),e(Ho,go),M(VS,go,null),e(go,yCr),e(go,L0e),e(L0e,xCr),e(go,$Cr),e(go,Tn),e(Tn,kCr),e(Tn,y0e),e(y0e,SCr),e(Tn,RCr),e(Tn,x0e),e(x0e,PCr),e(Tn,BCr),e(Tn,$0e),e($0e,ICr),e(Tn,NCr),e(go,qCr),e(go,U),e(U,u4),e(u4,k0e),e(k0e,jCr),e(u4,DCr),e(u4,see),e(see,GCr),e(u4,OCr),e(U,VCr),e(U,p4),e(p4,S0e),e(S0e,XCr),e(p4,zCr),e(p4,lee),e(lee,QCr),e(p4,WCr),e(U,UCr),e(U,_4),e(_4,R0e),e(R0e,HCr),e(_4,JCr),e(_4,iee),e(iee,YCr),e(_4,ZCr),e(U,KCr),e(U,b4),e(b4,P0e),e(P0e,e3r),e(b4,o3r),e(b4,dee),e(dee,r3r),e(b4,t3r),e(U,a3r),e(U,v4),e(v4,B0e),e(B0e,n3r),e(v4,s3r),e(v4,mee),e(mee,l3r),e(v4,i3r),e(U,d3r),e(U,F4),e(F4,I0e),e(I0e,m3r),e(F4,c3r),e(F4,cee),e(cee,f3r),e(F4,g3r),e(U,h3r),e(U,T4),e(T4,N0e),e(N0e,u3r),e(T4,p3r),e(T4,fee),e(fee,_3r),e(T4,b3r),e(U,v3r),e(U,M4),e(M4,q0e),e(q0e,F3r),e(M4,T3r),e(M4,gee),e(gee,M3r),e(M4,E3r),e(U,C3r),e(U,E4),e(E4,j0e),e(j0e,w3r),e(E4,A3r),e(E4,hee),e(hee,L3r),e(E4,y3r),e(U,x3r),e(U,C4),e(C4,D0e),e(D0e,$3r),e(C4,k3r),e(C4,uee),e(uee,S3r),e(C4,R3r),e(U,P3r),e(U,w4),e(w4,G0e),e(G0e,B3r),e(w4,I3r),e(w4,pee),e(pee,N3r),e(w4,q3r),e(U,j3r),e(U,A4),e(A4,O0e),e(O0e,D3r),e(A4,G3r),e(A4,_ee),e(_ee,O3r),e(A4,V3r),e(U,X3r),e(U,L4),e(L4,V0e),e(V0e,z3r),e(L4,Q3r),e(L4,bee),e(bee,W3r),e(L4,U3r),e(U,H3r),e(U,y4),e(y4,X0e),e(X0e,J3r),e(y4,Y3r),e(y4,vee),e(vee,Z3r),e(y4,K3r),e(U,e5r),e(U,x4),e(x4,z0e),e(z0e,o5r),e(x4,r5r),e(x4,Fee),e(Fee,t5r),e(x4,a5r),e(U,n5r),e(U,$4),e($4,Q0e),e(Q0e,s5r),e($4,l5r),e($4,Tee),e(Tee,i5r),e($4,d5r),e(U,m5r),e(U,k4),e(k4,W0e),e(W0e,c5r),e(k4,f5r),e(k4,Mee),e(Mee,g5r),e(k4,h5r),e(U,u5r),e(U,S4),e(S4,U0e),e(U0e,p5r),e(S4,_5r),e(S4,Eee),e(Eee,b5r),e(S4,v5r),e(U,F5r),e(U,R4),e(R4,H0e),e(H0e,T5r),e(R4,M5r),e(R4,Cee),e(Cee,E5r),e(R4,C5r),e(U,w5r),e(U,P4),e(P4,J0e),e(J0e,A5r),e(P4,L5r),e(P4,wee),e(wee,y5r),e(P4,x5r),e(U,$5r),e(U,B4),e(B4,Y0e),e(Y0e,k5r),e(B4,S5r),e(B4,Aee),e(Aee,R5r),e(B4,P5r),e(U,B5r),e(U,I4),e(I4,Z0e),e(Z0e,I5r),e(I4,N5r),e(I4,Lee),e(Lee,q5r),e(I4,j5r),e(U,D5r),e(U,N4),e(N4,K0e),e(K0e,G5r),e(N4,O5r),e(N4,yee),e(yee,V5r),e(N4,X5r),e(U,z5r),e(U,q4),e(q4,ewe),e(ewe,Q5r),e(q4,W5r),e(q4,xee),e(xee,U5r),e(q4,H5r),e(U,J5r),e(U,j4),e(j4,owe),e(owe,Y5r),e(j4,Z5r),e(j4,$ee),e($ee,K5r),e(j4,e0r),e(U,o0r),e(U,D4),e(D4,rwe),e(rwe,r0r),e(D4,t0r),e(D4,kee),e(kee,a0r),e(D4,n0r),e(U,s0r),e(U,G4),e(G4,twe),e(twe,l0r),e(G4,i0r),e(G4,See),e(See,d0r),e(G4,m0r),e(U,c0r),e(U,O4),e(O4,awe),e(awe,f0r),e(O4,g0r),e(O4,Ree),e(Ree,h0r),e(O4,u0r),e(U,p0r),e(U,V4),e(V4,nwe),e(nwe,_0r),e(V4,b0r),e(V4,Pee),e(Pee,v0r),e(V4,F0r),e(U,T0r),e(U,X4),e(X4,swe),e(swe,M0r),e(X4,E0r),e(X4,Bee),e(Bee,C0r),e(X4,w0r),e(U,A0r),e(U,z4),e(z4,lwe),e(lwe,L0r),e(z4,y0r),e(z4,Iee),e(Iee,x0r),e(z4,$0r),e(U,k0r),e(U,Q4),e(Q4,iwe),e(iwe,S0r),e(Q4,R0r),e(Q4,Nee),e(Nee,P0r),e(Q4,B0r),e(U,I0r),e(U,W4),e(W4,dwe),e(dwe,N0r),e(W4,q0r),e(W4,qee),e(qee,j0r),e(W4,D0r),e(U,G0r),e(U,U4),e(U4,mwe),e(mwe,O0r),e(U4,V0r),e(U4,jee),e(jee,X0r),e(U4,z0r),e(U,Q0r),e(U,H4),e(H4,cwe),e(cwe,W0r),e(H4,U0r),e(H4,Dee),e(Dee,H0r),e(H4,J0r),e(U,Y0r),e(U,J4),e(J4,fwe),e(fwe,Z0r),e(J4,K0r),e(J4,Gee),e(Gee,ewr),e(J4,owr),e(U,rwr),e(U,Y4),e(Y4,gwe),e(gwe,twr),e(Y4,awr),e(Y4,Oee),e(Oee,nwr),e(Y4,swr),e(U,lwr),e(U,Z4),e(Z4,hwe),e(hwe,iwr),e(Z4,dwr),e(Z4,Vee),e(Vee,mwr),e(Z4,cwr),e(U,fwr),e(U,K4),e(K4,uwe),e(uwe,gwr),e(K4,hwr),e(K4,Xee),e(Xee,uwr),e(K4,pwr),e(U,_wr),e(U,eC),e(eC,pwe),e(pwe,bwr),e(eC,vwr),e(eC,zee),e(zee,Fwr),e(eC,Twr),e(U,Mwr),e(U,oC),e(oC,_we),e(_we,Ewr),e(oC,Cwr),e(oC,Qee),e(Qee,wwr),e(oC,Awr),e(U,Lwr),e(U,rC),e(rC,bwe),e(bwe,ywr),e(rC,xwr),e(rC,Wee),e(Wee,$wr),e(rC,kwr),e(go,Swr),e(go,tC),e(tC,Rwr),e(tC,vwe),e(vwe,Pwr),e(tC,Bwr),e(tC,Fwe),e(Fwe,Iwr),e(go,Nwr),M(aC,go,null),b(c,dio,_),b(c,_m,_),e(_m,nC),e(nC,Twe),M(XS,Twe,null),e(_m,qwr),e(_m,Mwe),e(Mwe,jwr),b(c,mio,_),b(c,Jo,_),M(zS,Jo,null),e(Jo,Dwr),e(Jo,bm),e(bm,Gwr),e(bm,Uee),e(Uee,Owr),e(bm,Vwr),e(bm,Hee),e(Hee,Xwr),e(bm,zwr),e(Jo,Qwr),e(Jo,QS),e(QS,Wwr),e(QS,Ewe),e(Ewe,Uwr),e(QS,Hwr),e(Jo,Jwr),e(Jo,It),M(WS,It,null),e(It,Ywr),e(It,Cwe),e(Cwe,Zwr),e(It,Kwr),e(It,vm),e(vm,eAr),e(vm,wwe),e(wwe,oAr),e(vm,rAr),e(vm,Jee),e(Jee,tAr),e(vm,aAr),e(It,nAr),M(sC,It,null),e(Jo,sAr),e(Jo,ho),M(US,ho,null),e(ho,lAr),e(ho,Awe),e(Awe,iAr),e(ho,dAr),e(ho,Mn),e(Mn,mAr),e(Mn,Lwe),e(Lwe,cAr),e(Mn,fAr),e(Mn,ywe),e(ywe,gAr),e(Mn,hAr),e(Mn,xwe),e(xwe,uAr),e(Mn,pAr),e(ho,_Ar),e(ho,O),e(O,lC),e(lC,$we),e($we,bAr),e(lC,vAr),e(lC,Yee),e(Yee,FAr),e(lC,TAr),e(O,MAr),e(O,iC),e(iC,kwe),e(kwe,EAr),e(iC,CAr),e(iC,Zee),e(Zee,wAr),e(iC,AAr),e(O,LAr),e(O,dC),e(dC,Swe),e(Swe,yAr),e(dC,xAr),e(dC,Kee),e(Kee,$Ar),e(dC,kAr),e(O,SAr),e(O,mC),e(mC,Rwe),e(Rwe,RAr),e(mC,PAr),e(mC,eoe),e(eoe,BAr),e(mC,IAr),e(O,NAr),e(O,cC),e(cC,Pwe),e(Pwe,qAr),e(cC,jAr),e(cC,ooe),e(ooe,DAr),e(cC,GAr),e(O,OAr),e(O,fC),e(fC,Bwe),e(Bwe,VAr),e(fC,XAr),e(fC,roe),e(roe,zAr),e(fC,QAr),e(O,WAr),e(O,gC),e(gC,Iwe),e(Iwe,UAr),e(gC,HAr),e(gC,toe),e(toe,JAr),e(gC,YAr),e(O,ZAr),e(O,hC),e(hC,Nwe),e(Nwe,KAr),e(hC,e6r),e(hC,aoe),e(aoe,o6r),e(hC,r6r),e(O,t6r),e(O,uC),e(uC,qwe),e(qwe,a6r),e(uC,n6r),e(uC,noe),e(noe,s6r),e(uC,l6r),e(O,i6r),e(O,pC),e(pC,jwe),e(jwe,d6r),e(pC,m6r),e(pC,soe),e(soe,c6r),e(pC,f6r),e(O,g6r),e(O,_C),e(_C,Dwe),e(Dwe,h6r),e(_C,u6r),e(_C,loe),e(loe,p6r),e(_C,_6r),e(O,b6r),e(O,bC),e(bC,Gwe),e(Gwe,v6r),e(bC,F6r),e(bC,ioe),e(ioe,T6r),e(bC,M6r),e(O,E6r),e(O,vC),e(vC,Owe),e(Owe,C6r),e(vC,w6r),e(vC,doe),e(doe,A6r),e(vC,L6r),e(O,y6r),e(O,FC),e(FC,Vwe),e(Vwe,x6r),e(FC,$6r),e(FC,moe),e(moe,k6r),e(FC,S6r),e(O,R6r),e(O,TC),e(TC,Xwe),e(Xwe,P6r),e(TC,B6r),e(TC,coe),e(coe,I6r),e(TC,N6r),e(O,q6r),e(O,MC),e(MC,zwe),e(zwe,j6r),e(MC,D6r),e(MC,foe),e(foe,G6r),e(MC,O6r),e(O,V6r),e(O,EC),e(EC,Qwe),e(Qwe,X6r),e(EC,z6r),e(EC,goe),e(goe,Q6r),e(EC,W6r),e(O,U6r),e(O,CC),e(CC,Wwe),e(Wwe,H6r),e(CC,J6r),e(CC,hoe),e(hoe,Y6r),e(CC,Z6r),e(O,K6r),e(O,wC),e(wC,Uwe),e(Uwe,e7r),e(wC,o7r),e(wC,uoe),e(uoe,r7r),e(wC,t7r),e(O,a7r),e(O,AC),e(AC,Hwe),e(Hwe,n7r),e(AC,s7r),e(AC,poe),e(poe,l7r),e(AC,i7r),e(O,d7r),e(O,LC),e(LC,Jwe),e(Jwe,m7r),e(LC,c7r),e(LC,_oe),e(_oe,f7r),e(LC,g7r),e(O,h7r),e(O,yC),e(yC,Ywe),e(Ywe,u7r),e(yC,p7r),e(yC,boe),e(boe,_7r),e(yC,b7r),e(O,v7r),e(O,xC),e(xC,Zwe),e(Zwe,F7r),e(xC,T7r),e(xC,voe),e(voe,M7r),e(xC,E7r),e(O,C7r),e(O,$C),e($C,Kwe),e(Kwe,w7r),e($C,A7r),e($C,Foe),e(Foe,L7r),e($C,y7r),e(O,x7r),e(O,kC),e(kC,eAe),e(eAe,$7r),e(kC,k7r),e(kC,Toe),e(Toe,S7r),e(kC,R7r),e(O,P7r),e(O,SC),e(SC,oAe),e(oAe,B7r),e(SC,I7r),e(SC,Moe),e(Moe,N7r),e(SC,q7r),e(O,j7r),e(O,RC),e(RC,rAe),e(rAe,D7r),e(RC,G7r),e(RC,Eoe),e(Eoe,O7r),e(RC,V7r),e(O,X7r),e(O,PC),e(PC,tAe),e(tAe,z7r),e(PC,Q7r),e(PC,Coe),e(Coe,W7r),e(PC,U7r),e(O,H7r),e(O,BC),e(BC,aAe),e(aAe,J7r),e(BC,Y7r),e(BC,woe),e(woe,Z7r),e(BC,K7r),e(O,e8r),e(O,IC),e(IC,nAe),e(nAe,o8r),e(IC,r8r),e(IC,Aoe),e(Aoe,t8r),e(IC,a8r),e(O,n8r),e(O,NC),e(NC,sAe),e(sAe,s8r),e(NC,l8r),e(NC,Loe),e(Loe,i8r),e(NC,d8r),e(O,m8r),e(O,qC),e(qC,lAe),e(lAe,c8r),e(qC,f8r),e(qC,yoe),e(yoe,g8r),e(qC,h8r),e(O,u8r),e(O,jC),e(jC,iAe),e(iAe,p8r),e(jC,_8r),e(jC,xoe),e(xoe,b8r),e(jC,v8r),e(O,F8r),e(O,DC),e(DC,dAe),e(dAe,T8r),e(DC,M8r),e(DC,$oe),e($oe,E8r),e(DC,C8r),e(O,w8r),e(O,GC),e(GC,mAe),e(mAe,A8r),e(GC,L8r),e(GC,koe),e(koe,y8r),e(GC,x8r),e(O,$8r),e(O,OC),e(OC,cAe),e(cAe,k8r),e(OC,S8r),e(OC,Soe),e(Soe,R8r),e(OC,P8r),e(O,B8r),e(O,VC),e(VC,fAe),e(fAe,I8r),e(VC,N8r),e(VC,Roe),e(Roe,q8r),e(VC,j8r),e(O,D8r),e(O,XC),e(XC,gAe),e(gAe,G8r),e(XC,O8r),e(XC,Poe),e(Poe,V8r),e(XC,X8r),e(O,z8r),e(O,zC),e(zC,hAe),e(hAe,Q8r),e(zC,W8r),e(zC,Boe),e(Boe,U8r),e(zC,H8r),e(O,J8r),e(O,QC),e(QC,uAe),e(uAe,Y8r),e(QC,Z8r),e(QC,Ioe),e(Ioe,K8r),e(QC,eLr),e(O,oLr),e(O,WC),e(WC,pAe),e(pAe,rLr),e(WC,tLr),e(WC,Noe),e(Noe,aLr),e(WC,nLr),e(O,sLr),e(O,UC),e(UC,_Ae),e(_Ae,lLr),e(UC,iLr),e(UC,qoe),e(qoe,dLr),e(UC,mLr),e(O,cLr),e(O,HC),e(HC,bAe),e(bAe,fLr),e(HC,gLr),e(HC,joe),e(joe,hLr),e(HC,uLr),e(O,pLr),e(O,JC),e(JC,vAe),e(vAe,_Lr),e(JC,bLr),e(JC,Doe),e(Doe,vLr),e(JC,FLr),e(O,TLr),e(O,YC),e(YC,FAe),e(FAe,MLr),e(YC,ELr),e(YC,Goe),e(Goe,CLr),e(YC,wLr),e(O,ALr),e(O,ZC),e(ZC,TAe),e(TAe,LLr),e(ZC,yLr),e(ZC,Ooe),e(Ooe,xLr),e(ZC,$Lr),e(O,kLr),e(O,KC),e(KC,MAe),e(MAe,SLr),e(KC,RLr),e(KC,Voe),e(Voe,PLr),e(KC,BLr),e(O,ILr),e(O,e3),e(e3,EAe),e(EAe,NLr),e(e3,qLr),e(e3,Xoe),e(Xoe,jLr),e(e3,DLr),e(O,GLr),e(O,o3),e(o3,CAe),e(CAe,OLr),e(o3,VLr),e(o3,zoe),e(zoe,XLr),e(o3,zLr),e(ho,QLr),e(ho,r3),e(r3,WLr),e(r3,wAe),e(wAe,ULr),e(r3,HLr),e(r3,AAe),e(AAe,JLr),e(ho,YLr),M(t3,ho,null),b(c,cio,_),b(c,Fm,_),e(Fm,a3),e(a3,LAe),M(HS,LAe,null),e(Fm,ZLr),e(Fm,yAe),e(yAe,KLr),b(c,fio,_),b(c,Yo,_),M(JS,Yo,null),e(Yo,eyr),e(Yo,Tm),e(Tm,oyr),e(Tm,Qoe),e(Qoe,ryr),e(Tm,tyr),e(Tm,Woe),e(Woe,ayr),e(Tm,nyr),e(Yo,syr),e(Yo,YS),e(YS,lyr),e(YS,xAe),e(xAe,iyr),e(YS,dyr),e(Yo,myr),e(Yo,Nt),M(ZS,Nt,null),e(Nt,cyr),e(Nt,$Ae),e($Ae,fyr),e(Nt,gyr),e(Nt,Mm),e(Mm,hyr),e(Mm,kAe),e(kAe,uyr),e(Mm,pyr),e(Mm,Uoe),e(Uoe,_yr),e(Mm,byr),e(Nt,vyr),M(n3,Nt,null),e(Yo,Fyr),e(Yo,uo),M(KS,uo,null),e(uo,Tyr),e(uo,SAe),e(SAe,Myr),e(uo,Eyr),e(uo,En),e(En,Cyr),e(En,RAe),e(RAe,wyr),e(En,Ayr),e(En,PAe),e(PAe,Lyr),e(En,yyr),e(En,BAe),e(BAe,xyr),e(En,$yr),e(uo,kyr),e(uo,IAe),e(IAe,s3),e(s3,NAe),e(NAe,Syr),e(s3,Ryr),e(s3,Hoe),e(Hoe,Pyr),e(s3,Byr),e(uo,Iyr),e(uo,l3),e(l3,Nyr),e(l3,qAe),e(qAe,qyr),e(l3,jyr),e(l3,jAe),e(jAe,Dyr),e(uo,Gyr),M(i3,uo,null),b(c,gio,_),b(c,Em,_),e(Em,d3),e(d3,DAe),M(eR,DAe,null),e(Em,Oyr),e(Em,GAe),e(GAe,Vyr),b(c,hio,_),b(c,Zo,_),M(oR,Zo,null),e(Zo,Xyr),e(Zo,Cm),e(Cm,zyr),e(Cm,Joe),e(Joe,Qyr),e(Cm,Wyr),e(Cm,Yoe),e(Yoe,Uyr),e(Cm,Hyr),e(Zo,Jyr),e(Zo,rR),e(rR,Yyr),e(rR,OAe),e(OAe,Zyr),e(rR,Kyr),e(Zo,e9r),e(Zo,qt),M(tR,qt,null),e(qt,o9r),e(qt,VAe),e(VAe,r9r),e(qt,t9r),e(qt,wm),e(wm,a9r),e(wm,XAe),e(XAe,n9r),e(wm,s9r),e(wm,Zoe),e(Zoe,l9r),e(wm,i9r),e(qt,d9r),M(m3,qt,null),e(Zo,m9r),e(Zo,po),M(aR,po,null),e(po,c9r),e(po,zAe),e(zAe,f9r),e(po,g9r),e(po,Cn),e(Cn,h9r),e(Cn,QAe),e(QAe,u9r),e(Cn,p9r),e(Cn,WAe),e(WAe,_9r),e(Cn,b9r),e(Cn,UAe),e(UAe,v9r),e(Cn,F9r),e(po,T9r),e(po,Am),e(Am,c3),e(c3,HAe),e(HAe,M9r),e(c3,E9r),e(c3,Koe),e(Koe,C9r),e(c3,w9r),e(Am,A9r),e(Am,f3),e(f3,JAe),e(JAe,L9r),e(f3,y9r),e(f3,ere),e(ere,x9r),e(f3,$9r),e(Am,k9r),e(Am,g3),e(g3,YAe),e(YAe,S9r),e(g3,R9r),e(g3,ore),e(ore,P9r),e(g3,B9r),e(po,I9r),e(po,h3),e(h3,N9r),e(h3,ZAe),e(ZAe,q9r),e(h3,j9r),e(h3,KAe),e(KAe,D9r),e(po,G9r),M(u3,po,null),b(c,uio,_),b(c,Lm,_),e(Lm,p3),e(p3,e6e),M(nR,e6e,null),e(Lm,O9r),e(Lm,o6e),e(o6e,V9r),b(c,pio,_),b(c,Ko,_),M(sR,Ko,null),e(Ko,X9r),e(Ko,ym),e(ym,z9r),e(ym,rre),e(rre,Q9r),e(ym,W9r),e(ym,tre),e(tre,U9r),e(ym,H9r),e(Ko,J9r),e(Ko,lR),e(lR,Y9r),e(lR,r6e),e(r6e,Z9r),e(lR,K9r),e(Ko,exr),e(Ko,jt),M(iR,jt,null),e(jt,oxr),e(jt,t6e),e(t6e,rxr),e(jt,txr),e(jt,xm),e(xm,axr),e(xm,a6e),e(a6e,nxr),e(xm,sxr),e(xm,are),e(are,lxr),e(xm,ixr),e(jt,dxr),M(_3,jt,null),e(Ko,mxr),e(Ko,_o),M(dR,_o,null),e(_o,cxr),e(_o,n6e),e(n6e,fxr),e(_o,gxr),e(_o,wn),e(wn,hxr),e(wn,s6e),e(s6e,uxr),e(wn,pxr),e(wn,l6e),e(l6e,_xr),e(wn,bxr),e(wn,i6e),e(i6e,vxr),e(wn,Fxr),e(_o,Txr),e(_o,Fe),e(Fe,b3),e(b3,d6e),e(d6e,Mxr),e(b3,Exr),e(b3,nre),e(nre,Cxr),e(b3,wxr),e(Fe,Axr),e(Fe,v3),e(v3,m6e),e(m6e,Lxr),e(v3,yxr),e(v3,sre),e(sre,xxr),e(v3,$xr),e(Fe,kxr),e(Fe,F3),e(F3,c6e),e(c6e,Sxr),e(F3,Rxr),e(F3,lre),e(lre,Pxr),e(F3,Bxr),e(Fe,Ixr),e(Fe,T3),e(T3,f6e),e(f6e,Nxr),e(T3,qxr),e(T3,ire),e(ire,jxr),e(T3,Dxr),e(Fe,Gxr),e(Fe,Nl),e(Nl,g6e),e(g6e,Oxr),e(Nl,Vxr),e(Nl,dre),e(dre,Xxr),e(Nl,zxr),e(Nl,mre),e(mre,Qxr),e(Nl,Wxr),e(Fe,Uxr),e(Fe,M3),e(M3,h6e),e(h6e,Hxr),e(M3,Jxr),e(M3,cre),e(cre,Yxr),e(M3,Zxr),e(Fe,Kxr),e(Fe,ql),e(ql,u6e),e(u6e,e$r),e(ql,o$r),e(ql,fre),e(fre,r$r),e(ql,t$r),e(ql,gre),e(gre,a$r),e(ql,n$r),e(Fe,s$r),e(Fe,E3),e(E3,p6e),e(p6e,l$r),e(E3,i$r),e(E3,hre),e(hre,d$r),e(E3,m$r),e(Fe,c$r),e(Fe,Dt),e(Dt,_6e),e(_6e,f$r),e(Dt,g$r),e(Dt,ure),e(ure,h$r),e(Dt,u$r),e(Dt,pre),e(pre,p$r),e(Dt,_$r),e(Dt,_re),e(_re,b$r),e(Dt,v$r),e(Fe,F$r),e(Fe,C3),e(C3,b6e),e(b6e,T$r),e(C3,M$r),e(C3,bre),e(bre,E$r),e(C3,C$r),e(Fe,w$r),e(Fe,w3),e(w3,v6e),e(v6e,A$r),e(w3,L$r),e(w3,vre),e(vre,y$r),e(w3,x$r),e(Fe,$$r),e(Fe,A3),e(A3,F6e),e(F6e,k$r),e(A3,S$r),e(A3,Fre),e(Fre,R$r),e(A3,P$r),e(Fe,B$r),e(Fe,L3),e(L3,T6e),e(T6e,I$r),e(L3,N$r),e(L3,Tre),e(Tre,q$r),e(L3,j$r),e(Fe,D$r),e(Fe,y3),e(y3,M6e),e(M6e,G$r),e(y3,O$r),e(y3,Mre),e(Mre,V$r),e(y3,X$r),e(Fe,z$r),e(Fe,x3),e(x3,E6e),e(E6e,Q$r),e(x3,W$r),e(x3,Ere),e(Ere,U$r),e(x3,H$r),e(Fe,J$r),e(Fe,$3),e($3,C6e),e(C6e,Y$r),e($3,Z$r),e($3,Cre),e(Cre,K$r),e($3,ekr),e(Fe,okr),e(Fe,k3),e(k3,w6e),e(w6e,rkr),e(k3,tkr),e(k3,wre),e(wre,akr),e(k3,nkr),e(Fe,skr),e(Fe,S3),e(S3,A6e),e(A6e,lkr),e(S3,ikr),e(S3,Are),e(Are,dkr),e(S3,mkr),e(_o,ckr),e(_o,R3),e(R3,fkr),e(R3,L6e),e(L6e,gkr),e(R3,hkr),e(R3,y6e),e(y6e,ukr),e(_o,pkr),M(P3,_o,null),b(c,_io,_),b(c,$m,_),e($m,B3),e(B3,x6e),M(mR,x6e,null),e($m,_kr),e($m,$6e),e($6e,bkr),b(c,bio,_),b(c,er,_),M(cR,er,null),e(er,vkr),e(er,km),e(km,Fkr),e(km,Lre),e(Lre,Tkr),e(km,Mkr),e(km,yre),e(yre,Ekr),e(km,Ckr),e(er,wkr),e(er,fR),e(fR,Akr),e(fR,k6e),e(k6e,Lkr),e(fR,ykr),e(er,xkr),e(er,Gt),M(gR,Gt,null),e(Gt,$kr),e(Gt,S6e),e(S6e,kkr),e(Gt,Skr),e(Gt,Sm),e(Sm,Rkr),e(Sm,R6e),e(R6e,Pkr),e(Sm,Bkr),e(Sm,xre),e(xre,Ikr),e(Sm,Nkr),e(Gt,qkr),M(I3,Gt,null),e(er,jkr),e(er,bo),M(hR,bo,null),e(bo,Dkr),e(bo,P6e),e(P6e,Gkr),e(bo,Okr),e(bo,An),e(An,Vkr),e(An,B6e),e(B6e,Xkr),e(An,zkr),e(An,I6e),e(I6e,Qkr),e(An,Wkr),e(An,N6e),e(N6e,Ukr),e(An,Hkr),e(bo,Jkr),e(bo,q6e),e(q6e,N3),e(N3,j6e),e(j6e,Ykr),e(N3,Zkr),e(N3,$re),e($re,Kkr),e(N3,eSr),e(bo,oSr),e(bo,q3),e(q3,rSr),e(q3,D6e),e(D6e,tSr),e(q3,aSr),e(q3,G6e),e(G6e,nSr),e(bo,sSr),M(j3,bo,null),b(c,vio,_),b(c,Rm,_),e(Rm,D3),e(D3,O6e),M(uR,O6e,null),e(Rm,lSr),e(Rm,V6e),e(V6e,iSr),b(c,Fio,_),b(c,or,_),M(pR,or,null),e(or,dSr),e(or,Pm),e(Pm,mSr),e(Pm,kre),e(kre,cSr),e(Pm,fSr),e(Pm,Sre),e(Sre,gSr),e(Pm,hSr),e(or,uSr),e(or,_R),e(_R,pSr),e(_R,X6e),e(X6e,_Sr),e(_R,bSr),e(or,vSr),e(or,Ot),M(bR,Ot,null),e(Ot,FSr),e(Ot,z6e),e(z6e,TSr),e(Ot,MSr),e(Ot,Bm),e(Bm,ESr),e(Bm,Q6e),e(Q6e,CSr),e(Bm,wSr),e(Bm,Rre),e(Rre,ASr),e(Bm,LSr),e(Ot,ySr),M(G3,Ot,null),e(or,xSr),e(or,vo),M(vR,vo,null),e(vo,$Sr),e(vo,W6e),e(W6e,kSr),e(vo,SSr),e(vo,Ln),e(Ln,RSr),e(Ln,U6e),e(U6e,PSr),e(Ln,BSr),e(Ln,H6e),e(H6e,ISr),e(Ln,NSr),e(Ln,J6e),e(J6e,qSr),e(Ln,jSr),e(vo,DSr),e(vo,Y6e),e(Y6e,O3),e(O3,Z6e),e(Z6e,GSr),e(O3,OSr),e(O3,Pre),e(Pre,VSr),e(O3,XSr),e(vo,zSr),e(vo,V3),e(V3,QSr),e(V3,K6e),e(K6e,WSr),e(V3,USr),e(V3,e7e),e(e7e,HSr),e(vo,JSr),M(X3,vo,null),b(c,Tio,_),b(c,Im,_),e(Im,z3),e(z3,o7e),M(FR,o7e,null),e(Im,YSr),e(Im,r7e),e(r7e,ZSr),b(c,Mio,_),b(c,rr,_),M(TR,rr,null),e(rr,KSr),e(rr,Nm),e(Nm,eRr),e(Nm,Bre),e(Bre,oRr),e(Nm,rRr),e(Nm,Ire),e(Ire,tRr),e(Nm,aRr),e(rr,nRr),e(rr,MR),e(MR,sRr),e(MR,t7e),e(t7e,lRr),e(MR,iRr),e(rr,dRr),e(rr,Vt),M(ER,Vt,null),e(Vt,mRr),e(Vt,a7e),e(a7e,cRr),e(Vt,fRr),e(Vt,qm),e(qm,gRr),e(qm,n7e),e(n7e,hRr),e(qm,uRr),e(qm,Nre),e(Nre,pRr),e(qm,_Rr),e(Vt,bRr),M(Q3,Vt,null),e(rr,vRr),e(rr,Fo),M(CR,Fo,null),e(Fo,FRr),e(Fo,s7e),e(s7e,TRr),e(Fo,MRr),e(Fo,yn),e(yn,ERr),e(yn,l7e),e(l7e,CRr),e(yn,wRr),e(yn,i7e),e(i7e,ARr),e(yn,LRr),e(yn,d7e),e(d7e,yRr),e(yn,xRr),e(Fo,$Rr),e(Fo,m7e),e(m7e,W3),e(W3,c7e),e(c7e,kRr),e(W3,SRr),e(W3,qre),e(qre,RRr),e(W3,PRr),e(Fo,BRr),e(Fo,U3),e(U3,IRr),e(U3,f7e),e(f7e,NRr),e(U3,qRr),e(U3,g7e),e(g7e,jRr),e(Fo,DRr),M(H3,Fo,null),b(c,Eio,_),b(c,jm,_),e(jm,J3),e(J3,h7e),M(wR,h7e,null),e(jm,GRr),e(jm,u7e),e(u7e,ORr),b(c,Cio,_),b(c,tr,_),M(AR,tr,null),e(tr,VRr),e(tr,Dm),e(Dm,XRr),e(Dm,jre),e(jre,zRr),e(Dm,QRr),e(Dm,Dre),e(Dre,WRr),e(Dm,URr),e(tr,HRr),e(tr,LR),e(LR,JRr),e(LR,p7e),e(p7e,YRr),e(LR,ZRr),e(tr,KRr),e(tr,Xt),M(yR,Xt,null),e(Xt,ePr),e(Xt,_7e),e(_7e,oPr),e(Xt,rPr),e(Xt,Gm),e(Gm,tPr),e(Gm,b7e),e(b7e,aPr),e(Gm,nPr),e(Gm,Gre),e(Gre,sPr),e(Gm,lPr),e(Xt,iPr),M(Y3,Xt,null),e(tr,dPr),e(tr,To),M(xR,To,null),e(To,mPr),e(To,v7e),e(v7e,cPr),e(To,fPr),e(To,xn),e(xn,gPr),e(xn,F7e),e(F7e,hPr),e(xn,uPr),e(xn,T7e),e(T7e,pPr),e(xn,_Pr),e(xn,M7e),e(M7e,bPr),e(xn,vPr),e(To,FPr),e(To,Ne),e(Ne,Z3),e(Z3,E7e),e(E7e,TPr),e(Z3,MPr),e(Z3,Ore),e(Ore,EPr),e(Z3,CPr),e(Ne,wPr),e(Ne,K3),e(K3,C7e),e(C7e,APr),e(K3,LPr),e(K3,Vre),e(Vre,yPr),e(K3,xPr),e(Ne,$Pr),e(Ne,e5),e(e5,w7e),e(w7e,kPr),e(e5,SPr),e(e5,Xre),e(Xre,RPr),e(e5,PPr),e(Ne,BPr),e(Ne,o5),e(o5,A7e),e(A7e,IPr),e(o5,NPr),e(o5,zre),e(zre,qPr),e(o5,jPr),e(Ne,DPr),e(Ne,r5),e(r5,L7e),e(L7e,GPr),e(r5,OPr),e(r5,Qre),e(Qre,VPr),e(r5,XPr),e(Ne,zPr),e(Ne,t5),e(t5,y7e),e(y7e,QPr),e(t5,WPr),e(t5,Wre),e(Wre,UPr),e(t5,HPr),e(Ne,JPr),e(Ne,a5),e(a5,x7e),e(x7e,YPr),e(a5,ZPr),e(a5,Ure),e(Ure,KPr),e(a5,eBr),e(Ne,oBr),e(Ne,n5),e(n5,$7e),e($7e,rBr),e(n5,tBr),e(n5,Hre),e(Hre,aBr),e(n5,nBr),e(Ne,sBr),e(Ne,s5),e(s5,k7e),e(k7e,lBr),e(s5,iBr),e(s5,Jre),e(Jre,dBr),e(s5,mBr),e(To,cBr),e(To,l5),e(l5,fBr),e(l5,S7e),e(S7e,gBr),e(l5,hBr),e(l5,R7e),e(R7e,uBr),e(To,pBr),M(i5,To,null),b(c,wio,_),b(c,Om,_),e(Om,d5),e(d5,P7e),M($R,P7e,null),e(Om,_Br),e(Om,B7e),e(B7e,bBr),b(c,Aio,_),b(c,ar,_),M(kR,ar,null),e(ar,vBr),e(ar,Vm),e(Vm,FBr),e(Vm,Yre),e(Yre,TBr),e(Vm,MBr),e(Vm,Zre),e(Zre,EBr),e(Vm,CBr),e(ar,wBr),e(ar,SR),e(SR,ABr),e(SR,I7e),e(I7e,LBr),e(SR,yBr),e(ar,xBr),e(ar,zt),M(RR,zt,null),e(zt,$Br),e(zt,N7e),e(N7e,kBr),e(zt,SBr),e(zt,Xm),e(Xm,RBr),e(Xm,q7e),e(q7e,PBr),e(Xm,BBr),e(Xm,Kre),e(Kre,IBr),e(Xm,NBr),e(zt,qBr),M(m5,zt,null),e(ar,jBr),e(ar,Mo),M(PR,Mo,null),e(Mo,DBr),e(Mo,j7e),e(j7e,GBr),e(Mo,OBr),e(Mo,$n),e($n,VBr),e($n,D7e),e(D7e,XBr),e($n,zBr),e($n,G7e),e(G7e,QBr),e($n,WBr),e($n,O7e),e(O7e,UBr),e($n,HBr),e(Mo,JBr),e(Mo,vt),e(vt,c5),e(c5,V7e),e(V7e,YBr),e(c5,ZBr),e(c5,ete),e(ete,KBr),e(c5,eIr),e(vt,oIr),e(vt,f5),e(f5,X7e),e(X7e,rIr),e(f5,tIr),e(f5,ote),e(ote,aIr),e(f5,nIr),e(vt,sIr),e(vt,g5),e(g5,z7e),e(z7e,lIr),e(g5,iIr),e(g5,rte),e(rte,dIr),e(g5,mIr),e(vt,cIr),e(vt,h5),e(h5,Q7e),e(Q7e,fIr),e(h5,gIr),e(h5,tte),e(tte,hIr),e(h5,uIr),e(vt,pIr),e(vt,u5),e(u5,W7e),e(W7e,_Ir),e(u5,bIr),e(u5,ate),e(ate,vIr),e(u5,FIr),e(Mo,TIr),e(Mo,p5),e(p5,MIr),e(p5,U7e),e(U7e,EIr),e(p5,CIr),e(p5,H7e),e(H7e,wIr),e(Mo,AIr),M(_5,Mo,null),b(c,Lio,_),b(c,zm,_),e(zm,b5),e(b5,J7e),M(BR,J7e,null),e(zm,LIr),e(zm,Y7e),e(Y7e,yIr),b(c,yio,_),b(c,nr,_),M(IR,nr,null),e(nr,xIr),e(nr,Qm),e(Qm,$Ir),e(Qm,nte),e(nte,kIr),e(Qm,SIr),e(Qm,ste),e(ste,RIr),e(Qm,PIr),e(nr,BIr),e(nr,NR),e(NR,IIr),e(NR,Z7e),e(Z7e,NIr),e(NR,qIr),e(nr,jIr),e(nr,Qt),M(qR,Qt,null),e(Qt,DIr),e(Qt,K7e),e(K7e,GIr),e(Qt,OIr),e(Qt,Wm),e(Wm,VIr),e(Wm,e8e),e(e8e,XIr),e(Wm,zIr),e(Wm,lte),e(lte,QIr),e(Wm,WIr),e(Qt,UIr),M(v5,Qt,null),e(nr,HIr),e(nr,Eo),M(jR,Eo,null),e(Eo,JIr),e(Eo,o8e),e(o8e,YIr),e(Eo,ZIr),e(Eo,kn),e(kn,KIr),e(kn,r8e),e(r8e,eNr),e(kn,oNr),e(kn,t8e),e(t8e,rNr),e(kn,tNr),e(kn,a8e),e(a8e,aNr),e(kn,nNr),e(Eo,sNr),e(Eo,xe),e(xe,F5),e(F5,n8e),e(n8e,lNr),e(F5,iNr),e(F5,ite),e(ite,dNr),e(F5,mNr),e(xe,cNr),e(xe,T5),e(T5,s8e),e(s8e,fNr),e(T5,gNr),e(T5,dte),e(dte,hNr),e(T5,uNr),e(xe,pNr),e(xe,M5),e(M5,l8e),e(l8e,_Nr),e(M5,bNr),e(M5,mte),e(mte,vNr),e(M5,FNr),e(xe,TNr),e(xe,E5),e(E5,i8e),e(i8e,MNr),e(E5,ENr),e(E5,cte),e(cte,CNr),e(E5,wNr),e(xe,ANr),e(xe,C5),e(C5,d8e),e(d8e,LNr),e(C5,yNr),e(C5,fte),e(fte,xNr),e(C5,$Nr),e(xe,kNr),e(xe,w5),e(w5,m8e),e(m8e,SNr),e(w5,RNr),e(w5,gte),e(gte,PNr),e(w5,BNr),e(xe,INr),e(xe,A5),e(A5,c8e),e(c8e,NNr),e(A5,qNr),e(A5,hte),e(hte,jNr),e(A5,DNr),e(xe,GNr),e(xe,L5),e(L5,f8e),e(f8e,ONr),e(L5,VNr),e(L5,ute),e(ute,XNr),e(L5,zNr),e(xe,QNr),e(xe,y5),e(y5,g8e),e(g8e,WNr),e(y5,UNr),e(y5,pte),e(pte,HNr),e(y5,JNr),e(xe,YNr),e(xe,x5),e(x5,h8e),e(h8e,ZNr),e(x5,KNr),e(x5,_te),e(_te,eqr),e(x5,oqr),e(Eo,rqr),e(Eo,$5),e($5,tqr),e($5,u8e),e(u8e,aqr),e($5,nqr),e($5,p8e),e(p8e,sqr),e(Eo,lqr),M(k5,Eo,null),b(c,xio,_),b(c,Um,_),e(Um,S5),e(S5,_8e),M(DR,_8e,null),e(Um,iqr),e(Um,b8e),e(b8e,dqr),b(c,$io,_),b(c,sr,_),M(GR,sr,null),e(sr,mqr),e(sr,Hm),e(Hm,cqr),e(Hm,bte),e(bte,fqr),e(Hm,gqr),e(Hm,vte),e(vte,hqr),e(Hm,uqr),e(sr,pqr),e(sr,OR),e(OR,_qr),e(OR,v8e),e(v8e,bqr),e(OR,vqr),e(sr,Fqr),e(sr,Wt),M(VR,Wt,null),e(Wt,Tqr),e(Wt,F8e),e(F8e,Mqr),e(Wt,Eqr),e(Wt,Jm),e(Jm,Cqr),e(Jm,T8e),e(T8e,wqr),e(Jm,Aqr),e(Jm,Fte),e(Fte,Lqr),e(Jm,yqr),e(Wt,xqr),M(R5,Wt,null),e(sr,$qr),e(sr,Co),M(XR,Co,null),e(Co,kqr),e(Co,M8e),e(M8e,Sqr),e(Co,Rqr),e(Co,Sn),e(Sn,Pqr),e(Sn,E8e),e(E8e,Bqr),e(Sn,Iqr),e(Sn,C8e),e(C8e,Nqr),e(Sn,qqr),e(Sn,w8e),e(w8e,jqr),e(Sn,Dqr),e(Co,Gqr),e(Co,Ym),e(Ym,P5),e(P5,A8e),e(A8e,Oqr),e(P5,Vqr),e(P5,Tte),e(Tte,Xqr),e(P5,zqr),e(Ym,Qqr),e(Ym,B5),e(B5,L8e),e(L8e,Wqr),e(B5,Uqr),e(B5,Mte),e(Mte,Hqr),e(B5,Jqr),e(Ym,Yqr),e(Ym,I5),e(I5,y8e),e(y8e,Zqr),e(I5,Kqr),e(I5,Ete),e(Ete,ejr),e(I5,ojr),e(Co,rjr),e(Co,N5),e(N5,tjr),e(N5,x8e),e(x8e,ajr),e(N5,njr),e(N5,$8e),e($8e,sjr),e(Co,ljr),M(q5,Co,null),b(c,kio,_),b(c,Zm,_),e(Zm,j5),e(j5,k8e),M(zR,k8e,null),e(Zm,ijr),e(Zm,S8e),e(S8e,djr),b(c,Sio,_),b(c,lr,_),M(QR,lr,null),e(lr,mjr),e(lr,Km),e(Km,cjr),e(Km,Cte),e(Cte,fjr),e(Km,gjr),e(Km,wte),e(wte,hjr),e(Km,ujr),e(lr,pjr),e(lr,WR),e(WR,_jr),e(WR,R8e),e(R8e,bjr),e(WR,vjr),e(lr,Fjr),e(lr,Ut),M(UR,Ut,null),e(Ut,Tjr),e(Ut,P8e),e(P8e,Mjr),e(Ut,Ejr),e(Ut,ec),e(ec,Cjr),e(ec,B8e),e(B8e,wjr),e(ec,Ajr),e(ec,Ate),e(Ate,Ljr),e(ec,yjr),e(Ut,xjr),M(D5,Ut,null),e(lr,$jr),e(lr,wo),M(HR,wo,null),e(wo,kjr),e(wo,I8e),e(I8e,Sjr),e(wo,Rjr),e(wo,Rn),e(Rn,Pjr),e(Rn,N8e),e(N8e,Bjr),e(Rn,Ijr),e(Rn,q8e),e(q8e,Njr),e(Rn,qjr),e(Rn,j8e),e(j8e,jjr),e(Rn,Djr),e(wo,Gjr),e(wo,Ft),e(Ft,G5),e(G5,D8e),e(D8e,Ojr),e(G5,Vjr),e(G5,Lte),e(Lte,Xjr),e(G5,zjr),e(Ft,Qjr),e(Ft,O5),e(O5,G8e),e(G8e,Wjr),e(O5,Ujr),e(O5,yte),e(yte,Hjr),e(O5,Jjr),e(Ft,Yjr),e(Ft,V5),e(V5,O8e),e(O8e,Zjr),e(V5,Kjr),e(V5,xte),e(xte,eDr),e(V5,oDr),e(Ft,rDr),e(Ft,X5),e(X5,V8e),e(V8e,tDr),e(X5,aDr),e(X5,$te),e($te,nDr),e(X5,sDr),e(Ft,lDr),e(Ft,z5),e(z5,X8e),e(X8e,iDr),e(z5,dDr),e(z5,kte),e(kte,mDr),e(z5,cDr),e(wo,fDr),e(wo,Q5),e(Q5,gDr),e(Q5,z8e),e(z8e,hDr),e(Q5,uDr),e(Q5,Q8e),e(Q8e,pDr),e(wo,_Dr),M(W5,wo,null),b(c,Rio,_),b(c,oc,_),e(oc,U5),e(U5,W8e),M(JR,W8e,null),e(oc,bDr),e(oc,U8e),e(U8e,vDr),b(c,Pio,_),b(c,ir,_),M(YR,ir,null),e(ir,FDr),e(ir,rc),e(rc,TDr),e(rc,Ste),e(Ste,MDr),e(rc,EDr),e(rc,Rte),e(Rte,CDr),e(rc,wDr),e(ir,ADr),e(ir,ZR),e(ZR,LDr),e(ZR,H8e),e(H8e,yDr),e(ZR,xDr),e(ir,$Dr),e(ir,Ht),M(KR,Ht,null),e(Ht,kDr),e(Ht,J8e),e(J8e,SDr),e(Ht,RDr),e(Ht,tc),e(tc,PDr),e(tc,Y8e),e(Y8e,BDr),e(tc,IDr),e(tc,Pte),e(Pte,NDr),e(tc,qDr),e(Ht,jDr),M(H5,Ht,null),e(ir,DDr),e(ir,Ao),M(eP,Ao,null),e(Ao,GDr),e(Ao,Z8e),e(Z8e,ODr),e(Ao,VDr),e(Ao,Pn),e(Pn,XDr),e(Pn,K8e),e(K8e,zDr),e(Pn,QDr),e(Pn,eLe),e(eLe,WDr),e(Pn,UDr),e(Pn,oLe),e(oLe,HDr),e(Pn,JDr),e(Ao,YDr),e(Ao,Bn),e(Bn,J5),e(J5,rLe),e(rLe,ZDr),e(J5,KDr),e(J5,Bte),e(Bte,eGr),e(J5,oGr),e(Bn,rGr),e(Bn,Y5),e(Y5,tLe),e(tLe,tGr),e(Y5,aGr),e(Y5,Ite),e(Ite,nGr),e(Y5,sGr),e(Bn,lGr),e(Bn,Z5),e(Z5,aLe),e(aLe,iGr),e(Z5,dGr),e(Z5,Nte),e(Nte,mGr),e(Z5,cGr),e(Bn,fGr),e(Bn,K5),e(K5,nLe),e(nLe,gGr),e(K5,hGr),e(K5,qte),e(qte,uGr),e(K5,pGr),e(Ao,_Gr),e(Ao,e0),e(e0,bGr),e(e0,sLe),e(sLe,vGr),e(e0,FGr),e(e0,lLe),e(lLe,TGr),e(Ao,MGr),M(o0,Ao,null),b(c,Bio,_),b(c,ac,_),e(ac,r0),e(r0,iLe),M(oP,iLe,null),e(ac,EGr),e(ac,dLe),e(dLe,CGr),b(c,Iio,_),b(c,dr,_),M(rP,dr,null),e(dr,wGr),e(dr,nc),e(nc,AGr),e(nc,jte),e(jte,LGr),e(nc,yGr),e(nc,Dte),e(Dte,xGr),e(nc,$Gr),e(dr,kGr),e(dr,tP),e(tP,SGr),e(tP,mLe),e(mLe,RGr),e(tP,PGr),e(dr,BGr),e(dr,Jt),M(aP,Jt,null),e(Jt,IGr),e(Jt,cLe),e(cLe,NGr),e(Jt,qGr),e(Jt,sc),e(sc,jGr),e(sc,fLe),e(fLe,DGr),e(sc,GGr),e(sc,Gte),e(Gte,OGr),e(sc,VGr),e(Jt,XGr),M(t0,Jt,null),e(dr,zGr),e(dr,Lo),M(nP,Lo,null),e(Lo,QGr),e(Lo,gLe),e(gLe,WGr),e(Lo,UGr),e(Lo,In),e(In,HGr),e(In,hLe),e(hLe,JGr),e(In,YGr),e(In,uLe),e(uLe,ZGr),e(In,KGr),e(In,pLe),e(pLe,eOr),e(In,oOr),e(Lo,rOr),e(Lo,Tt),e(Tt,a0),e(a0,_Le),e(_Le,tOr),e(a0,aOr),e(a0,Ote),e(Ote,nOr),e(a0,sOr),e(Tt,lOr),e(Tt,n0),e(n0,bLe),e(bLe,iOr),e(n0,dOr),e(n0,Vte),e(Vte,mOr),e(n0,cOr),e(Tt,fOr),e(Tt,s0),e(s0,vLe),e(vLe,gOr),e(s0,hOr),e(s0,Xte),e(Xte,uOr),e(s0,pOr),e(Tt,_Or),e(Tt,l0),e(l0,FLe),e(FLe,bOr),e(l0,vOr),e(l0,zte),e(zte,FOr),e(l0,TOr),e(Tt,MOr),e(Tt,i0),e(i0,TLe),e(TLe,EOr),e(i0,COr),e(i0,Qte),e(Qte,wOr),e(i0,AOr),e(Lo,LOr),e(Lo,d0),e(d0,yOr),e(d0,MLe),e(MLe,xOr),e(d0,$Or),e(d0,ELe),e(ELe,kOr),e(Lo,SOr),M(m0,Lo,null),b(c,Nio,_),b(c,lc,_),e(lc,c0),e(c0,CLe),M(sP,CLe,null),e(lc,ROr),e(lc,wLe),e(wLe,POr),b(c,qio,_),b(c,mr,_),M(lP,mr,null),e(mr,BOr),e(mr,ic),e(ic,IOr),e(ic,Wte),e(Wte,NOr),e(ic,qOr),e(ic,Ute),e(Ute,jOr),e(ic,DOr),e(mr,GOr),e(mr,iP),e(iP,OOr),e(iP,ALe),e(ALe,VOr),e(iP,XOr),e(mr,zOr),e(mr,Yt),M(dP,Yt,null),e(Yt,QOr),e(Yt,LLe),e(LLe,WOr),e(Yt,UOr),e(Yt,dc),e(dc,HOr),e(dc,yLe),e(yLe,JOr),e(dc,YOr),e(dc,Hte),e(Hte,ZOr),e(dc,KOr),e(Yt,eVr),M(f0,Yt,null),e(mr,oVr),e(mr,yo),M(mP,yo,null),e(yo,rVr),e(yo,xLe),e(xLe,tVr),e(yo,aVr),e(yo,Nn),e(Nn,nVr),e(Nn,$Le),e($Le,sVr),e(Nn,lVr),e(Nn,kLe),e(kLe,iVr),e(Nn,dVr),e(Nn,SLe),e(SLe,mVr),e(Nn,cVr),e(yo,fVr),e(yo,RLe),e(RLe,g0),e(g0,PLe),e(PLe,gVr),e(g0,hVr),e(g0,Jte),e(Jte,uVr),e(g0,pVr),e(yo,_Vr),e(yo,h0),e(h0,bVr),e(h0,BLe),e(BLe,vVr),e(h0,FVr),e(h0,ILe),e(ILe,TVr),e(yo,MVr),M(u0,yo,null),b(c,jio,_),b(c,mc,_),e(mc,p0),e(p0,NLe),M(cP,NLe,null),e(mc,EVr),e(mc,qLe),e(qLe,CVr),b(c,Dio,_),b(c,cr,_),M(fP,cr,null),e(cr,wVr),e(cr,cc),e(cc,AVr),e(cc,Yte),e(Yte,LVr),e(cc,yVr),e(cc,Zte),e(Zte,xVr),e(cc,$Vr),e(cr,kVr),e(cr,gP),e(gP,SVr),e(gP,jLe),e(jLe,RVr),e(gP,PVr),e(cr,BVr),e(cr,Zt),M(hP,Zt,null),e(Zt,IVr),e(Zt,DLe),e(DLe,NVr),e(Zt,qVr),e(Zt,fc),e(fc,jVr),e(fc,GLe),e(GLe,DVr),e(fc,GVr),e(fc,Kte),e(Kte,OVr),e(fc,VVr),e(Zt,XVr),M(_0,Zt,null),e(cr,zVr),e(cr,xo),M(uP,xo,null),e(xo,QVr),e(xo,OLe),e(OLe,WVr),e(xo,UVr),e(xo,qn),e(qn,HVr),e(qn,VLe),e(VLe,JVr),e(qn,YVr),e(qn,XLe),e(XLe,ZVr),e(qn,KVr),e(qn,zLe),e(zLe,eXr),e(qn,oXr),e(xo,rXr),e(xo,Mt),e(Mt,b0),e(b0,QLe),e(QLe,tXr),e(b0,aXr),e(b0,eae),e(eae,nXr),e(b0,sXr),e(Mt,lXr),e(Mt,v0),e(v0,WLe),e(WLe,iXr),e(v0,dXr),e(v0,oae),e(oae,mXr),e(v0,cXr),e(Mt,fXr),e(Mt,F0),e(F0,ULe),e(ULe,gXr),e(F0,hXr),e(F0,rae),e(rae,uXr),e(F0,pXr),e(Mt,_Xr),e(Mt,T0),e(T0,HLe),e(HLe,bXr),e(T0,vXr),e(T0,tae),e(tae,FXr),e(T0,TXr),e(Mt,MXr),e(Mt,M0),e(M0,JLe),e(JLe,EXr),e(M0,CXr),e(M0,aae),e(aae,wXr),e(M0,AXr),e(xo,LXr),e(xo,E0),e(E0,yXr),e(E0,YLe),e(YLe,xXr),e(E0,$Xr),e(E0,ZLe),e(ZLe,kXr),e(xo,SXr),M(C0,xo,null),b(c,Gio,_),b(c,gc,_),e(gc,w0),e(w0,KLe),M(pP,KLe,null),e(gc,RXr),e(gc,eye),e(eye,PXr),b(c,Oio,_),b(c,fr,_),M(_P,fr,null),e(fr,BXr),e(fr,hc),e(hc,IXr),e(hc,nae),e(nae,NXr),e(hc,qXr),e(hc,sae),e(sae,jXr),e(hc,DXr),e(fr,GXr),e(fr,bP),e(bP,OXr),e(bP,oye),e(oye,VXr),e(bP,XXr),e(fr,zXr),e(fr,Kt),M(vP,Kt,null),e(Kt,QXr),e(Kt,rye),e(rye,WXr),e(Kt,UXr),e(Kt,uc),e(uc,HXr),e(uc,tye),e(tye,JXr),e(uc,YXr),e(uc,lae),e(lae,ZXr),e(uc,KXr),e(Kt,ezr),M(A0,Kt,null),e(fr,ozr),e(fr,$o),M(FP,$o,null),e($o,rzr),e($o,aye),e(aye,tzr),e($o,azr),e($o,jn),e(jn,nzr),e(jn,nye),e(nye,szr),e(jn,lzr),e(jn,sye),e(sye,izr),e(jn,dzr),e(jn,lye),e(lye,mzr),e(jn,czr),e($o,fzr),e($o,iye),e(iye,L0),e(L0,dye),e(dye,gzr),e(L0,hzr),e(L0,iae),e(iae,uzr),e(L0,pzr),e($o,_zr),e($o,y0),e(y0,bzr),e(y0,mye),e(mye,vzr),e(y0,Fzr),e(y0,cye),e(cye,Tzr),e($o,Mzr),M(x0,$o,null),b(c,Vio,_),b(c,pc,_),e(pc,$0),e($0,fye),M(TP,fye,null),e(pc,Ezr),e(pc,gye),e(gye,Czr),b(c,Xio,_),b(c,gr,_),M(MP,gr,null),e(gr,wzr),e(gr,_c),e(_c,Azr),e(_c,dae),e(dae,Lzr),e(_c,yzr),e(_c,mae),e(mae,xzr),e(_c,$zr),e(gr,kzr),e(gr,EP),e(EP,Szr),e(EP,hye),e(hye,Rzr),e(EP,Pzr),e(gr,Bzr),e(gr,ea),M(CP,ea,null),e(ea,Izr),e(ea,uye),e(uye,Nzr),e(ea,qzr),e(ea,bc),e(bc,jzr),e(bc,pye),e(pye,Dzr),e(bc,Gzr),e(bc,cae),e(cae,Ozr),e(bc,Vzr),e(ea,Xzr),M(k0,ea,null),e(gr,zzr),e(gr,ko),M(wP,ko,null),e(ko,Qzr),e(ko,_ye),e(_ye,Wzr),e(ko,Uzr),e(ko,Dn),e(Dn,Hzr),e(Dn,bye),e(bye,Jzr),e(Dn,Yzr),e(Dn,vye),e(vye,Zzr),e(Dn,Kzr),e(Dn,Fye),e(Fye,eQr),e(Dn,oQr),e(ko,rQr),e(ko,Tye),e(Tye,S0),e(S0,Mye),e(Mye,tQr),e(S0,aQr),e(S0,fae),e(fae,nQr),e(S0,sQr),e(ko,lQr),e(ko,R0),e(R0,iQr),e(R0,Eye),e(Eye,dQr),e(R0,mQr),e(R0,Cye),e(Cye,cQr),e(ko,fQr),M(P0,ko,null),b(c,zio,_),b(c,vc,_),e(vc,B0),e(B0,wye),M(AP,wye,null),e(vc,gQr),e(vc,Aye),e(Aye,hQr),b(c,Qio,_),b(c,hr,_),M(LP,hr,null),e(hr,uQr),e(hr,Fc),e(Fc,pQr),e(Fc,gae),e(gae,_Qr),e(Fc,bQr),e(Fc,hae),e(hae,vQr),e(Fc,FQr),e(hr,TQr),e(hr,yP),e(yP,MQr),e(yP,Lye),e(Lye,EQr),e(yP,CQr),e(hr,wQr),e(hr,oa),M(xP,oa,null),e(oa,AQr),e(oa,yye),e(yye,LQr),e(oa,yQr),e(oa,Tc),e(Tc,xQr),e(Tc,xye),e(xye,$Qr),e(Tc,kQr),e(Tc,uae),e(uae,SQr),e(Tc,RQr),e(oa,PQr),M(I0,oa,null),e(hr,BQr),e(hr,Xr),M($P,Xr,null),e(Xr,IQr),e(Xr,$ye),e($ye,NQr),e(Xr,qQr),e(Xr,Gn),e(Gn,jQr),e(Gn,kye),e(kye,DQr),e(Gn,GQr),e(Gn,Sye),e(Sye,OQr),e(Gn,VQr),e(Gn,Rye),e(Rye,XQr),e(Gn,zQr),e(Xr,QQr),e(Xr,P),e(P,N0),e(N0,Pye),e(Pye,WQr),e(N0,UQr),e(N0,pae),e(pae,HQr),e(N0,JQr),e(P,YQr),e(P,q0),e(q0,Bye),e(Bye,ZQr),e(q0,KQr),e(q0,_ae),e(_ae,eWr),e(q0,oWr),e(P,rWr),e(P,j0),e(j0,Iye),e(Iye,tWr),e(j0,aWr),e(j0,bae),e(bae,nWr),e(j0,sWr),e(P,lWr),e(P,D0),e(D0,Nye),e(Nye,iWr),e(D0,dWr),e(D0,vae),e(vae,mWr),e(D0,cWr),e(P,fWr),e(P,G0),e(G0,qye),e(qye,gWr),e(G0,hWr),e(G0,Fae),e(Fae,uWr),e(G0,pWr),e(P,_Wr),e(P,O0),e(O0,jye),e(jye,bWr),e(O0,vWr),e(O0,Tae),e(Tae,FWr),e(O0,TWr),e(P,MWr),e(P,V0),e(V0,Dye),e(Dye,EWr),e(V0,CWr),e(V0,Mae),e(Mae,wWr),e(V0,AWr),e(P,LWr),e(P,X0),e(X0,Gye),e(Gye,yWr),e(X0,xWr),e(X0,Eae),e(Eae,$Wr),e(X0,kWr),e(P,SWr),e(P,z0),e(z0,Oye),e(Oye,RWr),e(z0,PWr),e(z0,Cae),e(Cae,BWr),e(z0,IWr),e(P,NWr),e(P,Q0),e(Q0,Vye),e(Vye,qWr),e(Q0,jWr),e(Q0,wae),e(wae,DWr),e(Q0,GWr),e(P,OWr),e(P,W0),e(W0,Xye),e(Xye,VWr),e(W0,XWr),e(W0,Aae),e(Aae,zWr),e(W0,QWr),e(P,WWr),e(P,U0),e(U0,zye),e(zye,UWr),e(U0,HWr),e(U0,Lae),e(Lae,JWr),e(U0,YWr),e(P,ZWr),e(P,H0),e(H0,Qye),e(Qye,KWr),e(H0,eUr),e(H0,yae),e(yae,oUr),e(H0,rUr),e(P,tUr),e(P,J0),e(J0,Wye),e(Wye,aUr),e(J0,nUr),e(J0,xae),e(xae,sUr),e(J0,lUr),e(P,iUr),e(P,Y0),e(Y0,Uye),e(Uye,dUr),e(Y0,mUr),e(Y0,$ae),e($ae,cUr),e(Y0,fUr),e(P,gUr),e(P,Z0),e(Z0,Hye),e(Hye,hUr),e(Z0,uUr),e(Z0,kae),e(kae,pUr),e(Z0,_Ur),e(P,bUr),e(P,K0),e(K0,Jye),e(Jye,vUr),e(K0,FUr),e(K0,Sae),e(Sae,TUr),e(K0,MUr),e(P,EUr),e(P,ew),e(ew,Yye),e(Yye,CUr),e(ew,wUr),e(ew,Rae),e(Rae,AUr),e(ew,LUr),e(P,yUr),e(P,ow),e(ow,Zye),e(Zye,xUr),e(ow,$Ur),e(ow,Pae),e(Pae,kUr),e(ow,SUr),e(P,RUr),e(P,rw),e(rw,Kye),e(Kye,PUr),e(rw,BUr),e(rw,Bae),e(Bae,IUr),e(rw,NUr),e(P,qUr),e(P,jl),e(jl,e9e),e(e9e,jUr),e(jl,DUr),e(jl,Iae),e(Iae,GUr),e(jl,OUr),e(jl,Nae),e(Nae,VUr),e(jl,XUr),e(P,zUr),e(P,tw),e(tw,o9e),e(o9e,QUr),e(tw,WUr),e(tw,qae),e(qae,UUr),e(tw,HUr),e(P,JUr),e(P,aw),e(aw,r9e),e(r9e,YUr),e(aw,ZUr),e(aw,jae),e(jae,KUr),e(aw,eHr),e(P,oHr),e(P,nw),e(nw,t9e),e(t9e,rHr),e(nw,tHr),e(nw,Dae),e(Dae,aHr),e(nw,nHr),e(P,sHr),e(P,sw),e(sw,a9e),e(a9e,lHr),e(sw,iHr),e(sw,Gae),e(Gae,dHr),e(sw,mHr),e(P,cHr),e(P,lw),e(lw,n9e),e(n9e,fHr),e(lw,gHr),e(lw,Oae),e(Oae,hHr),e(lw,uHr),e(P,pHr),e(P,iw),e(iw,s9e),e(s9e,_Hr),e(iw,bHr),e(iw,Vae),e(Vae,vHr),e(iw,FHr),e(P,THr),e(P,dw),e(dw,l9e),e(l9e,MHr),e(dw,EHr),e(dw,Xae),e(Xae,CHr),e(dw,wHr),e(P,AHr),e(P,mw),e(mw,i9e),e(i9e,LHr),e(mw,yHr),e(mw,zae),e(zae,xHr),e(mw,$Hr),e(P,kHr),e(P,cw),e(cw,d9e),e(d9e,SHr),e(cw,RHr),e(cw,Qae),e(Qae,PHr),e(cw,BHr),e(P,IHr),e(P,fw),e(fw,m9e),e(m9e,NHr),e(fw,qHr),e(fw,Wae),e(Wae,jHr),e(fw,DHr),e(P,GHr),e(P,gw),e(gw,c9e),e(c9e,OHr),e(gw,VHr),e(gw,Uae),e(Uae,XHr),e(gw,zHr),e(P,QHr),e(P,hw),e(hw,f9e),e(f9e,WHr),e(hw,UHr),e(hw,Hae),e(Hae,HHr),e(hw,JHr),e(P,YHr),e(P,uw),e(uw,g9e),e(g9e,ZHr),e(uw,KHr),e(uw,Jae),e(Jae,eJr),e(uw,oJr),e(P,rJr),e(P,pw),e(pw,h9e),e(h9e,tJr),e(pw,aJr),e(pw,Yae),e(Yae,nJr),e(pw,sJr),e(P,lJr),e(P,_w),e(_w,u9e),e(u9e,iJr),e(_w,dJr),e(_w,Zae),e(Zae,mJr),e(_w,cJr),e(P,fJr),e(P,bw),e(bw,p9e),e(p9e,gJr),e(bw,hJr),e(bw,Kae),e(Kae,uJr),e(bw,pJr),e(P,_Jr),e(P,vw),e(vw,_9e),e(_9e,bJr),e(vw,vJr),e(vw,ene),e(ene,FJr),e(vw,TJr),e(P,MJr),e(P,Fw),e(Fw,b9e),e(b9e,EJr),e(Fw,CJr),e(Fw,one),e(one,wJr),e(Fw,AJr),e(P,LJr),e(P,Tw),e(Tw,v9e),e(v9e,yJr),e(Tw,xJr),e(Tw,rne),e(rne,$Jr),e(Tw,kJr),e(P,SJr),e(P,Mw),e(Mw,F9e),e(F9e,RJr),e(Mw,PJr),e(Mw,tne),e(tne,BJr),e(Mw,IJr),e(P,NJr),e(P,Ew),e(Ew,T9e),e(T9e,qJr),e(Ew,jJr),e(Ew,ane),e(ane,DJr),e(Ew,GJr),e(P,OJr),e(P,Cw),e(Cw,M9e),e(M9e,VJr),e(Cw,XJr),e(Cw,nne),e(nne,zJr),e(Cw,QJr),e(P,WJr),e(P,ww),e(ww,E9e),e(E9e,UJr),e(ww,HJr),e(ww,sne),e(sne,JJr),e(ww,YJr),e(P,ZJr),e(P,Aw),e(Aw,C9e),e(C9e,KJr),e(Aw,eYr),e(Aw,lne),e(lne,oYr),e(Aw,rYr),e(P,tYr),e(P,Lw),e(Lw,w9e),e(w9e,aYr),e(Lw,nYr),e(Lw,ine),e(ine,sYr),e(Lw,lYr),e(P,iYr),e(P,yw),e(yw,A9e),e(A9e,dYr),e(yw,mYr),e(yw,dne),e(dne,cYr),e(yw,fYr),e(P,gYr),e(P,xw),e(xw,L9e),e(L9e,hYr),e(xw,uYr),e(xw,mne),e(mne,pYr),e(xw,_Yr),e(P,bYr),e(P,$w),e($w,y9e),e(y9e,vYr),e($w,FYr),e($w,cne),e(cne,TYr),e($w,MYr),e(P,EYr),e(P,kw),e(kw,x9e),e(x9e,CYr),e(kw,wYr),e(kw,fne),e(fne,AYr),e(kw,LYr),e(P,yYr),e(P,Sw),e(Sw,$9e),e($9e,xYr),e(Sw,$Yr),e(Sw,gne),e(gne,kYr),e(Sw,SYr),e(P,RYr),e(P,Rw),e(Rw,k9e),e(k9e,PYr),e(Rw,BYr),e(Rw,hne),e(hne,IYr),e(Rw,NYr),e(P,qYr),e(P,Pw),e(Pw,S9e),e(S9e,jYr),e(Pw,DYr),e(Pw,une),e(une,GYr),e(Pw,OYr),e(P,VYr),e(P,Bw),e(Bw,R9e),e(R9e,XYr),e(Bw,zYr),e(Bw,pne),e(pne,QYr),e(Bw,WYr),e(P,UYr),e(P,Iw),e(Iw,P9e),e(P9e,HYr),e(Iw,JYr),e(Iw,_ne),e(_ne,YYr),e(Iw,ZYr),e(P,KYr),e(P,Nw),e(Nw,B9e),e(B9e,eZr),e(Nw,oZr),e(Nw,bne),e(bne,rZr),e(Nw,tZr),e(P,aZr),e(P,qw),e(qw,I9e),e(I9e,nZr),e(qw,sZr),e(qw,vne),e(vne,lZr),e(qw,iZr),e(P,dZr),e(P,jw),e(jw,N9e),e(N9e,mZr),e(jw,cZr),e(jw,Fne),e(Fne,fZr),e(jw,gZr),e(Xr,hZr),M(Dw,Xr,null),b(c,Wio,_),b(c,Mc,_),e(Mc,Gw),e(Gw,q9e),M(kP,q9e,null),e(Mc,uZr),e(Mc,j9e),e(j9e,pZr),b(c,Uio,_),b(c,ur,_),M(SP,ur,null),e(ur,_Zr),e(ur,Ec),e(Ec,bZr),e(Ec,Tne),e(Tne,vZr),e(Ec,FZr),e(Ec,Mne),e(Mne,TZr),e(Ec,MZr),e(ur,EZr),e(ur,RP),e(RP,CZr),e(RP,D9e),e(D9e,wZr),e(RP,AZr),e(ur,LZr),e(ur,ra),M(PP,ra,null),e(ra,yZr),e(ra,G9e),e(G9e,xZr),e(ra,$Zr),e(ra,Cc),e(Cc,kZr),e(Cc,O9e),e(O9e,SZr),e(Cc,RZr),e(Cc,Ene),e(Ene,PZr),e(Cc,BZr),e(ra,IZr),M(Ow,ra,null),e(ur,NZr),e(ur,zr),M(BP,zr,null),e(zr,qZr),e(zr,V9e),e(V9e,jZr),e(zr,DZr),e(zr,On),e(On,GZr),e(On,X9e),e(X9e,OZr),e(On,VZr),e(On,z9e),e(z9e,XZr),e(On,zZr),e(On,Q9e),e(Q9e,QZr),e(On,WZr),e(zr,UZr),e(zr,de),e(de,Vw),e(Vw,W9e),e(W9e,HZr),e(Vw,JZr),e(Vw,Cne),e(Cne,YZr),e(Vw,ZZr),e(de,KZr),e(de,Xw),e(Xw,U9e),e(U9e,eKr),e(Xw,oKr),e(Xw,wne),e(wne,rKr),e(Xw,tKr),e(de,aKr),e(de,zw),e(zw,H9e),e(H9e,nKr),e(zw,sKr),e(zw,Ane),e(Ane,lKr),e(zw,iKr),e(de,dKr),e(de,Qw),e(Qw,J9e),e(J9e,mKr),e(Qw,cKr),e(Qw,Lne),e(Lne,fKr),e(Qw,gKr),e(de,hKr),e(de,Ww),e(Ww,Y9e),e(Y9e,uKr),e(Ww,pKr),e(Ww,yne),e(yne,_Kr),e(Ww,bKr),e(de,vKr),e(de,Uw),e(Uw,Z9e),e(Z9e,FKr),e(Uw,TKr),e(Uw,xne),e(xne,MKr),e(Uw,EKr),e(de,CKr),e(de,Hw),e(Hw,K9e),e(K9e,wKr),e(Hw,AKr),e(Hw,$ne),e($ne,LKr),e(Hw,yKr),e(de,xKr),e(de,Jw),e(Jw,exe),e(exe,$Kr),e(Jw,kKr),e(Jw,kne),e(kne,SKr),e(Jw,RKr),e(de,PKr),e(de,Yw),e(Yw,oxe),e(oxe,BKr),e(Yw,IKr),e(Yw,Sne),e(Sne,NKr),e(Yw,qKr),e(de,jKr),e(de,Zw),e(Zw,rxe),e(rxe,DKr),e(Zw,GKr),e(Zw,Rne),e(Rne,OKr),e(Zw,VKr),e(de,XKr),e(de,Kw),e(Kw,txe),e(txe,zKr),e(Kw,QKr),e(Kw,Pne),e(Pne,WKr),e(Kw,UKr),e(de,HKr),e(de,eA),e(eA,axe),e(axe,JKr),e(eA,YKr),e(eA,Bne),e(Bne,ZKr),e(eA,KKr),e(de,eet),e(de,oA),e(oA,nxe),e(nxe,oet),e(oA,ret),e(oA,Ine),e(Ine,tet),e(oA,aet),e(de,net),e(de,rA),e(rA,sxe),e(sxe,set),e(rA,iet),e(rA,Nne),e(Nne,det),e(rA,met),e(de,cet),e(de,tA),e(tA,lxe),e(lxe,fet),e(tA,get),e(tA,qne),e(qne,het),e(tA,uet),e(de,pet),e(de,aA),e(aA,ixe),e(ixe,_et),e(aA,bet),e(aA,jne),e(jne,vet),e(aA,Fet),e(de,Tet),e(de,nA),e(nA,dxe),e(dxe,Met),e(nA,Eet),e(nA,Dne),e(Dne,Cet),e(nA,wet),e(de,Aet),e(de,sA),e(sA,mxe),e(mxe,Let),e(sA,yet),e(sA,Gne),e(Gne,xet),e(sA,$et),e(de,ket),e(de,lA),e(lA,cxe),e(cxe,Set),e(lA,Ret),e(lA,One),e(One,Pet),e(lA,Bet),e(de,Iet),e(de,iA),e(iA,fxe),e(fxe,Net),e(iA,qet),e(iA,Vne),e(Vne,jet),e(iA,Det),e(de,Get),e(de,dA),e(dA,gxe),e(gxe,Oet),e(dA,Vet),e(dA,Xne),e(Xne,Xet),e(dA,zet),e(de,Qet),e(de,mA),e(mA,hxe),e(hxe,Wet),e(mA,Uet),e(mA,zne),e(zne,Het),e(mA,Jet),e(de,Yet),e(de,cA),e(cA,uxe),e(uxe,Zet),e(cA,Ket),e(cA,Qne),e(Qne,eot),e(cA,oot),e(zr,rot),M(fA,zr,null),b(c,Hio,_),b(c,wc,_),e(wc,gA),e(gA,pxe),M(IP,pxe,null),e(wc,tot),e(wc,_xe),e(_xe,aot),b(c,Jio,_),b(c,pr,_),M(NP,pr,null),e(pr,not),e(pr,Ac),e(Ac,sot),e(Ac,Wne),e(Wne,lot),e(Ac,iot),e(Ac,Une),e(Une,dot),e(Ac,mot),e(pr,cot),e(pr,qP),e(qP,fot),e(qP,bxe),e(bxe,got),e(qP,hot),e(pr,uot),e(pr,ta),M(jP,ta,null),e(ta,pot),e(ta,vxe),e(vxe,_ot),e(ta,bot),e(ta,Lc),e(Lc,vot),e(Lc,Fxe),e(Fxe,Fot),e(Lc,Tot),e(Lc,Hne),e(Hne,Mot),e(Lc,Eot),e(ta,Cot),M(hA,ta,null),e(pr,wot),e(pr,Qr),M(DP,Qr,null),e(Qr,Aot),e(Qr,Txe),e(Txe,Lot),e(Qr,yot),e(Qr,Vn),e(Vn,xot),e(Vn,Mxe),e(Mxe,$ot),e(Vn,kot),e(Vn,Exe),e(Exe,Sot),e(Vn,Rot),e(Vn,Cxe),e(Cxe,Pot),e(Vn,Bot),e(Qr,Iot),e(Qr,Ce),e(Ce,uA),e(uA,wxe),e(wxe,Not),e(uA,qot),e(uA,Jne),e(Jne,jot),e(uA,Dot),e(Ce,Got),e(Ce,pA),e(pA,Axe),e(Axe,Oot),e(pA,Vot),e(pA,Yne),e(Yne,Xot),e(pA,zot),e(Ce,Qot),e(Ce,_A),e(_A,Lxe),e(Lxe,Wot),e(_A,Uot),e(_A,Zne),e(Zne,Hot),e(_A,Jot),e(Ce,Yot),e(Ce,bA),e(bA,yxe),e(yxe,Zot),e(bA,Kot),e(bA,Kne),e(Kne,ert),e(bA,ort),e(Ce,rrt),e(Ce,vA),e(vA,xxe),e(xxe,trt),e(vA,art),e(vA,ese),e(ese,nrt),e(vA,srt),e(Ce,lrt),e(Ce,FA),e(FA,$xe),e($xe,irt),e(FA,drt),e(FA,ose),e(ose,mrt),e(FA,crt),e(Ce,frt),e(Ce,TA),e(TA,kxe),e(kxe,grt),e(TA,hrt),e(TA,rse),e(rse,urt),e(TA,prt),e(Ce,_rt),e(Ce,MA),e(MA,Sxe),e(Sxe,brt),e(MA,vrt),e(MA,tse),e(tse,Frt),e(MA,Trt),e(Ce,Mrt),e(Ce,EA),e(EA,Rxe),e(Rxe,Ert),e(EA,Crt),e(EA,ase),e(ase,wrt),e(EA,Art),e(Ce,Lrt),e(Ce,CA),e(CA,Pxe),e(Pxe,yrt),e(CA,xrt),e(CA,nse),e(nse,$rt),e(CA,krt),e(Ce,Srt),e(Ce,wA),e(wA,Bxe),e(Bxe,Rrt),e(wA,Prt),e(wA,sse),e(sse,Brt),e(wA,Irt),e(Ce,Nrt),e(Ce,AA),e(AA,Ixe),e(Ixe,qrt),e(AA,jrt),e(AA,lse),e(lse,Drt),e(AA,Grt),e(Ce,Ort),e(Ce,LA),e(LA,Nxe),e(Nxe,Vrt),e(LA,Xrt),e(LA,ise),e(ise,zrt),e(LA,Qrt),e(Ce,Wrt),e(Ce,yA),e(yA,qxe),e(qxe,Urt),e(yA,Hrt),e(yA,dse),e(dse,Jrt),e(yA,Yrt),e(Qr,Zrt),M(xA,Qr,null),b(c,Yio,_),b(c,yc,_),e(yc,$A),e($A,jxe),M(GP,jxe,null),e(yc,Krt),e(yc,Dxe),e(Dxe,ett),b(c,Zio,_),b(c,_r,_),M(OP,_r,null),e(_r,ott),e(_r,xc),e(xc,rtt),e(xc,mse),e(mse,ttt),e(xc,att),e(xc,cse),e(cse,ntt),e(xc,stt),e(_r,ltt),e(_r,VP),e(VP,itt),e(VP,Gxe),e(Gxe,dtt),e(VP,mtt),e(_r,ctt),e(_r,aa),M(XP,aa,null),e(aa,ftt),e(aa,Oxe),e(Oxe,gtt),e(aa,htt),e(aa,$c),e($c,utt),e($c,Vxe),e(Vxe,ptt),e($c,_tt),e($c,fse),e(fse,btt),e($c,vtt),e(aa,Ftt),M(kA,aa,null),e(_r,Ttt),e(_r,Wr),M(zP,Wr,null),e(Wr,Mtt),e(Wr,Xxe),e(Xxe,Ett),e(Wr,Ctt),e(Wr,Xn),e(Xn,wtt),e(Xn,zxe),e(zxe,Att),e(Xn,Ltt),e(Xn,Qxe),e(Qxe,ytt),e(Xn,xtt),e(Xn,Wxe),e(Wxe,$tt),e(Xn,ktt),e(Wr,Stt),e(Wr,$e),e($e,SA),e(SA,Uxe),e(Uxe,Rtt),e(SA,Ptt),e(SA,gse),e(gse,Btt),e(SA,Itt),e($e,Ntt),e($e,RA),e(RA,Hxe),e(Hxe,qtt),e(RA,jtt),e(RA,hse),e(hse,Dtt),e(RA,Gtt),e($e,Ott),e($e,PA),e(PA,Jxe),e(Jxe,Vtt),e(PA,Xtt),e(PA,use),e(use,ztt),e(PA,Qtt),e($e,Wtt),e($e,Dl),e(Dl,Yxe),e(Yxe,Utt),e(Dl,Htt),e(Dl,pse),e(pse,Jtt),e(Dl,Ytt),e(Dl,_se),e(_se,Ztt),e(Dl,Ktt),e($e,eat),e($e,BA),e(BA,Zxe),e(Zxe,oat),e(BA,rat),e(BA,bse),e(bse,tat),e(BA,aat),e($e,nat),e($e,IA),e(IA,Kxe),e(Kxe,sat),e(IA,lat),e(IA,vse),e(vse,iat),e(IA,dat),e($e,mat),e($e,NA),e(NA,e$e),e(e$e,cat),e(NA,fat),e(NA,Fse),e(Fse,gat),e(NA,hat),e($e,uat),e($e,qA),e(qA,o$e),e(o$e,pat),e(qA,_at),e(qA,Tse),e(Tse,bat),e(qA,vat),e($e,Fat),e($e,jA),e(jA,r$e),e(r$e,Tat),e(jA,Mat),e(jA,Mse),e(Mse,Eat),e(jA,Cat),e($e,wat),e($e,DA),e(DA,t$e),e(t$e,Aat),e(DA,Lat),e(DA,Ese),e(Ese,yat),e(DA,xat),e(Wr,$at),M(GA,Wr,null),b(c,Kio,_),b(c,kc,_),e(kc,OA),e(OA,a$e),M(QP,a$e,null),e(kc,kat),e(kc,n$e),e(n$e,Sat),b(c,edo,_),b(c,br,_),M(WP,br,null),e(br,Rat),e(br,Sc),e(Sc,Pat),e(Sc,Cse),e(Cse,Bat),e(Sc,Iat),e(Sc,wse),e(wse,Nat),e(Sc,qat),e(br,jat),e(br,UP),e(UP,Dat),e(UP,s$e),e(s$e,Gat),e(UP,Oat),e(br,Vat),e(br,na),M(HP,na,null),e(na,Xat),e(na,l$e),e(l$e,zat),e(na,Qat),e(na,Rc),e(Rc,Wat),e(Rc,i$e),e(i$e,Uat),e(Rc,Hat),e(Rc,Ase),e(Ase,Jat),e(Rc,Yat),e(na,Zat),M(VA,na,null),e(br,Kat),e(br,Ur),M(JP,Ur,null),e(Ur,ent),e(Ur,d$e),e(d$e,ont),e(Ur,rnt),e(Ur,zn),e(zn,tnt),e(zn,m$e),e(m$e,ant),e(zn,nnt),e(zn,c$e),e(c$e,snt),e(zn,lnt),e(zn,f$e),e(f$e,int),e(zn,dnt),e(Ur,mnt),e(Ur,Pc),e(Pc,XA),e(XA,g$e),e(g$e,cnt),e(XA,fnt),e(XA,Lse),e(Lse,gnt),e(XA,hnt),e(Pc,unt),e(Pc,zA),e(zA,h$e),e(h$e,pnt),e(zA,_nt),e(zA,yse),e(yse,bnt),e(zA,vnt),e(Pc,Fnt),e(Pc,QA),e(QA,u$e),e(u$e,Tnt),e(QA,Mnt),e(QA,xse),e(xse,Ent),e(QA,Cnt),e(Ur,wnt),M(WA,Ur,null),b(c,odo,_),b(c,Bc,_),e(Bc,UA),e(UA,p$e),M(YP,p$e,null),e(Bc,Ant),e(Bc,_$e),e(_$e,Lnt),b(c,rdo,_),b(c,vr,_),M(ZP,vr,null),e(vr,ynt),e(vr,Ic),e(Ic,xnt),e(Ic,$se),e($se,$nt),e(Ic,knt),e(Ic,kse),e(kse,Snt),e(Ic,Rnt),e(vr,Pnt),e(vr,KP),e(KP,Bnt),e(KP,b$e),e(b$e,Int),e(KP,Nnt),e(vr,qnt),e(vr,sa),M(eB,sa,null),e(sa,jnt),e(sa,v$e),e(v$e,Dnt),e(sa,Gnt),e(sa,Nc),e(Nc,Ont),e(Nc,F$e),e(F$e,Vnt),e(Nc,Xnt),e(Nc,Sse),e(Sse,znt),e(Nc,Qnt),e(sa,Wnt),M(HA,sa,null),e(vr,Unt),e(vr,Hr),M(oB,Hr,null),e(Hr,Hnt),e(Hr,T$e),e(T$e,Jnt),e(Hr,Ynt),e(Hr,Qn),e(Qn,Znt),e(Qn,M$e),e(M$e,Knt),e(Qn,est),e(Qn,E$e),e(E$e,ost),e(Qn,rst),e(Qn,C$e),e(C$e,tst),e(Qn,ast),e(Hr,nst),e(Hr,ge),e(ge,JA),e(JA,w$e),e(w$e,sst),e(JA,lst),e(JA,Rse),e(Rse,ist),e(JA,dst),e(ge,mst),e(ge,YA),e(YA,A$e),e(A$e,cst),e(YA,fst),e(YA,Pse),e(Pse,gst),e(YA,hst),e(ge,ust),e(ge,ZA),e(ZA,L$e),e(L$e,pst),e(ZA,_st),e(ZA,Bse),e(Bse,bst),e(ZA,vst),e(ge,Fst),e(ge,KA),e(KA,y$e),e(y$e,Tst),e(KA,Mst),e(KA,Ise),e(Ise,Est),e(KA,Cst),e(ge,wst),e(ge,e6),e(e6,x$e),e(x$e,Ast),e(e6,Lst),e(e6,Nse),e(Nse,yst),e(e6,xst),e(ge,$st),e(ge,o6),e(o6,$$e),e($$e,kst),e(o6,Sst),e(o6,qse),e(qse,Rst),e(o6,Pst),e(ge,Bst),e(ge,r6),e(r6,k$e),e(k$e,Ist),e(r6,Nst),e(r6,jse),e(jse,qst),e(r6,jst),e(ge,Dst),e(ge,t6),e(t6,S$e),e(S$e,Gst),e(t6,Ost),e(t6,Dse),e(Dse,Vst),e(t6,Xst),e(ge,zst),e(ge,a6),e(a6,R$e),e(R$e,Qst),e(a6,Wst),e(a6,Gse),e(Gse,Ust),e(a6,Hst),e(ge,Jst),e(ge,n6),e(n6,P$e),e(P$e,Yst),e(n6,Zst),e(n6,Ose),e(Ose,Kst),e(n6,elt),e(ge,olt),e(ge,s6),e(s6,B$e),e(B$e,rlt),e(s6,tlt),e(s6,Vse),e(Vse,alt),e(s6,nlt),e(ge,slt),e(ge,l6),e(l6,I$e),e(I$e,llt),e(l6,ilt),e(l6,Xse),e(Xse,dlt),e(l6,mlt),e(ge,clt),e(ge,i6),e(i6,N$e),e(N$e,flt),e(i6,glt),e(i6,zse),e(zse,hlt),e(i6,ult),e(ge,plt),e(ge,d6),e(d6,q$e),e(q$e,_lt),e(d6,blt),e(d6,Qse),e(Qse,vlt),e(d6,Flt),e(ge,Tlt),e(ge,m6),e(m6,j$e),e(j$e,Mlt),e(m6,Elt),e(m6,Wse),e(Wse,Clt),e(m6,wlt),e(ge,Alt),e(ge,c6),e(c6,D$e),e(D$e,Llt),e(c6,ylt),e(c6,Use),e(Use,xlt),e(c6,$lt),e(ge,klt),e(ge,f6),e(f6,G$e),e(G$e,Slt),e(f6,Rlt),e(f6,Hse),e(Hse,Plt),e(f6,Blt),e(ge,Ilt),e(ge,g6),e(g6,O$e),e(O$e,Nlt),e(g6,qlt),e(g6,Jse),e(Jse,jlt),e(g6,Dlt),e(ge,Glt),e(ge,h6),e(h6,V$e),e(V$e,Olt),e(h6,Vlt),e(h6,Yse),e(Yse,Xlt),e(h6,zlt),e(ge,Qlt),e(ge,u6),e(u6,X$e),e(X$e,Wlt),e(u6,Ult),e(u6,Zse),e(Zse,Hlt),e(u6,Jlt),e(ge,Ylt),e(ge,p6),e(p6,z$e),e(z$e,Zlt),e(p6,Klt),e(p6,Kse),e(Kse,eit),e(p6,oit),e(Hr,rit),M(_6,Hr,null),b(c,tdo,_),b(c,qc,_),e(qc,b6),e(b6,Q$e),M(rB,Q$e,null),e(qc,tit),e(qc,W$e),e(W$e,ait),b(c,ado,_),b(c,Fr,_),M(tB,Fr,null),e(Fr,nit),e(Fr,jc),e(jc,sit),e(jc,ele),e(ele,lit),e(jc,iit),e(jc,ole),e(ole,dit),e(jc,mit),e(Fr,cit),e(Fr,aB),e(aB,fit),e(aB,U$e),e(U$e,git),e(aB,hit),e(Fr,uit),e(Fr,la),M(nB,la,null),e(la,pit),e(la,H$e),e(H$e,_it),e(la,bit),e(la,Dc),e(Dc,vit),e(Dc,J$e),e(J$e,Fit),e(Dc,Tit),e(Dc,rle),e(rle,Mit),e(Dc,Eit),e(la,Cit),M(v6,la,null),e(Fr,wit),e(Fr,Jr),M(sB,Jr,null),e(Jr,Ait),e(Jr,Y$e),e(Y$e,Lit),e(Jr,yit),e(Jr,Wn),e(Wn,xit),e(Wn,Z$e),e(Z$e,$it),e(Wn,kit),e(Wn,K$e),e(K$e,Sit),e(Wn,Rit),e(Wn,eke),e(eke,Pit),e(Wn,Bit),e(Jr,Iit),e(Jr,ke),e(ke,F6),e(F6,oke),e(oke,Nit),e(F6,qit),e(F6,tle),e(tle,jit),e(F6,Dit),e(ke,Git),e(ke,T6),e(T6,rke),e(rke,Oit),e(T6,Vit),e(T6,ale),e(ale,Xit),e(T6,zit),e(ke,Qit),e(ke,M6),e(M6,tke),e(tke,Wit),e(M6,Uit),e(M6,nle),e(nle,Hit),e(M6,Jit),e(ke,Yit),e(ke,E6),e(E6,ake),e(ake,Zit),e(E6,Kit),e(E6,sle),e(sle,edt),e(E6,odt),e(ke,rdt),e(ke,C6),e(C6,nke),e(nke,tdt),e(C6,adt),e(C6,lle),e(lle,ndt),e(C6,sdt),e(ke,ldt),e(ke,w6),e(w6,ske),e(ske,idt),e(w6,ddt),e(w6,ile),e(ile,mdt),e(w6,cdt),e(ke,fdt),e(ke,A6),e(A6,lke),e(lke,gdt),e(A6,hdt),e(A6,dle),e(dle,udt),e(A6,pdt),e(ke,_dt),e(ke,L6),e(L6,ike),e(ike,bdt),e(L6,vdt),e(L6,mle),e(mle,Fdt),e(L6,Tdt),e(ke,Mdt),e(ke,y6),e(y6,dke),e(dke,Edt),e(y6,Cdt),e(y6,cle),e(cle,wdt),e(y6,Adt),e(ke,Ldt),e(ke,x6),e(x6,mke),e(mke,ydt),e(x6,xdt),e(x6,fle),e(fle,$dt),e(x6,kdt),e(Jr,Sdt),M($6,Jr,null),b(c,ndo,_),b(c,Gc,_),e(Gc,k6),e(k6,cke),M(lB,cke,null),e(Gc,Rdt),e(Gc,fke),e(fke,Pdt),b(c,sdo,_),b(c,Tr,_),M(iB,Tr,null),e(Tr,Bdt),e(Tr,Oc),e(Oc,Idt),e(Oc,gle),e(gle,Ndt),e(Oc,qdt),e(Oc,hle),e(hle,jdt),e(Oc,Ddt),e(Tr,Gdt),e(Tr,dB),e(dB,Odt),e(dB,gke),e(gke,Vdt),e(dB,Xdt),e(Tr,zdt),e(Tr,ia),M(mB,ia,null),e(ia,Qdt),e(ia,hke),e(hke,Wdt),e(ia,Udt),e(ia,Vc),e(Vc,Hdt),e(Vc,uke),e(uke,Jdt),e(Vc,Ydt),e(Vc,ule),e(ule,Zdt),e(Vc,Kdt),e(ia,emt),M(S6,ia,null),e(Tr,omt),e(Tr,Yr),M(cB,Yr,null),e(Yr,rmt),e(Yr,pke),e(pke,tmt),e(Yr,amt),e(Yr,Un),e(Un,nmt),e(Un,_ke),e(_ke,smt),e(Un,lmt),e(Un,bke),e(bke,imt),e(Un,dmt),e(Un,vke),e(vke,mmt),e(Un,cmt),e(Yr,fmt),e(Yr,te),e(te,R6),e(R6,Fke),e(Fke,gmt),e(R6,hmt),e(R6,ple),e(ple,umt),e(R6,pmt),e(te,_mt),e(te,P6),e(P6,Tke),e(Tke,bmt),e(P6,vmt),e(P6,_le),e(_le,Fmt),e(P6,Tmt),e(te,Mmt),e(te,B6),e(B6,Mke),e(Mke,Emt),e(B6,Cmt),e(B6,ble),e(ble,wmt),e(B6,Amt),e(te,Lmt),e(te,I6),e(I6,Eke),e(Eke,ymt),e(I6,xmt),e(I6,vle),e(vle,$mt),e(I6,kmt),e(te,Smt),e(te,N6),e(N6,Cke),e(Cke,Rmt),e(N6,Pmt),e(N6,Fle),e(Fle,Bmt),e(N6,Imt),e(te,Nmt),e(te,q6),e(q6,wke),e(wke,qmt),e(q6,jmt),e(q6,Tle),e(Tle,Dmt),e(q6,Gmt),e(te,Omt),e(te,j6),e(j6,Ake),e(Ake,Vmt),e(j6,Xmt),e(j6,Mle),e(Mle,zmt),e(j6,Qmt),e(te,Wmt),e(te,D6),e(D6,Lke),e(Lke,Umt),e(D6,Hmt),e(D6,Ele),e(Ele,Jmt),e(D6,Ymt),e(te,Zmt),e(te,G6),e(G6,yke),e(yke,Kmt),e(G6,ect),e(G6,Cle),e(Cle,oct),e(G6,rct),e(te,tct),e(te,O6),e(O6,xke),e(xke,act),e(O6,nct),e(O6,wle),e(wle,sct),e(O6,lct),e(te,ict),e(te,V6),e(V6,$ke),e($ke,dct),e(V6,mct),e(V6,Ale),e(Ale,cct),e(V6,fct),e(te,gct),e(te,X6),e(X6,kke),e(kke,hct),e(X6,uct),e(X6,Lle),e(Lle,pct),e(X6,_ct),e(te,bct),e(te,z6),e(z6,Ske),e(Ske,vct),e(z6,Fct),e(z6,yle),e(yle,Tct),e(z6,Mct),e(te,Ect),e(te,Q6),e(Q6,Rke),e(Rke,Cct),e(Q6,wct),e(Q6,xle),e(xle,Act),e(Q6,Lct),e(te,yct),e(te,W6),e(W6,Pke),e(Pke,xct),e(W6,$ct),e(W6,$le),e($le,kct),e(W6,Sct),e(te,Rct),e(te,U6),e(U6,Bke),e(Bke,Pct),e(U6,Bct),e(U6,kle),e(kle,Ict),e(U6,Nct),e(te,qct),e(te,H6),e(H6,Ike),e(Ike,jct),e(H6,Dct),e(H6,Sle),e(Sle,Gct),e(H6,Oct),e(te,Vct),e(te,J6),e(J6,Nke),e(Nke,Xct),e(J6,zct),e(J6,Rle),e(Rle,Qct),e(J6,Wct),e(te,Uct),e(te,Y6),e(Y6,qke),e(qke,Hct),e(Y6,Jct),e(Y6,Ple),e(Ple,Yct),e(Y6,Zct),e(te,Kct),e(te,Z6),e(Z6,jke),e(jke,eft),e(Z6,oft),e(Z6,Ble),e(Ble,rft),e(Z6,tft),e(te,aft),e(te,K6),e(K6,Dke),e(Dke,nft),e(K6,sft),e(K6,Ile),e(Ile,lft),e(K6,ift),e(te,dft),e(te,e7),e(e7,Gke),e(Gke,mft),e(e7,cft),e(e7,Nle),e(Nle,fft),e(e7,gft),e(te,hft),e(te,o7),e(o7,Oke),e(Oke,uft),e(o7,pft),e(o7,qle),e(qle,_ft),e(o7,bft),e(te,vft),e(te,r7),e(r7,Vke),e(Vke,Fft),e(r7,Tft),e(r7,jle),e(jle,Mft),e(r7,Eft),e(te,Cft),e(te,t7),e(t7,Xke),e(Xke,wft),e(t7,Aft),e(t7,Dle),e(Dle,Lft),e(t7,yft),e(te,xft),e(te,a7),e(a7,zke),e(zke,$ft),e(a7,kft),e(a7,Gle),e(Gle,Sft),e(a7,Rft),e(te,Pft),e(te,n7),e(n7,Qke),e(Qke,Bft),e(n7,Ift),e(n7,Ole),e(Ole,Nft),e(n7,qft),e(te,jft),e(te,s7),e(s7,Wke),e(Wke,Dft),e(s7,Gft),e(s7,Vle),e(Vle,Oft),e(s7,Vft),e(Yr,Xft),M(l7,Yr,null),b(c,ldo,_),b(c,Xc,_),e(Xc,i7),e(i7,Uke),M(fB,Uke,null),e(Xc,zft),e(Xc,Hke),e(Hke,Qft),b(c,ido,_),b(c,Mr,_),M(gB,Mr,null),e(Mr,Wft),e(Mr,zc),e(zc,Uft),e(zc,Xle),e(Xle,Hft),e(zc,Jft),e(zc,zle),e(zle,Yft),e(zc,Zft),e(Mr,Kft),e(Mr,hB),e(hB,egt),e(hB,Jke),e(Jke,ogt),e(hB,rgt),e(Mr,tgt),e(Mr,da),M(uB,da,null),e(da,agt),e(da,Yke),e(Yke,ngt),e(da,sgt),e(da,Qc),e(Qc,lgt),e(Qc,Zke),e(Zke,igt),e(Qc,dgt),e(Qc,Qle),e(Qle,mgt),e(Qc,cgt),e(da,fgt),M(d7,da,null),e(Mr,ggt),e(Mr,Zr),M(pB,Zr,null),e(Zr,hgt),e(Zr,Kke),e(Kke,ugt),e(Zr,pgt),e(Zr,Hn),e(Hn,_gt),e(Hn,eSe),e(eSe,bgt),e(Hn,vgt),e(Hn,oSe),e(oSe,Fgt),e(Hn,Tgt),e(Hn,rSe),e(rSe,Mgt),e(Hn,Egt),e(Zr,Cgt),e(Zr,Te),e(Te,m7),e(m7,tSe),e(tSe,wgt),e(m7,Agt),e(m7,Wle),e(Wle,Lgt),e(m7,ygt),e(Te,xgt),e(Te,c7),e(c7,aSe),e(aSe,$gt),e(c7,kgt),e(c7,Ule),e(Ule,Sgt),e(c7,Rgt),e(Te,Pgt),e(Te,f7),e(f7,nSe),e(nSe,Bgt),e(f7,Igt),e(f7,Hle),e(Hle,Ngt),e(f7,qgt),e(Te,jgt),e(Te,g7),e(g7,sSe),e(sSe,Dgt),e(g7,Ggt),e(g7,Jle),e(Jle,Ogt),e(g7,Vgt),e(Te,Xgt),e(Te,h7),e(h7,lSe),e(lSe,zgt),e(h7,Qgt),e(h7,Yle),e(Yle,Wgt),e(h7,Ugt),e(Te,Hgt),e(Te,u7),e(u7,iSe),e(iSe,Jgt),e(u7,Ygt),e(u7,Zle),e(Zle,Zgt),e(u7,Kgt),e(Te,eht),e(Te,p7),e(p7,dSe),e(dSe,oht),e(p7,rht),e(p7,Kle),e(Kle,tht),e(p7,aht),e(Te,nht),e(Te,_7),e(_7,mSe),e(mSe,sht),e(_7,lht),e(_7,eie),e(eie,iht),e(_7,dht),e(Te,mht),e(Te,b7),e(b7,cSe),e(cSe,cht),e(b7,fht),e(b7,oie),e(oie,ght),e(b7,hht),e(Te,uht),e(Te,v7),e(v7,fSe),e(fSe,pht),e(v7,_ht),e(v7,rie),e(rie,bht),e(v7,vht),e(Te,Fht),e(Te,F7),e(F7,gSe),e(gSe,Tht),e(F7,Mht),e(F7,tie),e(tie,Eht),e(F7,Cht),e(Te,wht),e(Te,T7),e(T7,hSe),e(hSe,Aht),e(T7,Lht),e(T7,aie),e(aie,yht),e(T7,xht),e(Te,$ht),e(Te,M7),e(M7,uSe),e(uSe,kht),e(M7,Sht),e(M7,nie),e(nie,Rht),e(M7,Pht),e(Te,Bht),e(Te,E7),e(E7,pSe),e(pSe,Iht),e(E7,Nht),e(E7,sie),e(sie,qht),e(E7,jht),e(Te,Dht),e(Te,C7),e(C7,_Se),e(_Se,Ght),e(C7,Oht),e(C7,lie),e(lie,Vht),e(C7,Xht),e(Te,zht),e(Te,w7),e(w7,bSe),e(bSe,Qht),e(w7,Wht),e(w7,iie),e(iie,Uht),e(w7,Hht),e(Te,Jht),e(Te,A7),e(A7,vSe),e(vSe,Yht),e(A7,Zht),e(A7,die),e(die,Kht),e(A7,eut),e(Zr,out),M(L7,Zr,null),b(c,ddo,_),b(c,Wc,_),e(Wc,y7),e(y7,FSe),M(_B,FSe,null),e(Wc,rut),e(Wc,TSe),e(TSe,tut),b(c,mdo,_),b(c,Er,_),M(bB,Er,null),e(Er,aut),e(Er,Uc),e(Uc,nut),e(Uc,mie),e(mie,sut),e(Uc,lut),e(Uc,cie),e(cie,iut),e(Uc,dut),e(Er,mut),e(Er,vB),e(vB,cut),e(vB,MSe),e(MSe,fut),e(vB,gut),e(Er,hut),e(Er,ma),M(FB,ma,null),e(ma,uut),e(ma,ESe),e(ESe,put),e(ma,_ut),e(ma,Hc),e(Hc,but),e(Hc,CSe),e(CSe,vut),e(Hc,Fut),e(Hc,fie),e(fie,Tut),e(Hc,Mut),e(ma,Eut),M(x7,ma,null),e(Er,Cut),e(Er,Kr),M(TB,Kr,null),e(Kr,wut),e(Kr,wSe),e(wSe,Aut),e(Kr,Lut),e(Kr,Jn),e(Jn,yut),e(Jn,ASe),e(ASe,xut),e(Jn,$ut),e(Jn,LSe),e(LSe,kut),e(Jn,Sut),e(Jn,ySe),e(ySe,Rut),e(Jn,Put),e(Kr,But),e(Kr,MB),e(MB,$7),e($7,xSe),e(xSe,Iut),e($7,Nut),e($7,gie),e(gie,qut),e($7,jut),e(MB,Dut),e(MB,k7),e(k7,$Se),e($Se,Gut),e(k7,Out),e(k7,hie),e(hie,Vut),e(k7,Xut),e(Kr,zut),M(S7,Kr,null),b(c,cdo,_),b(c,Jc,_),e(Jc,R7),e(R7,kSe),M(EB,kSe,null),e(Jc,Qut),e(Jc,SSe),e(SSe,Wut),b(c,fdo,_),b(c,Cr,_),M(CB,Cr,null),e(Cr,Uut),e(Cr,Yc),e(Yc,Hut),e(Yc,uie),e(uie,Jut),e(Yc,Yut),e(Yc,pie),e(pie,Zut),e(Yc,Kut),e(Cr,ept),e(Cr,wB),e(wB,opt),e(wB,RSe),e(RSe,rpt),e(wB,tpt),e(Cr,apt),e(Cr,ca),M(AB,ca,null),e(ca,npt),e(ca,PSe),e(PSe,spt),e(ca,lpt),e(ca,Zc),e(Zc,ipt),e(Zc,BSe),e(BSe,dpt),e(Zc,mpt),e(Zc,_ie),e(_ie,cpt),e(Zc,fpt),e(ca,gpt),M(P7,ca,null),e(Cr,hpt),e(Cr,et),M(LB,et,null),e(et,upt),e(et,ISe),e(ISe,ppt),e(et,_pt),e(et,Yn),e(Yn,bpt),e(Yn,NSe),e(NSe,vpt),e(Yn,Fpt),e(Yn,qSe),e(qSe,Tpt),e(Yn,Mpt),e(Yn,jSe),e(jSe,Ept),e(Yn,Cpt),e(et,wpt),e(et,DSe),e(DSe,B7),e(B7,GSe),e(GSe,Apt),e(B7,Lpt),e(B7,bie),e(bie,ypt),e(B7,xpt),e(et,$pt),M(I7,et,null),b(c,gdo,_),b(c,Kc,_),e(Kc,N7),e(N7,OSe),M(yB,OSe,null),e(Kc,kpt),e(Kc,VSe),e(VSe,Spt),b(c,hdo,_),b(c,wr,_),M(xB,wr,null),e(wr,Rpt),e(wr,ef),e(ef,Ppt),e(ef,vie),e(vie,Bpt),e(ef,Ipt),e(ef,Fie),e(Fie,Npt),e(ef,qpt),e(wr,jpt),e(wr,$B),e($B,Dpt),e($B,XSe),e(XSe,Gpt),e($B,Opt),e(wr,Vpt),e(wr,fa),M(kB,fa,null),e(fa,Xpt),e(fa,zSe),e(zSe,zpt),e(fa,Qpt),e(fa,of),e(of,Wpt),e(of,QSe),e(QSe,Upt),e(of,Hpt),e(of,Tie),e(Tie,Jpt),e(of,Ypt),e(fa,Zpt),M(q7,fa,null),e(wr,Kpt),e(wr,ot),M(SB,ot,null),e(ot,e_t),e(ot,WSe),e(WSe,o_t),e(ot,r_t),e(ot,Zn),e(Zn,t_t),e(Zn,USe),e(USe,a_t),e(Zn,n_t),e(Zn,HSe),e(HSe,s_t),e(Zn,l_t),e(Zn,JSe),e(JSe,i_t),e(Zn,d_t),e(ot,m_t),e(ot,YSe),e(YSe,j7),e(j7,ZSe),e(ZSe,c_t),e(j7,f_t),e(j7,Mie),e(Mie,g_t),e(j7,h_t),e(ot,u_t),M(D7,ot,null),b(c,udo,_),b(c,rf,_),e(rf,G7),e(G7,KSe),M(RB,KSe,null),e(rf,p_t),e(rf,eRe),e(eRe,__t),b(c,pdo,_),b(c,Ar,_),M(PB,Ar,null),e(Ar,b_t),e(Ar,tf),e(tf,v_t),e(tf,Eie),e(Eie,F_t),e(tf,T_t),e(tf,Cie),e(Cie,M_t),e(tf,E_t),e(Ar,C_t),e(Ar,BB),e(BB,w_t),e(BB,oRe),e(oRe,A_t),e(BB,L_t),e(Ar,y_t),e(Ar,ga),M(IB,ga,null),e(ga,x_t),e(ga,rRe),e(rRe,$_t),e(ga,k_t),e(ga,af),e(af,S_t),e(af,tRe),e(tRe,R_t),e(af,P_t),e(af,wie),e(wie,B_t),e(af,I_t),e(ga,N_t),M(O7,ga,null),e(Ar,q_t),e(Ar,rt),M(NB,rt,null),e(rt,j_t),e(rt,aRe),e(aRe,D_t),e(rt,G_t),e(rt,Kn),e(Kn,O_t),e(Kn,nRe),e(nRe,V_t),e(Kn,X_t),e(Kn,sRe),e(sRe,z_t),e(Kn,Q_t),e(Kn,lRe),e(lRe,W_t),e(Kn,U_t),e(rt,H_t),e(rt,me),e(me,V7),e(V7,iRe),e(iRe,J_t),e(V7,Y_t),e(V7,Aie),e(Aie,Z_t),e(V7,K_t),e(me,e1t),e(me,X7),e(X7,dRe),e(dRe,o1t),e(X7,r1t),e(X7,Lie),e(Lie,t1t),e(X7,a1t),e(me,n1t),e(me,z7),e(z7,mRe),e(mRe,s1t),e(z7,l1t),e(z7,yie),e(yie,i1t),e(z7,d1t),e(me,m1t),e(me,Q7),e(Q7,cRe),e(cRe,c1t),e(Q7,f1t),e(Q7,xie),e(xie,g1t),e(Q7,h1t),e(me,u1t),e(me,W7),e(W7,fRe),e(fRe,p1t),e(W7,_1t),e(W7,$ie),e($ie,b1t),e(W7,v1t),e(me,F1t),e(me,U7),e(U7,gRe),e(gRe,T1t),e(U7,M1t),e(U7,kie),e(kie,E1t),e(U7,C1t),e(me,w1t),e(me,H7),e(H7,hRe),e(hRe,A1t),e(H7,L1t),e(H7,Sie),e(Sie,y1t),e(H7,x1t),e(me,$1t),e(me,J7),e(J7,uRe),e(uRe,k1t),e(J7,S1t),e(J7,Rie),e(Rie,R1t),e(J7,P1t),e(me,B1t),e(me,Y7),e(Y7,pRe),e(pRe,I1t),e(Y7,N1t),e(Y7,Pie),e(Pie,q1t),e(Y7,j1t),e(me,D1t),e(me,Z7),e(Z7,_Re),e(_Re,G1t),e(Z7,O1t),e(Z7,Bie),e(Bie,V1t),e(Z7,X1t),e(me,z1t),e(me,K7),e(K7,bRe),e(bRe,Q1t),e(K7,W1t),e(K7,Iie),e(Iie,U1t),e(K7,H1t),e(me,J1t),e(me,e8),e(e8,vRe),e(vRe,Y1t),e(e8,Z1t),e(e8,Nie),e(Nie,K1t),e(e8,e2t),e(me,o2t),e(me,o8),e(o8,FRe),e(FRe,r2t),e(o8,t2t),e(o8,qie),e(qie,a2t),e(o8,n2t),e(me,s2t),e(me,r8),e(r8,TRe),e(TRe,l2t),e(r8,i2t),e(r8,jie),e(jie,d2t),e(r8,m2t),e(me,c2t),e(me,t8),e(t8,MRe),e(MRe,f2t),e(t8,g2t),e(t8,Die),e(Die,h2t),e(t8,u2t),e(me,p2t),e(me,a8),e(a8,ERe),e(ERe,_2t),e(a8,b2t),e(a8,Gie),e(Gie,v2t),e(a8,F2t),e(me,T2t),e(me,n8),e(n8,CRe),e(CRe,M2t),e(n8,E2t),e(n8,Oie),e(Oie,C2t),e(n8,w2t),e(me,A2t),e(me,s8),e(s8,wRe),e(wRe,L2t),e(s8,y2t),e(s8,Vie),e(Vie,x2t),e(s8,$2t),e(me,k2t),e(me,l8),e(l8,ARe),e(ARe,S2t),e(l8,R2t),e(l8,Xie),e(Xie,P2t),e(l8,B2t),e(me,I2t),e(me,i8),e(i8,LRe),e(LRe,N2t),e(i8,q2t),e(i8,zie),e(zie,j2t),e(i8,D2t),e(me,G2t),e(me,d8),e(d8,yRe),e(yRe,O2t),e(d8,V2t),e(d8,Qie),e(Qie,X2t),e(d8,z2t),e(me,Q2t),e(me,m8),e(m8,xRe),e(xRe,W2t),e(m8,U2t),e(m8,Wie),e(Wie,H2t),e(m8,J2t),e(rt,Y2t),M(c8,rt,null),b(c,_do,_),b(c,nf,_),e(nf,f8),e(f8,$Re),M(qB,$Re,null),e(nf,Z2t),e(nf,kRe),e(kRe,K2t),b(c,bdo,_),b(c,Lr,_),M(jB,Lr,null),e(Lr,ebt),e(Lr,sf),e(sf,obt),e(sf,Uie),e(Uie,rbt),e(sf,tbt),e(sf,Hie),e(Hie,abt),e(sf,nbt),e(Lr,sbt),e(Lr,DB),e(DB,lbt),e(DB,SRe),e(SRe,ibt),e(DB,dbt),e(Lr,mbt),e(Lr,ha),M(GB,ha,null),e(ha,cbt),e(ha,RRe),e(RRe,fbt),e(ha,gbt),e(ha,lf),e(lf,hbt),e(lf,PRe),e(PRe,ubt),e(lf,pbt),e(lf,Jie),e(Jie,_bt),e(lf,bbt),e(ha,vbt),M(g8,ha,null),e(Lr,Fbt),e(Lr,tt),M(OB,tt,null),e(tt,Tbt),e(tt,BRe),e(BRe,Mbt),e(tt,Ebt),e(tt,es),e(es,Cbt),e(es,IRe),e(IRe,wbt),e(es,Abt),e(es,NRe),e(NRe,Lbt),e(es,ybt),e(es,qRe),e(qRe,xbt),e(es,$bt),e(tt,kbt),e(tt,he),e(he,h8),e(h8,jRe),e(jRe,Sbt),e(h8,Rbt),e(h8,Yie),e(Yie,Pbt),e(h8,Bbt),e(he,Ibt),e(he,u8),e(u8,DRe),e(DRe,Nbt),e(u8,qbt),e(u8,Zie),e(Zie,jbt),e(u8,Dbt),e(he,Gbt),e(he,p8),e(p8,GRe),e(GRe,Obt),e(p8,Vbt),e(p8,Kie),e(Kie,Xbt),e(p8,zbt),e(he,Qbt),e(he,_8),e(_8,ORe),e(ORe,Wbt),e(_8,Ubt),e(_8,ede),e(ede,Hbt),e(_8,Jbt),e(he,Ybt),e(he,b8),e(b8,VRe),e(VRe,Zbt),e(b8,Kbt),e(b8,ode),e(ode,evt),e(b8,ovt),e(he,rvt),e(he,v8),e(v8,XRe),e(XRe,tvt),e(v8,avt),e(v8,rde),e(rde,nvt),e(v8,svt),e(he,lvt),e(he,F8),e(F8,zRe),e(zRe,ivt),e(F8,dvt),e(F8,tde),e(tde,mvt),e(F8,cvt),e(he,fvt),e(he,T8),e(T8,QRe),e(QRe,gvt),e(T8,hvt),e(T8,ade),e(ade,uvt),e(T8,pvt),e(he,_vt),e(he,M8),e(M8,WRe),e(WRe,bvt),e(M8,vvt),e(M8,nde),e(nde,Fvt),e(M8,Tvt),e(he,Mvt),e(he,E8),e(E8,URe),e(URe,Evt),e(E8,Cvt),e(E8,sde),e(sde,wvt),e(E8,Avt),e(he,Lvt),e(he,C8),e(C8,HRe),e(HRe,yvt),e(C8,xvt),e(C8,lde),e(lde,$vt),e(C8,kvt),e(he,Svt),e(he,w8),e(w8,JRe),e(JRe,Rvt),e(w8,Pvt),e(w8,ide),e(ide,Bvt),e(w8,Ivt),e(he,Nvt),e(he,A8),e(A8,YRe),e(YRe,qvt),e(A8,jvt),e(A8,dde),e(dde,Dvt),e(A8,Gvt),e(he,Ovt),e(he,L8),e(L8,ZRe),e(ZRe,Vvt),e(L8,Xvt),e(L8,mde),e(mde,zvt),e(L8,Qvt),e(he,Wvt),e(he,y8),e(y8,KRe),e(KRe,Uvt),e(y8,Hvt),e(y8,cde),e(cde,Jvt),e(y8,Yvt),e(he,Zvt),e(he,x8),e(x8,ePe),e(ePe,Kvt),e(x8,eFt),e(x8,fde),e(fde,oFt),e(x8,rFt),e(he,tFt),e(he,$8),e($8,oPe),e(oPe,aFt),e($8,nFt),e($8,gde),e(gde,sFt),e($8,lFt),e(he,iFt),e(he,k8),e(k8,rPe),e(rPe,dFt),e(k8,mFt),e(k8,hde),e(hde,cFt),e(k8,fFt),e(he,gFt),e(he,S8),e(S8,tPe),e(tPe,hFt),e(S8,uFt),e(S8,ude),e(ude,pFt),e(S8,_Ft),e(he,bFt),e(he,R8),e(R8,aPe),e(aPe,vFt),e(R8,FFt),e(R8,pde),e(pde,TFt),e(R8,MFt),e(he,EFt),e(he,P8),e(P8,nPe),e(nPe,CFt),e(P8,wFt),e(P8,_de),e(_de,AFt),e(P8,LFt),e(tt,yFt),M(B8,tt,null),b(c,vdo,_),b(c,df,_),e(df,I8),e(I8,sPe),M(VB,sPe,null),e(df,xFt),e(df,lPe),e(lPe,$Ft),b(c,Fdo,_),b(c,yr,_),M(XB,yr,null),e(yr,kFt),e(yr,mf),e(mf,SFt),e(mf,bde),e(bde,RFt),e(mf,PFt),e(mf,vde),e(vde,BFt),e(mf,IFt),e(yr,NFt),e(yr,zB),e(zB,qFt),e(zB,iPe),e(iPe,jFt),e(zB,DFt),e(yr,GFt),e(yr,ua),M(QB,ua,null),e(ua,OFt),e(ua,dPe),e(dPe,VFt),e(ua,XFt),e(ua,cf),e(cf,zFt),e(cf,mPe),e(mPe,QFt),e(cf,WFt),e(cf,Fde),e(Fde,UFt),e(cf,HFt),e(ua,JFt),M(N8,ua,null),e(yr,YFt),e(yr,at),M(WB,at,null),e(at,ZFt),e(at,cPe),e(cPe,KFt),e(at,eTt),e(at,os),e(os,oTt),e(os,fPe),e(fPe,rTt),e(os,tTt),e(os,gPe),e(gPe,aTt),e(os,nTt),e(os,hPe),e(hPe,sTt),e(os,lTt),e(at,iTt),e(at,uPe),e(uPe,q8),e(q8,pPe),e(pPe,dTt),e(q8,mTt),e(q8,Tde),e(Tde,cTt),e(q8,fTt),e(at,gTt),M(j8,at,null),b(c,Tdo,_),b(c,ff,_),e(ff,D8),e(D8,_Pe),M(UB,_Pe,null),e(ff,hTt),e(ff,bPe),e(bPe,uTt),b(c,Mdo,_),b(c,xr,_),M(HB,xr,null),e(xr,pTt),e(xr,gf),e(gf,_Tt),e(gf,Mde),e(Mde,bTt),e(gf,vTt),e(gf,Ede),e(Ede,FTt),e(gf,TTt),e(xr,MTt),e(xr,JB),e(JB,ETt),e(JB,vPe),e(vPe,CTt),e(JB,wTt),e(xr,ATt),e(xr,pa),M(YB,pa,null),e(pa,LTt),e(pa,FPe),e(FPe,yTt),e(pa,xTt),e(pa,hf),e(hf,$Tt),e(hf,TPe),e(TPe,kTt),e(hf,STt),e(hf,Cde),e(Cde,RTt),e(hf,PTt),e(pa,BTt),M(G8,pa,null),e(xr,ITt),e(xr,nt),M(ZB,nt,null),e(nt,NTt),e(nt,MPe),e(MPe,qTt),e(nt,jTt),e(nt,rs),e(rs,DTt),e(rs,EPe),e(EPe,GTt),e(rs,OTt),e(rs,CPe),e(CPe,VTt),e(rs,XTt),e(rs,wPe),e(wPe,zTt),e(rs,QTt),e(nt,WTt),e(nt,KB),e(KB,O8),e(O8,APe),e(APe,UTt),e(O8,HTt),e(O8,wde),e(wde,JTt),e(O8,YTt),e(KB,ZTt),e(KB,V8),e(V8,LPe),e(LPe,KTt),e(V8,eMt),e(V8,Ade),e(Ade,oMt),e(V8,rMt),e(nt,tMt),M(X8,nt,null),b(c,Edo,_),b(c,uf,_),e(uf,z8),e(z8,yPe),M(eI,yPe,null),e(uf,aMt),e(uf,xPe),e(xPe,nMt),b(c,Cdo,_),b(c,$r,_),M(oI,$r,null),e($r,sMt),e($r,pf),e(pf,lMt),e(pf,Lde),e(Lde,iMt),e(pf,dMt),e(pf,yde),e(yde,mMt),e(pf,cMt),e($r,fMt),e($r,rI),e(rI,gMt),e(rI,$Pe),e($Pe,hMt),e(rI,uMt),e($r,pMt),e($r,_a),M(tI,_a,null),e(_a,_Mt),e(_a,kPe),e(kPe,bMt),e(_a,vMt),e(_a,_f),e(_f,FMt),e(_f,SPe),e(SPe,TMt),e(_f,MMt),e(_f,xde),e(xde,EMt),e(_f,CMt),e(_a,wMt),M(Q8,_a,null),e($r,AMt),e($r,st),M(aI,st,null),e(st,LMt),e(st,RPe),e(RPe,yMt),e(st,xMt),e(st,ts),e(ts,$Mt),e(ts,PPe),e(PPe,kMt),e(ts,SMt),e(ts,BPe),e(BPe,RMt),e(ts,PMt),e(ts,IPe),e(IPe,BMt),e(ts,IMt),e(st,NMt),e(st,ne),e(ne,W8),e(W8,NPe),e(NPe,qMt),e(W8,jMt),e(W8,$de),e($de,DMt),e(W8,GMt),e(ne,OMt),e(ne,U8),e(U8,qPe),e(qPe,VMt),e(U8,XMt),e(U8,kde),e(kde,zMt),e(U8,QMt),e(ne,WMt),e(ne,H8),e(H8,jPe),e(jPe,UMt),e(H8,HMt),e(H8,Sde),e(Sde,JMt),e(H8,YMt),e(ne,ZMt),e(ne,J8),e(J8,DPe),e(DPe,KMt),e(J8,eEt),e(J8,Rde),e(Rde,oEt),e(J8,rEt),e(ne,tEt),e(ne,Y8),e(Y8,GPe),e(GPe,aEt),e(Y8,nEt),e(Y8,Pde),e(Pde,sEt),e(Y8,lEt),e(ne,iEt),e(ne,Z8),e(Z8,OPe),e(OPe,dEt),e(Z8,mEt),e(Z8,Bde),e(Bde,cEt),e(Z8,fEt),e(ne,gEt),e(ne,K8),e(K8,VPe),e(VPe,hEt),e(K8,uEt),e(K8,Ide),e(Ide,pEt),e(K8,_Et),e(ne,bEt),e(ne,eL),e(eL,XPe),e(XPe,vEt),e(eL,FEt),e(eL,Nde),e(Nde,TEt),e(eL,MEt),e(ne,EEt),e(ne,oL),e(oL,zPe),e(zPe,CEt),e(oL,wEt),e(oL,qde),e(qde,AEt),e(oL,LEt),e(ne,yEt),e(ne,rL),e(rL,QPe),e(QPe,xEt),e(rL,$Et),e(rL,jde),e(jde,kEt),e(rL,SEt),e(ne,REt),e(ne,tL),e(tL,WPe),e(WPe,PEt),e(tL,BEt),e(tL,Dde),e(Dde,IEt),e(tL,NEt),e(ne,qEt),e(ne,aL),e(aL,UPe),e(UPe,jEt),e(aL,DEt),e(aL,Gde),e(Gde,GEt),e(aL,OEt),e(ne,VEt),e(ne,nL),e(nL,HPe),e(HPe,XEt),e(nL,zEt),e(nL,Ode),e(Ode,QEt),e(nL,WEt),e(ne,UEt),e(ne,sL),e(sL,JPe),e(JPe,HEt),e(sL,JEt),e(sL,Vde),e(Vde,YEt),e(sL,ZEt),e(ne,KEt),e(ne,lL),e(lL,YPe),e(YPe,e4t),e(lL,o4t),e(lL,Xde),e(Xde,r4t),e(lL,t4t),e(ne,a4t),e(ne,iL),e(iL,ZPe),e(ZPe,n4t),e(iL,s4t),e(iL,zde),e(zde,l4t),e(iL,i4t),e(ne,d4t),e(ne,dL),e(dL,KPe),e(KPe,m4t),e(dL,c4t),e(dL,Qde),e(Qde,f4t),e(dL,g4t),e(ne,h4t),e(ne,mL),e(mL,eBe),e(eBe,u4t),e(mL,p4t),e(mL,Wde),e(Wde,_4t),e(mL,b4t),e(ne,v4t),e(ne,cL),e(cL,oBe),e(oBe,F4t),e(cL,T4t),e(cL,Ude),e(Ude,M4t),e(cL,E4t),e(ne,C4t),e(ne,fL),e(fL,rBe),e(rBe,w4t),e(fL,A4t),e(fL,Hde),e(Hde,L4t),e(fL,y4t),e(ne,x4t),e(ne,gL),e(gL,tBe),e(tBe,$4t),e(gL,k4t),e(gL,Jde),e(Jde,S4t),e(gL,R4t),e(ne,P4t),e(ne,hL),e(hL,aBe),e(aBe,B4t),e(hL,I4t),e(hL,Yde),e(Yde,N4t),e(hL,q4t),e(ne,j4t),e(ne,uL),e(uL,nBe),e(nBe,D4t),e(uL,G4t),e(uL,Zde),e(Zde,O4t),e(uL,V4t),e(ne,X4t),e(ne,pL),e(pL,sBe),e(sBe,z4t),e(pL,Q4t),e(pL,Kde),e(Kde,W4t),e(pL,U4t),e(ne,H4t),e(ne,_L),e(_L,lBe),e(lBe,J4t),e(_L,Y4t),e(_L,eme),e(eme,Z4t),e(_L,K4t),e(ne,eCt),e(ne,bL),e(bL,iBe),e(iBe,oCt),e(bL,rCt),e(bL,ome),e(ome,tCt),e(bL,aCt),e(ne,nCt),e(ne,vL),e(vL,dBe),e(dBe,sCt),e(vL,lCt),e(vL,rme),e(rme,iCt),e(vL,dCt),e(st,mCt),M(FL,st,null),b(c,wdo,_),b(c,bf,_),e(bf,TL),e(TL,mBe),M(nI,mBe,null),e(bf,cCt),e(bf,cBe),e(cBe,fCt),b(c,Ado,_),b(c,kr,_),M(sI,kr,null),e(kr,gCt),e(kr,vf),e(vf,hCt),e(vf,tme),e(tme,uCt),e(vf,pCt),e(vf,ame),e(ame,_Ct),e(vf,bCt),e(kr,vCt),e(kr,lI),e(lI,FCt),e(lI,fBe),e(fBe,TCt),e(lI,MCt),e(kr,ECt),e(kr,ba),M(iI,ba,null),e(ba,CCt),e(ba,gBe),e(gBe,wCt),e(ba,ACt),e(ba,Ff),e(Ff,LCt),e(Ff,hBe),e(hBe,yCt),e(Ff,xCt),e(Ff,nme),e(nme,$Ct),e(Ff,kCt),e(ba,SCt),M(ML,ba,null),e(kr,RCt),e(kr,lt),M(dI,lt,null),e(lt,PCt),e(lt,uBe),e(uBe,BCt),e(lt,ICt),e(lt,as),e(as,NCt),e(as,pBe),e(pBe,qCt),e(as,jCt),e(as,_Be),e(_Be,DCt),e(as,GCt),e(as,bBe),e(bBe,OCt),e(as,VCt),e(lt,XCt),e(lt,Se),e(Se,EL),e(EL,vBe),e(vBe,zCt),e(EL,QCt),e(EL,sme),e(sme,WCt),e(EL,UCt),e(Se,HCt),e(Se,CL),e(CL,FBe),e(FBe,JCt),e(CL,YCt),e(CL,lme),e(lme,ZCt),e(CL,KCt),e(Se,e3t),e(Se,wL),e(wL,TBe),e(TBe,o3t),e(wL,r3t),e(wL,ime),e(ime,t3t),e(wL,a3t),e(Se,n3t),e(Se,AL),e(AL,MBe),e(MBe,s3t),e(AL,l3t),e(AL,dme),e(dme,i3t),e(AL,d3t),e(Se,m3t),e(Se,LL),e(LL,EBe),e(EBe,c3t),e(LL,f3t),e(LL,mme),e(mme,g3t),e(LL,h3t),e(Se,u3t),e(Se,yL),e(yL,CBe),e(CBe,p3t),e(yL,_3t),e(yL,cme),e(cme,b3t),e(yL,v3t),e(Se,F3t),e(Se,xL),e(xL,wBe),e(wBe,T3t),e(xL,M3t),e(xL,fme),e(fme,E3t),e(xL,C3t),e(Se,w3t),e(Se,$L),e($L,ABe),e(ABe,A3t),e($L,L3t),e($L,gme),e(gme,y3t),e($L,x3t),e(Se,$3t),e(Se,kL),e(kL,LBe),e(LBe,k3t),e(kL,S3t),e(kL,hme),e(hme,R3t),e(kL,P3t),e(Se,B3t),e(Se,SL),e(SL,yBe),e(yBe,I3t),e(SL,N3t),e(SL,ume),e(ume,q3t),e(SL,j3t),e(lt,D3t),M(RL,lt,null),b(c,Ldo,_),b(c,Tf,_),e(Tf,PL),e(PL,xBe),M(mI,xBe,null),e(Tf,G3t),e(Tf,$Be),e($Be,O3t),b(c,ydo,_),b(c,Sr,_),M(cI,Sr,null),e(Sr,V3t),e(Sr,Mf),e(Mf,X3t),e(Mf,pme),e(pme,z3t),e(Mf,Q3t),e(Mf,_me),e(_me,W3t),e(Mf,U3t),e(Sr,H3t),e(Sr,fI),e(fI,J3t),e(fI,kBe),e(kBe,Y3t),e(fI,Z3t),e(Sr,K3t),e(Sr,va),M(gI,va,null),e(va,e5t),e(va,SBe),e(SBe,o5t),e(va,r5t),e(va,Ef),e(Ef,t5t),e(Ef,RBe),e(RBe,a5t),e(Ef,n5t),e(Ef,bme),e(bme,s5t),e(Ef,l5t),e(va,i5t),M(BL,va,null),e(Sr,d5t),e(Sr,it),M(hI,it,null),e(it,m5t),e(it,PBe),e(PBe,c5t),e(it,f5t),e(it,ns),e(ns,g5t),e(ns,BBe),e(BBe,h5t),e(ns,u5t),e(ns,IBe),e(IBe,p5t),e(ns,_5t),e(ns,NBe),e(NBe,b5t),e(ns,v5t),e(it,F5t),e(it,we),e(we,IL),e(IL,qBe),e(qBe,T5t),e(IL,M5t),e(IL,vme),e(vme,E5t),e(IL,C5t),e(we,w5t),e(we,NL),e(NL,jBe),e(jBe,A5t),e(NL,L5t),e(NL,Fme),e(Fme,y5t),e(NL,x5t),e(we,$5t),e(we,qL),e(qL,DBe),e(DBe,k5t),e(qL,S5t),e(qL,Tme),e(Tme,R5t),e(qL,P5t),e(we,B5t),e(we,jL),e(jL,GBe),e(GBe,I5t),e(jL,N5t),e(jL,Mme),e(Mme,q5t),e(jL,j5t),e(we,D5t),e(we,DL),e(DL,OBe),e(OBe,G5t),e(DL,O5t),e(DL,Eme),e(Eme,V5t),e(DL,X5t),e(we,z5t),e(we,GL),e(GL,VBe),e(VBe,Q5t),e(GL,W5t),e(GL,Cme),e(Cme,U5t),e(GL,H5t),e(we,J5t),e(we,OL),e(OL,XBe),e(XBe,Y5t),e(OL,Z5t),e(OL,wme),e(wme,K5t),e(OL,e0t),e(we,o0t),e(we,VL),e(VL,zBe),e(zBe,r0t),e(VL,t0t),e(VL,Ame),e(Ame,a0t),e(VL,n0t),e(we,s0t),e(we,XL),e(XL,QBe),e(QBe,l0t),e(XL,i0t),e(XL,Lme),e(Lme,d0t),e(XL,m0t),e(we,c0t),e(we,zL),e(zL,WBe),e(WBe,f0t),e(zL,g0t),e(zL,yme),e(yme,h0t),e(zL,u0t),e(we,p0t),e(we,QL),e(QL,UBe),e(UBe,_0t),e(QL,b0t),e(QL,xme),e(xme,v0t),e(QL,F0t),e(we,T0t),e(we,WL),e(WL,HBe),e(HBe,M0t),e(WL,E0t),e(WL,$me),e($me,C0t),e(WL,w0t),e(we,A0t),e(we,UL),e(UL,JBe),e(JBe,L0t),e(UL,y0t),e(UL,kme),e(kme,x0t),e(UL,$0t),e(it,k0t),M(HL,it,null),b(c,xdo,_),b(c,Cf,_),e(Cf,JL),e(JL,YBe),M(uI,YBe,null),e(Cf,S0t),e(Cf,ZBe),e(ZBe,R0t),b(c,$do,_),b(c,Rr,_),M(pI,Rr,null),e(Rr,P0t),e(Rr,wf),e(wf,B0t),e(wf,Sme),e(Sme,I0t),e(wf,N0t),e(wf,Rme),e(Rme,q0t),e(wf,j0t),e(Rr,D0t),e(Rr,_I),e(_I,G0t),e(_I,KBe),e(KBe,O0t),e(_I,V0t),e(Rr,X0t),e(Rr,Fa),M(bI,Fa,null),e(Fa,z0t),e(Fa,eIe),e(eIe,Q0t),e(Fa,W0t),e(Fa,Af),e(Af,U0t),e(Af,oIe),e(oIe,H0t),e(Af,J0t),e(Af,Pme),e(Pme,Y0t),e(Af,Z0t),e(Fa,K0t),M(YL,Fa,null),e(Rr,ewt),e(Rr,dt),M(vI,dt,null),e(dt,owt),e(dt,rIe),e(rIe,rwt),e(dt,twt),e(dt,ss),e(ss,awt),e(ss,tIe),e(tIe,nwt),e(ss,swt),e(ss,aIe),e(aIe,lwt),e(ss,iwt),e(ss,nIe),e(nIe,dwt),e(ss,mwt),e(dt,cwt),e(dt,Re),e(Re,ZL),e(ZL,sIe),e(sIe,fwt),e(ZL,gwt),e(ZL,Bme),e(Bme,hwt),e(ZL,uwt),e(Re,pwt),e(Re,KL),e(KL,lIe),e(lIe,_wt),e(KL,bwt),e(KL,Ime),e(Ime,vwt),e(KL,Fwt),e(Re,Twt),e(Re,ey),e(ey,iIe),e(iIe,Mwt),e(ey,Ewt),e(ey,Nme),e(Nme,Cwt),e(ey,wwt),e(Re,Awt),e(Re,oy),e(oy,dIe),e(dIe,Lwt),e(oy,ywt),e(oy,qme),e(qme,xwt),e(oy,$wt),e(Re,kwt),e(Re,ry),e(ry,mIe),e(mIe,Swt),e(ry,Rwt),e(ry,jme),e(jme,Pwt),e(ry,Bwt),e(Re,Iwt),e(Re,ty),e(ty,cIe),e(cIe,Nwt),e(ty,qwt),e(ty,Dme),e(Dme,jwt),e(ty,Dwt),e(Re,Gwt),e(Re,ay),e(ay,fIe),e(fIe,Owt),e(ay,Vwt),e(ay,Gme),e(Gme,Xwt),e(ay,zwt),e(Re,Qwt),e(Re,ny),e(ny,gIe),e(gIe,Wwt),e(ny,Uwt),e(ny,Ome),e(Ome,Hwt),e(ny,Jwt),e(Re,Ywt),e(Re,sy),e(sy,hIe),e(hIe,Zwt),e(sy,Kwt),e(sy,Vme),e(Vme,eAt),e(sy,oAt),e(Re,rAt),e(Re,ly),e(ly,uIe),e(uIe,tAt),e(ly,aAt),e(ly,Xme),e(Xme,nAt),e(ly,sAt),e(dt,lAt),M(iy,dt,null),b(c,kdo,_),b(c,Lf,_),e(Lf,dy),e(dy,pIe),M(FI,pIe,null),e(Lf,iAt),e(Lf,_Ie),e(_Ie,dAt),b(c,Sdo,_),b(c,Pr,_),M(TI,Pr,null),e(Pr,mAt),e(Pr,yf),e(yf,cAt),e(yf,zme),e(zme,fAt),e(yf,gAt),e(yf,Qme),e(Qme,hAt),e(yf,uAt),e(Pr,pAt),e(Pr,MI),e(MI,_At),e(MI,bIe),e(bIe,bAt),e(MI,vAt),e(Pr,FAt),e(Pr,Ta),M(EI,Ta,null),e(Ta,TAt),e(Ta,vIe),e(vIe,MAt),e(Ta,EAt),e(Ta,xf),e(xf,CAt),e(xf,FIe),e(FIe,wAt),e(xf,AAt),e(xf,Wme),e(Wme,LAt),e(xf,yAt),e(Ta,xAt),M(my,Ta,null),e(Pr,$At),e(Pr,mt),M(CI,mt,null),e(mt,kAt),e(mt,TIe),e(TIe,SAt),e(mt,RAt),e(mt,ls),e(ls,PAt),e(ls,MIe),e(MIe,BAt),e(ls,IAt),e(ls,EIe),e(EIe,NAt),e(ls,qAt),e(ls,CIe),e(CIe,jAt),e(ls,DAt),e(mt,GAt),e(mt,Pe),e(Pe,cy),e(cy,wIe),e(wIe,OAt),e(cy,VAt),e(cy,Ume),e(Ume,XAt),e(cy,zAt),e(Pe,QAt),e(Pe,fy),e(fy,AIe),e(AIe,WAt),e(fy,UAt),e(fy,Hme),e(Hme,HAt),e(fy,JAt),e(Pe,YAt),e(Pe,gy),e(gy,LIe),e(LIe,ZAt),e(gy,KAt),e(gy,Jme),e(Jme,e6t),e(gy,o6t),e(Pe,r6t),e(Pe,hy),e(hy,yIe),e(yIe,t6t),e(hy,a6t),e(hy,Yme),e(Yme,n6t),e(hy,s6t),e(Pe,l6t),e(Pe,uy),e(uy,xIe),e(xIe,i6t),e(uy,d6t),e(uy,Zme),e(Zme,m6t),e(uy,c6t),e(Pe,f6t),e(Pe,py),e(py,$Ie),e($Ie,g6t),e(py,h6t),e(py,Kme),e(Kme,u6t),e(py,p6t),e(Pe,_6t),e(Pe,_y),e(_y,kIe),e(kIe,b6t),e(_y,v6t),e(_y,ece),e(ece,F6t),e(_y,T6t),e(Pe,M6t),e(Pe,by),e(by,SIe),e(SIe,E6t),e(by,C6t),e(by,oce),e(oce,w6t),e(by,A6t),e(Pe,L6t),e(Pe,vy),e(vy,RIe),e(RIe,y6t),e(vy,x6t),e(vy,rce),e(rce,$6t),e(vy,k6t),e(Pe,S6t),e(Pe,Fy),e(Fy,PIe),e(PIe,R6t),e(Fy,P6t),e(Fy,tce),e(tce,B6t),e(Fy,I6t),e(mt,N6t),M(Ty,mt,null),b(c,Rdo,_),b(c,$f,_),e($f,My),e(My,BIe),M(wI,BIe,null),e($f,q6t),e($f,IIe),e(IIe,j6t),b(c,Pdo,_),b(c,Br,_),M(AI,Br,null),e(Br,D6t),e(Br,kf),e(kf,G6t),e(kf,ace),e(ace,O6t),e(kf,V6t),e(kf,nce),e(nce,X6t),e(kf,z6t),e(Br,Q6t),e(Br,LI),e(LI,W6t),e(LI,NIe),e(NIe,U6t),e(LI,H6t),e(Br,J6t),e(Br,Ma),M(yI,Ma,null),e(Ma,Y6t),e(Ma,qIe),e(qIe,Z6t),e(Ma,K6t),e(Ma,Sf),e(Sf,e7t),e(Sf,jIe),e(jIe,o7t),e(Sf,r7t),e(Sf,sce),e(sce,t7t),e(Sf,a7t),e(Ma,n7t),M(Ey,Ma,null),e(Br,s7t),e(Br,ct),M(xI,ct,null),e(ct,l7t),e(ct,DIe),e(DIe,i7t),e(ct,d7t),e(ct,is),e(is,m7t),e(is,GIe),e(GIe,c7t),e(is,f7t),e(is,OIe),e(OIe,g7t),e(is,h7t),e(is,VIe),e(VIe,u7t),e(is,p7t),e(ct,_7t),e(ct,Be),e(Be,Cy),e(Cy,XIe),e(XIe,b7t),e(Cy,v7t),e(Cy,lce),e(lce,F7t),e(Cy,T7t),e(Be,M7t),e(Be,wy),e(wy,zIe),e(zIe,E7t),e(wy,C7t),e(wy,ice),e(ice,w7t),e(wy,A7t),e(Be,L7t),e(Be,Ay),e(Ay,QIe),e(QIe,y7t),e(Ay,x7t),e(Ay,dce),e(dce,$7t),e(Ay,k7t),e(Be,S7t),e(Be,Ly),e(Ly,WIe),e(WIe,R7t),e(Ly,P7t),e(Ly,mce),e(mce,B7t),e(Ly,I7t),e(Be,N7t),e(Be,yy),e(yy,UIe),e(UIe,q7t),e(yy,j7t),e(yy,cce),e(cce,D7t),e(yy,G7t),e(Be,O7t),e(Be,xy),e(xy,HIe),e(HIe,V7t),e(xy,X7t),e(xy,fce),e(fce,z7t),e(xy,Q7t),e(Be,W7t),e(Be,$y),e($y,JIe),e(JIe,U7t),e($y,H7t),e($y,gce),e(gce,J7t),e($y,Y7t),e(Be,Z7t),e(Be,ky),e(ky,YIe),e(YIe,K7t),e(ky,e8t),e(ky,hce),e(hce,o8t),e(ky,r8t),e(Be,t8t),e(Be,Sy),e(Sy,ZIe),e(ZIe,a8t),e(Sy,n8t),e(Sy,uce),e(uce,s8t),e(Sy,l8t),e(Be,i8t),e(Be,Ry),e(Ry,KIe),e(KIe,d8t),e(Ry,m8t),e(Ry,pce),e(pce,c8t),e(Ry,f8t),e(ct,g8t),M(Py,ct,null),b(c,Bdo,_),b(c,Rf,_),e(Rf,By),e(By,eNe),M($I,eNe,null),e(Rf,h8t),e(Rf,oNe),e(oNe,u8t),b(c,Ido,_),b(c,Ir,_),M(kI,Ir,null),e(Ir,p8t),e(Ir,Pf),e(Pf,_8t),e(Pf,_ce),e(_ce,b8t),e(Pf,v8t),e(Pf,bce),e(bce,F8t),e(Pf,T8t),e(Ir,M8t),e(Ir,SI),e(SI,E8t),e(SI,rNe),e(rNe,C8t),e(SI,w8t),e(Ir,A8t),e(Ir,Ea),M(RI,Ea,null),e(Ea,L8t),e(Ea,tNe),e(tNe,y8t),e(Ea,x8t),e(Ea,Bf),e(Bf,$8t),e(Bf,aNe),e(aNe,k8t),e(Bf,S8t),e(Bf,vce),e(vce,R8t),e(Bf,P8t),e(Ea,B8t),M(Iy,Ea,null),e(Ir,I8t),e(Ir,ft),M(PI,ft,null),e(ft,N8t),e(ft,nNe),e(nNe,q8t),e(ft,j8t),e(ft,ds),e(ds,D8t),e(ds,sNe),e(sNe,G8t),e(ds,O8t),e(ds,lNe),e(lNe,V8t),e(ds,X8t),e(ds,iNe),e(iNe,z8t),e(ds,Q8t),e(ft,W8t),e(ft,Ie),e(Ie,Ny),e(Ny,dNe),e(dNe,U8t),e(Ny,H8t),e(Ny,Fce),e(Fce,J8t),e(Ny,Y8t),e(Ie,Z8t),e(Ie,qy),e(qy,mNe),e(mNe,K8t),e(qy,eLt),e(qy,Tce),e(Tce,oLt),e(qy,rLt),e(Ie,tLt),e(Ie,jy),e(jy,cNe),e(cNe,aLt),e(jy,nLt),e(jy,Mce),e(Mce,sLt),e(jy,lLt),e(Ie,iLt),e(Ie,Dy),e(Dy,fNe),e(fNe,dLt),e(Dy,mLt),e(Dy,Ece),e(Ece,cLt),e(Dy,fLt),e(Ie,gLt),e(Ie,Gy),e(Gy,gNe),e(gNe,hLt),e(Gy,uLt),e(Gy,Cce),e(Cce,pLt),e(Gy,_Lt),e(Ie,bLt),e(Ie,Oy),e(Oy,hNe),e(hNe,vLt),e(Oy,FLt),e(Oy,wce),e(wce,TLt),e(Oy,MLt),e(Ie,ELt),e(Ie,Vy),e(Vy,uNe),e(uNe,CLt),e(Vy,wLt),e(Vy,Ace),e(Ace,ALt),e(Vy,LLt),e(Ie,yLt),e(Ie,Xy),e(Xy,pNe),e(pNe,xLt),e(Xy,$Lt),e(Xy,Lce),e(Lce,kLt),e(Xy,SLt),e(Ie,RLt),e(Ie,zy),e(zy,_Ne),e(_Ne,PLt),e(zy,BLt),e(zy,yce),e(yce,ILt),e(zy,NLt),e(Ie,qLt),e(Ie,Qy),e(Qy,bNe),e(bNe,jLt),e(Qy,DLt),e(Qy,xce),e(xce,GLt),e(Qy,OLt),e(ft,VLt),M(Wy,ft,null),b(c,Ndo,_),b(c,If,_),e(If,Uy),e(Uy,vNe),M(BI,vNe,null),e(If,XLt),e(If,FNe),e(FNe,zLt),b(c,qdo,_),b(c,Nr,_),M(II,Nr,null),e(Nr,QLt),e(Nr,Nf),e(Nf,WLt),e(Nf,$ce),e($ce,ULt),e(Nf,HLt),e(Nf,kce),e(kce,JLt),e(Nf,YLt),e(Nr,ZLt),e(Nr,NI),e(NI,KLt),e(NI,TNe),e(TNe,eyt),e(NI,oyt),e(Nr,ryt),e(Nr,Ca),M(qI,Ca,null),e(Ca,tyt),e(Ca,MNe),e(MNe,ayt),e(Ca,nyt),e(Ca,qf),e(qf,syt),e(qf,ENe),e(ENe,lyt),e(qf,iyt),e(qf,Sce),e(Sce,dyt),e(qf,myt),e(Ca,cyt),M(Hy,Ca,null),e(Nr,fyt),e(Nr,gt),M(jI,gt,null),e(gt,gyt),e(gt,CNe),e(CNe,hyt),e(gt,uyt),e(gt,ms),e(ms,pyt),e(ms,wNe),e(wNe,_yt),e(ms,byt),e(ms,ANe),e(ANe,vyt),e(ms,Fyt),e(ms,LNe),e(LNe,Tyt),e(ms,Myt),e(gt,Eyt),e(gt,We),e(We,Jy),e(Jy,yNe),e(yNe,Cyt),e(Jy,wyt),e(Jy,Rce),e(Rce,Ayt),e(Jy,Lyt),e(We,yyt),e(We,Yy),e(Yy,xNe),e(xNe,xyt),e(Yy,$yt),e(Yy,Pce),e(Pce,kyt),e(Yy,Syt),e(We,Ryt),e(We,Zy),e(Zy,$Ne),e($Ne,Pyt),e(Zy,Byt),e(Zy,Bce),e(Bce,Iyt),e(Zy,Nyt),e(We,qyt),e(We,Ky),e(Ky,kNe),e(kNe,jyt),e(Ky,Dyt),e(Ky,Ice),e(Ice,Gyt),e(Ky,Oyt),e(We,Vyt),e(We,e9),e(e9,SNe),e(SNe,Xyt),e(e9,zyt),e(e9,Nce),e(Nce,Qyt),e(e9,Wyt),e(We,Uyt),e(We,o9),e(o9,RNe),e(RNe,Hyt),e(o9,Jyt),e(o9,qce),e(qce,Yyt),e(o9,Zyt),e(We,Kyt),e(We,r9),e(r9,PNe),e(PNe,e9t),e(r9,o9t),e(r9,jce),e(jce,r9t),e(r9,t9t),e(We,a9t),e(We,t9),e(t9,BNe),e(BNe,n9t),e(t9,s9t),e(t9,Dce),e(Dce,l9t),e(t9,i9t),e(gt,d9t),M(a9,gt,null),b(c,jdo,_),b(c,jf,_),e(jf,n9),e(n9,INe),M(DI,INe,null),e(jf,m9t),e(jf,NNe),e(NNe,c9t),b(c,Ddo,_),b(c,qr,_),M(GI,qr,null),e(qr,f9t),e(qr,Df),e(Df,g9t),e(Df,Gce),e(Gce,h9t),e(Df,u9t),e(Df,Oce),e(Oce,p9t),e(Df,_9t),e(qr,b9t),e(qr,OI),e(OI,v9t),e(OI,qNe),e(qNe,F9t),e(OI,T9t),e(qr,M9t),e(qr,wa),M(VI,wa,null),e(wa,E9t),e(wa,jNe),e(jNe,C9t),e(wa,w9t),e(wa,Gf),e(Gf,A9t),e(Gf,DNe),e(DNe,L9t),e(Gf,y9t),e(Gf,Vce),e(Vce,x9t),e(Gf,$9t),e(wa,k9t),M(s9,wa,null),e(qr,S9t),e(qr,ht),M(XI,ht,null),e(ht,R9t),e(ht,GNe),e(GNe,P9t),e(ht,B9t),e(ht,cs),e(cs,I9t),e(cs,ONe),e(ONe,N9t),e(cs,q9t),e(cs,VNe),e(VNe,j9t),e(cs,D9t),e(cs,XNe),e(XNe,G9t),e(cs,O9t),e(ht,V9t),e(ht,Ue),e(Ue,l9),e(l9,zNe),e(zNe,X9t),e(l9,z9t),e(l9,Xce),e(Xce,Q9t),e(l9,W9t),e(Ue,U9t),e(Ue,i9),e(i9,QNe),e(QNe,H9t),e(i9,J9t),e(i9,zce),e(zce,Y9t),e(i9,Z9t),e(Ue,K9t),e(Ue,d9),e(d9,WNe),e(WNe,ext),e(d9,oxt),e(d9,Qce),e(Qce,rxt),e(d9,txt),e(Ue,axt),e(Ue,m9),e(m9,UNe),e(UNe,nxt),e(m9,sxt),e(m9,Wce),e(Wce,lxt),e(m9,ixt),e(Ue,dxt),e(Ue,c9),e(c9,HNe),e(HNe,mxt),e(c9,cxt),e(c9,Uce),e(Uce,fxt),e(c9,gxt),e(Ue,hxt),e(Ue,f9),e(f9,JNe),e(JNe,uxt),e(f9,pxt),e(f9,Hce),e(Hce,_xt),e(f9,bxt),e(Ue,vxt),e(Ue,g9),e(g9,YNe),e(YNe,Fxt),e(g9,Txt),e(g9,Jce),e(Jce,Mxt),e(g9,Ext),e(Ue,Cxt),e(Ue,h9),e(h9,ZNe),e(ZNe,wxt),e(h9,Axt),e(h9,Yce),e(Yce,Lxt),e(h9,yxt),e(ht,xxt),M(u9,ht,null),b(c,Gdo,_),b(c,Of,_),e(Of,p9),e(p9,KNe),M(zI,KNe,null),e(Of,$xt),e(Of,eqe),e(eqe,kxt),b(c,Odo,_),b(c,jr,_),M(QI,jr,null),e(jr,Sxt),e(jr,Vf),e(Vf,Rxt),e(Vf,Zce),e(Zce,Pxt),e(Vf,Bxt),e(Vf,Kce),e(Kce,Ixt),e(Vf,Nxt),e(jr,qxt),e(jr,WI),e(WI,jxt),e(WI,oqe),e(oqe,Dxt),e(WI,Gxt),e(jr,Oxt),e(jr,Aa),M(UI,Aa,null),e(Aa,Vxt),e(Aa,rqe),e(rqe,Xxt),e(Aa,zxt),e(Aa,Xf),e(Xf,Qxt),e(Xf,tqe),e(tqe,Wxt),e(Xf,Uxt),e(Xf,efe),e(efe,Hxt),e(Xf,Jxt),e(Aa,Yxt),M(_9,Aa,null),e(jr,Zxt),e(jr,ut),M(HI,ut,null),e(ut,Kxt),e(ut,aqe),e(aqe,e$t),e(ut,o$t),e(ut,fs),e(fs,r$t),e(fs,nqe),e(nqe,t$t),e(fs,a$t),e(fs,sqe),e(sqe,n$t),e(fs,s$t),e(fs,lqe),e(lqe,l$t),e(fs,i$t),e(ut,d$t),e(ut,iqe),e(iqe,b9),e(b9,dqe),e(dqe,m$t),e(b9,c$t),e(b9,ofe),e(ofe,f$t),e(b9,g$t),e(ut,h$t),M(v9,ut,null),b(c,Vdo,_),b(c,zf,_),e(zf,F9),e(F9,mqe),M(JI,mqe,null),e(zf,u$t),e(zf,cqe),e(cqe,p$t),b(c,Xdo,_),b(c,Dr,_),M(YI,Dr,null),e(Dr,_$t),e(Dr,Qf),e(Qf,b$t),e(Qf,rfe),e(rfe,v$t),e(Qf,F$t),e(Qf,tfe),e(tfe,T$t),e(Qf,M$t),e(Dr,E$t),e(Dr,ZI),e(ZI,C$t),e(ZI,fqe),e(fqe,w$t),e(ZI,A$t),e(Dr,L$t),e(Dr,La),M(KI,La,null),e(La,y$t),e(La,gqe),e(gqe,x$t),e(La,$$t),e(La,Wf),e(Wf,k$t),e(Wf,hqe),e(hqe,S$t),e(Wf,R$t),e(Wf,afe),e(afe,P$t),e(Wf,B$t),e(La,I$t),M(T9,La,null),e(Dr,N$t),e(Dr,pt),M(eN,pt,null),e(pt,q$t),e(pt,uqe),e(uqe,j$t),e(pt,D$t),e(pt,gs),e(gs,G$t),e(gs,pqe),e(pqe,O$t),e(gs,V$t),e(gs,_qe),e(_qe,X$t),e(gs,z$t),e(gs,bqe),e(bqe,Q$t),e(gs,W$t),e(pt,U$t),e(pt,oN),e(oN,M9),e(M9,vqe),e(vqe,H$t),e(M9,J$t),e(M9,nfe),e(nfe,Y$t),e(M9,Z$t),e(oN,K$t),e(oN,E9),e(E9,Fqe),e(Fqe,ekt),e(E9,okt),e(E9,sfe),e(sfe,rkt),e(E9,tkt),e(pt,akt),M(C9,pt,null),b(c,zdo,_),b(c,Uf,_),e(Uf,w9),e(w9,Tqe),M(rN,Tqe,null),e(Uf,nkt),e(Uf,Mqe),e(Mqe,skt),b(c,Qdo,_),b(c,Gr,_),M(tN,Gr,null),e(Gr,lkt),e(Gr,Hf),e(Hf,ikt),e(Hf,lfe),e(lfe,dkt),e(Hf,mkt),e(Hf,ife),e(ife,ckt),e(Hf,fkt),e(Gr,gkt),e(Gr,aN),e(aN,hkt),e(aN,Eqe),e(Eqe,ukt),e(aN,pkt),e(Gr,_kt),e(Gr,ya),M(nN,ya,null),e(ya,bkt),e(ya,Cqe),e(Cqe,vkt),e(ya,Fkt),e(ya,Jf),e(Jf,Tkt),e(Jf,wqe),e(wqe,Mkt),e(Jf,Ekt),e(Jf,dfe),e(dfe,Ckt),e(Jf,wkt),e(ya,Akt),M(A9,ya,null),e(Gr,Lkt),e(Gr,_t),M(sN,_t,null),e(_t,ykt),e(_t,Aqe),e(Aqe,xkt),e(_t,$kt),e(_t,hs),e(hs,kkt),e(hs,Lqe),e(Lqe,Skt),e(hs,Rkt),e(hs,yqe),e(yqe,Pkt),e(hs,Bkt),e(hs,xqe),e(xqe,Ikt),e(hs,Nkt),e(_t,qkt),e(_t,$qe),e($qe,L9),e(L9,kqe),e(kqe,jkt),e(L9,Dkt),e(L9,mfe),e(mfe,Gkt),e(L9,Okt),e(_t,Vkt),M(y9,_t,null),Wdo=!0},p(c,[_]){const lN={};_&2&&(lN.$$scope={dirty:_,ctx:c}),ng.$set(lN);const Sqe={};_&2&&(Sqe.$$scope={dirty:_,ctx:c}),Nu.$set(Sqe);const Rqe={};_&2&&(Rqe.$$scope={dirty:_,ctx:c}),Cp.$set(Rqe);const Pqe={};_&2&&(Pqe.$$scope={dirty:_,ctx:c}),b_.$set(Pqe);const iN={};_&2&&(iN.$$scope={dirty:_,ctx:c}),v_.$set(iN);const Bqe={};_&2&&(Bqe.$$scope={dirty:_,ctx:c}),Y_.$set(Bqe);const us={};_&2&&(us.$$scope={dirty:_,ctx:c}),Z_.$set(us);const Iqe={};_&2&&(Iqe.$$scope={dirty:_,ctx:c}),C1.$set(Iqe);const Nqe={};_&2&&(Nqe.$$scope={dirty:_,ctx:c}),w1.$set(Nqe);const qqe={};_&2&&(qqe.$$scope={dirty:_,ctx:c}),y1.$set(qqe);const dN={};_&2&&(dN.$$scope={dirty:_,ctx:c}),Kb.$set(dN);const jqe={};_&2&&(jqe.$$scope={dirty:_,ctx:c}),ov.$set(jqe);const mN={};_&2&&(mN.$$scope={dirty:_,ctx:c}),Zv.$set(mN);const Dqe={};_&2&&(Dqe.$$scope={dirty:_,ctx:c}),eF.$set(Dqe);const cN={};_&2&&(cN.$$scope={dirty:_,ctx:c}),zF.$set(cN);const Gqe={};_&2&&(Gqe.$$scope={dirty:_,ctx:c}),WF.$set(Gqe);const Oqe={};_&2&&(Oqe.$$scope={dirty:_,ctx:c}),YF.$set(Oqe);const Vqe={};_&2&&(Vqe.$$scope={dirty:_,ctx:c}),KF.$set(Vqe);const Yf={};_&2&&(Yf.$$scope={dirty:_,ctx:c}),GT.$set(Yf);const Xqe={};_&2&&(Xqe.$$scope={dirty:_,ctx:c}),VT.$set(Xqe);const zqe={};_&2&&(zqe.$$scope={dirty:_,ctx:c}),cM.$set(zqe);const Qqe={};_&2&&(Qqe.$$scope={dirty:_,ctx:c}),gM.$set(Qqe);const fN={};_&2&&(fN.$$scope={dirty:_,ctx:c}),bE.$set(fN);const Wqe={};_&2&&(Wqe.$$scope={dirty:_,ctx:c}),FE.$set(Wqe);const Uqe={};_&2&&(Uqe.$$scope={dirty:_,ctx:c}),o4.$set(Uqe);const Hqe={};_&2&&(Hqe.$$scope={dirty:_,ctx:c}),t4.$set(Hqe);const Et={};_&2&&(Et.$$scope={dirty:_,ctx:c}),f4.$set(Et);const gN={};_&2&&(gN.$$scope={dirty:_,ctx:c}),h4.$set(gN);const Jqe={};_&2&&(Jqe.$$scope={dirty:_,ctx:c}),aC.$set(Jqe);const hN={};_&2&&(hN.$$scope={dirty:_,ctx:c}),sC.$set(hN);const Yqe={};_&2&&(Yqe.$$scope={dirty:_,ctx:c}),t3.$set(Yqe);const Ct={};_&2&&(Ct.$$scope={dirty:_,ctx:c}),n3.$set(Ct);const Zqe={};_&2&&(Zqe.$$scope={dirty:_,ctx:c}),i3.$set(Zqe);const Zf={};_&2&&(Zf.$$scope={dirty:_,ctx:c}),m3.$set(Zf);const Kqe={};_&2&&(Kqe.$$scope={dirty:_,ctx:c}),u3.$set(Kqe);const eje={};_&2&&(eje.$$scope={dirty:_,ctx:c}),_3.$set(eje);const L={};_&2&&(L.$$scope={dirty:_,ctx:c}),P3.$set(L);const x9={};_&2&&(x9.$$scope={dirty:_,ctx:c}),I3.$set(x9);const oje={};_&2&&(oje.$$scope={dirty:_,ctx:c}),j3.$set(oje);const rje={};_&2&&(rje.$$scope={dirty:_,ctx:c}),G3.$set(rje);const $9={};_&2&&($9.$$scope={dirty:_,ctx:c}),X3.$set($9);const tje={};_&2&&(tje.$$scope={dirty:_,ctx:c}),Q3.$set(tje);const aje={};_&2&&(aje.$$scope={dirty:_,ctx:c}),H3.$set(aje);const k9={};_&2&&(k9.$$scope={dirty:_,ctx:c}),Y3.$set(k9);const nje={};_&2&&(nje.$$scope={dirty:_,ctx:c}),i5.$set(nje);const sje={};_&2&&(sje.$$scope={dirty:_,ctx:c}),m5.$set(sje);const S9={};_&2&&(S9.$$scope={dirty:_,ctx:c}),_5.$set(S9);const lje={};_&2&&(lje.$$scope={dirty:_,ctx:c}),v5.$set(lje);const ije={};_&2&&(ije.$$scope={dirty:_,ctx:c}),k5.$set(ije);const R9={};_&2&&(R9.$$scope={dirty:_,ctx:c}),R5.$set(R9);const dje={};_&2&&(dje.$$scope={dirty:_,ctx:c}),q5.$set(dje);const mje={};_&2&&(mje.$$scope={dirty:_,ctx:c}),D5.$set(mje);const P9={};_&2&&(P9.$$scope={dirty:_,ctx:c}),W5.$set(P9);const cje={};_&2&&(cje.$$scope={dirty:_,ctx:c}),H5.$set(cje);const fje={};_&2&&(fje.$$scope={dirty:_,ctx:c}),o0.$set(fje);const B9={};_&2&&(B9.$$scope={dirty:_,ctx:c}),t0.$set(B9);const gje={};_&2&&(gje.$$scope={dirty:_,ctx:c}),m0.$set(gje);const hje={};_&2&&(hje.$$scope={dirty:_,ctx:c}),f0.$set(hje);const I9={};_&2&&(I9.$$scope={dirty:_,ctx:c}),u0.$set(I9);const uje={};_&2&&(uje.$$scope={dirty:_,ctx:c}),_0.$set(uje);const pje={};_&2&&(pje.$$scope={dirty:_,ctx:c}),C0.$set(pje);const N9={};_&2&&(N9.$$scope={dirty:_,ctx:c}),A0.$set(N9);const _je={};_&2&&(_je.$$scope={dirty:_,ctx:c}),x0.$set(_je);const bje={};_&2&&(bje.$$scope={dirty:_,ctx:c}),k0.$set(bje);const q9={};_&2&&(q9.$$scope={dirty:_,ctx:c}),P0.$set(q9);const vje={};_&2&&(vje.$$scope={dirty:_,ctx:c}),I0.$set(vje);const Fje={};_&2&&(Fje.$$scope={dirty:_,ctx:c}),Dw.$set(Fje);const j9={};_&2&&(j9.$$scope={dirty:_,ctx:c}),Ow.$set(j9);const Tje={};_&2&&(Tje.$$scope={dirty:_,ctx:c}),fA.$set(Tje);const Mje={};_&2&&(Mje.$$scope={dirty:_,ctx:c}),hA.$set(Mje);const D9={};_&2&&(D9.$$scope={dirty:_,ctx:c}),xA.$set(D9);const Eje={};_&2&&(Eje.$$scope={dirty:_,ctx:c}),kA.$set(Eje);const Cje={};_&2&&(Cje.$$scope={dirty:_,ctx:c}),GA.$set(Cje);const G9={};_&2&&(G9.$$scope={dirty:_,ctx:c}),VA.$set(G9);const wje={};_&2&&(wje.$$scope={dirty:_,ctx:c}),WA.$set(wje);const Aje={};_&2&&(Aje.$$scope={dirty:_,ctx:c}),HA.$set(Aje);const O9={};_&2&&(O9.$$scope={dirty:_,ctx:c}),_6.$set(O9);const Lje={};_&2&&(Lje.$$scope={dirty:_,ctx:c}),v6.$set(Lje);const yje={};_&2&&(yje.$$scope={dirty:_,ctx:c}),$6.$set(yje);const V9={};_&2&&(V9.$$scope={dirty:_,ctx:c}),S6.$set(V9);const xje={};_&2&&(xje.$$scope={dirty:_,ctx:c}),l7.$set(xje);const $je={};_&2&&($je.$$scope={dirty:_,ctx:c}),d7.$set($je);const X9={};_&2&&(X9.$$scope={dirty:_,ctx:c}),L7.$set(X9);const kje={};_&2&&(kje.$$scope={dirty:_,ctx:c}),x7.$set(kje);const Sje={};_&2&&(Sje.$$scope={dirty:_,ctx:c}),S7.$set(Sje);const z9={};_&2&&(z9.$$scope={dirty:_,ctx:c}),P7.$set(z9);const Rje={};_&2&&(Rje.$$scope={dirty:_,ctx:c}),I7.$set(Rje);const Pje={};_&2&&(Pje.$$scope={dirty:_,ctx:c}),q7.$set(Pje);const Q9={};_&2&&(Q9.$$scope={dirty:_,ctx:c}),D7.$set(Q9);const Bje={};_&2&&(Bje.$$scope={dirty:_,ctx:c}),O7.$set(Bje);const Ije={};_&2&&(Ije.$$scope={dirty:_,ctx:c}),c8.$set(Ije);const W9={};_&2&&(W9.$$scope={dirty:_,ctx:c}),g8.$set(W9);const Nje={};_&2&&(Nje.$$scope={dirty:_,ctx:c}),B8.$set(Nje);const qje={};_&2&&(qje.$$scope={dirty:_,ctx:c}),N8.$set(qje);const U9={};_&2&&(U9.$$scope={dirty:_,ctx:c}),j8.$set(U9);const jje={};_&2&&(jje.$$scope={dirty:_,ctx:c}),G8.$set(jje);const Dje={};_&2&&(Dje.$$scope={dirty:_,ctx:c}),X8.$set(Dje);const H9={};_&2&&(H9.$$scope={dirty:_,ctx:c}),Q8.$set(H9);const Gje={};_&2&&(Gje.$$scope={dirty:_,ctx:c}),FL.$set(Gje);const Oje={};_&2&&(Oje.$$scope={dirty:_,ctx:c}),ML.$set(Oje);const J9={};_&2&&(J9.$$scope={dirty:_,ctx:c}),RL.$set(J9);const Vje={};_&2&&(Vje.$$scope={dirty:_,ctx:c}),BL.$set(Vje);const Xje={};_&2&&(Xje.$$scope={dirty:_,ctx:c}),HL.$set(Xje);const Y9={};_&2&&(Y9.$$scope={dirty:_,ctx:c}),YL.$set(Y9);const zje={};_&2&&(zje.$$scope={dirty:_,ctx:c}),iy.$set(zje);const Qje={};_&2&&(Qje.$$scope={dirty:_,ctx:c}),my.$set(Qje);const Z9={};_&2&&(Z9.$$scope={dirty:_,ctx:c}),Ty.$set(Z9);const Wje={};_&2&&(Wje.$$scope={dirty:_,ctx:c}),Ey.$set(Wje);const Uje={};_&2&&(Uje.$$scope={dirty:_,ctx:c}),Py.$set(Uje);const K9={};_&2&&(K9.$$scope={dirty:_,ctx:c}),Iy.$set(K9);const Hje={};_&2&&(Hje.$$scope={dirty:_,ctx:c}),Wy.$set(Hje);const Jje={};_&2&&(Jje.$$scope={dirty:_,ctx:c}),Hy.$set(Jje);const ex={};_&2&&(ex.$$scope={dirty:_,ctx:c}),a9.$set(ex);const Yje={};_&2&&(Yje.$$scope={dirty:_,ctx:c}),s9.$set(Yje);const Zje={};_&2&&(Zje.$$scope={dirty:_,ctx:c}),u9.$set(Zje);const ox={};_&2&&(ox.$$scope={dirty:_,ctx:c}),_9.$set(ox);const Kje={};_&2&&(Kje.$$scope={dirty:_,ctx:c}),v9.$set(Kje);const eDe={};_&2&&(eDe.$$scope={dirty:_,ctx:c}),T9.$set(eDe);const rx={};_&2&&(rx.$$scope={dirty:_,ctx:c}),C9.$set(rx);const oDe={};_&2&&(oDe.$$scope={dirty:_,ctx:c}),A9.$set(oDe);const rDe={};_&2&&(rDe.$$scope={dirty:_,ctx:c}),y9.$set(rDe)},i(c){Wdo||(E(m.$$.fragment,c),E(sn.$$.fragment,c),E(uk.$$.fragment,c),E(pk.$$.fragment,c),E(ng.$$.fragment,c),E(_k.$$.fragment,c),E(bk.$$.fragment,c),E(Tk.$$.fragment,c),E(Nu.$$.fragment,c),E(Mk.$$.fragment,c),E(Ek.$$.fragment,c),E(Ck.$$.fragment,c),E(Lk.$$.fragment,c),E(Cp.$$.fragment,c),E(yk.$$.fragment,c),E(xk.$$.fragment,c),E($k.$$.fragment,c),E(Rk.$$.fragment,c),E(b_.$$.fragment,c),E(v_.$$.fragment,c),E(Pk.$$.fragment,c),E(Bk.$$.fragment,c),E(Ik.$$.fragment,c),E(jk.$$.fragment,c),E(Y_.$$.fragment,c),E(Z_.$$.fragment,c),E(Dk.$$.fragment,c),E(Gk.$$.fragment,c),E(Ok.$$.fragment,c),E(zk.$$.fragment,c),E(C1.$$.fragment,c),E(w1.$$.fragment,c),E(Qk.$$.fragment,c),E(Wk.$$.fragment,c),E(Uk.$$.fragment,c),E(Jk.$$.fragment,c),E(y1.$$.fragment,c),E(Yk.$$.fragment,c),E(Kb.$$.fragment,c),E(Zk.$$.fragment,c),E(Kk.$$.fragment,c),E(oS.$$.fragment,c),E(ov.$$.fragment,c),E(rS.$$.fragment,c),E(Zv.$$.fragment,c),E(tS.$$.fragment,c),E(aS.$$.fragment,c),E(sS.$$.fragment,c),E(eF.$$.fragment,c),E(lS.$$.fragment,c),E(zF.$$.fragment,c),E(iS.$$.fragment,c),E(dS.$$.fragment,c),E(cS.$$.fragment,c),E(WF.$$.fragment,c),E(fS.$$.fragment,c),E(YF.$$.fragment,c),E(hS.$$.fragment,c),E(uS.$$.fragment,c),E(_S.$$.fragment,c),E(KF.$$.fragment,c),E(bS.$$.fragment,c),E(GT.$$.fragment,c),E(vS.$$.fragment,c),E(FS.$$.fragment,c),E(MS.$$.fragment,c),E(VT.$$.fragment,c),E(ES.$$.fragment,c),E(cM.$$.fragment,c),E(CS.$$.fragment,c),E(wS.$$.fragment,c),E(LS.$$.fragment,c),E(gM.$$.fragment,c),E(yS.$$.fragment,c),E(bE.$$.fragment,c),E(xS.$$.fragment,c),E($S.$$.fragment,c),E(SS.$$.fragment,c),E(FE.$$.fragment,c),E(RS.$$.fragment,c),E(o4.$$.fragment,c),E(PS.$$.fragment,c),E(BS.$$.fragment,c),E(NS.$$.fragment,c),E(t4.$$.fragment,c),E(qS.$$.fragment,c),E(f4.$$.fragment,c),E(jS.$$.fragment,c),E(DS.$$.fragment,c),E(OS.$$.fragment,c),E(h4.$$.fragment,c),E(VS.$$.fragment,c),E(aC.$$.fragment,c),E(XS.$$.fragment,c),E(zS.$$.fragment,c),E(WS.$$.fragment,c),E(sC.$$.fragment,c),E(US.$$.fragment,c),E(t3.$$.fragment,c),E(HS.$$.fragment,c),E(JS.$$.fragment,c),E(ZS.$$.fragment,c),E(n3.$$.fragment,c),E(KS.$$.fragment,c),E(i3.$$.fragment,c),E(eR.$$.fragment,c),E(oR.$$.fragment,c),E(tR.$$.fragment,c),E(m3.$$.fragment,c),E(aR.$$.fragment,c),E(u3.$$.fragment,c),E(nR.$$.fragment,c),E(sR.$$.fragment,c),E(iR.$$.fragment,c),E(_3.$$.fragment,c),E(dR.$$.fragment,c),E(P3.$$.fragment,c),E(mR.$$.fragment,c),E(cR.$$.fragment,c),E(gR.$$.fragment,c),E(I3.$$.fragment,c),E(hR.$$.fragment,c),E(j3.$$.fragment,c),E(uR.$$.fragment,c),E(pR.$$.fragment,c),E(bR.$$.fragment,c),E(G3.$$.fragment,c),E(vR.$$.fragment,c),E(X3.$$.fragment,c),E(FR.$$.fragment,c),E(TR.$$.fragment,c),E(ER.$$.fragment,c),E(Q3.$$.fragment,c),E(CR.$$.fragment,c),E(H3.$$.fragment,c),E(wR.$$.fragment,c),E(AR.$$.fragment,c),E(yR.$$.fragment,c),E(Y3.$$.fragment,c),E(xR.$$.fragment,c),E(i5.$$.fragment,c),E($R.$$.fragment,c),E(kR.$$.fragment,c),E(RR.$$.fragment,c),E(m5.$$.fragment,c),E(PR.$$.fragment,c),E(_5.$$.fragment,c),E(BR.$$.fragment,c),E(IR.$$.fragment,c),E(qR.$$.fragment,c),E(v5.$$.fragment,c),E(jR.$$.fragment,c),E(k5.$$.fragment,c),E(DR.$$.fragment,c),E(GR.$$.fragment,c),E(VR.$$.fragment,c),E(R5.$$.fragment,c),E(XR.$$.fragment,c),E(q5.$$.fragment,c),E(zR.$$.fragment,c),E(QR.$$.fragment,c),E(UR.$$.fragment,c),E(D5.$$.fragment,c),E(HR.$$.fragment,c),E(W5.$$.fragment,c),E(JR.$$.fragment,c),E(YR.$$.fragment,c),E(KR.$$.fragment,c),E(H5.$$.fragment,c),E(eP.$$.fragment,c),E(o0.$$.fragment,c),E(oP.$$.fragment,c),E(rP.$$.fragment,c),E(aP.$$.fragment,c),E(t0.$$.fragment,c),E(nP.$$.fragment,c),E(m0.$$.fragment,c),E(sP.$$.fragment,c),E(lP.$$.fragment,c),E(dP.$$.fragment,c),E(f0.$$.fragment,c),E(mP.$$.fragment,c),E(u0.$$.fragment,c),E(cP.$$.fragment,c),E(fP.$$.fragment,c),E(hP.$$.fragment,c),E(_0.$$.fragment,c),E(uP.$$.fragment,c),E(C0.$$.fragment,c),E(pP.$$.fragment,c),E(_P.$$.fragment,c),E(vP.$$.fragment,c),E(A0.$$.fragment,c),E(FP.$$.fragment,c),E(x0.$$.fragment,c),E(TP.$$.fragment,c),E(MP.$$.fragment,c),E(CP.$$.fragment,c),E(k0.$$.fragment,c),E(wP.$$.fragment,c),E(P0.$$.fragment,c),E(AP.$$.fragment,c),E(LP.$$.fragment,c),E(xP.$$.fragment,c),E(I0.$$.fragment,c),E($P.$$.fragment,c),E(Dw.$$.fragment,c),E(kP.$$.fragment,c),E(SP.$$.fragment,c),E(PP.$$.fragment,c),E(Ow.$$.fragment,c),E(BP.$$.fragment,c),E(fA.$$.fragment,c),E(IP.$$.fragment,c),E(NP.$$.fragment,c),E(jP.$$.fragment,c),E(hA.$$.fragment,c),E(DP.$$.fragment,c),E(xA.$$.fragment,c),E(GP.$$.fragment,c),E(OP.$$.fragment,c),E(XP.$$.fragment,c),E(kA.$$.fragment,c),E(zP.$$.fragment,c),E(GA.$$.fragment,c),E(QP.$$.fragment,c),E(WP.$$.fragment,c),E(HP.$$.fragment,c),E(VA.$$.fragment,c),E(JP.$$.fragment,c),E(WA.$$.fragment,c),E(YP.$$.fragment,c),E(ZP.$$.fragment,c),E(eB.$$.fragment,c),E(HA.$$.fragment,c),E(oB.$$.fragment,c),E(_6.$$.fragment,c),E(rB.$$.fragment,c),E(tB.$$.fragment,c),E(nB.$$.fragment,c),E(v6.$$.fragment,c),E(sB.$$.fragment,c),E($6.$$.fragment,c),E(lB.$$.fragment,c),E(iB.$$.fragment,c),E(mB.$$.fragment,c),E(S6.$$.fragment,c),E(cB.$$.fragment,c),E(l7.$$.fragment,c),E(fB.$$.fragment,c),E(gB.$$.fragment,c),E(uB.$$.fragment,c),E(d7.$$.fragment,c),E(pB.$$.fragment,c),E(L7.$$.fragment,c),E(_B.$$.fragment,c),E(bB.$$.fragment,c),E(FB.$$.fragment,c),E(x7.$$.fragment,c),E(TB.$$.fragment,c),E(S7.$$.fragment,c),E(EB.$$.fragment,c),E(CB.$$.fragment,c),E(AB.$$.fragment,c),E(P7.$$.fragment,c),E(LB.$$.fragment,c),E(I7.$$.fragment,c),E(yB.$$.fragment,c),E(xB.$$.fragment,c),E(kB.$$.fragment,c),E(q7.$$.fragment,c),E(SB.$$.fragment,c),E(D7.$$.fragment,c),E(RB.$$.fragment,c),E(PB.$$.fragment,c),E(IB.$$.fragment,c),E(O7.$$.fragment,c),E(NB.$$.fragment,c),E(c8.$$.fragment,c),E(qB.$$.fragment,c),E(jB.$$.fragment,c),E(GB.$$.fragment,c),E(g8.$$.fragment,c),E(OB.$$.fragment,c),E(B8.$$.fragment,c),E(VB.$$.fragment,c),E(XB.$$.fragment,c),E(QB.$$.fragment,c),E(N8.$$.fragment,c),E(WB.$$.fragment,c),E(j8.$$.fragment,c),E(UB.$$.fragment,c),E(HB.$$.fragment,c),E(YB.$$.fragment,c),E(G8.$$.fragment,c),E(ZB.$$.fragment,c),E(X8.$$.fragment,c),E(eI.$$.fragment,c),E(oI.$$.fragment,c),E(tI.$$.fragment,c),E(Q8.$$.fragment,c),E(aI.$$.fragment,c),E(FL.$$.fragment,c),E(nI.$$.fragment,c),E(sI.$$.fragment,c),E(iI.$$.fragment,c),E(ML.$$.fragment,c),E(dI.$$.fragment,c),E(RL.$$.fragment,c),E(mI.$$.fragment,c),E(cI.$$.fragment,c),E(gI.$$.fragment,c),E(BL.$$.fragment,c),E(hI.$$.fragment,c),E(HL.$$.fragment,c),E(uI.$$.fragment,c),E(pI.$$.fragment,c),E(bI.$$.fragment,c),E(YL.$$.fragment,c),E(vI.$$.fragment,c),E(iy.$$.fragment,c),E(FI.$$.fragment,c),E(TI.$$.fragment,c),E(EI.$$.fragment,c),E(my.$$.fragment,c),E(CI.$$.fragment,c),E(Ty.$$.fragment,c),E(wI.$$.fragment,c),E(AI.$$.fragment,c),E(yI.$$.fragment,c),E(Ey.$$.fragment,c),E(xI.$$.fragment,c),E(Py.$$.fragment,c),E($I.$$.fragment,c),E(kI.$$.fragment,c),E(RI.$$.fragment,c),E(Iy.$$.fragment,c),E(PI.$$.fragment,c),E(Wy.$$.fragment,c),E(BI.$$.fragment,c),E(II.$$.fragment,c),E(qI.$$.fragment,c),E(Hy.$$.fragment,c),E(jI.$$.fragment,c),E(a9.$$.fragment,c),E(DI.$$.fragment,c),E(GI.$$.fragment,c),E(VI.$$.fragment,c),E(s9.$$.fragment,c),E(XI.$$.fragment,c),E(u9.$$.fragment,c),E(zI.$$.fragment,c),E(QI.$$.fragment,c),E(UI.$$.fragment,c),E(_9.$$.fragment,c),E(HI.$$.fragment,c),E(v9.$$.fragment,c),E(JI.$$.fragment,c),E(YI.$$.fragment,c),E(KI.$$.fragment,c),E(T9.$$.fragment,c),E(eN.$$.fragment,c),E(C9.$$.fragment,c),E(rN.$$.fragment,c),E(tN.$$.fragment,c),E(nN.$$.fragment,c),E(A9.$$.fragment,c),E(sN.$$.fragment,c),E(y9.$$.fragment,c),Wdo=!0)},o(c){C(m.$$.fragment,c),C(sn.$$.fragment,c),C(uk.$$.fragment,c),C(pk.$$.fragment,c),C(ng.$$.fragment,c),C(_k.$$.fragment,c),C(bk.$$.fragment,c),C(Tk.$$.fragment,c),C(Nu.$$.fragment,c),C(Mk.$$.fragment,c),C(Ek.$$.fragment,c),C(Ck.$$.fragment,c),C(Lk.$$.fragment,c),C(Cp.$$.fragment,c),C(yk.$$.fragment,c),C(xk.$$.fragment,c),C($k.$$.fragment,c),C(Rk.$$.fragment,c),C(b_.$$.fragment,c),C(v_.$$.fragment,c),C(Pk.$$.fragment,c),C(Bk.$$.fragment,c),C(Ik.$$.fragment,c),C(jk.$$.fragment,c),C(Y_.$$.fragment,c),C(Z_.$$.fragment,c),C(Dk.$$.fragment,c),C(Gk.$$.fragment,c),C(Ok.$$.fragment,c),C(zk.$$.fragment,c),C(C1.$$.fragment,c),C(w1.$$.fragment,c),C(Qk.$$.fragment,c),C(Wk.$$.fragment,c),C(Uk.$$.fragment,c),C(Jk.$$.fragment,c),C(y1.$$.fragment,c),C(Yk.$$.fragment,c),C(Kb.$$.fragment,c),C(Zk.$$.fragment,c),C(Kk.$$.fragment,c),C(oS.$$.fragment,c),C(ov.$$.fragment,c),C(rS.$$.fragment,c),C(Zv.$$.fragment,c),C(tS.$$.fragment,c),C(aS.$$.fragment,c),C(sS.$$.fragment,c),C(eF.$$.fragment,c),C(lS.$$.fragment,c),C(zF.$$.fragment,c),C(iS.$$.fragment,c),C(dS.$$.fragment,c),C(cS.$$.fragment,c),C(WF.$$.fragment,c),C(fS.$$.fragment,c),C(YF.$$.fragment,c),C(hS.$$.fragment,c),C(uS.$$.fragment,c),C(_S.$$.fragment,c),C(KF.$$.fragment,c),C(bS.$$.fragment,c),C(GT.$$.fragment,c),C(vS.$$.fragment,c),C(FS.$$.fragment,c),C(MS.$$.fragment,c),C(VT.$$.fragment,c),C(ES.$$.fragment,c),C(cM.$$.fragment,c),C(CS.$$.fragment,c),C(wS.$$.fragment,c),C(LS.$$.fragment,c),C(gM.$$.fragment,c),C(yS.$$.fragment,c),C(bE.$$.fragment,c),C(xS.$$.fragment,c),C($S.$$.fragment,c),C(SS.$$.fragment,c),C(FE.$$.fragment,c),C(RS.$$.fragment,c),C(o4.$$.fragment,c),C(PS.$$.fragment,c),C(BS.$$.fragment,c),C(NS.$$.fragment,c),C(t4.$$.fragment,c),C(qS.$$.fragment,c),C(f4.$$.fragment,c),C(jS.$$.fragment,c),C(DS.$$.fragment,c),C(OS.$$.fragment,c),C(h4.$$.fragment,c),C(VS.$$.fragment,c),C(aC.$$.fragment,c),C(XS.$$.fragment,c),C(zS.$$.fragment,c),C(WS.$$.fragment,c),C(sC.$$.fragment,c),C(US.$$.fragment,c),C(t3.$$.fragment,c),C(HS.$$.fragment,c),C(JS.$$.fragment,c),C(ZS.$$.fragment,c),C(n3.$$.fragment,c),C(KS.$$.fragment,c),C(i3.$$.fragment,c),C(eR.$$.fragment,c),C(oR.$$.fragment,c),C(tR.$$.fragment,c),C(m3.$$.fragment,c),C(aR.$$.fragment,c),C(u3.$$.fragment,c),C(nR.$$.fragment,c),C(sR.$$.fragment,c),C(iR.$$.fragment,c),C(_3.$$.fragment,c),C(dR.$$.fragment,c),C(P3.$$.fragment,c),C(mR.$$.fragment,c),C(cR.$$.fragment,c),C(gR.$$.fragment,c),C(I3.$$.fragment,c),C(hR.$$.fragment,c),C(j3.$$.fragment,c),C(uR.$$.fragment,c),C(pR.$$.fragment,c),C(bR.$$.fragment,c),C(G3.$$.fragment,c),C(vR.$$.fragment,c),C(X3.$$.fragment,c),C(FR.$$.fragment,c),C(TR.$$.fragment,c),C(ER.$$.fragment,c),C(Q3.$$.fragment,c),C(CR.$$.fragment,c),C(H3.$$.fragment,c),C(wR.$$.fragment,c),C(AR.$$.fragment,c),C(yR.$$.fragment,c),C(Y3.$$.fragment,c),C(xR.$$.fragment,c),C(i5.$$.fragment,c),C($R.$$.fragment,c),C(kR.$$.fragment,c),C(RR.$$.fragment,c),C(m5.$$.fragment,c),C(PR.$$.fragment,c),C(_5.$$.fragment,c),C(BR.$$.fragment,c),C(IR.$$.fragment,c),C(qR.$$.fragment,c),C(v5.$$.fragment,c),C(jR.$$.fragment,c),C(k5.$$.fragment,c),C(DR.$$.fragment,c),C(GR.$$.fragment,c),C(VR.$$.fragment,c),C(R5.$$.fragment,c),C(XR.$$.fragment,c),C(q5.$$.fragment,c),C(zR.$$.fragment,c),C(QR.$$.fragment,c),C(UR.$$.fragment,c),C(D5.$$.fragment,c),C(HR.$$.fragment,c),C(W5.$$.fragment,c),C(JR.$$.fragment,c),C(YR.$$.fragment,c),C(KR.$$.fragment,c),C(H5.$$.fragment,c),C(eP.$$.fragment,c),C(o0.$$.fragment,c),C(oP.$$.fragment,c),C(rP.$$.fragment,c),C(aP.$$.fragment,c),C(t0.$$.fragment,c),C(nP.$$.fragment,c),C(m0.$$.fragment,c),C(sP.$$.fragment,c),C(lP.$$.fragment,c),C(dP.$$.fragment,c),C(f0.$$.fragment,c),C(mP.$$.fragment,c),C(u0.$$.fragment,c),C(cP.$$.fragment,c),C(fP.$$.fragment,c),C(hP.$$.fragment,c),C(_0.$$.fragment,c),C(uP.$$.fragment,c),C(C0.$$.fragment,c),C(pP.$$.fragment,c),C(_P.$$.fragment,c),C(vP.$$.fragment,c),C(A0.$$.fragment,c),C(FP.$$.fragment,c),C(x0.$$.fragment,c),C(TP.$$.fragment,c),C(MP.$$.fragment,c),C(CP.$$.fragment,c),C(k0.$$.fragment,c),C(wP.$$.fragment,c),C(P0.$$.fragment,c),C(AP.$$.fragment,c),C(LP.$$.fragment,c),C(xP.$$.fragment,c),C(I0.$$.fragment,c),C($P.$$.fragment,c),C(Dw.$$.fragment,c),C(kP.$$.fragment,c),C(SP.$$.fragment,c),C(PP.$$.fragment,c),C(Ow.$$.fragment,c),C(BP.$$.fragment,c),C(fA.$$.fragment,c),C(IP.$$.fragment,c),C(NP.$$.fragment,c),C(jP.$$.fragment,c),C(hA.$$.fragment,c),C(DP.$$.fragment,c),C(xA.$$.fragment,c),C(GP.$$.fragment,c),C(OP.$$.fragment,c),C(XP.$$.fragment,c),C(kA.$$.fragment,c),C(zP.$$.fragment,c),C(GA.$$.fragment,c),C(QP.$$.fragment,c),C(WP.$$.fragment,c),C(HP.$$.fragment,c),C(VA.$$.fragment,c),C(JP.$$.fragment,c),C(WA.$$.fragment,c),C(YP.$$.fragment,c),C(ZP.$$.fragment,c),C(eB.$$.fragment,c),C(HA.$$.fragment,c),C(oB.$$.fragment,c),C(_6.$$.fragment,c),C(rB.$$.fragment,c),C(tB.$$.fragment,c),C(nB.$$.fragment,c),C(v6.$$.fragment,c),C(sB.$$.fragment,c),C($6.$$.fragment,c),C(lB.$$.fragment,c),C(iB.$$.fragment,c),C(mB.$$.fragment,c),C(S6.$$.fragment,c),C(cB.$$.fragment,c),C(l7.$$.fragment,c),C(fB.$$.fragment,c),C(gB.$$.fragment,c),C(uB.$$.fragment,c),C(d7.$$.fragment,c),C(pB.$$.fragment,c),C(L7.$$.fragment,c),C(_B.$$.fragment,c),C(bB.$$.fragment,c),C(FB.$$.fragment,c),C(x7.$$.fragment,c),C(TB.$$.fragment,c),C(S7.$$.fragment,c),C(EB.$$.fragment,c),C(CB.$$.fragment,c),C(AB.$$.fragment,c),C(P7.$$.fragment,c),C(LB.$$.fragment,c),C(I7.$$.fragment,c),C(yB.$$.fragment,c),C(xB.$$.fragment,c),C(kB.$$.fragment,c),C(q7.$$.fragment,c),C(SB.$$.fragment,c),C(D7.$$.fragment,c),C(RB.$$.fragment,c),C(PB.$$.fragment,c),C(IB.$$.fragment,c),C(O7.$$.fragment,c),C(NB.$$.fragment,c),C(c8.$$.fragment,c),C(qB.$$.fragment,c),C(jB.$$.fragment,c),C(GB.$$.fragment,c),C(g8.$$.fragment,c),C(OB.$$.fragment,c),C(B8.$$.fragment,c),C(VB.$$.fragment,c),C(XB.$$.fragment,c),C(QB.$$.fragment,c),C(N8.$$.fragment,c),C(WB.$$.fragment,c),C(j8.$$.fragment,c),C(UB.$$.fragment,c),C(HB.$$.fragment,c),C(YB.$$.fragment,c),C(G8.$$.fragment,c),C(ZB.$$.fragment,c),C(X8.$$.fragment,c),C(eI.$$.fragment,c),C(oI.$$.fragment,c),C(tI.$$.fragment,c),C(Q8.$$.fragment,c),C(aI.$$.fragment,c),C(FL.$$.fragment,c),C(nI.$$.fragment,c),C(sI.$$.fragment,c),C(iI.$$.fragment,c),C(ML.$$.fragment,c),C(dI.$$.fragment,c),C(RL.$$.fragment,c),C(mI.$$.fragment,c),C(cI.$$.fragment,c),C(gI.$$.fragment,c),C(BL.$$.fragment,c),C(hI.$$.fragment,c),C(HL.$$.fragment,c),C(uI.$$.fragment,c),C(pI.$$.fragment,c),C(bI.$$.fragment,c),C(YL.$$.fragment,c),C(vI.$$.fragment,c),C(iy.$$.fragment,c),C(FI.$$.fragment,c),C(TI.$$.fragment,c),C(EI.$$.fragment,c),C(my.$$.fragment,c),C(CI.$$.fragment,c),C(Ty.$$.fragment,c),C(wI.$$.fragment,c),C(AI.$$.fragment,c),C(yI.$$.fragment,c),C(Ey.$$.fragment,c),C(xI.$$.fragment,c),C(Py.$$.fragment,c),C($I.$$.fragment,c),C(kI.$$.fragment,c),C(RI.$$.fragment,c),C(Iy.$$.fragment,c),C(PI.$$.fragment,c),C(Wy.$$.fragment,c),C(BI.$$.fragment,c),C(II.$$.fragment,c),C(qI.$$.fragment,c),C(Hy.$$.fragment,c),C(jI.$$.fragment,c),C(a9.$$.fragment,c),C(DI.$$.fragment,c),C(GI.$$.fragment,c),C(VI.$$.fragment,c),C(s9.$$.fragment,c),C(XI.$$.fragment,c),C(u9.$$.fragment,c),C(zI.$$.fragment,c),C(QI.$$.fragment,c),C(UI.$$.fragment,c),C(_9.$$.fragment,c),C(HI.$$.fragment,c),C(v9.$$.fragment,c),C(JI.$$.fragment,c),C(YI.$$.fragment,c),C(KI.$$.fragment,c),C(T9.$$.fragment,c),C(eN.$$.fragment,c),C(C9.$$.fragment,c),C(rN.$$.fragment,c),C(tN.$$.fragment,c),C(nN.$$.fragment,c),C(A9.$$.fragment,c),C(sN.$$.fragment,c),C(y9.$$.fragment,c),Wdo=!1},d(c){t(g),c&&t(v),c&&t(u),w(m),c&&t(eg),c&&t(wt),c&&t(Qe),c&&t(Ze),c&&t(rg),w(sn,c),c&&t(Ke),c&&t(ye),c&&t(Po),c&&t(ln),c&&t(ylo),c&&t(Rd),w(uk),c&&t(xlo),c&&t(Fs),c&&t($lo),w(pk,c),c&&t(klo),c&&t(Dq),c&&t(Slo),w(ng,c),c&&t(Rlo),c&&t(Pd),w(_k),c&&t(Plo),c&&t(Bo),w(bk),w(Tk),w(Nu),w(Mk),c&&t(Blo),c&&t(Id),w(Ek),c&&t(Ilo),c&&t(Io),w(Ck),w(Lk),w(Cp),w(yk),c&&t(Nlo),c&&t(Nd),w(xk),c&&t(qlo),c&&t(No),w($k),w(Rk),w(b_),w(v_),w(Pk),c&&t(jlo),c&&t(qd),w(Bk),c&&t(Dlo),c&&t(qo),w(Ik),w(jk),w(Y_),w(Z_),w(Dk),c&&t(Glo),c&&t(jd),w(Gk),c&&t(Olo),c&&t(jo),w(Ok),w(zk),w(C1),w(w1),w(Qk),c&&t(Vlo),c&&t(Gd),w(Wk),c&&t(Xlo),c&&t(Do),w(Uk),w(Jk),w(y1),w(Yk),w(Kb),c&&t(zlo),c&&t(Xd),w(Zk),c&&t(Qlo),c&&t(Go),w(Kk),w(oS),w(ov),w(rS),w(Zv),c&&t(Wlo),c&&t(Wd),w(tS),c&&t(Ulo),c&&t(Oo),w(aS),w(sS),w(eF),w(lS),w(zF),c&&t(Hlo),c&&t(Jd),w(iS),c&&t(Jlo),c&&t(Vo),w(dS),w(cS),w(WF),w(fS),w(YF),c&&t(Ylo),c&&t(Kd),w(hS),c&&t(Zlo),c&&t(Xo),w(uS),w(_S),w(KF),w(bS),w(GT),c&&t(Klo),c&&t(rm),w(vS),c&&t(eio),c&&t(zo),w(FS),w(MS),w(VT),w(ES),w(cM),c&&t(oio),c&&t(nm),w(CS),c&&t(rio),c&&t(Qo),w(wS),w(LS),w(gM),w(yS),w(bE),c&&t(tio),c&&t(im),w(xS),c&&t(aio),c&&t(Wo),w($S),w(SS),w(FE),w(RS),w(o4),c&&t(nio),c&&t(cm),w(PS),c&&t(sio),c&&t(Uo),w(BS),w(NS),w(t4),w(qS),w(f4),c&&t(lio),c&&t(hm),w(jS),c&&t(iio),c&&t(Ho),w(DS),w(OS),w(h4),w(VS),w(aC),c&&t(dio),c&&t(_m),w(XS),c&&t(mio),c&&t(Jo),w(zS),w(WS),w(sC),w(US),w(t3),c&&t(cio),c&&t(Fm),w(HS),c&&t(fio),c&&t(Yo),w(JS),w(ZS),w(n3),w(KS),w(i3),c&&t(gio),c&&t(Em),w(eR),c&&t(hio),c&&t(Zo),w(oR),w(tR),w(m3),w(aR),w(u3),c&&t(uio),c&&t(Lm),w(nR),c&&t(pio),c&&t(Ko),w(sR),w(iR),w(_3),w(dR),w(P3),c&&t(_io),c&&t($m),w(mR),c&&t(bio),c&&t(er),w(cR),w(gR),w(I3),w(hR),w(j3),c&&t(vio),c&&t(Rm),w(uR),c&&t(Fio),c&&t(or),w(pR),w(bR),w(G3),w(vR),w(X3),c&&t(Tio),c&&t(Im),w(FR),c&&t(Mio),c&&t(rr),w(TR),w(ER),w(Q3),w(CR),w(H3),c&&t(Eio),c&&t(jm),w(wR),c&&t(Cio),c&&t(tr),w(AR),w(yR),w(Y3),w(xR),w(i5),c&&t(wio),c&&t(Om),w($R),c&&t(Aio),c&&t(ar),w(kR),w(RR),w(m5),w(PR),w(_5),c&&t(Lio),c&&t(zm),w(BR),c&&t(yio),c&&t(nr),w(IR),w(qR),w(v5),w(jR),w(k5),c&&t(xio),c&&t(Um),w(DR),c&&t($io),c&&t(sr),w(GR),w(VR),w(R5),w(XR),w(q5),c&&t(kio),c&&t(Zm),w(zR),c&&t(Sio),c&&t(lr),w(QR),w(UR),w(D5),w(HR),w(W5),c&&t(Rio),c&&t(oc),w(JR),c&&t(Pio),c&&t(ir),w(YR),w(KR),w(H5),w(eP),w(o0),c&&t(Bio),c&&t(ac),w(oP),c&&t(Iio),c&&t(dr),w(rP),w(aP),w(t0),w(nP),w(m0),c&&t(Nio),c&&t(lc),w(sP),c&&t(qio),c&&t(mr),w(lP),w(dP),w(f0),w(mP),w(u0),c&&t(jio),c&&t(mc),w(cP),c&&t(Dio),c&&t(cr),w(fP),w(hP),w(_0),w(uP),w(C0),c&&t(Gio),c&&t(gc),w(pP),c&&t(Oio),c&&t(fr),w(_P),w(vP),w(A0),w(FP),w(x0),c&&t(Vio),c&&t(pc),w(TP),c&&t(Xio),c&&t(gr),w(MP),w(CP),w(k0),w(wP),w(P0),c&&t(zio),c&&t(vc),w(AP),c&&t(Qio),c&&t(hr),w(LP),w(xP),w(I0),w($P),w(Dw),c&&t(Wio),c&&t(Mc),w(kP),c&&t(Uio),c&&t(ur),w(SP),w(PP),w(Ow),w(BP),w(fA),c&&t(Hio),c&&t(wc),w(IP),c&&t(Jio),c&&t(pr),w(NP),w(jP),w(hA),w(DP),w(xA),c&&t(Yio),c&&t(yc),w(GP),c&&t(Zio),c&&t(_r),w(OP),w(XP),w(kA),w(zP),w(GA),c&&t(Kio),c&&t(kc),w(QP),c&&t(edo),c&&t(br),w(WP),w(HP),w(VA),w(JP),w(WA),c&&t(odo),c&&t(Bc),w(YP),c&&t(rdo),c&&t(vr),w(ZP),w(eB),w(HA),w(oB),w(_6),c&&t(tdo),c&&t(qc),w(rB),c&&t(ado),c&&t(Fr),w(tB),w(nB),w(v6),w(sB),w($6),c&&t(ndo),c&&t(Gc),w(lB),c&&t(sdo),c&&t(Tr),w(iB),w(mB),w(S6),w(cB),w(l7),c&&t(ldo),c&&t(Xc),w(fB),c&&t(ido),c&&t(Mr),w(gB),w(uB),w(d7),w(pB),w(L7),c&&t(ddo),c&&t(Wc),w(_B),c&&t(mdo),c&&t(Er),w(bB),w(FB),w(x7),w(TB),w(S7),c&&t(cdo),c&&t(Jc),w(EB),c&&t(fdo),c&&t(Cr),w(CB),w(AB),w(P7),w(LB),w(I7),c&&t(gdo),c&&t(Kc),w(yB),c&&t(hdo),c&&t(wr),w(xB),w(kB),w(q7),w(SB),w(D7),c&&t(udo),c&&t(rf),w(RB),c&&t(pdo),c&&t(Ar),w(PB),w(IB),w(O7),w(NB),w(c8),c&&t(_do),c&&t(nf),w(qB),c&&t(bdo),c&&t(Lr),w(jB),w(GB),w(g8),w(OB),w(B8),c&&t(vdo),c&&t(df),w(VB),c&&t(Fdo),c&&t(yr),w(XB),w(QB),w(N8),w(WB),w(j8),c&&t(Tdo),c&&t(ff),w(UB),c&&t(Mdo),c&&t(xr),w(HB),w(YB),w(G8),w(ZB),w(X8),c&&t(Edo),c&&t(uf),w(eI),c&&t(Cdo),c&&t($r),w(oI),w(tI),w(Q8),w(aI),w(FL),c&&t(wdo),c&&t(bf),w(nI),c&&t(Ado),c&&t(kr),w(sI),w(iI),w(ML),w(dI),w(RL),c&&t(Ldo),c&&t(Tf),w(mI),c&&t(ydo),c&&t(Sr),w(cI),w(gI),w(BL),w(hI),w(HL),c&&t(xdo),c&&t(Cf),w(uI),c&&t($do),c&&t(Rr),w(pI),w(bI),w(YL),w(vI),w(iy),c&&t(kdo),c&&t(Lf),w(FI),c&&t(Sdo),c&&t(Pr),w(TI),w(EI),w(my),w(CI),w(Ty),c&&t(Rdo),c&&t($f),w(wI),c&&t(Pdo),c&&t(Br),w(AI),w(yI),w(Ey),w(xI),w(Py),c&&t(Bdo),c&&t(Rf),w($I),c&&t(Ido),c&&t(Ir),w(kI),w(RI),w(Iy),w(PI),w(Wy),c&&t(Ndo),c&&t(If),w(BI),c&&t(qdo),c&&t(Nr),w(II),w(qI),w(Hy),w(jI),w(a9),c&&t(jdo),c&&t(jf),w(DI),c&&t(Ddo),c&&t(qr),w(GI),w(VI),w(s9),w(XI),w(u9),c&&t(Gdo),c&&t(Of),w(zI),c&&t(Odo),c&&t(jr),w(QI),w(UI),w(_9),w(HI),w(v9),c&&t(Vdo),c&&t(zf),w(JI),c&&t(Xdo),c&&t(Dr),w(YI),w(KI),w(T9),w(eN),w(C9),c&&t(zdo),c&&t(Uf),w(rN),c&&t(Qdo),c&&t(Gr),w(tN),w(nN),w(A9),w(sN),w(y9)}}}const jka={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoImageProcessor",title:"AutoImageProcessor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForDepthEstimation",title:"AutoModelForDepthEstimation"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForDocumentQuestionAnswering",title:"AutoModelForDocumentQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVideoClassification",title:"AutoModelForVideoClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.AutoModelForZeroShotObjectDetection",title:"AutoModelForZeroShotObjectDetection"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForSemanticSegmentation",title:"TFAutoModelForSemanticSegmentation"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForDocumentQuestionAnswering",title:"TFAutoModelForDocumentQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function Dka($){return Cxa(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Wka extends Fxa{constructor(g){super();Txa(this,g,Dka,qka,Mxa,{})}}export{Wka as default,jka as metadata};
