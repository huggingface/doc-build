import{S as P3a,i as B3a,s as I3a,e as a,k as l,w as F,t as o,M as N3a,c as n,d as t,m as i,a as s,x as T,h as r,b as m,G as e,g as b,y as M,q as E,o as C,B as w,v as q3a,L as q}from"../../chunks/vendor-hf-doc-builder.js";import{T as JAt}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as B}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as oe}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as N}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function D3a($){let g,v,u,f,p,d,h,$o,bd,zf,Tt,vd,Fd,s$,Qf,Xe,He,Td,ms,l$,cs,fs,i$,Md,gs,d$,Ed,Wf,on;return{c(){g=a("p"),v=o("If your "),u=a("code"),f=o("NewModelConfig"),p=o(" is a subclass of "),d=a("code"),h=o("~transformer.PretrainedConfig"),$o=o(`, make sure its
`),bd=a("code"),zf=o("model_type"),Tt=o(" attribute is set to the same key you use when registering the config (here "),vd=a("code"),Fd=o('"new-model"'),s$=o(")."),Qf=l(),Xe=a("p"),He=o("Likewise, if your "),Td=a("code"),ms=o("NewModel"),l$=o(" is a subclass of "),cs=a("a"),fs=o("PreTrainedModel"),i$=o(`, make sure its
`),Md=a("code"),gs=o("config_class"),d$=o(` attribute is set to the same class you use when registering the model (here
`),Ed=a("code"),Wf=o("NewModelConfig"),on=o(")."),this.h()},l(Je){g=n(Je,"P",{});var Ae=s(g);v=r(Ae,"If your "),u=n(Ae,"CODE",{});var EN=s(u);f=r(EN,"NewModelConfig"),EN.forEach(t),p=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var Cd=s(d);h=r(Cd,"~transformer.PretrainedConfig"),Cd.forEach(t),$o=r(Ae,`, make sure its
`),bd=n(Ae,"CODE",{});var CN=s(bd);zf=r(CN,"model_type"),CN.forEach(t),Tt=r(Ae," attribute is set to the same key you use when registering the config (here "),vd=n(Ae,"CODE",{});var wN=s(vd);Fd=r(wN,'"new-model"'),wN.forEach(t),s$=r(Ae,")."),Ae.forEach(t),Qf=i(Je),Xe=n(Je,"P",{});var ko=s(Xe);He=r(ko,"Likewise, if your "),Td=n(ko,"CODE",{});var rn=s(Td);ms=r(rn,"NewModel"),rn.forEach(t),l$=r(ko," is a subclass of "),cs=n(ko,"A",{href:!0});var AN=s(cs);fs=r(AN,"PreTrainedModel"),AN.forEach(t),i$=r(ko,`, make sure its
`),Md=n(ko,"CODE",{});var Uf=s(Md);gs=r(Uf,"config_class"),Uf.forEach(t),d$=r(ko,` attribute is set to the same class you use when registering the model (here
`),Ed=n(ko,"CODE",{});var LN=s(Ed);Wf=r(LN,"NewModelConfig"),LN.forEach(t),on=r(ko,")."),ko.forEach(t),this.h()},h(){m(cs,"href","/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel")},m(Je,Ae){b(Je,g,Ae),e(g,v),e(g,u),e(u,f),e(g,p),e(g,d),e(d,h),e(g,$o),e(g,bd),e(bd,zf),e(g,Tt),e(g,vd),e(vd,Fd),e(g,s$),b(Je,Qf,Ae),b(Je,Xe,Ae),e(Xe,He),e(Xe,Td),e(Td,ms),e(Xe,l$),e(Xe,cs),e(cs,fs),e(Xe,i$),e(Xe,Md),e(Md,gs),e(Xe,d$),e(Xe,Ed),e(Ed,Wf),e(Xe,on)},d(Je){Je&&t(g),Je&&t(Qf),Je&&t(Xe)}}}function j3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function G3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function O3a($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var $o=s(u);f=r($o,"use_auth_token=True"),$o.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(d){d&&t(g)}}}function V3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function X3a($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var $o=s(u);f=r($o,"use_auth_token=True"),$o.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(d){d&&t(g)}}}function z3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Q3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function W3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function U3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function H3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function J3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Y3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Z3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDepthEstimation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForDepthEstimation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDepthEstimation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function K3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDepthEstimation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDepthEstimation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForDepthEstimation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForDepthEstimation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDepthEstimation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function e5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function o5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function r5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function t5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function a5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function n5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function s5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function l5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function i5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function d5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function m5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function c5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function f5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function g5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function h5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function u5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function p5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = AutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function _5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/layoutlm_tf_model_config.json")
model = AutoModelForDocumentQuestionAnswering.from_pretrained(
    "./tf_model/layoutlm_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/layoutlm_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/layoutlm_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function b5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function v5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function F5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVideoClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function T5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVideoClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function M5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function E5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function C5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function w5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function A5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function L5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function y5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function x5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function $5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function k5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function S5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function R5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function P5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function B5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function I5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function N5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function q5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function D5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function j5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function G5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function O5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function V5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function X5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function z5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Q5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForZeroShotObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function W5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForZeroShotObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function U5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function H5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function J5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Y5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Z5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function K5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function e0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function o0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function r0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function t0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSemanticSegmentation.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function a0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function n0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function s0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function l0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function i0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function d0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function m0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function c0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function f0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function g0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function h0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function u0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function p0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function _0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/layoutlm_pt_model_config.json")
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
    "./pt_model/layoutlm_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/layoutlm_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/layoutlm_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function b0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function v0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function F0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function T0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function M0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function E0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function C0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function w0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function A0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function L0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function y0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function x0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function $0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function k0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function S0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function R0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function P0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function B0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function I0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function N0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function q0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function D0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function j0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function G0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function O0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function V0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function X0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function z0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Q0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function W0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function U0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function H0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function J0a($){let g,v,u,f,p,d,h,$o,bd,zf,Tt,vd,Fd,s$,Qf,Xe,He,Td,ms,l$,cs,fs,i$,Md,gs,d$,Ed,Wf,on,Je,Ae,EN,Cd,CN,wN,ko,rn,AN,Uf,LN,hio,xto,wd,Hf,gfe,m$,uio,hfe,pio,$to,hs,_io,ufe,bio,vio,pfe,Fio,Tio,kto,c$,Sto,yN,Mio,Rto,Jf,Pto,Ad,Yf,_fe,f$,Eio,bfe,Cio,Bto,So,g$,wio,h$,Aio,xN,Lio,yio,xio,u$,$io,vfe,kio,Sio,Rio,qr,p$,Pio,Ffe,Bio,Iio,Ld,Nio,Tfe,qio,Dio,Mfe,jio,Gio,Oio,A,Zf,Efe,Vio,Xio,$N,zio,Qio,Wio,Kf,Cfe,Uio,Hio,kN,Jio,Yio,Zio,eg,wfe,Kio,edo,SN,odo,rdo,tdo,og,Afe,ado,ndo,RN,sdo,ldo,ido,rg,Lfe,ddo,mdo,PN,cdo,fdo,gdo,tg,yfe,hdo,udo,BN,pdo,_do,bdo,ag,xfe,vdo,Fdo,IN,Tdo,Mdo,Edo,ng,$fe,Cdo,wdo,NN,Ado,Ldo,ydo,sg,kfe,xdo,$do,qN,kdo,Sdo,Rdo,lg,Sfe,Pdo,Bdo,DN,Ido,Ndo,qdo,ig,Rfe,Ddo,jdo,jN,Gdo,Odo,Vdo,dg,Pfe,Xdo,zdo,GN,Qdo,Wdo,Udo,mg,Bfe,Hdo,Jdo,ON,Ydo,Zdo,Kdo,cg,Ife,emo,omo,VN,rmo,tmo,amo,fg,Nfe,nmo,smo,XN,lmo,imo,dmo,gg,qfe,mmo,cmo,zN,fmo,gmo,hmo,hg,Dfe,umo,pmo,QN,_mo,bmo,vmo,ug,jfe,Fmo,Tmo,WN,Mmo,Emo,Cmo,pg,Gfe,wmo,Amo,UN,Lmo,ymo,xmo,_g,Ofe,$mo,kmo,HN,Smo,Rmo,Pmo,bg,Vfe,Bmo,Imo,JN,Nmo,qmo,Dmo,vg,Xfe,jmo,Gmo,YN,Omo,Vmo,Xmo,Fg,zfe,zmo,Qmo,ZN,Wmo,Umo,Hmo,Tg,Qfe,Jmo,Ymo,KN,Zmo,Kmo,eco,Mg,Wfe,oco,rco,eq,tco,aco,nco,Eg,Ufe,sco,lco,oq,ico,dco,mco,Cg,Hfe,cco,fco,rq,gco,hco,uco,wg,Jfe,pco,_co,tq,bco,vco,Fco,Ag,Yfe,Tco,Mco,aq,Eco,Cco,wco,Lg,Zfe,Aco,Lco,nq,yco,xco,$co,yg,Kfe,kco,Sco,sq,Rco,Pco,Bco,xg,ege,Ico,Nco,lq,qco,Dco,jco,$g,oge,Gco,Oco,iq,Vco,Xco,zco,kg,rge,Qco,Wco,dq,Uco,Hco,Jco,Sg,tge,Yco,Zco,mq,Kco,efo,ofo,Rg,age,rfo,tfo,cq,afo,nfo,sfo,Pg,nge,lfo,ifo,fq,dfo,mfo,cfo,Bg,sge,ffo,gfo,gq,hfo,ufo,pfo,Ig,lge,_fo,bfo,hq,vfo,Ffo,Tfo,Ng,ige,Mfo,Efo,uq,Cfo,wfo,Afo,qg,dge,Lfo,yfo,pq,xfo,$fo,kfo,Dg,mge,Sfo,Rfo,_q,Pfo,Bfo,Ifo,jg,cge,Nfo,qfo,bq,Dfo,jfo,Gfo,Gg,fge,Ofo,Vfo,vq,Xfo,zfo,Qfo,Og,gge,Wfo,Ufo,Fq,Hfo,Jfo,Yfo,Vg,hge,Zfo,Kfo,Tq,ego,ogo,rgo,Xg,uge,tgo,ago,Mq,ngo,sgo,lgo,zg,pge,igo,dgo,Eq,mgo,cgo,fgo,Qg,_ge,ggo,hgo,Cq,ugo,pgo,_go,Wg,bge,bgo,vgo,wq,Fgo,Tgo,Mgo,Ug,vge,Ego,Cgo,Aq,wgo,Ago,Lgo,Hg,Fge,ygo,xgo,Lq,$go,kgo,Sgo,Jg,Tge,Rgo,Pgo,yq,Bgo,Igo,Ngo,Yg,Mge,qgo,Dgo,xq,jgo,Ggo,Ogo,Zg,Ege,Vgo,Xgo,$q,zgo,Qgo,Wgo,Kg,Cge,Ugo,Hgo,kq,Jgo,Ygo,Zgo,eh,wge,Kgo,eho,Sq,oho,rho,tho,oh,Age,aho,nho,Rq,sho,lho,iho,rh,Lge,dho,mho,Pq,cho,fho,gho,th,yge,hho,uho,Bq,pho,_ho,bho,ah,xge,vho,Fho,Iq,Tho,Mho,Eho,nh,$ge,Cho,who,Nq,Aho,Lho,yho,sh,kge,xho,$ho,qq,kho,Sho,Rho,lh,Sge,Pho,Bho,Dq,Iho,Nho,qho,ih,Rge,Dho,jho,jq,Gho,Oho,Vho,dh,Pge,Xho,zho,Gq,Qho,Who,Uho,mh,Bge,Hho,Jho,Oq,Yho,Zho,Kho,ch,Ige,euo,ouo,Vq,ruo,tuo,auo,fh,Nge,nuo,suo,Xq,luo,iuo,duo,gh,qge,muo,cuo,zq,fuo,guo,huo,hh,Dge,uuo,puo,Qq,_uo,buo,vuo,uh,jge,Fuo,Tuo,Wq,Muo,Euo,Cuo,ph,Gge,wuo,Auo,Uq,Luo,yuo,xuo,_h,Oge,$uo,kuo,Hq,Suo,Ruo,Puo,bh,Vge,Buo,Iuo,Jq,Nuo,quo,Duo,vh,Xge,juo,Guo,Yq,Ouo,Vuo,Xuo,Fh,zge,zuo,Quo,Zq,Wuo,Uuo,Huo,Th,Qge,Juo,Yuo,Kq,Zuo,Kuo,epo,Mh,Wge,opo,rpo,eD,tpo,apo,npo,Eh,Uge,spo,lpo,oD,ipo,dpo,mpo,Ch,Hge,cpo,fpo,rD,gpo,hpo,upo,wh,Jge,ppo,_po,tD,bpo,vpo,Fpo,Ah,Yge,Tpo,Mpo,aD,Epo,Cpo,wpo,Lh,Zge,Apo,Lpo,nD,ypo,xpo,$po,yh,Kge,kpo,Spo,sD,Rpo,Ppo,Bpo,xh,ehe,Ipo,Npo,lD,qpo,Dpo,jpo,$h,ohe,Gpo,Opo,iD,Vpo,Xpo,zpo,kh,rhe,Qpo,Wpo,dD,Upo,Hpo,Jpo,Sh,the,Ypo,Zpo,mD,Kpo,e_o,o_o,Rh,ahe,r_o,t_o,cD,a_o,n_o,s_o,Ph,nhe,l_o,i_o,fD,d_o,m_o,c_o,Bh,she,f_o,g_o,gD,h_o,u_o,p_o,Ih,lhe,__o,b_o,hD,v_o,F_o,T_o,Nh,ihe,M_o,E_o,uD,C_o,w_o,A_o,qh,dhe,L_o,y_o,pD,x_o,$_o,k_o,Dh,mhe,S_o,R_o,_D,P_o,B_o,I_o,jh,che,N_o,q_o,bD,D_o,j_o,G_o,Gh,fhe,O_o,V_o,vD,X_o,z_o,Q_o,Oh,ghe,W_o,U_o,FD,H_o,J_o,Y_o,Vh,hhe,Z_o,K_o,TD,e1o,o1o,r1o,Xh,uhe,t1o,a1o,MD,n1o,s1o,l1o,zh,phe,i1o,d1o,ED,m1o,c1o,f1o,Qh,_he,g1o,h1o,CD,u1o,p1o,_1o,Wh,bhe,b1o,v1o,wD,F1o,T1o,M1o,Uh,vhe,E1o,C1o,AD,w1o,A1o,L1o,Hh,Fhe,y1o,x1o,LD,$1o,k1o,S1o,Jh,The,R1o,P1o,yD,B1o,I1o,N1o,Yh,Mhe,q1o,D1o,xD,j1o,G1o,O1o,Zh,Ehe,V1o,X1o,$D,z1o,Q1o,W1o,Kh,Che,U1o,H1o,kD,J1o,Y1o,Z1o,eu,whe,K1o,e2o,SD,o2o,r2o,t2o,ou,Ahe,a2o,n2o,RD,s2o,l2o,i2o,ru,Lhe,d2o,m2o,PD,c2o,f2o,g2o,tu,yhe,h2o,u2o,BD,p2o,_2o,b2o,au,xhe,v2o,F2o,ID,T2o,M2o,E2o,nu,$he,C2o,w2o,ND,A2o,L2o,y2o,su,khe,x2o,$2o,qD,k2o,S2o,R2o,lu,She,P2o,B2o,DD,I2o,N2o,q2o,iu,Rhe,D2o,j2o,jD,G2o,O2o,V2o,du,Phe,X2o,z2o,GD,Q2o,W2o,U2o,mu,Bhe,H2o,J2o,OD,Y2o,Z2o,K2o,cu,Ihe,ebo,obo,VD,rbo,tbo,abo,fu,Nhe,nbo,sbo,XD,lbo,ibo,dbo,gu,qhe,mbo,cbo,zD,fbo,gbo,hbo,hu,Dhe,ubo,pbo,QD,_bo,bbo,vbo,uu,jhe,Fbo,Tbo,WD,Mbo,Ebo,Cbo,pu,Ghe,wbo,Abo,UD,Lbo,ybo,xbo,_u,Ohe,$bo,kbo,HD,Sbo,Rbo,Pbo,bu,Vhe,Bbo,Ibo,JD,Nbo,qbo,Dbo,vu,Xhe,jbo,Gbo,YD,Obo,Vbo,Xbo,Fu,zhe,zbo,Qbo,ZD,Wbo,Ubo,Hbo,Tu,Qhe,Jbo,Ybo,KD,Zbo,Kbo,evo,Mu,Whe,ovo,rvo,ej,tvo,avo,nvo,Eu,Uhe,svo,lvo,oj,ivo,dvo,mvo,Cu,Hhe,cvo,fvo,rj,gvo,hvo,uvo,wu,pvo,Au,_$,_vo,Jhe,bvo,Ito,yd,Lu,Yhe,b$,vvo,Zhe,Fvo,Nto,Ro,v$,Tvo,F$,Mvo,tj,Evo,Cvo,wvo,T$,Avo,Khe,Lvo,yvo,xvo,Dr,M$,$vo,eue,kvo,Svo,tn,Rvo,oue,Pvo,Bvo,rue,Ivo,Nvo,tue,qvo,Dvo,jvo,k,us,aue,Gvo,Ovo,aj,Vvo,Xvo,nj,zvo,Qvo,Wvo,ps,nue,Uvo,Hvo,sj,Jvo,Yvo,lj,Zvo,Kvo,eFo,_s,sue,oFo,rFo,ij,tFo,aFo,dj,nFo,sFo,lFo,yu,lue,iFo,dFo,mj,mFo,cFo,fFo,bs,iue,gFo,hFo,cj,uFo,pFo,fj,_Fo,bFo,vFo,xu,due,FFo,TFo,gj,MFo,EFo,CFo,$u,mue,wFo,AFo,hj,LFo,yFo,xFo,ku,cue,$Fo,kFo,uj,SFo,RFo,PFo,vs,fue,BFo,IFo,pj,NFo,qFo,_j,DFo,jFo,GFo,Fs,gue,OFo,VFo,bj,XFo,zFo,vj,QFo,WFo,UFo,Ts,hue,HFo,JFo,Fj,YFo,ZFo,Tj,KFo,eTo,oTo,Su,uue,rTo,tTo,Mj,aTo,nTo,sTo,Ru,pue,lTo,iTo,Ej,dTo,mTo,cTo,Pu,_ue,fTo,gTo,Cj,hTo,uTo,pTo,Ms,bue,_To,bTo,wj,vTo,FTo,Aj,TTo,MTo,ETo,Bu,vue,CTo,wTo,Lj,ATo,LTo,yTo,Es,Fue,xTo,$To,yj,kTo,STo,xj,RTo,PTo,BTo,Cs,Tue,ITo,NTo,$j,qTo,DTo,kj,jTo,GTo,OTo,ws,Mue,VTo,XTo,Sj,zTo,QTo,Rj,WTo,UTo,HTo,As,Eue,JTo,YTo,Pj,ZTo,KTo,Bj,eMo,oMo,rMo,Iu,Cue,tMo,aMo,Ij,nMo,sMo,lMo,Ls,wue,iMo,dMo,Nj,mMo,cMo,qj,fMo,gMo,hMo,ys,Aue,uMo,pMo,Dj,_Mo,bMo,jj,vMo,FMo,TMo,xs,Lue,MMo,EMo,Gj,CMo,wMo,Oj,AMo,LMo,yMo,$s,yue,xMo,$Mo,Vj,kMo,SMo,Xj,RMo,PMo,BMo,ks,xue,IMo,NMo,zj,qMo,DMo,Qj,jMo,GMo,OMo,Ss,$ue,VMo,XMo,Wj,zMo,QMo,Uj,WMo,UMo,HMo,Rs,kue,JMo,YMo,Hj,ZMo,KMo,Jj,eEo,oEo,rEo,Nu,Sue,tEo,aEo,Yj,nEo,sEo,lEo,qu,Rue,iEo,dEo,Zj,mEo,cEo,fEo,Ps,Pue,gEo,hEo,Kj,uEo,pEo,eG,_Eo,bEo,vEo,Du,Bue,FEo,TEo,oG,MEo,EEo,CEo,Bs,Iue,wEo,AEo,rG,LEo,yEo,tG,xEo,$Eo,kEo,Is,Nue,SEo,REo,aG,PEo,BEo,nG,IEo,NEo,qEo,Ns,que,DEo,jEo,sG,GEo,OEo,lG,VEo,XEo,zEo,ju,Due,QEo,WEo,iG,UEo,HEo,JEo,Gu,jue,YEo,ZEo,dG,KEo,e4o,o4o,qs,Gue,r4o,t4o,mG,a4o,n4o,cG,s4o,l4o,i4o,Ds,Oue,d4o,m4o,fG,c4o,f4o,gG,g4o,h4o,u4o,js,Vue,p4o,_4o,hG,b4o,v4o,uG,F4o,T4o,M4o,Ou,Xue,E4o,C4o,pG,w4o,A4o,L4o,Gs,zue,y4o,x4o,_G,$4o,k4o,bG,S4o,R4o,P4o,Os,Que,B4o,I4o,vG,N4o,q4o,FG,D4o,j4o,G4o,Vs,Wue,O4o,V4o,TG,X4o,z4o,MG,Q4o,W4o,U4o,Xs,Uue,H4o,J4o,EG,Y4o,Z4o,CG,K4o,eCo,oCo,zs,Hue,rCo,tCo,wG,aCo,nCo,AG,sCo,lCo,iCo,Qs,Jue,dCo,mCo,LG,cCo,fCo,yG,gCo,hCo,uCo,Ws,Yue,pCo,_Co,xG,bCo,vCo,$G,FCo,TCo,MCo,Us,Zue,ECo,CCo,kG,wCo,ACo,SG,LCo,yCo,xCo,Hs,Kue,$Co,kCo,RG,SCo,RCo,PG,PCo,BCo,ICo,Vu,epe,NCo,qCo,BG,DCo,jCo,GCo,Js,ope,OCo,VCo,IG,XCo,zCo,NG,QCo,WCo,UCo,Xu,rpe,HCo,JCo,qG,YCo,ZCo,KCo,zu,tpe,e3o,o3o,DG,r3o,t3o,a3o,Ys,ape,n3o,s3o,jG,l3o,i3o,GG,d3o,m3o,c3o,Zs,npe,f3o,g3o,OG,h3o,u3o,VG,p3o,_3o,b3o,Ks,spe,v3o,F3o,XG,T3o,M3o,zG,E3o,C3o,w3o,Qu,lpe,A3o,L3o,QG,y3o,x3o,$3o,el,ipe,k3o,S3o,WG,R3o,P3o,UG,B3o,I3o,N3o,ol,dpe,q3o,D3o,HG,j3o,G3o,JG,O3o,V3o,X3o,rl,mpe,z3o,Q3o,YG,W3o,U3o,ZG,H3o,J3o,Y3o,tl,cpe,Z3o,K3o,KG,e5o,o5o,eO,r5o,t5o,a5o,al,fpe,n5o,s5o,oO,l5o,i5o,rO,d5o,m5o,c5o,nl,gpe,f5o,g5o,tO,h5o,u5o,aO,p5o,_5o,b5o,sl,hpe,v5o,F5o,nO,T5o,M5o,sO,E5o,C5o,w5o,ll,upe,A5o,L5o,lO,y5o,x5o,iO,$5o,k5o,S5o,Wu,ppe,R5o,P5o,dO,B5o,I5o,N5o,il,_pe,q5o,D5o,mO,j5o,G5o,cO,O5o,V5o,X5o,dl,bpe,z5o,Q5o,fO,W5o,U5o,gO,H5o,J5o,Y5o,ml,vpe,Z5o,K5o,hO,e0o,o0o,uO,r0o,t0o,a0o,Uu,Fpe,n0o,s0o,pO,l0o,i0o,d0o,Hu,Tpe,m0o,c0o,_O,f0o,g0o,h0o,Ju,Mpe,u0o,p0o,bO,_0o,b0o,v0o,Yu,Epe,F0o,T0o,vO,M0o,E0o,C0o,cl,Cpe,w0o,A0o,FO,L0o,y0o,TO,x0o,$0o,k0o,Zu,wpe,S0o,R0o,MO,P0o,B0o,I0o,fl,Ape,N0o,q0o,EO,D0o,j0o,CO,G0o,O0o,V0o,gl,Lpe,X0o,z0o,wO,Q0o,W0o,AO,U0o,H0o,J0o,hl,ype,Y0o,Z0o,LO,K0o,ewo,yO,owo,rwo,two,ul,xpe,awo,nwo,xO,swo,lwo,$O,iwo,dwo,mwo,pl,$pe,cwo,fwo,kO,gwo,hwo,SO,uwo,pwo,_wo,_l,kpe,bwo,vwo,RO,Fwo,Two,PO,Mwo,Ewo,Cwo,Ku,Spe,wwo,Awo,BO,Lwo,ywo,xwo,ep,Rpe,$wo,kwo,IO,Swo,Rwo,Pwo,bl,Ppe,Bwo,Iwo,NO,Nwo,qwo,qO,Dwo,jwo,Gwo,vl,Bpe,Owo,Vwo,DO,Xwo,zwo,jO,Qwo,Wwo,Uwo,Fl,Ipe,Hwo,Jwo,GO,Ywo,Zwo,OO,Kwo,eAo,oAo,op,Npe,rAo,tAo,VO,aAo,nAo,sAo,rp,qpe,lAo,iAo,XO,dAo,mAo,cAo,tp,Dpe,fAo,gAo,zO,hAo,uAo,pAo,Tl,jpe,_Ao,bAo,QO,vAo,FAo,WO,TAo,MAo,EAo,Ml,Gpe,CAo,wAo,UO,AAo,LAo,HO,yAo,xAo,$Ao,ap,Ope,kAo,SAo,JO,RAo,PAo,BAo,np,Vpe,IAo,NAo,YO,qAo,DAo,jAo,sp,Xpe,GAo,OAo,ZO,VAo,XAo,zAo,lp,zpe,QAo,WAo,KO,UAo,HAo,JAo,El,Qpe,YAo,ZAo,eV,KAo,e6o,oV,o6o,r6o,t6o,Cl,Wpe,a6o,n6o,rV,s6o,l6o,tV,i6o,d6o,m6o,ip,Upe,c6o,f6o,aV,g6o,h6o,u6o,dp,Hpe,p6o,_6o,nV,b6o,v6o,F6o,wl,Jpe,T6o,M6o,sV,E6o,C6o,lV,w6o,A6o,L6o,Al,Ype,y6o,x6o,iV,$6o,k6o,dV,S6o,R6o,P6o,Ll,Zpe,B6o,I6o,mV,N6o,q6o,cV,D6o,j6o,G6o,yl,Kpe,O6o,V6o,fV,X6o,z6o,gV,Q6o,W6o,U6o,mp,H6o,cp,E$,J6o,e_e,Y6o,qto,xd,fp,o_e,C$,Z6o,r_e,K6o,Dto,Po,w$,e7o,A$,o7o,hV,r7o,t7o,a7o,L$,n7o,t_e,s7o,l7o,i7o,Ye,y$,d7o,a_e,m7o,c7o,an,f7o,n_e,g7o,h7o,s_e,u7o,p7o,l_e,_7o,b7o,v7o,z,gp,i_e,F7o,T7o,uV,M7o,E7o,C7o,hp,d_e,w7o,A7o,pV,L7o,y7o,x7o,up,m_e,$7o,k7o,_V,S7o,R7o,P7o,pp,c_e,B7o,I7o,bV,N7o,q7o,D7o,_p,f_e,j7o,G7o,vV,O7o,V7o,X7o,bp,g_e,z7o,Q7o,FV,W7o,U7o,H7o,vp,h_e,J7o,Y7o,TV,Z7o,K7o,e8o,Fp,u_e,o8o,r8o,MV,t8o,a8o,n8o,Tp,p_e,s8o,l8o,EV,i8o,d8o,m8o,Mp,__e,c8o,f8o,CV,g8o,h8o,u8o,Ep,b_e,p8o,_8o,wV,b8o,v8o,F8o,Cp,v_e,T8o,M8o,AV,E8o,C8o,w8o,wp,F_e,A8o,L8o,LV,y8o,x8o,$8o,Ap,T_e,k8o,S8o,yV,R8o,P8o,B8o,Lp,M_e,I8o,N8o,xV,q8o,D8o,j8o,yp,E_e,G8o,O8o,$V,V8o,X8o,z8o,xp,C_e,Q8o,W8o,kV,U8o,H8o,J8o,$p,w_e,Y8o,Z8o,SV,K8o,eLo,oLo,kp,A_e,rLo,tLo,RV,aLo,nLo,sLo,Sp,L_e,lLo,iLo,PV,dLo,mLo,cLo,Rp,y_e,fLo,gLo,BV,hLo,uLo,pLo,Pp,x_e,_Lo,bLo,IV,vLo,FLo,TLo,Bp,$_e,MLo,ELo,NV,CLo,wLo,ALo,Ip,k_e,LLo,yLo,qV,xLo,$Lo,kLo,Np,S_e,SLo,RLo,DV,PLo,BLo,ILo,qp,R_e,NLo,qLo,jV,DLo,jLo,GLo,Dp,P_e,OLo,VLo,GV,XLo,zLo,QLo,jp,B_e,WLo,ULo,OV,HLo,JLo,YLo,Gp,I_e,ZLo,KLo,VV,eyo,oyo,ryo,Op,N_e,tyo,ayo,XV,nyo,syo,lyo,Vp,q_e,iyo,dyo,zV,myo,cyo,fyo,Xp,D_e,gyo,hyo,QV,uyo,pyo,_yo,zp,j_e,byo,vyo,WV,Fyo,Tyo,Myo,Qp,G_e,Eyo,Cyo,UV,wyo,Ayo,Lyo,Wp,O_e,yyo,xyo,HV,$yo,kyo,Syo,Up,V_e,Ryo,Pyo,JV,Byo,Iyo,Nyo,Hp,X_e,qyo,Dyo,YV,jyo,Gyo,Oyo,Jp,z_e,Vyo,Xyo,ZV,zyo,Qyo,Wyo,Yp,Q_e,Uyo,Hyo,KV,Jyo,Yyo,Zyo,Zp,W_e,Kyo,e9o,eX,o9o,r9o,t9o,Kp,U_e,a9o,n9o,oX,s9o,l9o,i9o,e_,H_e,d9o,m9o,rX,c9o,f9o,g9o,o_,J_e,h9o,u9o,tX,p9o,_9o,b9o,r_,Y_e,v9o,F9o,aX,T9o,M9o,E9o,t_,C9o,a_,w9o,n_,x$,A9o,Z_e,L9o,jto,$d,s_,K_e,$$,y9o,e1e,x9o,Gto,Bo,k$,$9o,S$,k9o,nX,S9o,R9o,P9o,R$,B9o,o1e,I9o,N9o,q9o,Ze,P$,D9o,r1e,j9o,G9o,kd,O9o,t1e,V9o,X9o,a1e,z9o,Q9o,W9o,se,l_,n1e,U9o,H9o,sX,J9o,Y9o,Z9o,i_,s1e,K9o,exo,lX,oxo,rxo,txo,d_,l1e,axo,nxo,iX,sxo,lxo,ixo,m_,i1e,dxo,mxo,dX,cxo,fxo,gxo,c_,d1e,hxo,uxo,mX,pxo,_xo,bxo,f_,m1e,vxo,Fxo,cX,Txo,Mxo,Exo,g_,c1e,Cxo,wxo,fX,Axo,Lxo,yxo,h_,f1e,xxo,$xo,gX,kxo,Sxo,Rxo,u_,g1e,Pxo,Bxo,hX,Ixo,Nxo,qxo,p_,h1e,Dxo,jxo,uX,Gxo,Oxo,Vxo,__,u1e,Xxo,zxo,pX,Qxo,Wxo,Uxo,b_,p1e,Hxo,Jxo,_X,Yxo,Zxo,Kxo,v_,_1e,e$o,o$o,bX,r$o,t$o,a$o,F_,b1e,n$o,s$o,vX,l$o,i$o,d$o,T_,v1e,m$o,c$o,FX,f$o,g$o,h$o,M_,F1e,u$o,p$o,TX,_$o,b$o,v$o,E_,T1e,F$o,T$o,MX,M$o,E$o,C$o,C_,M1e,w$o,A$o,EX,L$o,y$o,x$o,w_,E1e,$$o,k$o,CX,S$o,R$o,P$o,A_,C1e,B$o,I$o,wX,N$o,q$o,D$o,L_,w1e,j$o,G$o,AX,O$o,V$o,X$o,y_,A1e,z$o,Q$o,LX,W$o,U$o,H$o,x_,L1e,J$o,Y$o,yX,Z$o,K$o,eko,$_,oko,k_,rko,S_,B$,tko,y1e,ako,Oto,Sd,R_,x1e,I$,nko,$1e,sko,Vto,Io,N$,lko,Rd,iko,xX,dko,mko,$X,cko,fko,gko,q$,hko,k1e,uko,pko,_ko,Mt,D$,bko,S1e,vko,Fko,Pd,Tko,R1e,Mko,Eko,kX,Cko,wko,Ako,P_,Lko,Ke,j$,yko,P1e,xko,$ko,nn,kko,B1e,Sko,Rko,I1e,Pko,Bko,N1e,Iko,Nko,qko,y,B_,q1e,Dko,jko,SX,Gko,Oko,Vko,I_,D1e,Xko,zko,RX,Qko,Wko,Uko,N_,j1e,Hko,Jko,PX,Yko,Zko,Kko,q_,G1e,eSo,oSo,BX,rSo,tSo,aSo,D_,O1e,nSo,sSo,IX,lSo,iSo,dSo,j_,V1e,mSo,cSo,NX,fSo,gSo,hSo,G_,X1e,uSo,pSo,qX,_So,bSo,vSo,O_,z1e,FSo,TSo,DX,MSo,ESo,CSo,V_,Q1e,wSo,ASo,jX,LSo,ySo,xSo,X_,W1e,$So,kSo,GX,SSo,RSo,PSo,z_,U1e,BSo,ISo,OX,NSo,qSo,DSo,Q_,H1e,jSo,GSo,VX,OSo,VSo,XSo,W_,J1e,zSo,QSo,XX,WSo,USo,HSo,U_,Y1e,JSo,YSo,zX,ZSo,KSo,eRo,H_,Z1e,oRo,rRo,QX,tRo,aRo,nRo,J_,K1e,sRo,lRo,WX,iRo,dRo,mRo,Y_,e2e,cRo,fRo,UX,gRo,hRo,uRo,Z_,o2e,pRo,_Ro,HX,bRo,vRo,FRo,K_,r2e,TRo,MRo,JX,ERo,CRo,wRo,e1,t2e,ARo,LRo,YX,yRo,xRo,$Ro,o1,a2e,kRo,SRo,ZX,RRo,PRo,BRo,r1,n2e,IRo,NRo,KX,qRo,DRo,jRo,t1,s2e,GRo,ORo,ez,VRo,XRo,zRo,a1,l2e,QRo,WRo,oz,URo,HRo,JRo,n1,i2e,YRo,ZRo,rz,KRo,ePo,oPo,s1,d2e,rPo,tPo,tz,aPo,nPo,sPo,l1,m2e,lPo,iPo,az,dPo,mPo,cPo,i1,c2e,fPo,gPo,nz,hPo,uPo,pPo,d1,f2e,_Po,bPo,sz,vPo,FPo,TPo,m1,g2e,MPo,EPo,lz,CPo,wPo,APo,c1,h2e,LPo,yPo,iz,xPo,$Po,kPo,f1,u2e,SPo,RPo,dz,PPo,BPo,IPo,g1,p2e,NPo,qPo,mz,DPo,jPo,GPo,h1,_2e,OPo,VPo,cz,XPo,zPo,QPo,u1,b2e,WPo,UPo,fz,HPo,JPo,YPo,p1,v2e,ZPo,KPo,gz,eBo,oBo,rBo,_1,F2e,tBo,aBo,hz,nBo,sBo,lBo,b1,T2e,iBo,dBo,uz,mBo,cBo,fBo,v1,M2e,gBo,hBo,pz,uBo,pBo,_Bo,xl,E2e,bBo,vBo,_z,FBo,TBo,bz,MBo,EBo,CBo,F1,C2e,wBo,ABo,vz,LBo,yBo,xBo,T1,w2e,$Bo,kBo,Fz,SBo,RBo,PBo,M1,A2e,BBo,IBo,Tz,NBo,qBo,DBo,E1,L2e,jBo,GBo,Mz,OBo,VBo,XBo,C1,y2e,zBo,QBo,Ez,WBo,UBo,HBo,w1,x2e,JBo,YBo,Cz,ZBo,KBo,eIo,A1,$2e,oIo,rIo,wz,tIo,aIo,nIo,L1,k2e,sIo,lIo,Az,iIo,dIo,mIo,y1,S2e,cIo,fIo,Lz,gIo,hIo,uIo,x1,R2e,pIo,_Io,yz,bIo,vIo,FIo,$1,P2e,TIo,MIo,xz,EIo,CIo,wIo,k1,B2e,AIo,LIo,$z,yIo,xIo,$Io,S1,I2e,kIo,SIo,kz,RIo,PIo,BIo,R1,N2e,IIo,NIo,Sz,qIo,DIo,jIo,P1,q2e,GIo,OIo,Rz,VIo,XIo,zIo,B1,D2e,QIo,WIo,Pz,UIo,HIo,JIo,I1,j2e,YIo,ZIo,Bz,KIo,eNo,oNo,N1,G2e,rNo,tNo,Iz,aNo,nNo,sNo,q1,O2e,lNo,iNo,Nz,dNo,mNo,cNo,D1,V2e,fNo,gNo,qz,hNo,uNo,pNo,j1,X2e,_No,bNo,Dz,vNo,FNo,TNo,G1,z2e,MNo,ENo,jz,CNo,wNo,ANo,O1,Q2e,LNo,yNo,Gz,xNo,$No,kNo,V1,W2e,SNo,RNo,Oz,PNo,BNo,INo,X1,U2e,NNo,qNo,Vz,DNo,jNo,GNo,z1,H2e,ONo,VNo,Xz,XNo,zNo,QNo,Q1,J2e,WNo,UNo,zz,HNo,JNo,YNo,W1,Y2e,ZNo,KNo,Qz,eqo,oqo,rqo,U1,Z2e,tqo,aqo,Wz,nqo,sqo,lqo,H1,K2e,iqo,dqo,Uz,mqo,cqo,fqo,J1,ebe,gqo,hqo,Hz,uqo,pqo,_qo,Y1,obe,bqo,vqo,Jz,Fqo,Tqo,Mqo,Z1,rbe,Eqo,Cqo,Yz,wqo,Aqo,Lqo,K1,tbe,yqo,xqo,Zz,$qo,kqo,Sqo,e2,abe,Rqo,Pqo,Kz,Bqo,Iqo,Nqo,o2,nbe,qqo,Dqo,eQ,jqo,Gqo,Oqo,r2,sbe,Vqo,Xqo,oQ,zqo,Qqo,Wqo,t2,lbe,Uqo,Hqo,rQ,Jqo,Yqo,Zqo,a2,ibe,Kqo,eDo,tQ,oDo,rDo,tDo,n2,dbe,aDo,nDo,aQ,sDo,lDo,iDo,s2,mbe,dDo,mDo,nQ,cDo,fDo,gDo,l2,cbe,hDo,uDo,sQ,pDo,_Do,bDo,i2,fbe,vDo,FDo,lQ,TDo,MDo,EDo,d2,gbe,CDo,wDo,iQ,ADo,LDo,yDo,m2,hbe,xDo,$Do,dQ,kDo,SDo,RDo,c2,ube,PDo,BDo,mQ,IDo,NDo,qDo,f2,pbe,DDo,jDo,cQ,GDo,ODo,VDo,g2,_be,XDo,zDo,fQ,QDo,WDo,UDo,h2,bbe,HDo,JDo,gQ,YDo,ZDo,KDo,u2,vbe,ejo,ojo,hQ,rjo,tjo,ajo,p2,Fbe,njo,sjo,uQ,ljo,ijo,djo,_2,Tbe,mjo,cjo,pQ,fjo,gjo,hjo,b2,Mbe,ujo,pjo,_Q,_jo,bjo,vjo,v2,Ebe,Fjo,Tjo,bQ,Mjo,Ejo,Cjo,F2,Cbe,wjo,Ajo,vQ,Ljo,yjo,xjo,T2,wbe,$jo,kjo,FQ,Sjo,Rjo,Pjo,M2,Abe,Bjo,Ijo,TQ,Njo,qjo,Djo,E2,Lbe,jjo,Gjo,MQ,Ojo,Vjo,Xjo,C2,ybe,zjo,Qjo,EQ,Wjo,Ujo,Hjo,w2,xbe,Jjo,Yjo,CQ,Zjo,Kjo,eGo,A2,$be,oGo,rGo,wQ,tGo,aGo,nGo,L2,kbe,sGo,lGo,AQ,iGo,dGo,mGo,y2,Sbe,cGo,fGo,LQ,gGo,hGo,uGo,x2,Rbe,pGo,_Go,yQ,bGo,vGo,FGo,$2,Pbe,TGo,MGo,xQ,EGo,CGo,wGo,k2,Bbe,AGo,LGo,$Q,yGo,xGo,$Go,S2,Ibe,kGo,SGo,kQ,RGo,PGo,BGo,R2,Nbe,IGo,NGo,SQ,qGo,DGo,jGo,P2,qbe,GGo,OGo,RQ,VGo,XGo,zGo,B2,Dbe,QGo,WGo,PQ,UGo,HGo,JGo,I2,jbe,YGo,ZGo,BQ,KGo,eOo,oOo,N2,Gbe,rOo,tOo,IQ,aOo,nOo,sOo,q2,Obe,lOo,iOo,NQ,dOo,mOo,cOo,D2,Vbe,fOo,gOo,qQ,hOo,uOo,pOo,j2,Xbe,_Oo,bOo,DQ,vOo,FOo,TOo,G2,zbe,MOo,EOo,jQ,COo,wOo,AOo,O2,Qbe,LOo,yOo,GQ,xOo,$Oo,kOo,V2,Wbe,SOo,ROo,OQ,POo,BOo,IOo,X2,Ube,NOo,qOo,VQ,DOo,jOo,GOo,z2,Hbe,OOo,VOo,XQ,XOo,zOo,QOo,Q2,Jbe,WOo,UOo,zQ,HOo,JOo,YOo,W2,Ybe,ZOo,KOo,QQ,eVo,oVo,rVo,U2,Zbe,tVo,aVo,WQ,nVo,sVo,lVo,H2,Kbe,iVo,dVo,UQ,mVo,cVo,fVo,J2,eve,gVo,hVo,HQ,uVo,pVo,_Vo,Y2,ove,bVo,vVo,JQ,FVo,TVo,MVo,Z2,rve,EVo,CVo,YQ,wVo,AVo,LVo,K2,tve,yVo,xVo,ZQ,$Vo,kVo,SVo,eb,ave,RVo,PVo,KQ,BVo,IVo,NVo,ob,qVo,nve,DVo,jVo,sve,GVo,OVo,rb,Xto,Bd,tb,lve,G$,VVo,ive,XVo,zto,No,O$,zVo,Id,QVo,eW,WVo,UVo,oW,HVo,JVo,YVo,V$,ZVo,dve,KVo,eXo,oXo,Et,X$,rXo,mve,tXo,aXo,Nd,nXo,cve,sXo,lXo,rW,iXo,dXo,mXo,ab,cXo,eo,z$,fXo,fve,gXo,hXo,sn,uXo,gve,pXo,_Xo,hve,bXo,vXo,uve,FXo,TXo,MXo,G,nb,pve,EXo,CXo,tW,wXo,AXo,LXo,sb,_ve,yXo,xXo,aW,$Xo,kXo,SXo,lb,bve,RXo,PXo,nW,BXo,IXo,NXo,ib,vve,qXo,DXo,sW,jXo,GXo,OXo,db,Fve,VXo,XXo,lW,zXo,QXo,WXo,mb,Tve,UXo,HXo,iW,JXo,YXo,ZXo,cb,Mve,KXo,ezo,dW,ozo,rzo,tzo,fb,Eve,azo,nzo,mW,szo,lzo,izo,gb,Cve,dzo,mzo,cW,czo,fzo,gzo,hb,wve,hzo,uzo,fW,pzo,_zo,bzo,ub,Ave,vzo,Fzo,gW,Tzo,Mzo,Ezo,pb,Lve,Czo,wzo,hW,Azo,Lzo,yzo,_b,yve,xzo,$zo,uW,kzo,Szo,Rzo,bb,xve,Pzo,Bzo,pW,Izo,Nzo,qzo,vb,$ve,Dzo,jzo,_W,Gzo,Ozo,Vzo,Fb,kve,Xzo,zzo,bW,Qzo,Wzo,Uzo,Tb,Sve,Hzo,Jzo,vW,Yzo,Zzo,Kzo,Mb,Rve,eQo,oQo,FW,rQo,tQo,aQo,Eb,Pve,nQo,sQo,TW,lQo,iQo,dQo,Cb,Bve,mQo,cQo,MW,fQo,gQo,hQo,wb,Ive,uQo,pQo,EW,_Qo,bQo,vQo,Ab,Nve,FQo,TQo,CW,MQo,EQo,CQo,Lb,qve,wQo,AQo,wW,LQo,yQo,xQo,yb,Dve,$Qo,kQo,AW,SQo,RQo,PQo,xb,jve,BQo,IQo,LW,NQo,qQo,DQo,$b,Gve,jQo,GQo,yW,OQo,VQo,XQo,kb,Ove,zQo,QQo,xW,WQo,UQo,HQo,Sb,Vve,JQo,YQo,$W,ZQo,KQo,eWo,Rb,Xve,oWo,rWo,kW,tWo,aWo,nWo,Pb,zve,sWo,lWo,SW,iWo,dWo,mWo,Bb,Qve,cWo,fWo,RW,gWo,hWo,uWo,Ib,Wve,pWo,_Wo,PW,bWo,vWo,FWo,Nb,Uve,TWo,MWo,BW,EWo,CWo,wWo,qb,Hve,AWo,LWo,IW,yWo,xWo,$Wo,Db,Jve,kWo,SWo,NW,RWo,PWo,BWo,jb,Yve,IWo,NWo,qW,qWo,DWo,jWo,Gb,Zve,GWo,OWo,DW,VWo,XWo,zWo,Ob,Kve,QWo,WWo,jW,UWo,HWo,JWo,Vb,eFe,YWo,ZWo,GW,KWo,eUo,oUo,Xb,oFe,rUo,tUo,OW,aUo,nUo,sUo,zb,rFe,lUo,iUo,VW,dUo,mUo,cUo,Qb,tFe,fUo,gUo,XW,hUo,uUo,pUo,Wb,aFe,_Uo,bUo,zW,vUo,FUo,TUo,Ub,nFe,MUo,EUo,QW,CUo,wUo,AUo,Hb,sFe,LUo,yUo,WW,xUo,$Uo,kUo,Jb,lFe,SUo,RUo,UW,PUo,BUo,IUo,Yb,iFe,NUo,qUo,HW,DUo,jUo,GUo,Zb,dFe,OUo,VUo,JW,XUo,zUo,QUo,Kb,WUo,mFe,UUo,HUo,cFe,JUo,YUo,ev,Qto,qd,ov,fFe,Q$,ZUo,gFe,KUo,Wto,qo,W$,eHo,Dd,oHo,YW,rHo,tHo,ZW,aHo,nHo,sHo,U$,lHo,hFe,iHo,dHo,mHo,Ct,H$,cHo,uFe,fHo,gHo,jd,hHo,pFe,uHo,pHo,KW,_Ho,bHo,vHo,rv,FHo,oo,J$,THo,_Fe,MHo,EHo,ln,CHo,bFe,wHo,AHo,vFe,LHo,yHo,FFe,xHo,$Ho,kHo,W,tv,TFe,SHo,RHo,eU,PHo,BHo,IHo,av,MFe,NHo,qHo,oU,DHo,jHo,GHo,nv,EFe,OHo,VHo,rU,XHo,zHo,QHo,sv,CFe,WHo,UHo,tU,HHo,JHo,YHo,lv,wFe,ZHo,KHo,aU,eJo,oJo,rJo,iv,AFe,tJo,aJo,nU,nJo,sJo,lJo,dv,LFe,iJo,dJo,sU,mJo,cJo,fJo,mv,yFe,gJo,hJo,lU,uJo,pJo,_Jo,cv,xFe,bJo,vJo,iU,FJo,TJo,MJo,fv,$Fe,EJo,CJo,dU,wJo,AJo,LJo,gv,kFe,yJo,xJo,mU,$Jo,kJo,SJo,hv,SFe,RJo,PJo,cU,BJo,IJo,NJo,uv,RFe,qJo,DJo,fU,jJo,GJo,OJo,pv,PFe,VJo,XJo,gU,zJo,QJo,WJo,_v,BFe,UJo,HJo,hU,JJo,YJo,ZJo,bv,IFe,KJo,eYo,uU,oYo,rYo,tYo,vv,NFe,aYo,nYo,pU,sYo,lYo,iYo,Fv,qFe,dYo,mYo,_U,cYo,fYo,gYo,Tv,DFe,hYo,uYo,bU,pYo,_Yo,bYo,Mv,jFe,vYo,FYo,vU,TYo,MYo,EYo,Ev,GFe,CYo,wYo,FU,AYo,LYo,yYo,Cv,OFe,xYo,$Yo,TU,kYo,SYo,RYo,wv,VFe,PYo,BYo,MU,IYo,NYo,qYo,Av,XFe,DYo,jYo,EU,GYo,OYo,VYo,Lv,zFe,XYo,zYo,CU,QYo,WYo,UYo,yv,QFe,HYo,JYo,wU,YYo,ZYo,KYo,xv,WFe,eZo,oZo,AU,rZo,tZo,aZo,$v,UFe,nZo,sZo,LU,lZo,iZo,dZo,kv,HFe,mZo,cZo,yU,fZo,gZo,hZo,Sv,JFe,uZo,pZo,xU,_Zo,bZo,vZo,Rv,YFe,FZo,TZo,$U,MZo,EZo,CZo,Pv,ZFe,wZo,AZo,kU,LZo,yZo,xZo,Bv,KFe,$Zo,kZo,SU,SZo,RZo,PZo,Iv,eTe,BZo,IZo,RU,NZo,qZo,DZo,Nv,oTe,jZo,GZo,PU,OZo,VZo,XZo,qv,rTe,zZo,QZo,BU,WZo,UZo,HZo,Dv,tTe,JZo,YZo,IU,ZZo,KZo,eKo,jv,aTe,oKo,rKo,NU,tKo,aKo,nKo,Gv,nTe,sKo,lKo,qU,iKo,dKo,mKo,Ov,sTe,cKo,fKo,DU,gKo,hKo,uKo,Vv,lTe,pKo,_Ko,jU,bKo,vKo,FKo,Xv,iTe,TKo,MKo,GU,EKo,CKo,wKo,zv,AKo,dTe,LKo,yKo,mTe,xKo,$Ko,Qv,Uto,Gd,Wv,cTe,Y$,kKo,fTe,SKo,Hto,Do,Z$,RKo,Od,PKo,OU,BKo,IKo,VU,NKo,qKo,DKo,K$,jKo,gTe,GKo,OKo,VKo,wt,ek,XKo,hTe,zKo,QKo,Vd,WKo,uTe,UKo,HKo,XU,JKo,YKo,ZKo,Uv,KKo,ro,ok,eer,pTe,oer,rer,dn,ter,_Te,aer,ner,bTe,ser,ler,vTe,ier,der,mer,rk,Hv,FTe,cer,fer,zU,ger,her,uer,Jv,TTe,per,_er,QU,ber,ver,Fer,Yv,Ter,MTe,Mer,Eer,ETe,Cer,wer,Zv,Jto,Xd,Kv,CTe,tk,Aer,wTe,Ler,Yto,jo,ak,yer,zd,xer,WU,$er,ker,UU,Ser,Rer,Per,nk,Ber,ATe,Ier,Ner,qer,At,sk,Der,LTe,jer,Ger,Qd,Oer,yTe,Ver,Xer,HU,zer,Qer,Wer,eF,Uer,to,lk,Her,xTe,Jer,Yer,mn,Zer,$Te,Ker,eor,kTe,oor,ror,STe,tor,aor,nor,Y,oF,RTe,sor,lor,JU,ior,dor,mor,rF,PTe,cor,gor,YU,hor,uor,por,tF,BTe,_or,bor,ZU,vor,For,Tor,aF,ITe,Mor,Eor,KU,Cor,wor,Aor,nF,NTe,Lor,yor,eH,xor,$or,kor,sF,qTe,Sor,Ror,oH,Por,Bor,Ior,lF,DTe,Nor,qor,rH,Dor,jor,Gor,iF,jTe,Oor,Vor,tH,Xor,zor,Qor,dF,GTe,Wor,Uor,aH,Hor,Jor,Yor,mF,OTe,Zor,Kor,nH,err,orr,rrr,cF,VTe,trr,arr,sH,nrr,srr,lrr,fF,XTe,irr,drr,lH,mrr,crr,frr,gF,zTe,grr,hrr,iH,urr,prr,_rr,hF,QTe,brr,vrr,dH,Frr,Trr,Mrr,uF,WTe,Err,Crr,mH,wrr,Arr,Lrr,pF,UTe,yrr,xrr,cH,$rr,krr,Srr,_F,HTe,Rrr,Prr,fH,Brr,Irr,Nrr,bF,JTe,qrr,Drr,gH,jrr,Grr,Orr,vF,YTe,Vrr,Xrr,hH,zrr,Qrr,Wrr,FF,ZTe,Urr,Hrr,uH,Jrr,Yrr,Zrr,TF,KTe,Krr,etr,pH,otr,rtr,ttr,MF,eMe,atr,ntr,_H,str,ltr,itr,EF,oMe,dtr,mtr,bH,ctr,ftr,gtr,CF,rMe,htr,utr,vH,ptr,_tr,btr,wF,tMe,vtr,Ftr,FH,Ttr,Mtr,Etr,AF,aMe,Ctr,wtr,TH,Atr,Ltr,ytr,LF,nMe,xtr,$tr,MH,ktr,Str,Rtr,yF,sMe,Ptr,Btr,EH,Itr,Ntr,qtr,xF,lMe,Dtr,jtr,CH,Gtr,Otr,Vtr,$F,iMe,Xtr,ztr,wH,Qtr,Wtr,Utr,kF,dMe,Htr,Jtr,AH,Ytr,Ztr,Ktr,SF,mMe,ear,oar,LH,rar,tar,aar,RF,cMe,nar,sar,yH,lar,iar,dar,PF,fMe,mar,car,xH,far,gar,har,BF,gMe,uar,par,hMe,_ar,bar,Far,IF,uMe,Tar,Mar,$H,Ear,Car,war,NF,pMe,Aar,Lar,kH,yar,xar,$ar,qF,_Me,kar,Sar,SH,Rar,Par,Bar,DF,bMe,Iar,Nar,RH,qar,Dar,jar,jF,Gar,vMe,Oar,Var,FMe,Xar,zar,GF,Zto,Wd,OF,TMe,ik,Qar,MMe,War,Kto,Go,dk,Uar,Ud,Har,PH,Jar,Yar,BH,Zar,Kar,enr,mk,onr,EMe,rnr,tnr,anr,Lt,ck,nnr,CMe,snr,lnr,Hd,inr,wMe,dnr,mnr,IH,cnr,fnr,gnr,VF,hnr,ao,fk,unr,AMe,pnr,_nr,cn,bnr,LMe,vnr,Fnr,yMe,Tnr,Mnr,xMe,Enr,Cnr,wnr,he,XF,$Me,Anr,Lnr,NH,ynr,xnr,$nr,zF,kMe,knr,Snr,qH,Rnr,Pnr,Bnr,QF,SMe,Inr,Nnr,DH,qnr,Dnr,jnr,WF,RMe,Gnr,Onr,jH,Vnr,Xnr,znr,UF,PMe,Qnr,Wnr,GH,Unr,Hnr,Jnr,HF,BMe,Ynr,Znr,OH,Knr,esr,osr,JF,IMe,rsr,tsr,VH,asr,nsr,ssr,YF,NMe,lsr,isr,XH,dsr,msr,csr,ZF,qMe,fsr,gsr,zH,hsr,usr,psr,KF,DMe,_sr,bsr,QH,vsr,Fsr,Tsr,eT,jMe,Msr,Esr,WH,Csr,wsr,Asr,oT,GMe,Lsr,ysr,UH,xsr,$sr,ksr,rT,OMe,Ssr,Rsr,HH,Psr,Bsr,Isr,tT,VMe,Nsr,qsr,JH,Dsr,jsr,Gsr,aT,XMe,Osr,Vsr,YH,Xsr,zsr,Qsr,nT,zMe,Wsr,Usr,ZH,Hsr,Jsr,Ysr,sT,QMe,Zsr,Ksr,KH,elr,olr,rlr,lT,WMe,tlr,alr,eJ,nlr,slr,llr,iT,UMe,ilr,dlr,oJ,mlr,clr,flr,dT,HMe,glr,hlr,rJ,ulr,plr,_lr,mT,blr,JMe,vlr,Flr,YMe,Tlr,Mlr,cT,eao,Jd,fT,ZMe,gk,Elr,KMe,Clr,oao,Oo,hk,wlr,Yd,Alr,tJ,Llr,ylr,aJ,xlr,$lr,klr,uk,Slr,eEe,Rlr,Plr,Blr,yt,pk,Ilr,oEe,Nlr,qlr,Zd,Dlr,rEe,jlr,Glr,nJ,Olr,Vlr,Xlr,gT,zlr,no,_k,Qlr,tEe,Wlr,Ulr,fn,Hlr,aEe,Jlr,Ylr,nEe,Zlr,Klr,sEe,eir,oir,rir,D,hT,lEe,tir,air,sJ,nir,sir,lir,uT,iEe,iir,dir,lJ,mir,cir,fir,pT,dEe,gir,hir,iJ,uir,pir,_ir,_T,mEe,bir,vir,dJ,Fir,Tir,Mir,bT,cEe,Eir,Cir,mJ,wir,Air,Lir,vT,fEe,yir,xir,cJ,$ir,kir,Sir,FT,gEe,Rir,Pir,fJ,Bir,Iir,Nir,TT,hEe,qir,Dir,gJ,jir,Gir,Oir,MT,uEe,Vir,Xir,hJ,zir,Qir,Wir,ET,pEe,Uir,Hir,uJ,Jir,Yir,Zir,CT,_Ee,Kir,edr,pJ,odr,rdr,tdr,wT,bEe,adr,ndr,_J,sdr,ldr,idr,AT,vEe,ddr,mdr,bJ,cdr,fdr,gdr,LT,FEe,hdr,udr,vJ,pdr,_dr,bdr,yT,TEe,vdr,Fdr,FJ,Tdr,Mdr,Edr,xT,MEe,Cdr,wdr,TJ,Adr,Ldr,ydr,$T,EEe,xdr,$dr,MJ,kdr,Sdr,Rdr,kT,CEe,Pdr,Bdr,EJ,Idr,Ndr,qdr,ST,wEe,Ddr,jdr,CJ,Gdr,Odr,Vdr,RT,AEe,Xdr,zdr,wJ,Qdr,Wdr,Udr,PT,LEe,Hdr,Jdr,AJ,Ydr,Zdr,Kdr,BT,yEe,emr,omr,LJ,rmr,tmr,amr,IT,xEe,nmr,smr,yJ,lmr,imr,dmr,NT,$Ee,mmr,cmr,xJ,fmr,gmr,hmr,qT,kEe,umr,pmr,$J,_mr,bmr,vmr,DT,SEe,Fmr,Tmr,kJ,Mmr,Emr,Cmr,jT,REe,wmr,Amr,SJ,Lmr,ymr,xmr,GT,PEe,$mr,kmr,RJ,Smr,Rmr,Pmr,OT,BEe,Bmr,Imr,PJ,Nmr,qmr,Dmr,VT,IEe,jmr,Gmr,BJ,Omr,Vmr,Xmr,XT,NEe,zmr,Qmr,IJ,Wmr,Umr,Hmr,zT,qEe,Jmr,Ymr,NJ,Zmr,Kmr,ecr,QT,DEe,ocr,rcr,qJ,tcr,acr,ncr,WT,jEe,scr,lcr,DJ,icr,dcr,mcr,UT,GEe,ccr,fcr,jJ,gcr,hcr,ucr,HT,OEe,pcr,_cr,GJ,bcr,vcr,Fcr,JT,VEe,Tcr,Mcr,OJ,Ecr,Ccr,wcr,YT,XEe,Acr,Lcr,VJ,ycr,xcr,$cr,ZT,zEe,kcr,Scr,XJ,Rcr,Pcr,Bcr,KT,QEe,Icr,Ncr,zJ,qcr,Dcr,jcr,eM,WEe,Gcr,Ocr,QJ,Vcr,Xcr,zcr,oM,UEe,Qcr,Wcr,WJ,Ucr,Hcr,Jcr,rM,HEe,Ycr,Zcr,UJ,Kcr,efr,ofr,tM,JEe,rfr,tfr,HJ,afr,nfr,sfr,aM,YEe,lfr,ifr,JJ,dfr,mfr,cfr,nM,ZEe,ffr,gfr,YJ,hfr,ufr,pfr,sM,KEe,_fr,bfr,ZJ,vfr,Ffr,Tfr,lM,e4e,Mfr,Efr,KJ,Cfr,wfr,Afr,iM,o4e,Lfr,yfr,eY,xfr,$fr,kfr,dM,r4e,Sfr,Rfr,oY,Pfr,Bfr,Ifr,mM,t4e,Nfr,qfr,rY,Dfr,jfr,Gfr,cM,a4e,Ofr,Vfr,tY,Xfr,zfr,Qfr,fM,n4e,Wfr,Ufr,aY,Hfr,Jfr,Yfr,gM,s4e,Zfr,Kfr,nY,egr,ogr,rgr,hM,l4e,tgr,agr,sY,ngr,sgr,lgr,uM,i4e,igr,dgr,lY,mgr,cgr,fgr,pM,ggr,d4e,hgr,ugr,m4e,pgr,_gr,_M,rao,Kd,bM,c4e,bk,bgr,f4e,vgr,tao,Vo,vk,Fgr,em,Tgr,iY,Mgr,Egr,dY,Cgr,wgr,Agr,Fk,Lgr,g4e,ygr,xgr,$gr,xt,Tk,kgr,h4e,Sgr,Rgr,om,Pgr,u4e,Bgr,Igr,mY,Ngr,qgr,Dgr,vM,jgr,so,Mk,Ggr,p4e,Ogr,Vgr,gn,Xgr,_4e,zgr,Qgr,b4e,Wgr,Ugr,v4e,Hgr,Jgr,Ygr,K,FM,F4e,Zgr,Kgr,cY,ehr,ohr,rhr,TM,T4e,thr,ahr,fY,nhr,shr,lhr,MM,M4e,ihr,dhr,gY,mhr,chr,fhr,EM,E4e,ghr,hhr,hY,uhr,phr,_hr,CM,C4e,bhr,vhr,uY,Fhr,Thr,Mhr,wM,w4e,Ehr,Chr,pY,whr,Ahr,Lhr,AM,A4e,yhr,xhr,_Y,$hr,khr,Shr,LM,L4e,Rhr,Phr,bY,Bhr,Ihr,Nhr,yM,y4e,qhr,Dhr,vY,jhr,Ghr,Ohr,xM,x4e,Vhr,Xhr,FY,zhr,Qhr,Whr,$M,$4e,Uhr,Hhr,TY,Jhr,Yhr,Zhr,kM,k4e,Khr,eur,MY,our,rur,tur,SM,S4e,aur,nur,EY,sur,lur,iur,RM,R4e,dur,mur,CY,cur,fur,gur,PM,P4e,hur,uur,wY,pur,_ur,bur,BM,B4e,vur,Fur,AY,Tur,Mur,Eur,IM,I4e,Cur,wur,LY,Aur,Lur,yur,NM,N4e,xur,$ur,yY,kur,Sur,Rur,qM,q4e,Pur,Bur,xY,Iur,Nur,qur,DM,D4e,Dur,jur,$Y,Gur,Our,Vur,jM,j4e,Xur,zur,kY,Qur,Wur,Uur,GM,G4e,Hur,Jur,SY,Yur,Zur,Kur,OM,O4e,epr,opr,RY,rpr,tpr,apr,VM,V4e,npr,spr,PY,lpr,ipr,dpr,XM,X4e,mpr,cpr,BY,fpr,gpr,hpr,zM,z4e,upr,ppr,IY,_pr,bpr,vpr,QM,Q4e,Fpr,Tpr,NY,Mpr,Epr,Cpr,WM,W4e,wpr,Apr,qY,Lpr,ypr,xpr,UM,U4e,$pr,kpr,DY,Spr,Rpr,Ppr,HM,H4e,Bpr,Ipr,jY,Npr,qpr,Dpr,JM,J4e,jpr,Gpr,GY,Opr,Vpr,Xpr,YM,Y4e,zpr,Qpr,OY,Wpr,Upr,Hpr,ZM,Jpr,Z4e,Ypr,Zpr,K4e,Kpr,e_r,KM,aao,rm,eE,eCe,Ek,o_r,oCe,r_r,nao,Xo,Ck,t_r,tm,a_r,VY,n_r,s_r,XY,l_r,i_r,d_r,wk,m_r,rCe,c_r,f_r,g_r,$t,Ak,h_r,tCe,u_r,p_r,am,__r,aCe,b_r,v_r,zY,F_r,T_r,M_r,oE,E_r,lo,Lk,C_r,nCe,w_r,A_r,hn,L_r,sCe,y_r,x_r,lCe,$_r,k_r,iCe,S_r,R_r,P_r,Ue,rE,dCe,B_r,I_r,QY,N_r,q_r,D_r,tE,mCe,j_r,G_r,WY,O_r,V_r,X_r,aE,cCe,z_r,Q_r,UY,W_r,U_r,H_r,nE,fCe,J_r,Y_r,HY,Z_r,K_r,e1r,sE,gCe,o1r,r1r,JY,t1r,a1r,n1r,lE,hCe,s1r,l1r,YY,i1r,d1r,m1r,iE,uCe,c1r,f1r,ZY,g1r,h1r,u1r,dE,p1r,pCe,_1r,b1r,_Ce,v1r,F1r,mE,sao,nm,cE,bCe,yk,T1r,vCe,M1r,lao,zo,xk,E1r,sm,C1r,KY,w1r,A1r,eZ,L1r,y1r,x1r,$k,$1r,FCe,k1r,S1r,R1r,kt,kk,P1r,TCe,B1r,I1r,lm,N1r,MCe,q1r,D1r,oZ,j1r,G1r,O1r,fE,V1r,io,Sk,X1r,ECe,z1r,Q1r,un,W1r,CCe,U1r,H1r,wCe,J1r,Y1r,ACe,Z1r,K1r,e2r,U,gE,LCe,o2r,r2r,rZ,t2r,a2r,n2r,hE,yCe,s2r,l2r,tZ,i2r,d2r,m2r,uE,xCe,c2r,f2r,aZ,g2r,h2r,u2r,pE,$Ce,p2r,_2r,nZ,b2r,v2r,F2r,_E,kCe,T2r,M2r,sZ,E2r,C2r,w2r,bE,SCe,A2r,L2r,lZ,y2r,x2r,$2r,vE,RCe,k2r,S2r,iZ,R2r,P2r,B2r,FE,PCe,I2r,N2r,dZ,q2r,D2r,j2r,TE,BCe,G2r,O2r,mZ,V2r,X2r,z2r,ME,ICe,Q2r,W2r,cZ,U2r,H2r,J2r,EE,NCe,Y2r,Z2r,fZ,K2r,ebr,obr,CE,qCe,rbr,tbr,gZ,abr,nbr,sbr,wE,DCe,lbr,ibr,hZ,dbr,mbr,cbr,AE,jCe,fbr,gbr,uZ,hbr,ubr,pbr,LE,GCe,_br,bbr,pZ,vbr,Fbr,Tbr,yE,OCe,Mbr,Ebr,_Z,Cbr,wbr,Abr,xE,VCe,Lbr,ybr,bZ,xbr,$br,kbr,$E,XCe,Sbr,Rbr,vZ,Pbr,Bbr,Ibr,kE,zCe,Nbr,qbr,FZ,Dbr,jbr,Gbr,SE,QCe,Obr,Vbr,TZ,Xbr,zbr,Qbr,RE,WCe,Wbr,Ubr,MZ,Hbr,Jbr,Ybr,PE,UCe,Zbr,Kbr,EZ,evr,ovr,rvr,BE,HCe,tvr,avr,CZ,nvr,svr,lvr,IE,JCe,ivr,dvr,wZ,mvr,cvr,fvr,NE,YCe,gvr,hvr,AZ,uvr,pvr,_vr,qE,ZCe,bvr,vvr,LZ,Fvr,Tvr,Mvr,DE,KCe,Evr,Cvr,yZ,wvr,Avr,Lvr,jE,e3e,yvr,xvr,xZ,$vr,kvr,Svr,GE,o3e,Rvr,Pvr,$Z,Bvr,Ivr,Nvr,OE,r3e,qvr,Dvr,kZ,jvr,Gvr,Ovr,VE,t3e,Vvr,Xvr,SZ,zvr,Qvr,Wvr,XE,a3e,Uvr,Hvr,RZ,Jvr,Yvr,Zvr,zE,n3e,Kvr,eFr,PZ,oFr,rFr,tFr,QE,s3e,aFr,nFr,BZ,sFr,lFr,iFr,WE,l3e,dFr,mFr,IZ,cFr,fFr,gFr,UE,i3e,hFr,uFr,NZ,pFr,_Fr,bFr,HE,d3e,vFr,FFr,qZ,TFr,MFr,EFr,JE,m3e,CFr,wFr,DZ,AFr,LFr,yFr,YE,c3e,xFr,$Fr,jZ,kFr,SFr,RFr,ZE,f3e,PFr,BFr,GZ,IFr,NFr,qFr,KE,g3e,DFr,jFr,OZ,GFr,OFr,VFr,e4,XFr,h3e,zFr,QFr,u3e,WFr,UFr,o4,iao,im,r4,p3e,Rk,HFr,_3e,JFr,dao,Qo,Pk,YFr,dm,ZFr,VZ,KFr,eTr,XZ,oTr,rTr,tTr,Bk,aTr,b3e,nTr,sTr,lTr,St,Ik,iTr,v3e,dTr,mTr,mm,cTr,F3e,fTr,gTr,zZ,hTr,uTr,pTr,t4,_Tr,mo,Nk,bTr,T3e,vTr,FTr,pn,TTr,M3e,MTr,ETr,E3e,CTr,wTr,C3e,ATr,LTr,yTr,O,a4,w3e,xTr,$Tr,QZ,kTr,STr,RTr,n4,A3e,PTr,BTr,WZ,ITr,NTr,qTr,s4,L3e,DTr,jTr,UZ,GTr,OTr,VTr,l4,y3e,XTr,zTr,HZ,QTr,WTr,UTr,i4,x3e,HTr,JTr,JZ,YTr,ZTr,KTr,d4,$3e,eMr,oMr,YZ,rMr,tMr,aMr,m4,k3e,nMr,sMr,ZZ,lMr,iMr,dMr,c4,S3e,mMr,cMr,KZ,fMr,gMr,hMr,f4,R3e,uMr,pMr,eK,_Mr,bMr,vMr,g4,P3e,FMr,TMr,oK,MMr,EMr,CMr,h4,B3e,wMr,AMr,rK,LMr,yMr,xMr,u4,I3e,$Mr,kMr,tK,SMr,RMr,PMr,p4,N3e,BMr,IMr,aK,NMr,qMr,DMr,_4,q3e,jMr,GMr,nK,OMr,VMr,XMr,b4,D3e,zMr,QMr,sK,WMr,UMr,HMr,v4,j3e,JMr,YMr,lK,ZMr,KMr,eEr,F4,G3e,oEr,rEr,iK,tEr,aEr,nEr,T4,O3e,sEr,lEr,dK,iEr,dEr,mEr,M4,V3e,cEr,fEr,mK,gEr,hEr,uEr,E4,X3e,pEr,_Er,cK,bEr,vEr,FEr,C4,z3e,TEr,MEr,fK,EEr,CEr,wEr,w4,Q3e,AEr,LEr,gK,yEr,xEr,$Er,A4,W3e,kEr,SEr,hK,REr,PEr,BEr,L4,U3e,IEr,NEr,uK,qEr,DEr,jEr,y4,H3e,GEr,OEr,pK,VEr,XEr,zEr,x4,J3e,QEr,WEr,_K,UEr,HEr,JEr,$4,Y3e,YEr,ZEr,bK,KEr,e4r,o4r,k4,Z3e,r4r,t4r,vK,a4r,n4r,s4r,S4,K3e,l4r,i4r,FK,d4r,m4r,c4r,R4,e5e,f4r,g4r,TK,h4r,u4r,p4r,P4,o5e,_4r,b4r,MK,v4r,F4r,T4r,B4,r5e,M4r,E4r,EK,C4r,w4r,A4r,I4,t5e,L4r,y4r,CK,x4r,$4r,k4r,N4,a5e,S4r,R4r,wK,P4r,B4r,I4r,q4,n5e,N4r,q4r,AK,D4r,j4r,G4r,D4,s5e,O4r,V4r,LK,X4r,z4r,Q4r,j4,l5e,W4r,U4r,yK,H4r,J4r,Y4r,G4,i5e,Z4r,K4r,xK,eCr,oCr,rCr,O4,d5e,tCr,aCr,$K,nCr,sCr,lCr,V4,m5e,iCr,dCr,kK,mCr,cCr,fCr,X4,c5e,gCr,hCr,SK,uCr,pCr,_Cr,z4,f5e,bCr,vCr,RK,FCr,TCr,MCr,Q4,g5e,ECr,CCr,PK,wCr,ACr,LCr,W4,h5e,yCr,xCr,BK,$Cr,kCr,SCr,U4,u5e,RCr,PCr,IK,BCr,ICr,NCr,H4,p5e,qCr,DCr,NK,jCr,GCr,OCr,J4,_5e,VCr,XCr,qK,zCr,QCr,WCr,Y4,b5e,UCr,HCr,DK,JCr,YCr,ZCr,Z4,KCr,v5e,e3r,o3r,F5e,r3r,t3r,K4,mao,cm,eC,T5e,qk,a3r,M5e,n3r,cao,Wo,Dk,s3r,fm,l3r,jK,i3r,d3r,GK,m3r,c3r,f3r,jk,g3r,E5e,h3r,u3r,p3r,Rt,Gk,_3r,C5e,b3r,v3r,gm,F3r,w5e,T3r,M3r,OK,E3r,C3r,w3r,oC,A3r,co,Ok,L3r,A5e,y3r,x3r,_n,$3r,L5e,k3r,S3r,y5e,R3r,P3r,x5e,B3r,I3r,N3r,$5e,rC,k5e,q3r,D3r,VK,j3r,G3r,O3r,tC,V3r,S5e,X3r,z3r,R5e,Q3r,W3r,aC,fao,hm,nC,P5e,Vk,U3r,B5e,H3r,gao,Uo,Xk,J3r,um,Y3r,XK,Z3r,K3r,zK,e5r,o5r,r5r,zk,t5r,I5e,a5r,n5r,s5r,Pt,Qk,l5r,N5e,i5r,d5r,pm,m5r,q5e,c5r,f5r,QK,g5r,h5r,u5r,sC,p5r,fo,Wk,_5r,D5e,b5r,v5r,bn,F5r,j5e,T5r,M5r,G5e,E5r,C5r,O5e,w5r,A5r,L5r,_m,lC,V5e,y5r,x5r,WK,$5r,k5r,S5r,iC,X5e,R5r,P5r,UK,B5r,I5r,N5r,dC,z5e,q5r,D5r,HK,j5r,G5r,O5r,mC,V5r,Q5e,X5r,z5r,W5e,Q5r,W5r,cC,hao,bm,fC,U5e,Uk,U5r,H5e,H5r,uao,Ho,Hk,J5r,vm,Y5r,JK,Z5r,K5r,YK,e0r,o0r,r0r,Jk,t0r,J5e,a0r,n0r,s0r,Bt,Yk,l0r,Y5e,i0r,d0r,Fm,m0r,Z5e,c0r,f0r,ZK,g0r,h0r,u0r,gC,p0r,go,Zk,_0r,K5e,b0r,v0r,vn,F0r,e0e,T0r,M0r,o0e,E0r,C0r,r0e,w0r,A0r,L0r,be,hC,t0e,y0r,x0r,KK,$0r,k0r,S0r,uC,a0e,R0r,P0r,eee,B0r,I0r,N0r,pC,n0e,q0r,D0r,oee,j0r,G0r,O0r,_C,s0e,V0r,X0r,ree,z0r,Q0r,W0r,$l,l0e,U0r,H0r,tee,J0r,Y0r,aee,Z0r,K0r,ewr,bC,i0e,owr,rwr,nee,twr,awr,nwr,kl,d0e,swr,lwr,see,iwr,dwr,lee,mwr,cwr,fwr,vC,m0e,gwr,hwr,iee,uwr,pwr,_wr,It,c0e,bwr,vwr,dee,Fwr,Twr,mee,Mwr,Ewr,cee,Cwr,wwr,Awr,FC,f0e,Lwr,ywr,fee,xwr,$wr,kwr,TC,g0e,Swr,Rwr,gee,Pwr,Bwr,Iwr,MC,h0e,Nwr,qwr,hee,Dwr,jwr,Gwr,EC,u0e,Owr,Vwr,uee,Xwr,zwr,Qwr,CC,p0e,Wwr,Uwr,pee,Hwr,Jwr,Ywr,wC,_0e,Zwr,Kwr,_ee,eAr,oAr,rAr,AC,b0e,tAr,aAr,bee,nAr,sAr,lAr,LC,v0e,iAr,dAr,vee,mAr,cAr,fAr,yC,F0e,gAr,hAr,Fee,uAr,pAr,_Ar,xC,bAr,T0e,vAr,FAr,M0e,TAr,MAr,$C,pao,Tm,kC,E0e,Kk,EAr,C0e,CAr,_ao,Jo,eS,wAr,Mm,AAr,Tee,LAr,yAr,Mee,xAr,$Ar,kAr,oS,SAr,w0e,RAr,PAr,BAr,Nt,rS,IAr,A0e,NAr,qAr,Em,DAr,L0e,jAr,GAr,Eee,OAr,VAr,XAr,SC,zAr,ho,tS,QAr,y0e,WAr,UAr,Fn,HAr,x0e,JAr,YAr,$0e,ZAr,KAr,k0e,e6r,o6r,r6r,S0e,RC,R0e,t6r,a6r,Cee,n6r,s6r,l6r,PC,i6r,P0e,d6r,m6r,B0e,c6r,f6r,BC,bao,Cm,IC,I0e,aS,g6r,N0e,h6r,vao,Yo,nS,u6r,wm,p6r,wee,_6r,b6r,Aee,v6r,F6r,T6r,sS,M6r,q0e,E6r,C6r,w6r,qt,lS,A6r,D0e,L6r,y6r,Am,x6r,j0e,$6r,k6r,Lee,S6r,R6r,P6r,NC,B6r,uo,iS,I6r,G0e,N6r,q6r,Tn,D6r,O0e,j6r,G6r,V0e,O6r,V6r,X0e,X6r,z6r,Q6r,z0e,qC,Q0e,W6r,U6r,yee,H6r,J6r,Y6r,DC,Z6r,W0e,K6r,e7r,U0e,o7r,r7r,jC,Fao,Lm,GC,H0e,dS,t7r,J0e,a7r,Tao,Zo,mS,n7r,ym,s7r,xee,l7r,i7r,$ee,d7r,m7r,c7r,cS,f7r,Y0e,g7r,h7r,u7r,Dt,fS,p7r,Z0e,_7r,b7r,xm,v7r,K0e,F7r,T7r,kee,M7r,E7r,C7r,OC,w7r,po,gS,A7r,ewe,L7r,y7r,Mn,x7r,owe,$7r,k7r,rwe,S7r,R7r,twe,P7r,B7r,I7r,awe,VC,nwe,N7r,q7r,See,D7r,j7r,G7r,XC,O7r,swe,V7r,X7r,lwe,z7r,Q7r,zC,Mao,$m,QC,iwe,hS,W7r,dwe,U7r,Eao,Ko,uS,H7r,km,J7r,Ree,Y7r,Z7r,Pee,K7r,e8r,o8r,pS,r8r,mwe,t8r,a8r,n8r,jt,_S,s8r,cwe,l8r,i8r,Sm,d8r,fwe,m8r,c8r,Bee,f8r,g8r,h8r,WC,u8r,_o,bS,p8r,gwe,_8r,b8r,En,v8r,hwe,F8r,T8r,uwe,M8r,E8r,pwe,C8r,w8r,A8r,Be,UC,_we,L8r,y8r,Iee,x8r,$8r,k8r,HC,bwe,S8r,R8r,Nee,P8r,B8r,I8r,JC,vwe,N8r,q8r,qee,D8r,j8r,G8r,YC,Fwe,O8r,V8r,Dee,X8r,z8r,Q8r,ZC,Twe,W8r,U8r,jee,H8r,J8r,Y8r,KC,Mwe,Z8r,K8r,Gee,eLr,oLr,rLr,e3,Ewe,tLr,aLr,Oee,nLr,sLr,lLr,o3,Cwe,iLr,dLr,Vee,mLr,cLr,fLr,r3,wwe,gLr,hLr,Xee,uLr,pLr,_Lr,t3,bLr,Awe,vLr,FLr,Lwe,TLr,MLr,a3,Cao,Rm,n3,ywe,vS,ELr,xwe,CLr,wao,er,FS,wLr,Pm,ALr,zee,LLr,yLr,Qee,xLr,$Lr,kLr,TS,SLr,$we,RLr,PLr,BLr,Gt,MS,ILr,kwe,NLr,qLr,Bm,DLr,Swe,jLr,GLr,Wee,OLr,VLr,XLr,s3,zLr,bo,ES,QLr,Rwe,WLr,ULr,Cn,HLr,Pwe,JLr,YLr,Bwe,ZLr,KLr,Iwe,eyr,oyr,ryr,ut,l3,Nwe,tyr,ayr,Uee,nyr,syr,lyr,i3,qwe,iyr,dyr,Hee,myr,cyr,fyr,d3,Dwe,gyr,hyr,Jee,uyr,pyr,_yr,m3,jwe,byr,vyr,Yee,Fyr,Tyr,Myr,c3,Gwe,Eyr,Cyr,Zee,wyr,Ayr,Lyr,f3,yyr,Owe,xyr,$yr,Vwe,kyr,Syr,g3,Aao,Im,h3,Xwe,CS,Ryr,zwe,Pyr,Lao,or,wS,Byr,Nm,Iyr,Kee,Nyr,qyr,eoe,Dyr,jyr,Gyr,AS,Oyr,Qwe,Vyr,Xyr,zyr,Ot,LS,Qyr,Wwe,Wyr,Uyr,qm,Hyr,Uwe,Jyr,Yyr,ooe,Zyr,Kyr,e9r,u3,o9r,vo,yS,r9r,Hwe,t9r,a9r,wn,n9r,Jwe,s9r,l9r,Ywe,i9r,d9r,Zwe,m9r,c9r,f9r,Le,p3,Kwe,g9r,h9r,roe,u9r,p9r,_9r,_3,eAe,b9r,v9r,toe,F9r,T9r,M9r,b3,oAe,E9r,C9r,aoe,w9r,A9r,L9r,v3,rAe,y9r,x9r,noe,$9r,k9r,S9r,F3,tAe,R9r,P9r,soe,B9r,I9r,N9r,T3,aAe,q9r,D9r,loe,j9r,G9r,O9r,M3,nAe,V9r,X9r,ioe,z9r,Q9r,W9r,E3,sAe,U9r,H9r,doe,J9r,Y9r,Z9r,C3,lAe,K9r,exr,moe,oxr,rxr,txr,w3,iAe,axr,nxr,coe,sxr,lxr,ixr,A3,dxr,dAe,mxr,cxr,mAe,fxr,gxr,L3,yao,Dm,y3,cAe,xS,hxr,fAe,uxr,xao,rr,$S,pxr,jm,_xr,foe,bxr,vxr,goe,Fxr,Txr,Mxr,kS,Exr,gAe,Cxr,wxr,Axr,Vt,SS,Lxr,hAe,yxr,xxr,Gm,$xr,uAe,kxr,Sxr,hoe,Rxr,Pxr,Bxr,x3,Ixr,Fo,RS,Nxr,pAe,qxr,Dxr,An,jxr,_Ae,Gxr,Oxr,bAe,Vxr,Xxr,vAe,zxr,Qxr,Wxr,Om,$3,FAe,Uxr,Hxr,uoe,Jxr,Yxr,Zxr,k3,TAe,Kxr,e$r,poe,o$r,r$r,t$r,S3,MAe,a$r,n$r,_oe,s$r,l$r,i$r,R3,d$r,EAe,m$r,c$r,CAe,f$r,g$r,P3,$ao,Vm,B3,wAe,PS,h$r,AAe,u$r,kao,tr,BS,p$r,Xm,_$r,boe,b$r,v$r,voe,F$r,T$r,M$r,IS,E$r,LAe,C$r,w$r,A$r,Xt,NS,L$r,yAe,y$r,x$r,zm,$$r,xAe,k$r,S$r,Foe,R$r,P$r,B$r,I3,I$r,To,qS,N$r,$Ae,q$r,D$r,Ln,j$r,kAe,G$r,O$r,SAe,V$r,X$r,RAe,z$r,Q$r,W$r,pt,N3,PAe,U$r,H$r,Toe,J$r,Y$r,Z$r,q3,BAe,K$r,ekr,Moe,okr,rkr,tkr,D3,IAe,akr,nkr,Eoe,skr,lkr,ikr,j3,NAe,dkr,mkr,Coe,ckr,fkr,gkr,G3,qAe,hkr,ukr,woe,pkr,_kr,bkr,O3,vkr,DAe,Fkr,Tkr,jAe,Mkr,Ekr,V3,Sao,Qm,X3,GAe,DS,Ckr,OAe,wkr,Rao,ar,jS,Akr,Wm,Lkr,Aoe,ykr,xkr,Loe,$kr,kkr,Skr,GS,Rkr,VAe,Pkr,Bkr,Ikr,zt,OS,Nkr,XAe,qkr,Dkr,Um,jkr,zAe,Gkr,Okr,yoe,Vkr,Xkr,zkr,z3,Qkr,Mo,VS,Wkr,QAe,Ukr,Hkr,yn,Jkr,WAe,Ykr,Zkr,UAe,Kkr,eSr,HAe,oSr,rSr,tSr,xn,Q3,JAe,aSr,nSr,xoe,sSr,lSr,iSr,W3,YAe,dSr,mSr,$oe,cSr,fSr,gSr,U3,ZAe,hSr,uSr,koe,pSr,_Sr,bSr,H3,KAe,vSr,FSr,Soe,TSr,MSr,ESr,J3,CSr,e6e,wSr,ASr,o6e,LSr,ySr,Y3,Pao,Hm,Z3,r6e,XS,xSr,t6e,$Sr,Bao,nr,zS,kSr,Jm,SSr,Roe,RSr,PSr,Poe,BSr,ISr,NSr,QS,qSr,a6e,DSr,jSr,GSr,Qt,WS,OSr,n6e,VSr,XSr,Ym,zSr,s6e,QSr,WSr,Boe,USr,HSr,JSr,K3,YSr,Eo,US,ZSr,l6e,KSr,eRr,$n,oRr,i6e,rRr,tRr,d6e,aRr,nRr,m6e,sRr,lRr,iRr,_t,e5,c6e,dRr,mRr,Ioe,cRr,fRr,gRr,o5,f6e,hRr,uRr,Noe,pRr,_Rr,bRr,r5,g6e,vRr,FRr,qoe,TRr,MRr,ERr,t5,h6e,CRr,wRr,Doe,ARr,LRr,yRr,a5,u6e,xRr,$Rr,joe,kRr,SRr,RRr,n5,PRr,p6e,BRr,IRr,_6e,NRr,qRr,s5,Iao,Zm,l5,b6e,HS,DRr,v6e,jRr,Nao,sr,JS,GRr,Km,ORr,Goe,VRr,XRr,Ooe,zRr,QRr,WRr,YS,URr,F6e,HRr,JRr,YRr,Wt,ZS,ZRr,T6e,KRr,ePr,ec,oPr,M6e,rPr,tPr,Voe,aPr,nPr,sPr,i5,lPr,Co,KS,iPr,E6e,dPr,mPr,kn,cPr,C6e,fPr,gPr,w6e,hPr,uPr,A6e,pPr,_Pr,bPr,L6e,d5,y6e,vPr,FPr,Xoe,TPr,MPr,EPr,m5,CPr,x6e,wPr,APr,$6e,LPr,yPr,c5,qao,oc,f5,k6e,eR,xPr,S6e,$Pr,Dao,lr,oR,kPr,rc,SPr,zoe,RPr,PPr,Qoe,BPr,IPr,NPr,rR,qPr,R6e,DPr,jPr,GPr,Ut,tR,OPr,P6e,VPr,XPr,tc,zPr,B6e,QPr,WPr,Woe,UPr,HPr,JPr,g5,YPr,wo,aR,ZPr,I6e,KPr,eBr,Sn,oBr,N6e,rBr,tBr,q6e,aBr,nBr,D6e,sBr,lBr,iBr,bt,h5,j6e,dBr,mBr,Uoe,cBr,fBr,gBr,u5,G6e,hBr,uBr,Hoe,pBr,_Br,bBr,p5,O6e,vBr,FBr,Joe,TBr,MBr,EBr,_5,V6e,CBr,wBr,Yoe,ABr,LBr,yBr,b5,X6e,xBr,$Br,Zoe,kBr,SBr,RBr,v5,PBr,z6e,BBr,IBr,Q6e,NBr,qBr,F5,jao,ac,T5,W6e,nR,DBr,U6e,jBr,Gao,ir,sR,GBr,nc,OBr,Koe,VBr,XBr,ere,zBr,QBr,WBr,lR,UBr,H6e,HBr,JBr,YBr,Ht,iR,ZBr,J6e,KBr,eIr,sc,oIr,Y6e,rIr,tIr,ore,aIr,nIr,sIr,M5,lIr,Ao,dR,iIr,Z6e,dIr,mIr,Rn,cIr,K6e,fIr,gIr,e7e,hIr,uIr,o7e,pIr,_Ir,bIr,r7e,E5,t7e,vIr,FIr,rre,TIr,MIr,EIr,C5,CIr,a7e,wIr,AIr,n7e,LIr,yIr,w5,Oao,lc,A5,s7e,mR,xIr,l7e,$Ir,Vao,dr,cR,kIr,ic,SIr,tre,RIr,PIr,are,BIr,IIr,NIr,fR,qIr,i7e,DIr,jIr,GIr,Jt,gR,OIr,d7e,VIr,XIr,dc,zIr,m7e,QIr,WIr,nre,UIr,HIr,JIr,L5,YIr,Lo,hR,ZIr,c7e,KIr,eNr,Pn,oNr,f7e,rNr,tNr,g7e,aNr,nNr,h7e,sNr,lNr,iNr,u7e,y5,p7e,dNr,mNr,sre,cNr,fNr,gNr,x5,hNr,_7e,uNr,pNr,b7e,_Nr,bNr,$5,Xao,mc,k5,v7e,uR,vNr,F7e,FNr,zao,mr,pR,TNr,cc,MNr,lre,ENr,CNr,ire,wNr,ANr,LNr,_R,yNr,T7e,xNr,$Nr,kNr,Yt,bR,SNr,M7e,RNr,PNr,fc,BNr,E7e,INr,NNr,dre,qNr,DNr,jNr,S5,GNr,jr,vR,ONr,C7e,VNr,XNr,Bn,zNr,w7e,QNr,WNr,A7e,UNr,HNr,L7e,JNr,YNr,ZNr,P,R5,y7e,KNr,eqr,mre,oqr,rqr,tqr,P5,x7e,aqr,nqr,cre,sqr,lqr,iqr,B5,$7e,dqr,mqr,fre,cqr,fqr,gqr,I5,k7e,hqr,uqr,gre,pqr,_qr,bqr,N5,S7e,vqr,Fqr,hre,Tqr,Mqr,Eqr,q5,R7e,Cqr,wqr,ure,Aqr,Lqr,yqr,D5,P7e,xqr,$qr,pre,kqr,Sqr,Rqr,j5,B7e,Pqr,Bqr,_re,Iqr,Nqr,qqr,G5,I7e,Dqr,jqr,bre,Gqr,Oqr,Vqr,O5,N7e,Xqr,zqr,vre,Qqr,Wqr,Uqr,V5,q7e,Hqr,Jqr,Fre,Yqr,Zqr,Kqr,X5,D7e,eDr,oDr,Tre,rDr,tDr,aDr,z5,j7e,nDr,sDr,Mre,lDr,iDr,dDr,Q5,G7e,mDr,cDr,Ere,fDr,gDr,hDr,W5,O7e,uDr,pDr,Cre,_Dr,bDr,vDr,U5,V7e,FDr,TDr,wre,MDr,EDr,CDr,H5,X7e,wDr,ADr,Are,LDr,yDr,xDr,J5,z7e,$Dr,kDr,Lre,SDr,RDr,PDr,Y5,Q7e,BDr,IDr,yre,NDr,qDr,DDr,Z5,W7e,jDr,GDr,xre,ODr,VDr,XDr,Sl,U7e,zDr,QDr,$re,WDr,UDr,kre,HDr,JDr,YDr,K5,H7e,ZDr,KDr,Sre,ejr,ojr,rjr,e0,J7e,tjr,ajr,Rre,njr,sjr,ljr,o0,Y7e,ijr,djr,Pre,mjr,cjr,fjr,r0,Z7e,gjr,hjr,Bre,ujr,pjr,_jr,t0,K7e,bjr,vjr,Ire,Fjr,Tjr,Mjr,a0,e8e,Ejr,Cjr,Nre,wjr,Ajr,Ljr,n0,o8e,yjr,xjr,qre,$jr,kjr,Sjr,s0,r8e,Rjr,Pjr,Dre,Bjr,Ijr,Njr,l0,t8e,qjr,Djr,jre,jjr,Gjr,Ojr,i0,a8e,Vjr,Xjr,Gre,zjr,Qjr,Wjr,d0,n8e,Ujr,Hjr,Ore,Jjr,Yjr,Zjr,m0,s8e,Kjr,eGr,Vre,oGr,rGr,tGr,c0,l8e,aGr,nGr,Xre,sGr,lGr,iGr,f0,i8e,dGr,mGr,zre,cGr,fGr,gGr,g0,d8e,hGr,uGr,Qre,pGr,_Gr,bGr,h0,m8e,vGr,FGr,Wre,TGr,MGr,EGr,u0,c8e,CGr,wGr,Ure,AGr,LGr,yGr,p0,f8e,xGr,$Gr,Hre,kGr,SGr,RGr,_0,g8e,PGr,BGr,Jre,IGr,NGr,qGr,b0,h8e,DGr,jGr,Yre,GGr,OGr,VGr,v0,u8e,XGr,zGr,Zre,QGr,WGr,UGr,F0,p8e,HGr,JGr,Kre,YGr,ZGr,KGr,T0,_8e,eOr,oOr,ete,rOr,tOr,aOr,M0,b8e,nOr,sOr,ote,lOr,iOr,dOr,E0,v8e,mOr,cOr,rte,fOr,gOr,hOr,C0,F8e,uOr,pOr,tte,_Or,bOr,vOr,w0,T8e,FOr,TOr,ate,MOr,EOr,COr,A0,M8e,wOr,AOr,nte,LOr,yOr,xOr,L0,E8e,$Or,kOr,ste,SOr,ROr,POr,y0,C8e,BOr,IOr,lte,NOr,qOr,DOr,x0,w8e,jOr,GOr,ite,OOr,VOr,XOr,$0,A8e,zOr,QOr,dte,WOr,UOr,HOr,k0,L8e,JOr,YOr,mte,ZOr,KOr,eVr,S0,y8e,oVr,rVr,cte,tVr,aVr,nVr,R0,x8e,sVr,lVr,fte,iVr,dVr,mVr,P0,$8e,cVr,fVr,gte,gVr,hVr,uVr,B0,k8e,pVr,_Vr,hte,bVr,vVr,FVr,I0,Qao,gc,N0,S8e,FR,TVr,R8e,MVr,Wao,cr,TR,EVr,hc,CVr,ute,wVr,AVr,pte,LVr,yVr,xVr,MR,$Vr,P8e,kVr,SVr,RVr,Zt,ER,PVr,B8e,BVr,IVr,uc,NVr,I8e,qVr,DVr,_te,jVr,GVr,OVr,q0,VVr,Gr,CR,XVr,N8e,zVr,QVr,In,WVr,q8e,UVr,HVr,D8e,JVr,YVr,j8e,ZVr,KVr,eXr,le,D0,G8e,oXr,rXr,bte,tXr,aXr,nXr,j0,O8e,sXr,lXr,vte,iXr,dXr,mXr,G0,V8e,cXr,fXr,Fte,gXr,hXr,uXr,O0,X8e,pXr,_Xr,Tte,bXr,vXr,FXr,V0,z8e,TXr,MXr,Mte,EXr,CXr,wXr,X0,Q8e,AXr,LXr,Ete,yXr,xXr,$Xr,z0,W8e,kXr,SXr,Cte,RXr,PXr,BXr,Q0,U8e,IXr,NXr,wte,qXr,DXr,jXr,W0,H8e,GXr,OXr,Ate,VXr,XXr,zXr,U0,J8e,QXr,WXr,Lte,UXr,HXr,JXr,H0,Y8e,YXr,ZXr,yte,KXr,ezr,ozr,J0,Z8e,rzr,tzr,xte,azr,nzr,szr,Y0,K8e,lzr,izr,$te,dzr,mzr,czr,Z0,eLe,fzr,gzr,kte,hzr,uzr,pzr,K0,oLe,_zr,bzr,Ste,vzr,Fzr,Tzr,ew,rLe,Mzr,Ezr,Rte,Czr,wzr,Azr,ow,tLe,Lzr,yzr,Pte,xzr,$zr,kzr,rw,aLe,Szr,Rzr,Bte,Pzr,Bzr,Izr,tw,nLe,Nzr,qzr,Ite,Dzr,jzr,Gzr,aw,sLe,Ozr,Vzr,Nte,Xzr,zzr,Qzr,nw,lLe,Wzr,Uzr,qte,Hzr,Jzr,Yzr,sw,iLe,Zzr,Kzr,Dte,eQr,oQr,rQr,lw,dLe,tQr,aQr,jte,nQr,sQr,lQr,iw,Uao,pc,dw,mLe,wR,iQr,cLe,dQr,Hao,fr,AR,mQr,_c,cQr,Gte,fQr,gQr,Ote,hQr,uQr,pQr,LR,_Qr,fLe,bQr,vQr,FQr,Kt,yR,TQr,gLe,MQr,EQr,bc,CQr,hLe,wQr,AQr,Vte,LQr,yQr,xQr,mw,$Qr,Or,xR,kQr,uLe,SQr,RQr,Nn,PQr,pLe,BQr,IQr,_Le,NQr,qQr,bLe,DQr,jQr,GQr,Me,cw,vLe,OQr,VQr,Xte,XQr,zQr,QQr,fw,FLe,WQr,UQr,zte,HQr,JQr,YQr,gw,TLe,ZQr,KQr,Qte,eWr,oWr,rWr,hw,MLe,tWr,aWr,Wte,nWr,sWr,lWr,uw,ELe,iWr,dWr,Ute,mWr,cWr,fWr,pw,CLe,gWr,hWr,Hte,uWr,pWr,_Wr,_w,wLe,bWr,vWr,Jte,FWr,TWr,MWr,bw,ALe,EWr,CWr,Yte,wWr,AWr,LWr,vw,LLe,yWr,xWr,Zte,$Wr,kWr,SWr,Fw,yLe,RWr,PWr,Kte,BWr,IWr,NWr,Tw,xLe,qWr,DWr,eae,jWr,GWr,OWr,Mw,$Le,VWr,XWr,oae,zWr,QWr,WWr,Ew,kLe,UWr,HWr,rae,JWr,YWr,ZWr,Cw,SLe,KWr,eUr,tae,oUr,rUr,tUr,ww,Jao,vc,Aw,RLe,$R,aUr,PLe,nUr,Yao,gr,kR,sUr,Fc,lUr,aae,iUr,dUr,nae,mUr,cUr,fUr,SR,gUr,BLe,hUr,uUr,pUr,ea,RR,_Ur,ILe,bUr,vUr,Tc,FUr,NLe,TUr,MUr,sae,EUr,CUr,wUr,Lw,AUr,Vr,PR,LUr,qLe,yUr,xUr,qn,$Ur,DLe,kUr,SUr,jLe,RUr,PUr,GLe,BUr,IUr,NUr,ye,yw,OLe,qUr,DUr,lae,jUr,GUr,OUr,xw,VLe,VUr,XUr,iae,zUr,QUr,WUr,$w,XLe,UUr,HUr,dae,JUr,YUr,ZUr,Rl,zLe,KUr,eHr,mae,oHr,rHr,cae,tHr,aHr,nHr,kw,QLe,sHr,lHr,fae,iHr,dHr,mHr,Sw,WLe,cHr,fHr,gae,gHr,hHr,uHr,Rw,ULe,pHr,_Hr,hae,bHr,vHr,FHr,Pw,HLe,THr,MHr,uae,EHr,CHr,wHr,Bw,JLe,AHr,LHr,pae,yHr,xHr,$Hr,Iw,YLe,kHr,SHr,_ae,RHr,PHr,BHr,Nw,Zao,Mc,qw,ZLe,BR,IHr,KLe,NHr,Kao,hr,IR,qHr,Ec,DHr,bae,jHr,GHr,vae,OHr,VHr,XHr,NR,zHr,eye,QHr,WHr,UHr,oa,qR,HHr,oye,JHr,YHr,Cc,ZHr,rye,KHr,eJr,Fae,oJr,rJr,tJr,Dw,aJr,Xr,DR,nJr,tye,sJr,lJr,Dn,iJr,aye,dJr,mJr,nye,cJr,fJr,sye,gJr,hJr,uJr,wc,jw,lye,pJr,_Jr,Tae,bJr,vJr,FJr,Gw,iye,TJr,MJr,Mae,EJr,CJr,wJr,Ow,dye,AJr,LJr,Eae,yJr,xJr,$Jr,Vw,eno,Ac,Xw,mye,jR,kJr,cye,SJr,ono,ur,GR,RJr,Lc,PJr,Cae,BJr,IJr,wae,NJr,qJr,DJr,OR,jJr,fye,GJr,OJr,VJr,ra,VR,XJr,gye,zJr,QJr,yc,WJr,hye,UJr,HJr,Aae,JJr,YJr,ZJr,zw,KJr,zr,XR,eYr,uye,oYr,rYr,jn,tYr,pye,aYr,nYr,_ye,sYr,lYr,bye,iYr,dYr,mYr,ce,Qw,vye,cYr,fYr,Lae,gYr,hYr,uYr,Ww,Fye,pYr,_Yr,yae,bYr,vYr,FYr,Uw,Tye,TYr,MYr,xae,EYr,CYr,wYr,Hw,Mye,AYr,LYr,$ae,yYr,xYr,$Yr,Jw,Eye,kYr,SYr,kae,RYr,PYr,BYr,Yw,Cye,IYr,NYr,Sae,qYr,DYr,jYr,Zw,wye,GYr,OYr,Rae,VYr,XYr,zYr,Kw,Aye,QYr,WYr,Pae,UYr,HYr,JYr,eA,Lye,YYr,ZYr,Bae,KYr,eZr,oZr,oA,yye,rZr,tZr,Iae,aZr,nZr,sZr,rA,xye,lZr,iZr,Nae,dZr,mZr,cZr,tA,$ye,fZr,gZr,qae,hZr,uZr,pZr,aA,kye,_Zr,bZr,Dae,vZr,FZr,TZr,nA,Sye,MZr,EZr,jae,CZr,wZr,AZr,sA,Rye,LZr,yZr,Gae,xZr,$Zr,kZr,lA,Pye,SZr,RZr,Oae,PZr,BZr,IZr,iA,Bye,NZr,qZr,Vae,DZr,jZr,GZr,dA,Iye,OZr,VZr,Xae,XZr,zZr,QZr,mA,Nye,WZr,UZr,zae,HZr,JZr,YZr,cA,qye,ZZr,KZr,Qae,eKr,oKr,rKr,fA,Dye,tKr,aKr,Wae,nKr,sKr,lKr,gA,rno,xc,hA,jye,zR,iKr,Gye,dKr,tno,pr,QR,mKr,$c,cKr,Uae,fKr,gKr,Hae,hKr,uKr,pKr,WR,_Kr,Oye,bKr,vKr,FKr,ta,UR,TKr,Vye,MKr,EKr,kc,CKr,Xye,wKr,AKr,Jae,LKr,yKr,xKr,uA,$Kr,Qr,HR,kKr,zye,SKr,RKr,Gn,PKr,Qye,BKr,IKr,Wye,NKr,qKr,Uye,DKr,jKr,GKr,xe,pA,Hye,OKr,VKr,Yae,XKr,zKr,QKr,_A,Jye,WKr,UKr,Zae,HKr,JKr,YKr,bA,Yye,ZKr,KKr,Kae,eet,oet,ret,vA,Zye,tet,aet,ene,net,set,iet,FA,Kye,det,met,one,cet,fet,get,TA,e9e,het,uet,rne,pet,_et,bet,MA,o9e,vet,Fet,tne,Tet,Met,Eet,EA,r9e,Cet,wet,ane,Aet,Let,yet,CA,t9e,xet,$et,nne,ket,Set,Ret,wA,a9e,Pet,Bet,sne,Iet,Net,qet,AA,ano,Sc,LA,n9e,JR,Det,s9e,jet,nno,_r,YR,Get,Rc,Oet,lne,Vet,Xet,ine,zet,Qet,Wet,ZR,Uet,l9e,Het,Jet,Yet,aa,KR,Zet,i9e,Ket,eot,Pc,oot,d9e,rot,tot,dne,aot,not,sot,yA,lot,Wr,eP,iot,m9e,dot,mot,On,cot,c9e,fot,got,f9e,hot,uot,g9e,pot,_ot,bot,re,xA,h9e,vot,Fot,mne,Tot,Mot,Eot,$A,u9e,Cot,wot,cne,Aot,Lot,yot,kA,p9e,xot,$ot,fne,kot,Sot,Rot,SA,_9e,Pot,Bot,gne,Iot,Not,qot,RA,b9e,Dot,jot,hne,Got,Oot,Vot,PA,v9e,Xot,zot,une,Qot,Wot,Uot,BA,F9e,Hot,Jot,pne,Yot,Zot,Kot,IA,T9e,ert,ort,_ne,rrt,trt,art,NA,M9e,nrt,srt,bne,lrt,irt,drt,qA,E9e,mrt,crt,vne,frt,grt,hrt,DA,C9e,urt,prt,Fne,_rt,brt,vrt,jA,w9e,Frt,Trt,Tne,Mrt,Ert,Crt,GA,A9e,wrt,Art,Mne,Lrt,yrt,xrt,OA,L9e,$rt,krt,Ene,Srt,Rrt,Prt,VA,y9e,Brt,Irt,Cne,Nrt,qrt,Drt,XA,x9e,jrt,Grt,wne,Ort,Vrt,Xrt,zA,$9e,zrt,Qrt,Ane,Wrt,Urt,Hrt,QA,k9e,Jrt,Yrt,Lne,Zrt,Krt,ett,WA,S9e,ott,rtt,yne,ttt,att,ntt,UA,R9e,stt,ltt,xne,itt,dtt,mtt,HA,P9e,ctt,ftt,$ne,gtt,htt,utt,JA,B9e,ptt,_tt,kne,btt,vtt,Ftt,YA,I9e,Ttt,Mtt,Sne,Ett,Ctt,wtt,ZA,N9e,Att,Ltt,Rne,ytt,xtt,$tt,KA,q9e,ktt,Stt,Pne,Rtt,Ptt,Btt,e6,D9e,Itt,Ntt,Bne,qtt,Dtt,jtt,o6,j9e,Gtt,Ott,Ine,Vtt,Xtt,ztt,r6,G9e,Qtt,Wtt,Nne,Utt,Htt,Jtt,t6,sno,Bc,a6,O9e,oP,Ytt,V9e,Ztt,lno,br,rP,Ktt,Ic,eat,qne,oat,rat,Dne,tat,aat,nat,tP,sat,X9e,lat,iat,dat,na,aP,mat,z9e,cat,fat,Nc,gat,Q9e,hat,uat,jne,pat,_at,bat,n6,vat,Ur,nP,Fat,W9e,Tat,Mat,Vn,Eat,U9e,Cat,wat,H9e,Aat,Lat,J9e,yat,xat,$at,ve,s6,Y9e,kat,Sat,Gne,Rat,Pat,Bat,l6,Z9e,Iat,Nat,One,qat,Dat,jat,i6,K9e,Gat,Oat,Vne,Vat,Xat,zat,d6,exe,Qat,Wat,Xne,Uat,Hat,Jat,m6,oxe,Yat,Zat,zne,Kat,ent,ont,c6,rxe,rnt,tnt,Qne,ant,nnt,snt,f6,txe,lnt,int,Wne,dnt,mnt,cnt,g6,axe,fnt,gnt,Une,hnt,unt,pnt,h6,nxe,_nt,bnt,Hne,vnt,Fnt,Tnt,u6,sxe,Mnt,Ent,Jne,Cnt,wnt,Ant,p6,lxe,Lnt,ynt,Yne,xnt,$nt,knt,_6,ixe,Snt,Rnt,Zne,Pnt,Bnt,Int,b6,dxe,Nnt,qnt,Kne,Dnt,jnt,Gnt,v6,mxe,Ont,Vnt,ese,Xnt,znt,Qnt,F6,cxe,Wnt,Unt,ose,Hnt,Jnt,Ynt,T6,fxe,Znt,Knt,rse,est,ost,rst,M6,gxe,tst,ast,tse,nst,sst,lst,E6,ino,qc,C6,hxe,sP,ist,uxe,dst,dno,vr,lP,mst,Dc,cst,ase,fst,gst,nse,hst,ust,pst,iP,_st,pxe,bst,vst,Fst,sa,dP,Tst,_xe,Mst,Est,jc,Cst,bxe,wst,Ast,sse,Lst,yst,xst,w6,$st,Hr,mP,kst,vxe,Sst,Rst,Xn,Pst,Fxe,Bst,Ist,Txe,Nst,qst,Mxe,Dst,jst,Gst,cP,A6,Exe,Ost,Vst,lse,Xst,zst,Qst,L6,Cxe,Wst,Ust,ise,Hst,Jst,Yst,y6,mno,Gc,x6,wxe,fP,Zst,Axe,Kst,cno,Fr,gP,elt,Oc,olt,dse,rlt,tlt,mse,alt,nlt,slt,hP,llt,Lxe,ilt,dlt,mlt,la,uP,clt,yxe,flt,glt,Vc,hlt,xxe,ult,plt,cse,_lt,blt,vlt,$6,Flt,Jr,pP,Tlt,$xe,Mlt,Elt,zn,Clt,kxe,wlt,Alt,Sxe,Llt,ylt,Rxe,xlt,$lt,klt,Pxe,k6,Bxe,Slt,Rlt,fse,Plt,Blt,Ilt,S6,fno,Xc,R6,Ixe,_P,Nlt,Nxe,qlt,gno,Tr,bP,Dlt,zc,jlt,gse,Glt,Olt,hse,Vlt,Xlt,zlt,vP,Qlt,qxe,Wlt,Ult,Hlt,ia,FP,Jlt,Dxe,Ylt,Zlt,Qc,Klt,jxe,eit,oit,use,rit,tit,ait,P6,nit,Yr,TP,sit,Gxe,lit,iit,Qn,dit,Oxe,mit,cit,Vxe,fit,git,Xxe,hit,uit,pit,zxe,B6,Qxe,_it,bit,pse,vit,Fit,Tit,I6,hno,Wc,N6,Wxe,MP,Mit,Uxe,Eit,uno,Mr,EP,Cit,Uc,wit,_se,Ait,Lit,bse,yit,xit,$it,CP,kit,Hxe,Sit,Rit,Pit,da,wP,Bit,Jxe,Iit,Nit,Hc,qit,Yxe,Dit,jit,vse,Git,Oit,Vit,q6,Xit,Zr,AP,zit,Zxe,Qit,Wit,Wn,Uit,Kxe,Hit,Jit,e$e,Yit,Zit,o$e,Kit,edt,odt,ie,D6,r$e,rdt,tdt,Fse,adt,ndt,sdt,j6,t$e,ldt,idt,Tse,ddt,mdt,cdt,G6,a$e,fdt,gdt,Mse,hdt,udt,pdt,O6,n$e,_dt,bdt,Ese,vdt,Fdt,Tdt,V6,s$e,Mdt,Edt,Cse,Cdt,wdt,Adt,X6,l$e,Ldt,ydt,wse,xdt,$dt,kdt,z6,i$e,Sdt,Rdt,Ase,Pdt,Bdt,Idt,Q6,d$e,Ndt,qdt,Lse,Ddt,jdt,Gdt,W6,m$e,Odt,Vdt,yse,Xdt,zdt,Qdt,U6,c$e,Wdt,Udt,xse,Hdt,Jdt,Ydt,H6,f$e,Zdt,Kdt,$se,emt,omt,rmt,J6,g$e,tmt,amt,kse,nmt,smt,lmt,Y6,h$e,imt,dmt,Sse,mmt,cmt,fmt,Z6,u$e,gmt,hmt,Rse,umt,pmt,_mt,K6,p$e,bmt,vmt,Pse,Fmt,Tmt,Mmt,e7,_$e,Emt,Cmt,Bse,wmt,Amt,Lmt,o7,b$e,ymt,xmt,Ise,$mt,kmt,Smt,r7,v$e,Rmt,Pmt,Nse,Bmt,Imt,Nmt,t7,F$e,qmt,Dmt,qse,jmt,Gmt,Omt,a7,T$e,Vmt,Xmt,Dse,zmt,Qmt,Wmt,n7,M$e,Umt,Hmt,jse,Jmt,Ymt,Zmt,s7,E$e,Kmt,ect,Gse,oct,rct,tct,l7,pno,Jc,i7,C$e,LP,act,w$e,nct,_no,Er,yP,sct,Yc,lct,Ose,ict,dct,Vse,mct,cct,fct,xP,gct,A$e,hct,uct,pct,ma,$P,_ct,L$e,bct,vct,Zc,Fct,y$e,Tct,Mct,Xse,Ect,Cct,wct,d7,Act,Kr,kP,Lct,x$e,yct,xct,Un,$ct,$$e,kct,Sct,k$e,Rct,Pct,S$e,Bct,Ict,Nct,fe,m7,R$e,qct,Dct,zse,jct,Gct,Oct,c7,P$e,Vct,Xct,Qse,zct,Qct,Wct,f7,B$e,Uct,Hct,Wse,Jct,Yct,Zct,g7,I$e,Kct,eft,Use,oft,rft,tft,h7,N$e,aft,nft,Hse,sft,lft,ift,u7,q$e,dft,mft,Jse,cft,fft,gft,p7,D$e,hft,uft,Yse,pft,_ft,bft,_7,j$e,vft,Fft,Zse,Tft,Mft,Eft,b7,G$e,Cft,wft,Kse,Aft,Lft,yft,v7,O$e,xft,$ft,ele,kft,Sft,Rft,F7,V$e,Pft,Bft,ole,Ift,Nft,qft,T7,X$e,Dft,jft,rle,Gft,Oft,Vft,M7,z$e,Xft,zft,tle,Qft,Wft,Uft,E7,Q$e,Hft,Jft,ale,Yft,Zft,Kft,C7,W$e,egt,ogt,nle,rgt,tgt,agt,w7,U$e,ngt,sgt,sle,lgt,igt,dgt,A7,H$e,mgt,cgt,lle,fgt,ggt,hgt,L7,J$e,ugt,pgt,ile,_gt,bgt,vgt,y7,Y$e,Fgt,Tgt,dle,Mgt,Egt,Cgt,x7,Z$e,wgt,Agt,mle,Lgt,ygt,xgt,$7,K$e,$gt,kgt,cle,Sgt,Rgt,Pgt,k7,bno,Kc,S7,eke,SP,Bgt,oke,Igt,vno,Cr,RP,Ngt,ef,qgt,fle,Dgt,jgt,gle,Ggt,Ogt,Vgt,PP,Xgt,rke,zgt,Qgt,Wgt,ca,BP,Ugt,tke,Hgt,Jgt,of,Ygt,ake,Zgt,Kgt,hle,eht,oht,rht,R7,tht,et,IP,aht,nke,nht,sht,Hn,lht,ske,iht,dht,lke,mht,cht,ike,fht,ght,hht,dke,P7,mke,uht,pht,ule,_ht,bht,vht,B7,Fno,rf,I7,cke,NP,Fht,fke,Tht,Tno,wr,qP,Mht,tf,Eht,ple,Cht,wht,_le,Aht,Lht,yht,DP,xht,gke,$ht,kht,Sht,fa,jP,Rht,hke,Pht,Bht,af,Iht,uke,Nht,qht,ble,Dht,jht,Ght,N7,Oht,ot,GP,Vht,pke,Xht,zht,Jn,Qht,_ke,Wht,Uht,bke,Hht,Jht,vke,Yht,Zht,Kht,OP,q7,Fke,eut,out,vle,rut,tut,aut,D7,Tke,nut,sut,Fle,lut,iut,dut,j7,Mno,nf,G7,Mke,VP,mut,Eke,cut,Eno,Ar,XP,fut,sf,gut,Tle,hut,uut,Mle,put,_ut,but,zP,vut,Cke,Fut,Tut,Mut,ga,QP,Eut,wke,Cut,wut,lf,Aut,Ake,Lut,yut,Ele,xut,$ut,kut,O7,Sut,rt,WP,Rut,Lke,Put,But,Yn,Iut,yke,Nut,qut,xke,Dut,jut,$ke,Gut,Out,Vut,te,V7,kke,Xut,zut,Cle,Qut,Wut,Uut,X7,Ske,Hut,Jut,wle,Yut,Zut,Kut,z7,Rke,ept,opt,Ale,rpt,tpt,apt,Q7,Pke,npt,spt,Lle,lpt,ipt,dpt,W7,Bke,mpt,cpt,yle,fpt,gpt,hpt,U7,Ike,upt,ppt,xle,_pt,bpt,vpt,H7,Nke,Fpt,Tpt,$le,Mpt,Ept,Cpt,J7,qke,wpt,Apt,kle,Lpt,ypt,xpt,Y7,Dke,$pt,kpt,Sle,Spt,Rpt,Ppt,Z7,jke,Bpt,Ipt,Rle,Npt,qpt,Dpt,K7,Gke,jpt,Gpt,Ple,Opt,Vpt,Xpt,e8,Oke,zpt,Qpt,Ble,Wpt,Upt,Hpt,o8,Vke,Jpt,Ypt,Ile,Zpt,Kpt,e_t,r8,Xke,o_t,r_t,Nle,t_t,a_t,n_t,t8,zke,s_t,l_t,qle,i_t,d_t,m_t,a8,Qke,c_t,f_t,Dle,g_t,h_t,u_t,n8,Wke,p_t,__t,jle,b_t,v_t,F_t,s8,Uke,T_t,M_t,Gle,E_t,C_t,w_t,l8,Hke,A_t,L_t,Ole,y_t,x_t,$_t,i8,Jke,k_t,S_t,Vle,R_t,P_t,B_t,d8,Yke,I_t,N_t,Xle,q_t,D_t,j_t,m8,Zke,G_t,O_t,zle,V_t,X_t,z_t,c8,Kke,Q_t,W_t,Qle,U_t,H_t,J_t,f8,eSe,Y_t,Z_t,Wle,K_t,e1t,o1t,g8,oSe,r1t,t1t,Ule,a1t,n1t,s1t,h8,rSe,l1t,i1t,Hle,d1t,m1t,c1t,u8,tSe,f1t,g1t,Jle,h1t,u1t,p1t,p8,Cno,df,_8,aSe,UP,_1t,nSe,b1t,wno,Lr,HP,v1t,mf,F1t,Yle,T1t,M1t,Zle,E1t,C1t,w1t,JP,A1t,sSe,L1t,y1t,x1t,ha,YP,$1t,lSe,k1t,S1t,cf,R1t,iSe,P1t,B1t,Kle,I1t,N1t,q1t,b8,D1t,tt,ZP,j1t,dSe,G1t,O1t,Zn,V1t,mSe,X1t,z1t,cSe,Q1t,W1t,fSe,U1t,H1t,J1t,$e,v8,gSe,Y1t,Z1t,eie,K1t,e2t,o2t,F8,hSe,r2t,t2t,oie,a2t,n2t,s2t,T8,uSe,l2t,i2t,rie,d2t,m2t,c2t,M8,pSe,f2t,g2t,tie,h2t,u2t,p2t,E8,_Se,_2t,b2t,aie,v2t,F2t,T2t,C8,bSe,M2t,E2t,nie,C2t,w2t,A2t,w8,vSe,L2t,y2t,sie,x2t,$2t,k2t,A8,FSe,S2t,R2t,lie,P2t,B2t,I2t,L8,TSe,N2t,q2t,iie,D2t,j2t,G2t,y8,MSe,O2t,V2t,die,X2t,z2t,Q2t,x8,Ano,ff,$8,ESe,KP,W2t,CSe,U2t,Lno,yr,eB,H2t,gf,J2t,mie,Y2t,Z2t,cie,K2t,ebt,obt,oB,rbt,wSe,tbt,abt,nbt,ua,rB,sbt,ASe,lbt,ibt,hf,dbt,LSe,mbt,cbt,fie,fbt,gbt,hbt,k8,ubt,at,tB,pbt,ySe,_bt,bbt,Kn,vbt,xSe,Fbt,Tbt,$Se,Mbt,Ebt,kSe,Cbt,wbt,Abt,Ee,S8,SSe,Lbt,ybt,gie,xbt,$bt,kbt,R8,RSe,Sbt,Rbt,hie,Pbt,Bbt,Ibt,P8,PSe,Nbt,qbt,uie,Dbt,jbt,Gbt,B8,BSe,Obt,Vbt,pie,Xbt,zbt,Qbt,I8,ISe,Wbt,Ubt,_ie,Hbt,Jbt,Ybt,N8,NSe,Zbt,Kbt,bie,evt,ovt,rvt,q8,qSe,tvt,avt,vie,nvt,svt,lvt,D8,DSe,ivt,dvt,Fie,mvt,cvt,fvt,j8,jSe,gvt,hvt,Tie,uvt,pvt,_vt,G8,GSe,bvt,vvt,Mie,Fvt,Tvt,Mvt,O8,OSe,Evt,Cvt,Eie,wvt,Avt,Lvt,V8,VSe,yvt,xvt,Cie,$vt,kvt,Svt,X8,XSe,Rvt,Pvt,wie,Bvt,Ivt,Nvt,z8,yno,uf,Q8,zSe,aB,qvt,QSe,Dvt,xno,xr,nB,jvt,pf,Gvt,Aie,Ovt,Vvt,Lie,Xvt,zvt,Qvt,sB,Wvt,WSe,Uvt,Hvt,Jvt,pa,lB,Yvt,USe,Zvt,Kvt,_f,eFt,HSe,oFt,rFt,yie,tFt,aFt,nFt,W8,sFt,nt,iB,lFt,JSe,iFt,dFt,es,mFt,YSe,cFt,fFt,ZSe,gFt,hFt,KSe,uFt,pFt,_Ft,ke,U8,eRe,bFt,vFt,xie,FFt,TFt,MFt,H8,oRe,EFt,CFt,$ie,wFt,AFt,LFt,J8,rRe,yFt,xFt,kie,$Ft,kFt,SFt,Y8,tRe,RFt,PFt,Sie,BFt,IFt,NFt,Z8,aRe,qFt,DFt,Rie,jFt,GFt,OFt,K8,nRe,VFt,XFt,Pie,zFt,QFt,WFt,eL,sRe,UFt,HFt,Bie,JFt,YFt,ZFt,oL,lRe,KFt,eTt,Iie,oTt,rTt,tTt,rL,iRe,aTt,nTt,Nie,sTt,lTt,iTt,tL,dRe,dTt,mTt,qie,cTt,fTt,gTt,aL,$no,bf,nL,mRe,dB,hTt,cRe,uTt,kno,$r,mB,pTt,vf,_Tt,Die,bTt,vTt,jie,FTt,TTt,MTt,cB,ETt,fRe,CTt,wTt,ATt,_a,fB,LTt,gRe,yTt,xTt,Ff,$Tt,hRe,kTt,STt,Gie,RTt,PTt,BTt,sL,ITt,st,gB,NTt,uRe,qTt,DTt,os,jTt,pRe,GTt,OTt,_Re,VTt,XTt,bRe,zTt,QTt,WTt,Se,lL,vRe,UTt,HTt,Oie,JTt,YTt,ZTt,iL,FRe,KTt,eMt,Vie,oMt,rMt,tMt,dL,TRe,aMt,nMt,Xie,sMt,lMt,iMt,mL,MRe,dMt,mMt,zie,cMt,fMt,gMt,cL,ERe,hMt,uMt,Qie,pMt,_Mt,bMt,fL,CRe,vMt,FMt,Wie,TMt,MMt,EMt,gL,wRe,CMt,wMt,Uie,AMt,LMt,yMt,hL,ARe,xMt,$Mt,Hie,kMt,SMt,RMt,uL,LRe,PMt,BMt,Jie,IMt,NMt,qMt,pL,yRe,DMt,jMt,Yie,GMt,OMt,VMt,_L,Sno,Tf,bL,xRe,hB,XMt,$Re,zMt,Rno,kr,uB,QMt,Mf,WMt,Zie,UMt,HMt,Kie,JMt,YMt,ZMt,pB,KMt,kRe,eEt,oEt,rEt,ba,_B,tEt,SRe,aEt,nEt,Ef,sEt,RRe,lEt,iEt,ede,dEt,mEt,cEt,vL,fEt,lt,bB,gEt,PRe,hEt,uEt,rs,pEt,BRe,_Et,bEt,IRe,vEt,FEt,NRe,TEt,MEt,EEt,Re,FL,qRe,CEt,wEt,ode,AEt,LEt,yEt,TL,DRe,xEt,$Et,rde,kEt,SEt,REt,ML,jRe,PEt,BEt,tde,IEt,NEt,qEt,EL,GRe,DEt,jEt,ade,GEt,OEt,VEt,CL,ORe,XEt,zEt,nde,QEt,WEt,UEt,wL,VRe,HEt,JEt,sde,YEt,ZEt,KEt,AL,XRe,e4t,o4t,lde,r4t,t4t,a4t,LL,zRe,n4t,s4t,ide,l4t,i4t,d4t,yL,QRe,m4t,c4t,dde,f4t,g4t,h4t,xL,WRe,u4t,p4t,mde,_4t,b4t,v4t,$L,Pno,Cf,kL,URe,vB,F4t,HRe,T4t,Bno,Sr,FB,M4t,wf,E4t,cde,C4t,w4t,fde,A4t,L4t,y4t,TB,x4t,JRe,$4t,k4t,S4t,va,MB,R4t,YRe,P4t,B4t,Af,I4t,ZRe,N4t,q4t,gde,D4t,j4t,G4t,SL,O4t,it,EB,V4t,KRe,X4t,z4t,ts,Q4t,ePe,W4t,U4t,oPe,H4t,J4t,rPe,Y4t,Z4t,K4t,Pe,RL,tPe,eCt,oCt,hde,rCt,tCt,aCt,PL,aPe,nCt,sCt,ude,lCt,iCt,dCt,BL,nPe,mCt,cCt,pde,fCt,gCt,hCt,IL,sPe,uCt,pCt,_de,_Ct,bCt,vCt,NL,lPe,FCt,TCt,bde,MCt,ECt,CCt,qL,iPe,wCt,ACt,vde,LCt,yCt,xCt,DL,dPe,$Ct,kCt,Fde,SCt,RCt,PCt,jL,mPe,BCt,ICt,Tde,NCt,qCt,DCt,GL,cPe,jCt,GCt,Mde,OCt,VCt,XCt,OL,fPe,zCt,QCt,Ede,WCt,UCt,HCt,VL,Ino,Lf,XL,gPe,CB,JCt,hPe,YCt,Nno,Rr,wB,ZCt,yf,KCt,Cde,e3t,o3t,wde,r3t,t3t,a3t,AB,n3t,uPe,s3t,l3t,i3t,Fa,LB,d3t,pPe,m3t,c3t,xf,f3t,_Pe,g3t,h3t,Ade,u3t,p3t,_3t,zL,b3t,dt,yB,v3t,bPe,F3t,T3t,as,M3t,vPe,E3t,C3t,FPe,w3t,A3t,TPe,L3t,y3t,x3t,ze,QL,MPe,$3t,k3t,Lde,S3t,R3t,P3t,WL,EPe,B3t,I3t,yde,N3t,q3t,D3t,UL,CPe,j3t,G3t,xde,O3t,V3t,X3t,HL,wPe,z3t,Q3t,$de,W3t,U3t,H3t,JL,APe,J3t,Y3t,kde,Z3t,K3t,e5t,YL,LPe,o5t,r5t,Sde,t5t,a5t,n5t,ZL,yPe,s5t,l5t,Rde,i5t,d5t,m5t,KL,xPe,c5t,f5t,Pde,g5t,h5t,u5t,ey,qno,$f,oy,$Pe,xB,p5t,kPe,_5t,Dno,Pr,$B,b5t,kf,v5t,Bde,F5t,T5t,Ide,M5t,E5t,C5t,kB,w5t,SPe,A5t,L5t,y5t,Ta,SB,x5t,RPe,$5t,k5t,Sf,S5t,PPe,R5t,P5t,Nde,B5t,I5t,N5t,ry,q5t,mt,RB,D5t,BPe,j5t,G5t,ns,O5t,IPe,V5t,X5t,NPe,z5t,Q5t,qPe,W5t,U5t,H5t,Qe,ty,DPe,J5t,Y5t,qde,Z5t,K5t,e0t,ay,jPe,o0t,r0t,Dde,t0t,a0t,n0t,ny,GPe,s0t,l0t,jde,i0t,d0t,m0t,sy,OPe,c0t,f0t,Gde,g0t,h0t,u0t,ly,VPe,p0t,_0t,Ode,b0t,v0t,F0t,iy,XPe,T0t,M0t,Vde,E0t,C0t,w0t,dy,zPe,A0t,L0t,Xde,y0t,x0t,$0t,my,QPe,k0t,S0t,zde,R0t,P0t,B0t,cy,jno,Rf,fy,WPe,PB,I0t,UPe,N0t,Gno,Br,BB,q0t,Pf,D0t,Qde,j0t,G0t,Wde,O0t,V0t,X0t,IB,z0t,HPe,Q0t,W0t,U0t,Ma,NB,H0t,JPe,J0t,Y0t,Bf,Z0t,YPe,K0t,ewt,Ude,owt,rwt,twt,gy,awt,ct,qB,nwt,ZPe,swt,lwt,ss,iwt,KPe,dwt,mwt,eBe,cwt,fwt,oBe,gwt,hwt,uwt,rBe,hy,tBe,pwt,_wt,Hde,bwt,vwt,Fwt,uy,Ono,If,py,aBe,DB,Twt,nBe,Mwt,Vno,Ir,jB,Ewt,Nf,Cwt,Jde,wwt,Awt,Yde,Lwt,ywt,xwt,GB,$wt,sBe,kwt,Swt,Rwt,Ea,OB,Pwt,lBe,Bwt,Iwt,qf,Nwt,iBe,qwt,Dwt,Zde,jwt,Gwt,Owt,_y,Vwt,ft,VB,Xwt,dBe,zwt,Qwt,ls,Wwt,mBe,Uwt,Hwt,cBe,Jwt,Ywt,fBe,Zwt,Kwt,eAt,XB,by,gBe,oAt,rAt,Kde,tAt,aAt,nAt,vy,hBe,sAt,lAt,eme,iAt,dAt,mAt,Fy,Xno,Df,Ty,uBe,zB,cAt,pBe,fAt,zno,Nr,QB,gAt,jf,hAt,ome,uAt,pAt,rme,_At,bAt,vAt,WB,FAt,_Be,TAt,MAt,EAt,Ca,UB,CAt,bBe,wAt,AAt,Gf,LAt,vBe,yAt,xAt,tme,$At,kAt,SAt,My,RAt,gt,HB,PAt,FBe,BAt,IAt,is,NAt,TBe,qAt,DAt,MBe,jAt,GAt,EBe,OAt,VAt,XAt,CBe,Ey,wBe,zAt,QAt,ame,WAt,UAt,HAt,Cy,Qno;return d=new oe({}),on=new B({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),m$=new oe({}),c$=new B({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Jf=new JAt({props:{warning:!0,$$slots:{default:[D3a]},$$scope:{ctx:$}}}),f$=new oe({}),g$=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L666"}}),p$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L689"}}),wu=new N({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[j3a]},$$scope:{ctx:$}}}),_$=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L812"}}),b$=new oe({}),v$=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L437"}}),M$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/main/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L451"}}),mp=new N({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[G3a]},$$scope:{ctx:$}}}),E$=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L652"}}),C$=new oe({}),w$=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L204"}}),y$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/main/en/internal/image_processing_utils#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L218"}}),t_=new JAt({props:{$$slots:{default:[O3a]},$$scope:{ctx:$}}}),a_=new N({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[V3a]},$$scope:{ctx:$}}}),x$=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L345"}}),$$=new oe({}),k$=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L96"}}),P$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L110"}}),$_=new JAt({props:{$$slots:{default:[X3a]},$$scope:{ctx:$}}}),k_=new N({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[z3a]},$$scope:{ctx:$}}}),B$=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L277"}}),I$=new oe({}),N$=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L887"}}),D$=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel">ConditionalDetrModel</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel">DeformableDetrModel</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig">DonutSwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel">DonutSwinModel</a> (DonutSwin model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel">ErnieModel</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmModel">EsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel">GPTNeoXJapaneseModel</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltModel">LiltModel</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel">MarkupLMModel</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel">MobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel">OwlViTModel</a> (OWL-ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel">PegasusXModel</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model">Swinv2Model</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig">TableTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerModel">TableTransformerModel</a> (Table Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig">TimeSeriesTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel">TimeSeriesTransformerModel</a> (Time Series Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel">ViTMSNModel</a> (ViTMSN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel">VideoMAEModel</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel">WhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig">XCLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel">XCLIPModel</a> (X-CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),P_=new N({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[Q3a]},$$scope:{ctx:$}}}),j$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),rb=new N({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[W3a]},$$scope:{ctx:$}}}),G$=new oe({}),O$=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L894"}}),X$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining">ErnieForPreTraining</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining">VideoMAEForPreTraining</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),ab=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[U3a]},$$scope:{ctx:$}}}),z$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ev=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[H3a]},$$scope:{ctx:$}}}),Q$=new oe({}),W$=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L909"}}),H$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM">ErnieForCausalLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM">GPTNeoXJapaneseForCausalLM</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),rv=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[J3a]},$$scope:{ctx:$}}}),J$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Qv=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Y3a]},$$scope:{ctx:$}}}),Y$=new oe({}),Z$=new R({props:{name:"class transformers.AutoModelForDepthEstimation",anchor:"transformers.AutoModelForDepthEstimation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1052"}}),ek=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDepthEstimation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDepthEstimation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForDepthEstimation">DPTForDepthEstimation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNForDepthEstimation">GLPNForDepthEstimation</a> (GLPN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Uv=new N({props:{anchor:"transformers.AutoModelForDepthEstimation.from_config.example",$$slots:{default:[Z3a]},$$scope:{ctx:$}}}),ok=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDepthEstimation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Zv=new N({props:{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.example",$$slots:{default:[K3a]},$$scope:{ctx:$}}}),tk=new oe({}),ak=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L916"}}),sk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM">ErnieForMaskedLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),eF=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[e5a]},$$scope:{ctx:$}}}),lk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),GF=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[o5a]},$$scope:{ctx:$}}}),ik=new oe({}),dk=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L923"}}),ck=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration">PegasusXForConditionalGeneration</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),VF=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[r5a]},$$scope:{ctx:$}}}),fk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),cT=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[t5a]},$$scope:{ctx:$}}}),gk=new oe({}),hk=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L932"}}),pk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification">ErnieForSequenceClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification">EsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForSequenceClassification">LiltForSequenceClassification</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification">LukeForSequenceClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification">MarkupLMForSequenceClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification">OPTForSequenceClassification</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),gT=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[a5a]},$$scope:{ctx:$}}}),_k=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),_M=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[n5a]},$$scope:{ctx:$}}}),bk=new oe({}),vk=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L988"}}),Tk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice">ErnieForMultipleChoice</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice">LukeForMultipleChoice</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),vM=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[s5a]},$$scope:{ctx:$}}}),Mk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),KM=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[l5a]},$$scope:{ctx:$}}}),Ek=new oe({}),Ck=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L995"}}),Ak=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction">ErnieForNextSentencePrediction</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),oE=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[i5a]},$$scope:{ctx:$}}}),Lk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),mE=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[d5a]},$$scope:{ctx:$}}}),yk=new oe({}),xk=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L981"}}),kk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification">ErnieForTokenClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification">EsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForTokenClassification">LiltForTokenClassification</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification">LukeForTokenClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification">MarkupLMForTokenClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),fE=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[m5a]},$$scope:{ctx:$}}}),Sk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),o4=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[c5a]},$$scope:{ctx:$}}}),Rk=new oe({}),Pk=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L941"}}),Ik=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering">BloomForQuestionAnswering</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering">ErnieForQuestionAnswering</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForQuestionAnswering">LiltForQuestionAnswering</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering">LukeForQuestionAnswering</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering">MarkupLMForQuestionAnswering</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForQuestionAnswering">OPTForQuestionAnswering</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),t4=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[f5a]},$$scope:{ctx:$}}}),Nk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),K4=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[g5a]},$$scope:{ctx:$}}}),qk=new oe({}),Dk=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L948"}}),Gk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),oC=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[h5a]},$$scope:{ctx:$}}}),Ok=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),aC=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[u5a]},$$scope:{ctx:$}}}),Vk=new oe({}),Xk=new R({props:{name:"class transformers.AutoModelForDocumentQuestionAnswering",anchor:"transformers.AutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L970"}}),Qk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering">LayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),sC=new N({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[p5a]},$$scope:{ctx:$}}}),Wk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),cC=new N({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[_5a]},$$scope:{ctx:$}}}),Uk=new oe({}),Hk=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1004"}}),Yk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification">MobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification">Swinv2ForImageClassification</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification">ViTMSNForImageClassification</a> (ViTMSN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),gC=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[b5a]},$$scope:{ctx:$}}}),Zk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),$C=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[v5a]},$$scope:{ctx:$}}}),Kk=new oe({}),eS=new R({props:{name:"class transformers.AutoModelForVideoClassification",anchor:"transformers.AutoModelForVideoClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1059"}}),rS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVideoClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification">VideoMAEForVideoClassification</a> (VideoMAE model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),SC=new N({props:{anchor:"transformers.AutoModelForVideoClassification.from_config.example",$$slots:{default:[F5a]},$$scope:{ctx:$}}}),tS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVideoClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),BC=new N({props:{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.example",$$slots:{default:[T5a]},$$scope:{ctx:$}}}),aS=new oe({}),nS=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1066"}}),lS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),NC=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[M5a]},$$scope:{ctx:$}}}),iS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),jC=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[E5a]},$$scope:{ctx:$}}}),dS=new oe({}),mS=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L959"}}),fS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),OC=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[C5a]},$$scope:{ctx:$}}}),gS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),zC=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[w5a]},$$scope:{ctx:$}}}),hS=new oe({}),uS=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1073"}}),_S=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),WC=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[A5a]},$$scope:{ctx:$}}}),bS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),a3=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[L5a]},$$scope:{ctx:$}}}),vS=new oe({}),FS=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1096"}}),MS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),s3=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[y5a]},$$scope:{ctx:$}}}),ES=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),g3=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[x5a]},$$scope:{ctx:$}}}),CS=new oe({}),wS=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1080"}}),LS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),u3=new N({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[$5a]},$$scope:{ctx:$}}}),yS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),L3=new N({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[k5a]},$$scope:{ctx:$}}}),xS=new oe({}),$S=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1087"}}),SS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration">WhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),x3=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[S5a]},$$scope:{ctx:$}}}),RS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),P3=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[R5a]},$$scope:{ctx:$}}}),PS=new oe({}),BS=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1105"}}),NS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),I3=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[P5a]},$$scope:{ctx:$}}}),qS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),V3=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[B5a]},$$scope:{ctx:$}}}),DS=new oe({}),jS=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1112"}}),OS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling">Swinv2ForMaskedImageModeling</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),z3=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[I5a]},$$scope:{ctx:$}}}),VS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Y3=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[N5a]},$$scope:{ctx:$}}}),XS=new oe({}),zS=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1036"}}),WS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection">ConditionalDetrForObjectDetection</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection">DeformableDetrForObjectDetection</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig">TableTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection">TableTransformerForObjectDetection</a> (Table Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),K3=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[q5a]},$$scope:{ctx:$}}}),US=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),s5=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[D5a]},$$scope:{ctx:$}}}),HS=new oe({}),JS=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1011"}}),ZS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),i5=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[j5a]},$$scope:{ctx:$}}}),KS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),c5=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[G5a]},$$scope:{ctx:$}}}),eR=new oe({}),oR=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1018"}}),tR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation">MobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),g5=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[O5a]},$$scope:{ctx:$}}}),aR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),F5=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[V5a]},$$scope:{ctx:$}}}),nR=new oe({}),sR=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1027"}}),iR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),M5=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[X5a]},$$scope:{ctx:$}}}),dR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),w5=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[z5a]},$$scope:{ctx:$}}}),mR=new oe({}),cR=new R({props:{name:"class transformers.AutoModelForZeroShotObjectDetection",anchor:"transformers.AutoModelForZeroShotObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1043"}}),gR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTForObjectDetection">OwlViTForObjectDetection</a> (OWL-ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),L5=new N({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.example",$$slots:{default:[Q5a]},$$scope:{ctx:$}}}),hR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),$5=new N({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.example",$$slots:{default:[W5a]},$$scope:{ctx:$}}}),uR=new oe({}),pR=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L444"}}),bR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtModel">TFCvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel">TFDeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmModel">TFEsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel">TFGroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model">TFLayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel">TFMobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel">TFSegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperModel">TFWhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel">TFXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),S5=new N({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[U5a]},$$scope:{ctx:$}}}),vR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),I0=new N({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[H5a]},$$scope:{ctx:$}}}),FR=new oe({}),TR=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L451"}}),ER=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),q0=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[J5a]},$$scope:{ctx:$}}}),CR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),iw=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[Y5a]},$$scope:{ctx:$}}}),wR=new oe({}),AR=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L466"}}),yR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM">TFXGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),mw=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[Z5a]},$$scope:{ctx:$}}}),xR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ww=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[K5a]},$$scope:{ctx:$}}}),$R=new oe({}),kR=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L482"}}),RR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtForImageClassification">TFCvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification">TFDeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher">TFDeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification">TFMobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification">TFSegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Lw=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[e0a]},$$scope:{ctx:$}}}),PR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Nw=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[o0a]},$$scope:{ctx:$}}}),BR=new oe({}),IR=new R({props:{name:"class transformers.TFAutoModelForSemanticSegmentation",anchor:"transformers.TFAutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L491"}}),qR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation">TFData2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation">TFMobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation">TFSegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Dw=new N({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[r0a]},$$scope:{ctx:$}}}),DR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Vw=new N({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[t0a]},$$scope:{ctx:$}}}),jR=new oe({}),GR=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L507"}}),VR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForMaskedLM">TFEsmForMaskedLM</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),zw=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[a0a]},$$scope:{ctx:$}}}),XR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),gA=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[n0a]},$$scope:{ctx:$}}}),zR=new oe({}),QR=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L514"}}),UR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),uA=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[s0a]},$$scope:{ctx:$}}}),HR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),AA=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[l0a]},$$scope:{ctx:$}}}),JR=new oe({}),YR=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L523"}}),KR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForSequenceClassification">TFEsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification">TFLayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),yA=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[i0a]},$$scope:{ctx:$}}}),eP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),t6=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[d0a]},$$scope:{ctx:$}}}),oP=new oe({}),rP=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L570"}}),aP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),n6=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[m0a]},$$scope:{ctx:$}}}),nP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),E6=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[c0a]},$$scope:{ctx:$}}}),sP=new oe({}),lP=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L577"}}),dP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),w6=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[f0a]},$$scope:{ctx:$}}}),mP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),y6=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[g0a]},$$scope:{ctx:$}}}),fP=new oe({}),gP=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L550"}}),uP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),$6=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[h0a]},$$scope:{ctx:$}}}),pP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),S6=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[u0a]},$$scope:{ctx:$}}}),_P=new oe({}),bP=new R({props:{name:"class transformers.TFAutoModelForDocumentQuestionAnswering",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L539"}}),FP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering">TFLayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),P6=new N({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[p0a]},$$scope:{ctx:$}}}),TP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),I6=new N({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[_0a]},$$scope:{ctx:$}}}),MP=new oe({}),EP=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L561"}}),wP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForTokenClassification">TFEsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification">TFLayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),q6=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[b0a]},$$scope:{ctx:$}}}),AP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),l7=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[v0a]},$$scope:{ctx:$}}}),LP=new oe({}),yP=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L532"}}),$P=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering">TFLayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),d7=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[F0a]},$$scope:{ctx:$}}}),kP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),k7=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[T0a]},$$scope:{ctx:$}}}),SP=new oe({}),RP=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L500"}}),BP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),R7=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[M0a]},$$scope:{ctx:$}}}),IP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),B7=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[E0a]},$$scope:{ctx:$}}}),NP=new oe({}),qP=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L586"}}),jP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration">TFWhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),N7=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[C0a]},$$scope:{ctx:$}}}),GP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),j7=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[w0a]},$$scope:{ctx:$}}}),VP=new oe({}),XP=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),QP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),O7=new N({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[A0a]},$$scope:{ctx:$}}}),WP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),p8=new N({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[L0a]},$$scope:{ctx:$}}}),UP=new oe({}),HP=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),YP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),b8=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[y0a]},$$scope:{ctx:$}}}),ZP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),x8=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[x0a]},$$scope:{ctx:$}}}),KP=new oe({}),eB=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),rB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),k8=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[$0a]},$$scope:{ctx:$}}}),tB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),z8=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[k0a]},$$scope:{ctx:$}}}),aB=new oe({}),nB=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),lB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),W8=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[S0a]},$$scope:{ctx:$}}}),iB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),aL=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[R0a]},$$scope:{ctx:$}}}),dB=new oe({}),mB=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),fB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),sL=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[P0a]},$$scope:{ctx:$}}}),gB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),_L=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[B0a]},$$scope:{ctx:$}}}),hB=new oe({}),uB=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),_B=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),vL=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[I0a]},$$scope:{ctx:$}}}),bB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),$L=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[N0a]},$$scope:{ctx:$}}}),vB=new oe({}),FB=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),MB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),SL=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[q0a]},$$scope:{ctx:$}}}),EB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),VL=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[D0a]},$$scope:{ctx:$}}}),CB=new oe({}),wB=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),LB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),zL=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[j0a]},$$scope:{ctx:$}}}),yB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ey=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[G0a]},$$scope:{ctx:$}}}),xB=new oe({}),$B=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),SB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),ry=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[O0a]},$$scope:{ctx:$}}}),RB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),cy=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[V0a]},$$scope:{ctx:$}}}),PB=new oe({}),BB=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),NB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),gy=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[X0a]},$$scope:{ctx:$}}}),qB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),uy=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[z0a]},$$scope:{ctx:$}}}),DB=new oe({}),jB=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),OB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),_y=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[Q0a]},$$scope:{ctx:$}}}),VB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Fy=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[W0a]},$$scope:{ctx:$}}}),zB=new oe({}),QB=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),UB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),My=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[U0a]},$$scope:{ctx:$}}}),HB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Cy=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[H0a]},$$scope:{ctx:$}}}),{c(){g=a("meta"),v=l(),u=a("h1"),f=a("a"),p=a("span"),F(d.$$.fragment),h=l(),$o=a("span"),bd=o("Auto Classes"),zf=l(),Tt=a("p"),vd=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Fd=a("code"),s$=o("from_pretrained()"),Qf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Xe=l(),He=a("p"),Td=o("Instantiating one of "),ms=a("a"),l$=o("AutoConfig"),cs=o(", "),fs=a("a"),i$=o("AutoModel"),Md=o(`, and
`),gs=a("a"),d$=o("AutoTokenizer"),Ed=o(" will directly create a class of the relevant architecture. For instance"),Wf=l(),F(on.$$.fragment),Je=l(),Ae=a("p"),EN=o("will create a model that is an instance of "),Cd=a("a"),CN=o("BertModel"),wN=o("."),ko=l(),rn=a("p"),AN=o("There is one class of "),Uf=a("code"),LN=o("AutoModel"),hio=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),xto=l(),wd=a("h2"),Hf=a("a"),gfe=a("span"),F(m$.$$.fragment),uio=l(),hfe=a("span"),pio=o("Extending the Auto Classes"),$to=l(),hs=a("p"),_io=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),ufe=a("code"),bio=o("NewModel"),vio=o(", make sure you have a "),pfe=a("code"),Fio=o("NewModelConfig"),Tio=o(` then you can add those to the auto
classes like this:`),kto=l(),F(c$.$$.fragment),Sto=l(),yN=a("p"),Mio=o("You will then be able to use the auto classes like you would usually do!"),Rto=l(),F(Jf.$$.fragment),Pto=l(),Ad=a("h2"),Yf=a("a"),_fe=a("span"),F(f$.$$.fragment),Eio=l(),bfe=a("span"),Cio=o("AutoConfig"),Bto=l(),So=a("div"),F(g$.$$.fragment),wio=l(),h$=a("p"),Aio=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),xN=a("a"),Lio=o("from_pretrained()"),yio=o(" class method."),xio=l(),u$=a("p"),$io=o("This class cannot be instantiated directly using "),vfe=a("code"),kio=o("__init__()"),Sio=o(" (throws an error)."),Rio=l(),qr=a("div"),F(p$.$$.fragment),Pio=l(),Ffe=a("p"),Bio=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),Iio=l(),Ld=a("p"),Nio=o("The configuration class to instantiate is selected based on the "),Tfe=a("code"),qio=o("model_type"),Dio=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Mfe=a("code"),jio=o("pretrained_model_name_or_path"),Gio=o(":"),Oio=l(),A=a("ul"),Zf=a("li"),Efe=a("strong"),Vio=o("albert"),Xio=o(" \u2014 "),$N=a("a"),zio=o("AlbertConfig"),Qio=o(" (ALBERT model)"),Wio=l(),Kf=a("li"),Cfe=a("strong"),Uio=o("bart"),Hio=o(" \u2014 "),kN=a("a"),Jio=o("BartConfig"),Yio=o(" (BART model)"),Zio=l(),eg=a("li"),wfe=a("strong"),Kio=o("beit"),edo=o(" \u2014 "),SN=a("a"),odo=o("BeitConfig"),rdo=o(" (BEiT model)"),tdo=l(),og=a("li"),Afe=a("strong"),ado=o("bert"),ndo=o(" \u2014 "),RN=a("a"),sdo=o("BertConfig"),ldo=o(" (BERT model)"),ido=l(),rg=a("li"),Lfe=a("strong"),ddo=o("bert-generation"),mdo=o(" \u2014 "),PN=a("a"),cdo=o("BertGenerationConfig"),fdo=o(" (Bert Generation model)"),gdo=l(),tg=a("li"),yfe=a("strong"),hdo=o("big_bird"),udo=o(" \u2014 "),BN=a("a"),pdo=o("BigBirdConfig"),_do=o(" (BigBird model)"),bdo=l(),ag=a("li"),xfe=a("strong"),vdo=o("bigbird_pegasus"),Fdo=o(" \u2014 "),IN=a("a"),Tdo=o("BigBirdPegasusConfig"),Mdo=o(" (BigBird-Pegasus model)"),Edo=l(),ng=a("li"),$fe=a("strong"),Cdo=o("blenderbot"),wdo=o(" \u2014 "),NN=a("a"),Ado=o("BlenderbotConfig"),Ldo=o(" (Blenderbot model)"),ydo=l(),sg=a("li"),kfe=a("strong"),xdo=o("blenderbot-small"),$do=o(" \u2014 "),qN=a("a"),kdo=o("BlenderbotSmallConfig"),Sdo=o(" (BlenderbotSmall model)"),Rdo=l(),lg=a("li"),Sfe=a("strong"),Pdo=o("bloom"),Bdo=o(" \u2014 "),DN=a("a"),Ido=o("BloomConfig"),Ndo=o(" (BLOOM model)"),qdo=l(),ig=a("li"),Rfe=a("strong"),Ddo=o("camembert"),jdo=o(" \u2014 "),jN=a("a"),Gdo=o("CamembertConfig"),Odo=o(" (CamemBERT model)"),Vdo=l(),dg=a("li"),Pfe=a("strong"),Xdo=o("canine"),zdo=o(" \u2014 "),GN=a("a"),Qdo=o("CanineConfig"),Wdo=o(" (CANINE model)"),Udo=l(),mg=a("li"),Bfe=a("strong"),Hdo=o("clip"),Jdo=o(" \u2014 "),ON=a("a"),Ydo=o("CLIPConfig"),Zdo=o(" (CLIP model)"),Kdo=l(),cg=a("li"),Ife=a("strong"),emo=o("codegen"),omo=o(" \u2014 "),VN=a("a"),rmo=o("CodeGenConfig"),tmo=o(" (CodeGen model)"),amo=l(),fg=a("li"),Nfe=a("strong"),nmo=o("conditional_detr"),smo=o(" \u2014 "),XN=a("a"),lmo=o("ConditionalDetrConfig"),imo=o(" (Conditional DETR model)"),dmo=l(),gg=a("li"),qfe=a("strong"),mmo=o("convbert"),cmo=o(" \u2014 "),zN=a("a"),fmo=o("ConvBertConfig"),gmo=o(" (ConvBERT model)"),hmo=l(),hg=a("li"),Dfe=a("strong"),umo=o("convnext"),pmo=o(" \u2014 "),QN=a("a"),_mo=o("ConvNextConfig"),bmo=o(" (ConvNeXT model)"),vmo=l(),ug=a("li"),jfe=a("strong"),Fmo=o("ctrl"),Tmo=o(" \u2014 "),WN=a("a"),Mmo=o("CTRLConfig"),Emo=o(" (CTRL model)"),Cmo=l(),pg=a("li"),Gfe=a("strong"),wmo=o("cvt"),Amo=o(" \u2014 "),UN=a("a"),Lmo=o("CvtConfig"),ymo=o(" (CvT model)"),xmo=l(),_g=a("li"),Ofe=a("strong"),$mo=o("data2vec-audio"),kmo=o(" \u2014 "),HN=a("a"),Smo=o("Data2VecAudioConfig"),Rmo=o(" (Data2VecAudio model)"),Pmo=l(),bg=a("li"),Vfe=a("strong"),Bmo=o("data2vec-text"),Imo=o(" \u2014 "),JN=a("a"),Nmo=o("Data2VecTextConfig"),qmo=o(" (Data2VecText model)"),Dmo=l(),vg=a("li"),Xfe=a("strong"),jmo=o("data2vec-vision"),Gmo=o(" \u2014 "),YN=a("a"),Omo=o("Data2VecVisionConfig"),Vmo=o(" (Data2VecVision model)"),Xmo=l(),Fg=a("li"),zfe=a("strong"),zmo=o("deberta"),Qmo=o(" \u2014 "),ZN=a("a"),Wmo=o("DebertaConfig"),Umo=o(" (DeBERTa model)"),Hmo=l(),Tg=a("li"),Qfe=a("strong"),Jmo=o("deberta-v2"),Ymo=o(" \u2014 "),KN=a("a"),Zmo=o("DebertaV2Config"),Kmo=o(" (DeBERTa-v2 model)"),eco=l(),Mg=a("li"),Wfe=a("strong"),oco=o("decision_transformer"),rco=o(" \u2014 "),eq=a("a"),tco=o("DecisionTransformerConfig"),aco=o(" (Decision Transformer model)"),nco=l(),Eg=a("li"),Ufe=a("strong"),sco=o("deformable_detr"),lco=o(" \u2014 "),oq=a("a"),ico=o("DeformableDetrConfig"),dco=o(" (Deformable DETR model)"),mco=l(),Cg=a("li"),Hfe=a("strong"),cco=o("deit"),fco=o(" \u2014 "),rq=a("a"),gco=o("DeiTConfig"),hco=o(" (DeiT model)"),uco=l(),wg=a("li"),Jfe=a("strong"),pco=o("detr"),_co=o(" \u2014 "),tq=a("a"),bco=o("DetrConfig"),vco=o(" (DETR model)"),Fco=l(),Ag=a("li"),Yfe=a("strong"),Tco=o("distilbert"),Mco=o(" \u2014 "),aq=a("a"),Eco=o("DistilBertConfig"),Cco=o(" (DistilBERT model)"),wco=l(),Lg=a("li"),Zfe=a("strong"),Aco=o("donut-swin"),Lco=o(" \u2014 "),nq=a("a"),yco=o("DonutSwinConfig"),xco=o(" (DonutSwin model)"),$co=l(),yg=a("li"),Kfe=a("strong"),kco=o("dpr"),Sco=o(" \u2014 "),sq=a("a"),Rco=o("DPRConfig"),Pco=o(" (DPR model)"),Bco=l(),xg=a("li"),ege=a("strong"),Ico=o("dpt"),Nco=o(" \u2014 "),lq=a("a"),qco=o("DPTConfig"),Dco=o(" (DPT model)"),jco=l(),$g=a("li"),oge=a("strong"),Gco=o("electra"),Oco=o(" \u2014 "),iq=a("a"),Vco=o("ElectraConfig"),Xco=o(" (ELECTRA model)"),zco=l(),kg=a("li"),rge=a("strong"),Qco=o("encoder-decoder"),Wco=o(" \u2014 "),dq=a("a"),Uco=o("EncoderDecoderConfig"),Hco=o(" (Encoder decoder model)"),Jco=l(),Sg=a("li"),tge=a("strong"),Yco=o("ernie"),Zco=o(" \u2014 "),mq=a("a"),Kco=o("ErnieConfig"),efo=o(" (ERNIE model)"),ofo=l(),Rg=a("li"),age=a("strong"),rfo=o("esm"),tfo=o(" \u2014 "),cq=a("a"),afo=o("EsmConfig"),nfo=o(" (ESM model)"),sfo=l(),Pg=a("li"),nge=a("strong"),lfo=o("flaubert"),ifo=o(" \u2014 "),fq=a("a"),dfo=o("FlaubertConfig"),mfo=o(" (FlauBERT model)"),cfo=l(),Bg=a("li"),sge=a("strong"),ffo=o("flava"),gfo=o(" \u2014 "),gq=a("a"),hfo=o("FlavaConfig"),ufo=o(" (FLAVA model)"),pfo=l(),Ig=a("li"),lge=a("strong"),_fo=o("fnet"),bfo=o(" \u2014 "),hq=a("a"),vfo=o("FNetConfig"),Ffo=o(" (FNet model)"),Tfo=l(),Ng=a("li"),ige=a("strong"),Mfo=o("fsmt"),Efo=o(" \u2014 "),uq=a("a"),Cfo=o("FSMTConfig"),wfo=o(" (FairSeq Machine-Translation model)"),Afo=l(),qg=a("li"),dge=a("strong"),Lfo=o("funnel"),yfo=o(" \u2014 "),pq=a("a"),xfo=o("FunnelConfig"),$fo=o(" (Funnel Transformer model)"),kfo=l(),Dg=a("li"),mge=a("strong"),Sfo=o("glpn"),Rfo=o(" \u2014 "),_q=a("a"),Pfo=o("GLPNConfig"),Bfo=o(" (GLPN model)"),Ifo=l(),jg=a("li"),cge=a("strong"),Nfo=o("gpt2"),qfo=o(" \u2014 "),bq=a("a"),Dfo=o("GPT2Config"),jfo=o(" (OpenAI GPT-2 model)"),Gfo=l(),Gg=a("li"),fge=a("strong"),Ofo=o("gpt_neo"),Vfo=o(" \u2014 "),vq=a("a"),Xfo=o("GPTNeoConfig"),zfo=o(" (GPT Neo model)"),Qfo=l(),Og=a("li"),gge=a("strong"),Wfo=o("gpt_neox"),Ufo=o(" \u2014 "),Fq=a("a"),Hfo=o("GPTNeoXConfig"),Jfo=o(" (GPT NeoX model)"),Yfo=l(),Vg=a("li"),hge=a("strong"),Zfo=o("gpt_neox_japanese"),Kfo=o(" \u2014 "),Tq=a("a"),ego=o("GPTNeoXJapaneseConfig"),ogo=o(" (GPT NeoX Japanese model)"),rgo=l(),Xg=a("li"),uge=a("strong"),tgo=o("gptj"),ago=o(" \u2014 "),Mq=a("a"),ngo=o("GPTJConfig"),sgo=o(" (GPT-J model)"),lgo=l(),zg=a("li"),pge=a("strong"),igo=o("groupvit"),dgo=o(" \u2014 "),Eq=a("a"),mgo=o("GroupViTConfig"),cgo=o(" (GroupViT model)"),fgo=l(),Qg=a("li"),_ge=a("strong"),ggo=o("hubert"),hgo=o(" \u2014 "),Cq=a("a"),ugo=o("HubertConfig"),pgo=o(" (Hubert model)"),_go=l(),Wg=a("li"),bge=a("strong"),bgo=o("ibert"),vgo=o(" \u2014 "),wq=a("a"),Fgo=o("IBertConfig"),Tgo=o(" (I-BERT model)"),Mgo=l(),Ug=a("li"),vge=a("strong"),Ego=o("imagegpt"),Cgo=o(" \u2014 "),Aq=a("a"),wgo=o("ImageGPTConfig"),Ago=o(" (ImageGPT model)"),Lgo=l(),Hg=a("li"),Fge=a("strong"),ygo=o("layoutlm"),xgo=o(" \u2014 "),Lq=a("a"),$go=o("LayoutLMConfig"),kgo=o(" (LayoutLM model)"),Sgo=l(),Jg=a("li"),Tge=a("strong"),Rgo=o("layoutlmv2"),Pgo=o(" \u2014 "),yq=a("a"),Bgo=o("LayoutLMv2Config"),Igo=o(" (LayoutLMv2 model)"),Ngo=l(),Yg=a("li"),Mge=a("strong"),qgo=o("layoutlmv3"),Dgo=o(" \u2014 "),xq=a("a"),jgo=o("LayoutLMv3Config"),Ggo=o(" (LayoutLMv3 model)"),Ogo=l(),Zg=a("li"),Ege=a("strong"),Vgo=o("led"),Xgo=o(" \u2014 "),$q=a("a"),zgo=o("LEDConfig"),Qgo=o(" (LED model)"),Wgo=l(),Kg=a("li"),Cge=a("strong"),Ugo=o("levit"),Hgo=o(" \u2014 "),kq=a("a"),Jgo=o("LevitConfig"),Ygo=o(" (LeViT model)"),Zgo=l(),eh=a("li"),wge=a("strong"),Kgo=o("lilt"),eho=o(" \u2014 "),Sq=a("a"),oho=o("LiltConfig"),rho=o(" (LiLT model)"),tho=l(),oh=a("li"),Age=a("strong"),aho=o("longformer"),nho=o(" \u2014 "),Rq=a("a"),sho=o("LongformerConfig"),lho=o(" (Longformer model)"),iho=l(),rh=a("li"),Lge=a("strong"),dho=o("longt5"),mho=o(" \u2014 "),Pq=a("a"),cho=o("LongT5Config"),fho=o(" (LongT5 model)"),gho=l(),th=a("li"),yge=a("strong"),hho=o("luke"),uho=o(" \u2014 "),Bq=a("a"),pho=o("LukeConfig"),_ho=o(" (LUKE model)"),bho=l(),ah=a("li"),xge=a("strong"),vho=o("lxmert"),Fho=o(" \u2014 "),Iq=a("a"),Tho=o("LxmertConfig"),Mho=o(" (LXMERT model)"),Eho=l(),nh=a("li"),$ge=a("strong"),Cho=o("m2m_100"),who=o(" \u2014 "),Nq=a("a"),Aho=o("M2M100Config"),Lho=o(" (M2M100 model)"),yho=l(),sh=a("li"),kge=a("strong"),xho=o("marian"),$ho=o(" \u2014 "),qq=a("a"),kho=o("MarianConfig"),Sho=o(" (Marian model)"),Rho=l(),lh=a("li"),Sge=a("strong"),Pho=o("markuplm"),Bho=o(" \u2014 "),Dq=a("a"),Iho=o("MarkupLMConfig"),Nho=o(" (MarkupLM model)"),qho=l(),ih=a("li"),Rge=a("strong"),Dho=o("maskformer"),jho=o(" \u2014 "),jq=a("a"),Gho=o("MaskFormerConfig"),Oho=o(" (MaskFormer model)"),Vho=l(),dh=a("li"),Pge=a("strong"),Xho=o("mbart"),zho=o(" \u2014 "),Gq=a("a"),Qho=o("MBartConfig"),Who=o(" (mBART model)"),Uho=l(),mh=a("li"),Bge=a("strong"),Hho=o("mctct"),Jho=o(" \u2014 "),Oq=a("a"),Yho=o("MCTCTConfig"),Zho=o(" (M-CTC-T model)"),Kho=l(),ch=a("li"),Ige=a("strong"),euo=o("megatron-bert"),ouo=o(" \u2014 "),Vq=a("a"),ruo=o("MegatronBertConfig"),tuo=o(" (Megatron-BERT model)"),auo=l(),fh=a("li"),Nge=a("strong"),nuo=o("mobilebert"),suo=o(" \u2014 "),Xq=a("a"),luo=o("MobileBertConfig"),iuo=o(" (MobileBERT model)"),duo=l(),gh=a("li"),qge=a("strong"),muo=o("mobilevit"),cuo=o(" \u2014 "),zq=a("a"),fuo=o("MobileViTConfig"),guo=o(" (MobileViT model)"),huo=l(),hh=a("li"),Dge=a("strong"),uuo=o("mpnet"),puo=o(" \u2014 "),Qq=a("a"),_uo=o("MPNetConfig"),buo=o(" (MPNet model)"),vuo=l(),uh=a("li"),jge=a("strong"),Fuo=o("mt5"),Tuo=o(" \u2014 "),Wq=a("a"),Muo=o("MT5Config"),Euo=o(" (MT5 model)"),Cuo=l(),ph=a("li"),Gge=a("strong"),wuo=o("mvp"),Auo=o(" \u2014 "),Uq=a("a"),Luo=o("MvpConfig"),yuo=o(" (MVP model)"),xuo=l(),_h=a("li"),Oge=a("strong"),$uo=o("nezha"),kuo=o(" \u2014 "),Hq=a("a"),Suo=o("NezhaConfig"),Ruo=o(" (Nezha model)"),Puo=l(),bh=a("li"),Vge=a("strong"),Buo=o("nystromformer"),Iuo=o(" \u2014 "),Jq=a("a"),Nuo=o("NystromformerConfig"),quo=o(" (Nystr\xF6mformer model)"),Duo=l(),vh=a("li"),Xge=a("strong"),juo=o("openai-gpt"),Guo=o(" \u2014 "),Yq=a("a"),Ouo=o("OpenAIGPTConfig"),Vuo=o(" (OpenAI GPT model)"),Xuo=l(),Fh=a("li"),zge=a("strong"),zuo=o("opt"),Quo=o(" \u2014 "),Zq=a("a"),Wuo=o("OPTConfig"),Uuo=o(" (OPT model)"),Huo=l(),Th=a("li"),Qge=a("strong"),Juo=o("owlvit"),Yuo=o(" \u2014 "),Kq=a("a"),Zuo=o("OwlViTConfig"),Kuo=o(" (OWL-ViT model)"),epo=l(),Mh=a("li"),Wge=a("strong"),opo=o("pegasus"),rpo=o(" \u2014 "),eD=a("a"),tpo=o("PegasusConfig"),apo=o(" (Pegasus model)"),npo=l(),Eh=a("li"),Uge=a("strong"),spo=o("pegasus_x"),lpo=o(" \u2014 "),oD=a("a"),ipo=o("PegasusXConfig"),dpo=o(" (PEGASUS-X model)"),mpo=l(),Ch=a("li"),Hge=a("strong"),cpo=o("perceiver"),fpo=o(" \u2014 "),rD=a("a"),gpo=o("PerceiverConfig"),hpo=o(" (Perceiver model)"),upo=l(),wh=a("li"),Jge=a("strong"),ppo=o("plbart"),_po=o(" \u2014 "),tD=a("a"),bpo=o("PLBartConfig"),vpo=o(" (PLBart model)"),Fpo=l(),Ah=a("li"),Yge=a("strong"),Tpo=o("poolformer"),Mpo=o(" \u2014 "),aD=a("a"),Epo=o("PoolFormerConfig"),Cpo=o(" (PoolFormer model)"),wpo=l(),Lh=a("li"),Zge=a("strong"),Apo=o("prophetnet"),Lpo=o(" \u2014 "),nD=a("a"),ypo=o("ProphetNetConfig"),xpo=o(" (ProphetNet model)"),$po=l(),yh=a("li"),Kge=a("strong"),kpo=o("qdqbert"),Spo=o(" \u2014 "),sD=a("a"),Rpo=o("QDQBertConfig"),Ppo=o(" (QDQBert model)"),Bpo=l(),xh=a("li"),ehe=a("strong"),Ipo=o("rag"),Npo=o(" \u2014 "),lD=a("a"),qpo=o("RagConfig"),Dpo=o(" (RAG model)"),jpo=l(),$h=a("li"),ohe=a("strong"),Gpo=o("realm"),Opo=o(" \u2014 "),iD=a("a"),Vpo=o("RealmConfig"),Xpo=o(" (REALM model)"),zpo=l(),kh=a("li"),rhe=a("strong"),Qpo=o("reformer"),Wpo=o(" \u2014 "),dD=a("a"),Upo=o("ReformerConfig"),Hpo=o(" (Reformer model)"),Jpo=l(),Sh=a("li"),the=a("strong"),Ypo=o("regnet"),Zpo=o(" \u2014 "),mD=a("a"),Kpo=o("RegNetConfig"),e_o=o(" (RegNet model)"),o_o=l(),Rh=a("li"),ahe=a("strong"),r_o=o("rembert"),t_o=o(" \u2014 "),cD=a("a"),a_o=o("RemBertConfig"),n_o=o(" (RemBERT model)"),s_o=l(),Ph=a("li"),nhe=a("strong"),l_o=o("resnet"),i_o=o(" \u2014 "),fD=a("a"),d_o=o("ResNetConfig"),m_o=o(" (ResNet model)"),c_o=l(),Bh=a("li"),she=a("strong"),f_o=o("retribert"),g_o=o(" \u2014 "),gD=a("a"),h_o=o("RetriBertConfig"),u_o=o(" (RetriBERT model)"),p_o=l(),Ih=a("li"),lhe=a("strong"),__o=o("roberta"),b_o=o(" \u2014 "),hD=a("a"),v_o=o("RobertaConfig"),F_o=o(" (RoBERTa model)"),T_o=l(),Nh=a("li"),ihe=a("strong"),M_o=o("roformer"),E_o=o(" \u2014 "),uD=a("a"),C_o=o("RoFormerConfig"),w_o=o(" (RoFormer model)"),A_o=l(),qh=a("li"),dhe=a("strong"),L_o=o("segformer"),y_o=o(" \u2014 "),pD=a("a"),x_o=o("SegformerConfig"),$_o=o(" (SegFormer model)"),k_o=l(),Dh=a("li"),mhe=a("strong"),S_o=o("sew"),R_o=o(" \u2014 "),_D=a("a"),P_o=o("SEWConfig"),B_o=o(" (SEW model)"),I_o=l(),jh=a("li"),che=a("strong"),N_o=o("sew-d"),q_o=o(" \u2014 "),bD=a("a"),D_o=o("SEWDConfig"),j_o=o(" (SEW-D model)"),G_o=l(),Gh=a("li"),fhe=a("strong"),O_o=o("speech-encoder-decoder"),V_o=o(" \u2014 "),vD=a("a"),X_o=o("SpeechEncoderDecoderConfig"),z_o=o(" (Speech Encoder decoder model)"),Q_o=l(),Oh=a("li"),ghe=a("strong"),W_o=o("speech_to_text"),U_o=o(" \u2014 "),FD=a("a"),H_o=o("Speech2TextConfig"),J_o=o(" (Speech2Text model)"),Y_o=l(),Vh=a("li"),hhe=a("strong"),Z_o=o("speech_to_text_2"),K_o=o(" \u2014 "),TD=a("a"),e1o=o("Speech2Text2Config"),o1o=o(" (Speech2Text2 model)"),r1o=l(),Xh=a("li"),uhe=a("strong"),t1o=o("splinter"),a1o=o(" \u2014 "),MD=a("a"),n1o=o("SplinterConfig"),s1o=o(" (Splinter model)"),l1o=l(),zh=a("li"),phe=a("strong"),i1o=o("squeezebert"),d1o=o(" \u2014 "),ED=a("a"),m1o=o("SqueezeBertConfig"),c1o=o(" (SqueezeBERT model)"),f1o=l(),Qh=a("li"),_he=a("strong"),g1o=o("swin"),h1o=o(" \u2014 "),CD=a("a"),u1o=o("SwinConfig"),p1o=o(" (Swin Transformer model)"),_1o=l(),Wh=a("li"),bhe=a("strong"),b1o=o("swinv2"),v1o=o(" \u2014 "),wD=a("a"),F1o=o("Swinv2Config"),T1o=o(" (Swin Transformer V2 model)"),M1o=l(),Uh=a("li"),vhe=a("strong"),E1o=o("t5"),C1o=o(" \u2014 "),AD=a("a"),w1o=o("T5Config"),A1o=o(" (T5 model)"),L1o=l(),Hh=a("li"),Fhe=a("strong"),y1o=o("table-transformer"),x1o=o(" \u2014 "),LD=a("a"),$1o=o("TableTransformerConfig"),k1o=o(" (Table Transformer model)"),S1o=l(),Jh=a("li"),The=a("strong"),R1o=o("tapas"),P1o=o(" \u2014 "),yD=a("a"),B1o=o("TapasConfig"),I1o=o(" (TAPAS model)"),N1o=l(),Yh=a("li"),Mhe=a("strong"),q1o=o("time_series_transformer"),D1o=o(" \u2014 "),xD=a("a"),j1o=o("TimeSeriesTransformerConfig"),G1o=o(" (Time Series Transformer model)"),O1o=l(),Zh=a("li"),Ehe=a("strong"),V1o=o("trajectory_transformer"),X1o=o(" \u2014 "),$D=a("a"),z1o=o("TrajectoryTransformerConfig"),Q1o=o(" (Trajectory Transformer model)"),W1o=l(),Kh=a("li"),Che=a("strong"),U1o=o("transfo-xl"),H1o=o(" \u2014 "),kD=a("a"),J1o=o("TransfoXLConfig"),Y1o=o(" (Transformer-XL model)"),Z1o=l(),eu=a("li"),whe=a("strong"),K1o=o("trocr"),e2o=o(" \u2014 "),SD=a("a"),o2o=o("TrOCRConfig"),r2o=o(" (TrOCR model)"),t2o=l(),ou=a("li"),Ahe=a("strong"),a2o=o("unispeech"),n2o=o(" \u2014 "),RD=a("a"),s2o=o("UniSpeechConfig"),l2o=o(" (UniSpeech model)"),i2o=l(),ru=a("li"),Lhe=a("strong"),d2o=o("unispeech-sat"),m2o=o(" \u2014 "),PD=a("a"),c2o=o("UniSpeechSatConfig"),f2o=o(" (UniSpeechSat model)"),g2o=l(),tu=a("li"),yhe=a("strong"),h2o=o("van"),u2o=o(" \u2014 "),BD=a("a"),p2o=o("VanConfig"),_2o=o(" (VAN model)"),b2o=l(),au=a("li"),xhe=a("strong"),v2o=o("videomae"),F2o=o(" \u2014 "),ID=a("a"),T2o=o("VideoMAEConfig"),M2o=o(" (VideoMAE model)"),E2o=l(),nu=a("li"),$he=a("strong"),C2o=o("vilt"),w2o=o(" \u2014 "),ND=a("a"),A2o=o("ViltConfig"),L2o=o(" (ViLT model)"),y2o=l(),su=a("li"),khe=a("strong"),x2o=o("vision-encoder-decoder"),$2o=o(" \u2014 "),qD=a("a"),k2o=o("VisionEncoderDecoderConfig"),S2o=o(" (Vision Encoder decoder model)"),R2o=l(),lu=a("li"),She=a("strong"),P2o=o("vision-text-dual-encoder"),B2o=o(" \u2014 "),DD=a("a"),I2o=o("VisionTextDualEncoderConfig"),N2o=o(" (VisionTextDualEncoder model)"),q2o=l(),iu=a("li"),Rhe=a("strong"),D2o=o("visual_bert"),j2o=o(" \u2014 "),jD=a("a"),G2o=o("VisualBertConfig"),O2o=o(" (VisualBERT model)"),V2o=l(),du=a("li"),Phe=a("strong"),X2o=o("vit"),z2o=o(" \u2014 "),GD=a("a"),Q2o=o("ViTConfig"),W2o=o(" (ViT model)"),U2o=l(),mu=a("li"),Bhe=a("strong"),H2o=o("vit_mae"),J2o=o(" \u2014 "),OD=a("a"),Y2o=o("ViTMAEConfig"),Z2o=o(" (ViTMAE model)"),K2o=l(),cu=a("li"),Ihe=a("strong"),ebo=o("vit_msn"),obo=o(" \u2014 "),VD=a("a"),rbo=o("ViTMSNConfig"),tbo=o(" (ViTMSN model)"),abo=l(),fu=a("li"),Nhe=a("strong"),nbo=o("wav2vec2"),sbo=o(" \u2014 "),XD=a("a"),lbo=o("Wav2Vec2Config"),ibo=o(" (Wav2Vec2 model)"),dbo=l(),gu=a("li"),qhe=a("strong"),mbo=o("wav2vec2-conformer"),cbo=o(" \u2014 "),zD=a("a"),fbo=o("Wav2Vec2ConformerConfig"),gbo=o(" (Wav2Vec2-Conformer model)"),hbo=l(),hu=a("li"),Dhe=a("strong"),ubo=o("wavlm"),pbo=o(" \u2014 "),QD=a("a"),_bo=o("WavLMConfig"),bbo=o(" (WavLM model)"),vbo=l(),uu=a("li"),jhe=a("strong"),Fbo=o("whisper"),Tbo=o(" \u2014 "),WD=a("a"),Mbo=o("WhisperConfig"),Ebo=o(" (Whisper model)"),Cbo=l(),pu=a("li"),Ghe=a("strong"),wbo=o("xclip"),Abo=o(" \u2014 "),UD=a("a"),Lbo=o("XCLIPConfig"),ybo=o(" (X-CLIP model)"),xbo=l(),_u=a("li"),Ohe=a("strong"),$bo=o("xglm"),kbo=o(" \u2014 "),HD=a("a"),Sbo=o("XGLMConfig"),Rbo=o(" (XGLM model)"),Pbo=l(),bu=a("li"),Vhe=a("strong"),Bbo=o("xlm"),Ibo=o(" \u2014 "),JD=a("a"),Nbo=o("XLMConfig"),qbo=o(" (XLM model)"),Dbo=l(),vu=a("li"),Xhe=a("strong"),jbo=o("xlm-prophetnet"),Gbo=o(" \u2014 "),YD=a("a"),Obo=o("XLMProphetNetConfig"),Vbo=o(" (XLM-ProphetNet model)"),Xbo=l(),Fu=a("li"),zhe=a("strong"),zbo=o("xlm-roberta"),Qbo=o(" \u2014 "),ZD=a("a"),Wbo=o("XLMRobertaConfig"),Ubo=o(" (XLM-RoBERTa model)"),Hbo=l(),Tu=a("li"),Qhe=a("strong"),Jbo=o("xlm-roberta-xl"),Ybo=o(" \u2014 "),KD=a("a"),Zbo=o("XLMRobertaXLConfig"),Kbo=o(" (XLM-RoBERTa-XL model)"),evo=l(),Mu=a("li"),Whe=a("strong"),ovo=o("xlnet"),rvo=o(" \u2014 "),ej=a("a"),tvo=o("XLNetConfig"),avo=o(" (XLNet model)"),nvo=l(),Eu=a("li"),Uhe=a("strong"),svo=o("yolos"),lvo=o(" \u2014 "),oj=a("a"),ivo=o("YolosConfig"),dvo=o(" (YOLOS model)"),mvo=l(),Cu=a("li"),Hhe=a("strong"),cvo=o("yoso"),fvo=o(" \u2014 "),rj=a("a"),gvo=o("YosoConfig"),hvo=o(" (YOSO model)"),uvo=l(),F(wu.$$.fragment),pvo=l(),Au=a("div"),F(_$.$$.fragment),_vo=l(),Jhe=a("p"),bvo=o("Register a new configuration for this class."),Ito=l(),yd=a("h2"),Lu=a("a"),Yhe=a("span"),F(b$.$$.fragment),vvo=l(),Zhe=a("span"),Fvo=o("AutoTokenizer"),Nto=l(),Ro=a("div"),F(v$.$$.fragment),Tvo=l(),F$=a("p"),Mvo=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),tj=a("a"),Evo=o("AutoTokenizer.from_pretrained()"),Cvo=o(" class method."),wvo=l(),T$=a("p"),Avo=o("This class cannot be instantiated directly using "),Khe=a("code"),Lvo=o("__init__()"),yvo=o(" (throws an error)."),xvo=l(),Dr=a("div"),F(M$.$$.fragment),$vo=l(),eue=a("p"),kvo=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Svo=l(),tn=a("p"),Rvo=o("The tokenizer class to instantiate is selected based on the "),oue=a("code"),Pvo=o("model_type"),Bvo=o(` property of the config object (either
passed as an argument or loaded from `),rue=a("code"),Ivo=o("pretrained_model_name_or_path"),Nvo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tue=a("code"),qvo=o("pretrained_model_name_or_path"),Dvo=o(":"),jvo=l(),k=a("ul"),us=a("li"),aue=a("strong"),Gvo=o("albert"),Ovo=o(" \u2014 "),aj=a("a"),Vvo=o("AlbertTokenizer"),Xvo=o(" or "),nj=a("a"),zvo=o("AlbertTokenizerFast"),Qvo=o(" (ALBERT model)"),Wvo=l(),ps=a("li"),nue=a("strong"),Uvo=o("bart"),Hvo=o(" \u2014 "),sj=a("a"),Jvo=o("BartTokenizer"),Yvo=o(" or "),lj=a("a"),Zvo=o("BartTokenizerFast"),Kvo=o(" (BART model)"),eFo=l(),_s=a("li"),sue=a("strong"),oFo=o("barthez"),rFo=o(" \u2014 "),ij=a("a"),tFo=o("BarthezTokenizer"),aFo=o(" or "),dj=a("a"),nFo=o("BarthezTokenizerFast"),sFo=o(" (BARThez model)"),lFo=l(),yu=a("li"),lue=a("strong"),iFo=o("bartpho"),dFo=o(" \u2014 "),mj=a("a"),mFo=o("BartphoTokenizer"),cFo=o(" (BARTpho model)"),fFo=l(),bs=a("li"),iue=a("strong"),gFo=o("bert"),hFo=o(" \u2014 "),cj=a("a"),uFo=o("BertTokenizer"),pFo=o(" or "),fj=a("a"),_Fo=o("BertTokenizerFast"),bFo=o(" (BERT model)"),vFo=l(),xu=a("li"),due=a("strong"),FFo=o("bert-generation"),TFo=o(" \u2014 "),gj=a("a"),MFo=o("BertGenerationTokenizer"),EFo=o(" (Bert Generation model)"),CFo=l(),$u=a("li"),mue=a("strong"),wFo=o("bert-japanese"),AFo=o(" \u2014 "),hj=a("a"),LFo=o("BertJapaneseTokenizer"),yFo=o(" (BertJapanese model)"),xFo=l(),ku=a("li"),cue=a("strong"),$Fo=o("bertweet"),kFo=o(" \u2014 "),uj=a("a"),SFo=o("BertweetTokenizer"),RFo=o(" (BERTweet model)"),PFo=l(),vs=a("li"),fue=a("strong"),BFo=o("big_bird"),IFo=o(" \u2014 "),pj=a("a"),NFo=o("BigBirdTokenizer"),qFo=o(" or "),_j=a("a"),DFo=o("BigBirdTokenizerFast"),jFo=o(" (BigBird model)"),GFo=l(),Fs=a("li"),gue=a("strong"),OFo=o("bigbird_pegasus"),VFo=o(" \u2014 "),bj=a("a"),XFo=o("PegasusTokenizer"),zFo=o(" or "),vj=a("a"),QFo=o("PegasusTokenizerFast"),WFo=o(" (BigBird-Pegasus model)"),UFo=l(),Ts=a("li"),hue=a("strong"),HFo=o("blenderbot"),JFo=o(" \u2014 "),Fj=a("a"),YFo=o("BlenderbotTokenizer"),ZFo=o(" or "),Tj=a("a"),KFo=o("BlenderbotTokenizerFast"),eTo=o(" (Blenderbot model)"),oTo=l(),Su=a("li"),uue=a("strong"),rTo=o("blenderbot-small"),tTo=o(" \u2014 "),Mj=a("a"),aTo=o("BlenderbotSmallTokenizer"),nTo=o(" (BlenderbotSmall model)"),sTo=l(),Ru=a("li"),pue=a("strong"),lTo=o("bloom"),iTo=o(" \u2014 "),Ej=a("a"),dTo=o("BloomTokenizerFast"),mTo=o(" (BLOOM model)"),cTo=l(),Pu=a("li"),_ue=a("strong"),fTo=o("byt5"),gTo=o(" \u2014 "),Cj=a("a"),hTo=o("ByT5Tokenizer"),uTo=o(" (ByT5 model)"),pTo=l(),Ms=a("li"),bue=a("strong"),_To=o("camembert"),bTo=o(" \u2014 "),wj=a("a"),vTo=o("CamembertTokenizer"),FTo=o(" or "),Aj=a("a"),TTo=o("CamembertTokenizerFast"),MTo=o(" (CamemBERT model)"),ETo=l(),Bu=a("li"),vue=a("strong"),CTo=o("canine"),wTo=o(" \u2014 "),Lj=a("a"),ATo=o("CanineTokenizer"),LTo=o(" (CANINE model)"),yTo=l(),Es=a("li"),Fue=a("strong"),xTo=o("clip"),$To=o(" \u2014 "),yj=a("a"),kTo=o("CLIPTokenizer"),STo=o(" or "),xj=a("a"),RTo=o("CLIPTokenizerFast"),PTo=o(" (CLIP model)"),BTo=l(),Cs=a("li"),Tue=a("strong"),ITo=o("codegen"),NTo=o(" \u2014 "),$j=a("a"),qTo=o("CodeGenTokenizer"),DTo=o(" or "),kj=a("a"),jTo=o("CodeGenTokenizerFast"),GTo=o(" (CodeGen model)"),OTo=l(),ws=a("li"),Mue=a("strong"),VTo=o("convbert"),XTo=o(" \u2014 "),Sj=a("a"),zTo=o("ConvBertTokenizer"),QTo=o(" or "),Rj=a("a"),WTo=o("ConvBertTokenizerFast"),UTo=o(" (ConvBERT model)"),HTo=l(),As=a("li"),Eue=a("strong"),JTo=o("cpm"),YTo=o(" \u2014 "),Pj=a("a"),ZTo=o("CpmTokenizer"),KTo=o(" or "),Bj=a("a"),eMo=o("CpmTokenizerFast"),oMo=o(" (CPM model)"),rMo=l(),Iu=a("li"),Cue=a("strong"),tMo=o("ctrl"),aMo=o(" \u2014 "),Ij=a("a"),nMo=o("CTRLTokenizer"),sMo=o(" (CTRL model)"),lMo=l(),Ls=a("li"),wue=a("strong"),iMo=o("data2vec-text"),dMo=o(" \u2014 "),Nj=a("a"),mMo=o("RobertaTokenizer"),cMo=o(" or "),qj=a("a"),fMo=o("RobertaTokenizerFast"),gMo=o(" (Data2VecText model)"),hMo=l(),ys=a("li"),Aue=a("strong"),uMo=o("deberta"),pMo=o(" \u2014 "),Dj=a("a"),_Mo=o("DebertaTokenizer"),bMo=o(" or "),jj=a("a"),vMo=o("DebertaTokenizerFast"),FMo=o(" (DeBERTa model)"),TMo=l(),xs=a("li"),Lue=a("strong"),MMo=o("deberta-v2"),EMo=o(" \u2014 "),Gj=a("a"),CMo=o("DebertaV2Tokenizer"),wMo=o(" or "),Oj=a("a"),AMo=o("DebertaV2TokenizerFast"),LMo=o(" (DeBERTa-v2 model)"),yMo=l(),$s=a("li"),yue=a("strong"),xMo=o("distilbert"),$Mo=o(" \u2014 "),Vj=a("a"),kMo=o("DistilBertTokenizer"),SMo=o(" or "),Xj=a("a"),RMo=o("DistilBertTokenizerFast"),PMo=o(" (DistilBERT model)"),BMo=l(),ks=a("li"),xue=a("strong"),IMo=o("dpr"),NMo=o(" \u2014 "),zj=a("a"),qMo=o("DPRQuestionEncoderTokenizer"),DMo=o(" or "),Qj=a("a"),jMo=o("DPRQuestionEncoderTokenizerFast"),GMo=o(" (DPR model)"),OMo=l(),Ss=a("li"),$ue=a("strong"),VMo=o("electra"),XMo=o(" \u2014 "),Wj=a("a"),zMo=o("ElectraTokenizer"),QMo=o(" or "),Uj=a("a"),WMo=o("ElectraTokenizerFast"),UMo=o(" (ELECTRA model)"),HMo=l(),Rs=a("li"),kue=a("strong"),JMo=o("ernie"),YMo=o(" \u2014 "),Hj=a("a"),ZMo=o("BertTokenizer"),KMo=o(" or "),Jj=a("a"),eEo=o("BertTokenizerFast"),oEo=o(" (ERNIE model)"),rEo=l(),Nu=a("li"),Sue=a("strong"),tEo=o("esm"),aEo=o(" \u2014 "),Yj=a("a"),nEo=o("EsmTokenizer"),sEo=o(" (ESM model)"),lEo=l(),qu=a("li"),Rue=a("strong"),iEo=o("flaubert"),dEo=o(" \u2014 "),Zj=a("a"),mEo=o("FlaubertTokenizer"),cEo=o(" (FlauBERT model)"),fEo=l(),Ps=a("li"),Pue=a("strong"),gEo=o("fnet"),hEo=o(" \u2014 "),Kj=a("a"),uEo=o("FNetTokenizer"),pEo=o(" or "),eG=a("a"),_Eo=o("FNetTokenizerFast"),bEo=o(" (FNet model)"),vEo=l(),Du=a("li"),Bue=a("strong"),FEo=o("fsmt"),TEo=o(" \u2014 "),oG=a("a"),MEo=o("FSMTTokenizer"),EEo=o(" (FairSeq Machine-Translation model)"),CEo=l(),Bs=a("li"),Iue=a("strong"),wEo=o("funnel"),AEo=o(" \u2014 "),rG=a("a"),LEo=o("FunnelTokenizer"),yEo=o(" or "),tG=a("a"),xEo=o("FunnelTokenizerFast"),$Eo=o(" (Funnel Transformer model)"),kEo=l(),Is=a("li"),Nue=a("strong"),SEo=o("gpt2"),REo=o(" \u2014 "),aG=a("a"),PEo=o("GPT2Tokenizer"),BEo=o(" or "),nG=a("a"),IEo=o("GPT2TokenizerFast"),NEo=o(" (OpenAI GPT-2 model)"),qEo=l(),Ns=a("li"),que=a("strong"),DEo=o("gpt_neo"),jEo=o(" \u2014 "),sG=a("a"),GEo=o("GPT2Tokenizer"),OEo=o(" or "),lG=a("a"),VEo=o("GPT2TokenizerFast"),XEo=o(" (GPT Neo model)"),zEo=l(),ju=a("li"),Due=a("strong"),QEo=o("gpt_neox"),WEo=o(" \u2014 "),iG=a("a"),UEo=o("GPTNeoXTokenizerFast"),HEo=o(" (GPT NeoX model)"),JEo=l(),Gu=a("li"),jue=a("strong"),YEo=o("gpt_neox_japanese"),ZEo=o(" \u2014 "),dG=a("a"),KEo=o("GPTNeoXJapaneseTokenizer"),e4o=o(" (GPT NeoX Japanese model)"),o4o=l(),qs=a("li"),Gue=a("strong"),r4o=o("gptj"),t4o=o(" \u2014 "),mG=a("a"),a4o=o("GPT2Tokenizer"),n4o=o(" or "),cG=a("a"),s4o=o("GPT2TokenizerFast"),l4o=o(" (GPT-J model)"),i4o=l(),Ds=a("li"),Oue=a("strong"),d4o=o("groupvit"),m4o=o(" \u2014 "),fG=a("a"),c4o=o("CLIPTokenizer"),f4o=o(" or "),gG=a("a"),g4o=o("CLIPTokenizerFast"),h4o=o(" (GroupViT model)"),u4o=l(),js=a("li"),Vue=a("strong"),p4o=o("herbert"),_4o=o(" \u2014 "),hG=a("a"),b4o=o("HerbertTokenizer"),v4o=o(" or "),uG=a("a"),F4o=o("HerbertTokenizerFast"),T4o=o(" (HerBERT model)"),M4o=l(),Ou=a("li"),Xue=a("strong"),E4o=o("hubert"),C4o=o(" \u2014 "),pG=a("a"),w4o=o("Wav2Vec2CTCTokenizer"),A4o=o(" (Hubert model)"),L4o=l(),Gs=a("li"),zue=a("strong"),y4o=o("ibert"),x4o=o(" \u2014 "),_G=a("a"),$4o=o("RobertaTokenizer"),k4o=o(" or "),bG=a("a"),S4o=o("RobertaTokenizerFast"),R4o=o(" (I-BERT model)"),P4o=l(),Os=a("li"),Que=a("strong"),B4o=o("layoutlm"),I4o=o(" \u2014 "),vG=a("a"),N4o=o("LayoutLMTokenizer"),q4o=o(" or "),FG=a("a"),D4o=o("LayoutLMTokenizerFast"),j4o=o(" (LayoutLM model)"),G4o=l(),Vs=a("li"),Wue=a("strong"),O4o=o("layoutlmv2"),V4o=o(" \u2014 "),TG=a("a"),X4o=o("LayoutLMv2Tokenizer"),z4o=o(" or "),MG=a("a"),Q4o=o("LayoutLMv2TokenizerFast"),W4o=o(" (LayoutLMv2 model)"),U4o=l(),Xs=a("li"),Uue=a("strong"),H4o=o("layoutlmv3"),J4o=o(" \u2014 "),EG=a("a"),Y4o=o("LayoutLMv3Tokenizer"),Z4o=o(" or "),CG=a("a"),K4o=o("LayoutLMv3TokenizerFast"),eCo=o(" (LayoutLMv3 model)"),oCo=l(),zs=a("li"),Hue=a("strong"),rCo=o("layoutxlm"),tCo=o(" \u2014 "),wG=a("a"),aCo=o("LayoutXLMTokenizer"),nCo=o(" or "),AG=a("a"),sCo=o("LayoutXLMTokenizerFast"),lCo=o(" (LayoutXLM model)"),iCo=l(),Qs=a("li"),Jue=a("strong"),dCo=o("led"),mCo=o(" \u2014 "),LG=a("a"),cCo=o("LEDTokenizer"),fCo=o(" or "),yG=a("a"),gCo=o("LEDTokenizerFast"),hCo=o(" (LED model)"),uCo=l(),Ws=a("li"),Yue=a("strong"),pCo=o("lilt"),_Co=o(" \u2014 "),xG=a("a"),bCo=o("LayoutLMv3Tokenizer"),vCo=o(" or "),$G=a("a"),FCo=o("LayoutLMv3TokenizerFast"),TCo=o(" (LiLT model)"),MCo=l(),Us=a("li"),Zue=a("strong"),ECo=o("longformer"),CCo=o(" \u2014 "),kG=a("a"),wCo=o("LongformerTokenizer"),ACo=o(" or "),SG=a("a"),LCo=o("LongformerTokenizerFast"),yCo=o(" (Longformer model)"),xCo=l(),Hs=a("li"),Kue=a("strong"),$Co=o("longt5"),kCo=o(" \u2014 "),RG=a("a"),SCo=o("T5Tokenizer"),RCo=o(" or "),PG=a("a"),PCo=o("T5TokenizerFast"),BCo=o(" (LongT5 model)"),ICo=l(),Vu=a("li"),epe=a("strong"),NCo=o("luke"),qCo=o(" \u2014 "),BG=a("a"),DCo=o("LukeTokenizer"),jCo=o(" (LUKE model)"),GCo=l(),Js=a("li"),ope=a("strong"),OCo=o("lxmert"),VCo=o(" \u2014 "),IG=a("a"),XCo=o("LxmertTokenizer"),zCo=o(" or "),NG=a("a"),QCo=o("LxmertTokenizerFast"),WCo=o(" (LXMERT model)"),UCo=l(),Xu=a("li"),rpe=a("strong"),HCo=o("m2m_100"),JCo=o(" \u2014 "),qG=a("a"),YCo=o("M2M100Tokenizer"),ZCo=o(" (M2M100 model)"),KCo=l(),zu=a("li"),tpe=a("strong"),e3o=o("marian"),o3o=o(" \u2014 "),DG=a("a"),r3o=o("MarianTokenizer"),t3o=o(" (Marian model)"),a3o=l(),Ys=a("li"),ape=a("strong"),n3o=o("mbart"),s3o=o(" \u2014 "),jG=a("a"),l3o=o("MBartTokenizer"),i3o=o(" or "),GG=a("a"),d3o=o("MBartTokenizerFast"),m3o=o(" (mBART model)"),c3o=l(),Zs=a("li"),npe=a("strong"),f3o=o("mbart50"),g3o=o(" \u2014 "),OG=a("a"),h3o=o("MBart50Tokenizer"),u3o=o(" or "),VG=a("a"),p3o=o("MBart50TokenizerFast"),_3o=o(" (mBART-50 model)"),b3o=l(),Ks=a("li"),spe=a("strong"),v3o=o("megatron-bert"),F3o=o(" \u2014 "),XG=a("a"),T3o=o("BertTokenizer"),M3o=o(" or "),zG=a("a"),E3o=o("BertTokenizerFast"),C3o=o(" (Megatron-BERT model)"),w3o=l(),Qu=a("li"),lpe=a("strong"),A3o=o("mluke"),L3o=o(" \u2014 "),QG=a("a"),y3o=o("MLukeTokenizer"),x3o=o(" (mLUKE model)"),$3o=l(),el=a("li"),ipe=a("strong"),k3o=o("mobilebert"),S3o=o(" \u2014 "),WG=a("a"),R3o=o("MobileBertTokenizer"),P3o=o(" or "),UG=a("a"),B3o=o("MobileBertTokenizerFast"),I3o=o(" (MobileBERT model)"),N3o=l(),ol=a("li"),dpe=a("strong"),q3o=o("mpnet"),D3o=o(" \u2014 "),HG=a("a"),j3o=o("MPNetTokenizer"),G3o=o(" or "),JG=a("a"),O3o=o("MPNetTokenizerFast"),V3o=o(" (MPNet model)"),X3o=l(),rl=a("li"),mpe=a("strong"),z3o=o("mt5"),Q3o=o(" \u2014 "),YG=a("a"),W3o=o("MT5Tokenizer"),U3o=o(" or "),ZG=a("a"),H3o=o("MT5TokenizerFast"),J3o=o(" (MT5 model)"),Y3o=l(),tl=a("li"),cpe=a("strong"),Z3o=o("mvp"),K3o=o(" \u2014 "),KG=a("a"),e5o=o("MvpTokenizer"),o5o=o(" or "),eO=a("a"),r5o=o("MvpTokenizerFast"),t5o=o(" (MVP model)"),a5o=l(),al=a("li"),fpe=a("strong"),n5o=o("nezha"),s5o=o(" \u2014 "),oO=a("a"),l5o=o("BertTokenizer"),i5o=o(" or "),rO=a("a"),d5o=o("BertTokenizerFast"),m5o=o(" (Nezha model)"),c5o=l(),nl=a("li"),gpe=a("strong"),f5o=o("nllb"),g5o=o(" \u2014 "),tO=a("a"),h5o=o("NllbTokenizer"),u5o=o(" or "),aO=a("a"),p5o=o("NllbTokenizerFast"),_5o=o(" (NLLB model)"),b5o=l(),sl=a("li"),hpe=a("strong"),v5o=o("nystromformer"),F5o=o(" \u2014 "),nO=a("a"),T5o=o("AlbertTokenizer"),M5o=o(" or "),sO=a("a"),E5o=o("AlbertTokenizerFast"),C5o=o(" (Nystr\xF6mformer model)"),w5o=l(),ll=a("li"),upe=a("strong"),A5o=o("openai-gpt"),L5o=o(" \u2014 "),lO=a("a"),y5o=o("OpenAIGPTTokenizer"),x5o=o(" or "),iO=a("a"),$5o=o("OpenAIGPTTokenizerFast"),k5o=o(" (OpenAI GPT model)"),S5o=l(),Wu=a("li"),ppe=a("strong"),R5o=o("opt"),P5o=o(" \u2014 "),dO=a("a"),B5o=o("GPT2Tokenizer"),I5o=o(" (OPT model)"),N5o=l(),il=a("li"),_pe=a("strong"),q5o=o("owlvit"),D5o=o(" \u2014 "),mO=a("a"),j5o=o("CLIPTokenizer"),G5o=o(" or "),cO=a("a"),O5o=o("CLIPTokenizerFast"),V5o=o(" (OWL-ViT model)"),X5o=l(),dl=a("li"),bpe=a("strong"),z5o=o("pegasus"),Q5o=o(" \u2014 "),fO=a("a"),W5o=o("PegasusTokenizer"),U5o=o(" or "),gO=a("a"),H5o=o("PegasusTokenizerFast"),J5o=o(" (Pegasus model)"),Y5o=l(),ml=a("li"),vpe=a("strong"),Z5o=o("pegasus_x"),K5o=o(" \u2014 "),hO=a("a"),e0o=o("PegasusTokenizer"),o0o=o(" or "),uO=a("a"),r0o=o("PegasusTokenizerFast"),t0o=o(" (PEGASUS-X model)"),a0o=l(),Uu=a("li"),Fpe=a("strong"),n0o=o("perceiver"),s0o=o(" \u2014 "),pO=a("a"),l0o=o("PerceiverTokenizer"),i0o=o(" (Perceiver model)"),d0o=l(),Hu=a("li"),Tpe=a("strong"),m0o=o("phobert"),c0o=o(" \u2014 "),_O=a("a"),f0o=o("PhobertTokenizer"),g0o=o(" (PhoBERT model)"),h0o=l(),Ju=a("li"),Mpe=a("strong"),u0o=o("plbart"),p0o=o(" \u2014 "),bO=a("a"),_0o=o("PLBartTokenizer"),b0o=o(" (PLBart model)"),v0o=l(),Yu=a("li"),Epe=a("strong"),F0o=o("prophetnet"),T0o=o(" \u2014 "),vO=a("a"),M0o=o("ProphetNetTokenizer"),E0o=o(" (ProphetNet model)"),C0o=l(),cl=a("li"),Cpe=a("strong"),w0o=o("qdqbert"),A0o=o(" \u2014 "),FO=a("a"),L0o=o("BertTokenizer"),y0o=o(" or "),TO=a("a"),x0o=o("BertTokenizerFast"),$0o=o(" (QDQBert model)"),k0o=l(),Zu=a("li"),wpe=a("strong"),S0o=o("rag"),R0o=o(" \u2014 "),MO=a("a"),P0o=o("RagTokenizer"),B0o=o(" (RAG model)"),I0o=l(),fl=a("li"),Ape=a("strong"),N0o=o("realm"),q0o=o(" \u2014 "),EO=a("a"),D0o=o("RealmTokenizer"),j0o=o(" or "),CO=a("a"),G0o=o("RealmTokenizerFast"),O0o=o(" (REALM model)"),V0o=l(),gl=a("li"),Lpe=a("strong"),X0o=o("reformer"),z0o=o(" \u2014 "),wO=a("a"),Q0o=o("ReformerTokenizer"),W0o=o(" or "),AO=a("a"),U0o=o("ReformerTokenizerFast"),H0o=o(" (Reformer model)"),J0o=l(),hl=a("li"),ype=a("strong"),Y0o=o("rembert"),Z0o=o(" \u2014 "),LO=a("a"),K0o=o("RemBertTokenizer"),ewo=o(" or "),yO=a("a"),owo=o("RemBertTokenizerFast"),rwo=o(" (RemBERT model)"),two=l(),ul=a("li"),xpe=a("strong"),awo=o("retribert"),nwo=o(" \u2014 "),xO=a("a"),swo=o("RetriBertTokenizer"),lwo=o(" or "),$O=a("a"),iwo=o("RetriBertTokenizerFast"),dwo=o(" (RetriBERT model)"),mwo=l(),pl=a("li"),$pe=a("strong"),cwo=o("roberta"),fwo=o(" \u2014 "),kO=a("a"),gwo=o("RobertaTokenizer"),hwo=o(" or "),SO=a("a"),uwo=o("RobertaTokenizerFast"),pwo=o(" (RoBERTa model)"),_wo=l(),_l=a("li"),kpe=a("strong"),bwo=o("roformer"),vwo=o(" \u2014 "),RO=a("a"),Fwo=o("RoFormerTokenizer"),Two=o(" or "),PO=a("a"),Mwo=o("RoFormerTokenizerFast"),Ewo=o(" (RoFormer model)"),Cwo=l(),Ku=a("li"),Spe=a("strong"),wwo=o("speech_to_text"),Awo=o(" \u2014 "),BO=a("a"),Lwo=o("Speech2TextTokenizer"),ywo=o(" (Speech2Text model)"),xwo=l(),ep=a("li"),Rpe=a("strong"),$wo=o("speech_to_text_2"),kwo=o(" \u2014 "),IO=a("a"),Swo=o("Speech2Text2Tokenizer"),Rwo=o(" (Speech2Text2 model)"),Pwo=l(),bl=a("li"),Ppe=a("strong"),Bwo=o("splinter"),Iwo=o(" \u2014 "),NO=a("a"),Nwo=o("SplinterTokenizer"),qwo=o(" or "),qO=a("a"),Dwo=o("SplinterTokenizerFast"),jwo=o(" (Splinter model)"),Gwo=l(),vl=a("li"),Bpe=a("strong"),Owo=o("squeezebert"),Vwo=o(" \u2014 "),DO=a("a"),Xwo=o("SqueezeBertTokenizer"),zwo=o(" or "),jO=a("a"),Qwo=o("SqueezeBertTokenizerFast"),Wwo=o(" (SqueezeBERT model)"),Uwo=l(),Fl=a("li"),Ipe=a("strong"),Hwo=o("t5"),Jwo=o(" \u2014 "),GO=a("a"),Ywo=o("T5Tokenizer"),Zwo=o(" or "),OO=a("a"),Kwo=o("T5TokenizerFast"),eAo=o(" (T5 model)"),oAo=l(),op=a("li"),Npe=a("strong"),rAo=o("tapas"),tAo=o(" \u2014 "),VO=a("a"),aAo=o("TapasTokenizer"),nAo=o(" (TAPAS model)"),sAo=l(),rp=a("li"),qpe=a("strong"),lAo=o("tapex"),iAo=o(" \u2014 "),XO=a("a"),dAo=o("TapexTokenizer"),mAo=o(" (TAPEX model)"),cAo=l(),tp=a("li"),Dpe=a("strong"),fAo=o("transfo-xl"),gAo=o(" \u2014 "),zO=a("a"),hAo=o("TransfoXLTokenizer"),uAo=o(" (Transformer-XL model)"),pAo=l(),Tl=a("li"),jpe=a("strong"),_Ao=o("vilt"),bAo=o(" \u2014 "),QO=a("a"),vAo=o("BertTokenizer"),FAo=o(" or "),WO=a("a"),TAo=o("BertTokenizerFast"),MAo=o(" (ViLT model)"),EAo=l(),Ml=a("li"),Gpe=a("strong"),CAo=o("visual_bert"),wAo=o(" \u2014 "),UO=a("a"),AAo=o("BertTokenizer"),LAo=o(" or "),HO=a("a"),yAo=o("BertTokenizerFast"),xAo=o(" (VisualBERT model)"),$Ao=l(),ap=a("li"),Ope=a("strong"),kAo=o("wav2vec2"),SAo=o(" \u2014 "),JO=a("a"),RAo=o("Wav2Vec2CTCTokenizer"),PAo=o(" (Wav2Vec2 model)"),BAo=l(),np=a("li"),Vpe=a("strong"),IAo=o("wav2vec2-conformer"),NAo=o(" \u2014 "),YO=a("a"),qAo=o("Wav2Vec2CTCTokenizer"),DAo=o(" (Wav2Vec2-Conformer model)"),jAo=l(),sp=a("li"),Xpe=a("strong"),GAo=o("wav2vec2_phoneme"),OAo=o(" \u2014 "),ZO=a("a"),VAo=o("Wav2Vec2PhonemeCTCTokenizer"),XAo=o(" (Wav2Vec2Phoneme model)"),zAo=l(),lp=a("li"),zpe=a("strong"),QAo=o("whisper"),WAo=o(" \u2014 "),KO=a("a"),UAo=o("WhisperTokenizer"),HAo=o(" (Whisper model)"),JAo=l(),El=a("li"),Qpe=a("strong"),YAo=o("xclip"),ZAo=o(" \u2014 "),eV=a("a"),KAo=o("CLIPTokenizer"),e6o=o(" or "),oV=a("a"),o6o=o("CLIPTokenizerFast"),r6o=o(" (X-CLIP model)"),t6o=l(),Cl=a("li"),Wpe=a("strong"),a6o=o("xglm"),n6o=o(" \u2014 "),rV=a("a"),s6o=o("XGLMTokenizer"),l6o=o(" or "),tV=a("a"),i6o=o("XGLMTokenizerFast"),d6o=o(" (XGLM model)"),m6o=l(),ip=a("li"),Upe=a("strong"),c6o=o("xlm"),f6o=o(" \u2014 "),aV=a("a"),g6o=o("XLMTokenizer"),h6o=o(" (XLM model)"),u6o=l(),dp=a("li"),Hpe=a("strong"),p6o=o("xlm-prophetnet"),_6o=o(" \u2014 "),nV=a("a"),b6o=o("XLMProphetNetTokenizer"),v6o=o(" (XLM-ProphetNet model)"),F6o=l(),wl=a("li"),Jpe=a("strong"),T6o=o("xlm-roberta"),M6o=o(" \u2014 "),sV=a("a"),E6o=o("XLMRobertaTokenizer"),C6o=o(" or "),lV=a("a"),w6o=o("XLMRobertaTokenizerFast"),A6o=o(" (XLM-RoBERTa model)"),L6o=l(),Al=a("li"),Ype=a("strong"),y6o=o("xlm-roberta-xl"),x6o=o(" \u2014 "),iV=a("a"),$6o=o("XLMRobertaTokenizer"),k6o=o(" or "),dV=a("a"),S6o=o("XLMRobertaTokenizerFast"),R6o=o(" (XLM-RoBERTa-XL model)"),P6o=l(),Ll=a("li"),Zpe=a("strong"),B6o=o("xlnet"),I6o=o(" \u2014 "),mV=a("a"),N6o=o("XLNetTokenizer"),q6o=o(" or "),cV=a("a"),D6o=o("XLNetTokenizerFast"),j6o=o(" (XLNet model)"),G6o=l(),yl=a("li"),Kpe=a("strong"),O6o=o("yoso"),V6o=o(" \u2014 "),fV=a("a"),X6o=o("AlbertTokenizer"),z6o=o(" or "),gV=a("a"),Q6o=o("AlbertTokenizerFast"),W6o=o(" (YOSO model)"),U6o=l(),F(mp.$$.fragment),H6o=l(),cp=a("div"),F(E$.$$.fragment),J6o=l(),e_e=a("p"),Y6o=o("Register a new tokenizer in this mapping."),qto=l(),xd=a("h2"),fp=a("a"),o_e=a("span"),F(C$.$$.fragment),Z6o=l(),r_e=a("span"),K6o=o("AutoFeatureExtractor"),Dto=l(),Po=a("div"),F(w$.$$.fragment),e7o=l(),A$=a("p"),o7o=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),hV=a("a"),r7o=o("AutoFeatureExtractor.from_pretrained()"),t7o=o(" class method."),a7o=l(),L$=a("p"),n7o=o("This class cannot be instantiated directly using "),t_e=a("code"),s7o=o("__init__()"),l7o=o(" (throws an error)."),i7o=l(),Ye=a("div"),F(y$.$$.fragment),d7o=l(),a_e=a("p"),m7o=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),c7o=l(),an=a("p"),f7o=o("The feature extractor class to instantiate is selected based on the "),n_e=a("code"),g7o=o("model_type"),h7o=o(` property of the config object
(either passed as an argument or loaded from `),s_e=a("code"),u7o=o("pretrained_model_name_or_path"),p7o=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),l_e=a("code"),_7o=o("pretrained_model_name_or_path"),b7o=o(":"),v7o=l(),z=a("ul"),gp=a("li"),i_e=a("strong"),F7o=o("beit"),T7o=o(" \u2014 "),uV=a("a"),M7o=o("BeitFeatureExtractor"),E7o=o(" (BEiT model)"),C7o=l(),hp=a("li"),d_e=a("strong"),w7o=o("clip"),A7o=o(" \u2014 "),pV=a("a"),L7o=o("CLIPFeatureExtractor"),y7o=o(" (CLIP model)"),x7o=l(),up=a("li"),m_e=a("strong"),$7o=o("conditional_detr"),k7o=o(" \u2014 "),_V=a("a"),S7o=o("ConditionalDetrFeatureExtractor"),R7o=o(" (Conditional DETR model)"),P7o=l(),pp=a("li"),c_e=a("strong"),B7o=o("convnext"),I7o=o(" \u2014 "),bV=a("a"),N7o=o("ConvNextFeatureExtractor"),q7o=o(" (ConvNeXT model)"),D7o=l(),_p=a("li"),f_e=a("strong"),j7o=o("cvt"),G7o=o(" \u2014 "),vV=a("a"),O7o=o("ConvNextFeatureExtractor"),V7o=o(" (CvT model)"),X7o=l(),bp=a("li"),g_e=a("strong"),z7o=o("data2vec-audio"),Q7o=o(" \u2014 "),FV=a("a"),W7o=o("Wav2Vec2FeatureExtractor"),U7o=o(" (Data2VecAudio model)"),H7o=l(),vp=a("li"),h_e=a("strong"),J7o=o("data2vec-vision"),Y7o=o(" \u2014 "),TV=a("a"),Z7o=o("BeitFeatureExtractor"),K7o=o(" (Data2VecVision model)"),e8o=l(),Fp=a("li"),u_e=a("strong"),o8o=o("deformable_detr"),r8o=o(" \u2014 "),MV=a("a"),t8o=o("DeformableDetrFeatureExtractor"),a8o=o(" (Deformable DETR model)"),n8o=l(),Tp=a("li"),p_e=a("strong"),s8o=o("deit"),l8o=o(" \u2014 "),EV=a("a"),i8o=o("DeiTFeatureExtractor"),d8o=o(" (DeiT model)"),m8o=l(),Mp=a("li"),__e=a("strong"),c8o=o("detr"),f8o=o(" \u2014 "),CV=a("a"),g8o=o("DetrFeatureExtractor"),h8o=o(" (DETR model)"),u8o=l(),Ep=a("li"),b_e=a("strong"),p8o=o("donut"),_8o=o(" \u2014 "),wV=a("a"),b8o=o("DonutFeatureExtractor"),v8o=o(" (Donut model)"),F8o=l(),Cp=a("li"),v_e=a("strong"),T8o=o("dpt"),M8o=o(" \u2014 "),AV=a("a"),E8o=o("DPTFeatureExtractor"),C8o=o(" (DPT model)"),w8o=l(),wp=a("li"),F_e=a("strong"),A8o=o("flava"),L8o=o(" \u2014 "),LV=a("a"),y8o=o("FlavaFeatureExtractor"),x8o=o(" (FLAVA model)"),$8o=l(),Ap=a("li"),T_e=a("strong"),k8o=o("glpn"),S8o=o(" \u2014 "),yV=a("a"),R8o=o("GLPNFeatureExtractor"),P8o=o(" (GLPN model)"),B8o=l(),Lp=a("li"),M_e=a("strong"),I8o=o("groupvit"),N8o=o(" \u2014 "),xV=a("a"),q8o=o("CLIPFeatureExtractor"),D8o=o(" (GroupViT model)"),j8o=l(),yp=a("li"),E_e=a("strong"),G8o=o("hubert"),O8o=o(" \u2014 "),$V=a("a"),V8o=o("Wav2Vec2FeatureExtractor"),X8o=o(" (Hubert model)"),z8o=l(),xp=a("li"),C_e=a("strong"),Q8o=o("imagegpt"),W8o=o(" \u2014 "),kV=a("a"),U8o=o("ImageGPTFeatureExtractor"),H8o=o(" (ImageGPT model)"),J8o=l(),$p=a("li"),w_e=a("strong"),Y8o=o("layoutlmv2"),Z8o=o(" \u2014 "),SV=a("a"),K8o=o("LayoutLMv2FeatureExtractor"),eLo=o(" (LayoutLMv2 model)"),oLo=l(),kp=a("li"),A_e=a("strong"),rLo=o("layoutlmv3"),tLo=o(" \u2014 "),RV=a("a"),aLo=o("LayoutLMv3FeatureExtractor"),nLo=o(" (LayoutLMv3 model)"),sLo=l(),Sp=a("li"),L_e=a("strong"),lLo=o("levit"),iLo=o(" \u2014 "),PV=a("a"),dLo=o("LevitFeatureExtractor"),mLo=o(" (LeViT model)"),cLo=l(),Rp=a("li"),y_e=a("strong"),fLo=o("maskformer"),gLo=o(" \u2014 "),BV=a("a"),hLo=o("MaskFormerFeatureExtractor"),uLo=o(" (MaskFormer model)"),pLo=l(),Pp=a("li"),x_e=a("strong"),_Lo=o("mctct"),bLo=o(" \u2014 "),IV=a("a"),vLo=o("MCTCTFeatureExtractor"),FLo=o(" (M-CTC-T model)"),TLo=l(),Bp=a("li"),$_e=a("strong"),MLo=o("mobilevit"),ELo=o(" \u2014 "),NV=a("a"),CLo=o("MobileViTFeatureExtractor"),wLo=o(" (MobileViT model)"),ALo=l(),Ip=a("li"),k_e=a("strong"),LLo=o("owlvit"),yLo=o(" \u2014 "),qV=a("a"),xLo=o("OwlViTFeatureExtractor"),$Lo=o(" (OWL-ViT model)"),kLo=l(),Np=a("li"),S_e=a("strong"),SLo=o("perceiver"),RLo=o(" \u2014 "),DV=a("a"),PLo=o("PerceiverFeatureExtractor"),BLo=o(" (Perceiver model)"),ILo=l(),qp=a("li"),R_e=a("strong"),NLo=o("poolformer"),qLo=o(" \u2014 "),jV=a("a"),DLo=o("PoolFormerFeatureExtractor"),jLo=o(" (PoolFormer model)"),GLo=l(),Dp=a("li"),P_e=a("strong"),OLo=o("regnet"),VLo=o(" \u2014 "),GV=a("a"),XLo=o("ConvNextFeatureExtractor"),zLo=o(" (RegNet model)"),QLo=l(),jp=a("li"),B_e=a("strong"),WLo=o("resnet"),ULo=o(" \u2014 "),OV=a("a"),HLo=o("ConvNextFeatureExtractor"),JLo=o(" (ResNet model)"),YLo=l(),Gp=a("li"),I_e=a("strong"),ZLo=o("segformer"),KLo=o(" \u2014 "),VV=a("a"),eyo=o("SegformerFeatureExtractor"),oyo=o(" (SegFormer model)"),ryo=l(),Op=a("li"),N_e=a("strong"),tyo=o("speech_to_text"),ayo=o(" \u2014 "),XV=a("a"),nyo=o("Speech2TextFeatureExtractor"),syo=o(" (Speech2Text model)"),lyo=l(),Vp=a("li"),q_e=a("strong"),iyo=o("swin"),dyo=o(" \u2014 "),zV=a("a"),myo=o("ViTFeatureExtractor"),cyo=o(" (Swin Transformer model)"),fyo=l(),Xp=a("li"),D_e=a("strong"),gyo=o("swinv2"),hyo=o(" \u2014 "),QV=a("a"),uyo=o("ViTFeatureExtractor"),pyo=o(" (Swin Transformer V2 model)"),_yo=l(),zp=a("li"),j_e=a("strong"),byo=o("table-transformer"),vyo=o(" \u2014 "),WV=a("a"),Fyo=o("DetrFeatureExtractor"),Tyo=o(" (Table Transformer model)"),Myo=l(),Qp=a("li"),G_e=a("strong"),Eyo=o("van"),Cyo=o(" \u2014 "),UV=a("a"),wyo=o("ConvNextFeatureExtractor"),Ayo=o(" (VAN model)"),Lyo=l(),Wp=a("li"),O_e=a("strong"),yyo=o("videomae"),xyo=o(" \u2014 "),HV=a("a"),$yo=o("VideoMAEFeatureExtractor"),kyo=o(" (VideoMAE model)"),Syo=l(),Up=a("li"),V_e=a("strong"),Ryo=o("vilt"),Pyo=o(" \u2014 "),JV=a("a"),Byo=o("ViltFeatureExtractor"),Iyo=o(" (ViLT model)"),Nyo=l(),Hp=a("li"),X_e=a("strong"),qyo=o("vit"),Dyo=o(" \u2014 "),YV=a("a"),jyo=o("ViTFeatureExtractor"),Gyo=o(" (ViT model)"),Oyo=l(),Jp=a("li"),z_e=a("strong"),Vyo=o("vit_mae"),Xyo=o(" \u2014 "),ZV=a("a"),zyo=o("ViTFeatureExtractor"),Qyo=o(" (ViTMAE model)"),Wyo=l(),Yp=a("li"),Q_e=a("strong"),Uyo=o("vit_msn"),Hyo=o(" \u2014 "),KV=a("a"),Jyo=o("ViTFeatureExtractor"),Yyo=o(" (ViTMSN model)"),Zyo=l(),Zp=a("li"),W_e=a("strong"),Kyo=o("wav2vec2"),e9o=o(" \u2014 "),eX=a("a"),o9o=o("Wav2Vec2FeatureExtractor"),r9o=o(" (Wav2Vec2 model)"),t9o=l(),Kp=a("li"),U_e=a("strong"),a9o=o("wav2vec2-conformer"),n9o=o(" \u2014 "),oX=a("a"),s9o=o("Wav2Vec2FeatureExtractor"),l9o=o(" (Wav2Vec2-Conformer model)"),i9o=l(),e_=a("li"),H_e=a("strong"),d9o=o("whisper"),m9o=o(" \u2014 "),rX=a("a"),c9o=o("WhisperFeatureExtractor"),f9o=o(" (Whisper model)"),g9o=l(),o_=a("li"),J_e=a("strong"),h9o=o("xclip"),u9o=o(" \u2014 "),tX=a("a"),p9o=o("CLIPFeatureExtractor"),_9o=o(" (X-CLIP model)"),b9o=l(),r_=a("li"),Y_e=a("strong"),v9o=o("yolos"),F9o=o(" \u2014 "),aX=a("a"),T9o=o("YolosFeatureExtractor"),M9o=o(" (YOLOS model)"),E9o=l(),F(t_.$$.fragment),C9o=l(),F(a_.$$.fragment),w9o=l(),n_=a("div"),F(x$.$$.fragment),A9o=l(),Z_e=a("p"),L9o=o("Register a new feature extractor for this class."),jto=l(),$d=a("h2"),s_=a("a"),K_e=a("span"),F($$.$$.fragment),y9o=l(),e1e=a("span"),x9o=o("AutoProcessor"),Gto=l(),Bo=a("div"),F(k$.$$.fragment),$9o=l(),S$=a("p"),k9o=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),nX=a("a"),S9o=o("AutoProcessor.from_pretrained()"),R9o=o(" class method."),P9o=l(),R$=a("p"),B9o=o("This class cannot be instantiated directly using "),o1e=a("code"),I9o=o("__init__()"),N9o=o(" (throws an error)."),q9o=l(),Ze=a("div"),F(P$.$$.fragment),D9o=l(),r1e=a("p"),j9o=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),G9o=l(),kd=a("p"),O9o=o("The processor class to instantiate is selected based on the "),t1e=a("code"),V9o=o("model_type"),X9o=o(` property of the config object (either
passed as an argument or loaded from `),a1e=a("code"),z9o=o("pretrained_model_name_or_path"),Q9o=o(" if possible):"),W9o=l(),se=a("ul"),l_=a("li"),n1e=a("strong"),U9o=o("clip"),H9o=o(" \u2014 "),sX=a("a"),J9o=o("CLIPProcessor"),Y9o=o(" (CLIP model)"),Z9o=l(),i_=a("li"),s1e=a("strong"),K9o=o("donut"),exo=o(" \u2014 "),lX=a("a"),oxo=o("DonutProcessor"),rxo=o(" (Donut model)"),txo=l(),d_=a("li"),l1e=a("strong"),axo=o("flava"),nxo=o(" \u2014 "),iX=a("a"),sxo=o("FlavaProcessor"),lxo=o(" (FLAVA model)"),ixo=l(),m_=a("li"),i1e=a("strong"),dxo=o("groupvit"),mxo=o(" \u2014 "),dX=a("a"),cxo=o("CLIPProcessor"),fxo=o(" (GroupViT model)"),gxo=l(),c_=a("li"),d1e=a("strong"),hxo=o("layoutlmv2"),uxo=o(" \u2014 "),mX=a("a"),pxo=o("LayoutLMv2Processor"),_xo=o(" (LayoutLMv2 model)"),bxo=l(),f_=a("li"),m1e=a("strong"),vxo=o("layoutlmv3"),Fxo=o(" \u2014 "),cX=a("a"),Txo=o("LayoutLMv3Processor"),Mxo=o(" (LayoutLMv3 model)"),Exo=l(),g_=a("li"),c1e=a("strong"),Cxo=o("layoutxlm"),wxo=o(" \u2014 "),fX=a("a"),Axo=o("LayoutXLMProcessor"),Lxo=o(" (LayoutXLM model)"),yxo=l(),h_=a("li"),f1e=a("strong"),xxo=o("markuplm"),$xo=o(" \u2014 "),gX=a("a"),kxo=o("MarkupLMProcessor"),Sxo=o(" (MarkupLM model)"),Rxo=l(),u_=a("li"),g1e=a("strong"),Pxo=o("owlvit"),Bxo=o(" \u2014 "),hX=a("a"),Ixo=o("OwlViTProcessor"),Nxo=o(" (OWL-ViT model)"),qxo=l(),p_=a("li"),h1e=a("strong"),Dxo=o("sew"),jxo=o(" \u2014 "),uX=a("a"),Gxo=o("Wav2Vec2Processor"),Oxo=o(" (SEW model)"),Vxo=l(),__=a("li"),u1e=a("strong"),Xxo=o("sew-d"),zxo=o(" \u2014 "),pX=a("a"),Qxo=o("Wav2Vec2Processor"),Wxo=o(" (SEW-D model)"),Uxo=l(),b_=a("li"),p1e=a("strong"),Hxo=o("speech_to_text"),Jxo=o(" \u2014 "),_X=a("a"),Yxo=o("Speech2TextProcessor"),Zxo=o(" (Speech2Text model)"),Kxo=l(),v_=a("li"),_1e=a("strong"),e$o=o("speech_to_text_2"),o$o=o(" \u2014 "),bX=a("a"),r$o=o("Speech2Text2Processor"),t$o=o(" (Speech2Text2 model)"),a$o=l(),F_=a("li"),b1e=a("strong"),n$o=o("trocr"),s$o=o(" \u2014 "),vX=a("a"),l$o=o("TrOCRProcessor"),i$o=o(" (TrOCR model)"),d$o=l(),T_=a("li"),v1e=a("strong"),m$o=o("unispeech"),c$o=o(" \u2014 "),FX=a("a"),f$o=o("Wav2Vec2Processor"),g$o=o(" (UniSpeech model)"),h$o=l(),M_=a("li"),F1e=a("strong"),u$o=o("unispeech-sat"),p$o=o(" \u2014 "),TX=a("a"),_$o=o("Wav2Vec2Processor"),b$o=o(" (UniSpeechSat model)"),v$o=l(),E_=a("li"),T1e=a("strong"),F$o=o("vilt"),T$o=o(" \u2014 "),MX=a("a"),M$o=o("ViltProcessor"),E$o=o(" (ViLT model)"),C$o=l(),C_=a("li"),M1e=a("strong"),w$o=o("vision-text-dual-encoder"),A$o=o(" \u2014 "),EX=a("a"),L$o=o("VisionTextDualEncoderProcessor"),y$o=o(" (VisionTextDualEncoder model)"),x$o=l(),w_=a("li"),E1e=a("strong"),$$o=o("wav2vec2"),k$o=o(" \u2014 "),CX=a("a"),S$o=o("Wav2Vec2Processor"),R$o=o(" (Wav2Vec2 model)"),P$o=l(),A_=a("li"),C1e=a("strong"),B$o=o("wav2vec2-conformer"),I$o=o(" \u2014 "),wX=a("a"),N$o=o("Wav2Vec2Processor"),q$o=o(" (Wav2Vec2-Conformer model)"),D$o=l(),L_=a("li"),w1e=a("strong"),j$o=o("wavlm"),G$o=o(" \u2014 "),AX=a("a"),O$o=o("Wav2Vec2Processor"),V$o=o(" (WavLM model)"),X$o=l(),y_=a("li"),A1e=a("strong"),z$o=o("whisper"),Q$o=o(" \u2014 "),LX=a("a"),W$o=o("WhisperProcessor"),U$o=o(" (Whisper model)"),H$o=l(),x_=a("li"),L1e=a("strong"),J$o=o("xclip"),Y$o=o(" \u2014 "),yX=a("a"),Z$o=o("XCLIPProcessor"),K$o=o(" (X-CLIP model)"),eko=l(),F($_.$$.fragment),oko=l(),F(k_.$$.fragment),rko=l(),S_=a("div"),F(B$.$$.fragment),tko=l(),y1e=a("p"),ako=o("Register a new processor for this class."),Oto=l(),Sd=a("h2"),R_=a("a"),x1e=a("span"),F(I$.$$.fragment),nko=l(),$1e=a("span"),sko=o("AutoModel"),Vto=l(),Io=a("div"),F(N$.$$.fragment),lko=l(),Rd=a("p"),iko=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),xX=a("a"),dko=o("from_pretrained()"),mko=o(" class method or the "),$X=a("a"),cko=o("from_config()"),fko=o(` class
method.`),gko=l(),q$=a("p"),hko=o("This class cannot be instantiated directly using "),k1e=a("code"),uko=o("__init__()"),pko=o(" (throws an error)."),_ko=l(),Mt=a("div"),F(D$.$$.fragment),bko=l(),S1e=a("p"),vko=o("Instantiates one of the base model classes of the library from a configuration."),Fko=l(),Pd=a("p"),Tko=o(`Note:
Loading a model from its configuration file does `),R1e=a("strong"),Mko=o("not"),Eko=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kX=a("a"),Cko=o("from_pretrained()"),wko=o(" to load the model weights."),Ako=l(),F(P_.$$.fragment),Lko=l(),Ke=a("div"),F(j$.$$.fragment),yko=l(),P1e=a("p"),xko=o("Instantiate one of the base model classes of the library from a pretrained model."),$ko=l(),nn=a("p"),kko=o("The model class to instantiate is selected based on the "),B1e=a("code"),Sko=o("model_type"),Rko=o(` property of the config object (either
passed as an argument or loaded from `),I1e=a("code"),Pko=o("pretrained_model_name_or_path"),Bko=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N1e=a("code"),Iko=o("pretrained_model_name_or_path"),Nko=o(":"),qko=l(),y=a("ul"),B_=a("li"),q1e=a("strong"),Dko=o("albert"),jko=o(" \u2014 "),SX=a("a"),Gko=o("AlbertModel"),Oko=o(" (ALBERT model)"),Vko=l(),I_=a("li"),D1e=a("strong"),Xko=o("bart"),zko=o(" \u2014 "),RX=a("a"),Qko=o("BartModel"),Wko=o(" (BART model)"),Uko=l(),N_=a("li"),j1e=a("strong"),Hko=o("beit"),Jko=o(" \u2014 "),PX=a("a"),Yko=o("BeitModel"),Zko=o(" (BEiT model)"),Kko=l(),q_=a("li"),G1e=a("strong"),eSo=o("bert"),oSo=o(" \u2014 "),BX=a("a"),rSo=o("BertModel"),tSo=o(" (BERT model)"),aSo=l(),D_=a("li"),O1e=a("strong"),nSo=o("bert-generation"),sSo=o(" \u2014 "),IX=a("a"),lSo=o("BertGenerationEncoder"),iSo=o(" (Bert Generation model)"),dSo=l(),j_=a("li"),V1e=a("strong"),mSo=o("big_bird"),cSo=o(" \u2014 "),NX=a("a"),fSo=o("BigBirdModel"),gSo=o(" (BigBird model)"),hSo=l(),G_=a("li"),X1e=a("strong"),uSo=o("bigbird_pegasus"),pSo=o(" \u2014 "),qX=a("a"),_So=o("BigBirdPegasusModel"),bSo=o(" (BigBird-Pegasus model)"),vSo=l(),O_=a("li"),z1e=a("strong"),FSo=o("blenderbot"),TSo=o(" \u2014 "),DX=a("a"),MSo=o("BlenderbotModel"),ESo=o(" (Blenderbot model)"),CSo=l(),V_=a("li"),Q1e=a("strong"),wSo=o("blenderbot-small"),ASo=o(" \u2014 "),jX=a("a"),LSo=o("BlenderbotSmallModel"),ySo=o(" (BlenderbotSmall model)"),xSo=l(),X_=a("li"),W1e=a("strong"),$So=o("bloom"),kSo=o(" \u2014 "),GX=a("a"),SSo=o("BloomModel"),RSo=o(" (BLOOM model)"),PSo=l(),z_=a("li"),U1e=a("strong"),BSo=o("camembert"),ISo=o(" \u2014 "),OX=a("a"),NSo=o("CamembertModel"),qSo=o(" (CamemBERT model)"),DSo=l(),Q_=a("li"),H1e=a("strong"),jSo=o("canine"),GSo=o(" \u2014 "),VX=a("a"),OSo=o("CanineModel"),VSo=o(" (CANINE model)"),XSo=l(),W_=a("li"),J1e=a("strong"),zSo=o("clip"),QSo=o(" \u2014 "),XX=a("a"),WSo=o("CLIPModel"),USo=o(" (CLIP model)"),HSo=l(),U_=a("li"),Y1e=a("strong"),JSo=o("codegen"),YSo=o(" \u2014 "),zX=a("a"),ZSo=o("CodeGenModel"),KSo=o(" (CodeGen model)"),eRo=l(),H_=a("li"),Z1e=a("strong"),oRo=o("conditional_detr"),rRo=o(" \u2014 "),QX=a("a"),tRo=o("ConditionalDetrModel"),aRo=o(" (Conditional DETR model)"),nRo=l(),J_=a("li"),K1e=a("strong"),sRo=o("convbert"),lRo=o(" \u2014 "),WX=a("a"),iRo=o("ConvBertModel"),dRo=o(" (ConvBERT model)"),mRo=l(),Y_=a("li"),e2e=a("strong"),cRo=o("convnext"),fRo=o(" \u2014 "),UX=a("a"),gRo=o("ConvNextModel"),hRo=o(" (ConvNeXT model)"),uRo=l(),Z_=a("li"),o2e=a("strong"),pRo=o("ctrl"),_Ro=o(" \u2014 "),HX=a("a"),bRo=o("CTRLModel"),vRo=o(" (CTRL model)"),FRo=l(),K_=a("li"),r2e=a("strong"),TRo=o("cvt"),MRo=o(" \u2014 "),JX=a("a"),ERo=o("CvtModel"),CRo=o(" (CvT model)"),wRo=l(),e1=a("li"),t2e=a("strong"),ARo=o("data2vec-audio"),LRo=o(" \u2014 "),YX=a("a"),yRo=o("Data2VecAudioModel"),xRo=o(" (Data2VecAudio model)"),$Ro=l(),o1=a("li"),a2e=a("strong"),kRo=o("data2vec-text"),SRo=o(" \u2014 "),ZX=a("a"),RRo=o("Data2VecTextModel"),PRo=o(" (Data2VecText model)"),BRo=l(),r1=a("li"),n2e=a("strong"),IRo=o("data2vec-vision"),NRo=o(" \u2014 "),KX=a("a"),qRo=o("Data2VecVisionModel"),DRo=o(" (Data2VecVision model)"),jRo=l(),t1=a("li"),s2e=a("strong"),GRo=o("deberta"),ORo=o(" \u2014 "),ez=a("a"),VRo=o("DebertaModel"),XRo=o(" (DeBERTa model)"),zRo=l(),a1=a("li"),l2e=a("strong"),QRo=o("deberta-v2"),WRo=o(" \u2014 "),oz=a("a"),URo=o("DebertaV2Model"),HRo=o(" (DeBERTa-v2 model)"),JRo=l(),n1=a("li"),i2e=a("strong"),YRo=o("decision_transformer"),ZRo=o(" \u2014 "),rz=a("a"),KRo=o("DecisionTransformerModel"),ePo=o(" (Decision Transformer model)"),oPo=l(),s1=a("li"),d2e=a("strong"),rPo=o("deformable_detr"),tPo=o(" \u2014 "),tz=a("a"),aPo=o("DeformableDetrModel"),nPo=o(" (Deformable DETR model)"),sPo=l(),l1=a("li"),m2e=a("strong"),lPo=o("deit"),iPo=o(" \u2014 "),az=a("a"),dPo=o("DeiTModel"),mPo=o(" (DeiT model)"),cPo=l(),i1=a("li"),c2e=a("strong"),fPo=o("detr"),gPo=o(" \u2014 "),nz=a("a"),hPo=o("DetrModel"),uPo=o(" (DETR model)"),pPo=l(),d1=a("li"),f2e=a("strong"),_Po=o("distilbert"),bPo=o(" \u2014 "),sz=a("a"),vPo=o("DistilBertModel"),FPo=o(" (DistilBERT model)"),TPo=l(),m1=a("li"),g2e=a("strong"),MPo=o("donut-swin"),EPo=o(" \u2014 "),lz=a("a"),CPo=o("DonutSwinModel"),wPo=o(" (DonutSwin model)"),APo=l(),c1=a("li"),h2e=a("strong"),LPo=o("dpr"),yPo=o(" \u2014 "),iz=a("a"),xPo=o("DPRQuestionEncoder"),$Po=o(" (DPR model)"),kPo=l(),f1=a("li"),u2e=a("strong"),SPo=o("dpt"),RPo=o(" \u2014 "),dz=a("a"),PPo=o("DPTModel"),BPo=o(" (DPT model)"),IPo=l(),g1=a("li"),p2e=a("strong"),NPo=o("electra"),qPo=o(" \u2014 "),mz=a("a"),DPo=o("ElectraModel"),jPo=o(" (ELECTRA model)"),GPo=l(),h1=a("li"),_2e=a("strong"),OPo=o("ernie"),VPo=o(" \u2014 "),cz=a("a"),XPo=o("ErnieModel"),zPo=o(" (ERNIE model)"),QPo=l(),u1=a("li"),b2e=a("strong"),WPo=o("esm"),UPo=o(" \u2014 "),fz=a("a"),HPo=o("EsmModel"),JPo=o(" (ESM model)"),YPo=l(),p1=a("li"),v2e=a("strong"),ZPo=o("flaubert"),KPo=o(" \u2014 "),gz=a("a"),eBo=o("FlaubertModel"),oBo=o(" (FlauBERT model)"),rBo=l(),_1=a("li"),F2e=a("strong"),tBo=o("flava"),aBo=o(" \u2014 "),hz=a("a"),nBo=o("FlavaModel"),sBo=o(" (FLAVA model)"),lBo=l(),b1=a("li"),T2e=a("strong"),iBo=o("fnet"),dBo=o(" \u2014 "),uz=a("a"),mBo=o("FNetModel"),cBo=o(" (FNet model)"),fBo=l(),v1=a("li"),M2e=a("strong"),gBo=o("fsmt"),hBo=o(" \u2014 "),pz=a("a"),uBo=o("FSMTModel"),pBo=o(" (FairSeq Machine-Translation model)"),_Bo=l(),xl=a("li"),E2e=a("strong"),bBo=o("funnel"),vBo=o(" \u2014 "),_z=a("a"),FBo=o("FunnelModel"),TBo=o(" or "),bz=a("a"),MBo=o("FunnelBaseModel"),EBo=o(" (Funnel Transformer model)"),CBo=l(),F1=a("li"),C2e=a("strong"),wBo=o("glpn"),ABo=o(" \u2014 "),vz=a("a"),LBo=o("GLPNModel"),yBo=o(" (GLPN model)"),xBo=l(),T1=a("li"),w2e=a("strong"),$Bo=o("gpt2"),kBo=o(" \u2014 "),Fz=a("a"),SBo=o("GPT2Model"),RBo=o(" (OpenAI GPT-2 model)"),PBo=l(),M1=a("li"),A2e=a("strong"),BBo=o("gpt_neo"),IBo=o(" \u2014 "),Tz=a("a"),NBo=o("GPTNeoModel"),qBo=o(" (GPT Neo model)"),DBo=l(),E1=a("li"),L2e=a("strong"),jBo=o("gpt_neox"),GBo=o(" \u2014 "),Mz=a("a"),OBo=o("GPTNeoXModel"),VBo=o(" (GPT NeoX model)"),XBo=l(),C1=a("li"),y2e=a("strong"),zBo=o("gpt_neox_japanese"),QBo=o(" \u2014 "),Ez=a("a"),WBo=o("GPTNeoXJapaneseModel"),UBo=o(" (GPT NeoX Japanese model)"),HBo=l(),w1=a("li"),x2e=a("strong"),JBo=o("gptj"),YBo=o(" \u2014 "),Cz=a("a"),ZBo=o("GPTJModel"),KBo=o(" (GPT-J model)"),eIo=l(),A1=a("li"),$2e=a("strong"),oIo=o("groupvit"),rIo=o(" \u2014 "),wz=a("a"),tIo=o("GroupViTModel"),aIo=o(" (GroupViT model)"),nIo=l(),L1=a("li"),k2e=a("strong"),sIo=o("hubert"),lIo=o(" \u2014 "),Az=a("a"),iIo=o("HubertModel"),dIo=o(" (Hubert model)"),mIo=l(),y1=a("li"),S2e=a("strong"),cIo=o("ibert"),fIo=o(" \u2014 "),Lz=a("a"),gIo=o("IBertModel"),hIo=o(" (I-BERT model)"),uIo=l(),x1=a("li"),R2e=a("strong"),pIo=o("imagegpt"),_Io=o(" \u2014 "),yz=a("a"),bIo=o("ImageGPTModel"),vIo=o(" (ImageGPT model)"),FIo=l(),$1=a("li"),P2e=a("strong"),TIo=o("layoutlm"),MIo=o(" \u2014 "),xz=a("a"),EIo=o("LayoutLMModel"),CIo=o(" (LayoutLM model)"),wIo=l(),k1=a("li"),B2e=a("strong"),AIo=o("layoutlmv2"),LIo=o(" \u2014 "),$z=a("a"),yIo=o("LayoutLMv2Model"),xIo=o(" (LayoutLMv2 model)"),$Io=l(),S1=a("li"),I2e=a("strong"),kIo=o("layoutlmv3"),SIo=o(" \u2014 "),kz=a("a"),RIo=o("LayoutLMv3Model"),PIo=o(" (LayoutLMv3 model)"),BIo=l(),R1=a("li"),N2e=a("strong"),IIo=o("led"),NIo=o(" \u2014 "),Sz=a("a"),qIo=o("LEDModel"),DIo=o(" (LED model)"),jIo=l(),P1=a("li"),q2e=a("strong"),GIo=o("levit"),OIo=o(" \u2014 "),Rz=a("a"),VIo=o("LevitModel"),XIo=o(" (LeViT model)"),zIo=l(),B1=a("li"),D2e=a("strong"),QIo=o("lilt"),WIo=o(" \u2014 "),Pz=a("a"),UIo=o("LiltModel"),HIo=o(" (LiLT model)"),JIo=l(),I1=a("li"),j2e=a("strong"),YIo=o("longformer"),ZIo=o(" \u2014 "),Bz=a("a"),KIo=o("LongformerModel"),eNo=o(" (Longformer model)"),oNo=l(),N1=a("li"),G2e=a("strong"),rNo=o("longt5"),tNo=o(" \u2014 "),Iz=a("a"),aNo=o("LongT5Model"),nNo=o(" (LongT5 model)"),sNo=l(),q1=a("li"),O2e=a("strong"),lNo=o("luke"),iNo=o(" \u2014 "),Nz=a("a"),dNo=o("LukeModel"),mNo=o(" (LUKE model)"),cNo=l(),D1=a("li"),V2e=a("strong"),fNo=o("lxmert"),gNo=o(" \u2014 "),qz=a("a"),hNo=o("LxmertModel"),uNo=o(" (LXMERT model)"),pNo=l(),j1=a("li"),X2e=a("strong"),_No=o("m2m_100"),bNo=o(" \u2014 "),Dz=a("a"),vNo=o("M2M100Model"),FNo=o(" (M2M100 model)"),TNo=l(),G1=a("li"),z2e=a("strong"),MNo=o("marian"),ENo=o(" \u2014 "),jz=a("a"),CNo=o("MarianModel"),wNo=o(" (Marian model)"),ANo=l(),O1=a("li"),Q2e=a("strong"),LNo=o("markuplm"),yNo=o(" \u2014 "),Gz=a("a"),xNo=o("MarkupLMModel"),$No=o(" (MarkupLM model)"),kNo=l(),V1=a("li"),W2e=a("strong"),SNo=o("maskformer"),RNo=o(" \u2014 "),Oz=a("a"),PNo=o("MaskFormerModel"),BNo=o(" (MaskFormer model)"),INo=l(),X1=a("li"),U2e=a("strong"),NNo=o("mbart"),qNo=o(" \u2014 "),Vz=a("a"),DNo=o("MBartModel"),jNo=o(" (mBART model)"),GNo=l(),z1=a("li"),H2e=a("strong"),ONo=o("mctct"),VNo=o(" \u2014 "),Xz=a("a"),XNo=o("MCTCTModel"),zNo=o(" (M-CTC-T model)"),QNo=l(),Q1=a("li"),J2e=a("strong"),WNo=o("megatron-bert"),UNo=o(" \u2014 "),zz=a("a"),HNo=o("MegatronBertModel"),JNo=o(" (Megatron-BERT model)"),YNo=l(),W1=a("li"),Y2e=a("strong"),ZNo=o("mobilebert"),KNo=o(" \u2014 "),Qz=a("a"),eqo=o("MobileBertModel"),oqo=o(" (MobileBERT model)"),rqo=l(),U1=a("li"),Z2e=a("strong"),tqo=o("mobilevit"),aqo=o(" \u2014 "),Wz=a("a"),nqo=o("MobileViTModel"),sqo=o(" (MobileViT model)"),lqo=l(),H1=a("li"),K2e=a("strong"),iqo=o("mpnet"),dqo=o(" \u2014 "),Uz=a("a"),mqo=o("MPNetModel"),cqo=o(" (MPNet model)"),fqo=l(),J1=a("li"),ebe=a("strong"),gqo=o("mt5"),hqo=o(" \u2014 "),Hz=a("a"),uqo=o("MT5Model"),pqo=o(" (MT5 model)"),_qo=l(),Y1=a("li"),obe=a("strong"),bqo=o("mvp"),vqo=o(" \u2014 "),Jz=a("a"),Fqo=o("MvpModel"),Tqo=o(" (MVP model)"),Mqo=l(),Z1=a("li"),rbe=a("strong"),Eqo=o("nezha"),Cqo=o(" \u2014 "),Yz=a("a"),wqo=o("NezhaModel"),Aqo=o(" (Nezha model)"),Lqo=l(),K1=a("li"),tbe=a("strong"),yqo=o("nllb"),xqo=o(" \u2014 "),Zz=a("a"),$qo=o("M2M100Model"),kqo=o(" (NLLB model)"),Sqo=l(),e2=a("li"),abe=a("strong"),Rqo=o("nystromformer"),Pqo=o(" \u2014 "),Kz=a("a"),Bqo=o("NystromformerModel"),Iqo=o(" (Nystr\xF6mformer model)"),Nqo=l(),o2=a("li"),nbe=a("strong"),qqo=o("openai-gpt"),Dqo=o(" \u2014 "),eQ=a("a"),jqo=o("OpenAIGPTModel"),Gqo=o(" (OpenAI GPT model)"),Oqo=l(),r2=a("li"),sbe=a("strong"),Vqo=o("opt"),Xqo=o(" \u2014 "),oQ=a("a"),zqo=o("OPTModel"),Qqo=o(" (OPT model)"),Wqo=l(),t2=a("li"),lbe=a("strong"),Uqo=o("owlvit"),Hqo=o(" \u2014 "),rQ=a("a"),Jqo=o("OwlViTModel"),Yqo=o(" (OWL-ViT model)"),Zqo=l(),a2=a("li"),ibe=a("strong"),Kqo=o("pegasus"),eDo=o(" \u2014 "),tQ=a("a"),oDo=o("PegasusModel"),rDo=o(" (Pegasus model)"),tDo=l(),n2=a("li"),dbe=a("strong"),aDo=o("pegasus_x"),nDo=o(" \u2014 "),aQ=a("a"),sDo=o("PegasusXModel"),lDo=o(" (PEGASUS-X model)"),iDo=l(),s2=a("li"),mbe=a("strong"),dDo=o("perceiver"),mDo=o(" \u2014 "),nQ=a("a"),cDo=o("PerceiverModel"),fDo=o(" (Perceiver model)"),gDo=l(),l2=a("li"),cbe=a("strong"),hDo=o("plbart"),uDo=o(" \u2014 "),sQ=a("a"),pDo=o("PLBartModel"),_Do=o(" (PLBart model)"),bDo=l(),i2=a("li"),fbe=a("strong"),vDo=o("poolformer"),FDo=o(" \u2014 "),lQ=a("a"),TDo=o("PoolFormerModel"),MDo=o(" (PoolFormer model)"),EDo=l(),d2=a("li"),gbe=a("strong"),CDo=o("prophetnet"),wDo=o(" \u2014 "),iQ=a("a"),ADo=o("ProphetNetModel"),LDo=o(" (ProphetNet model)"),yDo=l(),m2=a("li"),hbe=a("strong"),xDo=o("qdqbert"),$Do=o(" \u2014 "),dQ=a("a"),kDo=o("QDQBertModel"),SDo=o(" (QDQBert model)"),RDo=l(),c2=a("li"),ube=a("strong"),PDo=o("reformer"),BDo=o(" \u2014 "),mQ=a("a"),IDo=o("ReformerModel"),NDo=o(" (Reformer model)"),qDo=l(),f2=a("li"),pbe=a("strong"),DDo=o("regnet"),jDo=o(" \u2014 "),cQ=a("a"),GDo=o("RegNetModel"),ODo=o(" (RegNet model)"),VDo=l(),g2=a("li"),_be=a("strong"),XDo=o("rembert"),zDo=o(" \u2014 "),fQ=a("a"),QDo=o("RemBertModel"),WDo=o(" (RemBERT model)"),UDo=l(),h2=a("li"),bbe=a("strong"),HDo=o("resnet"),JDo=o(" \u2014 "),gQ=a("a"),YDo=o("ResNetModel"),ZDo=o(" (ResNet model)"),KDo=l(),u2=a("li"),vbe=a("strong"),ejo=o("retribert"),ojo=o(" \u2014 "),hQ=a("a"),rjo=o("RetriBertModel"),tjo=o(" (RetriBERT model)"),ajo=l(),p2=a("li"),Fbe=a("strong"),njo=o("roberta"),sjo=o(" \u2014 "),uQ=a("a"),ljo=o("RobertaModel"),ijo=o(" (RoBERTa model)"),djo=l(),_2=a("li"),Tbe=a("strong"),mjo=o("roformer"),cjo=o(" \u2014 "),pQ=a("a"),fjo=o("RoFormerModel"),gjo=o(" (RoFormer model)"),hjo=l(),b2=a("li"),Mbe=a("strong"),ujo=o("segformer"),pjo=o(" \u2014 "),_Q=a("a"),_jo=o("SegformerModel"),bjo=o(" (SegFormer model)"),vjo=l(),v2=a("li"),Ebe=a("strong"),Fjo=o("sew"),Tjo=o(" \u2014 "),bQ=a("a"),Mjo=o("SEWModel"),Ejo=o(" (SEW model)"),Cjo=l(),F2=a("li"),Cbe=a("strong"),wjo=o("sew-d"),Ajo=o(" \u2014 "),vQ=a("a"),Ljo=o("SEWDModel"),yjo=o(" (SEW-D model)"),xjo=l(),T2=a("li"),wbe=a("strong"),$jo=o("speech_to_text"),kjo=o(" \u2014 "),FQ=a("a"),Sjo=o("Speech2TextModel"),Rjo=o(" (Speech2Text model)"),Pjo=l(),M2=a("li"),Abe=a("strong"),Bjo=o("splinter"),Ijo=o(" \u2014 "),TQ=a("a"),Njo=o("SplinterModel"),qjo=o(" (Splinter model)"),Djo=l(),E2=a("li"),Lbe=a("strong"),jjo=o("squeezebert"),Gjo=o(" \u2014 "),MQ=a("a"),Ojo=o("SqueezeBertModel"),Vjo=o(" (SqueezeBERT model)"),Xjo=l(),C2=a("li"),ybe=a("strong"),zjo=o("swin"),Qjo=o(" \u2014 "),EQ=a("a"),Wjo=o("SwinModel"),Ujo=o(" (Swin Transformer model)"),Hjo=l(),w2=a("li"),xbe=a("strong"),Jjo=o("swinv2"),Yjo=o(" \u2014 "),CQ=a("a"),Zjo=o("Swinv2Model"),Kjo=o(" (Swin Transformer V2 model)"),eGo=l(),A2=a("li"),$be=a("strong"),oGo=o("t5"),rGo=o(" \u2014 "),wQ=a("a"),tGo=o("T5Model"),aGo=o(" (T5 model)"),nGo=l(),L2=a("li"),kbe=a("strong"),sGo=o("table-transformer"),lGo=o(" \u2014 "),AQ=a("a"),iGo=o("TableTransformerModel"),dGo=o(" (Table Transformer model)"),mGo=l(),y2=a("li"),Sbe=a("strong"),cGo=o("tapas"),fGo=o(" \u2014 "),LQ=a("a"),gGo=o("TapasModel"),hGo=o(" (TAPAS model)"),uGo=l(),x2=a("li"),Rbe=a("strong"),pGo=o("time_series_transformer"),_Go=o(" \u2014 "),yQ=a("a"),bGo=o("TimeSeriesTransformerModel"),vGo=o(" (Time Series Transformer model)"),FGo=l(),$2=a("li"),Pbe=a("strong"),TGo=o("trajectory_transformer"),MGo=o(" \u2014 "),xQ=a("a"),EGo=o("TrajectoryTransformerModel"),CGo=o(" (Trajectory Transformer model)"),wGo=l(),k2=a("li"),Bbe=a("strong"),AGo=o("transfo-xl"),LGo=o(" \u2014 "),$Q=a("a"),yGo=o("TransfoXLModel"),xGo=o(" (Transformer-XL model)"),$Go=l(),S2=a("li"),Ibe=a("strong"),kGo=o("unispeech"),SGo=o(" \u2014 "),kQ=a("a"),RGo=o("UniSpeechModel"),PGo=o(" (UniSpeech model)"),BGo=l(),R2=a("li"),Nbe=a("strong"),IGo=o("unispeech-sat"),NGo=o(" \u2014 "),SQ=a("a"),qGo=o("UniSpeechSatModel"),DGo=o(" (UniSpeechSat model)"),jGo=l(),P2=a("li"),qbe=a("strong"),GGo=o("van"),OGo=o(" \u2014 "),RQ=a("a"),VGo=o("VanModel"),XGo=o(" (VAN model)"),zGo=l(),B2=a("li"),Dbe=a("strong"),QGo=o("videomae"),WGo=o(" \u2014 "),PQ=a("a"),UGo=o("VideoMAEModel"),HGo=o(" (VideoMAE model)"),JGo=l(),I2=a("li"),jbe=a("strong"),YGo=o("vilt"),ZGo=o(" \u2014 "),BQ=a("a"),KGo=o("ViltModel"),eOo=o(" (ViLT model)"),oOo=l(),N2=a("li"),Gbe=a("strong"),rOo=o("vision-text-dual-encoder"),tOo=o(" \u2014 "),IQ=a("a"),aOo=o("VisionTextDualEncoderModel"),nOo=o(" (VisionTextDualEncoder model)"),sOo=l(),q2=a("li"),Obe=a("strong"),lOo=o("visual_bert"),iOo=o(" \u2014 "),NQ=a("a"),dOo=o("VisualBertModel"),mOo=o(" (VisualBERT model)"),cOo=l(),D2=a("li"),Vbe=a("strong"),fOo=o("vit"),gOo=o(" \u2014 "),qQ=a("a"),hOo=o("ViTModel"),uOo=o(" (ViT model)"),pOo=l(),j2=a("li"),Xbe=a("strong"),_Oo=o("vit_mae"),bOo=o(" \u2014 "),DQ=a("a"),vOo=o("ViTMAEModel"),FOo=o(" (ViTMAE model)"),TOo=l(),G2=a("li"),zbe=a("strong"),MOo=o("vit_msn"),EOo=o(" \u2014 "),jQ=a("a"),COo=o("ViTMSNModel"),wOo=o(" (ViTMSN model)"),AOo=l(),O2=a("li"),Qbe=a("strong"),LOo=o("wav2vec2"),yOo=o(" \u2014 "),GQ=a("a"),xOo=o("Wav2Vec2Model"),$Oo=o(" (Wav2Vec2 model)"),kOo=l(),V2=a("li"),Wbe=a("strong"),SOo=o("wav2vec2-conformer"),ROo=o(" \u2014 "),OQ=a("a"),POo=o("Wav2Vec2ConformerModel"),BOo=o(" (Wav2Vec2-Conformer model)"),IOo=l(),X2=a("li"),Ube=a("strong"),NOo=o("wavlm"),qOo=o(" \u2014 "),VQ=a("a"),DOo=o("WavLMModel"),jOo=o(" (WavLM model)"),GOo=l(),z2=a("li"),Hbe=a("strong"),OOo=o("whisper"),VOo=o(" \u2014 "),XQ=a("a"),XOo=o("WhisperModel"),zOo=o(" (Whisper model)"),QOo=l(),Q2=a("li"),Jbe=a("strong"),WOo=o("xclip"),UOo=o(" \u2014 "),zQ=a("a"),HOo=o("XCLIPModel"),JOo=o(" (X-CLIP model)"),YOo=l(),W2=a("li"),Ybe=a("strong"),ZOo=o("xglm"),KOo=o(" \u2014 "),QQ=a("a"),eVo=o("XGLMModel"),oVo=o(" (XGLM model)"),rVo=l(),U2=a("li"),Zbe=a("strong"),tVo=o("xlm"),aVo=o(" \u2014 "),WQ=a("a"),nVo=o("XLMModel"),sVo=o(" (XLM model)"),lVo=l(),H2=a("li"),Kbe=a("strong"),iVo=o("xlm-prophetnet"),dVo=o(" \u2014 "),UQ=a("a"),mVo=o("XLMProphetNetModel"),cVo=o(" (XLM-ProphetNet model)"),fVo=l(),J2=a("li"),eve=a("strong"),gVo=o("xlm-roberta"),hVo=o(" \u2014 "),HQ=a("a"),uVo=o("XLMRobertaModel"),pVo=o(" (XLM-RoBERTa model)"),_Vo=l(),Y2=a("li"),ove=a("strong"),bVo=o("xlm-roberta-xl"),vVo=o(" \u2014 "),JQ=a("a"),FVo=o("XLMRobertaXLModel"),TVo=o(" (XLM-RoBERTa-XL model)"),MVo=l(),Z2=a("li"),rve=a("strong"),EVo=o("xlnet"),CVo=o(" \u2014 "),YQ=a("a"),wVo=o("XLNetModel"),AVo=o(" (XLNet model)"),LVo=l(),K2=a("li"),tve=a("strong"),yVo=o("yolos"),xVo=o(" \u2014 "),ZQ=a("a"),$Vo=o("YolosModel"),kVo=o(" (YOLOS model)"),SVo=l(),eb=a("li"),ave=a("strong"),RVo=o("yoso"),PVo=o(" \u2014 "),KQ=a("a"),BVo=o("YosoModel"),IVo=o(" (YOSO model)"),NVo=l(),ob=a("p"),qVo=o("The model is set in evaluation mode by default using "),nve=a("code"),DVo=o("model.eval()"),jVo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sve=a("code"),GVo=o("model.train()"),OVo=l(),F(rb.$$.fragment),Xto=l(),Bd=a("h2"),tb=a("a"),lve=a("span"),F(G$.$$.fragment),VVo=l(),ive=a("span"),XVo=o("AutoModelForPreTraining"),zto=l(),No=a("div"),F(O$.$$.fragment),zVo=l(),Id=a("p"),QVo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),eW=a("a"),WVo=o("from_pretrained()"),UVo=o(" class method or the "),oW=a("a"),HVo=o("from_config()"),JVo=o(` class
method.`),YVo=l(),V$=a("p"),ZVo=o("This class cannot be instantiated directly using "),dve=a("code"),KVo=o("__init__()"),eXo=o(" (throws an error)."),oXo=l(),Et=a("div"),F(X$.$$.fragment),rXo=l(),mve=a("p"),tXo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),aXo=l(),Nd=a("p"),nXo=o(`Note:
Loading a model from its configuration file does `),cve=a("strong"),sXo=o("not"),lXo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rW=a("a"),iXo=o("from_pretrained()"),dXo=o(" to load the model weights."),mXo=l(),F(ab.$$.fragment),cXo=l(),eo=a("div"),F(z$.$$.fragment),fXo=l(),fve=a("p"),gXo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),hXo=l(),sn=a("p"),uXo=o("The model class to instantiate is selected based on the "),gve=a("code"),pXo=o("model_type"),_Xo=o(` property of the config object (either
passed as an argument or loaded from `),hve=a("code"),bXo=o("pretrained_model_name_or_path"),vXo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uve=a("code"),FXo=o("pretrained_model_name_or_path"),TXo=o(":"),MXo=l(),G=a("ul"),nb=a("li"),pve=a("strong"),EXo=o("albert"),CXo=o(" \u2014 "),tW=a("a"),wXo=o("AlbertForPreTraining"),AXo=o(" (ALBERT model)"),LXo=l(),sb=a("li"),_ve=a("strong"),yXo=o("bart"),xXo=o(" \u2014 "),aW=a("a"),$Xo=o("BartForConditionalGeneration"),kXo=o(" (BART model)"),SXo=l(),lb=a("li"),bve=a("strong"),RXo=o("bert"),PXo=o(" \u2014 "),nW=a("a"),BXo=o("BertForPreTraining"),IXo=o(" (BERT model)"),NXo=l(),ib=a("li"),vve=a("strong"),qXo=o("big_bird"),DXo=o(" \u2014 "),sW=a("a"),jXo=o("BigBirdForPreTraining"),GXo=o(" (BigBird model)"),OXo=l(),db=a("li"),Fve=a("strong"),VXo=o("bloom"),XXo=o(" \u2014 "),lW=a("a"),zXo=o("BloomForCausalLM"),QXo=o(" (BLOOM model)"),WXo=l(),mb=a("li"),Tve=a("strong"),UXo=o("camembert"),HXo=o(" \u2014 "),iW=a("a"),JXo=o("CamembertForMaskedLM"),YXo=o(" (CamemBERT model)"),ZXo=l(),cb=a("li"),Mve=a("strong"),KXo=o("ctrl"),ezo=o(" \u2014 "),dW=a("a"),ozo=o("CTRLLMHeadModel"),rzo=o(" (CTRL model)"),tzo=l(),fb=a("li"),Eve=a("strong"),azo=o("data2vec-text"),nzo=o(" \u2014 "),mW=a("a"),szo=o("Data2VecTextForMaskedLM"),lzo=o(" (Data2VecText model)"),izo=l(),gb=a("li"),Cve=a("strong"),dzo=o("deberta"),mzo=o(" \u2014 "),cW=a("a"),czo=o("DebertaForMaskedLM"),fzo=o(" (DeBERTa model)"),gzo=l(),hb=a("li"),wve=a("strong"),hzo=o("deberta-v2"),uzo=o(" \u2014 "),fW=a("a"),pzo=o("DebertaV2ForMaskedLM"),_zo=o(" (DeBERTa-v2 model)"),bzo=l(),ub=a("li"),Ave=a("strong"),vzo=o("distilbert"),Fzo=o(" \u2014 "),gW=a("a"),Tzo=o("DistilBertForMaskedLM"),Mzo=o(" (DistilBERT model)"),Ezo=l(),pb=a("li"),Lve=a("strong"),Czo=o("electra"),wzo=o(" \u2014 "),hW=a("a"),Azo=o("ElectraForPreTraining"),Lzo=o(" (ELECTRA model)"),yzo=l(),_b=a("li"),yve=a("strong"),xzo=o("ernie"),$zo=o(" \u2014 "),uW=a("a"),kzo=o("ErnieForPreTraining"),Szo=o(" (ERNIE model)"),Rzo=l(),bb=a("li"),xve=a("strong"),Pzo=o("flaubert"),Bzo=o(" \u2014 "),pW=a("a"),Izo=o("FlaubertWithLMHeadModel"),Nzo=o(" (FlauBERT model)"),qzo=l(),vb=a("li"),$ve=a("strong"),Dzo=o("flava"),jzo=o(" \u2014 "),_W=a("a"),Gzo=o("FlavaForPreTraining"),Ozo=o(" (FLAVA model)"),Vzo=l(),Fb=a("li"),kve=a("strong"),Xzo=o("fnet"),zzo=o(" \u2014 "),bW=a("a"),Qzo=o("FNetForPreTraining"),Wzo=o(" (FNet model)"),Uzo=l(),Tb=a("li"),Sve=a("strong"),Hzo=o("fsmt"),Jzo=o(" \u2014 "),vW=a("a"),Yzo=o("FSMTForConditionalGeneration"),Zzo=o(" (FairSeq Machine-Translation model)"),Kzo=l(),Mb=a("li"),Rve=a("strong"),eQo=o("funnel"),oQo=o(" \u2014 "),FW=a("a"),rQo=o("FunnelForPreTraining"),tQo=o(" (Funnel Transformer model)"),aQo=l(),Eb=a("li"),Pve=a("strong"),nQo=o("gpt2"),sQo=o(" \u2014 "),TW=a("a"),lQo=o("GPT2LMHeadModel"),iQo=o(" (OpenAI GPT-2 model)"),dQo=l(),Cb=a("li"),Bve=a("strong"),mQo=o("ibert"),cQo=o(" \u2014 "),MW=a("a"),fQo=o("IBertForMaskedLM"),gQo=o(" (I-BERT model)"),hQo=l(),wb=a("li"),Ive=a("strong"),uQo=o("layoutlm"),pQo=o(" \u2014 "),EW=a("a"),_Qo=o("LayoutLMForMaskedLM"),bQo=o(" (LayoutLM model)"),vQo=l(),Ab=a("li"),Nve=a("strong"),FQo=o("longformer"),TQo=o(" \u2014 "),CW=a("a"),MQo=o("LongformerForMaskedLM"),EQo=o(" (Longformer model)"),CQo=l(),Lb=a("li"),qve=a("strong"),wQo=o("luke"),AQo=o(" \u2014 "),wW=a("a"),LQo=o("LukeForMaskedLM"),yQo=o(" (LUKE model)"),xQo=l(),yb=a("li"),Dve=a("strong"),$Qo=o("lxmert"),kQo=o(" \u2014 "),AW=a("a"),SQo=o("LxmertForPreTraining"),RQo=o(" (LXMERT model)"),PQo=l(),xb=a("li"),jve=a("strong"),BQo=o("megatron-bert"),IQo=o(" \u2014 "),LW=a("a"),NQo=o("MegatronBertForPreTraining"),qQo=o(" (Megatron-BERT model)"),DQo=l(),$b=a("li"),Gve=a("strong"),jQo=o("mobilebert"),GQo=o(" \u2014 "),yW=a("a"),OQo=o("MobileBertForPreTraining"),VQo=o(" (MobileBERT model)"),XQo=l(),kb=a("li"),Ove=a("strong"),zQo=o("mpnet"),QQo=o(" \u2014 "),xW=a("a"),WQo=o("MPNetForMaskedLM"),UQo=o(" (MPNet model)"),HQo=l(),Sb=a("li"),Vve=a("strong"),JQo=o("mvp"),YQo=o(" \u2014 "),$W=a("a"),ZQo=o("MvpForConditionalGeneration"),KQo=o(" (MVP model)"),eWo=l(),Rb=a("li"),Xve=a("strong"),oWo=o("nezha"),rWo=o(" \u2014 "),kW=a("a"),tWo=o("NezhaForPreTraining"),aWo=o(" (Nezha model)"),nWo=l(),Pb=a("li"),zve=a("strong"),sWo=o("openai-gpt"),lWo=o(" \u2014 "),SW=a("a"),iWo=o("OpenAIGPTLMHeadModel"),dWo=o(" (OpenAI GPT model)"),mWo=l(),Bb=a("li"),Qve=a("strong"),cWo=o("retribert"),fWo=o(" \u2014 "),RW=a("a"),gWo=o("RetriBertModel"),hWo=o(" (RetriBERT model)"),uWo=l(),Ib=a("li"),Wve=a("strong"),pWo=o("roberta"),_Wo=o(" \u2014 "),PW=a("a"),bWo=o("RobertaForMaskedLM"),vWo=o(" (RoBERTa model)"),FWo=l(),Nb=a("li"),Uve=a("strong"),TWo=o("splinter"),MWo=o(" \u2014 "),BW=a("a"),EWo=o("SplinterForPreTraining"),CWo=o(" (Splinter model)"),wWo=l(),qb=a("li"),Hve=a("strong"),AWo=o("squeezebert"),LWo=o(" \u2014 "),IW=a("a"),yWo=o("SqueezeBertForMaskedLM"),xWo=o(" (SqueezeBERT model)"),$Wo=l(),Db=a("li"),Jve=a("strong"),kWo=o("t5"),SWo=o(" \u2014 "),NW=a("a"),RWo=o("T5ForConditionalGeneration"),PWo=o(" (T5 model)"),BWo=l(),jb=a("li"),Yve=a("strong"),IWo=o("tapas"),NWo=o(" \u2014 "),qW=a("a"),qWo=o("TapasForMaskedLM"),DWo=o(" (TAPAS model)"),jWo=l(),Gb=a("li"),Zve=a("strong"),GWo=o("transfo-xl"),OWo=o(" \u2014 "),DW=a("a"),VWo=o("TransfoXLLMHeadModel"),XWo=o(" (Transformer-XL model)"),zWo=l(),Ob=a("li"),Kve=a("strong"),QWo=o("unispeech"),WWo=o(" \u2014 "),jW=a("a"),UWo=o("UniSpeechForPreTraining"),HWo=o(" (UniSpeech model)"),JWo=l(),Vb=a("li"),eFe=a("strong"),YWo=o("unispeech-sat"),ZWo=o(" \u2014 "),GW=a("a"),KWo=o("UniSpeechSatForPreTraining"),eUo=o(" (UniSpeechSat model)"),oUo=l(),Xb=a("li"),oFe=a("strong"),rUo=o("videomae"),tUo=o(" \u2014 "),OW=a("a"),aUo=o("VideoMAEForPreTraining"),nUo=o(" (VideoMAE model)"),sUo=l(),zb=a("li"),rFe=a("strong"),lUo=o("visual_bert"),iUo=o(" \u2014 "),VW=a("a"),dUo=o("VisualBertForPreTraining"),mUo=o(" (VisualBERT model)"),cUo=l(),Qb=a("li"),tFe=a("strong"),fUo=o("vit_mae"),gUo=o(" \u2014 "),XW=a("a"),hUo=o("ViTMAEForPreTraining"),uUo=o(" (ViTMAE model)"),pUo=l(),Wb=a("li"),aFe=a("strong"),_Uo=o("wav2vec2"),bUo=o(" \u2014 "),zW=a("a"),vUo=o("Wav2Vec2ForPreTraining"),FUo=o(" (Wav2Vec2 model)"),TUo=l(),Ub=a("li"),nFe=a("strong"),MUo=o("wav2vec2-conformer"),EUo=o(" \u2014 "),QW=a("a"),CUo=o("Wav2Vec2ConformerForPreTraining"),wUo=o(" (Wav2Vec2-Conformer model)"),AUo=l(),Hb=a("li"),sFe=a("strong"),LUo=o("xlm"),yUo=o(" \u2014 "),WW=a("a"),xUo=o("XLMWithLMHeadModel"),$Uo=o(" (XLM model)"),kUo=l(),Jb=a("li"),lFe=a("strong"),SUo=o("xlm-roberta"),RUo=o(" \u2014 "),UW=a("a"),PUo=o("XLMRobertaForMaskedLM"),BUo=o(" (XLM-RoBERTa model)"),IUo=l(),Yb=a("li"),iFe=a("strong"),NUo=o("xlm-roberta-xl"),qUo=o(" \u2014 "),HW=a("a"),DUo=o("XLMRobertaXLForMaskedLM"),jUo=o(" (XLM-RoBERTa-XL model)"),GUo=l(),Zb=a("li"),dFe=a("strong"),OUo=o("xlnet"),VUo=o(" \u2014 "),JW=a("a"),XUo=o("XLNetLMHeadModel"),zUo=o(" (XLNet model)"),QUo=l(),Kb=a("p"),WUo=o("The model is set in evaluation mode by default using "),mFe=a("code"),UUo=o("model.eval()"),HUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cFe=a("code"),JUo=o("model.train()"),YUo=l(),F(ev.$$.fragment),Qto=l(),qd=a("h2"),ov=a("a"),fFe=a("span"),F(Q$.$$.fragment),ZUo=l(),gFe=a("span"),KUo=o("AutoModelForCausalLM"),Wto=l(),qo=a("div"),F(W$.$$.fragment),eHo=l(),Dd=a("p"),oHo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),YW=a("a"),rHo=o("from_pretrained()"),tHo=o(" class method or the "),ZW=a("a"),aHo=o("from_config()"),nHo=o(` class
method.`),sHo=l(),U$=a("p"),lHo=o("This class cannot be instantiated directly using "),hFe=a("code"),iHo=o("__init__()"),dHo=o(" (throws an error)."),mHo=l(),Ct=a("div"),F(H$.$$.fragment),cHo=l(),uFe=a("p"),fHo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),gHo=l(),jd=a("p"),hHo=o(`Note:
Loading a model from its configuration file does `),pFe=a("strong"),uHo=o("not"),pHo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),KW=a("a"),_Ho=o("from_pretrained()"),bHo=o(" to load the model weights."),vHo=l(),F(rv.$$.fragment),FHo=l(),oo=a("div"),F(J$.$$.fragment),THo=l(),_Fe=a("p"),MHo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),EHo=l(),ln=a("p"),CHo=o("The model class to instantiate is selected based on the "),bFe=a("code"),wHo=o("model_type"),AHo=o(` property of the config object (either
passed as an argument or loaded from `),vFe=a("code"),LHo=o("pretrained_model_name_or_path"),yHo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FFe=a("code"),xHo=o("pretrained_model_name_or_path"),$Ho=o(":"),kHo=l(),W=a("ul"),tv=a("li"),TFe=a("strong"),SHo=o("bart"),RHo=o(" \u2014 "),eU=a("a"),PHo=o("BartForCausalLM"),BHo=o(" (BART model)"),IHo=l(),av=a("li"),MFe=a("strong"),NHo=o("bert"),qHo=o(" \u2014 "),oU=a("a"),DHo=o("BertLMHeadModel"),jHo=o(" (BERT model)"),GHo=l(),nv=a("li"),EFe=a("strong"),OHo=o("bert-generation"),VHo=o(" \u2014 "),rU=a("a"),XHo=o("BertGenerationDecoder"),zHo=o(" (Bert Generation model)"),QHo=l(),sv=a("li"),CFe=a("strong"),WHo=o("big_bird"),UHo=o(" \u2014 "),tU=a("a"),HHo=o("BigBirdForCausalLM"),JHo=o(" (BigBird model)"),YHo=l(),lv=a("li"),wFe=a("strong"),ZHo=o("bigbird_pegasus"),KHo=o(" \u2014 "),aU=a("a"),eJo=o("BigBirdPegasusForCausalLM"),oJo=o(" (BigBird-Pegasus model)"),rJo=l(),iv=a("li"),AFe=a("strong"),tJo=o("blenderbot"),aJo=o(" \u2014 "),nU=a("a"),nJo=o("BlenderbotForCausalLM"),sJo=o(" (Blenderbot model)"),lJo=l(),dv=a("li"),LFe=a("strong"),iJo=o("blenderbot-small"),dJo=o(" \u2014 "),sU=a("a"),mJo=o("BlenderbotSmallForCausalLM"),cJo=o(" (BlenderbotSmall model)"),fJo=l(),mv=a("li"),yFe=a("strong"),gJo=o("bloom"),hJo=o(" \u2014 "),lU=a("a"),uJo=o("BloomForCausalLM"),pJo=o(" (BLOOM model)"),_Jo=l(),cv=a("li"),xFe=a("strong"),bJo=o("camembert"),vJo=o(" \u2014 "),iU=a("a"),FJo=o("CamembertForCausalLM"),TJo=o(" (CamemBERT model)"),MJo=l(),fv=a("li"),$Fe=a("strong"),EJo=o("codegen"),CJo=o(" \u2014 "),dU=a("a"),wJo=o("CodeGenForCausalLM"),AJo=o(" (CodeGen model)"),LJo=l(),gv=a("li"),kFe=a("strong"),yJo=o("ctrl"),xJo=o(" \u2014 "),mU=a("a"),$Jo=o("CTRLLMHeadModel"),kJo=o(" (CTRL model)"),SJo=l(),hv=a("li"),SFe=a("strong"),RJo=o("data2vec-text"),PJo=o(" \u2014 "),cU=a("a"),BJo=o("Data2VecTextForCausalLM"),IJo=o(" (Data2VecText model)"),NJo=l(),uv=a("li"),RFe=a("strong"),qJo=o("electra"),DJo=o(" \u2014 "),fU=a("a"),jJo=o("ElectraForCausalLM"),GJo=o(" (ELECTRA model)"),OJo=l(),pv=a("li"),PFe=a("strong"),VJo=o("ernie"),XJo=o(" \u2014 "),gU=a("a"),zJo=o("ErnieForCausalLM"),QJo=o(" (ERNIE model)"),WJo=l(),_v=a("li"),BFe=a("strong"),UJo=o("gpt2"),HJo=o(" \u2014 "),hU=a("a"),JJo=o("GPT2LMHeadModel"),YJo=o(" (OpenAI GPT-2 model)"),ZJo=l(),bv=a("li"),IFe=a("strong"),KJo=o("gpt_neo"),eYo=o(" \u2014 "),uU=a("a"),oYo=o("GPTNeoForCausalLM"),rYo=o(" (GPT Neo model)"),tYo=l(),vv=a("li"),NFe=a("strong"),aYo=o("gpt_neox"),nYo=o(" \u2014 "),pU=a("a"),sYo=o("GPTNeoXForCausalLM"),lYo=o(" (GPT NeoX model)"),iYo=l(),Fv=a("li"),qFe=a("strong"),dYo=o("gpt_neox_japanese"),mYo=o(" \u2014 "),_U=a("a"),cYo=o("GPTNeoXJapaneseForCausalLM"),fYo=o(" (GPT NeoX Japanese model)"),gYo=l(),Tv=a("li"),DFe=a("strong"),hYo=o("gptj"),uYo=o(" \u2014 "),bU=a("a"),pYo=o("GPTJForCausalLM"),_Yo=o(" (GPT-J model)"),bYo=l(),Mv=a("li"),jFe=a("strong"),vYo=o("marian"),FYo=o(" \u2014 "),vU=a("a"),TYo=o("MarianForCausalLM"),MYo=o(" (Marian model)"),EYo=l(),Ev=a("li"),GFe=a("strong"),CYo=o("mbart"),wYo=o(" \u2014 "),FU=a("a"),AYo=o("MBartForCausalLM"),LYo=o(" (mBART model)"),yYo=l(),Cv=a("li"),OFe=a("strong"),xYo=o("megatron-bert"),$Yo=o(" \u2014 "),TU=a("a"),kYo=o("MegatronBertForCausalLM"),SYo=o(" (Megatron-BERT model)"),RYo=l(),wv=a("li"),VFe=a("strong"),PYo=o("mvp"),BYo=o(" \u2014 "),MU=a("a"),IYo=o("MvpForCausalLM"),NYo=o(" (MVP model)"),qYo=l(),Av=a("li"),XFe=a("strong"),DYo=o("openai-gpt"),jYo=o(" \u2014 "),EU=a("a"),GYo=o("OpenAIGPTLMHeadModel"),OYo=o(" (OpenAI GPT model)"),VYo=l(),Lv=a("li"),zFe=a("strong"),XYo=o("opt"),zYo=o(" \u2014 "),CU=a("a"),QYo=o("OPTForCausalLM"),WYo=o(" (OPT model)"),UYo=l(),yv=a("li"),QFe=a("strong"),HYo=o("pegasus"),JYo=o(" \u2014 "),wU=a("a"),YYo=o("PegasusForCausalLM"),ZYo=o(" (Pegasus model)"),KYo=l(),xv=a("li"),WFe=a("strong"),eZo=o("plbart"),oZo=o(" \u2014 "),AU=a("a"),rZo=o("PLBartForCausalLM"),tZo=o(" (PLBart model)"),aZo=l(),$v=a("li"),UFe=a("strong"),nZo=o("prophetnet"),sZo=o(" \u2014 "),LU=a("a"),lZo=o("ProphetNetForCausalLM"),iZo=o(" (ProphetNet model)"),dZo=l(),kv=a("li"),HFe=a("strong"),mZo=o("qdqbert"),cZo=o(" \u2014 "),yU=a("a"),fZo=o("QDQBertLMHeadModel"),gZo=o(" (QDQBert model)"),hZo=l(),Sv=a("li"),JFe=a("strong"),uZo=o("reformer"),pZo=o(" \u2014 "),xU=a("a"),_Zo=o("ReformerModelWithLMHead"),bZo=o(" (Reformer model)"),vZo=l(),Rv=a("li"),YFe=a("strong"),FZo=o("rembert"),TZo=o(" \u2014 "),$U=a("a"),MZo=o("RemBertForCausalLM"),EZo=o(" (RemBERT model)"),CZo=l(),Pv=a("li"),ZFe=a("strong"),wZo=o("roberta"),AZo=o(" \u2014 "),kU=a("a"),LZo=o("RobertaForCausalLM"),yZo=o(" (RoBERTa model)"),xZo=l(),Bv=a("li"),KFe=a("strong"),$Zo=o("roformer"),kZo=o(" \u2014 "),SU=a("a"),SZo=o("RoFormerForCausalLM"),RZo=o(" (RoFormer model)"),PZo=l(),Iv=a("li"),eTe=a("strong"),BZo=o("speech_to_text_2"),IZo=o(" \u2014 "),RU=a("a"),NZo=o("Speech2Text2ForCausalLM"),qZo=o(" (Speech2Text2 model)"),DZo=l(),Nv=a("li"),oTe=a("strong"),jZo=o("transfo-xl"),GZo=o(" \u2014 "),PU=a("a"),OZo=o("TransfoXLLMHeadModel"),VZo=o(" (Transformer-XL model)"),XZo=l(),qv=a("li"),rTe=a("strong"),zZo=o("trocr"),QZo=o(" \u2014 "),BU=a("a"),WZo=o("TrOCRForCausalLM"),UZo=o(" (TrOCR model)"),HZo=l(),Dv=a("li"),tTe=a("strong"),JZo=o("xglm"),YZo=o(" \u2014 "),IU=a("a"),ZZo=o("XGLMForCausalLM"),KZo=o(" (XGLM model)"),eKo=l(),jv=a("li"),aTe=a("strong"),oKo=o("xlm"),rKo=o(" \u2014 "),NU=a("a"),tKo=o("XLMWithLMHeadModel"),aKo=o(" (XLM model)"),nKo=l(),Gv=a("li"),nTe=a("strong"),sKo=o("xlm-prophetnet"),lKo=o(" \u2014 "),qU=a("a"),iKo=o("XLMProphetNetForCausalLM"),dKo=o(" (XLM-ProphetNet model)"),mKo=l(),Ov=a("li"),sTe=a("strong"),cKo=o("xlm-roberta"),fKo=o(" \u2014 "),DU=a("a"),gKo=o("XLMRobertaForCausalLM"),hKo=o(" (XLM-RoBERTa model)"),uKo=l(),Vv=a("li"),lTe=a("strong"),pKo=o("xlm-roberta-xl"),_Ko=o(" \u2014 "),jU=a("a"),bKo=o("XLMRobertaXLForCausalLM"),vKo=o(" (XLM-RoBERTa-XL model)"),FKo=l(),Xv=a("li"),iTe=a("strong"),TKo=o("xlnet"),MKo=o(" \u2014 "),GU=a("a"),EKo=o("XLNetLMHeadModel"),CKo=o(" (XLNet model)"),wKo=l(),zv=a("p"),AKo=o("The model is set in evaluation mode by default using "),dTe=a("code"),LKo=o("model.eval()"),yKo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mTe=a("code"),xKo=o("model.train()"),$Ko=l(),F(Qv.$$.fragment),Uto=l(),Gd=a("h2"),Wv=a("a"),cTe=a("span"),F(Y$.$$.fragment),kKo=l(),fTe=a("span"),SKo=o("AutoModelForDepthEstimation"),Hto=l(),Do=a("div"),F(Z$.$$.fragment),RKo=l(),Od=a("p"),PKo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a depth estimation head) when created
with the `),OU=a("a"),BKo=o("from_pretrained()"),IKo=o(" class method or the "),VU=a("a"),NKo=o("from_config()"),qKo=o(` class
method.`),DKo=l(),K$=a("p"),jKo=o("This class cannot be instantiated directly using "),gTe=a("code"),GKo=o("__init__()"),OKo=o(" (throws an error)."),VKo=l(),wt=a("div"),F(ek.$$.fragment),XKo=l(),hTe=a("p"),zKo=o("Instantiates one of the model classes of the library (with a depth estimation head) from a configuration."),QKo=l(),Vd=a("p"),WKo=o(`Note:
Loading a model from its configuration file does `),uTe=a("strong"),UKo=o("not"),HKo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XU=a("a"),JKo=o("from_pretrained()"),YKo=o(" to load the model weights."),ZKo=l(),F(Uv.$$.fragment),KKo=l(),ro=a("div"),F(ok.$$.fragment),eer=l(),pTe=a("p"),oer=o("Instantiate one of the model classes of the library (with a depth estimation head) from a pretrained model."),rer=l(),dn=a("p"),ter=o("The model class to instantiate is selected based on the "),_Te=a("code"),aer=o("model_type"),ner=o(` property of the config object (either
passed as an argument or loaded from `),bTe=a("code"),ser=o("pretrained_model_name_or_path"),ler=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vTe=a("code"),ier=o("pretrained_model_name_or_path"),der=o(":"),mer=l(),rk=a("ul"),Hv=a("li"),FTe=a("strong"),cer=o("dpt"),fer=o(" \u2014 "),zU=a("a"),ger=o("DPTForDepthEstimation"),her=o(" (DPT model)"),uer=l(),Jv=a("li"),TTe=a("strong"),per=o("glpn"),_er=o(" \u2014 "),QU=a("a"),ber=o("GLPNForDepthEstimation"),ver=o(" (GLPN model)"),Fer=l(),Yv=a("p"),Ter=o("The model is set in evaluation mode by default using "),MTe=a("code"),Mer=o("model.eval()"),Eer=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ETe=a("code"),Cer=o("model.train()"),wer=l(),F(Zv.$$.fragment),Jto=l(),Xd=a("h2"),Kv=a("a"),CTe=a("span"),F(tk.$$.fragment),Aer=l(),wTe=a("span"),Ler=o("AutoModelForMaskedLM"),Yto=l(),jo=a("div"),F(ak.$$.fragment),yer=l(),zd=a("p"),xer=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),WU=a("a"),$er=o("from_pretrained()"),ker=o(" class method or the "),UU=a("a"),Ser=o("from_config()"),Rer=o(` class
method.`),Per=l(),nk=a("p"),Ber=o("This class cannot be instantiated directly using "),ATe=a("code"),Ier=o("__init__()"),Ner=o(" (throws an error)."),qer=l(),At=a("div"),F(sk.$$.fragment),Der=l(),LTe=a("p"),jer=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Ger=l(),Qd=a("p"),Oer=o(`Note:
Loading a model from its configuration file does `),yTe=a("strong"),Ver=o("not"),Xer=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),HU=a("a"),zer=o("from_pretrained()"),Qer=o(" to load the model weights."),Wer=l(),F(eF.$$.fragment),Uer=l(),to=a("div"),F(lk.$$.fragment),Her=l(),xTe=a("p"),Jer=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Yer=l(),mn=a("p"),Zer=o("The model class to instantiate is selected based on the "),$Te=a("code"),Ker=o("model_type"),eor=o(` property of the config object (either
passed as an argument or loaded from `),kTe=a("code"),oor=o("pretrained_model_name_or_path"),ror=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),STe=a("code"),tor=o("pretrained_model_name_or_path"),aor=o(":"),nor=l(),Y=a("ul"),oF=a("li"),RTe=a("strong"),sor=o("albert"),lor=o(" \u2014 "),JU=a("a"),ior=o("AlbertForMaskedLM"),dor=o(" (ALBERT model)"),mor=l(),rF=a("li"),PTe=a("strong"),cor=o("bart"),gor=o(" \u2014 "),YU=a("a"),hor=o("BartForConditionalGeneration"),uor=o(" (BART model)"),por=l(),tF=a("li"),BTe=a("strong"),_or=o("bert"),bor=o(" \u2014 "),ZU=a("a"),vor=o("BertForMaskedLM"),For=o(" (BERT model)"),Tor=l(),aF=a("li"),ITe=a("strong"),Mor=o("big_bird"),Eor=o(" \u2014 "),KU=a("a"),Cor=o("BigBirdForMaskedLM"),wor=o(" (BigBird model)"),Aor=l(),nF=a("li"),NTe=a("strong"),Lor=o("camembert"),yor=o(" \u2014 "),eH=a("a"),xor=o("CamembertForMaskedLM"),$or=o(" (CamemBERT model)"),kor=l(),sF=a("li"),qTe=a("strong"),Sor=o("convbert"),Ror=o(" \u2014 "),oH=a("a"),Por=o("ConvBertForMaskedLM"),Bor=o(" (ConvBERT model)"),Ior=l(),lF=a("li"),DTe=a("strong"),Nor=o("data2vec-text"),qor=o(" \u2014 "),rH=a("a"),Dor=o("Data2VecTextForMaskedLM"),jor=o(" (Data2VecText model)"),Gor=l(),iF=a("li"),jTe=a("strong"),Oor=o("deberta"),Vor=o(" \u2014 "),tH=a("a"),Xor=o("DebertaForMaskedLM"),zor=o(" (DeBERTa model)"),Qor=l(),dF=a("li"),GTe=a("strong"),Wor=o("deberta-v2"),Uor=o(" \u2014 "),aH=a("a"),Hor=o("DebertaV2ForMaskedLM"),Jor=o(" (DeBERTa-v2 model)"),Yor=l(),mF=a("li"),OTe=a("strong"),Zor=o("distilbert"),Kor=o(" \u2014 "),nH=a("a"),err=o("DistilBertForMaskedLM"),orr=o(" (DistilBERT model)"),rrr=l(),cF=a("li"),VTe=a("strong"),trr=o("electra"),arr=o(" \u2014 "),sH=a("a"),nrr=o("ElectraForMaskedLM"),srr=o(" (ELECTRA model)"),lrr=l(),fF=a("li"),XTe=a("strong"),irr=o("ernie"),drr=o(" \u2014 "),lH=a("a"),mrr=o("ErnieForMaskedLM"),crr=o(" (ERNIE model)"),frr=l(),gF=a("li"),zTe=a("strong"),grr=o("flaubert"),hrr=o(" \u2014 "),iH=a("a"),urr=o("FlaubertWithLMHeadModel"),prr=o(" (FlauBERT model)"),_rr=l(),hF=a("li"),QTe=a("strong"),brr=o("fnet"),vrr=o(" \u2014 "),dH=a("a"),Frr=o("FNetForMaskedLM"),Trr=o(" (FNet model)"),Mrr=l(),uF=a("li"),WTe=a("strong"),Err=o("funnel"),Crr=o(" \u2014 "),mH=a("a"),wrr=o("FunnelForMaskedLM"),Arr=o(" (Funnel Transformer model)"),Lrr=l(),pF=a("li"),UTe=a("strong"),yrr=o("ibert"),xrr=o(" \u2014 "),cH=a("a"),$rr=o("IBertForMaskedLM"),krr=o(" (I-BERT model)"),Srr=l(),_F=a("li"),HTe=a("strong"),Rrr=o("layoutlm"),Prr=o(" \u2014 "),fH=a("a"),Brr=o("LayoutLMForMaskedLM"),Irr=o(" (LayoutLM model)"),Nrr=l(),bF=a("li"),JTe=a("strong"),qrr=o("longformer"),Drr=o(" \u2014 "),gH=a("a"),jrr=o("LongformerForMaskedLM"),Grr=o(" (Longformer model)"),Orr=l(),vF=a("li"),YTe=a("strong"),Vrr=o("luke"),Xrr=o(" \u2014 "),hH=a("a"),zrr=o("LukeForMaskedLM"),Qrr=o(" (LUKE model)"),Wrr=l(),FF=a("li"),ZTe=a("strong"),Urr=o("mbart"),Hrr=o(" \u2014 "),uH=a("a"),Jrr=o("MBartForConditionalGeneration"),Yrr=o(" (mBART model)"),Zrr=l(),TF=a("li"),KTe=a("strong"),Krr=o("megatron-bert"),etr=o(" \u2014 "),pH=a("a"),otr=o("MegatronBertForMaskedLM"),rtr=o(" (Megatron-BERT model)"),ttr=l(),MF=a("li"),eMe=a("strong"),atr=o("mobilebert"),ntr=o(" \u2014 "),_H=a("a"),str=o("MobileBertForMaskedLM"),ltr=o(" (MobileBERT model)"),itr=l(),EF=a("li"),oMe=a("strong"),dtr=o("mpnet"),mtr=o(" \u2014 "),bH=a("a"),ctr=o("MPNetForMaskedLM"),ftr=o(" (MPNet model)"),gtr=l(),CF=a("li"),rMe=a("strong"),htr=o("mvp"),utr=o(" \u2014 "),vH=a("a"),ptr=o("MvpForConditionalGeneration"),_tr=o(" (MVP model)"),btr=l(),wF=a("li"),tMe=a("strong"),vtr=o("nezha"),Ftr=o(" \u2014 "),FH=a("a"),Ttr=o("NezhaForMaskedLM"),Mtr=o(" (Nezha model)"),Etr=l(),AF=a("li"),aMe=a("strong"),Ctr=o("nystromformer"),wtr=o(" \u2014 "),TH=a("a"),Atr=o("NystromformerForMaskedLM"),Ltr=o(" (Nystr\xF6mformer model)"),ytr=l(),LF=a("li"),nMe=a("strong"),xtr=o("perceiver"),$tr=o(" \u2014 "),MH=a("a"),ktr=o("PerceiverForMaskedLM"),Str=o(" (Perceiver model)"),Rtr=l(),yF=a("li"),sMe=a("strong"),Ptr=o("qdqbert"),Btr=o(" \u2014 "),EH=a("a"),Itr=o("QDQBertForMaskedLM"),Ntr=o(" (QDQBert model)"),qtr=l(),xF=a("li"),lMe=a("strong"),Dtr=o("reformer"),jtr=o(" \u2014 "),CH=a("a"),Gtr=o("ReformerForMaskedLM"),Otr=o(" (Reformer model)"),Vtr=l(),$F=a("li"),iMe=a("strong"),Xtr=o("rembert"),ztr=o(" \u2014 "),wH=a("a"),Qtr=o("RemBertForMaskedLM"),Wtr=o(" (RemBERT model)"),Utr=l(),kF=a("li"),dMe=a("strong"),Htr=o("roberta"),Jtr=o(" \u2014 "),AH=a("a"),Ytr=o("RobertaForMaskedLM"),Ztr=o(" (RoBERTa model)"),Ktr=l(),SF=a("li"),mMe=a("strong"),ear=o("roformer"),oar=o(" \u2014 "),LH=a("a"),rar=o("RoFormerForMaskedLM"),tar=o(" (RoFormer model)"),aar=l(),RF=a("li"),cMe=a("strong"),nar=o("squeezebert"),sar=o(" \u2014 "),yH=a("a"),lar=o("SqueezeBertForMaskedLM"),iar=o(" (SqueezeBERT model)"),dar=l(),PF=a("li"),fMe=a("strong"),mar=o("tapas"),car=o(" \u2014 "),xH=a("a"),far=o("TapasForMaskedLM"),gar=o(" (TAPAS model)"),har=l(),BF=a("li"),gMe=a("strong"),uar=o("wav2vec2"),par=o(" \u2014 "),hMe=a("code"),_ar=o("Wav2Vec2ForMaskedLM"),bar=o(" (Wav2Vec2 model)"),Far=l(),IF=a("li"),uMe=a("strong"),Tar=o("xlm"),Mar=o(" \u2014 "),$H=a("a"),Ear=o("XLMWithLMHeadModel"),Car=o(" (XLM model)"),war=l(),NF=a("li"),pMe=a("strong"),Aar=o("xlm-roberta"),Lar=o(" \u2014 "),kH=a("a"),yar=o("XLMRobertaForMaskedLM"),xar=o(" (XLM-RoBERTa model)"),$ar=l(),qF=a("li"),_Me=a("strong"),kar=o("xlm-roberta-xl"),Sar=o(" \u2014 "),SH=a("a"),Rar=o("XLMRobertaXLForMaskedLM"),Par=o(" (XLM-RoBERTa-XL model)"),Bar=l(),DF=a("li"),bMe=a("strong"),Iar=o("yoso"),Nar=o(" \u2014 "),RH=a("a"),qar=o("YosoForMaskedLM"),Dar=o(" (YOSO model)"),jar=l(),jF=a("p"),Gar=o("The model is set in evaluation mode by default using "),vMe=a("code"),Oar=o("model.eval()"),Var=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),FMe=a("code"),Xar=o("model.train()"),zar=l(),F(GF.$$.fragment),Zto=l(),Wd=a("h2"),OF=a("a"),TMe=a("span"),F(ik.$$.fragment),Qar=l(),MMe=a("span"),War=o("AutoModelForSeq2SeqLM"),Kto=l(),Go=a("div"),F(dk.$$.fragment),Uar=l(),Ud=a("p"),Har=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),PH=a("a"),Jar=o("from_pretrained()"),Yar=o(" class method or the "),BH=a("a"),Zar=o("from_config()"),Kar=o(` class
method.`),enr=l(),mk=a("p"),onr=o("This class cannot be instantiated directly using "),EMe=a("code"),rnr=o("__init__()"),tnr=o(" (throws an error)."),anr=l(),Lt=a("div"),F(ck.$$.fragment),nnr=l(),CMe=a("p"),snr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),lnr=l(),Hd=a("p"),inr=o(`Note:
Loading a model from its configuration file does `),wMe=a("strong"),dnr=o("not"),mnr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IH=a("a"),cnr=o("from_pretrained()"),fnr=o(" to load the model weights."),gnr=l(),F(VF.$$.fragment),hnr=l(),ao=a("div"),F(fk.$$.fragment),unr=l(),AMe=a("p"),pnr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),_nr=l(),cn=a("p"),bnr=o("The model class to instantiate is selected based on the "),LMe=a("code"),vnr=o("model_type"),Fnr=o(` property of the config object (either
passed as an argument or loaded from `),yMe=a("code"),Tnr=o("pretrained_model_name_or_path"),Mnr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xMe=a("code"),Enr=o("pretrained_model_name_or_path"),Cnr=o(":"),wnr=l(),he=a("ul"),XF=a("li"),$Me=a("strong"),Anr=o("bart"),Lnr=o(" \u2014 "),NH=a("a"),ynr=o("BartForConditionalGeneration"),xnr=o(" (BART model)"),$nr=l(),zF=a("li"),kMe=a("strong"),knr=o("bigbird_pegasus"),Snr=o(" \u2014 "),qH=a("a"),Rnr=o("BigBirdPegasusForConditionalGeneration"),Pnr=o(" (BigBird-Pegasus model)"),Bnr=l(),QF=a("li"),SMe=a("strong"),Inr=o("blenderbot"),Nnr=o(" \u2014 "),DH=a("a"),qnr=o("BlenderbotForConditionalGeneration"),Dnr=o(" (Blenderbot model)"),jnr=l(),WF=a("li"),RMe=a("strong"),Gnr=o("blenderbot-small"),Onr=o(" \u2014 "),jH=a("a"),Vnr=o("BlenderbotSmallForConditionalGeneration"),Xnr=o(" (BlenderbotSmall model)"),znr=l(),UF=a("li"),PMe=a("strong"),Qnr=o("encoder-decoder"),Wnr=o(" \u2014 "),GH=a("a"),Unr=o("EncoderDecoderModel"),Hnr=o(" (Encoder decoder model)"),Jnr=l(),HF=a("li"),BMe=a("strong"),Ynr=o("fsmt"),Znr=o(" \u2014 "),OH=a("a"),Knr=o("FSMTForConditionalGeneration"),esr=o(" (FairSeq Machine-Translation model)"),osr=l(),JF=a("li"),IMe=a("strong"),rsr=o("led"),tsr=o(" \u2014 "),VH=a("a"),asr=o("LEDForConditionalGeneration"),nsr=o(" (LED model)"),ssr=l(),YF=a("li"),NMe=a("strong"),lsr=o("longt5"),isr=o(" \u2014 "),XH=a("a"),dsr=o("LongT5ForConditionalGeneration"),msr=o(" (LongT5 model)"),csr=l(),ZF=a("li"),qMe=a("strong"),fsr=o("m2m_100"),gsr=o(" \u2014 "),zH=a("a"),hsr=o("M2M100ForConditionalGeneration"),usr=o(" (M2M100 model)"),psr=l(),KF=a("li"),DMe=a("strong"),_sr=o("marian"),bsr=o(" \u2014 "),QH=a("a"),vsr=o("MarianMTModel"),Fsr=o(" (Marian model)"),Tsr=l(),eT=a("li"),jMe=a("strong"),Msr=o("mbart"),Esr=o(" \u2014 "),WH=a("a"),Csr=o("MBartForConditionalGeneration"),wsr=o(" (mBART model)"),Asr=l(),oT=a("li"),GMe=a("strong"),Lsr=o("mt5"),ysr=o(" \u2014 "),UH=a("a"),xsr=o("MT5ForConditionalGeneration"),$sr=o(" (MT5 model)"),ksr=l(),rT=a("li"),OMe=a("strong"),Ssr=o("mvp"),Rsr=o(" \u2014 "),HH=a("a"),Psr=o("MvpForConditionalGeneration"),Bsr=o(" (MVP model)"),Isr=l(),tT=a("li"),VMe=a("strong"),Nsr=o("nllb"),qsr=o(" \u2014 "),JH=a("a"),Dsr=o("M2M100ForConditionalGeneration"),jsr=o(" (NLLB model)"),Gsr=l(),aT=a("li"),XMe=a("strong"),Osr=o("pegasus"),Vsr=o(" \u2014 "),YH=a("a"),Xsr=o("PegasusForConditionalGeneration"),zsr=o(" (Pegasus model)"),Qsr=l(),nT=a("li"),zMe=a("strong"),Wsr=o("pegasus_x"),Usr=o(" \u2014 "),ZH=a("a"),Hsr=o("PegasusXForConditionalGeneration"),Jsr=o(" (PEGASUS-X model)"),Ysr=l(),sT=a("li"),QMe=a("strong"),Zsr=o("plbart"),Ksr=o(" \u2014 "),KH=a("a"),elr=o("PLBartForConditionalGeneration"),olr=o(" (PLBart model)"),rlr=l(),lT=a("li"),WMe=a("strong"),tlr=o("prophetnet"),alr=o(" \u2014 "),eJ=a("a"),nlr=o("ProphetNetForConditionalGeneration"),slr=o(" (ProphetNet model)"),llr=l(),iT=a("li"),UMe=a("strong"),ilr=o("t5"),dlr=o(" \u2014 "),oJ=a("a"),mlr=o("T5ForConditionalGeneration"),clr=o(" (T5 model)"),flr=l(),dT=a("li"),HMe=a("strong"),glr=o("xlm-prophetnet"),hlr=o(" \u2014 "),rJ=a("a"),ulr=o("XLMProphetNetForConditionalGeneration"),plr=o(" (XLM-ProphetNet model)"),_lr=l(),mT=a("p"),blr=o("The model is set in evaluation mode by default using "),JMe=a("code"),vlr=o("model.eval()"),Flr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),YMe=a("code"),Tlr=o("model.train()"),Mlr=l(),F(cT.$$.fragment),eao=l(),Jd=a("h2"),fT=a("a"),ZMe=a("span"),F(gk.$$.fragment),Elr=l(),KMe=a("span"),Clr=o("AutoModelForSequenceClassification"),oao=l(),Oo=a("div"),F(hk.$$.fragment),wlr=l(),Yd=a("p"),Alr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),tJ=a("a"),Llr=o("from_pretrained()"),ylr=o(" class method or the "),aJ=a("a"),xlr=o("from_config()"),$lr=o(` class
method.`),klr=l(),uk=a("p"),Slr=o("This class cannot be instantiated directly using "),eEe=a("code"),Rlr=o("__init__()"),Plr=o(" (throws an error)."),Blr=l(),yt=a("div"),F(pk.$$.fragment),Ilr=l(),oEe=a("p"),Nlr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),qlr=l(),Zd=a("p"),Dlr=o(`Note:
Loading a model from its configuration file does `),rEe=a("strong"),jlr=o("not"),Glr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nJ=a("a"),Olr=o("from_pretrained()"),Vlr=o(" to load the model weights."),Xlr=l(),F(gT.$$.fragment),zlr=l(),no=a("div"),F(_k.$$.fragment),Qlr=l(),tEe=a("p"),Wlr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Ulr=l(),fn=a("p"),Hlr=o("The model class to instantiate is selected based on the "),aEe=a("code"),Jlr=o("model_type"),Ylr=o(` property of the config object (either
passed as an argument or loaded from `),nEe=a("code"),Zlr=o("pretrained_model_name_or_path"),Klr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sEe=a("code"),eir=o("pretrained_model_name_or_path"),oir=o(":"),rir=l(),D=a("ul"),hT=a("li"),lEe=a("strong"),tir=o("albert"),air=o(" \u2014 "),sJ=a("a"),nir=o("AlbertForSequenceClassification"),sir=o(" (ALBERT model)"),lir=l(),uT=a("li"),iEe=a("strong"),iir=o("bart"),dir=o(" \u2014 "),lJ=a("a"),mir=o("BartForSequenceClassification"),cir=o(" (BART model)"),fir=l(),pT=a("li"),dEe=a("strong"),gir=o("bert"),hir=o(" \u2014 "),iJ=a("a"),uir=o("BertForSequenceClassification"),pir=o(" (BERT model)"),_ir=l(),_T=a("li"),mEe=a("strong"),bir=o("big_bird"),vir=o(" \u2014 "),dJ=a("a"),Fir=o("BigBirdForSequenceClassification"),Tir=o(" (BigBird model)"),Mir=l(),bT=a("li"),cEe=a("strong"),Eir=o("bigbird_pegasus"),Cir=o(" \u2014 "),mJ=a("a"),wir=o("BigBirdPegasusForSequenceClassification"),Air=o(" (BigBird-Pegasus model)"),Lir=l(),vT=a("li"),fEe=a("strong"),yir=o("bloom"),xir=o(" \u2014 "),cJ=a("a"),$ir=o("BloomForSequenceClassification"),kir=o(" (BLOOM model)"),Sir=l(),FT=a("li"),gEe=a("strong"),Rir=o("camembert"),Pir=o(" \u2014 "),fJ=a("a"),Bir=o("CamembertForSequenceClassification"),Iir=o(" (CamemBERT model)"),Nir=l(),TT=a("li"),hEe=a("strong"),qir=o("canine"),Dir=o(" \u2014 "),gJ=a("a"),jir=o("CanineForSequenceClassification"),Gir=o(" (CANINE model)"),Oir=l(),MT=a("li"),uEe=a("strong"),Vir=o("convbert"),Xir=o(" \u2014 "),hJ=a("a"),zir=o("ConvBertForSequenceClassification"),Qir=o(" (ConvBERT model)"),Wir=l(),ET=a("li"),pEe=a("strong"),Uir=o("ctrl"),Hir=o(" \u2014 "),uJ=a("a"),Jir=o("CTRLForSequenceClassification"),Yir=o(" (CTRL model)"),Zir=l(),CT=a("li"),_Ee=a("strong"),Kir=o("data2vec-text"),edr=o(" \u2014 "),pJ=a("a"),odr=o("Data2VecTextForSequenceClassification"),rdr=o(" (Data2VecText model)"),tdr=l(),wT=a("li"),bEe=a("strong"),adr=o("deberta"),ndr=o(" \u2014 "),_J=a("a"),sdr=o("DebertaForSequenceClassification"),ldr=o(" (DeBERTa model)"),idr=l(),AT=a("li"),vEe=a("strong"),ddr=o("deberta-v2"),mdr=o(" \u2014 "),bJ=a("a"),cdr=o("DebertaV2ForSequenceClassification"),fdr=o(" (DeBERTa-v2 model)"),gdr=l(),LT=a("li"),FEe=a("strong"),hdr=o("distilbert"),udr=o(" \u2014 "),vJ=a("a"),pdr=o("DistilBertForSequenceClassification"),_dr=o(" (DistilBERT model)"),bdr=l(),yT=a("li"),TEe=a("strong"),vdr=o("electra"),Fdr=o(" \u2014 "),FJ=a("a"),Tdr=o("ElectraForSequenceClassification"),Mdr=o(" (ELECTRA model)"),Edr=l(),xT=a("li"),MEe=a("strong"),Cdr=o("ernie"),wdr=o(" \u2014 "),TJ=a("a"),Adr=o("ErnieForSequenceClassification"),Ldr=o(" (ERNIE model)"),ydr=l(),$T=a("li"),EEe=a("strong"),xdr=o("esm"),$dr=o(" \u2014 "),MJ=a("a"),kdr=o("EsmForSequenceClassification"),Sdr=o(" (ESM model)"),Rdr=l(),kT=a("li"),CEe=a("strong"),Pdr=o("flaubert"),Bdr=o(" \u2014 "),EJ=a("a"),Idr=o("FlaubertForSequenceClassification"),Ndr=o(" (FlauBERT model)"),qdr=l(),ST=a("li"),wEe=a("strong"),Ddr=o("fnet"),jdr=o(" \u2014 "),CJ=a("a"),Gdr=o("FNetForSequenceClassification"),Odr=o(" (FNet model)"),Vdr=l(),RT=a("li"),AEe=a("strong"),Xdr=o("funnel"),zdr=o(" \u2014 "),wJ=a("a"),Qdr=o("FunnelForSequenceClassification"),Wdr=o(" (Funnel Transformer model)"),Udr=l(),PT=a("li"),LEe=a("strong"),Hdr=o("gpt2"),Jdr=o(" \u2014 "),AJ=a("a"),Ydr=o("GPT2ForSequenceClassification"),Zdr=o(" (OpenAI GPT-2 model)"),Kdr=l(),BT=a("li"),yEe=a("strong"),emr=o("gpt_neo"),omr=o(" \u2014 "),LJ=a("a"),rmr=o("GPTNeoForSequenceClassification"),tmr=o(" (GPT Neo model)"),amr=l(),IT=a("li"),xEe=a("strong"),nmr=o("gptj"),smr=o(" \u2014 "),yJ=a("a"),lmr=o("GPTJForSequenceClassification"),imr=o(" (GPT-J model)"),dmr=l(),NT=a("li"),$Ee=a("strong"),mmr=o("ibert"),cmr=o(" \u2014 "),xJ=a("a"),fmr=o("IBertForSequenceClassification"),gmr=o(" (I-BERT model)"),hmr=l(),qT=a("li"),kEe=a("strong"),umr=o("layoutlm"),pmr=o(" \u2014 "),$J=a("a"),_mr=o("LayoutLMForSequenceClassification"),bmr=o(" (LayoutLM model)"),vmr=l(),DT=a("li"),SEe=a("strong"),Fmr=o("layoutlmv2"),Tmr=o(" \u2014 "),kJ=a("a"),Mmr=o("LayoutLMv2ForSequenceClassification"),Emr=o(" (LayoutLMv2 model)"),Cmr=l(),jT=a("li"),REe=a("strong"),wmr=o("layoutlmv3"),Amr=o(" \u2014 "),SJ=a("a"),Lmr=o("LayoutLMv3ForSequenceClassification"),ymr=o(" (LayoutLMv3 model)"),xmr=l(),GT=a("li"),PEe=a("strong"),$mr=o("led"),kmr=o(" \u2014 "),RJ=a("a"),Smr=o("LEDForSequenceClassification"),Rmr=o(" (LED model)"),Pmr=l(),OT=a("li"),BEe=a("strong"),Bmr=o("lilt"),Imr=o(" \u2014 "),PJ=a("a"),Nmr=o("LiltForSequenceClassification"),qmr=o(" (LiLT model)"),Dmr=l(),VT=a("li"),IEe=a("strong"),jmr=o("longformer"),Gmr=o(" \u2014 "),BJ=a("a"),Omr=o("LongformerForSequenceClassification"),Vmr=o(" (Longformer model)"),Xmr=l(),XT=a("li"),NEe=a("strong"),zmr=o("luke"),Qmr=o(" \u2014 "),IJ=a("a"),Wmr=o("LukeForSequenceClassification"),Umr=o(" (LUKE model)"),Hmr=l(),zT=a("li"),qEe=a("strong"),Jmr=o("markuplm"),Ymr=o(" \u2014 "),NJ=a("a"),Zmr=o("MarkupLMForSequenceClassification"),Kmr=o(" (MarkupLM model)"),ecr=l(),QT=a("li"),DEe=a("strong"),ocr=o("mbart"),rcr=o(" \u2014 "),qJ=a("a"),tcr=o("MBartForSequenceClassification"),acr=o(" (mBART model)"),ncr=l(),WT=a("li"),jEe=a("strong"),scr=o("megatron-bert"),lcr=o(" \u2014 "),DJ=a("a"),icr=o("MegatronBertForSequenceClassification"),dcr=o(" (Megatron-BERT model)"),mcr=l(),UT=a("li"),GEe=a("strong"),ccr=o("mobilebert"),fcr=o(" \u2014 "),jJ=a("a"),gcr=o("MobileBertForSequenceClassification"),hcr=o(" (MobileBERT model)"),ucr=l(),HT=a("li"),OEe=a("strong"),pcr=o("mpnet"),_cr=o(" \u2014 "),GJ=a("a"),bcr=o("MPNetForSequenceClassification"),vcr=o(" (MPNet model)"),Fcr=l(),JT=a("li"),VEe=a("strong"),Tcr=o("mvp"),Mcr=o(" \u2014 "),OJ=a("a"),Ecr=o("MvpForSequenceClassification"),Ccr=o(" (MVP model)"),wcr=l(),YT=a("li"),XEe=a("strong"),Acr=o("nezha"),Lcr=o(" \u2014 "),VJ=a("a"),ycr=o("NezhaForSequenceClassification"),xcr=o(" (Nezha model)"),$cr=l(),ZT=a("li"),zEe=a("strong"),kcr=o("nystromformer"),Scr=o(" \u2014 "),XJ=a("a"),Rcr=o("NystromformerForSequenceClassification"),Pcr=o(" (Nystr\xF6mformer model)"),Bcr=l(),KT=a("li"),QEe=a("strong"),Icr=o("openai-gpt"),Ncr=o(" \u2014 "),zJ=a("a"),qcr=o("OpenAIGPTForSequenceClassification"),Dcr=o(" (OpenAI GPT model)"),jcr=l(),eM=a("li"),WEe=a("strong"),Gcr=o("opt"),Ocr=o(" \u2014 "),QJ=a("a"),Vcr=o("OPTForSequenceClassification"),Xcr=o(" (OPT model)"),zcr=l(),oM=a("li"),UEe=a("strong"),Qcr=o("perceiver"),Wcr=o(" \u2014 "),WJ=a("a"),Ucr=o("PerceiverForSequenceClassification"),Hcr=o(" (Perceiver model)"),Jcr=l(),rM=a("li"),HEe=a("strong"),Ycr=o("plbart"),Zcr=o(" \u2014 "),UJ=a("a"),Kcr=o("PLBartForSequenceClassification"),efr=o(" (PLBart model)"),ofr=l(),tM=a("li"),JEe=a("strong"),rfr=o("qdqbert"),tfr=o(" \u2014 "),HJ=a("a"),afr=o("QDQBertForSequenceClassification"),nfr=o(" (QDQBert model)"),sfr=l(),aM=a("li"),YEe=a("strong"),lfr=o("reformer"),ifr=o(" \u2014 "),JJ=a("a"),dfr=o("ReformerForSequenceClassification"),mfr=o(" (Reformer model)"),cfr=l(),nM=a("li"),ZEe=a("strong"),ffr=o("rembert"),gfr=o(" \u2014 "),YJ=a("a"),hfr=o("RemBertForSequenceClassification"),ufr=o(" (RemBERT model)"),pfr=l(),sM=a("li"),KEe=a("strong"),_fr=o("roberta"),bfr=o(" \u2014 "),ZJ=a("a"),vfr=o("RobertaForSequenceClassification"),Ffr=o(" (RoBERTa model)"),Tfr=l(),lM=a("li"),e4e=a("strong"),Mfr=o("roformer"),Efr=o(" \u2014 "),KJ=a("a"),Cfr=o("RoFormerForSequenceClassification"),wfr=o(" (RoFormer model)"),Afr=l(),iM=a("li"),o4e=a("strong"),Lfr=o("squeezebert"),yfr=o(" \u2014 "),eY=a("a"),xfr=o("SqueezeBertForSequenceClassification"),$fr=o(" (SqueezeBERT model)"),kfr=l(),dM=a("li"),r4e=a("strong"),Sfr=o("tapas"),Rfr=o(" \u2014 "),oY=a("a"),Pfr=o("TapasForSequenceClassification"),Bfr=o(" (TAPAS model)"),Ifr=l(),mM=a("li"),t4e=a("strong"),Nfr=o("transfo-xl"),qfr=o(" \u2014 "),rY=a("a"),Dfr=o("TransfoXLForSequenceClassification"),jfr=o(" (Transformer-XL model)"),Gfr=l(),cM=a("li"),a4e=a("strong"),Ofr=o("xlm"),Vfr=o(" \u2014 "),tY=a("a"),Xfr=o("XLMForSequenceClassification"),zfr=o(" (XLM model)"),Qfr=l(),fM=a("li"),n4e=a("strong"),Wfr=o("xlm-roberta"),Ufr=o(" \u2014 "),aY=a("a"),Hfr=o("XLMRobertaForSequenceClassification"),Jfr=o(" (XLM-RoBERTa model)"),Yfr=l(),gM=a("li"),s4e=a("strong"),Zfr=o("xlm-roberta-xl"),Kfr=o(" \u2014 "),nY=a("a"),egr=o("XLMRobertaXLForSequenceClassification"),ogr=o(" (XLM-RoBERTa-XL model)"),rgr=l(),hM=a("li"),l4e=a("strong"),tgr=o("xlnet"),agr=o(" \u2014 "),sY=a("a"),ngr=o("XLNetForSequenceClassification"),sgr=o(" (XLNet model)"),lgr=l(),uM=a("li"),i4e=a("strong"),igr=o("yoso"),dgr=o(" \u2014 "),lY=a("a"),mgr=o("YosoForSequenceClassification"),cgr=o(" (YOSO model)"),fgr=l(),pM=a("p"),ggr=o("The model is set in evaluation mode by default using "),d4e=a("code"),hgr=o("model.eval()"),ugr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),m4e=a("code"),pgr=o("model.train()"),_gr=l(),F(_M.$$.fragment),rao=l(),Kd=a("h2"),bM=a("a"),c4e=a("span"),F(bk.$$.fragment),bgr=l(),f4e=a("span"),vgr=o("AutoModelForMultipleChoice"),tao=l(),Vo=a("div"),F(vk.$$.fragment),Fgr=l(),em=a("p"),Tgr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),iY=a("a"),Mgr=o("from_pretrained()"),Egr=o(" class method or the "),dY=a("a"),Cgr=o("from_config()"),wgr=o(` class
method.`),Agr=l(),Fk=a("p"),Lgr=o("This class cannot be instantiated directly using "),g4e=a("code"),ygr=o("__init__()"),xgr=o(" (throws an error)."),$gr=l(),xt=a("div"),F(Tk.$$.fragment),kgr=l(),h4e=a("p"),Sgr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Rgr=l(),om=a("p"),Pgr=o(`Note:
Loading a model from its configuration file does `),u4e=a("strong"),Bgr=o("not"),Igr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mY=a("a"),Ngr=o("from_pretrained()"),qgr=o(" to load the model weights."),Dgr=l(),F(vM.$$.fragment),jgr=l(),so=a("div"),F(Mk.$$.fragment),Ggr=l(),p4e=a("p"),Ogr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Vgr=l(),gn=a("p"),Xgr=o("The model class to instantiate is selected based on the "),_4e=a("code"),zgr=o("model_type"),Qgr=o(` property of the config object (either
passed as an argument or loaded from `),b4e=a("code"),Wgr=o("pretrained_model_name_or_path"),Ugr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v4e=a("code"),Hgr=o("pretrained_model_name_or_path"),Jgr=o(":"),Ygr=l(),K=a("ul"),FM=a("li"),F4e=a("strong"),Zgr=o("albert"),Kgr=o(" \u2014 "),cY=a("a"),ehr=o("AlbertForMultipleChoice"),ohr=o(" (ALBERT model)"),rhr=l(),TM=a("li"),T4e=a("strong"),thr=o("bert"),ahr=o(" \u2014 "),fY=a("a"),nhr=o("BertForMultipleChoice"),shr=o(" (BERT model)"),lhr=l(),MM=a("li"),M4e=a("strong"),ihr=o("big_bird"),dhr=o(" \u2014 "),gY=a("a"),mhr=o("BigBirdForMultipleChoice"),chr=o(" (BigBird model)"),fhr=l(),EM=a("li"),E4e=a("strong"),ghr=o("camembert"),hhr=o(" \u2014 "),hY=a("a"),uhr=o("CamembertForMultipleChoice"),phr=o(" (CamemBERT model)"),_hr=l(),CM=a("li"),C4e=a("strong"),bhr=o("canine"),vhr=o(" \u2014 "),uY=a("a"),Fhr=o("CanineForMultipleChoice"),Thr=o(" (CANINE model)"),Mhr=l(),wM=a("li"),w4e=a("strong"),Ehr=o("convbert"),Chr=o(" \u2014 "),pY=a("a"),whr=o("ConvBertForMultipleChoice"),Ahr=o(" (ConvBERT model)"),Lhr=l(),AM=a("li"),A4e=a("strong"),yhr=o("data2vec-text"),xhr=o(" \u2014 "),_Y=a("a"),$hr=o("Data2VecTextForMultipleChoice"),khr=o(" (Data2VecText model)"),Shr=l(),LM=a("li"),L4e=a("strong"),Rhr=o("deberta-v2"),Phr=o(" \u2014 "),bY=a("a"),Bhr=o("DebertaV2ForMultipleChoice"),Ihr=o(" (DeBERTa-v2 model)"),Nhr=l(),yM=a("li"),y4e=a("strong"),qhr=o("distilbert"),Dhr=o(" \u2014 "),vY=a("a"),jhr=o("DistilBertForMultipleChoice"),Ghr=o(" (DistilBERT model)"),Ohr=l(),xM=a("li"),x4e=a("strong"),Vhr=o("electra"),Xhr=o(" \u2014 "),FY=a("a"),zhr=o("ElectraForMultipleChoice"),Qhr=o(" (ELECTRA model)"),Whr=l(),$M=a("li"),$4e=a("strong"),Uhr=o("ernie"),Hhr=o(" \u2014 "),TY=a("a"),Jhr=o("ErnieForMultipleChoice"),Yhr=o(" (ERNIE model)"),Zhr=l(),kM=a("li"),k4e=a("strong"),Khr=o("flaubert"),eur=o(" \u2014 "),MY=a("a"),our=o("FlaubertForMultipleChoice"),rur=o(" (FlauBERT model)"),tur=l(),SM=a("li"),S4e=a("strong"),aur=o("fnet"),nur=o(" \u2014 "),EY=a("a"),sur=o("FNetForMultipleChoice"),lur=o(" (FNet model)"),iur=l(),RM=a("li"),R4e=a("strong"),dur=o("funnel"),mur=o(" \u2014 "),CY=a("a"),cur=o("FunnelForMultipleChoice"),fur=o(" (Funnel Transformer model)"),gur=l(),PM=a("li"),P4e=a("strong"),hur=o("ibert"),uur=o(" \u2014 "),wY=a("a"),pur=o("IBertForMultipleChoice"),_ur=o(" (I-BERT model)"),bur=l(),BM=a("li"),B4e=a("strong"),vur=o("longformer"),Fur=o(" \u2014 "),AY=a("a"),Tur=o("LongformerForMultipleChoice"),Mur=o(" (Longformer model)"),Eur=l(),IM=a("li"),I4e=a("strong"),Cur=o("luke"),wur=o(" \u2014 "),LY=a("a"),Aur=o("LukeForMultipleChoice"),Lur=o(" (LUKE model)"),yur=l(),NM=a("li"),N4e=a("strong"),xur=o("megatron-bert"),$ur=o(" \u2014 "),yY=a("a"),kur=o("MegatronBertForMultipleChoice"),Sur=o(" (Megatron-BERT model)"),Rur=l(),qM=a("li"),q4e=a("strong"),Pur=o("mobilebert"),Bur=o(" \u2014 "),xY=a("a"),Iur=o("MobileBertForMultipleChoice"),Nur=o(" (MobileBERT model)"),qur=l(),DM=a("li"),D4e=a("strong"),Dur=o("mpnet"),jur=o(" \u2014 "),$Y=a("a"),Gur=o("MPNetForMultipleChoice"),Our=o(" (MPNet model)"),Vur=l(),jM=a("li"),j4e=a("strong"),Xur=o("nezha"),zur=o(" \u2014 "),kY=a("a"),Qur=o("NezhaForMultipleChoice"),Wur=o(" (Nezha model)"),Uur=l(),GM=a("li"),G4e=a("strong"),Hur=o("nystromformer"),Jur=o(" \u2014 "),SY=a("a"),Yur=o("NystromformerForMultipleChoice"),Zur=o(" (Nystr\xF6mformer model)"),Kur=l(),OM=a("li"),O4e=a("strong"),epr=o("qdqbert"),opr=o(" \u2014 "),RY=a("a"),rpr=o("QDQBertForMultipleChoice"),tpr=o(" (QDQBert model)"),apr=l(),VM=a("li"),V4e=a("strong"),npr=o("rembert"),spr=o(" \u2014 "),PY=a("a"),lpr=o("RemBertForMultipleChoice"),ipr=o(" (RemBERT model)"),dpr=l(),XM=a("li"),X4e=a("strong"),mpr=o("roberta"),cpr=o(" \u2014 "),BY=a("a"),fpr=o("RobertaForMultipleChoice"),gpr=o(" (RoBERTa model)"),hpr=l(),zM=a("li"),z4e=a("strong"),upr=o("roformer"),ppr=o(" \u2014 "),IY=a("a"),_pr=o("RoFormerForMultipleChoice"),bpr=o(" (RoFormer model)"),vpr=l(),QM=a("li"),Q4e=a("strong"),Fpr=o("squeezebert"),Tpr=o(" \u2014 "),NY=a("a"),Mpr=o("SqueezeBertForMultipleChoice"),Epr=o(" (SqueezeBERT model)"),Cpr=l(),WM=a("li"),W4e=a("strong"),wpr=o("xlm"),Apr=o(" \u2014 "),qY=a("a"),Lpr=o("XLMForMultipleChoice"),ypr=o(" (XLM model)"),xpr=l(),UM=a("li"),U4e=a("strong"),$pr=o("xlm-roberta"),kpr=o(" \u2014 "),DY=a("a"),Spr=o("XLMRobertaForMultipleChoice"),Rpr=o(" (XLM-RoBERTa model)"),Ppr=l(),HM=a("li"),H4e=a("strong"),Bpr=o("xlm-roberta-xl"),Ipr=o(" \u2014 "),jY=a("a"),Npr=o("XLMRobertaXLForMultipleChoice"),qpr=o(" (XLM-RoBERTa-XL model)"),Dpr=l(),JM=a("li"),J4e=a("strong"),jpr=o("xlnet"),Gpr=o(" \u2014 "),GY=a("a"),Opr=o("XLNetForMultipleChoice"),Vpr=o(" (XLNet model)"),Xpr=l(),YM=a("li"),Y4e=a("strong"),zpr=o("yoso"),Qpr=o(" \u2014 "),OY=a("a"),Wpr=o("YosoForMultipleChoice"),Upr=o(" (YOSO model)"),Hpr=l(),ZM=a("p"),Jpr=o("The model is set in evaluation mode by default using "),Z4e=a("code"),Ypr=o("model.eval()"),Zpr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),K4e=a("code"),Kpr=o("model.train()"),e_r=l(),F(KM.$$.fragment),aao=l(),rm=a("h2"),eE=a("a"),eCe=a("span"),F(Ek.$$.fragment),o_r=l(),oCe=a("span"),r_r=o("AutoModelForNextSentencePrediction"),nao=l(),Xo=a("div"),F(Ck.$$.fragment),t_r=l(),tm=a("p"),a_r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),VY=a("a"),n_r=o("from_pretrained()"),s_r=o(" class method or the "),XY=a("a"),l_r=o("from_config()"),i_r=o(` class
method.`),d_r=l(),wk=a("p"),m_r=o("This class cannot be instantiated directly using "),rCe=a("code"),c_r=o("__init__()"),f_r=o(" (throws an error)."),g_r=l(),$t=a("div"),F(Ak.$$.fragment),h_r=l(),tCe=a("p"),u_r=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),p_r=l(),am=a("p"),__r=o(`Note:
Loading a model from its configuration file does `),aCe=a("strong"),b_r=o("not"),v_r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zY=a("a"),F_r=o("from_pretrained()"),T_r=o(" to load the model weights."),M_r=l(),F(oE.$$.fragment),E_r=l(),lo=a("div"),F(Lk.$$.fragment),C_r=l(),nCe=a("p"),w_r=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),A_r=l(),hn=a("p"),L_r=o("The model class to instantiate is selected based on the "),sCe=a("code"),y_r=o("model_type"),x_r=o(` property of the config object (either
passed as an argument or loaded from `),lCe=a("code"),$_r=o("pretrained_model_name_or_path"),k_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iCe=a("code"),S_r=o("pretrained_model_name_or_path"),R_r=o(":"),P_r=l(),Ue=a("ul"),rE=a("li"),dCe=a("strong"),B_r=o("bert"),I_r=o(" \u2014 "),QY=a("a"),N_r=o("BertForNextSentencePrediction"),q_r=o(" (BERT model)"),D_r=l(),tE=a("li"),mCe=a("strong"),j_r=o("ernie"),G_r=o(" \u2014 "),WY=a("a"),O_r=o("ErnieForNextSentencePrediction"),V_r=o(" (ERNIE model)"),X_r=l(),aE=a("li"),cCe=a("strong"),z_r=o("fnet"),Q_r=o(" \u2014 "),UY=a("a"),W_r=o("FNetForNextSentencePrediction"),U_r=o(" (FNet model)"),H_r=l(),nE=a("li"),fCe=a("strong"),J_r=o("megatron-bert"),Y_r=o(" \u2014 "),HY=a("a"),Z_r=o("MegatronBertForNextSentencePrediction"),K_r=o(" (Megatron-BERT model)"),e1r=l(),sE=a("li"),gCe=a("strong"),o1r=o("mobilebert"),r1r=o(" \u2014 "),JY=a("a"),t1r=o("MobileBertForNextSentencePrediction"),a1r=o(" (MobileBERT model)"),n1r=l(),lE=a("li"),hCe=a("strong"),s1r=o("nezha"),l1r=o(" \u2014 "),YY=a("a"),i1r=o("NezhaForNextSentencePrediction"),d1r=o(" (Nezha model)"),m1r=l(),iE=a("li"),uCe=a("strong"),c1r=o("qdqbert"),f1r=o(" \u2014 "),ZY=a("a"),g1r=o("QDQBertForNextSentencePrediction"),h1r=o(" (QDQBert model)"),u1r=l(),dE=a("p"),p1r=o("The model is set in evaluation mode by default using "),pCe=a("code"),_1r=o("model.eval()"),b1r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_Ce=a("code"),v1r=o("model.train()"),F1r=l(),F(mE.$$.fragment),sao=l(),nm=a("h2"),cE=a("a"),bCe=a("span"),F(yk.$$.fragment),T1r=l(),vCe=a("span"),M1r=o("AutoModelForTokenClassification"),lao=l(),zo=a("div"),F(xk.$$.fragment),E1r=l(),sm=a("p"),C1r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),KY=a("a"),w1r=o("from_pretrained()"),A1r=o(" class method or the "),eZ=a("a"),L1r=o("from_config()"),y1r=o(` class
method.`),x1r=l(),$k=a("p"),$1r=o("This class cannot be instantiated directly using "),FCe=a("code"),k1r=o("__init__()"),S1r=o(" (throws an error)."),R1r=l(),kt=a("div"),F(kk.$$.fragment),P1r=l(),TCe=a("p"),B1r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),I1r=l(),lm=a("p"),N1r=o(`Note:
Loading a model from its configuration file does `),MCe=a("strong"),q1r=o("not"),D1r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oZ=a("a"),j1r=o("from_pretrained()"),G1r=o(" to load the model weights."),O1r=l(),F(fE.$$.fragment),V1r=l(),io=a("div"),F(Sk.$$.fragment),X1r=l(),ECe=a("p"),z1r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Q1r=l(),un=a("p"),W1r=o("The model class to instantiate is selected based on the "),CCe=a("code"),U1r=o("model_type"),H1r=o(` property of the config object (either
passed as an argument or loaded from `),wCe=a("code"),J1r=o("pretrained_model_name_or_path"),Y1r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ACe=a("code"),Z1r=o("pretrained_model_name_or_path"),K1r=o(":"),e2r=l(),U=a("ul"),gE=a("li"),LCe=a("strong"),o2r=o("albert"),r2r=o(" \u2014 "),rZ=a("a"),t2r=o("AlbertForTokenClassification"),a2r=o(" (ALBERT model)"),n2r=l(),hE=a("li"),yCe=a("strong"),s2r=o("bert"),l2r=o(" \u2014 "),tZ=a("a"),i2r=o("BertForTokenClassification"),d2r=o(" (BERT model)"),m2r=l(),uE=a("li"),xCe=a("strong"),c2r=o("big_bird"),f2r=o(" \u2014 "),aZ=a("a"),g2r=o("BigBirdForTokenClassification"),h2r=o(" (BigBird model)"),u2r=l(),pE=a("li"),$Ce=a("strong"),p2r=o("bloom"),_2r=o(" \u2014 "),nZ=a("a"),b2r=o("BloomForTokenClassification"),v2r=o(" (BLOOM model)"),F2r=l(),_E=a("li"),kCe=a("strong"),T2r=o("camembert"),M2r=o(" \u2014 "),sZ=a("a"),E2r=o("CamembertForTokenClassification"),C2r=o(" (CamemBERT model)"),w2r=l(),bE=a("li"),SCe=a("strong"),A2r=o("canine"),L2r=o(" \u2014 "),lZ=a("a"),y2r=o("CanineForTokenClassification"),x2r=o(" (CANINE model)"),$2r=l(),vE=a("li"),RCe=a("strong"),k2r=o("convbert"),S2r=o(" \u2014 "),iZ=a("a"),R2r=o("ConvBertForTokenClassification"),P2r=o(" (ConvBERT model)"),B2r=l(),FE=a("li"),PCe=a("strong"),I2r=o("data2vec-text"),N2r=o(" \u2014 "),dZ=a("a"),q2r=o("Data2VecTextForTokenClassification"),D2r=o(" (Data2VecText model)"),j2r=l(),TE=a("li"),BCe=a("strong"),G2r=o("deberta"),O2r=o(" \u2014 "),mZ=a("a"),V2r=o("DebertaForTokenClassification"),X2r=o(" (DeBERTa model)"),z2r=l(),ME=a("li"),ICe=a("strong"),Q2r=o("deberta-v2"),W2r=o(" \u2014 "),cZ=a("a"),U2r=o("DebertaV2ForTokenClassification"),H2r=o(" (DeBERTa-v2 model)"),J2r=l(),EE=a("li"),NCe=a("strong"),Y2r=o("distilbert"),Z2r=o(" \u2014 "),fZ=a("a"),K2r=o("DistilBertForTokenClassification"),ebr=o(" (DistilBERT model)"),obr=l(),CE=a("li"),qCe=a("strong"),rbr=o("electra"),tbr=o(" \u2014 "),gZ=a("a"),abr=o("ElectraForTokenClassification"),nbr=o(" (ELECTRA model)"),sbr=l(),wE=a("li"),DCe=a("strong"),lbr=o("ernie"),ibr=o(" \u2014 "),hZ=a("a"),dbr=o("ErnieForTokenClassification"),mbr=o(" (ERNIE model)"),cbr=l(),AE=a("li"),jCe=a("strong"),fbr=o("esm"),gbr=o(" \u2014 "),uZ=a("a"),hbr=o("EsmForTokenClassification"),ubr=o(" (ESM model)"),pbr=l(),LE=a("li"),GCe=a("strong"),_br=o("flaubert"),bbr=o(" \u2014 "),pZ=a("a"),vbr=o("FlaubertForTokenClassification"),Fbr=o(" (FlauBERT model)"),Tbr=l(),yE=a("li"),OCe=a("strong"),Mbr=o("fnet"),Ebr=o(" \u2014 "),_Z=a("a"),Cbr=o("FNetForTokenClassification"),wbr=o(" (FNet model)"),Abr=l(),xE=a("li"),VCe=a("strong"),Lbr=o("funnel"),ybr=o(" \u2014 "),bZ=a("a"),xbr=o("FunnelForTokenClassification"),$br=o(" (Funnel Transformer model)"),kbr=l(),$E=a("li"),XCe=a("strong"),Sbr=o("gpt2"),Rbr=o(" \u2014 "),vZ=a("a"),Pbr=o("GPT2ForTokenClassification"),Bbr=o(" (OpenAI GPT-2 model)"),Ibr=l(),kE=a("li"),zCe=a("strong"),Nbr=o("ibert"),qbr=o(" \u2014 "),FZ=a("a"),Dbr=o("IBertForTokenClassification"),jbr=o(" (I-BERT model)"),Gbr=l(),SE=a("li"),QCe=a("strong"),Obr=o("layoutlm"),Vbr=o(" \u2014 "),TZ=a("a"),Xbr=o("LayoutLMForTokenClassification"),zbr=o(" (LayoutLM model)"),Qbr=l(),RE=a("li"),WCe=a("strong"),Wbr=o("layoutlmv2"),Ubr=o(" \u2014 "),MZ=a("a"),Hbr=o("LayoutLMv2ForTokenClassification"),Jbr=o(" (LayoutLMv2 model)"),Ybr=l(),PE=a("li"),UCe=a("strong"),Zbr=o("layoutlmv3"),Kbr=o(" \u2014 "),EZ=a("a"),evr=o("LayoutLMv3ForTokenClassification"),ovr=o(" (LayoutLMv3 model)"),rvr=l(),BE=a("li"),HCe=a("strong"),tvr=o("lilt"),avr=o(" \u2014 "),CZ=a("a"),nvr=o("LiltForTokenClassification"),svr=o(" (LiLT model)"),lvr=l(),IE=a("li"),JCe=a("strong"),ivr=o("longformer"),dvr=o(" \u2014 "),wZ=a("a"),mvr=o("LongformerForTokenClassification"),cvr=o(" (Longformer model)"),fvr=l(),NE=a("li"),YCe=a("strong"),gvr=o("luke"),hvr=o(" \u2014 "),AZ=a("a"),uvr=o("LukeForTokenClassification"),pvr=o(" (LUKE model)"),_vr=l(),qE=a("li"),ZCe=a("strong"),bvr=o("markuplm"),vvr=o(" \u2014 "),LZ=a("a"),Fvr=o("MarkupLMForTokenClassification"),Tvr=o(" (MarkupLM model)"),Mvr=l(),DE=a("li"),KCe=a("strong"),Evr=o("megatron-bert"),Cvr=o(" \u2014 "),yZ=a("a"),wvr=o("MegatronBertForTokenClassification"),Avr=o(" (Megatron-BERT model)"),Lvr=l(),jE=a("li"),e3e=a("strong"),yvr=o("mobilebert"),xvr=o(" \u2014 "),xZ=a("a"),$vr=o("MobileBertForTokenClassification"),kvr=o(" (MobileBERT model)"),Svr=l(),GE=a("li"),o3e=a("strong"),Rvr=o("mpnet"),Pvr=o(" \u2014 "),$Z=a("a"),Bvr=o("MPNetForTokenClassification"),Ivr=o(" (MPNet model)"),Nvr=l(),OE=a("li"),r3e=a("strong"),qvr=o("nezha"),Dvr=o(" \u2014 "),kZ=a("a"),jvr=o("NezhaForTokenClassification"),Gvr=o(" (Nezha model)"),Ovr=l(),VE=a("li"),t3e=a("strong"),Vvr=o("nystromformer"),Xvr=o(" \u2014 "),SZ=a("a"),zvr=o("NystromformerForTokenClassification"),Qvr=o(" (Nystr\xF6mformer model)"),Wvr=l(),XE=a("li"),a3e=a("strong"),Uvr=o("qdqbert"),Hvr=o(" \u2014 "),RZ=a("a"),Jvr=o("QDQBertForTokenClassification"),Yvr=o(" (QDQBert model)"),Zvr=l(),zE=a("li"),n3e=a("strong"),Kvr=o("rembert"),eFr=o(" \u2014 "),PZ=a("a"),oFr=o("RemBertForTokenClassification"),rFr=o(" (RemBERT model)"),tFr=l(),QE=a("li"),s3e=a("strong"),aFr=o("roberta"),nFr=o(" \u2014 "),BZ=a("a"),sFr=o("RobertaForTokenClassification"),lFr=o(" (RoBERTa model)"),iFr=l(),WE=a("li"),l3e=a("strong"),dFr=o("roformer"),mFr=o(" \u2014 "),IZ=a("a"),cFr=o("RoFormerForTokenClassification"),fFr=o(" (RoFormer model)"),gFr=l(),UE=a("li"),i3e=a("strong"),hFr=o("squeezebert"),uFr=o(" \u2014 "),NZ=a("a"),pFr=o("SqueezeBertForTokenClassification"),_Fr=o(" (SqueezeBERT model)"),bFr=l(),HE=a("li"),d3e=a("strong"),vFr=o("xlm"),FFr=o(" \u2014 "),qZ=a("a"),TFr=o("XLMForTokenClassification"),MFr=o(" (XLM model)"),EFr=l(),JE=a("li"),m3e=a("strong"),CFr=o("xlm-roberta"),wFr=o(" \u2014 "),DZ=a("a"),AFr=o("XLMRobertaForTokenClassification"),LFr=o(" (XLM-RoBERTa model)"),yFr=l(),YE=a("li"),c3e=a("strong"),xFr=o("xlm-roberta-xl"),$Fr=o(" \u2014 "),jZ=a("a"),kFr=o("XLMRobertaXLForTokenClassification"),SFr=o(" (XLM-RoBERTa-XL model)"),RFr=l(),ZE=a("li"),f3e=a("strong"),PFr=o("xlnet"),BFr=o(" \u2014 "),GZ=a("a"),IFr=o("XLNetForTokenClassification"),NFr=o(" (XLNet model)"),qFr=l(),KE=a("li"),g3e=a("strong"),DFr=o("yoso"),jFr=o(" \u2014 "),OZ=a("a"),GFr=o("YosoForTokenClassification"),OFr=o(" (YOSO model)"),VFr=l(),e4=a("p"),XFr=o("The model is set in evaluation mode by default using "),h3e=a("code"),zFr=o("model.eval()"),QFr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u3e=a("code"),WFr=o("model.train()"),UFr=l(),F(o4.$$.fragment),iao=l(),im=a("h2"),r4=a("a"),p3e=a("span"),F(Rk.$$.fragment),HFr=l(),_3e=a("span"),JFr=o("AutoModelForQuestionAnswering"),dao=l(),Qo=a("div"),F(Pk.$$.fragment),YFr=l(),dm=a("p"),ZFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),VZ=a("a"),KFr=o("from_pretrained()"),eTr=o(" class method or the "),XZ=a("a"),oTr=o("from_config()"),rTr=o(` class
method.`),tTr=l(),Bk=a("p"),aTr=o("This class cannot be instantiated directly using "),b3e=a("code"),nTr=o("__init__()"),sTr=o(" (throws an error)."),lTr=l(),St=a("div"),F(Ik.$$.fragment),iTr=l(),v3e=a("p"),dTr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),mTr=l(),mm=a("p"),cTr=o(`Note:
Loading a model from its configuration file does `),F3e=a("strong"),fTr=o("not"),gTr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zZ=a("a"),hTr=o("from_pretrained()"),uTr=o(" to load the model weights."),pTr=l(),F(t4.$$.fragment),_Tr=l(),mo=a("div"),F(Nk.$$.fragment),bTr=l(),T3e=a("p"),vTr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),FTr=l(),pn=a("p"),TTr=o("The model class to instantiate is selected based on the "),M3e=a("code"),MTr=o("model_type"),ETr=o(` property of the config object (either
passed as an argument or loaded from `),E3e=a("code"),CTr=o("pretrained_model_name_or_path"),wTr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C3e=a("code"),ATr=o("pretrained_model_name_or_path"),LTr=o(":"),yTr=l(),O=a("ul"),a4=a("li"),w3e=a("strong"),xTr=o("albert"),$Tr=o(" \u2014 "),QZ=a("a"),kTr=o("AlbertForQuestionAnswering"),STr=o(" (ALBERT model)"),RTr=l(),n4=a("li"),A3e=a("strong"),PTr=o("bart"),BTr=o(" \u2014 "),WZ=a("a"),ITr=o("BartForQuestionAnswering"),NTr=o(" (BART model)"),qTr=l(),s4=a("li"),L3e=a("strong"),DTr=o("bert"),jTr=o(" \u2014 "),UZ=a("a"),GTr=o("BertForQuestionAnswering"),OTr=o(" (BERT model)"),VTr=l(),l4=a("li"),y3e=a("strong"),XTr=o("big_bird"),zTr=o(" \u2014 "),HZ=a("a"),QTr=o("BigBirdForQuestionAnswering"),WTr=o(" (BigBird model)"),UTr=l(),i4=a("li"),x3e=a("strong"),HTr=o("bigbird_pegasus"),JTr=o(" \u2014 "),JZ=a("a"),YTr=o("BigBirdPegasusForQuestionAnswering"),ZTr=o(" (BigBird-Pegasus model)"),KTr=l(),d4=a("li"),$3e=a("strong"),eMr=o("bloom"),oMr=o(" \u2014 "),YZ=a("a"),rMr=o("BloomForQuestionAnswering"),tMr=o(" (BLOOM model)"),aMr=l(),m4=a("li"),k3e=a("strong"),nMr=o("camembert"),sMr=o(" \u2014 "),ZZ=a("a"),lMr=o("CamembertForQuestionAnswering"),iMr=o(" (CamemBERT model)"),dMr=l(),c4=a("li"),S3e=a("strong"),mMr=o("canine"),cMr=o(" \u2014 "),KZ=a("a"),fMr=o("CanineForQuestionAnswering"),gMr=o(" (CANINE model)"),hMr=l(),f4=a("li"),R3e=a("strong"),uMr=o("convbert"),pMr=o(" \u2014 "),eK=a("a"),_Mr=o("ConvBertForQuestionAnswering"),bMr=o(" (ConvBERT model)"),vMr=l(),g4=a("li"),P3e=a("strong"),FMr=o("data2vec-text"),TMr=o(" \u2014 "),oK=a("a"),MMr=o("Data2VecTextForQuestionAnswering"),EMr=o(" (Data2VecText model)"),CMr=l(),h4=a("li"),B3e=a("strong"),wMr=o("deberta"),AMr=o(" \u2014 "),rK=a("a"),LMr=o("DebertaForQuestionAnswering"),yMr=o(" (DeBERTa model)"),xMr=l(),u4=a("li"),I3e=a("strong"),$Mr=o("deberta-v2"),kMr=o(" \u2014 "),tK=a("a"),SMr=o("DebertaV2ForQuestionAnswering"),RMr=o(" (DeBERTa-v2 model)"),PMr=l(),p4=a("li"),N3e=a("strong"),BMr=o("distilbert"),IMr=o(" \u2014 "),aK=a("a"),NMr=o("DistilBertForQuestionAnswering"),qMr=o(" (DistilBERT model)"),DMr=l(),_4=a("li"),q3e=a("strong"),jMr=o("electra"),GMr=o(" \u2014 "),nK=a("a"),OMr=o("ElectraForQuestionAnswering"),VMr=o(" (ELECTRA model)"),XMr=l(),b4=a("li"),D3e=a("strong"),zMr=o("ernie"),QMr=o(" \u2014 "),sK=a("a"),WMr=o("ErnieForQuestionAnswering"),UMr=o(" (ERNIE model)"),HMr=l(),v4=a("li"),j3e=a("strong"),JMr=o("flaubert"),YMr=o(" \u2014 "),lK=a("a"),ZMr=o("FlaubertForQuestionAnsweringSimple"),KMr=o(" (FlauBERT model)"),eEr=l(),F4=a("li"),G3e=a("strong"),oEr=o("fnet"),rEr=o(" \u2014 "),iK=a("a"),tEr=o("FNetForQuestionAnswering"),aEr=o(" (FNet model)"),nEr=l(),T4=a("li"),O3e=a("strong"),sEr=o("funnel"),lEr=o(" \u2014 "),dK=a("a"),iEr=o("FunnelForQuestionAnswering"),dEr=o(" (Funnel Transformer model)"),mEr=l(),M4=a("li"),V3e=a("strong"),cEr=o("gptj"),fEr=o(" \u2014 "),mK=a("a"),gEr=o("GPTJForQuestionAnswering"),hEr=o(" (GPT-J model)"),uEr=l(),E4=a("li"),X3e=a("strong"),pEr=o("ibert"),_Er=o(" \u2014 "),cK=a("a"),bEr=o("IBertForQuestionAnswering"),vEr=o(" (I-BERT model)"),FEr=l(),C4=a("li"),z3e=a("strong"),TEr=o("layoutlmv2"),MEr=o(" \u2014 "),fK=a("a"),EEr=o("LayoutLMv2ForQuestionAnswering"),CEr=o(" (LayoutLMv2 model)"),wEr=l(),w4=a("li"),Q3e=a("strong"),AEr=o("layoutlmv3"),LEr=o(" \u2014 "),gK=a("a"),yEr=o("LayoutLMv3ForQuestionAnswering"),xEr=o(" (LayoutLMv3 model)"),$Er=l(),A4=a("li"),W3e=a("strong"),kEr=o("led"),SEr=o(" \u2014 "),hK=a("a"),REr=o("LEDForQuestionAnswering"),PEr=o(" (LED model)"),BEr=l(),L4=a("li"),U3e=a("strong"),IEr=o("lilt"),NEr=o(" \u2014 "),uK=a("a"),qEr=o("LiltForQuestionAnswering"),DEr=o(" (LiLT model)"),jEr=l(),y4=a("li"),H3e=a("strong"),GEr=o("longformer"),OEr=o(" \u2014 "),pK=a("a"),VEr=o("LongformerForQuestionAnswering"),XEr=o(" (Longformer model)"),zEr=l(),x4=a("li"),J3e=a("strong"),QEr=o("luke"),WEr=o(" \u2014 "),_K=a("a"),UEr=o("LukeForQuestionAnswering"),HEr=o(" (LUKE model)"),JEr=l(),$4=a("li"),Y3e=a("strong"),YEr=o("lxmert"),ZEr=o(" \u2014 "),bK=a("a"),KEr=o("LxmertForQuestionAnswering"),e4r=o(" (LXMERT model)"),o4r=l(),k4=a("li"),Z3e=a("strong"),r4r=o("markuplm"),t4r=o(" \u2014 "),vK=a("a"),a4r=o("MarkupLMForQuestionAnswering"),n4r=o(" (MarkupLM model)"),s4r=l(),S4=a("li"),K3e=a("strong"),l4r=o("mbart"),i4r=o(" \u2014 "),FK=a("a"),d4r=o("MBartForQuestionAnswering"),m4r=o(" (mBART model)"),c4r=l(),R4=a("li"),e5e=a("strong"),f4r=o("megatron-bert"),g4r=o(" \u2014 "),TK=a("a"),h4r=o("MegatronBertForQuestionAnswering"),u4r=o(" (Megatron-BERT model)"),p4r=l(),P4=a("li"),o5e=a("strong"),_4r=o("mobilebert"),b4r=o(" \u2014 "),MK=a("a"),v4r=o("MobileBertForQuestionAnswering"),F4r=o(" (MobileBERT model)"),T4r=l(),B4=a("li"),r5e=a("strong"),M4r=o("mpnet"),E4r=o(" \u2014 "),EK=a("a"),C4r=o("MPNetForQuestionAnswering"),w4r=o(" (MPNet model)"),A4r=l(),I4=a("li"),t5e=a("strong"),L4r=o("mvp"),y4r=o(" \u2014 "),CK=a("a"),x4r=o("MvpForQuestionAnswering"),$4r=o(" (MVP model)"),k4r=l(),N4=a("li"),a5e=a("strong"),S4r=o("nezha"),R4r=o(" \u2014 "),wK=a("a"),P4r=o("NezhaForQuestionAnswering"),B4r=o(" (Nezha model)"),I4r=l(),q4=a("li"),n5e=a("strong"),N4r=o("nystromformer"),q4r=o(" \u2014 "),AK=a("a"),D4r=o("NystromformerForQuestionAnswering"),j4r=o(" (Nystr\xF6mformer model)"),G4r=l(),D4=a("li"),s5e=a("strong"),O4r=o("opt"),V4r=o(" \u2014 "),LK=a("a"),X4r=o("OPTForQuestionAnswering"),z4r=o(" (OPT model)"),Q4r=l(),j4=a("li"),l5e=a("strong"),W4r=o("qdqbert"),U4r=o(" \u2014 "),yK=a("a"),H4r=o("QDQBertForQuestionAnswering"),J4r=o(" (QDQBert model)"),Y4r=l(),G4=a("li"),i5e=a("strong"),Z4r=o("reformer"),K4r=o(" \u2014 "),xK=a("a"),eCr=o("ReformerForQuestionAnswering"),oCr=o(" (Reformer model)"),rCr=l(),O4=a("li"),d5e=a("strong"),tCr=o("rembert"),aCr=o(" \u2014 "),$K=a("a"),nCr=o("RemBertForQuestionAnswering"),sCr=o(" (RemBERT model)"),lCr=l(),V4=a("li"),m5e=a("strong"),iCr=o("roberta"),dCr=o(" \u2014 "),kK=a("a"),mCr=o("RobertaForQuestionAnswering"),cCr=o(" (RoBERTa model)"),fCr=l(),X4=a("li"),c5e=a("strong"),gCr=o("roformer"),hCr=o(" \u2014 "),SK=a("a"),uCr=o("RoFormerForQuestionAnswering"),pCr=o(" (RoFormer model)"),_Cr=l(),z4=a("li"),f5e=a("strong"),bCr=o("splinter"),vCr=o(" \u2014 "),RK=a("a"),FCr=o("SplinterForQuestionAnswering"),TCr=o(" (Splinter model)"),MCr=l(),Q4=a("li"),g5e=a("strong"),ECr=o("squeezebert"),CCr=o(" \u2014 "),PK=a("a"),wCr=o("SqueezeBertForQuestionAnswering"),ACr=o(" (SqueezeBERT model)"),LCr=l(),W4=a("li"),h5e=a("strong"),yCr=o("xlm"),xCr=o(" \u2014 "),BK=a("a"),$Cr=o("XLMForQuestionAnsweringSimple"),kCr=o(" (XLM model)"),SCr=l(),U4=a("li"),u5e=a("strong"),RCr=o("xlm-roberta"),PCr=o(" \u2014 "),IK=a("a"),BCr=o("XLMRobertaForQuestionAnswering"),ICr=o(" (XLM-RoBERTa model)"),NCr=l(),H4=a("li"),p5e=a("strong"),qCr=o("xlm-roberta-xl"),DCr=o(" \u2014 "),NK=a("a"),jCr=o("XLMRobertaXLForQuestionAnswering"),GCr=o(" (XLM-RoBERTa-XL model)"),OCr=l(),J4=a("li"),_5e=a("strong"),VCr=o("xlnet"),XCr=o(" \u2014 "),qK=a("a"),zCr=o("XLNetForQuestionAnsweringSimple"),QCr=o(" (XLNet model)"),WCr=l(),Y4=a("li"),b5e=a("strong"),UCr=o("yoso"),HCr=o(" \u2014 "),DK=a("a"),JCr=o("YosoForQuestionAnswering"),YCr=o(" (YOSO model)"),ZCr=l(),Z4=a("p"),KCr=o("The model is set in evaluation mode by default using "),v5e=a("code"),e3r=o("model.eval()"),o3r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F5e=a("code"),r3r=o("model.train()"),t3r=l(),F(K4.$$.fragment),mao=l(),cm=a("h2"),eC=a("a"),T5e=a("span"),F(qk.$$.fragment),a3r=l(),M5e=a("span"),n3r=o("AutoModelForTableQuestionAnswering"),cao=l(),Wo=a("div"),F(Dk.$$.fragment),s3r=l(),fm=a("p"),l3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),jK=a("a"),i3r=o("from_pretrained()"),d3r=o(" class method or the "),GK=a("a"),m3r=o("from_config()"),c3r=o(` class
method.`),f3r=l(),jk=a("p"),g3r=o("This class cannot be instantiated directly using "),E5e=a("code"),h3r=o("__init__()"),u3r=o(" (throws an error)."),p3r=l(),Rt=a("div"),F(Gk.$$.fragment),_3r=l(),C5e=a("p"),b3r=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),v3r=l(),gm=a("p"),F3r=o(`Note:
Loading a model from its configuration file does `),w5e=a("strong"),T3r=o("not"),M3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),OK=a("a"),E3r=o("from_pretrained()"),C3r=o(" to load the model weights."),w3r=l(),F(oC.$$.fragment),A3r=l(),co=a("div"),F(Ok.$$.fragment),L3r=l(),A5e=a("p"),y3r=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),x3r=l(),_n=a("p"),$3r=o("The model class to instantiate is selected based on the "),L5e=a("code"),k3r=o("model_type"),S3r=o(` property of the config object (either
passed as an argument or loaded from `),y5e=a("code"),R3r=o("pretrained_model_name_or_path"),P3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x5e=a("code"),B3r=o("pretrained_model_name_or_path"),I3r=o(":"),N3r=l(),$5e=a("ul"),rC=a("li"),k5e=a("strong"),q3r=o("tapas"),D3r=o(" \u2014 "),VK=a("a"),j3r=o("TapasForQuestionAnswering"),G3r=o(" (TAPAS model)"),O3r=l(),tC=a("p"),V3r=o("The model is set in evaluation mode by default using "),S5e=a("code"),X3r=o("model.eval()"),z3r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),R5e=a("code"),Q3r=o("model.train()"),W3r=l(),F(aC.$$.fragment),fao=l(),hm=a("h2"),nC=a("a"),P5e=a("span"),F(Vk.$$.fragment),U3r=l(),B5e=a("span"),H3r=o("AutoModelForDocumentQuestionAnswering"),gao=l(),Uo=a("div"),F(Xk.$$.fragment),J3r=l(),um=a("p"),Y3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),XK=a("a"),Z3r=o("from_pretrained()"),K3r=o(" class method or the "),zK=a("a"),e5r=o("from_config()"),o5r=o(` class
method.`),r5r=l(),zk=a("p"),t5r=o("This class cannot be instantiated directly using "),I5e=a("code"),a5r=o("__init__()"),n5r=o(" (throws an error)."),s5r=l(),Pt=a("div"),F(Qk.$$.fragment),l5r=l(),N5e=a("p"),i5r=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),d5r=l(),pm=a("p"),m5r=o(`Note:
Loading a model from its configuration file does `),q5e=a("strong"),c5r=o("not"),f5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),QK=a("a"),g5r=o("from_pretrained()"),h5r=o(" to load the model weights."),u5r=l(),F(sC.$$.fragment),p5r=l(),fo=a("div"),F(Wk.$$.fragment),_5r=l(),D5e=a("p"),b5r=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),v5r=l(),bn=a("p"),F5r=o("The model class to instantiate is selected based on the "),j5e=a("code"),T5r=o("model_type"),M5r=o(` property of the config object (either
passed as an argument or loaded from `),G5e=a("code"),E5r=o("pretrained_model_name_or_path"),C5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O5e=a("code"),w5r=o("pretrained_model_name_or_path"),A5r=o(":"),L5r=l(),_m=a("ul"),lC=a("li"),V5e=a("strong"),y5r=o("layoutlm"),x5r=o(" \u2014 "),WK=a("a"),$5r=o("LayoutLMForQuestionAnswering"),k5r=o(" (LayoutLM model)"),S5r=l(),iC=a("li"),X5e=a("strong"),R5r=o("layoutlmv2"),P5r=o(" \u2014 "),UK=a("a"),B5r=o("LayoutLMv2ForQuestionAnswering"),I5r=o(" (LayoutLMv2 model)"),N5r=l(),dC=a("li"),z5e=a("strong"),q5r=o("layoutlmv3"),D5r=o(" \u2014 "),HK=a("a"),j5r=o("LayoutLMv3ForQuestionAnswering"),G5r=o(" (LayoutLMv3 model)"),O5r=l(),mC=a("p"),V5r=o("The model is set in evaluation mode by default using "),Q5e=a("code"),X5r=o("model.eval()"),z5r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),W5e=a("code"),Q5r=o("model.train()"),W5r=l(),F(cC.$$.fragment),hao=l(),bm=a("h2"),fC=a("a"),U5e=a("span"),F(Uk.$$.fragment),U5r=l(),H5e=a("span"),H5r=o("AutoModelForImageClassification"),uao=l(),Ho=a("div"),F(Hk.$$.fragment),J5r=l(),vm=a("p"),Y5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),JK=a("a"),Z5r=o("from_pretrained()"),K5r=o(" class method or the "),YK=a("a"),e0r=o("from_config()"),o0r=o(` class
method.`),r0r=l(),Jk=a("p"),t0r=o("This class cannot be instantiated directly using "),J5e=a("code"),a0r=o("__init__()"),n0r=o(" (throws an error)."),s0r=l(),Bt=a("div"),F(Yk.$$.fragment),l0r=l(),Y5e=a("p"),i0r=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),d0r=l(),Fm=a("p"),m0r=o(`Note:
Loading a model from its configuration file does `),Z5e=a("strong"),c0r=o("not"),f0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ZK=a("a"),g0r=o("from_pretrained()"),h0r=o(" to load the model weights."),u0r=l(),F(gC.$$.fragment),p0r=l(),go=a("div"),F(Zk.$$.fragment),_0r=l(),K5e=a("p"),b0r=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),v0r=l(),vn=a("p"),F0r=o("The model class to instantiate is selected based on the "),e0e=a("code"),T0r=o("model_type"),M0r=o(` property of the config object (either
passed as an argument or loaded from `),o0e=a("code"),E0r=o("pretrained_model_name_or_path"),C0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),r0e=a("code"),w0r=o("pretrained_model_name_or_path"),A0r=o(":"),L0r=l(),be=a("ul"),hC=a("li"),t0e=a("strong"),y0r=o("beit"),x0r=o(" \u2014 "),KK=a("a"),$0r=o("BeitForImageClassification"),k0r=o(" (BEiT model)"),S0r=l(),uC=a("li"),a0e=a("strong"),R0r=o("convnext"),P0r=o(" \u2014 "),eee=a("a"),B0r=o("ConvNextForImageClassification"),I0r=o(" (ConvNeXT model)"),N0r=l(),pC=a("li"),n0e=a("strong"),q0r=o("cvt"),D0r=o(" \u2014 "),oee=a("a"),j0r=o("CvtForImageClassification"),G0r=o(" (CvT model)"),O0r=l(),_C=a("li"),s0e=a("strong"),V0r=o("data2vec-vision"),X0r=o(" \u2014 "),ree=a("a"),z0r=o("Data2VecVisionForImageClassification"),Q0r=o(" (Data2VecVision model)"),W0r=l(),$l=a("li"),l0e=a("strong"),U0r=o("deit"),H0r=o(" \u2014 "),tee=a("a"),J0r=o("DeiTForImageClassification"),Y0r=o(" or "),aee=a("a"),Z0r=o("DeiTForImageClassificationWithTeacher"),K0r=o(" (DeiT model)"),ewr=l(),bC=a("li"),i0e=a("strong"),owr=o("imagegpt"),rwr=o(" \u2014 "),nee=a("a"),twr=o("ImageGPTForImageClassification"),awr=o(" (ImageGPT model)"),nwr=l(),kl=a("li"),d0e=a("strong"),swr=o("levit"),lwr=o(" \u2014 "),see=a("a"),iwr=o("LevitForImageClassification"),dwr=o(" or "),lee=a("a"),mwr=o("LevitForImageClassificationWithTeacher"),cwr=o(" (LeViT model)"),fwr=l(),vC=a("li"),m0e=a("strong"),gwr=o("mobilevit"),hwr=o(" \u2014 "),iee=a("a"),uwr=o("MobileViTForImageClassification"),pwr=o(" (MobileViT model)"),_wr=l(),It=a("li"),c0e=a("strong"),bwr=o("perceiver"),vwr=o(" \u2014 "),dee=a("a"),Fwr=o("PerceiverForImageClassificationLearned"),Twr=o(" or "),mee=a("a"),Mwr=o("PerceiverForImageClassificationFourier"),Ewr=o(" or "),cee=a("a"),Cwr=o("PerceiverForImageClassificationConvProcessing"),wwr=o(" (Perceiver model)"),Awr=l(),FC=a("li"),f0e=a("strong"),Lwr=o("poolformer"),ywr=o(" \u2014 "),fee=a("a"),xwr=o("PoolFormerForImageClassification"),$wr=o(" (PoolFormer model)"),kwr=l(),TC=a("li"),g0e=a("strong"),Swr=o("regnet"),Rwr=o(" \u2014 "),gee=a("a"),Pwr=o("RegNetForImageClassification"),Bwr=o(" (RegNet model)"),Iwr=l(),MC=a("li"),h0e=a("strong"),Nwr=o("resnet"),qwr=o(" \u2014 "),hee=a("a"),Dwr=o("ResNetForImageClassification"),jwr=o(" (ResNet model)"),Gwr=l(),EC=a("li"),u0e=a("strong"),Owr=o("segformer"),Vwr=o(" \u2014 "),uee=a("a"),Xwr=o("SegformerForImageClassification"),zwr=o(" (SegFormer model)"),Qwr=l(),CC=a("li"),p0e=a("strong"),Wwr=o("swin"),Uwr=o(" \u2014 "),pee=a("a"),Hwr=o("SwinForImageClassification"),Jwr=o(" (Swin Transformer model)"),Ywr=l(),wC=a("li"),_0e=a("strong"),Zwr=o("swinv2"),Kwr=o(" \u2014 "),_ee=a("a"),eAr=o("Swinv2ForImageClassification"),oAr=o(" (Swin Transformer V2 model)"),rAr=l(),AC=a("li"),b0e=a("strong"),tAr=o("van"),aAr=o(" \u2014 "),bee=a("a"),nAr=o("VanForImageClassification"),sAr=o(" (VAN model)"),lAr=l(),LC=a("li"),v0e=a("strong"),iAr=o("vit"),dAr=o(" \u2014 "),vee=a("a"),mAr=o("ViTForImageClassification"),cAr=o(" (ViT model)"),fAr=l(),yC=a("li"),F0e=a("strong"),gAr=o("vit_msn"),hAr=o(" \u2014 "),Fee=a("a"),uAr=o("ViTMSNForImageClassification"),pAr=o(" (ViTMSN model)"),_Ar=l(),xC=a("p"),bAr=o("The model is set in evaluation mode by default using "),T0e=a("code"),vAr=o("model.eval()"),FAr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),M0e=a("code"),TAr=o("model.train()"),MAr=l(),F($C.$$.fragment),pao=l(),Tm=a("h2"),kC=a("a"),E0e=a("span"),F(Kk.$$.fragment),EAr=l(),C0e=a("span"),CAr=o("AutoModelForVideoClassification"),_ao=l(),Jo=a("div"),F(eS.$$.fragment),wAr=l(),Mm=a("p"),AAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),Tee=a("a"),LAr=o("from_pretrained()"),yAr=o(" class method or the "),Mee=a("a"),xAr=o("from_config()"),$Ar=o(` class
method.`),kAr=l(),oS=a("p"),SAr=o("This class cannot be instantiated directly using "),w0e=a("code"),RAr=o("__init__()"),PAr=o(" (throws an error)."),BAr=l(),Nt=a("div"),F(rS.$$.fragment),IAr=l(),A0e=a("p"),NAr=o("Instantiates one of the model classes of the library (with a video classification head) from a configuration."),qAr=l(),Em=a("p"),DAr=o(`Note:
Loading a model from its configuration file does `),L0e=a("strong"),jAr=o("not"),GAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Eee=a("a"),OAr=o("from_pretrained()"),VAr=o(" to load the model weights."),XAr=l(),F(SC.$$.fragment),zAr=l(),ho=a("div"),F(tS.$$.fragment),QAr=l(),y0e=a("p"),WAr=o("Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),UAr=l(),Fn=a("p"),HAr=o("The model class to instantiate is selected based on the "),x0e=a("code"),JAr=o("model_type"),YAr=o(` property of the config object (either
passed as an argument or loaded from `),$0e=a("code"),ZAr=o("pretrained_model_name_or_path"),KAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k0e=a("code"),e6r=o("pretrained_model_name_or_path"),o6r=o(":"),r6r=l(),S0e=a("ul"),RC=a("li"),R0e=a("strong"),t6r=o("videomae"),a6r=o(" \u2014 "),Cee=a("a"),n6r=o("VideoMAEForVideoClassification"),s6r=o(" (VideoMAE model)"),l6r=l(),PC=a("p"),i6r=o("The model is set in evaluation mode by default using "),P0e=a("code"),d6r=o("model.eval()"),m6r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),B0e=a("code"),c6r=o("model.train()"),f6r=l(),F(BC.$$.fragment),bao=l(),Cm=a("h2"),IC=a("a"),I0e=a("span"),F(aS.$$.fragment),g6r=l(),N0e=a("span"),h6r=o("AutoModelForVision2Seq"),vao=l(),Yo=a("div"),F(nS.$$.fragment),u6r=l(),wm=a("p"),p6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),wee=a("a"),_6r=o("from_pretrained()"),b6r=o(" class method or the "),Aee=a("a"),v6r=o("from_config()"),F6r=o(` class
method.`),T6r=l(),sS=a("p"),M6r=o("This class cannot be instantiated directly using "),q0e=a("code"),E6r=o("__init__()"),C6r=o(" (throws an error)."),w6r=l(),qt=a("div"),F(lS.$$.fragment),A6r=l(),D0e=a("p"),L6r=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),y6r=l(),Am=a("p"),x6r=o(`Note:
Loading a model from its configuration file does `),j0e=a("strong"),$6r=o("not"),k6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Lee=a("a"),S6r=o("from_pretrained()"),R6r=o(" to load the model weights."),P6r=l(),F(NC.$$.fragment),B6r=l(),uo=a("div"),F(iS.$$.fragment),I6r=l(),G0e=a("p"),N6r=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),q6r=l(),Tn=a("p"),D6r=o("The model class to instantiate is selected based on the "),O0e=a("code"),j6r=o("model_type"),G6r=o(` property of the config object (either
passed as an argument or loaded from `),V0e=a("code"),O6r=o("pretrained_model_name_or_path"),V6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X0e=a("code"),X6r=o("pretrained_model_name_or_path"),z6r=o(":"),Q6r=l(),z0e=a("ul"),qC=a("li"),Q0e=a("strong"),W6r=o("vision-encoder-decoder"),U6r=o(" \u2014 "),yee=a("a"),H6r=o("VisionEncoderDecoderModel"),J6r=o(" (Vision Encoder decoder model)"),Y6r=l(),DC=a("p"),Z6r=o("The model is set in evaluation mode by default using "),W0e=a("code"),K6r=o("model.eval()"),e7r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),U0e=a("code"),o7r=o("model.train()"),r7r=l(),F(jC.$$.fragment),Fao=l(),Lm=a("h2"),GC=a("a"),H0e=a("span"),F(dS.$$.fragment),t7r=l(),J0e=a("span"),a7r=o("AutoModelForVisualQuestionAnswering"),Tao=l(),Zo=a("div"),F(mS.$$.fragment),n7r=l(),ym=a("p"),s7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),xee=a("a"),l7r=o("from_pretrained()"),i7r=o(" class method or the "),$ee=a("a"),d7r=o("from_config()"),m7r=o(` class
method.`),c7r=l(),cS=a("p"),f7r=o("This class cannot be instantiated directly using "),Y0e=a("code"),g7r=o("__init__()"),h7r=o(" (throws an error)."),u7r=l(),Dt=a("div"),F(fS.$$.fragment),p7r=l(),Z0e=a("p"),_7r=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),b7r=l(),xm=a("p"),v7r=o(`Note:
Loading a model from its configuration file does `),K0e=a("strong"),F7r=o("not"),T7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kee=a("a"),M7r=o("from_pretrained()"),E7r=o(" to load the model weights."),C7r=l(),F(OC.$$.fragment),w7r=l(),po=a("div"),F(gS.$$.fragment),A7r=l(),ewe=a("p"),L7r=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),y7r=l(),Mn=a("p"),x7r=o("The model class to instantiate is selected based on the "),owe=a("code"),$7r=o("model_type"),k7r=o(` property of the config object (either
passed as an argument or loaded from `),rwe=a("code"),S7r=o("pretrained_model_name_or_path"),R7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),twe=a("code"),P7r=o("pretrained_model_name_or_path"),B7r=o(":"),I7r=l(),awe=a("ul"),VC=a("li"),nwe=a("strong"),N7r=o("vilt"),q7r=o(" \u2014 "),See=a("a"),D7r=o("ViltForQuestionAnswering"),j7r=o(" (ViLT model)"),G7r=l(),XC=a("p"),O7r=o("The model is set in evaluation mode by default using "),swe=a("code"),V7r=o("model.eval()"),X7r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lwe=a("code"),z7r=o("model.train()"),Q7r=l(),F(zC.$$.fragment),Mao=l(),$m=a("h2"),QC=a("a"),iwe=a("span"),F(hS.$$.fragment),W7r=l(),dwe=a("span"),U7r=o("AutoModelForAudioClassification"),Eao=l(),Ko=a("div"),F(uS.$$.fragment),H7r=l(),km=a("p"),J7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),Ree=a("a"),Y7r=o("from_pretrained()"),Z7r=o(" class method or the "),Pee=a("a"),K7r=o("from_config()"),e8r=o(` class
method.`),o8r=l(),pS=a("p"),r8r=o("This class cannot be instantiated directly using "),mwe=a("code"),t8r=o("__init__()"),a8r=o(" (throws an error)."),n8r=l(),jt=a("div"),F(_S.$$.fragment),s8r=l(),cwe=a("p"),l8r=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),i8r=l(),Sm=a("p"),d8r=o(`Note:
Loading a model from its configuration file does `),fwe=a("strong"),m8r=o("not"),c8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Bee=a("a"),f8r=o("from_pretrained()"),g8r=o(" to load the model weights."),h8r=l(),F(WC.$$.fragment),u8r=l(),_o=a("div"),F(bS.$$.fragment),p8r=l(),gwe=a("p"),_8r=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),b8r=l(),En=a("p"),v8r=o("The model class to instantiate is selected based on the "),hwe=a("code"),F8r=o("model_type"),T8r=o(` property of the config object (either
passed as an argument or loaded from `),uwe=a("code"),M8r=o("pretrained_model_name_or_path"),E8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pwe=a("code"),C8r=o("pretrained_model_name_or_path"),w8r=o(":"),A8r=l(),Be=a("ul"),UC=a("li"),_we=a("strong"),L8r=o("data2vec-audio"),y8r=o(" \u2014 "),Iee=a("a"),x8r=o("Data2VecAudioForSequenceClassification"),$8r=o(" (Data2VecAudio model)"),k8r=l(),HC=a("li"),bwe=a("strong"),S8r=o("hubert"),R8r=o(" \u2014 "),Nee=a("a"),P8r=o("HubertForSequenceClassification"),B8r=o(" (Hubert model)"),I8r=l(),JC=a("li"),vwe=a("strong"),N8r=o("sew"),q8r=o(" \u2014 "),qee=a("a"),D8r=o("SEWForSequenceClassification"),j8r=o(" (SEW model)"),G8r=l(),YC=a("li"),Fwe=a("strong"),O8r=o("sew-d"),V8r=o(" \u2014 "),Dee=a("a"),X8r=o("SEWDForSequenceClassification"),z8r=o(" (SEW-D model)"),Q8r=l(),ZC=a("li"),Twe=a("strong"),W8r=o("unispeech"),U8r=o(" \u2014 "),jee=a("a"),H8r=o("UniSpeechForSequenceClassification"),J8r=o(" (UniSpeech model)"),Y8r=l(),KC=a("li"),Mwe=a("strong"),Z8r=o("unispeech-sat"),K8r=o(" \u2014 "),Gee=a("a"),eLr=o("UniSpeechSatForSequenceClassification"),oLr=o(" (UniSpeechSat model)"),rLr=l(),e3=a("li"),Ewe=a("strong"),tLr=o("wav2vec2"),aLr=o(" \u2014 "),Oee=a("a"),nLr=o("Wav2Vec2ForSequenceClassification"),sLr=o(" (Wav2Vec2 model)"),lLr=l(),o3=a("li"),Cwe=a("strong"),iLr=o("wav2vec2-conformer"),dLr=o(" \u2014 "),Vee=a("a"),mLr=o("Wav2Vec2ConformerForSequenceClassification"),cLr=o(" (Wav2Vec2-Conformer model)"),fLr=l(),r3=a("li"),wwe=a("strong"),gLr=o("wavlm"),hLr=o(" \u2014 "),Xee=a("a"),uLr=o("WavLMForSequenceClassification"),pLr=o(" (WavLM model)"),_Lr=l(),t3=a("p"),bLr=o("The model is set in evaluation mode by default using "),Awe=a("code"),vLr=o("model.eval()"),FLr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Lwe=a("code"),TLr=o("model.train()"),MLr=l(),F(a3.$$.fragment),Cao=l(),Rm=a("h2"),n3=a("a"),ywe=a("span"),F(vS.$$.fragment),ELr=l(),xwe=a("span"),CLr=o("AutoModelForAudioFrameClassification"),wao=l(),er=a("div"),F(FS.$$.fragment),wLr=l(),Pm=a("p"),ALr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),zee=a("a"),LLr=o("from_pretrained()"),yLr=o(" class method or the "),Qee=a("a"),xLr=o("from_config()"),$Lr=o(` class
method.`),kLr=l(),TS=a("p"),SLr=o("This class cannot be instantiated directly using "),$we=a("code"),RLr=o("__init__()"),PLr=o(" (throws an error)."),BLr=l(),Gt=a("div"),F(MS.$$.fragment),ILr=l(),kwe=a("p"),NLr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),qLr=l(),Bm=a("p"),DLr=o(`Note:
Loading a model from its configuration file does `),Swe=a("strong"),jLr=o("not"),GLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Wee=a("a"),OLr=o("from_pretrained()"),VLr=o(" to load the model weights."),XLr=l(),F(s3.$$.fragment),zLr=l(),bo=a("div"),F(ES.$$.fragment),QLr=l(),Rwe=a("p"),WLr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),ULr=l(),Cn=a("p"),HLr=o("The model class to instantiate is selected based on the "),Pwe=a("code"),JLr=o("model_type"),YLr=o(` property of the config object (either
passed as an argument or loaded from `),Bwe=a("code"),ZLr=o("pretrained_model_name_or_path"),KLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Iwe=a("code"),eyr=o("pretrained_model_name_or_path"),oyr=o(":"),ryr=l(),ut=a("ul"),l3=a("li"),Nwe=a("strong"),tyr=o("data2vec-audio"),ayr=o(" \u2014 "),Uee=a("a"),nyr=o("Data2VecAudioForAudioFrameClassification"),syr=o(" (Data2VecAudio model)"),lyr=l(),i3=a("li"),qwe=a("strong"),iyr=o("unispeech-sat"),dyr=o(" \u2014 "),Hee=a("a"),myr=o("UniSpeechSatForAudioFrameClassification"),cyr=o(" (UniSpeechSat model)"),fyr=l(),d3=a("li"),Dwe=a("strong"),gyr=o("wav2vec2"),hyr=o(" \u2014 "),Jee=a("a"),uyr=o("Wav2Vec2ForAudioFrameClassification"),pyr=o(" (Wav2Vec2 model)"),_yr=l(),m3=a("li"),jwe=a("strong"),byr=o("wav2vec2-conformer"),vyr=o(" \u2014 "),Yee=a("a"),Fyr=o("Wav2Vec2ConformerForAudioFrameClassification"),Tyr=o(" (Wav2Vec2-Conformer model)"),Myr=l(),c3=a("li"),Gwe=a("strong"),Eyr=o("wavlm"),Cyr=o(" \u2014 "),Zee=a("a"),wyr=o("WavLMForAudioFrameClassification"),Ayr=o(" (WavLM model)"),Lyr=l(),f3=a("p"),yyr=o("The model is set in evaluation mode by default using "),Owe=a("code"),xyr=o("model.eval()"),$yr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Vwe=a("code"),kyr=o("model.train()"),Syr=l(),F(g3.$$.fragment),Aao=l(),Im=a("h2"),h3=a("a"),Xwe=a("span"),F(CS.$$.fragment),Ryr=l(),zwe=a("span"),Pyr=o("AutoModelForCTC"),Lao=l(),or=a("div"),F(wS.$$.fragment),Byr=l(),Nm=a("p"),Iyr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),Kee=a("a"),Nyr=o("from_pretrained()"),qyr=o(" class method or the "),eoe=a("a"),Dyr=o("from_config()"),jyr=o(` class
method.`),Gyr=l(),AS=a("p"),Oyr=o("This class cannot be instantiated directly using "),Qwe=a("code"),Vyr=o("__init__()"),Xyr=o(" (throws an error)."),zyr=l(),Ot=a("div"),F(LS.$$.fragment),Qyr=l(),Wwe=a("p"),Wyr=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),Uyr=l(),qm=a("p"),Hyr=o(`Note:
Loading a model from its configuration file does `),Uwe=a("strong"),Jyr=o("not"),Yyr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ooe=a("a"),Zyr=o("from_pretrained()"),Kyr=o(" to load the model weights."),e9r=l(),F(u3.$$.fragment),o9r=l(),vo=a("div"),F(yS.$$.fragment),r9r=l(),Hwe=a("p"),t9r=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),a9r=l(),wn=a("p"),n9r=o("The model class to instantiate is selected based on the "),Jwe=a("code"),s9r=o("model_type"),l9r=o(` property of the config object (either
passed as an argument or loaded from `),Ywe=a("code"),i9r=o("pretrained_model_name_or_path"),d9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zwe=a("code"),m9r=o("pretrained_model_name_or_path"),c9r=o(":"),f9r=l(),Le=a("ul"),p3=a("li"),Kwe=a("strong"),g9r=o("data2vec-audio"),h9r=o(" \u2014 "),roe=a("a"),u9r=o("Data2VecAudioForCTC"),p9r=o(" (Data2VecAudio model)"),_9r=l(),_3=a("li"),eAe=a("strong"),b9r=o("hubert"),v9r=o(" \u2014 "),toe=a("a"),F9r=o("HubertForCTC"),T9r=o(" (Hubert model)"),M9r=l(),b3=a("li"),oAe=a("strong"),E9r=o("mctct"),C9r=o(" \u2014 "),aoe=a("a"),w9r=o("MCTCTForCTC"),A9r=o(" (M-CTC-T model)"),L9r=l(),v3=a("li"),rAe=a("strong"),y9r=o("sew"),x9r=o(" \u2014 "),noe=a("a"),$9r=o("SEWForCTC"),k9r=o(" (SEW model)"),S9r=l(),F3=a("li"),tAe=a("strong"),R9r=o("sew-d"),P9r=o(" \u2014 "),soe=a("a"),B9r=o("SEWDForCTC"),I9r=o(" (SEW-D model)"),N9r=l(),T3=a("li"),aAe=a("strong"),q9r=o("unispeech"),D9r=o(" \u2014 "),loe=a("a"),j9r=o("UniSpeechForCTC"),G9r=o(" (UniSpeech model)"),O9r=l(),M3=a("li"),nAe=a("strong"),V9r=o("unispeech-sat"),X9r=o(" \u2014 "),ioe=a("a"),z9r=o("UniSpeechSatForCTC"),Q9r=o(" (UniSpeechSat model)"),W9r=l(),E3=a("li"),sAe=a("strong"),U9r=o("wav2vec2"),H9r=o(" \u2014 "),doe=a("a"),J9r=o("Wav2Vec2ForCTC"),Y9r=o(" (Wav2Vec2 model)"),Z9r=l(),C3=a("li"),lAe=a("strong"),K9r=o("wav2vec2-conformer"),exr=o(" \u2014 "),moe=a("a"),oxr=o("Wav2Vec2ConformerForCTC"),rxr=o(" (Wav2Vec2-Conformer model)"),txr=l(),w3=a("li"),iAe=a("strong"),axr=o("wavlm"),nxr=o(" \u2014 "),coe=a("a"),sxr=o("WavLMForCTC"),lxr=o(" (WavLM model)"),ixr=l(),A3=a("p"),dxr=o("The model is set in evaluation mode by default using "),dAe=a("code"),mxr=o("model.eval()"),cxr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mAe=a("code"),fxr=o("model.train()"),gxr=l(),F(L3.$$.fragment),yao=l(),Dm=a("h2"),y3=a("a"),cAe=a("span"),F(xS.$$.fragment),hxr=l(),fAe=a("span"),uxr=o("AutoModelForSpeechSeq2Seq"),xao=l(),rr=a("div"),F($S.$$.fragment),pxr=l(),jm=a("p"),_xr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),foe=a("a"),bxr=o("from_pretrained()"),vxr=o(" class method or the "),goe=a("a"),Fxr=o("from_config()"),Txr=o(` class
method.`),Mxr=l(),kS=a("p"),Exr=o("This class cannot be instantiated directly using "),gAe=a("code"),Cxr=o("__init__()"),wxr=o(" (throws an error)."),Axr=l(),Vt=a("div"),F(SS.$$.fragment),Lxr=l(),hAe=a("p"),yxr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),xxr=l(),Gm=a("p"),$xr=o(`Note:
Loading a model from its configuration file does `),uAe=a("strong"),kxr=o("not"),Sxr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hoe=a("a"),Rxr=o("from_pretrained()"),Pxr=o(" to load the model weights."),Bxr=l(),F(x3.$$.fragment),Ixr=l(),Fo=a("div"),F(RS.$$.fragment),Nxr=l(),pAe=a("p"),qxr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Dxr=l(),An=a("p"),jxr=o("The model class to instantiate is selected based on the "),_Ae=a("code"),Gxr=o("model_type"),Oxr=o(` property of the config object (either
passed as an argument or loaded from `),bAe=a("code"),Vxr=o("pretrained_model_name_or_path"),Xxr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vAe=a("code"),zxr=o("pretrained_model_name_or_path"),Qxr=o(":"),Wxr=l(),Om=a("ul"),$3=a("li"),FAe=a("strong"),Uxr=o("speech-encoder-decoder"),Hxr=o(" \u2014 "),uoe=a("a"),Jxr=o("SpeechEncoderDecoderModel"),Yxr=o(" (Speech Encoder decoder model)"),Zxr=l(),k3=a("li"),TAe=a("strong"),Kxr=o("speech_to_text"),e$r=o(" \u2014 "),poe=a("a"),o$r=o("Speech2TextForConditionalGeneration"),r$r=o(" (Speech2Text model)"),t$r=l(),S3=a("li"),MAe=a("strong"),a$r=o("whisper"),n$r=o(" \u2014 "),_oe=a("a"),s$r=o("WhisperForConditionalGeneration"),l$r=o(" (Whisper model)"),i$r=l(),R3=a("p"),d$r=o("The model is set in evaluation mode by default using "),EAe=a("code"),m$r=o("model.eval()"),c$r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),CAe=a("code"),f$r=o("model.train()"),g$r=l(),F(P3.$$.fragment),$ao=l(),Vm=a("h2"),B3=a("a"),wAe=a("span"),F(PS.$$.fragment),h$r=l(),AAe=a("span"),u$r=o("AutoModelForAudioXVector"),kao=l(),tr=a("div"),F(BS.$$.fragment),p$r=l(),Xm=a("p"),_$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),boe=a("a"),b$r=o("from_pretrained()"),v$r=o(" class method or the "),voe=a("a"),F$r=o("from_config()"),T$r=o(` class
method.`),M$r=l(),IS=a("p"),E$r=o("This class cannot be instantiated directly using "),LAe=a("code"),C$r=o("__init__()"),w$r=o(" (throws an error)."),A$r=l(),Xt=a("div"),F(NS.$$.fragment),L$r=l(),yAe=a("p"),y$r=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),x$r=l(),zm=a("p"),$$r=o(`Note:
Loading a model from its configuration file does `),xAe=a("strong"),k$r=o("not"),S$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Foe=a("a"),R$r=o("from_pretrained()"),P$r=o(" to load the model weights."),B$r=l(),F(I3.$$.fragment),I$r=l(),To=a("div"),F(qS.$$.fragment),N$r=l(),$Ae=a("p"),q$r=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),D$r=l(),Ln=a("p"),j$r=o("The model class to instantiate is selected based on the "),kAe=a("code"),G$r=o("model_type"),O$r=o(` property of the config object (either
passed as an argument or loaded from `),SAe=a("code"),V$r=o("pretrained_model_name_or_path"),X$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RAe=a("code"),z$r=o("pretrained_model_name_or_path"),Q$r=o(":"),W$r=l(),pt=a("ul"),N3=a("li"),PAe=a("strong"),U$r=o("data2vec-audio"),H$r=o(" \u2014 "),Toe=a("a"),J$r=o("Data2VecAudioForXVector"),Y$r=o(" (Data2VecAudio model)"),Z$r=l(),q3=a("li"),BAe=a("strong"),K$r=o("unispeech-sat"),ekr=o(" \u2014 "),Moe=a("a"),okr=o("UniSpeechSatForXVector"),rkr=o(" (UniSpeechSat model)"),tkr=l(),D3=a("li"),IAe=a("strong"),akr=o("wav2vec2"),nkr=o(" \u2014 "),Eoe=a("a"),skr=o("Wav2Vec2ForXVector"),lkr=o(" (Wav2Vec2 model)"),ikr=l(),j3=a("li"),NAe=a("strong"),dkr=o("wav2vec2-conformer"),mkr=o(" \u2014 "),Coe=a("a"),ckr=o("Wav2Vec2ConformerForXVector"),fkr=o(" (Wav2Vec2-Conformer model)"),gkr=l(),G3=a("li"),qAe=a("strong"),hkr=o("wavlm"),ukr=o(" \u2014 "),woe=a("a"),pkr=o("WavLMForXVector"),_kr=o(" (WavLM model)"),bkr=l(),O3=a("p"),vkr=o("The model is set in evaluation mode by default using "),DAe=a("code"),Fkr=o("model.eval()"),Tkr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),jAe=a("code"),Mkr=o("model.train()"),Ekr=l(),F(V3.$$.fragment),Sao=l(),Qm=a("h2"),X3=a("a"),GAe=a("span"),F(DS.$$.fragment),Ckr=l(),OAe=a("span"),wkr=o("AutoModelForMaskedImageModeling"),Rao=l(),ar=a("div"),F(jS.$$.fragment),Akr=l(),Wm=a("p"),Lkr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),Aoe=a("a"),ykr=o("from_pretrained()"),xkr=o(" class method or the "),Loe=a("a"),$kr=o("from_config()"),kkr=o(` class
method.`),Skr=l(),GS=a("p"),Rkr=o("This class cannot be instantiated directly using "),VAe=a("code"),Pkr=o("__init__()"),Bkr=o(" (throws an error)."),Ikr=l(),zt=a("div"),F(OS.$$.fragment),Nkr=l(),XAe=a("p"),qkr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),Dkr=l(),Um=a("p"),jkr=o(`Note:
Loading a model from its configuration file does `),zAe=a("strong"),Gkr=o("not"),Okr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yoe=a("a"),Vkr=o("from_pretrained()"),Xkr=o(" to load the model weights."),zkr=l(),F(z3.$$.fragment),Qkr=l(),Mo=a("div"),F(VS.$$.fragment),Wkr=l(),QAe=a("p"),Ukr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),Hkr=l(),yn=a("p"),Jkr=o("The model class to instantiate is selected based on the "),WAe=a("code"),Ykr=o("model_type"),Zkr=o(` property of the config object (either
passed as an argument or loaded from `),UAe=a("code"),Kkr=o("pretrained_model_name_or_path"),eSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HAe=a("code"),oSr=o("pretrained_model_name_or_path"),rSr=o(":"),tSr=l(),xn=a("ul"),Q3=a("li"),JAe=a("strong"),aSr=o("deit"),nSr=o(" \u2014 "),xoe=a("a"),sSr=o("DeiTForMaskedImageModeling"),lSr=o(" (DeiT model)"),iSr=l(),W3=a("li"),YAe=a("strong"),dSr=o("swin"),mSr=o(" \u2014 "),$oe=a("a"),cSr=o("SwinForMaskedImageModeling"),fSr=o(" (Swin Transformer model)"),gSr=l(),U3=a("li"),ZAe=a("strong"),hSr=o("swinv2"),uSr=o(" \u2014 "),koe=a("a"),pSr=o("Swinv2ForMaskedImageModeling"),_Sr=o(" (Swin Transformer V2 model)"),bSr=l(),H3=a("li"),KAe=a("strong"),vSr=o("vit"),FSr=o(" \u2014 "),Soe=a("a"),TSr=o("ViTForMaskedImageModeling"),MSr=o(" (ViT model)"),ESr=l(),J3=a("p"),CSr=o("The model is set in evaluation mode by default using "),e6e=a("code"),wSr=o("model.eval()"),ASr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o6e=a("code"),LSr=o("model.train()"),ySr=l(),F(Y3.$$.fragment),Pao=l(),Hm=a("h2"),Z3=a("a"),r6e=a("span"),F(XS.$$.fragment),xSr=l(),t6e=a("span"),$Sr=o("AutoModelForObjectDetection"),Bao=l(),nr=a("div"),F(zS.$$.fragment),kSr=l(),Jm=a("p"),SSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),Roe=a("a"),RSr=o("from_pretrained()"),PSr=o(" class method or the "),Poe=a("a"),BSr=o("from_config()"),ISr=o(` class
method.`),NSr=l(),QS=a("p"),qSr=o("This class cannot be instantiated directly using "),a6e=a("code"),DSr=o("__init__()"),jSr=o(" (throws an error)."),GSr=l(),Qt=a("div"),F(WS.$$.fragment),OSr=l(),n6e=a("p"),VSr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),XSr=l(),Ym=a("p"),zSr=o(`Note:
Loading a model from its configuration file does `),s6e=a("strong"),QSr=o("not"),WSr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Boe=a("a"),USr=o("from_pretrained()"),HSr=o(" to load the model weights."),JSr=l(),F(K3.$$.fragment),YSr=l(),Eo=a("div"),F(US.$$.fragment),ZSr=l(),l6e=a("p"),KSr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),eRr=l(),$n=a("p"),oRr=o("The model class to instantiate is selected based on the "),i6e=a("code"),rRr=o("model_type"),tRr=o(` property of the config object (either
passed as an argument or loaded from `),d6e=a("code"),aRr=o("pretrained_model_name_or_path"),nRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m6e=a("code"),sRr=o("pretrained_model_name_or_path"),lRr=o(":"),iRr=l(),_t=a("ul"),e5=a("li"),c6e=a("strong"),dRr=o("conditional_detr"),mRr=o(" \u2014 "),Ioe=a("a"),cRr=o("ConditionalDetrForObjectDetection"),fRr=o(" (Conditional DETR model)"),gRr=l(),o5=a("li"),f6e=a("strong"),hRr=o("deformable_detr"),uRr=o(" \u2014 "),Noe=a("a"),pRr=o("DeformableDetrForObjectDetection"),_Rr=o(" (Deformable DETR model)"),bRr=l(),r5=a("li"),g6e=a("strong"),vRr=o("detr"),FRr=o(" \u2014 "),qoe=a("a"),TRr=o("DetrForObjectDetection"),MRr=o(" (DETR model)"),ERr=l(),t5=a("li"),h6e=a("strong"),CRr=o("table-transformer"),wRr=o(" \u2014 "),Doe=a("a"),ARr=o("TableTransformerForObjectDetection"),LRr=o(" (Table Transformer model)"),yRr=l(),a5=a("li"),u6e=a("strong"),xRr=o("yolos"),$Rr=o(" \u2014 "),joe=a("a"),kRr=o("YolosForObjectDetection"),SRr=o(" (YOLOS model)"),RRr=l(),n5=a("p"),PRr=o("The model is set in evaluation mode by default using "),p6e=a("code"),BRr=o("model.eval()"),IRr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_6e=a("code"),NRr=o("model.train()"),qRr=l(),F(s5.$$.fragment),Iao=l(),Zm=a("h2"),l5=a("a"),b6e=a("span"),F(HS.$$.fragment),DRr=l(),v6e=a("span"),jRr=o("AutoModelForImageSegmentation"),Nao=l(),sr=a("div"),F(JS.$$.fragment),GRr=l(),Km=a("p"),ORr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),Goe=a("a"),VRr=o("from_pretrained()"),XRr=o(" class method or the "),Ooe=a("a"),zRr=o("from_config()"),QRr=o(` class
method.`),WRr=l(),YS=a("p"),URr=o("This class cannot be instantiated directly using "),F6e=a("code"),HRr=o("__init__()"),JRr=o(" (throws an error)."),YRr=l(),Wt=a("div"),F(ZS.$$.fragment),ZRr=l(),T6e=a("p"),KRr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),ePr=l(),ec=a("p"),oPr=o(`Note:
Loading a model from its configuration file does `),M6e=a("strong"),rPr=o("not"),tPr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Voe=a("a"),aPr=o("from_pretrained()"),nPr=o(" to load the model weights."),sPr=l(),F(i5.$$.fragment),lPr=l(),Co=a("div"),F(KS.$$.fragment),iPr=l(),E6e=a("p"),dPr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),mPr=l(),kn=a("p"),cPr=o("The model class to instantiate is selected based on the "),C6e=a("code"),fPr=o("model_type"),gPr=o(` property of the config object (either
passed as an argument or loaded from `),w6e=a("code"),hPr=o("pretrained_model_name_or_path"),uPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A6e=a("code"),pPr=o("pretrained_model_name_or_path"),_Pr=o(":"),bPr=l(),L6e=a("ul"),d5=a("li"),y6e=a("strong"),vPr=o("detr"),FPr=o(" \u2014 "),Xoe=a("a"),TPr=o("DetrForSegmentation"),MPr=o(" (DETR model)"),EPr=l(),m5=a("p"),CPr=o("The model is set in evaluation mode by default using "),x6e=a("code"),wPr=o("model.eval()"),APr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$6e=a("code"),LPr=o("model.train()"),yPr=l(),F(c5.$$.fragment),qao=l(),oc=a("h2"),f5=a("a"),k6e=a("span"),F(eR.$$.fragment),xPr=l(),S6e=a("span"),$Pr=o("AutoModelForSemanticSegmentation"),Dao=l(),lr=a("div"),F(oR.$$.fragment),kPr=l(),rc=a("p"),SPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),zoe=a("a"),RPr=o("from_pretrained()"),PPr=o(" class method or the "),Qoe=a("a"),BPr=o("from_config()"),IPr=o(` class
method.`),NPr=l(),rR=a("p"),qPr=o("This class cannot be instantiated directly using "),R6e=a("code"),DPr=o("__init__()"),jPr=o(" (throws an error)."),GPr=l(),Ut=a("div"),F(tR.$$.fragment),OPr=l(),P6e=a("p"),VPr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),XPr=l(),tc=a("p"),zPr=o(`Note:
Loading a model from its configuration file does `),B6e=a("strong"),QPr=o("not"),WPr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Woe=a("a"),UPr=o("from_pretrained()"),HPr=o(" to load the model weights."),JPr=l(),F(g5.$$.fragment),YPr=l(),wo=a("div"),F(aR.$$.fragment),ZPr=l(),I6e=a("p"),KPr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),eBr=l(),Sn=a("p"),oBr=o("The model class to instantiate is selected based on the "),N6e=a("code"),rBr=o("model_type"),tBr=o(` property of the config object (either
passed as an argument or loaded from `),q6e=a("code"),aBr=o("pretrained_model_name_or_path"),nBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D6e=a("code"),sBr=o("pretrained_model_name_or_path"),lBr=o(":"),iBr=l(),bt=a("ul"),h5=a("li"),j6e=a("strong"),dBr=o("beit"),mBr=o(" \u2014 "),Uoe=a("a"),cBr=o("BeitForSemanticSegmentation"),fBr=o(" (BEiT model)"),gBr=l(),u5=a("li"),G6e=a("strong"),hBr=o("data2vec-vision"),uBr=o(" \u2014 "),Hoe=a("a"),pBr=o("Data2VecVisionForSemanticSegmentation"),_Br=o(" (Data2VecVision model)"),bBr=l(),p5=a("li"),O6e=a("strong"),vBr=o("dpt"),FBr=o(" \u2014 "),Joe=a("a"),TBr=o("DPTForSemanticSegmentation"),MBr=o(" (DPT model)"),EBr=l(),_5=a("li"),V6e=a("strong"),CBr=o("mobilevit"),wBr=o(" \u2014 "),Yoe=a("a"),ABr=o("MobileViTForSemanticSegmentation"),LBr=o(" (MobileViT model)"),yBr=l(),b5=a("li"),X6e=a("strong"),xBr=o("segformer"),$Br=o(" \u2014 "),Zoe=a("a"),kBr=o("SegformerForSemanticSegmentation"),SBr=o(" (SegFormer model)"),RBr=l(),v5=a("p"),PBr=o("The model is set in evaluation mode by default using "),z6e=a("code"),BBr=o("model.eval()"),IBr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Q6e=a("code"),NBr=o("model.train()"),qBr=l(),F(F5.$$.fragment),jao=l(),ac=a("h2"),T5=a("a"),W6e=a("span"),F(nR.$$.fragment),DBr=l(),U6e=a("span"),jBr=o("AutoModelForInstanceSegmentation"),Gao=l(),ir=a("div"),F(sR.$$.fragment),GBr=l(),nc=a("p"),OBr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Koe=a("a"),VBr=o("from_pretrained()"),XBr=o(" class method or the "),ere=a("a"),zBr=o("from_config()"),QBr=o(` class
method.`),WBr=l(),lR=a("p"),UBr=o("This class cannot be instantiated directly using "),H6e=a("code"),HBr=o("__init__()"),JBr=o(" (throws an error)."),YBr=l(),Ht=a("div"),F(iR.$$.fragment),ZBr=l(),J6e=a("p"),KBr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),eIr=l(),sc=a("p"),oIr=o(`Note:
Loading a model from its configuration file does `),Y6e=a("strong"),rIr=o("not"),tIr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ore=a("a"),aIr=o("from_pretrained()"),nIr=o(" to load the model weights."),sIr=l(),F(M5.$$.fragment),lIr=l(),Ao=a("div"),F(dR.$$.fragment),iIr=l(),Z6e=a("p"),dIr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),mIr=l(),Rn=a("p"),cIr=o("The model class to instantiate is selected based on the "),K6e=a("code"),fIr=o("model_type"),gIr=o(` property of the config object (either
passed as an argument or loaded from `),e7e=a("code"),hIr=o("pretrained_model_name_or_path"),uIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o7e=a("code"),pIr=o("pretrained_model_name_or_path"),_Ir=o(":"),bIr=l(),r7e=a("ul"),E5=a("li"),t7e=a("strong"),vIr=o("maskformer"),FIr=o(" \u2014 "),rre=a("a"),TIr=o("MaskFormerForInstanceSegmentation"),MIr=o(" (MaskFormer model)"),EIr=l(),C5=a("p"),CIr=o("The model is set in evaluation mode by default using "),a7e=a("code"),wIr=o("model.eval()"),AIr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n7e=a("code"),LIr=o("model.train()"),yIr=l(),F(w5.$$.fragment),Oao=l(),lc=a("h2"),A5=a("a"),s7e=a("span"),F(mR.$$.fragment),xIr=l(),l7e=a("span"),$Ir=o("AutoModelForZeroShotObjectDetection"),Vao=l(),dr=a("div"),F(cR.$$.fragment),kIr=l(),ic=a("p"),SIr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),tre=a("a"),RIr=o("from_pretrained()"),PIr=o(" class method or the "),are=a("a"),BIr=o("from_config()"),IIr=o(` class
method.`),NIr=l(),fR=a("p"),qIr=o("This class cannot be instantiated directly using "),i7e=a("code"),DIr=o("__init__()"),jIr=o(" (throws an error)."),GIr=l(),Jt=a("div"),F(gR.$$.fragment),OIr=l(),d7e=a("p"),VIr=o("Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),XIr=l(),dc=a("p"),zIr=o(`Note:
Loading a model from its configuration file does `),m7e=a("strong"),QIr=o("not"),WIr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nre=a("a"),UIr=o("from_pretrained()"),HIr=o(" to load the model weights."),JIr=l(),F(L5.$$.fragment),YIr=l(),Lo=a("div"),F(hR.$$.fragment),ZIr=l(),c7e=a("p"),KIr=o("Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),eNr=l(),Pn=a("p"),oNr=o("The model class to instantiate is selected based on the "),f7e=a("code"),rNr=o("model_type"),tNr=o(` property of the config object (either
passed as an argument or loaded from `),g7e=a("code"),aNr=o("pretrained_model_name_or_path"),nNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h7e=a("code"),sNr=o("pretrained_model_name_or_path"),lNr=o(":"),iNr=l(),u7e=a("ul"),y5=a("li"),p7e=a("strong"),dNr=o("owlvit"),mNr=o(" \u2014 "),sre=a("a"),cNr=o("OwlViTForObjectDetection"),fNr=o(" (OWL-ViT model)"),gNr=l(),x5=a("p"),hNr=o("The model is set in evaluation mode by default using "),_7e=a("code"),uNr=o("model.eval()"),pNr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b7e=a("code"),_Nr=o("model.train()"),bNr=l(),F($5.$$.fragment),Xao=l(),mc=a("h2"),k5=a("a"),v7e=a("span"),F(uR.$$.fragment),vNr=l(),F7e=a("span"),FNr=o("TFAutoModel"),zao=l(),mr=a("div"),F(pR.$$.fragment),TNr=l(),cc=a("p"),MNr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),lre=a("a"),ENr=o("from_pretrained()"),CNr=o(" class method or the "),ire=a("a"),wNr=o("from_config()"),ANr=o(` class
method.`),LNr=l(),_R=a("p"),yNr=o("This class cannot be instantiated directly using "),T7e=a("code"),xNr=o("__init__()"),$Nr=o(" (throws an error)."),kNr=l(),Yt=a("div"),F(bR.$$.fragment),SNr=l(),M7e=a("p"),RNr=o("Instantiates one of the base model classes of the library from a configuration."),PNr=l(),fc=a("p"),BNr=o(`Note:
Loading a model from its configuration file does `),E7e=a("strong"),INr=o("not"),NNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dre=a("a"),qNr=o("from_pretrained()"),DNr=o(" to load the model weights."),jNr=l(),F(S5.$$.fragment),GNr=l(),jr=a("div"),F(vR.$$.fragment),ONr=l(),C7e=a("p"),VNr=o("Instantiate one of the base model classes of the library from a pretrained model."),XNr=l(),Bn=a("p"),zNr=o("The model class to instantiate is selected based on the "),w7e=a("code"),QNr=o("model_type"),WNr=o(` property of the config object (either
passed as an argument or loaded from `),A7e=a("code"),UNr=o("pretrained_model_name_or_path"),HNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L7e=a("code"),JNr=o("pretrained_model_name_or_path"),YNr=o(":"),ZNr=l(),P=a("ul"),R5=a("li"),y7e=a("strong"),KNr=o("albert"),eqr=o(" \u2014 "),mre=a("a"),oqr=o("TFAlbertModel"),rqr=o(" (ALBERT model)"),tqr=l(),P5=a("li"),x7e=a("strong"),aqr=o("bart"),nqr=o(" \u2014 "),cre=a("a"),sqr=o("TFBartModel"),lqr=o(" (BART model)"),iqr=l(),B5=a("li"),$7e=a("strong"),dqr=o("bert"),mqr=o(" \u2014 "),fre=a("a"),cqr=o("TFBertModel"),fqr=o(" (BERT model)"),gqr=l(),I5=a("li"),k7e=a("strong"),hqr=o("blenderbot"),uqr=o(" \u2014 "),gre=a("a"),pqr=o("TFBlenderbotModel"),_qr=o(" (Blenderbot model)"),bqr=l(),N5=a("li"),S7e=a("strong"),vqr=o("blenderbot-small"),Fqr=o(" \u2014 "),hre=a("a"),Tqr=o("TFBlenderbotSmallModel"),Mqr=o(" (BlenderbotSmall model)"),Eqr=l(),q5=a("li"),R7e=a("strong"),Cqr=o("camembert"),wqr=o(" \u2014 "),ure=a("a"),Aqr=o("TFCamembertModel"),Lqr=o(" (CamemBERT model)"),yqr=l(),D5=a("li"),P7e=a("strong"),xqr=o("clip"),$qr=o(" \u2014 "),pre=a("a"),kqr=o("TFCLIPModel"),Sqr=o(" (CLIP model)"),Rqr=l(),j5=a("li"),B7e=a("strong"),Pqr=o("convbert"),Bqr=o(" \u2014 "),_re=a("a"),Iqr=o("TFConvBertModel"),Nqr=o(" (ConvBERT model)"),qqr=l(),G5=a("li"),I7e=a("strong"),Dqr=o("convnext"),jqr=o(" \u2014 "),bre=a("a"),Gqr=o("TFConvNextModel"),Oqr=o(" (ConvNeXT model)"),Vqr=l(),O5=a("li"),N7e=a("strong"),Xqr=o("ctrl"),zqr=o(" \u2014 "),vre=a("a"),Qqr=o("TFCTRLModel"),Wqr=o(" (CTRL model)"),Uqr=l(),V5=a("li"),q7e=a("strong"),Hqr=o("cvt"),Jqr=o(" \u2014 "),Fre=a("a"),Yqr=o("TFCvtModel"),Zqr=o(" (CvT model)"),Kqr=l(),X5=a("li"),D7e=a("strong"),eDr=o("data2vec-vision"),oDr=o(" \u2014 "),Tre=a("a"),rDr=o("TFData2VecVisionModel"),tDr=o(" (Data2VecVision model)"),aDr=l(),z5=a("li"),j7e=a("strong"),nDr=o("deberta"),sDr=o(" \u2014 "),Mre=a("a"),lDr=o("TFDebertaModel"),iDr=o(" (DeBERTa model)"),dDr=l(),Q5=a("li"),G7e=a("strong"),mDr=o("deberta-v2"),cDr=o(" \u2014 "),Ere=a("a"),fDr=o("TFDebertaV2Model"),gDr=o(" (DeBERTa-v2 model)"),hDr=l(),W5=a("li"),O7e=a("strong"),uDr=o("deit"),pDr=o(" \u2014 "),Cre=a("a"),_Dr=o("TFDeiTModel"),bDr=o(" (DeiT model)"),vDr=l(),U5=a("li"),V7e=a("strong"),FDr=o("distilbert"),TDr=o(" \u2014 "),wre=a("a"),MDr=o("TFDistilBertModel"),EDr=o(" (DistilBERT model)"),CDr=l(),H5=a("li"),X7e=a("strong"),wDr=o("dpr"),ADr=o(" \u2014 "),Are=a("a"),LDr=o("TFDPRQuestionEncoder"),yDr=o(" (DPR model)"),xDr=l(),J5=a("li"),z7e=a("strong"),$Dr=o("electra"),kDr=o(" \u2014 "),Lre=a("a"),SDr=o("TFElectraModel"),RDr=o(" (ELECTRA model)"),PDr=l(),Y5=a("li"),Q7e=a("strong"),BDr=o("esm"),IDr=o(" \u2014 "),yre=a("a"),NDr=o("TFEsmModel"),qDr=o(" (ESM model)"),DDr=l(),Z5=a("li"),W7e=a("strong"),jDr=o("flaubert"),GDr=o(" \u2014 "),xre=a("a"),ODr=o("TFFlaubertModel"),VDr=o(" (FlauBERT model)"),XDr=l(),Sl=a("li"),U7e=a("strong"),zDr=o("funnel"),QDr=o(" \u2014 "),$re=a("a"),WDr=o("TFFunnelModel"),UDr=o(" or "),kre=a("a"),HDr=o("TFFunnelBaseModel"),JDr=o(" (Funnel Transformer model)"),YDr=l(),K5=a("li"),H7e=a("strong"),ZDr=o("gpt2"),KDr=o(" \u2014 "),Sre=a("a"),ejr=o("TFGPT2Model"),ojr=o(" (OpenAI GPT-2 model)"),rjr=l(),e0=a("li"),J7e=a("strong"),tjr=o("gptj"),ajr=o(" \u2014 "),Rre=a("a"),njr=o("TFGPTJModel"),sjr=o(" (GPT-J model)"),ljr=l(),o0=a("li"),Y7e=a("strong"),ijr=o("groupvit"),djr=o(" \u2014 "),Pre=a("a"),mjr=o("TFGroupViTModel"),cjr=o(" (GroupViT model)"),fjr=l(),r0=a("li"),Z7e=a("strong"),gjr=o("hubert"),hjr=o(" \u2014 "),Bre=a("a"),ujr=o("TFHubertModel"),pjr=o(" (Hubert model)"),_jr=l(),t0=a("li"),K7e=a("strong"),bjr=o("layoutlm"),vjr=o(" \u2014 "),Ire=a("a"),Fjr=o("TFLayoutLMModel"),Tjr=o(" (LayoutLM model)"),Mjr=l(),a0=a("li"),e8e=a("strong"),Ejr=o("layoutlmv3"),Cjr=o(" \u2014 "),Nre=a("a"),wjr=o("TFLayoutLMv3Model"),Ajr=o(" (LayoutLMv3 model)"),Ljr=l(),n0=a("li"),o8e=a("strong"),yjr=o("led"),xjr=o(" \u2014 "),qre=a("a"),$jr=o("TFLEDModel"),kjr=o(" (LED model)"),Sjr=l(),s0=a("li"),r8e=a("strong"),Rjr=o("longformer"),Pjr=o(" \u2014 "),Dre=a("a"),Bjr=o("TFLongformerModel"),Ijr=o(" (Longformer model)"),Njr=l(),l0=a("li"),t8e=a("strong"),qjr=o("lxmert"),Djr=o(" \u2014 "),jre=a("a"),jjr=o("TFLxmertModel"),Gjr=o(" (LXMERT model)"),Ojr=l(),i0=a("li"),a8e=a("strong"),Vjr=o("marian"),Xjr=o(" \u2014 "),Gre=a("a"),zjr=o("TFMarianModel"),Qjr=o(" (Marian model)"),Wjr=l(),d0=a("li"),n8e=a("strong"),Ujr=o("mbart"),Hjr=o(" \u2014 "),Ore=a("a"),Jjr=o("TFMBartModel"),Yjr=o(" (mBART model)"),Zjr=l(),m0=a("li"),s8e=a("strong"),Kjr=o("mobilebert"),eGr=o(" \u2014 "),Vre=a("a"),oGr=o("TFMobileBertModel"),rGr=o(" (MobileBERT model)"),tGr=l(),c0=a("li"),l8e=a("strong"),aGr=o("mobilevit"),nGr=o(" \u2014 "),Xre=a("a"),sGr=o("TFMobileViTModel"),lGr=o(" (MobileViT model)"),iGr=l(),f0=a("li"),i8e=a("strong"),dGr=o("mpnet"),mGr=o(" \u2014 "),zre=a("a"),cGr=o("TFMPNetModel"),fGr=o(" (MPNet model)"),gGr=l(),g0=a("li"),d8e=a("strong"),hGr=o("mt5"),uGr=o(" \u2014 "),Qre=a("a"),pGr=o("TFMT5Model"),_Gr=o(" (MT5 model)"),bGr=l(),h0=a("li"),m8e=a("strong"),vGr=o("openai-gpt"),FGr=o(" \u2014 "),Wre=a("a"),TGr=o("TFOpenAIGPTModel"),MGr=o(" (OpenAI GPT model)"),EGr=l(),u0=a("li"),c8e=a("strong"),CGr=o("opt"),wGr=o(" \u2014 "),Ure=a("a"),AGr=o("TFOPTModel"),LGr=o(" (OPT model)"),yGr=l(),p0=a("li"),f8e=a("strong"),xGr=o("pegasus"),$Gr=o(" \u2014 "),Hre=a("a"),kGr=o("TFPegasusModel"),SGr=o(" (Pegasus model)"),RGr=l(),_0=a("li"),g8e=a("strong"),PGr=o("regnet"),BGr=o(" \u2014 "),Jre=a("a"),IGr=o("TFRegNetModel"),NGr=o(" (RegNet model)"),qGr=l(),b0=a("li"),h8e=a("strong"),DGr=o("rembert"),jGr=o(" \u2014 "),Yre=a("a"),GGr=o("TFRemBertModel"),OGr=o(" (RemBERT model)"),VGr=l(),v0=a("li"),u8e=a("strong"),XGr=o("resnet"),zGr=o(" \u2014 "),Zre=a("a"),QGr=o("TFResNetModel"),WGr=o(" (ResNet model)"),UGr=l(),F0=a("li"),p8e=a("strong"),HGr=o("roberta"),JGr=o(" \u2014 "),Kre=a("a"),YGr=o("TFRobertaModel"),ZGr=o(" (RoBERTa model)"),KGr=l(),T0=a("li"),_8e=a("strong"),eOr=o("roformer"),oOr=o(" \u2014 "),ete=a("a"),rOr=o("TFRoFormerModel"),tOr=o(" (RoFormer model)"),aOr=l(),M0=a("li"),b8e=a("strong"),nOr=o("segformer"),sOr=o(" \u2014 "),ote=a("a"),lOr=o("TFSegformerModel"),iOr=o(" (SegFormer model)"),dOr=l(),E0=a("li"),v8e=a("strong"),mOr=o("speech_to_text"),cOr=o(" \u2014 "),rte=a("a"),fOr=o("TFSpeech2TextModel"),gOr=o(" (Speech2Text model)"),hOr=l(),C0=a("li"),F8e=a("strong"),uOr=o("swin"),pOr=o(" \u2014 "),tte=a("a"),_Or=o("TFSwinModel"),bOr=o(" (Swin Transformer model)"),vOr=l(),w0=a("li"),T8e=a("strong"),FOr=o("t5"),TOr=o(" \u2014 "),ate=a("a"),MOr=o("TFT5Model"),EOr=o(" (T5 model)"),COr=l(),A0=a("li"),M8e=a("strong"),wOr=o("tapas"),AOr=o(" \u2014 "),nte=a("a"),LOr=o("TFTapasModel"),yOr=o(" (TAPAS model)"),xOr=l(),L0=a("li"),E8e=a("strong"),$Or=o("transfo-xl"),kOr=o(" \u2014 "),ste=a("a"),SOr=o("TFTransfoXLModel"),ROr=o(" (Transformer-XL model)"),POr=l(),y0=a("li"),C8e=a("strong"),BOr=o("vit"),IOr=o(" \u2014 "),lte=a("a"),NOr=o("TFViTModel"),qOr=o(" (ViT model)"),DOr=l(),x0=a("li"),w8e=a("strong"),jOr=o("vit_mae"),GOr=o(" \u2014 "),ite=a("a"),OOr=o("TFViTMAEModel"),VOr=o(" (ViTMAE model)"),XOr=l(),$0=a("li"),A8e=a("strong"),zOr=o("wav2vec2"),QOr=o(" \u2014 "),dte=a("a"),WOr=o("TFWav2Vec2Model"),UOr=o(" (Wav2Vec2 model)"),HOr=l(),k0=a("li"),L8e=a("strong"),JOr=o("whisper"),YOr=o(" \u2014 "),mte=a("a"),ZOr=o("TFWhisperModel"),KOr=o(" (Whisper model)"),eVr=l(),S0=a("li"),y8e=a("strong"),oVr=o("xglm"),rVr=o(" \u2014 "),cte=a("a"),tVr=o("TFXGLMModel"),aVr=o(" (XGLM model)"),nVr=l(),R0=a("li"),x8e=a("strong"),sVr=o("xlm"),lVr=o(" \u2014 "),fte=a("a"),iVr=o("TFXLMModel"),dVr=o(" (XLM model)"),mVr=l(),P0=a("li"),$8e=a("strong"),cVr=o("xlm-roberta"),fVr=o(" \u2014 "),gte=a("a"),gVr=o("TFXLMRobertaModel"),hVr=o(" (XLM-RoBERTa model)"),uVr=l(),B0=a("li"),k8e=a("strong"),pVr=o("xlnet"),_Vr=o(" \u2014 "),hte=a("a"),bVr=o("TFXLNetModel"),vVr=o(" (XLNet model)"),FVr=l(),F(I0.$$.fragment),Qao=l(),gc=a("h2"),N0=a("a"),S8e=a("span"),F(FR.$$.fragment),TVr=l(),R8e=a("span"),MVr=o("TFAutoModelForPreTraining"),Wao=l(),cr=a("div"),F(TR.$$.fragment),EVr=l(),hc=a("p"),CVr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),ute=a("a"),wVr=o("from_pretrained()"),AVr=o(" class method or the "),pte=a("a"),LVr=o("from_config()"),yVr=o(` class
method.`),xVr=l(),MR=a("p"),$Vr=o("This class cannot be instantiated directly using "),P8e=a("code"),kVr=o("__init__()"),SVr=o(" (throws an error)."),RVr=l(),Zt=a("div"),F(ER.$$.fragment),PVr=l(),B8e=a("p"),BVr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),IVr=l(),uc=a("p"),NVr=o(`Note:
Loading a model from its configuration file does `),I8e=a("strong"),qVr=o("not"),DVr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_te=a("a"),jVr=o("from_pretrained()"),GVr=o(" to load the model weights."),OVr=l(),F(q0.$$.fragment),VVr=l(),Gr=a("div"),F(CR.$$.fragment),XVr=l(),N8e=a("p"),zVr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),QVr=l(),In=a("p"),WVr=o("The model class to instantiate is selected based on the "),q8e=a("code"),UVr=o("model_type"),HVr=o(` property of the config object (either
passed as an argument or loaded from `),D8e=a("code"),JVr=o("pretrained_model_name_or_path"),YVr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j8e=a("code"),ZVr=o("pretrained_model_name_or_path"),KVr=o(":"),eXr=l(),le=a("ul"),D0=a("li"),G8e=a("strong"),oXr=o("albert"),rXr=o(" \u2014 "),bte=a("a"),tXr=o("TFAlbertForPreTraining"),aXr=o(" (ALBERT model)"),nXr=l(),j0=a("li"),O8e=a("strong"),sXr=o("bart"),lXr=o(" \u2014 "),vte=a("a"),iXr=o("TFBartForConditionalGeneration"),dXr=o(" (BART model)"),mXr=l(),G0=a("li"),V8e=a("strong"),cXr=o("bert"),fXr=o(" \u2014 "),Fte=a("a"),gXr=o("TFBertForPreTraining"),hXr=o(" (BERT model)"),uXr=l(),O0=a("li"),X8e=a("strong"),pXr=o("camembert"),_Xr=o(" \u2014 "),Tte=a("a"),bXr=o("TFCamembertForMaskedLM"),vXr=o(" (CamemBERT model)"),FXr=l(),V0=a("li"),z8e=a("strong"),TXr=o("ctrl"),MXr=o(" \u2014 "),Mte=a("a"),EXr=o("TFCTRLLMHeadModel"),CXr=o(" (CTRL model)"),wXr=l(),X0=a("li"),Q8e=a("strong"),AXr=o("distilbert"),LXr=o(" \u2014 "),Ete=a("a"),yXr=o("TFDistilBertForMaskedLM"),xXr=o(" (DistilBERT model)"),$Xr=l(),z0=a("li"),W8e=a("strong"),kXr=o("electra"),SXr=o(" \u2014 "),Cte=a("a"),RXr=o("TFElectraForPreTraining"),PXr=o(" (ELECTRA model)"),BXr=l(),Q0=a("li"),U8e=a("strong"),IXr=o("flaubert"),NXr=o(" \u2014 "),wte=a("a"),qXr=o("TFFlaubertWithLMHeadModel"),DXr=o(" (FlauBERT model)"),jXr=l(),W0=a("li"),H8e=a("strong"),GXr=o("funnel"),OXr=o(" \u2014 "),Ate=a("a"),VXr=o("TFFunnelForPreTraining"),XXr=o(" (Funnel Transformer model)"),zXr=l(),U0=a("li"),J8e=a("strong"),QXr=o("gpt2"),WXr=o(" \u2014 "),Lte=a("a"),UXr=o("TFGPT2LMHeadModel"),HXr=o(" (OpenAI GPT-2 model)"),JXr=l(),H0=a("li"),Y8e=a("strong"),YXr=o("layoutlm"),ZXr=o(" \u2014 "),yte=a("a"),KXr=o("TFLayoutLMForMaskedLM"),ezr=o(" (LayoutLM model)"),ozr=l(),J0=a("li"),Z8e=a("strong"),rzr=o("lxmert"),tzr=o(" \u2014 "),xte=a("a"),azr=o("TFLxmertForPreTraining"),nzr=o(" (LXMERT model)"),szr=l(),Y0=a("li"),K8e=a("strong"),lzr=o("mobilebert"),izr=o(" \u2014 "),$te=a("a"),dzr=o("TFMobileBertForPreTraining"),mzr=o(" (MobileBERT model)"),czr=l(),Z0=a("li"),eLe=a("strong"),fzr=o("mpnet"),gzr=o(" \u2014 "),kte=a("a"),hzr=o("TFMPNetForMaskedLM"),uzr=o(" (MPNet model)"),pzr=l(),K0=a("li"),oLe=a("strong"),_zr=o("openai-gpt"),bzr=o(" \u2014 "),Ste=a("a"),vzr=o("TFOpenAIGPTLMHeadModel"),Fzr=o(" (OpenAI GPT model)"),Tzr=l(),ew=a("li"),rLe=a("strong"),Mzr=o("roberta"),Ezr=o(" \u2014 "),Rte=a("a"),Czr=o("TFRobertaForMaskedLM"),wzr=o(" (RoBERTa model)"),Azr=l(),ow=a("li"),tLe=a("strong"),Lzr=o("t5"),yzr=o(" \u2014 "),Pte=a("a"),xzr=o("TFT5ForConditionalGeneration"),$zr=o(" (T5 model)"),kzr=l(),rw=a("li"),aLe=a("strong"),Szr=o("tapas"),Rzr=o(" \u2014 "),Bte=a("a"),Pzr=o("TFTapasForMaskedLM"),Bzr=o(" (TAPAS model)"),Izr=l(),tw=a("li"),nLe=a("strong"),Nzr=o("transfo-xl"),qzr=o(" \u2014 "),Ite=a("a"),Dzr=o("TFTransfoXLLMHeadModel"),jzr=o(" (Transformer-XL model)"),Gzr=l(),aw=a("li"),sLe=a("strong"),Ozr=o("vit_mae"),Vzr=o(" \u2014 "),Nte=a("a"),Xzr=o("TFViTMAEForPreTraining"),zzr=o(" (ViTMAE model)"),Qzr=l(),nw=a("li"),lLe=a("strong"),Wzr=o("xlm"),Uzr=o(" \u2014 "),qte=a("a"),Hzr=o("TFXLMWithLMHeadModel"),Jzr=o(" (XLM model)"),Yzr=l(),sw=a("li"),iLe=a("strong"),Zzr=o("xlm-roberta"),Kzr=o(" \u2014 "),Dte=a("a"),eQr=o("TFXLMRobertaForMaskedLM"),oQr=o(" (XLM-RoBERTa model)"),rQr=l(),lw=a("li"),dLe=a("strong"),tQr=o("xlnet"),aQr=o(" \u2014 "),jte=a("a"),nQr=o("TFXLNetLMHeadModel"),sQr=o(" (XLNet model)"),lQr=l(),F(iw.$$.fragment),Uao=l(),pc=a("h2"),dw=a("a"),mLe=a("span"),F(wR.$$.fragment),iQr=l(),cLe=a("span"),dQr=o("TFAutoModelForCausalLM"),Hao=l(),fr=a("div"),F(AR.$$.fragment),mQr=l(),_c=a("p"),cQr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Gte=a("a"),fQr=o("from_pretrained()"),gQr=o(" class method or the "),Ote=a("a"),hQr=o("from_config()"),uQr=o(` class
method.`),pQr=l(),LR=a("p"),_Qr=o("This class cannot be instantiated directly using "),fLe=a("code"),bQr=o("__init__()"),vQr=o(" (throws an error)."),FQr=l(),Kt=a("div"),F(yR.$$.fragment),TQr=l(),gLe=a("p"),MQr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),EQr=l(),bc=a("p"),CQr=o(`Note:
Loading a model from its configuration file does `),hLe=a("strong"),wQr=o("not"),AQr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Vte=a("a"),LQr=o("from_pretrained()"),yQr=o(" to load the model weights."),xQr=l(),F(mw.$$.fragment),$Qr=l(),Or=a("div"),F(xR.$$.fragment),kQr=l(),uLe=a("p"),SQr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),RQr=l(),Nn=a("p"),PQr=o("The model class to instantiate is selected based on the "),pLe=a("code"),BQr=o("model_type"),IQr=o(` property of the config object (either
passed as an argument or loaded from `),_Le=a("code"),NQr=o("pretrained_model_name_or_path"),qQr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bLe=a("code"),DQr=o("pretrained_model_name_or_path"),jQr=o(":"),GQr=l(),Me=a("ul"),cw=a("li"),vLe=a("strong"),OQr=o("bert"),VQr=o(" \u2014 "),Xte=a("a"),XQr=o("TFBertLMHeadModel"),zQr=o(" (BERT model)"),QQr=l(),fw=a("li"),FLe=a("strong"),WQr=o("camembert"),UQr=o(" \u2014 "),zte=a("a"),HQr=o("TFCamembertForCausalLM"),JQr=o(" (CamemBERT model)"),YQr=l(),gw=a("li"),TLe=a("strong"),ZQr=o("ctrl"),KQr=o(" \u2014 "),Qte=a("a"),eWr=o("TFCTRLLMHeadModel"),oWr=o(" (CTRL model)"),rWr=l(),hw=a("li"),MLe=a("strong"),tWr=o("gpt2"),aWr=o(" \u2014 "),Wte=a("a"),nWr=o("TFGPT2LMHeadModel"),sWr=o(" (OpenAI GPT-2 model)"),lWr=l(),uw=a("li"),ELe=a("strong"),iWr=o("gptj"),dWr=o(" \u2014 "),Ute=a("a"),mWr=o("TFGPTJForCausalLM"),cWr=o(" (GPT-J model)"),fWr=l(),pw=a("li"),CLe=a("strong"),gWr=o("openai-gpt"),hWr=o(" \u2014 "),Hte=a("a"),uWr=o("TFOpenAIGPTLMHeadModel"),pWr=o(" (OpenAI GPT model)"),_Wr=l(),_w=a("li"),wLe=a("strong"),bWr=o("opt"),vWr=o(" \u2014 "),Jte=a("a"),FWr=o("TFOPTForCausalLM"),TWr=o(" (OPT model)"),MWr=l(),bw=a("li"),ALe=a("strong"),EWr=o("rembert"),CWr=o(" \u2014 "),Yte=a("a"),wWr=o("TFRemBertForCausalLM"),AWr=o(" (RemBERT model)"),LWr=l(),vw=a("li"),LLe=a("strong"),yWr=o("roberta"),xWr=o(" \u2014 "),Zte=a("a"),$Wr=o("TFRobertaForCausalLM"),kWr=o(" (RoBERTa model)"),SWr=l(),Fw=a("li"),yLe=a("strong"),RWr=o("roformer"),PWr=o(" \u2014 "),Kte=a("a"),BWr=o("TFRoFormerForCausalLM"),IWr=o(" (RoFormer model)"),NWr=l(),Tw=a("li"),xLe=a("strong"),qWr=o("transfo-xl"),DWr=o(" \u2014 "),eae=a("a"),jWr=o("TFTransfoXLLMHeadModel"),GWr=o(" (Transformer-XL model)"),OWr=l(),Mw=a("li"),$Le=a("strong"),VWr=o("xglm"),XWr=o(" \u2014 "),oae=a("a"),zWr=o("TFXGLMForCausalLM"),QWr=o(" (XGLM model)"),WWr=l(),Ew=a("li"),kLe=a("strong"),UWr=o("xlm"),HWr=o(" \u2014 "),rae=a("a"),JWr=o("TFXLMWithLMHeadModel"),YWr=o(" (XLM model)"),ZWr=l(),Cw=a("li"),SLe=a("strong"),KWr=o("xlnet"),eUr=o(" \u2014 "),tae=a("a"),oUr=o("TFXLNetLMHeadModel"),rUr=o(" (XLNet model)"),tUr=l(),F(ww.$$.fragment),Jao=l(),vc=a("h2"),Aw=a("a"),RLe=a("span"),F($R.$$.fragment),aUr=l(),PLe=a("span"),nUr=o("TFAutoModelForImageClassification"),Yao=l(),gr=a("div"),F(kR.$$.fragment),sUr=l(),Fc=a("p"),lUr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),aae=a("a"),iUr=o("from_pretrained()"),dUr=o(" class method or the "),nae=a("a"),mUr=o("from_config()"),cUr=o(` class
method.`),fUr=l(),SR=a("p"),gUr=o("This class cannot be instantiated directly using "),BLe=a("code"),hUr=o("__init__()"),uUr=o(" (throws an error)."),pUr=l(),ea=a("div"),F(RR.$$.fragment),_Ur=l(),ILe=a("p"),bUr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),vUr=l(),Tc=a("p"),FUr=o(`Note:
Loading a model from its configuration file does `),NLe=a("strong"),TUr=o("not"),MUr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sae=a("a"),EUr=o("from_pretrained()"),CUr=o(" to load the model weights."),wUr=l(),F(Lw.$$.fragment),AUr=l(),Vr=a("div"),F(PR.$$.fragment),LUr=l(),qLe=a("p"),yUr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),xUr=l(),qn=a("p"),$Ur=o("The model class to instantiate is selected based on the "),DLe=a("code"),kUr=o("model_type"),SUr=o(` property of the config object (either
passed as an argument or loaded from `),jLe=a("code"),RUr=o("pretrained_model_name_or_path"),PUr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),GLe=a("code"),BUr=o("pretrained_model_name_or_path"),IUr=o(":"),NUr=l(),ye=a("ul"),yw=a("li"),OLe=a("strong"),qUr=o("convnext"),DUr=o(" \u2014 "),lae=a("a"),jUr=o("TFConvNextForImageClassification"),GUr=o(" (ConvNeXT model)"),OUr=l(),xw=a("li"),VLe=a("strong"),VUr=o("cvt"),XUr=o(" \u2014 "),iae=a("a"),zUr=o("TFCvtForImageClassification"),QUr=o(" (CvT model)"),WUr=l(),$w=a("li"),XLe=a("strong"),UUr=o("data2vec-vision"),HUr=o(" \u2014 "),dae=a("a"),JUr=o("TFData2VecVisionForImageClassification"),YUr=o(" (Data2VecVision model)"),ZUr=l(),Rl=a("li"),zLe=a("strong"),KUr=o("deit"),eHr=o(" \u2014 "),mae=a("a"),oHr=o("TFDeiTForImageClassification"),rHr=o(" or "),cae=a("a"),tHr=o("TFDeiTForImageClassificationWithTeacher"),aHr=o(" (DeiT model)"),nHr=l(),kw=a("li"),QLe=a("strong"),sHr=o("mobilevit"),lHr=o(" \u2014 "),fae=a("a"),iHr=o("TFMobileViTForImageClassification"),dHr=o(" (MobileViT model)"),mHr=l(),Sw=a("li"),WLe=a("strong"),cHr=o("regnet"),fHr=o(" \u2014 "),gae=a("a"),gHr=o("TFRegNetForImageClassification"),hHr=o(" (RegNet model)"),uHr=l(),Rw=a("li"),ULe=a("strong"),pHr=o("resnet"),_Hr=o(" \u2014 "),hae=a("a"),bHr=o("TFResNetForImageClassification"),vHr=o(" (ResNet model)"),FHr=l(),Pw=a("li"),HLe=a("strong"),THr=o("segformer"),MHr=o(" \u2014 "),uae=a("a"),EHr=o("TFSegformerForImageClassification"),CHr=o(" (SegFormer model)"),wHr=l(),Bw=a("li"),JLe=a("strong"),AHr=o("swin"),LHr=o(" \u2014 "),pae=a("a"),yHr=o("TFSwinForImageClassification"),xHr=o(" (Swin Transformer model)"),$Hr=l(),Iw=a("li"),YLe=a("strong"),kHr=o("vit"),SHr=o(" \u2014 "),_ae=a("a"),RHr=o("TFViTForImageClassification"),PHr=o(" (ViT model)"),BHr=l(),F(Nw.$$.fragment),Zao=l(),Mc=a("h2"),qw=a("a"),ZLe=a("span"),F(BR.$$.fragment),IHr=l(),KLe=a("span"),NHr=o("TFAutoModelForSemanticSegmentation"),Kao=l(),hr=a("div"),F(IR.$$.fragment),qHr=l(),Ec=a("p"),DHr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),bae=a("a"),jHr=o("from_pretrained()"),GHr=o(" class method or the "),vae=a("a"),OHr=o("from_config()"),VHr=o(` class
method.`),XHr=l(),NR=a("p"),zHr=o("This class cannot be instantiated directly using "),eye=a("code"),QHr=o("__init__()"),WHr=o(" (throws an error)."),UHr=l(),oa=a("div"),F(qR.$$.fragment),HHr=l(),oye=a("p"),JHr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),YHr=l(),Cc=a("p"),ZHr=o(`Note:
Loading a model from its configuration file does `),rye=a("strong"),KHr=o("not"),eJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Fae=a("a"),oJr=o("from_pretrained()"),rJr=o(" to load the model weights."),tJr=l(),F(Dw.$$.fragment),aJr=l(),Xr=a("div"),F(DR.$$.fragment),nJr=l(),tye=a("p"),sJr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),lJr=l(),Dn=a("p"),iJr=o("The model class to instantiate is selected based on the "),aye=a("code"),dJr=o("model_type"),mJr=o(` property of the config object (either
passed as an argument or loaded from `),nye=a("code"),cJr=o("pretrained_model_name_or_path"),fJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sye=a("code"),gJr=o("pretrained_model_name_or_path"),hJr=o(":"),uJr=l(),wc=a("ul"),jw=a("li"),lye=a("strong"),pJr=o("data2vec-vision"),_Jr=o(" \u2014 "),Tae=a("a"),bJr=o("TFData2VecVisionForSemanticSegmentation"),vJr=o(" (Data2VecVision model)"),FJr=l(),Gw=a("li"),iye=a("strong"),TJr=o("mobilevit"),MJr=o(" \u2014 "),Mae=a("a"),EJr=o("TFMobileViTForSemanticSegmentation"),CJr=o(" (MobileViT model)"),wJr=l(),Ow=a("li"),dye=a("strong"),AJr=o("segformer"),LJr=o(" \u2014 "),Eae=a("a"),yJr=o("TFSegformerForSemanticSegmentation"),xJr=o(" (SegFormer model)"),$Jr=l(),F(Vw.$$.fragment),eno=l(),Ac=a("h2"),Xw=a("a"),mye=a("span"),F(jR.$$.fragment),kJr=l(),cye=a("span"),SJr=o("TFAutoModelForMaskedLM"),ono=l(),ur=a("div"),F(GR.$$.fragment),RJr=l(),Lc=a("p"),PJr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Cae=a("a"),BJr=o("from_pretrained()"),IJr=o(" class method or the "),wae=a("a"),NJr=o("from_config()"),qJr=o(` class
method.`),DJr=l(),OR=a("p"),jJr=o("This class cannot be instantiated directly using "),fye=a("code"),GJr=o("__init__()"),OJr=o(" (throws an error)."),VJr=l(),ra=a("div"),F(VR.$$.fragment),XJr=l(),gye=a("p"),zJr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),QJr=l(),yc=a("p"),WJr=o(`Note:
Loading a model from its configuration file does `),hye=a("strong"),UJr=o("not"),HJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Aae=a("a"),JJr=o("from_pretrained()"),YJr=o(" to load the model weights."),ZJr=l(),F(zw.$$.fragment),KJr=l(),zr=a("div"),F(XR.$$.fragment),eYr=l(),uye=a("p"),oYr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),rYr=l(),jn=a("p"),tYr=o("The model class to instantiate is selected based on the "),pye=a("code"),aYr=o("model_type"),nYr=o(` property of the config object (either
passed as an argument or loaded from `),_ye=a("code"),sYr=o("pretrained_model_name_or_path"),lYr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bye=a("code"),iYr=o("pretrained_model_name_or_path"),dYr=o(":"),mYr=l(),ce=a("ul"),Qw=a("li"),vye=a("strong"),cYr=o("albert"),fYr=o(" \u2014 "),Lae=a("a"),gYr=o("TFAlbertForMaskedLM"),hYr=o(" (ALBERT model)"),uYr=l(),Ww=a("li"),Fye=a("strong"),pYr=o("bert"),_Yr=o(" \u2014 "),yae=a("a"),bYr=o("TFBertForMaskedLM"),vYr=o(" (BERT model)"),FYr=l(),Uw=a("li"),Tye=a("strong"),TYr=o("camembert"),MYr=o(" \u2014 "),xae=a("a"),EYr=o("TFCamembertForMaskedLM"),CYr=o(" (CamemBERT model)"),wYr=l(),Hw=a("li"),Mye=a("strong"),AYr=o("convbert"),LYr=o(" \u2014 "),$ae=a("a"),yYr=o("TFConvBertForMaskedLM"),xYr=o(" (ConvBERT model)"),$Yr=l(),Jw=a("li"),Eye=a("strong"),kYr=o("deberta"),SYr=o(" \u2014 "),kae=a("a"),RYr=o("TFDebertaForMaskedLM"),PYr=o(" (DeBERTa model)"),BYr=l(),Yw=a("li"),Cye=a("strong"),IYr=o("deberta-v2"),NYr=o(" \u2014 "),Sae=a("a"),qYr=o("TFDebertaV2ForMaskedLM"),DYr=o(" (DeBERTa-v2 model)"),jYr=l(),Zw=a("li"),wye=a("strong"),GYr=o("distilbert"),OYr=o(" \u2014 "),Rae=a("a"),VYr=o("TFDistilBertForMaskedLM"),XYr=o(" (DistilBERT model)"),zYr=l(),Kw=a("li"),Aye=a("strong"),QYr=o("electra"),WYr=o(" \u2014 "),Pae=a("a"),UYr=o("TFElectraForMaskedLM"),HYr=o(" (ELECTRA model)"),JYr=l(),eA=a("li"),Lye=a("strong"),YYr=o("esm"),ZYr=o(" \u2014 "),Bae=a("a"),KYr=o("TFEsmForMaskedLM"),eZr=o(" (ESM model)"),oZr=l(),oA=a("li"),yye=a("strong"),rZr=o("flaubert"),tZr=o(" \u2014 "),Iae=a("a"),aZr=o("TFFlaubertWithLMHeadModel"),nZr=o(" (FlauBERT model)"),sZr=l(),rA=a("li"),xye=a("strong"),lZr=o("funnel"),iZr=o(" \u2014 "),Nae=a("a"),dZr=o("TFFunnelForMaskedLM"),mZr=o(" (Funnel Transformer model)"),cZr=l(),tA=a("li"),$ye=a("strong"),fZr=o("layoutlm"),gZr=o(" \u2014 "),qae=a("a"),hZr=o("TFLayoutLMForMaskedLM"),uZr=o(" (LayoutLM model)"),pZr=l(),aA=a("li"),kye=a("strong"),_Zr=o("longformer"),bZr=o(" \u2014 "),Dae=a("a"),vZr=o("TFLongformerForMaskedLM"),FZr=o(" (Longformer model)"),TZr=l(),nA=a("li"),Sye=a("strong"),MZr=o("mobilebert"),EZr=o(" \u2014 "),jae=a("a"),CZr=o("TFMobileBertForMaskedLM"),wZr=o(" (MobileBERT model)"),AZr=l(),sA=a("li"),Rye=a("strong"),LZr=o("mpnet"),yZr=o(" \u2014 "),Gae=a("a"),xZr=o("TFMPNetForMaskedLM"),$Zr=o(" (MPNet model)"),kZr=l(),lA=a("li"),Pye=a("strong"),SZr=o("rembert"),RZr=o(" \u2014 "),Oae=a("a"),PZr=o("TFRemBertForMaskedLM"),BZr=o(" (RemBERT model)"),IZr=l(),iA=a("li"),Bye=a("strong"),NZr=o("roberta"),qZr=o(" \u2014 "),Vae=a("a"),DZr=o("TFRobertaForMaskedLM"),jZr=o(" (RoBERTa model)"),GZr=l(),dA=a("li"),Iye=a("strong"),OZr=o("roformer"),VZr=o(" \u2014 "),Xae=a("a"),XZr=o("TFRoFormerForMaskedLM"),zZr=o(" (RoFormer model)"),QZr=l(),mA=a("li"),Nye=a("strong"),WZr=o("tapas"),UZr=o(" \u2014 "),zae=a("a"),HZr=o("TFTapasForMaskedLM"),JZr=o(" (TAPAS model)"),YZr=l(),cA=a("li"),qye=a("strong"),ZZr=o("xlm"),KZr=o(" \u2014 "),Qae=a("a"),eKr=o("TFXLMWithLMHeadModel"),oKr=o(" (XLM model)"),rKr=l(),fA=a("li"),Dye=a("strong"),tKr=o("xlm-roberta"),aKr=o(" \u2014 "),Wae=a("a"),nKr=o("TFXLMRobertaForMaskedLM"),sKr=o(" (XLM-RoBERTa model)"),lKr=l(),F(gA.$$.fragment),rno=l(),xc=a("h2"),hA=a("a"),jye=a("span"),F(zR.$$.fragment),iKr=l(),Gye=a("span"),dKr=o("TFAutoModelForSeq2SeqLM"),tno=l(),pr=a("div"),F(QR.$$.fragment),mKr=l(),$c=a("p"),cKr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Uae=a("a"),fKr=o("from_pretrained()"),gKr=o(" class method or the "),Hae=a("a"),hKr=o("from_config()"),uKr=o(` class
method.`),pKr=l(),WR=a("p"),_Kr=o("This class cannot be instantiated directly using "),Oye=a("code"),bKr=o("__init__()"),vKr=o(" (throws an error)."),FKr=l(),ta=a("div"),F(UR.$$.fragment),TKr=l(),Vye=a("p"),MKr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),EKr=l(),kc=a("p"),CKr=o(`Note:
Loading a model from its configuration file does `),Xye=a("strong"),wKr=o("not"),AKr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Jae=a("a"),LKr=o("from_pretrained()"),yKr=o(" to load the model weights."),xKr=l(),F(uA.$$.fragment),$Kr=l(),Qr=a("div"),F(HR.$$.fragment),kKr=l(),zye=a("p"),SKr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),RKr=l(),Gn=a("p"),PKr=o("The model class to instantiate is selected based on the "),Qye=a("code"),BKr=o("model_type"),IKr=o(` property of the config object (either
passed as an argument or loaded from `),Wye=a("code"),NKr=o("pretrained_model_name_or_path"),qKr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Uye=a("code"),DKr=o("pretrained_model_name_or_path"),jKr=o(":"),GKr=l(),xe=a("ul"),pA=a("li"),Hye=a("strong"),OKr=o("bart"),VKr=o(" \u2014 "),Yae=a("a"),XKr=o("TFBartForConditionalGeneration"),zKr=o(" (BART model)"),QKr=l(),_A=a("li"),Jye=a("strong"),WKr=o("blenderbot"),UKr=o(" \u2014 "),Zae=a("a"),HKr=o("TFBlenderbotForConditionalGeneration"),JKr=o(" (Blenderbot model)"),YKr=l(),bA=a("li"),Yye=a("strong"),ZKr=o("blenderbot-small"),KKr=o(" \u2014 "),Kae=a("a"),eet=o("TFBlenderbotSmallForConditionalGeneration"),oet=o(" (BlenderbotSmall model)"),ret=l(),vA=a("li"),Zye=a("strong"),tet=o("encoder-decoder"),aet=o(" \u2014 "),ene=a("a"),net=o("TFEncoderDecoderModel"),set=o(" (Encoder decoder model)"),iet=l(),FA=a("li"),Kye=a("strong"),det=o("led"),met=o(" \u2014 "),one=a("a"),cet=o("TFLEDForConditionalGeneration"),fet=o(" (LED model)"),get=l(),TA=a("li"),e9e=a("strong"),het=o("marian"),uet=o(" \u2014 "),rne=a("a"),pet=o("TFMarianMTModel"),_et=o(" (Marian model)"),bet=l(),MA=a("li"),o9e=a("strong"),vet=o("mbart"),Fet=o(" \u2014 "),tne=a("a"),Tet=o("TFMBartForConditionalGeneration"),Met=o(" (mBART model)"),Eet=l(),EA=a("li"),r9e=a("strong"),Cet=o("mt5"),wet=o(" \u2014 "),ane=a("a"),Aet=o("TFMT5ForConditionalGeneration"),Let=o(" (MT5 model)"),yet=l(),CA=a("li"),t9e=a("strong"),xet=o("pegasus"),$et=o(" \u2014 "),nne=a("a"),ket=o("TFPegasusForConditionalGeneration"),Set=o(" (Pegasus model)"),Ret=l(),wA=a("li"),a9e=a("strong"),Pet=o("t5"),Bet=o(" \u2014 "),sne=a("a"),Iet=o("TFT5ForConditionalGeneration"),Net=o(" (T5 model)"),qet=l(),F(AA.$$.fragment),ano=l(),Sc=a("h2"),LA=a("a"),n9e=a("span"),F(JR.$$.fragment),Det=l(),s9e=a("span"),jet=o("TFAutoModelForSequenceClassification"),nno=l(),_r=a("div"),F(YR.$$.fragment),Get=l(),Rc=a("p"),Oet=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),lne=a("a"),Vet=o("from_pretrained()"),Xet=o(" class method or the "),ine=a("a"),zet=o("from_config()"),Qet=o(` class
method.`),Wet=l(),ZR=a("p"),Uet=o("This class cannot be instantiated directly using "),l9e=a("code"),Het=o("__init__()"),Jet=o(" (throws an error)."),Yet=l(),aa=a("div"),F(KR.$$.fragment),Zet=l(),i9e=a("p"),Ket=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),eot=l(),Pc=a("p"),oot=o(`Note:
Loading a model from its configuration file does `),d9e=a("strong"),rot=o("not"),tot=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dne=a("a"),aot=o("from_pretrained()"),not=o(" to load the model weights."),sot=l(),F(yA.$$.fragment),lot=l(),Wr=a("div"),F(eP.$$.fragment),iot=l(),m9e=a("p"),dot=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),mot=l(),On=a("p"),cot=o("The model class to instantiate is selected based on the "),c9e=a("code"),fot=o("model_type"),got=o(` property of the config object (either
passed as an argument or loaded from `),f9e=a("code"),hot=o("pretrained_model_name_or_path"),uot=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g9e=a("code"),pot=o("pretrained_model_name_or_path"),_ot=o(":"),bot=l(),re=a("ul"),xA=a("li"),h9e=a("strong"),vot=o("albert"),Fot=o(" \u2014 "),mne=a("a"),Tot=o("TFAlbertForSequenceClassification"),Mot=o(" (ALBERT model)"),Eot=l(),$A=a("li"),u9e=a("strong"),Cot=o("bert"),wot=o(" \u2014 "),cne=a("a"),Aot=o("TFBertForSequenceClassification"),Lot=o(" (BERT model)"),yot=l(),kA=a("li"),p9e=a("strong"),xot=o("camembert"),$ot=o(" \u2014 "),fne=a("a"),kot=o("TFCamembertForSequenceClassification"),Sot=o(" (CamemBERT model)"),Rot=l(),SA=a("li"),_9e=a("strong"),Pot=o("convbert"),Bot=o(" \u2014 "),gne=a("a"),Iot=o("TFConvBertForSequenceClassification"),Not=o(" (ConvBERT model)"),qot=l(),RA=a("li"),b9e=a("strong"),Dot=o("ctrl"),jot=o(" \u2014 "),hne=a("a"),Got=o("TFCTRLForSequenceClassification"),Oot=o(" (CTRL model)"),Vot=l(),PA=a("li"),v9e=a("strong"),Xot=o("deberta"),zot=o(" \u2014 "),une=a("a"),Qot=o("TFDebertaForSequenceClassification"),Wot=o(" (DeBERTa model)"),Uot=l(),BA=a("li"),F9e=a("strong"),Hot=o("deberta-v2"),Jot=o(" \u2014 "),pne=a("a"),Yot=o("TFDebertaV2ForSequenceClassification"),Zot=o(" (DeBERTa-v2 model)"),Kot=l(),IA=a("li"),T9e=a("strong"),ert=o("distilbert"),ort=o(" \u2014 "),_ne=a("a"),rrt=o("TFDistilBertForSequenceClassification"),trt=o(" (DistilBERT model)"),art=l(),NA=a("li"),M9e=a("strong"),nrt=o("electra"),srt=o(" \u2014 "),bne=a("a"),lrt=o("TFElectraForSequenceClassification"),irt=o(" (ELECTRA model)"),drt=l(),qA=a("li"),E9e=a("strong"),mrt=o("esm"),crt=o(" \u2014 "),vne=a("a"),frt=o("TFEsmForSequenceClassification"),grt=o(" (ESM model)"),hrt=l(),DA=a("li"),C9e=a("strong"),urt=o("flaubert"),prt=o(" \u2014 "),Fne=a("a"),_rt=o("TFFlaubertForSequenceClassification"),brt=o(" (FlauBERT model)"),vrt=l(),jA=a("li"),w9e=a("strong"),Frt=o("funnel"),Trt=o(" \u2014 "),Tne=a("a"),Mrt=o("TFFunnelForSequenceClassification"),Ert=o(" (Funnel Transformer model)"),Crt=l(),GA=a("li"),A9e=a("strong"),wrt=o("gpt2"),Art=o(" \u2014 "),Mne=a("a"),Lrt=o("TFGPT2ForSequenceClassification"),yrt=o(" (OpenAI GPT-2 model)"),xrt=l(),OA=a("li"),L9e=a("strong"),$rt=o("gptj"),krt=o(" \u2014 "),Ene=a("a"),Srt=o("TFGPTJForSequenceClassification"),Rrt=o(" (GPT-J model)"),Prt=l(),VA=a("li"),y9e=a("strong"),Brt=o("layoutlm"),Irt=o(" \u2014 "),Cne=a("a"),Nrt=o("TFLayoutLMForSequenceClassification"),qrt=o(" (LayoutLM model)"),Drt=l(),XA=a("li"),x9e=a("strong"),jrt=o("layoutlmv3"),Grt=o(" \u2014 "),wne=a("a"),Ort=o("TFLayoutLMv3ForSequenceClassification"),Vrt=o(" (LayoutLMv3 model)"),Xrt=l(),zA=a("li"),$9e=a("strong"),zrt=o("longformer"),Qrt=o(" \u2014 "),Ane=a("a"),Wrt=o("TFLongformerForSequenceClassification"),Urt=o(" (Longformer model)"),Hrt=l(),QA=a("li"),k9e=a("strong"),Jrt=o("mobilebert"),Yrt=o(" \u2014 "),Lne=a("a"),Zrt=o("TFMobileBertForSequenceClassification"),Krt=o(" (MobileBERT model)"),ett=l(),WA=a("li"),S9e=a("strong"),ott=o("mpnet"),rtt=o(" \u2014 "),yne=a("a"),ttt=o("TFMPNetForSequenceClassification"),att=o(" (MPNet model)"),ntt=l(),UA=a("li"),R9e=a("strong"),stt=o("openai-gpt"),ltt=o(" \u2014 "),xne=a("a"),itt=o("TFOpenAIGPTForSequenceClassification"),dtt=o(" (OpenAI GPT model)"),mtt=l(),HA=a("li"),P9e=a("strong"),ctt=o("rembert"),ftt=o(" \u2014 "),$ne=a("a"),gtt=o("TFRemBertForSequenceClassification"),htt=o(" (RemBERT model)"),utt=l(),JA=a("li"),B9e=a("strong"),ptt=o("roberta"),_tt=o(" \u2014 "),kne=a("a"),btt=o("TFRobertaForSequenceClassification"),vtt=o(" (RoBERTa model)"),Ftt=l(),YA=a("li"),I9e=a("strong"),Ttt=o("roformer"),Mtt=o(" \u2014 "),Sne=a("a"),Ett=o("TFRoFormerForSequenceClassification"),Ctt=o(" (RoFormer model)"),wtt=l(),ZA=a("li"),N9e=a("strong"),Att=o("tapas"),Ltt=o(" \u2014 "),Rne=a("a"),ytt=o("TFTapasForSequenceClassification"),xtt=o(" (TAPAS model)"),$tt=l(),KA=a("li"),q9e=a("strong"),ktt=o("transfo-xl"),Stt=o(" \u2014 "),Pne=a("a"),Rtt=o("TFTransfoXLForSequenceClassification"),Ptt=o(" (Transformer-XL model)"),Btt=l(),e6=a("li"),D9e=a("strong"),Itt=o("xlm"),Ntt=o(" \u2014 "),Bne=a("a"),qtt=o("TFXLMForSequenceClassification"),Dtt=o(" (XLM model)"),jtt=l(),o6=a("li"),j9e=a("strong"),Gtt=o("xlm-roberta"),Ott=o(" \u2014 "),Ine=a("a"),Vtt=o("TFXLMRobertaForSequenceClassification"),Xtt=o(" (XLM-RoBERTa model)"),ztt=l(),r6=a("li"),G9e=a("strong"),Qtt=o("xlnet"),Wtt=o(" \u2014 "),Nne=a("a"),Utt=o("TFXLNetForSequenceClassification"),Htt=o(" (XLNet model)"),Jtt=l(),F(t6.$$.fragment),sno=l(),Bc=a("h2"),a6=a("a"),O9e=a("span"),F(oP.$$.fragment),Ytt=l(),V9e=a("span"),Ztt=o("TFAutoModelForMultipleChoice"),lno=l(),br=a("div"),F(rP.$$.fragment),Ktt=l(),Ic=a("p"),eat=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),qne=a("a"),oat=o("from_pretrained()"),rat=o(" class method or the "),Dne=a("a"),tat=o("from_config()"),aat=o(` class
method.`),nat=l(),tP=a("p"),sat=o("This class cannot be instantiated directly using "),X9e=a("code"),lat=o("__init__()"),iat=o(" (throws an error)."),dat=l(),na=a("div"),F(aP.$$.fragment),mat=l(),z9e=a("p"),cat=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),fat=l(),Nc=a("p"),gat=o(`Note:
Loading a model from its configuration file does `),Q9e=a("strong"),hat=o("not"),uat=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jne=a("a"),pat=o("from_pretrained()"),_at=o(" to load the model weights."),bat=l(),F(n6.$$.fragment),vat=l(),Ur=a("div"),F(nP.$$.fragment),Fat=l(),W9e=a("p"),Tat=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Mat=l(),Vn=a("p"),Eat=o("The model class to instantiate is selected based on the "),U9e=a("code"),Cat=o("model_type"),wat=o(` property of the config object (either
passed as an argument or loaded from `),H9e=a("code"),Aat=o("pretrained_model_name_or_path"),Lat=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J9e=a("code"),yat=o("pretrained_model_name_or_path"),xat=o(":"),$at=l(),ve=a("ul"),s6=a("li"),Y9e=a("strong"),kat=o("albert"),Sat=o(" \u2014 "),Gne=a("a"),Rat=o("TFAlbertForMultipleChoice"),Pat=o(" (ALBERT model)"),Bat=l(),l6=a("li"),Z9e=a("strong"),Iat=o("bert"),Nat=o(" \u2014 "),One=a("a"),qat=o("TFBertForMultipleChoice"),Dat=o(" (BERT model)"),jat=l(),i6=a("li"),K9e=a("strong"),Gat=o("camembert"),Oat=o(" \u2014 "),Vne=a("a"),Vat=o("TFCamembertForMultipleChoice"),Xat=o(" (CamemBERT model)"),zat=l(),d6=a("li"),exe=a("strong"),Qat=o("convbert"),Wat=o(" \u2014 "),Xne=a("a"),Uat=o("TFConvBertForMultipleChoice"),Hat=o(" (ConvBERT model)"),Jat=l(),m6=a("li"),oxe=a("strong"),Yat=o("distilbert"),Zat=o(" \u2014 "),zne=a("a"),Kat=o("TFDistilBertForMultipleChoice"),ent=o(" (DistilBERT model)"),ont=l(),c6=a("li"),rxe=a("strong"),rnt=o("electra"),tnt=o(" \u2014 "),Qne=a("a"),ant=o("TFElectraForMultipleChoice"),nnt=o(" (ELECTRA model)"),snt=l(),f6=a("li"),txe=a("strong"),lnt=o("flaubert"),int=o(" \u2014 "),Wne=a("a"),dnt=o("TFFlaubertForMultipleChoice"),mnt=o(" (FlauBERT model)"),cnt=l(),g6=a("li"),axe=a("strong"),fnt=o("funnel"),gnt=o(" \u2014 "),Une=a("a"),hnt=o("TFFunnelForMultipleChoice"),unt=o(" (Funnel Transformer model)"),pnt=l(),h6=a("li"),nxe=a("strong"),_nt=o("longformer"),bnt=o(" \u2014 "),Hne=a("a"),vnt=o("TFLongformerForMultipleChoice"),Fnt=o(" (Longformer model)"),Tnt=l(),u6=a("li"),sxe=a("strong"),Mnt=o("mobilebert"),Ent=o(" \u2014 "),Jne=a("a"),Cnt=o("TFMobileBertForMultipleChoice"),wnt=o(" (MobileBERT model)"),Ant=l(),p6=a("li"),lxe=a("strong"),Lnt=o("mpnet"),ynt=o(" \u2014 "),Yne=a("a"),xnt=o("TFMPNetForMultipleChoice"),$nt=o(" (MPNet model)"),knt=l(),_6=a("li"),ixe=a("strong"),Snt=o("rembert"),Rnt=o(" \u2014 "),Zne=a("a"),Pnt=o("TFRemBertForMultipleChoice"),Bnt=o(" (RemBERT model)"),Int=l(),b6=a("li"),dxe=a("strong"),Nnt=o("roberta"),qnt=o(" \u2014 "),Kne=a("a"),Dnt=o("TFRobertaForMultipleChoice"),jnt=o(" (RoBERTa model)"),Gnt=l(),v6=a("li"),mxe=a("strong"),Ont=o("roformer"),Vnt=o(" \u2014 "),ese=a("a"),Xnt=o("TFRoFormerForMultipleChoice"),znt=o(" (RoFormer model)"),Qnt=l(),F6=a("li"),cxe=a("strong"),Wnt=o("xlm"),Unt=o(" \u2014 "),ose=a("a"),Hnt=o("TFXLMForMultipleChoice"),Jnt=o(" (XLM model)"),Ynt=l(),T6=a("li"),fxe=a("strong"),Znt=o("xlm-roberta"),Knt=o(" \u2014 "),rse=a("a"),est=o("TFXLMRobertaForMultipleChoice"),ost=o(" (XLM-RoBERTa model)"),rst=l(),M6=a("li"),gxe=a("strong"),tst=o("xlnet"),ast=o(" \u2014 "),tse=a("a"),nst=o("TFXLNetForMultipleChoice"),sst=o(" (XLNet model)"),lst=l(),F(E6.$$.fragment),ino=l(),qc=a("h2"),C6=a("a"),hxe=a("span"),F(sP.$$.fragment),ist=l(),uxe=a("span"),dst=o("TFAutoModelForNextSentencePrediction"),dno=l(),vr=a("div"),F(lP.$$.fragment),mst=l(),Dc=a("p"),cst=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),ase=a("a"),fst=o("from_pretrained()"),gst=o(" class method or the "),nse=a("a"),hst=o("from_config()"),ust=o(` class
method.`),pst=l(),iP=a("p"),_st=o("This class cannot be instantiated directly using "),pxe=a("code"),bst=o("__init__()"),vst=o(" (throws an error)."),Fst=l(),sa=a("div"),F(dP.$$.fragment),Tst=l(),_xe=a("p"),Mst=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Est=l(),jc=a("p"),Cst=o(`Note:
Loading a model from its configuration file does `),bxe=a("strong"),wst=o("not"),Ast=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sse=a("a"),Lst=o("from_pretrained()"),yst=o(" to load the model weights."),xst=l(),F(w6.$$.fragment),$st=l(),Hr=a("div"),F(mP.$$.fragment),kst=l(),vxe=a("p"),Sst=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Rst=l(),Xn=a("p"),Pst=o("The model class to instantiate is selected based on the "),Fxe=a("code"),Bst=o("model_type"),Ist=o(` property of the config object (either
passed as an argument or loaded from `),Txe=a("code"),Nst=o("pretrained_model_name_or_path"),qst=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mxe=a("code"),Dst=o("pretrained_model_name_or_path"),jst=o(":"),Gst=l(),cP=a("ul"),A6=a("li"),Exe=a("strong"),Ost=o("bert"),Vst=o(" \u2014 "),lse=a("a"),Xst=o("TFBertForNextSentencePrediction"),zst=o(" (BERT model)"),Qst=l(),L6=a("li"),Cxe=a("strong"),Wst=o("mobilebert"),Ust=o(" \u2014 "),ise=a("a"),Hst=o("TFMobileBertForNextSentencePrediction"),Jst=o(" (MobileBERT model)"),Yst=l(),F(y6.$$.fragment),mno=l(),Gc=a("h2"),x6=a("a"),wxe=a("span"),F(fP.$$.fragment),Zst=l(),Axe=a("span"),Kst=o("TFAutoModelForTableQuestionAnswering"),cno=l(),Fr=a("div"),F(gP.$$.fragment),elt=l(),Oc=a("p"),olt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),dse=a("a"),rlt=o("from_pretrained()"),tlt=o(" class method or the "),mse=a("a"),alt=o("from_config()"),nlt=o(` class
method.`),slt=l(),hP=a("p"),llt=o("This class cannot be instantiated directly using "),Lxe=a("code"),ilt=o("__init__()"),dlt=o(" (throws an error)."),mlt=l(),la=a("div"),F(uP.$$.fragment),clt=l(),yxe=a("p"),flt=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),glt=l(),Vc=a("p"),hlt=o(`Note:
Loading a model from its configuration file does `),xxe=a("strong"),ult=o("not"),plt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cse=a("a"),_lt=o("from_pretrained()"),blt=o(" to load the model weights."),vlt=l(),F($6.$$.fragment),Flt=l(),Jr=a("div"),F(pP.$$.fragment),Tlt=l(),$xe=a("p"),Mlt=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Elt=l(),zn=a("p"),Clt=o("The model class to instantiate is selected based on the "),kxe=a("code"),wlt=o("model_type"),Alt=o(` property of the config object (either
passed as an argument or loaded from `),Sxe=a("code"),Llt=o("pretrained_model_name_or_path"),ylt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rxe=a("code"),xlt=o("pretrained_model_name_or_path"),$lt=o(":"),klt=l(),Pxe=a("ul"),k6=a("li"),Bxe=a("strong"),Slt=o("tapas"),Rlt=o(" \u2014 "),fse=a("a"),Plt=o("TFTapasForQuestionAnswering"),Blt=o(" (TAPAS model)"),Ilt=l(),F(S6.$$.fragment),fno=l(),Xc=a("h2"),R6=a("a"),Ixe=a("span"),F(_P.$$.fragment),Nlt=l(),Nxe=a("span"),qlt=o("TFAutoModelForDocumentQuestionAnswering"),gno=l(),Tr=a("div"),F(bP.$$.fragment),Dlt=l(),zc=a("p"),jlt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),gse=a("a"),Glt=o("from_pretrained()"),Olt=o(" class method or the "),hse=a("a"),Vlt=o("from_config()"),Xlt=o(` class
method.`),zlt=l(),vP=a("p"),Qlt=o("This class cannot be instantiated directly using "),qxe=a("code"),Wlt=o("__init__()"),Ult=o(" (throws an error)."),Hlt=l(),ia=a("div"),F(FP.$$.fragment),Jlt=l(),Dxe=a("p"),Ylt=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Zlt=l(),Qc=a("p"),Klt=o(`Note:
Loading a model from its configuration file does `),jxe=a("strong"),eit=o("not"),oit=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),use=a("a"),rit=o("from_pretrained()"),tit=o(" to load the model weights."),ait=l(),F(P6.$$.fragment),nit=l(),Yr=a("div"),F(TP.$$.fragment),sit=l(),Gxe=a("p"),lit=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),iit=l(),Qn=a("p"),dit=o("The model class to instantiate is selected based on the "),Oxe=a("code"),mit=o("model_type"),cit=o(` property of the config object (either
passed as an argument or loaded from `),Vxe=a("code"),fit=o("pretrained_model_name_or_path"),git=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xxe=a("code"),hit=o("pretrained_model_name_or_path"),uit=o(":"),pit=l(),zxe=a("ul"),B6=a("li"),Qxe=a("strong"),_it=o("layoutlm"),bit=o(" \u2014 "),pse=a("a"),vit=o("TFLayoutLMForQuestionAnswering"),Fit=o(" (LayoutLM model)"),Tit=l(),F(I6.$$.fragment),hno=l(),Wc=a("h2"),N6=a("a"),Wxe=a("span"),F(MP.$$.fragment),Mit=l(),Uxe=a("span"),Eit=o("TFAutoModelForTokenClassification"),uno=l(),Mr=a("div"),F(EP.$$.fragment),Cit=l(),Uc=a("p"),wit=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),_se=a("a"),Ait=o("from_pretrained()"),Lit=o(" class method or the "),bse=a("a"),yit=o("from_config()"),xit=o(` class
method.`),$it=l(),CP=a("p"),kit=o("This class cannot be instantiated directly using "),Hxe=a("code"),Sit=o("__init__()"),Rit=o(" (throws an error)."),Pit=l(),da=a("div"),F(wP.$$.fragment),Bit=l(),Jxe=a("p"),Iit=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Nit=l(),Hc=a("p"),qit=o(`Note:
Loading a model from its configuration file does `),Yxe=a("strong"),Dit=o("not"),jit=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vse=a("a"),Git=o("from_pretrained()"),Oit=o(" to load the model weights."),Vit=l(),F(q6.$$.fragment),Xit=l(),Zr=a("div"),F(AP.$$.fragment),zit=l(),Zxe=a("p"),Qit=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Wit=l(),Wn=a("p"),Uit=o("The model class to instantiate is selected based on the "),Kxe=a("code"),Hit=o("model_type"),Jit=o(` property of the config object (either
passed as an argument or loaded from `),e$e=a("code"),Yit=o("pretrained_model_name_or_path"),Zit=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o$e=a("code"),Kit=o("pretrained_model_name_or_path"),edt=o(":"),odt=l(),ie=a("ul"),D6=a("li"),r$e=a("strong"),rdt=o("albert"),tdt=o(" \u2014 "),Fse=a("a"),adt=o("TFAlbertForTokenClassification"),ndt=o(" (ALBERT model)"),sdt=l(),j6=a("li"),t$e=a("strong"),ldt=o("bert"),idt=o(" \u2014 "),Tse=a("a"),ddt=o("TFBertForTokenClassification"),mdt=o(" (BERT model)"),cdt=l(),G6=a("li"),a$e=a("strong"),fdt=o("camembert"),gdt=o(" \u2014 "),Mse=a("a"),hdt=o("TFCamembertForTokenClassification"),udt=o(" (CamemBERT model)"),pdt=l(),O6=a("li"),n$e=a("strong"),_dt=o("convbert"),bdt=o(" \u2014 "),Ese=a("a"),vdt=o("TFConvBertForTokenClassification"),Fdt=o(" (ConvBERT model)"),Tdt=l(),V6=a("li"),s$e=a("strong"),Mdt=o("deberta"),Edt=o(" \u2014 "),Cse=a("a"),Cdt=o("TFDebertaForTokenClassification"),wdt=o(" (DeBERTa model)"),Adt=l(),X6=a("li"),l$e=a("strong"),Ldt=o("deberta-v2"),ydt=o(" \u2014 "),wse=a("a"),xdt=o("TFDebertaV2ForTokenClassification"),$dt=o(" (DeBERTa-v2 model)"),kdt=l(),z6=a("li"),i$e=a("strong"),Sdt=o("distilbert"),Rdt=o(" \u2014 "),Ase=a("a"),Pdt=o("TFDistilBertForTokenClassification"),Bdt=o(" (DistilBERT model)"),Idt=l(),Q6=a("li"),d$e=a("strong"),Ndt=o("electra"),qdt=o(" \u2014 "),Lse=a("a"),Ddt=o("TFElectraForTokenClassification"),jdt=o(" (ELECTRA model)"),Gdt=l(),W6=a("li"),m$e=a("strong"),Odt=o("esm"),Vdt=o(" \u2014 "),yse=a("a"),Xdt=o("TFEsmForTokenClassification"),zdt=o(" (ESM model)"),Qdt=l(),U6=a("li"),c$e=a("strong"),Wdt=o("flaubert"),Udt=o(" \u2014 "),xse=a("a"),Hdt=o("TFFlaubertForTokenClassification"),Jdt=o(" (FlauBERT model)"),Ydt=l(),H6=a("li"),f$e=a("strong"),Zdt=o("funnel"),Kdt=o(" \u2014 "),$se=a("a"),emt=o("TFFunnelForTokenClassification"),omt=o(" (Funnel Transformer model)"),rmt=l(),J6=a("li"),g$e=a("strong"),tmt=o("layoutlm"),amt=o(" \u2014 "),kse=a("a"),nmt=o("TFLayoutLMForTokenClassification"),smt=o(" (LayoutLM model)"),lmt=l(),Y6=a("li"),h$e=a("strong"),imt=o("layoutlmv3"),dmt=o(" \u2014 "),Sse=a("a"),mmt=o("TFLayoutLMv3ForTokenClassification"),cmt=o(" (LayoutLMv3 model)"),fmt=l(),Z6=a("li"),u$e=a("strong"),gmt=o("longformer"),hmt=o(" \u2014 "),Rse=a("a"),umt=o("TFLongformerForTokenClassification"),pmt=o(" (Longformer model)"),_mt=l(),K6=a("li"),p$e=a("strong"),bmt=o("mobilebert"),vmt=o(" \u2014 "),Pse=a("a"),Fmt=o("TFMobileBertForTokenClassification"),Tmt=o(" (MobileBERT model)"),Mmt=l(),e7=a("li"),_$e=a("strong"),Emt=o("mpnet"),Cmt=o(" \u2014 "),Bse=a("a"),wmt=o("TFMPNetForTokenClassification"),Amt=o(" (MPNet model)"),Lmt=l(),o7=a("li"),b$e=a("strong"),ymt=o("rembert"),xmt=o(" \u2014 "),Ise=a("a"),$mt=o("TFRemBertForTokenClassification"),kmt=o(" (RemBERT model)"),Smt=l(),r7=a("li"),v$e=a("strong"),Rmt=o("roberta"),Pmt=o(" \u2014 "),Nse=a("a"),Bmt=o("TFRobertaForTokenClassification"),Imt=o(" (RoBERTa model)"),Nmt=l(),t7=a("li"),F$e=a("strong"),qmt=o("roformer"),Dmt=o(" \u2014 "),qse=a("a"),jmt=o("TFRoFormerForTokenClassification"),Gmt=o(" (RoFormer model)"),Omt=l(),a7=a("li"),T$e=a("strong"),Vmt=o("xlm"),Xmt=o(" \u2014 "),Dse=a("a"),zmt=o("TFXLMForTokenClassification"),Qmt=o(" (XLM model)"),Wmt=l(),n7=a("li"),M$e=a("strong"),Umt=o("xlm-roberta"),Hmt=o(" \u2014 "),jse=a("a"),Jmt=o("TFXLMRobertaForTokenClassification"),Ymt=o(" (XLM-RoBERTa model)"),Zmt=l(),s7=a("li"),E$e=a("strong"),Kmt=o("xlnet"),ect=o(" \u2014 "),Gse=a("a"),oct=o("TFXLNetForTokenClassification"),rct=o(" (XLNet model)"),tct=l(),F(l7.$$.fragment),pno=l(),Jc=a("h2"),i7=a("a"),C$e=a("span"),F(LP.$$.fragment),act=l(),w$e=a("span"),nct=o("TFAutoModelForQuestionAnswering"),_no=l(),Er=a("div"),F(yP.$$.fragment),sct=l(),Yc=a("p"),lct=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Ose=a("a"),ict=o("from_pretrained()"),dct=o(" class method or the "),Vse=a("a"),mct=o("from_config()"),cct=o(` class
method.`),fct=l(),xP=a("p"),gct=o("This class cannot be instantiated directly using "),A$e=a("code"),hct=o("__init__()"),uct=o(" (throws an error)."),pct=l(),ma=a("div"),F($P.$$.fragment),_ct=l(),L$e=a("p"),bct=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),vct=l(),Zc=a("p"),Fct=o(`Note:
Loading a model from its configuration file does `),y$e=a("strong"),Tct=o("not"),Mct=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Xse=a("a"),Ect=o("from_pretrained()"),Cct=o(" to load the model weights."),wct=l(),F(d7.$$.fragment),Act=l(),Kr=a("div"),F(kP.$$.fragment),Lct=l(),x$e=a("p"),yct=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),xct=l(),Un=a("p"),$ct=o("The model class to instantiate is selected based on the "),$$e=a("code"),kct=o("model_type"),Sct=o(` property of the config object (either
passed as an argument or loaded from `),k$e=a("code"),Rct=o("pretrained_model_name_or_path"),Pct=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S$e=a("code"),Bct=o("pretrained_model_name_or_path"),Ict=o(":"),Nct=l(),fe=a("ul"),m7=a("li"),R$e=a("strong"),qct=o("albert"),Dct=o(" \u2014 "),zse=a("a"),jct=o("TFAlbertForQuestionAnswering"),Gct=o(" (ALBERT model)"),Oct=l(),c7=a("li"),P$e=a("strong"),Vct=o("bert"),Xct=o(" \u2014 "),Qse=a("a"),zct=o("TFBertForQuestionAnswering"),Qct=o(" (BERT model)"),Wct=l(),f7=a("li"),B$e=a("strong"),Uct=o("camembert"),Hct=o(" \u2014 "),Wse=a("a"),Jct=o("TFCamembertForQuestionAnswering"),Yct=o(" (CamemBERT model)"),Zct=l(),g7=a("li"),I$e=a("strong"),Kct=o("convbert"),eft=o(" \u2014 "),Use=a("a"),oft=o("TFConvBertForQuestionAnswering"),rft=o(" (ConvBERT model)"),tft=l(),h7=a("li"),N$e=a("strong"),aft=o("deberta"),nft=o(" \u2014 "),Hse=a("a"),sft=o("TFDebertaForQuestionAnswering"),lft=o(" (DeBERTa model)"),ift=l(),u7=a("li"),q$e=a("strong"),dft=o("deberta-v2"),mft=o(" \u2014 "),Jse=a("a"),cft=o("TFDebertaV2ForQuestionAnswering"),fft=o(" (DeBERTa-v2 model)"),gft=l(),p7=a("li"),D$e=a("strong"),hft=o("distilbert"),uft=o(" \u2014 "),Yse=a("a"),pft=o("TFDistilBertForQuestionAnswering"),_ft=o(" (DistilBERT model)"),bft=l(),_7=a("li"),j$e=a("strong"),vft=o("electra"),Fft=o(" \u2014 "),Zse=a("a"),Tft=o("TFElectraForQuestionAnswering"),Mft=o(" (ELECTRA model)"),Eft=l(),b7=a("li"),G$e=a("strong"),Cft=o("flaubert"),wft=o(" \u2014 "),Kse=a("a"),Aft=o("TFFlaubertForQuestionAnsweringSimple"),Lft=o(" (FlauBERT model)"),yft=l(),v7=a("li"),O$e=a("strong"),xft=o("funnel"),$ft=o(" \u2014 "),ele=a("a"),kft=o("TFFunnelForQuestionAnswering"),Sft=o(" (Funnel Transformer model)"),Rft=l(),F7=a("li"),V$e=a("strong"),Pft=o("gptj"),Bft=o(" \u2014 "),ole=a("a"),Ift=o("TFGPTJForQuestionAnswering"),Nft=o(" (GPT-J model)"),qft=l(),T7=a("li"),X$e=a("strong"),Dft=o("layoutlmv3"),jft=o(" \u2014 "),rle=a("a"),Gft=o("TFLayoutLMv3ForQuestionAnswering"),Oft=o(" (LayoutLMv3 model)"),Vft=l(),M7=a("li"),z$e=a("strong"),Xft=o("longformer"),zft=o(" \u2014 "),tle=a("a"),Qft=o("TFLongformerForQuestionAnswering"),Wft=o(" (Longformer model)"),Uft=l(),E7=a("li"),Q$e=a("strong"),Hft=o("mobilebert"),Jft=o(" \u2014 "),ale=a("a"),Yft=o("TFMobileBertForQuestionAnswering"),Zft=o(" (MobileBERT model)"),Kft=l(),C7=a("li"),W$e=a("strong"),egt=o("mpnet"),ogt=o(" \u2014 "),nle=a("a"),rgt=o("TFMPNetForQuestionAnswering"),tgt=o(" (MPNet model)"),agt=l(),w7=a("li"),U$e=a("strong"),ngt=o("rembert"),sgt=o(" \u2014 "),sle=a("a"),lgt=o("TFRemBertForQuestionAnswering"),igt=o(" (RemBERT model)"),dgt=l(),A7=a("li"),H$e=a("strong"),mgt=o("roberta"),cgt=o(" \u2014 "),lle=a("a"),fgt=o("TFRobertaForQuestionAnswering"),ggt=o(" (RoBERTa model)"),hgt=l(),L7=a("li"),J$e=a("strong"),ugt=o("roformer"),pgt=o(" \u2014 "),ile=a("a"),_gt=o("TFRoFormerForQuestionAnswering"),bgt=o(" (RoFormer model)"),vgt=l(),y7=a("li"),Y$e=a("strong"),Fgt=o("xlm"),Tgt=o(" \u2014 "),dle=a("a"),Mgt=o("TFXLMForQuestionAnsweringSimple"),Egt=o(" (XLM model)"),Cgt=l(),x7=a("li"),Z$e=a("strong"),wgt=o("xlm-roberta"),Agt=o(" \u2014 "),mle=a("a"),Lgt=o("TFXLMRobertaForQuestionAnswering"),ygt=o(" (XLM-RoBERTa model)"),xgt=l(),$7=a("li"),K$e=a("strong"),$gt=o("xlnet"),kgt=o(" \u2014 "),cle=a("a"),Sgt=o("TFXLNetForQuestionAnsweringSimple"),Rgt=o(" (XLNet model)"),Pgt=l(),F(k7.$$.fragment),bno=l(),Kc=a("h2"),S7=a("a"),eke=a("span"),F(SP.$$.fragment),Bgt=l(),oke=a("span"),Igt=o("TFAutoModelForVision2Seq"),vno=l(),Cr=a("div"),F(RP.$$.fragment),Ngt=l(),ef=a("p"),qgt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),fle=a("a"),Dgt=o("from_pretrained()"),jgt=o(" class method or the "),gle=a("a"),Ggt=o("from_config()"),Ogt=o(` class
method.`),Vgt=l(),PP=a("p"),Xgt=o("This class cannot be instantiated directly using "),rke=a("code"),zgt=o("__init__()"),Qgt=o(" (throws an error)."),Wgt=l(),ca=a("div"),F(BP.$$.fragment),Ugt=l(),tke=a("p"),Hgt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Jgt=l(),of=a("p"),Ygt=o(`Note:
Loading a model from its configuration file does `),ake=a("strong"),Zgt=o("not"),Kgt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hle=a("a"),eht=o("from_pretrained()"),oht=o(" to load the model weights."),rht=l(),F(R7.$$.fragment),tht=l(),et=a("div"),F(IP.$$.fragment),aht=l(),nke=a("p"),nht=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),sht=l(),Hn=a("p"),lht=o("The model class to instantiate is selected based on the "),ske=a("code"),iht=o("model_type"),dht=o(` property of the config object (either
passed as an argument or loaded from `),lke=a("code"),mht=o("pretrained_model_name_or_path"),cht=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ike=a("code"),fht=o("pretrained_model_name_or_path"),ght=o(":"),hht=l(),dke=a("ul"),P7=a("li"),mke=a("strong"),uht=o("vision-encoder-decoder"),pht=o(" \u2014 "),ule=a("a"),_ht=o("TFVisionEncoderDecoderModel"),bht=o(" (Vision Encoder decoder model)"),vht=l(),F(B7.$$.fragment),Fno=l(),rf=a("h2"),I7=a("a"),cke=a("span"),F(NP.$$.fragment),Fht=l(),fke=a("span"),Tht=o("TFAutoModelForSpeechSeq2Seq"),Tno=l(),wr=a("div"),F(qP.$$.fragment),Mht=l(),tf=a("p"),Eht=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),ple=a("a"),Cht=o("from_pretrained()"),wht=o(" class method or the "),_le=a("a"),Aht=o("from_config()"),Lht=o(` class
method.`),yht=l(),DP=a("p"),xht=o("This class cannot be instantiated directly using "),gke=a("code"),$ht=o("__init__()"),kht=o(" (throws an error)."),Sht=l(),fa=a("div"),F(jP.$$.fragment),Rht=l(),hke=a("p"),Pht=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Bht=l(),af=a("p"),Iht=o(`Note:
Loading a model from its configuration file does `),uke=a("strong"),Nht=o("not"),qht=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ble=a("a"),Dht=o("from_pretrained()"),jht=o(" to load the model weights."),Ght=l(),F(N7.$$.fragment),Oht=l(),ot=a("div"),F(GP.$$.fragment),Vht=l(),pke=a("p"),Xht=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),zht=l(),Jn=a("p"),Qht=o("The model class to instantiate is selected based on the "),_ke=a("code"),Wht=o("model_type"),Uht=o(` property of the config object (either
passed as an argument or loaded from `),bke=a("code"),Hht=o("pretrained_model_name_or_path"),Jht=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vke=a("code"),Yht=o("pretrained_model_name_or_path"),Zht=o(":"),Kht=l(),OP=a("ul"),q7=a("li"),Fke=a("strong"),eut=o("speech_to_text"),out=o(" \u2014 "),vle=a("a"),rut=o("TFSpeech2TextForConditionalGeneration"),tut=o(" (Speech2Text model)"),aut=l(),D7=a("li"),Tke=a("strong"),nut=o("whisper"),sut=o(" \u2014 "),Fle=a("a"),lut=o("TFWhisperForConditionalGeneration"),iut=o(" (Whisper model)"),dut=l(),F(j7.$$.fragment),Mno=l(),nf=a("h2"),G7=a("a"),Mke=a("span"),F(VP.$$.fragment),mut=l(),Eke=a("span"),cut=o("FlaxAutoModel"),Eno=l(),Ar=a("div"),F(XP.$$.fragment),fut=l(),sf=a("p"),gut=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Tle=a("a"),hut=o("from_pretrained()"),uut=o(" class method or the "),Mle=a("a"),put=o("from_config()"),_ut=o(` class
method.`),but=l(),zP=a("p"),vut=o("This class cannot be instantiated directly using "),Cke=a("code"),Fut=o("__init__()"),Tut=o(" (throws an error)."),Mut=l(),ga=a("div"),F(QP.$$.fragment),Eut=l(),wke=a("p"),Cut=o("Instantiates one of the base model classes of the library from a configuration."),wut=l(),lf=a("p"),Aut=o(`Note:
Loading a model from its configuration file does `),Ake=a("strong"),Lut=o("not"),yut=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ele=a("a"),xut=o("from_pretrained()"),$ut=o(" to load the model weights."),kut=l(),F(O7.$$.fragment),Sut=l(),rt=a("div"),F(WP.$$.fragment),Rut=l(),Lke=a("p"),Put=o("Instantiate one of the base model classes of the library from a pretrained model."),But=l(),Yn=a("p"),Iut=o("The model class to instantiate is selected based on the "),yke=a("code"),Nut=o("model_type"),qut=o(` property of the config object (either
passed as an argument or loaded from `),xke=a("code"),Dut=o("pretrained_model_name_or_path"),jut=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$ke=a("code"),Gut=o("pretrained_model_name_or_path"),Out=o(":"),Vut=l(),te=a("ul"),V7=a("li"),kke=a("strong"),Xut=o("albert"),zut=o(" \u2014 "),Cle=a("a"),Qut=o("FlaxAlbertModel"),Wut=o(" (ALBERT model)"),Uut=l(),X7=a("li"),Ske=a("strong"),Hut=o("bart"),Jut=o(" \u2014 "),wle=a("a"),Yut=o("FlaxBartModel"),Zut=o(" (BART model)"),Kut=l(),z7=a("li"),Rke=a("strong"),ept=o("beit"),opt=o(" \u2014 "),Ale=a("a"),rpt=o("FlaxBeitModel"),tpt=o(" (BEiT model)"),apt=l(),Q7=a("li"),Pke=a("strong"),npt=o("bert"),spt=o(" \u2014 "),Lle=a("a"),lpt=o("FlaxBertModel"),ipt=o(" (BERT model)"),dpt=l(),W7=a("li"),Bke=a("strong"),mpt=o("big_bird"),cpt=o(" \u2014 "),yle=a("a"),fpt=o("FlaxBigBirdModel"),gpt=o(" (BigBird model)"),hpt=l(),U7=a("li"),Ike=a("strong"),upt=o("blenderbot"),ppt=o(" \u2014 "),xle=a("a"),_pt=o("FlaxBlenderbotModel"),bpt=o(" (Blenderbot model)"),vpt=l(),H7=a("li"),Nke=a("strong"),Fpt=o("blenderbot-small"),Tpt=o(" \u2014 "),$le=a("a"),Mpt=o("FlaxBlenderbotSmallModel"),Ept=o(" (BlenderbotSmall model)"),Cpt=l(),J7=a("li"),qke=a("strong"),wpt=o("clip"),Apt=o(" \u2014 "),kle=a("a"),Lpt=o("FlaxCLIPModel"),ypt=o(" (CLIP model)"),xpt=l(),Y7=a("li"),Dke=a("strong"),$pt=o("distilbert"),kpt=o(" \u2014 "),Sle=a("a"),Spt=o("FlaxDistilBertModel"),Rpt=o(" (DistilBERT model)"),Ppt=l(),Z7=a("li"),jke=a("strong"),Bpt=o("electra"),Ipt=o(" \u2014 "),Rle=a("a"),Npt=o("FlaxElectraModel"),qpt=o(" (ELECTRA model)"),Dpt=l(),K7=a("li"),Gke=a("strong"),jpt=o("gpt2"),Gpt=o(" \u2014 "),Ple=a("a"),Opt=o("FlaxGPT2Model"),Vpt=o(" (OpenAI GPT-2 model)"),Xpt=l(),e8=a("li"),Oke=a("strong"),zpt=o("gpt_neo"),Qpt=o(" \u2014 "),Ble=a("a"),Wpt=o("FlaxGPTNeoModel"),Upt=o(" (GPT Neo model)"),Hpt=l(),o8=a("li"),Vke=a("strong"),Jpt=o("gptj"),Ypt=o(" \u2014 "),Ile=a("a"),Zpt=o("FlaxGPTJModel"),Kpt=o(" (GPT-J model)"),e_t=l(),r8=a("li"),Xke=a("strong"),o_t=o("longt5"),r_t=o(" \u2014 "),Nle=a("a"),t_t=o("FlaxLongT5Model"),a_t=o(" (LongT5 model)"),n_t=l(),t8=a("li"),zke=a("strong"),s_t=o("marian"),l_t=o(" \u2014 "),qle=a("a"),i_t=o("FlaxMarianModel"),d_t=o(" (Marian model)"),m_t=l(),a8=a("li"),Qke=a("strong"),c_t=o("mbart"),f_t=o(" \u2014 "),Dle=a("a"),g_t=o("FlaxMBartModel"),h_t=o(" (mBART model)"),u_t=l(),n8=a("li"),Wke=a("strong"),p_t=o("mt5"),__t=o(" \u2014 "),jle=a("a"),b_t=o("FlaxMT5Model"),v_t=o(" (MT5 model)"),F_t=l(),s8=a("li"),Uke=a("strong"),T_t=o("opt"),M_t=o(" \u2014 "),Gle=a("a"),E_t=o("FlaxOPTModel"),C_t=o(" (OPT model)"),w_t=l(),l8=a("li"),Hke=a("strong"),A_t=o("pegasus"),L_t=o(" \u2014 "),Ole=a("a"),y_t=o("FlaxPegasusModel"),x_t=o(" (Pegasus model)"),$_t=l(),i8=a("li"),Jke=a("strong"),k_t=o("roberta"),S_t=o(" \u2014 "),Vle=a("a"),R_t=o("FlaxRobertaModel"),P_t=o(" (RoBERTa model)"),B_t=l(),d8=a("li"),Yke=a("strong"),I_t=o("roformer"),N_t=o(" \u2014 "),Xle=a("a"),q_t=o("FlaxRoFormerModel"),D_t=o(" (RoFormer model)"),j_t=l(),m8=a("li"),Zke=a("strong"),G_t=o("t5"),O_t=o(" \u2014 "),zle=a("a"),V_t=o("FlaxT5Model"),X_t=o(" (T5 model)"),z_t=l(),c8=a("li"),Kke=a("strong"),Q_t=o("vision-text-dual-encoder"),W_t=o(" \u2014 "),Qle=a("a"),U_t=o("FlaxVisionTextDualEncoderModel"),H_t=o(" (VisionTextDualEncoder model)"),J_t=l(),f8=a("li"),eSe=a("strong"),Y_t=o("vit"),Z_t=o(" \u2014 "),Wle=a("a"),K_t=o("FlaxViTModel"),e1t=o(" (ViT model)"),o1t=l(),g8=a("li"),oSe=a("strong"),r1t=o("wav2vec2"),t1t=o(" \u2014 "),Ule=a("a"),a1t=o("FlaxWav2Vec2Model"),n1t=o(" (Wav2Vec2 model)"),s1t=l(),h8=a("li"),rSe=a("strong"),l1t=o("xglm"),i1t=o(" \u2014 "),Hle=a("a"),d1t=o("FlaxXGLMModel"),m1t=o(" (XGLM model)"),c1t=l(),u8=a("li"),tSe=a("strong"),f1t=o("xlm-roberta"),g1t=o(" \u2014 "),Jle=a("a"),h1t=o("FlaxXLMRobertaModel"),u1t=o(" (XLM-RoBERTa model)"),p1t=l(),F(p8.$$.fragment),Cno=l(),df=a("h2"),_8=a("a"),aSe=a("span"),F(UP.$$.fragment),_1t=l(),nSe=a("span"),b1t=o("FlaxAutoModelForCausalLM"),wno=l(),Lr=a("div"),F(HP.$$.fragment),v1t=l(),mf=a("p"),F1t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Yle=a("a"),T1t=o("from_pretrained()"),M1t=o(" class method or the "),Zle=a("a"),E1t=o("from_config()"),C1t=o(` class
method.`),w1t=l(),JP=a("p"),A1t=o("This class cannot be instantiated directly using "),sSe=a("code"),L1t=o("__init__()"),y1t=o(" (throws an error)."),x1t=l(),ha=a("div"),F(YP.$$.fragment),$1t=l(),lSe=a("p"),k1t=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),S1t=l(),cf=a("p"),R1t=o(`Note:
Loading a model from its configuration file does `),iSe=a("strong"),P1t=o("not"),B1t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Kle=a("a"),I1t=o("from_pretrained()"),N1t=o(" to load the model weights."),q1t=l(),F(b8.$$.fragment),D1t=l(),tt=a("div"),F(ZP.$$.fragment),j1t=l(),dSe=a("p"),G1t=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),O1t=l(),Zn=a("p"),V1t=o("The model class to instantiate is selected based on the "),mSe=a("code"),X1t=o("model_type"),z1t=o(` property of the config object (either
passed as an argument or loaded from `),cSe=a("code"),Q1t=o("pretrained_model_name_or_path"),W1t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fSe=a("code"),U1t=o("pretrained_model_name_or_path"),H1t=o(":"),J1t=l(),$e=a("ul"),v8=a("li"),gSe=a("strong"),Y1t=o("bart"),Z1t=o(" \u2014 "),eie=a("a"),K1t=o("FlaxBartForCausalLM"),e2t=o(" (BART model)"),o2t=l(),F8=a("li"),hSe=a("strong"),r2t=o("bert"),t2t=o(" \u2014 "),oie=a("a"),a2t=o("FlaxBertForCausalLM"),n2t=o(" (BERT model)"),s2t=l(),T8=a("li"),uSe=a("strong"),l2t=o("big_bird"),i2t=o(" \u2014 "),rie=a("a"),d2t=o("FlaxBigBirdForCausalLM"),m2t=o(" (BigBird model)"),c2t=l(),M8=a("li"),pSe=a("strong"),f2t=o("electra"),g2t=o(" \u2014 "),tie=a("a"),h2t=o("FlaxElectraForCausalLM"),u2t=o(" (ELECTRA model)"),p2t=l(),E8=a("li"),_Se=a("strong"),_2t=o("gpt2"),b2t=o(" \u2014 "),aie=a("a"),v2t=o("FlaxGPT2LMHeadModel"),F2t=o(" (OpenAI GPT-2 model)"),T2t=l(),C8=a("li"),bSe=a("strong"),M2t=o("gpt_neo"),E2t=o(" \u2014 "),nie=a("a"),C2t=o("FlaxGPTNeoForCausalLM"),w2t=o(" (GPT Neo model)"),A2t=l(),w8=a("li"),vSe=a("strong"),L2t=o("gptj"),y2t=o(" \u2014 "),sie=a("a"),x2t=o("FlaxGPTJForCausalLM"),$2t=o(" (GPT-J model)"),k2t=l(),A8=a("li"),FSe=a("strong"),S2t=o("opt"),R2t=o(" \u2014 "),lie=a("a"),P2t=o("FlaxOPTForCausalLM"),B2t=o(" (OPT model)"),I2t=l(),L8=a("li"),TSe=a("strong"),N2t=o("roberta"),q2t=o(" \u2014 "),iie=a("a"),D2t=o("FlaxRobertaForCausalLM"),j2t=o(" (RoBERTa model)"),G2t=l(),y8=a("li"),MSe=a("strong"),O2t=o("xglm"),V2t=o(" \u2014 "),die=a("a"),X2t=o("FlaxXGLMForCausalLM"),z2t=o(" (XGLM model)"),Q2t=l(),F(x8.$$.fragment),Ano=l(),ff=a("h2"),$8=a("a"),ESe=a("span"),F(KP.$$.fragment),W2t=l(),CSe=a("span"),U2t=o("FlaxAutoModelForPreTraining"),Lno=l(),yr=a("div"),F(eB.$$.fragment),H2t=l(),gf=a("p"),J2t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),mie=a("a"),Y2t=o("from_pretrained()"),Z2t=o(" class method or the "),cie=a("a"),K2t=o("from_config()"),ebt=o(` class
method.`),obt=l(),oB=a("p"),rbt=o("This class cannot be instantiated directly using "),wSe=a("code"),tbt=o("__init__()"),abt=o(" (throws an error)."),nbt=l(),ua=a("div"),F(rB.$$.fragment),sbt=l(),ASe=a("p"),lbt=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),ibt=l(),hf=a("p"),dbt=o(`Note:
Loading a model from its configuration file does `),LSe=a("strong"),mbt=o("not"),cbt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fie=a("a"),fbt=o("from_pretrained()"),gbt=o(" to load the model weights."),hbt=l(),F(k8.$$.fragment),ubt=l(),at=a("div"),F(tB.$$.fragment),pbt=l(),ySe=a("p"),_bt=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),bbt=l(),Kn=a("p"),vbt=o("The model class to instantiate is selected based on the "),xSe=a("code"),Fbt=o("model_type"),Tbt=o(` property of the config object (either
passed as an argument or loaded from `),$Se=a("code"),Mbt=o("pretrained_model_name_or_path"),Ebt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kSe=a("code"),Cbt=o("pretrained_model_name_or_path"),wbt=o(":"),Abt=l(),Ee=a("ul"),S8=a("li"),SSe=a("strong"),Lbt=o("albert"),ybt=o(" \u2014 "),gie=a("a"),xbt=o("FlaxAlbertForPreTraining"),$bt=o(" (ALBERT model)"),kbt=l(),R8=a("li"),RSe=a("strong"),Sbt=o("bart"),Rbt=o(" \u2014 "),hie=a("a"),Pbt=o("FlaxBartForConditionalGeneration"),Bbt=o(" (BART model)"),Ibt=l(),P8=a("li"),PSe=a("strong"),Nbt=o("bert"),qbt=o(" \u2014 "),uie=a("a"),Dbt=o("FlaxBertForPreTraining"),jbt=o(" (BERT model)"),Gbt=l(),B8=a("li"),BSe=a("strong"),Obt=o("big_bird"),Vbt=o(" \u2014 "),pie=a("a"),Xbt=o("FlaxBigBirdForPreTraining"),zbt=o(" (BigBird model)"),Qbt=l(),I8=a("li"),ISe=a("strong"),Wbt=o("electra"),Ubt=o(" \u2014 "),_ie=a("a"),Hbt=o("FlaxElectraForPreTraining"),Jbt=o(" (ELECTRA model)"),Ybt=l(),N8=a("li"),NSe=a("strong"),Zbt=o("longt5"),Kbt=o(" \u2014 "),bie=a("a"),evt=o("FlaxLongT5ForConditionalGeneration"),ovt=o(" (LongT5 model)"),rvt=l(),q8=a("li"),qSe=a("strong"),tvt=o("mbart"),avt=o(" \u2014 "),vie=a("a"),nvt=o("FlaxMBartForConditionalGeneration"),svt=o(" (mBART model)"),lvt=l(),D8=a("li"),DSe=a("strong"),ivt=o("mt5"),dvt=o(" \u2014 "),Fie=a("a"),mvt=o("FlaxMT5ForConditionalGeneration"),cvt=o(" (MT5 model)"),fvt=l(),j8=a("li"),jSe=a("strong"),gvt=o("roberta"),hvt=o(" \u2014 "),Tie=a("a"),uvt=o("FlaxRobertaForMaskedLM"),pvt=o(" (RoBERTa model)"),_vt=l(),G8=a("li"),GSe=a("strong"),bvt=o("roformer"),vvt=o(" \u2014 "),Mie=a("a"),Fvt=o("FlaxRoFormerForMaskedLM"),Tvt=o(" (RoFormer model)"),Mvt=l(),O8=a("li"),OSe=a("strong"),Evt=o("t5"),Cvt=o(" \u2014 "),Eie=a("a"),wvt=o("FlaxT5ForConditionalGeneration"),Avt=o(" (T5 model)"),Lvt=l(),V8=a("li"),VSe=a("strong"),yvt=o("wav2vec2"),xvt=o(" \u2014 "),Cie=a("a"),$vt=o("FlaxWav2Vec2ForPreTraining"),kvt=o(" (Wav2Vec2 model)"),Svt=l(),X8=a("li"),XSe=a("strong"),Rvt=o("xlm-roberta"),Pvt=o(" \u2014 "),wie=a("a"),Bvt=o("FlaxXLMRobertaForMaskedLM"),Ivt=o(" (XLM-RoBERTa model)"),Nvt=l(),F(z8.$$.fragment),yno=l(),uf=a("h2"),Q8=a("a"),zSe=a("span"),F(aB.$$.fragment),qvt=l(),QSe=a("span"),Dvt=o("FlaxAutoModelForMaskedLM"),xno=l(),xr=a("div"),F(nB.$$.fragment),jvt=l(),pf=a("p"),Gvt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Aie=a("a"),Ovt=o("from_pretrained()"),Vvt=o(" class method or the "),Lie=a("a"),Xvt=o("from_config()"),zvt=o(` class
method.`),Qvt=l(),sB=a("p"),Wvt=o("This class cannot be instantiated directly using "),WSe=a("code"),Uvt=o("__init__()"),Hvt=o(" (throws an error)."),Jvt=l(),pa=a("div"),F(lB.$$.fragment),Yvt=l(),USe=a("p"),Zvt=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Kvt=l(),_f=a("p"),eFt=o(`Note:
Loading a model from its configuration file does `),HSe=a("strong"),oFt=o("not"),rFt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yie=a("a"),tFt=o("from_pretrained()"),aFt=o(" to load the model weights."),nFt=l(),F(W8.$$.fragment),sFt=l(),nt=a("div"),F(iB.$$.fragment),lFt=l(),JSe=a("p"),iFt=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),dFt=l(),es=a("p"),mFt=o("The model class to instantiate is selected based on the "),YSe=a("code"),cFt=o("model_type"),fFt=o(` property of the config object (either
passed as an argument or loaded from `),ZSe=a("code"),gFt=o("pretrained_model_name_or_path"),hFt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KSe=a("code"),uFt=o("pretrained_model_name_or_path"),pFt=o(":"),_Ft=l(),ke=a("ul"),U8=a("li"),eRe=a("strong"),bFt=o("albert"),vFt=o(" \u2014 "),xie=a("a"),FFt=o("FlaxAlbertForMaskedLM"),TFt=o(" (ALBERT model)"),MFt=l(),H8=a("li"),oRe=a("strong"),EFt=o("bart"),CFt=o(" \u2014 "),$ie=a("a"),wFt=o("FlaxBartForConditionalGeneration"),AFt=o(" (BART model)"),LFt=l(),J8=a("li"),rRe=a("strong"),yFt=o("bert"),xFt=o(" \u2014 "),kie=a("a"),$Ft=o("FlaxBertForMaskedLM"),kFt=o(" (BERT model)"),SFt=l(),Y8=a("li"),tRe=a("strong"),RFt=o("big_bird"),PFt=o(" \u2014 "),Sie=a("a"),BFt=o("FlaxBigBirdForMaskedLM"),IFt=o(" (BigBird model)"),NFt=l(),Z8=a("li"),aRe=a("strong"),qFt=o("distilbert"),DFt=o(" \u2014 "),Rie=a("a"),jFt=o("FlaxDistilBertForMaskedLM"),GFt=o(" (DistilBERT model)"),OFt=l(),K8=a("li"),nRe=a("strong"),VFt=o("electra"),XFt=o(" \u2014 "),Pie=a("a"),zFt=o("FlaxElectraForMaskedLM"),QFt=o(" (ELECTRA model)"),WFt=l(),eL=a("li"),sRe=a("strong"),UFt=o("mbart"),HFt=o(" \u2014 "),Bie=a("a"),JFt=o("FlaxMBartForConditionalGeneration"),YFt=o(" (mBART model)"),ZFt=l(),oL=a("li"),lRe=a("strong"),KFt=o("roberta"),eTt=o(" \u2014 "),Iie=a("a"),oTt=o("FlaxRobertaForMaskedLM"),rTt=o(" (RoBERTa model)"),tTt=l(),rL=a("li"),iRe=a("strong"),aTt=o("roformer"),nTt=o(" \u2014 "),Nie=a("a"),sTt=o("FlaxRoFormerForMaskedLM"),lTt=o(" (RoFormer model)"),iTt=l(),tL=a("li"),dRe=a("strong"),dTt=o("xlm-roberta"),mTt=o(" \u2014 "),qie=a("a"),cTt=o("FlaxXLMRobertaForMaskedLM"),fTt=o(" (XLM-RoBERTa model)"),gTt=l(),F(aL.$$.fragment),$no=l(),bf=a("h2"),nL=a("a"),mRe=a("span"),F(dB.$$.fragment),hTt=l(),cRe=a("span"),uTt=o("FlaxAutoModelForSeq2SeqLM"),kno=l(),$r=a("div"),F(mB.$$.fragment),pTt=l(),vf=a("p"),_Tt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Die=a("a"),bTt=o("from_pretrained()"),vTt=o(" class method or the "),jie=a("a"),FTt=o("from_config()"),TTt=o(` class
method.`),MTt=l(),cB=a("p"),ETt=o("This class cannot be instantiated directly using "),fRe=a("code"),CTt=o("__init__()"),wTt=o(" (throws an error)."),ATt=l(),_a=a("div"),F(fB.$$.fragment),LTt=l(),gRe=a("p"),yTt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),xTt=l(),Ff=a("p"),$Tt=o(`Note:
Loading a model from its configuration file does `),hRe=a("strong"),kTt=o("not"),STt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Gie=a("a"),RTt=o("from_pretrained()"),PTt=o(" to load the model weights."),BTt=l(),F(sL.$$.fragment),ITt=l(),st=a("div"),F(gB.$$.fragment),NTt=l(),uRe=a("p"),qTt=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),DTt=l(),os=a("p"),jTt=o("The model class to instantiate is selected based on the "),pRe=a("code"),GTt=o("model_type"),OTt=o(` property of the config object (either
passed as an argument or loaded from `),_Re=a("code"),VTt=o("pretrained_model_name_or_path"),XTt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bRe=a("code"),zTt=o("pretrained_model_name_or_path"),QTt=o(":"),WTt=l(),Se=a("ul"),lL=a("li"),vRe=a("strong"),UTt=o("bart"),HTt=o(" \u2014 "),Oie=a("a"),JTt=o("FlaxBartForConditionalGeneration"),YTt=o(" (BART model)"),ZTt=l(),iL=a("li"),FRe=a("strong"),KTt=o("blenderbot"),eMt=o(" \u2014 "),Vie=a("a"),oMt=o("FlaxBlenderbotForConditionalGeneration"),rMt=o(" (Blenderbot model)"),tMt=l(),dL=a("li"),TRe=a("strong"),aMt=o("blenderbot-small"),nMt=o(" \u2014 "),Xie=a("a"),sMt=o("FlaxBlenderbotSmallForConditionalGeneration"),lMt=o(" (BlenderbotSmall model)"),iMt=l(),mL=a("li"),MRe=a("strong"),dMt=o("encoder-decoder"),mMt=o(" \u2014 "),zie=a("a"),cMt=o("FlaxEncoderDecoderModel"),fMt=o(" (Encoder decoder model)"),gMt=l(),cL=a("li"),ERe=a("strong"),hMt=o("longt5"),uMt=o(" \u2014 "),Qie=a("a"),pMt=o("FlaxLongT5ForConditionalGeneration"),_Mt=o(" (LongT5 model)"),bMt=l(),fL=a("li"),CRe=a("strong"),vMt=o("marian"),FMt=o(" \u2014 "),Wie=a("a"),TMt=o("FlaxMarianMTModel"),MMt=o(" (Marian model)"),EMt=l(),gL=a("li"),wRe=a("strong"),CMt=o("mbart"),wMt=o(" \u2014 "),Uie=a("a"),AMt=o("FlaxMBartForConditionalGeneration"),LMt=o(" (mBART model)"),yMt=l(),hL=a("li"),ARe=a("strong"),xMt=o("mt5"),$Mt=o(" \u2014 "),Hie=a("a"),kMt=o("FlaxMT5ForConditionalGeneration"),SMt=o(" (MT5 model)"),RMt=l(),uL=a("li"),LRe=a("strong"),PMt=o("pegasus"),BMt=o(" \u2014 "),Jie=a("a"),IMt=o("FlaxPegasusForConditionalGeneration"),NMt=o(" (Pegasus model)"),qMt=l(),pL=a("li"),yRe=a("strong"),DMt=o("t5"),jMt=o(" \u2014 "),Yie=a("a"),GMt=o("FlaxT5ForConditionalGeneration"),OMt=o(" (T5 model)"),VMt=l(),F(_L.$$.fragment),Sno=l(),Tf=a("h2"),bL=a("a"),xRe=a("span"),F(hB.$$.fragment),XMt=l(),$Re=a("span"),zMt=o("FlaxAutoModelForSequenceClassification"),Rno=l(),kr=a("div"),F(uB.$$.fragment),QMt=l(),Mf=a("p"),WMt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Zie=a("a"),UMt=o("from_pretrained()"),HMt=o(" class method or the "),Kie=a("a"),JMt=o("from_config()"),YMt=o(` class
method.`),ZMt=l(),pB=a("p"),KMt=o("This class cannot be instantiated directly using "),kRe=a("code"),eEt=o("__init__()"),oEt=o(" (throws an error)."),rEt=l(),ba=a("div"),F(_B.$$.fragment),tEt=l(),SRe=a("p"),aEt=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),nEt=l(),Ef=a("p"),sEt=o(`Note:
Loading a model from its configuration file does `),RRe=a("strong"),lEt=o("not"),iEt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ede=a("a"),dEt=o("from_pretrained()"),mEt=o(" to load the model weights."),cEt=l(),F(vL.$$.fragment),fEt=l(),lt=a("div"),F(bB.$$.fragment),gEt=l(),PRe=a("p"),hEt=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),uEt=l(),rs=a("p"),pEt=o("The model class to instantiate is selected based on the "),BRe=a("code"),_Et=o("model_type"),bEt=o(` property of the config object (either
passed as an argument or loaded from `),IRe=a("code"),vEt=o("pretrained_model_name_or_path"),FEt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NRe=a("code"),TEt=o("pretrained_model_name_or_path"),MEt=o(":"),EEt=l(),Re=a("ul"),FL=a("li"),qRe=a("strong"),CEt=o("albert"),wEt=o(" \u2014 "),ode=a("a"),AEt=o("FlaxAlbertForSequenceClassification"),LEt=o(" (ALBERT model)"),yEt=l(),TL=a("li"),DRe=a("strong"),xEt=o("bart"),$Et=o(" \u2014 "),rde=a("a"),kEt=o("FlaxBartForSequenceClassification"),SEt=o(" (BART model)"),REt=l(),ML=a("li"),jRe=a("strong"),PEt=o("bert"),BEt=o(" \u2014 "),tde=a("a"),IEt=o("FlaxBertForSequenceClassification"),NEt=o(" (BERT model)"),qEt=l(),EL=a("li"),GRe=a("strong"),DEt=o("big_bird"),jEt=o(" \u2014 "),ade=a("a"),GEt=o("FlaxBigBirdForSequenceClassification"),OEt=o(" (BigBird model)"),VEt=l(),CL=a("li"),ORe=a("strong"),XEt=o("distilbert"),zEt=o(" \u2014 "),nde=a("a"),QEt=o("FlaxDistilBertForSequenceClassification"),WEt=o(" (DistilBERT model)"),UEt=l(),wL=a("li"),VRe=a("strong"),HEt=o("electra"),JEt=o(" \u2014 "),sde=a("a"),YEt=o("FlaxElectraForSequenceClassification"),ZEt=o(" (ELECTRA model)"),KEt=l(),AL=a("li"),XRe=a("strong"),e4t=o("mbart"),o4t=o(" \u2014 "),lde=a("a"),r4t=o("FlaxMBartForSequenceClassification"),t4t=o(" (mBART model)"),a4t=l(),LL=a("li"),zRe=a("strong"),n4t=o("roberta"),s4t=o(" \u2014 "),ide=a("a"),l4t=o("FlaxRobertaForSequenceClassification"),i4t=o(" (RoBERTa model)"),d4t=l(),yL=a("li"),QRe=a("strong"),m4t=o("roformer"),c4t=o(" \u2014 "),dde=a("a"),f4t=o("FlaxRoFormerForSequenceClassification"),g4t=o(" (RoFormer model)"),h4t=l(),xL=a("li"),WRe=a("strong"),u4t=o("xlm-roberta"),p4t=o(" \u2014 "),mde=a("a"),_4t=o("FlaxXLMRobertaForSequenceClassification"),b4t=o(" (XLM-RoBERTa model)"),v4t=l(),F($L.$$.fragment),Pno=l(),Cf=a("h2"),kL=a("a"),URe=a("span"),F(vB.$$.fragment),F4t=l(),HRe=a("span"),T4t=o("FlaxAutoModelForQuestionAnswering"),Bno=l(),Sr=a("div"),F(FB.$$.fragment),M4t=l(),wf=a("p"),E4t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),cde=a("a"),C4t=o("from_pretrained()"),w4t=o(" class method or the "),fde=a("a"),A4t=o("from_config()"),L4t=o(` class
method.`),y4t=l(),TB=a("p"),x4t=o("This class cannot be instantiated directly using "),JRe=a("code"),$4t=o("__init__()"),k4t=o(" (throws an error)."),S4t=l(),va=a("div"),F(MB.$$.fragment),R4t=l(),YRe=a("p"),P4t=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),B4t=l(),Af=a("p"),I4t=o(`Note:
Loading a model from its configuration file does `),ZRe=a("strong"),N4t=o("not"),q4t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gde=a("a"),D4t=o("from_pretrained()"),j4t=o(" to load the model weights."),G4t=l(),F(SL.$$.fragment),O4t=l(),it=a("div"),F(EB.$$.fragment),V4t=l(),KRe=a("p"),X4t=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),z4t=l(),ts=a("p"),Q4t=o("The model class to instantiate is selected based on the "),ePe=a("code"),W4t=o("model_type"),U4t=o(` property of the config object (either
passed as an argument or loaded from `),oPe=a("code"),H4t=o("pretrained_model_name_or_path"),J4t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rPe=a("code"),Y4t=o("pretrained_model_name_or_path"),Z4t=o(":"),K4t=l(),Pe=a("ul"),RL=a("li"),tPe=a("strong"),eCt=o("albert"),oCt=o(" \u2014 "),hde=a("a"),rCt=o("FlaxAlbertForQuestionAnswering"),tCt=o(" (ALBERT model)"),aCt=l(),PL=a("li"),aPe=a("strong"),nCt=o("bart"),sCt=o(" \u2014 "),ude=a("a"),lCt=o("FlaxBartForQuestionAnswering"),iCt=o(" (BART model)"),dCt=l(),BL=a("li"),nPe=a("strong"),mCt=o("bert"),cCt=o(" \u2014 "),pde=a("a"),fCt=o("FlaxBertForQuestionAnswering"),gCt=o(" (BERT model)"),hCt=l(),IL=a("li"),sPe=a("strong"),uCt=o("big_bird"),pCt=o(" \u2014 "),_de=a("a"),_Ct=o("FlaxBigBirdForQuestionAnswering"),bCt=o(" (BigBird model)"),vCt=l(),NL=a("li"),lPe=a("strong"),FCt=o("distilbert"),TCt=o(" \u2014 "),bde=a("a"),MCt=o("FlaxDistilBertForQuestionAnswering"),ECt=o(" (DistilBERT model)"),CCt=l(),qL=a("li"),iPe=a("strong"),wCt=o("electra"),ACt=o(" \u2014 "),vde=a("a"),LCt=o("FlaxElectraForQuestionAnswering"),yCt=o(" (ELECTRA model)"),xCt=l(),DL=a("li"),dPe=a("strong"),$Ct=o("mbart"),kCt=o(" \u2014 "),Fde=a("a"),SCt=o("FlaxMBartForQuestionAnswering"),RCt=o(" (mBART model)"),PCt=l(),jL=a("li"),mPe=a("strong"),BCt=o("roberta"),ICt=o(" \u2014 "),Tde=a("a"),NCt=o("FlaxRobertaForQuestionAnswering"),qCt=o(" (RoBERTa model)"),DCt=l(),GL=a("li"),cPe=a("strong"),jCt=o("roformer"),GCt=o(" \u2014 "),Mde=a("a"),OCt=o("FlaxRoFormerForQuestionAnswering"),VCt=o(" (RoFormer model)"),XCt=l(),OL=a("li"),fPe=a("strong"),zCt=o("xlm-roberta"),QCt=o(" \u2014 "),Ede=a("a"),WCt=o("FlaxXLMRobertaForQuestionAnswering"),UCt=o(" (XLM-RoBERTa model)"),HCt=l(),F(VL.$$.fragment),Ino=l(),Lf=a("h2"),XL=a("a"),gPe=a("span"),F(CB.$$.fragment),JCt=l(),hPe=a("span"),YCt=o("FlaxAutoModelForTokenClassification"),Nno=l(),Rr=a("div"),F(wB.$$.fragment),ZCt=l(),yf=a("p"),KCt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Cde=a("a"),e3t=o("from_pretrained()"),o3t=o(" class method or the "),wde=a("a"),r3t=o("from_config()"),t3t=o(` class
method.`),a3t=l(),AB=a("p"),n3t=o("This class cannot be instantiated directly using "),uPe=a("code"),s3t=o("__init__()"),l3t=o(" (throws an error)."),i3t=l(),Fa=a("div"),F(LB.$$.fragment),d3t=l(),pPe=a("p"),m3t=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),c3t=l(),xf=a("p"),f3t=o(`Note:
Loading a model from its configuration file does `),_Pe=a("strong"),g3t=o("not"),h3t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ade=a("a"),u3t=o("from_pretrained()"),p3t=o(" to load the model weights."),_3t=l(),F(zL.$$.fragment),b3t=l(),dt=a("div"),F(yB.$$.fragment),v3t=l(),bPe=a("p"),F3t=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),T3t=l(),as=a("p"),M3t=o("The model class to instantiate is selected based on the "),vPe=a("code"),E3t=o("model_type"),C3t=o(` property of the config object (either
passed as an argument or loaded from `),FPe=a("code"),w3t=o("pretrained_model_name_or_path"),A3t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TPe=a("code"),L3t=o("pretrained_model_name_or_path"),y3t=o(":"),x3t=l(),ze=a("ul"),QL=a("li"),MPe=a("strong"),$3t=o("albert"),k3t=o(" \u2014 "),Lde=a("a"),S3t=o("FlaxAlbertForTokenClassification"),R3t=o(" (ALBERT model)"),P3t=l(),WL=a("li"),EPe=a("strong"),B3t=o("bert"),I3t=o(" \u2014 "),yde=a("a"),N3t=o("FlaxBertForTokenClassification"),q3t=o(" (BERT model)"),D3t=l(),UL=a("li"),CPe=a("strong"),j3t=o("big_bird"),G3t=o(" \u2014 "),xde=a("a"),O3t=o("FlaxBigBirdForTokenClassification"),V3t=o(" (BigBird model)"),X3t=l(),HL=a("li"),wPe=a("strong"),z3t=o("distilbert"),Q3t=o(" \u2014 "),$de=a("a"),W3t=o("FlaxDistilBertForTokenClassification"),U3t=o(" (DistilBERT model)"),H3t=l(),JL=a("li"),APe=a("strong"),J3t=o("electra"),Y3t=o(" \u2014 "),kde=a("a"),Z3t=o("FlaxElectraForTokenClassification"),K3t=o(" (ELECTRA model)"),e5t=l(),YL=a("li"),LPe=a("strong"),o5t=o("roberta"),r5t=o(" \u2014 "),Sde=a("a"),t5t=o("FlaxRobertaForTokenClassification"),a5t=o(" (RoBERTa model)"),n5t=l(),ZL=a("li"),yPe=a("strong"),s5t=o("roformer"),l5t=o(" \u2014 "),Rde=a("a"),i5t=o("FlaxRoFormerForTokenClassification"),d5t=o(" (RoFormer model)"),m5t=l(),KL=a("li"),xPe=a("strong"),c5t=o("xlm-roberta"),f5t=o(" \u2014 "),Pde=a("a"),g5t=o("FlaxXLMRobertaForTokenClassification"),h5t=o(" (XLM-RoBERTa model)"),u5t=l(),F(ey.$$.fragment),qno=l(),$f=a("h2"),oy=a("a"),$Pe=a("span"),F(xB.$$.fragment),p5t=l(),kPe=a("span"),_5t=o("FlaxAutoModelForMultipleChoice"),Dno=l(),Pr=a("div"),F($B.$$.fragment),b5t=l(),kf=a("p"),v5t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Bde=a("a"),F5t=o("from_pretrained()"),T5t=o(" class method or the "),Ide=a("a"),M5t=o("from_config()"),E5t=o(` class
method.`),C5t=l(),kB=a("p"),w5t=o("This class cannot be instantiated directly using "),SPe=a("code"),A5t=o("__init__()"),L5t=o(" (throws an error)."),y5t=l(),Ta=a("div"),F(SB.$$.fragment),x5t=l(),RPe=a("p"),$5t=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),k5t=l(),Sf=a("p"),S5t=o(`Note:
Loading a model from its configuration file does `),PPe=a("strong"),R5t=o("not"),P5t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Nde=a("a"),B5t=o("from_pretrained()"),I5t=o(" to load the model weights."),N5t=l(),F(ry.$$.fragment),q5t=l(),mt=a("div"),F(RB.$$.fragment),D5t=l(),BPe=a("p"),j5t=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),G5t=l(),ns=a("p"),O5t=o("The model class to instantiate is selected based on the "),IPe=a("code"),V5t=o("model_type"),X5t=o(` property of the config object (either
passed as an argument or loaded from `),NPe=a("code"),z5t=o("pretrained_model_name_or_path"),Q5t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qPe=a("code"),W5t=o("pretrained_model_name_or_path"),U5t=o(":"),H5t=l(),Qe=a("ul"),ty=a("li"),DPe=a("strong"),J5t=o("albert"),Y5t=o(" \u2014 "),qde=a("a"),Z5t=o("FlaxAlbertForMultipleChoice"),K5t=o(" (ALBERT model)"),e0t=l(),ay=a("li"),jPe=a("strong"),o0t=o("bert"),r0t=o(" \u2014 "),Dde=a("a"),t0t=o("FlaxBertForMultipleChoice"),a0t=o(" (BERT model)"),n0t=l(),ny=a("li"),GPe=a("strong"),s0t=o("big_bird"),l0t=o(" \u2014 "),jde=a("a"),i0t=o("FlaxBigBirdForMultipleChoice"),d0t=o(" (BigBird model)"),m0t=l(),sy=a("li"),OPe=a("strong"),c0t=o("distilbert"),f0t=o(" \u2014 "),Gde=a("a"),g0t=o("FlaxDistilBertForMultipleChoice"),h0t=o(" (DistilBERT model)"),u0t=l(),ly=a("li"),VPe=a("strong"),p0t=o("electra"),_0t=o(" \u2014 "),Ode=a("a"),b0t=o("FlaxElectraForMultipleChoice"),v0t=o(" (ELECTRA model)"),F0t=l(),iy=a("li"),XPe=a("strong"),T0t=o("roberta"),M0t=o(" \u2014 "),Vde=a("a"),E0t=o("FlaxRobertaForMultipleChoice"),C0t=o(" (RoBERTa model)"),w0t=l(),dy=a("li"),zPe=a("strong"),A0t=o("roformer"),L0t=o(" \u2014 "),Xde=a("a"),y0t=o("FlaxRoFormerForMultipleChoice"),x0t=o(" (RoFormer model)"),$0t=l(),my=a("li"),QPe=a("strong"),k0t=o("xlm-roberta"),S0t=o(" \u2014 "),zde=a("a"),R0t=o("FlaxXLMRobertaForMultipleChoice"),P0t=o(" (XLM-RoBERTa model)"),B0t=l(),F(cy.$$.fragment),jno=l(),Rf=a("h2"),fy=a("a"),WPe=a("span"),F(PB.$$.fragment),I0t=l(),UPe=a("span"),N0t=o("FlaxAutoModelForNextSentencePrediction"),Gno=l(),Br=a("div"),F(BB.$$.fragment),q0t=l(),Pf=a("p"),D0t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Qde=a("a"),j0t=o("from_pretrained()"),G0t=o(" class method or the "),Wde=a("a"),O0t=o("from_config()"),V0t=o(` class
method.`),X0t=l(),IB=a("p"),z0t=o("This class cannot be instantiated directly using "),HPe=a("code"),Q0t=o("__init__()"),W0t=o(" (throws an error)."),U0t=l(),Ma=a("div"),F(NB.$$.fragment),H0t=l(),JPe=a("p"),J0t=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Y0t=l(),Bf=a("p"),Z0t=o(`Note:
Loading a model from its configuration file does `),YPe=a("strong"),K0t=o("not"),ewt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ude=a("a"),owt=o("from_pretrained()"),rwt=o(" to load the model weights."),twt=l(),F(gy.$$.fragment),awt=l(),ct=a("div"),F(qB.$$.fragment),nwt=l(),ZPe=a("p"),swt=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),lwt=l(),ss=a("p"),iwt=o("The model class to instantiate is selected based on the "),KPe=a("code"),dwt=o("model_type"),mwt=o(` property of the config object (either
passed as an argument or loaded from `),eBe=a("code"),cwt=o("pretrained_model_name_or_path"),fwt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oBe=a("code"),gwt=o("pretrained_model_name_or_path"),hwt=o(":"),uwt=l(),rBe=a("ul"),hy=a("li"),tBe=a("strong"),pwt=o("bert"),_wt=o(" \u2014 "),Hde=a("a"),bwt=o("FlaxBertForNextSentencePrediction"),vwt=o(" (BERT model)"),Fwt=l(),F(uy.$$.fragment),Ono=l(),If=a("h2"),py=a("a"),aBe=a("span"),F(DB.$$.fragment),Twt=l(),nBe=a("span"),Mwt=o("FlaxAutoModelForImageClassification"),Vno=l(),Ir=a("div"),F(jB.$$.fragment),Ewt=l(),Nf=a("p"),Cwt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Jde=a("a"),wwt=o("from_pretrained()"),Awt=o(" class method or the "),Yde=a("a"),Lwt=o("from_config()"),ywt=o(` class
method.`),xwt=l(),GB=a("p"),$wt=o("This class cannot be instantiated directly using "),sBe=a("code"),kwt=o("__init__()"),Swt=o(" (throws an error)."),Rwt=l(),Ea=a("div"),F(OB.$$.fragment),Pwt=l(),lBe=a("p"),Bwt=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Iwt=l(),qf=a("p"),Nwt=o(`Note:
Loading a model from its configuration file does `),iBe=a("strong"),qwt=o("not"),Dwt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zde=a("a"),jwt=o("from_pretrained()"),Gwt=o(" to load the model weights."),Owt=l(),F(_y.$$.fragment),Vwt=l(),ft=a("div"),F(VB.$$.fragment),Xwt=l(),dBe=a("p"),zwt=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Qwt=l(),ls=a("p"),Wwt=o("The model class to instantiate is selected based on the "),mBe=a("code"),Uwt=o("model_type"),Hwt=o(` property of the config object (either
passed as an argument or loaded from `),cBe=a("code"),Jwt=o("pretrained_model_name_or_path"),Ywt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fBe=a("code"),Zwt=o("pretrained_model_name_or_path"),Kwt=o(":"),eAt=l(),XB=a("ul"),by=a("li"),gBe=a("strong"),oAt=o("beit"),rAt=o(" \u2014 "),Kde=a("a"),tAt=o("FlaxBeitForImageClassification"),aAt=o(" (BEiT model)"),nAt=l(),vy=a("li"),hBe=a("strong"),sAt=o("vit"),lAt=o(" \u2014 "),eme=a("a"),iAt=o("FlaxViTForImageClassification"),dAt=o(" (ViT model)"),mAt=l(),F(Fy.$$.fragment),Xno=l(),Df=a("h2"),Ty=a("a"),uBe=a("span"),F(zB.$$.fragment),cAt=l(),pBe=a("span"),fAt=o("FlaxAutoModelForVision2Seq"),zno=l(),Nr=a("div"),F(QB.$$.fragment),gAt=l(),jf=a("p"),hAt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),ome=a("a"),uAt=o("from_pretrained()"),pAt=o(" class method or the "),rme=a("a"),_At=o("from_config()"),bAt=o(` class
method.`),vAt=l(),WB=a("p"),FAt=o("This class cannot be instantiated directly using "),_Be=a("code"),TAt=o("__init__()"),MAt=o(" (throws an error)."),EAt=l(),Ca=a("div"),F(UB.$$.fragment),CAt=l(),bBe=a("p"),wAt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),AAt=l(),Gf=a("p"),LAt=o(`Note:
Loading a model from its configuration file does `),vBe=a("strong"),yAt=o("not"),xAt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tme=a("a"),$At=o("from_pretrained()"),kAt=o(" to load the model weights."),SAt=l(),F(My.$$.fragment),RAt=l(),gt=a("div"),F(HB.$$.fragment),PAt=l(),FBe=a("p"),BAt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),IAt=l(),is=a("p"),NAt=o("The model class to instantiate is selected based on the "),TBe=a("code"),qAt=o("model_type"),DAt=o(` property of the config object (either
passed as an argument or loaded from `),MBe=a("code"),jAt=o("pretrained_model_name_or_path"),GAt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),EBe=a("code"),OAt=o("pretrained_model_name_or_path"),VAt=o(":"),XAt=l(),CBe=a("ul"),Ey=a("li"),wBe=a("strong"),zAt=o("vision-encoder-decoder"),QAt=o(" \u2014 "),ame=a("a"),WAt=o("FlaxVisionEncoderDecoderModel"),UAt=o(" (Vision Encoder decoder model)"),HAt=l(),F(Cy.$$.fragment),this.h()},l(c){const _=N3a('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(c),u=n(c,"H1",{class:!0});var JB=s(u);f=n(JB,"A",{id:!0,class:!0,href:!0});var ABe=s(f);p=n(ABe,"SPAN",{});var LBe=s(p);T(d.$$.fragment,LBe),LBe.forEach(t),ABe.forEach(t),h=i(JB),$o=n(JB,"SPAN",{});var yBe=s($o);bd=r(yBe,"Auto Classes"),yBe.forEach(t),JB.forEach(t),zf=i(c),Tt=n(c,"P",{});var YB=s(Tt);vd=r(YB,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Fd=n(YB,"CODE",{});var xBe=s(Fd);s$=r(xBe,"from_pretrained()"),xBe.forEach(t),Qf=r(YB,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),YB.forEach(t),Xe=i(c),He=n(c,"P",{});var ds=s(He);Td=r(ds,"Instantiating one of "),ms=n(ds,"A",{href:!0});var $Be=s(ms);l$=r($Be,"AutoConfig"),$Be.forEach(t),cs=r(ds,", "),fs=n(ds,"A",{href:!0});var kBe=s(fs);i$=r(kBe,"AutoModel"),kBe.forEach(t),Md=r(ds,`, and
`),gs=n(ds,"A",{href:!0});var SBe=s(gs);d$=r(SBe,"AutoTokenizer"),SBe.forEach(t),Ed=r(ds," will directly create a class of the relevant architecture. For instance"),ds.forEach(t),Wf=i(c),T(on.$$.fragment,c),Je=i(c),Ae=n(c,"P",{});var ZB=s(Ae);EN=r(ZB,"will create a model that is an instance of "),Cd=n(ZB,"A",{href:!0});var RBe=s(Cd);CN=r(RBe,"BertModel"),RBe.forEach(t),wN=r(ZB,"."),ZB.forEach(t),ko=i(c),rn=n(c,"P",{});var KB=s(rn);AN=r(KB,"There is one class of "),Uf=n(KB,"CODE",{});var PBe=s(Uf);LN=r(PBe,"AutoModel"),PBe.forEach(t),hio=r(KB," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),KB.forEach(t),xto=i(c),wd=n(c,"H2",{class:!0});var eI=s(wd);Hf=n(eI,"A",{id:!0,class:!0,href:!0});var BBe=s(Hf);gfe=n(BBe,"SPAN",{});var IBe=s(gfe);T(m$.$$.fragment,IBe),IBe.forEach(t),BBe.forEach(t),uio=i(eI),hfe=n(eI,"SPAN",{});var NBe=s(hfe);pio=r(NBe,"Extending the Auto Classes"),NBe.forEach(t),eI.forEach(t),$to=i(c),hs=n(c,"P",{});var Of=s(hs);_io=r(Of,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),ufe=n(Of,"CODE",{});var qBe=s(ufe);bio=r(qBe,"NewModel"),qBe.forEach(t),vio=r(Of,", make sure you have a "),pfe=n(Of,"CODE",{});var DBe=s(pfe);Fio=r(DBe,"NewModelConfig"),DBe.forEach(t),Tio=r(Of,` then you can add those to the auto
classes like this:`),Of.forEach(t),kto=i(c),T(c$.$$.fragment,c),Sto=i(c),yN=n(c,"P",{});var jBe=s(yN);Mio=r(jBe,"You will then be able to use the auto classes like you would usually do!"),jBe.forEach(t),Rto=i(c),T(Jf.$$.fragment,c),Pto=i(c),Ad=n(c,"H2",{class:!0});var oI=s(Ad);Yf=n(oI,"A",{id:!0,class:!0,href:!0});var GBe=s(Yf);_fe=n(GBe,"SPAN",{});var OBe=s(_fe);T(f$.$$.fragment,OBe),OBe.forEach(t),GBe.forEach(t),Eio=i(oI),bfe=n(oI,"SPAN",{});var VBe=s(bfe);Cio=r(VBe,"AutoConfig"),VBe.forEach(t),oI.forEach(t),Bto=i(c),So=n(c,"DIV",{class:!0});var vt=s(So);T(g$.$$.fragment,vt),wio=i(vt),h$=n(vt,"P",{});var rI=s(h$);Aio=r(rI,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),xN=n(rI,"A",{href:!0});var XBe=s(xN);Lio=r(XBe,"from_pretrained()"),XBe.forEach(t),yio=r(rI," class method."),rI.forEach(t),xio=i(vt),u$=n(vt,"P",{});var tI=s(u$);$io=r(tI,"This class cannot be instantiated directly using "),vfe=n(tI,"CODE",{});var zBe=s(vfe);kio=r(zBe,"__init__()"),zBe.forEach(t),Sio=r(tI," (throws an error)."),tI.forEach(t),Rio=i(vt),qr=n(vt,"DIV",{class:!0});var Ft=s(qr);T(p$.$$.fragment,Ft),Pio=i(Ft),Ffe=n(Ft,"P",{});var QBe=s(Ffe);Bio=r(QBe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),QBe.forEach(t),Iio=i(Ft),Ld=n(Ft,"P",{});var Vf=s(Ld);Nio=r(Vf,"The configuration class to instantiate is selected based on the "),Tfe=n(Vf,"CODE",{});var WBe=s(Tfe);qio=r(WBe,"model_type"),WBe.forEach(t),Dio=r(Vf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Mfe=n(Vf,"CODE",{});var UBe=s(Mfe);jio=r(UBe,"pretrained_model_name_or_path"),UBe.forEach(t),Gio=r(Vf,":"),Vf.forEach(t),Oio=i(Ft),A=n(Ft,"UL",{});var L=s(A);Zf=n(L,"LI",{});var wy=s(Zf);Efe=n(wy,"STRONG",{});var HBe=s(Efe);Vio=r(HBe,"albert"),HBe.forEach(t),Xio=r(wy," \u2014 "),$N=n(wy,"A",{href:!0});var JBe=s($N);zio=r(JBe,"AlbertConfig"),JBe.forEach(t),Qio=r(wy," (ALBERT model)"),wy.forEach(t),Wio=i(L),Kf=n(L,"LI",{});var Ay=s(Kf);Cfe=n(Ay,"STRONG",{});var YBe=s(Cfe);Uio=r(YBe,"bart"),YBe.forEach(t),Hio=r(Ay," \u2014 "),kN=n(Ay,"A",{href:!0});var ZBe=s(kN);Jio=r(ZBe,"BartConfig"),ZBe.forEach(t),Yio=r(Ay," (BART model)"),Ay.forEach(t),Zio=i(L),eg=n(L,"LI",{});var Ly=s(eg);wfe=n(Ly,"STRONG",{});var KBe=s(wfe);Kio=r(KBe,"beit"),KBe.forEach(t),edo=r(Ly," \u2014 "),SN=n(Ly,"A",{href:!0});var eIe=s(SN);odo=r(eIe,"BeitConfig"),eIe.forEach(t),rdo=r(Ly," (BEiT model)"),Ly.forEach(t),tdo=i(L),og=n(L,"LI",{});var yy=s(og);Afe=n(yy,"STRONG",{});var oIe=s(Afe);ado=r(oIe,"bert"),oIe.forEach(t),ndo=r(yy," \u2014 "),RN=n(yy,"A",{href:!0});var rIe=s(RN);sdo=r(rIe,"BertConfig"),rIe.forEach(t),ldo=r(yy," (BERT model)"),yy.forEach(t),ido=i(L),rg=n(L,"LI",{});var xy=s(rg);Lfe=n(xy,"STRONG",{});var tIe=s(Lfe);ddo=r(tIe,"bert-generation"),tIe.forEach(t),mdo=r(xy," \u2014 "),PN=n(xy,"A",{href:!0});var aIe=s(PN);cdo=r(aIe,"BertGenerationConfig"),aIe.forEach(t),fdo=r(xy," (Bert Generation model)"),xy.forEach(t),gdo=i(L),tg=n(L,"LI",{});var $y=s(tg);yfe=n($y,"STRONG",{});var nIe=s(yfe);hdo=r(nIe,"big_bird"),nIe.forEach(t),udo=r($y," \u2014 "),BN=n($y,"A",{href:!0});var sIe=s(BN);pdo=r(sIe,"BigBirdConfig"),sIe.forEach(t),_do=r($y," (BigBird model)"),$y.forEach(t),bdo=i(L),ag=n(L,"LI",{});var ky=s(ag);xfe=n(ky,"STRONG",{});var lIe=s(xfe);vdo=r(lIe,"bigbird_pegasus"),lIe.forEach(t),Fdo=r(ky," \u2014 "),IN=n(ky,"A",{href:!0});var iIe=s(IN);Tdo=r(iIe,"BigBirdPegasusConfig"),iIe.forEach(t),Mdo=r(ky," (BigBird-Pegasus model)"),ky.forEach(t),Edo=i(L),ng=n(L,"LI",{});var Sy=s(ng);$fe=n(Sy,"STRONG",{});var dIe=s($fe);Cdo=r(dIe,"blenderbot"),dIe.forEach(t),wdo=r(Sy," \u2014 "),NN=n(Sy,"A",{href:!0});var mIe=s(NN);Ado=r(mIe,"BlenderbotConfig"),mIe.forEach(t),Ldo=r(Sy," (Blenderbot model)"),Sy.forEach(t),ydo=i(L),sg=n(L,"LI",{});var Ry=s(sg);kfe=n(Ry,"STRONG",{});var cIe=s(kfe);xdo=r(cIe,"blenderbot-small"),cIe.forEach(t),$do=r(Ry," \u2014 "),qN=n(Ry,"A",{href:!0});var fIe=s(qN);kdo=r(fIe,"BlenderbotSmallConfig"),fIe.forEach(t),Sdo=r(Ry," (BlenderbotSmall model)"),Ry.forEach(t),Rdo=i(L),lg=n(L,"LI",{});var Py=s(lg);Sfe=n(Py,"STRONG",{});var gIe=s(Sfe);Pdo=r(gIe,"bloom"),gIe.forEach(t),Bdo=r(Py," \u2014 "),DN=n(Py,"A",{href:!0});var hIe=s(DN);Ido=r(hIe,"BloomConfig"),hIe.forEach(t),Ndo=r(Py," (BLOOM model)"),Py.forEach(t),qdo=i(L),ig=n(L,"LI",{});var By=s(ig);Rfe=n(By,"STRONG",{});var uIe=s(Rfe);Ddo=r(uIe,"camembert"),uIe.forEach(t),jdo=r(By," \u2014 "),jN=n(By,"A",{href:!0});var pIe=s(jN);Gdo=r(pIe,"CamembertConfig"),pIe.forEach(t),Odo=r(By," (CamemBERT model)"),By.forEach(t),Vdo=i(L),dg=n(L,"LI",{});var Iy=s(dg);Pfe=n(Iy,"STRONG",{});var _Ie=s(Pfe);Xdo=r(_Ie,"canine"),_Ie.forEach(t),zdo=r(Iy," \u2014 "),GN=n(Iy,"A",{href:!0});var bIe=s(GN);Qdo=r(bIe,"CanineConfig"),bIe.forEach(t),Wdo=r(Iy," (CANINE model)"),Iy.forEach(t),Udo=i(L),mg=n(L,"LI",{});var Ny=s(mg);Bfe=n(Ny,"STRONG",{});var vIe=s(Bfe);Hdo=r(vIe,"clip"),vIe.forEach(t),Jdo=r(Ny," \u2014 "),ON=n(Ny,"A",{href:!0});var FIe=s(ON);Ydo=r(FIe,"CLIPConfig"),FIe.forEach(t),Zdo=r(Ny," (CLIP model)"),Ny.forEach(t),Kdo=i(L),cg=n(L,"LI",{});var qy=s(cg);Ife=n(qy,"STRONG",{});var TIe=s(Ife);emo=r(TIe,"codegen"),TIe.forEach(t),omo=r(qy," \u2014 "),VN=n(qy,"A",{href:!0});var MIe=s(VN);rmo=r(MIe,"CodeGenConfig"),MIe.forEach(t),tmo=r(qy," (CodeGen model)"),qy.forEach(t),amo=i(L),fg=n(L,"LI",{});var Dy=s(fg);Nfe=n(Dy,"STRONG",{});var EIe=s(Nfe);nmo=r(EIe,"conditional_detr"),EIe.forEach(t),smo=r(Dy," \u2014 "),XN=n(Dy,"A",{href:!0});var CIe=s(XN);lmo=r(CIe,"ConditionalDetrConfig"),CIe.forEach(t),imo=r(Dy," (Conditional DETR model)"),Dy.forEach(t),dmo=i(L),gg=n(L,"LI",{});var jy=s(gg);qfe=n(jy,"STRONG",{});var wIe=s(qfe);mmo=r(wIe,"convbert"),wIe.forEach(t),cmo=r(jy," \u2014 "),zN=n(jy,"A",{href:!0});var AIe=s(zN);fmo=r(AIe,"ConvBertConfig"),AIe.forEach(t),gmo=r(jy," (ConvBERT model)"),jy.forEach(t),hmo=i(L),hg=n(L,"LI",{});var Gy=s(hg);Dfe=n(Gy,"STRONG",{});var LIe=s(Dfe);umo=r(LIe,"convnext"),LIe.forEach(t),pmo=r(Gy," \u2014 "),QN=n(Gy,"A",{href:!0});var yIe=s(QN);_mo=r(yIe,"ConvNextConfig"),yIe.forEach(t),bmo=r(Gy," (ConvNeXT model)"),Gy.forEach(t),vmo=i(L),ug=n(L,"LI",{});var Oy=s(ug);jfe=n(Oy,"STRONG",{});var xIe=s(jfe);Fmo=r(xIe,"ctrl"),xIe.forEach(t),Tmo=r(Oy," \u2014 "),WN=n(Oy,"A",{href:!0});var $Ie=s(WN);Mmo=r($Ie,"CTRLConfig"),$Ie.forEach(t),Emo=r(Oy," (CTRL model)"),Oy.forEach(t),Cmo=i(L),pg=n(L,"LI",{});var Vy=s(pg);Gfe=n(Vy,"STRONG",{});var kIe=s(Gfe);wmo=r(kIe,"cvt"),kIe.forEach(t),Amo=r(Vy," \u2014 "),UN=n(Vy,"A",{href:!0});var SIe=s(UN);Lmo=r(SIe,"CvtConfig"),SIe.forEach(t),ymo=r(Vy," (CvT model)"),Vy.forEach(t),xmo=i(L),_g=n(L,"LI",{});var Xy=s(_g);Ofe=n(Xy,"STRONG",{});var RIe=s(Ofe);$mo=r(RIe,"data2vec-audio"),RIe.forEach(t),kmo=r(Xy," \u2014 "),HN=n(Xy,"A",{href:!0});var PIe=s(HN);Smo=r(PIe,"Data2VecAudioConfig"),PIe.forEach(t),Rmo=r(Xy," (Data2VecAudio model)"),Xy.forEach(t),Pmo=i(L),bg=n(L,"LI",{});var zy=s(bg);Vfe=n(zy,"STRONG",{});var BIe=s(Vfe);Bmo=r(BIe,"data2vec-text"),BIe.forEach(t),Imo=r(zy," \u2014 "),JN=n(zy,"A",{href:!0});var IIe=s(JN);Nmo=r(IIe,"Data2VecTextConfig"),IIe.forEach(t),qmo=r(zy," (Data2VecText model)"),zy.forEach(t),Dmo=i(L),vg=n(L,"LI",{});var Qy=s(vg);Xfe=n(Qy,"STRONG",{});var NIe=s(Xfe);jmo=r(NIe,"data2vec-vision"),NIe.forEach(t),Gmo=r(Qy," \u2014 "),YN=n(Qy,"A",{href:!0});var qIe=s(YN);Omo=r(qIe,"Data2VecVisionConfig"),qIe.forEach(t),Vmo=r(Qy," (Data2VecVision model)"),Qy.forEach(t),Xmo=i(L),Fg=n(L,"LI",{});var Wy=s(Fg);zfe=n(Wy,"STRONG",{});var DIe=s(zfe);zmo=r(DIe,"deberta"),DIe.forEach(t),Qmo=r(Wy," \u2014 "),ZN=n(Wy,"A",{href:!0});var jIe=s(ZN);Wmo=r(jIe,"DebertaConfig"),jIe.forEach(t),Umo=r(Wy," (DeBERTa model)"),Wy.forEach(t),Hmo=i(L),Tg=n(L,"LI",{});var Uy=s(Tg);Qfe=n(Uy,"STRONG",{});var GIe=s(Qfe);Jmo=r(GIe,"deberta-v2"),GIe.forEach(t),Ymo=r(Uy," \u2014 "),KN=n(Uy,"A",{href:!0});var OIe=s(KN);Zmo=r(OIe,"DebertaV2Config"),OIe.forEach(t),Kmo=r(Uy," (DeBERTa-v2 model)"),Uy.forEach(t),eco=i(L),Mg=n(L,"LI",{});var Hy=s(Mg);Wfe=n(Hy,"STRONG",{});var VIe=s(Wfe);oco=r(VIe,"decision_transformer"),VIe.forEach(t),rco=r(Hy," \u2014 "),eq=n(Hy,"A",{href:!0});var XIe=s(eq);tco=r(XIe,"DecisionTransformerConfig"),XIe.forEach(t),aco=r(Hy," (Decision Transformer model)"),Hy.forEach(t),nco=i(L),Eg=n(L,"LI",{});var Jy=s(Eg);Ufe=n(Jy,"STRONG",{});var zIe=s(Ufe);sco=r(zIe,"deformable_detr"),zIe.forEach(t),lco=r(Jy," \u2014 "),oq=n(Jy,"A",{href:!0});var QIe=s(oq);ico=r(QIe,"DeformableDetrConfig"),QIe.forEach(t),dco=r(Jy," (Deformable DETR model)"),Jy.forEach(t),mco=i(L),Cg=n(L,"LI",{});var Yy=s(Cg);Hfe=n(Yy,"STRONG",{});var WIe=s(Hfe);cco=r(WIe,"deit"),WIe.forEach(t),fco=r(Yy," \u2014 "),rq=n(Yy,"A",{href:!0});var UIe=s(rq);gco=r(UIe,"DeiTConfig"),UIe.forEach(t),hco=r(Yy," (DeiT model)"),Yy.forEach(t),uco=i(L),wg=n(L,"LI",{});var Zy=s(wg);Jfe=n(Zy,"STRONG",{});var YAt=s(Jfe);pco=r(YAt,"detr"),YAt.forEach(t),_co=r(Zy," \u2014 "),tq=n(Zy,"A",{href:!0});var ZAt=s(tq);bco=r(ZAt,"DetrConfig"),ZAt.forEach(t),vco=r(Zy," (DETR model)"),Zy.forEach(t),Fco=i(L),Ag=n(L,"LI",{});var HIe=s(Ag);Yfe=n(HIe,"STRONG",{});var KAt=s(Yfe);Tco=r(KAt,"distilbert"),KAt.forEach(t),Mco=r(HIe," \u2014 "),aq=n(HIe,"A",{href:!0});var e6t=s(aq);Eco=r(e6t,"DistilBertConfig"),e6t.forEach(t),Cco=r(HIe," (DistilBERT model)"),HIe.forEach(t),wco=i(L),Lg=n(L,"LI",{});var JIe=s(Lg);Zfe=n(JIe,"STRONG",{});var o6t=s(Zfe);Aco=r(o6t,"donut-swin"),o6t.forEach(t),Lco=r(JIe," \u2014 "),nq=n(JIe,"A",{href:!0});var r6t=s(nq);yco=r(r6t,"DonutSwinConfig"),r6t.forEach(t),xco=r(JIe," (DonutSwin model)"),JIe.forEach(t),$co=i(L),yg=n(L,"LI",{});var YIe=s(yg);Kfe=n(YIe,"STRONG",{});var t6t=s(Kfe);kco=r(t6t,"dpr"),t6t.forEach(t),Sco=r(YIe," \u2014 "),sq=n(YIe,"A",{href:!0});var a6t=s(sq);Rco=r(a6t,"DPRConfig"),a6t.forEach(t),Pco=r(YIe," (DPR model)"),YIe.forEach(t),Bco=i(L),xg=n(L,"LI",{});var ZIe=s(xg);ege=n(ZIe,"STRONG",{});var n6t=s(ege);Ico=r(n6t,"dpt"),n6t.forEach(t),Nco=r(ZIe," \u2014 "),lq=n(ZIe,"A",{href:!0});var s6t=s(lq);qco=r(s6t,"DPTConfig"),s6t.forEach(t),Dco=r(ZIe," (DPT model)"),ZIe.forEach(t),jco=i(L),$g=n(L,"LI",{});var KIe=s($g);oge=n(KIe,"STRONG",{});var l6t=s(oge);Gco=r(l6t,"electra"),l6t.forEach(t),Oco=r(KIe," \u2014 "),iq=n(KIe,"A",{href:!0});var i6t=s(iq);Vco=r(i6t,"ElectraConfig"),i6t.forEach(t),Xco=r(KIe," (ELECTRA model)"),KIe.forEach(t),zco=i(L),kg=n(L,"LI",{});var eNe=s(kg);rge=n(eNe,"STRONG",{});var d6t=s(rge);Qco=r(d6t,"encoder-decoder"),d6t.forEach(t),Wco=r(eNe," \u2014 "),dq=n(eNe,"A",{href:!0});var m6t=s(dq);Uco=r(m6t,"EncoderDecoderConfig"),m6t.forEach(t),Hco=r(eNe," (Encoder decoder model)"),eNe.forEach(t),Jco=i(L),Sg=n(L,"LI",{});var oNe=s(Sg);tge=n(oNe,"STRONG",{});var c6t=s(tge);Yco=r(c6t,"ernie"),c6t.forEach(t),Zco=r(oNe," \u2014 "),mq=n(oNe,"A",{href:!0});var f6t=s(mq);Kco=r(f6t,"ErnieConfig"),f6t.forEach(t),efo=r(oNe," (ERNIE model)"),oNe.forEach(t),ofo=i(L),Rg=n(L,"LI",{});var rNe=s(Rg);age=n(rNe,"STRONG",{});var g6t=s(age);rfo=r(g6t,"esm"),g6t.forEach(t),tfo=r(rNe," \u2014 "),cq=n(rNe,"A",{href:!0});var h6t=s(cq);afo=r(h6t,"EsmConfig"),h6t.forEach(t),nfo=r(rNe," (ESM model)"),rNe.forEach(t),sfo=i(L),Pg=n(L,"LI",{});var tNe=s(Pg);nge=n(tNe,"STRONG",{});var u6t=s(nge);lfo=r(u6t,"flaubert"),u6t.forEach(t),ifo=r(tNe," \u2014 "),fq=n(tNe,"A",{href:!0});var p6t=s(fq);dfo=r(p6t,"FlaubertConfig"),p6t.forEach(t),mfo=r(tNe," (FlauBERT model)"),tNe.forEach(t),cfo=i(L),Bg=n(L,"LI",{});var aNe=s(Bg);sge=n(aNe,"STRONG",{});var _6t=s(sge);ffo=r(_6t,"flava"),_6t.forEach(t),gfo=r(aNe," \u2014 "),gq=n(aNe,"A",{href:!0});var b6t=s(gq);hfo=r(b6t,"FlavaConfig"),b6t.forEach(t),ufo=r(aNe," (FLAVA model)"),aNe.forEach(t),pfo=i(L),Ig=n(L,"LI",{});var nNe=s(Ig);lge=n(nNe,"STRONG",{});var v6t=s(lge);_fo=r(v6t,"fnet"),v6t.forEach(t),bfo=r(nNe," \u2014 "),hq=n(nNe,"A",{href:!0});var F6t=s(hq);vfo=r(F6t,"FNetConfig"),F6t.forEach(t),Ffo=r(nNe," (FNet model)"),nNe.forEach(t),Tfo=i(L),Ng=n(L,"LI",{});var sNe=s(Ng);ige=n(sNe,"STRONG",{});var T6t=s(ige);Mfo=r(T6t,"fsmt"),T6t.forEach(t),Efo=r(sNe," \u2014 "),uq=n(sNe,"A",{href:!0});var M6t=s(uq);Cfo=r(M6t,"FSMTConfig"),M6t.forEach(t),wfo=r(sNe," (FairSeq Machine-Translation model)"),sNe.forEach(t),Afo=i(L),qg=n(L,"LI",{});var lNe=s(qg);dge=n(lNe,"STRONG",{});var E6t=s(dge);Lfo=r(E6t,"funnel"),E6t.forEach(t),yfo=r(lNe," \u2014 "),pq=n(lNe,"A",{href:!0});var C6t=s(pq);xfo=r(C6t,"FunnelConfig"),C6t.forEach(t),$fo=r(lNe," (Funnel Transformer model)"),lNe.forEach(t),kfo=i(L),Dg=n(L,"LI",{});var iNe=s(Dg);mge=n(iNe,"STRONG",{});var w6t=s(mge);Sfo=r(w6t,"glpn"),w6t.forEach(t),Rfo=r(iNe," \u2014 "),_q=n(iNe,"A",{href:!0});var A6t=s(_q);Pfo=r(A6t,"GLPNConfig"),A6t.forEach(t),Bfo=r(iNe," (GLPN model)"),iNe.forEach(t),Ifo=i(L),jg=n(L,"LI",{});var dNe=s(jg);cge=n(dNe,"STRONG",{});var L6t=s(cge);Nfo=r(L6t,"gpt2"),L6t.forEach(t),qfo=r(dNe," \u2014 "),bq=n(dNe,"A",{href:!0});var y6t=s(bq);Dfo=r(y6t,"GPT2Config"),y6t.forEach(t),jfo=r(dNe," (OpenAI GPT-2 model)"),dNe.forEach(t),Gfo=i(L),Gg=n(L,"LI",{});var mNe=s(Gg);fge=n(mNe,"STRONG",{});var x6t=s(fge);Ofo=r(x6t,"gpt_neo"),x6t.forEach(t),Vfo=r(mNe," \u2014 "),vq=n(mNe,"A",{href:!0});var $6t=s(vq);Xfo=r($6t,"GPTNeoConfig"),$6t.forEach(t),zfo=r(mNe," (GPT Neo model)"),mNe.forEach(t),Qfo=i(L),Og=n(L,"LI",{});var cNe=s(Og);gge=n(cNe,"STRONG",{});var k6t=s(gge);Wfo=r(k6t,"gpt_neox"),k6t.forEach(t),Ufo=r(cNe," \u2014 "),Fq=n(cNe,"A",{href:!0});var S6t=s(Fq);Hfo=r(S6t,"GPTNeoXConfig"),S6t.forEach(t),Jfo=r(cNe," (GPT NeoX model)"),cNe.forEach(t),Yfo=i(L),Vg=n(L,"LI",{});var fNe=s(Vg);hge=n(fNe,"STRONG",{});var R6t=s(hge);Zfo=r(R6t,"gpt_neox_japanese"),R6t.forEach(t),Kfo=r(fNe," \u2014 "),Tq=n(fNe,"A",{href:!0});var P6t=s(Tq);ego=r(P6t,"GPTNeoXJapaneseConfig"),P6t.forEach(t),ogo=r(fNe," (GPT NeoX Japanese model)"),fNe.forEach(t),rgo=i(L),Xg=n(L,"LI",{});var gNe=s(Xg);uge=n(gNe,"STRONG",{});var B6t=s(uge);tgo=r(B6t,"gptj"),B6t.forEach(t),ago=r(gNe," \u2014 "),Mq=n(gNe,"A",{href:!0});var I6t=s(Mq);ngo=r(I6t,"GPTJConfig"),I6t.forEach(t),sgo=r(gNe," (GPT-J model)"),gNe.forEach(t),lgo=i(L),zg=n(L,"LI",{});var hNe=s(zg);pge=n(hNe,"STRONG",{});var N6t=s(pge);igo=r(N6t,"groupvit"),N6t.forEach(t),dgo=r(hNe," \u2014 "),Eq=n(hNe,"A",{href:!0});var q6t=s(Eq);mgo=r(q6t,"GroupViTConfig"),q6t.forEach(t),cgo=r(hNe," (GroupViT model)"),hNe.forEach(t),fgo=i(L),Qg=n(L,"LI",{});var uNe=s(Qg);_ge=n(uNe,"STRONG",{});var D6t=s(_ge);ggo=r(D6t,"hubert"),D6t.forEach(t),hgo=r(uNe," \u2014 "),Cq=n(uNe,"A",{href:!0});var j6t=s(Cq);ugo=r(j6t,"HubertConfig"),j6t.forEach(t),pgo=r(uNe," (Hubert model)"),uNe.forEach(t),_go=i(L),Wg=n(L,"LI",{});var pNe=s(Wg);bge=n(pNe,"STRONG",{});var G6t=s(bge);bgo=r(G6t,"ibert"),G6t.forEach(t),vgo=r(pNe," \u2014 "),wq=n(pNe,"A",{href:!0});var O6t=s(wq);Fgo=r(O6t,"IBertConfig"),O6t.forEach(t),Tgo=r(pNe," (I-BERT model)"),pNe.forEach(t),Mgo=i(L),Ug=n(L,"LI",{});var _Ne=s(Ug);vge=n(_Ne,"STRONG",{});var V6t=s(vge);Ego=r(V6t,"imagegpt"),V6t.forEach(t),Cgo=r(_Ne," \u2014 "),Aq=n(_Ne,"A",{href:!0});var X6t=s(Aq);wgo=r(X6t,"ImageGPTConfig"),X6t.forEach(t),Ago=r(_Ne," (ImageGPT model)"),_Ne.forEach(t),Lgo=i(L),Hg=n(L,"LI",{});var bNe=s(Hg);Fge=n(bNe,"STRONG",{});var z6t=s(Fge);ygo=r(z6t,"layoutlm"),z6t.forEach(t),xgo=r(bNe," \u2014 "),Lq=n(bNe,"A",{href:!0});var Q6t=s(Lq);$go=r(Q6t,"LayoutLMConfig"),Q6t.forEach(t),kgo=r(bNe," (LayoutLM model)"),bNe.forEach(t),Sgo=i(L),Jg=n(L,"LI",{});var vNe=s(Jg);Tge=n(vNe,"STRONG",{});var W6t=s(Tge);Rgo=r(W6t,"layoutlmv2"),W6t.forEach(t),Pgo=r(vNe," \u2014 "),yq=n(vNe,"A",{href:!0});var U6t=s(yq);Bgo=r(U6t,"LayoutLMv2Config"),U6t.forEach(t),Igo=r(vNe," (LayoutLMv2 model)"),vNe.forEach(t),Ngo=i(L),Yg=n(L,"LI",{});var FNe=s(Yg);Mge=n(FNe,"STRONG",{});var H6t=s(Mge);qgo=r(H6t,"layoutlmv3"),H6t.forEach(t),Dgo=r(FNe," \u2014 "),xq=n(FNe,"A",{href:!0});var J6t=s(xq);jgo=r(J6t,"LayoutLMv3Config"),J6t.forEach(t),Ggo=r(FNe," (LayoutLMv3 model)"),FNe.forEach(t),Ogo=i(L),Zg=n(L,"LI",{});var TNe=s(Zg);Ege=n(TNe,"STRONG",{});var Y6t=s(Ege);Vgo=r(Y6t,"led"),Y6t.forEach(t),Xgo=r(TNe," \u2014 "),$q=n(TNe,"A",{href:!0});var Z6t=s($q);zgo=r(Z6t,"LEDConfig"),Z6t.forEach(t),Qgo=r(TNe," (LED model)"),TNe.forEach(t),Wgo=i(L),Kg=n(L,"LI",{});var MNe=s(Kg);Cge=n(MNe,"STRONG",{});var K6t=s(Cge);Ugo=r(K6t,"levit"),K6t.forEach(t),Hgo=r(MNe," \u2014 "),kq=n(MNe,"A",{href:!0});var e7t=s(kq);Jgo=r(e7t,"LevitConfig"),e7t.forEach(t),Ygo=r(MNe," (LeViT model)"),MNe.forEach(t),Zgo=i(L),eh=n(L,"LI",{});var ENe=s(eh);wge=n(ENe,"STRONG",{});var o7t=s(wge);Kgo=r(o7t,"lilt"),o7t.forEach(t),eho=r(ENe," \u2014 "),Sq=n(ENe,"A",{href:!0});var r7t=s(Sq);oho=r(r7t,"LiltConfig"),r7t.forEach(t),rho=r(ENe," (LiLT model)"),ENe.forEach(t),tho=i(L),oh=n(L,"LI",{});var CNe=s(oh);Age=n(CNe,"STRONG",{});var t7t=s(Age);aho=r(t7t,"longformer"),t7t.forEach(t),nho=r(CNe," \u2014 "),Rq=n(CNe,"A",{href:!0});var a7t=s(Rq);sho=r(a7t,"LongformerConfig"),a7t.forEach(t),lho=r(CNe," (Longformer model)"),CNe.forEach(t),iho=i(L),rh=n(L,"LI",{});var wNe=s(rh);Lge=n(wNe,"STRONG",{});var n7t=s(Lge);dho=r(n7t,"longt5"),n7t.forEach(t),mho=r(wNe," \u2014 "),Pq=n(wNe,"A",{href:!0});var s7t=s(Pq);cho=r(s7t,"LongT5Config"),s7t.forEach(t),fho=r(wNe," (LongT5 model)"),wNe.forEach(t),gho=i(L),th=n(L,"LI",{});var ANe=s(th);yge=n(ANe,"STRONG",{});var l7t=s(yge);hho=r(l7t,"luke"),l7t.forEach(t),uho=r(ANe," \u2014 "),Bq=n(ANe,"A",{href:!0});var i7t=s(Bq);pho=r(i7t,"LukeConfig"),i7t.forEach(t),_ho=r(ANe," (LUKE model)"),ANe.forEach(t),bho=i(L),ah=n(L,"LI",{});var LNe=s(ah);xge=n(LNe,"STRONG",{});var d7t=s(xge);vho=r(d7t,"lxmert"),d7t.forEach(t),Fho=r(LNe," \u2014 "),Iq=n(LNe,"A",{href:!0});var m7t=s(Iq);Tho=r(m7t,"LxmertConfig"),m7t.forEach(t),Mho=r(LNe," (LXMERT model)"),LNe.forEach(t),Eho=i(L),nh=n(L,"LI",{});var yNe=s(nh);$ge=n(yNe,"STRONG",{});var c7t=s($ge);Cho=r(c7t,"m2m_100"),c7t.forEach(t),who=r(yNe," \u2014 "),Nq=n(yNe,"A",{href:!0});var f7t=s(Nq);Aho=r(f7t,"M2M100Config"),f7t.forEach(t),Lho=r(yNe," (M2M100 model)"),yNe.forEach(t),yho=i(L),sh=n(L,"LI",{});var xNe=s(sh);kge=n(xNe,"STRONG",{});var g7t=s(kge);xho=r(g7t,"marian"),g7t.forEach(t),$ho=r(xNe," \u2014 "),qq=n(xNe,"A",{href:!0});var h7t=s(qq);kho=r(h7t,"MarianConfig"),h7t.forEach(t),Sho=r(xNe," (Marian model)"),xNe.forEach(t),Rho=i(L),lh=n(L,"LI",{});var $Ne=s(lh);Sge=n($Ne,"STRONG",{});var u7t=s(Sge);Pho=r(u7t,"markuplm"),u7t.forEach(t),Bho=r($Ne," \u2014 "),Dq=n($Ne,"A",{href:!0});var p7t=s(Dq);Iho=r(p7t,"MarkupLMConfig"),p7t.forEach(t),Nho=r($Ne," (MarkupLM model)"),$Ne.forEach(t),qho=i(L),ih=n(L,"LI",{});var kNe=s(ih);Rge=n(kNe,"STRONG",{});var _7t=s(Rge);Dho=r(_7t,"maskformer"),_7t.forEach(t),jho=r(kNe," \u2014 "),jq=n(kNe,"A",{href:!0});var b7t=s(jq);Gho=r(b7t,"MaskFormerConfig"),b7t.forEach(t),Oho=r(kNe," (MaskFormer model)"),kNe.forEach(t),Vho=i(L),dh=n(L,"LI",{});var SNe=s(dh);Pge=n(SNe,"STRONG",{});var v7t=s(Pge);Xho=r(v7t,"mbart"),v7t.forEach(t),zho=r(SNe," \u2014 "),Gq=n(SNe,"A",{href:!0});var F7t=s(Gq);Qho=r(F7t,"MBartConfig"),F7t.forEach(t),Who=r(SNe," (mBART model)"),SNe.forEach(t),Uho=i(L),mh=n(L,"LI",{});var RNe=s(mh);Bge=n(RNe,"STRONG",{});var T7t=s(Bge);Hho=r(T7t,"mctct"),T7t.forEach(t),Jho=r(RNe," \u2014 "),Oq=n(RNe,"A",{href:!0});var M7t=s(Oq);Yho=r(M7t,"MCTCTConfig"),M7t.forEach(t),Zho=r(RNe," (M-CTC-T model)"),RNe.forEach(t),Kho=i(L),ch=n(L,"LI",{});var PNe=s(ch);Ige=n(PNe,"STRONG",{});var E7t=s(Ige);euo=r(E7t,"megatron-bert"),E7t.forEach(t),ouo=r(PNe," \u2014 "),Vq=n(PNe,"A",{href:!0});var C7t=s(Vq);ruo=r(C7t,"MegatronBertConfig"),C7t.forEach(t),tuo=r(PNe," (Megatron-BERT model)"),PNe.forEach(t),auo=i(L),fh=n(L,"LI",{});var BNe=s(fh);Nge=n(BNe,"STRONG",{});var w7t=s(Nge);nuo=r(w7t,"mobilebert"),w7t.forEach(t),suo=r(BNe," \u2014 "),Xq=n(BNe,"A",{href:!0});var A7t=s(Xq);luo=r(A7t,"MobileBertConfig"),A7t.forEach(t),iuo=r(BNe," (MobileBERT model)"),BNe.forEach(t),duo=i(L),gh=n(L,"LI",{});var INe=s(gh);qge=n(INe,"STRONG",{});var L7t=s(qge);muo=r(L7t,"mobilevit"),L7t.forEach(t),cuo=r(INe," \u2014 "),zq=n(INe,"A",{href:!0});var y7t=s(zq);fuo=r(y7t,"MobileViTConfig"),y7t.forEach(t),guo=r(INe," (MobileViT model)"),INe.forEach(t),huo=i(L),hh=n(L,"LI",{});var NNe=s(hh);Dge=n(NNe,"STRONG",{});var x7t=s(Dge);uuo=r(x7t,"mpnet"),x7t.forEach(t),puo=r(NNe," \u2014 "),Qq=n(NNe,"A",{href:!0});var $7t=s(Qq);_uo=r($7t,"MPNetConfig"),$7t.forEach(t),buo=r(NNe," (MPNet model)"),NNe.forEach(t),vuo=i(L),uh=n(L,"LI",{});var qNe=s(uh);jge=n(qNe,"STRONG",{});var k7t=s(jge);Fuo=r(k7t,"mt5"),k7t.forEach(t),Tuo=r(qNe," \u2014 "),Wq=n(qNe,"A",{href:!0});var S7t=s(Wq);Muo=r(S7t,"MT5Config"),S7t.forEach(t),Euo=r(qNe," (MT5 model)"),qNe.forEach(t),Cuo=i(L),ph=n(L,"LI",{});var DNe=s(ph);Gge=n(DNe,"STRONG",{});var R7t=s(Gge);wuo=r(R7t,"mvp"),R7t.forEach(t),Auo=r(DNe," \u2014 "),Uq=n(DNe,"A",{href:!0});var P7t=s(Uq);Luo=r(P7t,"MvpConfig"),P7t.forEach(t),yuo=r(DNe," (MVP model)"),DNe.forEach(t),xuo=i(L),_h=n(L,"LI",{});var jNe=s(_h);Oge=n(jNe,"STRONG",{});var B7t=s(Oge);$uo=r(B7t,"nezha"),B7t.forEach(t),kuo=r(jNe," \u2014 "),Hq=n(jNe,"A",{href:!0});var I7t=s(Hq);Suo=r(I7t,"NezhaConfig"),I7t.forEach(t),Ruo=r(jNe," (Nezha model)"),jNe.forEach(t),Puo=i(L),bh=n(L,"LI",{});var GNe=s(bh);Vge=n(GNe,"STRONG",{});var N7t=s(Vge);Buo=r(N7t,"nystromformer"),N7t.forEach(t),Iuo=r(GNe," \u2014 "),Jq=n(GNe,"A",{href:!0});var q7t=s(Jq);Nuo=r(q7t,"NystromformerConfig"),q7t.forEach(t),quo=r(GNe," (Nystr\xF6mformer model)"),GNe.forEach(t),Duo=i(L),vh=n(L,"LI",{});var ONe=s(vh);Xge=n(ONe,"STRONG",{});var D7t=s(Xge);juo=r(D7t,"openai-gpt"),D7t.forEach(t),Guo=r(ONe," \u2014 "),Yq=n(ONe,"A",{href:!0});var j7t=s(Yq);Ouo=r(j7t,"OpenAIGPTConfig"),j7t.forEach(t),Vuo=r(ONe," (OpenAI GPT model)"),ONe.forEach(t),Xuo=i(L),Fh=n(L,"LI",{});var VNe=s(Fh);zge=n(VNe,"STRONG",{});var G7t=s(zge);zuo=r(G7t,"opt"),G7t.forEach(t),Quo=r(VNe," \u2014 "),Zq=n(VNe,"A",{href:!0});var O7t=s(Zq);Wuo=r(O7t,"OPTConfig"),O7t.forEach(t),Uuo=r(VNe," (OPT model)"),VNe.forEach(t),Huo=i(L),Th=n(L,"LI",{});var XNe=s(Th);Qge=n(XNe,"STRONG",{});var V7t=s(Qge);Juo=r(V7t,"owlvit"),V7t.forEach(t),Yuo=r(XNe," \u2014 "),Kq=n(XNe,"A",{href:!0});var X7t=s(Kq);Zuo=r(X7t,"OwlViTConfig"),X7t.forEach(t),Kuo=r(XNe," (OWL-ViT model)"),XNe.forEach(t),epo=i(L),Mh=n(L,"LI",{});var zNe=s(Mh);Wge=n(zNe,"STRONG",{});var z7t=s(Wge);opo=r(z7t,"pegasus"),z7t.forEach(t),rpo=r(zNe," \u2014 "),eD=n(zNe,"A",{href:!0});var Q7t=s(eD);tpo=r(Q7t,"PegasusConfig"),Q7t.forEach(t),apo=r(zNe," (Pegasus model)"),zNe.forEach(t),npo=i(L),Eh=n(L,"LI",{});var QNe=s(Eh);Uge=n(QNe,"STRONG",{});var W7t=s(Uge);spo=r(W7t,"pegasus_x"),W7t.forEach(t),lpo=r(QNe," \u2014 "),oD=n(QNe,"A",{href:!0});var U7t=s(oD);ipo=r(U7t,"PegasusXConfig"),U7t.forEach(t),dpo=r(QNe," (PEGASUS-X model)"),QNe.forEach(t),mpo=i(L),Ch=n(L,"LI",{});var WNe=s(Ch);Hge=n(WNe,"STRONG",{});var H7t=s(Hge);cpo=r(H7t,"perceiver"),H7t.forEach(t),fpo=r(WNe," \u2014 "),rD=n(WNe,"A",{href:!0});var J7t=s(rD);gpo=r(J7t,"PerceiverConfig"),J7t.forEach(t),hpo=r(WNe," (Perceiver model)"),WNe.forEach(t),upo=i(L),wh=n(L,"LI",{});var UNe=s(wh);Jge=n(UNe,"STRONG",{});var Y7t=s(Jge);ppo=r(Y7t,"plbart"),Y7t.forEach(t),_po=r(UNe," \u2014 "),tD=n(UNe,"A",{href:!0});var Z7t=s(tD);bpo=r(Z7t,"PLBartConfig"),Z7t.forEach(t),vpo=r(UNe," (PLBart model)"),UNe.forEach(t),Fpo=i(L),Ah=n(L,"LI",{});var HNe=s(Ah);Yge=n(HNe,"STRONG",{});var K7t=s(Yge);Tpo=r(K7t,"poolformer"),K7t.forEach(t),Mpo=r(HNe," \u2014 "),aD=n(HNe,"A",{href:!0});var e8t=s(aD);Epo=r(e8t,"PoolFormerConfig"),e8t.forEach(t),Cpo=r(HNe," (PoolFormer model)"),HNe.forEach(t),wpo=i(L),Lh=n(L,"LI",{});var JNe=s(Lh);Zge=n(JNe,"STRONG",{});var o8t=s(Zge);Apo=r(o8t,"prophetnet"),o8t.forEach(t),Lpo=r(JNe," \u2014 "),nD=n(JNe,"A",{href:!0});var r8t=s(nD);ypo=r(r8t,"ProphetNetConfig"),r8t.forEach(t),xpo=r(JNe," (ProphetNet model)"),JNe.forEach(t),$po=i(L),yh=n(L,"LI",{});var YNe=s(yh);Kge=n(YNe,"STRONG",{});var t8t=s(Kge);kpo=r(t8t,"qdqbert"),t8t.forEach(t),Spo=r(YNe," \u2014 "),sD=n(YNe,"A",{href:!0});var a8t=s(sD);Rpo=r(a8t,"QDQBertConfig"),a8t.forEach(t),Ppo=r(YNe," (QDQBert model)"),YNe.forEach(t),Bpo=i(L),xh=n(L,"LI",{});var ZNe=s(xh);ehe=n(ZNe,"STRONG",{});var n8t=s(ehe);Ipo=r(n8t,"rag"),n8t.forEach(t),Npo=r(ZNe," \u2014 "),lD=n(ZNe,"A",{href:!0});var s8t=s(lD);qpo=r(s8t,"RagConfig"),s8t.forEach(t),Dpo=r(ZNe," (RAG model)"),ZNe.forEach(t),jpo=i(L),$h=n(L,"LI",{});var KNe=s($h);ohe=n(KNe,"STRONG",{});var l8t=s(ohe);Gpo=r(l8t,"realm"),l8t.forEach(t),Opo=r(KNe," \u2014 "),iD=n(KNe,"A",{href:!0});var i8t=s(iD);Vpo=r(i8t,"RealmConfig"),i8t.forEach(t),Xpo=r(KNe," (REALM model)"),KNe.forEach(t),zpo=i(L),kh=n(L,"LI",{});var eqe=s(kh);rhe=n(eqe,"STRONG",{});var d8t=s(rhe);Qpo=r(d8t,"reformer"),d8t.forEach(t),Wpo=r(eqe," \u2014 "),dD=n(eqe,"A",{href:!0});var m8t=s(dD);Upo=r(m8t,"ReformerConfig"),m8t.forEach(t),Hpo=r(eqe," (Reformer model)"),eqe.forEach(t),Jpo=i(L),Sh=n(L,"LI",{});var oqe=s(Sh);the=n(oqe,"STRONG",{});var c8t=s(the);Ypo=r(c8t,"regnet"),c8t.forEach(t),Zpo=r(oqe," \u2014 "),mD=n(oqe,"A",{href:!0});var f8t=s(mD);Kpo=r(f8t,"RegNetConfig"),f8t.forEach(t),e_o=r(oqe," (RegNet model)"),oqe.forEach(t),o_o=i(L),Rh=n(L,"LI",{});var rqe=s(Rh);ahe=n(rqe,"STRONG",{});var g8t=s(ahe);r_o=r(g8t,"rembert"),g8t.forEach(t),t_o=r(rqe," \u2014 "),cD=n(rqe,"A",{href:!0});var h8t=s(cD);a_o=r(h8t,"RemBertConfig"),h8t.forEach(t),n_o=r(rqe," (RemBERT model)"),rqe.forEach(t),s_o=i(L),Ph=n(L,"LI",{});var tqe=s(Ph);nhe=n(tqe,"STRONG",{});var u8t=s(nhe);l_o=r(u8t,"resnet"),u8t.forEach(t),i_o=r(tqe," \u2014 "),fD=n(tqe,"A",{href:!0});var p8t=s(fD);d_o=r(p8t,"ResNetConfig"),p8t.forEach(t),m_o=r(tqe," (ResNet model)"),tqe.forEach(t),c_o=i(L),Bh=n(L,"LI",{});var aqe=s(Bh);she=n(aqe,"STRONG",{});var _8t=s(she);f_o=r(_8t,"retribert"),_8t.forEach(t),g_o=r(aqe," \u2014 "),gD=n(aqe,"A",{href:!0});var b8t=s(gD);h_o=r(b8t,"RetriBertConfig"),b8t.forEach(t),u_o=r(aqe," (RetriBERT model)"),aqe.forEach(t),p_o=i(L),Ih=n(L,"LI",{});var nqe=s(Ih);lhe=n(nqe,"STRONG",{});var v8t=s(lhe);__o=r(v8t,"roberta"),v8t.forEach(t),b_o=r(nqe," \u2014 "),hD=n(nqe,"A",{href:!0});var F8t=s(hD);v_o=r(F8t,"RobertaConfig"),F8t.forEach(t),F_o=r(nqe," (RoBERTa model)"),nqe.forEach(t),T_o=i(L),Nh=n(L,"LI",{});var sqe=s(Nh);ihe=n(sqe,"STRONG",{});var T8t=s(ihe);M_o=r(T8t,"roformer"),T8t.forEach(t),E_o=r(sqe," \u2014 "),uD=n(sqe,"A",{href:!0});var M8t=s(uD);C_o=r(M8t,"RoFormerConfig"),M8t.forEach(t),w_o=r(sqe," (RoFormer model)"),sqe.forEach(t),A_o=i(L),qh=n(L,"LI",{});var lqe=s(qh);dhe=n(lqe,"STRONG",{});var E8t=s(dhe);L_o=r(E8t,"segformer"),E8t.forEach(t),y_o=r(lqe," \u2014 "),pD=n(lqe,"A",{href:!0});var C8t=s(pD);x_o=r(C8t,"SegformerConfig"),C8t.forEach(t),$_o=r(lqe," (SegFormer model)"),lqe.forEach(t),k_o=i(L),Dh=n(L,"LI",{});var iqe=s(Dh);mhe=n(iqe,"STRONG",{});var w8t=s(mhe);S_o=r(w8t,"sew"),w8t.forEach(t),R_o=r(iqe," \u2014 "),_D=n(iqe,"A",{href:!0});var A8t=s(_D);P_o=r(A8t,"SEWConfig"),A8t.forEach(t),B_o=r(iqe," (SEW model)"),iqe.forEach(t),I_o=i(L),jh=n(L,"LI",{});var dqe=s(jh);che=n(dqe,"STRONG",{});var L8t=s(che);N_o=r(L8t,"sew-d"),L8t.forEach(t),q_o=r(dqe," \u2014 "),bD=n(dqe,"A",{href:!0});var y8t=s(bD);D_o=r(y8t,"SEWDConfig"),y8t.forEach(t),j_o=r(dqe," (SEW-D model)"),dqe.forEach(t),G_o=i(L),Gh=n(L,"LI",{});var mqe=s(Gh);fhe=n(mqe,"STRONG",{});var x8t=s(fhe);O_o=r(x8t,"speech-encoder-decoder"),x8t.forEach(t),V_o=r(mqe," \u2014 "),vD=n(mqe,"A",{href:!0});var $8t=s(vD);X_o=r($8t,"SpeechEncoderDecoderConfig"),$8t.forEach(t),z_o=r(mqe," (Speech Encoder decoder model)"),mqe.forEach(t),Q_o=i(L),Oh=n(L,"LI",{});var cqe=s(Oh);ghe=n(cqe,"STRONG",{});var k8t=s(ghe);W_o=r(k8t,"speech_to_text"),k8t.forEach(t),U_o=r(cqe," \u2014 "),FD=n(cqe,"A",{href:!0});var S8t=s(FD);H_o=r(S8t,"Speech2TextConfig"),S8t.forEach(t),J_o=r(cqe," (Speech2Text model)"),cqe.forEach(t),Y_o=i(L),Vh=n(L,"LI",{});var fqe=s(Vh);hhe=n(fqe,"STRONG",{});var R8t=s(hhe);Z_o=r(R8t,"speech_to_text_2"),R8t.forEach(t),K_o=r(fqe," \u2014 "),TD=n(fqe,"A",{href:!0});var P8t=s(TD);e1o=r(P8t,"Speech2Text2Config"),P8t.forEach(t),o1o=r(fqe," (Speech2Text2 model)"),fqe.forEach(t),r1o=i(L),Xh=n(L,"LI",{});var gqe=s(Xh);uhe=n(gqe,"STRONG",{});var B8t=s(uhe);t1o=r(B8t,"splinter"),B8t.forEach(t),a1o=r(gqe," \u2014 "),MD=n(gqe,"A",{href:!0});var I8t=s(MD);n1o=r(I8t,"SplinterConfig"),I8t.forEach(t),s1o=r(gqe," (Splinter model)"),gqe.forEach(t),l1o=i(L),zh=n(L,"LI",{});var hqe=s(zh);phe=n(hqe,"STRONG",{});var N8t=s(phe);i1o=r(N8t,"squeezebert"),N8t.forEach(t),d1o=r(hqe," \u2014 "),ED=n(hqe,"A",{href:!0});var q8t=s(ED);m1o=r(q8t,"SqueezeBertConfig"),q8t.forEach(t),c1o=r(hqe," (SqueezeBERT model)"),hqe.forEach(t),f1o=i(L),Qh=n(L,"LI",{});var uqe=s(Qh);_he=n(uqe,"STRONG",{});var D8t=s(_he);g1o=r(D8t,"swin"),D8t.forEach(t),h1o=r(uqe," \u2014 "),CD=n(uqe,"A",{href:!0});var j8t=s(CD);u1o=r(j8t,"SwinConfig"),j8t.forEach(t),p1o=r(uqe," (Swin Transformer model)"),uqe.forEach(t),_1o=i(L),Wh=n(L,"LI",{});var pqe=s(Wh);bhe=n(pqe,"STRONG",{});var G8t=s(bhe);b1o=r(G8t,"swinv2"),G8t.forEach(t),v1o=r(pqe," \u2014 "),wD=n(pqe,"A",{href:!0});var O8t=s(wD);F1o=r(O8t,"Swinv2Config"),O8t.forEach(t),T1o=r(pqe," (Swin Transformer V2 model)"),pqe.forEach(t),M1o=i(L),Uh=n(L,"LI",{});var _qe=s(Uh);vhe=n(_qe,"STRONG",{});var V8t=s(vhe);E1o=r(V8t,"t5"),V8t.forEach(t),C1o=r(_qe," \u2014 "),AD=n(_qe,"A",{href:!0});var X8t=s(AD);w1o=r(X8t,"T5Config"),X8t.forEach(t),A1o=r(_qe," (T5 model)"),_qe.forEach(t),L1o=i(L),Hh=n(L,"LI",{});var bqe=s(Hh);Fhe=n(bqe,"STRONG",{});var z8t=s(Fhe);y1o=r(z8t,"table-transformer"),z8t.forEach(t),x1o=r(bqe," \u2014 "),LD=n(bqe,"A",{href:!0});var Q8t=s(LD);$1o=r(Q8t,"TableTransformerConfig"),Q8t.forEach(t),k1o=r(bqe," (Table Transformer model)"),bqe.forEach(t),S1o=i(L),Jh=n(L,"LI",{});var vqe=s(Jh);The=n(vqe,"STRONG",{});var W8t=s(The);R1o=r(W8t,"tapas"),W8t.forEach(t),P1o=r(vqe," \u2014 "),yD=n(vqe,"A",{href:!0});var U8t=s(yD);B1o=r(U8t,"TapasConfig"),U8t.forEach(t),I1o=r(vqe," (TAPAS model)"),vqe.forEach(t),N1o=i(L),Yh=n(L,"LI",{});var Fqe=s(Yh);Mhe=n(Fqe,"STRONG",{});var H8t=s(Mhe);q1o=r(H8t,"time_series_transformer"),H8t.forEach(t),D1o=r(Fqe," \u2014 "),xD=n(Fqe,"A",{href:!0});var J8t=s(xD);j1o=r(J8t,"TimeSeriesTransformerConfig"),J8t.forEach(t),G1o=r(Fqe," (Time Series Transformer model)"),Fqe.forEach(t),O1o=i(L),Zh=n(L,"LI",{});var Tqe=s(Zh);Ehe=n(Tqe,"STRONG",{});var Y8t=s(Ehe);V1o=r(Y8t,"trajectory_transformer"),Y8t.forEach(t),X1o=r(Tqe," \u2014 "),$D=n(Tqe,"A",{href:!0});var Z8t=s($D);z1o=r(Z8t,"TrajectoryTransformerConfig"),Z8t.forEach(t),Q1o=r(Tqe," (Trajectory Transformer model)"),Tqe.forEach(t),W1o=i(L),Kh=n(L,"LI",{});var Mqe=s(Kh);Che=n(Mqe,"STRONG",{});var K8t=s(Che);U1o=r(K8t,"transfo-xl"),K8t.forEach(t),H1o=r(Mqe," \u2014 "),kD=n(Mqe,"A",{href:!0});var eLt=s(kD);J1o=r(eLt,"TransfoXLConfig"),eLt.forEach(t),Y1o=r(Mqe," (Transformer-XL model)"),Mqe.forEach(t),Z1o=i(L),eu=n(L,"LI",{});var Eqe=s(eu);whe=n(Eqe,"STRONG",{});var oLt=s(whe);K1o=r(oLt,"trocr"),oLt.forEach(t),e2o=r(Eqe," \u2014 "),SD=n(Eqe,"A",{href:!0});var rLt=s(SD);o2o=r(rLt,"TrOCRConfig"),rLt.forEach(t),r2o=r(Eqe," (TrOCR model)"),Eqe.forEach(t),t2o=i(L),ou=n(L,"LI",{});var Cqe=s(ou);Ahe=n(Cqe,"STRONG",{});var tLt=s(Ahe);a2o=r(tLt,"unispeech"),tLt.forEach(t),n2o=r(Cqe," \u2014 "),RD=n(Cqe,"A",{href:!0});var aLt=s(RD);s2o=r(aLt,"UniSpeechConfig"),aLt.forEach(t),l2o=r(Cqe," (UniSpeech model)"),Cqe.forEach(t),i2o=i(L),ru=n(L,"LI",{});var wqe=s(ru);Lhe=n(wqe,"STRONG",{});var nLt=s(Lhe);d2o=r(nLt,"unispeech-sat"),nLt.forEach(t),m2o=r(wqe," \u2014 "),PD=n(wqe,"A",{href:!0});var sLt=s(PD);c2o=r(sLt,"UniSpeechSatConfig"),sLt.forEach(t),f2o=r(wqe," (UniSpeechSat model)"),wqe.forEach(t),g2o=i(L),tu=n(L,"LI",{});var Aqe=s(tu);yhe=n(Aqe,"STRONG",{});var lLt=s(yhe);h2o=r(lLt,"van"),lLt.forEach(t),u2o=r(Aqe," \u2014 "),BD=n(Aqe,"A",{href:!0});var iLt=s(BD);p2o=r(iLt,"VanConfig"),iLt.forEach(t),_2o=r(Aqe," (VAN model)"),Aqe.forEach(t),b2o=i(L),au=n(L,"LI",{});var Lqe=s(au);xhe=n(Lqe,"STRONG",{});var dLt=s(xhe);v2o=r(dLt,"videomae"),dLt.forEach(t),F2o=r(Lqe," \u2014 "),ID=n(Lqe,"A",{href:!0});var mLt=s(ID);T2o=r(mLt,"VideoMAEConfig"),mLt.forEach(t),M2o=r(Lqe," (VideoMAE model)"),Lqe.forEach(t),E2o=i(L),nu=n(L,"LI",{});var yqe=s(nu);$he=n(yqe,"STRONG",{});var cLt=s($he);C2o=r(cLt,"vilt"),cLt.forEach(t),w2o=r(yqe," \u2014 "),ND=n(yqe,"A",{href:!0});var fLt=s(ND);A2o=r(fLt,"ViltConfig"),fLt.forEach(t),L2o=r(yqe," (ViLT model)"),yqe.forEach(t),y2o=i(L),su=n(L,"LI",{});var xqe=s(su);khe=n(xqe,"STRONG",{});var gLt=s(khe);x2o=r(gLt,"vision-encoder-decoder"),gLt.forEach(t),$2o=r(xqe," \u2014 "),qD=n(xqe,"A",{href:!0});var hLt=s(qD);k2o=r(hLt,"VisionEncoderDecoderConfig"),hLt.forEach(t),S2o=r(xqe," (Vision Encoder decoder model)"),xqe.forEach(t),R2o=i(L),lu=n(L,"LI",{});var $qe=s(lu);She=n($qe,"STRONG",{});var uLt=s(She);P2o=r(uLt,"vision-text-dual-encoder"),uLt.forEach(t),B2o=r($qe," \u2014 "),DD=n($qe,"A",{href:!0});var pLt=s(DD);I2o=r(pLt,"VisionTextDualEncoderConfig"),pLt.forEach(t),N2o=r($qe," (VisionTextDualEncoder model)"),$qe.forEach(t),q2o=i(L),iu=n(L,"LI",{});var kqe=s(iu);Rhe=n(kqe,"STRONG",{});var _Lt=s(Rhe);D2o=r(_Lt,"visual_bert"),_Lt.forEach(t),j2o=r(kqe," \u2014 "),jD=n(kqe,"A",{href:!0});var bLt=s(jD);G2o=r(bLt,"VisualBertConfig"),bLt.forEach(t),O2o=r(kqe," (VisualBERT model)"),kqe.forEach(t),V2o=i(L),du=n(L,"LI",{});var Sqe=s(du);Phe=n(Sqe,"STRONG",{});var vLt=s(Phe);X2o=r(vLt,"vit"),vLt.forEach(t),z2o=r(Sqe," \u2014 "),GD=n(Sqe,"A",{href:!0});var FLt=s(GD);Q2o=r(FLt,"ViTConfig"),FLt.forEach(t),W2o=r(Sqe," (ViT model)"),Sqe.forEach(t),U2o=i(L),mu=n(L,"LI",{});var Rqe=s(mu);Bhe=n(Rqe,"STRONG",{});var TLt=s(Bhe);H2o=r(TLt,"vit_mae"),TLt.forEach(t),J2o=r(Rqe," \u2014 "),OD=n(Rqe,"A",{href:!0});var MLt=s(OD);Y2o=r(MLt,"ViTMAEConfig"),MLt.forEach(t),Z2o=r(Rqe," (ViTMAE model)"),Rqe.forEach(t),K2o=i(L),cu=n(L,"LI",{});var Pqe=s(cu);Ihe=n(Pqe,"STRONG",{});var ELt=s(Ihe);ebo=r(ELt,"vit_msn"),ELt.forEach(t),obo=r(Pqe," \u2014 "),VD=n(Pqe,"A",{href:!0});var CLt=s(VD);rbo=r(CLt,"ViTMSNConfig"),CLt.forEach(t),tbo=r(Pqe," (ViTMSN model)"),Pqe.forEach(t),abo=i(L),fu=n(L,"LI",{});var Bqe=s(fu);Nhe=n(Bqe,"STRONG",{});var wLt=s(Nhe);nbo=r(wLt,"wav2vec2"),wLt.forEach(t),sbo=r(Bqe," \u2014 "),XD=n(Bqe,"A",{href:!0});var ALt=s(XD);lbo=r(ALt,"Wav2Vec2Config"),ALt.forEach(t),ibo=r(Bqe," (Wav2Vec2 model)"),Bqe.forEach(t),dbo=i(L),gu=n(L,"LI",{});var Iqe=s(gu);qhe=n(Iqe,"STRONG",{});var LLt=s(qhe);mbo=r(LLt,"wav2vec2-conformer"),LLt.forEach(t),cbo=r(Iqe," \u2014 "),zD=n(Iqe,"A",{href:!0});var yLt=s(zD);fbo=r(yLt,"Wav2Vec2ConformerConfig"),yLt.forEach(t),gbo=r(Iqe," (Wav2Vec2-Conformer model)"),Iqe.forEach(t),hbo=i(L),hu=n(L,"LI",{});var Nqe=s(hu);Dhe=n(Nqe,"STRONG",{});var xLt=s(Dhe);ubo=r(xLt,"wavlm"),xLt.forEach(t),pbo=r(Nqe," \u2014 "),QD=n(Nqe,"A",{href:!0});var $Lt=s(QD);_bo=r($Lt,"WavLMConfig"),$Lt.forEach(t),bbo=r(Nqe," (WavLM model)"),Nqe.forEach(t),vbo=i(L),uu=n(L,"LI",{});var qqe=s(uu);jhe=n(qqe,"STRONG",{});var kLt=s(jhe);Fbo=r(kLt,"whisper"),kLt.forEach(t),Tbo=r(qqe," \u2014 "),WD=n(qqe,"A",{href:!0});var SLt=s(WD);Mbo=r(SLt,"WhisperConfig"),SLt.forEach(t),Ebo=r(qqe," (Whisper model)"),qqe.forEach(t),Cbo=i(L),pu=n(L,"LI",{});var Dqe=s(pu);Ghe=n(Dqe,"STRONG",{});var RLt=s(Ghe);wbo=r(RLt,"xclip"),RLt.forEach(t),Abo=r(Dqe," \u2014 "),UD=n(Dqe,"A",{href:!0});var PLt=s(UD);Lbo=r(PLt,"XCLIPConfig"),PLt.forEach(t),ybo=r(Dqe," (X-CLIP model)"),Dqe.forEach(t),xbo=i(L),_u=n(L,"LI",{});var jqe=s(_u);Ohe=n(jqe,"STRONG",{});var BLt=s(Ohe);$bo=r(BLt,"xglm"),BLt.forEach(t),kbo=r(jqe," \u2014 "),HD=n(jqe,"A",{href:!0});var ILt=s(HD);Sbo=r(ILt,"XGLMConfig"),ILt.forEach(t),Rbo=r(jqe," (XGLM model)"),jqe.forEach(t),Pbo=i(L),bu=n(L,"LI",{});var Gqe=s(bu);Vhe=n(Gqe,"STRONG",{});var NLt=s(Vhe);Bbo=r(NLt,"xlm"),NLt.forEach(t),Ibo=r(Gqe," \u2014 "),JD=n(Gqe,"A",{href:!0});var qLt=s(JD);Nbo=r(qLt,"XLMConfig"),qLt.forEach(t),qbo=r(Gqe," (XLM model)"),Gqe.forEach(t),Dbo=i(L),vu=n(L,"LI",{});var Oqe=s(vu);Xhe=n(Oqe,"STRONG",{});var DLt=s(Xhe);jbo=r(DLt,"xlm-prophetnet"),DLt.forEach(t),Gbo=r(Oqe," \u2014 "),YD=n(Oqe,"A",{href:!0});var jLt=s(YD);Obo=r(jLt,"XLMProphetNetConfig"),jLt.forEach(t),Vbo=r(Oqe," (XLM-ProphetNet model)"),Oqe.forEach(t),Xbo=i(L),Fu=n(L,"LI",{});var Vqe=s(Fu);zhe=n(Vqe,"STRONG",{});var GLt=s(zhe);zbo=r(GLt,"xlm-roberta"),GLt.forEach(t),Qbo=r(Vqe," \u2014 "),ZD=n(Vqe,"A",{href:!0});var OLt=s(ZD);Wbo=r(OLt,"XLMRobertaConfig"),OLt.forEach(t),Ubo=r(Vqe," (XLM-RoBERTa model)"),Vqe.forEach(t),Hbo=i(L),Tu=n(L,"LI",{});var Xqe=s(Tu);Qhe=n(Xqe,"STRONG",{});var VLt=s(Qhe);Jbo=r(VLt,"xlm-roberta-xl"),VLt.forEach(t),Ybo=r(Xqe," \u2014 "),KD=n(Xqe,"A",{href:!0});var XLt=s(KD);Zbo=r(XLt,"XLMRobertaXLConfig"),XLt.forEach(t),Kbo=r(Xqe," (XLM-RoBERTa-XL model)"),Xqe.forEach(t),evo=i(L),Mu=n(L,"LI",{});var zqe=s(Mu);Whe=n(zqe,"STRONG",{});var zLt=s(Whe);ovo=r(zLt,"xlnet"),zLt.forEach(t),rvo=r(zqe," \u2014 "),ej=n(zqe,"A",{href:!0});var QLt=s(ej);tvo=r(QLt,"XLNetConfig"),QLt.forEach(t),avo=r(zqe," (XLNet model)"),zqe.forEach(t),nvo=i(L),Eu=n(L,"LI",{});var Qqe=s(Eu);Uhe=n(Qqe,"STRONG",{});var WLt=s(Uhe);svo=r(WLt,"yolos"),WLt.forEach(t),lvo=r(Qqe," \u2014 "),oj=n(Qqe,"A",{href:!0});var ULt=s(oj);ivo=r(ULt,"YolosConfig"),ULt.forEach(t),dvo=r(Qqe," (YOLOS model)"),Qqe.forEach(t),mvo=i(L),Cu=n(L,"LI",{});var Wqe=s(Cu);Hhe=n(Wqe,"STRONG",{});var HLt=s(Hhe);cvo=r(HLt,"yoso"),HLt.forEach(t),fvo=r(Wqe," \u2014 "),rj=n(Wqe,"A",{href:!0});var JLt=s(rj);gvo=r(JLt,"YosoConfig"),JLt.forEach(t),hvo=r(Wqe," (YOSO model)"),Wqe.forEach(t),L.forEach(t),uvo=i(Ft),T(wu.$$.fragment,Ft),Ft.forEach(t),pvo=i(vt),Au=n(vt,"DIV",{class:!0});var Wno=s(Au);T(_$.$$.fragment,Wno),_vo=i(Wno),Jhe=n(Wno,"P",{});var YLt=s(Jhe);bvo=r(YLt,"Register a new configuration for this class."),YLt.forEach(t),Wno.forEach(t),vt.forEach(t),Ito=i(c),yd=n(c,"H2",{class:!0});var Uno=s(yd);Lu=n(Uno,"A",{id:!0,class:!0,href:!0});var ZLt=s(Lu);Yhe=n(ZLt,"SPAN",{});var KLt=s(Yhe);T(b$.$$.fragment,KLt),KLt.forEach(t),ZLt.forEach(t),vvo=i(Uno),Zhe=n(Uno,"SPAN",{});var eyt=s(Zhe);Fvo=r(eyt,"AutoTokenizer"),eyt.forEach(t),Uno.forEach(t),Nto=i(c),Ro=n(c,"DIV",{class:!0});var Pl=s(Ro);T(v$.$$.fragment,Pl),Tvo=i(Pl),F$=n(Pl,"P",{});var Hno=s(F$);Mvo=r(Hno,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),tj=n(Hno,"A",{href:!0});var oyt=s(tj);Evo=r(oyt,"AutoTokenizer.from_pretrained()"),oyt.forEach(t),Cvo=r(Hno," class method."),Hno.forEach(t),wvo=i(Pl),T$=n(Pl,"P",{});var Jno=s(T$);Avo=r(Jno,"This class cannot be instantiated directly using "),Khe=n(Jno,"CODE",{});var ryt=s(Khe);Lvo=r(ryt,"__init__()"),ryt.forEach(t),yvo=r(Jno," (throws an error)."),Jno.forEach(t),xvo=i(Pl),Dr=n(Pl,"DIV",{class:!0});var Bl=s(Dr);T(M$.$$.fragment,Bl),$vo=i(Bl),eue=n(Bl,"P",{});var tyt=s(eue);kvo=r(tyt,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),tyt.forEach(t),Svo=i(Bl),tn=n(Bl,"P",{});var Ky=s(tn);Rvo=r(Ky,"The tokenizer class to instantiate is selected based on the "),oue=n(Ky,"CODE",{});var ayt=s(oue);Pvo=r(ayt,"model_type"),ayt.forEach(t),Bvo=r(Ky,` property of the config object (either
passed as an argument or loaded from `),rue=n(Ky,"CODE",{});var nyt=s(rue);Ivo=r(nyt,"pretrained_model_name_or_path"),nyt.forEach(t),Nvo=r(Ky,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tue=n(Ky,"CODE",{});var syt=s(tue);qvo=r(syt,"pretrained_model_name_or_path"),syt.forEach(t),Dvo=r(Ky,":"),Ky.forEach(t),jvo=i(Bl),k=n(Bl,"UL",{});var S=s(k);us=n(S,"LI",{});var aI=s(us);aue=n(aI,"STRONG",{});var lyt=s(aue);Gvo=r(lyt,"albert"),lyt.forEach(t),Ovo=r(aI," \u2014 "),aj=n(aI,"A",{href:!0});var iyt=s(aj);Vvo=r(iyt,"AlbertTokenizer"),iyt.forEach(t),Xvo=r(aI," or "),nj=n(aI,"A",{href:!0});var dyt=s(nj);zvo=r(dyt,"AlbertTokenizerFast"),dyt.forEach(t),Qvo=r(aI," (ALBERT model)"),aI.forEach(t),Wvo=i(S),ps=n(S,"LI",{});var nI=s(ps);nue=n(nI,"STRONG",{});var myt=s(nue);Uvo=r(myt,"bart"),myt.forEach(t),Hvo=r(nI," \u2014 "),sj=n(nI,"A",{href:!0});var cyt=s(sj);Jvo=r(cyt,"BartTokenizer"),cyt.forEach(t),Yvo=r(nI," or "),lj=n(nI,"A",{href:!0});var fyt=s(lj);Zvo=r(fyt,"BartTokenizerFast"),fyt.forEach(t),Kvo=r(nI," (BART model)"),nI.forEach(t),eFo=i(S),_s=n(S,"LI",{});var sI=s(_s);sue=n(sI,"STRONG",{});var gyt=s(sue);oFo=r(gyt,"barthez"),gyt.forEach(t),rFo=r(sI," \u2014 "),ij=n(sI,"A",{href:!0});var hyt=s(ij);tFo=r(hyt,"BarthezTokenizer"),hyt.forEach(t),aFo=r(sI," or "),dj=n(sI,"A",{href:!0});var uyt=s(dj);nFo=r(uyt,"BarthezTokenizerFast"),uyt.forEach(t),sFo=r(sI," (BARThez model)"),sI.forEach(t),lFo=i(S),yu=n(S,"LI",{});var Uqe=s(yu);lue=n(Uqe,"STRONG",{});var pyt=s(lue);iFo=r(pyt,"bartpho"),pyt.forEach(t),dFo=r(Uqe," \u2014 "),mj=n(Uqe,"A",{href:!0});var _yt=s(mj);mFo=r(_yt,"BartphoTokenizer"),_yt.forEach(t),cFo=r(Uqe," (BARTpho model)"),Uqe.forEach(t),fFo=i(S),bs=n(S,"LI",{});var lI=s(bs);iue=n(lI,"STRONG",{});var byt=s(iue);gFo=r(byt,"bert"),byt.forEach(t),hFo=r(lI," \u2014 "),cj=n(lI,"A",{href:!0});var vyt=s(cj);uFo=r(vyt,"BertTokenizer"),vyt.forEach(t),pFo=r(lI," or "),fj=n(lI,"A",{href:!0});var Fyt=s(fj);_Fo=r(Fyt,"BertTokenizerFast"),Fyt.forEach(t),bFo=r(lI," (BERT model)"),lI.forEach(t),vFo=i(S),xu=n(S,"LI",{});var Hqe=s(xu);due=n(Hqe,"STRONG",{});var Tyt=s(due);FFo=r(Tyt,"bert-generation"),Tyt.forEach(t),TFo=r(Hqe," \u2014 "),gj=n(Hqe,"A",{href:!0});var Myt=s(gj);MFo=r(Myt,"BertGenerationTokenizer"),Myt.forEach(t),EFo=r(Hqe," (Bert Generation model)"),Hqe.forEach(t),CFo=i(S),$u=n(S,"LI",{});var Jqe=s($u);mue=n(Jqe,"STRONG",{});var Eyt=s(mue);wFo=r(Eyt,"bert-japanese"),Eyt.forEach(t),AFo=r(Jqe," \u2014 "),hj=n(Jqe,"A",{href:!0});var Cyt=s(hj);LFo=r(Cyt,"BertJapaneseTokenizer"),Cyt.forEach(t),yFo=r(Jqe," (BertJapanese model)"),Jqe.forEach(t),xFo=i(S),ku=n(S,"LI",{});var Yqe=s(ku);cue=n(Yqe,"STRONG",{});var wyt=s(cue);$Fo=r(wyt,"bertweet"),wyt.forEach(t),kFo=r(Yqe," \u2014 "),uj=n(Yqe,"A",{href:!0});var Ayt=s(uj);SFo=r(Ayt,"BertweetTokenizer"),Ayt.forEach(t),RFo=r(Yqe," (BERTweet model)"),Yqe.forEach(t),PFo=i(S),vs=n(S,"LI",{});var iI=s(vs);fue=n(iI,"STRONG",{});var Lyt=s(fue);BFo=r(Lyt,"big_bird"),Lyt.forEach(t),IFo=r(iI," \u2014 "),pj=n(iI,"A",{href:!0});var yyt=s(pj);NFo=r(yyt,"BigBirdTokenizer"),yyt.forEach(t),qFo=r(iI," or "),_j=n(iI,"A",{href:!0});var xyt=s(_j);DFo=r(xyt,"BigBirdTokenizerFast"),xyt.forEach(t),jFo=r(iI," (BigBird model)"),iI.forEach(t),GFo=i(S),Fs=n(S,"LI",{});var dI=s(Fs);gue=n(dI,"STRONG",{});var $yt=s(gue);OFo=r($yt,"bigbird_pegasus"),$yt.forEach(t),VFo=r(dI," \u2014 "),bj=n(dI,"A",{href:!0});var kyt=s(bj);XFo=r(kyt,"PegasusTokenizer"),kyt.forEach(t),zFo=r(dI," or "),vj=n(dI,"A",{href:!0});var Syt=s(vj);QFo=r(Syt,"PegasusTokenizerFast"),Syt.forEach(t),WFo=r(dI," (BigBird-Pegasus model)"),dI.forEach(t),UFo=i(S),Ts=n(S,"LI",{});var mI=s(Ts);hue=n(mI,"STRONG",{});var Ryt=s(hue);HFo=r(Ryt,"blenderbot"),Ryt.forEach(t),JFo=r(mI," \u2014 "),Fj=n(mI,"A",{href:!0});var Pyt=s(Fj);YFo=r(Pyt,"BlenderbotTokenizer"),Pyt.forEach(t),ZFo=r(mI," or "),Tj=n(mI,"A",{href:!0});var Byt=s(Tj);KFo=r(Byt,"BlenderbotTokenizerFast"),Byt.forEach(t),eTo=r(mI," (Blenderbot model)"),mI.forEach(t),oTo=i(S),Su=n(S,"LI",{});var Zqe=s(Su);uue=n(Zqe,"STRONG",{});var Iyt=s(uue);rTo=r(Iyt,"blenderbot-small"),Iyt.forEach(t),tTo=r(Zqe," \u2014 "),Mj=n(Zqe,"A",{href:!0});var Nyt=s(Mj);aTo=r(Nyt,"BlenderbotSmallTokenizer"),Nyt.forEach(t),nTo=r(Zqe," (BlenderbotSmall model)"),Zqe.forEach(t),sTo=i(S),Ru=n(S,"LI",{});var Kqe=s(Ru);pue=n(Kqe,"STRONG",{});var qyt=s(pue);lTo=r(qyt,"bloom"),qyt.forEach(t),iTo=r(Kqe," \u2014 "),Ej=n(Kqe,"A",{href:!0});var Dyt=s(Ej);dTo=r(Dyt,"BloomTokenizerFast"),Dyt.forEach(t),mTo=r(Kqe," (BLOOM model)"),Kqe.forEach(t),cTo=i(S),Pu=n(S,"LI",{});var eDe=s(Pu);_ue=n(eDe,"STRONG",{});var jyt=s(_ue);fTo=r(jyt,"byt5"),jyt.forEach(t),gTo=r(eDe," \u2014 "),Cj=n(eDe,"A",{href:!0});var Gyt=s(Cj);hTo=r(Gyt,"ByT5Tokenizer"),Gyt.forEach(t),uTo=r(eDe," (ByT5 model)"),eDe.forEach(t),pTo=i(S),Ms=n(S,"LI",{});var cI=s(Ms);bue=n(cI,"STRONG",{});var Oyt=s(bue);_To=r(Oyt,"camembert"),Oyt.forEach(t),bTo=r(cI," \u2014 "),wj=n(cI,"A",{href:!0});var Vyt=s(wj);vTo=r(Vyt,"CamembertTokenizer"),Vyt.forEach(t),FTo=r(cI," or "),Aj=n(cI,"A",{href:!0});var Xyt=s(Aj);TTo=r(Xyt,"CamembertTokenizerFast"),Xyt.forEach(t),MTo=r(cI," (CamemBERT model)"),cI.forEach(t),ETo=i(S),Bu=n(S,"LI",{});var oDe=s(Bu);vue=n(oDe,"STRONG",{});var zyt=s(vue);CTo=r(zyt,"canine"),zyt.forEach(t),wTo=r(oDe," \u2014 "),Lj=n(oDe,"A",{href:!0});var Qyt=s(Lj);ATo=r(Qyt,"CanineTokenizer"),Qyt.forEach(t),LTo=r(oDe," (CANINE model)"),oDe.forEach(t),yTo=i(S),Es=n(S,"LI",{});var fI=s(Es);Fue=n(fI,"STRONG",{});var Wyt=s(Fue);xTo=r(Wyt,"clip"),Wyt.forEach(t),$To=r(fI," \u2014 "),yj=n(fI,"A",{href:!0});var Uyt=s(yj);kTo=r(Uyt,"CLIPTokenizer"),Uyt.forEach(t),STo=r(fI," or "),xj=n(fI,"A",{href:!0});var Hyt=s(xj);RTo=r(Hyt,"CLIPTokenizerFast"),Hyt.forEach(t),PTo=r(fI," (CLIP model)"),fI.forEach(t),BTo=i(S),Cs=n(S,"LI",{});var gI=s(Cs);Tue=n(gI,"STRONG",{});var Jyt=s(Tue);ITo=r(Jyt,"codegen"),Jyt.forEach(t),NTo=r(gI," \u2014 "),$j=n(gI,"A",{href:!0});var Yyt=s($j);qTo=r(Yyt,"CodeGenTokenizer"),Yyt.forEach(t),DTo=r(gI," or "),kj=n(gI,"A",{href:!0});var Zyt=s(kj);jTo=r(Zyt,"CodeGenTokenizerFast"),Zyt.forEach(t),GTo=r(gI," (CodeGen model)"),gI.forEach(t),OTo=i(S),ws=n(S,"LI",{});var hI=s(ws);Mue=n(hI,"STRONG",{});var Kyt=s(Mue);VTo=r(Kyt,"convbert"),Kyt.forEach(t),XTo=r(hI," \u2014 "),Sj=n(hI,"A",{href:!0});var e9t=s(Sj);zTo=r(e9t,"ConvBertTokenizer"),e9t.forEach(t),QTo=r(hI," or "),Rj=n(hI,"A",{href:!0});var o9t=s(Rj);WTo=r(o9t,"ConvBertTokenizerFast"),o9t.forEach(t),UTo=r(hI," (ConvBERT model)"),hI.forEach(t),HTo=i(S),As=n(S,"LI",{});var uI=s(As);Eue=n(uI,"STRONG",{});var r9t=s(Eue);JTo=r(r9t,"cpm"),r9t.forEach(t),YTo=r(uI," \u2014 "),Pj=n(uI,"A",{href:!0});var t9t=s(Pj);ZTo=r(t9t,"CpmTokenizer"),t9t.forEach(t),KTo=r(uI," or "),Bj=n(uI,"A",{href:!0});var a9t=s(Bj);eMo=r(a9t,"CpmTokenizerFast"),a9t.forEach(t),oMo=r(uI," (CPM model)"),uI.forEach(t),rMo=i(S),Iu=n(S,"LI",{});var rDe=s(Iu);Cue=n(rDe,"STRONG",{});var n9t=s(Cue);tMo=r(n9t,"ctrl"),n9t.forEach(t),aMo=r(rDe," \u2014 "),Ij=n(rDe,"A",{href:!0});var s9t=s(Ij);nMo=r(s9t,"CTRLTokenizer"),s9t.forEach(t),sMo=r(rDe," (CTRL model)"),rDe.forEach(t),lMo=i(S),Ls=n(S,"LI",{});var pI=s(Ls);wue=n(pI,"STRONG",{});var l9t=s(wue);iMo=r(l9t,"data2vec-text"),l9t.forEach(t),dMo=r(pI," \u2014 "),Nj=n(pI,"A",{href:!0});var i9t=s(Nj);mMo=r(i9t,"RobertaTokenizer"),i9t.forEach(t),cMo=r(pI," or "),qj=n(pI,"A",{href:!0});var d9t=s(qj);fMo=r(d9t,"RobertaTokenizerFast"),d9t.forEach(t),gMo=r(pI," (Data2VecText model)"),pI.forEach(t),hMo=i(S),ys=n(S,"LI",{});var _I=s(ys);Aue=n(_I,"STRONG",{});var m9t=s(Aue);uMo=r(m9t,"deberta"),m9t.forEach(t),pMo=r(_I," \u2014 "),Dj=n(_I,"A",{href:!0});var c9t=s(Dj);_Mo=r(c9t,"DebertaTokenizer"),c9t.forEach(t),bMo=r(_I," or "),jj=n(_I,"A",{href:!0});var f9t=s(jj);vMo=r(f9t,"DebertaTokenizerFast"),f9t.forEach(t),FMo=r(_I," (DeBERTa model)"),_I.forEach(t),TMo=i(S),xs=n(S,"LI",{});var bI=s(xs);Lue=n(bI,"STRONG",{});var g9t=s(Lue);MMo=r(g9t,"deberta-v2"),g9t.forEach(t),EMo=r(bI," \u2014 "),Gj=n(bI,"A",{href:!0});var h9t=s(Gj);CMo=r(h9t,"DebertaV2Tokenizer"),h9t.forEach(t),wMo=r(bI," or "),Oj=n(bI,"A",{href:!0});var u9t=s(Oj);AMo=r(u9t,"DebertaV2TokenizerFast"),u9t.forEach(t),LMo=r(bI," (DeBERTa-v2 model)"),bI.forEach(t),yMo=i(S),$s=n(S,"LI",{});var vI=s($s);yue=n(vI,"STRONG",{});var p9t=s(yue);xMo=r(p9t,"distilbert"),p9t.forEach(t),$Mo=r(vI," \u2014 "),Vj=n(vI,"A",{href:!0});var _9t=s(Vj);kMo=r(_9t,"DistilBertTokenizer"),_9t.forEach(t),SMo=r(vI," or "),Xj=n(vI,"A",{href:!0});var b9t=s(Xj);RMo=r(b9t,"DistilBertTokenizerFast"),b9t.forEach(t),PMo=r(vI," (DistilBERT model)"),vI.forEach(t),BMo=i(S),ks=n(S,"LI",{});var FI=s(ks);xue=n(FI,"STRONG",{});var v9t=s(xue);IMo=r(v9t,"dpr"),v9t.forEach(t),NMo=r(FI," \u2014 "),zj=n(FI,"A",{href:!0});var F9t=s(zj);qMo=r(F9t,"DPRQuestionEncoderTokenizer"),F9t.forEach(t),DMo=r(FI," or "),Qj=n(FI,"A",{href:!0});var T9t=s(Qj);jMo=r(T9t,"DPRQuestionEncoderTokenizerFast"),T9t.forEach(t),GMo=r(FI," (DPR model)"),FI.forEach(t),OMo=i(S),Ss=n(S,"LI",{});var TI=s(Ss);$ue=n(TI,"STRONG",{});var M9t=s($ue);VMo=r(M9t,"electra"),M9t.forEach(t),XMo=r(TI," \u2014 "),Wj=n(TI,"A",{href:!0});var E9t=s(Wj);zMo=r(E9t,"ElectraTokenizer"),E9t.forEach(t),QMo=r(TI," or "),Uj=n(TI,"A",{href:!0});var C9t=s(Uj);WMo=r(C9t,"ElectraTokenizerFast"),C9t.forEach(t),UMo=r(TI," (ELECTRA model)"),TI.forEach(t),HMo=i(S),Rs=n(S,"LI",{});var MI=s(Rs);kue=n(MI,"STRONG",{});var w9t=s(kue);JMo=r(w9t,"ernie"),w9t.forEach(t),YMo=r(MI," \u2014 "),Hj=n(MI,"A",{href:!0});var A9t=s(Hj);ZMo=r(A9t,"BertTokenizer"),A9t.forEach(t),KMo=r(MI," or "),Jj=n(MI,"A",{href:!0});var L9t=s(Jj);eEo=r(L9t,"BertTokenizerFast"),L9t.forEach(t),oEo=r(MI," (ERNIE model)"),MI.forEach(t),rEo=i(S),Nu=n(S,"LI",{});var tDe=s(Nu);Sue=n(tDe,"STRONG",{});var y9t=s(Sue);tEo=r(y9t,"esm"),y9t.forEach(t),aEo=r(tDe," \u2014 "),Yj=n(tDe,"A",{href:!0});var x9t=s(Yj);nEo=r(x9t,"EsmTokenizer"),x9t.forEach(t),sEo=r(tDe," (ESM model)"),tDe.forEach(t),lEo=i(S),qu=n(S,"LI",{});var aDe=s(qu);Rue=n(aDe,"STRONG",{});var $9t=s(Rue);iEo=r($9t,"flaubert"),$9t.forEach(t),dEo=r(aDe," \u2014 "),Zj=n(aDe,"A",{href:!0});var k9t=s(Zj);mEo=r(k9t,"FlaubertTokenizer"),k9t.forEach(t),cEo=r(aDe," (FlauBERT model)"),aDe.forEach(t),fEo=i(S),Ps=n(S,"LI",{});var EI=s(Ps);Pue=n(EI,"STRONG",{});var S9t=s(Pue);gEo=r(S9t,"fnet"),S9t.forEach(t),hEo=r(EI," \u2014 "),Kj=n(EI,"A",{href:!0});var R9t=s(Kj);uEo=r(R9t,"FNetTokenizer"),R9t.forEach(t),pEo=r(EI," or "),eG=n(EI,"A",{href:!0});var P9t=s(eG);_Eo=r(P9t,"FNetTokenizerFast"),P9t.forEach(t),bEo=r(EI," (FNet model)"),EI.forEach(t),vEo=i(S),Du=n(S,"LI",{});var nDe=s(Du);Bue=n(nDe,"STRONG",{});var B9t=s(Bue);FEo=r(B9t,"fsmt"),B9t.forEach(t),TEo=r(nDe," \u2014 "),oG=n(nDe,"A",{href:!0});var I9t=s(oG);MEo=r(I9t,"FSMTTokenizer"),I9t.forEach(t),EEo=r(nDe," (FairSeq Machine-Translation model)"),nDe.forEach(t),CEo=i(S),Bs=n(S,"LI",{});var CI=s(Bs);Iue=n(CI,"STRONG",{});var N9t=s(Iue);wEo=r(N9t,"funnel"),N9t.forEach(t),AEo=r(CI," \u2014 "),rG=n(CI,"A",{href:!0});var q9t=s(rG);LEo=r(q9t,"FunnelTokenizer"),q9t.forEach(t),yEo=r(CI," or "),tG=n(CI,"A",{href:!0});var D9t=s(tG);xEo=r(D9t,"FunnelTokenizerFast"),D9t.forEach(t),$Eo=r(CI," (Funnel Transformer model)"),CI.forEach(t),kEo=i(S),Is=n(S,"LI",{});var wI=s(Is);Nue=n(wI,"STRONG",{});var j9t=s(Nue);SEo=r(j9t,"gpt2"),j9t.forEach(t),REo=r(wI," \u2014 "),aG=n(wI,"A",{href:!0});var G9t=s(aG);PEo=r(G9t,"GPT2Tokenizer"),G9t.forEach(t),BEo=r(wI," or "),nG=n(wI,"A",{href:!0});var O9t=s(nG);IEo=r(O9t,"GPT2TokenizerFast"),O9t.forEach(t),NEo=r(wI," (OpenAI GPT-2 model)"),wI.forEach(t),qEo=i(S),Ns=n(S,"LI",{});var AI=s(Ns);que=n(AI,"STRONG",{});var V9t=s(que);DEo=r(V9t,"gpt_neo"),V9t.forEach(t),jEo=r(AI," \u2014 "),sG=n(AI,"A",{href:!0});var X9t=s(sG);GEo=r(X9t,"GPT2Tokenizer"),X9t.forEach(t),OEo=r(AI," or "),lG=n(AI,"A",{href:!0});var z9t=s(lG);VEo=r(z9t,"GPT2TokenizerFast"),z9t.forEach(t),XEo=r(AI," (GPT Neo model)"),AI.forEach(t),zEo=i(S),ju=n(S,"LI",{});var sDe=s(ju);Due=n(sDe,"STRONG",{});var Q9t=s(Due);QEo=r(Q9t,"gpt_neox"),Q9t.forEach(t),WEo=r(sDe," \u2014 "),iG=n(sDe,"A",{href:!0});var W9t=s(iG);UEo=r(W9t,"GPTNeoXTokenizerFast"),W9t.forEach(t),HEo=r(sDe," (GPT NeoX model)"),sDe.forEach(t),JEo=i(S),Gu=n(S,"LI",{});var lDe=s(Gu);jue=n(lDe,"STRONG",{});var U9t=s(jue);YEo=r(U9t,"gpt_neox_japanese"),U9t.forEach(t),ZEo=r(lDe," \u2014 "),dG=n(lDe,"A",{href:!0});var H9t=s(dG);KEo=r(H9t,"GPTNeoXJapaneseTokenizer"),H9t.forEach(t),e4o=r(lDe," (GPT NeoX Japanese model)"),lDe.forEach(t),o4o=i(S),qs=n(S,"LI",{});var LI=s(qs);Gue=n(LI,"STRONG",{});var J9t=s(Gue);r4o=r(J9t,"gptj"),J9t.forEach(t),t4o=r(LI," \u2014 "),mG=n(LI,"A",{href:!0});var Y9t=s(mG);a4o=r(Y9t,"GPT2Tokenizer"),Y9t.forEach(t),n4o=r(LI," or "),cG=n(LI,"A",{href:!0});var Z9t=s(cG);s4o=r(Z9t,"GPT2TokenizerFast"),Z9t.forEach(t),l4o=r(LI," (GPT-J model)"),LI.forEach(t),i4o=i(S),Ds=n(S,"LI",{});var yI=s(Ds);Oue=n(yI,"STRONG",{});var K9t=s(Oue);d4o=r(K9t,"groupvit"),K9t.forEach(t),m4o=r(yI," \u2014 "),fG=n(yI,"A",{href:!0});var ext=s(fG);c4o=r(ext,"CLIPTokenizer"),ext.forEach(t),f4o=r(yI," or "),gG=n(yI,"A",{href:!0});var oxt=s(gG);g4o=r(oxt,"CLIPTokenizerFast"),oxt.forEach(t),h4o=r(yI," (GroupViT model)"),yI.forEach(t),u4o=i(S),js=n(S,"LI",{});var xI=s(js);Vue=n(xI,"STRONG",{});var rxt=s(Vue);p4o=r(rxt,"herbert"),rxt.forEach(t),_4o=r(xI," \u2014 "),hG=n(xI,"A",{href:!0});var txt=s(hG);b4o=r(txt,"HerbertTokenizer"),txt.forEach(t),v4o=r(xI," or "),uG=n(xI,"A",{href:!0});var axt=s(uG);F4o=r(axt,"HerbertTokenizerFast"),axt.forEach(t),T4o=r(xI," (HerBERT model)"),xI.forEach(t),M4o=i(S),Ou=n(S,"LI",{});var iDe=s(Ou);Xue=n(iDe,"STRONG",{});var nxt=s(Xue);E4o=r(nxt,"hubert"),nxt.forEach(t),C4o=r(iDe," \u2014 "),pG=n(iDe,"A",{href:!0});var sxt=s(pG);w4o=r(sxt,"Wav2Vec2CTCTokenizer"),sxt.forEach(t),A4o=r(iDe," (Hubert model)"),iDe.forEach(t),L4o=i(S),Gs=n(S,"LI",{});var $I=s(Gs);zue=n($I,"STRONG",{});var lxt=s(zue);y4o=r(lxt,"ibert"),lxt.forEach(t),x4o=r($I," \u2014 "),_G=n($I,"A",{href:!0});var ixt=s(_G);$4o=r(ixt,"RobertaTokenizer"),ixt.forEach(t),k4o=r($I," or "),bG=n($I,"A",{href:!0});var dxt=s(bG);S4o=r(dxt,"RobertaTokenizerFast"),dxt.forEach(t),R4o=r($I," (I-BERT model)"),$I.forEach(t),P4o=i(S),Os=n(S,"LI",{});var kI=s(Os);Que=n(kI,"STRONG",{});var mxt=s(Que);B4o=r(mxt,"layoutlm"),mxt.forEach(t),I4o=r(kI," \u2014 "),vG=n(kI,"A",{href:!0});var cxt=s(vG);N4o=r(cxt,"LayoutLMTokenizer"),cxt.forEach(t),q4o=r(kI," or "),FG=n(kI,"A",{href:!0});var fxt=s(FG);D4o=r(fxt,"LayoutLMTokenizerFast"),fxt.forEach(t),j4o=r(kI," (LayoutLM model)"),kI.forEach(t),G4o=i(S),Vs=n(S,"LI",{});var SI=s(Vs);Wue=n(SI,"STRONG",{});var gxt=s(Wue);O4o=r(gxt,"layoutlmv2"),gxt.forEach(t),V4o=r(SI," \u2014 "),TG=n(SI,"A",{href:!0});var hxt=s(TG);X4o=r(hxt,"LayoutLMv2Tokenizer"),hxt.forEach(t),z4o=r(SI," or "),MG=n(SI,"A",{href:!0});var uxt=s(MG);Q4o=r(uxt,"LayoutLMv2TokenizerFast"),uxt.forEach(t),W4o=r(SI," (LayoutLMv2 model)"),SI.forEach(t),U4o=i(S),Xs=n(S,"LI",{});var RI=s(Xs);Uue=n(RI,"STRONG",{});var pxt=s(Uue);H4o=r(pxt,"layoutlmv3"),pxt.forEach(t),J4o=r(RI," \u2014 "),EG=n(RI,"A",{href:!0});var _xt=s(EG);Y4o=r(_xt,"LayoutLMv3Tokenizer"),_xt.forEach(t),Z4o=r(RI," or "),CG=n(RI,"A",{href:!0});var bxt=s(CG);K4o=r(bxt,"LayoutLMv3TokenizerFast"),bxt.forEach(t),eCo=r(RI," (LayoutLMv3 model)"),RI.forEach(t),oCo=i(S),zs=n(S,"LI",{});var PI=s(zs);Hue=n(PI,"STRONG",{});var vxt=s(Hue);rCo=r(vxt,"layoutxlm"),vxt.forEach(t),tCo=r(PI," \u2014 "),wG=n(PI,"A",{href:!0});var Fxt=s(wG);aCo=r(Fxt,"LayoutXLMTokenizer"),Fxt.forEach(t),nCo=r(PI," or "),AG=n(PI,"A",{href:!0});var Txt=s(AG);sCo=r(Txt,"LayoutXLMTokenizerFast"),Txt.forEach(t),lCo=r(PI," (LayoutXLM model)"),PI.forEach(t),iCo=i(S),Qs=n(S,"LI",{});var BI=s(Qs);Jue=n(BI,"STRONG",{});var Mxt=s(Jue);dCo=r(Mxt,"led"),Mxt.forEach(t),mCo=r(BI," \u2014 "),LG=n(BI,"A",{href:!0});var Ext=s(LG);cCo=r(Ext,"LEDTokenizer"),Ext.forEach(t),fCo=r(BI," or "),yG=n(BI,"A",{href:!0});var Cxt=s(yG);gCo=r(Cxt,"LEDTokenizerFast"),Cxt.forEach(t),hCo=r(BI," (LED model)"),BI.forEach(t),uCo=i(S),Ws=n(S,"LI",{});var II=s(Ws);Yue=n(II,"STRONG",{});var wxt=s(Yue);pCo=r(wxt,"lilt"),wxt.forEach(t),_Co=r(II," \u2014 "),xG=n(II,"A",{href:!0});var Axt=s(xG);bCo=r(Axt,"LayoutLMv3Tokenizer"),Axt.forEach(t),vCo=r(II," or "),$G=n(II,"A",{href:!0});var Lxt=s($G);FCo=r(Lxt,"LayoutLMv3TokenizerFast"),Lxt.forEach(t),TCo=r(II," (LiLT model)"),II.forEach(t),MCo=i(S),Us=n(S,"LI",{});var NI=s(Us);Zue=n(NI,"STRONG",{});var yxt=s(Zue);ECo=r(yxt,"longformer"),yxt.forEach(t),CCo=r(NI," \u2014 "),kG=n(NI,"A",{href:!0});var xxt=s(kG);wCo=r(xxt,"LongformerTokenizer"),xxt.forEach(t),ACo=r(NI," or "),SG=n(NI,"A",{href:!0});var $xt=s(SG);LCo=r($xt,"LongformerTokenizerFast"),$xt.forEach(t),yCo=r(NI," (Longformer model)"),NI.forEach(t),xCo=i(S),Hs=n(S,"LI",{});var qI=s(Hs);Kue=n(qI,"STRONG",{});var kxt=s(Kue);$Co=r(kxt,"longt5"),kxt.forEach(t),kCo=r(qI," \u2014 "),RG=n(qI,"A",{href:!0});var Sxt=s(RG);SCo=r(Sxt,"T5Tokenizer"),Sxt.forEach(t),RCo=r(qI," or "),PG=n(qI,"A",{href:!0});var Rxt=s(PG);PCo=r(Rxt,"T5TokenizerFast"),Rxt.forEach(t),BCo=r(qI," (LongT5 model)"),qI.forEach(t),ICo=i(S),Vu=n(S,"LI",{});var dDe=s(Vu);epe=n(dDe,"STRONG",{});var Pxt=s(epe);NCo=r(Pxt,"luke"),Pxt.forEach(t),qCo=r(dDe," \u2014 "),BG=n(dDe,"A",{href:!0});var Bxt=s(BG);DCo=r(Bxt,"LukeTokenizer"),Bxt.forEach(t),jCo=r(dDe," (LUKE model)"),dDe.forEach(t),GCo=i(S),Js=n(S,"LI",{});var DI=s(Js);ope=n(DI,"STRONG",{});var Ixt=s(ope);OCo=r(Ixt,"lxmert"),Ixt.forEach(t),VCo=r(DI," \u2014 "),IG=n(DI,"A",{href:!0});var Nxt=s(IG);XCo=r(Nxt,"LxmertTokenizer"),Nxt.forEach(t),zCo=r(DI," or "),NG=n(DI,"A",{href:!0});var qxt=s(NG);QCo=r(qxt,"LxmertTokenizerFast"),qxt.forEach(t),WCo=r(DI," (LXMERT model)"),DI.forEach(t),UCo=i(S),Xu=n(S,"LI",{});var mDe=s(Xu);rpe=n(mDe,"STRONG",{});var Dxt=s(rpe);HCo=r(Dxt,"m2m_100"),Dxt.forEach(t),JCo=r(mDe," \u2014 "),qG=n(mDe,"A",{href:!0});var jxt=s(qG);YCo=r(jxt,"M2M100Tokenizer"),jxt.forEach(t),ZCo=r(mDe," (M2M100 model)"),mDe.forEach(t),KCo=i(S),zu=n(S,"LI",{});var cDe=s(zu);tpe=n(cDe,"STRONG",{});var Gxt=s(tpe);e3o=r(Gxt,"marian"),Gxt.forEach(t),o3o=r(cDe," \u2014 "),DG=n(cDe,"A",{href:!0});var Oxt=s(DG);r3o=r(Oxt,"MarianTokenizer"),Oxt.forEach(t),t3o=r(cDe," (Marian model)"),cDe.forEach(t),a3o=i(S),Ys=n(S,"LI",{});var jI=s(Ys);ape=n(jI,"STRONG",{});var Vxt=s(ape);n3o=r(Vxt,"mbart"),Vxt.forEach(t),s3o=r(jI," \u2014 "),jG=n(jI,"A",{href:!0});var Xxt=s(jG);l3o=r(Xxt,"MBartTokenizer"),Xxt.forEach(t),i3o=r(jI," or "),GG=n(jI,"A",{href:!0});var zxt=s(GG);d3o=r(zxt,"MBartTokenizerFast"),zxt.forEach(t),m3o=r(jI," (mBART model)"),jI.forEach(t),c3o=i(S),Zs=n(S,"LI",{});var GI=s(Zs);npe=n(GI,"STRONG",{});var Qxt=s(npe);f3o=r(Qxt,"mbart50"),Qxt.forEach(t),g3o=r(GI," \u2014 "),OG=n(GI,"A",{href:!0});var Wxt=s(OG);h3o=r(Wxt,"MBart50Tokenizer"),Wxt.forEach(t),u3o=r(GI," or "),VG=n(GI,"A",{href:!0});var Uxt=s(VG);p3o=r(Uxt,"MBart50TokenizerFast"),Uxt.forEach(t),_3o=r(GI," (mBART-50 model)"),GI.forEach(t),b3o=i(S),Ks=n(S,"LI",{});var OI=s(Ks);spe=n(OI,"STRONG",{});var Hxt=s(spe);v3o=r(Hxt,"megatron-bert"),Hxt.forEach(t),F3o=r(OI," \u2014 "),XG=n(OI,"A",{href:!0});var Jxt=s(XG);T3o=r(Jxt,"BertTokenizer"),Jxt.forEach(t),M3o=r(OI," or "),zG=n(OI,"A",{href:!0});var Yxt=s(zG);E3o=r(Yxt,"BertTokenizerFast"),Yxt.forEach(t),C3o=r(OI," (Megatron-BERT model)"),OI.forEach(t),w3o=i(S),Qu=n(S,"LI",{});var fDe=s(Qu);lpe=n(fDe,"STRONG",{});var Zxt=s(lpe);A3o=r(Zxt,"mluke"),Zxt.forEach(t),L3o=r(fDe," \u2014 "),QG=n(fDe,"A",{href:!0});var Kxt=s(QG);y3o=r(Kxt,"MLukeTokenizer"),Kxt.forEach(t),x3o=r(fDe," (mLUKE model)"),fDe.forEach(t),$3o=i(S),el=n(S,"LI",{});var VI=s(el);ipe=n(VI,"STRONG",{});var e$t=s(ipe);k3o=r(e$t,"mobilebert"),e$t.forEach(t),S3o=r(VI," \u2014 "),WG=n(VI,"A",{href:!0});var o$t=s(WG);R3o=r(o$t,"MobileBertTokenizer"),o$t.forEach(t),P3o=r(VI," or "),UG=n(VI,"A",{href:!0});var r$t=s(UG);B3o=r(r$t,"MobileBertTokenizerFast"),r$t.forEach(t),I3o=r(VI," (MobileBERT model)"),VI.forEach(t),N3o=i(S),ol=n(S,"LI",{});var XI=s(ol);dpe=n(XI,"STRONG",{});var t$t=s(dpe);q3o=r(t$t,"mpnet"),t$t.forEach(t),D3o=r(XI," \u2014 "),HG=n(XI,"A",{href:!0});var a$t=s(HG);j3o=r(a$t,"MPNetTokenizer"),a$t.forEach(t),G3o=r(XI," or "),JG=n(XI,"A",{href:!0});var n$t=s(JG);O3o=r(n$t,"MPNetTokenizerFast"),n$t.forEach(t),V3o=r(XI," (MPNet model)"),XI.forEach(t),X3o=i(S),rl=n(S,"LI",{});var zI=s(rl);mpe=n(zI,"STRONG",{});var s$t=s(mpe);z3o=r(s$t,"mt5"),s$t.forEach(t),Q3o=r(zI," \u2014 "),YG=n(zI,"A",{href:!0});var l$t=s(YG);W3o=r(l$t,"MT5Tokenizer"),l$t.forEach(t),U3o=r(zI," or "),ZG=n(zI,"A",{href:!0});var i$t=s(ZG);H3o=r(i$t,"MT5TokenizerFast"),i$t.forEach(t),J3o=r(zI," (MT5 model)"),zI.forEach(t),Y3o=i(S),tl=n(S,"LI",{});var QI=s(tl);cpe=n(QI,"STRONG",{});var d$t=s(cpe);Z3o=r(d$t,"mvp"),d$t.forEach(t),K3o=r(QI," \u2014 "),KG=n(QI,"A",{href:!0});var m$t=s(KG);e5o=r(m$t,"MvpTokenizer"),m$t.forEach(t),o5o=r(QI," or "),eO=n(QI,"A",{href:!0});var c$t=s(eO);r5o=r(c$t,"MvpTokenizerFast"),c$t.forEach(t),t5o=r(QI," (MVP model)"),QI.forEach(t),a5o=i(S),al=n(S,"LI",{});var WI=s(al);fpe=n(WI,"STRONG",{});var f$t=s(fpe);n5o=r(f$t,"nezha"),f$t.forEach(t),s5o=r(WI," \u2014 "),oO=n(WI,"A",{href:!0});var g$t=s(oO);l5o=r(g$t,"BertTokenizer"),g$t.forEach(t),i5o=r(WI," or "),rO=n(WI,"A",{href:!0});var h$t=s(rO);d5o=r(h$t,"BertTokenizerFast"),h$t.forEach(t),m5o=r(WI," (Nezha model)"),WI.forEach(t),c5o=i(S),nl=n(S,"LI",{});var UI=s(nl);gpe=n(UI,"STRONG",{});var u$t=s(gpe);f5o=r(u$t,"nllb"),u$t.forEach(t),g5o=r(UI," \u2014 "),tO=n(UI,"A",{href:!0});var p$t=s(tO);h5o=r(p$t,"NllbTokenizer"),p$t.forEach(t),u5o=r(UI," or "),aO=n(UI,"A",{href:!0});var _$t=s(aO);p5o=r(_$t,"NllbTokenizerFast"),_$t.forEach(t),_5o=r(UI," (NLLB model)"),UI.forEach(t),b5o=i(S),sl=n(S,"LI",{});var HI=s(sl);hpe=n(HI,"STRONG",{});var b$t=s(hpe);v5o=r(b$t,"nystromformer"),b$t.forEach(t),F5o=r(HI," \u2014 "),nO=n(HI,"A",{href:!0});var v$t=s(nO);T5o=r(v$t,"AlbertTokenizer"),v$t.forEach(t),M5o=r(HI," or "),sO=n(HI,"A",{href:!0});var F$t=s(sO);E5o=r(F$t,"AlbertTokenizerFast"),F$t.forEach(t),C5o=r(HI," (Nystr\xF6mformer model)"),HI.forEach(t),w5o=i(S),ll=n(S,"LI",{});var JI=s(ll);upe=n(JI,"STRONG",{});var T$t=s(upe);A5o=r(T$t,"openai-gpt"),T$t.forEach(t),L5o=r(JI," \u2014 "),lO=n(JI,"A",{href:!0});var M$t=s(lO);y5o=r(M$t,"OpenAIGPTTokenizer"),M$t.forEach(t),x5o=r(JI," or "),iO=n(JI,"A",{href:!0});var E$t=s(iO);$5o=r(E$t,"OpenAIGPTTokenizerFast"),E$t.forEach(t),k5o=r(JI," (OpenAI GPT model)"),JI.forEach(t),S5o=i(S),Wu=n(S,"LI",{});var gDe=s(Wu);ppe=n(gDe,"STRONG",{});var C$t=s(ppe);R5o=r(C$t,"opt"),C$t.forEach(t),P5o=r(gDe," \u2014 "),dO=n(gDe,"A",{href:!0});var w$t=s(dO);B5o=r(w$t,"GPT2Tokenizer"),w$t.forEach(t),I5o=r(gDe," (OPT model)"),gDe.forEach(t),N5o=i(S),il=n(S,"LI",{});var YI=s(il);_pe=n(YI,"STRONG",{});var A$t=s(_pe);q5o=r(A$t,"owlvit"),A$t.forEach(t),D5o=r(YI," \u2014 "),mO=n(YI,"A",{href:!0});var L$t=s(mO);j5o=r(L$t,"CLIPTokenizer"),L$t.forEach(t),G5o=r(YI," or "),cO=n(YI,"A",{href:!0});var y$t=s(cO);O5o=r(y$t,"CLIPTokenizerFast"),y$t.forEach(t),V5o=r(YI," (OWL-ViT model)"),YI.forEach(t),X5o=i(S),dl=n(S,"LI",{});var ZI=s(dl);bpe=n(ZI,"STRONG",{});var x$t=s(bpe);z5o=r(x$t,"pegasus"),x$t.forEach(t),Q5o=r(ZI," \u2014 "),fO=n(ZI,"A",{href:!0});var $$t=s(fO);W5o=r($$t,"PegasusTokenizer"),$$t.forEach(t),U5o=r(ZI," or "),gO=n(ZI,"A",{href:!0});var k$t=s(gO);H5o=r(k$t,"PegasusTokenizerFast"),k$t.forEach(t),J5o=r(ZI," (Pegasus model)"),ZI.forEach(t),Y5o=i(S),ml=n(S,"LI",{});var KI=s(ml);vpe=n(KI,"STRONG",{});var S$t=s(vpe);Z5o=r(S$t,"pegasus_x"),S$t.forEach(t),K5o=r(KI," \u2014 "),hO=n(KI,"A",{href:!0});var R$t=s(hO);e0o=r(R$t,"PegasusTokenizer"),R$t.forEach(t),o0o=r(KI," or "),uO=n(KI,"A",{href:!0});var P$t=s(uO);r0o=r(P$t,"PegasusTokenizerFast"),P$t.forEach(t),t0o=r(KI," (PEGASUS-X model)"),KI.forEach(t),a0o=i(S),Uu=n(S,"LI",{});var hDe=s(Uu);Fpe=n(hDe,"STRONG",{});var B$t=s(Fpe);n0o=r(B$t,"perceiver"),B$t.forEach(t),s0o=r(hDe," \u2014 "),pO=n(hDe,"A",{href:!0});var I$t=s(pO);l0o=r(I$t,"PerceiverTokenizer"),I$t.forEach(t),i0o=r(hDe," (Perceiver model)"),hDe.forEach(t),d0o=i(S),Hu=n(S,"LI",{});var uDe=s(Hu);Tpe=n(uDe,"STRONG",{});var N$t=s(Tpe);m0o=r(N$t,"phobert"),N$t.forEach(t),c0o=r(uDe," \u2014 "),_O=n(uDe,"A",{href:!0});var q$t=s(_O);f0o=r(q$t,"PhobertTokenizer"),q$t.forEach(t),g0o=r(uDe," (PhoBERT model)"),uDe.forEach(t),h0o=i(S),Ju=n(S,"LI",{});var pDe=s(Ju);Mpe=n(pDe,"STRONG",{});var D$t=s(Mpe);u0o=r(D$t,"plbart"),D$t.forEach(t),p0o=r(pDe," \u2014 "),bO=n(pDe,"A",{href:!0});var j$t=s(bO);_0o=r(j$t,"PLBartTokenizer"),j$t.forEach(t),b0o=r(pDe," (PLBart model)"),pDe.forEach(t),v0o=i(S),Yu=n(S,"LI",{});var _De=s(Yu);Epe=n(_De,"STRONG",{});var G$t=s(Epe);F0o=r(G$t,"prophetnet"),G$t.forEach(t),T0o=r(_De," \u2014 "),vO=n(_De,"A",{href:!0});var O$t=s(vO);M0o=r(O$t,"ProphetNetTokenizer"),O$t.forEach(t),E0o=r(_De," (ProphetNet model)"),_De.forEach(t),C0o=i(S),cl=n(S,"LI",{});var eN=s(cl);Cpe=n(eN,"STRONG",{});var V$t=s(Cpe);w0o=r(V$t,"qdqbert"),V$t.forEach(t),A0o=r(eN," \u2014 "),FO=n(eN,"A",{href:!0});var X$t=s(FO);L0o=r(X$t,"BertTokenizer"),X$t.forEach(t),y0o=r(eN," or "),TO=n(eN,"A",{href:!0});var z$t=s(TO);x0o=r(z$t,"BertTokenizerFast"),z$t.forEach(t),$0o=r(eN," (QDQBert model)"),eN.forEach(t),k0o=i(S),Zu=n(S,"LI",{});var bDe=s(Zu);wpe=n(bDe,"STRONG",{});var Q$t=s(wpe);S0o=r(Q$t,"rag"),Q$t.forEach(t),R0o=r(bDe," \u2014 "),MO=n(bDe,"A",{href:!0});var W$t=s(MO);P0o=r(W$t,"RagTokenizer"),W$t.forEach(t),B0o=r(bDe," (RAG model)"),bDe.forEach(t),I0o=i(S),fl=n(S,"LI",{});var oN=s(fl);Ape=n(oN,"STRONG",{});var U$t=s(Ape);N0o=r(U$t,"realm"),U$t.forEach(t),q0o=r(oN," \u2014 "),EO=n(oN,"A",{href:!0});var H$t=s(EO);D0o=r(H$t,"RealmTokenizer"),H$t.forEach(t),j0o=r(oN," or "),CO=n(oN,"A",{href:!0});var J$t=s(CO);G0o=r(J$t,"RealmTokenizerFast"),J$t.forEach(t),O0o=r(oN," (REALM model)"),oN.forEach(t),V0o=i(S),gl=n(S,"LI",{});var rN=s(gl);Lpe=n(rN,"STRONG",{});var Y$t=s(Lpe);X0o=r(Y$t,"reformer"),Y$t.forEach(t),z0o=r(rN," \u2014 "),wO=n(rN,"A",{href:!0});var Z$t=s(wO);Q0o=r(Z$t,"ReformerTokenizer"),Z$t.forEach(t),W0o=r(rN," or "),AO=n(rN,"A",{href:!0});var K$t=s(AO);U0o=r(K$t,"ReformerTokenizerFast"),K$t.forEach(t),H0o=r(rN," (Reformer model)"),rN.forEach(t),J0o=i(S),hl=n(S,"LI",{});var tN=s(hl);ype=n(tN,"STRONG",{});var ekt=s(ype);Y0o=r(ekt,"rembert"),ekt.forEach(t),Z0o=r(tN," \u2014 "),LO=n(tN,"A",{href:!0});var okt=s(LO);K0o=r(okt,"RemBertTokenizer"),okt.forEach(t),ewo=r(tN," or "),yO=n(tN,"A",{href:!0});var rkt=s(yO);owo=r(rkt,"RemBertTokenizerFast"),rkt.forEach(t),rwo=r(tN," (RemBERT model)"),tN.forEach(t),two=i(S),ul=n(S,"LI",{});var aN=s(ul);xpe=n(aN,"STRONG",{});var tkt=s(xpe);awo=r(tkt,"retribert"),tkt.forEach(t),nwo=r(aN," \u2014 "),xO=n(aN,"A",{href:!0});var akt=s(xO);swo=r(akt,"RetriBertTokenizer"),akt.forEach(t),lwo=r(aN," or "),$O=n(aN,"A",{href:!0});var nkt=s($O);iwo=r(nkt,"RetriBertTokenizerFast"),nkt.forEach(t),dwo=r(aN," (RetriBERT model)"),aN.forEach(t),mwo=i(S),pl=n(S,"LI",{});var nN=s(pl);$pe=n(nN,"STRONG",{});var skt=s($pe);cwo=r(skt,"roberta"),skt.forEach(t),fwo=r(nN," \u2014 "),kO=n(nN,"A",{href:!0});var lkt=s(kO);gwo=r(lkt,"RobertaTokenizer"),lkt.forEach(t),hwo=r(nN," or "),SO=n(nN,"A",{href:!0});var ikt=s(SO);uwo=r(ikt,"RobertaTokenizerFast"),ikt.forEach(t),pwo=r(nN," (RoBERTa model)"),nN.forEach(t),_wo=i(S),_l=n(S,"LI",{});var sN=s(_l);kpe=n(sN,"STRONG",{});var dkt=s(kpe);bwo=r(dkt,"roformer"),dkt.forEach(t),vwo=r(sN," \u2014 "),RO=n(sN,"A",{href:!0});var mkt=s(RO);Fwo=r(mkt,"RoFormerTokenizer"),mkt.forEach(t),Two=r(sN," or "),PO=n(sN,"A",{href:!0});var ckt=s(PO);Mwo=r(ckt,"RoFormerTokenizerFast"),ckt.forEach(t),Ewo=r(sN," (RoFormer model)"),sN.forEach(t),Cwo=i(S),Ku=n(S,"LI",{});var vDe=s(Ku);Spe=n(vDe,"STRONG",{});var fkt=s(Spe);wwo=r(fkt,"speech_to_text"),fkt.forEach(t),Awo=r(vDe," \u2014 "),BO=n(vDe,"A",{href:!0});var gkt=s(BO);Lwo=r(gkt,"Speech2TextTokenizer"),gkt.forEach(t),ywo=r(vDe," (Speech2Text model)"),vDe.forEach(t),xwo=i(S),ep=n(S,"LI",{});var FDe=s(ep);Rpe=n(FDe,"STRONG",{});var hkt=s(Rpe);$wo=r(hkt,"speech_to_text_2"),hkt.forEach(t),kwo=r(FDe," \u2014 "),IO=n(FDe,"A",{href:!0});var ukt=s(IO);Swo=r(ukt,"Speech2Text2Tokenizer"),ukt.forEach(t),Rwo=r(FDe," (Speech2Text2 model)"),FDe.forEach(t),Pwo=i(S),bl=n(S,"LI",{});var lN=s(bl);Ppe=n(lN,"STRONG",{});var pkt=s(Ppe);Bwo=r(pkt,"splinter"),pkt.forEach(t),Iwo=r(lN," \u2014 "),NO=n(lN,"A",{href:!0});var _kt=s(NO);Nwo=r(_kt,"SplinterTokenizer"),_kt.forEach(t),qwo=r(lN," or "),qO=n(lN,"A",{href:!0});var bkt=s(qO);Dwo=r(bkt,"SplinterTokenizerFast"),bkt.forEach(t),jwo=r(lN," (Splinter model)"),lN.forEach(t),Gwo=i(S),vl=n(S,"LI",{});var iN=s(vl);Bpe=n(iN,"STRONG",{});var vkt=s(Bpe);Owo=r(vkt,"squeezebert"),vkt.forEach(t),Vwo=r(iN," \u2014 "),DO=n(iN,"A",{href:!0});var Fkt=s(DO);Xwo=r(Fkt,"SqueezeBertTokenizer"),Fkt.forEach(t),zwo=r(iN," or "),jO=n(iN,"A",{href:!0});var Tkt=s(jO);Qwo=r(Tkt,"SqueezeBertTokenizerFast"),Tkt.forEach(t),Wwo=r(iN," (SqueezeBERT model)"),iN.forEach(t),Uwo=i(S),Fl=n(S,"LI",{});var dN=s(Fl);Ipe=n(dN,"STRONG",{});var Mkt=s(Ipe);Hwo=r(Mkt,"t5"),Mkt.forEach(t),Jwo=r(dN," \u2014 "),GO=n(dN,"A",{href:!0});var Ekt=s(GO);Ywo=r(Ekt,"T5Tokenizer"),Ekt.forEach(t),Zwo=r(dN," or "),OO=n(dN,"A",{href:!0});var Ckt=s(OO);Kwo=r(Ckt,"T5TokenizerFast"),Ckt.forEach(t),eAo=r(dN," (T5 model)"),dN.forEach(t),oAo=i(S),op=n(S,"LI",{});var TDe=s(op);Npe=n(TDe,"STRONG",{});var wkt=s(Npe);rAo=r(wkt,"tapas"),wkt.forEach(t),tAo=r(TDe," \u2014 "),VO=n(TDe,"A",{href:!0});var Akt=s(VO);aAo=r(Akt,"TapasTokenizer"),Akt.forEach(t),nAo=r(TDe," (TAPAS model)"),TDe.forEach(t),sAo=i(S),rp=n(S,"LI",{});var MDe=s(rp);qpe=n(MDe,"STRONG",{});var Lkt=s(qpe);lAo=r(Lkt,"tapex"),Lkt.forEach(t),iAo=r(MDe," \u2014 "),XO=n(MDe,"A",{href:!0});var ykt=s(XO);dAo=r(ykt,"TapexTokenizer"),ykt.forEach(t),mAo=r(MDe," (TAPEX model)"),MDe.forEach(t),cAo=i(S),tp=n(S,"LI",{});var EDe=s(tp);Dpe=n(EDe,"STRONG",{});var xkt=s(Dpe);fAo=r(xkt,"transfo-xl"),xkt.forEach(t),gAo=r(EDe," \u2014 "),zO=n(EDe,"A",{href:!0});var $kt=s(zO);hAo=r($kt,"TransfoXLTokenizer"),$kt.forEach(t),uAo=r(EDe," (Transformer-XL model)"),EDe.forEach(t),pAo=i(S),Tl=n(S,"LI",{});var mN=s(Tl);jpe=n(mN,"STRONG",{});var kkt=s(jpe);_Ao=r(kkt,"vilt"),kkt.forEach(t),bAo=r(mN," \u2014 "),QO=n(mN,"A",{href:!0});var Skt=s(QO);vAo=r(Skt,"BertTokenizer"),Skt.forEach(t),FAo=r(mN," or "),WO=n(mN,"A",{href:!0});var Rkt=s(WO);TAo=r(Rkt,"BertTokenizerFast"),Rkt.forEach(t),MAo=r(mN," (ViLT model)"),mN.forEach(t),EAo=i(S),Ml=n(S,"LI",{});var cN=s(Ml);Gpe=n(cN,"STRONG",{});var Pkt=s(Gpe);CAo=r(Pkt,"visual_bert"),Pkt.forEach(t),wAo=r(cN," \u2014 "),UO=n(cN,"A",{href:!0});var Bkt=s(UO);AAo=r(Bkt,"BertTokenizer"),Bkt.forEach(t),LAo=r(cN," or "),HO=n(cN,"A",{href:!0});var Ikt=s(HO);yAo=r(Ikt,"BertTokenizerFast"),Ikt.forEach(t),xAo=r(cN," (VisualBERT model)"),cN.forEach(t),$Ao=i(S),ap=n(S,"LI",{});var CDe=s(ap);Ope=n(CDe,"STRONG",{});var Nkt=s(Ope);kAo=r(Nkt,"wav2vec2"),Nkt.forEach(t),SAo=r(CDe," \u2014 "),JO=n(CDe,"A",{href:!0});var qkt=s(JO);RAo=r(qkt,"Wav2Vec2CTCTokenizer"),qkt.forEach(t),PAo=r(CDe," (Wav2Vec2 model)"),CDe.forEach(t),BAo=i(S),np=n(S,"LI",{});var wDe=s(np);Vpe=n(wDe,"STRONG",{});var Dkt=s(Vpe);IAo=r(Dkt,"wav2vec2-conformer"),Dkt.forEach(t),NAo=r(wDe," \u2014 "),YO=n(wDe,"A",{href:!0});var jkt=s(YO);qAo=r(jkt,"Wav2Vec2CTCTokenizer"),jkt.forEach(t),DAo=r(wDe," (Wav2Vec2-Conformer model)"),wDe.forEach(t),jAo=i(S),sp=n(S,"LI",{});var ADe=s(sp);Xpe=n(ADe,"STRONG",{});var Gkt=s(Xpe);GAo=r(Gkt,"wav2vec2_phoneme"),Gkt.forEach(t),OAo=r(ADe," \u2014 "),ZO=n(ADe,"A",{href:!0});var Okt=s(ZO);VAo=r(Okt,"Wav2Vec2PhonemeCTCTokenizer"),Okt.forEach(t),XAo=r(ADe," (Wav2Vec2Phoneme model)"),ADe.forEach(t),zAo=i(S),lp=n(S,"LI",{});var LDe=s(lp);zpe=n(LDe,"STRONG",{});var Vkt=s(zpe);QAo=r(Vkt,"whisper"),Vkt.forEach(t),WAo=r(LDe," \u2014 "),KO=n(LDe,"A",{href:!0});var Xkt=s(KO);UAo=r(Xkt,"WhisperTokenizer"),Xkt.forEach(t),HAo=r(LDe," (Whisper model)"),LDe.forEach(t),JAo=i(S),El=n(S,"LI",{});var fN=s(El);Qpe=n(fN,"STRONG",{});var zkt=s(Qpe);YAo=r(zkt,"xclip"),zkt.forEach(t),ZAo=r(fN," \u2014 "),eV=n(fN,"A",{href:!0});var Qkt=s(eV);KAo=r(Qkt,"CLIPTokenizer"),Qkt.forEach(t),e6o=r(fN," or "),oV=n(fN,"A",{href:!0});var Wkt=s(oV);o6o=r(Wkt,"CLIPTokenizerFast"),Wkt.forEach(t),r6o=r(fN," (X-CLIP model)"),fN.forEach(t),t6o=i(S),Cl=n(S,"LI",{});var gN=s(Cl);Wpe=n(gN,"STRONG",{});var Ukt=s(Wpe);a6o=r(Ukt,"xglm"),Ukt.forEach(t),n6o=r(gN," \u2014 "),rV=n(gN,"A",{href:!0});var Hkt=s(rV);s6o=r(Hkt,"XGLMTokenizer"),Hkt.forEach(t),l6o=r(gN," or "),tV=n(gN,"A",{href:!0});var Jkt=s(tV);i6o=r(Jkt,"XGLMTokenizerFast"),Jkt.forEach(t),d6o=r(gN," (XGLM model)"),gN.forEach(t),m6o=i(S),ip=n(S,"LI",{});var yDe=s(ip);Upe=n(yDe,"STRONG",{});var Ykt=s(Upe);c6o=r(Ykt,"xlm"),Ykt.forEach(t),f6o=r(yDe," \u2014 "),aV=n(yDe,"A",{href:!0});var Zkt=s(aV);g6o=r(Zkt,"XLMTokenizer"),Zkt.forEach(t),h6o=r(yDe," (XLM model)"),yDe.forEach(t),u6o=i(S),dp=n(S,"LI",{});var xDe=s(dp);Hpe=n(xDe,"STRONG",{});var Kkt=s(Hpe);p6o=r(Kkt,"xlm-prophetnet"),Kkt.forEach(t),_6o=r(xDe," \u2014 "),nV=n(xDe,"A",{href:!0});var eSt=s(nV);b6o=r(eSt,"XLMProphetNetTokenizer"),eSt.forEach(t),v6o=r(xDe," (XLM-ProphetNet model)"),xDe.forEach(t),F6o=i(S),wl=n(S,"LI",{});var hN=s(wl);Jpe=n(hN,"STRONG",{});var oSt=s(Jpe);T6o=r(oSt,"xlm-roberta"),oSt.forEach(t),M6o=r(hN," \u2014 "),sV=n(hN,"A",{href:!0});var rSt=s(sV);E6o=r(rSt,"XLMRobertaTokenizer"),rSt.forEach(t),C6o=r(hN," or "),lV=n(hN,"A",{href:!0});var tSt=s(lV);w6o=r(tSt,"XLMRobertaTokenizerFast"),tSt.forEach(t),A6o=r(hN," (XLM-RoBERTa model)"),hN.forEach(t),L6o=i(S),Al=n(S,"LI",{});var uN=s(Al);Ype=n(uN,"STRONG",{});var aSt=s(Ype);y6o=r(aSt,"xlm-roberta-xl"),aSt.forEach(t),x6o=r(uN," \u2014 "),iV=n(uN,"A",{href:!0});var nSt=s(iV);$6o=r(nSt,"XLMRobertaTokenizer"),nSt.forEach(t),k6o=r(uN," or "),dV=n(uN,"A",{href:!0});var sSt=s(dV);S6o=r(sSt,"XLMRobertaTokenizerFast"),sSt.forEach(t),R6o=r(uN," (XLM-RoBERTa-XL model)"),uN.forEach(t),P6o=i(S),Ll=n(S,"LI",{});var pN=s(Ll);Zpe=n(pN,"STRONG",{});var lSt=s(Zpe);B6o=r(lSt,"xlnet"),lSt.forEach(t),I6o=r(pN," \u2014 "),mV=n(pN,"A",{href:!0});var iSt=s(mV);N6o=r(iSt,"XLNetTokenizer"),iSt.forEach(t),q6o=r(pN," or "),cV=n(pN,"A",{href:!0});var dSt=s(cV);D6o=r(dSt,"XLNetTokenizerFast"),dSt.forEach(t),j6o=r(pN," (XLNet model)"),pN.forEach(t),G6o=i(S),yl=n(S,"LI",{});var _N=s(yl);Kpe=n(_N,"STRONG",{});var mSt=s(Kpe);O6o=r(mSt,"yoso"),mSt.forEach(t),V6o=r(_N," \u2014 "),fV=n(_N,"A",{href:!0});var cSt=s(fV);X6o=r(cSt,"AlbertTokenizer"),cSt.forEach(t),z6o=r(_N," or "),gV=n(_N,"A",{href:!0});var fSt=s(gV);Q6o=r(fSt,"AlbertTokenizerFast"),fSt.forEach(t),W6o=r(_N," (YOSO model)"),_N.forEach(t),S.forEach(t),U6o=i(Bl),T(mp.$$.fragment,Bl),Bl.forEach(t),H6o=i(Pl),cp=n(Pl,"DIV",{class:!0});var Yno=s(cp);T(E$.$$.fragment,Yno),J6o=i(Yno),e_e=n(Yno,"P",{});var gSt=s(e_e);Y6o=r(gSt,"Register a new tokenizer in this mapping."),gSt.forEach(t),Yno.forEach(t),Pl.forEach(t),qto=i(c),xd=n(c,"H2",{class:!0});var Zno=s(xd);fp=n(Zno,"A",{id:!0,class:!0,href:!0});var hSt=s(fp);o_e=n(hSt,"SPAN",{});var uSt=s(o_e);T(C$.$$.fragment,uSt),uSt.forEach(t),hSt.forEach(t),Z6o=i(Zno),r_e=n(Zno,"SPAN",{});var pSt=s(r_e);K6o=r(pSt,"AutoFeatureExtractor"),pSt.forEach(t),Zno.forEach(t),Dto=i(c),Po=n(c,"DIV",{class:!0});var Il=s(Po);T(w$.$$.fragment,Il),e7o=i(Il),A$=n(Il,"P",{});var Kno=s(A$);o7o=r(Kno,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),hV=n(Kno,"A",{href:!0});var _St=s(hV);r7o=r(_St,"AutoFeatureExtractor.from_pretrained()"),_St.forEach(t),t7o=r(Kno," class method."),Kno.forEach(t),a7o=i(Il),L$=n(Il,"P",{});var eso=s(L$);n7o=r(eso,"This class cannot be instantiated directly using "),t_e=n(eso,"CODE",{});var bSt=s(t_e);s7o=r(bSt,"__init__()"),bSt.forEach(t),l7o=r(eso," (throws an error)."),eso.forEach(t),i7o=i(Il),Ye=n(Il,"DIV",{class:!0});var wa=s(Ye);T(y$.$$.fragment,wa),d7o=i(wa),a_e=n(wa,"P",{});var vSt=s(a_e);m7o=r(vSt,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),vSt.forEach(t),c7o=i(wa),an=n(wa,"P",{});var e9=s(an);f7o=r(e9,"The feature extractor class to instantiate is selected based on the "),n_e=n(e9,"CODE",{});var FSt=s(n_e);g7o=r(FSt,"model_type"),FSt.forEach(t),h7o=r(e9,` property of the config object
(either passed as an argument or loaded from `),s_e=n(e9,"CODE",{});var TSt=s(s_e);u7o=r(TSt,"pretrained_model_name_or_path"),TSt.forEach(t),p7o=r(e9,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),l_e=n(e9,"CODE",{});var MSt=s(l_e);_7o=r(MSt,"pretrained_model_name_or_path"),MSt.forEach(t),b7o=r(e9,":"),e9.forEach(t),v7o=i(wa),z=n(wa,"UL",{});var Q=s(z);gp=n(Q,"LI",{});var $De=s(gp);i_e=n($De,"STRONG",{});var ESt=s(i_e);F7o=r(ESt,"beit"),ESt.forEach(t),T7o=r($De," \u2014 "),uV=n($De,"A",{href:!0});var CSt=s(uV);M7o=r(CSt,"BeitFeatureExtractor"),CSt.forEach(t),E7o=r($De," (BEiT model)"),$De.forEach(t),C7o=i(Q),hp=n(Q,"LI",{});var kDe=s(hp);d_e=n(kDe,"STRONG",{});var wSt=s(d_e);w7o=r(wSt,"clip"),wSt.forEach(t),A7o=r(kDe," \u2014 "),pV=n(kDe,"A",{href:!0});var ASt=s(pV);L7o=r(ASt,"CLIPFeatureExtractor"),ASt.forEach(t),y7o=r(kDe," (CLIP model)"),kDe.forEach(t),x7o=i(Q),up=n(Q,"LI",{});var SDe=s(up);m_e=n(SDe,"STRONG",{});var LSt=s(m_e);$7o=r(LSt,"conditional_detr"),LSt.forEach(t),k7o=r(SDe," \u2014 "),_V=n(SDe,"A",{href:!0});var ySt=s(_V);S7o=r(ySt,"ConditionalDetrFeatureExtractor"),ySt.forEach(t),R7o=r(SDe," (Conditional DETR model)"),SDe.forEach(t),P7o=i(Q),pp=n(Q,"LI",{});var RDe=s(pp);c_e=n(RDe,"STRONG",{});var xSt=s(c_e);B7o=r(xSt,"convnext"),xSt.forEach(t),I7o=r(RDe," \u2014 "),bV=n(RDe,"A",{href:!0});var $St=s(bV);N7o=r($St,"ConvNextFeatureExtractor"),$St.forEach(t),q7o=r(RDe," (ConvNeXT model)"),RDe.forEach(t),D7o=i(Q),_p=n(Q,"LI",{});var PDe=s(_p);f_e=n(PDe,"STRONG",{});var kSt=s(f_e);j7o=r(kSt,"cvt"),kSt.forEach(t),G7o=r(PDe," \u2014 "),vV=n(PDe,"A",{href:!0});var SSt=s(vV);O7o=r(SSt,"ConvNextFeatureExtractor"),SSt.forEach(t),V7o=r(PDe," (CvT model)"),PDe.forEach(t),X7o=i(Q),bp=n(Q,"LI",{});var BDe=s(bp);g_e=n(BDe,"STRONG",{});var RSt=s(g_e);z7o=r(RSt,"data2vec-audio"),RSt.forEach(t),Q7o=r(BDe," \u2014 "),FV=n(BDe,"A",{href:!0});var PSt=s(FV);W7o=r(PSt,"Wav2Vec2FeatureExtractor"),PSt.forEach(t),U7o=r(BDe," (Data2VecAudio model)"),BDe.forEach(t),H7o=i(Q),vp=n(Q,"LI",{});var IDe=s(vp);h_e=n(IDe,"STRONG",{});var BSt=s(h_e);J7o=r(BSt,"data2vec-vision"),BSt.forEach(t),Y7o=r(IDe," \u2014 "),TV=n(IDe,"A",{href:!0});var ISt=s(TV);Z7o=r(ISt,"BeitFeatureExtractor"),ISt.forEach(t),K7o=r(IDe," (Data2VecVision model)"),IDe.forEach(t),e8o=i(Q),Fp=n(Q,"LI",{});var NDe=s(Fp);u_e=n(NDe,"STRONG",{});var NSt=s(u_e);o8o=r(NSt,"deformable_detr"),NSt.forEach(t),r8o=r(NDe," \u2014 "),MV=n(NDe,"A",{href:!0});var qSt=s(MV);t8o=r(qSt,"DeformableDetrFeatureExtractor"),qSt.forEach(t),a8o=r(NDe," (Deformable DETR model)"),NDe.forEach(t),n8o=i(Q),Tp=n(Q,"LI",{});var qDe=s(Tp);p_e=n(qDe,"STRONG",{});var DSt=s(p_e);s8o=r(DSt,"deit"),DSt.forEach(t),l8o=r(qDe," \u2014 "),EV=n(qDe,"A",{href:!0});var jSt=s(EV);i8o=r(jSt,"DeiTFeatureExtractor"),jSt.forEach(t),d8o=r(qDe," (DeiT model)"),qDe.forEach(t),m8o=i(Q),Mp=n(Q,"LI",{});var DDe=s(Mp);__e=n(DDe,"STRONG",{});var GSt=s(__e);c8o=r(GSt,"detr"),GSt.forEach(t),f8o=r(DDe," \u2014 "),CV=n(DDe,"A",{href:!0});var OSt=s(CV);g8o=r(OSt,"DetrFeatureExtractor"),OSt.forEach(t),h8o=r(DDe," (DETR model)"),DDe.forEach(t),u8o=i(Q),Ep=n(Q,"LI",{});var jDe=s(Ep);b_e=n(jDe,"STRONG",{});var VSt=s(b_e);p8o=r(VSt,"donut"),VSt.forEach(t),_8o=r(jDe," \u2014 "),wV=n(jDe,"A",{href:!0});var XSt=s(wV);b8o=r(XSt,"DonutFeatureExtractor"),XSt.forEach(t),v8o=r(jDe," (Donut model)"),jDe.forEach(t),F8o=i(Q),Cp=n(Q,"LI",{});var GDe=s(Cp);v_e=n(GDe,"STRONG",{});var zSt=s(v_e);T8o=r(zSt,"dpt"),zSt.forEach(t),M8o=r(GDe," \u2014 "),AV=n(GDe,"A",{href:!0});var QSt=s(AV);E8o=r(QSt,"DPTFeatureExtractor"),QSt.forEach(t),C8o=r(GDe," (DPT model)"),GDe.forEach(t),w8o=i(Q),wp=n(Q,"LI",{});var ODe=s(wp);F_e=n(ODe,"STRONG",{});var WSt=s(F_e);A8o=r(WSt,"flava"),WSt.forEach(t),L8o=r(ODe," \u2014 "),LV=n(ODe,"A",{href:!0});var USt=s(LV);y8o=r(USt,"FlavaFeatureExtractor"),USt.forEach(t),x8o=r(ODe," (FLAVA model)"),ODe.forEach(t),$8o=i(Q),Ap=n(Q,"LI",{});var VDe=s(Ap);T_e=n(VDe,"STRONG",{});var HSt=s(T_e);k8o=r(HSt,"glpn"),HSt.forEach(t),S8o=r(VDe," \u2014 "),yV=n(VDe,"A",{href:!0});var JSt=s(yV);R8o=r(JSt,"GLPNFeatureExtractor"),JSt.forEach(t),P8o=r(VDe," (GLPN model)"),VDe.forEach(t),B8o=i(Q),Lp=n(Q,"LI",{});var XDe=s(Lp);M_e=n(XDe,"STRONG",{});var YSt=s(M_e);I8o=r(YSt,"groupvit"),YSt.forEach(t),N8o=r(XDe," \u2014 "),xV=n(XDe,"A",{href:!0});var ZSt=s(xV);q8o=r(ZSt,"CLIPFeatureExtractor"),ZSt.forEach(t),D8o=r(XDe," (GroupViT model)"),XDe.forEach(t),j8o=i(Q),yp=n(Q,"LI",{});var zDe=s(yp);E_e=n(zDe,"STRONG",{});var KSt=s(E_e);G8o=r(KSt,"hubert"),KSt.forEach(t),O8o=r(zDe," \u2014 "),$V=n(zDe,"A",{href:!0});var eRt=s($V);V8o=r(eRt,"Wav2Vec2FeatureExtractor"),eRt.forEach(t),X8o=r(zDe," (Hubert model)"),zDe.forEach(t),z8o=i(Q),xp=n(Q,"LI",{});var QDe=s(xp);C_e=n(QDe,"STRONG",{});var oRt=s(C_e);Q8o=r(oRt,"imagegpt"),oRt.forEach(t),W8o=r(QDe," \u2014 "),kV=n(QDe,"A",{href:!0});var rRt=s(kV);U8o=r(rRt,"ImageGPTFeatureExtractor"),rRt.forEach(t),H8o=r(QDe," (ImageGPT model)"),QDe.forEach(t),J8o=i(Q),$p=n(Q,"LI",{});var WDe=s($p);w_e=n(WDe,"STRONG",{});var tRt=s(w_e);Y8o=r(tRt,"layoutlmv2"),tRt.forEach(t),Z8o=r(WDe," \u2014 "),SV=n(WDe,"A",{href:!0});var aRt=s(SV);K8o=r(aRt,"LayoutLMv2FeatureExtractor"),aRt.forEach(t),eLo=r(WDe," (LayoutLMv2 model)"),WDe.forEach(t),oLo=i(Q),kp=n(Q,"LI",{});var UDe=s(kp);A_e=n(UDe,"STRONG",{});var nRt=s(A_e);rLo=r(nRt,"layoutlmv3"),nRt.forEach(t),tLo=r(UDe," \u2014 "),RV=n(UDe,"A",{href:!0});var sRt=s(RV);aLo=r(sRt,"LayoutLMv3FeatureExtractor"),sRt.forEach(t),nLo=r(UDe," (LayoutLMv3 model)"),UDe.forEach(t),sLo=i(Q),Sp=n(Q,"LI",{});var HDe=s(Sp);L_e=n(HDe,"STRONG",{});var lRt=s(L_e);lLo=r(lRt,"levit"),lRt.forEach(t),iLo=r(HDe," \u2014 "),PV=n(HDe,"A",{href:!0});var iRt=s(PV);dLo=r(iRt,"LevitFeatureExtractor"),iRt.forEach(t),mLo=r(HDe," (LeViT model)"),HDe.forEach(t),cLo=i(Q),Rp=n(Q,"LI",{});var JDe=s(Rp);y_e=n(JDe,"STRONG",{});var dRt=s(y_e);fLo=r(dRt,"maskformer"),dRt.forEach(t),gLo=r(JDe," \u2014 "),BV=n(JDe,"A",{href:!0});var mRt=s(BV);hLo=r(mRt,"MaskFormerFeatureExtractor"),mRt.forEach(t),uLo=r(JDe," (MaskFormer model)"),JDe.forEach(t),pLo=i(Q),Pp=n(Q,"LI",{});var YDe=s(Pp);x_e=n(YDe,"STRONG",{});var cRt=s(x_e);_Lo=r(cRt,"mctct"),cRt.forEach(t),bLo=r(YDe," \u2014 "),IV=n(YDe,"A",{href:!0});var fRt=s(IV);vLo=r(fRt,"MCTCTFeatureExtractor"),fRt.forEach(t),FLo=r(YDe," (M-CTC-T model)"),YDe.forEach(t),TLo=i(Q),Bp=n(Q,"LI",{});var ZDe=s(Bp);$_e=n(ZDe,"STRONG",{});var gRt=s($_e);MLo=r(gRt,"mobilevit"),gRt.forEach(t),ELo=r(ZDe," \u2014 "),NV=n(ZDe,"A",{href:!0});var hRt=s(NV);CLo=r(hRt,"MobileViTFeatureExtractor"),hRt.forEach(t),wLo=r(ZDe," (MobileViT model)"),ZDe.forEach(t),ALo=i(Q),Ip=n(Q,"LI",{});var KDe=s(Ip);k_e=n(KDe,"STRONG",{});var uRt=s(k_e);LLo=r(uRt,"owlvit"),uRt.forEach(t),yLo=r(KDe," \u2014 "),qV=n(KDe,"A",{href:!0});var pRt=s(qV);xLo=r(pRt,"OwlViTFeatureExtractor"),pRt.forEach(t),$Lo=r(KDe," (OWL-ViT model)"),KDe.forEach(t),kLo=i(Q),Np=n(Q,"LI",{});var eje=s(Np);S_e=n(eje,"STRONG",{});var _Rt=s(S_e);SLo=r(_Rt,"perceiver"),_Rt.forEach(t),RLo=r(eje," \u2014 "),DV=n(eje,"A",{href:!0});var bRt=s(DV);PLo=r(bRt,"PerceiverFeatureExtractor"),bRt.forEach(t),BLo=r(eje," (Perceiver model)"),eje.forEach(t),ILo=i(Q),qp=n(Q,"LI",{});var oje=s(qp);R_e=n(oje,"STRONG",{});var vRt=s(R_e);NLo=r(vRt,"poolformer"),vRt.forEach(t),qLo=r(oje," \u2014 "),jV=n(oje,"A",{href:!0});var FRt=s(jV);DLo=r(FRt,"PoolFormerFeatureExtractor"),FRt.forEach(t),jLo=r(oje," (PoolFormer model)"),oje.forEach(t),GLo=i(Q),Dp=n(Q,"LI",{});var rje=s(Dp);P_e=n(rje,"STRONG",{});var TRt=s(P_e);OLo=r(TRt,"regnet"),TRt.forEach(t),VLo=r(rje," \u2014 "),GV=n(rje,"A",{href:!0});var MRt=s(GV);XLo=r(MRt,"ConvNextFeatureExtractor"),MRt.forEach(t),zLo=r(rje," (RegNet model)"),rje.forEach(t),QLo=i(Q),jp=n(Q,"LI",{});var tje=s(jp);B_e=n(tje,"STRONG",{});var ERt=s(B_e);WLo=r(ERt,"resnet"),ERt.forEach(t),ULo=r(tje," \u2014 "),OV=n(tje,"A",{href:!0});var CRt=s(OV);HLo=r(CRt,"ConvNextFeatureExtractor"),CRt.forEach(t),JLo=r(tje," (ResNet model)"),tje.forEach(t),YLo=i(Q),Gp=n(Q,"LI",{});var aje=s(Gp);I_e=n(aje,"STRONG",{});var wRt=s(I_e);ZLo=r(wRt,"segformer"),wRt.forEach(t),KLo=r(aje," \u2014 "),VV=n(aje,"A",{href:!0});var ARt=s(VV);eyo=r(ARt,"SegformerFeatureExtractor"),ARt.forEach(t),oyo=r(aje," (SegFormer model)"),aje.forEach(t),ryo=i(Q),Op=n(Q,"LI",{});var nje=s(Op);N_e=n(nje,"STRONG",{});var LRt=s(N_e);tyo=r(LRt,"speech_to_text"),LRt.forEach(t),ayo=r(nje," \u2014 "),XV=n(nje,"A",{href:!0});var yRt=s(XV);nyo=r(yRt,"Speech2TextFeatureExtractor"),yRt.forEach(t),syo=r(nje," (Speech2Text model)"),nje.forEach(t),lyo=i(Q),Vp=n(Q,"LI",{});var sje=s(Vp);q_e=n(sje,"STRONG",{});var xRt=s(q_e);iyo=r(xRt,"swin"),xRt.forEach(t),dyo=r(sje," \u2014 "),zV=n(sje,"A",{href:!0});var $Rt=s(zV);myo=r($Rt,"ViTFeatureExtractor"),$Rt.forEach(t),cyo=r(sje," (Swin Transformer model)"),sje.forEach(t),fyo=i(Q),Xp=n(Q,"LI",{});var lje=s(Xp);D_e=n(lje,"STRONG",{});var kRt=s(D_e);gyo=r(kRt,"swinv2"),kRt.forEach(t),hyo=r(lje," \u2014 "),QV=n(lje,"A",{href:!0});var SRt=s(QV);uyo=r(SRt,"ViTFeatureExtractor"),SRt.forEach(t),pyo=r(lje," (Swin Transformer V2 model)"),lje.forEach(t),_yo=i(Q),zp=n(Q,"LI",{});var ije=s(zp);j_e=n(ije,"STRONG",{});var RRt=s(j_e);byo=r(RRt,"table-transformer"),RRt.forEach(t),vyo=r(ije," \u2014 "),WV=n(ije,"A",{href:!0});var PRt=s(WV);Fyo=r(PRt,"DetrFeatureExtractor"),PRt.forEach(t),Tyo=r(ije," (Table Transformer model)"),ije.forEach(t),Myo=i(Q),Qp=n(Q,"LI",{});var dje=s(Qp);G_e=n(dje,"STRONG",{});var BRt=s(G_e);Eyo=r(BRt,"van"),BRt.forEach(t),Cyo=r(dje," \u2014 "),UV=n(dje,"A",{href:!0});var IRt=s(UV);wyo=r(IRt,"ConvNextFeatureExtractor"),IRt.forEach(t),Ayo=r(dje," (VAN model)"),dje.forEach(t),Lyo=i(Q),Wp=n(Q,"LI",{});var mje=s(Wp);O_e=n(mje,"STRONG",{});var NRt=s(O_e);yyo=r(NRt,"videomae"),NRt.forEach(t),xyo=r(mje," \u2014 "),HV=n(mje,"A",{href:!0});var qRt=s(HV);$yo=r(qRt,"VideoMAEFeatureExtractor"),qRt.forEach(t),kyo=r(mje," (VideoMAE model)"),mje.forEach(t),Syo=i(Q),Up=n(Q,"LI",{});var cje=s(Up);V_e=n(cje,"STRONG",{});var DRt=s(V_e);Ryo=r(DRt,"vilt"),DRt.forEach(t),Pyo=r(cje," \u2014 "),JV=n(cje,"A",{href:!0});var jRt=s(JV);Byo=r(jRt,"ViltFeatureExtractor"),jRt.forEach(t),Iyo=r(cje," (ViLT model)"),cje.forEach(t),Nyo=i(Q),Hp=n(Q,"LI",{});var fje=s(Hp);X_e=n(fje,"STRONG",{});var GRt=s(X_e);qyo=r(GRt,"vit"),GRt.forEach(t),Dyo=r(fje," \u2014 "),YV=n(fje,"A",{href:!0});var ORt=s(YV);jyo=r(ORt,"ViTFeatureExtractor"),ORt.forEach(t),Gyo=r(fje," (ViT model)"),fje.forEach(t),Oyo=i(Q),Jp=n(Q,"LI",{});var gje=s(Jp);z_e=n(gje,"STRONG",{});var VRt=s(z_e);Vyo=r(VRt,"vit_mae"),VRt.forEach(t),Xyo=r(gje," \u2014 "),ZV=n(gje,"A",{href:!0});var XRt=s(ZV);zyo=r(XRt,"ViTFeatureExtractor"),XRt.forEach(t),Qyo=r(gje," (ViTMAE model)"),gje.forEach(t),Wyo=i(Q),Yp=n(Q,"LI",{});var hje=s(Yp);Q_e=n(hje,"STRONG",{});var zRt=s(Q_e);Uyo=r(zRt,"vit_msn"),zRt.forEach(t),Hyo=r(hje," \u2014 "),KV=n(hje,"A",{href:!0});var QRt=s(KV);Jyo=r(QRt,"ViTFeatureExtractor"),QRt.forEach(t),Yyo=r(hje," (ViTMSN model)"),hje.forEach(t),Zyo=i(Q),Zp=n(Q,"LI",{});var uje=s(Zp);W_e=n(uje,"STRONG",{});var WRt=s(W_e);Kyo=r(WRt,"wav2vec2"),WRt.forEach(t),e9o=r(uje," \u2014 "),eX=n(uje,"A",{href:!0});var URt=s(eX);o9o=r(URt,"Wav2Vec2FeatureExtractor"),URt.forEach(t),r9o=r(uje," (Wav2Vec2 model)"),uje.forEach(t),t9o=i(Q),Kp=n(Q,"LI",{});var pje=s(Kp);U_e=n(pje,"STRONG",{});var HRt=s(U_e);a9o=r(HRt,"wav2vec2-conformer"),HRt.forEach(t),n9o=r(pje," \u2014 "),oX=n(pje,"A",{href:!0});var JRt=s(oX);s9o=r(JRt,"Wav2Vec2FeatureExtractor"),JRt.forEach(t),l9o=r(pje," (Wav2Vec2-Conformer model)"),pje.forEach(t),i9o=i(Q),e_=n(Q,"LI",{});var _je=s(e_);H_e=n(_je,"STRONG",{});var YRt=s(H_e);d9o=r(YRt,"whisper"),YRt.forEach(t),m9o=r(_je," \u2014 "),rX=n(_je,"A",{href:!0});var ZRt=s(rX);c9o=r(ZRt,"WhisperFeatureExtractor"),ZRt.forEach(t),f9o=r(_je," (Whisper model)"),_je.forEach(t),g9o=i(Q),o_=n(Q,"LI",{});var bje=s(o_);J_e=n(bje,"STRONG",{});var KRt=s(J_e);h9o=r(KRt,"xclip"),KRt.forEach(t),u9o=r(bje," \u2014 "),tX=n(bje,"A",{href:!0});var ePt=s(tX);p9o=r(ePt,"CLIPFeatureExtractor"),ePt.forEach(t),_9o=r(bje," (X-CLIP model)"),bje.forEach(t),b9o=i(Q),r_=n(Q,"LI",{});var vje=s(r_);Y_e=n(vje,"STRONG",{});var oPt=s(Y_e);v9o=r(oPt,"yolos"),oPt.forEach(t),F9o=r(vje," \u2014 "),aX=n(vje,"A",{href:!0});var rPt=s(aX);T9o=r(rPt,"YolosFeatureExtractor"),rPt.forEach(t),M9o=r(vje," (YOLOS model)"),vje.forEach(t),Q.forEach(t),E9o=i(wa),T(t_.$$.fragment,wa),C9o=i(wa),T(a_.$$.fragment,wa),wa.forEach(t),w9o=i(Il),n_=n(Il,"DIV",{class:!0});var oso=s(n_);T(x$.$$.fragment,oso),A9o=i(oso),Z_e=n(oso,"P",{});var tPt=s(Z_e);L9o=r(tPt,"Register a new feature extractor for this class."),tPt.forEach(t),oso.forEach(t),Il.forEach(t),jto=i(c),$d=n(c,"H2",{class:!0});var rso=s($d);s_=n(rso,"A",{id:!0,class:!0,href:!0});var aPt=s(s_);K_e=n(aPt,"SPAN",{});var nPt=s(K_e);T($$.$$.fragment,nPt),nPt.forEach(t),aPt.forEach(t),y9o=i(rso),e1e=n(rso,"SPAN",{});var sPt=s(e1e);x9o=r(sPt,"AutoProcessor"),sPt.forEach(t),rso.forEach(t),Gto=i(c),Bo=n(c,"DIV",{class:!0});var Nl=s(Bo);T(k$.$$.fragment,Nl),$9o=i(Nl),S$=n(Nl,"P",{});var tso=s(S$);k9o=r(tso,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),nX=n(tso,"A",{href:!0});var lPt=s(nX);S9o=r(lPt,"AutoProcessor.from_pretrained()"),lPt.forEach(t),R9o=r(tso," class method."),tso.forEach(t),P9o=i(Nl),R$=n(Nl,"P",{});var aso=s(R$);B9o=r(aso,"This class cannot be instantiated directly using "),o1e=n(aso,"CODE",{});var iPt=s(o1e);I9o=r(iPt,"__init__()"),iPt.forEach(t),N9o=r(aso," (throws an error)."),aso.forEach(t),q9o=i(Nl),Ze=n(Nl,"DIV",{class:!0});var Aa=s(Ze);T(P$.$$.fragment,Aa),D9o=i(Aa),r1e=n(Aa,"P",{});var dPt=s(r1e);j9o=r(dPt,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),dPt.forEach(t),G9o=i(Aa),kd=n(Aa,"P",{});var nme=s(kd);O9o=r(nme,"The processor class to instantiate is selected based on the "),t1e=n(nme,"CODE",{});var mPt=s(t1e);V9o=r(mPt,"model_type"),mPt.forEach(t),X9o=r(nme,` property of the config object (either
passed as an argument or loaded from `),a1e=n(nme,"CODE",{});var cPt=s(a1e);z9o=r(cPt,"pretrained_model_name_or_path"),cPt.forEach(t),Q9o=r(nme," if possible):"),nme.forEach(t),W9o=i(Aa),se=n(Aa,"UL",{});var de=s(se);l_=n(de,"LI",{});var Fje=s(l_);n1e=n(Fje,"STRONG",{});var fPt=s(n1e);U9o=r(fPt,"clip"),fPt.forEach(t),H9o=r(Fje," \u2014 "),sX=n(Fje,"A",{href:!0});var gPt=s(sX);J9o=r(gPt,"CLIPProcessor"),gPt.forEach(t),Y9o=r(Fje," (CLIP model)"),Fje.forEach(t),Z9o=i(de),i_=n(de,"LI",{});var Tje=s(i_);s1e=n(Tje,"STRONG",{});var hPt=s(s1e);K9o=r(hPt,"donut"),hPt.forEach(t),exo=r(Tje," \u2014 "),lX=n(Tje,"A",{href:!0});var uPt=s(lX);oxo=r(uPt,"DonutProcessor"),uPt.forEach(t),rxo=r(Tje," (Donut model)"),Tje.forEach(t),txo=i(de),d_=n(de,"LI",{});var Mje=s(d_);l1e=n(Mje,"STRONG",{});var pPt=s(l1e);axo=r(pPt,"flava"),pPt.forEach(t),nxo=r(Mje," \u2014 "),iX=n(Mje,"A",{href:!0});var _Pt=s(iX);sxo=r(_Pt,"FlavaProcessor"),_Pt.forEach(t),lxo=r(Mje," (FLAVA model)"),Mje.forEach(t),ixo=i(de),m_=n(de,"LI",{});var Eje=s(m_);i1e=n(Eje,"STRONG",{});var bPt=s(i1e);dxo=r(bPt,"groupvit"),bPt.forEach(t),mxo=r(Eje," \u2014 "),dX=n(Eje,"A",{href:!0});var vPt=s(dX);cxo=r(vPt,"CLIPProcessor"),vPt.forEach(t),fxo=r(Eje," (GroupViT model)"),Eje.forEach(t),gxo=i(de),c_=n(de,"LI",{});var Cje=s(c_);d1e=n(Cje,"STRONG",{});var FPt=s(d1e);hxo=r(FPt,"layoutlmv2"),FPt.forEach(t),uxo=r(Cje," \u2014 "),mX=n(Cje,"A",{href:!0});var TPt=s(mX);pxo=r(TPt,"LayoutLMv2Processor"),TPt.forEach(t),_xo=r(Cje," (LayoutLMv2 model)"),Cje.forEach(t),bxo=i(de),f_=n(de,"LI",{});var wje=s(f_);m1e=n(wje,"STRONG",{});var MPt=s(m1e);vxo=r(MPt,"layoutlmv3"),MPt.forEach(t),Fxo=r(wje," \u2014 "),cX=n(wje,"A",{href:!0});var EPt=s(cX);Txo=r(EPt,"LayoutLMv3Processor"),EPt.forEach(t),Mxo=r(wje," (LayoutLMv3 model)"),wje.forEach(t),Exo=i(de),g_=n(de,"LI",{});var Aje=s(g_);c1e=n(Aje,"STRONG",{});var CPt=s(c1e);Cxo=r(CPt,"layoutxlm"),CPt.forEach(t),wxo=r(Aje," \u2014 "),fX=n(Aje,"A",{href:!0});var wPt=s(fX);Axo=r(wPt,"LayoutXLMProcessor"),wPt.forEach(t),Lxo=r(Aje," (LayoutXLM model)"),Aje.forEach(t),yxo=i(de),h_=n(de,"LI",{});var Lje=s(h_);f1e=n(Lje,"STRONG",{});var APt=s(f1e);xxo=r(APt,"markuplm"),APt.forEach(t),$xo=r(Lje," \u2014 "),gX=n(Lje,"A",{href:!0});var LPt=s(gX);kxo=r(LPt,"MarkupLMProcessor"),LPt.forEach(t),Sxo=r(Lje," (MarkupLM model)"),Lje.forEach(t),Rxo=i(de),u_=n(de,"LI",{});var yje=s(u_);g1e=n(yje,"STRONG",{});var yPt=s(g1e);Pxo=r(yPt,"owlvit"),yPt.forEach(t),Bxo=r(yje," \u2014 "),hX=n(yje,"A",{href:!0});var xPt=s(hX);Ixo=r(xPt,"OwlViTProcessor"),xPt.forEach(t),Nxo=r(yje," (OWL-ViT model)"),yje.forEach(t),qxo=i(de),p_=n(de,"LI",{});var xje=s(p_);h1e=n(xje,"STRONG",{});var $Pt=s(h1e);Dxo=r($Pt,"sew"),$Pt.forEach(t),jxo=r(xje," \u2014 "),uX=n(xje,"A",{href:!0});var kPt=s(uX);Gxo=r(kPt,"Wav2Vec2Processor"),kPt.forEach(t),Oxo=r(xje," (SEW model)"),xje.forEach(t),Vxo=i(de),__=n(de,"LI",{});var $je=s(__);u1e=n($je,"STRONG",{});var SPt=s(u1e);Xxo=r(SPt,"sew-d"),SPt.forEach(t),zxo=r($je," \u2014 "),pX=n($je,"A",{href:!0});var RPt=s(pX);Qxo=r(RPt,"Wav2Vec2Processor"),RPt.forEach(t),Wxo=r($je," (SEW-D model)"),$je.forEach(t),Uxo=i(de),b_=n(de,"LI",{});var kje=s(b_);p1e=n(kje,"STRONG",{});var PPt=s(p1e);Hxo=r(PPt,"speech_to_text"),PPt.forEach(t),Jxo=r(kje," \u2014 "),_X=n(kje,"A",{href:!0});var BPt=s(_X);Yxo=r(BPt,"Speech2TextProcessor"),BPt.forEach(t),Zxo=r(kje," (Speech2Text model)"),kje.forEach(t),Kxo=i(de),v_=n(de,"LI",{});var Sje=s(v_);_1e=n(Sje,"STRONG",{});var IPt=s(_1e);e$o=r(IPt,"speech_to_text_2"),IPt.forEach(t),o$o=r(Sje," \u2014 "),bX=n(Sje,"A",{href:!0});var NPt=s(bX);r$o=r(NPt,"Speech2Text2Processor"),NPt.forEach(t),t$o=r(Sje," (Speech2Text2 model)"),Sje.forEach(t),a$o=i(de),F_=n(de,"LI",{});var Rje=s(F_);b1e=n(Rje,"STRONG",{});var qPt=s(b1e);n$o=r(qPt,"trocr"),qPt.forEach(t),s$o=r(Rje," \u2014 "),vX=n(Rje,"A",{href:!0});var DPt=s(vX);l$o=r(DPt,"TrOCRProcessor"),DPt.forEach(t),i$o=r(Rje," (TrOCR model)"),Rje.forEach(t),d$o=i(de),T_=n(de,"LI",{});var Pje=s(T_);v1e=n(Pje,"STRONG",{});var jPt=s(v1e);m$o=r(jPt,"unispeech"),jPt.forEach(t),c$o=r(Pje," \u2014 "),FX=n(Pje,"A",{href:!0});var GPt=s(FX);f$o=r(GPt,"Wav2Vec2Processor"),GPt.forEach(t),g$o=r(Pje," (UniSpeech model)"),Pje.forEach(t),h$o=i(de),M_=n(de,"LI",{});var Bje=s(M_);F1e=n(Bje,"STRONG",{});var OPt=s(F1e);u$o=r(OPt,"unispeech-sat"),OPt.forEach(t),p$o=r(Bje," \u2014 "),TX=n(Bje,"A",{href:!0});var VPt=s(TX);_$o=r(VPt,"Wav2Vec2Processor"),VPt.forEach(t),b$o=r(Bje," (UniSpeechSat model)"),Bje.forEach(t),v$o=i(de),E_=n(de,"LI",{});var Ije=s(E_);T1e=n(Ije,"STRONG",{});var XPt=s(T1e);F$o=r(XPt,"vilt"),XPt.forEach(t),T$o=r(Ije," \u2014 "),MX=n(Ije,"A",{href:!0});var zPt=s(MX);M$o=r(zPt,"ViltProcessor"),zPt.forEach(t),E$o=r(Ije," (ViLT model)"),Ije.forEach(t),C$o=i(de),C_=n(de,"LI",{});var Nje=s(C_);M1e=n(Nje,"STRONG",{});var QPt=s(M1e);w$o=r(QPt,"vision-text-dual-encoder"),QPt.forEach(t),A$o=r(Nje," \u2014 "),EX=n(Nje,"A",{href:!0});var WPt=s(EX);L$o=r(WPt,"VisionTextDualEncoderProcessor"),WPt.forEach(t),y$o=r(Nje," (VisionTextDualEncoder model)"),Nje.forEach(t),x$o=i(de),w_=n(de,"LI",{});var qje=s(w_);E1e=n(qje,"STRONG",{});var UPt=s(E1e);$$o=r(UPt,"wav2vec2"),UPt.forEach(t),k$o=r(qje," \u2014 "),CX=n(qje,"A",{href:!0});var HPt=s(CX);S$o=r(HPt,"Wav2Vec2Processor"),HPt.forEach(t),R$o=r(qje," (Wav2Vec2 model)"),qje.forEach(t),P$o=i(de),A_=n(de,"LI",{});var Dje=s(A_);C1e=n(Dje,"STRONG",{});var JPt=s(C1e);B$o=r(JPt,"wav2vec2-conformer"),JPt.forEach(t),I$o=r(Dje," \u2014 "),wX=n(Dje,"A",{href:!0});var YPt=s(wX);N$o=r(YPt,"Wav2Vec2Processor"),YPt.forEach(t),q$o=r(Dje," (Wav2Vec2-Conformer model)"),Dje.forEach(t),D$o=i(de),L_=n(de,"LI",{});var jje=s(L_);w1e=n(jje,"STRONG",{});var ZPt=s(w1e);j$o=r(ZPt,"wavlm"),ZPt.forEach(t),G$o=r(jje," \u2014 "),AX=n(jje,"A",{href:!0});var KPt=s(AX);O$o=r(KPt,"Wav2Vec2Processor"),KPt.forEach(t),V$o=r(jje," (WavLM model)"),jje.forEach(t),X$o=i(de),y_=n(de,"LI",{});var Gje=s(y_);A1e=n(Gje,"STRONG",{});var eBt=s(A1e);z$o=r(eBt,"whisper"),eBt.forEach(t),Q$o=r(Gje," \u2014 "),LX=n(Gje,"A",{href:!0});var oBt=s(LX);W$o=r(oBt,"WhisperProcessor"),oBt.forEach(t),U$o=r(Gje," (Whisper model)"),Gje.forEach(t),H$o=i(de),x_=n(de,"LI",{});var Oje=s(x_);L1e=n(Oje,"STRONG",{});var rBt=s(L1e);J$o=r(rBt,"xclip"),rBt.forEach(t),Y$o=r(Oje," \u2014 "),yX=n(Oje,"A",{href:!0});var tBt=s(yX);Z$o=r(tBt,"XCLIPProcessor"),tBt.forEach(t),K$o=r(Oje," (X-CLIP model)"),Oje.forEach(t),de.forEach(t),eko=i(Aa),T($_.$$.fragment,Aa),oko=i(Aa),T(k_.$$.fragment,Aa),Aa.forEach(t),rko=i(Nl),S_=n(Nl,"DIV",{class:!0});var nso=s(S_);T(B$.$$.fragment,nso),tko=i(nso),y1e=n(nso,"P",{});var aBt=s(y1e);ako=r(aBt,"Register a new processor for this class."),aBt.forEach(t),nso.forEach(t),Nl.forEach(t),Oto=i(c),Sd=n(c,"H2",{class:!0});var sso=s(Sd);R_=n(sso,"A",{id:!0,class:!0,href:!0});var nBt=s(R_);x1e=n(nBt,"SPAN",{});var sBt=s(x1e);T(I$.$$.fragment,sBt),sBt.forEach(t),nBt.forEach(t),nko=i(sso),$1e=n(sso,"SPAN",{});var lBt=s($1e);sko=r(lBt,"AutoModel"),lBt.forEach(t),sso.forEach(t),Vto=i(c),Io=n(c,"DIV",{class:!0});var ql=s(Io);T(N$.$$.fragment,ql),lko=i(ql),Rd=n(ql,"P",{});var sme=s(Rd);iko=r(sme,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),xX=n(sme,"A",{href:!0});var iBt=s(xX);dko=r(iBt,"from_pretrained()"),iBt.forEach(t),mko=r(sme," class method or the "),$X=n(sme,"A",{href:!0});var dBt=s($X);cko=r(dBt,"from_config()"),dBt.forEach(t),fko=r(sme,` class
method.`),sme.forEach(t),gko=i(ql),q$=n(ql,"P",{});var lso=s(q$);hko=r(lso,"This class cannot be instantiated directly using "),k1e=n(lso,"CODE",{});var mBt=s(k1e);uko=r(mBt,"__init__()"),mBt.forEach(t),pko=r(lso," (throws an error)."),lso.forEach(t),_ko=i(ql),Mt=n(ql,"DIV",{class:!0});var o9=s(Mt);T(D$.$$.fragment,o9),bko=i(o9),S1e=n(o9,"P",{});var cBt=s(S1e);vko=r(cBt,"Instantiates one of the base model classes of the library from a configuration."),cBt.forEach(t),Fko=i(o9),Pd=n(o9,"P",{});var lme=s(Pd);Tko=r(lme,`Note:
Loading a model from its configuration file does `),R1e=n(lme,"STRONG",{});var fBt=s(R1e);Mko=r(fBt,"not"),fBt.forEach(t),Eko=r(lme,` load the model weights. It only affects the
model\u2019s configuration. Use `),kX=n(lme,"A",{href:!0});var gBt=s(kX);Cko=r(gBt,"from_pretrained()"),gBt.forEach(t),wko=r(lme," to load the model weights."),lme.forEach(t),Ako=i(o9),T(P_.$$.fragment,o9),o9.forEach(t),Lko=i(ql),Ke=n(ql,"DIV",{class:!0});var La=s(Ke);T(j$.$$.fragment,La),yko=i(La),P1e=n(La,"P",{});var hBt=s(P1e);xko=r(hBt,"Instantiate one of the base model classes of the library from a pretrained model."),hBt.forEach(t),$ko=i(La),nn=n(La,"P",{});var r9=s(nn);kko=r(r9,"The model class to instantiate is selected based on the "),B1e=n(r9,"CODE",{});var uBt=s(B1e);Sko=r(uBt,"model_type"),uBt.forEach(t),Rko=r(r9,` property of the config object (either
passed as an argument or loaded from `),I1e=n(r9,"CODE",{});var pBt=s(I1e);Pko=r(pBt,"pretrained_model_name_or_path"),pBt.forEach(t),Bko=r(r9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N1e=n(r9,"CODE",{});var _Bt=s(N1e);Iko=r(_Bt,"pretrained_model_name_or_path"),_Bt.forEach(t),Nko=r(r9,":"),r9.forEach(t),qko=i(La),y=n(La,"UL",{});var x=s(y);B_=n(x,"LI",{});var Vje=s(B_);q1e=n(Vje,"STRONG",{});var bBt=s(q1e);Dko=r(bBt,"albert"),bBt.forEach(t),jko=r(Vje," \u2014 "),SX=n(Vje,"A",{href:!0});var vBt=s(SX);Gko=r(vBt,"AlbertModel"),vBt.forEach(t),Oko=r(Vje," (ALBERT model)"),Vje.forEach(t),Vko=i(x),I_=n(x,"LI",{});var Xje=s(I_);D1e=n(Xje,"STRONG",{});var FBt=s(D1e);Xko=r(FBt,"bart"),FBt.forEach(t),zko=r(Xje," \u2014 "),RX=n(Xje,"A",{href:!0});var TBt=s(RX);Qko=r(TBt,"BartModel"),TBt.forEach(t),Wko=r(Xje," (BART model)"),Xje.forEach(t),Uko=i(x),N_=n(x,"LI",{});var zje=s(N_);j1e=n(zje,"STRONG",{});var MBt=s(j1e);Hko=r(MBt,"beit"),MBt.forEach(t),Jko=r(zje," \u2014 "),PX=n(zje,"A",{href:!0});var EBt=s(PX);Yko=r(EBt,"BeitModel"),EBt.forEach(t),Zko=r(zje," (BEiT model)"),zje.forEach(t),Kko=i(x),q_=n(x,"LI",{});var Qje=s(q_);G1e=n(Qje,"STRONG",{});var CBt=s(G1e);eSo=r(CBt,"bert"),CBt.forEach(t),oSo=r(Qje," \u2014 "),BX=n(Qje,"A",{href:!0});var wBt=s(BX);rSo=r(wBt,"BertModel"),wBt.forEach(t),tSo=r(Qje," (BERT model)"),Qje.forEach(t),aSo=i(x),D_=n(x,"LI",{});var Wje=s(D_);O1e=n(Wje,"STRONG",{});var ABt=s(O1e);nSo=r(ABt,"bert-generation"),ABt.forEach(t),sSo=r(Wje," \u2014 "),IX=n(Wje,"A",{href:!0});var LBt=s(IX);lSo=r(LBt,"BertGenerationEncoder"),LBt.forEach(t),iSo=r(Wje," (Bert Generation model)"),Wje.forEach(t),dSo=i(x),j_=n(x,"LI",{});var Uje=s(j_);V1e=n(Uje,"STRONG",{});var yBt=s(V1e);mSo=r(yBt,"big_bird"),yBt.forEach(t),cSo=r(Uje," \u2014 "),NX=n(Uje,"A",{href:!0});var xBt=s(NX);fSo=r(xBt,"BigBirdModel"),xBt.forEach(t),gSo=r(Uje," (BigBird model)"),Uje.forEach(t),hSo=i(x),G_=n(x,"LI",{});var Hje=s(G_);X1e=n(Hje,"STRONG",{});var $Bt=s(X1e);uSo=r($Bt,"bigbird_pegasus"),$Bt.forEach(t),pSo=r(Hje," \u2014 "),qX=n(Hje,"A",{href:!0});var kBt=s(qX);_So=r(kBt,"BigBirdPegasusModel"),kBt.forEach(t),bSo=r(Hje," (BigBird-Pegasus model)"),Hje.forEach(t),vSo=i(x),O_=n(x,"LI",{});var Jje=s(O_);z1e=n(Jje,"STRONG",{});var SBt=s(z1e);FSo=r(SBt,"blenderbot"),SBt.forEach(t),TSo=r(Jje," \u2014 "),DX=n(Jje,"A",{href:!0});var RBt=s(DX);MSo=r(RBt,"BlenderbotModel"),RBt.forEach(t),ESo=r(Jje," (Blenderbot model)"),Jje.forEach(t),CSo=i(x),V_=n(x,"LI",{});var Yje=s(V_);Q1e=n(Yje,"STRONG",{});var PBt=s(Q1e);wSo=r(PBt,"blenderbot-small"),PBt.forEach(t),ASo=r(Yje," \u2014 "),jX=n(Yje,"A",{href:!0});var BBt=s(jX);LSo=r(BBt,"BlenderbotSmallModel"),BBt.forEach(t),ySo=r(Yje," (BlenderbotSmall model)"),Yje.forEach(t),xSo=i(x),X_=n(x,"LI",{});var Zje=s(X_);W1e=n(Zje,"STRONG",{});var IBt=s(W1e);$So=r(IBt,"bloom"),IBt.forEach(t),kSo=r(Zje," \u2014 "),GX=n(Zje,"A",{href:!0});var NBt=s(GX);SSo=r(NBt,"BloomModel"),NBt.forEach(t),RSo=r(Zje," (BLOOM model)"),Zje.forEach(t),PSo=i(x),z_=n(x,"LI",{});var Kje=s(z_);U1e=n(Kje,"STRONG",{});var qBt=s(U1e);BSo=r(qBt,"camembert"),qBt.forEach(t),ISo=r(Kje," \u2014 "),OX=n(Kje,"A",{href:!0});var DBt=s(OX);NSo=r(DBt,"CamembertModel"),DBt.forEach(t),qSo=r(Kje," (CamemBERT model)"),Kje.forEach(t),DSo=i(x),Q_=n(x,"LI",{});var eGe=s(Q_);H1e=n(eGe,"STRONG",{});var jBt=s(H1e);jSo=r(jBt,"canine"),jBt.forEach(t),GSo=r(eGe," \u2014 "),VX=n(eGe,"A",{href:!0});var GBt=s(VX);OSo=r(GBt,"CanineModel"),GBt.forEach(t),VSo=r(eGe," (CANINE model)"),eGe.forEach(t),XSo=i(x),W_=n(x,"LI",{});var oGe=s(W_);J1e=n(oGe,"STRONG",{});var OBt=s(J1e);zSo=r(OBt,"clip"),OBt.forEach(t),QSo=r(oGe," \u2014 "),XX=n(oGe,"A",{href:!0});var VBt=s(XX);WSo=r(VBt,"CLIPModel"),VBt.forEach(t),USo=r(oGe," (CLIP model)"),oGe.forEach(t),HSo=i(x),U_=n(x,"LI",{});var rGe=s(U_);Y1e=n(rGe,"STRONG",{});var XBt=s(Y1e);JSo=r(XBt,"codegen"),XBt.forEach(t),YSo=r(rGe," \u2014 "),zX=n(rGe,"A",{href:!0});var zBt=s(zX);ZSo=r(zBt,"CodeGenModel"),zBt.forEach(t),KSo=r(rGe," (CodeGen model)"),rGe.forEach(t),eRo=i(x),H_=n(x,"LI",{});var tGe=s(H_);Z1e=n(tGe,"STRONG",{});var QBt=s(Z1e);oRo=r(QBt,"conditional_detr"),QBt.forEach(t),rRo=r(tGe," \u2014 "),QX=n(tGe,"A",{href:!0});var WBt=s(QX);tRo=r(WBt,"ConditionalDetrModel"),WBt.forEach(t),aRo=r(tGe," (Conditional DETR model)"),tGe.forEach(t),nRo=i(x),J_=n(x,"LI",{});var aGe=s(J_);K1e=n(aGe,"STRONG",{});var UBt=s(K1e);sRo=r(UBt,"convbert"),UBt.forEach(t),lRo=r(aGe," \u2014 "),WX=n(aGe,"A",{href:!0});var HBt=s(WX);iRo=r(HBt,"ConvBertModel"),HBt.forEach(t),dRo=r(aGe," (ConvBERT model)"),aGe.forEach(t),mRo=i(x),Y_=n(x,"LI",{});var nGe=s(Y_);e2e=n(nGe,"STRONG",{});var JBt=s(e2e);cRo=r(JBt,"convnext"),JBt.forEach(t),fRo=r(nGe," \u2014 "),UX=n(nGe,"A",{href:!0});var YBt=s(UX);gRo=r(YBt,"ConvNextModel"),YBt.forEach(t),hRo=r(nGe," (ConvNeXT model)"),nGe.forEach(t),uRo=i(x),Z_=n(x,"LI",{});var sGe=s(Z_);o2e=n(sGe,"STRONG",{});var ZBt=s(o2e);pRo=r(ZBt,"ctrl"),ZBt.forEach(t),_Ro=r(sGe," \u2014 "),HX=n(sGe,"A",{href:!0});var KBt=s(HX);bRo=r(KBt,"CTRLModel"),KBt.forEach(t),vRo=r(sGe," (CTRL model)"),sGe.forEach(t),FRo=i(x),K_=n(x,"LI",{});var lGe=s(K_);r2e=n(lGe,"STRONG",{});var eIt=s(r2e);TRo=r(eIt,"cvt"),eIt.forEach(t),MRo=r(lGe," \u2014 "),JX=n(lGe,"A",{href:!0});var oIt=s(JX);ERo=r(oIt,"CvtModel"),oIt.forEach(t),CRo=r(lGe," (CvT model)"),lGe.forEach(t),wRo=i(x),e1=n(x,"LI",{});var iGe=s(e1);t2e=n(iGe,"STRONG",{});var rIt=s(t2e);ARo=r(rIt,"data2vec-audio"),rIt.forEach(t),LRo=r(iGe," \u2014 "),YX=n(iGe,"A",{href:!0});var tIt=s(YX);yRo=r(tIt,"Data2VecAudioModel"),tIt.forEach(t),xRo=r(iGe," (Data2VecAudio model)"),iGe.forEach(t),$Ro=i(x),o1=n(x,"LI",{});var dGe=s(o1);a2e=n(dGe,"STRONG",{});var aIt=s(a2e);kRo=r(aIt,"data2vec-text"),aIt.forEach(t),SRo=r(dGe," \u2014 "),ZX=n(dGe,"A",{href:!0});var nIt=s(ZX);RRo=r(nIt,"Data2VecTextModel"),nIt.forEach(t),PRo=r(dGe," (Data2VecText model)"),dGe.forEach(t),BRo=i(x),r1=n(x,"LI",{});var mGe=s(r1);n2e=n(mGe,"STRONG",{});var sIt=s(n2e);IRo=r(sIt,"data2vec-vision"),sIt.forEach(t),NRo=r(mGe," \u2014 "),KX=n(mGe,"A",{href:!0});var lIt=s(KX);qRo=r(lIt,"Data2VecVisionModel"),lIt.forEach(t),DRo=r(mGe," (Data2VecVision model)"),mGe.forEach(t),jRo=i(x),t1=n(x,"LI",{});var cGe=s(t1);s2e=n(cGe,"STRONG",{});var iIt=s(s2e);GRo=r(iIt,"deberta"),iIt.forEach(t),ORo=r(cGe," \u2014 "),ez=n(cGe,"A",{href:!0});var dIt=s(ez);VRo=r(dIt,"DebertaModel"),dIt.forEach(t),XRo=r(cGe," (DeBERTa model)"),cGe.forEach(t),zRo=i(x),a1=n(x,"LI",{});var fGe=s(a1);l2e=n(fGe,"STRONG",{});var mIt=s(l2e);QRo=r(mIt,"deberta-v2"),mIt.forEach(t),WRo=r(fGe," \u2014 "),oz=n(fGe,"A",{href:!0});var cIt=s(oz);URo=r(cIt,"DebertaV2Model"),cIt.forEach(t),HRo=r(fGe," (DeBERTa-v2 model)"),fGe.forEach(t),JRo=i(x),n1=n(x,"LI",{});var gGe=s(n1);i2e=n(gGe,"STRONG",{});var fIt=s(i2e);YRo=r(fIt,"decision_transformer"),fIt.forEach(t),ZRo=r(gGe," \u2014 "),rz=n(gGe,"A",{href:!0});var gIt=s(rz);KRo=r(gIt,"DecisionTransformerModel"),gIt.forEach(t),ePo=r(gGe," (Decision Transformer model)"),gGe.forEach(t),oPo=i(x),s1=n(x,"LI",{});var hGe=s(s1);d2e=n(hGe,"STRONG",{});var hIt=s(d2e);rPo=r(hIt,"deformable_detr"),hIt.forEach(t),tPo=r(hGe," \u2014 "),tz=n(hGe,"A",{href:!0});var uIt=s(tz);aPo=r(uIt,"DeformableDetrModel"),uIt.forEach(t),nPo=r(hGe," (Deformable DETR model)"),hGe.forEach(t),sPo=i(x),l1=n(x,"LI",{});var uGe=s(l1);m2e=n(uGe,"STRONG",{});var pIt=s(m2e);lPo=r(pIt,"deit"),pIt.forEach(t),iPo=r(uGe," \u2014 "),az=n(uGe,"A",{href:!0});var _It=s(az);dPo=r(_It,"DeiTModel"),_It.forEach(t),mPo=r(uGe," (DeiT model)"),uGe.forEach(t),cPo=i(x),i1=n(x,"LI",{});var pGe=s(i1);c2e=n(pGe,"STRONG",{});var bIt=s(c2e);fPo=r(bIt,"detr"),bIt.forEach(t),gPo=r(pGe," \u2014 "),nz=n(pGe,"A",{href:!0});var vIt=s(nz);hPo=r(vIt,"DetrModel"),vIt.forEach(t),uPo=r(pGe," (DETR model)"),pGe.forEach(t),pPo=i(x),d1=n(x,"LI",{});var _Ge=s(d1);f2e=n(_Ge,"STRONG",{});var FIt=s(f2e);_Po=r(FIt,"distilbert"),FIt.forEach(t),bPo=r(_Ge," \u2014 "),sz=n(_Ge,"A",{href:!0});var TIt=s(sz);vPo=r(TIt,"DistilBertModel"),TIt.forEach(t),FPo=r(_Ge," (DistilBERT model)"),_Ge.forEach(t),TPo=i(x),m1=n(x,"LI",{});var bGe=s(m1);g2e=n(bGe,"STRONG",{});var MIt=s(g2e);MPo=r(MIt,"donut-swin"),MIt.forEach(t),EPo=r(bGe," \u2014 "),lz=n(bGe,"A",{href:!0});var EIt=s(lz);CPo=r(EIt,"DonutSwinModel"),EIt.forEach(t),wPo=r(bGe," (DonutSwin model)"),bGe.forEach(t),APo=i(x),c1=n(x,"LI",{});var vGe=s(c1);h2e=n(vGe,"STRONG",{});var CIt=s(h2e);LPo=r(CIt,"dpr"),CIt.forEach(t),yPo=r(vGe," \u2014 "),iz=n(vGe,"A",{href:!0});var wIt=s(iz);xPo=r(wIt,"DPRQuestionEncoder"),wIt.forEach(t),$Po=r(vGe," (DPR model)"),vGe.forEach(t),kPo=i(x),f1=n(x,"LI",{});var FGe=s(f1);u2e=n(FGe,"STRONG",{});var AIt=s(u2e);SPo=r(AIt,"dpt"),AIt.forEach(t),RPo=r(FGe," \u2014 "),dz=n(FGe,"A",{href:!0});var LIt=s(dz);PPo=r(LIt,"DPTModel"),LIt.forEach(t),BPo=r(FGe," (DPT model)"),FGe.forEach(t),IPo=i(x),g1=n(x,"LI",{});var TGe=s(g1);p2e=n(TGe,"STRONG",{});var yIt=s(p2e);NPo=r(yIt,"electra"),yIt.forEach(t),qPo=r(TGe," \u2014 "),mz=n(TGe,"A",{href:!0});var xIt=s(mz);DPo=r(xIt,"ElectraModel"),xIt.forEach(t),jPo=r(TGe," (ELECTRA model)"),TGe.forEach(t),GPo=i(x),h1=n(x,"LI",{});var MGe=s(h1);_2e=n(MGe,"STRONG",{});var $It=s(_2e);OPo=r($It,"ernie"),$It.forEach(t),VPo=r(MGe," \u2014 "),cz=n(MGe,"A",{href:!0});var kIt=s(cz);XPo=r(kIt,"ErnieModel"),kIt.forEach(t),zPo=r(MGe," (ERNIE model)"),MGe.forEach(t),QPo=i(x),u1=n(x,"LI",{});var EGe=s(u1);b2e=n(EGe,"STRONG",{});var SIt=s(b2e);WPo=r(SIt,"esm"),SIt.forEach(t),UPo=r(EGe," \u2014 "),fz=n(EGe,"A",{href:!0});var RIt=s(fz);HPo=r(RIt,"EsmModel"),RIt.forEach(t),JPo=r(EGe," (ESM model)"),EGe.forEach(t),YPo=i(x),p1=n(x,"LI",{});var CGe=s(p1);v2e=n(CGe,"STRONG",{});var PIt=s(v2e);ZPo=r(PIt,"flaubert"),PIt.forEach(t),KPo=r(CGe," \u2014 "),gz=n(CGe,"A",{href:!0});var BIt=s(gz);eBo=r(BIt,"FlaubertModel"),BIt.forEach(t),oBo=r(CGe," (FlauBERT model)"),CGe.forEach(t),rBo=i(x),_1=n(x,"LI",{});var wGe=s(_1);F2e=n(wGe,"STRONG",{});var IIt=s(F2e);tBo=r(IIt,"flava"),IIt.forEach(t),aBo=r(wGe," \u2014 "),hz=n(wGe,"A",{href:!0});var NIt=s(hz);nBo=r(NIt,"FlavaModel"),NIt.forEach(t),sBo=r(wGe," (FLAVA model)"),wGe.forEach(t),lBo=i(x),b1=n(x,"LI",{});var AGe=s(b1);T2e=n(AGe,"STRONG",{});var qIt=s(T2e);iBo=r(qIt,"fnet"),qIt.forEach(t),dBo=r(AGe," \u2014 "),uz=n(AGe,"A",{href:!0});var DIt=s(uz);mBo=r(DIt,"FNetModel"),DIt.forEach(t),cBo=r(AGe," (FNet model)"),AGe.forEach(t),fBo=i(x),v1=n(x,"LI",{});var LGe=s(v1);M2e=n(LGe,"STRONG",{});var jIt=s(M2e);gBo=r(jIt,"fsmt"),jIt.forEach(t),hBo=r(LGe," \u2014 "),pz=n(LGe,"A",{href:!0});var GIt=s(pz);uBo=r(GIt,"FSMTModel"),GIt.forEach(t),pBo=r(LGe," (FairSeq Machine-Translation model)"),LGe.forEach(t),_Bo=i(x),xl=n(x,"LI",{});var bN=s(xl);E2e=n(bN,"STRONG",{});var OIt=s(E2e);bBo=r(OIt,"funnel"),OIt.forEach(t),vBo=r(bN," \u2014 "),_z=n(bN,"A",{href:!0});var VIt=s(_z);FBo=r(VIt,"FunnelModel"),VIt.forEach(t),TBo=r(bN," or "),bz=n(bN,"A",{href:!0});var XIt=s(bz);MBo=r(XIt,"FunnelBaseModel"),XIt.forEach(t),EBo=r(bN," (Funnel Transformer model)"),bN.forEach(t),CBo=i(x),F1=n(x,"LI",{});var yGe=s(F1);C2e=n(yGe,"STRONG",{});var zIt=s(C2e);wBo=r(zIt,"glpn"),zIt.forEach(t),ABo=r(yGe," \u2014 "),vz=n(yGe,"A",{href:!0});var QIt=s(vz);LBo=r(QIt,"GLPNModel"),QIt.forEach(t),yBo=r(yGe," (GLPN model)"),yGe.forEach(t),xBo=i(x),T1=n(x,"LI",{});var xGe=s(T1);w2e=n(xGe,"STRONG",{});var WIt=s(w2e);$Bo=r(WIt,"gpt2"),WIt.forEach(t),kBo=r(xGe," \u2014 "),Fz=n(xGe,"A",{href:!0});var UIt=s(Fz);SBo=r(UIt,"GPT2Model"),UIt.forEach(t),RBo=r(xGe," (OpenAI GPT-2 model)"),xGe.forEach(t),PBo=i(x),M1=n(x,"LI",{});var $Ge=s(M1);A2e=n($Ge,"STRONG",{});var HIt=s(A2e);BBo=r(HIt,"gpt_neo"),HIt.forEach(t),IBo=r($Ge," \u2014 "),Tz=n($Ge,"A",{href:!0});var JIt=s(Tz);NBo=r(JIt,"GPTNeoModel"),JIt.forEach(t),qBo=r($Ge," (GPT Neo model)"),$Ge.forEach(t),DBo=i(x),E1=n(x,"LI",{});var kGe=s(E1);L2e=n(kGe,"STRONG",{});var YIt=s(L2e);jBo=r(YIt,"gpt_neox"),YIt.forEach(t),GBo=r(kGe," \u2014 "),Mz=n(kGe,"A",{href:!0});var ZIt=s(Mz);OBo=r(ZIt,"GPTNeoXModel"),ZIt.forEach(t),VBo=r(kGe," (GPT NeoX model)"),kGe.forEach(t),XBo=i(x),C1=n(x,"LI",{});var SGe=s(C1);y2e=n(SGe,"STRONG",{});var KIt=s(y2e);zBo=r(KIt,"gpt_neox_japanese"),KIt.forEach(t),QBo=r(SGe," \u2014 "),Ez=n(SGe,"A",{href:!0});var eNt=s(Ez);WBo=r(eNt,"GPTNeoXJapaneseModel"),eNt.forEach(t),UBo=r(SGe," (GPT NeoX Japanese model)"),SGe.forEach(t),HBo=i(x),w1=n(x,"LI",{});var RGe=s(w1);x2e=n(RGe,"STRONG",{});var oNt=s(x2e);JBo=r(oNt,"gptj"),oNt.forEach(t),YBo=r(RGe," \u2014 "),Cz=n(RGe,"A",{href:!0});var rNt=s(Cz);ZBo=r(rNt,"GPTJModel"),rNt.forEach(t),KBo=r(RGe," (GPT-J model)"),RGe.forEach(t),eIo=i(x),A1=n(x,"LI",{});var PGe=s(A1);$2e=n(PGe,"STRONG",{});var tNt=s($2e);oIo=r(tNt,"groupvit"),tNt.forEach(t),rIo=r(PGe," \u2014 "),wz=n(PGe,"A",{href:!0});var aNt=s(wz);tIo=r(aNt,"GroupViTModel"),aNt.forEach(t),aIo=r(PGe," (GroupViT model)"),PGe.forEach(t),nIo=i(x),L1=n(x,"LI",{});var BGe=s(L1);k2e=n(BGe,"STRONG",{});var nNt=s(k2e);sIo=r(nNt,"hubert"),nNt.forEach(t),lIo=r(BGe," \u2014 "),Az=n(BGe,"A",{href:!0});var sNt=s(Az);iIo=r(sNt,"HubertModel"),sNt.forEach(t),dIo=r(BGe," (Hubert model)"),BGe.forEach(t),mIo=i(x),y1=n(x,"LI",{});var IGe=s(y1);S2e=n(IGe,"STRONG",{});var lNt=s(S2e);cIo=r(lNt,"ibert"),lNt.forEach(t),fIo=r(IGe," \u2014 "),Lz=n(IGe,"A",{href:!0});var iNt=s(Lz);gIo=r(iNt,"IBertModel"),iNt.forEach(t),hIo=r(IGe," (I-BERT model)"),IGe.forEach(t),uIo=i(x),x1=n(x,"LI",{});var NGe=s(x1);R2e=n(NGe,"STRONG",{});var dNt=s(R2e);pIo=r(dNt,"imagegpt"),dNt.forEach(t),_Io=r(NGe," \u2014 "),yz=n(NGe,"A",{href:!0});var mNt=s(yz);bIo=r(mNt,"ImageGPTModel"),mNt.forEach(t),vIo=r(NGe," (ImageGPT model)"),NGe.forEach(t),FIo=i(x),$1=n(x,"LI",{});var qGe=s($1);P2e=n(qGe,"STRONG",{});var cNt=s(P2e);TIo=r(cNt,"layoutlm"),cNt.forEach(t),MIo=r(qGe," \u2014 "),xz=n(qGe,"A",{href:!0});var fNt=s(xz);EIo=r(fNt,"LayoutLMModel"),fNt.forEach(t),CIo=r(qGe," (LayoutLM model)"),qGe.forEach(t),wIo=i(x),k1=n(x,"LI",{});var DGe=s(k1);B2e=n(DGe,"STRONG",{});var gNt=s(B2e);AIo=r(gNt,"layoutlmv2"),gNt.forEach(t),LIo=r(DGe," \u2014 "),$z=n(DGe,"A",{href:!0});var hNt=s($z);yIo=r(hNt,"LayoutLMv2Model"),hNt.forEach(t),xIo=r(DGe," (LayoutLMv2 model)"),DGe.forEach(t),$Io=i(x),S1=n(x,"LI",{});var jGe=s(S1);I2e=n(jGe,"STRONG",{});var uNt=s(I2e);kIo=r(uNt,"layoutlmv3"),uNt.forEach(t),SIo=r(jGe," \u2014 "),kz=n(jGe,"A",{href:!0});var pNt=s(kz);RIo=r(pNt,"LayoutLMv3Model"),pNt.forEach(t),PIo=r(jGe," (LayoutLMv3 model)"),jGe.forEach(t),BIo=i(x),R1=n(x,"LI",{});var GGe=s(R1);N2e=n(GGe,"STRONG",{});var _Nt=s(N2e);IIo=r(_Nt,"led"),_Nt.forEach(t),NIo=r(GGe," \u2014 "),Sz=n(GGe,"A",{href:!0});var bNt=s(Sz);qIo=r(bNt,"LEDModel"),bNt.forEach(t),DIo=r(GGe," (LED model)"),GGe.forEach(t),jIo=i(x),P1=n(x,"LI",{});var OGe=s(P1);q2e=n(OGe,"STRONG",{});var vNt=s(q2e);GIo=r(vNt,"levit"),vNt.forEach(t),OIo=r(OGe," \u2014 "),Rz=n(OGe,"A",{href:!0});var FNt=s(Rz);VIo=r(FNt,"LevitModel"),FNt.forEach(t),XIo=r(OGe," (LeViT model)"),OGe.forEach(t),zIo=i(x),B1=n(x,"LI",{});var VGe=s(B1);D2e=n(VGe,"STRONG",{});var TNt=s(D2e);QIo=r(TNt,"lilt"),TNt.forEach(t),WIo=r(VGe," \u2014 "),Pz=n(VGe,"A",{href:!0});var MNt=s(Pz);UIo=r(MNt,"LiltModel"),MNt.forEach(t),HIo=r(VGe," (LiLT model)"),VGe.forEach(t),JIo=i(x),I1=n(x,"LI",{});var XGe=s(I1);j2e=n(XGe,"STRONG",{});var ENt=s(j2e);YIo=r(ENt,"longformer"),ENt.forEach(t),ZIo=r(XGe," \u2014 "),Bz=n(XGe,"A",{href:!0});var CNt=s(Bz);KIo=r(CNt,"LongformerModel"),CNt.forEach(t),eNo=r(XGe," (Longformer model)"),XGe.forEach(t),oNo=i(x),N1=n(x,"LI",{});var zGe=s(N1);G2e=n(zGe,"STRONG",{});var wNt=s(G2e);rNo=r(wNt,"longt5"),wNt.forEach(t),tNo=r(zGe," \u2014 "),Iz=n(zGe,"A",{href:!0});var ANt=s(Iz);aNo=r(ANt,"LongT5Model"),ANt.forEach(t),nNo=r(zGe," (LongT5 model)"),zGe.forEach(t),sNo=i(x),q1=n(x,"LI",{});var QGe=s(q1);O2e=n(QGe,"STRONG",{});var LNt=s(O2e);lNo=r(LNt,"luke"),LNt.forEach(t),iNo=r(QGe," \u2014 "),Nz=n(QGe,"A",{href:!0});var yNt=s(Nz);dNo=r(yNt,"LukeModel"),yNt.forEach(t),mNo=r(QGe," (LUKE model)"),QGe.forEach(t),cNo=i(x),D1=n(x,"LI",{});var WGe=s(D1);V2e=n(WGe,"STRONG",{});var xNt=s(V2e);fNo=r(xNt,"lxmert"),xNt.forEach(t),gNo=r(WGe," \u2014 "),qz=n(WGe,"A",{href:!0});var $Nt=s(qz);hNo=r($Nt,"LxmertModel"),$Nt.forEach(t),uNo=r(WGe," (LXMERT model)"),WGe.forEach(t),pNo=i(x),j1=n(x,"LI",{});var UGe=s(j1);X2e=n(UGe,"STRONG",{});var kNt=s(X2e);_No=r(kNt,"m2m_100"),kNt.forEach(t),bNo=r(UGe," \u2014 "),Dz=n(UGe,"A",{href:!0});var SNt=s(Dz);vNo=r(SNt,"M2M100Model"),SNt.forEach(t),FNo=r(UGe," (M2M100 model)"),UGe.forEach(t),TNo=i(x),G1=n(x,"LI",{});var HGe=s(G1);z2e=n(HGe,"STRONG",{});var RNt=s(z2e);MNo=r(RNt,"marian"),RNt.forEach(t),ENo=r(HGe," \u2014 "),jz=n(HGe,"A",{href:!0});var PNt=s(jz);CNo=r(PNt,"MarianModel"),PNt.forEach(t),wNo=r(HGe," (Marian model)"),HGe.forEach(t),ANo=i(x),O1=n(x,"LI",{});var JGe=s(O1);Q2e=n(JGe,"STRONG",{});var BNt=s(Q2e);LNo=r(BNt,"markuplm"),BNt.forEach(t),yNo=r(JGe," \u2014 "),Gz=n(JGe,"A",{href:!0});var INt=s(Gz);xNo=r(INt,"MarkupLMModel"),INt.forEach(t),$No=r(JGe," (MarkupLM model)"),JGe.forEach(t),kNo=i(x),V1=n(x,"LI",{});var YGe=s(V1);W2e=n(YGe,"STRONG",{});var NNt=s(W2e);SNo=r(NNt,"maskformer"),NNt.forEach(t),RNo=r(YGe," \u2014 "),Oz=n(YGe,"A",{href:!0});var qNt=s(Oz);PNo=r(qNt,"MaskFormerModel"),qNt.forEach(t),BNo=r(YGe," (MaskFormer model)"),YGe.forEach(t),INo=i(x),X1=n(x,"LI",{});var ZGe=s(X1);U2e=n(ZGe,"STRONG",{});var DNt=s(U2e);NNo=r(DNt,"mbart"),DNt.forEach(t),qNo=r(ZGe," \u2014 "),Vz=n(ZGe,"A",{href:!0});var jNt=s(Vz);DNo=r(jNt,"MBartModel"),jNt.forEach(t),jNo=r(ZGe," (mBART model)"),ZGe.forEach(t),GNo=i(x),z1=n(x,"LI",{});var KGe=s(z1);H2e=n(KGe,"STRONG",{});var GNt=s(H2e);ONo=r(GNt,"mctct"),GNt.forEach(t),VNo=r(KGe," \u2014 "),Xz=n(KGe,"A",{href:!0});var ONt=s(Xz);XNo=r(ONt,"MCTCTModel"),ONt.forEach(t),zNo=r(KGe," (M-CTC-T model)"),KGe.forEach(t),QNo=i(x),Q1=n(x,"LI",{});var eOe=s(Q1);J2e=n(eOe,"STRONG",{});var VNt=s(J2e);WNo=r(VNt,"megatron-bert"),VNt.forEach(t),UNo=r(eOe," \u2014 "),zz=n(eOe,"A",{href:!0});var XNt=s(zz);HNo=r(XNt,"MegatronBertModel"),XNt.forEach(t),JNo=r(eOe," (Megatron-BERT model)"),eOe.forEach(t),YNo=i(x),W1=n(x,"LI",{});var oOe=s(W1);Y2e=n(oOe,"STRONG",{});var zNt=s(Y2e);ZNo=r(zNt,"mobilebert"),zNt.forEach(t),KNo=r(oOe," \u2014 "),Qz=n(oOe,"A",{href:!0});var QNt=s(Qz);eqo=r(QNt,"MobileBertModel"),QNt.forEach(t),oqo=r(oOe," (MobileBERT model)"),oOe.forEach(t),rqo=i(x),U1=n(x,"LI",{});var rOe=s(U1);Z2e=n(rOe,"STRONG",{});var WNt=s(Z2e);tqo=r(WNt,"mobilevit"),WNt.forEach(t),aqo=r(rOe," \u2014 "),Wz=n(rOe,"A",{href:!0});var UNt=s(Wz);nqo=r(UNt,"MobileViTModel"),UNt.forEach(t),sqo=r(rOe," (MobileViT model)"),rOe.forEach(t),lqo=i(x),H1=n(x,"LI",{});var tOe=s(H1);K2e=n(tOe,"STRONG",{});var HNt=s(K2e);iqo=r(HNt,"mpnet"),HNt.forEach(t),dqo=r(tOe," \u2014 "),Uz=n(tOe,"A",{href:!0});var JNt=s(Uz);mqo=r(JNt,"MPNetModel"),JNt.forEach(t),cqo=r(tOe," (MPNet model)"),tOe.forEach(t),fqo=i(x),J1=n(x,"LI",{});var aOe=s(J1);ebe=n(aOe,"STRONG",{});var YNt=s(ebe);gqo=r(YNt,"mt5"),YNt.forEach(t),hqo=r(aOe," \u2014 "),Hz=n(aOe,"A",{href:!0});var ZNt=s(Hz);uqo=r(ZNt,"MT5Model"),ZNt.forEach(t),pqo=r(aOe," (MT5 model)"),aOe.forEach(t),_qo=i(x),Y1=n(x,"LI",{});var nOe=s(Y1);obe=n(nOe,"STRONG",{});var KNt=s(obe);bqo=r(KNt,"mvp"),KNt.forEach(t),vqo=r(nOe," \u2014 "),Jz=n(nOe,"A",{href:!0});var eqt=s(Jz);Fqo=r(eqt,"MvpModel"),eqt.forEach(t),Tqo=r(nOe," (MVP model)"),nOe.forEach(t),Mqo=i(x),Z1=n(x,"LI",{});var sOe=s(Z1);rbe=n(sOe,"STRONG",{});var oqt=s(rbe);Eqo=r(oqt,"nezha"),oqt.forEach(t),Cqo=r(sOe," \u2014 "),Yz=n(sOe,"A",{href:!0});var rqt=s(Yz);wqo=r(rqt,"NezhaModel"),rqt.forEach(t),Aqo=r(sOe," (Nezha model)"),sOe.forEach(t),Lqo=i(x),K1=n(x,"LI",{});var lOe=s(K1);tbe=n(lOe,"STRONG",{});var tqt=s(tbe);yqo=r(tqt,"nllb"),tqt.forEach(t),xqo=r(lOe," \u2014 "),Zz=n(lOe,"A",{href:!0});var aqt=s(Zz);$qo=r(aqt,"M2M100Model"),aqt.forEach(t),kqo=r(lOe," (NLLB model)"),lOe.forEach(t),Sqo=i(x),e2=n(x,"LI",{});var iOe=s(e2);abe=n(iOe,"STRONG",{});var nqt=s(abe);Rqo=r(nqt,"nystromformer"),nqt.forEach(t),Pqo=r(iOe," \u2014 "),Kz=n(iOe,"A",{href:!0});var sqt=s(Kz);Bqo=r(sqt,"NystromformerModel"),sqt.forEach(t),Iqo=r(iOe," (Nystr\xF6mformer model)"),iOe.forEach(t),Nqo=i(x),o2=n(x,"LI",{});var dOe=s(o2);nbe=n(dOe,"STRONG",{});var lqt=s(nbe);qqo=r(lqt,"openai-gpt"),lqt.forEach(t),Dqo=r(dOe," \u2014 "),eQ=n(dOe,"A",{href:!0});var iqt=s(eQ);jqo=r(iqt,"OpenAIGPTModel"),iqt.forEach(t),Gqo=r(dOe," (OpenAI GPT model)"),dOe.forEach(t),Oqo=i(x),r2=n(x,"LI",{});var mOe=s(r2);sbe=n(mOe,"STRONG",{});var dqt=s(sbe);Vqo=r(dqt,"opt"),dqt.forEach(t),Xqo=r(mOe," \u2014 "),oQ=n(mOe,"A",{href:!0});var mqt=s(oQ);zqo=r(mqt,"OPTModel"),mqt.forEach(t),Qqo=r(mOe," (OPT model)"),mOe.forEach(t),Wqo=i(x),t2=n(x,"LI",{});var cOe=s(t2);lbe=n(cOe,"STRONG",{});var cqt=s(lbe);Uqo=r(cqt,"owlvit"),cqt.forEach(t),Hqo=r(cOe," \u2014 "),rQ=n(cOe,"A",{href:!0});var fqt=s(rQ);Jqo=r(fqt,"OwlViTModel"),fqt.forEach(t),Yqo=r(cOe," (OWL-ViT model)"),cOe.forEach(t),Zqo=i(x),a2=n(x,"LI",{});var fOe=s(a2);ibe=n(fOe,"STRONG",{});var gqt=s(ibe);Kqo=r(gqt,"pegasus"),gqt.forEach(t),eDo=r(fOe," \u2014 "),tQ=n(fOe,"A",{href:!0});var hqt=s(tQ);oDo=r(hqt,"PegasusModel"),hqt.forEach(t),rDo=r(fOe," (Pegasus model)"),fOe.forEach(t),tDo=i(x),n2=n(x,"LI",{});var gOe=s(n2);dbe=n(gOe,"STRONG",{});var uqt=s(dbe);aDo=r(uqt,"pegasus_x"),uqt.forEach(t),nDo=r(gOe," \u2014 "),aQ=n(gOe,"A",{href:!0});var pqt=s(aQ);sDo=r(pqt,"PegasusXModel"),pqt.forEach(t),lDo=r(gOe," (PEGASUS-X model)"),gOe.forEach(t),iDo=i(x),s2=n(x,"LI",{});var hOe=s(s2);mbe=n(hOe,"STRONG",{});var _qt=s(mbe);dDo=r(_qt,"perceiver"),_qt.forEach(t),mDo=r(hOe," \u2014 "),nQ=n(hOe,"A",{href:!0});var bqt=s(nQ);cDo=r(bqt,"PerceiverModel"),bqt.forEach(t),fDo=r(hOe," (Perceiver model)"),hOe.forEach(t),gDo=i(x),l2=n(x,"LI",{});var uOe=s(l2);cbe=n(uOe,"STRONG",{});var vqt=s(cbe);hDo=r(vqt,"plbart"),vqt.forEach(t),uDo=r(uOe," \u2014 "),sQ=n(uOe,"A",{href:!0});var Fqt=s(sQ);pDo=r(Fqt,"PLBartModel"),Fqt.forEach(t),_Do=r(uOe," (PLBart model)"),uOe.forEach(t),bDo=i(x),i2=n(x,"LI",{});var pOe=s(i2);fbe=n(pOe,"STRONG",{});var Tqt=s(fbe);vDo=r(Tqt,"poolformer"),Tqt.forEach(t),FDo=r(pOe," \u2014 "),lQ=n(pOe,"A",{href:!0});var Mqt=s(lQ);TDo=r(Mqt,"PoolFormerModel"),Mqt.forEach(t),MDo=r(pOe," (PoolFormer model)"),pOe.forEach(t),EDo=i(x),d2=n(x,"LI",{});var _Oe=s(d2);gbe=n(_Oe,"STRONG",{});var Eqt=s(gbe);CDo=r(Eqt,"prophetnet"),Eqt.forEach(t),wDo=r(_Oe," \u2014 "),iQ=n(_Oe,"A",{href:!0});var Cqt=s(iQ);ADo=r(Cqt,"ProphetNetModel"),Cqt.forEach(t),LDo=r(_Oe," (ProphetNet model)"),_Oe.forEach(t),yDo=i(x),m2=n(x,"LI",{});var bOe=s(m2);hbe=n(bOe,"STRONG",{});var wqt=s(hbe);xDo=r(wqt,"qdqbert"),wqt.forEach(t),$Do=r(bOe," \u2014 "),dQ=n(bOe,"A",{href:!0});var Aqt=s(dQ);kDo=r(Aqt,"QDQBertModel"),Aqt.forEach(t),SDo=r(bOe," (QDQBert model)"),bOe.forEach(t),RDo=i(x),c2=n(x,"LI",{});var vOe=s(c2);ube=n(vOe,"STRONG",{});var Lqt=s(ube);PDo=r(Lqt,"reformer"),Lqt.forEach(t),BDo=r(vOe," \u2014 "),mQ=n(vOe,"A",{href:!0});var yqt=s(mQ);IDo=r(yqt,"ReformerModel"),yqt.forEach(t),NDo=r(vOe," (Reformer model)"),vOe.forEach(t),qDo=i(x),f2=n(x,"LI",{});var FOe=s(f2);pbe=n(FOe,"STRONG",{});var xqt=s(pbe);DDo=r(xqt,"regnet"),xqt.forEach(t),jDo=r(FOe," \u2014 "),cQ=n(FOe,"A",{href:!0});var $qt=s(cQ);GDo=r($qt,"RegNetModel"),$qt.forEach(t),ODo=r(FOe," (RegNet model)"),FOe.forEach(t),VDo=i(x),g2=n(x,"LI",{});var TOe=s(g2);_be=n(TOe,"STRONG",{});var kqt=s(_be);XDo=r(kqt,"rembert"),kqt.forEach(t),zDo=r(TOe," \u2014 "),fQ=n(TOe,"A",{href:!0});var Sqt=s(fQ);QDo=r(Sqt,"RemBertModel"),Sqt.forEach(t),WDo=r(TOe," (RemBERT model)"),TOe.forEach(t),UDo=i(x),h2=n(x,"LI",{});var MOe=s(h2);bbe=n(MOe,"STRONG",{});var Rqt=s(bbe);HDo=r(Rqt,"resnet"),Rqt.forEach(t),JDo=r(MOe," \u2014 "),gQ=n(MOe,"A",{href:!0});var Pqt=s(gQ);YDo=r(Pqt,"ResNetModel"),Pqt.forEach(t),ZDo=r(MOe," (ResNet model)"),MOe.forEach(t),KDo=i(x),u2=n(x,"LI",{});var EOe=s(u2);vbe=n(EOe,"STRONG",{});var Bqt=s(vbe);ejo=r(Bqt,"retribert"),Bqt.forEach(t),ojo=r(EOe," \u2014 "),hQ=n(EOe,"A",{href:!0});var Iqt=s(hQ);rjo=r(Iqt,"RetriBertModel"),Iqt.forEach(t),tjo=r(EOe," (RetriBERT model)"),EOe.forEach(t),ajo=i(x),p2=n(x,"LI",{});var COe=s(p2);Fbe=n(COe,"STRONG",{});var Nqt=s(Fbe);njo=r(Nqt,"roberta"),Nqt.forEach(t),sjo=r(COe," \u2014 "),uQ=n(COe,"A",{href:!0});var qqt=s(uQ);ljo=r(qqt,"RobertaModel"),qqt.forEach(t),ijo=r(COe," (RoBERTa model)"),COe.forEach(t),djo=i(x),_2=n(x,"LI",{});var wOe=s(_2);Tbe=n(wOe,"STRONG",{});var Dqt=s(Tbe);mjo=r(Dqt,"roformer"),Dqt.forEach(t),cjo=r(wOe," \u2014 "),pQ=n(wOe,"A",{href:!0});var jqt=s(pQ);fjo=r(jqt,"RoFormerModel"),jqt.forEach(t),gjo=r(wOe," (RoFormer model)"),wOe.forEach(t),hjo=i(x),b2=n(x,"LI",{});var AOe=s(b2);Mbe=n(AOe,"STRONG",{});var Gqt=s(Mbe);ujo=r(Gqt,"segformer"),Gqt.forEach(t),pjo=r(AOe," \u2014 "),_Q=n(AOe,"A",{href:!0});var Oqt=s(_Q);_jo=r(Oqt,"SegformerModel"),Oqt.forEach(t),bjo=r(AOe," (SegFormer model)"),AOe.forEach(t),vjo=i(x),v2=n(x,"LI",{});var LOe=s(v2);Ebe=n(LOe,"STRONG",{});var Vqt=s(Ebe);Fjo=r(Vqt,"sew"),Vqt.forEach(t),Tjo=r(LOe," \u2014 "),bQ=n(LOe,"A",{href:!0});var Xqt=s(bQ);Mjo=r(Xqt,"SEWModel"),Xqt.forEach(t),Ejo=r(LOe," (SEW model)"),LOe.forEach(t),Cjo=i(x),F2=n(x,"LI",{});var yOe=s(F2);Cbe=n(yOe,"STRONG",{});var zqt=s(Cbe);wjo=r(zqt,"sew-d"),zqt.forEach(t),Ajo=r(yOe," \u2014 "),vQ=n(yOe,"A",{href:!0});var Qqt=s(vQ);Ljo=r(Qqt,"SEWDModel"),Qqt.forEach(t),yjo=r(yOe," (SEW-D model)"),yOe.forEach(t),xjo=i(x),T2=n(x,"LI",{});var xOe=s(T2);wbe=n(xOe,"STRONG",{});var Wqt=s(wbe);$jo=r(Wqt,"speech_to_text"),Wqt.forEach(t),kjo=r(xOe," \u2014 "),FQ=n(xOe,"A",{href:!0});var Uqt=s(FQ);Sjo=r(Uqt,"Speech2TextModel"),Uqt.forEach(t),Rjo=r(xOe," (Speech2Text model)"),xOe.forEach(t),Pjo=i(x),M2=n(x,"LI",{});var $Oe=s(M2);Abe=n($Oe,"STRONG",{});var Hqt=s(Abe);Bjo=r(Hqt,"splinter"),Hqt.forEach(t),Ijo=r($Oe," \u2014 "),TQ=n($Oe,"A",{href:!0});var Jqt=s(TQ);Njo=r(Jqt,"SplinterModel"),Jqt.forEach(t),qjo=r($Oe," (Splinter model)"),$Oe.forEach(t),Djo=i(x),E2=n(x,"LI",{});var kOe=s(E2);Lbe=n(kOe,"STRONG",{});var Yqt=s(Lbe);jjo=r(Yqt,"squeezebert"),Yqt.forEach(t),Gjo=r(kOe," \u2014 "),MQ=n(kOe,"A",{href:!0});var Zqt=s(MQ);Ojo=r(Zqt,"SqueezeBertModel"),Zqt.forEach(t),Vjo=r(kOe," (SqueezeBERT model)"),kOe.forEach(t),Xjo=i(x),C2=n(x,"LI",{});var SOe=s(C2);ybe=n(SOe,"STRONG",{});var Kqt=s(ybe);zjo=r(Kqt,"swin"),Kqt.forEach(t),Qjo=r(SOe," \u2014 "),EQ=n(SOe,"A",{href:!0});var eDt=s(EQ);Wjo=r(eDt,"SwinModel"),eDt.forEach(t),Ujo=r(SOe," (Swin Transformer model)"),SOe.forEach(t),Hjo=i(x),w2=n(x,"LI",{});var ROe=s(w2);xbe=n(ROe,"STRONG",{});var oDt=s(xbe);Jjo=r(oDt,"swinv2"),oDt.forEach(t),Yjo=r(ROe," \u2014 "),CQ=n(ROe,"A",{href:!0});var rDt=s(CQ);Zjo=r(rDt,"Swinv2Model"),rDt.forEach(t),Kjo=r(ROe," (Swin Transformer V2 model)"),ROe.forEach(t),eGo=i(x),A2=n(x,"LI",{});var POe=s(A2);$be=n(POe,"STRONG",{});var tDt=s($be);oGo=r(tDt,"t5"),tDt.forEach(t),rGo=r(POe," \u2014 "),wQ=n(POe,"A",{href:!0});var aDt=s(wQ);tGo=r(aDt,"T5Model"),aDt.forEach(t),aGo=r(POe," (T5 model)"),POe.forEach(t),nGo=i(x),L2=n(x,"LI",{});var BOe=s(L2);kbe=n(BOe,"STRONG",{});var nDt=s(kbe);sGo=r(nDt,"table-transformer"),nDt.forEach(t),lGo=r(BOe," \u2014 "),AQ=n(BOe,"A",{href:!0});var sDt=s(AQ);iGo=r(sDt,"TableTransformerModel"),sDt.forEach(t),dGo=r(BOe," (Table Transformer model)"),BOe.forEach(t),mGo=i(x),y2=n(x,"LI",{});var IOe=s(y2);Sbe=n(IOe,"STRONG",{});var lDt=s(Sbe);cGo=r(lDt,"tapas"),lDt.forEach(t),fGo=r(IOe," \u2014 "),LQ=n(IOe,"A",{href:!0});var iDt=s(LQ);gGo=r(iDt,"TapasModel"),iDt.forEach(t),hGo=r(IOe," (TAPAS model)"),IOe.forEach(t),uGo=i(x),x2=n(x,"LI",{});var NOe=s(x2);Rbe=n(NOe,"STRONG",{});var dDt=s(Rbe);pGo=r(dDt,"time_series_transformer"),dDt.forEach(t),_Go=r(NOe," \u2014 "),yQ=n(NOe,"A",{href:!0});var mDt=s(yQ);bGo=r(mDt,"TimeSeriesTransformerModel"),mDt.forEach(t),vGo=r(NOe," (Time Series Transformer model)"),NOe.forEach(t),FGo=i(x),$2=n(x,"LI",{});var qOe=s($2);Pbe=n(qOe,"STRONG",{});var cDt=s(Pbe);TGo=r(cDt,"trajectory_transformer"),cDt.forEach(t),MGo=r(qOe," \u2014 "),xQ=n(qOe,"A",{href:!0});var fDt=s(xQ);EGo=r(fDt,"TrajectoryTransformerModel"),fDt.forEach(t),CGo=r(qOe," (Trajectory Transformer model)"),qOe.forEach(t),wGo=i(x),k2=n(x,"LI",{});var DOe=s(k2);Bbe=n(DOe,"STRONG",{});var gDt=s(Bbe);AGo=r(gDt,"transfo-xl"),gDt.forEach(t),LGo=r(DOe," \u2014 "),$Q=n(DOe,"A",{href:!0});var hDt=s($Q);yGo=r(hDt,"TransfoXLModel"),hDt.forEach(t),xGo=r(DOe," (Transformer-XL model)"),DOe.forEach(t),$Go=i(x),S2=n(x,"LI",{});var jOe=s(S2);Ibe=n(jOe,"STRONG",{});var uDt=s(Ibe);kGo=r(uDt,"unispeech"),uDt.forEach(t),SGo=r(jOe," \u2014 "),kQ=n(jOe,"A",{href:!0});var pDt=s(kQ);RGo=r(pDt,"UniSpeechModel"),pDt.forEach(t),PGo=r(jOe," (UniSpeech model)"),jOe.forEach(t),BGo=i(x),R2=n(x,"LI",{});var GOe=s(R2);Nbe=n(GOe,"STRONG",{});var _Dt=s(Nbe);IGo=r(_Dt,"unispeech-sat"),_Dt.forEach(t),NGo=r(GOe," \u2014 "),SQ=n(GOe,"A",{href:!0});var bDt=s(SQ);qGo=r(bDt,"UniSpeechSatModel"),bDt.forEach(t),DGo=r(GOe," (UniSpeechSat model)"),GOe.forEach(t),jGo=i(x),P2=n(x,"LI",{});var OOe=s(P2);qbe=n(OOe,"STRONG",{});var vDt=s(qbe);GGo=r(vDt,"van"),vDt.forEach(t),OGo=r(OOe," \u2014 "),RQ=n(OOe,"A",{href:!0});var FDt=s(RQ);VGo=r(FDt,"VanModel"),FDt.forEach(t),XGo=r(OOe," (VAN model)"),OOe.forEach(t),zGo=i(x),B2=n(x,"LI",{});var VOe=s(B2);Dbe=n(VOe,"STRONG",{});var TDt=s(Dbe);QGo=r(TDt,"videomae"),TDt.forEach(t),WGo=r(VOe," \u2014 "),PQ=n(VOe,"A",{href:!0});var MDt=s(PQ);UGo=r(MDt,"VideoMAEModel"),MDt.forEach(t),HGo=r(VOe," (VideoMAE model)"),VOe.forEach(t),JGo=i(x),I2=n(x,"LI",{});var XOe=s(I2);jbe=n(XOe,"STRONG",{});var EDt=s(jbe);YGo=r(EDt,"vilt"),EDt.forEach(t),ZGo=r(XOe," \u2014 "),BQ=n(XOe,"A",{href:!0});var CDt=s(BQ);KGo=r(CDt,"ViltModel"),CDt.forEach(t),eOo=r(XOe," (ViLT model)"),XOe.forEach(t),oOo=i(x),N2=n(x,"LI",{});var zOe=s(N2);Gbe=n(zOe,"STRONG",{});var wDt=s(Gbe);rOo=r(wDt,"vision-text-dual-encoder"),wDt.forEach(t),tOo=r(zOe," \u2014 "),IQ=n(zOe,"A",{href:!0});var ADt=s(IQ);aOo=r(ADt,"VisionTextDualEncoderModel"),ADt.forEach(t),nOo=r(zOe," (VisionTextDualEncoder model)"),zOe.forEach(t),sOo=i(x),q2=n(x,"LI",{});var QOe=s(q2);Obe=n(QOe,"STRONG",{});var LDt=s(Obe);lOo=r(LDt,"visual_bert"),LDt.forEach(t),iOo=r(QOe," \u2014 "),NQ=n(QOe,"A",{href:!0});var yDt=s(NQ);dOo=r(yDt,"VisualBertModel"),yDt.forEach(t),mOo=r(QOe," (VisualBERT model)"),QOe.forEach(t),cOo=i(x),D2=n(x,"LI",{});var WOe=s(D2);Vbe=n(WOe,"STRONG",{});var xDt=s(Vbe);fOo=r(xDt,"vit"),xDt.forEach(t),gOo=r(WOe," \u2014 "),qQ=n(WOe,"A",{href:!0});var $Dt=s(qQ);hOo=r($Dt,"ViTModel"),$Dt.forEach(t),uOo=r(WOe," (ViT model)"),WOe.forEach(t),pOo=i(x),j2=n(x,"LI",{});var UOe=s(j2);Xbe=n(UOe,"STRONG",{});var kDt=s(Xbe);_Oo=r(kDt,"vit_mae"),kDt.forEach(t),bOo=r(UOe," \u2014 "),DQ=n(UOe,"A",{href:!0});var SDt=s(DQ);vOo=r(SDt,"ViTMAEModel"),SDt.forEach(t),FOo=r(UOe," (ViTMAE model)"),UOe.forEach(t),TOo=i(x),G2=n(x,"LI",{});var HOe=s(G2);zbe=n(HOe,"STRONG",{});var RDt=s(zbe);MOo=r(RDt,"vit_msn"),RDt.forEach(t),EOo=r(HOe," \u2014 "),jQ=n(HOe,"A",{href:!0});var PDt=s(jQ);COo=r(PDt,"ViTMSNModel"),PDt.forEach(t),wOo=r(HOe," (ViTMSN model)"),HOe.forEach(t),AOo=i(x),O2=n(x,"LI",{});var JOe=s(O2);Qbe=n(JOe,"STRONG",{});var BDt=s(Qbe);LOo=r(BDt,"wav2vec2"),BDt.forEach(t),yOo=r(JOe," \u2014 "),GQ=n(JOe,"A",{href:!0});var IDt=s(GQ);xOo=r(IDt,"Wav2Vec2Model"),IDt.forEach(t),$Oo=r(JOe," (Wav2Vec2 model)"),JOe.forEach(t),kOo=i(x),V2=n(x,"LI",{});var YOe=s(V2);Wbe=n(YOe,"STRONG",{});var NDt=s(Wbe);SOo=r(NDt,"wav2vec2-conformer"),NDt.forEach(t),ROo=r(YOe," \u2014 "),OQ=n(YOe,"A",{href:!0});var qDt=s(OQ);POo=r(qDt,"Wav2Vec2ConformerModel"),qDt.forEach(t),BOo=r(YOe," (Wav2Vec2-Conformer model)"),YOe.forEach(t),IOo=i(x),X2=n(x,"LI",{});var ZOe=s(X2);Ube=n(ZOe,"STRONG",{});var DDt=s(Ube);NOo=r(DDt,"wavlm"),DDt.forEach(t),qOo=r(ZOe," \u2014 "),VQ=n(ZOe,"A",{href:!0});var jDt=s(VQ);DOo=r(jDt,"WavLMModel"),jDt.forEach(t),jOo=r(ZOe," (WavLM model)"),ZOe.forEach(t),GOo=i(x),z2=n(x,"LI",{});var KOe=s(z2);Hbe=n(KOe,"STRONG",{});var GDt=s(Hbe);OOo=r(GDt,"whisper"),GDt.forEach(t),VOo=r(KOe," \u2014 "),XQ=n(KOe,"A",{href:!0});var ODt=s(XQ);XOo=r(ODt,"WhisperModel"),ODt.forEach(t),zOo=r(KOe," (Whisper model)"),KOe.forEach(t),QOo=i(x),Q2=n(x,"LI",{});var eVe=s(Q2);Jbe=n(eVe,"STRONG",{});var VDt=s(Jbe);WOo=r(VDt,"xclip"),VDt.forEach(t),UOo=r(eVe," \u2014 "),zQ=n(eVe,"A",{href:!0});var XDt=s(zQ);HOo=r(XDt,"XCLIPModel"),XDt.forEach(t),JOo=r(eVe," (X-CLIP model)"),eVe.forEach(t),YOo=i(x),W2=n(x,"LI",{});var oVe=s(W2);Ybe=n(oVe,"STRONG",{});var zDt=s(Ybe);ZOo=r(zDt,"xglm"),zDt.forEach(t),KOo=r(oVe," \u2014 "),QQ=n(oVe,"A",{href:!0});var QDt=s(QQ);eVo=r(QDt,"XGLMModel"),QDt.forEach(t),oVo=r(oVe," (XGLM model)"),oVe.forEach(t),rVo=i(x),U2=n(x,"LI",{});var rVe=s(U2);Zbe=n(rVe,"STRONG",{});var WDt=s(Zbe);tVo=r(WDt,"xlm"),WDt.forEach(t),aVo=r(rVe," \u2014 "),WQ=n(rVe,"A",{href:!0});var UDt=s(WQ);nVo=r(UDt,"XLMModel"),UDt.forEach(t),sVo=r(rVe," (XLM model)"),rVe.forEach(t),lVo=i(x),H2=n(x,"LI",{});var tVe=s(H2);Kbe=n(tVe,"STRONG",{});var HDt=s(Kbe);iVo=r(HDt,"xlm-prophetnet"),HDt.forEach(t),dVo=r(tVe," \u2014 "),UQ=n(tVe,"A",{href:!0});var JDt=s(UQ);mVo=r(JDt,"XLMProphetNetModel"),JDt.forEach(t),cVo=r(tVe," (XLM-ProphetNet model)"),tVe.forEach(t),fVo=i(x),J2=n(x,"LI",{});var aVe=s(J2);eve=n(aVe,"STRONG",{});var YDt=s(eve);gVo=r(YDt,"xlm-roberta"),YDt.forEach(t),hVo=r(aVe," \u2014 "),HQ=n(aVe,"A",{href:!0});var ZDt=s(HQ);uVo=r(ZDt,"XLMRobertaModel"),ZDt.forEach(t),pVo=r(aVe," (XLM-RoBERTa model)"),aVe.forEach(t),_Vo=i(x),Y2=n(x,"LI",{});var nVe=s(Y2);ove=n(nVe,"STRONG",{});var KDt=s(ove);bVo=r(KDt,"xlm-roberta-xl"),KDt.forEach(t),vVo=r(nVe," \u2014 "),JQ=n(nVe,"A",{href:!0});var ejt=s(JQ);FVo=r(ejt,"XLMRobertaXLModel"),ejt.forEach(t),TVo=r(nVe," (XLM-RoBERTa-XL model)"),nVe.forEach(t),MVo=i(x),Z2=n(x,"LI",{});var sVe=s(Z2);rve=n(sVe,"STRONG",{});var ojt=s(rve);EVo=r(ojt,"xlnet"),ojt.forEach(t),CVo=r(sVe," \u2014 "),YQ=n(sVe,"A",{href:!0});var rjt=s(YQ);wVo=r(rjt,"XLNetModel"),rjt.forEach(t),AVo=r(sVe," (XLNet model)"),sVe.forEach(t),LVo=i(x),K2=n(x,"LI",{});var lVe=s(K2);tve=n(lVe,"STRONG",{});var tjt=s(tve);yVo=r(tjt,"yolos"),tjt.forEach(t),xVo=r(lVe," \u2014 "),ZQ=n(lVe,"A",{href:!0});var ajt=s(ZQ);$Vo=r(ajt,"YolosModel"),ajt.forEach(t),kVo=r(lVe," (YOLOS model)"),lVe.forEach(t),SVo=i(x),eb=n(x,"LI",{});var iVe=s(eb);ave=n(iVe,"STRONG",{});var njt=s(ave);RVo=r(njt,"yoso"),njt.forEach(t),PVo=r(iVe," \u2014 "),KQ=n(iVe,"A",{href:!0});var sjt=s(KQ);BVo=r(sjt,"YosoModel"),sjt.forEach(t),IVo=r(iVe," (YOSO model)"),iVe.forEach(t),x.forEach(t),NVo=i(La),ob=n(La,"P",{});var dVe=s(ob);qVo=r(dVe,"The model is set in evaluation mode by default using "),nve=n(dVe,"CODE",{});var ljt=s(nve);DVo=r(ljt,"model.eval()"),ljt.forEach(t),jVo=r(dVe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sve=n(dVe,"CODE",{});var ijt=s(sve);GVo=r(ijt,"model.train()"),ijt.forEach(t),dVe.forEach(t),OVo=i(La),T(rb.$$.fragment,La),La.forEach(t),ql.forEach(t),Xto=i(c),Bd=n(c,"H2",{class:!0});var iso=s(Bd);tb=n(iso,"A",{id:!0,class:!0,href:!0});var djt=s(tb);lve=n(djt,"SPAN",{});var mjt=s(lve);T(G$.$$.fragment,mjt),mjt.forEach(t),djt.forEach(t),VVo=i(iso),ive=n(iso,"SPAN",{});var cjt=s(ive);XVo=r(cjt,"AutoModelForPreTraining"),cjt.forEach(t),iso.forEach(t),zto=i(c),No=n(c,"DIV",{class:!0});var Dl=s(No);T(O$.$$.fragment,Dl),zVo=i(Dl),Id=n(Dl,"P",{});var ime=s(Id);QVo=r(ime,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),eW=n(ime,"A",{href:!0});var fjt=s(eW);WVo=r(fjt,"from_pretrained()"),fjt.forEach(t),UVo=r(ime," class method or the "),oW=n(ime,"A",{href:!0});var gjt=s(oW);HVo=r(gjt,"from_config()"),gjt.forEach(t),JVo=r(ime,` class
method.`),ime.forEach(t),YVo=i(Dl),V$=n(Dl,"P",{});var dso=s(V$);ZVo=r(dso,"This class cannot be instantiated directly using "),dve=n(dso,"CODE",{});var hjt=s(dve);KVo=r(hjt,"__init__()"),hjt.forEach(t),eXo=r(dso," (throws an error)."),dso.forEach(t),oXo=i(Dl),Et=n(Dl,"DIV",{class:!0});var t9=s(Et);T(X$.$$.fragment,t9),rXo=i(t9),mve=n(t9,"P",{});var ujt=s(mve);tXo=r(ujt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),ujt.forEach(t),aXo=i(t9),Nd=n(t9,"P",{});var dme=s(Nd);nXo=r(dme,`Note:
Loading a model from its configuration file does `),cve=n(dme,"STRONG",{});var pjt=s(cve);sXo=r(pjt,"not"),pjt.forEach(t),lXo=r(dme,` load the model weights. It only affects the
model\u2019s configuration. Use `),rW=n(dme,"A",{href:!0});var _jt=s(rW);iXo=r(_jt,"from_pretrained()"),_jt.forEach(t),dXo=r(dme," to load the model weights."),dme.forEach(t),mXo=i(t9),T(ab.$$.fragment,t9),t9.forEach(t),cXo=i(Dl),eo=n(Dl,"DIV",{class:!0});var ya=s(eo);T(z$.$$.fragment,ya),fXo=i(ya),fve=n(ya,"P",{});var bjt=s(fve);gXo=r(bjt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),bjt.forEach(t),hXo=i(ya),sn=n(ya,"P",{});var a9=s(sn);uXo=r(a9,"The model class to instantiate is selected based on the "),gve=n(a9,"CODE",{});var vjt=s(gve);pXo=r(vjt,"model_type"),vjt.forEach(t),_Xo=r(a9,` property of the config object (either
passed as an argument or loaded from `),hve=n(a9,"CODE",{});var Fjt=s(hve);bXo=r(Fjt,"pretrained_model_name_or_path"),Fjt.forEach(t),vXo=r(a9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uve=n(a9,"CODE",{});var Tjt=s(uve);FXo=r(Tjt,"pretrained_model_name_or_path"),Tjt.forEach(t),TXo=r(a9,":"),a9.forEach(t),MXo=i(ya),G=n(ya,"UL",{});var V=s(G);nb=n(V,"LI",{});var mVe=s(nb);pve=n(mVe,"STRONG",{});var Mjt=s(pve);EXo=r(Mjt,"albert"),Mjt.forEach(t),CXo=r(mVe," \u2014 "),tW=n(mVe,"A",{href:!0});var Ejt=s(tW);wXo=r(Ejt,"AlbertForPreTraining"),Ejt.forEach(t),AXo=r(mVe," (ALBERT model)"),mVe.forEach(t),LXo=i(V),sb=n(V,"LI",{});var cVe=s(sb);_ve=n(cVe,"STRONG",{});var Cjt=s(_ve);yXo=r(Cjt,"bart"),Cjt.forEach(t),xXo=r(cVe," \u2014 "),aW=n(cVe,"A",{href:!0});var wjt=s(aW);$Xo=r(wjt,"BartForConditionalGeneration"),wjt.forEach(t),kXo=r(cVe," (BART model)"),cVe.forEach(t),SXo=i(V),lb=n(V,"LI",{});var fVe=s(lb);bve=n(fVe,"STRONG",{});var Ajt=s(bve);RXo=r(Ajt,"bert"),Ajt.forEach(t),PXo=r(fVe," \u2014 "),nW=n(fVe,"A",{href:!0});var Ljt=s(nW);BXo=r(Ljt,"BertForPreTraining"),Ljt.forEach(t),IXo=r(fVe," (BERT model)"),fVe.forEach(t),NXo=i(V),ib=n(V,"LI",{});var gVe=s(ib);vve=n(gVe,"STRONG",{});var yjt=s(vve);qXo=r(yjt,"big_bird"),yjt.forEach(t),DXo=r(gVe," \u2014 "),sW=n(gVe,"A",{href:!0});var xjt=s(sW);jXo=r(xjt,"BigBirdForPreTraining"),xjt.forEach(t),GXo=r(gVe," (BigBird model)"),gVe.forEach(t),OXo=i(V),db=n(V,"LI",{});var hVe=s(db);Fve=n(hVe,"STRONG",{});var $jt=s(Fve);VXo=r($jt,"bloom"),$jt.forEach(t),XXo=r(hVe," \u2014 "),lW=n(hVe,"A",{href:!0});var kjt=s(lW);zXo=r(kjt,"BloomForCausalLM"),kjt.forEach(t),QXo=r(hVe," (BLOOM model)"),hVe.forEach(t),WXo=i(V),mb=n(V,"LI",{});var uVe=s(mb);Tve=n(uVe,"STRONG",{});var Sjt=s(Tve);UXo=r(Sjt,"camembert"),Sjt.forEach(t),HXo=r(uVe," \u2014 "),iW=n(uVe,"A",{href:!0});var Rjt=s(iW);JXo=r(Rjt,"CamembertForMaskedLM"),Rjt.forEach(t),YXo=r(uVe," (CamemBERT model)"),uVe.forEach(t),ZXo=i(V),cb=n(V,"LI",{});var pVe=s(cb);Mve=n(pVe,"STRONG",{});var Pjt=s(Mve);KXo=r(Pjt,"ctrl"),Pjt.forEach(t),ezo=r(pVe," \u2014 "),dW=n(pVe,"A",{href:!0});var Bjt=s(dW);ozo=r(Bjt,"CTRLLMHeadModel"),Bjt.forEach(t),rzo=r(pVe," (CTRL model)"),pVe.forEach(t),tzo=i(V),fb=n(V,"LI",{});var _Ve=s(fb);Eve=n(_Ve,"STRONG",{});var Ijt=s(Eve);azo=r(Ijt,"data2vec-text"),Ijt.forEach(t),nzo=r(_Ve," \u2014 "),mW=n(_Ve,"A",{href:!0});var Njt=s(mW);szo=r(Njt,"Data2VecTextForMaskedLM"),Njt.forEach(t),lzo=r(_Ve," (Data2VecText model)"),_Ve.forEach(t),izo=i(V),gb=n(V,"LI",{});var bVe=s(gb);Cve=n(bVe,"STRONG",{});var qjt=s(Cve);dzo=r(qjt,"deberta"),qjt.forEach(t),mzo=r(bVe," \u2014 "),cW=n(bVe,"A",{href:!0});var Djt=s(cW);czo=r(Djt,"DebertaForMaskedLM"),Djt.forEach(t),fzo=r(bVe," (DeBERTa model)"),bVe.forEach(t),gzo=i(V),hb=n(V,"LI",{});var vVe=s(hb);wve=n(vVe,"STRONG",{});var jjt=s(wve);hzo=r(jjt,"deberta-v2"),jjt.forEach(t),uzo=r(vVe," \u2014 "),fW=n(vVe,"A",{href:!0});var Gjt=s(fW);pzo=r(Gjt,"DebertaV2ForMaskedLM"),Gjt.forEach(t),_zo=r(vVe," (DeBERTa-v2 model)"),vVe.forEach(t),bzo=i(V),ub=n(V,"LI",{});var FVe=s(ub);Ave=n(FVe,"STRONG",{});var Ojt=s(Ave);vzo=r(Ojt,"distilbert"),Ojt.forEach(t),Fzo=r(FVe," \u2014 "),gW=n(FVe,"A",{href:!0});var Vjt=s(gW);Tzo=r(Vjt,"DistilBertForMaskedLM"),Vjt.forEach(t),Mzo=r(FVe," (DistilBERT model)"),FVe.forEach(t),Ezo=i(V),pb=n(V,"LI",{});var TVe=s(pb);Lve=n(TVe,"STRONG",{});var Xjt=s(Lve);Czo=r(Xjt,"electra"),Xjt.forEach(t),wzo=r(TVe," \u2014 "),hW=n(TVe,"A",{href:!0});var zjt=s(hW);Azo=r(zjt,"ElectraForPreTraining"),zjt.forEach(t),Lzo=r(TVe," (ELECTRA model)"),TVe.forEach(t),yzo=i(V),_b=n(V,"LI",{});var MVe=s(_b);yve=n(MVe,"STRONG",{});var Qjt=s(yve);xzo=r(Qjt,"ernie"),Qjt.forEach(t),$zo=r(MVe," \u2014 "),uW=n(MVe,"A",{href:!0});var Wjt=s(uW);kzo=r(Wjt,"ErnieForPreTraining"),Wjt.forEach(t),Szo=r(MVe," (ERNIE model)"),MVe.forEach(t),Rzo=i(V),bb=n(V,"LI",{});var EVe=s(bb);xve=n(EVe,"STRONG",{});var Ujt=s(xve);Pzo=r(Ujt,"flaubert"),Ujt.forEach(t),Bzo=r(EVe," \u2014 "),pW=n(EVe,"A",{href:!0});var Hjt=s(pW);Izo=r(Hjt,"FlaubertWithLMHeadModel"),Hjt.forEach(t),Nzo=r(EVe," (FlauBERT model)"),EVe.forEach(t),qzo=i(V),vb=n(V,"LI",{});var CVe=s(vb);$ve=n(CVe,"STRONG",{});var Jjt=s($ve);Dzo=r(Jjt,"flava"),Jjt.forEach(t),jzo=r(CVe," \u2014 "),_W=n(CVe,"A",{href:!0});var Yjt=s(_W);Gzo=r(Yjt,"FlavaForPreTraining"),Yjt.forEach(t),Ozo=r(CVe," (FLAVA model)"),CVe.forEach(t),Vzo=i(V),Fb=n(V,"LI",{});var wVe=s(Fb);kve=n(wVe,"STRONG",{});var Zjt=s(kve);Xzo=r(Zjt,"fnet"),Zjt.forEach(t),zzo=r(wVe," \u2014 "),bW=n(wVe,"A",{href:!0});var Kjt=s(bW);Qzo=r(Kjt,"FNetForPreTraining"),Kjt.forEach(t),Wzo=r(wVe," (FNet model)"),wVe.forEach(t),Uzo=i(V),Tb=n(V,"LI",{});var AVe=s(Tb);Sve=n(AVe,"STRONG",{});var eGt=s(Sve);Hzo=r(eGt,"fsmt"),eGt.forEach(t),Jzo=r(AVe," \u2014 "),vW=n(AVe,"A",{href:!0});var oGt=s(vW);Yzo=r(oGt,"FSMTForConditionalGeneration"),oGt.forEach(t),Zzo=r(AVe," (FairSeq Machine-Translation model)"),AVe.forEach(t),Kzo=i(V),Mb=n(V,"LI",{});var LVe=s(Mb);Rve=n(LVe,"STRONG",{});var rGt=s(Rve);eQo=r(rGt,"funnel"),rGt.forEach(t),oQo=r(LVe," \u2014 "),FW=n(LVe,"A",{href:!0});var tGt=s(FW);rQo=r(tGt,"FunnelForPreTraining"),tGt.forEach(t),tQo=r(LVe," (Funnel Transformer model)"),LVe.forEach(t),aQo=i(V),Eb=n(V,"LI",{});var yVe=s(Eb);Pve=n(yVe,"STRONG",{});var aGt=s(Pve);nQo=r(aGt,"gpt2"),aGt.forEach(t),sQo=r(yVe," \u2014 "),TW=n(yVe,"A",{href:!0});var nGt=s(TW);lQo=r(nGt,"GPT2LMHeadModel"),nGt.forEach(t),iQo=r(yVe," (OpenAI GPT-2 model)"),yVe.forEach(t),dQo=i(V),Cb=n(V,"LI",{});var xVe=s(Cb);Bve=n(xVe,"STRONG",{});var sGt=s(Bve);mQo=r(sGt,"ibert"),sGt.forEach(t),cQo=r(xVe," \u2014 "),MW=n(xVe,"A",{href:!0});var lGt=s(MW);fQo=r(lGt,"IBertForMaskedLM"),lGt.forEach(t),gQo=r(xVe," (I-BERT model)"),xVe.forEach(t),hQo=i(V),wb=n(V,"LI",{});var $Ve=s(wb);Ive=n($Ve,"STRONG",{});var iGt=s(Ive);uQo=r(iGt,"layoutlm"),iGt.forEach(t),pQo=r($Ve," \u2014 "),EW=n($Ve,"A",{href:!0});var dGt=s(EW);_Qo=r(dGt,"LayoutLMForMaskedLM"),dGt.forEach(t),bQo=r($Ve," (LayoutLM model)"),$Ve.forEach(t),vQo=i(V),Ab=n(V,"LI",{});var kVe=s(Ab);Nve=n(kVe,"STRONG",{});var mGt=s(Nve);FQo=r(mGt,"longformer"),mGt.forEach(t),TQo=r(kVe," \u2014 "),CW=n(kVe,"A",{href:!0});var cGt=s(CW);MQo=r(cGt,"LongformerForMaskedLM"),cGt.forEach(t),EQo=r(kVe," (Longformer model)"),kVe.forEach(t),CQo=i(V),Lb=n(V,"LI",{});var SVe=s(Lb);qve=n(SVe,"STRONG",{});var fGt=s(qve);wQo=r(fGt,"luke"),fGt.forEach(t),AQo=r(SVe," \u2014 "),wW=n(SVe,"A",{href:!0});var gGt=s(wW);LQo=r(gGt,"LukeForMaskedLM"),gGt.forEach(t),yQo=r(SVe," (LUKE model)"),SVe.forEach(t),xQo=i(V),yb=n(V,"LI",{});var RVe=s(yb);Dve=n(RVe,"STRONG",{});var hGt=s(Dve);$Qo=r(hGt,"lxmert"),hGt.forEach(t),kQo=r(RVe," \u2014 "),AW=n(RVe,"A",{href:!0});var uGt=s(AW);SQo=r(uGt,"LxmertForPreTraining"),uGt.forEach(t),RQo=r(RVe," (LXMERT model)"),RVe.forEach(t),PQo=i(V),xb=n(V,"LI",{});var PVe=s(xb);jve=n(PVe,"STRONG",{});var pGt=s(jve);BQo=r(pGt,"megatron-bert"),pGt.forEach(t),IQo=r(PVe," \u2014 "),LW=n(PVe,"A",{href:!0});var _Gt=s(LW);NQo=r(_Gt,"MegatronBertForPreTraining"),_Gt.forEach(t),qQo=r(PVe," (Megatron-BERT model)"),PVe.forEach(t),DQo=i(V),$b=n(V,"LI",{});var BVe=s($b);Gve=n(BVe,"STRONG",{});var bGt=s(Gve);jQo=r(bGt,"mobilebert"),bGt.forEach(t),GQo=r(BVe," \u2014 "),yW=n(BVe,"A",{href:!0});var vGt=s(yW);OQo=r(vGt,"MobileBertForPreTraining"),vGt.forEach(t),VQo=r(BVe," (MobileBERT model)"),BVe.forEach(t),XQo=i(V),kb=n(V,"LI",{});var IVe=s(kb);Ove=n(IVe,"STRONG",{});var FGt=s(Ove);zQo=r(FGt,"mpnet"),FGt.forEach(t),QQo=r(IVe," \u2014 "),xW=n(IVe,"A",{href:!0});var TGt=s(xW);WQo=r(TGt,"MPNetForMaskedLM"),TGt.forEach(t),UQo=r(IVe," (MPNet model)"),IVe.forEach(t),HQo=i(V),Sb=n(V,"LI",{});var NVe=s(Sb);Vve=n(NVe,"STRONG",{});var MGt=s(Vve);JQo=r(MGt,"mvp"),MGt.forEach(t),YQo=r(NVe," \u2014 "),$W=n(NVe,"A",{href:!0});var EGt=s($W);ZQo=r(EGt,"MvpForConditionalGeneration"),EGt.forEach(t),KQo=r(NVe," (MVP model)"),NVe.forEach(t),eWo=i(V),Rb=n(V,"LI",{});var qVe=s(Rb);Xve=n(qVe,"STRONG",{});var CGt=s(Xve);oWo=r(CGt,"nezha"),CGt.forEach(t),rWo=r(qVe," \u2014 "),kW=n(qVe,"A",{href:!0});var wGt=s(kW);tWo=r(wGt,"NezhaForPreTraining"),wGt.forEach(t),aWo=r(qVe," (Nezha model)"),qVe.forEach(t),nWo=i(V),Pb=n(V,"LI",{});var DVe=s(Pb);zve=n(DVe,"STRONG",{});var AGt=s(zve);sWo=r(AGt,"openai-gpt"),AGt.forEach(t),lWo=r(DVe," \u2014 "),SW=n(DVe,"A",{href:!0});var LGt=s(SW);iWo=r(LGt,"OpenAIGPTLMHeadModel"),LGt.forEach(t),dWo=r(DVe," (OpenAI GPT model)"),DVe.forEach(t),mWo=i(V),Bb=n(V,"LI",{});var jVe=s(Bb);Qve=n(jVe,"STRONG",{});var yGt=s(Qve);cWo=r(yGt,"retribert"),yGt.forEach(t),fWo=r(jVe," \u2014 "),RW=n(jVe,"A",{href:!0});var xGt=s(RW);gWo=r(xGt,"RetriBertModel"),xGt.forEach(t),hWo=r(jVe," (RetriBERT model)"),jVe.forEach(t),uWo=i(V),Ib=n(V,"LI",{});var GVe=s(Ib);Wve=n(GVe,"STRONG",{});var $Gt=s(Wve);pWo=r($Gt,"roberta"),$Gt.forEach(t),_Wo=r(GVe," \u2014 "),PW=n(GVe,"A",{href:!0});var kGt=s(PW);bWo=r(kGt,"RobertaForMaskedLM"),kGt.forEach(t),vWo=r(GVe," (RoBERTa model)"),GVe.forEach(t),FWo=i(V),Nb=n(V,"LI",{});var OVe=s(Nb);Uve=n(OVe,"STRONG",{});var SGt=s(Uve);TWo=r(SGt,"splinter"),SGt.forEach(t),MWo=r(OVe," \u2014 "),BW=n(OVe,"A",{href:!0});var RGt=s(BW);EWo=r(RGt,"SplinterForPreTraining"),RGt.forEach(t),CWo=r(OVe," (Splinter model)"),OVe.forEach(t),wWo=i(V),qb=n(V,"LI",{});var VVe=s(qb);Hve=n(VVe,"STRONG",{});var PGt=s(Hve);AWo=r(PGt,"squeezebert"),PGt.forEach(t),LWo=r(VVe," \u2014 "),IW=n(VVe,"A",{href:!0});var BGt=s(IW);yWo=r(BGt,"SqueezeBertForMaskedLM"),BGt.forEach(t),xWo=r(VVe," (SqueezeBERT model)"),VVe.forEach(t),$Wo=i(V),Db=n(V,"LI",{});var XVe=s(Db);Jve=n(XVe,"STRONG",{});var IGt=s(Jve);kWo=r(IGt,"t5"),IGt.forEach(t),SWo=r(XVe," \u2014 "),NW=n(XVe,"A",{href:!0});var NGt=s(NW);RWo=r(NGt,"T5ForConditionalGeneration"),NGt.forEach(t),PWo=r(XVe," (T5 model)"),XVe.forEach(t),BWo=i(V),jb=n(V,"LI",{});var zVe=s(jb);Yve=n(zVe,"STRONG",{});var qGt=s(Yve);IWo=r(qGt,"tapas"),qGt.forEach(t),NWo=r(zVe," \u2014 "),qW=n(zVe,"A",{href:!0});var DGt=s(qW);qWo=r(DGt,"TapasForMaskedLM"),DGt.forEach(t),DWo=r(zVe," (TAPAS model)"),zVe.forEach(t),jWo=i(V),Gb=n(V,"LI",{});var QVe=s(Gb);Zve=n(QVe,"STRONG",{});var jGt=s(Zve);GWo=r(jGt,"transfo-xl"),jGt.forEach(t),OWo=r(QVe," \u2014 "),DW=n(QVe,"A",{href:!0});var GGt=s(DW);VWo=r(GGt,"TransfoXLLMHeadModel"),GGt.forEach(t),XWo=r(QVe," (Transformer-XL model)"),QVe.forEach(t),zWo=i(V),Ob=n(V,"LI",{});var WVe=s(Ob);Kve=n(WVe,"STRONG",{});var OGt=s(Kve);QWo=r(OGt,"unispeech"),OGt.forEach(t),WWo=r(WVe," \u2014 "),jW=n(WVe,"A",{href:!0});var VGt=s(jW);UWo=r(VGt,"UniSpeechForPreTraining"),VGt.forEach(t),HWo=r(WVe," (UniSpeech model)"),WVe.forEach(t),JWo=i(V),Vb=n(V,"LI",{});var UVe=s(Vb);eFe=n(UVe,"STRONG",{});var XGt=s(eFe);YWo=r(XGt,"unispeech-sat"),XGt.forEach(t),ZWo=r(UVe," \u2014 "),GW=n(UVe,"A",{href:!0});var zGt=s(GW);KWo=r(zGt,"UniSpeechSatForPreTraining"),zGt.forEach(t),eUo=r(UVe," (UniSpeechSat model)"),UVe.forEach(t),oUo=i(V),Xb=n(V,"LI",{});var HVe=s(Xb);oFe=n(HVe,"STRONG",{});var QGt=s(oFe);rUo=r(QGt,"videomae"),QGt.forEach(t),tUo=r(HVe," \u2014 "),OW=n(HVe,"A",{href:!0});var WGt=s(OW);aUo=r(WGt,"VideoMAEForPreTraining"),WGt.forEach(t),nUo=r(HVe," (VideoMAE model)"),HVe.forEach(t),sUo=i(V),zb=n(V,"LI",{});var JVe=s(zb);rFe=n(JVe,"STRONG",{});var UGt=s(rFe);lUo=r(UGt,"visual_bert"),UGt.forEach(t),iUo=r(JVe," \u2014 "),VW=n(JVe,"A",{href:!0});var HGt=s(VW);dUo=r(HGt,"VisualBertForPreTraining"),HGt.forEach(t),mUo=r(JVe," (VisualBERT model)"),JVe.forEach(t),cUo=i(V),Qb=n(V,"LI",{});var YVe=s(Qb);tFe=n(YVe,"STRONG",{});var JGt=s(tFe);fUo=r(JGt,"vit_mae"),JGt.forEach(t),gUo=r(YVe," \u2014 "),XW=n(YVe,"A",{href:!0});var YGt=s(XW);hUo=r(YGt,"ViTMAEForPreTraining"),YGt.forEach(t),uUo=r(YVe," (ViTMAE model)"),YVe.forEach(t),pUo=i(V),Wb=n(V,"LI",{});var ZVe=s(Wb);aFe=n(ZVe,"STRONG",{});var ZGt=s(aFe);_Uo=r(ZGt,"wav2vec2"),ZGt.forEach(t),bUo=r(ZVe," \u2014 "),zW=n(ZVe,"A",{href:!0});var KGt=s(zW);vUo=r(KGt,"Wav2Vec2ForPreTraining"),KGt.forEach(t),FUo=r(ZVe," (Wav2Vec2 model)"),ZVe.forEach(t),TUo=i(V),Ub=n(V,"LI",{});var KVe=s(Ub);nFe=n(KVe,"STRONG",{});var eOt=s(nFe);MUo=r(eOt,"wav2vec2-conformer"),eOt.forEach(t),EUo=r(KVe," \u2014 "),QW=n(KVe,"A",{href:!0});var oOt=s(QW);CUo=r(oOt,"Wav2Vec2ConformerForPreTraining"),oOt.forEach(t),wUo=r(KVe," (Wav2Vec2-Conformer model)"),KVe.forEach(t),AUo=i(V),Hb=n(V,"LI",{});var eXe=s(Hb);sFe=n(eXe,"STRONG",{});var rOt=s(sFe);LUo=r(rOt,"xlm"),rOt.forEach(t),yUo=r(eXe," \u2014 "),WW=n(eXe,"A",{href:!0});var tOt=s(WW);xUo=r(tOt,"XLMWithLMHeadModel"),tOt.forEach(t),$Uo=r(eXe," (XLM model)"),eXe.forEach(t),kUo=i(V),Jb=n(V,"LI",{});var oXe=s(Jb);lFe=n(oXe,"STRONG",{});var aOt=s(lFe);SUo=r(aOt,"xlm-roberta"),aOt.forEach(t),RUo=r(oXe," \u2014 "),UW=n(oXe,"A",{href:!0});var nOt=s(UW);PUo=r(nOt,"XLMRobertaForMaskedLM"),nOt.forEach(t),BUo=r(oXe," (XLM-RoBERTa model)"),oXe.forEach(t),IUo=i(V),Yb=n(V,"LI",{});var rXe=s(Yb);iFe=n(rXe,"STRONG",{});var sOt=s(iFe);NUo=r(sOt,"xlm-roberta-xl"),sOt.forEach(t),qUo=r(rXe," \u2014 "),HW=n(rXe,"A",{href:!0});var lOt=s(HW);DUo=r(lOt,"XLMRobertaXLForMaskedLM"),lOt.forEach(t),jUo=r(rXe," (XLM-RoBERTa-XL model)"),rXe.forEach(t),GUo=i(V),Zb=n(V,"LI",{});var tXe=s(Zb);dFe=n(tXe,"STRONG",{});var iOt=s(dFe);OUo=r(iOt,"xlnet"),iOt.forEach(t),VUo=r(tXe," \u2014 "),JW=n(tXe,"A",{href:!0});var dOt=s(JW);XUo=r(dOt,"XLNetLMHeadModel"),dOt.forEach(t),zUo=r(tXe," (XLNet model)"),tXe.forEach(t),V.forEach(t),QUo=i(ya),Kb=n(ya,"P",{});var aXe=s(Kb);WUo=r(aXe,"The model is set in evaluation mode by default using "),mFe=n(aXe,"CODE",{});var mOt=s(mFe);UUo=r(mOt,"model.eval()"),mOt.forEach(t),HUo=r(aXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cFe=n(aXe,"CODE",{});var cOt=s(cFe);JUo=r(cOt,"model.train()"),cOt.forEach(t),aXe.forEach(t),YUo=i(ya),T(ev.$$.fragment,ya),ya.forEach(t),Dl.forEach(t),Qto=i(c),qd=n(c,"H2",{class:!0});var mso=s(qd);ov=n(mso,"A",{id:!0,class:!0,href:!0});var fOt=s(ov);fFe=n(fOt,"SPAN",{});var gOt=s(fFe);T(Q$.$$.fragment,gOt),gOt.forEach(t),fOt.forEach(t),ZUo=i(mso),gFe=n(mso,"SPAN",{});var hOt=s(gFe);KUo=r(hOt,"AutoModelForCausalLM"),hOt.forEach(t),mso.forEach(t),Wto=i(c),qo=n(c,"DIV",{class:!0});var jl=s(qo);T(W$.$$.fragment,jl),eHo=i(jl),Dd=n(jl,"P",{});var mme=s(Dd);oHo=r(mme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),YW=n(mme,"A",{href:!0});var uOt=s(YW);rHo=r(uOt,"from_pretrained()"),uOt.forEach(t),tHo=r(mme," class method or the "),ZW=n(mme,"A",{href:!0});var pOt=s(ZW);aHo=r(pOt,"from_config()"),pOt.forEach(t),nHo=r(mme,` class
method.`),mme.forEach(t),sHo=i(jl),U$=n(jl,"P",{});var cso=s(U$);lHo=r(cso,"This class cannot be instantiated directly using "),hFe=n(cso,"CODE",{});var _Ot=s(hFe);iHo=r(_Ot,"__init__()"),_Ot.forEach(t),dHo=r(cso," (throws an error)."),cso.forEach(t),mHo=i(jl),Ct=n(jl,"DIV",{class:!0});var n9=s(Ct);T(H$.$$.fragment,n9),cHo=i(n9),uFe=n(n9,"P",{});var bOt=s(uFe);fHo=r(bOt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),bOt.forEach(t),gHo=i(n9),jd=n(n9,"P",{});var cme=s(jd);hHo=r(cme,`Note:
Loading a model from its configuration file does `),pFe=n(cme,"STRONG",{});var vOt=s(pFe);uHo=r(vOt,"not"),vOt.forEach(t),pHo=r(cme,` load the model weights. It only affects the
model\u2019s configuration. Use `),KW=n(cme,"A",{href:!0});var FOt=s(KW);_Ho=r(FOt,"from_pretrained()"),FOt.forEach(t),bHo=r(cme," to load the model weights."),cme.forEach(t),vHo=i(n9),T(rv.$$.fragment,n9),n9.forEach(t),FHo=i(jl),oo=n(jl,"DIV",{class:!0});var xa=s(oo);T(J$.$$.fragment,xa),THo=i(xa),_Fe=n(xa,"P",{});var TOt=s(_Fe);MHo=r(TOt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),TOt.forEach(t),EHo=i(xa),ln=n(xa,"P",{});var s9=s(ln);CHo=r(s9,"The model class to instantiate is selected based on the "),bFe=n(s9,"CODE",{});var MOt=s(bFe);wHo=r(MOt,"model_type"),MOt.forEach(t),AHo=r(s9,` property of the config object (either
passed as an argument or loaded from `),vFe=n(s9,"CODE",{});var EOt=s(vFe);LHo=r(EOt,"pretrained_model_name_or_path"),EOt.forEach(t),yHo=r(s9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FFe=n(s9,"CODE",{});var COt=s(FFe);xHo=r(COt,"pretrained_model_name_or_path"),COt.forEach(t),$Ho=r(s9,":"),s9.forEach(t),kHo=i(xa),W=n(xa,"UL",{});var H=s(W);tv=n(H,"LI",{});var nXe=s(tv);TFe=n(nXe,"STRONG",{});var wOt=s(TFe);SHo=r(wOt,"bart"),wOt.forEach(t),RHo=r(nXe," \u2014 "),eU=n(nXe,"A",{href:!0});var AOt=s(eU);PHo=r(AOt,"BartForCausalLM"),AOt.forEach(t),BHo=r(nXe," (BART model)"),nXe.forEach(t),IHo=i(H),av=n(H,"LI",{});var sXe=s(av);MFe=n(sXe,"STRONG",{});var LOt=s(MFe);NHo=r(LOt,"bert"),LOt.forEach(t),qHo=r(sXe," \u2014 "),oU=n(sXe,"A",{href:!0});var yOt=s(oU);DHo=r(yOt,"BertLMHeadModel"),yOt.forEach(t),jHo=r(sXe," (BERT model)"),sXe.forEach(t),GHo=i(H),nv=n(H,"LI",{});var lXe=s(nv);EFe=n(lXe,"STRONG",{});var xOt=s(EFe);OHo=r(xOt,"bert-generation"),xOt.forEach(t),VHo=r(lXe," \u2014 "),rU=n(lXe,"A",{href:!0});var $Ot=s(rU);XHo=r($Ot,"BertGenerationDecoder"),$Ot.forEach(t),zHo=r(lXe," (Bert Generation model)"),lXe.forEach(t),QHo=i(H),sv=n(H,"LI",{});var iXe=s(sv);CFe=n(iXe,"STRONG",{});var kOt=s(CFe);WHo=r(kOt,"big_bird"),kOt.forEach(t),UHo=r(iXe," \u2014 "),tU=n(iXe,"A",{href:!0});var SOt=s(tU);HHo=r(SOt,"BigBirdForCausalLM"),SOt.forEach(t),JHo=r(iXe," (BigBird model)"),iXe.forEach(t),YHo=i(H),lv=n(H,"LI",{});var dXe=s(lv);wFe=n(dXe,"STRONG",{});var ROt=s(wFe);ZHo=r(ROt,"bigbird_pegasus"),ROt.forEach(t),KHo=r(dXe," \u2014 "),aU=n(dXe,"A",{href:!0});var POt=s(aU);eJo=r(POt,"BigBirdPegasusForCausalLM"),POt.forEach(t),oJo=r(dXe," (BigBird-Pegasus model)"),dXe.forEach(t),rJo=i(H),iv=n(H,"LI",{});var mXe=s(iv);AFe=n(mXe,"STRONG",{});var BOt=s(AFe);tJo=r(BOt,"blenderbot"),BOt.forEach(t),aJo=r(mXe," \u2014 "),nU=n(mXe,"A",{href:!0});var IOt=s(nU);nJo=r(IOt,"BlenderbotForCausalLM"),IOt.forEach(t),sJo=r(mXe," (Blenderbot model)"),mXe.forEach(t),lJo=i(H),dv=n(H,"LI",{});var cXe=s(dv);LFe=n(cXe,"STRONG",{});var NOt=s(LFe);iJo=r(NOt,"blenderbot-small"),NOt.forEach(t),dJo=r(cXe," \u2014 "),sU=n(cXe,"A",{href:!0});var qOt=s(sU);mJo=r(qOt,"BlenderbotSmallForCausalLM"),qOt.forEach(t),cJo=r(cXe," (BlenderbotSmall model)"),cXe.forEach(t),fJo=i(H),mv=n(H,"LI",{});var fXe=s(mv);yFe=n(fXe,"STRONG",{});var DOt=s(yFe);gJo=r(DOt,"bloom"),DOt.forEach(t),hJo=r(fXe," \u2014 "),lU=n(fXe,"A",{href:!0});var jOt=s(lU);uJo=r(jOt,"BloomForCausalLM"),jOt.forEach(t),pJo=r(fXe," (BLOOM model)"),fXe.forEach(t),_Jo=i(H),cv=n(H,"LI",{});var gXe=s(cv);xFe=n(gXe,"STRONG",{});var GOt=s(xFe);bJo=r(GOt,"camembert"),GOt.forEach(t),vJo=r(gXe," \u2014 "),iU=n(gXe,"A",{href:!0});var OOt=s(iU);FJo=r(OOt,"CamembertForCausalLM"),OOt.forEach(t),TJo=r(gXe," (CamemBERT model)"),gXe.forEach(t),MJo=i(H),fv=n(H,"LI",{});var hXe=s(fv);$Fe=n(hXe,"STRONG",{});var VOt=s($Fe);EJo=r(VOt,"codegen"),VOt.forEach(t),CJo=r(hXe," \u2014 "),dU=n(hXe,"A",{href:!0});var XOt=s(dU);wJo=r(XOt,"CodeGenForCausalLM"),XOt.forEach(t),AJo=r(hXe," (CodeGen model)"),hXe.forEach(t),LJo=i(H),gv=n(H,"LI",{});var uXe=s(gv);kFe=n(uXe,"STRONG",{});var zOt=s(kFe);yJo=r(zOt,"ctrl"),zOt.forEach(t),xJo=r(uXe," \u2014 "),mU=n(uXe,"A",{href:!0});var QOt=s(mU);$Jo=r(QOt,"CTRLLMHeadModel"),QOt.forEach(t),kJo=r(uXe," (CTRL model)"),uXe.forEach(t),SJo=i(H),hv=n(H,"LI",{});var pXe=s(hv);SFe=n(pXe,"STRONG",{});var WOt=s(SFe);RJo=r(WOt,"data2vec-text"),WOt.forEach(t),PJo=r(pXe," \u2014 "),cU=n(pXe,"A",{href:!0});var UOt=s(cU);BJo=r(UOt,"Data2VecTextForCausalLM"),UOt.forEach(t),IJo=r(pXe," (Data2VecText model)"),pXe.forEach(t),NJo=i(H),uv=n(H,"LI",{});var _Xe=s(uv);RFe=n(_Xe,"STRONG",{});var HOt=s(RFe);qJo=r(HOt,"electra"),HOt.forEach(t),DJo=r(_Xe," \u2014 "),fU=n(_Xe,"A",{href:!0});var JOt=s(fU);jJo=r(JOt,"ElectraForCausalLM"),JOt.forEach(t),GJo=r(_Xe," (ELECTRA model)"),_Xe.forEach(t),OJo=i(H),pv=n(H,"LI",{});var bXe=s(pv);PFe=n(bXe,"STRONG",{});var YOt=s(PFe);VJo=r(YOt,"ernie"),YOt.forEach(t),XJo=r(bXe," \u2014 "),gU=n(bXe,"A",{href:!0});var ZOt=s(gU);zJo=r(ZOt,"ErnieForCausalLM"),ZOt.forEach(t),QJo=r(bXe," (ERNIE model)"),bXe.forEach(t),WJo=i(H),_v=n(H,"LI",{});var vXe=s(_v);BFe=n(vXe,"STRONG",{});var KOt=s(BFe);UJo=r(KOt,"gpt2"),KOt.forEach(t),HJo=r(vXe," \u2014 "),hU=n(vXe,"A",{href:!0});var eVt=s(hU);JJo=r(eVt,"GPT2LMHeadModel"),eVt.forEach(t),YJo=r(vXe," (OpenAI GPT-2 model)"),vXe.forEach(t),ZJo=i(H),bv=n(H,"LI",{});var FXe=s(bv);IFe=n(FXe,"STRONG",{});var oVt=s(IFe);KJo=r(oVt,"gpt_neo"),oVt.forEach(t),eYo=r(FXe," \u2014 "),uU=n(FXe,"A",{href:!0});var rVt=s(uU);oYo=r(rVt,"GPTNeoForCausalLM"),rVt.forEach(t),rYo=r(FXe," (GPT Neo model)"),FXe.forEach(t),tYo=i(H),vv=n(H,"LI",{});var TXe=s(vv);NFe=n(TXe,"STRONG",{});var tVt=s(NFe);aYo=r(tVt,"gpt_neox"),tVt.forEach(t),nYo=r(TXe," \u2014 "),pU=n(TXe,"A",{href:!0});var aVt=s(pU);sYo=r(aVt,"GPTNeoXForCausalLM"),aVt.forEach(t),lYo=r(TXe," (GPT NeoX model)"),TXe.forEach(t),iYo=i(H),Fv=n(H,"LI",{});var MXe=s(Fv);qFe=n(MXe,"STRONG",{});var nVt=s(qFe);dYo=r(nVt,"gpt_neox_japanese"),nVt.forEach(t),mYo=r(MXe," \u2014 "),_U=n(MXe,"A",{href:!0});var sVt=s(_U);cYo=r(sVt,"GPTNeoXJapaneseForCausalLM"),sVt.forEach(t),fYo=r(MXe," (GPT NeoX Japanese model)"),MXe.forEach(t),gYo=i(H),Tv=n(H,"LI",{});var EXe=s(Tv);DFe=n(EXe,"STRONG",{});var lVt=s(DFe);hYo=r(lVt,"gptj"),lVt.forEach(t),uYo=r(EXe," \u2014 "),bU=n(EXe,"A",{href:!0});var iVt=s(bU);pYo=r(iVt,"GPTJForCausalLM"),iVt.forEach(t),_Yo=r(EXe," (GPT-J model)"),EXe.forEach(t),bYo=i(H),Mv=n(H,"LI",{});var CXe=s(Mv);jFe=n(CXe,"STRONG",{});var dVt=s(jFe);vYo=r(dVt,"marian"),dVt.forEach(t),FYo=r(CXe," \u2014 "),vU=n(CXe,"A",{href:!0});var mVt=s(vU);TYo=r(mVt,"MarianForCausalLM"),mVt.forEach(t),MYo=r(CXe," (Marian model)"),CXe.forEach(t),EYo=i(H),Ev=n(H,"LI",{});var wXe=s(Ev);GFe=n(wXe,"STRONG",{});var cVt=s(GFe);CYo=r(cVt,"mbart"),cVt.forEach(t),wYo=r(wXe," \u2014 "),FU=n(wXe,"A",{href:!0});var fVt=s(FU);AYo=r(fVt,"MBartForCausalLM"),fVt.forEach(t),LYo=r(wXe," (mBART model)"),wXe.forEach(t),yYo=i(H),Cv=n(H,"LI",{});var AXe=s(Cv);OFe=n(AXe,"STRONG",{});var gVt=s(OFe);xYo=r(gVt,"megatron-bert"),gVt.forEach(t),$Yo=r(AXe," \u2014 "),TU=n(AXe,"A",{href:!0});var hVt=s(TU);kYo=r(hVt,"MegatronBertForCausalLM"),hVt.forEach(t),SYo=r(AXe," (Megatron-BERT model)"),AXe.forEach(t),RYo=i(H),wv=n(H,"LI",{});var LXe=s(wv);VFe=n(LXe,"STRONG",{});var uVt=s(VFe);PYo=r(uVt,"mvp"),uVt.forEach(t),BYo=r(LXe," \u2014 "),MU=n(LXe,"A",{href:!0});var pVt=s(MU);IYo=r(pVt,"MvpForCausalLM"),pVt.forEach(t),NYo=r(LXe," (MVP model)"),LXe.forEach(t),qYo=i(H),Av=n(H,"LI",{});var yXe=s(Av);XFe=n(yXe,"STRONG",{});var _Vt=s(XFe);DYo=r(_Vt,"openai-gpt"),_Vt.forEach(t),jYo=r(yXe," \u2014 "),EU=n(yXe,"A",{href:!0});var bVt=s(EU);GYo=r(bVt,"OpenAIGPTLMHeadModel"),bVt.forEach(t),OYo=r(yXe," (OpenAI GPT model)"),yXe.forEach(t),VYo=i(H),Lv=n(H,"LI",{});var xXe=s(Lv);zFe=n(xXe,"STRONG",{});var vVt=s(zFe);XYo=r(vVt,"opt"),vVt.forEach(t),zYo=r(xXe," \u2014 "),CU=n(xXe,"A",{href:!0});var FVt=s(CU);QYo=r(FVt,"OPTForCausalLM"),FVt.forEach(t),WYo=r(xXe," (OPT model)"),xXe.forEach(t),UYo=i(H),yv=n(H,"LI",{});var $Xe=s(yv);QFe=n($Xe,"STRONG",{});var TVt=s(QFe);HYo=r(TVt,"pegasus"),TVt.forEach(t),JYo=r($Xe," \u2014 "),wU=n($Xe,"A",{href:!0});var MVt=s(wU);YYo=r(MVt,"PegasusForCausalLM"),MVt.forEach(t),ZYo=r($Xe," (Pegasus model)"),$Xe.forEach(t),KYo=i(H),xv=n(H,"LI",{});var kXe=s(xv);WFe=n(kXe,"STRONG",{});var EVt=s(WFe);eZo=r(EVt,"plbart"),EVt.forEach(t),oZo=r(kXe," \u2014 "),AU=n(kXe,"A",{href:!0});var CVt=s(AU);rZo=r(CVt,"PLBartForCausalLM"),CVt.forEach(t),tZo=r(kXe," (PLBart model)"),kXe.forEach(t),aZo=i(H),$v=n(H,"LI",{});var SXe=s($v);UFe=n(SXe,"STRONG",{});var wVt=s(UFe);nZo=r(wVt,"prophetnet"),wVt.forEach(t),sZo=r(SXe," \u2014 "),LU=n(SXe,"A",{href:!0});var AVt=s(LU);lZo=r(AVt,"ProphetNetForCausalLM"),AVt.forEach(t),iZo=r(SXe," (ProphetNet model)"),SXe.forEach(t),dZo=i(H),kv=n(H,"LI",{});var RXe=s(kv);HFe=n(RXe,"STRONG",{});var LVt=s(HFe);mZo=r(LVt,"qdqbert"),LVt.forEach(t),cZo=r(RXe," \u2014 "),yU=n(RXe,"A",{href:!0});var yVt=s(yU);fZo=r(yVt,"QDQBertLMHeadModel"),yVt.forEach(t),gZo=r(RXe," (QDQBert model)"),RXe.forEach(t),hZo=i(H),Sv=n(H,"LI",{});var PXe=s(Sv);JFe=n(PXe,"STRONG",{});var xVt=s(JFe);uZo=r(xVt,"reformer"),xVt.forEach(t),pZo=r(PXe," \u2014 "),xU=n(PXe,"A",{href:!0});var $Vt=s(xU);_Zo=r($Vt,"ReformerModelWithLMHead"),$Vt.forEach(t),bZo=r(PXe," (Reformer model)"),PXe.forEach(t),vZo=i(H),Rv=n(H,"LI",{});var BXe=s(Rv);YFe=n(BXe,"STRONG",{});var kVt=s(YFe);FZo=r(kVt,"rembert"),kVt.forEach(t),TZo=r(BXe," \u2014 "),$U=n(BXe,"A",{href:!0});var SVt=s($U);MZo=r(SVt,"RemBertForCausalLM"),SVt.forEach(t),EZo=r(BXe," (RemBERT model)"),BXe.forEach(t),CZo=i(H),Pv=n(H,"LI",{});var IXe=s(Pv);ZFe=n(IXe,"STRONG",{});var RVt=s(ZFe);wZo=r(RVt,"roberta"),RVt.forEach(t),AZo=r(IXe," \u2014 "),kU=n(IXe,"A",{href:!0});var PVt=s(kU);LZo=r(PVt,"RobertaForCausalLM"),PVt.forEach(t),yZo=r(IXe," (RoBERTa model)"),IXe.forEach(t),xZo=i(H),Bv=n(H,"LI",{});var NXe=s(Bv);KFe=n(NXe,"STRONG",{});var BVt=s(KFe);$Zo=r(BVt,"roformer"),BVt.forEach(t),kZo=r(NXe," \u2014 "),SU=n(NXe,"A",{href:!0});var IVt=s(SU);SZo=r(IVt,"RoFormerForCausalLM"),IVt.forEach(t),RZo=r(NXe," (RoFormer model)"),NXe.forEach(t),PZo=i(H),Iv=n(H,"LI",{});var qXe=s(Iv);eTe=n(qXe,"STRONG",{});var NVt=s(eTe);BZo=r(NVt,"speech_to_text_2"),NVt.forEach(t),IZo=r(qXe," \u2014 "),RU=n(qXe,"A",{href:!0});var qVt=s(RU);NZo=r(qVt,"Speech2Text2ForCausalLM"),qVt.forEach(t),qZo=r(qXe," (Speech2Text2 model)"),qXe.forEach(t),DZo=i(H),Nv=n(H,"LI",{});var DXe=s(Nv);oTe=n(DXe,"STRONG",{});var DVt=s(oTe);jZo=r(DVt,"transfo-xl"),DVt.forEach(t),GZo=r(DXe," \u2014 "),PU=n(DXe,"A",{href:!0});var jVt=s(PU);OZo=r(jVt,"TransfoXLLMHeadModel"),jVt.forEach(t),VZo=r(DXe," (Transformer-XL model)"),DXe.forEach(t),XZo=i(H),qv=n(H,"LI",{});var jXe=s(qv);rTe=n(jXe,"STRONG",{});var GVt=s(rTe);zZo=r(GVt,"trocr"),GVt.forEach(t),QZo=r(jXe," \u2014 "),BU=n(jXe,"A",{href:!0});var OVt=s(BU);WZo=r(OVt,"TrOCRForCausalLM"),OVt.forEach(t),UZo=r(jXe," (TrOCR model)"),jXe.forEach(t),HZo=i(H),Dv=n(H,"LI",{});var GXe=s(Dv);tTe=n(GXe,"STRONG",{});var VVt=s(tTe);JZo=r(VVt,"xglm"),VVt.forEach(t),YZo=r(GXe," \u2014 "),IU=n(GXe,"A",{href:!0});var XVt=s(IU);ZZo=r(XVt,"XGLMForCausalLM"),XVt.forEach(t),KZo=r(GXe," (XGLM model)"),GXe.forEach(t),eKo=i(H),jv=n(H,"LI",{});var OXe=s(jv);aTe=n(OXe,"STRONG",{});var zVt=s(aTe);oKo=r(zVt,"xlm"),zVt.forEach(t),rKo=r(OXe," \u2014 "),NU=n(OXe,"A",{href:!0});var QVt=s(NU);tKo=r(QVt,"XLMWithLMHeadModel"),QVt.forEach(t),aKo=r(OXe," (XLM model)"),OXe.forEach(t),nKo=i(H),Gv=n(H,"LI",{});var VXe=s(Gv);nTe=n(VXe,"STRONG",{});var WVt=s(nTe);sKo=r(WVt,"xlm-prophetnet"),WVt.forEach(t),lKo=r(VXe," \u2014 "),qU=n(VXe,"A",{href:!0});var UVt=s(qU);iKo=r(UVt,"XLMProphetNetForCausalLM"),UVt.forEach(t),dKo=r(VXe," (XLM-ProphetNet model)"),VXe.forEach(t),mKo=i(H),Ov=n(H,"LI",{});var XXe=s(Ov);sTe=n(XXe,"STRONG",{});var HVt=s(sTe);cKo=r(HVt,"xlm-roberta"),HVt.forEach(t),fKo=r(XXe," \u2014 "),DU=n(XXe,"A",{href:!0});var JVt=s(DU);gKo=r(JVt,"XLMRobertaForCausalLM"),JVt.forEach(t),hKo=r(XXe," (XLM-RoBERTa model)"),XXe.forEach(t),uKo=i(H),Vv=n(H,"LI",{});var zXe=s(Vv);lTe=n(zXe,"STRONG",{});var YVt=s(lTe);pKo=r(YVt,"xlm-roberta-xl"),YVt.forEach(t),_Ko=r(zXe," \u2014 "),jU=n(zXe,"A",{href:!0});var ZVt=s(jU);bKo=r(ZVt,"XLMRobertaXLForCausalLM"),ZVt.forEach(t),vKo=r(zXe," (XLM-RoBERTa-XL model)"),zXe.forEach(t),FKo=i(H),Xv=n(H,"LI",{});var QXe=s(Xv);iTe=n(QXe,"STRONG",{});var KVt=s(iTe);TKo=r(KVt,"xlnet"),KVt.forEach(t),MKo=r(QXe," \u2014 "),GU=n(QXe,"A",{href:!0});var eXt=s(GU);EKo=r(eXt,"XLNetLMHeadModel"),eXt.forEach(t),CKo=r(QXe," (XLNet model)"),QXe.forEach(t),H.forEach(t),wKo=i(xa),zv=n(xa,"P",{});var WXe=s(zv);AKo=r(WXe,"The model is set in evaluation mode by default using "),dTe=n(WXe,"CODE",{});var oXt=s(dTe);LKo=r(oXt,"model.eval()"),oXt.forEach(t),yKo=r(WXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mTe=n(WXe,"CODE",{});var rXt=s(mTe);xKo=r(rXt,"model.train()"),rXt.forEach(t),WXe.forEach(t),$Ko=i(xa),T(Qv.$$.fragment,xa),xa.forEach(t),jl.forEach(t),Uto=i(c),Gd=n(c,"H2",{class:!0});var fso=s(Gd);Wv=n(fso,"A",{id:!0,class:!0,href:!0});var tXt=s(Wv);cTe=n(tXt,"SPAN",{});var aXt=s(cTe);T(Y$.$$.fragment,aXt),aXt.forEach(t),tXt.forEach(t),kKo=i(fso),fTe=n(fso,"SPAN",{});var nXt=s(fTe);SKo=r(nXt,"AutoModelForDepthEstimation"),nXt.forEach(t),fso.forEach(t),Hto=i(c),Do=n(c,"DIV",{class:!0});var Gl=s(Do);T(Z$.$$.fragment,Gl),RKo=i(Gl),Od=n(Gl,"P",{});var fme=s(Od);PKo=r(fme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a depth estimation head) when created
with the `),OU=n(fme,"A",{href:!0});var sXt=s(OU);BKo=r(sXt,"from_pretrained()"),sXt.forEach(t),IKo=r(fme," class method or the "),VU=n(fme,"A",{href:!0});var lXt=s(VU);NKo=r(lXt,"from_config()"),lXt.forEach(t),qKo=r(fme,` class
method.`),fme.forEach(t),DKo=i(Gl),K$=n(Gl,"P",{});var gso=s(K$);jKo=r(gso,"This class cannot be instantiated directly using "),gTe=n(gso,"CODE",{});var iXt=s(gTe);GKo=r(iXt,"__init__()"),iXt.forEach(t),OKo=r(gso," (throws an error)."),gso.forEach(t),VKo=i(Gl),wt=n(Gl,"DIV",{class:!0});var l9=s(wt);T(ek.$$.fragment,l9),XKo=i(l9),hTe=n(l9,"P",{});var dXt=s(hTe);zKo=r(dXt,"Instantiates one of the model classes of the library (with a depth estimation head) from a configuration."),dXt.forEach(t),QKo=i(l9),Vd=n(l9,"P",{});var gme=s(Vd);WKo=r(gme,`Note:
Loading a model from its configuration file does `),uTe=n(gme,"STRONG",{});var mXt=s(uTe);UKo=r(mXt,"not"),mXt.forEach(t),HKo=r(gme,` load the model weights. It only affects the
model\u2019s configuration. Use `),XU=n(gme,"A",{href:!0});var cXt=s(XU);JKo=r(cXt,"from_pretrained()"),cXt.forEach(t),YKo=r(gme," to load the model weights."),gme.forEach(t),ZKo=i(l9),T(Uv.$$.fragment,l9),l9.forEach(t),KKo=i(Gl),ro=n(Gl,"DIV",{class:!0});var $a=s(ro);T(ok.$$.fragment,$a),eer=i($a),pTe=n($a,"P",{});var fXt=s(pTe);oer=r(fXt,"Instantiate one of the model classes of the library (with a depth estimation head) from a pretrained model."),fXt.forEach(t),rer=i($a),dn=n($a,"P",{});var i9=s(dn);ter=r(i9,"The model class to instantiate is selected based on the "),_Te=n(i9,"CODE",{});var gXt=s(_Te);aer=r(gXt,"model_type"),gXt.forEach(t),ner=r(i9,` property of the config object (either
passed as an argument or loaded from `),bTe=n(i9,"CODE",{});var hXt=s(bTe);ser=r(hXt,"pretrained_model_name_or_path"),hXt.forEach(t),ler=r(i9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vTe=n(i9,"CODE",{});var uXt=s(vTe);ier=r(uXt,"pretrained_model_name_or_path"),uXt.forEach(t),der=r(i9,":"),i9.forEach(t),mer=i($a),rk=n($a,"UL",{});var hso=s(rk);Hv=n(hso,"LI",{});var UXe=s(Hv);FTe=n(UXe,"STRONG",{});var pXt=s(FTe);cer=r(pXt,"dpt"),pXt.forEach(t),fer=r(UXe," \u2014 "),zU=n(UXe,"A",{href:!0});var _Xt=s(zU);ger=r(_Xt,"DPTForDepthEstimation"),_Xt.forEach(t),her=r(UXe," (DPT model)"),UXe.forEach(t),uer=i(hso),Jv=n(hso,"LI",{});var HXe=s(Jv);TTe=n(HXe,"STRONG",{});var bXt=s(TTe);per=r(bXt,"glpn"),bXt.forEach(t),_er=r(HXe," \u2014 "),QU=n(HXe,"A",{href:!0});var vXt=s(QU);ber=r(vXt,"GLPNForDepthEstimation"),vXt.forEach(t),ver=r(HXe," (GLPN model)"),HXe.forEach(t),hso.forEach(t),Fer=i($a),Yv=n($a,"P",{});var JXe=s(Yv);Ter=r(JXe,"The model is set in evaluation mode by default using "),MTe=n(JXe,"CODE",{});var FXt=s(MTe);Mer=r(FXt,"model.eval()"),FXt.forEach(t),Eer=r(JXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ETe=n(JXe,"CODE",{});var TXt=s(ETe);Cer=r(TXt,"model.train()"),TXt.forEach(t),JXe.forEach(t),wer=i($a),T(Zv.$$.fragment,$a),$a.forEach(t),Gl.forEach(t),Jto=i(c),Xd=n(c,"H2",{class:!0});var uso=s(Xd);Kv=n(uso,"A",{id:!0,class:!0,href:!0});var MXt=s(Kv);CTe=n(MXt,"SPAN",{});var EXt=s(CTe);T(tk.$$.fragment,EXt),EXt.forEach(t),MXt.forEach(t),Aer=i(uso),wTe=n(uso,"SPAN",{});var CXt=s(wTe);Ler=r(CXt,"AutoModelForMaskedLM"),CXt.forEach(t),uso.forEach(t),Yto=i(c),jo=n(c,"DIV",{class:!0});var Ol=s(jo);T(ak.$$.fragment,Ol),yer=i(Ol),zd=n(Ol,"P",{});var hme=s(zd);xer=r(hme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),WU=n(hme,"A",{href:!0});var wXt=s(WU);$er=r(wXt,"from_pretrained()"),wXt.forEach(t),ker=r(hme," class method or the "),UU=n(hme,"A",{href:!0});var AXt=s(UU);Ser=r(AXt,"from_config()"),AXt.forEach(t),Rer=r(hme,` class
method.`),hme.forEach(t),Per=i(Ol),nk=n(Ol,"P",{});var pso=s(nk);Ber=r(pso,"This class cannot be instantiated directly using "),ATe=n(pso,"CODE",{});var LXt=s(ATe);Ier=r(LXt,"__init__()"),LXt.forEach(t),Ner=r(pso," (throws an error)."),pso.forEach(t),qer=i(Ol),At=n(Ol,"DIV",{class:!0});var d9=s(At);T(sk.$$.fragment,d9),Der=i(d9),LTe=n(d9,"P",{});var yXt=s(LTe);jer=r(yXt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),yXt.forEach(t),Ger=i(d9),Qd=n(d9,"P",{});var ume=s(Qd);Oer=r(ume,`Note:
Loading a model from its configuration file does `),yTe=n(ume,"STRONG",{});var xXt=s(yTe);Ver=r(xXt,"not"),xXt.forEach(t),Xer=r(ume,` load the model weights. It only affects the
model\u2019s configuration. Use `),HU=n(ume,"A",{href:!0});var $Xt=s(HU);zer=r($Xt,"from_pretrained()"),$Xt.forEach(t),Qer=r(ume," to load the model weights."),ume.forEach(t),Wer=i(d9),T(eF.$$.fragment,d9),d9.forEach(t),Uer=i(Ol),to=n(Ol,"DIV",{class:!0});var ka=s(to);T(lk.$$.fragment,ka),Her=i(ka),xTe=n(ka,"P",{});var kXt=s(xTe);Jer=r(kXt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),kXt.forEach(t),Yer=i(ka),mn=n(ka,"P",{});var m9=s(mn);Zer=r(m9,"The model class to instantiate is selected based on the "),$Te=n(m9,"CODE",{});var SXt=s($Te);Ker=r(SXt,"model_type"),SXt.forEach(t),eor=r(m9,` property of the config object (either
passed as an argument or loaded from `),kTe=n(m9,"CODE",{});var RXt=s(kTe);oor=r(RXt,"pretrained_model_name_or_path"),RXt.forEach(t),ror=r(m9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),STe=n(m9,"CODE",{});var PXt=s(STe);tor=r(PXt,"pretrained_model_name_or_path"),PXt.forEach(t),aor=r(m9,":"),m9.forEach(t),nor=i(ka),Y=n(ka,"UL",{});var Z=s(Y);oF=n(Z,"LI",{});var YXe=s(oF);RTe=n(YXe,"STRONG",{});var BXt=s(RTe);sor=r(BXt,"albert"),BXt.forEach(t),lor=r(YXe," \u2014 "),JU=n(YXe,"A",{href:!0});var IXt=s(JU);ior=r(IXt,"AlbertForMaskedLM"),IXt.forEach(t),dor=r(YXe," (ALBERT model)"),YXe.forEach(t),mor=i(Z),rF=n(Z,"LI",{});var ZXe=s(rF);PTe=n(ZXe,"STRONG",{});var NXt=s(PTe);cor=r(NXt,"bart"),NXt.forEach(t),gor=r(ZXe," \u2014 "),YU=n(ZXe,"A",{href:!0});var qXt=s(YU);hor=r(qXt,"BartForConditionalGeneration"),qXt.forEach(t),uor=r(ZXe," (BART model)"),ZXe.forEach(t),por=i(Z),tF=n(Z,"LI",{});var KXe=s(tF);BTe=n(KXe,"STRONG",{});var DXt=s(BTe);_or=r(DXt,"bert"),DXt.forEach(t),bor=r(KXe," \u2014 "),ZU=n(KXe,"A",{href:!0});var jXt=s(ZU);vor=r(jXt,"BertForMaskedLM"),jXt.forEach(t),For=r(KXe," (BERT model)"),KXe.forEach(t),Tor=i(Z),aF=n(Z,"LI",{});var eze=s(aF);ITe=n(eze,"STRONG",{});var GXt=s(ITe);Mor=r(GXt,"big_bird"),GXt.forEach(t),Eor=r(eze," \u2014 "),KU=n(eze,"A",{href:!0});var OXt=s(KU);Cor=r(OXt,"BigBirdForMaskedLM"),OXt.forEach(t),wor=r(eze," (BigBird model)"),eze.forEach(t),Aor=i(Z),nF=n(Z,"LI",{});var oze=s(nF);NTe=n(oze,"STRONG",{});var VXt=s(NTe);Lor=r(VXt,"camembert"),VXt.forEach(t),yor=r(oze," \u2014 "),eH=n(oze,"A",{href:!0});var XXt=s(eH);xor=r(XXt,"CamembertForMaskedLM"),XXt.forEach(t),$or=r(oze," (CamemBERT model)"),oze.forEach(t),kor=i(Z),sF=n(Z,"LI",{});var rze=s(sF);qTe=n(rze,"STRONG",{});var zXt=s(qTe);Sor=r(zXt,"convbert"),zXt.forEach(t),Ror=r(rze," \u2014 "),oH=n(rze,"A",{href:!0});var QXt=s(oH);Por=r(QXt,"ConvBertForMaskedLM"),QXt.forEach(t),Bor=r(rze," (ConvBERT model)"),rze.forEach(t),Ior=i(Z),lF=n(Z,"LI",{});var tze=s(lF);DTe=n(tze,"STRONG",{});var WXt=s(DTe);Nor=r(WXt,"data2vec-text"),WXt.forEach(t),qor=r(tze," \u2014 "),rH=n(tze,"A",{href:!0});var UXt=s(rH);Dor=r(UXt,"Data2VecTextForMaskedLM"),UXt.forEach(t),jor=r(tze," (Data2VecText model)"),tze.forEach(t),Gor=i(Z),iF=n(Z,"LI",{});var aze=s(iF);jTe=n(aze,"STRONG",{});var HXt=s(jTe);Oor=r(HXt,"deberta"),HXt.forEach(t),Vor=r(aze," \u2014 "),tH=n(aze,"A",{href:!0});var JXt=s(tH);Xor=r(JXt,"DebertaForMaskedLM"),JXt.forEach(t),zor=r(aze," (DeBERTa model)"),aze.forEach(t),Qor=i(Z),dF=n(Z,"LI",{});var nze=s(dF);GTe=n(nze,"STRONG",{});var YXt=s(GTe);Wor=r(YXt,"deberta-v2"),YXt.forEach(t),Uor=r(nze," \u2014 "),aH=n(nze,"A",{href:!0});var ZXt=s(aH);Hor=r(ZXt,"DebertaV2ForMaskedLM"),ZXt.forEach(t),Jor=r(nze," (DeBERTa-v2 model)"),nze.forEach(t),Yor=i(Z),mF=n(Z,"LI",{});var sze=s(mF);OTe=n(sze,"STRONG",{});var KXt=s(OTe);Zor=r(KXt,"distilbert"),KXt.forEach(t),Kor=r(sze," \u2014 "),nH=n(sze,"A",{href:!0});var ezt=s(nH);err=r(ezt,"DistilBertForMaskedLM"),ezt.forEach(t),orr=r(sze," (DistilBERT model)"),sze.forEach(t),rrr=i(Z),cF=n(Z,"LI",{});var lze=s(cF);VTe=n(lze,"STRONG",{});var ozt=s(VTe);trr=r(ozt,"electra"),ozt.forEach(t),arr=r(lze," \u2014 "),sH=n(lze,"A",{href:!0});var rzt=s(sH);nrr=r(rzt,"ElectraForMaskedLM"),rzt.forEach(t),srr=r(lze," (ELECTRA model)"),lze.forEach(t),lrr=i(Z),fF=n(Z,"LI",{});var ize=s(fF);XTe=n(ize,"STRONG",{});var tzt=s(XTe);irr=r(tzt,"ernie"),tzt.forEach(t),drr=r(ize," \u2014 "),lH=n(ize,"A",{href:!0});var azt=s(lH);mrr=r(azt,"ErnieForMaskedLM"),azt.forEach(t),crr=r(ize," (ERNIE model)"),ize.forEach(t),frr=i(Z),gF=n(Z,"LI",{});var dze=s(gF);zTe=n(dze,"STRONG",{});var nzt=s(zTe);grr=r(nzt,"flaubert"),nzt.forEach(t),hrr=r(dze," \u2014 "),iH=n(dze,"A",{href:!0});var szt=s(iH);urr=r(szt,"FlaubertWithLMHeadModel"),szt.forEach(t),prr=r(dze," (FlauBERT model)"),dze.forEach(t),_rr=i(Z),hF=n(Z,"LI",{});var mze=s(hF);QTe=n(mze,"STRONG",{});var lzt=s(QTe);brr=r(lzt,"fnet"),lzt.forEach(t),vrr=r(mze," \u2014 "),dH=n(mze,"A",{href:!0});var izt=s(dH);Frr=r(izt,"FNetForMaskedLM"),izt.forEach(t),Trr=r(mze," (FNet model)"),mze.forEach(t),Mrr=i(Z),uF=n(Z,"LI",{});var cze=s(uF);WTe=n(cze,"STRONG",{});var dzt=s(WTe);Err=r(dzt,"funnel"),dzt.forEach(t),Crr=r(cze," \u2014 "),mH=n(cze,"A",{href:!0});var mzt=s(mH);wrr=r(mzt,"FunnelForMaskedLM"),mzt.forEach(t),Arr=r(cze," (Funnel Transformer model)"),cze.forEach(t),Lrr=i(Z),pF=n(Z,"LI",{});var fze=s(pF);UTe=n(fze,"STRONG",{});var czt=s(UTe);yrr=r(czt,"ibert"),czt.forEach(t),xrr=r(fze," \u2014 "),cH=n(fze,"A",{href:!0});var fzt=s(cH);$rr=r(fzt,"IBertForMaskedLM"),fzt.forEach(t),krr=r(fze," (I-BERT model)"),fze.forEach(t),Srr=i(Z),_F=n(Z,"LI",{});var gze=s(_F);HTe=n(gze,"STRONG",{});var gzt=s(HTe);Rrr=r(gzt,"layoutlm"),gzt.forEach(t),Prr=r(gze," \u2014 "),fH=n(gze,"A",{href:!0});var hzt=s(fH);Brr=r(hzt,"LayoutLMForMaskedLM"),hzt.forEach(t),Irr=r(gze," (LayoutLM model)"),gze.forEach(t),Nrr=i(Z),bF=n(Z,"LI",{});var hze=s(bF);JTe=n(hze,"STRONG",{});var uzt=s(JTe);qrr=r(uzt,"longformer"),uzt.forEach(t),Drr=r(hze," \u2014 "),gH=n(hze,"A",{href:!0});var pzt=s(gH);jrr=r(pzt,"LongformerForMaskedLM"),pzt.forEach(t),Grr=r(hze," (Longformer model)"),hze.forEach(t),Orr=i(Z),vF=n(Z,"LI",{});var uze=s(vF);YTe=n(uze,"STRONG",{});var _zt=s(YTe);Vrr=r(_zt,"luke"),_zt.forEach(t),Xrr=r(uze," \u2014 "),hH=n(uze,"A",{href:!0});var bzt=s(hH);zrr=r(bzt,"LukeForMaskedLM"),bzt.forEach(t),Qrr=r(uze," (LUKE model)"),uze.forEach(t),Wrr=i(Z),FF=n(Z,"LI",{});var pze=s(FF);ZTe=n(pze,"STRONG",{});var vzt=s(ZTe);Urr=r(vzt,"mbart"),vzt.forEach(t),Hrr=r(pze," \u2014 "),uH=n(pze,"A",{href:!0});var Fzt=s(uH);Jrr=r(Fzt,"MBartForConditionalGeneration"),Fzt.forEach(t),Yrr=r(pze," (mBART model)"),pze.forEach(t),Zrr=i(Z),TF=n(Z,"LI",{});var _ze=s(TF);KTe=n(_ze,"STRONG",{});var Tzt=s(KTe);Krr=r(Tzt,"megatron-bert"),Tzt.forEach(t),etr=r(_ze," \u2014 "),pH=n(_ze,"A",{href:!0});var Mzt=s(pH);otr=r(Mzt,"MegatronBertForMaskedLM"),Mzt.forEach(t),rtr=r(_ze," (Megatron-BERT model)"),_ze.forEach(t),ttr=i(Z),MF=n(Z,"LI",{});var bze=s(MF);eMe=n(bze,"STRONG",{});var Ezt=s(eMe);atr=r(Ezt,"mobilebert"),Ezt.forEach(t),ntr=r(bze," \u2014 "),_H=n(bze,"A",{href:!0});var Czt=s(_H);str=r(Czt,"MobileBertForMaskedLM"),Czt.forEach(t),ltr=r(bze," (MobileBERT model)"),bze.forEach(t),itr=i(Z),EF=n(Z,"LI",{});var vze=s(EF);oMe=n(vze,"STRONG",{});var wzt=s(oMe);dtr=r(wzt,"mpnet"),wzt.forEach(t),mtr=r(vze," \u2014 "),bH=n(vze,"A",{href:!0});var Azt=s(bH);ctr=r(Azt,"MPNetForMaskedLM"),Azt.forEach(t),ftr=r(vze," (MPNet model)"),vze.forEach(t),gtr=i(Z),CF=n(Z,"LI",{});var Fze=s(CF);rMe=n(Fze,"STRONG",{});var Lzt=s(rMe);htr=r(Lzt,"mvp"),Lzt.forEach(t),utr=r(Fze," \u2014 "),vH=n(Fze,"A",{href:!0});var yzt=s(vH);ptr=r(yzt,"MvpForConditionalGeneration"),yzt.forEach(t),_tr=r(Fze," (MVP model)"),Fze.forEach(t),btr=i(Z),wF=n(Z,"LI",{});var Tze=s(wF);tMe=n(Tze,"STRONG",{});var xzt=s(tMe);vtr=r(xzt,"nezha"),xzt.forEach(t),Ftr=r(Tze," \u2014 "),FH=n(Tze,"A",{href:!0});var $zt=s(FH);Ttr=r($zt,"NezhaForMaskedLM"),$zt.forEach(t),Mtr=r(Tze," (Nezha model)"),Tze.forEach(t),Etr=i(Z),AF=n(Z,"LI",{});var Mze=s(AF);aMe=n(Mze,"STRONG",{});var kzt=s(aMe);Ctr=r(kzt,"nystromformer"),kzt.forEach(t),wtr=r(Mze," \u2014 "),TH=n(Mze,"A",{href:!0});var Szt=s(TH);Atr=r(Szt,"NystromformerForMaskedLM"),Szt.forEach(t),Ltr=r(Mze," (Nystr\xF6mformer model)"),Mze.forEach(t),ytr=i(Z),LF=n(Z,"LI",{});var Eze=s(LF);nMe=n(Eze,"STRONG",{});var Rzt=s(nMe);xtr=r(Rzt,"perceiver"),Rzt.forEach(t),$tr=r(Eze," \u2014 "),MH=n(Eze,"A",{href:!0});var Pzt=s(MH);ktr=r(Pzt,"PerceiverForMaskedLM"),Pzt.forEach(t),Str=r(Eze," (Perceiver model)"),Eze.forEach(t),Rtr=i(Z),yF=n(Z,"LI",{});var Cze=s(yF);sMe=n(Cze,"STRONG",{});var Bzt=s(sMe);Ptr=r(Bzt,"qdqbert"),Bzt.forEach(t),Btr=r(Cze," \u2014 "),EH=n(Cze,"A",{href:!0});var Izt=s(EH);Itr=r(Izt,"QDQBertForMaskedLM"),Izt.forEach(t),Ntr=r(Cze," (QDQBert model)"),Cze.forEach(t),qtr=i(Z),xF=n(Z,"LI",{});var wze=s(xF);lMe=n(wze,"STRONG",{});var Nzt=s(lMe);Dtr=r(Nzt,"reformer"),Nzt.forEach(t),jtr=r(wze," \u2014 "),CH=n(wze,"A",{href:!0});var qzt=s(CH);Gtr=r(qzt,"ReformerForMaskedLM"),qzt.forEach(t),Otr=r(wze," (Reformer model)"),wze.forEach(t),Vtr=i(Z),$F=n(Z,"LI",{});var Aze=s($F);iMe=n(Aze,"STRONG",{});var Dzt=s(iMe);Xtr=r(Dzt,"rembert"),Dzt.forEach(t),ztr=r(Aze," \u2014 "),wH=n(Aze,"A",{href:!0});var jzt=s(wH);Qtr=r(jzt,"RemBertForMaskedLM"),jzt.forEach(t),Wtr=r(Aze," (RemBERT model)"),Aze.forEach(t),Utr=i(Z),kF=n(Z,"LI",{});var Lze=s(kF);dMe=n(Lze,"STRONG",{});var Gzt=s(dMe);Htr=r(Gzt,"roberta"),Gzt.forEach(t),Jtr=r(Lze," \u2014 "),AH=n(Lze,"A",{href:!0});var Ozt=s(AH);Ytr=r(Ozt,"RobertaForMaskedLM"),Ozt.forEach(t),Ztr=r(Lze," (RoBERTa model)"),Lze.forEach(t),Ktr=i(Z),SF=n(Z,"LI",{});var yze=s(SF);mMe=n(yze,"STRONG",{});var Vzt=s(mMe);ear=r(Vzt,"roformer"),Vzt.forEach(t),oar=r(yze," \u2014 "),LH=n(yze,"A",{href:!0});var Xzt=s(LH);rar=r(Xzt,"RoFormerForMaskedLM"),Xzt.forEach(t),tar=r(yze," (RoFormer model)"),yze.forEach(t),aar=i(Z),RF=n(Z,"LI",{});var xze=s(RF);cMe=n(xze,"STRONG",{});var zzt=s(cMe);nar=r(zzt,"squeezebert"),zzt.forEach(t),sar=r(xze," \u2014 "),yH=n(xze,"A",{href:!0});var Qzt=s(yH);lar=r(Qzt,"SqueezeBertForMaskedLM"),Qzt.forEach(t),iar=r(xze," (SqueezeBERT model)"),xze.forEach(t),dar=i(Z),PF=n(Z,"LI",{});var $ze=s(PF);fMe=n($ze,"STRONG",{});var Wzt=s(fMe);mar=r(Wzt,"tapas"),Wzt.forEach(t),car=r($ze," \u2014 "),xH=n($ze,"A",{href:!0});var Uzt=s(xH);far=r(Uzt,"TapasForMaskedLM"),Uzt.forEach(t),gar=r($ze," (TAPAS model)"),$ze.forEach(t),har=i(Z),BF=n(Z,"LI",{});var kze=s(BF);gMe=n(kze,"STRONG",{});var Hzt=s(gMe);uar=r(Hzt,"wav2vec2"),Hzt.forEach(t),par=r(kze," \u2014 "),hMe=n(kze,"CODE",{});var Jzt=s(hMe);_ar=r(Jzt,"Wav2Vec2ForMaskedLM"),Jzt.forEach(t),bar=r(kze," (Wav2Vec2 model)"),kze.forEach(t),Far=i(Z),IF=n(Z,"LI",{});var Sze=s(IF);uMe=n(Sze,"STRONG",{});var Yzt=s(uMe);Tar=r(Yzt,"xlm"),Yzt.forEach(t),Mar=r(Sze," \u2014 "),$H=n(Sze,"A",{href:!0});var Zzt=s($H);Ear=r(Zzt,"XLMWithLMHeadModel"),Zzt.forEach(t),Car=r(Sze," (XLM model)"),Sze.forEach(t),war=i(Z),NF=n(Z,"LI",{});var Rze=s(NF);pMe=n(Rze,"STRONG",{});var Kzt=s(pMe);Aar=r(Kzt,"xlm-roberta"),Kzt.forEach(t),Lar=r(Rze," \u2014 "),kH=n(Rze,"A",{href:!0});var eQt=s(kH);yar=r(eQt,"XLMRobertaForMaskedLM"),eQt.forEach(t),xar=r(Rze," (XLM-RoBERTa model)"),Rze.forEach(t),$ar=i(Z),qF=n(Z,"LI",{});var Pze=s(qF);_Me=n(Pze,"STRONG",{});var oQt=s(_Me);kar=r(oQt,"xlm-roberta-xl"),oQt.forEach(t),Sar=r(Pze," \u2014 "),SH=n(Pze,"A",{href:!0});var rQt=s(SH);Rar=r(rQt,"XLMRobertaXLForMaskedLM"),rQt.forEach(t),Par=r(Pze," (XLM-RoBERTa-XL model)"),Pze.forEach(t),Bar=i(Z),DF=n(Z,"LI",{});var Bze=s(DF);bMe=n(Bze,"STRONG",{});var tQt=s(bMe);Iar=r(tQt,"yoso"),tQt.forEach(t),Nar=r(Bze," \u2014 "),RH=n(Bze,"A",{href:!0});var aQt=s(RH);qar=r(aQt,"YosoForMaskedLM"),aQt.forEach(t),Dar=r(Bze," (YOSO model)"),Bze.forEach(t),Z.forEach(t),jar=i(ka),jF=n(ka,"P",{});var Ize=s(jF);Gar=r(Ize,"The model is set in evaluation mode by default using "),vMe=n(Ize,"CODE",{});var nQt=s(vMe);Oar=r(nQt,"model.eval()"),nQt.forEach(t),Var=r(Ize,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),FMe=n(Ize,"CODE",{});var sQt=s(FMe);Xar=r(sQt,"model.train()"),sQt.forEach(t),Ize.forEach(t),zar=i(ka),T(GF.$$.fragment,ka),ka.forEach(t),Ol.forEach(t),Zto=i(c),Wd=n(c,"H2",{class:!0});var _so=s(Wd);OF=n(_so,"A",{id:!0,class:!0,href:!0});var lQt=s(OF);TMe=n(lQt,"SPAN",{});var iQt=s(TMe);T(ik.$$.fragment,iQt),iQt.forEach(t),lQt.forEach(t),Qar=i(_so),MMe=n(_so,"SPAN",{});var dQt=s(MMe);War=r(dQt,"AutoModelForSeq2SeqLM"),dQt.forEach(t),_so.forEach(t),Kto=i(c),Go=n(c,"DIV",{class:!0});var Vl=s(Go);T(dk.$$.fragment,Vl),Uar=i(Vl),Ud=n(Vl,"P",{});var pme=s(Ud);Har=r(pme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),PH=n(pme,"A",{href:!0});var mQt=s(PH);Jar=r(mQt,"from_pretrained()"),mQt.forEach(t),Yar=r(pme," class method or the "),BH=n(pme,"A",{href:!0});var cQt=s(BH);Zar=r(cQt,"from_config()"),cQt.forEach(t),Kar=r(pme,` class
method.`),pme.forEach(t),enr=i(Vl),mk=n(Vl,"P",{});var bso=s(mk);onr=r(bso,"This class cannot be instantiated directly using "),EMe=n(bso,"CODE",{});var fQt=s(EMe);rnr=r(fQt,"__init__()"),fQt.forEach(t),tnr=r(bso," (throws an error)."),bso.forEach(t),anr=i(Vl),Lt=n(Vl,"DIV",{class:!0});var c9=s(Lt);T(ck.$$.fragment,c9),nnr=i(c9),CMe=n(c9,"P",{});var gQt=s(CMe);snr=r(gQt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),gQt.forEach(t),lnr=i(c9),Hd=n(c9,"P",{});var _me=s(Hd);inr=r(_me,`Note:
Loading a model from its configuration file does `),wMe=n(_me,"STRONG",{});var hQt=s(wMe);dnr=r(hQt,"not"),hQt.forEach(t),mnr=r(_me,` load the model weights. It only affects the
model\u2019s configuration. Use `),IH=n(_me,"A",{href:!0});var uQt=s(IH);cnr=r(uQt,"from_pretrained()"),uQt.forEach(t),fnr=r(_me," to load the model weights."),_me.forEach(t),gnr=i(c9),T(VF.$$.fragment,c9),c9.forEach(t),hnr=i(Vl),ao=n(Vl,"DIV",{class:!0});var Sa=s(ao);T(fk.$$.fragment,Sa),unr=i(Sa),AMe=n(Sa,"P",{});var pQt=s(AMe);pnr=r(pQt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),pQt.forEach(t),_nr=i(Sa),cn=n(Sa,"P",{});var f9=s(cn);bnr=r(f9,"The model class to instantiate is selected based on the "),LMe=n(f9,"CODE",{});var _Qt=s(LMe);vnr=r(_Qt,"model_type"),_Qt.forEach(t),Fnr=r(f9,` property of the config object (either
passed as an argument or loaded from `),yMe=n(f9,"CODE",{});var bQt=s(yMe);Tnr=r(bQt,"pretrained_model_name_or_path"),bQt.forEach(t),Mnr=r(f9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xMe=n(f9,"CODE",{});var vQt=s(xMe);Enr=r(vQt,"pretrained_model_name_or_path"),vQt.forEach(t),Cnr=r(f9,":"),f9.forEach(t),wnr=i(Sa),he=n(Sa,"UL",{});var _e=s(he);XF=n(_e,"LI",{});var Nze=s(XF);$Me=n(Nze,"STRONG",{});var FQt=s($Me);Anr=r(FQt,"bart"),FQt.forEach(t),Lnr=r(Nze," \u2014 "),NH=n(Nze,"A",{href:!0});var TQt=s(NH);ynr=r(TQt,"BartForConditionalGeneration"),TQt.forEach(t),xnr=r(Nze," (BART model)"),Nze.forEach(t),$nr=i(_e),zF=n(_e,"LI",{});var qze=s(zF);kMe=n(qze,"STRONG",{});var MQt=s(kMe);knr=r(MQt,"bigbird_pegasus"),MQt.forEach(t),Snr=r(qze," \u2014 "),qH=n(qze,"A",{href:!0});var EQt=s(qH);Rnr=r(EQt,"BigBirdPegasusForConditionalGeneration"),EQt.forEach(t),Pnr=r(qze," (BigBird-Pegasus model)"),qze.forEach(t),Bnr=i(_e),QF=n(_e,"LI",{});var Dze=s(QF);SMe=n(Dze,"STRONG",{});var CQt=s(SMe);Inr=r(CQt,"blenderbot"),CQt.forEach(t),Nnr=r(Dze," \u2014 "),DH=n(Dze,"A",{href:!0});var wQt=s(DH);qnr=r(wQt,"BlenderbotForConditionalGeneration"),wQt.forEach(t),Dnr=r(Dze," (Blenderbot model)"),Dze.forEach(t),jnr=i(_e),WF=n(_e,"LI",{});var jze=s(WF);RMe=n(jze,"STRONG",{});var AQt=s(RMe);Gnr=r(AQt,"blenderbot-small"),AQt.forEach(t),Onr=r(jze," \u2014 "),jH=n(jze,"A",{href:!0});var LQt=s(jH);Vnr=r(LQt,"BlenderbotSmallForConditionalGeneration"),LQt.forEach(t),Xnr=r(jze," (BlenderbotSmall model)"),jze.forEach(t),znr=i(_e),UF=n(_e,"LI",{});var Gze=s(UF);PMe=n(Gze,"STRONG",{});var yQt=s(PMe);Qnr=r(yQt,"encoder-decoder"),yQt.forEach(t),Wnr=r(Gze," \u2014 "),GH=n(Gze,"A",{href:!0});var xQt=s(GH);Unr=r(xQt,"EncoderDecoderModel"),xQt.forEach(t),Hnr=r(Gze," (Encoder decoder model)"),Gze.forEach(t),Jnr=i(_e),HF=n(_e,"LI",{});var Oze=s(HF);BMe=n(Oze,"STRONG",{});var $Qt=s(BMe);Ynr=r($Qt,"fsmt"),$Qt.forEach(t),Znr=r(Oze," \u2014 "),OH=n(Oze,"A",{href:!0});var kQt=s(OH);Knr=r(kQt,"FSMTForConditionalGeneration"),kQt.forEach(t),esr=r(Oze," (FairSeq Machine-Translation model)"),Oze.forEach(t),osr=i(_e),JF=n(_e,"LI",{});var Vze=s(JF);IMe=n(Vze,"STRONG",{});var SQt=s(IMe);rsr=r(SQt,"led"),SQt.forEach(t),tsr=r(Vze," \u2014 "),VH=n(Vze,"A",{href:!0});var RQt=s(VH);asr=r(RQt,"LEDForConditionalGeneration"),RQt.forEach(t),nsr=r(Vze," (LED model)"),Vze.forEach(t),ssr=i(_e),YF=n(_e,"LI",{});var Xze=s(YF);NMe=n(Xze,"STRONG",{});var PQt=s(NMe);lsr=r(PQt,"longt5"),PQt.forEach(t),isr=r(Xze," \u2014 "),XH=n(Xze,"A",{href:!0});var BQt=s(XH);dsr=r(BQt,"LongT5ForConditionalGeneration"),BQt.forEach(t),msr=r(Xze," (LongT5 model)"),Xze.forEach(t),csr=i(_e),ZF=n(_e,"LI",{});var zze=s(ZF);qMe=n(zze,"STRONG",{});var IQt=s(qMe);fsr=r(IQt,"m2m_100"),IQt.forEach(t),gsr=r(zze," \u2014 "),zH=n(zze,"A",{href:!0});var NQt=s(zH);hsr=r(NQt,"M2M100ForConditionalGeneration"),NQt.forEach(t),usr=r(zze," (M2M100 model)"),zze.forEach(t),psr=i(_e),KF=n(_e,"LI",{});var Qze=s(KF);DMe=n(Qze,"STRONG",{});var qQt=s(DMe);_sr=r(qQt,"marian"),qQt.forEach(t),bsr=r(Qze," \u2014 "),QH=n(Qze,"A",{href:!0});var DQt=s(QH);vsr=r(DQt,"MarianMTModel"),DQt.forEach(t),Fsr=r(Qze," (Marian model)"),Qze.forEach(t),Tsr=i(_e),eT=n(_e,"LI",{});var Wze=s(eT);jMe=n(Wze,"STRONG",{});var jQt=s(jMe);Msr=r(jQt,"mbart"),jQt.forEach(t),Esr=r(Wze," \u2014 "),WH=n(Wze,"A",{href:!0});var GQt=s(WH);Csr=r(GQt,"MBartForConditionalGeneration"),GQt.forEach(t),wsr=r(Wze," (mBART model)"),Wze.forEach(t),Asr=i(_e),oT=n(_e,"LI",{});var Uze=s(oT);GMe=n(Uze,"STRONG",{});var OQt=s(GMe);Lsr=r(OQt,"mt5"),OQt.forEach(t),ysr=r(Uze," \u2014 "),UH=n(Uze,"A",{href:!0});var VQt=s(UH);xsr=r(VQt,"MT5ForConditionalGeneration"),VQt.forEach(t),$sr=r(Uze," (MT5 model)"),Uze.forEach(t),ksr=i(_e),rT=n(_e,"LI",{});var Hze=s(rT);OMe=n(Hze,"STRONG",{});var XQt=s(OMe);Ssr=r(XQt,"mvp"),XQt.forEach(t),Rsr=r(Hze," \u2014 "),HH=n(Hze,"A",{href:!0});var zQt=s(HH);Psr=r(zQt,"MvpForConditionalGeneration"),zQt.forEach(t),Bsr=r(Hze," (MVP model)"),Hze.forEach(t),Isr=i(_e),tT=n(_e,"LI",{});var Jze=s(tT);VMe=n(Jze,"STRONG",{});var QQt=s(VMe);Nsr=r(QQt,"nllb"),QQt.forEach(t),qsr=r(Jze," \u2014 "),JH=n(Jze,"A",{href:!0});var WQt=s(JH);Dsr=r(WQt,"M2M100ForConditionalGeneration"),WQt.forEach(t),jsr=r(Jze," (NLLB model)"),Jze.forEach(t),Gsr=i(_e),aT=n(_e,"LI",{});var Yze=s(aT);XMe=n(Yze,"STRONG",{});var UQt=s(XMe);Osr=r(UQt,"pegasus"),UQt.forEach(t),Vsr=r(Yze," \u2014 "),YH=n(Yze,"A",{href:!0});var HQt=s(YH);Xsr=r(HQt,"PegasusForConditionalGeneration"),HQt.forEach(t),zsr=r(Yze," (Pegasus model)"),Yze.forEach(t),Qsr=i(_e),nT=n(_e,"LI",{});var Zze=s(nT);zMe=n(Zze,"STRONG",{});var JQt=s(zMe);Wsr=r(JQt,"pegasus_x"),JQt.forEach(t),Usr=r(Zze," \u2014 "),ZH=n(Zze,"A",{href:!0});var YQt=s(ZH);Hsr=r(YQt,"PegasusXForConditionalGeneration"),YQt.forEach(t),Jsr=r(Zze," (PEGASUS-X model)"),Zze.forEach(t),Ysr=i(_e),sT=n(_e,"LI",{});var Kze=s(sT);QMe=n(Kze,"STRONG",{});var ZQt=s(QMe);Zsr=r(ZQt,"plbart"),ZQt.forEach(t),Ksr=r(Kze," \u2014 "),KH=n(Kze,"A",{href:!0});var KQt=s(KH);elr=r(KQt,"PLBartForConditionalGeneration"),KQt.forEach(t),olr=r(Kze," (PLBart model)"),Kze.forEach(t),rlr=i(_e),lT=n(_e,"LI",{});var eQe=s(lT);WMe=n(eQe,"STRONG",{});var eWt=s(WMe);tlr=r(eWt,"prophetnet"),eWt.forEach(t),alr=r(eQe," \u2014 "),eJ=n(eQe,"A",{href:!0});var oWt=s(eJ);nlr=r(oWt,"ProphetNetForConditionalGeneration"),oWt.forEach(t),slr=r(eQe," (ProphetNet model)"),eQe.forEach(t),llr=i(_e),iT=n(_e,"LI",{});var oQe=s(iT);UMe=n(oQe,"STRONG",{});var rWt=s(UMe);ilr=r(rWt,"t5"),rWt.forEach(t),dlr=r(oQe," \u2014 "),oJ=n(oQe,"A",{href:!0});var tWt=s(oJ);mlr=r(tWt,"T5ForConditionalGeneration"),tWt.forEach(t),clr=r(oQe," (T5 model)"),oQe.forEach(t),flr=i(_e),dT=n(_e,"LI",{});var rQe=s(dT);HMe=n(rQe,"STRONG",{});var aWt=s(HMe);glr=r(aWt,"xlm-prophetnet"),aWt.forEach(t),hlr=r(rQe," \u2014 "),rJ=n(rQe,"A",{href:!0});var nWt=s(rJ);ulr=r(nWt,"XLMProphetNetForConditionalGeneration"),nWt.forEach(t),plr=r(rQe," (XLM-ProphetNet model)"),rQe.forEach(t),_e.forEach(t),_lr=i(Sa),mT=n(Sa,"P",{});var tQe=s(mT);blr=r(tQe,"The model is set in evaluation mode by default using "),JMe=n(tQe,"CODE",{});var sWt=s(JMe);vlr=r(sWt,"model.eval()"),sWt.forEach(t),Flr=r(tQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),YMe=n(tQe,"CODE",{});var lWt=s(YMe);Tlr=r(lWt,"model.train()"),lWt.forEach(t),tQe.forEach(t),Mlr=i(Sa),T(cT.$$.fragment,Sa),Sa.forEach(t),Vl.forEach(t),eao=i(c),Jd=n(c,"H2",{class:!0});var vso=s(Jd);fT=n(vso,"A",{id:!0,class:!0,href:!0});var iWt=s(fT);ZMe=n(iWt,"SPAN",{});var dWt=s(ZMe);T(gk.$$.fragment,dWt),dWt.forEach(t),iWt.forEach(t),Elr=i(vso),KMe=n(vso,"SPAN",{});var mWt=s(KMe);Clr=r(mWt,"AutoModelForSequenceClassification"),mWt.forEach(t),vso.forEach(t),oao=i(c),Oo=n(c,"DIV",{class:!0});var Xl=s(Oo);T(hk.$$.fragment,Xl),wlr=i(Xl),Yd=n(Xl,"P",{});var bme=s(Yd);Alr=r(bme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),tJ=n(bme,"A",{href:!0});var cWt=s(tJ);Llr=r(cWt,"from_pretrained()"),cWt.forEach(t),ylr=r(bme," class method or the "),aJ=n(bme,"A",{href:!0});var fWt=s(aJ);xlr=r(fWt,"from_config()"),fWt.forEach(t),$lr=r(bme,` class
method.`),bme.forEach(t),klr=i(Xl),uk=n(Xl,"P",{});var Fso=s(uk);Slr=r(Fso,"This class cannot be instantiated directly using "),eEe=n(Fso,"CODE",{});var gWt=s(eEe);Rlr=r(gWt,"__init__()"),gWt.forEach(t),Plr=r(Fso," (throws an error)."),Fso.forEach(t),Blr=i(Xl),yt=n(Xl,"DIV",{class:!0});var g9=s(yt);T(pk.$$.fragment,g9),Ilr=i(g9),oEe=n(g9,"P",{});var hWt=s(oEe);Nlr=r(hWt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),hWt.forEach(t),qlr=i(g9),Zd=n(g9,"P",{});var vme=s(Zd);Dlr=r(vme,`Note:
Loading a model from its configuration file does `),rEe=n(vme,"STRONG",{});var uWt=s(rEe);jlr=r(uWt,"not"),uWt.forEach(t),Glr=r(vme,` load the model weights. It only affects the
model\u2019s configuration. Use `),nJ=n(vme,"A",{href:!0});var pWt=s(nJ);Olr=r(pWt,"from_pretrained()"),pWt.forEach(t),Vlr=r(vme," to load the model weights."),vme.forEach(t),Xlr=i(g9),T(gT.$$.fragment,g9),g9.forEach(t),zlr=i(Xl),no=n(Xl,"DIV",{class:!0});var Ra=s(no);T(_k.$$.fragment,Ra),Qlr=i(Ra),tEe=n(Ra,"P",{});var _Wt=s(tEe);Wlr=r(_Wt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),_Wt.forEach(t),Ulr=i(Ra),fn=n(Ra,"P",{});var h9=s(fn);Hlr=r(h9,"The model class to instantiate is selected based on the "),aEe=n(h9,"CODE",{});var bWt=s(aEe);Jlr=r(bWt,"model_type"),bWt.forEach(t),Ylr=r(h9,` property of the config object (either
passed as an argument or loaded from `),nEe=n(h9,"CODE",{});var vWt=s(nEe);Zlr=r(vWt,"pretrained_model_name_or_path"),vWt.forEach(t),Klr=r(h9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sEe=n(h9,"CODE",{});var FWt=s(sEe);eir=r(FWt,"pretrained_model_name_or_path"),FWt.forEach(t),oir=r(h9,":"),h9.forEach(t),rir=i(Ra),D=n(Ra,"UL",{});var j=s(D);hT=n(j,"LI",{});var aQe=s(hT);lEe=n(aQe,"STRONG",{});var TWt=s(lEe);tir=r(TWt,"albert"),TWt.forEach(t),air=r(aQe," \u2014 "),sJ=n(aQe,"A",{href:!0});var MWt=s(sJ);nir=r(MWt,"AlbertForSequenceClassification"),MWt.forEach(t),sir=r(aQe," (ALBERT model)"),aQe.forEach(t),lir=i(j),uT=n(j,"LI",{});var nQe=s(uT);iEe=n(nQe,"STRONG",{});var EWt=s(iEe);iir=r(EWt,"bart"),EWt.forEach(t),dir=r(nQe," \u2014 "),lJ=n(nQe,"A",{href:!0});var CWt=s(lJ);mir=r(CWt,"BartForSequenceClassification"),CWt.forEach(t),cir=r(nQe," (BART model)"),nQe.forEach(t),fir=i(j),pT=n(j,"LI",{});var sQe=s(pT);dEe=n(sQe,"STRONG",{});var wWt=s(dEe);gir=r(wWt,"bert"),wWt.forEach(t),hir=r(sQe," \u2014 "),iJ=n(sQe,"A",{href:!0});var AWt=s(iJ);uir=r(AWt,"BertForSequenceClassification"),AWt.forEach(t),pir=r(sQe," (BERT model)"),sQe.forEach(t),_ir=i(j),_T=n(j,"LI",{});var lQe=s(_T);mEe=n(lQe,"STRONG",{});var LWt=s(mEe);bir=r(LWt,"big_bird"),LWt.forEach(t),vir=r(lQe," \u2014 "),dJ=n(lQe,"A",{href:!0});var yWt=s(dJ);Fir=r(yWt,"BigBirdForSequenceClassification"),yWt.forEach(t),Tir=r(lQe," (BigBird model)"),lQe.forEach(t),Mir=i(j),bT=n(j,"LI",{});var iQe=s(bT);cEe=n(iQe,"STRONG",{});var xWt=s(cEe);Eir=r(xWt,"bigbird_pegasus"),xWt.forEach(t),Cir=r(iQe," \u2014 "),mJ=n(iQe,"A",{href:!0});var $Wt=s(mJ);wir=r($Wt,"BigBirdPegasusForSequenceClassification"),$Wt.forEach(t),Air=r(iQe," (BigBird-Pegasus model)"),iQe.forEach(t),Lir=i(j),vT=n(j,"LI",{});var dQe=s(vT);fEe=n(dQe,"STRONG",{});var kWt=s(fEe);yir=r(kWt,"bloom"),kWt.forEach(t),xir=r(dQe," \u2014 "),cJ=n(dQe,"A",{href:!0});var SWt=s(cJ);$ir=r(SWt,"BloomForSequenceClassification"),SWt.forEach(t),kir=r(dQe," (BLOOM model)"),dQe.forEach(t),Sir=i(j),FT=n(j,"LI",{});var mQe=s(FT);gEe=n(mQe,"STRONG",{});var RWt=s(gEe);Rir=r(RWt,"camembert"),RWt.forEach(t),Pir=r(mQe," \u2014 "),fJ=n(mQe,"A",{href:!0});var PWt=s(fJ);Bir=r(PWt,"CamembertForSequenceClassification"),PWt.forEach(t),Iir=r(mQe," (CamemBERT model)"),mQe.forEach(t),Nir=i(j),TT=n(j,"LI",{});var cQe=s(TT);hEe=n(cQe,"STRONG",{});var BWt=s(hEe);qir=r(BWt,"canine"),BWt.forEach(t),Dir=r(cQe," \u2014 "),gJ=n(cQe,"A",{href:!0});var IWt=s(gJ);jir=r(IWt,"CanineForSequenceClassification"),IWt.forEach(t),Gir=r(cQe," (CANINE model)"),cQe.forEach(t),Oir=i(j),MT=n(j,"LI",{});var fQe=s(MT);uEe=n(fQe,"STRONG",{});var NWt=s(uEe);Vir=r(NWt,"convbert"),NWt.forEach(t),Xir=r(fQe," \u2014 "),hJ=n(fQe,"A",{href:!0});var qWt=s(hJ);zir=r(qWt,"ConvBertForSequenceClassification"),qWt.forEach(t),Qir=r(fQe," (ConvBERT model)"),fQe.forEach(t),Wir=i(j),ET=n(j,"LI",{});var gQe=s(ET);pEe=n(gQe,"STRONG",{});var DWt=s(pEe);Uir=r(DWt,"ctrl"),DWt.forEach(t),Hir=r(gQe," \u2014 "),uJ=n(gQe,"A",{href:!0});var jWt=s(uJ);Jir=r(jWt,"CTRLForSequenceClassification"),jWt.forEach(t),Yir=r(gQe," (CTRL model)"),gQe.forEach(t),Zir=i(j),CT=n(j,"LI",{});var hQe=s(CT);_Ee=n(hQe,"STRONG",{});var GWt=s(_Ee);Kir=r(GWt,"data2vec-text"),GWt.forEach(t),edr=r(hQe," \u2014 "),pJ=n(hQe,"A",{href:!0});var OWt=s(pJ);odr=r(OWt,"Data2VecTextForSequenceClassification"),OWt.forEach(t),rdr=r(hQe," (Data2VecText model)"),hQe.forEach(t),tdr=i(j),wT=n(j,"LI",{});var uQe=s(wT);bEe=n(uQe,"STRONG",{});var VWt=s(bEe);adr=r(VWt,"deberta"),VWt.forEach(t),ndr=r(uQe," \u2014 "),_J=n(uQe,"A",{href:!0});var XWt=s(_J);sdr=r(XWt,"DebertaForSequenceClassification"),XWt.forEach(t),ldr=r(uQe," (DeBERTa model)"),uQe.forEach(t),idr=i(j),AT=n(j,"LI",{});var pQe=s(AT);vEe=n(pQe,"STRONG",{});var zWt=s(vEe);ddr=r(zWt,"deberta-v2"),zWt.forEach(t),mdr=r(pQe," \u2014 "),bJ=n(pQe,"A",{href:!0});var QWt=s(bJ);cdr=r(QWt,"DebertaV2ForSequenceClassification"),QWt.forEach(t),fdr=r(pQe," (DeBERTa-v2 model)"),pQe.forEach(t),gdr=i(j),LT=n(j,"LI",{});var _Qe=s(LT);FEe=n(_Qe,"STRONG",{});var WWt=s(FEe);hdr=r(WWt,"distilbert"),WWt.forEach(t),udr=r(_Qe," \u2014 "),vJ=n(_Qe,"A",{href:!0});var UWt=s(vJ);pdr=r(UWt,"DistilBertForSequenceClassification"),UWt.forEach(t),_dr=r(_Qe," (DistilBERT model)"),_Qe.forEach(t),bdr=i(j),yT=n(j,"LI",{});var bQe=s(yT);TEe=n(bQe,"STRONG",{});var HWt=s(TEe);vdr=r(HWt,"electra"),HWt.forEach(t),Fdr=r(bQe," \u2014 "),FJ=n(bQe,"A",{href:!0});var JWt=s(FJ);Tdr=r(JWt,"ElectraForSequenceClassification"),JWt.forEach(t),Mdr=r(bQe," (ELECTRA model)"),bQe.forEach(t),Edr=i(j),xT=n(j,"LI",{});var vQe=s(xT);MEe=n(vQe,"STRONG",{});var YWt=s(MEe);Cdr=r(YWt,"ernie"),YWt.forEach(t),wdr=r(vQe," \u2014 "),TJ=n(vQe,"A",{href:!0});var ZWt=s(TJ);Adr=r(ZWt,"ErnieForSequenceClassification"),ZWt.forEach(t),Ldr=r(vQe," (ERNIE model)"),vQe.forEach(t),ydr=i(j),$T=n(j,"LI",{});var FQe=s($T);EEe=n(FQe,"STRONG",{});var KWt=s(EEe);xdr=r(KWt,"esm"),KWt.forEach(t),$dr=r(FQe," \u2014 "),MJ=n(FQe,"A",{href:!0});var eUt=s(MJ);kdr=r(eUt,"EsmForSequenceClassification"),eUt.forEach(t),Sdr=r(FQe," (ESM model)"),FQe.forEach(t),Rdr=i(j),kT=n(j,"LI",{});var TQe=s(kT);CEe=n(TQe,"STRONG",{});var oUt=s(CEe);Pdr=r(oUt,"flaubert"),oUt.forEach(t),Bdr=r(TQe," \u2014 "),EJ=n(TQe,"A",{href:!0});var rUt=s(EJ);Idr=r(rUt,"FlaubertForSequenceClassification"),rUt.forEach(t),Ndr=r(TQe," (FlauBERT model)"),TQe.forEach(t),qdr=i(j),ST=n(j,"LI",{});var MQe=s(ST);wEe=n(MQe,"STRONG",{});var tUt=s(wEe);Ddr=r(tUt,"fnet"),tUt.forEach(t),jdr=r(MQe," \u2014 "),CJ=n(MQe,"A",{href:!0});var aUt=s(CJ);Gdr=r(aUt,"FNetForSequenceClassification"),aUt.forEach(t),Odr=r(MQe," (FNet model)"),MQe.forEach(t),Vdr=i(j),RT=n(j,"LI",{});var EQe=s(RT);AEe=n(EQe,"STRONG",{});var nUt=s(AEe);Xdr=r(nUt,"funnel"),nUt.forEach(t),zdr=r(EQe," \u2014 "),wJ=n(EQe,"A",{href:!0});var sUt=s(wJ);Qdr=r(sUt,"FunnelForSequenceClassification"),sUt.forEach(t),Wdr=r(EQe," (Funnel Transformer model)"),EQe.forEach(t),Udr=i(j),PT=n(j,"LI",{});var CQe=s(PT);LEe=n(CQe,"STRONG",{});var lUt=s(LEe);Hdr=r(lUt,"gpt2"),lUt.forEach(t),Jdr=r(CQe," \u2014 "),AJ=n(CQe,"A",{href:!0});var iUt=s(AJ);Ydr=r(iUt,"GPT2ForSequenceClassification"),iUt.forEach(t),Zdr=r(CQe," (OpenAI GPT-2 model)"),CQe.forEach(t),Kdr=i(j),BT=n(j,"LI",{});var wQe=s(BT);yEe=n(wQe,"STRONG",{});var dUt=s(yEe);emr=r(dUt,"gpt_neo"),dUt.forEach(t),omr=r(wQe," \u2014 "),LJ=n(wQe,"A",{href:!0});var mUt=s(LJ);rmr=r(mUt,"GPTNeoForSequenceClassification"),mUt.forEach(t),tmr=r(wQe," (GPT Neo model)"),wQe.forEach(t),amr=i(j),IT=n(j,"LI",{});var AQe=s(IT);xEe=n(AQe,"STRONG",{});var cUt=s(xEe);nmr=r(cUt,"gptj"),cUt.forEach(t),smr=r(AQe," \u2014 "),yJ=n(AQe,"A",{href:!0});var fUt=s(yJ);lmr=r(fUt,"GPTJForSequenceClassification"),fUt.forEach(t),imr=r(AQe," (GPT-J model)"),AQe.forEach(t),dmr=i(j),NT=n(j,"LI",{});var LQe=s(NT);$Ee=n(LQe,"STRONG",{});var gUt=s($Ee);mmr=r(gUt,"ibert"),gUt.forEach(t),cmr=r(LQe," \u2014 "),xJ=n(LQe,"A",{href:!0});var hUt=s(xJ);fmr=r(hUt,"IBertForSequenceClassification"),hUt.forEach(t),gmr=r(LQe," (I-BERT model)"),LQe.forEach(t),hmr=i(j),qT=n(j,"LI",{});var yQe=s(qT);kEe=n(yQe,"STRONG",{});var uUt=s(kEe);umr=r(uUt,"layoutlm"),uUt.forEach(t),pmr=r(yQe," \u2014 "),$J=n(yQe,"A",{href:!0});var pUt=s($J);_mr=r(pUt,"LayoutLMForSequenceClassification"),pUt.forEach(t),bmr=r(yQe," (LayoutLM model)"),yQe.forEach(t),vmr=i(j),DT=n(j,"LI",{});var xQe=s(DT);SEe=n(xQe,"STRONG",{});var _Ut=s(SEe);Fmr=r(_Ut,"layoutlmv2"),_Ut.forEach(t),Tmr=r(xQe," \u2014 "),kJ=n(xQe,"A",{href:!0});var bUt=s(kJ);Mmr=r(bUt,"LayoutLMv2ForSequenceClassification"),bUt.forEach(t),Emr=r(xQe," (LayoutLMv2 model)"),xQe.forEach(t),Cmr=i(j),jT=n(j,"LI",{});var $Qe=s(jT);REe=n($Qe,"STRONG",{});var vUt=s(REe);wmr=r(vUt,"layoutlmv3"),vUt.forEach(t),Amr=r($Qe," \u2014 "),SJ=n($Qe,"A",{href:!0});var FUt=s(SJ);Lmr=r(FUt,"LayoutLMv3ForSequenceClassification"),FUt.forEach(t),ymr=r($Qe," (LayoutLMv3 model)"),$Qe.forEach(t),xmr=i(j),GT=n(j,"LI",{});var kQe=s(GT);PEe=n(kQe,"STRONG",{});var TUt=s(PEe);$mr=r(TUt,"led"),TUt.forEach(t),kmr=r(kQe," \u2014 "),RJ=n(kQe,"A",{href:!0});var MUt=s(RJ);Smr=r(MUt,"LEDForSequenceClassification"),MUt.forEach(t),Rmr=r(kQe," (LED model)"),kQe.forEach(t),Pmr=i(j),OT=n(j,"LI",{});var SQe=s(OT);BEe=n(SQe,"STRONG",{});var EUt=s(BEe);Bmr=r(EUt,"lilt"),EUt.forEach(t),Imr=r(SQe," \u2014 "),PJ=n(SQe,"A",{href:!0});var CUt=s(PJ);Nmr=r(CUt,"LiltForSequenceClassification"),CUt.forEach(t),qmr=r(SQe," (LiLT model)"),SQe.forEach(t),Dmr=i(j),VT=n(j,"LI",{});var RQe=s(VT);IEe=n(RQe,"STRONG",{});var wUt=s(IEe);jmr=r(wUt,"longformer"),wUt.forEach(t),Gmr=r(RQe," \u2014 "),BJ=n(RQe,"A",{href:!0});var AUt=s(BJ);Omr=r(AUt,"LongformerForSequenceClassification"),AUt.forEach(t),Vmr=r(RQe," (Longformer model)"),RQe.forEach(t),Xmr=i(j),XT=n(j,"LI",{});var PQe=s(XT);NEe=n(PQe,"STRONG",{});var LUt=s(NEe);zmr=r(LUt,"luke"),LUt.forEach(t),Qmr=r(PQe," \u2014 "),IJ=n(PQe,"A",{href:!0});var yUt=s(IJ);Wmr=r(yUt,"LukeForSequenceClassification"),yUt.forEach(t),Umr=r(PQe," (LUKE model)"),PQe.forEach(t),Hmr=i(j),zT=n(j,"LI",{});var BQe=s(zT);qEe=n(BQe,"STRONG",{});var xUt=s(qEe);Jmr=r(xUt,"markuplm"),xUt.forEach(t),Ymr=r(BQe," \u2014 "),NJ=n(BQe,"A",{href:!0});var $Ut=s(NJ);Zmr=r($Ut,"MarkupLMForSequenceClassification"),$Ut.forEach(t),Kmr=r(BQe," (MarkupLM model)"),BQe.forEach(t),ecr=i(j),QT=n(j,"LI",{});var IQe=s(QT);DEe=n(IQe,"STRONG",{});var kUt=s(DEe);ocr=r(kUt,"mbart"),kUt.forEach(t),rcr=r(IQe," \u2014 "),qJ=n(IQe,"A",{href:!0});var SUt=s(qJ);tcr=r(SUt,"MBartForSequenceClassification"),SUt.forEach(t),acr=r(IQe," (mBART model)"),IQe.forEach(t),ncr=i(j),WT=n(j,"LI",{});var NQe=s(WT);jEe=n(NQe,"STRONG",{});var RUt=s(jEe);scr=r(RUt,"megatron-bert"),RUt.forEach(t),lcr=r(NQe," \u2014 "),DJ=n(NQe,"A",{href:!0});var PUt=s(DJ);icr=r(PUt,"MegatronBertForSequenceClassification"),PUt.forEach(t),dcr=r(NQe," (Megatron-BERT model)"),NQe.forEach(t),mcr=i(j),UT=n(j,"LI",{});var qQe=s(UT);GEe=n(qQe,"STRONG",{});var BUt=s(GEe);ccr=r(BUt,"mobilebert"),BUt.forEach(t),fcr=r(qQe," \u2014 "),jJ=n(qQe,"A",{href:!0});var IUt=s(jJ);gcr=r(IUt,"MobileBertForSequenceClassification"),IUt.forEach(t),hcr=r(qQe," (MobileBERT model)"),qQe.forEach(t),ucr=i(j),HT=n(j,"LI",{});var DQe=s(HT);OEe=n(DQe,"STRONG",{});var NUt=s(OEe);pcr=r(NUt,"mpnet"),NUt.forEach(t),_cr=r(DQe," \u2014 "),GJ=n(DQe,"A",{href:!0});var qUt=s(GJ);bcr=r(qUt,"MPNetForSequenceClassification"),qUt.forEach(t),vcr=r(DQe," (MPNet model)"),DQe.forEach(t),Fcr=i(j),JT=n(j,"LI",{});var jQe=s(JT);VEe=n(jQe,"STRONG",{});var DUt=s(VEe);Tcr=r(DUt,"mvp"),DUt.forEach(t),Mcr=r(jQe," \u2014 "),OJ=n(jQe,"A",{href:!0});var jUt=s(OJ);Ecr=r(jUt,"MvpForSequenceClassification"),jUt.forEach(t),Ccr=r(jQe," (MVP model)"),jQe.forEach(t),wcr=i(j),YT=n(j,"LI",{});var GQe=s(YT);XEe=n(GQe,"STRONG",{});var GUt=s(XEe);Acr=r(GUt,"nezha"),GUt.forEach(t),Lcr=r(GQe," \u2014 "),VJ=n(GQe,"A",{href:!0});var OUt=s(VJ);ycr=r(OUt,"NezhaForSequenceClassification"),OUt.forEach(t),xcr=r(GQe," (Nezha model)"),GQe.forEach(t),$cr=i(j),ZT=n(j,"LI",{});var OQe=s(ZT);zEe=n(OQe,"STRONG",{});var VUt=s(zEe);kcr=r(VUt,"nystromformer"),VUt.forEach(t),Scr=r(OQe," \u2014 "),XJ=n(OQe,"A",{href:!0});var XUt=s(XJ);Rcr=r(XUt,"NystromformerForSequenceClassification"),XUt.forEach(t),Pcr=r(OQe," (Nystr\xF6mformer model)"),OQe.forEach(t),Bcr=i(j),KT=n(j,"LI",{});var VQe=s(KT);QEe=n(VQe,"STRONG",{});var zUt=s(QEe);Icr=r(zUt,"openai-gpt"),zUt.forEach(t),Ncr=r(VQe," \u2014 "),zJ=n(VQe,"A",{href:!0});var QUt=s(zJ);qcr=r(QUt,"OpenAIGPTForSequenceClassification"),QUt.forEach(t),Dcr=r(VQe," (OpenAI GPT model)"),VQe.forEach(t),jcr=i(j),eM=n(j,"LI",{});var XQe=s(eM);WEe=n(XQe,"STRONG",{});var WUt=s(WEe);Gcr=r(WUt,"opt"),WUt.forEach(t),Ocr=r(XQe," \u2014 "),QJ=n(XQe,"A",{href:!0});var UUt=s(QJ);Vcr=r(UUt,"OPTForSequenceClassification"),UUt.forEach(t),Xcr=r(XQe," (OPT model)"),XQe.forEach(t),zcr=i(j),oM=n(j,"LI",{});var zQe=s(oM);UEe=n(zQe,"STRONG",{});var HUt=s(UEe);Qcr=r(HUt,"perceiver"),HUt.forEach(t),Wcr=r(zQe," \u2014 "),WJ=n(zQe,"A",{href:!0});var JUt=s(WJ);Ucr=r(JUt,"PerceiverForSequenceClassification"),JUt.forEach(t),Hcr=r(zQe," (Perceiver model)"),zQe.forEach(t),Jcr=i(j),rM=n(j,"LI",{});var QQe=s(rM);HEe=n(QQe,"STRONG",{});var YUt=s(HEe);Ycr=r(YUt,"plbart"),YUt.forEach(t),Zcr=r(QQe," \u2014 "),UJ=n(QQe,"A",{href:!0});var ZUt=s(UJ);Kcr=r(ZUt,"PLBartForSequenceClassification"),ZUt.forEach(t),efr=r(QQe," (PLBart model)"),QQe.forEach(t),ofr=i(j),tM=n(j,"LI",{});var WQe=s(tM);JEe=n(WQe,"STRONG",{});var KUt=s(JEe);rfr=r(KUt,"qdqbert"),KUt.forEach(t),tfr=r(WQe," \u2014 "),HJ=n(WQe,"A",{href:!0});var eHt=s(HJ);afr=r(eHt,"QDQBertForSequenceClassification"),eHt.forEach(t),nfr=r(WQe," (QDQBert model)"),WQe.forEach(t),sfr=i(j),aM=n(j,"LI",{});var UQe=s(aM);YEe=n(UQe,"STRONG",{});var oHt=s(YEe);lfr=r(oHt,"reformer"),oHt.forEach(t),ifr=r(UQe," \u2014 "),JJ=n(UQe,"A",{href:!0});var rHt=s(JJ);dfr=r(rHt,"ReformerForSequenceClassification"),rHt.forEach(t),mfr=r(UQe," (Reformer model)"),UQe.forEach(t),cfr=i(j),nM=n(j,"LI",{});var HQe=s(nM);ZEe=n(HQe,"STRONG",{});var tHt=s(ZEe);ffr=r(tHt,"rembert"),tHt.forEach(t),gfr=r(HQe," \u2014 "),YJ=n(HQe,"A",{href:!0});var aHt=s(YJ);hfr=r(aHt,"RemBertForSequenceClassification"),aHt.forEach(t),ufr=r(HQe," (RemBERT model)"),HQe.forEach(t),pfr=i(j),sM=n(j,"LI",{});var JQe=s(sM);KEe=n(JQe,"STRONG",{});var nHt=s(KEe);_fr=r(nHt,"roberta"),nHt.forEach(t),bfr=r(JQe," \u2014 "),ZJ=n(JQe,"A",{href:!0});var sHt=s(ZJ);vfr=r(sHt,"RobertaForSequenceClassification"),sHt.forEach(t),Ffr=r(JQe," (RoBERTa model)"),JQe.forEach(t),Tfr=i(j),lM=n(j,"LI",{});var YQe=s(lM);e4e=n(YQe,"STRONG",{});var lHt=s(e4e);Mfr=r(lHt,"roformer"),lHt.forEach(t),Efr=r(YQe," \u2014 "),KJ=n(YQe,"A",{href:!0});var iHt=s(KJ);Cfr=r(iHt,"RoFormerForSequenceClassification"),iHt.forEach(t),wfr=r(YQe," (RoFormer model)"),YQe.forEach(t),Afr=i(j),iM=n(j,"LI",{});var ZQe=s(iM);o4e=n(ZQe,"STRONG",{});var dHt=s(o4e);Lfr=r(dHt,"squeezebert"),dHt.forEach(t),yfr=r(ZQe," \u2014 "),eY=n(ZQe,"A",{href:!0});var mHt=s(eY);xfr=r(mHt,"SqueezeBertForSequenceClassification"),mHt.forEach(t),$fr=r(ZQe," (SqueezeBERT model)"),ZQe.forEach(t),kfr=i(j),dM=n(j,"LI",{});var KQe=s(dM);r4e=n(KQe,"STRONG",{});var cHt=s(r4e);Sfr=r(cHt,"tapas"),cHt.forEach(t),Rfr=r(KQe," \u2014 "),oY=n(KQe,"A",{href:!0});var fHt=s(oY);Pfr=r(fHt,"TapasForSequenceClassification"),fHt.forEach(t),Bfr=r(KQe," (TAPAS model)"),KQe.forEach(t),Ifr=i(j),mM=n(j,"LI",{});var eWe=s(mM);t4e=n(eWe,"STRONG",{});var gHt=s(t4e);Nfr=r(gHt,"transfo-xl"),gHt.forEach(t),qfr=r(eWe," \u2014 "),rY=n(eWe,"A",{href:!0});var hHt=s(rY);Dfr=r(hHt,"TransfoXLForSequenceClassification"),hHt.forEach(t),jfr=r(eWe," (Transformer-XL model)"),eWe.forEach(t),Gfr=i(j),cM=n(j,"LI",{});var oWe=s(cM);a4e=n(oWe,"STRONG",{});var uHt=s(a4e);Ofr=r(uHt,"xlm"),uHt.forEach(t),Vfr=r(oWe," \u2014 "),tY=n(oWe,"A",{href:!0});var pHt=s(tY);Xfr=r(pHt,"XLMForSequenceClassification"),pHt.forEach(t),zfr=r(oWe," (XLM model)"),oWe.forEach(t),Qfr=i(j),fM=n(j,"LI",{});var rWe=s(fM);n4e=n(rWe,"STRONG",{});var _Ht=s(n4e);Wfr=r(_Ht,"xlm-roberta"),_Ht.forEach(t),Ufr=r(rWe," \u2014 "),aY=n(rWe,"A",{href:!0});var bHt=s(aY);Hfr=r(bHt,"XLMRobertaForSequenceClassification"),bHt.forEach(t),Jfr=r(rWe," (XLM-RoBERTa model)"),rWe.forEach(t),Yfr=i(j),gM=n(j,"LI",{});var tWe=s(gM);s4e=n(tWe,"STRONG",{});var vHt=s(s4e);Zfr=r(vHt,"xlm-roberta-xl"),vHt.forEach(t),Kfr=r(tWe," \u2014 "),nY=n(tWe,"A",{href:!0});var FHt=s(nY);egr=r(FHt,"XLMRobertaXLForSequenceClassification"),FHt.forEach(t),ogr=r(tWe," (XLM-RoBERTa-XL model)"),tWe.forEach(t),rgr=i(j),hM=n(j,"LI",{});var aWe=s(hM);l4e=n(aWe,"STRONG",{});var THt=s(l4e);tgr=r(THt,"xlnet"),THt.forEach(t),agr=r(aWe," \u2014 "),sY=n(aWe,"A",{href:!0});var MHt=s(sY);ngr=r(MHt,"XLNetForSequenceClassification"),MHt.forEach(t),sgr=r(aWe," (XLNet model)"),aWe.forEach(t),lgr=i(j),uM=n(j,"LI",{});var nWe=s(uM);i4e=n(nWe,"STRONG",{});var EHt=s(i4e);igr=r(EHt,"yoso"),EHt.forEach(t),dgr=r(nWe," \u2014 "),lY=n(nWe,"A",{href:!0});var CHt=s(lY);mgr=r(CHt,"YosoForSequenceClassification"),CHt.forEach(t),cgr=r(nWe," (YOSO model)"),nWe.forEach(t),j.forEach(t),fgr=i(Ra),pM=n(Ra,"P",{});var sWe=s(pM);ggr=r(sWe,"The model is set in evaluation mode by default using "),d4e=n(sWe,"CODE",{});var wHt=s(d4e);hgr=r(wHt,"model.eval()"),wHt.forEach(t),ugr=r(sWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),m4e=n(sWe,"CODE",{});var AHt=s(m4e);pgr=r(AHt,"model.train()"),AHt.forEach(t),sWe.forEach(t),_gr=i(Ra),T(_M.$$.fragment,Ra),Ra.forEach(t),Xl.forEach(t),rao=i(c),Kd=n(c,"H2",{class:!0});var Tso=s(Kd);bM=n(Tso,"A",{id:!0,class:!0,href:!0});var LHt=s(bM);c4e=n(LHt,"SPAN",{});var yHt=s(c4e);T(bk.$$.fragment,yHt),yHt.forEach(t),LHt.forEach(t),bgr=i(Tso),f4e=n(Tso,"SPAN",{});var xHt=s(f4e);vgr=r(xHt,"AutoModelForMultipleChoice"),xHt.forEach(t),Tso.forEach(t),tao=i(c),Vo=n(c,"DIV",{class:!0});var zl=s(Vo);T(vk.$$.fragment,zl),Fgr=i(zl),em=n(zl,"P",{});var Fme=s(em);Tgr=r(Fme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),iY=n(Fme,"A",{href:!0});var $Ht=s(iY);Mgr=r($Ht,"from_pretrained()"),$Ht.forEach(t),Egr=r(Fme," class method or the "),dY=n(Fme,"A",{href:!0});var kHt=s(dY);Cgr=r(kHt,"from_config()"),kHt.forEach(t),wgr=r(Fme,` class
method.`),Fme.forEach(t),Agr=i(zl),Fk=n(zl,"P",{});var Mso=s(Fk);Lgr=r(Mso,"This class cannot be instantiated directly using "),g4e=n(Mso,"CODE",{});var SHt=s(g4e);ygr=r(SHt,"__init__()"),SHt.forEach(t),xgr=r(Mso," (throws an error)."),Mso.forEach(t),$gr=i(zl),xt=n(zl,"DIV",{class:!0});var u9=s(xt);T(Tk.$$.fragment,u9),kgr=i(u9),h4e=n(u9,"P",{});var RHt=s(h4e);Sgr=r(RHt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),RHt.forEach(t),Rgr=i(u9),om=n(u9,"P",{});var Tme=s(om);Pgr=r(Tme,`Note:
Loading a model from its configuration file does `),u4e=n(Tme,"STRONG",{});var PHt=s(u4e);Bgr=r(PHt,"not"),PHt.forEach(t),Igr=r(Tme,` load the model weights. It only affects the
model\u2019s configuration. Use `),mY=n(Tme,"A",{href:!0});var BHt=s(mY);Ngr=r(BHt,"from_pretrained()"),BHt.forEach(t),qgr=r(Tme," to load the model weights."),Tme.forEach(t),Dgr=i(u9),T(vM.$$.fragment,u9),u9.forEach(t),jgr=i(zl),so=n(zl,"DIV",{class:!0});var Pa=s(so);T(Mk.$$.fragment,Pa),Ggr=i(Pa),p4e=n(Pa,"P",{});var IHt=s(p4e);Ogr=r(IHt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),IHt.forEach(t),Vgr=i(Pa),gn=n(Pa,"P",{});var p9=s(gn);Xgr=r(p9,"The model class to instantiate is selected based on the "),_4e=n(p9,"CODE",{});var NHt=s(_4e);zgr=r(NHt,"model_type"),NHt.forEach(t),Qgr=r(p9,` property of the config object (either
passed as an argument or loaded from `),b4e=n(p9,"CODE",{});var qHt=s(b4e);Wgr=r(qHt,"pretrained_model_name_or_path"),qHt.forEach(t),Ugr=r(p9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v4e=n(p9,"CODE",{});var DHt=s(v4e);Hgr=r(DHt,"pretrained_model_name_or_path"),DHt.forEach(t),Jgr=r(p9,":"),p9.forEach(t),Ygr=i(Pa),K=n(Pa,"UL",{});var ee=s(K);FM=n(ee,"LI",{});var lWe=s(FM);F4e=n(lWe,"STRONG",{});var jHt=s(F4e);Zgr=r(jHt,"albert"),jHt.forEach(t),Kgr=r(lWe," \u2014 "),cY=n(lWe,"A",{href:!0});var GHt=s(cY);ehr=r(GHt,"AlbertForMultipleChoice"),GHt.forEach(t),ohr=r(lWe," (ALBERT model)"),lWe.forEach(t),rhr=i(ee),TM=n(ee,"LI",{});var iWe=s(TM);T4e=n(iWe,"STRONG",{});var OHt=s(T4e);thr=r(OHt,"bert"),OHt.forEach(t),ahr=r(iWe," \u2014 "),fY=n(iWe,"A",{href:!0});var VHt=s(fY);nhr=r(VHt,"BertForMultipleChoice"),VHt.forEach(t),shr=r(iWe," (BERT model)"),iWe.forEach(t),lhr=i(ee),MM=n(ee,"LI",{});var dWe=s(MM);M4e=n(dWe,"STRONG",{});var XHt=s(M4e);ihr=r(XHt,"big_bird"),XHt.forEach(t),dhr=r(dWe," \u2014 "),gY=n(dWe,"A",{href:!0});var zHt=s(gY);mhr=r(zHt,"BigBirdForMultipleChoice"),zHt.forEach(t),chr=r(dWe," (BigBird model)"),dWe.forEach(t),fhr=i(ee),EM=n(ee,"LI",{});var mWe=s(EM);E4e=n(mWe,"STRONG",{});var QHt=s(E4e);ghr=r(QHt,"camembert"),QHt.forEach(t),hhr=r(mWe," \u2014 "),hY=n(mWe,"A",{href:!0});var WHt=s(hY);uhr=r(WHt,"CamembertForMultipleChoice"),WHt.forEach(t),phr=r(mWe," (CamemBERT model)"),mWe.forEach(t),_hr=i(ee),CM=n(ee,"LI",{});var cWe=s(CM);C4e=n(cWe,"STRONG",{});var UHt=s(C4e);bhr=r(UHt,"canine"),UHt.forEach(t),vhr=r(cWe," \u2014 "),uY=n(cWe,"A",{href:!0});var HHt=s(uY);Fhr=r(HHt,"CanineForMultipleChoice"),HHt.forEach(t),Thr=r(cWe," (CANINE model)"),cWe.forEach(t),Mhr=i(ee),wM=n(ee,"LI",{});var fWe=s(wM);w4e=n(fWe,"STRONG",{});var JHt=s(w4e);Ehr=r(JHt,"convbert"),JHt.forEach(t),Chr=r(fWe," \u2014 "),pY=n(fWe,"A",{href:!0});var YHt=s(pY);whr=r(YHt,"ConvBertForMultipleChoice"),YHt.forEach(t),Ahr=r(fWe," (ConvBERT model)"),fWe.forEach(t),Lhr=i(ee),AM=n(ee,"LI",{});var gWe=s(AM);A4e=n(gWe,"STRONG",{});var ZHt=s(A4e);yhr=r(ZHt,"data2vec-text"),ZHt.forEach(t),xhr=r(gWe," \u2014 "),_Y=n(gWe,"A",{href:!0});var KHt=s(_Y);$hr=r(KHt,"Data2VecTextForMultipleChoice"),KHt.forEach(t),khr=r(gWe," (Data2VecText model)"),gWe.forEach(t),Shr=i(ee),LM=n(ee,"LI",{});var hWe=s(LM);L4e=n(hWe,"STRONG",{});var eJt=s(L4e);Rhr=r(eJt,"deberta-v2"),eJt.forEach(t),Phr=r(hWe," \u2014 "),bY=n(hWe,"A",{href:!0});var oJt=s(bY);Bhr=r(oJt,"DebertaV2ForMultipleChoice"),oJt.forEach(t),Ihr=r(hWe," (DeBERTa-v2 model)"),hWe.forEach(t),Nhr=i(ee),yM=n(ee,"LI",{});var uWe=s(yM);y4e=n(uWe,"STRONG",{});var rJt=s(y4e);qhr=r(rJt,"distilbert"),rJt.forEach(t),Dhr=r(uWe," \u2014 "),vY=n(uWe,"A",{href:!0});var tJt=s(vY);jhr=r(tJt,"DistilBertForMultipleChoice"),tJt.forEach(t),Ghr=r(uWe," (DistilBERT model)"),uWe.forEach(t),Ohr=i(ee),xM=n(ee,"LI",{});var pWe=s(xM);x4e=n(pWe,"STRONG",{});var aJt=s(x4e);Vhr=r(aJt,"electra"),aJt.forEach(t),Xhr=r(pWe," \u2014 "),FY=n(pWe,"A",{href:!0});var nJt=s(FY);zhr=r(nJt,"ElectraForMultipleChoice"),nJt.forEach(t),Qhr=r(pWe," (ELECTRA model)"),pWe.forEach(t),Whr=i(ee),$M=n(ee,"LI",{});var _We=s($M);$4e=n(_We,"STRONG",{});var sJt=s($4e);Uhr=r(sJt,"ernie"),sJt.forEach(t),Hhr=r(_We," \u2014 "),TY=n(_We,"A",{href:!0});var lJt=s(TY);Jhr=r(lJt,"ErnieForMultipleChoice"),lJt.forEach(t),Yhr=r(_We," (ERNIE model)"),_We.forEach(t),Zhr=i(ee),kM=n(ee,"LI",{});var bWe=s(kM);k4e=n(bWe,"STRONG",{});var iJt=s(k4e);Khr=r(iJt,"flaubert"),iJt.forEach(t),eur=r(bWe," \u2014 "),MY=n(bWe,"A",{href:!0});var dJt=s(MY);our=r(dJt,"FlaubertForMultipleChoice"),dJt.forEach(t),rur=r(bWe," (FlauBERT model)"),bWe.forEach(t),tur=i(ee),SM=n(ee,"LI",{});var vWe=s(SM);S4e=n(vWe,"STRONG",{});var mJt=s(S4e);aur=r(mJt,"fnet"),mJt.forEach(t),nur=r(vWe," \u2014 "),EY=n(vWe,"A",{href:!0});var cJt=s(EY);sur=r(cJt,"FNetForMultipleChoice"),cJt.forEach(t),lur=r(vWe," (FNet model)"),vWe.forEach(t),iur=i(ee),RM=n(ee,"LI",{});var FWe=s(RM);R4e=n(FWe,"STRONG",{});var fJt=s(R4e);dur=r(fJt,"funnel"),fJt.forEach(t),mur=r(FWe," \u2014 "),CY=n(FWe,"A",{href:!0});var gJt=s(CY);cur=r(gJt,"FunnelForMultipleChoice"),gJt.forEach(t),fur=r(FWe," (Funnel Transformer model)"),FWe.forEach(t),gur=i(ee),PM=n(ee,"LI",{});var TWe=s(PM);P4e=n(TWe,"STRONG",{});var hJt=s(P4e);hur=r(hJt,"ibert"),hJt.forEach(t),uur=r(TWe," \u2014 "),wY=n(TWe,"A",{href:!0});var uJt=s(wY);pur=r(uJt,"IBertForMultipleChoice"),uJt.forEach(t),_ur=r(TWe," (I-BERT model)"),TWe.forEach(t),bur=i(ee),BM=n(ee,"LI",{});var MWe=s(BM);B4e=n(MWe,"STRONG",{});var pJt=s(B4e);vur=r(pJt,"longformer"),pJt.forEach(t),Fur=r(MWe," \u2014 "),AY=n(MWe,"A",{href:!0});var _Jt=s(AY);Tur=r(_Jt,"LongformerForMultipleChoice"),_Jt.forEach(t),Mur=r(MWe," (Longformer model)"),MWe.forEach(t),Eur=i(ee),IM=n(ee,"LI",{});var EWe=s(IM);I4e=n(EWe,"STRONG",{});var bJt=s(I4e);Cur=r(bJt,"luke"),bJt.forEach(t),wur=r(EWe," \u2014 "),LY=n(EWe,"A",{href:!0});var vJt=s(LY);Aur=r(vJt,"LukeForMultipleChoice"),vJt.forEach(t),Lur=r(EWe," (LUKE model)"),EWe.forEach(t),yur=i(ee),NM=n(ee,"LI",{});var CWe=s(NM);N4e=n(CWe,"STRONG",{});var FJt=s(N4e);xur=r(FJt,"megatron-bert"),FJt.forEach(t),$ur=r(CWe," \u2014 "),yY=n(CWe,"A",{href:!0});var TJt=s(yY);kur=r(TJt,"MegatronBertForMultipleChoice"),TJt.forEach(t),Sur=r(CWe," (Megatron-BERT model)"),CWe.forEach(t),Rur=i(ee),qM=n(ee,"LI",{});var wWe=s(qM);q4e=n(wWe,"STRONG",{});var MJt=s(q4e);Pur=r(MJt,"mobilebert"),MJt.forEach(t),Bur=r(wWe," \u2014 "),xY=n(wWe,"A",{href:!0});var EJt=s(xY);Iur=r(EJt,"MobileBertForMultipleChoice"),EJt.forEach(t),Nur=r(wWe," (MobileBERT model)"),wWe.forEach(t),qur=i(ee),DM=n(ee,"LI",{});var AWe=s(DM);D4e=n(AWe,"STRONG",{});var CJt=s(D4e);Dur=r(CJt,"mpnet"),CJt.forEach(t),jur=r(AWe," \u2014 "),$Y=n(AWe,"A",{href:!0});var wJt=s($Y);Gur=r(wJt,"MPNetForMultipleChoice"),wJt.forEach(t),Our=r(AWe," (MPNet model)"),AWe.forEach(t),Vur=i(ee),jM=n(ee,"LI",{});var LWe=s(jM);j4e=n(LWe,"STRONG",{});var AJt=s(j4e);Xur=r(AJt,"nezha"),AJt.forEach(t),zur=r(LWe," \u2014 "),kY=n(LWe,"A",{href:!0});var LJt=s(kY);Qur=r(LJt,"NezhaForMultipleChoice"),LJt.forEach(t),Wur=r(LWe," (Nezha model)"),LWe.forEach(t),Uur=i(ee),GM=n(ee,"LI",{});var yWe=s(GM);G4e=n(yWe,"STRONG",{});var yJt=s(G4e);Hur=r(yJt,"nystromformer"),yJt.forEach(t),Jur=r(yWe," \u2014 "),SY=n(yWe,"A",{href:!0});var xJt=s(SY);Yur=r(xJt,"NystromformerForMultipleChoice"),xJt.forEach(t),Zur=r(yWe," (Nystr\xF6mformer model)"),yWe.forEach(t),Kur=i(ee),OM=n(ee,"LI",{});var xWe=s(OM);O4e=n(xWe,"STRONG",{});var $Jt=s(O4e);epr=r($Jt,"qdqbert"),$Jt.forEach(t),opr=r(xWe," \u2014 "),RY=n(xWe,"A",{href:!0});var kJt=s(RY);rpr=r(kJt,"QDQBertForMultipleChoice"),kJt.forEach(t),tpr=r(xWe," (QDQBert model)"),xWe.forEach(t),apr=i(ee),VM=n(ee,"LI",{});var $We=s(VM);V4e=n($We,"STRONG",{});var SJt=s(V4e);npr=r(SJt,"rembert"),SJt.forEach(t),spr=r($We," \u2014 "),PY=n($We,"A",{href:!0});var RJt=s(PY);lpr=r(RJt,"RemBertForMultipleChoice"),RJt.forEach(t),ipr=r($We," (RemBERT model)"),$We.forEach(t),dpr=i(ee),XM=n(ee,"LI",{});var kWe=s(XM);X4e=n(kWe,"STRONG",{});var PJt=s(X4e);mpr=r(PJt,"roberta"),PJt.forEach(t),cpr=r(kWe," \u2014 "),BY=n(kWe,"A",{href:!0});var BJt=s(BY);fpr=r(BJt,"RobertaForMultipleChoice"),BJt.forEach(t),gpr=r(kWe," (RoBERTa model)"),kWe.forEach(t),hpr=i(ee),zM=n(ee,"LI",{});var SWe=s(zM);z4e=n(SWe,"STRONG",{});var IJt=s(z4e);upr=r(IJt,"roformer"),IJt.forEach(t),ppr=r(SWe," \u2014 "),IY=n(SWe,"A",{href:!0});var NJt=s(IY);_pr=r(NJt,"RoFormerForMultipleChoice"),NJt.forEach(t),bpr=r(SWe," (RoFormer model)"),SWe.forEach(t),vpr=i(ee),QM=n(ee,"LI",{});var RWe=s(QM);Q4e=n(RWe,"STRONG",{});var qJt=s(Q4e);Fpr=r(qJt,"squeezebert"),qJt.forEach(t),Tpr=r(RWe," \u2014 "),NY=n(RWe,"A",{href:!0});var DJt=s(NY);Mpr=r(DJt,"SqueezeBertForMultipleChoice"),DJt.forEach(t),Epr=r(RWe," (SqueezeBERT model)"),RWe.forEach(t),Cpr=i(ee),WM=n(ee,"LI",{});var PWe=s(WM);W4e=n(PWe,"STRONG",{});var jJt=s(W4e);wpr=r(jJt,"xlm"),jJt.forEach(t),Apr=r(PWe," \u2014 "),qY=n(PWe,"A",{href:!0});var GJt=s(qY);Lpr=r(GJt,"XLMForMultipleChoice"),GJt.forEach(t),ypr=r(PWe," (XLM model)"),PWe.forEach(t),xpr=i(ee),UM=n(ee,"LI",{});var BWe=s(UM);U4e=n(BWe,"STRONG",{});var OJt=s(U4e);$pr=r(OJt,"xlm-roberta"),OJt.forEach(t),kpr=r(BWe," \u2014 "),DY=n(BWe,"A",{href:!0});var VJt=s(DY);Spr=r(VJt,"XLMRobertaForMultipleChoice"),VJt.forEach(t),Rpr=r(BWe," (XLM-RoBERTa model)"),BWe.forEach(t),Ppr=i(ee),HM=n(ee,"LI",{});var IWe=s(HM);H4e=n(IWe,"STRONG",{});var XJt=s(H4e);Bpr=r(XJt,"xlm-roberta-xl"),XJt.forEach(t),Ipr=r(IWe," \u2014 "),jY=n(IWe,"A",{href:!0});var zJt=s(jY);Npr=r(zJt,"XLMRobertaXLForMultipleChoice"),zJt.forEach(t),qpr=r(IWe," (XLM-RoBERTa-XL model)"),IWe.forEach(t),Dpr=i(ee),JM=n(ee,"LI",{});var NWe=s(JM);J4e=n(NWe,"STRONG",{});var QJt=s(J4e);jpr=r(QJt,"xlnet"),QJt.forEach(t),Gpr=r(NWe," \u2014 "),GY=n(NWe,"A",{href:!0});var WJt=s(GY);Opr=r(WJt,"XLNetForMultipleChoice"),WJt.forEach(t),Vpr=r(NWe," (XLNet model)"),NWe.forEach(t),Xpr=i(ee),YM=n(ee,"LI",{});var qWe=s(YM);Y4e=n(qWe,"STRONG",{});var UJt=s(Y4e);zpr=r(UJt,"yoso"),UJt.forEach(t),Qpr=r(qWe," \u2014 "),OY=n(qWe,"A",{href:!0});var HJt=s(OY);Wpr=r(HJt,"YosoForMultipleChoice"),HJt.forEach(t),Upr=r(qWe," (YOSO model)"),qWe.forEach(t),ee.forEach(t),Hpr=i(Pa),ZM=n(Pa,"P",{});var DWe=s(ZM);Jpr=r(DWe,"The model is set in evaluation mode by default using "),Z4e=n(DWe,"CODE",{});var JJt=s(Z4e);Ypr=r(JJt,"model.eval()"),JJt.forEach(t),Zpr=r(DWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),K4e=n(DWe,"CODE",{});var YJt=s(K4e);Kpr=r(YJt,"model.train()"),YJt.forEach(t),DWe.forEach(t),e_r=i(Pa),T(KM.$$.fragment,Pa),Pa.forEach(t),zl.forEach(t),aao=i(c),rm=n(c,"H2",{class:!0});var Eso=s(rm);eE=n(Eso,"A",{id:!0,class:!0,href:!0});var ZJt=s(eE);eCe=n(ZJt,"SPAN",{});var KJt=s(eCe);T(Ek.$$.fragment,KJt),KJt.forEach(t),ZJt.forEach(t),o_r=i(Eso),oCe=n(Eso,"SPAN",{});var eYt=s(oCe);r_r=r(eYt,"AutoModelForNextSentencePrediction"),eYt.forEach(t),Eso.forEach(t),nao=i(c),Xo=n(c,"DIV",{class:!0});var Ql=s(Xo);T(Ck.$$.fragment,Ql),t_r=i(Ql),tm=n(Ql,"P",{});var Mme=s(tm);a_r=r(Mme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),VY=n(Mme,"A",{href:!0});var oYt=s(VY);n_r=r(oYt,"from_pretrained()"),oYt.forEach(t),s_r=r(Mme," class method or the "),XY=n(Mme,"A",{href:!0});var rYt=s(XY);l_r=r(rYt,"from_config()"),rYt.forEach(t),i_r=r(Mme,` class
method.`),Mme.forEach(t),d_r=i(Ql),wk=n(Ql,"P",{});var Cso=s(wk);m_r=r(Cso,"This class cannot be instantiated directly using "),rCe=n(Cso,"CODE",{});var tYt=s(rCe);c_r=r(tYt,"__init__()"),tYt.forEach(t),f_r=r(Cso," (throws an error)."),Cso.forEach(t),g_r=i(Ql),$t=n(Ql,"DIV",{class:!0});var _9=s($t);T(Ak.$$.fragment,_9),h_r=i(_9),tCe=n(_9,"P",{});var aYt=s(tCe);u_r=r(aYt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),aYt.forEach(t),p_r=i(_9),am=n(_9,"P",{});var Eme=s(am);__r=r(Eme,`Note:
Loading a model from its configuration file does `),aCe=n(Eme,"STRONG",{});var nYt=s(aCe);b_r=r(nYt,"not"),nYt.forEach(t),v_r=r(Eme,` load the model weights. It only affects the
model\u2019s configuration. Use `),zY=n(Eme,"A",{href:!0});var sYt=s(zY);F_r=r(sYt,"from_pretrained()"),sYt.forEach(t),T_r=r(Eme," to load the model weights."),Eme.forEach(t),M_r=i(_9),T(oE.$$.fragment,_9),_9.forEach(t),E_r=i(Ql),lo=n(Ql,"DIV",{class:!0});var Ba=s(lo);T(Lk.$$.fragment,Ba),C_r=i(Ba),nCe=n(Ba,"P",{});var lYt=s(nCe);w_r=r(lYt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),lYt.forEach(t),A_r=i(Ba),hn=n(Ba,"P",{});var b9=s(hn);L_r=r(b9,"The model class to instantiate is selected based on the "),sCe=n(b9,"CODE",{});var iYt=s(sCe);y_r=r(iYt,"model_type"),iYt.forEach(t),x_r=r(b9,` property of the config object (either
passed as an argument or loaded from `),lCe=n(b9,"CODE",{});var dYt=s(lCe);$_r=r(dYt,"pretrained_model_name_or_path"),dYt.forEach(t),k_r=r(b9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iCe=n(b9,"CODE",{});var mYt=s(iCe);S_r=r(mYt,"pretrained_model_name_or_path"),mYt.forEach(t),R_r=r(b9,":"),b9.forEach(t),P_r=i(Ba),Ue=n(Ba,"UL",{});var ht=s(Ue);rE=n(ht,"LI",{});var jWe=s(rE);dCe=n(jWe,"STRONG",{});var cYt=s(dCe);B_r=r(cYt,"bert"),cYt.forEach(t),I_r=r(jWe," \u2014 "),QY=n(jWe,"A",{href:!0});var fYt=s(QY);N_r=r(fYt,"BertForNextSentencePrediction"),fYt.forEach(t),q_r=r(jWe," (BERT model)"),jWe.forEach(t),D_r=i(ht),tE=n(ht,"LI",{});var GWe=s(tE);mCe=n(GWe,"STRONG",{});var gYt=s(mCe);j_r=r(gYt,"ernie"),gYt.forEach(t),G_r=r(GWe," \u2014 "),WY=n(GWe,"A",{href:!0});var hYt=s(WY);O_r=r(hYt,"ErnieForNextSentencePrediction"),hYt.forEach(t),V_r=r(GWe," (ERNIE model)"),GWe.forEach(t),X_r=i(ht),aE=n(ht,"LI",{});var OWe=s(aE);cCe=n(OWe,"STRONG",{});var uYt=s(cCe);z_r=r(uYt,"fnet"),uYt.forEach(t),Q_r=r(OWe," \u2014 "),UY=n(OWe,"A",{href:!0});var pYt=s(UY);W_r=r(pYt,"FNetForNextSentencePrediction"),pYt.forEach(t),U_r=r(OWe," (FNet model)"),OWe.forEach(t),H_r=i(ht),nE=n(ht,"LI",{});var VWe=s(nE);fCe=n(VWe,"STRONG",{});var _Yt=s(fCe);J_r=r(_Yt,"megatron-bert"),_Yt.forEach(t),Y_r=r(VWe," \u2014 "),HY=n(VWe,"A",{href:!0});var bYt=s(HY);Z_r=r(bYt,"MegatronBertForNextSentencePrediction"),bYt.forEach(t),K_r=r(VWe," (Megatron-BERT model)"),VWe.forEach(t),e1r=i(ht),sE=n(ht,"LI",{});var XWe=s(sE);gCe=n(XWe,"STRONG",{});var vYt=s(gCe);o1r=r(vYt,"mobilebert"),vYt.forEach(t),r1r=r(XWe," \u2014 "),JY=n(XWe,"A",{href:!0});var FYt=s(JY);t1r=r(FYt,"MobileBertForNextSentencePrediction"),FYt.forEach(t),a1r=r(XWe," (MobileBERT model)"),XWe.forEach(t),n1r=i(ht),lE=n(ht,"LI",{});var zWe=s(lE);hCe=n(zWe,"STRONG",{});var TYt=s(hCe);s1r=r(TYt,"nezha"),TYt.forEach(t),l1r=r(zWe," \u2014 "),YY=n(zWe,"A",{href:!0});var MYt=s(YY);i1r=r(MYt,"NezhaForNextSentencePrediction"),MYt.forEach(t),d1r=r(zWe," (Nezha model)"),zWe.forEach(t),m1r=i(ht),iE=n(ht,"LI",{});var QWe=s(iE);uCe=n(QWe,"STRONG",{});var EYt=s(uCe);c1r=r(EYt,"qdqbert"),EYt.forEach(t),f1r=r(QWe," \u2014 "),ZY=n(QWe,"A",{href:!0});var CYt=s(ZY);g1r=r(CYt,"QDQBertForNextSentencePrediction"),CYt.forEach(t),h1r=r(QWe," (QDQBert model)"),QWe.forEach(t),ht.forEach(t),u1r=i(Ba),dE=n(Ba,"P",{});var WWe=s(dE);p1r=r(WWe,"The model is set in evaluation mode by default using "),pCe=n(WWe,"CODE",{});var wYt=s(pCe);_1r=r(wYt,"model.eval()"),wYt.forEach(t),b1r=r(WWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_Ce=n(WWe,"CODE",{});var AYt=s(_Ce);v1r=r(AYt,"model.train()"),AYt.forEach(t),WWe.forEach(t),F1r=i(Ba),T(mE.$$.fragment,Ba),Ba.forEach(t),Ql.forEach(t),sao=i(c),nm=n(c,"H2",{class:!0});var wso=s(nm);cE=n(wso,"A",{id:!0,class:!0,href:!0});var LYt=s(cE);bCe=n(LYt,"SPAN",{});var yYt=s(bCe);T(yk.$$.fragment,yYt),yYt.forEach(t),LYt.forEach(t),T1r=i(wso),vCe=n(wso,"SPAN",{});var xYt=s(vCe);M1r=r(xYt,"AutoModelForTokenClassification"),xYt.forEach(t),wso.forEach(t),lao=i(c),zo=n(c,"DIV",{class:!0});var Wl=s(zo);T(xk.$$.fragment,Wl),E1r=i(Wl),sm=n(Wl,"P",{});var Cme=s(sm);C1r=r(Cme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),KY=n(Cme,"A",{href:!0});var $Yt=s(KY);w1r=r($Yt,"from_pretrained()"),$Yt.forEach(t),A1r=r(Cme," class method or the "),eZ=n(Cme,"A",{href:!0});var kYt=s(eZ);L1r=r(kYt,"from_config()"),kYt.forEach(t),y1r=r(Cme,` class
method.`),Cme.forEach(t),x1r=i(Wl),$k=n(Wl,"P",{});var Aso=s($k);$1r=r(Aso,"This class cannot be instantiated directly using "),FCe=n(Aso,"CODE",{});var SYt=s(FCe);k1r=r(SYt,"__init__()"),SYt.forEach(t),S1r=r(Aso," (throws an error)."),Aso.forEach(t),R1r=i(Wl),kt=n(Wl,"DIV",{class:!0});var v9=s(kt);T(kk.$$.fragment,v9),P1r=i(v9),TCe=n(v9,"P",{});var RYt=s(TCe);B1r=r(RYt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),RYt.forEach(t),I1r=i(v9),lm=n(v9,"P",{});var wme=s(lm);N1r=r(wme,`Note:
Loading a model from its configuration file does `),MCe=n(wme,"STRONG",{});var PYt=s(MCe);q1r=r(PYt,"not"),PYt.forEach(t),D1r=r(wme,` load the model weights. It only affects the
model\u2019s configuration. Use `),oZ=n(wme,"A",{href:!0});var BYt=s(oZ);j1r=r(BYt,"from_pretrained()"),BYt.forEach(t),G1r=r(wme," to load the model weights."),wme.forEach(t),O1r=i(v9),T(fE.$$.fragment,v9),v9.forEach(t),V1r=i(Wl),io=n(Wl,"DIV",{class:!0});var Ia=s(io);T(Sk.$$.fragment,Ia),X1r=i(Ia),ECe=n(Ia,"P",{});var IYt=s(ECe);z1r=r(IYt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),IYt.forEach(t),Q1r=i(Ia),un=n(Ia,"P",{});var F9=s(un);W1r=r(F9,"The model class to instantiate is selected based on the "),CCe=n(F9,"CODE",{});var NYt=s(CCe);U1r=r(NYt,"model_type"),NYt.forEach(t),H1r=r(F9,` property of the config object (either
passed as an argument or loaded from `),wCe=n(F9,"CODE",{});var qYt=s(wCe);J1r=r(qYt,"pretrained_model_name_or_path"),qYt.forEach(t),Y1r=r(F9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ACe=n(F9,"CODE",{});var DYt=s(ACe);Z1r=r(DYt,"pretrained_model_name_or_path"),DYt.forEach(t),K1r=r(F9,":"),F9.forEach(t),e2r=i(Ia),U=n(Ia,"UL",{});var J=s(U);gE=n(J,"LI",{});var UWe=s(gE);LCe=n(UWe,"STRONG",{});var jYt=s(LCe);o2r=r(jYt,"albert"),jYt.forEach(t),r2r=r(UWe," \u2014 "),rZ=n(UWe,"A",{href:!0});var GYt=s(rZ);t2r=r(GYt,"AlbertForTokenClassification"),GYt.forEach(t),a2r=r(UWe," (ALBERT model)"),UWe.forEach(t),n2r=i(J),hE=n(J,"LI",{});var HWe=s(hE);yCe=n(HWe,"STRONG",{});var OYt=s(yCe);s2r=r(OYt,"bert"),OYt.forEach(t),l2r=r(HWe," \u2014 "),tZ=n(HWe,"A",{href:!0});var VYt=s(tZ);i2r=r(VYt,"BertForTokenClassification"),VYt.forEach(t),d2r=r(HWe," (BERT model)"),HWe.forEach(t),m2r=i(J),uE=n(J,"LI",{});var JWe=s(uE);xCe=n(JWe,"STRONG",{});var XYt=s(xCe);c2r=r(XYt,"big_bird"),XYt.forEach(t),f2r=r(JWe," \u2014 "),aZ=n(JWe,"A",{href:!0});var zYt=s(aZ);g2r=r(zYt,"BigBirdForTokenClassification"),zYt.forEach(t),h2r=r(JWe," (BigBird model)"),JWe.forEach(t),u2r=i(J),pE=n(J,"LI",{});var YWe=s(pE);$Ce=n(YWe,"STRONG",{});var QYt=s($Ce);p2r=r(QYt,"bloom"),QYt.forEach(t),_2r=r(YWe," \u2014 "),nZ=n(YWe,"A",{href:!0});var WYt=s(nZ);b2r=r(WYt,"BloomForTokenClassification"),WYt.forEach(t),v2r=r(YWe," (BLOOM model)"),YWe.forEach(t),F2r=i(J),_E=n(J,"LI",{});var ZWe=s(_E);kCe=n(ZWe,"STRONG",{});var UYt=s(kCe);T2r=r(UYt,"camembert"),UYt.forEach(t),M2r=r(ZWe," \u2014 "),sZ=n(ZWe,"A",{href:!0});var HYt=s(sZ);E2r=r(HYt,"CamembertForTokenClassification"),HYt.forEach(t),C2r=r(ZWe," (CamemBERT model)"),ZWe.forEach(t),w2r=i(J),bE=n(J,"LI",{});var KWe=s(bE);SCe=n(KWe,"STRONG",{});var JYt=s(SCe);A2r=r(JYt,"canine"),JYt.forEach(t),L2r=r(KWe," \u2014 "),lZ=n(KWe,"A",{href:!0});var YYt=s(lZ);y2r=r(YYt,"CanineForTokenClassification"),YYt.forEach(t),x2r=r(KWe," (CANINE model)"),KWe.forEach(t),$2r=i(J),vE=n(J,"LI",{});var eUe=s(vE);RCe=n(eUe,"STRONG",{});var ZYt=s(RCe);k2r=r(ZYt,"convbert"),ZYt.forEach(t),S2r=r(eUe," \u2014 "),iZ=n(eUe,"A",{href:!0});var KYt=s(iZ);R2r=r(KYt,"ConvBertForTokenClassification"),KYt.forEach(t),P2r=r(eUe," (ConvBERT model)"),eUe.forEach(t),B2r=i(J),FE=n(J,"LI",{});var oUe=s(FE);PCe=n(oUe,"STRONG",{});var eZt=s(PCe);I2r=r(eZt,"data2vec-text"),eZt.forEach(t),N2r=r(oUe," \u2014 "),dZ=n(oUe,"A",{href:!0});var oZt=s(dZ);q2r=r(oZt,"Data2VecTextForTokenClassification"),oZt.forEach(t),D2r=r(oUe," (Data2VecText model)"),oUe.forEach(t),j2r=i(J),TE=n(J,"LI",{});var rUe=s(TE);BCe=n(rUe,"STRONG",{});var rZt=s(BCe);G2r=r(rZt,"deberta"),rZt.forEach(t),O2r=r(rUe," \u2014 "),mZ=n(rUe,"A",{href:!0});var tZt=s(mZ);V2r=r(tZt,"DebertaForTokenClassification"),tZt.forEach(t),X2r=r(rUe," (DeBERTa model)"),rUe.forEach(t),z2r=i(J),ME=n(J,"LI",{});var tUe=s(ME);ICe=n(tUe,"STRONG",{});var aZt=s(ICe);Q2r=r(aZt,"deberta-v2"),aZt.forEach(t),W2r=r(tUe," \u2014 "),cZ=n(tUe,"A",{href:!0});var nZt=s(cZ);U2r=r(nZt,"DebertaV2ForTokenClassification"),nZt.forEach(t),H2r=r(tUe," (DeBERTa-v2 model)"),tUe.forEach(t),J2r=i(J),EE=n(J,"LI",{});var aUe=s(EE);NCe=n(aUe,"STRONG",{});var sZt=s(NCe);Y2r=r(sZt,"distilbert"),sZt.forEach(t),Z2r=r(aUe," \u2014 "),fZ=n(aUe,"A",{href:!0});var lZt=s(fZ);K2r=r(lZt,"DistilBertForTokenClassification"),lZt.forEach(t),ebr=r(aUe," (DistilBERT model)"),aUe.forEach(t),obr=i(J),CE=n(J,"LI",{});var nUe=s(CE);qCe=n(nUe,"STRONG",{});var iZt=s(qCe);rbr=r(iZt,"electra"),iZt.forEach(t),tbr=r(nUe," \u2014 "),gZ=n(nUe,"A",{href:!0});var dZt=s(gZ);abr=r(dZt,"ElectraForTokenClassification"),dZt.forEach(t),nbr=r(nUe," (ELECTRA model)"),nUe.forEach(t),sbr=i(J),wE=n(J,"LI",{});var sUe=s(wE);DCe=n(sUe,"STRONG",{});var mZt=s(DCe);lbr=r(mZt,"ernie"),mZt.forEach(t),ibr=r(sUe," \u2014 "),hZ=n(sUe,"A",{href:!0});var cZt=s(hZ);dbr=r(cZt,"ErnieForTokenClassification"),cZt.forEach(t),mbr=r(sUe," (ERNIE model)"),sUe.forEach(t),cbr=i(J),AE=n(J,"LI",{});var lUe=s(AE);jCe=n(lUe,"STRONG",{});var fZt=s(jCe);fbr=r(fZt,"esm"),fZt.forEach(t),gbr=r(lUe," \u2014 "),uZ=n(lUe,"A",{href:!0});var gZt=s(uZ);hbr=r(gZt,"EsmForTokenClassification"),gZt.forEach(t),ubr=r(lUe," (ESM model)"),lUe.forEach(t),pbr=i(J),LE=n(J,"LI",{});var iUe=s(LE);GCe=n(iUe,"STRONG",{});var hZt=s(GCe);_br=r(hZt,"flaubert"),hZt.forEach(t),bbr=r(iUe," \u2014 "),pZ=n(iUe,"A",{href:!0});var uZt=s(pZ);vbr=r(uZt,"FlaubertForTokenClassification"),uZt.forEach(t),Fbr=r(iUe," (FlauBERT model)"),iUe.forEach(t),Tbr=i(J),yE=n(J,"LI",{});var dUe=s(yE);OCe=n(dUe,"STRONG",{});var pZt=s(OCe);Mbr=r(pZt,"fnet"),pZt.forEach(t),Ebr=r(dUe," \u2014 "),_Z=n(dUe,"A",{href:!0});var _Zt=s(_Z);Cbr=r(_Zt,"FNetForTokenClassification"),_Zt.forEach(t),wbr=r(dUe," (FNet model)"),dUe.forEach(t),Abr=i(J),xE=n(J,"LI",{});var mUe=s(xE);VCe=n(mUe,"STRONG",{});var bZt=s(VCe);Lbr=r(bZt,"funnel"),bZt.forEach(t),ybr=r(mUe," \u2014 "),bZ=n(mUe,"A",{href:!0});var vZt=s(bZ);xbr=r(vZt,"FunnelForTokenClassification"),vZt.forEach(t),$br=r(mUe," (Funnel Transformer model)"),mUe.forEach(t),kbr=i(J),$E=n(J,"LI",{});var cUe=s($E);XCe=n(cUe,"STRONG",{});var FZt=s(XCe);Sbr=r(FZt,"gpt2"),FZt.forEach(t),Rbr=r(cUe," \u2014 "),vZ=n(cUe,"A",{href:!0});var TZt=s(vZ);Pbr=r(TZt,"GPT2ForTokenClassification"),TZt.forEach(t),Bbr=r(cUe," (OpenAI GPT-2 model)"),cUe.forEach(t),Ibr=i(J),kE=n(J,"LI",{});var fUe=s(kE);zCe=n(fUe,"STRONG",{});var MZt=s(zCe);Nbr=r(MZt,"ibert"),MZt.forEach(t),qbr=r(fUe," \u2014 "),FZ=n(fUe,"A",{href:!0});var EZt=s(FZ);Dbr=r(EZt,"IBertForTokenClassification"),EZt.forEach(t),jbr=r(fUe," (I-BERT model)"),fUe.forEach(t),Gbr=i(J),SE=n(J,"LI",{});var gUe=s(SE);QCe=n(gUe,"STRONG",{});var CZt=s(QCe);Obr=r(CZt,"layoutlm"),CZt.forEach(t),Vbr=r(gUe," \u2014 "),TZ=n(gUe,"A",{href:!0});var wZt=s(TZ);Xbr=r(wZt,"LayoutLMForTokenClassification"),wZt.forEach(t),zbr=r(gUe," (LayoutLM model)"),gUe.forEach(t),Qbr=i(J),RE=n(J,"LI",{});var hUe=s(RE);WCe=n(hUe,"STRONG",{});var AZt=s(WCe);Wbr=r(AZt,"layoutlmv2"),AZt.forEach(t),Ubr=r(hUe," \u2014 "),MZ=n(hUe,"A",{href:!0});var LZt=s(MZ);Hbr=r(LZt,"LayoutLMv2ForTokenClassification"),LZt.forEach(t),Jbr=r(hUe," (LayoutLMv2 model)"),hUe.forEach(t),Ybr=i(J),PE=n(J,"LI",{});var uUe=s(PE);UCe=n(uUe,"STRONG",{});var yZt=s(UCe);Zbr=r(yZt,"layoutlmv3"),yZt.forEach(t),Kbr=r(uUe," \u2014 "),EZ=n(uUe,"A",{href:!0});var xZt=s(EZ);evr=r(xZt,"LayoutLMv3ForTokenClassification"),xZt.forEach(t),ovr=r(uUe," (LayoutLMv3 model)"),uUe.forEach(t),rvr=i(J),BE=n(J,"LI",{});var pUe=s(BE);HCe=n(pUe,"STRONG",{});var $Zt=s(HCe);tvr=r($Zt,"lilt"),$Zt.forEach(t),avr=r(pUe," \u2014 "),CZ=n(pUe,"A",{href:!0});var kZt=s(CZ);nvr=r(kZt,"LiltForTokenClassification"),kZt.forEach(t),svr=r(pUe," (LiLT model)"),pUe.forEach(t),lvr=i(J),IE=n(J,"LI",{});var _Ue=s(IE);JCe=n(_Ue,"STRONG",{});var SZt=s(JCe);ivr=r(SZt,"longformer"),SZt.forEach(t),dvr=r(_Ue," \u2014 "),wZ=n(_Ue,"A",{href:!0});var RZt=s(wZ);mvr=r(RZt,"LongformerForTokenClassification"),RZt.forEach(t),cvr=r(_Ue," (Longformer model)"),_Ue.forEach(t),fvr=i(J),NE=n(J,"LI",{});var bUe=s(NE);YCe=n(bUe,"STRONG",{});var PZt=s(YCe);gvr=r(PZt,"luke"),PZt.forEach(t),hvr=r(bUe," \u2014 "),AZ=n(bUe,"A",{href:!0});var BZt=s(AZ);uvr=r(BZt,"LukeForTokenClassification"),BZt.forEach(t),pvr=r(bUe," (LUKE model)"),bUe.forEach(t),_vr=i(J),qE=n(J,"LI",{});var vUe=s(qE);ZCe=n(vUe,"STRONG",{});var IZt=s(ZCe);bvr=r(IZt,"markuplm"),IZt.forEach(t),vvr=r(vUe," \u2014 "),LZ=n(vUe,"A",{href:!0});var NZt=s(LZ);Fvr=r(NZt,"MarkupLMForTokenClassification"),NZt.forEach(t),Tvr=r(vUe," (MarkupLM model)"),vUe.forEach(t),Mvr=i(J),DE=n(J,"LI",{});var FUe=s(DE);KCe=n(FUe,"STRONG",{});var qZt=s(KCe);Evr=r(qZt,"megatron-bert"),qZt.forEach(t),Cvr=r(FUe," \u2014 "),yZ=n(FUe,"A",{href:!0});var DZt=s(yZ);wvr=r(DZt,"MegatronBertForTokenClassification"),DZt.forEach(t),Avr=r(FUe," (Megatron-BERT model)"),FUe.forEach(t),Lvr=i(J),jE=n(J,"LI",{});var TUe=s(jE);e3e=n(TUe,"STRONG",{});var jZt=s(e3e);yvr=r(jZt,"mobilebert"),jZt.forEach(t),xvr=r(TUe," \u2014 "),xZ=n(TUe,"A",{href:!0});var GZt=s(xZ);$vr=r(GZt,"MobileBertForTokenClassification"),GZt.forEach(t),kvr=r(TUe," (MobileBERT model)"),TUe.forEach(t),Svr=i(J),GE=n(J,"LI",{});var MUe=s(GE);o3e=n(MUe,"STRONG",{});var OZt=s(o3e);Rvr=r(OZt,"mpnet"),OZt.forEach(t),Pvr=r(MUe," \u2014 "),$Z=n(MUe,"A",{href:!0});var VZt=s($Z);Bvr=r(VZt,"MPNetForTokenClassification"),VZt.forEach(t),Ivr=r(MUe," (MPNet model)"),MUe.forEach(t),Nvr=i(J),OE=n(J,"LI",{});var EUe=s(OE);r3e=n(EUe,"STRONG",{});var XZt=s(r3e);qvr=r(XZt,"nezha"),XZt.forEach(t),Dvr=r(EUe," \u2014 "),kZ=n(EUe,"A",{href:!0});var zZt=s(kZ);jvr=r(zZt,"NezhaForTokenClassification"),zZt.forEach(t),Gvr=r(EUe," (Nezha model)"),EUe.forEach(t),Ovr=i(J),VE=n(J,"LI",{});var CUe=s(VE);t3e=n(CUe,"STRONG",{});var QZt=s(t3e);Vvr=r(QZt,"nystromformer"),QZt.forEach(t),Xvr=r(CUe," \u2014 "),SZ=n(CUe,"A",{href:!0});var WZt=s(SZ);zvr=r(WZt,"NystromformerForTokenClassification"),WZt.forEach(t),Qvr=r(CUe," (Nystr\xF6mformer model)"),CUe.forEach(t),Wvr=i(J),XE=n(J,"LI",{});var wUe=s(XE);a3e=n(wUe,"STRONG",{});var UZt=s(a3e);Uvr=r(UZt,"qdqbert"),UZt.forEach(t),Hvr=r(wUe," \u2014 "),RZ=n(wUe,"A",{href:!0});var HZt=s(RZ);Jvr=r(HZt,"QDQBertForTokenClassification"),HZt.forEach(t),Yvr=r(wUe," (QDQBert model)"),wUe.forEach(t),Zvr=i(J),zE=n(J,"LI",{});var AUe=s(zE);n3e=n(AUe,"STRONG",{});var JZt=s(n3e);Kvr=r(JZt,"rembert"),JZt.forEach(t),eFr=r(AUe," \u2014 "),PZ=n(AUe,"A",{href:!0});var YZt=s(PZ);oFr=r(YZt,"RemBertForTokenClassification"),YZt.forEach(t),rFr=r(AUe," (RemBERT model)"),AUe.forEach(t),tFr=i(J),QE=n(J,"LI",{});var LUe=s(QE);s3e=n(LUe,"STRONG",{});var ZZt=s(s3e);aFr=r(ZZt,"roberta"),ZZt.forEach(t),nFr=r(LUe," \u2014 "),BZ=n(LUe,"A",{href:!0});var KZt=s(BZ);sFr=r(KZt,"RobertaForTokenClassification"),KZt.forEach(t),lFr=r(LUe," (RoBERTa model)"),LUe.forEach(t),iFr=i(J),WE=n(J,"LI",{});var yUe=s(WE);l3e=n(yUe,"STRONG",{});var eKt=s(l3e);dFr=r(eKt,"roformer"),eKt.forEach(t),mFr=r(yUe," \u2014 "),IZ=n(yUe,"A",{href:!0});var oKt=s(IZ);cFr=r(oKt,"RoFormerForTokenClassification"),oKt.forEach(t),fFr=r(yUe," (RoFormer model)"),yUe.forEach(t),gFr=i(J),UE=n(J,"LI",{});var xUe=s(UE);i3e=n(xUe,"STRONG",{});var rKt=s(i3e);hFr=r(rKt,"squeezebert"),rKt.forEach(t),uFr=r(xUe," \u2014 "),NZ=n(xUe,"A",{href:!0});var tKt=s(NZ);pFr=r(tKt,"SqueezeBertForTokenClassification"),tKt.forEach(t),_Fr=r(xUe," (SqueezeBERT model)"),xUe.forEach(t),bFr=i(J),HE=n(J,"LI",{});var $Ue=s(HE);d3e=n($Ue,"STRONG",{});var aKt=s(d3e);vFr=r(aKt,"xlm"),aKt.forEach(t),FFr=r($Ue," \u2014 "),qZ=n($Ue,"A",{href:!0});var nKt=s(qZ);TFr=r(nKt,"XLMForTokenClassification"),nKt.forEach(t),MFr=r($Ue," (XLM model)"),$Ue.forEach(t),EFr=i(J),JE=n(J,"LI",{});var kUe=s(JE);m3e=n(kUe,"STRONG",{});var sKt=s(m3e);CFr=r(sKt,"xlm-roberta"),sKt.forEach(t),wFr=r(kUe," \u2014 "),DZ=n(kUe,"A",{href:!0});var lKt=s(DZ);AFr=r(lKt,"XLMRobertaForTokenClassification"),lKt.forEach(t),LFr=r(kUe," (XLM-RoBERTa model)"),kUe.forEach(t),yFr=i(J),YE=n(J,"LI",{});var SUe=s(YE);c3e=n(SUe,"STRONG",{});var iKt=s(c3e);xFr=r(iKt,"xlm-roberta-xl"),iKt.forEach(t),$Fr=r(SUe," \u2014 "),jZ=n(SUe,"A",{href:!0});var dKt=s(jZ);kFr=r(dKt,"XLMRobertaXLForTokenClassification"),dKt.forEach(t),SFr=r(SUe," (XLM-RoBERTa-XL model)"),SUe.forEach(t),RFr=i(J),ZE=n(J,"LI",{});var RUe=s(ZE);f3e=n(RUe,"STRONG",{});var mKt=s(f3e);PFr=r(mKt,"xlnet"),mKt.forEach(t),BFr=r(RUe," \u2014 "),GZ=n(RUe,"A",{href:!0});var cKt=s(GZ);IFr=r(cKt,"XLNetForTokenClassification"),cKt.forEach(t),NFr=r(RUe," (XLNet model)"),RUe.forEach(t),qFr=i(J),KE=n(J,"LI",{});var PUe=s(KE);g3e=n(PUe,"STRONG",{});var fKt=s(g3e);DFr=r(fKt,"yoso"),fKt.forEach(t),jFr=r(PUe," \u2014 "),OZ=n(PUe,"A",{href:!0});var gKt=s(OZ);GFr=r(gKt,"YosoForTokenClassification"),gKt.forEach(t),OFr=r(PUe," (YOSO model)"),PUe.forEach(t),J.forEach(t),VFr=i(Ia),e4=n(Ia,"P",{});var BUe=s(e4);XFr=r(BUe,"The model is set in evaluation mode by default using "),h3e=n(BUe,"CODE",{});var hKt=s(h3e);zFr=r(hKt,"model.eval()"),hKt.forEach(t),QFr=r(BUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u3e=n(BUe,"CODE",{});var uKt=s(u3e);WFr=r(uKt,"model.train()"),uKt.forEach(t),BUe.forEach(t),UFr=i(Ia),T(o4.$$.fragment,Ia),Ia.forEach(t),Wl.forEach(t),iao=i(c),im=n(c,"H2",{class:!0});var Lso=s(im);r4=n(Lso,"A",{id:!0,class:!0,href:!0});var pKt=s(r4);p3e=n(pKt,"SPAN",{});var _Kt=s(p3e);T(Rk.$$.fragment,_Kt),_Kt.forEach(t),pKt.forEach(t),HFr=i(Lso),_3e=n(Lso,"SPAN",{});var bKt=s(_3e);JFr=r(bKt,"AutoModelForQuestionAnswering"),bKt.forEach(t),Lso.forEach(t),dao=i(c),Qo=n(c,"DIV",{class:!0});var Ul=s(Qo);T(Pk.$$.fragment,Ul),YFr=i(Ul),dm=n(Ul,"P",{});var Ame=s(dm);ZFr=r(Ame,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),VZ=n(Ame,"A",{href:!0});var vKt=s(VZ);KFr=r(vKt,"from_pretrained()"),vKt.forEach(t),eTr=r(Ame," class method or the "),XZ=n(Ame,"A",{href:!0});var FKt=s(XZ);oTr=r(FKt,"from_config()"),FKt.forEach(t),rTr=r(Ame,` class
method.`),Ame.forEach(t),tTr=i(Ul),Bk=n(Ul,"P",{});var yso=s(Bk);aTr=r(yso,"This class cannot be instantiated directly using "),b3e=n(yso,"CODE",{});var TKt=s(b3e);nTr=r(TKt,"__init__()"),TKt.forEach(t),sTr=r(yso," (throws an error)."),yso.forEach(t),lTr=i(Ul),St=n(Ul,"DIV",{class:!0});var T9=s(St);T(Ik.$$.fragment,T9),iTr=i(T9),v3e=n(T9,"P",{});var MKt=s(v3e);dTr=r(MKt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),MKt.forEach(t),mTr=i(T9),mm=n(T9,"P",{});var Lme=s(mm);cTr=r(Lme,`Note:
Loading a model from its configuration file does `),F3e=n(Lme,"STRONG",{});var EKt=s(F3e);fTr=r(EKt,"not"),EKt.forEach(t),gTr=r(Lme,` load the model weights. It only affects the
model\u2019s configuration. Use `),zZ=n(Lme,"A",{href:!0});var CKt=s(zZ);hTr=r(CKt,"from_pretrained()"),CKt.forEach(t),uTr=r(Lme," to load the model weights."),Lme.forEach(t),pTr=i(T9),T(t4.$$.fragment,T9),T9.forEach(t),_Tr=i(Ul),mo=n(Ul,"DIV",{class:!0});var Na=s(mo);T(Nk.$$.fragment,Na),bTr=i(Na),T3e=n(Na,"P",{});var wKt=s(T3e);vTr=r(wKt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),wKt.forEach(t),FTr=i(Na),pn=n(Na,"P",{});var M9=s(pn);TTr=r(M9,"The model class to instantiate is selected based on the "),M3e=n(M9,"CODE",{});var AKt=s(M3e);MTr=r(AKt,"model_type"),AKt.forEach(t),ETr=r(M9,` property of the config object (either
passed as an argument or loaded from `),E3e=n(M9,"CODE",{});var LKt=s(E3e);CTr=r(LKt,"pretrained_model_name_or_path"),LKt.forEach(t),wTr=r(M9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C3e=n(M9,"CODE",{});var yKt=s(C3e);ATr=r(yKt,"pretrained_model_name_or_path"),yKt.forEach(t),LTr=r(M9,":"),M9.forEach(t),yTr=i(Na),O=n(Na,"UL",{});var X=s(O);a4=n(X,"LI",{});var IUe=s(a4);w3e=n(IUe,"STRONG",{});var xKt=s(w3e);xTr=r(xKt,"albert"),xKt.forEach(t),$Tr=r(IUe," \u2014 "),QZ=n(IUe,"A",{href:!0});var $Kt=s(QZ);kTr=r($Kt,"AlbertForQuestionAnswering"),$Kt.forEach(t),STr=r(IUe," (ALBERT model)"),IUe.forEach(t),RTr=i(X),n4=n(X,"LI",{});var NUe=s(n4);A3e=n(NUe,"STRONG",{});var kKt=s(A3e);PTr=r(kKt,"bart"),kKt.forEach(t),BTr=r(NUe," \u2014 "),WZ=n(NUe,"A",{href:!0});var SKt=s(WZ);ITr=r(SKt,"BartForQuestionAnswering"),SKt.forEach(t),NTr=r(NUe," (BART model)"),NUe.forEach(t),qTr=i(X),s4=n(X,"LI",{});var qUe=s(s4);L3e=n(qUe,"STRONG",{});var RKt=s(L3e);DTr=r(RKt,"bert"),RKt.forEach(t),jTr=r(qUe," \u2014 "),UZ=n(qUe,"A",{href:!0});var PKt=s(UZ);GTr=r(PKt,"BertForQuestionAnswering"),PKt.forEach(t),OTr=r(qUe," (BERT model)"),qUe.forEach(t),VTr=i(X),l4=n(X,"LI",{});var DUe=s(l4);y3e=n(DUe,"STRONG",{});var BKt=s(y3e);XTr=r(BKt,"big_bird"),BKt.forEach(t),zTr=r(DUe," \u2014 "),HZ=n(DUe,"A",{href:!0});var IKt=s(HZ);QTr=r(IKt,"BigBirdForQuestionAnswering"),IKt.forEach(t),WTr=r(DUe," (BigBird model)"),DUe.forEach(t),UTr=i(X),i4=n(X,"LI",{});var jUe=s(i4);x3e=n(jUe,"STRONG",{});var NKt=s(x3e);HTr=r(NKt,"bigbird_pegasus"),NKt.forEach(t),JTr=r(jUe," \u2014 "),JZ=n(jUe,"A",{href:!0});var qKt=s(JZ);YTr=r(qKt,"BigBirdPegasusForQuestionAnswering"),qKt.forEach(t),ZTr=r(jUe," (BigBird-Pegasus model)"),jUe.forEach(t),KTr=i(X),d4=n(X,"LI",{});var GUe=s(d4);$3e=n(GUe,"STRONG",{});var DKt=s($3e);eMr=r(DKt,"bloom"),DKt.forEach(t),oMr=r(GUe," \u2014 "),YZ=n(GUe,"A",{href:!0});var jKt=s(YZ);rMr=r(jKt,"BloomForQuestionAnswering"),jKt.forEach(t),tMr=r(GUe," (BLOOM model)"),GUe.forEach(t),aMr=i(X),m4=n(X,"LI",{});var OUe=s(m4);k3e=n(OUe,"STRONG",{});var GKt=s(k3e);nMr=r(GKt,"camembert"),GKt.forEach(t),sMr=r(OUe," \u2014 "),ZZ=n(OUe,"A",{href:!0});var OKt=s(ZZ);lMr=r(OKt,"CamembertForQuestionAnswering"),OKt.forEach(t),iMr=r(OUe," (CamemBERT model)"),OUe.forEach(t),dMr=i(X),c4=n(X,"LI",{});var VUe=s(c4);S3e=n(VUe,"STRONG",{});var VKt=s(S3e);mMr=r(VKt,"canine"),VKt.forEach(t),cMr=r(VUe," \u2014 "),KZ=n(VUe,"A",{href:!0});var XKt=s(KZ);fMr=r(XKt,"CanineForQuestionAnswering"),XKt.forEach(t),gMr=r(VUe," (CANINE model)"),VUe.forEach(t),hMr=i(X),f4=n(X,"LI",{});var XUe=s(f4);R3e=n(XUe,"STRONG",{});var zKt=s(R3e);uMr=r(zKt,"convbert"),zKt.forEach(t),pMr=r(XUe," \u2014 "),eK=n(XUe,"A",{href:!0});var QKt=s(eK);_Mr=r(QKt,"ConvBertForQuestionAnswering"),QKt.forEach(t),bMr=r(XUe," (ConvBERT model)"),XUe.forEach(t),vMr=i(X),g4=n(X,"LI",{});var zUe=s(g4);P3e=n(zUe,"STRONG",{});var WKt=s(P3e);FMr=r(WKt,"data2vec-text"),WKt.forEach(t),TMr=r(zUe," \u2014 "),oK=n(zUe,"A",{href:!0});var UKt=s(oK);MMr=r(UKt,"Data2VecTextForQuestionAnswering"),UKt.forEach(t),EMr=r(zUe," (Data2VecText model)"),zUe.forEach(t),CMr=i(X),h4=n(X,"LI",{});var QUe=s(h4);B3e=n(QUe,"STRONG",{});var HKt=s(B3e);wMr=r(HKt,"deberta"),HKt.forEach(t),AMr=r(QUe," \u2014 "),rK=n(QUe,"A",{href:!0});var JKt=s(rK);LMr=r(JKt,"DebertaForQuestionAnswering"),JKt.forEach(t),yMr=r(QUe," (DeBERTa model)"),QUe.forEach(t),xMr=i(X),u4=n(X,"LI",{});var WUe=s(u4);I3e=n(WUe,"STRONG",{});var YKt=s(I3e);$Mr=r(YKt,"deberta-v2"),YKt.forEach(t),kMr=r(WUe," \u2014 "),tK=n(WUe,"A",{href:!0});var ZKt=s(tK);SMr=r(ZKt,"DebertaV2ForQuestionAnswering"),ZKt.forEach(t),RMr=r(WUe," (DeBERTa-v2 model)"),WUe.forEach(t),PMr=i(X),p4=n(X,"LI",{});var UUe=s(p4);N3e=n(UUe,"STRONG",{});var KKt=s(N3e);BMr=r(KKt,"distilbert"),KKt.forEach(t),IMr=r(UUe," \u2014 "),aK=n(UUe,"A",{href:!0});var eea=s(aK);NMr=r(eea,"DistilBertForQuestionAnswering"),eea.forEach(t),qMr=r(UUe," (DistilBERT model)"),UUe.forEach(t),DMr=i(X),_4=n(X,"LI",{});var HUe=s(_4);q3e=n(HUe,"STRONG",{});var oea=s(q3e);jMr=r(oea,"electra"),oea.forEach(t),GMr=r(HUe," \u2014 "),nK=n(HUe,"A",{href:!0});var rea=s(nK);OMr=r(rea,"ElectraForQuestionAnswering"),rea.forEach(t),VMr=r(HUe," (ELECTRA model)"),HUe.forEach(t),XMr=i(X),b4=n(X,"LI",{});var JUe=s(b4);D3e=n(JUe,"STRONG",{});var tea=s(D3e);zMr=r(tea,"ernie"),tea.forEach(t),QMr=r(JUe," \u2014 "),sK=n(JUe,"A",{href:!0});var aea=s(sK);WMr=r(aea,"ErnieForQuestionAnswering"),aea.forEach(t),UMr=r(JUe," (ERNIE model)"),JUe.forEach(t),HMr=i(X),v4=n(X,"LI",{});var YUe=s(v4);j3e=n(YUe,"STRONG",{});var nea=s(j3e);JMr=r(nea,"flaubert"),nea.forEach(t),YMr=r(YUe," \u2014 "),lK=n(YUe,"A",{href:!0});var sea=s(lK);ZMr=r(sea,"FlaubertForQuestionAnsweringSimple"),sea.forEach(t),KMr=r(YUe," (FlauBERT model)"),YUe.forEach(t),eEr=i(X),F4=n(X,"LI",{});var ZUe=s(F4);G3e=n(ZUe,"STRONG",{});var lea=s(G3e);oEr=r(lea,"fnet"),lea.forEach(t),rEr=r(ZUe," \u2014 "),iK=n(ZUe,"A",{href:!0});var iea=s(iK);tEr=r(iea,"FNetForQuestionAnswering"),iea.forEach(t),aEr=r(ZUe," (FNet model)"),ZUe.forEach(t),nEr=i(X),T4=n(X,"LI",{});var KUe=s(T4);O3e=n(KUe,"STRONG",{});var dea=s(O3e);sEr=r(dea,"funnel"),dea.forEach(t),lEr=r(KUe," \u2014 "),dK=n(KUe,"A",{href:!0});var mea=s(dK);iEr=r(mea,"FunnelForQuestionAnswering"),mea.forEach(t),dEr=r(KUe," (Funnel Transformer model)"),KUe.forEach(t),mEr=i(X),M4=n(X,"LI",{});var eHe=s(M4);V3e=n(eHe,"STRONG",{});var cea=s(V3e);cEr=r(cea,"gptj"),cea.forEach(t),fEr=r(eHe," \u2014 "),mK=n(eHe,"A",{href:!0});var fea=s(mK);gEr=r(fea,"GPTJForQuestionAnswering"),fea.forEach(t),hEr=r(eHe," (GPT-J model)"),eHe.forEach(t),uEr=i(X),E4=n(X,"LI",{});var oHe=s(E4);X3e=n(oHe,"STRONG",{});var gea=s(X3e);pEr=r(gea,"ibert"),gea.forEach(t),_Er=r(oHe," \u2014 "),cK=n(oHe,"A",{href:!0});var hea=s(cK);bEr=r(hea,"IBertForQuestionAnswering"),hea.forEach(t),vEr=r(oHe," (I-BERT model)"),oHe.forEach(t),FEr=i(X),C4=n(X,"LI",{});var rHe=s(C4);z3e=n(rHe,"STRONG",{});var uea=s(z3e);TEr=r(uea,"layoutlmv2"),uea.forEach(t),MEr=r(rHe," \u2014 "),fK=n(rHe,"A",{href:!0});var pea=s(fK);EEr=r(pea,"LayoutLMv2ForQuestionAnswering"),pea.forEach(t),CEr=r(rHe," (LayoutLMv2 model)"),rHe.forEach(t),wEr=i(X),w4=n(X,"LI",{});var tHe=s(w4);Q3e=n(tHe,"STRONG",{});var _ea=s(Q3e);AEr=r(_ea,"layoutlmv3"),_ea.forEach(t),LEr=r(tHe," \u2014 "),gK=n(tHe,"A",{href:!0});var bea=s(gK);yEr=r(bea,"LayoutLMv3ForQuestionAnswering"),bea.forEach(t),xEr=r(tHe," (LayoutLMv3 model)"),tHe.forEach(t),$Er=i(X),A4=n(X,"LI",{});var aHe=s(A4);W3e=n(aHe,"STRONG",{});var vea=s(W3e);kEr=r(vea,"led"),vea.forEach(t),SEr=r(aHe," \u2014 "),hK=n(aHe,"A",{href:!0});var Fea=s(hK);REr=r(Fea,"LEDForQuestionAnswering"),Fea.forEach(t),PEr=r(aHe," (LED model)"),aHe.forEach(t),BEr=i(X),L4=n(X,"LI",{});var nHe=s(L4);U3e=n(nHe,"STRONG",{});var Tea=s(U3e);IEr=r(Tea,"lilt"),Tea.forEach(t),NEr=r(nHe," \u2014 "),uK=n(nHe,"A",{href:!0});var Mea=s(uK);qEr=r(Mea,"LiltForQuestionAnswering"),Mea.forEach(t),DEr=r(nHe," (LiLT model)"),nHe.forEach(t),jEr=i(X),y4=n(X,"LI",{});var sHe=s(y4);H3e=n(sHe,"STRONG",{});var Eea=s(H3e);GEr=r(Eea,"longformer"),Eea.forEach(t),OEr=r(sHe," \u2014 "),pK=n(sHe,"A",{href:!0});var Cea=s(pK);VEr=r(Cea,"LongformerForQuestionAnswering"),Cea.forEach(t),XEr=r(sHe," (Longformer model)"),sHe.forEach(t),zEr=i(X),x4=n(X,"LI",{});var lHe=s(x4);J3e=n(lHe,"STRONG",{});var wea=s(J3e);QEr=r(wea,"luke"),wea.forEach(t),WEr=r(lHe," \u2014 "),_K=n(lHe,"A",{href:!0});var Aea=s(_K);UEr=r(Aea,"LukeForQuestionAnswering"),Aea.forEach(t),HEr=r(lHe," (LUKE model)"),lHe.forEach(t),JEr=i(X),$4=n(X,"LI",{});var iHe=s($4);Y3e=n(iHe,"STRONG",{});var Lea=s(Y3e);YEr=r(Lea,"lxmert"),Lea.forEach(t),ZEr=r(iHe," \u2014 "),bK=n(iHe,"A",{href:!0});var yea=s(bK);KEr=r(yea,"LxmertForQuestionAnswering"),yea.forEach(t),e4r=r(iHe," (LXMERT model)"),iHe.forEach(t),o4r=i(X),k4=n(X,"LI",{});var dHe=s(k4);Z3e=n(dHe,"STRONG",{});var xea=s(Z3e);r4r=r(xea,"markuplm"),xea.forEach(t),t4r=r(dHe," \u2014 "),vK=n(dHe,"A",{href:!0});var $ea=s(vK);a4r=r($ea,"MarkupLMForQuestionAnswering"),$ea.forEach(t),n4r=r(dHe," (MarkupLM model)"),dHe.forEach(t),s4r=i(X),S4=n(X,"LI",{});var mHe=s(S4);K3e=n(mHe,"STRONG",{});var kea=s(K3e);l4r=r(kea,"mbart"),kea.forEach(t),i4r=r(mHe," \u2014 "),FK=n(mHe,"A",{href:!0});var Sea=s(FK);d4r=r(Sea,"MBartForQuestionAnswering"),Sea.forEach(t),m4r=r(mHe," (mBART model)"),mHe.forEach(t),c4r=i(X),R4=n(X,"LI",{});var cHe=s(R4);e5e=n(cHe,"STRONG",{});var Rea=s(e5e);f4r=r(Rea,"megatron-bert"),Rea.forEach(t),g4r=r(cHe," \u2014 "),TK=n(cHe,"A",{href:!0});var Pea=s(TK);h4r=r(Pea,"MegatronBertForQuestionAnswering"),Pea.forEach(t),u4r=r(cHe," (Megatron-BERT model)"),cHe.forEach(t),p4r=i(X),P4=n(X,"LI",{});var fHe=s(P4);o5e=n(fHe,"STRONG",{});var Bea=s(o5e);_4r=r(Bea,"mobilebert"),Bea.forEach(t),b4r=r(fHe," \u2014 "),MK=n(fHe,"A",{href:!0});var Iea=s(MK);v4r=r(Iea,"MobileBertForQuestionAnswering"),Iea.forEach(t),F4r=r(fHe," (MobileBERT model)"),fHe.forEach(t),T4r=i(X),B4=n(X,"LI",{});var gHe=s(B4);r5e=n(gHe,"STRONG",{});var Nea=s(r5e);M4r=r(Nea,"mpnet"),Nea.forEach(t),E4r=r(gHe," \u2014 "),EK=n(gHe,"A",{href:!0});var qea=s(EK);C4r=r(qea,"MPNetForQuestionAnswering"),qea.forEach(t),w4r=r(gHe," (MPNet model)"),gHe.forEach(t),A4r=i(X),I4=n(X,"LI",{});var hHe=s(I4);t5e=n(hHe,"STRONG",{});var Dea=s(t5e);L4r=r(Dea,"mvp"),Dea.forEach(t),y4r=r(hHe," \u2014 "),CK=n(hHe,"A",{href:!0});var jea=s(CK);x4r=r(jea,"MvpForQuestionAnswering"),jea.forEach(t),$4r=r(hHe," (MVP model)"),hHe.forEach(t),k4r=i(X),N4=n(X,"LI",{});var uHe=s(N4);a5e=n(uHe,"STRONG",{});var Gea=s(a5e);S4r=r(Gea,"nezha"),Gea.forEach(t),R4r=r(uHe," \u2014 "),wK=n(uHe,"A",{href:!0});var Oea=s(wK);P4r=r(Oea,"NezhaForQuestionAnswering"),Oea.forEach(t),B4r=r(uHe," (Nezha model)"),uHe.forEach(t),I4r=i(X),q4=n(X,"LI",{});var pHe=s(q4);n5e=n(pHe,"STRONG",{});var Vea=s(n5e);N4r=r(Vea,"nystromformer"),Vea.forEach(t),q4r=r(pHe," \u2014 "),AK=n(pHe,"A",{href:!0});var Xea=s(AK);D4r=r(Xea,"NystromformerForQuestionAnswering"),Xea.forEach(t),j4r=r(pHe," (Nystr\xF6mformer model)"),pHe.forEach(t),G4r=i(X),D4=n(X,"LI",{});var _He=s(D4);s5e=n(_He,"STRONG",{});var zea=s(s5e);O4r=r(zea,"opt"),zea.forEach(t),V4r=r(_He," \u2014 "),LK=n(_He,"A",{href:!0});var Qea=s(LK);X4r=r(Qea,"OPTForQuestionAnswering"),Qea.forEach(t),z4r=r(_He," (OPT model)"),_He.forEach(t),Q4r=i(X),j4=n(X,"LI",{});var bHe=s(j4);l5e=n(bHe,"STRONG",{});var Wea=s(l5e);W4r=r(Wea,"qdqbert"),Wea.forEach(t),U4r=r(bHe," \u2014 "),yK=n(bHe,"A",{href:!0});var Uea=s(yK);H4r=r(Uea,"QDQBertForQuestionAnswering"),Uea.forEach(t),J4r=r(bHe," (QDQBert model)"),bHe.forEach(t),Y4r=i(X),G4=n(X,"LI",{});var vHe=s(G4);i5e=n(vHe,"STRONG",{});var Hea=s(i5e);Z4r=r(Hea,"reformer"),Hea.forEach(t),K4r=r(vHe," \u2014 "),xK=n(vHe,"A",{href:!0});var Jea=s(xK);eCr=r(Jea,"ReformerForQuestionAnswering"),Jea.forEach(t),oCr=r(vHe," (Reformer model)"),vHe.forEach(t),rCr=i(X),O4=n(X,"LI",{});var FHe=s(O4);d5e=n(FHe,"STRONG",{});var Yea=s(d5e);tCr=r(Yea,"rembert"),Yea.forEach(t),aCr=r(FHe," \u2014 "),$K=n(FHe,"A",{href:!0});var Zea=s($K);nCr=r(Zea,"RemBertForQuestionAnswering"),Zea.forEach(t),sCr=r(FHe," (RemBERT model)"),FHe.forEach(t),lCr=i(X),V4=n(X,"LI",{});var THe=s(V4);m5e=n(THe,"STRONG",{});var Kea=s(m5e);iCr=r(Kea,"roberta"),Kea.forEach(t),dCr=r(THe," \u2014 "),kK=n(THe,"A",{href:!0});var eoa=s(kK);mCr=r(eoa,"RobertaForQuestionAnswering"),eoa.forEach(t),cCr=r(THe," (RoBERTa model)"),THe.forEach(t),fCr=i(X),X4=n(X,"LI",{});var MHe=s(X4);c5e=n(MHe,"STRONG",{});var ooa=s(c5e);gCr=r(ooa,"roformer"),ooa.forEach(t),hCr=r(MHe," \u2014 "),SK=n(MHe,"A",{href:!0});var roa=s(SK);uCr=r(roa,"RoFormerForQuestionAnswering"),roa.forEach(t),pCr=r(MHe," (RoFormer model)"),MHe.forEach(t),_Cr=i(X),z4=n(X,"LI",{});var EHe=s(z4);f5e=n(EHe,"STRONG",{});var toa=s(f5e);bCr=r(toa,"splinter"),toa.forEach(t),vCr=r(EHe," \u2014 "),RK=n(EHe,"A",{href:!0});var aoa=s(RK);FCr=r(aoa,"SplinterForQuestionAnswering"),aoa.forEach(t),TCr=r(EHe," (Splinter model)"),EHe.forEach(t),MCr=i(X),Q4=n(X,"LI",{});var CHe=s(Q4);g5e=n(CHe,"STRONG",{});var noa=s(g5e);ECr=r(noa,"squeezebert"),noa.forEach(t),CCr=r(CHe," \u2014 "),PK=n(CHe,"A",{href:!0});var soa=s(PK);wCr=r(soa,"SqueezeBertForQuestionAnswering"),soa.forEach(t),ACr=r(CHe," (SqueezeBERT model)"),CHe.forEach(t),LCr=i(X),W4=n(X,"LI",{});var wHe=s(W4);h5e=n(wHe,"STRONG",{});var loa=s(h5e);yCr=r(loa,"xlm"),loa.forEach(t),xCr=r(wHe," \u2014 "),BK=n(wHe,"A",{href:!0});var ioa=s(BK);$Cr=r(ioa,"XLMForQuestionAnsweringSimple"),ioa.forEach(t),kCr=r(wHe," (XLM model)"),wHe.forEach(t),SCr=i(X),U4=n(X,"LI",{});var AHe=s(U4);u5e=n(AHe,"STRONG",{});var doa=s(u5e);RCr=r(doa,"xlm-roberta"),doa.forEach(t),PCr=r(AHe," \u2014 "),IK=n(AHe,"A",{href:!0});var moa=s(IK);BCr=r(moa,"XLMRobertaForQuestionAnswering"),moa.forEach(t),ICr=r(AHe," (XLM-RoBERTa model)"),AHe.forEach(t),NCr=i(X),H4=n(X,"LI",{});var LHe=s(H4);p5e=n(LHe,"STRONG",{});var coa=s(p5e);qCr=r(coa,"xlm-roberta-xl"),coa.forEach(t),DCr=r(LHe," \u2014 "),NK=n(LHe,"A",{href:!0});var foa=s(NK);jCr=r(foa,"XLMRobertaXLForQuestionAnswering"),foa.forEach(t),GCr=r(LHe," (XLM-RoBERTa-XL model)"),LHe.forEach(t),OCr=i(X),J4=n(X,"LI",{});var yHe=s(J4);_5e=n(yHe,"STRONG",{});var goa=s(_5e);VCr=r(goa,"xlnet"),goa.forEach(t),XCr=r(yHe," \u2014 "),qK=n(yHe,"A",{href:!0});var hoa=s(qK);zCr=r(hoa,"XLNetForQuestionAnsweringSimple"),hoa.forEach(t),QCr=r(yHe," (XLNet model)"),yHe.forEach(t),WCr=i(X),Y4=n(X,"LI",{});var xHe=s(Y4);b5e=n(xHe,"STRONG",{});var uoa=s(b5e);UCr=r(uoa,"yoso"),uoa.forEach(t),HCr=r(xHe," \u2014 "),DK=n(xHe,"A",{href:!0});var poa=s(DK);JCr=r(poa,"YosoForQuestionAnswering"),poa.forEach(t),YCr=r(xHe," (YOSO model)"),xHe.forEach(t),X.forEach(t),ZCr=i(Na),Z4=n(Na,"P",{});var $He=s(Z4);KCr=r($He,"The model is set in evaluation mode by default using "),v5e=n($He,"CODE",{});var _oa=s(v5e);e3r=r(_oa,"model.eval()"),_oa.forEach(t),o3r=r($He,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F5e=n($He,"CODE",{});var boa=s(F5e);r3r=r(boa,"model.train()"),boa.forEach(t),$He.forEach(t),t3r=i(Na),T(K4.$$.fragment,Na),Na.forEach(t),Ul.forEach(t),mao=i(c),cm=n(c,"H2",{class:!0});var xso=s(cm);eC=n(xso,"A",{id:!0,class:!0,href:!0});var voa=s(eC);T5e=n(voa,"SPAN",{});var Foa=s(T5e);T(qk.$$.fragment,Foa),Foa.forEach(t),voa.forEach(t),a3r=i(xso),M5e=n(xso,"SPAN",{});var Toa=s(M5e);n3r=r(Toa,"AutoModelForTableQuestionAnswering"),Toa.forEach(t),xso.forEach(t),cao=i(c),Wo=n(c,"DIV",{class:!0});var Hl=s(Wo);T(Dk.$$.fragment,Hl),s3r=i(Hl),fm=n(Hl,"P",{});var yme=s(fm);l3r=r(yme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),jK=n(yme,"A",{href:!0});var Moa=s(jK);i3r=r(Moa,"from_pretrained()"),Moa.forEach(t),d3r=r(yme," class method or the "),GK=n(yme,"A",{href:!0});var Eoa=s(GK);m3r=r(Eoa,"from_config()"),Eoa.forEach(t),c3r=r(yme,` class
method.`),yme.forEach(t),f3r=i(Hl),jk=n(Hl,"P",{});var $so=s(jk);g3r=r($so,"This class cannot be instantiated directly using "),E5e=n($so,"CODE",{});var Coa=s(E5e);h3r=r(Coa,"__init__()"),Coa.forEach(t),u3r=r($so," (throws an error)."),$so.forEach(t),p3r=i(Hl),Rt=n(Hl,"DIV",{class:!0});var E9=s(Rt);T(Gk.$$.fragment,E9),_3r=i(E9),C5e=n(E9,"P",{});var woa=s(C5e);b3r=r(woa,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),woa.forEach(t),v3r=i(E9),gm=n(E9,"P",{});var xme=s(gm);F3r=r(xme,`Note:
Loading a model from its configuration file does `),w5e=n(xme,"STRONG",{});var Aoa=s(w5e);T3r=r(Aoa,"not"),Aoa.forEach(t),M3r=r(xme,` load the model weights. It only affects the
model\u2019s configuration. Use `),OK=n(xme,"A",{href:!0});var Loa=s(OK);E3r=r(Loa,"from_pretrained()"),Loa.forEach(t),C3r=r(xme," to load the model weights."),xme.forEach(t),w3r=i(E9),T(oC.$$.fragment,E9),E9.forEach(t),A3r=i(Hl),co=n(Hl,"DIV",{class:!0});var qa=s(co);T(Ok.$$.fragment,qa),L3r=i(qa),A5e=n(qa,"P",{});var yoa=s(A5e);y3r=r(yoa,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),yoa.forEach(t),x3r=i(qa),_n=n(qa,"P",{});var C9=s(_n);$3r=r(C9,"The model class to instantiate is selected based on the "),L5e=n(C9,"CODE",{});var xoa=s(L5e);k3r=r(xoa,"model_type"),xoa.forEach(t),S3r=r(C9,` property of the config object (either
passed as an argument or loaded from `),y5e=n(C9,"CODE",{});var $oa=s(y5e);R3r=r($oa,"pretrained_model_name_or_path"),$oa.forEach(t),P3r=r(C9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x5e=n(C9,"CODE",{});var koa=s(x5e);B3r=r(koa,"pretrained_model_name_or_path"),koa.forEach(t),I3r=r(C9,":"),C9.forEach(t),N3r=i(qa),$5e=n(qa,"UL",{});var Soa=s($5e);rC=n(Soa,"LI",{});var kHe=s(rC);k5e=n(kHe,"STRONG",{});var Roa=s(k5e);q3r=r(Roa,"tapas"),Roa.forEach(t),D3r=r(kHe," \u2014 "),VK=n(kHe,"A",{href:!0});var Poa=s(VK);j3r=r(Poa,"TapasForQuestionAnswering"),Poa.forEach(t),G3r=r(kHe," (TAPAS model)"),kHe.forEach(t),Soa.forEach(t),O3r=i(qa),tC=n(qa,"P",{});var SHe=s(tC);V3r=r(SHe,"The model is set in evaluation mode by default using "),S5e=n(SHe,"CODE",{});var Boa=s(S5e);X3r=r(Boa,"model.eval()"),Boa.forEach(t),z3r=r(SHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),R5e=n(SHe,"CODE",{});var Ioa=s(R5e);Q3r=r(Ioa,"model.train()"),Ioa.forEach(t),SHe.forEach(t),W3r=i(qa),T(aC.$$.fragment,qa),qa.forEach(t),Hl.forEach(t),fao=i(c),hm=n(c,"H2",{class:!0});var kso=s(hm);nC=n(kso,"A",{id:!0,class:!0,href:!0});var Noa=s(nC);P5e=n(Noa,"SPAN",{});var qoa=s(P5e);T(Vk.$$.fragment,qoa),qoa.forEach(t),Noa.forEach(t),U3r=i(kso),B5e=n(kso,"SPAN",{});var Doa=s(B5e);H3r=r(Doa,"AutoModelForDocumentQuestionAnswering"),Doa.forEach(t),kso.forEach(t),gao=i(c),Uo=n(c,"DIV",{class:!0});var Jl=s(Uo);T(Xk.$$.fragment,Jl),J3r=i(Jl),um=n(Jl,"P",{});var $me=s(um);Y3r=r($me,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),XK=n($me,"A",{href:!0});var joa=s(XK);Z3r=r(joa,"from_pretrained()"),joa.forEach(t),K3r=r($me," class method or the "),zK=n($me,"A",{href:!0});var Goa=s(zK);e5r=r(Goa,"from_config()"),Goa.forEach(t),o5r=r($me,` class
method.`),$me.forEach(t),r5r=i(Jl),zk=n(Jl,"P",{});var Sso=s(zk);t5r=r(Sso,"This class cannot be instantiated directly using "),I5e=n(Sso,"CODE",{});var Ooa=s(I5e);a5r=r(Ooa,"__init__()"),Ooa.forEach(t),n5r=r(Sso," (throws an error)."),Sso.forEach(t),s5r=i(Jl),Pt=n(Jl,"DIV",{class:!0});var w9=s(Pt);T(Qk.$$.fragment,w9),l5r=i(w9),N5e=n(w9,"P",{});var Voa=s(N5e);i5r=r(Voa,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Voa.forEach(t),d5r=i(w9),pm=n(w9,"P",{});var kme=s(pm);m5r=r(kme,`Note:
Loading a model from its configuration file does `),q5e=n(kme,"STRONG",{});var Xoa=s(q5e);c5r=r(Xoa,"not"),Xoa.forEach(t),f5r=r(kme,` load the model weights. It only affects the
model\u2019s configuration. Use `),QK=n(kme,"A",{href:!0});var zoa=s(QK);g5r=r(zoa,"from_pretrained()"),zoa.forEach(t),h5r=r(kme," to load the model weights."),kme.forEach(t),u5r=i(w9),T(sC.$$.fragment,w9),w9.forEach(t),p5r=i(Jl),fo=n(Jl,"DIV",{class:!0});var Da=s(fo);T(Wk.$$.fragment,Da),_5r=i(Da),D5e=n(Da,"P",{});var Qoa=s(D5e);b5r=r(Qoa,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),Qoa.forEach(t),v5r=i(Da),bn=n(Da,"P",{});var A9=s(bn);F5r=r(A9,"The model class to instantiate is selected based on the "),j5e=n(A9,"CODE",{});var Woa=s(j5e);T5r=r(Woa,"model_type"),Woa.forEach(t),M5r=r(A9,` property of the config object (either
passed as an argument or loaded from `),G5e=n(A9,"CODE",{});var Uoa=s(G5e);E5r=r(Uoa,"pretrained_model_name_or_path"),Uoa.forEach(t),C5r=r(A9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O5e=n(A9,"CODE",{});var Hoa=s(O5e);w5r=r(Hoa,"pretrained_model_name_or_path"),Hoa.forEach(t),A5r=r(A9,":"),A9.forEach(t),L5r=i(Da),_m=n(Da,"UL",{});var Sme=s(_m);lC=n(Sme,"LI",{});var RHe=s(lC);V5e=n(RHe,"STRONG",{});var Joa=s(V5e);y5r=r(Joa,"layoutlm"),Joa.forEach(t),x5r=r(RHe," \u2014 "),WK=n(RHe,"A",{href:!0});var Yoa=s(WK);$5r=r(Yoa,"LayoutLMForQuestionAnswering"),Yoa.forEach(t),k5r=r(RHe," (LayoutLM model)"),RHe.forEach(t),S5r=i(Sme),iC=n(Sme,"LI",{});var PHe=s(iC);X5e=n(PHe,"STRONG",{});var Zoa=s(X5e);R5r=r(Zoa,"layoutlmv2"),Zoa.forEach(t),P5r=r(PHe," \u2014 "),UK=n(PHe,"A",{href:!0});var Koa=s(UK);B5r=r(Koa,"LayoutLMv2ForQuestionAnswering"),Koa.forEach(t),I5r=r(PHe," (LayoutLMv2 model)"),PHe.forEach(t),N5r=i(Sme),dC=n(Sme,"LI",{});var BHe=s(dC);z5e=n(BHe,"STRONG",{});var era=s(z5e);q5r=r(era,"layoutlmv3"),era.forEach(t),D5r=r(BHe," \u2014 "),HK=n(BHe,"A",{href:!0});var ora=s(HK);j5r=r(ora,"LayoutLMv3ForQuestionAnswering"),ora.forEach(t),G5r=r(BHe," (LayoutLMv3 model)"),BHe.forEach(t),Sme.forEach(t),O5r=i(Da),mC=n(Da,"P",{});var IHe=s(mC);V5r=r(IHe,"The model is set in evaluation mode by default using "),Q5e=n(IHe,"CODE",{});var rra=s(Q5e);X5r=r(rra,"model.eval()"),rra.forEach(t),z5r=r(IHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),W5e=n(IHe,"CODE",{});var tra=s(W5e);Q5r=r(tra,"model.train()"),tra.forEach(t),IHe.forEach(t),W5r=i(Da),T(cC.$$.fragment,Da),Da.forEach(t),Jl.forEach(t),hao=i(c),bm=n(c,"H2",{class:!0});var Rso=s(bm);fC=n(Rso,"A",{id:!0,class:!0,href:!0});var ara=s(fC);U5e=n(ara,"SPAN",{});var nra=s(U5e);T(Uk.$$.fragment,nra),nra.forEach(t),ara.forEach(t),U5r=i(Rso),H5e=n(Rso,"SPAN",{});var sra=s(H5e);H5r=r(sra,"AutoModelForImageClassification"),sra.forEach(t),Rso.forEach(t),uao=i(c),Ho=n(c,"DIV",{class:!0});var Yl=s(Ho);T(Hk.$$.fragment,Yl),J5r=i(Yl),vm=n(Yl,"P",{});var Rme=s(vm);Y5r=r(Rme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),JK=n(Rme,"A",{href:!0});var lra=s(JK);Z5r=r(lra,"from_pretrained()"),lra.forEach(t),K5r=r(Rme," class method or the "),YK=n(Rme,"A",{href:!0});var ira=s(YK);e0r=r(ira,"from_config()"),ira.forEach(t),o0r=r(Rme,` class
method.`),Rme.forEach(t),r0r=i(Yl),Jk=n(Yl,"P",{});var Pso=s(Jk);t0r=r(Pso,"This class cannot be instantiated directly using "),J5e=n(Pso,"CODE",{});var dra=s(J5e);a0r=r(dra,"__init__()"),dra.forEach(t),n0r=r(Pso," (throws an error)."),Pso.forEach(t),s0r=i(Yl),Bt=n(Yl,"DIV",{class:!0});var L9=s(Bt);T(Yk.$$.fragment,L9),l0r=i(L9),Y5e=n(L9,"P",{});var mra=s(Y5e);i0r=r(mra,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),mra.forEach(t),d0r=i(L9),Fm=n(L9,"P",{});var Pme=s(Fm);m0r=r(Pme,`Note:
Loading a model from its configuration file does `),Z5e=n(Pme,"STRONG",{});var cra=s(Z5e);c0r=r(cra,"not"),cra.forEach(t),f0r=r(Pme,` load the model weights. It only affects the
model\u2019s configuration. Use `),ZK=n(Pme,"A",{href:!0});var fra=s(ZK);g0r=r(fra,"from_pretrained()"),fra.forEach(t),h0r=r(Pme," to load the model weights."),Pme.forEach(t),u0r=i(L9),T(gC.$$.fragment,L9),L9.forEach(t),p0r=i(Yl),go=n(Yl,"DIV",{class:!0});var ja=s(go);T(Zk.$$.fragment,ja),_0r=i(ja),K5e=n(ja,"P",{});var gra=s(K5e);b0r=r(gra,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),gra.forEach(t),v0r=i(ja),vn=n(ja,"P",{});var y9=s(vn);F0r=r(y9,"The model class to instantiate is selected based on the "),e0e=n(y9,"CODE",{});var hra=s(e0e);T0r=r(hra,"model_type"),hra.forEach(t),M0r=r(y9,` property of the config object (either
passed as an argument or loaded from `),o0e=n(y9,"CODE",{});var ura=s(o0e);E0r=r(ura,"pretrained_model_name_or_path"),ura.forEach(t),C0r=r(y9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),r0e=n(y9,"CODE",{});var pra=s(r0e);w0r=r(pra,"pretrained_model_name_or_path"),pra.forEach(t),A0r=r(y9,":"),y9.forEach(t),L0r=i(ja),be=n(ja,"UL",{});var Fe=s(be);hC=n(Fe,"LI",{});var NHe=s(hC);t0e=n(NHe,"STRONG",{});var _ra=s(t0e);y0r=r(_ra,"beit"),_ra.forEach(t),x0r=r(NHe," \u2014 "),KK=n(NHe,"A",{href:!0});var bra=s(KK);$0r=r(bra,"BeitForImageClassification"),bra.forEach(t),k0r=r(NHe," (BEiT model)"),NHe.forEach(t),S0r=i(Fe),uC=n(Fe,"LI",{});var qHe=s(uC);a0e=n(qHe,"STRONG",{});var vra=s(a0e);R0r=r(vra,"convnext"),vra.forEach(t),P0r=r(qHe," \u2014 "),eee=n(qHe,"A",{href:!0});var Fra=s(eee);B0r=r(Fra,"ConvNextForImageClassification"),Fra.forEach(t),I0r=r(qHe," (ConvNeXT model)"),qHe.forEach(t),N0r=i(Fe),pC=n(Fe,"LI",{});var DHe=s(pC);n0e=n(DHe,"STRONG",{});var Tra=s(n0e);q0r=r(Tra,"cvt"),Tra.forEach(t),D0r=r(DHe," \u2014 "),oee=n(DHe,"A",{href:!0});var Mra=s(oee);j0r=r(Mra,"CvtForImageClassification"),Mra.forEach(t),G0r=r(DHe," (CvT model)"),DHe.forEach(t),O0r=i(Fe),_C=n(Fe,"LI",{});var jHe=s(_C);s0e=n(jHe,"STRONG",{});var Era=s(s0e);V0r=r(Era,"data2vec-vision"),Era.forEach(t),X0r=r(jHe," \u2014 "),ree=n(jHe,"A",{href:!0});var Cra=s(ree);z0r=r(Cra,"Data2VecVisionForImageClassification"),Cra.forEach(t),Q0r=r(jHe," (Data2VecVision model)"),jHe.forEach(t),W0r=i(Fe),$l=n(Fe,"LI",{});var vN=s($l);l0e=n(vN,"STRONG",{});var wra=s(l0e);U0r=r(wra,"deit"),wra.forEach(t),H0r=r(vN," \u2014 "),tee=n(vN,"A",{href:!0});var Ara=s(tee);J0r=r(Ara,"DeiTForImageClassification"),Ara.forEach(t),Y0r=r(vN," or "),aee=n(vN,"A",{href:!0});var Lra=s(aee);Z0r=r(Lra,"DeiTForImageClassificationWithTeacher"),Lra.forEach(t),K0r=r(vN," (DeiT model)"),vN.forEach(t),ewr=i(Fe),bC=n(Fe,"LI",{});var GHe=s(bC);i0e=n(GHe,"STRONG",{});var yra=s(i0e);owr=r(yra,"imagegpt"),yra.forEach(t),rwr=r(GHe," \u2014 "),nee=n(GHe,"A",{href:!0});var xra=s(nee);twr=r(xra,"ImageGPTForImageClassification"),xra.forEach(t),awr=r(GHe," (ImageGPT model)"),GHe.forEach(t),nwr=i(Fe),kl=n(Fe,"LI",{});var FN=s(kl);d0e=n(FN,"STRONG",{});var $ra=s(d0e);swr=r($ra,"levit"),$ra.forEach(t),lwr=r(FN," \u2014 "),see=n(FN,"A",{href:!0});var kra=s(see);iwr=r(kra,"LevitForImageClassification"),kra.forEach(t),dwr=r(FN," or "),lee=n(FN,"A",{href:!0});var Sra=s(lee);mwr=r(Sra,"LevitForImageClassificationWithTeacher"),Sra.forEach(t),cwr=r(FN," (LeViT model)"),FN.forEach(t),fwr=i(Fe),vC=n(Fe,"LI",{});var OHe=s(vC);m0e=n(OHe,"STRONG",{});var Rra=s(m0e);gwr=r(Rra,"mobilevit"),Rra.forEach(t),hwr=r(OHe," \u2014 "),iee=n(OHe,"A",{href:!0});var Pra=s(iee);uwr=r(Pra,"MobileViTForImageClassification"),Pra.forEach(t),pwr=r(OHe," (MobileViT model)"),OHe.forEach(t),_wr=i(Fe),It=n(Fe,"LI",{});var Xf=s(It);c0e=n(Xf,"STRONG",{});var Bra=s(c0e);bwr=r(Bra,"perceiver"),Bra.forEach(t),vwr=r(Xf," \u2014 "),dee=n(Xf,"A",{href:!0});var Ira=s(dee);Fwr=r(Ira,"PerceiverForImageClassificationLearned"),Ira.forEach(t),Twr=r(Xf," or "),mee=n(Xf,"A",{href:!0});var Nra=s(mee);Mwr=r(Nra,"PerceiverForImageClassificationFourier"),Nra.forEach(t),Ewr=r(Xf," or "),cee=n(Xf,"A",{href:!0});var qra=s(cee);Cwr=r(qra,"PerceiverForImageClassificationConvProcessing"),qra.forEach(t),wwr=r(Xf," (Perceiver model)"),Xf.forEach(t),Awr=i(Fe),FC=n(Fe,"LI",{});var VHe=s(FC);f0e=n(VHe,"STRONG",{});var Dra=s(f0e);Lwr=r(Dra,"poolformer"),Dra.forEach(t),ywr=r(VHe," \u2014 "),fee=n(VHe,"A",{href:!0});var jra=s(fee);xwr=r(jra,"PoolFormerForImageClassification"),jra.forEach(t),$wr=r(VHe," (PoolFormer model)"),VHe.forEach(t),kwr=i(Fe),TC=n(Fe,"LI",{});var XHe=s(TC);g0e=n(XHe,"STRONG",{});var Gra=s(g0e);Swr=r(Gra,"regnet"),Gra.forEach(t),Rwr=r(XHe," \u2014 "),gee=n(XHe,"A",{href:!0});var Ora=s(gee);Pwr=r(Ora,"RegNetForImageClassification"),Ora.forEach(t),Bwr=r(XHe," (RegNet model)"),XHe.forEach(t),Iwr=i(Fe),MC=n(Fe,"LI",{});var zHe=s(MC);h0e=n(zHe,"STRONG",{});var Vra=s(h0e);Nwr=r(Vra,"resnet"),Vra.forEach(t),qwr=r(zHe," \u2014 "),hee=n(zHe,"A",{href:!0});var Xra=s(hee);Dwr=r(Xra,"ResNetForImageClassification"),Xra.forEach(t),jwr=r(zHe," (ResNet model)"),zHe.forEach(t),Gwr=i(Fe),EC=n(Fe,"LI",{});var QHe=s(EC);u0e=n(QHe,"STRONG",{});var zra=s(u0e);Owr=r(zra,"segformer"),zra.forEach(t),Vwr=r(QHe," \u2014 "),uee=n(QHe,"A",{href:!0});var Qra=s(uee);Xwr=r(Qra,"SegformerForImageClassification"),Qra.forEach(t),zwr=r(QHe," (SegFormer model)"),QHe.forEach(t),Qwr=i(Fe),CC=n(Fe,"LI",{});var WHe=s(CC);p0e=n(WHe,"STRONG",{});var Wra=s(p0e);Wwr=r(Wra,"swin"),Wra.forEach(t),Uwr=r(WHe," \u2014 "),pee=n(WHe,"A",{href:!0});var Ura=s(pee);Hwr=r(Ura,"SwinForImageClassification"),Ura.forEach(t),Jwr=r(WHe," (Swin Transformer model)"),WHe.forEach(t),Ywr=i(Fe),wC=n(Fe,"LI",{});var UHe=s(wC);_0e=n(UHe,"STRONG",{});var Hra=s(_0e);Zwr=r(Hra,"swinv2"),Hra.forEach(t),Kwr=r(UHe," \u2014 "),_ee=n(UHe,"A",{href:!0});var Jra=s(_ee);eAr=r(Jra,"Swinv2ForImageClassification"),Jra.forEach(t),oAr=r(UHe," (Swin Transformer V2 model)"),UHe.forEach(t),rAr=i(Fe),AC=n(Fe,"LI",{});var HHe=s(AC);b0e=n(HHe,"STRONG",{});var Yra=s(b0e);tAr=r(Yra,"van"),Yra.forEach(t),aAr=r(HHe," \u2014 "),bee=n(HHe,"A",{href:!0});var Zra=s(bee);nAr=r(Zra,"VanForImageClassification"),Zra.forEach(t),sAr=r(HHe," (VAN model)"),HHe.forEach(t),lAr=i(Fe),LC=n(Fe,"LI",{});var JHe=s(LC);v0e=n(JHe,"STRONG",{});var Kra=s(v0e);iAr=r(Kra,"vit"),Kra.forEach(t),dAr=r(JHe," \u2014 "),vee=n(JHe,"A",{href:!0});var eta=s(vee);mAr=r(eta,"ViTForImageClassification"),eta.forEach(t),cAr=r(JHe," (ViT model)"),JHe.forEach(t),fAr=i(Fe),yC=n(Fe,"LI",{});var YHe=s(yC);F0e=n(YHe,"STRONG",{});var ota=s(F0e);gAr=r(ota,"vit_msn"),ota.forEach(t),hAr=r(YHe," \u2014 "),Fee=n(YHe,"A",{href:!0});var rta=s(Fee);uAr=r(rta,"ViTMSNForImageClassification"),rta.forEach(t),pAr=r(YHe," (ViTMSN model)"),YHe.forEach(t),Fe.forEach(t),_Ar=i(ja),xC=n(ja,"P",{});var ZHe=s(xC);bAr=r(ZHe,"The model is set in evaluation mode by default using "),T0e=n(ZHe,"CODE",{});var tta=s(T0e);vAr=r(tta,"model.eval()"),tta.forEach(t),FAr=r(ZHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),M0e=n(ZHe,"CODE",{});var ata=s(M0e);TAr=r(ata,"model.train()"),ata.forEach(t),ZHe.forEach(t),MAr=i(ja),T($C.$$.fragment,ja),ja.forEach(t),Yl.forEach(t),pao=i(c),Tm=n(c,"H2",{class:!0});var Bso=s(Tm);kC=n(Bso,"A",{id:!0,class:!0,href:!0});var nta=s(kC);E0e=n(nta,"SPAN",{});var sta=s(E0e);T(Kk.$$.fragment,sta),sta.forEach(t),nta.forEach(t),EAr=i(Bso),C0e=n(Bso,"SPAN",{});var lta=s(C0e);CAr=r(lta,"AutoModelForVideoClassification"),lta.forEach(t),Bso.forEach(t),_ao=i(c),Jo=n(c,"DIV",{class:!0});var Zl=s(Jo);T(eS.$$.fragment,Zl),wAr=i(Zl),Mm=n(Zl,"P",{});var Bme=s(Mm);AAr=r(Bme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),Tee=n(Bme,"A",{href:!0});var ita=s(Tee);LAr=r(ita,"from_pretrained()"),ita.forEach(t),yAr=r(Bme," class method or the "),Mee=n(Bme,"A",{href:!0});var dta=s(Mee);xAr=r(dta,"from_config()"),dta.forEach(t),$Ar=r(Bme,` class
method.`),Bme.forEach(t),kAr=i(Zl),oS=n(Zl,"P",{});var Iso=s(oS);SAr=r(Iso,"This class cannot be instantiated directly using "),w0e=n(Iso,"CODE",{});var mta=s(w0e);RAr=r(mta,"__init__()"),mta.forEach(t),PAr=r(Iso," (throws an error)."),Iso.forEach(t),BAr=i(Zl),Nt=n(Zl,"DIV",{class:!0});var x9=s(Nt);T(rS.$$.fragment,x9),IAr=i(x9),A0e=n(x9,"P",{});var cta=s(A0e);NAr=r(cta,"Instantiates one of the model classes of the library (with a video classification head) from a configuration."),cta.forEach(t),qAr=i(x9),Em=n(x9,"P",{});var Ime=s(Em);DAr=r(Ime,`Note:
Loading a model from its configuration file does `),L0e=n(Ime,"STRONG",{});var fta=s(L0e);jAr=r(fta,"not"),fta.forEach(t),GAr=r(Ime,` load the model weights. It only affects the
model\u2019s configuration. Use `),Eee=n(Ime,"A",{href:!0});var gta=s(Eee);OAr=r(gta,"from_pretrained()"),gta.forEach(t),VAr=r(Ime," to load the model weights."),Ime.forEach(t),XAr=i(x9),T(SC.$$.fragment,x9),x9.forEach(t),zAr=i(Zl),ho=n(Zl,"DIV",{class:!0});var Ga=s(ho);T(tS.$$.fragment,Ga),QAr=i(Ga),y0e=n(Ga,"P",{});var hta=s(y0e);WAr=r(hta,"Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),hta.forEach(t),UAr=i(Ga),Fn=n(Ga,"P",{});var $9=s(Fn);HAr=r($9,"The model class to instantiate is selected based on the "),x0e=n($9,"CODE",{});var uta=s(x0e);JAr=r(uta,"model_type"),uta.forEach(t),YAr=r($9,` property of the config object (either
passed as an argument or loaded from `),$0e=n($9,"CODE",{});var pta=s($0e);ZAr=r(pta,"pretrained_model_name_or_path"),pta.forEach(t),KAr=r($9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k0e=n($9,"CODE",{});var _ta=s(k0e);e6r=r(_ta,"pretrained_model_name_or_path"),_ta.forEach(t),o6r=r($9,":"),$9.forEach(t),r6r=i(Ga),S0e=n(Ga,"UL",{});var bta=s(S0e);RC=n(bta,"LI",{});var KHe=s(RC);R0e=n(KHe,"STRONG",{});var vta=s(R0e);t6r=r(vta,"videomae"),vta.forEach(t),a6r=r(KHe," \u2014 "),Cee=n(KHe,"A",{href:!0});var Fta=s(Cee);n6r=r(Fta,"VideoMAEForVideoClassification"),Fta.forEach(t),s6r=r(KHe," (VideoMAE model)"),KHe.forEach(t),bta.forEach(t),l6r=i(Ga),PC=n(Ga,"P",{});var eJe=s(PC);i6r=r(eJe,"The model is set in evaluation mode by default using "),P0e=n(eJe,"CODE",{});var Tta=s(P0e);d6r=r(Tta,"model.eval()"),Tta.forEach(t),m6r=r(eJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),B0e=n(eJe,"CODE",{});var Mta=s(B0e);c6r=r(Mta,"model.train()"),Mta.forEach(t),eJe.forEach(t),f6r=i(Ga),T(BC.$$.fragment,Ga),Ga.forEach(t),Zl.forEach(t),bao=i(c),Cm=n(c,"H2",{class:!0});var Nso=s(Cm);IC=n(Nso,"A",{id:!0,class:!0,href:!0});var Eta=s(IC);I0e=n(Eta,"SPAN",{});var Cta=s(I0e);T(aS.$$.fragment,Cta),Cta.forEach(t),Eta.forEach(t),g6r=i(Nso),N0e=n(Nso,"SPAN",{});var wta=s(N0e);h6r=r(wta,"AutoModelForVision2Seq"),wta.forEach(t),Nso.forEach(t),vao=i(c),Yo=n(c,"DIV",{class:!0});var Kl=s(Yo);T(nS.$$.fragment,Kl),u6r=i(Kl),wm=n(Kl,"P",{});var Nme=s(wm);p6r=r(Nme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),wee=n(Nme,"A",{href:!0});var Ata=s(wee);_6r=r(Ata,"from_pretrained()"),Ata.forEach(t),b6r=r(Nme," class method or the "),Aee=n(Nme,"A",{href:!0});var Lta=s(Aee);v6r=r(Lta,"from_config()"),Lta.forEach(t),F6r=r(Nme,` class
method.`),Nme.forEach(t),T6r=i(Kl),sS=n(Kl,"P",{});var qso=s(sS);M6r=r(qso,"This class cannot be instantiated directly using "),q0e=n(qso,"CODE",{});var yta=s(q0e);E6r=r(yta,"__init__()"),yta.forEach(t),C6r=r(qso," (throws an error)."),qso.forEach(t),w6r=i(Kl),qt=n(Kl,"DIV",{class:!0});var k9=s(qt);T(lS.$$.fragment,k9),A6r=i(k9),D0e=n(k9,"P",{});var xta=s(D0e);L6r=r(xta,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),xta.forEach(t),y6r=i(k9),Am=n(k9,"P",{});var qme=s(Am);x6r=r(qme,`Note:
Loading a model from its configuration file does `),j0e=n(qme,"STRONG",{});var $ta=s(j0e);$6r=r($ta,"not"),$ta.forEach(t),k6r=r(qme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Lee=n(qme,"A",{href:!0});var kta=s(Lee);S6r=r(kta,"from_pretrained()"),kta.forEach(t),R6r=r(qme," to load the model weights."),qme.forEach(t),P6r=i(k9),T(NC.$$.fragment,k9),k9.forEach(t),B6r=i(Kl),uo=n(Kl,"DIV",{class:!0});var Oa=s(uo);T(iS.$$.fragment,Oa),I6r=i(Oa),G0e=n(Oa,"P",{});var Sta=s(G0e);N6r=r(Sta,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Sta.forEach(t),q6r=i(Oa),Tn=n(Oa,"P",{});var S9=s(Tn);D6r=r(S9,"The model class to instantiate is selected based on the "),O0e=n(S9,"CODE",{});var Rta=s(O0e);j6r=r(Rta,"model_type"),Rta.forEach(t),G6r=r(S9,` property of the config object (either
passed as an argument or loaded from `),V0e=n(S9,"CODE",{});var Pta=s(V0e);O6r=r(Pta,"pretrained_model_name_or_path"),Pta.forEach(t),V6r=r(S9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X0e=n(S9,"CODE",{});var Bta=s(X0e);X6r=r(Bta,"pretrained_model_name_or_path"),Bta.forEach(t),z6r=r(S9,":"),S9.forEach(t),Q6r=i(Oa),z0e=n(Oa,"UL",{});var Ita=s(z0e);qC=n(Ita,"LI",{});var oJe=s(qC);Q0e=n(oJe,"STRONG",{});var Nta=s(Q0e);W6r=r(Nta,"vision-encoder-decoder"),Nta.forEach(t),U6r=r(oJe," \u2014 "),yee=n(oJe,"A",{href:!0});var qta=s(yee);H6r=r(qta,"VisionEncoderDecoderModel"),qta.forEach(t),J6r=r(oJe," (Vision Encoder decoder model)"),oJe.forEach(t),Ita.forEach(t),Y6r=i(Oa),DC=n(Oa,"P",{});var rJe=s(DC);Z6r=r(rJe,"The model is set in evaluation mode by default using "),W0e=n(rJe,"CODE",{});var Dta=s(W0e);K6r=r(Dta,"model.eval()"),Dta.forEach(t),e7r=r(rJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),U0e=n(rJe,"CODE",{});var jta=s(U0e);o7r=r(jta,"model.train()"),jta.forEach(t),rJe.forEach(t),r7r=i(Oa),T(jC.$$.fragment,Oa),Oa.forEach(t),Kl.forEach(t),Fao=i(c),Lm=n(c,"H2",{class:!0});var Dso=s(Lm);GC=n(Dso,"A",{id:!0,class:!0,href:!0});var Gta=s(GC);H0e=n(Gta,"SPAN",{});var Ota=s(H0e);T(dS.$$.fragment,Ota),Ota.forEach(t),Gta.forEach(t),t7r=i(Dso),J0e=n(Dso,"SPAN",{});var Vta=s(J0e);a7r=r(Vta,"AutoModelForVisualQuestionAnswering"),Vta.forEach(t),Dso.forEach(t),Tao=i(c),Zo=n(c,"DIV",{class:!0});var ei=s(Zo);T(mS.$$.fragment,ei),n7r=i(ei),ym=n(ei,"P",{});var Dme=s(ym);s7r=r(Dme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),xee=n(Dme,"A",{href:!0});var Xta=s(xee);l7r=r(Xta,"from_pretrained()"),Xta.forEach(t),i7r=r(Dme," class method or the "),$ee=n(Dme,"A",{href:!0});var zta=s($ee);d7r=r(zta,"from_config()"),zta.forEach(t),m7r=r(Dme,` class
method.`),Dme.forEach(t),c7r=i(ei),cS=n(ei,"P",{});var jso=s(cS);f7r=r(jso,"This class cannot be instantiated directly using "),Y0e=n(jso,"CODE",{});var Qta=s(Y0e);g7r=r(Qta,"__init__()"),Qta.forEach(t),h7r=r(jso," (throws an error)."),jso.forEach(t),u7r=i(ei),Dt=n(ei,"DIV",{class:!0});var R9=s(Dt);T(fS.$$.fragment,R9),p7r=i(R9),Z0e=n(R9,"P",{});var Wta=s(Z0e);_7r=r(Wta,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),Wta.forEach(t),b7r=i(R9),xm=n(R9,"P",{});var jme=s(xm);v7r=r(jme,`Note:
Loading a model from its configuration file does `),K0e=n(jme,"STRONG",{});var Uta=s(K0e);F7r=r(Uta,"not"),Uta.forEach(t),T7r=r(jme,` load the model weights. It only affects the
model\u2019s configuration. Use `),kee=n(jme,"A",{href:!0});var Hta=s(kee);M7r=r(Hta,"from_pretrained()"),Hta.forEach(t),E7r=r(jme," to load the model weights."),jme.forEach(t),C7r=i(R9),T(OC.$$.fragment,R9),R9.forEach(t),w7r=i(ei),po=n(ei,"DIV",{class:!0});var Va=s(po);T(gS.$$.fragment,Va),A7r=i(Va),ewe=n(Va,"P",{});var Jta=s(ewe);L7r=r(Jta,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),Jta.forEach(t),y7r=i(Va),Mn=n(Va,"P",{});var P9=s(Mn);x7r=r(P9,"The model class to instantiate is selected based on the "),owe=n(P9,"CODE",{});var Yta=s(owe);$7r=r(Yta,"model_type"),Yta.forEach(t),k7r=r(P9,` property of the config object (either
passed as an argument or loaded from `),rwe=n(P9,"CODE",{});var Zta=s(rwe);S7r=r(Zta,"pretrained_model_name_or_path"),Zta.forEach(t),R7r=r(P9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),twe=n(P9,"CODE",{});var Kta=s(twe);P7r=r(Kta,"pretrained_model_name_or_path"),Kta.forEach(t),B7r=r(P9,":"),P9.forEach(t),I7r=i(Va),awe=n(Va,"UL",{});var eaa=s(awe);VC=n(eaa,"LI",{});var tJe=s(VC);nwe=n(tJe,"STRONG",{});var oaa=s(nwe);N7r=r(oaa,"vilt"),oaa.forEach(t),q7r=r(tJe," \u2014 "),See=n(tJe,"A",{href:!0});var raa=s(See);D7r=r(raa,"ViltForQuestionAnswering"),raa.forEach(t),j7r=r(tJe," (ViLT model)"),tJe.forEach(t),eaa.forEach(t),G7r=i(Va),XC=n(Va,"P",{});var aJe=s(XC);O7r=r(aJe,"The model is set in evaluation mode by default using "),swe=n(aJe,"CODE",{});var taa=s(swe);V7r=r(taa,"model.eval()"),taa.forEach(t),X7r=r(aJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lwe=n(aJe,"CODE",{});var aaa=s(lwe);z7r=r(aaa,"model.train()"),aaa.forEach(t),aJe.forEach(t),Q7r=i(Va),T(zC.$$.fragment,Va),Va.forEach(t),ei.forEach(t),Mao=i(c),$m=n(c,"H2",{class:!0});var Gso=s($m);QC=n(Gso,"A",{id:!0,class:!0,href:!0});var naa=s(QC);iwe=n(naa,"SPAN",{});var saa=s(iwe);T(hS.$$.fragment,saa),saa.forEach(t),naa.forEach(t),W7r=i(Gso),dwe=n(Gso,"SPAN",{});var laa=s(dwe);U7r=r(laa,"AutoModelForAudioClassification"),laa.forEach(t),Gso.forEach(t),Eao=i(c),Ko=n(c,"DIV",{class:!0});var oi=s(Ko);T(uS.$$.fragment,oi),H7r=i(oi),km=n(oi,"P",{});var Gme=s(km);J7r=r(Gme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),Ree=n(Gme,"A",{href:!0});var iaa=s(Ree);Y7r=r(iaa,"from_pretrained()"),iaa.forEach(t),Z7r=r(Gme," class method or the "),Pee=n(Gme,"A",{href:!0});var daa=s(Pee);K7r=r(daa,"from_config()"),daa.forEach(t),e8r=r(Gme,` class
method.`),Gme.forEach(t),o8r=i(oi),pS=n(oi,"P",{});var Oso=s(pS);r8r=r(Oso,"This class cannot be instantiated directly using "),mwe=n(Oso,"CODE",{});var maa=s(mwe);t8r=r(maa,"__init__()"),maa.forEach(t),a8r=r(Oso," (throws an error)."),Oso.forEach(t),n8r=i(oi),jt=n(oi,"DIV",{class:!0});var B9=s(jt);T(_S.$$.fragment,B9),s8r=i(B9),cwe=n(B9,"P",{});var caa=s(cwe);l8r=r(caa,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),caa.forEach(t),i8r=i(B9),Sm=n(B9,"P",{});var Ome=s(Sm);d8r=r(Ome,`Note:
Loading a model from its configuration file does `),fwe=n(Ome,"STRONG",{});var faa=s(fwe);m8r=r(faa,"not"),faa.forEach(t),c8r=r(Ome,` load the model weights. It only affects the
model\u2019s configuration. Use `),Bee=n(Ome,"A",{href:!0});var gaa=s(Bee);f8r=r(gaa,"from_pretrained()"),gaa.forEach(t),g8r=r(Ome," to load the model weights."),Ome.forEach(t),h8r=i(B9),T(WC.$$.fragment,B9),B9.forEach(t),u8r=i(oi),_o=n(oi,"DIV",{class:!0});var Xa=s(_o);T(bS.$$.fragment,Xa),p8r=i(Xa),gwe=n(Xa,"P",{});var haa=s(gwe);_8r=r(haa,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),haa.forEach(t),b8r=i(Xa),En=n(Xa,"P",{});var I9=s(En);v8r=r(I9,"The model class to instantiate is selected based on the "),hwe=n(I9,"CODE",{});var uaa=s(hwe);F8r=r(uaa,"model_type"),uaa.forEach(t),T8r=r(I9,` property of the config object (either
passed as an argument or loaded from `),uwe=n(I9,"CODE",{});var paa=s(uwe);M8r=r(paa,"pretrained_model_name_or_path"),paa.forEach(t),E8r=r(I9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pwe=n(I9,"CODE",{});var _aa=s(pwe);C8r=r(_aa,"pretrained_model_name_or_path"),_aa.forEach(t),w8r=r(I9,":"),I9.forEach(t),A8r=i(Xa),Be=n(Xa,"UL",{});var We=s(Be);UC=n(We,"LI",{});var nJe=s(UC);_we=n(nJe,"STRONG",{});var baa=s(_we);L8r=r(baa,"data2vec-audio"),baa.forEach(t),y8r=r(nJe," \u2014 "),Iee=n(nJe,"A",{href:!0});var vaa=s(Iee);x8r=r(vaa,"Data2VecAudioForSequenceClassification"),vaa.forEach(t),$8r=r(nJe," (Data2VecAudio model)"),nJe.forEach(t),k8r=i(We),HC=n(We,"LI",{});var sJe=s(HC);bwe=n(sJe,"STRONG",{});var Faa=s(bwe);S8r=r(Faa,"hubert"),Faa.forEach(t),R8r=r(sJe," \u2014 "),Nee=n(sJe,"A",{href:!0});var Taa=s(Nee);P8r=r(Taa,"HubertForSequenceClassification"),Taa.forEach(t),B8r=r(sJe," (Hubert model)"),sJe.forEach(t),I8r=i(We),JC=n(We,"LI",{});var lJe=s(JC);vwe=n(lJe,"STRONG",{});var Maa=s(vwe);N8r=r(Maa,"sew"),Maa.forEach(t),q8r=r(lJe," \u2014 "),qee=n(lJe,"A",{href:!0});var Eaa=s(qee);D8r=r(Eaa,"SEWForSequenceClassification"),Eaa.forEach(t),j8r=r(lJe," (SEW model)"),lJe.forEach(t),G8r=i(We),YC=n(We,"LI",{});var iJe=s(YC);Fwe=n(iJe,"STRONG",{});var Caa=s(Fwe);O8r=r(Caa,"sew-d"),Caa.forEach(t),V8r=r(iJe," \u2014 "),Dee=n(iJe,"A",{href:!0});var waa=s(Dee);X8r=r(waa,"SEWDForSequenceClassification"),waa.forEach(t),z8r=r(iJe," (SEW-D model)"),iJe.forEach(t),Q8r=i(We),ZC=n(We,"LI",{});var dJe=s(ZC);Twe=n(dJe,"STRONG",{});var Aaa=s(Twe);W8r=r(Aaa,"unispeech"),Aaa.forEach(t),U8r=r(dJe," \u2014 "),jee=n(dJe,"A",{href:!0});var Laa=s(jee);H8r=r(Laa,"UniSpeechForSequenceClassification"),Laa.forEach(t),J8r=r(dJe," (UniSpeech model)"),dJe.forEach(t),Y8r=i(We),KC=n(We,"LI",{});var mJe=s(KC);Mwe=n(mJe,"STRONG",{});var yaa=s(Mwe);Z8r=r(yaa,"unispeech-sat"),yaa.forEach(t),K8r=r(mJe," \u2014 "),Gee=n(mJe,"A",{href:!0});var xaa=s(Gee);eLr=r(xaa,"UniSpeechSatForSequenceClassification"),xaa.forEach(t),oLr=r(mJe," (UniSpeechSat model)"),mJe.forEach(t),rLr=i(We),e3=n(We,"LI",{});var cJe=s(e3);Ewe=n(cJe,"STRONG",{});var $aa=s(Ewe);tLr=r($aa,"wav2vec2"),$aa.forEach(t),aLr=r(cJe," \u2014 "),Oee=n(cJe,"A",{href:!0});var kaa=s(Oee);nLr=r(kaa,"Wav2Vec2ForSequenceClassification"),kaa.forEach(t),sLr=r(cJe," (Wav2Vec2 model)"),cJe.forEach(t),lLr=i(We),o3=n(We,"LI",{});var fJe=s(o3);Cwe=n(fJe,"STRONG",{});var Saa=s(Cwe);iLr=r(Saa,"wav2vec2-conformer"),Saa.forEach(t),dLr=r(fJe," \u2014 "),Vee=n(fJe,"A",{href:!0});var Raa=s(Vee);mLr=r(Raa,"Wav2Vec2ConformerForSequenceClassification"),Raa.forEach(t),cLr=r(fJe," (Wav2Vec2-Conformer model)"),fJe.forEach(t),fLr=i(We),r3=n(We,"LI",{});var gJe=s(r3);wwe=n(gJe,"STRONG",{});var Paa=s(wwe);gLr=r(Paa,"wavlm"),Paa.forEach(t),hLr=r(gJe," \u2014 "),Xee=n(gJe,"A",{href:!0});var Baa=s(Xee);uLr=r(Baa,"WavLMForSequenceClassification"),Baa.forEach(t),pLr=r(gJe," (WavLM model)"),gJe.forEach(t),We.forEach(t),_Lr=i(Xa),t3=n(Xa,"P",{});var hJe=s(t3);bLr=r(hJe,"The model is set in evaluation mode by default using "),Awe=n(hJe,"CODE",{});var Iaa=s(Awe);vLr=r(Iaa,"model.eval()"),Iaa.forEach(t),FLr=r(hJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Lwe=n(hJe,"CODE",{});var Naa=s(Lwe);TLr=r(Naa,"model.train()"),Naa.forEach(t),hJe.forEach(t),MLr=i(Xa),T(a3.$$.fragment,Xa),Xa.forEach(t),oi.forEach(t),Cao=i(c),Rm=n(c,"H2",{class:!0});var Vso=s(Rm);n3=n(Vso,"A",{id:!0,class:!0,href:!0});var qaa=s(n3);ywe=n(qaa,"SPAN",{});var Daa=s(ywe);T(vS.$$.fragment,Daa),Daa.forEach(t),qaa.forEach(t),ELr=i(Vso),xwe=n(Vso,"SPAN",{});var jaa=s(xwe);CLr=r(jaa,"AutoModelForAudioFrameClassification"),jaa.forEach(t),Vso.forEach(t),wao=i(c),er=n(c,"DIV",{class:!0});var ri=s(er);T(FS.$$.fragment,ri),wLr=i(ri),Pm=n(ri,"P",{});var Vme=s(Pm);ALr=r(Vme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),zee=n(Vme,"A",{href:!0});var Gaa=s(zee);LLr=r(Gaa,"from_pretrained()"),Gaa.forEach(t),yLr=r(Vme," class method or the "),Qee=n(Vme,"A",{href:!0});var Oaa=s(Qee);xLr=r(Oaa,"from_config()"),Oaa.forEach(t),$Lr=r(Vme,` class
method.`),Vme.forEach(t),kLr=i(ri),TS=n(ri,"P",{});var Xso=s(TS);SLr=r(Xso,"This class cannot be instantiated directly using "),$we=n(Xso,"CODE",{});var Vaa=s($we);RLr=r(Vaa,"__init__()"),Vaa.forEach(t),PLr=r(Xso," (throws an error)."),Xso.forEach(t),BLr=i(ri),Gt=n(ri,"DIV",{class:!0});var N9=s(Gt);T(MS.$$.fragment,N9),ILr=i(N9),kwe=n(N9,"P",{});var Xaa=s(kwe);NLr=r(Xaa,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),Xaa.forEach(t),qLr=i(N9),Bm=n(N9,"P",{});var Xme=s(Bm);DLr=r(Xme,`Note:
Loading a model from its configuration file does `),Swe=n(Xme,"STRONG",{});var zaa=s(Swe);jLr=r(zaa,"not"),zaa.forEach(t),GLr=r(Xme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Wee=n(Xme,"A",{href:!0});var Qaa=s(Wee);OLr=r(Qaa,"from_pretrained()"),Qaa.forEach(t),VLr=r(Xme," to load the model weights."),Xme.forEach(t),XLr=i(N9),T(s3.$$.fragment,N9),N9.forEach(t),zLr=i(ri),bo=n(ri,"DIV",{class:!0});var za=s(bo);T(ES.$$.fragment,za),QLr=i(za),Rwe=n(za,"P",{});var Waa=s(Rwe);WLr=r(Waa,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),Waa.forEach(t),ULr=i(za),Cn=n(za,"P",{});var q9=s(Cn);HLr=r(q9,"The model class to instantiate is selected based on the "),Pwe=n(q9,"CODE",{});var Uaa=s(Pwe);JLr=r(Uaa,"model_type"),Uaa.forEach(t),YLr=r(q9,` property of the config object (either
passed as an argument or loaded from `),Bwe=n(q9,"CODE",{});var Haa=s(Bwe);ZLr=r(Haa,"pretrained_model_name_or_path"),Haa.forEach(t),KLr=r(q9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Iwe=n(q9,"CODE",{});var Jaa=s(Iwe);eyr=r(Jaa,"pretrained_model_name_or_path"),Jaa.forEach(t),oyr=r(q9,":"),q9.forEach(t),ryr=i(za),ut=n(za,"UL",{});var ti=s(ut);l3=n(ti,"LI",{});var uJe=s(l3);Nwe=n(uJe,"STRONG",{});var Yaa=s(Nwe);tyr=r(Yaa,"data2vec-audio"),Yaa.forEach(t),ayr=r(uJe," \u2014 "),Uee=n(uJe,"A",{href:!0});var Zaa=s(Uee);nyr=r(Zaa,"Data2VecAudioForAudioFrameClassification"),Zaa.forEach(t),syr=r(uJe," (Data2VecAudio model)"),uJe.forEach(t),lyr=i(ti),i3=n(ti,"LI",{});var pJe=s(i3);qwe=n(pJe,"STRONG",{});var Kaa=s(qwe);iyr=r(Kaa,"unispeech-sat"),Kaa.forEach(t),dyr=r(pJe," \u2014 "),Hee=n(pJe,"A",{href:!0});var ena=s(Hee);myr=r(ena,"UniSpeechSatForAudioFrameClassification"),ena.forEach(t),cyr=r(pJe," (UniSpeechSat model)"),pJe.forEach(t),fyr=i(ti),d3=n(ti,"LI",{});var _Je=s(d3);Dwe=n(_Je,"STRONG",{});var ona=s(Dwe);gyr=r(ona,"wav2vec2"),ona.forEach(t),hyr=r(_Je," \u2014 "),Jee=n(_Je,"A",{href:!0});var rna=s(Jee);uyr=r(rna,"Wav2Vec2ForAudioFrameClassification"),rna.forEach(t),pyr=r(_Je," (Wav2Vec2 model)"),_Je.forEach(t),_yr=i(ti),m3=n(ti,"LI",{});var bJe=s(m3);jwe=n(bJe,"STRONG",{});var tna=s(jwe);byr=r(tna,"wav2vec2-conformer"),tna.forEach(t),vyr=r(bJe," \u2014 "),Yee=n(bJe,"A",{href:!0});var ana=s(Yee);Fyr=r(ana,"Wav2Vec2ConformerForAudioFrameClassification"),ana.forEach(t),Tyr=r(bJe," (Wav2Vec2-Conformer model)"),bJe.forEach(t),Myr=i(ti),c3=n(ti,"LI",{});var vJe=s(c3);Gwe=n(vJe,"STRONG",{});var nna=s(Gwe);Eyr=r(nna,"wavlm"),nna.forEach(t),Cyr=r(vJe," \u2014 "),Zee=n(vJe,"A",{href:!0});var sna=s(Zee);wyr=r(sna,"WavLMForAudioFrameClassification"),sna.forEach(t),Ayr=r(vJe," (WavLM model)"),vJe.forEach(t),ti.forEach(t),Lyr=i(za),f3=n(za,"P",{});var FJe=s(f3);yyr=r(FJe,"The model is set in evaluation mode by default using "),Owe=n(FJe,"CODE",{});var lna=s(Owe);xyr=r(lna,"model.eval()"),lna.forEach(t),$yr=r(FJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Vwe=n(FJe,"CODE",{});var ina=s(Vwe);kyr=r(ina,"model.train()"),ina.forEach(t),FJe.forEach(t),Syr=i(za),T(g3.$$.fragment,za),za.forEach(t),ri.forEach(t),Aao=i(c),Im=n(c,"H2",{class:!0});var zso=s(Im);h3=n(zso,"A",{id:!0,class:!0,href:!0});var dna=s(h3);Xwe=n(dna,"SPAN",{});var mna=s(Xwe);T(CS.$$.fragment,mna),mna.forEach(t),dna.forEach(t),Ryr=i(zso),zwe=n(zso,"SPAN",{});var cna=s(zwe);Pyr=r(cna,"AutoModelForCTC"),cna.forEach(t),zso.forEach(t),Lao=i(c),or=n(c,"DIV",{class:!0});var ai=s(or);T(wS.$$.fragment,ai),Byr=i(ai),Nm=n(ai,"P",{});var zme=s(Nm);Iyr=r(zme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),Kee=n(zme,"A",{href:!0});var fna=s(Kee);Nyr=r(fna,"from_pretrained()"),fna.forEach(t),qyr=r(zme," class method or the "),eoe=n(zme,"A",{href:!0});var gna=s(eoe);Dyr=r(gna,"from_config()"),gna.forEach(t),jyr=r(zme,` class
method.`),zme.forEach(t),Gyr=i(ai),AS=n(ai,"P",{});var Qso=s(AS);Oyr=r(Qso,"This class cannot be instantiated directly using "),Qwe=n(Qso,"CODE",{});var hna=s(Qwe);Vyr=r(hna,"__init__()"),hna.forEach(t),Xyr=r(Qso," (throws an error)."),Qso.forEach(t),zyr=i(ai),Ot=n(ai,"DIV",{class:!0});var D9=s(Ot);T(LS.$$.fragment,D9),Qyr=i(D9),Wwe=n(D9,"P",{});var una=s(Wwe);Wyr=r(una,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),una.forEach(t),Uyr=i(D9),qm=n(D9,"P",{});var Qme=s(qm);Hyr=r(Qme,`Note:
Loading a model from its configuration file does `),Uwe=n(Qme,"STRONG",{});var pna=s(Uwe);Jyr=r(pna,"not"),pna.forEach(t),Yyr=r(Qme,` load the model weights. It only affects the
model\u2019s configuration. Use `),ooe=n(Qme,"A",{href:!0});var _na=s(ooe);Zyr=r(_na,"from_pretrained()"),_na.forEach(t),Kyr=r(Qme," to load the model weights."),Qme.forEach(t),e9r=i(D9),T(u3.$$.fragment,D9),D9.forEach(t),o9r=i(ai),vo=n(ai,"DIV",{class:!0});var Qa=s(vo);T(yS.$$.fragment,Qa),r9r=i(Qa),Hwe=n(Qa,"P",{});var bna=s(Hwe);t9r=r(bna,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),bna.forEach(t),a9r=i(Qa),wn=n(Qa,"P",{});var j9=s(wn);n9r=r(j9,"The model class to instantiate is selected based on the "),Jwe=n(j9,"CODE",{});var vna=s(Jwe);s9r=r(vna,"model_type"),vna.forEach(t),l9r=r(j9,` property of the config object (either
passed as an argument or loaded from `),Ywe=n(j9,"CODE",{});var Fna=s(Ywe);i9r=r(Fna,"pretrained_model_name_or_path"),Fna.forEach(t),d9r=r(j9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zwe=n(j9,"CODE",{});var Tna=s(Zwe);m9r=r(Tna,"pretrained_model_name_or_path"),Tna.forEach(t),c9r=r(j9,":"),j9.forEach(t),f9r=i(Qa),Le=n(Qa,"UL",{});var Ie=s(Le);p3=n(Ie,"LI",{});var TJe=s(p3);Kwe=n(TJe,"STRONG",{});var Mna=s(Kwe);g9r=r(Mna,"data2vec-audio"),Mna.forEach(t),h9r=r(TJe," \u2014 "),roe=n(TJe,"A",{href:!0});var Ena=s(roe);u9r=r(Ena,"Data2VecAudioForCTC"),Ena.forEach(t),p9r=r(TJe," (Data2VecAudio model)"),TJe.forEach(t),_9r=i(Ie),_3=n(Ie,"LI",{});var MJe=s(_3);eAe=n(MJe,"STRONG",{});var Cna=s(eAe);b9r=r(Cna,"hubert"),Cna.forEach(t),v9r=r(MJe," \u2014 "),toe=n(MJe,"A",{href:!0});var wna=s(toe);F9r=r(wna,"HubertForCTC"),wna.forEach(t),T9r=r(MJe," (Hubert model)"),MJe.forEach(t),M9r=i(Ie),b3=n(Ie,"LI",{});var EJe=s(b3);oAe=n(EJe,"STRONG",{});var Ana=s(oAe);E9r=r(Ana,"mctct"),Ana.forEach(t),C9r=r(EJe," \u2014 "),aoe=n(EJe,"A",{href:!0});var Lna=s(aoe);w9r=r(Lna,"MCTCTForCTC"),Lna.forEach(t),A9r=r(EJe," (M-CTC-T model)"),EJe.forEach(t),L9r=i(Ie),v3=n(Ie,"LI",{});var CJe=s(v3);rAe=n(CJe,"STRONG",{});var yna=s(rAe);y9r=r(yna,"sew"),yna.forEach(t),x9r=r(CJe," \u2014 "),noe=n(CJe,"A",{href:!0});var xna=s(noe);$9r=r(xna,"SEWForCTC"),xna.forEach(t),k9r=r(CJe," (SEW model)"),CJe.forEach(t),S9r=i(Ie),F3=n(Ie,"LI",{});var wJe=s(F3);tAe=n(wJe,"STRONG",{});var $na=s(tAe);R9r=r($na,"sew-d"),$na.forEach(t),P9r=r(wJe," \u2014 "),soe=n(wJe,"A",{href:!0});var kna=s(soe);B9r=r(kna,"SEWDForCTC"),kna.forEach(t),I9r=r(wJe," (SEW-D model)"),wJe.forEach(t),N9r=i(Ie),T3=n(Ie,"LI",{});var AJe=s(T3);aAe=n(AJe,"STRONG",{});var Sna=s(aAe);q9r=r(Sna,"unispeech"),Sna.forEach(t),D9r=r(AJe," \u2014 "),loe=n(AJe,"A",{href:!0});var Rna=s(loe);j9r=r(Rna,"UniSpeechForCTC"),Rna.forEach(t),G9r=r(AJe," (UniSpeech model)"),AJe.forEach(t),O9r=i(Ie),M3=n(Ie,"LI",{});var LJe=s(M3);nAe=n(LJe,"STRONG",{});var Pna=s(nAe);V9r=r(Pna,"unispeech-sat"),Pna.forEach(t),X9r=r(LJe," \u2014 "),ioe=n(LJe,"A",{href:!0});var Bna=s(ioe);z9r=r(Bna,"UniSpeechSatForCTC"),Bna.forEach(t),Q9r=r(LJe," (UniSpeechSat model)"),LJe.forEach(t),W9r=i(Ie),E3=n(Ie,"LI",{});var yJe=s(E3);sAe=n(yJe,"STRONG",{});var Ina=s(sAe);U9r=r(Ina,"wav2vec2"),Ina.forEach(t),H9r=r(yJe," \u2014 "),doe=n(yJe,"A",{href:!0});var Nna=s(doe);J9r=r(Nna,"Wav2Vec2ForCTC"),Nna.forEach(t),Y9r=r(yJe," (Wav2Vec2 model)"),yJe.forEach(t),Z9r=i(Ie),C3=n(Ie,"LI",{});var xJe=s(C3);lAe=n(xJe,"STRONG",{});var qna=s(lAe);K9r=r(qna,"wav2vec2-conformer"),qna.forEach(t),exr=r(xJe," \u2014 "),moe=n(xJe,"A",{href:!0});var Dna=s(moe);oxr=r(Dna,"Wav2Vec2ConformerForCTC"),Dna.forEach(t),rxr=r(xJe," (Wav2Vec2-Conformer model)"),xJe.forEach(t),txr=i(Ie),w3=n(Ie,"LI",{});var $Je=s(w3);iAe=n($Je,"STRONG",{});var jna=s(iAe);axr=r(jna,"wavlm"),jna.forEach(t),nxr=r($Je," \u2014 "),coe=n($Je,"A",{href:!0});var Gna=s(coe);sxr=r(Gna,"WavLMForCTC"),Gna.forEach(t),lxr=r($Je," (WavLM model)"),$Je.forEach(t),Ie.forEach(t),ixr=i(Qa),A3=n(Qa,"P",{});var kJe=s(A3);dxr=r(kJe,"The model is set in evaluation mode by default using "),dAe=n(kJe,"CODE",{});var Ona=s(dAe);mxr=r(Ona,"model.eval()"),Ona.forEach(t),cxr=r(kJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mAe=n(kJe,"CODE",{});var Vna=s(mAe);fxr=r(Vna,"model.train()"),Vna.forEach(t),kJe.forEach(t),gxr=i(Qa),T(L3.$$.fragment,Qa),Qa.forEach(t),ai.forEach(t),yao=i(c),Dm=n(c,"H2",{class:!0});var Wso=s(Dm);y3=n(Wso,"A",{id:!0,class:!0,href:!0});var Xna=s(y3);cAe=n(Xna,"SPAN",{});var zna=s(cAe);T(xS.$$.fragment,zna),zna.forEach(t),Xna.forEach(t),hxr=i(Wso),fAe=n(Wso,"SPAN",{});var Qna=s(fAe);uxr=r(Qna,"AutoModelForSpeechSeq2Seq"),Qna.forEach(t),Wso.forEach(t),xao=i(c),rr=n(c,"DIV",{class:!0});var ni=s(rr);T($S.$$.fragment,ni),pxr=i(ni),jm=n(ni,"P",{});var Wme=s(jm);_xr=r(Wme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),foe=n(Wme,"A",{href:!0});var Wna=s(foe);bxr=r(Wna,"from_pretrained()"),Wna.forEach(t),vxr=r(Wme," class method or the "),goe=n(Wme,"A",{href:!0});var Una=s(goe);Fxr=r(Una,"from_config()"),Una.forEach(t),Txr=r(Wme,` class
method.`),Wme.forEach(t),Mxr=i(ni),kS=n(ni,"P",{});var Uso=s(kS);Exr=r(Uso,"This class cannot be instantiated directly using "),gAe=n(Uso,"CODE",{});var Hna=s(gAe);Cxr=r(Hna,"__init__()"),Hna.forEach(t),wxr=r(Uso," (throws an error)."),Uso.forEach(t),Axr=i(ni),Vt=n(ni,"DIV",{class:!0});var G9=s(Vt);T(SS.$$.fragment,G9),Lxr=i(G9),hAe=n(G9,"P",{});var Jna=s(hAe);yxr=r(Jna,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Jna.forEach(t),xxr=i(G9),Gm=n(G9,"P",{});var Ume=s(Gm);$xr=r(Ume,`Note:
Loading a model from its configuration file does `),uAe=n(Ume,"STRONG",{});var Yna=s(uAe);kxr=r(Yna,"not"),Yna.forEach(t),Sxr=r(Ume,` load the model weights. It only affects the
model\u2019s configuration. Use `),hoe=n(Ume,"A",{href:!0});var Zna=s(hoe);Rxr=r(Zna,"from_pretrained()"),Zna.forEach(t),Pxr=r(Ume," to load the model weights."),Ume.forEach(t),Bxr=i(G9),T(x3.$$.fragment,G9),G9.forEach(t),Ixr=i(ni),Fo=n(ni,"DIV",{class:!0});var Wa=s(Fo);T(RS.$$.fragment,Wa),Nxr=i(Wa),pAe=n(Wa,"P",{});var Kna=s(pAe);qxr=r(Kna,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Kna.forEach(t),Dxr=i(Wa),An=n(Wa,"P",{});var O9=s(An);jxr=r(O9,"The model class to instantiate is selected based on the "),_Ae=n(O9,"CODE",{});var esa=s(_Ae);Gxr=r(esa,"model_type"),esa.forEach(t),Oxr=r(O9,` property of the config object (either
passed as an argument or loaded from `),bAe=n(O9,"CODE",{});var osa=s(bAe);Vxr=r(osa,"pretrained_model_name_or_path"),osa.forEach(t),Xxr=r(O9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vAe=n(O9,"CODE",{});var rsa=s(vAe);zxr=r(rsa,"pretrained_model_name_or_path"),rsa.forEach(t),Qxr=r(O9,":"),O9.forEach(t),Wxr=i(Wa),Om=n(Wa,"UL",{});var Hme=s(Om);$3=n(Hme,"LI",{});var SJe=s($3);FAe=n(SJe,"STRONG",{});var tsa=s(FAe);Uxr=r(tsa,"speech-encoder-decoder"),tsa.forEach(t),Hxr=r(SJe," \u2014 "),uoe=n(SJe,"A",{href:!0});var asa=s(uoe);Jxr=r(asa,"SpeechEncoderDecoderModel"),asa.forEach(t),Yxr=r(SJe," (Speech Encoder decoder model)"),SJe.forEach(t),Zxr=i(Hme),k3=n(Hme,"LI",{});var RJe=s(k3);TAe=n(RJe,"STRONG",{});var nsa=s(TAe);Kxr=r(nsa,"speech_to_text"),nsa.forEach(t),e$r=r(RJe," \u2014 "),poe=n(RJe,"A",{href:!0});var ssa=s(poe);o$r=r(ssa,"Speech2TextForConditionalGeneration"),ssa.forEach(t),r$r=r(RJe," (Speech2Text model)"),RJe.forEach(t),t$r=i(Hme),S3=n(Hme,"LI",{});var PJe=s(S3);MAe=n(PJe,"STRONG",{});var lsa=s(MAe);a$r=r(lsa,"whisper"),lsa.forEach(t),n$r=r(PJe," \u2014 "),_oe=n(PJe,"A",{href:!0});var isa=s(_oe);s$r=r(isa,"WhisperForConditionalGeneration"),isa.forEach(t),l$r=r(PJe," (Whisper model)"),PJe.forEach(t),Hme.forEach(t),i$r=i(Wa),R3=n(Wa,"P",{});var BJe=s(R3);d$r=r(BJe,"The model is set in evaluation mode by default using "),EAe=n(BJe,"CODE",{});var dsa=s(EAe);m$r=r(dsa,"model.eval()"),dsa.forEach(t),c$r=r(BJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),CAe=n(BJe,"CODE",{});var msa=s(CAe);f$r=r(msa,"model.train()"),msa.forEach(t),BJe.forEach(t),g$r=i(Wa),T(P3.$$.fragment,Wa),Wa.forEach(t),ni.forEach(t),$ao=i(c),Vm=n(c,"H2",{class:!0});var Hso=s(Vm);B3=n(Hso,"A",{id:!0,class:!0,href:!0});var csa=s(B3);wAe=n(csa,"SPAN",{});var fsa=s(wAe);T(PS.$$.fragment,fsa),fsa.forEach(t),csa.forEach(t),h$r=i(Hso),AAe=n(Hso,"SPAN",{});var gsa=s(AAe);u$r=r(gsa,"AutoModelForAudioXVector"),gsa.forEach(t),Hso.forEach(t),kao=i(c),tr=n(c,"DIV",{class:!0});var si=s(tr);T(BS.$$.fragment,si),p$r=i(si),Xm=n(si,"P",{});var Jme=s(Xm);_$r=r(Jme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),boe=n(Jme,"A",{href:!0});var hsa=s(boe);b$r=r(hsa,"from_pretrained()"),hsa.forEach(t),v$r=r(Jme," class method or the "),voe=n(Jme,"A",{href:!0});var usa=s(voe);F$r=r(usa,"from_config()"),usa.forEach(t),T$r=r(Jme,` class
method.`),Jme.forEach(t),M$r=i(si),IS=n(si,"P",{});var Jso=s(IS);E$r=r(Jso,"This class cannot be instantiated directly using "),LAe=n(Jso,"CODE",{});var psa=s(LAe);C$r=r(psa,"__init__()"),psa.forEach(t),w$r=r(Jso," (throws an error)."),Jso.forEach(t),A$r=i(si),Xt=n(si,"DIV",{class:!0});var V9=s(Xt);T(NS.$$.fragment,V9),L$r=i(V9),yAe=n(V9,"P",{});var _sa=s(yAe);y$r=r(_sa,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),_sa.forEach(t),x$r=i(V9),zm=n(V9,"P",{});var Yme=s(zm);$$r=r(Yme,`Note:
Loading a model from its configuration file does `),xAe=n(Yme,"STRONG",{});var bsa=s(xAe);k$r=r(bsa,"not"),bsa.forEach(t),S$r=r(Yme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Foe=n(Yme,"A",{href:!0});var vsa=s(Foe);R$r=r(vsa,"from_pretrained()"),vsa.forEach(t),P$r=r(Yme," to load the model weights."),Yme.forEach(t),B$r=i(V9),T(I3.$$.fragment,V9),V9.forEach(t),I$r=i(si),To=n(si,"DIV",{class:!0});var Ua=s(To);T(qS.$$.fragment,Ua),N$r=i(Ua),$Ae=n(Ua,"P",{});var Fsa=s($Ae);q$r=r(Fsa,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),Fsa.forEach(t),D$r=i(Ua),Ln=n(Ua,"P",{});var X9=s(Ln);j$r=r(X9,"The model class to instantiate is selected based on the "),kAe=n(X9,"CODE",{});var Tsa=s(kAe);G$r=r(Tsa,"model_type"),Tsa.forEach(t),O$r=r(X9,` property of the config object (either
passed as an argument or loaded from `),SAe=n(X9,"CODE",{});var Msa=s(SAe);V$r=r(Msa,"pretrained_model_name_or_path"),Msa.forEach(t),X$r=r(X9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RAe=n(X9,"CODE",{});var Esa=s(RAe);z$r=r(Esa,"pretrained_model_name_or_path"),Esa.forEach(t),Q$r=r(X9,":"),X9.forEach(t),W$r=i(Ua),pt=n(Ua,"UL",{});var li=s(pt);N3=n(li,"LI",{});var IJe=s(N3);PAe=n(IJe,"STRONG",{});var Csa=s(PAe);U$r=r(Csa,"data2vec-audio"),Csa.forEach(t),H$r=r(IJe," \u2014 "),Toe=n(IJe,"A",{href:!0});var wsa=s(Toe);J$r=r(wsa,"Data2VecAudioForXVector"),wsa.forEach(t),Y$r=r(IJe," (Data2VecAudio model)"),IJe.forEach(t),Z$r=i(li),q3=n(li,"LI",{});var NJe=s(q3);BAe=n(NJe,"STRONG",{});var Asa=s(BAe);K$r=r(Asa,"unispeech-sat"),Asa.forEach(t),ekr=r(NJe," \u2014 "),Moe=n(NJe,"A",{href:!0});var Lsa=s(Moe);okr=r(Lsa,"UniSpeechSatForXVector"),Lsa.forEach(t),rkr=r(NJe," (UniSpeechSat model)"),NJe.forEach(t),tkr=i(li),D3=n(li,"LI",{});var qJe=s(D3);IAe=n(qJe,"STRONG",{});var ysa=s(IAe);akr=r(ysa,"wav2vec2"),ysa.forEach(t),nkr=r(qJe," \u2014 "),Eoe=n(qJe,"A",{href:!0});var xsa=s(Eoe);skr=r(xsa,"Wav2Vec2ForXVector"),xsa.forEach(t),lkr=r(qJe," (Wav2Vec2 model)"),qJe.forEach(t),ikr=i(li),j3=n(li,"LI",{});var DJe=s(j3);NAe=n(DJe,"STRONG",{});var $sa=s(NAe);dkr=r($sa,"wav2vec2-conformer"),$sa.forEach(t),mkr=r(DJe," \u2014 "),Coe=n(DJe,"A",{href:!0});var ksa=s(Coe);ckr=r(ksa,"Wav2Vec2ConformerForXVector"),ksa.forEach(t),fkr=r(DJe," (Wav2Vec2-Conformer model)"),DJe.forEach(t),gkr=i(li),G3=n(li,"LI",{});var jJe=s(G3);qAe=n(jJe,"STRONG",{});var Ssa=s(qAe);hkr=r(Ssa,"wavlm"),Ssa.forEach(t),ukr=r(jJe," \u2014 "),woe=n(jJe,"A",{href:!0});var Rsa=s(woe);pkr=r(Rsa,"WavLMForXVector"),Rsa.forEach(t),_kr=r(jJe," (WavLM model)"),jJe.forEach(t),li.forEach(t),bkr=i(Ua),O3=n(Ua,"P",{});var GJe=s(O3);vkr=r(GJe,"The model is set in evaluation mode by default using "),DAe=n(GJe,"CODE",{});var Psa=s(DAe);Fkr=r(Psa,"model.eval()"),Psa.forEach(t),Tkr=r(GJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),jAe=n(GJe,"CODE",{});var Bsa=s(jAe);Mkr=r(Bsa,"model.train()"),Bsa.forEach(t),GJe.forEach(t),Ekr=i(Ua),T(V3.$$.fragment,Ua),Ua.forEach(t),si.forEach(t),Sao=i(c),Qm=n(c,"H2",{class:!0});var Yso=s(Qm);X3=n(Yso,"A",{id:!0,class:!0,href:!0});var Isa=s(X3);GAe=n(Isa,"SPAN",{});var Nsa=s(GAe);T(DS.$$.fragment,Nsa),Nsa.forEach(t),Isa.forEach(t),Ckr=i(Yso),OAe=n(Yso,"SPAN",{});var qsa=s(OAe);wkr=r(qsa,"AutoModelForMaskedImageModeling"),qsa.forEach(t),Yso.forEach(t),Rao=i(c),ar=n(c,"DIV",{class:!0});var ii=s(ar);T(jS.$$.fragment,ii),Akr=i(ii),Wm=n(ii,"P",{});var Zme=s(Wm);Lkr=r(Zme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),Aoe=n(Zme,"A",{href:!0});var Dsa=s(Aoe);ykr=r(Dsa,"from_pretrained()"),Dsa.forEach(t),xkr=r(Zme," class method or the "),Loe=n(Zme,"A",{href:!0});var jsa=s(Loe);$kr=r(jsa,"from_config()"),jsa.forEach(t),kkr=r(Zme,` class
method.`),Zme.forEach(t),Skr=i(ii),GS=n(ii,"P",{});var Zso=s(GS);Rkr=r(Zso,"This class cannot be instantiated directly using "),VAe=n(Zso,"CODE",{});var Gsa=s(VAe);Pkr=r(Gsa,"__init__()"),Gsa.forEach(t),Bkr=r(Zso," (throws an error)."),Zso.forEach(t),Ikr=i(ii),zt=n(ii,"DIV",{class:!0});var z9=s(zt);T(OS.$$.fragment,z9),Nkr=i(z9),XAe=n(z9,"P",{});var Osa=s(XAe);qkr=r(Osa,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),Osa.forEach(t),Dkr=i(z9),Um=n(z9,"P",{});var Kme=s(Um);jkr=r(Kme,`Note:
Loading a model from its configuration file does `),zAe=n(Kme,"STRONG",{});var Vsa=s(zAe);Gkr=r(Vsa,"not"),Vsa.forEach(t),Okr=r(Kme,` load the model weights. It only affects the
model\u2019s configuration. Use `),yoe=n(Kme,"A",{href:!0});var Xsa=s(yoe);Vkr=r(Xsa,"from_pretrained()"),Xsa.forEach(t),Xkr=r(Kme," to load the model weights."),Kme.forEach(t),zkr=i(z9),T(z3.$$.fragment,z9),z9.forEach(t),Qkr=i(ii),Mo=n(ii,"DIV",{class:!0});var Ha=s(Mo);T(VS.$$.fragment,Ha),Wkr=i(Ha),QAe=n(Ha,"P",{});var zsa=s(QAe);Ukr=r(zsa,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),zsa.forEach(t),Hkr=i(Ha),yn=n(Ha,"P",{});var Q9=s(yn);Jkr=r(Q9,"The model class to instantiate is selected based on the "),WAe=n(Q9,"CODE",{});var Qsa=s(WAe);Ykr=r(Qsa,"model_type"),Qsa.forEach(t),Zkr=r(Q9,` property of the config object (either
passed as an argument or loaded from `),UAe=n(Q9,"CODE",{});var Wsa=s(UAe);Kkr=r(Wsa,"pretrained_model_name_or_path"),Wsa.forEach(t),eSr=r(Q9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HAe=n(Q9,"CODE",{});var Usa=s(HAe);oSr=r(Usa,"pretrained_model_name_or_path"),Usa.forEach(t),rSr=r(Q9,":"),Q9.forEach(t),tSr=i(Ha),xn=n(Ha,"UL",{});var W9=s(xn);Q3=n(W9,"LI",{});var OJe=s(Q3);JAe=n(OJe,"STRONG",{});var Hsa=s(JAe);aSr=r(Hsa,"deit"),Hsa.forEach(t),nSr=r(OJe," \u2014 "),xoe=n(OJe,"A",{href:!0});var Jsa=s(xoe);sSr=r(Jsa,"DeiTForMaskedImageModeling"),Jsa.forEach(t),lSr=r(OJe," (DeiT model)"),OJe.forEach(t),iSr=i(W9),W3=n(W9,"LI",{});var VJe=s(W3);YAe=n(VJe,"STRONG",{});var Ysa=s(YAe);dSr=r(Ysa,"swin"),Ysa.forEach(t),mSr=r(VJe," \u2014 "),$oe=n(VJe,"A",{href:!0});var Zsa=s($oe);cSr=r(Zsa,"SwinForMaskedImageModeling"),Zsa.forEach(t),fSr=r(VJe," (Swin Transformer model)"),VJe.forEach(t),gSr=i(W9),U3=n(W9,"LI",{});var XJe=s(U3);ZAe=n(XJe,"STRONG",{});var Ksa=s(ZAe);hSr=r(Ksa,"swinv2"),Ksa.forEach(t),uSr=r(XJe," \u2014 "),koe=n(XJe,"A",{href:!0});var ela=s(koe);pSr=r(ela,"Swinv2ForMaskedImageModeling"),ela.forEach(t),_Sr=r(XJe," (Swin Transformer V2 model)"),XJe.forEach(t),bSr=i(W9),H3=n(W9,"LI",{});var zJe=s(H3);KAe=n(zJe,"STRONG",{});var ola=s(KAe);vSr=r(ola,"vit"),ola.forEach(t),FSr=r(zJe," \u2014 "),Soe=n(zJe,"A",{href:!0});var rla=s(Soe);TSr=r(rla,"ViTForMaskedImageModeling"),rla.forEach(t),MSr=r(zJe," (ViT model)"),zJe.forEach(t),W9.forEach(t),ESr=i(Ha),J3=n(Ha,"P",{});var QJe=s(J3);CSr=r(QJe,"The model is set in evaluation mode by default using "),e6e=n(QJe,"CODE",{});var tla=s(e6e);wSr=r(tla,"model.eval()"),tla.forEach(t),ASr=r(QJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o6e=n(QJe,"CODE",{});var ala=s(o6e);LSr=r(ala,"model.train()"),ala.forEach(t),QJe.forEach(t),ySr=i(Ha),T(Y3.$$.fragment,Ha),Ha.forEach(t),ii.forEach(t),Pao=i(c),Hm=n(c,"H2",{class:!0});var Kso=s(Hm);Z3=n(Kso,"A",{id:!0,class:!0,href:!0});var nla=s(Z3);r6e=n(nla,"SPAN",{});var sla=s(r6e);T(XS.$$.fragment,sla),sla.forEach(t),nla.forEach(t),xSr=i(Kso),t6e=n(Kso,"SPAN",{});var lla=s(t6e);$Sr=r(lla,"AutoModelForObjectDetection"),lla.forEach(t),Kso.forEach(t),Bao=i(c),nr=n(c,"DIV",{class:!0});var di=s(nr);T(zS.$$.fragment,di),kSr=i(di),Jm=n(di,"P",{});var ece=s(Jm);SSr=r(ece,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),Roe=n(ece,"A",{href:!0});var ila=s(Roe);RSr=r(ila,"from_pretrained()"),ila.forEach(t),PSr=r(ece," class method or the "),Poe=n(ece,"A",{href:!0});var dla=s(Poe);BSr=r(dla,"from_config()"),dla.forEach(t),ISr=r(ece,` class
method.`),ece.forEach(t),NSr=i(di),QS=n(di,"P",{});var elo=s(QS);qSr=r(elo,"This class cannot be instantiated directly using "),a6e=n(elo,"CODE",{});var mla=s(a6e);DSr=r(mla,"__init__()"),mla.forEach(t),jSr=r(elo," (throws an error)."),elo.forEach(t),GSr=i(di),Qt=n(di,"DIV",{class:!0});var U9=s(Qt);T(WS.$$.fragment,U9),OSr=i(U9),n6e=n(U9,"P",{});var cla=s(n6e);VSr=r(cla,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),cla.forEach(t),XSr=i(U9),Ym=n(U9,"P",{});var oce=s(Ym);zSr=r(oce,`Note:
Loading a model from its configuration file does `),s6e=n(oce,"STRONG",{});var fla=s(s6e);QSr=r(fla,"not"),fla.forEach(t),WSr=r(oce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Boe=n(oce,"A",{href:!0});var gla=s(Boe);USr=r(gla,"from_pretrained()"),gla.forEach(t),HSr=r(oce," to load the model weights."),oce.forEach(t),JSr=i(U9),T(K3.$$.fragment,U9),U9.forEach(t),YSr=i(di),Eo=n(di,"DIV",{class:!0});var Ja=s(Eo);T(US.$$.fragment,Ja),ZSr=i(Ja),l6e=n(Ja,"P",{});var hla=s(l6e);KSr=r(hla,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),hla.forEach(t),eRr=i(Ja),$n=n(Ja,"P",{});var H9=s($n);oRr=r(H9,"The model class to instantiate is selected based on the "),i6e=n(H9,"CODE",{});var ula=s(i6e);rRr=r(ula,"model_type"),ula.forEach(t),tRr=r(H9,` property of the config object (either
passed as an argument or loaded from `),d6e=n(H9,"CODE",{});var pla=s(d6e);aRr=r(pla,"pretrained_model_name_or_path"),pla.forEach(t),nRr=r(H9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m6e=n(H9,"CODE",{});var _la=s(m6e);sRr=r(_la,"pretrained_model_name_or_path"),_la.forEach(t),lRr=r(H9,":"),H9.forEach(t),iRr=i(Ja),_t=n(Ja,"UL",{});var mi=s(_t);e5=n(mi,"LI",{});var WJe=s(e5);c6e=n(WJe,"STRONG",{});var bla=s(c6e);dRr=r(bla,"conditional_detr"),bla.forEach(t),mRr=r(WJe," \u2014 "),Ioe=n(WJe,"A",{href:!0});var vla=s(Ioe);cRr=r(vla,"ConditionalDetrForObjectDetection"),vla.forEach(t),fRr=r(WJe," (Conditional DETR model)"),WJe.forEach(t),gRr=i(mi),o5=n(mi,"LI",{});var UJe=s(o5);f6e=n(UJe,"STRONG",{});var Fla=s(f6e);hRr=r(Fla,"deformable_detr"),Fla.forEach(t),uRr=r(UJe," \u2014 "),Noe=n(UJe,"A",{href:!0});var Tla=s(Noe);pRr=r(Tla,"DeformableDetrForObjectDetection"),Tla.forEach(t),_Rr=r(UJe," (Deformable DETR model)"),UJe.forEach(t),bRr=i(mi),r5=n(mi,"LI",{});var HJe=s(r5);g6e=n(HJe,"STRONG",{});var Mla=s(g6e);vRr=r(Mla,"detr"),Mla.forEach(t),FRr=r(HJe," \u2014 "),qoe=n(HJe,"A",{href:!0});var Ela=s(qoe);TRr=r(Ela,"DetrForObjectDetection"),Ela.forEach(t),MRr=r(HJe," (DETR model)"),HJe.forEach(t),ERr=i(mi),t5=n(mi,"LI",{});var JJe=s(t5);h6e=n(JJe,"STRONG",{});var Cla=s(h6e);CRr=r(Cla,"table-transformer"),Cla.forEach(t),wRr=r(JJe," \u2014 "),Doe=n(JJe,"A",{href:!0});var wla=s(Doe);ARr=r(wla,"TableTransformerForObjectDetection"),wla.forEach(t),LRr=r(JJe," (Table Transformer model)"),JJe.forEach(t),yRr=i(mi),a5=n(mi,"LI",{});var YJe=s(a5);u6e=n(YJe,"STRONG",{});var Ala=s(u6e);xRr=r(Ala,"yolos"),Ala.forEach(t),$Rr=r(YJe," \u2014 "),joe=n(YJe,"A",{href:!0});var Lla=s(joe);kRr=r(Lla,"YolosForObjectDetection"),Lla.forEach(t),SRr=r(YJe," (YOLOS model)"),YJe.forEach(t),mi.forEach(t),RRr=i(Ja),n5=n(Ja,"P",{});var ZJe=s(n5);PRr=r(ZJe,"The model is set in evaluation mode by default using "),p6e=n(ZJe,"CODE",{});var yla=s(p6e);BRr=r(yla,"model.eval()"),yla.forEach(t),IRr=r(ZJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_6e=n(ZJe,"CODE",{});var xla=s(_6e);NRr=r(xla,"model.train()"),xla.forEach(t),ZJe.forEach(t),qRr=i(Ja),T(s5.$$.fragment,Ja),Ja.forEach(t),di.forEach(t),Iao=i(c),Zm=n(c,"H2",{class:!0});var olo=s(Zm);l5=n(olo,"A",{id:!0,class:!0,href:!0});var $la=s(l5);b6e=n($la,"SPAN",{});var kla=s(b6e);T(HS.$$.fragment,kla),kla.forEach(t),$la.forEach(t),DRr=i(olo),v6e=n(olo,"SPAN",{});var Sla=s(v6e);jRr=r(Sla,"AutoModelForImageSegmentation"),Sla.forEach(t),olo.forEach(t),Nao=i(c),sr=n(c,"DIV",{class:!0});var ci=s(sr);T(JS.$$.fragment,ci),GRr=i(ci),Km=n(ci,"P",{});var rce=s(Km);ORr=r(rce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),Goe=n(rce,"A",{href:!0});var Rla=s(Goe);VRr=r(Rla,"from_pretrained()"),Rla.forEach(t),XRr=r(rce," class method or the "),Ooe=n(rce,"A",{href:!0});var Pla=s(Ooe);zRr=r(Pla,"from_config()"),Pla.forEach(t),QRr=r(rce,` class
method.`),rce.forEach(t),WRr=i(ci),YS=n(ci,"P",{});var rlo=s(YS);URr=r(rlo,"This class cannot be instantiated directly using "),F6e=n(rlo,"CODE",{});var Bla=s(F6e);HRr=r(Bla,"__init__()"),Bla.forEach(t),JRr=r(rlo," (throws an error)."),rlo.forEach(t),YRr=i(ci),Wt=n(ci,"DIV",{class:!0});var J9=s(Wt);T(ZS.$$.fragment,J9),ZRr=i(J9),T6e=n(J9,"P",{});var Ila=s(T6e);KRr=r(Ila,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),Ila.forEach(t),ePr=i(J9),ec=n(J9,"P",{});var tce=s(ec);oPr=r(tce,`Note:
Loading a model from its configuration file does `),M6e=n(tce,"STRONG",{});var Nla=s(M6e);rPr=r(Nla,"not"),Nla.forEach(t),tPr=r(tce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Voe=n(tce,"A",{href:!0});var qla=s(Voe);aPr=r(qla,"from_pretrained()"),qla.forEach(t),nPr=r(tce," to load the model weights."),tce.forEach(t),sPr=i(J9),T(i5.$$.fragment,J9),J9.forEach(t),lPr=i(ci),Co=n(ci,"DIV",{class:!0});var Ya=s(Co);T(KS.$$.fragment,Ya),iPr=i(Ya),E6e=n(Ya,"P",{});var Dla=s(E6e);dPr=r(Dla,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),Dla.forEach(t),mPr=i(Ya),kn=n(Ya,"P",{});var Y9=s(kn);cPr=r(Y9,"The model class to instantiate is selected based on the "),C6e=n(Y9,"CODE",{});var jla=s(C6e);fPr=r(jla,"model_type"),jla.forEach(t),gPr=r(Y9,` property of the config object (either
passed as an argument or loaded from `),w6e=n(Y9,"CODE",{});var Gla=s(w6e);hPr=r(Gla,"pretrained_model_name_or_path"),Gla.forEach(t),uPr=r(Y9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A6e=n(Y9,"CODE",{});var Ola=s(A6e);pPr=r(Ola,"pretrained_model_name_or_path"),Ola.forEach(t),_Pr=r(Y9,":"),Y9.forEach(t),bPr=i(Ya),L6e=n(Ya,"UL",{});var Vla=s(L6e);d5=n(Vla,"LI",{});var KJe=s(d5);y6e=n(KJe,"STRONG",{});var Xla=s(y6e);vPr=r(Xla,"detr"),Xla.forEach(t),FPr=r(KJe," \u2014 "),Xoe=n(KJe,"A",{href:!0});var zla=s(Xoe);TPr=r(zla,"DetrForSegmentation"),zla.forEach(t),MPr=r(KJe," (DETR model)"),KJe.forEach(t),Vla.forEach(t),EPr=i(Ya),m5=n(Ya,"P",{});var eYe=s(m5);CPr=r(eYe,"The model is set in evaluation mode by default using "),x6e=n(eYe,"CODE",{});var Qla=s(x6e);wPr=r(Qla,"model.eval()"),Qla.forEach(t),APr=r(eYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$6e=n(eYe,"CODE",{});var Wla=s($6e);LPr=r(Wla,"model.train()"),Wla.forEach(t),eYe.forEach(t),yPr=i(Ya),T(c5.$$.fragment,Ya),Ya.forEach(t),ci.forEach(t),qao=i(c),oc=n(c,"H2",{class:!0});var tlo=s(oc);f5=n(tlo,"A",{id:!0,class:!0,href:!0});var Ula=s(f5);k6e=n(Ula,"SPAN",{});var Hla=s(k6e);T(eR.$$.fragment,Hla),Hla.forEach(t),Ula.forEach(t),xPr=i(tlo),S6e=n(tlo,"SPAN",{});var Jla=s(S6e);$Pr=r(Jla,"AutoModelForSemanticSegmentation"),Jla.forEach(t),tlo.forEach(t),Dao=i(c),lr=n(c,"DIV",{class:!0});var fi=s(lr);T(oR.$$.fragment,fi),kPr=i(fi),rc=n(fi,"P",{});var ace=s(rc);SPr=r(ace,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),zoe=n(ace,"A",{href:!0});var Yla=s(zoe);RPr=r(Yla,"from_pretrained()"),Yla.forEach(t),PPr=r(ace," class method or the "),Qoe=n(ace,"A",{href:!0});var Zla=s(Qoe);BPr=r(Zla,"from_config()"),Zla.forEach(t),IPr=r(ace,` class
method.`),ace.forEach(t),NPr=i(fi),rR=n(fi,"P",{});var alo=s(rR);qPr=r(alo,"This class cannot be instantiated directly using "),R6e=n(alo,"CODE",{});var Kla=s(R6e);DPr=r(Kla,"__init__()"),Kla.forEach(t),jPr=r(alo," (throws an error)."),alo.forEach(t),GPr=i(fi),Ut=n(fi,"DIV",{class:!0});var Z9=s(Ut);T(tR.$$.fragment,Z9),OPr=i(Z9),P6e=n(Z9,"P",{});var eia=s(P6e);VPr=r(eia,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),eia.forEach(t),XPr=i(Z9),tc=n(Z9,"P",{});var nce=s(tc);zPr=r(nce,`Note:
Loading a model from its configuration file does `),B6e=n(nce,"STRONG",{});var oia=s(B6e);QPr=r(oia,"not"),oia.forEach(t),WPr=r(nce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Woe=n(nce,"A",{href:!0});var ria=s(Woe);UPr=r(ria,"from_pretrained()"),ria.forEach(t),HPr=r(nce," to load the model weights."),nce.forEach(t),JPr=i(Z9),T(g5.$$.fragment,Z9),Z9.forEach(t),YPr=i(fi),wo=n(fi,"DIV",{class:!0});var Za=s(wo);T(aR.$$.fragment,Za),ZPr=i(Za),I6e=n(Za,"P",{});var tia=s(I6e);KPr=r(tia,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),tia.forEach(t),eBr=i(Za),Sn=n(Za,"P",{});var K9=s(Sn);oBr=r(K9,"The model class to instantiate is selected based on the "),N6e=n(K9,"CODE",{});var aia=s(N6e);rBr=r(aia,"model_type"),aia.forEach(t),tBr=r(K9,` property of the config object (either
passed as an argument or loaded from `),q6e=n(K9,"CODE",{});var nia=s(q6e);aBr=r(nia,"pretrained_model_name_or_path"),nia.forEach(t),nBr=r(K9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D6e=n(K9,"CODE",{});var sia=s(D6e);sBr=r(sia,"pretrained_model_name_or_path"),sia.forEach(t),lBr=r(K9,":"),K9.forEach(t),iBr=i(Za),bt=n(Za,"UL",{});var gi=s(bt);h5=n(gi,"LI",{});var oYe=s(h5);j6e=n(oYe,"STRONG",{});var lia=s(j6e);dBr=r(lia,"beit"),lia.forEach(t),mBr=r(oYe," \u2014 "),Uoe=n(oYe,"A",{href:!0});var iia=s(Uoe);cBr=r(iia,"BeitForSemanticSegmentation"),iia.forEach(t),fBr=r(oYe," (BEiT model)"),oYe.forEach(t),gBr=i(gi),u5=n(gi,"LI",{});var rYe=s(u5);G6e=n(rYe,"STRONG",{});var dia=s(G6e);hBr=r(dia,"data2vec-vision"),dia.forEach(t),uBr=r(rYe," \u2014 "),Hoe=n(rYe,"A",{href:!0});var mia=s(Hoe);pBr=r(mia,"Data2VecVisionForSemanticSegmentation"),mia.forEach(t),_Br=r(rYe," (Data2VecVision model)"),rYe.forEach(t),bBr=i(gi),p5=n(gi,"LI",{});var tYe=s(p5);O6e=n(tYe,"STRONG",{});var cia=s(O6e);vBr=r(cia,"dpt"),cia.forEach(t),FBr=r(tYe," \u2014 "),Joe=n(tYe,"A",{href:!0});var fia=s(Joe);TBr=r(fia,"DPTForSemanticSegmentation"),fia.forEach(t),MBr=r(tYe," (DPT model)"),tYe.forEach(t),EBr=i(gi),_5=n(gi,"LI",{});var aYe=s(_5);V6e=n(aYe,"STRONG",{});var gia=s(V6e);CBr=r(gia,"mobilevit"),gia.forEach(t),wBr=r(aYe," \u2014 "),Yoe=n(aYe,"A",{href:!0});var hia=s(Yoe);ABr=r(hia,"MobileViTForSemanticSegmentation"),hia.forEach(t),LBr=r(aYe," (MobileViT model)"),aYe.forEach(t),yBr=i(gi),b5=n(gi,"LI",{});var nYe=s(b5);X6e=n(nYe,"STRONG",{});var uia=s(X6e);xBr=r(uia,"segformer"),uia.forEach(t),$Br=r(nYe," \u2014 "),Zoe=n(nYe,"A",{href:!0});var pia=s(Zoe);kBr=r(pia,"SegformerForSemanticSegmentation"),pia.forEach(t),SBr=r(nYe," (SegFormer model)"),nYe.forEach(t),gi.forEach(t),RBr=i(Za),v5=n(Za,"P",{});var sYe=s(v5);PBr=r(sYe,"The model is set in evaluation mode by default using "),z6e=n(sYe,"CODE",{});var _ia=s(z6e);BBr=r(_ia,"model.eval()"),_ia.forEach(t),IBr=r(sYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Q6e=n(sYe,"CODE",{});var bia=s(Q6e);NBr=r(bia,"model.train()"),bia.forEach(t),sYe.forEach(t),qBr=i(Za),T(F5.$$.fragment,Za),Za.forEach(t),fi.forEach(t),jao=i(c),ac=n(c,"H2",{class:!0});var nlo=s(ac);T5=n(nlo,"A",{id:!0,class:!0,href:!0});var via=s(T5);W6e=n(via,"SPAN",{});var Fia=s(W6e);T(nR.$$.fragment,Fia),Fia.forEach(t),via.forEach(t),DBr=i(nlo),U6e=n(nlo,"SPAN",{});var Tia=s(U6e);jBr=r(Tia,"AutoModelForInstanceSegmentation"),Tia.forEach(t),nlo.forEach(t),Gao=i(c),ir=n(c,"DIV",{class:!0});var hi=s(ir);T(sR.$$.fragment,hi),GBr=i(hi),nc=n(hi,"P",{});var sce=s(nc);OBr=r(sce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Koe=n(sce,"A",{href:!0});var Mia=s(Koe);VBr=r(Mia,"from_pretrained()"),Mia.forEach(t),XBr=r(sce," class method or the "),ere=n(sce,"A",{href:!0});var Eia=s(ere);zBr=r(Eia,"from_config()"),Eia.forEach(t),QBr=r(sce,` class
method.`),sce.forEach(t),WBr=i(hi),lR=n(hi,"P",{});var slo=s(lR);UBr=r(slo,"This class cannot be instantiated directly using "),H6e=n(slo,"CODE",{});var Cia=s(H6e);HBr=r(Cia,"__init__()"),Cia.forEach(t),JBr=r(slo," (throws an error)."),slo.forEach(t),YBr=i(hi),Ht=n(hi,"DIV",{class:!0});var ex=s(Ht);T(iR.$$.fragment,ex),ZBr=i(ex),J6e=n(ex,"P",{});var wia=s(J6e);KBr=r(wia,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),wia.forEach(t),eIr=i(ex),sc=n(ex,"P",{});var lce=s(sc);oIr=r(lce,`Note:
Loading a model from its configuration file does `),Y6e=n(lce,"STRONG",{});var Aia=s(Y6e);rIr=r(Aia,"not"),Aia.forEach(t),tIr=r(lce,` load the model weights. It only affects the
model\u2019s configuration. Use `),ore=n(lce,"A",{href:!0});var Lia=s(ore);aIr=r(Lia,"from_pretrained()"),Lia.forEach(t),nIr=r(lce," to load the model weights."),lce.forEach(t),sIr=i(ex),T(M5.$$.fragment,ex),ex.forEach(t),lIr=i(hi),Ao=n(hi,"DIV",{class:!0});var Ka=s(Ao);T(dR.$$.fragment,Ka),iIr=i(Ka),Z6e=n(Ka,"P",{});var yia=s(Z6e);dIr=r(yia,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),yia.forEach(t),mIr=i(Ka),Rn=n(Ka,"P",{});var ox=s(Rn);cIr=r(ox,"The model class to instantiate is selected based on the "),K6e=n(ox,"CODE",{});var xia=s(K6e);fIr=r(xia,"model_type"),xia.forEach(t),gIr=r(ox,` property of the config object (either
passed as an argument or loaded from `),e7e=n(ox,"CODE",{});var $ia=s(e7e);hIr=r($ia,"pretrained_model_name_or_path"),$ia.forEach(t),uIr=r(ox,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o7e=n(ox,"CODE",{});var kia=s(o7e);pIr=r(kia,"pretrained_model_name_or_path"),kia.forEach(t),_Ir=r(ox,":"),ox.forEach(t),bIr=i(Ka),r7e=n(Ka,"UL",{});var Sia=s(r7e);E5=n(Sia,"LI",{});var lYe=s(E5);t7e=n(lYe,"STRONG",{});var Ria=s(t7e);vIr=r(Ria,"maskformer"),Ria.forEach(t),FIr=r(lYe," \u2014 "),rre=n(lYe,"A",{href:!0});var Pia=s(rre);TIr=r(Pia,"MaskFormerForInstanceSegmentation"),Pia.forEach(t),MIr=r(lYe," (MaskFormer model)"),lYe.forEach(t),Sia.forEach(t),EIr=i(Ka),C5=n(Ka,"P",{});var iYe=s(C5);CIr=r(iYe,"The model is set in evaluation mode by default using "),a7e=n(iYe,"CODE",{});var Bia=s(a7e);wIr=r(Bia,"model.eval()"),Bia.forEach(t),AIr=r(iYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n7e=n(iYe,"CODE",{});var Iia=s(n7e);LIr=r(Iia,"model.train()"),Iia.forEach(t),iYe.forEach(t),yIr=i(Ka),T(w5.$$.fragment,Ka),Ka.forEach(t),hi.forEach(t),Oao=i(c),lc=n(c,"H2",{class:!0});var llo=s(lc);A5=n(llo,"A",{id:!0,class:!0,href:!0});var Nia=s(A5);s7e=n(Nia,"SPAN",{});var qia=s(s7e);T(mR.$$.fragment,qia),qia.forEach(t),Nia.forEach(t),xIr=i(llo),l7e=n(llo,"SPAN",{});var Dia=s(l7e);$Ir=r(Dia,"AutoModelForZeroShotObjectDetection"),Dia.forEach(t),llo.forEach(t),Vao=i(c),dr=n(c,"DIV",{class:!0});var ui=s(dr);T(cR.$$.fragment,ui),kIr=i(ui),ic=n(ui,"P",{});var ice=s(ic);SIr=r(ice,`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),tre=n(ice,"A",{href:!0});var jia=s(tre);RIr=r(jia,"from_pretrained()"),jia.forEach(t),PIr=r(ice," class method or the "),are=n(ice,"A",{href:!0});var Gia=s(are);BIr=r(Gia,"from_config()"),Gia.forEach(t),IIr=r(ice,` class
method.`),ice.forEach(t),NIr=i(ui),fR=n(ui,"P",{});var ilo=s(fR);qIr=r(ilo,"This class cannot be instantiated directly using "),i7e=n(ilo,"CODE",{});var Oia=s(i7e);DIr=r(Oia,"__init__()"),Oia.forEach(t),jIr=r(ilo," (throws an error)."),ilo.forEach(t),GIr=i(ui),Jt=n(ui,"DIV",{class:!0});var rx=s(Jt);T(gR.$$.fragment,rx),OIr=i(rx),d7e=n(rx,"P",{});var Via=s(d7e);VIr=r(Via,"Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),Via.forEach(t),XIr=i(rx),dc=n(rx,"P",{});var dce=s(dc);zIr=r(dce,`Note:
Loading a model from its configuration file does `),m7e=n(dce,"STRONG",{});var Xia=s(m7e);QIr=r(Xia,"not"),Xia.forEach(t),WIr=r(dce,` load the model weights. It only affects the
model\u2019s configuration. Use `),nre=n(dce,"A",{href:!0});var zia=s(nre);UIr=r(zia,"from_pretrained()"),zia.forEach(t),HIr=r(dce," to load the model weights."),dce.forEach(t),JIr=i(rx),T(L5.$$.fragment,rx),rx.forEach(t),YIr=i(ui),Lo=n(ui,"DIV",{class:!0});var en=s(Lo);T(hR.$$.fragment,en),ZIr=i(en),c7e=n(en,"P",{});var Qia=s(c7e);KIr=r(Qia,"Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),Qia.forEach(t),eNr=i(en),Pn=n(en,"P",{});var tx=s(Pn);oNr=r(tx,"The model class to instantiate is selected based on the "),f7e=n(tx,"CODE",{});var Wia=s(f7e);rNr=r(Wia,"model_type"),Wia.forEach(t),tNr=r(tx,` property of the config object (either
passed as an argument or loaded from `),g7e=n(tx,"CODE",{});var Uia=s(g7e);aNr=r(Uia,"pretrained_model_name_or_path"),Uia.forEach(t),nNr=r(tx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h7e=n(tx,"CODE",{});var Hia=s(h7e);sNr=r(Hia,"pretrained_model_name_or_path"),Hia.forEach(t),lNr=r(tx,":"),tx.forEach(t),iNr=i(en),u7e=n(en,"UL",{});var Jia=s(u7e);y5=n(Jia,"LI",{});var dYe=s(y5);p7e=n(dYe,"STRONG",{});var Yia=s(p7e);dNr=r(Yia,"owlvit"),Yia.forEach(t),mNr=r(dYe," \u2014 "),sre=n(dYe,"A",{href:!0});var Zia=s(sre);cNr=r(Zia,"OwlViTForObjectDetection"),Zia.forEach(t),fNr=r(dYe," (OWL-ViT model)"),dYe.forEach(t),Jia.forEach(t),gNr=i(en),x5=n(en,"P",{});var mYe=s(x5);hNr=r(mYe,"The model is set in evaluation mode by default using "),_7e=n(mYe,"CODE",{});var Kia=s(_7e);uNr=r(Kia,"model.eval()"),Kia.forEach(t),pNr=r(mYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b7e=n(mYe,"CODE",{});var eda=s(b7e);_Nr=r(eda,"model.train()"),eda.forEach(t),mYe.forEach(t),bNr=i(en),T($5.$$.fragment,en),en.forEach(t),ui.forEach(t),Xao=i(c),mc=n(c,"H2",{class:!0});var dlo=s(mc);k5=n(dlo,"A",{id:!0,class:!0,href:!0});var oda=s(k5);v7e=n(oda,"SPAN",{});var rda=s(v7e);T(uR.$$.fragment,rda),rda.forEach(t),oda.forEach(t),vNr=i(dlo),F7e=n(dlo,"SPAN",{});var tda=s(F7e);FNr=r(tda,"TFAutoModel"),tda.forEach(t),dlo.forEach(t),zao=i(c),mr=n(c,"DIV",{class:!0});var pi=s(mr);T(pR.$$.fragment,pi),TNr=i(pi),cc=n(pi,"P",{});var mce=s(cc);MNr=r(mce,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),lre=n(mce,"A",{href:!0});var ada=s(lre);ENr=r(ada,"from_pretrained()"),ada.forEach(t),CNr=r(mce," class method or the "),ire=n(mce,"A",{href:!0});var nda=s(ire);wNr=r(nda,"from_config()"),nda.forEach(t),ANr=r(mce,` class
method.`),mce.forEach(t),LNr=i(pi),_R=n(pi,"P",{});var mlo=s(_R);yNr=r(mlo,"This class cannot be instantiated directly using "),T7e=n(mlo,"CODE",{});var sda=s(T7e);xNr=r(sda,"__init__()"),sda.forEach(t),$Nr=r(mlo," (throws an error)."),mlo.forEach(t),kNr=i(pi),Yt=n(pi,"DIV",{class:!0});var ax=s(Yt);T(bR.$$.fragment,ax),SNr=i(ax),M7e=n(ax,"P",{});var lda=s(M7e);RNr=r(lda,"Instantiates one of the base model classes of the library from a configuration."),lda.forEach(t),PNr=i(ax),fc=n(ax,"P",{});var cce=s(fc);BNr=r(cce,`Note:
Loading a model from its configuration file does `),E7e=n(cce,"STRONG",{});var ida=s(E7e);INr=r(ida,"not"),ida.forEach(t),NNr=r(cce,` load the model weights. It only affects the
model\u2019s configuration. Use `),dre=n(cce,"A",{href:!0});var dda=s(dre);qNr=r(dda,"from_pretrained()"),dda.forEach(t),DNr=r(cce," to load the model weights."),cce.forEach(t),jNr=i(ax),T(S5.$$.fragment,ax),ax.forEach(t),GNr=i(pi),jr=n(pi,"DIV",{class:!0});var _i=s(jr);T(vR.$$.fragment,_i),ONr=i(_i),C7e=n(_i,"P",{});var mda=s(C7e);VNr=r(mda,"Instantiate one of the base model classes of the library from a pretrained model."),mda.forEach(t),XNr=i(_i),Bn=n(_i,"P",{});var nx=s(Bn);zNr=r(nx,"The model class to instantiate is selected based on the "),w7e=n(nx,"CODE",{});var cda=s(w7e);QNr=r(cda,"model_type"),cda.forEach(t),WNr=r(nx,` property of the config object (either
passed as an argument or loaded from `),A7e=n(nx,"CODE",{});var fda=s(A7e);UNr=r(fda,"pretrained_model_name_or_path"),fda.forEach(t),HNr=r(nx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L7e=n(nx,"CODE",{});var gda=s(L7e);JNr=r(gda,"pretrained_model_name_or_path"),gda.forEach(t),YNr=r(nx,":"),nx.forEach(t),ZNr=i(_i),P=n(_i,"UL",{});var I=s(P);R5=n(I,"LI",{});var cYe=s(R5);y7e=n(cYe,"STRONG",{});var hda=s(y7e);KNr=r(hda,"albert"),hda.forEach(t),eqr=r(cYe," \u2014 "),mre=n(cYe,"A",{href:!0});var uda=s(mre);oqr=r(uda,"TFAlbertModel"),uda.forEach(t),rqr=r(cYe," (ALBERT model)"),cYe.forEach(t),tqr=i(I),P5=n(I,"LI",{});var fYe=s(P5);x7e=n(fYe,"STRONG",{});var pda=s(x7e);aqr=r(pda,"bart"),pda.forEach(t),nqr=r(fYe," \u2014 "),cre=n(fYe,"A",{href:!0});var _da=s(cre);sqr=r(_da,"TFBartModel"),_da.forEach(t),lqr=r(fYe," (BART model)"),fYe.forEach(t),iqr=i(I),B5=n(I,"LI",{});var gYe=s(B5);$7e=n(gYe,"STRONG",{});var bda=s($7e);dqr=r(bda,"bert"),bda.forEach(t),mqr=r(gYe," \u2014 "),fre=n(gYe,"A",{href:!0});var vda=s(fre);cqr=r(vda,"TFBertModel"),vda.forEach(t),fqr=r(gYe," (BERT model)"),gYe.forEach(t),gqr=i(I),I5=n(I,"LI",{});var hYe=s(I5);k7e=n(hYe,"STRONG",{});var Fda=s(k7e);hqr=r(Fda,"blenderbot"),Fda.forEach(t),uqr=r(hYe," \u2014 "),gre=n(hYe,"A",{href:!0});var Tda=s(gre);pqr=r(Tda,"TFBlenderbotModel"),Tda.forEach(t),_qr=r(hYe," (Blenderbot model)"),hYe.forEach(t),bqr=i(I),N5=n(I,"LI",{});var uYe=s(N5);S7e=n(uYe,"STRONG",{});var Mda=s(S7e);vqr=r(Mda,"blenderbot-small"),Mda.forEach(t),Fqr=r(uYe," \u2014 "),hre=n(uYe,"A",{href:!0});var Eda=s(hre);Tqr=r(Eda,"TFBlenderbotSmallModel"),Eda.forEach(t),Mqr=r(uYe," (BlenderbotSmall model)"),uYe.forEach(t),Eqr=i(I),q5=n(I,"LI",{});var pYe=s(q5);R7e=n(pYe,"STRONG",{});var Cda=s(R7e);Cqr=r(Cda,"camembert"),Cda.forEach(t),wqr=r(pYe," \u2014 "),ure=n(pYe,"A",{href:!0});var wda=s(ure);Aqr=r(wda,"TFCamembertModel"),wda.forEach(t),Lqr=r(pYe," (CamemBERT model)"),pYe.forEach(t),yqr=i(I),D5=n(I,"LI",{});var _Ye=s(D5);P7e=n(_Ye,"STRONG",{});var Ada=s(P7e);xqr=r(Ada,"clip"),Ada.forEach(t),$qr=r(_Ye," \u2014 "),pre=n(_Ye,"A",{href:!0});var Lda=s(pre);kqr=r(Lda,"TFCLIPModel"),Lda.forEach(t),Sqr=r(_Ye," (CLIP model)"),_Ye.forEach(t),Rqr=i(I),j5=n(I,"LI",{});var bYe=s(j5);B7e=n(bYe,"STRONG",{});var yda=s(B7e);Pqr=r(yda,"convbert"),yda.forEach(t),Bqr=r(bYe," \u2014 "),_re=n(bYe,"A",{href:!0});var xda=s(_re);Iqr=r(xda,"TFConvBertModel"),xda.forEach(t),Nqr=r(bYe," (ConvBERT model)"),bYe.forEach(t),qqr=i(I),G5=n(I,"LI",{});var vYe=s(G5);I7e=n(vYe,"STRONG",{});var $da=s(I7e);Dqr=r($da,"convnext"),$da.forEach(t),jqr=r(vYe," \u2014 "),bre=n(vYe,"A",{href:!0});var kda=s(bre);Gqr=r(kda,"TFConvNextModel"),kda.forEach(t),Oqr=r(vYe," (ConvNeXT model)"),vYe.forEach(t),Vqr=i(I),O5=n(I,"LI",{});var FYe=s(O5);N7e=n(FYe,"STRONG",{});var Sda=s(N7e);Xqr=r(Sda,"ctrl"),Sda.forEach(t),zqr=r(FYe," \u2014 "),vre=n(FYe,"A",{href:!0});var Rda=s(vre);Qqr=r(Rda,"TFCTRLModel"),Rda.forEach(t),Wqr=r(FYe," (CTRL model)"),FYe.forEach(t),Uqr=i(I),V5=n(I,"LI",{});var TYe=s(V5);q7e=n(TYe,"STRONG",{});var Pda=s(q7e);Hqr=r(Pda,"cvt"),Pda.forEach(t),Jqr=r(TYe," \u2014 "),Fre=n(TYe,"A",{href:!0});var Bda=s(Fre);Yqr=r(Bda,"TFCvtModel"),Bda.forEach(t),Zqr=r(TYe," (CvT model)"),TYe.forEach(t),Kqr=i(I),X5=n(I,"LI",{});var MYe=s(X5);D7e=n(MYe,"STRONG",{});var Ida=s(D7e);eDr=r(Ida,"data2vec-vision"),Ida.forEach(t),oDr=r(MYe," \u2014 "),Tre=n(MYe,"A",{href:!0});var Nda=s(Tre);rDr=r(Nda,"TFData2VecVisionModel"),Nda.forEach(t),tDr=r(MYe," (Data2VecVision model)"),MYe.forEach(t),aDr=i(I),z5=n(I,"LI",{});var EYe=s(z5);j7e=n(EYe,"STRONG",{});var qda=s(j7e);nDr=r(qda,"deberta"),qda.forEach(t),sDr=r(EYe," \u2014 "),Mre=n(EYe,"A",{href:!0});var Dda=s(Mre);lDr=r(Dda,"TFDebertaModel"),Dda.forEach(t),iDr=r(EYe," (DeBERTa model)"),EYe.forEach(t),dDr=i(I),Q5=n(I,"LI",{});var CYe=s(Q5);G7e=n(CYe,"STRONG",{});var jda=s(G7e);mDr=r(jda,"deberta-v2"),jda.forEach(t),cDr=r(CYe," \u2014 "),Ere=n(CYe,"A",{href:!0});var Gda=s(Ere);fDr=r(Gda,"TFDebertaV2Model"),Gda.forEach(t),gDr=r(CYe," (DeBERTa-v2 model)"),CYe.forEach(t),hDr=i(I),W5=n(I,"LI",{});var wYe=s(W5);O7e=n(wYe,"STRONG",{});var Oda=s(O7e);uDr=r(Oda,"deit"),Oda.forEach(t),pDr=r(wYe," \u2014 "),Cre=n(wYe,"A",{href:!0});var Vda=s(Cre);_Dr=r(Vda,"TFDeiTModel"),Vda.forEach(t),bDr=r(wYe," (DeiT model)"),wYe.forEach(t),vDr=i(I),U5=n(I,"LI",{});var AYe=s(U5);V7e=n(AYe,"STRONG",{});var Xda=s(V7e);FDr=r(Xda,"distilbert"),Xda.forEach(t),TDr=r(AYe," \u2014 "),wre=n(AYe,"A",{href:!0});var zda=s(wre);MDr=r(zda,"TFDistilBertModel"),zda.forEach(t),EDr=r(AYe," (DistilBERT model)"),AYe.forEach(t),CDr=i(I),H5=n(I,"LI",{});var LYe=s(H5);X7e=n(LYe,"STRONG",{});var Qda=s(X7e);wDr=r(Qda,"dpr"),Qda.forEach(t),ADr=r(LYe," \u2014 "),Are=n(LYe,"A",{href:!0});var Wda=s(Are);LDr=r(Wda,"TFDPRQuestionEncoder"),Wda.forEach(t),yDr=r(LYe," (DPR model)"),LYe.forEach(t),xDr=i(I),J5=n(I,"LI",{});var yYe=s(J5);z7e=n(yYe,"STRONG",{});var Uda=s(z7e);$Dr=r(Uda,"electra"),Uda.forEach(t),kDr=r(yYe," \u2014 "),Lre=n(yYe,"A",{href:!0});var Hda=s(Lre);SDr=r(Hda,"TFElectraModel"),Hda.forEach(t),RDr=r(yYe," (ELECTRA model)"),yYe.forEach(t),PDr=i(I),Y5=n(I,"LI",{});var xYe=s(Y5);Q7e=n(xYe,"STRONG",{});var Jda=s(Q7e);BDr=r(Jda,"esm"),Jda.forEach(t),IDr=r(xYe," \u2014 "),yre=n(xYe,"A",{href:!0});var Yda=s(yre);NDr=r(Yda,"TFEsmModel"),Yda.forEach(t),qDr=r(xYe," (ESM model)"),xYe.forEach(t),DDr=i(I),Z5=n(I,"LI",{});var $Ye=s(Z5);W7e=n($Ye,"STRONG",{});var Zda=s(W7e);jDr=r(Zda,"flaubert"),Zda.forEach(t),GDr=r($Ye," \u2014 "),xre=n($Ye,"A",{href:!0});var Kda=s(xre);ODr=r(Kda,"TFFlaubertModel"),Kda.forEach(t),VDr=r($Ye," (FlauBERT model)"),$Ye.forEach(t),XDr=i(I),Sl=n(I,"LI",{});var TN=s(Sl);U7e=n(TN,"STRONG",{});var ema=s(U7e);zDr=r(ema,"funnel"),ema.forEach(t),QDr=r(TN," \u2014 "),$re=n(TN,"A",{href:!0});var oma=s($re);WDr=r(oma,"TFFunnelModel"),oma.forEach(t),UDr=r(TN," or "),kre=n(TN,"A",{href:!0});var rma=s(kre);HDr=r(rma,"TFFunnelBaseModel"),rma.forEach(t),JDr=r(TN," (Funnel Transformer model)"),TN.forEach(t),YDr=i(I),K5=n(I,"LI",{});var kYe=s(K5);H7e=n(kYe,"STRONG",{});var tma=s(H7e);ZDr=r(tma,"gpt2"),tma.forEach(t),KDr=r(kYe," \u2014 "),Sre=n(kYe,"A",{href:!0});var ama=s(Sre);ejr=r(ama,"TFGPT2Model"),ama.forEach(t),ojr=r(kYe," (OpenAI GPT-2 model)"),kYe.forEach(t),rjr=i(I),e0=n(I,"LI",{});var SYe=s(e0);J7e=n(SYe,"STRONG",{});var nma=s(J7e);tjr=r(nma,"gptj"),nma.forEach(t),ajr=r(SYe," \u2014 "),Rre=n(SYe,"A",{href:!0});var sma=s(Rre);njr=r(sma,"TFGPTJModel"),sma.forEach(t),sjr=r(SYe," (GPT-J model)"),SYe.forEach(t),ljr=i(I),o0=n(I,"LI",{});var RYe=s(o0);Y7e=n(RYe,"STRONG",{});var lma=s(Y7e);ijr=r(lma,"groupvit"),lma.forEach(t),djr=r(RYe," \u2014 "),Pre=n(RYe,"A",{href:!0});var ima=s(Pre);mjr=r(ima,"TFGroupViTModel"),ima.forEach(t),cjr=r(RYe," (GroupViT model)"),RYe.forEach(t),fjr=i(I),r0=n(I,"LI",{});var PYe=s(r0);Z7e=n(PYe,"STRONG",{});var dma=s(Z7e);gjr=r(dma,"hubert"),dma.forEach(t),hjr=r(PYe," \u2014 "),Bre=n(PYe,"A",{href:!0});var mma=s(Bre);ujr=r(mma,"TFHubertModel"),mma.forEach(t),pjr=r(PYe," (Hubert model)"),PYe.forEach(t),_jr=i(I),t0=n(I,"LI",{});var BYe=s(t0);K7e=n(BYe,"STRONG",{});var cma=s(K7e);bjr=r(cma,"layoutlm"),cma.forEach(t),vjr=r(BYe," \u2014 "),Ire=n(BYe,"A",{href:!0});var fma=s(Ire);Fjr=r(fma,"TFLayoutLMModel"),fma.forEach(t),Tjr=r(BYe," (LayoutLM model)"),BYe.forEach(t),Mjr=i(I),a0=n(I,"LI",{});var IYe=s(a0);e8e=n(IYe,"STRONG",{});var gma=s(e8e);Ejr=r(gma,"layoutlmv3"),gma.forEach(t),Cjr=r(IYe," \u2014 "),Nre=n(IYe,"A",{href:!0});var hma=s(Nre);wjr=r(hma,"TFLayoutLMv3Model"),hma.forEach(t),Ajr=r(IYe," (LayoutLMv3 model)"),IYe.forEach(t),Ljr=i(I),n0=n(I,"LI",{});var NYe=s(n0);o8e=n(NYe,"STRONG",{});var uma=s(o8e);yjr=r(uma,"led"),uma.forEach(t),xjr=r(NYe," \u2014 "),qre=n(NYe,"A",{href:!0});var pma=s(qre);$jr=r(pma,"TFLEDModel"),pma.forEach(t),kjr=r(NYe," (LED model)"),NYe.forEach(t),Sjr=i(I),s0=n(I,"LI",{});var qYe=s(s0);r8e=n(qYe,"STRONG",{});var _ma=s(r8e);Rjr=r(_ma,"longformer"),_ma.forEach(t),Pjr=r(qYe," \u2014 "),Dre=n(qYe,"A",{href:!0});var bma=s(Dre);Bjr=r(bma,"TFLongformerModel"),bma.forEach(t),Ijr=r(qYe," (Longformer model)"),qYe.forEach(t),Njr=i(I),l0=n(I,"LI",{});var DYe=s(l0);t8e=n(DYe,"STRONG",{});var vma=s(t8e);qjr=r(vma,"lxmert"),vma.forEach(t),Djr=r(DYe," \u2014 "),jre=n(DYe,"A",{href:!0});var Fma=s(jre);jjr=r(Fma,"TFLxmertModel"),Fma.forEach(t),Gjr=r(DYe," (LXMERT model)"),DYe.forEach(t),Ojr=i(I),i0=n(I,"LI",{});var jYe=s(i0);a8e=n(jYe,"STRONG",{});var Tma=s(a8e);Vjr=r(Tma,"marian"),Tma.forEach(t),Xjr=r(jYe," \u2014 "),Gre=n(jYe,"A",{href:!0});var Mma=s(Gre);zjr=r(Mma,"TFMarianModel"),Mma.forEach(t),Qjr=r(jYe," (Marian model)"),jYe.forEach(t),Wjr=i(I),d0=n(I,"LI",{});var GYe=s(d0);n8e=n(GYe,"STRONG",{});var Ema=s(n8e);Ujr=r(Ema,"mbart"),Ema.forEach(t),Hjr=r(GYe," \u2014 "),Ore=n(GYe,"A",{href:!0});var Cma=s(Ore);Jjr=r(Cma,"TFMBartModel"),Cma.forEach(t),Yjr=r(GYe," (mBART model)"),GYe.forEach(t),Zjr=i(I),m0=n(I,"LI",{});var OYe=s(m0);s8e=n(OYe,"STRONG",{});var wma=s(s8e);Kjr=r(wma,"mobilebert"),wma.forEach(t),eGr=r(OYe," \u2014 "),Vre=n(OYe,"A",{href:!0});var Ama=s(Vre);oGr=r(Ama,"TFMobileBertModel"),Ama.forEach(t),rGr=r(OYe," (MobileBERT model)"),OYe.forEach(t),tGr=i(I),c0=n(I,"LI",{});var VYe=s(c0);l8e=n(VYe,"STRONG",{});var Lma=s(l8e);aGr=r(Lma,"mobilevit"),Lma.forEach(t),nGr=r(VYe," \u2014 "),Xre=n(VYe,"A",{href:!0});var yma=s(Xre);sGr=r(yma,"TFMobileViTModel"),yma.forEach(t),lGr=r(VYe," (MobileViT model)"),VYe.forEach(t),iGr=i(I),f0=n(I,"LI",{});var XYe=s(f0);i8e=n(XYe,"STRONG",{});var xma=s(i8e);dGr=r(xma,"mpnet"),xma.forEach(t),mGr=r(XYe," \u2014 "),zre=n(XYe,"A",{href:!0});var $ma=s(zre);cGr=r($ma,"TFMPNetModel"),$ma.forEach(t),fGr=r(XYe," (MPNet model)"),XYe.forEach(t),gGr=i(I),g0=n(I,"LI",{});var zYe=s(g0);d8e=n(zYe,"STRONG",{});var kma=s(d8e);hGr=r(kma,"mt5"),kma.forEach(t),uGr=r(zYe," \u2014 "),Qre=n(zYe,"A",{href:!0});var Sma=s(Qre);pGr=r(Sma,"TFMT5Model"),Sma.forEach(t),_Gr=r(zYe," (MT5 model)"),zYe.forEach(t),bGr=i(I),h0=n(I,"LI",{});var QYe=s(h0);m8e=n(QYe,"STRONG",{});var Rma=s(m8e);vGr=r(Rma,"openai-gpt"),Rma.forEach(t),FGr=r(QYe," \u2014 "),Wre=n(QYe,"A",{href:!0});var Pma=s(Wre);TGr=r(Pma,"TFOpenAIGPTModel"),Pma.forEach(t),MGr=r(QYe," (OpenAI GPT model)"),QYe.forEach(t),EGr=i(I),u0=n(I,"LI",{});var WYe=s(u0);c8e=n(WYe,"STRONG",{});var Bma=s(c8e);CGr=r(Bma,"opt"),Bma.forEach(t),wGr=r(WYe," \u2014 "),Ure=n(WYe,"A",{href:!0});var Ima=s(Ure);AGr=r(Ima,"TFOPTModel"),Ima.forEach(t),LGr=r(WYe," (OPT model)"),WYe.forEach(t),yGr=i(I),p0=n(I,"LI",{});var UYe=s(p0);f8e=n(UYe,"STRONG",{});var Nma=s(f8e);xGr=r(Nma,"pegasus"),Nma.forEach(t),$Gr=r(UYe," \u2014 "),Hre=n(UYe,"A",{href:!0});var qma=s(Hre);kGr=r(qma,"TFPegasusModel"),qma.forEach(t),SGr=r(UYe," (Pegasus model)"),UYe.forEach(t),RGr=i(I),_0=n(I,"LI",{});var HYe=s(_0);g8e=n(HYe,"STRONG",{});var Dma=s(g8e);PGr=r(Dma,"regnet"),Dma.forEach(t),BGr=r(HYe," \u2014 "),Jre=n(HYe,"A",{href:!0});var jma=s(Jre);IGr=r(jma,"TFRegNetModel"),jma.forEach(t),NGr=r(HYe," (RegNet model)"),HYe.forEach(t),qGr=i(I),b0=n(I,"LI",{});var JYe=s(b0);h8e=n(JYe,"STRONG",{});var Gma=s(h8e);DGr=r(Gma,"rembert"),Gma.forEach(t),jGr=r(JYe," \u2014 "),Yre=n(JYe,"A",{href:!0});var Oma=s(Yre);GGr=r(Oma,"TFRemBertModel"),Oma.forEach(t),OGr=r(JYe," (RemBERT model)"),JYe.forEach(t),VGr=i(I),v0=n(I,"LI",{});var YYe=s(v0);u8e=n(YYe,"STRONG",{});var Vma=s(u8e);XGr=r(Vma,"resnet"),Vma.forEach(t),zGr=r(YYe," \u2014 "),Zre=n(YYe,"A",{href:!0});var Xma=s(Zre);QGr=r(Xma,"TFResNetModel"),Xma.forEach(t),WGr=r(YYe," (ResNet model)"),YYe.forEach(t),UGr=i(I),F0=n(I,"LI",{});var ZYe=s(F0);p8e=n(ZYe,"STRONG",{});var zma=s(p8e);HGr=r(zma,"roberta"),zma.forEach(t),JGr=r(ZYe," \u2014 "),Kre=n(ZYe,"A",{href:!0});var Qma=s(Kre);YGr=r(Qma,"TFRobertaModel"),Qma.forEach(t),ZGr=r(ZYe," (RoBERTa model)"),ZYe.forEach(t),KGr=i(I),T0=n(I,"LI",{});var KYe=s(T0);_8e=n(KYe,"STRONG",{});var Wma=s(_8e);eOr=r(Wma,"roformer"),Wma.forEach(t),oOr=r(KYe," \u2014 "),ete=n(KYe,"A",{href:!0});var Uma=s(ete);rOr=r(Uma,"TFRoFormerModel"),Uma.forEach(t),tOr=r(KYe," (RoFormer model)"),KYe.forEach(t),aOr=i(I),M0=n(I,"LI",{});var eZe=s(M0);b8e=n(eZe,"STRONG",{});var Hma=s(b8e);nOr=r(Hma,"segformer"),Hma.forEach(t),sOr=r(eZe," \u2014 "),ote=n(eZe,"A",{href:!0});var Jma=s(ote);lOr=r(Jma,"TFSegformerModel"),Jma.forEach(t),iOr=r(eZe," (SegFormer model)"),eZe.forEach(t),dOr=i(I),E0=n(I,"LI",{});var oZe=s(E0);v8e=n(oZe,"STRONG",{});var Yma=s(v8e);mOr=r(Yma,"speech_to_text"),Yma.forEach(t),cOr=r(oZe," \u2014 "),rte=n(oZe,"A",{href:!0});var Zma=s(rte);fOr=r(Zma,"TFSpeech2TextModel"),Zma.forEach(t),gOr=r(oZe," (Speech2Text model)"),oZe.forEach(t),hOr=i(I),C0=n(I,"LI",{});var rZe=s(C0);F8e=n(rZe,"STRONG",{});var Kma=s(F8e);uOr=r(Kma,"swin"),Kma.forEach(t),pOr=r(rZe," \u2014 "),tte=n(rZe,"A",{href:!0});var eca=s(tte);_Or=r(eca,"TFSwinModel"),eca.forEach(t),bOr=r(rZe," (Swin Transformer model)"),rZe.forEach(t),vOr=i(I),w0=n(I,"LI",{});var tZe=s(w0);T8e=n(tZe,"STRONG",{});var oca=s(T8e);FOr=r(oca,"t5"),oca.forEach(t),TOr=r(tZe," \u2014 "),ate=n(tZe,"A",{href:!0});var rca=s(ate);MOr=r(rca,"TFT5Model"),rca.forEach(t),EOr=r(tZe," (T5 model)"),tZe.forEach(t),COr=i(I),A0=n(I,"LI",{});var aZe=s(A0);M8e=n(aZe,"STRONG",{});var tca=s(M8e);wOr=r(tca,"tapas"),tca.forEach(t),AOr=r(aZe," \u2014 "),nte=n(aZe,"A",{href:!0});var aca=s(nte);LOr=r(aca,"TFTapasModel"),aca.forEach(t),yOr=r(aZe," (TAPAS model)"),aZe.forEach(t),xOr=i(I),L0=n(I,"LI",{});var nZe=s(L0);E8e=n(nZe,"STRONG",{});var nca=s(E8e);$Or=r(nca,"transfo-xl"),nca.forEach(t),kOr=r(nZe," \u2014 "),ste=n(nZe,"A",{href:!0});var sca=s(ste);SOr=r(sca,"TFTransfoXLModel"),sca.forEach(t),ROr=r(nZe," (Transformer-XL model)"),nZe.forEach(t),POr=i(I),y0=n(I,"LI",{});var sZe=s(y0);C8e=n(sZe,"STRONG",{});var lca=s(C8e);BOr=r(lca,"vit"),lca.forEach(t),IOr=r(sZe," \u2014 "),lte=n(sZe,"A",{href:!0});var ica=s(lte);NOr=r(ica,"TFViTModel"),ica.forEach(t),qOr=r(sZe," (ViT model)"),sZe.forEach(t),DOr=i(I),x0=n(I,"LI",{});var lZe=s(x0);w8e=n(lZe,"STRONG",{});var dca=s(w8e);jOr=r(dca,"vit_mae"),dca.forEach(t),GOr=r(lZe," \u2014 "),ite=n(lZe,"A",{href:!0});var mca=s(ite);OOr=r(mca,"TFViTMAEModel"),mca.forEach(t),VOr=r(lZe," (ViTMAE model)"),lZe.forEach(t),XOr=i(I),$0=n(I,"LI",{});var iZe=s($0);A8e=n(iZe,"STRONG",{});var cca=s(A8e);zOr=r(cca,"wav2vec2"),cca.forEach(t),QOr=r(iZe," \u2014 "),dte=n(iZe,"A",{href:!0});var fca=s(dte);WOr=r(fca,"TFWav2Vec2Model"),fca.forEach(t),UOr=r(iZe," (Wav2Vec2 model)"),iZe.forEach(t),HOr=i(I),k0=n(I,"LI",{});var dZe=s(k0);L8e=n(dZe,"STRONG",{});var gca=s(L8e);JOr=r(gca,"whisper"),gca.forEach(t),YOr=r(dZe," \u2014 "),mte=n(dZe,"A",{href:!0});var hca=s(mte);ZOr=r(hca,"TFWhisperModel"),hca.forEach(t),KOr=r(dZe," (Whisper model)"),dZe.forEach(t),eVr=i(I),S0=n(I,"LI",{});var mZe=s(S0);y8e=n(mZe,"STRONG",{});var uca=s(y8e);oVr=r(uca,"xglm"),uca.forEach(t),rVr=r(mZe," \u2014 "),cte=n(mZe,"A",{href:!0});var pca=s(cte);tVr=r(pca,"TFXGLMModel"),pca.forEach(t),aVr=r(mZe," (XGLM model)"),mZe.forEach(t),nVr=i(I),R0=n(I,"LI",{});var cZe=s(R0);x8e=n(cZe,"STRONG",{});var _ca=s(x8e);sVr=r(_ca,"xlm"),_ca.forEach(t),lVr=r(cZe," \u2014 "),fte=n(cZe,"A",{href:!0});var bca=s(fte);iVr=r(bca,"TFXLMModel"),bca.forEach(t),dVr=r(cZe," (XLM model)"),cZe.forEach(t),mVr=i(I),P0=n(I,"LI",{});var fZe=s(P0);$8e=n(fZe,"STRONG",{});var vca=s($8e);cVr=r(vca,"xlm-roberta"),vca.forEach(t),fVr=r(fZe," \u2014 "),gte=n(fZe,"A",{href:!0});var Fca=s(gte);gVr=r(Fca,"TFXLMRobertaModel"),Fca.forEach(t),hVr=r(fZe," (XLM-RoBERTa model)"),fZe.forEach(t),uVr=i(I),B0=n(I,"LI",{});var gZe=s(B0);k8e=n(gZe,"STRONG",{});var Tca=s(k8e);pVr=r(Tca,"xlnet"),Tca.forEach(t),_Vr=r(gZe," \u2014 "),hte=n(gZe,"A",{href:!0});var Mca=s(hte);bVr=r(Mca,"TFXLNetModel"),Mca.forEach(t),vVr=r(gZe," (XLNet model)"),gZe.forEach(t),I.forEach(t),FVr=i(_i),T(I0.$$.fragment,_i),_i.forEach(t),pi.forEach(t),Qao=i(c),gc=n(c,"H2",{class:!0});var clo=s(gc);N0=n(clo,"A",{id:!0,class:!0,href:!0});var Eca=s(N0);S8e=n(Eca,"SPAN",{});var Cca=s(S8e);T(FR.$$.fragment,Cca),Cca.forEach(t),Eca.forEach(t),TVr=i(clo),R8e=n(clo,"SPAN",{});var wca=s(R8e);MVr=r(wca,"TFAutoModelForPreTraining"),wca.forEach(t),clo.forEach(t),Wao=i(c),cr=n(c,"DIV",{class:!0});var bi=s(cr);T(TR.$$.fragment,bi),EVr=i(bi),hc=n(bi,"P",{});var fce=s(hc);CVr=r(fce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),ute=n(fce,"A",{href:!0});var Aca=s(ute);wVr=r(Aca,"from_pretrained()"),Aca.forEach(t),AVr=r(fce," class method or the "),pte=n(fce,"A",{href:!0});var Lca=s(pte);LVr=r(Lca,"from_config()"),Lca.forEach(t),yVr=r(fce,` class
method.`),fce.forEach(t),xVr=i(bi),MR=n(bi,"P",{});var flo=s(MR);$Vr=r(flo,"This class cannot be instantiated directly using "),P8e=n(flo,"CODE",{});var yca=s(P8e);kVr=r(yca,"__init__()"),yca.forEach(t),SVr=r(flo," (throws an error)."),flo.forEach(t),RVr=i(bi),Zt=n(bi,"DIV",{class:!0});var sx=s(Zt);T(ER.$$.fragment,sx),PVr=i(sx),B8e=n(sx,"P",{});var xca=s(B8e);BVr=r(xca,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),xca.forEach(t),IVr=i(sx),uc=n(sx,"P",{});var gce=s(uc);NVr=r(gce,`Note:
Loading a model from its configuration file does `),I8e=n(gce,"STRONG",{});var $ca=s(I8e);qVr=r($ca,"not"),$ca.forEach(t),DVr=r(gce,` load the model weights. It only affects the
model\u2019s configuration. Use `),_te=n(gce,"A",{href:!0});var kca=s(_te);jVr=r(kca,"from_pretrained()"),kca.forEach(t),GVr=r(gce," to load the model weights."),gce.forEach(t),OVr=i(sx),T(q0.$$.fragment,sx),sx.forEach(t),VVr=i(bi),Gr=n(bi,"DIV",{class:!0});var vi=s(Gr);T(CR.$$.fragment,vi),XVr=i(vi),N8e=n(vi,"P",{});var Sca=s(N8e);zVr=r(Sca,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Sca.forEach(t),QVr=i(vi),In=n(vi,"P",{});var lx=s(In);WVr=r(lx,"The model class to instantiate is selected based on the "),q8e=n(lx,"CODE",{});var Rca=s(q8e);UVr=r(Rca,"model_type"),Rca.forEach(t),HVr=r(lx,` property of the config object (either
passed as an argument or loaded from `),D8e=n(lx,"CODE",{});var Pca=s(D8e);JVr=r(Pca,"pretrained_model_name_or_path"),Pca.forEach(t),YVr=r(lx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j8e=n(lx,"CODE",{});var Bca=s(j8e);ZVr=r(Bca,"pretrained_model_name_or_path"),Bca.forEach(t),KVr=r(lx,":"),lx.forEach(t),eXr=i(vi),le=n(vi,"UL",{});var me=s(le);D0=n(me,"LI",{});var hZe=s(D0);G8e=n(hZe,"STRONG",{});var Ica=s(G8e);oXr=r(Ica,"albert"),Ica.forEach(t),rXr=r(hZe," \u2014 "),bte=n(hZe,"A",{href:!0});var Nca=s(bte);tXr=r(Nca,"TFAlbertForPreTraining"),Nca.forEach(t),aXr=r(hZe," (ALBERT model)"),hZe.forEach(t),nXr=i(me),j0=n(me,"LI",{});var uZe=s(j0);O8e=n(uZe,"STRONG",{});var qca=s(O8e);sXr=r(qca,"bart"),qca.forEach(t),lXr=r(uZe," \u2014 "),vte=n(uZe,"A",{href:!0});var Dca=s(vte);iXr=r(Dca,"TFBartForConditionalGeneration"),Dca.forEach(t),dXr=r(uZe," (BART model)"),uZe.forEach(t),mXr=i(me),G0=n(me,"LI",{});var pZe=s(G0);V8e=n(pZe,"STRONG",{});var jca=s(V8e);cXr=r(jca,"bert"),jca.forEach(t),fXr=r(pZe," \u2014 "),Fte=n(pZe,"A",{href:!0});var Gca=s(Fte);gXr=r(Gca,"TFBertForPreTraining"),Gca.forEach(t),hXr=r(pZe," (BERT model)"),pZe.forEach(t),uXr=i(me),O0=n(me,"LI",{});var _Ze=s(O0);X8e=n(_Ze,"STRONG",{});var Oca=s(X8e);pXr=r(Oca,"camembert"),Oca.forEach(t),_Xr=r(_Ze," \u2014 "),Tte=n(_Ze,"A",{href:!0});var Vca=s(Tte);bXr=r(Vca,"TFCamembertForMaskedLM"),Vca.forEach(t),vXr=r(_Ze," (CamemBERT model)"),_Ze.forEach(t),FXr=i(me),V0=n(me,"LI",{});var bZe=s(V0);z8e=n(bZe,"STRONG",{});var Xca=s(z8e);TXr=r(Xca,"ctrl"),Xca.forEach(t),MXr=r(bZe," \u2014 "),Mte=n(bZe,"A",{href:!0});var zca=s(Mte);EXr=r(zca,"TFCTRLLMHeadModel"),zca.forEach(t),CXr=r(bZe," (CTRL model)"),bZe.forEach(t),wXr=i(me),X0=n(me,"LI",{});var vZe=s(X0);Q8e=n(vZe,"STRONG",{});var Qca=s(Q8e);AXr=r(Qca,"distilbert"),Qca.forEach(t),LXr=r(vZe," \u2014 "),Ete=n(vZe,"A",{href:!0});var Wca=s(Ete);yXr=r(Wca,"TFDistilBertForMaskedLM"),Wca.forEach(t),xXr=r(vZe," (DistilBERT model)"),vZe.forEach(t),$Xr=i(me),z0=n(me,"LI",{});var FZe=s(z0);W8e=n(FZe,"STRONG",{});var Uca=s(W8e);kXr=r(Uca,"electra"),Uca.forEach(t),SXr=r(FZe," \u2014 "),Cte=n(FZe,"A",{href:!0});var Hca=s(Cte);RXr=r(Hca,"TFElectraForPreTraining"),Hca.forEach(t),PXr=r(FZe," (ELECTRA model)"),FZe.forEach(t),BXr=i(me),Q0=n(me,"LI",{});var TZe=s(Q0);U8e=n(TZe,"STRONG",{});var Jca=s(U8e);IXr=r(Jca,"flaubert"),Jca.forEach(t),NXr=r(TZe," \u2014 "),wte=n(TZe,"A",{href:!0});var Yca=s(wte);qXr=r(Yca,"TFFlaubertWithLMHeadModel"),Yca.forEach(t),DXr=r(TZe," (FlauBERT model)"),TZe.forEach(t),jXr=i(me),W0=n(me,"LI",{});var MZe=s(W0);H8e=n(MZe,"STRONG",{});var Zca=s(H8e);GXr=r(Zca,"funnel"),Zca.forEach(t),OXr=r(MZe," \u2014 "),Ate=n(MZe,"A",{href:!0});var Kca=s(Ate);VXr=r(Kca,"TFFunnelForPreTraining"),Kca.forEach(t),XXr=r(MZe," (Funnel Transformer model)"),MZe.forEach(t),zXr=i(me),U0=n(me,"LI",{});var EZe=s(U0);J8e=n(EZe,"STRONG",{});var efa=s(J8e);QXr=r(efa,"gpt2"),efa.forEach(t),WXr=r(EZe," \u2014 "),Lte=n(EZe,"A",{href:!0});var ofa=s(Lte);UXr=r(ofa,"TFGPT2LMHeadModel"),ofa.forEach(t),HXr=r(EZe," (OpenAI GPT-2 model)"),EZe.forEach(t),JXr=i(me),H0=n(me,"LI",{});var CZe=s(H0);Y8e=n(CZe,"STRONG",{});var rfa=s(Y8e);YXr=r(rfa,"layoutlm"),rfa.forEach(t),ZXr=r(CZe," \u2014 "),yte=n(CZe,"A",{href:!0});var tfa=s(yte);KXr=r(tfa,"TFLayoutLMForMaskedLM"),tfa.forEach(t),ezr=r(CZe," (LayoutLM model)"),CZe.forEach(t),ozr=i(me),J0=n(me,"LI",{});var wZe=s(J0);Z8e=n(wZe,"STRONG",{});var afa=s(Z8e);rzr=r(afa,"lxmert"),afa.forEach(t),tzr=r(wZe," \u2014 "),xte=n(wZe,"A",{href:!0});var nfa=s(xte);azr=r(nfa,"TFLxmertForPreTraining"),nfa.forEach(t),nzr=r(wZe," (LXMERT model)"),wZe.forEach(t),szr=i(me),Y0=n(me,"LI",{});var AZe=s(Y0);K8e=n(AZe,"STRONG",{});var sfa=s(K8e);lzr=r(sfa,"mobilebert"),sfa.forEach(t),izr=r(AZe," \u2014 "),$te=n(AZe,"A",{href:!0});var lfa=s($te);dzr=r(lfa,"TFMobileBertForPreTraining"),lfa.forEach(t),mzr=r(AZe," (MobileBERT model)"),AZe.forEach(t),czr=i(me),Z0=n(me,"LI",{});var LZe=s(Z0);eLe=n(LZe,"STRONG",{});var ifa=s(eLe);fzr=r(ifa,"mpnet"),ifa.forEach(t),gzr=r(LZe," \u2014 "),kte=n(LZe,"A",{href:!0});var dfa=s(kte);hzr=r(dfa,"TFMPNetForMaskedLM"),dfa.forEach(t),uzr=r(LZe," (MPNet model)"),LZe.forEach(t),pzr=i(me),K0=n(me,"LI",{});var yZe=s(K0);oLe=n(yZe,"STRONG",{});var mfa=s(oLe);_zr=r(mfa,"openai-gpt"),mfa.forEach(t),bzr=r(yZe," \u2014 "),Ste=n(yZe,"A",{href:!0});var cfa=s(Ste);vzr=r(cfa,"TFOpenAIGPTLMHeadModel"),cfa.forEach(t),Fzr=r(yZe," (OpenAI GPT model)"),yZe.forEach(t),Tzr=i(me),ew=n(me,"LI",{});var xZe=s(ew);rLe=n(xZe,"STRONG",{});var ffa=s(rLe);Mzr=r(ffa,"roberta"),ffa.forEach(t),Ezr=r(xZe," \u2014 "),Rte=n(xZe,"A",{href:!0});var gfa=s(Rte);Czr=r(gfa,"TFRobertaForMaskedLM"),gfa.forEach(t),wzr=r(xZe," (RoBERTa model)"),xZe.forEach(t),Azr=i(me),ow=n(me,"LI",{});var $Ze=s(ow);tLe=n($Ze,"STRONG",{});var hfa=s(tLe);Lzr=r(hfa,"t5"),hfa.forEach(t),yzr=r($Ze," \u2014 "),Pte=n($Ze,"A",{href:!0});var ufa=s(Pte);xzr=r(ufa,"TFT5ForConditionalGeneration"),ufa.forEach(t),$zr=r($Ze," (T5 model)"),$Ze.forEach(t),kzr=i(me),rw=n(me,"LI",{});var kZe=s(rw);aLe=n(kZe,"STRONG",{});var pfa=s(aLe);Szr=r(pfa,"tapas"),pfa.forEach(t),Rzr=r(kZe," \u2014 "),Bte=n(kZe,"A",{href:!0});var _fa=s(Bte);Pzr=r(_fa,"TFTapasForMaskedLM"),_fa.forEach(t),Bzr=r(kZe," (TAPAS model)"),kZe.forEach(t),Izr=i(me),tw=n(me,"LI",{});var SZe=s(tw);nLe=n(SZe,"STRONG",{});var bfa=s(nLe);Nzr=r(bfa,"transfo-xl"),bfa.forEach(t),qzr=r(SZe," \u2014 "),Ite=n(SZe,"A",{href:!0});var vfa=s(Ite);Dzr=r(vfa,"TFTransfoXLLMHeadModel"),vfa.forEach(t),jzr=r(SZe," (Transformer-XL model)"),SZe.forEach(t),Gzr=i(me),aw=n(me,"LI",{});var RZe=s(aw);sLe=n(RZe,"STRONG",{});var Ffa=s(sLe);Ozr=r(Ffa,"vit_mae"),Ffa.forEach(t),Vzr=r(RZe," \u2014 "),Nte=n(RZe,"A",{href:!0});var Tfa=s(Nte);Xzr=r(Tfa,"TFViTMAEForPreTraining"),Tfa.forEach(t),zzr=r(RZe," (ViTMAE model)"),RZe.forEach(t),Qzr=i(me),nw=n(me,"LI",{});var PZe=s(nw);lLe=n(PZe,"STRONG",{});var Mfa=s(lLe);Wzr=r(Mfa,"xlm"),Mfa.forEach(t),Uzr=r(PZe," \u2014 "),qte=n(PZe,"A",{href:!0});var Efa=s(qte);Hzr=r(Efa,"TFXLMWithLMHeadModel"),Efa.forEach(t),Jzr=r(PZe," (XLM model)"),PZe.forEach(t),Yzr=i(me),sw=n(me,"LI",{});var BZe=s(sw);iLe=n(BZe,"STRONG",{});var Cfa=s(iLe);Zzr=r(Cfa,"xlm-roberta"),Cfa.forEach(t),Kzr=r(BZe," \u2014 "),Dte=n(BZe,"A",{href:!0});var wfa=s(Dte);eQr=r(wfa,"TFXLMRobertaForMaskedLM"),wfa.forEach(t),oQr=r(BZe," (XLM-RoBERTa model)"),BZe.forEach(t),rQr=i(me),lw=n(me,"LI",{});var IZe=s(lw);dLe=n(IZe,"STRONG",{});var Afa=s(dLe);tQr=r(Afa,"xlnet"),Afa.forEach(t),aQr=r(IZe," \u2014 "),jte=n(IZe,"A",{href:!0});var Lfa=s(jte);nQr=r(Lfa,"TFXLNetLMHeadModel"),Lfa.forEach(t),sQr=r(IZe," (XLNet model)"),IZe.forEach(t),me.forEach(t),lQr=i(vi),T(iw.$$.fragment,vi),vi.forEach(t),bi.forEach(t),Uao=i(c),pc=n(c,"H2",{class:!0});var glo=s(pc);dw=n(glo,"A",{id:!0,class:!0,href:!0});var yfa=s(dw);mLe=n(yfa,"SPAN",{});var xfa=s(mLe);T(wR.$$.fragment,xfa),xfa.forEach(t),yfa.forEach(t),iQr=i(glo),cLe=n(glo,"SPAN",{});var $fa=s(cLe);dQr=r($fa,"TFAutoModelForCausalLM"),$fa.forEach(t),glo.forEach(t),Hao=i(c),fr=n(c,"DIV",{class:!0});var Fi=s(fr);T(AR.$$.fragment,Fi),mQr=i(Fi),_c=n(Fi,"P",{});var hce=s(_c);cQr=r(hce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Gte=n(hce,"A",{href:!0});var kfa=s(Gte);fQr=r(kfa,"from_pretrained()"),kfa.forEach(t),gQr=r(hce," class method or the "),Ote=n(hce,"A",{href:!0});var Sfa=s(Ote);hQr=r(Sfa,"from_config()"),Sfa.forEach(t),uQr=r(hce,` class
method.`),hce.forEach(t),pQr=i(Fi),LR=n(Fi,"P",{});var hlo=s(LR);_Qr=r(hlo,"This class cannot be instantiated directly using "),fLe=n(hlo,"CODE",{});var Rfa=s(fLe);bQr=r(Rfa,"__init__()"),Rfa.forEach(t),vQr=r(hlo," (throws an error)."),hlo.forEach(t),FQr=i(Fi),Kt=n(Fi,"DIV",{class:!0});var ix=s(Kt);T(yR.$$.fragment,ix),TQr=i(ix),gLe=n(ix,"P",{});var Pfa=s(gLe);MQr=r(Pfa,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Pfa.forEach(t),EQr=i(ix),bc=n(ix,"P",{});var uce=s(bc);CQr=r(uce,`Note:
Loading a model from its configuration file does `),hLe=n(uce,"STRONG",{});var Bfa=s(hLe);wQr=r(Bfa,"not"),Bfa.forEach(t),AQr=r(uce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Vte=n(uce,"A",{href:!0});var Ifa=s(Vte);LQr=r(Ifa,"from_pretrained()"),Ifa.forEach(t),yQr=r(uce," to load the model weights."),uce.forEach(t),xQr=i(ix),T(mw.$$.fragment,ix),ix.forEach(t),$Qr=i(Fi),Or=n(Fi,"DIV",{class:!0});var Ti=s(Or);T(xR.$$.fragment,Ti),kQr=i(Ti),uLe=n(Ti,"P",{});var Nfa=s(uLe);SQr=r(Nfa,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Nfa.forEach(t),RQr=i(Ti),Nn=n(Ti,"P",{});var dx=s(Nn);PQr=r(dx,"The model class to instantiate is selected based on the "),pLe=n(dx,"CODE",{});var qfa=s(pLe);BQr=r(qfa,"model_type"),qfa.forEach(t),IQr=r(dx,` property of the config object (either
passed as an argument or loaded from `),_Le=n(dx,"CODE",{});var Dfa=s(_Le);NQr=r(Dfa,"pretrained_model_name_or_path"),Dfa.forEach(t),qQr=r(dx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bLe=n(dx,"CODE",{});var jfa=s(bLe);DQr=r(jfa,"pretrained_model_name_or_path"),jfa.forEach(t),jQr=r(dx,":"),dx.forEach(t),GQr=i(Ti),Me=n(Ti,"UL",{});var Ce=s(Me);cw=n(Ce,"LI",{});var NZe=s(cw);vLe=n(NZe,"STRONG",{});var Gfa=s(vLe);OQr=r(Gfa,"bert"),Gfa.forEach(t),VQr=r(NZe," \u2014 "),Xte=n(NZe,"A",{href:!0});var Ofa=s(Xte);XQr=r(Ofa,"TFBertLMHeadModel"),Ofa.forEach(t),zQr=r(NZe," (BERT model)"),NZe.forEach(t),QQr=i(Ce),fw=n(Ce,"LI",{});var qZe=s(fw);FLe=n(qZe,"STRONG",{});var Vfa=s(FLe);WQr=r(Vfa,"camembert"),Vfa.forEach(t),UQr=r(qZe," \u2014 "),zte=n(qZe,"A",{href:!0});var Xfa=s(zte);HQr=r(Xfa,"TFCamembertForCausalLM"),Xfa.forEach(t),JQr=r(qZe," (CamemBERT model)"),qZe.forEach(t),YQr=i(Ce),gw=n(Ce,"LI",{});var DZe=s(gw);TLe=n(DZe,"STRONG",{});var zfa=s(TLe);ZQr=r(zfa,"ctrl"),zfa.forEach(t),KQr=r(DZe," \u2014 "),Qte=n(DZe,"A",{href:!0});var Qfa=s(Qte);eWr=r(Qfa,"TFCTRLLMHeadModel"),Qfa.forEach(t),oWr=r(DZe," (CTRL model)"),DZe.forEach(t),rWr=i(Ce),hw=n(Ce,"LI",{});var jZe=s(hw);MLe=n(jZe,"STRONG",{});var Wfa=s(MLe);tWr=r(Wfa,"gpt2"),Wfa.forEach(t),aWr=r(jZe," \u2014 "),Wte=n(jZe,"A",{href:!0});var Ufa=s(Wte);nWr=r(Ufa,"TFGPT2LMHeadModel"),Ufa.forEach(t),sWr=r(jZe," (OpenAI GPT-2 model)"),jZe.forEach(t),lWr=i(Ce),uw=n(Ce,"LI",{});var GZe=s(uw);ELe=n(GZe,"STRONG",{});var Hfa=s(ELe);iWr=r(Hfa,"gptj"),Hfa.forEach(t),dWr=r(GZe," \u2014 "),Ute=n(GZe,"A",{href:!0});var Jfa=s(Ute);mWr=r(Jfa,"TFGPTJForCausalLM"),Jfa.forEach(t),cWr=r(GZe," (GPT-J model)"),GZe.forEach(t),fWr=i(Ce),pw=n(Ce,"LI",{});var OZe=s(pw);CLe=n(OZe,"STRONG",{});var Yfa=s(CLe);gWr=r(Yfa,"openai-gpt"),Yfa.forEach(t),hWr=r(OZe," \u2014 "),Hte=n(OZe,"A",{href:!0});var Zfa=s(Hte);uWr=r(Zfa,"TFOpenAIGPTLMHeadModel"),Zfa.forEach(t),pWr=r(OZe," (OpenAI GPT model)"),OZe.forEach(t),_Wr=i(Ce),_w=n(Ce,"LI",{});var VZe=s(_w);wLe=n(VZe,"STRONG",{});var Kfa=s(wLe);bWr=r(Kfa,"opt"),Kfa.forEach(t),vWr=r(VZe," \u2014 "),Jte=n(VZe,"A",{href:!0});var ega=s(Jte);FWr=r(ega,"TFOPTForCausalLM"),ega.forEach(t),TWr=r(VZe," (OPT model)"),VZe.forEach(t),MWr=i(Ce),bw=n(Ce,"LI",{});var XZe=s(bw);ALe=n(XZe,"STRONG",{});var oga=s(ALe);EWr=r(oga,"rembert"),oga.forEach(t),CWr=r(XZe," \u2014 "),Yte=n(XZe,"A",{href:!0});var rga=s(Yte);wWr=r(rga,"TFRemBertForCausalLM"),rga.forEach(t),AWr=r(XZe," (RemBERT model)"),XZe.forEach(t),LWr=i(Ce),vw=n(Ce,"LI",{});var zZe=s(vw);LLe=n(zZe,"STRONG",{});var tga=s(LLe);yWr=r(tga,"roberta"),tga.forEach(t),xWr=r(zZe," \u2014 "),Zte=n(zZe,"A",{href:!0});var aga=s(Zte);$Wr=r(aga,"TFRobertaForCausalLM"),aga.forEach(t),kWr=r(zZe," (RoBERTa model)"),zZe.forEach(t),SWr=i(Ce),Fw=n(Ce,"LI",{});var QZe=s(Fw);yLe=n(QZe,"STRONG",{});var nga=s(yLe);RWr=r(nga,"roformer"),nga.forEach(t),PWr=r(QZe," \u2014 "),Kte=n(QZe,"A",{href:!0});var sga=s(Kte);BWr=r(sga,"TFRoFormerForCausalLM"),sga.forEach(t),IWr=r(QZe," (RoFormer model)"),QZe.forEach(t),NWr=i(Ce),Tw=n(Ce,"LI",{});var WZe=s(Tw);xLe=n(WZe,"STRONG",{});var lga=s(xLe);qWr=r(lga,"transfo-xl"),lga.forEach(t),DWr=r(WZe," \u2014 "),eae=n(WZe,"A",{href:!0});var iga=s(eae);jWr=r(iga,"TFTransfoXLLMHeadModel"),iga.forEach(t),GWr=r(WZe," (Transformer-XL model)"),WZe.forEach(t),OWr=i(Ce),Mw=n(Ce,"LI",{});var UZe=s(Mw);$Le=n(UZe,"STRONG",{});var dga=s($Le);VWr=r(dga,"xglm"),dga.forEach(t),XWr=r(UZe," \u2014 "),oae=n(UZe,"A",{href:!0});var mga=s(oae);zWr=r(mga,"TFXGLMForCausalLM"),mga.forEach(t),QWr=r(UZe," (XGLM model)"),UZe.forEach(t),WWr=i(Ce),Ew=n(Ce,"LI",{});var HZe=s(Ew);kLe=n(HZe,"STRONG",{});var cga=s(kLe);UWr=r(cga,"xlm"),cga.forEach(t),HWr=r(HZe," \u2014 "),rae=n(HZe,"A",{href:!0});var fga=s(rae);JWr=r(fga,"TFXLMWithLMHeadModel"),fga.forEach(t),YWr=r(HZe," (XLM model)"),HZe.forEach(t),ZWr=i(Ce),Cw=n(Ce,"LI",{});var JZe=s(Cw);SLe=n(JZe,"STRONG",{});var gga=s(SLe);KWr=r(gga,"xlnet"),gga.forEach(t),eUr=r(JZe," \u2014 "),tae=n(JZe,"A",{href:!0});var hga=s(tae);oUr=r(hga,"TFXLNetLMHeadModel"),hga.forEach(t),rUr=r(JZe," (XLNet model)"),JZe.forEach(t),Ce.forEach(t),tUr=i(Ti),T(ww.$$.fragment,Ti),Ti.forEach(t),Fi.forEach(t),Jao=i(c),vc=n(c,"H2",{class:!0});var ulo=s(vc);Aw=n(ulo,"A",{id:!0,class:!0,href:!0});var uga=s(Aw);RLe=n(uga,"SPAN",{});var pga=s(RLe);T($R.$$.fragment,pga),pga.forEach(t),uga.forEach(t),aUr=i(ulo),PLe=n(ulo,"SPAN",{});var _ga=s(PLe);nUr=r(_ga,"TFAutoModelForImageClassification"),_ga.forEach(t),ulo.forEach(t),Yao=i(c),gr=n(c,"DIV",{class:!0});var Mi=s(gr);T(kR.$$.fragment,Mi),sUr=i(Mi),Fc=n(Mi,"P",{});var pce=s(Fc);lUr=r(pce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),aae=n(pce,"A",{href:!0});var bga=s(aae);iUr=r(bga,"from_pretrained()"),bga.forEach(t),dUr=r(pce," class method or the "),nae=n(pce,"A",{href:!0});var vga=s(nae);mUr=r(vga,"from_config()"),vga.forEach(t),cUr=r(pce,` class
method.`),pce.forEach(t),fUr=i(Mi),SR=n(Mi,"P",{});var plo=s(SR);gUr=r(plo,"This class cannot be instantiated directly using "),BLe=n(plo,"CODE",{});var Fga=s(BLe);hUr=r(Fga,"__init__()"),Fga.forEach(t),uUr=r(plo," (throws an error)."),plo.forEach(t),pUr=i(Mi),ea=n(Mi,"DIV",{class:!0});var mx=s(ea);T(RR.$$.fragment,mx),_Ur=i(mx),ILe=n(mx,"P",{});var Tga=s(ILe);bUr=r(Tga,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Tga.forEach(t),vUr=i(mx),Tc=n(mx,"P",{});var _ce=s(Tc);FUr=r(_ce,`Note:
Loading a model from its configuration file does `),NLe=n(_ce,"STRONG",{});var Mga=s(NLe);TUr=r(Mga,"not"),Mga.forEach(t),MUr=r(_ce,` load the model weights. It only affects the
model\u2019s configuration. Use `),sae=n(_ce,"A",{href:!0});var Ega=s(sae);EUr=r(Ega,"from_pretrained()"),Ega.forEach(t),CUr=r(_ce," to load the model weights."),_ce.forEach(t),wUr=i(mx),T(Lw.$$.fragment,mx),mx.forEach(t),AUr=i(Mi),Vr=n(Mi,"DIV",{class:!0});var Ei=s(Vr);T(PR.$$.fragment,Ei),LUr=i(Ei),qLe=n(Ei,"P",{});var Cga=s(qLe);yUr=r(Cga,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Cga.forEach(t),xUr=i(Ei),qn=n(Ei,"P",{});var cx=s(qn);$Ur=r(cx,"The model class to instantiate is selected based on the "),DLe=n(cx,"CODE",{});var wga=s(DLe);kUr=r(wga,"model_type"),wga.forEach(t),SUr=r(cx,` property of the config object (either
passed as an argument or loaded from `),jLe=n(cx,"CODE",{});var Aga=s(jLe);RUr=r(Aga,"pretrained_model_name_or_path"),Aga.forEach(t),PUr=r(cx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),GLe=n(cx,"CODE",{});var Lga=s(GLe);BUr=r(Lga,"pretrained_model_name_or_path"),Lga.forEach(t),IUr=r(cx,":"),cx.forEach(t),NUr=i(Ei),ye=n(Ei,"UL",{});var Ne=s(ye);yw=n(Ne,"LI",{});var YZe=s(yw);OLe=n(YZe,"STRONG",{});var yga=s(OLe);qUr=r(yga,"convnext"),yga.forEach(t),DUr=r(YZe," \u2014 "),lae=n(YZe,"A",{href:!0});var xga=s(lae);jUr=r(xga,"TFConvNextForImageClassification"),xga.forEach(t),GUr=r(YZe," (ConvNeXT model)"),YZe.forEach(t),OUr=i(Ne),xw=n(Ne,"LI",{});var ZZe=s(xw);VLe=n(ZZe,"STRONG",{});var $ga=s(VLe);VUr=r($ga,"cvt"),$ga.forEach(t),XUr=r(ZZe," \u2014 "),iae=n(ZZe,"A",{href:!0});var kga=s(iae);zUr=r(kga,"TFCvtForImageClassification"),kga.forEach(t),QUr=r(ZZe," (CvT model)"),ZZe.forEach(t),WUr=i(Ne),$w=n(Ne,"LI",{});var KZe=s($w);XLe=n(KZe,"STRONG",{});var Sga=s(XLe);UUr=r(Sga,"data2vec-vision"),Sga.forEach(t),HUr=r(KZe," \u2014 "),dae=n(KZe,"A",{href:!0});var Rga=s(dae);JUr=r(Rga,"TFData2VecVisionForImageClassification"),Rga.forEach(t),YUr=r(KZe," (Data2VecVision model)"),KZe.forEach(t),ZUr=i(Ne),Rl=n(Ne,"LI",{});var MN=s(Rl);zLe=n(MN,"STRONG",{});var Pga=s(zLe);KUr=r(Pga,"deit"),Pga.forEach(t),eHr=r(MN," \u2014 "),mae=n(MN,"A",{href:!0});var Bga=s(mae);oHr=r(Bga,"TFDeiTForImageClassification"),Bga.forEach(t),rHr=r(MN," or "),cae=n(MN,"A",{href:!0});var Iga=s(cae);tHr=r(Iga,"TFDeiTForImageClassificationWithTeacher"),Iga.forEach(t),aHr=r(MN," (DeiT model)"),MN.forEach(t),nHr=i(Ne),kw=n(Ne,"LI",{});var eKe=s(kw);QLe=n(eKe,"STRONG",{});var Nga=s(QLe);sHr=r(Nga,"mobilevit"),Nga.forEach(t),lHr=r(eKe," \u2014 "),fae=n(eKe,"A",{href:!0});var qga=s(fae);iHr=r(qga,"TFMobileViTForImageClassification"),qga.forEach(t),dHr=r(eKe," (MobileViT model)"),eKe.forEach(t),mHr=i(Ne),Sw=n(Ne,"LI",{});var oKe=s(Sw);WLe=n(oKe,"STRONG",{});var Dga=s(WLe);cHr=r(Dga,"regnet"),Dga.forEach(t),fHr=r(oKe," \u2014 "),gae=n(oKe,"A",{href:!0});var jga=s(gae);gHr=r(jga,"TFRegNetForImageClassification"),jga.forEach(t),hHr=r(oKe," (RegNet model)"),oKe.forEach(t),uHr=i(Ne),Rw=n(Ne,"LI",{});var rKe=s(Rw);ULe=n(rKe,"STRONG",{});var Gga=s(ULe);pHr=r(Gga,"resnet"),Gga.forEach(t),_Hr=r(rKe," \u2014 "),hae=n(rKe,"A",{href:!0});var Oga=s(hae);bHr=r(Oga,"TFResNetForImageClassification"),Oga.forEach(t),vHr=r(rKe," (ResNet model)"),rKe.forEach(t),FHr=i(Ne),Pw=n(Ne,"LI",{});var tKe=s(Pw);HLe=n(tKe,"STRONG",{});var Vga=s(HLe);THr=r(Vga,"segformer"),Vga.forEach(t),MHr=r(tKe," \u2014 "),uae=n(tKe,"A",{href:!0});var Xga=s(uae);EHr=r(Xga,"TFSegformerForImageClassification"),Xga.forEach(t),CHr=r(tKe," (SegFormer model)"),tKe.forEach(t),wHr=i(Ne),Bw=n(Ne,"LI",{});var aKe=s(Bw);JLe=n(aKe,"STRONG",{});var zga=s(JLe);AHr=r(zga,"swin"),zga.forEach(t),LHr=r(aKe," \u2014 "),pae=n(aKe,"A",{href:!0});var Qga=s(pae);yHr=r(Qga,"TFSwinForImageClassification"),Qga.forEach(t),xHr=r(aKe," (Swin Transformer model)"),aKe.forEach(t),$Hr=i(Ne),Iw=n(Ne,"LI",{});var nKe=s(Iw);YLe=n(nKe,"STRONG",{});var Wga=s(YLe);kHr=r(Wga,"vit"),Wga.forEach(t),SHr=r(nKe," \u2014 "),_ae=n(nKe,"A",{href:!0});var Uga=s(_ae);RHr=r(Uga,"TFViTForImageClassification"),Uga.forEach(t),PHr=r(nKe," (ViT model)"),nKe.forEach(t),Ne.forEach(t),BHr=i(Ei),T(Nw.$$.fragment,Ei),Ei.forEach(t),Mi.forEach(t),Zao=i(c),Mc=n(c,"H2",{class:!0});var _lo=s(Mc);qw=n(_lo,"A",{id:!0,class:!0,href:!0});var Hga=s(qw);ZLe=n(Hga,"SPAN",{});var Jga=s(ZLe);T(BR.$$.fragment,Jga),Jga.forEach(t),Hga.forEach(t),IHr=i(_lo),KLe=n(_lo,"SPAN",{});var Yga=s(KLe);NHr=r(Yga,"TFAutoModelForSemanticSegmentation"),Yga.forEach(t),_lo.forEach(t),Kao=i(c),hr=n(c,"DIV",{class:!0});var Ci=s(hr);T(IR.$$.fragment,Ci),qHr=i(Ci),Ec=n(Ci,"P",{});var bce=s(Ec);DHr=r(bce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),bae=n(bce,"A",{href:!0});var Zga=s(bae);jHr=r(Zga,"from_pretrained()"),Zga.forEach(t),GHr=r(bce," class method or the "),vae=n(bce,"A",{href:!0});var Kga=s(vae);OHr=r(Kga,"from_config()"),Kga.forEach(t),VHr=r(bce,` class
method.`),bce.forEach(t),XHr=i(Ci),NR=n(Ci,"P",{});var blo=s(NR);zHr=r(blo,"This class cannot be instantiated directly using "),eye=n(blo,"CODE",{});var eha=s(eye);QHr=r(eha,"__init__()"),eha.forEach(t),WHr=r(blo," (throws an error)."),blo.forEach(t),UHr=i(Ci),oa=n(Ci,"DIV",{class:!0});var fx=s(oa);T(qR.$$.fragment,fx),HHr=i(fx),oye=n(fx,"P",{});var oha=s(oye);JHr=r(oha,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),oha.forEach(t),YHr=i(fx),Cc=n(fx,"P",{});var vce=s(Cc);ZHr=r(vce,`Note:
Loading a model from its configuration file does `),rye=n(vce,"STRONG",{});var rha=s(rye);KHr=r(rha,"not"),rha.forEach(t),eJr=r(vce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Fae=n(vce,"A",{href:!0});var tha=s(Fae);oJr=r(tha,"from_pretrained()"),tha.forEach(t),rJr=r(vce," to load the model weights."),vce.forEach(t),tJr=i(fx),T(Dw.$$.fragment,fx),fx.forEach(t),aJr=i(Ci),Xr=n(Ci,"DIV",{class:!0});var wi=s(Xr);T(DR.$$.fragment,wi),nJr=i(wi),tye=n(wi,"P",{});var aha=s(tye);sJr=r(aha,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),aha.forEach(t),lJr=i(wi),Dn=n(wi,"P",{});var gx=s(Dn);iJr=r(gx,"The model class to instantiate is selected based on the "),aye=n(gx,"CODE",{});var nha=s(aye);dJr=r(nha,"model_type"),nha.forEach(t),mJr=r(gx,` property of the config object (either
passed as an argument or loaded from `),nye=n(gx,"CODE",{});var sha=s(nye);cJr=r(sha,"pretrained_model_name_or_path"),sha.forEach(t),fJr=r(gx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sye=n(gx,"CODE",{});var lha=s(sye);gJr=r(lha,"pretrained_model_name_or_path"),lha.forEach(t),hJr=r(gx,":"),gx.forEach(t),uJr=i(wi),wc=n(wi,"UL",{});var Fce=s(wc);jw=n(Fce,"LI",{});var sKe=s(jw);lye=n(sKe,"STRONG",{});var iha=s(lye);pJr=r(iha,"data2vec-vision"),iha.forEach(t),_Jr=r(sKe," \u2014 "),Tae=n(sKe,"A",{href:!0});var dha=s(Tae);bJr=r(dha,"TFData2VecVisionForSemanticSegmentation"),dha.forEach(t),vJr=r(sKe," (Data2VecVision model)"),sKe.forEach(t),FJr=i(Fce),Gw=n(Fce,"LI",{});var lKe=s(Gw);iye=n(lKe,"STRONG",{});var mha=s(iye);TJr=r(mha,"mobilevit"),mha.forEach(t),MJr=r(lKe," \u2014 "),Mae=n(lKe,"A",{href:!0});var cha=s(Mae);EJr=r(cha,"TFMobileViTForSemanticSegmentation"),cha.forEach(t),CJr=r(lKe," (MobileViT model)"),lKe.forEach(t),wJr=i(Fce),Ow=n(Fce,"LI",{});var iKe=s(Ow);dye=n(iKe,"STRONG",{});var fha=s(dye);AJr=r(fha,"segformer"),fha.forEach(t),LJr=r(iKe," \u2014 "),Eae=n(iKe,"A",{href:!0});var gha=s(Eae);yJr=r(gha,"TFSegformerForSemanticSegmentation"),gha.forEach(t),xJr=r(iKe," (SegFormer model)"),iKe.forEach(t),Fce.forEach(t),$Jr=i(wi),T(Vw.$$.fragment,wi),wi.forEach(t),Ci.forEach(t),eno=i(c),Ac=n(c,"H2",{class:!0});var vlo=s(Ac);Xw=n(vlo,"A",{id:!0,class:!0,href:!0});var hha=s(Xw);mye=n(hha,"SPAN",{});var uha=s(mye);T(jR.$$.fragment,uha),uha.forEach(t),hha.forEach(t),kJr=i(vlo),cye=n(vlo,"SPAN",{});var pha=s(cye);SJr=r(pha,"TFAutoModelForMaskedLM"),pha.forEach(t),vlo.forEach(t),ono=i(c),ur=n(c,"DIV",{class:!0});var Ai=s(ur);T(GR.$$.fragment,Ai),RJr=i(Ai),Lc=n(Ai,"P",{});var Tce=s(Lc);PJr=r(Tce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Cae=n(Tce,"A",{href:!0});var _ha=s(Cae);BJr=r(_ha,"from_pretrained()"),_ha.forEach(t),IJr=r(Tce," class method or the "),wae=n(Tce,"A",{href:!0});var bha=s(wae);NJr=r(bha,"from_config()"),bha.forEach(t),qJr=r(Tce,` class
method.`),Tce.forEach(t),DJr=i(Ai),OR=n(Ai,"P",{});var Flo=s(OR);jJr=r(Flo,"This class cannot be instantiated directly using "),fye=n(Flo,"CODE",{});var vha=s(fye);GJr=r(vha,"__init__()"),vha.forEach(t),OJr=r(Flo," (throws an error)."),Flo.forEach(t),VJr=i(Ai),ra=n(Ai,"DIV",{class:!0});var hx=s(ra);T(VR.$$.fragment,hx),XJr=i(hx),gye=n(hx,"P",{});var Fha=s(gye);zJr=r(Fha,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Fha.forEach(t),QJr=i(hx),yc=n(hx,"P",{});var Mce=s(yc);WJr=r(Mce,`Note:
Loading a model from its configuration file does `),hye=n(Mce,"STRONG",{});var Tha=s(hye);UJr=r(Tha,"not"),Tha.forEach(t),HJr=r(Mce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Aae=n(Mce,"A",{href:!0});var Mha=s(Aae);JJr=r(Mha,"from_pretrained()"),Mha.forEach(t),YJr=r(Mce," to load the model weights."),Mce.forEach(t),ZJr=i(hx),T(zw.$$.fragment,hx),hx.forEach(t),KJr=i(Ai),zr=n(Ai,"DIV",{class:!0});var Li=s(zr);T(XR.$$.fragment,Li),eYr=i(Li),uye=n(Li,"P",{});var Eha=s(uye);oYr=r(Eha,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Eha.forEach(t),rYr=i(Li),jn=n(Li,"P",{});var ux=s(jn);tYr=r(ux,"The model class to instantiate is selected based on the "),pye=n(ux,"CODE",{});var Cha=s(pye);aYr=r(Cha,"model_type"),Cha.forEach(t),nYr=r(ux,` property of the config object (either
passed as an argument or loaded from `),_ye=n(ux,"CODE",{});var wha=s(_ye);sYr=r(wha,"pretrained_model_name_or_path"),wha.forEach(t),lYr=r(ux,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bye=n(ux,"CODE",{});var Aha=s(bye);iYr=r(Aha,"pretrained_model_name_or_path"),Aha.forEach(t),dYr=r(ux,":"),ux.forEach(t),mYr=i(Li),ce=n(Li,"UL",{});var ue=s(ce);Qw=n(ue,"LI",{});var dKe=s(Qw);vye=n(dKe,"STRONG",{});var Lha=s(vye);cYr=r(Lha,"albert"),Lha.forEach(t),fYr=r(dKe," \u2014 "),Lae=n(dKe,"A",{href:!0});var yha=s(Lae);gYr=r(yha,"TFAlbertForMaskedLM"),yha.forEach(t),hYr=r(dKe," (ALBERT model)"),dKe.forEach(t),uYr=i(ue),Ww=n(ue,"LI",{});var mKe=s(Ww);Fye=n(mKe,"STRONG",{});var xha=s(Fye);pYr=r(xha,"bert"),xha.forEach(t),_Yr=r(mKe," \u2014 "),yae=n(mKe,"A",{href:!0});var $ha=s(yae);bYr=r($ha,"TFBertForMaskedLM"),$ha.forEach(t),vYr=r(mKe," (BERT model)"),mKe.forEach(t),FYr=i(ue),Uw=n(ue,"LI",{});var cKe=s(Uw);Tye=n(cKe,"STRONG",{});var kha=s(Tye);TYr=r(kha,"camembert"),kha.forEach(t),MYr=r(cKe," \u2014 "),xae=n(cKe,"A",{href:!0});var Sha=s(xae);EYr=r(Sha,"TFCamembertForMaskedLM"),Sha.forEach(t),CYr=r(cKe," (CamemBERT model)"),cKe.forEach(t),wYr=i(ue),Hw=n(ue,"LI",{});var fKe=s(Hw);Mye=n(fKe,"STRONG",{});var Rha=s(Mye);AYr=r(Rha,"convbert"),Rha.forEach(t),LYr=r(fKe," \u2014 "),$ae=n(fKe,"A",{href:!0});var Pha=s($ae);yYr=r(Pha,"TFConvBertForMaskedLM"),Pha.forEach(t),xYr=r(fKe," (ConvBERT model)"),fKe.forEach(t),$Yr=i(ue),Jw=n(ue,"LI",{});var gKe=s(Jw);Eye=n(gKe,"STRONG",{});var Bha=s(Eye);kYr=r(Bha,"deberta"),Bha.forEach(t),SYr=r(gKe," \u2014 "),kae=n(gKe,"A",{href:!0});var Iha=s(kae);RYr=r(Iha,"TFDebertaForMaskedLM"),Iha.forEach(t),PYr=r(gKe," (DeBERTa model)"),gKe.forEach(t),BYr=i(ue),Yw=n(ue,"LI",{});var hKe=s(Yw);Cye=n(hKe,"STRONG",{});var Nha=s(Cye);IYr=r(Nha,"deberta-v2"),Nha.forEach(t),NYr=r(hKe," \u2014 "),Sae=n(hKe,"A",{href:!0});var qha=s(Sae);qYr=r(qha,"TFDebertaV2ForMaskedLM"),qha.forEach(t),DYr=r(hKe," (DeBERTa-v2 model)"),hKe.forEach(t),jYr=i(ue),Zw=n(ue,"LI",{});var uKe=s(Zw);wye=n(uKe,"STRONG",{});var Dha=s(wye);GYr=r(Dha,"distilbert"),Dha.forEach(t),OYr=r(uKe," \u2014 "),Rae=n(uKe,"A",{href:!0});var jha=s(Rae);VYr=r(jha,"TFDistilBertForMaskedLM"),jha.forEach(t),XYr=r(uKe," (DistilBERT model)"),uKe.forEach(t),zYr=i(ue),Kw=n(ue,"LI",{});var pKe=s(Kw);Aye=n(pKe,"STRONG",{});var Gha=s(Aye);QYr=r(Gha,"electra"),Gha.forEach(t),WYr=r(pKe," \u2014 "),Pae=n(pKe,"A",{href:!0});var Oha=s(Pae);UYr=r(Oha,"TFElectraForMaskedLM"),Oha.forEach(t),HYr=r(pKe," (ELECTRA model)"),pKe.forEach(t),JYr=i(ue),eA=n(ue,"LI",{});var _Ke=s(eA);Lye=n(_Ke,"STRONG",{});var Vha=s(Lye);YYr=r(Vha,"esm"),Vha.forEach(t),ZYr=r(_Ke," \u2014 "),Bae=n(_Ke,"A",{href:!0});var Xha=s(Bae);KYr=r(Xha,"TFEsmForMaskedLM"),Xha.forEach(t),eZr=r(_Ke," (ESM model)"),_Ke.forEach(t),oZr=i(ue),oA=n(ue,"LI",{});var bKe=s(oA);yye=n(bKe,"STRONG",{});var zha=s(yye);rZr=r(zha,"flaubert"),zha.forEach(t),tZr=r(bKe," \u2014 "),Iae=n(bKe,"A",{href:!0});var Qha=s(Iae);aZr=r(Qha,"TFFlaubertWithLMHeadModel"),Qha.forEach(t),nZr=r(bKe," (FlauBERT model)"),bKe.forEach(t),sZr=i(ue),rA=n(ue,"LI",{});var vKe=s(rA);xye=n(vKe,"STRONG",{});var Wha=s(xye);lZr=r(Wha,"funnel"),Wha.forEach(t),iZr=r(vKe," \u2014 "),Nae=n(vKe,"A",{href:!0});var Uha=s(Nae);dZr=r(Uha,"TFFunnelForMaskedLM"),Uha.forEach(t),mZr=r(vKe," (Funnel Transformer model)"),vKe.forEach(t),cZr=i(ue),tA=n(ue,"LI",{});var FKe=s(tA);$ye=n(FKe,"STRONG",{});var Hha=s($ye);fZr=r(Hha,"layoutlm"),Hha.forEach(t),gZr=r(FKe," \u2014 "),qae=n(FKe,"A",{href:!0});var Jha=s(qae);hZr=r(Jha,"TFLayoutLMForMaskedLM"),Jha.forEach(t),uZr=r(FKe," (LayoutLM model)"),FKe.forEach(t),pZr=i(ue),aA=n(ue,"LI",{});var TKe=s(aA);kye=n(TKe,"STRONG",{});var Yha=s(kye);_Zr=r(Yha,"longformer"),Yha.forEach(t),bZr=r(TKe," \u2014 "),Dae=n(TKe,"A",{href:!0});var Zha=s(Dae);vZr=r(Zha,"TFLongformerForMaskedLM"),Zha.forEach(t),FZr=r(TKe," (Longformer model)"),TKe.forEach(t),TZr=i(ue),nA=n(ue,"LI",{});var MKe=s(nA);Sye=n(MKe,"STRONG",{});var Kha=s(Sye);MZr=r(Kha,"mobilebert"),Kha.forEach(t),EZr=r(MKe," \u2014 "),jae=n(MKe,"A",{href:!0});var eua=s(jae);CZr=r(eua,"TFMobileBertForMaskedLM"),eua.forEach(t),wZr=r(MKe," (MobileBERT model)"),MKe.forEach(t),AZr=i(ue),sA=n(ue,"LI",{});var EKe=s(sA);Rye=n(EKe,"STRONG",{});var oua=s(Rye);LZr=r(oua,"mpnet"),oua.forEach(t),yZr=r(EKe," \u2014 "),Gae=n(EKe,"A",{href:!0});var rua=s(Gae);xZr=r(rua,"TFMPNetForMaskedLM"),rua.forEach(t),$Zr=r(EKe," (MPNet model)"),EKe.forEach(t),kZr=i(ue),lA=n(ue,"LI",{});var CKe=s(lA);Pye=n(CKe,"STRONG",{});var tua=s(Pye);SZr=r(tua,"rembert"),tua.forEach(t),RZr=r(CKe," \u2014 "),Oae=n(CKe,"A",{href:!0});var aua=s(Oae);PZr=r(aua,"TFRemBertForMaskedLM"),aua.forEach(t),BZr=r(CKe," (RemBERT model)"),CKe.forEach(t),IZr=i(ue),iA=n(ue,"LI",{});var wKe=s(iA);Bye=n(wKe,"STRONG",{});var nua=s(Bye);NZr=r(nua,"roberta"),nua.forEach(t),qZr=r(wKe," \u2014 "),Vae=n(wKe,"A",{href:!0});var sua=s(Vae);DZr=r(sua,"TFRobertaForMaskedLM"),sua.forEach(t),jZr=r(wKe," (RoBERTa model)"),wKe.forEach(t),GZr=i(ue),dA=n(ue,"LI",{});var AKe=s(dA);Iye=n(AKe,"STRONG",{});var lua=s(Iye);OZr=r(lua,"roformer"),lua.forEach(t),VZr=r(AKe," \u2014 "),Xae=n(AKe,"A",{href:!0});var iua=s(Xae);XZr=r(iua,"TFRoFormerForMaskedLM"),iua.forEach(t),zZr=r(AKe," (RoFormer model)"),AKe.forEach(t),QZr=i(ue),mA=n(ue,"LI",{});var LKe=s(mA);Nye=n(LKe,"STRONG",{});var dua=s(Nye);WZr=r(dua,"tapas"),dua.forEach(t),UZr=r(LKe," \u2014 "),zae=n(LKe,"A",{href:!0});var mua=s(zae);HZr=r(mua,"TFTapasForMaskedLM"),mua.forEach(t),JZr=r(LKe," (TAPAS model)"),LKe.forEach(t),YZr=i(ue),cA=n(ue,"LI",{});var yKe=s(cA);qye=n(yKe,"STRONG",{});var cua=s(qye);ZZr=r(cua,"xlm"),cua.forEach(t),KZr=r(yKe," \u2014 "),Qae=n(yKe,"A",{href:!0});var fua=s(Qae);eKr=r(fua,"TFXLMWithLMHeadModel"),fua.forEach(t),oKr=r(yKe," (XLM model)"),yKe.forEach(t),rKr=i(ue),fA=n(ue,"LI",{});var xKe=s(fA);Dye=n(xKe,"STRONG",{});var gua=s(Dye);tKr=r(gua,"xlm-roberta"),gua.forEach(t),aKr=r(xKe," \u2014 "),Wae=n(xKe,"A",{href:!0});var hua=s(Wae);nKr=r(hua,"TFXLMRobertaForMaskedLM"),hua.forEach(t),sKr=r(xKe," (XLM-RoBERTa model)"),xKe.forEach(t),ue.forEach(t),lKr=i(Li),T(gA.$$.fragment,Li),Li.forEach(t),Ai.forEach(t),rno=i(c),xc=n(c,"H2",{class:!0});var Tlo=s(xc);hA=n(Tlo,"A",{id:!0,class:!0,href:!0});var uua=s(hA);jye=n(uua,"SPAN",{});var pua=s(jye);T(zR.$$.fragment,pua),pua.forEach(t),uua.forEach(t),iKr=i(Tlo),Gye=n(Tlo,"SPAN",{});var _ua=s(Gye);dKr=r(_ua,"TFAutoModelForSeq2SeqLM"),_ua.forEach(t),Tlo.forEach(t),tno=i(c),pr=n(c,"DIV",{class:!0});var yi=s(pr);T(QR.$$.fragment,yi),mKr=i(yi),$c=n(yi,"P",{});var Ece=s($c);cKr=r(Ece,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Uae=n(Ece,"A",{href:!0});var bua=s(Uae);fKr=r(bua,"from_pretrained()"),bua.forEach(t),gKr=r(Ece," class method or the "),Hae=n(Ece,"A",{href:!0});var vua=s(Hae);hKr=r(vua,"from_config()"),vua.forEach(t),uKr=r(Ece,` class
method.`),Ece.forEach(t),pKr=i(yi),WR=n(yi,"P",{});var Mlo=s(WR);_Kr=r(Mlo,"This class cannot be instantiated directly using "),Oye=n(Mlo,"CODE",{});var Fua=s(Oye);bKr=r(Fua,"__init__()"),Fua.forEach(t),vKr=r(Mlo," (throws an error)."),Mlo.forEach(t),FKr=i(yi),ta=n(yi,"DIV",{class:!0});var px=s(ta);T(UR.$$.fragment,px),TKr=i(px),Vye=n(px,"P",{});var Tua=s(Vye);MKr=r(Tua,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Tua.forEach(t),EKr=i(px),kc=n(px,"P",{});var Cce=s(kc);CKr=r(Cce,`Note:
Loading a model from its configuration file does `),Xye=n(Cce,"STRONG",{});var Mua=s(Xye);wKr=r(Mua,"not"),Mua.forEach(t),AKr=r(Cce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Jae=n(Cce,"A",{href:!0});var Eua=s(Jae);LKr=r(Eua,"from_pretrained()"),Eua.forEach(t),yKr=r(Cce," to load the model weights."),Cce.forEach(t),xKr=i(px),T(uA.$$.fragment,px),px.forEach(t),$Kr=i(yi),Qr=n(yi,"DIV",{class:!0});var xi=s(Qr);T(HR.$$.fragment,xi),kKr=i(xi),zye=n(xi,"P",{});var Cua=s(zye);SKr=r(Cua,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Cua.forEach(t),RKr=i(xi),Gn=n(xi,"P",{});var _x=s(Gn);PKr=r(_x,"The model class to instantiate is selected based on the "),Qye=n(_x,"CODE",{});var wua=s(Qye);BKr=r(wua,"model_type"),wua.forEach(t),IKr=r(_x,` property of the config object (either
passed as an argument or loaded from `),Wye=n(_x,"CODE",{});var Aua=s(Wye);NKr=r(Aua,"pretrained_model_name_or_path"),Aua.forEach(t),qKr=r(_x,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Uye=n(_x,"CODE",{});var Lua=s(Uye);DKr=r(Lua,"pretrained_model_name_or_path"),Lua.forEach(t),jKr=r(_x,":"),_x.forEach(t),GKr=i(xi),xe=n(xi,"UL",{});var qe=s(xe);pA=n(qe,"LI",{});var $Ke=s(pA);Hye=n($Ke,"STRONG",{});var yua=s(Hye);OKr=r(yua,"bart"),yua.forEach(t),VKr=r($Ke," \u2014 "),Yae=n($Ke,"A",{href:!0});var xua=s(Yae);XKr=r(xua,"TFBartForConditionalGeneration"),xua.forEach(t),zKr=r($Ke," (BART model)"),$Ke.forEach(t),QKr=i(qe),_A=n(qe,"LI",{});var kKe=s(_A);Jye=n(kKe,"STRONG",{});var $ua=s(Jye);WKr=r($ua,"blenderbot"),$ua.forEach(t),UKr=r(kKe," \u2014 "),Zae=n(kKe,"A",{href:!0});var kua=s(Zae);HKr=r(kua,"TFBlenderbotForConditionalGeneration"),kua.forEach(t),JKr=r(kKe," (Blenderbot model)"),kKe.forEach(t),YKr=i(qe),bA=n(qe,"LI",{});var SKe=s(bA);Yye=n(SKe,"STRONG",{});var Sua=s(Yye);ZKr=r(Sua,"blenderbot-small"),Sua.forEach(t),KKr=r(SKe," \u2014 "),Kae=n(SKe,"A",{href:!0});var Rua=s(Kae);eet=r(Rua,"TFBlenderbotSmallForConditionalGeneration"),Rua.forEach(t),oet=r(SKe," (BlenderbotSmall model)"),SKe.forEach(t),ret=i(qe),vA=n(qe,"LI",{});var RKe=s(vA);Zye=n(RKe,"STRONG",{});var Pua=s(Zye);tet=r(Pua,"encoder-decoder"),Pua.forEach(t),aet=r(RKe," \u2014 "),ene=n(RKe,"A",{href:!0});var Bua=s(ene);net=r(Bua,"TFEncoderDecoderModel"),Bua.forEach(t),set=r(RKe," (Encoder decoder model)"),RKe.forEach(t),iet=i(qe),FA=n(qe,"LI",{});var PKe=s(FA);Kye=n(PKe,"STRONG",{});var Iua=s(Kye);det=r(Iua,"led"),Iua.forEach(t),met=r(PKe," \u2014 "),one=n(PKe,"A",{href:!0});var Nua=s(one);cet=r(Nua,"TFLEDForConditionalGeneration"),Nua.forEach(t),fet=r(PKe," (LED model)"),PKe.forEach(t),get=i(qe),TA=n(qe,"LI",{});var BKe=s(TA);e9e=n(BKe,"STRONG",{});var qua=s(e9e);het=r(qua,"marian"),qua.forEach(t),uet=r(BKe," \u2014 "),rne=n(BKe,"A",{href:!0});var Dua=s(rne);pet=r(Dua,"TFMarianMTModel"),Dua.forEach(t),_et=r(BKe," (Marian model)"),BKe.forEach(t),bet=i(qe),MA=n(qe,"LI",{});var IKe=s(MA);o9e=n(IKe,"STRONG",{});var jua=s(o9e);vet=r(jua,"mbart"),jua.forEach(t),Fet=r(IKe," \u2014 "),tne=n(IKe,"A",{href:!0});var Gua=s(tne);Tet=r(Gua,"TFMBartForConditionalGeneration"),Gua.forEach(t),Met=r(IKe," (mBART model)"),IKe.forEach(t),Eet=i(qe),EA=n(qe,"LI",{});var NKe=s(EA);r9e=n(NKe,"STRONG",{});var Oua=s(r9e);Cet=r(Oua,"mt5"),Oua.forEach(t),wet=r(NKe," \u2014 "),ane=n(NKe,"A",{href:!0});var Vua=s(ane);Aet=r(Vua,"TFMT5ForConditionalGeneration"),Vua.forEach(t),Let=r(NKe," (MT5 model)"),NKe.forEach(t),yet=i(qe),CA=n(qe,"LI",{});var qKe=s(CA);t9e=n(qKe,"STRONG",{});var Xua=s(t9e);xet=r(Xua,"pegasus"),Xua.forEach(t),$et=r(qKe," \u2014 "),nne=n(qKe,"A",{href:!0});var zua=s(nne);ket=r(zua,"TFPegasusForConditionalGeneration"),zua.forEach(t),Set=r(qKe," (Pegasus model)"),qKe.forEach(t),Ret=i(qe),wA=n(qe,"LI",{});var DKe=s(wA);a9e=n(DKe,"STRONG",{});var Qua=s(a9e);Pet=r(Qua,"t5"),Qua.forEach(t),Bet=r(DKe," \u2014 "),sne=n(DKe,"A",{href:!0});var Wua=s(sne);Iet=r(Wua,"TFT5ForConditionalGeneration"),Wua.forEach(t),Net=r(DKe," (T5 model)"),DKe.forEach(t),qe.forEach(t),qet=i(xi),T(AA.$$.fragment,xi),xi.forEach(t),yi.forEach(t),ano=i(c),Sc=n(c,"H2",{class:!0});var Elo=s(Sc);LA=n(Elo,"A",{id:!0,class:!0,href:!0});var Uua=s(LA);n9e=n(Uua,"SPAN",{});var Hua=s(n9e);T(JR.$$.fragment,Hua),Hua.forEach(t),Uua.forEach(t),Det=i(Elo),s9e=n(Elo,"SPAN",{});var Jua=s(s9e);jet=r(Jua,"TFAutoModelForSequenceClassification"),Jua.forEach(t),Elo.forEach(t),nno=i(c),_r=n(c,"DIV",{class:!0});var $i=s(_r);T(YR.$$.fragment,$i),Get=i($i),Rc=n($i,"P",{});var wce=s(Rc);Oet=r(wce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),lne=n(wce,"A",{href:!0});var Yua=s(lne);Vet=r(Yua,"from_pretrained()"),Yua.forEach(t),Xet=r(wce," class method or the "),ine=n(wce,"A",{href:!0});var Zua=s(ine);zet=r(Zua,"from_config()"),Zua.forEach(t),Qet=r(wce,` class
method.`),wce.forEach(t),Wet=i($i),ZR=n($i,"P",{});var Clo=s(ZR);Uet=r(Clo,"This class cannot be instantiated directly using "),l9e=n(Clo,"CODE",{});var Kua=s(l9e);Het=r(Kua,"__init__()"),Kua.forEach(t),Jet=r(Clo," (throws an error)."),Clo.forEach(t),Yet=i($i),aa=n($i,"DIV",{class:!0});var bx=s(aa);T(KR.$$.fragment,bx),Zet=i(bx),i9e=n(bx,"P",{});var epa=s(i9e);Ket=r(epa,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),epa.forEach(t),eot=i(bx),Pc=n(bx,"P",{});var Ace=s(Pc);oot=r(Ace,`Note:
Loading a model from its configuration file does `),d9e=n(Ace,"STRONG",{});var opa=s(d9e);rot=r(opa,"not"),opa.forEach(t),tot=r(Ace,` load the model weights. It only affects the
model\u2019s configuration. Use `),dne=n(Ace,"A",{href:!0});var rpa=s(dne);aot=r(rpa,"from_pretrained()"),rpa.forEach(t),not=r(Ace," to load the model weights."),Ace.forEach(t),sot=i(bx),T(yA.$$.fragment,bx),bx.forEach(t),lot=i($i),Wr=n($i,"DIV",{class:!0});var ki=s(Wr);T(eP.$$.fragment,ki),iot=i(ki),m9e=n(ki,"P",{});var tpa=s(m9e);dot=r(tpa,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),tpa.forEach(t),mot=i(ki),On=n(ki,"P",{});var vx=s(On);cot=r(vx,"The model class to instantiate is selected based on the "),c9e=n(vx,"CODE",{});var apa=s(c9e);fot=r(apa,"model_type"),apa.forEach(t),got=r(vx,` property of the config object (either
passed as an argument or loaded from `),f9e=n(vx,"CODE",{});var npa=s(f9e);hot=r(npa,"pretrained_model_name_or_path"),npa.forEach(t),uot=r(vx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g9e=n(vx,"CODE",{});var spa=s(g9e);pot=r(spa,"pretrained_model_name_or_path"),spa.forEach(t),_ot=r(vx,":"),vx.forEach(t),bot=i(ki),re=n(ki,"UL",{});var ae=s(re);xA=n(ae,"LI",{});var jKe=s(xA);h9e=n(jKe,"STRONG",{});var lpa=s(h9e);vot=r(lpa,"albert"),lpa.forEach(t),Fot=r(jKe," \u2014 "),mne=n(jKe,"A",{href:!0});var ipa=s(mne);Tot=r(ipa,"TFAlbertForSequenceClassification"),ipa.forEach(t),Mot=r(jKe," (ALBERT model)"),jKe.forEach(t),Eot=i(ae),$A=n(ae,"LI",{});var GKe=s($A);u9e=n(GKe,"STRONG",{});var dpa=s(u9e);Cot=r(dpa,"bert"),dpa.forEach(t),wot=r(GKe," \u2014 "),cne=n(GKe,"A",{href:!0});var mpa=s(cne);Aot=r(mpa,"TFBertForSequenceClassification"),mpa.forEach(t),Lot=r(GKe," (BERT model)"),GKe.forEach(t),yot=i(ae),kA=n(ae,"LI",{});var OKe=s(kA);p9e=n(OKe,"STRONG",{});var cpa=s(p9e);xot=r(cpa,"camembert"),cpa.forEach(t),$ot=r(OKe," \u2014 "),fne=n(OKe,"A",{href:!0});var fpa=s(fne);kot=r(fpa,"TFCamembertForSequenceClassification"),fpa.forEach(t),Sot=r(OKe," (CamemBERT model)"),OKe.forEach(t),Rot=i(ae),SA=n(ae,"LI",{});var VKe=s(SA);_9e=n(VKe,"STRONG",{});var gpa=s(_9e);Pot=r(gpa,"convbert"),gpa.forEach(t),Bot=r(VKe," \u2014 "),gne=n(VKe,"A",{href:!0});var hpa=s(gne);Iot=r(hpa,"TFConvBertForSequenceClassification"),hpa.forEach(t),Not=r(VKe," (ConvBERT model)"),VKe.forEach(t),qot=i(ae),RA=n(ae,"LI",{});var XKe=s(RA);b9e=n(XKe,"STRONG",{});var upa=s(b9e);Dot=r(upa,"ctrl"),upa.forEach(t),jot=r(XKe," \u2014 "),hne=n(XKe,"A",{href:!0});var ppa=s(hne);Got=r(ppa,"TFCTRLForSequenceClassification"),ppa.forEach(t),Oot=r(XKe," (CTRL model)"),XKe.forEach(t),Vot=i(ae),PA=n(ae,"LI",{});var zKe=s(PA);v9e=n(zKe,"STRONG",{});var _pa=s(v9e);Xot=r(_pa,"deberta"),_pa.forEach(t),zot=r(zKe," \u2014 "),une=n(zKe,"A",{href:!0});var bpa=s(une);Qot=r(bpa,"TFDebertaForSequenceClassification"),bpa.forEach(t),Wot=r(zKe," (DeBERTa model)"),zKe.forEach(t),Uot=i(ae),BA=n(ae,"LI",{});var QKe=s(BA);F9e=n(QKe,"STRONG",{});var vpa=s(F9e);Hot=r(vpa,"deberta-v2"),vpa.forEach(t),Jot=r(QKe," \u2014 "),pne=n(QKe,"A",{href:!0});var Fpa=s(pne);Yot=r(Fpa,"TFDebertaV2ForSequenceClassification"),Fpa.forEach(t),Zot=r(QKe," (DeBERTa-v2 model)"),QKe.forEach(t),Kot=i(ae),IA=n(ae,"LI",{});var WKe=s(IA);T9e=n(WKe,"STRONG",{});var Tpa=s(T9e);ert=r(Tpa,"distilbert"),Tpa.forEach(t),ort=r(WKe," \u2014 "),_ne=n(WKe,"A",{href:!0});var Mpa=s(_ne);rrt=r(Mpa,"TFDistilBertForSequenceClassification"),Mpa.forEach(t),trt=r(WKe," (DistilBERT model)"),WKe.forEach(t),art=i(ae),NA=n(ae,"LI",{});var UKe=s(NA);M9e=n(UKe,"STRONG",{});var Epa=s(M9e);nrt=r(Epa,"electra"),Epa.forEach(t),srt=r(UKe," \u2014 "),bne=n(UKe,"A",{href:!0});var Cpa=s(bne);lrt=r(Cpa,"TFElectraForSequenceClassification"),Cpa.forEach(t),irt=r(UKe," (ELECTRA model)"),UKe.forEach(t),drt=i(ae),qA=n(ae,"LI",{});var HKe=s(qA);E9e=n(HKe,"STRONG",{});var wpa=s(E9e);mrt=r(wpa,"esm"),wpa.forEach(t),crt=r(HKe," \u2014 "),vne=n(HKe,"A",{href:!0});var Apa=s(vne);frt=r(Apa,"TFEsmForSequenceClassification"),Apa.forEach(t),grt=r(HKe," (ESM model)"),HKe.forEach(t),hrt=i(ae),DA=n(ae,"LI",{});var JKe=s(DA);C9e=n(JKe,"STRONG",{});var Lpa=s(C9e);urt=r(Lpa,"flaubert"),Lpa.forEach(t),prt=r(JKe," \u2014 "),Fne=n(JKe,"A",{href:!0});var ypa=s(Fne);_rt=r(ypa,"TFFlaubertForSequenceClassification"),ypa.forEach(t),brt=r(JKe," (FlauBERT model)"),JKe.forEach(t),vrt=i(ae),jA=n(ae,"LI",{});var YKe=s(jA);w9e=n(YKe,"STRONG",{});var xpa=s(w9e);Frt=r(xpa,"funnel"),xpa.forEach(t),Trt=r(YKe," \u2014 "),Tne=n(YKe,"A",{href:!0});var $pa=s(Tne);Mrt=r($pa,"TFFunnelForSequenceClassification"),$pa.forEach(t),Ert=r(YKe," (Funnel Transformer model)"),YKe.forEach(t),Crt=i(ae),GA=n(ae,"LI",{});var ZKe=s(GA);A9e=n(ZKe,"STRONG",{});var kpa=s(A9e);wrt=r(kpa,"gpt2"),kpa.forEach(t),Art=r(ZKe," \u2014 "),Mne=n(ZKe,"A",{href:!0});var Spa=s(Mne);Lrt=r(Spa,"TFGPT2ForSequenceClassification"),Spa.forEach(t),yrt=r(ZKe," (OpenAI GPT-2 model)"),ZKe.forEach(t),xrt=i(ae),OA=n(ae,"LI",{});var KKe=s(OA);L9e=n(KKe,"STRONG",{});var Rpa=s(L9e);$rt=r(Rpa,"gptj"),Rpa.forEach(t),krt=r(KKe," \u2014 "),Ene=n(KKe,"A",{href:!0});var Ppa=s(Ene);Srt=r(Ppa,"TFGPTJForSequenceClassification"),Ppa.forEach(t),Rrt=r(KKe," (GPT-J model)"),KKe.forEach(t),Prt=i(ae),VA=n(ae,"LI",{});var eeo=s(VA);y9e=n(eeo,"STRONG",{});var Bpa=s(y9e);Brt=r(Bpa,"layoutlm"),Bpa.forEach(t),Irt=r(eeo," \u2014 "),Cne=n(eeo,"A",{href:!0});var Ipa=s(Cne);Nrt=r(Ipa,"TFLayoutLMForSequenceClassification"),Ipa.forEach(t),qrt=r(eeo," (LayoutLM model)"),eeo.forEach(t),Drt=i(ae),XA=n(ae,"LI",{});var oeo=s(XA);x9e=n(oeo,"STRONG",{});var Npa=s(x9e);jrt=r(Npa,"layoutlmv3"),Npa.forEach(t),Grt=r(oeo," \u2014 "),wne=n(oeo,"A",{href:!0});var qpa=s(wne);Ort=r(qpa,"TFLayoutLMv3ForSequenceClassification"),qpa.forEach(t),Vrt=r(oeo," (LayoutLMv3 model)"),oeo.forEach(t),Xrt=i(ae),zA=n(ae,"LI",{});var reo=s(zA);$9e=n(reo,"STRONG",{});var Dpa=s($9e);zrt=r(Dpa,"longformer"),Dpa.forEach(t),Qrt=r(reo," \u2014 "),Ane=n(reo,"A",{href:!0});var jpa=s(Ane);Wrt=r(jpa,"TFLongformerForSequenceClassification"),jpa.forEach(t),Urt=r(reo," (Longformer model)"),reo.forEach(t),Hrt=i(ae),QA=n(ae,"LI",{});var teo=s(QA);k9e=n(teo,"STRONG",{});var Gpa=s(k9e);Jrt=r(Gpa,"mobilebert"),Gpa.forEach(t),Yrt=r(teo," \u2014 "),Lne=n(teo,"A",{href:!0});var Opa=s(Lne);Zrt=r(Opa,"TFMobileBertForSequenceClassification"),Opa.forEach(t),Krt=r(teo," (MobileBERT model)"),teo.forEach(t),ett=i(ae),WA=n(ae,"LI",{});var aeo=s(WA);S9e=n(aeo,"STRONG",{});var Vpa=s(S9e);ott=r(Vpa,"mpnet"),Vpa.forEach(t),rtt=r(aeo," \u2014 "),yne=n(aeo,"A",{href:!0});var Xpa=s(yne);ttt=r(Xpa,"TFMPNetForSequenceClassification"),Xpa.forEach(t),att=r(aeo," (MPNet model)"),aeo.forEach(t),ntt=i(ae),UA=n(ae,"LI",{});var neo=s(UA);R9e=n(neo,"STRONG",{});var zpa=s(R9e);stt=r(zpa,"openai-gpt"),zpa.forEach(t),ltt=r(neo," \u2014 "),xne=n(neo,"A",{href:!0});var Qpa=s(xne);itt=r(Qpa,"TFOpenAIGPTForSequenceClassification"),Qpa.forEach(t),dtt=r(neo," (OpenAI GPT model)"),neo.forEach(t),mtt=i(ae),HA=n(ae,"LI",{});var seo=s(HA);P9e=n(seo,"STRONG",{});var Wpa=s(P9e);ctt=r(Wpa,"rembert"),Wpa.forEach(t),ftt=r(seo," \u2014 "),$ne=n(seo,"A",{href:!0});var Upa=s($ne);gtt=r(Upa,"TFRemBertForSequenceClassification"),Upa.forEach(t),htt=r(seo," (RemBERT model)"),seo.forEach(t),utt=i(ae),JA=n(ae,"LI",{});var leo=s(JA);B9e=n(leo,"STRONG",{});var Hpa=s(B9e);ptt=r(Hpa,"roberta"),Hpa.forEach(t),_tt=r(leo," \u2014 "),kne=n(leo,"A",{href:!0});var Jpa=s(kne);btt=r(Jpa,"TFRobertaForSequenceClassification"),Jpa.forEach(t),vtt=r(leo," (RoBERTa model)"),leo.forEach(t),Ftt=i(ae),YA=n(ae,"LI",{});var ieo=s(YA);I9e=n(ieo,"STRONG",{});var Ypa=s(I9e);Ttt=r(Ypa,"roformer"),Ypa.forEach(t),Mtt=r(ieo," \u2014 "),Sne=n(ieo,"A",{href:!0});var Zpa=s(Sne);Ett=r(Zpa,"TFRoFormerForSequenceClassification"),Zpa.forEach(t),Ctt=r(ieo," (RoFormer model)"),ieo.forEach(t),wtt=i(ae),ZA=n(ae,"LI",{});var deo=s(ZA);N9e=n(deo,"STRONG",{});var Kpa=s(N9e);Att=r(Kpa,"tapas"),Kpa.forEach(t),Ltt=r(deo," \u2014 "),Rne=n(deo,"A",{href:!0});var e_a=s(Rne);ytt=r(e_a,"TFTapasForSequenceClassification"),e_a.forEach(t),xtt=r(deo," (TAPAS model)"),deo.forEach(t),$tt=i(ae),KA=n(ae,"LI",{});var meo=s(KA);q9e=n(meo,"STRONG",{});var o_a=s(q9e);ktt=r(o_a,"transfo-xl"),o_a.forEach(t),Stt=r(meo," \u2014 "),Pne=n(meo,"A",{href:!0});var r_a=s(Pne);Rtt=r(r_a,"TFTransfoXLForSequenceClassification"),r_a.forEach(t),Ptt=r(meo," (Transformer-XL model)"),meo.forEach(t),Btt=i(ae),e6=n(ae,"LI",{});var ceo=s(e6);D9e=n(ceo,"STRONG",{});var t_a=s(D9e);Itt=r(t_a,"xlm"),t_a.forEach(t),Ntt=r(ceo," \u2014 "),Bne=n(ceo,"A",{href:!0});var a_a=s(Bne);qtt=r(a_a,"TFXLMForSequenceClassification"),a_a.forEach(t),Dtt=r(ceo," (XLM model)"),ceo.forEach(t),jtt=i(ae),o6=n(ae,"LI",{});var feo=s(o6);j9e=n(feo,"STRONG",{});var n_a=s(j9e);Gtt=r(n_a,"xlm-roberta"),n_a.forEach(t),Ott=r(feo," \u2014 "),Ine=n(feo,"A",{href:!0});var s_a=s(Ine);Vtt=r(s_a,"TFXLMRobertaForSequenceClassification"),s_a.forEach(t),Xtt=r(feo," (XLM-RoBERTa model)"),feo.forEach(t),ztt=i(ae),r6=n(ae,"LI",{});var geo=s(r6);G9e=n(geo,"STRONG",{});var l_a=s(G9e);Qtt=r(l_a,"xlnet"),l_a.forEach(t),Wtt=r(geo," \u2014 "),Nne=n(geo,"A",{href:!0});var i_a=s(Nne);Utt=r(i_a,"TFXLNetForSequenceClassification"),i_a.forEach(t),Htt=r(geo," (XLNet model)"),geo.forEach(t),ae.forEach(t),Jtt=i(ki),T(t6.$$.fragment,ki),ki.forEach(t),$i.forEach(t),sno=i(c),Bc=n(c,"H2",{class:!0});var wlo=s(Bc);a6=n(wlo,"A",{id:!0,class:!0,href:!0});var d_a=s(a6);O9e=n(d_a,"SPAN",{});var m_a=s(O9e);T(oP.$$.fragment,m_a),m_a.forEach(t),d_a.forEach(t),Ytt=i(wlo),V9e=n(wlo,"SPAN",{});var c_a=s(V9e);Ztt=r(c_a,"TFAutoModelForMultipleChoice"),c_a.forEach(t),wlo.forEach(t),lno=i(c),br=n(c,"DIV",{class:!0});var Si=s(br);T(rP.$$.fragment,Si),Ktt=i(Si),Ic=n(Si,"P",{});var Lce=s(Ic);eat=r(Lce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),qne=n(Lce,"A",{href:!0});var f_a=s(qne);oat=r(f_a,"from_pretrained()"),f_a.forEach(t),rat=r(Lce," class method or the "),Dne=n(Lce,"A",{href:!0});var g_a=s(Dne);tat=r(g_a,"from_config()"),g_a.forEach(t),aat=r(Lce,` class
method.`),Lce.forEach(t),nat=i(Si),tP=n(Si,"P",{});var Alo=s(tP);sat=r(Alo,"This class cannot be instantiated directly using "),X9e=n(Alo,"CODE",{});var h_a=s(X9e);lat=r(h_a,"__init__()"),h_a.forEach(t),iat=r(Alo," (throws an error)."),Alo.forEach(t),dat=i(Si),na=n(Si,"DIV",{class:!0});var Fx=s(na);T(aP.$$.fragment,Fx),mat=i(Fx),z9e=n(Fx,"P",{});var u_a=s(z9e);cat=r(u_a,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),u_a.forEach(t),fat=i(Fx),Nc=n(Fx,"P",{});var yce=s(Nc);gat=r(yce,`Note:
Loading a model from its configuration file does `),Q9e=n(yce,"STRONG",{});var p_a=s(Q9e);hat=r(p_a,"not"),p_a.forEach(t),uat=r(yce,` load the model weights. It only affects the
model\u2019s configuration. Use `),jne=n(yce,"A",{href:!0});var __a=s(jne);pat=r(__a,"from_pretrained()"),__a.forEach(t),_at=r(yce," to load the model weights."),yce.forEach(t),bat=i(Fx),T(n6.$$.fragment,Fx),Fx.forEach(t),vat=i(Si),Ur=n(Si,"DIV",{class:!0});var Ri=s(Ur);T(nP.$$.fragment,Ri),Fat=i(Ri),W9e=n(Ri,"P",{});var b_a=s(W9e);Tat=r(b_a,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),b_a.forEach(t),Mat=i(Ri),Vn=n(Ri,"P",{});var Tx=s(Vn);Eat=r(Tx,"The model class to instantiate is selected based on the "),U9e=n(Tx,"CODE",{});var v_a=s(U9e);Cat=r(v_a,"model_type"),v_a.forEach(t),wat=r(Tx,` property of the config object (either
passed as an argument or loaded from `),H9e=n(Tx,"CODE",{});var F_a=s(H9e);Aat=r(F_a,"pretrained_model_name_or_path"),F_a.forEach(t),Lat=r(Tx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J9e=n(Tx,"CODE",{});var T_a=s(J9e);yat=r(T_a,"pretrained_model_name_or_path"),T_a.forEach(t),xat=r(Tx,":"),Tx.forEach(t),$at=i(Ri),ve=n(Ri,"UL",{});var Te=s(ve);s6=n(Te,"LI",{});var heo=s(s6);Y9e=n(heo,"STRONG",{});var M_a=s(Y9e);kat=r(M_a,"albert"),M_a.forEach(t),Sat=r(heo," \u2014 "),Gne=n(heo,"A",{href:!0});var E_a=s(Gne);Rat=r(E_a,"TFAlbertForMultipleChoice"),E_a.forEach(t),Pat=r(heo," (ALBERT model)"),heo.forEach(t),Bat=i(Te),l6=n(Te,"LI",{});var ueo=s(l6);Z9e=n(ueo,"STRONG",{});var C_a=s(Z9e);Iat=r(C_a,"bert"),C_a.forEach(t),Nat=r(ueo," \u2014 "),One=n(ueo,"A",{href:!0});var w_a=s(One);qat=r(w_a,"TFBertForMultipleChoice"),w_a.forEach(t),Dat=r(ueo," (BERT model)"),ueo.forEach(t),jat=i(Te),i6=n(Te,"LI",{});var peo=s(i6);K9e=n(peo,"STRONG",{});var A_a=s(K9e);Gat=r(A_a,"camembert"),A_a.forEach(t),Oat=r(peo," \u2014 "),Vne=n(peo,"A",{href:!0});var L_a=s(Vne);Vat=r(L_a,"TFCamembertForMultipleChoice"),L_a.forEach(t),Xat=r(peo," (CamemBERT model)"),peo.forEach(t),zat=i(Te),d6=n(Te,"LI",{});var _eo=s(d6);exe=n(_eo,"STRONG",{});var y_a=s(exe);Qat=r(y_a,"convbert"),y_a.forEach(t),Wat=r(_eo," \u2014 "),Xne=n(_eo,"A",{href:!0});var x_a=s(Xne);Uat=r(x_a,"TFConvBertForMultipleChoice"),x_a.forEach(t),Hat=r(_eo," (ConvBERT model)"),_eo.forEach(t),Jat=i(Te),m6=n(Te,"LI",{});var beo=s(m6);oxe=n(beo,"STRONG",{});var $_a=s(oxe);Yat=r($_a,"distilbert"),$_a.forEach(t),Zat=r(beo," \u2014 "),zne=n(beo,"A",{href:!0});var k_a=s(zne);Kat=r(k_a,"TFDistilBertForMultipleChoice"),k_a.forEach(t),ent=r(beo," (DistilBERT model)"),beo.forEach(t),ont=i(Te),c6=n(Te,"LI",{});var veo=s(c6);rxe=n(veo,"STRONG",{});var S_a=s(rxe);rnt=r(S_a,"electra"),S_a.forEach(t),tnt=r(veo," \u2014 "),Qne=n(veo,"A",{href:!0});var R_a=s(Qne);ant=r(R_a,"TFElectraForMultipleChoice"),R_a.forEach(t),nnt=r(veo," (ELECTRA model)"),veo.forEach(t),snt=i(Te),f6=n(Te,"LI",{});var Feo=s(f6);txe=n(Feo,"STRONG",{});var P_a=s(txe);lnt=r(P_a,"flaubert"),P_a.forEach(t),int=r(Feo," \u2014 "),Wne=n(Feo,"A",{href:!0});var B_a=s(Wne);dnt=r(B_a,"TFFlaubertForMultipleChoice"),B_a.forEach(t),mnt=r(Feo," (FlauBERT model)"),Feo.forEach(t),cnt=i(Te),g6=n(Te,"LI",{});var Teo=s(g6);axe=n(Teo,"STRONG",{});var I_a=s(axe);fnt=r(I_a,"funnel"),I_a.forEach(t),gnt=r(Teo," \u2014 "),Une=n(Teo,"A",{href:!0});var N_a=s(Une);hnt=r(N_a,"TFFunnelForMultipleChoice"),N_a.forEach(t),unt=r(Teo," (Funnel Transformer model)"),Teo.forEach(t),pnt=i(Te),h6=n(Te,"LI",{});var Meo=s(h6);nxe=n(Meo,"STRONG",{});var q_a=s(nxe);_nt=r(q_a,"longformer"),q_a.forEach(t),bnt=r(Meo," \u2014 "),Hne=n(Meo,"A",{href:!0});var D_a=s(Hne);vnt=r(D_a,"TFLongformerForMultipleChoice"),D_a.forEach(t),Fnt=r(Meo," (Longformer model)"),Meo.forEach(t),Tnt=i(Te),u6=n(Te,"LI",{});var Eeo=s(u6);sxe=n(Eeo,"STRONG",{});var j_a=s(sxe);Mnt=r(j_a,"mobilebert"),j_a.forEach(t),Ent=r(Eeo," \u2014 "),Jne=n(Eeo,"A",{href:!0});var G_a=s(Jne);Cnt=r(G_a,"TFMobileBertForMultipleChoice"),G_a.forEach(t),wnt=r(Eeo," (MobileBERT model)"),Eeo.forEach(t),Ant=i(Te),p6=n(Te,"LI",{});var Ceo=s(p6);lxe=n(Ceo,"STRONG",{});var O_a=s(lxe);Lnt=r(O_a,"mpnet"),O_a.forEach(t),ynt=r(Ceo," \u2014 "),Yne=n(Ceo,"A",{href:!0});var V_a=s(Yne);xnt=r(V_a,"TFMPNetForMultipleChoice"),V_a.forEach(t),$nt=r(Ceo," (MPNet model)"),Ceo.forEach(t),knt=i(Te),_6=n(Te,"LI",{});var weo=s(_6);ixe=n(weo,"STRONG",{});var X_a=s(ixe);Snt=r(X_a,"rembert"),X_a.forEach(t),Rnt=r(weo," \u2014 "),Zne=n(weo,"A",{href:!0});var z_a=s(Zne);Pnt=r(z_a,"TFRemBertForMultipleChoice"),z_a.forEach(t),Bnt=r(weo," (RemBERT model)"),weo.forEach(t),Int=i(Te),b6=n(Te,"LI",{});var Aeo=s(b6);dxe=n(Aeo,"STRONG",{});var Q_a=s(dxe);Nnt=r(Q_a,"roberta"),Q_a.forEach(t),qnt=r(Aeo," \u2014 "),Kne=n(Aeo,"A",{href:!0});var W_a=s(Kne);Dnt=r(W_a,"TFRobertaForMultipleChoice"),W_a.forEach(t),jnt=r(Aeo," (RoBERTa model)"),Aeo.forEach(t),Gnt=i(Te),v6=n(Te,"LI",{});var Leo=s(v6);mxe=n(Leo,"STRONG",{});var U_a=s(mxe);Ont=r(U_a,"roformer"),U_a.forEach(t),Vnt=r(Leo," \u2014 "),ese=n(Leo,"A",{href:!0});var H_a=s(ese);Xnt=r(H_a,"TFRoFormerForMultipleChoice"),H_a.forEach(t),znt=r(Leo," (RoFormer model)"),Leo.forEach(t),Qnt=i(Te),F6=n(Te,"LI",{});var yeo=s(F6);cxe=n(yeo,"STRONG",{});var J_a=s(cxe);Wnt=r(J_a,"xlm"),J_a.forEach(t),Unt=r(yeo," \u2014 "),ose=n(yeo,"A",{href:!0});var Y_a=s(ose);Hnt=r(Y_a,"TFXLMForMultipleChoice"),Y_a.forEach(t),Jnt=r(yeo," (XLM model)"),yeo.forEach(t),Ynt=i(Te),T6=n(Te,"LI",{});var xeo=s(T6);fxe=n(xeo,"STRONG",{});var Z_a=s(fxe);Znt=r(Z_a,"xlm-roberta"),Z_a.forEach(t),Knt=r(xeo," \u2014 "),rse=n(xeo,"A",{href:!0});var K_a=s(rse);est=r(K_a,"TFXLMRobertaForMultipleChoice"),K_a.forEach(t),ost=r(xeo," (XLM-RoBERTa model)"),xeo.forEach(t),rst=i(Te),M6=n(Te,"LI",{});var $eo=s(M6);gxe=n($eo,"STRONG",{});var e1a=s(gxe);tst=r(e1a,"xlnet"),e1a.forEach(t),ast=r($eo," \u2014 "),tse=n($eo,"A",{href:!0});var o1a=s(tse);nst=r(o1a,"TFXLNetForMultipleChoice"),o1a.forEach(t),sst=r($eo," (XLNet model)"),$eo.forEach(t),Te.forEach(t),lst=i(Ri),T(E6.$$.fragment,Ri),Ri.forEach(t),Si.forEach(t),ino=i(c),qc=n(c,"H2",{class:!0});var Llo=s(qc);C6=n(Llo,"A",{id:!0,class:!0,href:!0});var r1a=s(C6);hxe=n(r1a,"SPAN",{});var t1a=s(hxe);T(sP.$$.fragment,t1a),t1a.forEach(t),r1a.forEach(t),ist=i(Llo),uxe=n(Llo,"SPAN",{});var a1a=s(uxe);dst=r(a1a,"TFAutoModelForNextSentencePrediction"),a1a.forEach(t),Llo.forEach(t),dno=i(c),vr=n(c,"DIV",{class:!0});var Pi=s(vr);T(lP.$$.fragment,Pi),mst=i(Pi),Dc=n(Pi,"P",{});var xce=s(Dc);cst=r(xce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),ase=n(xce,"A",{href:!0});var n1a=s(ase);fst=r(n1a,"from_pretrained()"),n1a.forEach(t),gst=r(xce," class method or the "),nse=n(xce,"A",{href:!0});var s1a=s(nse);hst=r(s1a,"from_config()"),s1a.forEach(t),ust=r(xce,` class
method.`),xce.forEach(t),pst=i(Pi),iP=n(Pi,"P",{});var ylo=s(iP);_st=r(ylo,"This class cannot be instantiated directly using "),pxe=n(ylo,"CODE",{});var l1a=s(pxe);bst=r(l1a,"__init__()"),l1a.forEach(t),vst=r(ylo," (throws an error)."),ylo.forEach(t),Fst=i(Pi),sa=n(Pi,"DIV",{class:!0});var Mx=s(sa);T(dP.$$.fragment,Mx),Tst=i(Mx),_xe=n(Mx,"P",{});var i1a=s(_xe);Mst=r(i1a,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),i1a.forEach(t),Est=i(Mx),jc=n(Mx,"P",{});var $ce=s(jc);Cst=r($ce,`Note:
Loading a model from its configuration file does `),bxe=n($ce,"STRONG",{});var d1a=s(bxe);wst=r(d1a,"not"),d1a.forEach(t),Ast=r($ce,` load the model weights. It only affects the
model\u2019s configuration. Use `),sse=n($ce,"A",{href:!0});var m1a=s(sse);Lst=r(m1a,"from_pretrained()"),m1a.forEach(t),yst=r($ce," to load the model weights."),$ce.forEach(t),xst=i(Mx),T(w6.$$.fragment,Mx),Mx.forEach(t),$st=i(Pi),Hr=n(Pi,"DIV",{class:!0});var Bi=s(Hr);T(mP.$$.fragment,Bi),kst=i(Bi),vxe=n(Bi,"P",{});var c1a=s(vxe);Sst=r(c1a,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),c1a.forEach(t),Rst=i(Bi),Xn=n(Bi,"P",{});var Ex=s(Xn);Pst=r(Ex,"The model class to instantiate is selected based on the "),Fxe=n(Ex,"CODE",{});var f1a=s(Fxe);Bst=r(f1a,"model_type"),f1a.forEach(t),Ist=r(Ex,` property of the config object (either
passed as an argument or loaded from `),Txe=n(Ex,"CODE",{});var g1a=s(Txe);Nst=r(g1a,"pretrained_model_name_or_path"),g1a.forEach(t),qst=r(Ex,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mxe=n(Ex,"CODE",{});var h1a=s(Mxe);Dst=r(h1a,"pretrained_model_name_or_path"),h1a.forEach(t),jst=r(Ex,":"),Ex.forEach(t),Gst=i(Bi),cP=n(Bi,"UL",{});var xlo=s(cP);A6=n(xlo,"LI",{});var keo=s(A6);Exe=n(keo,"STRONG",{});var u1a=s(Exe);Ost=r(u1a,"bert"),u1a.forEach(t),Vst=r(keo," \u2014 "),lse=n(keo,"A",{href:!0});var p1a=s(lse);Xst=r(p1a,"TFBertForNextSentencePrediction"),p1a.forEach(t),zst=r(keo," (BERT model)"),keo.forEach(t),Qst=i(xlo),L6=n(xlo,"LI",{});var Seo=s(L6);Cxe=n(Seo,"STRONG",{});var _1a=s(Cxe);Wst=r(_1a,"mobilebert"),_1a.forEach(t),Ust=r(Seo," \u2014 "),ise=n(Seo,"A",{href:!0});var b1a=s(ise);Hst=r(b1a,"TFMobileBertForNextSentencePrediction"),b1a.forEach(t),Jst=r(Seo," (MobileBERT model)"),Seo.forEach(t),xlo.forEach(t),Yst=i(Bi),T(y6.$$.fragment,Bi),Bi.forEach(t),Pi.forEach(t),mno=i(c),Gc=n(c,"H2",{class:!0});var $lo=s(Gc);x6=n($lo,"A",{id:!0,class:!0,href:!0});var v1a=s(x6);wxe=n(v1a,"SPAN",{});var F1a=s(wxe);T(fP.$$.fragment,F1a),F1a.forEach(t),v1a.forEach(t),Zst=i($lo),Axe=n($lo,"SPAN",{});var T1a=s(Axe);Kst=r(T1a,"TFAutoModelForTableQuestionAnswering"),T1a.forEach(t),$lo.forEach(t),cno=i(c),Fr=n(c,"DIV",{class:!0});var Ii=s(Fr);T(gP.$$.fragment,Ii),elt=i(Ii),Oc=n(Ii,"P",{});var kce=s(Oc);olt=r(kce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),dse=n(kce,"A",{href:!0});var M1a=s(dse);rlt=r(M1a,"from_pretrained()"),M1a.forEach(t),tlt=r(kce," class method or the "),mse=n(kce,"A",{href:!0});var E1a=s(mse);alt=r(E1a,"from_config()"),E1a.forEach(t),nlt=r(kce,` class
method.`),kce.forEach(t),slt=i(Ii),hP=n(Ii,"P",{});var klo=s(hP);llt=r(klo,"This class cannot be instantiated directly using "),Lxe=n(klo,"CODE",{});var C1a=s(Lxe);ilt=r(C1a,"__init__()"),C1a.forEach(t),dlt=r(klo," (throws an error)."),klo.forEach(t),mlt=i(Ii),la=n(Ii,"DIV",{class:!0});var Cx=s(la);T(uP.$$.fragment,Cx),clt=i(Cx),yxe=n(Cx,"P",{});var w1a=s(yxe);flt=r(w1a,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),w1a.forEach(t),glt=i(Cx),Vc=n(Cx,"P",{});var Sce=s(Vc);hlt=r(Sce,`Note:
Loading a model from its configuration file does `),xxe=n(Sce,"STRONG",{});var A1a=s(xxe);ult=r(A1a,"not"),A1a.forEach(t),plt=r(Sce,` load the model weights. It only affects the
model\u2019s configuration. Use `),cse=n(Sce,"A",{href:!0});var L1a=s(cse);_lt=r(L1a,"from_pretrained()"),L1a.forEach(t),blt=r(Sce," to load the model weights."),Sce.forEach(t),vlt=i(Cx),T($6.$$.fragment,Cx),Cx.forEach(t),Flt=i(Ii),Jr=n(Ii,"DIV",{class:!0});var Ni=s(Jr);T(pP.$$.fragment,Ni),Tlt=i(Ni),$xe=n(Ni,"P",{});var y1a=s($xe);Mlt=r(y1a,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),y1a.forEach(t),Elt=i(Ni),zn=n(Ni,"P",{});var wx=s(zn);Clt=r(wx,"The model class to instantiate is selected based on the "),kxe=n(wx,"CODE",{});var x1a=s(kxe);wlt=r(x1a,"model_type"),x1a.forEach(t),Alt=r(wx,` property of the config object (either
passed as an argument or loaded from `),Sxe=n(wx,"CODE",{});var $1a=s(Sxe);Llt=r($1a,"pretrained_model_name_or_path"),$1a.forEach(t),ylt=r(wx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rxe=n(wx,"CODE",{});var k1a=s(Rxe);xlt=r(k1a,"pretrained_model_name_or_path"),k1a.forEach(t),$lt=r(wx,":"),wx.forEach(t),klt=i(Ni),Pxe=n(Ni,"UL",{});var S1a=s(Pxe);k6=n(S1a,"LI",{});var Reo=s(k6);Bxe=n(Reo,"STRONG",{});var R1a=s(Bxe);Slt=r(R1a,"tapas"),R1a.forEach(t),Rlt=r(Reo," \u2014 "),fse=n(Reo,"A",{href:!0});var P1a=s(fse);Plt=r(P1a,"TFTapasForQuestionAnswering"),P1a.forEach(t),Blt=r(Reo," (TAPAS model)"),Reo.forEach(t),S1a.forEach(t),Ilt=i(Ni),T(S6.$$.fragment,Ni),Ni.forEach(t),Ii.forEach(t),fno=i(c),Xc=n(c,"H2",{class:!0});var Slo=s(Xc);R6=n(Slo,"A",{id:!0,class:!0,href:!0});var B1a=s(R6);Ixe=n(B1a,"SPAN",{});var I1a=s(Ixe);T(_P.$$.fragment,I1a),I1a.forEach(t),B1a.forEach(t),Nlt=i(Slo),Nxe=n(Slo,"SPAN",{});var N1a=s(Nxe);qlt=r(N1a,"TFAutoModelForDocumentQuestionAnswering"),N1a.forEach(t),Slo.forEach(t),gno=i(c),Tr=n(c,"DIV",{class:!0});var qi=s(Tr);T(bP.$$.fragment,qi),Dlt=i(qi),zc=n(qi,"P",{});var Rce=s(zc);jlt=r(Rce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),gse=n(Rce,"A",{href:!0});var q1a=s(gse);Glt=r(q1a,"from_pretrained()"),q1a.forEach(t),Olt=r(Rce," class method or the "),hse=n(Rce,"A",{href:!0});var D1a=s(hse);Vlt=r(D1a,"from_config()"),D1a.forEach(t),Xlt=r(Rce,` class
method.`),Rce.forEach(t),zlt=i(qi),vP=n(qi,"P",{});var Rlo=s(vP);Qlt=r(Rlo,"This class cannot be instantiated directly using "),qxe=n(Rlo,"CODE",{});var j1a=s(qxe);Wlt=r(j1a,"__init__()"),j1a.forEach(t),Ult=r(Rlo," (throws an error)."),Rlo.forEach(t),Hlt=i(qi),ia=n(qi,"DIV",{class:!0});var Ax=s(ia);T(FP.$$.fragment,Ax),Jlt=i(Ax),Dxe=n(Ax,"P",{});var G1a=s(Dxe);Ylt=r(G1a,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),G1a.forEach(t),Zlt=i(Ax),Qc=n(Ax,"P",{});var Pce=s(Qc);Klt=r(Pce,`Note:
Loading a model from its configuration file does `),jxe=n(Pce,"STRONG",{});var O1a=s(jxe);eit=r(O1a,"not"),O1a.forEach(t),oit=r(Pce,` load the model weights. It only affects the
model\u2019s configuration. Use `),use=n(Pce,"A",{href:!0});var V1a=s(use);rit=r(V1a,"from_pretrained()"),V1a.forEach(t),tit=r(Pce," to load the model weights."),Pce.forEach(t),ait=i(Ax),T(P6.$$.fragment,Ax),Ax.forEach(t),nit=i(qi),Yr=n(qi,"DIV",{class:!0});var Di=s(Yr);T(TP.$$.fragment,Di),sit=i(Di),Gxe=n(Di,"P",{});var X1a=s(Gxe);lit=r(X1a,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),X1a.forEach(t),iit=i(Di),Qn=n(Di,"P",{});var Lx=s(Qn);dit=r(Lx,"The model class to instantiate is selected based on the "),Oxe=n(Lx,"CODE",{});var z1a=s(Oxe);mit=r(z1a,"model_type"),z1a.forEach(t),cit=r(Lx,` property of the config object (either
passed as an argument or loaded from `),Vxe=n(Lx,"CODE",{});var Q1a=s(Vxe);fit=r(Q1a,"pretrained_model_name_or_path"),Q1a.forEach(t),git=r(Lx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xxe=n(Lx,"CODE",{});var W1a=s(Xxe);hit=r(W1a,"pretrained_model_name_or_path"),W1a.forEach(t),uit=r(Lx,":"),Lx.forEach(t),pit=i(Di),zxe=n(Di,"UL",{});var U1a=s(zxe);B6=n(U1a,"LI",{});var Peo=s(B6);Qxe=n(Peo,"STRONG",{});var H1a=s(Qxe);_it=r(H1a,"layoutlm"),H1a.forEach(t),bit=r(Peo," \u2014 "),pse=n(Peo,"A",{href:!0});var J1a=s(pse);vit=r(J1a,"TFLayoutLMForQuestionAnswering"),J1a.forEach(t),Fit=r(Peo," (LayoutLM model)"),Peo.forEach(t),U1a.forEach(t),Tit=i(Di),T(I6.$$.fragment,Di),Di.forEach(t),qi.forEach(t),hno=i(c),Wc=n(c,"H2",{class:!0});var Plo=s(Wc);N6=n(Plo,"A",{id:!0,class:!0,href:!0});var Y1a=s(N6);Wxe=n(Y1a,"SPAN",{});var Z1a=s(Wxe);T(MP.$$.fragment,Z1a),Z1a.forEach(t),Y1a.forEach(t),Mit=i(Plo),Uxe=n(Plo,"SPAN",{});var K1a=s(Uxe);Eit=r(K1a,"TFAutoModelForTokenClassification"),K1a.forEach(t),Plo.forEach(t),uno=i(c),Mr=n(c,"DIV",{class:!0});var ji=s(Mr);T(EP.$$.fragment,ji),Cit=i(ji),Uc=n(ji,"P",{});var Bce=s(Uc);wit=r(Bce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),_se=n(Bce,"A",{href:!0});var e2a=s(_se);Ait=r(e2a,"from_pretrained()"),e2a.forEach(t),Lit=r(Bce," class method or the "),bse=n(Bce,"A",{href:!0});var o2a=s(bse);yit=r(o2a,"from_config()"),o2a.forEach(t),xit=r(Bce,` class
method.`),Bce.forEach(t),$it=i(ji),CP=n(ji,"P",{});var Blo=s(CP);kit=r(Blo,"This class cannot be instantiated directly using "),Hxe=n(Blo,"CODE",{});var r2a=s(Hxe);Sit=r(r2a,"__init__()"),r2a.forEach(t),Rit=r(Blo," (throws an error)."),Blo.forEach(t),Pit=i(ji),da=n(ji,"DIV",{class:!0});var yx=s(da);T(wP.$$.fragment,yx),Bit=i(yx),Jxe=n(yx,"P",{});var t2a=s(Jxe);Iit=r(t2a,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),t2a.forEach(t),Nit=i(yx),Hc=n(yx,"P",{});var Ice=s(Hc);qit=r(Ice,`Note:
Loading a model from its configuration file does `),Yxe=n(Ice,"STRONG",{});var a2a=s(Yxe);Dit=r(a2a,"not"),a2a.forEach(t),jit=r(Ice,` load the model weights. It only affects the
model\u2019s configuration. Use `),vse=n(Ice,"A",{href:!0});var n2a=s(vse);Git=r(n2a,"from_pretrained()"),n2a.forEach(t),Oit=r(Ice," to load the model weights."),Ice.forEach(t),Vit=i(yx),T(q6.$$.fragment,yx),yx.forEach(t),Xit=i(ji),Zr=n(ji,"DIV",{class:!0});var Gi=s(Zr);T(AP.$$.fragment,Gi),zit=i(Gi),Zxe=n(Gi,"P",{});var s2a=s(Zxe);Qit=r(s2a,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),s2a.forEach(t),Wit=i(Gi),Wn=n(Gi,"P",{});var xx=s(Wn);Uit=r(xx,"The model class to instantiate is selected based on the "),Kxe=n(xx,"CODE",{});var l2a=s(Kxe);Hit=r(l2a,"model_type"),l2a.forEach(t),Jit=r(xx,` property of the config object (either
passed as an argument or loaded from `),e$e=n(xx,"CODE",{});var i2a=s(e$e);Yit=r(i2a,"pretrained_model_name_or_path"),i2a.forEach(t),Zit=r(xx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o$e=n(xx,"CODE",{});var d2a=s(o$e);Kit=r(d2a,"pretrained_model_name_or_path"),d2a.forEach(t),edt=r(xx,":"),xx.forEach(t),odt=i(Gi),ie=n(Gi,"UL",{});var ge=s(ie);D6=n(ge,"LI",{});var Beo=s(D6);r$e=n(Beo,"STRONG",{});var m2a=s(r$e);rdt=r(m2a,"albert"),m2a.forEach(t),tdt=r(Beo," \u2014 "),Fse=n(Beo,"A",{href:!0});var c2a=s(Fse);adt=r(c2a,"TFAlbertForTokenClassification"),c2a.forEach(t),ndt=r(Beo," (ALBERT model)"),Beo.forEach(t),sdt=i(ge),j6=n(ge,"LI",{});var Ieo=s(j6);t$e=n(Ieo,"STRONG",{});var f2a=s(t$e);ldt=r(f2a,"bert"),f2a.forEach(t),idt=r(Ieo," \u2014 "),Tse=n(Ieo,"A",{href:!0});var g2a=s(Tse);ddt=r(g2a,"TFBertForTokenClassification"),g2a.forEach(t),mdt=r(Ieo," (BERT model)"),Ieo.forEach(t),cdt=i(ge),G6=n(ge,"LI",{});var Neo=s(G6);a$e=n(Neo,"STRONG",{});var h2a=s(a$e);fdt=r(h2a,"camembert"),h2a.forEach(t),gdt=r(Neo," \u2014 "),Mse=n(Neo,"A",{href:!0});var u2a=s(Mse);hdt=r(u2a,"TFCamembertForTokenClassification"),u2a.forEach(t),udt=r(Neo," (CamemBERT model)"),Neo.forEach(t),pdt=i(ge),O6=n(ge,"LI",{});var qeo=s(O6);n$e=n(qeo,"STRONG",{});var p2a=s(n$e);_dt=r(p2a,"convbert"),p2a.forEach(t),bdt=r(qeo," \u2014 "),Ese=n(qeo,"A",{href:!0});var _2a=s(Ese);vdt=r(_2a,"TFConvBertForTokenClassification"),_2a.forEach(t),Fdt=r(qeo," (ConvBERT model)"),qeo.forEach(t),Tdt=i(ge),V6=n(ge,"LI",{});var Deo=s(V6);s$e=n(Deo,"STRONG",{});var b2a=s(s$e);Mdt=r(b2a,"deberta"),b2a.forEach(t),Edt=r(Deo," \u2014 "),Cse=n(Deo,"A",{href:!0});var v2a=s(Cse);Cdt=r(v2a,"TFDebertaForTokenClassification"),v2a.forEach(t),wdt=r(Deo," (DeBERTa model)"),Deo.forEach(t),Adt=i(ge),X6=n(ge,"LI",{});var jeo=s(X6);l$e=n(jeo,"STRONG",{});var F2a=s(l$e);Ldt=r(F2a,"deberta-v2"),F2a.forEach(t),ydt=r(jeo," \u2014 "),wse=n(jeo,"A",{href:!0});var T2a=s(wse);xdt=r(T2a,"TFDebertaV2ForTokenClassification"),T2a.forEach(t),$dt=r(jeo," (DeBERTa-v2 model)"),jeo.forEach(t),kdt=i(ge),z6=n(ge,"LI",{});var Geo=s(z6);i$e=n(Geo,"STRONG",{});var M2a=s(i$e);Sdt=r(M2a,"distilbert"),M2a.forEach(t),Rdt=r(Geo," \u2014 "),Ase=n(Geo,"A",{href:!0});var E2a=s(Ase);Pdt=r(E2a,"TFDistilBertForTokenClassification"),E2a.forEach(t),Bdt=r(Geo," (DistilBERT model)"),Geo.forEach(t),Idt=i(ge),Q6=n(ge,"LI",{});var Oeo=s(Q6);d$e=n(Oeo,"STRONG",{});var C2a=s(d$e);Ndt=r(C2a,"electra"),C2a.forEach(t),qdt=r(Oeo," \u2014 "),Lse=n(Oeo,"A",{href:!0});var w2a=s(Lse);Ddt=r(w2a,"TFElectraForTokenClassification"),w2a.forEach(t),jdt=r(Oeo," (ELECTRA model)"),Oeo.forEach(t),Gdt=i(ge),W6=n(ge,"LI",{});var Veo=s(W6);m$e=n(Veo,"STRONG",{});var A2a=s(m$e);Odt=r(A2a,"esm"),A2a.forEach(t),Vdt=r(Veo," \u2014 "),yse=n(Veo,"A",{href:!0});var L2a=s(yse);Xdt=r(L2a,"TFEsmForTokenClassification"),L2a.forEach(t),zdt=r(Veo," (ESM model)"),Veo.forEach(t),Qdt=i(ge),U6=n(ge,"LI",{});var Xeo=s(U6);c$e=n(Xeo,"STRONG",{});var y2a=s(c$e);Wdt=r(y2a,"flaubert"),y2a.forEach(t),Udt=r(Xeo," \u2014 "),xse=n(Xeo,"A",{href:!0});var x2a=s(xse);Hdt=r(x2a,"TFFlaubertForTokenClassification"),x2a.forEach(t),Jdt=r(Xeo," (FlauBERT model)"),Xeo.forEach(t),Ydt=i(ge),H6=n(ge,"LI",{});var zeo=s(H6);f$e=n(zeo,"STRONG",{});var $2a=s(f$e);Zdt=r($2a,"funnel"),$2a.forEach(t),Kdt=r(zeo," \u2014 "),$se=n(zeo,"A",{href:!0});var k2a=s($se);emt=r(k2a,"TFFunnelForTokenClassification"),k2a.forEach(t),omt=r(zeo," (Funnel Transformer model)"),zeo.forEach(t),rmt=i(ge),J6=n(ge,"LI",{});var Qeo=s(J6);g$e=n(Qeo,"STRONG",{});var S2a=s(g$e);tmt=r(S2a,"layoutlm"),S2a.forEach(t),amt=r(Qeo," \u2014 "),kse=n(Qeo,"A",{href:!0});var R2a=s(kse);nmt=r(R2a,"TFLayoutLMForTokenClassification"),R2a.forEach(t),smt=r(Qeo," (LayoutLM model)"),Qeo.forEach(t),lmt=i(ge),Y6=n(ge,"LI",{});var Weo=s(Y6);h$e=n(Weo,"STRONG",{});var P2a=s(h$e);imt=r(P2a,"layoutlmv3"),P2a.forEach(t),dmt=r(Weo," \u2014 "),Sse=n(Weo,"A",{href:!0});var B2a=s(Sse);mmt=r(B2a,"TFLayoutLMv3ForTokenClassification"),B2a.forEach(t),cmt=r(Weo," (LayoutLMv3 model)"),Weo.forEach(t),fmt=i(ge),Z6=n(ge,"LI",{});var Ueo=s(Z6);u$e=n(Ueo,"STRONG",{});var I2a=s(u$e);gmt=r(I2a,"longformer"),I2a.forEach(t),hmt=r(Ueo," \u2014 "),Rse=n(Ueo,"A",{href:!0});var N2a=s(Rse);umt=r(N2a,"TFLongformerForTokenClassification"),N2a.forEach(t),pmt=r(Ueo," (Longformer model)"),Ueo.forEach(t),_mt=i(ge),K6=n(ge,"LI",{});var Heo=s(K6);p$e=n(Heo,"STRONG",{});var q2a=s(p$e);bmt=r(q2a,"mobilebert"),q2a.forEach(t),vmt=r(Heo," \u2014 "),Pse=n(Heo,"A",{href:!0});var D2a=s(Pse);Fmt=r(D2a,"TFMobileBertForTokenClassification"),D2a.forEach(t),Tmt=r(Heo," (MobileBERT model)"),Heo.forEach(t),Mmt=i(ge),e7=n(ge,"LI",{});var Jeo=s(e7);_$e=n(Jeo,"STRONG",{});var j2a=s(_$e);Emt=r(j2a,"mpnet"),j2a.forEach(t),Cmt=r(Jeo," \u2014 "),Bse=n(Jeo,"A",{href:!0});var G2a=s(Bse);wmt=r(G2a,"TFMPNetForTokenClassification"),G2a.forEach(t),Amt=r(Jeo," (MPNet model)"),Jeo.forEach(t),Lmt=i(ge),o7=n(ge,"LI",{});var Yeo=s(o7);b$e=n(Yeo,"STRONG",{});var O2a=s(b$e);ymt=r(O2a,"rembert"),O2a.forEach(t),xmt=r(Yeo," \u2014 "),Ise=n(Yeo,"A",{href:!0});var V2a=s(Ise);$mt=r(V2a,"TFRemBertForTokenClassification"),V2a.forEach(t),kmt=r(Yeo," (RemBERT model)"),Yeo.forEach(t),Smt=i(ge),r7=n(ge,"LI",{});var Zeo=s(r7);v$e=n(Zeo,"STRONG",{});var X2a=s(v$e);Rmt=r(X2a,"roberta"),X2a.forEach(t),Pmt=r(Zeo," \u2014 "),Nse=n(Zeo,"A",{href:!0});var z2a=s(Nse);Bmt=r(z2a,"TFRobertaForTokenClassification"),z2a.forEach(t),Imt=r(Zeo," (RoBERTa model)"),Zeo.forEach(t),Nmt=i(ge),t7=n(ge,"LI",{});var Keo=s(t7);F$e=n(Keo,"STRONG",{});var Q2a=s(F$e);qmt=r(Q2a,"roformer"),Q2a.forEach(t),Dmt=r(Keo," \u2014 "),qse=n(Keo,"A",{href:!0});var W2a=s(qse);jmt=r(W2a,"TFRoFormerForTokenClassification"),W2a.forEach(t),Gmt=r(Keo," (RoFormer model)"),Keo.forEach(t),Omt=i(ge),a7=n(ge,"LI",{});var eoo=s(a7);T$e=n(eoo,"STRONG",{});var U2a=s(T$e);Vmt=r(U2a,"xlm"),U2a.forEach(t),Xmt=r(eoo," \u2014 "),Dse=n(eoo,"A",{href:!0});var H2a=s(Dse);zmt=r(H2a,"TFXLMForTokenClassification"),H2a.forEach(t),Qmt=r(eoo," (XLM model)"),eoo.forEach(t),Wmt=i(ge),n7=n(ge,"LI",{});var ooo=s(n7);M$e=n(ooo,"STRONG",{});var J2a=s(M$e);Umt=r(J2a,"xlm-roberta"),J2a.forEach(t),Hmt=r(ooo," \u2014 "),jse=n(ooo,"A",{href:!0});var Y2a=s(jse);Jmt=r(Y2a,"TFXLMRobertaForTokenClassification"),Y2a.forEach(t),Ymt=r(ooo," (XLM-RoBERTa model)"),ooo.forEach(t),Zmt=i(ge),s7=n(ge,"LI",{});var roo=s(s7);E$e=n(roo,"STRONG",{});var Z2a=s(E$e);Kmt=r(Z2a,"xlnet"),Z2a.forEach(t),ect=r(roo," \u2014 "),Gse=n(roo,"A",{href:!0});var K2a=s(Gse);oct=r(K2a,"TFXLNetForTokenClassification"),K2a.forEach(t),rct=r(roo," (XLNet model)"),roo.forEach(t),ge.forEach(t),tct=i(Gi),T(l7.$$.fragment,Gi),Gi.forEach(t),ji.forEach(t),pno=i(c),Jc=n(c,"H2",{class:!0});var Ilo=s(Jc);i7=n(Ilo,"A",{id:!0,class:!0,href:!0});var eba=s(i7);C$e=n(eba,"SPAN",{});var oba=s(C$e);T(LP.$$.fragment,oba),oba.forEach(t),eba.forEach(t),act=i(Ilo),w$e=n(Ilo,"SPAN",{});var rba=s(w$e);nct=r(rba,"TFAutoModelForQuestionAnswering"),rba.forEach(t),Ilo.forEach(t),_no=i(c),Er=n(c,"DIV",{class:!0});var Oi=s(Er);T(yP.$$.fragment,Oi),sct=i(Oi),Yc=n(Oi,"P",{});var Nce=s(Yc);lct=r(Nce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Ose=n(Nce,"A",{href:!0});var tba=s(Ose);ict=r(tba,"from_pretrained()"),tba.forEach(t),dct=r(Nce," class method or the "),Vse=n(Nce,"A",{href:!0});var aba=s(Vse);mct=r(aba,"from_config()"),aba.forEach(t),cct=r(Nce,` class
method.`),Nce.forEach(t),fct=i(Oi),xP=n(Oi,"P",{});var Nlo=s(xP);gct=r(Nlo,"This class cannot be instantiated directly using "),A$e=n(Nlo,"CODE",{});var nba=s(A$e);hct=r(nba,"__init__()"),nba.forEach(t),uct=r(Nlo," (throws an error)."),Nlo.forEach(t),pct=i(Oi),ma=n(Oi,"DIV",{class:!0});var $x=s(ma);T($P.$$.fragment,$x),_ct=i($x),L$e=n($x,"P",{});var sba=s(L$e);bct=r(sba,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),sba.forEach(t),vct=i($x),Zc=n($x,"P",{});var qce=s(Zc);Fct=r(qce,`Note:
Loading a model from its configuration file does `),y$e=n(qce,"STRONG",{});var lba=s(y$e);Tct=r(lba,"not"),lba.forEach(t),Mct=r(qce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Xse=n(qce,"A",{href:!0});var iba=s(Xse);Ect=r(iba,"from_pretrained()"),iba.forEach(t),Cct=r(qce," to load the model weights."),qce.forEach(t),wct=i($x),T(d7.$$.fragment,$x),$x.forEach(t),Act=i(Oi),Kr=n(Oi,"DIV",{class:!0});var Vi=s(Kr);T(kP.$$.fragment,Vi),Lct=i(Vi),x$e=n(Vi,"P",{});var dba=s(x$e);yct=r(dba,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),dba.forEach(t),xct=i(Vi),Un=n(Vi,"P",{});var kx=s(Un);$ct=r(kx,"The model class to instantiate is selected based on the "),$$e=n(kx,"CODE",{});var mba=s($$e);kct=r(mba,"model_type"),mba.forEach(t),Sct=r(kx,` property of the config object (either
passed as an argument or loaded from `),k$e=n(kx,"CODE",{});var cba=s(k$e);Rct=r(cba,"pretrained_model_name_or_path"),cba.forEach(t),Pct=r(kx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S$e=n(kx,"CODE",{});var fba=s(S$e);Bct=r(fba,"pretrained_model_name_or_path"),fba.forEach(t),Ict=r(kx,":"),kx.forEach(t),Nct=i(Vi),fe=n(Vi,"UL",{});var pe=s(fe);m7=n(pe,"LI",{});var too=s(m7);R$e=n(too,"STRONG",{});var gba=s(R$e);qct=r(gba,"albert"),gba.forEach(t),Dct=r(too," \u2014 "),zse=n(too,"A",{href:!0});var hba=s(zse);jct=r(hba,"TFAlbertForQuestionAnswering"),hba.forEach(t),Gct=r(too," (ALBERT model)"),too.forEach(t),Oct=i(pe),c7=n(pe,"LI",{});var aoo=s(c7);P$e=n(aoo,"STRONG",{});var uba=s(P$e);Vct=r(uba,"bert"),uba.forEach(t),Xct=r(aoo," \u2014 "),Qse=n(aoo,"A",{href:!0});var pba=s(Qse);zct=r(pba,"TFBertForQuestionAnswering"),pba.forEach(t),Qct=r(aoo," (BERT model)"),aoo.forEach(t),Wct=i(pe),f7=n(pe,"LI",{});var noo=s(f7);B$e=n(noo,"STRONG",{});var _ba=s(B$e);Uct=r(_ba,"camembert"),_ba.forEach(t),Hct=r(noo," \u2014 "),Wse=n(noo,"A",{href:!0});var bba=s(Wse);Jct=r(bba,"TFCamembertForQuestionAnswering"),bba.forEach(t),Yct=r(noo," (CamemBERT model)"),noo.forEach(t),Zct=i(pe),g7=n(pe,"LI",{});var soo=s(g7);I$e=n(soo,"STRONG",{});var vba=s(I$e);Kct=r(vba,"convbert"),vba.forEach(t),eft=r(soo," \u2014 "),Use=n(soo,"A",{href:!0});var Fba=s(Use);oft=r(Fba,"TFConvBertForQuestionAnswering"),Fba.forEach(t),rft=r(soo," (ConvBERT model)"),soo.forEach(t),tft=i(pe),h7=n(pe,"LI",{});var loo=s(h7);N$e=n(loo,"STRONG",{});var Tba=s(N$e);aft=r(Tba,"deberta"),Tba.forEach(t),nft=r(loo," \u2014 "),Hse=n(loo,"A",{href:!0});var Mba=s(Hse);sft=r(Mba,"TFDebertaForQuestionAnswering"),Mba.forEach(t),lft=r(loo," (DeBERTa model)"),loo.forEach(t),ift=i(pe),u7=n(pe,"LI",{});var ioo=s(u7);q$e=n(ioo,"STRONG",{});var Eba=s(q$e);dft=r(Eba,"deberta-v2"),Eba.forEach(t),mft=r(ioo," \u2014 "),Jse=n(ioo,"A",{href:!0});var Cba=s(Jse);cft=r(Cba,"TFDebertaV2ForQuestionAnswering"),Cba.forEach(t),fft=r(ioo," (DeBERTa-v2 model)"),ioo.forEach(t),gft=i(pe),p7=n(pe,"LI",{});var doo=s(p7);D$e=n(doo,"STRONG",{});var wba=s(D$e);hft=r(wba,"distilbert"),wba.forEach(t),uft=r(doo," \u2014 "),Yse=n(doo,"A",{href:!0});var Aba=s(Yse);pft=r(Aba,"TFDistilBertForQuestionAnswering"),Aba.forEach(t),_ft=r(doo," (DistilBERT model)"),doo.forEach(t),bft=i(pe),_7=n(pe,"LI",{});var moo=s(_7);j$e=n(moo,"STRONG",{});var Lba=s(j$e);vft=r(Lba,"electra"),Lba.forEach(t),Fft=r(moo," \u2014 "),Zse=n(moo,"A",{href:!0});var yba=s(Zse);Tft=r(yba,"TFElectraForQuestionAnswering"),yba.forEach(t),Mft=r(moo," (ELECTRA model)"),moo.forEach(t),Eft=i(pe),b7=n(pe,"LI",{});var coo=s(b7);G$e=n(coo,"STRONG",{});var xba=s(G$e);Cft=r(xba,"flaubert"),xba.forEach(t),wft=r(coo," \u2014 "),Kse=n(coo,"A",{href:!0});var $ba=s(Kse);Aft=r($ba,"TFFlaubertForQuestionAnsweringSimple"),$ba.forEach(t),Lft=r(coo," (FlauBERT model)"),coo.forEach(t),yft=i(pe),v7=n(pe,"LI",{});var foo=s(v7);O$e=n(foo,"STRONG",{});var kba=s(O$e);xft=r(kba,"funnel"),kba.forEach(t),$ft=r(foo," \u2014 "),ele=n(foo,"A",{href:!0});var Sba=s(ele);kft=r(Sba,"TFFunnelForQuestionAnswering"),Sba.forEach(t),Sft=r(foo," (Funnel Transformer model)"),foo.forEach(t),Rft=i(pe),F7=n(pe,"LI",{});var goo=s(F7);V$e=n(goo,"STRONG",{});var Rba=s(V$e);Pft=r(Rba,"gptj"),Rba.forEach(t),Bft=r(goo," \u2014 "),ole=n(goo,"A",{href:!0});var Pba=s(ole);Ift=r(Pba,"TFGPTJForQuestionAnswering"),Pba.forEach(t),Nft=r(goo," (GPT-J model)"),goo.forEach(t),qft=i(pe),T7=n(pe,"LI",{});var hoo=s(T7);X$e=n(hoo,"STRONG",{});var Bba=s(X$e);Dft=r(Bba,"layoutlmv3"),Bba.forEach(t),jft=r(hoo," \u2014 "),rle=n(hoo,"A",{href:!0});var Iba=s(rle);Gft=r(Iba,"TFLayoutLMv3ForQuestionAnswering"),Iba.forEach(t),Oft=r(hoo," (LayoutLMv3 model)"),hoo.forEach(t),Vft=i(pe),M7=n(pe,"LI",{});var uoo=s(M7);z$e=n(uoo,"STRONG",{});var Nba=s(z$e);Xft=r(Nba,"longformer"),Nba.forEach(t),zft=r(uoo," \u2014 "),tle=n(uoo,"A",{href:!0});var qba=s(tle);Qft=r(qba,"TFLongformerForQuestionAnswering"),qba.forEach(t),Wft=r(uoo," (Longformer model)"),uoo.forEach(t),Uft=i(pe),E7=n(pe,"LI",{});var poo=s(E7);Q$e=n(poo,"STRONG",{});var Dba=s(Q$e);Hft=r(Dba,"mobilebert"),Dba.forEach(t),Jft=r(poo," \u2014 "),ale=n(poo,"A",{href:!0});var jba=s(ale);Yft=r(jba,"TFMobileBertForQuestionAnswering"),jba.forEach(t),Zft=r(poo," (MobileBERT model)"),poo.forEach(t),Kft=i(pe),C7=n(pe,"LI",{});var _oo=s(C7);W$e=n(_oo,"STRONG",{});var Gba=s(W$e);egt=r(Gba,"mpnet"),Gba.forEach(t),ogt=r(_oo," \u2014 "),nle=n(_oo,"A",{href:!0});var Oba=s(nle);rgt=r(Oba,"TFMPNetForQuestionAnswering"),Oba.forEach(t),tgt=r(_oo," (MPNet model)"),_oo.forEach(t),agt=i(pe),w7=n(pe,"LI",{});var boo=s(w7);U$e=n(boo,"STRONG",{});var Vba=s(U$e);ngt=r(Vba,"rembert"),Vba.forEach(t),sgt=r(boo," \u2014 "),sle=n(boo,"A",{href:!0});var Xba=s(sle);lgt=r(Xba,"TFRemBertForQuestionAnswering"),Xba.forEach(t),igt=r(boo," (RemBERT model)"),boo.forEach(t),dgt=i(pe),A7=n(pe,"LI",{});var voo=s(A7);H$e=n(voo,"STRONG",{});var zba=s(H$e);mgt=r(zba,"roberta"),zba.forEach(t),cgt=r(voo," \u2014 "),lle=n(voo,"A",{href:!0});var Qba=s(lle);fgt=r(Qba,"TFRobertaForQuestionAnswering"),Qba.forEach(t),ggt=r(voo," (RoBERTa model)"),voo.forEach(t),hgt=i(pe),L7=n(pe,"LI",{});var Foo=s(L7);J$e=n(Foo,"STRONG",{});var Wba=s(J$e);ugt=r(Wba,"roformer"),Wba.forEach(t),pgt=r(Foo," \u2014 "),ile=n(Foo,"A",{href:!0});var Uba=s(ile);_gt=r(Uba,"TFRoFormerForQuestionAnswering"),Uba.forEach(t),bgt=r(Foo," (RoFormer model)"),Foo.forEach(t),vgt=i(pe),y7=n(pe,"LI",{});var Too=s(y7);Y$e=n(Too,"STRONG",{});var Hba=s(Y$e);Fgt=r(Hba,"xlm"),Hba.forEach(t),Tgt=r(Too," \u2014 "),dle=n(Too,"A",{href:!0});var Jba=s(dle);Mgt=r(Jba,"TFXLMForQuestionAnsweringSimple"),Jba.forEach(t),Egt=r(Too," (XLM model)"),Too.forEach(t),Cgt=i(pe),x7=n(pe,"LI",{});var Moo=s(x7);Z$e=n(Moo,"STRONG",{});var Yba=s(Z$e);wgt=r(Yba,"xlm-roberta"),Yba.forEach(t),Agt=r(Moo," \u2014 "),mle=n(Moo,"A",{href:!0});var Zba=s(mle);Lgt=r(Zba,"TFXLMRobertaForQuestionAnswering"),Zba.forEach(t),ygt=r(Moo," (XLM-RoBERTa model)"),Moo.forEach(t),xgt=i(pe),$7=n(pe,"LI",{});var Eoo=s($7);K$e=n(Eoo,"STRONG",{});var Kba=s(K$e);$gt=r(Kba,"xlnet"),Kba.forEach(t),kgt=r(Eoo," \u2014 "),cle=n(Eoo,"A",{href:!0});var eva=s(cle);Sgt=r(eva,"TFXLNetForQuestionAnsweringSimple"),eva.forEach(t),Rgt=r(Eoo," (XLNet model)"),Eoo.forEach(t),pe.forEach(t),Pgt=i(Vi),T(k7.$$.fragment,Vi),Vi.forEach(t),Oi.forEach(t),bno=i(c),Kc=n(c,"H2",{class:!0});var qlo=s(Kc);S7=n(qlo,"A",{id:!0,class:!0,href:!0});var ova=s(S7);eke=n(ova,"SPAN",{});var rva=s(eke);T(SP.$$.fragment,rva),rva.forEach(t),ova.forEach(t),Bgt=i(qlo),oke=n(qlo,"SPAN",{});var tva=s(oke);Igt=r(tva,"TFAutoModelForVision2Seq"),tva.forEach(t),qlo.forEach(t),vno=i(c),Cr=n(c,"DIV",{class:!0});var Xi=s(Cr);T(RP.$$.fragment,Xi),Ngt=i(Xi),ef=n(Xi,"P",{});var Dce=s(ef);qgt=r(Dce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),fle=n(Dce,"A",{href:!0});var ava=s(fle);Dgt=r(ava,"from_pretrained()"),ava.forEach(t),jgt=r(Dce," class method or the "),gle=n(Dce,"A",{href:!0});var nva=s(gle);Ggt=r(nva,"from_config()"),nva.forEach(t),Ogt=r(Dce,` class
method.`),Dce.forEach(t),Vgt=i(Xi),PP=n(Xi,"P",{});var Dlo=s(PP);Xgt=r(Dlo,"This class cannot be instantiated directly using "),rke=n(Dlo,"CODE",{});var sva=s(rke);zgt=r(sva,"__init__()"),sva.forEach(t),Qgt=r(Dlo," (throws an error)."),Dlo.forEach(t),Wgt=i(Xi),ca=n(Xi,"DIV",{class:!0});var Sx=s(ca);T(BP.$$.fragment,Sx),Ugt=i(Sx),tke=n(Sx,"P",{});var lva=s(tke);Hgt=r(lva,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),lva.forEach(t),Jgt=i(Sx),of=n(Sx,"P",{});var jce=s(of);Ygt=r(jce,`Note:
Loading a model from its configuration file does `),ake=n(jce,"STRONG",{});var iva=s(ake);Zgt=r(iva,"not"),iva.forEach(t),Kgt=r(jce,` load the model weights. It only affects the
model\u2019s configuration. Use `),hle=n(jce,"A",{href:!0});var dva=s(hle);eht=r(dva,"from_pretrained()"),dva.forEach(t),oht=r(jce," to load the model weights."),jce.forEach(t),rht=i(Sx),T(R7.$$.fragment,Sx),Sx.forEach(t),tht=i(Xi),et=n(Xi,"DIV",{class:!0});var zi=s(et);T(IP.$$.fragment,zi),aht=i(zi),nke=n(zi,"P",{});var mva=s(nke);nht=r(mva,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),mva.forEach(t),sht=i(zi),Hn=n(zi,"P",{});var Rx=s(Hn);lht=r(Rx,"The model class to instantiate is selected based on the "),ske=n(Rx,"CODE",{});var cva=s(ske);iht=r(cva,"model_type"),cva.forEach(t),dht=r(Rx,` property of the config object (either
passed as an argument or loaded from `),lke=n(Rx,"CODE",{});var fva=s(lke);mht=r(fva,"pretrained_model_name_or_path"),fva.forEach(t),cht=r(Rx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ike=n(Rx,"CODE",{});var gva=s(ike);fht=r(gva,"pretrained_model_name_or_path"),gva.forEach(t),ght=r(Rx,":"),Rx.forEach(t),hht=i(zi),dke=n(zi,"UL",{});var hva=s(dke);P7=n(hva,"LI",{});var Coo=s(P7);mke=n(Coo,"STRONG",{});var uva=s(mke);uht=r(uva,"vision-encoder-decoder"),uva.forEach(t),pht=r(Coo," \u2014 "),ule=n(Coo,"A",{href:!0});var pva=s(ule);_ht=r(pva,"TFVisionEncoderDecoderModel"),pva.forEach(t),bht=r(Coo," (Vision Encoder decoder model)"),Coo.forEach(t),hva.forEach(t),vht=i(zi),T(B7.$$.fragment,zi),zi.forEach(t),Xi.forEach(t),Fno=i(c),rf=n(c,"H2",{class:!0});var jlo=s(rf);I7=n(jlo,"A",{id:!0,class:!0,href:!0});var _va=s(I7);cke=n(_va,"SPAN",{});var bva=s(cke);T(NP.$$.fragment,bva),bva.forEach(t),_va.forEach(t),Fht=i(jlo),fke=n(jlo,"SPAN",{});var vva=s(fke);Tht=r(vva,"TFAutoModelForSpeechSeq2Seq"),vva.forEach(t),jlo.forEach(t),Tno=i(c),wr=n(c,"DIV",{class:!0});var Qi=s(wr);T(qP.$$.fragment,Qi),Mht=i(Qi),tf=n(Qi,"P",{});var Gce=s(tf);Eht=r(Gce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),ple=n(Gce,"A",{href:!0});var Fva=s(ple);Cht=r(Fva,"from_pretrained()"),Fva.forEach(t),wht=r(Gce," class method or the "),_le=n(Gce,"A",{href:!0});var Tva=s(_le);Aht=r(Tva,"from_config()"),Tva.forEach(t),Lht=r(Gce,` class
method.`),Gce.forEach(t),yht=i(Qi),DP=n(Qi,"P",{});var Glo=s(DP);xht=r(Glo,"This class cannot be instantiated directly using "),gke=n(Glo,"CODE",{});var Mva=s(gke);$ht=r(Mva,"__init__()"),Mva.forEach(t),kht=r(Glo," (throws an error)."),Glo.forEach(t),Sht=i(Qi),fa=n(Qi,"DIV",{class:!0});var Px=s(fa);T(jP.$$.fragment,Px),Rht=i(Px),hke=n(Px,"P",{});var Eva=s(hke);Pht=r(Eva,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Eva.forEach(t),Bht=i(Px),af=n(Px,"P",{});var Oce=s(af);Iht=r(Oce,`Note:
Loading a model from its configuration file does `),uke=n(Oce,"STRONG",{});var Cva=s(uke);Nht=r(Cva,"not"),Cva.forEach(t),qht=r(Oce,` load the model weights. It only affects the
model\u2019s configuration. Use `),ble=n(Oce,"A",{href:!0});var wva=s(ble);Dht=r(wva,"from_pretrained()"),wva.forEach(t),jht=r(Oce," to load the model weights."),Oce.forEach(t),Ght=i(Px),T(N7.$$.fragment,Px),Px.forEach(t),Oht=i(Qi),ot=n(Qi,"DIV",{class:!0});var Wi=s(ot);T(GP.$$.fragment,Wi),Vht=i(Wi),pke=n(Wi,"P",{});var Ava=s(pke);Xht=r(Ava,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Ava.forEach(t),zht=i(Wi),Jn=n(Wi,"P",{});var Bx=s(Jn);Qht=r(Bx,"The model class to instantiate is selected based on the "),_ke=n(Bx,"CODE",{});var Lva=s(_ke);Wht=r(Lva,"model_type"),Lva.forEach(t),Uht=r(Bx,` property of the config object (either
passed as an argument or loaded from `),bke=n(Bx,"CODE",{});var yva=s(bke);Hht=r(yva,"pretrained_model_name_or_path"),yva.forEach(t),Jht=r(Bx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vke=n(Bx,"CODE",{});var xva=s(vke);Yht=r(xva,"pretrained_model_name_or_path"),xva.forEach(t),Zht=r(Bx,":"),Bx.forEach(t),Kht=i(Wi),OP=n(Wi,"UL",{});var Olo=s(OP);q7=n(Olo,"LI",{});var woo=s(q7);Fke=n(woo,"STRONG",{});var $va=s(Fke);eut=r($va,"speech_to_text"),$va.forEach(t),out=r(woo," \u2014 "),vle=n(woo,"A",{href:!0});var kva=s(vle);rut=r(kva,"TFSpeech2TextForConditionalGeneration"),kva.forEach(t),tut=r(woo," (Speech2Text model)"),woo.forEach(t),aut=i(Olo),D7=n(Olo,"LI",{});var Aoo=s(D7);Tke=n(Aoo,"STRONG",{});var Sva=s(Tke);nut=r(Sva,"whisper"),Sva.forEach(t),sut=r(Aoo," \u2014 "),Fle=n(Aoo,"A",{href:!0});var Rva=s(Fle);lut=r(Rva,"TFWhisperForConditionalGeneration"),Rva.forEach(t),iut=r(Aoo," (Whisper model)"),Aoo.forEach(t),Olo.forEach(t),dut=i(Wi),T(j7.$$.fragment,Wi),Wi.forEach(t),Qi.forEach(t),Mno=i(c),nf=n(c,"H2",{class:!0});var Vlo=s(nf);G7=n(Vlo,"A",{id:!0,class:!0,href:!0});var Pva=s(G7);Mke=n(Pva,"SPAN",{});var Bva=s(Mke);T(VP.$$.fragment,Bva),Bva.forEach(t),Pva.forEach(t),mut=i(Vlo),Eke=n(Vlo,"SPAN",{});var Iva=s(Eke);cut=r(Iva,"FlaxAutoModel"),Iva.forEach(t),Vlo.forEach(t),Eno=i(c),Ar=n(c,"DIV",{class:!0});var Ui=s(Ar);T(XP.$$.fragment,Ui),fut=i(Ui),sf=n(Ui,"P",{});var Vce=s(sf);gut=r(Vce,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Tle=n(Vce,"A",{href:!0});var Nva=s(Tle);hut=r(Nva,"from_pretrained()"),Nva.forEach(t),uut=r(Vce," class method or the "),Mle=n(Vce,"A",{href:!0});var qva=s(Mle);put=r(qva,"from_config()"),qva.forEach(t),_ut=r(Vce,` class
method.`),Vce.forEach(t),but=i(Ui),zP=n(Ui,"P",{});var Xlo=s(zP);vut=r(Xlo,"This class cannot be instantiated directly using "),Cke=n(Xlo,"CODE",{});var Dva=s(Cke);Fut=r(Dva,"__init__()"),Dva.forEach(t),Tut=r(Xlo," (throws an error)."),Xlo.forEach(t),Mut=i(Ui),ga=n(Ui,"DIV",{class:!0});var Ix=s(ga);T(QP.$$.fragment,Ix),Eut=i(Ix),wke=n(Ix,"P",{});var jva=s(wke);Cut=r(jva,"Instantiates one of the base model classes of the library from a configuration."),jva.forEach(t),wut=i(Ix),lf=n(Ix,"P",{});var Xce=s(lf);Aut=r(Xce,`Note:
Loading a model from its configuration file does `),Ake=n(Xce,"STRONG",{});var Gva=s(Ake);Lut=r(Gva,"not"),Gva.forEach(t),yut=r(Xce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ele=n(Xce,"A",{href:!0});var Ova=s(Ele);xut=r(Ova,"from_pretrained()"),Ova.forEach(t),$ut=r(Xce," to load the model weights."),Xce.forEach(t),kut=i(Ix),T(O7.$$.fragment,Ix),Ix.forEach(t),Sut=i(Ui),rt=n(Ui,"DIV",{class:!0});var Hi=s(rt);T(WP.$$.fragment,Hi),Rut=i(Hi),Lke=n(Hi,"P",{});var Vva=s(Lke);Put=r(Vva,"Instantiate one of the base model classes of the library from a pretrained model."),Vva.forEach(t),But=i(Hi),Yn=n(Hi,"P",{});var Nx=s(Yn);Iut=r(Nx,"The model class to instantiate is selected based on the "),yke=n(Nx,"CODE",{});var Xva=s(yke);Nut=r(Xva,"model_type"),Xva.forEach(t),qut=r(Nx,` property of the config object (either
passed as an argument or loaded from `),xke=n(Nx,"CODE",{});var zva=s(xke);Dut=r(zva,"pretrained_model_name_or_path"),zva.forEach(t),jut=r(Nx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$ke=n(Nx,"CODE",{});var Qva=s($ke);Gut=r(Qva,"pretrained_model_name_or_path"),Qva.forEach(t),Out=r(Nx,":"),Nx.forEach(t),Vut=i(Hi),te=n(Hi,"UL",{});var ne=s(te);V7=n(ne,"LI",{});var Loo=s(V7);kke=n(Loo,"STRONG",{});var Wva=s(kke);Xut=r(Wva,"albert"),Wva.forEach(t),zut=r(Loo," \u2014 "),Cle=n(Loo,"A",{href:!0});var Uva=s(Cle);Qut=r(Uva,"FlaxAlbertModel"),Uva.forEach(t),Wut=r(Loo," (ALBERT model)"),Loo.forEach(t),Uut=i(ne),X7=n(ne,"LI",{});var yoo=s(X7);Ske=n(yoo,"STRONG",{});var Hva=s(Ske);Hut=r(Hva,"bart"),Hva.forEach(t),Jut=r(yoo," \u2014 "),wle=n(yoo,"A",{href:!0});var Jva=s(wle);Yut=r(Jva,"FlaxBartModel"),Jva.forEach(t),Zut=r(yoo," (BART model)"),yoo.forEach(t),Kut=i(ne),z7=n(ne,"LI",{});var xoo=s(z7);Rke=n(xoo,"STRONG",{});var Yva=s(Rke);ept=r(Yva,"beit"),Yva.forEach(t),opt=r(xoo," \u2014 "),Ale=n(xoo,"A",{href:!0});var Zva=s(Ale);rpt=r(Zva,"FlaxBeitModel"),Zva.forEach(t),tpt=r(xoo," (BEiT model)"),xoo.forEach(t),apt=i(ne),Q7=n(ne,"LI",{});var $oo=s(Q7);Pke=n($oo,"STRONG",{});var Kva=s(Pke);npt=r(Kva,"bert"),Kva.forEach(t),spt=r($oo," \u2014 "),Lle=n($oo,"A",{href:!0});var eFa=s(Lle);lpt=r(eFa,"FlaxBertModel"),eFa.forEach(t),ipt=r($oo," (BERT model)"),$oo.forEach(t),dpt=i(ne),W7=n(ne,"LI",{});var koo=s(W7);Bke=n(koo,"STRONG",{});var oFa=s(Bke);mpt=r(oFa,"big_bird"),oFa.forEach(t),cpt=r(koo," \u2014 "),yle=n(koo,"A",{href:!0});var rFa=s(yle);fpt=r(rFa,"FlaxBigBirdModel"),rFa.forEach(t),gpt=r(koo," (BigBird model)"),koo.forEach(t),hpt=i(ne),U7=n(ne,"LI",{});var Soo=s(U7);Ike=n(Soo,"STRONG",{});var tFa=s(Ike);upt=r(tFa,"blenderbot"),tFa.forEach(t),ppt=r(Soo," \u2014 "),xle=n(Soo,"A",{href:!0});var aFa=s(xle);_pt=r(aFa,"FlaxBlenderbotModel"),aFa.forEach(t),bpt=r(Soo," (Blenderbot model)"),Soo.forEach(t),vpt=i(ne),H7=n(ne,"LI",{});var Roo=s(H7);Nke=n(Roo,"STRONG",{});var nFa=s(Nke);Fpt=r(nFa,"blenderbot-small"),nFa.forEach(t),Tpt=r(Roo," \u2014 "),$le=n(Roo,"A",{href:!0});var sFa=s($le);Mpt=r(sFa,"FlaxBlenderbotSmallModel"),sFa.forEach(t),Ept=r(Roo," (BlenderbotSmall model)"),Roo.forEach(t),Cpt=i(ne),J7=n(ne,"LI",{});var Poo=s(J7);qke=n(Poo,"STRONG",{});var lFa=s(qke);wpt=r(lFa,"clip"),lFa.forEach(t),Apt=r(Poo," \u2014 "),kle=n(Poo,"A",{href:!0});var iFa=s(kle);Lpt=r(iFa,"FlaxCLIPModel"),iFa.forEach(t),ypt=r(Poo," (CLIP model)"),Poo.forEach(t),xpt=i(ne),Y7=n(ne,"LI",{});var Boo=s(Y7);Dke=n(Boo,"STRONG",{});var dFa=s(Dke);$pt=r(dFa,"distilbert"),dFa.forEach(t),kpt=r(Boo," \u2014 "),Sle=n(Boo,"A",{href:!0});var mFa=s(Sle);Spt=r(mFa,"FlaxDistilBertModel"),mFa.forEach(t),Rpt=r(Boo," (DistilBERT model)"),Boo.forEach(t),Ppt=i(ne),Z7=n(ne,"LI",{});var Ioo=s(Z7);jke=n(Ioo,"STRONG",{});var cFa=s(jke);Bpt=r(cFa,"electra"),cFa.forEach(t),Ipt=r(Ioo," \u2014 "),Rle=n(Ioo,"A",{href:!0});var fFa=s(Rle);Npt=r(fFa,"FlaxElectraModel"),fFa.forEach(t),qpt=r(Ioo," (ELECTRA model)"),Ioo.forEach(t),Dpt=i(ne),K7=n(ne,"LI",{});var Noo=s(K7);Gke=n(Noo,"STRONG",{});var gFa=s(Gke);jpt=r(gFa,"gpt2"),gFa.forEach(t),Gpt=r(Noo," \u2014 "),Ple=n(Noo,"A",{href:!0});var hFa=s(Ple);Opt=r(hFa,"FlaxGPT2Model"),hFa.forEach(t),Vpt=r(Noo," (OpenAI GPT-2 model)"),Noo.forEach(t),Xpt=i(ne),e8=n(ne,"LI",{});var qoo=s(e8);Oke=n(qoo,"STRONG",{});var uFa=s(Oke);zpt=r(uFa,"gpt_neo"),uFa.forEach(t),Qpt=r(qoo," \u2014 "),Ble=n(qoo,"A",{href:!0});var pFa=s(Ble);Wpt=r(pFa,"FlaxGPTNeoModel"),pFa.forEach(t),Upt=r(qoo," (GPT Neo model)"),qoo.forEach(t),Hpt=i(ne),o8=n(ne,"LI",{});var Doo=s(o8);Vke=n(Doo,"STRONG",{});var _Fa=s(Vke);Jpt=r(_Fa,"gptj"),_Fa.forEach(t),Ypt=r(Doo," \u2014 "),Ile=n(Doo,"A",{href:!0});var bFa=s(Ile);Zpt=r(bFa,"FlaxGPTJModel"),bFa.forEach(t),Kpt=r(Doo," (GPT-J model)"),Doo.forEach(t),e_t=i(ne),r8=n(ne,"LI",{});var joo=s(r8);Xke=n(joo,"STRONG",{});var vFa=s(Xke);o_t=r(vFa,"longt5"),vFa.forEach(t),r_t=r(joo," \u2014 "),Nle=n(joo,"A",{href:!0});var FFa=s(Nle);t_t=r(FFa,"FlaxLongT5Model"),FFa.forEach(t),a_t=r(joo," (LongT5 model)"),joo.forEach(t),n_t=i(ne),t8=n(ne,"LI",{});var Goo=s(t8);zke=n(Goo,"STRONG",{});var TFa=s(zke);s_t=r(TFa,"marian"),TFa.forEach(t),l_t=r(Goo," \u2014 "),qle=n(Goo,"A",{href:!0});var MFa=s(qle);i_t=r(MFa,"FlaxMarianModel"),MFa.forEach(t),d_t=r(Goo," (Marian model)"),Goo.forEach(t),m_t=i(ne),a8=n(ne,"LI",{});var Ooo=s(a8);Qke=n(Ooo,"STRONG",{});var EFa=s(Qke);c_t=r(EFa,"mbart"),EFa.forEach(t),f_t=r(Ooo," \u2014 "),Dle=n(Ooo,"A",{href:!0});var CFa=s(Dle);g_t=r(CFa,"FlaxMBartModel"),CFa.forEach(t),h_t=r(Ooo," (mBART model)"),Ooo.forEach(t),u_t=i(ne),n8=n(ne,"LI",{});var Voo=s(n8);Wke=n(Voo,"STRONG",{});var wFa=s(Wke);p_t=r(wFa,"mt5"),wFa.forEach(t),__t=r(Voo," \u2014 "),jle=n(Voo,"A",{href:!0});var AFa=s(jle);b_t=r(AFa,"FlaxMT5Model"),AFa.forEach(t),v_t=r(Voo," (MT5 model)"),Voo.forEach(t),F_t=i(ne),s8=n(ne,"LI",{});var Xoo=s(s8);Uke=n(Xoo,"STRONG",{});var LFa=s(Uke);T_t=r(LFa,"opt"),LFa.forEach(t),M_t=r(Xoo," \u2014 "),Gle=n(Xoo,"A",{href:!0});var yFa=s(Gle);E_t=r(yFa,"FlaxOPTModel"),yFa.forEach(t),C_t=r(Xoo," (OPT model)"),Xoo.forEach(t),w_t=i(ne),l8=n(ne,"LI",{});var zoo=s(l8);Hke=n(zoo,"STRONG",{});var xFa=s(Hke);A_t=r(xFa,"pegasus"),xFa.forEach(t),L_t=r(zoo," \u2014 "),Ole=n(zoo,"A",{href:!0});var $Fa=s(Ole);y_t=r($Fa,"FlaxPegasusModel"),$Fa.forEach(t),x_t=r(zoo," (Pegasus model)"),zoo.forEach(t),$_t=i(ne),i8=n(ne,"LI",{});var Qoo=s(i8);Jke=n(Qoo,"STRONG",{});var kFa=s(Jke);k_t=r(kFa,"roberta"),kFa.forEach(t),S_t=r(Qoo," \u2014 "),Vle=n(Qoo,"A",{href:!0});var SFa=s(Vle);R_t=r(SFa,"FlaxRobertaModel"),SFa.forEach(t),P_t=r(Qoo," (RoBERTa model)"),Qoo.forEach(t),B_t=i(ne),d8=n(ne,"LI",{});var Woo=s(d8);Yke=n(Woo,"STRONG",{});var RFa=s(Yke);I_t=r(RFa,"roformer"),RFa.forEach(t),N_t=r(Woo," \u2014 "),Xle=n(Woo,"A",{href:!0});var PFa=s(Xle);q_t=r(PFa,"FlaxRoFormerModel"),PFa.forEach(t),D_t=r(Woo," (RoFormer model)"),Woo.forEach(t),j_t=i(ne),m8=n(ne,"LI",{});var Uoo=s(m8);Zke=n(Uoo,"STRONG",{});var BFa=s(Zke);G_t=r(BFa,"t5"),BFa.forEach(t),O_t=r(Uoo," \u2014 "),zle=n(Uoo,"A",{href:!0});var IFa=s(zle);V_t=r(IFa,"FlaxT5Model"),IFa.forEach(t),X_t=r(Uoo," (T5 model)"),Uoo.forEach(t),z_t=i(ne),c8=n(ne,"LI",{});var Hoo=s(c8);Kke=n(Hoo,"STRONG",{});var NFa=s(Kke);Q_t=r(NFa,"vision-text-dual-encoder"),NFa.forEach(t),W_t=r(Hoo," \u2014 "),Qle=n(Hoo,"A",{href:!0});var qFa=s(Qle);U_t=r(qFa,"FlaxVisionTextDualEncoderModel"),qFa.forEach(t),H_t=r(Hoo," (VisionTextDualEncoder model)"),Hoo.forEach(t),J_t=i(ne),f8=n(ne,"LI",{});var Joo=s(f8);eSe=n(Joo,"STRONG",{});var DFa=s(eSe);Y_t=r(DFa,"vit"),DFa.forEach(t),Z_t=r(Joo," \u2014 "),Wle=n(Joo,"A",{href:!0});var jFa=s(Wle);K_t=r(jFa,"FlaxViTModel"),jFa.forEach(t),e1t=r(Joo," (ViT model)"),Joo.forEach(t),o1t=i(ne),g8=n(ne,"LI",{});var Yoo=s(g8);oSe=n(Yoo,"STRONG",{});var GFa=s(oSe);r1t=r(GFa,"wav2vec2"),GFa.forEach(t),t1t=r(Yoo," \u2014 "),Ule=n(Yoo,"A",{href:!0});var OFa=s(Ule);a1t=r(OFa,"FlaxWav2Vec2Model"),OFa.forEach(t),n1t=r(Yoo," (Wav2Vec2 model)"),Yoo.forEach(t),s1t=i(ne),h8=n(ne,"LI",{});var Zoo=s(h8);rSe=n(Zoo,"STRONG",{});var VFa=s(rSe);l1t=r(VFa,"xglm"),VFa.forEach(t),i1t=r(Zoo," \u2014 "),Hle=n(Zoo,"A",{href:!0});var XFa=s(Hle);d1t=r(XFa,"FlaxXGLMModel"),XFa.forEach(t),m1t=r(Zoo," (XGLM model)"),Zoo.forEach(t),c1t=i(ne),u8=n(ne,"LI",{});var Koo=s(u8);tSe=n(Koo,"STRONG",{});var zFa=s(tSe);f1t=r(zFa,"xlm-roberta"),zFa.forEach(t),g1t=r(Koo," \u2014 "),Jle=n(Koo,"A",{href:!0});var QFa=s(Jle);h1t=r(QFa,"FlaxXLMRobertaModel"),QFa.forEach(t),u1t=r(Koo," (XLM-RoBERTa model)"),Koo.forEach(t),ne.forEach(t),p1t=i(Hi),T(p8.$$.fragment,Hi),Hi.forEach(t),Ui.forEach(t),Cno=i(c),df=n(c,"H2",{class:!0});var zlo=s(df);_8=n(zlo,"A",{id:!0,class:!0,href:!0});var WFa=s(_8);aSe=n(WFa,"SPAN",{});var UFa=s(aSe);T(UP.$$.fragment,UFa),UFa.forEach(t),WFa.forEach(t),_1t=i(zlo),nSe=n(zlo,"SPAN",{});var HFa=s(nSe);b1t=r(HFa,"FlaxAutoModelForCausalLM"),HFa.forEach(t),zlo.forEach(t),wno=i(c),Lr=n(c,"DIV",{class:!0});var Ji=s(Lr);T(HP.$$.fragment,Ji),v1t=i(Ji),mf=n(Ji,"P",{});var zce=s(mf);F1t=r(zce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Yle=n(zce,"A",{href:!0});var JFa=s(Yle);T1t=r(JFa,"from_pretrained()"),JFa.forEach(t),M1t=r(zce," class method or the "),Zle=n(zce,"A",{href:!0});var YFa=s(Zle);E1t=r(YFa,"from_config()"),YFa.forEach(t),C1t=r(zce,` class
method.`),zce.forEach(t),w1t=i(Ji),JP=n(Ji,"P",{});var Qlo=s(JP);A1t=r(Qlo,"This class cannot be instantiated directly using "),sSe=n(Qlo,"CODE",{});var ZFa=s(sSe);L1t=r(ZFa,"__init__()"),ZFa.forEach(t),y1t=r(Qlo," (throws an error)."),Qlo.forEach(t),x1t=i(Ji),ha=n(Ji,"DIV",{class:!0});var qx=s(ha);T(YP.$$.fragment,qx),$1t=i(qx),lSe=n(qx,"P",{});var KFa=s(lSe);k1t=r(KFa,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),KFa.forEach(t),S1t=i(qx),cf=n(qx,"P",{});var Qce=s(cf);R1t=r(Qce,`Note:
Loading a model from its configuration file does `),iSe=n(Qce,"STRONG",{});var eTa=s(iSe);P1t=r(eTa,"not"),eTa.forEach(t),B1t=r(Qce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Kle=n(Qce,"A",{href:!0});var oTa=s(Kle);I1t=r(oTa,"from_pretrained()"),oTa.forEach(t),N1t=r(Qce," to load the model weights."),Qce.forEach(t),q1t=i(qx),T(b8.$$.fragment,qx),qx.forEach(t),D1t=i(Ji),tt=n(Ji,"DIV",{class:!0});var Yi=s(tt);T(ZP.$$.fragment,Yi),j1t=i(Yi),dSe=n(Yi,"P",{});var rTa=s(dSe);G1t=r(rTa,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),rTa.forEach(t),O1t=i(Yi),Zn=n(Yi,"P",{});var Dx=s(Zn);V1t=r(Dx,"The model class to instantiate is selected based on the "),mSe=n(Dx,"CODE",{});var tTa=s(mSe);X1t=r(tTa,"model_type"),tTa.forEach(t),z1t=r(Dx,` property of the config object (either
passed as an argument or loaded from `),cSe=n(Dx,"CODE",{});var aTa=s(cSe);Q1t=r(aTa,"pretrained_model_name_or_path"),aTa.forEach(t),W1t=r(Dx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fSe=n(Dx,"CODE",{});var nTa=s(fSe);U1t=r(nTa,"pretrained_model_name_or_path"),nTa.forEach(t),H1t=r(Dx,":"),Dx.forEach(t),J1t=i(Yi),$e=n(Yi,"UL",{});var De=s($e);v8=n(De,"LI",{});var ero=s(v8);gSe=n(ero,"STRONG",{});var sTa=s(gSe);Y1t=r(sTa,"bart"),sTa.forEach(t),Z1t=r(ero," \u2014 "),eie=n(ero,"A",{href:!0});var lTa=s(eie);K1t=r(lTa,"FlaxBartForCausalLM"),lTa.forEach(t),e2t=r(ero," (BART model)"),ero.forEach(t),o2t=i(De),F8=n(De,"LI",{});var oro=s(F8);hSe=n(oro,"STRONG",{});var iTa=s(hSe);r2t=r(iTa,"bert"),iTa.forEach(t),t2t=r(oro," \u2014 "),oie=n(oro,"A",{href:!0});var dTa=s(oie);a2t=r(dTa,"FlaxBertForCausalLM"),dTa.forEach(t),n2t=r(oro," (BERT model)"),oro.forEach(t),s2t=i(De),T8=n(De,"LI",{});var rro=s(T8);uSe=n(rro,"STRONG",{});var mTa=s(uSe);l2t=r(mTa,"big_bird"),mTa.forEach(t),i2t=r(rro," \u2014 "),rie=n(rro,"A",{href:!0});var cTa=s(rie);d2t=r(cTa,"FlaxBigBirdForCausalLM"),cTa.forEach(t),m2t=r(rro," (BigBird model)"),rro.forEach(t),c2t=i(De),M8=n(De,"LI",{});var tro=s(M8);pSe=n(tro,"STRONG",{});var fTa=s(pSe);f2t=r(fTa,"electra"),fTa.forEach(t),g2t=r(tro," \u2014 "),tie=n(tro,"A",{href:!0});var gTa=s(tie);h2t=r(gTa,"FlaxElectraForCausalLM"),gTa.forEach(t),u2t=r(tro," (ELECTRA model)"),tro.forEach(t),p2t=i(De),E8=n(De,"LI",{});var aro=s(E8);_Se=n(aro,"STRONG",{});var hTa=s(_Se);_2t=r(hTa,"gpt2"),hTa.forEach(t),b2t=r(aro," \u2014 "),aie=n(aro,"A",{href:!0});var uTa=s(aie);v2t=r(uTa,"FlaxGPT2LMHeadModel"),uTa.forEach(t),F2t=r(aro," (OpenAI GPT-2 model)"),aro.forEach(t),T2t=i(De),C8=n(De,"LI",{});var nro=s(C8);bSe=n(nro,"STRONG",{});var pTa=s(bSe);M2t=r(pTa,"gpt_neo"),pTa.forEach(t),E2t=r(nro," \u2014 "),nie=n(nro,"A",{href:!0});var _Ta=s(nie);C2t=r(_Ta,"FlaxGPTNeoForCausalLM"),_Ta.forEach(t),w2t=r(nro," (GPT Neo model)"),nro.forEach(t),A2t=i(De),w8=n(De,"LI",{});var sro=s(w8);vSe=n(sro,"STRONG",{});var bTa=s(vSe);L2t=r(bTa,"gptj"),bTa.forEach(t),y2t=r(sro," \u2014 "),sie=n(sro,"A",{href:!0});var vTa=s(sie);x2t=r(vTa,"FlaxGPTJForCausalLM"),vTa.forEach(t),$2t=r(sro," (GPT-J model)"),sro.forEach(t),k2t=i(De),A8=n(De,"LI",{});var lro=s(A8);FSe=n(lro,"STRONG",{});var FTa=s(FSe);S2t=r(FTa,"opt"),FTa.forEach(t),R2t=r(lro," \u2014 "),lie=n(lro,"A",{href:!0});var TTa=s(lie);P2t=r(TTa,"FlaxOPTForCausalLM"),TTa.forEach(t),B2t=r(lro," (OPT model)"),lro.forEach(t),I2t=i(De),L8=n(De,"LI",{});var iro=s(L8);TSe=n(iro,"STRONG",{});var MTa=s(TSe);N2t=r(MTa,"roberta"),MTa.forEach(t),q2t=r(iro," \u2014 "),iie=n(iro,"A",{href:!0});var ETa=s(iie);D2t=r(ETa,"FlaxRobertaForCausalLM"),ETa.forEach(t),j2t=r(iro," (RoBERTa model)"),iro.forEach(t),G2t=i(De),y8=n(De,"LI",{});var dro=s(y8);MSe=n(dro,"STRONG",{});var CTa=s(MSe);O2t=r(CTa,"xglm"),CTa.forEach(t),V2t=r(dro," \u2014 "),die=n(dro,"A",{href:!0});var wTa=s(die);X2t=r(wTa,"FlaxXGLMForCausalLM"),wTa.forEach(t),z2t=r(dro," (XGLM model)"),dro.forEach(t),De.forEach(t),Q2t=i(Yi),T(x8.$$.fragment,Yi),Yi.forEach(t),Ji.forEach(t),Ano=i(c),ff=n(c,"H2",{class:!0});var Wlo=s(ff);$8=n(Wlo,"A",{id:!0,class:!0,href:!0});var ATa=s($8);ESe=n(ATa,"SPAN",{});var LTa=s(ESe);T(KP.$$.fragment,LTa),LTa.forEach(t),ATa.forEach(t),W2t=i(Wlo),CSe=n(Wlo,"SPAN",{});var yTa=s(CSe);U2t=r(yTa,"FlaxAutoModelForPreTraining"),yTa.forEach(t),Wlo.forEach(t),Lno=i(c),yr=n(c,"DIV",{class:!0});var Zi=s(yr);T(eB.$$.fragment,Zi),H2t=i(Zi),gf=n(Zi,"P",{});var Wce=s(gf);J2t=r(Wce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),mie=n(Wce,"A",{href:!0});var xTa=s(mie);Y2t=r(xTa,"from_pretrained()"),xTa.forEach(t),Z2t=r(Wce," class method or the "),cie=n(Wce,"A",{href:!0});var $Ta=s(cie);K2t=r($Ta,"from_config()"),$Ta.forEach(t),ebt=r(Wce,` class
method.`),Wce.forEach(t),obt=i(Zi),oB=n(Zi,"P",{});var Ulo=s(oB);rbt=r(Ulo,"This class cannot be instantiated directly using "),wSe=n(Ulo,"CODE",{});var kTa=s(wSe);tbt=r(kTa,"__init__()"),kTa.forEach(t),abt=r(Ulo," (throws an error)."),Ulo.forEach(t),nbt=i(Zi),ua=n(Zi,"DIV",{class:!0});var jx=s(ua);T(rB.$$.fragment,jx),sbt=i(jx),ASe=n(jx,"P",{});var STa=s(ASe);lbt=r(STa,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),STa.forEach(t),ibt=i(jx),hf=n(jx,"P",{});var Uce=s(hf);dbt=r(Uce,`Note:
Loading a model from its configuration file does `),LSe=n(Uce,"STRONG",{});var RTa=s(LSe);mbt=r(RTa,"not"),RTa.forEach(t),cbt=r(Uce,` load the model weights. It only affects the
model\u2019s configuration. Use `),fie=n(Uce,"A",{href:!0});var PTa=s(fie);fbt=r(PTa,"from_pretrained()"),PTa.forEach(t),gbt=r(Uce," to load the model weights."),Uce.forEach(t),hbt=i(jx),T(k8.$$.fragment,jx),jx.forEach(t),ubt=i(Zi),at=n(Zi,"DIV",{class:!0});var Ki=s(at);T(tB.$$.fragment,Ki),pbt=i(Ki),ySe=n(Ki,"P",{});var BTa=s(ySe);_bt=r(BTa,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),BTa.forEach(t),bbt=i(Ki),Kn=n(Ki,"P",{});var Gx=s(Kn);vbt=r(Gx,"The model class to instantiate is selected based on the "),xSe=n(Gx,"CODE",{});var ITa=s(xSe);Fbt=r(ITa,"model_type"),ITa.forEach(t),Tbt=r(Gx,` property of the config object (either
passed as an argument or loaded from `),$Se=n(Gx,"CODE",{});var NTa=s($Se);Mbt=r(NTa,"pretrained_model_name_or_path"),NTa.forEach(t),Ebt=r(Gx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kSe=n(Gx,"CODE",{});var qTa=s(kSe);Cbt=r(qTa,"pretrained_model_name_or_path"),qTa.forEach(t),wbt=r(Gx,":"),Gx.forEach(t),Abt=i(Ki),Ee=n(Ki,"UL",{});var we=s(Ee);S8=n(we,"LI",{});var mro=s(S8);SSe=n(mro,"STRONG",{});var DTa=s(SSe);Lbt=r(DTa,"albert"),DTa.forEach(t),ybt=r(mro," \u2014 "),gie=n(mro,"A",{href:!0});var jTa=s(gie);xbt=r(jTa,"FlaxAlbertForPreTraining"),jTa.forEach(t),$bt=r(mro," (ALBERT model)"),mro.forEach(t),kbt=i(we),R8=n(we,"LI",{});var cro=s(R8);RSe=n(cro,"STRONG",{});var GTa=s(RSe);Sbt=r(GTa,"bart"),GTa.forEach(t),Rbt=r(cro," \u2014 "),hie=n(cro,"A",{href:!0});var OTa=s(hie);Pbt=r(OTa,"FlaxBartForConditionalGeneration"),OTa.forEach(t),Bbt=r(cro," (BART model)"),cro.forEach(t),Ibt=i(we),P8=n(we,"LI",{});var fro=s(P8);PSe=n(fro,"STRONG",{});var VTa=s(PSe);Nbt=r(VTa,"bert"),VTa.forEach(t),qbt=r(fro," \u2014 "),uie=n(fro,"A",{href:!0});var XTa=s(uie);Dbt=r(XTa,"FlaxBertForPreTraining"),XTa.forEach(t),jbt=r(fro," (BERT model)"),fro.forEach(t),Gbt=i(we),B8=n(we,"LI",{});var gro=s(B8);BSe=n(gro,"STRONG",{});var zTa=s(BSe);Obt=r(zTa,"big_bird"),zTa.forEach(t),Vbt=r(gro," \u2014 "),pie=n(gro,"A",{href:!0});var QTa=s(pie);Xbt=r(QTa,"FlaxBigBirdForPreTraining"),QTa.forEach(t),zbt=r(gro," (BigBird model)"),gro.forEach(t),Qbt=i(we),I8=n(we,"LI",{});var hro=s(I8);ISe=n(hro,"STRONG",{});var WTa=s(ISe);Wbt=r(WTa,"electra"),WTa.forEach(t),Ubt=r(hro," \u2014 "),_ie=n(hro,"A",{href:!0});var UTa=s(_ie);Hbt=r(UTa,"FlaxElectraForPreTraining"),UTa.forEach(t),Jbt=r(hro," (ELECTRA model)"),hro.forEach(t),Ybt=i(we),N8=n(we,"LI",{});var uro=s(N8);NSe=n(uro,"STRONG",{});var HTa=s(NSe);Zbt=r(HTa,"longt5"),HTa.forEach(t),Kbt=r(uro," \u2014 "),bie=n(uro,"A",{href:!0});var JTa=s(bie);evt=r(JTa,"FlaxLongT5ForConditionalGeneration"),JTa.forEach(t),ovt=r(uro," (LongT5 model)"),uro.forEach(t),rvt=i(we),q8=n(we,"LI",{});var pro=s(q8);qSe=n(pro,"STRONG",{});var YTa=s(qSe);tvt=r(YTa,"mbart"),YTa.forEach(t),avt=r(pro," \u2014 "),vie=n(pro,"A",{href:!0});var ZTa=s(vie);nvt=r(ZTa,"FlaxMBartForConditionalGeneration"),ZTa.forEach(t),svt=r(pro," (mBART model)"),pro.forEach(t),lvt=i(we),D8=n(we,"LI",{});var _ro=s(D8);DSe=n(_ro,"STRONG",{});var KTa=s(DSe);ivt=r(KTa,"mt5"),KTa.forEach(t),dvt=r(_ro," \u2014 "),Fie=n(_ro,"A",{href:!0});var eMa=s(Fie);mvt=r(eMa,"FlaxMT5ForConditionalGeneration"),eMa.forEach(t),cvt=r(_ro," (MT5 model)"),_ro.forEach(t),fvt=i(we),j8=n(we,"LI",{});var bro=s(j8);jSe=n(bro,"STRONG",{});var oMa=s(jSe);gvt=r(oMa,"roberta"),oMa.forEach(t),hvt=r(bro," \u2014 "),Tie=n(bro,"A",{href:!0});var rMa=s(Tie);uvt=r(rMa,"FlaxRobertaForMaskedLM"),rMa.forEach(t),pvt=r(bro," (RoBERTa model)"),bro.forEach(t),_vt=i(we),G8=n(we,"LI",{});var vro=s(G8);GSe=n(vro,"STRONG",{});var tMa=s(GSe);bvt=r(tMa,"roformer"),tMa.forEach(t),vvt=r(vro," \u2014 "),Mie=n(vro,"A",{href:!0});var aMa=s(Mie);Fvt=r(aMa,"FlaxRoFormerForMaskedLM"),aMa.forEach(t),Tvt=r(vro," (RoFormer model)"),vro.forEach(t),Mvt=i(we),O8=n(we,"LI",{});var Fro=s(O8);OSe=n(Fro,"STRONG",{});var nMa=s(OSe);Evt=r(nMa,"t5"),nMa.forEach(t),Cvt=r(Fro," \u2014 "),Eie=n(Fro,"A",{href:!0});var sMa=s(Eie);wvt=r(sMa,"FlaxT5ForConditionalGeneration"),sMa.forEach(t),Avt=r(Fro," (T5 model)"),Fro.forEach(t),Lvt=i(we),V8=n(we,"LI",{});var Tro=s(V8);VSe=n(Tro,"STRONG",{});var lMa=s(VSe);yvt=r(lMa,"wav2vec2"),lMa.forEach(t),xvt=r(Tro," \u2014 "),Cie=n(Tro,"A",{href:!0});var iMa=s(Cie);$vt=r(iMa,"FlaxWav2Vec2ForPreTraining"),iMa.forEach(t),kvt=r(Tro," (Wav2Vec2 model)"),Tro.forEach(t),Svt=i(we),X8=n(we,"LI",{});var Mro=s(X8);XSe=n(Mro,"STRONG",{});var dMa=s(XSe);Rvt=r(dMa,"xlm-roberta"),dMa.forEach(t),Pvt=r(Mro," \u2014 "),wie=n(Mro,"A",{href:!0});var mMa=s(wie);Bvt=r(mMa,"FlaxXLMRobertaForMaskedLM"),mMa.forEach(t),Ivt=r(Mro," (XLM-RoBERTa model)"),Mro.forEach(t),we.forEach(t),Nvt=i(Ki),T(z8.$$.fragment,Ki),Ki.forEach(t),Zi.forEach(t),yno=i(c),uf=n(c,"H2",{class:!0});var Hlo=s(uf);Q8=n(Hlo,"A",{id:!0,class:!0,href:!0});var cMa=s(Q8);zSe=n(cMa,"SPAN",{});var fMa=s(zSe);T(aB.$$.fragment,fMa),fMa.forEach(t),cMa.forEach(t),qvt=i(Hlo),QSe=n(Hlo,"SPAN",{});var gMa=s(QSe);Dvt=r(gMa,"FlaxAutoModelForMaskedLM"),gMa.forEach(t),Hlo.forEach(t),xno=i(c),xr=n(c,"DIV",{class:!0});var ed=s(xr);T(nB.$$.fragment,ed),jvt=i(ed),pf=n(ed,"P",{});var Hce=s(pf);Gvt=r(Hce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Aie=n(Hce,"A",{href:!0});var hMa=s(Aie);Ovt=r(hMa,"from_pretrained()"),hMa.forEach(t),Vvt=r(Hce," class method or the "),Lie=n(Hce,"A",{href:!0});var uMa=s(Lie);Xvt=r(uMa,"from_config()"),uMa.forEach(t),zvt=r(Hce,` class
method.`),Hce.forEach(t),Qvt=i(ed),sB=n(ed,"P",{});var Jlo=s(sB);Wvt=r(Jlo,"This class cannot be instantiated directly using "),WSe=n(Jlo,"CODE",{});var pMa=s(WSe);Uvt=r(pMa,"__init__()"),pMa.forEach(t),Hvt=r(Jlo," (throws an error)."),Jlo.forEach(t),Jvt=i(ed),pa=n(ed,"DIV",{class:!0});var Ox=s(pa);T(lB.$$.fragment,Ox),Yvt=i(Ox),USe=n(Ox,"P",{});var _Ma=s(USe);Zvt=r(_Ma,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),_Ma.forEach(t),Kvt=i(Ox),_f=n(Ox,"P",{});var Jce=s(_f);eFt=r(Jce,`Note:
Loading a model from its configuration file does `),HSe=n(Jce,"STRONG",{});var bMa=s(HSe);oFt=r(bMa,"not"),bMa.forEach(t),rFt=r(Jce,` load the model weights. It only affects the
model\u2019s configuration. Use `),yie=n(Jce,"A",{href:!0});var vMa=s(yie);tFt=r(vMa,"from_pretrained()"),vMa.forEach(t),aFt=r(Jce," to load the model weights."),Jce.forEach(t),nFt=i(Ox),T(W8.$$.fragment,Ox),Ox.forEach(t),sFt=i(ed),nt=n(ed,"DIV",{class:!0});var od=s(nt);T(iB.$$.fragment,od),lFt=i(od),JSe=n(od,"P",{});var FMa=s(JSe);iFt=r(FMa,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),FMa.forEach(t),dFt=i(od),es=n(od,"P",{});var Vx=s(es);mFt=r(Vx,"The model class to instantiate is selected based on the "),YSe=n(Vx,"CODE",{});var TMa=s(YSe);cFt=r(TMa,"model_type"),TMa.forEach(t),fFt=r(Vx,` property of the config object (either
passed as an argument or loaded from `),ZSe=n(Vx,"CODE",{});var MMa=s(ZSe);gFt=r(MMa,"pretrained_model_name_or_path"),MMa.forEach(t),hFt=r(Vx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KSe=n(Vx,"CODE",{});var EMa=s(KSe);uFt=r(EMa,"pretrained_model_name_or_path"),EMa.forEach(t),pFt=r(Vx,":"),Vx.forEach(t),_Ft=i(od),ke=n(od,"UL",{});var je=s(ke);U8=n(je,"LI",{});var Ero=s(U8);eRe=n(Ero,"STRONG",{});var CMa=s(eRe);bFt=r(CMa,"albert"),CMa.forEach(t),vFt=r(Ero," \u2014 "),xie=n(Ero,"A",{href:!0});var wMa=s(xie);FFt=r(wMa,"FlaxAlbertForMaskedLM"),wMa.forEach(t),TFt=r(Ero," (ALBERT model)"),Ero.forEach(t),MFt=i(je),H8=n(je,"LI",{});var Cro=s(H8);oRe=n(Cro,"STRONG",{});var AMa=s(oRe);EFt=r(AMa,"bart"),AMa.forEach(t),CFt=r(Cro," \u2014 "),$ie=n(Cro,"A",{href:!0});var LMa=s($ie);wFt=r(LMa,"FlaxBartForConditionalGeneration"),LMa.forEach(t),AFt=r(Cro," (BART model)"),Cro.forEach(t),LFt=i(je),J8=n(je,"LI",{});var wro=s(J8);rRe=n(wro,"STRONG",{});var yMa=s(rRe);yFt=r(yMa,"bert"),yMa.forEach(t),xFt=r(wro," \u2014 "),kie=n(wro,"A",{href:!0});var xMa=s(kie);$Ft=r(xMa,"FlaxBertForMaskedLM"),xMa.forEach(t),kFt=r(wro," (BERT model)"),wro.forEach(t),SFt=i(je),Y8=n(je,"LI",{});var Aro=s(Y8);tRe=n(Aro,"STRONG",{});var $Ma=s(tRe);RFt=r($Ma,"big_bird"),$Ma.forEach(t),PFt=r(Aro," \u2014 "),Sie=n(Aro,"A",{href:!0});var kMa=s(Sie);BFt=r(kMa,"FlaxBigBirdForMaskedLM"),kMa.forEach(t),IFt=r(Aro," (BigBird model)"),Aro.forEach(t),NFt=i(je),Z8=n(je,"LI",{});var Lro=s(Z8);aRe=n(Lro,"STRONG",{});var SMa=s(aRe);qFt=r(SMa,"distilbert"),SMa.forEach(t),DFt=r(Lro," \u2014 "),Rie=n(Lro,"A",{href:!0});var RMa=s(Rie);jFt=r(RMa,"FlaxDistilBertForMaskedLM"),RMa.forEach(t),GFt=r(Lro," (DistilBERT model)"),Lro.forEach(t),OFt=i(je),K8=n(je,"LI",{});var yro=s(K8);nRe=n(yro,"STRONG",{});var PMa=s(nRe);VFt=r(PMa,"electra"),PMa.forEach(t),XFt=r(yro," \u2014 "),Pie=n(yro,"A",{href:!0});var BMa=s(Pie);zFt=r(BMa,"FlaxElectraForMaskedLM"),BMa.forEach(t),QFt=r(yro," (ELECTRA model)"),yro.forEach(t),WFt=i(je),eL=n(je,"LI",{});var xro=s(eL);sRe=n(xro,"STRONG",{});var IMa=s(sRe);UFt=r(IMa,"mbart"),IMa.forEach(t),HFt=r(xro," \u2014 "),Bie=n(xro,"A",{href:!0});var NMa=s(Bie);JFt=r(NMa,"FlaxMBartForConditionalGeneration"),NMa.forEach(t),YFt=r(xro," (mBART model)"),xro.forEach(t),ZFt=i(je),oL=n(je,"LI",{});var $ro=s(oL);lRe=n($ro,"STRONG",{});var qMa=s(lRe);KFt=r(qMa,"roberta"),qMa.forEach(t),eTt=r($ro," \u2014 "),Iie=n($ro,"A",{href:!0});var DMa=s(Iie);oTt=r(DMa,"FlaxRobertaForMaskedLM"),DMa.forEach(t),rTt=r($ro," (RoBERTa model)"),$ro.forEach(t),tTt=i(je),rL=n(je,"LI",{});var kro=s(rL);iRe=n(kro,"STRONG",{});var jMa=s(iRe);aTt=r(jMa,"roformer"),jMa.forEach(t),nTt=r(kro," \u2014 "),Nie=n(kro,"A",{href:!0});var GMa=s(Nie);sTt=r(GMa,"FlaxRoFormerForMaskedLM"),GMa.forEach(t),lTt=r(kro," (RoFormer model)"),kro.forEach(t),iTt=i(je),tL=n(je,"LI",{});var Sro=s(tL);dRe=n(Sro,"STRONG",{});var OMa=s(dRe);dTt=r(OMa,"xlm-roberta"),OMa.forEach(t),mTt=r(Sro," \u2014 "),qie=n(Sro,"A",{href:!0});var VMa=s(qie);cTt=r(VMa,"FlaxXLMRobertaForMaskedLM"),VMa.forEach(t),fTt=r(Sro," (XLM-RoBERTa model)"),Sro.forEach(t),je.forEach(t),gTt=i(od),T(aL.$$.fragment,od),od.forEach(t),ed.forEach(t),$no=i(c),bf=n(c,"H2",{class:!0});var Ylo=s(bf);nL=n(Ylo,"A",{id:!0,class:!0,href:!0});var XMa=s(nL);mRe=n(XMa,"SPAN",{});var zMa=s(mRe);T(dB.$$.fragment,zMa),zMa.forEach(t),XMa.forEach(t),hTt=i(Ylo),cRe=n(Ylo,"SPAN",{});var QMa=s(cRe);uTt=r(QMa,"FlaxAutoModelForSeq2SeqLM"),QMa.forEach(t),Ylo.forEach(t),kno=i(c),$r=n(c,"DIV",{class:!0});var rd=s($r);T(mB.$$.fragment,rd),pTt=i(rd),vf=n(rd,"P",{});var Yce=s(vf);_Tt=r(Yce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Die=n(Yce,"A",{href:!0});var WMa=s(Die);bTt=r(WMa,"from_pretrained()"),WMa.forEach(t),vTt=r(Yce," class method or the "),jie=n(Yce,"A",{href:!0});var UMa=s(jie);FTt=r(UMa,"from_config()"),UMa.forEach(t),TTt=r(Yce,` class
method.`),Yce.forEach(t),MTt=i(rd),cB=n(rd,"P",{});var Zlo=s(cB);ETt=r(Zlo,"This class cannot be instantiated directly using "),fRe=n(Zlo,"CODE",{});var HMa=s(fRe);CTt=r(HMa,"__init__()"),HMa.forEach(t),wTt=r(Zlo," (throws an error)."),Zlo.forEach(t),ATt=i(rd),_a=n(rd,"DIV",{class:!0});var Xx=s(_a);T(fB.$$.fragment,Xx),LTt=i(Xx),gRe=n(Xx,"P",{});var JMa=s(gRe);yTt=r(JMa,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),JMa.forEach(t),xTt=i(Xx),Ff=n(Xx,"P",{});var Zce=s(Ff);$Tt=r(Zce,`Note:
Loading a model from its configuration file does `),hRe=n(Zce,"STRONG",{});var YMa=s(hRe);kTt=r(YMa,"not"),YMa.forEach(t),STt=r(Zce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Gie=n(Zce,"A",{href:!0});var ZMa=s(Gie);RTt=r(ZMa,"from_pretrained()"),ZMa.forEach(t),PTt=r(Zce," to load the model weights."),Zce.forEach(t),BTt=i(Xx),T(sL.$$.fragment,Xx),Xx.forEach(t),ITt=i(rd),st=n(rd,"DIV",{class:!0});var td=s(st);T(gB.$$.fragment,td),NTt=i(td),uRe=n(td,"P",{});var KMa=s(uRe);qTt=r(KMa,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),KMa.forEach(t),DTt=i(td),os=n(td,"P",{});var zx=s(os);jTt=r(zx,"The model class to instantiate is selected based on the "),pRe=n(zx,"CODE",{});var eEa=s(pRe);GTt=r(eEa,"model_type"),eEa.forEach(t),OTt=r(zx,` property of the config object (either
passed as an argument or loaded from `),_Re=n(zx,"CODE",{});var oEa=s(_Re);VTt=r(oEa,"pretrained_model_name_or_path"),oEa.forEach(t),XTt=r(zx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bRe=n(zx,"CODE",{});var rEa=s(bRe);zTt=r(rEa,"pretrained_model_name_or_path"),rEa.forEach(t),QTt=r(zx,":"),zx.forEach(t),WTt=i(td),Se=n(td,"UL",{});var Ge=s(Se);lL=n(Ge,"LI",{});var Rro=s(lL);vRe=n(Rro,"STRONG",{});var tEa=s(vRe);UTt=r(tEa,"bart"),tEa.forEach(t),HTt=r(Rro," \u2014 "),Oie=n(Rro,"A",{href:!0});var aEa=s(Oie);JTt=r(aEa,"FlaxBartForConditionalGeneration"),aEa.forEach(t),YTt=r(Rro," (BART model)"),Rro.forEach(t),ZTt=i(Ge),iL=n(Ge,"LI",{});var Pro=s(iL);FRe=n(Pro,"STRONG",{});var nEa=s(FRe);KTt=r(nEa,"blenderbot"),nEa.forEach(t),eMt=r(Pro," \u2014 "),Vie=n(Pro,"A",{href:!0});var sEa=s(Vie);oMt=r(sEa,"FlaxBlenderbotForConditionalGeneration"),sEa.forEach(t),rMt=r(Pro," (Blenderbot model)"),Pro.forEach(t),tMt=i(Ge),dL=n(Ge,"LI",{});var Bro=s(dL);TRe=n(Bro,"STRONG",{});var lEa=s(TRe);aMt=r(lEa,"blenderbot-small"),lEa.forEach(t),nMt=r(Bro," \u2014 "),Xie=n(Bro,"A",{href:!0});var iEa=s(Xie);sMt=r(iEa,"FlaxBlenderbotSmallForConditionalGeneration"),iEa.forEach(t),lMt=r(Bro," (BlenderbotSmall model)"),Bro.forEach(t),iMt=i(Ge),mL=n(Ge,"LI",{});var Iro=s(mL);MRe=n(Iro,"STRONG",{});var dEa=s(MRe);dMt=r(dEa,"encoder-decoder"),dEa.forEach(t),mMt=r(Iro," \u2014 "),zie=n(Iro,"A",{href:!0});var mEa=s(zie);cMt=r(mEa,"FlaxEncoderDecoderModel"),mEa.forEach(t),fMt=r(Iro," (Encoder decoder model)"),Iro.forEach(t),gMt=i(Ge),cL=n(Ge,"LI",{});var Nro=s(cL);ERe=n(Nro,"STRONG",{});var cEa=s(ERe);hMt=r(cEa,"longt5"),cEa.forEach(t),uMt=r(Nro," \u2014 "),Qie=n(Nro,"A",{href:!0});var fEa=s(Qie);pMt=r(fEa,"FlaxLongT5ForConditionalGeneration"),fEa.forEach(t),_Mt=r(Nro," (LongT5 model)"),Nro.forEach(t),bMt=i(Ge),fL=n(Ge,"LI",{});var qro=s(fL);CRe=n(qro,"STRONG",{});var gEa=s(CRe);vMt=r(gEa,"marian"),gEa.forEach(t),FMt=r(qro," \u2014 "),Wie=n(qro,"A",{href:!0});var hEa=s(Wie);TMt=r(hEa,"FlaxMarianMTModel"),hEa.forEach(t),MMt=r(qro," (Marian model)"),qro.forEach(t),EMt=i(Ge),gL=n(Ge,"LI",{});var Dro=s(gL);wRe=n(Dro,"STRONG",{});var uEa=s(wRe);CMt=r(uEa,"mbart"),uEa.forEach(t),wMt=r(Dro," \u2014 "),Uie=n(Dro,"A",{href:!0});var pEa=s(Uie);AMt=r(pEa,"FlaxMBartForConditionalGeneration"),pEa.forEach(t),LMt=r(Dro," (mBART model)"),Dro.forEach(t),yMt=i(Ge),hL=n(Ge,"LI",{});var jro=s(hL);ARe=n(jro,"STRONG",{});var _Ea=s(ARe);xMt=r(_Ea,"mt5"),_Ea.forEach(t),$Mt=r(jro," \u2014 "),Hie=n(jro,"A",{href:!0});var bEa=s(Hie);kMt=r(bEa,"FlaxMT5ForConditionalGeneration"),bEa.forEach(t),SMt=r(jro," (MT5 model)"),jro.forEach(t),RMt=i(Ge),uL=n(Ge,"LI",{});var Gro=s(uL);LRe=n(Gro,"STRONG",{});var vEa=s(LRe);PMt=r(vEa,"pegasus"),vEa.forEach(t),BMt=r(Gro," \u2014 "),Jie=n(Gro,"A",{href:!0});var FEa=s(Jie);IMt=r(FEa,"FlaxPegasusForConditionalGeneration"),FEa.forEach(t),NMt=r(Gro," (Pegasus model)"),Gro.forEach(t),qMt=i(Ge),pL=n(Ge,"LI",{});var Oro=s(pL);yRe=n(Oro,"STRONG",{});var TEa=s(yRe);DMt=r(TEa,"t5"),TEa.forEach(t),jMt=r(Oro," \u2014 "),Yie=n(Oro,"A",{href:!0});var MEa=s(Yie);GMt=r(MEa,"FlaxT5ForConditionalGeneration"),MEa.forEach(t),OMt=r(Oro," (T5 model)"),Oro.forEach(t),Ge.forEach(t),VMt=i(td),T(_L.$$.fragment,td),td.forEach(t),rd.forEach(t),Sno=i(c),Tf=n(c,"H2",{class:!0});var Klo=s(Tf);bL=n(Klo,"A",{id:!0,class:!0,href:!0});var EEa=s(bL);xRe=n(EEa,"SPAN",{});var CEa=s(xRe);T(hB.$$.fragment,CEa),CEa.forEach(t),EEa.forEach(t),XMt=i(Klo),$Re=n(Klo,"SPAN",{});var wEa=s($Re);zMt=r(wEa,"FlaxAutoModelForSequenceClassification"),wEa.forEach(t),Klo.forEach(t),Rno=i(c),kr=n(c,"DIV",{class:!0});var ad=s(kr);T(uB.$$.fragment,ad),QMt=i(ad),Mf=n(ad,"P",{});var Kce=s(Mf);WMt=r(Kce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Zie=n(Kce,"A",{href:!0});var AEa=s(Zie);UMt=r(AEa,"from_pretrained()"),AEa.forEach(t),HMt=r(Kce," class method or the "),Kie=n(Kce,"A",{href:!0});var LEa=s(Kie);JMt=r(LEa,"from_config()"),LEa.forEach(t),YMt=r(Kce,` class
method.`),Kce.forEach(t),ZMt=i(ad),pB=n(ad,"P",{});var eio=s(pB);KMt=r(eio,"This class cannot be instantiated directly using "),kRe=n(eio,"CODE",{});var yEa=s(kRe);eEt=r(yEa,"__init__()"),yEa.forEach(t),oEt=r(eio," (throws an error)."),eio.forEach(t),rEt=i(ad),ba=n(ad,"DIV",{class:!0});var Qx=s(ba);T(_B.$$.fragment,Qx),tEt=i(Qx),SRe=n(Qx,"P",{});var xEa=s(SRe);aEt=r(xEa,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),xEa.forEach(t),nEt=i(Qx),Ef=n(Qx,"P",{});var efe=s(Ef);sEt=r(efe,`Note:
Loading a model from its configuration file does `),RRe=n(efe,"STRONG",{});var $Ea=s(RRe);lEt=r($Ea,"not"),$Ea.forEach(t),iEt=r(efe,` load the model weights. It only affects the
model\u2019s configuration. Use `),ede=n(efe,"A",{href:!0});var kEa=s(ede);dEt=r(kEa,"from_pretrained()"),kEa.forEach(t),mEt=r(efe," to load the model weights."),efe.forEach(t),cEt=i(Qx),T(vL.$$.fragment,Qx),Qx.forEach(t),fEt=i(ad),lt=n(ad,"DIV",{class:!0});var nd=s(lt);T(bB.$$.fragment,nd),gEt=i(nd),PRe=n(nd,"P",{});var SEa=s(PRe);hEt=r(SEa,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),SEa.forEach(t),uEt=i(nd),rs=n(nd,"P",{});var Wx=s(rs);pEt=r(Wx,"The model class to instantiate is selected based on the "),BRe=n(Wx,"CODE",{});var REa=s(BRe);_Et=r(REa,"model_type"),REa.forEach(t),bEt=r(Wx,` property of the config object (either
passed as an argument or loaded from `),IRe=n(Wx,"CODE",{});var PEa=s(IRe);vEt=r(PEa,"pretrained_model_name_or_path"),PEa.forEach(t),FEt=r(Wx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NRe=n(Wx,"CODE",{});var BEa=s(NRe);TEt=r(BEa,"pretrained_model_name_or_path"),BEa.forEach(t),MEt=r(Wx,":"),Wx.forEach(t),EEt=i(nd),Re=n(nd,"UL",{});var Oe=s(Re);FL=n(Oe,"LI",{});var Vro=s(FL);qRe=n(Vro,"STRONG",{});var IEa=s(qRe);CEt=r(IEa,"albert"),IEa.forEach(t),wEt=r(Vro," \u2014 "),ode=n(Vro,"A",{href:!0});var NEa=s(ode);AEt=r(NEa,"FlaxAlbertForSequenceClassification"),NEa.forEach(t),LEt=r(Vro," (ALBERT model)"),Vro.forEach(t),yEt=i(Oe),TL=n(Oe,"LI",{});var Xro=s(TL);DRe=n(Xro,"STRONG",{});var qEa=s(DRe);xEt=r(qEa,"bart"),qEa.forEach(t),$Et=r(Xro," \u2014 "),rde=n(Xro,"A",{href:!0});var DEa=s(rde);kEt=r(DEa,"FlaxBartForSequenceClassification"),DEa.forEach(t),SEt=r(Xro," (BART model)"),Xro.forEach(t),REt=i(Oe),ML=n(Oe,"LI",{});var zro=s(ML);jRe=n(zro,"STRONG",{});var jEa=s(jRe);PEt=r(jEa,"bert"),jEa.forEach(t),BEt=r(zro," \u2014 "),tde=n(zro,"A",{href:!0});var GEa=s(tde);IEt=r(GEa,"FlaxBertForSequenceClassification"),GEa.forEach(t),NEt=r(zro," (BERT model)"),zro.forEach(t),qEt=i(Oe),EL=n(Oe,"LI",{});var Qro=s(EL);GRe=n(Qro,"STRONG",{});var OEa=s(GRe);DEt=r(OEa,"big_bird"),OEa.forEach(t),jEt=r(Qro," \u2014 "),ade=n(Qro,"A",{href:!0});var VEa=s(ade);GEt=r(VEa,"FlaxBigBirdForSequenceClassification"),VEa.forEach(t),OEt=r(Qro," (BigBird model)"),Qro.forEach(t),VEt=i(Oe),CL=n(Oe,"LI",{});var Wro=s(CL);ORe=n(Wro,"STRONG",{});var XEa=s(ORe);XEt=r(XEa,"distilbert"),XEa.forEach(t),zEt=r(Wro," \u2014 "),nde=n(Wro,"A",{href:!0});var zEa=s(nde);QEt=r(zEa,"FlaxDistilBertForSequenceClassification"),zEa.forEach(t),WEt=r(Wro," (DistilBERT model)"),Wro.forEach(t),UEt=i(Oe),wL=n(Oe,"LI",{});var Uro=s(wL);VRe=n(Uro,"STRONG",{});var QEa=s(VRe);HEt=r(QEa,"electra"),QEa.forEach(t),JEt=r(Uro," \u2014 "),sde=n(Uro,"A",{href:!0});var WEa=s(sde);YEt=r(WEa,"FlaxElectraForSequenceClassification"),WEa.forEach(t),ZEt=r(Uro," (ELECTRA model)"),Uro.forEach(t),KEt=i(Oe),AL=n(Oe,"LI",{});var Hro=s(AL);XRe=n(Hro,"STRONG",{});var UEa=s(XRe);e4t=r(UEa,"mbart"),UEa.forEach(t),o4t=r(Hro," \u2014 "),lde=n(Hro,"A",{href:!0});var HEa=s(lde);r4t=r(HEa,"FlaxMBartForSequenceClassification"),HEa.forEach(t),t4t=r(Hro," (mBART model)"),Hro.forEach(t),a4t=i(Oe),LL=n(Oe,"LI",{});var Jro=s(LL);zRe=n(Jro,"STRONG",{});var JEa=s(zRe);n4t=r(JEa,"roberta"),JEa.forEach(t),s4t=r(Jro," \u2014 "),ide=n(Jro,"A",{href:!0});var YEa=s(ide);l4t=r(YEa,"FlaxRobertaForSequenceClassification"),YEa.forEach(t),i4t=r(Jro," (RoBERTa model)"),Jro.forEach(t),d4t=i(Oe),yL=n(Oe,"LI",{});var Yro=s(yL);QRe=n(Yro,"STRONG",{});var ZEa=s(QRe);m4t=r(ZEa,"roformer"),ZEa.forEach(t),c4t=r(Yro," \u2014 "),dde=n(Yro,"A",{href:!0});var KEa=s(dde);f4t=r(KEa,"FlaxRoFormerForSequenceClassification"),KEa.forEach(t),g4t=r(Yro," (RoFormer model)"),Yro.forEach(t),h4t=i(Oe),xL=n(Oe,"LI",{});var Zro=s(xL);WRe=n(Zro,"STRONG",{});var e4a=s(WRe);u4t=r(e4a,"xlm-roberta"),e4a.forEach(t),p4t=r(Zro," \u2014 "),mde=n(Zro,"A",{href:!0});var o4a=s(mde);_4t=r(o4a,"FlaxXLMRobertaForSequenceClassification"),o4a.forEach(t),b4t=r(Zro," (XLM-RoBERTa model)"),Zro.forEach(t),Oe.forEach(t),v4t=i(nd),T($L.$$.fragment,nd),nd.forEach(t),ad.forEach(t),Pno=i(c),Cf=n(c,"H2",{class:!0});var oio=s(Cf);kL=n(oio,"A",{id:!0,class:!0,href:!0});var r4a=s(kL);URe=n(r4a,"SPAN",{});var t4a=s(URe);T(vB.$$.fragment,t4a),t4a.forEach(t),r4a.forEach(t),F4t=i(oio),HRe=n(oio,"SPAN",{});var a4a=s(HRe);T4t=r(a4a,"FlaxAutoModelForQuestionAnswering"),a4a.forEach(t),oio.forEach(t),Bno=i(c),Sr=n(c,"DIV",{class:!0});var sd=s(Sr);T(FB.$$.fragment,sd),M4t=i(sd),wf=n(sd,"P",{});var ofe=s(wf);E4t=r(ofe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),cde=n(ofe,"A",{href:!0});var n4a=s(cde);C4t=r(n4a,"from_pretrained()"),n4a.forEach(t),w4t=r(ofe," class method or the "),fde=n(ofe,"A",{href:!0});var s4a=s(fde);A4t=r(s4a,"from_config()"),s4a.forEach(t),L4t=r(ofe,` class
method.`),ofe.forEach(t),y4t=i(sd),TB=n(sd,"P",{});var rio=s(TB);x4t=r(rio,"This class cannot be instantiated directly using "),JRe=n(rio,"CODE",{});var l4a=s(JRe);$4t=r(l4a,"__init__()"),l4a.forEach(t),k4t=r(rio," (throws an error)."),rio.forEach(t),S4t=i(sd),va=n(sd,"DIV",{class:!0});var Ux=s(va);T(MB.$$.fragment,Ux),R4t=i(Ux),YRe=n(Ux,"P",{});var i4a=s(YRe);P4t=r(i4a,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),i4a.forEach(t),B4t=i(Ux),Af=n(Ux,"P",{});var rfe=s(Af);I4t=r(rfe,`Note:
Loading a model from its configuration file does `),ZRe=n(rfe,"STRONG",{});var d4a=s(ZRe);N4t=r(d4a,"not"),d4a.forEach(t),q4t=r(rfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),gde=n(rfe,"A",{href:!0});var m4a=s(gde);D4t=r(m4a,"from_pretrained()"),m4a.forEach(t),j4t=r(rfe," to load the model weights."),rfe.forEach(t),G4t=i(Ux),T(SL.$$.fragment,Ux),Ux.forEach(t),O4t=i(sd),it=n(sd,"DIV",{class:!0});var ld=s(it);T(EB.$$.fragment,ld),V4t=i(ld),KRe=n(ld,"P",{});var c4a=s(KRe);X4t=r(c4a,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),c4a.forEach(t),z4t=i(ld),ts=n(ld,"P",{});var Hx=s(ts);Q4t=r(Hx,"The model class to instantiate is selected based on the "),ePe=n(Hx,"CODE",{});var f4a=s(ePe);W4t=r(f4a,"model_type"),f4a.forEach(t),U4t=r(Hx,` property of the config object (either
passed as an argument or loaded from `),oPe=n(Hx,"CODE",{});var g4a=s(oPe);H4t=r(g4a,"pretrained_model_name_or_path"),g4a.forEach(t),J4t=r(Hx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rPe=n(Hx,"CODE",{});var h4a=s(rPe);Y4t=r(h4a,"pretrained_model_name_or_path"),h4a.forEach(t),Z4t=r(Hx,":"),Hx.forEach(t),K4t=i(ld),Pe=n(ld,"UL",{});var Ve=s(Pe);RL=n(Ve,"LI",{});var Kro=s(RL);tPe=n(Kro,"STRONG",{});var u4a=s(tPe);eCt=r(u4a,"albert"),u4a.forEach(t),oCt=r(Kro," \u2014 "),hde=n(Kro,"A",{href:!0});var p4a=s(hde);rCt=r(p4a,"FlaxAlbertForQuestionAnswering"),p4a.forEach(t),tCt=r(Kro," (ALBERT model)"),Kro.forEach(t),aCt=i(Ve),PL=n(Ve,"LI",{});var eto=s(PL);aPe=n(eto,"STRONG",{});var _4a=s(aPe);nCt=r(_4a,"bart"),_4a.forEach(t),sCt=r(eto," \u2014 "),ude=n(eto,"A",{href:!0});var b4a=s(ude);lCt=r(b4a,"FlaxBartForQuestionAnswering"),b4a.forEach(t),iCt=r(eto," (BART model)"),eto.forEach(t),dCt=i(Ve),BL=n(Ve,"LI",{});var oto=s(BL);nPe=n(oto,"STRONG",{});var v4a=s(nPe);mCt=r(v4a,"bert"),v4a.forEach(t),cCt=r(oto," \u2014 "),pde=n(oto,"A",{href:!0});var F4a=s(pde);fCt=r(F4a,"FlaxBertForQuestionAnswering"),F4a.forEach(t),gCt=r(oto," (BERT model)"),oto.forEach(t),hCt=i(Ve),IL=n(Ve,"LI",{});var rto=s(IL);sPe=n(rto,"STRONG",{});var T4a=s(sPe);uCt=r(T4a,"big_bird"),T4a.forEach(t),pCt=r(rto," \u2014 "),_de=n(rto,"A",{href:!0});var M4a=s(_de);_Ct=r(M4a,"FlaxBigBirdForQuestionAnswering"),M4a.forEach(t),bCt=r(rto," (BigBird model)"),rto.forEach(t),vCt=i(Ve),NL=n(Ve,"LI",{});var tto=s(NL);lPe=n(tto,"STRONG",{});var E4a=s(lPe);FCt=r(E4a,"distilbert"),E4a.forEach(t),TCt=r(tto," \u2014 "),bde=n(tto,"A",{href:!0});var C4a=s(bde);MCt=r(C4a,"FlaxDistilBertForQuestionAnswering"),C4a.forEach(t),ECt=r(tto," (DistilBERT model)"),tto.forEach(t),CCt=i(Ve),qL=n(Ve,"LI",{});var ato=s(qL);iPe=n(ato,"STRONG",{});var w4a=s(iPe);wCt=r(w4a,"electra"),w4a.forEach(t),ACt=r(ato," \u2014 "),vde=n(ato,"A",{href:!0});var A4a=s(vde);LCt=r(A4a,"FlaxElectraForQuestionAnswering"),A4a.forEach(t),yCt=r(ato," (ELECTRA model)"),ato.forEach(t),xCt=i(Ve),DL=n(Ve,"LI",{});var nto=s(DL);dPe=n(nto,"STRONG",{});var L4a=s(dPe);$Ct=r(L4a,"mbart"),L4a.forEach(t),kCt=r(nto," \u2014 "),Fde=n(nto,"A",{href:!0});var y4a=s(Fde);SCt=r(y4a,"FlaxMBartForQuestionAnswering"),y4a.forEach(t),RCt=r(nto," (mBART model)"),nto.forEach(t),PCt=i(Ve),jL=n(Ve,"LI",{});var sto=s(jL);mPe=n(sto,"STRONG",{});var x4a=s(mPe);BCt=r(x4a,"roberta"),x4a.forEach(t),ICt=r(sto," \u2014 "),Tde=n(sto,"A",{href:!0});var $4a=s(Tde);NCt=r($4a,"FlaxRobertaForQuestionAnswering"),$4a.forEach(t),qCt=r(sto," (RoBERTa model)"),sto.forEach(t),DCt=i(Ve),GL=n(Ve,"LI",{});var lto=s(GL);cPe=n(lto,"STRONG",{});var k4a=s(cPe);jCt=r(k4a,"roformer"),k4a.forEach(t),GCt=r(lto," \u2014 "),Mde=n(lto,"A",{href:!0});var S4a=s(Mde);OCt=r(S4a,"FlaxRoFormerForQuestionAnswering"),S4a.forEach(t),VCt=r(lto," (RoFormer model)"),lto.forEach(t),XCt=i(Ve),OL=n(Ve,"LI",{});var ito=s(OL);fPe=n(ito,"STRONG",{});var R4a=s(fPe);zCt=r(R4a,"xlm-roberta"),R4a.forEach(t),QCt=r(ito," \u2014 "),Ede=n(ito,"A",{href:!0});var P4a=s(Ede);WCt=r(P4a,"FlaxXLMRobertaForQuestionAnswering"),P4a.forEach(t),UCt=r(ito," (XLM-RoBERTa model)"),ito.forEach(t),Ve.forEach(t),HCt=i(ld),T(VL.$$.fragment,ld),ld.forEach(t),sd.forEach(t),Ino=i(c),Lf=n(c,"H2",{class:!0});var tio=s(Lf);XL=n(tio,"A",{id:!0,class:!0,href:!0});var B4a=s(XL);gPe=n(B4a,"SPAN",{});var I4a=s(gPe);T(CB.$$.fragment,I4a),I4a.forEach(t),B4a.forEach(t),JCt=i(tio),hPe=n(tio,"SPAN",{});var N4a=s(hPe);YCt=r(N4a,"FlaxAutoModelForTokenClassification"),N4a.forEach(t),tio.forEach(t),Nno=i(c),Rr=n(c,"DIV",{class:!0});var id=s(Rr);T(wB.$$.fragment,id),ZCt=i(id),yf=n(id,"P",{});var tfe=s(yf);KCt=r(tfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Cde=n(tfe,"A",{href:!0});var q4a=s(Cde);e3t=r(q4a,"from_pretrained()"),q4a.forEach(t),o3t=r(tfe," class method or the "),wde=n(tfe,"A",{href:!0});var D4a=s(wde);r3t=r(D4a,"from_config()"),D4a.forEach(t),t3t=r(tfe,` class
method.`),tfe.forEach(t),a3t=i(id),AB=n(id,"P",{});var aio=s(AB);n3t=r(aio,"This class cannot be instantiated directly using "),uPe=n(aio,"CODE",{});var j4a=s(uPe);s3t=r(j4a,"__init__()"),j4a.forEach(t),l3t=r(aio," (throws an error)."),aio.forEach(t),i3t=i(id),Fa=n(id,"DIV",{class:!0});var Jx=s(Fa);T(LB.$$.fragment,Jx),d3t=i(Jx),pPe=n(Jx,"P",{});var G4a=s(pPe);m3t=r(G4a,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),G4a.forEach(t),c3t=i(Jx),xf=n(Jx,"P",{});var afe=s(xf);f3t=r(afe,`Note:
Loading a model from its configuration file does `),_Pe=n(afe,"STRONG",{});var O4a=s(_Pe);g3t=r(O4a,"not"),O4a.forEach(t),h3t=r(afe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ade=n(afe,"A",{href:!0});var V4a=s(Ade);u3t=r(V4a,"from_pretrained()"),V4a.forEach(t),p3t=r(afe," to load the model weights."),afe.forEach(t),_3t=i(Jx),T(zL.$$.fragment,Jx),Jx.forEach(t),b3t=i(id),dt=n(id,"DIV",{class:!0});var dd=s(dt);T(yB.$$.fragment,dd),v3t=i(dd),bPe=n(dd,"P",{});var X4a=s(bPe);F3t=r(X4a,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),X4a.forEach(t),T3t=i(dd),as=n(dd,"P",{});var Yx=s(as);M3t=r(Yx,"The model class to instantiate is selected based on the "),vPe=n(Yx,"CODE",{});var z4a=s(vPe);E3t=r(z4a,"model_type"),z4a.forEach(t),C3t=r(Yx,` property of the config object (either
passed as an argument or loaded from `),FPe=n(Yx,"CODE",{});var Q4a=s(FPe);w3t=r(Q4a,"pretrained_model_name_or_path"),Q4a.forEach(t),A3t=r(Yx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TPe=n(Yx,"CODE",{});var W4a=s(TPe);L3t=r(W4a,"pretrained_model_name_or_path"),W4a.forEach(t),y3t=r(Yx,":"),Yx.forEach(t),x3t=i(dd),ze=n(dd,"UL",{});var yo=s(ze);QL=n(yo,"LI",{});var dto=s(QL);MPe=n(dto,"STRONG",{});var U4a=s(MPe);$3t=r(U4a,"albert"),U4a.forEach(t),k3t=r(dto," \u2014 "),Lde=n(dto,"A",{href:!0});var H4a=s(Lde);S3t=r(H4a,"FlaxAlbertForTokenClassification"),H4a.forEach(t),R3t=r(dto," (ALBERT model)"),dto.forEach(t),P3t=i(yo),WL=n(yo,"LI",{});var mto=s(WL);EPe=n(mto,"STRONG",{});var J4a=s(EPe);B3t=r(J4a,"bert"),J4a.forEach(t),I3t=r(mto," \u2014 "),yde=n(mto,"A",{href:!0});var Y4a=s(yde);N3t=r(Y4a,"FlaxBertForTokenClassification"),Y4a.forEach(t),q3t=r(mto," (BERT model)"),mto.forEach(t),D3t=i(yo),UL=n(yo,"LI",{});var cto=s(UL);CPe=n(cto,"STRONG",{});var Z4a=s(CPe);j3t=r(Z4a,"big_bird"),Z4a.forEach(t),G3t=r(cto," \u2014 "),xde=n(cto,"A",{href:!0});var K4a=s(xde);O3t=r(K4a,"FlaxBigBirdForTokenClassification"),K4a.forEach(t),V3t=r(cto," (BigBird model)"),cto.forEach(t),X3t=i(yo),HL=n(yo,"LI",{});var fto=s(HL);wPe=n(fto,"STRONG",{});var eCa=s(wPe);z3t=r(eCa,"distilbert"),eCa.forEach(t),Q3t=r(fto," \u2014 "),$de=n(fto,"A",{href:!0});var oCa=s($de);W3t=r(oCa,"FlaxDistilBertForTokenClassification"),oCa.forEach(t),U3t=r(fto," (DistilBERT model)"),fto.forEach(t),H3t=i(yo),JL=n(yo,"LI",{});var gto=s(JL);APe=n(gto,"STRONG",{});var rCa=s(APe);J3t=r(rCa,"electra"),rCa.forEach(t),Y3t=r(gto," \u2014 "),kde=n(gto,"A",{href:!0});var tCa=s(kde);Z3t=r(tCa,"FlaxElectraForTokenClassification"),tCa.forEach(t),K3t=r(gto," (ELECTRA model)"),gto.forEach(t),e5t=i(yo),YL=n(yo,"LI",{});var hto=s(YL);LPe=n(hto,"STRONG",{});var aCa=s(LPe);o5t=r(aCa,"roberta"),aCa.forEach(t),r5t=r(hto," \u2014 "),Sde=n(hto,"A",{href:!0});var nCa=s(Sde);t5t=r(nCa,"FlaxRobertaForTokenClassification"),nCa.forEach(t),a5t=r(hto," (RoBERTa model)"),hto.forEach(t),n5t=i(yo),ZL=n(yo,"LI",{});var uto=s(ZL);yPe=n(uto,"STRONG",{});var sCa=s(yPe);s5t=r(sCa,"roformer"),sCa.forEach(t),l5t=r(uto," \u2014 "),Rde=n(uto,"A",{href:!0});var lCa=s(Rde);i5t=r(lCa,"FlaxRoFormerForTokenClassification"),lCa.forEach(t),d5t=r(uto," (RoFormer model)"),uto.forEach(t),m5t=i(yo),KL=n(yo,"LI",{});var pto=s(KL);xPe=n(pto,"STRONG",{});var iCa=s(xPe);c5t=r(iCa,"xlm-roberta"),iCa.forEach(t),f5t=r(pto," \u2014 "),Pde=n(pto,"A",{href:!0});var dCa=s(Pde);g5t=r(dCa,"FlaxXLMRobertaForTokenClassification"),dCa.forEach(t),h5t=r(pto," (XLM-RoBERTa model)"),pto.forEach(t),yo.forEach(t),u5t=i(dd),T(ey.$$.fragment,dd),dd.forEach(t),id.forEach(t),qno=i(c),$f=n(c,"H2",{class:!0});var nio=s($f);oy=n(nio,"A",{id:!0,class:!0,href:!0});var mCa=s(oy);$Pe=n(mCa,"SPAN",{});var cCa=s($Pe);T(xB.$$.fragment,cCa),cCa.forEach(t),mCa.forEach(t),p5t=i(nio),kPe=n(nio,"SPAN",{});var fCa=s(kPe);_5t=r(fCa,"FlaxAutoModelForMultipleChoice"),fCa.forEach(t),nio.forEach(t),Dno=i(c),Pr=n(c,"DIV",{class:!0});var md=s(Pr);T($B.$$.fragment,md),b5t=i(md),kf=n(md,"P",{});var nfe=s(kf);v5t=r(nfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Bde=n(nfe,"A",{href:!0});var gCa=s(Bde);F5t=r(gCa,"from_pretrained()"),gCa.forEach(t),T5t=r(nfe," class method or the "),Ide=n(nfe,"A",{href:!0});var hCa=s(Ide);M5t=r(hCa,"from_config()"),hCa.forEach(t),E5t=r(nfe,` class
method.`),nfe.forEach(t),C5t=i(md),kB=n(md,"P",{});var sio=s(kB);w5t=r(sio,"This class cannot be instantiated directly using "),SPe=n(sio,"CODE",{});var uCa=s(SPe);A5t=r(uCa,"__init__()"),uCa.forEach(t),L5t=r(sio," (throws an error)."),sio.forEach(t),y5t=i(md),Ta=n(md,"DIV",{class:!0});var Zx=s(Ta);T(SB.$$.fragment,Zx),x5t=i(Zx),RPe=n(Zx,"P",{});var pCa=s(RPe);$5t=r(pCa,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),pCa.forEach(t),k5t=i(Zx),Sf=n(Zx,"P",{});var sfe=s(Sf);S5t=r(sfe,`Note:
Loading a model from its configuration file does `),PPe=n(sfe,"STRONG",{});var _Ca=s(PPe);R5t=r(_Ca,"not"),_Ca.forEach(t),P5t=r(sfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Nde=n(sfe,"A",{href:!0});var bCa=s(Nde);B5t=r(bCa,"from_pretrained()"),bCa.forEach(t),I5t=r(sfe," to load the model weights."),sfe.forEach(t),N5t=i(Zx),T(ry.$$.fragment,Zx),Zx.forEach(t),q5t=i(md),mt=n(md,"DIV",{class:!0});var cd=s(mt);T(RB.$$.fragment,cd),D5t=i(cd),BPe=n(cd,"P",{});var vCa=s(BPe);j5t=r(vCa,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),vCa.forEach(t),G5t=i(cd),ns=n(cd,"P",{});var Kx=s(ns);O5t=r(Kx,"The model class to instantiate is selected based on the "),IPe=n(Kx,"CODE",{});var FCa=s(IPe);V5t=r(FCa,"model_type"),FCa.forEach(t),X5t=r(Kx,` property of the config object (either
passed as an argument or loaded from `),NPe=n(Kx,"CODE",{});var TCa=s(NPe);z5t=r(TCa,"pretrained_model_name_or_path"),TCa.forEach(t),Q5t=r(Kx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qPe=n(Kx,"CODE",{});var MCa=s(qPe);W5t=r(MCa,"pretrained_model_name_or_path"),MCa.forEach(t),U5t=r(Kx,":"),Kx.forEach(t),H5t=i(cd),Qe=n(cd,"UL",{});var xo=s(Qe);ty=n(xo,"LI",{});var _to=s(ty);DPe=n(_to,"STRONG",{});var ECa=s(DPe);J5t=r(ECa,"albert"),ECa.forEach(t),Y5t=r(_to," \u2014 "),qde=n(_to,"A",{href:!0});var CCa=s(qde);Z5t=r(CCa,"FlaxAlbertForMultipleChoice"),CCa.forEach(t),K5t=r(_to," (ALBERT model)"),_to.forEach(t),e0t=i(xo),ay=n(xo,"LI",{});var bto=s(ay);jPe=n(bto,"STRONG",{});var wCa=s(jPe);o0t=r(wCa,"bert"),wCa.forEach(t),r0t=r(bto," \u2014 "),Dde=n(bto,"A",{href:!0});var ACa=s(Dde);t0t=r(ACa,"FlaxBertForMultipleChoice"),ACa.forEach(t),a0t=r(bto," (BERT model)"),bto.forEach(t),n0t=i(xo),ny=n(xo,"LI",{});var vto=s(ny);GPe=n(vto,"STRONG",{});var LCa=s(GPe);s0t=r(LCa,"big_bird"),LCa.forEach(t),l0t=r(vto," \u2014 "),jde=n(vto,"A",{href:!0});var yCa=s(jde);i0t=r(yCa,"FlaxBigBirdForMultipleChoice"),yCa.forEach(t),d0t=r(vto," (BigBird model)"),vto.forEach(t),m0t=i(xo),sy=n(xo,"LI",{});var Fto=s(sy);OPe=n(Fto,"STRONG",{});var xCa=s(OPe);c0t=r(xCa,"distilbert"),xCa.forEach(t),f0t=r(Fto," \u2014 "),Gde=n(Fto,"A",{href:!0});var $Ca=s(Gde);g0t=r($Ca,"FlaxDistilBertForMultipleChoice"),$Ca.forEach(t),h0t=r(Fto," (DistilBERT model)"),Fto.forEach(t),u0t=i(xo),ly=n(xo,"LI",{});var Tto=s(ly);VPe=n(Tto,"STRONG",{});var kCa=s(VPe);p0t=r(kCa,"electra"),kCa.forEach(t),_0t=r(Tto," \u2014 "),Ode=n(Tto,"A",{href:!0});var SCa=s(Ode);b0t=r(SCa,"FlaxElectraForMultipleChoice"),SCa.forEach(t),v0t=r(Tto," (ELECTRA model)"),Tto.forEach(t),F0t=i(xo),iy=n(xo,"LI",{});var Mto=s(iy);XPe=n(Mto,"STRONG",{});var RCa=s(XPe);T0t=r(RCa,"roberta"),RCa.forEach(t),M0t=r(Mto," \u2014 "),Vde=n(Mto,"A",{href:!0});var PCa=s(Vde);E0t=r(PCa,"FlaxRobertaForMultipleChoice"),PCa.forEach(t),C0t=r(Mto," (RoBERTa model)"),Mto.forEach(t),w0t=i(xo),dy=n(xo,"LI",{});var Eto=s(dy);zPe=n(Eto,"STRONG",{});var BCa=s(zPe);A0t=r(BCa,"roformer"),BCa.forEach(t),L0t=r(Eto," \u2014 "),Xde=n(Eto,"A",{href:!0});var ICa=s(Xde);y0t=r(ICa,"FlaxRoFormerForMultipleChoice"),ICa.forEach(t),x0t=r(Eto," (RoFormer model)"),Eto.forEach(t),$0t=i(xo),my=n(xo,"LI",{});var Cto=s(my);QPe=n(Cto,"STRONG",{});var NCa=s(QPe);k0t=r(NCa,"xlm-roberta"),NCa.forEach(t),S0t=r(Cto," \u2014 "),zde=n(Cto,"A",{href:!0});var qCa=s(zde);R0t=r(qCa,"FlaxXLMRobertaForMultipleChoice"),qCa.forEach(t),P0t=r(Cto," (XLM-RoBERTa model)"),Cto.forEach(t),xo.forEach(t),B0t=i(cd),T(cy.$$.fragment,cd),cd.forEach(t),md.forEach(t),jno=i(c),Rf=n(c,"H2",{class:!0});var lio=s(Rf);fy=n(lio,"A",{id:!0,class:!0,href:!0});var DCa=s(fy);WPe=n(DCa,"SPAN",{});var jCa=s(WPe);T(PB.$$.fragment,jCa),jCa.forEach(t),DCa.forEach(t),I0t=i(lio),UPe=n(lio,"SPAN",{});var GCa=s(UPe);N0t=r(GCa,"FlaxAutoModelForNextSentencePrediction"),GCa.forEach(t),lio.forEach(t),Gno=i(c),Br=n(c,"DIV",{class:!0});var fd=s(Br);T(BB.$$.fragment,fd),q0t=i(fd),Pf=n(fd,"P",{});var lfe=s(Pf);D0t=r(lfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Qde=n(lfe,"A",{href:!0});var OCa=s(Qde);j0t=r(OCa,"from_pretrained()"),OCa.forEach(t),G0t=r(lfe," class method or the "),Wde=n(lfe,"A",{href:!0});var VCa=s(Wde);O0t=r(VCa,"from_config()"),VCa.forEach(t),V0t=r(lfe,` class
method.`),lfe.forEach(t),X0t=i(fd),IB=n(fd,"P",{});var iio=s(IB);z0t=r(iio,"This class cannot be instantiated directly using "),HPe=n(iio,"CODE",{});var XCa=s(HPe);Q0t=r(XCa,"__init__()"),XCa.forEach(t),W0t=r(iio," (throws an error)."),iio.forEach(t),U0t=i(fd),Ma=n(fd,"DIV",{class:!0});var e$=s(Ma);T(NB.$$.fragment,e$),H0t=i(e$),JPe=n(e$,"P",{});var zCa=s(JPe);J0t=r(zCa,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),zCa.forEach(t),Y0t=i(e$),Bf=n(e$,"P",{});var ife=s(Bf);Z0t=r(ife,`Note:
Loading a model from its configuration file does `),YPe=n(ife,"STRONG",{});var QCa=s(YPe);K0t=r(QCa,"not"),QCa.forEach(t),ewt=r(ife,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ude=n(ife,"A",{href:!0});var WCa=s(Ude);owt=r(WCa,"from_pretrained()"),WCa.forEach(t),rwt=r(ife," to load the model weights."),ife.forEach(t),twt=i(e$),T(gy.$$.fragment,e$),e$.forEach(t),awt=i(fd),ct=n(fd,"DIV",{class:!0});var gd=s(ct);T(qB.$$.fragment,gd),nwt=i(gd),ZPe=n(gd,"P",{});var UCa=s(ZPe);swt=r(UCa,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),UCa.forEach(t),lwt=i(gd),ss=n(gd,"P",{});var o$=s(ss);iwt=r(o$,"The model class to instantiate is selected based on the "),KPe=n(o$,"CODE",{});var HCa=s(KPe);dwt=r(HCa,"model_type"),HCa.forEach(t),mwt=r(o$,` property of the config object (either
passed as an argument or loaded from `),eBe=n(o$,"CODE",{});var JCa=s(eBe);cwt=r(JCa,"pretrained_model_name_or_path"),JCa.forEach(t),fwt=r(o$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oBe=n(o$,"CODE",{});var YCa=s(oBe);gwt=r(YCa,"pretrained_model_name_or_path"),YCa.forEach(t),hwt=r(o$,":"),o$.forEach(t),uwt=i(gd),rBe=n(gd,"UL",{});var ZCa=s(rBe);hy=n(ZCa,"LI",{});var wto=s(hy);tBe=n(wto,"STRONG",{});var KCa=s(tBe);pwt=r(KCa,"bert"),KCa.forEach(t),_wt=r(wto," \u2014 "),Hde=n(wto,"A",{href:!0});var e3a=s(Hde);bwt=r(e3a,"FlaxBertForNextSentencePrediction"),e3a.forEach(t),vwt=r(wto," (BERT model)"),wto.forEach(t),ZCa.forEach(t),Fwt=i(gd),T(uy.$$.fragment,gd),gd.forEach(t),fd.forEach(t),Ono=i(c),If=n(c,"H2",{class:!0});var dio=s(If);py=n(dio,"A",{id:!0,class:!0,href:!0});var o3a=s(py);aBe=n(o3a,"SPAN",{});var r3a=s(aBe);T(DB.$$.fragment,r3a),r3a.forEach(t),o3a.forEach(t),Twt=i(dio),nBe=n(dio,"SPAN",{});var t3a=s(nBe);Mwt=r(t3a,"FlaxAutoModelForImageClassification"),t3a.forEach(t),dio.forEach(t),Vno=i(c),Ir=n(c,"DIV",{class:!0});var hd=s(Ir);T(jB.$$.fragment,hd),Ewt=i(hd),Nf=n(hd,"P",{});var dfe=s(Nf);Cwt=r(dfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Jde=n(dfe,"A",{href:!0});var a3a=s(Jde);wwt=r(a3a,"from_pretrained()"),a3a.forEach(t),Awt=r(dfe," class method or the "),Yde=n(dfe,"A",{href:!0});var n3a=s(Yde);Lwt=r(n3a,"from_config()"),n3a.forEach(t),ywt=r(dfe,` class
method.`),dfe.forEach(t),xwt=i(hd),GB=n(hd,"P",{});var mio=s(GB);$wt=r(mio,"This class cannot be instantiated directly using "),sBe=n(mio,"CODE",{});var s3a=s(sBe);kwt=r(s3a,"__init__()"),s3a.forEach(t),Swt=r(mio," (throws an error)."),mio.forEach(t),Rwt=i(hd),Ea=n(hd,"DIV",{class:!0});var r$=s(Ea);T(OB.$$.fragment,r$),Pwt=i(r$),lBe=n(r$,"P",{});var l3a=s(lBe);Bwt=r(l3a,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),l3a.forEach(t),Iwt=i(r$),qf=n(r$,"P",{});var mfe=s(qf);Nwt=r(mfe,`Note:
Loading a model from its configuration file does `),iBe=n(mfe,"STRONG",{});var i3a=s(iBe);qwt=r(i3a,"not"),i3a.forEach(t),Dwt=r(mfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zde=n(mfe,"A",{href:!0});var d3a=s(Zde);jwt=r(d3a,"from_pretrained()"),d3a.forEach(t),Gwt=r(mfe," to load the model weights."),mfe.forEach(t),Owt=i(r$),T(_y.$$.fragment,r$),r$.forEach(t),Vwt=i(hd),ft=n(hd,"DIV",{class:!0});var ud=s(ft);T(VB.$$.fragment,ud),Xwt=i(ud),dBe=n(ud,"P",{});var m3a=s(dBe);zwt=r(m3a,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),m3a.forEach(t),Qwt=i(ud),ls=n(ud,"P",{});var t$=s(ls);Wwt=r(t$,"The model class to instantiate is selected based on the "),mBe=n(t$,"CODE",{});var c3a=s(mBe);Uwt=r(c3a,"model_type"),c3a.forEach(t),Hwt=r(t$,` property of the config object (either
passed as an argument or loaded from `),cBe=n(t$,"CODE",{});var f3a=s(cBe);Jwt=r(f3a,"pretrained_model_name_or_path"),f3a.forEach(t),Ywt=r(t$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fBe=n(t$,"CODE",{});var g3a=s(fBe);Zwt=r(g3a,"pretrained_model_name_or_path"),g3a.forEach(t),Kwt=r(t$,":"),t$.forEach(t),eAt=i(ud),XB=n(ud,"UL",{});var cio=s(XB);by=n(cio,"LI",{});var Ato=s(by);gBe=n(Ato,"STRONG",{});var h3a=s(gBe);oAt=r(h3a,"beit"),h3a.forEach(t),rAt=r(Ato," \u2014 "),Kde=n(Ato,"A",{href:!0});var u3a=s(Kde);tAt=r(u3a,"FlaxBeitForImageClassification"),u3a.forEach(t),aAt=r(Ato," (BEiT model)"),Ato.forEach(t),nAt=i(cio),vy=n(cio,"LI",{});var Lto=s(vy);hBe=n(Lto,"STRONG",{});var p3a=s(hBe);sAt=r(p3a,"vit"),p3a.forEach(t),lAt=r(Lto," \u2014 "),eme=n(Lto,"A",{href:!0});var _3a=s(eme);iAt=r(_3a,"FlaxViTForImageClassification"),_3a.forEach(t),dAt=r(Lto," (ViT model)"),Lto.forEach(t),cio.forEach(t),mAt=i(ud),T(Fy.$$.fragment,ud),ud.forEach(t),hd.forEach(t),Xno=i(c),Df=n(c,"H2",{class:!0});var fio=s(Df);Ty=n(fio,"A",{id:!0,class:!0,href:!0});var b3a=s(Ty);uBe=n(b3a,"SPAN",{});var v3a=s(uBe);T(zB.$$.fragment,v3a),v3a.forEach(t),b3a.forEach(t),cAt=i(fio),pBe=n(fio,"SPAN",{});var F3a=s(pBe);fAt=r(F3a,"FlaxAutoModelForVision2Seq"),F3a.forEach(t),fio.forEach(t),zno=i(c),Nr=n(c,"DIV",{class:!0});var pd=s(Nr);T(QB.$$.fragment,pd),gAt=i(pd),jf=n(pd,"P",{});var cfe=s(jf);hAt=r(cfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),ome=n(cfe,"A",{href:!0});var T3a=s(ome);uAt=r(T3a,"from_pretrained()"),T3a.forEach(t),pAt=r(cfe," class method or the "),rme=n(cfe,"A",{href:!0});var M3a=s(rme);_At=r(M3a,"from_config()"),M3a.forEach(t),bAt=r(cfe,` class
method.`),cfe.forEach(t),vAt=i(pd),WB=n(pd,"P",{});var gio=s(WB);FAt=r(gio,"This class cannot be instantiated directly using "),_Be=n(gio,"CODE",{});var E3a=s(_Be);TAt=r(E3a,"__init__()"),E3a.forEach(t),MAt=r(gio," (throws an error)."),gio.forEach(t),EAt=i(pd),Ca=n(pd,"DIV",{class:!0});var a$=s(Ca);T(UB.$$.fragment,a$),CAt=i(a$),bBe=n(a$,"P",{});var C3a=s(bBe);wAt=r(C3a,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),C3a.forEach(t),AAt=i(a$),Gf=n(a$,"P",{});var ffe=s(Gf);LAt=r(ffe,`Note:
Loading a model from its configuration file does `),vBe=n(ffe,"STRONG",{});var w3a=s(vBe);yAt=r(w3a,"not"),w3a.forEach(t),xAt=r(ffe,` load the model weights. It only affects the
model\u2019s configuration. Use `),tme=n(ffe,"A",{href:!0});var A3a=s(tme);$At=r(A3a,"from_pretrained()"),A3a.forEach(t),kAt=r(ffe," to load the model weights."),ffe.forEach(t),SAt=i(a$),T(My.$$.fragment,a$),a$.forEach(t),RAt=i(pd),gt=n(pd,"DIV",{class:!0});var _d=s(gt);T(HB.$$.fragment,_d),PAt=i(_d),FBe=n(_d,"P",{});var L3a=s(FBe);BAt=r(L3a,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),L3a.forEach(t),IAt=i(_d),is=n(_d,"P",{});var n$=s(is);NAt=r(n$,"The model class to instantiate is selected based on the "),TBe=n(n$,"CODE",{});var y3a=s(TBe);qAt=r(y3a,"model_type"),y3a.forEach(t),DAt=r(n$,` property of the config object (either
passed as an argument or loaded from `),MBe=n(n$,"CODE",{});var x3a=s(MBe);jAt=r(x3a,"pretrained_model_name_or_path"),x3a.forEach(t),GAt=r(n$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),EBe=n(n$,"CODE",{});var $3a=s(EBe);OAt=r($3a,"pretrained_model_name_or_path"),$3a.forEach(t),VAt=r(n$,":"),n$.forEach(t),XAt=i(_d),CBe=n(_d,"UL",{});var k3a=s(CBe);Ey=n(k3a,"LI",{});var yto=s(Ey);wBe=n(yto,"STRONG",{});var S3a=s(wBe);zAt=r(S3a,"vision-encoder-decoder"),S3a.forEach(t),QAt=r(yto," \u2014 "),ame=n(yto,"A",{href:!0});var R3a=s(ame);WAt=r(R3a,"FlaxVisionEncoderDecoderModel"),R3a.forEach(t),UAt=r(yto," (Vision Encoder decoder model)"),yto.forEach(t),k3a.forEach(t),HAt=i(_d),T(Cy.$$.fragment,_d),_d.forEach(t),pd.forEach(t),this.h()},h(){m(g,"name","hf:doc:metadata"),m(g,"content",JSON.stringify(Y0a)),m(f,"id","auto-classes"),m(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(f,"href","#auto-classes"),m(u,"class","relative group"),m(ms,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig"),m(fs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel"),m(gs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),m(Cd,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),m(Hf,"id","extending-the-auto-classes"),m(Hf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Hf,"href","#extending-the-auto-classes"),m(wd,"class","relative group"),m(Yf,"id","transformers.AutoConfig"),m(Yf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Yf,"href","#transformers.AutoConfig"),m(Ad,"class","relative group"),m(xN,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),m($N,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig"),m(kN,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartConfig"),m(SN,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig"),m(RN,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertConfig"),m(PN,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig"),m(BN,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig"),m(IN,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),m(NN,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig"),m(qN,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),m(DN,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig"),m(jN,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig"),m(GN,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig"),m(ON,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig"),m(VN,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig"),m(XN,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig"),m(zN,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig"),m(QN,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig"),m(WN,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig"),m(UN,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig"),m(HN,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),m(JN,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig"),m(YN,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),m(ZN,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig"),m(KN,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config"),m(eq,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),m(oq,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig"),m(rq,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig"),m(tq,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig"),m(aq,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig"),m(nq,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig"),m(sq,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig"),m(lq,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig"),m(iq,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig"),m(dq,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),m(mq,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig"),m(cq,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig"),m(fq,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig"),m(gq,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig"),m(hq,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig"),m(uq,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig"),m(pq,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig"),m(_q,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig"),m(bq,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config"),m(vq,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),m(Fq,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),m(Tq,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig"),m(Mq,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig"),m(Eq,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig"),m(Cq,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig"),m(wq,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig"),m(Aq,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig"),m(Lq,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig"),m(yq,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),m(xq,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),m($q,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDConfig"),m(kq,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig"),m(Sq,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig"),m(Rq,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig"),m(Pq,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config"),m(Bq,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig"),m(Iq,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig"),m(Nq,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config"),m(qq,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig"),m(Dq,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig"),m(jq,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig"),m(Gq,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig"),m(Oq,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig"),m(Vq,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),m(Xq,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig"),m(zq,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig"),m(Qq,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig"),m(Wq,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config"),m(Uq,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig"),m(Hq,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig"),m(Jq,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig"),m(Yq,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),m(Zq,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig"),m(Kq,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig"),m(eD,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig"),m(oD,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig"),m(rD,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig"),m(tD,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig"),m(aD,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig"),m(nD,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig"),m(sD,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig"),m(lD,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagConfig"),m(iD,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmConfig"),m(dD,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig"),m(mD,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig"),m(cD,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig"),m(fD,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig"),m(gD,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig"),m(hD,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig"),m(uD,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig"),m(pD,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig"),m(_D,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig"),m(bD,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig"),m(vD,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),m(FD,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),m(TD,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),m(MD,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig"),m(ED,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),m(CD,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig"),m(wD,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config"),m(AD,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Config"),m(LD,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig"),m(yD,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig"),m(xD,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig"),m($D,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),m(kD,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),m(SD,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig"),m(RD,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig"),m(PD,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),m(BD,"href","/docs/transformers/main/en/model_doc/van#transformers.VanConfig"),m(ID,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig"),m(ND,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig"),m(qD,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),m(DD,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),m(jD,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig"),m(GD,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig"),m(OD,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig"),m(VD,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig"),m(XD,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),m(zD,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),m(QD,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig"),m(WD,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig"),m(UD,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig"),m(HD,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig"),m(JD,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig"),m(YD,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),m(ZD,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),m(KD,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),m(ej,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig"),m(oj,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig"),m(rj,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig"),m(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Au,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Lu,"id","transformers.AutoTokenizer"),m(Lu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Lu,"href","#transformers.AutoTokenizer"),m(yd,"class","relative group"),m(tj,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),m(aj,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),m(nj,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),m(sj,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizer"),m(lj,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizerFast"),m(ij,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizer"),m(dj,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizerFast"),m(mj,"href","/docs/transformers/main/en/model_doc/bartpho#transformers.BartphoTokenizer"),m(cj,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(fj,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(gj,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),m(hj,"href","/docs/transformers/main/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),m(uj,"href","/docs/transformers/main/en/model_doc/bertweet#transformers.BertweetTokenizer"),m(pj,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizer"),m(_j,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),m(bj,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),m(vj,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),m(Fj,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),m(Tj,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),m(Mj,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),m(Ej,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomTokenizerFast"),m(Cj,"href","/docs/transformers/main/en/model_doc/byt5#transformers.ByT5Tokenizer"),m(wj,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizer"),m(Aj,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizerFast"),m(Lj,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineTokenizer"),m(yj,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),m(xj,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),m($j,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizer"),m(kj,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),m(Sj,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizer"),m(Rj,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),m(Pj,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizer"),m(Bj,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizerFast"),m(Ij,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLTokenizer"),m(Nj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),m(qj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),m(Dj,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizer"),m(jj,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizerFast"),m(Gj,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),m(Oj,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),m(Vj,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizer"),m(Xj,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),m(zj,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),m(Qj,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),m(Wj,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizer"),m(Uj,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizerFast"),m(Hj,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(Jj,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(Yj,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmTokenizer"),m(Zj,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertTokenizer"),m(Kj,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizer"),m(eG,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizerFast"),m(oG,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTTokenizer"),m(rG,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizer"),m(tG,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizerFast"),m(aG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),m(nG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),m(sG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),m(lG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),m(iG,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),m(dG,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseTokenizer"),m(mG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),m(cG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),m(fG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),m(gG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),m(hG,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizer"),m(uG,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizerFast"),m(pG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),m(_G,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),m(bG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),m(vG,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),m(FG,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),m(TG,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),m(MG,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),m(EG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),m(CG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),m(wG,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),m(AG,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),m(LG,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizer"),m(yG,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizerFast"),m(xG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),m($G,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),m(kG,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizer"),m(SG,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizerFast"),m(RG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),m(PG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),m(BG,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeTokenizer"),m(IG,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizer"),m(NG,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),m(qG,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),m(DG,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianTokenizer"),m(jG,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizer"),m(GG,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizerFast"),m(OG,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50Tokenizer"),m(VG,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50TokenizerFast"),m(XG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(zG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(QG,"href","/docs/transformers/main/en/model_doc/mluke#transformers.MLukeTokenizer"),m(WG,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),m(UG,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),m(HG,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizer"),m(JG,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),m(YG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),m(ZG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),m(KG,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizer"),m(eO,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizerFast"),m(oO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(rO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(tO,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizer"),m(aO,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizerFast"),m(nO,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),m(sO,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),m(lO,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),m(iO,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),m(dO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),m(mO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),m(cO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),m(fO,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),m(gO,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),m(hO,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),m(uO,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),m(pO,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverTokenizer"),m(_O,"href","/docs/transformers/main/en/model_doc/phobert#transformers.PhobertTokenizer"),m(bO,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartTokenizer"),m(vO,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),m(FO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(TO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(MO,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagTokenizer"),m(EO,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizer"),m(CO,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizerFast"),m(wO,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizer"),m(AO,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizerFast"),m(LO,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizer"),m(yO,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizerFast"),m(xO,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizer"),m($O,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),m(kO,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),m(SO,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),m(RO,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizer"),m(PO,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),m(BO,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),m(IO,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),m(NO,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizer"),m(qO,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizerFast"),m(DO,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),m(jO,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),m(GO,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),m(OO,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),m(VO,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasTokenizer"),m(XO,"href","/docs/transformers/main/en/model_doc/tapex#transformers.TapexTokenizer"),m(zO,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),m(QO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(WO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(UO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(HO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(JO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),m(YO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),m(ZO,"href","/docs/transformers/main/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),m(KO,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperTokenizer"),m(eV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),m(oV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),m(rV,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizer"),m(tV,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizerFast"),m(aV,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMTokenizer"),m(nV,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),m(sV,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),m(lV,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),m(iV,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),m(dV,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),m(mV,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizer"),m(cV,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),m(fV,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),m(gV,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),m(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(cp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(fp,"id","transformers.AutoFeatureExtractor"),m(fp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(fp,"href","#transformers.AutoFeatureExtractor"),m(xd,"class","relative group"),m(hV,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),m(uV,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitFeatureExtractor"),m(pV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),m(_V,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrFeatureExtractor"),m(bV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),m(vV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),m(FV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),m(TV,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitFeatureExtractor"),m(MV,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrFeatureExtractor"),m(EV,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTFeatureExtractor"),m(CV,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),m(wV,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutFeatureExtractor"),m(AV,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTFeatureExtractor"),m(LV,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaFeatureExtractor"),m(yV,"href","/docs/transformers/main/en/model_doc/glpn#transformers.models.glpn.image_processing_glpn.GLPNImageProcessor"),m(xV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),m($V,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),m(kV,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),m(SV,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),m(RV,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),m(PV,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitFeatureExtractor"),m(BV,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),m(IV,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),m(NV,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTFeatureExtractor"),m(qV,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor"),m(DV,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),m(jV,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),m(GV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),m(OV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),m(VV,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),m(XV,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),m(zV,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),m(QV,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),m(WV,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),m(UV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),m(HV,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEFeatureExtractor"),m(JV,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltFeatureExtractor"),m(YV,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),m(ZV,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),m(KV,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),m(eX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),m(oX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),m(rX,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperFeatureExtractor"),m(tX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),m(aX,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosFeatureExtractor"),m(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(n_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(s_,"id","transformers.AutoProcessor"),m(s_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(s_,"href","#transformers.AutoProcessor"),m($d,"class","relative group"),m(nX,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),m(sX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),m(lX,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutProcessor"),m(iX,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaProcessor"),m(dX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),m(mX,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),m(cX,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),m(fX,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),m(gX,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMProcessor"),m(hX,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTProcessor"),m(uX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(pX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(_X,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),m(bX,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),m(vX,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRProcessor"),m(FX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(TX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(MX,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltProcessor"),m(EX,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),m(CX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(wX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(AX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(LX,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperProcessor"),m(yX,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPProcessor"),m(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(S_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(R_,"id","transformers.AutoModel"),m(R_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(R_,"href","#transformers.AutoModel"),m(Sd,"class","relative group"),m(xX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m($X,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(kX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(SX,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel"),m(RX,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartModel"),m(PX,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitModel"),m(BX,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),m(IX,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),m(NX,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel"),m(qX,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),m(DX,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel"),m(jX,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),m(GX,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel"),m(OX,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel"),m(VX,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineModel"),m(XX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel"),m(zX,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel"),m(QX,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel"),m(WX,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel"),m(UX,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel"),m(HX,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel"),m(JX,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel"),m(YX,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel"),m(ZX,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel"),m(KX,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel"),m(ez,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel"),m(oz,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model"),m(rz,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),m(tz,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel"),m(az,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel"),m(nz,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrModel"),m(sz,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel"),m(lz,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel"),m(iz,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder"),m(dz,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel"),m(mz,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel"),m(cz,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel"),m(fz,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmModel"),m(gz,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel"),m(hz,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel"),m(uz,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel"),m(pz,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel"),m(_z,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel"),m(bz,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel"),m(vz,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel"),m(Fz,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model"),m(Tz,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel"),m(Mz,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),m(Ez,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel"),m(Cz,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel"),m(wz,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel"),m(Az,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel"),m(Lz,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel"),m(yz,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel"),m(xz,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel"),m($z,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),m(kz,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),m(Sz,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDModel"),m(Rz,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitModel"),m(Pz,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltModel"),m(Bz,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel"),m(Iz,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model"),m(Nz,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeModel"),m(qz,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel"),m(Dz,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),m(jz,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianModel"),m(Gz,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel"),m(Oz,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel"),m(Vz,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel"),m(Xz,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel"),m(zz,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel"),m(Qz,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel"),m(Wz,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel"),m(Uz,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel"),m(Hz,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model"),m(Jz,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel"),m(Yz,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel"),m(Zz,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),m(Kz,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel"),m(eQ,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),m(oQ,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTModel"),m(rQ,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel"),m(tQ,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel"),m(aQ,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel"),m(nQ,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel"),m(sQ,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel"),m(lQ,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel"),m(iQ,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel"),m(dQ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel"),m(mQ,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel"),m(cQ,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel"),m(fQ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel"),m(gQ,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel"),m(hQ,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),m(uQ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel"),m(pQ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel"),m(_Q,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel"),m(bQ,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWModel"),m(vQ,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel"),m(FQ,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel"),m(TQ,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel"),m(MQ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel"),m(EQ,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinModel"),m(CQ,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model"),m(wQ,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Model"),m(AQ,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerModel"),m(LQ,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel"),m(yQ,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel"),m(xQ,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),m($Q,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel"),m(kQ,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel"),m(SQ,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),m(RQ,"href","/docs/transformers/main/en/model_doc/van#transformers.VanModel"),m(PQ,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel"),m(BQ,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel"),m(IQ,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),m(NQ,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel"),m(qQ,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTModel"),m(DQ,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel"),m(jQ,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel"),m(GQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),m(OQ,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),m(VQ,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel"),m(XQ,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel"),m(zQ,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel"),m(QQ,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel"),m(WQ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel"),m(UQ,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),m(HQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),m(JQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),m(YQ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel"),m(ZQ,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel"),m(KQ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel"),m(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(tb,"id","transformers.AutoModelForPreTraining"),m(tb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(tb,"href","#transformers.AutoModelForPreTraining"),m(Bd,"class","relative group"),m(eW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(oW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(rW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(tW,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining"),m(aW,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),m(nW,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining"),m(sW,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),m(lW,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),m(iW,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),m(dW,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),m(mW,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),m(cW,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),m(fW,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),m(gW,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),m(hW,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining"),m(uW,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining"),m(pW,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),m(_W,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining"),m(bW,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining"),m(vW,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),m(FW,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining"),m(TW,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),m(MW,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),m(EW,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),m(CW,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),m(wW,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),m(AW,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining"),m(LW,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),m(yW,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),m(xW,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),m($W,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),m(kW,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining"),m(SW,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),m(RW,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),m(PW,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),m(BW,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining"),m(IW,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),m(NW,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),m(qW,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),m(DW,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),m(jW,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),m(GW,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),m(OW,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining"),m(VW,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),m(XW,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),m(zW,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),m(QW,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),m(WW,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),m(UW,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),m(HW,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),m(JW,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),m(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ov,"id","transformers.AutoModelForCausalLM"),m(ov,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ov,"href","#transformers.AutoModelForCausalLM"),m(qd,"class","relative group"),m(YW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ZW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(KW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(eU,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM"),m(oU,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel"),m(rU,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),m(tU,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),m(aU,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),m(nU,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),m(sU,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),m(lU,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),m(iU,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM"),m(dU,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM"),m(mU,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),m(cU,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),m(fU,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM"),m(gU,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM"),m(hU,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),m(uU,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),m(pU,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),m(_U,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM"),m(bU,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM"),m(vU,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM"),m(FU,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM"),m(TU,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),m(MU,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM"),m(EU,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),m(CU,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM"),m(wU,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM"),m(AU,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM"),m(LU,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),m(yU,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),m(xU,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),m($U,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM"),m(kU,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM"),m(SU,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM"),m(RU,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),m(PU,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),m(BU,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM"),m(IU,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM"),m(NU,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),m(qU,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),m(DU,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),m(jU,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),m(GU,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),m(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Wv,"id","transformers.AutoModelForDepthEstimation"),m(Wv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Wv,"href","#transformers.AutoModelForDepthEstimation"),m(Gd,"class","relative group"),m(OU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(VU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(XU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(zU,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForDepthEstimation"),m(QU,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNForDepthEstimation"),m(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Kv,"id","transformers.AutoModelForMaskedLM"),m(Kv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Kv,"href","#transformers.AutoModelForMaskedLM"),m(Xd,"class","relative group"),m(WU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(UU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(HU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(JU,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM"),m(YU,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),m(ZU,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM"),m(KU,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),m(eH,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),m(oH,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),m(rH,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),m(tH,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),m(aH,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),m(nH,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),m(sH,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM"),m(lH,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM"),m(iH,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),m(dH,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM"),m(mH,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM"),m(cH,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),m(fH,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),m(gH,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),m(hH,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),m(uH,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),m(pH,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),m(_H,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),m(bH,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),m(vH,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),m(FH,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM"),m(TH,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),m(MH,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),m(EH,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),m(CH,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM"),m(wH,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM"),m(AH,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),m(LH,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),m(yH,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),m(xH,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),m($H,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),m(kH,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),m(SH,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),m(RH,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM"),m(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(OF,"id","transformers.AutoModelForSeq2SeqLM"),m(OF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(OF,"href","#transformers.AutoModelForSeq2SeqLM"),m(Wd,"class","relative group"),m(PH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(BH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(IH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(NH,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),m(qH,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),m(DH,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),m(jH,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),m(GH,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),m(OH,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),m(VH,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration"),m(XH,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),m(zH,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),m(QH,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel"),m(WH,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),m(UH,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),m(HH,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),m(JH,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),m(YH,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),m(ZH,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration"),m(KH,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),m(eJ,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),m(oJ,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),m(rJ,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),m(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(fT,"id","transformers.AutoModelForSequenceClassification"),m(fT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(fT,"href","#transformers.AutoModelForSequenceClassification"),m(Jd,"class","relative group"),m(tJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(aJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(nJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(sJ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification"),m(lJ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification"),m(iJ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification"),m(dJ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),m(mJ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),m(cJ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification"),m(fJ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),m(gJ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification"),m(hJ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),m(uJ,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),m(pJ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),m(_J,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),m(bJ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),m(vJ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),m(FJ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification"),m(TJ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification"),m(MJ,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification"),m(EJ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),m(CJ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification"),m(wJ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),m(AJ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),m(LJ,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),m(yJ,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),m(xJ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification"),m($J,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),m(kJ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),m(SJ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),m(RJ,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification"),m(PJ,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForSequenceClassification"),m(BJ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),m(IJ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification"),m(NJ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification"),m(qJ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification"),m(DJ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),m(jJ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),m(GJ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),m(OJ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification"),m(VJ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),m(XJ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),m(zJ,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),m(QJ,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification"),m(WJ,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),m(UJ,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),m(HJ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),m(JJ,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),m(YJ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),m(ZJ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),m(KJ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),m(eY,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),m(oY,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification"),m(rY,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),m(tY,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification"),m(aY,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),m(nY,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),m(sY,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),m(lY,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification"),m(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(bM,"id","transformers.AutoModelForMultipleChoice"),m(bM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(bM,"href","#transformers.AutoModelForMultipleChoice"),m(Kd,"class","relative group"),m(iY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(dY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(mY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(cY,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice"),m(fY,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice"),m(gY,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),m(hY,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),m(uY,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice"),m(pY,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),m(_Y,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),m(bY,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),m(vY,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),m(FY,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice"),m(TY,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice"),m(MY,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),m(EY,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice"),m(CY,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),m(wY,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice"),m(AY,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),m(LY,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice"),m(yY,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),m(xY,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),m($Y,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),m(kY,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),m(SY,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),m(RY,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),m(PY,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),m(BY,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),m(IY,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),m(NY,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),m(qY,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice"),m(DY,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),m(jY,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),m(GY,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),m(OY,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice"),m(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(eE,"id","transformers.AutoModelForNextSentencePrediction"),m(eE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(eE,"href","#transformers.AutoModelForNextSentencePrediction"),m(rm,"class","relative group"),m(VY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(XY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(zY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(QY,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction"),m(WY,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction"),m(UY,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),m(HY,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),m(JY,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),m(YY,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),m(ZY,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),m(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(cE,"id","transformers.AutoModelForTokenClassification"),m(cE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(cE,"href","#transformers.AutoModelForTokenClassification"),m(nm,"class","relative group"),m(KY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(eZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(oZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(rZ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification"),m(tZ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification"),m(aZ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),m(nZ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification"),m(sZ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification"),m(lZ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification"),m(iZ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),m(dZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),m(mZ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification"),m(cZ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),m(fZ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),m(gZ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification"),m(hZ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification"),m(uZ,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification"),m(pZ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),m(_Z,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification"),m(bZ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification"),m(vZ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),m(FZ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification"),m(TZ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),m(MZ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),m(EZ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),m(CZ,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForTokenClassification"),m(wZ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification"),m(AZ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification"),m(LZ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification"),m(yZ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),m(xZ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),m($Z,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),m(kZ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification"),m(SZ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),m(RZ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),m(PZ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification"),m(BZ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification"),m(IZ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),m(NZ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),m(qZ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification"),m(DZ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),m(jZ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),m(GZ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),m(OZ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification"),m(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(r4,"id","transformers.AutoModelForQuestionAnswering"),m(r4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(r4,"href","#transformers.AutoModelForQuestionAnswering"),m(im,"class","relative group"),m(VZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(XZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(zZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(QZ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),m(WZ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering"),m(UZ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering"),m(HZ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),m(JZ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),m(YZ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering"),m(ZZ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),m(KZ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering"),m(eK,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),m(oK,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),m(rK,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),m(tK,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),m(aK,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),m(nK,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),m(sK,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering"),m(lK,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),m(iK,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),m(dK,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),m(mK,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),m(cK,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),m(fK,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),m(gK,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),m(hK,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering"),m(uK,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForQuestionAnswering"),m(pK,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),m(_K,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering"),m(bK,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),m(vK,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering"),m(FK,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),m(TK,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),m(MK,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),m(EK,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),m(CK,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),m(wK,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),m(AK,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),m(LK,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForQuestionAnswering"),m(yK,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),m(xK,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),m($K,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),m(kK,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),m(SK,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),m(RK,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),m(PK,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),m(BK,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),m(IK,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),m(NK,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),m(qK,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),m(DK,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),m(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(eC,"id","transformers.AutoModelForTableQuestionAnswering"),m(eC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(eC,"href","#transformers.AutoModelForTableQuestionAnswering"),m(cm,"class","relative group"),m(jK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(GK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(OK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(VK,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),m(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(nC,"id","transformers.AutoModelForDocumentQuestionAnswering"),m(nC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(nC,"href","#transformers.AutoModelForDocumentQuestionAnswering"),m(hm,"class","relative group"),m(XK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(zK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(QK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(WK,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering"),m(UK,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),m(HK,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),m(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(fC,"id","transformers.AutoModelForImageClassification"),m(fC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(fC,"href","#transformers.AutoModelForImageClassification"),m(bm,"class","relative group"),m(JK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(YK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(ZK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(KK,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification"),m(eee,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification"),m(oee,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification"),m(ree,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),m(tee,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification"),m(aee,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),m(nee,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),m(see,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification"),m(lee,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),m(iee,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification"),m(dee,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),m(mee,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),m(cee,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),m(fee,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),m(gee,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification"),m(hee,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification"),m(uee,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification"),m(pee,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification"),m(_ee,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification"),m(bee,"href","/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification"),m(vee,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification"),m(Fee,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification"),m(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(kC,"id","transformers.AutoModelForVideoClassification"),m(kC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(kC,"href","#transformers.AutoModelForVideoClassification"),m(Tm,"class","relative group"),m(Tee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Mee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Eee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Cee,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification"),m(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(IC,"id","transformers.AutoModelForVision2Seq"),m(IC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(IC,"href","#transformers.AutoModelForVision2Seq"),m(Cm,"class","relative group"),m(wee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Aee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Lee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(yee,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),m(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(GC,"id","transformers.AutoModelForVisualQuestionAnswering"),m(GC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(GC,"href","#transformers.AutoModelForVisualQuestionAnswering"),m(Lm,"class","relative group"),m(xee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m($ee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(kee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(See,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),m(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(QC,"id","transformers.AutoModelForAudioClassification"),m(QC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(QC,"href","#transformers.AutoModelForAudioClassification"),m($m,"class","relative group"),m(Ree,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Pee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Bee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Iee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),m(Nee,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification"),m(qee,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification"),m(Dee,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),m(jee,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),m(Gee,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),m(Oee,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),m(Vee,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),m(Xee,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),m(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(n3,"id","transformers.AutoModelForAudioFrameClassification"),m(n3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(n3,"href","#transformers.AutoModelForAudioFrameClassification"),m(Rm,"class","relative group"),m(zee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Qee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Wee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Uee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),m(Hee,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),m(Jee,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),m(Yee,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),m(Zee,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),m(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(h3,"id","transformers.AutoModelForCTC"),m(h3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(h3,"href","#transformers.AutoModelForCTC"),m(Im,"class","relative group"),m(Kee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(eoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(ooe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(roe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),m(toe,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC"),m(aoe,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC"),m(noe,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC"),m(soe,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC"),m(loe,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC"),m(ioe,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),m(doe,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),m(moe,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),m(coe,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC"),m(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(y3,"id","transformers.AutoModelForSpeechSeq2Seq"),m(y3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(y3,"href","#transformers.AutoModelForSpeechSeq2Seq"),m(Dm,"class","relative group"),m(foe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(goe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(hoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(uoe,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),m(poe,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),m(_oe,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration"),m(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(B3,"id","transformers.AutoModelForAudioXVector"),m(B3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(B3,"href","#transformers.AutoModelForAudioXVector"),m(Vm,"class","relative group"),m(boe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(voe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Foe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Toe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),m(Moe,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),m(Eoe,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),m(Coe,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),m(woe,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector"),m(To,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(X3,"id","transformers.AutoModelForMaskedImageModeling"),m(X3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(X3,"href","#transformers.AutoModelForMaskedImageModeling"),m(Qm,"class","relative group"),m(Aoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Loe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(yoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(xoe,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),m($oe,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),m(koe,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling"),m(Soe,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),m(Mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Z3,"id","transformers.AutoModelForObjectDetection"),m(Z3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Z3,"href","#transformers.AutoModelForObjectDetection"),m(Hm,"class","relative group"),m(Roe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Poe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Boe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ioe,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection"),m(Noe,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection"),m(qoe,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection"),m(Doe,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection"),m(joe,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection"),m(Eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(l5,"id","transformers.AutoModelForImageSegmentation"),m(l5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(l5,"href","#transformers.AutoModelForImageSegmentation"),m(Zm,"class","relative group"),m(Goe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ooe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Voe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Xoe,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation"),m(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(f5,"id","transformers.AutoModelForSemanticSegmentation"),m(f5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(f5,"href","#transformers.AutoModelForSemanticSegmentation"),m(oc,"class","relative group"),m(zoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Qoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Woe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Uoe,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),m(Hoe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),m(Joe,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),m(Yoe,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation"),m(Zoe,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),m(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(T5,"id","transformers.AutoModelForInstanceSegmentation"),m(T5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(T5,"href","#transformers.AutoModelForInstanceSegmentation"),m(ac,"class","relative group"),m(Koe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ere,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(ore,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(rre,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),m(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(A5,"id","transformers.AutoModelForZeroShotObjectDetection"),m(A5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(A5,"href","#transformers.AutoModelForZeroShotObjectDetection"),m(lc,"class","relative group"),m(tre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(are,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(nre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(sre,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTForObjectDetection"),m(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(k5,"id","transformers.TFAutoModel"),m(k5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(k5,"href","#transformers.TFAutoModel"),m(mc,"class","relative group"),m(lre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ire,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(dre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(mre,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel"),m(cre,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel"),m(fre,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel"),m(gre,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),m(hre,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),m(ure,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel"),m(pre,"href","/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel"),m(_re,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel"),m(bre,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel"),m(vre,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel"),m(Fre,"href","/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtModel"),m(Tre,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),m(Mre,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel"),m(Ere,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),m(Cre,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel"),m(wre,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel"),m(Are,"href","/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),m(Lre,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel"),m(yre,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmModel"),m(xre,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel"),m($re,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel"),m(kre,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel"),m(Sre,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model"),m(Rre,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel"),m(Pre,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel"),m(Bre,"href","/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel"),m(Ire,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),m(Nre,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model"),m(qre,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel"),m(Dre,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel"),m(jre,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel"),m(Gre,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel"),m(Ore,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel"),m(Vre,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel"),m(Xre,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel"),m(zre,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel"),m(Qre,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model"),m(Wre,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),m(Ure,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel"),m(Hre,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel"),m(Jre,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel"),m(Yre,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel"),m(Zre,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel"),m(Kre,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel"),m(ete,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel"),m(ote,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel"),m(rte,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),m(tte,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel"),m(ate,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model"),m(nte,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel"),m(ste,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),m(lte,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel"),m(ite,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel"),m(dte,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),m(mte,"href","/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperModel"),m(cte,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel"),m(fte,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel"),m(gte,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),m(hte,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel"),m(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(N0,"id","transformers.TFAutoModelForPreTraining"),m(N0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(N0,"href","#transformers.TFAutoModelForPreTraining"),m(gc,"class","relative group"),m(ute,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(pte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(_te,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(bte,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining"),m(vte,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),m(Fte,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining"),m(Tte,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),m(Mte,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),m(Ete,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),m(Cte,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining"),m(wte,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),m(Ate,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),m(Lte,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),m(yte,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),m(xte,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),m($te,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),m(kte,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),m(Ste,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),m(Rte,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),m(Pte,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),m(Bte,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),m(Ite,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),m(Nte,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),m(qte,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),m(Dte,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),m(jte,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),m(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(dw,"id","transformers.TFAutoModelForCausalLM"),m(dw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(dw,"href","#transformers.TFAutoModelForCausalLM"),m(pc,"class","relative group"),m(Gte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ote,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Vte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Xte,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel"),m(zte,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),m(Qte,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),m(Wte,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),m(Ute,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),m(Hte,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),m(Jte,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM"),m(Yte,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),m(Zte,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),m(Kte,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),m(eae,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),m(oae,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM"),m(rae,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),m(tae,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),m(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Aw,"id","transformers.TFAutoModelForImageClassification"),m(Aw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Aw,"href","#transformers.TFAutoModelForImageClassification"),m(vc,"class","relative group"),m(aae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(nae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(sae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(lae,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),m(iae,"href","/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtForImageClassification"),m(dae,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),m(mae,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification"),m(cae,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher"),m(fae,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification"),m(gae,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),m(hae,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification"),m(uae,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification"),m(pae,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification"),m(_ae,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification"),m(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(qw,"id","transformers.TFAutoModelForSemanticSegmentation"),m(qw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(qw,"href","#transformers.TFAutoModelForSemanticSegmentation"),m(Mc,"class","relative group"),m(bae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(vae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Fae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Tae,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation"),m(Mae,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation"),m(Eae,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation"),m(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Xw,"id","transformers.TFAutoModelForMaskedLM"),m(Xw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Xw,"href","#transformers.TFAutoModelForMaskedLM"),m(Ac,"class","relative group"),m(Cae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(wae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Aae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Lae,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),m(yae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM"),m(xae,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),m($ae,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),m(kae,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),m(Sae,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),m(Rae,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),m(Pae,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM"),m(Bae,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForMaskedLM"),m(Iae,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),m(Nae,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),m(qae,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),m(Dae,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),m(jae,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),m(Gae,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),m(Oae,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),m(Vae,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),m(Xae,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),m(zae,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),m(Qae,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),m(Wae,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),m(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(hA,"id","transformers.TFAutoModelForSeq2SeqLM"),m(hA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(hA,"href","#transformers.TFAutoModelForSeq2SeqLM"),m(xc,"class","relative group"),m(Uae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Hae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Jae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Yae,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),m(Zae,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),m(Kae,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),m(ene,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),m(one,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),m(rne,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel"),m(tne,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),m(ane,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),m(nne,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),m(sne,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),m(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(LA,"id","transformers.TFAutoModelForSequenceClassification"),m(LA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(LA,"href","#transformers.TFAutoModelForSequenceClassification"),m(Sc,"class","relative group"),m(lne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ine,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(dne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(mne,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),m(cne,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification"),m(fne,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),m(gne,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),m(hne,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),m(une,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),m(pne,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),m(_ne,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),m(bne,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),m(vne,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForSequenceClassification"),m(Fne,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),m(Tne,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),m(Mne,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),m(Ene,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),m(Cne,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),m(wne,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification"),m(Ane,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),m(Lne,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),m(yne,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),m(xne,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),m($ne,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),m(kne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),m(Sne,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),m(Rne,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),m(Pne,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),m(Bne,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),m(Ine,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),m(Nne,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),m(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(a6,"id","transformers.TFAutoModelForMultipleChoice"),m(a6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(a6,"href","#transformers.TFAutoModelForMultipleChoice"),m(Bc,"class","relative group"),m(qne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Dne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(jne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(na,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Gne,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),m(One,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice"),m(Vne,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),m(Xne,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),m(zne,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),m(Qne,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),m(Wne,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),m(Une,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),m(Hne,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),m(Jne,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),m(Yne,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),m(Zne,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),m(Kne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),m(ese,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),m(ose,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),m(rse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),m(tse,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),m(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(C6,"id","transformers.TFAutoModelForNextSentencePrediction"),m(C6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(C6,"href","#transformers.TFAutoModelForNextSentencePrediction"),m(qc,"class","relative group"),m(ase,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(nse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(sse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(sa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(lse,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),m(ise,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),m(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(x6,"id","transformers.TFAutoModelForTableQuestionAnswering"),m(x6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(x6,"href","#transformers.TFAutoModelForTableQuestionAnswering"),m(Gc,"class","relative group"),m(dse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(mse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(cse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(la,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(fse,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),m(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(R6,"id","transformers.TFAutoModelForDocumentQuestionAnswering"),m(R6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(R6,"href","#transformers.TFAutoModelForDocumentQuestionAnswering"),m(Xc,"class","relative group"),m(gse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(hse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(use,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ia,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(pse,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering"),m(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(N6,"id","transformers.TFAutoModelForTokenClassification"),m(N6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(N6,"href","#transformers.TFAutoModelForTokenClassification"),m(Wc,"class","relative group"),m(_se,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(bse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(vse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(da,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Fse,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),m(Tse,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification"),m(Mse,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),m(Ese,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),m(Cse,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),m(wse,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),m(Ase,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),m(Lse,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification"),m(yse,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForTokenClassification"),m(xse,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),m($se,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),m(kse,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),m(Sse,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification"),m(Rse,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),m(Pse,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),m(Bse,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),m(Ise,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),m(Nse,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),m(qse,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),m(Dse,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),m(jse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),m(Gse,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),m(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(i7,"id","transformers.TFAutoModelForQuestionAnswering"),m(i7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(i7,"href","#transformers.TFAutoModelForQuestionAnswering"),m(Jc,"class","relative group"),m(Ose,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Vse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Xse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(zse,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),m(Qse,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),m(Wse,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),m(Use,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),m(Hse,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),m(Jse,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),m(Yse,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),m(Zse,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),m(Kse,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),m(ele,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),m(ole,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),m(rle,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering"),m(tle,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),m(ale,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),m(nle,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),m(sle,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),m(lle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),m(ile,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),m(dle,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),m(mle,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),m(cle,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),m(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(S7,"id","transformers.TFAutoModelForVision2Seq"),m(S7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(S7,"href","#transformers.TFAutoModelForVision2Seq"),m(Kc,"class","relative group"),m(fle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(gle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(hle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ule,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),m(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(I7,"id","transformers.TFAutoModelForSpeechSeq2Seq"),m(I7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(I7,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),m(rf,"class","relative group"),m(ple,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(_le,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(ble,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(vle,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),m(Fle,"href","/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration"),m(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(G7,"id","transformers.FlaxAutoModel"),m(G7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(G7,"href","#transformers.FlaxAutoModel"),m(nf,"class","relative group"),m(Tle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Mle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Ele,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ga,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Cle,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel"),m(wle,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel"),m(Ale,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel"),m(Lle,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel"),m(yle,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),m(xle,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),m($le,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),m(kle,"href","/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel"),m(Sle,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),m(Rle,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel"),m(Ple,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model"),m(Ble,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),m(Ile,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel"),m(Nle,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model"),m(qle,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel"),m(Dle,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel"),m(jle,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model"),m(Gle,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel"),m(Ole,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel"),m(Vle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel"),m(Xle,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel"),m(zle,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model"),m(Qle,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),m(Wle,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel"),m(Ule,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),m(Hle,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel"),m(Jle,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),m(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(_8,"id","transformers.FlaxAutoModelForCausalLM"),m(_8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(_8,"href","#transformers.FlaxAutoModelForCausalLM"),m(df,"class","relative group"),m(Yle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Zle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Kle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ha,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(eie,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM"),m(oie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM"),m(rie,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),m(tie,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),m(aie,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),m(nie,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),m(sie,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),m(lie,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),m(iie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),m(die,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),m(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($8,"id","transformers.FlaxAutoModelForPreTraining"),m($8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m($8,"href","#transformers.FlaxAutoModelForPreTraining"),m(ff,"class","relative group"),m(mie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(cie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(fie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ua,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(gie,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),m(hie,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),m(uie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining"),m(pie,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),m(_ie,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),m(bie,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),m(vie,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),m(Fie,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),m(Tie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),m(Mie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),m(Eie,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),m(Cie,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),m(wie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),m(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Q8,"id","transformers.FlaxAutoModelForMaskedLM"),m(Q8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Q8,"href","#transformers.FlaxAutoModelForMaskedLM"),m(uf,"class","relative group"),m(Aie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Lie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(yie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(pa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(xie,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),m($ie,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),m(kie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),m(Sie,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),m(Rie,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),m(Pie,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),m(Bie,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),m(Iie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),m(Nie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),m(qie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),m(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(nL,"id","transformers.FlaxAutoModelForSeq2SeqLM"),m(nL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(nL,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),m(bf,"class","relative group"),m(Die,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(jie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Gie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(_a,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Oie,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),m(Vie,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),m(Xie,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),m(zie,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),m(Qie,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),m(Wie,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel"),m(Uie,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),m(Hie,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),m(Jie,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),m(Yie,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),m(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(bL,"id","transformers.FlaxAutoModelForSequenceClassification"),m(bL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(bL,"href","#transformers.FlaxAutoModelForSequenceClassification"),m(Tf,"class","relative group"),m(Zie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Kie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(ede,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ba,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ode,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),m(rde,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),m(tde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),m(ade,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),m(nde,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),m(sde,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),m(lde,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),m(ide,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),m(dde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),m(mde,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),m(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(kL,"id","transformers.FlaxAutoModelForQuestionAnswering"),m(kL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(kL,"href","#transformers.FlaxAutoModelForQuestionAnswering"),m(Cf,"class","relative group"),m(cde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(fde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(gde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(va,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(hde,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),m(ude,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),m(pde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),m(_de,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),m(bde,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),m(vde,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),m(Fde,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),m(Tde,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),m(Mde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),m(Ede,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),m(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(XL,"id","transformers.FlaxAutoModelForTokenClassification"),m(XL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(XL,"href","#transformers.FlaxAutoModelForTokenClassification"),m(Lf,"class","relative group"),m(Cde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(wde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Ade,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Lde,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),m(yde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),m(xde,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),m($de,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),m(kde,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),m(Sde,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),m(Rde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),m(Pde,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),m(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(oy,"id","transformers.FlaxAutoModelForMultipleChoice"),m(oy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(oy,"href","#transformers.FlaxAutoModelForMultipleChoice"),m($f,"class","relative group"),m(Bde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ide,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Nde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(qde,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),m(Dde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),m(jde,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),m(Gde,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),m(Ode,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),m(Vde,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),m(Xde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),m(zde,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),m(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(fy,"id","transformers.FlaxAutoModelForNextSentencePrediction"),m(fy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(fy,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),m(Rf,"class","relative group"),m(Qde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Wde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Ude,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Hde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),m(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(py,"id","transformers.FlaxAutoModelForImageClassification"),m(py,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(py,"href","#transformers.FlaxAutoModelForImageClassification"),m(If,"class","relative group"),m(Jde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Yde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Zde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Kde,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),m(eme,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification"),m(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ty,"id","transformers.FlaxAutoModelForVision2Seq"),m(Ty,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Ty,"href","#transformers.FlaxAutoModelForVision2Seq"),m(Df,"class","relative group"),m(ome,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(rme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(tme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ame,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),m(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(c,_){e(document.head,g),b(c,v,_),b(c,u,_),e(u,f),e(f,p),M(d,p,null),e(u,h),e(u,$o),e($o,bd),b(c,zf,_),b(c,Tt,_),e(Tt,vd),e(Tt,Fd),e(Fd,s$),e(Tt,Qf),b(c,Xe,_),b(c,He,_),e(He,Td),e(He,ms),e(ms,l$),e(He,cs),e(He,fs),e(fs,i$),e(He,Md),e(He,gs),e(gs,d$),e(He,Ed),b(c,Wf,_),M(on,c,_),b(c,Je,_),b(c,Ae,_),e(Ae,EN),e(Ae,Cd),e(Cd,CN),e(Ae,wN),b(c,ko,_),b(c,rn,_),e(rn,AN),e(rn,Uf),e(Uf,LN),e(rn,hio),b(c,xto,_),b(c,wd,_),e(wd,Hf),e(Hf,gfe),M(m$,gfe,null),e(wd,uio),e(wd,hfe),e(hfe,pio),b(c,$to,_),b(c,hs,_),e(hs,_io),e(hs,ufe),e(ufe,bio),e(hs,vio),e(hs,pfe),e(pfe,Fio),e(hs,Tio),b(c,kto,_),M(c$,c,_),b(c,Sto,_),b(c,yN,_),e(yN,Mio),b(c,Rto,_),M(Jf,c,_),b(c,Pto,_),b(c,Ad,_),e(Ad,Yf),e(Yf,_fe),M(f$,_fe,null),e(Ad,Eio),e(Ad,bfe),e(bfe,Cio),b(c,Bto,_),b(c,So,_),M(g$,So,null),e(So,wio),e(So,h$),e(h$,Aio),e(h$,xN),e(xN,Lio),e(h$,yio),e(So,xio),e(So,u$),e(u$,$io),e(u$,vfe),e(vfe,kio),e(u$,Sio),e(So,Rio),e(So,qr),M(p$,qr,null),e(qr,Pio),e(qr,Ffe),e(Ffe,Bio),e(qr,Iio),e(qr,Ld),e(Ld,Nio),e(Ld,Tfe),e(Tfe,qio),e(Ld,Dio),e(Ld,Mfe),e(Mfe,jio),e(Ld,Gio),e(qr,Oio),e(qr,A),e(A,Zf),e(Zf,Efe),e(Efe,Vio),e(Zf,Xio),e(Zf,$N),e($N,zio),e(Zf,Qio),e(A,Wio),e(A,Kf),e(Kf,Cfe),e(Cfe,Uio),e(Kf,Hio),e(Kf,kN),e(kN,Jio),e(Kf,Yio),e(A,Zio),e(A,eg),e(eg,wfe),e(wfe,Kio),e(eg,edo),e(eg,SN),e(SN,odo),e(eg,rdo),e(A,tdo),e(A,og),e(og,Afe),e(Afe,ado),e(og,ndo),e(og,RN),e(RN,sdo),e(og,ldo),e(A,ido),e(A,rg),e(rg,Lfe),e(Lfe,ddo),e(rg,mdo),e(rg,PN),e(PN,cdo),e(rg,fdo),e(A,gdo),e(A,tg),e(tg,yfe),e(yfe,hdo),e(tg,udo),e(tg,BN),e(BN,pdo),e(tg,_do),e(A,bdo),e(A,ag),e(ag,xfe),e(xfe,vdo),e(ag,Fdo),e(ag,IN),e(IN,Tdo),e(ag,Mdo),e(A,Edo),e(A,ng),e(ng,$fe),e($fe,Cdo),e(ng,wdo),e(ng,NN),e(NN,Ado),e(ng,Ldo),e(A,ydo),e(A,sg),e(sg,kfe),e(kfe,xdo),e(sg,$do),e(sg,qN),e(qN,kdo),e(sg,Sdo),e(A,Rdo),e(A,lg),e(lg,Sfe),e(Sfe,Pdo),e(lg,Bdo),e(lg,DN),e(DN,Ido),e(lg,Ndo),e(A,qdo),e(A,ig),e(ig,Rfe),e(Rfe,Ddo),e(ig,jdo),e(ig,jN),e(jN,Gdo),e(ig,Odo),e(A,Vdo),e(A,dg),e(dg,Pfe),e(Pfe,Xdo),e(dg,zdo),e(dg,GN),e(GN,Qdo),e(dg,Wdo),e(A,Udo),e(A,mg),e(mg,Bfe),e(Bfe,Hdo),e(mg,Jdo),e(mg,ON),e(ON,Ydo),e(mg,Zdo),e(A,Kdo),e(A,cg),e(cg,Ife),e(Ife,emo),e(cg,omo),e(cg,VN),e(VN,rmo),e(cg,tmo),e(A,amo),e(A,fg),e(fg,Nfe),e(Nfe,nmo),e(fg,smo),e(fg,XN),e(XN,lmo),e(fg,imo),e(A,dmo),e(A,gg),e(gg,qfe),e(qfe,mmo),e(gg,cmo),e(gg,zN),e(zN,fmo),e(gg,gmo),e(A,hmo),e(A,hg),e(hg,Dfe),e(Dfe,umo),e(hg,pmo),e(hg,QN),e(QN,_mo),e(hg,bmo),e(A,vmo),e(A,ug),e(ug,jfe),e(jfe,Fmo),e(ug,Tmo),e(ug,WN),e(WN,Mmo),e(ug,Emo),e(A,Cmo),e(A,pg),e(pg,Gfe),e(Gfe,wmo),e(pg,Amo),e(pg,UN),e(UN,Lmo),e(pg,ymo),e(A,xmo),e(A,_g),e(_g,Ofe),e(Ofe,$mo),e(_g,kmo),e(_g,HN),e(HN,Smo),e(_g,Rmo),e(A,Pmo),e(A,bg),e(bg,Vfe),e(Vfe,Bmo),e(bg,Imo),e(bg,JN),e(JN,Nmo),e(bg,qmo),e(A,Dmo),e(A,vg),e(vg,Xfe),e(Xfe,jmo),e(vg,Gmo),e(vg,YN),e(YN,Omo),e(vg,Vmo),e(A,Xmo),e(A,Fg),e(Fg,zfe),e(zfe,zmo),e(Fg,Qmo),e(Fg,ZN),e(ZN,Wmo),e(Fg,Umo),e(A,Hmo),e(A,Tg),e(Tg,Qfe),e(Qfe,Jmo),e(Tg,Ymo),e(Tg,KN),e(KN,Zmo),e(Tg,Kmo),e(A,eco),e(A,Mg),e(Mg,Wfe),e(Wfe,oco),e(Mg,rco),e(Mg,eq),e(eq,tco),e(Mg,aco),e(A,nco),e(A,Eg),e(Eg,Ufe),e(Ufe,sco),e(Eg,lco),e(Eg,oq),e(oq,ico),e(Eg,dco),e(A,mco),e(A,Cg),e(Cg,Hfe),e(Hfe,cco),e(Cg,fco),e(Cg,rq),e(rq,gco),e(Cg,hco),e(A,uco),e(A,wg),e(wg,Jfe),e(Jfe,pco),e(wg,_co),e(wg,tq),e(tq,bco),e(wg,vco),e(A,Fco),e(A,Ag),e(Ag,Yfe),e(Yfe,Tco),e(Ag,Mco),e(Ag,aq),e(aq,Eco),e(Ag,Cco),e(A,wco),e(A,Lg),e(Lg,Zfe),e(Zfe,Aco),e(Lg,Lco),e(Lg,nq),e(nq,yco),e(Lg,xco),e(A,$co),e(A,yg),e(yg,Kfe),e(Kfe,kco),e(yg,Sco),e(yg,sq),e(sq,Rco),e(yg,Pco),e(A,Bco),e(A,xg),e(xg,ege),e(ege,Ico),e(xg,Nco),e(xg,lq),e(lq,qco),e(xg,Dco),e(A,jco),e(A,$g),e($g,oge),e(oge,Gco),e($g,Oco),e($g,iq),e(iq,Vco),e($g,Xco),e(A,zco),e(A,kg),e(kg,rge),e(rge,Qco),e(kg,Wco),e(kg,dq),e(dq,Uco),e(kg,Hco),e(A,Jco),e(A,Sg),e(Sg,tge),e(tge,Yco),e(Sg,Zco),e(Sg,mq),e(mq,Kco),e(Sg,efo),e(A,ofo),e(A,Rg),e(Rg,age),e(age,rfo),e(Rg,tfo),e(Rg,cq),e(cq,afo),e(Rg,nfo),e(A,sfo),e(A,Pg),e(Pg,nge),e(nge,lfo),e(Pg,ifo),e(Pg,fq),e(fq,dfo),e(Pg,mfo),e(A,cfo),e(A,Bg),e(Bg,sge),e(sge,ffo),e(Bg,gfo),e(Bg,gq),e(gq,hfo),e(Bg,ufo),e(A,pfo),e(A,Ig),e(Ig,lge),e(lge,_fo),e(Ig,bfo),e(Ig,hq),e(hq,vfo),e(Ig,Ffo),e(A,Tfo),e(A,Ng),e(Ng,ige),e(ige,Mfo),e(Ng,Efo),e(Ng,uq),e(uq,Cfo),e(Ng,wfo),e(A,Afo),e(A,qg),e(qg,dge),e(dge,Lfo),e(qg,yfo),e(qg,pq),e(pq,xfo),e(qg,$fo),e(A,kfo),e(A,Dg),e(Dg,mge),e(mge,Sfo),e(Dg,Rfo),e(Dg,_q),e(_q,Pfo),e(Dg,Bfo),e(A,Ifo),e(A,jg),e(jg,cge),e(cge,Nfo),e(jg,qfo),e(jg,bq),e(bq,Dfo),e(jg,jfo),e(A,Gfo),e(A,Gg),e(Gg,fge),e(fge,Ofo),e(Gg,Vfo),e(Gg,vq),e(vq,Xfo),e(Gg,zfo),e(A,Qfo),e(A,Og),e(Og,gge),e(gge,Wfo),e(Og,Ufo),e(Og,Fq),e(Fq,Hfo),e(Og,Jfo),e(A,Yfo),e(A,Vg),e(Vg,hge),e(hge,Zfo),e(Vg,Kfo),e(Vg,Tq),e(Tq,ego),e(Vg,ogo),e(A,rgo),e(A,Xg),e(Xg,uge),e(uge,tgo),e(Xg,ago),e(Xg,Mq),e(Mq,ngo),e(Xg,sgo),e(A,lgo),e(A,zg),e(zg,pge),e(pge,igo),e(zg,dgo),e(zg,Eq),e(Eq,mgo),e(zg,cgo),e(A,fgo),e(A,Qg),e(Qg,_ge),e(_ge,ggo),e(Qg,hgo),e(Qg,Cq),e(Cq,ugo),e(Qg,pgo),e(A,_go),e(A,Wg),e(Wg,bge),e(bge,bgo),e(Wg,vgo),e(Wg,wq),e(wq,Fgo),e(Wg,Tgo),e(A,Mgo),e(A,Ug),e(Ug,vge),e(vge,Ego),e(Ug,Cgo),e(Ug,Aq),e(Aq,wgo),e(Ug,Ago),e(A,Lgo),e(A,Hg),e(Hg,Fge),e(Fge,ygo),e(Hg,xgo),e(Hg,Lq),e(Lq,$go),e(Hg,kgo),e(A,Sgo),e(A,Jg),e(Jg,Tge),e(Tge,Rgo),e(Jg,Pgo),e(Jg,yq),e(yq,Bgo),e(Jg,Igo),e(A,Ngo),e(A,Yg),e(Yg,Mge),e(Mge,qgo),e(Yg,Dgo),e(Yg,xq),e(xq,jgo),e(Yg,Ggo),e(A,Ogo),e(A,Zg),e(Zg,Ege),e(Ege,Vgo),e(Zg,Xgo),e(Zg,$q),e($q,zgo),e(Zg,Qgo),e(A,Wgo),e(A,Kg),e(Kg,Cge),e(Cge,Ugo),e(Kg,Hgo),e(Kg,kq),e(kq,Jgo),e(Kg,Ygo),e(A,Zgo),e(A,eh),e(eh,wge),e(wge,Kgo),e(eh,eho),e(eh,Sq),e(Sq,oho),e(eh,rho),e(A,tho),e(A,oh),e(oh,Age),e(Age,aho),e(oh,nho),e(oh,Rq),e(Rq,sho),e(oh,lho),e(A,iho),e(A,rh),e(rh,Lge),e(Lge,dho),e(rh,mho),e(rh,Pq),e(Pq,cho),e(rh,fho),e(A,gho),e(A,th),e(th,yge),e(yge,hho),e(th,uho),e(th,Bq),e(Bq,pho),e(th,_ho),e(A,bho),e(A,ah),e(ah,xge),e(xge,vho),e(ah,Fho),e(ah,Iq),e(Iq,Tho),e(ah,Mho),e(A,Eho),e(A,nh),e(nh,$ge),e($ge,Cho),e(nh,who),e(nh,Nq),e(Nq,Aho),e(nh,Lho),e(A,yho),e(A,sh),e(sh,kge),e(kge,xho),e(sh,$ho),e(sh,qq),e(qq,kho),e(sh,Sho),e(A,Rho),e(A,lh),e(lh,Sge),e(Sge,Pho),e(lh,Bho),e(lh,Dq),e(Dq,Iho),e(lh,Nho),e(A,qho),e(A,ih),e(ih,Rge),e(Rge,Dho),e(ih,jho),e(ih,jq),e(jq,Gho),e(ih,Oho),e(A,Vho),e(A,dh),e(dh,Pge),e(Pge,Xho),e(dh,zho),e(dh,Gq),e(Gq,Qho),e(dh,Who),e(A,Uho),e(A,mh),e(mh,Bge),e(Bge,Hho),e(mh,Jho),e(mh,Oq),e(Oq,Yho),e(mh,Zho),e(A,Kho),e(A,ch),e(ch,Ige),e(Ige,euo),e(ch,ouo),e(ch,Vq),e(Vq,ruo),e(ch,tuo),e(A,auo),e(A,fh),e(fh,Nge),e(Nge,nuo),e(fh,suo),e(fh,Xq),e(Xq,luo),e(fh,iuo),e(A,duo),e(A,gh),e(gh,qge),e(qge,muo),e(gh,cuo),e(gh,zq),e(zq,fuo),e(gh,guo),e(A,huo),e(A,hh),e(hh,Dge),e(Dge,uuo),e(hh,puo),e(hh,Qq),e(Qq,_uo),e(hh,buo),e(A,vuo),e(A,uh),e(uh,jge),e(jge,Fuo),e(uh,Tuo),e(uh,Wq),e(Wq,Muo),e(uh,Euo),e(A,Cuo),e(A,ph),e(ph,Gge),e(Gge,wuo),e(ph,Auo),e(ph,Uq),e(Uq,Luo),e(ph,yuo),e(A,xuo),e(A,_h),e(_h,Oge),e(Oge,$uo),e(_h,kuo),e(_h,Hq),e(Hq,Suo),e(_h,Ruo),e(A,Puo),e(A,bh),e(bh,Vge),e(Vge,Buo),e(bh,Iuo),e(bh,Jq),e(Jq,Nuo),e(bh,quo),e(A,Duo),e(A,vh),e(vh,Xge),e(Xge,juo),e(vh,Guo),e(vh,Yq),e(Yq,Ouo),e(vh,Vuo),e(A,Xuo),e(A,Fh),e(Fh,zge),e(zge,zuo),e(Fh,Quo),e(Fh,Zq),e(Zq,Wuo),e(Fh,Uuo),e(A,Huo),e(A,Th),e(Th,Qge),e(Qge,Juo),e(Th,Yuo),e(Th,Kq),e(Kq,Zuo),e(Th,Kuo),e(A,epo),e(A,Mh),e(Mh,Wge),e(Wge,opo),e(Mh,rpo),e(Mh,eD),e(eD,tpo),e(Mh,apo),e(A,npo),e(A,Eh),e(Eh,Uge),e(Uge,spo),e(Eh,lpo),e(Eh,oD),e(oD,ipo),e(Eh,dpo),e(A,mpo),e(A,Ch),e(Ch,Hge),e(Hge,cpo),e(Ch,fpo),e(Ch,rD),e(rD,gpo),e(Ch,hpo),e(A,upo),e(A,wh),e(wh,Jge),e(Jge,ppo),e(wh,_po),e(wh,tD),e(tD,bpo),e(wh,vpo),e(A,Fpo),e(A,Ah),e(Ah,Yge),e(Yge,Tpo),e(Ah,Mpo),e(Ah,aD),e(aD,Epo),e(Ah,Cpo),e(A,wpo),e(A,Lh),e(Lh,Zge),e(Zge,Apo),e(Lh,Lpo),e(Lh,nD),e(nD,ypo),e(Lh,xpo),e(A,$po),e(A,yh),e(yh,Kge),e(Kge,kpo),e(yh,Spo),e(yh,sD),e(sD,Rpo),e(yh,Ppo),e(A,Bpo),e(A,xh),e(xh,ehe),e(ehe,Ipo),e(xh,Npo),e(xh,lD),e(lD,qpo),e(xh,Dpo),e(A,jpo),e(A,$h),e($h,ohe),e(ohe,Gpo),e($h,Opo),e($h,iD),e(iD,Vpo),e($h,Xpo),e(A,zpo),e(A,kh),e(kh,rhe),e(rhe,Qpo),e(kh,Wpo),e(kh,dD),e(dD,Upo),e(kh,Hpo),e(A,Jpo),e(A,Sh),e(Sh,the),e(the,Ypo),e(Sh,Zpo),e(Sh,mD),e(mD,Kpo),e(Sh,e_o),e(A,o_o),e(A,Rh),e(Rh,ahe),e(ahe,r_o),e(Rh,t_o),e(Rh,cD),e(cD,a_o),e(Rh,n_o),e(A,s_o),e(A,Ph),e(Ph,nhe),e(nhe,l_o),e(Ph,i_o),e(Ph,fD),e(fD,d_o),e(Ph,m_o),e(A,c_o),e(A,Bh),e(Bh,she),e(she,f_o),e(Bh,g_o),e(Bh,gD),e(gD,h_o),e(Bh,u_o),e(A,p_o),e(A,Ih),e(Ih,lhe),e(lhe,__o),e(Ih,b_o),e(Ih,hD),e(hD,v_o),e(Ih,F_o),e(A,T_o),e(A,Nh),e(Nh,ihe),e(ihe,M_o),e(Nh,E_o),e(Nh,uD),e(uD,C_o),e(Nh,w_o),e(A,A_o),e(A,qh),e(qh,dhe),e(dhe,L_o),e(qh,y_o),e(qh,pD),e(pD,x_o),e(qh,$_o),e(A,k_o),e(A,Dh),e(Dh,mhe),e(mhe,S_o),e(Dh,R_o),e(Dh,_D),e(_D,P_o),e(Dh,B_o),e(A,I_o),e(A,jh),e(jh,che),e(che,N_o),e(jh,q_o),e(jh,bD),e(bD,D_o),e(jh,j_o),e(A,G_o),e(A,Gh),e(Gh,fhe),e(fhe,O_o),e(Gh,V_o),e(Gh,vD),e(vD,X_o),e(Gh,z_o),e(A,Q_o),e(A,Oh),e(Oh,ghe),e(ghe,W_o),e(Oh,U_o),e(Oh,FD),e(FD,H_o),e(Oh,J_o),e(A,Y_o),e(A,Vh),e(Vh,hhe),e(hhe,Z_o),e(Vh,K_o),e(Vh,TD),e(TD,e1o),e(Vh,o1o),e(A,r1o),e(A,Xh),e(Xh,uhe),e(uhe,t1o),e(Xh,a1o),e(Xh,MD),e(MD,n1o),e(Xh,s1o),e(A,l1o),e(A,zh),e(zh,phe),e(phe,i1o),e(zh,d1o),e(zh,ED),e(ED,m1o),e(zh,c1o),e(A,f1o),e(A,Qh),e(Qh,_he),e(_he,g1o),e(Qh,h1o),e(Qh,CD),e(CD,u1o),e(Qh,p1o),e(A,_1o),e(A,Wh),e(Wh,bhe),e(bhe,b1o),e(Wh,v1o),e(Wh,wD),e(wD,F1o),e(Wh,T1o),e(A,M1o),e(A,Uh),e(Uh,vhe),e(vhe,E1o),e(Uh,C1o),e(Uh,AD),e(AD,w1o),e(Uh,A1o),e(A,L1o),e(A,Hh),e(Hh,Fhe),e(Fhe,y1o),e(Hh,x1o),e(Hh,LD),e(LD,$1o),e(Hh,k1o),e(A,S1o),e(A,Jh),e(Jh,The),e(The,R1o),e(Jh,P1o),e(Jh,yD),e(yD,B1o),e(Jh,I1o),e(A,N1o),e(A,Yh),e(Yh,Mhe),e(Mhe,q1o),e(Yh,D1o),e(Yh,xD),e(xD,j1o),e(Yh,G1o),e(A,O1o),e(A,Zh),e(Zh,Ehe),e(Ehe,V1o),e(Zh,X1o),e(Zh,$D),e($D,z1o),e(Zh,Q1o),e(A,W1o),e(A,Kh),e(Kh,Che),e(Che,U1o),e(Kh,H1o),e(Kh,kD),e(kD,J1o),e(Kh,Y1o),e(A,Z1o),e(A,eu),e(eu,whe),e(whe,K1o),e(eu,e2o),e(eu,SD),e(SD,o2o),e(eu,r2o),e(A,t2o),e(A,ou),e(ou,Ahe),e(Ahe,a2o),e(ou,n2o),e(ou,RD),e(RD,s2o),e(ou,l2o),e(A,i2o),e(A,ru),e(ru,Lhe),e(Lhe,d2o),e(ru,m2o),e(ru,PD),e(PD,c2o),e(ru,f2o),e(A,g2o),e(A,tu),e(tu,yhe),e(yhe,h2o),e(tu,u2o),e(tu,BD),e(BD,p2o),e(tu,_2o),e(A,b2o),e(A,au),e(au,xhe),e(xhe,v2o),e(au,F2o),e(au,ID),e(ID,T2o),e(au,M2o),e(A,E2o),e(A,nu),e(nu,$he),e($he,C2o),e(nu,w2o),e(nu,ND),e(ND,A2o),e(nu,L2o),e(A,y2o),e(A,su),e(su,khe),e(khe,x2o),e(su,$2o),e(su,qD),e(qD,k2o),e(su,S2o),e(A,R2o),e(A,lu),e(lu,She),e(She,P2o),e(lu,B2o),e(lu,DD),e(DD,I2o),e(lu,N2o),e(A,q2o),e(A,iu),e(iu,Rhe),e(Rhe,D2o),e(iu,j2o),e(iu,jD),e(jD,G2o),e(iu,O2o),e(A,V2o),e(A,du),e(du,Phe),e(Phe,X2o),e(du,z2o),e(du,GD),e(GD,Q2o),e(du,W2o),e(A,U2o),e(A,mu),e(mu,Bhe),e(Bhe,H2o),e(mu,J2o),e(mu,OD),e(OD,Y2o),e(mu,Z2o),e(A,K2o),e(A,cu),e(cu,Ihe),e(Ihe,ebo),e(cu,obo),e(cu,VD),e(VD,rbo),e(cu,tbo),e(A,abo),e(A,fu),e(fu,Nhe),e(Nhe,nbo),e(fu,sbo),e(fu,XD),e(XD,lbo),e(fu,ibo),e(A,dbo),e(A,gu),e(gu,qhe),e(qhe,mbo),e(gu,cbo),e(gu,zD),e(zD,fbo),e(gu,gbo),e(A,hbo),e(A,hu),e(hu,Dhe),e(Dhe,ubo),e(hu,pbo),e(hu,QD),e(QD,_bo),e(hu,bbo),e(A,vbo),e(A,uu),e(uu,jhe),e(jhe,Fbo),e(uu,Tbo),e(uu,WD),e(WD,Mbo),e(uu,Ebo),e(A,Cbo),e(A,pu),e(pu,Ghe),e(Ghe,wbo),e(pu,Abo),e(pu,UD),e(UD,Lbo),e(pu,ybo),e(A,xbo),e(A,_u),e(_u,Ohe),e(Ohe,$bo),e(_u,kbo),e(_u,HD),e(HD,Sbo),e(_u,Rbo),e(A,Pbo),e(A,bu),e(bu,Vhe),e(Vhe,Bbo),e(bu,Ibo),e(bu,JD),e(JD,Nbo),e(bu,qbo),e(A,Dbo),e(A,vu),e(vu,Xhe),e(Xhe,jbo),e(vu,Gbo),e(vu,YD),e(YD,Obo),e(vu,Vbo),e(A,Xbo),e(A,Fu),e(Fu,zhe),e(zhe,zbo),e(Fu,Qbo),e(Fu,ZD),e(ZD,Wbo),e(Fu,Ubo),e(A,Hbo),e(A,Tu),e(Tu,Qhe),e(Qhe,Jbo),e(Tu,Ybo),e(Tu,KD),e(KD,Zbo),e(Tu,Kbo),e(A,evo),e(A,Mu),e(Mu,Whe),e(Whe,ovo),e(Mu,rvo),e(Mu,ej),e(ej,tvo),e(Mu,avo),e(A,nvo),e(A,Eu),e(Eu,Uhe),e(Uhe,svo),e(Eu,lvo),e(Eu,oj),e(oj,ivo),e(Eu,dvo),e(A,mvo),e(A,Cu),e(Cu,Hhe),e(Hhe,cvo),e(Cu,fvo),e(Cu,rj),e(rj,gvo),e(Cu,hvo),e(qr,uvo),M(wu,qr,null),e(So,pvo),e(So,Au),M(_$,Au,null),e(Au,_vo),e(Au,Jhe),e(Jhe,bvo),b(c,Ito,_),b(c,yd,_),e(yd,Lu),e(Lu,Yhe),M(b$,Yhe,null),e(yd,vvo),e(yd,Zhe),e(Zhe,Fvo),b(c,Nto,_),b(c,Ro,_),M(v$,Ro,null),e(Ro,Tvo),e(Ro,F$),e(F$,Mvo),e(F$,tj),e(tj,Evo),e(F$,Cvo),e(Ro,wvo),e(Ro,T$),e(T$,Avo),e(T$,Khe),e(Khe,Lvo),e(T$,yvo),e(Ro,xvo),e(Ro,Dr),M(M$,Dr,null),e(Dr,$vo),e(Dr,eue),e(eue,kvo),e(Dr,Svo),e(Dr,tn),e(tn,Rvo),e(tn,oue),e(oue,Pvo),e(tn,Bvo),e(tn,rue),e(rue,Ivo),e(tn,Nvo),e(tn,tue),e(tue,qvo),e(tn,Dvo),e(Dr,jvo),e(Dr,k),e(k,us),e(us,aue),e(aue,Gvo),e(us,Ovo),e(us,aj),e(aj,Vvo),e(us,Xvo),e(us,nj),e(nj,zvo),e(us,Qvo),e(k,Wvo),e(k,ps),e(ps,nue),e(nue,Uvo),e(ps,Hvo),e(ps,sj),e(sj,Jvo),e(ps,Yvo),e(ps,lj),e(lj,Zvo),e(ps,Kvo),e(k,eFo),e(k,_s),e(_s,sue),e(sue,oFo),e(_s,rFo),e(_s,ij),e(ij,tFo),e(_s,aFo),e(_s,dj),e(dj,nFo),e(_s,sFo),e(k,lFo),e(k,yu),e(yu,lue),e(lue,iFo),e(yu,dFo),e(yu,mj),e(mj,mFo),e(yu,cFo),e(k,fFo),e(k,bs),e(bs,iue),e(iue,gFo),e(bs,hFo),e(bs,cj),e(cj,uFo),e(bs,pFo),e(bs,fj),e(fj,_Fo),e(bs,bFo),e(k,vFo),e(k,xu),e(xu,due),e(due,FFo),e(xu,TFo),e(xu,gj),e(gj,MFo),e(xu,EFo),e(k,CFo),e(k,$u),e($u,mue),e(mue,wFo),e($u,AFo),e($u,hj),e(hj,LFo),e($u,yFo),e(k,xFo),e(k,ku),e(ku,cue),e(cue,$Fo),e(ku,kFo),e(ku,uj),e(uj,SFo),e(ku,RFo),e(k,PFo),e(k,vs),e(vs,fue),e(fue,BFo),e(vs,IFo),e(vs,pj),e(pj,NFo),e(vs,qFo),e(vs,_j),e(_j,DFo),e(vs,jFo),e(k,GFo),e(k,Fs),e(Fs,gue),e(gue,OFo),e(Fs,VFo),e(Fs,bj),e(bj,XFo),e(Fs,zFo),e(Fs,vj),e(vj,QFo),e(Fs,WFo),e(k,UFo),e(k,Ts),e(Ts,hue),e(hue,HFo),e(Ts,JFo),e(Ts,Fj),e(Fj,YFo),e(Ts,ZFo),e(Ts,Tj),e(Tj,KFo),e(Ts,eTo),e(k,oTo),e(k,Su),e(Su,uue),e(uue,rTo),e(Su,tTo),e(Su,Mj),e(Mj,aTo),e(Su,nTo),e(k,sTo),e(k,Ru),e(Ru,pue),e(pue,lTo),e(Ru,iTo),e(Ru,Ej),e(Ej,dTo),e(Ru,mTo),e(k,cTo),e(k,Pu),e(Pu,_ue),e(_ue,fTo),e(Pu,gTo),e(Pu,Cj),e(Cj,hTo),e(Pu,uTo),e(k,pTo),e(k,Ms),e(Ms,bue),e(bue,_To),e(Ms,bTo),e(Ms,wj),e(wj,vTo),e(Ms,FTo),e(Ms,Aj),e(Aj,TTo),e(Ms,MTo),e(k,ETo),e(k,Bu),e(Bu,vue),e(vue,CTo),e(Bu,wTo),e(Bu,Lj),e(Lj,ATo),e(Bu,LTo),e(k,yTo),e(k,Es),e(Es,Fue),e(Fue,xTo),e(Es,$To),e(Es,yj),e(yj,kTo),e(Es,STo),e(Es,xj),e(xj,RTo),e(Es,PTo),e(k,BTo),e(k,Cs),e(Cs,Tue),e(Tue,ITo),e(Cs,NTo),e(Cs,$j),e($j,qTo),e(Cs,DTo),e(Cs,kj),e(kj,jTo),e(Cs,GTo),e(k,OTo),e(k,ws),e(ws,Mue),e(Mue,VTo),e(ws,XTo),e(ws,Sj),e(Sj,zTo),e(ws,QTo),e(ws,Rj),e(Rj,WTo),e(ws,UTo),e(k,HTo),e(k,As),e(As,Eue),e(Eue,JTo),e(As,YTo),e(As,Pj),e(Pj,ZTo),e(As,KTo),e(As,Bj),e(Bj,eMo),e(As,oMo),e(k,rMo),e(k,Iu),e(Iu,Cue),e(Cue,tMo),e(Iu,aMo),e(Iu,Ij),e(Ij,nMo),e(Iu,sMo),e(k,lMo),e(k,Ls),e(Ls,wue),e(wue,iMo),e(Ls,dMo),e(Ls,Nj),e(Nj,mMo),e(Ls,cMo),e(Ls,qj),e(qj,fMo),e(Ls,gMo),e(k,hMo),e(k,ys),e(ys,Aue),e(Aue,uMo),e(ys,pMo),e(ys,Dj),e(Dj,_Mo),e(ys,bMo),e(ys,jj),e(jj,vMo),e(ys,FMo),e(k,TMo),e(k,xs),e(xs,Lue),e(Lue,MMo),e(xs,EMo),e(xs,Gj),e(Gj,CMo),e(xs,wMo),e(xs,Oj),e(Oj,AMo),e(xs,LMo),e(k,yMo),e(k,$s),e($s,yue),e(yue,xMo),e($s,$Mo),e($s,Vj),e(Vj,kMo),e($s,SMo),e($s,Xj),e(Xj,RMo),e($s,PMo),e(k,BMo),e(k,ks),e(ks,xue),e(xue,IMo),e(ks,NMo),e(ks,zj),e(zj,qMo),e(ks,DMo),e(ks,Qj),e(Qj,jMo),e(ks,GMo),e(k,OMo),e(k,Ss),e(Ss,$ue),e($ue,VMo),e(Ss,XMo),e(Ss,Wj),e(Wj,zMo),e(Ss,QMo),e(Ss,Uj),e(Uj,WMo),e(Ss,UMo),e(k,HMo),e(k,Rs),e(Rs,kue),e(kue,JMo),e(Rs,YMo),e(Rs,Hj),e(Hj,ZMo),e(Rs,KMo),e(Rs,Jj),e(Jj,eEo),e(Rs,oEo),e(k,rEo),e(k,Nu),e(Nu,Sue),e(Sue,tEo),e(Nu,aEo),e(Nu,Yj),e(Yj,nEo),e(Nu,sEo),e(k,lEo),e(k,qu),e(qu,Rue),e(Rue,iEo),e(qu,dEo),e(qu,Zj),e(Zj,mEo),e(qu,cEo),e(k,fEo),e(k,Ps),e(Ps,Pue),e(Pue,gEo),e(Ps,hEo),e(Ps,Kj),e(Kj,uEo),e(Ps,pEo),e(Ps,eG),e(eG,_Eo),e(Ps,bEo),e(k,vEo),e(k,Du),e(Du,Bue),e(Bue,FEo),e(Du,TEo),e(Du,oG),e(oG,MEo),e(Du,EEo),e(k,CEo),e(k,Bs),e(Bs,Iue),e(Iue,wEo),e(Bs,AEo),e(Bs,rG),e(rG,LEo),e(Bs,yEo),e(Bs,tG),e(tG,xEo),e(Bs,$Eo),e(k,kEo),e(k,Is),e(Is,Nue),e(Nue,SEo),e(Is,REo),e(Is,aG),e(aG,PEo),e(Is,BEo),e(Is,nG),e(nG,IEo),e(Is,NEo),e(k,qEo),e(k,Ns),e(Ns,que),e(que,DEo),e(Ns,jEo),e(Ns,sG),e(sG,GEo),e(Ns,OEo),e(Ns,lG),e(lG,VEo),e(Ns,XEo),e(k,zEo),e(k,ju),e(ju,Due),e(Due,QEo),e(ju,WEo),e(ju,iG),e(iG,UEo),e(ju,HEo),e(k,JEo),e(k,Gu),e(Gu,jue),e(jue,YEo),e(Gu,ZEo),e(Gu,dG),e(dG,KEo),e(Gu,e4o),e(k,o4o),e(k,qs),e(qs,Gue),e(Gue,r4o),e(qs,t4o),e(qs,mG),e(mG,a4o),e(qs,n4o),e(qs,cG),e(cG,s4o),e(qs,l4o),e(k,i4o),e(k,Ds),e(Ds,Oue),e(Oue,d4o),e(Ds,m4o),e(Ds,fG),e(fG,c4o),e(Ds,f4o),e(Ds,gG),e(gG,g4o),e(Ds,h4o),e(k,u4o),e(k,js),e(js,Vue),e(Vue,p4o),e(js,_4o),e(js,hG),e(hG,b4o),e(js,v4o),e(js,uG),e(uG,F4o),e(js,T4o),e(k,M4o),e(k,Ou),e(Ou,Xue),e(Xue,E4o),e(Ou,C4o),e(Ou,pG),e(pG,w4o),e(Ou,A4o),e(k,L4o),e(k,Gs),e(Gs,zue),e(zue,y4o),e(Gs,x4o),e(Gs,_G),e(_G,$4o),e(Gs,k4o),e(Gs,bG),e(bG,S4o),e(Gs,R4o),e(k,P4o),e(k,Os),e(Os,Que),e(Que,B4o),e(Os,I4o),e(Os,vG),e(vG,N4o),e(Os,q4o),e(Os,FG),e(FG,D4o),e(Os,j4o),e(k,G4o),e(k,Vs),e(Vs,Wue),e(Wue,O4o),e(Vs,V4o),e(Vs,TG),e(TG,X4o),e(Vs,z4o),e(Vs,MG),e(MG,Q4o),e(Vs,W4o),e(k,U4o),e(k,Xs),e(Xs,Uue),e(Uue,H4o),e(Xs,J4o),e(Xs,EG),e(EG,Y4o),e(Xs,Z4o),e(Xs,CG),e(CG,K4o),e(Xs,eCo),e(k,oCo),e(k,zs),e(zs,Hue),e(Hue,rCo),e(zs,tCo),e(zs,wG),e(wG,aCo),e(zs,nCo),e(zs,AG),e(AG,sCo),e(zs,lCo),e(k,iCo),e(k,Qs),e(Qs,Jue),e(Jue,dCo),e(Qs,mCo),e(Qs,LG),e(LG,cCo),e(Qs,fCo),e(Qs,yG),e(yG,gCo),e(Qs,hCo),e(k,uCo),e(k,Ws),e(Ws,Yue),e(Yue,pCo),e(Ws,_Co),e(Ws,xG),e(xG,bCo),e(Ws,vCo),e(Ws,$G),e($G,FCo),e(Ws,TCo),e(k,MCo),e(k,Us),e(Us,Zue),e(Zue,ECo),e(Us,CCo),e(Us,kG),e(kG,wCo),e(Us,ACo),e(Us,SG),e(SG,LCo),e(Us,yCo),e(k,xCo),e(k,Hs),e(Hs,Kue),e(Kue,$Co),e(Hs,kCo),e(Hs,RG),e(RG,SCo),e(Hs,RCo),e(Hs,PG),e(PG,PCo),e(Hs,BCo),e(k,ICo),e(k,Vu),e(Vu,epe),e(epe,NCo),e(Vu,qCo),e(Vu,BG),e(BG,DCo),e(Vu,jCo),e(k,GCo),e(k,Js),e(Js,ope),e(ope,OCo),e(Js,VCo),e(Js,IG),e(IG,XCo),e(Js,zCo),e(Js,NG),e(NG,QCo),e(Js,WCo),e(k,UCo),e(k,Xu),e(Xu,rpe),e(rpe,HCo),e(Xu,JCo),e(Xu,qG),e(qG,YCo),e(Xu,ZCo),e(k,KCo),e(k,zu),e(zu,tpe),e(tpe,e3o),e(zu,o3o),e(zu,DG),e(DG,r3o),e(zu,t3o),e(k,a3o),e(k,Ys),e(Ys,ape),e(ape,n3o),e(Ys,s3o),e(Ys,jG),e(jG,l3o),e(Ys,i3o),e(Ys,GG),e(GG,d3o),e(Ys,m3o),e(k,c3o),e(k,Zs),e(Zs,npe),e(npe,f3o),e(Zs,g3o),e(Zs,OG),e(OG,h3o),e(Zs,u3o),e(Zs,VG),e(VG,p3o),e(Zs,_3o),e(k,b3o),e(k,Ks),e(Ks,spe),e(spe,v3o),e(Ks,F3o),e(Ks,XG),e(XG,T3o),e(Ks,M3o),e(Ks,zG),e(zG,E3o),e(Ks,C3o),e(k,w3o),e(k,Qu),e(Qu,lpe),e(lpe,A3o),e(Qu,L3o),e(Qu,QG),e(QG,y3o),e(Qu,x3o),e(k,$3o),e(k,el),e(el,ipe),e(ipe,k3o),e(el,S3o),e(el,WG),e(WG,R3o),e(el,P3o),e(el,UG),e(UG,B3o),e(el,I3o),e(k,N3o),e(k,ol),e(ol,dpe),e(dpe,q3o),e(ol,D3o),e(ol,HG),e(HG,j3o),e(ol,G3o),e(ol,JG),e(JG,O3o),e(ol,V3o),e(k,X3o),e(k,rl),e(rl,mpe),e(mpe,z3o),e(rl,Q3o),e(rl,YG),e(YG,W3o),e(rl,U3o),e(rl,ZG),e(ZG,H3o),e(rl,J3o),e(k,Y3o),e(k,tl),e(tl,cpe),e(cpe,Z3o),e(tl,K3o),e(tl,KG),e(KG,e5o),e(tl,o5o),e(tl,eO),e(eO,r5o),e(tl,t5o),e(k,a5o),e(k,al),e(al,fpe),e(fpe,n5o),e(al,s5o),e(al,oO),e(oO,l5o),e(al,i5o),e(al,rO),e(rO,d5o),e(al,m5o),e(k,c5o),e(k,nl),e(nl,gpe),e(gpe,f5o),e(nl,g5o),e(nl,tO),e(tO,h5o),e(nl,u5o),e(nl,aO),e(aO,p5o),e(nl,_5o),e(k,b5o),e(k,sl),e(sl,hpe),e(hpe,v5o),e(sl,F5o),e(sl,nO),e(nO,T5o),e(sl,M5o),e(sl,sO),e(sO,E5o),e(sl,C5o),e(k,w5o),e(k,ll),e(ll,upe),e(upe,A5o),e(ll,L5o),e(ll,lO),e(lO,y5o),e(ll,x5o),e(ll,iO),e(iO,$5o),e(ll,k5o),e(k,S5o),e(k,Wu),e(Wu,ppe),e(ppe,R5o),e(Wu,P5o),e(Wu,dO),e(dO,B5o),e(Wu,I5o),e(k,N5o),e(k,il),e(il,_pe),e(_pe,q5o),e(il,D5o),e(il,mO),e(mO,j5o),e(il,G5o),e(il,cO),e(cO,O5o),e(il,V5o),e(k,X5o),e(k,dl),e(dl,bpe),e(bpe,z5o),e(dl,Q5o),e(dl,fO),e(fO,W5o),e(dl,U5o),e(dl,gO),e(gO,H5o),e(dl,J5o),e(k,Y5o),e(k,ml),e(ml,vpe),e(vpe,Z5o),e(ml,K5o),e(ml,hO),e(hO,e0o),e(ml,o0o),e(ml,uO),e(uO,r0o),e(ml,t0o),e(k,a0o),e(k,Uu),e(Uu,Fpe),e(Fpe,n0o),e(Uu,s0o),e(Uu,pO),e(pO,l0o),e(Uu,i0o),e(k,d0o),e(k,Hu),e(Hu,Tpe),e(Tpe,m0o),e(Hu,c0o),e(Hu,_O),e(_O,f0o),e(Hu,g0o),e(k,h0o),e(k,Ju),e(Ju,Mpe),e(Mpe,u0o),e(Ju,p0o),e(Ju,bO),e(bO,_0o),e(Ju,b0o),e(k,v0o),e(k,Yu),e(Yu,Epe),e(Epe,F0o),e(Yu,T0o),e(Yu,vO),e(vO,M0o),e(Yu,E0o),e(k,C0o),e(k,cl),e(cl,Cpe),e(Cpe,w0o),e(cl,A0o),e(cl,FO),e(FO,L0o),e(cl,y0o),e(cl,TO),e(TO,x0o),e(cl,$0o),e(k,k0o),e(k,Zu),e(Zu,wpe),e(wpe,S0o),e(Zu,R0o),e(Zu,MO),e(MO,P0o),e(Zu,B0o),e(k,I0o),e(k,fl),e(fl,Ape),e(Ape,N0o),e(fl,q0o),e(fl,EO),e(EO,D0o),e(fl,j0o),e(fl,CO),e(CO,G0o),e(fl,O0o),e(k,V0o),e(k,gl),e(gl,Lpe),e(Lpe,X0o),e(gl,z0o),e(gl,wO),e(wO,Q0o),e(gl,W0o),e(gl,AO),e(AO,U0o),e(gl,H0o),e(k,J0o),e(k,hl),e(hl,ype),e(ype,Y0o),e(hl,Z0o),e(hl,LO),e(LO,K0o),e(hl,ewo),e(hl,yO),e(yO,owo),e(hl,rwo),e(k,two),e(k,ul),e(ul,xpe),e(xpe,awo),e(ul,nwo),e(ul,xO),e(xO,swo),e(ul,lwo),e(ul,$O),e($O,iwo),e(ul,dwo),e(k,mwo),e(k,pl),e(pl,$pe),e($pe,cwo),e(pl,fwo),e(pl,kO),e(kO,gwo),e(pl,hwo),e(pl,SO),e(SO,uwo),e(pl,pwo),e(k,_wo),e(k,_l),e(_l,kpe),e(kpe,bwo),e(_l,vwo),e(_l,RO),e(RO,Fwo),e(_l,Two),e(_l,PO),e(PO,Mwo),e(_l,Ewo),e(k,Cwo),e(k,Ku),e(Ku,Spe),e(Spe,wwo),e(Ku,Awo),e(Ku,BO),e(BO,Lwo),e(Ku,ywo),e(k,xwo),e(k,ep),e(ep,Rpe),e(Rpe,$wo),e(ep,kwo),e(ep,IO),e(IO,Swo),e(ep,Rwo),e(k,Pwo),e(k,bl),e(bl,Ppe),e(Ppe,Bwo),e(bl,Iwo),e(bl,NO),e(NO,Nwo),e(bl,qwo),e(bl,qO),e(qO,Dwo),e(bl,jwo),e(k,Gwo),e(k,vl),e(vl,Bpe),e(Bpe,Owo),e(vl,Vwo),e(vl,DO),e(DO,Xwo),e(vl,zwo),e(vl,jO),e(jO,Qwo),e(vl,Wwo),e(k,Uwo),e(k,Fl),e(Fl,Ipe),e(Ipe,Hwo),e(Fl,Jwo),e(Fl,GO),e(GO,Ywo),e(Fl,Zwo),e(Fl,OO),e(OO,Kwo),e(Fl,eAo),e(k,oAo),e(k,op),e(op,Npe),e(Npe,rAo),e(op,tAo),e(op,VO),e(VO,aAo),e(op,nAo),e(k,sAo),e(k,rp),e(rp,qpe),e(qpe,lAo),e(rp,iAo),e(rp,XO),e(XO,dAo),e(rp,mAo),e(k,cAo),e(k,tp),e(tp,Dpe),e(Dpe,fAo),e(tp,gAo),e(tp,zO),e(zO,hAo),e(tp,uAo),e(k,pAo),e(k,Tl),e(Tl,jpe),e(jpe,_Ao),e(Tl,bAo),e(Tl,QO),e(QO,vAo),e(Tl,FAo),e(Tl,WO),e(WO,TAo),e(Tl,MAo),e(k,EAo),e(k,Ml),e(Ml,Gpe),e(Gpe,CAo),e(Ml,wAo),e(Ml,UO),e(UO,AAo),e(Ml,LAo),e(Ml,HO),e(HO,yAo),e(Ml,xAo),e(k,$Ao),e(k,ap),e(ap,Ope),e(Ope,kAo),e(ap,SAo),e(ap,JO),e(JO,RAo),e(ap,PAo),e(k,BAo),e(k,np),e(np,Vpe),e(Vpe,IAo),e(np,NAo),e(np,YO),e(YO,qAo),e(np,DAo),e(k,jAo),e(k,sp),e(sp,Xpe),e(Xpe,GAo),e(sp,OAo),e(sp,ZO),e(ZO,VAo),e(sp,XAo),e(k,zAo),e(k,lp),e(lp,zpe),e(zpe,QAo),e(lp,WAo),e(lp,KO),e(KO,UAo),e(lp,HAo),e(k,JAo),e(k,El),e(El,Qpe),e(Qpe,YAo),e(El,ZAo),e(El,eV),e(eV,KAo),e(El,e6o),e(El,oV),e(oV,o6o),e(El,r6o),e(k,t6o),e(k,Cl),e(Cl,Wpe),e(Wpe,a6o),e(Cl,n6o),e(Cl,rV),e(rV,s6o),e(Cl,l6o),e(Cl,tV),e(tV,i6o),e(Cl,d6o),e(k,m6o),e(k,ip),e(ip,Upe),e(Upe,c6o),e(ip,f6o),e(ip,aV),e(aV,g6o),e(ip,h6o),e(k,u6o),e(k,dp),e(dp,Hpe),e(Hpe,p6o),e(dp,_6o),e(dp,nV),e(nV,b6o),e(dp,v6o),e(k,F6o),e(k,wl),e(wl,Jpe),e(Jpe,T6o),e(wl,M6o),e(wl,sV),e(sV,E6o),e(wl,C6o),e(wl,lV),e(lV,w6o),e(wl,A6o),e(k,L6o),e(k,Al),e(Al,Ype),e(Ype,y6o),e(Al,x6o),e(Al,iV),e(iV,$6o),e(Al,k6o),e(Al,dV),e(dV,S6o),e(Al,R6o),e(k,P6o),e(k,Ll),e(Ll,Zpe),e(Zpe,B6o),e(Ll,I6o),e(Ll,mV),e(mV,N6o),e(Ll,q6o),e(Ll,cV),e(cV,D6o),e(Ll,j6o),e(k,G6o),e(k,yl),e(yl,Kpe),e(Kpe,O6o),e(yl,V6o),e(yl,fV),e(fV,X6o),e(yl,z6o),e(yl,gV),e(gV,Q6o),e(yl,W6o),e(Dr,U6o),M(mp,Dr,null),e(Ro,H6o),e(Ro,cp),M(E$,cp,null),e(cp,J6o),e(cp,e_e),e(e_e,Y6o),b(c,qto,_),b(c,xd,_),e(xd,fp),e(fp,o_e),M(C$,o_e,null),e(xd,Z6o),e(xd,r_e),e(r_e,K6o),b(c,Dto,_),b(c,Po,_),M(w$,Po,null),e(Po,e7o),e(Po,A$),e(A$,o7o),e(A$,hV),e(hV,r7o),e(A$,t7o),e(Po,a7o),e(Po,L$),e(L$,n7o),e(L$,t_e),e(t_e,s7o),e(L$,l7o),e(Po,i7o),e(Po,Ye),M(y$,Ye,null),e(Ye,d7o),e(Ye,a_e),e(a_e,m7o),e(Ye,c7o),e(Ye,an),e(an,f7o),e(an,n_e),e(n_e,g7o),e(an,h7o),e(an,s_e),e(s_e,u7o),e(an,p7o),e(an,l_e),e(l_e,_7o),e(an,b7o),e(Ye,v7o),e(Ye,z),e(z,gp),e(gp,i_e),e(i_e,F7o),e(gp,T7o),e(gp,uV),e(uV,M7o),e(gp,E7o),e(z,C7o),e(z,hp),e(hp,d_e),e(d_e,w7o),e(hp,A7o),e(hp,pV),e(pV,L7o),e(hp,y7o),e(z,x7o),e(z,up),e(up,m_e),e(m_e,$7o),e(up,k7o),e(up,_V),e(_V,S7o),e(up,R7o),e(z,P7o),e(z,pp),e(pp,c_e),e(c_e,B7o),e(pp,I7o),e(pp,bV),e(bV,N7o),e(pp,q7o),e(z,D7o),e(z,_p),e(_p,f_e),e(f_e,j7o),e(_p,G7o),e(_p,vV),e(vV,O7o),e(_p,V7o),e(z,X7o),e(z,bp),e(bp,g_e),e(g_e,z7o),e(bp,Q7o),e(bp,FV),e(FV,W7o),e(bp,U7o),e(z,H7o),e(z,vp),e(vp,h_e),e(h_e,J7o),e(vp,Y7o),e(vp,TV),e(TV,Z7o),e(vp,K7o),e(z,e8o),e(z,Fp),e(Fp,u_e),e(u_e,o8o),e(Fp,r8o),e(Fp,MV),e(MV,t8o),e(Fp,a8o),e(z,n8o),e(z,Tp),e(Tp,p_e),e(p_e,s8o),e(Tp,l8o),e(Tp,EV),e(EV,i8o),e(Tp,d8o),e(z,m8o),e(z,Mp),e(Mp,__e),e(__e,c8o),e(Mp,f8o),e(Mp,CV),e(CV,g8o),e(Mp,h8o),e(z,u8o),e(z,Ep),e(Ep,b_e),e(b_e,p8o),e(Ep,_8o),e(Ep,wV),e(wV,b8o),e(Ep,v8o),e(z,F8o),e(z,Cp),e(Cp,v_e),e(v_e,T8o),e(Cp,M8o),e(Cp,AV),e(AV,E8o),e(Cp,C8o),e(z,w8o),e(z,wp),e(wp,F_e),e(F_e,A8o),e(wp,L8o),e(wp,LV),e(LV,y8o),e(wp,x8o),e(z,$8o),e(z,Ap),e(Ap,T_e),e(T_e,k8o),e(Ap,S8o),e(Ap,yV),e(yV,R8o),e(Ap,P8o),e(z,B8o),e(z,Lp),e(Lp,M_e),e(M_e,I8o),e(Lp,N8o),e(Lp,xV),e(xV,q8o),e(Lp,D8o),e(z,j8o),e(z,yp),e(yp,E_e),e(E_e,G8o),e(yp,O8o),e(yp,$V),e($V,V8o),e(yp,X8o),e(z,z8o),e(z,xp),e(xp,C_e),e(C_e,Q8o),e(xp,W8o),e(xp,kV),e(kV,U8o),e(xp,H8o),e(z,J8o),e(z,$p),e($p,w_e),e(w_e,Y8o),e($p,Z8o),e($p,SV),e(SV,K8o),e($p,eLo),e(z,oLo),e(z,kp),e(kp,A_e),e(A_e,rLo),e(kp,tLo),e(kp,RV),e(RV,aLo),e(kp,nLo),e(z,sLo),e(z,Sp),e(Sp,L_e),e(L_e,lLo),e(Sp,iLo),e(Sp,PV),e(PV,dLo),e(Sp,mLo),e(z,cLo),e(z,Rp),e(Rp,y_e),e(y_e,fLo),e(Rp,gLo),e(Rp,BV),e(BV,hLo),e(Rp,uLo),e(z,pLo),e(z,Pp),e(Pp,x_e),e(x_e,_Lo),e(Pp,bLo),e(Pp,IV),e(IV,vLo),e(Pp,FLo),e(z,TLo),e(z,Bp),e(Bp,$_e),e($_e,MLo),e(Bp,ELo),e(Bp,NV),e(NV,CLo),e(Bp,wLo),e(z,ALo),e(z,Ip),e(Ip,k_e),e(k_e,LLo),e(Ip,yLo),e(Ip,qV),e(qV,xLo),e(Ip,$Lo),e(z,kLo),e(z,Np),e(Np,S_e),e(S_e,SLo),e(Np,RLo),e(Np,DV),e(DV,PLo),e(Np,BLo),e(z,ILo),e(z,qp),e(qp,R_e),e(R_e,NLo),e(qp,qLo),e(qp,jV),e(jV,DLo),e(qp,jLo),e(z,GLo),e(z,Dp),e(Dp,P_e),e(P_e,OLo),e(Dp,VLo),e(Dp,GV),e(GV,XLo),e(Dp,zLo),e(z,QLo),e(z,jp),e(jp,B_e),e(B_e,WLo),e(jp,ULo),e(jp,OV),e(OV,HLo),e(jp,JLo),e(z,YLo),e(z,Gp),e(Gp,I_e),e(I_e,ZLo),e(Gp,KLo),e(Gp,VV),e(VV,eyo),e(Gp,oyo),e(z,ryo),e(z,Op),e(Op,N_e),e(N_e,tyo),e(Op,ayo),e(Op,XV),e(XV,nyo),e(Op,syo),e(z,lyo),e(z,Vp),e(Vp,q_e),e(q_e,iyo),e(Vp,dyo),e(Vp,zV),e(zV,myo),e(Vp,cyo),e(z,fyo),e(z,Xp),e(Xp,D_e),e(D_e,gyo),e(Xp,hyo),e(Xp,QV),e(QV,uyo),e(Xp,pyo),e(z,_yo),e(z,zp),e(zp,j_e),e(j_e,byo),e(zp,vyo),e(zp,WV),e(WV,Fyo),e(zp,Tyo),e(z,Myo),e(z,Qp),e(Qp,G_e),e(G_e,Eyo),e(Qp,Cyo),e(Qp,UV),e(UV,wyo),e(Qp,Ayo),e(z,Lyo),e(z,Wp),e(Wp,O_e),e(O_e,yyo),e(Wp,xyo),e(Wp,HV),e(HV,$yo),e(Wp,kyo),e(z,Syo),e(z,Up),e(Up,V_e),e(V_e,Ryo),e(Up,Pyo),e(Up,JV),e(JV,Byo),e(Up,Iyo),e(z,Nyo),e(z,Hp),e(Hp,X_e),e(X_e,qyo),e(Hp,Dyo),e(Hp,YV),e(YV,jyo),e(Hp,Gyo),e(z,Oyo),e(z,Jp),e(Jp,z_e),e(z_e,Vyo),e(Jp,Xyo),e(Jp,ZV),e(ZV,zyo),e(Jp,Qyo),e(z,Wyo),e(z,Yp),e(Yp,Q_e),e(Q_e,Uyo),e(Yp,Hyo),e(Yp,KV),e(KV,Jyo),e(Yp,Yyo),e(z,Zyo),e(z,Zp),e(Zp,W_e),e(W_e,Kyo),e(Zp,e9o),e(Zp,eX),e(eX,o9o),e(Zp,r9o),e(z,t9o),e(z,Kp),e(Kp,U_e),e(U_e,a9o),e(Kp,n9o),e(Kp,oX),e(oX,s9o),e(Kp,l9o),e(z,i9o),e(z,e_),e(e_,H_e),e(H_e,d9o),e(e_,m9o),e(e_,rX),e(rX,c9o),e(e_,f9o),e(z,g9o),e(z,o_),e(o_,J_e),e(J_e,h9o),e(o_,u9o),e(o_,tX),e(tX,p9o),e(o_,_9o),e(z,b9o),e(z,r_),e(r_,Y_e),e(Y_e,v9o),e(r_,F9o),e(r_,aX),e(aX,T9o),e(r_,M9o),e(Ye,E9o),M(t_,Ye,null),e(Ye,C9o),M(a_,Ye,null),e(Po,w9o),e(Po,n_),M(x$,n_,null),e(n_,A9o),e(n_,Z_e),e(Z_e,L9o),b(c,jto,_),b(c,$d,_),e($d,s_),e(s_,K_e),M($$,K_e,null),e($d,y9o),e($d,e1e),e(e1e,x9o),b(c,Gto,_),b(c,Bo,_),M(k$,Bo,null),e(Bo,$9o),e(Bo,S$),e(S$,k9o),e(S$,nX),e(nX,S9o),e(S$,R9o),e(Bo,P9o),e(Bo,R$),e(R$,B9o),e(R$,o1e),e(o1e,I9o),e(R$,N9o),e(Bo,q9o),e(Bo,Ze),M(P$,Ze,null),e(Ze,D9o),e(Ze,r1e),e(r1e,j9o),e(Ze,G9o),e(Ze,kd),e(kd,O9o),e(kd,t1e),e(t1e,V9o),e(kd,X9o),e(kd,a1e),e(a1e,z9o),e(kd,Q9o),e(Ze,W9o),e(Ze,se),e(se,l_),e(l_,n1e),e(n1e,U9o),e(l_,H9o),e(l_,sX),e(sX,J9o),e(l_,Y9o),e(se,Z9o),e(se,i_),e(i_,s1e),e(s1e,K9o),e(i_,exo),e(i_,lX),e(lX,oxo),e(i_,rxo),e(se,txo),e(se,d_),e(d_,l1e),e(l1e,axo),e(d_,nxo),e(d_,iX),e(iX,sxo),e(d_,lxo),e(se,ixo),e(se,m_),e(m_,i1e),e(i1e,dxo),e(m_,mxo),e(m_,dX),e(dX,cxo),e(m_,fxo),e(se,gxo),e(se,c_),e(c_,d1e),e(d1e,hxo),e(c_,uxo),e(c_,mX),e(mX,pxo),e(c_,_xo),e(se,bxo),e(se,f_),e(f_,m1e),e(m1e,vxo),e(f_,Fxo),e(f_,cX),e(cX,Txo),e(f_,Mxo),e(se,Exo),e(se,g_),e(g_,c1e),e(c1e,Cxo),e(g_,wxo),e(g_,fX),e(fX,Axo),e(g_,Lxo),e(se,yxo),e(se,h_),e(h_,f1e),e(f1e,xxo),e(h_,$xo),e(h_,gX),e(gX,kxo),e(h_,Sxo),e(se,Rxo),e(se,u_),e(u_,g1e),e(g1e,Pxo),e(u_,Bxo),e(u_,hX),e(hX,Ixo),e(u_,Nxo),e(se,qxo),e(se,p_),e(p_,h1e),e(h1e,Dxo),e(p_,jxo),e(p_,uX),e(uX,Gxo),e(p_,Oxo),e(se,Vxo),e(se,__),e(__,u1e),e(u1e,Xxo),e(__,zxo),e(__,pX),e(pX,Qxo),e(__,Wxo),e(se,Uxo),e(se,b_),e(b_,p1e),e(p1e,Hxo),e(b_,Jxo),e(b_,_X),e(_X,Yxo),e(b_,Zxo),e(se,Kxo),e(se,v_),e(v_,_1e),e(_1e,e$o),e(v_,o$o),e(v_,bX),e(bX,r$o),e(v_,t$o),e(se,a$o),e(se,F_),e(F_,b1e),e(b1e,n$o),e(F_,s$o),e(F_,vX),e(vX,l$o),e(F_,i$o),e(se,d$o),e(se,T_),e(T_,v1e),e(v1e,m$o),e(T_,c$o),e(T_,FX),e(FX,f$o),e(T_,g$o),e(se,h$o),e(se,M_),e(M_,F1e),e(F1e,u$o),e(M_,p$o),e(M_,TX),e(TX,_$o),e(M_,b$o),e(se,v$o),e(se,E_),e(E_,T1e),e(T1e,F$o),e(E_,T$o),e(E_,MX),e(MX,M$o),e(E_,E$o),e(se,C$o),e(se,C_),e(C_,M1e),e(M1e,w$o),e(C_,A$o),e(C_,EX),e(EX,L$o),e(C_,y$o),e(se,x$o),e(se,w_),e(w_,E1e),e(E1e,$$o),e(w_,k$o),e(w_,CX),e(CX,S$o),e(w_,R$o),e(se,P$o),e(se,A_),e(A_,C1e),e(C1e,B$o),e(A_,I$o),e(A_,wX),e(wX,N$o),e(A_,q$o),e(se,D$o),e(se,L_),e(L_,w1e),e(w1e,j$o),e(L_,G$o),e(L_,AX),e(AX,O$o),e(L_,V$o),e(se,X$o),e(se,y_),e(y_,A1e),e(A1e,z$o),e(y_,Q$o),e(y_,LX),e(LX,W$o),e(y_,U$o),e(se,H$o),e(se,x_),e(x_,L1e),e(L1e,J$o),e(x_,Y$o),e(x_,yX),e(yX,Z$o),e(x_,K$o),e(Ze,eko),M($_,Ze,null),e(Ze,oko),M(k_,Ze,null),e(Bo,rko),e(Bo,S_),M(B$,S_,null),e(S_,tko),e(S_,y1e),e(y1e,ako),b(c,Oto,_),b(c,Sd,_),e(Sd,R_),e(R_,x1e),M(I$,x1e,null),e(Sd,nko),e(Sd,$1e),e($1e,sko),b(c,Vto,_),b(c,Io,_),M(N$,Io,null),e(Io,lko),e(Io,Rd),e(Rd,iko),e(Rd,xX),e(xX,dko),e(Rd,mko),e(Rd,$X),e($X,cko),e(Rd,fko),e(Io,gko),e(Io,q$),e(q$,hko),e(q$,k1e),e(k1e,uko),e(q$,pko),e(Io,_ko),e(Io,Mt),M(D$,Mt,null),e(Mt,bko),e(Mt,S1e),e(S1e,vko),e(Mt,Fko),e(Mt,Pd),e(Pd,Tko),e(Pd,R1e),e(R1e,Mko),e(Pd,Eko),e(Pd,kX),e(kX,Cko),e(Pd,wko),e(Mt,Ako),M(P_,Mt,null),e(Io,Lko),e(Io,Ke),M(j$,Ke,null),e(Ke,yko),e(Ke,P1e),e(P1e,xko),e(Ke,$ko),e(Ke,nn),e(nn,kko),e(nn,B1e),e(B1e,Sko),e(nn,Rko),e(nn,I1e),e(I1e,Pko),e(nn,Bko),e(nn,N1e),e(N1e,Iko),e(nn,Nko),e(Ke,qko),e(Ke,y),e(y,B_),e(B_,q1e),e(q1e,Dko),e(B_,jko),e(B_,SX),e(SX,Gko),e(B_,Oko),e(y,Vko),e(y,I_),e(I_,D1e),e(D1e,Xko),e(I_,zko),e(I_,RX),e(RX,Qko),e(I_,Wko),e(y,Uko),e(y,N_),e(N_,j1e),e(j1e,Hko),e(N_,Jko),e(N_,PX),e(PX,Yko),e(N_,Zko),e(y,Kko),e(y,q_),e(q_,G1e),e(G1e,eSo),e(q_,oSo),e(q_,BX),e(BX,rSo),e(q_,tSo),e(y,aSo),e(y,D_),e(D_,O1e),e(O1e,nSo),e(D_,sSo),e(D_,IX),e(IX,lSo),e(D_,iSo),e(y,dSo),e(y,j_),e(j_,V1e),e(V1e,mSo),e(j_,cSo),e(j_,NX),e(NX,fSo),e(j_,gSo),e(y,hSo),e(y,G_),e(G_,X1e),e(X1e,uSo),e(G_,pSo),e(G_,qX),e(qX,_So),e(G_,bSo),e(y,vSo),e(y,O_),e(O_,z1e),e(z1e,FSo),e(O_,TSo),e(O_,DX),e(DX,MSo),e(O_,ESo),e(y,CSo),e(y,V_),e(V_,Q1e),e(Q1e,wSo),e(V_,ASo),e(V_,jX),e(jX,LSo),e(V_,ySo),e(y,xSo),e(y,X_),e(X_,W1e),e(W1e,$So),e(X_,kSo),e(X_,GX),e(GX,SSo),e(X_,RSo),e(y,PSo),e(y,z_),e(z_,U1e),e(U1e,BSo),e(z_,ISo),e(z_,OX),e(OX,NSo),e(z_,qSo),e(y,DSo),e(y,Q_),e(Q_,H1e),e(H1e,jSo),e(Q_,GSo),e(Q_,VX),e(VX,OSo),e(Q_,VSo),e(y,XSo),e(y,W_),e(W_,J1e),e(J1e,zSo),e(W_,QSo),e(W_,XX),e(XX,WSo),e(W_,USo),e(y,HSo),e(y,U_),e(U_,Y1e),e(Y1e,JSo),e(U_,YSo),e(U_,zX),e(zX,ZSo),e(U_,KSo),e(y,eRo),e(y,H_),e(H_,Z1e),e(Z1e,oRo),e(H_,rRo),e(H_,QX),e(QX,tRo),e(H_,aRo),e(y,nRo),e(y,J_),e(J_,K1e),e(K1e,sRo),e(J_,lRo),e(J_,WX),e(WX,iRo),e(J_,dRo),e(y,mRo),e(y,Y_),e(Y_,e2e),e(e2e,cRo),e(Y_,fRo),e(Y_,UX),e(UX,gRo),e(Y_,hRo),e(y,uRo),e(y,Z_),e(Z_,o2e),e(o2e,pRo),e(Z_,_Ro),e(Z_,HX),e(HX,bRo),e(Z_,vRo),e(y,FRo),e(y,K_),e(K_,r2e),e(r2e,TRo),e(K_,MRo),e(K_,JX),e(JX,ERo),e(K_,CRo),e(y,wRo),e(y,e1),e(e1,t2e),e(t2e,ARo),e(e1,LRo),e(e1,YX),e(YX,yRo),e(e1,xRo),e(y,$Ro),e(y,o1),e(o1,a2e),e(a2e,kRo),e(o1,SRo),e(o1,ZX),e(ZX,RRo),e(o1,PRo),e(y,BRo),e(y,r1),e(r1,n2e),e(n2e,IRo),e(r1,NRo),e(r1,KX),e(KX,qRo),e(r1,DRo),e(y,jRo),e(y,t1),e(t1,s2e),e(s2e,GRo),e(t1,ORo),e(t1,ez),e(ez,VRo),e(t1,XRo),e(y,zRo),e(y,a1),e(a1,l2e),e(l2e,QRo),e(a1,WRo),e(a1,oz),e(oz,URo),e(a1,HRo),e(y,JRo),e(y,n1),e(n1,i2e),e(i2e,YRo),e(n1,ZRo),e(n1,rz),e(rz,KRo),e(n1,ePo),e(y,oPo),e(y,s1),e(s1,d2e),e(d2e,rPo),e(s1,tPo),e(s1,tz),e(tz,aPo),e(s1,nPo),e(y,sPo),e(y,l1),e(l1,m2e),e(m2e,lPo),e(l1,iPo),e(l1,az),e(az,dPo),e(l1,mPo),e(y,cPo),e(y,i1),e(i1,c2e),e(c2e,fPo),e(i1,gPo),e(i1,nz),e(nz,hPo),e(i1,uPo),e(y,pPo),e(y,d1),e(d1,f2e),e(f2e,_Po),e(d1,bPo),e(d1,sz),e(sz,vPo),e(d1,FPo),e(y,TPo),e(y,m1),e(m1,g2e),e(g2e,MPo),e(m1,EPo),e(m1,lz),e(lz,CPo),e(m1,wPo),e(y,APo),e(y,c1),e(c1,h2e),e(h2e,LPo),e(c1,yPo),e(c1,iz),e(iz,xPo),e(c1,$Po),e(y,kPo),e(y,f1),e(f1,u2e),e(u2e,SPo),e(f1,RPo),e(f1,dz),e(dz,PPo),e(f1,BPo),e(y,IPo),e(y,g1),e(g1,p2e),e(p2e,NPo),e(g1,qPo),e(g1,mz),e(mz,DPo),e(g1,jPo),e(y,GPo),e(y,h1),e(h1,_2e),e(_2e,OPo),e(h1,VPo),e(h1,cz),e(cz,XPo),e(h1,zPo),e(y,QPo),e(y,u1),e(u1,b2e),e(b2e,WPo),e(u1,UPo),e(u1,fz),e(fz,HPo),e(u1,JPo),e(y,YPo),e(y,p1),e(p1,v2e),e(v2e,ZPo),e(p1,KPo),e(p1,gz),e(gz,eBo),e(p1,oBo),e(y,rBo),e(y,_1),e(_1,F2e),e(F2e,tBo),e(_1,aBo),e(_1,hz),e(hz,nBo),e(_1,sBo),e(y,lBo),e(y,b1),e(b1,T2e),e(T2e,iBo),e(b1,dBo),e(b1,uz),e(uz,mBo),e(b1,cBo),e(y,fBo),e(y,v1),e(v1,M2e),e(M2e,gBo),e(v1,hBo),e(v1,pz),e(pz,uBo),e(v1,pBo),e(y,_Bo),e(y,xl),e(xl,E2e),e(E2e,bBo),e(xl,vBo),e(xl,_z),e(_z,FBo),e(xl,TBo),e(xl,bz),e(bz,MBo),e(xl,EBo),e(y,CBo),e(y,F1),e(F1,C2e),e(C2e,wBo),e(F1,ABo),e(F1,vz),e(vz,LBo),e(F1,yBo),e(y,xBo),e(y,T1),e(T1,w2e),e(w2e,$Bo),e(T1,kBo),e(T1,Fz),e(Fz,SBo),e(T1,RBo),e(y,PBo),e(y,M1),e(M1,A2e),e(A2e,BBo),e(M1,IBo),e(M1,Tz),e(Tz,NBo),e(M1,qBo),e(y,DBo),e(y,E1),e(E1,L2e),e(L2e,jBo),e(E1,GBo),e(E1,Mz),e(Mz,OBo),e(E1,VBo),e(y,XBo),e(y,C1),e(C1,y2e),e(y2e,zBo),e(C1,QBo),e(C1,Ez),e(Ez,WBo),e(C1,UBo),e(y,HBo),e(y,w1),e(w1,x2e),e(x2e,JBo),e(w1,YBo),e(w1,Cz),e(Cz,ZBo),e(w1,KBo),e(y,eIo),e(y,A1),e(A1,$2e),e($2e,oIo),e(A1,rIo),e(A1,wz),e(wz,tIo),e(A1,aIo),e(y,nIo),e(y,L1),e(L1,k2e),e(k2e,sIo),e(L1,lIo),e(L1,Az),e(Az,iIo),e(L1,dIo),e(y,mIo),e(y,y1),e(y1,S2e),e(S2e,cIo),e(y1,fIo),e(y1,Lz),e(Lz,gIo),e(y1,hIo),e(y,uIo),e(y,x1),e(x1,R2e),e(R2e,pIo),e(x1,_Io),e(x1,yz),e(yz,bIo),e(x1,vIo),e(y,FIo),e(y,$1),e($1,P2e),e(P2e,TIo),e($1,MIo),e($1,xz),e(xz,EIo),e($1,CIo),e(y,wIo),e(y,k1),e(k1,B2e),e(B2e,AIo),e(k1,LIo),e(k1,$z),e($z,yIo),e(k1,xIo),e(y,$Io),e(y,S1),e(S1,I2e),e(I2e,kIo),e(S1,SIo),e(S1,kz),e(kz,RIo),e(S1,PIo),e(y,BIo),e(y,R1),e(R1,N2e),e(N2e,IIo),e(R1,NIo),e(R1,Sz),e(Sz,qIo),e(R1,DIo),e(y,jIo),e(y,P1),e(P1,q2e),e(q2e,GIo),e(P1,OIo),e(P1,Rz),e(Rz,VIo),e(P1,XIo),e(y,zIo),e(y,B1),e(B1,D2e),e(D2e,QIo),e(B1,WIo),e(B1,Pz),e(Pz,UIo),e(B1,HIo),e(y,JIo),e(y,I1),e(I1,j2e),e(j2e,YIo),e(I1,ZIo),e(I1,Bz),e(Bz,KIo),e(I1,eNo),e(y,oNo),e(y,N1),e(N1,G2e),e(G2e,rNo),e(N1,tNo),e(N1,Iz),e(Iz,aNo),e(N1,nNo),e(y,sNo),e(y,q1),e(q1,O2e),e(O2e,lNo),e(q1,iNo),e(q1,Nz),e(Nz,dNo),e(q1,mNo),e(y,cNo),e(y,D1),e(D1,V2e),e(V2e,fNo),e(D1,gNo),e(D1,qz),e(qz,hNo),e(D1,uNo),e(y,pNo),e(y,j1),e(j1,X2e),e(X2e,_No),e(j1,bNo),e(j1,Dz),e(Dz,vNo),e(j1,FNo),e(y,TNo),e(y,G1),e(G1,z2e),e(z2e,MNo),e(G1,ENo),e(G1,jz),e(jz,CNo),e(G1,wNo),e(y,ANo),e(y,O1),e(O1,Q2e),e(Q2e,LNo),e(O1,yNo),e(O1,Gz),e(Gz,xNo),e(O1,$No),e(y,kNo),e(y,V1),e(V1,W2e),e(W2e,SNo),e(V1,RNo),e(V1,Oz),e(Oz,PNo),e(V1,BNo),e(y,INo),e(y,X1),e(X1,U2e),e(U2e,NNo),e(X1,qNo),e(X1,Vz),e(Vz,DNo),e(X1,jNo),e(y,GNo),e(y,z1),e(z1,H2e),e(H2e,ONo),e(z1,VNo),e(z1,Xz),e(Xz,XNo),e(z1,zNo),e(y,QNo),e(y,Q1),e(Q1,J2e),e(J2e,WNo),e(Q1,UNo),e(Q1,zz),e(zz,HNo),e(Q1,JNo),e(y,YNo),e(y,W1),e(W1,Y2e),e(Y2e,ZNo),e(W1,KNo),e(W1,Qz),e(Qz,eqo),e(W1,oqo),e(y,rqo),e(y,U1),e(U1,Z2e),e(Z2e,tqo),e(U1,aqo),e(U1,Wz),e(Wz,nqo),e(U1,sqo),e(y,lqo),e(y,H1),e(H1,K2e),e(K2e,iqo),e(H1,dqo),e(H1,Uz),e(Uz,mqo),e(H1,cqo),e(y,fqo),e(y,J1),e(J1,ebe),e(ebe,gqo),e(J1,hqo),e(J1,Hz),e(Hz,uqo),e(J1,pqo),e(y,_qo),e(y,Y1),e(Y1,obe),e(obe,bqo),e(Y1,vqo),e(Y1,Jz),e(Jz,Fqo),e(Y1,Tqo),e(y,Mqo),e(y,Z1),e(Z1,rbe),e(rbe,Eqo),e(Z1,Cqo),e(Z1,Yz),e(Yz,wqo),e(Z1,Aqo),e(y,Lqo),e(y,K1),e(K1,tbe),e(tbe,yqo),e(K1,xqo),e(K1,Zz),e(Zz,$qo),e(K1,kqo),e(y,Sqo),e(y,e2),e(e2,abe),e(abe,Rqo),e(e2,Pqo),e(e2,Kz),e(Kz,Bqo),e(e2,Iqo),e(y,Nqo),e(y,o2),e(o2,nbe),e(nbe,qqo),e(o2,Dqo),e(o2,eQ),e(eQ,jqo),e(o2,Gqo),e(y,Oqo),e(y,r2),e(r2,sbe),e(sbe,Vqo),e(r2,Xqo),e(r2,oQ),e(oQ,zqo),e(r2,Qqo),e(y,Wqo),e(y,t2),e(t2,lbe),e(lbe,Uqo),e(t2,Hqo),e(t2,rQ),e(rQ,Jqo),e(t2,Yqo),e(y,Zqo),e(y,a2),e(a2,ibe),e(ibe,Kqo),e(a2,eDo),e(a2,tQ),e(tQ,oDo),e(a2,rDo),e(y,tDo),e(y,n2),e(n2,dbe),e(dbe,aDo),e(n2,nDo),e(n2,aQ),e(aQ,sDo),e(n2,lDo),e(y,iDo),e(y,s2),e(s2,mbe),e(mbe,dDo),e(s2,mDo),e(s2,nQ),e(nQ,cDo),e(s2,fDo),e(y,gDo),e(y,l2),e(l2,cbe),e(cbe,hDo),e(l2,uDo),e(l2,sQ),e(sQ,pDo),e(l2,_Do),e(y,bDo),e(y,i2),e(i2,fbe),e(fbe,vDo),e(i2,FDo),e(i2,lQ),e(lQ,TDo),e(i2,MDo),e(y,EDo),e(y,d2),e(d2,gbe),e(gbe,CDo),e(d2,wDo),e(d2,iQ),e(iQ,ADo),e(d2,LDo),e(y,yDo),e(y,m2),e(m2,hbe),e(hbe,xDo),e(m2,$Do),e(m2,dQ),e(dQ,kDo),e(m2,SDo),e(y,RDo),e(y,c2),e(c2,ube),e(ube,PDo),e(c2,BDo),e(c2,mQ),e(mQ,IDo),e(c2,NDo),e(y,qDo),e(y,f2),e(f2,pbe),e(pbe,DDo),e(f2,jDo),e(f2,cQ),e(cQ,GDo),e(f2,ODo),e(y,VDo),e(y,g2),e(g2,_be),e(_be,XDo),e(g2,zDo),e(g2,fQ),e(fQ,QDo),e(g2,WDo),e(y,UDo),e(y,h2),e(h2,bbe),e(bbe,HDo),e(h2,JDo),e(h2,gQ),e(gQ,YDo),e(h2,ZDo),e(y,KDo),e(y,u2),e(u2,vbe),e(vbe,ejo),e(u2,ojo),e(u2,hQ),e(hQ,rjo),e(u2,tjo),e(y,ajo),e(y,p2),e(p2,Fbe),e(Fbe,njo),e(p2,sjo),e(p2,uQ),e(uQ,ljo),e(p2,ijo),e(y,djo),e(y,_2),e(_2,Tbe),e(Tbe,mjo),e(_2,cjo),e(_2,pQ),e(pQ,fjo),e(_2,gjo),e(y,hjo),e(y,b2),e(b2,Mbe),e(Mbe,ujo),e(b2,pjo),e(b2,_Q),e(_Q,_jo),e(b2,bjo),e(y,vjo),e(y,v2),e(v2,Ebe),e(Ebe,Fjo),e(v2,Tjo),e(v2,bQ),e(bQ,Mjo),e(v2,Ejo),e(y,Cjo),e(y,F2),e(F2,Cbe),e(Cbe,wjo),e(F2,Ajo),e(F2,vQ),e(vQ,Ljo),e(F2,yjo),e(y,xjo),e(y,T2),e(T2,wbe),e(wbe,$jo),e(T2,kjo),e(T2,FQ),e(FQ,Sjo),e(T2,Rjo),e(y,Pjo),e(y,M2),e(M2,Abe),e(Abe,Bjo),e(M2,Ijo),e(M2,TQ),e(TQ,Njo),e(M2,qjo),e(y,Djo),e(y,E2),e(E2,Lbe),e(Lbe,jjo),e(E2,Gjo),e(E2,MQ),e(MQ,Ojo),e(E2,Vjo),e(y,Xjo),e(y,C2),e(C2,ybe),e(ybe,zjo),e(C2,Qjo),e(C2,EQ),e(EQ,Wjo),e(C2,Ujo),e(y,Hjo),e(y,w2),e(w2,xbe),e(xbe,Jjo),e(w2,Yjo),e(w2,CQ),e(CQ,Zjo),e(w2,Kjo),e(y,eGo),e(y,A2),e(A2,$be),e($be,oGo),e(A2,rGo),e(A2,wQ),e(wQ,tGo),e(A2,aGo),e(y,nGo),e(y,L2),e(L2,kbe),e(kbe,sGo),e(L2,lGo),e(L2,AQ),e(AQ,iGo),e(L2,dGo),e(y,mGo),e(y,y2),e(y2,Sbe),e(Sbe,cGo),e(y2,fGo),e(y2,LQ),e(LQ,gGo),e(y2,hGo),e(y,uGo),e(y,x2),e(x2,Rbe),e(Rbe,pGo),e(x2,_Go),e(x2,yQ),e(yQ,bGo),e(x2,vGo),e(y,FGo),e(y,$2),e($2,Pbe),e(Pbe,TGo),e($2,MGo),e($2,xQ),e(xQ,EGo),e($2,CGo),e(y,wGo),e(y,k2),e(k2,Bbe),e(Bbe,AGo),e(k2,LGo),e(k2,$Q),e($Q,yGo),e(k2,xGo),e(y,$Go),e(y,S2),e(S2,Ibe),e(Ibe,kGo),e(S2,SGo),e(S2,kQ),e(kQ,RGo),e(S2,PGo),e(y,BGo),e(y,R2),e(R2,Nbe),e(Nbe,IGo),e(R2,NGo),e(R2,SQ),e(SQ,qGo),e(R2,DGo),e(y,jGo),e(y,P2),e(P2,qbe),e(qbe,GGo),e(P2,OGo),e(P2,RQ),e(RQ,VGo),e(P2,XGo),e(y,zGo),e(y,B2),e(B2,Dbe),e(Dbe,QGo),e(B2,WGo),e(B2,PQ),e(PQ,UGo),e(B2,HGo),e(y,JGo),e(y,I2),e(I2,jbe),e(jbe,YGo),e(I2,ZGo),e(I2,BQ),e(BQ,KGo),e(I2,eOo),e(y,oOo),e(y,N2),e(N2,Gbe),e(Gbe,rOo),e(N2,tOo),e(N2,IQ),e(IQ,aOo),e(N2,nOo),e(y,sOo),e(y,q2),e(q2,Obe),e(Obe,lOo),e(q2,iOo),e(q2,NQ),e(NQ,dOo),e(q2,mOo),e(y,cOo),e(y,D2),e(D2,Vbe),e(Vbe,fOo),e(D2,gOo),e(D2,qQ),e(qQ,hOo),e(D2,uOo),e(y,pOo),e(y,j2),e(j2,Xbe),e(Xbe,_Oo),e(j2,bOo),e(j2,DQ),e(DQ,vOo),e(j2,FOo),e(y,TOo),e(y,G2),e(G2,zbe),e(zbe,MOo),e(G2,EOo),e(G2,jQ),e(jQ,COo),e(G2,wOo),e(y,AOo),e(y,O2),e(O2,Qbe),e(Qbe,LOo),e(O2,yOo),e(O2,GQ),e(GQ,xOo),e(O2,$Oo),e(y,kOo),e(y,V2),e(V2,Wbe),e(Wbe,SOo),e(V2,ROo),e(V2,OQ),e(OQ,POo),e(V2,BOo),e(y,IOo),e(y,X2),e(X2,Ube),e(Ube,NOo),e(X2,qOo),e(X2,VQ),e(VQ,DOo),e(X2,jOo),e(y,GOo),e(y,z2),e(z2,Hbe),e(Hbe,OOo),e(z2,VOo),e(z2,XQ),e(XQ,XOo),e(z2,zOo),e(y,QOo),e(y,Q2),e(Q2,Jbe),e(Jbe,WOo),e(Q2,UOo),e(Q2,zQ),e(zQ,HOo),e(Q2,JOo),e(y,YOo),e(y,W2),e(W2,Ybe),e(Ybe,ZOo),e(W2,KOo),e(W2,QQ),e(QQ,eVo),e(W2,oVo),e(y,rVo),e(y,U2),e(U2,Zbe),e(Zbe,tVo),e(U2,aVo),e(U2,WQ),e(WQ,nVo),e(U2,sVo),e(y,lVo),e(y,H2),e(H2,Kbe),e(Kbe,iVo),e(H2,dVo),e(H2,UQ),e(UQ,mVo),e(H2,cVo),e(y,fVo),e(y,J2),e(J2,eve),e(eve,gVo),e(J2,hVo),e(J2,HQ),e(HQ,uVo),e(J2,pVo),e(y,_Vo),e(y,Y2),e(Y2,ove),e(ove,bVo),e(Y2,vVo),e(Y2,JQ),e(JQ,FVo),e(Y2,TVo),e(y,MVo),e(y,Z2),e(Z2,rve),e(rve,EVo),e(Z2,CVo),e(Z2,YQ),e(YQ,wVo),e(Z2,AVo),e(y,LVo),e(y,K2),e(K2,tve),e(tve,yVo),e(K2,xVo),e(K2,ZQ),e(ZQ,$Vo),e(K2,kVo),e(y,SVo),e(y,eb),e(eb,ave),e(ave,RVo),e(eb,PVo),e(eb,KQ),e(KQ,BVo),e(eb,IVo),e(Ke,NVo),e(Ke,ob),e(ob,qVo),e(ob,nve),e(nve,DVo),e(ob,jVo),e(ob,sve),e(sve,GVo),e(Ke,OVo),M(rb,Ke,null),b(c,Xto,_),b(c,Bd,_),e(Bd,tb),e(tb,lve),M(G$,lve,null),e(Bd,VVo),e(Bd,ive),e(ive,XVo),b(c,zto,_),b(c,No,_),M(O$,No,null),e(No,zVo),e(No,Id),e(Id,QVo),e(Id,eW),e(eW,WVo),e(Id,UVo),e(Id,oW),e(oW,HVo),e(Id,JVo),e(No,YVo),e(No,V$),e(V$,ZVo),e(V$,dve),e(dve,KVo),e(V$,eXo),e(No,oXo),e(No,Et),M(X$,Et,null),e(Et,rXo),e(Et,mve),e(mve,tXo),e(Et,aXo),e(Et,Nd),e(Nd,nXo),e(Nd,cve),e(cve,sXo),e(Nd,lXo),e(Nd,rW),e(rW,iXo),e(Nd,dXo),e(Et,mXo),M(ab,Et,null),e(No,cXo),e(No,eo),M(z$,eo,null),e(eo,fXo),e(eo,fve),e(fve,gXo),e(eo,hXo),e(eo,sn),e(sn,uXo),e(sn,gve),e(gve,pXo),e(sn,_Xo),e(sn,hve),e(hve,bXo),e(sn,vXo),e(sn,uve),e(uve,FXo),e(sn,TXo),e(eo,MXo),e(eo,G),e(G,nb),e(nb,pve),e(pve,EXo),e(nb,CXo),e(nb,tW),e(tW,wXo),e(nb,AXo),e(G,LXo),e(G,sb),e(sb,_ve),e(_ve,yXo),e(sb,xXo),e(sb,aW),e(aW,$Xo),e(sb,kXo),e(G,SXo),e(G,lb),e(lb,bve),e(bve,RXo),e(lb,PXo),e(lb,nW),e(nW,BXo),e(lb,IXo),e(G,NXo),e(G,ib),e(ib,vve),e(vve,qXo),e(ib,DXo),e(ib,sW),e(sW,jXo),e(ib,GXo),e(G,OXo),e(G,db),e(db,Fve),e(Fve,VXo),e(db,XXo),e(db,lW),e(lW,zXo),e(db,QXo),e(G,WXo),e(G,mb),e(mb,Tve),e(Tve,UXo),e(mb,HXo),e(mb,iW),e(iW,JXo),e(mb,YXo),e(G,ZXo),e(G,cb),e(cb,Mve),e(Mve,KXo),e(cb,ezo),e(cb,dW),e(dW,ozo),e(cb,rzo),e(G,tzo),e(G,fb),e(fb,Eve),e(Eve,azo),e(fb,nzo),e(fb,mW),e(mW,szo),e(fb,lzo),e(G,izo),e(G,gb),e(gb,Cve),e(Cve,dzo),e(gb,mzo),e(gb,cW),e(cW,czo),e(gb,fzo),e(G,gzo),e(G,hb),e(hb,wve),e(wve,hzo),e(hb,uzo),e(hb,fW),e(fW,pzo),e(hb,_zo),e(G,bzo),e(G,ub),e(ub,Ave),e(Ave,vzo),e(ub,Fzo),e(ub,gW),e(gW,Tzo),e(ub,Mzo),e(G,Ezo),e(G,pb),e(pb,Lve),e(Lve,Czo),e(pb,wzo),e(pb,hW),e(hW,Azo),e(pb,Lzo),e(G,yzo),e(G,_b),e(_b,yve),e(yve,xzo),e(_b,$zo),e(_b,uW),e(uW,kzo),e(_b,Szo),e(G,Rzo),e(G,bb),e(bb,xve),e(xve,Pzo),e(bb,Bzo),e(bb,pW),e(pW,Izo),e(bb,Nzo),e(G,qzo),e(G,vb),e(vb,$ve),e($ve,Dzo),e(vb,jzo),e(vb,_W),e(_W,Gzo),e(vb,Ozo),e(G,Vzo),e(G,Fb),e(Fb,kve),e(kve,Xzo),e(Fb,zzo),e(Fb,bW),e(bW,Qzo),e(Fb,Wzo),e(G,Uzo),e(G,Tb),e(Tb,Sve),e(Sve,Hzo),e(Tb,Jzo),e(Tb,vW),e(vW,Yzo),e(Tb,Zzo),e(G,Kzo),e(G,Mb),e(Mb,Rve),e(Rve,eQo),e(Mb,oQo),e(Mb,FW),e(FW,rQo),e(Mb,tQo),e(G,aQo),e(G,Eb),e(Eb,Pve),e(Pve,nQo),e(Eb,sQo),e(Eb,TW),e(TW,lQo),e(Eb,iQo),e(G,dQo),e(G,Cb),e(Cb,Bve),e(Bve,mQo),e(Cb,cQo),e(Cb,MW),e(MW,fQo),e(Cb,gQo),e(G,hQo),e(G,wb),e(wb,Ive),e(Ive,uQo),e(wb,pQo),e(wb,EW),e(EW,_Qo),e(wb,bQo),e(G,vQo),e(G,Ab),e(Ab,Nve),e(Nve,FQo),e(Ab,TQo),e(Ab,CW),e(CW,MQo),e(Ab,EQo),e(G,CQo),e(G,Lb),e(Lb,qve),e(qve,wQo),e(Lb,AQo),e(Lb,wW),e(wW,LQo),e(Lb,yQo),e(G,xQo),e(G,yb),e(yb,Dve),e(Dve,$Qo),e(yb,kQo),e(yb,AW),e(AW,SQo),e(yb,RQo),e(G,PQo),e(G,xb),e(xb,jve),e(jve,BQo),e(xb,IQo),e(xb,LW),e(LW,NQo),e(xb,qQo),e(G,DQo),e(G,$b),e($b,Gve),e(Gve,jQo),e($b,GQo),e($b,yW),e(yW,OQo),e($b,VQo),e(G,XQo),e(G,kb),e(kb,Ove),e(Ove,zQo),e(kb,QQo),e(kb,xW),e(xW,WQo),e(kb,UQo),e(G,HQo),e(G,Sb),e(Sb,Vve),e(Vve,JQo),e(Sb,YQo),e(Sb,$W),e($W,ZQo),e(Sb,KQo),e(G,eWo),e(G,Rb),e(Rb,Xve),e(Xve,oWo),e(Rb,rWo),e(Rb,kW),e(kW,tWo),e(Rb,aWo),e(G,nWo),e(G,Pb),e(Pb,zve),e(zve,sWo),e(Pb,lWo),e(Pb,SW),e(SW,iWo),e(Pb,dWo),e(G,mWo),e(G,Bb),e(Bb,Qve),e(Qve,cWo),e(Bb,fWo),e(Bb,RW),e(RW,gWo),e(Bb,hWo),e(G,uWo),e(G,Ib),e(Ib,Wve),e(Wve,pWo),e(Ib,_Wo),e(Ib,PW),e(PW,bWo),e(Ib,vWo),e(G,FWo),e(G,Nb),e(Nb,Uve),e(Uve,TWo),e(Nb,MWo),e(Nb,BW),e(BW,EWo),e(Nb,CWo),e(G,wWo),e(G,qb),e(qb,Hve),e(Hve,AWo),e(qb,LWo),e(qb,IW),e(IW,yWo),e(qb,xWo),e(G,$Wo),e(G,Db),e(Db,Jve),e(Jve,kWo),e(Db,SWo),e(Db,NW),e(NW,RWo),e(Db,PWo),e(G,BWo),e(G,jb),e(jb,Yve),e(Yve,IWo),e(jb,NWo),e(jb,qW),e(qW,qWo),e(jb,DWo),e(G,jWo),e(G,Gb),e(Gb,Zve),e(Zve,GWo),e(Gb,OWo),e(Gb,DW),e(DW,VWo),e(Gb,XWo),e(G,zWo),e(G,Ob),e(Ob,Kve),e(Kve,QWo),e(Ob,WWo),e(Ob,jW),e(jW,UWo),e(Ob,HWo),e(G,JWo),e(G,Vb),e(Vb,eFe),e(eFe,YWo),e(Vb,ZWo),e(Vb,GW),e(GW,KWo),e(Vb,eUo),e(G,oUo),e(G,Xb),e(Xb,oFe),e(oFe,rUo),e(Xb,tUo),e(Xb,OW),e(OW,aUo),e(Xb,nUo),e(G,sUo),e(G,zb),e(zb,rFe),e(rFe,lUo),e(zb,iUo),e(zb,VW),e(VW,dUo),e(zb,mUo),e(G,cUo),e(G,Qb),e(Qb,tFe),e(tFe,fUo),e(Qb,gUo),e(Qb,XW),e(XW,hUo),e(Qb,uUo),e(G,pUo),e(G,Wb),e(Wb,aFe),e(aFe,_Uo),e(Wb,bUo),e(Wb,zW),e(zW,vUo),e(Wb,FUo),e(G,TUo),e(G,Ub),e(Ub,nFe),e(nFe,MUo),e(Ub,EUo),e(Ub,QW),e(QW,CUo),e(Ub,wUo),e(G,AUo),e(G,Hb),e(Hb,sFe),e(sFe,LUo),e(Hb,yUo),e(Hb,WW),e(WW,xUo),e(Hb,$Uo),e(G,kUo),e(G,Jb),e(Jb,lFe),e(lFe,SUo),e(Jb,RUo),e(Jb,UW),e(UW,PUo),e(Jb,BUo),e(G,IUo),e(G,Yb),e(Yb,iFe),e(iFe,NUo),e(Yb,qUo),e(Yb,HW),e(HW,DUo),e(Yb,jUo),e(G,GUo),e(G,Zb),e(Zb,dFe),e(dFe,OUo),e(Zb,VUo),e(Zb,JW),e(JW,XUo),e(Zb,zUo),e(eo,QUo),e(eo,Kb),e(Kb,WUo),e(Kb,mFe),e(mFe,UUo),e(Kb,HUo),e(Kb,cFe),e(cFe,JUo),e(eo,YUo),M(ev,eo,null),b(c,Qto,_),b(c,qd,_),e(qd,ov),e(ov,fFe),M(Q$,fFe,null),e(qd,ZUo),e(qd,gFe),e(gFe,KUo),b(c,Wto,_),b(c,qo,_),M(W$,qo,null),e(qo,eHo),e(qo,Dd),e(Dd,oHo),e(Dd,YW),e(YW,rHo),e(Dd,tHo),e(Dd,ZW),e(ZW,aHo),e(Dd,nHo),e(qo,sHo),e(qo,U$),e(U$,lHo),e(U$,hFe),e(hFe,iHo),e(U$,dHo),e(qo,mHo),e(qo,Ct),M(H$,Ct,null),e(Ct,cHo),e(Ct,uFe),e(uFe,fHo),e(Ct,gHo),e(Ct,jd),e(jd,hHo),e(jd,pFe),e(pFe,uHo),e(jd,pHo),e(jd,KW),e(KW,_Ho),e(jd,bHo),e(Ct,vHo),M(rv,Ct,null),e(qo,FHo),e(qo,oo),M(J$,oo,null),e(oo,THo),e(oo,_Fe),e(_Fe,MHo),e(oo,EHo),e(oo,ln),e(ln,CHo),e(ln,bFe),e(bFe,wHo),e(ln,AHo),e(ln,vFe),e(vFe,LHo),e(ln,yHo),e(ln,FFe),e(FFe,xHo),e(ln,$Ho),e(oo,kHo),e(oo,W),e(W,tv),e(tv,TFe),e(TFe,SHo),e(tv,RHo),e(tv,eU),e(eU,PHo),e(tv,BHo),e(W,IHo),e(W,av),e(av,MFe),e(MFe,NHo),e(av,qHo),e(av,oU),e(oU,DHo),e(av,jHo),e(W,GHo),e(W,nv),e(nv,EFe),e(EFe,OHo),e(nv,VHo),e(nv,rU),e(rU,XHo),e(nv,zHo),e(W,QHo),e(W,sv),e(sv,CFe),e(CFe,WHo),e(sv,UHo),e(sv,tU),e(tU,HHo),e(sv,JHo),e(W,YHo),e(W,lv),e(lv,wFe),e(wFe,ZHo),e(lv,KHo),e(lv,aU),e(aU,eJo),e(lv,oJo),e(W,rJo),e(W,iv),e(iv,AFe),e(AFe,tJo),e(iv,aJo),e(iv,nU),e(nU,nJo),e(iv,sJo),e(W,lJo),e(W,dv),e(dv,LFe),e(LFe,iJo),e(dv,dJo),e(dv,sU),e(sU,mJo),e(dv,cJo),e(W,fJo),e(W,mv),e(mv,yFe),e(yFe,gJo),e(mv,hJo),e(mv,lU),e(lU,uJo),e(mv,pJo),e(W,_Jo),e(W,cv),e(cv,xFe),e(xFe,bJo),e(cv,vJo),e(cv,iU),e(iU,FJo),e(cv,TJo),e(W,MJo),e(W,fv),e(fv,$Fe),e($Fe,EJo),e(fv,CJo),e(fv,dU),e(dU,wJo),e(fv,AJo),e(W,LJo),e(W,gv),e(gv,kFe),e(kFe,yJo),e(gv,xJo),e(gv,mU),e(mU,$Jo),e(gv,kJo),e(W,SJo),e(W,hv),e(hv,SFe),e(SFe,RJo),e(hv,PJo),e(hv,cU),e(cU,BJo),e(hv,IJo),e(W,NJo),e(W,uv),e(uv,RFe),e(RFe,qJo),e(uv,DJo),e(uv,fU),e(fU,jJo),e(uv,GJo),e(W,OJo),e(W,pv),e(pv,PFe),e(PFe,VJo),e(pv,XJo),e(pv,gU),e(gU,zJo),e(pv,QJo),e(W,WJo),e(W,_v),e(_v,BFe),e(BFe,UJo),e(_v,HJo),e(_v,hU),e(hU,JJo),e(_v,YJo),e(W,ZJo),e(W,bv),e(bv,IFe),e(IFe,KJo),e(bv,eYo),e(bv,uU),e(uU,oYo),e(bv,rYo),e(W,tYo),e(W,vv),e(vv,NFe),e(NFe,aYo),e(vv,nYo),e(vv,pU),e(pU,sYo),e(vv,lYo),e(W,iYo),e(W,Fv),e(Fv,qFe),e(qFe,dYo),e(Fv,mYo),e(Fv,_U),e(_U,cYo),e(Fv,fYo),e(W,gYo),e(W,Tv),e(Tv,DFe),e(DFe,hYo),e(Tv,uYo),e(Tv,bU),e(bU,pYo),e(Tv,_Yo),e(W,bYo),e(W,Mv),e(Mv,jFe),e(jFe,vYo),e(Mv,FYo),e(Mv,vU),e(vU,TYo),e(Mv,MYo),e(W,EYo),e(W,Ev),e(Ev,GFe),e(GFe,CYo),e(Ev,wYo),e(Ev,FU),e(FU,AYo),e(Ev,LYo),e(W,yYo),e(W,Cv),e(Cv,OFe),e(OFe,xYo),e(Cv,$Yo),e(Cv,TU),e(TU,kYo),e(Cv,SYo),e(W,RYo),e(W,wv),e(wv,VFe),e(VFe,PYo),e(wv,BYo),e(wv,MU),e(MU,IYo),e(wv,NYo),e(W,qYo),e(W,Av),e(Av,XFe),e(XFe,DYo),e(Av,jYo),e(Av,EU),e(EU,GYo),e(Av,OYo),e(W,VYo),e(W,Lv),e(Lv,zFe),e(zFe,XYo),e(Lv,zYo),e(Lv,CU),e(CU,QYo),e(Lv,WYo),e(W,UYo),e(W,yv),e(yv,QFe),e(QFe,HYo),e(yv,JYo),e(yv,wU),e(wU,YYo),e(yv,ZYo),e(W,KYo),e(W,xv),e(xv,WFe),e(WFe,eZo),e(xv,oZo),e(xv,AU),e(AU,rZo),e(xv,tZo),e(W,aZo),e(W,$v),e($v,UFe),e(UFe,nZo),e($v,sZo),e($v,LU),e(LU,lZo),e($v,iZo),e(W,dZo),e(W,kv),e(kv,HFe),e(HFe,mZo),e(kv,cZo),e(kv,yU),e(yU,fZo),e(kv,gZo),e(W,hZo),e(W,Sv),e(Sv,JFe),e(JFe,uZo),e(Sv,pZo),e(Sv,xU),e(xU,_Zo),e(Sv,bZo),e(W,vZo),e(W,Rv),e(Rv,YFe),e(YFe,FZo),e(Rv,TZo),e(Rv,$U),e($U,MZo),e(Rv,EZo),e(W,CZo),e(W,Pv),e(Pv,ZFe),e(ZFe,wZo),e(Pv,AZo),e(Pv,kU),e(kU,LZo),e(Pv,yZo),e(W,xZo),e(W,Bv),e(Bv,KFe),e(KFe,$Zo),e(Bv,kZo),e(Bv,SU),e(SU,SZo),e(Bv,RZo),e(W,PZo),e(W,Iv),e(Iv,eTe),e(eTe,BZo),e(Iv,IZo),e(Iv,RU),e(RU,NZo),e(Iv,qZo),e(W,DZo),e(W,Nv),e(Nv,oTe),e(oTe,jZo),e(Nv,GZo),e(Nv,PU),e(PU,OZo),e(Nv,VZo),e(W,XZo),e(W,qv),e(qv,rTe),e(rTe,zZo),e(qv,QZo),e(qv,BU),e(BU,WZo),e(qv,UZo),e(W,HZo),e(W,Dv),e(Dv,tTe),e(tTe,JZo),e(Dv,YZo),e(Dv,IU),e(IU,ZZo),e(Dv,KZo),e(W,eKo),e(W,jv),e(jv,aTe),e(aTe,oKo),e(jv,rKo),e(jv,NU),e(NU,tKo),e(jv,aKo),e(W,nKo),e(W,Gv),e(Gv,nTe),e(nTe,sKo),e(Gv,lKo),e(Gv,qU),e(qU,iKo),e(Gv,dKo),e(W,mKo),e(W,Ov),e(Ov,sTe),e(sTe,cKo),e(Ov,fKo),e(Ov,DU),e(DU,gKo),e(Ov,hKo),e(W,uKo),e(W,Vv),e(Vv,lTe),e(lTe,pKo),e(Vv,_Ko),e(Vv,jU),e(jU,bKo),e(Vv,vKo),e(W,FKo),e(W,Xv),e(Xv,iTe),e(iTe,TKo),e(Xv,MKo),e(Xv,GU),e(GU,EKo),e(Xv,CKo),e(oo,wKo),e(oo,zv),e(zv,AKo),e(zv,dTe),e(dTe,LKo),e(zv,yKo),e(zv,mTe),e(mTe,xKo),e(oo,$Ko),M(Qv,oo,null),b(c,Uto,_),b(c,Gd,_),e(Gd,Wv),e(Wv,cTe),M(Y$,cTe,null),e(Gd,kKo),e(Gd,fTe),e(fTe,SKo),b(c,Hto,_),b(c,Do,_),M(Z$,Do,null),e(Do,RKo),e(Do,Od),e(Od,PKo),e(Od,OU),e(OU,BKo),e(Od,IKo),e(Od,VU),e(VU,NKo),e(Od,qKo),e(Do,DKo),e(Do,K$),e(K$,jKo),e(K$,gTe),e(gTe,GKo),e(K$,OKo),e(Do,VKo),e(Do,wt),M(ek,wt,null),e(wt,XKo),e(wt,hTe),e(hTe,zKo),e(wt,QKo),e(wt,Vd),e(Vd,WKo),e(Vd,uTe),e(uTe,UKo),e(Vd,HKo),e(Vd,XU),e(XU,JKo),e(Vd,YKo),e(wt,ZKo),M(Uv,wt,null),e(Do,KKo),e(Do,ro),M(ok,ro,null),e(ro,eer),e(ro,pTe),e(pTe,oer),e(ro,rer),e(ro,dn),e(dn,ter),e(dn,_Te),e(_Te,aer),e(dn,ner),e(dn,bTe),e(bTe,ser),e(dn,ler),e(dn,vTe),e(vTe,ier),e(dn,der),e(ro,mer),e(ro,rk),e(rk,Hv),e(Hv,FTe),e(FTe,cer),e(Hv,fer),e(Hv,zU),e(zU,ger),e(Hv,her),e(rk,uer),e(rk,Jv),e(Jv,TTe),e(TTe,per),e(Jv,_er),e(Jv,QU),e(QU,ber),e(Jv,ver),e(ro,Fer),e(ro,Yv),e(Yv,Ter),e(Yv,MTe),e(MTe,Mer),e(Yv,Eer),e(Yv,ETe),e(ETe,Cer),e(ro,wer),M(Zv,ro,null),b(c,Jto,_),b(c,Xd,_),e(Xd,Kv),e(Kv,CTe),M(tk,CTe,null),e(Xd,Aer),e(Xd,wTe),e(wTe,Ler),b(c,Yto,_),b(c,jo,_),M(ak,jo,null),e(jo,yer),e(jo,zd),e(zd,xer),e(zd,WU),e(WU,$er),e(zd,ker),e(zd,UU),e(UU,Ser),e(zd,Rer),e(jo,Per),e(jo,nk),e(nk,Ber),e(nk,ATe),e(ATe,Ier),e(nk,Ner),e(jo,qer),e(jo,At),M(sk,At,null),e(At,Der),e(At,LTe),e(LTe,jer),e(At,Ger),e(At,Qd),e(Qd,Oer),e(Qd,yTe),e(yTe,Ver),e(Qd,Xer),e(Qd,HU),e(HU,zer),e(Qd,Qer),e(At,Wer),M(eF,At,null),e(jo,Uer),e(jo,to),M(lk,to,null),e(to,Her),e(to,xTe),e(xTe,Jer),e(to,Yer),e(to,mn),e(mn,Zer),e(mn,$Te),e($Te,Ker),e(mn,eor),e(mn,kTe),e(kTe,oor),e(mn,ror),e(mn,STe),e(STe,tor),e(mn,aor),e(to,nor),e(to,Y),e(Y,oF),e(oF,RTe),e(RTe,sor),e(oF,lor),e(oF,JU),e(JU,ior),e(oF,dor),e(Y,mor),e(Y,rF),e(rF,PTe),e(PTe,cor),e(rF,gor),e(rF,YU),e(YU,hor),e(rF,uor),e(Y,por),e(Y,tF),e(tF,BTe),e(BTe,_or),e(tF,bor),e(tF,ZU),e(ZU,vor),e(tF,For),e(Y,Tor),e(Y,aF),e(aF,ITe),e(ITe,Mor),e(aF,Eor),e(aF,KU),e(KU,Cor),e(aF,wor),e(Y,Aor),e(Y,nF),e(nF,NTe),e(NTe,Lor),e(nF,yor),e(nF,eH),e(eH,xor),e(nF,$or),e(Y,kor),e(Y,sF),e(sF,qTe),e(qTe,Sor),e(sF,Ror),e(sF,oH),e(oH,Por),e(sF,Bor),e(Y,Ior),e(Y,lF),e(lF,DTe),e(DTe,Nor),e(lF,qor),e(lF,rH),e(rH,Dor),e(lF,jor),e(Y,Gor),e(Y,iF),e(iF,jTe),e(jTe,Oor),e(iF,Vor),e(iF,tH),e(tH,Xor),e(iF,zor),e(Y,Qor),e(Y,dF),e(dF,GTe),e(GTe,Wor),e(dF,Uor),e(dF,aH),e(aH,Hor),e(dF,Jor),e(Y,Yor),e(Y,mF),e(mF,OTe),e(OTe,Zor),e(mF,Kor),e(mF,nH),e(nH,err),e(mF,orr),e(Y,rrr),e(Y,cF),e(cF,VTe),e(VTe,trr),e(cF,arr),e(cF,sH),e(sH,nrr),e(cF,srr),e(Y,lrr),e(Y,fF),e(fF,XTe),e(XTe,irr),e(fF,drr),e(fF,lH),e(lH,mrr),e(fF,crr),e(Y,frr),e(Y,gF),e(gF,zTe),e(zTe,grr),e(gF,hrr),e(gF,iH),e(iH,urr),e(gF,prr),e(Y,_rr),e(Y,hF),e(hF,QTe),e(QTe,brr),e(hF,vrr),e(hF,dH),e(dH,Frr),e(hF,Trr),e(Y,Mrr),e(Y,uF),e(uF,WTe),e(WTe,Err),e(uF,Crr),e(uF,mH),e(mH,wrr),e(uF,Arr),e(Y,Lrr),e(Y,pF),e(pF,UTe),e(UTe,yrr),e(pF,xrr),e(pF,cH),e(cH,$rr),e(pF,krr),e(Y,Srr),e(Y,_F),e(_F,HTe),e(HTe,Rrr),e(_F,Prr),e(_F,fH),e(fH,Brr),e(_F,Irr),e(Y,Nrr),e(Y,bF),e(bF,JTe),e(JTe,qrr),e(bF,Drr),e(bF,gH),e(gH,jrr),e(bF,Grr),e(Y,Orr),e(Y,vF),e(vF,YTe),e(YTe,Vrr),e(vF,Xrr),e(vF,hH),e(hH,zrr),e(vF,Qrr),e(Y,Wrr),e(Y,FF),e(FF,ZTe),e(ZTe,Urr),e(FF,Hrr),e(FF,uH),e(uH,Jrr),e(FF,Yrr),e(Y,Zrr),e(Y,TF),e(TF,KTe),e(KTe,Krr),e(TF,etr),e(TF,pH),e(pH,otr),e(TF,rtr),e(Y,ttr),e(Y,MF),e(MF,eMe),e(eMe,atr),e(MF,ntr),e(MF,_H),e(_H,str),e(MF,ltr),e(Y,itr),e(Y,EF),e(EF,oMe),e(oMe,dtr),e(EF,mtr),e(EF,bH),e(bH,ctr),e(EF,ftr),e(Y,gtr),e(Y,CF),e(CF,rMe),e(rMe,htr),e(CF,utr),e(CF,vH),e(vH,ptr),e(CF,_tr),e(Y,btr),e(Y,wF),e(wF,tMe),e(tMe,vtr),e(wF,Ftr),e(wF,FH),e(FH,Ttr),e(wF,Mtr),e(Y,Etr),e(Y,AF),e(AF,aMe),e(aMe,Ctr),e(AF,wtr),e(AF,TH),e(TH,Atr),e(AF,Ltr),e(Y,ytr),e(Y,LF),e(LF,nMe),e(nMe,xtr),e(LF,$tr),e(LF,MH),e(MH,ktr),e(LF,Str),e(Y,Rtr),e(Y,yF),e(yF,sMe),e(sMe,Ptr),e(yF,Btr),e(yF,EH),e(EH,Itr),e(yF,Ntr),e(Y,qtr),e(Y,xF),e(xF,lMe),e(lMe,Dtr),e(xF,jtr),e(xF,CH),e(CH,Gtr),e(xF,Otr),e(Y,Vtr),e(Y,$F),e($F,iMe),e(iMe,Xtr),e($F,ztr),e($F,wH),e(wH,Qtr),e($F,Wtr),e(Y,Utr),e(Y,kF),e(kF,dMe),e(dMe,Htr),e(kF,Jtr),e(kF,AH),e(AH,Ytr),e(kF,Ztr),e(Y,Ktr),e(Y,SF),e(SF,mMe),e(mMe,ear),e(SF,oar),e(SF,LH),e(LH,rar),e(SF,tar),e(Y,aar),e(Y,RF),e(RF,cMe),e(cMe,nar),e(RF,sar),e(RF,yH),e(yH,lar),e(RF,iar),e(Y,dar),e(Y,PF),e(PF,fMe),e(fMe,mar),e(PF,car),e(PF,xH),e(xH,far),e(PF,gar),e(Y,har),e(Y,BF),e(BF,gMe),e(gMe,uar),e(BF,par),e(BF,hMe),e(hMe,_ar),e(BF,bar),e(Y,Far),e(Y,IF),e(IF,uMe),e(uMe,Tar),e(IF,Mar),e(IF,$H),e($H,Ear),e(IF,Car),e(Y,war),e(Y,NF),e(NF,pMe),e(pMe,Aar),e(NF,Lar),e(NF,kH),e(kH,yar),e(NF,xar),e(Y,$ar),e(Y,qF),e(qF,_Me),e(_Me,kar),e(qF,Sar),e(qF,SH),e(SH,Rar),e(qF,Par),e(Y,Bar),e(Y,DF),e(DF,bMe),e(bMe,Iar),e(DF,Nar),e(DF,RH),e(RH,qar),e(DF,Dar),e(to,jar),e(to,jF),e(jF,Gar),e(jF,vMe),e(vMe,Oar),e(jF,Var),e(jF,FMe),e(FMe,Xar),e(to,zar),M(GF,to,null),b(c,Zto,_),b(c,Wd,_),e(Wd,OF),e(OF,TMe),M(ik,TMe,null),e(Wd,Qar),e(Wd,MMe),e(MMe,War),b(c,Kto,_),b(c,Go,_),M(dk,Go,null),e(Go,Uar),e(Go,Ud),e(Ud,Har),e(Ud,PH),e(PH,Jar),e(Ud,Yar),e(Ud,BH),e(BH,Zar),e(Ud,Kar),e(Go,enr),e(Go,mk),e(mk,onr),e(mk,EMe),e(EMe,rnr),e(mk,tnr),e(Go,anr),e(Go,Lt),M(ck,Lt,null),e(Lt,nnr),e(Lt,CMe),e(CMe,snr),e(Lt,lnr),e(Lt,Hd),e(Hd,inr),e(Hd,wMe),e(wMe,dnr),e(Hd,mnr),e(Hd,IH),e(IH,cnr),e(Hd,fnr),e(Lt,gnr),M(VF,Lt,null),e(Go,hnr),e(Go,ao),M(fk,ao,null),e(ao,unr),e(ao,AMe),e(AMe,pnr),e(ao,_nr),e(ao,cn),e(cn,bnr),e(cn,LMe),e(LMe,vnr),e(cn,Fnr),e(cn,yMe),e(yMe,Tnr),e(cn,Mnr),e(cn,xMe),e(xMe,Enr),e(cn,Cnr),e(ao,wnr),e(ao,he),e(he,XF),e(XF,$Me),e($Me,Anr),e(XF,Lnr),e(XF,NH),e(NH,ynr),e(XF,xnr),e(he,$nr),e(he,zF),e(zF,kMe),e(kMe,knr),e(zF,Snr),e(zF,qH),e(qH,Rnr),e(zF,Pnr),e(he,Bnr),e(he,QF),e(QF,SMe),e(SMe,Inr),e(QF,Nnr),e(QF,DH),e(DH,qnr),e(QF,Dnr),e(he,jnr),e(he,WF),e(WF,RMe),e(RMe,Gnr),e(WF,Onr),e(WF,jH),e(jH,Vnr),e(WF,Xnr),e(he,znr),e(he,UF),e(UF,PMe),e(PMe,Qnr),e(UF,Wnr),e(UF,GH),e(GH,Unr),e(UF,Hnr),e(he,Jnr),e(he,HF),e(HF,BMe),e(BMe,Ynr),e(HF,Znr),e(HF,OH),e(OH,Knr),e(HF,esr),e(he,osr),e(he,JF),e(JF,IMe),e(IMe,rsr),e(JF,tsr),e(JF,VH),e(VH,asr),e(JF,nsr),e(he,ssr),e(he,YF),e(YF,NMe),e(NMe,lsr),e(YF,isr),e(YF,XH),e(XH,dsr),e(YF,msr),e(he,csr),e(he,ZF),e(ZF,qMe),e(qMe,fsr),e(ZF,gsr),e(ZF,zH),e(zH,hsr),e(ZF,usr),e(he,psr),e(he,KF),e(KF,DMe),e(DMe,_sr),e(KF,bsr),e(KF,QH),e(QH,vsr),e(KF,Fsr),e(he,Tsr),e(he,eT),e(eT,jMe),e(jMe,Msr),e(eT,Esr),e(eT,WH),e(WH,Csr),e(eT,wsr),e(he,Asr),e(he,oT),e(oT,GMe),e(GMe,Lsr),e(oT,ysr),e(oT,UH),e(UH,xsr),e(oT,$sr),e(he,ksr),e(he,rT),e(rT,OMe),e(OMe,Ssr),e(rT,Rsr),e(rT,HH),e(HH,Psr),e(rT,Bsr),e(he,Isr),e(he,tT),e(tT,VMe),e(VMe,Nsr),e(tT,qsr),e(tT,JH),e(JH,Dsr),e(tT,jsr),e(he,Gsr),e(he,aT),e(aT,XMe),e(XMe,Osr),e(aT,Vsr),e(aT,YH),e(YH,Xsr),e(aT,zsr),e(he,Qsr),e(he,nT),e(nT,zMe),e(zMe,Wsr),e(nT,Usr),e(nT,ZH),e(ZH,Hsr),e(nT,Jsr),e(he,Ysr),e(he,sT),e(sT,QMe),e(QMe,Zsr),e(sT,Ksr),e(sT,KH),e(KH,elr),e(sT,olr),e(he,rlr),e(he,lT),e(lT,WMe),e(WMe,tlr),e(lT,alr),e(lT,eJ),e(eJ,nlr),e(lT,slr),e(he,llr),e(he,iT),e(iT,UMe),e(UMe,ilr),e(iT,dlr),e(iT,oJ),e(oJ,mlr),e(iT,clr),e(he,flr),e(he,dT),e(dT,HMe),e(HMe,glr),e(dT,hlr),e(dT,rJ),e(rJ,ulr),e(dT,plr),e(ao,_lr),e(ao,mT),e(mT,blr),e(mT,JMe),e(JMe,vlr),e(mT,Flr),e(mT,YMe),e(YMe,Tlr),e(ao,Mlr),M(cT,ao,null),b(c,eao,_),b(c,Jd,_),e(Jd,fT),e(fT,ZMe),M(gk,ZMe,null),e(Jd,Elr),e(Jd,KMe),e(KMe,Clr),b(c,oao,_),b(c,Oo,_),M(hk,Oo,null),e(Oo,wlr),e(Oo,Yd),e(Yd,Alr),e(Yd,tJ),e(tJ,Llr),e(Yd,ylr),e(Yd,aJ),e(aJ,xlr),e(Yd,$lr),e(Oo,klr),e(Oo,uk),e(uk,Slr),e(uk,eEe),e(eEe,Rlr),e(uk,Plr),e(Oo,Blr),e(Oo,yt),M(pk,yt,null),e(yt,Ilr),e(yt,oEe),e(oEe,Nlr),e(yt,qlr),e(yt,Zd),e(Zd,Dlr),e(Zd,rEe),e(rEe,jlr),e(Zd,Glr),e(Zd,nJ),e(nJ,Olr),e(Zd,Vlr),e(yt,Xlr),M(gT,yt,null),e(Oo,zlr),e(Oo,no),M(_k,no,null),e(no,Qlr),e(no,tEe),e(tEe,Wlr),e(no,Ulr),e(no,fn),e(fn,Hlr),e(fn,aEe),e(aEe,Jlr),e(fn,Ylr),e(fn,nEe),e(nEe,Zlr),e(fn,Klr),e(fn,sEe),e(sEe,eir),e(fn,oir),e(no,rir),e(no,D),e(D,hT),e(hT,lEe),e(lEe,tir),e(hT,air),e(hT,sJ),e(sJ,nir),e(hT,sir),e(D,lir),e(D,uT),e(uT,iEe),e(iEe,iir),e(uT,dir),e(uT,lJ),e(lJ,mir),e(uT,cir),e(D,fir),e(D,pT),e(pT,dEe),e(dEe,gir),e(pT,hir),e(pT,iJ),e(iJ,uir),e(pT,pir),e(D,_ir),e(D,_T),e(_T,mEe),e(mEe,bir),e(_T,vir),e(_T,dJ),e(dJ,Fir),e(_T,Tir),e(D,Mir),e(D,bT),e(bT,cEe),e(cEe,Eir),e(bT,Cir),e(bT,mJ),e(mJ,wir),e(bT,Air),e(D,Lir),e(D,vT),e(vT,fEe),e(fEe,yir),e(vT,xir),e(vT,cJ),e(cJ,$ir),e(vT,kir),e(D,Sir),e(D,FT),e(FT,gEe),e(gEe,Rir),e(FT,Pir),e(FT,fJ),e(fJ,Bir),e(FT,Iir),e(D,Nir),e(D,TT),e(TT,hEe),e(hEe,qir),e(TT,Dir),e(TT,gJ),e(gJ,jir),e(TT,Gir),e(D,Oir),e(D,MT),e(MT,uEe),e(uEe,Vir),e(MT,Xir),e(MT,hJ),e(hJ,zir),e(MT,Qir),e(D,Wir),e(D,ET),e(ET,pEe),e(pEe,Uir),e(ET,Hir),e(ET,uJ),e(uJ,Jir),e(ET,Yir),e(D,Zir),e(D,CT),e(CT,_Ee),e(_Ee,Kir),e(CT,edr),e(CT,pJ),e(pJ,odr),e(CT,rdr),e(D,tdr),e(D,wT),e(wT,bEe),e(bEe,adr),e(wT,ndr),e(wT,_J),e(_J,sdr),e(wT,ldr),e(D,idr),e(D,AT),e(AT,vEe),e(vEe,ddr),e(AT,mdr),e(AT,bJ),e(bJ,cdr),e(AT,fdr),e(D,gdr),e(D,LT),e(LT,FEe),e(FEe,hdr),e(LT,udr),e(LT,vJ),e(vJ,pdr),e(LT,_dr),e(D,bdr),e(D,yT),e(yT,TEe),e(TEe,vdr),e(yT,Fdr),e(yT,FJ),e(FJ,Tdr),e(yT,Mdr),e(D,Edr),e(D,xT),e(xT,MEe),e(MEe,Cdr),e(xT,wdr),e(xT,TJ),e(TJ,Adr),e(xT,Ldr),e(D,ydr),e(D,$T),e($T,EEe),e(EEe,xdr),e($T,$dr),e($T,MJ),e(MJ,kdr),e($T,Sdr),e(D,Rdr),e(D,kT),e(kT,CEe),e(CEe,Pdr),e(kT,Bdr),e(kT,EJ),e(EJ,Idr),e(kT,Ndr),e(D,qdr),e(D,ST),e(ST,wEe),e(wEe,Ddr),e(ST,jdr),e(ST,CJ),e(CJ,Gdr),e(ST,Odr),e(D,Vdr),e(D,RT),e(RT,AEe),e(AEe,Xdr),e(RT,zdr),e(RT,wJ),e(wJ,Qdr),e(RT,Wdr),e(D,Udr),e(D,PT),e(PT,LEe),e(LEe,Hdr),e(PT,Jdr),e(PT,AJ),e(AJ,Ydr),e(PT,Zdr),e(D,Kdr),e(D,BT),e(BT,yEe),e(yEe,emr),e(BT,omr),e(BT,LJ),e(LJ,rmr),e(BT,tmr),e(D,amr),e(D,IT),e(IT,xEe),e(xEe,nmr),e(IT,smr),e(IT,yJ),e(yJ,lmr),e(IT,imr),e(D,dmr),e(D,NT),e(NT,$Ee),e($Ee,mmr),e(NT,cmr),e(NT,xJ),e(xJ,fmr),e(NT,gmr),e(D,hmr),e(D,qT),e(qT,kEe),e(kEe,umr),e(qT,pmr),e(qT,$J),e($J,_mr),e(qT,bmr),e(D,vmr),e(D,DT),e(DT,SEe),e(SEe,Fmr),e(DT,Tmr),e(DT,kJ),e(kJ,Mmr),e(DT,Emr),e(D,Cmr),e(D,jT),e(jT,REe),e(REe,wmr),e(jT,Amr),e(jT,SJ),e(SJ,Lmr),e(jT,ymr),e(D,xmr),e(D,GT),e(GT,PEe),e(PEe,$mr),e(GT,kmr),e(GT,RJ),e(RJ,Smr),e(GT,Rmr),e(D,Pmr),e(D,OT),e(OT,BEe),e(BEe,Bmr),e(OT,Imr),e(OT,PJ),e(PJ,Nmr),e(OT,qmr),e(D,Dmr),e(D,VT),e(VT,IEe),e(IEe,jmr),e(VT,Gmr),e(VT,BJ),e(BJ,Omr),e(VT,Vmr),e(D,Xmr),e(D,XT),e(XT,NEe),e(NEe,zmr),e(XT,Qmr),e(XT,IJ),e(IJ,Wmr),e(XT,Umr),e(D,Hmr),e(D,zT),e(zT,qEe),e(qEe,Jmr),e(zT,Ymr),e(zT,NJ),e(NJ,Zmr),e(zT,Kmr),e(D,ecr),e(D,QT),e(QT,DEe),e(DEe,ocr),e(QT,rcr),e(QT,qJ),e(qJ,tcr),e(QT,acr),e(D,ncr),e(D,WT),e(WT,jEe),e(jEe,scr),e(WT,lcr),e(WT,DJ),e(DJ,icr),e(WT,dcr),e(D,mcr),e(D,UT),e(UT,GEe),e(GEe,ccr),e(UT,fcr),e(UT,jJ),e(jJ,gcr),e(UT,hcr),e(D,ucr),e(D,HT),e(HT,OEe),e(OEe,pcr),e(HT,_cr),e(HT,GJ),e(GJ,bcr),e(HT,vcr),e(D,Fcr),e(D,JT),e(JT,VEe),e(VEe,Tcr),e(JT,Mcr),e(JT,OJ),e(OJ,Ecr),e(JT,Ccr),e(D,wcr),e(D,YT),e(YT,XEe),e(XEe,Acr),e(YT,Lcr),e(YT,VJ),e(VJ,ycr),e(YT,xcr),e(D,$cr),e(D,ZT),e(ZT,zEe),e(zEe,kcr),e(ZT,Scr),e(ZT,XJ),e(XJ,Rcr),e(ZT,Pcr),e(D,Bcr),e(D,KT),e(KT,QEe),e(QEe,Icr),e(KT,Ncr),e(KT,zJ),e(zJ,qcr),e(KT,Dcr),e(D,jcr),e(D,eM),e(eM,WEe),e(WEe,Gcr),e(eM,Ocr),e(eM,QJ),e(QJ,Vcr),e(eM,Xcr),e(D,zcr),e(D,oM),e(oM,UEe),e(UEe,Qcr),e(oM,Wcr),e(oM,WJ),e(WJ,Ucr),e(oM,Hcr),e(D,Jcr),e(D,rM),e(rM,HEe),e(HEe,Ycr),e(rM,Zcr),e(rM,UJ),e(UJ,Kcr),e(rM,efr),e(D,ofr),e(D,tM),e(tM,JEe),e(JEe,rfr),e(tM,tfr),e(tM,HJ),e(HJ,afr),e(tM,nfr),e(D,sfr),e(D,aM),e(aM,YEe),e(YEe,lfr),e(aM,ifr),e(aM,JJ),e(JJ,dfr),e(aM,mfr),e(D,cfr),e(D,nM),e(nM,ZEe),e(ZEe,ffr),e(nM,gfr),e(nM,YJ),e(YJ,hfr),e(nM,ufr),e(D,pfr),e(D,sM),e(sM,KEe),e(KEe,_fr),e(sM,bfr),e(sM,ZJ),e(ZJ,vfr),e(sM,Ffr),e(D,Tfr),e(D,lM),e(lM,e4e),e(e4e,Mfr),e(lM,Efr),e(lM,KJ),e(KJ,Cfr),e(lM,wfr),e(D,Afr),e(D,iM),e(iM,o4e),e(o4e,Lfr),e(iM,yfr),e(iM,eY),e(eY,xfr),e(iM,$fr),e(D,kfr),e(D,dM),e(dM,r4e),e(r4e,Sfr),e(dM,Rfr),e(dM,oY),e(oY,Pfr),e(dM,Bfr),e(D,Ifr),e(D,mM),e(mM,t4e),e(t4e,Nfr),e(mM,qfr),e(mM,rY),e(rY,Dfr),e(mM,jfr),e(D,Gfr),e(D,cM),e(cM,a4e),e(a4e,Ofr),e(cM,Vfr),e(cM,tY),e(tY,Xfr),e(cM,zfr),e(D,Qfr),e(D,fM),e(fM,n4e),e(n4e,Wfr),e(fM,Ufr),e(fM,aY),e(aY,Hfr),e(fM,Jfr),e(D,Yfr),e(D,gM),e(gM,s4e),e(s4e,Zfr),e(gM,Kfr),e(gM,nY),e(nY,egr),e(gM,ogr),e(D,rgr),e(D,hM),e(hM,l4e),e(l4e,tgr),e(hM,agr),e(hM,sY),e(sY,ngr),e(hM,sgr),e(D,lgr),e(D,uM),e(uM,i4e),e(i4e,igr),e(uM,dgr),e(uM,lY),e(lY,mgr),e(uM,cgr),e(no,fgr),e(no,pM),e(pM,ggr),e(pM,d4e),e(d4e,hgr),e(pM,ugr),e(pM,m4e),e(m4e,pgr),e(no,_gr),M(_M,no,null),b(c,rao,_),b(c,Kd,_),e(Kd,bM),e(bM,c4e),M(bk,c4e,null),e(Kd,bgr),e(Kd,f4e),e(f4e,vgr),b(c,tao,_),b(c,Vo,_),M(vk,Vo,null),e(Vo,Fgr),e(Vo,em),e(em,Tgr),e(em,iY),e(iY,Mgr),e(em,Egr),e(em,dY),e(dY,Cgr),e(em,wgr),e(Vo,Agr),e(Vo,Fk),e(Fk,Lgr),e(Fk,g4e),e(g4e,ygr),e(Fk,xgr),e(Vo,$gr),e(Vo,xt),M(Tk,xt,null),e(xt,kgr),e(xt,h4e),e(h4e,Sgr),e(xt,Rgr),e(xt,om),e(om,Pgr),e(om,u4e),e(u4e,Bgr),e(om,Igr),e(om,mY),e(mY,Ngr),e(om,qgr),e(xt,Dgr),M(vM,xt,null),e(Vo,jgr),e(Vo,so),M(Mk,so,null),e(so,Ggr),e(so,p4e),e(p4e,Ogr),e(so,Vgr),e(so,gn),e(gn,Xgr),e(gn,_4e),e(_4e,zgr),e(gn,Qgr),e(gn,b4e),e(b4e,Wgr),e(gn,Ugr),e(gn,v4e),e(v4e,Hgr),e(gn,Jgr),e(so,Ygr),e(so,K),e(K,FM),e(FM,F4e),e(F4e,Zgr),e(FM,Kgr),e(FM,cY),e(cY,ehr),e(FM,ohr),e(K,rhr),e(K,TM),e(TM,T4e),e(T4e,thr),e(TM,ahr),e(TM,fY),e(fY,nhr),e(TM,shr),e(K,lhr),e(K,MM),e(MM,M4e),e(M4e,ihr),e(MM,dhr),e(MM,gY),e(gY,mhr),e(MM,chr),e(K,fhr),e(K,EM),e(EM,E4e),e(E4e,ghr),e(EM,hhr),e(EM,hY),e(hY,uhr),e(EM,phr),e(K,_hr),e(K,CM),e(CM,C4e),e(C4e,bhr),e(CM,vhr),e(CM,uY),e(uY,Fhr),e(CM,Thr),e(K,Mhr),e(K,wM),e(wM,w4e),e(w4e,Ehr),e(wM,Chr),e(wM,pY),e(pY,whr),e(wM,Ahr),e(K,Lhr),e(K,AM),e(AM,A4e),e(A4e,yhr),e(AM,xhr),e(AM,_Y),e(_Y,$hr),e(AM,khr),e(K,Shr),e(K,LM),e(LM,L4e),e(L4e,Rhr),e(LM,Phr),e(LM,bY),e(bY,Bhr),e(LM,Ihr),e(K,Nhr),e(K,yM),e(yM,y4e),e(y4e,qhr),e(yM,Dhr),e(yM,vY),e(vY,jhr),e(yM,Ghr),e(K,Ohr),e(K,xM),e(xM,x4e),e(x4e,Vhr),e(xM,Xhr),e(xM,FY),e(FY,zhr),e(xM,Qhr),e(K,Whr),e(K,$M),e($M,$4e),e($4e,Uhr),e($M,Hhr),e($M,TY),e(TY,Jhr),e($M,Yhr),e(K,Zhr),e(K,kM),e(kM,k4e),e(k4e,Khr),e(kM,eur),e(kM,MY),e(MY,our),e(kM,rur),e(K,tur),e(K,SM),e(SM,S4e),e(S4e,aur),e(SM,nur),e(SM,EY),e(EY,sur),e(SM,lur),e(K,iur),e(K,RM),e(RM,R4e),e(R4e,dur),e(RM,mur),e(RM,CY),e(CY,cur),e(RM,fur),e(K,gur),e(K,PM),e(PM,P4e),e(P4e,hur),e(PM,uur),e(PM,wY),e(wY,pur),e(PM,_ur),e(K,bur),e(K,BM),e(BM,B4e),e(B4e,vur),e(BM,Fur),e(BM,AY),e(AY,Tur),e(BM,Mur),e(K,Eur),e(K,IM),e(IM,I4e),e(I4e,Cur),e(IM,wur),e(IM,LY),e(LY,Aur),e(IM,Lur),e(K,yur),e(K,NM),e(NM,N4e),e(N4e,xur),e(NM,$ur),e(NM,yY),e(yY,kur),e(NM,Sur),e(K,Rur),e(K,qM),e(qM,q4e),e(q4e,Pur),e(qM,Bur),e(qM,xY),e(xY,Iur),e(qM,Nur),e(K,qur),e(K,DM),e(DM,D4e),e(D4e,Dur),e(DM,jur),e(DM,$Y),e($Y,Gur),e(DM,Our),e(K,Vur),e(K,jM),e(jM,j4e),e(j4e,Xur),e(jM,zur),e(jM,kY),e(kY,Qur),e(jM,Wur),e(K,Uur),e(K,GM),e(GM,G4e),e(G4e,Hur),e(GM,Jur),e(GM,SY),e(SY,Yur),e(GM,Zur),e(K,Kur),e(K,OM),e(OM,O4e),e(O4e,epr),e(OM,opr),e(OM,RY),e(RY,rpr),e(OM,tpr),e(K,apr),e(K,VM),e(VM,V4e),e(V4e,npr),e(VM,spr),e(VM,PY),e(PY,lpr),e(VM,ipr),e(K,dpr),e(K,XM),e(XM,X4e),e(X4e,mpr),e(XM,cpr),e(XM,BY),e(BY,fpr),e(XM,gpr),e(K,hpr),e(K,zM),e(zM,z4e),e(z4e,upr),e(zM,ppr),e(zM,IY),e(IY,_pr),e(zM,bpr),e(K,vpr),e(K,QM),e(QM,Q4e),e(Q4e,Fpr),e(QM,Tpr),e(QM,NY),e(NY,Mpr),e(QM,Epr),e(K,Cpr),e(K,WM),e(WM,W4e),e(W4e,wpr),e(WM,Apr),e(WM,qY),e(qY,Lpr),e(WM,ypr),e(K,xpr),e(K,UM),e(UM,U4e),e(U4e,$pr),e(UM,kpr),e(UM,DY),e(DY,Spr),e(UM,Rpr),e(K,Ppr),e(K,HM),e(HM,H4e),e(H4e,Bpr),e(HM,Ipr),e(HM,jY),e(jY,Npr),e(HM,qpr),e(K,Dpr),e(K,JM),e(JM,J4e),e(J4e,jpr),e(JM,Gpr),e(JM,GY),e(GY,Opr),e(JM,Vpr),e(K,Xpr),e(K,YM),e(YM,Y4e),e(Y4e,zpr),e(YM,Qpr),e(YM,OY),e(OY,Wpr),e(YM,Upr),e(so,Hpr),e(so,ZM),e(ZM,Jpr),e(ZM,Z4e),e(Z4e,Ypr),e(ZM,Zpr),e(ZM,K4e),e(K4e,Kpr),e(so,e_r),M(KM,so,null),b(c,aao,_),b(c,rm,_),e(rm,eE),e(eE,eCe),M(Ek,eCe,null),e(rm,o_r),e(rm,oCe),e(oCe,r_r),b(c,nao,_),b(c,Xo,_),M(Ck,Xo,null),e(Xo,t_r),e(Xo,tm),e(tm,a_r),e(tm,VY),e(VY,n_r),e(tm,s_r),e(tm,XY),e(XY,l_r),e(tm,i_r),e(Xo,d_r),e(Xo,wk),e(wk,m_r),e(wk,rCe),e(rCe,c_r),e(wk,f_r),e(Xo,g_r),e(Xo,$t),M(Ak,$t,null),e($t,h_r),e($t,tCe),e(tCe,u_r),e($t,p_r),e($t,am),e(am,__r),e(am,aCe),e(aCe,b_r),e(am,v_r),e(am,zY),e(zY,F_r),e(am,T_r),e($t,M_r),M(oE,$t,null),e(Xo,E_r),e(Xo,lo),M(Lk,lo,null),e(lo,C_r),e(lo,nCe),e(nCe,w_r),e(lo,A_r),e(lo,hn),e(hn,L_r),e(hn,sCe),e(sCe,y_r),e(hn,x_r),e(hn,lCe),e(lCe,$_r),e(hn,k_r),e(hn,iCe),e(iCe,S_r),e(hn,R_r),e(lo,P_r),e(lo,Ue),e(Ue,rE),e(rE,dCe),e(dCe,B_r),e(rE,I_r),e(rE,QY),e(QY,N_r),e(rE,q_r),e(Ue,D_r),e(Ue,tE),e(tE,mCe),e(mCe,j_r),e(tE,G_r),e(tE,WY),e(WY,O_r),e(tE,V_r),e(Ue,X_r),e(Ue,aE),e(aE,cCe),e(cCe,z_r),e(aE,Q_r),e(aE,UY),e(UY,W_r),e(aE,U_r),e(Ue,H_r),e(Ue,nE),e(nE,fCe),e(fCe,J_r),e(nE,Y_r),e(nE,HY),e(HY,Z_r),e(nE,K_r),e(Ue,e1r),e(Ue,sE),e(sE,gCe),e(gCe,o1r),e(sE,r1r),e(sE,JY),e(JY,t1r),e(sE,a1r),e(Ue,n1r),e(Ue,lE),e(lE,hCe),e(hCe,s1r),e(lE,l1r),e(lE,YY),e(YY,i1r),e(lE,d1r),e(Ue,m1r),e(Ue,iE),e(iE,uCe),e(uCe,c1r),e(iE,f1r),e(iE,ZY),e(ZY,g1r),e(iE,h1r),e(lo,u1r),e(lo,dE),e(dE,p1r),e(dE,pCe),e(pCe,_1r),e(dE,b1r),e(dE,_Ce),e(_Ce,v1r),e(lo,F1r),M(mE,lo,null),b(c,sao,_),b(c,nm,_),e(nm,cE),e(cE,bCe),M(yk,bCe,null),e(nm,T1r),e(nm,vCe),e(vCe,M1r),b(c,lao,_),b(c,zo,_),M(xk,zo,null),e(zo,E1r),e(zo,sm),e(sm,C1r),e(sm,KY),e(KY,w1r),e(sm,A1r),e(sm,eZ),e(eZ,L1r),e(sm,y1r),e(zo,x1r),e(zo,$k),e($k,$1r),e($k,FCe),e(FCe,k1r),e($k,S1r),e(zo,R1r),e(zo,kt),M(kk,kt,null),e(kt,P1r),e(kt,TCe),e(TCe,B1r),e(kt,I1r),e(kt,lm),e(lm,N1r),e(lm,MCe),e(MCe,q1r),e(lm,D1r),e(lm,oZ),e(oZ,j1r),e(lm,G1r),e(kt,O1r),M(fE,kt,null),e(zo,V1r),e(zo,io),M(Sk,io,null),e(io,X1r),e(io,ECe),e(ECe,z1r),e(io,Q1r),e(io,un),e(un,W1r),e(un,CCe),e(CCe,U1r),e(un,H1r),e(un,wCe),e(wCe,J1r),e(un,Y1r),e(un,ACe),e(ACe,Z1r),e(un,K1r),e(io,e2r),e(io,U),e(U,gE),e(gE,LCe),e(LCe,o2r),e(gE,r2r),e(gE,rZ),e(rZ,t2r),e(gE,a2r),e(U,n2r),e(U,hE),e(hE,yCe),e(yCe,s2r),e(hE,l2r),e(hE,tZ),e(tZ,i2r),e(hE,d2r),e(U,m2r),e(U,uE),e(uE,xCe),e(xCe,c2r),e(uE,f2r),e(uE,aZ),e(aZ,g2r),e(uE,h2r),e(U,u2r),e(U,pE),e(pE,$Ce),e($Ce,p2r),e(pE,_2r),e(pE,nZ),e(nZ,b2r),e(pE,v2r),e(U,F2r),e(U,_E),e(_E,kCe),e(kCe,T2r),e(_E,M2r),e(_E,sZ),e(sZ,E2r),e(_E,C2r),e(U,w2r),e(U,bE),e(bE,SCe),e(SCe,A2r),e(bE,L2r),e(bE,lZ),e(lZ,y2r),e(bE,x2r),e(U,$2r),e(U,vE),e(vE,RCe),e(RCe,k2r),e(vE,S2r),e(vE,iZ),e(iZ,R2r),e(vE,P2r),e(U,B2r),e(U,FE),e(FE,PCe),e(PCe,I2r),e(FE,N2r),e(FE,dZ),e(dZ,q2r),e(FE,D2r),e(U,j2r),e(U,TE),e(TE,BCe),e(BCe,G2r),e(TE,O2r),e(TE,mZ),e(mZ,V2r),e(TE,X2r),e(U,z2r),e(U,ME),e(ME,ICe),e(ICe,Q2r),e(ME,W2r),e(ME,cZ),e(cZ,U2r),e(ME,H2r),e(U,J2r),e(U,EE),e(EE,NCe),e(NCe,Y2r),e(EE,Z2r),e(EE,fZ),e(fZ,K2r),e(EE,ebr),e(U,obr),e(U,CE),e(CE,qCe),e(qCe,rbr),e(CE,tbr),e(CE,gZ),e(gZ,abr),e(CE,nbr),e(U,sbr),e(U,wE),e(wE,DCe),e(DCe,lbr),e(wE,ibr),e(wE,hZ),e(hZ,dbr),e(wE,mbr),e(U,cbr),e(U,AE),e(AE,jCe),e(jCe,fbr),e(AE,gbr),e(AE,uZ),e(uZ,hbr),e(AE,ubr),e(U,pbr),e(U,LE),e(LE,GCe),e(GCe,_br),e(LE,bbr),e(LE,pZ),e(pZ,vbr),e(LE,Fbr),e(U,Tbr),e(U,yE),e(yE,OCe),e(OCe,Mbr),e(yE,Ebr),e(yE,_Z),e(_Z,Cbr),e(yE,wbr),e(U,Abr),e(U,xE),e(xE,VCe),e(VCe,Lbr),e(xE,ybr),e(xE,bZ),e(bZ,xbr),e(xE,$br),e(U,kbr),e(U,$E),e($E,XCe),e(XCe,Sbr),e($E,Rbr),e($E,vZ),e(vZ,Pbr),e($E,Bbr),e(U,Ibr),e(U,kE),e(kE,zCe),e(zCe,Nbr),e(kE,qbr),e(kE,FZ),e(FZ,Dbr),e(kE,jbr),e(U,Gbr),e(U,SE),e(SE,QCe),e(QCe,Obr),e(SE,Vbr),e(SE,TZ),e(TZ,Xbr),e(SE,zbr),e(U,Qbr),e(U,RE),e(RE,WCe),e(WCe,Wbr),e(RE,Ubr),e(RE,MZ),e(MZ,Hbr),e(RE,Jbr),e(U,Ybr),e(U,PE),e(PE,UCe),e(UCe,Zbr),e(PE,Kbr),e(PE,EZ),e(EZ,evr),e(PE,ovr),e(U,rvr),e(U,BE),e(BE,HCe),e(HCe,tvr),e(BE,avr),e(BE,CZ),e(CZ,nvr),e(BE,svr),e(U,lvr),e(U,IE),e(IE,JCe),e(JCe,ivr),e(IE,dvr),e(IE,wZ),e(wZ,mvr),e(IE,cvr),e(U,fvr),e(U,NE),e(NE,YCe),e(YCe,gvr),e(NE,hvr),e(NE,AZ),e(AZ,uvr),e(NE,pvr),e(U,_vr),e(U,qE),e(qE,ZCe),e(ZCe,bvr),e(qE,vvr),e(qE,LZ),e(LZ,Fvr),e(qE,Tvr),e(U,Mvr),e(U,DE),e(DE,KCe),e(KCe,Evr),e(DE,Cvr),e(DE,yZ),e(yZ,wvr),e(DE,Avr),e(U,Lvr),e(U,jE),e(jE,e3e),e(e3e,yvr),e(jE,xvr),e(jE,xZ),e(xZ,$vr),e(jE,kvr),e(U,Svr),e(U,GE),e(GE,o3e),e(o3e,Rvr),e(GE,Pvr),e(GE,$Z),e($Z,Bvr),e(GE,Ivr),e(U,Nvr),e(U,OE),e(OE,r3e),e(r3e,qvr),e(OE,Dvr),e(OE,kZ),e(kZ,jvr),e(OE,Gvr),e(U,Ovr),e(U,VE),e(VE,t3e),e(t3e,Vvr),e(VE,Xvr),e(VE,SZ),e(SZ,zvr),e(VE,Qvr),e(U,Wvr),e(U,XE),e(XE,a3e),e(a3e,Uvr),e(XE,Hvr),e(XE,RZ),e(RZ,Jvr),e(XE,Yvr),e(U,Zvr),e(U,zE),e(zE,n3e),e(n3e,Kvr),e(zE,eFr),e(zE,PZ),e(PZ,oFr),e(zE,rFr),e(U,tFr),e(U,QE),e(QE,s3e),e(s3e,aFr),e(QE,nFr),e(QE,BZ),e(BZ,sFr),e(QE,lFr),e(U,iFr),e(U,WE),e(WE,l3e),e(l3e,dFr),e(WE,mFr),e(WE,IZ),e(IZ,cFr),e(WE,fFr),e(U,gFr),e(U,UE),e(UE,i3e),e(i3e,hFr),e(UE,uFr),e(UE,NZ),e(NZ,pFr),e(UE,_Fr),e(U,bFr),e(U,HE),e(HE,d3e),e(d3e,vFr),e(HE,FFr),e(HE,qZ),e(qZ,TFr),e(HE,MFr),e(U,EFr),e(U,JE),e(JE,m3e),e(m3e,CFr),e(JE,wFr),e(JE,DZ),e(DZ,AFr),e(JE,LFr),e(U,yFr),e(U,YE),e(YE,c3e),e(c3e,xFr),e(YE,$Fr),e(YE,jZ),e(jZ,kFr),e(YE,SFr),e(U,RFr),e(U,ZE),e(ZE,f3e),e(f3e,PFr),e(ZE,BFr),e(ZE,GZ),e(GZ,IFr),e(ZE,NFr),e(U,qFr),e(U,KE),e(KE,g3e),e(g3e,DFr),e(KE,jFr),e(KE,OZ),e(OZ,GFr),e(KE,OFr),e(io,VFr),e(io,e4),e(e4,XFr),e(e4,h3e),e(h3e,zFr),e(e4,QFr),e(e4,u3e),e(u3e,WFr),e(io,UFr),M(o4,io,null),b(c,iao,_),b(c,im,_),e(im,r4),e(r4,p3e),M(Rk,p3e,null),e(im,HFr),e(im,_3e),e(_3e,JFr),b(c,dao,_),b(c,Qo,_),M(Pk,Qo,null),e(Qo,YFr),e(Qo,dm),e(dm,ZFr),e(dm,VZ),e(VZ,KFr),e(dm,eTr),e(dm,XZ),e(XZ,oTr),e(dm,rTr),e(Qo,tTr),e(Qo,Bk),e(Bk,aTr),e(Bk,b3e),e(b3e,nTr),e(Bk,sTr),e(Qo,lTr),e(Qo,St),M(Ik,St,null),e(St,iTr),e(St,v3e),e(v3e,dTr),e(St,mTr),e(St,mm),e(mm,cTr),e(mm,F3e),e(F3e,fTr),e(mm,gTr),e(mm,zZ),e(zZ,hTr),e(mm,uTr),e(St,pTr),M(t4,St,null),e(Qo,_Tr),e(Qo,mo),M(Nk,mo,null),e(mo,bTr),e(mo,T3e),e(T3e,vTr),e(mo,FTr),e(mo,pn),e(pn,TTr),e(pn,M3e),e(M3e,MTr),e(pn,ETr),e(pn,E3e),e(E3e,CTr),e(pn,wTr),e(pn,C3e),e(C3e,ATr),e(pn,LTr),e(mo,yTr),e(mo,O),e(O,a4),e(a4,w3e),e(w3e,xTr),e(a4,$Tr),e(a4,QZ),e(QZ,kTr),e(a4,STr),e(O,RTr),e(O,n4),e(n4,A3e),e(A3e,PTr),e(n4,BTr),e(n4,WZ),e(WZ,ITr),e(n4,NTr),e(O,qTr),e(O,s4),e(s4,L3e),e(L3e,DTr),e(s4,jTr),e(s4,UZ),e(UZ,GTr),e(s4,OTr),e(O,VTr),e(O,l4),e(l4,y3e),e(y3e,XTr),e(l4,zTr),e(l4,HZ),e(HZ,QTr),e(l4,WTr),e(O,UTr),e(O,i4),e(i4,x3e),e(x3e,HTr),e(i4,JTr),e(i4,JZ),e(JZ,YTr),e(i4,ZTr),e(O,KTr),e(O,d4),e(d4,$3e),e($3e,eMr),e(d4,oMr),e(d4,YZ),e(YZ,rMr),e(d4,tMr),e(O,aMr),e(O,m4),e(m4,k3e),e(k3e,nMr),e(m4,sMr),e(m4,ZZ),e(ZZ,lMr),e(m4,iMr),e(O,dMr),e(O,c4),e(c4,S3e),e(S3e,mMr),e(c4,cMr),e(c4,KZ),e(KZ,fMr),e(c4,gMr),e(O,hMr),e(O,f4),e(f4,R3e),e(R3e,uMr),e(f4,pMr),e(f4,eK),e(eK,_Mr),e(f4,bMr),e(O,vMr),e(O,g4),e(g4,P3e),e(P3e,FMr),e(g4,TMr),e(g4,oK),e(oK,MMr),e(g4,EMr),e(O,CMr),e(O,h4),e(h4,B3e),e(B3e,wMr),e(h4,AMr),e(h4,rK),e(rK,LMr),e(h4,yMr),e(O,xMr),e(O,u4),e(u4,I3e),e(I3e,$Mr),e(u4,kMr),e(u4,tK),e(tK,SMr),e(u4,RMr),e(O,PMr),e(O,p4),e(p4,N3e),e(N3e,BMr),e(p4,IMr),e(p4,aK),e(aK,NMr),e(p4,qMr),e(O,DMr),e(O,_4),e(_4,q3e),e(q3e,jMr),e(_4,GMr),e(_4,nK),e(nK,OMr),e(_4,VMr),e(O,XMr),e(O,b4),e(b4,D3e),e(D3e,zMr),e(b4,QMr),e(b4,sK),e(sK,WMr),e(b4,UMr),e(O,HMr),e(O,v4),e(v4,j3e),e(j3e,JMr),e(v4,YMr),e(v4,lK),e(lK,ZMr),e(v4,KMr),e(O,eEr),e(O,F4),e(F4,G3e),e(G3e,oEr),e(F4,rEr),e(F4,iK),e(iK,tEr),e(F4,aEr),e(O,nEr),e(O,T4),e(T4,O3e),e(O3e,sEr),e(T4,lEr),e(T4,dK),e(dK,iEr),e(T4,dEr),e(O,mEr),e(O,M4),e(M4,V3e),e(V3e,cEr),e(M4,fEr),e(M4,mK),e(mK,gEr),e(M4,hEr),e(O,uEr),e(O,E4),e(E4,X3e),e(X3e,pEr),e(E4,_Er),e(E4,cK),e(cK,bEr),e(E4,vEr),e(O,FEr),e(O,C4),e(C4,z3e),e(z3e,TEr),e(C4,MEr),e(C4,fK),e(fK,EEr),e(C4,CEr),e(O,wEr),e(O,w4),e(w4,Q3e),e(Q3e,AEr),e(w4,LEr),e(w4,gK),e(gK,yEr),e(w4,xEr),e(O,$Er),e(O,A4),e(A4,W3e),e(W3e,kEr),e(A4,SEr),e(A4,hK),e(hK,REr),e(A4,PEr),e(O,BEr),e(O,L4),e(L4,U3e),e(U3e,IEr),e(L4,NEr),e(L4,uK),e(uK,qEr),e(L4,DEr),e(O,jEr),e(O,y4),e(y4,H3e),e(H3e,GEr),e(y4,OEr),e(y4,pK),e(pK,VEr),e(y4,XEr),e(O,zEr),e(O,x4),e(x4,J3e),e(J3e,QEr),e(x4,WEr),e(x4,_K),e(_K,UEr),e(x4,HEr),e(O,JEr),e(O,$4),e($4,Y3e),e(Y3e,YEr),e($4,ZEr),e($4,bK),e(bK,KEr),e($4,e4r),e(O,o4r),e(O,k4),e(k4,Z3e),e(Z3e,r4r),e(k4,t4r),e(k4,vK),e(vK,a4r),e(k4,n4r),e(O,s4r),e(O,S4),e(S4,K3e),e(K3e,l4r),e(S4,i4r),e(S4,FK),e(FK,d4r),e(S4,m4r),e(O,c4r),e(O,R4),e(R4,e5e),e(e5e,f4r),e(R4,g4r),e(R4,TK),e(TK,h4r),e(R4,u4r),e(O,p4r),e(O,P4),e(P4,o5e),e(o5e,_4r),e(P4,b4r),e(P4,MK),e(MK,v4r),e(P4,F4r),e(O,T4r),e(O,B4),e(B4,r5e),e(r5e,M4r),e(B4,E4r),e(B4,EK),e(EK,C4r),e(B4,w4r),e(O,A4r),e(O,I4),e(I4,t5e),e(t5e,L4r),e(I4,y4r),e(I4,CK),e(CK,x4r),e(I4,$4r),e(O,k4r),e(O,N4),e(N4,a5e),e(a5e,S4r),e(N4,R4r),e(N4,wK),e(wK,P4r),e(N4,B4r),e(O,I4r),e(O,q4),e(q4,n5e),e(n5e,N4r),e(q4,q4r),e(q4,AK),e(AK,D4r),e(q4,j4r),e(O,G4r),e(O,D4),e(D4,s5e),e(s5e,O4r),e(D4,V4r),e(D4,LK),e(LK,X4r),e(D4,z4r),e(O,Q4r),e(O,j4),e(j4,l5e),e(l5e,W4r),e(j4,U4r),e(j4,yK),e(yK,H4r),e(j4,J4r),e(O,Y4r),e(O,G4),e(G4,i5e),e(i5e,Z4r),e(G4,K4r),e(G4,xK),e(xK,eCr),e(G4,oCr),e(O,rCr),e(O,O4),e(O4,d5e),e(d5e,tCr),e(O4,aCr),e(O4,$K),e($K,nCr),e(O4,sCr),e(O,lCr),e(O,V4),e(V4,m5e),e(m5e,iCr),e(V4,dCr),e(V4,kK),e(kK,mCr),e(V4,cCr),e(O,fCr),e(O,X4),e(X4,c5e),e(c5e,gCr),e(X4,hCr),e(X4,SK),e(SK,uCr),e(X4,pCr),e(O,_Cr),e(O,z4),e(z4,f5e),e(f5e,bCr),e(z4,vCr),e(z4,RK),e(RK,FCr),e(z4,TCr),e(O,MCr),e(O,Q4),e(Q4,g5e),e(g5e,ECr),e(Q4,CCr),e(Q4,PK),e(PK,wCr),e(Q4,ACr),e(O,LCr),e(O,W4),e(W4,h5e),e(h5e,yCr),e(W4,xCr),e(W4,BK),e(BK,$Cr),e(W4,kCr),e(O,SCr),e(O,U4),e(U4,u5e),e(u5e,RCr),e(U4,PCr),e(U4,IK),e(IK,BCr),e(U4,ICr),e(O,NCr),e(O,H4),e(H4,p5e),e(p5e,qCr),e(H4,DCr),e(H4,NK),e(NK,jCr),e(H4,GCr),e(O,OCr),e(O,J4),e(J4,_5e),e(_5e,VCr),e(J4,XCr),e(J4,qK),e(qK,zCr),e(J4,QCr),e(O,WCr),e(O,Y4),e(Y4,b5e),e(b5e,UCr),e(Y4,HCr),e(Y4,DK),e(DK,JCr),e(Y4,YCr),e(mo,ZCr),e(mo,Z4),e(Z4,KCr),e(Z4,v5e),e(v5e,e3r),e(Z4,o3r),e(Z4,F5e),e(F5e,r3r),e(mo,t3r),M(K4,mo,null),b(c,mao,_),b(c,cm,_),e(cm,eC),e(eC,T5e),M(qk,T5e,null),e(cm,a3r),e(cm,M5e),e(M5e,n3r),b(c,cao,_),b(c,Wo,_),M(Dk,Wo,null),e(Wo,s3r),e(Wo,fm),e(fm,l3r),e(fm,jK),e(jK,i3r),e(fm,d3r),e(fm,GK),e(GK,m3r),e(fm,c3r),e(Wo,f3r),e(Wo,jk),e(jk,g3r),e(jk,E5e),e(E5e,h3r),e(jk,u3r),e(Wo,p3r),e(Wo,Rt),M(Gk,Rt,null),e(Rt,_3r),e(Rt,C5e),e(C5e,b3r),e(Rt,v3r),e(Rt,gm),e(gm,F3r),e(gm,w5e),e(w5e,T3r),e(gm,M3r),e(gm,OK),e(OK,E3r),e(gm,C3r),e(Rt,w3r),M(oC,Rt,null),e(Wo,A3r),e(Wo,co),M(Ok,co,null),e(co,L3r),e(co,A5e),e(A5e,y3r),e(co,x3r),e(co,_n),e(_n,$3r),e(_n,L5e),e(L5e,k3r),e(_n,S3r),e(_n,y5e),e(y5e,R3r),e(_n,P3r),e(_n,x5e),e(x5e,B3r),e(_n,I3r),e(co,N3r),e(co,$5e),e($5e,rC),e(rC,k5e),e(k5e,q3r),e(rC,D3r),e(rC,VK),e(VK,j3r),e(rC,G3r),e(co,O3r),e(co,tC),e(tC,V3r),e(tC,S5e),e(S5e,X3r),e(tC,z3r),e(tC,R5e),e(R5e,Q3r),e(co,W3r),M(aC,co,null),b(c,fao,_),b(c,hm,_),e(hm,nC),e(nC,P5e),M(Vk,P5e,null),e(hm,U3r),e(hm,B5e),e(B5e,H3r),b(c,gao,_),b(c,Uo,_),M(Xk,Uo,null),e(Uo,J3r),e(Uo,um),e(um,Y3r),e(um,XK),e(XK,Z3r),e(um,K3r),e(um,zK),e(zK,e5r),e(um,o5r),e(Uo,r5r),e(Uo,zk),e(zk,t5r),e(zk,I5e),e(I5e,a5r),e(zk,n5r),e(Uo,s5r),e(Uo,Pt),M(Qk,Pt,null),e(Pt,l5r),e(Pt,N5e),e(N5e,i5r),e(Pt,d5r),e(Pt,pm),e(pm,m5r),e(pm,q5e),e(q5e,c5r),e(pm,f5r),e(pm,QK),e(QK,g5r),e(pm,h5r),e(Pt,u5r),M(sC,Pt,null),e(Uo,p5r),e(Uo,fo),M(Wk,fo,null),e(fo,_5r),e(fo,D5e),e(D5e,b5r),e(fo,v5r),e(fo,bn),e(bn,F5r),e(bn,j5e),e(j5e,T5r),e(bn,M5r),e(bn,G5e),e(G5e,E5r),e(bn,C5r),e(bn,O5e),e(O5e,w5r),e(bn,A5r),e(fo,L5r),e(fo,_m),e(_m,lC),e(lC,V5e),e(V5e,y5r),e(lC,x5r),e(lC,WK),e(WK,$5r),e(lC,k5r),e(_m,S5r),e(_m,iC),e(iC,X5e),e(X5e,R5r),e(iC,P5r),e(iC,UK),e(UK,B5r),e(iC,I5r),e(_m,N5r),e(_m,dC),e(dC,z5e),e(z5e,q5r),e(dC,D5r),e(dC,HK),e(HK,j5r),e(dC,G5r),e(fo,O5r),e(fo,mC),e(mC,V5r),e(mC,Q5e),e(Q5e,X5r),e(mC,z5r),e(mC,W5e),e(W5e,Q5r),e(fo,W5r),M(cC,fo,null),b(c,hao,_),b(c,bm,_),e(bm,fC),e(fC,U5e),M(Uk,U5e,null),e(bm,U5r),e(bm,H5e),e(H5e,H5r),b(c,uao,_),b(c,Ho,_),M(Hk,Ho,null),e(Ho,J5r),e(Ho,vm),e(vm,Y5r),e(vm,JK),e(JK,Z5r),e(vm,K5r),e(vm,YK),e(YK,e0r),e(vm,o0r),e(Ho,r0r),e(Ho,Jk),e(Jk,t0r),e(Jk,J5e),e(J5e,a0r),e(Jk,n0r),e(Ho,s0r),e(Ho,Bt),M(Yk,Bt,null),e(Bt,l0r),e(Bt,Y5e),e(Y5e,i0r),e(Bt,d0r),e(Bt,Fm),e(Fm,m0r),e(Fm,Z5e),e(Z5e,c0r),e(Fm,f0r),e(Fm,ZK),e(ZK,g0r),e(Fm,h0r),e(Bt,u0r),M(gC,Bt,null),e(Ho,p0r),e(Ho,go),M(Zk,go,null),e(go,_0r),e(go,K5e),e(K5e,b0r),e(go,v0r),e(go,vn),e(vn,F0r),e(vn,e0e),e(e0e,T0r),e(vn,M0r),e(vn,o0e),e(o0e,E0r),e(vn,C0r),e(vn,r0e),e(r0e,w0r),e(vn,A0r),e(go,L0r),e(go,be),e(be,hC),e(hC,t0e),e(t0e,y0r),e(hC,x0r),e(hC,KK),e(KK,$0r),e(hC,k0r),e(be,S0r),e(be,uC),e(uC,a0e),e(a0e,R0r),e(uC,P0r),e(uC,eee),e(eee,B0r),e(uC,I0r),e(be,N0r),e(be,pC),e(pC,n0e),e(n0e,q0r),e(pC,D0r),e(pC,oee),e(oee,j0r),e(pC,G0r),e(be,O0r),e(be,_C),e(_C,s0e),e(s0e,V0r),e(_C,X0r),e(_C,ree),e(ree,z0r),e(_C,Q0r),e(be,W0r),e(be,$l),e($l,l0e),e(l0e,U0r),e($l,H0r),e($l,tee),e(tee,J0r),e($l,Y0r),e($l,aee),e(aee,Z0r),e($l,K0r),e(be,ewr),e(be,bC),e(bC,i0e),e(i0e,owr),e(bC,rwr),e(bC,nee),e(nee,twr),e(bC,awr),e(be,nwr),e(be,kl),e(kl,d0e),e(d0e,swr),e(kl,lwr),e(kl,see),e(see,iwr),e(kl,dwr),e(kl,lee),e(lee,mwr),e(kl,cwr),e(be,fwr),e(be,vC),e(vC,m0e),e(m0e,gwr),e(vC,hwr),e(vC,iee),e(iee,uwr),e(vC,pwr),e(be,_wr),e(be,It),e(It,c0e),e(c0e,bwr),e(It,vwr),e(It,dee),e(dee,Fwr),e(It,Twr),e(It,mee),e(mee,Mwr),e(It,Ewr),e(It,cee),e(cee,Cwr),e(It,wwr),e(be,Awr),e(be,FC),e(FC,f0e),e(f0e,Lwr),e(FC,ywr),e(FC,fee),e(fee,xwr),e(FC,$wr),e(be,kwr),e(be,TC),e(TC,g0e),e(g0e,Swr),e(TC,Rwr),e(TC,gee),e(gee,Pwr),e(TC,Bwr),e(be,Iwr),e(be,MC),e(MC,h0e),e(h0e,Nwr),e(MC,qwr),e(MC,hee),e(hee,Dwr),e(MC,jwr),e(be,Gwr),e(be,EC),e(EC,u0e),e(u0e,Owr),e(EC,Vwr),e(EC,uee),e(uee,Xwr),e(EC,zwr),e(be,Qwr),e(be,CC),e(CC,p0e),e(p0e,Wwr),e(CC,Uwr),e(CC,pee),e(pee,Hwr),e(CC,Jwr),e(be,Ywr),e(be,wC),e(wC,_0e),e(_0e,Zwr),e(wC,Kwr),e(wC,_ee),e(_ee,eAr),e(wC,oAr),e(be,rAr),e(be,AC),e(AC,b0e),e(b0e,tAr),e(AC,aAr),e(AC,bee),e(bee,nAr),e(AC,sAr),e(be,lAr),e(be,LC),e(LC,v0e),e(v0e,iAr),e(LC,dAr),e(LC,vee),e(vee,mAr),e(LC,cAr),e(be,fAr),e(be,yC),e(yC,F0e),e(F0e,gAr),e(yC,hAr),e(yC,Fee),e(Fee,uAr),e(yC,pAr),e(go,_Ar),e(go,xC),e(xC,bAr),e(xC,T0e),e(T0e,vAr),e(xC,FAr),e(xC,M0e),e(M0e,TAr),e(go,MAr),M($C,go,null),b(c,pao,_),b(c,Tm,_),e(Tm,kC),e(kC,E0e),M(Kk,E0e,null),e(Tm,EAr),e(Tm,C0e),e(C0e,CAr),b(c,_ao,_),b(c,Jo,_),M(eS,Jo,null),e(Jo,wAr),e(Jo,Mm),e(Mm,AAr),e(Mm,Tee),e(Tee,LAr),e(Mm,yAr),e(Mm,Mee),e(Mee,xAr),e(Mm,$Ar),e(Jo,kAr),e(Jo,oS),e(oS,SAr),e(oS,w0e),e(w0e,RAr),e(oS,PAr),e(Jo,BAr),e(Jo,Nt),M(rS,Nt,null),e(Nt,IAr),e(Nt,A0e),e(A0e,NAr),e(Nt,qAr),e(Nt,Em),e(Em,DAr),e(Em,L0e),e(L0e,jAr),e(Em,GAr),e(Em,Eee),e(Eee,OAr),e(Em,VAr),e(Nt,XAr),M(SC,Nt,null),e(Jo,zAr),e(Jo,ho),M(tS,ho,null),e(ho,QAr),e(ho,y0e),e(y0e,WAr),e(ho,UAr),e(ho,Fn),e(Fn,HAr),e(Fn,x0e),e(x0e,JAr),e(Fn,YAr),e(Fn,$0e),e($0e,ZAr),e(Fn,KAr),e(Fn,k0e),e(k0e,e6r),e(Fn,o6r),e(ho,r6r),e(ho,S0e),e(S0e,RC),e(RC,R0e),e(R0e,t6r),e(RC,a6r),e(RC,Cee),e(Cee,n6r),e(RC,s6r),e(ho,l6r),e(ho,PC),e(PC,i6r),e(PC,P0e),e(P0e,d6r),e(PC,m6r),e(PC,B0e),e(B0e,c6r),e(ho,f6r),M(BC,ho,null),b(c,bao,_),b(c,Cm,_),e(Cm,IC),e(IC,I0e),M(aS,I0e,null),e(Cm,g6r),e(Cm,N0e),e(N0e,h6r),b(c,vao,_),b(c,Yo,_),M(nS,Yo,null),e(Yo,u6r),e(Yo,wm),e(wm,p6r),e(wm,wee),e(wee,_6r),e(wm,b6r),e(wm,Aee),e(Aee,v6r),e(wm,F6r),e(Yo,T6r),e(Yo,sS),e(sS,M6r),e(sS,q0e),e(q0e,E6r),e(sS,C6r),e(Yo,w6r),e(Yo,qt),M(lS,qt,null),e(qt,A6r),e(qt,D0e),e(D0e,L6r),e(qt,y6r),e(qt,Am),e(Am,x6r),e(Am,j0e),e(j0e,$6r),e(Am,k6r),e(Am,Lee),e(Lee,S6r),e(Am,R6r),e(qt,P6r),M(NC,qt,null),e(Yo,B6r),e(Yo,uo),M(iS,uo,null),e(uo,I6r),e(uo,G0e),e(G0e,N6r),e(uo,q6r),e(uo,Tn),e(Tn,D6r),e(Tn,O0e),e(O0e,j6r),e(Tn,G6r),e(Tn,V0e),e(V0e,O6r),e(Tn,V6r),e(Tn,X0e),e(X0e,X6r),e(Tn,z6r),e(uo,Q6r),e(uo,z0e),e(z0e,qC),e(qC,Q0e),e(Q0e,W6r),e(qC,U6r),e(qC,yee),e(yee,H6r),e(qC,J6r),e(uo,Y6r),e(uo,DC),e(DC,Z6r),e(DC,W0e),e(W0e,K6r),e(DC,e7r),e(DC,U0e),e(U0e,o7r),e(uo,r7r),M(jC,uo,null),b(c,Fao,_),b(c,Lm,_),e(Lm,GC),e(GC,H0e),M(dS,H0e,null),e(Lm,t7r),e(Lm,J0e),e(J0e,a7r),b(c,Tao,_),b(c,Zo,_),M(mS,Zo,null),e(Zo,n7r),e(Zo,ym),e(ym,s7r),e(ym,xee),e(xee,l7r),e(ym,i7r),e(ym,$ee),e($ee,d7r),e(ym,m7r),e(Zo,c7r),e(Zo,cS),e(cS,f7r),e(cS,Y0e),e(Y0e,g7r),e(cS,h7r),e(Zo,u7r),e(Zo,Dt),M(fS,Dt,null),e(Dt,p7r),e(Dt,Z0e),e(Z0e,_7r),e(Dt,b7r),e(Dt,xm),e(xm,v7r),e(xm,K0e),e(K0e,F7r),e(xm,T7r),e(xm,kee),e(kee,M7r),e(xm,E7r),e(Dt,C7r),M(OC,Dt,null),e(Zo,w7r),e(Zo,po),M(gS,po,null),e(po,A7r),e(po,ewe),e(ewe,L7r),e(po,y7r),e(po,Mn),e(Mn,x7r),e(Mn,owe),e(owe,$7r),e(Mn,k7r),e(Mn,rwe),e(rwe,S7r),e(Mn,R7r),e(Mn,twe),e(twe,P7r),e(Mn,B7r),e(po,I7r),e(po,awe),e(awe,VC),e(VC,nwe),e(nwe,N7r),e(VC,q7r),e(VC,See),e(See,D7r),e(VC,j7r),e(po,G7r),e(po,XC),e(XC,O7r),e(XC,swe),e(swe,V7r),e(XC,X7r),e(XC,lwe),e(lwe,z7r),e(po,Q7r),M(zC,po,null),b(c,Mao,_),b(c,$m,_),e($m,QC),e(QC,iwe),M(hS,iwe,null),e($m,W7r),e($m,dwe),e(dwe,U7r),b(c,Eao,_),b(c,Ko,_),M(uS,Ko,null),e(Ko,H7r),e(Ko,km),e(km,J7r),e(km,Ree),e(Ree,Y7r),e(km,Z7r),e(km,Pee),e(Pee,K7r),e(km,e8r),e(Ko,o8r),e(Ko,pS),e(pS,r8r),e(pS,mwe),e(mwe,t8r),e(pS,a8r),e(Ko,n8r),e(Ko,jt),M(_S,jt,null),e(jt,s8r),e(jt,cwe),e(cwe,l8r),e(jt,i8r),e(jt,Sm),e(Sm,d8r),e(Sm,fwe),e(fwe,m8r),e(Sm,c8r),e(Sm,Bee),e(Bee,f8r),e(Sm,g8r),e(jt,h8r),M(WC,jt,null),e(Ko,u8r),e(Ko,_o),M(bS,_o,null),e(_o,p8r),e(_o,gwe),e(gwe,_8r),e(_o,b8r),e(_o,En),e(En,v8r),e(En,hwe),e(hwe,F8r),e(En,T8r),e(En,uwe),e(uwe,M8r),e(En,E8r),e(En,pwe),e(pwe,C8r),e(En,w8r),e(_o,A8r),e(_o,Be),e(Be,UC),e(UC,_we),e(_we,L8r),e(UC,y8r),e(UC,Iee),e(Iee,x8r),e(UC,$8r),e(Be,k8r),e(Be,HC),e(HC,bwe),e(bwe,S8r),e(HC,R8r),e(HC,Nee),e(Nee,P8r),e(HC,B8r),e(Be,I8r),e(Be,JC),e(JC,vwe),e(vwe,N8r),e(JC,q8r),e(JC,qee),e(qee,D8r),e(JC,j8r),e(Be,G8r),e(Be,YC),e(YC,Fwe),e(Fwe,O8r),e(YC,V8r),e(YC,Dee),e(Dee,X8r),e(YC,z8r),e(Be,Q8r),e(Be,ZC),e(ZC,Twe),e(Twe,W8r),e(ZC,U8r),e(ZC,jee),e(jee,H8r),e(ZC,J8r),e(Be,Y8r),e(Be,KC),e(KC,Mwe),e(Mwe,Z8r),e(KC,K8r),e(KC,Gee),e(Gee,eLr),e(KC,oLr),e(Be,rLr),e(Be,e3),e(e3,Ewe),e(Ewe,tLr),e(e3,aLr),e(e3,Oee),e(Oee,nLr),e(e3,sLr),e(Be,lLr),e(Be,o3),e(o3,Cwe),e(Cwe,iLr),e(o3,dLr),e(o3,Vee),e(Vee,mLr),e(o3,cLr),e(Be,fLr),e(Be,r3),e(r3,wwe),e(wwe,gLr),e(r3,hLr),e(r3,Xee),e(Xee,uLr),e(r3,pLr),e(_o,_Lr),e(_o,t3),e(t3,bLr),e(t3,Awe),e(Awe,vLr),e(t3,FLr),e(t3,Lwe),e(Lwe,TLr),e(_o,MLr),M(a3,_o,null),b(c,Cao,_),b(c,Rm,_),e(Rm,n3),e(n3,ywe),M(vS,ywe,null),e(Rm,ELr),e(Rm,xwe),e(xwe,CLr),b(c,wao,_),b(c,er,_),M(FS,er,null),e(er,wLr),e(er,Pm),e(Pm,ALr),e(Pm,zee),e(zee,LLr),e(Pm,yLr),e(Pm,Qee),e(Qee,xLr),e(Pm,$Lr),e(er,kLr),e(er,TS),e(TS,SLr),e(TS,$we),e($we,RLr),e(TS,PLr),e(er,BLr),e(er,Gt),M(MS,Gt,null),e(Gt,ILr),e(Gt,kwe),e(kwe,NLr),e(Gt,qLr),e(Gt,Bm),e(Bm,DLr),e(Bm,Swe),e(Swe,jLr),e(Bm,GLr),e(Bm,Wee),e(Wee,OLr),e(Bm,VLr),e(Gt,XLr),M(s3,Gt,null),e(er,zLr),e(er,bo),M(ES,bo,null),e(bo,QLr),e(bo,Rwe),e(Rwe,WLr),e(bo,ULr),e(bo,Cn),e(Cn,HLr),e(Cn,Pwe),e(Pwe,JLr),e(Cn,YLr),e(Cn,Bwe),e(Bwe,ZLr),e(Cn,KLr),e(Cn,Iwe),e(Iwe,eyr),e(Cn,oyr),e(bo,ryr),e(bo,ut),e(ut,l3),e(l3,Nwe),e(Nwe,tyr),e(l3,ayr),e(l3,Uee),e(Uee,nyr),e(l3,syr),e(ut,lyr),e(ut,i3),e(i3,qwe),e(qwe,iyr),e(i3,dyr),e(i3,Hee),e(Hee,myr),e(i3,cyr),e(ut,fyr),e(ut,d3),e(d3,Dwe),e(Dwe,gyr),e(d3,hyr),e(d3,Jee),e(Jee,uyr),e(d3,pyr),e(ut,_yr),e(ut,m3),e(m3,jwe),e(jwe,byr),e(m3,vyr),e(m3,Yee),e(Yee,Fyr),e(m3,Tyr),e(ut,Myr),e(ut,c3),e(c3,Gwe),e(Gwe,Eyr),e(c3,Cyr),e(c3,Zee),e(Zee,wyr),e(c3,Ayr),e(bo,Lyr),e(bo,f3),e(f3,yyr),e(f3,Owe),e(Owe,xyr),e(f3,$yr),e(f3,Vwe),e(Vwe,kyr),e(bo,Syr),M(g3,bo,null),b(c,Aao,_),b(c,Im,_),e(Im,h3),e(h3,Xwe),M(CS,Xwe,null),e(Im,Ryr),e(Im,zwe),e(zwe,Pyr),b(c,Lao,_),b(c,or,_),M(wS,or,null),e(or,Byr),e(or,Nm),e(Nm,Iyr),e(Nm,Kee),e(Kee,Nyr),e(Nm,qyr),e(Nm,eoe),e(eoe,Dyr),e(Nm,jyr),e(or,Gyr),e(or,AS),e(AS,Oyr),e(AS,Qwe),e(Qwe,Vyr),e(AS,Xyr),e(or,zyr),e(or,Ot),M(LS,Ot,null),e(Ot,Qyr),e(Ot,Wwe),e(Wwe,Wyr),e(Ot,Uyr),e(Ot,qm),e(qm,Hyr),e(qm,Uwe),e(Uwe,Jyr),e(qm,Yyr),e(qm,ooe),e(ooe,Zyr),e(qm,Kyr),e(Ot,e9r),M(u3,Ot,null),e(or,o9r),e(or,vo),M(yS,vo,null),e(vo,r9r),e(vo,Hwe),e(Hwe,t9r),e(vo,a9r),e(vo,wn),e(wn,n9r),e(wn,Jwe),e(Jwe,s9r),e(wn,l9r),e(wn,Ywe),e(Ywe,i9r),e(wn,d9r),e(wn,Zwe),e(Zwe,m9r),e(wn,c9r),e(vo,f9r),e(vo,Le),e(Le,p3),e(p3,Kwe),e(Kwe,g9r),e(p3,h9r),e(p3,roe),e(roe,u9r),e(p3,p9r),e(Le,_9r),e(Le,_3),e(_3,eAe),e(eAe,b9r),e(_3,v9r),e(_3,toe),e(toe,F9r),e(_3,T9r),e(Le,M9r),e(Le,b3),e(b3,oAe),e(oAe,E9r),e(b3,C9r),e(b3,aoe),e(aoe,w9r),e(b3,A9r),e(Le,L9r),e(Le,v3),e(v3,rAe),e(rAe,y9r),e(v3,x9r),e(v3,noe),e(noe,$9r),e(v3,k9r),e(Le,S9r),e(Le,F3),e(F3,tAe),e(tAe,R9r),e(F3,P9r),e(F3,soe),e(soe,B9r),e(F3,I9r),e(Le,N9r),e(Le,T3),e(T3,aAe),e(aAe,q9r),e(T3,D9r),e(T3,loe),e(loe,j9r),e(T3,G9r),e(Le,O9r),e(Le,M3),e(M3,nAe),e(nAe,V9r),e(M3,X9r),e(M3,ioe),e(ioe,z9r),e(M3,Q9r),e(Le,W9r),e(Le,E3),e(E3,sAe),e(sAe,U9r),e(E3,H9r),e(E3,doe),e(doe,J9r),e(E3,Y9r),e(Le,Z9r),e(Le,C3),e(C3,lAe),e(lAe,K9r),e(C3,exr),e(C3,moe),e(moe,oxr),e(C3,rxr),e(Le,txr),e(Le,w3),e(w3,iAe),e(iAe,axr),e(w3,nxr),e(w3,coe),e(coe,sxr),e(w3,lxr),e(vo,ixr),e(vo,A3),e(A3,dxr),e(A3,dAe),e(dAe,mxr),e(A3,cxr),e(A3,mAe),e(mAe,fxr),e(vo,gxr),M(L3,vo,null),b(c,yao,_),b(c,Dm,_),e(Dm,y3),e(y3,cAe),M(xS,cAe,null),e(Dm,hxr),e(Dm,fAe),e(fAe,uxr),b(c,xao,_),b(c,rr,_),M($S,rr,null),e(rr,pxr),e(rr,jm),e(jm,_xr),e(jm,foe),e(foe,bxr),e(jm,vxr),e(jm,goe),e(goe,Fxr),e(jm,Txr),e(rr,Mxr),e(rr,kS),e(kS,Exr),e(kS,gAe),e(gAe,Cxr),e(kS,wxr),e(rr,Axr),e(rr,Vt),M(SS,Vt,null),e(Vt,Lxr),e(Vt,hAe),e(hAe,yxr),e(Vt,xxr),e(Vt,Gm),e(Gm,$xr),e(Gm,uAe),e(uAe,kxr),e(Gm,Sxr),e(Gm,hoe),e(hoe,Rxr),e(Gm,Pxr),e(Vt,Bxr),M(x3,Vt,null),e(rr,Ixr),e(rr,Fo),M(RS,Fo,null),e(Fo,Nxr),e(Fo,pAe),e(pAe,qxr),e(Fo,Dxr),e(Fo,An),e(An,jxr),e(An,_Ae),e(_Ae,Gxr),e(An,Oxr),e(An,bAe),e(bAe,Vxr),e(An,Xxr),e(An,vAe),e(vAe,zxr),e(An,Qxr),e(Fo,Wxr),e(Fo,Om),e(Om,$3),e($3,FAe),e(FAe,Uxr),e($3,Hxr),e($3,uoe),e(uoe,Jxr),e($3,Yxr),e(Om,Zxr),e(Om,k3),e(k3,TAe),e(TAe,Kxr),e(k3,e$r),e(k3,poe),e(poe,o$r),e(k3,r$r),e(Om,t$r),e(Om,S3),e(S3,MAe),e(MAe,a$r),e(S3,n$r),e(S3,_oe),e(_oe,s$r),e(S3,l$r),e(Fo,i$r),e(Fo,R3),e(R3,d$r),e(R3,EAe),e(EAe,m$r),e(R3,c$r),e(R3,CAe),e(CAe,f$r),e(Fo,g$r),M(P3,Fo,null),b(c,$ao,_),b(c,Vm,_),e(Vm,B3),e(B3,wAe),M(PS,wAe,null),e(Vm,h$r),e(Vm,AAe),e(AAe,u$r),b(c,kao,_),b(c,tr,_),M(BS,tr,null),e(tr,p$r),e(tr,Xm),e(Xm,_$r),e(Xm,boe),e(boe,b$r),e(Xm,v$r),e(Xm,voe),e(voe,F$r),e(Xm,T$r),e(tr,M$r),e(tr,IS),e(IS,E$r),e(IS,LAe),e(LAe,C$r),e(IS,w$r),e(tr,A$r),e(tr,Xt),M(NS,Xt,null),e(Xt,L$r),e(Xt,yAe),e(yAe,y$r),e(Xt,x$r),e(Xt,zm),e(zm,$$r),e(zm,xAe),e(xAe,k$r),e(zm,S$r),e(zm,Foe),e(Foe,R$r),e(zm,P$r),e(Xt,B$r),M(I3,Xt,null),e(tr,I$r),e(tr,To),M(qS,To,null),e(To,N$r),e(To,$Ae),e($Ae,q$r),e(To,D$r),e(To,Ln),e(Ln,j$r),e(Ln,kAe),e(kAe,G$r),e(Ln,O$r),e(Ln,SAe),e(SAe,V$r),e(Ln,X$r),e(Ln,RAe),e(RAe,z$r),e(Ln,Q$r),e(To,W$r),e(To,pt),e(pt,N3),e(N3,PAe),e(PAe,U$r),e(N3,H$r),e(N3,Toe),e(Toe,J$r),e(N3,Y$r),e(pt,Z$r),e(pt,q3),e(q3,BAe),e(BAe,K$r),e(q3,ekr),e(q3,Moe),e(Moe,okr),e(q3,rkr),e(pt,tkr),e(pt,D3),e(D3,IAe),e(IAe,akr),e(D3,nkr),e(D3,Eoe),e(Eoe,skr),e(D3,lkr),e(pt,ikr),e(pt,j3),e(j3,NAe),e(NAe,dkr),e(j3,mkr),e(j3,Coe),e(Coe,ckr),e(j3,fkr),e(pt,gkr),e(pt,G3),e(G3,qAe),e(qAe,hkr),e(G3,ukr),e(G3,woe),e(woe,pkr),e(G3,_kr),e(To,bkr),e(To,O3),e(O3,vkr),e(O3,DAe),e(DAe,Fkr),e(O3,Tkr),e(O3,jAe),e(jAe,Mkr),e(To,Ekr),M(V3,To,null),b(c,Sao,_),b(c,Qm,_),e(Qm,X3),e(X3,GAe),M(DS,GAe,null),e(Qm,Ckr),e(Qm,OAe),e(OAe,wkr),b(c,Rao,_),b(c,ar,_),M(jS,ar,null),e(ar,Akr),e(ar,Wm),e(Wm,Lkr),e(Wm,Aoe),e(Aoe,ykr),e(Wm,xkr),e(Wm,Loe),e(Loe,$kr),e(Wm,kkr),e(ar,Skr),e(ar,GS),e(GS,Rkr),e(GS,VAe),e(VAe,Pkr),e(GS,Bkr),e(ar,Ikr),e(ar,zt),M(OS,zt,null),e(zt,Nkr),e(zt,XAe),e(XAe,qkr),e(zt,Dkr),e(zt,Um),e(Um,jkr),e(Um,zAe),e(zAe,Gkr),e(Um,Okr),e(Um,yoe),e(yoe,Vkr),e(Um,Xkr),e(zt,zkr),M(z3,zt,null),e(ar,Qkr),e(ar,Mo),M(VS,Mo,null),e(Mo,Wkr),e(Mo,QAe),e(QAe,Ukr),e(Mo,Hkr),e(Mo,yn),e(yn,Jkr),e(yn,WAe),e(WAe,Ykr),e(yn,Zkr),e(yn,UAe),e(UAe,Kkr),e(yn,eSr),e(yn,HAe),e(HAe,oSr),e(yn,rSr),e(Mo,tSr),e(Mo,xn),e(xn,Q3),e(Q3,JAe),e(JAe,aSr),e(Q3,nSr),e(Q3,xoe),e(xoe,sSr),e(Q3,lSr),e(xn,iSr),e(xn,W3),e(W3,YAe),e(YAe,dSr),e(W3,mSr),e(W3,$oe),e($oe,cSr),e(W3,fSr),e(xn,gSr),e(xn,U3),e(U3,ZAe),e(ZAe,hSr),e(U3,uSr),e(U3,koe),e(koe,pSr),e(U3,_Sr),e(xn,bSr),e(xn,H3),e(H3,KAe),e(KAe,vSr),e(H3,FSr),e(H3,Soe),e(Soe,TSr),e(H3,MSr),e(Mo,ESr),e(Mo,J3),e(J3,CSr),e(J3,e6e),e(e6e,wSr),e(J3,ASr),e(J3,o6e),e(o6e,LSr),e(Mo,ySr),M(Y3,Mo,null),b(c,Pao,_),b(c,Hm,_),e(Hm,Z3),e(Z3,r6e),M(XS,r6e,null),e(Hm,xSr),e(Hm,t6e),e(t6e,$Sr),b(c,Bao,_),b(c,nr,_),M(zS,nr,null),e(nr,kSr),e(nr,Jm),e(Jm,SSr),e(Jm,Roe),e(Roe,RSr),e(Jm,PSr),e(Jm,Poe),e(Poe,BSr),e(Jm,ISr),e(nr,NSr),e(nr,QS),e(QS,qSr),e(QS,a6e),e(a6e,DSr),e(QS,jSr),e(nr,GSr),e(nr,Qt),M(WS,Qt,null),e(Qt,OSr),e(Qt,n6e),e(n6e,VSr),e(Qt,XSr),e(Qt,Ym),e(Ym,zSr),e(Ym,s6e),e(s6e,QSr),e(Ym,WSr),e(Ym,Boe),e(Boe,USr),e(Ym,HSr),e(Qt,JSr),M(K3,Qt,null),e(nr,YSr),e(nr,Eo),M(US,Eo,null),e(Eo,ZSr),e(Eo,l6e),e(l6e,KSr),e(Eo,eRr),e(Eo,$n),e($n,oRr),e($n,i6e),e(i6e,rRr),e($n,tRr),e($n,d6e),e(d6e,aRr),e($n,nRr),e($n,m6e),e(m6e,sRr),e($n,lRr),e(Eo,iRr),e(Eo,_t),e(_t,e5),e(e5,c6e),e(c6e,dRr),e(e5,mRr),e(e5,Ioe),e(Ioe,cRr),e(e5,fRr),e(_t,gRr),e(_t,o5),e(o5,f6e),e(f6e,hRr),e(o5,uRr),e(o5,Noe),e(Noe,pRr),e(o5,_Rr),e(_t,bRr),e(_t,r5),e(r5,g6e),e(g6e,vRr),e(r5,FRr),e(r5,qoe),e(qoe,TRr),e(r5,MRr),e(_t,ERr),e(_t,t5),e(t5,h6e),e(h6e,CRr),e(t5,wRr),e(t5,Doe),e(Doe,ARr),e(t5,LRr),e(_t,yRr),e(_t,a5),e(a5,u6e),e(u6e,xRr),e(a5,$Rr),e(a5,joe),e(joe,kRr),e(a5,SRr),e(Eo,RRr),e(Eo,n5),e(n5,PRr),e(n5,p6e),e(p6e,BRr),e(n5,IRr),e(n5,_6e),e(_6e,NRr),e(Eo,qRr),M(s5,Eo,null),b(c,Iao,_),b(c,Zm,_),e(Zm,l5),e(l5,b6e),M(HS,b6e,null),e(Zm,DRr),e(Zm,v6e),e(v6e,jRr),b(c,Nao,_),b(c,sr,_),M(JS,sr,null),e(sr,GRr),e(sr,Km),e(Km,ORr),e(Km,Goe),e(Goe,VRr),e(Km,XRr),e(Km,Ooe),e(Ooe,zRr),e(Km,QRr),e(sr,WRr),e(sr,YS),e(YS,URr),e(YS,F6e),e(F6e,HRr),e(YS,JRr),e(sr,YRr),e(sr,Wt),M(ZS,Wt,null),e(Wt,ZRr),e(Wt,T6e),e(T6e,KRr),e(Wt,ePr),e(Wt,ec),e(ec,oPr),e(ec,M6e),e(M6e,rPr),e(ec,tPr),e(ec,Voe),e(Voe,aPr),e(ec,nPr),e(Wt,sPr),M(i5,Wt,null),e(sr,lPr),e(sr,Co),M(KS,Co,null),e(Co,iPr),e(Co,E6e),e(E6e,dPr),e(Co,mPr),e(Co,kn),e(kn,cPr),e(kn,C6e),e(C6e,fPr),e(kn,gPr),e(kn,w6e),e(w6e,hPr),e(kn,uPr),e(kn,A6e),e(A6e,pPr),e(kn,_Pr),e(Co,bPr),e(Co,L6e),e(L6e,d5),e(d5,y6e),e(y6e,vPr),e(d5,FPr),e(d5,Xoe),e(Xoe,TPr),e(d5,MPr),e(Co,EPr),e(Co,m5),e(m5,CPr),e(m5,x6e),e(x6e,wPr),e(m5,APr),e(m5,$6e),e($6e,LPr),e(Co,yPr),M(c5,Co,null),b(c,qao,_),b(c,oc,_),e(oc,f5),e(f5,k6e),M(eR,k6e,null),e(oc,xPr),e(oc,S6e),e(S6e,$Pr),b(c,Dao,_),b(c,lr,_),M(oR,lr,null),e(lr,kPr),e(lr,rc),e(rc,SPr),e(rc,zoe),e(zoe,RPr),e(rc,PPr),e(rc,Qoe),e(Qoe,BPr),e(rc,IPr),e(lr,NPr),e(lr,rR),e(rR,qPr),e(rR,R6e),e(R6e,DPr),e(rR,jPr),e(lr,GPr),e(lr,Ut),M(tR,Ut,null),e(Ut,OPr),e(Ut,P6e),e(P6e,VPr),e(Ut,XPr),e(Ut,tc),e(tc,zPr),e(tc,B6e),e(B6e,QPr),e(tc,WPr),e(tc,Woe),e(Woe,UPr),e(tc,HPr),e(Ut,JPr),M(g5,Ut,null),e(lr,YPr),e(lr,wo),M(aR,wo,null),e(wo,ZPr),e(wo,I6e),e(I6e,KPr),e(wo,eBr),e(wo,Sn),e(Sn,oBr),e(Sn,N6e),e(N6e,rBr),e(Sn,tBr),e(Sn,q6e),e(q6e,aBr),e(Sn,nBr),e(Sn,D6e),e(D6e,sBr),e(Sn,lBr),e(wo,iBr),e(wo,bt),e(bt,h5),e(h5,j6e),e(j6e,dBr),e(h5,mBr),e(h5,Uoe),e(Uoe,cBr),e(h5,fBr),e(bt,gBr),e(bt,u5),e(u5,G6e),e(G6e,hBr),e(u5,uBr),e(u5,Hoe),e(Hoe,pBr),e(u5,_Br),e(bt,bBr),e(bt,p5),e(p5,O6e),e(O6e,vBr),e(p5,FBr),e(p5,Joe),e(Joe,TBr),e(p5,MBr),e(bt,EBr),e(bt,_5),e(_5,V6e),e(V6e,CBr),e(_5,wBr),e(_5,Yoe),e(Yoe,ABr),e(_5,LBr),e(bt,yBr),e(bt,b5),e(b5,X6e),e(X6e,xBr),e(b5,$Br),e(b5,Zoe),e(Zoe,kBr),e(b5,SBr),e(wo,RBr),e(wo,v5),e(v5,PBr),e(v5,z6e),e(z6e,BBr),e(v5,IBr),e(v5,Q6e),e(Q6e,NBr),e(wo,qBr),M(F5,wo,null),b(c,jao,_),b(c,ac,_),e(ac,T5),e(T5,W6e),M(nR,W6e,null),e(ac,DBr),e(ac,U6e),e(U6e,jBr),b(c,Gao,_),b(c,ir,_),M(sR,ir,null),e(ir,GBr),e(ir,nc),e(nc,OBr),e(nc,Koe),e(Koe,VBr),e(nc,XBr),e(nc,ere),e(ere,zBr),e(nc,QBr),e(ir,WBr),e(ir,lR),e(lR,UBr),e(lR,H6e),e(H6e,HBr),e(lR,JBr),e(ir,YBr),e(ir,Ht),M(iR,Ht,null),e(Ht,ZBr),e(Ht,J6e),e(J6e,KBr),e(Ht,eIr),e(Ht,sc),e(sc,oIr),e(sc,Y6e),e(Y6e,rIr),e(sc,tIr),e(sc,ore),e(ore,aIr),e(sc,nIr),e(Ht,sIr),M(M5,Ht,null),e(ir,lIr),e(ir,Ao),M(dR,Ao,null),e(Ao,iIr),e(Ao,Z6e),e(Z6e,dIr),e(Ao,mIr),e(Ao,Rn),e(Rn,cIr),e(Rn,K6e),e(K6e,fIr),e(Rn,gIr),e(Rn,e7e),e(e7e,hIr),e(Rn,uIr),e(Rn,o7e),e(o7e,pIr),e(Rn,_Ir),e(Ao,bIr),e(Ao,r7e),e(r7e,E5),e(E5,t7e),e(t7e,vIr),e(E5,FIr),e(E5,rre),e(rre,TIr),e(E5,MIr),e(Ao,EIr),e(Ao,C5),e(C5,CIr),e(C5,a7e),e(a7e,wIr),e(C5,AIr),e(C5,n7e),e(n7e,LIr),e(Ao,yIr),M(w5,Ao,null),b(c,Oao,_),b(c,lc,_),e(lc,A5),e(A5,s7e),M(mR,s7e,null),e(lc,xIr),e(lc,l7e),e(l7e,$Ir),b(c,Vao,_),b(c,dr,_),M(cR,dr,null),e(dr,kIr),e(dr,ic),e(ic,SIr),e(ic,tre),e(tre,RIr),e(ic,PIr),e(ic,are),e(are,BIr),e(ic,IIr),e(dr,NIr),e(dr,fR),e(fR,qIr),e(fR,i7e),e(i7e,DIr),e(fR,jIr),e(dr,GIr),e(dr,Jt),M(gR,Jt,null),e(Jt,OIr),e(Jt,d7e),e(d7e,VIr),e(Jt,XIr),e(Jt,dc),e(dc,zIr),e(dc,m7e),e(m7e,QIr),e(dc,WIr),e(dc,nre),e(nre,UIr),e(dc,HIr),e(Jt,JIr),M(L5,Jt,null),e(dr,YIr),e(dr,Lo),M(hR,Lo,null),e(Lo,ZIr),e(Lo,c7e),e(c7e,KIr),e(Lo,eNr),e(Lo,Pn),e(Pn,oNr),e(Pn,f7e),e(f7e,rNr),e(Pn,tNr),e(Pn,g7e),e(g7e,aNr),e(Pn,nNr),e(Pn,h7e),e(h7e,sNr),e(Pn,lNr),e(Lo,iNr),e(Lo,u7e),e(u7e,y5),e(y5,p7e),e(p7e,dNr),e(y5,mNr),e(y5,sre),e(sre,cNr),e(y5,fNr),e(Lo,gNr),e(Lo,x5),e(x5,hNr),e(x5,_7e),e(_7e,uNr),e(x5,pNr),e(x5,b7e),e(b7e,_Nr),e(Lo,bNr),M($5,Lo,null),b(c,Xao,_),b(c,mc,_),e(mc,k5),e(k5,v7e),M(uR,v7e,null),e(mc,vNr),e(mc,F7e),e(F7e,FNr),b(c,zao,_),b(c,mr,_),M(pR,mr,null),e(mr,TNr),e(mr,cc),e(cc,MNr),e(cc,lre),e(lre,ENr),e(cc,CNr),e(cc,ire),e(ire,wNr),e(cc,ANr),e(mr,LNr),e(mr,_R),e(_R,yNr),e(_R,T7e),e(T7e,xNr),e(_R,$Nr),e(mr,kNr),e(mr,Yt),M(bR,Yt,null),e(Yt,SNr),e(Yt,M7e),e(M7e,RNr),e(Yt,PNr),e(Yt,fc),e(fc,BNr),e(fc,E7e),e(E7e,INr),e(fc,NNr),e(fc,dre),e(dre,qNr),e(fc,DNr),e(Yt,jNr),M(S5,Yt,null),e(mr,GNr),e(mr,jr),M(vR,jr,null),e(jr,ONr),e(jr,C7e),e(C7e,VNr),e(jr,XNr),e(jr,Bn),e(Bn,zNr),e(Bn,w7e),e(w7e,QNr),e(Bn,WNr),e(Bn,A7e),e(A7e,UNr),e(Bn,HNr),e(Bn,L7e),e(L7e,JNr),e(Bn,YNr),e(jr,ZNr),e(jr,P),e(P,R5),e(R5,y7e),e(y7e,KNr),e(R5,eqr),e(R5,mre),e(mre,oqr),e(R5,rqr),e(P,tqr),e(P,P5),e(P5,x7e),e(x7e,aqr),e(P5,nqr),e(P5,cre),e(cre,sqr),e(P5,lqr),e(P,iqr),e(P,B5),e(B5,$7e),e($7e,dqr),e(B5,mqr),e(B5,fre),e(fre,cqr),e(B5,fqr),e(P,gqr),e(P,I5),e(I5,k7e),e(k7e,hqr),e(I5,uqr),e(I5,gre),e(gre,pqr),e(I5,_qr),e(P,bqr),e(P,N5),e(N5,S7e),e(S7e,vqr),e(N5,Fqr),e(N5,hre),e(hre,Tqr),e(N5,Mqr),e(P,Eqr),e(P,q5),e(q5,R7e),e(R7e,Cqr),e(q5,wqr),e(q5,ure),e(ure,Aqr),e(q5,Lqr),e(P,yqr),e(P,D5),e(D5,P7e),e(P7e,xqr),e(D5,$qr),e(D5,pre),e(pre,kqr),e(D5,Sqr),e(P,Rqr),e(P,j5),e(j5,B7e),e(B7e,Pqr),e(j5,Bqr),e(j5,_re),e(_re,Iqr),e(j5,Nqr),e(P,qqr),e(P,G5),e(G5,I7e),e(I7e,Dqr),e(G5,jqr),e(G5,bre),e(bre,Gqr),e(G5,Oqr),e(P,Vqr),e(P,O5),e(O5,N7e),e(N7e,Xqr),e(O5,zqr),e(O5,vre),e(vre,Qqr),e(O5,Wqr),e(P,Uqr),e(P,V5),e(V5,q7e),e(q7e,Hqr),e(V5,Jqr),e(V5,Fre),e(Fre,Yqr),e(V5,Zqr),e(P,Kqr),e(P,X5),e(X5,D7e),e(D7e,eDr),e(X5,oDr),e(X5,Tre),e(Tre,rDr),e(X5,tDr),e(P,aDr),e(P,z5),e(z5,j7e),e(j7e,nDr),e(z5,sDr),e(z5,Mre),e(Mre,lDr),e(z5,iDr),e(P,dDr),e(P,Q5),e(Q5,G7e),e(G7e,mDr),e(Q5,cDr),e(Q5,Ere),e(Ere,fDr),e(Q5,gDr),e(P,hDr),e(P,W5),e(W5,O7e),e(O7e,uDr),e(W5,pDr),e(W5,Cre),e(Cre,_Dr),e(W5,bDr),e(P,vDr),e(P,U5),e(U5,V7e),e(V7e,FDr),e(U5,TDr),e(U5,wre),e(wre,MDr),e(U5,EDr),e(P,CDr),e(P,H5),e(H5,X7e),e(X7e,wDr),e(H5,ADr),e(H5,Are),e(Are,LDr),e(H5,yDr),e(P,xDr),e(P,J5),e(J5,z7e),e(z7e,$Dr),e(J5,kDr),e(J5,Lre),e(Lre,SDr),e(J5,RDr),e(P,PDr),e(P,Y5),e(Y5,Q7e),e(Q7e,BDr),e(Y5,IDr),e(Y5,yre),e(yre,NDr),e(Y5,qDr),e(P,DDr),e(P,Z5),e(Z5,W7e),e(W7e,jDr),e(Z5,GDr),e(Z5,xre),e(xre,ODr),e(Z5,VDr),e(P,XDr),e(P,Sl),e(Sl,U7e),e(U7e,zDr),e(Sl,QDr),e(Sl,$re),e($re,WDr),e(Sl,UDr),e(Sl,kre),e(kre,HDr),e(Sl,JDr),e(P,YDr),e(P,K5),e(K5,H7e),e(H7e,ZDr),e(K5,KDr),e(K5,Sre),e(Sre,ejr),e(K5,ojr),e(P,rjr),e(P,e0),e(e0,J7e),e(J7e,tjr),e(e0,ajr),e(e0,Rre),e(Rre,njr),e(e0,sjr),e(P,ljr),e(P,o0),e(o0,Y7e),e(Y7e,ijr),e(o0,djr),e(o0,Pre),e(Pre,mjr),e(o0,cjr),e(P,fjr),e(P,r0),e(r0,Z7e),e(Z7e,gjr),e(r0,hjr),e(r0,Bre),e(Bre,ujr),e(r0,pjr),e(P,_jr),e(P,t0),e(t0,K7e),e(K7e,bjr),e(t0,vjr),e(t0,Ire),e(Ire,Fjr),e(t0,Tjr),e(P,Mjr),e(P,a0),e(a0,e8e),e(e8e,Ejr),e(a0,Cjr),e(a0,Nre),e(Nre,wjr),e(a0,Ajr),e(P,Ljr),e(P,n0),e(n0,o8e),e(o8e,yjr),e(n0,xjr),e(n0,qre),e(qre,$jr),e(n0,kjr),e(P,Sjr),e(P,s0),e(s0,r8e),e(r8e,Rjr),e(s0,Pjr),e(s0,Dre),e(Dre,Bjr),e(s0,Ijr),e(P,Njr),e(P,l0),e(l0,t8e),e(t8e,qjr),e(l0,Djr),e(l0,jre),e(jre,jjr),e(l0,Gjr),e(P,Ojr),e(P,i0),e(i0,a8e),e(a8e,Vjr),e(i0,Xjr),e(i0,Gre),e(Gre,zjr),e(i0,Qjr),e(P,Wjr),e(P,d0),e(d0,n8e),e(n8e,Ujr),e(d0,Hjr),e(d0,Ore),e(Ore,Jjr),e(d0,Yjr),e(P,Zjr),e(P,m0),e(m0,s8e),e(s8e,Kjr),e(m0,eGr),e(m0,Vre),e(Vre,oGr),e(m0,rGr),e(P,tGr),e(P,c0),e(c0,l8e),e(l8e,aGr),e(c0,nGr),e(c0,Xre),e(Xre,sGr),e(c0,lGr),e(P,iGr),e(P,f0),e(f0,i8e),e(i8e,dGr),e(f0,mGr),e(f0,zre),e(zre,cGr),e(f0,fGr),e(P,gGr),e(P,g0),e(g0,d8e),e(d8e,hGr),e(g0,uGr),e(g0,Qre),e(Qre,pGr),e(g0,_Gr),e(P,bGr),e(P,h0),e(h0,m8e),e(m8e,vGr),e(h0,FGr),e(h0,Wre),e(Wre,TGr),e(h0,MGr),e(P,EGr),e(P,u0),e(u0,c8e),e(c8e,CGr),e(u0,wGr),e(u0,Ure),e(Ure,AGr),e(u0,LGr),e(P,yGr),e(P,p0),e(p0,f8e),e(f8e,xGr),e(p0,$Gr),e(p0,Hre),e(Hre,kGr),e(p0,SGr),e(P,RGr),e(P,_0),e(_0,g8e),e(g8e,PGr),e(_0,BGr),e(_0,Jre),e(Jre,IGr),e(_0,NGr),e(P,qGr),e(P,b0),e(b0,h8e),e(h8e,DGr),e(b0,jGr),e(b0,Yre),e(Yre,GGr),e(b0,OGr),e(P,VGr),e(P,v0),e(v0,u8e),e(u8e,XGr),e(v0,zGr),e(v0,Zre),e(Zre,QGr),e(v0,WGr),e(P,UGr),e(P,F0),e(F0,p8e),e(p8e,HGr),e(F0,JGr),e(F0,Kre),e(Kre,YGr),e(F0,ZGr),e(P,KGr),e(P,T0),e(T0,_8e),e(_8e,eOr),e(T0,oOr),e(T0,ete),e(ete,rOr),e(T0,tOr),e(P,aOr),e(P,M0),e(M0,b8e),e(b8e,nOr),e(M0,sOr),e(M0,ote),e(ote,lOr),e(M0,iOr),e(P,dOr),e(P,E0),e(E0,v8e),e(v8e,mOr),e(E0,cOr),e(E0,rte),e(rte,fOr),e(E0,gOr),e(P,hOr),e(P,C0),e(C0,F8e),e(F8e,uOr),e(C0,pOr),e(C0,tte),e(tte,_Or),e(C0,bOr),e(P,vOr),e(P,w0),e(w0,T8e),e(T8e,FOr),e(w0,TOr),e(w0,ate),e(ate,MOr),e(w0,EOr),e(P,COr),e(P,A0),e(A0,M8e),e(M8e,wOr),e(A0,AOr),e(A0,nte),e(nte,LOr),e(A0,yOr),e(P,xOr),e(P,L0),e(L0,E8e),e(E8e,$Or),e(L0,kOr),e(L0,ste),e(ste,SOr),e(L0,ROr),e(P,POr),e(P,y0),e(y0,C8e),e(C8e,BOr),e(y0,IOr),e(y0,lte),e(lte,NOr),e(y0,qOr),e(P,DOr),e(P,x0),e(x0,w8e),e(w8e,jOr),e(x0,GOr),e(x0,ite),e(ite,OOr),e(x0,VOr),e(P,XOr),e(P,$0),e($0,A8e),e(A8e,zOr),e($0,QOr),e($0,dte),e(dte,WOr),e($0,UOr),e(P,HOr),e(P,k0),e(k0,L8e),e(L8e,JOr),e(k0,YOr),e(k0,mte),e(mte,ZOr),e(k0,KOr),e(P,eVr),e(P,S0),e(S0,y8e),e(y8e,oVr),e(S0,rVr),e(S0,cte),e(cte,tVr),e(S0,aVr),e(P,nVr),e(P,R0),e(R0,x8e),e(x8e,sVr),e(R0,lVr),e(R0,fte),e(fte,iVr),e(R0,dVr),e(P,mVr),e(P,P0),e(P0,$8e),e($8e,cVr),e(P0,fVr),e(P0,gte),e(gte,gVr),e(P0,hVr),e(P,uVr),e(P,B0),e(B0,k8e),e(k8e,pVr),e(B0,_Vr),e(B0,hte),e(hte,bVr),e(B0,vVr),e(jr,FVr),M(I0,jr,null),b(c,Qao,_),b(c,gc,_),e(gc,N0),e(N0,S8e),M(FR,S8e,null),e(gc,TVr),e(gc,R8e),e(R8e,MVr),b(c,Wao,_),b(c,cr,_),M(TR,cr,null),e(cr,EVr),e(cr,hc),e(hc,CVr),e(hc,ute),e(ute,wVr),e(hc,AVr),e(hc,pte),e(pte,LVr),e(hc,yVr),e(cr,xVr),e(cr,MR),e(MR,$Vr),e(MR,P8e),e(P8e,kVr),e(MR,SVr),e(cr,RVr),e(cr,Zt),M(ER,Zt,null),e(Zt,PVr),e(Zt,B8e),e(B8e,BVr),e(Zt,IVr),e(Zt,uc),e(uc,NVr),e(uc,I8e),e(I8e,qVr),e(uc,DVr),e(uc,_te),e(_te,jVr),e(uc,GVr),e(Zt,OVr),M(q0,Zt,null),e(cr,VVr),e(cr,Gr),M(CR,Gr,null),e(Gr,XVr),e(Gr,N8e),e(N8e,zVr),e(Gr,QVr),e(Gr,In),e(In,WVr),e(In,q8e),e(q8e,UVr),e(In,HVr),e(In,D8e),e(D8e,JVr),e(In,YVr),e(In,j8e),e(j8e,ZVr),e(In,KVr),e(Gr,eXr),e(Gr,le),e(le,D0),e(D0,G8e),e(G8e,oXr),e(D0,rXr),e(D0,bte),e(bte,tXr),e(D0,aXr),e(le,nXr),e(le,j0),e(j0,O8e),e(O8e,sXr),e(j0,lXr),e(j0,vte),e(vte,iXr),e(j0,dXr),e(le,mXr),e(le,G0),e(G0,V8e),e(V8e,cXr),e(G0,fXr),e(G0,Fte),e(Fte,gXr),e(G0,hXr),e(le,uXr),e(le,O0),e(O0,X8e),e(X8e,pXr),e(O0,_Xr),e(O0,Tte),e(Tte,bXr),e(O0,vXr),e(le,FXr),e(le,V0),e(V0,z8e),e(z8e,TXr),e(V0,MXr),e(V0,Mte),e(Mte,EXr),e(V0,CXr),e(le,wXr),e(le,X0),e(X0,Q8e),e(Q8e,AXr),e(X0,LXr),e(X0,Ete),e(Ete,yXr),e(X0,xXr),e(le,$Xr),e(le,z0),e(z0,W8e),e(W8e,kXr),e(z0,SXr),e(z0,Cte),e(Cte,RXr),e(z0,PXr),e(le,BXr),e(le,Q0),e(Q0,U8e),e(U8e,IXr),e(Q0,NXr),e(Q0,wte),e(wte,qXr),e(Q0,DXr),e(le,jXr),e(le,W0),e(W0,H8e),e(H8e,GXr),e(W0,OXr),e(W0,Ate),e(Ate,VXr),e(W0,XXr),e(le,zXr),e(le,U0),e(U0,J8e),e(J8e,QXr),e(U0,WXr),e(U0,Lte),e(Lte,UXr),e(U0,HXr),e(le,JXr),e(le,H0),e(H0,Y8e),e(Y8e,YXr),e(H0,ZXr),e(H0,yte),e(yte,KXr),e(H0,ezr),e(le,ozr),e(le,J0),e(J0,Z8e),e(Z8e,rzr),e(J0,tzr),e(J0,xte),e(xte,azr),e(J0,nzr),e(le,szr),e(le,Y0),e(Y0,K8e),e(K8e,lzr),e(Y0,izr),e(Y0,$te),e($te,dzr),e(Y0,mzr),e(le,czr),e(le,Z0),e(Z0,eLe),e(eLe,fzr),e(Z0,gzr),e(Z0,kte),e(kte,hzr),e(Z0,uzr),e(le,pzr),e(le,K0),e(K0,oLe),e(oLe,_zr),e(K0,bzr),e(K0,Ste),e(Ste,vzr),e(K0,Fzr),e(le,Tzr),e(le,ew),e(ew,rLe),e(rLe,Mzr),e(ew,Ezr),e(ew,Rte),e(Rte,Czr),e(ew,wzr),e(le,Azr),e(le,ow),e(ow,tLe),e(tLe,Lzr),e(ow,yzr),e(ow,Pte),e(Pte,xzr),e(ow,$zr),e(le,kzr),e(le,rw),e(rw,aLe),e(aLe,Szr),e(rw,Rzr),e(rw,Bte),e(Bte,Pzr),e(rw,Bzr),e(le,Izr),e(le,tw),e(tw,nLe),e(nLe,Nzr),e(tw,qzr),e(tw,Ite),e(Ite,Dzr),e(tw,jzr),e(le,Gzr),e(le,aw),e(aw,sLe),e(sLe,Ozr),e(aw,Vzr),e(aw,Nte),e(Nte,Xzr),e(aw,zzr),e(le,Qzr),e(le,nw),e(nw,lLe),e(lLe,Wzr),e(nw,Uzr),e(nw,qte),e(qte,Hzr),e(nw,Jzr),e(le,Yzr),e(le,sw),e(sw,iLe),e(iLe,Zzr),e(sw,Kzr),e(sw,Dte),e(Dte,eQr),e(sw,oQr),e(le,rQr),e(le,lw),e(lw,dLe),e(dLe,tQr),e(lw,aQr),e(lw,jte),e(jte,nQr),e(lw,sQr),e(Gr,lQr),M(iw,Gr,null),b(c,Uao,_),b(c,pc,_),e(pc,dw),e(dw,mLe),M(wR,mLe,null),e(pc,iQr),e(pc,cLe),e(cLe,dQr),b(c,Hao,_),b(c,fr,_),M(AR,fr,null),e(fr,mQr),e(fr,_c),e(_c,cQr),e(_c,Gte),e(Gte,fQr),e(_c,gQr),e(_c,Ote),e(Ote,hQr),e(_c,uQr),e(fr,pQr),e(fr,LR),e(LR,_Qr),e(LR,fLe),e(fLe,bQr),e(LR,vQr),e(fr,FQr),e(fr,Kt),M(yR,Kt,null),e(Kt,TQr),e(Kt,gLe),e(gLe,MQr),e(Kt,EQr),e(Kt,bc),e(bc,CQr),e(bc,hLe),e(hLe,wQr),e(bc,AQr),e(bc,Vte),e(Vte,LQr),e(bc,yQr),e(Kt,xQr),M(mw,Kt,null),e(fr,$Qr),e(fr,Or),M(xR,Or,null),e(Or,kQr),e(Or,uLe),e(uLe,SQr),e(Or,RQr),e(Or,Nn),e(Nn,PQr),e(Nn,pLe),e(pLe,BQr),e(Nn,IQr),e(Nn,_Le),e(_Le,NQr),e(Nn,qQr),e(Nn,bLe),e(bLe,DQr),e(Nn,jQr),e(Or,GQr),e(Or,Me),e(Me,cw),e(cw,vLe),e(vLe,OQr),e(cw,VQr),e(cw,Xte),e(Xte,XQr),e(cw,zQr),e(Me,QQr),e(Me,fw),e(fw,FLe),e(FLe,WQr),e(fw,UQr),e(fw,zte),e(zte,HQr),e(fw,JQr),e(Me,YQr),e(Me,gw),e(gw,TLe),e(TLe,ZQr),e(gw,KQr),e(gw,Qte),e(Qte,eWr),e(gw,oWr),e(Me,rWr),e(Me,hw),e(hw,MLe),e(MLe,tWr),e(hw,aWr),e(hw,Wte),e(Wte,nWr),e(hw,sWr),e(Me,lWr),e(Me,uw),e(uw,ELe),e(ELe,iWr),e(uw,dWr),e(uw,Ute),e(Ute,mWr),e(uw,cWr),e(Me,fWr),e(Me,pw),e(pw,CLe),e(CLe,gWr),e(pw,hWr),e(pw,Hte),e(Hte,uWr),e(pw,pWr),e(Me,_Wr),e(Me,_w),e(_w,wLe),e(wLe,bWr),e(_w,vWr),e(_w,Jte),e(Jte,FWr),e(_w,TWr),e(Me,MWr),e(Me,bw),e(bw,ALe),e(ALe,EWr),e(bw,CWr),e(bw,Yte),e(Yte,wWr),e(bw,AWr),e(Me,LWr),e(Me,vw),e(vw,LLe),e(LLe,yWr),e(vw,xWr),e(vw,Zte),e(Zte,$Wr),e(vw,kWr),e(Me,SWr),e(Me,Fw),e(Fw,yLe),e(yLe,RWr),e(Fw,PWr),e(Fw,Kte),e(Kte,BWr),e(Fw,IWr),e(Me,NWr),e(Me,Tw),e(Tw,xLe),e(xLe,qWr),e(Tw,DWr),e(Tw,eae),e(eae,jWr),e(Tw,GWr),e(Me,OWr),e(Me,Mw),e(Mw,$Le),e($Le,VWr),e(Mw,XWr),e(Mw,oae),e(oae,zWr),e(Mw,QWr),e(Me,WWr),e(Me,Ew),e(Ew,kLe),e(kLe,UWr),e(Ew,HWr),e(Ew,rae),e(rae,JWr),e(Ew,YWr),e(Me,ZWr),e(Me,Cw),e(Cw,SLe),e(SLe,KWr),e(Cw,eUr),e(Cw,tae),e(tae,oUr),e(Cw,rUr),e(Or,tUr),M(ww,Or,null),b(c,Jao,_),b(c,vc,_),e(vc,Aw),e(Aw,RLe),M($R,RLe,null),e(vc,aUr),e(vc,PLe),e(PLe,nUr),b(c,Yao,_),b(c,gr,_),M(kR,gr,null),e(gr,sUr),e(gr,Fc),e(Fc,lUr),e(Fc,aae),e(aae,iUr),e(Fc,dUr),e(Fc,nae),e(nae,mUr),e(Fc,cUr),e(gr,fUr),e(gr,SR),e(SR,gUr),e(SR,BLe),e(BLe,hUr),e(SR,uUr),e(gr,pUr),e(gr,ea),M(RR,ea,null),e(ea,_Ur),e(ea,ILe),e(ILe,bUr),e(ea,vUr),e(ea,Tc),e(Tc,FUr),e(Tc,NLe),e(NLe,TUr),e(Tc,MUr),e(Tc,sae),e(sae,EUr),e(Tc,CUr),e(ea,wUr),M(Lw,ea,null),e(gr,AUr),e(gr,Vr),M(PR,Vr,null),e(Vr,LUr),e(Vr,qLe),e(qLe,yUr),e(Vr,xUr),e(Vr,qn),e(qn,$Ur),e(qn,DLe),e(DLe,kUr),e(qn,SUr),e(qn,jLe),e(jLe,RUr),e(qn,PUr),e(qn,GLe),e(GLe,BUr),e(qn,IUr),e(Vr,NUr),e(Vr,ye),e(ye,yw),e(yw,OLe),e(OLe,qUr),e(yw,DUr),e(yw,lae),e(lae,jUr),e(yw,GUr),e(ye,OUr),e(ye,xw),e(xw,VLe),e(VLe,VUr),e(xw,XUr),e(xw,iae),e(iae,zUr),e(xw,QUr),e(ye,WUr),e(ye,$w),e($w,XLe),e(XLe,UUr),e($w,HUr),e($w,dae),e(dae,JUr),e($w,YUr),e(ye,ZUr),e(ye,Rl),e(Rl,zLe),e(zLe,KUr),e(Rl,eHr),e(Rl,mae),e(mae,oHr),e(Rl,rHr),e(Rl,cae),e(cae,tHr),e(Rl,aHr),e(ye,nHr),e(ye,kw),e(kw,QLe),e(QLe,sHr),e(kw,lHr),e(kw,fae),e(fae,iHr),e(kw,dHr),e(ye,mHr),e(ye,Sw),e(Sw,WLe),e(WLe,cHr),e(Sw,fHr),e(Sw,gae),e(gae,gHr),e(Sw,hHr),e(ye,uHr),e(ye,Rw),e(Rw,ULe),e(ULe,pHr),e(Rw,_Hr),e(Rw,hae),e(hae,bHr),e(Rw,vHr),e(ye,FHr),e(ye,Pw),e(Pw,HLe),e(HLe,THr),e(Pw,MHr),e(Pw,uae),e(uae,EHr),e(Pw,CHr),e(ye,wHr),e(ye,Bw),e(Bw,JLe),e(JLe,AHr),e(Bw,LHr),e(Bw,pae),e(pae,yHr),e(Bw,xHr),e(ye,$Hr),e(ye,Iw),e(Iw,YLe),e(YLe,kHr),e(Iw,SHr),e(Iw,_ae),e(_ae,RHr),e(Iw,PHr),e(Vr,BHr),M(Nw,Vr,null),b(c,Zao,_),b(c,Mc,_),e(Mc,qw),e(qw,ZLe),M(BR,ZLe,null),e(Mc,IHr),e(Mc,KLe),e(KLe,NHr),b(c,Kao,_),b(c,hr,_),M(IR,hr,null),e(hr,qHr),e(hr,Ec),e(Ec,DHr),e(Ec,bae),e(bae,jHr),e(Ec,GHr),e(Ec,vae),e(vae,OHr),e(Ec,VHr),e(hr,XHr),e(hr,NR),e(NR,zHr),e(NR,eye),e(eye,QHr),e(NR,WHr),e(hr,UHr),e(hr,oa),M(qR,oa,null),e(oa,HHr),e(oa,oye),e(oye,JHr),e(oa,YHr),e(oa,Cc),e(Cc,ZHr),e(Cc,rye),e(rye,KHr),e(Cc,eJr),e(Cc,Fae),e(Fae,oJr),e(Cc,rJr),e(oa,tJr),M(Dw,oa,null),e(hr,aJr),e(hr,Xr),M(DR,Xr,null),e(Xr,nJr),e(Xr,tye),e(tye,sJr),e(Xr,lJr),e(Xr,Dn),e(Dn,iJr),e(Dn,aye),e(aye,dJr),e(Dn,mJr),e(Dn,nye),e(nye,cJr),e(Dn,fJr),e(Dn,sye),e(sye,gJr),e(Dn,hJr),e(Xr,uJr),e(Xr,wc),e(wc,jw),e(jw,lye),e(lye,pJr),e(jw,_Jr),e(jw,Tae),e(Tae,bJr),e(jw,vJr),e(wc,FJr),e(wc,Gw),e(Gw,iye),e(iye,TJr),e(Gw,MJr),e(Gw,Mae),e(Mae,EJr),e(Gw,CJr),e(wc,wJr),e(wc,Ow),e(Ow,dye),e(dye,AJr),e(Ow,LJr),e(Ow,Eae),e(Eae,yJr),e(Ow,xJr),e(Xr,$Jr),M(Vw,Xr,null),b(c,eno,_),b(c,Ac,_),e(Ac,Xw),e(Xw,mye),M(jR,mye,null),e(Ac,kJr),e(Ac,cye),e(cye,SJr),b(c,ono,_),b(c,ur,_),M(GR,ur,null),e(ur,RJr),e(ur,Lc),e(Lc,PJr),e(Lc,Cae),e(Cae,BJr),e(Lc,IJr),e(Lc,wae),e(wae,NJr),e(Lc,qJr),e(ur,DJr),e(ur,OR),e(OR,jJr),e(OR,fye),e(fye,GJr),e(OR,OJr),e(ur,VJr),e(ur,ra),M(VR,ra,null),e(ra,XJr),e(ra,gye),e(gye,zJr),e(ra,QJr),e(ra,yc),e(yc,WJr),e(yc,hye),e(hye,UJr),e(yc,HJr),e(yc,Aae),e(Aae,JJr),e(yc,YJr),e(ra,ZJr),M(zw,ra,null),e(ur,KJr),e(ur,zr),M(XR,zr,null),e(zr,eYr),e(zr,uye),e(uye,oYr),e(zr,rYr),e(zr,jn),e(jn,tYr),e(jn,pye),e(pye,aYr),e(jn,nYr),e(jn,_ye),e(_ye,sYr),e(jn,lYr),e(jn,bye),e(bye,iYr),e(jn,dYr),e(zr,mYr),e(zr,ce),e(ce,Qw),e(Qw,vye),e(vye,cYr),e(Qw,fYr),e(Qw,Lae),e(Lae,gYr),e(Qw,hYr),e(ce,uYr),e(ce,Ww),e(Ww,Fye),e(Fye,pYr),e(Ww,_Yr),e(Ww,yae),e(yae,bYr),e(Ww,vYr),e(ce,FYr),e(ce,Uw),e(Uw,Tye),e(Tye,TYr),e(Uw,MYr),e(Uw,xae),e(xae,EYr),e(Uw,CYr),e(ce,wYr),e(ce,Hw),e(Hw,Mye),e(Mye,AYr),e(Hw,LYr),e(Hw,$ae),e($ae,yYr),e(Hw,xYr),e(ce,$Yr),e(ce,Jw),e(Jw,Eye),e(Eye,kYr),e(Jw,SYr),e(Jw,kae),e(kae,RYr),e(Jw,PYr),e(ce,BYr),e(ce,Yw),e(Yw,Cye),e(Cye,IYr),e(Yw,NYr),e(Yw,Sae),e(Sae,qYr),e(Yw,DYr),e(ce,jYr),e(ce,Zw),e(Zw,wye),e(wye,GYr),e(Zw,OYr),e(Zw,Rae),e(Rae,VYr),e(Zw,XYr),e(ce,zYr),e(ce,Kw),e(Kw,Aye),e(Aye,QYr),e(Kw,WYr),e(Kw,Pae),e(Pae,UYr),e(Kw,HYr),e(ce,JYr),e(ce,eA),e(eA,Lye),e(Lye,YYr),e(eA,ZYr),e(eA,Bae),e(Bae,KYr),e(eA,eZr),e(ce,oZr),e(ce,oA),e(oA,yye),e(yye,rZr),e(oA,tZr),e(oA,Iae),e(Iae,aZr),e(oA,nZr),e(ce,sZr),e(ce,rA),e(rA,xye),e(xye,lZr),e(rA,iZr),e(rA,Nae),e(Nae,dZr),e(rA,mZr),e(ce,cZr),e(ce,tA),e(tA,$ye),e($ye,fZr),e(tA,gZr),e(tA,qae),e(qae,hZr),e(tA,uZr),e(ce,pZr),e(ce,aA),e(aA,kye),e(kye,_Zr),e(aA,bZr),e(aA,Dae),e(Dae,vZr),e(aA,FZr),e(ce,TZr),e(ce,nA),e(nA,Sye),e(Sye,MZr),e(nA,EZr),e(nA,jae),e(jae,CZr),e(nA,wZr),e(ce,AZr),e(ce,sA),e(sA,Rye),e(Rye,LZr),e(sA,yZr),e(sA,Gae),e(Gae,xZr),e(sA,$Zr),e(ce,kZr),e(ce,lA),e(lA,Pye),e(Pye,SZr),e(lA,RZr),e(lA,Oae),e(Oae,PZr),e(lA,BZr),e(ce,IZr),e(ce,iA),e(iA,Bye),e(Bye,NZr),e(iA,qZr),e(iA,Vae),e(Vae,DZr),e(iA,jZr),e(ce,GZr),e(ce,dA),e(dA,Iye),e(Iye,OZr),e(dA,VZr),e(dA,Xae),e(Xae,XZr),e(dA,zZr),e(ce,QZr),e(ce,mA),e(mA,Nye),e(Nye,WZr),e(mA,UZr),e(mA,zae),e(zae,HZr),e(mA,JZr),e(ce,YZr),e(ce,cA),e(cA,qye),e(qye,ZZr),e(cA,KZr),e(cA,Qae),e(Qae,eKr),e(cA,oKr),e(ce,rKr),e(ce,fA),e(fA,Dye),e(Dye,tKr),e(fA,aKr),e(fA,Wae),e(Wae,nKr),e(fA,sKr),e(zr,lKr),M(gA,zr,null),b(c,rno,_),b(c,xc,_),e(xc,hA),e(hA,jye),M(zR,jye,null),e(xc,iKr),e(xc,Gye),e(Gye,dKr),b(c,tno,_),b(c,pr,_),M(QR,pr,null),e(pr,mKr),e(pr,$c),e($c,cKr),e($c,Uae),e(Uae,fKr),e($c,gKr),e($c,Hae),e(Hae,hKr),e($c,uKr),e(pr,pKr),e(pr,WR),e(WR,_Kr),e(WR,Oye),e(Oye,bKr),e(WR,vKr),e(pr,FKr),e(pr,ta),M(UR,ta,null),e(ta,TKr),e(ta,Vye),e(Vye,MKr),e(ta,EKr),e(ta,kc),e(kc,CKr),e(kc,Xye),e(Xye,wKr),e(kc,AKr),e(kc,Jae),e(Jae,LKr),e(kc,yKr),e(ta,xKr),M(uA,ta,null),e(pr,$Kr),e(pr,Qr),M(HR,Qr,null),e(Qr,kKr),e(Qr,zye),e(zye,SKr),e(Qr,RKr),e(Qr,Gn),e(Gn,PKr),e(Gn,Qye),e(Qye,BKr),e(Gn,IKr),e(Gn,Wye),e(Wye,NKr),e(Gn,qKr),e(Gn,Uye),e(Uye,DKr),e(Gn,jKr),e(Qr,GKr),e(Qr,xe),e(xe,pA),e(pA,Hye),e(Hye,OKr),e(pA,VKr),e(pA,Yae),e(Yae,XKr),e(pA,zKr),e(xe,QKr),e(xe,_A),e(_A,Jye),e(Jye,WKr),e(_A,UKr),e(_A,Zae),e(Zae,HKr),e(_A,JKr),e(xe,YKr),e(xe,bA),e(bA,Yye),e(Yye,ZKr),e(bA,KKr),e(bA,Kae),e(Kae,eet),e(bA,oet),e(xe,ret),e(xe,vA),e(vA,Zye),e(Zye,tet),e(vA,aet),e(vA,ene),e(ene,net),e(vA,set),e(xe,iet),e(xe,FA),e(FA,Kye),e(Kye,det),e(FA,met),e(FA,one),e(one,cet),e(FA,fet),e(xe,get),e(xe,TA),e(TA,e9e),e(e9e,het),e(TA,uet),e(TA,rne),e(rne,pet),e(TA,_et),e(xe,bet),e(xe,MA),e(MA,o9e),e(o9e,vet),e(MA,Fet),e(MA,tne),e(tne,Tet),e(MA,Met),e(xe,Eet),e(xe,EA),e(EA,r9e),e(r9e,Cet),e(EA,wet),e(EA,ane),e(ane,Aet),e(EA,Let),e(xe,yet),e(xe,CA),e(CA,t9e),e(t9e,xet),e(CA,$et),e(CA,nne),e(nne,ket),e(CA,Set),e(xe,Ret),e(xe,wA),e(wA,a9e),e(a9e,Pet),e(wA,Bet),e(wA,sne),e(sne,Iet),e(wA,Net),e(Qr,qet),M(AA,Qr,null),b(c,ano,_),b(c,Sc,_),e(Sc,LA),e(LA,n9e),M(JR,n9e,null),e(Sc,Det),e(Sc,s9e),e(s9e,jet),b(c,nno,_),b(c,_r,_),M(YR,_r,null),e(_r,Get),e(_r,Rc),e(Rc,Oet),e(Rc,lne),e(lne,Vet),e(Rc,Xet),e(Rc,ine),e(ine,zet),e(Rc,Qet),e(_r,Wet),e(_r,ZR),e(ZR,Uet),e(ZR,l9e),e(l9e,Het),e(ZR,Jet),e(_r,Yet),e(_r,aa),M(KR,aa,null),e(aa,Zet),e(aa,i9e),e(i9e,Ket),e(aa,eot),e(aa,Pc),e(Pc,oot),e(Pc,d9e),e(d9e,rot),e(Pc,tot),e(Pc,dne),e(dne,aot),e(Pc,not),e(aa,sot),M(yA,aa,null),e(_r,lot),e(_r,Wr),M(eP,Wr,null),e(Wr,iot),e(Wr,m9e),e(m9e,dot),e(Wr,mot),e(Wr,On),e(On,cot),e(On,c9e),e(c9e,fot),e(On,got),e(On,f9e),e(f9e,hot),e(On,uot),e(On,g9e),e(g9e,pot),e(On,_ot),e(Wr,bot),e(Wr,re),e(re,xA),e(xA,h9e),e(h9e,vot),e(xA,Fot),e(xA,mne),e(mne,Tot),e(xA,Mot),e(re,Eot),e(re,$A),e($A,u9e),e(u9e,Cot),e($A,wot),e($A,cne),e(cne,Aot),e($A,Lot),e(re,yot),e(re,kA),e(kA,p9e),e(p9e,xot),e(kA,$ot),e(kA,fne),e(fne,kot),e(kA,Sot),e(re,Rot),e(re,SA),e(SA,_9e),e(_9e,Pot),e(SA,Bot),e(SA,gne),e(gne,Iot),e(SA,Not),e(re,qot),e(re,RA),e(RA,b9e),e(b9e,Dot),e(RA,jot),e(RA,hne),e(hne,Got),e(RA,Oot),e(re,Vot),e(re,PA),e(PA,v9e),e(v9e,Xot),e(PA,zot),e(PA,une),e(une,Qot),e(PA,Wot),e(re,Uot),e(re,BA),e(BA,F9e),e(F9e,Hot),e(BA,Jot),e(BA,pne),e(pne,Yot),e(BA,Zot),e(re,Kot),e(re,IA),e(IA,T9e),e(T9e,ert),e(IA,ort),e(IA,_ne),e(_ne,rrt),e(IA,trt),e(re,art),e(re,NA),e(NA,M9e),e(M9e,nrt),e(NA,srt),e(NA,bne),e(bne,lrt),e(NA,irt),e(re,drt),e(re,qA),e(qA,E9e),e(E9e,mrt),e(qA,crt),e(qA,vne),e(vne,frt),e(qA,grt),e(re,hrt),e(re,DA),e(DA,C9e),e(C9e,urt),e(DA,prt),e(DA,Fne),e(Fne,_rt),e(DA,brt),e(re,vrt),e(re,jA),e(jA,w9e),e(w9e,Frt),e(jA,Trt),e(jA,Tne),e(Tne,Mrt),e(jA,Ert),e(re,Crt),e(re,GA),e(GA,A9e),e(A9e,wrt),e(GA,Art),e(GA,Mne),e(Mne,Lrt),e(GA,yrt),e(re,xrt),e(re,OA),e(OA,L9e),e(L9e,$rt),e(OA,krt),e(OA,Ene),e(Ene,Srt),e(OA,Rrt),e(re,Prt),e(re,VA),e(VA,y9e),e(y9e,Brt),e(VA,Irt),e(VA,Cne),e(Cne,Nrt),e(VA,qrt),e(re,Drt),e(re,XA),e(XA,x9e),e(x9e,jrt),e(XA,Grt),e(XA,wne),e(wne,Ort),e(XA,Vrt),e(re,Xrt),e(re,zA),e(zA,$9e),e($9e,zrt),e(zA,Qrt),e(zA,Ane),e(Ane,Wrt),e(zA,Urt),e(re,Hrt),e(re,QA),e(QA,k9e),e(k9e,Jrt),e(QA,Yrt),e(QA,Lne),e(Lne,Zrt),e(QA,Krt),e(re,ett),e(re,WA),e(WA,S9e),e(S9e,ott),e(WA,rtt),e(WA,yne),e(yne,ttt),e(WA,att),e(re,ntt),e(re,UA),e(UA,R9e),e(R9e,stt),e(UA,ltt),e(UA,xne),e(xne,itt),e(UA,dtt),e(re,mtt),e(re,HA),e(HA,P9e),e(P9e,ctt),e(HA,ftt),e(HA,$ne),e($ne,gtt),e(HA,htt),e(re,utt),e(re,JA),e(JA,B9e),e(B9e,ptt),e(JA,_tt),e(JA,kne),e(kne,btt),e(JA,vtt),e(re,Ftt),e(re,YA),e(YA,I9e),e(I9e,Ttt),e(YA,Mtt),e(YA,Sne),e(Sne,Ett),e(YA,Ctt),e(re,wtt),e(re,ZA),e(ZA,N9e),e(N9e,Att),e(ZA,Ltt),e(ZA,Rne),e(Rne,ytt),e(ZA,xtt),e(re,$tt),e(re,KA),e(KA,q9e),e(q9e,ktt),e(KA,Stt),e(KA,Pne),e(Pne,Rtt),e(KA,Ptt),e(re,Btt),e(re,e6),e(e6,D9e),e(D9e,Itt),e(e6,Ntt),e(e6,Bne),e(Bne,qtt),e(e6,Dtt),e(re,jtt),e(re,o6),e(o6,j9e),e(j9e,Gtt),e(o6,Ott),e(o6,Ine),e(Ine,Vtt),e(o6,Xtt),e(re,ztt),e(re,r6),e(r6,G9e),e(G9e,Qtt),e(r6,Wtt),e(r6,Nne),e(Nne,Utt),e(r6,Htt),e(Wr,Jtt),M(t6,Wr,null),b(c,sno,_),b(c,Bc,_),e(Bc,a6),e(a6,O9e),M(oP,O9e,null),e(Bc,Ytt),e(Bc,V9e),e(V9e,Ztt),b(c,lno,_),b(c,br,_),M(rP,br,null),e(br,Ktt),e(br,Ic),e(Ic,eat),e(Ic,qne),e(qne,oat),e(Ic,rat),e(Ic,Dne),e(Dne,tat),e(Ic,aat),e(br,nat),e(br,tP),e(tP,sat),e(tP,X9e),e(X9e,lat),e(tP,iat),e(br,dat),e(br,na),M(aP,na,null),e(na,mat),e(na,z9e),e(z9e,cat),e(na,fat),e(na,Nc),e(Nc,gat),e(Nc,Q9e),e(Q9e,hat),e(Nc,uat),e(Nc,jne),e(jne,pat),e(Nc,_at),e(na,bat),M(n6,na,null),e(br,vat),e(br,Ur),M(nP,Ur,null),e(Ur,Fat),e(Ur,W9e),e(W9e,Tat),e(Ur,Mat),e(Ur,Vn),e(Vn,Eat),e(Vn,U9e),e(U9e,Cat),e(Vn,wat),e(Vn,H9e),e(H9e,Aat),e(Vn,Lat),e(Vn,J9e),e(J9e,yat),e(Vn,xat),e(Ur,$at),e(Ur,ve),e(ve,s6),e(s6,Y9e),e(Y9e,kat),e(s6,Sat),e(s6,Gne),e(Gne,Rat),e(s6,Pat),e(ve,Bat),e(ve,l6),e(l6,Z9e),e(Z9e,Iat),e(l6,Nat),e(l6,One),e(One,qat),e(l6,Dat),e(ve,jat),e(ve,i6),e(i6,K9e),e(K9e,Gat),e(i6,Oat),e(i6,Vne),e(Vne,Vat),e(i6,Xat),e(ve,zat),e(ve,d6),e(d6,exe),e(exe,Qat),e(d6,Wat),e(d6,Xne),e(Xne,Uat),e(d6,Hat),e(ve,Jat),e(ve,m6),e(m6,oxe),e(oxe,Yat),e(m6,Zat),e(m6,zne),e(zne,Kat),e(m6,ent),e(ve,ont),e(ve,c6),e(c6,rxe),e(rxe,rnt),e(c6,tnt),e(c6,Qne),e(Qne,ant),e(c6,nnt),e(ve,snt),e(ve,f6),e(f6,txe),e(txe,lnt),e(f6,int),e(f6,Wne),e(Wne,dnt),e(f6,mnt),e(ve,cnt),e(ve,g6),e(g6,axe),e(axe,fnt),e(g6,gnt),e(g6,Une),e(Une,hnt),e(g6,unt),e(ve,pnt),e(ve,h6),e(h6,nxe),e(nxe,_nt),e(h6,bnt),e(h6,Hne),e(Hne,vnt),e(h6,Fnt),e(ve,Tnt),e(ve,u6),e(u6,sxe),e(sxe,Mnt),e(u6,Ent),e(u6,Jne),e(Jne,Cnt),e(u6,wnt),e(ve,Ant),e(ve,p6),e(p6,lxe),e(lxe,Lnt),e(p6,ynt),e(p6,Yne),e(Yne,xnt),e(p6,$nt),e(ve,knt),e(ve,_6),e(_6,ixe),e(ixe,Snt),e(_6,Rnt),e(_6,Zne),e(Zne,Pnt),e(_6,Bnt),e(ve,Int),e(ve,b6),e(b6,dxe),e(dxe,Nnt),e(b6,qnt),e(b6,Kne),e(Kne,Dnt),e(b6,jnt),e(ve,Gnt),e(ve,v6),e(v6,mxe),e(mxe,Ont),e(v6,Vnt),e(v6,ese),e(ese,Xnt),e(v6,znt),e(ve,Qnt),e(ve,F6),e(F6,cxe),e(cxe,Wnt),e(F6,Unt),e(F6,ose),e(ose,Hnt),e(F6,Jnt),e(ve,Ynt),e(ve,T6),e(T6,fxe),e(fxe,Znt),e(T6,Knt),e(T6,rse),e(rse,est),e(T6,ost),e(ve,rst),e(ve,M6),e(M6,gxe),e(gxe,tst),e(M6,ast),e(M6,tse),e(tse,nst),e(M6,sst),e(Ur,lst),M(E6,Ur,null),b(c,ino,_),b(c,qc,_),e(qc,C6),e(C6,hxe),M(sP,hxe,null),e(qc,ist),e(qc,uxe),e(uxe,dst),b(c,dno,_),b(c,vr,_),M(lP,vr,null),e(vr,mst),e(vr,Dc),e(Dc,cst),e(Dc,ase),e(ase,fst),e(Dc,gst),e(Dc,nse),e(nse,hst),e(Dc,ust),e(vr,pst),e(vr,iP),e(iP,_st),e(iP,pxe),e(pxe,bst),e(iP,vst),e(vr,Fst),e(vr,sa),M(dP,sa,null),e(sa,Tst),e(sa,_xe),e(_xe,Mst),e(sa,Est),e(sa,jc),e(jc,Cst),e(jc,bxe),e(bxe,wst),e(jc,Ast),e(jc,sse),e(sse,Lst),e(jc,yst),e(sa,xst),M(w6,sa,null),e(vr,$st),e(vr,Hr),M(mP,Hr,null),e(Hr,kst),e(Hr,vxe),e(vxe,Sst),e(Hr,Rst),e(Hr,Xn),e(Xn,Pst),e(Xn,Fxe),e(Fxe,Bst),e(Xn,Ist),e(Xn,Txe),e(Txe,Nst),e(Xn,qst),e(Xn,Mxe),e(Mxe,Dst),e(Xn,jst),e(Hr,Gst),e(Hr,cP),e(cP,A6),e(A6,Exe),e(Exe,Ost),e(A6,Vst),e(A6,lse),e(lse,Xst),e(A6,zst),e(cP,Qst),e(cP,L6),e(L6,Cxe),e(Cxe,Wst),e(L6,Ust),e(L6,ise),e(ise,Hst),e(L6,Jst),e(Hr,Yst),M(y6,Hr,null),b(c,mno,_),b(c,Gc,_),e(Gc,x6),e(x6,wxe),M(fP,wxe,null),e(Gc,Zst),e(Gc,Axe),e(Axe,Kst),b(c,cno,_),b(c,Fr,_),M(gP,Fr,null),e(Fr,elt),e(Fr,Oc),e(Oc,olt),e(Oc,dse),e(dse,rlt),e(Oc,tlt),e(Oc,mse),e(mse,alt),e(Oc,nlt),e(Fr,slt),e(Fr,hP),e(hP,llt),e(hP,Lxe),e(Lxe,ilt),e(hP,dlt),e(Fr,mlt),e(Fr,la),M(uP,la,null),e(la,clt),e(la,yxe),e(yxe,flt),e(la,glt),e(la,Vc),e(Vc,hlt),e(Vc,xxe),e(xxe,ult),e(Vc,plt),e(Vc,cse),e(cse,_lt),e(Vc,blt),e(la,vlt),M($6,la,null),e(Fr,Flt),e(Fr,Jr),M(pP,Jr,null),e(Jr,Tlt),e(Jr,$xe),e($xe,Mlt),e(Jr,Elt),e(Jr,zn),e(zn,Clt),e(zn,kxe),e(kxe,wlt),e(zn,Alt),e(zn,Sxe),e(Sxe,Llt),e(zn,ylt),e(zn,Rxe),e(Rxe,xlt),e(zn,$lt),e(Jr,klt),e(Jr,Pxe),e(Pxe,k6),e(k6,Bxe),e(Bxe,Slt),e(k6,Rlt),e(k6,fse),e(fse,Plt),e(k6,Blt),e(Jr,Ilt),M(S6,Jr,null),b(c,fno,_),b(c,Xc,_),e(Xc,R6),e(R6,Ixe),M(_P,Ixe,null),e(Xc,Nlt),e(Xc,Nxe),e(Nxe,qlt),b(c,gno,_),b(c,Tr,_),M(bP,Tr,null),e(Tr,Dlt),e(Tr,zc),e(zc,jlt),e(zc,gse),e(gse,Glt),e(zc,Olt),e(zc,hse),e(hse,Vlt),e(zc,Xlt),e(Tr,zlt),e(Tr,vP),e(vP,Qlt),e(vP,qxe),e(qxe,Wlt),e(vP,Ult),e(Tr,Hlt),e(Tr,ia),M(FP,ia,null),e(ia,Jlt),e(ia,Dxe),e(Dxe,Ylt),e(ia,Zlt),e(ia,Qc),e(Qc,Klt),e(Qc,jxe),e(jxe,eit),e(Qc,oit),e(Qc,use),e(use,rit),e(Qc,tit),e(ia,ait),M(P6,ia,null),e(Tr,nit),e(Tr,Yr),M(TP,Yr,null),e(Yr,sit),e(Yr,Gxe),e(Gxe,lit),e(Yr,iit),e(Yr,Qn),e(Qn,dit),e(Qn,Oxe),e(Oxe,mit),e(Qn,cit),e(Qn,Vxe),e(Vxe,fit),e(Qn,git),e(Qn,Xxe),e(Xxe,hit),e(Qn,uit),e(Yr,pit),e(Yr,zxe),e(zxe,B6),e(B6,Qxe),e(Qxe,_it),e(B6,bit),e(B6,pse),e(pse,vit),e(B6,Fit),e(Yr,Tit),M(I6,Yr,null),b(c,hno,_),b(c,Wc,_),e(Wc,N6),e(N6,Wxe),M(MP,Wxe,null),e(Wc,Mit),e(Wc,Uxe),e(Uxe,Eit),b(c,uno,_),b(c,Mr,_),M(EP,Mr,null),e(Mr,Cit),e(Mr,Uc),e(Uc,wit),e(Uc,_se),e(_se,Ait),e(Uc,Lit),e(Uc,bse),e(bse,yit),e(Uc,xit),e(Mr,$it),e(Mr,CP),e(CP,kit),e(CP,Hxe),e(Hxe,Sit),e(CP,Rit),e(Mr,Pit),e(Mr,da),M(wP,da,null),e(da,Bit),e(da,Jxe),e(Jxe,Iit),e(da,Nit),e(da,Hc),e(Hc,qit),e(Hc,Yxe),e(Yxe,Dit),e(Hc,jit),e(Hc,vse),e(vse,Git),e(Hc,Oit),e(da,Vit),M(q6,da,null),e(Mr,Xit),e(Mr,Zr),M(AP,Zr,null),e(Zr,zit),e(Zr,Zxe),e(Zxe,Qit),e(Zr,Wit),e(Zr,Wn),e(Wn,Uit),e(Wn,Kxe),e(Kxe,Hit),e(Wn,Jit),e(Wn,e$e),e(e$e,Yit),e(Wn,Zit),e(Wn,o$e),e(o$e,Kit),e(Wn,edt),e(Zr,odt),e(Zr,ie),e(ie,D6),e(D6,r$e),e(r$e,rdt),e(D6,tdt),e(D6,Fse),e(Fse,adt),e(D6,ndt),e(ie,sdt),e(ie,j6),e(j6,t$e),e(t$e,ldt),e(j6,idt),e(j6,Tse),e(Tse,ddt),e(j6,mdt),e(ie,cdt),e(ie,G6),e(G6,a$e),e(a$e,fdt),e(G6,gdt),e(G6,Mse),e(Mse,hdt),e(G6,udt),e(ie,pdt),e(ie,O6),e(O6,n$e),e(n$e,_dt),e(O6,bdt),e(O6,Ese),e(Ese,vdt),e(O6,Fdt),e(ie,Tdt),e(ie,V6),e(V6,s$e),e(s$e,Mdt),e(V6,Edt),e(V6,Cse),e(Cse,Cdt),e(V6,wdt),e(ie,Adt),e(ie,X6),e(X6,l$e),e(l$e,Ldt),e(X6,ydt),e(X6,wse),e(wse,xdt),e(X6,$dt),e(ie,kdt),e(ie,z6),e(z6,i$e),e(i$e,Sdt),e(z6,Rdt),e(z6,Ase),e(Ase,Pdt),e(z6,Bdt),e(ie,Idt),e(ie,Q6),e(Q6,d$e),e(d$e,Ndt),e(Q6,qdt),e(Q6,Lse),e(Lse,Ddt),e(Q6,jdt),e(ie,Gdt),e(ie,W6),e(W6,m$e),e(m$e,Odt),e(W6,Vdt),e(W6,yse),e(yse,Xdt),e(W6,zdt),e(ie,Qdt),e(ie,U6),e(U6,c$e),e(c$e,Wdt),e(U6,Udt),e(U6,xse),e(xse,Hdt),e(U6,Jdt),e(ie,Ydt),e(ie,H6),e(H6,f$e),e(f$e,Zdt),e(H6,Kdt),e(H6,$se),e($se,emt),e(H6,omt),e(ie,rmt),e(ie,J6),e(J6,g$e),e(g$e,tmt),e(J6,amt),e(J6,kse),e(kse,nmt),e(J6,smt),e(ie,lmt),e(ie,Y6),e(Y6,h$e),e(h$e,imt),e(Y6,dmt),e(Y6,Sse),e(Sse,mmt),e(Y6,cmt),e(ie,fmt),e(ie,Z6),e(Z6,u$e),e(u$e,gmt),e(Z6,hmt),e(Z6,Rse),e(Rse,umt),e(Z6,pmt),e(ie,_mt),e(ie,K6),e(K6,p$e),e(p$e,bmt),e(K6,vmt),e(K6,Pse),e(Pse,Fmt),e(K6,Tmt),e(ie,Mmt),e(ie,e7),e(e7,_$e),e(_$e,Emt),e(e7,Cmt),e(e7,Bse),e(Bse,wmt),e(e7,Amt),e(ie,Lmt),e(ie,o7),e(o7,b$e),e(b$e,ymt),e(o7,xmt),e(o7,Ise),e(Ise,$mt),e(o7,kmt),e(ie,Smt),e(ie,r7),e(r7,v$e),e(v$e,Rmt),e(r7,Pmt),e(r7,Nse),e(Nse,Bmt),e(r7,Imt),e(ie,Nmt),e(ie,t7),e(t7,F$e),e(F$e,qmt),e(t7,Dmt),e(t7,qse),e(qse,jmt),e(t7,Gmt),e(ie,Omt),e(ie,a7),e(a7,T$e),e(T$e,Vmt),e(a7,Xmt),e(a7,Dse),e(Dse,zmt),e(a7,Qmt),e(ie,Wmt),e(ie,n7),e(n7,M$e),e(M$e,Umt),e(n7,Hmt),e(n7,jse),e(jse,Jmt),e(n7,Ymt),e(ie,Zmt),e(ie,s7),e(s7,E$e),e(E$e,Kmt),e(s7,ect),e(s7,Gse),e(Gse,oct),e(s7,rct),e(Zr,tct),M(l7,Zr,null),b(c,pno,_),b(c,Jc,_),e(Jc,i7),e(i7,C$e),M(LP,C$e,null),e(Jc,act),e(Jc,w$e),e(w$e,nct),b(c,_no,_),b(c,Er,_),M(yP,Er,null),e(Er,sct),e(Er,Yc),e(Yc,lct),e(Yc,Ose),e(Ose,ict),e(Yc,dct),e(Yc,Vse),e(Vse,mct),e(Yc,cct),e(Er,fct),e(Er,xP),e(xP,gct),e(xP,A$e),e(A$e,hct),e(xP,uct),e(Er,pct),e(Er,ma),M($P,ma,null),e(ma,_ct),e(ma,L$e),e(L$e,bct),e(ma,vct),e(ma,Zc),e(Zc,Fct),e(Zc,y$e),e(y$e,Tct),e(Zc,Mct),e(Zc,Xse),e(Xse,Ect),e(Zc,Cct),e(ma,wct),M(d7,ma,null),e(Er,Act),e(Er,Kr),M(kP,Kr,null),e(Kr,Lct),e(Kr,x$e),e(x$e,yct),e(Kr,xct),e(Kr,Un),e(Un,$ct),e(Un,$$e),e($$e,kct),e(Un,Sct),e(Un,k$e),e(k$e,Rct),e(Un,Pct),e(Un,S$e),e(S$e,Bct),e(Un,Ict),e(Kr,Nct),e(Kr,fe),e(fe,m7),e(m7,R$e),e(R$e,qct),e(m7,Dct),e(m7,zse),e(zse,jct),e(m7,Gct),e(fe,Oct),e(fe,c7),e(c7,P$e),e(P$e,Vct),e(c7,Xct),e(c7,Qse),e(Qse,zct),e(c7,Qct),e(fe,Wct),e(fe,f7),e(f7,B$e),e(B$e,Uct),e(f7,Hct),e(f7,Wse),e(Wse,Jct),e(f7,Yct),e(fe,Zct),e(fe,g7),e(g7,I$e),e(I$e,Kct),e(g7,eft),e(g7,Use),e(Use,oft),e(g7,rft),e(fe,tft),e(fe,h7),e(h7,N$e),e(N$e,aft),e(h7,nft),e(h7,Hse),e(Hse,sft),e(h7,lft),e(fe,ift),e(fe,u7),e(u7,q$e),e(q$e,dft),e(u7,mft),e(u7,Jse),e(Jse,cft),e(u7,fft),e(fe,gft),e(fe,p7),e(p7,D$e),e(D$e,hft),e(p7,uft),e(p7,Yse),e(Yse,pft),e(p7,_ft),e(fe,bft),e(fe,_7),e(_7,j$e),e(j$e,vft),e(_7,Fft),e(_7,Zse),e(Zse,Tft),e(_7,Mft),e(fe,Eft),e(fe,b7),e(b7,G$e),e(G$e,Cft),e(b7,wft),e(b7,Kse),e(Kse,Aft),e(b7,Lft),e(fe,yft),e(fe,v7),e(v7,O$e),e(O$e,xft),e(v7,$ft),e(v7,ele),e(ele,kft),e(v7,Sft),e(fe,Rft),e(fe,F7),e(F7,V$e),e(V$e,Pft),e(F7,Bft),e(F7,ole),e(ole,Ift),e(F7,Nft),e(fe,qft),e(fe,T7),e(T7,X$e),e(X$e,Dft),e(T7,jft),e(T7,rle),e(rle,Gft),e(T7,Oft),e(fe,Vft),e(fe,M7),e(M7,z$e),e(z$e,Xft),e(M7,zft),e(M7,tle),e(tle,Qft),e(M7,Wft),e(fe,Uft),e(fe,E7),e(E7,Q$e),e(Q$e,Hft),e(E7,Jft),e(E7,ale),e(ale,Yft),e(E7,Zft),e(fe,Kft),e(fe,C7),e(C7,W$e),e(W$e,egt),e(C7,ogt),e(C7,nle),e(nle,rgt),e(C7,tgt),e(fe,agt),e(fe,w7),e(w7,U$e),e(U$e,ngt),e(w7,sgt),e(w7,sle),e(sle,lgt),e(w7,igt),e(fe,dgt),e(fe,A7),e(A7,H$e),e(H$e,mgt),e(A7,cgt),e(A7,lle),e(lle,fgt),e(A7,ggt),e(fe,hgt),e(fe,L7),e(L7,J$e),e(J$e,ugt),e(L7,pgt),e(L7,ile),e(ile,_gt),e(L7,bgt),e(fe,vgt),e(fe,y7),e(y7,Y$e),e(Y$e,Fgt),e(y7,Tgt),e(y7,dle),e(dle,Mgt),e(y7,Egt),e(fe,Cgt),e(fe,x7),e(x7,Z$e),e(Z$e,wgt),e(x7,Agt),e(x7,mle),e(mle,Lgt),e(x7,ygt),e(fe,xgt),e(fe,$7),e($7,K$e),e(K$e,$gt),e($7,kgt),e($7,cle),e(cle,Sgt),e($7,Rgt),e(Kr,Pgt),M(k7,Kr,null),b(c,bno,_),b(c,Kc,_),e(Kc,S7),e(S7,eke),M(SP,eke,null),e(Kc,Bgt),e(Kc,oke),e(oke,Igt),b(c,vno,_),b(c,Cr,_),M(RP,Cr,null),e(Cr,Ngt),e(Cr,ef),e(ef,qgt),e(ef,fle),e(fle,Dgt),e(ef,jgt),e(ef,gle),e(gle,Ggt),e(ef,Ogt),e(Cr,Vgt),e(Cr,PP),e(PP,Xgt),e(PP,rke),e(rke,zgt),e(PP,Qgt),e(Cr,Wgt),e(Cr,ca),M(BP,ca,null),e(ca,Ugt),e(ca,tke),e(tke,Hgt),e(ca,Jgt),e(ca,of),e(of,Ygt),e(of,ake),e(ake,Zgt),e(of,Kgt),e(of,hle),e(hle,eht),e(of,oht),e(ca,rht),M(R7,ca,null),e(Cr,tht),e(Cr,et),M(IP,et,null),e(et,aht),e(et,nke),e(nke,nht),e(et,sht),e(et,Hn),e(Hn,lht),e(Hn,ske),e(ske,iht),e(Hn,dht),e(Hn,lke),e(lke,mht),e(Hn,cht),e(Hn,ike),e(ike,fht),e(Hn,ght),e(et,hht),e(et,dke),e(dke,P7),e(P7,mke),e(mke,uht),e(P7,pht),e(P7,ule),e(ule,_ht),e(P7,bht),e(et,vht),M(B7,et,null),b(c,Fno,_),b(c,rf,_),e(rf,I7),e(I7,cke),M(NP,cke,null),e(rf,Fht),e(rf,fke),e(fke,Tht),b(c,Tno,_),b(c,wr,_),M(qP,wr,null),e(wr,Mht),e(wr,tf),e(tf,Eht),e(tf,ple),e(ple,Cht),e(tf,wht),e(tf,_le),e(_le,Aht),e(tf,Lht),e(wr,yht),e(wr,DP),e(DP,xht),e(DP,gke),e(gke,$ht),e(DP,kht),e(wr,Sht),e(wr,fa),M(jP,fa,null),e(fa,Rht),e(fa,hke),e(hke,Pht),e(fa,Bht),e(fa,af),e(af,Iht),e(af,uke),e(uke,Nht),e(af,qht),e(af,ble),e(ble,Dht),e(af,jht),e(fa,Ght),M(N7,fa,null),e(wr,Oht),e(wr,ot),M(GP,ot,null),e(ot,Vht),e(ot,pke),e(pke,Xht),e(ot,zht),e(ot,Jn),e(Jn,Qht),e(Jn,_ke),e(_ke,Wht),e(Jn,Uht),e(Jn,bke),e(bke,Hht),e(Jn,Jht),e(Jn,vke),e(vke,Yht),e(Jn,Zht),e(ot,Kht),e(ot,OP),e(OP,q7),e(q7,Fke),e(Fke,eut),e(q7,out),e(q7,vle),e(vle,rut),e(q7,tut),e(OP,aut),e(OP,D7),e(D7,Tke),e(Tke,nut),e(D7,sut),e(D7,Fle),e(Fle,lut),e(D7,iut),e(ot,dut),M(j7,ot,null),b(c,Mno,_),b(c,nf,_),e(nf,G7),e(G7,Mke),M(VP,Mke,null),e(nf,mut),e(nf,Eke),e(Eke,cut),b(c,Eno,_),b(c,Ar,_),M(XP,Ar,null),e(Ar,fut),e(Ar,sf),e(sf,gut),e(sf,Tle),e(Tle,hut),e(sf,uut),e(sf,Mle),e(Mle,put),e(sf,_ut),e(Ar,but),e(Ar,zP),e(zP,vut),e(zP,Cke),e(Cke,Fut),e(zP,Tut),e(Ar,Mut),e(Ar,ga),M(QP,ga,null),e(ga,Eut),e(ga,wke),e(wke,Cut),e(ga,wut),e(ga,lf),e(lf,Aut),e(lf,Ake),e(Ake,Lut),e(lf,yut),e(lf,Ele),e(Ele,xut),e(lf,$ut),e(ga,kut),M(O7,ga,null),e(Ar,Sut),e(Ar,rt),M(WP,rt,null),e(rt,Rut),e(rt,Lke),e(Lke,Put),e(rt,But),e(rt,Yn),e(Yn,Iut),e(Yn,yke),e(yke,Nut),e(Yn,qut),e(Yn,xke),e(xke,Dut),e(Yn,jut),e(Yn,$ke),e($ke,Gut),e(Yn,Out),e(rt,Vut),e(rt,te),e(te,V7),e(V7,kke),e(kke,Xut),e(V7,zut),e(V7,Cle),e(Cle,Qut),e(V7,Wut),e(te,Uut),e(te,X7),e(X7,Ske),e(Ske,Hut),e(X7,Jut),e(X7,wle),e(wle,Yut),e(X7,Zut),e(te,Kut),e(te,z7),e(z7,Rke),e(Rke,ept),e(z7,opt),e(z7,Ale),e(Ale,rpt),e(z7,tpt),e(te,apt),e(te,Q7),e(Q7,Pke),e(Pke,npt),e(Q7,spt),e(Q7,Lle),e(Lle,lpt),e(Q7,ipt),e(te,dpt),e(te,W7),e(W7,Bke),e(Bke,mpt),e(W7,cpt),e(W7,yle),e(yle,fpt),e(W7,gpt),e(te,hpt),e(te,U7),e(U7,Ike),e(Ike,upt),e(U7,ppt),e(U7,xle),e(xle,_pt),e(U7,bpt),e(te,vpt),e(te,H7),e(H7,Nke),e(Nke,Fpt),e(H7,Tpt),e(H7,$le),e($le,Mpt),e(H7,Ept),e(te,Cpt),e(te,J7),e(J7,qke),e(qke,wpt),e(J7,Apt),e(J7,kle),e(kle,Lpt),e(J7,ypt),e(te,xpt),e(te,Y7),e(Y7,Dke),e(Dke,$pt),e(Y7,kpt),e(Y7,Sle),e(Sle,Spt),e(Y7,Rpt),e(te,Ppt),e(te,Z7),e(Z7,jke),e(jke,Bpt),e(Z7,Ipt),e(Z7,Rle),e(Rle,Npt),e(Z7,qpt),e(te,Dpt),e(te,K7),e(K7,Gke),e(Gke,jpt),e(K7,Gpt),e(K7,Ple),e(Ple,Opt),e(K7,Vpt),e(te,Xpt),e(te,e8),e(e8,Oke),e(Oke,zpt),e(e8,Qpt),e(e8,Ble),e(Ble,Wpt),e(e8,Upt),e(te,Hpt),e(te,o8),e(o8,Vke),e(Vke,Jpt),e(o8,Ypt),e(o8,Ile),e(Ile,Zpt),e(o8,Kpt),e(te,e_t),e(te,r8),e(r8,Xke),e(Xke,o_t),e(r8,r_t),e(r8,Nle),e(Nle,t_t),e(r8,a_t),e(te,n_t),e(te,t8),e(t8,zke),e(zke,s_t),e(t8,l_t),e(t8,qle),e(qle,i_t),e(t8,d_t),e(te,m_t),e(te,a8),e(a8,Qke),e(Qke,c_t),e(a8,f_t),e(a8,Dle),e(Dle,g_t),e(a8,h_t),e(te,u_t),e(te,n8),e(n8,Wke),e(Wke,p_t),e(n8,__t),e(n8,jle),e(jle,b_t),e(n8,v_t),e(te,F_t),e(te,s8),e(s8,Uke),e(Uke,T_t),e(s8,M_t),e(s8,Gle),e(Gle,E_t),e(s8,C_t),e(te,w_t),e(te,l8),e(l8,Hke),e(Hke,A_t),e(l8,L_t),e(l8,Ole),e(Ole,y_t),e(l8,x_t),e(te,$_t),e(te,i8),e(i8,Jke),e(Jke,k_t),e(i8,S_t),e(i8,Vle),e(Vle,R_t),e(i8,P_t),e(te,B_t),e(te,d8),e(d8,Yke),e(Yke,I_t),e(d8,N_t),e(d8,Xle),e(Xle,q_t),e(d8,D_t),e(te,j_t),e(te,m8),e(m8,Zke),e(Zke,G_t),e(m8,O_t),e(m8,zle),e(zle,V_t),e(m8,X_t),e(te,z_t),e(te,c8),e(c8,Kke),e(Kke,Q_t),e(c8,W_t),e(c8,Qle),e(Qle,U_t),e(c8,H_t),e(te,J_t),e(te,f8),e(f8,eSe),e(eSe,Y_t),e(f8,Z_t),e(f8,Wle),e(Wle,K_t),e(f8,e1t),e(te,o1t),e(te,g8),e(g8,oSe),e(oSe,r1t),e(g8,t1t),e(g8,Ule),e(Ule,a1t),e(g8,n1t),e(te,s1t),e(te,h8),e(h8,rSe),e(rSe,l1t),e(h8,i1t),e(h8,Hle),e(Hle,d1t),e(h8,m1t),e(te,c1t),e(te,u8),e(u8,tSe),e(tSe,f1t),e(u8,g1t),e(u8,Jle),e(Jle,h1t),e(u8,u1t),e(rt,p1t),M(p8,rt,null),b(c,Cno,_),b(c,df,_),e(df,_8),e(_8,aSe),M(UP,aSe,null),e(df,_1t),e(df,nSe),e(nSe,b1t),b(c,wno,_),b(c,Lr,_),M(HP,Lr,null),e(Lr,v1t),e(Lr,mf),e(mf,F1t),e(mf,Yle),e(Yle,T1t),e(mf,M1t),e(mf,Zle),e(Zle,E1t),e(mf,C1t),e(Lr,w1t),e(Lr,JP),e(JP,A1t),e(JP,sSe),e(sSe,L1t),e(JP,y1t),e(Lr,x1t),e(Lr,ha),M(YP,ha,null),e(ha,$1t),e(ha,lSe),e(lSe,k1t),e(ha,S1t),e(ha,cf),e(cf,R1t),e(cf,iSe),e(iSe,P1t),e(cf,B1t),e(cf,Kle),e(Kle,I1t),e(cf,N1t),e(ha,q1t),M(b8,ha,null),e(Lr,D1t),e(Lr,tt),M(ZP,tt,null),e(tt,j1t),e(tt,dSe),e(dSe,G1t),e(tt,O1t),e(tt,Zn),e(Zn,V1t),e(Zn,mSe),e(mSe,X1t),e(Zn,z1t),e(Zn,cSe),e(cSe,Q1t),e(Zn,W1t),e(Zn,fSe),e(fSe,U1t),e(Zn,H1t),e(tt,J1t),e(tt,$e),e($e,v8),e(v8,gSe),e(gSe,Y1t),e(v8,Z1t),e(v8,eie),e(eie,K1t),e(v8,e2t),e($e,o2t),e($e,F8),e(F8,hSe),e(hSe,r2t),e(F8,t2t),e(F8,oie),e(oie,a2t),e(F8,n2t),e($e,s2t),e($e,T8),e(T8,uSe),e(uSe,l2t),e(T8,i2t),e(T8,rie),e(rie,d2t),e(T8,m2t),e($e,c2t),e($e,M8),e(M8,pSe),e(pSe,f2t),e(M8,g2t),e(M8,tie),e(tie,h2t),e(M8,u2t),e($e,p2t),e($e,E8),e(E8,_Se),e(_Se,_2t),e(E8,b2t),e(E8,aie),e(aie,v2t),e(E8,F2t),e($e,T2t),e($e,C8),e(C8,bSe),e(bSe,M2t),e(C8,E2t),e(C8,nie),e(nie,C2t),e(C8,w2t),e($e,A2t),e($e,w8),e(w8,vSe),e(vSe,L2t),e(w8,y2t),e(w8,sie),e(sie,x2t),e(w8,$2t),e($e,k2t),e($e,A8),e(A8,FSe),e(FSe,S2t),e(A8,R2t),e(A8,lie),e(lie,P2t),e(A8,B2t),e($e,I2t),e($e,L8),e(L8,TSe),e(TSe,N2t),e(L8,q2t),e(L8,iie),e(iie,D2t),e(L8,j2t),e($e,G2t),e($e,y8),e(y8,MSe),e(MSe,O2t),e(y8,V2t),e(y8,die),e(die,X2t),e(y8,z2t),e(tt,Q2t),M(x8,tt,null),b(c,Ano,_),b(c,ff,_),e(ff,$8),e($8,ESe),M(KP,ESe,null),e(ff,W2t),e(ff,CSe),e(CSe,U2t),b(c,Lno,_),b(c,yr,_),M(eB,yr,null),e(yr,H2t),e(yr,gf),e(gf,J2t),e(gf,mie),e(mie,Y2t),e(gf,Z2t),e(gf,cie),e(cie,K2t),e(gf,ebt),e(yr,obt),e(yr,oB),e(oB,rbt),e(oB,wSe),e(wSe,tbt),e(oB,abt),e(yr,nbt),e(yr,ua),M(rB,ua,null),e(ua,sbt),e(ua,ASe),e(ASe,lbt),e(ua,ibt),e(ua,hf),e(hf,dbt),e(hf,LSe),e(LSe,mbt),e(hf,cbt),e(hf,fie),e(fie,fbt),e(hf,gbt),e(ua,hbt),M(k8,ua,null),e(yr,ubt),e(yr,at),M(tB,at,null),e(at,pbt),e(at,ySe),e(ySe,_bt),e(at,bbt),e(at,Kn),e(Kn,vbt),e(Kn,xSe),e(xSe,Fbt),e(Kn,Tbt),e(Kn,$Se),e($Se,Mbt),e(Kn,Ebt),e(Kn,kSe),e(kSe,Cbt),e(Kn,wbt),e(at,Abt),e(at,Ee),e(Ee,S8),e(S8,SSe),e(SSe,Lbt),e(S8,ybt),e(S8,gie),e(gie,xbt),e(S8,$bt),e(Ee,kbt),e(Ee,R8),e(R8,RSe),e(RSe,Sbt),e(R8,Rbt),e(R8,hie),e(hie,Pbt),e(R8,Bbt),e(Ee,Ibt),e(Ee,P8),e(P8,PSe),e(PSe,Nbt),e(P8,qbt),e(P8,uie),e(uie,Dbt),e(P8,jbt),e(Ee,Gbt),e(Ee,B8),e(B8,BSe),e(BSe,Obt),e(B8,Vbt),e(B8,pie),e(pie,Xbt),e(B8,zbt),e(Ee,Qbt),e(Ee,I8),e(I8,ISe),e(ISe,Wbt),e(I8,Ubt),e(I8,_ie),e(_ie,Hbt),e(I8,Jbt),e(Ee,Ybt),e(Ee,N8),e(N8,NSe),e(NSe,Zbt),e(N8,Kbt),e(N8,bie),e(bie,evt),e(N8,ovt),e(Ee,rvt),e(Ee,q8),e(q8,qSe),e(qSe,tvt),e(q8,avt),e(q8,vie),e(vie,nvt),e(q8,svt),e(Ee,lvt),e(Ee,D8),e(D8,DSe),e(DSe,ivt),e(D8,dvt),e(D8,Fie),e(Fie,mvt),e(D8,cvt),e(Ee,fvt),e(Ee,j8),e(j8,jSe),e(jSe,gvt),e(j8,hvt),e(j8,Tie),e(Tie,uvt),e(j8,pvt),e(Ee,_vt),e(Ee,G8),e(G8,GSe),e(GSe,bvt),e(G8,vvt),e(G8,Mie),e(Mie,Fvt),e(G8,Tvt),e(Ee,Mvt),e(Ee,O8),e(O8,OSe),e(OSe,Evt),e(O8,Cvt),e(O8,Eie),e(Eie,wvt),e(O8,Avt),e(Ee,Lvt),e(Ee,V8),e(V8,VSe),e(VSe,yvt),e(V8,xvt),e(V8,Cie),e(Cie,$vt),e(V8,kvt),e(Ee,Svt),e(Ee,X8),e(X8,XSe),e(XSe,Rvt),e(X8,Pvt),e(X8,wie),e(wie,Bvt),e(X8,Ivt),e(at,Nvt),M(z8,at,null),b(c,yno,_),b(c,uf,_),e(uf,Q8),e(Q8,zSe),M(aB,zSe,null),e(uf,qvt),e(uf,QSe),e(QSe,Dvt),b(c,xno,_),b(c,xr,_),M(nB,xr,null),e(xr,jvt),e(xr,pf),e(pf,Gvt),e(pf,Aie),e(Aie,Ovt),e(pf,Vvt),e(pf,Lie),e(Lie,Xvt),e(pf,zvt),e(xr,Qvt),e(xr,sB),e(sB,Wvt),e(sB,WSe),e(WSe,Uvt),e(sB,Hvt),e(xr,Jvt),e(xr,pa),M(lB,pa,null),e(pa,Yvt),e(pa,USe),e(USe,Zvt),e(pa,Kvt),e(pa,_f),e(_f,eFt),e(_f,HSe),e(HSe,oFt),e(_f,rFt),e(_f,yie),e(yie,tFt),e(_f,aFt),e(pa,nFt),M(W8,pa,null),e(xr,sFt),e(xr,nt),M(iB,nt,null),e(nt,lFt),e(nt,JSe),e(JSe,iFt),e(nt,dFt),e(nt,es),e(es,mFt),e(es,YSe),e(YSe,cFt),e(es,fFt),e(es,ZSe),e(ZSe,gFt),e(es,hFt),e(es,KSe),e(KSe,uFt),e(es,pFt),e(nt,_Ft),e(nt,ke),e(ke,U8),e(U8,eRe),e(eRe,bFt),e(U8,vFt),e(U8,xie),e(xie,FFt),e(U8,TFt),e(ke,MFt),e(ke,H8),e(H8,oRe),e(oRe,EFt),e(H8,CFt),e(H8,$ie),e($ie,wFt),e(H8,AFt),e(ke,LFt),e(ke,J8),e(J8,rRe),e(rRe,yFt),e(J8,xFt),e(J8,kie),e(kie,$Ft),e(J8,kFt),e(ke,SFt),e(ke,Y8),e(Y8,tRe),e(tRe,RFt),e(Y8,PFt),e(Y8,Sie),e(Sie,BFt),e(Y8,IFt),e(ke,NFt),e(ke,Z8),e(Z8,aRe),e(aRe,qFt),e(Z8,DFt),e(Z8,Rie),e(Rie,jFt),e(Z8,GFt),e(ke,OFt),e(ke,K8),e(K8,nRe),e(nRe,VFt),e(K8,XFt),e(K8,Pie),e(Pie,zFt),e(K8,QFt),e(ke,WFt),e(ke,eL),e(eL,sRe),e(sRe,UFt),e(eL,HFt),e(eL,Bie),e(Bie,JFt),e(eL,YFt),e(ke,ZFt),e(ke,oL),e(oL,lRe),e(lRe,KFt),e(oL,eTt),e(oL,Iie),e(Iie,oTt),e(oL,rTt),e(ke,tTt),e(ke,rL),e(rL,iRe),e(iRe,aTt),e(rL,nTt),e(rL,Nie),e(Nie,sTt),e(rL,lTt),e(ke,iTt),e(ke,tL),e(tL,dRe),e(dRe,dTt),e(tL,mTt),e(tL,qie),e(qie,cTt),e(tL,fTt),e(nt,gTt),M(aL,nt,null),b(c,$no,_),b(c,bf,_),e(bf,nL),e(nL,mRe),M(dB,mRe,null),e(bf,hTt),e(bf,cRe),e(cRe,uTt),b(c,kno,_),b(c,$r,_),M(mB,$r,null),e($r,pTt),e($r,vf),e(vf,_Tt),e(vf,Die),e(Die,bTt),e(vf,vTt),e(vf,jie),e(jie,FTt),e(vf,TTt),e($r,MTt),e($r,cB),e(cB,ETt),e(cB,fRe),e(fRe,CTt),e(cB,wTt),e($r,ATt),e($r,_a),M(fB,_a,null),e(_a,LTt),e(_a,gRe),e(gRe,yTt),e(_a,xTt),e(_a,Ff),e(Ff,$Tt),e(Ff,hRe),e(hRe,kTt),e(Ff,STt),e(Ff,Gie),e(Gie,RTt),e(Ff,PTt),e(_a,BTt),M(sL,_a,null),e($r,ITt),e($r,st),M(gB,st,null),e(st,NTt),e(st,uRe),e(uRe,qTt),e(st,DTt),e(st,os),e(os,jTt),e(os,pRe),e(pRe,GTt),e(os,OTt),e(os,_Re),e(_Re,VTt),e(os,XTt),e(os,bRe),e(bRe,zTt),e(os,QTt),e(st,WTt),e(st,Se),e(Se,lL),e(lL,vRe),e(vRe,UTt),e(lL,HTt),e(lL,Oie),e(Oie,JTt),e(lL,YTt),e(Se,ZTt),e(Se,iL),e(iL,FRe),e(FRe,KTt),e(iL,eMt),e(iL,Vie),e(Vie,oMt),e(iL,rMt),e(Se,tMt),e(Se,dL),e(dL,TRe),e(TRe,aMt),e(dL,nMt),e(dL,Xie),e(Xie,sMt),e(dL,lMt),e(Se,iMt),e(Se,mL),e(mL,MRe),e(MRe,dMt),e(mL,mMt),e(mL,zie),e(zie,cMt),e(mL,fMt),e(Se,gMt),e(Se,cL),e(cL,ERe),e(ERe,hMt),e(cL,uMt),e(cL,Qie),e(Qie,pMt),e(cL,_Mt),e(Se,bMt),e(Se,fL),e(fL,CRe),e(CRe,vMt),e(fL,FMt),e(fL,Wie),e(Wie,TMt),e(fL,MMt),e(Se,EMt),e(Se,gL),e(gL,wRe),e(wRe,CMt),e(gL,wMt),e(gL,Uie),e(Uie,AMt),e(gL,LMt),e(Se,yMt),e(Se,hL),e(hL,ARe),e(ARe,xMt),e(hL,$Mt),e(hL,Hie),e(Hie,kMt),e(hL,SMt),e(Se,RMt),e(Se,uL),e(uL,LRe),e(LRe,PMt),e(uL,BMt),e(uL,Jie),e(Jie,IMt),e(uL,NMt),e(Se,qMt),e(Se,pL),e(pL,yRe),e(yRe,DMt),e(pL,jMt),e(pL,Yie),e(Yie,GMt),e(pL,OMt),e(st,VMt),M(_L,st,null),b(c,Sno,_),b(c,Tf,_),e(Tf,bL),e(bL,xRe),M(hB,xRe,null),e(Tf,XMt),e(Tf,$Re),e($Re,zMt),b(c,Rno,_),b(c,kr,_),M(uB,kr,null),e(kr,QMt),e(kr,Mf),e(Mf,WMt),e(Mf,Zie),e(Zie,UMt),e(Mf,HMt),e(Mf,Kie),e(Kie,JMt),e(Mf,YMt),e(kr,ZMt),e(kr,pB),e(pB,KMt),e(pB,kRe),e(kRe,eEt),e(pB,oEt),e(kr,rEt),e(kr,ba),M(_B,ba,null),e(ba,tEt),e(ba,SRe),e(SRe,aEt),e(ba,nEt),e(ba,Ef),e(Ef,sEt),e(Ef,RRe),e(RRe,lEt),e(Ef,iEt),e(Ef,ede),e(ede,dEt),e(Ef,mEt),e(ba,cEt),M(vL,ba,null),e(kr,fEt),e(kr,lt),M(bB,lt,null),e(lt,gEt),e(lt,PRe),e(PRe,hEt),e(lt,uEt),e(lt,rs),e(rs,pEt),e(rs,BRe),e(BRe,_Et),e(rs,bEt),e(rs,IRe),e(IRe,vEt),e(rs,FEt),e(rs,NRe),e(NRe,TEt),e(rs,MEt),e(lt,EEt),e(lt,Re),e(Re,FL),e(FL,qRe),e(qRe,CEt),e(FL,wEt),e(FL,ode),e(ode,AEt),e(FL,LEt),e(Re,yEt),e(Re,TL),e(TL,DRe),e(DRe,xEt),e(TL,$Et),e(TL,rde),e(rde,kEt),e(TL,SEt),e(Re,REt),e(Re,ML),e(ML,jRe),e(jRe,PEt),e(ML,BEt),e(ML,tde),e(tde,IEt),e(ML,NEt),e(Re,qEt),e(Re,EL),e(EL,GRe),e(GRe,DEt),e(EL,jEt),e(EL,ade),e(ade,GEt),e(EL,OEt),e(Re,VEt),e(Re,CL),e(CL,ORe),e(ORe,XEt),e(CL,zEt),e(CL,nde),e(nde,QEt),e(CL,WEt),e(Re,UEt),e(Re,wL),e(wL,VRe),e(VRe,HEt),e(wL,JEt),e(wL,sde),e(sde,YEt),e(wL,ZEt),e(Re,KEt),e(Re,AL),e(AL,XRe),e(XRe,e4t),e(AL,o4t),e(AL,lde),e(lde,r4t),e(AL,t4t),e(Re,a4t),e(Re,LL),e(LL,zRe),e(zRe,n4t),e(LL,s4t),e(LL,ide),e(ide,l4t),e(LL,i4t),e(Re,d4t),e(Re,yL),e(yL,QRe),e(QRe,m4t),e(yL,c4t),e(yL,dde),e(dde,f4t),e(yL,g4t),e(Re,h4t),e(Re,xL),e(xL,WRe),e(WRe,u4t),e(xL,p4t),e(xL,mde),e(mde,_4t),e(xL,b4t),e(lt,v4t),M($L,lt,null),b(c,Pno,_),b(c,Cf,_),e(Cf,kL),e(kL,URe),M(vB,URe,null),e(Cf,F4t),e(Cf,HRe),e(HRe,T4t),b(c,Bno,_),b(c,Sr,_),M(FB,Sr,null),e(Sr,M4t),e(Sr,wf),e(wf,E4t),e(wf,cde),e(cde,C4t),e(wf,w4t),e(wf,fde),e(fde,A4t),e(wf,L4t),e(Sr,y4t),e(Sr,TB),e(TB,x4t),e(TB,JRe),e(JRe,$4t),e(TB,k4t),e(Sr,S4t),e(Sr,va),M(MB,va,null),e(va,R4t),e(va,YRe),e(YRe,P4t),e(va,B4t),e(va,Af),e(Af,I4t),e(Af,ZRe),e(ZRe,N4t),e(Af,q4t),e(Af,gde),e(gde,D4t),e(Af,j4t),e(va,G4t),M(SL,va,null),e(Sr,O4t),e(Sr,it),M(EB,it,null),e(it,V4t),e(it,KRe),e(KRe,X4t),e(it,z4t),e(it,ts),e(ts,Q4t),e(ts,ePe),e(ePe,W4t),e(ts,U4t),e(ts,oPe),e(oPe,H4t),e(ts,J4t),e(ts,rPe),e(rPe,Y4t),e(ts,Z4t),e(it,K4t),e(it,Pe),e(Pe,RL),e(RL,tPe),e(tPe,eCt),e(RL,oCt),e(RL,hde),e(hde,rCt),e(RL,tCt),e(Pe,aCt),e(Pe,PL),e(PL,aPe),e(aPe,nCt),e(PL,sCt),e(PL,ude),e(ude,lCt),e(PL,iCt),e(Pe,dCt),e(Pe,BL),e(BL,nPe),e(nPe,mCt),e(BL,cCt),e(BL,pde),e(pde,fCt),e(BL,gCt),e(Pe,hCt),e(Pe,IL),e(IL,sPe),e(sPe,uCt),e(IL,pCt),e(IL,_de),e(_de,_Ct),e(IL,bCt),e(Pe,vCt),e(Pe,NL),e(NL,lPe),e(lPe,FCt),e(NL,TCt),e(NL,bde),e(bde,MCt),e(NL,ECt),e(Pe,CCt),e(Pe,qL),e(qL,iPe),e(iPe,wCt),e(qL,ACt),e(qL,vde),e(vde,LCt),e(qL,yCt),e(Pe,xCt),e(Pe,DL),e(DL,dPe),e(dPe,$Ct),e(DL,kCt),e(DL,Fde),e(Fde,SCt),e(DL,RCt),e(Pe,PCt),e(Pe,jL),e(jL,mPe),e(mPe,BCt),e(jL,ICt),e(jL,Tde),e(Tde,NCt),e(jL,qCt),e(Pe,DCt),e(Pe,GL),e(GL,cPe),e(cPe,jCt),e(GL,GCt),e(GL,Mde),e(Mde,OCt),e(GL,VCt),e(Pe,XCt),e(Pe,OL),e(OL,fPe),e(fPe,zCt),e(OL,QCt),e(OL,Ede),e(Ede,WCt),e(OL,UCt),e(it,HCt),M(VL,it,null),b(c,Ino,_),b(c,Lf,_),e(Lf,XL),e(XL,gPe),M(CB,gPe,null),e(Lf,JCt),e(Lf,hPe),e(hPe,YCt),b(c,Nno,_),b(c,Rr,_),M(wB,Rr,null),e(Rr,ZCt),e(Rr,yf),e(yf,KCt),e(yf,Cde),e(Cde,e3t),e(yf,o3t),e(yf,wde),e(wde,r3t),e(yf,t3t),e(Rr,a3t),e(Rr,AB),e(AB,n3t),e(AB,uPe),e(uPe,s3t),e(AB,l3t),e(Rr,i3t),e(Rr,Fa),M(LB,Fa,null),e(Fa,d3t),e(Fa,pPe),e(pPe,m3t),e(Fa,c3t),e(Fa,xf),e(xf,f3t),e(xf,_Pe),e(_Pe,g3t),e(xf,h3t),e(xf,Ade),e(Ade,u3t),e(xf,p3t),e(Fa,_3t),M(zL,Fa,null),e(Rr,b3t),e(Rr,dt),M(yB,dt,null),e(dt,v3t),e(dt,bPe),e(bPe,F3t),e(dt,T3t),e(dt,as),e(as,M3t),e(as,vPe),e(vPe,E3t),e(as,C3t),e(as,FPe),e(FPe,w3t),e(as,A3t),e(as,TPe),e(TPe,L3t),e(as,y3t),e(dt,x3t),e(dt,ze),e(ze,QL),e(QL,MPe),e(MPe,$3t),e(QL,k3t),e(QL,Lde),e(Lde,S3t),e(QL,R3t),e(ze,P3t),e(ze,WL),e(WL,EPe),e(EPe,B3t),e(WL,I3t),e(WL,yde),e(yde,N3t),e(WL,q3t),e(ze,D3t),e(ze,UL),e(UL,CPe),e(CPe,j3t),e(UL,G3t),e(UL,xde),e(xde,O3t),e(UL,V3t),e(ze,X3t),e(ze,HL),e(HL,wPe),e(wPe,z3t),e(HL,Q3t),e(HL,$de),e($de,W3t),e(HL,U3t),e(ze,H3t),e(ze,JL),e(JL,APe),e(APe,J3t),e(JL,Y3t),e(JL,kde),e(kde,Z3t),e(JL,K3t),e(ze,e5t),e(ze,YL),e(YL,LPe),e(LPe,o5t),e(YL,r5t),e(YL,Sde),e(Sde,t5t),e(YL,a5t),e(ze,n5t),e(ze,ZL),e(ZL,yPe),e(yPe,s5t),e(ZL,l5t),e(ZL,Rde),e(Rde,i5t),e(ZL,d5t),e(ze,m5t),e(ze,KL),e(KL,xPe),e(xPe,c5t),e(KL,f5t),e(KL,Pde),e(Pde,g5t),e(KL,h5t),e(dt,u5t),M(ey,dt,null),b(c,qno,_),b(c,$f,_),e($f,oy),e(oy,$Pe),M(xB,$Pe,null),e($f,p5t),e($f,kPe),e(kPe,_5t),b(c,Dno,_),b(c,Pr,_),M($B,Pr,null),e(Pr,b5t),e(Pr,kf),e(kf,v5t),e(kf,Bde),e(Bde,F5t),e(kf,T5t),e(kf,Ide),e(Ide,M5t),e(kf,E5t),e(Pr,C5t),e(Pr,kB),e(kB,w5t),e(kB,SPe),e(SPe,A5t),e(kB,L5t),e(Pr,y5t),e(Pr,Ta),M(SB,Ta,null),e(Ta,x5t),e(Ta,RPe),e(RPe,$5t),e(Ta,k5t),e(Ta,Sf),e(Sf,S5t),e(Sf,PPe),e(PPe,R5t),e(Sf,P5t),e(Sf,Nde),e(Nde,B5t),e(Sf,I5t),e(Ta,N5t),M(ry,Ta,null),e(Pr,q5t),e(Pr,mt),M(RB,mt,null),e(mt,D5t),e(mt,BPe),e(BPe,j5t),e(mt,G5t),e(mt,ns),e(ns,O5t),e(ns,IPe),e(IPe,V5t),e(ns,X5t),e(ns,NPe),e(NPe,z5t),e(ns,Q5t),e(ns,qPe),e(qPe,W5t),e(ns,U5t),e(mt,H5t),e(mt,Qe),e(Qe,ty),e(ty,DPe),e(DPe,J5t),e(ty,Y5t),e(ty,qde),e(qde,Z5t),e(ty,K5t),e(Qe,e0t),e(Qe,ay),e(ay,jPe),e(jPe,o0t),e(ay,r0t),e(ay,Dde),e(Dde,t0t),e(ay,a0t),e(Qe,n0t),e(Qe,ny),e(ny,GPe),e(GPe,s0t),e(ny,l0t),e(ny,jde),e(jde,i0t),e(ny,d0t),e(Qe,m0t),e(Qe,sy),e(sy,OPe),e(OPe,c0t),e(sy,f0t),e(sy,Gde),e(Gde,g0t),e(sy,h0t),e(Qe,u0t),e(Qe,ly),e(ly,VPe),e(VPe,p0t),e(ly,_0t),e(ly,Ode),e(Ode,b0t),e(ly,v0t),e(Qe,F0t),e(Qe,iy),e(iy,XPe),e(XPe,T0t),e(iy,M0t),e(iy,Vde),e(Vde,E0t),e(iy,C0t),e(Qe,w0t),e(Qe,dy),e(dy,zPe),e(zPe,A0t),e(dy,L0t),e(dy,Xde),e(Xde,y0t),e(dy,x0t),e(Qe,$0t),e(Qe,my),e(my,QPe),e(QPe,k0t),e(my,S0t),e(my,zde),e(zde,R0t),e(my,P0t),e(mt,B0t),M(cy,mt,null),b(c,jno,_),b(c,Rf,_),e(Rf,fy),e(fy,WPe),M(PB,WPe,null),e(Rf,I0t),e(Rf,UPe),e(UPe,N0t),b(c,Gno,_),b(c,Br,_),M(BB,Br,null),e(Br,q0t),e(Br,Pf),e(Pf,D0t),e(Pf,Qde),e(Qde,j0t),e(Pf,G0t),e(Pf,Wde),e(Wde,O0t),e(Pf,V0t),e(Br,X0t),e(Br,IB),e(IB,z0t),e(IB,HPe),e(HPe,Q0t),e(IB,W0t),e(Br,U0t),e(Br,Ma),M(NB,Ma,null),e(Ma,H0t),e(Ma,JPe),e(JPe,J0t),e(Ma,Y0t),e(Ma,Bf),e(Bf,Z0t),e(Bf,YPe),e(YPe,K0t),e(Bf,ewt),e(Bf,Ude),e(Ude,owt),e(Bf,rwt),e(Ma,twt),M(gy,Ma,null),e(Br,awt),e(Br,ct),M(qB,ct,null),e(ct,nwt),e(ct,ZPe),e(ZPe,swt),e(ct,lwt),e(ct,ss),e(ss,iwt),e(ss,KPe),e(KPe,dwt),e(ss,mwt),e(ss,eBe),e(eBe,cwt),e(ss,fwt),e(ss,oBe),e(oBe,gwt),e(ss,hwt),e(ct,uwt),e(ct,rBe),e(rBe,hy),e(hy,tBe),e(tBe,pwt),e(hy,_wt),e(hy,Hde),e(Hde,bwt),e(hy,vwt),e(ct,Fwt),M(uy,ct,null),b(c,Ono,_),b(c,If,_),e(If,py),e(py,aBe),M(DB,aBe,null),e(If,Twt),e(If,nBe),e(nBe,Mwt),b(c,Vno,_),b(c,Ir,_),M(jB,Ir,null),e(Ir,Ewt),e(Ir,Nf),e(Nf,Cwt),e(Nf,Jde),e(Jde,wwt),e(Nf,Awt),e(Nf,Yde),e(Yde,Lwt),e(Nf,ywt),e(Ir,xwt),e(Ir,GB),e(GB,$wt),e(GB,sBe),e(sBe,kwt),e(GB,Swt),e(Ir,Rwt),e(Ir,Ea),M(OB,Ea,null),e(Ea,Pwt),e(Ea,lBe),e(lBe,Bwt),e(Ea,Iwt),e(Ea,qf),e(qf,Nwt),e(qf,iBe),e(iBe,qwt),e(qf,Dwt),e(qf,Zde),e(Zde,jwt),e(qf,Gwt),e(Ea,Owt),M(_y,Ea,null),e(Ir,Vwt),e(Ir,ft),M(VB,ft,null),e(ft,Xwt),e(ft,dBe),e(dBe,zwt),e(ft,Qwt),e(ft,ls),e(ls,Wwt),e(ls,mBe),e(mBe,Uwt),e(ls,Hwt),e(ls,cBe),e(cBe,Jwt),e(ls,Ywt),e(ls,fBe),e(fBe,Zwt),e(ls,Kwt),e(ft,eAt),e(ft,XB),e(XB,by),e(by,gBe),e(gBe,oAt),e(by,rAt),e(by,Kde),e(Kde,tAt),e(by,aAt),e(XB,nAt),e(XB,vy),e(vy,hBe),e(hBe,sAt),e(vy,lAt),e(vy,eme),e(eme,iAt),e(vy,dAt),e(ft,mAt),M(Fy,ft,null),b(c,Xno,_),b(c,Df,_),e(Df,Ty),e(Ty,uBe),M(zB,uBe,null),e(Df,cAt),e(Df,pBe),e(pBe,fAt),b(c,zno,_),b(c,Nr,_),M(QB,Nr,null),e(Nr,gAt),e(Nr,jf),e(jf,hAt),e(jf,ome),e(ome,uAt),e(jf,pAt),e(jf,rme),e(rme,_At),e(jf,bAt),e(Nr,vAt),e(Nr,WB),e(WB,FAt),e(WB,_Be),e(_Be,TAt),e(WB,MAt),e(Nr,EAt),e(Nr,Ca),M(UB,Ca,null),e(Ca,CAt),e(Ca,bBe),e(bBe,wAt),e(Ca,AAt),e(Ca,Gf),e(Gf,LAt),e(Gf,vBe),e(vBe,yAt),e(Gf,xAt),e(Gf,tme),e(tme,$At),e(Gf,kAt),e(Ca,SAt),M(My,Ca,null),e(Nr,RAt),e(Nr,gt),M(HB,gt,null),e(gt,PAt),e(gt,FBe),e(FBe,BAt),e(gt,IAt),e(gt,is),e(is,NAt),e(is,TBe),e(TBe,qAt),e(is,DAt),e(is,MBe),e(MBe,jAt),e(is,GAt),e(is,EBe),e(EBe,OAt),e(is,VAt),e(gt,XAt),e(gt,CBe),e(CBe,Ey),e(Ey,wBe),e(wBe,zAt),e(Ey,QAt),e(Ey,ame),e(ame,WAt),e(Ey,UAt),e(gt,HAt),M(Cy,gt,null),Qno=!0},p(c,[_]){const JB={};_&2&&(JB.$$scope={dirty:_,ctx:c}),Jf.$set(JB);const ABe={};_&2&&(ABe.$$scope={dirty:_,ctx:c}),wu.$set(ABe);const LBe={};_&2&&(LBe.$$scope={dirty:_,ctx:c}),mp.$set(LBe);const yBe={};_&2&&(yBe.$$scope={dirty:_,ctx:c}),t_.$set(yBe);const YB={};_&2&&(YB.$$scope={dirty:_,ctx:c}),a_.$set(YB);const xBe={};_&2&&(xBe.$$scope={dirty:_,ctx:c}),$_.$set(xBe);const ds={};_&2&&(ds.$$scope={dirty:_,ctx:c}),k_.$set(ds);const $Be={};_&2&&($Be.$$scope={dirty:_,ctx:c}),P_.$set($Be);const kBe={};_&2&&(kBe.$$scope={dirty:_,ctx:c}),rb.$set(kBe);const SBe={};_&2&&(SBe.$$scope={dirty:_,ctx:c}),ab.$set(SBe);const ZB={};_&2&&(ZB.$$scope={dirty:_,ctx:c}),ev.$set(ZB);const RBe={};_&2&&(RBe.$$scope={dirty:_,ctx:c}),rv.$set(RBe);const KB={};_&2&&(KB.$$scope={dirty:_,ctx:c}),Qv.$set(KB);const PBe={};_&2&&(PBe.$$scope={dirty:_,ctx:c}),Uv.$set(PBe);const eI={};_&2&&(eI.$$scope={dirty:_,ctx:c}),Zv.$set(eI);const BBe={};_&2&&(BBe.$$scope={dirty:_,ctx:c}),eF.$set(BBe);const IBe={};_&2&&(IBe.$$scope={dirty:_,ctx:c}),GF.$set(IBe);const NBe={};_&2&&(NBe.$$scope={dirty:_,ctx:c}),VF.$set(NBe);const Of={};_&2&&(Of.$$scope={dirty:_,ctx:c}),cT.$set(Of);const qBe={};_&2&&(qBe.$$scope={dirty:_,ctx:c}),gT.$set(qBe);const DBe={};_&2&&(DBe.$$scope={dirty:_,ctx:c}),_M.$set(DBe);const jBe={};_&2&&(jBe.$$scope={dirty:_,ctx:c}),vM.$set(jBe);const oI={};_&2&&(oI.$$scope={dirty:_,ctx:c}),KM.$set(oI);const GBe={};_&2&&(GBe.$$scope={dirty:_,ctx:c}),oE.$set(GBe);const OBe={};_&2&&(OBe.$$scope={dirty:_,ctx:c}),mE.$set(OBe);const VBe={};_&2&&(VBe.$$scope={dirty:_,ctx:c}),fE.$set(VBe);const vt={};_&2&&(vt.$$scope={dirty:_,ctx:c}),o4.$set(vt);const rI={};_&2&&(rI.$$scope={dirty:_,ctx:c}),t4.$set(rI);const XBe={};_&2&&(XBe.$$scope={dirty:_,ctx:c}),K4.$set(XBe);const tI={};_&2&&(tI.$$scope={dirty:_,ctx:c}),oC.$set(tI);const zBe={};_&2&&(zBe.$$scope={dirty:_,ctx:c}),aC.$set(zBe);const Ft={};_&2&&(Ft.$$scope={dirty:_,ctx:c}),sC.$set(Ft);const QBe={};_&2&&(QBe.$$scope={dirty:_,ctx:c}),cC.$set(QBe);const Vf={};_&2&&(Vf.$$scope={dirty:_,ctx:c}),gC.$set(Vf);const WBe={};_&2&&(WBe.$$scope={dirty:_,ctx:c}),$C.$set(WBe);const UBe={};_&2&&(UBe.$$scope={dirty:_,ctx:c}),SC.$set(UBe);const L={};_&2&&(L.$$scope={dirty:_,ctx:c}),BC.$set(L);const wy={};_&2&&(wy.$$scope={dirty:_,ctx:c}),NC.$set(wy);const HBe={};_&2&&(HBe.$$scope={dirty:_,ctx:c}),jC.$set(HBe);const JBe={};_&2&&(JBe.$$scope={dirty:_,ctx:c}),OC.$set(JBe);const Ay={};_&2&&(Ay.$$scope={dirty:_,ctx:c}),zC.$set(Ay);const YBe={};_&2&&(YBe.$$scope={dirty:_,ctx:c}),WC.$set(YBe);const ZBe={};_&2&&(ZBe.$$scope={dirty:_,ctx:c}),a3.$set(ZBe);const Ly={};_&2&&(Ly.$$scope={dirty:_,ctx:c}),s3.$set(Ly);const KBe={};_&2&&(KBe.$$scope={dirty:_,ctx:c}),g3.$set(KBe);const eIe={};_&2&&(eIe.$$scope={dirty:_,ctx:c}),u3.$set(eIe);const yy={};_&2&&(yy.$$scope={dirty:_,ctx:c}),L3.$set(yy);const oIe={};_&2&&(oIe.$$scope={dirty:_,ctx:c}),x3.$set(oIe);const rIe={};_&2&&(rIe.$$scope={dirty:_,ctx:c}),P3.$set(rIe);const xy={};_&2&&(xy.$$scope={dirty:_,ctx:c}),I3.$set(xy);const tIe={};_&2&&(tIe.$$scope={dirty:_,ctx:c}),V3.$set(tIe);const aIe={};_&2&&(aIe.$$scope={dirty:_,ctx:c}),z3.$set(aIe);const $y={};_&2&&($y.$$scope={dirty:_,ctx:c}),Y3.$set($y);const nIe={};_&2&&(nIe.$$scope={dirty:_,ctx:c}),K3.$set(nIe);const sIe={};_&2&&(sIe.$$scope={dirty:_,ctx:c}),s5.$set(sIe);const ky={};_&2&&(ky.$$scope={dirty:_,ctx:c}),i5.$set(ky);const lIe={};_&2&&(lIe.$$scope={dirty:_,ctx:c}),c5.$set(lIe);const iIe={};_&2&&(iIe.$$scope={dirty:_,ctx:c}),g5.$set(iIe);const Sy={};_&2&&(Sy.$$scope={dirty:_,ctx:c}),F5.$set(Sy);const dIe={};_&2&&(dIe.$$scope={dirty:_,ctx:c}),M5.$set(dIe);const mIe={};_&2&&(mIe.$$scope={dirty:_,ctx:c}),w5.$set(mIe);const Ry={};_&2&&(Ry.$$scope={dirty:_,ctx:c}),L5.$set(Ry);const cIe={};_&2&&(cIe.$$scope={dirty:_,ctx:c}),$5.$set(cIe);const fIe={};_&2&&(fIe.$$scope={dirty:_,ctx:c}),S5.$set(fIe);const Py={};_&2&&(Py.$$scope={dirty:_,ctx:c}),I0.$set(Py);const gIe={};_&2&&(gIe.$$scope={dirty:_,ctx:c}),q0.$set(gIe);const hIe={};_&2&&(hIe.$$scope={dirty:_,ctx:c}),iw.$set(hIe);const By={};_&2&&(By.$$scope={dirty:_,ctx:c}),mw.$set(By);const uIe={};_&2&&(uIe.$$scope={dirty:_,ctx:c}),ww.$set(uIe);const pIe={};_&2&&(pIe.$$scope={dirty:_,ctx:c}),Lw.$set(pIe);const Iy={};_&2&&(Iy.$$scope={dirty:_,ctx:c}),Nw.$set(Iy);const _Ie={};_&2&&(_Ie.$$scope={dirty:_,ctx:c}),Dw.$set(_Ie);const bIe={};_&2&&(bIe.$$scope={dirty:_,ctx:c}),Vw.$set(bIe);const Ny={};_&2&&(Ny.$$scope={dirty:_,ctx:c}),zw.$set(Ny);const vIe={};_&2&&(vIe.$$scope={dirty:_,ctx:c}),gA.$set(vIe);const FIe={};_&2&&(FIe.$$scope={dirty:_,ctx:c}),uA.$set(FIe);const qy={};_&2&&(qy.$$scope={dirty:_,ctx:c}),AA.$set(qy);const TIe={};_&2&&(TIe.$$scope={dirty:_,ctx:c}),yA.$set(TIe);const MIe={};_&2&&(MIe.$$scope={dirty:_,ctx:c}),t6.$set(MIe);const Dy={};_&2&&(Dy.$$scope={dirty:_,ctx:c}),n6.$set(Dy);const EIe={};_&2&&(EIe.$$scope={dirty:_,ctx:c}),E6.$set(EIe);const CIe={};_&2&&(CIe.$$scope={dirty:_,ctx:c}),w6.$set(CIe);const jy={};_&2&&(jy.$$scope={dirty:_,ctx:c}),y6.$set(jy);const wIe={};_&2&&(wIe.$$scope={dirty:_,ctx:c}),$6.$set(wIe);const AIe={};_&2&&(AIe.$$scope={dirty:_,ctx:c}),S6.$set(AIe);const Gy={};_&2&&(Gy.$$scope={dirty:_,ctx:c}),P6.$set(Gy);const LIe={};_&2&&(LIe.$$scope={dirty:_,ctx:c}),I6.$set(LIe);const yIe={};_&2&&(yIe.$$scope={dirty:_,ctx:c}),q6.$set(yIe);const Oy={};_&2&&(Oy.$$scope={dirty:_,ctx:c}),l7.$set(Oy);const xIe={};_&2&&(xIe.$$scope={dirty:_,ctx:c}),d7.$set(xIe);const $Ie={};_&2&&($Ie.$$scope={dirty:_,ctx:c}),k7.$set($Ie);const Vy={};_&2&&(Vy.$$scope={dirty:_,ctx:c}),R7.$set(Vy);const kIe={};_&2&&(kIe.$$scope={dirty:_,ctx:c}),B7.$set(kIe);const SIe={};_&2&&(SIe.$$scope={dirty:_,ctx:c}),N7.$set(SIe);const Xy={};_&2&&(Xy.$$scope={dirty:_,ctx:c}),j7.$set(Xy);const RIe={};_&2&&(RIe.$$scope={dirty:_,ctx:c}),O7.$set(RIe);const PIe={};_&2&&(PIe.$$scope={dirty:_,ctx:c}),p8.$set(PIe);const zy={};_&2&&(zy.$$scope={dirty:_,ctx:c}),b8.$set(zy);const BIe={};_&2&&(BIe.$$scope={dirty:_,ctx:c}),x8.$set(BIe);const IIe={};_&2&&(IIe.$$scope={dirty:_,ctx:c}),k8.$set(IIe);const Qy={};_&2&&(Qy.$$scope={dirty:_,ctx:c}),z8.$set(Qy);const NIe={};_&2&&(NIe.$$scope={dirty:_,ctx:c}),W8.$set(NIe);const qIe={};_&2&&(qIe.$$scope={dirty:_,ctx:c}),aL.$set(qIe);const Wy={};_&2&&(Wy.$$scope={dirty:_,ctx:c}),sL.$set(Wy);const DIe={};_&2&&(DIe.$$scope={dirty:_,ctx:c}),_L.$set(DIe);const jIe={};_&2&&(jIe.$$scope={dirty:_,ctx:c}),vL.$set(jIe);const Uy={};_&2&&(Uy.$$scope={dirty:_,ctx:c}),$L.$set(Uy);const GIe={};_&2&&(GIe.$$scope={dirty:_,ctx:c}),SL.$set(GIe);const OIe={};_&2&&(OIe.$$scope={dirty:_,ctx:c}),VL.$set(OIe);const Hy={};_&2&&(Hy.$$scope={dirty:_,ctx:c}),zL.$set(Hy);const VIe={};_&2&&(VIe.$$scope={dirty:_,ctx:c}),ey.$set(VIe);const XIe={};_&2&&(XIe.$$scope={dirty:_,ctx:c}),ry.$set(XIe);const Jy={};_&2&&(Jy.$$scope={dirty:_,ctx:c}),cy.$set(Jy);const zIe={};_&2&&(zIe.$$scope={dirty:_,ctx:c}),gy.$set(zIe);const QIe={};_&2&&(QIe.$$scope={dirty:_,ctx:c}),uy.$set(QIe);const Yy={};_&2&&(Yy.$$scope={dirty:_,ctx:c}),_y.$set(Yy);const WIe={};_&2&&(WIe.$$scope={dirty:_,ctx:c}),Fy.$set(WIe);const UIe={};_&2&&(UIe.$$scope={dirty:_,ctx:c}),My.$set(UIe);const Zy={};_&2&&(Zy.$$scope={dirty:_,ctx:c}),Cy.$set(Zy)},i(c){Qno||(E(d.$$.fragment,c),E(on.$$.fragment,c),E(m$.$$.fragment,c),E(c$.$$.fragment,c),E(Jf.$$.fragment,c),E(f$.$$.fragment,c),E(g$.$$.fragment,c),E(p$.$$.fragment,c),E(wu.$$.fragment,c),E(_$.$$.fragment,c),E(b$.$$.fragment,c),E(v$.$$.fragment,c),E(M$.$$.fragment,c),E(mp.$$.fragment,c),E(E$.$$.fragment,c),E(C$.$$.fragment,c),E(w$.$$.fragment,c),E(y$.$$.fragment,c),E(t_.$$.fragment,c),E(a_.$$.fragment,c),E(x$.$$.fragment,c),E($$.$$.fragment,c),E(k$.$$.fragment,c),E(P$.$$.fragment,c),E($_.$$.fragment,c),E(k_.$$.fragment,c),E(B$.$$.fragment,c),E(I$.$$.fragment,c),E(N$.$$.fragment,c),E(D$.$$.fragment,c),E(P_.$$.fragment,c),E(j$.$$.fragment,c),E(rb.$$.fragment,c),E(G$.$$.fragment,c),E(O$.$$.fragment,c),E(X$.$$.fragment,c),E(ab.$$.fragment,c),E(z$.$$.fragment,c),E(ev.$$.fragment,c),E(Q$.$$.fragment,c),E(W$.$$.fragment,c),E(H$.$$.fragment,c),E(rv.$$.fragment,c),E(J$.$$.fragment,c),E(Qv.$$.fragment,c),E(Y$.$$.fragment,c),E(Z$.$$.fragment,c),E(ek.$$.fragment,c),E(Uv.$$.fragment,c),E(ok.$$.fragment,c),E(Zv.$$.fragment,c),E(tk.$$.fragment,c),E(ak.$$.fragment,c),E(sk.$$.fragment,c),E(eF.$$.fragment,c),E(lk.$$.fragment,c),E(GF.$$.fragment,c),E(ik.$$.fragment,c),E(dk.$$.fragment,c),E(ck.$$.fragment,c),E(VF.$$.fragment,c),E(fk.$$.fragment,c),E(cT.$$.fragment,c),E(gk.$$.fragment,c),E(hk.$$.fragment,c),E(pk.$$.fragment,c),E(gT.$$.fragment,c),E(_k.$$.fragment,c),E(_M.$$.fragment,c),E(bk.$$.fragment,c),E(vk.$$.fragment,c),E(Tk.$$.fragment,c),E(vM.$$.fragment,c),E(Mk.$$.fragment,c),E(KM.$$.fragment,c),E(Ek.$$.fragment,c),E(Ck.$$.fragment,c),E(Ak.$$.fragment,c),E(oE.$$.fragment,c),E(Lk.$$.fragment,c),E(mE.$$.fragment,c),E(yk.$$.fragment,c),E(xk.$$.fragment,c),E(kk.$$.fragment,c),E(fE.$$.fragment,c),E(Sk.$$.fragment,c),E(o4.$$.fragment,c),E(Rk.$$.fragment,c),E(Pk.$$.fragment,c),E(Ik.$$.fragment,c),E(t4.$$.fragment,c),E(Nk.$$.fragment,c),E(K4.$$.fragment,c),E(qk.$$.fragment,c),E(Dk.$$.fragment,c),E(Gk.$$.fragment,c),E(oC.$$.fragment,c),E(Ok.$$.fragment,c),E(aC.$$.fragment,c),E(Vk.$$.fragment,c),E(Xk.$$.fragment,c),E(Qk.$$.fragment,c),E(sC.$$.fragment,c),E(Wk.$$.fragment,c),E(cC.$$.fragment,c),E(Uk.$$.fragment,c),E(Hk.$$.fragment,c),E(Yk.$$.fragment,c),E(gC.$$.fragment,c),E(Zk.$$.fragment,c),E($C.$$.fragment,c),E(Kk.$$.fragment,c),E(eS.$$.fragment,c),E(rS.$$.fragment,c),E(SC.$$.fragment,c),E(tS.$$.fragment,c),E(BC.$$.fragment,c),E(aS.$$.fragment,c),E(nS.$$.fragment,c),E(lS.$$.fragment,c),E(NC.$$.fragment,c),E(iS.$$.fragment,c),E(jC.$$.fragment,c),E(dS.$$.fragment,c),E(mS.$$.fragment,c),E(fS.$$.fragment,c),E(OC.$$.fragment,c),E(gS.$$.fragment,c),E(zC.$$.fragment,c),E(hS.$$.fragment,c),E(uS.$$.fragment,c),E(_S.$$.fragment,c),E(WC.$$.fragment,c),E(bS.$$.fragment,c),E(a3.$$.fragment,c),E(vS.$$.fragment,c),E(FS.$$.fragment,c),E(MS.$$.fragment,c),E(s3.$$.fragment,c),E(ES.$$.fragment,c),E(g3.$$.fragment,c),E(CS.$$.fragment,c),E(wS.$$.fragment,c),E(LS.$$.fragment,c),E(u3.$$.fragment,c),E(yS.$$.fragment,c),E(L3.$$.fragment,c),E(xS.$$.fragment,c),E($S.$$.fragment,c),E(SS.$$.fragment,c),E(x3.$$.fragment,c),E(RS.$$.fragment,c),E(P3.$$.fragment,c),E(PS.$$.fragment,c),E(BS.$$.fragment,c),E(NS.$$.fragment,c),E(I3.$$.fragment,c),E(qS.$$.fragment,c),E(V3.$$.fragment,c),E(DS.$$.fragment,c),E(jS.$$.fragment,c),E(OS.$$.fragment,c),E(z3.$$.fragment,c),E(VS.$$.fragment,c),E(Y3.$$.fragment,c),E(XS.$$.fragment,c),E(zS.$$.fragment,c),E(WS.$$.fragment,c),E(K3.$$.fragment,c),E(US.$$.fragment,c),E(s5.$$.fragment,c),E(HS.$$.fragment,c),E(JS.$$.fragment,c),E(ZS.$$.fragment,c),E(i5.$$.fragment,c),E(KS.$$.fragment,c),E(c5.$$.fragment,c),E(eR.$$.fragment,c),E(oR.$$.fragment,c),E(tR.$$.fragment,c),E(g5.$$.fragment,c),E(aR.$$.fragment,c),E(F5.$$.fragment,c),E(nR.$$.fragment,c),E(sR.$$.fragment,c),E(iR.$$.fragment,c),E(M5.$$.fragment,c),E(dR.$$.fragment,c),E(w5.$$.fragment,c),E(mR.$$.fragment,c),E(cR.$$.fragment,c),E(gR.$$.fragment,c),E(L5.$$.fragment,c),E(hR.$$.fragment,c),E($5.$$.fragment,c),E(uR.$$.fragment,c),E(pR.$$.fragment,c),E(bR.$$.fragment,c),E(S5.$$.fragment,c),E(vR.$$.fragment,c),E(I0.$$.fragment,c),E(FR.$$.fragment,c),E(TR.$$.fragment,c),E(ER.$$.fragment,c),E(q0.$$.fragment,c),E(CR.$$.fragment,c),E(iw.$$.fragment,c),E(wR.$$.fragment,c),E(AR.$$.fragment,c),E(yR.$$.fragment,c),E(mw.$$.fragment,c),E(xR.$$.fragment,c),E(ww.$$.fragment,c),E($R.$$.fragment,c),E(kR.$$.fragment,c),E(RR.$$.fragment,c),E(Lw.$$.fragment,c),E(PR.$$.fragment,c),E(Nw.$$.fragment,c),E(BR.$$.fragment,c),E(IR.$$.fragment,c),E(qR.$$.fragment,c),E(Dw.$$.fragment,c),E(DR.$$.fragment,c),E(Vw.$$.fragment,c),E(jR.$$.fragment,c),E(GR.$$.fragment,c),E(VR.$$.fragment,c),E(zw.$$.fragment,c),E(XR.$$.fragment,c),E(gA.$$.fragment,c),E(zR.$$.fragment,c),E(QR.$$.fragment,c),E(UR.$$.fragment,c),E(uA.$$.fragment,c),E(HR.$$.fragment,c),E(AA.$$.fragment,c),E(JR.$$.fragment,c),E(YR.$$.fragment,c),E(KR.$$.fragment,c),E(yA.$$.fragment,c),E(eP.$$.fragment,c),E(t6.$$.fragment,c),E(oP.$$.fragment,c),E(rP.$$.fragment,c),E(aP.$$.fragment,c),E(n6.$$.fragment,c),E(nP.$$.fragment,c),E(E6.$$.fragment,c),E(sP.$$.fragment,c),E(lP.$$.fragment,c),E(dP.$$.fragment,c),E(w6.$$.fragment,c),E(mP.$$.fragment,c),E(y6.$$.fragment,c),E(fP.$$.fragment,c),E(gP.$$.fragment,c),E(uP.$$.fragment,c),E($6.$$.fragment,c),E(pP.$$.fragment,c),E(S6.$$.fragment,c),E(_P.$$.fragment,c),E(bP.$$.fragment,c),E(FP.$$.fragment,c),E(P6.$$.fragment,c),E(TP.$$.fragment,c),E(I6.$$.fragment,c),E(MP.$$.fragment,c),E(EP.$$.fragment,c),E(wP.$$.fragment,c),E(q6.$$.fragment,c),E(AP.$$.fragment,c),E(l7.$$.fragment,c),E(LP.$$.fragment,c),E(yP.$$.fragment,c),E($P.$$.fragment,c),E(d7.$$.fragment,c),E(kP.$$.fragment,c),E(k7.$$.fragment,c),E(SP.$$.fragment,c),E(RP.$$.fragment,c),E(BP.$$.fragment,c),E(R7.$$.fragment,c),E(IP.$$.fragment,c),E(B7.$$.fragment,c),E(NP.$$.fragment,c),E(qP.$$.fragment,c),E(jP.$$.fragment,c),E(N7.$$.fragment,c),E(GP.$$.fragment,c),E(j7.$$.fragment,c),E(VP.$$.fragment,c),E(XP.$$.fragment,c),E(QP.$$.fragment,c),E(O7.$$.fragment,c),E(WP.$$.fragment,c),E(p8.$$.fragment,c),E(UP.$$.fragment,c),E(HP.$$.fragment,c),E(YP.$$.fragment,c),E(b8.$$.fragment,c),E(ZP.$$.fragment,c),E(x8.$$.fragment,c),E(KP.$$.fragment,c),E(eB.$$.fragment,c),E(rB.$$.fragment,c),E(k8.$$.fragment,c),E(tB.$$.fragment,c),E(z8.$$.fragment,c),E(aB.$$.fragment,c),E(nB.$$.fragment,c),E(lB.$$.fragment,c),E(W8.$$.fragment,c),E(iB.$$.fragment,c),E(aL.$$.fragment,c),E(dB.$$.fragment,c),E(mB.$$.fragment,c),E(fB.$$.fragment,c),E(sL.$$.fragment,c),E(gB.$$.fragment,c),E(_L.$$.fragment,c),E(hB.$$.fragment,c),E(uB.$$.fragment,c),E(_B.$$.fragment,c),E(vL.$$.fragment,c),E(bB.$$.fragment,c),E($L.$$.fragment,c),E(vB.$$.fragment,c),E(FB.$$.fragment,c),E(MB.$$.fragment,c),E(SL.$$.fragment,c),E(EB.$$.fragment,c),E(VL.$$.fragment,c),E(CB.$$.fragment,c),E(wB.$$.fragment,c),E(LB.$$.fragment,c),E(zL.$$.fragment,c),E(yB.$$.fragment,c),E(ey.$$.fragment,c),E(xB.$$.fragment,c),E($B.$$.fragment,c),E(SB.$$.fragment,c),E(ry.$$.fragment,c),E(RB.$$.fragment,c),E(cy.$$.fragment,c),E(PB.$$.fragment,c),E(BB.$$.fragment,c),E(NB.$$.fragment,c),E(gy.$$.fragment,c),E(qB.$$.fragment,c),E(uy.$$.fragment,c),E(DB.$$.fragment,c),E(jB.$$.fragment,c),E(OB.$$.fragment,c),E(_y.$$.fragment,c),E(VB.$$.fragment,c),E(Fy.$$.fragment,c),E(zB.$$.fragment,c),E(QB.$$.fragment,c),E(UB.$$.fragment,c),E(My.$$.fragment,c),E(HB.$$.fragment,c),E(Cy.$$.fragment,c),Qno=!0)},o(c){C(d.$$.fragment,c),C(on.$$.fragment,c),C(m$.$$.fragment,c),C(c$.$$.fragment,c),C(Jf.$$.fragment,c),C(f$.$$.fragment,c),C(g$.$$.fragment,c),C(p$.$$.fragment,c),C(wu.$$.fragment,c),C(_$.$$.fragment,c),C(b$.$$.fragment,c),C(v$.$$.fragment,c),C(M$.$$.fragment,c),C(mp.$$.fragment,c),C(E$.$$.fragment,c),C(C$.$$.fragment,c),C(w$.$$.fragment,c),C(y$.$$.fragment,c),C(t_.$$.fragment,c),C(a_.$$.fragment,c),C(x$.$$.fragment,c),C($$.$$.fragment,c),C(k$.$$.fragment,c),C(P$.$$.fragment,c),C($_.$$.fragment,c),C(k_.$$.fragment,c),C(B$.$$.fragment,c),C(I$.$$.fragment,c),C(N$.$$.fragment,c),C(D$.$$.fragment,c),C(P_.$$.fragment,c),C(j$.$$.fragment,c),C(rb.$$.fragment,c),C(G$.$$.fragment,c),C(O$.$$.fragment,c),C(X$.$$.fragment,c),C(ab.$$.fragment,c),C(z$.$$.fragment,c),C(ev.$$.fragment,c),C(Q$.$$.fragment,c),C(W$.$$.fragment,c),C(H$.$$.fragment,c),C(rv.$$.fragment,c),C(J$.$$.fragment,c),C(Qv.$$.fragment,c),C(Y$.$$.fragment,c),C(Z$.$$.fragment,c),C(ek.$$.fragment,c),C(Uv.$$.fragment,c),C(ok.$$.fragment,c),C(Zv.$$.fragment,c),C(tk.$$.fragment,c),C(ak.$$.fragment,c),C(sk.$$.fragment,c),C(eF.$$.fragment,c),C(lk.$$.fragment,c),C(GF.$$.fragment,c),C(ik.$$.fragment,c),C(dk.$$.fragment,c),C(ck.$$.fragment,c),C(VF.$$.fragment,c),C(fk.$$.fragment,c),C(cT.$$.fragment,c),C(gk.$$.fragment,c),C(hk.$$.fragment,c),C(pk.$$.fragment,c),C(gT.$$.fragment,c),C(_k.$$.fragment,c),C(_M.$$.fragment,c),C(bk.$$.fragment,c),C(vk.$$.fragment,c),C(Tk.$$.fragment,c),C(vM.$$.fragment,c),C(Mk.$$.fragment,c),C(KM.$$.fragment,c),C(Ek.$$.fragment,c),C(Ck.$$.fragment,c),C(Ak.$$.fragment,c),C(oE.$$.fragment,c),C(Lk.$$.fragment,c),C(mE.$$.fragment,c),C(yk.$$.fragment,c),C(xk.$$.fragment,c),C(kk.$$.fragment,c),C(fE.$$.fragment,c),C(Sk.$$.fragment,c),C(o4.$$.fragment,c),C(Rk.$$.fragment,c),C(Pk.$$.fragment,c),C(Ik.$$.fragment,c),C(t4.$$.fragment,c),C(Nk.$$.fragment,c),C(K4.$$.fragment,c),C(qk.$$.fragment,c),C(Dk.$$.fragment,c),C(Gk.$$.fragment,c),C(oC.$$.fragment,c),C(Ok.$$.fragment,c),C(aC.$$.fragment,c),C(Vk.$$.fragment,c),C(Xk.$$.fragment,c),C(Qk.$$.fragment,c),C(sC.$$.fragment,c),C(Wk.$$.fragment,c),C(cC.$$.fragment,c),C(Uk.$$.fragment,c),C(Hk.$$.fragment,c),C(Yk.$$.fragment,c),C(gC.$$.fragment,c),C(Zk.$$.fragment,c),C($C.$$.fragment,c),C(Kk.$$.fragment,c),C(eS.$$.fragment,c),C(rS.$$.fragment,c),C(SC.$$.fragment,c),C(tS.$$.fragment,c),C(BC.$$.fragment,c),C(aS.$$.fragment,c),C(nS.$$.fragment,c),C(lS.$$.fragment,c),C(NC.$$.fragment,c),C(iS.$$.fragment,c),C(jC.$$.fragment,c),C(dS.$$.fragment,c),C(mS.$$.fragment,c),C(fS.$$.fragment,c),C(OC.$$.fragment,c),C(gS.$$.fragment,c),C(zC.$$.fragment,c),C(hS.$$.fragment,c),C(uS.$$.fragment,c),C(_S.$$.fragment,c),C(WC.$$.fragment,c),C(bS.$$.fragment,c),C(a3.$$.fragment,c),C(vS.$$.fragment,c),C(FS.$$.fragment,c),C(MS.$$.fragment,c),C(s3.$$.fragment,c),C(ES.$$.fragment,c),C(g3.$$.fragment,c),C(CS.$$.fragment,c),C(wS.$$.fragment,c),C(LS.$$.fragment,c),C(u3.$$.fragment,c),C(yS.$$.fragment,c),C(L3.$$.fragment,c),C(xS.$$.fragment,c),C($S.$$.fragment,c),C(SS.$$.fragment,c),C(x3.$$.fragment,c),C(RS.$$.fragment,c),C(P3.$$.fragment,c),C(PS.$$.fragment,c),C(BS.$$.fragment,c),C(NS.$$.fragment,c),C(I3.$$.fragment,c),C(qS.$$.fragment,c),C(V3.$$.fragment,c),C(DS.$$.fragment,c),C(jS.$$.fragment,c),C(OS.$$.fragment,c),C(z3.$$.fragment,c),C(VS.$$.fragment,c),C(Y3.$$.fragment,c),C(XS.$$.fragment,c),C(zS.$$.fragment,c),C(WS.$$.fragment,c),C(K3.$$.fragment,c),C(US.$$.fragment,c),C(s5.$$.fragment,c),C(HS.$$.fragment,c),C(JS.$$.fragment,c),C(ZS.$$.fragment,c),C(i5.$$.fragment,c),C(KS.$$.fragment,c),C(c5.$$.fragment,c),C(eR.$$.fragment,c),C(oR.$$.fragment,c),C(tR.$$.fragment,c),C(g5.$$.fragment,c),C(aR.$$.fragment,c),C(F5.$$.fragment,c),C(nR.$$.fragment,c),C(sR.$$.fragment,c),C(iR.$$.fragment,c),C(M5.$$.fragment,c),C(dR.$$.fragment,c),C(w5.$$.fragment,c),C(mR.$$.fragment,c),C(cR.$$.fragment,c),C(gR.$$.fragment,c),C(L5.$$.fragment,c),C(hR.$$.fragment,c),C($5.$$.fragment,c),C(uR.$$.fragment,c),C(pR.$$.fragment,c),C(bR.$$.fragment,c),C(S5.$$.fragment,c),C(vR.$$.fragment,c),C(I0.$$.fragment,c),C(FR.$$.fragment,c),C(TR.$$.fragment,c),C(ER.$$.fragment,c),C(q0.$$.fragment,c),C(CR.$$.fragment,c),C(iw.$$.fragment,c),C(wR.$$.fragment,c),C(AR.$$.fragment,c),C(yR.$$.fragment,c),C(mw.$$.fragment,c),C(xR.$$.fragment,c),C(ww.$$.fragment,c),C($R.$$.fragment,c),C(kR.$$.fragment,c),C(RR.$$.fragment,c),C(Lw.$$.fragment,c),C(PR.$$.fragment,c),C(Nw.$$.fragment,c),C(BR.$$.fragment,c),C(IR.$$.fragment,c),C(qR.$$.fragment,c),C(Dw.$$.fragment,c),C(DR.$$.fragment,c),C(Vw.$$.fragment,c),C(jR.$$.fragment,c),C(GR.$$.fragment,c),C(VR.$$.fragment,c),C(zw.$$.fragment,c),C(XR.$$.fragment,c),C(gA.$$.fragment,c),C(zR.$$.fragment,c),C(QR.$$.fragment,c),C(UR.$$.fragment,c),C(uA.$$.fragment,c),C(HR.$$.fragment,c),C(AA.$$.fragment,c),C(JR.$$.fragment,c),C(YR.$$.fragment,c),C(KR.$$.fragment,c),C(yA.$$.fragment,c),C(eP.$$.fragment,c),C(t6.$$.fragment,c),C(oP.$$.fragment,c),C(rP.$$.fragment,c),C(aP.$$.fragment,c),C(n6.$$.fragment,c),C(nP.$$.fragment,c),C(E6.$$.fragment,c),C(sP.$$.fragment,c),C(lP.$$.fragment,c),C(dP.$$.fragment,c),C(w6.$$.fragment,c),C(mP.$$.fragment,c),C(y6.$$.fragment,c),C(fP.$$.fragment,c),C(gP.$$.fragment,c),C(uP.$$.fragment,c),C($6.$$.fragment,c),C(pP.$$.fragment,c),C(S6.$$.fragment,c),C(_P.$$.fragment,c),C(bP.$$.fragment,c),C(FP.$$.fragment,c),C(P6.$$.fragment,c),C(TP.$$.fragment,c),C(I6.$$.fragment,c),C(MP.$$.fragment,c),C(EP.$$.fragment,c),C(wP.$$.fragment,c),C(q6.$$.fragment,c),C(AP.$$.fragment,c),C(l7.$$.fragment,c),C(LP.$$.fragment,c),C(yP.$$.fragment,c),C($P.$$.fragment,c),C(d7.$$.fragment,c),C(kP.$$.fragment,c),C(k7.$$.fragment,c),C(SP.$$.fragment,c),C(RP.$$.fragment,c),C(BP.$$.fragment,c),C(R7.$$.fragment,c),C(IP.$$.fragment,c),C(B7.$$.fragment,c),C(NP.$$.fragment,c),C(qP.$$.fragment,c),C(jP.$$.fragment,c),C(N7.$$.fragment,c),C(GP.$$.fragment,c),C(j7.$$.fragment,c),C(VP.$$.fragment,c),C(XP.$$.fragment,c),C(QP.$$.fragment,c),C(O7.$$.fragment,c),C(WP.$$.fragment,c),C(p8.$$.fragment,c),C(UP.$$.fragment,c),C(HP.$$.fragment,c),C(YP.$$.fragment,c),C(b8.$$.fragment,c),C(ZP.$$.fragment,c),C(x8.$$.fragment,c),C(KP.$$.fragment,c),C(eB.$$.fragment,c),C(rB.$$.fragment,c),C(k8.$$.fragment,c),C(tB.$$.fragment,c),C(z8.$$.fragment,c),C(aB.$$.fragment,c),C(nB.$$.fragment,c),C(lB.$$.fragment,c),C(W8.$$.fragment,c),C(iB.$$.fragment,c),C(aL.$$.fragment,c),C(dB.$$.fragment,c),C(mB.$$.fragment,c),C(fB.$$.fragment,c),C(sL.$$.fragment,c),C(gB.$$.fragment,c),C(_L.$$.fragment,c),C(hB.$$.fragment,c),C(uB.$$.fragment,c),C(_B.$$.fragment,c),C(vL.$$.fragment,c),C(bB.$$.fragment,c),C($L.$$.fragment,c),C(vB.$$.fragment,c),C(FB.$$.fragment,c),C(MB.$$.fragment,c),C(SL.$$.fragment,c),C(EB.$$.fragment,c),C(VL.$$.fragment,c),C(CB.$$.fragment,c),C(wB.$$.fragment,c),C(LB.$$.fragment,c),C(zL.$$.fragment,c),C(yB.$$.fragment,c),C(ey.$$.fragment,c),C(xB.$$.fragment,c),C($B.$$.fragment,c),C(SB.$$.fragment,c),C(ry.$$.fragment,c),C(RB.$$.fragment,c),C(cy.$$.fragment,c),C(PB.$$.fragment,c),C(BB.$$.fragment,c),C(NB.$$.fragment,c),C(gy.$$.fragment,c),C(qB.$$.fragment,c),C(uy.$$.fragment,c),C(DB.$$.fragment,c),C(jB.$$.fragment,c),C(OB.$$.fragment,c),C(_y.$$.fragment,c),C(VB.$$.fragment,c),C(Fy.$$.fragment,c),C(zB.$$.fragment,c),C(QB.$$.fragment,c),C(UB.$$.fragment,c),C(My.$$.fragment,c),C(HB.$$.fragment,c),C(Cy.$$.fragment,c),Qno=!1},d(c){t(g),c&&t(v),c&&t(u),w(d),c&&t(zf),c&&t(Tt),c&&t(Xe),c&&t(He),c&&t(Wf),w(on,c),c&&t(Je),c&&t(Ae),c&&t(ko),c&&t(rn),c&&t(xto),c&&t(wd),w(m$),c&&t($to),c&&t(hs),c&&t(kto),w(c$,c),c&&t(Sto),c&&t(yN),c&&t(Rto),w(Jf,c),c&&t(Pto),c&&t(Ad),w(f$),c&&t(Bto),c&&t(So),w(g$),w(p$),w(wu),w(_$),c&&t(Ito),c&&t(yd),w(b$),c&&t(Nto),c&&t(Ro),w(v$),w(M$),w(mp),w(E$),c&&t(qto),c&&t(xd),w(C$),c&&t(Dto),c&&t(Po),w(w$),w(y$),w(t_),w(a_),w(x$),c&&t(jto),c&&t($d),w($$),c&&t(Gto),c&&t(Bo),w(k$),w(P$),w($_),w(k_),w(B$),c&&t(Oto),c&&t(Sd),w(I$),c&&t(Vto),c&&t(Io),w(N$),w(D$),w(P_),w(j$),w(rb),c&&t(Xto),c&&t(Bd),w(G$),c&&t(zto),c&&t(No),w(O$),w(X$),w(ab),w(z$),w(ev),c&&t(Qto),c&&t(qd),w(Q$),c&&t(Wto),c&&t(qo),w(W$),w(H$),w(rv),w(J$),w(Qv),c&&t(Uto),c&&t(Gd),w(Y$),c&&t(Hto),c&&t(Do),w(Z$),w(ek),w(Uv),w(ok),w(Zv),c&&t(Jto),c&&t(Xd),w(tk),c&&t(Yto),c&&t(jo),w(ak),w(sk),w(eF),w(lk),w(GF),c&&t(Zto),c&&t(Wd),w(ik),c&&t(Kto),c&&t(Go),w(dk),w(ck),w(VF),w(fk),w(cT),c&&t(eao),c&&t(Jd),w(gk),c&&t(oao),c&&t(Oo),w(hk),w(pk),w(gT),w(_k),w(_M),c&&t(rao),c&&t(Kd),w(bk),c&&t(tao),c&&t(Vo),w(vk),w(Tk),w(vM),w(Mk),w(KM),c&&t(aao),c&&t(rm),w(Ek),c&&t(nao),c&&t(Xo),w(Ck),w(Ak),w(oE),w(Lk),w(mE),c&&t(sao),c&&t(nm),w(yk),c&&t(lao),c&&t(zo),w(xk),w(kk),w(fE),w(Sk),w(o4),c&&t(iao),c&&t(im),w(Rk),c&&t(dao),c&&t(Qo),w(Pk),w(Ik),w(t4),w(Nk),w(K4),c&&t(mao),c&&t(cm),w(qk),c&&t(cao),c&&t(Wo),w(Dk),w(Gk),w(oC),w(Ok),w(aC),c&&t(fao),c&&t(hm),w(Vk),c&&t(gao),c&&t(Uo),w(Xk),w(Qk),w(sC),w(Wk),w(cC),c&&t(hao),c&&t(bm),w(Uk),c&&t(uao),c&&t(Ho),w(Hk),w(Yk),w(gC),w(Zk),w($C),c&&t(pao),c&&t(Tm),w(Kk),c&&t(_ao),c&&t(Jo),w(eS),w(rS),w(SC),w(tS),w(BC),c&&t(bao),c&&t(Cm),w(aS),c&&t(vao),c&&t(Yo),w(nS),w(lS),w(NC),w(iS),w(jC),c&&t(Fao),c&&t(Lm),w(dS),c&&t(Tao),c&&t(Zo),w(mS),w(fS),w(OC),w(gS),w(zC),c&&t(Mao),c&&t($m),w(hS),c&&t(Eao),c&&t(Ko),w(uS),w(_S),w(WC),w(bS),w(a3),c&&t(Cao),c&&t(Rm),w(vS),c&&t(wao),c&&t(er),w(FS),w(MS),w(s3),w(ES),w(g3),c&&t(Aao),c&&t(Im),w(CS),c&&t(Lao),c&&t(or),w(wS),w(LS),w(u3),w(yS),w(L3),c&&t(yao),c&&t(Dm),w(xS),c&&t(xao),c&&t(rr),w($S),w(SS),w(x3),w(RS),w(P3),c&&t($ao),c&&t(Vm),w(PS),c&&t(kao),c&&t(tr),w(BS),w(NS),w(I3),w(qS),w(V3),c&&t(Sao),c&&t(Qm),w(DS),c&&t(Rao),c&&t(ar),w(jS),w(OS),w(z3),w(VS),w(Y3),c&&t(Pao),c&&t(Hm),w(XS),c&&t(Bao),c&&t(nr),w(zS),w(WS),w(K3),w(US),w(s5),c&&t(Iao),c&&t(Zm),w(HS),c&&t(Nao),c&&t(sr),w(JS),w(ZS),w(i5),w(KS),w(c5),c&&t(qao),c&&t(oc),w(eR),c&&t(Dao),c&&t(lr),w(oR),w(tR),w(g5),w(aR),w(F5),c&&t(jao),c&&t(ac),w(nR),c&&t(Gao),c&&t(ir),w(sR),w(iR),w(M5),w(dR),w(w5),c&&t(Oao),c&&t(lc),w(mR),c&&t(Vao),c&&t(dr),w(cR),w(gR),w(L5),w(hR),w($5),c&&t(Xao),c&&t(mc),w(uR),c&&t(zao),c&&t(mr),w(pR),w(bR),w(S5),w(vR),w(I0),c&&t(Qao),c&&t(gc),w(FR),c&&t(Wao),c&&t(cr),w(TR),w(ER),w(q0),w(CR),w(iw),c&&t(Uao),c&&t(pc),w(wR),c&&t(Hao),c&&t(fr),w(AR),w(yR),w(mw),w(xR),w(ww),c&&t(Jao),c&&t(vc),w($R),c&&t(Yao),c&&t(gr),w(kR),w(RR),w(Lw),w(PR),w(Nw),c&&t(Zao),c&&t(Mc),w(BR),c&&t(Kao),c&&t(hr),w(IR),w(qR),w(Dw),w(DR),w(Vw),c&&t(eno),c&&t(Ac),w(jR),c&&t(ono),c&&t(ur),w(GR),w(VR),w(zw),w(XR),w(gA),c&&t(rno),c&&t(xc),w(zR),c&&t(tno),c&&t(pr),w(QR),w(UR),w(uA),w(HR),w(AA),c&&t(ano),c&&t(Sc),w(JR),c&&t(nno),c&&t(_r),w(YR),w(KR),w(yA),w(eP),w(t6),c&&t(sno),c&&t(Bc),w(oP),c&&t(lno),c&&t(br),w(rP),w(aP),w(n6),w(nP),w(E6),c&&t(ino),c&&t(qc),w(sP),c&&t(dno),c&&t(vr),w(lP),w(dP),w(w6),w(mP),w(y6),c&&t(mno),c&&t(Gc),w(fP),c&&t(cno),c&&t(Fr),w(gP),w(uP),w($6),w(pP),w(S6),c&&t(fno),c&&t(Xc),w(_P),c&&t(gno),c&&t(Tr),w(bP),w(FP),w(P6),w(TP),w(I6),c&&t(hno),c&&t(Wc),w(MP),c&&t(uno),c&&t(Mr),w(EP),w(wP),w(q6),w(AP),w(l7),c&&t(pno),c&&t(Jc),w(LP),c&&t(_no),c&&t(Er),w(yP),w($P),w(d7),w(kP),w(k7),c&&t(bno),c&&t(Kc),w(SP),c&&t(vno),c&&t(Cr),w(RP),w(BP),w(R7),w(IP),w(B7),c&&t(Fno),c&&t(rf),w(NP),c&&t(Tno),c&&t(wr),w(qP),w(jP),w(N7),w(GP),w(j7),c&&t(Mno),c&&t(nf),w(VP),c&&t(Eno),c&&t(Ar),w(XP),w(QP),w(O7),w(WP),w(p8),c&&t(Cno),c&&t(df),w(UP),c&&t(wno),c&&t(Lr),w(HP),w(YP),w(b8),w(ZP),w(x8),c&&t(Ano),c&&t(ff),w(KP),c&&t(Lno),c&&t(yr),w(eB),w(rB),w(k8),w(tB),w(z8),c&&t(yno),c&&t(uf),w(aB),c&&t(xno),c&&t(xr),w(nB),w(lB),w(W8),w(iB),w(aL),c&&t($no),c&&t(bf),w(dB),c&&t(kno),c&&t($r),w(mB),w(fB),w(sL),w(gB),w(_L),c&&t(Sno),c&&t(Tf),w(hB),c&&t(Rno),c&&t(kr),w(uB),w(_B),w(vL),w(bB),w($L),c&&t(Pno),c&&t(Cf),w(vB),c&&t(Bno),c&&t(Sr),w(FB),w(MB),w(SL),w(EB),w(VL),c&&t(Ino),c&&t(Lf),w(CB),c&&t(Nno),c&&t(Rr),w(wB),w(LB),w(zL),w(yB),w(ey),c&&t(qno),c&&t($f),w(xB),c&&t(Dno),c&&t(Pr),w($B),w(SB),w(ry),w(RB),w(cy),c&&t(jno),c&&t(Rf),w(PB),c&&t(Gno),c&&t(Br),w(BB),w(NB),w(gy),w(qB),w(uy),c&&t(Ono),c&&t(If),w(DB),c&&t(Vno),c&&t(Ir),w(jB),w(OB),w(_y),w(VB),w(Fy),c&&t(Xno),c&&t(Df),w(zB),c&&t(zno),c&&t(Nr),w(QB),w(UB),w(My),w(HB),w(Cy)}}}const Y0a={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForDepthEstimation",title:"AutoModelForDepthEstimation"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForDocumentQuestionAnswering",title:"AutoModelForDocumentQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVideoClassification",title:"AutoModelForVideoClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.AutoModelForZeroShotObjectDetection",title:"AutoModelForZeroShotObjectDetection"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForSemanticSegmentation",title:"TFAutoModelForSemanticSegmentation"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForDocumentQuestionAnswering",title:"TFAutoModelForDocumentQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function Z0a($){return q3a(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class nwa extends P3a{constructor(g){super();B3a(this,g,Z0a,J0a,I3a,{})}}export{nwa as default,Y0a as metadata};
