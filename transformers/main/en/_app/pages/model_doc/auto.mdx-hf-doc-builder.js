import{S as $9a,i as k9a,s as S9a,e as a,k as l,w as F,t as o,M as R9a,c as n,d as t,m as i,a as s,x as T,h as r,b as d,G as e,g as b,y as M,q as E,o as C,B as w,v as P9a,L as q}from"../../chunks/vendor-hf-doc-builder.js";import{T as tfo}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as B}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as oe}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as N}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function B9a($){let g,v,u,f,p,m,h,He,Ad,eg,wt,Ld,yd,lk,og,Qe,Ze,xd,ps,ik,_s,bs,dk,$d,vs,mk,kd,rg,sn;return{c(){g=a("p"),v=o("If your "),u=a("code"),f=o("NewModelConfig"),p=o(" is a subclass of "),m=a("code"),h=o("~transformer.PretrainedConfig"),He=o(`, make sure its
`),Ad=a("code"),eg=o("model_type"),wt=o(" attribute is set to the same key you use when registering the config (here "),Ld=a("code"),yd=o('"new-model"'),lk=o(")."),og=l(),Qe=a("p"),Ze=o("Likewise, if your "),xd=a("code"),ps=o("NewModel"),ik=o(" is a subclass of "),_s=a("a"),bs=o("PreTrainedModel"),dk=o(`, make sure its
`),$d=a("code"),vs=o("config_class"),mk=o(` attribute is set to the same class you use when registering the model (here
`),kd=a("code"),rg=o("NewModelConfig"),sn=o(")."),this.h()},l(Ke){g=n(Ke,"P",{});var ye=s(g);v=r(ye,"If your "),u=n(ye,"CODE",{});var kq=s(u);f=r(kq,"NewModelConfig"),kq.forEach(t),p=r(ye," is a subclass of "),m=n(ye,"CODE",{});var Sd=s(m);h=r(Sd,"~transformer.PretrainedConfig"),Sd.forEach(t),He=r(ye,`, make sure its
`),Ad=n(ye,"CODE",{});var Sq=s(Ad);eg=r(Sq,"model_type"),Sq.forEach(t),wt=r(ye," attribute is set to the same key you use when registering the config (here "),Ld=n(ye,"CODE",{});var Rq=s(Ld);yd=r(Rq,'"new-model"'),Rq.forEach(t),lk=r(ye,")."),ye.forEach(t),og=i(Ke),Qe=n(Ke,"P",{});var Po=s(Qe);Ze=r(Po,"Likewise, if your "),xd=n(Po,"CODE",{});var ln=s(xd);ps=r(ln,"NewModel"),ln.forEach(t),ik=r(Po," is a subclass of "),_s=n(Po,"A",{href:!0});var Pq=s(_s);bs=r(Pq,"PreTrainedModel"),Pq.forEach(t),dk=r(Po,`, make sure its
`),$d=n(Po,"CODE",{});var tg=s($d);vs=r(tg,"config_class"),tg.forEach(t),mk=r(Po,` attribute is set to the same class you use when registering the model (here
`),kd=n(Po,"CODE",{});var Bq=s(kd);rg=r(Bq,"NewModelConfig"),Bq.forEach(t),sn=r(Po,")."),Po.forEach(t),this.h()},h(){d(_s,"href","/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel")},m(Ke,ye){b(Ke,g,ye),e(g,v),e(g,u),e(u,f),e(g,p),e(g,m),e(m,h),e(g,He),e(g,Ad),e(Ad,eg),e(g,wt),e(g,Ld),e(Ld,yd),e(g,lk),b(Ke,og,ye),b(Ke,Qe,ye),e(Qe,Ze),e(Qe,xd),e(xd,ps),e(Qe,ik),e(Qe,_s),e(_s,bs),e(Qe,dk),e(Qe,$d),e($d,vs),e(Qe,mk),e(Qe,kd),e(kd,rg),e(Qe,sn)},d(Ke){Ke&&t(g),Ke&&t(og),Ke&&t(Qe)}}}function I9a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function N9a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function q9a($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var He=s(u);f=r(He,"use_auth_token=True"),He.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(m,h){b(m,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(m){m&&t(g)}}}function D9a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function j9a($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var He=s(u);f=r(He,"use_auth_token=True"),He.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(m,h){b(m,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(m){m&&t(g)}}}function G9a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoImageProcessor

# Download image processor from huggingface.co and cache.
image_processor = AutoImageProcessor.from_pretrained("google/vit-base-patch16-224-in21k")

# If image processor files are in a directory (e.g. image processor was saved using *save_pretrained('./test/saved_model/')*)
image_processor = AutoImageProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoImageProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download image processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>image_processor = AutoImageProcessor.from_pretrained(<span class="hljs-string">&quot;google/vit-base-patch16-224-in21k&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If image processor files are in a directory (e.g. image processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>image_processor = AutoImageProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function O9a($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var He=s(u);f=r(He,"use_auth_token=True"),He.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(m,h){b(m,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(m){m&&t(g)}}}function V9a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function X9a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function z9a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Q9a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function W9a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function U9a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function H9a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function J9a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDepthEstimation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForDepthEstimation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDepthEstimation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Y9a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDepthEstimation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDepthEstimation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForDepthEstimation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForDepthEstimation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDepthEstimation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Z9a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function K9a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function exa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function oxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function rxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function txa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function axa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function nxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function sxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function lxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function ixa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function dxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function mxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function cxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function fxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function gxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function hxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = AutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function uxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/layoutlm_tf_model_config.json")
model = AutoModelForDocumentQuestionAnswering.from_pretrained(
    "./tf_model/layoutlm_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/layoutlm_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/layoutlm_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function pxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function _xa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function bxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVideoClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function vxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVideoClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Fxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Txa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Mxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Exa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Cxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function wxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Axa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Lxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function yxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function xxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function $xa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function kxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Sxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Rxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Pxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Bxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Ixa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Nxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function qxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Dxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function jxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Gxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Oxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Vxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Xxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForZeroShotObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function zxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForZeroShotObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Qxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Wxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Uxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Hxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Jxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Yxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Zxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Kxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function e$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function o$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSemanticSegmentation.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function r$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function t$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function a$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function n$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function s$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function l$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function i$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function d$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function m$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function c$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function f$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function g$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function h$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function u$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/layoutlm_pt_model_config.json")
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
    "./pt_model/layoutlm_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/layoutlm_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/layoutlm_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function p$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function _$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function b$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function v$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function F$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function T$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function M$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function E$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function C$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function w$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function A$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function L$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function y$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function x$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function $$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function k$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function S$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function R$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function P$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function B$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function I$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function N$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function q$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function D$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function j$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function G$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function O$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function V$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function X$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function z$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Q$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function W$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function U$a($){let g,v,u,f,p,m,h,He,Ad,eg,wt,Ld,yd,lk,og,Qe,Ze,xd,ps,ik,_s,bs,dk,$d,vs,mk,kd,rg,sn,Ke,ye,kq,Sd,Sq,Rq,Po,ln,Pq,tg,Bq,afo,flo,Rd,ag,che,ck,nfo,fhe,sfo,glo,Fs,lfo,ghe,ifo,dfo,hhe,mfo,cfo,hlo,fk,ulo,Iq,ffo,plo,ng,_lo,Pd,sg,uhe,gk,gfo,phe,hfo,blo,Bo,hk,ufo,uk,pfo,Nq,_fo,bfo,vfo,pk,Ffo,_he,Tfo,Mfo,Efo,Or,_k,Cfo,bhe,wfo,Afo,Bd,Lfo,vhe,yfo,xfo,Fhe,$fo,kfo,Sfo,A,lg,The,Rfo,Pfo,qq,Bfo,Ifo,Nfo,ig,Mhe,qfo,Dfo,Dq,jfo,Gfo,Ofo,dg,Ehe,Vfo,Xfo,jq,zfo,Qfo,Wfo,mg,Che,Ufo,Hfo,Gq,Jfo,Yfo,Zfo,cg,whe,Kfo,ego,Oq,ogo,rgo,tgo,fg,Ahe,ago,ngo,Vq,sgo,lgo,igo,gg,Lhe,dgo,mgo,Xq,cgo,fgo,ggo,hg,yhe,hgo,ugo,zq,pgo,_go,bgo,ug,xhe,vgo,Fgo,Qq,Tgo,Mgo,Ego,pg,$he,Cgo,wgo,Wq,Ago,Lgo,ygo,_g,khe,xgo,$go,Uq,kgo,Sgo,Rgo,bg,She,Pgo,Bgo,Hq,Igo,Ngo,qgo,vg,Rhe,Dgo,jgo,Jq,Ggo,Ogo,Vgo,Fg,Phe,Xgo,zgo,Yq,Qgo,Wgo,Ugo,Tg,Bhe,Hgo,Jgo,Zq,Ygo,Zgo,Kgo,Mg,Ihe,eho,oho,Kq,rho,tho,aho,Eg,Nhe,nho,sho,eD,lho,iho,dho,Cg,qhe,mho,cho,oD,fho,gho,hho,wg,Dhe,uho,pho,rD,_ho,bho,vho,Ag,jhe,Fho,Tho,tD,Mho,Eho,Cho,Lg,Ghe,who,Aho,aD,Lho,yho,xho,yg,Ohe,$ho,kho,nD,Sho,Rho,Pho,xg,Vhe,Bho,Iho,sD,Nho,qho,Dho,$g,Xhe,jho,Gho,lD,Oho,Vho,Xho,kg,zhe,zho,Qho,iD,Who,Uho,Hho,Sg,Qhe,Jho,Yho,dD,Zho,Kho,euo,Rg,Whe,ouo,ruo,mD,tuo,auo,nuo,Pg,Uhe,suo,luo,cD,iuo,duo,muo,Bg,Hhe,cuo,fuo,fD,guo,huo,uuo,Ig,Jhe,puo,_uo,gD,buo,vuo,Fuo,Ng,Yhe,Tuo,Muo,hD,Euo,Cuo,wuo,qg,Zhe,Auo,Luo,uD,yuo,xuo,$uo,Dg,Khe,kuo,Suo,pD,Ruo,Puo,Buo,jg,eue,Iuo,Nuo,_D,quo,Duo,juo,Gg,oue,Guo,Ouo,bD,Vuo,Xuo,zuo,Og,rue,Quo,Wuo,vD,Uuo,Huo,Juo,Vg,tue,Yuo,Zuo,FD,Kuo,epo,opo,Xg,aue,rpo,tpo,TD,apo,npo,spo,zg,nue,lpo,ipo,MD,dpo,mpo,cpo,Qg,sue,fpo,gpo,ED,hpo,upo,ppo,Wg,lue,_po,bpo,CD,vpo,Fpo,Tpo,Ug,iue,Mpo,Epo,wD,Cpo,wpo,Apo,Hg,due,Lpo,ypo,AD,xpo,$po,kpo,Jg,mue,Spo,Rpo,LD,Ppo,Bpo,Ipo,Yg,cue,Npo,qpo,yD,Dpo,jpo,Gpo,Zg,fue,Opo,Vpo,xD,Xpo,zpo,Qpo,Kg,gue,Wpo,Upo,$D,Hpo,Jpo,Ypo,eh,hue,Zpo,Kpo,kD,e_o,o_o,r_o,oh,uue,t_o,a_o,SD,n_o,s_o,l_o,rh,pue,i_o,d_o,RD,m_o,c_o,f_o,th,_ue,g_o,h_o,PD,u_o,p_o,__o,ah,bue,b_o,v_o,BD,F_o,T_o,M_o,nh,vue,E_o,C_o,ID,w_o,A_o,L_o,sh,Fue,y_o,x_o,ND,$_o,k_o,S_o,lh,Tue,R_o,P_o,qD,B_o,I_o,N_o,ih,Mue,q_o,D_o,DD,j_o,G_o,O_o,dh,Eue,V_o,X_o,jD,z_o,Q_o,W_o,mh,Cue,U_o,H_o,GD,J_o,Y_o,Z_o,ch,wue,K_o,e1o,OD,o1o,r1o,t1o,fh,Aue,a1o,n1o,VD,s1o,l1o,i1o,gh,Lue,d1o,m1o,XD,c1o,f1o,g1o,hh,yue,h1o,u1o,zD,p1o,_1o,b1o,uh,xue,v1o,F1o,QD,T1o,M1o,E1o,ph,$ue,C1o,w1o,WD,A1o,L1o,y1o,_h,kue,x1o,$1o,UD,k1o,S1o,R1o,bh,Sue,P1o,B1o,HD,I1o,N1o,q1o,vh,Rue,D1o,j1o,JD,G1o,O1o,V1o,Fh,Pue,X1o,z1o,YD,Q1o,W1o,U1o,Th,Bue,H1o,J1o,ZD,Y1o,Z1o,K1o,Mh,Iue,e2o,o2o,KD,r2o,t2o,a2o,Eh,Nue,n2o,s2o,ej,l2o,i2o,d2o,Ch,que,m2o,c2o,oj,f2o,g2o,h2o,wh,Due,u2o,p2o,rj,_2o,b2o,v2o,Ah,jue,F2o,T2o,tj,M2o,E2o,C2o,Lh,Gue,w2o,A2o,aj,L2o,y2o,x2o,yh,Oue,$2o,k2o,nj,S2o,R2o,P2o,xh,Vue,B2o,I2o,sj,N2o,q2o,D2o,$h,Xue,j2o,G2o,lj,O2o,V2o,X2o,kh,zue,z2o,Q2o,ij,W2o,U2o,H2o,Sh,Que,J2o,Y2o,dj,Z2o,K2o,ebo,Rh,Wue,obo,rbo,mj,tbo,abo,nbo,Ph,Uue,sbo,lbo,cj,ibo,dbo,mbo,Bh,Hue,cbo,fbo,fj,gbo,hbo,ubo,Ih,Jue,pbo,_bo,gj,bbo,vbo,Fbo,Nh,Yue,Tbo,Mbo,hj,Ebo,Cbo,wbo,qh,Zue,Abo,Lbo,uj,ybo,xbo,$bo,Dh,Kue,kbo,Sbo,pj,Rbo,Pbo,Bbo,jh,epe,Ibo,Nbo,_j,qbo,Dbo,jbo,Gh,ope,Gbo,Obo,bj,Vbo,Xbo,zbo,Oh,rpe,Qbo,Wbo,vj,Ubo,Hbo,Jbo,Vh,tpe,Ybo,Zbo,Fj,Kbo,evo,ovo,Xh,ape,rvo,tvo,Tj,avo,nvo,svo,zh,npe,lvo,ivo,Mj,dvo,mvo,cvo,Qh,spe,fvo,gvo,Ej,hvo,uvo,pvo,Wh,lpe,_vo,bvo,Cj,vvo,Fvo,Tvo,Uh,ipe,Mvo,Evo,wj,Cvo,wvo,Avo,Hh,dpe,Lvo,yvo,Aj,xvo,$vo,kvo,Jh,mpe,Svo,Rvo,Lj,Pvo,Bvo,Ivo,Yh,cpe,Nvo,qvo,yj,Dvo,jvo,Gvo,Zh,fpe,Ovo,Vvo,xj,Xvo,zvo,Qvo,Kh,gpe,Wvo,Uvo,$j,Hvo,Jvo,Yvo,eu,hpe,Zvo,Kvo,kj,eFo,oFo,rFo,ou,upe,tFo,aFo,Sj,nFo,sFo,lFo,ru,ppe,iFo,dFo,Rj,mFo,cFo,fFo,tu,_pe,gFo,hFo,Pj,uFo,pFo,_Fo,au,bpe,bFo,vFo,Bj,FFo,TFo,MFo,nu,vpe,EFo,CFo,Ij,wFo,AFo,LFo,su,Fpe,yFo,xFo,Nj,$Fo,kFo,SFo,lu,Tpe,RFo,PFo,qj,BFo,IFo,NFo,iu,Mpe,qFo,DFo,Dj,jFo,GFo,OFo,du,Epe,VFo,XFo,jj,zFo,QFo,WFo,mu,Cpe,UFo,HFo,Gj,JFo,YFo,ZFo,cu,wpe,KFo,eTo,Oj,oTo,rTo,tTo,fu,Ape,aTo,nTo,Vj,sTo,lTo,iTo,gu,Lpe,dTo,mTo,Xj,cTo,fTo,gTo,hu,ype,hTo,uTo,zj,pTo,_To,bTo,uu,xpe,vTo,FTo,Qj,TTo,MTo,ETo,pu,$pe,CTo,wTo,Wj,ATo,LTo,yTo,_u,kpe,xTo,$To,Uj,kTo,STo,RTo,bu,Spe,PTo,BTo,Hj,ITo,NTo,qTo,vu,Rpe,DTo,jTo,Jj,GTo,OTo,VTo,Fu,Ppe,XTo,zTo,Yj,QTo,WTo,UTo,Tu,Bpe,HTo,JTo,Zj,YTo,ZTo,KTo,Mu,Ipe,eMo,oMo,Kj,rMo,tMo,aMo,Eu,Npe,nMo,sMo,eG,lMo,iMo,dMo,Cu,qpe,mMo,cMo,oG,fMo,gMo,hMo,wu,Dpe,uMo,pMo,rG,_Mo,bMo,vMo,Au,jpe,FMo,TMo,tG,MMo,EMo,CMo,Lu,Gpe,wMo,AMo,aG,LMo,yMo,xMo,yu,Ope,$Mo,kMo,nG,SMo,RMo,PMo,xu,Vpe,BMo,IMo,sG,NMo,qMo,DMo,$u,Xpe,jMo,GMo,lG,OMo,VMo,XMo,ku,zpe,zMo,QMo,iG,WMo,UMo,HMo,Su,Qpe,JMo,YMo,dG,ZMo,KMo,eEo,Ru,Wpe,oEo,rEo,mG,tEo,aEo,nEo,Pu,Upe,sEo,lEo,cG,iEo,dEo,mEo,Bu,Hpe,cEo,fEo,fG,gEo,hEo,uEo,Iu,pEo,Nu,bk,_Eo,Jpe,bEo,vlo,Id,qu,Ype,vk,vEo,Zpe,FEo,Flo,Io,Fk,TEo,Tk,MEo,gG,EEo,CEo,wEo,Mk,AEo,Kpe,LEo,yEo,xEo,Vr,Ek,$Eo,e_e,kEo,SEo,dn,REo,o_e,PEo,BEo,r_e,IEo,NEo,t_e,qEo,DEo,jEo,k,Ts,a_e,GEo,OEo,hG,VEo,XEo,uG,zEo,QEo,WEo,Ms,n_e,UEo,HEo,pG,JEo,YEo,_G,ZEo,KEo,e4o,Es,s_e,o4o,r4o,bG,t4o,a4o,vG,n4o,s4o,l4o,Du,l_e,i4o,d4o,FG,m4o,c4o,f4o,Cs,i_e,g4o,h4o,TG,u4o,p4o,MG,_4o,b4o,v4o,ju,d_e,F4o,T4o,EG,M4o,E4o,C4o,Gu,m_e,w4o,A4o,CG,L4o,y4o,x4o,Ou,c_e,$4o,k4o,wG,S4o,R4o,P4o,ws,f_e,B4o,I4o,AG,N4o,q4o,LG,D4o,j4o,G4o,As,g_e,O4o,V4o,yG,X4o,z4o,xG,Q4o,W4o,U4o,Ls,h_e,H4o,J4o,$G,Y4o,Z4o,kG,K4o,eCo,oCo,Vu,u_e,rCo,tCo,SG,aCo,nCo,sCo,Xu,p_e,lCo,iCo,RG,dCo,mCo,cCo,zu,__e,fCo,gCo,PG,hCo,uCo,pCo,ys,b_e,_Co,bCo,BG,vCo,FCo,IG,TCo,MCo,ECo,Qu,v_e,CCo,wCo,NG,ACo,LCo,yCo,xs,F_e,xCo,$Co,qG,kCo,SCo,DG,RCo,PCo,BCo,$s,T_e,ICo,NCo,jG,qCo,DCo,GG,jCo,GCo,OCo,ks,M_e,VCo,XCo,OG,zCo,QCo,VG,WCo,UCo,HCo,Ss,E_e,JCo,YCo,XG,ZCo,KCo,zG,e3o,o3o,r3o,Rs,C_e,t3o,a3o,QG,n3o,s3o,WG,l3o,i3o,d3o,Wu,w_e,m3o,c3o,UG,f3o,g3o,h3o,Ps,A_e,u3o,p3o,HG,_3o,b3o,JG,v3o,F3o,T3o,Bs,L_e,M3o,E3o,YG,C3o,w3o,ZG,A3o,L3o,y3o,Is,y_e,x3o,$3o,KG,k3o,S3o,eO,R3o,P3o,B3o,Ns,x_e,I3o,N3o,oO,q3o,D3o,rO,j3o,G3o,O3o,qs,$_e,V3o,X3o,tO,z3o,Q3o,aO,W3o,U3o,H3o,Ds,k_e,J3o,Y3o,nO,Z3o,K3o,sO,e5o,o5o,r5o,js,S_e,t5o,a5o,lO,n5o,s5o,iO,l5o,i5o,d5o,Uu,R_e,m5o,c5o,dO,f5o,g5o,h5o,Hu,P_e,u5o,p5o,mO,_5o,b5o,v5o,Gs,B_e,F5o,T5o,cO,M5o,E5o,fO,C5o,w5o,A5o,Ju,I_e,L5o,y5o,gO,x5o,$5o,k5o,Os,N_e,S5o,R5o,hO,P5o,B5o,uO,I5o,N5o,q5o,Vs,q_e,D5o,j5o,pO,G5o,O5o,_O,V5o,X5o,z5o,Xs,D_e,Q5o,W5o,bO,U5o,H5o,vO,J5o,Y5o,Z5o,Yu,j_e,K5o,e0o,FO,o0o,r0o,t0o,Zu,G_e,a0o,n0o,TO,s0o,l0o,i0o,zs,O_e,d0o,m0o,MO,c0o,f0o,EO,g0o,h0o,u0o,Qs,V_e,p0o,_0o,CO,b0o,v0o,wO,F0o,T0o,M0o,Ws,X_e,E0o,C0o,AO,w0o,A0o,LO,L0o,y0o,x0o,Ku,z_e,$0o,k0o,yO,S0o,R0o,P0o,Us,Q_e,B0o,I0o,xO,N0o,q0o,$O,D0o,j0o,G0o,Hs,W_e,O0o,V0o,kO,X0o,z0o,SO,Q0o,W0o,U0o,Js,U_e,H0o,J0o,RO,Y0o,Z0o,PO,K0o,ewo,owo,Ys,H_e,rwo,two,BO,awo,nwo,IO,swo,lwo,iwo,Zs,J_e,dwo,mwo,NO,cwo,fwo,qO,gwo,hwo,uwo,Ks,Y_e,pwo,_wo,DO,bwo,vwo,jO,Fwo,Two,Mwo,el,Z_e,Ewo,Cwo,GO,wwo,Awo,OO,Lwo,ywo,xwo,ol,K_e,$wo,kwo,VO,Swo,Rwo,XO,Pwo,Bwo,Iwo,rl,e1e,Nwo,qwo,zO,Dwo,jwo,QO,Gwo,Owo,Vwo,ep,o1e,Xwo,zwo,WO,Qwo,Wwo,Uwo,tl,r1e,Hwo,Jwo,UO,Ywo,Zwo,HO,Kwo,eAo,oAo,op,t1e,rAo,tAo,JO,aAo,nAo,sAo,rp,a1e,lAo,iAo,YO,dAo,mAo,cAo,al,n1e,fAo,gAo,ZO,hAo,uAo,KO,pAo,_Ao,bAo,nl,s1e,vAo,FAo,eV,TAo,MAo,oV,EAo,CAo,wAo,sl,l1e,AAo,LAo,rV,yAo,xAo,tV,$Ao,kAo,SAo,tp,i1e,RAo,PAo,aV,BAo,IAo,NAo,ll,d1e,qAo,DAo,nV,jAo,GAo,sV,OAo,VAo,XAo,il,m1e,zAo,QAo,lV,WAo,UAo,iV,HAo,JAo,YAo,dl,c1e,ZAo,KAo,dV,e6o,o6o,mV,r6o,t6o,a6o,ml,f1e,n6o,s6o,cV,l6o,i6o,fV,d6o,m6o,c6o,cl,g1e,f6o,g6o,gV,h6o,u6o,hV,p6o,_6o,b6o,fl,h1e,v6o,F6o,uV,T6o,M6o,pV,E6o,C6o,w6o,gl,u1e,A6o,L6o,_V,y6o,x6o,bV,$6o,k6o,S6o,hl,p1e,R6o,P6o,vV,B6o,I6o,FV,N6o,q6o,D6o,ap,_1e,j6o,G6o,TV,O6o,V6o,X6o,ul,b1e,z6o,Q6o,MV,W6o,U6o,EV,H6o,J6o,Y6o,pl,v1e,Z6o,K6o,CV,e7o,o7o,wV,r7o,t7o,a7o,_l,F1e,n7o,s7o,AV,l7o,i7o,LV,d7o,m7o,c7o,np,T1e,f7o,g7o,yV,h7o,u7o,p7o,sp,M1e,_7o,b7o,xV,v7o,F7o,T7o,lp,E1e,M7o,E7o,$V,C7o,w7o,A7o,ip,C1e,L7o,y7o,kV,x7o,$7o,k7o,bl,w1e,S7o,R7o,SV,P7o,B7o,RV,I7o,N7o,q7o,dp,A1e,D7o,j7o,PV,G7o,O7o,V7o,vl,L1e,X7o,z7o,BV,Q7o,W7o,IV,U7o,H7o,J7o,Fl,y1e,Y7o,Z7o,NV,K7o,e8o,qV,o8o,r8o,t8o,Tl,x1e,a8o,n8o,DV,s8o,l8o,jV,i8o,d8o,m8o,Ml,$1e,c8o,f8o,GV,g8o,h8o,OV,u8o,p8o,_8o,El,k1e,b8o,v8o,VV,F8o,T8o,XV,M8o,E8o,C8o,Cl,S1e,w8o,A8o,zV,L8o,y8o,QV,x8o,$8o,k8o,mp,R1e,S8o,R8o,WV,P8o,B8o,I8o,cp,P1e,N8o,q8o,UV,D8o,j8o,G8o,wl,B1e,O8o,V8o,HV,X8o,z8o,JV,Q8o,W8o,U8o,Al,I1e,H8o,J8o,YV,Y8o,Z8o,ZV,K8o,eLo,oLo,Ll,N1e,rLo,tLo,KV,aLo,nLo,eX,sLo,lLo,iLo,fp,q1e,dLo,mLo,oX,cLo,fLo,gLo,gp,D1e,hLo,uLo,rX,pLo,_Lo,bLo,hp,j1e,vLo,FLo,tX,TLo,MLo,ELo,yl,G1e,CLo,wLo,aX,ALo,LLo,nX,yLo,xLo,$Lo,xl,O1e,kLo,SLo,sX,RLo,PLo,lX,BLo,ILo,NLo,up,V1e,qLo,DLo,iX,jLo,GLo,OLo,pp,X1e,VLo,XLo,dX,zLo,QLo,WLo,_p,z1e,ULo,HLo,mX,JLo,YLo,ZLo,bp,Q1e,KLo,eyo,cX,oyo,ryo,tyo,$l,W1e,ayo,nyo,fX,syo,lyo,gX,iyo,dyo,myo,kl,U1e,cyo,fyo,hX,gyo,hyo,uX,uyo,pyo,_yo,vp,H1e,byo,vyo,pX,Fyo,Tyo,Myo,Fp,J1e,Eyo,Cyo,_X,wyo,Ayo,Lyo,Sl,Y1e,yyo,xyo,bX,$yo,kyo,vX,Syo,Ryo,Pyo,Rl,Z1e,Byo,Iyo,FX,Nyo,qyo,TX,Dyo,jyo,Gyo,Pl,K1e,Oyo,Vyo,MX,Xyo,zyo,EX,Qyo,Wyo,Uyo,Bl,e2e,Hyo,Jyo,CX,Yyo,Zyo,wX,Kyo,e9o,o9o,Tp,r9o,Mp,Ck,t9o,o2e,a9o,Tlo,Nd,Ep,r2e,wk,n9o,t2e,s9o,Mlo,No,Ak,l9o,Lk,i9o,AX,d9o,m9o,c9o,yk,f9o,a2e,g9o,h9o,u9o,eo,xk,p9o,n2e,_9o,b9o,mn,v9o,s2e,F9o,T9o,l2e,M9o,E9o,i2e,C9o,w9o,A9o,z,Cp,d2e,L9o,y9o,LX,x9o,$9o,k9o,wp,m2e,S9o,R9o,yX,P9o,B9o,I9o,Ap,c2e,N9o,q9o,xX,D9o,j9o,G9o,Lp,f2e,O9o,V9o,$X,X9o,z9o,Q9o,yp,g2e,W9o,U9o,kX,H9o,J9o,Y9o,xp,h2e,Z9o,K9o,SX,exo,oxo,rxo,$p,u2e,txo,axo,RX,nxo,sxo,lxo,kp,p2e,ixo,dxo,PX,mxo,cxo,fxo,Sp,_2e,gxo,hxo,BX,uxo,pxo,_xo,Rp,b2e,bxo,vxo,IX,Fxo,Txo,Mxo,Pp,v2e,Exo,Cxo,NX,wxo,Axo,Lxo,Bp,F2e,yxo,xxo,qX,$xo,kxo,Sxo,Ip,T2e,Rxo,Pxo,DX,Bxo,Ixo,Nxo,Np,M2e,qxo,Dxo,jX,jxo,Gxo,Oxo,qp,E2e,Vxo,Xxo,GX,zxo,Qxo,Wxo,Dp,C2e,Uxo,Hxo,OX,Jxo,Yxo,Zxo,jp,w2e,Kxo,e$o,VX,o$o,r$o,t$o,Gp,A2e,a$o,n$o,XX,s$o,l$o,i$o,Op,L2e,d$o,m$o,zX,c$o,f$o,g$o,Vp,y2e,h$o,u$o,QX,p$o,_$o,b$o,Xp,x2e,v$o,F$o,WX,T$o,M$o,E$o,zp,$2e,C$o,w$o,UX,A$o,L$o,y$o,Qp,k2e,x$o,$$o,HX,k$o,S$o,R$o,Wp,S2e,P$o,B$o,JX,I$o,N$o,q$o,Up,R2e,D$o,j$o,YX,G$o,O$o,V$o,Hp,P2e,X$o,z$o,ZX,Q$o,W$o,U$o,Jp,B2e,H$o,J$o,KX,Y$o,Z$o,K$o,Yp,I2e,eko,oko,ez,rko,tko,ako,Zp,N2e,nko,sko,oz,lko,iko,dko,Kp,q2e,mko,cko,rz,fko,gko,hko,e_,D2e,uko,pko,tz,_ko,bko,vko,o_,j2e,Fko,Tko,az,Mko,Eko,Cko,r_,G2e,wko,Ako,nz,Lko,yko,xko,t_,O2e,$ko,kko,sz,Sko,Rko,Pko,a_,V2e,Bko,Iko,lz,Nko,qko,Dko,n_,X2e,jko,Gko,iz,Oko,Vko,Xko,s_,z2e,zko,Qko,dz,Wko,Uko,Hko,l_,Q2e,Jko,Yko,mz,Zko,Kko,eSo,i_,W2e,oSo,rSo,cz,tSo,aSo,nSo,d_,U2e,sSo,lSo,fz,iSo,dSo,mSo,m_,H2e,cSo,fSo,gz,gSo,hSo,uSo,c_,J2e,pSo,_So,hz,bSo,vSo,FSo,f_,Y2e,TSo,MSo,uz,ESo,CSo,wSo,g_,Z2e,ASo,LSo,pz,ySo,xSo,$So,h_,K2e,kSo,SSo,_z,RSo,PSo,BSo,u_,ISo,p_,NSo,__,$k,qSo,ebe,DSo,Elo,qd,b_,obe,kk,jSo,rbe,GSo,Clo,qo,Sk,OSo,Rk,VSo,bz,XSo,zSo,QSo,Pk,WSo,tbe,USo,HSo,JSo,oo,Bk,YSo,abe,ZSo,KSo,cn,eRo,nbe,oRo,rRo,sbe,tRo,aRo,lbe,nRo,sRo,lRo,re,v_,ibe,iRo,dRo,vz,mRo,cRo,fRo,F_,dbe,gRo,hRo,Fz,uRo,pRo,_Ro,T_,mbe,bRo,vRo,Tz,FRo,TRo,MRo,M_,cbe,ERo,CRo,Mz,wRo,ARo,LRo,E_,fbe,yRo,xRo,Ez,$Ro,kRo,SRo,C_,gbe,RRo,PRo,Cz,BRo,IRo,NRo,w_,hbe,qRo,DRo,wz,jRo,GRo,ORo,A_,ube,VRo,XRo,Az,zRo,QRo,WRo,L_,pbe,URo,HRo,Lz,JRo,YRo,ZRo,y_,_be,KRo,ePo,yz,oPo,rPo,tPo,x_,bbe,aPo,nPo,xz,sPo,lPo,iPo,$_,vbe,dPo,mPo,$z,cPo,fPo,gPo,k_,Fbe,hPo,uPo,kz,pPo,_Po,bPo,S_,Tbe,vPo,FPo,Sz,TPo,MPo,EPo,R_,Mbe,CPo,wPo,Rz,APo,LPo,yPo,P_,Ebe,xPo,$Po,Pz,kPo,SPo,RPo,B_,Cbe,PPo,BPo,Bz,IPo,NPo,qPo,I_,wbe,DPo,jPo,Iz,GPo,OPo,VPo,N_,Abe,XPo,zPo,Nz,QPo,WPo,UPo,q_,Lbe,HPo,JPo,qz,YPo,ZPo,KPo,D_,ybe,eBo,oBo,Dz,rBo,tBo,aBo,j_,xbe,nBo,sBo,jz,lBo,iBo,dBo,G_,$be,mBo,cBo,Gz,fBo,gBo,hBo,O_,kbe,uBo,pBo,Oz,_Bo,bBo,vBo,V_,Sbe,FBo,TBo,Vz,MBo,EBo,CBo,X_,Rbe,wBo,ABo,Xz,LBo,yBo,xBo,z_,Pbe,$Bo,kBo,zz,SBo,RBo,PBo,Q_,Bbe,BBo,IBo,Qz,NBo,qBo,DBo,W_,Ibe,jBo,GBo,Wz,OBo,VBo,XBo,U_,zBo,H_,QBo,J_,Ik,WBo,Nbe,UBo,wlo,Dd,Y_,qbe,Nk,HBo,Dbe,JBo,Alo,Do,qk,YBo,Dk,ZBo,Uz,KBo,eIo,oIo,jk,rIo,jbe,tIo,aIo,nIo,ro,Gk,sIo,Gbe,lIo,iIo,jd,dIo,Obe,mIo,cIo,Vbe,fIo,gIo,hIo,ie,Z_,Xbe,uIo,pIo,Hz,_Io,bIo,vIo,K_,zbe,FIo,TIo,Jz,MIo,EIo,CIo,e1,Qbe,wIo,AIo,Yz,LIo,yIo,xIo,o1,Wbe,$Io,kIo,Zz,SIo,RIo,PIo,r1,Ube,BIo,IIo,Kz,NIo,qIo,DIo,t1,Hbe,jIo,GIo,eQ,OIo,VIo,XIo,a1,Jbe,zIo,QIo,oQ,WIo,UIo,HIo,n1,Ybe,JIo,YIo,rQ,ZIo,KIo,eNo,s1,Zbe,oNo,rNo,tQ,tNo,aNo,nNo,l1,Kbe,sNo,lNo,aQ,iNo,dNo,mNo,i1,eve,cNo,fNo,nQ,gNo,hNo,uNo,d1,ove,pNo,_No,sQ,bNo,vNo,FNo,m1,rve,TNo,MNo,lQ,ENo,CNo,wNo,c1,tve,ANo,LNo,iQ,yNo,xNo,$No,f1,ave,kNo,SNo,dQ,RNo,PNo,BNo,g1,nve,INo,NNo,mQ,qNo,DNo,jNo,h1,sve,GNo,ONo,cQ,VNo,XNo,zNo,u1,lve,QNo,WNo,fQ,UNo,HNo,JNo,p1,ive,YNo,ZNo,gQ,KNo,eqo,oqo,_1,dve,rqo,tqo,hQ,aqo,nqo,sqo,b1,mve,lqo,iqo,uQ,dqo,mqo,cqo,v1,cve,fqo,gqo,pQ,hqo,uqo,pqo,F1,fve,_qo,bqo,_Q,vqo,Fqo,Tqo,T1,Mqo,M1,Eqo,E1,Ok,Cqo,gve,wqo,Llo,Gd,C1,hve,Vk,Aqo,uve,Lqo,ylo,jo,Xk,yqo,Od,xqo,bQ,$qo,kqo,vQ,Sqo,Rqo,Pqo,zk,Bqo,pve,Iqo,Nqo,qqo,At,Qk,Dqo,_ve,jqo,Gqo,Vd,Oqo,bve,Vqo,Xqo,FQ,zqo,Qqo,Wqo,w1,Uqo,to,Wk,Hqo,vve,Jqo,Yqo,fn,Zqo,Fve,Kqo,eDo,Tve,oDo,rDo,Mve,tDo,aDo,nDo,y,A1,Eve,sDo,lDo,TQ,iDo,dDo,mDo,L1,Cve,cDo,fDo,MQ,gDo,hDo,uDo,y1,wve,pDo,_Do,EQ,bDo,vDo,FDo,x1,Ave,TDo,MDo,CQ,EDo,CDo,wDo,$1,Lve,ADo,LDo,wQ,yDo,xDo,$Do,k1,yve,kDo,SDo,AQ,RDo,PDo,BDo,S1,xve,IDo,NDo,LQ,qDo,DDo,jDo,R1,$ve,GDo,ODo,yQ,VDo,XDo,zDo,P1,kve,QDo,WDo,xQ,UDo,HDo,JDo,B1,Sve,YDo,ZDo,$Q,KDo,ejo,ojo,I1,Rve,rjo,tjo,kQ,ajo,njo,sjo,N1,Pve,ljo,ijo,SQ,djo,mjo,cjo,q1,Bve,fjo,gjo,RQ,hjo,ujo,pjo,D1,Ive,_jo,bjo,PQ,vjo,Fjo,Tjo,j1,Nve,Mjo,Ejo,BQ,Cjo,wjo,Ajo,G1,qve,Ljo,yjo,IQ,xjo,$jo,kjo,O1,Dve,Sjo,Rjo,NQ,Pjo,Bjo,Ijo,V1,jve,Njo,qjo,qQ,Djo,jjo,Gjo,X1,Gve,Ojo,Vjo,DQ,Xjo,zjo,Qjo,z1,Ove,Wjo,Ujo,jQ,Hjo,Jjo,Yjo,Q1,Vve,Zjo,Kjo,GQ,eGo,oGo,rGo,W1,Xve,tGo,aGo,OQ,nGo,sGo,lGo,U1,zve,iGo,dGo,VQ,mGo,cGo,fGo,H1,Qve,gGo,hGo,XQ,uGo,pGo,_Go,J1,Wve,bGo,vGo,zQ,FGo,TGo,MGo,Y1,Uve,EGo,CGo,QQ,wGo,AGo,LGo,Z1,Hve,yGo,xGo,WQ,$Go,kGo,SGo,K1,Jve,RGo,PGo,UQ,BGo,IGo,NGo,e2,Yve,qGo,DGo,HQ,jGo,GGo,OGo,o2,Zve,VGo,XGo,JQ,zGo,QGo,WGo,r2,Kve,UGo,HGo,YQ,JGo,YGo,ZGo,t2,eFe,KGo,eOo,ZQ,oOo,rOo,tOo,a2,oFe,aOo,nOo,KQ,sOo,lOo,iOo,n2,rFe,dOo,mOo,eW,cOo,fOo,gOo,s2,tFe,hOo,uOo,oW,pOo,_Oo,bOo,l2,aFe,vOo,FOo,rW,TOo,MOo,EOo,i2,nFe,COo,wOo,tW,AOo,LOo,yOo,d2,sFe,xOo,$Oo,aW,kOo,SOo,ROo,m2,lFe,POo,BOo,nW,IOo,NOo,qOo,c2,iFe,DOo,jOo,sW,GOo,OOo,VOo,Il,dFe,XOo,zOo,lW,QOo,WOo,iW,UOo,HOo,JOo,f2,mFe,YOo,ZOo,dW,KOo,eVo,oVo,g2,cFe,rVo,tVo,mW,aVo,nVo,sVo,h2,fFe,lVo,iVo,cW,dVo,mVo,cVo,u2,gFe,fVo,gVo,fW,hVo,uVo,pVo,p2,hFe,_Vo,bVo,gW,vVo,FVo,TVo,_2,uFe,MVo,EVo,hW,CVo,wVo,AVo,b2,pFe,LVo,yVo,uW,xVo,$Vo,kVo,v2,_Fe,SVo,RVo,pW,PVo,BVo,IVo,F2,bFe,NVo,qVo,_W,DVo,jVo,GVo,T2,vFe,OVo,VVo,bW,XVo,zVo,QVo,M2,FFe,WVo,UVo,vW,HVo,JVo,YVo,E2,TFe,ZVo,KVo,FW,eXo,oXo,rXo,C2,MFe,tXo,aXo,TW,nXo,sXo,lXo,w2,EFe,iXo,dXo,MW,mXo,cXo,fXo,A2,CFe,gXo,hXo,EW,uXo,pXo,_Xo,L2,wFe,bXo,vXo,CW,FXo,TXo,MXo,y2,AFe,EXo,CXo,wW,wXo,AXo,LXo,x2,LFe,yXo,xXo,AW,$Xo,kXo,SXo,$2,yFe,RXo,PXo,LW,BXo,IXo,NXo,k2,xFe,qXo,DXo,yW,jXo,GXo,OXo,S2,$Fe,VXo,XXo,xW,zXo,QXo,WXo,R2,kFe,UXo,HXo,$W,JXo,YXo,ZXo,P2,SFe,KXo,ezo,kW,ozo,rzo,tzo,B2,RFe,azo,nzo,SW,szo,lzo,izo,I2,PFe,dzo,mzo,RW,czo,fzo,gzo,N2,BFe,hzo,uzo,PW,pzo,_zo,bzo,q2,IFe,vzo,Fzo,BW,Tzo,Mzo,Ezo,D2,NFe,Czo,wzo,IW,Azo,Lzo,yzo,j2,qFe,xzo,$zo,NW,kzo,Szo,Rzo,G2,DFe,Pzo,Bzo,qW,Izo,Nzo,qzo,O2,jFe,Dzo,jzo,DW,Gzo,Ozo,Vzo,V2,GFe,Xzo,zzo,jW,Qzo,Wzo,Uzo,X2,OFe,Hzo,Jzo,GW,Yzo,Zzo,Kzo,z2,VFe,eQo,oQo,OW,rQo,tQo,aQo,Q2,XFe,nQo,sQo,VW,lQo,iQo,dQo,W2,zFe,mQo,cQo,XW,fQo,gQo,hQo,U2,QFe,uQo,pQo,zW,_Qo,bQo,vQo,H2,WFe,FQo,TQo,QW,MQo,EQo,CQo,J2,UFe,wQo,AQo,WW,LQo,yQo,xQo,Y2,HFe,$Qo,kQo,UW,SQo,RQo,PQo,Z2,JFe,BQo,IQo,HW,NQo,qQo,DQo,K2,YFe,jQo,GQo,JW,OQo,VQo,XQo,eb,ZFe,zQo,QQo,YW,WQo,UQo,HQo,ob,KFe,JQo,YQo,ZW,ZQo,KQo,eWo,rb,eTe,oWo,rWo,KW,tWo,aWo,nWo,tb,oTe,sWo,lWo,eU,iWo,dWo,mWo,ab,rTe,cWo,fWo,oU,gWo,hWo,uWo,nb,tTe,pWo,_Wo,rU,bWo,vWo,FWo,sb,aTe,TWo,MWo,tU,EWo,CWo,wWo,lb,nTe,AWo,LWo,aU,yWo,xWo,$Wo,ib,sTe,kWo,SWo,nU,RWo,PWo,BWo,db,lTe,IWo,NWo,sU,qWo,DWo,jWo,mb,iTe,GWo,OWo,lU,VWo,XWo,zWo,cb,dTe,QWo,WWo,iU,UWo,HWo,JWo,fb,mTe,YWo,ZWo,dU,KWo,eUo,oUo,gb,cTe,rUo,tUo,mU,aUo,nUo,sUo,hb,fTe,lUo,iUo,cU,dUo,mUo,cUo,ub,gTe,fUo,gUo,fU,hUo,uUo,pUo,pb,hTe,_Uo,bUo,gU,vUo,FUo,TUo,_b,uTe,MUo,EUo,hU,CUo,wUo,AUo,bb,pTe,LUo,yUo,uU,xUo,$Uo,kUo,vb,_Te,SUo,RUo,pU,PUo,BUo,IUo,Fb,bTe,NUo,qUo,_U,DUo,jUo,GUo,Tb,vTe,OUo,VUo,bU,XUo,zUo,QUo,Mb,FTe,WUo,UUo,vU,HUo,JUo,YUo,Eb,TTe,ZUo,KUo,FU,eHo,oHo,rHo,Cb,MTe,tHo,aHo,TU,nHo,sHo,lHo,wb,ETe,iHo,dHo,MU,mHo,cHo,fHo,Ab,CTe,gHo,hHo,EU,uHo,pHo,_Ho,Lb,wTe,bHo,vHo,CU,FHo,THo,MHo,yb,ATe,EHo,CHo,wU,wHo,AHo,LHo,xb,LTe,yHo,xHo,AU,$Ho,kHo,SHo,$b,yTe,RHo,PHo,LU,BHo,IHo,NHo,kb,xTe,qHo,DHo,yU,jHo,GHo,OHo,Sb,$Te,VHo,XHo,xU,zHo,QHo,WHo,Rb,kTe,UHo,HHo,$U,JHo,YHo,ZHo,Pb,STe,KHo,eJo,kU,oJo,rJo,tJo,Bb,RTe,aJo,nJo,SU,sJo,lJo,iJo,Ib,PTe,dJo,mJo,RU,cJo,fJo,gJo,Nb,BTe,hJo,uJo,PU,pJo,_Jo,bJo,qb,ITe,vJo,FJo,BU,TJo,MJo,EJo,Db,NTe,CJo,wJo,IU,AJo,LJo,yJo,jb,qTe,xJo,$Jo,NU,kJo,SJo,RJo,Gb,DTe,PJo,BJo,qU,IJo,NJo,qJo,Ob,jTe,DJo,jJo,DU,GJo,OJo,VJo,Vb,GTe,XJo,zJo,jU,QJo,WJo,UJo,Xb,OTe,HJo,JJo,GU,YJo,ZJo,KJo,zb,VTe,eYo,oYo,OU,rYo,tYo,aYo,Qb,XTe,nYo,sYo,VU,lYo,iYo,dYo,Wb,zTe,mYo,cYo,XU,fYo,gYo,hYo,Ub,uYo,QTe,pYo,_Yo,WTe,bYo,vYo,Hb,xlo,Xd,Jb,UTe,Uk,FYo,HTe,TYo,$lo,Go,Hk,MYo,zd,EYo,zU,CYo,wYo,QU,AYo,LYo,yYo,Jk,xYo,JTe,$Yo,kYo,SYo,Lt,Yk,RYo,YTe,PYo,BYo,Qd,IYo,ZTe,NYo,qYo,WU,DYo,jYo,GYo,Yb,OYo,ao,Zk,VYo,KTe,XYo,zYo,gn,QYo,eMe,WYo,UYo,oMe,HYo,JYo,rMe,YYo,ZYo,KYo,G,Zb,tMe,eZo,oZo,UU,rZo,tZo,aZo,Kb,aMe,nZo,sZo,HU,lZo,iZo,dZo,ev,nMe,mZo,cZo,JU,fZo,gZo,hZo,ov,sMe,uZo,pZo,YU,_Zo,bZo,vZo,rv,lMe,FZo,TZo,ZU,MZo,EZo,CZo,tv,iMe,wZo,AZo,KU,LZo,yZo,xZo,av,dMe,$Zo,kZo,eH,SZo,RZo,PZo,nv,mMe,BZo,IZo,oH,NZo,qZo,DZo,sv,cMe,jZo,GZo,rH,OZo,VZo,XZo,lv,fMe,zZo,QZo,tH,WZo,UZo,HZo,iv,gMe,JZo,YZo,aH,ZZo,KZo,eKo,dv,hMe,oKo,rKo,nH,tKo,aKo,nKo,mv,uMe,sKo,lKo,sH,iKo,dKo,mKo,cv,pMe,cKo,fKo,lH,gKo,hKo,uKo,fv,_Me,pKo,_Ko,iH,bKo,vKo,FKo,gv,bMe,TKo,MKo,dH,EKo,CKo,wKo,hv,vMe,AKo,LKo,mH,yKo,xKo,$Ko,uv,FMe,kKo,SKo,cH,RKo,PKo,BKo,pv,TMe,IKo,NKo,fH,qKo,DKo,jKo,_v,MMe,GKo,OKo,gH,VKo,XKo,zKo,bv,EMe,QKo,WKo,hH,UKo,HKo,JKo,vv,CMe,YKo,ZKo,uH,KKo,eer,oer,Fv,wMe,rer,ter,pH,aer,ner,ser,Tv,AMe,ler,ier,_H,der,mer,cer,Mv,LMe,fer,ger,bH,her,uer,per,Ev,yMe,_er,ber,vH,ver,Fer,Ter,Cv,xMe,Mer,Eer,FH,Cer,wer,Aer,wv,$Me,Ler,yer,TH,xer,$er,ker,Av,kMe,Ser,Rer,MH,Per,Ber,Ier,Lv,SMe,Ner,qer,EH,Der,jer,Ger,yv,RMe,Oer,Ver,CH,Xer,zer,Qer,xv,PMe,Wer,Uer,wH,Her,Jer,Yer,$v,BMe,Zer,Ker,AH,eor,oor,ror,kv,IMe,tor,aor,LH,nor,sor,lor,Sv,NMe,ior,dor,yH,mor,cor,gor,Rv,qMe,hor,uor,xH,por,_or,bor,Pv,DMe,vor,For,$H,Tor,Mor,Eor,Bv,jMe,Cor,wor,kH,Aor,Lor,yor,Iv,GMe,xor,$or,SH,kor,Sor,Ror,Nv,OMe,Por,Bor,RH,Ior,Nor,qor,qv,VMe,Dor,jor,PH,Gor,Oor,Vor,Dv,XMe,Xor,zor,BH,Qor,Wor,Uor,jv,zMe,Hor,Jor,IH,Yor,Zor,Kor,Gv,QMe,err,orr,NH,rrr,trr,arr,Ov,WMe,nrr,srr,qH,lrr,irr,drr,Vv,UMe,mrr,crr,DH,frr,grr,hrr,Xv,HMe,urr,prr,jH,_rr,brr,vrr,zv,JMe,Frr,Trr,GH,Mrr,Err,Crr,Qv,YMe,wrr,Arr,OH,Lrr,yrr,xrr,Wv,$rr,ZMe,krr,Srr,KMe,Rrr,Prr,Uv,klo,Wd,Hv,eEe,Kk,Brr,oEe,Irr,Slo,Oo,eS,Nrr,Ud,qrr,VH,Drr,jrr,XH,Grr,Orr,Vrr,oS,Xrr,rEe,zrr,Qrr,Wrr,yt,rS,Urr,tEe,Hrr,Jrr,Hd,Yrr,aEe,Zrr,Krr,zH,etr,otr,rtr,Jv,ttr,no,tS,atr,nEe,ntr,str,hn,ltr,sEe,itr,dtr,lEe,mtr,ctr,iEe,ftr,gtr,htr,W,Yv,dEe,utr,ptr,QH,_tr,btr,vtr,Zv,mEe,Ftr,Ttr,WH,Mtr,Etr,Ctr,Kv,cEe,wtr,Atr,UH,Ltr,ytr,xtr,eF,fEe,$tr,ktr,HH,Str,Rtr,Ptr,oF,gEe,Btr,Itr,JH,Ntr,qtr,Dtr,rF,hEe,jtr,Gtr,YH,Otr,Vtr,Xtr,tF,uEe,ztr,Qtr,ZH,Wtr,Utr,Htr,aF,pEe,Jtr,Ytr,KH,Ztr,Ktr,ear,nF,_Ee,oar,rar,eJ,tar,aar,nar,sF,bEe,sar,lar,oJ,iar,dar,mar,lF,vEe,car,far,rJ,gar,har,uar,iF,FEe,par,_ar,tJ,bar,Far,Tar,dF,TEe,Mar,Ear,aJ,Car,war,Aar,mF,MEe,Lar,yar,nJ,xar,$ar,kar,cF,EEe,Sar,Rar,sJ,Par,Bar,Iar,fF,CEe,Nar,qar,lJ,Dar,jar,Gar,gF,wEe,Oar,Var,iJ,Xar,zar,Qar,hF,AEe,War,Uar,dJ,Har,Jar,Yar,uF,LEe,Zar,Kar,mJ,enr,onr,rnr,pF,yEe,tnr,anr,cJ,nnr,snr,lnr,_F,xEe,inr,dnr,fJ,mnr,cnr,fnr,bF,$Ee,gnr,hnr,gJ,unr,pnr,_nr,vF,kEe,bnr,vnr,hJ,Fnr,Tnr,Mnr,FF,SEe,Enr,Cnr,uJ,wnr,Anr,Lnr,TF,REe,ynr,xnr,pJ,$nr,knr,Snr,MF,PEe,Rnr,Pnr,_J,Bnr,Inr,Nnr,EF,BEe,qnr,Dnr,bJ,jnr,Gnr,Onr,CF,IEe,Vnr,Xnr,vJ,znr,Qnr,Wnr,wF,NEe,Unr,Hnr,FJ,Jnr,Ynr,Znr,AF,qEe,Knr,esr,TJ,osr,rsr,tsr,LF,DEe,asr,nsr,MJ,ssr,lsr,isr,yF,jEe,dsr,msr,EJ,csr,fsr,gsr,xF,GEe,hsr,usr,CJ,psr,_sr,bsr,$F,OEe,vsr,Fsr,wJ,Tsr,Msr,Esr,kF,VEe,Csr,wsr,AJ,Asr,Lsr,ysr,SF,XEe,xsr,$sr,LJ,ksr,Ssr,Rsr,RF,zEe,Psr,Bsr,yJ,Isr,Nsr,qsr,PF,QEe,Dsr,jsr,xJ,Gsr,Osr,Vsr,BF,WEe,Xsr,zsr,$J,Qsr,Wsr,Usr,IF,UEe,Hsr,Jsr,kJ,Ysr,Zsr,Ksr,NF,HEe,elr,olr,SJ,rlr,tlr,alr,qF,JEe,nlr,slr,RJ,llr,ilr,dlr,DF,YEe,mlr,clr,PJ,flr,glr,hlr,jF,ulr,ZEe,plr,_lr,KEe,blr,vlr,GF,Rlo,Jd,OF,e4e,aS,Flr,o4e,Tlr,Plo,Vo,nS,Mlr,Yd,Elr,BJ,Clr,wlr,IJ,Alr,Llr,ylr,sS,xlr,r4e,$lr,klr,Slr,xt,lS,Rlr,t4e,Plr,Blr,Zd,Ilr,a4e,Nlr,qlr,NJ,Dlr,jlr,Glr,VF,Olr,so,iS,Vlr,n4e,Xlr,zlr,un,Qlr,s4e,Wlr,Ulr,l4e,Hlr,Jlr,i4e,Ylr,Zlr,Klr,dS,XF,d4e,eir,oir,qJ,rir,tir,air,zF,m4e,nir,sir,DJ,lir,iir,dir,QF,mir,c4e,cir,fir,f4e,gir,hir,WF,Blo,Kd,UF,g4e,mS,uir,h4e,pir,Ilo,Xo,cS,_ir,em,bir,jJ,vir,Fir,GJ,Tir,Mir,Eir,fS,Cir,u4e,wir,Air,Lir,$t,gS,yir,p4e,xir,$ir,om,kir,_4e,Sir,Rir,OJ,Pir,Bir,Iir,HF,Nir,lo,hS,qir,b4e,Dir,jir,pn,Gir,v4e,Oir,Vir,F4e,Xir,zir,T4e,Qir,Wir,Uir,Y,JF,M4e,Hir,Jir,VJ,Yir,Zir,Kir,YF,E4e,edr,odr,XJ,rdr,tdr,adr,ZF,C4e,ndr,sdr,zJ,ldr,idr,ddr,KF,w4e,mdr,cdr,QJ,fdr,gdr,hdr,eT,A4e,udr,pdr,WJ,_dr,bdr,vdr,oT,L4e,Fdr,Tdr,UJ,Mdr,Edr,Cdr,rT,y4e,wdr,Adr,HJ,Ldr,ydr,xdr,tT,x4e,$dr,kdr,JJ,Sdr,Rdr,Pdr,aT,$4e,Bdr,Idr,YJ,Ndr,qdr,Ddr,nT,k4e,jdr,Gdr,ZJ,Odr,Vdr,Xdr,sT,S4e,zdr,Qdr,KJ,Wdr,Udr,Hdr,lT,R4e,Jdr,Ydr,eY,Zdr,Kdr,emr,iT,P4e,omr,rmr,oY,tmr,amr,nmr,dT,B4e,smr,lmr,rY,imr,dmr,mmr,mT,I4e,cmr,fmr,tY,gmr,hmr,umr,cT,N4e,pmr,_mr,aY,bmr,vmr,Fmr,fT,q4e,Tmr,Mmr,nY,Emr,Cmr,wmr,gT,D4e,Amr,Lmr,sY,ymr,xmr,$mr,hT,j4e,kmr,Smr,lY,Rmr,Pmr,Bmr,uT,G4e,Imr,Nmr,iY,qmr,Dmr,jmr,pT,O4e,Gmr,Omr,dY,Vmr,Xmr,zmr,_T,V4e,Qmr,Wmr,mY,Umr,Hmr,Jmr,bT,X4e,Ymr,Zmr,cY,Kmr,ecr,ocr,vT,z4e,rcr,tcr,fY,acr,ncr,scr,FT,Q4e,lcr,icr,gY,dcr,mcr,ccr,TT,W4e,fcr,gcr,hY,hcr,ucr,pcr,MT,U4e,_cr,bcr,uY,vcr,Fcr,Tcr,ET,H4e,Mcr,Ecr,pY,Ccr,wcr,Acr,CT,J4e,Lcr,ycr,_Y,xcr,$cr,kcr,wT,Y4e,Scr,Rcr,bY,Pcr,Bcr,Icr,AT,Z4e,Ncr,qcr,vY,Dcr,jcr,Gcr,LT,K4e,Ocr,Vcr,FY,Xcr,zcr,Qcr,yT,eCe,Wcr,Ucr,TY,Hcr,Jcr,Ycr,xT,oCe,Zcr,Kcr,MY,efr,ofr,rfr,$T,rCe,tfr,afr,EY,nfr,sfr,lfr,kT,tCe,ifr,dfr,aCe,mfr,cfr,ffr,ST,nCe,gfr,hfr,CY,ufr,pfr,_fr,RT,sCe,bfr,vfr,wY,Ffr,Tfr,Mfr,PT,lCe,Efr,Cfr,AY,wfr,Afr,Lfr,BT,iCe,yfr,xfr,LY,$fr,kfr,Sfr,IT,Rfr,dCe,Pfr,Bfr,mCe,Ifr,Nfr,NT,Nlo,rm,qT,cCe,uS,qfr,fCe,Dfr,qlo,zo,pS,jfr,tm,Gfr,yY,Ofr,Vfr,xY,Xfr,zfr,Qfr,_S,Wfr,gCe,Ufr,Hfr,Jfr,kt,bS,Yfr,hCe,Zfr,Kfr,am,egr,uCe,ogr,rgr,$Y,tgr,agr,ngr,DT,sgr,io,vS,lgr,pCe,igr,dgr,_n,mgr,_Ce,cgr,fgr,bCe,ggr,hgr,vCe,ugr,pgr,_gr,pe,jT,FCe,bgr,vgr,kY,Fgr,Tgr,Mgr,GT,TCe,Egr,Cgr,SY,wgr,Agr,Lgr,OT,MCe,ygr,xgr,RY,$gr,kgr,Sgr,VT,ECe,Rgr,Pgr,PY,Bgr,Igr,Ngr,XT,CCe,qgr,Dgr,BY,jgr,Ggr,Ogr,zT,wCe,Vgr,Xgr,IY,zgr,Qgr,Wgr,QT,ACe,Ugr,Hgr,NY,Jgr,Ygr,Zgr,WT,LCe,Kgr,ehr,qY,ohr,rhr,thr,UT,yCe,ahr,nhr,DY,shr,lhr,ihr,HT,xCe,dhr,mhr,jY,chr,fhr,ghr,JT,$Ce,hhr,uhr,GY,phr,_hr,bhr,YT,kCe,vhr,Fhr,OY,Thr,Mhr,Ehr,ZT,SCe,Chr,whr,VY,Ahr,Lhr,yhr,KT,RCe,xhr,$hr,XY,khr,Shr,Rhr,eM,PCe,Phr,Bhr,zY,Ihr,Nhr,qhr,oM,BCe,Dhr,jhr,QY,Ghr,Ohr,Vhr,rM,ICe,Xhr,zhr,WY,Qhr,Whr,Uhr,tM,NCe,Hhr,Jhr,UY,Yhr,Zhr,Khr,aM,qCe,eur,our,HY,rur,tur,aur,nM,DCe,nur,sur,JY,lur,iur,dur,sM,mur,jCe,cur,fur,GCe,gur,hur,lM,Dlo,nm,iM,OCe,FS,uur,VCe,pur,jlo,Qo,TS,_ur,sm,bur,YY,vur,Fur,ZY,Tur,Mur,Eur,MS,Cur,XCe,wur,Aur,Lur,St,ES,yur,zCe,xur,$ur,lm,kur,QCe,Sur,Rur,KY,Pur,Bur,Iur,dM,Nur,mo,CS,qur,WCe,Dur,jur,bn,Gur,UCe,Our,Vur,HCe,Xur,zur,JCe,Qur,Wur,Uur,I,mM,YCe,Hur,Jur,eZ,Yur,Zur,Kur,cM,ZCe,epr,opr,oZ,rpr,tpr,apr,fM,KCe,npr,spr,rZ,lpr,ipr,dpr,gM,e3e,mpr,cpr,tZ,fpr,gpr,hpr,hM,o3e,upr,ppr,aZ,_pr,bpr,vpr,uM,r3e,Fpr,Tpr,nZ,Mpr,Epr,Cpr,pM,t3e,wpr,Apr,sZ,Lpr,ypr,xpr,_M,a3e,$pr,kpr,lZ,Spr,Rpr,Ppr,bM,n3e,Bpr,Ipr,iZ,Npr,qpr,Dpr,vM,s3e,jpr,Gpr,dZ,Opr,Vpr,Xpr,FM,l3e,zpr,Qpr,mZ,Wpr,Upr,Hpr,TM,i3e,Jpr,Ypr,cZ,Zpr,Kpr,e_r,MM,d3e,o_r,r_r,fZ,t_r,a_r,n_r,EM,m3e,s_r,l_r,gZ,i_r,d_r,m_r,CM,c3e,c_r,f_r,hZ,g_r,h_r,u_r,wM,f3e,p_r,__r,uZ,b_r,v_r,F_r,AM,g3e,T_r,M_r,pZ,E_r,C_r,w_r,LM,h3e,A_r,L_r,_Z,y_r,x_r,$_r,yM,u3e,k_r,S_r,bZ,R_r,P_r,B_r,xM,p3e,I_r,N_r,vZ,q_r,D_r,j_r,$M,_3e,G_r,O_r,FZ,V_r,X_r,z_r,kM,b3e,Q_r,W_r,TZ,U_r,H_r,J_r,SM,v3e,Y_r,Z_r,MZ,K_r,e1r,o1r,RM,F3e,r1r,t1r,EZ,a1r,n1r,s1r,PM,T3e,l1r,i1r,CZ,d1r,m1r,c1r,BM,M3e,f1r,g1r,wZ,h1r,u1r,p1r,IM,E3e,_1r,b1r,AZ,v1r,F1r,T1r,NM,C3e,M1r,E1r,LZ,C1r,w1r,A1r,qM,w3e,L1r,y1r,yZ,x1r,$1r,k1r,DM,A3e,S1r,R1r,xZ,P1r,B1r,I1r,jM,L3e,N1r,q1r,$Z,D1r,j1r,G1r,GM,y3e,O1r,V1r,kZ,X1r,z1r,Q1r,OM,x3e,W1r,U1r,SZ,H1r,J1r,Y1r,VM,$3e,Z1r,K1r,RZ,e2r,o2r,r2r,XM,k3e,t2r,a2r,PZ,n2r,s2r,l2r,zM,S3e,i2r,d2r,BZ,m2r,c2r,f2r,QM,R3e,g2r,h2r,IZ,u2r,p2r,_2r,WM,P3e,b2r,v2r,NZ,F2r,T2r,M2r,UM,B3e,E2r,C2r,qZ,w2r,A2r,L2r,HM,I3e,y2r,x2r,DZ,$2r,k2r,S2r,JM,N3e,R2r,P2r,jZ,B2r,I2r,N2r,YM,q3e,q2r,D2r,GZ,j2r,G2r,O2r,ZM,D3e,V2r,X2r,OZ,z2r,Q2r,W2r,KM,j3e,U2r,H2r,VZ,J2r,Y2r,Z2r,eE,G3e,K2r,ebr,XZ,obr,rbr,tbr,oE,O3e,abr,nbr,zZ,sbr,lbr,ibr,rE,V3e,dbr,mbr,QZ,cbr,fbr,gbr,tE,X3e,hbr,ubr,WZ,pbr,_br,bbr,aE,z3e,vbr,Fbr,UZ,Tbr,Mbr,Ebr,nE,Q3e,Cbr,wbr,HZ,Abr,Lbr,ybr,sE,W3e,xbr,$br,JZ,kbr,Sbr,Rbr,lE,U3e,Pbr,Bbr,YZ,Ibr,Nbr,qbr,iE,H3e,Dbr,jbr,ZZ,Gbr,Obr,Vbr,dE,J3e,Xbr,zbr,KZ,Qbr,Wbr,Ubr,mE,Y3e,Hbr,Jbr,eK,Ybr,Zbr,Kbr,cE,Z3e,evr,ovr,oK,rvr,tvr,avr,fE,K3e,nvr,svr,rK,lvr,ivr,dvr,gE,mvr,e5e,cvr,fvr,o5e,gvr,hvr,hE,Glo,im,uE,r5e,wS,uvr,t5e,pvr,Olo,Wo,AS,_vr,dm,bvr,tK,vvr,Fvr,aK,Tvr,Mvr,Evr,LS,Cvr,a5e,wvr,Avr,Lvr,Rt,yS,yvr,n5e,xvr,$vr,mm,kvr,s5e,Svr,Rvr,nK,Pvr,Bvr,Ivr,pE,Nvr,co,xS,qvr,l5e,Dvr,jvr,vn,Gvr,i5e,Ovr,Vvr,d5e,Xvr,zvr,m5e,Qvr,Wvr,Uvr,K,_E,c5e,Hvr,Jvr,sK,Yvr,Zvr,Kvr,bE,f5e,eFr,oFr,lK,rFr,tFr,aFr,vE,g5e,nFr,sFr,iK,lFr,iFr,dFr,FE,h5e,mFr,cFr,dK,fFr,gFr,hFr,TE,u5e,uFr,pFr,mK,_Fr,bFr,vFr,ME,p5e,FFr,TFr,cK,MFr,EFr,CFr,EE,_5e,wFr,AFr,fK,LFr,yFr,xFr,CE,b5e,$Fr,kFr,gK,SFr,RFr,PFr,wE,v5e,BFr,IFr,hK,NFr,qFr,DFr,AE,F5e,jFr,GFr,uK,OFr,VFr,XFr,LE,T5e,zFr,QFr,pK,WFr,UFr,HFr,yE,M5e,JFr,YFr,_K,ZFr,KFr,eTr,xE,E5e,oTr,rTr,bK,tTr,aTr,nTr,$E,C5e,sTr,lTr,vK,iTr,dTr,mTr,kE,w5e,cTr,fTr,FK,gTr,hTr,uTr,SE,A5e,pTr,_Tr,TK,bTr,vTr,FTr,RE,L5e,TTr,MTr,MK,ETr,CTr,wTr,PE,y5e,ATr,LTr,EK,yTr,xTr,$Tr,BE,x5e,kTr,STr,CK,RTr,PTr,BTr,IE,$5e,ITr,NTr,wK,qTr,DTr,jTr,NE,k5e,GTr,OTr,AK,VTr,XTr,zTr,qE,S5e,QTr,WTr,LK,UTr,HTr,JTr,DE,R5e,YTr,ZTr,yK,KTr,eMr,oMr,jE,P5e,rMr,tMr,xK,aMr,nMr,sMr,GE,B5e,lMr,iMr,$K,dMr,mMr,cMr,OE,I5e,fMr,gMr,kK,hMr,uMr,pMr,VE,N5e,_Mr,bMr,SK,vMr,FMr,TMr,XE,q5e,MMr,EMr,RK,CMr,wMr,AMr,zE,D5e,LMr,yMr,PK,xMr,$Mr,kMr,QE,j5e,SMr,RMr,BK,PMr,BMr,IMr,WE,G5e,NMr,qMr,IK,DMr,jMr,GMr,UE,O5e,OMr,VMr,NK,XMr,zMr,QMr,HE,V5e,WMr,UMr,qK,HMr,JMr,YMr,JE,ZMr,X5e,KMr,eEr,z5e,oEr,rEr,YE,Vlo,cm,ZE,Q5e,$S,tEr,W5e,aEr,Xlo,Uo,kS,nEr,fm,sEr,DK,lEr,iEr,jK,dEr,mEr,cEr,SS,fEr,U5e,gEr,hEr,uEr,Pt,RS,pEr,H5e,_Er,bEr,gm,vEr,J5e,FEr,TEr,GK,MEr,EEr,CEr,KE,wEr,fo,PS,AEr,Y5e,LEr,yEr,Fn,xEr,Z5e,$Er,kEr,K5e,SEr,REr,e0e,PEr,BEr,IEr,Ye,e4,o0e,NEr,qEr,OK,DEr,jEr,GEr,o4,r0e,OEr,VEr,VK,XEr,zEr,QEr,r4,t0e,WEr,UEr,XK,HEr,JEr,YEr,t4,a0e,ZEr,KEr,zK,e4r,o4r,r4r,a4,n0e,t4r,a4r,QK,n4r,s4r,l4r,n4,s0e,i4r,d4r,WK,m4r,c4r,f4r,s4,l0e,g4r,h4r,UK,u4r,p4r,_4r,l4,b4r,i0e,v4r,F4r,d0e,T4r,M4r,i4,zlo,hm,d4,m0e,BS,E4r,c0e,C4r,Qlo,Ho,IS,w4r,um,A4r,HK,L4r,y4r,JK,x4r,$4r,k4r,NS,S4r,f0e,R4r,P4r,B4r,Bt,qS,I4r,g0e,N4r,q4r,pm,D4r,h0e,j4r,G4r,YK,O4r,V4r,X4r,m4,z4r,go,DS,Q4r,u0e,W4r,U4r,Tn,H4r,p0e,J4r,Y4r,_0e,Z4r,K4r,b0e,eCr,oCr,rCr,U,c4,v0e,tCr,aCr,ZK,nCr,sCr,lCr,f4,F0e,iCr,dCr,KK,mCr,cCr,fCr,g4,T0e,gCr,hCr,eee,uCr,pCr,_Cr,h4,M0e,bCr,vCr,oee,FCr,TCr,MCr,u4,E0e,ECr,CCr,ree,wCr,ACr,LCr,p4,C0e,yCr,xCr,tee,$Cr,kCr,SCr,_4,w0e,RCr,PCr,aee,BCr,ICr,NCr,b4,A0e,qCr,DCr,nee,jCr,GCr,OCr,v4,L0e,VCr,XCr,see,zCr,QCr,WCr,F4,y0e,UCr,HCr,lee,JCr,YCr,ZCr,T4,x0e,KCr,e3r,iee,o3r,r3r,t3r,M4,$0e,a3r,n3r,dee,s3r,l3r,i3r,E4,k0e,d3r,m3r,mee,c3r,f3r,g3r,C4,S0e,h3r,u3r,cee,p3r,_3r,b3r,w4,R0e,v3r,F3r,fee,T3r,M3r,E3r,A4,P0e,C3r,w3r,gee,A3r,L3r,y3r,L4,B0e,x3r,$3r,hee,k3r,S3r,R3r,y4,I0e,P3r,B3r,uee,I3r,N3r,q3r,x4,N0e,D3r,j3r,pee,G3r,O3r,V3r,$4,q0e,X3r,z3r,_ee,Q3r,W3r,U3r,k4,D0e,H3r,J3r,bee,Y3r,Z3r,K3r,S4,j0e,e5r,o5r,vee,r5r,t5r,a5r,R4,G0e,n5r,s5r,Fee,l5r,i5r,d5r,P4,O0e,m5r,c5r,Tee,f5r,g5r,h5r,B4,V0e,u5r,p5r,Mee,_5r,b5r,v5r,I4,X0e,F5r,T5r,Eee,M5r,E5r,C5r,N4,z0e,w5r,A5r,Cee,L5r,y5r,x5r,q4,Q0e,$5r,k5r,wee,S5r,R5r,P5r,D4,W0e,B5r,I5r,Aee,N5r,q5r,D5r,j4,U0e,j5r,G5r,Lee,O5r,V5r,X5r,G4,H0e,z5r,Q5r,yee,W5r,U5r,H5r,O4,J0e,J5r,Y5r,xee,Z5r,K5r,e0r,V4,Y0e,o0r,r0r,$ee,t0r,a0r,n0r,X4,Z0e,s0r,l0r,kee,i0r,d0r,m0r,z4,K0e,c0r,f0r,See,g0r,h0r,u0r,Q4,ewe,p0r,_0r,Ree,b0r,v0r,F0r,W4,owe,T0r,M0r,Pee,E0r,C0r,w0r,U4,rwe,A0r,L0r,Bee,y0r,x0r,$0r,H4,twe,k0r,S0r,Iee,R0r,P0r,B0r,J4,awe,I0r,N0r,Nee,q0r,D0r,j0r,Y4,nwe,G0r,O0r,qee,V0r,X0r,z0r,Z4,swe,Q0r,W0r,Dee,U0r,H0r,J0r,K4,Y0r,lwe,Z0r,K0r,iwe,ewr,owr,eC,Wlo,_m,oC,dwe,jS,rwr,mwe,twr,Ulo,Jo,GS,awr,bm,nwr,jee,swr,lwr,Gee,iwr,dwr,mwr,OS,cwr,cwe,fwr,gwr,hwr,It,VS,uwr,fwe,pwr,_wr,vm,bwr,gwe,vwr,Fwr,Oee,Twr,Mwr,Ewr,rC,Cwr,ho,XS,wwr,hwe,Awr,Lwr,Mn,ywr,uwe,xwr,$wr,pwe,kwr,Swr,_we,Rwr,Pwr,Bwr,O,tC,bwe,Iwr,Nwr,Vee,qwr,Dwr,jwr,aC,vwe,Gwr,Owr,Xee,Vwr,Xwr,zwr,nC,Fwe,Qwr,Wwr,zee,Uwr,Hwr,Jwr,sC,Twe,Ywr,Zwr,Qee,Kwr,eAr,oAr,lC,Mwe,rAr,tAr,Wee,aAr,nAr,sAr,iC,Ewe,lAr,iAr,Uee,dAr,mAr,cAr,dC,Cwe,fAr,gAr,Hee,hAr,uAr,pAr,mC,wwe,_Ar,bAr,Jee,vAr,FAr,TAr,cC,Awe,MAr,EAr,Yee,CAr,wAr,AAr,fC,Lwe,LAr,yAr,Zee,xAr,$Ar,kAr,gC,ywe,SAr,RAr,Kee,PAr,BAr,IAr,hC,xwe,NAr,qAr,eoe,DAr,jAr,GAr,uC,$we,OAr,VAr,ooe,XAr,zAr,QAr,pC,kwe,WAr,UAr,roe,HAr,JAr,YAr,_C,Swe,ZAr,KAr,toe,e6r,o6r,r6r,bC,Rwe,t6r,a6r,aoe,n6r,s6r,l6r,vC,Pwe,i6r,d6r,noe,m6r,c6r,f6r,FC,Bwe,g6r,h6r,soe,u6r,p6r,_6r,TC,Iwe,b6r,v6r,loe,F6r,T6r,M6r,MC,Nwe,E6r,C6r,ioe,w6r,A6r,L6r,EC,qwe,y6r,x6r,doe,$6r,k6r,S6r,CC,Dwe,R6r,P6r,moe,B6r,I6r,N6r,wC,jwe,q6r,D6r,coe,j6r,G6r,O6r,AC,Gwe,V6r,X6r,foe,z6r,Q6r,W6r,LC,Owe,U6r,H6r,goe,J6r,Y6r,Z6r,yC,Vwe,K6r,e7r,hoe,o7r,r7r,t7r,xC,Xwe,a7r,n7r,uoe,s7r,l7r,i7r,$C,zwe,d7r,m7r,poe,c7r,f7r,g7r,kC,Qwe,h7r,u7r,_oe,p7r,_7r,b7r,SC,Wwe,v7r,F7r,boe,T7r,M7r,E7r,RC,Uwe,C7r,w7r,voe,A7r,L7r,y7r,PC,Hwe,x7r,$7r,Foe,k7r,S7r,R7r,BC,Jwe,P7r,B7r,Toe,I7r,N7r,q7r,IC,Ywe,D7r,j7r,Moe,G7r,O7r,V7r,NC,Zwe,X7r,z7r,Eoe,Q7r,W7r,U7r,qC,Kwe,H7r,J7r,Coe,Y7r,Z7r,K7r,DC,eAe,e8r,o8r,woe,r8r,t8r,a8r,jC,oAe,n8r,s8r,Aoe,l8r,i8r,d8r,GC,rAe,m8r,c8r,Loe,f8r,g8r,h8r,OC,tAe,u8r,p8r,yoe,_8r,b8r,v8r,VC,aAe,F8r,T8r,xoe,M8r,E8r,C8r,XC,nAe,w8r,A8r,$oe,L8r,y8r,x8r,zC,sAe,$8r,k8r,koe,S8r,R8r,P8r,QC,lAe,B8r,I8r,Soe,N8r,q8r,D8r,WC,iAe,j8r,G8r,Roe,O8r,V8r,X8r,UC,dAe,z8r,Q8r,Poe,W8r,U8r,H8r,HC,mAe,J8r,Y8r,Boe,Z8r,K8r,eLr,JC,cAe,oLr,rLr,Ioe,tLr,aLr,nLr,YC,fAe,sLr,lLr,Noe,iLr,dLr,mLr,ZC,cLr,gAe,fLr,gLr,hAe,hLr,uLr,KC,Hlo,Fm,e3,uAe,zS,pLr,pAe,_Lr,Jlo,Yo,QS,bLr,Tm,vLr,qoe,FLr,TLr,Doe,MLr,ELr,CLr,WS,wLr,_Ae,ALr,LLr,yLr,Nt,US,xLr,bAe,$Lr,kLr,Mm,SLr,vAe,RLr,PLr,joe,BLr,ILr,NLr,o3,qLr,uo,HS,DLr,FAe,jLr,GLr,En,OLr,TAe,VLr,XLr,MAe,zLr,QLr,EAe,WLr,ULr,HLr,CAe,r3,wAe,JLr,YLr,Goe,ZLr,KLr,eyr,t3,oyr,AAe,ryr,tyr,LAe,ayr,nyr,a3,Ylo,Em,n3,yAe,JS,syr,xAe,lyr,Zlo,Zo,YS,iyr,Cm,dyr,Ooe,myr,cyr,Voe,fyr,gyr,hyr,ZS,uyr,$Ae,pyr,_yr,byr,qt,KS,vyr,kAe,Fyr,Tyr,wm,Myr,SAe,Eyr,Cyr,Xoe,wyr,Ayr,Lyr,s3,yyr,po,eR,xyr,RAe,$yr,kyr,Cn,Syr,PAe,Ryr,Pyr,BAe,Byr,Iyr,IAe,Nyr,qyr,Dyr,Am,l3,NAe,jyr,Gyr,zoe,Oyr,Vyr,Xyr,i3,qAe,zyr,Qyr,Qoe,Wyr,Uyr,Hyr,d3,DAe,Jyr,Yyr,Woe,Zyr,Kyr,e9r,m3,o9r,jAe,r9r,t9r,GAe,a9r,n9r,c3,Klo,Lm,f3,OAe,oR,s9r,VAe,l9r,eio,Ko,rR,i9r,ym,d9r,Uoe,m9r,c9r,Hoe,f9r,g9r,h9r,tR,u9r,XAe,p9r,_9r,b9r,Dt,aR,v9r,zAe,F9r,T9r,xm,M9r,QAe,E9r,C9r,Joe,w9r,A9r,L9r,g3,y9r,_o,nR,x9r,WAe,$9r,k9r,wn,S9r,UAe,R9r,P9r,HAe,B9r,I9r,JAe,N9r,q9r,D9r,Fe,h3,YAe,j9r,G9r,Yoe,O9r,V9r,X9r,u3,ZAe,z9r,Q9r,Zoe,W9r,U9r,H9r,p3,KAe,J9r,Y9r,Koe,Z9r,K9r,exr,_3,e6e,oxr,rxr,ere,txr,axr,nxr,Nl,o6e,sxr,lxr,ore,ixr,dxr,rre,mxr,cxr,fxr,b3,r6e,gxr,hxr,tre,uxr,pxr,_xr,ql,t6e,bxr,vxr,are,Fxr,Txr,nre,Mxr,Exr,Cxr,v3,a6e,wxr,Axr,sre,Lxr,yxr,xxr,jt,n6e,$xr,kxr,lre,Sxr,Rxr,ire,Pxr,Bxr,dre,Ixr,Nxr,qxr,F3,s6e,Dxr,jxr,mre,Gxr,Oxr,Vxr,T3,l6e,Xxr,zxr,cre,Qxr,Wxr,Uxr,M3,i6e,Hxr,Jxr,fre,Yxr,Zxr,Kxr,E3,d6e,e$r,o$r,gre,r$r,t$r,a$r,C3,m6e,n$r,s$r,hre,l$r,i$r,d$r,w3,c6e,m$r,c$r,ure,f$r,g$r,h$r,A3,f6e,u$r,p$r,pre,_$r,b$r,v$r,L3,g6e,F$r,T$r,_re,M$r,E$r,C$r,y3,h6e,w$r,A$r,bre,L$r,y$r,x$r,x3,$$r,u6e,k$r,S$r,p6e,R$r,P$r,$3,oio,$m,k3,_6e,sR,B$r,b6e,I$r,rio,er,lR,N$r,km,q$r,vre,D$r,j$r,Fre,G$r,O$r,V$r,iR,X$r,v6e,z$r,Q$r,W$r,Gt,dR,U$r,F6e,H$r,J$r,Sm,Y$r,T6e,Z$r,K$r,Tre,ekr,okr,rkr,S3,tkr,bo,mR,akr,M6e,nkr,skr,An,lkr,E6e,ikr,dkr,C6e,mkr,ckr,w6e,fkr,gkr,hkr,A6e,R3,L6e,ukr,pkr,Mre,_kr,bkr,vkr,P3,Fkr,y6e,Tkr,Mkr,x6e,Ekr,Ckr,B3,tio,Rm,I3,$6e,cR,wkr,k6e,Akr,aio,or,fR,Lkr,Pm,ykr,Ere,xkr,$kr,Cre,kkr,Skr,Rkr,gR,Pkr,S6e,Bkr,Ikr,Nkr,Ot,hR,qkr,R6e,Dkr,jkr,Bm,Gkr,P6e,Okr,Vkr,wre,Xkr,zkr,Qkr,N3,Wkr,vo,uR,Ukr,B6e,Hkr,Jkr,Ln,Ykr,I6e,Zkr,Kkr,N6e,eSr,oSr,q6e,rSr,tSr,aSr,D6e,q3,j6e,nSr,sSr,Are,lSr,iSr,dSr,D3,mSr,G6e,cSr,fSr,O6e,gSr,hSr,j3,nio,Im,G3,V6e,pR,uSr,X6e,pSr,sio,rr,_R,_Sr,Nm,bSr,Lre,vSr,FSr,yre,TSr,MSr,ESr,bR,CSr,z6e,wSr,ASr,LSr,Vt,vR,ySr,Q6e,xSr,$Sr,qm,kSr,W6e,SSr,RSr,xre,PSr,BSr,ISr,O3,NSr,Fo,FR,qSr,U6e,DSr,jSr,yn,GSr,H6e,OSr,VSr,J6e,XSr,zSr,Y6e,QSr,WSr,USr,Z6e,V3,K6e,HSr,JSr,$re,YSr,ZSr,KSr,X3,eRr,e7e,oRr,rRr,o7e,tRr,aRr,z3,lio,Dm,Q3,r7e,TR,nRr,t7e,sRr,iio,tr,MR,lRr,jm,iRr,kre,dRr,mRr,Sre,cRr,fRr,gRr,ER,hRr,a7e,uRr,pRr,_Rr,Xt,CR,bRr,n7e,vRr,FRr,Gm,TRr,s7e,MRr,ERr,Rre,CRr,wRr,ARr,W3,LRr,To,wR,yRr,l7e,xRr,$Rr,xn,kRr,i7e,SRr,RRr,d7e,PRr,BRr,m7e,IRr,NRr,qRr,Ne,U3,c7e,DRr,jRr,Pre,GRr,ORr,VRr,H3,f7e,XRr,zRr,Bre,QRr,WRr,URr,J3,g7e,HRr,JRr,Ire,YRr,ZRr,KRr,Y3,h7e,ePr,oPr,Nre,rPr,tPr,aPr,Z3,u7e,nPr,sPr,qre,lPr,iPr,dPr,K3,p7e,mPr,cPr,Dre,fPr,gPr,hPr,e5,_7e,uPr,pPr,jre,_Pr,bPr,vPr,o5,b7e,FPr,TPr,Gre,MPr,EPr,CPr,r5,v7e,wPr,APr,Ore,LPr,yPr,xPr,t5,$Pr,F7e,kPr,SPr,T7e,RPr,PPr,a5,dio,Om,n5,M7e,AR,BPr,E7e,IPr,mio,ar,LR,NPr,Vm,qPr,Vre,DPr,jPr,Xre,GPr,OPr,VPr,yR,XPr,C7e,zPr,QPr,WPr,zt,xR,UPr,w7e,HPr,JPr,Xm,YPr,A7e,ZPr,KPr,zre,eBr,oBr,rBr,s5,tBr,Mo,$R,aBr,L7e,nBr,sBr,$n,lBr,y7e,iBr,dBr,x7e,mBr,cBr,$7e,fBr,gBr,hBr,vt,l5,k7e,uBr,pBr,Qre,_Br,bBr,vBr,i5,S7e,FBr,TBr,Wre,MBr,EBr,CBr,d5,R7e,wBr,ABr,Ure,LBr,yBr,xBr,m5,P7e,$Br,kBr,Hre,SBr,RBr,PBr,c5,B7e,BBr,IBr,Jre,NBr,qBr,DBr,f5,jBr,I7e,GBr,OBr,N7e,VBr,XBr,g5,cio,zm,h5,q7e,kR,zBr,D7e,QBr,fio,nr,SR,WBr,Qm,UBr,Yre,HBr,JBr,Zre,YBr,ZBr,KBr,RR,eIr,j7e,oIr,rIr,tIr,Qt,PR,aIr,G7e,nIr,sIr,Wm,lIr,O7e,iIr,dIr,Kre,mIr,cIr,fIr,u5,gIr,Eo,BR,hIr,V7e,uIr,pIr,kn,_Ir,X7e,bIr,vIr,z7e,FIr,TIr,Q7e,MIr,EIr,CIr,xe,p5,W7e,wIr,AIr,ete,LIr,yIr,xIr,_5,U7e,$Ir,kIr,ote,SIr,RIr,PIr,b5,H7e,BIr,IIr,rte,NIr,qIr,DIr,v5,J7e,jIr,GIr,tte,OIr,VIr,XIr,F5,Y7e,zIr,QIr,ate,WIr,UIr,HIr,T5,Z7e,JIr,YIr,nte,ZIr,KIr,eNr,M5,K7e,oNr,rNr,ste,tNr,aNr,nNr,E5,e8e,sNr,lNr,lte,iNr,dNr,mNr,C5,o8e,cNr,fNr,ite,gNr,hNr,uNr,w5,r8e,pNr,_Nr,dte,bNr,vNr,FNr,A5,TNr,t8e,MNr,ENr,a8e,CNr,wNr,L5,gio,Um,y5,n8e,IR,ANr,s8e,LNr,hio,sr,NR,yNr,Hm,xNr,mte,$Nr,kNr,cte,SNr,RNr,PNr,qR,BNr,l8e,INr,NNr,qNr,Wt,DR,DNr,i8e,jNr,GNr,Jm,ONr,d8e,VNr,XNr,fte,zNr,QNr,WNr,x5,UNr,Co,jR,HNr,m8e,JNr,YNr,Sn,ZNr,c8e,KNr,eqr,f8e,oqr,rqr,g8e,tqr,aqr,nqr,Ym,$5,h8e,sqr,lqr,gte,iqr,dqr,mqr,k5,u8e,cqr,fqr,hte,gqr,hqr,uqr,S5,p8e,pqr,_qr,ute,bqr,vqr,Fqr,R5,Tqr,_8e,Mqr,Eqr,b8e,Cqr,wqr,P5,uio,Zm,B5,v8e,GR,Aqr,F8e,Lqr,pio,lr,OR,yqr,Km,xqr,pte,$qr,kqr,_te,Sqr,Rqr,Pqr,VR,Bqr,T8e,Iqr,Nqr,qqr,Ut,XR,Dqr,M8e,jqr,Gqr,ec,Oqr,E8e,Vqr,Xqr,bte,zqr,Qqr,Wqr,I5,Uqr,wo,zR,Hqr,C8e,Jqr,Yqr,Rn,Zqr,w8e,Kqr,eDr,A8e,oDr,rDr,L8e,tDr,aDr,nDr,Ft,N5,y8e,sDr,lDr,vte,iDr,dDr,mDr,q5,x8e,cDr,fDr,Fte,gDr,hDr,uDr,D5,$8e,pDr,_Dr,Tte,bDr,vDr,FDr,j5,k8e,TDr,MDr,Mte,EDr,CDr,wDr,G5,S8e,ADr,LDr,Ete,yDr,xDr,$Dr,O5,kDr,R8e,SDr,RDr,P8e,PDr,BDr,V5,_io,oc,X5,B8e,QR,IDr,I8e,NDr,bio,ir,WR,qDr,rc,DDr,Cte,jDr,GDr,wte,ODr,VDr,XDr,UR,zDr,N8e,QDr,WDr,UDr,Ht,HR,HDr,q8e,JDr,YDr,tc,ZDr,D8e,KDr,ejr,Ate,ojr,rjr,tjr,z5,ajr,Ao,JR,njr,j8e,sjr,ljr,Pn,ijr,G8e,djr,mjr,O8e,cjr,fjr,V8e,gjr,hjr,ujr,Bn,Q5,X8e,pjr,_jr,Lte,bjr,vjr,Fjr,W5,z8e,Tjr,Mjr,yte,Ejr,Cjr,wjr,U5,Q8e,Ajr,Ljr,xte,yjr,xjr,$jr,H5,W8e,kjr,Sjr,$te,Rjr,Pjr,Bjr,J5,Ijr,U8e,Njr,qjr,H8e,Djr,jjr,Y5,vio,ac,Z5,J8e,YR,Gjr,Y8e,Ojr,Fio,dr,ZR,Vjr,nc,Xjr,kte,zjr,Qjr,Ste,Wjr,Ujr,Hjr,KR,Jjr,Z8e,Yjr,Zjr,Kjr,Jt,eP,eGr,K8e,oGr,rGr,sc,tGr,eLe,aGr,nGr,Rte,sGr,lGr,iGr,K5,dGr,Lo,oP,mGr,oLe,cGr,fGr,In,gGr,rLe,hGr,uGr,tLe,pGr,_Gr,aLe,bGr,vGr,FGr,Tt,e0,nLe,TGr,MGr,Pte,EGr,CGr,wGr,o0,sLe,AGr,LGr,Bte,yGr,xGr,$Gr,r0,lLe,kGr,SGr,Ite,RGr,PGr,BGr,t0,iLe,IGr,NGr,Nte,qGr,DGr,jGr,a0,dLe,GGr,OGr,qte,VGr,XGr,zGr,n0,QGr,mLe,WGr,UGr,cLe,HGr,JGr,s0,Tio,lc,l0,fLe,rP,YGr,gLe,ZGr,Mio,mr,tP,KGr,ic,eOr,Dte,oOr,rOr,jte,tOr,aOr,nOr,aP,sOr,hLe,lOr,iOr,dOr,Yt,nP,mOr,uLe,cOr,fOr,dc,gOr,pLe,hOr,uOr,Gte,pOr,_Or,bOr,i0,vOr,yo,sP,FOr,_Le,TOr,MOr,Nn,EOr,bLe,COr,wOr,vLe,AOr,LOr,FLe,yOr,xOr,$Or,TLe,d0,MLe,kOr,SOr,Ote,ROr,POr,BOr,m0,IOr,ELe,NOr,qOr,CLe,DOr,jOr,c0,Eio,mc,f0,wLe,lP,GOr,ALe,OOr,Cio,cr,iP,VOr,cc,XOr,Vte,zOr,QOr,Xte,WOr,UOr,HOr,dP,JOr,LLe,YOr,ZOr,KOr,Zt,mP,eVr,yLe,oVr,rVr,fc,tVr,xLe,aVr,nVr,zte,sVr,lVr,iVr,g0,dVr,xo,cP,mVr,$Le,cVr,fVr,qn,gVr,kLe,hVr,uVr,SLe,pVr,_Vr,RLe,bVr,vVr,FVr,Mt,h0,PLe,TVr,MVr,Qte,EVr,CVr,wVr,u0,BLe,AVr,LVr,Wte,yVr,xVr,$Vr,p0,ILe,kVr,SVr,Ute,RVr,PVr,BVr,_0,NLe,IVr,NVr,Hte,qVr,DVr,jVr,b0,qLe,GVr,OVr,Jte,VVr,XVr,zVr,v0,QVr,DLe,WVr,UVr,jLe,HVr,JVr,F0,wio,gc,T0,GLe,fP,YVr,OLe,ZVr,Aio,fr,gP,KVr,hc,eXr,Yte,oXr,rXr,Zte,tXr,aXr,nXr,hP,sXr,VLe,lXr,iXr,dXr,Kt,uP,mXr,XLe,cXr,fXr,uc,gXr,zLe,hXr,uXr,Kte,pXr,_Xr,bXr,M0,vXr,$o,pP,FXr,QLe,TXr,MXr,Dn,EXr,WLe,CXr,wXr,ULe,AXr,LXr,HLe,yXr,xXr,$Xr,JLe,E0,YLe,kXr,SXr,eae,RXr,PXr,BXr,C0,IXr,ZLe,NXr,qXr,KLe,DXr,jXr,w0,Lio,pc,A0,eye,_P,GXr,oye,OXr,yio,gr,bP,VXr,_c,XXr,oae,zXr,QXr,rae,WXr,UXr,HXr,vP,JXr,rye,YXr,ZXr,KXr,ea,FP,ezr,tye,ozr,rzr,bc,tzr,aye,azr,nzr,tae,szr,lzr,izr,L0,dzr,ko,TP,mzr,nye,czr,fzr,jn,gzr,sye,hzr,uzr,lye,pzr,_zr,iye,bzr,vzr,Fzr,dye,y0,mye,Tzr,Mzr,aae,Ezr,Czr,wzr,x0,Azr,cye,Lzr,yzr,fye,xzr,$zr,$0,xio,vc,k0,gye,MP,kzr,hye,Szr,$io,hr,EP,Rzr,Fc,Pzr,nae,Bzr,Izr,sae,Nzr,qzr,Dzr,CP,jzr,uye,Gzr,Ozr,Vzr,oa,wP,Xzr,pye,zzr,Qzr,Tc,Wzr,_ye,Uzr,Hzr,lae,Jzr,Yzr,Zzr,S0,Kzr,Xr,AP,eQr,bye,oQr,rQr,Gn,tQr,vye,aQr,nQr,Fye,sQr,lQr,Tye,iQr,dQr,mQr,P,R0,Mye,cQr,fQr,iae,gQr,hQr,uQr,P0,Eye,pQr,_Qr,dae,bQr,vQr,FQr,B0,Cye,TQr,MQr,mae,EQr,CQr,wQr,I0,wye,AQr,LQr,cae,yQr,xQr,$Qr,N0,Aye,kQr,SQr,fae,RQr,PQr,BQr,q0,Lye,IQr,NQr,gae,qQr,DQr,jQr,D0,yye,GQr,OQr,hae,VQr,XQr,zQr,j0,xye,QQr,WQr,uae,UQr,HQr,JQr,G0,$ye,YQr,ZQr,pae,KQr,eWr,oWr,O0,kye,rWr,tWr,_ae,aWr,nWr,sWr,V0,Sye,lWr,iWr,bae,dWr,mWr,cWr,X0,Rye,fWr,gWr,vae,hWr,uWr,pWr,z0,Pye,_Wr,bWr,Fae,vWr,FWr,TWr,Q0,Bye,MWr,EWr,Tae,CWr,wWr,AWr,W0,Iye,LWr,yWr,Mae,xWr,$Wr,kWr,U0,Nye,SWr,RWr,Eae,PWr,BWr,IWr,H0,qye,NWr,qWr,Cae,DWr,jWr,GWr,J0,Dye,OWr,VWr,wae,XWr,zWr,QWr,Y0,jye,WWr,UWr,Aae,HWr,JWr,YWr,Z0,Gye,ZWr,KWr,Lae,eUr,oUr,rUr,Dl,Oye,tUr,aUr,yae,nUr,sUr,xae,lUr,iUr,dUr,K0,Vye,mUr,cUr,$ae,fUr,gUr,hUr,ew,Xye,uUr,pUr,kae,_Ur,bUr,vUr,ow,zye,FUr,TUr,Sae,MUr,EUr,CUr,rw,Qye,wUr,AUr,Rae,LUr,yUr,xUr,tw,Wye,$Ur,kUr,Pae,SUr,RUr,PUr,aw,Uye,BUr,IUr,Bae,NUr,qUr,DUr,nw,Hye,jUr,GUr,Iae,OUr,VUr,XUr,sw,Jye,zUr,QUr,Nae,WUr,UUr,HUr,lw,Yye,JUr,YUr,qae,ZUr,KUr,eHr,iw,Zye,oHr,rHr,Dae,tHr,aHr,nHr,dw,Kye,sHr,lHr,jae,iHr,dHr,mHr,mw,e9e,cHr,fHr,Gae,gHr,hHr,uHr,cw,o9e,pHr,_Hr,Oae,bHr,vHr,FHr,fw,r9e,THr,MHr,Vae,EHr,CHr,wHr,gw,t9e,AHr,LHr,Xae,yHr,xHr,$Hr,hw,a9e,kHr,SHr,zae,RHr,PHr,BHr,uw,n9e,IHr,NHr,Qae,qHr,DHr,jHr,pw,s9e,GHr,OHr,Wae,VHr,XHr,zHr,_w,l9e,QHr,WHr,Uae,UHr,HHr,JHr,bw,i9e,YHr,ZHr,Hae,KHr,eJr,oJr,vw,d9e,rJr,tJr,Jae,aJr,nJr,sJr,Fw,m9e,lJr,iJr,Yae,dJr,mJr,cJr,Tw,c9e,fJr,gJr,Zae,hJr,uJr,pJr,Mw,f9e,_Jr,bJr,Kae,vJr,FJr,TJr,Ew,g9e,MJr,EJr,ene,CJr,wJr,AJr,Cw,h9e,LJr,yJr,one,xJr,$Jr,kJr,ww,u9e,SJr,RJr,rne,PJr,BJr,IJr,Aw,p9e,NJr,qJr,tne,DJr,jJr,GJr,Lw,_9e,OJr,VJr,ane,XJr,zJr,QJr,yw,b9e,WJr,UJr,nne,HJr,JJr,YJr,xw,v9e,ZJr,KJr,sne,eYr,oYr,rYr,$w,F9e,tYr,aYr,lne,nYr,sYr,lYr,kw,T9e,iYr,dYr,ine,mYr,cYr,fYr,Sw,M9e,gYr,hYr,dne,uYr,pYr,_Yr,Rw,E9e,bYr,vYr,mne,FYr,TYr,MYr,Pw,C9e,EYr,CYr,cne,wYr,AYr,LYr,Bw,w9e,yYr,xYr,fne,$Yr,kYr,SYr,Iw,kio,Mc,Nw,A9e,LP,RYr,L9e,PYr,Sio,ur,yP,BYr,Ec,IYr,gne,NYr,qYr,hne,DYr,jYr,GYr,xP,OYr,y9e,VYr,XYr,zYr,ra,$P,QYr,x9e,WYr,UYr,Cc,HYr,$9e,JYr,YYr,une,ZYr,KYr,eZr,qw,oZr,zr,kP,rZr,k9e,tZr,aZr,On,nZr,S9e,sZr,lZr,R9e,iZr,dZr,P9e,mZr,cZr,fZr,de,Dw,B9e,gZr,hZr,pne,uZr,pZr,_Zr,jw,I9e,bZr,vZr,_ne,FZr,TZr,MZr,Gw,N9e,EZr,CZr,bne,wZr,AZr,LZr,Ow,q9e,yZr,xZr,vne,$Zr,kZr,SZr,Vw,D9e,RZr,PZr,Fne,BZr,IZr,NZr,Xw,j9e,qZr,DZr,Tne,jZr,GZr,OZr,zw,G9e,VZr,XZr,Mne,zZr,QZr,WZr,Qw,O9e,UZr,HZr,Ene,JZr,YZr,ZZr,Ww,V9e,KZr,eKr,Cne,oKr,rKr,tKr,Uw,X9e,aKr,nKr,wne,sKr,lKr,iKr,Hw,z9e,dKr,mKr,Ane,cKr,fKr,gKr,Jw,Q9e,hKr,uKr,Lne,pKr,_Kr,bKr,Yw,W9e,vKr,FKr,yne,TKr,MKr,EKr,Zw,U9e,CKr,wKr,xne,AKr,LKr,yKr,Kw,H9e,xKr,$Kr,$ne,kKr,SKr,RKr,eA,J9e,PKr,BKr,kne,IKr,NKr,qKr,oA,Y9e,DKr,jKr,Sne,GKr,OKr,VKr,rA,Z9e,XKr,zKr,Rne,QKr,WKr,UKr,tA,K9e,HKr,JKr,Pne,YKr,ZKr,KKr,aA,exe,eet,oet,Bne,ret,tet,aet,nA,oxe,net,set,Ine,iet,det,met,sA,rxe,cet,fet,Nne,get,het,uet,lA,txe,pet,_et,qne,bet,vet,Fet,iA,Rio,wc,dA,axe,SP,Tet,nxe,Met,Pio,pr,RP,Eet,Ac,Cet,Dne,wet,Aet,jne,Let,yet,xet,PP,$et,sxe,ket,Set,Ret,ta,BP,Pet,lxe,Bet,Iet,Lc,Net,ixe,qet,Det,Gne,jet,Get,Oet,mA,Vet,Qr,IP,Xet,dxe,zet,Qet,Vn,Wet,mxe,Uet,Het,cxe,Jet,Yet,fxe,Zet,Ket,eot,Ce,cA,gxe,oot,rot,One,tot,aot,not,fA,hxe,sot,lot,Vne,iot,dot,mot,gA,uxe,cot,fot,Xne,got,hot,uot,hA,pxe,pot,_ot,zne,bot,vot,Fot,uA,_xe,Tot,Mot,Qne,Eot,Cot,wot,pA,bxe,Aot,Lot,Wne,yot,xot,$ot,_A,vxe,kot,Sot,Une,Rot,Pot,Bot,bA,Fxe,Iot,Not,Hne,qot,Dot,jot,vA,Txe,Got,Oot,Jne,Vot,Xot,zot,FA,Mxe,Qot,Wot,Yne,Uot,Hot,Jot,TA,Exe,Yot,Zot,Zne,Kot,ert,ort,MA,Cxe,rrt,trt,Kne,art,nrt,srt,EA,wxe,lrt,irt,ese,drt,mrt,crt,CA,Axe,frt,grt,ose,hrt,urt,prt,wA,Bio,yc,AA,Lxe,NP,_rt,yxe,brt,Iio,_r,qP,vrt,xc,Frt,rse,Trt,Mrt,tse,Ert,Crt,wrt,DP,Art,xxe,Lrt,yrt,xrt,aa,jP,$rt,$xe,krt,Srt,$c,Rrt,kxe,Prt,Brt,ase,Irt,Nrt,qrt,LA,Drt,Wr,GP,jrt,Sxe,Grt,Ort,Xn,Vrt,Rxe,Xrt,zrt,Pxe,Qrt,Wrt,Bxe,Urt,Hrt,Jrt,$e,yA,Ixe,Yrt,Zrt,nse,Krt,ett,ott,xA,Nxe,rtt,ttt,sse,att,ntt,stt,$A,qxe,ltt,itt,lse,dtt,mtt,ctt,jl,Dxe,ftt,gtt,ise,htt,utt,dse,ptt,_tt,btt,kA,jxe,vtt,Ftt,mse,Ttt,Mtt,Ett,SA,Gxe,Ctt,wtt,cse,Att,Ltt,ytt,RA,Oxe,xtt,$tt,fse,ktt,Stt,Rtt,PA,Vxe,Ptt,Btt,gse,Itt,Ntt,qtt,BA,Xxe,Dtt,jtt,hse,Gtt,Ott,Vtt,IA,zxe,Xtt,ztt,use,Qtt,Wtt,Utt,NA,Nio,kc,qA,Qxe,OP,Htt,Wxe,Jtt,qio,br,VP,Ytt,Sc,Ztt,pse,Ktt,eat,_se,oat,rat,tat,XP,aat,Uxe,nat,sat,lat,na,zP,iat,Hxe,dat,mat,Rc,cat,Jxe,fat,gat,bse,hat,uat,pat,DA,_at,Ur,QP,bat,Yxe,vat,Fat,zn,Tat,Zxe,Mat,Eat,Kxe,Cat,wat,e$e,Aat,Lat,yat,Pc,jA,o$e,xat,$at,vse,kat,Sat,Rat,GA,r$e,Pat,Bat,Fse,Iat,Nat,qat,OA,t$e,Dat,jat,Tse,Gat,Oat,Vat,VA,Dio,Bc,XA,a$e,WP,Xat,n$e,zat,jio,vr,UP,Qat,Ic,Wat,Mse,Uat,Hat,Ese,Jat,Yat,Zat,HP,Kat,s$e,ent,ont,rnt,sa,JP,tnt,l$e,ant,nnt,Nc,snt,i$e,lnt,int,Cse,dnt,mnt,cnt,zA,fnt,Hr,YP,gnt,d$e,hnt,unt,Qn,pnt,m$e,_nt,bnt,c$e,vnt,Fnt,f$e,Tnt,Mnt,Ent,ge,QA,g$e,Cnt,wnt,wse,Ant,Lnt,ynt,WA,h$e,xnt,$nt,Ase,knt,Snt,Rnt,UA,u$e,Pnt,Bnt,Lse,Int,Nnt,qnt,HA,p$e,Dnt,jnt,yse,Gnt,Ont,Vnt,JA,_$e,Xnt,znt,xse,Qnt,Wnt,Unt,YA,b$e,Hnt,Jnt,$se,Ynt,Znt,Knt,ZA,v$e,est,ost,kse,rst,tst,ast,KA,F$e,nst,sst,Sse,lst,ist,dst,e6,T$e,mst,cst,Rse,fst,gst,hst,o6,M$e,ust,pst,Pse,_st,bst,vst,r6,E$e,Fst,Tst,Bse,Mst,Est,Cst,t6,C$e,wst,Ast,Ise,Lst,yst,xst,a6,w$e,$st,kst,Nse,Sst,Rst,Pst,n6,A$e,Bst,Ist,qse,Nst,qst,Dst,s6,L$e,jst,Gst,Dse,Ost,Vst,Xst,l6,y$e,zst,Qst,jse,Wst,Ust,Hst,i6,x$e,Jst,Yst,Gse,Zst,Kst,elt,d6,$$e,olt,rlt,Ose,tlt,alt,nlt,m6,k$e,slt,llt,Vse,ilt,dlt,mlt,c6,S$e,clt,flt,Xse,glt,hlt,ult,f6,R$e,plt,_lt,zse,blt,vlt,Flt,g6,Gio,qc,h6,P$e,ZP,Tlt,B$e,Mlt,Oio,Fr,KP,Elt,Dc,Clt,Qse,wlt,Alt,Wse,Llt,ylt,xlt,eB,$lt,I$e,klt,Slt,Rlt,la,oB,Plt,N$e,Blt,Ilt,jc,Nlt,q$e,qlt,Dlt,Use,jlt,Glt,Olt,u6,Vlt,Jr,rB,Xlt,D$e,zlt,Qlt,Wn,Wlt,j$e,Ult,Hlt,G$e,Jlt,Ylt,O$e,Zlt,Klt,eit,ke,p6,V$e,oit,rit,Hse,tit,ait,nit,_6,X$e,sit,lit,Jse,iit,dit,mit,b6,z$e,cit,fit,Yse,git,hit,uit,v6,Q$e,pit,_it,Zse,bit,vit,Fit,F6,W$e,Tit,Mit,Kse,Eit,Cit,wit,T6,U$e,Ait,Lit,ele,yit,xit,$it,M6,H$e,kit,Sit,ole,Rit,Pit,Bit,E6,J$e,Iit,Nit,rle,qit,Dit,jit,C6,Y$e,Git,Oit,tle,Vit,Xit,zit,w6,Z$e,Qit,Wit,ale,Uit,Hit,Jit,A6,Vio,Gc,L6,K$e,tB,Yit,eke,Zit,Xio,Tr,aB,Kit,Oc,edt,nle,odt,rdt,sle,tdt,adt,ndt,nB,sdt,oke,ldt,idt,ddt,ia,sB,mdt,rke,cdt,fdt,Vc,gdt,tke,hdt,udt,lle,pdt,_dt,bdt,y6,vdt,Yr,lB,Fdt,ake,Tdt,Mdt,Un,Edt,nke,Cdt,wdt,ske,Adt,Ldt,lke,ydt,xdt,$dt,te,x6,ike,kdt,Sdt,ile,Rdt,Pdt,Bdt,$6,dke,Idt,Ndt,dle,qdt,Ddt,jdt,k6,mke,Gdt,Odt,mle,Vdt,Xdt,zdt,S6,cke,Qdt,Wdt,cle,Udt,Hdt,Jdt,R6,fke,Ydt,Zdt,fle,Kdt,emt,omt,P6,gke,rmt,tmt,gle,amt,nmt,smt,B6,hke,lmt,imt,hle,dmt,mmt,cmt,I6,uke,fmt,gmt,ule,hmt,umt,pmt,N6,pke,_mt,bmt,ple,vmt,Fmt,Tmt,q6,_ke,Mmt,Emt,_le,Cmt,wmt,Amt,D6,bke,Lmt,ymt,ble,xmt,$mt,kmt,j6,vke,Smt,Rmt,vle,Pmt,Bmt,Imt,G6,Fke,Nmt,qmt,Fle,Dmt,jmt,Gmt,O6,Tke,Omt,Vmt,Tle,Xmt,zmt,Qmt,V6,Mke,Wmt,Umt,Mle,Hmt,Jmt,Ymt,X6,Eke,Zmt,Kmt,Ele,ect,oct,rct,z6,Cke,tct,act,Cle,nct,sct,lct,Q6,wke,ict,dct,wle,mct,cct,fct,W6,Ake,gct,hct,Ale,uct,pct,_ct,U6,Lke,bct,vct,Lle,Fct,Tct,Mct,H6,yke,Ect,Cct,yle,wct,Act,Lct,J6,xke,yct,xct,xle,$ct,kct,Sct,Y6,$ke,Rct,Pct,$le,Bct,Ict,Nct,Z6,kke,qct,Dct,kle,jct,Gct,Oct,K6,Ske,Vct,Xct,Sle,zct,Qct,Wct,e7,Rke,Uct,Hct,Rle,Jct,Yct,Zct,o7,Pke,Kct,eft,Ple,oft,rft,tft,r7,Bke,aft,nft,Ble,sft,lft,ift,t7,zio,Xc,a7,Ike,iB,dft,Nke,mft,Qio,Mr,dB,cft,zc,fft,Ile,gft,hft,Nle,uft,pft,_ft,mB,bft,qke,vft,Fft,Tft,da,cB,Mft,Dke,Eft,Cft,Qc,wft,jke,Aft,Lft,qle,yft,xft,$ft,n7,kft,Zr,fB,Sft,Gke,Rft,Pft,Hn,Bft,Oke,Ift,Nft,Vke,qft,Dft,Xke,jft,Gft,Oft,Te,s7,zke,Vft,Xft,Dle,zft,Qft,Wft,l7,Qke,Uft,Hft,jle,Jft,Yft,Zft,i7,Wke,Kft,egt,Gle,ogt,rgt,tgt,d7,Uke,agt,ngt,Ole,sgt,lgt,igt,m7,Hke,dgt,mgt,Vle,cgt,fgt,ggt,c7,Jke,hgt,ugt,Xle,pgt,_gt,bgt,f7,Yke,vgt,Fgt,zle,Tgt,Mgt,Egt,g7,Zke,Cgt,wgt,Qle,Agt,Lgt,ygt,h7,Kke,xgt,$gt,Wle,kgt,Sgt,Rgt,u7,eSe,Pgt,Bgt,Ule,Igt,Ngt,qgt,p7,oSe,Dgt,jgt,Hle,Ggt,Ogt,Vgt,_7,rSe,Xgt,zgt,Jle,Qgt,Wgt,Ugt,b7,tSe,Hgt,Jgt,Yle,Ygt,Zgt,Kgt,v7,aSe,eht,oht,Zle,rht,tht,aht,F7,nSe,nht,sht,Kle,lht,iht,dht,T7,sSe,mht,cht,eie,fht,ght,hht,M7,lSe,uht,pht,oie,_ht,bht,vht,E7,Wio,Wc,C7,iSe,gB,Fht,dSe,Tht,Uio,Er,hB,Mht,Uc,Eht,rie,Cht,wht,tie,Aht,Lht,yht,uB,xht,mSe,$ht,kht,Sht,ma,pB,Rht,cSe,Pht,Bht,Hc,Iht,fSe,Nht,qht,aie,Dht,jht,Ght,w7,Oht,Kr,_B,Vht,gSe,Xht,zht,Jn,Qht,hSe,Wht,Uht,uSe,Hht,Jht,pSe,Yht,Zht,Kht,bB,A7,_Se,eut,out,nie,rut,tut,aut,L7,bSe,nut,sut,sie,lut,iut,dut,y7,Hio,Jc,x7,vSe,vB,mut,FSe,cut,Jio,Cr,FB,fut,Yc,gut,lie,hut,uut,iie,put,_ut,but,TB,vut,TSe,Fut,Tut,Mut,ca,MB,Eut,MSe,Cut,wut,Zc,Aut,ESe,Lut,yut,die,xut,$ut,kut,$7,Sut,et,EB,Rut,CSe,Put,But,Yn,Iut,wSe,Nut,qut,ASe,Dut,jut,LSe,Gut,Out,Vut,ySe,k7,xSe,Xut,zut,mie,Qut,Wut,Uut,S7,Yio,Kc,R7,$Se,CB,Hut,kSe,Jut,Zio,wr,wB,Yut,ef,Zut,cie,Kut,ept,fie,opt,rpt,tpt,AB,apt,SSe,npt,spt,lpt,fa,LB,ipt,RSe,dpt,mpt,of,cpt,PSe,fpt,gpt,gie,hpt,upt,ppt,P7,_pt,ot,yB,bpt,BSe,vpt,Fpt,Zn,Tpt,ISe,Mpt,Ept,NSe,Cpt,wpt,qSe,Apt,Lpt,ypt,DSe,B7,jSe,xpt,$pt,hie,kpt,Spt,Rpt,I7,Kio,rf,N7,GSe,xB,Ppt,OSe,Bpt,edo,Ar,$B,Ipt,tf,Npt,uie,qpt,Dpt,pie,jpt,Gpt,Opt,kB,Vpt,VSe,Xpt,zpt,Qpt,ga,SB,Wpt,XSe,Upt,Hpt,af,Jpt,zSe,Ypt,Zpt,_ie,Kpt,e_t,o_t,q7,r_t,rt,RB,t_t,QSe,a_t,n_t,Kn,s_t,WSe,l_t,i_t,USe,d_t,m_t,HSe,c_t,f_t,g_t,me,D7,JSe,h_t,u_t,bie,p_t,__t,b_t,j7,YSe,v_t,F_t,vie,T_t,M_t,E_t,G7,ZSe,C_t,w_t,Fie,A_t,L_t,y_t,O7,KSe,x_t,$_t,Tie,k_t,S_t,R_t,V7,eRe,P_t,B_t,Mie,I_t,N_t,q_t,X7,oRe,D_t,j_t,Eie,G_t,O_t,V_t,z7,rRe,X_t,z_t,Cie,Q_t,W_t,U_t,Q7,tRe,H_t,J_t,wie,Y_t,Z_t,K_t,W7,aRe,e1t,o1t,Aie,r1t,t1t,a1t,U7,nRe,n1t,s1t,Lie,l1t,i1t,d1t,H7,sRe,m1t,c1t,yie,f1t,g1t,h1t,J7,lRe,u1t,p1t,xie,_1t,b1t,v1t,Y7,iRe,F1t,T1t,$ie,M1t,E1t,C1t,Z7,dRe,w1t,A1t,kie,L1t,y1t,x1t,K7,mRe,$1t,k1t,Sie,S1t,R1t,P1t,e8,cRe,B1t,I1t,Rie,N1t,q1t,D1t,o8,fRe,j1t,G1t,Pie,O1t,V1t,X1t,r8,gRe,z1t,Q1t,Bie,W1t,U1t,H1t,t8,hRe,J1t,Y1t,Iie,Z1t,K1t,e2t,a8,uRe,o2t,r2t,Nie,t2t,a2t,n2t,n8,pRe,s2t,l2t,qie,i2t,d2t,m2t,s8,_Re,c2t,f2t,Die,g2t,h2t,u2t,l8,odo,nf,i8,bRe,PB,p2t,vRe,_2t,rdo,Lr,BB,b2t,sf,v2t,jie,F2t,T2t,Gie,M2t,E2t,C2t,IB,w2t,FRe,A2t,L2t,y2t,ha,NB,x2t,TRe,$2t,k2t,lf,S2t,MRe,R2t,P2t,Oie,B2t,I2t,N2t,d8,q2t,tt,qB,D2t,ERe,j2t,G2t,es,O2t,CRe,V2t,X2t,wRe,z2t,Q2t,ARe,W2t,U2t,H2t,he,m8,LRe,J2t,Y2t,Vie,Z2t,K2t,ebt,c8,yRe,obt,rbt,Xie,tbt,abt,nbt,f8,xRe,sbt,lbt,zie,ibt,dbt,mbt,g8,$Re,cbt,fbt,Qie,gbt,hbt,ubt,h8,kRe,pbt,_bt,Wie,bbt,vbt,Fbt,u8,SRe,Tbt,Mbt,Uie,Ebt,Cbt,wbt,p8,RRe,Abt,Lbt,Hie,ybt,xbt,$bt,_8,PRe,kbt,Sbt,Jie,Rbt,Pbt,Bbt,b8,BRe,Ibt,Nbt,Yie,qbt,Dbt,jbt,v8,IRe,Gbt,Obt,Zie,Vbt,Xbt,zbt,F8,NRe,Qbt,Wbt,Kie,Ubt,Hbt,Jbt,T8,qRe,Ybt,Zbt,ede,Kbt,evt,ovt,M8,DRe,rvt,tvt,ode,avt,nvt,svt,E8,jRe,lvt,ivt,rde,dvt,mvt,cvt,C8,GRe,fvt,gvt,tde,hvt,uvt,pvt,w8,ORe,_vt,bvt,ade,vvt,Fvt,Tvt,A8,VRe,Mvt,Evt,nde,Cvt,wvt,Avt,L8,XRe,Lvt,yvt,sde,xvt,$vt,kvt,y8,zRe,Svt,Rvt,lde,Pvt,Bvt,Ivt,x8,QRe,Nvt,qvt,ide,Dvt,jvt,Gvt,$8,WRe,Ovt,Vvt,dde,Xvt,zvt,Qvt,k8,tdo,df,S8,URe,DB,Wvt,HRe,Uvt,ado,yr,jB,Hvt,mf,Jvt,mde,Yvt,Zvt,cde,Kvt,eFt,oFt,GB,rFt,JRe,tFt,aFt,nFt,ua,OB,sFt,YRe,lFt,iFt,cf,dFt,ZRe,mFt,cFt,fde,fFt,gFt,hFt,R8,uFt,at,VB,pFt,KRe,_Ft,bFt,os,vFt,ePe,FFt,TFt,oPe,MFt,EFt,rPe,CFt,wFt,AFt,tPe,P8,aPe,LFt,yFt,gde,xFt,$Ft,kFt,B8,ndo,ff,I8,nPe,XB,SFt,sPe,RFt,sdo,xr,zB,PFt,gf,BFt,hde,IFt,NFt,ude,qFt,DFt,jFt,QB,GFt,lPe,OFt,VFt,XFt,pa,WB,zFt,iPe,QFt,WFt,hf,UFt,dPe,HFt,JFt,pde,YFt,ZFt,KFt,N8,eTt,nt,UB,oTt,mPe,rTt,tTt,rs,aTt,cPe,nTt,sTt,fPe,lTt,iTt,gPe,dTt,mTt,cTt,HB,q8,hPe,fTt,gTt,_de,hTt,uTt,pTt,D8,uPe,_Tt,bTt,bde,vTt,FTt,TTt,j8,ldo,uf,G8,pPe,JB,MTt,_Pe,ETt,ido,$r,YB,CTt,pf,wTt,vde,ATt,LTt,Fde,yTt,xTt,$Tt,ZB,kTt,bPe,STt,RTt,PTt,_a,KB,BTt,vPe,ITt,NTt,_f,qTt,FPe,DTt,jTt,Tde,GTt,OTt,VTt,O8,XTt,st,eI,zTt,TPe,QTt,WTt,ts,UTt,MPe,HTt,JTt,EPe,YTt,ZTt,CPe,KTt,eMt,oMt,ne,V8,wPe,rMt,tMt,Mde,aMt,nMt,sMt,X8,APe,lMt,iMt,Ede,dMt,mMt,cMt,z8,LPe,fMt,gMt,Cde,hMt,uMt,pMt,Q8,yPe,_Mt,bMt,wde,vMt,FMt,TMt,W8,xPe,MMt,EMt,Ade,CMt,wMt,AMt,U8,$Pe,LMt,yMt,Lde,xMt,$Mt,kMt,H8,kPe,SMt,RMt,yde,PMt,BMt,IMt,J8,SPe,NMt,qMt,xde,DMt,jMt,GMt,Y8,RPe,OMt,VMt,$de,XMt,zMt,QMt,Z8,PPe,WMt,UMt,kde,HMt,JMt,YMt,K8,BPe,ZMt,KMt,Sde,eEt,oEt,rEt,eL,IPe,tEt,aEt,Rde,nEt,sEt,lEt,oL,NPe,iEt,dEt,Pde,mEt,cEt,fEt,rL,qPe,gEt,hEt,Bde,uEt,pEt,_Et,tL,DPe,bEt,vEt,Ide,FEt,TEt,MEt,aL,jPe,EEt,CEt,Nde,wEt,AEt,LEt,nL,GPe,yEt,xEt,qde,$Et,kEt,SEt,sL,OPe,REt,PEt,Dde,BEt,IEt,NEt,lL,VPe,qEt,DEt,jde,jEt,GEt,OEt,iL,XPe,VEt,XEt,Gde,zEt,QEt,WEt,dL,zPe,UEt,HEt,Ode,JEt,YEt,ZEt,mL,QPe,KEt,e4t,Vde,o4t,r4t,t4t,cL,WPe,a4t,n4t,Xde,s4t,l4t,i4t,fL,UPe,d4t,m4t,zde,c4t,f4t,g4t,gL,HPe,h4t,u4t,Qde,p4t,_4t,b4t,hL,JPe,v4t,F4t,Wde,T4t,M4t,E4t,uL,YPe,C4t,w4t,Ude,A4t,L4t,y4t,pL,ddo,bf,_L,ZPe,oI,x4t,KPe,$4t,mdo,kr,rI,k4t,vf,S4t,Hde,R4t,P4t,Jde,B4t,I4t,N4t,tI,q4t,eBe,D4t,j4t,G4t,ba,aI,O4t,oBe,V4t,X4t,Ff,z4t,rBe,Q4t,W4t,Yde,U4t,H4t,J4t,bL,Y4t,lt,nI,Z4t,tBe,K4t,eCt,as,oCt,aBe,rCt,tCt,nBe,aCt,nCt,sBe,sCt,lCt,iCt,Se,vL,lBe,dCt,mCt,Zde,cCt,fCt,gCt,FL,iBe,hCt,uCt,Kde,pCt,_Ct,bCt,TL,dBe,vCt,FCt,eme,TCt,MCt,ECt,ML,mBe,CCt,wCt,ome,ACt,LCt,yCt,EL,cBe,xCt,$Ct,rme,kCt,SCt,RCt,CL,fBe,PCt,BCt,tme,ICt,NCt,qCt,wL,gBe,DCt,jCt,ame,GCt,OCt,VCt,AL,hBe,XCt,zCt,nme,QCt,WCt,UCt,LL,uBe,HCt,JCt,sme,YCt,ZCt,KCt,yL,pBe,e3t,o3t,lme,r3t,t3t,a3t,xL,cdo,Tf,$L,_Be,sI,n3t,bBe,s3t,fdo,Sr,lI,l3t,Mf,i3t,ime,d3t,m3t,dme,c3t,f3t,g3t,iI,h3t,vBe,u3t,p3t,_3t,va,dI,b3t,FBe,v3t,F3t,Ef,T3t,TBe,M3t,E3t,mme,C3t,w3t,A3t,kL,L3t,it,mI,y3t,MBe,x3t,$3t,ns,k3t,EBe,S3t,R3t,CBe,P3t,B3t,wBe,I3t,N3t,q3t,we,SL,ABe,D3t,j3t,cme,G3t,O3t,V3t,RL,LBe,X3t,z3t,fme,Q3t,W3t,U3t,PL,yBe,H3t,J3t,gme,Y3t,Z3t,K3t,BL,xBe,e5t,o5t,hme,r5t,t5t,a5t,IL,$Be,n5t,s5t,ume,l5t,i5t,d5t,NL,kBe,m5t,c5t,pme,f5t,g5t,h5t,qL,SBe,u5t,p5t,_me,_5t,b5t,v5t,DL,RBe,F5t,T5t,bme,M5t,E5t,C5t,jL,PBe,w5t,A5t,vme,L5t,y5t,x5t,GL,BBe,$5t,k5t,Fme,S5t,R5t,P5t,OL,IBe,B5t,I5t,Tme,N5t,q5t,D5t,VL,NBe,j5t,G5t,Mme,O5t,V5t,X5t,XL,qBe,z5t,Q5t,Eme,W5t,U5t,H5t,zL,gdo,Cf,QL,DBe,cI,J5t,jBe,Y5t,hdo,Rr,fI,Z5t,wf,K5t,Cme,e0t,o0t,wme,r0t,t0t,a0t,gI,n0t,GBe,s0t,l0t,i0t,Fa,hI,d0t,OBe,m0t,c0t,Af,f0t,VBe,g0t,h0t,Ame,u0t,p0t,_0t,WL,b0t,dt,uI,v0t,XBe,F0t,T0t,ss,M0t,zBe,E0t,C0t,QBe,w0t,A0t,WBe,L0t,y0t,x0t,Re,UL,UBe,$0t,k0t,Lme,S0t,R0t,P0t,HL,HBe,B0t,I0t,yme,N0t,q0t,D0t,JL,JBe,j0t,G0t,xme,O0t,V0t,X0t,YL,YBe,z0t,Q0t,$me,W0t,U0t,H0t,ZL,ZBe,J0t,Y0t,kme,Z0t,K0t,ewt,KL,KBe,owt,rwt,Sme,twt,awt,nwt,ey,eIe,swt,lwt,Rme,iwt,dwt,mwt,oy,oIe,cwt,fwt,Pme,gwt,hwt,uwt,ry,rIe,pwt,_wt,Bme,bwt,vwt,Fwt,ty,tIe,Twt,Mwt,Ime,Ewt,Cwt,wwt,ay,udo,Lf,ny,aIe,pI,Awt,nIe,Lwt,pdo,Pr,_I,ywt,yf,xwt,Nme,$wt,kwt,qme,Swt,Rwt,Pwt,bI,Bwt,sIe,Iwt,Nwt,qwt,Ta,vI,Dwt,lIe,jwt,Gwt,xf,Owt,iIe,Vwt,Xwt,Dme,zwt,Qwt,Wwt,sy,Uwt,mt,FI,Hwt,dIe,Jwt,Ywt,ls,Zwt,mIe,Kwt,eAt,cIe,oAt,rAt,fIe,tAt,aAt,nAt,Pe,ly,gIe,sAt,lAt,jme,iAt,dAt,mAt,iy,hIe,cAt,fAt,Gme,gAt,hAt,uAt,dy,uIe,pAt,_At,Ome,bAt,vAt,FAt,my,pIe,TAt,MAt,Vme,EAt,CAt,wAt,cy,_Ie,AAt,LAt,Xme,yAt,xAt,$At,fy,bIe,kAt,SAt,zme,RAt,PAt,BAt,gy,vIe,IAt,NAt,Qme,qAt,DAt,jAt,hy,FIe,GAt,OAt,Wme,VAt,XAt,zAt,uy,TIe,QAt,WAt,Ume,UAt,HAt,JAt,py,MIe,YAt,ZAt,Hme,KAt,e6t,o6t,_y,_do,$f,by,EIe,TI,r6t,CIe,t6t,bdo,Br,MI,a6t,kf,n6t,Jme,s6t,l6t,Yme,i6t,d6t,m6t,EI,c6t,wIe,f6t,g6t,h6t,Ma,CI,u6t,AIe,p6t,_6t,Sf,b6t,LIe,v6t,F6t,Zme,T6t,M6t,E6t,vy,C6t,ct,wI,w6t,yIe,A6t,L6t,is,y6t,xIe,x6t,$6t,$Ie,k6t,S6t,kIe,R6t,P6t,B6t,Be,Fy,SIe,I6t,N6t,Kme,q6t,D6t,j6t,Ty,RIe,G6t,O6t,ece,V6t,X6t,z6t,My,PIe,Q6t,W6t,oce,U6t,H6t,J6t,Ey,BIe,Y6t,Z6t,rce,K6t,e7t,o7t,Cy,IIe,r7t,t7t,tce,a7t,n7t,s7t,wy,NIe,l7t,i7t,ace,d7t,m7t,c7t,Ay,qIe,f7t,g7t,nce,h7t,u7t,p7t,Ly,DIe,_7t,b7t,sce,v7t,F7t,T7t,yy,jIe,M7t,E7t,lce,C7t,w7t,A7t,xy,GIe,L7t,y7t,ice,x7t,$7t,k7t,$y,vdo,Rf,ky,OIe,AI,S7t,VIe,R7t,Fdo,Ir,LI,P7t,Pf,B7t,dce,I7t,N7t,mce,q7t,D7t,j7t,yI,G7t,XIe,O7t,V7t,X7t,Ea,xI,z7t,zIe,Q7t,W7t,Bf,U7t,QIe,H7t,J7t,cce,Y7t,Z7t,K7t,Sy,e8t,ft,$I,o8t,WIe,r8t,t8t,ds,a8t,UIe,n8t,s8t,HIe,l8t,i8t,JIe,d8t,m8t,c8t,Ie,Ry,YIe,f8t,g8t,fce,h8t,u8t,p8t,Py,ZIe,_8t,b8t,gce,v8t,F8t,T8t,By,KIe,M8t,E8t,hce,C8t,w8t,A8t,Iy,eNe,L8t,y8t,uce,x8t,$8t,k8t,Ny,oNe,S8t,R8t,pce,P8t,B8t,I8t,qy,rNe,N8t,q8t,_ce,D8t,j8t,G8t,Dy,tNe,O8t,V8t,bce,X8t,z8t,Q8t,jy,aNe,W8t,U8t,vce,H8t,J8t,Y8t,Gy,nNe,Z8t,K8t,Fce,eLt,oLt,rLt,Oy,sNe,tLt,aLt,Tce,nLt,sLt,lLt,Vy,Tdo,If,Xy,lNe,kI,iLt,iNe,dLt,Mdo,Nr,SI,mLt,Nf,cLt,Mce,fLt,gLt,Ece,hLt,uLt,pLt,RI,_Lt,dNe,bLt,vLt,FLt,Ca,PI,TLt,mNe,MLt,ELt,qf,CLt,cNe,wLt,ALt,Cce,LLt,yLt,xLt,zy,$Lt,gt,BI,kLt,fNe,SLt,RLt,ms,PLt,gNe,BLt,ILt,hNe,NLt,qLt,uNe,DLt,jLt,GLt,We,Qy,pNe,OLt,VLt,wce,XLt,zLt,QLt,Wy,_Ne,WLt,ULt,Ace,HLt,JLt,YLt,Uy,bNe,ZLt,KLt,Lce,eyt,oyt,ryt,Hy,vNe,tyt,ayt,yce,nyt,syt,lyt,Jy,FNe,iyt,dyt,xce,myt,cyt,fyt,Yy,TNe,gyt,hyt,$ce,uyt,pyt,_yt,Zy,MNe,byt,vyt,kce,Fyt,Tyt,Myt,Ky,ENe,Eyt,Cyt,Sce,wyt,Ayt,Lyt,e9,Edo,Df,o9,CNe,II,yyt,wNe,xyt,Cdo,qr,NI,$yt,jf,kyt,Rce,Syt,Ryt,Pce,Pyt,Byt,Iyt,qI,Nyt,ANe,qyt,Dyt,jyt,wa,DI,Gyt,LNe,Oyt,Vyt,Gf,Xyt,yNe,zyt,Qyt,Bce,Wyt,Uyt,Hyt,r9,Jyt,ht,jI,Yyt,xNe,Zyt,Kyt,cs,e9t,$Ne,o9t,r9t,kNe,t9t,a9t,SNe,n9t,s9t,l9t,Ue,t9,RNe,i9t,d9t,Ice,m9t,c9t,f9t,a9,PNe,g9t,h9t,Nce,u9t,p9t,_9t,n9,BNe,b9t,v9t,qce,F9t,T9t,M9t,s9,INe,E9t,C9t,Dce,w9t,A9t,L9t,l9,NNe,y9t,x9t,jce,$9t,k9t,S9t,i9,qNe,R9t,P9t,Gce,B9t,I9t,N9t,d9,DNe,q9t,D9t,Oce,j9t,G9t,O9t,m9,jNe,V9t,X9t,Vce,z9t,Q9t,W9t,c9,wdo,Of,f9,GNe,GI,U9t,ONe,H9t,Ado,Dr,OI,J9t,Vf,Y9t,Xce,Z9t,K9t,zce,ext,oxt,rxt,VI,txt,VNe,axt,nxt,sxt,Aa,XI,lxt,XNe,ixt,dxt,Xf,mxt,zNe,cxt,fxt,Qce,gxt,hxt,uxt,g9,pxt,ut,zI,_xt,QNe,bxt,vxt,fs,Fxt,WNe,Txt,Mxt,UNe,Ext,Cxt,HNe,wxt,Axt,Lxt,JNe,h9,YNe,yxt,xxt,Wce,$xt,kxt,Sxt,u9,Ldo,zf,p9,ZNe,QI,Rxt,KNe,Pxt,ydo,jr,WI,Bxt,Qf,Ixt,Uce,Nxt,qxt,Hce,Dxt,jxt,Gxt,UI,Oxt,eqe,Vxt,Xxt,zxt,La,HI,Qxt,oqe,Wxt,Uxt,Wf,Hxt,rqe,Jxt,Yxt,Jce,Zxt,Kxt,e$t,_9,o$t,pt,JI,r$t,tqe,t$t,a$t,gs,n$t,aqe,s$t,l$t,nqe,i$t,d$t,sqe,m$t,c$t,f$t,YI,b9,lqe,g$t,h$t,Yce,u$t,p$t,_$t,v9,iqe,b$t,v$t,Zce,F$t,T$t,M$t,F9,xdo,Uf,T9,dqe,ZI,E$t,mqe,C$t,$do,Gr,KI,w$t,Hf,A$t,Kce,L$t,y$t,efe,x$t,$$t,k$t,eN,S$t,cqe,R$t,P$t,B$t,ya,oN,I$t,fqe,N$t,q$t,Jf,D$t,gqe,j$t,G$t,ofe,O$t,V$t,X$t,M9,z$t,_t,rN,Q$t,hqe,W$t,U$t,hs,H$t,uqe,J$t,Y$t,pqe,Z$t,K$t,_qe,ekt,okt,rkt,bqe,E9,vqe,tkt,akt,rfe,nkt,skt,lkt,C9,kdo;return m=new oe({}),sn=new B({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),ck=new oe({}),fk=new B({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),ng=new tfo({props:{warning:!0,$$slots:{default:[B9a]},$$scope:{ctx:$}}}),gk=new oe({}),hk=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L671"}}),_k=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L694"}}),Iu=new N({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[I9a]},$$scope:{ctx:$}}}),bk=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L817"}}),vk=new oe({}),Fk=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L449"}}),Ek=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/main/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L463"}}),Tp=new N({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[N9a]},$$scope:{ctx:$}}}),Ck=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L664"}}),wk=new oe({}),Ak=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L205"}}),xk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L219"}}),u_=new tfo({props:{$$slots:{default:[q9a]},$$scope:{ctx:$}}}),p_=new N({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[D9a]},$$scope:{ctx:$}}}),$k=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L346"}}),kk=new oe({}),Sk=new R({props:{name:"class transformers.AutoImageProcessor",anchor:"transformers.AutoImageProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/image_processing_auto.py#L189"}}),Bk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoImageProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoImageProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained image_processor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a image processor file saved using the
<a href="/docs/transformers/main/en/internal/image_processing_utils#transformers.ImageProcessingMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved image processor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoImageProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model image processor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoImageProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the image processor files and override the cached versions if
they exist.`,name:"force_download"},{anchor:"transformers.AutoImageProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoImageProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoImageProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoImageProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoImageProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final image processor object. If <code>True</code>, then this
functions returns a <code>Tuple(image_processor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not image processor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>image_processor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoImageProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoImageProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are image processor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> image processor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/image_processing_auto.py#L203"}}),U_=new tfo({props:{$$slots:{default:[j9a]},$$scope:{ctx:$}}}),H_=new N({props:{anchor:"transformers.AutoImageProcessor.from_pretrained.example",$$slots:{default:[G9a]},$$scope:{ctx:$}}}),Ik=new R({props:{name:"register",anchor:"transformers.AutoImageProcessor.register",parameters:[{name:"config_class",val:""},{name:"image_processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoImageProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoImageProcessor.register.image_processor_class",description:'<strong>image_processor_class</strong> (<a href="/docs/transformers/main/en/internal/image_processing_utils#transformers.ImageProcessingMixin">ImageProcessingMixin</a>) &#x2014; The image processor to register.',name:"image_processor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/image_processing_auto.py#L348"}}),Nk=new oe({}),qk=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L98"}}),Gk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L112"}}),T1=new tfo({props:{$$slots:{default:[O9a]},$$scope:{ctx:$}}}),M1=new N({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[V9a]},$$scope:{ctx:$}}}),Ok=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L293"}}),Vk=new oe({}),Xk=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L898"}}),Qk=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegConfig">CLIPSegConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegModel">CLIPSegModel</a> (CLIPSeg model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel">ConditionalDetrModel</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel">DeformableDetrModel</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig">DonutSwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel">DonutSwinModel</a> (DonutSwin model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel">ErnieModel</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmModel">EsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel">GPTNeoXJapaneseModel</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltModel">LiltModel</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel">MarkupLMModel</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel">MobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel">OwlViTModel</a> (OWL-ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel">PegasusXModel</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertModel">RoCBertModel</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model">Swinv2Model</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig">TableTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerModel">TableTransformerModel</a> (Table Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig">TimeSeriesTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel">TimeSeriesTransformerModel</a> (Time Series Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel">ViTMSNModel</a> (ViTMSN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel">VideoMAEModel</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel">WhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig">XCLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel">XCLIPModel</a> (X-CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),w1=new N({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[X9a]},$$scope:{ctx:$}}}),Wk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Hb=new N({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[z9a]},$$scope:{ctx:$}}}),Uk=new oe({}),Hk=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L905"}}),Yk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining">ErnieForPreTraining</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForPreTraining">RoCBertForPreTraining</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining">VideoMAEForPreTraining</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Yb=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[Q9a]},$$scope:{ctx:$}}}),Zk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Uv=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[W9a]},$$scope:{ctx:$}}}),Kk=new oe({}),eS=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L920"}}),rS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM">ErnieForCausalLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM">GPTNeoXJapaneseForCausalLM</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForCausalLM">RoCBertForCausalLM</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Jv=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[U9a]},$$scope:{ctx:$}}}),tS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),GF=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[H9a]},$$scope:{ctx:$}}}),aS=new oe({}),nS=new R({props:{name:"class transformers.AutoModelForDepthEstimation",anchor:"transformers.AutoModelForDepthEstimation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1063"}}),lS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDepthEstimation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDepthEstimation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForDepthEstimation">DPTForDepthEstimation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNForDepthEstimation">GLPNForDepthEstimation</a> (GLPN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),VF=new N({props:{anchor:"transformers.AutoModelForDepthEstimation.from_config.example",$$slots:{default:[J9a]},$$scope:{ctx:$}}}),iS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDepthEstimation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),WF=new N({props:{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.example",$$slots:{default:[Y9a]},$$scope:{ctx:$}}}),mS=new oe({}),cS=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L927"}}),gS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM">ErnieForMaskedLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForMaskedLM">RoCBertForMaskedLM</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),HF=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[Z9a]},$$scope:{ctx:$}}}),hS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),NT=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[K9a]},$$scope:{ctx:$}}}),uS=new oe({}),pS=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L934"}}),bS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration">PegasusXForConditionalGeneration</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),DT=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[exa]},$$scope:{ctx:$}}}),vS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),lM=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[oxa]},$$scope:{ctx:$}}}),FS=new oe({}),TS=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L943"}}),ES=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification">ErnieForSequenceClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification">EsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForSequenceClassification">LiltForSequenceClassification</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification">LukeForSequenceClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification">MarkupLMForSequenceClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification">OPTForSequenceClassification</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForSequenceClassification">RoCBertForSequenceClassification</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),dM=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[rxa]},$$scope:{ctx:$}}}),CS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),hE=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[txa]},$$scope:{ctx:$}}}),wS=new oe({}),AS=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L999"}}),yS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice">ErnieForMultipleChoice</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice">LukeForMultipleChoice</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForMultipleChoice">RoCBertForMultipleChoice</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),pE=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[axa]},$$scope:{ctx:$}}}),xS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),YE=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[nxa]},$$scope:{ctx:$}}}),$S=new oe({}),kS=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1006"}}),RS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction">ErnieForNextSentencePrediction</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),KE=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[sxa]},$$scope:{ctx:$}}}),PS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),i4=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[lxa]},$$scope:{ctx:$}}}),BS=new oe({}),IS=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L992"}}),qS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification">ErnieForTokenClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification">EsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForTokenClassification">LiltForTokenClassification</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification">LukeForTokenClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification">MarkupLMForTokenClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForTokenClassification">RoCBertForTokenClassification</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),m4=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[ixa]},$$scope:{ctx:$}}}),DS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),eC=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[dxa]},$$scope:{ctx:$}}}),jS=new oe({}),GS=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L952"}}),VS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering">BloomForQuestionAnswering</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering">ErnieForQuestionAnswering</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForQuestionAnswering">LiltForQuestionAnswering</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering">LukeForQuestionAnswering</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering">MarkupLMForQuestionAnswering</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForQuestionAnswering">OPTForQuestionAnswering</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForQuestionAnswering">RoCBertForQuestionAnswering</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),rC=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[mxa]},$$scope:{ctx:$}}}),XS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),KC=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[cxa]},$$scope:{ctx:$}}}),zS=new oe({}),QS=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L959"}}),US=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),o3=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[fxa]},$$scope:{ctx:$}}}),HS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),a3=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[gxa]},$$scope:{ctx:$}}}),JS=new oe({}),YS=new R({props:{name:"class transformers.AutoModelForDocumentQuestionAnswering",anchor:"transformers.AutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L981"}}),KS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering">LayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),s3=new N({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[hxa]},$$scope:{ctx:$}}}),eR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),c3=new N({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[uxa]},$$scope:{ctx:$}}}),oR=new oe({}),rR=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1015"}}),aR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification">MobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification">Swinv2ForImageClassification</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification">ViTMSNForImageClassification</a> (ViTMSN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),g3=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[pxa]},$$scope:{ctx:$}}}),nR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),$3=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[_xa]},$$scope:{ctx:$}}}),sR=new oe({}),lR=new R({props:{name:"class transformers.AutoModelForVideoClassification",anchor:"transformers.AutoModelForVideoClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1070"}}),dR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVideoClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification">VideoMAEForVideoClassification</a> (VideoMAE model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),S3=new N({props:{anchor:"transformers.AutoModelForVideoClassification.from_config.example",$$slots:{default:[bxa]},$$scope:{ctx:$}}}),mR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVideoClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),B3=new N({props:{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.example",$$slots:{default:[vxa]},$$scope:{ctx:$}}}),cR=new oe({}),fR=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1077"}}),hR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),N3=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[Fxa]},$$scope:{ctx:$}}}),uR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),j3=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Txa]},$$scope:{ctx:$}}}),pR=new oe({}),_R=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L970"}}),vR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),O3=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[Mxa]},$$scope:{ctx:$}}}),FR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),z3=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[Exa]},$$scope:{ctx:$}}}),TR=new oe({}),MR=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1084"}}),CR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),W3=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[Cxa]},$$scope:{ctx:$}}}),wR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),a5=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[wxa]},$$scope:{ctx:$}}}),AR=new oe({}),LR=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1107"}}),xR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),s5=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[Axa]},$$scope:{ctx:$}}}),$R=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),g5=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[Lxa]},$$scope:{ctx:$}}}),kR=new oe({}),SR=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1091"}}),PR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),u5=new N({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[yxa]},$$scope:{ctx:$}}}),BR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),L5=new N({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[xxa]},$$scope:{ctx:$}}}),IR=new oe({}),NR=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1098"}}),DR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration">WhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),x5=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[$xa]},$$scope:{ctx:$}}}),jR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),P5=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[kxa]},$$scope:{ctx:$}}}),GR=new oe({}),OR=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1116"}}),XR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),I5=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[Sxa]},$$scope:{ctx:$}}}),zR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),V5=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[Rxa]},$$scope:{ctx:$}}}),QR=new oe({}),WR=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1123"}}),HR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling">Swinv2ForMaskedImageModeling</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),z5=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[Pxa]},$$scope:{ctx:$}}}),JR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Y5=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[Bxa]},$$scope:{ctx:$}}}),YR=new oe({}),ZR=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1047"}}),eP=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection">ConditionalDetrForObjectDetection</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection">DeformableDetrForObjectDetection</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig">TableTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection">TableTransformerForObjectDetection</a> (Table Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),K5=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[Ixa]},$$scope:{ctx:$}}}),oP=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),s0=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[Nxa]},$$scope:{ctx:$}}}),rP=new oe({}),tP=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1022"}}),nP=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),i0=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[qxa]},$$scope:{ctx:$}}}),sP=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),c0=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[Dxa]},$$scope:{ctx:$}}}),lP=new oe({}),iP=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1029"}}),mP=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation">MobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),g0=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[jxa]},$$scope:{ctx:$}}}),cP=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),F0=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[Gxa]},$$scope:{ctx:$}}}),fP=new oe({}),gP=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1038"}}),uP=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),M0=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[Oxa]},$$scope:{ctx:$}}}),pP=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),w0=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[Vxa]},$$scope:{ctx:$}}}),_P=new oe({}),bP=new R({props:{name:"class transformers.AutoModelForZeroShotObjectDetection",anchor:"transformers.AutoModelForZeroShotObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1054"}}),FP=new R({props:{name:"from_config",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTForObjectDetection">OwlViTForObjectDetection</a> (OWL-ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),L0=new N({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.example",$$slots:{default:[Xxa]},$$scope:{ctx:$}}}),TP=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),$0=new N({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.example",$$slots:{default:[zxa]},$$scope:{ctx:$}}}),MP=new oe({}),EP=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L444"}}),wP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtModel">TFCvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel">TFDeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmModel">TFEsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel">TFGroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model">TFLayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel">TFMobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel">TFSegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperModel">TFWhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel">TFXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),S0=new N({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[Qxa]},$$scope:{ctx:$}}}),AP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Iw=new N({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[Wxa]},$$scope:{ctx:$}}}),LP=new oe({}),yP=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L451"}}),$P=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),qw=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[Uxa]},$$scope:{ctx:$}}}),kP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),iA=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[Hxa]},$$scope:{ctx:$}}}),SP=new oe({}),RP=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L466"}}),BP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM">TFXGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),mA=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[Jxa]},$$scope:{ctx:$}}}),IP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),wA=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Yxa]},$$scope:{ctx:$}}}),NP=new oe({}),qP=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L482"}}),jP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtForImageClassification">TFCvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification">TFDeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher">TFDeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification">TFMobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification">TFSegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),LA=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[Zxa]},$$scope:{ctx:$}}}),GP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),NA=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[Kxa]},$$scope:{ctx:$}}}),OP=new oe({}),VP=new R({props:{name:"class transformers.TFAutoModelForSemanticSegmentation",anchor:"transformers.TFAutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L491"}}),zP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation">TFData2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation">TFMobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation">TFSegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),DA=new N({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[e$a]},$$scope:{ctx:$}}}),QP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),VA=new N({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[o$a]},$$scope:{ctx:$}}}),WP=new oe({}),UP=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L507"}}),JP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForMaskedLM">TFEsmForMaskedLM</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),zA=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[r$a]},$$scope:{ctx:$}}}),YP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),g6=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[t$a]},$$scope:{ctx:$}}}),ZP=new oe({}),KP=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L514"}}),oB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),u6=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[a$a]},$$scope:{ctx:$}}}),rB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),A6=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[n$a]},$$scope:{ctx:$}}}),tB=new oe({}),aB=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L523"}}),sB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForSequenceClassification">TFEsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification">TFLayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),y6=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[s$a]},$$scope:{ctx:$}}}),lB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),t7=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[l$a]},$$scope:{ctx:$}}}),iB=new oe({}),dB=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L570"}}),cB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),n7=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[i$a]},$$scope:{ctx:$}}}),fB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),E7=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[d$a]},$$scope:{ctx:$}}}),gB=new oe({}),hB=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L577"}}),pB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),w7=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[m$a]},$$scope:{ctx:$}}}),_B=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),y7=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[c$a]},$$scope:{ctx:$}}}),vB=new oe({}),FB=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L550"}}),MB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),$7=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[f$a]},$$scope:{ctx:$}}}),EB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),S7=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[g$a]},$$scope:{ctx:$}}}),CB=new oe({}),wB=new R({props:{name:"class transformers.TFAutoModelForDocumentQuestionAnswering",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L539"}}),LB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering">TFLayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),P7=new N({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[h$a]},$$scope:{ctx:$}}}),yB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),I7=new N({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[u$a]},$$scope:{ctx:$}}}),xB=new oe({}),$B=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L561"}}),SB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForTokenClassification">TFEsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification">TFLayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),q7=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[p$a]},$$scope:{ctx:$}}}),RB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),l8=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[_$a]},$$scope:{ctx:$}}}),PB=new oe({}),BB=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L532"}}),NB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering">TFLayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),d8=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[b$a]},$$scope:{ctx:$}}}),qB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),k8=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[v$a]},$$scope:{ctx:$}}}),DB=new oe({}),jB=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L500"}}),OB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),R8=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[F$a]},$$scope:{ctx:$}}}),VB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),B8=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[T$a]},$$scope:{ctx:$}}}),XB=new oe({}),zB=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L586"}}),WB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration">TFWhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),N8=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[M$a]},$$scope:{ctx:$}}}),UB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),j8=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[E$a]},$$scope:{ctx:$}}}),JB=new oe({}),YB=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),KB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),O8=new N({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[C$a]},$$scope:{ctx:$}}}),eI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),pL=new N({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[w$a]},$$scope:{ctx:$}}}),oI=new oe({}),rI=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),aI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),bL=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[A$a]},$$scope:{ctx:$}}}),nI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),xL=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[L$a]},$$scope:{ctx:$}}}),sI=new oe({}),lI=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),dI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),kL=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[y$a]},$$scope:{ctx:$}}}),mI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),zL=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[x$a]},$$scope:{ctx:$}}}),cI=new oe({}),fI=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),hI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),WL=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[$$a]},$$scope:{ctx:$}}}),uI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ay=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[k$a]},$$scope:{ctx:$}}}),pI=new oe({}),_I=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),vI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),sy=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[S$a]},$$scope:{ctx:$}}}),FI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),_y=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[R$a]},$$scope:{ctx:$}}}),TI=new oe({}),MI=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),CI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),vy=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[P$a]},$$scope:{ctx:$}}}),wI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),$y=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[B$a]},$$scope:{ctx:$}}}),AI=new oe({}),LI=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),xI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Sy=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[I$a]},$$scope:{ctx:$}}}),$I=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Vy=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[N$a]},$$scope:{ctx:$}}}),kI=new oe({}),SI=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),PI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),zy=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[q$a]},$$scope:{ctx:$}}}),BI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),e9=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[D$a]},$$scope:{ctx:$}}}),II=new oe({}),NI=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),DI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),r9=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[j$a]},$$scope:{ctx:$}}}),jI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),c9=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[G$a]},$$scope:{ctx:$}}}),GI=new oe({}),OI=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),XI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),g9=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[O$a]},$$scope:{ctx:$}}}),zI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),u9=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[V$a]},$$scope:{ctx:$}}}),QI=new oe({}),WI=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),HI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),_9=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[X$a]},$$scope:{ctx:$}}}),JI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),F9=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[z$a]},$$scope:{ctx:$}}}),ZI=new oe({}),KI=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),oN=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),M9=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[Q$a]},$$scope:{ctx:$}}}),rN=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),C9=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[W$a]},$$scope:{ctx:$}}}),{c(){g=a("meta"),v=l(),u=a("h1"),f=a("a"),p=a("span"),F(m.$$.fragment),h=l(),He=a("span"),Ad=o("Auto Classes"),eg=l(),wt=a("p"),Ld=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),yd=a("code"),lk=o("from_pretrained()"),og=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Qe=l(),Ze=a("p"),xd=o("Instantiating one of "),ps=a("a"),ik=o("AutoConfig"),_s=o(", "),bs=a("a"),dk=o("AutoModel"),$d=o(`, and
`),vs=a("a"),mk=o("AutoTokenizer"),kd=o(" will directly create a class of the relevant architecture. For instance"),rg=l(),F(sn.$$.fragment),Ke=l(),ye=a("p"),kq=o("will create a model that is an instance of "),Sd=a("a"),Sq=o("BertModel"),Rq=o("."),Po=l(),ln=a("p"),Pq=o("There is one class of "),tg=a("code"),Bq=o("AutoModel"),afo=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),flo=l(),Rd=a("h2"),ag=a("a"),che=a("span"),F(ck.$$.fragment),nfo=l(),fhe=a("span"),sfo=o("Extending the Auto Classes"),glo=l(),Fs=a("p"),lfo=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),ghe=a("code"),ifo=o("NewModel"),dfo=o(", make sure you have a "),hhe=a("code"),mfo=o("NewModelConfig"),cfo=o(` then you can add those to the auto
classes like this:`),hlo=l(),F(fk.$$.fragment),ulo=l(),Iq=a("p"),ffo=o("You will then be able to use the auto classes like you would usually do!"),plo=l(),F(ng.$$.fragment),_lo=l(),Pd=a("h2"),sg=a("a"),uhe=a("span"),F(gk.$$.fragment),gfo=l(),phe=a("span"),hfo=o("AutoConfig"),blo=l(),Bo=a("div"),F(hk.$$.fragment),ufo=l(),uk=a("p"),pfo=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),Nq=a("a"),_fo=o("from_pretrained()"),bfo=o(" class method."),vfo=l(),pk=a("p"),Ffo=o("This class cannot be instantiated directly using "),_he=a("code"),Tfo=o("__init__()"),Mfo=o(" (throws an error)."),Efo=l(),Or=a("div"),F(_k.$$.fragment),Cfo=l(),bhe=a("p"),wfo=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),Afo=l(),Bd=a("p"),Lfo=o("The configuration class to instantiate is selected based on the "),vhe=a("code"),yfo=o("model_type"),xfo=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Fhe=a("code"),$fo=o("pretrained_model_name_or_path"),kfo=o(":"),Sfo=l(),A=a("ul"),lg=a("li"),The=a("strong"),Rfo=o("albert"),Pfo=o(" \u2014 "),qq=a("a"),Bfo=o("AlbertConfig"),Ifo=o(" (ALBERT model)"),Nfo=l(),ig=a("li"),Mhe=a("strong"),qfo=o("bart"),Dfo=o(" \u2014 "),Dq=a("a"),jfo=o("BartConfig"),Gfo=o(" (BART model)"),Ofo=l(),dg=a("li"),Ehe=a("strong"),Vfo=o("beit"),Xfo=o(" \u2014 "),jq=a("a"),zfo=o("BeitConfig"),Qfo=o(" (BEiT model)"),Wfo=l(),mg=a("li"),Che=a("strong"),Ufo=o("bert"),Hfo=o(" \u2014 "),Gq=a("a"),Jfo=o("BertConfig"),Yfo=o(" (BERT model)"),Zfo=l(),cg=a("li"),whe=a("strong"),Kfo=o("bert-generation"),ego=o(" \u2014 "),Oq=a("a"),ogo=o("BertGenerationConfig"),rgo=o(" (Bert Generation model)"),tgo=l(),fg=a("li"),Ahe=a("strong"),ago=o("big_bird"),ngo=o(" \u2014 "),Vq=a("a"),sgo=o("BigBirdConfig"),lgo=o(" (BigBird model)"),igo=l(),gg=a("li"),Lhe=a("strong"),dgo=o("bigbird_pegasus"),mgo=o(" \u2014 "),Xq=a("a"),cgo=o("BigBirdPegasusConfig"),fgo=o(" (BigBird-Pegasus model)"),ggo=l(),hg=a("li"),yhe=a("strong"),hgo=o("blenderbot"),ugo=o(" \u2014 "),zq=a("a"),pgo=o("BlenderbotConfig"),_go=o(" (Blenderbot model)"),bgo=l(),ug=a("li"),xhe=a("strong"),vgo=o("blenderbot-small"),Fgo=o(" \u2014 "),Qq=a("a"),Tgo=o("BlenderbotSmallConfig"),Mgo=o(" (BlenderbotSmall model)"),Ego=l(),pg=a("li"),$he=a("strong"),Cgo=o("bloom"),wgo=o(" \u2014 "),Wq=a("a"),Ago=o("BloomConfig"),Lgo=o(" (BLOOM model)"),ygo=l(),_g=a("li"),khe=a("strong"),xgo=o("camembert"),$go=o(" \u2014 "),Uq=a("a"),kgo=o("CamembertConfig"),Sgo=o(" (CamemBERT model)"),Rgo=l(),bg=a("li"),She=a("strong"),Pgo=o("canine"),Bgo=o(" \u2014 "),Hq=a("a"),Igo=o("CanineConfig"),Ngo=o(" (CANINE model)"),qgo=l(),vg=a("li"),Rhe=a("strong"),Dgo=o("clip"),jgo=o(" \u2014 "),Jq=a("a"),Ggo=o("CLIPConfig"),Ogo=o(" (CLIP model)"),Vgo=l(),Fg=a("li"),Phe=a("strong"),Xgo=o("clipseg"),zgo=o(" \u2014 "),Yq=a("a"),Qgo=o("CLIPSegConfig"),Wgo=o(" (CLIPSeg model)"),Ugo=l(),Tg=a("li"),Bhe=a("strong"),Hgo=o("codegen"),Jgo=o(" \u2014 "),Zq=a("a"),Ygo=o("CodeGenConfig"),Zgo=o(" (CodeGen model)"),Kgo=l(),Mg=a("li"),Ihe=a("strong"),eho=o("conditional_detr"),oho=o(" \u2014 "),Kq=a("a"),rho=o("ConditionalDetrConfig"),tho=o(" (Conditional DETR model)"),aho=l(),Eg=a("li"),Nhe=a("strong"),nho=o("convbert"),sho=o(" \u2014 "),eD=a("a"),lho=o("ConvBertConfig"),iho=o(" (ConvBERT model)"),dho=l(),Cg=a("li"),qhe=a("strong"),mho=o("convnext"),cho=o(" \u2014 "),oD=a("a"),fho=o("ConvNextConfig"),gho=o(" (ConvNeXT model)"),hho=l(),wg=a("li"),Dhe=a("strong"),uho=o("ctrl"),pho=o(" \u2014 "),rD=a("a"),_ho=o("CTRLConfig"),bho=o(" (CTRL model)"),vho=l(),Ag=a("li"),jhe=a("strong"),Fho=o("cvt"),Tho=o(" \u2014 "),tD=a("a"),Mho=o("CvtConfig"),Eho=o(" (CvT model)"),Cho=l(),Lg=a("li"),Ghe=a("strong"),who=o("data2vec-audio"),Aho=o(" \u2014 "),aD=a("a"),Lho=o("Data2VecAudioConfig"),yho=o(" (Data2VecAudio model)"),xho=l(),yg=a("li"),Ohe=a("strong"),$ho=o("data2vec-text"),kho=o(" \u2014 "),nD=a("a"),Sho=o("Data2VecTextConfig"),Rho=o(" (Data2VecText model)"),Pho=l(),xg=a("li"),Vhe=a("strong"),Bho=o("data2vec-vision"),Iho=o(" \u2014 "),sD=a("a"),Nho=o("Data2VecVisionConfig"),qho=o(" (Data2VecVision model)"),Dho=l(),$g=a("li"),Xhe=a("strong"),jho=o("deberta"),Gho=o(" \u2014 "),lD=a("a"),Oho=o("DebertaConfig"),Vho=o(" (DeBERTa model)"),Xho=l(),kg=a("li"),zhe=a("strong"),zho=o("deberta-v2"),Qho=o(" \u2014 "),iD=a("a"),Who=o("DebertaV2Config"),Uho=o(" (DeBERTa-v2 model)"),Hho=l(),Sg=a("li"),Qhe=a("strong"),Jho=o("decision_transformer"),Yho=o(" \u2014 "),dD=a("a"),Zho=o("DecisionTransformerConfig"),Kho=o(" (Decision Transformer model)"),euo=l(),Rg=a("li"),Whe=a("strong"),ouo=o("deformable_detr"),ruo=o(" \u2014 "),mD=a("a"),tuo=o("DeformableDetrConfig"),auo=o(" (Deformable DETR model)"),nuo=l(),Pg=a("li"),Uhe=a("strong"),suo=o("deit"),luo=o(" \u2014 "),cD=a("a"),iuo=o("DeiTConfig"),duo=o(" (DeiT model)"),muo=l(),Bg=a("li"),Hhe=a("strong"),cuo=o("detr"),fuo=o(" \u2014 "),fD=a("a"),guo=o("DetrConfig"),huo=o(" (DETR model)"),uuo=l(),Ig=a("li"),Jhe=a("strong"),puo=o("distilbert"),_uo=o(" \u2014 "),gD=a("a"),buo=o("DistilBertConfig"),vuo=o(" (DistilBERT model)"),Fuo=l(),Ng=a("li"),Yhe=a("strong"),Tuo=o("donut-swin"),Muo=o(" \u2014 "),hD=a("a"),Euo=o("DonutSwinConfig"),Cuo=o(" (DonutSwin model)"),wuo=l(),qg=a("li"),Zhe=a("strong"),Auo=o("dpr"),Luo=o(" \u2014 "),uD=a("a"),yuo=o("DPRConfig"),xuo=o(" (DPR model)"),$uo=l(),Dg=a("li"),Khe=a("strong"),kuo=o("dpt"),Suo=o(" \u2014 "),pD=a("a"),Ruo=o("DPTConfig"),Puo=o(" (DPT model)"),Buo=l(),jg=a("li"),eue=a("strong"),Iuo=o("electra"),Nuo=o(" \u2014 "),_D=a("a"),quo=o("ElectraConfig"),Duo=o(" (ELECTRA model)"),juo=l(),Gg=a("li"),oue=a("strong"),Guo=o("encoder-decoder"),Ouo=o(" \u2014 "),bD=a("a"),Vuo=o("EncoderDecoderConfig"),Xuo=o(" (Encoder decoder model)"),zuo=l(),Og=a("li"),rue=a("strong"),Quo=o("ernie"),Wuo=o(" \u2014 "),vD=a("a"),Uuo=o("ErnieConfig"),Huo=o(" (ERNIE model)"),Juo=l(),Vg=a("li"),tue=a("strong"),Yuo=o("esm"),Zuo=o(" \u2014 "),FD=a("a"),Kuo=o("EsmConfig"),epo=o(" (ESM model)"),opo=l(),Xg=a("li"),aue=a("strong"),rpo=o("flaubert"),tpo=o(" \u2014 "),TD=a("a"),apo=o("FlaubertConfig"),npo=o(" (FlauBERT model)"),spo=l(),zg=a("li"),nue=a("strong"),lpo=o("flava"),ipo=o(" \u2014 "),MD=a("a"),dpo=o("FlavaConfig"),mpo=o(" (FLAVA model)"),cpo=l(),Qg=a("li"),sue=a("strong"),fpo=o("fnet"),gpo=o(" \u2014 "),ED=a("a"),hpo=o("FNetConfig"),upo=o(" (FNet model)"),ppo=l(),Wg=a("li"),lue=a("strong"),_po=o("fsmt"),bpo=o(" \u2014 "),CD=a("a"),vpo=o("FSMTConfig"),Fpo=o(" (FairSeq Machine-Translation model)"),Tpo=l(),Ug=a("li"),iue=a("strong"),Mpo=o("funnel"),Epo=o(" \u2014 "),wD=a("a"),Cpo=o("FunnelConfig"),wpo=o(" (Funnel Transformer model)"),Apo=l(),Hg=a("li"),due=a("strong"),Lpo=o("glpn"),ypo=o(" \u2014 "),AD=a("a"),xpo=o("GLPNConfig"),$po=o(" (GLPN model)"),kpo=l(),Jg=a("li"),mue=a("strong"),Spo=o("gpt2"),Rpo=o(" \u2014 "),LD=a("a"),Ppo=o("GPT2Config"),Bpo=o(" (OpenAI GPT-2 model)"),Ipo=l(),Yg=a("li"),cue=a("strong"),Npo=o("gpt_neo"),qpo=o(" \u2014 "),yD=a("a"),Dpo=o("GPTNeoConfig"),jpo=o(" (GPT Neo model)"),Gpo=l(),Zg=a("li"),fue=a("strong"),Opo=o("gpt_neox"),Vpo=o(" \u2014 "),xD=a("a"),Xpo=o("GPTNeoXConfig"),zpo=o(" (GPT NeoX model)"),Qpo=l(),Kg=a("li"),gue=a("strong"),Wpo=o("gpt_neox_japanese"),Upo=o(" \u2014 "),$D=a("a"),Hpo=o("GPTNeoXJapaneseConfig"),Jpo=o(" (GPT NeoX Japanese model)"),Ypo=l(),eh=a("li"),hue=a("strong"),Zpo=o("gptj"),Kpo=o(" \u2014 "),kD=a("a"),e_o=o("GPTJConfig"),o_o=o(" (GPT-J model)"),r_o=l(),oh=a("li"),uue=a("strong"),t_o=o("groupvit"),a_o=o(" \u2014 "),SD=a("a"),n_o=o("GroupViTConfig"),s_o=o(" (GroupViT model)"),l_o=l(),rh=a("li"),pue=a("strong"),i_o=o("hubert"),d_o=o(" \u2014 "),RD=a("a"),m_o=o("HubertConfig"),c_o=o(" (Hubert model)"),f_o=l(),th=a("li"),_ue=a("strong"),g_o=o("ibert"),h_o=o(" \u2014 "),PD=a("a"),u_o=o("IBertConfig"),p_o=o(" (I-BERT model)"),__o=l(),ah=a("li"),bue=a("strong"),b_o=o("imagegpt"),v_o=o(" \u2014 "),BD=a("a"),F_o=o("ImageGPTConfig"),T_o=o(" (ImageGPT model)"),M_o=l(),nh=a("li"),vue=a("strong"),E_o=o("layoutlm"),C_o=o(" \u2014 "),ID=a("a"),w_o=o("LayoutLMConfig"),A_o=o(" (LayoutLM model)"),L_o=l(),sh=a("li"),Fue=a("strong"),y_o=o("layoutlmv2"),x_o=o(" \u2014 "),ND=a("a"),$_o=o("LayoutLMv2Config"),k_o=o(" (LayoutLMv2 model)"),S_o=l(),lh=a("li"),Tue=a("strong"),R_o=o("layoutlmv3"),P_o=o(" \u2014 "),qD=a("a"),B_o=o("LayoutLMv3Config"),I_o=o(" (LayoutLMv3 model)"),N_o=l(),ih=a("li"),Mue=a("strong"),q_o=o("led"),D_o=o(" \u2014 "),DD=a("a"),j_o=o("LEDConfig"),G_o=o(" (LED model)"),O_o=l(),dh=a("li"),Eue=a("strong"),V_o=o("levit"),X_o=o(" \u2014 "),jD=a("a"),z_o=o("LevitConfig"),Q_o=o(" (LeViT model)"),W_o=l(),mh=a("li"),Cue=a("strong"),U_o=o("lilt"),H_o=o(" \u2014 "),GD=a("a"),J_o=o("LiltConfig"),Y_o=o(" (LiLT model)"),Z_o=l(),ch=a("li"),wue=a("strong"),K_o=o("longformer"),e1o=o(" \u2014 "),OD=a("a"),o1o=o("LongformerConfig"),r1o=o(" (Longformer model)"),t1o=l(),fh=a("li"),Aue=a("strong"),a1o=o("longt5"),n1o=o(" \u2014 "),VD=a("a"),s1o=o("LongT5Config"),l1o=o(" (LongT5 model)"),i1o=l(),gh=a("li"),Lue=a("strong"),d1o=o("luke"),m1o=o(" \u2014 "),XD=a("a"),c1o=o("LukeConfig"),f1o=o(" (LUKE model)"),g1o=l(),hh=a("li"),yue=a("strong"),h1o=o("lxmert"),u1o=o(" \u2014 "),zD=a("a"),p1o=o("LxmertConfig"),_1o=o(" (LXMERT model)"),b1o=l(),uh=a("li"),xue=a("strong"),v1o=o("m2m_100"),F1o=o(" \u2014 "),QD=a("a"),T1o=o("M2M100Config"),M1o=o(" (M2M100 model)"),E1o=l(),ph=a("li"),$ue=a("strong"),C1o=o("marian"),w1o=o(" \u2014 "),WD=a("a"),A1o=o("MarianConfig"),L1o=o(" (Marian model)"),y1o=l(),_h=a("li"),kue=a("strong"),x1o=o("markuplm"),$1o=o(" \u2014 "),UD=a("a"),k1o=o("MarkupLMConfig"),S1o=o(" (MarkupLM model)"),R1o=l(),bh=a("li"),Sue=a("strong"),P1o=o("maskformer"),B1o=o(" \u2014 "),HD=a("a"),I1o=o("MaskFormerConfig"),N1o=o(" (MaskFormer model)"),q1o=l(),vh=a("li"),Rue=a("strong"),D1o=o("mbart"),j1o=o(" \u2014 "),JD=a("a"),G1o=o("MBartConfig"),O1o=o(" (mBART model)"),V1o=l(),Fh=a("li"),Pue=a("strong"),X1o=o("mctct"),z1o=o(" \u2014 "),YD=a("a"),Q1o=o("MCTCTConfig"),W1o=o(" (M-CTC-T model)"),U1o=l(),Th=a("li"),Bue=a("strong"),H1o=o("megatron-bert"),J1o=o(" \u2014 "),ZD=a("a"),Y1o=o("MegatronBertConfig"),Z1o=o(" (Megatron-BERT model)"),K1o=l(),Mh=a("li"),Iue=a("strong"),e2o=o("mobilebert"),o2o=o(" \u2014 "),KD=a("a"),r2o=o("MobileBertConfig"),t2o=o(" (MobileBERT model)"),a2o=l(),Eh=a("li"),Nue=a("strong"),n2o=o("mobilevit"),s2o=o(" \u2014 "),ej=a("a"),l2o=o("MobileViTConfig"),i2o=o(" (MobileViT model)"),d2o=l(),Ch=a("li"),que=a("strong"),m2o=o("mpnet"),c2o=o(" \u2014 "),oj=a("a"),f2o=o("MPNetConfig"),g2o=o(" (MPNet model)"),h2o=l(),wh=a("li"),Due=a("strong"),u2o=o("mt5"),p2o=o(" \u2014 "),rj=a("a"),_2o=o("MT5Config"),b2o=o(" (MT5 model)"),v2o=l(),Ah=a("li"),jue=a("strong"),F2o=o("mvp"),T2o=o(" \u2014 "),tj=a("a"),M2o=o("MvpConfig"),E2o=o(" (MVP model)"),C2o=l(),Lh=a("li"),Gue=a("strong"),w2o=o("nezha"),A2o=o(" \u2014 "),aj=a("a"),L2o=o("NezhaConfig"),y2o=o(" (Nezha model)"),x2o=l(),yh=a("li"),Oue=a("strong"),$2o=o("nystromformer"),k2o=o(" \u2014 "),nj=a("a"),S2o=o("NystromformerConfig"),R2o=o(" (Nystr\xF6mformer model)"),P2o=l(),xh=a("li"),Vue=a("strong"),B2o=o("openai-gpt"),I2o=o(" \u2014 "),sj=a("a"),N2o=o("OpenAIGPTConfig"),q2o=o(" (OpenAI GPT model)"),D2o=l(),$h=a("li"),Xue=a("strong"),j2o=o("opt"),G2o=o(" \u2014 "),lj=a("a"),O2o=o("OPTConfig"),V2o=o(" (OPT model)"),X2o=l(),kh=a("li"),zue=a("strong"),z2o=o("owlvit"),Q2o=o(" \u2014 "),ij=a("a"),W2o=o("OwlViTConfig"),U2o=o(" (OWL-ViT model)"),H2o=l(),Sh=a("li"),Que=a("strong"),J2o=o("pegasus"),Y2o=o(" \u2014 "),dj=a("a"),Z2o=o("PegasusConfig"),K2o=o(" (Pegasus model)"),ebo=l(),Rh=a("li"),Wue=a("strong"),obo=o("pegasus_x"),rbo=o(" \u2014 "),mj=a("a"),tbo=o("PegasusXConfig"),abo=o(" (PEGASUS-X model)"),nbo=l(),Ph=a("li"),Uue=a("strong"),sbo=o("perceiver"),lbo=o(" \u2014 "),cj=a("a"),ibo=o("PerceiverConfig"),dbo=o(" (Perceiver model)"),mbo=l(),Bh=a("li"),Hue=a("strong"),cbo=o("plbart"),fbo=o(" \u2014 "),fj=a("a"),gbo=o("PLBartConfig"),hbo=o(" (PLBart model)"),ubo=l(),Ih=a("li"),Jue=a("strong"),pbo=o("poolformer"),_bo=o(" \u2014 "),gj=a("a"),bbo=o("PoolFormerConfig"),vbo=o(" (PoolFormer model)"),Fbo=l(),Nh=a("li"),Yue=a("strong"),Tbo=o("prophetnet"),Mbo=o(" \u2014 "),hj=a("a"),Ebo=o("ProphetNetConfig"),Cbo=o(" (ProphetNet model)"),wbo=l(),qh=a("li"),Zue=a("strong"),Abo=o("qdqbert"),Lbo=o(" \u2014 "),uj=a("a"),ybo=o("QDQBertConfig"),xbo=o(" (QDQBert model)"),$bo=l(),Dh=a("li"),Kue=a("strong"),kbo=o("rag"),Sbo=o(" \u2014 "),pj=a("a"),Rbo=o("RagConfig"),Pbo=o(" (RAG model)"),Bbo=l(),jh=a("li"),epe=a("strong"),Ibo=o("realm"),Nbo=o(" \u2014 "),_j=a("a"),qbo=o("RealmConfig"),Dbo=o(" (REALM model)"),jbo=l(),Gh=a("li"),ope=a("strong"),Gbo=o("reformer"),Obo=o(" \u2014 "),bj=a("a"),Vbo=o("ReformerConfig"),Xbo=o(" (Reformer model)"),zbo=l(),Oh=a("li"),rpe=a("strong"),Qbo=o("regnet"),Wbo=o(" \u2014 "),vj=a("a"),Ubo=o("RegNetConfig"),Hbo=o(" (RegNet model)"),Jbo=l(),Vh=a("li"),tpe=a("strong"),Ybo=o("rembert"),Zbo=o(" \u2014 "),Fj=a("a"),Kbo=o("RemBertConfig"),evo=o(" (RemBERT model)"),ovo=l(),Xh=a("li"),ape=a("strong"),rvo=o("resnet"),tvo=o(" \u2014 "),Tj=a("a"),avo=o("ResNetConfig"),nvo=o(" (ResNet model)"),svo=l(),zh=a("li"),npe=a("strong"),lvo=o("retribert"),ivo=o(" \u2014 "),Mj=a("a"),dvo=o("RetriBertConfig"),mvo=o(" (RetriBERT model)"),cvo=l(),Qh=a("li"),spe=a("strong"),fvo=o("roberta"),gvo=o(" \u2014 "),Ej=a("a"),hvo=o("RobertaConfig"),uvo=o(" (RoBERTa model)"),pvo=l(),Wh=a("li"),lpe=a("strong"),_vo=o("roc_bert"),bvo=o(" \u2014 "),Cj=a("a"),vvo=o("RoCBertConfig"),Fvo=o(" (RoCBert model)"),Tvo=l(),Uh=a("li"),ipe=a("strong"),Mvo=o("roformer"),Evo=o(" \u2014 "),wj=a("a"),Cvo=o("RoFormerConfig"),wvo=o(" (RoFormer model)"),Avo=l(),Hh=a("li"),dpe=a("strong"),Lvo=o("segformer"),yvo=o(" \u2014 "),Aj=a("a"),xvo=o("SegformerConfig"),$vo=o(" (SegFormer model)"),kvo=l(),Jh=a("li"),mpe=a("strong"),Svo=o("sew"),Rvo=o(" \u2014 "),Lj=a("a"),Pvo=o("SEWConfig"),Bvo=o(" (SEW model)"),Ivo=l(),Yh=a("li"),cpe=a("strong"),Nvo=o("sew-d"),qvo=o(" \u2014 "),yj=a("a"),Dvo=o("SEWDConfig"),jvo=o(" (SEW-D model)"),Gvo=l(),Zh=a("li"),fpe=a("strong"),Ovo=o("speech-encoder-decoder"),Vvo=o(" \u2014 "),xj=a("a"),Xvo=o("SpeechEncoderDecoderConfig"),zvo=o(" (Speech Encoder decoder model)"),Qvo=l(),Kh=a("li"),gpe=a("strong"),Wvo=o("speech_to_text"),Uvo=o(" \u2014 "),$j=a("a"),Hvo=o("Speech2TextConfig"),Jvo=o(" (Speech2Text model)"),Yvo=l(),eu=a("li"),hpe=a("strong"),Zvo=o("speech_to_text_2"),Kvo=o(" \u2014 "),kj=a("a"),eFo=o("Speech2Text2Config"),oFo=o(" (Speech2Text2 model)"),rFo=l(),ou=a("li"),upe=a("strong"),tFo=o("splinter"),aFo=o(" \u2014 "),Sj=a("a"),nFo=o("SplinterConfig"),sFo=o(" (Splinter model)"),lFo=l(),ru=a("li"),ppe=a("strong"),iFo=o("squeezebert"),dFo=o(" \u2014 "),Rj=a("a"),mFo=o("SqueezeBertConfig"),cFo=o(" (SqueezeBERT model)"),fFo=l(),tu=a("li"),_pe=a("strong"),gFo=o("swin"),hFo=o(" \u2014 "),Pj=a("a"),uFo=o("SwinConfig"),pFo=o(" (Swin Transformer model)"),_Fo=l(),au=a("li"),bpe=a("strong"),bFo=o("swinv2"),vFo=o(" \u2014 "),Bj=a("a"),FFo=o("Swinv2Config"),TFo=o(" (Swin Transformer V2 model)"),MFo=l(),nu=a("li"),vpe=a("strong"),EFo=o("t5"),CFo=o(" \u2014 "),Ij=a("a"),wFo=o("T5Config"),AFo=o(" (T5 model)"),LFo=l(),su=a("li"),Fpe=a("strong"),yFo=o("table-transformer"),xFo=o(" \u2014 "),Nj=a("a"),$Fo=o("TableTransformerConfig"),kFo=o(" (Table Transformer model)"),SFo=l(),lu=a("li"),Tpe=a("strong"),RFo=o("tapas"),PFo=o(" \u2014 "),qj=a("a"),BFo=o("TapasConfig"),IFo=o(" (TAPAS model)"),NFo=l(),iu=a("li"),Mpe=a("strong"),qFo=o("time_series_transformer"),DFo=o(" \u2014 "),Dj=a("a"),jFo=o("TimeSeriesTransformerConfig"),GFo=o(" (Time Series Transformer model)"),OFo=l(),du=a("li"),Epe=a("strong"),VFo=o("trajectory_transformer"),XFo=o(" \u2014 "),jj=a("a"),zFo=o("TrajectoryTransformerConfig"),QFo=o(" (Trajectory Transformer model)"),WFo=l(),mu=a("li"),Cpe=a("strong"),UFo=o("transfo-xl"),HFo=o(" \u2014 "),Gj=a("a"),JFo=o("TransfoXLConfig"),YFo=o(" (Transformer-XL model)"),ZFo=l(),cu=a("li"),wpe=a("strong"),KFo=o("trocr"),eTo=o(" \u2014 "),Oj=a("a"),oTo=o("TrOCRConfig"),rTo=o(" (TrOCR model)"),tTo=l(),fu=a("li"),Ape=a("strong"),aTo=o("unispeech"),nTo=o(" \u2014 "),Vj=a("a"),sTo=o("UniSpeechConfig"),lTo=o(" (UniSpeech model)"),iTo=l(),gu=a("li"),Lpe=a("strong"),dTo=o("unispeech-sat"),mTo=o(" \u2014 "),Xj=a("a"),cTo=o("UniSpeechSatConfig"),fTo=o(" (UniSpeechSat model)"),gTo=l(),hu=a("li"),ype=a("strong"),hTo=o("van"),uTo=o(" \u2014 "),zj=a("a"),pTo=o("VanConfig"),_To=o(" (VAN model)"),bTo=l(),uu=a("li"),xpe=a("strong"),vTo=o("videomae"),FTo=o(" \u2014 "),Qj=a("a"),TTo=o("VideoMAEConfig"),MTo=o(" (VideoMAE model)"),ETo=l(),pu=a("li"),$pe=a("strong"),CTo=o("vilt"),wTo=o(" \u2014 "),Wj=a("a"),ATo=o("ViltConfig"),LTo=o(" (ViLT model)"),yTo=l(),_u=a("li"),kpe=a("strong"),xTo=o("vision-encoder-decoder"),$To=o(" \u2014 "),Uj=a("a"),kTo=o("VisionEncoderDecoderConfig"),STo=o(" (Vision Encoder decoder model)"),RTo=l(),bu=a("li"),Spe=a("strong"),PTo=o("vision-text-dual-encoder"),BTo=o(" \u2014 "),Hj=a("a"),ITo=o("VisionTextDualEncoderConfig"),NTo=o(" (VisionTextDualEncoder model)"),qTo=l(),vu=a("li"),Rpe=a("strong"),DTo=o("visual_bert"),jTo=o(" \u2014 "),Jj=a("a"),GTo=o("VisualBertConfig"),OTo=o(" (VisualBERT model)"),VTo=l(),Fu=a("li"),Ppe=a("strong"),XTo=o("vit"),zTo=o(" \u2014 "),Yj=a("a"),QTo=o("ViTConfig"),WTo=o(" (ViT model)"),UTo=l(),Tu=a("li"),Bpe=a("strong"),HTo=o("vit_mae"),JTo=o(" \u2014 "),Zj=a("a"),YTo=o("ViTMAEConfig"),ZTo=o(" (ViTMAE model)"),KTo=l(),Mu=a("li"),Ipe=a("strong"),eMo=o("vit_msn"),oMo=o(" \u2014 "),Kj=a("a"),rMo=o("ViTMSNConfig"),tMo=o(" (ViTMSN model)"),aMo=l(),Eu=a("li"),Npe=a("strong"),nMo=o("wav2vec2"),sMo=o(" \u2014 "),eG=a("a"),lMo=o("Wav2Vec2Config"),iMo=o(" (Wav2Vec2 model)"),dMo=l(),Cu=a("li"),qpe=a("strong"),mMo=o("wav2vec2-conformer"),cMo=o(" \u2014 "),oG=a("a"),fMo=o("Wav2Vec2ConformerConfig"),gMo=o(" (Wav2Vec2-Conformer model)"),hMo=l(),wu=a("li"),Dpe=a("strong"),uMo=o("wavlm"),pMo=o(" \u2014 "),rG=a("a"),_Mo=o("WavLMConfig"),bMo=o(" (WavLM model)"),vMo=l(),Au=a("li"),jpe=a("strong"),FMo=o("whisper"),TMo=o(" \u2014 "),tG=a("a"),MMo=o("WhisperConfig"),EMo=o(" (Whisper model)"),CMo=l(),Lu=a("li"),Gpe=a("strong"),wMo=o("xclip"),AMo=o(" \u2014 "),aG=a("a"),LMo=o("XCLIPConfig"),yMo=o(" (X-CLIP model)"),xMo=l(),yu=a("li"),Ope=a("strong"),$Mo=o("xglm"),kMo=o(" \u2014 "),nG=a("a"),SMo=o("XGLMConfig"),RMo=o(" (XGLM model)"),PMo=l(),xu=a("li"),Vpe=a("strong"),BMo=o("xlm"),IMo=o(" \u2014 "),sG=a("a"),NMo=o("XLMConfig"),qMo=o(" (XLM model)"),DMo=l(),$u=a("li"),Xpe=a("strong"),jMo=o("xlm-prophetnet"),GMo=o(" \u2014 "),lG=a("a"),OMo=o("XLMProphetNetConfig"),VMo=o(" (XLM-ProphetNet model)"),XMo=l(),ku=a("li"),zpe=a("strong"),zMo=o("xlm-roberta"),QMo=o(" \u2014 "),iG=a("a"),WMo=o("XLMRobertaConfig"),UMo=o(" (XLM-RoBERTa model)"),HMo=l(),Su=a("li"),Qpe=a("strong"),JMo=o("xlm-roberta-xl"),YMo=o(" \u2014 "),dG=a("a"),ZMo=o("XLMRobertaXLConfig"),KMo=o(" (XLM-RoBERTa-XL model)"),eEo=l(),Ru=a("li"),Wpe=a("strong"),oEo=o("xlnet"),rEo=o(" \u2014 "),mG=a("a"),tEo=o("XLNetConfig"),aEo=o(" (XLNet model)"),nEo=l(),Pu=a("li"),Upe=a("strong"),sEo=o("yolos"),lEo=o(" \u2014 "),cG=a("a"),iEo=o("YolosConfig"),dEo=o(" (YOLOS model)"),mEo=l(),Bu=a("li"),Hpe=a("strong"),cEo=o("yoso"),fEo=o(" \u2014 "),fG=a("a"),gEo=o("YosoConfig"),hEo=o(" (YOSO model)"),uEo=l(),F(Iu.$$.fragment),pEo=l(),Nu=a("div"),F(bk.$$.fragment),_Eo=l(),Jpe=a("p"),bEo=o("Register a new configuration for this class."),vlo=l(),Id=a("h2"),qu=a("a"),Ype=a("span"),F(vk.$$.fragment),vEo=l(),Zpe=a("span"),FEo=o("AutoTokenizer"),Flo=l(),Io=a("div"),F(Fk.$$.fragment),TEo=l(),Tk=a("p"),MEo=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),gG=a("a"),EEo=o("AutoTokenizer.from_pretrained()"),CEo=o(" class method."),wEo=l(),Mk=a("p"),AEo=o("This class cannot be instantiated directly using "),Kpe=a("code"),LEo=o("__init__()"),yEo=o(" (throws an error)."),xEo=l(),Vr=a("div"),F(Ek.$$.fragment),$Eo=l(),e_e=a("p"),kEo=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),SEo=l(),dn=a("p"),REo=o("The tokenizer class to instantiate is selected based on the "),o_e=a("code"),PEo=o("model_type"),BEo=o(` property of the config object (either
passed as an argument or loaded from `),r_e=a("code"),IEo=o("pretrained_model_name_or_path"),NEo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t_e=a("code"),qEo=o("pretrained_model_name_or_path"),DEo=o(":"),jEo=l(),k=a("ul"),Ts=a("li"),a_e=a("strong"),GEo=o("albert"),OEo=o(" \u2014 "),hG=a("a"),VEo=o("AlbertTokenizer"),XEo=o(" or "),uG=a("a"),zEo=o("AlbertTokenizerFast"),QEo=o(" (ALBERT model)"),WEo=l(),Ms=a("li"),n_e=a("strong"),UEo=o("bart"),HEo=o(" \u2014 "),pG=a("a"),JEo=o("BartTokenizer"),YEo=o(" or "),_G=a("a"),ZEo=o("BartTokenizerFast"),KEo=o(" (BART model)"),e4o=l(),Es=a("li"),s_e=a("strong"),o4o=o("barthez"),r4o=o(" \u2014 "),bG=a("a"),t4o=o("BarthezTokenizer"),a4o=o(" or "),vG=a("a"),n4o=o("BarthezTokenizerFast"),s4o=o(" (BARThez model)"),l4o=l(),Du=a("li"),l_e=a("strong"),i4o=o("bartpho"),d4o=o(" \u2014 "),FG=a("a"),m4o=o("BartphoTokenizer"),c4o=o(" (BARTpho model)"),f4o=l(),Cs=a("li"),i_e=a("strong"),g4o=o("bert"),h4o=o(" \u2014 "),TG=a("a"),u4o=o("BertTokenizer"),p4o=o(" or "),MG=a("a"),_4o=o("BertTokenizerFast"),b4o=o(" (BERT model)"),v4o=l(),ju=a("li"),d_e=a("strong"),F4o=o("bert-generation"),T4o=o(" \u2014 "),EG=a("a"),M4o=o("BertGenerationTokenizer"),E4o=o(" (Bert Generation model)"),C4o=l(),Gu=a("li"),m_e=a("strong"),w4o=o("bert-japanese"),A4o=o(" \u2014 "),CG=a("a"),L4o=o("BertJapaneseTokenizer"),y4o=o(" (BertJapanese model)"),x4o=l(),Ou=a("li"),c_e=a("strong"),$4o=o("bertweet"),k4o=o(" \u2014 "),wG=a("a"),S4o=o("BertweetTokenizer"),R4o=o(" (BERTweet model)"),P4o=l(),ws=a("li"),f_e=a("strong"),B4o=o("big_bird"),I4o=o(" \u2014 "),AG=a("a"),N4o=o("BigBirdTokenizer"),q4o=o(" or "),LG=a("a"),D4o=o("BigBirdTokenizerFast"),j4o=o(" (BigBird model)"),G4o=l(),As=a("li"),g_e=a("strong"),O4o=o("bigbird_pegasus"),V4o=o(" \u2014 "),yG=a("a"),X4o=o("PegasusTokenizer"),z4o=o(" or "),xG=a("a"),Q4o=o("PegasusTokenizerFast"),W4o=o(" (BigBird-Pegasus model)"),U4o=l(),Ls=a("li"),h_e=a("strong"),H4o=o("blenderbot"),J4o=o(" \u2014 "),$G=a("a"),Y4o=o("BlenderbotTokenizer"),Z4o=o(" or "),kG=a("a"),K4o=o("BlenderbotTokenizerFast"),eCo=o(" (Blenderbot model)"),oCo=l(),Vu=a("li"),u_e=a("strong"),rCo=o("blenderbot-small"),tCo=o(" \u2014 "),SG=a("a"),aCo=o("BlenderbotSmallTokenizer"),nCo=o(" (BlenderbotSmall model)"),sCo=l(),Xu=a("li"),p_e=a("strong"),lCo=o("bloom"),iCo=o(" \u2014 "),RG=a("a"),dCo=o("BloomTokenizerFast"),mCo=o(" (BLOOM model)"),cCo=l(),zu=a("li"),__e=a("strong"),fCo=o("byt5"),gCo=o(" \u2014 "),PG=a("a"),hCo=o("ByT5Tokenizer"),uCo=o(" (ByT5 model)"),pCo=l(),ys=a("li"),b_e=a("strong"),_Co=o("camembert"),bCo=o(" \u2014 "),BG=a("a"),vCo=o("CamembertTokenizer"),FCo=o(" or "),IG=a("a"),TCo=o("CamembertTokenizerFast"),MCo=o(" (CamemBERT model)"),ECo=l(),Qu=a("li"),v_e=a("strong"),CCo=o("canine"),wCo=o(" \u2014 "),NG=a("a"),ACo=o("CanineTokenizer"),LCo=o(" (CANINE model)"),yCo=l(),xs=a("li"),F_e=a("strong"),xCo=o("clip"),$Co=o(" \u2014 "),qG=a("a"),kCo=o("CLIPTokenizer"),SCo=o(" or "),DG=a("a"),RCo=o("CLIPTokenizerFast"),PCo=o(" (CLIP model)"),BCo=l(),$s=a("li"),T_e=a("strong"),ICo=o("clipseg"),NCo=o(" \u2014 "),jG=a("a"),qCo=o("CLIPTokenizer"),DCo=o(" or "),GG=a("a"),jCo=o("CLIPTokenizerFast"),GCo=o(" (CLIPSeg model)"),OCo=l(),ks=a("li"),M_e=a("strong"),VCo=o("codegen"),XCo=o(" \u2014 "),OG=a("a"),zCo=o("CodeGenTokenizer"),QCo=o(" or "),VG=a("a"),WCo=o("CodeGenTokenizerFast"),UCo=o(" (CodeGen model)"),HCo=l(),Ss=a("li"),E_e=a("strong"),JCo=o("convbert"),YCo=o(" \u2014 "),XG=a("a"),ZCo=o("ConvBertTokenizer"),KCo=o(" or "),zG=a("a"),e3o=o("ConvBertTokenizerFast"),o3o=o(" (ConvBERT model)"),r3o=l(),Rs=a("li"),C_e=a("strong"),t3o=o("cpm"),a3o=o(" \u2014 "),QG=a("a"),n3o=o("CpmTokenizer"),s3o=o(" or "),WG=a("a"),l3o=o("CpmTokenizerFast"),i3o=o(" (CPM model)"),d3o=l(),Wu=a("li"),w_e=a("strong"),m3o=o("ctrl"),c3o=o(" \u2014 "),UG=a("a"),f3o=o("CTRLTokenizer"),g3o=o(" (CTRL model)"),h3o=l(),Ps=a("li"),A_e=a("strong"),u3o=o("data2vec-text"),p3o=o(" \u2014 "),HG=a("a"),_3o=o("RobertaTokenizer"),b3o=o(" or "),JG=a("a"),v3o=o("RobertaTokenizerFast"),F3o=o(" (Data2VecText model)"),T3o=l(),Bs=a("li"),L_e=a("strong"),M3o=o("deberta"),E3o=o(" \u2014 "),YG=a("a"),C3o=o("DebertaTokenizer"),w3o=o(" or "),ZG=a("a"),A3o=o("DebertaTokenizerFast"),L3o=o(" (DeBERTa model)"),y3o=l(),Is=a("li"),y_e=a("strong"),x3o=o("deberta-v2"),$3o=o(" \u2014 "),KG=a("a"),k3o=o("DebertaV2Tokenizer"),S3o=o(" or "),eO=a("a"),R3o=o("DebertaV2TokenizerFast"),P3o=o(" (DeBERTa-v2 model)"),B3o=l(),Ns=a("li"),x_e=a("strong"),I3o=o("distilbert"),N3o=o(" \u2014 "),oO=a("a"),q3o=o("DistilBertTokenizer"),D3o=o(" or "),rO=a("a"),j3o=o("DistilBertTokenizerFast"),G3o=o(" (DistilBERT model)"),O3o=l(),qs=a("li"),$_e=a("strong"),V3o=o("dpr"),X3o=o(" \u2014 "),tO=a("a"),z3o=o("DPRQuestionEncoderTokenizer"),Q3o=o(" or "),aO=a("a"),W3o=o("DPRQuestionEncoderTokenizerFast"),U3o=o(" (DPR model)"),H3o=l(),Ds=a("li"),k_e=a("strong"),J3o=o("electra"),Y3o=o(" \u2014 "),nO=a("a"),Z3o=o("ElectraTokenizer"),K3o=o(" or "),sO=a("a"),e5o=o("ElectraTokenizerFast"),o5o=o(" (ELECTRA model)"),r5o=l(),js=a("li"),S_e=a("strong"),t5o=o("ernie"),a5o=o(" \u2014 "),lO=a("a"),n5o=o("BertTokenizer"),s5o=o(" or "),iO=a("a"),l5o=o("BertTokenizerFast"),i5o=o(" (ERNIE model)"),d5o=l(),Uu=a("li"),R_e=a("strong"),m5o=o("esm"),c5o=o(" \u2014 "),dO=a("a"),f5o=o("EsmTokenizer"),g5o=o(" (ESM model)"),h5o=l(),Hu=a("li"),P_e=a("strong"),u5o=o("flaubert"),p5o=o(" \u2014 "),mO=a("a"),_5o=o("FlaubertTokenizer"),b5o=o(" (FlauBERT model)"),v5o=l(),Gs=a("li"),B_e=a("strong"),F5o=o("fnet"),T5o=o(" \u2014 "),cO=a("a"),M5o=o("FNetTokenizer"),E5o=o(" or "),fO=a("a"),C5o=o("FNetTokenizerFast"),w5o=o(" (FNet model)"),A5o=l(),Ju=a("li"),I_e=a("strong"),L5o=o("fsmt"),y5o=o(" \u2014 "),gO=a("a"),x5o=o("FSMTTokenizer"),$5o=o(" (FairSeq Machine-Translation model)"),k5o=l(),Os=a("li"),N_e=a("strong"),S5o=o("funnel"),R5o=o(" \u2014 "),hO=a("a"),P5o=o("FunnelTokenizer"),B5o=o(" or "),uO=a("a"),I5o=o("FunnelTokenizerFast"),N5o=o(" (Funnel Transformer model)"),q5o=l(),Vs=a("li"),q_e=a("strong"),D5o=o("gpt2"),j5o=o(" \u2014 "),pO=a("a"),G5o=o("GPT2Tokenizer"),O5o=o(" or "),_O=a("a"),V5o=o("GPT2TokenizerFast"),X5o=o(" (OpenAI GPT-2 model)"),z5o=l(),Xs=a("li"),D_e=a("strong"),Q5o=o("gpt_neo"),W5o=o(" \u2014 "),bO=a("a"),U5o=o("GPT2Tokenizer"),H5o=o(" or "),vO=a("a"),J5o=o("GPT2TokenizerFast"),Y5o=o(" (GPT Neo model)"),Z5o=l(),Yu=a("li"),j_e=a("strong"),K5o=o("gpt_neox"),e0o=o(" \u2014 "),FO=a("a"),o0o=o("GPTNeoXTokenizerFast"),r0o=o(" (GPT NeoX model)"),t0o=l(),Zu=a("li"),G_e=a("strong"),a0o=o("gpt_neox_japanese"),n0o=o(" \u2014 "),TO=a("a"),s0o=o("GPTNeoXJapaneseTokenizer"),l0o=o(" (GPT NeoX Japanese model)"),i0o=l(),zs=a("li"),O_e=a("strong"),d0o=o("gptj"),m0o=o(" \u2014 "),MO=a("a"),c0o=o("GPT2Tokenizer"),f0o=o(" or "),EO=a("a"),g0o=o("GPT2TokenizerFast"),h0o=o(" (GPT-J model)"),u0o=l(),Qs=a("li"),V_e=a("strong"),p0o=o("groupvit"),_0o=o(" \u2014 "),CO=a("a"),b0o=o("CLIPTokenizer"),v0o=o(" or "),wO=a("a"),F0o=o("CLIPTokenizerFast"),T0o=o(" (GroupViT model)"),M0o=l(),Ws=a("li"),X_e=a("strong"),E0o=o("herbert"),C0o=o(" \u2014 "),AO=a("a"),w0o=o("HerbertTokenizer"),A0o=o(" or "),LO=a("a"),L0o=o("HerbertTokenizerFast"),y0o=o(" (HerBERT model)"),x0o=l(),Ku=a("li"),z_e=a("strong"),$0o=o("hubert"),k0o=o(" \u2014 "),yO=a("a"),S0o=o("Wav2Vec2CTCTokenizer"),R0o=o(" (Hubert model)"),P0o=l(),Us=a("li"),Q_e=a("strong"),B0o=o("ibert"),I0o=o(" \u2014 "),xO=a("a"),N0o=o("RobertaTokenizer"),q0o=o(" or "),$O=a("a"),D0o=o("RobertaTokenizerFast"),j0o=o(" (I-BERT model)"),G0o=l(),Hs=a("li"),W_e=a("strong"),O0o=o("layoutlm"),V0o=o(" \u2014 "),kO=a("a"),X0o=o("LayoutLMTokenizer"),z0o=o(" or "),SO=a("a"),Q0o=o("LayoutLMTokenizerFast"),W0o=o(" (LayoutLM model)"),U0o=l(),Js=a("li"),U_e=a("strong"),H0o=o("layoutlmv2"),J0o=o(" \u2014 "),RO=a("a"),Y0o=o("LayoutLMv2Tokenizer"),Z0o=o(" or "),PO=a("a"),K0o=o("LayoutLMv2TokenizerFast"),ewo=o(" (LayoutLMv2 model)"),owo=l(),Ys=a("li"),H_e=a("strong"),rwo=o("layoutlmv3"),two=o(" \u2014 "),BO=a("a"),awo=o("LayoutLMv3Tokenizer"),nwo=o(" or "),IO=a("a"),swo=o("LayoutLMv3TokenizerFast"),lwo=o(" (LayoutLMv3 model)"),iwo=l(),Zs=a("li"),J_e=a("strong"),dwo=o("layoutxlm"),mwo=o(" \u2014 "),NO=a("a"),cwo=o("LayoutXLMTokenizer"),fwo=o(" or "),qO=a("a"),gwo=o("LayoutXLMTokenizerFast"),hwo=o(" (LayoutXLM model)"),uwo=l(),Ks=a("li"),Y_e=a("strong"),pwo=o("led"),_wo=o(" \u2014 "),DO=a("a"),bwo=o("LEDTokenizer"),vwo=o(" or "),jO=a("a"),Fwo=o("LEDTokenizerFast"),Two=o(" (LED model)"),Mwo=l(),el=a("li"),Z_e=a("strong"),Ewo=o("lilt"),Cwo=o(" \u2014 "),GO=a("a"),wwo=o("LayoutLMv3Tokenizer"),Awo=o(" or "),OO=a("a"),Lwo=o("LayoutLMv3TokenizerFast"),ywo=o(" (LiLT model)"),xwo=l(),ol=a("li"),K_e=a("strong"),$wo=o("longformer"),kwo=o(" \u2014 "),VO=a("a"),Swo=o("LongformerTokenizer"),Rwo=o(" or "),XO=a("a"),Pwo=o("LongformerTokenizerFast"),Bwo=o(" (Longformer model)"),Iwo=l(),rl=a("li"),e1e=a("strong"),Nwo=o("longt5"),qwo=o(" \u2014 "),zO=a("a"),Dwo=o("T5Tokenizer"),jwo=o(" or "),QO=a("a"),Gwo=o("T5TokenizerFast"),Owo=o(" (LongT5 model)"),Vwo=l(),ep=a("li"),o1e=a("strong"),Xwo=o("luke"),zwo=o(" \u2014 "),WO=a("a"),Qwo=o("LukeTokenizer"),Wwo=o(" (LUKE model)"),Uwo=l(),tl=a("li"),r1e=a("strong"),Hwo=o("lxmert"),Jwo=o(" \u2014 "),UO=a("a"),Ywo=o("LxmertTokenizer"),Zwo=o(" or "),HO=a("a"),Kwo=o("LxmertTokenizerFast"),eAo=o(" (LXMERT model)"),oAo=l(),op=a("li"),t1e=a("strong"),rAo=o("m2m_100"),tAo=o(" \u2014 "),JO=a("a"),aAo=o("M2M100Tokenizer"),nAo=o(" (M2M100 model)"),sAo=l(),rp=a("li"),a1e=a("strong"),lAo=o("marian"),iAo=o(" \u2014 "),YO=a("a"),dAo=o("MarianTokenizer"),mAo=o(" (Marian model)"),cAo=l(),al=a("li"),n1e=a("strong"),fAo=o("mbart"),gAo=o(" \u2014 "),ZO=a("a"),hAo=o("MBartTokenizer"),uAo=o(" or "),KO=a("a"),pAo=o("MBartTokenizerFast"),_Ao=o(" (mBART model)"),bAo=l(),nl=a("li"),s1e=a("strong"),vAo=o("mbart50"),FAo=o(" \u2014 "),eV=a("a"),TAo=o("MBart50Tokenizer"),MAo=o(" or "),oV=a("a"),EAo=o("MBart50TokenizerFast"),CAo=o(" (mBART-50 model)"),wAo=l(),sl=a("li"),l1e=a("strong"),AAo=o("megatron-bert"),LAo=o(" \u2014 "),rV=a("a"),yAo=o("BertTokenizer"),xAo=o(" or "),tV=a("a"),$Ao=o("BertTokenizerFast"),kAo=o(" (Megatron-BERT model)"),SAo=l(),tp=a("li"),i1e=a("strong"),RAo=o("mluke"),PAo=o(" \u2014 "),aV=a("a"),BAo=o("MLukeTokenizer"),IAo=o(" (mLUKE model)"),NAo=l(),ll=a("li"),d1e=a("strong"),qAo=o("mobilebert"),DAo=o(" \u2014 "),nV=a("a"),jAo=o("MobileBertTokenizer"),GAo=o(" or "),sV=a("a"),OAo=o("MobileBertTokenizerFast"),VAo=o(" (MobileBERT model)"),XAo=l(),il=a("li"),m1e=a("strong"),zAo=o("mpnet"),QAo=o(" \u2014 "),lV=a("a"),WAo=o("MPNetTokenizer"),UAo=o(" or "),iV=a("a"),HAo=o("MPNetTokenizerFast"),JAo=o(" (MPNet model)"),YAo=l(),dl=a("li"),c1e=a("strong"),ZAo=o("mt5"),KAo=o(" \u2014 "),dV=a("a"),e6o=o("MT5Tokenizer"),o6o=o(" or "),mV=a("a"),r6o=o("MT5TokenizerFast"),t6o=o(" (MT5 model)"),a6o=l(),ml=a("li"),f1e=a("strong"),n6o=o("mvp"),s6o=o(" \u2014 "),cV=a("a"),l6o=o("MvpTokenizer"),i6o=o(" or "),fV=a("a"),d6o=o("MvpTokenizerFast"),m6o=o(" (MVP model)"),c6o=l(),cl=a("li"),g1e=a("strong"),f6o=o("nezha"),g6o=o(" \u2014 "),gV=a("a"),h6o=o("BertTokenizer"),u6o=o(" or "),hV=a("a"),p6o=o("BertTokenizerFast"),_6o=o(" (Nezha model)"),b6o=l(),fl=a("li"),h1e=a("strong"),v6o=o("nllb"),F6o=o(" \u2014 "),uV=a("a"),T6o=o("NllbTokenizer"),M6o=o(" or "),pV=a("a"),E6o=o("NllbTokenizerFast"),C6o=o(" (NLLB model)"),w6o=l(),gl=a("li"),u1e=a("strong"),A6o=o("nystromformer"),L6o=o(" \u2014 "),_V=a("a"),y6o=o("AlbertTokenizer"),x6o=o(" or "),bV=a("a"),$6o=o("AlbertTokenizerFast"),k6o=o(" (Nystr\xF6mformer model)"),S6o=l(),hl=a("li"),p1e=a("strong"),R6o=o("openai-gpt"),P6o=o(" \u2014 "),vV=a("a"),B6o=o("OpenAIGPTTokenizer"),I6o=o(" or "),FV=a("a"),N6o=o("OpenAIGPTTokenizerFast"),q6o=o(" (OpenAI GPT model)"),D6o=l(),ap=a("li"),_1e=a("strong"),j6o=o("opt"),G6o=o(" \u2014 "),TV=a("a"),O6o=o("GPT2Tokenizer"),V6o=o(" (OPT model)"),X6o=l(),ul=a("li"),b1e=a("strong"),z6o=o("owlvit"),Q6o=o(" \u2014 "),MV=a("a"),W6o=o("CLIPTokenizer"),U6o=o(" or "),EV=a("a"),H6o=o("CLIPTokenizerFast"),J6o=o(" (OWL-ViT model)"),Y6o=l(),pl=a("li"),v1e=a("strong"),Z6o=o("pegasus"),K6o=o(" \u2014 "),CV=a("a"),e7o=o("PegasusTokenizer"),o7o=o(" or "),wV=a("a"),r7o=o("PegasusTokenizerFast"),t7o=o(" (Pegasus model)"),a7o=l(),_l=a("li"),F1e=a("strong"),n7o=o("pegasus_x"),s7o=o(" \u2014 "),AV=a("a"),l7o=o("PegasusTokenizer"),i7o=o(" or "),LV=a("a"),d7o=o("PegasusTokenizerFast"),m7o=o(" (PEGASUS-X model)"),c7o=l(),np=a("li"),T1e=a("strong"),f7o=o("perceiver"),g7o=o(" \u2014 "),yV=a("a"),h7o=o("PerceiverTokenizer"),u7o=o(" (Perceiver model)"),p7o=l(),sp=a("li"),M1e=a("strong"),_7o=o("phobert"),b7o=o(" \u2014 "),xV=a("a"),v7o=o("PhobertTokenizer"),F7o=o(" (PhoBERT model)"),T7o=l(),lp=a("li"),E1e=a("strong"),M7o=o("plbart"),E7o=o(" \u2014 "),$V=a("a"),C7o=o("PLBartTokenizer"),w7o=o(" (PLBart model)"),A7o=l(),ip=a("li"),C1e=a("strong"),L7o=o("prophetnet"),y7o=o(" \u2014 "),kV=a("a"),x7o=o("ProphetNetTokenizer"),$7o=o(" (ProphetNet model)"),k7o=l(),bl=a("li"),w1e=a("strong"),S7o=o("qdqbert"),R7o=o(" \u2014 "),SV=a("a"),P7o=o("BertTokenizer"),B7o=o(" or "),RV=a("a"),I7o=o("BertTokenizerFast"),N7o=o(" (QDQBert model)"),q7o=l(),dp=a("li"),A1e=a("strong"),D7o=o("rag"),j7o=o(" \u2014 "),PV=a("a"),G7o=o("RagTokenizer"),O7o=o(" (RAG model)"),V7o=l(),vl=a("li"),L1e=a("strong"),X7o=o("realm"),z7o=o(" \u2014 "),BV=a("a"),Q7o=o("RealmTokenizer"),W7o=o(" or "),IV=a("a"),U7o=o("RealmTokenizerFast"),H7o=o(" (REALM model)"),J7o=l(),Fl=a("li"),y1e=a("strong"),Y7o=o("reformer"),Z7o=o(" \u2014 "),NV=a("a"),K7o=o("ReformerTokenizer"),e8o=o(" or "),qV=a("a"),o8o=o("ReformerTokenizerFast"),r8o=o(" (Reformer model)"),t8o=l(),Tl=a("li"),x1e=a("strong"),a8o=o("rembert"),n8o=o(" \u2014 "),DV=a("a"),s8o=o("RemBertTokenizer"),l8o=o(" or "),jV=a("a"),i8o=o("RemBertTokenizerFast"),d8o=o(" (RemBERT model)"),m8o=l(),Ml=a("li"),$1e=a("strong"),c8o=o("retribert"),f8o=o(" \u2014 "),GV=a("a"),g8o=o("RetriBertTokenizer"),h8o=o(" or "),OV=a("a"),u8o=o("RetriBertTokenizerFast"),p8o=o(" (RetriBERT model)"),_8o=l(),El=a("li"),k1e=a("strong"),b8o=o("roberta"),v8o=o(" \u2014 "),VV=a("a"),F8o=o("RobertaTokenizer"),T8o=o(" or "),XV=a("a"),M8o=o("RobertaTokenizerFast"),E8o=o(" (RoBERTa model)"),C8o=l(),Cl=a("li"),S1e=a("strong"),w8o=o("roformer"),A8o=o(" \u2014 "),zV=a("a"),L8o=o("RoFormerTokenizer"),y8o=o(" or "),QV=a("a"),x8o=o("RoFormerTokenizerFast"),$8o=o(" (RoFormer model)"),k8o=l(),mp=a("li"),R1e=a("strong"),S8o=o("speech_to_text"),R8o=o(" \u2014 "),WV=a("a"),P8o=o("Speech2TextTokenizer"),B8o=o(" (Speech2Text model)"),I8o=l(),cp=a("li"),P1e=a("strong"),N8o=o("speech_to_text_2"),q8o=o(" \u2014 "),UV=a("a"),D8o=o("Speech2Text2Tokenizer"),j8o=o(" (Speech2Text2 model)"),G8o=l(),wl=a("li"),B1e=a("strong"),O8o=o("splinter"),V8o=o(" \u2014 "),HV=a("a"),X8o=o("SplinterTokenizer"),z8o=o(" or "),JV=a("a"),Q8o=o("SplinterTokenizerFast"),W8o=o(" (Splinter model)"),U8o=l(),Al=a("li"),I1e=a("strong"),H8o=o("squeezebert"),J8o=o(" \u2014 "),YV=a("a"),Y8o=o("SqueezeBertTokenizer"),Z8o=o(" or "),ZV=a("a"),K8o=o("SqueezeBertTokenizerFast"),eLo=o(" (SqueezeBERT model)"),oLo=l(),Ll=a("li"),N1e=a("strong"),rLo=o("t5"),tLo=o(" \u2014 "),KV=a("a"),aLo=o("T5Tokenizer"),nLo=o(" or "),eX=a("a"),sLo=o("T5TokenizerFast"),lLo=o(" (T5 model)"),iLo=l(),fp=a("li"),q1e=a("strong"),dLo=o("tapas"),mLo=o(" \u2014 "),oX=a("a"),cLo=o("TapasTokenizer"),fLo=o(" (TAPAS model)"),gLo=l(),gp=a("li"),D1e=a("strong"),hLo=o("tapex"),uLo=o(" \u2014 "),rX=a("a"),pLo=o("TapexTokenizer"),_Lo=o(" (TAPEX model)"),bLo=l(),hp=a("li"),j1e=a("strong"),vLo=o("transfo-xl"),FLo=o(" \u2014 "),tX=a("a"),TLo=o("TransfoXLTokenizer"),MLo=o(" (Transformer-XL model)"),ELo=l(),yl=a("li"),G1e=a("strong"),CLo=o("vilt"),wLo=o(" \u2014 "),aX=a("a"),ALo=o("BertTokenizer"),LLo=o(" or "),nX=a("a"),yLo=o("BertTokenizerFast"),xLo=o(" (ViLT model)"),$Lo=l(),xl=a("li"),O1e=a("strong"),kLo=o("visual_bert"),SLo=o(" \u2014 "),sX=a("a"),RLo=o("BertTokenizer"),PLo=o(" or "),lX=a("a"),BLo=o("BertTokenizerFast"),ILo=o(" (VisualBERT model)"),NLo=l(),up=a("li"),V1e=a("strong"),qLo=o("wav2vec2"),DLo=o(" \u2014 "),iX=a("a"),jLo=o("Wav2Vec2CTCTokenizer"),GLo=o(" (Wav2Vec2 model)"),OLo=l(),pp=a("li"),X1e=a("strong"),VLo=o("wav2vec2-conformer"),XLo=o(" \u2014 "),dX=a("a"),zLo=o("Wav2Vec2CTCTokenizer"),QLo=o(" (Wav2Vec2-Conformer model)"),WLo=l(),_p=a("li"),z1e=a("strong"),ULo=o("wav2vec2_phoneme"),HLo=o(" \u2014 "),mX=a("a"),JLo=o("Wav2Vec2PhonemeCTCTokenizer"),YLo=o(" (Wav2Vec2Phoneme model)"),ZLo=l(),bp=a("li"),Q1e=a("strong"),KLo=o("whisper"),eyo=o(" \u2014 "),cX=a("a"),oyo=o("WhisperTokenizer"),ryo=o(" (Whisper model)"),tyo=l(),$l=a("li"),W1e=a("strong"),ayo=o("xclip"),nyo=o(" \u2014 "),fX=a("a"),syo=o("CLIPTokenizer"),lyo=o(" or "),gX=a("a"),iyo=o("CLIPTokenizerFast"),dyo=o(" (X-CLIP model)"),myo=l(),kl=a("li"),U1e=a("strong"),cyo=o("xglm"),fyo=o(" \u2014 "),hX=a("a"),gyo=o("XGLMTokenizer"),hyo=o(" or "),uX=a("a"),uyo=o("XGLMTokenizerFast"),pyo=o(" (XGLM model)"),_yo=l(),vp=a("li"),H1e=a("strong"),byo=o("xlm"),vyo=o(" \u2014 "),pX=a("a"),Fyo=o("XLMTokenizer"),Tyo=o(" (XLM model)"),Myo=l(),Fp=a("li"),J1e=a("strong"),Eyo=o("xlm-prophetnet"),Cyo=o(" \u2014 "),_X=a("a"),wyo=o("XLMProphetNetTokenizer"),Ayo=o(" (XLM-ProphetNet model)"),Lyo=l(),Sl=a("li"),Y1e=a("strong"),yyo=o("xlm-roberta"),xyo=o(" \u2014 "),bX=a("a"),$yo=o("XLMRobertaTokenizer"),kyo=o(" or "),vX=a("a"),Syo=o("XLMRobertaTokenizerFast"),Ryo=o(" (XLM-RoBERTa model)"),Pyo=l(),Rl=a("li"),Z1e=a("strong"),Byo=o("xlm-roberta-xl"),Iyo=o(" \u2014 "),FX=a("a"),Nyo=o("XLMRobertaTokenizer"),qyo=o(" or "),TX=a("a"),Dyo=o("XLMRobertaTokenizerFast"),jyo=o(" (XLM-RoBERTa-XL model)"),Gyo=l(),Pl=a("li"),K1e=a("strong"),Oyo=o("xlnet"),Vyo=o(" \u2014 "),MX=a("a"),Xyo=o("XLNetTokenizer"),zyo=o(" or "),EX=a("a"),Qyo=o("XLNetTokenizerFast"),Wyo=o(" (XLNet model)"),Uyo=l(),Bl=a("li"),e2e=a("strong"),Hyo=o("yoso"),Jyo=o(" \u2014 "),CX=a("a"),Yyo=o("AlbertTokenizer"),Zyo=o(" or "),wX=a("a"),Kyo=o("AlbertTokenizerFast"),e9o=o(" (YOSO model)"),o9o=l(),F(Tp.$$.fragment),r9o=l(),Mp=a("div"),F(Ck.$$.fragment),t9o=l(),o2e=a("p"),a9o=o("Register a new tokenizer in this mapping."),Tlo=l(),Nd=a("h2"),Ep=a("a"),r2e=a("span"),F(wk.$$.fragment),n9o=l(),t2e=a("span"),s9o=o("AutoFeatureExtractor"),Mlo=l(),No=a("div"),F(Ak.$$.fragment),l9o=l(),Lk=a("p"),i9o=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),AX=a("a"),d9o=o("AutoFeatureExtractor.from_pretrained()"),m9o=o(" class method."),c9o=l(),yk=a("p"),f9o=o("This class cannot be instantiated directly using "),a2e=a("code"),g9o=o("__init__()"),h9o=o(" (throws an error)."),u9o=l(),eo=a("div"),F(xk.$$.fragment),p9o=l(),n2e=a("p"),_9o=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),b9o=l(),mn=a("p"),v9o=o("The feature extractor class to instantiate is selected based on the "),s2e=a("code"),F9o=o("model_type"),T9o=o(` property of the config object
(either passed as an argument or loaded from `),l2e=a("code"),M9o=o("pretrained_model_name_or_path"),E9o=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),i2e=a("code"),C9o=o("pretrained_model_name_or_path"),w9o=o(":"),A9o=l(),z=a("ul"),Cp=a("li"),d2e=a("strong"),L9o=o("beit"),y9o=o(" \u2014 "),LX=a("a"),x9o=o("BeitFeatureExtractor"),$9o=o(" (BEiT model)"),k9o=l(),wp=a("li"),m2e=a("strong"),S9o=o("clip"),R9o=o(" \u2014 "),yX=a("a"),P9o=o("CLIPFeatureExtractor"),B9o=o(" (CLIP model)"),I9o=l(),Ap=a("li"),c2e=a("strong"),N9o=o("clipseg"),q9o=o(" \u2014 "),xX=a("a"),D9o=o("ViTFeatureExtractor"),j9o=o(" (CLIPSeg model)"),G9o=l(),Lp=a("li"),f2e=a("strong"),O9o=o("conditional_detr"),V9o=o(" \u2014 "),$X=a("a"),X9o=o("ConditionalDetrFeatureExtractor"),z9o=o(" (Conditional DETR model)"),Q9o=l(),yp=a("li"),g2e=a("strong"),W9o=o("convnext"),U9o=o(" \u2014 "),kX=a("a"),H9o=o("ConvNextFeatureExtractor"),J9o=o(" (ConvNeXT model)"),Y9o=l(),xp=a("li"),h2e=a("strong"),Z9o=o("cvt"),K9o=o(" \u2014 "),SX=a("a"),exo=o("ConvNextFeatureExtractor"),oxo=o(" (CvT model)"),rxo=l(),$p=a("li"),u2e=a("strong"),txo=o("data2vec-audio"),axo=o(" \u2014 "),RX=a("a"),nxo=o("Wav2Vec2FeatureExtractor"),sxo=o(" (Data2VecAudio model)"),lxo=l(),kp=a("li"),p2e=a("strong"),ixo=o("data2vec-vision"),dxo=o(" \u2014 "),PX=a("a"),mxo=o("BeitFeatureExtractor"),cxo=o(" (Data2VecVision model)"),fxo=l(),Sp=a("li"),_2e=a("strong"),gxo=o("deformable_detr"),hxo=o(" \u2014 "),BX=a("a"),uxo=o("DeformableDetrFeatureExtractor"),pxo=o(" (Deformable DETR model)"),_xo=l(),Rp=a("li"),b2e=a("strong"),bxo=o("deit"),vxo=o(" \u2014 "),IX=a("a"),Fxo=o("DeiTFeatureExtractor"),Txo=o(" (DeiT model)"),Mxo=l(),Pp=a("li"),v2e=a("strong"),Exo=o("detr"),Cxo=o(" \u2014 "),NX=a("a"),wxo=o("DetrFeatureExtractor"),Axo=o(" (DETR model)"),Lxo=l(),Bp=a("li"),F2e=a("strong"),yxo=o("donut-swin"),xxo=o(" \u2014 "),qX=a("a"),$xo=o("DonutFeatureExtractor"),kxo=o(" (DonutSwin model)"),Sxo=l(),Ip=a("li"),T2e=a("strong"),Rxo=o("dpt"),Pxo=o(" \u2014 "),DX=a("a"),Bxo=o("DPTFeatureExtractor"),Ixo=o(" (DPT model)"),Nxo=l(),Np=a("li"),M2e=a("strong"),qxo=o("flava"),Dxo=o(" \u2014 "),jX=a("a"),jxo=o("FlavaFeatureExtractor"),Gxo=o(" (FLAVA model)"),Oxo=l(),qp=a("li"),E2e=a("strong"),Vxo=o("glpn"),Xxo=o(" \u2014 "),GX=a("a"),zxo=o("GLPNFeatureExtractor"),Qxo=o(" (GLPN model)"),Wxo=l(),Dp=a("li"),C2e=a("strong"),Uxo=o("groupvit"),Hxo=o(" \u2014 "),OX=a("a"),Jxo=o("CLIPFeatureExtractor"),Yxo=o(" (GroupViT model)"),Zxo=l(),jp=a("li"),w2e=a("strong"),Kxo=o("hubert"),e$o=o(" \u2014 "),VX=a("a"),o$o=o("Wav2Vec2FeatureExtractor"),r$o=o(" (Hubert model)"),t$o=l(),Gp=a("li"),A2e=a("strong"),a$o=o("imagegpt"),n$o=o(" \u2014 "),XX=a("a"),s$o=o("ImageGPTFeatureExtractor"),l$o=o(" (ImageGPT model)"),i$o=l(),Op=a("li"),L2e=a("strong"),d$o=o("layoutlmv2"),m$o=o(" \u2014 "),zX=a("a"),c$o=o("LayoutLMv2FeatureExtractor"),f$o=o(" (LayoutLMv2 model)"),g$o=l(),Vp=a("li"),y2e=a("strong"),h$o=o("layoutlmv3"),u$o=o(" \u2014 "),QX=a("a"),p$o=o("LayoutLMv3FeatureExtractor"),_$o=o(" (LayoutLMv3 model)"),b$o=l(),Xp=a("li"),x2e=a("strong"),v$o=o("levit"),F$o=o(" \u2014 "),WX=a("a"),T$o=o("LevitFeatureExtractor"),M$o=o(" (LeViT model)"),E$o=l(),zp=a("li"),$2e=a("strong"),C$o=o("maskformer"),w$o=o(" \u2014 "),UX=a("a"),A$o=o("MaskFormerFeatureExtractor"),L$o=o(" (MaskFormer model)"),y$o=l(),Qp=a("li"),k2e=a("strong"),x$o=o("mctct"),$$o=o(" \u2014 "),HX=a("a"),k$o=o("MCTCTFeatureExtractor"),S$o=o(" (M-CTC-T model)"),R$o=l(),Wp=a("li"),S2e=a("strong"),P$o=o("mobilevit"),B$o=o(" \u2014 "),JX=a("a"),I$o=o("MobileViTFeatureExtractor"),N$o=o(" (MobileViT model)"),q$o=l(),Up=a("li"),R2e=a("strong"),D$o=o("owlvit"),j$o=o(" \u2014 "),YX=a("a"),G$o=o("OwlViTFeatureExtractor"),O$o=o(" (OWL-ViT model)"),V$o=l(),Hp=a("li"),P2e=a("strong"),X$o=o("perceiver"),z$o=o(" \u2014 "),ZX=a("a"),Q$o=o("PerceiverFeatureExtractor"),W$o=o(" (Perceiver model)"),U$o=l(),Jp=a("li"),B2e=a("strong"),H$o=o("poolformer"),J$o=o(" \u2014 "),KX=a("a"),Y$o=o("PoolFormerFeatureExtractor"),Z$o=o(" (PoolFormer model)"),K$o=l(),Yp=a("li"),I2e=a("strong"),eko=o("regnet"),oko=o(" \u2014 "),ez=a("a"),rko=o("ConvNextFeatureExtractor"),tko=o(" (RegNet model)"),ako=l(),Zp=a("li"),N2e=a("strong"),nko=o("resnet"),sko=o(" \u2014 "),oz=a("a"),lko=o("ConvNextFeatureExtractor"),iko=o(" (ResNet model)"),dko=l(),Kp=a("li"),q2e=a("strong"),mko=o("segformer"),cko=o(" \u2014 "),rz=a("a"),fko=o("SegformerFeatureExtractor"),gko=o(" (SegFormer model)"),hko=l(),e_=a("li"),D2e=a("strong"),uko=o("speech_to_text"),pko=o(" \u2014 "),tz=a("a"),_ko=o("Speech2TextFeatureExtractor"),bko=o(" (Speech2Text model)"),vko=l(),o_=a("li"),j2e=a("strong"),Fko=o("swin"),Tko=o(" \u2014 "),az=a("a"),Mko=o("ViTFeatureExtractor"),Eko=o(" (Swin Transformer model)"),Cko=l(),r_=a("li"),G2e=a("strong"),wko=o("swinv2"),Ako=o(" \u2014 "),nz=a("a"),Lko=o("ViTFeatureExtractor"),yko=o(" (Swin Transformer V2 model)"),xko=l(),t_=a("li"),O2e=a("strong"),$ko=o("table-transformer"),kko=o(" \u2014 "),sz=a("a"),Sko=o("DetrFeatureExtractor"),Rko=o(" (Table Transformer model)"),Pko=l(),a_=a("li"),V2e=a("strong"),Bko=o("van"),Iko=o(" \u2014 "),lz=a("a"),Nko=o("ConvNextFeatureExtractor"),qko=o(" (VAN model)"),Dko=l(),n_=a("li"),X2e=a("strong"),jko=o("videomae"),Gko=o(" \u2014 "),iz=a("a"),Oko=o("VideoMAEFeatureExtractor"),Vko=o(" (VideoMAE model)"),Xko=l(),s_=a("li"),z2e=a("strong"),zko=o("vilt"),Qko=o(" \u2014 "),dz=a("a"),Wko=o("ViltFeatureExtractor"),Uko=o(" (ViLT model)"),Hko=l(),l_=a("li"),Q2e=a("strong"),Jko=o("vit"),Yko=o(" \u2014 "),mz=a("a"),Zko=o("ViTFeatureExtractor"),Kko=o(" (ViT model)"),eSo=l(),i_=a("li"),W2e=a("strong"),oSo=o("vit_mae"),rSo=o(" \u2014 "),cz=a("a"),tSo=o("ViTFeatureExtractor"),aSo=o(" (ViTMAE model)"),nSo=l(),d_=a("li"),U2e=a("strong"),sSo=o("vit_msn"),lSo=o(" \u2014 "),fz=a("a"),iSo=o("ViTFeatureExtractor"),dSo=o(" (ViTMSN model)"),mSo=l(),m_=a("li"),H2e=a("strong"),cSo=o("wav2vec2"),fSo=o(" \u2014 "),gz=a("a"),gSo=o("Wav2Vec2FeatureExtractor"),hSo=o(" (Wav2Vec2 model)"),uSo=l(),c_=a("li"),J2e=a("strong"),pSo=o("wav2vec2-conformer"),_So=o(" \u2014 "),hz=a("a"),bSo=o("Wav2Vec2FeatureExtractor"),vSo=o(" (Wav2Vec2-Conformer model)"),FSo=l(),f_=a("li"),Y2e=a("strong"),TSo=o("whisper"),MSo=o(" \u2014 "),uz=a("a"),ESo=o("WhisperFeatureExtractor"),CSo=o(" (Whisper model)"),wSo=l(),g_=a("li"),Z2e=a("strong"),ASo=o("xclip"),LSo=o(" \u2014 "),pz=a("a"),ySo=o("CLIPFeatureExtractor"),xSo=o(" (X-CLIP model)"),$So=l(),h_=a("li"),K2e=a("strong"),kSo=o("yolos"),SSo=o(" \u2014 "),_z=a("a"),RSo=o("YolosFeatureExtractor"),PSo=o(" (YOLOS model)"),BSo=l(),F(u_.$$.fragment),ISo=l(),F(p_.$$.fragment),NSo=l(),__=a("div"),F($k.$$.fragment),qSo=l(),ebe=a("p"),DSo=o("Register a new feature extractor for this class."),Elo=l(),qd=a("h2"),b_=a("a"),obe=a("span"),F(kk.$$.fragment),jSo=l(),rbe=a("span"),GSo=o("AutoImageProcessor"),Clo=l(),qo=a("div"),F(Sk.$$.fragment),OSo=l(),Rk=a("p"),VSo=o(`This is a generic image processor class that will be instantiated as one of the image processor classes of the
library when created with the `),bz=a("a"),XSo=o("AutoImageProcessor.from_pretrained()"),zSo=o(" class method."),QSo=l(),Pk=a("p"),WSo=o("This class cannot be instantiated directly using "),tbe=a("code"),USo=o("__init__()"),HSo=o(" (throws an error)."),JSo=l(),oo=a("div"),F(Bk.$$.fragment),YSo=l(),abe=a("p"),ZSo=o("Instantiate one of the image processor classes of the library from a pretrained model vocabulary."),KSo=l(),cn=a("p"),eRo=o("The image processor class to instantiate is selected based on the "),nbe=a("code"),oRo=o("model_type"),rRo=o(` property of the config object
(either passed as an argument or loaded from `),sbe=a("code"),tRo=o("pretrained_model_name_or_path"),aRo=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),lbe=a("code"),nRo=o("pretrained_model_name_or_path"),sRo=o(":"),lRo=l(),re=a("ul"),v_=a("li"),ibe=a("strong"),iRo=o("beit"),dRo=o(" \u2014 "),vz=a("a"),mRo=o("BeitImageProcessor"),cRo=o(" (BEiT model)"),fRo=l(),F_=a("li"),dbe=a("strong"),gRo=o("clip"),hRo=o(" \u2014 "),Fz=a("a"),uRo=o("CLIPImageProcessor"),pRo=o(" (CLIP model)"),_Ro=l(),T_=a("li"),mbe=a("strong"),bRo=o("convnext"),vRo=o(" \u2014 "),Tz=a("a"),FRo=o("ConvNextImageProcessor"),TRo=o(" (ConvNeXT model)"),MRo=l(),M_=a("li"),cbe=a("strong"),ERo=o("cvt"),CRo=o(" \u2014 "),Mz=a("a"),wRo=o("ConvNextImageProcessor"),ARo=o(" (CvT model)"),LRo=l(),E_=a("li"),fbe=a("strong"),yRo=o("data2vec-vision"),xRo=o(" \u2014 "),Ez=a("a"),$Ro=o("BeitImageProcessor"),kRo=o(" (Data2VecVision model)"),SRo=l(),C_=a("li"),gbe=a("strong"),RRo=o("deit"),PRo=o(" \u2014 "),Cz=a("a"),BRo=o("DeiTImageProcessor"),IRo=o(" (DeiT model)"),NRo=l(),w_=a("li"),hbe=a("strong"),qRo=o("dpt"),DRo=o(" \u2014 "),wz=a("a"),jRo=o("DPTImageProcessor"),GRo=o(" (DPT model)"),ORo=l(),A_=a("li"),ube=a("strong"),VRo=o("flava"),XRo=o(" \u2014 "),Az=a("a"),zRo=o("FlavaImageProcessor"),QRo=o(" (FLAVA model)"),WRo=l(),L_=a("li"),pbe=a("strong"),URo=o("glpn"),HRo=o(" \u2014 "),Lz=a("a"),JRo=o("GLPNImageProcessor"),YRo=o(" (GLPN model)"),ZRo=l(),y_=a("li"),_be=a("strong"),KRo=o("groupvit"),ePo=o(" \u2014 "),yz=a("a"),oPo=o("CLIPImageProcessor"),rPo=o(" (GroupViT model)"),tPo=l(),x_=a("li"),bbe=a("strong"),aPo=o("imagegpt"),nPo=o(" \u2014 "),xz=a("a"),sPo=o("ImageGPTImageProcessor"),lPo=o(" (ImageGPT model)"),iPo=l(),$_=a("li"),vbe=a("strong"),dPo=o("layoutlmv2"),mPo=o(" \u2014 "),$z=a("a"),cPo=o("LayoutLMv2ImageProcessor"),fPo=o(" (LayoutLMv2 model)"),gPo=l(),k_=a("li"),Fbe=a("strong"),hPo=o("layoutlmv3"),uPo=o(" \u2014 "),kz=a("a"),pPo=o("LayoutLMv3ImageProcessor"),_Po=o(" (LayoutLMv3 model)"),bPo=l(),S_=a("li"),Tbe=a("strong"),vPo=o("levit"),FPo=o(" \u2014 "),Sz=a("a"),TPo=o("LevitImageProcessor"),MPo=o(" (LeViT model)"),EPo=l(),R_=a("li"),Mbe=a("strong"),CPo=o("mobilevit"),wPo=o(" \u2014 "),Rz=a("a"),APo=o("MobileViTImageProcessor"),LPo=o(" (MobileViT model)"),yPo=l(),P_=a("li"),Ebe=a("strong"),xPo=o("perceiver"),$Po=o(" \u2014 "),Pz=a("a"),kPo=o("PerceiverImageProcessor"),SPo=o(" (Perceiver model)"),RPo=l(),B_=a("li"),Cbe=a("strong"),PPo=o("poolformer"),BPo=o(" \u2014 "),Bz=a("a"),IPo=o("PoolFormerImageProcessor"),NPo=o(" (PoolFormer model)"),qPo=l(),I_=a("li"),wbe=a("strong"),DPo=o("regnet"),jPo=o(" \u2014 "),Iz=a("a"),GPo=o("ConvNextImageProcessor"),OPo=o(" (RegNet model)"),VPo=l(),N_=a("li"),Abe=a("strong"),XPo=o("resnet"),zPo=o(" \u2014 "),Nz=a("a"),QPo=o("ConvNextImageProcessor"),WPo=o(" (ResNet model)"),UPo=l(),q_=a("li"),Lbe=a("strong"),HPo=o("segformer"),JPo=o(" \u2014 "),qz=a("a"),YPo=o("SegformerImageProcessor"),ZPo=o(" (SegFormer model)"),KPo=l(),D_=a("li"),ybe=a("strong"),eBo=o("swin"),oBo=o(" \u2014 "),Dz=a("a"),rBo=o("ViTImageProcessor"),tBo=o(" (Swin Transformer model)"),aBo=l(),j_=a("li"),xbe=a("strong"),nBo=o("swinv2"),sBo=o(" \u2014 "),jz=a("a"),lBo=o("ViTImageProcessor"),iBo=o(" (Swin Transformer V2 model)"),dBo=l(),G_=a("li"),$be=a("strong"),mBo=o("van"),cBo=o(" \u2014 "),Gz=a("a"),fBo=o("ConvNextImageProcessor"),gBo=o(" (VAN model)"),hBo=l(),O_=a("li"),kbe=a("strong"),uBo=o("videomae"),pBo=o(" \u2014 "),Oz=a("a"),_Bo=o("VideoMAEImageProcessor"),bBo=o(" (VideoMAE model)"),vBo=l(),V_=a("li"),Sbe=a("strong"),FBo=o("vilt"),TBo=o(" \u2014 "),Vz=a("a"),MBo=o("ViltImageProcessor"),EBo=o(" (ViLT model)"),CBo=l(),X_=a("li"),Rbe=a("strong"),wBo=o("vit"),ABo=o(" \u2014 "),Xz=a("a"),LBo=o("ViTImageProcessor"),yBo=o(" (ViT model)"),xBo=l(),z_=a("li"),Pbe=a("strong"),$Bo=o("vit_mae"),kBo=o(" \u2014 "),zz=a("a"),SBo=o("ViTImageProcessor"),RBo=o(" (ViTMAE model)"),PBo=l(),Q_=a("li"),Bbe=a("strong"),BBo=o("vit_msn"),IBo=o(" \u2014 "),Qz=a("a"),NBo=o("ViTImageProcessor"),qBo=o(" (ViTMSN model)"),DBo=l(),W_=a("li"),Ibe=a("strong"),jBo=o("xclip"),GBo=o(" \u2014 "),Wz=a("a"),OBo=o("CLIPImageProcessor"),VBo=o(" (X-CLIP model)"),XBo=l(),F(U_.$$.fragment),zBo=l(),F(H_.$$.fragment),QBo=l(),J_=a("div"),F(Ik.$$.fragment),WBo=l(),Nbe=a("p"),UBo=o("Register a new image processor for this class."),wlo=l(),Dd=a("h2"),Y_=a("a"),qbe=a("span"),F(Nk.$$.fragment),HBo=l(),Dbe=a("span"),JBo=o("AutoProcessor"),Alo=l(),Do=a("div"),F(qk.$$.fragment),YBo=l(),Dk=a("p"),ZBo=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),Uz=a("a"),KBo=o("AutoProcessor.from_pretrained()"),eIo=o(" class method."),oIo=l(),jk=a("p"),rIo=o("This class cannot be instantiated directly using "),jbe=a("code"),tIo=o("__init__()"),aIo=o(" (throws an error)."),nIo=l(),ro=a("div"),F(Gk.$$.fragment),sIo=l(),Gbe=a("p"),lIo=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),iIo=l(),jd=a("p"),dIo=o("The processor class to instantiate is selected based on the "),Obe=a("code"),mIo=o("model_type"),cIo=o(` property of the config object (either
passed as an argument or loaded from `),Vbe=a("code"),fIo=o("pretrained_model_name_or_path"),gIo=o(" if possible):"),hIo=l(),ie=a("ul"),Z_=a("li"),Xbe=a("strong"),uIo=o("clip"),pIo=o(" \u2014 "),Hz=a("a"),_Io=o("CLIPProcessor"),bIo=o(" (CLIP model)"),vIo=l(),K_=a("li"),zbe=a("strong"),FIo=o("clipseg"),TIo=o(" \u2014 "),Jz=a("a"),MIo=o("CLIPSegProcessor"),EIo=o(" (CLIPSeg model)"),CIo=l(),e1=a("li"),Qbe=a("strong"),wIo=o("flava"),AIo=o(" \u2014 "),Yz=a("a"),LIo=o("FlavaProcessor"),yIo=o(" (FLAVA model)"),xIo=l(),o1=a("li"),Wbe=a("strong"),$Io=o("groupvit"),kIo=o(" \u2014 "),Zz=a("a"),SIo=o("CLIPProcessor"),RIo=o(" (GroupViT model)"),PIo=l(),r1=a("li"),Ube=a("strong"),BIo=o("layoutlmv2"),IIo=o(" \u2014 "),Kz=a("a"),NIo=o("LayoutLMv2Processor"),qIo=o(" (LayoutLMv2 model)"),DIo=l(),t1=a("li"),Hbe=a("strong"),jIo=o("layoutlmv3"),GIo=o(" \u2014 "),eQ=a("a"),OIo=o("LayoutLMv3Processor"),VIo=o(" (LayoutLMv3 model)"),XIo=l(),a1=a("li"),Jbe=a("strong"),zIo=o("layoutxlm"),QIo=o(" \u2014 "),oQ=a("a"),WIo=o("LayoutXLMProcessor"),UIo=o(" (LayoutXLM model)"),HIo=l(),n1=a("li"),Ybe=a("strong"),JIo=o("markuplm"),YIo=o(" \u2014 "),rQ=a("a"),ZIo=o("MarkupLMProcessor"),KIo=o(" (MarkupLM model)"),eNo=l(),s1=a("li"),Zbe=a("strong"),oNo=o("owlvit"),rNo=o(" \u2014 "),tQ=a("a"),tNo=o("OwlViTProcessor"),aNo=o(" (OWL-ViT model)"),nNo=l(),l1=a("li"),Kbe=a("strong"),sNo=o("sew"),lNo=o(" \u2014 "),aQ=a("a"),iNo=o("Wav2Vec2Processor"),dNo=o(" (SEW model)"),mNo=l(),i1=a("li"),eve=a("strong"),cNo=o("sew-d"),fNo=o(" \u2014 "),nQ=a("a"),gNo=o("Wav2Vec2Processor"),hNo=o(" (SEW-D model)"),uNo=l(),d1=a("li"),ove=a("strong"),pNo=o("speech_to_text"),_No=o(" \u2014 "),sQ=a("a"),bNo=o("Speech2TextProcessor"),vNo=o(" (Speech2Text model)"),FNo=l(),m1=a("li"),rve=a("strong"),TNo=o("speech_to_text_2"),MNo=o(" \u2014 "),lQ=a("a"),ENo=o("Speech2Text2Processor"),CNo=o(" (Speech2Text2 model)"),wNo=l(),c1=a("li"),tve=a("strong"),ANo=o("trocr"),LNo=o(" \u2014 "),iQ=a("a"),yNo=o("TrOCRProcessor"),xNo=o(" (TrOCR model)"),$No=l(),f1=a("li"),ave=a("strong"),kNo=o("unispeech"),SNo=o(" \u2014 "),dQ=a("a"),RNo=o("Wav2Vec2Processor"),PNo=o(" (UniSpeech model)"),BNo=l(),g1=a("li"),nve=a("strong"),INo=o("unispeech-sat"),NNo=o(" \u2014 "),mQ=a("a"),qNo=o("Wav2Vec2Processor"),DNo=o(" (UniSpeechSat model)"),jNo=l(),h1=a("li"),sve=a("strong"),GNo=o("vilt"),ONo=o(" \u2014 "),cQ=a("a"),VNo=o("ViltProcessor"),XNo=o(" (ViLT model)"),zNo=l(),u1=a("li"),lve=a("strong"),QNo=o("vision-text-dual-encoder"),WNo=o(" \u2014 "),fQ=a("a"),UNo=o("VisionTextDualEncoderProcessor"),HNo=o(" (VisionTextDualEncoder model)"),JNo=l(),p1=a("li"),ive=a("strong"),YNo=o("wav2vec2"),ZNo=o(" \u2014 "),gQ=a("a"),KNo=o("Wav2Vec2Processor"),eqo=o(" (Wav2Vec2 model)"),oqo=l(),_1=a("li"),dve=a("strong"),rqo=o("wav2vec2-conformer"),tqo=o(" \u2014 "),hQ=a("a"),aqo=o("Wav2Vec2Processor"),nqo=o(" (Wav2Vec2-Conformer model)"),sqo=l(),b1=a("li"),mve=a("strong"),lqo=o("wavlm"),iqo=o(" \u2014 "),uQ=a("a"),dqo=o("Wav2Vec2Processor"),mqo=o(" (WavLM model)"),cqo=l(),v1=a("li"),cve=a("strong"),fqo=o("whisper"),gqo=o(" \u2014 "),pQ=a("a"),hqo=o("WhisperProcessor"),uqo=o(" (Whisper model)"),pqo=l(),F1=a("li"),fve=a("strong"),_qo=o("xclip"),bqo=o(" \u2014 "),_Q=a("a"),vqo=o("XCLIPProcessor"),Fqo=o(" (X-CLIP model)"),Tqo=l(),F(T1.$$.fragment),Mqo=l(),F(M1.$$.fragment),Eqo=l(),E1=a("div"),F(Ok.$$.fragment),Cqo=l(),gve=a("p"),wqo=o("Register a new processor for this class."),Llo=l(),Gd=a("h2"),C1=a("a"),hve=a("span"),F(Vk.$$.fragment),Aqo=l(),uve=a("span"),Lqo=o("AutoModel"),ylo=l(),jo=a("div"),F(Xk.$$.fragment),yqo=l(),Od=a("p"),xqo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),bQ=a("a"),$qo=o("from_pretrained()"),kqo=o(" class method or the "),vQ=a("a"),Sqo=o("from_config()"),Rqo=o(` class
method.`),Pqo=l(),zk=a("p"),Bqo=o("This class cannot be instantiated directly using "),pve=a("code"),Iqo=o("__init__()"),Nqo=o(" (throws an error)."),qqo=l(),At=a("div"),F(Qk.$$.fragment),Dqo=l(),_ve=a("p"),jqo=o("Instantiates one of the base model classes of the library from a configuration."),Gqo=l(),Vd=a("p"),Oqo=o(`Note:
Loading a model from its configuration file does `),bve=a("strong"),Vqo=o("not"),Xqo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),FQ=a("a"),zqo=o("from_pretrained()"),Qqo=o(" to load the model weights."),Wqo=l(),F(w1.$$.fragment),Uqo=l(),to=a("div"),F(Wk.$$.fragment),Hqo=l(),vve=a("p"),Jqo=o("Instantiate one of the base model classes of the library from a pretrained model."),Yqo=l(),fn=a("p"),Zqo=o("The model class to instantiate is selected based on the "),Fve=a("code"),Kqo=o("model_type"),eDo=o(` property of the config object (either
passed as an argument or loaded from `),Tve=a("code"),oDo=o("pretrained_model_name_or_path"),rDo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mve=a("code"),tDo=o("pretrained_model_name_or_path"),aDo=o(":"),nDo=l(),y=a("ul"),A1=a("li"),Eve=a("strong"),sDo=o("albert"),lDo=o(" \u2014 "),TQ=a("a"),iDo=o("AlbertModel"),dDo=o(" (ALBERT model)"),mDo=l(),L1=a("li"),Cve=a("strong"),cDo=o("bart"),fDo=o(" \u2014 "),MQ=a("a"),gDo=o("BartModel"),hDo=o(" (BART model)"),uDo=l(),y1=a("li"),wve=a("strong"),pDo=o("beit"),_Do=o(" \u2014 "),EQ=a("a"),bDo=o("BeitModel"),vDo=o(" (BEiT model)"),FDo=l(),x1=a("li"),Ave=a("strong"),TDo=o("bert"),MDo=o(" \u2014 "),CQ=a("a"),EDo=o("BertModel"),CDo=o(" (BERT model)"),wDo=l(),$1=a("li"),Lve=a("strong"),ADo=o("bert-generation"),LDo=o(" \u2014 "),wQ=a("a"),yDo=o("BertGenerationEncoder"),xDo=o(" (Bert Generation model)"),$Do=l(),k1=a("li"),yve=a("strong"),kDo=o("big_bird"),SDo=o(" \u2014 "),AQ=a("a"),RDo=o("BigBirdModel"),PDo=o(" (BigBird model)"),BDo=l(),S1=a("li"),xve=a("strong"),IDo=o("bigbird_pegasus"),NDo=o(" \u2014 "),LQ=a("a"),qDo=o("BigBirdPegasusModel"),DDo=o(" (BigBird-Pegasus model)"),jDo=l(),R1=a("li"),$ve=a("strong"),GDo=o("blenderbot"),ODo=o(" \u2014 "),yQ=a("a"),VDo=o("BlenderbotModel"),XDo=o(" (Blenderbot model)"),zDo=l(),P1=a("li"),kve=a("strong"),QDo=o("blenderbot-small"),WDo=o(" \u2014 "),xQ=a("a"),UDo=o("BlenderbotSmallModel"),HDo=o(" (BlenderbotSmall model)"),JDo=l(),B1=a("li"),Sve=a("strong"),YDo=o("bloom"),ZDo=o(" \u2014 "),$Q=a("a"),KDo=o("BloomModel"),ejo=o(" (BLOOM model)"),ojo=l(),I1=a("li"),Rve=a("strong"),rjo=o("camembert"),tjo=o(" \u2014 "),kQ=a("a"),ajo=o("CamembertModel"),njo=o(" (CamemBERT model)"),sjo=l(),N1=a("li"),Pve=a("strong"),ljo=o("canine"),ijo=o(" \u2014 "),SQ=a("a"),djo=o("CanineModel"),mjo=o(" (CANINE model)"),cjo=l(),q1=a("li"),Bve=a("strong"),fjo=o("clip"),gjo=o(" \u2014 "),RQ=a("a"),hjo=o("CLIPModel"),ujo=o(" (CLIP model)"),pjo=l(),D1=a("li"),Ive=a("strong"),_jo=o("clipseg"),bjo=o(" \u2014 "),PQ=a("a"),vjo=o("CLIPSegModel"),Fjo=o(" (CLIPSeg model)"),Tjo=l(),j1=a("li"),Nve=a("strong"),Mjo=o("codegen"),Ejo=o(" \u2014 "),BQ=a("a"),Cjo=o("CodeGenModel"),wjo=o(" (CodeGen model)"),Ajo=l(),G1=a("li"),qve=a("strong"),Ljo=o("conditional_detr"),yjo=o(" \u2014 "),IQ=a("a"),xjo=o("ConditionalDetrModel"),$jo=o(" (Conditional DETR model)"),kjo=l(),O1=a("li"),Dve=a("strong"),Sjo=o("convbert"),Rjo=o(" \u2014 "),NQ=a("a"),Pjo=o("ConvBertModel"),Bjo=o(" (ConvBERT model)"),Ijo=l(),V1=a("li"),jve=a("strong"),Njo=o("convnext"),qjo=o(" \u2014 "),qQ=a("a"),Djo=o("ConvNextModel"),jjo=o(" (ConvNeXT model)"),Gjo=l(),X1=a("li"),Gve=a("strong"),Ojo=o("ctrl"),Vjo=o(" \u2014 "),DQ=a("a"),Xjo=o("CTRLModel"),zjo=o(" (CTRL model)"),Qjo=l(),z1=a("li"),Ove=a("strong"),Wjo=o("cvt"),Ujo=o(" \u2014 "),jQ=a("a"),Hjo=o("CvtModel"),Jjo=o(" (CvT model)"),Yjo=l(),Q1=a("li"),Vve=a("strong"),Zjo=o("data2vec-audio"),Kjo=o(" \u2014 "),GQ=a("a"),eGo=o("Data2VecAudioModel"),oGo=o(" (Data2VecAudio model)"),rGo=l(),W1=a("li"),Xve=a("strong"),tGo=o("data2vec-text"),aGo=o(" \u2014 "),OQ=a("a"),nGo=o("Data2VecTextModel"),sGo=o(" (Data2VecText model)"),lGo=l(),U1=a("li"),zve=a("strong"),iGo=o("data2vec-vision"),dGo=o(" \u2014 "),VQ=a("a"),mGo=o("Data2VecVisionModel"),cGo=o(" (Data2VecVision model)"),fGo=l(),H1=a("li"),Qve=a("strong"),gGo=o("deberta"),hGo=o(" \u2014 "),XQ=a("a"),uGo=o("DebertaModel"),pGo=o(" (DeBERTa model)"),_Go=l(),J1=a("li"),Wve=a("strong"),bGo=o("deberta-v2"),vGo=o(" \u2014 "),zQ=a("a"),FGo=o("DebertaV2Model"),TGo=o(" (DeBERTa-v2 model)"),MGo=l(),Y1=a("li"),Uve=a("strong"),EGo=o("decision_transformer"),CGo=o(" \u2014 "),QQ=a("a"),wGo=o("DecisionTransformerModel"),AGo=o(" (Decision Transformer model)"),LGo=l(),Z1=a("li"),Hve=a("strong"),yGo=o("deformable_detr"),xGo=o(" \u2014 "),WQ=a("a"),$Go=o("DeformableDetrModel"),kGo=o(" (Deformable DETR model)"),SGo=l(),K1=a("li"),Jve=a("strong"),RGo=o("deit"),PGo=o(" \u2014 "),UQ=a("a"),BGo=o("DeiTModel"),IGo=o(" (DeiT model)"),NGo=l(),e2=a("li"),Yve=a("strong"),qGo=o("detr"),DGo=o(" \u2014 "),HQ=a("a"),jGo=o("DetrModel"),GGo=o(" (DETR model)"),OGo=l(),o2=a("li"),Zve=a("strong"),VGo=o("distilbert"),XGo=o(" \u2014 "),JQ=a("a"),zGo=o("DistilBertModel"),QGo=o(" (DistilBERT model)"),WGo=l(),r2=a("li"),Kve=a("strong"),UGo=o("donut-swin"),HGo=o(" \u2014 "),YQ=a("a"),JGo=o("DonutSwinModel"),YGo=o(" (DonutSwin model)"),ZGo=l(),t2=a("li"),eFe=a("strong"),KGo=o("dpr"),eOo=o(" \u2014 "),ZQ=a("a"),oOo=o("DPRQuestionEncoder"),rOo=o(" (DPR model)"),tOo=l(),a2=a("li"),oFe=a("strong"),aOo=o("dpt"),nOo=o(" \u2014 "),KQ=a("a"),sOo=o("DPTModel"),lOo=o(" (DPT model)"),iOo=l(),n2=a("li"),rFe=a("strong"),dOo=o("electra"),mOo=o(" \u2014 "),eW=a("a"),cOo=o("ElectraModel"),fOo=o(" (ELECTRA model)"),gOo=l(),s2=a("li"),tFe=a("strong"),hOo=o("ernie"),uOo=o(" \u2014 "),oW=a("a"),pOo=o("ErnieModel"),_Oo=o(" (ERNIE model)"),bOo=l(),l2=a("li"),aFe=a("strong"),vOo=o("esm"),FOo=o(" \u2014 "),rW=a("a"),TOo=o("EsmModel"),MOo=o(" (ESM model)"),EOo=l(),i2=a("li"),nFe=a("strong"),COo=o("flaubert"),wOo=o(" \u2014 "),tW=a("a"),AOo=o("FlaubertModel"),LOo=o(" (FlauBERT model)"),yOo=l(),d2=a("li"),sFe=a("strong"),xOo=o("flava"),$Oo=o(" \u2014 "),aW=a("a"),kOo=o("FlavaModel"),SOo=o(" (FLAVA model)"),ROo=l(),m2=a("li"),lFe=a("strong"),POo=o("fnet"),BOo=o(" \u2014 "),nW=a("a"),IOo=o("FNetModel"),NOo=o(" (FNet model)"),qOo=l(),c2=a("li"),iFe=a("strong"),DOo=o("fsmt"),jOo=o(" \u2014 "),sW=a("a"),GOo=o("FSMTModel"),OOo=o(" (FairSeq Machine-Translation model)"),VOo=l(),Il=a("li"),dFe=a("strong"),XOo=o("funnel"),zOo=o(" \u2014 "),lW=a("a"),QOo=o("FunnelModel"),WOo=o(" or "),iW=a("a"),UOo=o("FunnelBaseModel"),HOo=o(" (Funnel Transformer model)"),JOo=l(),f2=a("li"),mFe=a("strong"),YOo=o("glpn"),ZOo=o(" \u2014 "),dW=a("a"),KOo=o("GLPNModel"),eVo=o(" (GLPN model)"),oVo=l(),g2=a("li"),cFe=a("strong"),rVo=o("gpt2"),tVo=o(" \u2014 "),mW=a("a"),aVo=o("GPT2Model"),nVo=o(" (OpenAI GPT-2 model)"),sVo=l(),h2=a("li"),fFe=a("strong"),lVo=o("gpt_neo"),iVo=o(" \u2014 "),cW=a("a"),dVo=o("GPTNeoModel"),mVo=o(" (GPT Neo model)"),cVo=l(),u2=a("li"),gFe=a("strong"),fVo=o("gpt_neox"),gVo=o(" \u2014 "),fW=a("a"),hVo=o("GPTNeoXModel"),uVo=o(" (GPT NeoX model)"),pVo=l(),p2=a("li"),hFe=a("strong"),_Vo=o("gpt_neox_japanese"),bVo=o(" \u2014 "),gW=a("a"),vVo=o("GPTNeoXJapaneseModel"),FVo=o(" (GPT NeoX Japanese model)"),TVo=l(),_2=a("li"),uFe=a("strong"),MVo=o("gptj"),EVo=o(" \u2014 "),hW=a("a"),CVo=o("GPTJModel"),wVo=o(" (GPT-J model)"),AVo=l(),b2=a("li"),pFe=a("strong"),LVo=o("groupvit"),yVo=o(" \u2014 "),uW=a("a"),xVo=o("GroupViTModel"),$Vo=o(" (GroupViT model)"),kVo=l(),v2=a("li"),_Fe=a("strong"),SVo=o("hubert"),RVo=o(" \u2014 "),pW=a("a"),PVo=o("HubertModel"),BVo=o(" (Hubert model)"),IVo=l(),F2=a("li"),bFe=a("strong"),NVo=o("ibert"),qVo=o(" \u2014 "),_W=a("a"),DVo=o("IBertModel"),jVo=o(" (I-BERT model)"),GVo=l(),T2=a("li"),vFe=a("strong"),OVo=o("imagegpt"),VVo=o(" \u2014 "),bW=a("a"),XVo=o("ImageGPTModel"),zVo=o(" (ImageGPT model)"),QVo=l(),M2=a("li"),FFe=a("strong"),WVo=o("layoutlm"),UVo=o(" \u2014 "),vW=a("a"),HVo=o("LayoutLMModel"),JVo=o(" (LayoutLM model)"),YVo=l(),E2=a("li"),TFe=a("strong"),ZVo=o("layoutlmv2"),KVo=o(" \u2014 "),FW=a("a"),eXo=o("LayoutLMv2Model"),oXo=o(" (LayoutLMv2 model)"),rXo=l(),C2=a("li"),MFe=a("strong"),tXo=o("layoutlmv3"),aXo=o(" \u2014 "),TW=a("a"),nXo=o("LayoutLMv3Model"),sXo=o(" (LayoutLMv3 model)"),lXo=l(),w2=a("li"),EFe=a("strong"),iXo=o("led"),dXo=o(" \u2014 "),MW=a("a"),mXo=o("LEDModel"),cXo=o(" (LED model)"),fXo=l(),A2=a("li"),CFe=a("strong"),gXo=o("levit"),hXo=o(" \u2014 "),EW=a("a"),uXo=o("LevitModel"),pXo=o(" (LeViT model)"),_Xo=l(),L2=a("li"),wFe=a("strong"),bXo=o("lilt"),vXo=o(" \u2014 "),CW=a("a"),FXo=o("LiltModel"),TXo=o(" (LiLT model)"),MXo=l(),y2=a("li"),AFe=a("strong"),EXo=o("longformer"),CXo=o(" \u2014 "),wW=a("a"),wXo=o("LongformerModel"),AXo=o(" (Longformer model)"),LXo=l(),x2=a("li"),LFe=a("strong"),yXo=o("longt5"),xXo=o(" \u2014 "),AW=a("a"),$Xo=o("LongT5Model"),kXo=o(" (LongT5 model)"),SXo=l(),$2=a("li"),yFe=a("strong"),RXo=o("luke"),PXo=o(" \u2014 "),LW=a("a"),BXo=o("LukeModel"),IXo=o(" (LUKE model)"),NXo=l(),k2=a("li"),xFe=a("strong"),qXo=o("lxmert"),DXo=o(" \u2014 "),yW=a("a"),jXo=o("LxmertModel"),GXo=o(" (LXMERT model)"),OXo=l(),S2=a("li"),$Fe=a("strong"),VXo=o("m2m_100"),XXo=o(" \u2014 "),xW=a("a"),zXo=o("M2M100Model"),QXo=o(" (M2M100 model)"),WXo=l(),R2=a("li"),kFe=a("strong"),UXo=o("marian"),HXo=o(" \u2014 "),$W=a("a"),JXo=o("MarianModel"),YXo=o(" (Marian model)"),ZXo=l(),P2=a("li"),SFe=a("strong"),KXo=o("markuplm"),ezo=o(" \u2014 "),kW=a("a"),ozo=o("MarkupLMModel"),rzo=o(" (MarkupLM model)"),tzo=l(),B2=a("li"),RFe=a("strong"),azo=o("maskformer"),nzo=o(" \u2014 "),SW=a("a"),szo=o("MaskFormerModel"),lzo=o(" (MaskFormer model)"),izo=l(),I2=a("li"),PFe=a("strong"),dzo=o("mbart"),mzo=o(" \u2014 "),RW=a("a"),czo=o("MBartModel"),fzo=o(" (mBART model)"),gzo=l(),N2=a("li"),BFe=a("strong"),hzo=o("mctct"),uzo=o(" \u2014 "),PW=a("a"),pzo=o("MCTCTModel"),_zo=o(" (M-CTC-T model)"),bzo=l(),q2=a("li"),IFe=a("strong"),vzo=o("megatron-bert"),Fzo=o(" \u2014 "),BW=a("a"),Tzo=o("MegatronBertModel"),Mzo=o(" (Megatron-BERT model)"),Ezo=l(),D2=a("li"),NFe=a("strong"),Czo=o("mobilebert"),wzo=o(" \u2014 "),IW=a("a"),Azo=o("MobileBertModel"),Lzo=o(" (MobileBERT model)"),yzo=l(),j2=a("li"),qFe=a("strong"),xzo=o("mobilevit"),$zo=o(" \u2014 "),NW=a("a"),kzo=o("MobileViTModel"),Szo=o(" (MobileViT model)"),Rzo=l(),G2=a("li"),DFe=a("strong"),Pzo=o("mpnet"),Bzo=o(" \u2014 "),qW=a("a"),Izo=o("MPNetModel"),Nzo=o(" (MPNet model)"),qzo=l(),O2=a("li"),jFe=a("strong"),Dzo=o("mt5"),jzo=o(" \u2014 "),DW=a("a"),Gzo=o("MT5Model"),Ozo=o(" (MT5 model)"),Vzo=l(),V2=a("li"),GFe=a("strong"),Xzo=o("mvp"),zzo=o(" \u2014 "),jW=a("a"),Qzo=o("MvpModel"),Wzo=o(" (MVP model)"),Uzo=l(),X2=a("li"),OFe=a("strong"),Hzo=o("nezha"),Jzo=o(" \u2014 "),GW=a("a"),Yzo=o("NezhaModel"),Zzo=o(" (Nezha model)"),Kzo=l(),z2=a("li"),VFe=a("strong"),eQo=o("nllb"),oQo=o(" \u2014 "),OW=a("a"),rQo=o("M2M100Model"),tQo=o(" (NLLB model)"),aQo=l(),Q2=a("li"),XFe=a("strong"),nQo=o("nystromformer"),sQo=o(" \u2014 "),VW=a("a"),lQo=o("NystromformerModel"),iQo=o(" (Nystr\xF6mformer model)"),dQo=l(),W2=a("li"),zFe=a("strong"),mQo=o("openai-gpt"),cQo=o(" \u2014 "),XW=a("a"),fQo=o("OpenAIGPTModel"),gQo=o(" (OpenAI GPT model)"),hQo=l(),U2=a("li"),QFe=a("strong"),uQo=o("opt"),pQo=o(" \u2014 "),zW=a("a"),_Qo=o("OPTModel"),bQo=o(" (OPT model)"),vQo=l(),H2=a("li"),WFe=a("strong"),FQo=o("owlvit"),TQo=o(" \u2014 "),QW=a("a"),MQo=o("OwlViTModel"),EQo=o(" (OWL-ViT model)"),CQo=l(),J2=a("li"),UFe=a("strong"),wQo=o("pegasus"),AQo=o(" \u2014 "),WW=a("a"),LQo=o("PegasusModel"),yQo=o(" (Pegasus model)"),xQo=l(),Y2=a("li"),HFe=a("strong"),$Qo=o("pegasus_x"),kQo=o(" \u2014 "),UW=a("a"),SQo=o("PegasusXModel"),RQo=o(" (PEGASUS-X model)"),PQo=l(),Z2=a("li"),JFe=a("strong"),BQo=o("perceiver"),IQo=o(" \u2014 "),HW=a("a"),NQo=o("PerceiverModel"),qQo=o(" (Perceiver model)"),DQo=l(),K2=a("li"),YFe=a("strong"),jQo=o("plbart"),GQo=o(" \u2014 "),JW=a("a"),OQo=o("PLBartModel"),VQo=o(" (PLBart model)"),XQo=l(),eb=a("li"),ZFe=a("strong"),zQo=o("poolformer"),QQo=o(" \u2014 "),YW=a("a"),WQo=o("PoolFormerModel"),UQo=o(" (PoolFormer model)"),HQo=l(),ob=a("li"),KFe=a("strong"),JQo=o("prophetnet"),YQo=o(" \u2014 "),ZW=a("a"),ZQo=o("ProphetNetModel"),KQo=o(" (ProphetNet model)"),eWo=l(),rb=a("li"),eTe=a("strong"),oWo=o("qdqbert"),rWo=o(" \u2014 "),KW=a("a"),tWo=o("QDQBertModel"),aWo=o(" (QDQBert model)"),nWo=l(),tb=a("li"),oTe=a("strong"),sWo=o("reformer"),lWo=o(" \u2014 "),eU=a("a"),iWo=o("ReformerModel"),dWo=o(" (Reformer model)"),mWo=l(),ab=a("li"),rTe=a("strong"),cWo=o("regnet"),fWo=o(" \u2014 "),oU=a("a"),gWo=o("RegNetModel"),hWo=o(" (RegNet model)"),uWo=l(),nb=a("li"),tTe=a("strong"),pWo=o("rembert"),_Wo=o(" \u2014 "),rU=a("a"),bWo=o("RemBertModel"),vWo=o(" (RemBERT model)"),FWo=l(),sb=a("li"),aTe=a("strong"),TWo=o("resnet"),MWo=o(" \u2014 "),tU=a("a"),EWo=o("ResNetModel"),CWo=o(" (ResNet model)"),wWo=l(),lb=a("li"),nTe=a("strong"),AWo=o("retribert"),LWo=o(" \u2014 "),aU=a("a"),yWo=o("RetriBertModel"),xWo=o(" (RetriBERT model)"),$Wo=l(),ib=a("li"),sTe=a("strong"),kWo=o("roberta"),SWo=o(" \u2014 "),nU=a("a"),RWo=o("RobertaModel"),PWo=o(" (RoBERTa model)"),BWo=l(),db=a("li"),lTe=a("strong"),IWo=o("roc_bert"),NWo=o(" \u2014 "),sU=a("a"),qWo=o("RoCBertModel"),DWo=o(" (RoCBert model)"),jWo=l(),mb=a("li"),iTe=a("strong"),GWo=o("roformer"),OWo=o(" \u2014 "),lU=a("a"),VWo=o("RoFormerModel"),XWo=o(" (RoFormer model)"),zWo=l(),cb=a("li"),dTe=a("strong"),QWo=o("segformer"),WWo=o(" \u2014 "),iU=a("a"),UWo=o("SegformerModel"),HWo=o(" (SegFormer model)"),JWo=l(),fb=a("li"),mTe=a("strong"),YWo=o("sew"),ZWo=o(" \u2014 "),dU=a("a"),KWo=o("SEWModel"),eUo=o(" (SEW model)"),oUo=l(),gb=a("li"),cTe=a("strong"),rUo=o("sew-d"),tUo=o(" \u2014 "),mU=a("a"),aUo=o("SEWDModel"),nUo=o(" (SEW-D model)"),sUo=l(),hb=a("li"),fTe=a("strong"),lUo=o("speech_to_text"),iUo=o(" \u2014 "),cU=a("a"),dUo=o("Speech2TextModel"),mUo=o(" (Speech2Text model)"),cUo=l(),ub=a("li"),gTe=a("strong"),fUo=o("splinter"),gUo=o(" \u2014 "),fU=a("a"),hUo=o("SplinterModel"),uUo=o(" (Splinter model)"),pUo=l(),pb=a("li"),hTe=a("strong"),_Uo=o("squeezebert"),bUo=o(" \u2014 "),gU=a("a"),vUo=o("SqueezeBertModel"),FUo=o(" (SqueezeBERT model)"),TUo=l(),_b=a("li"),uTe=a("strong"),MUo=o("swin"),EUo=o(" \u2014 "),hU=a("a"),CUo=o("SwinModel"),wUo=o(" (Swin Transformer model)"),AUo=l(),bb=a("li"),pTe=a("strong"),LUo=o("swinv2"),yUo=o(" \u2014 "),uU=a("a"),xUo=o("Swinv2Model"),$Uo=o(" (Swin Transformer V2 model)"),kUo=l(),vb=a("li"),_Te=a("strong"),SUo=o("t5"),RUo=o(" \u2014 "),pU=a("a"),PUo=o("T5Model"),BUo=o(" (T5 model)"),IUo=l(),Fb=a("li"),bTe=a("strong"),NUo=o("table-transformer"),qUo=o(" \u2014 "),_U=a("a"),DUo=o("TableTransformerModel"),jUo=o(" (Table Transformer model)"),GUo=l(),Tb=a("li"),vTe=a("strong"),OUo=o("tapas"),VUo=o(" \u2014 "),bU=a("a"),XUo=o("TapasModel"),zUo=o(" (TAPAS model)"),QUo=l(),Mb=a("li"),FTe=a("strong"),WUo=o("time_series_transformer"),UUo=o(" \u2014 "),vU=a("a"),HUo=o("TimeSeriesTransformerModel"),JUo=o(" (Time Series Transformer model)"),YUo=l(),Eb=a("li"),TTe=a("strong"),ZUo=o("trajectory_transformer"),KUo=o(" \u2014 "),FU=a("a"),eHo=o("TrajectoryTransformerModel"),oHo=o(" (Trajectory Transformer model)"),rHo=l(),Cb=a("li"),MTe=a("strong"),tHo=o("transfo-xl"),aHo=o(" \u2014 "),TU=a("a"),nHo=o("TransfoXLModel"),sHo=o(" (Transformer-XL model)"),lHo=l(),wb=a("li"),ETe=a("strong"),iHo=o("unispeech"),dHo=o(" \u2014 "),MU=a("a"),mHo=o("UniSpeechModel"),cHo=o(" (UniSpeech model)"),fHo=l(),Ab=a("li"),CTe=a("strong"),gHo=o("unispeech-sat"),hHo=o(" \u2014 "),EU=a("a"),uHo=o("UniSpeechSatModel"),pHo=o(" (UniSpeechSat model)"),_Ho=l(),Lb=a("li"),wTe=a("strong"),bHo=o("van"),vHo=o(" \u2014 "),CU=a("a"),FHo=o("VanModel"),THo=o(" (VAN model)"),MHo=l(),yb=a("li"),ATe=a("strong"),EHo=o("videomae"),CHo=o(" \u2014 "),wU=a("a"),wHo=o("VideoMAEModel"),AHo=o(" (VideoMAE model)"),LHo=l(),xb=a("li"),LTe=a("strong"),yHo=o("vilt"),xHo=o(" \u2014 "),AU=a("a"),$Ho=o("ViltModel"),kHo=o(" (ViLT model)"),SHo=l(),$b=a("li"),yTe=a("strong"),RHo=o("vision-text-dual-encoder"),PHo=o(" \u2014 "),LU=a("a"),BHo=o("VisionTextDualEncoderModel"),IHo=o(" (VisionTextDualEncoder model)"),NHo=l(),kb=a("li"),xTe=a("strong"),qHo=o("visual_bert"),DHo=o(" \u2014 "),yU=a("a"),jHo=o("VisualBertModel"),GHo=o(" (VisualBERT model)"),OHo=l(),Sb=a("li"),$Te=a("strong"),VHo=o("vit"),XHo=o(" \u2014 "),xU=a("a"),zHo=o("ViTModel"),QHo=o(" (ViT model)"),WHo=l(),Rb=a("li"),kTe=a("strong"),UHo=o("vit_mae"),HHo=o(" \u2014 "),$U=a("a"),JHo=o("ViTMAEModel"),YHo=o(" (ViTMAE model)"),ZHo=l(),Pb=a("li"),STe=a("strong"),KHo=o("vit_msn"),eJo=o(" \u2014 "),kU=a("a"),oJo=o("ViTMSNModel"),rJo=o(" (ViTMSN model)"),tJo=l(),Bb=a("li"),RTe=a("strong"),aJo=o("wav2vec2"),nJo=o(" \u2014 "),SU=a("a"),sJo=o("Wav2Vec2Model"),lJo=o(" (Wav2Vec2 model)"),iJo=l(),Ib=a("li"),PTe=a("strong"),dJo=o("wav2vec2-conformer"),mJo=o(" \u2014 "),RU=a("a"),cJo=o("Wav2Vec2ConformerModel"),fJo=o(" (Wav2Vec2-Conformer model)"),gJo=l(),Nb=a("li"),BTe=a("strong"),hJo=o("wavlm"),uJo=o(" \u2014 "),PU=a("a"),pJo=o("WavLMModel"),_Jo=o(" (WavLM model)"),bJo=l(),qb=a("li"),ITe=a("strong"),vJo=o("whisper"),FJo=o(" \u2014 "),BU=a("a"),TJo=o("WhisperModel"),MJo=o(" (Whisper model)"),EJo=l(),Db=a("li"),NTe=a("strong"),CJo=o("xclip"),wJo=o(" \u2014 "),IU=a("a"),AJo=o("XCLIPModel"),LJo=o(" (X-CLIP model)"),yJo=l(),jb=a("li"),qTe=a("strong"),xJo=o("xglm"),$Jo=o(" \u2014 "),NU=a("a"),kJo=o("XGLMModel"),SJo=o(" (XGLM model)"),RJo=l(),Gb=a("li"),DTe=a("strong"),PJo=o("xlm"),BJo=o(" \u2014 "),qU=a("a"),IJo=o("XLMModel"),NJo=o(" (XLM model)"),qJo=l(),Ob=a("li"),jTe=a("strong"),DJo=o("xlm-prophetnet"),jJo=o(" \u2014 "),DU=a("a"),GJo=o("XLMProphetNetModel"),OJo=o(" (XLM-ProphetNet model)"),VJo=l(),Vb=a("li"),GTe=a("strong"),XJo=o("xlm-roberta"),zJo=o(" \u2014 "),jU=a("a"),QJo=o("XLMRobertaModel"),WJo=o(" (XLM-RoBERTa model)"),UJo=l(),Xb=a("li"),OTe=a("strong"),HJo=o("xlm-roberta-xl"),JJo=o(" \u2014 "),GU=a("a"),YJo=o("XLMRobertaXLModel"),ZJo=o(" (XLM-RoBERTa-XL model)"),KJo=l(),zb=a("li"),VTe=a("strong"),eYo=o("xlnet"),oYo=o(" \u2014 "),OU=a("a"),rYo=o("XLNetModel"),tYo=o(" (XLNet model)"),aYo=l(),Qb=a("li"),XTe=a("strong"),nYo=o("yolos"),sYo=o(" \u2014 "),VU=a("a"),lYo=o("YolosModel"),iYo=o(" (YOLOS model)"),dYo=l(),Wb=a("li"),zTe=a("strong"),mYo=o("yoso"),cYo=o(" \u2014 "),XU=a("a"),fYo=o("YosoModel"),gYo=o(" (YOSO model)"),hYo=l(),Ub=a("p"),uYo=o("The model is set in evaluation mode by default using "),QTe=a("code"),pYo=o("model.eval()"),_Yo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),WTe=a("code"),bYo=o("model.train()"),vYo=l(),F(Hb.$$.fragment),xlo=l(),Xd=a("h2"),Jb=a("a"),UTe=a("span"),F(Uk.$$.fragment),FYo=l(),HTe=a("span"),TYo=o("AutoModelForPreTraining"),$lo=l(),Go=a("div"),F(Hk.$$.fragment),MYo=l(),zd=a("p"),EYo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),zU=a("a"),CYo=o("from_pretrained()"),wYo=o(" class method or the "),QU=a("a"),AYo=o("from_config()"),LYo=o(` class
method.`),yYo=l(),Jk=a("p"),xYo=o("This class cannot be instantiated directly using "),JTe=a("code"),$Yo=o("__init__()"),kYo=o(" (throws an error)."),SYo=l(),Lt=a("div"),F(Yk.$$.fragment),RYo=l(),YTe=a("p"),PYo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),BYo=l(),Qd=a("p"),IYo=o(`Note:
Loading a model from its configuration file does `),ZTe=a("strong"),NYo=o("not"),qYo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WU=a("a"),DYo=o("from_pretrained()"),jYo=o(" to load the model weights."),GYo=l(),F(Yb.$$.fragment),OYo=l(),ao=a("div"),F(Zk.$$.fragment),VYo=l(),KTe=a("p"),XYo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),zYo=l(),gn=a("p"),QYo=o("The model class to instantiate is selected based on the "),eMe=a("code"),WYo=o("model_type"),UYo=o(` property of the config object (either
passed as an argument or loaded from `),oMe=a("code"),HYo=o("pretrained_model_name_or_path"),JYo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rMe=a("code"),YYo=o("pretrained_model_name_or_path"),ZYo=o(":"),KYo=l(),G=a("ul"),Zb=a("li"),tMe=a("strong"),eZo=o("albert"),oZo=o(" \u2014 "),UU=a("a"),rZo=o("AlbertForPreTraining"),tZo=o(" (ALBERT model)"),aZo=l(),Kb=a("li"),aMe=a("strong"),nZo=o("bart"),sZo=o(" \u2014 "),HU=a("a"),lZo=o("BartForConditionalGeneration"),iZo=o(" (BART model)"),dZo=l(),ev=a("li"),nMe=a("strong"),mZo=o("bert"),cZo=o(" \u2014 "),JU=a("a"),fZo=o("BertForPreTraining"),gZo=o(" (BERT model)"),hZo=l(),ov=a("li"),sMe=a("strong"),uZo=o("big_bird"),pZo=o(" \u2014 "),YU=a("a"),_Zo=o("BigBirdForPreTraining"),bZo=o(" (BigBird model)"),vZo=l(),rv=a("li"),lMe=a("strong"),FZo=o("bloom"),TZo=o(" \u2014 "),ZU=a("a"),MZo=o("BloomForCausalLM"),EZo=o(" (BLOOM model)"),CZo=l(),tv=a("li"),iMe=a("strong"),wZo=o("camembert"),AZo=o(" \u2014 "),KU=a("a"),LZo=o("CamembertForMaskedLM"),yZo=o(" (CamemBERT model)"),xZo=l(),av=a("li"),dMe=a("strong"),$Zo=o("ctrl"),kZo=o(" \u2014 "),eH=a("a"),SZo=o("CTRLLMHeadModel"),RZo=o(" (CTRL model)"),PZo=l(),nv=a("li"),mMe=a("strong"),BZo=o("data2vec-text"),IZo=o(" \u2014 "),oH=a("a"),NZo=o("Data2VecTextForMaskedLM"),qZo=o(" (Data2VecText model)"),DZo=l(),sv=a("li"),cMe=a("strong"),jZo=o("deberta"),GZo=o(" \u2014 "),rH=a("a"),OZo=o("DebertaForMaskedLM"),VZo=o(" (DeBERTa model)"),XZo=l(),lv=a("li"),fMe=a("strong"),zZo=o("deberta-v2"),QZo=o(" \u2014 "),tH=a("a"),WZo=o("DebertaV2ForMaskedLM"),UZo=o(" (DeBERTa-v2 model)"),HZo=l(),iv=a("li"),gMe=a("strong"),JZo=o("distilbert"),YZo=o(" \u2014 "),aH=a("a"),ZZo=o("DistilBertForMaskedLM"),KZo=o(" (DistilBERT model)"),eKo=l(),dv=a("li"),hMe=a("strong"),oKo=o("electra"),rKo=o(" \u2014 "),nH=a("a"),tKo=o("ElectraForPreTraining"),aKo=o(" (ELECTRA model)"),nKo=l(),mv=a("li"),uMe=a("strong"),sKo=o("ernie"),lKo=o(" \u2014 "),sH=a("a"),iKo=o("ErnieForPreTraining"),dKo=o(" (ERNIE model)"),mKo=l(),cv=a("li"),pMe=a("strong"),cKo=o("flaubert"),fKo=o(" \u2014 "),lH=a("a"),gKo=o("FlaubertWithLMHeadModel"),hKo=o(" (FlauBERT model)"),uKo=l(),fv=a("li"),_Me=a("strong"),pKo=o("flava"),_Ko=o(" \u2014 "),iH=a("a"),bKo=o("FlavaForPreTraining"),vKo=o(" (FLAVA model)"),FKo=l(),gv=a("li"),bMe=a("strong"),TKo=o("fnet"),MKo=o(" \u2014 "),dH=a("a"),EKo=o("FNetForPreTraining"),CKo=o(" (FNet model)"),wKo=l(),hv=a("li"),vMe=a("strong"),AKo=o("fsmt"),LKo=o(" \u2014 "),mH=a("a"),yKo=o("FSMTForConditionalGeneration"),xKo=o(" (FairSeq Machine-Translation model)"),$Ko=l(),uv=a("li"),FMe=a("strong"),kKo=o("funnel"),SKo=o(" \u2014 "),cH=a("a"),RKo=o("FunnelForPreTraining"),PKo=o(" (Funnel Transformer model)"),BKo=l(),pv=a("li"),TMe=a("strong"),IKo=o("gpt2"),NKo=o(" \u2014 "),fH=a("a"),qKo=o("GPT2LMHeadModel"),DKo=o(" (OpenAI GPT-2 model)"),jKo=l(),_v=a("li"),MMe=a("strong"),GKo=o("ibert"),OKo=o(" \u2014 "),gH=a("a"),VKo=o("IBertForMaskedLM"),XKo=o(" (I-BERT model)"),zKo=l(),bv=a("li"),EMe=a("strong"),QKo=o("layoutlm"),WKo=o(" \u2014 "),hH=a("a"),UKo=o("LayoutLMForMaskedLM"),HKo=o(" (LayoutLM model)"),JKo=l(),vv=a("li"),CMe=a("strong"),YKo=o("longformer"),ZKo=o(" \u2014 "),uH=a("a"),KKo=o("LongformerForMaskedLM"),eer=o(" (Longformer model)"),oer=l(),Fv=a("li"),wMe=a("strong"),rer=o("luke"),ter=o(" \u2014 "),pH=a("a"),aer=o("LukeForMaskedLM"),ner=o(" (LUKE model)"),ser=l(),Tv=a("li"),AMe=a("strong"),ler=o("lxmert"),ier=o(" \u2014 "),_H=a("a"),der=o("LxmertForPreTraining"),mer=o(" (LXMERT model)"),cer=l(),Mv=a("li"),LMe=a("strong"),fer=o("megatron-bert"),ger=o(" \u2014 "),bH=a("a"),her=o("MegatronBertForPreTraining"),uer=o(" (Megatron-BERT model)"),per=l(),Ev=a("li"),yMe=a("strong"),_er=o("mobilebert"),ber=o(" \u2014 "),vH=a("a"),ver=o("MobileBertForPreTraining"),Fer=o(" (MobileBERT model)"),Ter=l(),Cv=a("li"),xMe=a("strong"),Mer=o("mpnet"),Eer=o(" \u2014 "),FH=a("a"),Cer=o("MPNetForMaskedLM"),wer=o(" (MPNet model)"),Aer=l(),wv=a("li"),$Me=a("strong"),Ler=o("mvp"),yer=o(" \u2014 "),TH=a("a"),xer=o("MvpForConditionalGeneration"),$er=o(" (MVP model)"),ker=l(),Av=a("li"),kMe=a("strong"),Ser=o("nezha"),Rer=o(" \u2014 "),MH=a("a"),Per=o("NezhaForPreTraining"),Ber=o(" (Nezha model)"),Ier=l(),Lv=a("li"),SMe=a("strong"),Ner=o("openai-gpt"),qer=o(" \u2014 "),EH=a("a"),Der=o("OpenAIGPTLMHeadModel"),jer=o(" (OpenAI GPT model)"),Ger=l(),yv=a("li"),RMe=a("strong"),Oer=o("retribert"),Ver=o(" \u2014 "),CH=a("a"),Xer=o("RetriBertModel"),zer=o(" (RetriBERT model)"),Qer=l(),xv=a("li"),PMe=a("strong"),Wer=o("roberta"),Uer=o(" \u2014 "),wH=a("a"),Her=o("RobertaForMaskedLM"),Jer=o(" (RoBERTa model)"),Yer=l(),$v=a("li"),BMe=a("strong"),Zer=o("roc_bert"),Ker=o(" \u2014 "),AH=a("a"),eor=o("RoCBertForPreTraining"),oor=o(" (RoCBert model)"),ror=l(),kv=a("li"),IMe=a("strong"),tor=o("splinter"),aor=o(" \u2014 "),LH=a("a"),nor=o("SplinterForPreTraining"),sor=o(" (Splinter model)"),lor=l(),Sv=a("li"),NMe=a("strong"),ior=o("squeezebert"),dor=o(" \u2014 "),yH=a("a"),mor=o("SqueezeBertForMaskedLM"),cor=o(" (SqueezeBERT model)"),gor=l(),Rv=a("li"),qMe=a("strong"),hor=o("t5"),uor=o(" \u2014 "),xH=a("a"),por=o("T5ForConditionalGeneration"),_or=o(" (T5 model)"),bor=l(),Pv=a("li"),DMe=a("strong"),vor=o("tapas"),For=o(" \u2014 "),$H=a("a"),Tor=o("TapasForMaskedLM"),Mor=o(" (TAPAS model)"),Eor=l(),Bv=a("li"),jMe=a("strong"),Cor=o("transfo-xl"),wor=o(" \u2014 "),kH=a("a"),Aor=o("TransfoXLLMHeadModel"),Lor=o(" (Transformer-XL model)"),yor=l(),Iv=a("li"),GMe=a("strong"),xor=o("unispeech"),$or=o(" \u2014 "),SH=a("a"),kor=o("UniSpeechForPreTraining"),Sor=o(" (UniSpeech model)"),Ror=l(),Nv=a("li"),OMe=a("strong"),Por=o("unispeech-sat"),Bor=o(" \u2014 "),RH=a("a"),Ior=o("UniSpeechSatForPreTraining"),Nor=o(" (UniSpeechSat model)"),qor=l(),qv=a("li"),VMe=a("strong"),Dor=o("videomae"),jor=o(" \u2014 "),PH=a("a"),Gor=o("VideoMAEForPreTraining"),Oor=o(" (VideoMAE model)"),Vor=l(),Dv=a("li"),XMe=a("strong"),Xor=o("visual_bert"),zor=o(" \u2014 "),BH=a("a"),Qor=o("VisualBertForPreTraining"),Wor=o(" (VisualBERT model)"),Uor=l(),jv=a("li"),zMe=a("strong"),Hor=o("vit_mae"),Jor=o(" \u2014 "),IH=a("a"),Yor=o("ViTMAEForPreTraining"),Zor=o(" (ViTMAE model)"),Kor=l(),Gv=a("li"),QMe=a("strong"),err=o("wav2vec2"),orr=o(" \u2014 "),NH=a("a"),rrr=o("Wav2Vec2ForPreTraining"),trr=o(" (Wav2Vec2 model)"),arr=l(),Ov=a("li"),WMe=a("strong"),nrr=o("wav2vec2-conformer"),srr=o(" \u2014 "),qH=a("a"),lrr=o("Wav2Vec2ConformerForPreTraining"),irr=o(" (Wav2Vec2-Conformer model)"),drr=l(),Vv=a("li"),UMe=a("strong"),mrr=o("xlm"),crr=o(" \u2014 "),DH=a("a"),frr=o("XLMWithLMHeadModel"),grr=o(" (XLM model)"),hrr=l(),Xv=a("li"),HMe=a("strong"),urr=o("xlm-roberta"),prr=o(" \u2014 "),jH=a("a"),_rr=o("XLMRobertaForMaskedLM"),brr=o(" (XLM-RoBERTa model)"),vrr=l(),zv=a("li"),JMe=a("strong"),Frr=o("xlm-roberta-xl"),Trr=o(" \u2014 "),GH=a("a"),Mrr=o("XLMRobertaXLForMaskedLM"),Err=o(" (XLM-RoBERTa-XL model)"),Crr=l(),Qv=a("li"),YMe=a("strong"),wrr=o("xlnet"),Arr=o(" \u2014 "),OH=a("a"),Lrr=o("XLNetLMHeadModel"),yrr=o(" (XLNet model)"),xrr=l(),Wv=a("p"),$rr=o("The model is set in evaluation mode by default using "),ZMe=a("code"),krr=o("model.eval()"),Srr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),KMe=a("code"),Rrr=o("model.train()"),Prr=l(),F(Uv.$$.fragment),klo=l(),Wd=a("h2"),Hv=a("a"),eEe=a("span"),F(Kk.$$.fragment),Brr=l(),oEe=a("span"),Irr=o("AutoModelForCausalLM"),Slo=l(),Oo=a("div"),F(eS.$$.fragment),Nrr=l(),Ud=a("p"),qrr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),VH=a("a"),Drr=o("from_pretrained()"),jrr=o(" class method or the "),XH=a("a"),Grr=o("from_config()"),Orr=o(` class
method.`),Vrr=l(),oS=a("p"),Xrr=o("This class cannot be instantiated directly using "),rEe=a("code"),zrr=o("__init__()"),Qrr=o(" (throws an error)."),Wrr=l(),yt=a("div"),F(rS.$$.fragment),Urr=l(),tEe=a("p"),Hrr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Jrr=l(),Hd=a("p"),Yrr=o(`Note:
Loading a model from its configuration file does `),aEe=a("strong"),Zrr=o("not"),Krr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zH=a("a"),etr=o("from_pretrained()"),otr=o(" to load the model weights."),rtr=l(),F(Jv.$$.fragment),ttr=l(),no=a("div"),F(tS.$$.fragment),atr=l(),nEe=a("p"),ntr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),str=l(),hn=a("p"),ltr=o("The model class to instantiate is selected based on the "),sEe=a("code"),itr=o("model_type"),dtr=o(` property of the config object (either
passed as an argument or loaded from `),lEe=a("code"),mtr=o("pretrained_model_name_or_path"),ctr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iEe=a("code"),ftr=o("pretrained_model_name_or_path"),gtr=o(":"),htr=l(),W=a("ul"),Yv=a("li"),dEe=a("strong"),utr=o("bart"),ptr=o(" \u2014 "),QH=a("a"),_tr=o("BartForCausalLM"),btr=o(" (BART model)"),vtr=l(),Zv=a("li"),mEe=a("strong"),Ftr=o("bert"),Ttr=o(" \u2014 "),WH=a("a"),Mtr=o("BertLMHeadModel"),Etr=o(" (BERT model)"),Ctr=l(),Kv=a("li"),cEe=a("strong"),wtr=o("bert-generation"),Atr=o(" \u2014 "),UH=a("a"),Ltr=o("BertGenerationDecoder"),ytr=o(" (Bert Generation model)"),xtr=l(),eF=a("li"),fEe=a("strong"),$tr=o("big_bird"),ktr=o(" \u2014 "),HH=a("a"),Str=o("BigBirdForCausalLM"),Rtr=o(" (BigBird model)"),Ptr=l(),oF=a("li"),gEe=a("strong"),Btr=o("bigbird_pegasus"),Itr=o(" \u2014 "),JH=a("a"),Ntr=o("BigBirdPegasusForCausalLM"),qtr=o(" (BigBird-Pegasus model)"),Dtr=l(),rF=a("li"),hEe=a("strong"),jtr=o("blenderbot"),Gtr=o(" \u2014 "),YH=a("a"),Otr=o("BlenderbotForCausalLM"),Vtr=o(" (Blenderbot model)"),Xtr=l(),tF=a("li"),uEe=a("strong"),ztr=o("blenderbot-small"),Qtr=o(" \u2014 "),ZH=a("a"),Wtr=o("BlenderbotSmallForCausalLM"),Utr=o(" (BlenderbotSmall model)"),Htr=l(),aF=a("li"),pEe=a("strong"),Jtr=o("bloom"),Ytr=o(" \u2014 "),KH=a("a"),Ztr=o("BloomForCausalLM"),Ktr=o(" (BLOOM model)"),ear=l(),nF=a("li"),_Ee=a("strong"),oar=o("camembert"),rar=o(" \u2014 "),eJ=a("a"),tar=o("CamembertForCausalLM"),aar=o(" (CamemBERT model)"),nar=l(),sF=a("li"),bEe=a("strong"),sar=o("codegen"),lar=o(" \u2014 "),oJ=a("a"),iar=o("CodeGenForCausalLM"),dar=o(" (CodeGen model)"),mar=l(),lF=a("li"),vEe=a("strong"),car=o("ctrl"),far=o(" \u2014 "),rJ=a("a"),gar=o("CTRLLMHeadModel"),har=o(" (CTRL model)"),uar=l(),iF=a("li"),FEe=a("strong"),par=o("data2vec-text"),_ar=o(" \u2014 "),tJ=a("a"),bar=o("Data2VecTextForCausalLM"),Far=o(" (Data2VecText model)"),Tar=l(),dF=a("li"),TEe=a("strong"),Mar=o("electra"),Ear=o(" \u2014 "),aJ=a("a"),Car=o("ElectraForCausalLM"),war=o(" (ELECTRA model)"),Aar=l(),mF=a("li"),MEe=a("strong"),Lar=o("ernie"),yar=o(" \u2014 "),nJ=a("a"),xar=o("ErnieForCausalLM"),$ar=o(" (ERNIE model)"),kar=l(),cF=a("li"),EEe=a("strong"),Sar=o("gpt2"),Rar=o(" \u2014 "),sJ=a("a"),Par=o("GPT2LMHeadModel"),Bar=o(" (OpenAI GPT-2 model)"),Iar=l(),fF=a("li"),CEe=a("strong"),Nar=o("gpt_neo"),qar=o(" \u2014 "),lJ=a("a"),Dar=o("GPTNeoForCausalLM"),jar=o(" (GPT Neo model)"),Gar=l(),gF=a("li"),wEe=a("strong"),Oar=o("gpt_neox"),Var=o(" \u2014 "),iJ=a("a"),Xar=o("GPTNeoXForCausalLM"),zar=o(" (GPT NeoX model)"),Qar=l(),hF=a("li"),AEe=a("strong"),War=o("gpt_neox_japanese"),Uar=o(" \u2014 "),dJ=a("a"),Har=o("GPTNeoXJapaneseForCausalLM"),Jar=o(" (GPT NeoX Japanese model)"),Yar=l(),uF=a("li"),LEe=a("strong"),Zar=o("gptj"),Kar=o(" \u2014 "),mJ=a("a"),enr=o("GPTJForCausalLM"),onr=o(" (GPT-J model)"),rnr=l(),pF=a("li"),yEe=a("strong"),tnr=o("marian"),anr=o(" \u2014 "),cJ=a("a"),nnr=o("MarianForCausalLM"),snr=o(" (Marian model)"),lnr=l(),_F=a("li"),xEe=a("strong"),inr=o("mbart"),dnr=o(" \u2014 "),fJ=a("a"),mnr=o("MBartForCausalLM"),cnr=o(" (mBART model)"),fnr=l(),bF=a("li"),$Ee=a("strong"),gnr=o("megatron-bert"),hnr=o(" \u2014 "),gJ=a("a"),unr=o("MegatronBertForCausalLM"),pnr=o(" (Megatron-BERT model)"),_nr=l(),vF=a("li"),kEe=a("strong"),bnr=o("mvp"),vnr=o(" \u2014 "),hJ=a("a"),Fnr=o("MvpForCausalLM"),Tnr=o(" (MVP model)"),Mnr=l(),FF=a("li"),SEe=a("strong"),Enr=o("openai-gpt"),Cnr=o(" \u2014 "),uJ=a("a"),wnr=o("OpenAIGPTLMHeadModel"),Anr=o(" (OpenAI GPT model)"),Lnr=l(),TF=a("li"),REe=a("strong"),ynr=o("opt"),xnr=o(" \u2014 "),pJ=a("a"),$nr=o("OPTForCausalLM"),knr=o(" (OPT model)"),Snr=l(),MF=a("li"),PEe=a("strong"),Rnr=o("pegasus"),Pnr=o(" \u2014 "),_J=a("a"),Bnr=o("PegasusForCausalLM"),Inr=o(" (Pegasus model)"),Nnr=l(),EF=a("li"),BEe=a("strong"),qnr=o("plbart"),Dnr=o(" \u2014 "),bJ=a("a"),jnr=o("PLBartForCausalLM"),Gnr=o(" (PLBart model)"),Onr=l(),CF=a("li"),IEe=a("strong"),Vnr=o("prophetnet"),Xnr=o(" \u2014 "),vJ=a("a"),znr=o("ProphetNetForCausalLM"),Qnr=o(" (ProphetNet model)"),Wnr=l(),wF=a("li"),NEe=a("strong"),Unr=o("qdqbert"),Hnr=o(" \u2014 "),FJ=a("a"),Jnr=o("QDQBertLMHeadModel"),Ynr=o(" (QDQBert model)"),Znr=l(),AF=a("li"),qEe=a("strong"),Knr=o("reformer"),esr=o(" \u2014 "),TJ=a("a"),osr=o("ReformerModelWithLMHead"),rsr=o(" (Reformer model)"),tsr=l(),LF=a("li"),DEe=a("strong"),asr=o("rembert"),nsr=o(" \u2014 "),MJ=a("a"),ssr=o("RemBertForCausalLM"),lsr=o(" (RemBERT model)"),isr=l(),yF=a("li"),jEe=a("strong"),dsr=o("roberta"),msr=o(" \u2014 "),EJ=a("a"),csr=o("RobertaForCausalLM"),fsr=o(" (RoBERTa model)"),gsr=l(),xF=a("li"),GEe=a("strong"),hsr=o("roc_bert"),usr=o(" \u2014 "),CJ=a("a"),psr=o("RoCBertForCausalLM"),_sr=o(" (RoCBert model)"),bsr=l(),$F=a("li"),OEe=a("strong"),vsr=o("roformer"),Fsr=o(" \u2014 "),wJ=a("a"),Tsr=o("RoFormerForCausalLM"),Msr=o(" (RoFormer model)"),Esr=l(),kF=a("li"),VEe=a("strong"),Csr=o("speech_to_text_2"),wsr=o(" \u2014 "),AJ=a("a"),Asr=o("Speech2Text2ForCausalLM"),Lsr=o(" (Speech2Text2 model)"),ysr=l(),SF=a("li"),XEe=a("strong"),xsr=o("transfo-xl"),$sr=o(" \u2014 "),LJ=a("a"),ksr=o("TransfoXLLMHeadModel"),Ssr=o(" (Transformer-XL model)"),Rsr=l(),RF=a("li"),zEe=a("strong"),Psr=o("trocr"),Bsr=o(" \u2014 "),yJ=a("a"),Isr=o("TrOCRForCausalLM"),Nsr=o(" (TrOCR model)"),qsr=l(),PF=a("li"),QEe=a("strong"),Dsr=o("xglm"),jsr=o(" \u2014 "),xJ=a("a"),Gsr=o("XGLMForCausalLM"),Osr=o(" (XGLM model)"),Vsr=l(),BF=a("li"),WEe=a("strong"),Xsr=o("xlm"),zsr=o(" \u2014 "),$J=a("a"),Qsr=o("XLMWithLMHeadModel"),Wsr=o(" (XLM model)"),Usr=l(),IF=a("li"),UEe=a("strong"),Hsr=o("xlm-prophetnet"),Jsr=o(" \u2014 "),kJ=a("a"),Ysr=o("XLMProphetNetForCausalLM"),Zsr=o(" (XLM-ProphetNet model)"),Ksr=l(),NF=a("li"),HEe=a("strong"),elr=o("xlm-roberta"),olr=o(" \u2014 "),SJ=a("a"),rlr=o("XLMRobertaForCausalLM"),tlr=o(" (XLM-RoBERTa model)"),alr=l(),qF=a("li"),JEe=a("strong"),nlr=o("xlm-roberta-xl"),slr=o(" \u2014 "),RJ=a("a"),llr=o("XLMRobertaXLForCausalLM"),ilr=o(" (XLM-RoBERTa-XL model)"),dlr=l(),DF=a("li"),YEe=a("strong"),mlr=o("xlnet"),clr=o(" \u2014 "),PJ=a("a"),flr=o("XLNetLMHeadModel"),glr=o(" (XLNet model)"),hlr=l(),jF=a("p"),ulr=o("The model is set in evaluation mode by default using "),ZEe=a("code"),plr=o("model.eval()"),_lr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),KEe=a("code"),blr=o("model.train()"),vlr=l(),F(GF.$$.fragment),Rlo=l(),Jd=a("h2"),OF=a("a"),e4e=a("span"),F(aS.$$.fragment),Flr=l(),o4e=a("span"),Tlr=o("AutoModelForDepthEstimation"),Plo=l(),Vo=a("div"),F(nS.$$.fragment),Mlr=l(),Yd=a("p"),Elr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a depth estimation head) when created
with the `),BJ=a("a"),Clr=o("from_pretrained()"),wlr=o(" class method or the "),IJ=a("a"),Alr=o("from_config()"),Llr=o(` class
method.`),ylr=l(),sS=a("p"),xlr=o("This class cannot be instantiated directly using "),r4e=a("code"),$lr=o("__init__()"),klr=o(" (throws an error)."),Slr=l(),xt=a("div"),F(lS.$$.fragment),Rlr=l(),t4e=a("p"),Plr=o("Instantiates one of the model classes of the library (with a depth estimation head) from a configuration."),Blr=l(),Zd=a("p"),Ilr=o(`Note:
Loading a model from its configuration file does `),a4e=a("strong"),Nlr=o("not"),qlr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),NJ=a("a"),Dlr=o("from_pretrained()"),jlr=o(" to load the model weights."),Glr=l(),F(VF.$$.fragment),Olr=l(),so=a("div"),F(iS.$$.fragment),Vlr=l(),n4e=a("p"),Xlr=o("Instantiate one of the model classes of the library (with a depth estimation head) from a pretrained model."),zlr=l(),un=a("p"),Qlr=o("The model class to instantiate is selected based on the "),s4e=a("code"),Wlr=o("model_type"),Ulr=o(` property of the config object (either
passed as an argument or loaded from `),l4e=a("code"),Hlr=o("pretrained_model_name_or_path"),Jlr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i4e=a("code"),Ylr=o("pretrained_model_name_or_path"),Zlr=o(":"),Klr=l(),dS=a("ul"),XF=a("li"),d4e=a("strong"),eir=o("dpt"),oir=o(" \u2014 "),qJ=a("a"),rir=o("DPTForDepthEstimation"),tir=o(" (DPT model)"),air=l(),zF=a("li"),m4e=a("strong"),nir=o("glpn"),sir=o(" \u2014 "),DJ=a("a"),lir=o("GLPNForDepthEstimation"),iir=o(" (GLPN model)"),dir=l(),QF=a("p"),mir=o("The model is set in evaluation mode by default using "),c4e=a("code"),cir=o("model.eval()"),fir=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),f4e=a("code"),gir=o("model.train()"),hir=l(),F(WF.$$.fragment),Blo=l(),Kd=a("h2"),UF=a("a"),g4e=a("span"),F(mS.$$.fragment),uir=l(),h4e=a("span"),pir=o("AutoModelForMaskedLM"),Ilo=l(),Xo=a("div"),F(cS.$$.fragment),_ir=l(),em=a("p"),bir=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),jJ=a("a"),vir=o("from_pretrained()"),Fir=o(" class method or the "),GJ=a("a"),Tir=o("from_config()"),Mir=o(` class
method.`),Eir=l(),fS=a("p"),Cir=o("This class cannot be instantiated directly using "),u4e=a("code"),wir=o("__init__()"),Air=o(" (throws an error)."),Lir=l(),$t=a("div"),F(gS.$$.fragment),yir=l(),p4e=a("p"),xir=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),$ir=l(),om=a("p"),kir=o(`Note:
Loading a model from its configuration file does `),_4e=a("strong"),Sir=o("not"),Rir=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),OJ=a("a"),Pir=o("from_pretrained()"),Bir=o(" to load the model weights."),Iir=l(),F(HF.$$.fragment),Nir=l(),lo=a("div"),F(hS.$$.fragment),qir=l(),b4e=a("p"),Dir=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),jir=l(),pn=a("p"),Gir=o("The model class to instantiate is selected based on the "),v4e=a("code"),Oir=o("model_type"),Vir=o(` property of the config object (either
passed as an argument or loaded from `),F4e=a("code"),Xir=o("pretrained_model_name_or_path"),zir=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T4e=a("code"),Qir=o("pretrained_model_name_or_path"),Wir=o(":"),Uir=l(),Y=a("ul"),JF=a("li"),M4e=a("strong"),Hir=o("albert"),Jir=o(" \u2014 "),VJ=a("a"),Yir=o("AlbertForMaskedLM"),Zir=o(" (ALBERT model)"),Kir=l(),YF=a("li"),E4e=a("strong"),edr=o("bart"),odr=o(" \u2014 "),XJ=a("a"),rdr=o("BartForConditionalGeneration"),tdr=o(" (BART model)"),adr=l(),ZF=a("li"),C4e=a("strong"),ndr=o("bert"),sdr=o(" \u2014 "),zJ=a("a"),ldr=o("BertForMaskedLM"),idr=o(" (BERT model)"),ddr=l(),KF=a("li"),w4e=a("strong"),mdr=o("big_bird"),cdr=o(" \u2014 "),QJ=a("a"),fdr=o("BigBirdForMaskedLM"),gdr=o(" (BigBird model)"),hdr=l(),eT=a("li"),A4e=a("strong"),udr=o("camembert"),pdr=o(" \u2014 "),WJ=a("a"),_dr=o("CamembertForMaskedLM"),bdr=o(" (CamemBERT model)"),vdr=l(),oT=a("li"),L4e=a("strong"),Fdr=o("convbert"),Tdr=o(" \u2014 "),UJ=a("a"),Mdr=o("ConvBertForMaskedLM"),Edr=o(" (ConvBERT model)"),Cdr=l(),rT=a("li"),y4e=a("strong"),wdr=o("data2vec-text"),Adr=o(" \u2014 "),HJ=a("a"),Ldr=o("Data2VecTextForMaskedLM"),ydr=o(" (Data2VecText model)"),xdr=l(),tT=a("li"),x4e=a("strong"),$dr=o("deberta"),kdr=o(" \u2014 "),JJ=a("a"),Sdr=o("DebertaForMaskedLM"),Rdr=o(" (DeBERTa model)"),Pdr=l(),aT=a("li"),$4e=a("strong"),Bdr=o("deberta-v2"),Idr=o(" \u2014 "),YJ=a("a"),Ndr=o("DebertaV2ForMaskedLM"),qdr=o(" (DeBERTa-v2 model)"),Ddr=l(),nT=a("li"),k4e=a("strong"),jdr=o("distilbert"),Gdr=o(" \u2014 "),ZJ=a("a"),Odr=o("DistilBertForMaskedLM"),Vdr=o(" (DistilBERT model)"),Xdr=l(),sT=a("li"),S4e=a("strong"),zdr=o("electra"),Qdr=o(" \u2014 "),KJ=a("a"),Wdr=o("ElectraForMaskedLM"),Udr=o(" (ELECTRA model)"),Hdr=l(),lT=a("li"),R4e=a("strong"),Jdr=o("ernie"),Ydr=o(" \u2014 "),eY=a("a"),Zdr=o("ErnieForMaskedLM"),Kdr=o(" (ERNIE model)"),emr=l(),iT=a("li"),P4e=a("strong"),omr=o("flaubert"),rmr=o(" \u2014 "),oY=a("a"),tmr=o("FlaubertWithLMHeadModel"),amr=o(" (FlauBERT model)"),nmr=l(),dT=a("li"),B4e=a("strong"),smr=o("fnet"),lmr=o(" \u2014 "),rY=a("a"),imr=o("FNetForMaskedLM"),dmr=o(" (FNet model)"),mmr=l(),mT=a("li"),I4e=a("strong"),cmr=o("funnel"),fmr=o(" \u2014 "),tY=a("a"),gmr=o("FunnelForMaskedLM"),hmr=o(" (Funnel Transformer model)"),umr=l(),cT=a("li"),N4e=a("strong"),pmr=o("ibert"),_mr=o(" \u2014 "),aY=a("a"),bmr=o("IBertForMaskedLM"),vmr=o(" (I-BERT model)"),Fmr=l(),fT=a("li"),q4e=a("strong"),Tmr=o("layoutlm"),Mmr=o(" \u2014 "),nY=a("a"),Emr=o("LayoutLMForMaskedLM"),Cmr=o(" (LayoutLM model)"),wmr=l(),gT=a("li"),D4e=a("strong"),Amr=o("longformer"),Lmr=o(" \u2014 "),sY=a("a"),ymr=o("LongformerForMaskedLM"),xmr=o(" (Longformer model)"),$mr=l(),hT=a("li"),j4e=a("strong"),kmr=o("luke"),Smr=o(" \u2014 "),lY=a("a"),Rmr=o("LukeForMaskedLM"),Pmr=o(" (LUKE model)"),Bmr=l(),uT=a("li"),G4e=a("strong"),Imr=o("mbart"),Nmr=o(" \u2014 "),iY=a("a"),qmr=o("MBartForConditionalGeneration"),Dmr=o(" (mBART model)"),jmr=l(),pT=a("li"),O4e=a("strong"),Gmr=o("megatron-bert"),Omr=o(" \u2014 "),dY=a("a"),Vmr=o("MegatronBertForMaskedLM"),Xmr=o(" (Megatron-BERT model)"),zmr=l(),_T=a("li"),V4e=a("strong"),Qmr=o("mobilebert"),Wmr=o(" \u2014 "),mY=a("a"),Umr=o("MobileBertForMaskedLM"),Hmr=o(" (MobileBERT model)"),Jmr=l(),bT=a("li"),X4e=a("strong"),Ymr=o("mpnet"),Zmr=o(" \u2014 "),cY=a("a"),Kmr=o("MPNetForMaskedLM"),ecr=o(" (MPNet model)"),ocr=l(),vT=a("li"),z4e=a("strong"),rcr=o("mvp"),tcr=o(" \u2014 "),fY=a("a"),acr=o("MvpForConditionalGeneration"),ncr=o(" (MVP model)"),scr=l(),FT=a("li"),Q4e=a("strong"),lcr=o("nezha"),icr=o(" \u2014 "),gY=a("a"),dcr=o("NezhaForMaskedLM"),mcr=o(" (Nezha model)"),ccr=l(),TT=a("li"),W4e=a("strong"),fcr=o("nystromformer"),gcr=o(" \u2014 "),hY=a("a"),hcr=o("NystromformerForMaskedLM"),ucr=o(" (Nystr\xF6mformer model)"),pcr=l(),MT=a("li"),U4e=a("strong"),_cr=o("perceiver"),bcr=o(" \u2014 "),uY=a("a"),vcr=o("PerceiverForMaskedLM"),Fcr=o(" (Perceiver model)"),Tcr=l(),ET=a("li"),H4e=a("strong"),Mcr=o("qdqbert"),Ecr=o(" \u2014 "),pY=a("a"),Ccr=o("QDQBertForMaskedLM"),wcr=o(" (QDQBert model)"),Acr=l(),CT=a("li"),J4e=a("strong"),Lcr=o("reformer"),ycr=o(" \u2014 "),_Y=a("a"),xcr=o("ReformerForMaskedLM"),$cr=o(" (Reformer model)"),kcr=l(),wT=a("li"),Y4e=a("strong"),Scr=o("rembert"),Rcr=o(" \u2014 "),bY=a("a"),Pcr=o("RemBertForMaskedLM"),Bcr=o(" (RemBERT model)"),Icr=l(),AT=a("li"),Z4e=a("strong"),Ncr=o("roberta"),qcr=o(" \u2014 "),vY=a("a"),Dcr=o("RobertaForMaskedLM"),jcr=o(" (RoBERTa model)"),Gcr=l(),LT=a("li"),K4e=a("strong"),Ocr=o("roc_bert"),Vcr=o(" \u2014 "),FY=a("a"),Xcr=o("RoCBertForMaskedLM"),zcr=o(" (RoCBert model)"),Qcr=l(),yT=a("li"),eCe=a("strong"),Wcr=o("roformer"),Ucr=o(" \u2014 "),TY=a("a"),Hcr=o("RoFormerForMaskedLM"),Jcr=o(" (RoFormer model)"),Ycr=l(),xT=a("li"),oCe=a("strong"),Zcr=o("squeezebert"),Kcr=o(" \u2014 "),MY=a("a"),efr=o("SqueezeBertForMaskedLM"),ofr=o(" (SqueezeBERT model)"),rfr=l(),$T=a("li"),rCe=a("strong"),tfr=o("tapas"),afr=o(" \u2014 "),EY=a("a"),nfr=o("TapasForMaskedLM"),sfr=o(" (TAPAS model)"),lfr=l(),kT=a("li"),tCe=a("strong"),ifr=o("wav2vec2"),dfr=o(" \u2014 "),aCe=a("code"),mfr=o("Wav2Vec2ForMaskedLM"),cfr=o(" (Wav2Vec2 model)"),ffr=l(),ST=a("li"),nCe=a("strong"),gfr=o("xlm"),hfr=o(" \u2014 "),CY=a("a"),ufr=o("XLMWithLMHeadModel"),pfr=o(" (XLM model)"),_fr=l(),RT=a("li"),sCe=a("strong"),bfr=o("xlm-roberta"),vfr=o(" \u2014 "),wY=a("a"),Ffr=o("XLMRobertaForMaskedLM"),Tfr=o(" (XLM-RoBERTa model)"),Mfr=l(),PT=a("li"),lCe=a("strong"),Efr=o("xlm-roberta-xl"),Cfr=o(" \u2014 "),AY=a("a"),wfr=o("XLMRobertaXLForMaskedLM"),Afr=o(" (XLM-RoBERTa-XL model)"),Lfr=l(),BT=a("li"),iCe=a("strong"),yfr=o("yoso"),xfr=o(" \u2014 "),LY=a("a"),$fr=o("YosoForMaskedLM"),kfr=o(" (YOSO model)"),Sfr=l(),IT=a("p"),Rfr=o("The model is set in evaluation mode by default using "),dCe=a("code"),Pfr=o("model.eval()"),Bfr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mCe=a("code"),Ifr=o("model.train()"),Nfr=l(),F(NT.$$.fragment),Nlo=l(),rm=a("h2"),qT=a("a"),cCe=a("span"),F(uS.$$.fragment),qfr=l(),fCe=a("span"),Dfr=o("AutoModelForSeq2SeqLM"),qlo=l(),zo=a("div"),F(pS.$$.fragment),jfr=l(),tm=a("p"),Gfr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),yY=a("a"),Ofr=o("from_pretrained()"),Vfr=o(" class method or the "),xY=a("a"),Xfr=o("from_config()"),zfr=o(` class
method.`),Qfr=l(),_S=a("p"),Wfr=o("This class cannot be instantiated directly using "),gCe=a("code"),Ufr=o("__init__()"),Hfr=o(" (throws an error)."),Jfr=l(),kt=a("div"),F(bS.$$.fragment),Yfr=l(),hCe=a("p"),Zfr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Kfr=l(),am=a("p"),egr=o(`Note:
Loading a model from its configuration file does `),uCe=a("strong"),ogr=o("not"),rgr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$Y=a("a"),tgr=o("from_pretrained()"),agr=o(" to load the model weights."),ngr=l(),F(DT.$$.fragment),sgr=l(),io=a("div"),F(vS.$$.fragment),lgr=l(),pCe=a("p"),igr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),dgr=l(),_n=a("p"),mgr=o("The model class to instantiate is selected based on the "),_Ce=a("code"),cgr=o("model_type"),fgr=o(` property of the config object (either
passed as an argument or loaded from `),bCe=a("code"),ggr=o("pretrained_model_name_or_path"),hgr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vCe=a("code"),ugr=o("pretrained_model_name_or_path"),pgr=o(":"),_gr=l(),pe=a("ul"),jT=a("li"),FCe=a("strong"),bgr=o("bart"),vgr=o(" \u2014 "),kY=a("a"),Fgr=o("BartForConditionalGeneration"),Tgr=o(" (BART model)"),Mgr=l(),GT=a("li"),TCe=a("strong"),Egr=o("bigbird_pegasus"),Cgr=o(" \u2014 "),SY=a("a"),wgr=o("BigBirdPegasusForConditionalGeneration"),Agr=o(" (BigBird-Pegasus model)"),Lgr=l(),OT=a("li"),MCe=a("strong"),ygr=o("blenderbot"),xgr=o(" \u2014 "),RY=a("a"),$gr=o("BlenderbotForConditionalGeneration"),kgr=o(" (Blenderbot model)"),Sgr=l(),VT=a("li"),ECe=a("strong"),Rgr=o("blenderbot-small"),Pgr=o(" \u2014 "),PY=a("a"),Bgr=o("BlenderbotSmallForConditionalGeneration"),Igr=o(" (BlenderbotSmall model)"),Ngr=l(),XT=a("li"),CCe=a("strong"),qgr=o("encoder-decoder"),Dgr=o(" \u2014 "),BY=a("a"),jgr=o("EncoderDecoderModel"),Ggr=o(" (Encoder decoder model)"),Ogr=l(),zT=a("li"),wCe=a("strong"),Vgr=o("fsmt"),Xgr=o(" \u2014 "),IY=a("a"),zgr=o("FSMTForConditionalGeneration"),Qgr=o(" (FairSeq Machine-Translation model)"),Wgr=l(),QT=a("li"),ACe=a("strong"),Ugr=o("led"),Hgr=o(" \u2014 "),NY=a("a"),Jgr=o("LEDForConditionalGeneration"),Ygr=o(" (LED model)"),Zgr=l(),WT=a("li"),LCe=a("strong"),Kgr=o("longt5"),ehr=o(" \u2014 "),qY=a("a"),ohr=o("LongT5ForConditionalGeneration"),rhr=o(" (LongT5 model)"),thr=l(),UT=a("li"),yCe=a("strong"),ahr=o("m2m_100"),nhr=o(" \u2014 "),DY=a("a"),shr=o("M2M100ForConditionalGeneration"),lhr=o(" (M2M100 model)"),ihr=l(),HT=a("li"),xCe=a("strong"),dhr=o("marian"),mhr=o(" \u2014 "),jY=a("a"),chr=o("MarianMTModel"),fhr=o(" (Marian model)"),ghr=l(),JT=a("li"),$Ce=a("strong"),hhr=o("mbart"),uhr=o(" \u2014 "),GY=a("a"),phr=o("MBartForConditionalGeneration"),_hr=o(" (mBART model)"),bhr=l(),YT=a("li"),kCe=a("strong"),vhr=o("mt5"),Fhr=o(" \u2014 "),OY=a("a"),Thr=o("MT5ForConditionalGeneration"),Mhr=o(" (MT5 model)"),Ehr=l(),ZT=a("li"),SCe=a("strong"),Chr=o("mvp"),whr=o(" \u2014 "),VY=a("a"),Ahr=o("MvpForConditionalGeneration"),Lhr=o(" (MVP model)"),yhr=l(),KT=a("li"),RCe=a("strong"),xhr=o("nllb"),$hr=o(" \u2014 "),XY=a("a"),khr=o("M2M100ForConditionalGeneration"),Shr=o(" (NLLB model)"),Rhr=l(),eM=a("li"),PCe=a("strong"),Phr=o("pegasus"),Bhr=o(" \u2014 "),zY=a("a"),Ihr=o("PegasusForConditionalGeneration"),Nhr=o(" (Pegasus model)"),qhr=l(),oM=a("li"),BCe=a("strong"),Dhr=o("pegasus_x"),jhr=o(" \u2014 "),QY=a("a"),Ghr=o("PegasusXForConditionalGeneration"),Ohr=o(" (PEGASUS-X model)"),Vhr=l(),rM=a("li"),ICe=a("strong"),Xhr=o("plbart"),zhr=o(" \u2014 "),WY=a("a"),Qhr=o("PLBartForConditionalGeneration"),Whr=o(" (PLBart model)"),Uhr=l(),tM=a("li"),NCe=a("strong"),Hhr=o("prophetnet"),Jhr=o(" \u2014 "),UY=a("a"),Yhr=o("ProphetNetForConditionalGeneration"),Zhr=o(" (ProphetNet model)"),Khr=l(),aM=a("li"),qCe=a("strong"),eur=o("t5"),our=o(" \u2014 "),HY=a("a"),rur=o("T5ForConditionalGeneration"),tur=o(" (T5 model)"),aur=l(),nM=a("li"),DCe=a("strong"),nur=o("xlm-prophetnet"),sur=o(" \u2014 "),JY=a("a"),lur=o("XLMProphetNetForConditionalGeneration"),iur=o(" (XLM-ProphetNet model)"),dur=l(),sM=a("p"),mur=o("The model is set in evaluation mode by default using "),jCe=a("code"),cur=o("model.eval()"),fur=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),GCe=a("code"),gur=o("model.train()"),hur=l(),F(lM.$$.fragment),Dlo=l(),nm=a("h2"),iM=a("a"),OCe=a("span"),F(FS.$$.fragment),uur=l(),VCe=a("span"),pur=o("AutoModelForSequenceClassification"),jlo=l(),Qo=a("div"),F(TS.$$.fragment),_ur=l(),sm=a("p"),bur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),YY=a("a"),vur=o("from_pretrained()"),Fur=o(" class method or the "),ZY=a("a"),Tur=o("from_config()"),Mur=o(` class
method.`),Eur=l(),MS=a("p"),Cur=o("This class cannot be instantiated directly using "),XCe=a("code"),wur=o("__init__()"),Aur=o(" (throws an error)."),Lur=l(),St=a("div"),F(ES.$$.fragment),yur=l(),zCe=a("p"),xur=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),$ur=l(),lm=a("p"),kur=o(`Note:
Loading a model from its configuration file does `),QCe=a("strong"),Sur=o("not"),Rur=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),KY=a("a"),Pur=o("from_pretrained()"),Bur=o(" to load the model weights."),Iur=l(),F(dM.$$.fragment),Nur=l(),mo=a("div"),F(CS.$$.fragment),qur=l(),WCe=a("p"),Dur=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),jur=l(),bn=a("p"),Gur=o("The model class to instantiate is selected based on the "),UCe=a("code"),Our=o("model_type"),Vur=o(` property of the config object (either
passed as an argument or loaded from `),HCe=a("code"),Xur=o("pretrained_model_name_or_path"),zur=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JCe=a("code"),Qur=o("pretrained_model_name_or_path"),Wur=o(":"),Uur=l(),I=a("ul"),mM=a("li"),YCe=a("strong"),Hur=o("albert"),Jur=o(" \u2014 "),eZ=a("a"),Yur=o("AlbertForSequenceClassification"),Zur=o(" (ALBERT model)"),Kur=l(),cM=a("li"),ZCe=a("strong"),epr=o("bart"),opr=o(" \u2014 "),oZ=a("a"),rpr=o("BartForSequenceClassification"),tpr=o(" (BART model)"),apr=l(),fM=a("li"),KCe=a("strong"),npr=o("bert"),spr=o(" \u2014 "),rZ=a("a"),lpr=o("BertForSequenceClassification"),ipr=o(" (BERT model)"),dpr=l(),gM=a("li"),e3e=a("strong"),mpr=o("big_bird"),cpr=o(" \u2014 "),tZ=a("a"),fpr=o("BigBirdForSequenceClassification"),gpr=o(" (BigBird model)"),hpr=l(),hM=a("li"),o3e=a("strong"),upr=o("bigbird_pegasus"),ppr=o(" \u2014 "),aZ=a("a"),_pr=o("BigBirdPegasusForSequenceClassification"),bpr=o(" (BigBird-Pegasus model)"),vpr=l(),uM=a("li"),r3e=a("strong"),Fpr=o("bloom"),Tpr=o(" \u2014 "),nZ=a("a"),Mpr=o("BloomForSequenceClassification"),Epr=o(" (BLOOM model)"),Cpr=l(),pM=a("li"),t3e=a("strong"),wpr=o("camembert"),Apr=o(" \u2014 "),sZ=a("a"),Lpr=o("CamembertForSequenceClassification"),ypr=o(" (CamemBERT model)"),xpr=l(),_M=a("li"),a3e=a("strong"),$pr=o("canine"),kpr=o(" \u2014 "),lZ=a("a"),Spr=o("CanineForSequenceClassification"),Rpr=o(" (CANINE model)"),Ppr=l(),bM=a("li"),n3e=a("strong"),Bpr=o("convbert"),Ipr=o(" \u2014 "),iZ=a("a"),Npr=o("ConvBertForSequenceClassification"),qpr=o(" (ConvBERT model)"),Dpr=l(),vM=a("li"),s3e=a("strong"),jpr=o("ctrl"),Gpr=o(" \u2014 "),dZ=a("a"),Opr=o("CTRLForSequenceClassification"),Vpr=o(" (CTRL model)"),Xpr=l(),FM=a("li"),l3e=a("strong"),zpr=o("data2vec-text"),Qpr=o(" \u2014 "),mZ=a("a"),Wpr=o("Data2VecTextForSequenceClassification"),Upr=o(" (Data2VecText model)"),Hpr=l(),TM=a("li"),i3e=a("strong"),Jpr=o("deberta"),Ypr=o(" \u2014 "),cZ=a("a"),Zpr=o("DebertaForSequenceClassification"),Kpr=o(" (DeBERTa model)"),e_r=l(),MM=a("li"),d3e=a("strong"),o_r=o("deberta-v2"),r_r=o(" \u2014 "),fZ=a("a"),t_r=o("DebertaV2ForSequenceClassification"),a_r=o(" (DeBERTa-v2 model)"),n_r=l(),EM=a("li"),m3e=a("strong"),s_r=o("distilbert"),l_r=o(" \u2014 "),gZ=a("a"),i_r=o("DistilBertForSequenceClassification"),d_r=o(" (DistilBERT model)"),m_r=l(),CM=a("li"),c3e=a("strong"),c_r=o("electra"),f_r=o(" \u2014 "),hZ=a("a"),g_r=o("ElectraForSequenceClassification"),h_r=o(" (ELECTRA model)"),u_r=l(),wM=a("li"),f3e=a("strong"),p_r=o("ernie"),__r=o(" \u2014 "),uZ=a("a"),b_r=o("ErnieForSequenceClassification"),v_r=o(" (ERNIE model)"),F_r=l(),AM=a("li"),g3e=a("strong"),T_r=o("esm"),M_r=o(" \u2014 "),pZ=a("a"),E_r=o("EsmForSequenceClassification"),C_r=o(" (ESM model)"),w_r=l(),LM=a("li"),h3e=a("strong"),A_r=o("flaubert"),L_r=o(" \u2014 "),_Z=a("a"),y_r=o("FlaubertForSequenceClassification"),x_r=o(" (FlauBERT model)"),$_r=l(),yM=a("li"),u3e=a("strong"),k_r=o("fnet"),S_r=o(" \u2014 "),bZ=a("a"),R_r=o("FNetForSequenceClassification"),P_r=o(" (FNet model)"),B_r=l(),xM=a("li"),p3e=a("strong"),I_r=o("funnel"),N_r=o(" \u2014 "),vZ=a("a"),q_r=o("FunnelForSequenceClassification"),D_r=o(" (Funnel Transformer model)"),j_r=l(),$M=a("li"),_3e=a("strong"),G_r=o("gpt2"),O_r=o(" \u2014 "),FZ=a("a"),V_r=o("GPT2ForSequenceClassification"),X_r=o(" (OpenAI GPT-2 model)"),z_r=l(),kM=a("li"),b3e=a("strong"),Q_r=o("gpt_neo"),W_r=o(" \u2014 "),TZ=a("a"),U_r=o("GPTNeoForSequenceClassification"),H_r=o(" (GPT Neo model)"),J_r=l(),SM=a("li"),v3e=a("strong"),Y_r=o("gptj"),Z_r=o(" \u2014 "),MZ=a("a"),K_r=o("GPTJForSequenceClassification"),e1r=o(" (GPT-J model)"),o1r=l(),RM=a("li"),F3e=a("strong"),r1r=o("ibert"),t1r=o(" \u2014 "),EZ=a("a"),a1r=o("IBertForSequenceClassification"),n1r=o(" (I-BERT model)"),s1r=l(),PM=a("li"),T3e=a("strong"),l1r=o("layoutlm"),i1r=o(" \u2014 "),CZ=a("a"),d1r=o("LayoutLMForSequenceClassification"),m1r=o(" (LayoutLM model)"),c1r=l(),BM=a("li"),M3e=a("strong"),f1r=o("layoutlmv2"),g1r=o(" \u2014 "),wZ=a("a"),h1r=o("LayoutLMv2ForSequenceClassification"),u1r=o(" (LayoutLMv2 model)"),p1r=l(),IM=a("li"),E3e=a("strong"),_1r=o("layoutlmv3"),b1r=o(" \u2014 "),AZ=a("a"),v1r=o("LayoutLMv3ForSequenceClassification"),F1r=o(" (LayoutLMv3 model)"),T1r=l(),NM=a("li"),C3e=a("strong"),M1r=o("led"),E1r=o(" \u2014 "),LZ=a("a"),C1r=o("LEDForSequenceClassification"),w1r=o(" (LED model)"),A1r=l(),qM=a("li"),w3e=a("strong"),L1r=o("lilt"),y1r=o(" \u2014 "),yZ=a("a"),x1r=o("LiltForSequenceClassification"),$1r=o(" (LiLT model)"),k1r=l(),DM=a("li"),A3e=a("strong"),S1r=o("longformer"),R1r=o(" \u2014 "),xZ=a("a"),P1r=o("LongformerForSequenceClassification"),B1r=o(" (Longformer model)"),I1r=l(),jM=a("li"),L3e=a("strong"),N1r=o("luke"),q1r=o(" \u2014 "),$Z=a("a"),D1r=o("LukeForSequenceClassification"),j1r=o(" (LUKE model)"),G1r=l(),GM=a("li"),y3e=a("strong"),O1r=o("markuplm"),V1r=o(" \u2014 "),kZ=a("a"),X1r=o("MarkupLMForSequenceClassification"),z1r=o(" (MarkupLM model)"),Q1r=l(),OM=a("li"),x3e=a("strong"),W1r=o("mbart"),U1r=o(" \u2014 "),SZ=a("a"),H1r=o("MBartForSequenceClassification"),J1r=o(" (mBART model)"),Y1r=l(),VM=a("li"),$3e=a("strong"),Z1r=o("megatron-bert"),K1r=o(" \u2014 "),RZ=a("a"),e2r=o("MegatronBertForSequenceClassification"),o2r=o(" (Megatron-BERT model)"),r2r=l(),XM=a("li"),k3e=a("strong"),t2r=o("mobilebert"),a2r=o(" \u2014 "),PZ=a("a"),n2r=o("MobileBertForSequenceClassification"),s2r=o(" (MobileBERT model)"),l2r=l(),zM=a("li"),S3e=a("strong"),i2r=o("mpnet"),d2r=o(" \u2014 "),BZ=a("a"),m2r=o("MPNetForSequenceClassification"),c2r=o(" (MPNet model)"),f2r=l(),QM=a("li"),R3e=a("strong"),g2r=o("mvp"),h2r=o(" \u2014 "),IZ=a("a"),u2r=o("MvpForSequenceClassification"),p2r=o(" (MVP model)"),_2r=l(),WM=a("li"),P3e=a("strong"),b2r=o("nezha"),v2r=o(" \u2014 "),NZ=a("a"),F2r=o("NezhaForSequenceClassification"),T2r=o(" (Nezha model)"),M2r=l(),UM=a("li"),B3e=a("strong"),E2r=o("nystromformer"),C2r=o(" \u2014 "),qZ=a("a"),w2r=o("NystromformerForSequenceClassification"),A2r=o(" (Nystr\xF6mformer model)"),L2r=l(),HM=a("li"),I3e=a("strong"),y2r=o("openai-gpt"),x2r=o(" \u2014 "),DZ=a("a"),$2r=o("OpenAIGPTForSequenceClassification"),k2r=o(" (OpenAI GPT model)"),S2r=l(),JM=a("li"),N3e=a("strong"),R2r=o("opt"),P2r=o(" \u2014 "),jZ=a("a"),B2r=o("OPTForSequenceClassification"),I2r=o(" (OPT model)"),N2r=l(),YM=a("li"),q3e=a("strong"),q2r=o("perceiver"),D2r=o(" \u2014 "),GZ=a("a"),j2r=o("PerceiverForSequenceClassification"),G2r=o(" (Perceiver model)"),O2r=l(),ZM=a("li"),D3e=a("strong"),V2r=o("plbart"),X2r=o(" \u2014 "),OZ=a("a"),z2r=o("PLBartForSequenceClassification"),Q2r=o(" (PLBart model)"),W2r=l(),KM=a("li"),j3e=a("strong"),U2r=o("qdqbert"),H2r=o(" \u2014 "),VZ=a("a"),J2r=o("QDQBertForSequenceClassification"),Y2r=o(" (QDQBert model)"),Z2r=l(),eE=a("li"),G3e=a("strong"),K2r=o("reformer"),ebr=o(" \u2014 "),XZ=a("a"),obr=o("ReformerForSequenceClassification"),rbr=o(" (Reformer model)"),tbr=l(),oE=a("li"),O3e=a("strong"),abr=o("rembert"),nbr=o(" \u2014 "),zZ=a("a"),sbr=o("RemBertForSequenceClassification"),lbr=o(" (RemBERT model)"),ibr=l(),rE=a("li"),V3e=a("strong"),dbr=o("roberta"),mbr=o(" \u2014 "),QZ=a("a"),cbr=o("RobertaForSequenceClassification"),fbr=o(" (RoBERTa model)"),gbr=l(),tE=a("li"),X3e=a("strong"),hbr=o("roc_bert"),ubr=o(" \u2014 "),WZ=a("a"),pbr=o("RoCBertForSequenceClassification"),_br=o(" (RoCBert model)"),bbr=l(),aE=a("li"),z3e=a("strong"),vbr=o("roformer"),Fbr=o(" \u2014 "),UZ=a("a"),Tbr=o("RoFormerForSequenceClassification"),Mbr=o(" (RoFormer model)"),Ebr=l(),nE=a("li"),Q3e=a("strong"),Cbr=o("squeezebert"),wbr=o(" \u2014 "),HZ=a("a"),Abr=o("SqueezeBertForSequenceClassification"),Lbr=o(" (SqueezeBERT model)"),ybr=l(),sE=a("li"),W3e=a("strong"),xbr=o("tapas"),$br=o(" \u2014 "),JZ=a("a"),kbr=o("TapasForSequenceClassification"),Sbr=o(" (TAPAS model)"),Rbr=l(),lE=a("li"),U3e=a("strong"),Pbr=o("transfo-xl"),Bbr=o(" \u2014 "),YZ=a("a"),Ibr=o("TransfoXLForSequenceClassification"),Nbr=o(" (Transformer-XL model)"),qbr=l(),iE=a("li"),H3e=a("strong"),Dbr=o("xlm"),jbr=o(" \u2014 "),ZZ=a("a"),Gbr=o("XLMForSequenceClassification"),Obr=o(" (XLM model)"),Vbr=l(),dE=a("li"),J3e=a("strong"),Xbr=o("xlm-roberta"),zbr=o(" \u2014 "),KZ=a("a"),Qbr=o("XLMRobertaForSequenceClassification"),Wbr=o(" (XLM-RoBERTa model)"),Ubr=l(),mE=a("li"),Y3e=a("strong"),Hbr=o("xlm-roberta-xl"),Jbr=o(" \u2014 "),eK=a("a"),Ybr=o("XLMRobertaXLForSequenceClassification"),Zbr=o(" (XLM-RoBERTa-XL model)"),Kbr=l(),cE=a("li"),Z3e=a("strong"),evr=o("xlnet"),ovr=o(" \u2014 "),oK=a("a"),rvr=o("XLNetForSequenceClassification"),tvr=o(" (XLNet model)"),avr=l(),fE=a("li"),K3e=a("strong"),nvr=o("yoso"),svr=o(" \u2014 "),rK=a("a"),lvr=o("YosoForSequenceClassification"),ivr=o(" (YOSO model)"),dvr=l(),gE=a("p"),mvr=o("The model is set in evaluation mode by default using "),e5e=a("code"),cvr=o("model.eval()"),fvr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o5e=a("code"),gvr=o("model.train()"),hvr=l(),F(hE.$$.fragment),Glo=l(),im=a("h2"),uE=a("a"),r5e=a("span"),F(wS.$$.fragment),uvr=l(),t5e=a("span"),pvr=o("AutoModelForMultipleChoice"),Olo=l(),Wo=a("div"),F(AS.$$.fragment),_vr=l(),dm=a("p"),bvr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),tK=a("a"),vvr=o("from_pretrained()"),Fvr=o(" class method or the "),aK=a("a"),Tvr=o("from_config()"),Mvr=o(` class
method.`),Evr=l(),LS=a("p"),Cvr=o("This class cannot be instantiated directly using "),a5e=a("code"),wvr=o("__init__()"),Avr=o(" (throws an error)."),Lvr=l(),Rt=a("div"),F(yS.$$.fragment),yvr=l(),n5e=a("p"),xvr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),$vr=l(),mm=a("p"),kvr=o(`Note:
Loading a model from its configuration file does `),s5e=a("strong"),Svr=o("not"),Rvr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nK=a("a"),Pvr=o("from_pretrained()"),Bvr=o(" to load the model weights."),Ivr=l(),F(pE.$$.fragment),Nvr=l(),co=a("div"),F(xS.$$.fragment),qvr=l(),l5e=a("p"),Dvr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),jvr=l(),vn=a("p"),Gvr=o("The model class to instantiate is selected based on the "),i5e=a("code"),Ovr=o("model_type"),Vvr=o(` property of the config object (either
passed as an argument or loaded from `),d5e=a("code"),Xvr=o("pretrained_model_name_or_path"),zvr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m5e=a("code"),Qvr=o("pretrained_model_name_or_path"),Wvr=o(":"),Uvr=l(),K=a("ul"),_E=a("li"),c5e=a("strong"),Hvr=o("albert"),Jvr=o(" \u2014 "),sK=a("a"),Yvr=o("AlbertForMultipleChoice"),Zvr=o(" (ALBERT model)"),Kvr=l(),bE=a("li"),f5e=a("strong"),eFr=o("bert"),oFr=o(" \u2014 "),lK=a("a"),rFr=o("BertForMultipleChoice"),tFr=o(" (BERT model)"),aFr=l(),vE=a("li"),g5e=a("strong"),nFr=o("big_bird"),sFr=o(" \u2014 "),iK=a("a"),lFr=o("BigBirdForMultipleChoice"),iFr=o(" (BigBird model)"),dFr=l(),FE=a("li"),h5e=a("strong"),mFr=o("camembert"),cFr=o(" \u2014 "),dK=a("a"),fFr=o("CamembertForMultipleChoice"),gFr=o(" (CamemBERT model)"),hFr=l(),TE=a("li"),u5e=a("strong"),uFr=o("canine"),pFr=o(" \u2014 "),mK=a("a"),_Fr=o("CanineForMultipleChoice"),bFr=o(" (CANINE model)"),vFr=l(),ME=a("li"),p5e=a("strong"),FFr=o("convbert"),TFr=o(" \u2014 "),cK=a("a"),MFr=o("ConvBertForMultipleChoice"),EFr=o(" (ConvBERT model)"),CFr=l(),EE=a("li"),_5e=a("strong"),wFr=o("data2vec-text"),AFr=o(" \u2014 "),fK=a("a"),LFr=o("Data2VecTextForMultipleChoice"),yFr=o(" (Data2VecText model)"),xFr=l(),CE=a("li"),b5e=a("strong"),$Fr=o("deberta-v2"),kFr=o(" \u2014 "),gK=a("a"),SFr=o("DebertaV2ForMultipleChoice"),RFr=o(" (DeBERTa-v2 model)"),PFr=l(),wE=a("li"),v5e=a("strong"),BFr=o("distilbert"),IFr=o(" \u2014 "),hK=a("a"),NFr=o("DistilBertForMultipleChoice"),qFr=o(" (DistilBERT model)"),DFr=l(),AE=a("li"),F5e=a("strong"),jFr=o("electra"),GFr=o(" \u2014 "),uK=a("a"),OFr=o("ElectraForMultipleChoice"),VFr=o(" (ELECTRA model)"),XFr=l(),LE=a("li"),T5e=a("strong"),zFr=o("ernie"),QFr=o(" \u2014 "),pK=a("a"),WFr=o("ErnieForMultipleChoice"),UFr=o(" (ERNIE model)"),HFr=l(),yE=a("li"),M5e=a("strong"),JFr=o("flaubert"),YFr=o(" \u2014 "),_K=a("a"),ZFr=o("FlaubertForMultipleChoice"),KFr=o(" (FlauBERT model)"),eTr=l(),xE=a("li"),E5e=a("strong"),oTr=o("fnet"),rTr=o(" \u2014 "),bK=a("a"),tTr=o("FNetForMultipleChoice"),aTr=o(" (FNet model)"),nTr=l(),$E=a("li"),C5e=a("strong"),sTr=o("funnel"),lTr=o(" \u2014 "),vK=a("a"),iTr=o("FunnelForMultipleChoice"),dTr=o(" (Funnel Transformer model)"),mTr=l(),kE=a("li"),w5e=a("strong"),cTr=o("ibert"),fTr=o(" \u2014 "),FK=a("a"),gTr=o("IBertForMultipleChoice"),hTr=o(" (I-BERT model)"),uTr=l(),SE=a("li"),A5e=a("strong"),pTr=o("longformer"),_Tr=o(" \u2014 "),TK=a("a"),bTr=o("LongformerForMultipleChoice"),vTr=o(" (Longformer model)"),FTr=l(),RE=a("li"),L5e=a("strong"),TTr=o("luke"),MTr=o(" \u2014 "),MK=a("a"),ETr=o("LukeForMultipleChoice"),CTr=o(" (LUKE model)"),wTr=l(),PE=a("li"),y5e=a("strong"),ATr=o("megatron-bert"),LTr=o(" \u2014 "),EK=a("a"),yTr=o("MegatronBertForMultipleChoice"),xTr=o(" (Megatron-BERT model)"),$Tr=l(),BE=a("li"),x5e=a("strong"),kTr=o("mobilebert"),STr=o(" \u2014 "),CK=a("a"),RTr=o("MobileBertForMultipleChoice"),PTr=o(" (MobileBERT model)"),BTr=l(),IE=a("li"),$5e=a("strong"),ITr=o("mpnet"),NTr=o(" \u2014 "),wK=a("a"),qTr=o("MPNetForMultipleChoice"),DTr=o(" (MPNet model)"),jTr=l(),NE=a("li"),k5e=a("strong"),GTr=o("nezha"),OTr=o(" \u2014 "),AK=a("a"),VTr=o("NezhaForMultipleChoice"),XTr=o(" (Nezha model)"),zTr=l(),qE=a("li"),S5e=a("strong"),QTr=o("nystromformer"),WTr=o(" \u2014 "),LK=a("a"),UTr=o("NystromformerForMultipleChoice"),HTr=o(" (Nystr\xF6mformer model)"),JTr=l(),DE=a("li"),R5e=a("strong"),YTr=o("qdqbert"),ZTr=o(" \u2014 "),yK=a("a"),KTr=o("QDQBertForMultipleChoice"),eMr=o(" (QDQBert model)"),oMr=l(),jE=a("li"),P5e=a("strong"),rMr=o("rembert"),tMr=o(" \u2014 "),xK=a("a"),aMr=o("RemBertForMultipleChoice"),nMr=o(" (RemBERT model)"),sMr=l(),GE=a("li"),B5e=a("strong"),lMr=o("roberta"),iMr=o(" \u2014 "),$K=a("a"),dMr=o("RobertaForMultipleChoice"),mMr=o(" (RoBERTa model)"),cMr=l(),OE=a("li"),I5e=a("strong"),fMr=o("roc_bert"),gMr=o(" \u2014 "),kK=a("a"),hMr=o("RoCBertForMultipleChoice"),uMr=o(" (RoCBert model)"),pMr=l(),VE=a("li"),N5e=a("strong"),_Mr=o("roformer"),bMr=o(" \u2014 "),SK=a("a"),vMr=o("RoFormerForMultipleChoice"),FMr=o(" (RoFormer model)"),TMr=l(),XE=a("li"),q5e=a("strong"),MMr=o("squeezebert"),EMr=o(" \u2014 "),RK=a("a"),CMr=o("SqueezeBertForMultipleChoice"),wMr=o(" (SqueezeBERT model)"),AMr=l(),zE=a("li"),D5e=a("strong"),LMr=o("xlm"),yMr=o(" \u2014 "),PK=a("a"),xMr=o("XLMForMultipleChoice"),$Mr=o(" (XLM model)"),kMr=l(),QE=a("li"),j5e=a("strong"),SMr=o("xlm-roberta"),RMr=o(" \u2014 "),BK=a("a"),PMr=o("XLMRobertaForMultipleChoice"),BMr=o(" (XLM-RoBERTa model)"),IMr=l(),WE=a("li"),G5e=a("strong"),NMr=o("xlm-roberta-xl"),qMr=o(" \u2014 "),IK=a("a"),DMr=o("XLMRobertaXLForMultipleChoice"),jMr=o(" (XLM-RoBERTa-XL model)"),GMr=l(),UE=a("li"),O5e=a("strong"),OMr=o("xlnet"),VMr=o(" \u2014 "),NK=a("a"),XMr=o("XLNetForMultipleChoice"),zMr=o(" (XLNet model)"),QMr=l(),HE=a("li"),V5e=a("strong"),WMr=o("yoso"),UMr=o(" \u2014 "),qK=a("a"),HMr=o("YosoForMultipleChoice"),JMr=o(" (YOSO model)"),YMr=l(),JE=a("p"),ZMr=o("The model is set in evaluation mode by default using "),X5e=a("code"),KMr=o("model.eval()"),eEr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),z5e=a("code"),oEr=o("model.train()"),rEr=l(),F(YE.$$.fragment),Vlo=l(),cm=a("h2"),ZE=a("a"),Q5e=a("span"),F($S.$$.fragment),tEr=l(),W5e=a("span"),aEr=o("AutoModelForNextSentencePrediction"),Xlo=l(),Uo=a("div"),F(kS.$$.fragment),nEr=l(),fm=a("p"),sEr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),DK=a("a"),lEr=o("from_pretrained()"),iEr=o(" class method or the "),jK=a("a"),dEr=o("from_config()"),mEr=o(` class
method.`),cEr=l(),SS=a("p"),fEr=o("This class cannot be instantiated directly using "),U5e=a("code"),gEr=o("__init__()"),hEr=o(" (throws an error)."),uEr=l(),Pt=a("div"),F(RS.$$.fragment),pEr=l(),H5e=a("p"),_Er=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),bEr=l(),gm=a("p"),vEr=o(`Note:
Loading a model from its configuration file does `),J5e=a("strong"),FEr=o("not"),TEr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),GK=a("a"),MEr=o("from_pretrained()"),EEr=o(" to load the model weights."),CEr=l(),F(KE.$$.fragment),wEr=l(),fo=a("div"),F(PS.$$.fragment),AEr=l(),Y5e=a("p"),LEr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),yEr=l(),Fn=a("p"),xEr=o("The model class to instantiate is selected based on the "),Z5e=a("code"),$Er=o("model_type"),kEr=o(` property of the config object (either
passed as an argument or loaded from `),K5e=a("code"),SEr=o("pretrained_model_name_or_path"),REr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e0e=a("code"),PEr=o("pretrained_model_name_or_path"),BEr=o(":"),IEr=l(),Ye=a("ul"),e4=a("li"),o0e=a("strong"),NEr=o("bert"),qEr=o(" \u2014 "),OK=a("a"),DEr=o("BertForNextSentencePrediction"),jEr=o(" (BERT model)"),GEr=l(),o4=a("li"),r0e=a("strong"),OEr=o("ernie"),VEr=o(" \u2014 "),VK=a("a"),XEr=o("ErnieForNextSentencePrediction"),zEr=o(" (ERNIE model)"),QEr=l(),r4=a("li"),t0e=a("strong"),WEr=o("fnet"),UEr=o(" \u2014 "),XK=a("a"),HEr=o("FNetForNextSentencePrediction"),JEr=o(" (FNet model)"),YEr=l(),t4=a("li"),a0e=a("strong"),ZEr=o("megatron-bert"),KEr=o(" \u2014 "),zK=a("a"),e4r=o("MegatronBertForNextSentencePrediction"),o4r=o(" (Megatron-BERT model)"),r4r=l(),a4=a("li"),n0e=a("strong"),t4r=o("mobilebert"),a4r=o(" \u2014 "),QK=a("a"),n4r=o("MobileBertForNextSentencePrediction"),s4r=o(" (MobileBERT model)"),l4r=l(),n4=a("li"),s0e=a("strong"),i4r=o("nezha"),d4r=o(" \u2014 "),WK=a("a"),m4r=o("NezhaForNextSentencePrediction"),c4r=o(" (Nezha model)"),f4r=l(),s4=a("li"),l0e=a("strong"),g4r=o("qdqbert"),h4r=o(" \u2014 "),UK=a("a"),u4r=o("QDQBertForNextSentencePrediction"),p4r=o(" (QDQBert model)"),_4r=l(),l4=a("p"),b4r=o("The model is set in evaluation mode by default using "),i0e=a("code"),v4r=o("model.eval()"),F4r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),d0e=a("code"),T4r=o("model.train()"),M4r=l(),F(i4.$$.fragment),zlo=l(),hm=a("h2"),d4=a("a"),m0e=a("span"),F(BS.$$.fragment),E4r=l(),c0e=a("span"),C4r=o("AutoModelForTokenClassification"),Qlo=l(),Ho=a("div"),F(IS.$$.fragment),w4r=l(),um=a("p"),A4r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),HK=a("a"),L4r=o("from_pretrained()"),y4r=o(" class method or the "),JK=a("a"),x4r=o("from_config()"),$4r=o(` class
method.`),k4r=l(),NS=a("p"),S4r=o("This class cannot be instantiated directly using "),f0e=a("code"),R4r=o("__init__()"),P4r=o(" (throws an error)."),B4r=l(),Bt=a("div"),F(qS.$$.fragment),I4r=l(),g0e=a("p"),N4r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),q4r=l(),pm=a("p"),D4r=o(`Note:
Loading a model from its configuration file does `),h0e=a("strong"),j4r=o("not"),G4r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YK=a("a"),O4r=o("from_pretrained()"),V4r=o(" to load the model weights."),X4r=l(),F(m4.$$.fragment),z4r=l(),go=a("div"),F(DS.$$.fragment),Q4r=l(),u0e=a("p"),W4r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),U4r=l(),Tn=a("p"),H4r=o("The model class to instantiate is selected based on the "),p0e=a("code"),J4r=o("model_type"),Y4r=o(` property of the config object (either
passed as an argument or loaded from `),_0e=a("code"),Z4r=o("pretrained_model_name_or_path"),K4r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b0e=a("code"),eCr=o("pretrained_model_name_or_path"),oCr=o(":"),rCr=l(),U=a("ul"),c4=a("li"),v0e=a("strong"),tCr=o("albert"),aCr=o(" \u2014 "),ZK=a("a"),nCr=o("AlbertForTokenClassification"),sCr=o(" (ALBERT model)"),lCr=l(),f4=a("li"),F0e=a("strong"),iCr=o("bert"),dCr=o(" \u2014 "),KK=a("a"),mCr=o("BertForTokenClassification"),cCr=o(" (BERT model)"),fCr=l(),g4=a("li"),T0e=a("strong"),gCr=o("big_bird"),hCr=o(" \u2014 "),eee=a("a"),uCr=o("BigBirdForTokenClassification"),pCr=o(" (BigBird model)"),_Cr=l(),h4=a("li"),M0e=a("strong"),bCr=o("bloom"),vCr=o(" \u2014 "),oee=a("a"),FCr=o("BloomForTokenClassification"),TCr=o(" (BLOOM model)"),MCr=l(),u4=a("li"),E0e=a("strong"),ECr=o("camembert"),CCr=o(" \u2014 "),ree=a("a"),wCr=o("CamembertForTokenClassification"),ACr=o(" (CamemBERT model)"),LCr=l(),p4=a("li"),C0e=a("strong"),yCr=o("canine"),xCr=o(" \u2014 "),tee=a("a"),$Cr=o("CanineForTokenClassification"),kCr=o(" (CANINE model)"),SCr=l(),_4=a("li"),w0e=a("strong"),RCr=o("convbert"),PCr=o(" \u2014 "),aee=a("a"),BCr=o("ConvBertForTokenClassification"),ICr=o(" (ConvBERT model)"),NCr=l(),b4=a("li"),A0e=a("strong"),qCr=o("data2vec-text"),DCr=o(" \u2014 "),nee=a("a"),jCr=o("Data2VecTextForTokenClassification"),GCr=o(" (Data2VecText model)"),OCr=l(),v4=a("li"),L0e=a("strong"),VCr=o("deberta"),XCr=o(" \u2014 "),see=a("a"),zCr=o("DebertaForTokenClassification"),QCr=o(" (DeBERTa model)"),WCr=l(),F4=a("li"),y0e=a("strong"),UCr=o("deberta-v2"),HCr=o(" \u2014 "),lee=a("a"),JCr=o("DebertaV2ForTokenClassification"),YCr=o(" (DeBERTa-v2 model)"),ZCr=l(),T4=a("li"),x0e=a("strong"),KCr=o("distilbert"),e3r=o(" \u2014 "),iee=a("a"),o3r=o("DistilBertForTokenClassification"),r3r=o(" (DistilBERT model)"),t3r=l(),M4=a("li"),$0e=a("strong"),a3r=o("electra"),n3r=o(" \u2014 "),dee=a("a"),s3r=o("ElectraForTokenClassification"),l3r=o(" (ELECTRA model)"),i3r=l(),E4=a("li"),k0e=a("strong"),d3r=o("ernie"),m3r=o(" \u2014 "),mee=a("a"),c3r=o("ErnieForTokenClassification"),f3r=o(" (ERNIE model)"),g3r=l(),C4=a("li"),S0e=a("strong"),h3r=o("esm"),u3r=o(" \u2014 "),cee=a("a"),p3r=o("EsmForTokenClassification"),_3r=o(" (ESM model)"),b3r=l(),w4=a("li"),R0e=a("strong"),v3r=o("flaubert"),F3r=o(" \u2014 "),fee=a("a"),T3r=o("FlaubertForTokenClassification"),M3r=o(" (FlauBERT model)"),E3r=l(),A4=a("li"),P0e=a("strong"),C3r=o("fnet"),w3r=o(" \u2014 "),gee=a("a"),A3r=o("FNetForTokenClassification"),L3r=o(" (FNet model)"),y3r=l(),L4=a("li"),B0e=a("strong"),x3r=o("funnel"),$3r=o(" \u2014 "),hee=a("a"),k3r=o("FunnelForTokenClassification"),S3r=o(" (Funnel Transformer model)"),R3r=l(),y4=a("li"),I0e=a("strong"),P3r=o("gpt2"),B3r=o(" \u2014 "),uee=a("a"),I3r=o("GPT2ForTokenClassification"),N3r=o(" (OpenAI GPT-2 model)"),q3r=l(),x4=a("li"),N0e=a("strong"),D3r=o("ibert"),j3r=o(" \u2014 "),pee=a("a"),G3r=o("IBertForTokenClassification"),O3r=o(" (I-BERT model)"),V3r=l(),$4=a("li"),q0e=a("strong"),X3r=o("layoutlm"),z3r=o(" \u2014 "),_ee=a("a"),Q3r=o("LayoutLMForTokenClassification"),W3r=o(" (LayoutLM model)"),U3r=l(),k4=a("li"),D0e=a("strong"),H3r=o("layoutlmv2"),J3r=o(" \u2014 "),bee=a("a"),Y3r=o("LayoutLMv2ForTokenClassification"),Z3r=o(" (LayoutLMv2 model)"),K3r=l(),S4=a("li"),j0e=a("strong"),e5r=o("layoutlmv3"),o5r=o(" \u2014 "),vee=a("a"),r5r=o("LayoutLMv3ForTokenClassification"),t5r=o(" (LayoutLMv3 model)"),a5r=l(),R4=a("li"),G0e=a("strong"),n5r=o("lilt"),s5r=o(" \u2014 "),Fee=a("a"),l5r=o("LiltForTokenClassification"),i5r=o(" (LiLT model)"),d5r=l(),P4=a("li"),O0e=a("strong"),m5r=o("longformer"),c5r=o(" \u2014 "),Tee=a("a"),f5r=o("LongformerForTokenClassification"),g5r=o(" (Longformer model)"),h5r=l(),B4=a("li"),V0e=a("strong"),u5r=o("luke"),p5r=o(" \u2014 "),Mee=a("a"),_5r=o("LukeForTokenClassification"),b5r=o(" (LUKE model)"),v5r=l(),I4=a("li"),X0e=a("strong"),F5r=o("markuplm"),T5r=o(" \u2014 "),Eee=a("a"),M5r=o("MarkupLMForTokenClassification"),E5r=o(" (MarkupLM model)"),C5r=l(),N4=a("li"),z0e=a("strong"),w5r=o("megatron-bert"),A5r=o(" \u2014 "),Cee=a("a"),L5r=o("MegatronBertForTokenClassification"),y5r=o(" (Megatron-BERT model)"),x5r=l(),q4=a("li"),Q0e=a("strong"),$5r=o("mobilebert"),k5r=o(" \u2014 "),wee=a("a"),S5r=o("MobileBertForTokenClassification"),R5r=o(" (MobileBERT model)"),P5r=l(),D4=a("li"),W0e=a("strong"),B5r=o("mpnet"),I5r=o(" \u2014 "),Aee=a("a"),N5r=o("MPNetForTokenClassification"),q5r=o(" (MPNet model)"),D5r=l(),j4=a("li"),U0e=a("strong"),j5r=o("nezha"),G5r=o(" \u2014 "),Lee=a("a"),O5r=o("NezhaForTokenClassification"),V5r=o(" (Nezha model)"),X5r=l(),G4=a("li"),H0e=a("strong"),z5r=o("nystromformer"),Q5r=o(" \u2014 "),yee=a("a"),W5r=o("NystromformerForTokenClassification"),U5r=o(" (Nystr\xF6mformer model)"),H5r=l(),O4=a("li"),J0e=a("strong"),J5r=o("qdqbert"),Y5r=o(" \u2014 "),xee=a("a"),Z5r=o("QDQBertForTokenClassification"),K5r=o(" (QDQBert model)"),e0r=l(),V4=a("li"),Y0e=a("strong"),o0r=o("rembert"),r0r=o(" \u2014 "),$ee=a("a"),t0r=o("RemBertForTokenClassification"),a0r=o(" (RemBERT model)"),n0r=l(),X4=a("li"),Z0e=a("strong"),s0r=o("roberta"),l0r=o(" \u2014 "),kee=a("a"),i0r=o("RobertaForTokenClassification"),d0r=o(" (RoBERTa model)"),m0r=l(),z4=a("li"),K0e=a("strong"),c0r=o("roc_bert"),f0r=o(" \u2014 "),See=a("a"),g0r=o("RoCBertForTokenClassification"),h0r=o(" (RoCBert model)"),u0r=l(),Q4=a("li"),ewe=a("strong"),p0r=o("roformer"),_0r=o(" \u2014 "),Ree=a("a"),b0r=o("RoFormerForTokenClassification"),v0r=o(" (RoFormer model)"),F0r=l(),W4=a("li"),owe=a("strong"),T0r=o("squeezebert"),M0r=o(" \u2014 "),Pee=a("a"),E0r=o("SqueezeBertForTokenClassification"),C0r=o(" (SqueezeBERT model)"),w0r=l(),U4=a("li"),rwe=a("strong"),A0r=o("xlm"),L0r=o(" \u2014 "),Bee=a("a"),y0r=o("XLMForTokenClassification"),x0r=o(" (XLM model)"),$0r=l(),H4=a("li"),twe=a("strong"),k0r=o("xlm-roberta"),S0r=o(" \u2014 "),Iee=a("a"),R0r=o("XLMRobertaForTokenClassification"),P0r=o(" (XLM-RoBERTa model)"),B0r=l(),J4=a("li"),awe=a("strong"),I0r=o("xlm-roberta-xl"),N0r=o(" \u2014 "),Nee=a("a"),q0r=o("XLMRobertaXLForTokenClassification"),D0r=o(" (XLM-RoBERTa-XL model)"),j0r=l(),Y4=a("li"),nwe=a("strong"),G0r=o("xlnet"),O0r=o(" \u2014 "),qee=a("a"),V0r=o("XLNetForTokenClassification"),X0r=o(" (XLNet model)"),z0r=l(),Z4=a("li"),swe=a("strong"),Q0r=o("yoso"),W0r=o(" \u2014 "),Dee=a("a"),U0r=o("YosoForTokenClassification"),H0r=o(" (YOSO model)"),J0r=l(),K4=a("p"),Y0r=o("The model is set in evaluation mode by default using "),lwe=a("code"),Z0r=o("model.eval()"),K0r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),iwe=a("code"),ewr=o("model.train()"),owr=l(),F(eC.$$.fragment),Wlo=l(),_m=a("h2"),oC=a("a"),dwe=a("span"),F(jS.$$.fragment),rwr=l(),mwe=a("span"),twr=o("AutoModelForQuestionAnswering"),Ulo=l(),Jo=a("div"),F(GS.$$.fragment),awr=l(),bm=a("p"),nwr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),jee=a("a"),swr=o("from_pretrained()"),lwr=o(" class method or the "),Gee=a("a"),iwr=o("from_config()"),dwr=o(` class
method.`),mwr=l(),OS=a("p"),cwr=o("This class cannot be instantiated directly using "),cwe=a("code"),fwr=o("__init__()"),gwr=o(" (throws an error)."),hwr=l(),It=a("div"),F(VS.$$.fragment),uwr=l(),fwe=a("p"),pwr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),_wr=l(),vm=a("p"),bwr=o(`Note:
Loading a model from its configuration file does `),gwe=a("strong"),vwr=o("not"),Fwr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Oee=a("a"),Twr=o("from_pretrained()"),Mwr=o(" to load the model weights."),Ewr=l(),F(rC.$$.fragment),Cwr=l(),ho=a("div"),F(XS.$$.fragment),wwr=l(),hwe=a("p"),Awr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Lwr=l(),Mn=a("p"),ywr=o("The model class to instantiate is selected based on the "),uwe=a("code"),xwr=o("model_type"),$wr=o(` property of the config object (either
passed as an argument or loaded from `),pwe=a("code"),kwr=o("pretrained_model_name_or_path"),Swr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_we=a("code"),Rwr=o("pretrained_model_name_or_path"),Pwr=o(":"),Bwr=l(),O=a("ul"),tC=a("li"),bwe=a("strong"),Iwr=o("albert"),Nwr=o(" \u2014 "),Vee=a("a"),qwr=o("AlbertForQuestionAnswering"),Dwr=o(" (ALBERT model)"),jwr=l(),aC=a("li"),vwe=a("strong"),Gwr=o("bart"),Owr=o(" \u2014 "),Xee=a("a"),Vwr=o("BartForQuestionAnswering"),Xwr=o(" (BART model)"),zwr=l(),nC=a("li"),Fwe=a("strong"),Qwr=o("bert"),Wwr=o(" \u2014 "),zee=a("a"),Uwr=o("BertForQuestionAnswering"),Hwr=o(" (BERT model)"),Jwr=l(),sC=a("li"),Twe=a("strong"),Ywr=o("big_bird"),Zwr=o(" \u2014 "),Qee=a("a"),Kwr=o("BigBirdForQuestionAnswering"),eAr=o(" (BigBird model)"),oAr=l(),lC=a("li"),Mwe=a("strong"),rAr=o("bigbird_pegasus"),tAr=o(" \u2014 "),Wee=a("a"),aAr=o("BigBirdPegasusForQuestionAnswering"),nAr=o(" (BigBird-Pegasus model)"),sAr=l(),iC=a("li"),Ewe=a("strong"),lAr=o("bloom"),iAr=o(" \u2014 "),Uee=a("a"),dAr=o("BloomForQuestionAnswering"),mAr=o(" (BLOOM model)"),cAr=l(),dC=a("li"),Cwe=a("strong"),fAr=o("camembert"),gAr=o(" \u2014 "),Hee=a("a"),hAr=o("CamembertForQuestionAnswering"),uAr=o(" (CamemBERT model)"),pAr=l(),mC=a("li"),wwe=a("strong"),_Ar=o("canine"),bAr=o(" \u2014 "),Jee=a("a"),vAr=o("CanineForQuestionAnswering"),FAr=o(" (CANINE model)"),TAr=l(),cC=a("li"),Awe=a("strong"),MAr=o("convbert"),EAr=o(" \u2014 "),Yee=a("a"),CAr=o("ConvBertForQuestionAnswering"),wAr=o(" (ConvBERT model)"),AAr=l(),fC=a("li"),Lwe=a("strong"),LAr=o("data2vec-text"),yAr=o(" \u2014 "),Zee=a("a"),xAr=o("Data2VecTextForQuestionAnswering"),$Ar=o(" (Data2VecText model)"),kAr=l(),gC=a("li"),ywe=a("strong"),SAr=o("deberta"),RAr=o(" \u2014 "),Kee=a("a"),PAr=o("DebertaForQuestionAnswering"),BAr=o(" (DeBERTa model)"),IAr=l(),hC=a("li"),xwe=a("strong"),NAr=o("deberta-v2"),qAr=o(" \u2014 "),eoe=a("a"),DAr=o("DebertaV2ForQuestionAnswering"),jAr=o(" (DeBERTa-v2 model)"),GAr=l(),uC=a("li"),$we=a("strong"),OAr=o("distilbert"),VAr=o(" \u2014 "),ooe=a("a"),XAr=o("DistilBertForQuestionAnswering"),zAr=o(" (DistilBERT model)"),QAr=l(),pC=a("li"),kwe=a("strong"),WAr=o("electra"),UAr=o(" \u2014 "),roe=a("a"),HAr=o("ElectraForQuestionAnswering"),JAr=o(" (ELECTRA model)"),YAr=l(),_C=a("li"),Swe=a("strong"),ZAr=o("ernie"),KAr=o(" \u2014 "),toe=a("a"),e6r=o("ErnieForQuestionAnswering"),o6r=o(" (ERNIE model)"),r6r=l(),bC=a("li"),Rwe=a("strong"),t6r=o("flaubert"),a6r=o(" \u2014 "),aoe=a("a"),n6r=o("FlaubertForQuestionAnsweringSimple"),s6r=o(" (FlauBERT model)"),l6r=l(),vC=a("li"),Pwe=a("strong"),i6r=o("fnet"),d6r=o(" \u2014 "),noe=a("a"),m6r=o("FNetForQuestionAnswering"),c6r=o(" (FNet model)"),f6r=l(),FC=a("li"),Bwe=a("strong"),g6r=o("funnel"),h6r=o(" \u2014 "),soe=a("a"),u6r=o("FunnelForQuestionAnswering"),p6r=o(" (Funnel Transformer model)"),_6r=l(),TC=a("li"),Iwe=a("strong"),b6r=o("gptj"),v6r=o(" \u2014 "),loe=a("a"),F6r=o("GPTJForQuestionAnswering"),T6r=o(" (GPT-J model)"),M6r=l(),MC=a("li"),Nwe=a("strong"),E6r=o("ibert"),C6r=o(" \u2014 "),ioe=a("a"),w6r=o("IBertForQuestionAnswering"),A6r=o(" (I-BERT model)"),L6r=l(),EC=a("li"),qwe=a("strong"),y6r=o("layoutlmv2"),x6r=o(" \u2014 "),doe=a("a"),$6r=o("LayoutLMv2ForQuestionAnswering"),k6r=o(" (LayoutLMv2 model)"),S6r=l(),CC=a("li"),Dwe=a("strong"),R6r=o("layoutlmv3"),P6r=o(" \u2014 "),moe=a("a"),B6r=o("LayoutLMv3ForQuestionAnswering"),I6r=o(" (LayoutLMv3 model)"),N6r=l(),wC=a("li"),jwe=a("strong"),q6r=o("led"),D6r=o(" \u2014 "),coe=a("a"),j6r=o("LEDForQuestionAnswering"),G6r=o(" (LED model)"),O6r=l(),AC=a("li"),Gwe=a("strong"),V6r=o("lilt"),X6r=o(" \u2014 "),foe=a("a"),z6r=o("LiltForQuestionAnswering"),Q6r=o(" (LiLT model)"),W6r=l(),LC=a("li"),Owe=a("strong"),U6r=o("longformer"),H6r=o(" \u2014 "),goe=a("a"),J6r=o("LongformerForQuestionAnswering"),Y6r=o(" (Longformer model)"),Z6r=l(),yC=a("li"),Vwe=a("strong"),K6r=o("luke"),e7r=o(" \u2014 "),hoe=a("a"),o7r=o("LukeForQuestionAnswering"),r7r=o(" (LUKE model)"),t7r=l(),xC=a("li"),Xwe=a("strong"),a7r=o("lxmert"),n7r=o(" \u2014 "),uoe=a("a"),s7r=o("LxmertForQuestionAnswering"),l7r=o(" (LXMERT model)"),i7r=l(),$C=a("li"),zwe=a("strong"),d7r=o("markuplm"),m7r=o(" \u2014 "),poe=a("a"),c7r=o("MarkupLMForQuestionAnswering"),f7r=o(" (MarkupLM model)"),g7r=l(),kC=a("li"),Qwe=a("strong"),h7r=o("mbart"),u7r=o(" \u2014 "),_oe=a("a"),p7r=o("MBartForQuestionAnswering"),_7r=o(" (mBART model)"),b7r=l(),SC=a("li"),Wwe=a("strong"),v7r=o("megatron-bert"),F7r=o(" \u2014 "),boe=a("a"),T7r=o("MegatronBertForQuestionAnswering"),M7r=o(" (Megatron-BERT model)"),E7r=l(),RC=a("li"),Uwe=a("strong"),C7r=o("mobilebert"),w7r=o(" \u2014 "),voe=a("a"),A7r=o("MobileBertForQuestionAnswering"),L7r=o(" (MobileBERT model)"),y7r=l(),PC=a("li"),Hwe=a("strong"),x7r=o("mpnet"),$7r=o(" \u2014 "),Foe=a("a"),k7r=o("MPNetForQuestionAnswering"),S7r=o(" (MPNet model)"),R7r=l(),BC=a("li"),Jwe=a("strong"),P7r=o("mvp"),B7r=o(" \u2014 "),Toe=a("a"),I7r=o("MvpForQuestionAnswering"),N7r=o(" (MVP model)"),q7r=l(),IC=a("li"),Ywe=a("strong"),D7r=o("nezha"),j7r=o(" \u2014 "),Moe=a("a"),G7r=o("NezhaForQuestionAnswering"),O7r=o(" (Nezha model)"),V7r=l(),NC=a("li"),Zwe=a("strong"),X7r=o("nystromformer"),z7r=o(" \u2014 "),Eoe=a("a"),Q7r=o("NystromformerForQuestionAnswering"),W7r=o(" (Nystr\xF6mformer model)"),U7r=l(),qC=a("li"),Kwe=a("strong"),H7r=o("opt"),J7r=o(" \u2014 "),Coe=a("a"),Y7r=o("OPTForQuestionAnswering"),Z7r=o(" (OPT model)"),K7r=l(),DC=a("li"),eAe=a("strong"),e8r=o("qdqbert"),o8r=o(" \u2014 "),woe=a("a"),r8r=o("QDQBertForQuestionAnswering"),t8r=o(" (QDQBert model)"),a8r=l(),jC=a("li"),oAe=a("strong"),n8r=o("reformer"),s8r=o(" \u2014 "),Aoe=a("a"),l8r=o("ReformerForQuestionAnswering"),i8r=o(" (Reformer model)"),d8r=l(),GC=a("li"),rAe=a("strong"),m8r=o("rembert"),c8r=o(" \u2014 "),Loe=a("a"),f8r=o("RemBertForQuestionAnswering"),g8r=o(" (RemBERT model)"),h8r=l(),OC=a("li"),tAe=a("strong"),u8r=o("roberta"),p8r=o(" \u2014 "),yoe=a("a"),_8r=o("RobertaForQuestionAnswering"),b8r=o(" (RoBERTa model)"),v8r=l(),VC=a("li"),aAe=a("strong"),F8r=o("roc_bert"),T8r=o(" \u2014 "),xoe=a("a"),M8r=o("RoCBertForQuestionAnswering"),E8r=o(" (RoCBert model)"),C8r=l(),XC=a("li"),nAe=a("strong"),w8r=o("roformer"),A8r=o(" \u2014 "),$oe=a("a"),L8r=o("RoFormerForQuestionAnswering"),y8r=o(" (RoFormer model)"),x8r=l(),zC=a("li"),sAe=a("strong"),$8r=o("splinter"),k8r=o(" \u2014 "),koe=a("a"),S8r=o("SplinterForQuestionAnswering"),R8r=o(" (Splinter model)"),P8r=l(),QC=a("li"),lAe=a("strong"),B8r=o("squeezebert"),I8r=o(" \u2014 "),Soe=a("a"),N8r=o("SqueezeBertForQuestionAnswering"),q8r=o(" (SqueezeBERT model)"),D8r=l(),WC=a("li"),iAe=a("strong"),j8r=o("xlm"),G8r=o(" \u2014 "),Roe=a("a"),O8r=o("XLMForQuestionAnsweringSimple"),V8r=o(" (XLM model)"),X8r=l(),UC=a("li"),dAe=a("strong"),z8r=o("xlm-roberta"),Q8r=o(" \u2014 "),Poe=a("a"),W8r=o("XLMRobertaForQuestionAnswering"),U8r=o(" (XLM-RoBERTa model)"),H8r=l(),HC=a("li"),mAe=a("strong"),J8r=o("xlm-roberta-xl"),Y8r=o(" \u2014 "),Boe=a("a"),Z8r=o("XLMRobertaXLForQuestionAnswering"),K8r=o(" (XLM-RoBERTa-XL model)"),eLr=l(),JC=a("li"),cAe=a("strong"),oLr=o("xlnet"),rLr=o(" \u2014 "),Ioe=a("a"),tLr=o("XLNetForQuestionAnsweringSimple"),aLr=o(" (XLNet model)"),nLr=l(),YC=a("li"),fAe=a("strong"),sLr=o("yoso"),lLr=o(" \u2014 "),Noe=a("a"),iLr=o("YosoForQuestionAnswering"),dLr=o(" (YOSO model)"),mLr=l(),ZC=a("p"),cLr=o("The model is set in evaluation mode by default using "),gAe=a("code"),fLr=o("model.eval()"),gLr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),hAe=a("code"),hLr=o("model.train()"),uLr=l(),F(KC.$$.fragment),Hlo=l(),Fm=a("h2"),e3=a("a"),uAe=a("span"),F(zS.$$.fragment),pLr=l(),pAe=a("span"),_Lr=o("AutoModelForTableQuestionAnswering"),Jlo=l(),Yo=a("div"),F(QS.$$.fragment),bLr=l(),Tm=a("p"),vLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),qoe=a("a"),FLr=o("from_pretrained()"),TLr=o(" class method or the "),Doe=a("a"),MLr=o("from_config()"),ELr=o(` class
method.`),CLr=l(),WS=a("p"),wLr=o("This class cannot be instantiated directly using "),_Ae=a("code"),ALr=o("__init__()"),LLr=o(" (throws an error)."),yLr=l(),Nt=a("div"),F(US.$$.fragment),xLr=l(),bAe=a("p"),$Lr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),kLr=l(),Mm=a("p"),SLr=o(`Note:
Loading a model from its configuration file does `),vAe=a("strong"),RLr=o("not"),PLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),joe=a("a"),BLr=o("from_pretrained()"),ILr=o(" to load the model weights."),NLr=l(),F(o3.$$.fragment),qLr=l(),uo=a("div"),F(HS.$$.fragment),DLr=l(),FAe=a("p"),jLr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),GLr=l(),En=a("p"),OLr=o("The model class to instantiate is selected based on the "),TAe=a("code"),VLr=o("model_type"),XLr=o(` property of the config object (either
passed as an argument or loaded from `),MAe=a("code"),zLr=o("pretrained_model_name_or_path"),QLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),EAe=a("code"),WLr=o("pretrained_model_name_or_path"),ULr=o(":"),HLr=l(),CAe=a("ul"),r3=a("li"),wAe=a("strong"),JLr=o("tapas"),YLr=o(" \u2014 "),Goe=a("a"),ZLr=o("TapasForQuestionAnswering"),KLr=o(" (TAPAS model)"),eyr=l(),t3=a("p"),oyr=o("The model is set in evaluation mode by default using "),AAe=a("code"),ryr=o("model.eval()"),tyr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),LAe=a("code"),ayr=o("model.train()"),nyr=l(),F(a3.$$.fragment),Ylo=l(),Em=a("h2"),n3=a("a"),yAe=a("span"),F(JS.$$.fragment),syr=l(),xAe=a("span"),lyr=o("AutoModelForDocumentQuestionAnswering"),Zlo=l(),Zo=a("div"),F(YS.$$.fragment),iyr=l(),Cm=a("p"),dyr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),Ooe=a("a"),myr=o("from_pretrained()"),cyr=o(" class method or the "),Voe=a("a"),fyr=o("from_config()"),gyr=o(` class
method.`),hyr=l(),ZS=a("p"),uyr=o("This class cannot be instantiated directly using "),$Ae=a("code"),pyr=o("__init__()"),_yr=o(" (throws an error)."),byr=l(),qt=a("div"),F(KS.$$.fragment),vyr=l(),kAe=a("p"),Fyr=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Tyr=l(),wm=a("p"),Myr=o(`Note:
Loading a model from its configuration file does `),SAe=a("strong"),Eyr=o("not"),Cyr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Xoe=a("a"),wyr=o("from_pretrained()"),Ayr=o(" to load the model weights."),Lyr=l(),F(s3.$$.fragment),yyr=l(),po=a("div"),F(eR.$$.fragment),xyr=l(),RAe=a("p"),$yr=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),kyr=l(),Cn=a("p"),Syr=o("The model class to instantiate is selected based on the "),PAe=a("code"),Ryr=o("model_type"),Pyr=o(` property of the config object (either
passed as an argument or loaded from `),BAe=a("code"),Byr=o("pretrained_model_name_or_path"),Iyr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),IAe=a("code"),Nyr=o("pretrained_model_name_or_path"),qyr=o(":"),Dyr=l(),Am=a("ul"),l3=a("li"),NAe=a("strong"),jyr=o("layoutlm"),Gyr=o(" \u2014 "),zoe=a("a"),Oyr=o("LayoutLMForQuestionAnswering"),Vyr=o(" (LayoutLM model)"),Xyr=l(),i3=a("li"),qAe=a("strong"),zyr=o("layoutlmv2"),Qyr=o(" \u2014 "),Qoe=a("a"),Wyr=o("LayoutLMv2ForQuestionAnswering"),Uyr=o(" (LayoutLMv2 model)"),Hyr=l(),d3=a("li"),DAe=a("strong"),Jyr=o("layoutlmv3"),Yyr=o(" \u2014 "),Woe=a("a"),Zyr=o("LayoutLMv3ForQuestionAnswering"),Kyr=o(" (LayoutLMv3 model)"),e9r=l(),m3=a("p"),o9r=o("The model is set in evaluation mode by default using "),jAe=a("code"),r9r=o("model.eval()"),t9r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),GAe=a("code"),a9r=o("model.train()"),n9r=l(),F(c3.$$.fragment),Klo=l(),Lm=a("h2"),f3=a("a"),OAe=a("span"),F(oR.$$.fragment),s9r=l(),VAe=a("span"),l9r=o("AutoModelForImageClassification"),eio=l(),Ko=a("div"),F(rR.$$.fragment),i9r=l(),ym=a("p"),d9r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Uoe=a("a"),m9r=o("from_pretrained()"),c9r=o(" class method or the "),Hoe=a("a"),f9r=o("from_config()"),g9r=o(` class
method.`),h9r=l(),tR=a("p"),u9r=o("This class cannot be instantiated directly using "),XAe=a("code"),p9r=o("__init__()"),_9r=o(" (throws an error)."),b9r=l(),Dt=a("div"),F(aR.$$.fragment),v9r=l(),zAe=a("p"),F9r=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),T9r=l(),xm=a("p"),M9r=o(`Note:
Loading a model from its configuration file does `),QAe=a("strong"),E9r=o("not"),C9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Joe=a("a"),w9r=o("from_pretrained()"),A9r=o(" to load the model weights."),L9r=l(),F(g3.$$.fragment),y9r=l(),_o=a("div"),F(nR.$$.fragment),x9r=l(),WAe=a("p"),$9r=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),k9r=l(),wn=a("p"),S9r=o("The model class to instantiate is selected based on the "),UAe=a("code"),R9r=o("model_type"),P9r=o(` property of the config object (either
passed as an argument or loaded from `),HAe=a("code"),B9r=o("pretrained_model_name_or_path"),I9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JAe=a("code"),N9r=o("pretrained_model_name_or_path"),q9r=o(":"),D9r=l(),Fe=a("ul"),h3=a("li"),YAe=a("strong"),j9r=o("beit"),G9r=o(" \u2014 "),Yoe=a("a"),O9r=o("BeitForImageClassification"),V9r=o(" (BEiT model)"),X9r=l(),u3=a("li"),ZAe=a("strong"),z9r=o("convnext"),Q9r=o(" \u2014 "),Zoe=a("a"),W9r=o("ConvNextForImageClassification"),U9r=o(" (ConvNeXT model)"),H9r=l(),p3=a("li"),KAe=a("strong"),J9r=o("cvt"),Y9r=o(" \u2014 "),Koe=a("a"),Z9r=o("CvtForImageClassification"),K9r=o(" (CvT model)"),exr=l(),_3=a("li"),e6e=a("strong"),oxr=o("data2vec-vision"),rxr=o(" \u2014 "),ere=a("a"),txr=o("Data2VecVisionForImageClassification"),axr=o(" (Data2VecVision model)"),nxr=l(),Nl=a("li"),o6e=a("strong"),sxr=o("deit"),lxr=o(" \u2014 "),ore=a("a"),ixr=o("DeiTForImageClassification"),dxr=o(" or "),rre=a("a"),mxr=o("DeiTForImageClassificationWithTeacher"),cxr=o(" (DeiT model)"),fxr=l(),b3=a("li"),r6e=a("strong"),gxr=o("imagegpt"),hxr=o(" \u2014 "),tre=a("a"),uxr=o("ImageGPTForImageClassification"),pxr=o(" (ImageGPT model)"),_xr=l(),ql=a("li"),t6e=a("strong"),bxr=o("levit"),vxr=o(" \u2014 "),are=a("a"),Fxr=o("LevitForImageClassification"),Txr=o(" or "),nre=a("a"),Mxr=o("LevitForImageClassificationWithTeacher"),Exr=o(" (LeViT model)"),Cxr=l(),v3=a("li"),a6e=a("strong"),wxr=o("mobilevit"),Axr=o(" \u2014 "),sre=a("a"),Lxr=o("MobileViTForImageClassification"),yxr=o(" (MobileViT model)"),xxr=l(),jt=a("li"),n6e=a("strong"),$xr=o("perceiver"),kxr=o(" \u2014 "),lre=a("a"),Sxr=o("PerceiverForImageClassificationLearned"),Rxr=o(" or "),ire=a("a"),Pxr=o("PerceiverForImageClassificationFourier"),Bxr=o(" or "),dre=a("a"),Ixr=o("PerceiverForImageClassificationConvProcessing"),Nxr=o(" (Perceiver model)"),qxr=l(),F3=a("li"),s6e=a("strong"),Dxr=o("poolformer"),jxr=o(" \u2014 "),mre=a("a"),Gxr=o("PoolFormerForImageClassification"),Oxr=o(" (PoolFormer model)"),Vxr=l(),T3=a("li"),l6e=a("strong"),Xxr=o("regnet"),zxr=o(" \u2014 "),cre=a("a"),Qxr=o("RegNetForImageClassification"),Wxr=o(" (RegNet model)"),Uxr=l(),M3=a("li"),i6e=a("strong"),Hxr=o("resnet"),Jxr=o(" \u2014 "),fre=a("a"),Yxr=o("ResNetForImageClassification"),Zxr=o(" (ResNet model)"),Kxr=l(),E3=a("li"),d6e=a("strong"),e$r=o("segformer"),o$r=o(" \u2014 "),gre=a("a"),r$r=o("SegformerForImageClassification"),t$r=o(" (SegFormer model)"),a$r=l(),C3=a("li"),m6e=a("strong"),n$r=o("swin"),s$r=o(" \u2014 "),hre=a("a"),l$r=o("SwinForImageClassification"),i$r=o(" (Swin Transformer model)"),d$r=l(),w3=a("li"),c6e=a("strong"),m$r=o("swinv2"),c$r=o(" \u2014 "),ure=a("a"),f$r=o("Swinv2ForImageClassification"),g$r=o(" (Swin Transformer V2 model)"),h$r=l(),A3=a("li"),f6e=a("strong"),u$r=o("van"),p$r=o(" \u2014 "),pre=a("a"),_$r=o("VanForImageClassification"),b$r=o(" (VAN model)"),v$r=l(),L3=a("li"),g6e=a("strong"),F$r=o("vit"),T$r=o(" \u2014 "),_re=a("a"),M$r=o("ViTForImageClassification"),E$r=o(" (ViT model)"),C$r=l(),y3=a("li"),h6e=a("strong"),w$r=o("vit_msn"),A$r=o(" \u2014 "),bre=a("a"),L$r=o("ViTMSNForImageClassification"),y$r=o(" (ViTMSN model)"),x$r=l(),x3=a("p"),$$r=o("The model is set in evaluation mode by default using "),u6e=a("code"),k$r=o("model.eval()"),S$r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),p6e=a("code"),R$r=o("model.train()"),P$r=l(),F($3.$$.fragment),oio=l(),$m=a("h2"),k3=a("a"),_6e=a("span"),F(sR.$$.fragment),B$r=l(),b6e=a("span"),I$r=o("AutoModelForVideoClassification"),rio=l(),er=a("div"),F(lR.$$.fragment),N$r=l(),km=a("p"),q$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),vre=a("a"),D$r=o("from_pretrained()"),j$r=o(" class method or the "),Fre=a("a"),G$r=o("from_config()"),O$r=o(` class
method.`),V$r=l(),iR=a("p"),X$r=o("This class cannot be instantiated directly using "),v6e=a("code"),z$r=o("__init__()"),Q$r=o(" (throws an error)."),W$r=l(),Gt=a("div"),F(dR.$$.fragment),U$r=l(),F6e=a("p"),H$r=o("Instantiates one of the model classes of the library (with a video classification head) from a configuration."),J$r=l(),Sm=a("p"),Y$r=o(`Note:
Loading a model from its configuration file does `),T6e=a("strong"),Z$r=o("not"),K$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Tre=a("a"),ekr=o("from_pretrained()"),okr=o(" to load the model weights."),rkr=l(),F(S3.$$.fragment),tkr=l(),bo=a("div"),F(mR.$$.fragment),akr=l(),M6e=a("p"),nkr=o("Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),skr=l(),An=a("p"),lkr=o("The model class to instantiate is selected based on the "),E6e=a("code"),ikr=o("model_type"),dkr=o(` property of the config object (either
passed as an argument or loaded from `),C6e=a("code"),mkr=o("pretrained_model_name_or_path"),ckr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),w6e=a("code"),fkr=o("pretrained_model_name_or_path"),gkr=o(":"),hkr=l(),A6e=a("ul"),R3=a("li"),L6e=a("strong"),ukr=o("videomae"),pkr=o(" \u2014 "),Mre=a("a"),_kr=o("VideoMAEForVideoClassification"),bkr=o(" (VideoMAE model)"),vkr=l(),P3=a("p"),Fkr=o("The model is set in evaluation mode by default using "),y6e=a("code"),Tkr=o("model.eval()"),Mkr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),x6e=a("code"),Ekr=o("model.train()"),Ckr=l(),F(B3.$$.fragment),tio=l(),Rm=a("h2"),I3=a("a"),$6e=a("span"),F(cR.$$.fragment),wkr=l(),k6e=a("span"),Akr=o("AutoModelForVision2Seq"),aio=l(),or=a("div"),F(fR.$$.fragment),Lkr=l(),Pm=a("p"),ykr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Ere=a("a"),xkr=o("from_pretrained()"),$kr=o(" class method or the "),Cre=a("a"),kkr=o("from_config()"),Skr=o(` class
method.`),Rkr=l(),gR=a("p"),Pkr=o("This class cannot be instantiated directly using "),S6e=a("code"),Bkr=o("__init__()"),Ikr=o(" (throws an error)."),Nkr=l(),Ot=a("div"),F(hR.$$.fragment),qkr=l(),R6e=a("p"),Dkr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),jkr=l(),Bm=a("p"),Gkr=o(`Note:
Loading a model from its configuration file does `),P6e=a("strong"),Okr=o("not"),Vkr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wre=a("a"),Xkr=o("from_pretrained()"),zkr=o(" to load the model weights."),Qkr=l(),F(N3.$$.fragment),Wkr=l(),vo=a("div"),F(uR.$$.fragment),Ukr=l(),B6e=a("p"),Hkr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Jkr=l(),Ln=a("p"),Ykr=o("The model class to instantiate is selected based on the "),I6e=a("code"),Zkr=o("model_type"),Kkr=o(` property of the config object (either
passed as an argument or loaded from `),N6e=a("code"),eSr=o("pretrained_model_name_or_path"),oSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),q6e=a("code"),rSr=o("pretrained_model_name_or_path"),tSr=o(":"),aSr=l(),D6e=a("ul"),q3=a("li"),j6e=a("strong"),nSr=o("vision-encoder-decoder"),sSr=o(" \u2014 "),Are=a("a"),lSr=o("VisionEncoderDecoderModel"),iSr=o(" (Vision Encoder decoder model)"),dSr=l(),D3=a("p"),mSr=o("The model is set in evaluation mode by default using "),G6e=a("code"),cSr=o("model.eval()"),fSr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),O6e=a("code"),gSr=o("model.train()"),hSr=l(),F(j3.$$.fragment),nio=l(),Im=a("h2"),G3=a("a"),V6e=a("span"),F(pR.$$.fragment),uSr=l(),X6e=a("span"),pSr=o("AutoModelForVisualQuestionAnswering"),sio=l(),rr=a("div"),F(_R.$$.fragment),_Sr=l(),Nm=a("p"),bSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),Lre=a("a"),vSr=o("from_pretrained()"),FSr=o(" class method or the "),yre=a("a"),TSr=o("from_config()"),MSr=o(` class
method.`),ESr=l(),bR=a("p"),CSr=o("This class cannot be instantiated directly using "),z6e=a("code"),wSr=o("__init__()"),ASr=o(" (throws an error)."),LSr=l(),Vt=a("div"),F(vR.$$.fragment),ySr=l(),Q6e=a("p"),xSr=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),$Sr=l(),qm=a("p"),kSr=o(`Note:
Loading a model from its configuration file does `),W6e=a("strong"),SSr=o("not"),RSr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xre=a("a"),PSr=o("from_pretrained()"),BSr=o(" to load the model weights."),ISr=l(),F(O3.$$.fragment),NSr=l(),Fo=a("div"),F(FR.$$.fragment),qSr=l(),U6e=a("p"),DSr=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),jSr=l(),yn=a("p"),GSr=o("The model class to instantiate is selected based on the "),H6e=a("code"),OSr=o("model_type"),VSr=o(` property of the config object (either
passed as an argument or loaded from `),J6e=a("code"),XSr=o("pretrained_model_name_or_path"),zSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Y6e=a("code"),QSr=o("pretrained_model_name_or_path"),WSr=o(":"),USr=l(),Z6e=a("ul"),V3=a("li"),K6e=a("strong"),HSr=o("vilt"),JSr=o(" \u2014 "),$re=a("a"),YSr=o("ViltForQuestionAnswering"),ZSr=o(" (ViLT model)"),KSr=l(),X3=a("p"),eRr=o("The model is set in evaluation mode by default using "),e7e=a("code"),oRr=o("model.eval()"),rRr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o7e=a("code"),tRr=o("model.train()"),aRr=l(),F(z3.$$.fragment),lio=l(),Dm=a("h2"),Q3=a("a"),r7e=a("span"),F(TR.$$.fragment),nRr=l(),t7e=a("span"),sRr=o("AutoModelForAudioClassification"),iio=l(),tr=a("div"),F(MR.$$.fragment),lRr=l(),jm=a("p"),iRr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),kre=a("a"),dRr=o("from_pretrained()"),mRr=o(" class method or the "),Sre=a("a"),cRr=o("from_config()"),fRr=o(` class
method.`),gRr=l(),ER=a("p"),hRr=o("This class cannot be instantiated directly using "),a7e=a("code"),uRr=o("__init__()"),pRr=o(" (throws an error)."),_Rr=l(),Xt=a("div"),F(CR.$$.fragment),bRr=l(),n7e=a("p"),vRr=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),FRr=l(),Gm=a("p"),TRr=o(`Note:
Loading a model from its configuration file does `),s7e=a("strong"),MRr=o("not"),ERr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Rre=a("a"),CRr=o("from_pretrained()"),wRr=o(" to load the model weights."),ARr=l(),F(W3.$$.fragment),LRr=l(),To=a("div"),F(wR.$$.fragment),yRr=l(),l7e=a("p"),xRr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),$Rr=l(),xn=a("p"),kRr=o("The model class to instantiate is selected based on the "),i7e=a("code"),SRr=o("model_type"),RRr=o(` property of the config object (either
passed as an argument or loaded from `),d7e=a("code"),PRr=o("pretrained_model_name_or_path"),BRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m7e=a("code"),IRr=o("pretrained_model_name_or_path"),NRr=o(":"),qRr=l(),Ne=a("ul"),U3=a("li"),c7e=a("strong"),DRr=o("data2vec-audio"),jRr=o(" \u2014 "),Pre=a("a"),GRr=o("Data2VecAudioForSequenceClassification"),ORr=o(" (Data2VecAudio model)"),VRr=l(),H3=a("li"),f7e=a("strong"),XRr=o("hubert"),zRr=o(" \u2014 "),Bre=a("a"),QRr=o("HubertForSequenceClassification"),WRr=o(" (Hubert model)"),URr=l(),J3=a("li"),g7e=a("strong"),HRr=o("sew"),JRr=o(" \u2014 "),Ire=a("a"),YRr=o("SEWForSequenceClassification"),ZRr=o(" (SEW model)"),KRr=l(),Y3=a("li"),h7e=a("strong"),ePr=o("sew-d"),oPr=o(" \u2014 "),Nre=a("a"),rPr=o("SEWDForSequenceClassification"),tPr=o(" (SEW-D model)"),aPr=l(),Z3=a("li"),u7e=a("strong"),nPr=o("unispeech"),sPr=o(" \u2014 "),qre=a("a"),lPr=o("UniSpeechForSequenceClassification"),iPr=o(" (UniSpeech model)"),dPr=l(),K3=a("li"),p7e=a("strong"),mPr=o("unispeech-sat"),cPr=o(" \u2014 "),Dre=a("a"),fPr=o("UniSpeechSatForSequenceClassification"),gPr=o(" (UniSpeechSat model)"),hPr=l(),e5=a("li"),_7e=a("strong"),uPr=o("wav2vec2"),pPr=o(" \u2014 "),jre=a("a"),_Pr=o("Wav2Vec2ForSequenceClassification"),bPr=o(" (Wav2Vec2 model)"),vPr=l(),o5=a("li"),b7e=a("strong"),FPr=o("wav2vec2-conformer"),TPr=o(" \u2014 "),Gre=a("a"),MPr=o("Wav2Vec2ConformerForSequenceClassification"),EPr=o(" (Wav2Vec2-Conformer model)"),CPr=l(),r5=a("li"),v7e=a("strong"),wPr=o("wavlm"),APr=o(" \u2014 "),Ore=a("a"),LPr=o("WavLMForSequenceClassification"),yPr=o(" (WavLM model)"),xPr=l(),t5=a("p"),$Pr=o("The model is set in evaluation mode by default using "),F7e=a("code"),kPr=o("model.eval()"),SPr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),T7e=a("code"),RPr=o("model.train()"),PPr=l(),F(a5.$$.fragment),dio=l(),Om=a("h2"),n5=a("a"),M7e=a("span"),F(AR.$$.fragment),BPr=l(),E7e=a("span"),IPr=o("AutoModelForAudioFrameClassification"),mio=l(),ar=a("div"),F(LR.$$.fragment),NPr=l(),Vm=a("p"),qPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),Vre=a("a"),DPr=o("from_pretrained()"),jPr=o(" class method or the "),Xre=a("a"),GPr=o("from_config()"),OPr=o(` class
method.`),VPr=l(),yR=a("p"),XPr=o("This class cannot be instantiated directly using "),C7e=a("code"),zPr=o("__init__()"),QPr=o(" (throws an error)."),WPr=l(),zt=a("div"),F(xR.$$.fragment),UPr=l(),w7e=a("p"),HPr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),JPr=l(),Xm=a("p"),YPr=o(`Note:
Loading a model from its configuration file does `),A7e=a("strong"),ZPr=o("not"),KPr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zre=a("a"),eBr=o("from_pretrained()"),oBr=o(" to load the model weights."),rBr=l(),F(s5.$$.fragment),tBr=l(),Mo=a("div"),F($R.$$.fragment),aBr=l(),L7e=a("p"),nBr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),sBr=l(),$n=a("p"),lBr=o("The model class to instantiate is selected based on the "),y7e=a("code"),iBr=o("model_type"),dBr=o(` property of the config object (either
passed as an argument or loaded from `),x7e=a("code"),mBr=o("pretrained_model_name_or_path"),cBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$7e=a("code"),fBr=o("pretrained_model_name_or_path"),gBr=o(":"),hBr=l(),vt=a("ul"),l5=a("li"),k7e=a("strong"),uBr=o("data2vec-audio"),pBr=o(" \u2014 "),Qre=a("a"),_Br=o("Data2VecAudioForAudioFrameClassification"),bBr=o(" (Data2VecAudio model)"),vBr=l(),i5=a("li"),S7e=a("strong"),FBr=o("unispeech-sat"),TBr=o(" \u2014 "),Wre=a("a"),MBr=o("UniSpeechSatForAudioFrameClassification"),EBr=o(" (UniSpeechSat model)"),CBr=l(),d5=a("li"),R7e=a("strong"),wBr=o("wav2vec2"),ABr=o(" \u2014 "),Ure=a("a"),LBr=o("Wav2Vec2ForAudioFrameClassification"),yBr=o(" (Wav2Vec2 model)"),xBr=l(),m5=a("li"),P7e=a("strong"),$Br=o("wav2vec2-conformer"),kBr=o(" \u2014 "),Hre=a("a"),SBr=o("Wav2Vec2ConformerForAudioFrameClassification"),RBr=o(" (Wav2Vec2-Conformer model)"),PBr=l(),c5=a("li"),B7e=a("strong"),BBr=o("wavlm"),IBr=o(" \u2014 "),Jre=a("a"),NBr=o("WavLMForAudioFrameClassification"),qBr=o(" (WavLM model)"),DBr=l(),f5=a("p"),jBr=o("The model is set in evaluation mode by default using "),I7e=a("code"),GBr=o("model.eval()"),OBr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),N7e=a("code"),VBr=o("model.train()"),XBr=l(),F(g5.$$.fragment),cio=l(),zm=a("h2"),h5=a("a"),q7e=a("span"),F(kR.$$.fragment),zBr=l(),D7e=a("span"),QBr=o("AutoModelForCTC"),fio=l(),nr=a("div"),F(SR.$$.fragment),WBr=l(),Qm=a("p"),UBr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),Yre=a("a"),HBr=o("from_pretrained()"),JBr=o(" class method or the "),Zre=a("a"),YBr=o("from_config()"),ZBr=o(` class
method.`),KBr=l(),RR=a("p"),eIr=o("This class cannot be instantiated directly using "),j7e=a("code"),oIr=o("__init__()"),rIr=o(" (throws an error)."),tIr=l(),Qt=a("div"),F(PR.$$.fragment),aIr=l(),G7e=a("p"),nIr=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),sIr=l(),Wm=a("p"),lIr=o(`Note:
Loading a model from its configuration file does `),O7e=a("strong"),iIr=o("not"),dIr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Kre=a("a"),mIr=o("from_pretrained()"),cIr=o(" to load the model weights."),fIr=l(),F(u5.$$.fragment),gIr=l(),Eo=a("div"),F(BR.$$.fragment),hIr=l(),V7e=a("p"),uIr=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),pIr=l(),kn=a("p"),_Ir=o("The model class to instantiate is selected based on the "),X7e=a("code"),bIr=o("model_type"),vIr=o(` property of the config object (either
passed as an argument or loaded from `),z7e=a("code"),FIr=o("pretrained_model_name_or_path"),TIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q7e=a("code"),MIr=o("pretrained_model_name_or_path"),EIr=o(":"),CIr=l(),xe=a("ul"),p5=a("li"),W7e=a("strong"),wIr=o("data2vec-audio"),AIr=o(" \u2014 "),ete=a("a"),LIr=o("Data2VecAudioForCTC"),yIr=o(" (Data2VecAudio model)"),xIr=l(),_5=a("li"),U7e=a("strong"),$Ir=o("hubert"),kIr=o(" \u2014 "),ote=a("a"),SIr=o("HubertForCTC"),RIr=o(" (Hubert model)"),PIr=l(),b5=a("li"),H7e=a("strong"),BIr=o("mctct"),IIr=o(" \u2014 "),rte=a("a"),NIr=o("MCTCTForCTC"),qIr=o(" (M-CTC-T model)"),DIr=l(),v5=a("li"),J7e=a("strong"),jIr=o("sew"),GIr=o(" \u2014 "),tte=a("a"),OIr=o("SEWForCTC"),VIr=o(" (SEW model)"),XIr=l(),F5=a("li"),Y7e=a("strong"),zIr=o("sew-d"),QIr=o(" \u2014 "),ate=a("a"),WIr=o("SEWDForCTC"),UIr=o(" (SEW-D model)"),HIr=l(),T5=a("li"),Z7e=a("strong"),JIr=o("unispeech"),YIr=o(" \u2014 "),nte=a("a"),ZIr=o("UniSpeechForCTC"),KIr=o(" (UniSpeech model)"),eNr=l(),M5=a("li"),K7e=a("strong"),oNr=o("unispeech-sat"),rNr=o(" \u2014 "),ste=a("a"),tNr=o("UniSpeechSatForCTC"),aNr=o(" (UniSpeechSat model)"),nNr=l(),E5=a("li"),e8e=a("strong"),sNr=o("wav2vec2"),lNr=o(" \u2014 "),lte=a("a"),iNr=o("Wav2Vec2ForCTC"),dNr=o(" (Wav2Vec2 model)"),mNr=l(),C5=a("li"),o8e=a("strong"),cNr=o("wav2vec2-conformer"),fNr=o(" \u2014 "),ite=a("a"),gNr=o("Wav2Vec2ConformerForCTC"),hNr=o(" (Wav2Vec2-Conformer model)"),uNr=l(),w5=a("li"),r8e=a("strong"),pNr=o("wavlm"),_Nr=o(" \u2014 "),dte=a("a"),bNr=o("WavLMForCTC"),vNr=o(" (WavLM model)"),FNr=l(),A5=a("p"),TNr=o("The model is set in evaluation mode by default using "),t8e=a("code"),MNr=o("model.eval()"),ENr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),a8e=a("code"),CNr=o("model.train()"),wNr=l(),F(L5.$$.fragment),gio=l(),Um=a("h2"),y5=a("a"),n8e=a("span"),F(IR.$$.fragment),ANr=l(),s8e=a("span"),LNr=o("AutoModelForSpeechSeq2Seq"),hio=l(),sr=a("div"),F(NR.$$.fragment),yNr=l(),Hm=a("p"),xNr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),mte=a("a"),$Nr=o("from_pretrained()"),kNr=o(" class method or the "),cte=a("a"),SNr=o("from_config()"),RNr=o(` class
method.`),PNr=l(),qR=a("p"),BNr=o("This class cannot be instantiated directly using "),l8e=a("code"),INr=o("__init__()"),NNr=o(" (throws an error)."),qNr=l(),Wt=a("div"),F(DR.$$.fragment),DNr=l(),i8e=a("p"),jNr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),GNr=l(),Jm=a("p"),ONr=o(`Note:
Loading a model from its configuration file does `),d8e=a("strong"),VNr=o("not"),XNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fte=a("a"),zNr=o("from_pretrained()"),QNr=o(" to load the model weights."),WNr=l(),F(x5.$$.fragment),UNr=l(),Co=a("div"),F(jR.$$.fragment),HNr=l(),m8e=a("p"),JNr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),YNr=l(),Sn=a("p"),ZNr=o("The model class to instantiate is selected based on the "),c8e=a("code"),KNr=o("model_type"),eqr=o(` property of the config object (either
passed as an argument or loaded from `),f8e=a("code"),oqr=o("pretrained_model_name_or_path"),rqr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g8e=a("code"),tqr=o("pretrained_model_name_or_path"),aqr=o(":"),nqr=l(),Ym=a("ul"),$5=a("li"),h8e=a("strong"),sqr=o("speech-encoder-decoder"),lqr=o(" \u2014 "),gte=a("a"),iqr=o("SpeechEncoderDecoderModel"),dqr=o(" (Speech Encoder decoder model)"),mqr=l(),k5=a("li"),u8e=a("strong"),cqr=o("speech_to_text"),fqr=o(" \u2014 "),hte=a("a"),gqr=o("Speech2TextForConditionalGeneration"),hqr=o(" (Speech2Text model)"),uqr=l(),S5=a("li"),p8e=a("strong"),pqr=o("whisper"),_qr=o(" \u2014 "),ute=a("a"),bqr=o("WhisperForConditionalGeneration"),vqr=o(" (Whisper model)"),Fqr=l(),R5=a("p"),Tqr=o("The model is set in evaluation mode by default using "),_8e=a("code"),Mqr=o("model.eval()"),Eqr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b8e=a("code"),Cqr=o("model.train()"),wqr=l(),F(P5.$$.fragment),uio=l(),Zm=a("h2"),B5=a("a"),v8e=a("span"),F(GR.$$.fragment),Aqr=l(),F8e=a("span"),Lqr=o("AutoModelForAudioXVector"),pio=l(),lr=a("div"),F(OR.$$.fragment),yqr=l(),Km=a("p"),xqr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),pte=a("a"),$qr=o("from_pretrained()"),kqr=o(" class method or the "),_te=a("a"),Sqr=o("from_config()"),Rqr=o(` class
method.`),Pqr=l(),VR=a("p"),Bqr=o("This class cannot be instantiated directly using "),T8e=a("code"),Iqr=o("__init__()"),Nqr=o(" (throws an error)."),qqr=l(),Ut=a("div"),F(XR.$$.fragment),Dqr=l(),M8e=a("p"),jqr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Gqr=l(),ec=a("p"),Oqr=o(`Note:
Loading a model from its configuration file does `),E8e=a("strong"),Vqr=o("not"),Xqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bte=a("a"),zqr=o("from_pretrained()"),Qqr=o(" to load the model weights."),Wqr=l(),F(I5.$$.fragment),Uqr=l(),wo=a("div"),F(zR.$$.fragment),Hqr=l(),C8e=a("p"),Jqr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),Yqr=l(),Rn=a("p"),Zqr=o("The model class to instantiate is selected based on the "),w8e=a("code"),Kqr=o("model_type"),eDr=o(` property of the config object (either
passed as an argument or loaded from `),A8e=a("code"),oDr=o("pretrained_model_name_or_path"),rDr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L8e=a("code"),tDr=o("pretrained_model_name_or_path"),aDr=o(":"),nDr=l(),Ft=a("ul"),N5=a("li"),y8e=a("strong"),sDr=o("data2vec-audio"),lDr=o(" \u2014 "),vte=a("a"),iDr=o("Data2VecAudioForXVector"),dDr=o(" (Data2VecAudio model)"),mDr=l(),q5=a("li"),x8e=a("strong"),cDr=o("unispeech-sat"),fDr=o(" \u2014 "),Fte=a("a"),gDr=o("UniSpeechSatForXVector"),hDr=o(" (UniSpeechSat model)"),uDr=l(),D5=a("li"),$8e=a("strong"),pDr=o("wav2vec2"),_Dr=o(" \u2014 "),Tte=a("a"),bDr=o("Wav2Vec2ForXVector"),vDr=o(" (Wav2Vec2 model)"),FDr=l(),j5=a("li"),k8e=a("strong"),TDr=o("wav2vec2-conformer"),MDr=o(" \u2014 "),Mte=a("a"),EDr=o("Wav2Vec2ConformerForXVector"),CDr=o(" (Wav2Vec2-Conformer model)"),wDr=l(),G5=a("li"),S8e=a("strong"),ADr=o("wavlm"),LDr=o(" \u2014 "),Ete=a("a"),yDr=o("WavLMForXVector"),xDr=o(" (WavLM model)"),$Dr=l(),O5=a("p"),kDr=o("The model is set in evaluation mode by default using "),R8e=a("code"),SDr=o("model.eval()"),RDr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P8e=a("code"),PDr=o("model.train()"),BDr=l(),F(V5.$$.fragment),_io=l(),oc=a("h2"),X5=a("a"),B8e=a("span"),F(QR.$$.fragment),IDr=l(),I8e=a("span"),NDr=o("AutoModelForMaskedImageModeling"),bio=l(),ir=a("div"),F(WR.$$.fragment),qDr=l(),rc=a("p"),DDr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),Cte=a("a"),jDr=o("from_pretrained()"),GDr=o(" class method or the "),wte=a("a"),ODr=o("from_config()"),VDr=o(` class
method.`),XDr=l(),UR=a("p"),zDr=o("This class cannot be instantiated directly using "),N8e=a("code"),QDr=o("__init__()"),WDr=o(" (throws an error)."),UDr=l(),Ht=a("div"),F(HR.$$.fragment),HDr=l(),q8e=a("p"),JDr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),YDr=l(),tc=a("p"),ZDr=o(`Note:
Loading a model from its configuration file does `),D8e=a("strong"),KDr=o("not"),ejr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ate=a("a"),ojr=o("from_pretrained()"),rjr=o(" to load the model weights."),tjr=l(),F(z5.$$.fragment),ajr=l(),Ao=a("div"),F(JR.$$.fragment),njr=l(),j8e=a("p"),sjr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),ljr=l(),Pn=a("p"),ijr=o("The model class to instantiate is selected based on the "),G8e=a("code"),djr=o("model_type"),mjr=o(` property of the config object (either
passed as an argument or loaded from `),O8e=a("code"),cjr=o("pretrained_model_name_or_path"),fjr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V8e=a("code"),gjr=o("pretrained_model_name_or_path"),hjr=o(":"),ujr=l(),Bn=a("ul"),Q5=a("li"),X8e=a("strong"),pjr=o("deit"),_jr=o(" \u2014 "),Lte=a("a"),bjr=o("DeiTForMaskedImageModeling"),vjr=o(" (DeiT model)"),Fjr=l(),W5=a("li"),z8e=a("strong"),Tjr=o("swin"),Mjr=o(" \u2014 "),yte=a("a"),Ejr=o("SwinForMaskedImageModeling"),Cjr=o(" (Swin Transformer model)"),wjr=l(),U5=a("li"),Q8e=a("strong"),Ajr=o("swinv2"),Ljr=o(" \u2014 "),xte=a("a"),yjr=o("Swinv2ForMaskedImageModeling"),xjr=o(" (Swin Transformer V2 model)"),$jr=l(),H5=a("li"),W8e=a("strong"),kjr=o("vit"),Sjr=o(" \u2014 "),$te=a("a"),Rjr=o("ViTForMaskedImageModeling"),Pjr=o(" (ViT model)"),Bjr=l(),J5=a("p"),Ijr=o("The model is set in evaluation mode by default using "),U8e=a("code"),Njr=o("model.eval()"),qjr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),H8e=a("code"),Djr=o("model.train()"),jjr=l(),F(Y5.$$.fragment),vio=l(),ac=a("h2"),Z5=a("a"),J8e=a("span"),F(YR.$$.fragment),Gjr=l(),Y8e=a("span"),Ojr=o("AutoModelForObjectDetection"),Fio=l(),dr=a("div"),F(ZR.$$.fragment),Vjr=l(),nc=a("p"),Xjr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),kte=a("a"),zjr=o("from_pretrained()"),Qjr=o(" class method or the "),Ste=a("a"),Wjr=o("from_config()"),Ujr=o(` class
method.`),Hjr=l(),KR=a("p"),Jjr=o("This class cannot be instantiated directly using "),Z8e=a("code"),Yjr=o("__init__()"),Zjr=o(" (throws an error)."),Kjr=l(),Jt=a("div"),F(eP.$$.fragment),eGr=l(),K8e=a("p"),oGr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),rGr=l(),sc=a("p"),tGr=o(`Note:
Loading a model from its configuration file does `),eLe=a("strong"),aGr=o("not"),nGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Rte=a("a"),sGr=o("from_pretrained()"),lGr=o(" to load the model weights."),iGr=l(),F(K5.$$.fragment),dGr=l(),Lo=a("div"),F(oP.$$.fragment),mGr=l(),oLe=a("p"),cGr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),fGr=l(),In=a("p"),gGr=o("The model class to instantiate is selected based on the "),rLe=a("code"),hGr=o("model_type"),uGr=o(` property of the config object (either
passed as an argument or loaded from `),tLe=a("code"),pGr=o("pretrained_model_name_or_path"),_Gr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),aLe=a("code"),bGr=o("pretrained_model_name_or_path"),vGr=o(":"),FGr=l(),Tt=a("ul"),e0=a("li"),nLe=a("strong"),TGr=o("conditional_detr"),MGr=o(" \u2014 "),Pte=a("a"),EGr=o("ConditionalDetrForObjectDetection"),CGr=o(" (Conditional DETR model)"),wGr=l(),o0=a("li"),sLe=a("strong"),AGr=o("deformable_detr"),LGr=o(" \u2014 "),Bte=a("a"),yGr=o("DeformableDetrForObjectDetection"),xGr=o(" (Deformable DETR model)"),$Gr=l(),r0=a("li"),lLe=a("strong"),kGr=o("detr"),SGr=o(" \u2014 "),Ite=a("a"),RGr=o("DetrForObjectDetection"),PGr=o(" (DETR model)"),BGr=l(),t0=a("li"),iLe=a("strong"),IGr=o("table-transformer"),NGr=o(" \u2014 "),Nte=a("a"),qGr=o("TableTransformerForObjectDetection"),DGr=o(" (Table Transformer model)"),jGr=l(),a0=a("li"),dLe=a("strong"),GGr=o("yolos"),OGr=o(" \u2014 "),qte=a("a"),VGr=o("YolosForObjectDetection"),XGr=o(" (YOLOS model)"),zGr=l(),n0=a("p"),QGr=o("The model is set in evaluation mode by default using "),mLe=a("code"),WGr=o("model.eval()"),UGr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cLe=a("code"),HGr=o("model.train()"),JGr=l(),F(s0.$$.fragment),Tio=l(),lc=a("h2"),l0=a("a"),fLe=a("span"),F(rP.$$.fragment),YGr=l(),gLe=a("span"),ZGr=o("AutoModelForImageSegmentation"),Mio=l(),mr=a("div"),F(tP.$$.fragment),KGr=l(),ic=a("p"),eOr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),Dte=a("a"),oOr=o("from_pretrained()"),rOr=o(" class method or the "),jte=a("a"),tOr=o("from_config()"),aOr=o(` class
method.`),nOr=l(),aP=a("p"),sOr=o("This class cannot be instantiated directly using "),hLe=a("code"),lOr=o("__init__()"),iOr=o(" (throws an error)."),dOr=l(),Yt=a("div"),F(nP.$$.fragment),mOr=l(),uLe=a("p"),cOr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),fOr=l(),dc=a("p"),gOr=o(`Note:
Loading a model from its configuration file does `),pLe=a("strong"),hOr=o("not"),uOr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Gte=a("a"),pOr=o("from_pretrained()"),_Or=o(" to load the model weights."),bOr=l(),F(i0.$$.fragment),vOr=l(),yo=a("div"),F(sP.$$.fragment),FOr=l(),_Le=a("p"),TOr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),MOr=l(),Nn=a("p"),EOr=o("The model class to instantiate is selected based on the "),bLe=a("code"),COr=o("model_type"),wOr=o(` property of the config object (either
passed as an argument or loaded from `),vLe=a("code"),AOr=o("pretrained_model_name_or_path"),LOr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FLe=a("code"),yOr=o("pretrained_model_name_or_path"),xOr=o(":"),$Or=l(),TLe=a("ul"),d0=a("li"),MLe=a("strong"),kOr=o("detr"),SOr=o(" \u2014 "),Ote=a("a"),ROr=o("DetrForSegmentation"),POr=o(" (DETR model)"),BOr=l(),m0=a("p"),IOr=o("The model is set in evaluation mode by default using "),ELe=a("code"),NOr=o("model.eval()"),qOr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),CLe=a("code"),DOr=o("model.train()"),jOr=l(),F(c0.$$.fragment),Eio=l(),mc=a("h2"),f0=a("a"),wLe=a("span"),F(lP.$$.fragment),GOr=l(),ALe=a("span"),OOr=o("AutoModelForSemanticSegmentation"),Cio=l(),cr=a("div"),F(iP.$$.fragment),VOr=l(),cc=a("p"),XOr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Vte=a("a"),zOr=o("from_pretrained()"),QOr=o(" class method or the "),Xte=a("a"),WOr=o("from_config()"),UOr=o(` class
method.`),HOr=l(),dP=a("p"),JOr=o("This class cannot be instantiated directly using "),LLe=a("code"),YOr=o("__init__()"),ZOr=o(" (throws an error)."),KOr=l(),Zt=a("div"),F(mP.$$.fragment),eVr=l(),yLe=a("p"),oVr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),rVr=l(),fc=a("p"),tVr=o(`Note:
Loading a model from its configuration file does `),xLe=a("strong"),aVr=o("not"),nVr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zte=a("a"),sVr=o("from_pretrained()"),lVr=o(" to load the model weights."),iVr=l(),F(g0.$$.fragment),dVr=l(),xo=a("div"),F(cP.$$.fragment),mVr=l(),$Le=a("p"),cVr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),fVr=l(),qn=a("p"),gVr=o("The model class to instantiate is selected based on the "),kLe=a("code"),hVr=o("model_type"),uVr=o(` property of the config object (either
passed as an argument or loaded from `),SLe=a("code"),pVr=o("pretrained_model_name_or_path"),_Vr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RLe=a("code"),bVr=o("pretrained_model_name_or_path"),vVr=o(":"),FVr=l(),Mt=a("ul"),h0=a("li"),PLe=a("strong"),TVr=o("beit"),MVr=o(" \u2014 "),Qte=a("a"),EVr=o("BeitForSemanticSegmentation"),CVr=o(" (BEiT model)"),wVr=l(),u0=a("li"),BLe=a("strong"),AVr=o("data2vec-vision"),LVr=o(" \u2014 "),Wte=a("a"),yVr=o("Data2VecVisionForSemanticSegmentation"),xVr=o(" (Data2VecVision model)"),$Vr=l(),p0=a("li"),ILe=a("strong"),kVr=o("dpt"),SVr=o(" \u2014 "),Ute=a("a"),RVr=o("DPTForSemanticSegmentation"),PVr=o(" (DPT model)"),BVr=l(),_0=a("li"),NLe=a("strong"),IVr=o("mobilevit"),NVr=o(" \u2014 "),Hte=a("a"),qVr=o("MobileViTForSemanticSegmentation"),DVr=o(" (MobileViT model)"),jVr=l(),b0=a("li"),qLe=a("strong"),GVr=o("segformer"),OVr=o(" \u2014 "),Jte=a("a"),VVr=o("SegformerForSemanticSegmentation"),XVr=o(" (SegFormer model)"),zVr=l(),v0=a("p"),QVr=o("The model is set in evaluation mode by default using "),DLe=a("code"),WVr=o("model.eval()"),UVr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),jLe=a("code"),HVr=o("model.train()"),JVr=l(),F(F0.$$.fragment),wio=l(),gc=a("h2"),T0=a("a"),GLe=a("span"),F(fP.$$.fragment),YVr=l(),OLe=a("span"),ZVr=o("AutoModelForInstanceSegmentation"),Aio=l(),fr=a("div"),F(gP.$$.fragment),KVr=l(),hc=a("p"),eXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Yte=a("a"),oXr=o("from_pretrained()"),rXr=o(" class method or the "),Zte=a("a"),tXr=o("from_config()"),aXr=o(` class
method.`),nXr=l(),hP=a("p"),sXr=o("This class cannot be instantiated directly using "),VLe=a("code"),lXr=o("__init__()"),iXr=o(" (throws an error)."),dXr=l(),Kt=a("div"),F(uP.$$.fragment),mXr=l(),XLe=a("p"),cXr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),fXr=l(),uc=a("p"),gXr=o(`Note:
Loading a model from its configuration file does `),zLe=a("strong"),hXr=o("not"),uXr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Kte=a("a"),pXr=o("from_pretrained()"),_Xr=o(" to load the model weights."),bXr=l(),F(M0.$$.fragment),vXr=l(),$o=a("div"),F(pP.$$.fragment),FXr=l(),QLe=a("p"),TXr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),MXr=l(),Dn=a("p"),EXr=o("The model class to instantiate is selected based on the "),WLe=a("code"),CXr=o("model_type"),wXr=o(` property of the config object (either
passed as an argument or loaded from `),ULe=a("code"),AXr=o("pretrained_model_name_or_path"),LXr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HLe=a("code"),yXr=o("pretrained_model_name_or_path"),xXr=o(":"),$Xr=l(),JLe=a("ul"),E0=a("li"),YLe=a("strong"),kXr=o("maskformer"),SXr=o(" \u2014 "),eae=a("a"),RXr=o("MaskFormerForInstanceSegmentation"),PXr=o(" (MaskFormer model)"),BXr=l(),C0=a("p"),IXr=o("The model is set in evaluation mode by default using "),ZLe=a("code"),NXr=o("model.eval()"),qXr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),KLe=a("code"),DXr=o("model.train()"),jXr=l(),F(w0.$$.fragment),Lio=l(),pc=a("h2"),A0=a("a"),eye=a("span"),F(_P.$$.fragment),GXr=l(),oye=a("span"),OXr=o("AutoModelForZeroShotObjectDetection"),yio=l(),gr=a("div"),F(bP.$$.fragment),VXr=l(),_c=a("p"),XXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),oae=a("a"),zXr=o("from_pretrained()"),QXr=o(" class method or the "),rae=a("a"),WXr=o("from_config()"),UXr=o(` class
method.`),HXr=l(),vP=a("p"),JXr=o("This class cannot be instantiated directly using "),rye=a("code"),YXr=o("__init__()"),ZXr=o(" (throws an error)."),KXr=l(),ea=a("div"),F(FP.$$.fragment),ezr=l(),tye=a("p"),ozr=o("Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),rzr=l(),bc=a("p"),tzr=o(`Note:
Loading a model from its configuration file does `),aye=a("strong"),azr=o("not"),nzr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tae=a("a"),szr=o("from_pretrained()"),lzr=o(" to load the model weights."),izr=l(),F(L0.$$.fragment),dzr=l(),ko=a("div"),F(TP.$$.fragment),mzr=l(),nye=a("p"),czr=o("Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),fzr=l(),jn=a("p"),gzr=o("The model class to instantiate is selected based on the "),sye=a("code"),hzr=o("model_type"),uzr=o(` property of the config object (either
passed as an argument or loaded from `),lye=a("code"),pzr=o("pretrained_model_name_or_path"),_zr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iye=a("code"),bzr=o("pretrained_model_name_or_path"),vzr=o(":"),Fzr=l(),dye=a("ul"),y0=a("li"),mye=a("strong"),Tzr=o("owlvit"),Mzr=o(" \u2014 "),aae=a("a"),Ezr=o("OwlViTForObjectDetection"),Czr=o(" (OWL-ViT model)"),wzr=l(),x0=a("p"),Azr=o("The model is set in evaluation mode by default using "),cye=a("code"),Lzr=o("model.eval()"),yzr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),fye=a("code"),xzr=o("model.train()"),$zr=l(),F($0.$$.fragment),xio=l(),vc=a("h2"),k0=a("a"),gye=a("span"),F(MP.$$.fragment),kzr=l(),hye=a("span"),Szr=o("TFAutoModel"),$io=l(),hr=a("div"),F(EP.$$.fragment),Rzr=l(),Fc=a("p"),Pzr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),nae=a("a"),Bzr=o("from_pretrained()"),Izr=o(" class method or the "),sae=a("a"),Nzr=o("from_config()"),qzr=o(` class
method.`),Dzr=l(),CP=a("p"),jzr=o("This class cannot be instantiated directly using "),uye=a("code"),Gzr=o("__init__()"),Ozr=o(" (throws an error)."),Vzr=l(),oa=a("div"),F(wP.$$.fragment),Xzr=l(),pye=a("p"),zzr=o("Instantiates one of the base model classes of the library from a configuration."),Qzr=l(),Tc=a("p"),Wzr=o(`Note:
Loading a model from its configuration file does `),_ye=a("strong"),Uzr=o("not"),Hzr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lae=a("a"),Jzr=o("from_pretrained()"),Yzr=o(" to load the model weights."),Zzr=l(),F(S0.$$.fragment),Kzr=l(),Xr=a("div"),F(AP.$$.fragment),eQr=l(),bye=a("p"),oQr=o("Instantiate one of the base model classes of the library from a pretrained model."),rQr=l(),Gn=a("p"),tQr=o("The model class to instantiate is selected based on the "),vye=a("code"),aQr=o("model_type"),nQr=o(` property of the config object (either
passed as an argument or loaded from `),Fye=a("code"),sQr=o("pretrained_model_name_or_path"),lQr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tye=a("code"),iQr=o("pretrained_model_name_or_path"),dQr=o(":"),mQr=l(),P=a("ul"),R0=a("li"),Mye=a("strong"),cQr=o("albert"),fQr=o(" \u2014 "),iae=a("a"),gQr=o("TFAlbertModel"),hQr=o(" (ALBERT model)"),uQr=l(),P0=a("li"),Eye=a("strong"),pQr=o("bart"),_Qr=o(" \u2014 "),dae=a("a"),bQr=o("TFBartModel"),vQr=o(" (BART model)"),FQr=l(),B0=a("li"),Cye=a("strong"),TQr=o("bert"),MQr=o(" \u2014 "),mae=a("a"),EQr=o("TFBertModel"),CQr=o(" (BERT model)"),wQr=l(),I0=a("li"),wye=a("strong"),AQr=o("blenderbot"),LQr=o(" \u2014 "),cae=a("a"),yQr=o("TFBlenderbotModel"),xQr=o(" (Blenderbot model)"),$Qr=l(),N0=a("li"),Aye=a("strong"),kQr=o("blenderbot-small"),SQr=o(" \u2014 "),fae=a("a"),RQr=o("TFBlenderbotSmallModel"),PQr=o(" (BlenderbotSmall model)"),BQr=l(),q0=a("li"),Lye=a("strong"),IQr=o("camembert"),NQr=o(" \u2014 "),gae=a("a"),qQr=o("TFCamembertModel"),DQr=o(" (CamemBERT model)"),jQr=l(),D0=a("li"),yye=a("strong"),GQr=o("clip"),OQr=o(" \u2014 "),hae=a("a"),VQr=o("TFCLIPModel"),XQr=o(" (CLIP model)"),zQr=l(),j0=a("li"),xye=a("strong"),QQr=o("convbert"),WQr=o(" \u2014 "),uae=a("a"),UQr=o("TFConvBertModel"),HQr=o(" (ConvBERT model)"),JQr=l(),G0=a("li"),$ye=a("strong"),YQr=o("convnext"),ZQr=o(" \u2014 "),pae=a("a"),KQr=o("TFConvNextModel"),eWr=o(" (ConvNeXT model)"),oWr=l(),O0=a("li"),kye=a("strong"),rWr=o("ctrl"),tWr=o(" \u2014 "),_ae=a("a"),aWr=o("TFCTRLModel"),nWr=o(" (CTRL model)"),sWr=l(),V0=a("li"),Sye=a("strong"),lWr=o("cvt"),iWr=o(" \u2014 "),bae=a("a"),dWr=o("TFCvtModel"),mWr=o(" (CvT model)"),cWr=l(),X0=a("li"),Rye=a("strong"),fWr=o("data2vec-vision"),gWr=o(" \u2014 "),vae=a("a"),hWr=o("TFData2VecVisionModel"),uWr=o(" (Data2VecVision model)"),pWr=l(),z0=a("li"),Pye=a("strong"),_Wr=o("deberta"),bWr=o(" \u2014 "),Fae=a("a"),vWr=o("TFDebertaModel"),FWr=o(" (DeBERTa model)"),TWr=l(),Q0=a("li"),Bye=a("strong"),MWr=o("deberta-v2"),EWr=o(" \u2014 "),Tae=a("a"),CWr=o("TFDebertaV2Model"),wWr=o(" (DeBERTa-v2 model)"),AWr=l(),W0=a("li"),Iye=a("strong"),LWr=o("deit"),yWr=o(" \u2014 "),Mae=a("a"),xWr=o("TFDeiTModel"),$Wr=o(" (DeiT model)"),kWr=l(),U0=a("li"),Nye=a("strong"),SWr=o("distilbert"),RWr=o(" \u2014 "),Eae=a("a"),PWr=o("TFDistilBertModel"),BWr=o(" (DistilBERT model)"),IWr=l(),H0=a("li"),qye=a("strong"),NWr=o("dpr"),qWr=o(" \u2014 "),Cae=a("a"),DWr=o("TFDPRQuestionEncoder"),jWr=o(" (DPR model)"),GWr=l(),J0=a("li"),Dye=a("strong"),OWr=o("electra"),VWr=o(" \u2014 "),wae=a("a"),XWr=o("TFElectraModel"),zWr=o(" (ELECTRA model)"),QWr=l(),Y0=a("li"),jye=a("strong"),WWr=o("esm"),UWr=o(" \u2014 "),Aae=a("a"),HWr=o("TFEsmModel"),JWr=o(" (ESM model)"),YWr=l(),Z0=a("li"),Gye=a("strong"),ZWr=o("flaubert"),KWr=o(" \u2014 "),Lae=a("a"),eUr=o("TFFlaubertModel"),oUr=o(" (FlauBERT model)"),rUr=l(),Dl=a("li"),Oye=a("strong"),tUr=o("funnel"),aUr=o(" \u2014 "),yae=a("a"),nUr=o("TFFunnelModel"),sUr=o(" or "),xae=a("a"),lUr=o("TFFunnelBaseModel"),iUr=o(" (Funnel Transformer model)"),dUr=l(),K0=a("li"),Vye=a("strong"),mUr=o("gpt2"),cUr=o(" \u2014 "),$ae=a("a"),fUr=o("TFGPT2Model"),gUr=o(" (OpenAI GPT-2 model)"),hUr=l(),ew=a("li"),Xye=a("strong"),uUr=o("gptj"),pUr=o(" \u2014 "),kae=a("a"),_Ur=o("TFGPTJModel"),bUr=o(" (GPT-J model)"),vUr=l(),ow=a("li"),zye=a("strong"),FUr=o("groupvit"),TUr=o(" \u2014 "),Sae=a("a"),MUr=o("TFGroupViTModel"),EUr=o(" (GroupViT model)"),CUr=l(),rw=a("li"),Qye=a("strong"),wUr=o("hubert"),AUr=o(" \u2014 "),Rae=a("a"),LUr=o("TFHubertModel"),yUr=o(" (Hubert model)"),xUr=l(),tw=a("li"),Wye=a("strong"),$Ur=o("layoutlm"),kUr=o(" \u2014 "),Pae=a("a"),SUr=o("TFLayoutLMModel"),RUr=o(" (LayoutLM model)"),PUr=l(),aw=a("li"),Uye=a("strong"),BUr=o("layoutlmv3"),IUr=o(" \u2014 "),Bae=a("a"),NUr=o("TFLayoutLMv3Model"),qUr=o(" (LayoutLMv3 model)"),DUr=l(),nw=a("li"),Hye=a("strong"),jUr=o("led"),GUr=o(" \u2014 "),Iae=a("a"),OUr=o("TFLEDModel"),VUr=o(" (LED model)"),XUr=l(),sw=a("li"),Jye=a("strong"),zUr=o("longformer"),QUr=o(" \u2014 "),Nae=a("a"),WUr=o("TFLongformerModel"),UUr=o(" (Longformer model)"),HUr=l(),lw=a("li"),Yye=a("strong"),JUr=o("lxmert"),YUr=o(" \u2014 "),qae=a("a"),ZUr=o("TFLxmertModel"),KUr=o(" (LXMERT model)"),eHr=l(),iw=a("li"),Zye=a("strong"),oHr=o("marian"),rHr=o(" \u2014 "),Dae=a("a"),tHr=o("TFMarianModel"),aHr=o(" (Marian model)"),nHr=l(),dw=a("li"),Kye=a("strong"),sHr=o("mbart"),lHr=o(" \u2014 "),jae=a("a"),iHr=o("TFMBartModel"),dHr=o(" (mBART model)"),mHr=l(),mw=a("li"),e9e=a("strong"),cHr=o("mobilebert"),fHr=o(" \u2014 "),Gae=a("a"),gHr=o("TFMobileBertModel"),hHr=o(" (MobileBERT model)"),uHr=l(),cw=a("li"),o9e=a("strong"),pHr=o("mobilevit"),_Hr=o(" \u2014 "),Oae=a("a"),bHr=o("TFMobileViTModel"),vHr=o(" (MobileViT model)"),FHr=l(),fw=a("li"),r9e=a("strong"),THr=o("mpnet"),MHr=o(" \u2014 "),Vae=a("a"),EHr=o("TFMPNetModel"),CHr=o(" (MPNet model)"),wHr=l(),gw=a("li"),t9e=a("strong"),AHr=o("mt5"),LHr=o(" \u2014 "),Xae=a("a"),yHr=o("TFMT5Model"),xHr=o(" (MT5 model)"),$Hr=l(),hw=a("li"),a9e=a("strong"),kHr=o("openai-gpt"),SHr=o(" \u2014 "),zae=a("a"),RHr=o("TFOpenAIGPTModel"),PHr=o(" (OpenAI GPT model)"),BHr=l(),uw=a("li"),n9e=a("strong"),IHr=o("opt"),NHr=o(" \u2014 "),Qae=a("a"),qHr=o("TFOPTModel"),DHr=o(" (OPT model)"),jHr=l(),pw=a("li"),s9e=a("strong"),GHr=o("pegasus"),OHr=o(" \u2014 "),Wae=a("a"),VHr=o("TFPegasusModel"),XHr=o(" (Pegasus model)"),zHr=l(),_w=a("li"),l9e=a("strong"),QHr=o("regnet"),WHr=o(" \u2014 "),Uae=a("a"),UHr=o("TFRegNetModel"),HHr=o(" (RegNet model)"),JHr=l(),bw=a("li"),i9e=a("strong"),YHr=o("rembert"),ZHr=o(" \u2014 "),Hae=a("a"),KHr=o("TFRemBertModel"),eJr=o(" (RemBERT model)"),oJr=l(),vw=a("li"),d9e=a("strong"),rJr=o("resnet"),tJr=o(" \u2014 "),Jae=a("a"),aJr=o("TFResNetModel"),nJr=o(" (ResNet model)"),sJr=l(),Fw=a("li"),m9e=a("strong"),lJr=o("roberta"),iJr=o(" \u2014 "),Yae=a("a"),dJr=o("TFRobertaModel"),mJr=o(" (RoBERTa model)"),cJr=l(),Tw=a("li"),c9e=a("strong"),fJr=o("roformer"),gJr=o(" \u2014 "),Zae=a("a"),hJr=o("TFRoFormerModel"),uJr=o(" (RoFormer model)"),pJr=l(),Mw=a("li"),f9e=a("strong"),_Jr=o("segformer"),bJr=o(" \u2014 "),Kae=a("a"),vJr=o("TFSegformerModel"),FJr=o(" (SegFormer model)"),TJr=l(),Ew=a("li"),g9e=a("strong"),MJr=o("speech_to_text"),EJr=o(" \u2014 "),ene=a("a"),CJr=o("TFSpeech2TextModel"),wJr=o(" (Speech2Text model)"),AJr=l(),Cw=a("li"),h9e=a("strong"),LJr=o("swin"),yJr=o(" \u2014 "),one=a("a"),xJr=o("TFSwinModel"),$Jr=o(" (Swin Transformer model)"),kJr=l(),ww=a("li"),u9e=a("strong"),SJr=o("t5"),RJr=o(" \u2014 "),rne=a("a"),PJr=o("TFT5Model"),BJr=o(" (T5 model)"),IJr=l(),Aw=a("li"),p9e=a("strong"),NJr=o("tapas"),qJr=o(" \u2014 "),tne=a("a"),DJr=o("TFTapasModel"),jJr=o(" (TAPAS model)"),GJr=l(),Lw=a("li"),_9e=a("strong"),OJr=o("transfo-xl"),VJr=o(" \u2014 "),ane=a("a"),XJr=o("TFTransfoXLModel"),zJr=o(" (Transformer-XL model)"),QJr=l(),yw=a("li"),b9e=a("strong"),WJr=o("vit"),UJr=o(" \u2014 "),nne=a("a"),HJr=o("TFViTModel"),JJr=o(" (ViT model)"),YJr=l(),xw=a("li"),v9e=a("strong"),ZJr=o("vit_mae"),KJr=o(" \u2014 "),sne=a("a"),eYr=o("TFViTMAEModel"),oYr=o(" (ViTMAE model)"),rYr=l(),$w=a("li"),F9e=a("strong"),tYr=o("wav2vec2"),aYr=o(" \u2014 "),lne=a("a"),nYr=o("TFWav2Vec2Model"),sYr=o(" (Wav2Vec2 model)"),lYr=l(),kw=a("li"),T9e=a("strong"),iYr=o("whisper"),dYr=o(" \u2014 "),ine=a("a"),mYr=o("TFWhisperModel"),cYr=o(" (Whisper model)"),fYr=l(),Sw=a("li"),M9e=a("strong"),gYr=o("xglm"),hYr=o(" \u2014 "),dne=a("a"),uYr=o("TFXGLMModel"),pYr=o(" (XGLM model)"),_Yr=l(),Rw=a("li"),E9e=a("strong"),bYr=o("xlm"),vYr=o(" \u2014 "),mne=a("a"),FYr=o("TFXLMModel"),TYr=o(" (XLM model)"),MYr=l(),Pw=a("li"),C9e=a("strong"),EYr=o("xlm-roberta"),CYr=o(" \u2014 "),cne=a("a"),wYr=o("TFXLMRobertaModel"),AYr=o(" (XLM-RoBERTa model)"),LYr=l(),Bw=a("li"),w9e=a("strong"),yYr=o("xlnet"),xYr=o(" \u2014 "),fne=a("a"),$Yr=o("TFXLNetModel"),kYr=o(" (XLNet model)"),SYr=l(),F(Iw.$$.fragment),kio=l(),Mc=a("h2"),Nw=a("a"),A9e=a("span"),F(LP.$$.fragment),RYr=l(),L9e=a("span"),PYr=o("TFAutoModelForPreTraining"),Sio=l(),ur=a("div"),F(yP.$$.fragment),BYr=l(),Ec=a("p"),IYr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),gne=a("a"),NYr=o("from_pretrained()"),qYr=o(" class method or the "),hne=a("a"),DYr=o("from_config()"),jYr=o(` class
method.`),GYr=l(),xP=a("p"),OYr=o("This class cannot be instantiated directly using "),y9e=a("code"),VYr=o("__init__()"),XYr=o(" (throws an error)."),zYr=l(),ra=a("div"),F($P.$$.fragment),QYr=l(),x9e=a("p"),WYr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),UYr=l(),Cc=a("p"),HYr=o(`Note:
Loading a model from its configuration file does `),$9e=a("strong"),JYr=o("not"),YYr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),une=a("a"),ZYr=o("from_pretrained()"),KYr=o(" to load the model weights."),eZr=l(),F(qw.$$.fragment),oZr=l(),zr=a("div"),F(kP.$$.fragment),rZr=l(),k9e=a("p"),tZr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),aZr=l(),On=a("p"),nZr=o("The model class to instantiate is selected based on the "),S9e=a("code"),sZr=o("model_type"),lZr=o(` property of the config object (either
passed as an argument or loaded from `),R9e=a("code"),iZr=o("pretrained_model_name_or_path"),dZr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P9e=a("code"),mZr=o("pretrained_model_name_or_path"),cZr=o(":"),fZr=l(),de=a("ul"),Dw=a("li"),B9e=a("strong"),gZr=o("albert"),hZr=o(" \u2014 "),pne=a("a"),uZr=o("TFAlbertForPreTraining"),pZr=o(" (ALBERT model)"),_Zr=l(),jw=a("li"),I9e=a("strong"),bZr=o("bart"),vZr=o(" \u2014 "),_ne=a("a"),FZr=o("TFBartForConditionalGeneration"),TZr=o(" (BART model)"),MZr=l(),Gw=a("li"),N9e=a("strong"),EZr=o("bert"),CZr=o(" \u2014 "),bne=a("a"),wZr=o("TFBertForPreTraining"),AZr=o(" (BERT model)"),LZr=l(),Ow=a("li"),q9e=a("strong"),yZr=o("camembert"),xZr=o(" \u2014 "),vne=a("a"),$Zr=o("TFCamembertForMaskedLM"),kZr=o(" (CamemBERT model)"),SZr=l(),Vw=a("li"),D9e=a("strong"),RZr=o("ctrl"),PZr=o(" \u2014 "),Fne=a("a"),BZr=o("TFCTRLLMHeadModel"),IZr=o(" (CTRL model)"),NZr=l(),Xw=a("li"),j9e=a("strong"),qZr=o("distilbert"),DZr=o(" \u2014 "),Tne=a("a"),jZr=o("TFDistilBertForMaskedLM"),GZr=o(" (DistilBERT model)"),OZr=l(),zw=a("li"),G9e=a("strong"),VZr=o("electra"),XZr=o(" \u2014 "),Mne=a("a"),zZr=o("TFElectraForPreTraining"),QZr=o(" (ELECTRA model)"),WZr=l(),Qw=a("li"),O9e=a("strong"),UZr=o("flaubert"),HZr=o(" \u2014 "),Ene=a("a"),JZr=o("TFFlaubertWithLMHeadModel"),YZr=o(" (FlauBERT model)"),ZZr=l(),Ww=a("li"),V9e=a("strong"),KZr=o("funnel"),eKr=o(" \u2014 "),Cne=a("a"),oKr=o("TFFunnelForPreTraining"),rKr=o(" (Funnel Transformer model)"),tKr=l(),Uw=a("li"),X9e=a("strong"),aKr=o("gpt2"),nKr=o(" \u2014 "),wne=a("a"),sKr=o("TFGPT2LMHeadModel"),lKr=o(" (OpenAI GPT-2 model)"),iKr=l(),Hw=a("li"),z9e=a("strong"),dKr=o("layoutlm"),mKr=o(" \u2014 "),Ane=a("a"),cKr=o("TFLayoutLMForMaskedLM"),fKr=o(" (LayoutLM model)"),gKr=l(),Jw=a("li"),Q9e=a("strong"),hKr=o("lxmert"),uKr=o(" \u2014 "),Lne=a("a"),pKr=o("TFLxmertForPreTraining"),_Kr=o(" (LXMERT model)"),bKr=l(),Yw=a("li"),W9e=a("strong"),vKr=o("mobilebert"),FKr=o(" \u2014 "),yne=a("a"),TKr=o("TFMobileBertForPreTraining"),MKr=o(" (MobileBERT model)"),EKr=l(),Zw=a("li"),U9e=a("strong"),CKr=o("mpnet"),wKr=o(" \u2014 "),xne=a("a"),AKr=o("TFMPNetForMaskedLM"),LKr=o(" (MPNet model)"),yKr=l(),Kw=a("li"),H9e=a("strong"),xKr=o("openai-gpt"),$Kr=o(" \u2014 "),$ne=a("a"),kKr=o("TFOpenAIGPTLMHeadModel"),SKr=o(" (OpenAI GPT model)"),RKr=l(),eA=a("li"),J9e=a("strong"),PKr=o("roberta"),BKr=o(" \u2014 "),kne=a("a"),IKr=o("TFRobertaForMaskedLM"),NKr=o(" (RoBERTa model)"),qKr=l(),oA=a("li"),Y9e=a("strong"),DKr=o("t5"),jKr=o(" \u2014 "),Sne=a("a"),GKr=o("TFT5ForConditionalGeneration"),OKr=o(" (T5 model)"),VKr=l(),rA=a("li"),Z9e=a("strong"),XKr=o("tapas"),zKr=o(" \u2014 "),Rne=a("a"),QKr=o("TFTapasForMaskedLM"),WKr=o(" (TAPAS model)"),UKr=l(),tA=a("li"),K9e=a("strong"),HKr=o("transfo-xl"),JKr=o(" \u2014 "),Pne=a("a"),YKr=o("TFTransfoXLLMHeadModel"),ZKr=o(" (Transformer-XL model)"),KKr=l(),aA=a("li"),exe=a("strong"),eet=o("vit_mae"),oet=o(" \u2014 "),Bne=a("a"),ret=o("TFViTMAEForPreTraining"),tet=o(" (ViTMAE model)"),aet=l(),nA=a("li"),oxe=a("strong"),net=o("xlm"),set=o(" \u2014 "),Ine=a("a"),iet=o("TFXLMWithLMHeadModel"),det=o(" (XLM model)"),met=l(),sA=a("li"),rxe=a("strong"),cet=o("xlm-roberta"),fet=o(" \u2014 "),Nne=a("a"),get=o("TFXLMRobertaForMaskedLM"),het=o(" (XLM-RoBERTa model)"),uet=l(),lA=a("li"),txe=a("strong"),pet=o("xlnet"),_et=o(" \u2014 "),qne=a("a"),bet=o("TFXLNetLMHeadModel"),vet=o(" (XLNet model)"),Fet=l(),F(iA.$$.fragment),Rio=l(),wc=a("h2"),dA=a("a"),axe=a("span"),F(SP.$$.fragment),Tet=l(),nxe=a("span"),Met=o("TFAutoModelForCausalLM"),Pio=l(),pr=a("div"),F(RP.$$.fragment),Eet=l(),Ac=a("p"),Cet=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Dne=a("a"),wet=o("from_pretrained()"),Aet=o(" class method or the "),jne=a("a"),Let=o("from_config()"),yet=o(` class
method.`),xet=l(),PP=a("p"),$et=o("This class cannot be instantiated directly using "),sxe=a("code"),ket=o("__init__()"),Set=o(" (throws an error)."),Ret=l(),ta=a("div"),F(BP.$$.fragment),Pet=l(),lxe=a("p"),Bet=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Iet=l(),Lc=a("p"),Net=o(`Note:
Loading a model from its configuration file does `),ixe=a("strong"),qet=o("not"),Det=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Gne=a("a"),jet=o("from_pretrained()"),Get=o(" to load the model weights."),Oet=l(),F(mA.$$.fragment),Vet=l(),Qr=a("div"),F(IP.$$.fragment),Xet=l(),dxe=a("p"),zet=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Qet=l(),Vn=a("p"),Wet=o("The model class to instantiate is selected based on the "),mxe=a("code"),Uet=o("model_type"),Het=o(` property of the config object (either
passed as an argument or loaded from `),cxe=a("code"),Jet=o("pretrained_model_name_or_path"),Yet=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fxe=a("code"),Zet=o("pretrained_model_name_or_path"),Ket=o(":"),eot=l(),Ce=a("ul"),cA=a("li"),gxe=a("strong"),oot=o("bert"),rot=o(" \u2014 "),One=a("a"),tot=o("TFBertLMHeadModel"),aot=o(" (BERT model)"),not=l(),fA=a("li"),hxe=a("strong"),sot=o("camembert"),lot=o(" \u2014 "),Vne=a("a"),iot=o("TFCamembertForCausalLM"),dot=o(" (CamemBERT model)"),mot=l(),gA=a("li"),uxe=a("strong"),cot=o("ctrl"),fot=o(" \u2014 "),Xne=a("a"),got=o("TFCTRLLMHeadModel"),hot=o(" (CTRL model)"),uot=l(),hA=a("li"),pxe=a("strong"),pot=o("gpt2"),_ot=o(" \u2014 "),zne=a("a"),bot=o("TFGPT2LMHeadModel"),vot=o(" (OpenAI GPT-2 model)"),Fot=l(),uA=a("li"),_xe=a("strong"),Tot=o("gptj"),Mot=o(" \u2014 "),Qne=a("a"),Eot=o("TFGPTJForCausalLM"),Cot=o(" (GPT-J model)"),wot=l(),pA=a("li"),bxe=a("strong"),Aot=o("openai-gpt"),Lot=o(" \u2014 "),Wne=a("a"),yot=o("TFOpenAIGPTLMHeadModel"),xot=o(" (OpenAI GPT model)"),$ot=l(),_A=a("li"),vxe=a("strong"),kot=o("opt"),Sot=o(" \u2014 "),Une=a("a"),Rot=o("TFOPTForCausalLM"),Pot=o(" (OPT model)"),Bot=l(),bA=a("li"),Fxe=a("strong"),Iot=o("rembert"),Not=o(" \u2014 "),Hne=a("a"),qot=o("TFRemBertForCausalLM"),Dot=o(" (RemBERT model)"),jot=l(),vA=a("li"),Txe=a("strong"),Got=o("roberta"),Oot=o(" \u2014 "),Jne=a("a"),Vot=o("TFRobertaForCausalLM"),Xot=o(" (RoBERTa model)"),zot=l(),FA=a("li"),Mxe=a("strong"),Qot=o("roformer"),Wot=o(" \u2014 "),Yne=a("a"),Uot=o("TFRoFormerForCausalLM"),Hot=o(" (RoFormer model)"),Jot=l(),TA=a("li"),Exe=a("strong"),Yot=o("transfo-xl"),Zot=o(" \u2014 "),Zne=a("a"),Kot=o("TFTransfoXLLMHeadModel"),ert=o(" (Transformer-XL model)"),ort=l(),MA=a("li"),Cxe=a("strong"),rrt=o("xglm"),trt=o(" \u2014 "),Kne=a("a"),art=o("TFXGLMForCausalLM"),nrt=o(" (XGLM model)"),srt=l(),EA=a("li"),wxe=a("strong"),lrt=o("xlm"),irt=o(" \u2014 "),ese=a("a"),drt=o("TFXLMWithLMHeadModel"),mrt=o(" (XLM model)"),crt=l(),CA=a("li"),Axe=a("strong"),frt=o("xlnet"),grt=o(" \u2014 "),ose=a("a"),hrt=o("TFXLNetLMHeadModel"),urt=o(" (XLNet model)"),prt=l(),F(wA.$$.fragment),Bio=l(),yc=a("h2"),AA=a("a"),Lxe=a("span"),F(NP.$$.fragment),_rt=l(),yxe=a("span"),brt=o("TFAutoModelForImageClassification"),Iio=l(),_r=a("div"),F(qP.$$.fragment),vrt=l(),xc=a("p"),Frt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),rse=a("a"),Trt=o("from_pretrained()"),Mrt=o(" class method or the "),tse=a("a"),Ert=o("from_config()"),Crt=o(` class
method.`),wrt=l(),DP=a("p"),Art=o("This class cannot be instantiated directly using "),xxe=a("code"),Lrt=o("__init__()"),yrt=o(" (throws an error)."),xrt=l(),aa=a("div"),F(jP.$$.fragment),$rt=l(),$xe=a("p"),krt=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Srt=l(),$c=a("p"),Rrt=o(`Note:
Loading a model from its configuration file does `),kxe=a("strong"),Prt=o("not"),Brt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ase=a("a"),Irt=o("from_pretrained()"),Nrt=o(" to load the model weights."),qrt=l(),F(LA.$$.fragment),Drt=l(),Wr=a("div"),F(GP.$$.fragment),jrt=l(),Sxe=a("p"),Grt=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Ort=l(),Xn=a("p"),Vrt=o("The model class to instantiate is selected based on the "),Rxe=a("code"),Xrt=o("model_type"),zrt=o(` property of the config object (either
passed as an argument or loaded from `),Pxe=a("code"),Qrt=o("pretrained_model_name_or_path"),Wrt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bxe=a("code"),Urt=o("pretrained_model_name_or_path"),Hrt=o(":"),Jrt=l(),$e=a("ul"),yA=a("li"),Ixe=a("strong"),Yrt=o("convnext"),Zrt=o(" \u2014 "),nse=a("a"),Krt=o("TFConvNextForImageClassification"),ett=o(" (ConvNeXT model)"),ott=l(),xA=a("li"),Nxe=a("strong"),rtt=o("cvt"),ttt=o(" \u2014 "),sse=a("a"),att=o("TFCvtForImageClassification"),ntt=o(" (CvT model)"),stt=l(),$A=a("li"),qxe=a("strong"),ltt=o("data2vec-vision"),itt=o(" \u2014 "),lse=a("a"),dtt=o("TFData2VecVisionForImageClassification"),mtt=o(" (Data2VecVision model)"),ctt=l(),jl=a("li"),Dxe=a("strong"),ftt=o("deit"),gtt=o(" \u2014 "),ise=a("a"),htt=o("TFDeiTForImageClassification"),utt=o(" or "),dse=a("a"),ptt=o("TFDeiTForImageClassificationWithTeacher"),_tt=o(" (DeiT model)"),btt=l(),kA=a("li"),jxe=a("strong"),vtt=o("mobilevit"),Ftt=o(" \u2014 "),mse=a("a"),Ttt=o("TFMobileViTForImageClassification"),Mtt=o(" (MobileViT model)"),Ett=l(),SA=a("li"),Gxe=a("strong"),Ctt=o("regnet"),wtt=o(" \u2014 "),cse=a("a"),Att=o("TFRegNetForImageClassification"),Ltt=o(" (RegNet model)"),ytt=l(),RA=a("li"),Oxe=a("strong"),xtt=o("resnet"),$tt=o(" \u2014 "),fse=a("a"),ktt=o("TFResNetForImageClassification"),Stt=o(" (ResNet model)"),Rtt=l(),PA=a("li"),Vxe=a("strong"),Ptt=o("segformer"),Btt=o(" \u2014 "),gse=a("a"),Itt=o("TFSegformerForImageClassification"),Ntt=o(" (SegFormer model)"),qtt=l(),BA=a("li"),Xxe=a("strong"),Dtt=o("swin"),jtt=o(" \u2014 "),hse=a("a"),Gtt=o("TFSwinForImageClassification"),Ott=o(" (Swin Transformer model)"),Vtt=l(),IA=a("li"),zxe=a("strong"),Xtt=o("vit"),ztt=o(" \u2014 "),use=a("a"),Qtt=o("TFViTForImageClassification"),Wtt=o(" (ViT model)"),Utt=l(),F(NA.$$.fragment),Nio=l(),kc=a("h2"),qA=a("a"),Qxe=a("span"),F(OP.$$.fragment),Htt=l(),Wxe=a("span"),Jtt=o("TFAutoModelForSemanticSegmentation"),qio=l(),br=a("div"),F(VP.$$.fragment),Ytt=l(),Sc=a("p"),Ztt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),pse=a("a"),Ktt=o("from_pretrained()"),eat=o(" class method or the "),_se=a("a"),oat=o("from_config()"),rat=o(` class
method.`),tat=l(),XP=a("p"),aat=o("This class cannot be instantiated directly using "),Uxe=a("code"),nat=o("__init__()"),sat=o(" (throws an error)."),lat=l(),na=a("div"),F(zP.$$.fragment),iat=l(),Hxe=a("p"),dat=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),mat=l(),Rc=a("p"),cat=o(`Note:
Loading a model from its configuration file does `),Jxe=a("strong"),fat=o("not"),gat=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bse=a("a"),hat=o("from_pretrained()"),uat=o(" to load the model weights."),pat=l(),F(DA.$$.fragment),_at=l(),Ur=a("div"),F(QP.$$.fragment),bat=l(),Yxe=a("p"),vat=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Fat=l(),zn=a("p"),Tat=o("The model class to instantiate is selected based on the "),Zxe=a("code"),Mat=o("model_type"),Eat=o(` property of the config object (either
passed as an argument or loaded from `),Kxe=a("code"),Cat=o("pretrained_model_name_or_path"),wat=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e$e=a("code"),Aat=o("pretrained_model_name_or_path"),Lat=o(":"),yat=l(),Pc=a("ul"),jA=a("li"),o$e=a("strong"),xat=o("data2vec-vision"),$at=o(" \u2014 "),vse=a("a"),kat=o("TFData2VecVisionForSemanticSegmentation"),Sat=o(" (Data2VecVision model)"),Rat=l(),GA=a("li"),r$e=a("strong"),Pat=o("mobilevit"),Bat=o(" \u2014 "),Fse=a("a"),Iat=o("TFMobileViTForSemanticSegmentation"),Nat=o(" (MobileViT model)"),qat=l(),OA=a("li"),t$e=a("strong"),Dat=o("segformer"),jat=o(" \u2014 "),Tse=a("a"),Gat=o("TFSegformerForSemanticSegmentation"),Oat=o(" (SegFormer model)"),Vat=l(),F(VA.$$.fragment),Dio=l(),Bc=a("h2"),XA=a("a"),a$e=a("span"),F(WP.$$.fragment),Xat=l(),n$e=a("span"),zat=o("TFAutoModelForMaskedLM"),jio=l(),vr=a("div"),F(UP.$$.fragment),Qat=l(),Ic=a("p"),Wat=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Mse=a("a"),Uat=o("from_pretrained()"),Hat=o(" class method or the "),Ese=a("a"),Jat=o("from_config()"),Yat=o(` class
method.`),Zat=l(),HP=a("p"),Kat=o("This class cannot be instantiated directly using "),s$e=a("code"),ent=o("__init__()"),ont=o(" (throws an error)."),rnt=l(),sa=a("div"),F(JP.$$.fragment),tnt=l(),l$e=a("p"),ant=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),nnt=l(),Nc=a("p"),snt=o(`Note:
Loading a model from its configuration file does `),i$e=a("strong"),lnt=o("not"),int=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Cse=a("a"),dnt=o("from_pretrained()"),mnt=o(" to load the model weights."),cnt=l(),F(zA.$$.fragment),fnt=l(),Hr=a("div"),F(YP.$$.fragment),gnt=l(),d$e=a("p"),hnt=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),unt=l(),Qn=a("p"),pnt=o("The model class to instantiate is selected based on the "),m$e=a("code"),_nt=o("model_type"),bnt=o(` property of the config object (either
passed as an argument or loaded from `),c$e=a("code"),vnt=o("pretrained_model_name_or_path"),Fnt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f$e=a("code"),Tnt=o("pretrained_model_name_or_path"),Mnt=o(":"),Ent=l(),ge=a("ul"),QA=a("li"),g$e=a("strong"),Cnt=o("albert"),wnt=o(" \u2014 "),wse=a("a"),Ant=o("TFAlbertForMaskedLM"),Lnt=o(" (ALBERT model)"),ynt=l(),WA=a("li"),h$e=a("strong"),xnt=o("bert"),$nt=o(" \u2014 "),Ase=a("a"),knt=o("TFBertForMaskedLM"),Snt=o(" (BERT model)"),Rnt=l(),UA=a("li"),u$e=a("strong"),Pnt=o("camembert"),Bnt=o(" \u2014 "),Lse=a("a"),Int=o("TFCamembertForMaskedLM"),Nnt=o(" (CamemBERT model)"),qnt=l(),HA=a("li"),p$e=a("strong"),Dnt=o("convbert"),jnt=o(" \u2014 "),yse=a("a"),Gnt=o("TFConvBertForMaskedLM"),Ont=o(" (ConvBERT model)"),Vnt=l(),JA=a("li"),_$e=a("strong"),Xnt=o("deberta"),znt=o(" \u2014 "),xse=a("a"),Qnt=o("TFDebertaForMaskedLM"),Wnt=o(" (DeBERTa model)"),Unt=l(),YA=a("li"),b$e=a("strong"),Hnt=o("deberta-v2"),Jnt=o(" \u2014 "),$se=a("a"),Ynt=o("TFDebertaV2ForMaskedLM"),Znt=o(" (DeBERTa-v2 model)"),Knt=l(),ZA=a("li"),v$e=a("strong"),est=o("distilbert"),ost=o(" \u2014 "),kse=a("a"),rst=o("TFDistilBertForMaskedLM"),tst=o(" (DistilBERT model)"),ast=l(),KA=a("li"),F$e=a("strong"),nst=o("electra"),sst=o(" \u2014 "),Sse=a("a"),lst=o("TFElectraForMaskedLM"),ist=o(" (ELECTRA model)"),dst=l(),e6=a("li"),T$e=a("strong"),mst=o("esm"),cst=o(" \u2014 "),Rse=a("a"),fst=o("TFEsmForMaskedLM"),gst=o(" (ESM model)"),hst=l(),o6=a("li"),M$e=a("strong"),ust=o("flaubert"),pst=o(" \u2014 "),Pse=a("a"),_st=o("TFFlaubertWithLMHeadModel"),bst=o(" (FlauBERT model)"),vst=l(),r6=a("li"),E$e=a("strong"),Fst=o("funnel"),Tst=o(" \u2014 "),Bse=a("a"),Mst=o("TFFunnelForMaskedLM"),Est=o(" (Funnel Transformer model)"),Cst=l(),t6=a("li"),C$e=a("strong"),wst=o("layoutlm"),Ast=o(" \u2014 "),Ise=a("a"),Lst=o("TFLayoutLMForMaskedLM"),yst=o(" (LayoutLM model)"),xst=l(),a6=a("li"),w$e=a("strong"),$st=o("longformer"),kst=o(" \u2014 "),Nse=a("a"),Sst=o("TFLongformerForMaskedLM"),Rst=o(" (Longformer model)"),Pst=l(),n6=a("li"),A$e=a("strong"),Bst=o("mobilebert"),Ist=o(" \u2014 "),qse=a("a"),Nst=o("TFMobileBertForMaskedLM"),qst=o(" (MobileBERT model)"),Dst=l(),s6=a("li"),L$e=a("strong"),jst=o("mpnet"),Gst=o(" \u2014 "),Dse=a("a"),Ost=o("TFMPNetForMaskedLM"),Vst=o(" (MPNet model)"),Xst=l(),l6=a("li"),y$e=a("strong"),zst=o("rembert"),Qst=o(" \u2014 "),jse=a("a"),Wst=o("TFRemBertForMaskedLM"),Ust=o(" (RemBERT model)"),Hst=l(),i6=a("li"),x$e=a("strong"),Jst=o("roberta"),Yst=o(" \u2014 "),Gse=a("a"),Zst=o("TFRobertaForMaskedLM"),Kst=o(" (RoBERTa model)"),elt=l(),d6=a("li"),$$e=a("strong"),olt=o("roformer"),rlt=o(" \u2014 "),Ose=a("a"),tlt=o("TFRoFormerForMaskedLM"),alt=o(" (RoFormer model)"),nlt=l(),m6=a("li"),k$e=a("strong"),slt=o("tapas"),llt=o(" \u2014 "),Vse=a("a"),ilt=o("TFTapasForMaskedLM"),dlt=o(" (TAPAS model)"),mlt=l(),c6=a("li"),S$e=a("strong"),clt=o("xlm"),flt=o(" \u2014 "),Xse=a("a"),glt=o("TFXLMWithLMHeadModel"),hlt=o(" (XLM model)"),ult=l(),f6=a("li"),R$e=a("strong"),plt=o("xlm-roberta"),_lt=o(" \u2014 "),zse=a("a"),blt=o("TFXLMRobertaForMaskedLM"),vlt=o(" (XLM-RoBERTa model)"),Flt=l(),F(g6.$$.fragment),Gio=l(),qc=a("h2"),h6=a("a"),P$e=a("span"),F(ZP.$$.fragment),Tlt=l(),B$e=a("span"),Mlt=o("TFAutoModelForSeq2SeqLM"),Oio=l(),Fr=a("div"),F(KP.$$.fragment),Elt=l(),Dc=a("p"),Clt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Qse=a("a"),wlt=o("from_pretrained()"),Alt=o(" class method or the "),Wse=a("a"),Llt=o("from_config()"),ylt=o(` class
method.`),xlt=l(),eB=a("p"),$lt=o("This class cannot be instantiated directly using "),I$e=a("code"),klt=o("__init__()"),Slt=o(" (throws an error)."),Rlt=l(),la=a("div"),F(oB.$$.fragment),Plt=l(),N$e=a("p"),Blt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Ilt=l(),jc=a("p"),Nlt=o(`Note:
Loading a model from its configuration file does `),q$e=a("strong"),qlt=o("not"),Dlt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Use=a("a"),jlt=o("from_pretrained()"),Glt=o(" to load the model weights."),Olt=l(),F(u6.$$.fragment),Vlt=l(),Jr=a("div"),F(rB.$$.fragment),Xlt=l(),D$e=a("p"),zlt=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Qlt=l(),Wn=a("p"),Wlt=o("The model class to instantiate is selected based on the "),j$e=a("code"),Ult=o("model_type"),Hlt=o(` property of the config object (either
passed as an argument or loaded from `),G$e=a("code"),Jlt=o("pretrained_model_name_or_path"),Ylt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O$e=a("code"),Zlt=o("pretrained_model_name_or_path"),Klt=o(":"),eit=l(),ke=a("ul"),p6=a("li"),V$e=a("strong"),oit=o("bart"),rit=o(" \u2014 "),Hse=a("a"),tit=o("TFBartForConditionalGeneration"),ait=o(" (BART model)"),nit=l(),_6=a("li"),X$e=a("strong"),sit=o("blenderbot"),lit=o(" \u2014 "),Jse=a("a"),iit=o("TFBlenderbotForConditionalGeneration"),dit=o(" (Blenderbot model)"),mit=l(),b6=a("li"),z$e=a("strong"),cit=o("blenderbot-small"),fit=o(" \u2014 "),Yse=a("a"),git=o("TFBlenderbotSmallForConditionalGeneration"),hit=o(" (BlenderbotSmall model)"),uit=l(),v6=a("li"),Q$e=a("strong"),pit=o("encoder-decoder"),_it=o(" \u2014 "),Zse=a("a"),bit=o("TFEncoderDecoderModel"),vit=o(" (Encoder decoder model)"),Fit=l(),F6=a("li"),W$e=a("strong"),Tit=o("led"),Mit=o(" \u2014 "),Kse=a("a"),Eit=o("TFLEDForConditionalGeneration"),Cit=o(" (LED model)"),wit=l(),T6=a("li"),U$e=a("strong"),Ait=o("marian"),Lit=o(" \u2014 "),ele=a("a"),yit=o("TFMarianMTModel"),xit=o(" (Marian model)"),$it=l(),M6=a("li"),H$e=a("strong"),kit=o("mbart"),Sit=o(" \u2014 "),ole=a("a"),Rit=o("TFMBartForConditionalGeneration"),Pit=o(" (mBART model)"),Bit=l(),E6=a("li"),J$e=a("strong"),Iit=o("mt5"),Nit=o(" \u2014 "),rle=a("a"),qit=o("TFMT5ForConditionalGeneration"),Dit=o(" (MT5 model)"),jit=l(),C6=a("li"),Y$e=a("strong"),Git=o("pegasus"),Oit=o(" \u2014 "),tle=a("a"),Vit=o("TFPegasusForConditionalGeneration"),Xit=o(" (Pegasus model)"),zit=l(),w6=a("li"),Z$e=a("strong"),Qit=o("t5"),Wit=o(" \u2014 "),ale=a("a"),Uit=o("TFT5ForConditionalGeneration"),Hit=o(" (T5 model)"),Jit=l(),F(A6.$$.fragment),Vio=l(),Gc=a("h2"),L6=a("a"),K$e=a("span"),F(tB.$$.fragment),Yit=l(),eke=a("span"),Zit=o("TFAutoModelForSequenceClassification"),Xio=l(),Tr=a("div"),F(aB.$$.fragment),Kit=l(),Oc=a("p"),edt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),nle=a("a"),odt=o("from_pretrained()"),rdt=o(" class method or the "),sle=a("a"),tdt=o("from_config()"),adt=o(` class
method.`),ndt=l(),nB=a("p"),sdt=o("This class cannot be instantiated directly using "),oke=a("code"),ldt=o("__init__()"),idt=o(" (throws an error)."),ddt=l(),ia=a("div"),F(sB.$$.fragment),mdt=l(),rke=a("p"),cdt=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),fdt=l(),Vc=a("p"),gdt=o(`Note:
Loading a model from its configuration file does `),tke=a("strong"),hdt=o("not"),udt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lle=a("a"),pdt=o("from_pretrained()"),_dt=o(" to load the model weights."),bdt=l(),F(y6.$$.fragment),vdt=l(),Yr=a("div"),F(lB.$$.fragment),Fdt=l(),ake=a("p"),Tdt=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Mdt=l(),Un=a("p"),Edt=o("The model class to instantiate is selected based on the "),nke=a("code"),Cdt=o("model_type"),wdt=o(` property of the config object (either
passed as an argument or loaded from `),ske=a("code"),Adt=o("pretrained_model_name_or_path"),Ldt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lke=a("code"),ydt=o("pretrained_model_name_or_path"),xdt=o(":"),$dt=l(),te=a("ul"),x6=a("li"),ike=a("strong"),kdt=o("albert"),Sdt=o(" \u2014 "),ile=a("a"),Rdt=o("TFAlbertForSequenceClassification"),Pdt=o(" (ALBERT model)"),Bdt=l(),$6=a("li"),dke=a("strong"),Idt=o("bert"),Ndt=o(" \u2014 "),dle=a("a"),qdt=o("TFBertForSequenceClassification"),Ddt=o(" (BERT model)"),jdt=l(),k6=a("li"),mke=a("strong"),Gdt=o("camembert"),Odt=o(" \u2014 "),mle=a("a"),Vdt=o("TFCamembertForSequenceClassification"),Xdt=o(" (CamemBERT model)"),zdt=l(),S6=a("li"),cke=a("strong"),Qdt=o("convbert"),Wdt=o(" \u2014 "),cle=a("a"),Udt=o("TFConvBertForSequenceClassification"),Hdt=o(" (ConvBERT model)"),Jdt=l(),R6=a("li"),fke=a("strong"),Ydt=o("ctrl"),Zdt=o(" \u2014 "),fle=a("a"),Kdt=o("TFCTRLForSequenceClassification"),emt=o(" (CTRL model)"),omt=l(),P6=a("li"),gke=a("strong"),rmt=o("deberta"),tmt=o(" \u2014 "),gle=a("a"),amt=o("TFDebertaForSequenceClassification"),nmt=o(" (DeBERTa model)"),smt=l(),B6=a("li"),hke=a("strong"),lmt=o("deberta-v2"),imt=o(" \u2014 "),hle=a("a"),dmt=o("TFDebertaV2ForSequenceClassification"),mmt=o(" (DeBERTa-v2 model)"),cmt=l(),I6=a("li"),uke=a("strong"),fmt=o("distilbert"),gmt=o(" \u2014 "),ule=a("a"),hmt=o("TFDistilBertForSequenceClassification"),umt=o(" (DistilBERT model)"),pmt=l(),N6=a("li"),pke=a("strong"),_mt=o("electra"),bmt=o(" \u2014 "),ple=a("a"),vmt=o("TFElectraForSequenceClassification"),Fmt=o(" (ELECTRA model)"),Tmt=l(),q6=a("li"),_ke=a("strong"),Mmt=o("esm"),Emt=o(" \u2014 "),_le=a("a"),Cmt=o("TFEsmForSequenceClassification"),wmt=o(" (ESM model)"),Amt=l(),D6=a("li"),bke=a("strong"),Lmt=o("flaubert"),ymt=o(" \u2014 "),ble=a("a"),xmt=o("TFFlaubertForSequenceClassification"),$mt=o(" (FlauBERT model)"),kmt=l(),j6=a("li"),vke=a("strong"),Smt=o("funnel"),Rmt=o(" \u2014 "),vle=a("a"),Pmt=o("TFFunnelForSequenceClassification"),Bmt=o(" (Funnel Transformer model)"),Imt=l(),G6=a("li"),Fke=a("strong"),Nmt=o("gpt2"),qmt=o(" \u2014 "),Fle=a("a"),Dmt=o("TFGPT2ForSequenceClassification"),jmt=o(" (OpenAI GPT-2 model)"),Gmt=l(),O6=a("li"),Tke=a("strong"),Omt=o("gptj"),Vmt=o(" \u2014 "),Tle=a("a"),Xmt=o("TFGPTJForSequenceClassification"),zmt=o(" (GPT-J model)"),Qmt=l(),V6=a("li"),Mke=a("strong"),Wmt=o("layoutlm"),Umt=o(" \u2014 "),Mle=a("a"),Hmt=o("TFLayoutLMForSequenceClassification"),Jmt=o(" (LayoutLM model)"),Ymt=l(),X6=a("li"),Eke=a("strong"),Zmt=o("layoutlmv3"),Kmt=o(" \u2014 "),Ele=a("a"),ect=o("TFLayoutLMv3ForSequenceClassification"),oct=o(" (LayoutLMv3 model)"),rct=l(),z6=a("li"),Cke=a("strong"),tct=o("longformer"),act=o(" \u2014 "),Cle=a("a"),nct=o("TFLongformerForSequenceClassification"),sct=o(" (Longformer model)"),lct=l(),Q6=a("li"),wke=a("strong"),ict=o("mobilebert"),dct=o(" \u2014 "),wle=a("a"),mct=o("TFMobileBertForSequenceClassification"),cct=o(" (MobileBERT model)"),fct=l(),W6=a("li"),Ake=a("strong"),gct=o("mpnet"),hct=o(" \u2014 "),Ale=a("a"),uct=o("TFMPNetForSequenceClassification"),pct=o(" (MPNet model)"),_ct=l(),U6=a("li"),Lke=a("strong"),bct=o("openai-gpt"),vct=o(" \u2014 "),Lle=a("a"),Fct=o("TFOpenAIGPTForSequenceClassification"),Tct=o(" (OpenAI GPT model)"),Mct=l(),H6=a("li"),yke=a("strong"),Ect=o("rembert"),Cct=o(" \u2014 "),yle=a("a"),wct=o("TFRemBertForSequenceClassification"),Act=o(" (RemBERT model)"),Lct=l(),J6=a("li"),xke=a("strong"),yct=o("roberta"),xct=o(" \u2014 "),xle=a("a"),$ct=o("TFRobertaForSequenceClassification"),kct=o(" (RoBERTa model)"),Sct=l(),Y6=a("li"),$ke=a("strong"),Rct=o("roformer"),Pct=o(" \u2014 "),$le=a("a"),Bct=o("TFRoFormerForSequenceClassification"),Ict=o(" (RoFormer model)"),Nct=l(),Z6=a("li"),kke=a("strong"),qct=o("tapas"),Dct=o(" \u2014 "),kle=a("a"),jct=o("TFTapasForSequenceClassification"),Gct=o(" (TAPAS model)"),Oct=l(),K6=a("li"),Ske=a("strong"),Vct=o("transfo-xl"),Xct=o(" \u2014 "),Sle=a("a"),zct=o("TFTransfoXLForSequenceClassification"),Qct=o(" (Transformer-XL model)"),Wct=l(),e7=a("li"),Rke=a("strong"),Uct=o("xlm"),Hct=o(" \u2014 "),Rle=a("a"),Jct=o("TFXLMForSequenceClassification"),Yct=o(" (XLM model)"),Zct=l(),o7=a("li"),Pke=a("strong"),Kct=o("xlm-roberta"),eft=o(" \u2014 "),Ple=a("a"),oft=o("TFXLMRobertaForSequenceClassification"),rft=o(" (XLM-RoBERTa model)"),tft=l(),r7=a("li"),Bke=a("strong"),aft=o("xlnet"),nft=o(" \u2014 "),Ble=a("a"),sft=o("TFXLNetForSequenceClassification"),lft=o(" (XLNet model)"),ift=l(),F(t7.$$.fragment),zio=l(),Xc=a("h2"),a7=a("a"),Ike=a("span"),F(iB.$$.fragment),dft=l(),Nke=a("span"),mft=o("TFAutoModelForMultipleChoice"),Qio=l(),Mr=a("div"),F(dB.$$.fragment),cft=l(),zc=a("p"),fft=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Ile=a("a"),gft=o("from_pretrained()"),hft=o(" class method or the "),Nle=a("a"),uft=o("from_config()"),pft=o(` class
method.`),_ft=l(),mB=a("p"),bft=o("This class cannot be instantiated directly using "),qke=a("code"),vft=o("__init__()"),Fft=o(" (throws an error)."),Tft=l(),da=a("div"),F(cB.$$.fragment),Mft=l(),Dke=a("p"),Eft=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Cft=l(),Qc=a("p"),wft=o(`Note:
Loading a model from its configuration file does `),jke=a("strong"),Aft=o("not"),Lft=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qle=a("a"),yft=o("from_pretrained()"),xft=o(" to load the model weights."),$ft=l(),F(n7.$$.fragment),kft=l(),Zr=a("div"),F(fB.$$.fragment),Sft=l(),Gke=a("p"),Rft=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Pft=l(),Hn=a("p"),Bft=o("The model class to instantiate is selected based on the "),Oke=a("code"),Ift=o("model_type"),Nft=o(` property of the config object (either
passed as an argument or loaded from `),Vke=a("code"),qft=o("pretrained_model_name_or_path"),Dft=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xke=a("code"),jft=o("pretrained_model_name_or_path"),Gft=o(":"),Oft=l(),Te=a("ul"),s7=a("li"),zke=a("strong"),Vft=o("albert"),Xft=o(" \u2014 "),Dle=a("a"),zft=o("TFAlbertForMultipleChoice"),Qft=o(" (ALBERT model)"),Wft=l(),l7=a("li"),Qke=a("strong"),Uft=o("bert"),Hft=o(" \u2014 "),jle=a("a"),Jft=o("TFBertForMultipleChoice"),Yft=o(" (BERT model)"),Zft=l(),i7=a("li"),Wke=a("strong"),Kft=o("camembert"),egt=o(" \u2014 "),Gle=a("a"),ogt=o("TFCamembertForMultipleChoice"),rgt=o(" (CamemBERT model)"),tgt=l(),d7=a("li"),Uke=a("strong"),agt=o("convbert"),ngt=o(" \u2014 "),Ole=a("a"),sgt=o("TFConvBertForMultipleChoice"),lgt=o(" (ConvBERT model)"),igt=l(),m7=a("li"),Hke=a("strong"),dgt=o("distilbert"),mgt=o(" \u2014 "),Vle=a("a"),cgt=o("TFDistilBertForMultipleChoice"),fgt=o(" (DistilBERT model)"),ggt=l(),c7=a("li"),Jke=a("strong"),hgt=o("electra"),ugt=o(" \u2014 "),Xle=a("a"),pgt=o("TFElectraForMultipleChoice"),_gt=o(" (ELECTRA model)"),bgt=l(),f7=a("li"),Yke=a("strong"),vgt=o("flaubert"),Fgt=o(" \u2014 "),zle=a("a"),Tgt=o("TFFlaubertForMultipleChoice"),Mgt=o(" (FlauBERT model)"),Egt=l(),g7=a("li"),Zke=a("strong"),Cgt=o("funnel"),wgt=o(" \u2014 "),Qle=a("a"),Agt=o("TFFunnelForMultipleChoice"),Lgt=o(" (Funnel Transformer model)"),ygt=l(),h7=a("li"),Kke=a("strong"),xgt=o("longformer"),$gt=o(" \u2014 "),Wle=a("a"),kgt=o("TFLongformerForMultipleChoice"),Sgt=o(" (Longformer model)"),Rgt=l(),u7=a("li"),eSe=a("strong"),Pgt=o("mobilebert"),Bgt=o(" \u2014 "),Ule=a("a"),Igt=o("TFMobileBertForMultipleChoice"),Ngt=o(" (MobileBERT model)"),qgt=l(),p7=a("li"),oSe=a("strong"),Dgt=o("mpnet"),jgt=o(" \u2014 "),Hle=a("a"),Ggt=o("TFMPNetForMultipleChoice"),Ogt=o(" (MPNet model)"),Vgt=l(),_7=a("li"),rSe=a("strong"),Xgt=o("rembert"),zgt=o(" \u2014 "),Jle=a("a"),Qgt=o("TFRemBertForMultipleChoice"),Wgt=o(" (RemBERT model)"),Ugt=l(),b7=a("li"),tSe=a("strong"),Hgt=o("roberta"),Jgt=o(" \u2014 "),Yle=a("a"),Ygt=o("TFRobertaForMultipleChoice"),Zgt=o(" (RoBERTa model)"),Kgt=l(),v7=a("li"),aSe=a("strong"),eht=o("roformer"),oht=o(" \u2014 "),Zle=a("a"),rht=o("TFRoFormerForMultipleChoice"),tht=o(" (RoFormer model)"),aht=l(),F7=a("li"),nSe=a("strong"),nht=o("xlm"),sht=o(" \u2014 "),Kle=a("a"),lht=o("TFXLMForMultipleChoice"),iht=o(" (XLM model)"),dht=l(),T7=a("li"),sSe=a("strong"),mht=o("xlm-roberta"),cht=o(" \u2014 "),eie=a("a"),fht=o("TFXLMRobertaForMultipleChoice"),ght=o(" (XLM-RoBERTa model)"),hht=l(),M7=a("li"),lSe=a("strong"),uht=o("xlnet"),pht=o(" \u2014 "),oie=a("a"),_ht=o("TFXLNetForMultipleChoice"),bht=o(" (XLNet model)"),vht=l(),F(E7.$$.fragment),Wio=l(),Wc=a("h2"),C7=a("a"),iSe=a("span"),F(gB.$$.fragment),Fht=l(),dSe=a("span"),Tht=o("TFAutoModelForNextSentencePrediction"),Uio=l(),Er=a("div"),F(hB.$$.fragment),Mht=l(),Uc=a("p"),Eht=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),rie=a("a"),Cht=o("from_pretrained()"),wht=o(" class method or the "),tie=a("a"),Aht=o("from_config()"),Lht=o(` class
method.`),yht=l(),uB=a("p"),xht=o("This class cannot be instantiated directly using "),mSe=a("code"),$ht=o("__init__()"),kht=o(" (throws an error)."),Sht=l(),ma=a("div"),F(pB.$$.fragment),Rht=l(),cSe=a("p"),Pht=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Bht=l(),Hc=a("p"),Iht=o(`Note:
Loading a model from its configuration file does `),fSe=a("strong"),Nht=o("not"),qht=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aie=a("a"),Dht=o("from_pretrained()"),jht=o(" to load the model weights."),Ght=l(),F(w7.$$.fragment),Oht=l(),Kr=a("div"),F(_B.$$.fragment),Vht=l(),gSe=a("p"),Xht=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),zht=l(),Jn=a("p"),Qht=o("The model class to instantiate is selected based on the "),hSe=a("code"),Wht=o("model_type"),Uht=o(` property of the config object (either
passed as an argument or loaded from `),uSe=a("code"),Hht=o("pretrained_model_name_or_path"),Jht=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pSe=a("code"),Yht=o("pretrained_model_name_or_path"),Zht=o(":"),Kht=l(),bB=a("ul"),A7=a("li"),_Se=a("strong"),eut=o("bert"),out=o(" \u2014 "),nie=a("a"),rut=o("TFBertForNextSentencePrediction"),tut=o(" (BERT model)"),aut=l(),L7=a("li"),bSe=a("strong"),nut=o("mobilebert"),sut=o(" \u2014 "),sie=a("a"),lut=o("TFMobileBertForNextSentencePrediction"),iut=o(" (MobileBERT model)"),dut=l(),F(y7.$$.fragment),Hio=l(),Jc=a("h2"),x7=a("a"),vSe=a("span"),F(vB.$$.fragment),mut=l(),FSe=a("span"),cut=o("TFAutoModelForTableQuestionAnswering"),Jio=l(),Cr=a("div"),F(FB.$$.fragment),fut=l(),Yc=a("p"),gut=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),lie=a("a"),hut=o("from_pretrained()"),uut=o(" class method or the "),iie=a("a"),put=o("from_config()"),_ut=o(` class
method.`),but=l(),TB=a("p"),vut=o("This class cannot be instantiated directly using "),TSe=a("code"),Fut=o("__init__()"),Tut=o(" (throws an error)."),Mut=l(),ca=a("div"),F(MB.$$.fragment),Eut=l(),MSe=a("p"),Cut=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),wut=l(),Zc=a("p"),Aut=o(`Note:
Loading a model from its configuration file does `),ESe=a("strong"),Lut=o("not"),yut=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),die=a("a"),xut=o("from_pretrained()"),$ut=o(" to load the model weights."),kut=l(),F($7.$$.fragment),Sut=l(),et=a("div"),F(EB.$$.fragment),Rut=l(),CSe=a("p"),Put=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),But=l(),Yn=a("p"),Iut=o("The model class to instantiate is selected based on the "),wSe=a("code"),Nut=o("model_type"),qut=o(` property of the config object (either
passed as an argument or loaded from `),ASe=a("code"),Dut=o("pretrained_model_name_or_path"),jut=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LSe=a("code"),Gut=o("pretrained_model_name_or_path"),Out=o(":"),Vut=l(),ySe=a("ul"),k7=a("li"),xSe=a("strong"),Xut=o("tapas"),zut=o(" \u2014 "),mie=a("a"),Qut=o("TFTapasForQuestionAnswering"),Wut=o(" (TAPAS model)"),Uut=l(),F(S7.$$.fragment),Yio=l(),Kc=a("h2"),R7=a("a"),$Se=a("span"),F(CB.$$.fragment),Hut=l(),kSe=a("span"),Jut=o("TFAutoModelForDocumentQuestionAnswering"),Zio=l(),wr=a("div"),F(wB.$$.fragment),Yut=l(),ef=a("p"),Zut=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),cie=a("a"),Kut=o("from_pretrained()"),ept=o(" class method or the "),fie=a("a"),opt=o("from_config()"),rpt=o(` class
method.`),tpt=l(),AB=a("p"),apt=o("This class cannot be instantiated directly using "),SSe=a("code"),npt=o("__init__()"),spt=o(" (throws an error)."),lpt=l(),fa=a("div"),F(LB.$$.fragment),ipt=l(),RSe=a("p"),dpt=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),mpt=l(),of=a("p"),cpt=o(`Note:
Loading a model from its configuration file does `),PSe=a("strong"),fpt=o("not"),gpt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gie=a("a"),hpt=o("from_pretrained()"),upt=o(" to load the model weights."),ppt=l(),F(P7.$$.fragment),_pt=l(),ot=a("div"),F(yB.$$.fragment),bpt=l(),BSe=a("p"),vpt=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),Fpt=l(),Zn=a("p"),Tpt=o("The model class to instantiate is selected based on the "),ISe=a("code"),Mpt=o("model_type"),Ept=o(` property of the config object (either
passed as an argument or loaded from `),NSe=a("code"),Cpt=o("pretrained_model_name_or_path"),wpt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qSe=a("code"),Apt=o("pretrained_model_name_or_path"),Lpt=o(":"),ypt=l(),DSe=a("ul"),B7=a("li"),jSe=a("strong"),xpt=o("layoutlm"),$pt=o(" \u2014 "),hie=a("a"),kpt=o("TFLayoutLMForQuestionAnswering"),Spt=o(" (LayoutLM model)"),Rpt=l(),F(I7.$$.fragment),Kio=l(),rf=a("h2"),N7=a("a"),GSe=a("span"),F(xB.$$.fragment),Ppt=l(),OSe=a("span"),Bpt=o("TFAutoModelForTokenClassification"),edo=l(),Ar=a("div"),F($B.$$.fragment),Ipt=l(),tf=a("p"),Npt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),uie=a("a"),qpt=o("from_pretrained()"),Dpt=o(" class method or the "),pie=a("a"),jpt=o("from_config()"),Gpt=o(` class
method.`),Opt=l(),kB=a("p"),Vpt=o("This class cannot be instantiated directly using "),VSe=a("code"),Xpt=o("__init__()"),zpt=o(" (throws an error)."),Qpt=l(),ga=a("div"),F(SB.$$.fragment),Wpt=l(),XSe=a("p"),Upt=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Hpt=l(),af=a("p"),Jpt=o(`Note:
Loading a model from its configuration file does `),zSe=a("strong"),Ypt=o("not"),Zpt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_ie=a("a"),Kpt=o("from_pretrained()"),e_t=o(" to load the model weights."),o_t=l(),F(q7.$$.fragment),r_t=l(),rt=a("div"),F(RB.$$.fragment),t_t=l(),QSe=a("p"),a_t=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),n_t=l(),Kn=a("p"),s_t=o("The model class to instantiate is selected based on the "),WSe=a("code"),l_t=o("model_type"),i_t=o(` property of the config object (either
passed as an argument or loaded from `),USe=a("code"),d_t=o("pretrained_model_name_or_path"),m_t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HSe=a("code"),c_t=o("pretrained_model_name_or_path"),f_t=o(":"),g_t=l(),me=a("ul"),D7=a("li"),JSe=a("strong"),h_t=o("albert"),u_t=o(" \u2014 "),bie=a("a"),p_t=o("TFAlbertForTokenClassification"),__t=o(" (ALBERT model)"),b_t=l(),j7=a("li"),YSe=a("strong"),v_t=o("bert"),F_t=o(" \u2014 "),vie=a("a"),T_t=o("TFBertForTokenClassification"),M_t=o(" (BERT model)"),E_t=l(),G7=a("li"),ZSe=a("strong"),C_t=o("camembert"),w_t=o(" \u2014 "),Fie=a("a"),A_t=o("TFCamembertForTokenClassification"),L_t=o(" (CamemBERT model)"),y_t=l(),O7=a("li"),KSe=a("strong"),x_t=o("convbert"),$_t=o(" \u2014 "),Tie=a("a"),k_t=o("TFConvBertForTokenClassification"),S_t=o(" (ConvBERT model)"),R_t=l(),V7=a("li"),eRe=a("strong"),P_t=o("deberta"),B_t=o(" \u2014 "),Mie=a("a"),I_t=o("TFDebertaForTokenClassification"),N_t=o(" (DeBERTa model)"),q_t=l(),X7=a("li"),oRe=a("strong"),D_t=o("deberta-v2"),j_t=o(" \u2014 "),Eie=a("a"),G_t=o("TFDebertaV2ForTokenClassification"),O_t=o(" (DeBERTa-v2 model)"),V_t=l(),z7=a("li"),rRe=a("strong"),X_t=o("distilbert"),z_t=o(" \u2014 "),Cie=a("a"),Q_t=o("TFDistilBertForTokenClassification"),W_t=o(" (DistilBERT model)"),U_t=l(),Q7=a("li"),tRe=a("strong"),H_t=o("electra"),J_t=o(" \u2014 "),wie=a("a"),Y_t=o("TFElectraForTokenClassification"),Z_t=o(" (ELECTRA model)"),K_t=l(),W7=a("li"),aRe=a("strong"),e1t=o("esm"),o1t=o(" \u2014 "),Aie=a("a"),r1t=o("TFEsmForTokenClassification"),t1t=o(" (ESM model)"),a1t=l(),U7=a("li"),nRe=a("strong"),n1t=o("flaubert"),s1t=o(" \u2014 "),Lie=a("a"),l1t=o("TFFlaubertForTokenClassification"),i1t=o(" (FlauBERT model)"),d1t=l(),H7=a("li"),sRe=a("strong"),m1t=o("funnel"),c1t=o(" \u2014 "),yie=a("a"),f1t=o("TFFunnelForTokenClassification"),g1t=o(" (Funnel Transformer model)"),h1t=l(),J7=a("li"),lRe=a("strong"),u1t=o("layoutlm"),p1t=o(" \u2014 "),xie=a("a"),_1t=o("TFLayoutLMForTokenClassification"),b1t=o(" (LayoutLM model)"),v1t=l(),Y7=a("li"),iRe=a("strong"),F1t=o("layoutlmv3"),T1t=o(" \u2014 "),$ie=a("a"),M1t=o("TFLayoutLMv3ForTokenClassification"),E1t=o(" (LayoutLMv3 model)"),C1t=l(),Z7=a("li"),dRe=a("strong"),w1t=o("longformer"),A1t=o(" \u2014 "),kie=a("a"),L1t=o("TFLongformerForTokenClassification"),y1t=o(" (Longformer model)"),x1t=l(),K7=a("li"),mRe=a("strong"),$1t=o("mobilebert"),k1t=o(" \u2014 "),Sie=a("a"),S1t=o("TFMobileBertForTokenClassification"),R1t=o(" (MobileBERT model)"),P1t=l(),e8=a("li"),cRe=a("strong"),B1t=o("mpnet"),I1t=o(" \u2014 "),Rie=a("a"),N1t=o("TFMPNetForTokenClassification"),q1t=o(" (MPNet model)"),D1t=l(),o8=a("li"),fRe=a("strong"),j1t=o("rembert"),G1t=o(" \u2014 "),Pie=a("a"),O1t=o("TFRemBertForTokenClassification"),V1t=o(" (RemBERT model)"),X1t=l(),r8=a("li"),gRe=a("strong"),z1t=o("roberta"),Q1t=o(" \u2014 "),Bie=a("a"),W1t=o("TFRobertaForTokenClassification"),U1t=o(" (RoBERTa model)"),H1t=l(),t8=a("li"),hRe=a("strong"),J1t=o("roformer"),Y1t=o(" \u2014 "),Iie=a("a"),Z1t=o("TFRoFormerForTokenClassification"),K1t=o(" (RoFormer model)"),e2t=l(),a8=a("li"),uRe=a("strong"),o2t=o("xlm"),r2t=o(" \u2014 "),Nie=a("a"),t2t=o("TFXLMForTokenClassification"),a2t=o(" (XLM model)"),n2t=l(),n8=a("li"),pRe=a("strong"),s2t=o("xlm-roberta"),l2t=o(" \u2014 "),qie=a("a"),i2t=o("TFXLMRobertaForTokenClassification"),d2t=o(" (XLM-RoBERTa model)"),m2t=l(),s8=a("li"),_Re=a("strong"),c2t=o("xlnet"),f2t=o(" \u2014 "),Die=a("a"),g2t=o("TFXLNetForTokenClassification"),h2t=o(" (XLNet model)"),u2t=l(),F(l8.$$.fragment),odo=l(),nf=a("h2"),i8=a("a"),bRe=a("span"),F(PB.$$.fragment),p2t=l(),vRe=a("span"),_2t=o("TFAutoModelForQuestionAnswering"),rdo=l(),Lr=a("div"),F(BB.$$.fragment),b2t=l(),sf=a("p"),v2t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),jie=a("a"),F2t=o("from_pretrained()"),T2t=o(" class method or the "),Gie=a("a"),M2t=o("from_config()"),E2t=o(` class
method.`),C2t=l(),IB=a("p"),w2t=o("This class cannot be instantiated directly using "),FRe=a("code"),A2t=o("__init__()"),L2t=o(" (throws an error)."),y2t=l(),ha=a("div"),F(NB.$$.fragment),x2t=l(),TRe=a("p"),$2t=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),k2t=l(),lf=a("p"),S2t=o(`Note:
Loading a model from its configuration file does `),MRe=a("strong"),R2t=o("not"),P2t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Oie=a("a"),B2t=o("from_pretrained()"),I2t=o(" to load the model weights."),N2t=l(),F(d8.$$.fragment),q2t=l(),tt=a("div"),F(qB.$$.fragment),D2t=l(),ERe=a("p"),j2t=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),G2t=l(),es=a("p"),O2t=o("The model class to instantiate is selected based on the "),CRe=a("code"),V2t=o("model_type"),X2t=o(` property of the config object (either
passed as an argument or loaded from `),wRe=a("code"),z2t=o("pretrained_model_name_or_path"),Q2t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ARe=a("code"),W2t=o("pretrained_model_name_or_path"),U2t=o(":"),H2t=l(),he=a("ul"),m8=a("li"),LRe=a("strong"),J2t=o("albert"),Y2t=o(" \u2014 "),Vie=a("a"),Z2t=o("TFAlbertForQuestionAnswering"),K2t=o(" (ALBERT model)"),ebt=l(),c8=a("li"),yRe=a("strong"),obt=o("bert"),rbt=o(" \u2014 "),Xie=a("a"),tbt=o("TFBertForQuestionAnswering"),abt=o(" (BERT model)"),nbt=l(),f8=a("li"),xRe=a("strong"),sbt=o("camembert"),lbt=o(" \u2014 "),zie=a("a"),ibt=o("TFCamembertForQuestionAnswering"),dbt=o(" (CamemBERT model)"),mbt=l(),g8=a("li"),$Re=a("strong"),cbt=o("convbert"),fbt=o(" \u2014 "),Qie=a("a"),gbt=o("TFConvBertForQuestionAnswering"),hbt=o(" (ConvBERT model)"),ubt=l(),h8=a("li"),kRe=a("strong"),pbt=o("deberta"),_bt=o(" \u2014 "),Wie=a("a"),bbt=o("TFDebertaForQuestionAnswering"),vbt=o(" (DeBERTa model)"),Fbt=l(),u8=a("li"),SRe=a("strong"),Tbt=o("deberta-v2"),Mbt=o(" \u2014 "),Uie=a("a"),Ebt=o("TFDebertaV2ForQuestionAnswering"),Cbt=o(" (DeBERTa-v2 model)"),wbt=l(),p8=a("li"),RRe=a("strong"),Abt=o("distilbert"),Lbt=o(" \u2014 "),Hie=a("a"),ybt=o("TFDistilBertForQuestionAnswering"),xbt=o(" (DistilBERT model)"),$bt=l(),_8=a("li"),PRe=a("strong"),kbt=o("electra"),Sbt=o(" \u2014 "),Jie=a("a"),Rbt=o("TFElectraForQuestionAnswering"),Pbt=o(" (ELECTRA model)"),Bbt=l(),b8=a("li"),BRe=a("strong"),Ibt=o("flaubert"),Nbt=o(" \u2014 "),Yie=a("a"),qbt=o("TFFlaubertForQuestionAnsweringSimple"),Dbt=o(" (FlauBERT model)"),jbt=l(),v8=a("li"),IRe=a("strong"),Gbt=o("funnel"),Obt=o(" \u2014 "),Zie=a("a"),Vbt=o("TFFunnelForQuestionAnswering"),Xbt=o(" (Funnel Transformer model)"),zbt=l(),F8=a("li"),NRe=a("strong"),Qbt=o("gptj"),Wbt=o(" \u2014 "),Kie=a("a"),Ubt=o("TFGPTJForQuestionAnswering"),Hbt=o(" (GPT-J model)"),Jbt=l(),T8=a("li"),qRe=a("strong"),Ybt=o("layoutlmv3"),Zbt=o(" \u2014 "),ede=a("a"),Kbt=o("TFLayoutLMv3ForQuestionAnswering"),evt=o(" (LayoutLMv3 model)"),ovt=l(),M8=a("li"),DRe=a("strong"),rvt=o("longformer"),tvt=o(" \u2014 "),ode=a("a"),avt=o("TFLongformerForQuestionAnswering"),nvt=o(" (Longformer model)"),svt=l(),E8=a("li"),jRe=a("strong"),lvt=o("mobilebert"),ivt=o(" \u2014 "),rde=a("a"),dvt=o("TFMobileBertForQuestionAnswering"),mvt=o(" (MobileBERT model)"),cvt=l(),C8=a("li"),GRe=a("strong"),fvt=o("mpnet"),gvt=o(" \u2014 "),tde=a("a"),hvt=o("TFMPNetForQuestionAnswering"),uvt=o(" (MPNet model)"),pvt=l(),w8=a("li"),ORe=a("strong"),_vt=o("rembert"),bvt=o(" \u2014 "),ade=a("a"),vvt=o("TFRemBertForQuestionAnswering"),Fvt=o(" (RemBERT model)"),Tvt=l(),A8=a("li"),VRe=a("strong"),Mvt=o("roberta"),Evt=o(" \u2014 "),nde=a("a"),Cvt=o("TFRobertaForQuestionAnswering"),wvt=o(" (RoBERTa model)"),Avt=l(),L8=a("li"),XRe=a("strong"),Lvt=o("roformer"),yvt=o(" \u2014 "),sde=a("a"),xvt=o("TFRoFormerForQuestionAnswering"),$vt=o(" (RoFormer model)"),kvt=l(),y8=a("li"),zRe=a("strong"),Svt=o("xlm"),Rvt=o(" \u2014 "),lde=a("a"),Pvt=o("TFXLMForQuestionAnsweringSimple"),Bvt=o(" (XLM model)"),Ivt=l(),x8=a("li"),QRe=a("strong"),Nvt=o("xlm-roberta"),qvt=o(" \u2014 "),ide=a("a"),Dvt=o("TFXLMRobertaForQuestionAnswering"),jvt=o(" (XLM-RoBERTa model)"),Gvt=l(),$8=a("li"),WRe=a("strong"),Ovt=o("xlnet"),Vvt=o(" \u2014 "),dde=a("a"),Xvt=o("TFXLNetForQuestionAnsweringSimple"),zvt=o(" (XLNet model)"),Qvt=l(),F(k8.$$.fragment),tdo=l(),df=a("h2"),S8=a("a"),URe=a("span"),F(DB.$$.fragment),Wvt=l(),HRe=a("span"),Uvt=o("TFAutoModelForVision2Seq"),ado=l(),yr=a("div"),F(jB.$$.fragment),Hvt=l(),mf=a("p"),Jvt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),mde=a("a"),Yvt=o("from_pretrained()"),Zvt=o(" class method or the "),cde=a("a"),Kvt=o("from_config()"),eFt=o(` class
method.`),oFt=l(),GB=a("p"),rFt=o("This class cannot be instantiated directly using "),JRe=a("code"),tFt=o("__init__()"),aFt=o(" (throws an error)."),nFt=l(),ua=a("div"),F(OB.$$.fragment),sFt=l(),YRe=a("p"),lFt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),iFt=l(),cf=a("p"),dFt=o(`Note:
Loading a model from its configuration file does `),ZRe=a("strong"),mFt=o("not"),cFt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fde=a("a"),fFt=o("from_pretrained()"),gFt=o(" to load the model weights."),hFt=l(),F(R8.$$.fragment),uFt=l(),at=a("div"),F(VB.$$.fragment),pFt=l(),KRe=a("p"),_Ft=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),bFt=l(),os=a("p"),vFt=o("The model class to instantiate is selected based on the "),ePe=a("code"),FFt=o("model_type"),TFt=o(` property of the config object (either
passed as an argument or loaded from `),oPe=a("code"),MFt=o("pretrained_model_name_or_path"),EFt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rPe=a("code"),CFt=o("pretrained_model_name_or_path"),wFt=o(":"),AFt=l(),tPe=a("ul"),P8=a("li"),aPe=a("strong"),LFt=o("vision-encoder-decoder"),yFt=o(" \u2014 "),gde=a("a"),xFt=o("TFVisionEncoderDecoderModel"),$Ft=o(" (Vision Encoder decoder model)"),kFt=l(),F(B8.$$.fragment),ndo=l(),ff=a("h2"),I8=a("a"),nPe=a("span"),F(XB.$$.fragment),SFt=l(),sPe=a("span"),RFt=o("TFAutoModelForSpeechSeq2Seq"),sdo=l(),xr=a("div"),F(zB.$$.fragment),PFt=l(),gf=a("p"),BFt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),hde=a("a"),IFt=o("from_pretrained()"),NFt=o(" class method or the "),ude=a("a"),qFt=o("from_config()"),DFt=o(` class
method.`),jFt=l(),QB=a("p"),GFt=o("This class cannot be instantiated directly using "),lPe=a("code"),OFt=o("__init__()"),VFt=o(" (throws an error)."),XFt=l(),pa=a("div"),F(WB.$$.fragment),zFt=l(),iPe=a("p"),QFt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),WFt=l(),hf=a("p"),UFt=o(`Note:
Loading a model from its configuration file does `),dPe=a("strong"),HFt=o("not"),JFt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pde=a("a"),YFt=o("from_pretrained()"),ZFt=o(" to load the model weights."),KFt=l(),F(N8.$$.fragment),eTt=l(),nt=a("div"),F(UB.$$.fragment),oTt=l(),mPe=a("p"),rTt=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),tTt=l(),rs=a("p"),aTt=o("The model class to instantiate is selected based on the "),cPe=a("code"),nTt=o("model_type"),sTt=o(` property of the config object (either
passed as an argument or loaded from `),fPe=a("code"),lTt=o("pretrained_model_name_or_path"),iTt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gPe=a("code"),dTt=o("pretrained_model_name_or_path"),mTt=o(":"),cTt=l(),HB=a("ul"),q8=a("li"),hPe=a("strong"),fTt=o("speech_to_text"),gTt=o(" \u2014 "),_de=a("a"),hTt=o("TFSpeech2TextForConditionalGeneration"),uTt=o(" (Speech2Text model)"),pTt=l(),D8=a("li"),uPe=a("strong"),_Tt=o("whisper"),bTt=o(" \u2014 "),bde=a("a"),vTt=o("TFWhisperForConditionalGeneration"),FTt=o(" (Whisper model)"),TTt=l(),F(j8.$$.fragment),ldo=l(),uf=a("h2"),G8=a("a"),pPe=a("span"),F(JB.$$.fragment),MTt=l(),_Pe=a("span"),ETt=o("FlaxAutoModel"),ido=l(),$r=a("div"),F(YB.$$.fragment),CTt=l(),pf=a("p"),wTt=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),vde=a("a"),ATt=o("from_pretrained()"),LTt=o(" class method or the "),Fde=a("a"),yTt=o("from_config()"),xTt=o(` class
method.`),$Tt=l(),ZB=a("p"),kTt=o("This class cannot be instantiated directly using "),bPe=a("code"),STt=o("__init__()"),RTt=o(" (throws an error)."),PTt=l(),_a=a("div"),F(KB.$$.fragment),BTt=l(),vPe=a("p"),ITt=o("Instantiates one of the base model classes of the library from a configuration."),NTt=l(),_f=a("p"),qTt=o(`Note:
Loading a model from its configuration file does `),FPe=a("strong"),DTt=o("not"),jTt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Tde=a("a"),GTt=o("from_pretrained()"),OTt=o(" to load the model weights."),VTt=l(),F(O8.$$.fragment),XTt=l(),st=a("div"),F(eI.$$.fragment),zTt=l(),TPe=a("p"),QTt=o("Instantiate one of the base model classes of the library from a pretrained model."),WTt=l(),ts=a("p"),UTt=o("The model class to instantiate is selected based on the "),MPe=a("code"),HTt=o("model_type"),JTt=o(` property of the config object (either
passed as an argument or loaded from `),EPe=a("code"),YTt=o("pretrained_model_name_or_path"),ZTt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),CPe=a("code"),KTt=o("pretrained_model_name_or_path"),eMt=o(":"),oMt=l(),ne=a("ul"),V8=a("li"),wPe=a("strong"),rMt=o("albert"),tMt=o(" \u2014 "),Mde=a("a"),aMt=o("FlaxAlbertModel"),nMt=o(" (ALBERT model)"),sMt=l(),X8=a("li"),APe=a("strong"),lMt=o("bart"),iMt=o(" \u2014 "),Ede=a("a"),dMt=o("FlaxBartModel"),mMt=o(" (BART model)"),cMt=l(),z8=a("li"),LPe=a("strong"),fMt=o("beit"),gMt=o(" \u2014 "),Cde=a("a"),hMt=o("FlaxBeitModel"),uMt=o(" (BEiT model)"),pMt=l(),Q8=a("li"),yPe=a("strong"),_Mt=o("bert"),bMt=o(" \u2014 "),wde=a("a"),vMt=o("FlaxBertModel"),FMt=o(" (BERT model)"),TMt=l(),W8=a("li"),xPe=a("strong"),MMt=o("big_bird"),EMt=o(" \u2014 "),Ade=a("a"),CMt=o("FlaxBigBirdModel"),wMt=o(" (BigBird model)"),AMt=l(),U8=a("li"),$Pe=a("strong"),LMt=o("blenderbot"),yMt=o(" \u2014 "),Lde=a("a"),xMt=o("FlaxBlenderbotModel"),$Mt=o(" (Blenderbot model)"),kMt=l(),H8=a("li"),kPe=a("strong"),SMt=o("blenderbot-small"),RMt=o(" \u2014 "),yde=a("a"),PMt=o("FlaxBlenderbotSmallModel"),BMt=o(" (BlenderbotSmall model)"),IMt=l(),J8=a("li"),SPe=a("strong"),NMt=o("clip"),qMt=o(" \u2014 "),xde=a("a"),DMt=o("FlaxCLIPModel"),jMt=o(" (CLIP model)"),GMt=l(),Y8=a("li"),RPe=a("strong"),OMt=o("distilbert"),VMt=o(" \u2014 "),$de=a("a"),XMt=o("FlaxDistilBertModel"),zMt=o(" (DistilBERT model)"),QMt=l(),Z8=a("li"),PPe=a("strong"),WMt=o("electra"),UMt=o(" \u2014 "),kde=a("a"),HMt=o("FlaxElectraModel"),JMt=o(" (ELECTRA model)"),YMt=l(),K8=a("li"),BPe=a("strong"),ZMt=o("gpt2"),KMt=o(" \u2014 "),Sde=a("a"),eEt=o("FlaxGPT2Model"),oEt=o(" (OpenAI GPT-2 model)"),rEt=l(),eL=a("li"),IPe=a("strong"),tEt=o("gpt_neo"),aEt=o(" \u2014 "),Rde=a("a"),nEt=o("FlaxGPTNeoModel"),sEt=o(" (GPT Neo model)"),lEt=l(),oL=a("li"),NPe=a("strong"),iEt=o("gptj"),dEt=o(" \u2014 "),Pde=a("a"),mEt=o("FlaxGPTJModel"),cEt=o(" (GPT-J model)"),fEt=l(),rL=a("li"),qPe=a("strong"),gEt=o("longt5"),hEt=o(" \u2014 "),Bde=a("a"),uEt=o("FlaxLongT5Model"),pEt=o(" (LongT5 model)"),_Et=l(),tL=a("li"),DPe=a("strong"),bEt=o("marian"),vEt=o(" \u2014 "),Ide=a("a"),FEt=o("FlaxMarianModel"),TEt=o(" (Marian model)"),MEt=l(),aL=a("li"),jPe=a("strong"),EEt=o("mbart"),CEt=o(" \u2014 "),Nde=a("a"),wEt=o("FlaxMBartModel"),AEt=o(" (mBART model)"),LEt=l(),nL=a("li"),GPe=a("strong"),yEt=o("mt5"),xEt=o(" \u2014 "),qde=a("a"),$Et=o("FlaxMT5Model"),kEt=o(" (MT5 model)"),SEt=l(),sL=a("li"),OPe=a("strong"),REt=o("opt"),PEt=o(" \u2014 "),Dde=a("a"),BEt=o("FlaxOPTModel"),IEt=o(" (OPT model)"),NEt=l(),lL=a("li"),VPe=a("strong"),qEt=o("pegasus"),DEt=o(" \u2014 "),jde=a("a"),jEt=o("FlaxPegasusModel"),GEt=o(" (Pegasus model)"),OEt=l(),iL=a("li"),XPe=a("strong"),VEt=o("roberta"),XEt=o(" \u2014 "),Gde=a("a"),zEt=o("FlaxRobertaModel"),QEt=o(" (RoBERTa model)"),WEt=l(),dL=a("li"),zPe=a("strong"),UEt=o("roformer"),HEt=o(" \u2014 "),Ode=a("a"),JEt=o("FlaxRoFormerModel"),YEt=o(" (RoFormer model)"),ZEt=l(),mL=a("li"),QPe=a("strong"),KEt=o("t5"),e4t=o(" \u2014 "),Vde=a("a"),o4t=o("FlaxT5Model"),r4t=o(" (T5 model)"),t4t=l(),cL=a("li"),WPe=a("strong"),a4t=o("vision-text-dual-encoder"),n4t=o(" \u2014 "),Xde=a("a"),s4t=o("FlaxVisionTextDualEncoderModel"),l4t=o(" (VisionTextDualEncoder model)"),i4t=l(),fL=a("li"),UPe=a("strong"),d4t=o("vit"),m4t=o(" \u2014 "),zde=a("a"),c4t=o("FlaxViTModel"),f4t=o(" (ViT model)"),g4t=l(),gL=a("li"),HPe=a("strong"),h4t=o("wav2vec2"),u4t=o(" \u2014 "),Qde=a("a"),p4t=o("FlaxWav2Vec2Model"),_4t=o(" (Wav2Vec2 model)"),b4t=l(),hL=a("li"),JPe=a("strong"),v4t=o("xglm"),F4t=o(" \u2014 "),Wde=a("a"),T4t=o("FlaxXGLMModel"),M4t=o(" (XGLM model)"),E4t=l(),uL=a("li"),YPe=a("strong"),C4t=o("xlm-roberta"),w4t=o(" \u2014 "),Ude=a("a"),A4t=o("FlaxXLMRobertaModel"),L4t=o(" (XLM-RoBERTa model)"),y4t=l(),F(pL.$$.fragment),ddo=l(),bf=a("h2"),_L=a("a"),ZPe=a("span"),F(oI.$$.fragment),x4t=l(),KPe=a("span"),$4t=o("FlaxAutoModelForCausalLM"),mdo=l(),kr=a("div"),F(rI.$$.fragment),k4t=l(),vf=a("p"),S4t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Hde=a("a"),R4t=o("from_pretrained()"),P4t=o(" class method or the "),Jde=a("a"),B4t=o("from_config()"),I4t=o(` class
method.`),N4t=l(),tI=a("p"),q4t=o("This class cannot be instantiated directly using "),eBe=a("code"),D4t=o("__init__()"),j4t=o(" (throws an error)."),G4t=l(),ba=a("div"),F(aI.$$.fragment),O4t=l(),oBe=a("p"),V4t=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),X4t=l(),Ff=a("p"),z4t=o(`Note:
Loading a model from its configuration file does `),rBe=a("strong"),Q4t=o("not"),W4t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Yde=a("a"),U4t=o("from_pretrained()"),H4t=o(" to load the model weights."),J4t=l(),F(bL.$$.fragment),Y4t=l(),lt=a("div"),F(nI.$$.fragment),Z4t=l(),tBe=a("p"),K4t=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),eCt=l(),as=a("p"),oCt=o("The model class to instantiate is selected based on the "),aBe=a("code"),rCt=o("model_type"),tCt=o(` property of the config object (either
passed as an argument or loaded from `),nBe=a("code"),aCt=o("pretrained_model_name_or_path"),nCt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sBe=a("code"),sCt=o("pretrained_model_name_or_path"),lCt=o(":"),iCt=l(),Se=a("ul"),vL=a("li"),lBe=a("strong"),dCt=o("bart"),mCt=o(" \u2014 "),Zde=a("a"),cCt=o("FlaxBartForCausalLM"),fCt=o(" (BART model)"),gCt=l(),FL=a("li"),iBe=a("strong"),hCt=o("bert"),uCt=o(" \u2014 "),Kde=a("a"),pCt=o("FlaxBertForCausalLM"),_Ct=o(" (BERT model)"),bCt=l(),TL=a("li"),dBe=a("strong"),vCt=o("big_bird"),FCt=o(" \u2014 "),eme=a("a"),TCt=o("FlaxBigBirdForCausalLM"),MCt=o(" (BigBird model)"),ECt=l(),ML=a("li"),mBe=a("strong"),CCt=o("electra"),wCt=o(" \u2014 "),ome=a("a"),ACt=o("FlaxElectraForCausalLM"),LCt=o(" (ELECTRA model)"),yCt=l(),EL=a("li"),cBe=a("strong"),xCt=o("gpt2"),$Ct=o(" \u2014 "),rme=a("a"),kCt=o("FlaxGPT2LMHeadModel"),SCt=o(" (OpenAI GPT-2 model)"),RCt=l(),CL=a("li"),fBe=a("strong"),PCt=o("gpt_neo"),BCt=o(" \u2014 "),tme=a("a"),ICt=o("FlaxGPTNeoForCausalLM"),NCt=o(" (GPT Neo model)"),qCt=l(),wL=a("li"),gBe=a("strong"),DCt=o("gptj"),jCt=o(" \u2014 "),ame=a("a"),GCt=o("FlaxGPTJForCausalLM"),OCt=o(" (GPT-J model)"),VCt=l(),AL=a("li"),hBe=a("strong"),XCt=o("opt"),zCt=o(" \u2014 "),nme=a("a"),QCt=o("FlaxOPTForCausalLM"),WCt=o(" (OPT model)"),UCt=l(),LL=a("li"),uBe=a("strong"),HCt=o("roberta"),JCt=o(" \u2014 "),sme=a("a"),YCt=o("FlaxRobertaForCausalLM"),ZCt=o(" (RoBERTa model)"),KCt=l(),yL=a("li"),pBe=a("strong"),e3t=o("xglm"),o3t=o(" \u2014 "),lme=a("a"),r3t=o("FlaxXGLMForCausalLM"),t3t=o(" (XGLM model)"),a3t=l(),F(xL.$$.fragment),cdo=l(),Tf=a("h2"),$L=a("a"),_Be=a("span"),F(sI.$$.fragment),n3t=l(),bBe=a("span"),s3t=o("FlaxAutoModelForPreTraining"),fdo=l(),Sr=a("div"),F(lI.$$.fragment),l3t=l(),Mf=a("p"),i3t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),ime=a("a"),d3t=o("from_pretrained()"),m3t=o(" class method or the "),dme=a("a"),c3t=o("from_config()"),f3t=o(` class
method.`),g3t=l(),iI=a("p"),h3t=o("This class cannot be instantiated directly using "),vBe=a("code"),u3t=o("__init__()"),p3t=o(" (throws an error)."),_3t=l(),va=a("div"),F(dI.$$.fragment),b3t=l(),FBe=a("p"),v3t=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),F3t=l(),Ef=a("p"),T3t=o(`Note:
Loading a model from its configuration file does `),TBe=a("strong"),M3t=o("not"),E3t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mme=a("a"),C3t=o("from_pretrained()"),w3t=o(" to load the model weights."),A3t=l(),F(kL.$$.fragment),L3t=l(),it=a("div"),F(mI.$$.fragment),y3t=l(),MBe=a("p"),x3t=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),$3t=l(),ns=a("p"),k3t=o("The model class to instantiate is selected based on the "),EBe=a("code"),S3t=o("model_type"),R3t=o(` property of the config object (either
passed as an argument or loaded from `),CBe=a("code"),P3t=o("pretrained_model_name_or_path"),B3t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wBe=a("code"),I3t=o("pretrained_model_name_or_path"),N3t=o(":"),q3t=l(),we=a("ul"),SL=a("li"),ABe=a("strong"),D3t=o("albert"),j3t=o(" \u2014 "),cme=a("a"),G3t=o("FlaxAlbertForPreTraining"),O3t=o(" (ALBERT model)"),V3t=l(),RL=a("li"),LBe=a("strong"),X3t=o("bart"),z3t=o(" \u2014 "),fme=a("a"),Q3t=o("FlaxBartForConditionalGeneration"),W3t=o(" (BART model)"),U3t=l(),PL=a("li"),yBe=a("strong"),H3t=o("bert"),J3t=o(" \u2014 "),gme=a("a"),Y3t=o("FlaxBertForPreTraining"),Z3t=o(" (BERT model)"),K3t=l(),BL=a("li"),xBe=a("strong"),e5t=o("big_bird"),o5t=o(" \u2014 "),hme=a("a"),r5t=o("FlaxBigBirdForPreTraining"),t5t=o(" (BigBird model)"),a5t=l(),IL=a("li"),$Be=a("strong"),n5t=o("electra"),s5t=o(" \u2014 "),ume=a("a"),l5t=o("FlaxElectraForPreTraining"),i5t=o(" (ELECTRA model)"),d5t=l(),NL=a("li"),kBe=a("strong"),m5t=o("longt5"),c5t=o(" \u2014 "),pme=a("a"),f5t=o("FlaxLongT5ForConditionalGeneration"),g5t=o(" (LongT5 model)"),h5t=l(),qL=a("li"),SBe=a("strong"),u5t=o("mbart"),p5t=o(" \u2014 "),_me=a("a"),_5t=o("FlaxMBartForConditionalGeneration"),b5t=o(" (mBART model)"),v5t=l(),DL=a("li"),RBe=a("strong"),F5t=o("mt5"),T5t=o(" \u2014 "),bme=a("a"),M5t=o("FlaxMT5ForConditionalGeneration"),E5t=o(" (MT5 model)"),C5t=l(),jL=a("li"),PBe=a("strong"),w5t=o("roberta"),A5t=o(" \u2014 "),vme=a("a"),L5t=o("FlaxRobertaForMaskedLM"),y5t=o(" (RoBERTa model)"),x5t=l(),GL=a("li"),BBe=a("strong"),$5t=o("roformer"),k5t=o(" \u2014 "),Fme=a("a"),S5t=o("FlaxRoFormerForMaskedLM"),R5t=o(" (RoFormer model)"),P5t=l(),OL=a("li"),IBe=a("strong"),B5t=o("t5"),I5t=o(" \u2014 "),Tme=a("a"),N5t=o("FlaxT5ForConditionalGeneration"),q5t=o(" (T5 model)"),D5t=l(),VL=a("li"),NBe=a("strong"),j5t=o("wav2vec2"),G5t=o(" \u2014 "),Mme=a("a"),O5t=o("FlaxWav2Vec2ForPreTraining"),V5t=o(" (Wav2Vec2 model)"),X5t=l(),XL=a("li"),qBe=a("strong"),z5t=o("xlm-roberta"),Q5t=o(" \u2014 "),Eme=a("a"),W5t=o("FlaxXLMRobertaForMaskedLM"),U5t=o(" (XLM-RoBERTa model)"),H5t=l(),F(zL.$$.fragment),gdo=l(),Cf=a("h2"),QL=a("a"),DBe=a("span"),F(cI.$$.fragment),J5t=l(),jBe=a("span"),Y5t=o("FlaxAutoModelForMaskedLM"),hdo=l(),Rr=a("div"),F(fI.$$.fragment),Z5t=l(),wf=a("p"),K5t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Cme=a("a"),e0t=o("from_pretrained()"),o0t=o(" class method or the "),wme=a("a"),r0t=o("from_config()"),t0t=o(` class
method.`),a0t=l(),gI=a("p"),n0t=o("This class cannot be instantiated directly using "),GBe=a("code"),s0t=o("__init__()"),l0t=o(" (throws an error)."),i0t=l(),Fa=a("div"),F(hI.$$.fragment),d0t=l(),OBe=a("p"),m0t=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),c0t=l(),Af=a("p"),f0t=o(`Note:
Loading a model from its configuration file does `),VBe=a("strong"),g0t=o("not"),h0t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ame=a("a"),u0t=o("from_pretrained()"),p0t=o(" to load the model weights."),_0t=l(),F(WL.$$.fragment),b0t=l(),dt=a("div"),F(uI.$$.fragment),v0t=l(),XBe=a("p"),F0t=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),T0t=l(),ss=a("p"),M0t=o("The model class to instantiate is selected based on the "),zBe=a("code"),E0t=o("model_type"),C0t=o(` property of the config object (either
passed as an argument or loaded from `),QBe=a("code"),w0t=o("pretrained_model_name_or_path"),A0t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),WBe=a("code"),L0t=o("pretrained_model_name_or_path"),y0t=o(":"),x0t=l(),Re=a("ul"),UL=a("li"),UBe=a("strong"),$0t=o("albert"),k0t=o(" \u2014 "),Lme=a("a"),S0t=o("FlaxAlbertForMaskedLM"),R0t=o(" (ALBERT model)"),P0t=l(),HL=a("li"),HBe=a("strong"),B0t=o("bart"),I0t=o(" \u2014 "),yme=a("a"),N0t=o("FlaxBartForConditionalGeneration"),q0t=o(" (BART model)"),D0t=l(),JL=a("li"),JBe=a("strong"),j0t=o("bert"),G0t=o(" \u2014 "),xme=a("a"),O0t=o("FlaxBertForMaskedLM"),V0t=o(" (BERT model)"),X0t=l(),YL=a("li"),YBe=a("strong"),z0t=o("big_bird"),Q0t=o(" \u2014 "),$me=a("a"),W0t=o("FlaxBigBirdForMaskedLM"),U0t=o(" (BigBird model)"),H0t=l(),ZL=a("li"),ZBe=a("strong"),J0t=o("distilbert"),Y0t=o(" \u2014 "),kme=a("a"),Z0t=o("FlaxDistilBertForMaskedLM"),K0t=o(" (DistilBERT model)"),ewt=l(),KL=a("li"),KBe=a("strong"),owt=o("electra"),rwt=o(" \u2014 "),Sme=a("a"),twt=o("FlaxElectraForMaskedLM"),awt=o(" (ELECTRA model)"),nwt=l(),ey=a("li"),eIe=a("strong"),swt=o("mbart"),lwt=o(" \u2014 "),Rme=a("a"),iwt=o("FlaxMBartForConditionalGeneration"),dwt=o(" (mBART model)"),mwt=l(),oy=a("li"),oIe=a("strong"),cwt=o("roberta"),fwt=o(" \u2014 "),Pme=a("a"),gwt=o("FlaxRobertaForMaskedLM"),hwt=o(" (RoBERTa model)"),uwt=l(),ry=a("li"),rIe=a("strong"),pwt=o("roformer"),_wt=o(" \u2014 "),Bme=a("a"),bwt=o("FlaxRoFormerForMaskedLM"),vwt=o(" (RoFormer model)"),Fwt=l(),ty=a("li"),tIe=a("strong"),Twt=o("xlm-roberta"),Mwt=o(" \u2014 "),Ime=a("a"),Ewt=o("FlaxXLMRobertaForMaskedLM"),Cwt=o(" (XLM-RoBERTa model)"),wwt=l(),F(ay.$$.fragment),udo=l(),Lf=a("h2"),ny=a("a"),aIe=a("span"),F(pI.$$.fragment),Awt=l(),nIe=a("span"),Lwt=o("FlaxAutoModelForSeq2SeqLM"),pdo=l(),Pr=a("div"),F(_I.$$.fragment),ywt=l(),yf=a("p"),xwt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Nme=a("a"),$wt=o("from_pretrained()"),kwt=o(" class method or the "),qme=a("a"),Swt=o("from_config()"),Rwt=o(` class
method.`),Pwt=l(),bI=a("p"),Bwt=o("This class cannot be instantiated directly using "),sIe=a("code"),Iwt=o("__init__()"),Nwt=o(" (throws an error)."),qwt=l(),Ta=a("div"),F(vI.$$.fragment),Dwt=l(),lIe=a("p"),jwt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Gwt=l(),xf=a("p"),Owt=o(`Note:
Loading a model from its configuration file does `),iIe=a("strong"),Vwt=o("not"),Xwt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Dme=a("a"),zwt=o("from_pretrained()"),Qwt=o(" to load the model weights."),Wwt=l(),F(sy.$$.fragment),Uwt=l(),mt=a("div"),F(FI.$$.fragment),Hwt=l(),dIe=a("p"),Jwt=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Ywt=l(),ls=a("p"),Zwt=o("The model class to instantiate is selected based on the "),mIe=a("code"),Kwt=o("model_type"),eAt=o(` property of the config object (either
passed as an argument or loaded from `),cIe=a("code"),oAt=o("pretrained_model_name_or_path"),rAt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fIe=a("code"),tAt=o("pretrained_model_name_or_path"),aAt=o(":"),nAt=l(),Pe=a("ul"),ly=a("li"),gIe=a("strong"),sAt=o("bart"),lAt=o(" \u2014 "),jme=a("a"),iAt=o("FlaxBartForConditionalGeneration"),dAt=o(" (BART model)"),mAt=l(),iy=a("li"),hIe=a("strong"),cAt=o("blenderbot"),fAt=o(" \u2014 "),Gme=a("a"),gAt=o("FlaxBlenderbotForConditionalGeneration"),hAt=o(" (Blenderbot model)"),uAt=l(),dy=a("li"),uIe=a("strong"),pAt=o("blenderbot-small"),_At=o(" \u2014 "),Ome=a("a"),bAt=o("FlaxBlenderbotSmallForConditionalGeneration"),vAt=o(" (BlenderbotSmall model)"),FAt=l(),my=a("li"),pIe=a("strong"),TAt=o("encoder-decoder"),MAt=o(" \u2014 "),Vme=a("a"),EAt=o("FlaxEncoderDecoderModel"),CAt=o(" (Encoder decoder model)"),wAt=l(),cy=a("li"),_Ie=a("strong"),AAt=o("longt5"),LAt=o(" \u2014 "),Xme=a("a"),yAt=o("FlaxLongT5ForConditionalGeneration"),xAt=o(" (LongT5 model)"),$At=l(),fy=a("li"),bIe=a("strong"),kAt=o("marian"),SAt=o(" \u2014 "),zme=a("a"),RAt=o("FlaxMarianMTModel"),PAt=o(" (Marian model)"),BAt=l(),gy=a("li"),vIe=a("strong"),IAt=o("mbart"),NAt=o(" \u2014 "),Qme=a("a"),qAt=o("FlaxMBartForConditionalGeneration"),DAt=o(" (mBART model)"),jAt=l(),hy=a("li"),FIe=a("strong"),GAt=o("mt5"),OAt=o(" \u2014 "),Wme=a("a"),VAt=o("FlaxMT5ForConditionalGeneration"),XAt=o(" (MT5 model)"),zAt=l(),uy=a("li"),TIe=a("strong"),QAt=o("pegasus"),WAt=o(" \u2014 "),Ume=a("a"),UAt=o("FlaxPegasusForConditionalGeneration"),HAt=o(" (Pegasus model)"),JAt=l(),py=a("li"),MIe=a("strong"),YAt=o("t5"),ZAt=o(" \u2014 "),Hme=a("a"),KAt=o("FlaxT5ForConditionalGeneration"),e6t=o(" (T5 model)"),o6t=l(),F(_y.$$.fragment),_do=l(),$f=a("h2"),by=a("a"),EIe=a("span"),F(TI.$$.fragment),r6t=l(),CIe=a("span"),t6t=o("FlaxAutoModelForSequenceClassification"),bdo=l(),Br=a("div"),F(MI.$$.fragment),a6t=l(),kf=a("p"),n6t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Jme=a("a"),s6t=o("from_pretrained()"),l6t=o(" class method or the "),Yme=a("a"),i6t=o("from_config()"),d6t=o(` class
method.`),m6t=l(),EI=a("p"),c6t=o("This class cannot be instantiated directly using "),wIe=a("code"),f6t=o("__init__()"),g6t=o(" (throws an error)."),h6t=l(),Ma=a("div"),F(CI.$$.fragment),u6t=l(),AIe=a("p"),p6t=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),_6t=l(),Sf=a("p"),b6t=o(`Note:
Loading a model from its configuration file does `),LIe=a("strong"),v6t=o("not"),F6t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zme=a("a"),T6t=o("from_pretrained()"),M6t=o(" to load the model weights."),E6t=l(),F(vy.$$.fragment),C6t=l(),ct=a("div"),F(wI.$$.fragment),w6t=l(),yIe=a("p"),A6t=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),L6t=l(),is=a("p"),y6t=o("The model class to instantiate is selected based on the "),xIe=a("code"),x6t=o("model_type"),$6t=o(` property of the config object (either
passed as an argument or loaded from `),$Ie=a("code"),k6t=o("pretrained_model_name_or_path"),S6t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kIe=a("code"),R6t=o("pretrained_model_name_or_path"),P6t=o(":"),B6t=l(),Be=a("ul"),Fy=a("li"),SIe=a("strong"),I6t=o("albert"),N6t=o(" \u2014 "),Kme=a("a"),q6t=o("FlaxAlbertForSequenceClassification"),D6t=o(" (ALBERT model)"),j6t=l(),Ty=a("li"),RIe=a("strong"),G6t=o("bart"),O6t=o(" \u2014 "),ece=a("a"),V6t=o("FlaxBartForSequenceClassification"),X6t=o(" (BART model)"),z6t=l(),My=a("li"),PIe=a("strong"),Q6t=o("bert"),W6t=o(" \u2014 "),oce=a("a"),U6t=o("FlaxBertForSequenceClassification"),H6t=o(" (BERT model)"),J6t=l(),Ey=a("li"),BIe=a("strong"),Y6t=o("big_bird"),Z6t=o(" \u2014 "),rce=a("a"),K6t=o("FlaxBigBirdForSequenceClassification"),e7t=o(" (BigBird model)"),o7t=l(),Cy=a("li"),IIe=a("strong"),r7t=o("distilbert"),t7t=o(" \u2014 "),tce=a("a"),a7t=o("FlaxDistilBertForSequenceClassification"),n7t=o(" (DistilBERT model)"),s7t=l(),wy=a("li"),NIe=a("strong"),l7t=o("electra"),i7t=o(" \u2014 "),ace=a("a"),d7t=o("FlaxElectraForSequenceClassification"),m7t=o(" (ELECTRA model)"),c7t=l(),Ay=a("li"),qIe=a("strong"),f7t=o("mbart"),g7t=o(" \u2014 "),nce=a("a"),h7t=o("FlaxMBartForSequenceClassification"),u7t=o(" (mBART model)"),p7t=l(),Ly=a("li"),DIe=a("strong"),_7t=o("roberta"),b7t=o(" \u2014 "),sce=a("a"),v7t=o("FlaxRobertaForSequenceClassification"),F7t=o(" (RoBERTa model)"),T7t=l(),yy=a("li"),jIe=a("strong"),M7t=o("roformer"),E7t=o(" \u2014 "),lce=a("a"),C7t=o("FlaxRoFormerForSequenceClassification"),w7t=o(" (RoFormer model)"),A7t=l(),xy=a("li"),GIe=a("strong"),L7t=o("xlm-roberta"),y7t=o(" \u2014 "),ice=a("a"),x7t=o("FlaxXLMRobertaForSequenceClassification"),$7t=o(" (XLM-RoBERTa model)"),k7t=l(),F($y.$$.fragment),vdo=l(),Rf=a("h2"),ky=a("a"),OIe=a("span"),F(AI.$$.fragment),S7t=l(),VIe=a("span"),R7t=o("FlaxAutoModelForQuestionAnswering"),Fdo=l(),Ir=a("div"),F(LI.$$.fragment),P7t=l(),Pf=a("p"),B7t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),dce=a("a"),I7t=o("from_pretrained()"),N7t=o(" class method or the "),mce=a("a"),q7t=o("from_config()"),D7t=o(` class
method.`),j7t=l(),yI=a("p"),G7t=o("This class cannot be instantiated directly using "),XIe=a("code"),O7t=o("__init__()"),V7t=o(" (throws an error)."),X7t=l(),Ea=a("div"),F(xI.$$.fragment),z7t=l(),zIe=a("p"),Q7t=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),W7t=l(),Bf=a("p"),U7t=o(`Note:
Loading a model from its configuration file does `),QIe=a("strong"),H7t=o("not"),J7t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cce=a("a"),Y7t=o("from_pretrained()"),Z7t=o(" to load the model weights."),K7t=l(),F(Sy.$$.fragment),e8t=l(),ft=a("div"),F($I.$$.fragment),o8t=l(),WIe=a("p"),r8t=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),t8t=l(),ds=a("p"),a8t=o("The model class to instantiate is selected based on the "),UIe=a("code"),n8t=o("model_type"),s8t=o(` property of the config object (either
passed as an argument or loaded from `),HIe=a("code"),l8t=o("pretrained_model_name_or_path"),i8t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JIe=a("code"),d8t=o("pretrained_model_name_or_path"),m8t=o(":"),c8t=l(),Ie=a("ul"),Ry=a("li"),YIe=a("strong"),f8t=o("albert"),g8t=o(" \u2014 "),fce=a("a"),h8t=o("FlaxAlbertForQuestionAnswering"),u8t=o(" (ALBERT model)"),p8t=l(),Py=a("li"),ZIe=a("strong"),_8t=o("bart"),b8t=o(" \u2014 "),gce=a("a"),v8t=o("FlaxBartForQuestionAnswering"),F8t=o(" (BART model)"),T8t=l(),By=a("li"),KIe=a("strong"),M8t=o("bert"),E8t=o(" \u2014 "),hce=a("a"),C8t=o("FlaxBertForQuestionAnswering"),w8t=o(" (BERT model)"),A8t=l(),Iy=a("li"),eNe=a("strong"),L8t=o("big_bird"),y8t=o(" \u2014 "),uce=a("a"),x8t=o("FlaxBigBirdForQuestionAnswering"),$8t=o(" (BigBird model)"),k8t=l(),Ny=a("li"),oNe=a("strong"),S8t=o("distilbert"),R8t=o(" \u2014 "),pce=a("a"),P8t=o("FlaxDistilBertForQuestionAnswering"),B8t=o(" (DistilBERT model)"),I8t=l(),qy=a("li"),rNe=a("strong"),N8t=o("electra"),q8t=o(" \u2014 "),_ce=a("a"),D8t=o("FlaxElectraForQuestionAnswering"),j8t=o(" (ELECTRA model)"),G8t=l(),Dy=a("li"),tNe=a("strong"),O8t=o("mbart"),V8t=o(" \u2014 "),bce=a("a"),X8t=o("FlaxMBartForQuestionAnswering"),z8t=o(" (mBART model)"),Q8t=l(),jy=a("li"),aNe=a("strong"),W8t=o("roberta"),U8t=o(" \u2014 "),vce=a("a"),H8t=o("FlaxRobertaForQuestionAnswering"),J8t=o(" (RoBERTa model)"),Y8t=l(),Gy=a("li"),nNe=a("strong"),Z8t=o("roformer"),K8t=o(" \u2014 "),Fce=a("a"),eLt=o("FlaxRoFormerForQuestionAnswering"),oLt=o(" (RoFormer model)"),rLt=l(),Oy=a("li"),sNe=a("strong"),tLt=o("xlm-roberta"),aLt=o(" \u2014 "),Tce=a("a"),nLt=o("FlaxXLMRobertaForQuestionAnswering"),sLt=o(" (XLM-RoBERTa model)"),lLt=l(),F(Vy.$$.fragment),Tdo=l(),If=a("h2"),Xy=a("a"),lNe=a("span"),F(kI.$$.fragment),iLt=l(),iNe=a("span"),dLt=o("FlaxAutoModelForTokenClassification"),Mdo=l(),Nr=a("div"),F(SI.$$.fragment),mLt=l(),Nf=a("p"),cLt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Mce=a("a"),fLt=o("from_pretrained()"),gLt=o(" class method or the "),Ece=a("a"),hLt=o("from_config()"),uLt=o(` class
method.`),pLt=l(),RI=a("p"),_Lt=o("This class cannot be instantiated directly using "),dNe=a("code"),bLt=o("__init__()"),vLt=o(" (throws an error)."),FLt=l(),Ca=a("div"),F(PI.$$.fragment),TLt=l(),mNe=a("p"),MLt=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),ELt=l(),qf=a("p"),CLt=o(`Note:
Loading a model from its configuration file does `),cNe=a("strong"),wLt=o("not"),ALt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Cce=a("a"),LLt=o("from_pretrained()"),yLt=o(" to load the model weights."),xLt=l(),F(zy.$$.fragment),$Lt=l(),gt=a("div"),F(BI.$$.fragment),kLt=l(),fNe=a("p"),SLt=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),RLt=l(),ms=a("p"),PLt=o("The model class to instantiate is selected based on the "),gNe=a("code"),BLt=o("model_type"),ILt=o(` property of the config object (either
passed as an argument or loaded from `),hNe=a("code"),NLt=o("pretrained_model_name_or_path"),qLt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uNe=a("code"),DLt=o("pretrained_model_name_or_path"),jLt=o(":"),GLt=l(),We=a("ul"),Qy=a("li"),pNe=a("strong"),OLt=o("albert"),VLt=o(" \u2014 "),wce=a("a"),XLt=o("FlaxAlbertForTokenClassification"),zLt=o(" (ALBERT model)"),QLt=l(),Wy=a("li"),_Ne=a("strong"),WLt=o("bert"),ULt=o(" \u2014 "),Ace=a("a"),HLt=o("FlaxBertForTokenClassification"),JLt=o(" (BERT model)"),YLt=l(),Uy=a("li"),bNe=a("strong"),ZLt=o("big_bird"),KLt=o(" \u2014 "),Lce=a("a"),eyt=o("FlaxBigBirdForTokenClassification"),oyt=o(" (BigBird model)"),ryt=l(),Hy=a("li"),vNe=a("strong"),tyt=o("distilbert"),ayt=o(" \u2014 "),yce=a("a"),nyt=o("FlaxDistilBertForTokenClassification"),syt=o(" (DistilBERT model)"),lyt=l(),Jy=a("li"),FNe=a("strong"),iyt=o("electra"),dyt=o(" \u2014 "),xce=a("a"),myt=o("FlaxElectraForTokenClassification"),cyt=o(" (ELECTRA model)"),fyt=l(),Yy=a("li"),TNe=a("strong"),gyt=o("roberta"),hyt=o(" \u2014 "),$ce=a("a"),uyt=o("FlaxRobertaForTokenClassification"),pyt=o(" (RoBERTa model)"),_yt=l(),Zy=a("li"),MNe=a("strong"),byt=o("roformer"),vyt=o(" \u2014 "),kce=a("a"),Fyt=o("FlaxRoFormerForTokenClassification"),Tyt=o(" (RoFormer model)"),Myt=l(),Ky=a("li"),ENe=a("strong"),Eyt=o("xlm-roberta"),Cyt=o(" \u2014 "),Sce=a("a"),wyt=o("FlaxXLMRobertaForTokenClassification"),Ayt=o(" (XLM-RoBERTa model)"),Lyt=l(),F(e9.$$.fragment),Edo=l(),Df=a("h2"),o9=a("a"),CNe=a("span"),F(II.$$.fragment),yyt=l(),wNe=a("span"),xyt=o("FlaxAutoModelForMultipleChoice"),Cdo=l(),qr=a("div"),F(NI.$$.fragment),$yt=l(),jf=a("p"),kyt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Rce=a("a"),Syt=o("from_pretrained()"),Ryt=o(" class method or the "),Pce=a("a"),Pyt=o("from_config()"),Byt=o(` class
method.`),Iyt=l(),qI=a("p"),Nyt=o("This class cannot be instantiated directly using "),ANe=a("code"),qyt=o("__init__()"),Dyt=o(" (throws an error)."),jyt=l(),wa=a("div"),F(DI.$$.fragment),Gyt=l(),LNe=a("p"),Oyt=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Vyt=l(),Gf=a("p"),Xyt=o(`Note:
Loading a model from its configuration file does `),yNe=a("strong"),zyt=o("not"),Qyt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Bce=a("a"),Wyt=o("from_pretrained()"),Uyt=o(" to load the model weights."),Hyt=l(),F(r9.$$.fragment),Jyt=l(),ht=a("div"),F(jI.$$.fragment),Yyt=l(),xNe=a("p"),Zyt=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Kyt=l(),cs=a("p"),e9t=o("The model class to instantiate is selected based on the "),$Ne=a("code"),o9t=o("model_type"),r9t=o(` property of the config object (either
passed as an argument or loaded from `),kNe=a("code"),t9t=o("pretrained_model_name_or_path"),a9t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SNe=a("code"),n9t=o("pretrained_model_name_or_path"),s9t=o(":"),l9t=l(),Ue=a("ul"),t9=a("li"),RNe=a("strong"),i9t=o("albert"),d9t=o(" \u2014 "),Ice=a("a"),m9t=o("FlaxAlbertForMultipleChoice"),c9t=o(" (ALBERT model)"),f9t=l(),a9=a("li"),PNe=a("strong"),g9t=o("bert"),h9t=o(" \u2014 "),Nce=a("a"),u9t=o("FlaxBertForMultipleChoice"),p9t=o(" (BERT model)"),_9t=l(),n9=a("li"),BNe=a("strong"),b9t=o("big_bird"),v9t=o(" \u2014 "),qce=a("a"),F9t=o("FlaxBigBirdForMultipleChoice"),T9t=o(" (BigBird model)"),M9t=l(),s9=a("li"),INe=a("strong"),E9t=o("distilbert"),C9t=o(" \u2014 "),Dce=a("a"),w9t=o("FlaxDistilBertForMultipleChoice"),A9t=o(" (DistilBERT model)"),L9t=l(),l9=a("li"),NNe=a("strong"),y9t=o("electra"),x9t=o(" \u2014 "),jce=a("a"),$9t=o("FlaxElectraForMultipleChoice"),k9t=o(" (ELECTRA model)"),S9t=l(),i9=a("li"),qNe=a("strong"),R9t=o("roberta"),P9t=o(" \u2014 "),Gce=a("a"),B9t=o("FlaxRobertaForMultipleChoice"),I9t=o(" (RoBERTa model)"),N9t=l(),d9=a("li"),DNe=a("strong"),q9t=o("roformer"),D9t=o(" \u2014 "),Oce=a("a"),j9t=o("FlaxRoFormerForMultipleChoice"),G9t=o(" (RoFormer model)"),O9t=l(),m9=a("li"),jNe=a("strong"),V9t=o("xlm-roberta"),X9t=o(" \u2014 "),Vce=a("a"),z9t=o("FlaxXLMRobertaForMultipleChoice"),Q9t=o(" (XLM-RoBERTa model)"),W9t=l(),F(c9.$$.fragment),wdo=l(),Of=a("h2"),f9=a("a"),GNe=a("span"),F(GI.$$.fragment),U9t=l(),ONe=a("span"),H9t=o("FlaxAutoModelForNextSentencePrediction"),Ado=l(),Dr=a("div"),F(OI.$$.fragment),J9t=l(),Vf=a("p"),Y9t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Xce=a("a"),Z9t=o("from_pretrained()"),K9t=o(" class method or the "),zce=a("a"),ext=o("from_config()"),oxt=o(` class
method.`),rxt=l(),VI=a("p"),txt=o("This class cannot be instantiated directly using "),VNe=a("code"),axt=o("__init__()"),nxt=o(" (throws an error)."),sxt=l(),Aa=a("div"),F(XI.$$.fragment),lxt=l(),XNe=a("p"),ixt=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),dxt=l(),Xf=a("p"),mxt=o(`Note:
Loading a model from its configuration file does `),zNe=a("strong"),cxt=o("not"),fxt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Qce=a("a"),gxt=o("from_pretrained()"),hxt=o(" to load the model weights."),uxt=l(),F(g9.$$.fragment),pxt=l(),ut=a("div"),F(zI.$$.fragment),_xt=l(),QNe=a("p"),bxt=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),vxt=l(),fs=a("p"),Fxt=o("The model class to instantiate is selected based on the "),WNe=a("code"),Txt=o("model_type"),Mxt=o(` property of the config object (either
passed as an argument or loaded from `),UNe=a("code"),Ext=o("pretrained_model_name_or_path"),Cxt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HNe=a("code"),wxt=o("pretrained_model_name_or_path"),Axt=o(":"),Lxt=l(),JNe=a("ul"),h9=a("li"),YNe=a("strong"),yxt=o("bert"),xxt=o(" \u2014 "),Wce=a("a"),$xt=o("FlaxBertForNextSentencePrediction"),kxt=o(" (BERT model)"),Sxt=l(),F(u9.$$.fragment),Ldo=l(),zf=a("h2"),p9=a("a"),ZNe=a("span"),F(QI.$$.fragment),Rxt=l(),KNe=a("span"),Pxt=o("FlaxAutoModelForImageClassification"),ydo=l(),jr=a("div"),F(WI.$$.fragment),Bxt=l(),Qf=a("p"),Ixt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Uce=a("a"),Nxt=o("from_pretrained()"),qxt=o(" class method or the "),Hce=a("a"),Dxt=o("from_config()"),jxt=o(` class
method.`),Gxt=l(),UI=a("p"),Oxt=o("This class cannot be instantiated directly using "),eqe=a("code"),Vxt=o("__init__()"),Xxt=o(" (throws an error)."),zxt=l(),La=a("div"),F(HI.$$.fragment),Qxt=l(),oqe=a("p"),Wxt=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Uxt=l(),Wf=a("p"),Hxt=o(`Note:
Loading a model from its configuration file does `),rqe=a("strong"),Jxt=o("not"),Yxt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Jce=a("a"),Zxt=o("from_pretrained()"),Kxt=o(" to load the model weights."),e$t=l(),F(_9.$$.fragment),o$t=l(),pt=a("div"),F(JI.$$.fragment),r$t=l(),tqe=a("p"),t$t=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),a$t=l(),gs=a("p"),n$t=o("The model class to instantiate is selected based on the "),aqe=a("code"),s$t=o("model_type"),l$t=o(` property of the config object (either
passed as an argument or loaded from `),nqe=a("code"),i$t=o("pretrained_model_name_or_path"),d$t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sqe=a("code"),m$t=o("pretrained_model_name_or_path"),c$t=o(":"),f$t=l(),YI=a("ul"),b9=a("li"),lqe=a("strong"),g$t=o("beit"),h$t=o(" \u2014 "),Yce=a("a"),u$t=o("FlaxBeitForImageClassification"),p$t=o(" (BEiT model)"),_$t=l(),v9=a("li"),iqe=a("strong"),b$t=o("vit"),v$t=o(" \u2014 "),Zce=a("a"),F$t=o("FlaxViTForImageClassification"),T$t=o(" (ViT model)"),M$t=l(),F(F9.$$.fragment),xdo=l(),Uf=a("h2"),T9=a("a"),dqe=a("span"),F(ZI.$$.fragment),E$t=l(),mqe=a("span"),C$t=o("FlaxAutoModelForVision2Seq"),$do=l(),Gr=a("div"),F(KI.$$.fragment),w$t=l(),Hf=a("p"),A$t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Kce=a("a"),L$t=o("from_pretrained()"),y$t=o(" class method or the "),efe=a("a"),x$t=o("from_config()"),$$t=o(` class
method.`),k$t=l(),eN=a("p"),S$t=o("This class cannot be instantiated directly using "),cqe=a("code"),R$t=o("__init__()"),P$t=o(" (throws an error)."),B$t=l(),ya=a("div"),F(oN.$$.fragment),I$t=l(),fqe=a("p"),N$t=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),q$t=l(),Jf=a("p"),D$t=o(`Note:
Loading a model from its configuration file does `),gqe=a("strong"),j$t=o("not"),G$t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ofe=a("a"),O$t=o("from_pretrained()"),V$t=o(" to load the model weights."),X$t=l(),F(M9.$$.fragment),z$t=l(),_t=a("div"),F(rN.$$.fragment),Q$t=l(),hqe=a("p"),W$t=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),U$t=l(),hs=a("p"),H$t=o("The model class to instantiate is selected based on the "),uqe=a("code"),J$t=o("model_type"),Y$t=o(` property of the config object (either
passed as an argument or loaded from `),pqe=a("code"),Z$t=o("pretrained_model_name_or_path"),K$t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_qe=a("code"),ekt=o("pretrained_model_name_or_path"),okt=o(":"),rkt=l(),bqe=a("ul"),E9=a("li"),vqe=a("strong"),tkt=o("vision-encoder-decoder"),akt=o(" \u2014 "),rfe=a("a"),nkt=o("FlaxVisionEncoderDecoderModel"),skt=o(" (Vision Encoder decoder model)"),lkt=l(),F(C9.$$.fragment),this.h()},l(c){const _=R9a('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(c),u=n(c,"H1",{class:!0});var tN=s(u);f=n(tN,"A",{id:!0,class:!0,href:!0});var Fqe=s(f);p=n(Fqe,"SPAN",{});var Tqe=s(p);T(m.$$.fragment,Tqe),Tqe.forEach(t),Fqe.forEach(t),h=i(tN),He=n(tN,"SPAN",{});var Mqe=s(He);Ad=r(Mqe,"Auto Classes"),Mqe.forEach(t),tN.forEach(t),eg=i(c),wt=n(c,"P",{});var aN=s(wt);Ld=r(aN,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),yd=n(aN,"CODE",{});var Eqe=s(yd);lk=r(Eqe,"from_pretrained()"),Eqe.forEach(t),og=r(aN,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),aN.forEach(t),Qe=i(c),Ze=n(c,"P",{});var us=s(Ze);xd=r(us,"Instantiating one of "),ps=n(us,"A",{href:!0});var Cqe=s(ps);ik=r(Cqe,"AutoConfig"),Cqe.forEach(t),_s=r(us,", "),bs=n(us,"A",{href:!0});var wqe=s(bs);dk=r(wqe,"AutoModel"),wqe.forEach(t),$d=r(us,`, and
`),vs=n(us,"A",{href:!0});var Aqe=s(vs);mk=r(Aqe,"AutoTokenizer"),Aqe.forEach(t),kd=r(us," will directly create a class of the relevant architecture. For instance"),us.forEach(t),rg=i(c),T(sn.$$.fragment,c),Ke=i(c),ye=n(c,"P",{});var nN=s(ye);kq=r(nN,"will create a model that is an instance of "),Sd=n(nN,"A",{href:!0});var Lqe=s(Sd);Sq=r(Lqe,"BertModel"),Lqe.forEach(t),Rq=r(nN,"."),nN.forEach(t),Po=i(c),ln=n(c,"P",{});var sN=s(ln);Pq=r(sN,"There is one class of "),tg=n(sN,"CODE",{});var yqe=s(tg);Bq=r(yqe,"AutoModel"),yqe.forEach(t),afo=r(sN," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),sN.forEach(t),flo=i(c),Rd=n(c,"H2",{class:!0});var lN=s(Rd);ag=n(lN,"A",{id:!0,class:!0,href:!0});var xqe=s(ag);che=n(xqe,"SPAN",{});var $qe=s(che);T(ck.$$.fragment,$qe),$qe.forEach(t),xqe.forEach(t),nfo=i(lN),fhe=n(lN,"SPAN",{});var kqe=s(fhe);sfo=r(kqe,"Extending the Auto Classes"),kqe.forEach(t),lN.forEach(t),glo=i(c),Fs=n(c,"P",{});var Yf=s(Fs);lfo=r(Yf,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),ghe=n(Yf,"CODE",{});var Sqe=s(ghe);ifo=r(Sqe,"NewModel"),Sqe.forEach(t),dfo=r(Yf,", make sure you have a "),hhe=n(Yf,"CODE",{});var Rqe=s(hhe);mfo=r(Rqe,"NewModelConfig"),Rqe.forEach(t),cfo=r(Yf,` then you can add those to the auto
classes like this:`),Yf.forEach(t),hlo=i(c),T(fk.$$.fragment,c),ulo=i(c),Iq=n(c,"P",{});var Pqe=s(Iq);ffo=r(Pqe,"You will then be able to use the auto classes like you would usually do!"),Pqe.forEach(t),plo=i(c),T(ng.$$.fragment,c),_lo=i(c),Pd=n(c,"H2",{class:!0});var iN=s(Pd);sg=n(iN,"A",{id:!0,class:!0,href:!0});var Bqe=s(sg);uhe=n(Bqe,"SPAN",{});var Iqe=s(uhe);T(gk.$$.fragment,Iqe),Iqe.forEach(t),Bqe.forEach(t),gfo=i(iN),phe=n(iN,"SPAN",{});var Nqe=s(phe);hfo=r(Nqe,"AutoConfig"),Nqe.forEach(t),iN.forEach(t),blo=i(c),Bo=n(c,"DIV",{class:!0});var Et=s(Bo);T(hk.$$.fragment,Et),ufo=i(Et),uk=n(Et,"P",{});var dN=s(uk);pfo=r(dN,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),Nq=n(dN,"A",{href:!0});var qqe=s(Nq);_fo=r(qqe,"from_pretrained()"),qqe.forEach(t),bfo=r(dN," class method."),dN.forEach(t),vfo=i(Et),pk=n(Et,"P",{});var mN=s(pk);Ffo=r(mN,"This class cannot be instantiated directly using "),_he=n(mN,"CODE",{});var Dqe=s(_he);Tfo=r(Dqe,"__init__()"),Dqe.forEach(t),Mfo=r(mN," (throws an error)."),mN.forEach(t),Efo=i(Et),Or=n(Et,"DIV",{class:!0});var Ct=s(Or);T(_k.$$.fragment,Ct),Cfo=i(Ct),bhe=n(Ct,"P",{});var jqe=s(bhe);wfo=r(jqe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),jqe.forEach(t),Afo=i(Ct),Bd=n(Ct,"P",{});var Zf=s(Bd);Lfo=r(Zf,"The configuration class to instantiate is selected based on the "),vhe=n(Zf,"CODE",{});var Gqe=s(vhe);yfo=r(Gqe,"model_type"),Gqe.forEach(t),xfo=r(Zf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Fhe=n(Zf,"CODE",{});var Oqe=s(Fhe);$fo=r(Oqe,"pretrained_model_name_or_path"),Oqe.forEach(t),kfo=r(Zf,":"),Zf.forEach(t),Sfo=i(Ct),A=n(Ct,"UL",{});var L=s(A);lg=n(L,"LI",{});var w9=s(lg);The=n(w9,"STRONG",{});var Vqe=s(The);Rfo=r(Vqe,"albert"),Vqe.forEach(t),Pfo=r(w9," \u2014 "),qq=n(w9,"A",{href:!0});var Xqe=s(qq);Bfo=r(Xqe,"AlbertConfig"),Xqe.forEach(t),Ifo=r(w9," (ALBERT model)"),w9.forEach(t),Nfo=i(L),ig=n(L,"LI",{});var A9=s(ig);Mhe=n(A9,"STRONG",{});var zqe=s(Mhe);qfo=r(zqe,"bart"),zqe.forEach(t),Dfo=r(A9," \u2014 "),Dq=n(A9,"A",{href:!0});var Qqe=s(Dq);jfo=r(Qqe,"BartConfig"),Qqe.forEach(t),Gfo=r(A9," (BART model)"),A9.forEach(t),Ofo=i(L),dg=n(L,"LI",{});var L9=s(dg);Ehe=n(L9,"STRONG",{});var Wqe=s(Ehe);Vfo=r(Wqe,"beit"),Wqe.forEach(t),Xfo=r(L9," \u2014 "),jq=n(L9,"A",{href:!0});var Uqe=s(jq);zfo=r(Uqe,"BeitConfig"),Uqe.forEach(t),Qfo=r(L9," (BEiT model)"),L9.forEach(t),Wfo=i(L),mg=n(L,"LI",{});var y9=s(mg);Che=n(y9,"STRONG",{});var Hqe=s(Che);Ufo=r(Hqe,"bert"),Hqe.forEach(t),Hfo=r(y9," \u2014 "),Gq=n(y9,"A",{href:!0});var Jqe=s(Gq);Jfo=r(Jqe,"BertConfig"),Jqe.forEach(t),Yfo=r(y9," (BERT model)"),y9.forEach(t),Zfo=i(L),cg=n(L,"LI",{});var x9=s(cg);whe=n(x9,"STRONG",{});var Yqe=s(whe);Kfo=r(Yqe,"bert-generation"),Yqe.forEach(t),ego=r(x9," \u2014 "),Oq=n(x9,"A",{href:!0});var Zqe=s(Oq);ogo=r(Zqe,"BertGenerationConfig"),Zqe.forEach(t),rgo=r(x9," (Bert Generation model)"),x9.forEach(t),tgo=i(L),fg=n(L,"LI",{});var $9=s(fg);Ahe=n($9,"STRONG",{});var Kqe=s(Ahe);ago=r(Kqe,"big_bird"),Kqe.forEach(t),ngo=r($9," \u2014 "),Vq=n($9,"A",{href:!0});var eDe=s(Vq);sgo=r(eDe,"BigBirdConfig"),eDe.forEach(t),lgo=r($9," (BigBird model)"),$9.forEach(t),igo=i(L),gg=n(L,"LI",{});var k9=s(gg);Lhe=n(k9,"STRONG",{});var oDe=s(Lhe);dgo=r(oDe,"bigbird_pegasus"),oDe.forEach(t),mgo=r(k9," \u2014 "),Xq=n(k9,"A",{href:!0});var rDe=s(Xq);cgo=r(rDe,"BigBirdPegasusConfig"),rDe.forEach(t),fgo=r(k9," (BigBird-Pegasus model)"),k9.forEach(t),ggo=i(L),hg=n(L,"LI",{});var S9=s(hg);yhe=n(S9,"STRONG",{});var tDe=s(yhe);hgo=r(tDe,"blenderbot"),tDe.forEach(t),ugo=r(S9," \u2014 "),zq=n(S9,"A",{href:!0});var aDe=s(zq);pgo=r(aDe,"BlenderbotConfig"),aDe.forEach(t),_go=r(S9," (Blenderbot model)"),S9.forEach(t),bgo=i(L),ug=n(L,"LI",{});var R9=s(ug);xhe=n(R9,"STRONG",{});var nDe=s(xhe);vgo=r(nDe,"blenderbot-small"),nDe.forEach(t),Fgo=r(R9," \u2014 "),Qq=n(R9,"A",{href:!0});var sDe=s(Qq);Tgo=r(sDe,"BlenderbotSmallConfig"),sDe.forEach(t),Mgo=r(R9," (BlenderbotSmall model)"),R9.forEach(t),Ego=i(L),pg=n(L,"LI",{});var P9=s(pg);$he=n(P9,"STRONG",{});var lDe=s($he);Cgo=r(lDe,"bloom"),lDe.forEach(t),wgo=r(P9," \u2014 "),Wq=n(P9,"A",{href:!0});var iDe=s(Wq);Ago=r(iDe,"BloomConfig"),iDe.forEach(t),Lgo=r(P9," (BLOOM model)"),P9.forEach(t),ygo=i(L),_g=n(L,"LI",{});var B9=s(_g);khe=n(B9,"STRONG",{});var dDe=s(khe);xgo=r(dDe,"camembert"),dDe.forEach(t),$go=r(B9," \u2014 "),Uq=n(B9,"A",{href:!0});var mDe=s(Uq);kgo=r(mDe,"CamembertConfig"),mDe.forEach(t),Sgo=r(B9," (CamemBERT model)"),B9.forEach(t),Rgo=i(L),bg=n(L,"LI",{});var I9=s(bg);She=n(I9,"STRONG",{});var cDe=s(She);Pgo=r(cDe,"canine"),cDe.forEach(t),Bgo=r(I9," \u2014 "),Hq=n(I9,"A",{href:!0});var fDe=s(Hq);Igo=r(fDe,"CanineConfig"),fDe.forEach(t),Ngo=r(I9," (CANINE model)"),I9.forEach(t),qgo=i(L),vg=n(L,"LI",{});var N9=s(vg);Rhe=n(N9,"STRONG",{});var gDe=s(Rhe);Dgo=r(gDe,"clip"),gDe.forEach(t),jgo=r(N9," \u2014 "),Jq=n(N9,"A",{href:!0});var hDe=s(Jq);Ggo=r(hDe,"CLIPConfig"),hDe.forEach(t),Ogo=r(N9," (CLIP model)"),N9.forEach(t),Vgo=i(L),Fg=n(L,"LI",{});var q9=s(Fg);Phe=n(q9,"STRONG",{});var uDe=s(Phe);Xgo=r(uDe,"clipseg"),uDe.forEach(t),zgo=r(q9," \u2014 "),Yq=n(q9,"A",{href:!0});var pDe=s(Yq);Qgo=r(pDe,"CLIPSegConfig"),pDe.forEach(t),Wgo=r(q9," (CLIPSeg model)"),q9.forEach(t),Ugo=i(L),Tg=n(L,"LI",{});var D9=s(Tg);Bhe=n(D9,"STRONG",{});var _De=s(Bhe);Hgo=r(_De,"codegen"),_De.forEach(t),Jgo=r(D9," \u2014 "),Zq=n(D9,"A",{href:!0});var bDe=s(Zq);Ygo=r(bDe,"CodeGenConfig"),bDe.forEach(t),Zgo=r(D9," (CodeGen model)"),D9.forEach(t),Kgo=i(L),Mg=n(L,"LI",{});var j9=s(Mg);Ihe=n(j9,"STRONG",{});var vDe=s(Ihe);eho=r(vDe,"conditional_detr"),vDe.forEach(t),oho=r(j9," \u2014 "),Kq=n(j9,"A",{href:!0});var FDe=s(Kq);rho=r(FDe,"ConditionalDetrConfig"),FDe.forEach(t),tho=r(j9," (Conditional DETR model)"),j9.forEach(t),aho=i(L),Eg=n(L,"LI",{});var G9=s(Eg);Nhe=n(G9,"STRONG",{});var TDe=s(Nhe);nho=r(TDe,"convbert"),TDe.forEach(t),sho=r(G9," \u2014 "),eD=n(G9,"A",{href:!0});var MDe=s(eD);lho=r(MDe,"ConvBertConfig"),MDe.forEach(t),iho=r(G9," (ConvBERT model)"),G9.forEach(t),dho=i(L),Cg=n(L,"LI",{});var O9=s(Cg);qhe=n(O9,"STRONG",{});var EDe=s(qhe);mho=r(EDe,"convnext"),EDe.forEach(t),cho=r(O9," \u2014 "),oD=n(O9,"A",{href:!0});var CDe=s(oD);fho=r(CDe,"ConvNextConfig"),CDe.forEach(t),gho=r(O9," (ConvNeXT model)"),O9.forEach(t),hho=i(L),wg=n(L,"LI",{});var V9=s(wg);Dhe=n(V9,"STRONG",{});var wDe=s(Dhe);uho=r(wDe,"ctrl"),wDe.forEach(t),pho=r(V9," \u2014 "),rD=n(V9,"A",{href:!0});var ADe=s(rD);_ho=r(ADe,"CTRLConfig"),ADe.forEach(t),bho=r(V9," (CTRL model)"),V9.forEach(t),vho=i(L),Ag=n(L,"LI",{});var X9=s(Ag);jhe=n(X9,"STRONG",{});var LDe=s(jhe);Fho=r(LDe,"cvt"),LDe.forEach(t),Tho=r(X9," \u2014 "),tD=n(X9,"A",{href:!0});var yDe=s(tD);Mho=r(yDe,"CvtConfig"),yDe.forEach(t),Eho=r(X9," (CvT model)"),X9.forEach(t),Cho=i(L),Lg=n(L,"LI",{});var z9=s(Lg);Ghe=n(z9,"STRONG",{});var xDe=s(Ghe);who=r(xDe,"data2vec-audio"),xDe.forEach(t),Aho=r(z9," \u2014 "),aD=n(z9,"A",{href:!0});var $De=s(aD);Lho=r($De,"Data2VecAudioConfig"),$De.forEach(t),yho=r(z9," (Data2VecAudio model)"),z9.forEach(t),xho=i(L),yg=n(L,"LI",{});var Q9=s(yg);Ohe=n(Q9,"STRONG",{});var kDe=s(Ohe);$ho=r(kDe,"data2vec-text"),kDe.forEach(t),kho=r(Q9," \u2014 "),nD=n(Q9,"A",{href:!0});var SDe=s(nD);Sho=r(SDe,"Data2VecTextConfig"),SDe.forEach(t),Rho=r(Q9," (Data2VecText model)"),Q9.forEach(t),Pho=i(L),xg=n(L,"LI",{});var W9=s(xg);Vhe=n(W9,"STRONG",{});var RDe=s(Vhe);Bho=r(RDe,"data2vec-vision"),RDe.forEach(t),Iho=r(W9," \u2014 "),sD=n(W9,"A",{href:!0});var PDe=s(sD);Nho=r(PDe,"Data2VecVisionConfig"),PDe.forEach(t),qho=r(W9," (Data2VecVision model)"),W9.forEach(t),Dho=i(L),$g=n(L,"LI",{});var U9=s($g);Xhe=n(U9,"STRONG",{});var BDe=s(Xhe);jho=r(BDe,"deberta"),BDe.forEach(t),Gho=r(U9," \u2014 "),lD=n(U9,"A",{href:!0});var IDe=s(lD);Oho=r(IDe,"DebertaConfig"),IDe.forEach(t),Vho=r(U9," (DeBERTa model)"),U9.forEach(t),Xho=i(L),kg=n(L,"LI",{});var H9=s(kg);zhe=n(H9,"STRONG",{});var NDe=s(zhe);zho=r(NDe,"deberta-v2"),NDe.forEach(t),Qho=r(H9," \u2014 "),iD=n(H9,"A",{href:!0});var qDe=s(iD);Who=r(qDe,"DebertaV2Config"),qDe.forEach(t),Uho=r(H9," (DeBERTa-v2 model)"),H9.forEach(t),Hho=i(L),Sg=n(L,"LI",{});var J9=s(Sg);Qhe=n(J9,"STRONG",{});var DDe=s(Qhe);Jho=r(DDe,"decision_transformer"),DDe.forEach(t),Yho=r(J9," \u2014 "),dD=n(J9,"A",{href:!0});var jDe=s(dD);Zho=r(jDe,"DecisionTransformerConfig"),jDe.forEach(t),Kho=r(J9," (Decision Transformer model)"),J9.forEach(t),euo=i(L),Rg=n(L,"LI",{});var Y9=s(Rg);Whe=n(Y9,"STRONG",{});var GDe=s(Whe);ouo=r(GDe,"deformable_detr"),GDe.forEach(t),ruo=r(Y9," \u2014 "),mD=n(Y9,"A",{href:!0});var ODe=s(mD);tuo=r(ODe,"DeformableDetrConfig"),ODe.forEach(t),auo=r(Y9," (Deformable DETR model)"),Y9.forEach(t),nuo=i(L),Pg=n(L,"LI",{});var Z9=s(Pg);Uhe=n(Z9,"STRONG",{});var VDe=s(Uhe);suo=r(VDe,"deit"),VDe.forEach(t),luo=r(Z9," \u2014 "),cD=n(Z9,"A",{href:!0});var XDe=s(cD);iuo=r(XDe,"DeiTConfig"),XDe.forEach(t),duo=r(Z9," (DeiT model)"),Z9.forEach(t),muo=i(L),Bg=n(L,"LI",{});var zDe=s(Bg);Hhe=n(zDe,"STRONG",{});var ikt=s(Hhe);cuo=r(ikt,"detr"),ikt.forEach(t),fuo=r(zDe," \u2014 "),fD=n(zDe,"A",{href:!0});var dkt=s(fD);guo=r(dkt,"DetrConfig"),dkt.forEach(t),huo=r(zDe," (DETR model)"),zDe.forEach(t),uuo=i(L),Ig=n(L,"LI",{});var QDe=s(Ig);Jhe=n(QDe,"STRONG",{});var mkt=s(Jhe);puo=r(mkt,"distilbert"),mkt.forEach(t),_uo=r(QDe," \u2014 "),gD=n(QDe,"A",{href:!0});var ckt=s(gD);buo=r(ckt,"DistilBertConfig"),ckt.forEach(t),vuo=r(QDe," (DistilBERT model)"),QDe.forEach(t),Fuo=i(L),Ng=n(L,"LI",{});var WDe=s(Ng);Yhe=n(WDe,"STRONG",{});var fkt=s(Yhe);Tuo=r(fkt,"donut-swin"),fkt.forEach(t),Muo=r(WDe," \u2014 "),hD=n(WDe,"A",{href:!0});var gkt=s(hD);Euo=r(gkt,"DonutSwinConfig"),gkt.forEach(t),Cuo=r(WDe," (DonutSwin model)"),WDe.forEach(t),wuo=i(L),qg=n(L,"LI",{});var UDe=s(qg);Zhe=n(UDe,"STRONG",{});var hkt=s(Zhe);Auo=r(hkt,"dpr"),hkt.forEach(t),Luo=r(UDe," \u2014 "),uD=n(UDe,"A",{href:!0});var ukt=s(uD);yuo=r(ukt,"DPRConfig"),ukt.forEach(t),xuo=r(UDe," (DPR model)"),UDe.forEach(t),$uo=i(L),Dg=n(L,"LI",{});var HDe=s(Dg);Khe=n(HDe,"STRONG",{});var pkt=s(Khe);kuo=r(pkt,"dpt"),pkt.forEach(t),Suo=r(HDe," \u2014 "),pD=n(HDe,"A",{href:!0});var _kt=s(pD);Ruo=r(_kt,"DPTConfig"),_kt.forEach(t),Puo=r(HDe," (DPT model)"),HDe.forEach(t),Buo=i(L),jg=n(L,"LI",{});var JDe=s(jg);eue=n(JDe,"STRONG",{});var bkt=s(eue);Iuo=r(bkt,"electra"),bkt.forEach(t),Nuo=r(JDe," \u2014 "),_D=n(JDe,"A",{href:!0});var vkt=s(_D);quo=r(vkt,"ElectraConfig"),vkt.forEach(t),Duo=r(JDe," (ELECTRA model)"),JDe.forEach(t),juo=i(L),Gg=n(L,"LI",{});var YDe=s(Gg);oue=n(YDe,"STRONG",{});var Fkt=s(oue);Guo=r(Fkt,"encoder-decoder"),Fkt.forEach(t),Ouo=r(YDe," \u2014 "),bD=n(YDe,"A",{href:!0});var Tkt=s(bD);Vuo=r(Tkt,"EncoderDecoderConfig"),Tkt.forEach(t),Xuo=r(YDe," (Encoder decoder model)"),YDe.forEach(t),zuo=i(L),Og=n(L,"LI",{});var ZDe=s(Og);rue=n(ZDe,"STRONG",{});var Mkt=s(rue);Quo=r(Mkt,"ernie"),Mkt.forEach(t),Wuo=r(ZDe," \u2014 "),vD=n(ZDe,"A",{href:!0});var Ekt=s(vD);Uuo=r(Ekt,"ErnieConfig"),Ekt.forEach(t),Huo=r(ZDe," (ERNIE model)"),ZDe.forEach(t),Juo=i(L),Vg=n(L,"LI",{});var KDe=s(Vg);tue=n(KDe,"STRONG",{});var Ckt=s(tue);Yuo=r(Ckt,"esm"),Ckt.forEach(t),Zuo=r(KDe," \u2014 "),FD=n(KDe,"A",{href:!0});var wkt=s(FD);Kuo=r(wkt,"EsmConfig"),wkt.forEach(t),epo=r(KDe," (ESM model)"),KDe.forEach(t),opo=i(L),Xg=n(L,"LI",{});var eje=s(Xg);aue=n(eje,"STRONG",{});var Akt=s(aue);rpo=r(Akt,"flaubert"),Akt.forEach(t),tpo=r(eje," \u2014 "),TD=n(eje,"A",{href:!0});var Lkt=s(TD);apo=r(Lkt,"FlaubertConfig"),Lkt.forEach(t),npo=r(eje," (FlauBERT model)"),eje.forEach(t),spo=i(L),zg=n(L,"LI",{});var oje=s(zg);nue=n(oje,"STRONG",{});var ykt=s(nue);lpo=r(ykt,"flava"),ykt.forEach(t),ipo=r(oje," \u2014 "),MD=n(oje,"A",{href:!0});var xkt=s(MD);dpo=r(xkt,"FlavaConfig"),xkt.forEach(t),mpo=r(oje," (FLAVA model)"),oje.forEach(t),cpo=i(L),Qg=n(L,"LI",{});var rje=s(Qg);sue=n(rje,"STRONG",{});var $kt=s(sue);fpo=r($kt,"fnet"),$kt.forEach(t),gpo=r(rje," \u2014 "),ED=n(rje,"A",{href:!0});var kkt=s(ED);hpo=r(kkt,"FNetConfig"),kkt.forEach(t),upo=r(rje," (FNet model)"),rje.forEach(t),ppo=i(L),Wg=n(L,"LI",{});var tje=s(Wg);lue=n(tje,"STRONG",{});var Skt=s(lue);_po=r(Skt,"fsmt"),Skt.forEach(t),bpo=r(tje," \u2014 "),CD=n(tje,"A",{href:!0});var Rkt=s(CD);vpo=r(Rkt,"FSMTConfig"),Rkt.forEach(t),Fpo=r(tje," (FairSeq Machine-Translation model)"),tje.forEach(t),Tpo=i(L),Ug=n(L,"LI",{});var aje=s(Ug);iue=n(aje,"STRONG",{});var Pkt=s(iue);Mpo=r(Pkt,"funnel"),Pkt.forEach(t),Epo=r(aje," \u2014 "),wD=n(aje,"A",{href:!0});var Bkt=s(wD);Cpo=r(Bkt,"FunnelConfig"),Bkt.forEach(t),wpo=r(aje," (Funnel Transformer model)"),aje.forEach(t),Apo=i(L),Hg=n(L,"LI",{});var nje=s(Hg);due=n(nje,"STRONG",{});var Ikt=s(due);Lpo=r(Ikt,"glpn"),Ikt.forEach(t),ypo=r(nje," \u2014 "),AD=n(nje,"A",{href:!0});var Nkt=s(AD);xpo=r(Nkt,"GLPNConfig"),Nkt.forEach(t),$po=r(nje," (GLPN model)"),nje.forEach(t),kpo=i(L),Jg=n(L,"LI",{});var sje=s(Jg);mue=n(sje,"STRONG",{});var qkt=s(mue);Spo=r(qkt,"gpt2"),qkt.forEach(t),Rpo=r(sje," \u2014 "),LD=n(sje,"A",{href:!0});var Dkt=s(LD);Ppo=r(Dkt,"GPT2Config"),Dkt.forEach(t),Bpo=r(sje," (OpenAI GPT-2 model)"),sje.forEach(t),Ipo=i(L),Yg=n(L,"LI",{});var lje=s(Yg);cue=n(lje,"STRONG",{});var jkt=s(cue);Npo=r(jkt,"gpt_neo"),jkt.forEach(t),qpo=r(lje," \u2014 "),yD=n(lje,"A",{href:!0});var Gkt=s(yD);Dpo=r(Gkt,"GPTNeoConfig"),Gkt.forEach(t),jpo=r(lje," (GPT Neo model)"),lje.forEach(t),Gpo=i(L),Zg=n(L,"LI",{});var ije=s(Zg);fue=n(ije,"STRONG",{});var Okt=s(fue);Opo=r(Okt,"gpt_neox"),Okt.forEach(t),Vpo=r(ije," \u2014 "),xD=n(ije,"A",{href:!0});var Vkt=s(xD);Xpo=r(Vkt,"GPTNeoXConfig"),Vkt.forEach(t),zpo=r(ije," (GPT NeoX model)"),ije.forEach(t),Qpo=i(L),Kg=n(L,"LI",{});var dje=s(Kg);gue=n(dje,"STRONG",{});var Xkt=s(gue);Wpo=r(Xkt,"gpt_neox_japanese"),Xkt.forEach(t),Upo=r(dje," \u2014 "),$D=n(dje,"A",{href:!0});var zkt=s($D);Hpo=r(zkt,"GPTNeoXJapaneseConfig"),zkt.forEach(t),Jpo=r(dje," (GPT NeoX Japanese model)"),dje.forEach(t),Ypo=i(L),eh=n(L,"LI",{});var mje=s(eh);hue=n(mje,"STRONG",{});var Qkt=s(hue);Zpo=r(Qkt,"gptj"),Qkt.forEach(t),Kpo=r(mje," \u2014 "),kD=n(mje,"A",{href:!0});var Wkt=s(kD);e_o=r(Wkt,"GPTJConfig"),Wkt.forEach(t),o_o=r(mje," (GPT-J model)"),mje.forEach(t),r_o=i(L),oh=n(L,"LI",{});var cje=s(oh);uue=n(cje,"STRONG",{});var Ukt=s(uue);t_o=r(Ukt,"groupvit"),Ukt.forEach(t),a_o=r(cje," \u2014 "),SD=n(cje,"A",{href:!0});var Hkt=s(SD);n_o=r(Hkt,"GroupViTConfig"),Hkt.forEach(t),s_o=r(cje," (GroupViT model)"),cje.forEach(t),l_o=i(L),rh=n(L,"LI",{});var fje=s(rh);pue=n(fje,"STRONG",{});var Jkt=s(pue);i_o=r(Jkt,"hubert"),Jkt.forEach(t),d_o=r(fje," \u2014 "),RD=n(fje,"A",{href:!0});var Ykt=s(RD);m_o=r(Ykt,"HubertConfig"),Ykt.forEach(t),c_o=r(fje," (Hubert model)"),fje.forEach(t),f_o=i(L),th=n(L,"LI",{});var gje=s(th);_ue=n(gje,"STRONG",{});var Zkt=s(_ue);g_o=r(Zkt,"ibert"),Zkt.forEach(t),h_o=r(gje," \u2014 "),PD=n(gje,"A",{href:!0});var Kkt=s(PD);u_o=r(Kkt,"IBertConfig"),Kkt.forEach(t),p_o=r(gje," (I-BERT model)"),gje.forEach(t),__o=i(L),ah=n(L,"LI",{});var hje=s(ah);bue=n(hje,"STRONG",{});var eSt=s(bue);b_o=r(eSt,"imagegpt"),eSt.forEach(t),v_o=r(hje," \u2014 "),BD=n(hje,"A",{href:!0});var oSt=s(BD);F_o=r(oSt,"ImageGPTConfig"),oSt.forEach(t),T_o=r(hje," (ImageGPT model)"),hje.forEach(t),M_o=i(L),nh=n(L,"LI",{});var uje=s(nh);vue=n(uje,"STRONG",{});var rSt=s(vue);E_o=r(rSt,"layoutlm"),rSt.forEach(t),C_o=r(uje," \u2014 "),ID=n(uje,"A",{href:!0});var tSt=s(ID);w_o=r(tSt,"LayoutLMConfig"),tSt.forEach(t),A_o=r(uje," (LayoutLM model)"),uje.forEach(t),L_o=i(L),sh=n(L,"LI",{});var pje=s(sh);Fue=n(pje,"STRONG",{});var aSt=s(Fue);y_o=r(aSt,"layoutlmv2"),aSt.forEach(t),x_o=r(pje," \u2014 "),ND=n(pje,"A",{href:!0});var nSt=s(ND);$_o=r(nSt,"LayoutLMv2Config"),nSt.forEach(t),k_o=r(pje," (LayoutLMv2 model)"),pje.forEach(t),S_o=i(L),lh=n(L,"LI",{});var _je=s(lh);Tue=n(_je,"STRONG",{});var sSt=s(Tue);R_o=r(sSt,"layoutlmv3"),sSt.forEach(t),P_o=r(_je," \u2014 "),qD=n(_je,"A",{href:!0});var lSt=s(qD);B_o=r(lSt,"LayoutLMv3Config"),lSt.forEach(t),I_o=r(_je," (LayoutLMv3 model)"),_je.forEach(t),N_o=i(L),ih=n(L,"LI",{});var bje=s(ih);Mue=n(bje,"STRONG",{});var iSt=s(Mue);q_o=r(iSt,"led"),iSt.forEach(t),D_o=r(bje," \u2014 "),DD=n(bje,"A",{href:!0});var dSt=s(DD);j_o=r(dSt,"LEDConfig"),dSt.forEach(t),G_o=r(bje," (LED model)"),bje.forEach(t),O_o=i(L),dh=n(L,"LI",{});var vje=s(dh);Eue=n(vje,"STRONG",{});var mSt=s(Eue);V_o=r(mSt,"levit"),mSt.forEach(t),X_o=r(vje," \u2014 "),jD=n(vje,"A",{href:!0});var cSt=s(jD);z_o=r(cSt,"LevitConfig"),cSt.forEach(t),Q_o=r(vje," (LeViT model)"),vje.forEach(t),W_o=i(L),mh=n(L,"LI",{});var Fje=s(mh);Cue=n(Fje,"STRONG",{});var fSt=s(Cue);U_o=r(fSt,"lilt"),fSt.forEach(t),H_o=r(Fje," \u2014 "),GD=n(Fje,"A",{href:!0});var gSt=s(GD);J_o=r(gSt,"LiltConfig"),gSt.forEach(t),Y_o=r(Fje," (LiLT model)"),Fje.forEach(t),Z_o=i(L),ch=n(L,"LI",{});var Tje=s(ch);wue=n(Tje,"STRONG",{});var hSt=s(wue);K_o=r(hSt,"longformer"),hSt.forEach(t),e1o=r(Tje," \u2014 "),OD=n(Tje,"A",{href:!0});var uSt=s(OD);o1o=r(uSt,"LongformerConfig"),uSt.forEach(t),r1o=r(Tje," (Longformer model)"),Tje.forEach(t),t1o=i(L),fh=n(L,"LI",{});var Mje=s(fh);Aue=n(Mje,"STRONG",{});var pSt=s(Aue);a1o=r(pSt,"longt5"),pSt.forEach(t),n1o=r(Mje," \u2014 "),VD=n(Mje,"A",{href:!0});var _St=s(VD);s1o=r(_St,"LongT5Config"),_St.forEach(t),l1o=r(Mje," (LongT5 model)"),Mje.forEach(t),i1o=i(L),gh=n(L,"LI",{});var Eje=s(gh);Lue=n(Eje,"STRONG",{});var bSt=s(Lue);d1o=r(bSt,"luke"),bSt.forEach(t),m1o=r(Eje," \u2014 "),XD=n(Eje,"A",{href:!0});var vSt=s(XD);c1o=r(vSt,"LukeConfig"),vSt.forEach(t),f1o=r(Eje," (LUKE model)"),Eje.forEach(t),g1o=i(L),hh=n(L,"LI",{});var Cje=s(hh);yue=n(Cje,"STRONG",{});var FSt=s(yue);h1o=r(FSt,"lxmert"),FSt.forEach(t),u1o=r(Cje," \u2014 "),zD=n(Cje,"A",{href:!0});var TSt=s(zD);p1o=r(TSt,"LxmertConfig"),TSt.forEach(t),_1o=r(Cje," (LXMERT model)"),Cje.forEach(t),b1o=i(L),uh=n(L,"LI",{});var wje=s(uh);xue=n(wje,"STRONG",{});var MSt=s(xue);v1o=r(MSt,"m2m_100"),MSt.forEach(t),F1o=r(wje," \u2014 "),QD=n(wje,"A",{href:!0});var ESt=s(QD);T1o=r(ESt,"M2M100Config"),ESt.forEach(t),M1o=r(wje," (M2M100 model)"),wje.forEach(t),E1o=i(L),ph=n(L,"LI",{});var Aje=s(ph);$ue=n(Aje,"STRONG",{});var CSt=s($ue);C1o=r(CSt,"marian"),CSt.forEach(t),w1o=r(Aje," \u2014 "),WD=n(Aje,"A",{href:!0});var wSt=s(WD);A1o=r(wSt,"MarianConfig"),wSt.forEach(t),L1o=r(Aje," (Marian model)"),Aje.forEach(t),y1o=i(L),_h=n(L,"LI",{});var Lje=s(_h);kue=n(Lje,"STRONG",{});var ASt=s(kue);x1o=r(ASt,"markuplm"),ASt.forEach(t),$1o=r(Lje," \u2014 "),UD=n(Lje,"A",{href:!0});var LSt=s(UD);k1o=r(LSt,"MarkupLMConfig"),LSt.forEach(t),S1o=r(Lje," (MarkupLM model)"),Lje.forEach(t),R1o=i(L),bh=n(L,"LI",{});var yje=s(bh);Sue=n(yje,"STRONG",{});var ySt=s(Sue);P1o=r(ySt,"maskformer"),ySt.forEach(t),B1o=r(yje," \u2014 "),HD=n(yje,"A",{href:!0});var xSt=s(HD);I1o=r(xSt,"MaskFormerConfig"),xSt.forEach(t),N1o=r(yje," (MaskFormer model)"),yje.forEach(t),q1o=i(L),vh=n(L,"LI",{});var xje=s(vh);Rue=n(xje,"STRONG",{});var $St=s(Rue);D1o=r($St,"mbart"),$St.forEach(t),j1o=r(xje," \u2014 "),JD=n(xje,"A",{href:!0});var kSt=s(JD);G1o=r(kSt,"MBartConfig"),kSt.forEach(t),O1o=r(xje," (mBART model)"),xje.forEach(t),V1o=i(L),Fh=n(L,"LI",{});var $je=s(Fh);Pue=n($je,"STRONG",{});var SSt=s(Pue);X1o=r(SSt,"mctct"),SSt.forEach(t),z1o=r($je," \u2014 "),YD=n($je,"A",{href:!0});var RSt=s(YD);Q1o=r(RSt,"MCTCTConfig"),RSt.forEach(t),W1o=r($je," (M-CTC-T model)"),$je.forEach(t),U1o=i(L),Th=n(L,"LI",{});var kje=s(Th);Bue=n(kje,"STRONG",{});var PSt=s(Bue);H1o=r(PSt,"megatron-bert"),PSt.forEach(t),J1o=r(kje," \u2014 "),ZD=n(kje,"A",{href:!0});var BSt=s(ZD);Y1o=r(BSt,"MegatronBertConfig"),BSt.forEach(t),Z1o=r(kje," (Megatron-BERT model)"),kje.forEach(t),K1o=i(L),Mh=n(L,"LI",{});var Sje=s(Mh);Iue=n(Sje,"STRONG",{});var ISt=s(Iue);e2o=r(ISt,"mobilebert"),ISt.forEach(t),o2o=r(Sje," \u2014 "),KD=n(Sje,"A",{href:!0});var NSt=s(KD);r2o=r(NSt,"MobileBertConfig"),NSt.forEach(t),t2o=r(Sje," (MobileBERT model)"),Sje.forEach(t),a2o=i(L),Eh=n(L,"LI",{});var Rje=s(Eh);Nue=n(Rje,"STRONG",{});var qSt=s(Nue);n2o=r(qSt,"mobilevit"),qSt.forEach(t),s2o=r(Rje," \u2014 "),ej=n(Rje,"A",{href:!0});var DSt=s(ej);l2o=r(DSt,"MobileViTConfig"),DSt.forEach(t),i2o=r(Rje," (MobileViT model)"),Rje.forEach(t),d2o=i(L),Ch=n(L,"LI",{});var Pje=s(Ch);que=n(Pje,"STRONG",{});var jSt=s(que);m2o=r(jSt,"mpnet"),jSt.forEach(t),c2o=r(Pje," \u2014 "),oj=n(Pje,"A",{href:!0});var GSt=s(oj);f2o=r(GSt,"MPNetConfig"),GSt.forEach(t),g2o=r(Pje," (MPNet model)"),Pje.forEach(t),h2o=i(L),wh=n(L,"LI",{});var Bje=s(wh);Due=n(Bje,"STRONG",{});var OSt=s(Due);u2o=r(OSt,"mt5"),OSt.forEach(t),p2o=r(Bje," \u2014 "),rj=n(Bje,"A",{href:!0});var VSt=s(rj);_2o=r(VSt,"MT5Config"),VSt.forEach(t),b2o=r(Bje," (MT5 model)"),Bje.forEach(t),v2o=i(L),Ah=n(L,"LI",{});var Ije=s(Ah);jue=n(Ije,"STRONG",{});var XSt=s(jue);F2o=r(XSt,"mvp"),XSt.forEach(t),T2o=r(Ije," \u2014 "),tj=n(Ije,"A",{href:!0});var zSt=s(tj);M2o=r(zSt,"MvpConfig"),zSt.forEach(t),E2o=r(Ije," (MVP model)"),Ije.forEach(t),C2o=i(L),Lh=n(L,"LI",{});var Nje=s(Lh);Gue=n(Nje,"STRONG",{});var QSt=s(Gue);w2o=r(QSt,"nezha"),QSt.forEach(t),A2o=r(Nje," \u2014 "),aj=n(Nje,"A",{href:!0});var WSt=s(aj);L2o=r(WSt,"NezhaConfig"),WSt.forEach(t),y2o=r(Nje," (Nezha model)"),Nje.forEach(t),x2o=i(L),yh=n(L,"LI",{});var qje=s(yh);Oue=n(qje,"STRONG",{});var USt=s(Oue);$2o=r(USt,"nystromformer"),USt.forEach(t),k2o=r(qje," \u2014 "),nj=n(qje,"A",{href:!0});var HSt=s(nj);S2o=r(HSt,"NystromformerConfig"),HSt.forEach(t),R2o=r(qje," (Nystr\xF6mformer model)"),qje.forEach(t),P2o=i(L),xh=n(L,"LI",{});var Dje=s(xh);Vue=n(Dje,"STRONG",{});var JSt=s(Vue);B2o=r(JSt,"openai-gpt"),JSt.forEach(t),I2o=r(Dje," \u2014 "),sj=n(Dje,"A",{href:!0});var YSt=s(sj);N2o=r(YSt,"OpenAIGPTConfig"),YSt.forEach(t),q2o=r(Dje," (OpenAI GPT model)"),Dje.forEach(t),D2o=i(L),$h=n(L,"LI",{});var jje=s($h);Xue=n(jje,"STRONG",{});var ZSt=s(Xue);j2o=r(ZSt,"opt"),ZSt.forEach(t),G2o=r(jje," \u2014 "),lj=n(jje,"A",{href:!0});var KSt=s(lj);O2o=r(KSt,"OPTConfig"),KSt.forEach(t),V2o=r(jje," (OPT model)"),jje.forEach(t),X2o=i(L),kh=n(L,"LI",{});var Gje=s(kh);zue=n(Gje,"STRONG",{});var eRt=s(zue);z2o=r(eRt,"owlvit"),eRt.forEach(t),Q2o=r(Gje," \u2014 "),ij=n(Gje,"A",{href:!0});var oRt=s(ij);W2o=r(oRt,"OwlViTConfig"),oRt.forEach(t),U2o=r(Gje," (OWL-ViT model)"),Gje.forEach(t),H2o=i(L),Sh=n(L,"LI",{});var Oje=s(Sh);Que=n(Oje,"STRONG",{});var rRt=s(Que);J2o=r(rRt,"pegasus"),rRt.forEach(t),Y2o=r(Oje," \u2014 "),dj=n(Oje,"A",{href:!0});var tRt=s(dj);Z2o=r(tRt,"PegasusConfig"),tRt.forEach(t),K2o=r(Oje," (Pegasus model)"),Oje.forEach(t),ebo=i(L),Rh=n(L,"LI",{});var Vje=s(Rh);Wue=n(Vje,"STRONG",{});var aRt=s(Wue);obo=r(aRt,"pegasus_x"),aRt.forEach(t),rbo=r(Vje," \u2014 "),mj=n(Vje,"A",{href:!0});var nRt=s(mj);tbo=r(nRt,"PegasusXConfig"),nRt.forEach(t),abo=r(Vje," (PEGASUS-X model)"),Vje.forEach(t),nbo=i(L),Ph=n(L,"LI",{});var Xje=s(Ph);Uue=n(Xje,"STRONG",{});var sRt=s(Uue);sbo=r(sRt,"perceiver"),sRt.forEach(t),lbo=r(Xje," \u2014 "),cj=n(Xje,"A",{href:!0});var lRt=s(cj);ibo=r(lRt,"PerceiverConfig"),lRt.forEach(t),dbo=r(Xje," (Perceiver model)"),Xje.forEach(t),mbo=i(L),Bh=n(L,"LI",{});var zje=s(Bh);Hue=n(zje,"STRONG",{});var iRt=s(Hue);cbo=r(iRt,"plbart"),iRt.forEach(t),fbo=r(zje," \u2014 "),fj=n(zje,"A",{href:!0});var dRt=s(fj);gbo=r(dRt,"PLBartConfig"),dRt.forEach(t),hbo=r(zje," (PLBart model)"),zje.forEach(t),ubo=i(L),Ih=n(L,"LI",{});var Qje=s(Ih);Jue=n(Qje,"STRONG",{});var mRt=s(Jue);pbo=r(mRt,"poolformer"),mRt.forEach(t),_bo=r(Qje," \u2014 "),gj=n(Qje,"A",{href:!0});var cRt=s(gj);bbo=r(cRt,"PoolFormerConfig"),cRt.forEach(t),vbo=r(Qje," (PoolFormer model)"),Qje.forEach(t),Fbo=i(L),Nh=n(L,"LI",{});var Wje=s(Nh);Yue=n(Wje,"STRONG",{});var fRt=s(Yue);Tbo=r(fRt,"prophetnet"),fRt.forEach(t),Mbo=r(Wje," \u2014 "),hj=n(Wje,"A",{href:!0});var gRt=s(hj);Ebo=r(gRt,"ProphetNetConfig"),gRt.forEach(t),Cbo=r(Wje," (ProphetNet model)"),Wje.forEach(t),wbo=i(L),qh=n(L,"LI",{});var Uje=s(qh);Zue=n(Uje,"STRONG",{});var hRt=s(Zue);Abo=r(hRt,"qdqbert"),hRt.forEach(t),Lbo=r(Uje," \u2014 "),uj=n(Uje,"A",{href:!0});var uRt=s(uj);ybo=r(uRt,"QDQBertConfig"),uRt.forEach(t),xbo=r(Uje," (QDQBert model)"),Uje.forEach(t),$bo=i(L),Dh=n(L,"LI",{});var Hje=s(Dh);Kue=n(Hje,"STRONG",{});var pRt=s(Kue);kbo=r(pRt,"rag"),pRt.forEach(t),Sbo=r(Hje," \u2014 "),pj=n(Hje,"A",{href:!0});var _Rt=s(pj);Rbo=r(_Rt,"RagConfig"),_Rt.forEach(t),Pbo=r(Hje," (RAG model)"),Hje.forEach(t),Bbo=i(L),jh=n(L,"LI",{});var Jje=s(jh);epe=n(Jje,"STRONG",{});var bRt=s(epe);Ibo=r(bRt,"realm"),bRt.forEach(t),Nbo=r(Jje," \u2014 "),_j=n(Jje,"A",{href:!0});var vRt=s(_j);qbo=r(vRt,"RealmConfig"),vRt.forEach(t),Dbo=r(Jje," (REALM model)"),Jje.forEach(t),jbo=i(L),Gh=n(L,"LI",{});var Yje=s(Gh);ope=n(Yje,"STRONG",{});var FRt=s(ope);Gbo=r(FRt,"reformer"),FRt.forEach(t),Obo=r(Yje," \u2014 "),bj=n(Yje,"A",{href:!0});var TRt=s(bj);Vbo=r(TRt,"ReformerConfig"),TRt.forEach(t),Xbo=r(Yje," (Reformer model)"),Yje.forEach(t),zbo=i(L),Oh=n(L,"LI",{});var Zje=s(Oh);rpe=n(Zje,"STRONG",{});var MRt=s(rpe);Qbo=r(MRt,"regnet"),MRt.forEach(t),Wbo=r(Zje," \u2014 "),vj=n(Zje,"A",{href:!0});var ERt=s(vj);Ubo=r(ERt,"RegNetConfig"),ERt.forEach(t),Hbo=r(Zje," (RegNet model)"),Zje.forEach(t),Jbo=i(L),Vh=n(L,"LI",{});var Kje=s(Vh);tpe=n(Kje,"STRONG",{});var CRt=s(tpe);Ybo=r(CRt,"rembert"),CRt.forEach(t),Zbo=r(Kje," \u2014 "),Fj=n(Kje,"A",{href:!0});var wRt=s(Fj);Kbo=r(wRt,"RemBertConfig"),wRt.forEach(t),evo=r(Kje," (RemBERT model)"),Kje.forEach(t),ovo=i(L),Xh=n(L,"LI",{});var eGe=s(Xh);ape=n(eGe,"STRONG",{});var ARt=s(ape);rvo=r(ARt,"resnet"),ARt.forEach(t),tvo=r(eGe," \u2014 "),Tj=n(eGe,"A",{href:!0});var LRt=s(Tj);avo=r(LRt,"ResNetConfig"),LRt.forEach(t),nvo=r(eGe," (ResNet model)"),eGe.forEach(t),svo=i(L),zh=n(L,"LI",{});var oGe=s(zh);npe=n(oGe,"STRONG",{});var yRt=s(npe);lvo=r(yRt,"retribert"),yRt.forEach(t),ivo=r(oGe," \u2014 "),Mj=n(oGe,"A",{href:!0});var xRt=s(Mj);dvo=r(xRt,"RetriBertConfig"),xRt.forEach(t),mvo=r(oGe," (RetriBERT model)"),oGe.forEach(t),cvo=i(L),Qh=n(L,"LI",{});var rGe=s(Qh);spe=n(rGe,"STRONG",{});var $Rt=s(spe);fvo=r($Rt,"roberta"),$Rt.forEach(t),gvo=r(rGe," \u2014 "),Ej=n(rGe,"A",{href:!0});var kRt=s(Ej);hvo=r(kRt,"RobertaConfig"),kRt.forEach(t),uvo=r(rGe," (RoBERTa model)"),rGe.forEach(t),pvo=i(L),Wh=n(L,"LI",{});var tGe=s(Wh);lpe=n(tGe,"STRONG",{});var SRt=s(lpe);_vo=r(SRt,"roc_bert"),SRt.forEach(t),bvo=r(tGe," \u2014 "),Cj=n(tGe,"A",{href:!0});var RRt=s(Cj);vvo=r(RRt,"RoCBertConfig"),RRt.forEach(t),Fvo=r(tGe," (RoCBert model)"),tGe.forEach(t),Tvo=i(L),Uh=n(L,"LI",{});var aGe=s(Uh);ipe=n(aGe,"STRONG",{});var PRt=s(ipe);Mvo=r(PRt,"roformer"),PRt.forEach(t),Evo=r(aGe," \u2014 "),wj=n(aGe,"A",{href:!0});var BRt=s(wj);Cvo=r(BRt,"RoFormerConfig"),BRt.forEach(t),wvo=r(aGe," (RoFormer model)"),aGe.forEach(t),Avo=i(L),Hh=n(L,"LI",{});var nGe=s(Hh);dpe=n(nGe,"STRONG",{});var IRt=s(dpe);Lvo=r(IRt,"segformer"),IRt.forEach(t),yvo=r(nGe," \u2014 "),Aj=n(nGe,"A",{href:!0});var NRt=s(Aj);xvo=r(NRt,"SegformerConfig"),NRt.forEach(t),$vo=r(nGe," (SegFormer model)"),nGe.forEach(t),kvo=i(L),Jh=n(L,"LI",{});var sGe=s(Jh);mpe=n(sGe,"STRONG",{});var qRt=s(mpe);Svo=r(qRt,"sew"),qRt.forEach(t),Rvo=r(sGe," \u2014 "),Lj=n(sGe,"A",{href:!0});var DRt=s(Lj);Pvo=r(DRt,"SEWConfig"),DRt.forEach(t),Bvo=r(sGe," (SEW model)"),sGe.forEach(t),Ivo=i(L),Yh=n(L,"LI",{});var lGe=s(Yh);cpe=n(lGe,"STRONG",{});var jRt=s(cpe);Nvo=r(jRt,"sew-d"),jRt.forEach(t),qvo=r(lGe," \u2014 "),yj=n(lGe,"A",{href:!0});var GRt=s(yj);Dvo=r(GRt,"SEWDConfig"),GRt.forEach(t),jvo=r(lGe," (SEW-D model)"),lGe.forEach(t),Gvo=i(L),Zh=n(L,"LI",{});var iGe=s(Zh);fpe=n(iGe,"STRONG",{});var ORt=s(fpe);Ovo=r(ORt,"speech-encoder-decoder"),ORt.forEach(t),Vvo=r(iGe," \u2014 "),xj=n(iGe,"A",{href:!0});var VRt=s(xj);Xvo=r(VRt,"SpeechEncoderDecoderConfig"),VRt.forEach(t),zvo=r(iGe," (Speech Encoder decoder model)"),iGe.forEach(t),Qvo=i(L),Kh=n(L,"LI",{});var dGe=s(Kh);gpe=n(dGe,"STRONG",{});var XRt=s(gpe);Wvo=r(XRt,"speech_to_text"),XRt.forEach(t),Uvo=r(dGe," \u2014 "),$j=n(dGe,"A",{href:!0});var zRt=s($j);Hvo=r(zRt,"Speech2TextConfig"),zRt.forEach(t),Jvo=r(dGe," (Speech2Text model)"),dGe.forEach(t),Yvo=i(L),eu=n(L,"LI",{});var mGe=s(eu);hpe=n(mGe,"STRONG",{});var QRt=s(hpe);Zvo=r(QRt,"speech_to_text_2"),QRt.forEach(t),Kvo=r(mGe," \u2014 "),kj=n(mGe,"A",{href:!0});var WRt=s(kj);eFo=r(WRt,"Speech2Text2Config"),WRt.forEach(t),oFo=r(mGe," (Speech2Text2 model)"),mGe.forEach(t),rFo=i(L),ou=n(L,"LI",{});var cGe=s(ou);upe=n(cGe,"STRONG",{});var URt=s(upe);tFo=r(URt,"splinter"),URt.forEach(t),aFo=r(cGe," \u2014 "),Sj=n(cGe,"A",{href:!0});var HRt=s(Sj);nFo=r(HRt,"SplinterConfig"),HRt.forEach(t),sFo=r(cGe," (Splinter model)"),cGe.forEach(t),lFo=i(L),ru=n(L,"LI",{});var fGe=s(ru);ppe=n(fGe,"STRONG",{});var JRt=s(ppe);iFo=r(JRt,"squeezebert"),JRt.forEach(t),dFo=r(fGe," \u2014 "),Rj=n(fGe,"A",{href:!0});var YRt=s(Rj);mFo=r(YRt,"SqueezeBertConfig"),YRt.forEach(t),cFo=r(fGe," (SqueezeBERT model)"),fGe.forEach(t),fFo=i(L),tu=n(L,"LI",{});var gGe=s(tu);_pe=n(gGe,"STRONG",{});var ZRt=s(_pe);gFo=r(ZRt,"swin"),ZRt.forEach(t),hFo=r(gGe," \u2014 "),Pj=n(gGe,"A",{href:!0});var KRt=s(Pj);uFo=r(KRt,"SwinConfig"),KRt.forEach(t),pFo=r(gGe," (Swin Transformer model)"),gGe.forEach(t),_Fo=i(L),au=n(L,"LI",{});var hGe=s(au);bpe=n(hGe,"STRONG",{});var ePt=s(bpe);bFo=r(ePt,"swinv2"),ePt.forEach(t),vFo=r(hGe," \u2014 "),Bj=n(hGe,"A",{href:!0});var oPt=s(Bj);FFo=r(oPt,"Swinv2Config"),oPt.forEach(t),TFo=r(hGe," (Swin Transformer V2 model)"),hGe.forEach(t),MFo=i(L),nu=n(L,"LI",{});var uGe=s(nu);vpe=n(uGe,"STRONG",{});var rPt=s(vpe);EFo=r(rPt,"t5"),rPt.forEach(t),CFo=r(uGe," \u2014 "),Ij=n(uGe,"A",{href:!0});var tPt=s(Ij);wFo=r(tPt,"T5Config"),tPt.forEach(t),AFo=r(uGe," (T5 model)"),uGe.forEach(t),LFo=i(L),su=n(L,"LI",{});var pGe=s(su);Fpe=n(pGe,"STRONG",{});var aPt=s(Fpe);yFo=r(aPt,"table-transformer"),aPt.forEach(t),xFo=r(pGe," \u2014 "),Nj=n(pGe,"A",{href:!0});var nPt=s(Nj);$Fo=r(nPt,"TableTransformerConfig"),nPt.forEach(t),kFo=r(pGe," (Table Transformer model)"),pGe.forEach(t),SFo=i(L),lu=n(L,"LI",{});var _Ge=s(lu);Tpe=n(_Ge,"STRONG",{});var sPt=s(Tpe);RFo=r(sPt,"tapas"),sPt.forEach(t),PFo=r(_Ge," \u2014 "),qj=n(_Ge,"A",{href:!0});var lPt=s(qj);BFo=r(lPt,"TapasConfig"),lPt.forEach(t),IFo=r(_Ge," (TAPAS model)"),_Ge.forEach(t),NFo=i(L),iu=n(L,"LI",{});var bGe=s(iu);Mpe=n(bGe,"STRONG",{});var iPt=s(Mpe);qFo=r(iPt,"time_series_transformer"),iPt.forEach(t),DFo=r(bGe," \u2014 "),Dj=n(bGe,"A",{href:!0});var dPt=s(Dj);jFo=r(dPt,"TimeSeriesTransformerConfig"),dPt.forEach(t),GFo=r(bGe," (Time Series Transformer model)"),bGe.forEach(t),OFo=i(L),du=n(L,"LI",{});var vGe=s(du);Epe=n(vGe,"STRONG",{});var mPt=s(Epe);VFo=r(mPt,"trajectory_transformer"),mPt.forEach(t),XFo=r(vGe," \u2014 "),jj=n(vGe,"A",{href:!0});var cPt=s(jj);zFo=r(cPt,"TrajectoryTransformerConfig"),cPt.forEach(t),QFo=r(vGe," (Trajectory Transformer model)"),vGe.forEach(t),WFo=i(L),mu=n(L,"LI",{});var FGe=s(mu);Cpe=n(FGe,"STRONG",{});var fPt=s(Cpe);UFo=r(fPt,"transfo-xl"),fPt.forEach(t),HFo=r(FGe," \u2014 "),Gj=n(FGe,"A",{href:!0});var gPt=s(Gj);JFo=r(gPt,"TransfoXLConfig"),gPt.forEach(t),YFo=r(FGe," (Transformer-XL model)"),FGe.forEach(t),ZFo=i(L),cu=n(L,"LI",{});var TGe=s(cu);wpe=n(TGe,"STRONG",{});var hPt=s(wpe);KFo=r(hPt,"trocr"),hPt.forEach(t),eTo=r(TGe," \u2014 "),Oj=n(TGe,"A",{href:!0});var uPt=s(Oj);oTo=r(uPt,"TrOCRConfig"),uPt.forEach(t),rTo=r(TGe," (TrOCR model)"),TGe.forEach(t),tTo=i(L),fu=n(L,"LI",{});var MGe=s(fu);Ape=n(MGe,"STRONG",{});var pPt=s(Ape);aTo=r(pPt,"unispeech"),pPt.forEach(t),nTo=r(MGe," \u2014 "),Vj=n(MGe,"A",{href:!0});var _Pt=s(Vj);sTo=r(_Pt,"UniSpeechConfig"),_Pt.forEach(t),lTo=r(MGe," (UniSpeech model)"),MGe.forEach(t),iTo=i(L),gu=n(L,"LI",{});var EGe=s(gu);Lpe=n(EGe,"STRONG",{});var bPt=s(Lpe);dTo=r(bPt,"unispeech-sat"),bPt.forEach(t),mTo=r(EGe," \u2014 "),Xj=n(EGe,"A",{href:!0});var vPt=s(Xj);cTo=r(vPt,"UniSpeechSatConfig"),vPt.forEach(t),fTo=r(EGe," (UniSpeechSat model)"),EGe.forEach(t),gTo=i(L),hu=n(L,"LI",{});var CGe=s(hu);ype=n(CGe,"STRONG",{});var FPt=s(ype);hTo=r(FPt,"van"),FPt.forEach(t),uTo=r(CGe," \u2014 "),zj=n(CGe,"A",{href:!0});var TPt=s(zj);pTo=r(TPt,"VanConfig"),TPt.forEach(t),_To=r(CGe," (VAN model)"),CGe.forEach(t),bTo=i(L),uu=n(L,"LI",{});var wGe=s(uu);xpe=n(wGe,"STRONG",{});var MPt=s(xpe);vTo=r(MPt,"videomae"),MPt.forEach(t),FTo=r(wGe," \u2014 "),Qj=n(wGe,"A",{href:!0});var EPt=s(Qj);TTo=r(EPt,"VideoMAEConfig"),EPt.forEach(t),MTo=r(wGe," (VideoMAE model)"),wGe.forEach(t),ETo=i(L),pu=n(L,"LI",{});var AGe=s(pu);$pe=n(AGe,"STRONG",{});var CPt=s($pe);CTo=r(CPt,"vilt"),CPt.forEach(t),wTo=r(AGe," \u2014 "),Wj=n(AGe,"A",{href:!0});var wPt=s(Wj);ATo=r(wPt,"ViltConfig"),wPt.forEach(t),LTo=r(AGe," (ViLT model)"),AGe.forEach(t),yTo=i(L),_u=n(L,"LI",{});var LGe=s(_u);kpe=n(LGe,"STRONG",{});var APt=s(kpe);xTo=r(APt,"vision-encoder-decoder"),APt.forEach(t),$To=r(LGe," \u2014 "),Uj=n(LGe,"A",{href:!0});var LPt=s(Uj);kTo=r(LPt,"VisionEncoderDecoderConfig"),LPt.forEach(t),STo=r(LGe," (Vision Encoder decoder model)"),LGe.forEach(t),RTo=i(L),bu=n(L,"LI",{});var yGe=s(bu);Spe=n(yGe,"STRONG",{});var yPt=s(Spe);PTo=r(yPt,"vision-text-dual-encoder"),yPt.forEach(t),BTo=r(yGe," \u2014 "),Hj=n(yGe,"A",{href:!0});var xPt=s(Hj);ITo=r(xPt,"VisionTextDualEncoderConfig"),xPt.forEach(t),NTo=r(yGe," (VisionTextDualEncoder model)"),yGe.forEach(t),qTo=i(L),vu=n(L,"LI",{});var xGe=s(vu);Rpe=n(xGe,"STRONG",{});var $Pt=s(Rpe);DTo=r($Pt,"visual_bert"),$Pt.forEach(t),jTo=r(xGe," \u2014 "),Jj=n(xGe,"A",{href:!0});var kPt=s(Jj);GTo=r(kPt,"VisualBertConfig"),kPt.forEach(t),OTo=r(xGe," (VisualBERT model)"),xGe.forEach(t),VTo=i(L),Fu=n(L,"LI",{});var $Ge=s(Fu);Ppe=n($Ge,"STRONG",{});var SPt=s(Ppe);XTo=r(SPt,"vit"),SPt.forEach(t),zTo=r($Ge," \u2014 "),Yj=n($Ge,"A",{href:!0});var RPt=s(Yj);QTo=r(RPt,"ViTConfig"),RPt.forEach(t),WTo=r($Ge," (ViT model)"),$Ge.forEach(t),UTo=i(L),Tu=n(L,"LI",{});var kGe=s(Tu);Bpe=n(kGe,"STRONG",{});var PPt=s(Bpe);HTo=r(PPt,"vit_mae"),PPt.forEach(t),JTo=r(kGe," \u2014 "),Zj=n(kGe,"A",{href:!0});var BPt=s(Zj);YTo=r(BPt,"ViTMAEConfig"),BPt.forEach(t),ZTo=r(kGe," (ViTMAE model)"),kGe.forEach(t),KTo=i(L),Mu=n(L,"LI",{});var SGe=s(Mu);Ipe=n(SGe,"STRONG",{});var IPt=s(Ipe);eMo=r(IPt,"vit_msn"),IPt.forEach(t),oMo=r(SGe," \u2014 "),Kj=n(SGe,"A",{href:!0});var NPt=s(Kj);rMo=r(NPt,"ViTMSNConfig"),NPt.forEach(t),tMo=r(SGe," (ViTMSN model)"),SGe.forEach(t),aMo=i(L),Eu=n(L,"LI",{});var RGe=s(Eu);Npe=n(RGe,"STRONG",{});var qPt=s(Npe);nMo=r(qPt,"wav2vec2"),qPt.forEach(t),sMo=r(RGe," \u2014 "),eG=n(RGe,"A",{href:!0});var DPt=s(eG);lMo=r(DPt,"Wav2Vec2Config"),DPt.forEach(t),iMo=r(RGe," (Wav2Vec2 model)"),RGe.forEach(t),dMo=i(L),Cu=n(L,"LI",{});var PGe=s(Cu);qpe=n(PGe,"STRONG",{});var jPt=s(qpe);mMo=r(jPt,"wav2vec2-conformer"),jPt.forEach(t),cMo=r(PGe," \u2014 "),oG=n(PGe,"A",{href:!0});var GPt=s(oG);fMo=r(GPt,"Wav2Vec2ConformerConfig"),GPt.forEach(t),gMo=r(PGe," (Wav2Vec2-Conformer model)"),PGe.forEach(t),hMo=i(L),wu=n(L,"LI",{});var BGe=s(wu);Dpe=n(BGe,"STRONG",{});var OPt=s(Dpe);uMo=r(OPt,"wavlm"),OPt.forEach(t),pMo=r(BGe," \u2014 "),rG=n(BGe,"A",{href:!0});var VPt=s(rG);_Mo=r(VPt,"WavLMConfig"),VPt.forEach(t),bMo=r(BGe," (WavLM model)"),BGe.forEach(t),vMo=i(L),Au=n(L,"LI",{});var IGe=s(Au);jpe=n(IGe,"STRONG",{});var XPt=s(jpe);FMo=r(XPt,"whisper"),XPt.forEach(t),TMo=r(IGe," \u2014 "),tG=n(IGe,"A",{href:!0});var zPt=s(tG);MMo=r(zPt,"WhisperConfig"),zPt.forEach(t),EMo=r(IGe," (Whisper model)"),IGe.forEach(t),CMo=i(L),Lu=n(L,"LI",{});var NGe=s(Lu);Gpe=n(NGe,"STRONG",{});var QPt=s(Gpe);wMo=r(QPt,"xclip"),QPt.forEach(t),AMo=r(NGe," \u2014 "),aG=n(NGe,"A",{href:!0});var WPt=s(aG);LMo=r(WPt,"XCLIPConfig"),WPt.forEach(t),yMo=r(NGe," (X-CLIP model)"),NGe.forEach(t),xMo=i(L),yu=n(L,"LI",{});var qGe=s(yu);Ope=n(qGe,"STRONG",{});var UPt=s(Ope);$Mo=r(UPt,"xglm"),UPt.forEach(t),kMo=r(qGe," \u2014 "),nG=n(qGe,"A",{href:!0});var HPt=s(nG);SMo=r(HPt,"XGLMConfig"),HPt.forEach(t),RMo=r(qGe," (XGLM model)"),qGe.forEach(t),PMo=i(L),xu=n(L,"LI",{});var DGe=s(xu);Vpe=n(DGe,"STRONG",{});var JPt=s(Vpe);BMo=r(JPt,"xlm"),JPt.forEach(t),IMo=r(DGe," \u2014 "),sG=n(DGe,"A",{href:!0});var YPt=s(sG);NMo=r(YPt,"XLMConfig"),YPt.forEach(t),qMo=r(DGe," (XLM model)"),DGe.forEach(t),DMo=i(L),$u=n(L,"LI",{});var jGe=s($u);Xpe=n(jGe,"STRONG",{});var ZPt=s(Xpe);jMo=r(ZPt,"xlm-prophetnet"),ZPt.forEach(t),GMo=r(jGe," \u2014 "),lG=n(jGe,"A",{href:!0});var KPt=s(lG);OMo=r(KPt,"XLMProphetNetConfig"),KPt.forEach(t),VMo=r(jGe," (XLM-ProphetNet model)"),jGe.forEach(t),XMo=i(L),ku=n(L,"LI",{});var GGe=s(ku);zpe=n(GGe,"STRONG",{});var eBt=s(zpe);zMo=r(eBt,"xlm-roberta"),eBt.forEach(t),QMo=r(GGe," \u2014 "),iG=n(GGe,"A",{href:!0});var oBt=s(iG);WMo=r(oBt,"XLMRobertaConfig"),oBt.forEach(t),UMo=r(GGe," (XLM-RoBERTa model)"),GGe.forEach(t),HMo=i(L),Su=n(L,"LI",{});var OGe=s(Su);Qpe=n(OGe,"STRONG",{});var rBt=s(Qpe);JMo=r(rBt,"xlm-roberta-xl"),rBt.forEach(t),YMo=r(OGe," \u2014 "),dG=n(OGe,"A",{href:!0});var tBt=s(dG);ZMo=r(tBt,"XLMRobertaXLConfig"),tBt.forEach(t),KMo=r(OGe," (XLM-RoBERTa-XL model)"),OGe.forEach(t),eEo=i(L),Ru=n(L,"LI",{});var VGe=s(Ru);Wpe=n(VGe,"STRONG",{});var aBt=s(Wpe);oEo=r(aBt,"xlnet"),aBt.forEach(t),rEo=r(VGe," \u2014 "),mG=n(VGe,"A",{href:!0});var nBt=s(mG);tEo=r(nBt,"XLNetConfig"),nBt.forEach(t),aEo=r(VGe," (XLNet model)"),VGe.forEach(t),nEo=i(L),Pu=n(L,"LI",{});var XGe=s(Pu);Upe=n(XGe,"STRONG",{});var sBt=s(Upe);sEo=r(sBt,"yolos"),sBt.forEach(t),lEo=r(XGe," \u2014 "),cG=n(XGe,"A",{href:!0});var lBt=s(cG);iEo=r(lBt,"YolosConfig"),lBt.forEach(t),dEo=r(XGe," (YOLOS model)"),XGe.forEach(t),mEo=i(L),Bu=n(L,"LI",{});var zGe=s(Bu);Hpe=n(zGe,"STRONG",{});var iBt=s(Hpe);cEo=r(iBt,"yoso"),iBt.forEach(t),fEo=r(zGe," \u2014 "),fG=n(zGe,"A",{href:!0});var dBt=s(fG);gEo=r(dBt,"YosoConfig"),dBt.forEach(t),hEo=r(zGe," (YOSO model)"),zGe.forEach(t),L.forEach(t),uEo=i(Ct),T(Iu.$$.fragment,Ct),Ct.forEach(t),pEo=i(Et),Nu=n(Et,"DIV",{class:!0});var Sdo=s(Nu);T(bk.$$.fragment,Sdo),_Eo=i(Sdo),Jpe=n(Sdo,"P",{});var mBt=s(Jpe);bEo=r(mBt,"Register a new configuration for this class."),mBt.forEach(t),Sdo.forEach(t),Et.forEach(t),vlo=i(c),Id=n(c,"H2",{class:!0});var Rdo=s(Id);qu=n(Rdo,"A",{id:!0,class:!0,href:!0});var cBt=s(qu);Ype=n(cBt,"SPAN",{});var fBt=s(Ype);T(vk.$$.fragment,fBt),fBt.forEach(t),cBt.forEach(t),vEo=i(Rdo),Zpe=n(Rdo,"SPAN",{});var gBt=s(Zpe);FEo=r(gBt,"AutoTokenizer"),gBt.forEach(t),Rdo.forEach(t),Flo=i(c),Io=n(c,"DIV",{class:!0});var Gl=s(Io);T(Fk.$$.fragment,Gl),TEo=i(Gl),Tk=n(Gl,"P",{});var Pdo=s(Tk);MEo=r(Pdo,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),gG=n(Pdo,"A",{href:!0});var hBt=s(gG);EEo=r(hBt,"AutoTokenizer.from_pretrained()"),hBt.forEach(t),CEo=r(Pdo," class method."),Pdo.forEach(t),wEo=i(Gl),Mk=n(Gl,"P",{});var Bdo=s(Mk);AEo=r(Bdo,"This class cannot be instantiated directly using "),Kpe=n(Bdo,"CODE",{});var uBt=s(Kpe);LEo=r(uBt,"__init__()"),uBt.forEach(t),yEo=r(Bdo," (throws an error)."),Bdo.forEach(t),xEo=i(Gl),Vr=n(Gl,"DIV",{class:!0});var Ol=s(Vr);T(Ek.$$.fragment,Ol),$Eo=i(Ol),e_e=n(Ol,"P",{});var pBt=s(e_e);kEo=r(pBt,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),pBt.forEach(t),SEo=i(Ol),dn=n(Ol,"P",{});var K9=s(dn);REo=r(K9,"The tokenizer class to instantiate is selected based on the "),o_e=n(K9,"CODE",{});var _Bt=s(o_e);PEo=r(_Bt,"model_type"),_Bt.forEach(t),BEo=r(K9,` property of the config object (either
passed as an argument or loaded from `),r_e=n(K9,"CODE",{});var bBt=s(r_e);IEo=r(bBt,"pretrained_model_name_or_path"),bBt.forEach(t),NEo=r(K9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t_e=n(K9,"CODE",{});var vBt=s(t_e);qEo=r(vBt,"pretrained_model_name_or_path"),vBt.forEach(t),DEo=r(K9,":"),K9.forEach(t),jEo=i(Ol),k=n(Ol,"UL",{});var S=s(k);Ts=n(S,"LI",{});var cN=s(Ts);a_e=n(cN,"STRONG",{});var FBt=s(a_e);GEo=r(FBt,"albert"),FBt.forEach(t),OEo=r(cN," \u2014 "),hG=n(cN,"A",{href:!0});var TBt=s(hG);VEo=r(TBt,"AlbertTokenizer"),TBt.forEach(t),XEo=r(cN," or "),uG=n(cN,"A",{href:!0});var MBt=s(uG);zEo=r(MBt,"AlbertTokenizerFast"),MBt.forEach(t),QEo=r(cN," (ALBERT model)"),cN.forEach(t),WEo=i(S),Ms=n(S,"LI",{});var fN=s(Ms);n_e=n(fN,"STRONG",{});var EBt=s(n_e);UEo=r(EBt,"bart"),EBt.forEach(t),HEo=r(fN," \u2014 "),pG=n(fN,"A",{href:!0});var CBt=s(pG);JEo=r(CBt,"BartTokenizer"),CBt.forEach(t),YEo=r(fN," or "),_G=n(fN,"A",{href:!0});var wBt=s(_G);ZEo=r(wBt,"BartTokenizerFast"),wBt.forEach(t),KEo=r(fN," (BART model)"),fN.forEach(t),e4o=i(S),Es=n(S,"LI",{});var gN=s(Es);s_e=n(gN,"STRONG",{});var ABt=s(s_e);o4o=r(ABt,"barthez"),ABt.forEach(t),r4o=r(gN," \u2014 "),bG=n(gN,"A",{href:!0});var LBt=s(bG);t4o=r(LBt,"BarthezTokenizer"),LBt.forEach(t),a4o=r(gN," or "),vG=n(gN,"A",{href:!0});var yBt=s(vG);n4o=r(yBt,"BarthezTokenizerFast"),yBt.forEach(t),s4o=r(gN," (BARThez model)"),gN.forEach(t),l4o=i(S),Du=n(S,"LI",{});var QGe=s(Du);l_e=n(QGe,"STRONG",{});var xBt=s(l_e);i4o=r(xBt,"bartpho"),xBt.forEach(t),d4o=r(QGe," \u2014 "),FG=n(QGe,"A",{href:!0});var $Bt=s(FG);m4o=r($Bt,"BartphoTokenizer"),$Bt.forEach(t),c4o=r(QGe," (BARTpho model)"),QGe.forEach(t),f4o=i(S),Cs=n(S,"LI",{});var hN=s(Cs);i_e=n(hN,"STRONG",{});var kBt=s(i_e);g4o=r(kBt,"bert"),kBt.forEach(t),h4o=r(hN," \u2014 "),TG=n(hN,"A",{href:!0});var SBt=s(TG);u4o=r(SBt,"BertTokenizer"),SBt.forEach(t),p4o=r(hN," or "),MG=n(hN,"A",{href:!0});var RBt=s(MG);_4o=r(RBt,"BertTokenizerFast"),RBt.forEach(t),b4o=r(hN," (BERT model)"),hN.forEach(t),v4o=i(S),ju=n(S,"LI",{});var WGe=s(ju);d_e=n(WGe,"STRONG",{});var PBt=s(d_e);F4o=r(PBt,"bert-generation"),PBt.forEach(t),T4o=r(WGe," \u2014 "),EG=n(WGe,"A",{href:!0});var BBt=s(EG);M4o=r(BBt,"BertGenerationTokenizer"),BBt.forEach(t),E4o=r(WGe," (Bert Generation model)"),WGe.forEach(t),C4o=i(S),Gu=n(S,"LI",{});var UGe=s(Gu);m_e=n(UGe,"STRONG",{});var IBt=s(m_e);w4o=r(IBt,"bert-japanese"),IBt.forEach(t),A4o=r(UGe," \u2014 "),CG=n(UGe,"A",{href:!0});var NBt=s(CG);L4o=r(NBt,"BertJapaneseTokenizer"),NBt.forEach(t),y4o=r(UGe," (BertJapanese model)"),UGe.forEach(t),x4o=i(S),Ou=n(S,"LI",{});var HGe=s(Ou);c_e=n(HGe,"STRONG",{});var qBt=s(c_e);$4o=r(qBt,"bertweet"),qBt.forEach(t),k4o=r(HGe," \u2014 "),wG=n(HGe,"A",{href:!0});var DBt=s(wG);S4o=r(DBt,"BertweetTokenizer"),DBt.forEach(t),R4o=r(HGe," (BERTweet model)"),HGe.forEach(t),P4o=i(S),ws=n(S,"LI",{});var uN=s(ws);f_e=n(uN,"STRONG",{});var jBt=s(f_e);B4o=r(jBt,"big_bird"),jBt.forEach(t),I4o=r(uN," \u2014 "),AG=n(uN,"A",{href:!0});var GBt=s(AG);N4o=r(GBt,"BigBirdTokenizer"),GBt.forEach(t),q4o=r(uN," or "),LG=n(uN,"A",{href:!0});var OBt=s(LG);D4o=r(OBt,"BigBirdTokenizerFast"),OBt.forEach(t),j4o=r(uN," (BigBird model)"),uN.forEach(t),G4o=i(S),As=n(S,"LI",{});var pN=s(As);g_e=n(pN,"STRONG",{});var VBt=s(g_e);O4o=r(VBt,"bigbird_pegasus"),VBt.forEach(t),V4o=r(pN," \u2014 "),yG=n(pN,"A",{href:!0});var XBt=s(yG);X4o=r(XBt,"PegasusTokenizer"),XBt.forEach(t),z4o=r(pN," or "),xG=n(pN,"A",{href:!0});var zBt=s(xG);Q4o=r(zBt,"PegasusTokenizerFast"),zBt.forEach(t),W4o=r(pN," (BigBird-Pegasus model)"),pN.forEach(t),U4o=i(S),Ls=n(S,"LI",{});var _N=s(Ls);h_e=n(_N,"STRONG",{});var QBt=s(h_e);H4o=r(QBt,"blenderbot"),QBt.forEach(t),J4o=r(_N," \u2014 "),$G=n(_N,"A",{href:!0});var WBt=s($G);Y4o=r(WBt,"BlenderbotTokenizer"),WBt.forEach(t),Z4o=r(_N," or "),kG=n(_N,"A",{href:!0});var UBt=s(kG);K4o=r(UBt,"BlenderbotTokenizerFast"),UBt.forEach(t),eCo=r(_N," (Blenderbot model)"),_N.forEach(t),oCo=i(S),Vu=n(S,"LI",{});var JGe=s(Vu);u_e=n(JGe,"STRONG",{});var HBt=s(u_e);rCo=r(HBt,"blenderbot-small"),HBt.forEach(t),tCo=r(JGe," \u2014 "),SG=n(JGe,"A",{href:!0});var JBt=s(SG);aCo=r(JBt,"BlenderbotSmallTokenizer"),JBt.forEach(t),nCo=r(JGe," (BlenderbotSmall model)"),JGe.forEach(t),sCo=i(S),Xu=n(S,"LI",{});var YGe=s(Xu);p_e=n(YGe,"STRONG",{});var YBt=s(p_e);lCo=r(YBt,"bloom"),YBt.forEach(t),iCo=r(YGe," \u2014 "),RG=n(YGe,"A",{href:!0});var ZBt=s(RG);dCo=r(ZBt,"BloomTokenizerFast"),ZBt.forEach(t),mCo=r(YGe," (BLOOM model)"),YGe.forEach(t),cCo=i(S),zu=n(S,"LI",{});var ZGe=s(zu);__e=n(ZGe,"STRONG",{});var KBt=s(__e);fCo=r(KBt,"byt5"),KBt.forEach(t),gCo=r(ZGe," \u2014 "),PG=n(ZGe,"A",{href:!0});var eIt=s(PG);hCo=r(eIt,"ByT5Tokenizer"),eIt.forEach(t),uCo=r(ZGe," (ByT5 model)"),ZGe.forEach(t),pCo=i(S),ys=n(S,"LI",{});var bN=s(ys);b_e=n(bN,"STRONG",{});var oIt=s(b_e);_Co=r(oIt,"camembert"),oIt.forEach(t),bCo=r(bN," \u2014 "),BG=n(bN,"A",{href:!0});var rIt=s(BG);vCo=r(rIt,"CamembertTokenizer"),rIt.forEach(t),FCo=r(bN," or "),IG=n(bN,"A",{href:!0});var tIt=s(IG);TCo=r(tIt,"CamembertTokenizerFast"),tIt.forEach(t),MCo=r(bN," (CamemBERT model)"),bN.forEach(t),ECo=i(S),Qu=n(S,"LI",{});var KGe=s(Qu);v_e=n(KGe,"STRONG",{});var aIt=s(v_e);CCo=r(aIt,"canine"),aIt.forEach(t),wCo=r(KGe," \u2014 "),NG=n(KGe,"A",{href:!0});var nIt=s(NG);ACo=r(nIt,"CanineTokenizer"),nIt.forEach(t),LCo=r(KGe," (CANINE model)"),KGe.forEach(t),yCo=i(S),xs=n(S,"LI",{});var vN=s(xs);F_e=n(vN,"STRONG",{});var sIt=s(F_e);xCo=r(sIt,"clip"),sIt.forEach(t),$Co=r(vN," \u2014 "),qG=n(vN,"A",{href:!0});var lIt=s(qG);kCo=r(lIt,"CLIPTokenizer"),lIt.forEach(t),SCo=r(vN," or "),DG=n(vN,"A",{href:!0});var iIt=s(DG);RCo=r(iIt,"CLIPTokenizerFast"),iIt.forEach(t),PCo=r(vN," (CLIP model)"),vN.forEach(t),BCo=i(S),$s=n(S,"LI",{});var FN=s($s);T_e=n(FN,"STRONG",{});var dIt=s(T_e);ICo=r(dIt,"clipseg"),dIt.forEach(t),NCo=r(FN," \u2014 "),jG=n(FN,"A",{href:!0});var mIt=s(jG);qCo=r(mIt,"CLIPTokenizer"),mIt.forEach(t),DCo=r(FN," or "),GG=n(FN,"A",{href:!0});var cIt=s(GG);jCo=r(cIt,"CLIPTokenizerFast"),cIt.forEach(t),GCo=r(FN," (CLIPSeg model)"),FN.forEach(t),OCo=i(S),ks=n(S,"LI",{});var TN=s(ks);M_e=n(TN,"STRONG",{});var fIt=s(M_e);VCo=r(fIt,"codegen"),fIt.forEach(t),XCo=r(TN," \u2014 "),OG=n(TN,"A",{href:!0});var gIt=s(OG);zCo=r(gIt,"CodeGenTokenizer"),gIt.forEach(t),QCo=r(TN," or "),VG=n(TN,"A",{href:!0});var hIt=s(VG);WCo=r(hIt,"CodeGenTokenizerFast"),hIt.forEach(t),UCo=r(TN," (CodeGen model)"),TN.forEach(t),HCo=i(S),Ss=n(S,"LI",{});var MN=s(Ss);E_e=n(MN,"STRONG",{});var uIt=s(E_e);JCo=r(uIt,"convbert"),uIt.forEach(t),YCo=r(MN," \u2014 "),XG=n(MN,"A",{href:!0});var pIt=s(XG);ZCo=r(pIt,"ConvBertTokenizer"),pIt.forEach(t),KCo=r(MN," or "),zG=n(MN,"A",{href:!0});var _It=s(zG);e3o=r(_It,"ConvBertTokenizerFast"),_It.forEach(t),o3o=r(MN," (ConvBERT model)"),MN.forEach(t),r3o=i(S),Rs=n(S,"LI",{});var EN=s(Rs);C_e=n(EN,"STRONG",{});var bIt=s(C_e);t3o=r(bIt,"cpm"),bIt.forEach(t),a3o=r(EN," \u2014 "),QG=n(EN,"A",{href:!0});var vIt=s(QG);n3o=r(vIt,"CpmTokenizer"),vIt.forEach(t),s3o=r(EN," or "),WG=n(EN,"A",{href:!0});var FIt=s(WG);l3o=r(FIt,"CpmTokenizerFast"),FIt.forEach(t),i3o=r(EN," (CPM model)"),EN.forEach(t),d3o=i(S),Wu=n(S,"LI",{});var eOe=s(Wu);w_e=n(eOe,"STRONG",{});var TIt=s(w_e);m3o=r(TIt,"ctrl"),TIt.forEach(t),c3o=r(eOe," \u2014 "),UG=n(eOe,"A",{href:!0});var MIt=s(UG);f3o=r(MIt,"CTRLTokenizer"),MIt.forEach(t),g3o=r(eOe," (CTRL model)"),eOe.forEach(t),h3o=i(S),Ps=n(S,"LI",{});var CN=s(Ps);A_e=n(CN,"STRONG",{});var EIt=s(A_e);u3o=r(EIt,"data2vec-text"),EIt.forEach(t),p3o=r(CN," \u2014 "),HG=n(CN,"A",{href:!0});var CIt=s(HG);_3o=r(CIt,"RobertaTokenizer"),CIt.forEach(t),b3o=r(CN," or "),JG=n(CN,"A",{href:!0});var wIt=s(JG);v3o=r(wIt,"RobertaTokenizerFast"),wIt.forEach(t),F3o=r(CN," (Data2VecText model)"),CN.forEach(t),T3o=i(S),Bs=n(S,"LI",{});var wN=s(Bs);L_e=n(wN,"STRONG",{});var AIt=s(L_e);M3o=r(AIt,"deberta"),AIt.forEach(t),E3o=r(wN," \u2014 "),YG=n(wN,"A",{href:!0});var LIt=s(YG);C3o=r(LIt,"DebertaTokenizer"),LIt.forEach(t),w3o=r(wN," or "),ZG=n(wN,"A",{href:!0});var yIt=s(ZG);A3o=r(yIt,"DebertaTokenizerFast"),yIt.forEach(t),L3o=r(wN," (DeBERTa model)"),wN.forEach(t),y3o=i(S),Is=n(S,"LI",{});var AN=s(Is);y_e=n(AN,"STRONG",{});var xIt=s(y_e);x3o=r(xIt,"deberta-v2"),xIt.forEach(t),$3o=r(AN," \u2014 "),KG=n(AN,"A",{href:!0});var $It=s(KG);k3o=r($It,"DebertaV2Tokenizer"),$It.forEach(t),S3o=r(AN," or "),eO=n(AN,"A",{href:!0});var kIt=s(eO);R3o=r(kIt,"DebertaV2TokenizerFast"),kIt.forEach(t),P3o=r(AN," (DeBERTa-v2 model)"),AN.forEach(t),B3o=i(S),Ns=n(S,"LI",{});var LN=s(Ns);x_e=n(LN,"STRONG",{});var SIt=s(x_e);I3o=r(SIt,"distilbert"),SIt.forEach(t),N3o=r(LN," \u2014 "),oO=n(LN,"A",{href:!0});var RIt=s(oO);q3o=r(RIt,"DistilBertTokenizer"),RIt.forEach(t),D3o=r(LN," or "),rO=n(LN,"A",{href:!0});var PIt=s(rO);j3o=r(PIt,"DistilBertTokenizerFast"),PIt.forEach(t),G3o=r(LN," (DistilBERT model)"),LN.forEach(t),O3o=i(S),qs=n(S,"LI",{});var yN=s(qs);$_e=n(yN,"STRONG",{});var BIt=s($_e);V3o=r(BIt,"dpr"),BIt.forEach(t),X3o=r(yN," \u2014 "),tO=n(yN,"A",{href:!0});var IIt=s(tO);z3o=r(IIt,"DPRQuestionEncoderTokenizer"),IIt.forEach(t),Q3o=r(yN," or "),aO=n(yN,"A",{href:!0});var NIt=s(aO);W3o=r(NIt,"DPRQuestionEncoderTokenizerFast"),NIt.forEach(t),U3o=r(yN," (DPR model)"),yN.forEach(t),H3o=i(S),Ds=n(S,"LI",{});var xN=s(Ds);k_e=n(xN,"STRONG",{});var qIt=s(k_e);J3o=r(qIt,"electra"),qIt.forEach(t),Y3o=r(xN," \u2014 "),nO=n(xN,"A",{href:!0});var DIt=s(nO);Z3o=r(DIt,"ElectraTokenizer"),DIt.forEach(t),K3o=r(xN," or "),sO=n(xN,"A",{href:!0});var jIt=s(sO);e5o=r(jIt,"ElectraTokenizerFast"),jIt.forEach(t),o5o=r(xN," (ELECTRA model)"),xN.forEach(t),r5o=i(S),js=n(S,"LI",{});var $N=s(js);S_e=n($N,"STRONG",{});var GIt=s(S_e);t5o=r(GIt,"ernie"),GIt.forEach(t),a5o=r($N," \u2014 "),lO=n($N,"A",{href:!0});var OIt=s(lO);n5o=r(OIt,"BertTokenizer"),OIt.forEach(t),s5o=r($N," or "),iO=n($N,"A",{href:!0});var VIt=s(iO);l5o=r(VIt,"BertTokenizerFast"),VIt.forEach(t),i5o=r($N," (ERNIE model)"),$N.forEach(t),d5o=i(S),Uu=n(S,"LI",{});var oOe=s(Uu);R_e=n(oOe,"STRONG",{});var XIt=s(R_e);m5o=r(XIt,"esm"),XIt.forEach(t),c5o=r(oOe," \u2014 "),dO=n(oOe,"A",{href:!0});var zIt=s(dO);f5o=r(zIt,"EsmTokenizer"),zIt.forEach(t),g5o=r(oOe," (ESM model)"),oOe.forEach(t),h5o=i(S),Hu=n(S,"LI",{});var rOe=s(Hu);P_e=n(rOe,"STRONG",{});var QIt=s(P_e);u5o=r(QIt,"flaubert"),QIt.forEach(t),p5o=r(rOe," \u2014 "),mO=n(rOe,"A",{href:!0});var WIt=s(mO);_5o=r(WIt,"FlaubertTokenizer"),WIt.forEach(t),b5o=r(rOe," (FlauBERT model)"),rOe.forEach(t),v5o=i(S),Gs=n(S,"LI",{});var kN=s(Gs);B_e=n(kN,"STRONG",{});var UIt=s(B_e);F5o=r(UIt,"fnet"),UIt.forEach(t),T5o=r(kN," \u2014 "),cO=n(kN,"A",{href:!0});var HIt=s(cO);M5o=r(HIt,"FNetTokenizer"),HIt.forEach(t),E5o=r(kN," or "),fO=n(kN,"A",{href:!0});var JIt=s(fO);C5o=r(JIt,"FNetTokenizerFast"),JIt.forEach(t),w5o=r(kN," (FNet model)"),kN.forEach(t),A5o=i(S),Ju=n(S,"LI",{});var tOe=s(Ju);I_e=n(tOe,"STRONG",{});var YIt=s(I_e);L5o=r(YIt,"fsmt"),YIt.forEach(t),y5o=r(tOe," \u2014 "),gO=n(tOe,"A",{href:!0});var ZIt=s(gO);x5o=r(ZIt,"FSMTTokenizer"),ZIt.forEach(t),$5o=r(tOe," (FairSeq Machine-Translation model)"),tOe.forEach(t),k5o=i(S),Os=n(S,"LI",{});var SN=s(Os);N_e=n(SN,"STRONG",{});var KIt=s(N_e);S5o=r(KIt,"funnel"),KIt.forEach(t),R5o=r(SN," \u2014 "),hO=n(SN,"A",{href:!0});var eNt=s(hO);P5o=r(eNt,"FunnelTokenizer"),eNt.forEach(t),B5o=r(SN," or "),uO=n(SN,"A",{href:!0});var oNt=s(uO);I5o=r(oNt,"FunnelTokenizerFast"),oNt.forEach(t),N5o=r(SN," (Funnel Transformer model)"),SN.forEach(t),q5o=i(S),Vs=n(S,"LI",{});var RN=s(Vs);q_e=n(RN,"STRONG",{});var rNt=s(q_e);D5o=r(rNt,"gpt2"),rNt.forEach(t),j5o=r(RN," \u2014 "),pO=n(RN,"A",{href:!0});var tNt=s(pO);G5o=r(tNt,"GPT2Tokenizer"),tNt.forEach(t),O5o=r(RN," or "),_O=n(RN,"A",{href:!0});var aNt=s(_O);V5o=r(aNt,"GPT2TokenizerFast"),aNt.forEach(t),X5o=r(RN," (OpenAI GPT-2 model)"),RN.forEach(t),z5o=i(S),Xs=n(S,"LI",{});var PN=s(Xs);D_e=n(PN,"STRONG",{});var nNt=s(D_e);Q5o=r(nNt,"gpt_neo"),nNt.forEach(t),W5o=r(PN," \u2014 "),bO=n(PN,"A",{href:!0});var sNt=s(bO);U5o=r(sNt,"GPT2Tokenizer"),sNt.forEach(t),H5o=r(PN," or "),vO=n(PN,"A",{href:!0});var lNt=s(vO);J5o=r(lNt,"GPT2TokenizerFast"),lNt.forEach(t),Y5o=r(PN," (GPT Neo model)"),PN.forEach(t),Z5o=i(S),Yu=n(S,"LI",{});var aOe=s(Yu);j_e=n(aOe,"STRONG",{});var iNt=s(j_e);K5o=r(iNt,"gpt_neox"),iNt.forEach(t),e0o=r(aOe," \u2014 "),FO=n(aOe,"A",{href:!0});var dNt=s(FO);o0o=r(dNt,"GPTNeoXTokenizerFast"),dNt.forEach(t),r0o=r(aOe," (GPT NeoX model)"),aOe.forEach(t),t0o=i(S),Zu=n(S,"LI",{});var nOe=s(Zu);G_e=n(nOe,"STRONG",{});var mNt=s(G_e);a0o=r(mNt,"gpt_neox_japanese"),mNt.forEach(t),n0o=r(nOe," \u2014 "),TO=n(nOe,"A",{href:!0});var cNt=s(TO);s0o=r(cNt,"GPTNeoXJapaneseTokenizer"),cNt.forEach(t),l0o=r(nOe," (GPT NeoX Japanese model)"),nOe.forEach(t),i0o=i(S),zs=n(S,"LI",{});var BN=s(zs);O_e=n(BN,"STRONG",{});var fNt=s(O_e);d0o=r(fNt,"gptj"),fNt.forEach(t),m0o=r(BN," \u2014 "),MO=n(BN,"A",{href:!0});var gNt=s(MO);c0o=r(gNt,"GPT2Tokenizer"),gNt.forEach(t),f0o=r(BN," or "),EO=n(BN,"A",{href:!0});var hNt=s(EO);g0o=r(hNt,"GPT2TokenizerFast"),hNt.forEach(t),h0o=r(BN," (GPT-J model)"),BN.forEach(t),u0o=i(S),Qs=n(S,"LI",{});var IN=s(Qs);V_e=n(IN,"STRONG",{});var uNt=s(V_e);p0o=r(uNt,"groupvit"),uNt.forEach(t),_0o=r(IN," \u2014 "),CO=n(IN,"A",{href:!0});var pNt=s(CO);b0o=r(pNt,"CLIPTokenizer"),pNt.forEach(t),v0o=r(IN," or "),wO=n(IN,"A",{href:!0});var _Nt=s(wO);F0o=r(_Nt,"CLIPTokenizerFast"),_Nt.forEach(t),T0o=r(IN," (GroupViT model)"),IN.forEach(t),M0o=i(S),Ws=n(S,"LI",{});var NN=s(Ws);X_e=n(NN,"STRONG",{});var bNt=s(X_e);E0o=r(bNt,"herbert"),bNt.forEach(t),C0o=r(NN," \u2014 "),AO=n(NN,"A",{href:!0});var vNt=s(AO);w0o=r(vNt,"HerbertTokenizer"),vNt.forEach(t),A0o=r(NN," or "),LO=n(NN,"A",{href:!0});var FNt=s(LO);L0o=r(FNt,"HerbertTokenizerFast"),FNt.forEach(t),y0o=r(NN," (HerBERT model)"),NN.forEach(t),x0o=i(S),Ku=n(S,"LI",{});var sOe=s(Ku);z_e=n(sOe,"STRONG",{});var TNt=s(z_e);$0o=r(TNt,"hubert"),TNt.forEach(t),k0o=r(sOe," \u2014 "),yO=n(sOe,"A",{href:!0});var MNt=s(yO);S0o=r(MNt,"Wav2Vec2CTCTokenizer"),MNt.forEach(t),R0o=r(sOe," (Hubert model)"),sOe.forEach(t),P0o=i(S),Us=n(S,"LI",{});var qN=s(Us);Q_e=n(qN,"STRONG",{});var ENt=s(Q_e);B0o=r(ENt,"ibert"),ENt.forEach(t),I0o=r(qN," \u2014 "),xO=n(qN,"A",{href:!0});var CNt=s(xO);N0o=r(CNt,"RobertaTokenizer"),CNt.forEach(t),q0o=r(qN," or "),$O=n(qN,"A",{href:!0});var wNt=s($O);D0o=r(wNt,"RobertaTokenizerFast"),wNt.forEach(t),j0o=r(qN," (I-BERT model)"),qN.forEach(t),G0o=i(S),Hs=n(S,"LI",{});var DN=s(Hs);W_e=n(DN,"STRONG",{});var ANt=s(W_e);O0o=r(ANt,"layoutlm"),ANt.forEach(t),V0o=r(DN," \u2014 "),kO=n(DN,"A",{href:!0});var LNt=s(kO);X0o=r(LNt,"LayoutLMTokenizer"),LNt.forEach(t),z0o=r(DN," or "),SO=n(DN,"A",{href:!0});var yNt=s(SO);Q0o=r(yNt,"LayoutLMTokenizerFast"),yNt.forEach(t),W0o=r(DN," (LayoutLM model)"),DN.forEach(t),U0o=i(S),Js=n(S,"LI",{});var jN=s(Js);U_e=n(jN,"STRONG",{});var xNt=s(U_e);H0o=r(xNt,"layoutlmv2"),xNt.forEach(t),J0o=r(jN," \u2014 "),RO=n(jN,"A",{href:!0});var $Nt=s(RO);Y0o=r($Nt,"LayoutLMv2Tokenizer"),$Nt.forEach(t),Z0o=r(jN," or "),PO=n(jN,"A",{href:!0});var kNt=s(PO);K0o=r(kNt,"LayoutLMv2TokenizerFast"),kNt.forEach(t),ewo=r(jN," (LayoutLMv2 model)"),jN.forEach(t),owo=i(S),Ys=n(S,"LI",{});var GN=s(Ys);H_e=n(GN,"STRONG",{});var SNt=s(H_e);rwo=r(SNt,"layoutlmv3"),SNt.forEach(t),two=r(GN," \u2014 "),BO=n(GN,"A",{href:!0});var RNt=s(BO);awo=r(RNt,"LayoutLMv3Tokenizer"),RNt.forEach(t),nwo=r(GN," or "),IO=n(GN,"A",{href:!0});var PNt=s(IO);swo=r(PNt,"LayoutLMv3TokenizerFast"),PNt.forEach(t),lwo=r(GN," (LayoutLMv3 model)"),GN.forEach(t),iwo=i(S),Zs=n(S,"LI",{});var ON=s(Zs);J_e=n(ON,"STRONG",{});var BNt=s(J_e);dwo=r(BNt,"layoutxlm"),BNt.forEach(t),mwo=r(ON," \u2014 "),NO=n(ON,"A",{href:!0});var INt=s(NO);cwo=r(INt,"LayoutXLMTokenizer"),INt.forEach(t),fwo=r(ON," or "),qO=n(ON,"A",{href:!0});var NNt=s(qO);gwo=r(NNt,"LayoutXLMTokenizerFast"),NNt.forEach(t),hwo=r(ON," (LayoutXLM model)"),ON.forEach(t),uwo=i(S),Ks=n(S,"LI",{});var VN=s(Ks);Y_e=n(VN,"STRONG",{});var qNt=s(Y_e);pwo=r(qNt,"led"),qNt.forEach(t),_wo=r(VN," \u2014 "),DO=n(VN,"A",{href:!0});var DNt=s(DO);bwo=r(DNt,"LEDTokenizer"),DNt.forEach(t),vwo=r(VN," or "),jO=n(VN,"A",{href:!0});var jNt=s(jO);Fwo=r(jNt,"LEDTokenizerFast"),jNt.forEach(t),Two=r(VN," (LED model)"),VN.forEach(t),Mwo=i(S),el=n(S,"LI",{});var XN=s(el);Z_e=n(XN,"STRONG",{});var GNt=s(Z_e);Ewo=r(GNt,"lilt"),GNt.forEach(t),Cwo=r(XN," \u2014 "),GO=n(XN,"A",{href:!0});var ONt=s(GO);wwo=r(ONt,"LayoutLMv3Tokenizer"),ONt.forEach(t),Awo=r(XN," or "),OO=n(XN,"A",{href:!0});var VNt=s(OO);Lwo=r(VNt,"LayoutLMv3TokenizerFast"),VNt.forEach(t),ywo=r(XN," (LiLT model)"),XN.forEach(t),xwo=i(S),ol=n(S,"LI",{});var zN=s(ol);K_e=n(zN,"STRONG",{});var XNt=s(K_e);$wo=r(XNt,"longformer"),XNt.forEach(t),kwo=r(zN," \u2014 "),VO=n(zN,"A",{href:!0});var zNt=s(VO);Swo=r(zNt,"LongformerTokenizer"),zNt.forEach(t),Rwo=r(zN," or "),XO=n(zN,"A",{href:!0});var QNt=s(XO);Pwo=r(QNt,"LongformerTokenizerFast"),QNt.forEach(t),Bwo=r(zN," (Longformer model)"),zN.forEach(t),Iwo=i(S),rl=n(S,"LI",{});var QN=s(rl);e1e=n(QN,"STRONG",{});var WNt=s(e1e);Nwo=r(WNt,"longt5"),WNt.forEach(t),qwo=r(QN," \u2014 "),zO=n(QN,"A",{href:!0});var UNt=s(zO);Dwo=r(UNt,"T5Tokenizer"),UNt.forEach(t),jwo=r(QN," or "),QO=n(QN,"A",{href:!0});var HNt=s(QO);Gwo=r(HNt,"T5TokenizerFast"),HNt.forEach(t),Owo=r(QN," (LongT5 model)"),QN.forEach(t),Vwo=i(S),ep=n(S,"LI",{});var lOe=s(ep);o1e=n(lOe,"STRONG",{});var JNt=s(o1e);Xwo=r(JNt,"luke"),JNt.forEach(t),zwo=r(lOe," \u2014 "),WO=n(lOe,"A",{href:!0});var YNt=s(WO);Qwo=r(YNt,"LukeTokenizer"),YNt.forEach(t),Wwo=r(lOe," (LUKE model)"),lOe.forEach(t),Uwo=i(S),tl=n(S,"LI",{});var WN=s(tl);r1e=n(WN,"STRONG",{});var ZNt=s(r1e);Hwo=r(ZNt,"lxmert"),ZNt.forEach(t),Jwo=r(WN," \u2014 "),UO=n(WN,"A",{href:!0});var KNt=s(UO);Ywo=r(KNt,"LxmertTokenizer"),KNt.forEach(t),Zwo=r(WN," or "),HO=n(WN,"A",{href:!0});var eqt=s(HO);Kwo=r(eqt,"LxmertTokenizerFast"),eqt.forEach(t),eAo=r(WN," (LXMERT model)"),WN.forEach(t),oAo=i(S),op=n(S,"LI",{});var iOe=s(op);t1e=n(iOe,"STRONG",{});var oqt=s(t1e);rAo=r(oqt,"m2m_100"),oqt.forEach(t),tAo=r(iOe," \u2014 "),JO=n(iOe,"A",{href:!0});var rqt=s(JO);aAo=r(rqt,"M2M100Tokenizer"),rqt.forEach(t),nAo=r(iOe," (M2M100 model)"),iOe.forEach(t),sAo=i(S),rp=n(S,"LI",{});var dOe=s(rp);a1e=n(dOe,"STRONG",{});var tqt=s(a1e);lAo=r(tqt,"marian"),tqt.forEach(t),iAo=r(dOe," \u2014 "),YO=n(dOe,"A",{href:!0});var aqt=s(YO);dAo=r(aqt,"MarianTokenizer"),aqt.forEach(t),mAo=r(dOe," (Marian model)"),dOe.forEach(t),cAo=i(S),al=n(S,"LI",{});var UN=s(al);n1e=n(UN,"STRONG",{});var nqt=s(n1e);fAo=r(nqt,"mbart"),nqt.forEach(t),gAo=r(UN," \u2014 "),ZO=n(UN,"A",{href:!0});var sqt=s(ZO);hAo=r(sqt,"MBartTokenizer"),sqt.forEach(t),uAo=r(UN," or "),KO=n(UN,"A",{href:!0});var lqt=s(KO);pAo=r(lqt,"MBartTokenizerFast"),lqt.forEach(t),_Ao=r(UN," (mBART model)"),UN.forEach(t),bAo=i(S),nl=n(S,"LI",{});var HN=s(nl);s1e=n(HN,"STRONG",{});var iqt=s(s1e);vAo=r(iqt,"mbart50"),iqt.forEach(t),FAo=r(HN," \u2014 "),eV=n(HN,"A",{href:!0});var dqt=s(eV);TAo=r(dqt,"MBart50Tokenizer"),dqt.forEach(t),MAo=r(HN," or "),oV=n(HN,"A",{href:!0});var mqt=s(oV);EAo=r(mqt,"MBart50TokenizerFast"),mqt.forEach(t),CAo=r(HN," (mBART-50 model)"),HN.forEach(t),wAo=i(S),sl=n(S,"LI",{});var JN=s(sl);l1e=n(JN,"STRONG",{});var cqt=s(l1e);AAo=r(cqt,"megatron-bert"),cqt.forEach(t),LAo=r(JN," \u2014 "),rV=n(JN,"A",{href:!0});var fqt=s(rV);yAo=r(fqt,"BertTokenizer"),fqt.forEach(t),xAo=r(JN," or "),tV=n(JN,"A",{href:!0});var gqt=s(tV);$Ao=r(gqt,"BertTokenizerFast"),gqt.forEach(t),kAo=r(JN," (Megatron-BERT model)"),JN.forEach(t),SAo=i(S),tp=n(S,"LI",{});var mOe=s(tp);i1e=n(mOe,"STRONG",{});var hqt=s(i1e);RAo=r(hqt,"mluke"),hqt.forEach(t),PAo=r(mOe," \u2014 "),aV=n(mOe,"A",{href:!0});var uqt=s(aV);BAo=r(uqt,"MLukeTokenizer"),uqt.forEach(t),IAo=r(mOe," (mLUKE model)"),mOe.forEach(t),NAo=i(S),ll=n(S,"LI",{});var YN=s(ll);d1e=n(YN,"STRONG",{});var pqt=s(d1e);qAo=r(pqt,"mobilebert"),pqt.forEach(t),DAo=r(YN," \u2014 "),nV=n(YN,"A",{href:!0});var _qt=s(nV);jAo=r(_qt,"MobileBertTokenizer"),_qt.forEach(t),GAo=r(YN," or "),sV=n(YN,"A",{href:!0});var bqt=s(sV);OAo=r(bqt,"MobileBertTokenizerFast"),bqt.forEach(t),VAo=r(YN," (MobileBERT model)"),YN.forEach(t),XAo=i(S),il=n(S,"LI",{});var ZN=s(il);m1e=n(ZN,"STRONG",{});var vqt=s(m1e);zAo=r(vqt,"mpnet"),vqt.forEach(t),QAo=r(ZN," \u2014 "),lV=n(ZN,"A",{href:!0});var Fqt=s(lV);WAo=r(Fqt,"MPNetTokenizer"),Fqt.forEach(t),UAo=r(ZN," or "),iV=n(ZN,"A",{href:!0});var Tqt=s(iV);HAo=r(Tqt,"MPNetTokenizerFast"),Tqt.forEach(t),JAo=r(ZN," (MPNet model)"),ZN.forEach(t),YAo=i(S),dl=n(S,"LI",{});var KN=s(dl);c1e=n(KN,"STRONG",{});var Mqt=s(c1e);ZAo=r(Mqt,"mt5"),Mqt.forEach(t),KAo=r(KN," \u2014 "),dV=n(KN,"A",{href:!0});var Eqt=s(dV);e6o=r(Eqt,"MT5Tokenizer"),Eqt.forEach(t),o6o=r(KN," or "),mV=n(KN,"A",{href:!0});var Cqt=s(mV);r6o=r(Cqt,"MT5TokenizerFast"),Cqt.forEach(t),t6o=r(KN," (MT5 model)"),KN.forEach(t),a6o=i(S),ml=n(S,"LI",{});var eq=s(ml);f1e=n(eq,"STRONG",{});var wqt=s(f1e);n6o=r(wqt,"mvp"),wqt.forEach(t),s6o=r(eq," \u2014 "),cV=n(eq,"A",{href:!0});var Aqt=s(cV);l6o=r(Aqt,"MvpTokenizer"),Aqt.forEach(t),i6o=r(eq," or "),fV=n(eq,"A",{href:!0});var Lqt=s(fV);d6o=r(Lqt,"MvpTokenizerFast"),Lqt.forEach(t),m6o=r(eq," (MVP model)"),eq.forEach(t),c6o=i(S),cl=n(S,"LI",{});var oq=s(cl);g1e=n(oq,"STRONG",{});var yqt=s(g1e);f6o=r(yqt,"nezha"),yqt.forEach(t),g6o=r(oq," \u2014 "),gV=n(oq,"A",{href:!0});var xqt=s(gV);h6o=r(xqt,"BertTokenizer"),xqt.forEach(t),u6o=r(oq," or "),hV=n(oq,"A",{href:!0});var $qt=s(hV);p6o=r($qt,"BertTokenizerFast"),$qt.forEach(t),_6o=r(oq," (Nezha model)"),oq.forEach(t),b6o=i(S),fl=n(S,"LI",{});var rq=s(fl);h1e=n(rq,"STRONG",{});var kqt=s(h1e);v6o=r(kqt,"nllb"),kqt.forEach(t),F6o=r(rq," \u2014 "),uV=n(rq,"A",{href:!0});var Sqt=s(uV);T6o=r(Sqt,"NllbTokenizer"),Sqt.forEach(t),M6o=r(rq," or "),pV=n(rq,"A",{href:!0});var Rqt=s(pV);E6o=r(Rqt,"NllbTokenizerFast"),Rqt.forEach(t),C6o=r(rq," (NLLB model)"),rq.forEach(t),w6o=i(S),gl=n(S,"LI",{});var tq=s(gl);u1e=n(tq,"STRONG",{});var Pqt=s(u1e);A6o=r(Pqt,"nystromformer"),Pqt.forEach(t),L6o=r(tq," \u2014 "),_V=n(tq,"A",{href:!0});var Bqt=s(_V);y6o=r(Bqt,"AlbertTokenizer"),Bqt.forEach(t),x6o=r(tq," or "),bV=n(tq,"A",{href:!0});var Iqt=s(bV);$6o=r(Iqt,"AlbertTokenizerFast"),Iqt.forEach(t),k6o=r(tq," (Nystr\xF6mformer model)"),tq.forEach(t),S6o=i(S),hl=n(S,"LI",{});var aq=s(hl);p1e=n(aq,"STRONG",{});var Nqt=s(p1e);R6o=r(Nqt,"openai-gpt"),Nqt.forEach(t),P6o=r(aq," \u2014 "),vV=n(aq,"A",{href:!0});var qqt=s(vV);B6o=r(qqt,"OpenAIGPTTokenizer"),qqt.forEach(t),I6o=r(aq," or "),FV=n(aq,"A",{href:!0});var Dqt=s(FV);N6o=r(Dqt,"OpenAIGPTTokenizerFast"),Dqt.forEach(t),q6o=r(aq," (OpenAI GPT model)"),aq.forEach(t),D6o=i(S),ap=n(S,"LI",{});var cOe=s(ap);_1e=n(cOe,"STRONG",{});var jqt=s(_1e);j6o=r(jqt,"opt"),jqt.forEach(t),G6o=r(cOe," \u2014 "),TV=n(cOe,"A",{href:!0});var Gqt=s(TV);O6o=r(Gqt,"GPT2Tokenizer"),Gqt.forEach(t),V6o=r(cOe," (OPT model)"),cOe.forEach(t),X6o=i(S),ul=n(S,"LI",{});var nq=s(ul);b1e=n(nq,"STRONG",{});var Oqt=s(b1e);z6o=r(Oqt,"owlvit"),Oqt.forEach(t),Q6o=r(nq," \u2014 "),MV=n(nq,"A",{href:!0});var Vqt=s(MV);W6o=r(Vqt,"CLIPTokenizer"),Vqt.forEach(t),U6o=r(nq," or "),EV=n(nq,"A",{href:!0});var Xqt=s(EV);H6o=r(Xqt,"CLIPTokenizerFast"),Xqt.forEach(t),J6o=r(nq," (OWL-ViT model)"),nq.forEach(t),Y6o=i(S),pl=n(S,"LI",{});var sq=s(pl);v1e=n(sq,"STRONG",{});var zqt=s(v1e);Z6o=r(zqt,"pegasus"),zqt.forEach(t),K6o=r(sq," \u2014 "),CV=n(sq,"A",{href:!0});var Qqt=s(CV);e7o=r(Qqt,"PegasusTokenizer"),Qqt.forEach(t),o7o=r(sq," or "),wV=n(sq,"A",{href:!0});var Wqt=s(wV);r7o=r(Wqt,"PegasusTokenizerFast"),Wqt.forEach(t),t7o=r(sq," (Pegasus model)"),sq.forEach(t),a7o=i(S),_l=n(S,"LI",{});var lq=s(_l);F1e=n(lq,"STRONG",{});var Uqt=s(F1e);n7o=r(Uqt,"pegasus_x"),Uqt.forEach(t),s7o=r(lq," \u2014 "),AV=n(lq,"A",{href:!0});var Hqt=s(AV);l7o=r(Hqt,"PegasusTokenizer"),Hqt.forEach(t),i7o=r(lq," or "),LV=n(lq,"A",{href:!0});var Jqt=s(LV);d7o=r(Jqt,"PegasusTokenizerFast"),Jqt.forEach(t),m7o=r(lq," (PEGASUS-X model)"),lq.forEach(t),c7o=i(S),np=n(S,"LI",{});var fOe=s(np);T1e=n(fOe,"STRONG",{});var Yqt=s(T1e);f7o=r(Yqt,"perceiver"),Yqt.forEach(t),g7o=r(fOe," \u2014 "),yV=n(fOe,"A",{href:!0});var Zqt=s(yV);h7o=r(Zqt,"PerceiverTokenizer"),Zqt.forEach(t),u7o=r(fOe," (Perceiver model)"),fOe.forEach(t),p7o=i(S),sp=n(S,"LI",{});var gOe=s(sp);M1e=n(gOe,"STRONG",{});var Kqt=s(M1e);_7o=r(Kqt,"phobert"),Kqt.forEach(t),b7o=r(gOe," \u2014 "),xV=n(gOe,"A",{href:!0});var eDt=s(xV);v7o=r(eDt,"PhobertTokenizer"),eDt.forEach(t),F7o=r(gOe," (PhoBERT model)"),gOe.forEach(t),T7o=i(S),lp=n(S,"LI",{});var hOe=s(lp);E1e=n(hOe,"STRONG",{});var oDt=s(E1e);M7o=r(oDt,"plbart"),oDt.forEach(t),E7o=r(hOe," \u2014 "),$V=n(hOe,"A",{href:!0});var rDt=s($V);C7o=r(rDt,"PLBartTokenizer"),rDt.forEach(t),w7o=r(hOe," (PLBart model)"),hOe.forEach(t),A7o=i(S),ip=n(S,"LI",{});var uOe=s(ip);C1e=n(uOe,"STRONG",{});var tDt=s(C1e);L7o=r(tDt,"prophetnet"),tDt.forEach(t),y7o=r(uOe," \u2014 "),kV=n(uOe,"A",{href:!0});var aDt=s(kV);x7o=r(aDt,"ProphetNetTokenizer"),aDt.forEach(t),$7o=r(uOe," (ProphetNet model)"),uOe.forEach(t),k7o=i(S),bl=n(S,"LI",{});var iq=s(bl);w1e=n(iq,"STRONG",{});var nDt=s(w1e);S7o=r(nDt,"qdqbert"),nDt.forEach(t),R7o=r(iq," \u2014 "),SV=n(iq,"A",{href:!0});var sDt=s(SV);P7o=r(sDt,"BertTokenizer"),sDt.forEach(t),B7o=r(iq," or "),RV=n(iq,"A",{href:!0});var lDt=s(RV);I7o=r(lDt,"BertTokenizerFast"),lDt.forEach(t),N7o=r(iq," (QDQBert model)"),iq.forEach(t),q7o=i(S),dp=n(S,"LI",{});var pOe=s(dp);A1e=n(pOe,"STRONG",{});var iDt=s(A1e);D7o=r(iDt,"rag"),iDt.forEach(t),j7o=r(pOe," \u2014 "),PV=n(pOe,"A",{href:!0});var dDt=s(PV);G7o=r(dDt,"RagTokenizer"),dDt.forEach(t),O7o=r(pOe," (RAG model)"),pOe.forEach(t),V7o=i(S),vl=n(S,"LI",{});var dq=s(vl);L1e=n(dq,"STRONG",{});var mDt=s(L1e);X7o=r(mDt,"realm"),mDt.forEach(t),z7o=r(dq," \u2014 "),BV=n(dq,"A",{href:!0});var cDt=s(BV);Q7o=r(cDt,"RealmTokenizer"),cDt.forEach(t),W7o=r(dq," or "),IV=n(dq,"A",{href:!0});var fDt=s(IV);U7o=r(fDt,"RealmTokenizerFast"),fDt.forEach(t),H7o=r(dq," (REALM model)"),dq.forEach(t),J7o=i(S),Fl=n(S,"LI",{});var mq=s(Fl);y1e=n(mq,"STRONG",{});var gDt=s(y1e);Y7o=r(gDt,"reformer"),gDt.forEach(t),Z7o=r(mq," \u2014 "),NV=n(mq,"A",{href:!0});var hDt=s(NV);K7o=r(hDt,"ReformerTokenizer"),hDt.forEach(t),e8o=r(mq," or "),qV=n(mq,"A",{href:!0});var uDt=s(qV);o8o=r(uDt,"ReformerTokenizerFast"),uDt.forEach(t),r8o=r(mq," (Reformer model)"),mq.forEach(t),t8o=i(S),Tl=n(S,"LI",{});var cq=s(Tl);x1e=n(cq,"STRONG",{});var pDt=s(x1e);a8o=r(pDt,"rembert"),pDt.forEach(t),n8o=r(cq," \u2014 "),DV=n(cq,"A",{href:!0});var _Dt=s(DV);s8o=r(_Dt,"RemBertTokenizer"),_Dt.forEach(t),l8o=r(cq," or "),jV=n(cq,"A",{href:!0});var bDt=s(jV);i8o=r(bDt,"RemBertTokenizerFast"),bDt.forEach(t),d8o=r(cq," (RemBERT model)"),cq.forEach(t),m8o=i(S),Ml=n(S,"LI",{});var fq=s(Ml);$1e=n(fq,"STRONG",{});var vDt=s($1e);c8o=r(vDt,"retribert"),vDt.forEach(t),f8o=r(fq," \u2014 "),GV=n(fq,"A",{href:!0});var FDt=s(GV);g8o=r(FDt,"RetriBertTokenizer"),FDt.forEach(t),h8o=r(fq," or "),OV=n(fq,"A",{href:!0});var TDt=s(OV);u8o=r(TDt,"RetriBertTokenizerFast"),TDt.forEach(t),p8o=r(fq," (RetriBERT model)"),fq.forEach(t),_8o=i(S),El=n(S,"LI",{});var gq=s(El);k1e=n(gq,"STRONG",{});var MDt=s(k1e);b8o=r(MDt,"roberta"),MDt.forEach(t),v8o=r(gq," \u2014 "),VV=n(gq,"A",{href:!0});var EDt=s(VV);F8o=r(EDt,"RobertaTokenizer"),EDt.forEach(t),T8o=r(gq," or "),XV=n(gq,"A",{href:!0});var CDt=s(XV);M8o=r(CDt,"RobertaTokenizerFast"),CDt.forEach(t),E8o=r(gq," (RoBERTa model)"),gq.forEach(t),C8o=i(S),Cl=n(S,"LI",{});var hq=s(Cl);S1e=n(hq,"STRONG",{});var wDt=s(S1e);w8o=r(wDt,"roformer"),wDt.forEach(t),A8o=r(hq," \u2014 "),zV=n(hq,"A",{href:!0});var ADt=s(zV);L8o=r(ADt,"RoFormerTokenizer"),ADt.forEach(t),y8o=r(hq," or "),QV=n(hq,"A",{href:!0});var LDt=s(QV);x8o=r(LDt,"RoFormerTokenizerFast"),LDt.forEach(t),$8o=r(hq," (RoFormer model)"),hq.forEach(t),k8o=i(S),mp=n(S,"LI",{});var _Oe=s(mp);R1e=n(_Oe,"STRONG",{});var yDt=s(R1e);S8o=r(yDt,"speech_to_text"),yDt.forEach(t),R8o=r(_Oe," \u2014 "),WV=n(_Oe,"A",{href:!0});var xDt=s(WV);P8o=r(xDt,"Speech2TextTokenizer"),xDt.forEach(t),B8o=r(_Oe," (Speech2Text model)"),_Oe.forEach(t),I8o=i(S),cp=n(S,"LI",{});var bOe=s(cp);P1e=n(bOe,"STRONG",{});var $Dt=s(P1e);N8o=r($Dt,"speech_to_text_2"),$Dt.forEach(t),q8o=r(bOe," \u2014 "),UV=n(bOe,"A",{href:!0});var kDt=s(UV);D8o=r(kDt,"Speech2Text2Tokenizer"),kDt.forEach(t),j8o=r(bOe," (Speech2Text2 model)"),bOe.forEach(t),G8o=i(S),wl=n(S,"LI",{});var uq=s(wl);B1e=n(uq,"STRONG",{});var SDt=s(B1e);O8o=r(SDt,"splinter"),SDt.forEach(t),V8o=r(uq," \u2014 "),HV=n(uq,"A",{href:!0});var RDt=s(HV);X8o=r(RDt,"SplinterTokenizer"),RDt.forEach(t),z8o=r(uq," or "),JV=n(uq,"A",{href:!0});var PDt=s(JV);Q8o=r(PDt,"SplinterTokenizerFast"),PDt.forEach(t),W8o=r(uq," (Splinter model)"),uq.forEach(t),U8o=i(S),Al=n(S,"LI",{});var pq=s(Al);I1e=n(pq,"STRONG",{});var BDt=s(I1e);H8o=r(BDt,"squeezebert"),BDt.forEach(t),J8o=r(pq," \u2014 "),YV=n(pq,"A",{href:!0});var IDt=s(YV);Y8o=r(IDt,"SqueezeBertTokenizer"),IDt.forEach(t),Z8o=r(pq," or "),ZV=n(pq,"A",{href:!0});var NDt=s(ZV);K8o=r(NDt,"SqueezeBertTokenizerFast"),NDt.forEach(t),eLo=r(pq," (SqueezeBERT model)"),pq.forEach(t),oLo=i(S),Ll=n(S,"LI",{});var _q=s(Ll);N1e=n(_q,"STRONG",{});var qDt=s(N1e);rLo=r(qDt,"t5"),qDt.forEach(t),tLo=r(_q," \u2014 "),KV=n(_q,"A",{href:!0});var DDt=s(KV);aLo=r(DDt,"T5Tokenizer"),DDt.forEach(t),nLo=r(_q," or "),eX=n(_q,"A",{href:!0});var jDt=s(eX);sLo=r(jDt,"T5TokenizerFast"),jDt.forEach(t),lLo=r(_q," (T5 model)"),_q.forEach(t),iLo=i(S),fp=n(S,"LI",{});var vOe=s(fp);q1e=n(vOe,"STRONG",{});var GDt=s(q1e);dLo=r(GDt,"tapas"),GDt.forEach(t),mLo=r(vOe," \u2014 "),oX=n(vOe,"A",{href:!0});var ODt=s(oX);cLo=r(ODt,"TapasTokenizer"),ODt.forEach(t),fLo=r(vOe," (TAPAS model)"),vOe.forEach(t),gLo=i(S),gp=n(S,"LI",{});var FOe=s(gp);D1e=n(FOe,"STRONG",{});var VDt=s(D1e);hLo=r(VDt,"tapex"),VDt.forEach(t),uLo=r(FOe," \u2014 "),rX=n(FOe,"A",{href:!0});var XDt=s(rX);pLo=r(XDt,"TapexTokenizer"),XDt.forEach(t),_Lo=r(FOe," (TAPEX model)"),FOe.forEach(t),bLo=i(S),hp=n(S,"LI",{});var TOe=s(hp);j1e=n(TOe,"STRONG",{});var zDt=s(j1e);vLo=r(zDt,"transfo-xl"),zDt.forEach(t),FLo=r(TOe," \u2014 "),tX=n(TOe,"A",{href:!0});var QDt=s(tX);TLo=r(QDt,"TransfoXLTokenizer"),QDt.forEach(t),MLo=r(TOe," (Transformer-XL model)"),TOe.forEach(t),ELo=i(S),yl=n(S,"LI",{});var bq=s(yl);G1e=n(bq,"STRONG",{});var WDt=s(G1e);CLo=r(WDt,"vilt"),WDt.forEach(t),wLo=r(bq," \u2014 "),aX=n(bq,"A",{href:!0});var UDt=s(aX);ALo=r(UDt,"BertTokenizer"),UDt.forEach(t),LLo=r(bq," or "),nX=n(bq,"A",{href:!0});var HDt=s(nX);yLo=r(HDt,"BertTokenizerFast"),HDt.forEach(t),xLo=r(bq," (ViLT model)"),bq.forEach(t),$Lo=i(S),xl=n(S,"LI",{});var vq=s(xl);O1e=n(vq,"STRONG",{});var JDt=s(O1e);kLo=r(JDt,"visual_bert"),JDt.forEach(t),SLo=r(vq," \u2014 "),sX=n(vq,"A",{href:!0});var YDt=s(sX);RLo=r(YDt,"BertTokenizer"),YDt.forEach(t),PLo=r(vq," or "),lX=n(vq,"A",{href:!0});var ZDt=s(lX);BLo=r(ZDt,"BertTokenizerFast"),ZDt.forEach(t),ILo=r(vq," (VisualBERT model)"),vq.forEach(t),NLo=i(S),up=n(S,"LI",{});var MOe=s(up);V1e=n(MOe,"STRONG",{});var KDt=s(V1e);qLo=r(KDt,"wav2vec2"),KDt.forEach(t),DLo=r(MOe," \u2014 "),iX=n(MOe,"A",{href:!0});var ejt=s(iX);jLo=r(ejt,"Wav2Vec2CTCTokenizer"),ejt.forEach(t),GLo=r(MOe," (Wav2Vec2 model)"),MOe.forEach(t),OLo=i(S),pp=n(S,"LI",{});var EOe=s(pp);X1e=n(EOe,"STRONG",{});var ojt=s(X1e);VLo=r(ojt,"wav2vec2-conformer"),ojt.forEach(t),XLo=r(EOe," \u2014 "),dX=n(EOe,"A",{href:!0});var rjt=s(dX);zLo=r(rjt,"Wav2Vec2CTCTokenizer"),rjt.forEach(t),QLo=r(EOe," (Wav2Vec2-Conformer model)"),EOe.forEach(t),WLo=i(S),_p=n(S,"LI",{});var COe=s(_p);z1e=n(COe,"STRONG",{});var tjt=s(z1e);ULo=r(tjt,"wav2vec2_phoneme"),tjt.forEach(t),HLo=r(COe," \u2014 "),mX=n(COe,"A",{href:!0});var ajt=s(mX);JLo=r(ajt,"Wav2Vec2PhonemeCTCTokenizer"),ajt.forEach(t),YLo=r(COe," (Wav2Vec2Phoneme model)"),COe.forEach(t),ZLo=i(S),bp=n(S,"LI",{});var wOe=s(bp);Q1e=n(wOe,"STRONG",{});var njt=s(Q1e);KLo=r(njt,"whisper"),njt.forEach(t),eyo=r(wOe," \u2014 "),cX=n(wOe,"A",{href:!0});var sjt=s(cX);oyo=r(sjt,"WhisperTokenizer"),sjt.forEach(t),ryo=r(wOe," (Whisper model)"),wOe.forEach(t),tyo=i(S),$l=n(S,"LI",{});var Fq=s($l);W1e=n(Fq,"STRONG",{});var ljt=s(W1e);ayo=r(ljt,"xclip"),ljt.forEach(t),nyo=r(Fq," \u2014 "),fX=n(Fq,"A",{href:!0});var ijt=s(fX);syo=r(ijt,"CLIPTokenizer"),ijt.forEach(t),lyo=r(Fq," or "),gX=n(Fq,"A",{href:!0});var djt=s(gX);iyo=r(djt,"CLIPTokenizerFast"),djt.forEach(t),dyo=r(Fq," (X-CLIP model)"),Fq.forEach(t),myo=i(S),kl=n(S,"LI",{});var Tq=s(kl);U1e=n(Tq,"STRONG",{});var mjt=s(U1e);cyo=r(mjt,"xglm"),mjt.forEach(t),fyo=r(Tq," \u2014 "),hX=n(Tq,"A",{href:!0});var cjt=s(hX);gyo=r(cjt,"XGLMTokenizer"),cjt.forEach(t),hyo=r(Tq," or "),uX=n(Tq,"A",{href:!0});var fjt=s(uX);uyo=r(fjt,"XGLMTokenizerFast"),fjt.forEach(t),pyo=r(Tq," (XGLM model)"),Tq.forEach(t),_yo=i(S),vp=n(S,"LI",{});var AOe=s(vp);H1e=n(AOe,"STRONG",{});var gjt=s(H1e);byo=r(gjt,"xlm"),gjt.forEach(t),vyo=r(AOe," \u2014 "),pX=n(AOe,"A",{href:!0});var hjt=s(pX);Fyo=r(hjt,"XLMTokenizer"),hjt.forEach(t),Tyo=r(AOe," (XLM model)"),AOe.forEach(t),Myo=i(S),Fp=n(S,"LI",{});var LOe=s(Fp);J1e=n(LOe,"STRONG",{});var ujt=s(J1e);Eyo=r(ujt,"xlm-prophetnet"),ujt.forEach(t),Cyo=r(LOe," \u2014 "),_X=n(LOe,"A",{href:!0});var pjt=s(_X);wyo=r(pjt,"XLMProphetNetTokenizer"),pjt.forEach(t),Ayo=r(LOe," (XLM-ProphetNet model)"),LOe.forEach(t),Lyo=i(S),Sl=n(S,"LI",{});var Mq=s(Sl);Y1e=n(Mq,"STRONG",{});var _jt=s(Y1e);yyo=r(_jt,"xlm-roberta"),_jt.forEach(t),xyo=r(Mq," \u2014 "),bX=n(Mq,"A",{href:!0});var bjt=s(bX);$yo=r(bjt,"XLMRobertaTokenizer"),bjt.forEach(t),kyo=r(Mq," or "),vX=n(Mq,"A",{href:!0});var vjt=s(vX);Syo=r(vjt,"XLMRobertaTokenizerFast"),vjt.forEach(t),Ryo=r(Mq," (XLM-RoBERTa model)"),Mq.forEach(t),Pyo=i(S),Rl=n(S,"LI",{});var Eq=s(Rl);Z1e=n(Eq,"STRONG",{});var Fjt=s(Z1e);Byo=r(Fjt,"xlm-roberta-xl"),Fjt.forEach(t),Iyo=r(Eq," \u2014 "),FX=n(Eq,"A",{href:!0});var Tjt=s(FX);Nyo=r(Tjt,"XLMRobertaTokenizer"),Tjt.forEach(t),qyo=r(Eq," or "),TX=n(Eq,"A",{href:!0});var Mjt=s(TX);Dyo=r(Mjt,"XLMRobertaTokenizerFast"),Mjt.forEach(t),jyo=r(Eq," (XLM-RoBERTa-XL model)"),Eq.forEach(t),Gyo=i(S),Pl=n(S,"LI",{});var Cq=s(Pl);K1e=n(Cq,"STRONG",{});var Ejt=s(K1e);Oyo=r(Ejt,"xlnet"),Ejt.forEach(t),Vyo=r(Cq," \u2014 "),MX=n(Cq,"A",{href:!0});var Cjt=s(MX);Xyo=r(Cjt,"XLNetTokenizer"),Cjt.forEach(t),zyo=r(Cq," or "),EX=n(Cq,"A",{href:!0});var wjt=s(EX);Qyo=r(wjt,"XLNetTokenizerFast"),wjt.forEach(t),Wyo=r(Cq," (XLNet model)"),Cq.forEach(t),Uyo=i(S),Bl=n(S,"LI",{});var wq=s(Bl);e2e=n(wq,"STRONG",{});var Ajt=s(e2e);Hyo=r(Ajt,"yoso"),Ajt.forEach(t),Jyo=r(wq," \u2014 "),CX=n(wq,"A",{href:!0});var Ljt=s(CX);Yyo=r(Ljt,"AlbertTokenizer"),Ljt.forEach(t),Zyo=r(wq," or "),wX=n(wq,"A",{href:!0});var yjt=s(wX);Kyo=r(yjt,"AlbertTokenizerFast"),yjt.forEach(t),e9o=r(wq," (YOSO model)"),wq.forEach(t),S.forEach(t),o9o=i(Ol),T(Tp.$$.fragment,Ol),Ol.forEach(t),r9o=i(Gl),Mp=n(Gl,"DIV",{class:!0});var Ido=s(Mp);T(Ck.$$.fragment,Ido),t9o=i(Ido),o2e=n(Ido,"P",{});var xjt=s(o2e);a9o=r(xjt,"Register a new tokenizer in this mapping."),xjt.forEach(t),Ido.forEach(t),Gl.forEach(t),Tlo=i(c),Nd=n(c,"H2",{class:!0});var Ndo=s(Nd);Ep=n(Ndo,"A",{id:!0,class:!0,href:!0});var $jt=s(Ep);r2e=n($jt,"SPAN",{});var kjt=s(r2e);T(wk.$$.fragment,kjt),kjt.forEach(t),$jt.forEach(t),n9o=i(Ndo),t2e=n(Ndo,"SPAN",{});var Sjt=s(t2e);s9o=r(Sjt,"AutoFeatureExtractor"),Sjt.forEach(t),Ndo.forEach(t),Mlo=i(c),No=n(c,"DIV",{class:!0});var Vl=s(No);T(Ak.$$.fragment,Vl),l9o=i(Vl),Lk=n(Vl,"P",{});var qdo=s(Lk);i9o=r(qdo,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),AX=n(qdo,"A",{href:!0});var Rjt=s(AX);d9o=r(Rjt,"AutoFeatureExtractor.from_pretrained()"),Rjt.forEach(t),m9o=r(qdo," class method."),qdo.forEach(t),c9o=i(Vl),yk=n(Vl,"P",{});var Ddo=s(yk);f9o=r(Ddo,"This class cannot be instantiated directly using "),a2e=n(Ddo,"CODE",{});var Pjt=s(a2e);g9o=r(Pjt,"__init__()"),Pjt.forEach(t),h9o=r(Ddo," (throws an error)."),Ddo.forEach(t),u9o=i(Vl),eo=n(Vl,"DIV",{class:!0});var xa=s(eo);T(xk.$$.fragment,xa),p9o=i(xa),n2e=n(xa,"P",{});var Bjt=s(n2e);_9o=r(Bjt,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),Bjt.forEach(t),b9o=i(xa),mn=n(xa,"P",{});var ex=s(mn);v9o=r(ex,"The feature extractor class to instantiate is selected based on the "),s2e=n(ex,"CODE",{});var Ijt=s(s2e);F9o=r(Ijt,"model_type"),Ijt.forEach(t),T9o=r(ex,` property of the config object
(either passed as an argument or loaded from `),l2e=n(ex,"CODE",{});var Njt=s(l2e);M9o=r(Njt,"pretrained_model_name_or_path"),Njt.forEach(t),E9o=r(ex,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),i2e=n(ex,"CODE",{});var qjt=s(i2e);C9o=r(qjt,"pretrained_model_name_or_path"),qjt.forEach(t),w9o=r(ex,":"),ex.forEach(t),A9o=i(xa),z=n(xa,"UL",{});var Q=s(z);Cp=n(Q,"LI",{});var yOe=s(Cp);d2e=n(yOe,"STRONG",{});var Djt=s(d2e);L9o=r(Djt,"beit"),Djt.forEach(t),y9o=r(yOe," \u2014 "),LX=n(yOe,"A",{href:!0});var jjt=s(LX);x9o=r(jjt,"BeitFeatureExtractor"),jjt.forEach(t),$9o=r(yOe," (BEiT model)"),yOe.forEach(t),k9o=i(Q),wp=n(Q,"LI",{});var xOe=s(wp);m2e=n(xOe,"STRONG",{});var Gjt=s(m2e);S9o=r(Gjt,"clip"),Gjt.forEach(t),R9o=r(xOe," \u2014 "),yX=n(xOe,"A",{href:!0});var Ojt=s(yX);P9o=r(Ojt,"CLIPFeatureExtractor"),Ojt.forEach(t),B9o=r(xOe," (CLIP model)"),xOe.forEach(t),I9o=i(Q),Ap=n(Q,"LI",{});var $Oe=s(Ap);c2e=n($Oe,"STRONG",{});var Vjt=s(c2e);N9o=r(Vjt,"clipseg"),Vjt.forEach(t),q9o=r($Oe," \u2014 "),xX=n($Oe,"A",{href:!0});var Xjt=s(xX);D9o=r(Xjt,"ViTFeatureExtractor"),Xjt.forEach(t),j9o=r($Oe," (CLIPSeg model)"),$Oe.forEach(t),G9o=i(Q),Lp=n(Q,"LI",{});var kOe=s(Lp);f2e=n(kOe,"STRONG",{});var zjt=s(f2e);O9o=r(zjt,"conditional_detr"),zjt.forEach(t),V9o=r(kOe," \u2014 "),$X=n(kOe,"A",{href:!0});var Qjt=s($X);X9o=r(Qjt,"ConditionalDetrFeatureExtractor"),Qjt.forEach(t),z9o=r(kOe," (Conditional DETR model)"),kOe.forEach(t),Q9o=i(Q),yp=n(Q,"LI",{});var SOe=s(yp);g2e=n(SOe,"STRONG",{});var Wjt=s(g2e);W9o=r(Wjt,"convnext"),Wjt.forEach(t),U9o=r(SOe," \u2014 "),kX=n(SOe,"A",{href:!0});var Ujt=s(kX);H9o=r(Ujt,"ConvNextFeatureExtractor"),Ujt.forEach(t),J9o=r(SOe," (ConvNeXT model)"),SOe.forEach(t),Y9o=i(Q),xp=n(Q,"LI",{});var ROe=s(xp);h2e=n(ROe,"STRONG",{});var Hjt=s(h2e);Z9o=r(Hjt,"cvt"),Hjt.forEach(t),K9o=r(ROe," \u2014 "),SX=n(ROe,"A",{href:!0});var Jjt=s(SX);exo=r(Jjt,"ConvNextFeatureExtractor"),Jjt.forEach(t),oxo=r(ROe," (CvT model)"),ROe.forEach(t),rxo=i(Q),$p=n(Q,"LI",{});var POe=s($p);u2e=n(POe,"STRONG",{});var Yjt=s(u2e);txo=r(Yjt,"data2vec-audio"),Yjt.forEach(t),axo=r(POe," \u2014 "),RX=n(POe,"A",{href:!0});var Zjt=s(RX);nxo=r(Zjt,"Wav2Vec2FeatureExtractor"),Zjt.forEach(t),sxo=r(POe," (Data2VecAudio model)"),POe.forEach(t),lxo=i(Q),kp=n(Q,"LI",{});var BOe=s(kp);p2e=n(BOe,"STRONG",{});var Kjt=s(p2e);ixo=r(Kjt,"data2vec-vision"),Kjt.forEach(t),dxo=r(BOe," \u2014 "),PX=n(BOe,"A",{href:!0});var eGt=s(PX);mxo=r(eGt,"BeitFeatureExtractor"),eGt.forEach(t),cxo=r(BOe," (Data2VecVision model)"),BOe.forEach(t),fxo=i(Q),Sp=n(Q,"LI",{});var IOe=s(Sp);_2e=n(IOe,"STRONG",{});var oGt=s(_2e);gxo=r(oGt,"deformable_detr"),oGt.forEach(t),hxo=r(IOe," \u2014 "),BX=n(IOe,"A",{href:!0});var rGt=s(BX);uxo=r(rGt,"DeformableDetrFeatureExtractor"),rGt.forEach(t),pxo=r(IOe," (Deformable DETR model)"),IOe.forEach(t),_xo=i(Q),Rp=n(Q,"LI",{});var NOe=s(Rp);b2e=n(NOe,"STRONG",{});var tGt=s(b2e);bxo=r(tGt,"deit"),tGt.forEach(t),vxo=r(NOe," \u2014 "),IX=n(NOe,"A",{href:!0});var aGt=s(IX);Fxo=r(aGt,"DeiTFeatureExtractor"),aGt.forEach(t),Txo=r(NOe," (DeiT model)"),NOe.forEach(t),Mxo=i(Q),Pp=n(Q,"LI",{});var qOe=s(Pp);v2e=n(qOe,"STRONG",{});var nGt=s(v2e);Exo=r(nGt,"detr"),nGt.forEach(t),Cxo=r(qOe," \u2014 "),NX=n(qOe,"A",{href:!0});var sGt=s(NX);wxo=r(sGt,"DetrFeatureExtractor"),sGt.forEach(t),Axo=r(qOe," (DETR model)"),qOe.forEach(t),Lxo=i(Q),Bp=n(Q,"LI",{});var DOe=s(Bp);F2e=n(DOe,"STRONG",{});var lGt=s(F2e);yxo=r(lGt,"donut-swin"),lGt.forEach(t),xxo=r(DOe," \u2014 "),qX=n(DOe,"A",{href:!0});var iGt=s(qX);$xo=r(iGt,"DonutFeatureExtractor"),iGt.forEach(t),kxo=r(DOe," (DonutSwin model)"),DOe.forEach(t),Sxo=i(Q),Ip=n(Q,"LI",{});var jOe=s(Ip);T2e=n(jOe,"STRONG",{});var dGt=s(T2e);Rxo=r(dGt,"dpt"),dGt.forEach(t),Pxo=r(jOe," \u2014 "),DX=n(jOe,"A",{href:!0});var mGt=s(DX);Bxo=r(mGt,"DPTFeatureExtractor"),mGt.forEach(t),Ixo=r(jOe," (DPT model)"),jOe.forEach(t),Nxo=i(Q),Np=n(Q,"LI",{});var GOe=s(Np);M2e=n(GOe,"STRONG",{});var cGt=s(M2e);qxo=r(cGt,"flava"),cGt.forEach(t),Dxo=r(GOe," \u2014 "),jX=n(GOe,"A",{href:!0});var fGt=s(jX);jxo=r(fGt,"FlavaFeatureExtractor"),fGt.forEach(t),Gxo=r(GOe," (FLAVA model)"),GOe.forEach(t),Oxo=i(Q),qp=n(Q,"LI",{});var OOe=s(qp);E2e=n(OOe,"STRONG",{});var gGt=s(E2e);Vxo=r(gGt,"glpn"),gGt.forEach(t),Xxo=r(OOe," \u2014 "),GX=n(OOe,"A",{href:!0});var hGt=s(GX);zxo=r(hGt,"GLPNFeatureExtractor"),hGt.forEach(t),Qxo=r(OOe," (GLPN model)"),OOe.forEach(t),Wxo=i(Q),Dp=n(Q,"LI",{});var VOe=s(Dp);C2e=n(VOe,"STRONG",{});var uGt=s(C2e);Uxo=r(uGt,"groupvit"),uGt.forEach(t),Hxo=r(VOe," \u2014 "),OX=n(VOe,"A",{href:!0});var pGt=s(OX);Jxo=r(pGt,"CLIPFeatureExtractor"),pGt.forEach(t),Yxo=r(VOe," (GroupViT model)"),VOe.forEach(t),Zxo=i(Q),jp=n(Q,"LI",{});var XOe=s(jp);w2e=n(XOe,"STRONG",{});var _Gt=s(w2e);Kxo=r(_Gt,"hubert"),_Gt.forEach(t),e$o=r(XOe," \u2014 "),VX=n(XOe,"A",{href:!0});var bGt=s(VX);o$o=r(bGt,"Wav2Vec2FeatureExtractor"),bGt.forEach(t),r$o=r(XOe," (Hubert model)"),XOe.forEach(t),t$o=i(Q),Gp=n(Q,"LI",{});var zOe=s(Gp);A2e=n(zOe,"STRONG",{});var vGt=s(A2e);a$o=r(vGt,"imagegpt"),vGt.forEach(t),n$o=r(zOe," \u2014 "),XX=n(zOe,"A",{href:!0});var FGt=s(XX);s$o=r(FGt,"ImageGPTFeatureExtractor"),FGt.forEach(t),l$o=r(zOe," (ImageGPT model)"),zOe.forEach(t),i$o=i(Q),Op=n(Q,"LI",{});var QOe=s(Op);L2e=n(QOe,"STRONG",{});var TGt=s(L2e);d$o=r(TGt,"layoutlmv2"),TGt.forEach(t),m$o=r(QOe," \u2014 "),zX=n(QOe,"A",{href:!0});var MGt=s(zX);c$o=r(MGt,"LayoutLMv2FeatureExtractor"),MGt.forEach(t),f$o=r(QOe," (LayoutLMv2 model)"),QOe.forEach(t),g$o=i(Q),Vp=n(Q,"LI",{});var WOe=s(Vp);y2e=n(WOe,"STRONG",{});var EGt=s(y2e);h$o=r(EGt,"layoutlmv3"),EGt.forEach(t),u$o=r(WOe," \u2014 "),QX=n(WOe,"A",{href:!0});var CGt=s(QX);p$o=r(CGt,"LayoutLMv3FeatureExtractor"),CGt.forEach(t),_$o=r(WOe," (LayoutLMv3 model)"),WOe.forEach(t),b$o=i(Q),Xp=n(Q,"LI",{});var UOe=s(Xp);x2e=n(UOe,"STRONG",{});var wGt=s(x2e);v$o=r(wGt,"levit"),wGt.forEach(t),F$o=r(UOe," \u2014 "),WX=n(UOe,"A",{href:!0});var AGt=s(WX);T$o=r(AGt,"LevitFeatureExtractor"),AGt.forEach(t),M$o=r(UOe," (LeViT model)"),UOe.forEach(t),E$o=i(Q),zp=n(Q,"LI",{});var HOe=s(zp);$2e=n(HOe,"STRONG",{});var LGt=s($2e);C$o=r(LGt,"maskformer"),LGt.forEach(t),w$o=r(HOe," \u2014 "),UX=n(HOe,"A",{href:!0});var yGt=s(UX);A$o=r(yGt,"MaskFormerFeatureExtractor"),yGt.forEach(t),L$o=r(HOe," (MaskFormer model)"),HOe.forEach(t),y$o=i(Q),Qp=n(Q,"LI",{});var JOe=s(Qp);k2e=n(JOe,"STRONG",{});var xGt=s(k2e);x$o=r(xGt,"mctct"),xGt.forEach(t),$$o=r(JOe," \u2014 "),HX=n(JOe,"A",{href:!0});var $Gt=s(HX);k$o=r($Gt,"MCTCTFeatureExtractor"),$Gt.forEach(t),S$o=r(JOe," (M-CTC-T model)"),JOe.forEach(t),R$o=i(Q),Wp=n(Q,"LI",{});var YOe=s(Wp);S2e=n(YOe,"STRONG",{});var kGt=s(S2e);P$o=r(kGt,"mobilevit"),kGt.forEach(t),B$o=r(YOe," \u2014 "),JX=n(YOe,"A",{href:!0});var SGt=s(JX);I$o=r(SGt,"MobileViTFeatureExtractor"),SGt.forEach(t),N$o=r(YOe," (MobileViT model)"),YOe.forEach(t),q$o=i(Q),Up=n(Q,"LI",{});var ZOe=s(Up);R2e=n(ZOe,"STRONG",{});var RGt=s(R2e);D$o=r(RGt,"owlvit"),RGt.forEach(t),j$o=r(ZOe," \u2014 "),YX=n(ZOe,"A",{href:!0});var PGt=s(YX);G$o=r(PGt,"OwlViTFeatureExtractor"),PGt.forEach(t),O$o=r(ZOe," (OWL-ViT model)"),ZOe.forEach(t),V$o=i(Q),Hp=n(Q,"LI",{});var KOe=s(Hp);P2e=n(KOe,"STRONG",{});var BGt=s(P2e);X$o=r(BGt,"perceiver"),BGt.forEach(t),z$o=r(KOe," \u2014 "),ZX=n(KOe,"A",{href:!0});var IGt=s(ZX);Q$o=r(IGt,"PerceiverFeatureExtractor"),IGt.forEach(t),W$o=r(KOe," (Perceiver model)"),KOe.forEach(t),U$o=i(Q),Jp=n(Q,"LI",{});var eVe=s(Jp);B2e=n(eVe,"STRONG",{});var NGt=s(B2e);H$o=r(NGt,"poolformer"),NGt.forEach(t),J$o=r(eVe," \u2014 "),KX=n(eVe,"A",{href:!0});var qGt=s(KX);Y$o=r(qGt,"PoolFormerFeatureExtractor"),qGt.forEach(t),Z$o=r(eVe," (PoolFormer model)"),eVe.forEach(t),K$o=i(Q),Yp=n(Q,"LI",{});var oVe=s(Yp);I2e=n(oVe,"STRONG",{});var DGt=s(I2e);eko=r(DGt,"regnet"),DGt.forEach(t),oko=r(oVe," \u2014 "),ez=n(oVe,"A",{href:!0});var jGt=s(ez);rko=r(jGt,"ConvNextFeatureExtractor"),jGt.forEach(t),tko=r(oVe," (RegNet model)"),oVe.forEach(t),ako=i(Q),Zp=n(Q,"LI",{});var rVe=s(Zp);N2e=n(rVe,"STRONG",{});var GGt=s(N2e);nko=r(GGt,"resnet"),GGt.forEach(t),sko=r(rVe," \u2014 "),oz=n(rVe,"A",{href:!0});var OGt=s(oz);lko=r(OGt,"ConvNextFeatureExtractor"),OGt.forEach(t),iko=r(rVe," (ResNet model)"),rVe.forEach(t),dko=i(Q),Kp=n(Q,"LI",{});var tVe=s(Kp);q2e=n(tVe,"STRONG",{});var VGt=s(q2e);mko=r(VGt,"segformer"),VGt.forEach(t),cko=r(tVe," \u2014 "),rz=n(tVe,"A",{href:!0});var XGt=s(rz);fko=r(XGt,"SegformerFeatureExtractor"),XGt.forEach(t),gko=r(tVe," (SegFormer model)"),tVe.forEach(t),hko=i(Q),e_=n(Q,"LI",{});var aVe=s(e_);D2e=n(aVe,"STRONG",{});var zGt=s(D2e);uko=r(zGt,"speech_to_text"),zGt.forEach(t),pko=r(aVe," \u2014 "),tz=n(aVe,"A",{href:!0});var QGt=s(tz);_ko=r(QGt,"Speech2TextFeatureExtractor"),QGt.forEach(t),bko=r(aVe," (Speech2Text model)"),aVe.forEach(t),vko=i(Q),o_=n(Q,"LI",{});var nVe=s(o_);j2e=n(nVe,"STRONG",{});var WGt=s(j2e);Fko=r(WGt,"swin"),WGt.forEach(t),Tko=r(nVe," \u2014 "),az=n(nVe,"A",{href:!0});var UGt=s(az);Mko=r(UGt,"ViTFeatureExtractor"),UGt.forEach(t),Eko=r(nVe," (Swin Transformer model)"),nVe.forEach(t),Cko=i(Q),r_=n(Q,"LI",{});var sVe=s(r_);G2e=n(sVe,"STRONG",{});var HGt=s(G2e);wko=r(HGt,"swinv2"),HGt.forEach(t),Ako=r(sVe," \u2014 "),nz=n(sVe,"A",{href:!0});var JGt=s(nz);Lko=r(JGt,"ViTFeatureExtractor"),JGt.forEach(t),yko=r(sVe," (Swin Transformer V2 model)"),sVe.forEach(t),xko=i(Q),t_=n(Q,"LI",{});var lVe=s(t_);O2e=n(lVe,"STRONG",{});var YGt=s(O2e);$ko=r(YGt,"table-transformer"),YGt.forEach(t),kko=r(lVe," \u2014 "),sz=n(lVe,"A",{href:!0});var ZGt=s(sz);Sko=r(ZGt,"DetrFeatureExtractor"),ZGt.forEach(t),Rko=r(lVe," (Table Transformer model)"),lVe.forEach(t),Pko=i(Q),a_=n(Q,"LI",{});var iVe=s(a_);V2e=n(iVe,"STRONG",{});var KGt=s(V2e);Bko=r(KGt,"van"),KGt.forEach(t),Iko=r(iVe," \u2014 "),lz=n(iVe,"A",{href:!0});var eOt=s(lz);Nko=r(eOt,"ConvNextFeatureExtractor"),eOt.forEach(t),qko=r(iVe," (VAN model)"),iVe.forEach(t),Dko=i(Q),n_=n(Q,"LI",{});var dVe=s(n_);X2e=n(dVe,"STRONG",{});var oOt=s(X2e);jko=r(oOt,"videomae"),oOt.forEach(t),Gko=r(dVe," \u2014 "),iz=n(dVe,"A",{href:!0});var rOt=s(iz);Oko=r(rOt,"VideoMAEFeatureExtractor"),rOt.forEach(t),Vko=r(dVe," (VideoMAE model)"),dVe.forEach(t),Xko=i(Q),s_=n(Q,"LI",{});var mVe=s(s_);z2e=n(mVe,"STRONG",{});var tOt=s(z2e);zko=r(tOt,"vilt"),tOt.forEach(t),Qko=r(mVe," \u2014 "),dz=n(mVe,"A",{href:!0});var aOt=s(dz);Wko=r(aOt,"ViltFeatureExtractor"),aOt.forEach(t),Uko=r(mVe," (ViLT model)"),mVe.forEach(t),Hko=i(Q),l_=n(Q,"LI",{});var cVe=s(l_);Q2e=n(cVe,"STRONG",{});var nOt=s(Q2e);Jko=r(nOt,"vit"),nOt.forEach(t),Yko=r(cVe," \u2014 "),mz=n(cVe,"A",{href:!0});var sOt=s(mz);Zko=r(sOt,"ViTFeatureExtractor"),sOt.forEach(t),Kko=r(cVe," (ViT model)"),cVe.forEach(t),eSo=i(Q),i_=n(Q,"LI",{});var fVe=s(i_);W2e=n(fVe,"STRONG",{});var lOt=s(W2e);oSo=r(lOt,"vit_mae"),lOt.forEach(t),rSo=r(fVe," \u2014 "),cz=n(fVe,"A",{href:!0});var iOt=s(cz);tSo=r(iOt,"ViTFeatureExtractor"),iOt.forEach(t),aSo=r(fVe," (ViTMAE model)"),fVe.forEach(t),nSo=i(Q),d_=n(Q,"LI",{});var gVe=s(d_);U2e=n(gVe,"STRONG",{});var dOt=s(U2e);sSo=r(dOt,"vit_msn"),dOt.forEach(t),lSo=r(gVe," \u2014 "),fz=n(gVe,"A",{href:!0});var mOt=s(fz);iSo=r(mOt,"ViTFeatureExtractor"),mOt.forEach(t),dSo=r(gVe," (ViTMSN model)"),gVe.forEach(t),mSo=i(Q),m_=n(Q,"LI",{});var hVe=s(m_);H2e=n(hVe,"STRONG",{});var cOt=s(H2e);cSo=r(cOt,"wav2vec2"),cOt.forEach(t),fSo=r(hVe," \u2014 "),gz=n(hVe,"A",{href:!0});var fOt=s(gz);gSo=r(fOt,"Wav2Vec2FeatureExtractor"),fOt.forEach(t),hSo=r(hVe," (Wav2Vec2 model)"),hVe.forEach(t),uSo=i(Q),c_=n(Q,"LI",{});var uVe=s(c_);J2e=n(uVe,"STRONG",{});var gOt=s(J2e);pSo=r(gOt,"wav2vec2-conformer"),gOt.forEach(t),_So=r(uVe," \u2014 "),hz=n(uVe,"A",{href:!0});var hOt=s(hz);bSo=r(hOt,"Wav2Vec2FeatureExtractor"),hOt.forEach(t),vSo=r(uVe," (Wav2Vec2-Conformer model)"),uVe.forEach(t),FSo=i(Q),f_=n(Q,"LI",{});var pVe=s(f_);Y2e=n(pVe,"STRONG",{});var uOt=s(Y2e);TSo=r(uOt,"whisper"),uOt.forEach(t),MSo=r(pVe," \u2014 "),uz=n(pVe,"A",{href:!0});var pOt=s(uz);ESo=r(pOt,"WhisperFeatureExtractor"),pOt.forEach(t),CSo=r(pVe," (Whisper model)"),pVe.forEach(t),wSo=i(Q),g_=n(Q,"LI",{});var _Ve=s(g_);Z2e=n(_Ve,"STRONG",{});var _Ot=s(Z2e);ASo=r(_Ot,"xclip"),_Ot.forEach(t),LSo=r(_Ve," \u2014 "),pz=n(_Ve,"A",{href:!0});var bOt=s(pz);ySo=r(bOt,"CLIPFeatureExtractor"),bOt.forEach(t),xSo=r(_Ve," (X-CLIP model)"),_Ve.forEach(t),$So=i(Q),h_=n(Q,"LI",{});var bVe=s(h_);K2e=n(bVe,"STRONG",{});var vOt=s(K2e);kSo=r(vOt,"yolos"),vOt.forEach(t),SSo=r(bVe," \u2014 "),_z=n(bVe,"A",{href:!0});var FOt=s(_z);RSo=r(FOt,"YolosFeatureExtractor"),FOt.forEach(t),PSo=r(bVe," (YOLOS model)"),bVe.forEach(t),Q.forEach(t),BSo=i(xa),T(u_.$$.fragment,xa),ISo=i(xa),T(p_.$$.fragment,xa),xa.forEach(t),NSo=i(Vl),__=n(Vl,"DIV",{class:!0});var jdo=s(__);T($k.$$.fragment,jdo),qSo=i(jdo),ebe=n(jdo,"P",{});var TOt=s(ebe);DSo=r(TOt,"Register a new feature extractor for this class."),TOt.forEach(t),jdo.forEach(t),Vl.forEach(t),Elo=i(c),qd=n(c,"H2",{class:!0});var Gdo=s(qd);b_=n(Gdo,"A",{id:!0,class:!0,href:!0});var MOt=s(b_);obe=n(MOt,"SPAN",{});var EOt=s(obe);T(kk.$$.fragment,EOt),EOt.forEach(t),MOt.forEach(t),jSo=i(Gdo),rbe=n(Gdo,"SPAN",{});var COt=s(rbe);GSo=r(COt,"AutoImageProcessor"),COt.forEach(t),Gdo.forEach(t),Clo=i(c),qo=n(c,"DIV",{class:!0});var Xl=s(qo);T(Sk.$$.fragment,Xl),OSo=i(Xl),Rk=n(Xl,"P",{});var Odo=s(Rk);VSo=r(Odo,`This is a generic image processor class that will be instantiated as one of the image processor classes of the
library when created with the `),bz=n(Odo,"A",{href:!0});var wOt=s(bz);XSo=r(wOt,"AutoImageProcessor.from_pretrained()"),wOt.forEach(t),zSo=r(Odo," class method."),Odo.forEach(t),QSo=i(Xl),Pk=n(Xl,"P",{});var Vdo=s(Pk);WSo=r(Vdo,"This class cannot be instantiated directly using "),tbe=n(Vdo,"CODE",{});var AOt=s(tbe);USo=r(AOt,"__init__()"),AOt.forEach(t),HSo=r(Vdo," (throws an error)."),Vdo.forEach(t),JSo=i(Xl),oo=n(Xl,"DIV",{class:!0});var $a=s(oo);T(Bk.$$.fragment,$a),YSo=i($a),abe=n($a,"P",{});var LOt=s(abe);ZSo=r(LOt,"Instantiate one of the image processor classes of the library from a pretrained model vocabulary."),LOt.forEach(t),KSo=i($a),cn=n($a,"P",{});var ox=s(cn);eRo=r(ox,"The image processor class to instantiate is selected based on the "),nbe=n(ox,"CODE",{});var yOt=s(nbe);oRo=r(yOt,"model_type"),yOt.forEach(t),rRo=r(ox,` property of the config object
(either passed as an argument or loaded from `),sbe=n(ox,"CODE",{});var xOt=s(sbe);tRo=r(xOt,"pretrained_model_name_or_path"),xOt.forEach(t),aRo=r(ox,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),lbe=n(ox,"CODE",{});var $Ot=s(lbe);nRo=r($Ot,"pretrained_model_name_or_path"),$Ot.forEach(t),sRo=r(ox,":"),ox.forEach(t),lRo=i($a),re=n($a,"UL",{});var ae=s(re);v_=n(ae,"LI",{});var vVe=s(v_);ibe=n(vVe,"STRONG",{});var kOt=s(ibe);iRo=r(kOt,"beit"),kOt.forEach(t),dRo=r(vVe," \u2014 "),vz=n(vVe,"A",{href:!0});var SOt=s(vz);mRo=r(SOt,"BeitImageProcessor"),SOt.forEach(t),cRo=r(vVe," (BEiT model)"),vVe.forEach(t),fRo=i(ae),F_=n(ae,"LI",{});var FVe=s(F_);dbe=n(FVe,"STRONG",{});var ROt=s(dbe);gRo=r(ROt,"clip"),ROt.forEach(t),hRo=r(FVe," \u2014 "),Fz=n(FVe,"A",{href:!0});var POt=s(Fz);uRo=r(POt,"CLIPImageProcessor"),POt.forEach(t),pRo=r(FVe," (CLIP model)"),FVe.forEach(t),_Ro=i(ae),T_=n(ae,"LI",{});var TVe=s(T_);mbe=n(TVe,"STRONG",{});var BOt=s(mbe);bRo=r(BOt,"convnext"),BOt.forEach(t),vRo=r(TVe," \u2014 "),Tz=n(TVe,"A",{href:!0});var IOt=s(Tz);FRo=r(IOt,"ConvNextImageProcessor"),IOt.forEach(t),TRo=r(TVe," (ConvNeXT model)"),TVe.forEach(t),MRo=i(ae),M_=n(ae,"LI",{});var MVe=s(M_);cbe=n(MVe,"STRONG",{});var NOt=s(cbe);ERo=r(NOt,"cvt"),NOt.forEach(t),CRo=r(MVe," \u2014 "),Mz=n(MVe,"A",{href:!0});var qOt=s(Mz);wRo=r(qOt,"ConvNextImageProcessor"),qOt.forEach(t),ARo=r(MVe," (CvT model)"),MVe.forEach(t),LRo=i(ae),E_=n(ae,"LI",{});var EVe=s(E_);fbe=n(EVe,"STRONG",{});var DOt=s(fbe);yRo=r(DOt,"data2vec-vision"),DOt.forEach(t),xRo=r(EVe," \u2014 "),Ez=n(EVe,"A",{href:!0});var jOt=s(Ez);$Ro=r(jOt,"BeitImageProcessor"),jOt.forEach(t),kRo=r(EVe," (Data2VecVision model)"),EVe.forEach(t),SRo=i(ae),C_=n(ae,"LI",{});var CVe=s(C_);gbe=n(CVe,"STRONG",{});var GOt=s(gbe);RRo=r(GOt,"deit"),GOt.forEach(t),PRo=r(CVe," \u2014 "),Cz=n(CVe,"A",{href:!0});var OOt=s(Cz);BRo=r(OOt,"DeiTImageProcessor"),OOt.forEach(t),IRo=r(CVe," (DeiT model)"),CVe.forEach(t),NRo=i(ae),w_=n(ae,"LI",{});var wVe=s(w_);hbe=n(wVe,"STRONG",{});var VOt=s(hbe);qRo=r(VOt,"dpt"),VOt.forEach(t),DRo=r(wVe," \u2014 "),wz=n(wVe,"A",{href:!0});var XOt=s(wz);jRo=r(XOt,"DPTImageProcessor"),XOt.forEach(t),GRo=r(wVe," (DPT model)"),wVe.forEach(t),ORo=i(ae),A_=n(ae,"LI",{});var AVe=s(A_);ube=n(AVe,"STRONG",{});var zOt=s(ube);VRo=r(zOt,"flava"),zOt.forEach(t),XRo=r(AVe," \u2014 "),Az=n(AVe,"A",{href:!0});var QOt=s(Az);zRo=r(QOt,"FlavaImageProcessor"),QOt.forEach(t),QRo=r(AVe," (FLAVA model)"),AVe.forEach(t),WRo=i(ae),L_=n(ae,"LI",{});var LVe=s(L_);pbe=n(LVe,"STRONG",{});var WOt=s(pbe);URo=r(WOt,"glpn"),WOt.forEach(t),HRo=r(LVe," \u2014 "),Lz=n(LVe,"A",{href:!0});var UOt=s(Lz);JRo=r(UOt,"GLPNImageProcessor"),UOt.forEach(t),YRo=r(LVe," (GLPN model)"),LVe.forEach(t),ZRo=i(ae),y_=n(ae,"LI",{});var yVe=s(y_);_be=n(yVe,"STRONG",{});var HOt=s(_be);KRo=r(HOt,"groupvit"),HOt.forEach(t),ePo=r(yVe," \u2014 "),yz=n(yVe,"A",{href:!0});var JOt=s(yz);oPo=r(JOt,"CLIPImageProcessor"),JOt.forEach(t),rPo=r(yVe," (GroupViT model)"),yVe.forEach(t),tPo=i(ae),x_=n(ae,"LI",{});var xVe=s(x_);bbe=n(xVe,"STRONG",{});var YOt=s(bbe);aPo=r(YOt,"imagegpt"),YOt.forEach(t),nPo=r(xVe," \u2014 "),xz=n(xVe,"A",{href:!0});var ZOt=s(xz);sPo=r(ZOt,"ImageGPTImageProcessor"),ZOt.forEach(t),lPo=r(xVe," (ImageGPT model)"),xVe.forEach(t),iPo=i(ae),$_=n(ae,"LI",{});var $Ve=s($_);vbe=n($Ve,"STRONG",{});var KOt=s(vbe);dPo=r(KOt,"layoutlmv2"),KOt.forEach(t),mPo=r($Ve," \u2014 "),$z=n($Ve,"A",{href:!0});var eVt=s($z);cPo=r(eVt,"LayoutLMv2ImageProcessor"),eVt.forEach(t),fPo=r($Ve," (LayoutLMv2 model)"),$Ve.forEach(t),gPo=i(ae),k_=n(ae,"LI",{});var kVe=s(k_);Fbe=n(kVe,"STRONG",{});var oVt=s(Fbe);hPo=r(oVt,"layoutlmv3"),oVt.forEach(t),uPo=r(kVe," \u2014 "),kz=n(kVe,"A",{href:!0});var rVt=s(kz);pPo=r(rVt,"LayoutLMv3ImageProcessor"),rVt.forEach(t),_Po=r(kVe," (LayoutLMv3 model)"),kVe.forEach(t),bPo=i(ae),S_=n(ae,"LI",{});var SVe=s(S_);Tbe=n(SVe,"STRONG",{});var tVt=s(Tbe);vPo=r(tVt,"levit"),tVt.forEach(t),FPo=r(SVe," \u2014 "),Sz=n(SVe,"A",{href:!0});var aVt=s(Sz);TPo=r(aVt,"LevitImageProcessor"),aVt.forEach(t),MPo=r(SVe," (LeViT model)"),SVe.forEach(t),EPo=i(ae),R_=n(ae,"LI",{});var RVe=s(R_);Mbe=n(RVe,"STRONG",{});var nVt=s(Mbe);CPo=r(nVt,"mobilevit"),nVt.forEach(t),wPo=r(RVe," \u2014 "),Rz=n(RVe,"A",{href:!0});var sVt=s(Rz);APo=r(sVt,"MobileViTImageProcessor"),sVt.forEach(t),LPo=r(RVe," (MobileViT model)"),RVe.forEach(t),yPo=i(ae),P_=n(ae,"LI",{});var PVe=s(P_);Ebe=n(PVe,"STRONG",{});var lVt=s(Ebe);xPo=r(lVt,"perceiver"),lVt.forEach(t),$Po=r(PVe," \u2014 "),Pz=n(PVe,"A",{href:!0});var iVt=s(Pz);kPo=r(iVt,"PerceiverImageProcessor"),iVt.forEach(t),SPo=r(PVe," (Perceiver model)"),PVe.forEach(t),RPo=i(ae),B_=n(ae,"LI",{});var BVe=s(B_);Cbe=n(BVe,"STRONG",{});var dVt=s(Cbe);PPo=r(dVt,"poolformer"),dVt.forEach(t),BPo=r(BVe," \u2014 "),Bz=n(BVe,"A",{href:!0});var mVt=s(Bz);IPo=r(mVt,"PoolFormerImageProcessor"),mVt.forEach(t),NPo=r(BVe," (PoolFormer model)"),BVe.forEach(t),qPo=i(ae),I_=n(ae,"LI",{});var IVe=s(I_);wbe=n(IVe,"STRONG",{});var cVt=s(wbe);DPo=r(cVt,"regnet"),cVt.forEach(t),jPo=r(IVe," \u2014 "),Iz=n(IVe,"A",{href:!0});var fVt=s(Iz);GPo=r(fVt,"ConvNextImageProcessor"),fVt.forEach(t),OPo=r(IVe," (RegNet model)"),IVe.forEach(t),VPo=i(ae),N_=n(ae,"LI",{});var NVe=s(N_);Abe=n(NVe,"STRONG",{});var gVt=s(Abe);XPo=r(gVt,"resnet"),gVt.forEach(t),zPo=r(NVe," \u2014 "),Nz=n(NVe,"A",{href:!0});var hVt=s(Nz);QPo=r(hVt,"ConvNextImageProcessor"),hVt.forEach(t),WPo=r(NVe," (ResNet model)"),NVe.forEach(t),UPo=i(ae),q_=n(ae,"LI",{});var qVe=s(q_);Lbe=n(qVe,"STRONG",{});var uVt=s(Lbe);HPo=r(uVt,"segformer"),uVt.forEach(t),JPo=r(qVe," \u2014 "),qz=n(qVe,"A",{href:!0});var pVt=s(qz);YPo=r(pVt,"SegformerImageProcessor"),pVt.forEach(t),ZPo=r(qVe," (SegFormer model)"),qVe.forEach(t),KPo=i(ae),D_=n(ae,"LI",{});var DVe=s(D_);ybe=n(DVe,"STRONG",{});var _Vt=s(ybe);eBo=r(_Vt,"swin"),_Vt.forEach(t),oBo=r(DVe," \u2014 "),Dz=n(DVe,"A",{href:!0});var bVt=s(Dz);rBo=r(bVt,"ViTImageProcessor"),bVt.forEach(t),tBo=r(DVe," (Swin Transformer model)"),DVe.forEach(t),aBo=i(ae),j_=n(ae,"LI",{});var jVe=s(j_);xbe=n(jVe,"STRONG",{});var vVt=s(xbe);nBo=r(vVt,"swinv2"),vVt.forEach(t),sBo=r(jVe," \u2014 "),jz=n(jVe,"A",{href:!0});var FVt=s(jz);lBo=r(FVt,"ViTImageProcessor"),FVt.forEach(t),iBo=r(jVe," (Swin Transformer V2 model)"),jVe.forEach(t),dBo=i(ae),G_=n(ae,"LI",{});var GVe=s(G_);$be=n(GVe,"STRONG",{});var TVt=s($be);mBo=r(TVt,"van"),TVt.forEach(t),cBo=r(GVe," \u2014 "),Gz=n(GVe,"A",{href:!0});var MVt=s(Gz);fBo=r(MVt,"ConvNextImageProcessor"),MVt.forEach(t),gBo=r(GVe," (VAN model)"),GVe.forEach(t),hBo=i(ae),O_=n(ae,"LI",{});var OVe=s(O_);kbe=n(OVe,"STRONG",{});var EVt=s(kbe);uBo=r(EVt,"videomae"),EVt.forEach(t),pBo=r(OVe," \u2014 "),Oz=n(OVe,"A",{href:!0});var CVt=s(Oz);_Bo=r(CVt,"VideoMAEImageProcessor"),CVt.forEach(t),bBo=r(OVe," (VideoMAE model)"),OVe.forEach(t),vBo=i(ae),V_=n(ae,"LI",{});var VVe=s(V_);Sbe=n(VVe,"STRONG",{});var wVt=s(Sbe);FBo=r(wVt,"vilt"),wVt.forEach(t),TBo=r(VVe," \u2014 "),Vz=n(VVe,"A",{href:!0});var AVt=s(Vz);MBo=r(AVt,"ViltImageProcessor"),AVt.forEach(t),EBo=r(VVe," (ViLT model)"),VVe.forEach(t),CBo=i(ae),X_=n(ae,"LI",{});var XVe=s(X_);Rbe=n(XVe,"STRONG",{});var LVt=s(Rbe);wBo=r(LVt,"vit"),LVt.forEach(t),ABo=r(XVe," \u2014 "),Xz=n(XVe,"A",{href:!0});var yVt=s(Xz);LBo=r(yVt,"ViTImageProcessor"),yVt.forEach(t),yBo=r(XVe," (ViT model)"),XVe.forEach(t),xBo=i(ae),z_=n(ae,"LI",{});var zVe=s(z_);Pbe=n(zVe,"STRONG",{});var xVt=s(Pbe);$Bo=r(xVt,"vit_mae"),xVt.forEach(t),kBo=r(zVe," \u2014 "),zz=n(zVe,"A",{href:!0});var $Vt=s(zz);SBo=r($Vt,"ViTImageProcessor"),$Vt.forEach(t),RBo=r(zVe," (ViTMAE model)"),zVe.forEach(t),PBo=i(ae),Q_=n(ae,"LI",{});var QVe=s(Q_);Bbe=n(QVe,"STRONG",{});var kVt=s(Bbe);BBo=r(kVt,"vit_msn"),kVt.forEach(t),IBo=r(QVe," \u2014 "),Qz=n(QVe,"A",{href:!0});var SVt=s(Qz);NBo=r(SVt,"ViTImageProcessor"),SVt.forEach(t),qBo=r(QVe," (ViTMSN model)"),QVe.forEach(t),DBo=i(ae),W_=n(ae,"LI",{});var WVe=s(W_);Ibe=n(WVe,"STRONG",{});var RVt=s(Ibe);jBo=r(RVt,"xclip"),RVt.forEach(t),GBo=r(WVe," \u2014 "),Wz=n(WVe,"A",{href:!0});var PVt=s(Wz);OBo=r(PVt,"CLIPImageProcessor"),PVt.forEach(t),VBo=r(WVe," (X-CLIP model)"),WVe.forEach(t),ae.forEach(t),XBo=i($a),T(U_.$$.fragment,$a),zBo=i($a),T(H_.$$.fragment,$a),$a.forEach(t),QBo=i(Xl),J_=n(Xl,"DIV",{class:!0});var Xdo=s(J_);T(Ik.$$.fragment,Xdo),WBo=i(Xdo),Nbe=n(Xdo,"P",{});var BVt=s(Nbe);UBo=r(BVt,"Register a new image processor for this class."),BVt.forEach(t),Xdo.forEach(t),Xl.forEach(t),wlo=i(c),Dd=n(c,"H2",{class:!0});var zdo=s(Dd);Y_=n(zdo,"A",{id:!0,class:!0,href:!0});var IVt=s(Y_);qbe=n(IVt,"SPAN",{});var NVt=s(qbe);T(Nk.$$.fragment,NVt),NVt.forEach(t),IVt.forEach(t),HBo=i(zdo),Dbe=n(zdo,"SPAN",{});var qVt=s(Dbe);JBo=r(qVt,"AutoProcessor"),qVt.forEach(t),zdo.forEach(t),Alo=i(c),Do=n(c,"DIV",{class:!0});var zl=s(Do);T(qk.$$.fragment,zl),YBo=i(zl),Dk=n(zl,"P",{});var Qdo=s(Dk);ZBo=r(Qdo,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),Uz=n(Qdo,"A",{href:!0});var DVt=s(Uz);KBo=r(DVt,"AutoProcessor.from_pretrained()"),DVt.forEach(t),eIo=r(Qdo," class method."),Qdo.forEach(t),oIo=i(zl),jk=n(zl,"P",{});var Wdo=s(jk);rIo=r(Wdo,"This class cannot be instantiated directly using "),jbe=n(Wdo,"CODE",{});var jVt=s(jbe);tIo=r(jVt,"__init__()"),jVt.forEach(t),aIo=r(Wdo," (throws an error)."),Wdo.forEach(t),nIo=i(zl),ro=n(zl,"DIV",{class:!0});var ka=s(ro);T(Gk.$$.fragment,ka),sIo=i(ka),Gbe=n(ka,"P",{});var GVt=s(Gbe);lIo=r(GVt,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),GVt.forEach(t),iIo=i(ka),jd=n(ka,"P",{});var tfe=s(jd);dIo=r(tfe,"The processor class to instantiate is selected based on the "),Obe=n(tfe,"CODE",{});var OVt=s(Obe);mIo=r(OVt,"model_type"),OVt.forEach(t),cIo=r(tfe,` property of the config object (either
passed as an argument or loaded from `),Vbe=n(tfe,"CODE",{});var VVt=s(Vbe);fIo=r(VVt,"pretrained_model_name_or_path"),VVt.forEach(t),gIo=r(tfe," if possible):"),tfe.forEach(t),hIo=i(ka),ie=n(ka,"UL",{});var ce=s(ie);Z_=n(ce,"LI",{});var UVe=s(Z_);Xbe=n(UVe,"STRONG",{});var XVt=s(Xbe);uIo=r(XVt,"clip"),XVt.forEach(t),pIo=r(UVe," \u2014 "),Hz=n(UVe,"A",{href:!0});var zVt=s(Hz);_Io=r(zVt,"CLIPProcessor"),zVt.forEach(t),bIo=r(UVe," (CLIP model)"),UVe.forEach(t),vIo=i(ce),K_=n(ce,"LI",{});var HVe=s(K_);zbe=n(HVe,"STRONG",{});var QVt=s(zbe);FIo=r(QVt,"clipseg"),QVt.forEach(t),TIo=r(HVe," \u2014 "),Jz=n(HVe,"A",{href:!0});var WVt=s(Jz);MIo=r(WVt,"CLIPSegProcessor"),WVt.forEach(t),EIo=r(HVe," (CLIPSeg model)"),HVe.forEach(t),CIo=i(ce),e1=n(ce,"LI",{});var JVe=s(e1);Qbe=n(JVe,"STRONG",{});var UVt=s(Qbe);wIo=r(UVt,"flava"),UVt.forEach(t),AIo=r(JVe," \u2014 "),Yz=n(JVe,"A",{href:!0});var HVt=s(Yz);LIo=r(HVt,"FlavaProcessor"),HVt.forEach(t),yIo=r(JVe," (FLAVA model)"),JVe.forEach(t),xIo=i(ce),o1=n(ce,"LI",{});var YVe=s(o1);Wbe=n(YVe,"STRONG",{});var JVt=s(Wbe);$Io=r(JVt,"groupvit"),JVt.forEach(t),kIo=r(YVe," \u2014 "),Zz=n(YVe,"A",{href:!0});var YVt=s(Zz);SIo=r(YVt,"CLIPProcessor"),YVt.forEach(t),RIo=r(YVe," (GroupViT model)"),YVe.forEach(t),PIo=i(ce),r1=n(ce,"LI",{});var ZVe=s(r1);Ube=n(ZVe,"STRONG",{});var ZVt=s(Ube);BIo=r(ZVt,"layoutlmv2"),ZVt.forEach(t),IIo=r(ZVe," \u2014 "),Kz=n(ZVe,"A",{href:!0});var KVt=s(Kz);NIo=r(KVt,"LayoutLMv2Processor"),KVt.forEach(t),qIo=r(ZVe," (LayoutLMv2 model)"),ZVe.forEach(t),DIo=i(ce),t1=n(ce,"LI",{});var KVe=s(t1);Hbe=n(KVe,"STRONG",{});var eXt=s(Hbe);jIo=r(eXt,"layoutlmv3"),eXt.forEach(t),GIo=r(KVe," \u2014 "),eQ=n(KVe,"A",{href:!0});var oXt=s(eQ);OIo=r(oXt,"LayoutLMv3Processor"),oXt.forEach(t),VIo=r(KVe," (LayoutLMv3 model)"),KVe.forEach(t),XIo=i(ce),a1=n(ce,"LI",{});var eXe=s(a1);Jbe=n(eXe,"STRONG",{});var rXt=s(Jbe);zIo=r(rXt,"layoutxlm"),rXt.forEach(t),QIo=r(eXe," \u2014 "),oQ=n(eXe,"A",{href:!0});var tXt=s(oQ);WIo=r(tXt,"LayoutXLMProcessor"),tXt.forEach(t),UIo=r(eXe," (LayoutXLM model)"),eXe.forEach(t),HIo=i(ce),n1=n(ce,"LI",{});var oXe=s(n1);Ybe=n(oXe,"STRONG",{});var aXt=s(Ybe);JIo=r(aXt,"markuplm"),aXt.forEach(t),YIo=r(oXe," \u2014 "),rQ=n(oXe,"A",{href:!0});var nXt=s(rQ);ZIo=r(nXt,"MarkupLMProcessor"),nXt.forEach(t),KIo=r(oXe," (MarkupLM model)"),oXe.forEach(t),eNo=i(ce),s1=n(ce,"LI",{});var rXe=s(s1);Zbe=n(rXe,"STRONG",{});var sXt=s(Zbe);oNo=r(sXt,"owlvit"),sXt.forEach(t),rNo=r(rXe," \u2014 "),tQ=n(rXe,"A",{href:!0});var lXt=s(tQ);tNo=r(lXt,"OwlViTProcessor"),lXt.forEach(t),aNo=r(rXe," (OWL-ViT model)"),rXe.forEach(t),nNo=i(ce),l1=n(ce,"LI",{});var tXe=s(l1);Kbe=n(tXe,"STRONG",{});var iXt=s(Kbe);sNo=r(iXt,"sew"),iXt.forEach(t),lNo=r(tXe," \u2014 "),aQ=n(tXe,"A",{href:!0});var dXt=s(aQ);iNo=r(dXt,"Wav2Vec2Processor"),dXt.forEach(t),dNo=r(tXe," (SEW model)"),tXe.forEach(t),mNo=i(ce),i1=n(ce,"LI",{});var aXe=s(i1);eve=n(aXe,"STRONG",{});var mXt=s(eve);cNo=r(mXt,"sew-d"),mXt.forEach(t),fNo=r(aXe," \u2014 "),nQ=n(aXe,"A",{href:!0});var cXt=s(nQ);gNo=r(cXt,"Wav2Vec2Processor"),cXt.forEach(t),hNo=r(aXe," (SEW-D model)"),aXe.forEach(t),uNo=i(ce),d1=n(ce,"LI",{});var nXe=s(d1);ove=n(nXe,"STRONG",{});var fXt=s(ove);pNo=r(fXt,"speech_to_text"),fXt.forEach(t),_No=r(nXe," \u2014 "),sQ=n(nXe,"A",{href:!0});var gXt=s(sQ);bNo=r(gXt,"Speech2TextProcessor"),gXt.forEach(t),vNo=r(nXe," (Speech2Text model)"),nXe.forEach(t),FNo=i(ce),m1=n(ce,"LI",{});var sXe=s(m1);rve=n(sXe,"STRONG",{});var hXt=s(rve);TNo=r(hXt,"speech_to_text_2"),hXt.forEach(t),MNo=r(sXe," \u2014 "),lQ=n(sXe,"A",{href:!0});var uXt=s(lQ);ENo=r(uXt,"Speech2Text2Processor"),uXt.forEach(t),CNo=r(sXe," (Speech2Text2 model)"),sXe.forEach(t),wNo=i(ce),c1=n(ce,"LI",{});var lXe=s(c1);tve=n(lXe,"STRONG",{});var pXt=s(tve);ANo=r(pXt,"trocr"),pXt.forEach(t),LNo=r(lXe," \u2014 "),iQ=n(lXe,"A",{href:!0});var _Xt=s(iQ);yNo=r(_Xt,"TrOCRProcessor"),_Xt.forEach(t),xNo=r(lXe," (TrOCR model)"),lXe.forEach(t),$No=i(ce),f1=n(ce,"LI",{});var iXe=s(f1);ave=n(iXe,"STRONG",{});var bXt=s(ave);kNo=r(bXt,"unispeech"),bXt.forEach(t),SNo=r(iXe," \u2014 "),dQ=n(iXe,"A",{href:!0});var vXt=s(dQ);RNo=r(vXt,"Wav2Vec2Processor"),vXt.forEach(t),PNo=r(iXe," (UniSpeech model)"),iXe.forEach(t),BNo=i(ce),g1=n(ce,"LI",{});var dXe=s(g1);nve=n(dXe,"STRONG",{});var FXt=s(nve);INo=r(FXt,"unispeech-sat"),FXt.forEach(t),NNo=r(dXe," \u2014 "),mQ=n(dXe,"A",{href:!0});var TXt=s(mQ);qNo=r(TXt,"Wav2Vec2Processor"),TXt.forEach(t),DNo=r(dXe," (UniSpeechSat model)"),dXe.forEach(t),jNo=i(ce),h1=n(ce,"LI",{});var mXe=s(h1);sve=n(mXe,"STRONG",{});var MXt=s(sve);GNo=r(MXt,"vilt"),MXt.forEach(t),ONo=r(mXe," \u2014 "),cQ=n(mXe,"A",{href:!0});var EXt=s(cQ);VNo=r(EXt,"ViltProcessor"),EXt.forEach(t),XNo=r(mXe," (ViLT model)"),mXe.forEach(t),zNo=i(ce),u1=n(ce,"LI",{});var cXe=s(u1);lve=n(cXe,"STRONG",{});var CXt=s(lve);QNo=r(CXt,"vision-text-dual-encoder"),CXt.forEach(t),WNo=r(cXe," \u2014 "),fQ=n(cXe,"A",{href:!0});var wXt=s(fQ);UNo=r(wXt,"VisionTextDualEncoderProcessor"),wXt.forEach(t),HNo=r(cXe," (VisionTextDualEncoder model)"),cXe.forEach(t),JNo=i(ce),p1=n(ce,"LI",{});var fXe=s(p1);ive=n(fXe,"STRONG",{});var AXt=s(ive);YNo=r(AXt,"wav2vec2"),AXt.forEach(t),ZNo=r(fXe," \u2014 "),gQ=n(fXe,"A",{href:!0});var LXt=s(gQ);KNo=r(LXt,"Wav2Vec2Processor"),LXt.forEach(t),eqo=r(fXe," (Wav2Vec2 model)"),fXe.forEach(t),oqo=i(ce),_1=n(ce,"LI",{});var gXe=s(_1);dve=n(gXe,"STRONG",{});var yXt=s(dve);rqo=r(yXt,"wav2vec2-conformer"),yXt.forEach(t),tqo=r(gXe," \u2014 "),hQ=n(gXe,"A",{href:!0});var xXt=s(hQ);aqo=r(xXt,"Wav2Vec2Processor"),xXt.forEach(t),nqo=r(gXe," (Wav2Vec2-Conformer model)"),gXe.forEach(t),sqo=i(ce),b1=n(ce,"LI",{});var hXe=s(b1);mve=n(hXe,"STRONG",{});var $Xt=s(mve);lqo=r($Xt,"wavlm"),$Xt.forEach(t),iqo=r(hXe," \u2014 "),uQ=n(hXe,"A",{href:!0});var kXt=s(uQ);dqo=r(kXt,"Wav2Vec2Processor"),kXt.forEach(t),mqo=r(hXe," (WavLM model)"),hXe.forEach(t),cqo=i(ce),v1=n(ce,"LI",{});var uXe=s(v1);cve=n(uXe,"STRONG",{});var SXt=s(cve);fqo=r(SXt,"whisper"),SXt.forEach(t),gqo=r(uXe," \u2014 "),pQ=n(uXe,"A",{href:!0});var RXt=s(pQ);hqo=r(RXt,"WhisperProcessor"),RXt.forEach(t),uqo=r(uXe," (Whisper model)"),uXe.forEach(t),pqo=i(ce),F1=n(ce,"LI",{});var pXe=s(F1);fve=n(pXe,"STRONG",{});var PXt=s(fve);_qo=r(PXt,"xclip"),PXt.forEach(t),bqo=r(pXe," \u2014 "),_Q=n(pXe,"A",{href:!0});var BXt=s(_Q);vqo=r(BXt,"XCLIPProcessor"),BXt.forEach(t),Fqo=r(pXe," (X-CLIP model)"),pXe.forEach(t),ce.forEach(t),Tqo=i(ka),T(T1.$$.fragment,ka),Mqo=i(ka),T(M1.$$.fragment,ka),ka.forEach(t),Eqo=i(zl),E1=n(zl,"DIV",{class:!0});var Udo=s(E1);T(Ok.$$.fragment,Udo),Cqo=i(Udo),gve=n(Udo,"P",{});var IXt=s(gve);wqo=r(IXt,"Register a new processor for this class."),IXt.forEach(t),Udo.forEach(t),zl.forEach(t),Llo=i(c),Gd=n(c,"H2",{class:!0});var Hdo=s(Gd);C1=n(Hdo,"A",{id:!0,class:!0,href:!0});var NXt=s(C1);hve=n(NXt,"SPAN",{});var qXt=s(hve);T(Vk.$$.fragment,qXt),qXt.forEach(t),NXt.forEach(t),Aqo=i(Hdo),uve=n(Hdo,"SPAN",{});var DXt=s(uve);Lqo=r(DXt,"AutoModel"),DXt.forEach(t),Hdo.forEach(t),ylo=i(c),jo=n(c,"DIV",{class:!0});var Ql=s(jo);T(Xk.$$.fragment,Ql),yqo=i(Ql),Od=n(Ql,"P",{});var afe=s(Od);xqo=r(afe,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),bQ=n(afe,"A",{href:!0});var jXt=s(bQ);$qo=r(jXt,"from_pretrained()"),jXt.forEach(t),kqo=r(afe," class method or the "),vQ=n(afe,"A",{href:!0});var GXt=s(vQ);Sqo=r(GXt,"from_config()"),GXt.forEach(t),Rqo=r(afe,` class
method.`),afe.forEach(t),Pqo=i(Ql),zk=n(Ql,"P",{});var Jdo=s(zk);Bqo=r(Jdo,"This class cannot be instantiated directly using "),pve=n(Jdo,"CODE",{});var OXt=s(pve);Iqo=r(OXt,"__init__()"),OXt.forEach(t),Nqo=r(Jdo," (throws an error)."),Jdo.forEach(t),qqo=i(Ql),At=n(Ql,"DIV",{class:!0});var rx=s(At);T(Qk.$$.fragment,rx),Dqo=i(rx),_ve=n(rx,"P",{});var VXt=s(_ve);jqo=r(VXt,"Instantiates one of the base model classes of the library from a configuration."),VXt.forEach(t),Gqo=i(rx),Vd=n(rx,"P",{});var nfe=s(Vd);Oqo=r(nfe,`Note:
Loading a model from its configuration file does `),bve=n(nfe,"STRONG",{});var XXt=s(bve);Vqo=r(XXt,"not"),XXt.forEach(t),Xqo=r(nfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),FQ=n(nfe,"A",{href:!0});var zXt=s(FQ);zqo=r(zXt,"from_pretrained()"),zXt.forEach(t),Qqo=r(nfe," to load the model weights."),nfe.forEach(t),Wqo=i(rx),T(w1.$$.fragment,rx),rx.forEach(t),Uqo=i(Ql),to=n(Ql,"DIV",{class:!0});var Sa=s(to);T(Wk.$$.fragment,Sa),Hqo=i(Sa),vve=n(Sa,"P",{});var QXt=s(vve);Jqo=r(QXt,"Instantiate one of the base model classes of the library from a pretrained model."),QXt.forEach(t),Yqo=i(Sa),fn=n(Sa,"P",{});var tx=s(fn);Zqo=r(tx,"The model class to instantiate is selected based on the "),Fve=n(tx,"CODE",{});var WXt=s(Fve);Kqo=r(WXt,"model_type"),WXt.forEach(t),eDo=r(tx,` property of the config object (either
passed as an argument or loaded from `),Tve=n(tx,"CODE",{});var UXt=s(Tve);oDo=r(UXt,"pretrained_model_name_or_path"),UXt.forEach(t),rDo=r(tx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mve=n(tx,"CODE",{});var HXt=s(Mve);tDo=r(HXt,"pretrained_model_name_or_path"),HXt.forEach(t),aDo=r(tx,":"),tx.forEach(t),nDo=i(Sa),y=n(Sa,"UL",{});var x=s(y);A1=n(x,"LI",{});var _Xe=s(A1);Eve=n(_Xe,"STRONG",{});var JXt=s(Eve);sDo=r(JXt,"albert"),JXt.forEach(t),lDo=r(_Xe," \u2014 "),TQ=n(_Xe,"A",{href:!0});var YXt=s(TQ);iDo=r(YXt,"AlbertModel"),YXt.forEach(t),dDo=r(_Xe," (ALBERT model)"),_Xe.forEach(t),mDo=i(x),L1=n(x,"LI",{});var bXe=s(L1);Cve=n(bXe,"STRONG",{});var ZXt=s(Cve);cDo=r(ZXt,"bart"),ZXt.forEach(t),fDo=r(bXe," \u2014 "),MQ=n(bXe,"A",{href:!0});var KXt=s(MQ);gDo=r(KXt,"BartModel"),KXt.forEach(t),hDo=r(bXe," (BART model)"),bXe.forEach(t),uDo=i(x),y1=n(x,"LI",{});var vXe=s(y1);wve=n(vXe,"STRONG",{});var ezt=s(wve);pDo=r(ezt,"beit"),ezt.forEach(t),_Do=r(vXe," \u2014 "),EQ=n(vXe,"A",{href:!0});var ozt=s(EQ);bDo=r(ozt,"BeitModel"),ozt.forEach(t),vDo=r(vXe," (BEiT model)"),vXe.forEach(t),FDo=i(x),x1=n(x,"LI",{});var FXe=s(x1);Ave=n(FXe,"STRONG",{});var rzt=s(Ave);TDo=r(rzt,"bert"),rzt.forEach(t),MDo=r(FXe," \u2014 "),CQ=n(FXe,"A",{href:!0});var tzt=s(CQ);EDo=r(tzt,"BertModel"),tzt.forEach(t),CDo=r(FXe," (BERT model)"),FXe.forEach(t),wDo=i(x),$1=n(x,"LI",{});var TXe=s($1);Lve=n(TXe,"STRONG",{});var azt=s(Lve);ADo=r(azt,"bert-generation"),azt.forEach(t),LDo=r(TXe," \u2014 "),wQ=n(TXe,"A",{href:!0});var nzt=s(wQ);yDo=r(nzt,"BertGenerationEncoder"),nzt.forEach(t),xDo=r(TXe," (Bert Generation model)"),TXe.forEach(t),$Do=i(x),k1=n(x,"LI",{});var MXe=s(k1);yve=n(MXe,"STRONG",{});var szt=s(yve);kDo=r(szt,"big_bird"),szt.forEach(t),SDo=r(MXe," \u2014 "),AQ=n(MXe,"A",{href:!0});var lzt=s(AQ);RDo=r(lzt,"BigBirdModel"),lzt.forEach(t),PDo=r(MXe," (BigBird model)"),MXe.forEach(t),BDo=i(x),S1=n(x,"LI",{});var EXe=s(S1);xve=n(EXe,"STRONG",{});var izt=s(xve);IDo=r(izt,"bigbird_pegasus"),izt.forEach(t),NDo=r(EXe," \u2014 "),LQ=n(EXe,"A",{href:!0});var dzt=s(LQ);qDo=r(dzt,"BigBirdPegasusModel"),dzt.forEach(t),DDo=r(EXe," (BigBird-Pegasus model)"),EXe.forEach(t),jDo=i(x),R1=n(x,"LI",{});var CXe=s(R1);$ve=n(CXe,"STRONG",{});var mzt=s($ve);GDo=r(mzt,"blenderbot"),mzt.forEach(t),ODo=r(CXe," \u2014 "),yQ=n(CXe,"A",{href:!0});var czt=s(yQ);VDo=r(czt,"BlenderbotModel"),czt.forEach(t),XDo=r(CXe," (Blenderbot model)"),CXe.forEach(t),zDo=i(x),P1=n(x,"LI",{});var wXe=s(P1);kve=n(wXe,"STRONG",{});var fzt=s(kve);QDo=r(fzt,"blenderbot-small"),fzt.forEach(t),WDo=r(wXe," \u2014 "),xQ=n(wXe,"A",{href:!0});var gzt=s(xQ);UDo=r(gzt,"BlenderbotSmallModel"),gzt.forEach(t),HDo=r(wXe," (BlenderbotSmall model)"),wXe.forEach(t),JDo=i(x),B1=n(x,"LI",{});var AXe=s(B1);Sve=n(AXe,"STRONG",{});var hzt=s(Sve);YDo=r(hzt,"bloom"),hzt.forEach(t),ZDo=r(AXe," \u2014 "),$Q=n(AXe,"A",{href:!0});var uzt=s($Q);KDo=r(uzt,"BloomModel"),uzt.forEach(t),ejo=r(AXe," (BLOOM model)"),AXe.forEach(t),ojo=i(x),I1=n(x,"LI",{});var LXe=s(I1);Rve=n(LXe,"STRONG",{});var pzt=s(Rve);rjo=r(pzt,"camembert"),pzt.forEach(t),tjo=r(LXe," \u2014 "),kQ=n(LXe,"A",{href:!0});var _zt=s(kQ);ajo=r(_zt,"CamembertModel"),_zt.forEach(t),njo=r(LXe," (CamemBERT model)"),LXe.forEach(t),sjo=i(x),N1=n(x,"LI",{});var yXe=s(N1);Pve=n(yXe,"STRONG",{});var bzt=s(Pve);ljo=r(bzt,"canine"),bzt.forEach(t),ijo=r(yXe," \u2014 "),SQ=n(yXe,"A",{href:!0});var vzt=s(SQ);djo=r(vzt,"CanineModel"),vzt.forEach(t),mjo=r(yXe," (CANINE model)"),yXe.forEach(t),cjo=i(x),q1=n(x,"LI",{});var xXe=s(q1);Bve=n(xXe,"STRONG",{});var Fzt=s(Bve);fjo=r(Fzt,"clip"),Fzt.forEach(t),gjo=r(xXe," \u2014 "),RQ=n(xXe,"A",{href:!0});var Tzt=s(RQ);hjo=r(Tzt,"CLIPModel"),Tzt.forEach(t),ujo=r(xXe," (CLIP model)"),xXe.forEach(t),pjo=i(x),D1=n(x,"LI",{});var $Xe=s(D1);Ive=n($Xe,"STRONG",{});var Mzt=s(Ive);_jo=r(Mzt,"clipseg"),Mzt.forEach(t),bjo=r($Xe," \u2014 "),PQ=n($Xe,"A",{href:!0});var Ezt=s(PQ);vjo=r(Ezt,"CLIPSegModel"),Ezt.forEach(t),Fjo=r($Xe," (CLIPSeg model)"),$Xe.forEach(t),Tjo=i(x),j1=n(x,"LI",{});var kXe=s(j1);Nve=n(kXe,"STRONG",{});var Czt=s(Nve);Mjo=r(Czt,"codegen"),Czt.forEach(t),Ejo=r(kXe," \u2014 "),BQ=n(kXe,"A",{href:!0});var wzt=s(BQ);Cjo=r(wzt,"CodeGenModel"),wzt.forEach(t),wjo=r(kXe," (CodeGen model)"),kXe.forEach(t),Ajo=i(x),G1=n(x,"LI",{});var SXe=s(G1);qve=n(SXe,"STRONG",{});var Azt=s(qve);Ljo=r(Azt,"conditional_detr"),Azt.forEach(t),yjo=r(SXe," \u2014 "),IQ=n(SXe,"A",{href:!0});var Lzt=s(IQ);xjo=r(Lzt,"ConditionalDetrModel"),Lzt.forEach(t),$jo=r(SXe," (Conditional DETR model)"),SXe.forEach(t),kjo=i(x),O1=n(x,"LI",{});var RXe=s(O1);Dve=n(RXe,"STRONG",{});var yzt=s(Dve);Sjo=r(yzt,"convbert"),yzt.forEach(t),Rjo=r(RXe," \u2014 "),NQ=n(RXe,"A",{href:!0});var xzt=s(NQ);Pjo=r(xzt,"ConvBertModel"),xzt.forEach(t),Bjo=r(RXe," (ConvBERT model)"),RXe.forEach(t),Ijo=i(x),V1=n(x,"LI",{});var PXe=s(V1);jve=n(PXe,"STRONG",{});var $zt=s(jve);Njo=r($zt,"convnext"),$zt.forEach(t),qjo=r(PXe," \u2014 "),qQ=n(PXe,"A",{href:!0});var kzt=s(qQ);Djo=r(kzt,"ConvNextModel"),kzt.forEach(t),jjo=r(PXe," (ConvNeXT model)"),PXe.forEach(t),Gjo=i(x),X1=n(x,"LI",{});var BXe=s(X1);Gve=n(BXe,"STRONG",{});var Szt=s(Gve);Ojo=r(Szt,"ctrl"),Szt.forEach(t),Vjo=r(BXe," \u2014 "),DQ=n(BXe,"A",{href:!0});var Rzt=s(DQ);Xjo=r(Rzt,"CTRLModel"),Rzt.forEach(t),zjo=r(BXe," (CTRL model)"),BXe.forEach(t),Qjo=i(x),z1=n(x,"LI",{});var IXe=s(z1);Ove=n(IXe,"STRONG",{});var Pzt=s(Ove);Wjo=r(Pzt,"cvt"),Pzt.forEach(t),Ujo=r(IXe," \u2014 "),jQ=n(IXe,"A",{href:!0});var Bzt=s(jQ);Hjo=r(Bzt,"CvtModel"),Bzt.forEach(t),Jjo=r(IXe," (CvT model)"),IXe.forEach(t),Yjo=i(x),Q1=n(x,"LI",{});var NXe=s(Q1);Vve=n(NXe,"STRONG",{});var Izt=s(Vve);Zjo=r(Izt,"data2vec-audio"),Izt.forEach(t),Kjo=r(NXe," \u2014 "),GQ=n(NXe,"A",{href:!0});var Nzt=s(GQ);eGo=r(Nzt,"Data2VecAudioModel"),Nzt.forEach(t),oGo=r(NXe," (Data2VecAudio model)"),NXe.forEach(t),rGo=i(x),W1=n(x,"LI",{});var qXe=s(W1);Xve=n(qXe,"STRONG",{});var qzt=s(Xve);tGo=r(qzt,"data2vec-text"),qzt.forEach(t),aGo=r(qXe," \u2014 "),OQ=n(qXe,"A",{href:!0});var Dzt=s(OQ);nGo=r(Dzt,"Data2VecTextModel"),Dzt.forEach(t),sGo=r(qXe," (Data2VecText model)"),qXe.forEach(t),lGo=i(x),U1=n(x,"LI",{});var DXe=s(U1);zve=n(DXe,"STRONG",{});var jzt=s(zve);iGo=r(jzt,"data2vec-vision"),jzt.forEach(t),dGo=r(DXe," \u2014 "),VQ=n(DXe,"A",{href:!0});var Gzt=s(VQ);mGo=r(Gzt,"Data2VecVisionModel"),Gzt.forEach(t),cGo=r(DXe," (Data2VecVision model)"),DXe.forEach(t),fGo=i(x),H1=n(x,"LI",{});var jXe=s(H1);Qve=n(jXe,"STRONG",{});var Ozt=s(Qve);gGo=r(Ozt,"deberta"),Ozt.forEach(t),hGo=r(jXe," \u2014 "),XQ=n(jXe,"A",{href:!0});var Vzt=s(XQ);uGo=r(Vzt,"DebertaModel"),Vzt.forEach(t),pGo=r(jXe," (DeBERTa model)"),jXe.forEach(t),_Go=i(x),J1=n(x,"LI",{});var GXe=s(J1);Wve=n(GXe,"STRONG",{});var Xzt=s(Wve);bGo=r(Xzt,"deberta-v2"),Xzt.forEach(t),vGo=r(GXe," \u2014 "),zQ=n(GXe,"A",{href:!0});var zzt=s(zQ);FGo=r(zzt,"DebertaV2Model"),zzt.forEach(t),TGo=r(GXe," (DeBERTa-v2 model)"),GXe.forEach(t),MGo=i(x),Y1=n(x,"LI",{});var OXe=s(Y1);Uve=n(OXe,"STRONG",{});var Qzt=s(Uve);EGo=r(Qzt,"decision_transformer"),Qzt.forEach(t),CGo=r(OXe," \u2014 "),QQ=n(OXe,"A",{href:!0});var Wzt=s(QQ);wGo=r(Wzt,"DecisionTransformerModel"),Wzt.forEach(t),AGo=r(OXe," (Decision Transformer model)"),OXe.forEach(t),LGo=i(x),Z1=n(x,"LI",{});var VXe=s(Z1);Hve=n(VXe,"STRONG",{});var Uzt=s(Hve);yGo=r(Uzt,"deformable_detr"),Uzt.forEach(t),xGo=r(VXe," \u2014 "),WQ=n(VXe,"A",{href:!0});var Hzt=s(WQ);$Go=r(Hzt,"DeformableDetrModel"),Hzt.forEach(t),kGo=r(VXe," (Deformable DETR model)"),VXe.forEach(t),SGo=i(x),K1=n(x,"LI",{});var XXe=s(K1);Jve=n(XXe,"STRONG",{});var Jzt=s(Jve);RGo=r(Jzt,"deit"),Jzt.forEach(t),PGo=r(XXe," \u2014 "),UQ=n(XXe,"A",{href:!0});var Yzt=s(UQ);BGo=r(Yzt,"DeiTModel"),Yzt.forEach(t),IGo=r(XXe," (DeiT model)"),XXe.forEach(t),NGo=i(x),e2=n(x,"LI",{});var zXe=s(e2);Yve=n(zXe,"STRONG",{});var Zzt=s(Yve);qGo=r(Zzt,"detr"),Zzt.forEach(t),DGo=r(zXe," \u2014 "),HQ=n(zXe,"A",{href:!0});var Kzt=s(HQ);jGo=r(Kzt,"DetrModel"),Kzt.forEach(t),GGo=r(zXe," (DETR model)"),zXe.forEach(t),OGo=i(x),o2=n(x,"LI",{});var QXe=s(o2);Zve=n(QXe,"STRONG",{});var eQt=s(Zve);VGo=r(eQt,"distilbert"),eQt.forEach(t),XGo=r(QXe," \u2014 "),JQ=n(QXe,"A",{href:!0});var oQt=s(JQ);zGo=r(oQt,"DistilBertModel"),oQt.forEach(t),QGo=r(QXe," (DistilBERT model)"),QXe.forEach(t),WGo=i(x),r2=n(x,"LI",{});var WXe=s(r2);Kve=n(WXe,"STRONG",{});var rQt=s(Kve);UGo=r(rQt,"donut-swin"),rQt.forEach(t),HGo=r(WXe," \u2014 "),YQ=n(WXe,"A",{href:!0});var tQt=s(YQ);JGo=r(tQt,"DonutSwinModel"),tQt.forEach(t),YGo=r(WXe," (DonutSwin model)"),WXe.forEach(t),ZGo=i(x),t2=n(x,"LI",{});var UXe=s(t2);eFe=n(UXe,"STRONG",{});var aQt=s(eFe);KGo=r(aQt,"dpr"),aQt.forEach(t),eOo=r(UXe," \u2014 "),ZQ=n(UXe,"A",{href:!0});var nQt=s(ZQ);oOo=r(nQt,"DPRQuestionEncoder"),nQt.forEach(t),rOo=r(UXe," (DPR model)"),UXe.forEach(t),tOo=i(x),a2=n(x,"LI",{});var HXe=s(a2);oFe=n(HXe,"STRONG",{});var sQt=s(oFe);aOo=r(sQt,"dpt"),sQt.forEach(t),nOo=r(HXe," \u2014 "),KQ=n(HXe,"A",{href:!0});var lQt=s(KQ);sOo=r(lQt,"DPTModel"),lQt.forEach(t),lOo=r(HXe," (DPT model)"),HXe.forEach(t),iOo=i(x),n2=n(x,"LI",{});var JXe=s(n2);rFe=n(JXe,"STRONG",{});var iQt=s(rFe);dOo=r(iQt,"electra"),iQt.forEach(t),mOo=r(JXe," \u2014 "),eW=n(JXe,"A",{href:!0});var dQt=s(eW);cOo=r(dQt,"ElectraModel"),dQt.forEach(t),fOo=r(JXe," (ELECTRA model)"),JXe.forEach(t),gOo=i(x),s2=n(x,"LI",{});var YXe=s(s2);tFe=n(YXe,"STRONG",{});var mQt=s(tFe);hOo=r(mQt,"ernie"),mQt.forEach(t),uOo=r(YXe," \u2014 "),oW=n(YXe,"A",{href:!0});var cQt=s(oW);pOo=r(cQt,"ErnieModel"),cQt.forEach(t),_Oo=r(YXe," (ERNIE model)"),YXe.forEach(t),bOo=i(x),l2=n(x,"LI",{});var ZXe=s(l2);aFe=n(ZXe,"STRONG",{});var fQt=s(aFe);vOo=r(fQt,"esm"),fQt.forEach(t),FOo=r(ZXe," \u2014 "),rW=n(ZXe,"A",{href:!0});var gQt=s(rW);TOo=r(gQt,"EsmModel"),gQt.forEach(t),MOo=r(ZXe," (ESM model)"),ZXe.forEach(t),EOo=i(x),i2=n(x,"LI",{});var KXe=s(i2);nFe=n(KXe,"STRONG",{});var hQt=s(nFe);COo=r(hQt,"flaubert"),hQt.forEach(t),wOo=r(KXe," \u2014 "),tW=n(KXe,"A",{href:!0});var uQt=s(tW);AOo=r(uQt,"FlaubertModel"),uQt.forEach(t),LOo=r(KXe," (FlauBERT model)"),KXe.forEach(t),yOo=i(x),d2=n(x,"LI",{});var eze=s(d2);sFe=n(eze,"STRONG",{});var pQt=s(sFe);xOo=r(pQt,"flava"),pQt.forEach(t),$Oo=r(eze," \u2014 "),aW=n(eze,"A",{href:!0});var _Qt=s(aW);kOo=r(_Qt,"FlavaModel"),_Qt.forEach(t),SOo=r(eze," (FLAVA model)"),eze.forEach(t),ROo=i(x),m2=n(x,"LI",{});var oze=s(m2);lFe=n(oze,"STRONG",{});var bQt=s(lFe);POo=r(bQt,"fnet"),bQt.forEach(t),BOo=r(oze," \u2014 "),nW=n(oze,"A",{href:!0});var vQt=s(nW);IOo=r(vQt,"FNetModel"),vQt.forEach(t),NOo=r(oze," (FNet model)"),oze.forEach(t),qOo=i(x),c2=n(x,"LI",{});var rze=s(c2);iFe=n(rze,"STRONG",{});var FQt=s(iFe);DOo=r(FQt,"fsmt"),FQt.forEach(t),jOo=r(rze," \u2014 "),sW=n(rze,"A",{href:!0});var TQt=s(sW);GOo=r(TQt,"FSMTModel"),TQt.forEach(t),OOo=r(rze," (FairSeq Machine-Translation model)"),rze.forEach(t),VOo=i(x),Il=n(x,"LI",{});var Aq=s(Il);dFe=n(Aq,"STRONG",{});var MQt=s(dFe);XOo=r(MQt,"funnel"),MQt.forEach(t),zOo=r(Aq," \u2014 "),lW=n(Aq,"A",{href:!0});var EQt=s(lW);QOo=r(EQt,"FunnelModel"),EQt.forEach(t),WOo=r(Aq," or "),iW=n(Aq,"A",{href:!0});var CQt=s(iW);UOo=r(CQt,"FunnelBaseModel"),CQt.forEach(t),HOo=r(Aq," (Funnel Transformer model)"),Aq.forEach(t),JOo=i(x),f2=n(x,"LI",{});var tze=s(f2);mFe=n(tze,"STRONG",{});var wQt=s(mFe);YOo=r(wQt,"glpn"),wQt.forEach(t),ZOo=r(tze," \u2014 "),dW=n(tze,"A",{href:!0});var AQt=s(dW);KOo=r(AQt,"GLPNModel"),AQt.forEach(t),eVo=r(tze," (GLPN model)"),tze.forEach(t),oVo=i(x),g2=n(x,"LI",{});var aze=s(g2);cFe=n(aze,"STRONG",{});var LQt=s(cFe);rVo=r(LQt,"gpt2"),LQt.forEach(t),tVo=r(aze," \u2014 "),mW=n(aze,"A",{href:!0});var yQt=s(mW);aVo=r(yQt,"GPT2Model"),yQt.forEach(t),nVo=r(aze," (OpenAI GPT-2 model)"),aze.forEach(t),sVo=i(x),h2=n(x,"LI",{});var nze=s(h2);fFe=n(nze,"STRONG",{});var xQt=s(fFe);lVo=r(xQt,"gpt_neo"),xQt.forEach(t),iVo=r(nze," \u2014 "),cW=n(nze,"A",{href:!0});var $Qt=s(cW);dVo=r($Qt,"GPTNeoModel"),$Qt.forEach(t),mVo=r(nze," (GPT Neo model)"),nze.forEach(t),cVo=i(x),u2=n(x,"LI",{});var sze=s(u2);gFe=n(sze,"STRONG",{});var kQt=s(gFe);fVo=r(kQt,"gpt_neox"),kQt.forEach(t),gVo=r(sze," \u2014 "),fW=n(sze,"A",{href:!0});var SQt=s(fW);hVo=r(SQt,"GPTNeoXModel"),SQt.forEach(t),uVo=r(sze," (GPT NeoX model)"),sze.forEach(t),pVo=i(x),p2=n(x,"LI",{});var lze=s(p2);hFe=n(lze,"STRONG",{});var RQt=s(hFe);_Vo=r(RQt,"gpt_neox_japanese"),RQt.forEach(t),bVo=r(lze," \u2014 "),gW=n(lze,"A",{href:!0});var PQt=s(gW);vVo=r(PQt,"GPTNeoXJapaneseModel"),PQt.forEach(t),FVo=r(lze," (GPT NeoX Japanese model)"),lze.forEach(t),TVo=i(x),_2=n(x,"LI",{});var ize=s(_2);uFe=n(ize,"STRONG",{});var BQt=s(uFe);MVo=r(BQt,"gptj"),BQt.forEach(t),EVo=r(ize," \u2014 "),hW=n(ize,"A",{href:!0});var IQt=s(hW);CVo=r(IQt,"GPTJModel"),IQt.forEach(t),wVo=r(ize," (GPT-J model)"),ize.forEach(t),AVo=i(x),b2=n(x,"LI",{});var dze=s(b2);pFe=n(dze,"STRONG",{});var NQt=s(pFe);LVo=r(NQt,"groupvit"),NQt.forEach(t),yVo=r(dze," \u2014 "),uW=n(dze,"A",{href:!0});var qQt=s(uW);xVo=r(qQt,"GroupViTModel"),qQt.forEach(t),$Vo=r(dze," (GroupViT model)"),dze.forEach(t),kVo=i(x),v2=n(x,"LI",{});var mze=s(v2);_Fe=n(mze,"STRONG",{});var DQt=s(_Fe);SVo=r(DQt,"hubert"),DQt.forEach(t),RVo=r(mze," \u2014 "),pW=n(mze,"A",{href:!0});var jQt=s(pW);PVo=r(jQt,"HubertModel"),jQt.forEach(t),BVo=r(mze," (Hubert model)"),mze.forEach(t),IVo=i(x),F2=n(x,"LI",{});var cze=s(F2);bFe=n(cze,"STRONG",{});var GQt=s(bFe);NVo=r(GQt,"ibert"),GQt.forEach(t),qVo=r(cze," \u2014 "),_W=n(cze,"A",{href:!0});var OQt=s(_W);DVo=r(OQt,"IBertModel"),OQt.forEach(t),jVo=r(cze," (I-BERT model)"),cze.forEach(t),GVo=i(x),T2=n(x,"LI",{});var fze=s(T2);vFe=n(fze,"STRONG",{});var VQt=s(vFe);OVo=r(VQt,"imagegpt"),VQt.forEach(t),VVo=r(fze," \u2014 "),bW=n(fze,"A",{href:!0});var XQt=s(bW);XVo=r(XQt,"ImageGPTModel"),XQt.forEach(t),zVo=r(fze," (ImageGPT model)"),fze.forEach(t),QVo=i(x),M2=n(x,"LI",{});var gze=s(M2);FFe=n(gze,"STRONG",{});var zQt=s(FFe);WVo=r(zQt,"layoutlm"),zQt.forEach(t),UVo=r(gze," \u2014 "),vW=n(gze,"A",{href:!0});var QQt=s(vW);HVo=r(QQt,"LayoutLMModel"),QQt.forEach(t),JVo=r(gze," (LayoutLM model)"),gze.forEach(t),YVo=i(x),E2=n(x,"LI",{});var hze=s(E2);TFe=n(hze,"STRONG",{});var WQt=s(TFe);ZVo=r(WQt,"layoutlmv2"),WQt.forEach(t),KVo=r(hze," \u2014 "),FW=n(hze,"A",{href:!0});var UQt=s(FW);eXo=r(UQt,"LayoutLMv2Model"),UQt.forEach(t),oXo=r(hze," (LayoutLMv2 model)"),hze.forEach(t),rXo=i(x),C2=n(x,"LI",{});var uze=s(C2);MFe=n(uze,"STRONG",{});var HQt=s(MFe);tXo=r(HQt,"layoutlmv3"),HQt.forEach(t),aXo=r(uze," \u2014 "),TW=n(uze,"A",{href:!0});var JQt=s(TW);nXo=r(JQt,"LayoutLMv3Model"),JQt.forEach(t),sXo=r(uze," (LayoutLMv3 model)"),uze.forEach(t),lXo=i(x),w2=n(x,"LI",{});var pze=s(w2);EFe=n(pze,"STRONG",{});var YQt=s(EFe);iXo=r(YQt,"led"),YQt.forEach(t),dXo=r(pze," \u2014 "),MW=n(pze,"A",{href:!0});var ZQt=s(MW);mXo=r(ZQt,"LEDModel"),ZQt.forEach(t),cXo=r(pze," (LED model)"),pze.forEach(t),fXo=i(x),A2=n(x,"LI",{});var _ze=s(A2);CFe=n(_ze,"STRONG",{});var KQt=s(CFe);gXo=r(KQt,"levit"),KQt.forEach(t),hXo=r(_ze," \u2014 "),EW=n(_ze,"A",{href:!0});var eWt=s(EW);uXo=r(eWt,"LevitModel"),eWt.forEach(t),pXo=r(_ze," (LeViT model)"),_ze.forEach(t),_Xo=i(x),L2=n(x,"LI",{});var bze=s(L2);wFe=n(bze,"STRONG",{});var oWt=s(wFe);bXo=r(oWt,"lilt"),oWt.forEach(t),vXo=r(bze," \u2014 "),CW=n(bze,"A",{href:!0});var rWt=s(CW);FXo=r(rWt,"LiltModel"),rWt.forEach(t),TXo=r(bze," (LiLT model)"),bze.forEach(t),MXo=i(x),y2=n(x,"LI",{});var vze=s(y2);AFe=n(vze,"STRONG",{});var tWt=s(AFe);EXo=r(tWt,"longformer"),tWt.forEach(t),CXo=r(vze," \u2014 "),wW=n(vze,"A",{href:!0});var aWt=s(wW);wXo=r(aWt,"LongformerModel"),aWt.forEach(t),AXo=r(vze," (Longformer model)"),vze.forEach(t),LXo=i(x),x2=n(x,"LI",{});var Fze=s(x2);LFe=n(Fze,"STRONG",{});var nWt=s(LFe);yXo=r(nWt,"longt5"),nWt.forEach(t),xXo=r(Fze," \u2014 "),AW=n(Fze,"A",{href:!0});var sWt=s(AW);$Xo=r(sWt,"LongT5Model"),sWt.forEach(t),kXo=r(Fze," (LongT5 model)"),Fze.forEach(t),SXo=i(x),$2=n(x,"LI",{});var Tze=s($2);yFe=n(Tze,"STRONG",{});var lWt=s(yFe);RXo=r(lWt,"luke"),lWt.forEach(t),PXo=r(Tze," \u2014 "),LW=n(Tze,"A",{href:!0});var iWt=s(LW);BXo=r(iWt,"LukeModel"),iWt.forEach(t),IXo=r(Tze," (LUKE model)"),Tze.forEach(t),NXo=i(x),k2=n(x,"LI",{});var Mze=s(k2);xFe=n(Mze,"STRONG",{});var dWt=s(xFe);qXo=r(dWt,"lxmert"),dWt.forEach(t),DXo=r(Mze," \u2014 "),yW=n(Mze,"A",{href:!0});var mWt=s(yW);jXo=r(mWt,"LxmertModel"),mWt.forEach(t),GXo=r(Mze," (LXMERT model)"),Mze.forEach(t),OXo=i(x),S2=n(x,"LI",{});var Eze=s(S2);$Fe=n(Eze,"STRONG",{});var cWt=s($Fe);VXo=r(cWt,"m2m_100"),cWt.forEach(t),XXo=r(Eze," \u2014 "),xW=n(Eze,"A",{href:!0});var fWt=s(xW);zXo=r(fWt,"M2M100Model"),fWt.forEach(t),QXo=r(Eze," (M2M100 model)"),Eze.forEach(t),WXo=i(x),R2=n(x,"LI",{});var Cze=s(R2);kFe=n(Cze,"STRONG",{});var gWt=s(kFe);UXo=r(gWt,"marian"),gWt.forEach(t),HXo=r(Cze," \u2014 "),$W=n(Cze,"A",{href:!0});var hWt=s($W);JXo=r(hWt,"MarianModel"),hWt.forEach(t),YXo=r(Cze," (Marian model)"),Cze.forEach(t),ZXo=i(x),P2=n(x,"LI",{});var wze=s(P2);SFe=n(wze,"STRONG",{});var uWt=s(SFe);KXo=r(uWt,"markuplm"),uWt.forEach(t),ezo=r(wze," \u2014 "),kW=n(wze,"A",{href:!0});var pWt=s(kW);ozo=r(pWt,"MarkupLMModel"),pWt.forEach(t),rzo=r(wze," (MarkupLM model)"),wze.forEach(t),tzo=i(x),B2=n(x,"LI",{});var Aze=s(B2);RFe=n(Aze,"STRONG",{});var _Wt=s(RFe);azo=r(_Wt,"maskformer"),_Wt.forEach(t),nzo=r(Aze," \u2014 "),SW=n(Aze,"A",{href:!0});var bWt=s(SW);szo=r(bWt,"MaskFormerModel"),bWt.forEach(t),lzo=r(Aze," (MaskFormer model)"),Aze.forEach(t),izo=i(x),I2=n(x,"LI",{});var Lze=s(I2);PFe=n(Lze,"STRONG",{});var vWt=s(PFe);dzo=r(vWt,"mbart"),vWt.forEach(t),mzo=r(Lze," \u2014 "),RW=n(Lze,"A",{href:!0});var FWt=s(RW);czo=r(FWt,"MBartModel"),FWt.forEach(t),fzo=r(Lze," (mBART model)"),Lze.forEach(t),gzo=i(x),N2=n(x,"LI",{});var yze=s(N2);BFe=n(yze,"STRONG",{});var TWt=s(BFe);hzo=r(TWt,"mctct"),TWt.forEach(t),uzo=r(yze," \u2014 "),PW=n(yze,"A",{href:!0});var MWt=s(PW);pzo=r(MWt,"MCTCTModel"),MWt.forEach(t),_zo=r(yze," (M-CTC-T model)"),yze.forEach(t),bzo=i(x),q2=n(x,"LI",{});var xze=s(q2);IFe=n(xze,"STRONG",{});var EWt=s(IFe);vzo=r(EWt,"megatron-bert"),EWt.forEach(t),Fzo=r(xze," \u2014 "),BW=n(xze,"A",{href:!0});var CWt=s(BW);Tzo=r(CWt,"MegatronBertModel"),CWt.forEach(t),Mzo=r(xze," (Megatron-BERT model)"),xze.forEach(t),Ezo=i(x),D2=n(x,"LI",{});var $ze=s(D2);NFe=n($ze,"STRONG",{});var wWt=s(NFe);Czo=r(wWt,"mobilebert"),wWt.forEach(t),wzo=r($ze," \u2014 "),IW=n($ze,"A",{href:!0});var AWt=s(IW);Azo=r(AWt,"MobileBertModel"),AWt.forEach(t),Lzo=r($ze," (MobileBERT model)"),$ze.forEach(t),yzo=i(x),j2=n(x,"LI",{});var kze=s(j2);qFe=n(kze,"STRONG",{});var LWt=s(qFe);xzo=r(LWt,"mobilevit"),LWt.forEach(t),$zo=r(kze," \u2014 "),NW=n(kze,"A",{href:!0});var yWt=s(NW);kzo=r(yWt,"MobileViTModel"),yWt.forEach(t),Szo=r(kze," (MobileViT model)"),kze.forEach(t),Rzo=i(x),G2=n(x,"LI",{});var Sze=s(G2);DFe=n(Sze,"STRONG",{});var xWt=s(DFe);Pzo=r(xWt,"mpnet"),xWt.forEach(t),Bzo=r(Sze," \u2014 "),qW=n(Sze,"A",{href:!0});var $Wt=s(qW);Izo=r($Wt,"MPNetModel"),$Wt.forEach(t),Nzo=r(Sze," (MPNet model)"),Sze.forEach(t),qzo=i(x),O2=n(x,"LI",{});var Rze=s(O2);jFe=n(Rze,"STRONG",{});var kWt=s(jFe);Dzo=r(kWt,"mt5"),kWt.forEach(t),jzo=r(Rze," \u2014 "),DW=n(Rze,"A",{href:!0});var SWt=s(DW);Gzo=r(SWt,"MT5Model"),SWt.forEach(t),Ozo=r(Rze," (MT5 model)"),Rze.forEach(t),Vzo=i(x),V2=n(x,"LI",{});var Pze=s(V2);GFe=n(Pze,"STRONG",{});var RWt=s(GFe);Xzo=r(RWt,"mvp"),RWt.forEach(t),zzo=r(Pze," \u2014 "),jW=n(Pze,"A",{href:!0});var PWt=s(jW);Qzo=r(PWt,"MvpModel"),PWt.forEach(t),Wzo=r(Pze," (MVP model)"),Pze.forEach(t),Uzo=i(x),X2=n(x,"LI",{});var Bze=s(X2);OFe=n(Bze,"STRONG",{});var BWt=s(OFe);Hzo=r(BWt,"nezha"),BWt.forEach(t),Jzo=r(Bze," \u2014 "),GW=n(Bze,"A",{href:!0});var IWt=s(GW);Yzo=r(IWt,"NezhaModel"),IWt.forEach(t),Zzo=r(Bze," (Nezha model)"),Bze.forEach(t),Kzo=i(x),z2=n(x,"LI",{});var Ize=s(z2);VFe=n(Ize,"STRONG",{});var NWt=s(VFe);eQo=r(NWt,"nllb"),NWt.forEach(t),oQo=r(Ize," \u2014 "),OW=n(Ize,"A",{href:!0});var qWt=s(OW);rQo=r(qWt,"M2M100Model"),qWt.forEach(t),tQo=r(Ize," (NLLB model)"),Ize.forEach(t),aQo=i(x),Q2=n(x,"LI",{});var Nze=s(Q2);XFe=n(Nze,"STRONG",{});var DWt=s(XFe);nQo=r(DWt,"nystromformer"),DWt.forEach(t),sQo=r(Nze," \u2014 "),VW=n(Nze,"A",{href:!0});var jWt=s(VW);lQo=r(jWt,"NystromformerModel"),jWt.forEach(t),iQo=r(Nze," (Nystr\xF6mformer model)"),Nze.forEach(t),dQo=i(x),W2=n(x,"LI",{});var qze=s(W2);zFe=n(qze,"STRONG",{});var GWt=s(zFe);mQo=r(GWt,"openai-gpt"),GWt.forEach(t),cQo=r(qze," \u2014 "),XW=n(qze,"A",{href:!0});var OWt=s(XW);fQo=r(OWt,"OpenAIGPTModel"),OWt.forEach(t),gQo=r(qze," (OpenAI GPT model)"),qze.forEach(t),hQo=i(x),U2=n(x,"LI",{});var Dze=s(U2);QFe=n(Dze,"STRONG",{});var VWt=s(QFe);uQo=r(VWt,"opt"),VWt.forEach(t),pQo=r(Dze," \u2014 "),zW=n(Dze,"A",{href:!0});var XWt=s(zW);_Qo=r(XWt,"OPTModel"),XWt.forEach(t),bQo=r(Dze," (OPT model)"),Dze.forEach(t),vQo=i(x),H2=n(x,"LI",{});var jze=s(H2);WFe=n(jze,"STRONG",{});var zWt=s(WFe);FQo=r(zWt,"owlvit"),zWt.forEach(t),TQo=r(jze," \u2014 "),QW=n(jze,"A",{href:!0});var QWt=s(QW);MQo=r(QWt,"OwlViTModel"),QWt.forEach(t),EQo=r(jze," (OWL-ViT model)"),jze.forEach(t),CQo=i(x),J2=n(x,"LI",{});var Gze=s(J2);UFe=n(Gze,"STRONG",{});var WWt=s(UFe);wQo=r(WWt,"pegasus"),WWt.forEach(t),AQo=r(Gze," \u2014 "),WW=n(Gze,"A",{href:!0});var UWt=s(WW);LQo=r(UWt,"PegasusModel"),UWt.forEach(t),yQo=r(Gze," (Pegasus model)"),Gze.forEach(t),xQo=i(x),Y2=n(x,"LI",{});var Oze=s(Y2);HFe=n(Oze,"STRONG",{});var HWt=s(HFe);$Qo=r(HWt,"pegasus_x"),HWt.forEach(t),kQo=r(Oze," \u2014 "),UW=n(Oze,"A",{href:!0});var JWt=s(UW);SQo=r(JWt,"PegasusXModel"),JWt.forEach(t),RQo=r(Oze," (PEGASUS-X model)"),Oze.forEach(t),PQo=i(x),Z2=n(x,"LI",{});var Vze=s(Z2);JFe=n(Vze,"STRONG",{});var YWt=s(JFe);BQo=r(YWt,"perceiver"),YWt.forEach(t),IQo=r(Vze," \u2014 "),HW=n(Vze,"A",{href:!0});var ZWt=s(HW);NQo=r(ZWt,"PerceiverModel"),ZWt.forEach(t),qQo=r(Vze," (Perceiver model)"),Vze.forEach(t),DQo=i(x),K2=n(x,"LI",{});var Xze=s(K2);YFe=n(Xze,"STRONG",{});var KWt=s(YFe);jQo=r(KWt,"plbart"),KWt.forEach(t),GQo=r(Xze," \u2014 "),JW=n(Xze,"A",{href:!0});var eUt=s(JW);OQo=r(eUt,"PLBartModel"),eUt.forEach(t),VQo=r(Xze," (PLBart model)"),Xze.forEach(t),XQo=i(x),eb=n(x,"LI",{});var zze=s(eb);ZFe=n(zze,"STRONG",{});var oUt=s(ZFe);zQo=r(oUt,"poolformer"),oUt.forEach(t),QQo=r(zze," \u2014 "),YW=n(zze,"A",{href:!0});var rUt=s(YW);WQo=r(rUt,"PoolFormerModel"),rUt.forEach(t),UQo=r(zze," (PoolFormer model)"),zze.forEach(t),HQo=i(x),ob=n(x,"LI",{});var Qze=s(ob);KFe=n(Qze,"STRONG",{});var tUt=s(KFe);JQo=r(tUt,"prophetnet"),tUt.forEach(t),YQo=r(Qze," \u2014 "),ZW=n(Qze,"A",{href:!0});var aUt=s(ZW);ZQo=r(aUt,"ProphetNetModel"),aUt.forEach(t),KQo=r(Qze," (ProphetNet model)"),Qze.forEach(t),eWo=i(x),rb=n(x,"LI",{});var Wze=s(rb);eTe=n(Wze,"STRONG",{});var nUt=s(eTe);oWo=r(nUt,"qdqbert"),nUt.forEach(t),rWo=r(Wze," \u2014 "),KW=n(Wze,"A",{href:!0});var sUt=s(KW);tWo=r(sUt,"QDQBertModel"),sUt.forEach(t),aWo=r(Wze," (QDQBert model)"),Wze.forEach(t),nWo=i(x),tb=n(x,"LI",{});var Uze=s(tb);oTe=n(Uze,"STRONG",{});var lUt=s(oTe);sWo=r(lUt,"reformer"),lUt.forEach(t),lWo=r(Uze," \u2014 "),eU=n(Uze,"A",{href:!0});var iUt=s(eU);iWo=r(iUt,"ReformerModel"),iUt.forEach(t),dWo=r(Uze," (Reformer model)"),Uze.forEach(t),mWo=i(x),ab=n(x,"LI",{});var Hze=s(ab);rTe=n(Hze,"STRONG",{});var dUt=s(rTe);cWo=r(dUt,"regnet"),dUt.forEach(t),fWo=r(Hze," \u2014 "),oU=n(Hze,"A",{href:!0});var mUt=s(oU);gWo=r(mUt,"RegNetModel"),mUt.forEach(t),hWo=r(Hze," (RegNet model)"),Hze.forEach(t),uWo=i(x),nb=n(x,"LI",{});var Jze=s(nb);tTe=n(Jze,"STRONG",{});var cUt=s(tTe);pWo=r(cUt,"rembert"),cUt.forEach(t),_Wo=r(Jze," \u2014 "),rU=n(Jze,"A",{href:!0});var fUt=s(rU);bWo=r(fUt,"RemBertModel"),fUt.forEach(t),vWo=r(Jze," (RemBERT model)"),Jze.forEach(t),FWo=i(x),sb=n(x,"LI",{});var Yze=s(sb);aTe=n(Yze,"STRONG",{});var gUt=s(aTe);TWo=r(gUt,"resnet"),gUt.forEach(t),MWo=r(Yze," \u2014 "),tU=n(Yze,"A",{href:!0});var hUt=s(tU);EWo=r(hUt,"ResNetModel"),hUt.forEach(t),CWo=r(Yze," (ResNet model)"),Yze.forEach(t),wWo=i(x),lb=n(x,"LI",{});var Zze=s(lb);nTe=n(Zze,"STRONG",{});var uUt=s(nTe);AWo=r(uUt,"retribert"),uUt.forEach(t),LWo=r(Zze," \u2014 "),aU=n(Zze,"A",{href:!0});var pUt=s(aU);yWo=r(pUt,"RetriBertModel"),pUt.forEach(t),xWo=r(Zze," (RetriBERT model)"),Zze.forEach(t),$Wo=i(x),ib=n(x,"LI",{});var Kze=s(ib);sTe=n(Kze,"STRONG",{});var _Ut=s(sTe);kWo=r(_Ut,"roberta"),_Ut.forEach(t),SWo=r(Kze," \u2014 "),nU=n(Kze,"A",{href:!0});var bUt=s(nU);RWo=r(bUt,"RobertaModel"),bUt.forEach(t),PWo=r(Kze," (RoBERTa model)"),Kze.forEach(t),BWo=i(x),db=n(x,"LI",{});var eQe=s(db);lTe=n(eQe,"STRONG",{});var vUt=s(lTe);IWo=r(vUt,"roc_bert"),vUt.forEach(t),NWo=r(eQe," \u2014 "),sU=n(eQe,"A",{href:!0});var FUt=s(sU);qWo=r(FUt,"RoCBertModel"),FUt.forEach(t),DWo=r(eQe," (RoCBert model)"),eQe.forEach(t),jWo=i(x),mb=n(x,"LI",{});var oQe=s(mb);iTe=n(oQe,"STRONG",{});var TUt=s(iTe);GWo=r(TUt,"roformer"),TUt.forEach(t),OWo=r(oQe," \u2014 "),lU=n(oQe,"A",{href:!0});var MUt=s(lU);VWo=r(MUt,"RoFormerModel"),MUt.forEach(t),XWo=r(oQe," (RoFormer model)"),oQe.forEach(t),zWo=i(x),cb=n(x,"LI",{});var rQe=s(cb);dTe=n(rQe,"STRONG",{});var EUt=s(dTe);QWo=r(EUt,"segformer"),EUt.forEach(t),WWo=r(rQe," \u2014 "),iU=n(rQe,"A",{href:!0});var CUt=s(iU);UWo=r(CUt,"SegformerModel"),CUt.forEach(t),HWo=r(rQe," (SegFormer model)"),rQe.forEach(t),JWo=i(x),fb=n(x,"LI",{});var tQe=s(fb);mTe=n(tQe,"STRONG",{});var wUt=s(mTe);YWo=r(wUt,"sew"),wUt.forEach(t),ZWo=r(tQe," \u2014 "),dU=n(tQe,"A",{href:!0});var AUt=s(dU);KWo=r(AUt,"SEWModel"),AUt.forEach(t),eUo=r(tQe," (SEW model)"),tQe.forEach(t),oUo=i(x),gb=n(x,"LI",{});var aQe=s(gb);cTe=n(aQe,"STRONG",{});var LUt=s(cTe);rUo=r(LUt,"sew-d"),LUt.forEach(t),tUo=r(aQe," \u2014 "),mU=n(aQe,"A",{href:!0});var yUt=s(mU);aUo=r(yUt,"SEWDModel"),yUt.forEach(t),nUo=r(aQe," (SEW-D model)"),aQe.forEach(t),sUo=i(x),hb=n(x,"LI",{});var nQe=s(hb);fTe=n(nQe,"STRONG",{});var xUt=s(fTe);lUo=r(xUt,"speech_to_text"),xUt.forEach(t),iUo=r(nQe," \u2014 "),cU=n(nQe,"A",{href:!0});var $Ut=s(cU);dUo=r($Ut,"Speech2TextModel"),$Ut.forEach(t),mUo=r(nQe," (Speech2Text model)"),nQe.forEach(t),cUo=i(x),ub=n(x,"LI",{});var sQe=s(ub);gTe=n(sQe,"STRONG",{});var kUt=s(gTe);fUo=r(kUt,"splinter"),kUt.forEach(t),gUo=r(sQe," \u2014 "),fU=n(sQe,"A",{href:!0});var SUt=s(fU);hUo=r(SUt,"SplinterModel"),SUt.forEach(t),uUo=r(sQe," (Splinter model)"),sQe.forEach(t),pUo=i(x),pb=n(x,"LI",{});var lQe=s(pb);hTe=n(lQe,"STRONG",{});var RUt=s(hTe);_Uo=r(RUt,"squeezebert"),RUt.forEach(t),bUo=r(lQe," \u2014 "),gU=n(lQe,"A",{href:!0});var PUt=s(gU);vUo=r(PUt,"SqueezeBertModel"),PUt.forEach(t),FUo=r(lQe," (SqueezeBERT model)"),lQe.forEach(t),TUo=i(x),_b=n(x,"LI",{});var iQe=s(_b);uTe=n(iQe,"STRONG",{});var BUt=s(uTe);MUo=r(BUt,"swin"),BUt.forEach(t),EUo=r(iQe," \u2014 "),hU=n(iQe,"A",{href:!0});var IUt=s(hU);CUo=r(IUt,"SwinModel"),IUt.forEach(t),wUo=r(iQe," (Swin Transformer model)"),iQe.forEach(t),AUo=i(x),bb=n(x,"LI",{});var dQe=s(bb);pTe=n(dQe,"STRONG",{});var NUt=s(pTe);LUo=r(NUt,"swinv2"),NUt.forEach(t),yUo=r(dQe," \u2014 "),uU=n(dQe,"A",{href:!0});var qUt=s(uU);xUo=r(qUt,"Swinv2Model"),qUt.forEach(t),$Uo=r(dQe," (Swin Transformer V2 model)"),dQe.forEach(t),kUo=i(x),vb=n(x,"LI",{});var mQe=s(vb);_Te=n(mQe,"STRONG",{});var DUt=s(_Te);SUo=r(DUt,"t5"),DUt.forEach(t),RUo=r(mQe," \u2014 "),pU=n(mQe,"A",{href:!0});var jUt=s(pU);PUo=r(jUt,"T5Model"),jUt.forEach(t),BUo=r(mQe," (T5 model)"),mQe.forEach(t),IUo=i(x),Fb=n(x,"LI",{});var cQe=s(Fb);bTe=n(cQe,"STRONG",{});var GUt=s(bTe);NUo=r(GUt,"table-transformer"),GUt.forEach(t),qUo=r(cQe," \u2014 "),_U=n(cQe,"A",{href:!0});var OUt=s(_U);DUo=r(OUt,"TableTransformerModel"),OUt.forEach(t),jUo=r(cQe," (Table Transformer model)"),cQe.forEach(t),GUo=i(x),Tb=n(x,"LI",{});var fQe=s(Tb);vTe=n(fQe,"STRONG",{});var VUt=s(vTe);OUo=r(VUt,"tapas"),VUt.forEach(t),VUo=r(fQe," \u2014 "),bU=n(fQe,"A",{href:!0});var XUt=s(bU);XUo=r(XUt,"TapasModel"),XUt.forEach(t),zUo=r(fQe," (TAPAS model)"),fQe.forEach(t),QUo=i(x),Mb=n(x,"LI",{});var gQe=s(Mb);FTe=n(gQe,"STRONG",{});var zUt=s(FTe);WUo=r(zUt,"time_series_transformer"),zUt.forEach(t),UUo=r(gQe," \u2014 "),vU=n(gQe,"A",{href:!0});var QUt=s(vU);HUo=r(QUt,"TimeSeriesTransformerModel"),QUt.forEach(t),JUo=r(gQe," (Time Series Transformer model)"),gQe.forEach(t),YUo=i(x),Eb=n(x,"LI",{});var hQe=s(Eb);TTe=n(hQe,"STRONG",{});var WUt=s(TTe);ZUo=r(WUt,"trajectory_transformer"),WUt.forEach(t),KUo=r(hQe," \u2014 "),FU=n(hQe,"A",{href:!0});var UUt=s(FU);eHo=r(UUt,"TrajectoryTransformerModel"),UUt.forEach(t),oHo=r(hQe," (Trajectory Transformer model)"),hQe.forEach(t),rHo=i(x),Cb=n(x,"LI",{});var uQe=s(Cb);MTe=n(uQe,"STRONG",{});var HUt=s(MTe);tHo=r(HUt,"transfo-xl"),HUt.forEach(t),aHo=r(uQe," \u2014 "),TU=n(uQe,"A",{href:!0});var JUt=s(TU);nHo=r(JUt,"TransfoXLModel"),JUt.forEach(t),sHo=r(uQe," (Transformer-XL model)"),uQe.forEach(t),lHo=i(x),wb=n(x,"LI",{});var pQe=s(wb);ETe=n(pQe,"STRONG",{});var YUt=s(ETe);iHo=r(YUt,"unispeech"),YUt.forEach(t),dHo=r(pQe," \u2014 "),MU=n(pQe,"A",{href:!0});var ZUt=s(MU);mHo=r(ZUt,"UniSpeechModel"),ZUt.forEach(t),cHo=r(pQe," (UniSpeech model)"),pQe.forEach(t),fHo=i(x),Ab=n(x,"LI",{});var _Qe=s(Ab);CTe=n(_Qe,"STRONG",{});var KUt=s(CTe);gHo=r(KUt,"unispeech-sat"),KUt.forEach(t),hHo=r(_Qe," \u2014 "),EU=n(_Qe,"A",{href:!0});var eHt=s(EU);uHo=r(eHt,"UniSpeechSatModel"),eHt.forEach(t),pHo=r(_Qe," (UniSpeechSat model)"),_Qe.forEach(t),_Ho=i(x),Lb=n(x,"LI",{});var bQe=s(Lb);wTe=n(bQe,"STRONG",{});var oHt=s(wTe);bHo=r(oHt,"van"),oHt.forEach(t),vHo=r(bQe," \u2014 "),CU=n(bQe,"A",{href:!0});var rHt=s(CU);FHo=r(rHt,"VanModel"),rHt.forEach(t),THo=r(bQe," (VAN model)"),bQe.forEach(t),MHo=i(x),yb=n(x,"LI",{});var vQe=s(yb);ATe=n(vQe,"STRONG",{});var tHt=s(ATe);EHo=r(tHt,"videomae"),tHt.forEach(t),CHo=r(vQe," \u2014 "),wU=n(vQe,"A",{href:!0});var aHt=s(wU);wHo=r(aHt,"VideoMAEModel"),aHt.forEach(t),AHo=r(vQe," (VideoMAE model)"),vQe.forEach(t),LHo=i(x),xb=n(x,"LI",{});var FQe=s(xb);LTe=n(FQe,"STRONG",{});var nHt=s(LTe);yHo=r(nHt,"vilt"),nHt.forEach(t),xHo=r(FQe," \u2014 "),AU=n(FQe,"A",{href:!0});var sHt=s(AU);$Ho=r(sHt,"ViltModel"),sHt.forEach(t),kHo=r(FQe," (ViLT model)"),FQe.forEach(t),SHo=i(x),$b=n(x,"LI",{});var TQe=s($b);yTe=n(TQe,"STRONG",{});var lHt=s(yTe);RHo=r(lHt,"vision-text-dual-encoder"),lHt.forEach(t),PHo=r(TQe," \u2014 "),LU=n(TQe,"A",{href:!0});var iHt=s(LU);BHo=r(iHt,"VisionTextDualEncoderModel"),iHt.forEach(t),IHo=r(TQe," (VisionTextDualEncoder model)"),TQe.forEach(t),NHo=i(x),kb=n(x,"LI",{});var MQe=s(kb);xTe=n(MQe,"STRONG",{});var dHt=s(xTe);qHo=r(dHt,"visual_bert"),dHt.forEach(t),DHo=r(MQe," \u2014 "),yU=n(MQe,"A",{href:!0});var mHt=s(yU);jHo=r(mHt,"VisualBertModel"),mHt.forEach(t),GHo=r(MQe," (VisualBERT model)"),MQe.forEach(t),OHo=i(x),Sb=n(x,"LI",{});var EQe=s(Sb);$Te=n(EQe,"STRONG",{});var cHt=s($Te);VHo=r(cHt,"vit"),cHt.forEach(t),XHo=r(EQe," \u2014 "),xU=n(EQe,"A",{href:!0});var fHt=s(xU);zHo=r(fHt,"ViTModel"),fHt.forEach(t),QHo=r(EQe," (ViT model)"),EQe.forEach(t),WHo=i(x),Rb=n(x,"LI",{});var CQe=s(Rb);kTe=n(CQe,"STRONG",{});var gHt=s(kTe);UHo=r(gHt,"vit_mae"),gHt.forEach(t),HHo=r(CQe," \u2014 "),$U=n(CQe,"A",{href:!0});var hHt=s($U);JHo=r(hHt,"ViTMAEModel"),hHt.forEach(t),YHo=r(CQe," (ViTMAE model)"),CQe.forEach(t),ZHo=i(x),Pb=n(x,"LI",{});var wQe=s(Pb);STe=n(wQe,"STRONG",{});var uHt=s(STe);KHo=r(uHt,"vit_msn"),uHt.forEach(t),eJo=r(wQe," \u2014 "),kU=n(wQe,"A",{href:!0});var pHt=s(kU);oJo=r(pHt,"ViTMSNModel"),pHt.forEach(t),rJo=r(wQe," (ViTMSN model)"),wQe.forEach(t),tJo=i(x),Bb=n(x,"LI",{});var AQe=s(Bb);RTe=n(AQe,"STRONG",{});var _Ht=s(RTe);aJo=r(_Ht,"wav2vec2"),_Ht.forEach(t),nJo=r(AQe," \u2014 "),SU=n(AQe,"A",{href:!0});var bHt=s(SU);sJo=r(bHt,"Wav2Vec2Model"),bHt.forEach(t),lJo=r(AQe," (Wav2Vec2 model)"),AQe.forEach(t),iJo=i(x),Ib=n(x,"LI",{});var LQe=s(Ib);PTe=n(LQe,"STRONG",{});var vHt=s(PTe);dJo=r(vHt,"wav2vec2-conformer"),vHt.forEach(t),mJo=r(LQe," \u2014 "),RU=n(LQe,"A",{href:!0});var FHt=s(RU);cJo=r(FHt,"Wav2Vec2ConformerModel"),FHt.forEach(t),fJo=r(LQe," (Wav2Vec2-Conformer model)"),LQe.forEach(t),gJo=i(x),Nb=n(x,"LI",{});var yQe=s(Nb);BTe=n(yQe,"STRONG",{});var THt=s(BTe);hJo=r(THt,"wavlm"),THt.forEach(t),uJo=r(yQe," \u2014 "),PU=n(yQe,"A",{href:!0});var MHt=s(PU);pJo=r(MHt,"WavLMModel"),MHt.forEach(t),_Jo=r(yQe," (WavLM model)"),yQe.forEach(t),bJo=i(x),qb=n(x,"LI",{});var xQe=s(qb);ITe=n(xQe,"STRONG",{});var EHt=s(ITe);vJo=r(EHt,"whisper"),EHt.forEach(t),FJo=r(xQe," \u2014 "),BU=n(xQe,"A",{href:!0});var CHt=s(BU);TJo=r(CHt,"WhisperModel"),CHt.forEach(t),MJo=r(xQe," (Whisper model)"),xQe.forEach(t),EJo=i(x),Db=n(x,"LI",{});var $Qe=s(Db);NTe=n($Qe,"STRONG",{});var wHt=s(NTe);CJo=r(wHt,"xclip"),wHt.forEach(t),wJo=r($Qe," \u2014 "),IU=n($Qe,"A",{href:!0});var AHt=s(IU);AJo=r(AHt,"XCLIPModel"),AHt.forEach(t),LJo=r($Qe," (X-CLIP model)"),$Qe.forEach(t),yJo=i(x),jb=n(x,"LI",{});var kQe=s(jb);qTe=n(kQe,"STRONG",{});var LHt=s(qTe);xJo=r(LHt,"xglm"),LHt.forEach(t),$Jo=r(kQe," \u2014 "),NU=n(kQe,"A",{href:!0});var yHt=s(NU);kJo=r(yHt,"XGLMModel"),yHt.forEach(t),SJo=r(kQe," (XGLM model)"),kQe.forEach(t),RJo=i(x),Gb=n(x,"LI",{});var SQe=s(Gb);DTe=n(SQe,"STRONG",{});var xHt=s(DTe);PJo=r(xHt,"xlm"),xHt.forEach(t),BJo=r(SQe," \u2014 "),qU=n(SQe,"A",{href:!0});var $Ht=s(qU);IJo=r($Ht,"XLMModel"),$Ht.forEach(t),NJo=r(SQe," (XLM model)"),SQe.forEach(t),qJo=i(x),Ob=n(x,"LI",{});var RQe=s(Ob);jTe=n(RQe,"STRONG",{});var kHt=s(jTe);DJo=r(kHt,"xlm-prophetnet"),kHt.forEach(t),jJo=r(RQe," \u2014 "),DU=n(RQe,"A",{href:!0});var SHt=s(DU);GJo=r(SHt,"XLMProphetNetModel"),SHt.forEach(t),OJo=r(RQe," (XLM-ProphetNet model)"),RQe.forEach(t),VJo=i(x),Vb=n(x,"LI",{});var PQe=s(Vb);GTe=n(PQe,"STRONG",{});var RHt=s(GTe);XJo=r(RHt,"xlm-roberta"),RHt.forEach(t),zJo=r(PQe," \u2014 "),jU=n(PQe,"A",{href:!0});var PHt=s(jU);QJo=r(PHt,"XLMRobertaModel"),PHt.forEach(t),WJo=r(PQe," (XLM-RoBERTa model)"),PQe.forEach(t),UJo=i(x),Xb=n(x,"LI",{});var BQe=s(Xb);OTe=n(BQe,"STRONG",{});var BHt=s(OTe);HJo=r(BHt,"xlm-roberta-xl"),BHt.forEach(t),JJo=r(BQe," \u2014 "),GU=n(BQe,"A",{href:!0});var IHt=s(GU);YJo=r(IHt,"XLMRobertaXLModel"),IHt.forEach(t),ZJo=r(BQe," (XLM-RoBERTa-XL model)"),BQe.forEach(t),KJo=i(x),zb=n(x,"LI",{});var IQe=s(zb);VTe=n(IQe,"STRONG",{});var NHt=s(VTe);eYo=r(NHt,"xlnet"),NHt.forEach(t),oYo=r(IQe," \u2014 "),OU=n(IQe,"A",{href:!0});var qHt=s(OU);rYo=r(qHt,"XLNetModel"),qHt.forEach(t),tYo=r(IQe," (XLNet model)"),IQe.forEach(t),aYo=i(x),Qb=n(x,"LI",{});var NQe=s(Qb);XTe=n(NQe,"STRONG",{});var DHt=s(XTe);nYo=r(DHt,"yolos"),DHt.forEach(t),sYo=r(NQe," \u2014 "),VU=n(NQe,"A",{href:!0});var jHt=s(VU);lYo=r(jHt,"YolosModel"),jHt.forEach(t),iYo=r(NQe," (YOLOS model)"),NQe.forEach(t),dYo=i(x),Wb=n(x,"LI",{});var qQe=s(Wb);zTe=n(qQe,"STRONG",{});var GHt=s(zTe);mYo=r(GHt,"yoso"),GHt.forEach(t),cYo=r(qQe," \u2014 "),XU=n(qQe,"A",{href:!0});var OHt=s(XU);fYo=r(OHt,"YosoModel"),OHt.forEach(t),gYo=r(qQe," (YOSO model)"),qQe.forEach(t),x.forEach(t),hYo=i(Sa),Ub=n(Sa,"P",{});var DQe=s(Ub);uYo=r(DQe,"The model is set in evaluation mode by default using "),QTe=n(DQe,"CODE",{});var VHt=s(QTe);pYo=r(VHt,"model.eval()"),VHt.forEach(t),_Yo=r(DQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),WTe=n(DQe,"CODE",{});var XHt=s(WTe);bYo=r(XHt,"model.train()"),XHt.forEach(t),DQe.forEach(t),vYo=i(Sa),T(Hb.$$.fragment,Sa),Sa.forEach(t),Ql.forEach(t),xlo=i(c),Xd=n(c,"H2",{class:!0});var Ydo=s(Xd);Jb=n(Ydo,"A",{id:!0,class:!0,href:!0});var zHt=s(Jb);UTe=n(zHt,"SPAN",{});var QHt=s(UTe);T(Uk.$$.fragment,QHt),QHt.forEach(t),zHt.forEach(t),FYo=i(Ydo),HTe=n(Ydo,"SPAN",{});var WHt=s(HTe);TYo=r(WHt,"AutoModelForPreTraining"),WHt.forEach(t),Ydo.forEach(t),$lo=i(c),Go=n(c,"DIV",{class:!0});var Wl=s(Go);T(Hk.$$.fragment,Wl),MYo=i(Wl),zd=n(Wl,"P",{});var sfe=s(zd);EYo=r(sfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),zU=n(sfe,"A",{href:!0});var UHt=s(zU);CYo=r(UHt,"from_pretrained()"),UHt.forEach(t),wYo=r(sfe," class method or the "),QU=n(sfe,"A",{href:!0});var HHt=s(QU);AYo=r(HHt,"from_config()"),HHt.forEach(t),LYo=r(sfe,` class
method.`),sfe.forEach(t),yYo=i(Wl),Jk=n(Wl,"P",{});var Zdo=s(Jk);xYo=r(Zdo,"This class cannot be instantiated directly using "),JTe=n(Zdo,"CODE",{});var JHt=s(JTe);$Yo=r(JHt,"__init__()"),JHt.forEach(t),kYo=r(Zdo," (throws an error)."),Zdo.forEach(t),SYo=i(Wl),Lt=n(Wl,"DIV",{class:!0});var ax=s(Lt);T(Yk.$$.fragment,ax),RYo=i(ax),YTe=n(ax,"P",{});var YHt=s(YTe);PYo=r(YHt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),YHt.forEach(t),BYo=i(ax),Qd=n(ax,"P",{});var lfe=s(Qd);IYo=r(lfe,`Note:
Loading a model from its configuration file does `),ZTe=n(lfe,"STRONG",{});var ZHt=s(ZTe);NYo=r(ZHt,"not"),ZHt.forEach(t),qYo=r(lfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),WU=n(lfe,"A",{href:!0});var KHt=s(WU);DYo=r(KHt,"from_pretrained()"),KHt.forEach(t),jYo=r(lfe," to load the model weights."),lfe.forEach(t),GYo=i(ax),T(Yb.$$.fragment,ax),ax.forEach(t),OYo=i(Wl),ao=n(Wl,"DIV",{class:!0});var Ra=s(ao);T(Zk.$$.fragment,Ra),VYo=i(Ra),KTe=n(Ra,"P",{});var eJt=s(KTe);XYo=r(eJt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),eJt.forEach(t),zYo=i(Ra),gn=n(Ra,"P",{});var nx=s(gn);QYo=r(nx,"The model class to instantiate is selected based on the "),eMe=n(nx,"CODE",{});var oJt=s(eMe);WYo=r(oJt,"model_type"),oJt.forEach(t),UYo=r(nx,` property of the config object (either
passed as an argument or loaded from `),oMe=n(nx,"CODE",{});var rJt=s(oMe);HYo=r(rJt,"pretrained_model_name_or_path"),rJt.forEach(t),JYo=r(nx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rMe=n(nx,"CODE",{});var tJt=s(rMe);YYo=r(tJt,"pretrained_model_name_or_path"),tJt.forEach(t),ZYo=r(nx,":"),nx.forEach(t),KYo=i(Ra),G=n(Ra,"UL",{});var V=s(G);Zb=n(V,"LI",{});var jQe=s(Zb);tMe=n(jQe,"STRONG",{});var aJt=s(tMe);eZo=r(aJt,"albert"),aJt.forEach(t),oZo=r(jQe," \u2014 "),UU=n(jQe,"A",{href:!0});var nJt=s(UU);rZo=r(nJt,"AlbertForPreTraining"),nJt.forEach(t),tZo=r(jQe," (ALBERT model)"),jQe.forEach(t),aZo=i(V),Kb=n(V,"LI",{});var GQe=s(Kb);aMe=n(GQe,"STRONG",{});var sJt=s(aMe);nZo=r(sJt,"bart"),sJt.forEach(t),sZo=r(GQe," \u2014 "),HU=n(GQe,"A",{href:!0});var lJt=s(HU);lZo=r(lJt,"BartForConditionalGeneration"),lJt.forEach(t),iZo=r(GQe," (BART model)"),GQe.forEach(t),dZo=i(V),ev=n(V,"LI",{});var OQe=s(ev);nMe=n(OQe,"STRONG",{});var iJt=s(nMe);mZo=r(iJt,"bert"),iJt.forEach(t),cZo=r(OQe," \u2014 "),JU=n(OQe,"A",{href:!0});var dJt=s(JU);fZo=r(dJt,"BertForPreTraining"),dJt.forEach(t),gZo=r(OQe," (BERT model)"),OQe.forEach(t),hZo=i(V),ov=n(V,"LI",{});var VQe=s(ov);sMe=n(VQe,"STRONG",{});var mJt=s(sMe);uZo=r(mJt,"big_bird"),mJt.forEach(t),pZo=r(VQe," \u2014 "),YU=n(VQe,"A",{href:!0});var cJt=s(YU);_Zo=r(cJt,"BigBirdForPreTraining"),cJt.forEach(t),bZo=r(VQe," (BigBird model)"),VQe.forEach(t),vZo=i(V),rv=n(V,"LI",{});var XQe=s(rv);lMe=n(XQe,"STRONG",{});var fJt=s(lMe);FZo=r(fJt,"bloom"),fJt.forEach(t),TZo=r(XQe," \u2014 "),ZU=n(XQe,"A",{href:!0});var gJt=s(ZU);MZo=r(gJt,"BloomForCausalLM"),gJt.forEach(t),EZo=r(XQe," (BLOOM model)"),XQe.forEach(t),CZo=i(V),tv=n(V,"LI",{});var zQe=s(tv);iMe=n(zQe,"STRONG",{});var hJt=s(iMe);wZo=r(hJt,"camembert"),hJt.forEach(t),AZo=r(zQe," \u2014 "),KU=n(zQe,"A",{href:!0});var uJt=s(KU);LZo=r(uJt,"CamembertForMaskedLM"),uJt.forEach(t),yZo=r(zQe," (CamemBERT model)"),zQe.forEach(t),xZo=i(V),av=n(V,"LI",{});var QQe=s(av);dMe=n(QQe,"STRONG",{});var pJt=s(dMe);$Zo=r(pJt,"ctrl"),pJt.forEach(t),kZo=r(QQe," \u2014 "),eH=n(QQe,"A",{href:!0});var _Jt=s(eH);SZo=r(_Jt,"CTRLLMHeadModel"),_Jt.forEach(t),RZo=r(QQe," (CTRL model)"),QQe.forEach(t),PZo=i(V),nv=n(V,"LI",{});var WQe=s(nv);mMe=n(WQe,"STRONG",{});var bJt=s(mMe);BZo=r(bJt,"data2vec-text"),bJt.forEach(t),IZo=r(WQe," \u2014 "),oH=n(WQe,"A",{href:!0});var vJt=s(oH);NZo=r(vJt,"Data2VecTextForMaskedLM"),vJt.forEach(t),qZo=r(WQe," (Data2VecText model)"),WQe.forEach(t),DZo=i(V),sv=n(V,"LI",{});var UQe=s(sv);cMe=n(UQe,"STRONG",{});var FJt=s(cMe);jZo=r(FJt,"deberta"),FJt.forEach(t),GZo=r(UQe," \u2014 "),rH=n(UQe,"A",{href:!0});var TJt=s(rH);OZo=r(TJt,"DebertaForMaskedLM"),TJt.forEach(t),VZo=r(UQe," (DeBERTa model)"),UQe.forEach(t),XZo=i(V),lv=n(V,"LI",{});var HQe=s(lv);fMe=n(HQe,"STRONG",{});var MJt=s(fMe);zZo=r(MJt,"deberta-v2"),MJt.forEach(t),QZo=r(HQe," \u2014 "),tH=n(HQe,"A",{href:!0});var EJt=s(tH);WZo=r(EJt,"DebertaV2ForMaskedLM"),EJt.forEach(t),UZo=r(HQe," (DeBERTa-v2 model)"),HQe.forEach(t),HZo=i(V),iv=n(V,"LI",{});var JQe=s(iv);gMe=n(JQe,"STRONG",{});var CJt=s(gMe);JZo=r(CJt,"distilbert"),CJt.forEach(t),YZo=r(JQe," \u2014 "),aH=n(JQe,"A",{href:!0});var wJt=s(aH);ZZo=r(wJt,"DistilBertForMaskedLM"),wJt.forEach(t),KZo=r(JQe," (DistilBERT model)"),JQe.forEach(t),eKo=i(V),dv=n(V,"LI",{});var YQe=s(dv);hMe=n(YQe,"STRONG",{});var AJt=s(hMe);oKo=r(AJt,"electra"),AJt.forEach(t),rKo=r(YQe," \u2014 "),nH=n(YQe,"A",{href:!0});var LJt=s(nH);tKo=r(LJt,"ElectraForPreTraining"),LJt.forEach(t),aKo=r(YQe," (ELECTRA model)"),YQe.forEach(t),nKo=i(V),mv=n(V,"LI",{});var ZQe=s(mv);uMe=n(ZQe,"STRONG",{});var yJt=s(uMe);sKo=r(yJt,"ernie"),yJt.forEach(t),lKo=r(ZQe," \u2014 "),sH=n(ZQe,"A",{href:!0});var xJt=s(sH);iKo=r(xJt,"ErnieForPreTraining"),xJt.forEach(t),dKo=r(ZQe," (ERNIE model)"),ZQe.forEach(t),mKo=i(V),cv=n(V,"LI",{});var KQe=s(cv);pMe=n(KQe,"STRONG",{});var $Jt=s(pMe);cKo=r($Jt,"flaubert"),$Jt.forEach(t),fKo=r(KQe," \u2014 "),lH=n(KQe,"A",{href:!0});var kJt=s(lH);gKo=r(kJt,"FlaubertWithLMHeadModel"),kJt.forEach(t),hKo=r(KQe," (FlauBERT model)"),KQe.forEach(t),uKo=i(V),fv=n(V,"LI",{});var eWe=s(fv);_Me=n(eWe,"STRONG",{});var SJt=s(_Me);pKo=r(SJt,"flava"),SJt.forEach(t),_Ko=r(eWe," \u2014 "),iH=n(eWe,"A",{href:!0});var RJt=s(iH);bKo=r(RJt,"FlavaForPreTraining"),RJt.forEach(t),vKo=r(eWe," (FLAVA model)"),eWe.forEach(t),FKo=i(V),gv=n(V,"LI",{});var oWe=s(gv);bMe=n(oWe,"STRONG",{});var PJt=s(bMe);TKo=r(PJt,"fnet"),PJt.forEach(t),MKo=r(oWe," \u2014 "),dH=n(oWe,"A",{href:!0});var BJt=s(dH);EKo=r(BJt,"FNetForPreTraining"),BJt.forEach(t),CKo=r(oWe," (FNet model)"),oWe.forEach(t),wKo=i(V),hv=n(V,"LI",{});var rWe=s(hv);vMe=n(rWe,"STRONG",{});var IJt=s(vMe);AKo=r(IJt,"fsmt"),IJt.forEach(t),LKo=r(rWe," \u2014 "),mH=n(rWe,"A",{href:!0});var NJt=s(mH);yKo=r(NJt,"FSMTForConditionalGeneration"),NJt.forEach(t),xKo=r(rWe," (FairSeq Machine-Translation model)"),rWe.forEach(t),$Ko=i(V),uv=n(V,"LI",{});var tWe=s(uv);FMe=n(tWe,"STRONG",{});var qJt=s(FMe);kKo=r(qJt,"funnel"),qJt.forEach(t),SKo=r(tWe," \u2014 "),cH=n(tWe,"A",{href:!0});var DJt=s(cH);RKo=r(DJt,"FunnelForPreTraining"),DJt.forEach(t),PKo=r(tWe," (Funnel Transformer model)"),tWe.forEach(t),BKo=i(V),pv=n(V,"LI",{});var aWe=s(pv);TMe=n(aWe,"STRONG",{});var jJt=s(TMe);IKo=r(jJt,"gpt2"),jJt.forEach(t),NKo=r(aWe," \u2014 "),fH=n(aWe,"A",{href:!0});var GJt=s(fH);qKo=r(GJt,"GPT2LMHeadModel"),GJt.forEach(t),DKo=r(aWe," (OpenAI GPT-2 model)"),aWe.forEach(t),jKo=i(V),_v=n(V,"LI",{});var nWe=s(_v);MMe=n(nWe,"STRONG",{});var OJt=s(MMe);GKo=r(OJt,"ibert"),OJt.forEach(t),OKo=r(nWe," \u2014 "),gH=n(nWe,"A",{href:!0});var VJt=s(gH);VKo=r(VJt,"IBertForMaskedLM"),VJt.forEach(t),XKo=r(nWe," (I-BERT model)"),nWe.forEach(t),zKo=i(V),bv=n(V,"LI",{});var sWe=s(bv);EMe=n(sWe,"STRONG",{});var XJt=s(EMe);QKo=r(XJt,"layoutlm"),XJt.forEach(t),WKo=r(sWe," \u2014 "),hH=n(sWe,"A",{href:!0});var zJt=s(hH);UKo=r(zJt,"LayoutLMForMaskedLM"),zJt.forEach(t),HKo=r(sWe," (LayoutLM model)"),sWe.forEach(t),JKo=i(V),vv=n(V,"LI",{});var lWe=s(vv);CMe=n(lWe,"STRONG",{});var QJt=s(CMe);YKo=r(QJt,"longformer"),QJt.forEach(t),ZKo=r(lWe," \u2014 "),uH=n(lWe,"A",{href:!0});var WJt=s(uH);KKo=r(WJt,"LongformerForMaskedLM"),WJt.forEach(t),eer=r(lWe," (Longformer model)"),lWe.forEach(t),oer=i(V),Fv=n(V,"LI",{});var iWe=s(Fv);wMe=n(iWe,"STRONG",{});var UJt=s(wMe);rer=r(UJt,"luke"),UJt.forEach(t),ter=r(iWe," \u2014 "),pH=n(iWe,"A",{href:!0});var HJt=s(pH);aer=r(HJt,"LukeForMaskedLM"),HJt.forEach(t),ner=r(iWe," (LUKE model)"),iWe.forEach(t),ser=i(V),Tv=n(V,"LI",{});var dWe=s(Tv);AMe=n(dWe,"STRONG",{});var JJt=s(AMe);ler=r(JJt,"lxmert"),JJt.forEach(t),ier=r(dWe," \u2014 "),_H=n(dWe,"A",{href:!0});var YJt=s(_H);der=r(YJt,"LxmertForPreTraining"),YJt.forEach(t),mer=r(dWe," (LXMERT model)"),dWe.forEach(t),cer=i(V),Mv=n(V,"LI",{});var mWe=s(Mv);LMe=n(mWe,"STRONG",{});var ZJt=s(LMe);fer=r(ZJt,"megatron-bert"),ZJt.forEach(t),ger=r(mWe," \u2014 "),bH=n(mWe,"A",{href:!0});var KJt=s(bH);her=r(KJt,"MegatronBertForPreTraining"),KJt.forEach(t),uer=r(mWe," (Megatron-BERT model)"),mWe.forEach(t),per=i(V),Ev=n(V,"LI",{});var cWe=s(Ev);yMe=n(cWe,"STRONG",{});var eYt=s(yMe);_er=r(eYt,"mobilebert"),eYt.forEach(t),ber=r(cWe," \u2014 "),vH=n(cWe,"A",{href:!0});var oYt=s(vH);ver=r(oYt,"MobileBertForPreTraining"),oYt.forEach(t),Fer=r(cWe," (MobileBERT model)"),cWe.forEach(t),Ter=i(V),Cv=n(V,"LI",{});var fWe=s(Cv);xMe=n(fWe,"STRONG",{});var rYt=s(xMe);Mer=r(rYt,"mpnet"),rYt.forEach(t),Eer=r(fWe," \u2014 "),FH=n(fWe,"A",{href:!0});var tYt=s(FH);Cer=r(tYt,"MPNetForMaskedLM"),tYt.forEach(t),wer=r(fWe," (MPNet model)"),fWe.forEach(t),Aer=i(V),wv=n(V,"LI",{});var gWe=s(wv);$Me=n(gWe,"STRONG",{});var aYt=s($Me);Ler=r(aYt,"mvp"),aYt.forEach(t),yer=r(gWe," \u2014 "),TH=n(gWe,"A",{href:!0});var nYt=s(TH);xer=r(nYt,"MvpForConditionalGeneration"),nYt.forEach(t),$er=r(gWe," (MVP model)"),gWe.forEach(t),ker=i(V),Av=n(V,"LI",{});var hWe=s(Av);kMe=n(hWe,"STRONG",{});var sYt=s(kMe);Ser=r(sYt,"nezha"),sYt.forEach(t),Rer=r(hWe," \u2014 "),MH=n(hWe,"A",{href:!0});var lYt=s(MH);Per=r(lYt,"NezhaForPreTraining"),lYt.forEach(t),Ber=r(hWe," (Nezha model)"),hWe.forEach(t),Ier=i(V),Lv=n(V,"LI",{});var uWe=s(Lv);SMe=n(uWe,"STRONG",{});var iYt=s(SMe);Ner=r(iYt,"openai-gpt"),iYt.forEach(t),qer=r(uWe," \u2014 "),EH=n(uWe,"A",{href:!0});var dYt=s(EH);Der=r(dYt,"OpenAIGPTLMHeadModel"),dYt.forEach(t),jer=r(uWe," (OpenAI GPT model)"),uWe.forEach(t),Ger=i(V),yv=n(V,"LI",{});var pWe=s(yv);RMe=n(pWe,"STRONG",{});var mYt=s(RMe);Oer=r(mYt,"retribert"),mYt.forEach(t),Ver=r(pWe," \u2014 "),CH=n(pWe,"A",{href:!0});var cYt=s(CH);Xer=r(cYt,"RetriBertModel"),cYt.forEach(t),zer=r(pWe," (RetriBERT model)"),pWe.forEach(t),Qer=i(V),xv=n(V,"LI",{});var _We=s(xv);PMe=n(_We,"STRONG",{});var fYt=s(PMe);Wer=r(fYt,"roberta"),fYt.forEach(t),Uer=r(_We," \u2014 "),wH=n(_We,"A",{href:!0});var gYt=s(wH);Her=r(gYt,"RobertaForMaskedLM"),gYt.forEach(t),Jer=r(_We," (RoBERTa model)"),_We.forEach(t),Yer=i(V),$v=n(V,"LI",{});var bWe=s($v);BMe=n(bWe,"STRONG",{});var hYt=s(BMe);Zer=r(hYt,"roc_bert"),hYt.forEach(t),Ker=r(bWe," \u2014 "),AH=n(bWe,"A",{href:!0});var uYt=s(AH);eor=r(uYt,"RoCBertForPreTraining"),uYt.forEach(t),oor=r(bWe," (RoCBert model)"),bWe.forEach(t),ror=i(V),kv=n(V,"LI",{});var vWe=s(kv);IMe=n(vWe,"STRONG",{});var pYt=s(IMe);tor=r(pYt,"splinter"),pYt.forEach(t),aor=r(vWe," \u2014 "),LH=n(vWe,"A",{href:!0});var _Yt=s(LH);nor=r(_Yt,"SplinterForPreTraining"),_Yt.forEach(t),sor=r(vWe," (Splinter model)"),vWe.forEach(t),lor=i(V),Sv=n(V,"LI",{});var FWe=s(Sv);NMe=n(FWe,"STRONG",{});var bYt=s(NMe);ior=r(bYt,"squeezebert"),bYt.forEach(t),dor=r(FWe," \u2014 "),yH=n(FWe,"A",{href:!0});var vYt=s(yH);mor=r(vYt,"SqueezeBertForMaskedLM"),vYt.forEach(t),cor=r(FWe," (SqueezeBERT model)"),FWe.forEach(t),gor=i(V),Rv=n(V,"LI",{});var TWe=s(Rv);qMe=n(TWe,"STRONG",{});var FYt=s(qMe);hor=r(FYt,"t5"),FYt.forEach(t),uor=r(TWe," \u2014 "),xH=n(TWe,"A",{href:!0});var TYt=s(xH);por=r(TYt,"T5ForConditionalGeneration"),TYt.forEach(t),_or=r(TWe," (T5 model)"),TWe.forEach(t),bor=i(V),Pv=n(V,"LI",{});var MWe=s(Pv);DMe=n(MWe,"STRONG",{});var MYt=s(DMe);vor=r(MYt,"tapas"),MYt.forEach(t),For=r(MWe," \u2014 "),$H=n(MWe,"A",{href:!0});var EYt=s($H);Tor=r(EYt,"TapasForMaskedLM"),EYt.forEach(t),Mor=r(MWe," (TAPAS model)"),MWe.forEach(t),Eor=i(V),Bv=n(V,"LI",{});var EWe=s(Bv);jMe=n(EWe,"STRONG",{});var CYt=s(jMe);Cor=r(CYt,"transfo-xl"),CYt.forEach(t),wor=r(EWe," \u2014 "),kH=n(EWe,"A",{href:!0});var wYt=s(kH);Aor=r(wYt,"TransfoXLLMHeadModel"),wYt.forEach(t),Lor=r(EWe," (Transformer-XL model)"),EWe.forEach(t),yor=i(V),Iv=n(V,"LI",{});var CWe=s(Iv);GMe=n(CWe,"STRONG",{});var AYt=s(GMe);xor=r(AYt,"unispeech"),AYt.forEach(t),$or=r(CWe," \u2014 "),SH=n(CWe,"A",{href:!0});var LYt=s(SH);kor=r(LYt,"UniSpeechForPreTraining"),LYt.forEach(t),Sor=r(CWe," (UniSpeech model)"),CWe.forEach(t),Ror=i(V),Nv=n(V,"LI",{});var wWe=s(Nv);OMe=n(wWe,"STRONG",{});var yYt=s(OMe);Por=r(yYt,"unispeech-sat"),yYt.forEach(t),Bor=r(wWe," \u2014 "),RH=n(wWe,"A",{href:!0});var xYt=s(RH);Ior=r(xYt,"UniSpeechSatForPreTraining"),xYt.forEach(t),Nor=r(wWe," (UniSpeechSat model)"),wWe.forEach(t),qor=i(V),qv=n(V,"LI",{});var AWe=s(qv);VMe=n(AWe,"STRONG",{});var $Yt=s(VMe);Dor=r($Yt,"videomae"),$Yt.forEach(t),jor=r(AWe," \u2014 "),PH=n(AWe,"A",{href:!0});var kYt=s(PH);Gor=r(kYt,"VideoMAEForPreTraining"),kYt.forEach(t),Oor=r(AWe," (VideoMAE model)"),AWe.forEach(t),Vor=i(V),Dv=n(V,"LI",{});var LWe=s(Dv);XMe=n(LWe,"STRONG",{});var SYt=s(XMe);Xor=r(SYt,"visual_bert"),SYt.forEach(t),zor=r(LWe," \u2014 "),BH=n(LWe,"A",{href:!0});var RYt=s(BH);Qor=r(RYt,"VisualBertForPreTraining"),RYt.forEach(t),Wor=r(LWe," (VisualBERT model)"),LWe.forEach(t),Uor=i(V),jv=n(V,"LI",{});var yWe=s(jv);zMe=n(yWe,"STRONG",{});var PYt=s(zMe);Hor=r(PYt,"vit_mae"),PYt.forEach(t),Jor=r(yWe," \u2014 "),IH=n(yWe,"A",{href:!0});var BYt=s(IH);Yor=r(BYt,"ViTMAEForPreTraining"),BYt.forEach(t),Zor=r(yWe," (ViTMAE model)"),yWe.forEach(t),Kor=i(V),Gv=n(V,"LI",{});var xWe=s(Gv);QMe=n(xWe,"STRONG",{});var IYt=s(QMe);err=r(IYt,"wav2vec2"),IYt.forEach(t),orr=r(xWe," \u2014 "),NH=n(xWe,"A",{href:!0});var NYt=s(NH);rrr=r(NYt,"Wav2Vec2ForPreTraining"),NYt.forEach(t),trr=r(xWe," (Wav2Vec2 model)"),xWe.forEach(t),arr=i(V),Ov=n(V,"LI",{});var $We=s(Ov);WMe=n($We,"STRONG",{});var qYt=s(WMe);nrr=r(qYt,"wav2vec2-conformer"),qYt.forEach(t),srr=r($We," \u2014 "),qH=n($We,"A",{href:!0});var DYt=s(qH);lrr=r(DYt,"Wav2Vec2ConformerForPreTraining"),DYt.forEach(t),irr=r($We," (Wav2Vec2-Conformer model)"),$We.forEach(t),drr=i(V),Vv=n(V,"LI",{});var kWe=s(Vv);UMe=n(kWe,"STRONG",{});var jYt=s(UMe);mrr=r(jYt,"xlm"),jYt.forEach(t),crr=r(kWe," \u2014 "),DH=n(kWe,"A",{href:!0});var GYt=s(DH);frr=r(GYt,"XLMWithLMHeadModel"),GYt.forEach(t),grr=r(kWe," (XLM model)"),kWe.forEach(t),hrr=i(V),Xv=n(V,"LI",{});var SWe=s(Xv);HMe=n(SWe,"STRONG",{});var OYt=s(HMe);urr=r(OYt,"xlm-roberta"),OYt.forEach(t),prr=r(SWe," \u2014 "),jH=n(SWe,"A",{href:!0});var VYt=s(jH);_rr=r(VYt,"XLMRobertaForMaskedLM"),VYt.forEach(t),brr=r(SWe," (XLM-RoBERTa model)"),SWe.forEach(t),vrr=i(V),zv=n(V,"LI",{});var RWe=s(zv);JMe=n(RWe,"STRONG",{});var XYt=s(JMe);Frr=r(XYt,"xlm-roberta-xl"),XYt.forEach(t),Trr=r(RWe," \u2014 "),GH=n(RWe,"A",{href:!0});var zYt=s(GH);Mrr=r(zYt,"XLMRobertaXLForMaskedLM"),zYt.forEach(t),Err=r(RWe," (XLM-RoBERTa-XL model)"),RWe.forEach(t),Crr=i(V),Qv=n(V,"LI",{});var PWe=s(Qv);YMe=n(PWe,"STRONG",{});var QYt=s(YMe);wrr=r(QYt,"xlnet"),QYt.forEach(t),Arr=r(PWe," \u2014 "),OH=n(PWe,"A",{href:!0});var WYt=s(OH);Lrr=r(WYt,"XLNetLMHeadModel"),WYt.forEach(t),yrr=r(PWe," (XLNet model)"),PWe.forEach(t),V.forEach(t),xrr=i(Ra),Wv=n(Ra,"P",{});var BWe=s(Wv);$rr=r(BWe,"The model is set in evaluation mode by default using "),ZMe=n(BWe,"CODE",{});var UYt=s(ZMe);krr=r(UYt,"model.eval()"),UYt.forEach(t),Srr=r(BWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),KMe=n(BWe,"CODE",{});var HYt=s(KMe);Rrr=r(HYt,"model.train()"),HYt.forEach(t),BWe.forEach(t),Prr=i(Ra),T(Uv.$$.fragment,Ra),Ra.forEach(t),Wl.forEach(t),klo=i(c),Wd=n(c,"H2",{class:!0});var Kdo=s(Wd);Hv=n(Kdo,"A",{id:!0,class:!0,href:!0});var JYt=s(Hv);eEe=n(JYt,"SPAN",{});var YYt=s(eEe);T(Kk.$$.fragment,YYt),YYt.forEach(t),JYt.forEach(t),Brr=i(Kdo),oEe=n(Kdo,"SPAN",{});var ZYt=s(oEe);Irr=r(ZYt,"AutoModelForCausalLM"),ZYt.forEach(t),Kdo.forEach(t),Slo=i(c),Oo=n(c,"DIV",{class:!0});var Ul=s(Oo);T(eS.$$.fragment,Ul),Nrr=i(Ul),Ud=n(Ul,"P",{});var ife=s(Ud);qrr=r(ife,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),VH=n(ife,"A",{href:!0});var KYt=s(VH);Drr=r(KYt,"from_pretrained()"),KYt.forEach(t),jrr=r(ife," class method or the "),XH=n(ife,"A",{href:!0});var eZt=s(XH);Grr=r(eZt,"from_config()"),eZt.forEach(t),Orr=r(ife,` class
method.`),ife.forEach(t),Vrr=i(Ul),oS=n(Ul,"P",{});var emo=s(oS);Xrr=r(emo,"This class cannot be instantiated directly using "),rEe=n(emo,"CODE",{});var oZt=s(rEe);zrr=r(oZt,"__init__()"),oZt.forEach(t),Qrr=r(emo," (throws an error)."),emo.forEach(t),Wrr=i(Ul),yt=n(Ul,"DIV",{class:!0});var sx=s(yt);T(rS.$$.fragment,sx),Urr=i(sx),tEe=n(sx,"P",{});var rZt=s(tEe);Hrr=r(rZt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),rZt.forEach(t),Jrr=i(sx),Hd=n(sx,"P",{});var dfe=s(Hd);Yrr=r(dfe,`Note:
Loading a model from its configuration file does `),aEe=n(dfe,"STRONG",{});var tZt=s(aEe);Zrr=r(tZt,"not"),tZt.forEach(t),Krr=r(dfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),zH=n(dfe,"A",{href:!0});var aZt=s(zH);etr=r(aZt,"from_pretrained()"),aZt.forEach(t),otr=r(dfe," to load the model weights."),dfe.forEach(t),rtr=i(sx),T(Jv.$$.fragment,sx),sx.forEach(t),ttr=i(Ul),no=n(Ul,"DIV",{class:!0});var Pa=s(no);T(tS.$$.fragment,Pa),atr=i(Pa),nEe=n(Pa,"P",{});var nZt=s(nEe);ntr=r(nZt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),nZt.forEach(t),str=i(Pa),hn=n(Pa,"P",{});var lx=s(hn);ltr=r(lx,"The model class to instantiate is selected based on the "),sEe=n(lx,"CODE",{});var sZt=s(sEe);itr=r(sZt,"model_type"),sZt.forEach(t),dtr=r(lx,` property of the config object (either
passed as an argument or loaded from `),lEe=n(lx,"CODE",{});var lZt=s(lEe);mtr=r(lZt,"pretrained_model_name_or_path"),lZt.forEach(t),ctr=r(lx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iEe=n(lx,"CODE",{});var iZt=s(iEe);ftr=r(iZt,"pretrained_model_name_or_path"),iZt.forEach(t),gtr=r(lx,":"),lx.forEach(t),htr=i(Pa),W=n(Pa,"UL",{});var H=s(W);Yv=n(H,"LI",{});var IWe=s(Yv);dEe=n(IWe,"STRONG",{});var dZt=s(dEe);utr=r(dZt,"bart"),dZt.forEach(t),ptr=r(IWe," \u2014 "),QH=n(IWe,"A",{href:!0});var mZt=s(QH);_tr=r(mZt,"BartForCausalLM"),mZt.forEach(t),btr=r(IWe," (BART model)"),IWe.forEach(t),vtr=i(H),Zv=n(H,"LI",{});var NWe=s(Zv);mEe=n(NWe,"STRONG",{});var cZt=s(mEe);Ftr=r(cZt,"bert"),cZt.forEach(t),Ttr=r(NWe," \u2014 "),WH=n(NWe,"A",{href:!0});var fZt=s(WH);Mtr=r(fZt,"BertLMHeadModel"),fZt.forEach(t),Etr=r(NWe," (BERT model)"),NWe.forEach(t),Ctr=i(H),Kv=n(H,"LI",{});var qWe=s(Kv);cEe=n(qWe,"STRONG",{});var gZt=s(cEe);wtr=r(gZt,"bert-generation"),gZt.forEach(t),Atr=r(qWe," \u2014 "),UH=n(qWe,"A",{href:!0});var hZt=s(UH);Ltr=r(hZt,"BertGenerationDecoder"),hZt.forEach(t),ytr=r(qWe," (Bert Generation model)"),qWe.forEach(t),xtr=i(H),eF=n(H,"LI",{});var DWe=s(eF);fEe=n(DWe,"STRONG",{});var uZt=s(fEe);$tr=r(uZt,"big_bird"),uZt.forEach(t),ktr=r(DWe," \u2014 "),HH=n(DWe,"A",{href:!0});var pZt=s(HH);Str=r(pZt,"BigBirdForCausalLM"),pZt.forEach(t),Rtr=r(DWe," (BigBird model)"),DWe.forEach(t),Ptr=i(H),oF=n(H,"LI",{});var jWe=s(oF);gEe=n(jWe,"STRONG",{});var _Zt=s(gEe);Btr=r(_Zt,"bigbird_pegasus"),_Zt.forEach(t),Itr=r(jWe," \u2014 "),JH=n(jWe,"A",{href:!0});var bZt=s(JH);Ntr=r(bZt,"BigBirdPegasusForCausalLM"),bZt.forEach(t),qtr=r(jWe," (BigBird-Pegasus model)"),jWe.forEach(t),Dtr=i(H),rF=n(H,"LI",{});var GWe=s(rF);hEe=n(GWe,"STRONG",{});var vZt=s(hEe);jtr=r(vZt,"blenderbot"),vZt.forEach(t),Gtr=r(GWe," \u2014 "),YH=n(GWe,"A",{href:!0});var FZt=s(YH);Otr=r(FZt,"BlenderbotForCausalLM"),FZt.forEach(t),Vtr=r(GWe," (Blenderbot model)"),GWe.forEach(t),Xtr=i(H),tF=n(H,"LI",{});var OWe=s(tF);uEe=n(OWe,"STRONG",{});var TZt=s(uEe);ztr=r(TZt,"blenderbot-small"),TZt.forEach(t),Qtr=r(OWe," \u2014 "),ZH=n(OWe,"A",{href:!0});var MZt=s(ZH);Wtr=r(MZt,"BlenderbotSmallForCausalLM"),MZt.forEach(t),Utr=r(OWe," (BlenderbotSmall model)"),OWe.forEach(t),Htr=i(H),aF=n(H,"LI",{});var VWe=s(aF);pEe=n(VWe,"STRONG",{});var EZt=s(pEe);Jtr=r(EZt,"bloom"),EZt.forEach(t),Ytr=r(VWe," \u2014 "),KH=n(VWe,"A",{href:!0});var CZt=s(KH);Ztr=r(CZt,"BloomForCausalLM"),CZt.forEach(t),Ktr=r(VWe," (BLOOM model)"),VWe.forEach(t),ear=i(H),nF=n(H,"LI",{});var XWe=s(nF);_Ee=n(XWe,"STRONG",{});var wZt=s(_Ee);oar=r(wZt,"camembert"),wZt.forEach(t),rar=r(XWe," \u2014 "),eJ=n(XWe,"A",{href:!0});var AZt=s(eJ);tar=r(AZt,"CamembertForCausalLM"),AZt.forEach(t),aar=r(XWe," (CamemBERT model)"),XWe.forEach(t),nar=i(H),sF=n(H,"LI",{});var zWe=s(sF);bEe=n(zWe,"STRONG",{});var LZt=s(bEe);sar=r(LZt,"codegen"),LZt.forEach(t),lar=r(zWe," \u2014 "),oJ=n(zWe,"A",{href:!0});var yZt=s(oJ);iar=r(yZt,"CodeGenForCausalLM"),yZt.forEach(t),dar=r(zWe," (CodeGen model)"),zWe.forEach(t),mar=i(H),lF=n(H,"LI",{});var QWe=s(lF);vEe=n(QWe,"STRONG",{});var xZt=s(vEe);car=r(xZt,"ctrl"),xZt.forEach(t),far=r(QWe," \u2014 "),rJ=n(QWe,"A",{href:!0});var $Zt=s(rJ);gar=r($Zt,"CTRLLMHeadModel"),$Zt.forEach(t),har=r(QWe," (CTRL model)"),QWe.forEach(t),uar=i(H),iF=n(H,"LI",{});var WWe=s(iF);FEe=n(WWe,"STRONG",{});var kZt=s(FEe);par=r(kZt,"data2vec-text"),kZt.forEach(t),_ar=r(WWe," \u2014 "),tJ=n(WWe,"A",{href:!0});var SZt=s(tJ);bar=r(SZt,"Data2VecTextForCausalLM"),SZt.forEach(t),Far=r(WWe," (Data2VecText model)"),WWe.forEach(t),Tar=i(H),dF=n(H,"LI",{});var UWe=s(dF);TEe=n(UWe,"STRONG",{});var RZt=s(TEe);Mar=r(RZt,"electra"),RZt.forEach(t),Ear=r(UWe," \u2014 "),aJ=n(UWe,"A",{href:!0});var PZt=s(aJ);Car=r(PZt,"ElectraForCausalLM"),PZt.forEach(t),war=r(UWe," (ELECTRA model)"),UWe.forEach(t),Aar=i(H),mF=n(H,"LI",{});var HWe=s(mF);MEe=n(HWe,"STRONG",{});var BZt=s(MEe);Lar=r(BZt,"ernie"),BZt.forEach(t),yar=r(HWe," \u2014 "),nJ=n(HWe,"A",{href:!0});var IZt=s(nJ);xar=r(IZt,"ErnieForCausalLM"),IZt.forEach(t),$ar=r(HWe," (ERNIE model)"),HWe.forEach(t),kar=i(H),cF=n(H,"LI",{});var JWe=s(cF);EEe=n(JWe,"STRONG",{});var NZt=s(EEe);Sar=r(NZt,"gpt2"),NZt.forEach(t),Rar=r(JWe," \u2014 "),sJ=n(JWe,"A",{href:!0});var qZt=s(sJ);Par=r(qZt,"GPT2LMHeadModel"),qZt.forEach(t),Bar=r(JWe," (OpenAI GPT-2 model)"),JWe.forEach(t),Iar=i(H),fF=n(H,"LI",{});var YWe=s(fF);CEe=n(YWe,"STRONG",{});var DZt=s(CEe);Nar=r(DZt,"gpt_neo"),DZt.forEach(t),qar=r(YWe," \u2014 "),lJ=n(YWe,"A",{href:!0});var jZt=s(lJ);Dar=r(jZt,"GPTNeoForCausalLM"),jZt.forEach(t),jar=r(YWe," (GPT Neo model)"),YWe.forEach(t),Gar=i(H),gF=n(H,"LI",{});var ZWe=s(gF);wEe=n(ZWe,"STRONG",{});var GZt=s(wEe);Oar=r(GZt,"gpt_neox"),GZt.forEach(t),Var=r(ZWe," \u2014 "),iJ=n(ZWe,"A",{href:!0});var OZt=s(iJ);Xar=r(OZt,"GPTNeoXForCausalLM"),OZt.forEach(t),zar=r(ZWe," (GPT NeoX model)"),ZWe.forEach(t),Qar=i(H),hF=n(H,"LI",{});var KWe=s(hF);AEe=n(KWe,"STRONG",{});var VZt=s(AEe);War=r(VZt,"gpt_neox_japanese"),VZt.forEach(t),Uar=r(KWe," \u2014 "),dJ=n(KWe,"A",{href:!0});var XZt=s(dJ);Har=r(XZt,"GPTNeoXJapaneseForCausalLM"),XZt.forEach(t),Jar=r(KWe," (GPT NeoX Japanese model)"),KWe.forEach(t),Yar=i(H),uF=n(H,"LI",{});var eUe=s(uF);LEe=n(eUe,"STRONG",{});var zZt=s(LEe);Zar=r(zZt,"gptj"),zZt.forEach(t),Kar=r(eUe," \u2014 "),mJ=n(eUe,"A",{href:!0});var QZt=s(mJ);enr=r(QZt,"GPTJForCausalLM"),QZt.forEach(t),onr=r(eUe," (GPT-J model)"),eUe.forEach(t),rnr=i(H),pF=n(H,"LI",{});var oUe=s(pF);yEe=n(oUe,"STRONG",{});var WZt=s(yEe);tnr=r(WZt,"marian"),WZt.forEach(t),anr=r(oUe," \u2014 "),cJ=n(oUe,"A",{href:!0});var UZt=s(cJ);nnr=r(UZt,"MarianForCausalLM"),UZt.forEach(t),snr=r(oUe," (Marian model)"),oUe.forEach(t),lnr=i(H),_F=n(H,"LI",{});var rUe=s(_F);xEe=n(rUe,"STRONG",{});var HZt=s(xEe);inr=r(HZt,"mbart"),HZt.forEach(t),dnr=r(rUe," \u2014 "),fJ=n(rUe,"A",{href:!0});var JZt=s(fJ);mnr=r(JZt,"MBartForCausalLM"),JZt.forEach(t),cnr=r(rUe," (mBART model)"),rUe.forEach(t),fnr=i(H),bF=n(H,"LI",{});var tUe=s(bF);$Ee=n(tUe,"STRONG",{});var YZt=s($Ee);gnr=r(YZt,"megatron-bert"),YZt.forEach(t),hnr=r(tUe," \u2014 "),gJ=n(tUe,"A",{href:!0});var ZZt=s(gJ);unr=r(ZZt,"MegatronBertForCausalLM"),ZZt.forEach(t),pnr=r(tUe," (Megatron-BERT model)"),tUe.forEach(t),_nr=i(H),vF=n(H,"LI",{});var aUe=s(vF);kEe=n(aUe,"STRONG",{});var KZt=s(kEe);bnr=r(KZt,"mvp"),KZt.forEach(t),vnr=r(aUe," \u2014 "),hJ=n(aUe,"A",{href:!0});var eKt=s(hJ);Fnr=r(eKt,"MvpForCausalLM"),eKt.forEach(t),Tnr=r(aUe," (MVP model)"),aUe.forEach(t),Mnr=i(H),FF=n(H,"LI",{});var nUe=s(FF);SEe=n(nUe,"STRONG",{});var oKt=s(SEe);Enr=r(oKt,"openai-gpt"),oKt.forEach(t),Cnr=r(nUe," \u2014 "),uJ=n(nUe,"A",{href:!0});var rKt=s(uJ);wnr=r(rKt,"OpenAIGPTLMHeadModel"),rKt.forEach(t),Anr=r(nUe," (OpenAI GPT model)"),nUe.forEach(t),Lnr=i(H),TF=n(H,"LI",{});var sUe=s(TF);REe=n(sUe,"STRONG",{});var tKt=s(REe);ynr=r(tKt,"opt"),tKt.forEach(t),xnr=r(sUe," \u2014 "),pJ=n(sUe,"A",{href:!0});var aKt=s(pJ);$nr=r(aKt,"OPTForCausalLM"),aKt.forEach(t),knr=r(sUe," (OPT model)"),sUe.forEach(t),Snr=i(H),MF=n(H,"LI",{});var lUe=s(MF);PEe=n(lUe,"STRONG",{});var nKt=s(PEe);Rnr=r(nKt,"pegasus"),nKt.forEach(t),Pnr=r(lUe," \u2014 "),_J=n(lUe,"A",{href:!0});var sKt=s(_J);Bnr=r(sKt,"PegasusForCausalLM"),sKt.forEach(t),Inr=r(lUe," (Pegasus model)"),lUe.forEach(t),Nnr=i(H),EF=n(H,"LI",{});var iUe=s(EF);BEe=n(iUe,"STRONG",{});var lKt=s(BEe);qnr=r(lKt,"plbart"),lKt.forEach(t),Dnr=r(iUe," \u2014 "),bJ=n(iUe,"A",{href:!0});var iKt=s(bJ);jnr=r(iKt,"PLBartForCausalLM"),iKt.forEach(t),Gnr=r(iUe," (PLBart model)"),iUe.forEach(t),Onr=i(H),CF=n(H,"LI",{});var dUe=s(CF);IEe=n(dUe,"STRONG",{});var dKt=s(IEe);Vnr=r(dKt,"prophetnet"),dKt.forEach(t),Xnr=r(dUe," \u2014 "),vJ=n(dUe,"A",{href:!0});var mKt=s(vJ);znr=r(mKt,"ProphetNetForCausalLM"),mKt.forEach(t),Qnr=r(dUe," (ProphetNet model)"),dUe.forEach(t),Wnr=i(H),wF=n(H,"LI",{});var mUe=s(wF);NEe=n(mUe,"STRONG",{});var cKt=s(NEe);Unr=r(cKt,"qdqbert"),cKt.forEach(t),Hnr=r(mUe," \u2014 "),FJ=n(mUe,"A",{href:!0});var fKt=s(FJ);Jnr=r(fKt,"QDQBertLMHeadModel"),fKt.forEach(t),Ynr=r(mUe," (QDQBert model)"),mUe.forEach(t),Znr=i(H),AF=n(H,"LI",{});var cUe=s(AF);qEe=n(cUe,"STRONG",{});var gKt=s(qEe);Knr=r(gKt,"reformer"),gKt.forEach(t),esr=r(cUe," \u2014 "),TJ=n(cUe,"A",{href:!0});var hKt=s(TJ);osr=r(hKt,"ReformerModelWithLMHead"),hKt.forEach(t),rsr=r(cUe," (Reformer model)"),cUe.forEach(t),tsr=i(H),LF=n(H,"LI",{});var fUe=s(LF);DEe=n(fUe,"STRONG",{});var uKt=s(DEe);asr=r(uKt,"rembert"),uKt.forEach(t),nsr=r(fUe," \u2014 "),MJ=n(fUe,"A",{href:!0});var pKt=s(MJ);ssr=r(pKt,"RemBertForCausalLM"),pKt.forEach(t),lsr=r(fUe," (RemBERT model)"),fUe.forEach(t),isr=i(H),yF=n(H,"LI",{});var gUe=s(yF);jEe=n(gUe,"STRONG",{});var _Kt=s(jEe);dsr=r(_Kt,"roberta"),_Kt.forEach(t),msr=r(gUe," \u2014 "),EJ=n(gUe,"A",{href:!0});var bKt=s(EJ);csr=r(bKt,"RobertaForCausalLM"),bKt.forEach(t),fsr=r(gUe," (RoBERTa model)"),gUe.forEach(t),gsr=i(H),xF=n(H,"LI",{});var hUe=s(xF);GEe=n(hUe,"STRONG",{});var vKt=s(GEe);hsr=r(vKt,"roc_bert"),vKt.forEach(t),usr=r(hUe," \u2014 "),CJ=n(hUe,"A",{href:!0});var FKt=s(CJ);psr=r(FKt,"RoCBertForCausalLM"),FKt.forEach(t),_sr=r(hUe," (RoCBert model)"),hUe.forEach(t),bsr=i(H),$F=n(H,"LI",{});var uUe=s($F);OEe=n(uUe,"STRONG",{});var TKt=s(OEe);vsr=r(TKt,"roformer"),TKt.forEach(t),Fsr=r(uUe," \u2014 "),wJ=n(uUe,"A",{href:!0});var MKt=s(wJ);Tsr=r(MKt,"RoFormerForCausalLM"),MKt.forEach(t),Msr=r(uUe," (RoFormer model)"),uUe.forEach(t),Esr=i(H),kF=n(H,"LI",{});var pUe=s(kF);VEe=n(pUe,"STRONG",{});var EKt=s(VEe);Csr=r(EKt,"speech_to_text_2"),EKt.forEach(t),wsr=r(pUe," \u2014 "),AJ=n(pUe,"A",{href:!0});var CKt=s(AJ);Asr=r(CKt,"Speech2Text2ForCausalLM"),CKt.forEach(t),Lsr=r(pUe," (Speech2Text2 model)"),pUe.forEach(t),ysr=i(H),SF=n(H,"LI",{});var _Ue=s(SF);XEe=n(_Ue,"STRONG",{});var wKt=s(XEe);xsr=r(wKt,"transfo-xl"),wKt.forEach(t),$sr=r(_Ue," \u2014 "),LJ=n(_Ue,"A",{href:!0});var AKt=s(LJ);ksr=r(AKt,"TransfoXLLMHeadModel"),AKt.forEach(t),Ssr=r(_Ue," (Transformer-XL model)"),_Ue.forEach(t),Rsr=i(H),RF=n(H,"LI",{});var bUe=s(RF);zEe=n(bUe,"STRONG",{});var LKt=s(zEe);Psr=r(LKt,"trocr"),LKt.forEach(t),Bsr=r(bUe," \u2014 "),yJ=n(bUe,"A",{href:!0});var yKt=s(yJ);Isr=r(yKt,"TrOCRForCausalLM"),yKt.forEach(t),Nsr=r(bUe," (TrOCR model)"),bUe.forEach(t),qsr=i(H),PF=n(H,"LI",{});var vUe=s(PF);QEe=n(vUe,"STRONG",{});var xKt=s(QEe);Dsr=r(xKt,"xglm"),xKt.forEach(t),jsr=r(vUe," \u2014 "),xJ=n(vUe,"A",{href:!0});var $Kt=s(xJ);Gsr=r($Kt,"XGLMForCausalLM"),$Kt.forEach(t),Osr=r(vUe," (XGLM model)"),vUe.forEach(t),Vsr=i(H),BF=n(H,"LI",{});var FUe=s(BF);WEe=n(FUe,"STRONG",{});var kKt=s(WEe);Xsr=r(kKt,"xlm"),kKt.forEach(t),zsr=r(FUe," \u2014 "),$J=n(FUe,"A",{href:!0});var SKt=s($J);Qsr=r(SKt,"XLMWithLMHeadModel"),SKt.forEach(t),Wsr=r(FUe," (XLM model)"),FUe.forEach(t),Usr=i(H),IF=n(H,"LI",{});var TUe=s(IF);UEe=n(TUe,"STRONG",{});var RKt=s(UEe);Hsr=r(RKt,"xlm-prophetnet"),RKt.forEach(t),Jsr=r(TUe," \u2014 "),kJ=n(TUe,"A",{href:!0});var PKt=s(kJ);Ysr=r(PKt,"XLMProphetNetForCausalLM"),PKt.forEach(t),Zsr=r(TUe," (XLM-ProphetNet model)"),TUe.forEach(t),Ksr=i(H),NF=n(H,"LI",{});var MUe=s(NF);HEe=n(MUe,"STRONG",{});var BKt=s(HEe);elr=r(BKt,"xlm-roberta"),BKt.forEach(t),olr=r(MUe," \u2014 "),SJ=n(MUe,"A",{href:!0});var IKt=s(SJ);rlr=r(IKt,"XLMRobertaForCausalLM"),IKt.forEach(t),tlr=r(MUe," (XLM-RoBERTa model)"),MUe.forEach(t),alr=i(H),qF=n(H,"LI",{});var EUe=s(qF);JEe=n(EUe,"STRONG",{});var NKt=s(JEe);nlr=r(NKt,"xlm-roberta-xl"),NKt.forEach(t),slr=r(EUe," \u2014 "),RJ=n(EUe,"A",{href:!0});var qKt=s(RJ);llr=r(qKt,"XLMRobertaXLForCausalLM"),qKt.forEach(t),ilr=r(EUe," (XLM-RoBERTa-XL model)"),EUe.forEach(t),dlr=i(H),DF=n(H,"LI",{});var CUe=s(DF);YEe=n(CUe,"STRONG",{});var DKt=s(YEe);mlr=r(DKt,"xlnet"),DKt.forEach(t),clr=r(CUe," \u2014 "),PJ=n(CUe,"A",{href:!0});var jKt=s(PJ);flr=r(jKt,"XLNetLMHeadModel"),jKt.forEach(t),glr=r(CUe," (XLNet model)"),CUe.forEach(t),H.forEach(t),hlr=i(Pa),jF=n(Pa,"P",{});var wUe=s(jF);ulr=r(wUe,"The model is set in evaluation mode by default using "),ZEe=n(wUe,"CODE",{});var GKt=s(ZEe);plr=r(GKt,"model.eval()"),GKt.forEach(t),_lr=r(wUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),KEe=n(wUe,"CODE",{});var OKt=s(KEe);blr=r(OKt,"model.train()"),OKt.forEach(t),wUe.forEach(t),vlr=i(Pa),T(GF.$$.fragment,Pa),Pa.forEach(t),Ul.forEach(t),Rlo=i(c),Jd=n(c,"H2",{class:!0});var omo=s(Jd);OF=n(omo,"A",{id:!0,class:!0,href:!0});var VKt=s(OF);e4e=n(VKt,"SPAN",{});var XKt=s(e4e);T(aS.$$.fragment,XKt),XKt.forEach(t),VKt.forEach(t),Flr=i(omo),o4e=n(omo,"SPAN",{});var zKt=s(o4e);Tlr=r(zKt,"AutoModelForDepthEstimation"),zKt.forEach(t),omo.forEach(t),Plo=i(c),Vo=n(c,"DIV",{class:!0});var Hl=s(Vo);T(nS.$$.fragment,Hl),Mlr=i(Hl),Yd=n(Hl,"P",{});var mfe=s(Yd);Elr=r(mfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a depth estimation head) when created
with the `),BJ=n(mfe,"A",{href:!0});var QKt=s(BJ);Clr=r(QKt,"from_pretrained()"),QKt.forEach(t),wlr=r(mfe," class method or the "),IJ=n(mfe,"A",{href:!0});var WKt=s(IJ);Alr=r(WKt,"from_config()"),WKt.forEach(t),Llr=r(mfe,` class
method.`),mfe.forEach(t),ylr=i(Hl),sS=n(Hl,"P",{});var rmo=s(sS);xlr=r(rmo,"This class cannot be instantiated directly using "),r4e=n(rmo,"CODE",{});var UKt=s(r4e);$lr=r(UKt,"__init__()"),UKt.forEach(t),klr=r(rmo," (throws an error)."),rmo.forEach(t),Slr=i(Hl),xt=n(Hl,"DIV",{class:!0});var ix=s(xt);T(lS.$$.fragment,ix),Rlr=i(ix),t4e=n(ix,"P",{});var HKt=s(t4e);Plr=r(HKt,"Instantiates one of the model classes of the library (with a depth estimation head) from a configuration."),HKt.forEach(t),Blr=i(ix),Zd=n(ix,"P",{});var cfe=s(Zd);Ilr=r(cfe,`Note:
Loading a model from its configuration file does `),a4e=n(cfe,"STRONG",{});var JKt=s(a4e);Nlr=r(JKt,"not"),JKt.forEach(t),qlr=r(cfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),NJ=n(cfe,"A",{href:!0});var YKt=s(NJ);Dlr=r(YKt,"from_pretrained()"),YKt.forEach(t),jlr=r(cfe," to load the model weights."),cfe.forEach(t),Glr=i(ix),T(VF.$$.fragment,ix),ix.forEach(t),Olr=i(Hl),so=n(Hl,"DIV",{class:!0});var Ba=s(so);T(iS.$$.fragment,Ba),Vlr=i(Ba),n4e=n(Ba,"P",{});var ZKt=s(n4e);Xlr=r(ZKt,"Instantiate one of the model classes of the library (with a depth estimation head) from a pretrained model."),ZKt.forEach(t),zlr=i(Ba),un=n(Ba,"P",{});var dx=s(un);Qlr=r(dx,"The model class to instantiate is selected based on the "),s4e=n(dx,"CODE",{});var KKt=s(s4e);Wlr=r(KKt,"model_type"),KKt.forEach(t),Ulr=r(dx,` property of the config object (either
passed as an argument or loaded from `),l4e=n(dx,"CODE",{});var eea=s(l4e);Hlr=r(eea,"pretrained_model_name_or_path"),eea.forEach(t),Jlr=r(dx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i4e=n(dx,"CODE",{});var oea=s(i4e);Ylr=r(oea,"pretrained_model_name_or_path"),oea.forEach(t),Zlr=r(dx,":"),dx.forEach(t),Klr=i(Ba),dS=n(Ba,"UL",{});var tmo=s(dS);XF=n(tmo,"LI",{});var AUe=s(XF);d4e=n(AUe,"STRONG",{});var rea=s(d4e);eir=r(rea,"dpt"),rea.forEach(t),oir=r(AUe," \u2014 "),qJ=n(AUe,"A",{href:!0});var tea=s(qJ);rir=r(tea,"DPTForDepthEstimation"),tea.forEach(t),tir=r(AUe," (DPT model)"),AUe.forEach(t),air=i(tmo),zF=n(tmo,"LI",{});var LUe=s(zF);m4e=n(LUe,"STRONG",{});var aea=s(m4e);nir=r(aea,"glpn"),aea.forEach(t),sir=r(LUe," \u2014 "),DJ=n(LUe,"A",{href:!0});var nea=s(DJ);lir=r(nea,"GLPNForDepthEstimation"),nea.forEach(t),iir=r(LUe," (GLPN model)"),LUe.forEach(t),tmo.forEach(t),dir=i(Ba),QF=n(Ba,"P",{});var yUe=s(QF);mir=r(yUe,"The model is set in evaluation mode by default using "),c4e=n(yUe,"CODE",{});var sea=s(c4e);cir=r(sea,"model.eval()"),sea.forEach(t),fir=r(yUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),f4e=n(yUe,"CODE",{});var lea=s(f4e);gir=r(lea,"model.train()"),lea.forEach(t),yUe.forEach(t),hir=i(Ba),T(WF.$$.fragment,Ba),Ba.forEach(t),Hl.forEach(t),Blo=i(c),Kd=n(c,"H2",{class:!0});var amo=s(Kd);UF=n(amo,"A",{id:!0,class:!0,href:!0});var iea=s(UF);g4e=n(iea,"SPAN",{});var dea=s(g4e);T(mS.$$.fragment,dea),dea.forEach(t),iea.forEach(t),uir=i(amo),h4e=n(amo,"SPAN",{});var mea=s(h4e);pir=r(mea,"AutoModelForMaskedLM"),mea.forEach(t),amo.forEach(t),Ilo=i(c),Xo=n(c,"DIV",{class:!0});var Jl=s(Xo);T(cS.$$.fragment,Jl),_ir=i(Jl),em=n(Jl,"P",{});var ffe=s(em);bir=r(ffe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),jJ=n(ffe,"A",{href:!0});var cea=s(jJ);vir=r(cea,"from_pretrained()"),cea.forEach(t),Fir=r(ffe," class method or the "),GJ=n(ffe,"A",{href:!0});var fea=s(GJ);Tir=r(fea,"from_config()"),fea.forEach(t),Mir=r(ffe,` class
method.`),ffe.forEach(t),Eir=i(Jl),fS=n(Jl,"P",{});var nmo=s(fS);Cir=r(nmo,"This class cannot be instantiated directly using "),u4e=n(nmo,"CODE",{});var gea=s(u4e);wir=r(gea,"__init__()"),gea.forEach(t),Air=r(nmo," (throws an error)."),nmo.forEach(t),Lir=i(Jl),$t=n(Jl,"DIV",{class:!0});var mx=s($t);T(gS.$$.fragment,mx),yir=i(mx),p4e=n(mx,"P",{});var hea=s(p4e);xir=r(hea,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),hea.forEach(t),$ir=i(mx),om=n(mx,"P",{});var gfe=s(om);kir=r(gfe,`Note:
Loading a model from its configuration file does `),_4e=n(gfe,"STRONG",{});var uea=s(_4e);Sir=r(uea,"not"),uea.forEach(t),Rir=r(gfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),OJ=n(gfe,"A",{href:!0});var pea=s(OJ);Pir=r(pea,"from_pretrained()"),pea.forEach(t),Bir=r(gfe," to load the model weights."),gfe.forEach(t),Iir=i(mx),T(HF.$$.fragment,mx),mx.forEach(t),Nir=i(Jl),lo=n(Jl,"DIV",{class:!0});var Ia=s(lo);T(hS.$$.fragment,Ia),qir=i(Ia),b4e=n(Ia,"P",{});var _ea=s(b4e);Dir=r(_ea,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),_ea.forEach(t),jir=i(Ia),pn=n(Ia,"P",{});var cx=s(pn);Gir=r(cx,"The model class to instantiate is selected based on the "),v4e=n(cx,"CODE",{});var bea=s(v4e);Oir=r(bea,"model_type"),bea.forEach(t),Vir=r(cx,` property of the config object (either
passed as an argument or loaded from `),F4e=n(cx,"CODE",{});var vea=s(F4e);Xir=r(vea,"pretrained_model_name_or_path"),vea.forEach(t),zir=r(cx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T4e=n(cx,"CODE",{});var Fea=s(T4e);Qir=r(Fea,"pretrained_model_name_or_path"),Fea.forEach(t),Wir=r(cx,":"),cx.forEach(t),Uir=i(Ia),Y=n(Ia,"UL",{});var Z=s(Y);JF=n(Z,"LI",{});var xUe=s(JF);M4e=n(xUe,"STRONG",{});var Tea=s(M4e);Hir=r(Tea,"albert"),Tea.forEach(t),Jir=r(xUe," \u2014 "),VJ=n(xUe,"A",{href:!0});var Mea=s(VJ);Yir=r(Mea,"AlbertForMaskedLM"),Mea.forEach(t),Zir=r(xUe," (ALBERT model)"),xUe.forEach(t),Kir=i(Z),YF=n(Z,"LI",{});var $Ue=s(YF);E4e=n($Ue,"STRONG",{});var Eea=s(E4e);edr=r(Eea,"bart"),Eea.forEach(t),odr=r($Ue," \u2014 "),XJ=n($Ue,"A",{href:!0});var Cea=s(XJ);rdr=r(Cea,"BartForConditionalGeneration"),Cea.forEach(t),tdr=r($Ue," (BART model)"),$Ue.forEach(t),adr=i(Z),ZF=n(Z,"LI",{});var kUe=s(ZF);C4e=n(kUe,"STRONG",{});var wea=s(C4e);ndr=r(wea,"bert"),wea.forEach(t),sdr=r(kUe," \u2014 "),zJ=n(kUe,"A",{href:!0});var Aea=s(zJ);ldr=r(Aea,"BertForMaskedLM"),Aea.forEach(t),idr=r(kUe," (BERT model)"),kUe.forEach(t),ddr=i(Z),KF=n(Z,"LI",{});var SUe=s(KF);w4e=n(SUe,"STRONG",{});var Lea=s(w4e);mdr=r(Lea,"big_bird"),Lea.forEach(t),cdr=r(SUe," \u2014 "),QJ=n(SUe,"A",{href:!0});var yea=s(QJ);fdr=r(yea,"BigBirdForMaskedLM"),yea.forEach(t),gdr=r(SUe," (BigBird model)"),SUe.forEach(t),hdr=i(Z),eT=n(Z,"LI",{});var RUe=s(eT);A4e=n(RUe,"STRONG",{});var xea=s(A4e);udr=r(xea,"camembert"),xea.forEach(t),pdr=r(RUe," \u2014 "),WJ=n(RUe,"A",{href:!0});var $ea=s(WJ);_dr=r($ea,"CamembertForMaskedLM"),$ea.forEach(t),bdr=r(RUe," (CamemBERT model)"),RUe.forEach(t),vdr=i(Z),oT=n(Z,"LI",{});var PUe=s(oT);L4e=n(PUe,"STRONG",{});var kea=s(L4e);Fdr=r(kea,"convbert"),kea.forEach(t),Tdr=r(PUe," \u2014 "),UJ=n(PUe,"A",{href:!0});var Sea=s(UJ);Mdr=r(Sea,"ConvBertForMaskedLM"),Sea.forEach(t),Edr=r(PUe," (ConvBERT model)"),PUe.forEach(t),Cdr=i(Z),rT=n(Z,"LI",{});var BUe=s(rT);y4e=n(BUe,"STRONG",{});var Rea=s(y4e);wdr=r(Rea,"data2vec-text"),Rea.forEach(t),Adr=r(BUe," \u2014 "),HJ=n(BUe,"A",{href:!0});var Pea=s(HJ);Ldr=r(Pea,"Data2VecTextForMaskedLM"),Pea.forEach(t),ydr=r(BUe," (Data2VecText model)"),BUe.forEach(t),xdr=i(Z),tT=n(Z,"LI",{});var IUe=s(tT);x4e=n(IUe,"STRONG",{});var Bea=s(x4e);$dr=r(Bea,"deberta"),Bea.forEach(t),kdr=r(IUe," \u2014 "),JJ=n(IUe,"A",{href:!0});var Iea=s(JJ);Sdr=r(Iea,"DebertaForMaskedLM"),Iea.forEach(t),Rdr=r(IUe," (DeBERTa model)"),IUe.forEach(t),Pdr=i(Z),aT=n(Z,"LI",{});var NUe=s(aT);$4e=n(NUe,"STRONG",{});var Nea=s($4e);Bdr=r(Nea,"deberta-v2"),Nea.forEach(t),Idr=r(NUe," \u2014 "),YJ=n(NUe,"A",{href:!0});var qea=s(YJ);Ndr=r(qea,"DebertaV2ForMaskedLM"),qea.forEach(t),qdr=r(NUe," (DeBERTa-v2 model)"),NUe.forEach(t),Ddr=i(Z),nT=n(Z,"LI",{});var qUe=s(nT);k4e=n(qUe,"STRONG",{});var Dea=s(k4e);jdr=r(Dea,"distilbert"),Dea.forEach(t),Gdr=r(qUe," \u2014 "),ZJ=n(qUe,"A",{href:!0});var jea=s(ZJ);Odr=r(jea,"DistilBertForMaskedLM"),jea.forEach(t),Vdr=r(qUe," (DistilBERT model)"),qUe.forEach(t),Xdr=i(Z),sT=n(Z,"LI",{});var DUe=s(sT);S4e=n(DUe,"STRONG",{});var Gea=s(S4e);zdr=r(Gea,"electra"),Gea.forEach(t),Qdr=r(DUe," \u2014 "),KJ=n(DUe,"A",{href:!0});var Oea=s(KJ);Wdr=r(Oea,"ElectraForMaskedLM"),Oea.forEach(t),Udr=r(DUe," (ELECTRA model)"),DUe.forEach(t),Hdr=i(Z),lT=n(Z,"LI",{});var jUe=s(lT);R4e=n(jUe,"STRONG",{});var Vea=s(R4e);Jdr=r(Vea,"ernie"),Vea.forEach(t),Ydr=r(jUe," \u2014 "),eY=n(jUe,"A",{href:!0});var Xea=s(eY);Zdr=r(Xea,"ErnieForMaskedLM"),Xea.forEach(t),Kdr=r(jUe," (ERNIE model)"),jUe.forEach(t),emr=i(Z),iT=n(Z,"LI",{});var GUe=s(iT);P4e=n(GUe,"STRONG",{});var zea=s(P4e);omr=r(zea,"flaubert"),zea.forEach(t),rmr=r(GUe," \u2014 "),oY=n(GUe,"A",{href:!0});var Qea=s(oY);tmr=r(Qea,"FlaubertWithLMHeadModel"),Qea.forEach(t),amr=r(GUe," (FlauBERT model)"),GUe.forEach(t),nmr=i(Z),dT=n(Z,"LI",{});var OUe=s(dT);B4e=n(OUe,"STRONG",{});var Wea=s(B4e);smr=r(Wea,"fnet"),Wea.forEach(t),lmr=r(OUe," \u2014 "),rY=n(OUe,"A",{href:!0});var Uea=s(rY);imr=r(Uea,"FNetForMaskedLM"),Uea.forEach(t),dmr=r(OUe," (FNet model)"),OUe.forEach(t),mmr=i(Z),mT=n(Z,"LI",{});var VUe=s(mT);I4e=n(VUe,"STRONG",{});var Hea=s(I4e);cmr=r(Hea,"funnel"),Hea.forEach(t),fmr=r(VUe," \u2014 "),tY=n(VUe,"A",{href:!0});var Jea=s(tY);gmr=r(Jea,"FunnelForMaskedLM"),Jea.forEach(t),hmr=r(VUe," (Funnel Transformer model)"),VUe.forEach(t),umr=i(Z),cT=n(Z,"LI",{});var XUe=s(cT);N4e=n(XUe,"STRONG",{});var Yea=s(N4e);pmr=r(Yea,"ibert"),Yea.forEach(t),_mr=r(XUe," \u2014 "),aY=n(XUe,"A",{href:!0});var Zea=s(aY);bmr=r(Zea,"IBertForMaskedLM"),Zea.forEach(t),vmr=r(XUe," (I-BERT model)"),XUe.forEach(t),Fmr=i(Z),fT=n(Z,"LI",{});var zUe=s(fT);q4e=n(zUe,"STRONG",{});var Kea=s(q4e);Tmr=r(Kea,"layoutlm"),Kea.forEach(t),Mmr=r(zUe," \u2014 "),nY=n(zUe,"A",{href:!0});var eoa=s(nY);Emr=r(eoa,"LayoutLMForMaskedLM"),eoa.forEach(t),Cmr=r(zUe," (LayoutLM model)"),zUe.forEach(t),wmr=i(Z),gT=n(Z,"LI",{});var QUe=s(gT);D4e=n(QUe,"STRONG",{});var ooa=s(D4e);Amr=r(ooa,"longformer"),ooa.forEach(t),Lmr=r(QUe," \u2014 "),sY=n(QUe,"A",{href:!0});var roa=s(sY);ymr=r(roa,"LongformerForMaskedLM"),roa.forEach(t),xmr=r(QUe," (Longformer model)"),QUe.forEach(t),$mr=i(Z),hT=n(Z,"LI",{});var WUe=s(hT);j4e=n(WUe,"STRONG",{});var toa=s(j4e);kmr=r(toa,"luke"),toa.forEach(t),Smr=r(WUe," \u2014 "),lY=n(WUe,"A",{href:!0});var aoa=s(lY);Rmr=r(aoa,"LukeForMaskedLM"),aoa.forEach(t),Pmr=r(WUe," (LUKE model)"),WUe.forEach(t),Bmr=i(Z),uT=n(Z,"LI",{});var UUe=s(uT);G4e=n(UUe,"STRONG",{});var noa=s(G4e);Imr=r(noa,"mbart"),noa.forEach(t),Nmr=r(UUe," \u2014 "),iY=n(UUe,"A",{href:!0});var soa=s(iY);qmr=r(soa,"MBartForConditionalGeneration"),soa.forEach(t),Dmr=r(UUe," (mBART model)"),UUe.forEach(t),jmr=i(Z),pT=n(Z,"LI",{});var HUe=s(pT);O4e=n(HUe,"STRONG",{});var loa=s(O4e);Gmr=r(loa,"megatron-bert"),loa.forEach(t),Omr=r(HUe," \u2014 "),dY=n(HUe,"A",{href:!0});var ioa=s(dY);Vmr=r(ioa,"MegatronBertForMaskedLM"),ioa.forEach(t),Xmr=r(HUe," (Megatron-BERT model)"),HUe.forEach(t),zmr=i(Z),_T=n(Z,"LI",{});var JUe=s(_T);V4e=n(JUe,"STRONG",{});var doa=s(V4e);Qmr=r(doa,"mobilebert"),doa.forEach(t),Wmr=r(JUe," \u2014 "),mY=n(JUe,"A",{href:!0});var moa=s(mY);Umr=r(moa,"MobileBertForMaskedLM"),moa.forEach(t),Hmr=r(JUe," (MobileBERT model)"),JUe.forEach(t),Jmr=i(Z),bT=n(Z,"LI",{});var YUe=s(bT);X4e=n(YUe,"STRONG",{});var coa=s(X4e);Ymr=r(coa,"mpnet"),coa.forEach(t),Zmr=r(YUe," \u2014 "),cY=n(YUe,"A",{href:!0});var foa=s(cY);Kmr=r(foa,"MPNetForMaskedLM"),foa.forEach(t),ecr=r(YUe," (MPNet model)"),YUe.forEach(t),ocr=i(Z),vT=n(Z,"LI",{});var ZUe=s(vT);z4e=n(ZUe,"STRONG",{});var goa=s(z4e);rcr=r(goa,"mvp"),goa.forEach(t),tcr=r(ZUe," \u2014 "),fY=n(ZUe,"A",{href:!0});var hoa=s(fY);acr=r(hoa,"MvpForConditionalGeneration"),hoa.forEach(t),ncr=r(ZUe," (MVP model)"),ZUe.forEach(t),scr=i(Z),FT=n(Z,"LI",{});var KUe=s(FT);Q4e=n(KUe,"STRONG",{});var uoa=s(Q4e);lcr=r(uoa,"nezha"),uoa.forEach(t),icr=r(KUe," \u2014 "),gY=n(KUe,"A",{href:!0});var poa=s(gY);dcr=r(poa,"NezhaForMaskedLM"),poa.forEach(t),mcr=r(KUe," (Nezha model)"),KUe.forEach(t),ccr=i(Z),TT=n(Z,"LI",{});var eHe=s(TT);W4e=n(eHe,"STRONG",{});var _oa=s(W4e);fcr=r(_oa,"nystromformer"),_oa.forEach(t),gcr=r(eHe," \u2014 "),hY=n(eHe,"A",{href:!0});var boa=s(hY);hcr=r(boa,"NystromformerForMaskedLM"),boa.forEach(t),ucr=r(eHe," (Nystr\xF6mformer model)"),eHe.forEach(t),pcr=i(Z),MT=n(Z,"LI",{});var oHe=s(MT);U4e=n(oHe,"STRONG",{});var voa=s(U4e);_cr=r(voa,"perceiver"),voa.forEach(t),bcr=r(oHe," \u2014 "),uY=n(oHe,"A",{href:!0});var Foa=s(uY);vcr=r(Foa,"PerceiverForMaskedLM"),Foa.forEach(t),Fcr=r(oHe," (Perceiver model)"),oHe.forEach(t),Tcr=i(Z),ET=n(Z,"LI",{});var rHe=s(ET);H4e=n(rHe,"STRONG",{});var Toa=s(H4e);Mcr=r(Toa,"qdqbert"),Toa.forEach(t),Ecr=r(rHe," \u2014 "),pY=n(rHe,"A",{href:!0});var Moa=s(pY);Ccr=r(Moa,"QDQBertForMaskedLM"),Moa.forEach(t),wcr=r(rHe," (QDQBert model)"),rHe.forEach(t),Acr=i(Z),CT=n(Z,"LI",{});var tHe=s(CT);J4e=n(tHe,"STRONG",{});var Eoa=s(J4e);Lcr=r(Eoa,"reformer"),Eoa.forEach(t),ycr=r(tHe," \u2014 "),_Y=n(tHe,"A",{href:!0});var Coa=s(_Y);xcr=r(Coa,"ReformerForMaskedLM"),Coa.forEach(t),$cr=r(tHe," (Reformer model)"),tHe.forEach(t),kcr=i(Z),wT=n(Z,"LI",{});var aHe=s(wT);Y4e=n(aHe,"STRONG",{});var woa=s(Y4e);Scr=r(woa,"rembert"),woa.forEach(t),Rcr=r(aHe," \u2014 "),bY=n(aHe,"A",{href:!0});var Aoa=s(bY);Pcr=r(Aoa,"RemBertForMaskedLM"),Aoa.forEach(t),Bcr=r(aHe," (RemBERT model)"),aHe.forEach(t),Icr=i(Z),AT=n(Z,"LI",{});var nHe=s(AT);Z4e=n(nHe,"STRONG",{});var Loa=s(Z4e);Ncr=r(Loa,"roberta"),Loa.forEach(t),qcr=r(nHe," \u2014 "),vY=n(nHe,"A",{href:!0});var yoa=s(vY);Dcr=r(yoa,"RobertaForMaskedLM"),yoa.forEach(t),jcr=r(nHe," (RoBERTa model)"),nHe.forEach(t),Gcr=i(Z),LT=n(Z,"LI",{});var sHe=s(LT);K4e=n(sHe,"STRONG",{});var xoa=s(K4e);Ocr=r(xoa,"roc_bert"),xoa.forEach(t),Vcr=r(sHe," \u2014 "),FY=n(sHe,"A",{href:!0});var $oa=s(FY);Xcr=r($oa,"RoCBertForMaskedLM"),$oa.forEach(t),zcr=r(sHe," (RoCBert model)"),sHe.forEach(t),Qcr=i(Z),yT=n(Z,"LI",{});var lHe=s(yT);eCe=n(lHe,"STRONG",{});var koa=s(eCe);Wcr=r(koa,"roformer"),koa.forEach(t),Ucr=r(lHe," \u2014 "),TY=n(lHe,"A",{href:!0});var Soa=s(TY);Hcr=r(Soa,"RoFormerForMaskedLM"),Soa.forEach(t),Jcr=r(lHe," (RoFormer model)"),lHe.forEach(t),Ycr=i(Z),xT=n(Z,"LI",{});var iHe=s(xT);oCe=n(iHe,"STRONG",{});var Roa=s(oCe);Zcr=r(Roa,"squeezebert"),Roa.forEach(t),Kcr=r(iHe," \u2014 "),MY=n(iHe,"A",{href:!0});var Poa=s(MY);efr=r(Poa,"SqueezeBertForMaskedLM"),Poa.forEach(t),ofr=r(iHe," (SqueezeBERT model)"),iHe.forEach(t),rfr=i(Z),$T=n(Z,"LI",{});var dHe=s($T);rCe=n(dHe,"STRONG",{});var Boa=s(rCe);tfr=r(Boa,"tapas"),Boa.forEach(t),afr=r(dHe," \u2014 "),EY=n(dHe,"A",{href:!0});var Ioa=s(EY);nfr=r(Ioa,"TapasForMaskedLM"),Ioa.forEach(t),sfr=r(dHe," (TAPAS model)"),dHe.forEach(t),lfr=i(Z),kT=n(Z,"LI",{});var mHe=s(kT);tCe=n(mHe,"STRONG",{});var Noa=s(tCe);ifr=r(Noa,"wav2vec2"),Noa.forEach(t),dfr=r(mHe," \u2014 "),aCe=n(mHe,"CODE",{});var qoa=s(aCe);mfr=r(qoa,"Wav2Vec2ForMaskedLM"),qoa.forEach(t),cfr=r(mHe," (Wav2Vec2 model)"),mHe.forEach(t),ffr=i(Z),ST=n(Z,"LI",{});var cHe=s(ST);nCe=n(cHe,"STRONG",{});var Doa=s(nCe);gfr=r(Doa,"xlm"),Doa.forEach(t),hfr=r(cHe," \u2014 "),CY=n(cHe,"A",{href:!0});var joa=s(CY);ufr=r(joa,"XLMWithLMHeadModel"),joa.forEach(t),pfr=r(cHe," (XLM model)"),cHe.forEach(t),_fr=i(Z),RT=n(Z,"LI",{});var fHe=s(RT);sCe=n(fHe,"STRONG",{});var Goa=s(sCe);bfr=r(Goa,"xlm-roberta"),Goa.forEach(t),vfr=r(fHe," \u2014 "),wY=n(fHe,"A",{href:!0});var Ooa=s(wY);Ffr=r(Ooa,"XLMRobertaForMaskedLM"),Ooa.forEach(t),Tfr=r(fHe," (XLM-RoBERTa model)"),fHe.forEach(t),Mfr=i(Z),PT=n(Z,"LI",{});var gHe=s(PT);lCe=n(gHe,"STRONG",{});var Voa=s(lCe);Efr=r(Voa,"xlm-roberta-xl"),Voa.forEach(t),Cfr=r(gHe," \u2014 "),AY=n(gHe,"A",{href:!0});var Xoa=s(AY);wfr=r(Xoa,"XLMRobertaXLForMaskedLM"),Xoa.forEach(t),Afr=r(gHe," (XLM-RoBERTa-XL model)"),gHe.forEach(t),Lfr=i(Z),BT=n(Z,"LI",{});var hHe=s(BT);iCe=n(hHe,"STRONG",{});var zoa=s(iCe);yfr=r(zoa,"yoso"),zoa.forEach(t),xfr=r(hHe," \u2014 "),LY=n(hHe,"A",{href:!0});var Qoa=s(LY);$fr=r(Qoa,"YosoForMaskedLM"),Qoa.forEach(t),kfr=r(hHe," (YOSO model)"),hHe.forEach(t),Z.forEach(t),Sfr=i(Ia),IT=n(Ia,"P",{});var uHe=s(IT);Rfr=r(uHe,"The model is set in evaluation mode by default using "),dCe=n(uHe,"CODE",{});var Woa=s(dCe);Pfr=r(Woa,"model.eval()"),Woa.forEach(t),Bfr=r(uHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mCe=n(uHe,"CODE",{});var Uoa=s(mCe);Ifr=r(Uoa,"model.train()"),Uoa.forEach(t),uHe.forEach(t),Nfr=i(Ia),T(NT.$$.fragment,Ia),Ia.forEach(t),Jl.forEach(t),Nlo=i(c),rm=n(c,"H2",{class:!0});var smo=s(rm);qT=n(smo,"A",{id:!0,class:!0,href:!0});var Hoa=s(qT);cCe=n(Hoa,"SPAN",{});var Joa=s(cCe);T(uS.$$.fragment,Joa),Joa.forEach(t),Hoa.forEach(t),qfr=i(smo),fCe=n(smo,"SPAN",{});var Yoa=s(fCe);Dfr=r(Yoa,"AutoModelForSeq2SeqLM"),Yoa.forEach(t),smo.forEach(t),qlo=i(c),zo=n(c,"DIV",{class:!0});var Yl=s(zo);T(pS.$$.fragment,Yl),jfr=i(Yl),tm=n(Yl,"P",{});var hfe=s(tm);Gfr=r(hfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),yY=n(hfe,"A",{href:!0});var Zoa=s(yY);Ofr=r(Zoa,"from_pretrained()"),Zoa.forEach(t),Vfr=r(hfe," class method or the "),xY=n(hfe,"A",{href:!0});var Koa=s(xY);Xfr=r(Koa,"from_config()"),Koa.forEach(t),zfr=r(hfe,` class
method.`),hfe.forEach(t),Qfr=i(Yl),_S=n(Yl,"P",{});var lmo=s(_S);Wfr=r(lmo,"This class cannot be instantiated directly using "),gCe=n(lmo,"CODE",{});var era=s(gCe);Ufr=r(era,"__init__()"),era.forEach(t),Hfr=r(lmo," (throws an error)."),lmo.forEach(t),Jfr=i(Yl),kt=n(Yl,"DIV",{class:!0});var fx=s(kt);T(bS.$$.fragment,fx),Yfr=i(fx),hCe=n(fx,"P",{});var ora=s(hCe);Zfr=r(ora,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),ora.forEach(t),Kfr=i(fx),am=n(fx,"P",{});var ufe=s(am);egr=r(ufe,`Note:
Loading a model from its configuration file does `),uCe=n(ufe,"STRONG",{});var rra=s(uCe);ogr=r(rra,"not"),rra.forEach(t),rgr=r(ufe,` load the model weights. It only affects the
model\u2019s configuration. Use `),$Y=n(ufe,"A",{href:!0});var tra=s($Y);tgr=r(tra,"from_pretrained()"),tra.forEach(t),agr=r(ufe," to load the model weights."),ufe.forEach(t),ngr=i(fx),T(DT.$$.fragment,fx),fx.forEach(t),sgr=i(Yl),io=n(Yl,"DIV",{class:!0});var Na=s(io);T(vS.$$.fragment,Na),lgr=i(Na),pCe=n(Na,"P",{});var ara=s(pCe);igr=r(ara,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),ara.forEach(t),dgr=i(Na),_n=n(Na,"P",{});var gx=s(_n);mgr=r(gx,"The model class to instantiate is selected based on the "),_Ce=n(gx,"CODE",{});var nra=s(_Ce);cgr=r(nra,"model_type"),nra.forEach(t),fgr=r(gx,` property of the config object (either
passed as an argument or loaded from `),bCe=n(gx,"CODE",{});var sra=s(bCe);ggr=r(sra,"pretrained_model_name_or_path"),sra.forEach(t),hgr=r(gx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vCe=n(gx,"CODE",{});var lra=s(vCe);ugr=r(lra,"pretrained_model_name_or_path"),lra.forEach(t),pgr=r(gx,":"),gx.forEach(t),_gr=i(Na),pe=n(Na,"UL",{});var ve=s(pe);jT=n(ve,"LI",{});var pHe=s(jT);FCe=n(pHe,"STRONG",{});var ira=s(FCe);bgr=r(ira,"bart"),ira.forEach(t),vgr=r(pHe," \u2014 "),kY=n(pHe,"A",{href:!0});var dra=s(kY);Fgr=r(dra,"BartForConditionalGeneration"),dra.forEach(t),Tgr=r(pHe," (BART model)"),pHe.forEach(t),Mgr=i(ve),GT=n(ve,"LI",{});var _He=s(GT);TCe=n(_He,"STRONG",{});var mra=s(TCe);Egr=r(mra,"bigbird_pegasus"),mra.forEach(t),Cgr=r(_He," \u2014 "),SY=n(_He,"A",{href:!0});var cra=s(SY);wgr=r(cra,"BigBirdPegasusForConditionalGeneration"),cra.forEach(t),Agr=r(_He," (BigBird-Pegasus model)"),_He.forEach(t),Lgr=i(ve),OT=n(ve,"LI",{});var bHe=s(OT);MCe=n(bHe,"STRONG",{});var fra=s(MCe);ygr=r(fra,"blenderbot"),fra.forEach(t),xgr=r(bHe," \u2014 "),RY=n(bHe,"A",{href:!0});var gra=s(RY);$gr=r(gra,"BlenderbotForConditionalGeneration"),gra.forEach(t),kgr=r(bHe," (Blenderbot model)"),bHe.forEach(t),Sgr=i(ve),VT=n(ve,"LI",{});var vHe=s(VT);ECe=n(vHe,"STRONG",{});var hra=s(ECe);Rgr=r(hra,"blenderbot-small"),hra.forEach(t),Pgr=r(vHe," \u2014 "),PY=n(vHe,"A",{href:!0});var ura=s(PY);Bgr=r(ura,"BlenderbotSmallForConditionalGeneration"),ura.forEach(t),Igr=r(vHe," (BlenderbotSmall model)"),vHe.forEach(t),Ngr=i(ve),XT=n(ve,"LI",{});var FHe=s(XT);CCe=n(FHe,"STRONG",{});var pra=s(CCe);qgr=r(pra,"encoder-decoder"),pra.forEach(t),Dgr=r(FHe," \u2014 "),BY=n(FHe,"A",{href:!0});var _ra=s(BY);jgr=r(_ra,"EncoderDecoderModel"),_ra.forEach(t),Ggr=r(FHe," (Encoder decoder model)"),FHe.forEach(t),Ogr=i(ve),zT=n(ve,"LI",{});var THe=s(zT);wCe=n(THe,"STRONG",{});var bra=s(wCe);Vgr=r(bra,"fsmt"),bra.forEach(t),Xgr=r(THe," \u2014 "),IY=n(THe,"A",{href:!0});var vra=s(IY);zgr=r(vra,"FSMTForConditionalGeneration"),vra.forEach(t),Qgr=r(THe," (FairSeq Machine-Translation model)"),THe.forEach(t),Wgr=i(ve),QT=n(ve,"LI",{});var MHe=s(QT);ACe=n(MHe,"STRONG",{});var Fra=s(ACe);Ugr=r(Fra,"led"),Fra.forEach(t),Hgr=r(MHe," \u2014 "),NY=n(MHe,"A",{href:!0});var Tra=s(NY);Jgr=r(Tra,"LEDForConditionalGeneration"),Tra.forEach(t),Ygr=r(MHe," (LED model)"),MHe.forEach(t),Zgr=i(ve),WT=n(ve,"LI",{});var EHe=s(WT);LCe=n(EHe,"STRONG",{});var Mra=s(LCe);Kgr=r(Mra,"longt5"),Mra.forEach(t),ehr=r(EHe," \u2014 "),qY=n(EHe,"A",{href:!0});var Era=s(qY);ohr=r(Era,"LongT5ForConditionalGeneration"),Era.forEach(t),rhr=r(EHe," (LongT5 model)"),EHe.forEach(t),thr=i(ve),UT=n(ve,"LI",{});var CHe=s(UT);yCe=n(CHe,"STRONG",{});var Cra=s(yCe);ahr=r(Cra,"m2m_100"),Cra.forEach(t),nhr=r(CHe," \u2014 "),DY=n(CHe,"A",{href:!0});var wra=s(DY);shr=r(wra,"M2M100ForConditionalGeneration"),wra.forEach(t),lhr=r(CHe," (M2M100 model)"),CHe.forEach(t),ihr=i(ve),HT=n(ve,"LI",{});var wHe=s(HT);xCe=n(wHe,"STRONG",{});var Ara=s(xCe);dhr=r(Ara,"marian"),Ara.forEach(t),mhr=r(wHe," \u2014 "),jY=n(wHe,"A",{href:!0});var Lra=s(jY);chr=r(Lra,"MarianMTModel"),Lra.forEach(t),fhr=r(wHe," (Marian model)"),wHe.forEach(t),ghr=i(ve),JT=n(ve,"LI",{});var AHe=s(JT);$Ce=n(AHe,"STRONG",{});var yra=s($Ce);hhr=r(yra,"mbart"),yra.forEach(t),uhr=r(AHe," \u2014 "),GY=n(AHe,"A",{href:!0});var xra=s(GY);phr=r(xra,"MBartForConditionalGeneration"),xra.forEach(t),_hr=r(AHe," (mBART model)"),AHe.forEach(t),bhr=i(ve),YT=n(ve,"LI",{});var LHe=s(YT);kCe=n(LHe,"STRONG",{});var $ra=s(kCe);vhr=r($ra,"mt5"),$ra.forEach(t),Fhr=r(LHe," \u2014 "),OY=n(LHe,"A",{href:!0});var kra=s(OY);Thr=r(kra,"MT5ForConditionalGeneration"),kra.forEach(t),Mhr=r(LHe," (MT5 model)"),LHe.forEach(t),Ehr=i(ve),ZT=n(ve,"LI",{});var yHe=s(ZT);SCe=n(yHe,"STRONG",{});var Sra=s(SCe);Chr=r(Sra,"mvp"),Sra.forEach(t),whr=r(yHe," \u2014 "),VY=n(yHe,"A",{href:!0});var Rra=s(VY);Ahr=r(Rra,"MvpForConditionalGeneration"),Rra.forEach(t),Lhr=r(yHe," (MVP model)"),yHe.forEach(t),yhr=i(ve),KT=n(ve,"LI",{});var xHe=s(KT);RCe=n(xHe,"STRONG",{});var Pra=s(RCe);xhr=r(Pra,"nllb"),Pra.forEach(t),$hr=r(xHe," \u2014 "),XY=n(xHe,"A",{href:!0});var Bra=s(XY);khr=r(Bra,"M2M100ForConditionalGeneration"),Bra.forEach(t),Shr=r(xHe," (NLLB model)"),xHe.forEach(t),Rhr=i(ve),eM=n(ve,"LI",{});var $He=s(eM);PCe=n($He,"STRONG",{});var Ira=s(PCe);Phr=r(Ira,"pegasus"),Ira.forEach(t),Bhr=r($He," \u2014 "),zY=n($He,"A",{href:!0});var Nra=s(zY);Ihr=r(Nra,"PegasusForConditionalGeneration"),Nra.forEach(t),Nhr=r($He," (Pegasus model)"),$He.forEach(t),qhr=i(ve),oM=n(ve,"LI",{});var kHe=s(oM);BCe=n(kHe,"STRONG",{});var qra=s(BCe);Dhr=r(qra,"pegasus_x"),qra.forEach(t),jhr=r(kHe," \u2014 "),QY=n(kHe,"A",{href:!0});var Dra=s(QY);Ghr=r(Dra,"PegasusXForConditionalGeneration"),Dra.forEach(t),Ohr=r(kHe," (PEGASUS-X model)"),kHe.forEach(t),Vhr=i(ve),rM=n(ve,"LI",{});var SHe=s(rM);ICe=n(SHe,"STRONG",{});var jra=s(ICe);Xhr=r(jra,"plbart"),jra.forEach(t),zhr=r(SHe," \u2014 "),WY=n(SHe,"A",{href:!0});var Gra=s(WY);Qhr=r(Gra,"PLBartForConditionalGeneration"),Gra.forEach(t),Whr=r(SHe," (PLBart model)"),SHe.forEach(t),Uhr=i(ve),tM=n(ve,"LI",{});var RHe=s(tM);NCe=n(RHe,"STRONG",{});var Ora=s(NCe);Hhr=r(Ora,"prophetnet"),Ora.forEach(t),Jhr=r(RHe," \u2014 "),UY=n(RHe,"A",{href:!0});var Vra=s(UY);Yhr=r(Vra,"ProphetNetForConditionalGeneration"),Vra.forEach(t),Zhr=r(RHe," (ProphetNet model)"),RHe.forEach(t),Khr=i(ve),aM=n(ve,"LI",{});var PHe=s(aM);qCe=n(PHe,"STRONG",{});var Xra=s(qCe);eur=r(Xra,"t5"),Xra.forEach(t),our=r(PHe," \u2014 "),HY=n(PHe,"A",{href:!0});var zra=s(HY);rur=r(zra,"T5ForConditionalGeneration"),zra.forEach(t),tur=r(PHe," (T5 model)"),PHe.forEach(t),aur=i(ve),nM=n(ve,"LI",{});var BHe=s(nM);DCe=n(BHe,"STRONG",{});var Qra=s(DCe);nur=r(Qra,"xlm-prophetnet"),Qra.forEach(t),sur=r(BHe," \u2014 "),JY=n(BHe,"A",{href:!0});var Wra=s(JY);lur=r(Wra,"XLMProphetNetForConditionalGeneration"),Wra.forEach(t),iur=r(BHe," (XLM-ProphetNet model)"),BHe.forEach(t),ve.forEach(t),dur=i(Na),sM=n(Na,"P",{});var IHe=s(sM);mur=r(IHe,"The model is set in evaluation mode by default using "),jCe=n(IHe,"CODE",{});var Ura=s(jCe);cur=r(Ura,"model.eval()"),Ura.forEach(t),fur=r(IHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),GCe=n(IHe,"CODE",{});var Hra=s(GCe);gur=r(Hra,"model.train()"),Hra.forEach(t),IHe.forEach(t),hur=i(Na),T(lM.$$.fragment,Na),Na.forEach(t),Yl.forEach(t),Dlo=i(c),nm=n(c,"H2",{class:!0});var imo=s(nm);iM=n(imo,"A",{id:!0,class:!0,href:!0});var Jra=s(iM);OCe=n(Jra,"SPAN",{});var Yra=s(OCe);T(FS.$$.fragment,Yra),Yra.forEach(t),Jra.forEach(t),uur=i(imo),VCe=n(imo,"SPAN",{});var Zra=s(VCe);pur=r(Zra,"AutoModelForSequenceClassification"),Zra.forEach(t),imo.forEach(t),jlo=i(c),Qo=n(c,"DIV",{class:!0});var Zl=s(Qo);T(TS.$$.fragment,Zl),_ur=i(Zl),sm=n(Zl,"P",{});var pfe=s(sm);bur=r(pfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),YY=n(pfe,"A",{href:!0});var Kra=s(YY);vur=r(Kra,"from_pretrained()"),Kra.forEach(t),Fur=r(pfe," class method or the "),ZY=n(pfe,"A",{href:!0});var eta=s(ZY);Tur=r(eta,"from_config()"),eta.forEach(t),Mur=r(pfe,` class
method.`),pfe.forEach(t),Eur=i(Zl),MS=n(Zl,"P",{});var dmo=s(MS);Cur=r(dmo,"This class cannot be instantiated directly using "),XCe=n(dmo,"CODE",{});var ota=s(XCe);wur=r(ota,"__init__()"),ota.forEach(t),Aur=r(dmo," (throws an error)."),dmo.forEach(t),Lur=i(Zl),St=n(Zl,"DIV",{class:!0});var hx=s(St);T(ES.$$.fragment,hx),yur=i(hx),zCe=n(hx,"P",{});var rta=s(zCe);xur=r(rta,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),rta.forEach(t),$ur=i(hx),lm=n(hx,"P",{});var _fe=s(lm);kur=r(_fe,`Note:
Loading a model from its configuration file does `),QCe=n(_fe,"STRONG",{});var tta=s(QCe);Sur=r(tta,"not"),tta.forEach(t),Rur=r(_fe,` load the model weights. It only affects the
model\u2019s configuration. Use `),KY=n(_fe,"A",{href:!0});var ata=s(KY);Pur=r(ata,"from_pretrained()"),ata.forEach(t),Bur=r(_fe," to load the model weights."),_fe.forEach(t),Iur=i(hx),T(dM.$$.fragment,hx),hx.forEach(t),Nur=i(Zl),mo=n(Zl,"DIV",{class:!0});var qa=s(mo);T(CS.$$.fragment,qa),qur=i(qa),WCe=n(qa,"P",{});var nta=s(WCe);Dur=r(nta,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),nta.forEach(t),jur=i(qa),bn=n(qa,"P",{});var ux=s(bn);Gur=r(ux,"The model class to instantiate is selected based on the "),UCe=n(ux,"CODE",{});var sta=s(UCe);Our=r(sta,"model_type"),sta.forEach(t),Vur=r(ux,` property of the config object (either
passed as an argument or loaded from `),HCe=n(ux,"CODE",{});var lta=s(HCe);Xur=r(lta,"pretrained_model_name_or_path"),lta.forEach(t),zur=r(ux,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JCe=n(ux,"CODE",{});var ita=s(JCe);Qur=r(ita,"pretrained_model_name_or_path"),ita.forEach(t),Wur=r(ux,":"),ux.forEach(t),Uur=i(qa),I=n(qa,"UL",{});var j=s(I);mM=n(j,"LI",{});var NHe=s(mM);YCe=n(NHe,"STRONG",{});var dta=s(YCe);Hur=r(dta,"albert"),dta.forEach(t),Jur=r(NHe," \u2014 "),eZ=n(NHe,"A",{href:!0});var mta=s(eZ);Yur=r(mta,"AlbertForSequenceClassification"),mta.forEach(t),Zur=r(NHe," (ALBERT model)"),NHe.forEach(t),Kur=i(j),cM=n(j,"LI",{});var qHe=s(cM);ZCe=n(qHe,"STRONG",{});var cta=s(ZCe);epr=r(cta,"bart"),cta.forEach(t),opr=r(qHe," \u2014 "),oZ=n(qHe,"A",{href:!0});var fta=s(oZ);rpr=r(fta,"BartForSequenceClassification"),fta.forEach(t),tpr=r(qHe," (BART model)"),qHe.forEach(t),apr=i(j),fM=n(j,"LI",{});var DHe=s(fM);KCe=n(DHe,"STRONG",{});var gta=s(KCe);npr=r(gta,"bert"),gta.forEach(t),spr=r(DHe," \u2014 "),rZ=n(DHe,"A",{href:!0});var hta=s(rZ);lpr=r(hta,"BertForSequenceClassification"),hta.forEach(t),ipr=r(DHe," (BERT model)"),DHe.forEach(t),dpr=i(j),gM=n(j,"LI",{});var jHe=s(gM);e3e=n(jHe,"STRONG",{});var uta=s(e3e);mpr=r(uta,"big_bird"),uta.forEach(t),cpr=r(jHe," \u2014 "),tZ=n(jHe,"A",{href:!0});var pta=s(tZ);fpr=r(pta,"BigBirdForSequenceClassification"),pta.forEach(t),gpr=r(jHe," (BigBird model)"),jHe.forEach(t),hpr=i(j),hM=n(j,"LI",{});var GHe=s(hM);o3e=n(GHe,"STRONG",{});var _ta=s(o3e);upr=r(_ta,"bigbird_pegasus"),_ta.forEach(t),ppr=r(GHe," \u2014 "),aZ=n(GHe,"A",{href:!0});var bta=s(aZ);_pr=r(bta,"BigBirdPegasusForSequenceClassification"),bta.forEach(t),bpr=r(GHe," (BigBird-Pegasus model)"),GHe.forEach(t),vpr=i(j),uM=n(j,"LI",{});var OHe=s(uM);r3e=n(OHe,"STRONG",{});var vta=s(r3e);Fpr=r(vta,"bloom"),vta.forEach(t),Tpr=r(OHe," \u2014 "),nZ=n(OHe,"A",{href:!0});var Fta=s(nZ);Mpr=r(Fta,"BloomForSequenceClassification"),Fta.forEach(t),Epr=r(OHe," (BLOOM model)"),OHe.forEach(t),Cpr=i(j),pM=n(j,"LI",{});var VHe=s(pM);t3e=n(VHe,"STRONG",{});var Tta=s(t3e);wpr=r(Tta,"camembert"),Tta.forEach(t),Apr=r(VHe," \u2014 "),sZ=n(VHe,"A",{href:!0});var Mta=s(sZ);Lpr=r(Mta,"CamembertForSequenceClassification"),Mta.forEach(t),ypr=r(VHe," (CamemBERT model)"),VHe.forEach(t),xpr=i(j),_M=n(j,"LI",{});var XHe=s(_M);a3e=n(XHe,"STRONG",{});var Eta=s(a3e);$pr=r(Eta,"canine"),Eta.forEach(t),kpr=r(XHe," \u2014 "),lZ=n(XHe,"A",{href:!0});var Cta=s(lZ);Spr=r(Cta,"CanineForSequenceClassification"),Cta.forEach(t),Rpr=r(XHe," (CANINE model)"),XHe.forEach(t),Ppr=i(j),bM=n(j,"LI",{});var zHe=s(bM);n3e=n(zHe,"STRONG",{});var wta=s(n3e);Bpr=r(wta,"convbert"),wta.forEach(t),Ipr=r(zHe," \u2014 "),iZ=n(zHe,"A",{href:!0});var Ata=s(iZ);Npr=r(Ata,"ConvBertForSequenceClassification"),Ata.forEach(t),qpr=r(zHe," (ConvBERT model)"),zHe.forEach(t),Dpr=i(j),vM=n(j,"LI",{});var QHe=s(vM);s3e=n(QHe,"STRONG",{});var Lta=s(s3e);jpr=r(Lta,"ctrl"),Lta.forEach(t),Gpr=r(QHe," \u2014 "),dZ=n(QHe,"A",{href:!0});var yta=s(dZ);Opr=r(yta,"CTRLForSequenceClassification"),yta.forEach(t),Vpr=r(QHe," (CTRL model)"),QHe.forEach(t),Xpr=i(j),FM=n(j,"LI",{});var WHe=s(FM);l3e=n(WHe,"STRONG",{});var xta=s(l3e);zpr=r(xta,"data2vec-text"),xta.forEach(t),Qpr=r(WHe," \u2014 "),mZ=n(WHe,"A",{href:!0});var $ta=s(mZ);Wpr=r($ta,"Data2VecTextForSequenceClassification"),$ta.forEach(t),Upr=r(WHe," (Data2VecText model)"),WHe.forEach(t),Hpr=i(j),TM=n(j,"LI",{});var UHe=s(TM);i3e=n(UHe,"STRONG",{});var kta=s(i3e);Jpr=r(kta,"deberta"),kta.forEach(t),Ypr=r(UHe," \u2014 "),cZ=n(UHe,"A",{href:!0});var Sta=s(cZ);Zpr=r(Sta,"DebertaForSequenceClassification"),Sta.forEach(t),Kpr=r(UHe," (DeBERTa model)"),UHe.forEach(t),e_r=i(j),MM=n(j,"LI",{});var HHe=s(MM);d3e=n(HHe,"STRONG",{});var Rta=s(d3e);o_r=r(Rta,"deberta-v2"),Rta.forEach(t),r_r=r(HHe," \u2014 "),fZ=n(HHe,"A",{href:!0});var Pta=s(fZ);t_r=r(Pta,"DebertaV2ForSequenceClassification"),Pta.forEach(t),a_r=r(HHe," (DeBERTa-v2 model)"),HHe.forEach(t),n_r=i(j),EM=n(j,"LI",{});var JHe=s(EM);m3e=n(JHe,"STRONG",{});var Bta=s(m3e);s_r=r(Bta,"distilbert"),Bta.forEach(t),l_r=r(JHe," \u2014 "),gZ=n(JHe,"A",{href:!0});var Ita=s(gZ);i_r=r(Ita,"DistilBertForSequenceClassification"),Ita.forEach(t),d_r=r(JHe," (DistilBERT model)"),JHe.forEach(t),m_r=i(j),CM=n(j,"LI",{});var YHe=s(CM);c3e=n(YHe,"STRONG",{});var Nta=s(c3e);c_r=r(Nta,"electra"),Nta.forEach(t),f_r=r(YHe," \u2014 "),hZ=n(YHe,"A",{href:!0});var qta=s(hZ);g_r=r(qta,"ElectraForSequenceClassification"),qta.forEach(t),h_r=r(YHe," (ELECTRA model)"),YHe.forEach(t),u_r=i(j),wM=n(j,"LI",{});var ZHe=s(wM);f3e=n(ZHe,"STRONG",{});var Dta=s(f3e);p_r=r(Dta,"ernie"),Dta.forEach(t),__r=r(ZHe," \u2014 "),uZ=n(ZHe,"A",{href:!0});var jta=s(uZ);b_r=r(jta,"ErnieForSequenceClassification"),jta.forEach(t),v_r=r(ZHe," (ERNIE model)"),ZHe.forEach(t),F_r=i(j),AM=n(j,"LI",{});var KHe=s(AM);g3e=n(KHe,"STRONG",{});var Gta=s(g3e);T_r=r(Gta,"esm"),Gta.forEach(t),M_r=r(KHe," \u2014 "),pZ=n(KHe,"A",{href:!0});var Ota=s(pZ);E_r=r(Ota,"EsmForSequenceClassification"),Ota.forEach(t),C_r=r(KHe," (ESM model)"),KHe.forEach(t),w_r=i(j),LM=n(j,"LI",{});var eJe=s(LM);h3e=n(eJe,"STRONG",{});var Vta=s(h3e);A_r=r(Vta,"flaubert"),Vta.forEach(t),L_r=r(eJe," \u2014 "),_Z=n(eJe,"A",{href:!0});var Xta=s(_Z);y_r=r(Xta,"FlaubertForSequenceClassification"),Xta.forEach(t),x_r=r(eJe," (FlauBERT model)"),eJe.forEach(t),$_r=i(j),yM=n(j,"LI",{});var oJe=s(yM);u3e=n(oJe,"STRONG",{});var zta=s(u3e);k_r=r(zta,"fnet"),zta.forEach(t),S_r=r(oJe," \u2014 "),bZ=n(oJe,"A",{href:!0});var Qta=s(bZ);R_r=r(Qta,"FNetForSequenceClassification"),Qta.forEach(t),P_r=r(oJe," (FNet model)"),oJe.forEach(t),B_r=i(j),xM=n(j,"LI",{});var rJe=s(xM);p3e=n(rJe,"STRONG",{});var Wta=s(p3e);I_r=r(Wta,"funnel"),Wta.forEach(t),N_r=r(rJe," \u2014 "),vZ=n(rJe,"A",{href:!0});var Uta=s(vZ);q_r=r(Uta,"FunnelForSequenceClassification"),Uta.forEach(t),D_r=r(rJe," (Funnel Transformer model)"),rJe.forEach(t),j_r=i(j),$M=n(j,"LI",{});var tJe=s($M);_3e=n(tJe,"STRONG",{});var Hta=s(_3e);G_r=r(Hta,"gpt2"),Hta.forEach(t),O_r=r(tJe," \u2014 "),FZ=n(tJe,"A",{href:!0});var Jta=s(FZ);V_r=r(Jta,"GPT2ForSequenceClassification"),Jta.forEach(t),X_r=r(tJe," (OpenAI GPT-2 model)"),tJe.forEach(t),z_r=i(j),kM=n(j,"LI",{});var aJe=s(kM);b3e=n(aJe,"STRONG",{});var Yta=s(b3e);Q_r=r(Yta,"gpt_neo"),Yta.forEach(t),W_r=r(aJe," \u2014 "),TZ=n(aJe,"A",{href:!0});var Zta=s(TZ);U_r=r(Zta,"GPTNeoForSequenceClassification"),Zta.forEach(t),H_r=r(aJe," (GPT Neo model)"),aJe.forEach(t),J_r=i(j),SM=n(j,"LI",{});var nJe=s(SM);v3e=n(nJe,"STRONG",{});var Kta=s(v3e);Y_r=r(Kta,"gptj"),Kta.forEach(t),Z_r=r(nJe," \u2014 "),MZ=n(nJe,"A",{href:!0});var eaa=s(MZ);K_r=r(eaa,"GPTJForSequenceClassification"),eaa.forEach(t),e1r=r(nJe," (GPT-J model)"),nJe.forEach(t),o1r=i(j),RM=n(j,"LI",{});var sJe=s(RM);F3e=n(sJe,"STRONG",{});var oaa=s(F3e);r1r=r(oaa,"ibert"),oaa.forEach(t),t1r=r(sJe," \u2014 "),EZ=n(sJe,"A",{href:!0});var raa=s(EZ);a1r=r(raa,"IBertForSequenceClassification"),raa.forEach(t),n1r=r(sJe," (I-BERT model)"),sJe.forEach(t),s1r=i(j),PM=n(j,"LI",{});var lJe=s(PM);T3e=n(lJe,"STRONG",{});var taa=s(T3e);l1r=r(taa,"layoutlm"),taa.forEach(t),i1r=r(lJe," \u2014 "),CZ=n(lJe,"A",{href:!0});var aaa=s(CZ);d1r=r(aaa,"LayoutLMForSequenceClassification"),aaa.forEach(t),m1r=r(lJe," (LayoutLM model)"),lJe.forEach(t),c1r=i(j),BM=n(j,"LI",{});var iJe=s(BM);M3e=n(iJe,"STRONG",{});var naa=s(M3e);f1r=r(naa,"layoutlmv2"),naa.forEach(t),g1r=r(iJe," \u2014 "),wZ=n(iJe,"A",{href:!0});var saa=s(wZ);h1r=r(saa,"LayoutLMv2ForSequenceClassification"),saa.forEach(t),u1r=r(iJe," (LayoutLMv2 model)"),iJe.forEach(t),p1r=i(j),IM=n(j,"LI",{});var dJe=s(IM);E3e=n(dJe,"STRONG",{});var laa=s(E3e);_1r=r(laa,"layoutlmv3"),laa.forEach(t),b1r=r(dJe," \u2014 "),AZ=n(dJe,"A",{href:!0});var iaa=s(AZ);v1r=r(iaa,"LayoutLMv3ForSequenceClassification"),iaa.forEach(t),F1r=r(dJe," (LayoutLMv3 model)"),dJe.forEach(t),T1r=i(j),NM=n(j,"LI",{});var mJe=s(NM);C3e=n(mJe,"STRONG",{});var daa=s(C3e);M1r=r(daa,"led"),daa.forEach(t),E1r=r(mJe," \u2014 "),LZ=n(mJe,"A",{href:!0});var maa=s(LZ);C1r=r(maa,"LEDForSequenceClassification"),maa.forEach(t),w1r=r(mJe," (LED model)"),mJe.forEach(t),A1r=i(j),qM=n(j,"LI",{});var cJe=s(qM);w3e=n(cJe,"STRONG",{});var caa=s(w3e);L1r=r(caa,"lilt"),caa.forEach(t),y1r=r(cJe," \u2014 "),yZ=n(cJe,"A",{href:!0});var faa=s(yZ);x1r=r(faa,"LiltForSequenceClassification"),faa.forEach(t),$1r=r(cJe," (LiLT model)"),cJe.forEach(t),k1r=i(j),DM=n(j,"LI",{});var fJe=s(DM);A3e=n(fJe,"STRONG",{});var gaa=s(A3e);S1r=r(gaa,"longformer"),gaa.forEach(t),R1r=r(fJe," \u2014 "),xZ=n(fJe,"A",{href:!0});var haa=s(xZ);P1r=r(haa,"LongformerForSequenceClassification"),haa.forEach(t),B1r=r(fJe," (Longformer model)"),fJe.forEach(t),I1r=i(j),jM=n(j,"LI",{});var gJe=s(jM);L3e=n(gJe,"STRONG",{});var uaa=s(L3e);N1r=r(uaa,"luke"),uaa.forEach(t),q1r=r(gJe," \u2014 "),$Z=n(gJe,"A",{href:!0});var paa=s($Z);D1r=r(paa,"LukeForSequenceClassification"),paa.forEach(t),j1r=r(gJe," (LUKE model)"),gJe.forEach(t),G1r=i(j),GM=n(j,"LI",{});var hJe=s(GM);y3e=n(hJe,"STRONG",{});var _aa=s(y3e);O1r=r(_aa,"markuplm"),_aa.forEach(t),V1r=r(hJe," \u2014 "),kZ=n(hJe,"A",{href:!0});var baa=s(kZ);X1r=r(baa,"MarkupLMForSequenceClassification"),baa.forEach(t),z1r=r(hJe," (MarkupLM model)"),hJe.forEach(t),Q1r=i(j),OM=n(j,"LI",{});var uJe=s(OM);x3e=n(uJe,"STRONG",{});var vaa=s(x3e);W1r=r(vaa,"mbart"),vaa.forEach(t),U1r=r(uJe," \u2014 "),SZ=n(uJe,"A",{href:!0});var Faa=s(SZ);H1r=r(Faa,"MBartForSequenceClassification"),Faa.forEach(t),J1r=r(uJe," (mBART model)"),uJe.forEach(t),Y1r=i(j),VM=n(j,"LI",{});var pJe=s(VM);$3e=n(pJe,"STRONG",{});var Taa=s($3e);Z1r=r(Taa,"megatron-bert"),Taa.forEach(t),K1r=r(pJe," \u2014 "),RZ=n(pJe,"A",{href:!0});var Maa=s(RZ);e2r=r(Maa,"MegatronBertForSequenceClassification"),Maa.forEach(t),o2r=r(pJe," (Megatron-BERT model)"),pJe.forEach(t),r2r=i(j),XM=n(j,"LI",{});var _Je=s(XM);k3e=n(_Je,"STRONG",{});var Eaa=s(k3e);t2r=r(Eaa,"mobilebert"),Eaa.forEach(t),a2r=r(_Je," \u2014 "),PZ=n(_Je,"A",{href:!0});var Caa=s(PZ);n2r=r(Caa,"MobileBertForSequenceClassification"),Caa.forEach(t),s2r=r(_Je," (MobileBERT model)"),_Je.forEach(t),l2r=i(j),zM=n(j,"LI",{});var bJe=s(zM);S3e=n(bJe,"STRONG",{});var waa=s(S3e);i2r=r(waa,"mpnet"),waa.forEach(t),d2r=r(bJe," \u2014 "),BZ=n(bJe,"A",{href:!0});var Aaa=s(BZ);m2r=r(Aaa,"MPNetForSequenceClassification"),Aaa.forEach(t),c2r=r(bJe," (MPNet model)"),bJe.forEach(t),f2r=i(j),QM=n(j,"LI",{});var vJe=s(QM);R3e=n(vJe,"STRONG",{});var Laa=s(R3e);g2r=r(Laa,"mvp"),Laa.forEach(t),h2r=r(vJe," \u2014 "),IZ=n(vJe,"A",{href:!0});var yaa=s(IZ);u2r=r(yaa,"MvpForSequenceClassification"),yaa.forEach(t),p2r=r(vJe," (MVP model)"),vJe.forEach(t),_2r=i(j),WM=n(j,"LI",{});var FJe=s(WM);P3e=n(FJe,"STRONG",{});var xaa=s(P3e);b2r=r(xaa,"nezha"),xaa.forEach(t),v2r=r(FJe," \u2014 "),NZ=n(FJe,"A",{href:!0});var $aa=s(NZ);F2r=r($aa,"NezhaForSequenceClassification"),$aa.forEach(t),T2r=r(FJe," (Nezha model)"),FJe.forEach(t),M2r=i(j),UM=n(j,"LI",{});var TJe=s(UM);B3e=n(TJe,"STRONG",{});var kaa=s(B3e);E2r=r(kaa,"nystromformer"),kaa.forEach(t),C2r=r(TJe," \u2014 "),qZ=n(TJe,"A",{href:!0});var Saa=s(qZ);w2r=r(Saa,"NystromformerForSequenceClassification"),Saa.forEach(t),A2r=r(TJe," (Nystr\xF6mformer model)"),TJe.forEach(t),L2r=i(j),HM=n(j,"LI",{});var MJe=s(HM);I3e=n(MJe,"STRONG",{});var Raa=s(I3e);y2r=r(Raa,"openai-gpt"),Raa.forEach(t),x2r=r(MJe," \u2014 "),DZ=n(MJe,"A",{href:!0});var Paa=s(DZ);$2r=r(Paa,"OpenAIGPTForSequenceClassification"),Paa.forEach(t),k2r=r(MJe," (OpenAI GPT model)"),MJe.forEach(t),S2r=i(j),JM=n(j,"LI",{});var EJe=s(JM);N3e=n(EJe,"STRONG",{});var Baa=s(N3e);R2r=r(Baa,"opt"),Baa.forEach(t),P2r=r(EJe," \u2014 "),jZ=n(EJe,"A",{href:!0});var Iaa=s(jZ);B2r=r(Iaa,"OPTForSequenceClassification"),Iaa.forEach(t),I2r=r(EJe," (OPT model)"),EJe.forEach(t),N2r=i(j),YM=n(j,"LI",{});var CJe=s(YM);q3e=n(CJe,"STRONG",{});var Naa=s(q3e);q2r=r(Naa,"perceiver"),Naa.forEach(t),D2r=r(CJe," \u2014 "),GZ=n(CJe,"A",{href:!0});var qaa=s(GZ);j2r=r(qaa,"PerceiverForSequenceClassification"),qaa.forEach(t),G2r=r(CJe," (Perceiver model)"),CJe.forEach(t),O2r=i(j),ZM=n(j,"LI",{});var wJe=s(ZM);D3e=n(wJe,"STRONG",{});var Daa=s(D3e);V2r=r(Daa,"plbart"),Daa.forEach(t),X2r=r(wJe," \u2014 "),OZ=n(wJe,"A",{href:!0});var jaa=s(OZ);z2r=r(jaa,"PLBartForSequenceClassification"),jaa.forEach(t),Q2r=r(wJe," (PLBart model)"),wJe.forEach(t),W2r=i(j),KM=n(j,"LI",{});var AJe=s(KM);j3e=n(AJe,"STRONG",{});var Gaa=s(j3e);U2r=r(Gaa,"qdqbert"),Gaa.forEach(t),H2r=r(AJe," \u2014 "),VZ=n(AJe,"A",{href:!0});var Oaa=s(VZ);J2r=r(Oaa,"QDQBertForSequenceClassification"),Oaa.forEach(t),Y2r=r(AJe," (QDQBert model)"),AJe.forEach(t),Z2r=i(j),eE=n(j,"LI",{});var LJe=s(eE);G3e=n(LJe,"STRONG",{});var Vaa=s(G3e);K2r=r(Vaa,"reformer"),Vaa.forEach(t),ebr=r(LJe," \u2014 "),XZ=n(LJe,"A",{href:!0});var Xaa=s(XZ);obr=r(Xaa,"ReformerForSequenceClassification"),Xaa.forEach(t),rbr=r(LJe," (Reformer model)"),LJe.forEach(t),tbr=i(j),oE=n(j,"LI",{});var yJe=s(oE);O3e=n(yJe,"STRONG",{});var zaa=s(O3e);abr=r(zaa,"rembert"),zaa.forEach(t),nbr=r(yJe," \u2014 "),zZ=n(yJe,"A",{href:!0});var Qaa=s(zZ);sbr=r(Qaa,"RemBertForSequenceClassification"),Qaa.forEach(t),lbr=r(yJe," (RemBERT model)"),yJe.forEach(t),ibr=i(j),rE=n(j,"LI",{});var xJe=s(rE);V3e=n(xJe,"STRONG",{});var Waa=s(V3e);dbr=r(Waa,"roberta"),Waa.forEach(t),mbr=r(xJe," \u2014 "),QZ=n(xJe,"A",{href:!0});var Uaa=s(QZ);cbr=r(Uaa,"RobertaForSequenceClassification"),Uaa.forEach(t),fbr=r(xJe," (RoBERTa model)"),xJe.forEach(t),gbr=i(j),tE=n(j,"LI",{});var $Je=s(tE);X3e=n($Je,"STRONG",{});var Haa=s(X3e);hbr=r(Haa,"roc_bert"),Haa.forEach(t),ubr=r($Je," \u2014 "),WZ=n($Je,"A",{href:!0});var Jaa=s(WZ);pbr=r(Jaa,"RoCBertForSequenceClassification"),Jaa.forEach(t),_br=r($Je," (RoCBert model)"),$Je.forEach(t),bbr=i(j),aE=n(j,"LI",{});var kJe=s(aE);z3e=n(kJe,"STRONG",{});var Yaa=s(z3e);vbr=r(Yaa,"roformer"),Yaa.forEach(t),Fbr=r(kJe," \u2014 "),UZ=n(kJe,"A",{href:!0});var Zaa=s(UZ);Tbr=r(Zaa,"RoFormerForSequenceClassification"),Zaa.forEach(t),Mbr=r(kJe," (RoFormer model)"),kJe.forEach(t),Ebr=i(j),nE=n(j,"LI",{});var SJe=s(nE);Q3e=n(SJe,"STRONG",{});var Kaa=s(Q3e);Cbr=r(Kaa,"squeezebert"),Kaa.forEach(t),wbr=r(SJe," \u2014 "),HZ=n(SJe,"A",{href:!0});var ena=s(HZ);Abr=r(ena,"SqueezeBertForSequenceClassification"),ena.forEach(t),Lbr=r(SJe," (SqueezeBERT model)"),SJe.forEach(t),ybr=i(j),sE=n(j,"LI",{});var RJe=s(sE);W3e=n(RJe,"STRONG",{});var ona=s(W3e);xbr=r(ona,"tapas"),ona.forEach(t),$br=r(RJe," \u2014 "),JZ=n(RJe,"A",{href:!0});var rna=s(JZ);kbr=r(rna,"TapasForSequenceClassification"),rna.forEach(t),Sbr=r(RJe," (TAPAS model)"),RJe.forEach(t),Rbr=i(j),lE=n(j,"LI",{});var PJe=s(lE);U3e=n(PJe,"STRONG",{});var tna=s(U3e);Pbr=r(tna,"transfo-xl"),tna.forEach(t),Bbr=r(PJe," \u2014 "),YZ=n(PJe,"A",{href:!0});var ana=s(YZ);Ibr=r(ana,"TransfoXLForSequenceClassification"),ana.forEach(t),Nbr=r(PJe," (Transformer-XL model)"),PJe.forEach(t),qbr=i(j),iE=n(j,"LI",{});var BJe=s(iE);H3e=n(BJe,"STRONG",{});var nna=s(H3e);Dbr=r(nna,"xlm"),nna.forEach(t),jbr=r(BJe," \u2014 "),ZZ=n(BJe,"A",{href:!0});var sna=s(ZZ);Gbr=r(sna,"XLMForSequenceClassification"),sna.forEach(t),Obr=r(BJe," (XLM model)"),BJe.forEach(t),Vbr=i(j),dE=n(j,"LI",{});var IJe=s(dE);J3e=n(IJe,"STRONG",{});var lna=s(J3e);Xbr=r(lna,"xlm-roberta"),lna.forEach(t),zbr=r(IJe," \u2014 "),KZ=n(IJe,"A",{href:!0});var ina=s(KZ);Qbr=r(ina,"XLMRobertaForSequenceClassification"),ina.forEach(t),Wbr=r(IJe," (XLM-RoBERTa model)"),IJe.forEach(t),Ubr=i(j),mE=n(j,"LI",{});var NJe=s(mE);Y3e=n(NJe,"STRONG",{});var dna=s(Y3e);Hbr=r(dna,"xlm-roberta-xl"),dna.forEach(t),Jbr=r(NJe," \u2014 "),eK=n(NJe,"A",{href:!0});var mna=s(eK);Ybr=r(mna,"XLMRobertaXLForSequenceClassification"),mna.forEach(t),Zbr=r(NJe," (XLM-RoBERTa-XL model)"),NJe.forEach(t),Kbr=i(j),cE=n(j,"LI",{});var qJe=s(cE);Z3e=n(qJe,"STRONG",{});var cna=s(Z3e);evr=r(cna,"xlnet"),cna.forEach(t),ovr=r(qJe," \u2014 "),oK=n(qJe,"A",{href:!0});var fna=s(oK);rvr=r(fna,"XLNetForSequenceClassification"),fna.forEach(t),tvr=r(qJe," (XLNet model)"),qJe.forEach(t),avr=i(j),fE=n(j,"LI",{});var DJe=s(fE);K3e=n(DJe,"STRONG",{});var gna=s(K3e);nvr=r(gna,"yoso"),gna.forEach(t),svr=r(DJe," \u2014 "),rK=n(DJe,"A",{href:!0});var hna=s(rK);lvr=r(hna,"YosoForSequenceClassification"),hna.forEach(t),ivr=r(DJe," (YOSO model)"),DJe.forEach(t),j.forEach(t),dvr=i(qa),gE=n(qa,"P",{});var jJe=s(gE);mvr=r(jJe,"The model is set in evaluation mode by default using "),e5e=n(jJe,"CODE",{});var una=s(e5e);cvr=r(una,"model.eval()"),una.forEach(t),fvr=r(jJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o5e=n(jJe,"CODE",{});var pna=s(o5e);gvr=r(pna,"model.train()"),pna.forEach(t),jJe.forEach(t),hvr=i(qa),T(hE.$$.fragment,qa),qa.forEach(t),Zl.forEach(t),Glo=i(c),im=n(c,"H2",{class:!0});var mmo=s(im);uE=n(mmo,"A",{id:!0,class:!0,href:!0});var _na=s(uE);r5e=n(_na,"SPAN",{});var bna=s(r5e);T(wS.$$.fragment,bna),bna.forEach(t),_na.forEach(t),uvr=i(mmo),t5e=n(mmo,"SPAN",{});var vna=s(t5e);pvr=r(vna,"AutoModelForMultipleChoice"),vna.forEach(t),mmo.forEach(t),Olo=i(c),Wo=n(c,"DIV",{class:!0});var Kl=s(Wo);T(AS.$$.fragment,Kl),_vr=i(Kl),dm=n(Kl,"P",{});var bfe=s(dm);bvr=r(bfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),tK=n(bfe,"A",{href:!0});var Fna=s(tK);vvr=r(Fna,"from_pretrained()"),Fna.forEach(t),Fvr=r(bfe," class method or the "),aK=n(bfe,"A",{href:!0});var Tna=s(aK);Tvr=r(Tna,"from_config()"),Tna.forEach(t),Mvr=r(bfe,` class
method.`),bfe.forEach(t),Evr=i(Kl),LS=n(Kl,"P",{});var cmo=s(LS);Cvr=r(cmo,"This class cannot be instantiated directly using "),a5e=n(cmo,"CODE",{});var Mna=s(a5e);wvr=r(Mna,"__init__()"),Mna.forEach(t),Avr=r(cmo," (throws an error)."),cmo.forEach(t),Lvr=i(Kl),Rt=n(Kl,"DIV",{class:!0});var px=s(Rt);T(yS.$$.fragment,px),yvr=i(px),n5e=n(px,"P",{});var Ena=s(n5e);xvr=r(Ena,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Ena.forEach(t),$vr=i(px),mm=n(px,"P",{});var vfe=s(mm);kvr=r(vfe,`Note:
Loading a model from its configuration file does `),s5e=n(vfe,"STRONG",{});var Cna=s(s5e);Svr=r(Cna,"not"),Cna.forEach(t),Rvr=r(vfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),nK=n(vfe,"A",{href:!0});var wna=s(nK);Pvr=r(wna,"from_pretrained()"),wna.forEach(t),Bvr=r(vfe," to load the model weights."),vfe.forEach(t),Ivr=i(px),T(pE.$$.fragment,px),px.forEach(t),Nvr=i(Kl),co=n(Kl,"DIV",{class:!0});var Da=s(co);T(xS.$$.fragment,Da),qvr=i(Da),l5e=n(Da,"P",{});var Ana=s(l5e);Dvr=r(Ana,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Ana.forEach(t),jvr=i(Da),vn=n(Da,"P",{});var _x=s(vn);Gvr=r(_x,"The model class to instantiate is selected based on the "),i5e=n(_x,"CODE",{});var Lna=s(i5e);Ovr=r(Lna,"model_type"),Lna.forEach(t),Vvr=r(_x,` property of the config object (either
passed as an argument or loaded from `),d5e=n(_x,"CODE",{});var yna=s(d5e);Xvr=r(yna,"pretrained_model_name_or_path"),yna.forEach(t),zvr=r(_x,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m5e=n(_x,"CODE",{});var xna=s(m5e);Qvr=r(xna,"pretrained_model_name_or_path"),xna.forEach(t),Wvr=r(_x,":"),_x.forEach(t),Uvr=i(Da),K=n(Da,"UL",{});var ee=s(K);_E=n(ee,"LI",{});var GJe=s(_E);c5e=n(GJe,"STRONG",{});var $na=s(c5e);Hvr=r($na,"albert"),$na.forEach(t),Jvr=r(GJe," \u2014 "),sK=n(GJe,"A",{href:!0});var kna=s(sK);Yvr=r(kna,"AlbertForMultipleChoice"),kna.forEach(t),Zvr=r(GJe," (ALBERT model)"),GJe.forEach(t),Kvr=i(ee),bE=n(ee,"LI",{});var OJe=s(bE);f5e=n(OJe,"STRONG",{});var Sna=s(f5e);eFr=r(Sna,"bert"),Sna.forEach(t),oFr=r(OJe," \u2014 "),lK=n(OJe,"A",{href:!0});var Rna=s(lK);rFr=r(Rna,"BertForMultipleChoice"),Rna.forEach(t),tFr=r(OJe," (BERT model)"),OJe.forEach(t),aFr=i(ee),vE=n(ee,"LI",{});var VJe=s(vE);g5e=n(VJe,"STRONG",{});var Pna=s(g5e);nFr=r(Pna,"big_bird"),Pna.forEach(t),sFr=r(VJe," \u2014 "),iK=n(VJe,"A",{href:!0});var Bna=s(iK);lFr=r(Bna,"BigBirdForMultipleChoice"),Bna.forEach(t),iFr=r(VJe," (BigBird model)"),VJe.forEach(t),dFr=i(ee),FE=n(ee,"LI",{});var XJe=s(FE);h5e=n(XJe,"STRONG",{});var Ina=s(h5e);mFr=r(Ina,"camembert"),Ina.forEach(t),cFr=r(XJe," \u2014 "),dK=n(XJe,"A",{href:!0});var Nna=s(dK);fFr=r(Nna,"CamembertForMultipleChoice"),Nna.forEach(t),gFr=r(XJe," (CamemBERT model)"),XJe.forEach(t),hFr=i(ee),TE=n(ee,"LI",{});var zJe=s(TE);u5e=n(zJe,"STRONG",{});var qna=s(u5e);uFr=r(qna,"canine"),qna.forEach(t),pFr=r(zJe," \u2014 "),mK=n(zJe,"A",{href:!0});var Dna=s(mK);_Fr=r(Dna,"CanineForMultipleChoice"),Dna.forEach(t),bFr=r(zJe," (CANINE model)"),zJe.forEach(t),vFr=i(ee),ME=n(ee,"LI",{});var QJe=s(ME);p5e=n(QJe,"STRONG",{});var jna=s(p5e);FFr=r(jna,"convbert"),jna.forEach(t),TFr=r(QJe," \u2014 "),cK=n(QJe,"A",{href:!0});var Gna=s(cK);MFr=r(Gna,"ConvBertForMultipleChoice"),Gna.forEach(t),EFr=r(QJe," (ConvBERT model)"),QJe.forEach(t),CFr=i(ee),EE=n(ee,"LI",{});var WJe=s(EE);_5e=n(WJe,"STRONG",{});var Ona=s(_5e);wFr=r(Ona,"data2vec-text"),Ona.forEach(t),AFr=r(WJe," \u2014 "),fK=n(WJe,"A",{href:!0});var Vna=s(fK);LFr=r(Vna,"Data2VecTextForMultipleChoice"),Vna.forEach(t),yFr=r(WJe," (Data2VecText model)"),WJe.forEach(t),xFr=i(ee),CE=n(ee,"LI",{});var UJe=s(CE);b5e=n(UJe,"STRONG",{});var Xna=s(b5e);$Fr=r(Xna,"deberta-v2"),Xna.forEach(t),kFr=r(UJe," \u2014 "),gK=n(UJe,"A",{href:!0});var zna=s(gK);SFr=r(zna,"DebertaV2ForMultipleChoice"),zna.forEach(t),RFr=r(UJe," (DeBERTa-v2 model)"),UJe.forEach(t),PFr=i(ee),wE=n(ee,"LI",{});var HJe=s(wE);v5e=n(HJe,"STRONG",{});var Qna=s(v5e);BFr=r(Qna,"distilbert"),Qna.forEach(t),IFr=r(HJe," \u2014 "),hK=n(HJe,"A",{href:!0});var Wna=s(hK);NFr=r(Wna,"DistilBertForMultipleChoice"),Wna.forEach(t),qFr=r(HJe," (DistilBERT model)"),HJe.forEach(t),DFr=i(ee),AE=n(ee,"LI",{});var JJe=s(AE);F5e=n(JJe,"STRONG",{});var Una=s(F5e);jFr=r(Una,"electra"),Una.forEach(t),GFr=r(JJe," \u2014 "),uK=n(JJe,"A",{href:!0});var Hna=s(uK);OFr=r(Hna,"ElectraForMultipleChoice"),Hna.forEach(t),VFr=r(JJe," (ELECTRA model)"),JJe.forEach(t),XFr=i(ee),LE=n(ee,"LI",{});var YJe=s(LE);T5e=n(YJe,"STRONG",{});var Jna=s(T5e);zFr=r(Jna,"ernie"),Jna.forEach(t),QFr=r(YJe," \u2014 "),pK=n(YJe,"A",{href:!0});var Yna=s(pK);WFr=r(Yna,"ErnieForMultipleChoice"),Yna.forEach(t),UFr=r(YJe," (ERNIE model)"),YJe.forEach(t),HFr=i(ee),yE=n(ee,"LI",{});var ZJe=s(yE);M5e=n(ZJe,"STRONG",{});var Zna=s(M5e);JFr=r(Zna,"flaubert"),Zna.forEach(t),YFr=r(ZJe," \u2014 "),_K=n(ZJe,"A",{href:!0});var Kna=s(_K);ZFr=r(Kna,"FlaubertForMultipleChoice"),Kna.forEach(t),KFr=r(ZJe," (FlauBERT model)"),ZJe.forEach(t),eTr=i(ee),xE=n(ee,"LI",{});var KJe=s(xE);E5e=n(KJe,"STRONG",{});var esa=s(E5e);oTr=r(esa,"fnet"),esa.forEach(t),rTr=r(KJe," \u2014 "),bK=n(KJe,"A",{href:!0});var osa=s(bK);tTr=r(osa,"FNetForMultipleChoice"),osa.forEach(t),aTr=r(KJe," (FNet model)"),KJe.forEach(t),nTr=i(ee),$E=n(ee,"LI",{});var eYe=s($E);C5e=n(eYe,"STRONG",{});var rsa=s(C5e);sTr=r(rsa,"funnel"),rsa.forEach(t),lTr=r(eYe," \u2014 "),vK=n(eYe,"A",{href:!0});var tsa=s(vK);iTr=r(tsa,"FunnelForMultipleChoice"),tsa.forEach(t),dTr=r(eYe," (Funnel Transformer model)"),eYe.forEach(t),mTr=i(ee),kE=n(ee,"LI",{});var oYe=s(kE);w5e=n(oYe,"STRONG",{});var asa=s(w5e);cTr=r(asa,"ibert"),asa.forEach(t),fTr=r(oYe," \u2014 "),FK=n(oYe,"A",{href:!0});var nsa=s(FK);gTr=r(nsa,"IBertForMultipleChoice"),nsa.forEach(t),hTr=r(oYe," (I-BERT model)"),oYe.forEach(t),uTr=i(ee),SE=n(ee,"LI",{});var rYe=s(SE);A5e=n(rYe,"STRONG",{});var ssa=s(A5e);pTr=r(ssa,"longformer"),ssa.forEach(t),_Tr=r(rYe," \u2014 "),TK=n(rYe,"A",{href:!0});var lsa=s(TK);bTr=r(lsa,"LongformerForMultipleChoice"),lsa.forEach(t),vTr=r(rYe," (Longformer model)"),rYe.forEach(t),FTr=i(ee),RE=n(ee,"LI",{});var tYe=s(RE);L5e=n(tYe,"STRONG",{});var isa=s(L5e);TTr=r(isa,"luke"),isa.forEach(t),MTr=r(tYe," \u2014 "),MK=n(tYe,"A",{href:!0});var dsa=s(MK);ETr=r(dsa,"LukeForMultipleChoice"),dsa.forEach(t),CTr=r(tYe," (LUKE model)"),tYe.forEach(t),wTr=i(ee),PE=n(ee,"LI",{});var aYe=s(PE);y5e=n(aYe,"STRONG",{});var msa=s(y5e);ATr=r(msa,"megatron-bert"),msa.forEach(t),LTr=r(aYe," \u2014 "),EK=n(aYe,"A",{href:!0});var csa=s(EK);yTr=r(csa,"MegatronBertForMultipleChoice"),csa.forEach(t),xTr=r(aYe," (Megatron-BERT model)"),aYe.forEach(t),$Tr=i(ee),BE=n(ee,"LI",{});var nYe=s(BE);x5e=n(nYe,"STRONG",{});var fsa=s(x5e);kTr=r(fsa,"mobilebert"),fsa.forEach(t),STr=r(nYe," \u2014 "),CK=n(nYe,"A",{href:!0});var gsa=s(CK);RTr=r(gsa,"MobileBertForMultipleChoice"),gsa.forEach(t),PTr=r(nYe," (MobileBERT model)"),nYe.forEach(t),BTr=i(ee),IE=n(ee,"LI",{});var sYe=s(IE);$5e=n(sYe,"STRONG",{});var hsa=s($5e);ITr=r(hsa,"mpnet"),hsa.forEach(t),NTr=r(sYe," \u2014 "),wK=n(sYe,"A",{href:!0});var usa=s(wK);qTr=r(usa,"MPNetForMultipleChoice"),usa.forEach(t),DTr=r(sYe," (MPNet model)"),sYe.forEach(t),jTr=i(ee),NE=n(ee,"LI",{});var lYe=s(NE);k5e=n(lYe,"STRONG",{});var psa=s(k5e);GTr=r(psa,"nezha"),psa.forEach(t),OTr=r(lYe," \u2014 "),AK=n(lYe,"A",{href:!0});var _sa=s(AK);VTr=r(_sa,"NezhaForMultipleChoice"),_sa.forEach(t),XTr=r(lYe," (Nezha model)"),lYe.forEach(t),zTr=i(ee),qE=n(ee,"LI",{});var iYe=s(qE);S5e=n(iYe,"STRONG",{});var bsa=s(S5e);QTr=r(bsa,"nystromformer"),bsa.forEach(t),WTr=r(iYe," \u2014 "),LK=n(iYe,"A",{href:!0});var vsa=s(LK);UTr=r(vsa,"NystromformerForMultipleChoice"),vsa.forEach(t),HTr=r(iYe," (Nystr\xF6mformer model)"),iYe.forEach(t),JTr=i(ee),DE=n(ee,"LI",{});var dYe=s(DE);R5e=n(dYe,"STRONG",{});var Fsa=s(R5e);YTr=r(Fsa,"qdqbert"),Fsa.forEach(t),ZTr=r(dYe," \u2014 "),yK=n(dYe,"A",{href:!0});var Tsa=s(yK);KTr=r(Tsa,"QDQBertForMultipleChoice"),Tsa.forEach(t),eMr=r(dYe," (QDQBert model)"),dYe.forEach(t),oMr=i(ee),jE=n(ee,"LI",{});var mYe=s(jE);P5e=n(mYe,"STRONG",{});var Msa=s(P5e);rMr=r(Msa,"rembert"),Msa.forEach(t),tMr=r(mYe," \u2014 "),xK=n(mYe,"A",{href:!0});var Esa=s(xK);aMr=r(Esa,"RemBertForMultipleChoice"),Esa.forEach(t),nMr=r(mYe," (RemBERT model)"),mYe.forEach(t),sMr=i(ee),GE=n(ee,"LI",{});var cYe=s(GE);B5e=n(cYe,"STRONG",{});var Csa=s(B5e);lMr=r(Csa,"roberta"),Csa.forEach(t),iMr=r(cYe," \u2014 "),$K=n(cYe,"A",{href:!0});var wsa=s($K);dMr=r(wsa,"RobertaForMultipleChoice"),wsa.forEach(t),mMr=r(cYe," (RoBERTa model)"),cYe.forEach(t),cMr=i(ee),OE=n(ee,"LI",{});var fYe=s(OE);I5e=n(fYe,"STRONG",{});var Asa=s(I5e);fMr=r(Asa,"roc_bert"),Asa.forEach(t),gMr=r(fYe," \u2014 "),kK=n(fYe,"A",{href:!0});var Lsa=s(kK);hMr=r(Lsa,"RoCBertForMultipleChoice"),Lsa.forEach(t),uMr=r(fYe," (RoCBert model)"),fYe.forEach(t),pMr=i(ee),VE=n(ee,"LI",{});var gYe=s(VE);N5e=n(gYe,"STRONG",{});var ysa=s(N5e);_Mr=r(ysa,"roformer"),ysa.forEach(t),bMr=r(gYe," \u2014 "),SK=n(gYe,"A",{href:!0});var xsa=s(SK);vMr=r(xsa,"RoFormerForMultipleChoice"),xsa.forEach(t),FMr=r(gYe," (RoFormer model)"),gYe.forEach(t),TMr=i(ee),XE=n(ee,"LI",{});var hYe=s(XE);q5e=n(hYe,"STRONG",{});var $sa=s(q5e);MMr=r($sa,"squeezebert"),$sa.forEach(t),EMr=r(hYe," \u2014 "),RK=n(hYe,"A",{href:!0});var ksa=s(RK);CMr=r(ksa,"SqueezeBertForMultipleChoice"),ksa.forEach(t),wMr=r(hYe," (SqueezeBERT model)"),hYe.forEach(t),AMr=i(ee),zE=n(ee,"LI",{});var uYe=s(zE);D5e=n(uYe,"STRONG",{});var Ssa=s(D5e);LMr=r(Ssa,"xlm"),Ssa.forEach(t),yMr=r(uYe," \u2014 "),PK=n(uYe,"A",{href:!0});var Rsa=s(PK);xMr=r(Rsa,"XLMForMultipleChoice"),Rsa.forEach(t),$Mr=r(uYe," (XLM model)"),uYe.forEach(t),kMr=i(ee),QE=n(ee,"LI",{});var pYe=s(QE);j5e=n(pYe,"STRONG",{});var Psa=s(j5e);SMr=r(Psa,"xlm-roberta"),Psa.forEach(t),RMr=r(pYe," \u2014 "),BK=n(pYe,"A",{href:!0});var Bsa=s(BK);PMr=r(Bsa,"XLMRobertaForMultipleChoice"),Bsa.forEach(t),BMr=r(pYe," (XLM-RoBERTa model)"),pYe.forEach(t),IMr=i(ee),WE=n(ee,"LI",{});var _Ye=s(WE);G5e=n(_Ye,"STRONG",{});var Isa=s(G5e);NMr=r(Isa,"xlm-roberta-xl"),Isa.forEach(t),qMr=r(_Ye," \u2014 "),IK=n(_Ye,"A",{href:!0});var Nsa=s(IK);DMr=r(Nsa,"XLMRobertaXLForMultipleChoice"),Nsa.forEach(t),jMr=r(_Ye," (XLM-RoBERTa-XL model)"),_Ye.forEach(t),GMr=i(ee),UE=n(ee,"LI",{});var bYe=s(UE);O5e=n(bYe,"STRONG",{});var qsa=s(O5e);OMr=r(qsa,"xlnet"),qsa.forEach(t),VMr=r(bYe," \u2014 "),NK=n(bYe,"A",{href:!0});var Dsa=s(NK);XMr=r(Dsa,"XLNetForMultipleChoice"),Dsa.forEach(t),zMr=r(bYe," (XLNet model)"),bYe.forEach(t),QMr=i(ee),HE=n(ee,"LI",{});var vYe=s(HE);V5e=n(vYe,"STRONG",{});var jsa=s(V5e);WMr=r(jsa,"yoso"),jsa.forEach(t),UMr=r(vYe," \u2014 "),qK=n(vYe,"A",{href:!0});var Gsa=s(qK);HMr=r(Gsa,"YosoForMultipleChoice"),Gsa.forEach(t),JMr=r(vYe," (YOSO model)"),vYe.forEach(t),ee.forEach(t),YMr=i(Da),JE=n(Da,"P",{});var FYe=s(JE);ZMr=r(FYe,"The model is set in evaluation mode by default using "),X5e=n(FYe,"CODE",{});var Osa=s(X5e);KMr=r(Osa,"model.eval()"),Osa.forEach(t),eEr=r(FYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),z5e=n(FYe,"CODE",{});var Vsa=s(z5e);oEr=r(Vsa,"model.train()"),Vsa.forEach(t),FYe.forEach(t),rEr=i(Da),T(YE.$$.fragment,Da),Da.forEach(t),Kl.forEach(t),Vlo=i(c),cm=n(c,"H2",{class:!0});var fmo=s(cm);ZE=n(fmo,"A",{id:!0,class:!0,href:!0});var Xsa=s(ZE);Q5e=n(Xsa,"SPAN",{});var zsa=s(Q5e);T($S.$$.fragment,zsa),zsa.forEach(t),Xsa.forEach(t),tEr=i(fmo),W5e=n(fmo,"SPAN",{});var Qsa=s(W5e);aEr=r(Qsa,"AutoModelForNextSentencePrediction"),Qsa.forEach(t),fmo.forEach(t),Xlo=i(c),Uo=n(c,"DIV",{class:!0});var ei=s(Uo);T(kS.$$.fragment,ei),nEr=i(ei),fm=n(ei,"P",{});var Ffe=s(fm);sEr=r(Ffe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),DK=n(Ffe,"A",{href:!0});var Wsa=s(DK);lEr=r(Wsa,"from_pretrained()"),Wsa.forEach(t),iEr=r(Ffe," class method or the "),jK=n(Ffe,"A",{href:!0});var Usa=s(jK);dEr=r(Usa,"from_config()"),Usa.forEach(t),mEr=r(Ffe,` class
method.`),Ffe.forEach(t),cEr=i(ei),SS=n(ei,"P",{});var gmo=s(SS);fEr=r(gmo,"This class cannot be instantiated directly using "),U5e=n(gmo,"CODE",{});var Hsa=s(U5e);gEr=r(Hsa,"__init__()"),Hsa.forEach(t),hEr=r(gmo," (throws an error)."),gmo.forEach(t),uEr=i(ei),Pt=n(ei,"DIV",{class:!0});var bx=s(Pt);T(RS.$$.fragment,bx),pEr=i(bx),H5e=n(bx,"P",{});var Jsa=s(H5e);_Er=r(Jsa,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Jsa.forEach(t),bEr=i(bx),gm=n(bx,"P",{});var Tfe=s(gm);vEr=r(Tfe,`Note:
Loading a model from its configuration file does `),J5e=n(Tfe,"STRONG",{});var Ysa=s(J5e);FEr=r(Ysa,"not"),Ysa.forEach(t),TEr=r(Tfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),GK=n(Tfe,"A",{href:!0});var Zsa=s(GK);MEr=r(Zsa,"from_pretrained()"),Zsa.forEach(t),EEr=r(Tfe," to load the model weights."),Tfe.forEach(t),CEr=i(bx),T(KE.$$.fragment,bx),bx.forEach(t),wEr=i(ei),fo=n(ei,"DIV",{class:!0});var ja=s(fo);T(PS.$$.fragment,ja),AEr=i(ja),Y5e=n(ja,"P",{});var Ksa=s(Y5e);LEr=r(Ksa,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Ksa.forEach(t),yEr=i(ja),Fn=n(ja,"P",{});var vx=s(Fn);xEr=r(vx,"The model class to instantiate is selected based on the "),Z5e=n(vx,"CODE",{});var ela=s(Z5e);$Er=r(ela,"model_type"),ela.forEach(t),kEr=r(vx,` property of the config object (either
passed as an argument or loaded from `),K5e=n(vx,"CODE",{});var ola=s(K5e);SEr=r(ola,"pretrained_model_name_or_path"),ola.forEach(t),REr=r(vx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e0e=n(vx,"CODE",{});var rla=s(e0e);PEr=r(rla,"pretrained_model_name_or_path"),rla.forEach(t),BEr=r(vx,":"),vx.forEach(t),IEr=i(ja),Ye=n(ja,"UL",{});var bt=s(Ye);e4=n(bt,"LI",{});var TYe=s(e4);o0e=n(TYe,"STRONG",{});var tla=s(o0e);NEr=r(tla,"bert"),tla.forEach(t),qEr=r(TYe," \u2014 "),OK=n(TYe,"A",{href:!0});var ala=s(OK);DEr=r(ala,"BertForNextSentencePrediction"),ala.forEach(t),jEr=r(TYe," (BERT model)"),TYe.forEach(t),GEr=i(bt),o4=n(bt,"LI",{});var MYe=s(o4);r0e=n(MYe,"STRONG",{});var nla=s(r0e);OEr=r(nla,"ernie"),nla.forEach(t),VEr=r(MYe," \u2014 "),VK=n(MYe,"A",{href:!0});var sla=s(VK);XEr=r(sla,"ErnieForNextSentencePrediction"),sla.forEach(t),zEr=r(MYe," (ERNIE model)"),MYe.forEach(t),QEr=i(bt),r4=n(bt,"LI",{});var EYe=s(r4);t0e=n(EYe,"STRONG",{});var lla=s(t0e);WEr=r(lla,"fnet"),lla.forEach(t),UEr=r(EYe," \u2014 "),XK=n(EYe,"A",{href:!0});var ila=s(XK);HEr=r(ila,"FNetForNextSentencePrediction"),ila.forEach(t),JEr=r(EYe," (FNet model)"),EYe.forEach(t),YEr=i(bt),t4=n(bt,"LI",{});var CYe=s(t4);a0e=n(CYe,"STRONG",{});var dla=s(a0e);ZEr=r(dla,"megatron-bert"),dla.forEach(t),KEr=r(CYe," \u2014 "),zK=n(CYe,"A",{href:!0});var mla=s(zK);e4r=r(mla,"MegatronBertForNextSentencePrediction"),mla.forEach(t),o4r=r(CYe," (Megatron-BERT model)"),CYe.forEach(t),r4r=i(bt),a4=n(bt,"LI",{});var wYe=s(a4);n0e=n(wYe,"STRONG",{});var cla=s(n0e);t4r=r(cla,"mobilebert"),cla.forEach(t),a4r=r(wYe," \u2014 "),QK=n(wYe,"A",{href:!0});var fla=s(QK);n4r=r(fla,"MobileBertForNextSentencePrediction"),fla.forEach(t),s4r=r(wYe," (MobileBERT model)"),wYe.forEach(t),l4r=i(bt),n4=n(bt,"LI",{});var AYe=s(n4);s0e=n(AYe,"STRONG",{});var gla=s(s0e);i4r=r(gla,"nezha"),gla.forEach(t),d4r=r(AYe," \u2014 "),WK=n(AYe,"A",{href:!0});var hla=s(WK);m4r=r(hla,"NezhaForNextSentencePrediction"),hla.forEach(t),c4r=r(AYe," (Nezha model)"),AYe.forEach(t),f4r=i(bt),s4=n(bt,"LI",{});var LYe=s(s4);l0e=n(LYe,"STRONG",{});var ula=s(l0e);g4r=r(ula,"qdqbert"),ula.forEach(t),h4r=r(LYe," \u2014 "),UK=n(LYe,"A",{href:!0});var pla=s(UK);u4r=r(pla,"QDQBertForNextSentencePrediction"),pla.forEach(t),p4r=r(LYe," (QDQBert model)"),LYe.forEach(t),bt.forEach(t),_4r=i(ja),l4=n(ja,"P",{});var yYe=s(l4);b4r=r(yYe,"The model is set in evaluation mode by default using "),i0e=n(yYe,"CODE",{});var _la=s(i0e);v4r=r(_la,"model.eval()"),_la.forEach(t),F4r=r(yYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),d0e=n(yYe,"CODE",{});var bla=s(d0e);T4r=r(bla,"model.train()"),bla.forEach(t),yYe.forEach(t),M4r=i(ja),T(i4.$$.fragment,ja),ja.forEach(t),ei.forEach(t),zlo=i(c),hm=n(c,"H2",{class:!0});var hmo=s(hm);d4=n(hmo,"A",{id:!0,class:!0,href:!0});var vla=s(d4);m0e=n(vla,"SPAN",{});var Fla=s(m0e);T(BS.$$.fragment,Fla),Fla.forEach(t),vla.forEach(t),E4r=i(hmo),c0e=n(hmo,"SPAN",{});var Tla=s(c0e);C4r=r(Tla,"AutoModelForTokenClassification"),Tla.forEach(t),hmo.forEach(t),Qlo=i(c),Ho=n(c,"DIV",{class:!0});var oi=s(Ho);T(IS.$$.fragment,oi),w4r=i(oi),um=n(oi,"P",{});var Mfe=s(um);A4r=r(Mfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),HK=n(Mfe,"A",{href:!0});var Mla=s(HK);L4r=r(Mla,"from_pretrained()"),Mla.forEach(t),y4r=r(Mfe," class method or the "),JK=n(Mfe,"A",{href:!0});var Ela=s(JK);x4r=r(Ela,"from_config()"),Ela.forEach(t),$4r=r(Mfe,` class
method.`),Mfe.forEach(t),k4r=i(oi),NS=n(oi,"P",{});var umo=s(NS);S4r=r(umo,"This class cannot be instantiated directly using "),f0e=n(umo,"CODE",{});var Cla=s(f0e);R4r=r(Cla,"__init__()"),Cla.forEach(t),P4r=r(umo," (throws an error)."),umo.forEach(t),B4r=i(oi),Bt=n(oi,"DIV",{class:!0});var Fx=s(Bt);T(qS.$$.fragment,Fx),I4r=i(Fx),g0e=n(Fx,"P",{});var wla=s(g0e);N4r=r(wla,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),wla.forEach(t),q4r=i(Fx),pm=n(Fx,"P",{});var Efe=s(pm);D4r=r(Efe,`Note:
Loading a model from its configuration file does `),h0e=n(Efe,"STRONG",{});var Ala=s(h0e);j4r=r(Ala,"not"),Ala.forEach(t),G4r=r(Efe,` load the model weights. It only affects the
model\u2019s configuration. Use `),YK=n(Efe,"A",{href:!0});var Lla=s(YK);O4r=r(Lla,"from_pretrained()"),Lla.forEach(t),V4r=r(Efe," to load the model weights."),Efe.forEach(t),X4r=i(Fx),T(m4.$$.fragment,Fx),Fx.forEach(t),z4r=i(oi),go=n(oi,"DIV",{class:!0});var Ga=s(go);T(DS.$$.fragment,Ga),Q4r=i(Ga),u0e=n(Ga,"P",{});var yla=s(u0e);W4r=r(yla,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),yla.forEach(t),U4r=i(Ga),Tn=n(Ga,"P",{});var Tx=s(Tn);H4r=r(Tx,"The model class to instantiate is selected based on the "),p0e=n(Tx,"CODE",{});var xla=s(p0e);J4r=r(xla,"model_type"),xla.forEach(t),Y4r=r(Tx,` property of the config object (either
passed as an argument or loaded from `),_0e=n(Tx,"CODE",{});var $la=s(_0e);Z4r=r($la,"pretrained_model_name_or_path"),$la.forEach(t),K4r=r(Tx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b0e=n(Tx,"CODE",{});var kla=s(b0e);eCr=r(kla,"pretrained_model_name_or_path"),kla.forEach(t),oCr=r(Tx,":"),Tx.forEach(t),rCr=i(Ga),U=n(Ga,"UL",{});var J=s(U);c4=n(J,"LI",{});var xYe=s(c4);v0e=n(xYe,"STRONG",{});var Sla=s(v0e);tCr=r(Sla,"albert"),Sla.forEach(t),aCr=r(xYe," \u2014 "),ZK=n(xYe,"A",{href:!0});var Rla=s(ZK);nCr=r(Rla,"AlbertForTokenClassification"),Rla.forEach(t),sCr=r(xYe," (ALBERT model)"),xYe.forEach(t),lCr=i(J),f4=n(J,"LI",{});var $Ye=s(f4);F0e=n($Ye,"STRONG",{});var Pla=s(F0e);iCr=r(Pla,"bert"),Pla.forEach(t),dCr=r($Ye," \u2014 "),KK=n($Ye,"A",{href:!0});var Bla=s(KK);mCr=r(Bla,"BertForTokenClassification"),Bla.forEach(t),cCr=r($Ye," (BERT model)"),$Ye.forEach(t),fCr=i(J),g4=n(J,"LI",{});var kYe=s(g4);T0e=n(kYe,"STRONG",{});var Ila=s(T0e);gCr=r(Ila,"big_bird"),Ila.forEach(t),hCr=r(kYe," \u2014 "),eee=n(kYe,"A",{href:!0});var Nla=s(eee);uCr=r(Nla,"BigBirdForTokenClassification"),Nla.forEach(t),pCr=r(kYe," (BigBird model)"),kYe.forEach(t),_Cr=i(J),h4=n(J,"LI",{});var SYe=s(h4);M0e=n(SYe,"STRONG",{});var qla=s(M0e);bCr=r(qla,"bloom"),qla.forEach(t),vCr=r(SYe," \u2014 "),oee=n(SYe,"A",{href:!0});var Dla=s(oee);FCr=r(Dla,"BloomForTokenClassification"),Dla.forEach(t),TCr=r(SYe," (BLOOM model)"),SYe.forEach(t),MCr=i(J),u4=n(J,"LI",{});var RYe=s(u4);E0e=n(RYe,"STRONG",{});var jla=s(E0e);ECr=r(jla,"camembert"),jla.forEach(t),CCr=r(RYe," \u2014 "),ree=n(RYe,"A",{href:!0});var Gla=s(ree);wCr=r(Gla,"CamembertForTokenClassification"),Gla.forEach(t),ACr=r(RYe," (CamemBERT model)"),RYe.forEach(t),LCr=i(J),p4=n(J,"LI",{});var PYe=s(p4);C0e=n(PYe,"STRONG",{});var Ola=s(C0e);yCr=r(Ola,"canine"),Ola.forEach(t),xCr=r(PYe," \u2014 "),tee=n(PYe,"A",{href:!0});var Vla=s(tee);$Cr=r(Vla,"CanineForTokenClassification"),Vla.forEach(t),kCr=r(PYe," (CANINE model)"),PYe.forEach(t),SCr=i(J),_4=n(J,"LI",{});var BYe=s(_4);w0e=n(BYe,"STRONG",{});var Xla=s(w0e);RCr=r(Xla,"convbert"),Xla.forEach(t),PCr=r(BYe," \u2014 "),aee=n(BYe,"A",{href:!0});var zla=s(aee);BCr=r(zla,"ConvBertForTokenClassification"),zla.forEach(t),ICr=r(BYe," (ConvBERT model)"),BYe.forEach(t),NCr=i(J),b4=n(J,"LI",{});var IYe=s(b4);A0e=n(IYe,"STRONG",{});var Qla=s(A0e);qCr=r(Qla,"data2vec-text"),Qla.forEach(t),DCr=r(IYe," \u2014 "),nee=n(IYe,"A",{href:!0});var Wla=s(nee);jCr=r(Wla,"Data2VecTextForTokenClassification"),Wla.forEach(t),GCr=r(IYe," (Data2VecText model)"),IYe.forEach(t),OCr=i(J),v4=n(J,"LI",{});var NYe=s(v4);L0e=n(NYe,"STRONG",{});var Ula=s(L0e);VCr=r(Ula,"deberta"),Ula.forEach(t),XCr=r(NYe," \u2014 "),see=n(NYe,"A",{href:!0});var Hla=s(see);zCr=r(Hla,"DebertaForTokenClassification"),Hla.forEach(t),QCr=r(NYe," (DeBERTa model)"),NYe.forEach(t),WCr=i(J),F4=n(J,"LI",{});var qYe=s(F4);y0e=n(qYe,"STRONG",{});var Jla=s(y0e);UCr=r(Jla,"deberta-v2"),Jla.forEach(t),HCr=r(qYe," \u2014 "),lee=n(qYe,"A",{href:!0});var Yla=s(lee);JCr=r(Yla,"DebertaV2ForTokenClassification"),Yla.forEach(t),YCr=r(qYe," (DeBERTa-v2 model)"),qYe.forEach(t),ZCr=i(J),T4=n(J,"LI",{});var DYe=s(T4);x0e=n(DYe,"STRONG",{});var Zla=s(x0e);KCr=r(Zla,"distilbert"),Zla.forEach(t),e3r=r(DYe," \u2014 "),iee=n(DYe,"A",{href:!0});var Kla=s(iee);o3r=r(Kla,"DistilBertForTokenClassification"),Kla.forEach(t),r3r=r(DYe," (DistilBERT model)"),DYe.forEach(t),t3r=i(J),M4=n(J,"LI",{});var jYe=s(M4);$0e=n(jYe,"STRONG",{});var eia=s($0e);a3r=r(eia,"electra"),eia.forEach(t),n3r=r(jYe," \u2014 "),dee=n(jYe,"A",{href:!0});var oia=s(dee);s3r=r(oia,"ElectraForTokenClassification"),oia.forEach(t),l3r=r(jYe," (ELECTRA model)"),jYe.forEach(t),i3r=i(J),E4=n(J,"LI",{});var GYe=s(E4);k0e=n(GYe,"STRONG",{});var ria=s(k0e);d3r=r(ria,"ernie"),ria.forEach(t),m3r=r(GYe," \u2014 "),mee=n(GYe,"A",{href:!0});var tia=s(mee);c3r=r(tia,"ErnieForTokenClassification"),tia.forEach(t),f3r=r(GYe," (ERNIE model)"),GYe.forEach(t),g3r=i(J),C4=n(J,"LI",{});var OYe=s(C4);S0e=n(OYe,"STRONG",{});var aia=s(S0e);h3r=r(aia,"esm"),aia.forEach(t),u3r=r(OYe," \u2014 "),cee=n(OYe,"A",{href:!0});var nia=s(cee);p3r=r(nia,"EsmForTokenClassification"),nia.forEach(t),_3r=r(OYe," (ESM model)"),OYe.forEach(t),b3r=i(J),w4=n(J,"LI",{});var VYe=s(w4);R0e=n(VYe,"STRONG",{});var sia=s(R0e);v3r=r(sia,"flaubert"),sia.forEach(t),F3r=r(VYe," \u2014 "),fee=n(VYe,"A",{href:!0});var lia=s(fee);T3r=r(lia,"FlaubertForTokenClassification"),lia.forEach(t),M3r=r(VYe," (FlauBERT model)"),VYe.forEach(t),E3r=i(J),A4=n(J,"LI",{});var XYe=s(A4);P0e=n(XYe,"STRONG",{});var iia=s(P0e);C3r=r(iia,"fnet"),iia.forEach(t),w3r=r(XYe," \u2014 "),gee=n(XYe,"A",{href:!0});var dia=s(gee);A3r=r(dia,"FNetForTokenClassification"),dia.forEach(t),L3r=r(XYe," (FNet model)"),XYe.forEach(t),y3r=i(J),L4=n(J,"LI",{});var zYe=s(L4);B0e=n(zYe,"STRONG",{});var mia=s(B0e);x3r=r(mia,"funnel"),mia.forEach(t),$3r=r(zYe," \u2014 "),hee=n(zYe,"A",{href:!0});var cia=s(hee);k3r=r(cia,"FunnelForTokenClassification"),cia.forEach(t),S3r=r(zYe," (Funnel Transformer model)"),zYe.forEach(t),R3r=i(J),y4=n(J,"LI",{});var QYe=s(y4);I0e=n(QYe,"STRONG",{});var fia=s(I0e);P3r=r(fia,"gpt2"),fia.forEach(t),B3r=r(QYe," \u2014 "),uee=n(QYe,"A",{href:!0});var gia=s(uee);I3r=r(gia,"GPT2ForTokenClassification"),gia.forEach(t),N3r=r(QYe," (OpenAI GPT-2 model)"),QYe.forEach(t),q3r=i(J),x4=n(J,"LI",{});var WYe=s(x4);N0e=n(WYe,"STRONG",{});var hia=s(N0e);D3r=r(hia,"ibert"),hia.forEach(t),j3r=r(WYe," \u2014 "),pee=n(WYe,"A",{href:!0});var uia=s(pee);G3r=r(uia,"IBertForTokenClassification"),uia.forEach(t),O3r=r(WYe," (I-BERT model)"),WYe.forEach(t),V3r=i(J),$4=n(J,"LI",{});var UYe=s($4);q0e=n(UYe,"STRONG",{});var pia=s(q0e);X3r=r(pia,"layoutlm"),pia.forEach(t),z3r=r(UYe," \u2014 "),_ee=n(UYe,"A",{href:!0});var _ia=s(_ee);Q3r=r(_ia,"LayoutLMForTokenClassification"),_ia.forEach(t),W3r=r(UYe," (LayoutLM model)"),UYe.forEach(t),U3r=i(J),k4=n(J,"LI",{});var HYe=s(k4);D0e=n(HYe,"STRONG",{});var bia=s(D0e);H3r=r(bia,"layoutlmv2"),bia.forEach(t),J3r=r(HYe," \u2014 "),bee=n(HYe,"A",{href:!0});var via=s(bee);Y3r=r(via,"LayoutLMv2ForTokenClassification"),via.forEach(t),Z3r=r(HYe," (LayoutLMv2 model)"),HYe.forEach(t),K3r=i(J),S4=n(J,"LI",{});var JYe=s(S4);j0e=n(JYe,"STRONG",{});var Fia=s(j0e);e5r=r(Fia,"layoutlmv3"),Fia.forEach(t),o5r=r(JYe," \u2014 "),vee=n(JYe,"A",{href:!0});var Tia=s(vee);r5r=r(Tia,"LayoutLMv3ForTokenClassification"),Tia.forEach(t),t5r=r(JYe," (LayoutLMv3 model)"),JYe.forEach(t),a5r=i(J),R4=n(J,"LI",{});var YYe=s(R4);G0e=n(YYe,"STRONG",{});var Mia=s(G0e);n5r=r(Mia,"lilt"),Mia.forEach(t),s5r=r(YYe," \u2014 "),Fee=n(YYe,"A",{href:!0});var Eia=s(Fee);l5r=r(Eia,"LiltForTokenClassification"),Eia.forEach(t),i5r=r(YYe," (LiLT model)"),YYe.forEach(t),d5r=i(J),P4=n(J,"LI",{});var ZYe=s(P4);O0e=n(ZYe,"STRONG",{});var Cia=s(O0e);m5r=r(Cia,"longformer"),Cia.forEach(t),c5r=r(ZYe," \u2014 "),Tee=n(ZYe,"A",{href:!0});var wia=s(Tee);f5r=r(wia,"LongformerForTokenClassification"),wia.forEach(t),g5r=r(ZYe," (Longformer model)"),ZYe.forEach(t),h5r=i(J),B4=n(J,"LI",{});var KYe=s(B4);V0e=n(KYe,"STRONG",{});var Aia=s(V0e);u5r=r(Aia,"luke"),Aia.forEach(t),p5r=r(KYe," \u2014 "),Mee=n(KYe,"A",{href:!0});var Lia=s(Mee);_5r=r(Lia,"LukeForTokenClassification"),Lia.forEach(t),b5r=r(KYe," (LUKE model)"),KYe.forEach(t),v5r=i(J),I4=n(J,"LI",{});var eZe=s(I4);X0e=n(eZe,"STRONG",{});var yia=s(X0e);F5r=r(yia,"markuplm"),yia.forEach(t),T5r=r(eZe," \u2014 "),Eee=n(eZe,"A",{href:!0});var xia=s(Eee);M5r=r(xia,"MarkupLMForTokenClassification"),xia.forEach(t),E5r=r(eZe," (MarkupLM model)"),eZe.forEach(t),C5r=i(J),N4=n(J,"LI",{});var oZe=s(N4);z0e=n(oZe,"STRONG",{});var $ia=s(z0e);w5r=r($ia,"megatron-bert"),$ia.forEach(t),A5r=r(oZe," \u2014 "),Cee=n(oZe,"A",{href:!0});var kia=s(Cee);L5r=r(kia,"MegatronBertForTokenClassification"),kia.forEach(t),y5r=r(oZe," (Megatron-BERT model)"),oZe.forEach(t),x5r=i(J),q4=n(J,"LI",{});var rZe=s(q4);Q0e=n(rZe,"STRONG",{});var Sia=s(Q0e);$5r=r(Sia,"mobilebert"),Sia.forEach(t),k5r=r(rZe," \u2014 "),wee=n(rZe,"A",{href:!0});var Ria=s(wee);S5r=r(Ria,"MobileBertForTokenClassification"),Ria.forEach(t),R5r=r(rZe," (MobileBERT model)"),rZe.forEach(t),P5r=i(J),D4=n(J,"LI",{});var tZe=s(D4);W0e=n(tZe,"STRONG",{});var Pia=s(W0e);B5r=r(Pia,"mpnet"),Pia.forEach(t),I5r=r(tZe," \u2014 "),Aee=n(tZe,"A",{href:!0});var Bia=s(Aee);N5r=r(Bia,"MPNetForTokenClassification"),Bia.forEach(t),q5r=r(tZe," (MPNet model)"),tZe.forEach(t),D5r=i(J),j4=n(J,"LI",{});var aZe=s(j4);U0e=n(aZe,"STRONG",{});var Iia=s(U0e);j5r=r(Iia,"nezha"),Iia.forEach(t),G5r=r(aZe," \u2014 "),Lee=n(aZe,"A",{href:!0});var Nia=s(Lee);O5r=r(Nia,"NezhaForTokenClassification"),Nia.forEach(t),V5r=r(aZe," (Nezha model)"),aZe.forEach(t),X5r=i(J),G4=n(J,"LI",{});var nZe=s(G4);H0e=n(nZe,"STRONG",{});var qia=s(H0e);z5r=r(qia,"nystromformer"),qia.forEach(t),Q5r=r(nZe," \u2014 "),yee=n(nZe,"A",{href:!0});var Dia=s(yee);W5r=r(Dia,"NystromformerForTokenClassification"),Dia.forEach(t),U5r=r(nZe," (Nystr\xF6mformer model)"),nZe.forEach(t),H5r=i(J),O4=n(J,"LI",{});var sZe=s(O4);J0e=n(sZe,"STRONG",{});var jia=s(J0e);J5r=r(jia,"qdqbert"),jia.forEach(t),Y5r=r(sZe," \u2014 "),xee=n(sZe,"A",{href:!0});var Gia=s(xee);Z5r=r(Gia,"QDQBertForTokenClassification"),Gia.forEach(t),K5r=r(sZe," (QDQBert model)"),sZe.forEach(t),e0r=i(J),V4=n(J,"LI",{});var lZe=s(V4);Y0e=n(lZe,"STRONG",{});var Oia=s(Y0e);o0r=r(Oia,"rembert"),Oia.forEach(t),r0r=r(lZe," \u2014 "),$ee=n(lZe,"A",{href:!0});var Via=s($ee);t0r=r(Via,"RemBertForTokenClassification"),Via.forEach(t),a0r=r(lZe," (RemBERT model)"),lZe.forEach(t),n0r=i(J),X4=n(J,"LI",{});var iZe=s(X4);Z0e=n(iZe,"STRONG",{});var Xia=s(Z0e);s0r=r(Xia,"roberta"),Xia.forEach(t),l0r=r(iZe," \u2014 "),kee=n(iZe,"A",{href:!0});var zia=s(kee);i0r=r(zia,"RobertaForTokenClassification"),zia.forEach(t),d0r=r(iZe," (RoBERTa model)"),iZe.forEach(t),m0r=i(J),z4=n(J,"LI",{});var dZe=s(z4);K0e=n(dZe,"STRONG",{});var Qia=s(K0e);c0r=r(Qia,"roc_bert"),Qia.forEach(t),f0r=r(dZe," \u2014 "),See=n(dZe,"A",{href:!0});var Wia=s(See);g0r=r(Wia,"RoCBertForTokenClassification"),Wia.forEach(t),h0r=r(dZe," (RoCBert model)"),dZe.forEach(t),u0r=i(J),Q4=n(J,"LI",{});var mZe=s(Q4);ewe=n(mZe,"STRONG",{});var Uia=s(ewe);p0r=r(Uia,"roformer"),Uia.forEach(t),_0r=r(mZe," \u2014 "),Ree=n(mZe,"A",{href:!0});var Hia=s(Ree);b0r=r(Hia,"RoFormerForTokenClassification"),Hia.forEach(t),v0r=r(mZe," (RoFormer model)"),mZe.forEach(t),F0r=i(J),W4=n(J,"LI",{});var cZe=s(W4);owe=n(cZe,"STRONG",{});var Jia=s(owe);T0r=r(Jia,"squeezebert"),Jia.forEach(t),M0r=r(cZe," \u2014 "),Pee=n(cZe,"A",{href:!0});var Yia=s(Pee);E0r=r(Yia,"SqueezeBertForTokenClassification"),Yia.forEach(t),C0r=r(cZe," (SqueezeBERT model)"),cZe.forEach(t),w0r=i(J),U4=n(J,"LI",{});var fZe=s(U4);rwe=n(fZe,"STRONG",{});var Zia=s(rwe);A0r=r(Zia,"xlm"),Zia.forEach(t),L0r=r(fZe," \u2014 "),Bee=n(fZe,"A",{href:!0});var Kia=s(Bee);y0r=r(Kia,"XLMForTokenClassification"),Kia.forEach(t),x0r=r(fZe," (XLM model)"),fZe.forEach(t),$0r=i(J),H4=n(J,"LI",{});var gZe=s(H4);twe=n(gZe,"STRONG",{});var eda=s(twe);k0r=r(eda,"xlm-roberta"),eda.forEach(t),S0r=r(gZe," \u2014 "),Iee=n(gZe,"A",{href:!0});var oda=s(Iee);R0r=r(oda,"XLMRobertaForTokenClassification"),oda.forEach(t),P0r=r(gZe," (XLM-RoBERTa model)"),gZe.forEach(t),B0r=i(J),J4=n(J,"LI",{});var hZe=s(J4);awe=n(hZe,"STRONG",{});var rda=s(awe);I0r=r(rda,"xlm-roberta-xl"),rda.forEach(t),N0r=r(hZe," \u2014 "),Nee=n(hZe,"A",{href:!0});var tda=s(Nee);q0r=r(tda,"XLMRobertaXLForTokenClassification"),tda.forEach(t),D0r=r(hZe," (XLM-RoBERTa-XL model)"),hZe.forEach(t),j0r=i(J),Y4=n(J,"LI",{});var uZe=s(Y4);nwe=n(uZe,"STRONG",{});var ada=s(nwe);G0r=r(ada,"xlnet"),ada.forEach(t),O0r=r(uZe," \u2014 "),qee=n(uZe,"A",{href:!0});var nda=s(qee);V0r=r(nda,"XLNetForTokenClassification"),nda.forEach(t),X0r=r(uZe," (XLNet model)"),uZe.forEach(t),z0r=i(J),Z4=n(J,"LI",{});var pZe=s(Z4);swe=n(pZe,"STRONG",{});var sda=s(swe);Q0r=r(sda,"yoso"),sda.forEach(t),W0r=r(pZe," \u2014 "),Dee=n(pZe,"A",{href:!0});var lda=s(Dee);U0r=r(lda,"YosoForTokenClassification"),lda.forEach(t),H0r=r(pZe," (YOSO model)"),pZe.forEach(t),J.forEach(t),J0r=i(Ga),K4=n(Ga,"P",{});var _Ze=s(K4);Y0r=r(_Ze,"The model is set in evaluation mode by default using "),lwe=n(_Ze,"CODE",{});var ida=s(lwe);Z0r=r(ida,"model.eval()"),ida.forEach(t),K0r=r(_Ze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),iwe=n(_Ze,"CODE",{});var dda=s(iwe);ewr=r(dda,"model.train()"),dda.forEach(t),_Ze.forEach(t),owr=i(Ga),T(eC.$$.fragment,Ga),Ga.forEach(t),oi.forEach(t),Wlo=i(c),_m=n(c,"H2",{class:!0});var pmo=s(_m);oC=n(pmo,"A",{id:!0,class:!0,href:!0});var mda=s(oC);dwe=n(mda,"SPAN",{});var cda=s(dwe);T(jS.$$.fragment,cda),cda.forEach(t),mda.forEach(t),rwr=i(pmo),mwe=n(pmo,"SPAN",{});var fda=s(mwe);twr=r(fda,"AutoModelForQuestionAnswering"),fda.forEach(t),pmo.forEach(t),Ulo=i(c),Jo=n(c,"DIV",{class:!0});var ri=s(Jo);T(GS.$$.fragment,ri),awr=i(ri),bm=n(ri,"P",{});var Cfe=s(bm);nwr=r(Cfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),jee=n(Cfe,"A",{href:!0});var gda=s(jee);swr=r(gda,"from_pretrained()"),gda.forEach(t),lwr=r(Cfe," class method or the "),Gee=n(Cfe,"A",{href:!0});var hda=s(Gee);iwr=r(hda,"from_config()"),hda.forEach(t),dwr=r(Cfe,` class
method.`),Cfe.forEach(t),mwr=i(ri),OS=n(ri,"P",{});var _mo=s(OS);cwr=r(_mo,"This class cannot be instantiated directly using "),cwe=n(_mo,"CODE",{});var uda=s(cwe);fwr=r(uda,"__init__()"),uda.forEach(t),gwr=r(_mo," (throws an error)."),_mo.forEach(t),hwr=i(ri),It=n(ri,"DIV",{class:!0});var Mx=s(It);T(VS.$$.fragment,Mx),uwr=i(Mx),fwe=n(Mx,"P",{});var pda=s(fwe);pwr=r(pda,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),pda.forEach(t),_wr=i(Mx),vm=n(Mx,"P",{});var wfe=s(vm);bwr=r(wfe,`Note:
Loading a model from its configuration file does `),gwe=n(wfe,"STRONG",{});var _da=s(gwe);vwr=r(_da,"not"),_da.forEach(t),Fwr=r(wfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Oee=n(wfe,"A",{href:!0});var bda=s(Oee);Twr=r(bda,"from_pretrained()"),bda.forEach(t),Mwr=r(wfe," to load the model weights."),wfe.forEach(t),Ewr=i(Mx),T(rC.$$.fragment,Mx),Mx.forEach(t),Cwr=i(ri),ho=n(ri,"DIV",{class:!0});var Oa=s(ho);T(XS.$$.fragment,Oa),wwr=i(Oa),hwe=n(Oa,"P",{});var vda=s(hwe);Awr=r(vda,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),vda.forEach(t),Lwr=i(Oa),Mn=n(Oa,"P",{});var Ex=s(Mn);ywr=r(Ex,"The model class to instantiate is selected based on the "),uwe=n(Ex,"CODE",{});var Fda=s(uwe);xwr=r(Fda,"model_type"),Fda.forEach(t),$wr=r(Ex,` property of the config object (either
passed as an argument or loaded from `),pwe=n(Ex,"CODE",{});var Tda=s(pwe);kwr=r(Tda,"pretrained_model_name_or_path"),Tda.forEach(t),Swr=r(Ex,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_we=n(Ex,"CODE",{});var Mda=s(_we);Rwr=r(Mda,"pretrained_model_name_or_path"),Mda.forEach(t),Pwr=r(Ex,":"),Ex.forEach(t),Bwr=i(Oa),O=n(Oa,"UL",{});var X=s(O);tC=n(X,"LI",{});var bZe=s(tC);bwe=n(bZe,"STRONG",{});var Eda=s(bwe);Iwr=r(Eda,"albert"),Eda.forEach(t),Nwr=r(bZe," \u2014 "),Vee=n(bZe,"A",{href:!0});var Cda=s(Vee);qwr=r(Cda,"AlbertForQuestionAnswering"),Cda.forEach(t),Dwr=r(bZe," (ALBERT model)"),bZe.forEach(t),jwr=i(X),aC=n(X,"LI",{});var vZe=s(aC);vwe=n(vZe,"STRONG",{});var wda=s(vwe);Gwr=r(wda,"bart"),wda.forEach(t),Owr=r(vZe," \u2014 "),Xee=n(vZe,"A",{href:!0});var Ada=s(Xee);Vwr=r(Ada,"BartForQuestionAnswering"),Ada.forEach(t),Xwr=r(vZe," (BART model)"),vZe.forEach(t),zwr=i(X),nC=n(X,"LI",{});var FZe=s(nC);Fwe=n(FZe,"STRONG",{});var Lda=s(Fwe);Qwr=r(Lda,"bert"),Lda.forEach(t),Wwr=r(FZe," \u2014 "),zee=n(FZe,"A",{href:!0});var yda=s(zee);Uwr=r(yda,"BertForQuestionAnswering"),yda.forEach(t),Hwr=r(FZe," (BERT model)"),FZe.forEach(t),Jwr=i(X),sC=n(X,"LI",{});var TZe=s(sC);Twe=n(TZe,"STRONG",{});var xda=s(Twe);Ywr=r(xda,"big_bird"),xda.forEach(t),Zwr=r(TZe," \u2014 "),Qee=n(TZe,"A",{href:!0});var $da=s(Qee);Kwr=r($da,"BigBirdForQuestionAnswering"),$da.forEach(t),eAr=r(TZe," (BigBird model)"),TZe.forEach(t),oAr=i(X),lC=n(X,"LI",{});var MZe=s(lC);Mwe=n(MZe,"STRONG",{});var kda=s(Mwe);rAr=r(kda,"bigbird_pegasus"),kda.forEach(t),tAr=r(MZe," \u2014 "),Wee=n(MZe,"A",{href:!0});var Sda=s(Wee);aAr=r(Sda,"BigBirdPegasusForQuestionAnswering"),Sda.forEach(t),nAr=r(MZe," (BigBird-Pegasus model)"),MZe.forEach(t),sAr=i(X),iC=n(X,"LI",{});var EZe=s(iC);Ewe=n(EZe,"STRONG",{});var Rda=s(Ewe);lAr=r(Rda,"bloom"),Rda.forEach(t),iAr=r(EZe," \u2014 "),Uee=n(EZe,"A",{href:!0});var Pda=s(Uee);dAr=r(Pda,"BloomForQuestionAnswering"),Pda.forEach(t),mAr=r(EZe," (BLOOM model)"),EZe.forEach(t),cAr=i(X),dC=n(X,"LI",{});var CZe=s(dC);Cwe=n(CZe,"STRONG",{});var Bda=s(Cwe);fAr=r(Bda,"camembert"),Bda.forEach(t),gAr=r(CZe," \u2014 "),Hee=n(CZe,"A",{href:!0});var Ida=s(Hee);hAr=r(Ida,"CamembertForQuestionAnswering"),Ida.forEach(t),uAr=r(CZe," (CamemBERT model)"),CZe.forEach(t),pAr=i(X),mC=n(X,"LI",{});var wZe=s(mC);wwe=n(wZe,"STRONG",{});var Nda=s(wwe);_Ar=r(Nda,"canine"),Nda.forEach(t),bAr=r(wZe," \u2014 "),Jee=n(wZe,"A",{href:!0});var qda=s(Jee);vAr=r(qda,"CanineForQuestionAnswering"),qda.forEach(t),FAr=r(wZe," (CANINE model)"),wZe.forEach(t),TAr=i(X),cC=n(X,"LI",{});var AZe=s(cC);Awe=n(AZe,"STRONG",{});var Dda=s(Awe);MAr=r(Dda,"convbert"),Dda.forEach(t),EAr=r(AZe," \u2014 "),Yee=n(AZe,"A",{href:!0});var jda=s(Yee);CAr=r(jda,"ConvBertForQuestionAnswering"),jda.forEach(t),wAr=r(AZe," (ConvBERT model)"),AZe.forEach(t),AAr=i(X),fC=n(X,"LI",{});var LZe=s(fC);Lwe=n(LZe,"STRONG",{});var Gda=s(Lwe);LAr=r(Gda,"data2vec-text"),Gda.forEach(t),yAr=r(LZe," \u2014 "),Zee=n(LZe,"A",{href:!0});var Oda=s(Zee);xAr=r(Oda,"Data2VecTextForQuestionAnswering"),Oda.forEach(t),$Ar=r(LZe," (Data2VecText model)"),LZe.forEach(t),kAr=i(X),gC=n(X,"LI",{});var yZe=s(gC);ywe=n(yZe,"STRONG",{});var Vda=s(ywe);SAr=r(Vda,"deberta"),Vda.forEach(t),RAr=r(yZe," \u2014 "),Kee=n(yZe,"A",{href:!0});var Xda=s(Kee);PAr=r(Xda,"DebertaForQuestionAnswering"),Xda.forEach(t),BAr=r(yZe," (DeBERTa model)"),yZe.forEach(t),IAr=i(X),hC=n(X,"LI",{});var xZe=s(hC);xwe=n(xZe,"STRONG",{});var zda=s(xwe);NAr=r(zda,"deberta-v2"),zda.forEach(t),qAr=r(xZe," \u2014 "),eoe=n(xZe,"A",{href:!0});var Qda=s(eoe);DAr=r(Qda,"DebertaV2ForQuestionAnswering"),Qda.forEach(t),jAr=r(xZe," (DeBERTa-v2 model)"),xZe.forEach(t),GAr=i(X),uC=n(X,"LI",{});var $Ze=s(uC);$we=n($Ze,"STRONG",{});var Wda=s($we);OAr=r(Wda,"distilbert"),Wda.forEach(t),VAr=r($Ze," \u2014 "),ooe=n($Ze,"A",{href:!0});var Uda=s(ooe);XAr=r(Uda,"DistilBertForQuestionAnswering"),Uda.forEach(t),zAr=r($Ze," (DistilBERT model)"),$Ze.forEach(t),QAr=i(X),pC=n(X,"LI",{});var kZe=s(pC);kwe=n(kZe,"STRONG",{});var Hda=s(kwe);WAr=r(Hda,"electra"),Hda.forEach(t),UAr=r(kZe," \u2014 "),roe=n(kZe,"A",{href:!0});var Jda=s(roe);HAr=r(Jda,"ElectraForQuestionAnswering"),Jda.forEach(t),JAr=r(kZe," (ELECTRA model)"),kZe.forEach(t),YAr=i(X),_C=n(X,"LI",{});var SZe=s(_C);Swe=n(SZe,"STRONG",{});var Yda=s(Swe);ZAr=r(Yda,"ernie"),Yda.forEach(t),KAr=r(SZe," \u2014 "),toe=n(SZe,"A",{href:!0});var Zda=s(toe);e6r=r(Zda,"ErnieForQuestionAnswering"),Zda.forEach(t),o6r=r(SZe," (ERNIE model)"),SZe.forEach(t),r6r=i(X),bC=n(X,"LI",{});var RZe=s(bC);Rwe=n(RZe,"STRONG",{});var Kda=s(Rwe);t6r=r(Kda,"flaubert"),Kda.forEach(t),a6r=r(RZe," \u2014 "),aoe=n(RZe,"A",{href:!0});var ema=s(aoe);n6r=r(ema,"FlaubertForQuestionAnsweringSimple"),ema.forEach(t),s6r=r(RZe," (FlauBERT model)"),RZe.forEach(t),l6r=i(X),vC=n(X,"LI",{});var PZe=s(vC);Pwe=n(PZe,"STRONG",{});var oma=s(Pwe);i6r=r(oma,"fnet"),oma.forEach(t),d6r=r(PZe," \u2014 "),noe=n(PZe,"A",{href:!0});var rma=s(noe);m6r=r(rma,"FNetForQuestionAnswering"),rma.forEach(t),c6r=r(PZe," (FNet model)"),PZe.forEach(t),f6r=i(X),FC=n(X,"LI",{});var BZe=s(FC);Bwe=n(BZe,"STRONG",{});var tma=s(Bwe);g6r=r(tma,"funnel"),tma.forEach(t),h6r=r(BZe," \u2014 "),soe=n(BZe,"A",{href:!0});var ama=s(soe);u6r=r(ama,"FunnelForQuestionAnswering"),ama.forEach(t),p6r=r(BZe," (Funnel Transformer model)"),BZe.forEach(t),_6r=i(X),TC=n(X,"LI",{});var IZe=s(TC);Iwe=n(IZe,"STRONG",{});var nma=s(Iwe);b6r=r(nma,"gptj"),nma.forEach(t),v6r=r(IZe," \u2014 "),loe=n(IZe,"A",{href:!0});var sma=s(loe);F6r=r(sma,"GPTJForQuestionAnswering"),sma.forEach(t),T6r=r(IZe," (GPT-J model)"),IZe.forEach(t),M6r=i(X),MC=n(X,"LI",{});var NZe=s(MC);Nwe=n(NZe,"STRONG",{});var lma=s(Nwe);E6r=r(lma,"ibert"),lma.forEach(t),C6r=r(NZe," \u2014 "),ioe=n(NZe,"A",{href:!0});var ima=s(ioe);w6r=r(ima,"IBertForQuestionAnswering"),ima.forEach(t),A6r=r(NZe," (I-BERT model)"),NZe.forEach(t),L6r=i(X),EC=n(X,"LI",{});var qZe=s(EC);qwe=n(qZe,"STRONG",{});var dma=s(qwe);y6r=r(dma,"layoutlmv2"),dma.forEach(t),x6r=r(qZe," \u2014 "),doe=n(qZe,"A",{href:!0});var mma=s(doe);$6r=r(mma,"LayoutLMv2ForQuestionAnswering"),mma.forEach(t),k6r=r(qZe," (LayoutLMv2 model)"),qZe.forEach(t),S6r=i(X),CC=n(X,"LI",{});var DZe=s(CC);Dwe=n(DZe,"STRONG",{});var cma=s(Dwe);R6r=r(cma,"layoutlmv3"),cma.forEach(t),P6r=r(DZe," \u2014 "),moe=n(DZe,"A",{href:!0});var fma=s(moe);B6r=r(fma,"LayoutLMv3ForQuestionAnswering"),fma.forEach(t),I6r=r(DZe," (LayoutLMv3 model)"),DZe.forEach(t),N6r=i(X),wC=n(X,"LI",{});var jZe=s(wC);jwe=n(jZe,"STRONG",{});var gma=s(jwe);q6r=r(gma,"led"),gma.forEach(t),D6r=r(jZe," \u2014 "),coe=n(jZe,"A",{href:!0});var hma=s(coe);j6r=r(hma,"LEDForQuestionAnswering"),hma.forEach(t),G6r=r(jZe," (LED model)"),jZe.forEach(t),O6r=i(X),AC=n(X,"LI",{});var GZe=s(AC);Gwe=n(GZe,"STRONG",{});var uma=s(Gwe);V6r=r(uma,"lilt"),uma.forEach(t),X6r=r(GZe," \u2014 "),foe=n(GZe,"A",{href:!0});var pma=s(foe);z6r=r(pma,"LiltForQuestionAnswering"),pma.forEach(t),Q6r=r(GZe," (LiLT model)"),GZe.forEach(t),W6r=i(X),LC=n(X,"LI",{});var OZe=s(LC);Owe=n(OZe,"STRONG",{});var _ma=s(Owe);U6r=r(_ma,"longformer"),_ma.forEach(t),H6r=r(OZe," \u2014 "),goe=n(OZe,"A",{href:!0});var bma=s(goe);J6r=r(bma,"LongformerForQuestionAnswering"),bma.forEach(t),Y6r=r(OZe," (Longformer model)"),OZe.forEach(t),Z6r=i(X),yC=n(X,"LI",{});var VZe=s(yC);Vwe=n(VZe,"STRONG",{});var vma=s(Vwe);K6r=r(vma,"luke"),vma.forEach(t),e7r=r(VZe," \u2014 "),hoe=n(VZe,"A",{href:!0});var Fma=s(hoe);o7r=r(Fma,"LukeForQuestionAnswering"),Fma.forEach(t),r7r=r(VZe," (LUKE model)"),VZe.forEach(t),t7r=i(X),xC=n(X,"LI",{});var XZe=s(xC);Xwe=n(XZe,"STRONG",{});var Tma=s(Xwe);a7r=r(Tma,"lxmert"),Tma.forEach(t),n7r=r(XZe," \u2014 "),uoe=n(XZe,"A",{href:!0});var Mma=s(uoe);s7r=r(Mma,"LxmertForQuestionAnswering"),Mma.forEach(t),l7r=r(XZe," (LXMERT model)"),XZe.forEach(t),i7r=i(X),$C=n(X,"LI",{});var zZe=s($C);zwe=n(zZe,"STRONG",{});var Ema=s(zwe);d7r=r(Ema,"markuplm"),Ema.forEach(t),m7r=r(zZe," \u2014 "),poe=n(zZe,"A",{href:!0});var Cma=s(poe);c7r=r(Cma,"MarkupLMForQuestionAnswering"),Cma.forEach(t),f7r=r(zZe," (MarkupLM model)"),zZe.forEach(t),g7r=i(X),kC=n(X,"LI",{});var QZe=s(kC);Qwe=n(QZe,"STRONG",{});var wma=s(Qwe);h7r=r(wma,"mbart"),wma.forEach(t),u7r=r(QZe," \u2014 "),_oe=n(QZe,"A",{href:!0});var Ama=s(_oe);p7r=r(Ama,"MBartForQuestionAnswering"),Ama.forEach(t),_7r=r(QZe," (mBART model)"),QZe.forEach(t),b7r=i(X),SC=n(X,"LI",{});var WZe=s(SC);Wwe=n(WZe,"STRONG",{});var Lma=s(Wwe);v7r=r(Lma,"megatron-bert"),Lma.forEach(t),F7r=r(WZe," \u2014 "),boe=n(WZe,"A",{href:!0});var yma=s(boe);T7r=r(yma,"MegatronBertForQuestionAnswering"),yma.forEach(t),M7r=r(WZe," (Megatron-BERT model)"),WZe.forEach(t),E7r=i(X),RC=n(X,"LI",{});var UZe=s(RC);Uwe=n(UZe,"STRONG",{});var xma=s(Uwe);C7r=r(xma,"mobilebert"),xma.forEach(t),w7r=r(UZe," \u2014 "),voe=n(UZe,"A",{href:!0});var $ma=s(voe);A7r=r($ma,"MobileBertForQuestionAnswering"),$ma.forEach(t),L7r=r(UZe," (MobileBERT model)"),UZe.forEach(t),y7r=i(X),PC=n(X,"LI",{});var HZe=s(PC);Hwe=n(HZe,"STRONG",{});var kma=s(Hwe);x7r=r(kma,"mpnet"),kma.forEach(t),$7r=r(HZe," \u2014 "),Foe=n(HZe,"A",{href:!0});var Sma=s(Foe);k7r=r(Sma,"MPNetForQuestionAnswering"),Sma.forEach(t),S7r=r(HZe," (MPNet model)"),HZe.forEach(t),R7r=i(X),BC=n(X,"LI",{});var JZe=s(BC);Jwe=n(JZe,"STRONG",{});var Rma=s(Jwe);P7r=r(Rma,"mvp"),Rma.forEach(t),B7r=r(JZe," \u2014 "),Toe=n(JZe,"A",{href:!0});var Pma=s(Toe);I7r=r(Pma,"MvpForQuestionAnswering"),Pma.forEach(t),N7r=r(JZe," (MVP model)"),JZe.forEach(t),q7r=i(X),IC=n(X,"LI",{});var YZe=s(IC);Ywe=n(YZe,"STRONG",{});var Bma=s(Ywe);D7r=r(Bma,"nezha"),Bma.forEach(t),j7r=r(YZe," \u2014 "),Moe=n(YZe,"A",{href:!0});var Ima=s(Moe);G7r=r(Ima,"NezhaForQuestionAnswering"),Ima.forEach(t),O7r=r(YZe," (Nezha model)"),YZe.forEach(t),V7r=i(X),NC=n(X,"LI",{});var ZZe=s(NC);Zwe=n(ZZe,"STRONG",{});var Nma=s(Zwe);X7r=r(Nma,"nystromformer"),Nma.forEach(t),z7r=r(ZZe," \u2014 "),Eoe=n(ZZe,"A",{href:!0});var qma=s(Eoe);Q7r=r(qma,"NystromformerForQuestionAnswering"),qma.forEach(t),W7r=r(ZZe," (Nystr\xF6mformer model)"),ZZe.forEach(t),U7r=i(X),qC=n(X,"LI",{});var KZe=s(qC);Kwe=n(KZe,"STRONG",{});var Dma=s(Kwe);H7r=r(Dma,"opt"),Dma.forEach(t),J7r=r(KZe," \u2014 "),Coe=n(KZe,"A",{href:!0});var jma=s(Coe);Y7r=r(jma,"OPTForQuestionAnswering"),jma.forEach(t),Z7r=r(KZe," (OPT model)"),KZe.forEach(t),K7r=i(X),DC=n(X,"LI",{});var eKe=s(DC);eAe=n(eKe,"STRONG",{});var Gma=s(eAe);e8r=r(Gma,"qdqbert"),Gma.forEach(t),o8r=r(eKe," \u2014 "),woe=n(eKe,"A",{href:!0});var Oma=s(woe);r8r=r(Oma,"QDQBertForQuestionAnswering"),Oma.forEach(t),t8r=r(eKe," (QDQBert model)"),eKe.forEach(t),a8r=i(X),jC=n(X,"LI",{});var oKe=s(jC);oAe=n(oKe,"STRONG",{});var Vma=s(oAe);n8r=r(Vma,"reformer"),Vma.forEach(t),s8r=r(oKe," \u2014 "),Aoe=n(oKe,"A",{href:!0});var Xma=s(Aoe);l8r=r(Xma,"ReformerForQuestionAnswering"),Xma.forEach(t),i8r=r(oKe," (Reformer model)"),oKe.forEach(t),d8r=i(X),GC=n(X,"LI",{});var rKe=s(GC);rAe=n(rKe,"STRONG",{});var zma=s(rAe);m8r=r(zma,"rembert"),zma.forEach(t),c8r=r(rKe," \u2014 "),Loe=n(rKe,"A",{href:!0});var Qma=s(Loe);f8r=r(Qma,"RemBertForQuestionAnswering"),Qma.forEach(t),g8r=r(rKe," (RemBERT model)"),rKe.forEach(t),h8r=i(X),OC=n(X,"LI",{});var tKe=s(OC);tAe=n(tKe,"STRONG",{});var Wma=s(tAe);u8r=r(Wma,"roberta"),Wma.forEach(t),p8r=r(tKe," \u2014 "),yoe=n(tKe,"A",{href:!0});var Uma=s(yoe);_8r=r(Uma,"RobertaForQuestionAnswering"),Uma.forEach(t),b8r=r(tKe," (RoBERTa model)"),tKe.forEach(t),v8r=i(X),VC=n(X,"LI",{});var aKe=s(VC);aAe=n(aKe,"STRONG",{});var Hma=s(aAe);F8r=r(Hma,"roc_bert"),Hma.forEach(t),T8r=r(aKe," \u2014 "),xoe=n(aKe,"A",{href:!0});var Jma=s(xoe);M8r=r(Jma,"RoCBertForQuestionAnswering"),Jma.forEach(t),E8r=r(aKe," (RoCBert model)"),aKe.forEach(t),C8r=i(X),XC=n(X,"LI",{});var nKe=s(XC);nAe=n(nKe,"STRONG",{});var Yma=s(nAe);w8r=r(Yma,"roformer"),Yma.forEach(t),A8r=r(nKe," \u2014 "),$oe=n(nKe,"A",{href:!0});var Zma=s($oe);L8r=r(Zma,"RoFormerForQuestionAnswering"),Zma.forEach(t),y8r=r(nKe," (RoFormer model)"),nKe.forEach(t),x8r=i(X),zC=n(X,"LI",{});var sKe=s(zC);sAe=n(sKe,"STRONG",{});var Kma=s(sAe);$8r=r(Kma,"splinter"),Kma.forEach(t),k8r=r(sKe," \u2014 "),koe=n(sKe,"A",{href:!0});var eca=s(koe);S8r=r(eca,"SplinterForQuestionAnswering"),eca.forEach(t),R8r=r(sKe," (Splinter model)"),sKe.forEach(t),P8r=i(X),QC=n(X,"LI",{});var lKe=s(QC);lAe=n(lKe,"STRONG",{});var oca=s(lAe);B8r=r(oca,"squeezebert"),oca.forEach(t),I8r=r(lKe," \u2014 "),Soe=n(lKe,"A",{href:!0});var rca=s(Soe);N8r=r(rca,"SqueezeBertForQuestionAnswering"),rca.forEach(t),q8r=r(lKe," (SqueezeBERT model)"),lKe.forEach(t),D8r=i(X),WC=n(X,"LI",{});var iKe=s(WC);iAe=n(iKe,"STRONG",{});var tca=s(iAe);j8r=r(tca,"xlm"),tca.forEach(t),G8r=r(iKe," \u2014 "),Roe=n(iKe,"A",{href:!0});var aca=s(Roe);O8r=r(aca,"XLMForQuestionAnsweringSimple"),aca.forEach(t),V8r=r(iKe," (XLM model)"),iKe.forEach(t),X8r=i(X),UC=n(X,"LI",{});var dKe=s(UC);dAe=n(dKe,"STRONG",{});var nca=s(dAe);z8r=r(nca,"xlm-roberta"),nca.forEach(t),Q8r=r(dKe," \u2014 "),Poe=n(dKe,"A",{href:!0});var sca=s(Poe);W8r=r(sca,"XLMRobertaForQuestionAnswering"),sca.forEach(t),U8r=r(dKe," (XLM-RoBERTa model)"),dKe.forEach(t),H8r=i(X),HC=n(X,"LI",{});var mKe=s(HC);mAe=n(mKe,"STRONG",{});var lca=s(mAe);J8r=r(lca,"xlm-roberta-xl"),lca.forEach(t),Y8r=r(mKe," \u2014 "),Boe=n(mKe,"A",{href:!0});var ica=s(Boe);Z8r=r(ica,"XLMRobertaXLForQuestionAnswering"),ica.forEach(t),K8r=r(mKe," (XLM-RoBERTa-XL model)"),mKe.forEach(t),eLr=i(X),JC=n(X,"LI",{});var cKe=s(JC);cAe=n(cKe,"STRONG",{});var dca=s(cAe);oLr=r(dca,"xlnet"),dca.forEach(t),rLr=r(cKe," \u2014 "),Ioe=n(cKe,"A",{href:!0});var mca=s(Ioe);tLr=r(mca,"XLNetForQuestionAnsweringSimple"),mca.forEach(t),aLr=r(cKe," (XLNet model)"),cKe.forEach(t),nLr=i(X),YC=n(X,"LI",{});var fKe=s(YC);fAe=n(fKe,"STRONG",{});var cca=s(fAe);sLr=r(cca,"yoso"),cca.forEach(t),lLr=r(fKe," \u2014 "),Noe=n(fKe,"A",{href:!0});var fca=s(Noe);iLr=r(fca,"YosoForQuestionAnswering"),fca.forEach(t),dLr=r(fKe," (YOSO model)"),fKe.forEach(t),X.forEach(t),mLr=i(Oa),ZC=n(Oa,"P",{});var gKe=s(ZC);cLr=r(gKe,"The model is set in evaluation mode by default using "),gAe=n(gKe,"CODE",{});var gca=s(gAe);fLr=r(gca,"model.eval()"),gca.forEach(t),gLr=r(gKe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),hAe=n(gKe,"CODE",{});var hca=s(hAe);hLr=r(hca,"model.train()"),hca.forEach(t),gKe.forEach(t),uLr=i(Oa),T(KC.$$.fragment,Oa),Oa.forEach(t),ri.forEach(t),Hlo=i(c),Fm=n(c,"H2",{class:!0});var bmo=s(Fm);e3=n(bmo,"A",{id:!0,class:!0,href:!0});var uca=s(e3);uAe=n(uca,"SPAN",{});var pca=s(uAe);T(zS.$$.fragment,pca),pca.forEach(t),uca.forEach(t),pLr=i(bmo),pAe=n(bmo,"SPAN",{});var _ca=s(pAe);_Lr=r(_ca,"AutoModelForTableQuestionAnswering"),_ca.forEach(t),bmo.forEach(t),Jlo=i(c),Yo=n(c,"DIV",{class:!0});var ti=s(Yo);T(QS.$$.fragment,ti),bLr=i(ti),Tm=n(ti,"P",{});var Afe=s(Tm);vLr=r(Afe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),qoe=n(Afe,"A",{href:!0});var bca=s(qoe);FLr=r(bca,"from_pretrained()"),bca.forEach(t),TLr=r(Afe," class method or the "),Doe=n(Afe,"A",{href:!0});var vca=s(Doe);MLr=r(vca,"from_config()"),vca.forEach(t),ELr=r(Afe,` class
method.`),Afe.forEach(t),CLr=i(ti),WS=n(ti,"P",{});var vmo=s(WS);wLr=r(vmo,"This class cannot be instantiated directly using "),_Ae=n(vmo,"CODE",{});var Fca=s(_Ae);ALr=r(Fca,"__init__()"),Fca.forEach(t),LLr=r(vmo," (throws an error)."),vmo.forEach(t),yLr=i(ti),Nt=n(ti,"DIV",{class:!0});var Cx=s(Nt);T(US.$$.fragment,Cx),xLr=i(Cx),bAe=n(Cx,"P",{});var Tca=s(bAe);$Lr=r(Tca,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Tca.forEach(t),kLr=i(Cx),Mm=n(Cx,"P",{});var Lfe=s(Mm);SLr=r(Lfe,`Note:
Loading a model from its configuration file does `),vAe=n(Lfe,"STRONG",{});var Mca=s(vAe);RLr=r(Mca,"not"),Mca.forEach(t),PLr=r(Lfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),joe=n(Lfe,"A",{href:!0});var Eca=s(joe);BLr=r(Eca,"from_pretrained()"),Eca.forEach(t),ILr=r(Lfe," to load the model weights."),Lfe.forEach(t),NLr=i(Cx),T(o3.$$.fragment,Cx),Cx.forEach(t),qLr=i(ti),uo=n(ti,"DIV",{class:!0});var Va=s(uo);T(HS.$$.fragment,Va),DLr=i(Va),FAe=n(Va,"P",{});var Cca=s(FAe);jLr=r(Cca,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Cca.forEach(t),GLr=i(Va),En=n(Va,"P",{});var wx=s(En);OLr=r(wx,"The model class to instantiate is selected based on the "),TAe=n(wx,"CODE",{});var wca=s(TAe);VLr=r(wca,"model_type"),wca.forEach(t),XLr=r(wx,` property of the config object (either
passed as an argument or loaded from `),MAe=n(wx,"CODE",{});var Aca=s(MAe);zLr=r(Aca,"pretrained_model_name_or_path"),Aca.forEach(t),QLr=r(wx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),EAe=n(wx,"CODE",{});var Lca=s(EAe);WLr=r(Lca,"pretrained_model_name_or_path"),Lca.forEach(t),ULr=r(wx,":"),wx.forEach(t),HLr=i(Va),CAe=n(Va,"UL",{});var yca=s(CAe);r3=n(yca,"LI",{});var hKe=s(r3);wAe=n(hKe,"STRONG",{});var xca=s(wAe);JLr=r(xca,"tapas"),xca.forEach(t),YLr=r(hKe," \u2014 "),Goe=n(hKe,"A",{href:!0});var $ca=s(Goe);ZLr=r($ca,"TapasForQuestionAnswering"),$ca.forEach(t),KLr=r(hKe," (TAPAS model)"),hKe.forEach(t),yca.forEach(t),eyr=i(Va),t3=n(Va,"P",{});var uKe=s(t3);oyr=r(uKe,"The model is set in evaluation mode by default using "),AAe=n(uKe,"CODE",{});var kca=s(AAe);ryr=r(kca,"model.eval()"),kca.forEach(t),tyr=r(uKe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),LAe=n(uKe,"CODE",{});var Sca=s(LAe);ayr=r(Sca,"model.train()"),Sca.forEach(t),uKe.forEach(t),nyr=i(Va),T(a3.$$.fragment,Va),Va.forEach(t),ti.forEach(t),Ylo=i(c),Em=n(c,"H2",{class:!0});var Fmo=s(Em);n3=n(Fmo,"A",{id:!0,class:!0,href:!0});var Rca=s(n3);yAe=n(Rca,"SPAN",{});var Pca=s(yAe);T(JS.$$.fragment,Pca),Pca.forEach(t),Rca.forEach(t),syr=i(Fmo),xAe=n(Fmo,"SPAN",{});var Bca=s(xAe);lyr=r(Bca,"AutoModelForDocumentQuestionAnswering"),Bca.forEach(t),Fmo.forEach(t),Zlo=i(c),Zo=n(c,"DIV",{class:!0});var ai=s(Zo);T(YS.$$.fragment,ai),iyr=i(ai),Cm=n(ai,"P",{});var yfe=s(Cm);dyr=r(yfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),Ooe=n(yfe,"A",{href:!0});var Ica=s(Ooe);myr=r(Ica,"from_pretrained()"),Ica.forEach(t),cyr=r(yfe," class method or the "),Voe=n(yfe,"A",{href:!0});var Nca=s(Voe);fyr=r(Nca,"from_config()"),Nca.forEach(t),gyr=r(yfe,` class
method.`),yfe.forEach(t),hyr=i(ai),ZS=n(ai,"P",{});var Tmo=s(ZS);uyr=r(Tmo,"This class cannot be instantiated directly using "),$Ae=n(Tmo,"CODE",{});var qca=s($Ae);pyr=r(qca,"__init__()"),qca.forEach(t),_yr=r(Tmo," (throws an error)."),Tmo.forEach(t),byr=i(ai),qt=n(ai,"DIV",{class:!0});var Ax=s(qt);T(KS.$$.fragment,Ax),vyr=i(Ax),kAe=n(Ax,"P",{});var Dca=s(kAe);Fyr=r(Dca,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Dca.forEach(t),Tyr=i(Ax),wm=n(Ax,"P",{});var xfe=s(wm);Myr=r(xfe,`Note:
Loading a model from its configuration file does `),SAe=n(xfe,"STRONG",{});var jca=s(SAe);Eyr=r(jca,"not"),jca.forEach(t),Cyr=r(xfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Xoe=n(xfe,"A",{href:!0});var Gca=s(Xoe);wyr=r(Gca,"from_pretrained()"),Gca.forEach(t),Ayr=r(xfe," to load the model weights."),xfe.forEach(t),Lyr=i(Ax),T(s3.$$.fragment,Ax),Ax.forEach(t),yyr=i(ai),po=n(ai,"DIV",{class:!0});var Xa=s(po);T(eR.$$.fragment,Xa),xyr=i(Xa),RAe=n(Xa,"P",{});var Oca=s(RAe);$yr=r(Oca,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),Oca.forEach(t),kyr=i(Xa),Cn=n(Xa,"P",{});var Lx=s(Cn);Syr=r(Lx,"The model class to instantiate is selected based on the "),PAe=n(Lx,"CODE",{});var Vca=s(PAe);Ryr=r(Vca,"model_type"),Vca.forEach(t),Pyr=r(Lx,` property of the config object (either
passed as an argument or loaded from `),BAe=n(Lx,"CODE",{});var Xca=s(BAe);Byr=r(Xca,"pretrained_model_name_or_path"),Xca.forEach(t),Iyr=r(Lx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),IAe=n(Lx,"CODE",{});var zca=s(IAe);Nyr=r(zca,"pretrained_model_name_or_path"),zca.forEach(t),qyr=r(Lx,":"),Lx.forEach(t),Dyr=i(Xa),Am=n(Xa,"UL",{});var $fe=s(Am);l3=n($fe,"LI",{});var pKe=s(l3);NAe=n(pKe,"STRONG",{});var Qca=s(NAe);jyr=r(Qca,"layoutlm"),Qca.forEach(t),Gyr=r(pKe," \u2014 "),zoe=n(pKe,"A",{href:!0});var Wca=s(zoe);Oyr=r(Wca,"LayoutLMForQuestionAnswering"),Wca.forEach(t),Vyr=r(pKe," (LayoutLM model)"),pKe.forEach(t),Xyr=i($fe),i3=n($fe,"LI",{});var _Ke=s(i3);qAe=n(_Ke,"STRONG",{});var Uca=s(qAe);zyr=r(Uca,"layoutlmv2"),Uca.forEach(t),Qyr=r(_Ke," \u2014 "),Qoe=n(_Ke,"A",{href:!0});var Hca=s(Qoe);Wyr=r(Hca,"LayoutLMv2ForQuestionAnswering"),Hca.forEach(t),Uyr=r(_Ke," (LayoutLMv2 model)"),_Ke.forEach(t),Hyr=i($fe),d3=n($fe,"LI",{});var bKe=s(d3);DAe=n(bKe,"STRONG",{});var Jca=s(DAe);Jyr=r(Jca,"layoutlmv3"),Jca.forEach(t),Yyr=r(bKe," \u2014 "),Woe=n(bKe,"A",{href:!0});var Yca=s(Woe);Zyr=r(Yca,"LayoutLMv3ForQuestionAnswering"),Yca.forEach(t),Kyr=r(bKe," (LayoutLMv3 model)"),bKe.forEach(t),$fe.forEach(t),e9r=i(Xa),m3=n(Xa,"P",{});var vKe=s(m3);o9r=r(vKe,"The model is set in evaluation mode by default using "),jAe=n(vKe,"CODE",{});var Zca=s(jAe);r9r=r(Zca,"model.eval()"),Zca.forEach(t),t9r=r(vKe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),GAe=n(vKe,"CODE",{});var Kca=s(GAe);a9r=r(Kca,"model.train()"),Kca.forEach(t),vKe.forEach(t),n9r=i(Xa),T(c3.$$.fragment,Xa),Xa.forEach(t),ai.forEach(t),Klo=i(c),Lm=n(c,"H2",{class:!0});var Mmo=s(Lm);f3=n(Mmo,"A",{id:!0,class:!0,href:!0});var efa=s(f3);OAe=n(efa,"SPAN",{});var ofa=s(OAe);T(oR.$$.fragment,ofa),ofa.forEach(t),efa.forEach(t),s9r=i(Mmo),VAe=n(Mmo,"SPAN",{});var rfa=s(VAe);l9r=r(rfa,"AutoModelForImageClassification"),rfa.forEach(t),Mmo.forEach(t),eio=i(c),Ko=n(c,"DIV",{class:!0});var ni=s(Ko);T(rR.$$.fragment,ni),i9r=i(ni),ym=n(ni,"P",{});var kfe=s(ym);d9r=r(kfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Uoe=n(kfe,"A",{href:!0});var tfa=s(Uoe);m9r=r(tfa,"from_pretrained()"),tfa.forEach(t),c9r=r(kfe," class method or the "),Hoe=n(kfe,"A",{href:!0});var afa=s(Hoe);f9r=r(afa,"from_config()"),afa.forEach(t),g9r=r(kfe,` class
method.`),kfe.forEach(t),h9r=i(ni),tR=n(ni,"P",{});var Emo=s(tR);u9r=r(Emo,"This class cannot be instantiated directly using "),XAe=n(Emo,"CODE",{});var nfa=s(XAe);p9r=r(nfa,"__init__()"),nfa.forEach(t),_9r=r(Emo," (throws an error)."),Emo.forEach(t),b9r=i(ni),Dt=n(ni,"DIV",{class:!0});var yx=s(Dt);T(aR.$$.fragment,yx),v9r=i(yx),zAe=n(yx,"P",{});var sfa=s(zAe);F9r=r(sfa,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),sfa.forEach(t),T9r=i(yx),xm=n(yx,"P",{});var Sfe=s(xm);M9r=r(Sfe,`Note:
Loading a model from its configuration file does `),QAe=n(Sfe,"STRONG",{});var lfa=s(QAe);E9r=r(lfa,"not"),lfa.forEach(t),C9r=r(Sfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Joe=n(Sfe,"A",{href:!0});var ifa=s(Joe);w9r=r(ifa,"from_pretrained()"),ifa.forEach(t),A9r=r(Sfe," to load the model weights."),Sfe.forEach(t),L9r=i(yx),T(g3.$$.fragment,yx),yx.forEach(t),y9r=i(ni),_o=n(ni,"DIV",{class:!0});var za=s(_o);T(nR.$$.fragment,za),x9r=i(za),WAe=n(za,"P",{});var dfa=s(WAe);$9r=r(dfa,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),dfa.forEach(t),k9r=i(za),wn=n(za,"P",{});var xx=s(wn);S9r=r(xx,"The model class to instantiate is selected based on the "),UAe=n(xx,"CODE",{});var mfa=s(UAe);R9r=r(mfa,"model_type"),mfa.forEach(t),P9r=r(xx,` property of the config object (either
passed as an argument or loaded from `),HAe=n(xx,"CODE",{});var cfa=s(HAe);B9r=r(cfa,"pretrained_model_name_or_path"),cfa.forEach(t),I9r=r(xx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JAe=n(xx,"CODE",{});var ffa=s(JAe);N9r=r(ffa,"pretrained_model_name_or_path"),ffa.forEach(t),q9r=r(xx,":"),xx.forEach(t),D9r=i(za),Fe=n(za,"UL",{});var Me=s(Fe);h3=n(Me,"LI",{});var FKe=s(h3);YAe=n(FKe,"STRONG",{});var gfa=s(YAe);j9r=r(gfa,"beit"),gfa.forEach(t),G9r=r(FKe," \u2014 "),Yoe=n(FKe,"A",{href:!0});var hfa=s(Yoe);O9r=r(hfa,"BeitForImageClassification"),hfa.forEach(t),V9r=r(FKe," (BEiT model)"),FKe.forEach(t),X9r=i(Me),u3=n(Me,"LI",{});var TKe=s(u3);ZAe=n(TKe,"STRONG",{});var ufa=s(ZAe);z9r=r(ufa,"convnext"),ufa.forEach(t),Q9r=r(TKe," \u2014 "),Zoe=n(TKe,"A",{href:!0});var pfa=s(Zoe);W9r=r(pfa,"ConvNextForImageClassification"),pfa.forEach(t),U9r=r(TKe," (ConvNeXT model)"),TKe.forEach(t),H9r=i(Me),p3=n(Me,"LI",{});var MKe=s(p3);KAe=n(MKe,"STRONG",{});var _fa=s(KAe);J9r=r(_fa,"cvt"),_fa.forEach(t),Y9r=r(MKe," \u2014 "),Koe=n(MKe,"A",{href:!0});var bfa=s(Koe);Z9r=r(bfa,"CvtForImageClassification"),bfa.forEach(t),K9r=r(MKe," (CvT model)"),MKe.forEach(t),exr=i(Me),_3=n(Me,"LI",{});var EKe=s(_3);e6e=n(EKe,"STRONG",{});var vfa=s(e6e);oxr=r(vfa,"data2vec-vision"),vfa.forEach(t),rxr=r(EKe," \u2014 "),ere=n(EKe,"A",{href:!0});var Ffa=s(ere);txr=r(Ffa,"Data2VecVisionForImageClassification"),Ffa.forEach(t),axr=r(EKe," (Data2VecVision model)"),EKe.forEach(t),nxr=i(Me),Nl=n(Me,"LI",{});var Lq=s(Nl);o6e=n(Lq,"STRONG",{});var Tfa=s(o6e);sxr=r(Tfa,"deit"),Tfa.forEach(t),lxr=r(Lq," \u2014 "),ore=n(Lq,"A",{href:!0});var Mfa=s(ore);ixr=r(Mfa,"DeiTForImageClassification"),Mfa.forEach(t),dxr=r(Lq," or "),rre=n(Lq,"A",{href:!0});var Efa=s(rre);mxr=r(Efa,"DeiTForImageClassificationWithTeacher"),Efa.forEach(t),cxr=r(Lq," (DeiT model)"),Lq.forEach(t),fxr=i(Me),b3=n(Me,"LI",{});var CKe=s(b3);r6e=n(CKe,"STRONG",{});var Cfa=s(r6e);gxr=r(Cfa,"imagegpt"),Cfa.forEach(t),hxr=r(CKe," \u2014 "),tre=n(CKe,"A",{href:!0});var wfa=s(tre);uxr=r(wfa,"ImageGPTForImageClassification"),wfa.forEach(t),pxr=r(CKe," (ImageGPT model)"),CKe.forEach(t),_xr=i(Me),ql=n(Me,"LI",{});var yq=s(ql);t6e=n(yq,"STRONG",{});var Afa=s(t6e);bxr=r(Afa,"levit"),Afa.forEach(t),vxr=r(yq," \u2014 "),are=n(yq,"A",{href:!0});var Lfa=s(are);Fxr=r(Lfa,"LevitForImageClassification"),Lfa.forEach(t),Txr=r(yq," or "),nre=n(yq,"A",{href:!0});var yfa=s(nre);Mxr=r(yfa,"LevitForImageClassificationWithTeacher"),yfa.forEach(t),Exr=r(yq," (LeViT model)"),yq.forEach(t),Cxr=i(Me),v3=n(Me,"LI",{});var wKe=s(v3);a6e=n(wKe,"STRONG",{});var xfa=s(a6e);wxr=r(xfa,"mobilevit"),xfa.forEach(t),Axr=r(wKe," \u2014 "),sre=n(wKe,"A",{href:!0});var $fa=s(sre);Lxr=r($fa,"MobileViTForImageClassification"),$fa.forEach(t),yxr=r(wKe," (MobileViT model)"),wKe.forEach(t),xxr=i(Me),jt=n(Me,"LI",{});var Kf=s(jt);n6e=n(Kf,"STRONG",{});var kfa=s(n6e);$xr=r(kfa,"perceiver"),kfa.forEach(t),kxr=r(Kf," \u2014 "),lre=n(Kf,"A",{href:!0});var Sfa=s(lre);Sxr=r(Sfa,"PerceiverForImageClassificationLearned"),Sfa.forEach(t),Rxr=r(Kf," or "),ire=n(Kf,"A",{href:!0});var Rfa=s(ire);Pxr=r(Rfa,"PerceiverForImageClassificationFourier"),Rfa.forEach(t),Bxr=r(Kf," or "),dre=n(Kf,"A",{href:!0});var Pfa=s(dre);Ixr=r(Pfa,"PerceiverForImageClassificationConvProcessing"),Pfa.forEach(t),Nxr=r(Kf," (Perceiver model)"),Kf.forEach(t),qxr=i(Me),F3=n(Me,"LI",{});var AKe=s(F3);s6e=n(AKe,"STRONG",{});var Bfa=s(s6e);Dxr=r(Bfa,"poolformer"),Bfa.forEach(t),jxr=r(AKe," \u2014 "),mre=n(AKe,"A",{href:!0});var Ifa=s(mre);Gxr=r(Ifa,"PoolFormerForImageClassification"),Ifa.forEach(t),Oxr=r(AKe," (PoolFormer model)"),AKe.forEach(t),Vxr=i(Me),T3=n(Me,"LI",{});var LKe=s(T3);l6e=n(LKe,"STRONG",{});var Nfa=s(l6e);Xxr=r(Nfa,"regnet"),Nfa.forEach(t),zxr=r(LKe," \u2014 "),cre=n(LKe,"A",{href:!0});var qfa=s(cre);Qxr=r(qfa,"RegNetForImageClassification"),qfa.forEach(t),Wxr=r(LKe," (RegNet model)"),LKe.forEach(t),Uxr=i(Me),M3=n(Me,"LI",{});var yKe=s(M3);i6e=n(yKe,"STRONG",{});var Dfa=s(i6e);Hxr=r(Dfa,"resnet"),Dfa.forEach(t),Jxr=r(yKe," \u2014 "),fre=n(yKe,"A",{href:!0});var jfa=s(fre);Yxr=r(jfa,"ResNetForImageClassification"),jfa.forEach(t),Zxr=r(yKe," (ResNet model)"),yKe.forEach(t),Kxr=i(Me),E3=n(Me,"LI",{});var xKe=s(E3);d6e=n(xKe,"STRONG",{});var Gfa=s(d6e);e$r=r(Gfa,"segformer"),Gfa.forEach(t),o$r=r(xKe," \u2014 "),gre=n(xKe,"A",{href:!0});var Ofa=s(gre);r$r=r(Ofa,"SegformerForImageClassification"),Ofa.forEach(t),t$r=r(xKe," (SegFormer model)"),xKe.forEach(t),a$r=i(Me),C3=n(Me,"LI",{});var $Ke=s(C3);m6e=n($Ke,"STRONG",{});var Vfa=s(m6e);n$r=r(Vfa,"swin"),Vfa.forEach(t),s$r=r($Ke," \u2014 "),hre=n($Ke,"A",{href:!0});var Xfa=s(hre);l$r=r(Xfa,"SwinForImageClassification"),Xfa.forEach(t),i$r=r($Ke," (Swin Transformer model)"),$Ke.forEach(t),d$r=i(Me),w3=n(Me,"LI",{});var kKe=s(w3);c6e=n(kKe,"STRONG",{});var zfa=s(c6e);m$r=r(zfa,"swinv2"),zfa.forEach(t),c$r=r(kKe," \u2014 "),ure=n(kKe,"A",{href:!0});var Qfa=s(ure);f$r=r(Qfa,"Swinv2ForImageClassification"),Qfa.forEach(t),g$r=r(kKe," (Swin Transformer V2 model)"),kKe.forEach(t),h$r=i(Me),A3=n(Me,"LI",{});var SKe=s(A3);f6e=n(SKe,"STRONG",{});var Wfa=s(f6e);u$r=r(Wfa,"van"),Wfa.forEach(t),p$r=r(SKe," \u2014 "),pre=n(SKe,"A",{href:!0});var Ufa=s(pre);_$r=r(Ufa,"VanForImageClassification"),Ufa.forEach(t),b$r=r(SKe," (VAN model)"),SKe.forEach(t),v$r=i(Me),L3=n(Me,"LI",{});var RKe=s(L3);g6e=n(RKe,"STRONG",{});var Hfa=s(g6e);F$r=r(Hfa,"vit"),Hfa.forEach(t),T$r=r(RKe," \u2014 "),_re=n(RKe,"A",{href:!0});var Jfa=s(_re);M$r=r(Jfa,"ViTForImageClassification"),Jfa.forEach(t),E$r=r(RKe," (ViT model)"),RKe.forEach(t),C$r=i(Me),y3=n(Me,"LI",{});var PKe=s(y3);h6e=n(PKe,"STRONG",{});var Yfa=s(h6e);w$r=r(Yfa,"vit_msn"),Yfa.forEach(t),A$r=r(PKe," \u2014 "),bre=n(PKe,"A",{href:!0});var Zfa=s(bre);L$r=r(Zfa,"ViTMSNForImageClassification"),Zfa.forEach(t),y$r=r(PKe," (ViTMSN model)"),PKe.forEach(t),Me.forEach(t),x$r=i(za),x3=n(za,"P",{});var BKe=s(x3);$$r=r(BKe,"The model is set in evaluation mode by default using "),u6e=n(BKe,"CODE",{});var Kfa=s(u6e);k$r=r(Kfa,"model.eval()"),Kfa.forEach(t),S$r=r(BKe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),p6e=n(BKe,"CODE",{});var ega=s(p6e);R$r=r(ega,"model.train()"),ega.forEach(t),BKe.forEach(t),P$r=i(za),T($3.$$.fragment,za),za.forEach(t),ni.forEach(t),oio=i(c),$m=n(c,"H2",{class:!0});var Cmo=s($m);k3=n(Cmo,"A",{id:!0,class:!0,href:!0});var oga=s(k3);_6e=n(oga,"SPAN",{});var rga=s(_6e);T(sR.$$.fragment,rga),rga.forEach(t),oga.forEach(t),B$r=i(Cmo),b6e=n(Cmo,"SPAN",{});var tga=s(b6e);I$r=r(tga,"AutoModelForVideoClassification"),tga.forEach(t),Cmo.forEach(t),rio=i(c),er=n(c,"DIV",{class:!0});var si=s(er);T(lR.$$.fragment,si),N$r=i(si),km=n(si,"P",{});var Rfe=s(km);q$r=r(Rfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),vre=n(Rfe,"A",{href:!0});var aga=s(vre);D$r=r(aga,"from_pretrained()"),aga.forEach(t),j$r=r(Rfe," class method or the "),Fre=n(Rfe,"A",{href:!0});var nga=s(Fre);G$r=r(nga,"from_config()"),nga.forEach(t),O$r=r(Rfe,` class
method.`),Rfe.forEach(t),V$r=i(si),iR=n(si,"P",{});var wmo=s(iR);X$r=r(wmo,"This class cannot be instantiated directly using "),v6e=n(wmo,"CODE",{});var sga=s(v6e);z$r=r(sga,"__init__()"),sga.forEach(t),Q$r=r(wmo," (throws an error)."),wmo.forEach(t),W$r=i(si),Gt=n(si,"DIV",{class:!0});var $x=s(Gt);T(dR.$$.fragment,$x),U$r=i($x),F6e=n($x,"P",{});var lga=s(F6e);H$r=r(lga,"Instantiates one of the model classes of the library (with a video classification head) from a configuration."),lga.forEach(t),J$r=i($x),Sm=n($x,"P",{});var Pfe=s(Sm);Y$r=r(Pfe,`Note:
Loading a model from its configuration file does `),T6e=n(Pfe,"STRONG",{});var iga=s(T6e);Z$r=r(iga,"not"),iga.forEach(t),K$r=r(Pfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Tre=n(Pfe,"A",{href:!0});var dga=s(Tre);ekr=r(dga,"from_pretrained()"),dga.forEach(t),okr=r(Pfe," to load the model weights."),Pfe.forEach(t),rkr=i($x),T(S3.$$.fragment,$x),$x.forEach(t),tkr=i(si),bo=n(si,"DIV",{class:!0});var Qa=s(bo);T(mR.$$.fragment,Qa),akr=i(Qa),M6e=n(Qa,"P",{});var mga=s(M6e);nkr=r(mga,"Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),mga.forEach(t),skr=i(Qa),An=n(Qa,"P",{});var kx=s(An);lkr=r(kx,"The model class to instantiate is selected based on the "),E6e=n(kx,"CODE",{});var cga=s(E6e);ikr=r(cga,"model_type"),cga.forEach(t),dkr=r(kx,` property of the config object (either
passed as an argument or loaded from `),C6e=n(kx,"CODE",{});var fga=s(C6e);mkr=r(fga,"pretrained_model_name_or_path"),fga.forEach(t),ckr=r(kx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),w6e=n(kx,"CODE",{});var gga=s(w6e);fkr=r(gga,"pretrained_model_name_or_path"),gga.forEach(t),gkr=r(kx,":"),kx.forEach(t),hkr=i(Qa),A6e=n(Qa,"UL",{});var hga=s(A6e);R3=n(hga,"LI",{});var IKe=s(R3);L6e=n(IKe,"STRONG",{});var uga=s(L6e);ukr=r(uga,"videomae"),uga.forEach(t),pkr=r(IKe," \u2014 "),Mre=n(IKe,"A",{href:!0});var pga=s(Mre);_kr=r(pga,"VideoMAEForVideoClassification"),pga.forEach(t),bkr=r(IKe," (VideoMAE model)"),IKe.forEach(t),hga.forEach(t),vkr=i(Qa),P3=n(Qa,"P",{});var NKe=s(P3);Fkr=r(NKe,"The model is set in evaluation mode by default using "),y6e=n(NKe,"CODE",{});var _ga=s(y6e);Tkr=r(_ga,"model.eval()"),_ga.forEach(t),Mkr=r(NKe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),x6e=n(NKe,"CODE",{});var bga=s(x6e);Ekr=r(bga,"model.train()"),bga.forEach(t),NKe.forEach(t),Ckr=i(Qa),T(B3.$$.fragment,Qa),Qa.forEach(t),si.forEach(t),tio=i(c),Rm=n(c,"H2",{class:!0});var Amo=s(Rm);I3=n(Amo,"A",{id:!0,class:!0,href:!0});var vga=s(I3);$6e=n(vga,"SPAN",{});var Fga=s($6e);T(cR.$$.fragment,Fga),Fga.forEach(t),vga.forEach(t),wkr=i(Amo),k6e=n(Amo,"SPAN",{});var Tga=s(k6e);Akr=r(Tga,"AutoModelForVision2Seq"),Tga.forEach(t),Amo.forEach(t),aio=i(c),or=n(c,"DIV",{class:!0});var li=s(or);T(fR.$$.fragment,li),Lkr=i(li),Pm=n(li,"P",{});var Bfe=s(Pm);ykr=r(Bfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Ere=n(Bfe,"A",{href:!0});var Mga=s(Ere);xkr=r(Mga,"from_pretrained()"),Mga.forEach(t),$kr=r(Bfe," class method or the "),Cre=n(Bfe,"A",{href:!0});var Ega=s(Cre);kkr=r(Ega,"from_config()"),Ega.forEach(t),Skr=r(Bfe,` class
method.`),Bfe.forEach(t),Rkr=i(li),gR=n(li,"P",{});var Lmo=s(gR);Pkr=r(Lmo,"This class cannot be instantiated directly using "),S6e=n(Lmo,"CODE",{});var Cga=s(S6e);Bkr=r(Cga,"__init__()"),Cga.forEach(t),Ikr=r(Lmo," (throws an error)."),Lmo.forEach(t),Nkr=i(li),Ot=n(li,"DIV",{class:!0});var Sx=s(Ot);T(hR.$$.fragment,Sx),qkr=i(Sx),R6e=n(Sx,"P",{});var wga=s(R6e);Dkr=r(wga,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),wga.forEach(t),jkr=i(Sx),Bm=n(Sx,"P",{});var Ife=s(Bm);Gkr=r(Ife,`Note:
Loading a model from its configuration file does `),P6e=n(Ife,"STRONG",{});var Aga=s(P6e);Okr=r(Aga,"not"),Aga.forEach(t),Vkr=r(Ife,` load the model weights. It only affects the
model\u2019s configuration. Use `),wre=n(Ife,"A",{href:!0});var Lga=s(wre);Xkr=r(Lga,"from_pretrained()"),Lga.forEach(t),zkr=r(Ife," to load the model weights."),Ife.forEach(t),Qkr=i(Sx),T(N3.$$.fragment,Sx),Sx.forEach(t),Wkr=i(li),vo=n(li,"DIV",{class:!0});var Wa=s(vo);T(uR.$$.fragment,Wa),Ukr=i(Wa),B6e=n(Wa,"P",{});var yga=s(B6e);Hkr=r(yga,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),yga.forEach(t),Jkr=i(Wa),Ln=n(Wa,"P",{});var Rx=s(Ln);Ykr=r(Rx,"The model class to instantiate is selected based on the "),I6e=n(Rx,"CODE",{});var xga=s(I6e);Zkr=r(xga,"model_type"),xga.forEach(t),Kkr=r(Rx,` property of the config object (either
passed as an argument or loaded from `),N6e=n(Rx,"CODE",{});var $ga=s(N6e);eSr=r($ga,"pretrained_model_name_or_path"),$ga.forEach(t),oSr=r(Rx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),q6e=n(Rx,"CODE",{});var kga=s(q6e);rSr=r(kga,"pretrained_model_name_or_path"),kga.forEach(t),tSr=r(Rx,":"),Rx.forEach(t),aSr=i(Wa),D6e=n(Wa,"UL",{});var Sga=s(D6e);q3=n(Sga,"LI",{});var qKe=s(q3);j6e=n(qKe,"STRONG",{});var Rga=s(j6e);nSr=r(Rga,"vision-encoder-decoder"),Rga.forEach(t),sSr=r(qKe," \u2014 "),Are=n(qKe,"A",{href:!0});var Pga=s(Are);lSr=r(Pga,"VisionEncoderDecoderModel"),Pga.forEach(t),iSr=r(qKe," (Vision Encoder decoder model)"),qKe.forEach(t),Sga.forEach(t),dSr=i(Wa),D3=n(Wa,"P",{});var DKe=s(D3);mSr=r(DKe,"The model is set in evaluation mode by default using "),G6e=n(DKe,"CODE",{});var Bga=s(G6e);cSr=r(Bga,"model.eval()"),Bga.forEach(t),fSr=r(DKe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),O6e=n(DKe,"CODE",{});var Iga=s(O6e);gSr=r(Iga,"model.train()"),Iga.forEach(t),DKe.forEach(t),hSr=i(Wa),T(j3.$$.fragment,Wa),Wa.forEach(t),li.forEach(t),nio=i(c),Im=n(c,"H2",{class:!0});var ymo=s(Im);G3=n(ymo,"A",{id:!0,class:!0,href:!0});var Nga=s(G3);V6e=n(Nga,"SPAN",{});var qga=s(V6e);T(pR.$$.fragment,qga),qga.forEach(t),Nga.forEach(t),uSr=i(ymo),X6e=n(ymo,"SPAN",{});var Dga=s(X6e);pSr=r(Dga,"AutoModelForVisualQuestionAnswering"),Dga.forEach(t),ymo.forEach(t),sio=i(c),rr=n(c,"DIV",{class:!0});var ii=s(rr);T(_R.$$.fragment,ii),_Sr=i(ii),Nm=n(ii,"P",{});var Nfe=s(Nm);bSr=r(Nfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),Lre=n(Nfe,"A",{href:!0});var jga=s(Lre);vSr=r(jga,"from_pretrained()"),jga.forEach(t),FSr=r(Nfe," class method or the "),yre=n(Nfe,"A",{href:!0});var Gga=s(yre);TSr=r(Gga,"from_config()"),Gga.forEach(t),MSr=r(Nfe,` class
method.`),Nfe.forEach(t),ESr=i(ii),bR=n(ii,"P",{});var xmo=s(bR);CSr=r(xmo,"This class cannot be instantiated directly using "),z6e=n(xmo,"CODE",{});var Oga=s(z6e);wSr=r(Oga,"__init__()"),Oga.forEach(t),ASr=r(xmo," (throws an error)."),xmo.forEach(t),LSr=i(ii),Vt=n(ii,"DIV",{class:!0});var Px=s(Vt);T(vR.$$.fragment,Px),ySr=i(Px),Q6e=n(Px,"P",{});var Vga=s(Q6e);xSr=r(Vga,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),Vga.forEach(t),$Sr=i(Px),qm=n(Px,"P",{});var qfe=s(qm);kSr=r(qfe,`Note:
Loading a model from its configuration file does `),W6e=n(qfe,"STRONG",{});var Xga=s(W6e);SSr=r(Xga,"not"),Xga.forEach(t),RSr=r(qfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),xre=n(qfe,"A",{href:!0});var zga=s(xre);PSr=r(zga,"from_pretrained()"),zga.forEach(t),BSr=r(qfe," to load the model weights."),qfe.forEach(t),ISr=i(Px),T(O3.$$.fragment,Px),Px.forEach(t),NSr=i(ii),Fo=n(ii,"DIV",{class:!0});var Ua=s(Fo);T(FR.$$.fragment,Ua),qSr=i(Ua),U6e=n(Ua,"P",{});var Qga=s(U6e);DSr=r(Qga,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),Qga.forEach(t),jSr=i(Ua),yn=n(Ua,"P",{});var Bx=s(yn);GSr=r(Bx,"The model class to instantiate is selected based on the "),H6e=n(Bx,"CODE",{});var Wga=s(H6e);OSr=r(Wga,"model_type"),Wga.forEach(t),VSr=r(Bx,` property of the config object (either
passed as an argument or loaded from `),J6e=n(Bx,"CODE",{});var Uga=s(J6e);XSr=r(Uga,"pretrained_model_name_or_path"),Uga.forEach(t),zSr=r(Bx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Y6e=n(Bx,"CODE",{});var Hga=s(Y6e);QSr=r(Hga,"pretrained_model_name_or_path"),Hga.forEach(t),WSr=r(Bx,":"),Bx.forEach(t),USr=i(Ua),Z6e=n(Ua,"UL",{});var Jga=s(Z6e);V3=n(Jga,"LI",{});var jKe=s(V3);K6e=n(jKe,"STRONG",{});var Yga=s(K6e);HSr=r(Yga,"vilt"),Yga.forEach(t),JSr=r(jKe," \u2014 "),$re=n(jKe,"A",{href:!0});var Zga=s($re);YSr=r(Zga,"ViltForQuestionAnswering"),Zga.forEach(t),ZSr=r(jKe," (ViLT model)"),jKe.forEach(t),Jga.forEach(t),KSr=i(Ua),X3=n(Ua,"P",{});var GKe=s(X3);eRr=r(GKe,"The model is set in evaluation mode by default using "),e7e=n(GKe,"CODE",{});var Kga=s(e7e);oRr=r(Kga,"model.eval()"),Kga.forEach(t),rRr=r(GKe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o7e=n(GKe,"CODE",{});var eha=s(o7e);tRr=r(eha,"model.train()"),eha.forEach(t),GKe.forEach(t),aRr=i(Ua),T(z3.$$.fragment,Ua),Ua.forEach(t),ii.forEach(t),lio=i(c),Dm=n(c,"H2",{class:!0});var $mo=s(Dm);Q3=n($mo,"A",{id:!0,class:!0,href:!0});var oha=s(Q3);r7e=n(oha,"SPAN",{});var rha=s(r7e);T(TR.$$.fragment,rha),rha.forEach(t),oha.forEach(t),nRr=i($mo),t7e=n($mo,"SPAN",{});var tha=s(t7e);sRr=r(tha,"AutoModelForAudioClassification"),tha.forEach(t),$mo.forEach(t),iio=i(c),tr=n(c,"DIV",{class:!0});var di=s(tr);T(MR.$$.fragment,di),lRr=i(di),jm=n(di,"P",{});var Dfe=s(jm);iRr=r(Dfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),kre=n(Dfe,"A",{href:!0});var aha=s(kre);dRr=r(aha,"from_pretrained()"),aha.forEach(t),mRr=r(Dfe," class method or the "),Sre=n(Dfe,"A",{href:!0});var nha=s(Sre);cRr=r(nha,"from_config()"),nha.forEach(t),fRr=r(Dfe,` class
method.`),Dfe.forEach(t),gRr=i(di),ER=n(di,"P",{});var kmo=s(ER);hRr=r(kmo,"This class cannot be instantiated directly using "),a7e=n(kmo,"CODE",{});var sha=s(a7e);uRr=r(sha,"__init__()"),sha.forEach(t),pRr=r(kmo," (throws an error)."),kmo.forEach(t),_Rr=i(di),Xt=n(di,"DIV",{class:!0});var Ix=s(Xt);T(CR.$$.fragment,Ix),bRr=i(Ix),n7e=n(Ix,"P",{});var lha=s(n7e);vRr=r(lha,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),lha.forEach(t),FRr=i(Ix),Gm=n(Ix,"P",{});var jfe=s(Gm);TRr=r(jfe,`Note:
Loading a model from its configuration file does `),s7e=n(jfe,"STRONG",{});var iha=s(s7e);MRr=r(iha,"not"),iha.forEach(t),ERr=r(jfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Rre=n(jfe,"A",{href:!0});var dha=s(Rre);CRr=r(dha,"from_pretrained()"),dha.forEach(t),wRr=r(jfe," to load the model weights."),jfe.forEach(t),ARr=i(Ix),T(W3.$$.fragment,Ix),Ix.forEach(t),LRr=i(di),To=n(di,"DIV",{class:!0});var Ha=s(To);T(wR.$$.fragment,Ha),yRr=i(Ha),l7e=n(Ha,"P",{});var mha=s(l7e);xRr=r(mha,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),mha.forEach(t),$Rr=i(Ha),xn=n(Ha,"P",{});var Nx=s(xn);kRr=r(Nx,"The model class to instantiate is selected based on the "),i7e=n(Nx,"CODE",{});var cha=s(i7e);SRr=r(cha,"model_type"),cha.forEach(t),RRr=r(Nx,` property of the config object (either
passed as an argument or loaded from `),d7e=n(Nx,"CODE",{});var fha=s(d7e);PRr=r(fha,"pretrained_model_name_or_path"),fha.forEach(t),BRr=r(Nx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m7e=n(Nx,"CODE",{});var gha=s(m7e);IRr=r(gha,"pretrained_model_name_or_path"),gha.forEach(t),NRr=r(Nx,":"),Nx.forEach(t),qRr=i(Ha),Ne=n(Ha,"UL",{});var Je=s(Ne);U3=n(Je,"LI",{});var OKe=s(U3);c7e=n(OKe,"STRONG",{});var hha=s(c7e);DRr=r(hha,"data2vec-audio"),hha.forEach(t),jRr=r(OKe," \u2014 "),Pre=n(OKe,"A",{href:!0});var uha=s(Pre);GRr=r(uha,"Data2VecAudioForSequenceClassification"),uha.forEach(t),ORr=r(OKe," (Data2VecAudio model)"),OKe.forEach(t),VRr=i(Je),H3=n(Je,"LI",{});var VKe=s(H3);f7e=n(VKe,"STRONG",{});var pha=s(f7e);XRr=r(pha,"hubert"),pha.forEach(t),zRr=r(VKe," \u2014 "),Bre=n(VKe,"A",{href:!0});var _ha=s(Bre);QRr=r(_ha,"HubertForSequenceClassification"),_ha.forEach(t),WRr=r(VKe," (Hubert model)"),VKe.forEach(t),URr=i(Je),J3=n(Je,"LI",{});var XKe=s(J3);g7e=n(XKe,"STRONG",{});var bha=s(g7e);HRr=r(bha,"sew"),bha.forEach(t),JRr=r(XKe," \u2014 "),Ire=n(XKe,"A",{href:!0});var vha=s(Ire);YRr=r(vha,"SEWForSequenceClassification"),vha.forEach(t),ZRr=r(XKe," (SEW model)"),XKe.forEach(t),KRr=i(Je),Y3=n(Je,"LI",{});var zKe=s(Y3);h7e=n(zKe,"STRONG",{});var Fha=s(h7e);ePr=r(Fha,"sew-d"),Fha.forEach(t),oPr=r(zKe," \u2014 "),Nre=n(zKe,"A",{href:!0});var Tha=s(Nre);rPr=r(Tha,"SEWDForSequenceClassification"),Tha.forEach(t),tPr=r(zKe," (SEW-D model)"),zKe.forEach(t),aPr=i(Je),Z3=n(Je,"LI",{});var QKe=s(Z3);u7e=n(QKe,"STRONG",{});var Mha=s(u7e);nPr=r(Mha,"unispeech"),Mha.forEach(t),sPr=r(QKe," \u2014 "),qre=n(QKe,"A",{href:!0});var Eha=s(qre);lPr=r(Eha,"UniSpeechForSequenceClassification"),Eha.forEach(t),iPr=r(QKe," (UniSpeech model)"),QKe.forEach(t),dPr=i(Je),K3=n(Je,"LI",{});var WKe=s(K3);p7e=n(WKe,"STRONG",{});var Cha=s(p7e);mPr=r(Cha,"unispeech-sat"),Cha.forEach(t),cPr=r(WKe," \u2014 "),Dre=n(WKe,"A",{href:!0});var wha=s(Dre);fPr=r(wha,"UniSpeechSatForSequenceClassification"),wha.forEach(t),gPr=r(WKe," (UniSpeechSat model)"),WKe.forEach(t),hPr=i(Je),e5=n(Je,"LI",{});var UKe=s(e5);_7e=n(UKe,"STRONG",{});var Aha=s(_7e);uPr=r(Aha,"wav2vec2"),Aha.forEach(t),pPr=r(UKe," \u2014 "),jre=n(UKe,"A",{href:!0});var Lha=s(jre);_Pr=r(Lha,"Wav2Vec2ForSequenceClassification"),Lha.forEach(t),bPr=r(UKe," (Wav2Vec2 model)"),UKe.forEach(t),vPr=i(Je),o5=n(Je,"LI",{});var HKe=s(o5);b7e=n(HKe,"STRONG",{});var yha=s(b7e);FPr=r(yha,"wav2vec2-conformer"),yha.forEach(t),TPr=r(HKe," \u2014 "),Gre=n(HKe,"A",{href:!0});var xha=s(Gre);MPr=r(xha,"Wav2Vec2ConformerForSequenceClassification"),xha.forEach(t),EPr=r(HKe," (Wav2Vec2-Conformer model)"),HKe.forEach(t),CPr=i(Je),r5=n(Je,"LI",{});var JKe=s(r5);v7e=n(JKe,"STRONG",{});var $ha=s(v7e);wPr=r($ha,"wavlm"),$ha.forEach(t),APr=r(JKe," \u2014 "),Ore=n(JKe,"A",{href:!0});var kha=s(Ore);LPr=r(kha,"WavLMForSequenceClassification"),kha.forEach(t),yPr=r(JKe," (WavLM model)"),JKe.forEach(t),Je.forEach(t),xPr=i(Ha),t5=n(Ha,"P",{});var YKe=s(t5);$Pr=r(YKe,"The model is set in evaluation mode by default using "),F7e=n(YKe,"CODE",{});var Sha=s(F7e);kPr=r(Sha,"model.eval()"),Sha.forEach(t),SPr=r(YKe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),T7e=n(YKe,"CODE",{});var Rha=s(T7e);RPr=r(Rha,"model.train()"),Rha.forEach(t),YKe.forEach(t),PPr=i(Ha),T(a5.$$.fragment,Ha),Ha.forEach(t),di.forEach(t),dio=i(c),Om=n(c,"H2",{class:!0});var Smo=s(Om);n5=n(Smo,"A",{id:!0,class:!0,href:!0});var Pha=s(n5);M7e=n(Pha,"SPAN",{});var Bha=s(M7e);T(AR.$$.fragment,Bha),Bha.forEach(t),Pha.forEach(t),BPr=i(Smo),E7e=n(Smo,"SPAN",{});var Iha=s(E7e);IPr=r(Iha,"AutoModelForAudioFrameClassification"),Iha.forEach(t),Smo.forEach(t),mio=i(c),ar=n(c,"DIV",{class:!0});var mi=s(ar);T(LR.$$.fragment,mi),NPr=i(mi),Vm=n(mi,"P",{});var Gfe=s(Vm);qPr=r(Gfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),Vre=n(Gfe,"A",{href:!0});var Nha=s(Vre);DPr=r(Nha,"from_pretrained()"),Nha.forEach(t),jPr=r(Gfe," class method or the "),Xre=n(Gfe,"A",{href:!0});var qha=s(Xre);GPr=r(qha,"from_config()"),qha.forEach(t),OPr=r(Gfe,` class
method.`),Gfe.forEach(t),VPr=i(mi),yR=n(mi,"P",{});var Rmo=s(yR);XPr=r(Rmo,"This class cannot be instantiated directly using "),C7e=n(Rmo,"CODE",{});var Dha=s(C7e);zPr=r(Dha,"__init__()"),Dha.forEach(t),QPr=r(Rmo," (throws an error)."),Rmo.forEach(t),WPr=i(mi),zt=n(mi,"DIV",{class:!0});var qx=s(zt);T(xR.$$.fragment,qx),UPr=i(qx),w7e=n(qx,"P",{});var jha=s(w7e);HPr=r(jha,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),jha.forEach(t),JPr=i(qx),Xm=n(qx,"P",{});var Ofe=s(Xm);YPr=r(Ofe,`Note:
Loading a model from its configuration file does `),A7e=n(Ofe,"STRONG",{});var Gha=s(A7e);ZPr=r(Gha,"not"),Gha.forEach(t),KPr=r(Ofe,` load the model weights. It only affects the
model\u2019s configuration. Use `),zre=n(Ofe,"A",{href:!0});var Oha=s(zre);eBr=r(Oha,"from_pretrained()"),Oha.forEach(t),oBr=r(Ofe," to load the model weights."),Ofe.forEach(t),rBr=i(qx),T(s5.$$.fragment,qx),qx.forEach(t),tBr=i(mi),Mo=n(mi,"DIV",{class:!0});var Ja=s(Mo);T($R.$$.fragment,Ja),aBr=i(Ja),L7e=n(Ja,"P",{});var Vha=s(L7e);nBr=r(Vha,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),Vha.forEach(t),sBr=i(Ja),$n=n(Ja,"P",{});var Dx=s($n);lBr=r(Dx,"The model class to instantiate is selected based on the "),y7e=n(Dx,"CODE",{});var Xha=s(y7e);iBr=r(Xha,"model_type"),Xha.forEach(t),dBr=r(Dx,` property of the config object (either
passed as an argument or loaded from `),x7e=n(Dx,"CODE",{});var zha=s(x7e);mBr=r(zha,"pretrained_model_name_or_path"),zha.forEach(t),cBr=r(Dx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$7e=n(Dx,"CODE",{});var Qha=s($7e);fBr=r(Qha,"pretrained_model_name_or_path"),Qha.forEach(t),gBr=r(Dx,":"),Dx.forEach(t),hBr=i(Ja),vt=n(Ja,"UL",{});var ci=s(vt);l5=n(ci,"LI",{});var ZKe=s(l5);k7e=n(ZKe,"STRONG",{});var Wha=s(k7e);uBr=r(Wha,"data2vec-audio"),Wha.forEach(t),pBr=r(ZKe," \u2014 "),Qre=n(ZKe,"A",{href:!0});var Uha=s(Qre);_Br=r(Uha,"Data2VecAudioForAudioFrameClassification"),Uha.forEach(t),bBr=r(ZKe," (Data2VecAudio model)"),ZKe.forEach(t),vBr=i(ci),i5=n(ci,"LI",{});var KKe=s(i5);S7e=n(KKe,"STRONG",{});var Hha=s(S7e);FBr=r(Hha,"unispeech-sat"),Hha.forEach(t),TBr=r(KKe," \u2014 "),Wre=n(KKe,"A",{href:!0});var Jha=s(Wre);MBr=r(Jha,"UniSpeechSatForAudioFrameClassification"),Jha.forEach(t),EBr=r(KKe," (UniSpeechSat model)"),KKe.forEach(t),CBr=i(ci),d5=n(ci,"LI",{});var eeo=s(d5);R7e=n(eeo,"STRONG",{});var Yha=s(R7e);wBr=r(Yha,"wav2vec2"),Yha.forEach(t),ABr=r(eeo," \u2014 "),Ure=n(eeo,"A",{href:!0});var Zha=s(Ure);LBr=r(Zha,"Wav2Vec2ForAudioFrameClassification"),Zha.forEach(t),yBr=r(eeo," (Wav2Vec2 model)"),eeo.forEach(t),xBr=i(ci),m5=n(ci,"LI",{});var oeo=s(m5);P7e=n(oeo,"STRONG",{});var Kha=s(P7e);$Br=r(Kha,"wav2vec2-conformer"),Kha.forEach(t),kBr=r(oeo," \u2014 "),Hre=n(oeo,"A",{href:!0});var eua=s(Hre);SBr=r(eua,"Wav2Vec2ConformerForAudioFrameClassification"),eua.forEach(t),RBr=r(oeo," (Wav2Vec2-Conformer model)"),oeo.forEach(t),PBr=i(ci),c5=n(ci,"LI",{});var reo=s(c5);B7e=n(reo,"STRONG",{});var oua=s(B7e);BBr=r(oua,"wavlm"),oua.forEach(t),IBr=r(reo," \u2014 "),Jre=n(reo,"A",{href:!0});var rua=s(Jre);NBr=r(rua,"WavLMForAudioFrameClassification"),rua.forEach(t),qBr=r(reo," (WavLM model)"),reo.forEach(t),ci.forEach(t),DBr=i(Ja),f5=n(Ja,"P",{});var teo=s(f5);jBr=r(teo,"The model is set in evaluation mode by default using "),I7e=n(teo,"CODE",{});var tua=s(I7e);GBr=r(tua,"model.eval()"),tua.forEach(t),OBr=r(teo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),N7e=n(teo,"CODE",{});var aua=s(N7e);VBr=r(aua,"model.train()"),aua.forEach(t),teo.forEach(t),XBr=i(Ja),T(g5.$$.fragment,Ja),Ja.forEach(t),mi.forEach(t),cio=i(c),zm=n(c,"H2",{class:!0});var Pmo=s(zm);h5=n(Pmo,"A",{id:!0,class:!0,href:!0});var nua=s(h5);q7e=n(nua,"SPAN",{});var sua=s(q7e);T(kR.$$.fragment,sua),sua.forEach(t),nua.forEach(t),zBr=i(Pmo),D7e=n(Pmo,"SPAN",{});var lua=s(D7e);QBr=r(lua,"AutoModelForCTC"),lua.forEach(t),Pmo.forEach(t),fio=i(c),nr=n(c,"DIV",{class:!0});var fi=s(nr);T(SR.$$.fragment,fi),WBr=i(fi),Qm=n(fi,"P",{});var Vfe=s(Qm);UBr=r(Vfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),Yre=n(Vfe,"A",{href:!0});var iua=s(Yre);HBr=r(iua,"from_pretrained()"),iua.forEach(t),JBr=r(Vfe," class method or the "),Zre=n(Vfe,"A",{href:!0});var dua=s(Zre);YBr=r(dua,"from_config()"),dua.forEach(t),ZBr=r(Vfe,` class
method.`),Vfe.forEach(t),KBr=i(fi),RR=n(fi,"P",{});var Bmo=s(RR);eIr=r(Bmo,"This class cannot be instantiated directly using "),j7e=n(Bmo,"CODE",{});var mua=s(j7e);oIr=r(mua,"__init__()"),mua.forEach(t),rIr=r(Bmo," (throws an error)."),Bmo.forEach(t),tIr=i(fi),Qt=n(fi,"DIV",{class:!0});var jx=s(Qt);T(PR.$$.fragment,jx),aIr=i(jx),G7e=n(jx,"P",{});var cua=s(G7e);nIr=r(cua,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),cua.forEach(t),sIr=i(jx),Wm=n(jx,"P",{});var Xfe=s(Wm);lIr=r(Xfe,`Note:
Loading a model from its configuration file does `),O7e=n(Xfe,"STRONG",{});var fua=s(O7e);iIr=r(fua,"not"),fua.forEach(t),dIr=r(Xfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Kre=n(Xfe,"A",{href:!0});var gua=s(Kre);mIr=r(gua,"from_pretrained()"),gua.forEach(t),cIr=r(Xfe," to load the model weights."),Xfe.forEach(t),fIr=i(jx),T(u5.$$.fragment,jx),jx.forEach(t),gIr=i(fi),Eo=n(fi,"DIV",{class:!0});var Ya=s(Eo);T(BR.$$.fragment,Ya),hIr=i(Ya),V7e=n(Ya,"P",{});var hua=s(V7e);uIr=r(hua,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),hua.forEach(t),pIr=i(Ya),kn=n(Ya,"P",{});var Gx=s(kn);_Ir=r(Gx,"The model class to instantiate is selected based on the "),X7e=n(Gx,"CODE",{});var uua=s(X7e);bIr=r(uua,"model_type"),uua.forEach(t),vIr=r(Gx,` property of the config object (either
passed as an argument or loaded from `),z7e=n(Gx,"CODE",{});var pua=s(z7e);FIr=r(pua,"pretrained_model_name_or_path"),pua.forEach(t),TIr=r(Gx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q7e=n(Gx,"CODE",{});var _ua=s(Q7e);MIr=r(_ua,"pretrained_model_name_or_path"),_ua.forEach(t),EIr=r(Gx,":"),Gx.forEach(t),CIr=i(Ya),xe=n(Ya,"UL",{});var qe=s(xe);p5=n(qe,"LI",{});var aeo=s(p5);W7e=n(aeo,"STRONG",{});var bua=s(W7e);wIr=r(bua,"data2vec-audio"),bua.forEach(t),AIr=r(aeo," \u2014 "),ete=n(aeo,"A",{href:!0});var vua=s(ete);LIr=r(vua,"Data2VecAudioForCTC"),vua.forEach(t),yIr=r(aeo," (Data2VecAudio model)"),aeo.forEach(t),xIr=i(qe),_5=n(qe,"LI",{});var neo=s(_5);U7e=n(neo,"STRONG",{});var Fua=s(U7e);$Ir=r(Fua,"hubert"),Fua.forEach(t),kIr=r(neo," \u2014 "),ote=n(neo,"A",{href:!0});var Tua=s(ote);SIr=r(Tua,"HubertForCTC"),Tua.forEach(t),RIr=r(neo," (Hubert model)"),neo.forEach(t),PIr=i(qe),b5=n(qe,"LI",{});var seo=s(b5);H7e=n(seo,"STRONG",{});var Mua=s(H7e);BIr=r(Mua,"mctct"),Mua.forEach(t),IIr=r(seo," \u2014 "),rte=n(seo,"A",{href:!0});var Eua=s(rte);NIr=r(Eua,"MCTCTForCTC"),Eua.forEach(t),qIr=r(seo," (M-CTC-T model)"),seo.forEach(t),DIr=i(qe),v5=n(qe,"LI",{});var leo=s(v5);J7e=n(leo,"STRONG",{});var Cua=s(J7e);jIr=r(Cua,"sew"),Cua.forEach(t),GIr=r(leo," \u2014 "),tte=n(leo,"A",{href:!0});var wua=s(tte);OIr=r(wua,"SEWForCTC"),wua.forEach(t),VIr=r(leo," (SEW model)"),leo.forEach(t),XIr=i(qe),F5=n(qe,"LI",{});var ieo=s(F5);Y7e=n(ieo,"STRONG",{});var Aua=s(Y7e);zIr=r(Aua,"sew-d"),Aua.forEach(t),QIr=r(ieo," \u2014 "),ate=n(ieo,"A",{href:!0});var Lua=s(ate);WIr=r(Lua,"SEWDForCTC"),Lua.forEach(t),UIr=r(ieo," (SEW-D model)"),ieo.forEach(t),HIr=i(qe),T5=n(qe,"LI",{});var deo=s(T5);Z7e=n(deo,"STRONG",{});var yua=s(Z7e);JIr=r(yua,"unispeech"),yua.forEach(t),YIr=r(deo," \u2014 "),nte=n(deo,"A",{href:!0});var xua=s(nte);ZIr=r(xua,"UniSpeechForCTC"),xua.forEach(t),KIr=r(deo," (UniSpeech model)"),deo.forEach(t),eNr=i(qe),M5=n(qe,"LI",{});var meo=s(M5);K7e=n(meo,"STRONG",{});var $ua=s(K7e);oNr=r($ua,"unispeech-sat"),$ua.forEach(t),rNr=r(meo," \u2014 "),ste=n(meo,"A",{href:!0});var kua=s(ste);tNr=r(kua,"UniSpeechSatForCTC"),kua.forEach(t),aNr=r(meo," (UniSpeechSat model)"),meo.forEach(t),nNr=i(qe),E5=n(qe,"LI",{});var ceo=s(E5);e8e=n(ceo,"STRONG",{});var Sua=s(e8e);sNr=r(Sua,"wav2vec2"),Sua.forEach(t),lNr=r(ceo," \u2014 "),lte=n(ceo,"A",{href:!0});var Rua=s(lte);iNr=r(Rua,"Wav2Vec2ForCTC"),Rua.forEach(t),dNr=r(ceo," (Wav2Vec2 model)"),ceo.forEach(t),mNr=i(qe),C5=n(qe,"LI",{});var feo=s(C5);o8e=n(feo,"STRONG",{});var Pua=s(o8e);cNr=r(Pua,"wav2vec2-conformer"),Pua.forEach(t),fNr=r(feo," \u2014 "),ite=n(feo,"A",{href:!0});var Bua=s(ite);gNr=r(Bua,"Wav2Vec2ConformerForCTC"),Bua.forEach(t),hNr=r(feo," (Wav2Vec2-Conformer model)"),feo.forEach(t),uNr=i(qe),w5=n(qe,"LI",{});var geo=s(w5);r8e=n(geo,"STRONG",{});var Iua=s(r8e);pNr=r(Iua,"wavlm"),Iua.forEach(t),_Nr=r(geo," \u2014 "),dte=n(geo,"A",{href:!0});var Nua=s(dte);bNr=r(Nua,"WavLMForCTC"),Nua.forEach(t),vNr=r(geo," (WavLM model)"),geo.forEach(t),qe.forEach(t),FNr=i(Ya),A5=n(Ya,"P",{});var heo=s(A5);TNr=r(heo,"The model is set in evaluation mode by default using "),t8e=n(heo,"CODE",{});var qua=s(t8e);MNr=r(qua,"model.eval()"),qua.forEach(t),ENr=r(heo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),a8e=n(heo,"CODE",{});var Dua=s(a8e);CNr=r(Dua,"model.train()"),Dua.forEach(t),heo.forEach(t),wNr=i(Ya),T(L5.$$.fragment,Ya),Ya.forEach(t),fi.forEach(t),gio=i(c),Um=n(c,"H2",{class:!0});var Imo=s(Um);y5=n(Imo,"A",{id:!0,class:!0,href:!0});var jua=s(y5);n8e=n(jua,"SPAN",{});var Gua=s(n8e);T(IR.$$.fragment,Gua),Gua.forEach(t),jua.forEach(t),ANr=i(Imo),s8e=n(Imo,"SPAN",{});var Oua=s(s8e);LNr=r(Oua,"AutoModelForSpeechSeq2Seq"),Oua.forEach(t),Imo.forEach(t),hio=i(c),sr=n(c,"DIV",{class:!0});var gi=s(sr);T(NR.$$.fragment,gi),yNr=i(gi),Hm=n(gi,"P",{});var zfe=s(Hm);xNr=r(zfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),mte=n(zfe,"A",{href:!0});var Vua=s(mte);$Nr=r(Vua,"from_pretrained()"),Vua.forEach(t),kNr=r(zfe," class method or the "),cte=n(zfe,"A",{href:!0});var Xua=s(cte);SNr=r(Xua,"from_config()"),Xua.forEach(t),RNr=r(zfe,` class
method.`),zfe.forEach(t),PNr=i(gi),qR=n(gi,"P",{});var Nmo=s(qR);BNr=r(Nmo,"This class cannot be instantiated directly using "),l8e=n(Nmo,"CODE",{});var zua=s(l8e);INr=r(zua,"__init__()"),zua.forEach(t),NNr=r(Nmo," (throws an error)."),Nmo.forEach(t),qNr=i(gi),Wt=n(gi,"DIV",{class:!0});var Ox=s(Wt);T(DR.$$.fragment,Ox),DNr=i(Ox),i8e=n(Ox,"P",{});var Qua=s(i8e);jNr=r(Qua,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Qua.forEach(t),GNr=i(Ox),Jm=n(Ox,"P",{});var Qfe=s(Jm);ONr=r(Qfe,`Note:
Loading a model from its configuration file does `),d8e=n(Qfe,"STRONG",{});var Wua=s(d8e);VNr=r(Wua,"not"),Wua.forEach(t),XNr=r(Qfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),fte=n(Qfe,"A",{href:!0});var Uua=s(fte);zNr=r(Uua,"from_pretrained()"),Uua.forEach(t),QNr=r(Qfe," to load the model weights."),Qfe.forEach(t),WNr=i(Ox),T(x5.$$.fragment,Ox),Ox.forEach(t),UNr=i(gi),Co=n(gi,"DIV",{class:!0});var Za=s(Co);T(jR.$$.fragment,Za),HNr=i(Za),m8e=n(Za,"P",{});var Hua=s(m8e);JNr=r(Hua,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Hua.forEach(t),YNr=i(Za),Sn=n(Za,"P",{});var Vx=s(Sn);ZNr=r(Vx,"The model class to instantiate is selected based on the "),c8e=n(Vx,"CODE",{});var Jua=s(c8e);KNr=r(Jua,"model_type"),Jua.forEach(t),eqr=r(Vx,` property of the config object (either
passed as an argument or loaded from `),f8e=n(Vx,"CODE",{});var Yua=s(f8e);oqr=r(Yua,"pretrained_model_name_or_path"),Yua.forEach(t),rqr=r(Vx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g8e=n(Vx,"CODE",{});var Zua=s(g8e);tqr=r(Zua,"pretrained_model_name_or_path"),Zua.forEach(t),aqr=r(Vx,":"),Vx.forEach(t),nqr=i(Za),Ym=n(Za,"UL",{});var Wfe=s(Ym);$5=n(Wfe,"LI",{});var ueo=s($5);h8e=n(ueo,"STRONG",{});var Kua=s(h8e);sqr=r(Kua,"speech-encoder-decoder"),Kua.forEach(t),lqr=r(ueo," \u2014 "),gte=n(ueo,"A",{href:!0});var epa=s(gte);iqr=r(epa,"SpeechEncoderDecoderModel"),epa.forEach(t),dqr=r(ueo," (Speech Encoder decoder model)"),ueo.forEach(t),mqr=i(Wfe),k5=n(Wfe,"LI",{});var peo=s(k5);u8e=n(peo,"STRONG",{});var opa=s(u8e);cqr=r(opa,"speech_to_text"),opa.forEach(t),fqr=r(peo," \u2014 "),hte=n(peo,"A",{href:!0});var rpa=s(hte);gqr=r(rpa,"Speech2TextForConditionalGeneration"),rpa.forEach(t),hqr=r(peo," (Speech2Text model)"),peo.forEach(t),uqr=i(Wfe),S5=n(Wfe,"LI",{});var _eo=s(S5);p8e=n(_eo,"STRONG",{});var tpa=s(p8e);pqr=r(tpa,"whisper"),tpa.forEach(t),_qr=r(_eo," \u2014 "),ute=n(_eo,"A",{href:!0});var apa=s(ute);bqr=r(apa,"WhisperForConditionalGeneration"),apa.forEach(t),vqr=r(_eo," (Whisper model)"),_eo.forEach(t),Wfe.forEach(t),Fqr=i(Za),R5=n(Za,"P",{});var beo=s(R5);Tqr=r(beo,"The model is set in evaluation mode by default using "),_8e=n(beo,"CODE",{});var npa=s(_8e);Mqr=r(npa,"model.eval()"),npa.forEach(t),Eqr=r(beo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b8e=n(beo,"CODE",{});var spa=s(b8e);Cqr=r(spa,"model.train()"),spa.forEach(t),beo.forEach(t),wqr=i(Za),T(P5.$$.fragment,Za),Za.forEach(t),gi.forEach(t),uio=i(c),Zm=n(c,"H2",{class:!0});var qmo=s(Zm);B5=n(qmo,"A",{id:!0,class:!0,href:!0});var lpa=s(B5);v8e=n(lpa,"SPAN",{});var ipa=s(v8e);T(GR.$$.fragment,ipa),ipa.forEach(t),lpa.forEach(t),Aqr=i(qmo),F8e=n(qmo,"SPAN",{});var dpa=s(F8e);Lqr=r(dpa,"AutoModelForAudioXVector"),dpa.forEach(t),qmo.forEach(t),pio=i(c),lr=n(c,"DIV",{class:!0});var hi=s(lr);T(OR.$$.fragment,hi),yqr=i(hi),Km=n(hi,"P",{});var Ufe=s(Km);xqr=r(Ufe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),pte=n(Ufe,"A",{href:!0});var mpa=s(pte);$qr=r(mpa,"from_pretrained()"),mpa.forEach(t),kqr=r(Ufe," class method or the "),_te=n(Ufe,"A",{href:!0});var cpa=s(_te);Sqr=r(cpa,"from_config()"),cpa.forEach(t),Rqr=r(Ufe,` class
method.`),Ufe.forEach(t),Pqr=i(hi),VR=n(hi,"P",{});var Dmo=s(VR);Bqr=r(Dmo,"This class cannot be instantiated directly using "),T8e=n(Dmo,"CODE",{});var fpa=s(T8e);Iqr=r(fpa,"__init__()"),fpa.forEach(t),Nqr=r(Dmo," (throws an error)."),Dmo.forEach(t),qqr=i(hi),Ut=n(hi,"DIV",{class:!0});var Xx=s(Ut);T(XR.$$.fragment,Xx),Dqr=i(Xx),M8e=n(Xx,"P",{});var gpa=s(M8e);jqr=r(gpa,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),gpa.forEach(t),Gqr=i(Xx),ec=n(Xx,"P",{});var Hfe=s(ec);Oqr=r(Hfe,`Note:
Loading a model from its configuration file does `),E8e=n(Hfe,"STRONG",{});var hpa=s(E8e);Vqr=r(hpa,"not"),hpa.forEach(t),Xqr=r(Hfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),bte=n(Hfe,"A",{href:!0});var upa=s(bte);zqr=r(upa,"from_pretrained()"),upa.forEach(t),Qqr=r(Hfe," to load the model weights."),Hfe.forEach(t),Wqr=i(Xx),T(I5.$$.fragment,Xx),Xx.forEach(t),Uqr=i(hi),wo=n(hi,"DIV",{class:!0});var Ka=s(wo);T(zR.$$.fragment,Ka),Hqr=i(Ka),C8e=n(Ka,"P",{});var ppa=s(C8e);Jqr=r(ppa,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),ppa.forEach(t),Yqr=i(Ka),Rn=n(Ka,"P",{});var zx=s(Rn);Zqr=r(zx,"The model class to instantiate is selected based on the "),w8e=n(zx,"CODE",{});var _pa=s(w8e);Kqr=r(_pa,"model_type"),_pa.forEach(t),eDr=r(zx,` property of the config object (either
passed as an argument or loaded from `),A8e=n(zx,"CODE",{});var bpa=s(A8e);oDr=r(bpa,"pretrained_model_name_or_path"),bpa.forEach(t),rDr=r(zx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L8e=n(zx,"CODE",{});var vpa=s(L8e);tDr=r(vpa,"pretrained_model_name_or_path"),vpa.forEach(t),aDr=r(zx,":"),zx.forEach(t),nDr=i(Ka),Ft=n(Ka,"UL",{});var ui=s(Ft);N5=n(ui,"LI",{});var veo=s(N5);y8e=n(veo,"STRONG",{});var Fpa=s(y8e);sDr=r(Fpa,"data2vec-audio"),Fpa.forEach(t),lDr=r(veo," \u2014 "),vte=n(veo,"A",{href:!0});var Tpa=s(vte);iDr=r(Tpa,"Data2VecAudioForXVector"),Tpa.forEach(t),dDr=r(veo," (Data2VecAudio model)"),veo.forEach(t),mDr=i(ui),q5=n(ui,"LI",{});var Feo=s(q5);x8e=n(Feo,"STRONG",{});var Mpa=s(x8e);cDr=r(Mpa,"unispeech-sat"),Mpa.forEach(t),fDr=r(Feo," \u2014 "),Fte=n(Feo,"A",{href:!0});var Epa=s(Fte);gDr=r(Epa,"UniSpeechSatForXVector"),Epa.forEach(t),hDr=r(Feo," (UniSpeechSat model)"),Feo.forEach(t),uDr=i(ui),D5=n(ui,"LI",{});var Teo=s(D5);$8e=n(Teo,"STRONG",{});var Cpa=s($8e);pDr=r(Cpa,"wav2vec2"),Cpa.forEach(t),_Dr=r(Teo," \u2014 "),Tte=n(Teo,"A",{href:!0});var wpa=s(Tte);bDr=r(wpa,"Wav2Vec2ForXVector"),wpa.forEach(t),vDr=r(Teo," (Wav2Vec2 model)"),Teo.forEach(t),FDr=i(ui),j5=n(ui,"LI",{});var Meo=s(j5);k8e=n(Meo,"STRONG",{});var Apa=s(k8e);TDr=r(Apa,"wav2vec2-conformer"),Apa.forEach(t),MDr=r(Meo," \u2014 "),Mte=n(Meo,"A",{href:!0});var Lpa=s(Mte);EDr=r(Lpa,"Wav2Vec2ConformerForXVector"),Lpa.forEach(t),CDr=r(Meo," (Wav2Vec2-Conformer model)"),Meo.forEach(t),wDr=i(ui),G5=n(ui,"LI",{});var Eeo=s(G5);S8e=n(Eeo,"STRONG",{});var ypa=s(S8e);ADr=r(ypa,"wavlm"),ypa.forEach(t),LDr=r(Eeo," \u2014 "),Ete=n(Eeo,"A",{href:!0});var xpa=s(Ete);yDr=r(xpa,"WavLMForXVector"),xpa.forEach(t),xDr=r(Eeo," (WavLM model)"),Eeo.forEach(t),ui.forEach(t),$Dr=i(Ka),O5=n(Ka,"P",{});var Ceo=s(O5);kDr=r(Ceo,"The model is set in evaluation mode by default using "),R8e=n(Ceo,"CODE",{});var $pa=s(R8e);SDr=r($pa,"model.eval()"),$pa.forEach(t),RDr=r(Ceo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P8e=n(Ceo,"CODE",{});var kpa=s(P8e);PDr=r(kpa,"model.train()"),kpa.forEach(t),Ceo.forEach(t),BDr=i(Ka),T(V5.$$.fragment,Ka),Ka.forEach(t),hi.forEach(t),_io=i(c),oc=n(c,"H2",{class:!0});var jmo=s(oc);X5=n(jmo,"A",{id:!0,class:!0,href:!0});var Spa=s(X5);B8e=n(Spa,"SPAN",{});var Rpa=s(B8e);T(QR.$$.fragment,Rpa),Rpa.forEach(t),Spa.forEach(t),IDr=i(jmo),I8e=n(jmo,"SPAN",{});var Ppa=s(I8e);NDr=r(Ppa,"AutoModelForMaskedImageModeling"),Ppa.forEach(t),jmo.forEach(t),bio=i(c),ir=n(c,"DIV",{class:!0});var pi=s(ir);T(WR.$$.fragment,pi),qDr=i(pi),rc=n(pi,"P",{});var Jfe=s(rc);DDr=r(Jfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),Cte=n(Jfe,"A",{href:!0});var Bpa=s(Cte);jDr=r(Bpa,"from_pretrained()"),Bpa.forEach(t),GDr=r(Jfe," class method or the "),wte=n(Jfe,"A",{href:!0});var Ipa=s(wte);ODr=r(Ipa,"from_config()"),Ipa.forEach(t),VDr=r(Jfe,` class
method.`),Jfe.forEach(t),XDr=i(pi),UR=n(pi,"P",{});var Gmo=s(UR);zDr=r(Gmo,"This class cannot be instantiated directly using "),N8e=n(Gmo,"CODE",{});var Npa=s(N8e);QDr=r(Npa,"__init__()"),Npa.forEach(t),WDr=r(Gmo," (throws an error)."),Gmo.forEach(t),UDr=i(pi),Ht=n(pi,"DIV",{class:!0});var Qx=s(Ht);T(HR.$$.fragment,Qx),HDr=i(Qx),q8e=n(Qx,"P",{});var qpa=s(q8e);JDr=r(qpa,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),qpa.forEach(t),YDr=i(Qx),tc=n(Qx,"P",{});var Yfe=s(tc);ZDr=r(Yfe,`Note:
Loading a model from its configuration file does `),D8e=n(Yfe,"STRONG",{});var Dpa=s(D8e);KDr=r(Dpa,"not"),Dpa.forEach(t),ejr=r(Yfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ate=n(Yfe,"A",{href:!0});var jpa=s(Ate);ojr=r(jpa,"from_pretrained()"),jpa.forEach(t),rjr=r(Yfe," to load the model weights."),Yfe.forEach(t),tjr=i(Qx),T(z5.$$.fragment,Qx),Qx.forEach(t),ajr=i(pi),Ao=n(pi,"DIV",{class:!0});var en=s(Ao);T(JR.$$.fragment,en),njr=i(en),j8e=n(en,"P",{});var Gpa=s(j8e);sjr=r(Gpa,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),Gpa.forEach(t),ljr=i(en),Pn=n(en,"P",{});var Wx=s(Pn);ijr=r(Wx,"The model class to instantiate is selected based on the "),G8e=n(Wx,"CODE",{});var Opa=s(G8e);djr=r(Opa,"model_type"),Opa.forEach(t),mjr=r(Wx,` property of the config object (either
passed as an argument or loaded from `),O8e=n(Wx,"CODE",{});var Vpa=s(O8e);cjr=r(Vpa,"pretrained_model_name_or_path"),Vpa.forEach(t),fjr=r(Wx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V8e=n(Wx,"CODE",{});var Xpa=s(V8e);gjr=r(Xpa,"pretrained_model_name_or_path"),Xpa.forEach(t),hjr=r(Wx,":"),Wx.forEach(t),ujr=i(en),Bn=n(en,"UL",{});var Ux=s(Bn);Q5=n(Ux,"LI",{});var weo=s(Q5);X8e=n(weo,"STRONG",{});var zpa=s(X8e);pjr=r(zpa,"deit"),zpa.forEach(t),_jr=r(weo," \u2014 "),Lte=n(weo,"A",{href:!0});var Qpa=s(Lte);bjr=r(Qpa,"DeiTForMaskedImageModeling"),Qpa.forEach(t),vjr=r(weo," (DeiT model)"),weo.forEach(t),Fjr=i(Ux),W5=n(Ux,"LI",{});var Aeo=s(W5);z8e=n(Aeo,"STRONG",{});var Wpa=s(z8e);Tjr=r(Wpa,"swin"),Wpa.forEach(t),Mjr=r(Aeo," \u2014 "),yte=n(Aeo,"A",{href:!0});var Upa=s(yte);Ejr=r(Upa,"SwinForMaskedImageModeling"),Upa.forEach(t),Cjr=r(Aeo," (Swin Transformer model)"),Aeo.forEach(t),wjr=i(Ux),U5=n(Ux,"LI",{});var Leo=s(U5);Q8e=n(Leo,"STRONG",{});var Hpa=s(Q8e);Ajr=r(Hpa,"swinv2"),Hpa.forEach(t),Ljr=r(Leo," \u2014 "),xte=n(Leo,"A",{href:!0});var Jpa=s(xte);yjr=r(Jpa,"Swinv2ForMaskedImageModeling"),Jpa.forEach(t),xjr=r(Leo," (Swin Transformer V2 model)"),Leo.forEach(t),$jr=i(Ux),H5=n(Ux,"LI",{});var yeo=s(H5);W8e=n(yeo,"STRONG",{});var Ypa=s(W8e);kjr=r(Ypa,"vit"),Ypa.forEach(t),Sjr=r(yeo," \u2014 "),$te=n(yeo,"A",{href:!0});var Zpa=s($te);Rjr=r(Zpa,"ViTForMaskedImageModeling"),Zpa.forEach(t),Pjr=r(yeo," (ViT model)"),yeo.forEach(t),Ux.forEach(t),Bjr=i(en),J5=n(en,"P",{});var xeo=s(J5);Ijr=r(xeo,"The model is set in evaluation mode by default using "),U8e=n(xeo,"CODE",{});var Kpa=s(U8e);Njr=r(Kpa,"model.eval()"),Kpa.forEach(t),qjr=r(xeo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),H8e=n(xeo,"CODE",{});var e_a=s(H8e);Djr=r(e_a,"model.train()"),e_a.forEach(t),xeo.forEach(t),jjr=i(en),T(Y5.$$.fragment,en),en.forEach(t),pi.forEach(t),vio=i(c),ac=n(c,"H2",{class:!0});var Omo=s(ac);Z5=n(Omo,"A",{id:!0,class:!0,href:!0});var o_a=s(Z5);J8e=n(o_a,"SPAN",{});var r_a=s(J8e);T(YR.$$.fragment,r_a),r_a.forEach(t),o_a.forEach(t),Gjr=i(Omo),Y8e=n(Omo,"SPAN",{});var t_a=s(Y8e);Ojr=r(t_a,"AutoModelForObjectDetection"),t_a.forEach(t),Omo.forEach(t),Fio=i(c),dr=n(c,"DIV",{class:!0});var _i=s(dr);T(ZR.$$.fragment,_i),Vjr=i(_i),nc=n(_i,"P",{});var Zfe=s(nc);Xjr=r(Zfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),kte=n(Zfe,"A",{href:!0});var a_a=s(kte);zjr=r(a_a,"from_pretrained()"),a_a.forEach(t),Qjr=r(Zfe," class method or the "),Ste=n(Zfe,"A",{href:!0});var n_a=s(Ste);Wjr=r(n_a,"from_config()"),n_a.forEach(t),Ujr=r(Zfe,` class
method.`),Zfe.forEach(t),Hjr=i(_i),KR=n(_i,"P",{});var Vmo=s(KR);Jjr=r(Vmo,"This class cannot be instantiated directly using "),Z8e=n(Vmo,"CODE",{});var s_a=s(Z8e);Yjr=r(s_a,"__init__()"),s_a.forEach(t),Zjr=r(Vmo," (throws an error)."),Vmo.forEach(t),Kjr=i(_i),Jt=n(_i,"DIV",{class:!0});var Hx=s(Jt);T(eP.$$.fragment,Hx),eGr=i(Hx),K8e=n(Hx,"P",{});var l_a=s(K8e);oGr=r(l_a,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),l_a.forEach(t),rGr=i(Hx),sc=n(Hx,"P",{});var Kfe=s(sc);tGr=r(Kfe,`Note:
Loading a model from its configuration file does `),eLe=n(Kfe,"STRONG",{});var i_a=s(eLe);aGr=r(i_a,"not"),i_a.forEach(t),nGr=r(Kfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Rte=n(Kfe,"A",{href:!0});var d_a=s(Rte);sGr=r(d_a,"from_pretrained()"),d_a.forEach(t),lGr=r(Kfe," to load the model weights."),Kfe.forEach(t),iGr=i(Hx),T(K5.$$.fragment,Hx),Hx.forEach(t),dGr=i(_i),Lo=n(_i,"DIV",{class:!0});var on=s(Lo);T(oP.$$.fragment,on),mGr=i(on),oLe=n(on,"P",{});var m_a=s(oLe);cGr=r(m_a,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),m_a.forEach(t),fGr=i(on),In=n(on,"P",{});var Jx=s(In);gGr=r(Jx,"The model class to instantiate is selected based on the "),rLe=n(Jx,"CODE",{});var c_a=s(rLe);hGr=r(c_a,"model_type"),c_a.forEach(t),uGr=r(Jx,` property of the config object (either
passed as an argument or loaded from `),tLe=n(Jx,"CODE",{});var f_a=s(tLe);pGr=r(f_a,"pretrained_model_name_or_path"),f_a.forEach(t),_Gr=r(Jx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),aLe=n(Jx,"CODE",{});var g_a=s(aLe);bGr=r(g_a,"pretrained_model_name_or_path"),g_a.forEach(t),vGr=r(Jx,":"),Jx.forEach(t),FGr=i(on),Tt=n(on,"UL",{});var bi=s(Tt);e0=n(bi,"LI",{});var $eo=s(e0);nLe=n($eo,"STRONG",{});var h_a=s(nLe);TGr=r(h_a,"conditional_detr"),h_a.forEach(t),MGr=r($eo," \u2014 "),Pte=n($eo,"A",{href:!0});var u_a=s(Pte);EGr=r(u_a,"ConditionalDetrForObjectDetection"),u_a.forEach(t),CGr=r($eo," (Conditional DETR model)"),$eo.forEach(t),wGr=i(bi),o0=n(bi,"LI",{});var keo=s(o0);sLe=n(keo,"STRONG",{});var p_a=s(sLe);AGr=r(p_a,"deformable_detr"),p_a.forEach(t),LGr=r(keo," \u2014 "),Bte=n(keo,"A",{href:!0});var __a=s(Bte);yGr=r(__a,"DeformableDetrForObjectDetection"),__a.forEach(t),xGr=r(keo," (Deformable DETR model)"),keo.forEach(t),$Gr=i(bi),r0=n(bi,"LI",{});var Seo=s(r0);lLe=n(Seo,"STRONG",{});var b_a=s(lLe);kGr=r(b_a,"detr"),b_a.forEach(t),SGr=r(Seo," \u2014 "),Ite=n(Seo,"A",{href:!0});var v_a=s(Ite);RGr=r(v_a,"DetrForObjectDetection"),v_a.forEach(t),PGr=r(Seo," (DETR model)"),Seo.forEach(t),BGr=i(bi),t0=n(bi,"LI",{});var Reo=s(t0);iLe=n(Reo,"STRONG",{});var F_a=s(iLe);IGr=r(F_a,"table-transformer"),F_a.forEach(t),NGr=r(Reo," \u2014 "),Nte=n(Reo,"A",{href:!0});var T_a=s(Nte);qGr=r(T_a,"TableTransformerForObjectDetection"),T_a.forEach(t),DGr=r(Reo," (Table Transformer model)"),Reo.forEach(t),jGr=i(bi),a0=n(bi,"LI",{});var Peo=s(a0);dLe=n(Peo,"STRONG",{});var M_a=s(dLe);GGr=r(M_a,"yolos"),M_a.forEach(t),OGr=r(Peo," \u2014 "),qte=n(Peo,"A",{href:!0});var E_a=s(qte);VGr=r(E_a,"YolosForObjectDetection"),E_a.forEach(t),XGr=r(Peo," (YOLOS model)"),Peo.forEach(t),bi.forEach(t),zGr=i(on),n0=n(on,"P",{});var Beo=s(n0);QGr=r(Beo,"The model is set in evaluation mode by default using "),mLe=n(Beo,"CODE",{});var C_a=s(mLe);WGr=r(C_a,"model.eval()"),C_a.forEach(t),UGr=r(Beo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cLe=n(Beo,"CODE",{});var w_a=s(cLe);HGr=r(w_a,"model.train()"),w_a.forEach(t),Beo.forEach(t),JGr=i(on),T(s0.$$.fragment,on),on.forEach(t),_i.forEach(t),Tio=i(c),lc=n(c,"H2",{class:!0});var Xmo=s(lc);l0=n(Xmo,"A",{id:!0,class:!0,href:!0});var A_a=s(l0);fLe=n(A_a,"SPAN",{});var L_a=s(fLe);T(rP.$$.fragment,L_a),L_a.forEach(t),A_a.forEach(t),YGr=i(Xmo),gLe=n(Xmo,"SPAN",{});var y_a=s(gLe);ZGr=r(y_a,"AutoModelForImageSegmentation"),y_a.forEach(t),Xmo.forEach(t),Mio=i(c),mr=n(c,"DIV",{class:!0});var vi=s(mr);T(tP.$$.fragment,vi),KGr=i(vi),ic=n(vi,"P",{});var ege=s(ic);eOr=r(ege,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),Dte=n(ege,"A",{href:!0});var x_a=s(Dte);oOr=r(x_a,"from_pretrained()"),x_a.forEach(t),rOr=r(ege," class method or the "),jte=n(ege,"A",{href:!0});var $_a=s(jte);tOr=r($_a,"from_config()"),$_a.forEach(t),aOr=r(ege,` class
method.`),ege.forEach(t),nOr=i(vi),aP=n(vi,"P",{});var zmo=s(aP);sOr=r(zmo,"This class cannot be instantiated directly using "),hLe=n(zmo,"CODE",{});var k_a=s(hLe);lOr=r(k_a,"__init__()"),k_a.forEach(t),iOr=r(zmo," (throws an error)."),zmo.forEach(t),dOr=i(vi),Yt=n(vi,"DIV",{class:!0});var Yx=s(Yt);T(nP.$$.fragment,Yx),mOr=i(Yx),uLe=n(Yx,"P",{});var S_a=s(uLe);cOr=r(S_a,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),S_a.forEach(t),fOr=i(Yx),dc=n(Yx,"P",{});var oge=s(dc);gOr=r(oge,`Note:
Loading a model from its configuration file does `),pLe=n(oge,"STRONG",{});var R_a=s(pLe);hOr=r(R_a,"not"),R_a.forEach(t),uOr=r(oge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Gte=n(oge,"A",{href:!0});var P_a=s(Gte);pOr=r(P_a,"from_pretrained()"),P_a.forEach(t),_Or=r(oge," to load the model weights."),oge.forEach(t),bOr=i(Yx),T(i0.$$.fragment,Yx),Yx.forEach(t),vOr=i(vi),yo=n(vi,"DIV",{class:!0});var rn=s(yo);T(sP.$$.fragment,rn),FOr=i(rn),_Le=n(rn,"P",{});var B_a=s(_Le);TOr=r(B_a,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),B_a.forEach(t),MOr=i(rn),Nn=n(rn,"P",{});var Zx=s(Nn);EOr=r(Zx,"The model class to instantiate is selected based on the "),bLe=n(Zx,"CODE",{});var I_a=s(bLe);COr=r(I_a,"model_type"),I_a.forEach(t),wOr=r(Zx,` property of the config object (either
passed as an argument or loaded from `),vLe=n(Zx,"CODE",{});var N_a=s(vLe);AOr=r(N_a,"pretrained_model_name_or_path"),N_a.forEach(t),LOr=r(Zx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FLe=n(Zx,"CODE",{});var q_a=s(FLe);yOr=r(q_a,"pretrained_model_name_or_path"),q_a.forEach(t),xOr=r(Zx,":"),Zx.forEach(t),$Or=i(rn),TLe=n(rn,"UL",{});var D_a=s(TLe);d0=n(D_a,"LI",{});var Ieo=s(d0);MLe=n(Ieo,"STRONG",{});var j_a=s(MLe);kOr=r(j_a,"detr"),j_a.forEach(t),SOr=r(Ieo," \u2014 "),Ote=n(Ieo,"A",{href:!0});var G_a=s(Ote);ROr=r(G_a,"DetrForSegmentation"),G_a.forEach(t),POr=r(Ieo," (DETR model)"),Ieo.forEach(t),D_a.forEach(t),BOr=i(rn),m0=n(rn,"P",{});var Neo=s(m0);IOr=r(Neo,"The model is set in evaluation mode by default using "),ELe=n(Neo,"CODE",{});var O_a=s(ELe);NOr=r(O_a,"model.eval()"),O_a.forEach(t),qOr=r(Neo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),CLe=n(Neo,"CODE",{});var V_a=s(CLe);DOr=r(V_a,"model.train()"),V_a.forEach(t),Neo.forEach(t),jOr=i(rn),T(c0.$$.fragment,rn),rn.forEach(t),vi.forEach(t),Eio=i(c),mc=n(c,"H2",{class:!0});var Qmo=s(mc);f0=n(Qmo,"A",{id:!0,class:!0,href:!0});var X_a=s(f0);wLe=n(X_a,"SPAN",{});var z_a=s(wLe);T(lP.$$.fragment,z_a),z_a.forEach(t),X_a.forEach(t),GOr=i(Qmo),ALe=n(Qmo,"SPAN",{});var Q_a=s(ALe);OOr=r(Q_a,"AutoModelForSemanticSegmentation"),Q_a.forEach(t),Qmo.forEach(t),Cio=i(c),cr=n(c,"DIV",{class:!0});var Fi=s(cr);T(iP.$$.fragment,Fi),VOr=i(Fi),cc=n(Fi,"P",{});var rge=s(cc);XOr=r(rge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Vte=n(rge,"A",{href:!0});var W_a=s(Vte);zOr=r(W_a,"from_pretrained()"),W_a.forEach(t),QOr=r(rge," class method or the "),Xte=n(rge,"A",{href:!0});var U_a=s(Xte);WOr=r(U_a,"from_config()"),U_a.forEach(t),UOr=r(rge,` class
method.`),rge.forEach(t),HOr=i(Fi),dP=n(Fi,"P",{});var Wmo=s(dP);JOr=r(Wmo,"This class cannot be instantiated directly using "),LLe=n(Wmo,"CODE",{});var H_a=s(LLe);YOr=r(H_a,"__init__()"),H_a.forEach(t),ZOr=r(Wmo," (throws an error)."),Wmo.forEach(t),KOr=i(Fi),Zt=n(Fi,"DIV",{class:!0});var Kx=s(Zt);T(mP.$$.fragment,Kx),eVr=i(Kx),yLe=n(Kx,"P",{});var J_a=s(yLe);oVr=r(J_a,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),J_a.forEach(t),rVr=i(Kx),fc=n(Kx,"P",{});var tge=s(fc);tVr=r(tge,`Note:
Loading a model from its configuration file does `),xLe=n(tge,"STRONG",{});var Y_a=s(xLe);aVr=r(Y_a,"not"),Y_a.forEach(t),nVr=r(tge,` load the model weights. It only affects the
model\u2019s configuration. Use `),zte=n(tge,"A",{href:!0});var Z_a=s(zte);sVr=r(Z_a,"from_pretrained()"),Z_a.forEach(t),lVr=r(tge," to load the model weights."),tge.forEach(t),iVr=i(Kx),T(g0.$$.fragment,Kx),Kx.forEach(t),dVr=i(Fi),xo=n(Fi,"DIV",{class:!0});var tn=s(xo);T(cP.$$.fragment,tn),mVr=i(tn),$Le=n(tn,"P",{});var K_a=s($Le);cVr=r(K_a,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),K_a.forEach(t),fVr=i(tn),qn=n(tn,"P",{});var e$=s(qn);gVr=r(e$,"The model class to instantiate is selected based on the "),kLe=n(e$,"CODE",{});var e1a=s(kLe);hVr=r(e1a,"model_type"),e1a.forEach(t),uVr=r(e$,` property of the config object (either
passed as an argument or loaded from `),SLe=n(e$,"CODE",{});var o1a=s(SLe);pVr=r(o1a,"pretrained_model_name_or_path"),o1a.forEach(t),_Vr=r(e$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RLe=n(e$,"CODE",{});var r1a=s(RLe);bVr=r(r1a,"pretrained_model_name_or_path"),r1a.forEach(t),vVr=r(e$,":"),e$.forEach(t),FVr=i(tn),Mt=n(tn,"UL",{});var Ti=s(Mt);h0=n(Ti,"LI",{});var qeo=s(h0);PLe=n(qeo,"STRONG",{});var t1a=s(PLe);TVr=r(t1a,"beit"),t1a.forEach(t),MVr=r(qeo," \u2014 "),Qte=n(qeo,"A",{href:!0});var a1a=s(Qte);EVr=r(a1a,"BeitForSemanticSegmentation"),a1a.forEach(t),CVr=r(qeo," (BEiT model)"),qeo.forEach(t),wVr=i(Ti),u0=n(Ti,"LI",{});var Deo=s(u0);BLe=n(Deo,"STRONG",{});var n1a=s(BLe);AVr=r(n1a,"data2vec-vision"),n1a.forEach(t),LVr=r(Deo," \u2014 "),Wte=n(Deo,"A",{href:!0});var s1a=s(Wte);yVr=r(s1a,"Data2VecVisionForSemanticSegmentation"),s1a.forEach(t),xVr=r(Deo," (Data2VecVision model)"),Deo.forEach(t),$Vr=i(Ti),p0=n(Ti,"LI",{});var jeo=s(p0);ILe=n(jeo,"STRONG",{});var l1a=s(ILe);kVr=r(l1a,"dpt"),l1a.forEach(t),SVr=r(jeo," \u2014 "),Ute=n(jeo,"A",{href:!0});var i1a=s(Ute);RVr=r(i1a,"DPTForSemanticSegmentation"),i1a.forEach(t),PVr=r(jeo," (DPT model)"),jeo.forEach(t),BVr=i(Ti),_0=n(Ti,"LI",{});var Geo=s(_0);NLe=n(Geo,"STRONG",{});var d1a=s(NLe);IVr=r(d1a,"mobilevit"),d1a.forEach(t),NVr=r(Geo," \u2014 "),Hte=n(Geo,"A",{href:!0});var m1a=s(Hte);qVr=r(m1a,"MobileViTForSemanticSegmentation"),m1a.forEach(t),DVr=r(Geo," (MobileViT model)"),Geo.forEach(t),jVr=i(Ti),b0=n(Ti,"LI",{});var Oeo=s(b0);qLe=n(Oeo,"STRONG",{});var c1a=s(qLe);GVr=r(c1a,"segformer"),c1a.forEach(t),OVr=r(Oeo," \u2014 "),Jte=n(Oeo,"A",{href:!0});var f1a=s(Jte);VVr=r(f1a,"SegformerForSemanticSegmentation"),f1a.forEach(t),XVr=r(Oeo," (SegFormer model)"),Oeo.forEach(t),Ti.forEach(t),zVr=i(tn),v0=n(tn,"P",{});var Veo=s(v0);QVr=r(Veo,"The model is set in evaluation mode by default using "),DLe=n(Veo,"CODE",{});var g1a=s(DLe);WVr=r(g1a,"model.eval()"),g1a.forEach(t),UVr=r(Veo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),jLe=n(Veo,"CODE",{});var h1a=s(jLe);HVr=r(h1a,"model.train()"),h1a.forEach(t),Veo.forEach(t),JVr=i(tn),T(F0.$$.fragment,tn),tn.forEach(t),Fi.forEach(t),wio=i(c),gc=n(c,"H2",{class:!0});var Umo=s(gc);T0=n(Umo,"A",{id:!0,class:!0,href:!0});var u1a=s(T0);GLe=n(u1a,"SPAN",{});var p1a=s(GLe);T(fP.$$.fragment,p1a),p1a.forEach(t),u1a.forEach(t),YVr=i(Umo),OLe=n(Umo,"SPAN",{});var _1a=s(OLe);ZVr=r(_1a,"AutoModelForInstanceSegmentation"),_1a.forEach(t),Umo.forEach(t),Aio=i(c),fr=n(c,"DIV",{class:!0});var Mi=s(fr);T(gP.$$.fragment,Mi),KVr=i(Mi),hc=n(Mi,"P",{});var age=s(hc);eXr=r(age,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Yte=n(age,"A",{href:!0});var b1a=s(Yte);oXr=r(b1a,"from_pretrained()"),b1a.forEach(t),rXr=r(age," class method or the "),Zte=n(age,"A",{href:!0});var v1a=s(Zte);tXr=r(v1a,"from_config()"),v1a.forEach(t),aXr=r(age,` class
method.`),age.forEach(t),nXr=i(Mi),hP=n(Mi,"P",{});var Hmo=s(hP);sXr=r(Hmo,"This class cannot be instantiated directly using "),VLe=n(Hmo,"CODE",{});var F1a=s(VLe);lXr=r(F1a,"__init__()"),F1a.forEach(t),iXr=r(Hmo," (throws an error)."),Hmo.forEach(t),dXr=i(Mi),Kt=n(Mi,"DIV",{class:!0});var o$=s(Kt);T(uP.$$.fragment,o$),mXr=i(o$),XLe=n(o$,"P",{});var T1a=s(XLe);cXr=r(T1a,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),T1a.forEach(t),fXr=i(o$),uc=n(o$,"P",{});var nge=s(uc);gXr=r(nge,`Note:
Loading a model from its configuration file does `),zLe=n(nge,"STRONG",{});var M1a=s(zLe);hXr=r(M1a,"not"),M1a.forEach(t),uXr=r(nge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Kte=n(nge,"A",{href:!0});var E1a=s(Kte);pXr=r(E1a,"from_pretrained()"),E1a.forEach(t),_Xr=r(nge," to load the model weights."),nge.forEach(t),bXr=i(o$),T(M0.$$.fragment,o$),o$.forEach(t),vXr=i(Mi),$o=n(Mi,"DIV",{class:!0});var an=s($o);T(pP.$$.fragment,an),FXr=i(an),QLe=n(an,"P",{});var C1a=s(QLe);TXr=r(C1a,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),C1a.forEach(t),MXr=i(an),Dn=n(an,"P",{});var r$=s(Dn);EXr=r(r$,"The model class to instantiate is selected based on the "),WLe=n(r$,"CODE",{});var w1a=s(WLe);CXr=r(w1a,"model_type"),w1a.forEach(t),wXr=r(r$,` property of the config object (either
passed as an argument or loaded from `),ULe=n(r$,"CODE",{});var A1a=s(ULe);AXr=r(A1a,"pretrained_model_name_or_path"),A1a.forEach(t),LXr=r(r$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HLe=n(r$,"CODE",{});var L1a=s(HLe);yXr=r(L1a,"pretrained_model_name_or_path"),L1a.forEach(t),xXr=r(r$,":"),r$.forEach(t),$Xr=i(an),JLe=n(an,"UL",{});var y1a=s(JLe);E0=n(y1a,"LI",{});var Xeo=s(E0);YLe=n(Xeo,"STRONG",{});var x1a=s(YLe);kXr=r(x1a,"maskformer"),x1a.forEach(t),SXr=r(Xeo," \u2014 "),eae=n(Xeo,"A",{href:!0});var $1a=s(eae);RXr=r($1a,"MaskFormerForInstanceSegmentation"),$1a.forEach(t),PXr=r(Xeo," (MaskFormer model)"),Xeo.forEach(t),y1a.forEach(t),BXr=i(an),C0=n(an,"P",{});var zeo=s(C0);IXr=r(zeo,"The model is set in evaluation mode by default using "),ZLe=n(zeo,"CODE",{});var k1a=s(ZLe);NXr=r(k1a,"model.eval()"),k1a.forEach(t),qXr=r(zeo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),KLe=n(zeo,"CODE",{});var S1a=s(KLe);DXr=r(S1a,"model.train()"),S1a.forEach(t),zeo.forEach(t),jXr=i(an),T(w0.$$.fragment,an),an.forEach(t),Mi.forEach(t),Lio=i(c),pc=n(c,"H2",{class:!0});var Jmo=s(pc);A0=n(Jmo,"A",{id:!0,class:!0,href:!0});var R1a=s(A0);eye=n(R1a,"SPAN",{});var P1a=s(eye);T(_P.$$.fragment,P1a),P1a.forEach(t),R1a.forEach(t),GXr=i(Jmo),oye=n(Jmo,"SPAN",{});var B1a=s(oye);OXr=r(B1a,"AutoModelForZeroShotObjectDetection"),B1a.forEach(t),Jmo.forEach(t),yio=i(c),gr=n(c,"DIV",{class:!0});var Ei=s(gr);T(bP.$$.fragment,Ei),VXr=i(Ei),_c=n(Ei,"P",{});var sge=s(_c);XXr=r(sge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),oae=n(sge,"A",{href:!0});var I1a=s(oae);zXr=r(I1a,"from_pretrained()"),I1a.forEach(t),QXr=r(sge," class method or the "),rae=n(sge,"A",{href:!0});var N1a=s(rae);WXr=r(N1a,"from_config()"),N1a.forEach(t),UXr=r(sge,` class
method.`),sge.forEach(t),HXr=i(Ei),vP=n(Ei,"P",{});var Ymo=s(vP);JXr=r(Ymo,"This class cannot be instantiated directly using "),rye=n(Ymo,"CODE",{});var q1a=s(rye);YXr=r(q1a,"__init__()"),q1a.forEach(t),ZXr=r(Ymo," (throws an error)."),Ymo.forEach(t),KXr=i(Ei),ea=n(Ei,"DIV",{class:!0});var t$=s(ea);T(FP.$$.fragment,t$),ezr=i(t$),tye=n(t$,"P",{});var D1a=s(tye);ozr=r(D1a,"Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),D1a.forEach(t),rzr=i(t$),bc=n(t$,"P",{});var lge=s(bc);tzr=r(lge,`Note:
Loading a model from its configuration file does `),aye=n(lge,"STRONG",{});var j1a=s(aye);azr=r(j1a,"not"),j1a.forEach(t),nzr=r(lge,` load the model weights. It only affects the
model\u2019s configuration. Use `),tae=n(lge,"A",{href:!0});var G1a=s(tae);szr=r(G1a,"from_pretrained()"),G1a.forEach(t),lzr=r(lge," to load the model weights."),lge.forEach(t),izr=i(t$),T(L0.$$.fragment,t$),t$.forEach(t),dzr=i(Ei),ko=n(Ei,"DIV",{class:!0});var nn=s(ko);T(TP.$$.fragment,nn),mzr=i(nn),nye=n(nn,"P",{});var O1a=s(nye);czr=r(O1a,"Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),O1a.forEach(t),fzr=i(nn),jn=n(nn,"P",{});var a$=s(jn);gzr=r(a$,"The model class to instantiate is selected based on the "),sye=n(a$,"CODE",{});var V1a=s(sye);hzr=r(V1a,"model_type"),V1a.forEach(t),uzr=r(a$,` property of the config object (either
passed as an argument or loaded from `),lye=n(a$,"CODE",{});var X1a=s(lye);pzr=r(X1a,"pretrained_model_name_or_path"),X1a.forEach(t),_zr=r(a$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iye=n(a$,"CODE",{});var z1a=s(iye);bzr=r(z1a,"pretrained_model_name_or_path"),z1a.forEach(t),vzr=r(a$,":"),a$.forEach(t),Fzr=i(nn),dye=n(nn,"UL",{});var Q1a=s(dye);y0=n(Q1a,"LI",{});var Qeo=s(y0);mye=n(Qeo,"STRONG",{});var W1a=s(mye);Tzr=r(W1a,"owlvit"),W1a.forEach(t),Mzr=r(Qeo," \u2014 "),aae=n(Qeo,"A",{href:!0});var U1a=s(aae);Ezr=r(U1a,"OwlViTForObjectDetection"),U1a.forEach(t),Czr=r(Qeo," (OWL-ViT model)"),Qeo.forEach(t),Q1a.forEach(t),wzr=i(nn),x0=n(nn,"P",{});var Weo=s(x0);Azr=r(Weo,"The model is set in evaluation mode by default using "),cye=n(Weo,"CODE",{});var H1a=s(cye);Lzr=r(H1a,"model.eval()"),H1a.forEach(t),yzr=r(Weo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),fye=n(Weo,"CODE",{});var J1a=s(fye);xzr=r(J1a,"model.train()"),J1a.forEach(t),Weo.forEach(t),$zr=i(nn),T($0.$$.fragment,nn),nn.forEach(t),Ei.forEach(t),xio=i(c),vc=n(c,"H2",{class:!0});var Zmo=s(vc);k0=n(Zmo,"A",{id:!0,class:!0,href:!0});var Y1a=s(k0);gye=n(Y1a,"SPAN",{});var Z1a=s(gye);T(MP.$$.fragment,Z1a),Z1a.forEach(t),Y1a.forEach(t),kzr=i(Zmo),hye=n(Zmo,"SPAN",{});var K1a=s(hye);Szr=r(K1a,"TFAutoModel"),K1a.forEach(t),Zmo.forEach(t),$io=i(c),hr=n(c,"DIV",{class:!0});var Ci=s(hr);T(EP.$$.fragment,Ci),Rzr=i(Ci),Fc=n(Ci,"P",{});var ige=s(Fc);Pzr=r(ige,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),nae=n(ige,"A",{href:!0});var e2a=s(nae);Bzr=r(e2a,"from_pretrained()"),e2a.forEach(t),Izr=r(ige," class method or the "),sae=n(ige,"A",{href:!0});var o2a=s(sae);Nzr=r(o2a,"from_config()"),o2a.forEach(t),qzr=r(ige,` class
method.`),ige.forEach(t),Dzr=i(Ci),CP=n(Ci,"P",{});var Kmo=s(CP);jzr=r(Kmo,"This class cannot be instantiated directly using "),uye=n(Kmo,"CODE",{});var r2a=s(uye);Gzr=r(r2a,"__init__()"),r2a.forEach(t),Ozr=r(Kmo," (throws an error)."),Kmo.forEach(t),Vzr=i(Ci),oa=n(Ci,"DIV",{class:!0});var n$=s(oa);T(wP.$$.fragment,n$),Xzr=i(n$),pye=n(n$,"P",{});var t2a=s(pye);zzr=r(t2a,"Instantiates one of the base model classes of the library from a configuration."),t2a.forEach(t),Qzr=i(n$),Tc=n(n$,"P",{});var dge=s(Tc);Wzr=r(dge,`Note:
Loading a model from its configuration file does `),_ye=n(dge,"STRONG",{});var a2a=s(_ye);Uzr=r(a2a,"not"),a2a.forEach(t),Hzr=r(dge,` load the model weights. It only affects the
model\u2019s configuration. Use `),lae=n(dge,"A",{href:!0});var n2a=s(lae);Jzr=r(n2a,"from_pretrained()"),n2a.forEach(t),Yzr=r(dge," to load the model weights."),dge.forEach(t),Zzr=i(n$),T(S0.$$.fragment,n$),n$.forEach(t),Kzr=i(Ci),Xr=n(Ci,"DIV",{class:!0});var wi=s(Xr);T(AP.$$.fragment,wi),eQr=i(wi),bye=n(wi,"P",{});var s2a=s(bye);oQr=r(s2a,"Instantiate one of the base model classes of the library from a pretrained model."),s2a.forEach(t),rQr=i(wi),Gn=n(wi,"P",{});var s$=s(Gn);tQr=r(s$,"The model class to instantiate is selected based on the "),vye=n(s$,"CODE",{});var l2a=s(vye);aQr=r(l2a,"model_type"),l2a.forEach(t),nQr=r(s$,` property of the config object (either
passed as an argument or loaded from `),Fye=n(s$,"CODE",{});var i2a=s(Fye);sQr=r(i2a,"pretrained_model_name_or_path"),i2a.forEach(t),lQr=r(s$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tye=n(s$,"CODE",{});var d2a=s(Tye);iQr=r(d2a,"pretrained_model_name_or_path"),d2a.forEach(t),dQr=r(s$,":"),s$.forEach(t),mQr=i(wi),P=n(wi,"UL",{});var D=s(P);R0=n(D,"LI",{});var Ueo=s(R0);Mye=n(Ueo,"STRONG",{});var m2a=s(Mye);cQr=r(m2a,"albert"),m2a.forEach(t),fQr=r(Ueo," \u2014 "),iae=n(Ueo,"A",{href:!0});var c2a=s(iae);gQr=r(c2a,"TFAlbertModel"),c2a.forEach(t),hQr=r(Ueo," (ALBERT model)"),Ueo.forEach(t),uQr=i(D),P0=n(D,"LI",{});var Heo=s(P0);Eye=n(Heo,"STRONG",{});var f2a=s(Eye);pQr=r(f2a,"bart"),f2a.forEach(t),_Qr=r(Heo," \u2014 "),dae=n(Heo,"A",{href:!0});var g2a=s(dae);bQr=r(g2a,"TFBartModel"),g2a.forEach(t),vQr=r(Heo," (BART model)"),Heo.forEach(t),FQr=i(D),B0=n(D,"LI",{});var Jeo=s(B0);Cye=n(Jeo,"STRONG",{});var h2a=s(Cye);TQr=r(h2a,"bert"),h2a.forEach(t),MQr=r(Jeo," \u2014 "),mae=n(Jeo,"A",{href:!0});var u2a=s(mae);EQr=r(u2a,"TFBertModel"),u2a.forEach(t),CQr=r(Jeo," (BERT model)"),Jeo.forEach(t),wQr=i(D),I0=n(D,"LI",{});var Yeo=s(I0);wye=n(Yeo,"STRONG",{});var p2a=s(wye);AQr=r(p2a,"blenderbot"),p2a.forEach(t),LQr=r(Yeo," \u2014 "),cae=n(Yeo,"A",{href:!0});var _2a=s(cae);yQr=r(_2a,"TFBlenderbotModel"),_2a.forEach(t),xQr=r(Yeo," (Blenderbot model)"),Yeo.forEach(t),$Qr=i(D),N0=n(D,"LI",{});var Zeo=s(N0);Aye=n(Zeo,"STRONG",{});var b2a=s(Aye);kQr=r(b2a,"blenderbot-small"),b2a.forEach(t),SQr=r(Zeo," \u2014 "),fae=n(Zeo,"A",{href:!0});var v2a=s(fae);RQr=r(v2a,"TFBlenderbotSmallModel"),v2a.forEach(t),PQr=r(Zeo," (BlenderbotSmall model)"),Zeo.forEach(t),BQr=i(D),q0=n(D,"LI",{});var Keo=s(q0);Lye=n(Keo,"STRONG",{});var F2a=s(Lye);IQr=r(F2a,"camembert"),F2a.forEach(t),NQr=r(Keo," \u2014 "),gae=n(Keo,"A",{href:!0});var T2a=s(gae);qQr=r(T2a,"TFCamembertModel"),T2a.forEach(t),DQr=r(Keo," (CamemBERT model)"),Keo.forEach(t),jQr=i(D),D0=n(D,"LI",{});var eoo=s(D0);yye=n(eoo,"STRONG",{});var M2a=s(yye);GQr=r(M2a,"clip"),M2a.forEach(t),OQr=r(eoo," \u2014 "),hae=n(eoo,"A",{href:!0});var E2a=s(hae);VQr=r(E2a,"TFCLIPModel"),E2a.forEach(t),XQr=r(eoo," (CLIP model)"),eoo.forEach(t),zQr=i(D),j0=n(D,"LI",{});var ooo=s(j0);xye=n(ooo,"STRONG",{});var C2a=s(xye);QQr=r(C2a,"convbert"),C2a.forEach(t),WQr=r(ooo," \u2014 "),uae=n(ooo,"A",{href:!0});var w2a=s(uae);UQr=r(w2a,"TFConvBertModel"),w2a.forEach(t),HQr=r(ooo," (ConvBERT model)"),ooo.forEach(t),JQr=i(D),G0=n(D,"LI",{});var roo=s(G0);$ye=n(roo,"STRONG",{});var A2a=s($ye);YQr=r(A2a,"convnext"),A2a.forEach(t),ZQr=r(roo," \u2014 "),pae=n(roo,"A",{href:!0});var L2a=s(pae);KQr=r(L2a,"TFConvNextModel"),L2a.forEach(t),eWr=r(roo," (ConvNeXT model)"),roo.forEach(t),oWr=i(D),O0=n(D,"LI",{});var too=s(O0);kye=n(too,"STRONG",{});var y2a=s(kye);rWr=r(y2a,"ctrl"),y2a.forEach(t),tWr=r(too," \u2014 "),_ae=n(too,"A",{href:!0});var x2a=s(_ae);aWr=r(x2a,"TFCTRLModel"),x2a.forEach(t),nWr=r(too," (CTRL model)"),too.forEach(t),sWr=i(D),V0=n(D,"LI",{});var aoo=s(V0);Sye=n(aoo,"STRONG",{});var $2a=s(Sye);lWr=r($2a,"cvt"),$2a.forEach(t),iWr=r(aoo," \u2014 "),bae=n(aoo,"A",{href:!0});var k2a=s(bae);dWr=r(k2a,"TFCvtModel"),k2a.forEach(t),mWr=r(aoo," (CvT model)"),aoo.forEach(t),cWr=i(D),X0=n(D,"LI",{});var noo=s(X0);Rye=n(noo,"STRONG",{});var S2a=s(Rye);fWr=r(S2a,"data2vec-vision"),S2a.forEach(t),gWr=r(noo," \u2014 "),vae=n(noo,"A",{href:!0});var R2a=s(vae);hWr=r(R2a,"TFData2VecVisionModel"),R2a.forEach(t),uWr=r(noo," (Data2VecVision model)"),noo.forEach(t),pWr=i(D),z0=n(D,"LI",{});var soo=s(z0);Pye=n(soo,"STRONG",{});var P2a=s(Pye);_Wr=r(P2a,"deberta"),P2a.forEach(t),bWr=r(soo," \u2014 "),Fae=n(soo,"A",{href:!0});var B2a=s(Fae);vWr=r(B2a,"TFDebertaModel"),B2a.forEach(t),FWr=r(soo," (DeBERTa model)"),soo.forEach(t),TWr=i(D),Q0=n(D,"LI",{});var loo=s(Q0);Bye=n(loo,"STRONG",{});var I2a=s(Bye);MWr=r(I2a,"deberta-v2"),I2a.forEach(t),EWr=r(loo," \u2014 "),Tae=n(loo,"A",{href:!0});var N2a=s(Tae);CWr=r(N2a,"TFDebertaV2Model"),N2a.forEach(t),wWr=r(loo," (DeBERTa-v2 model)"),loo.forEach(t),AWr=i(D),W0=n(D,"LI",{});var ioo=s(W0);Iye=n(ioo,"STRONG",{});var q2a=s(Iye);LWr=r(q2a,"deit"),q2a.forEach(t),yWr=r(ioo," \u2014 "),Mae=n(ioo,"A",{href:!0});var D2a=s(Mae);xWr=r(D2a,"TFDeiTModel"),D2a.forEach(t),$Wr=r(ioo," (DeiT model)"),ioo.forEach(t),kWr=i(D),U0=n(D,"LI",{});var doo=s(U0);Nye=n(doo,"STRONG",{});var j2a=s(Nye);SWr=r(j2a,"distilbert"),j2a.forEach(t),RWr=r(doo," \u2014 "),Eae=n(doo,"A",{href:!0});var G2a=s(Eae);PWr=r(G2a,"TFDistilBertModel"),G2a.forEach(t),BWr=r(doo," (DistilBERT model)"),doo.forEach(t),IWr=i(D),H0=n(D,"LI",{});var moo=s(H0);qye=n(moo,"STRONG",{});var O2a=s(qye);NWr=r(O2a,"dpr"),O2a.forEach(t),qWr=r(moo," \u2014 "),Cae=n(moo,"A",{href:!0});var V2a=s(Cae);DWr=r(V2a,"TFDPRQuestionEncoder"),V2a.forEach(t),jWr=r(moo," (DPR model)"),moo.forEach(t),GWr=i(D),J0=n(D,"LI",{});var coo=s(J0);Dye=n(coo,"STRONG",{});var X2a=s(Dye);OWr=r(X2a,"electra"),X2a.forEach(t),VWr=r(coo," \u2014 "),wae=n(coo,"A",{href:!0});var z2a=s(wae);XWr=r(z2a,"TFElectraModel"),z2a.forEach(t),zWr=r(coo," (ELECTRA model)"),coo.forEach(t),QWr=i(D),Y0=n(D,"LI",{});var foo=s(Y0);jye=n(foo,"STRONG",{});var Q2a=s(jye);WWr=r(Q2a,"esm"),Q2a.forEach(t),UWr=r(foo," \u2014 "),Aae=n(foo,"A",{href:!0});var W2a=s(Aae);HWr=r(W2a,"TFEsmModel"),W2a.forEach(t),JWr=r(foo," (ESM model)"),foo.forEach(t),YWr=i(D),Z0=n(D,"LI",{});var goo=s(Z0);Gye=n(goo,"STRONG",{});var U2a=s(Gye);ZWr=r(U2a,"flaubert"),U2a.forEach(t),KWr=r(goo," \u2014 "),Lae=n(goo,"A",{href:!0});var H2a=s(Lae);eUr=r(H2a,"TFFlaubertModel"),H2a.forEach(t),oUr=r(goo," (FlauBERT model)"),goo.forEach(t),rUr=i(D),Dl=n(D,"LI",{});var xq=s(Dl);Oye=n(xq,"STRONG",{});var J2a=s(Oye);tUr=r(J2a,"funnel"),J2a.forEach(t),aUr=r(xq," \u2014 "),yae=n(xq,"A",{href:!0});var Y2a=s(yae);nUr=r(Y2a,"TFFunnelModel"),Y2a.forEach(t),sUr=r(xq," or "),xae=n(xq,"A",{href:!0});var Z2a=s(xae);lUr=r(Z2a,"TFFunnelBaseModel"),Z2a.forEach(t),iUr=r(xq," (Funnel Transformer model)"),xq.forEach(t),dUr=i(D),K0=n(D,"LI",{});var hoo=s(K0);Vye=n(hoo,"STRONG",{});var K2a=s(Vye);mUr=r(K2a,"gpt2"),K2a.forEach(t),cUr=r(hoo," \u2014 "),$ae=n(hoo,"A",{href:!0});var eba=s($ae);fUr=r(eba,"TFGPT2Model"),eba.forEach(t),gUr=r(hoo," (OpenAI GPT-2 model)"),hoo.forEach(t),hUr=i(D),ew=n(D,"LI",{});var uoo=s(ew);Xye=n(uoo,"STRONG",{});var oba=s(Xye);uUr=r(oba,"gptj"),oba.forEach(t),pUr=r(uoo," \u2014 "),kae=n(uoo,"A",{href:!0});var rba=s(kae);_Ur=r(rba,"TFGPTJModel"),rba.forEach(t),bUr=r(uoo," (GPT-J model)"),uoo.forEach(t),vUr=i(D),ow=n(D,"LI",{});var poo=s(ow);zye=n(poo,"STRONG",{});var tba=s(zye);FUr=r(tba,"groupvit"),tba.forEach(t),TUr=r(poo," \u2014 "),Sae=n(poo,"A",{href:!0});var aba=s(Sae);MUr=r(aba,"TFGroupViTModel"),aba.forEach(t),EUr=r(poo," (GroupViT model)"),poo.forEach(t),CUr=i(D),rw=n(D,"LI",{});var _oo=s(rw);Qye=n(_oo,"STRONG",{});var nba=s(Qye);wUr=r(nba,"hubert"),nba.forEach(t),AUr=r(_oo," \u2014 "),Rae=n(_oo,"A",{href:!0});var sba=s(Rae);LUr=r(sba,"TFHubertModel"),sba.forEach(t),yUr=r(_oo," (Hubert model)"),_oo.forEach(t),xUr=i(D),tw=n(D,"LI",{});var boo=s(tw);Wye=n(boo,"STRONG",{});var lba=s(Wye);$Ur=r(lba,"layoutlm"),lba.forEach(t),kUr=r(boo," \u2014 "),Pae=n(boo,"A",{href:!0});var iba=s(Pae);SUr=r(iba,"TFLayoutLMModel"),iba.forEach(t),RUr=r(boo," (LayoutLM model)"),boo.forEach(t),PUr=i(D),aw=n(D,"LI",{});var voo=s(aw);Uye=n(voo,"STRONG",{});var dba=s(Uye);BUr=r(dba,"layoutlmv3"),dba.forEach(t),IUr=r(voo," \u2014 "),Bae=n(voo,"A",{href:!0});var mba=s(Bae);NUr=r(mba,"TFLayoutLMv3Model"),mba.forEach(t),qUr=r(voo," (LayoutLMv3 model)"),voo.forEach(t),DUr=i(D),nw=n(D,"LI",{});var Foo=s(nw);Hye=n(Foo,"STRONG",{});var cba=s(Hye);jUr=r(cba,"led"),cba.forEach(t),GUr=r(Foo," \u2014 "),Iae=n(Foo,"A",{href:!0});var fba=s(Iae);OUr=r(fba,"TFLEDModel"),fba.forEach(t),VUr=r(Foo," (LED model)"),Foo.forEach(t),XUr=i(D),sw=n(D,"LI",{});var Too=s(sw);Jye=n(Too,"STRONG",{});var gba=s(Jye);zUr=r(gba,"longformer"),gba.forEach(t),QUr=r(Too," \u2014 "),Nae=n(Too,"A",{href:!0});var hba=s(Nae);WUr=r(hba,"TFLongformerModel"),hba.forEach(t),UUr=r(Too," (Longformer model)"),Too.forEach(t),HUr=i(D),lw=n(D,"LI",{});var Moo=s(lw);Yye=n(Moo,"STRONG",{});var uba=s(Yye);JUr=r(uba,"lxmert"),uba.forEach(t),YUr=r(Moo," \u2014 "),qae=n(Moo,"A",{href:!0});var pba=s(qae);ZUr=r(pba,"TFLxmertModel"),pba.forEach(t),KUr=r(Moo," (LXMERT model)"),Moo.forEach(t),eHr=i(D),iw=n(D,"LI",{});var Eoo=s(iw);Zye=n(Eoo,"STRONG",{});var _ba=s(Zye);oHr=r(_ba,"marian"),_ba.forEach(t),rHr=r(Eoo," \u2014 "),Dae=n(Eoo,"A",{href:!0});var bba=s(Dae);tHr=r(bba,"TFMarianModel"),bba.forEach(t),aHr=r(Eoo," (Marian model)"),Eoo.forEach(t),nHr=i(D),dw=n(D,"LI",{});var Coo=s(dw);Kye=n(Coo,"STRONG",{});var vba=s(Kye);sHr=r(vba,"mbart"),vba.forEach(t),lHr=r(Coo," \u2014 "),jae=n(Coo,"A",{href:!0});var Fba=s(jae);iHr=r(Fba,"TFMBartModel"),Fba.forEach(t),dHr=r(Coo," (mBART model)"),Coo.forEach(t),mHr=i(D),mw=n(D,"LI",{});var woo=s(mw);e9e=n(woo,"STRONG",{});var Tba=s(e9e);cHr=r(Tba,"mobilebert"),Tba.forEach(t),fHr=r(woo," \u2014 "),Gae=n(woo,"A",{href:!0});var Mba=s(Gae);gHr=r(Mba,"TFMobileBertModel"),Mba.forEach(t),hHr=r(woo," (MobileBERT model)"),woo.forEach(t),uHr=i(D),cw=n(D,"LI",{});var Aoo=s(cw);o9e=n(Aoo,"STRONG",{});var Eba=s(o9e);pHr=r(Eba,"mobilevit"),Eba.forEach(t),_Hr=r(Aoo," \u2014 "),Oae=n(Aoo,"A",{href:!0});var Cba=s(Oae);bHr=r(Cba,"TFMobileViTModel"),Cba.forEach(t),vHr=r(Aoo," (MobileViT model)"),Aoo.forEach(t),FHr=i(D),fw=n(D,"LI",{});var Loo=s(fw);r9e=n(Loo,"STRONG",{});var wba=s(r9e);THr=r(wba,"mpnet"),wba.forEach(t),MHr=r(Loo," \u2014 "),Vae=n(Loo,"A",{href:!0});var Aba=s(Vae);EHr=r(Aba,"TFMPNetModel"),Aba.forEach(t),CHr=r(Loo," (MPNet model)"),Loo.forEach(t),wHr=i(D),gw=n(D,"LI",{});var yoo=s(gw);t9e=n(yoo,"STRONG",{});var Lba=s(t9e);AHr=r(Lba,"mt5"),Lba.forEach(t),LHr=r(yoo," \u2014 "),Xae=n(yoo,"A",{href:!0});var yba=s(Xae);yHr=r(yba,"TFMT5Model"),yba.forEach(t),xHr=r(yoo," (MT5 model)"),yoo.forEach(t),$Hr=i(D),hw=n(D,"LI",{});var xoo=s(hw);a9e=n(xoo,"STRONG",{});var xba=s(a9e);kHr=r(xba,"openai-gpt"),xba.forEach(t),SHr=r(xoo," \u2014 "),zae=n(xoo,"A",{href:!0});var $ba=s(zae);RHr=r($ba,"TFOpenAIGPTModel"),$ba.forEach(t),PHr=r(xoo," (OpenAI GPT model)"),xoo.forEach(t),BHr=i(D),uw=n(D,"LI",{});var $oo=s(uw);n9e=n($oo,"STRONG",{});var kba=s(n9e);IHr=r(kba,"opt"),kba.forEach(t),NHr=r($oo," \u2014 "),Qae=n($oo,"A",{href:!0});var Sba=s(Qae);qHr=r(Sba,"TFOPTModel"),Sba.forEach(t),DHr=r($oo," (OPT model)"),$oo.forEach(t),jHr=i(D),pw=n(D,"LI",{});var koo=s(pw);s9e=n(koo,"STRONG",{});var Rba=s(s9e);GHr=r(Rba,"pegasus"),Rba.forEach(t),OHr=r(koo," \u2014 "),Wae=n(koo,"A",{href:!0});var Pba=s(Wae);VHr=r(Pba,"TFPegasusModel"),Pba.forEach(t),XHr=r(koo," (Pegasus model)"),koo.forEach(t),zHr=i(D),_w=n(D,"LI",{});var Soo=s(_w);l9e=n(Soo,"STRONG",{});var Bba=s(l9e);QHr=r(Bba,"regnet"),Bba.forEach(t),WHr=r(Soo," \u2014 "),Uae=n(Soo,"A",{href:!0});var Iba=s(Uae);UHr=r(Iba,"TFRegNetModel"),Iba.forEach(t),HHr=r(Soo," (RegNet model)"),Soo.forEach(t),JHr=i(D),bw=n(D,"LI",{});var Roo=s(bw);i9e=n(Roo,"STRONG",{});var Nba=s(i9e);YHr=r(Nba,"rembert"),Nba.forEach(t),ZHr=r(Roo," \u2014 "),Hae=n(Roo,"A",{href:!0});var qba=s(Hae);KHr=r(qba,"TFRemBertModel"),qba.forEach(t),eJr=r(Roo," (RemBERT model)"),Roo.forEach(t),oJr=i(D),vw=n(D,"LI",{});var Poo=s(vw);d9e=n(Poo,"STRONG",{});var Dba=s(d9e);rJr=r(Dba,"resnet"),Dba.forEach(t),tJr=r(Poo," \u2014 "),Jae=n(Poo,"A",{href:!0});var jba=s(Jae);aJr=r(jba,"TFResNetModel"),jba.forEach(t),nJr=r(Poo," (ResNet model)"),Poo.forEach(t),sJr=i(D),Fw=n(D,"LI",{});var Boo=s(Fw);m9e=n(Boo,"STRONG",{});var Gba=s(m9e);lJr=r(Gba,"roberta"),Gba.forEach(t),iJr=r(Boo," \u2014 "),Yae=n(Boo,"A",{href:!0});var Oba=s(Yae);dJr=r(Oba,"TFRobertaModel"),Oba.forEach(t),mJr=r(Boo," (RoBERTa model)"),Boo.forEach(t),cJr=i(D),Tw=n(D,"LI",{});var Ioo=s(Tw);c9e=n(Ioo,"STRONG",{});var Vba=s(c9e);fJr=r(Vba,"roformer"),Vba.forEach(t),gJr=r(Ioo," \u2014 "),Zae=n(Ioo,"A",{href:!0});var Xba=s(Zae);hJr=r(Xba,"TFRoFormerModel"),Xba.forEach(t),uJr=r(Ioo," (RoFormer model)"),Ioo.forEach(t),pJr=i(D),Mw=n(D,"LI",{});var Noo=s(Mw);f9e=n(Noo,"STRONG",{});var zba=s(f9e);_Jr=r(zba,"segformer"),zba.forEach(t),bJr=r(Noo," \u2014 "),Kae=n(Noo,"A",{href:!0});var Qba=s(Kae);vJr=r(Qba,"TFSegformerModel"),Qba.forEach(t),FJr=r(Noo," (SegFormer model)"),Noo.forEach(t),TJr=i(D),Ew=n(D,"LI",{});var qoo=s(Ew);g9e=n(qoo,"STRONG",{});var Wba=s(g9e);MJr=r(Wba,"speech_to_text"),Wba.forEach(t),EJr=r(qoo," \u2014 "),ene=n(qoo,"A",{href:!0});var Uba=s(ene);CJr=r(Uba,"TFSpeech2TextModel"),Uba.forEach(t),wJr=r(qoo," (Speech2Text model)"),qoo.forEach(t),AJr=i(D),Cw=n(D,"LI",{});var Doo=s(Cw);h9e=n(Doo,"STRONG",{});var Hba=s(h9e);LJr=r(Hba,"swin"),Hba.forEach(t),yJr=r(Doo," \u2014 "),one=n(Doo,"A",{href:!0});var Jba=s(one);xJr=r(Jba,"TFSwinModel"),Jba.forEach(t),$Jr=r(Doo," (Swin Transformer model)"),Doo.forEach(t),kJr=i(D),ww=n(D,"LI",{});var joo=s(ww);u9e=n(joo,"STRONG",{});var Yba=s(u9e);SJr=r(Yba,"t5"),Yba.forEach(t),RJr=r(joo," \u2014 "),rne=n(joo,"A",{href:!0});var Zba=s(rne);PJr=r(Zba,"TFT5Model"),Zba.forEach(t),BJr=r(joo," (T5 model)"),joo.forEach(t),IJr=i(D),Aw=n(D,"LI",{});var Goo=s(Aw);p9e=n(Goo,"STRONG",{});var Kba=s(p9e);NJr=r(Kba,"tapas"),Kba.forEach(t),qJr=r(Goo," \u2014 "),tne=n(Goo,"A",{href:!0});var eva=s(tne);DJr=r(eva,"TFTapasModel"),eva.forEach(t),jJr=r(Goo," (TAPAS model)"),Goo.forEach(t),GJr=i(D),Lw=n(D,"LI",{});var Ooo=s(Lw);_9e=n(Ooo,"STRONG",{});var ova=s(_9e);OJr=r(ova,"transfo-xl"),ova.forEach(t),VJr=r(Ooo," \u2014 "),ane=n(Ooo,"A",{href:!0});var rva=s(ane);XJr=r(rva,"TFTransfoXLModel"),rva.forEach(t),zJr=r(Ooo," (Transformer-XL model)"),Ooo.forEach(t),QJr=i(D),yw=n(D,"LI",{});var Voo=s(yw);b9e=n(Voo,"STRONG",{});var tva=s(b9e);WJr=r(tva,"vit"),tva.forEach(t),UJr=r(Voo," \u2014 "),nne=n(Voo,"A",{href:!0});var ava=s(nne);HJr=r(ava,"TFViTModel"),ava.forEach(t),JJr=r(Voo," (ViT model)"),Voo.forEach(t),YJr=i(D),xw=n(D,"LI",{});var Xoo=s(xw);v9e=n(Xoo,"STRONG",{});var nva=s(v9e);ZJr=r(nva,"vit_mae"),nva.forEach(t),KJr=r(Xoo," \u2014 "),sne=n(Xoo,"A",{href:!0});var sva=s(sne);eYr=r(sva,"TFViTMAEModel"),sva.forEach(t),oYr=r(Xoo," (ViTMAE model)"),Xoo.forEach(t),rYr=i(D),$w=n(D,"LI",{});var zoo=s($w);F9e=n(zoo,"STRONG",{});var lva=s(F9e);tYr=r(lva,"wav2vec2"),lva.forEach(t),aYr=r(zoo," \u2014 "),lne=n(zoo,"A",{href:!0});var iva=s(lne);nYr=r(iva,"TFWav2Vec2Model"),iva.forEach(t),sYr=r(zoo," (Wav2Vec2 model)"),zoo.forEach(t),lYr=i(D),kw=n(D,"LI",{});var Qoo=s(kw);T9e=n(Qoo,"STRONG",{});var dva=s(T9e);iYr=r(dva,"whisper"),dva.forEach(t),dYr=r(Qoo," \u2014 "),ine=n(Qoo,"A",{href:!0});var mva=s(ine);mYr=r(mva,"TFWhisperModel"),mva.forEach(t),cYr=r(Qoo," (Whisper model)"),Qoo.forEach(t),fYr=i(D),Sw=n(D,"LI",{});var Woo=s(Sw);M9e=n(Woo,"STRONG",{});var cva=s(M9e);gYr=r(cva,"xglm"),cva.forEach(t),hYr=r(Woo," \u2014 "),dne=n(Woo,"A",{href:!0});var fva=s(dne);uYr=r(fva,"TFXGLMModel"),fva.forEach(t),pYr=r(Woo," (XGLM model)"),Woo.forEach(t),_Yr=i(D),Rw=n(D,"LI",{});var Uoo=s(Rw);E9e=n(Uoo,"STRONG",{});var gva=s(E9e);bYr=r(gva,"xlm"),gva.forEach(t),vYr=r(Uoo," \u2014 "),mne=n(Uoo,"A",{href:!0});var hva=s(mne);FYr=r(hva,"TFXLMModel"),hva.forEach(t),TYr=r(Uoo," (XLM model)"),Uoo.forEach(t),MYr=i(D),Pw=n(D,"LI",{});var Hoo=s(Pw);C9e=n(Hoo,"STRONG",{});var uva=s(C9e);EYr=r(uva,"xlm-roberta"),uva.forEach(t),CYr=r(Hoo," \u2014 "),cne=n(Hoo,"A",{href:!0});var pva=s(cne);wYr=r(pva,"TFXLMRobertaModel"),pva.forEach(t),AYr=r(Hoo," (XLM-RoBERTa model)"),Hoo.forEach(t),LYr=i(D),Bw=n(D,"LI",{});var Joo=s(Bw);w9e=n(Joo,"STRONG",{});var _va=s(w9e);yYr=r(_va,"xlnet"),_va.forEach(t),xYr=r(Joo," \u2014 "),fne=n(Joo,"A",{href:!0});var bva=s(fne);$Yr=r(bva,"TFXLNetModel"),bva.forEach(t),kYr=r(Joo," (XLNet model)"),Joo.forEach(t),D.forEach(t),SYr=i(wi),T(Iw.$$.fragment,wi),wi.forEach(t),Ci.forEach(t),kio=i(c),Mc=n(c,"H2",{class:!0});var eco=s(Mc);Nw=n(eco,"A",{id:!0,class:!0,href:!0});var vva=s(Nw);A9e=n(vva,"SPAN",{});var Fva=s(A9e);T(LP.$$.fragment,Fva),Fva.forEach(t),vva.forEach(t),RYr=i(eco),L9e=n(eco,"SPAN",{});var Tva=s(L9e);PYr=r(Tva,"TFAutoModelForPreTraining"),Tva.forEach(t),eco.forEach(t),Sio=i(c),ur=n(c,"DIV",{class:!0});var Ai=s(ur);T(yP.$$.fragment,Ai),BYr=i(Ai),Ec=n(Ai,"P",{});var mge=s(Ec);IYr=r(mge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),gne=n(mge,"A",{href:!0});var Mva=s(gne);NYr=r(Mva,"from_pretrained()"),Mva.forEach(t),qYr=r(mge," class method or the "),hne=n(mge,"A",{href:!0});var Eva=s(hne);DYr=r(Eva,"from_config()"),Eva.forEach(t),jYr=r(mge,` class
method.`),mge.forEach(t),GYr=i(Ai),xP=n(Ai,"P",{});var oco=s(xP);OYr=r(oco,"This class cannot be instantiated directly using "),y9e=n(oco,"CODE",{});var Cva=s(y9e);VYr=r(Cva,"__init__()"),Cva.forEach(t),XYr=r(oco," (throws an error)."),oco.forEach(t),zYr=i(Ai),ra=n(Ai,"DIV",{class:!0});var l$=s(ra);T($P.$$.fragment,l$),QYr=i(l$),x9e=n(l$,"P",{});var wva=s(x9e);WYr=r(wva,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),wva.forEach(t),UYr=i(l$),Cc=n(l$,"P",{});var cge=s(Cc);HYr=r(cge,`Note:
Loading a model from its configuration file does `),$9e=n(cge,"STRONG",{});var Ava=s($9e);JYr=r(Ava,"not"),Ava.forEach(t),YYr=r(cge,` load the model weights. It only affects the
model\u2019s configuration. Use `),une=n(cge,"A",{href:!0});var Lva=s(une);ZYr=r(Lva,"from_pretrained()"),Lva.forEach(t),KYr=r(cge," to load the model weights."),cge.forEach(t),eZr=i(l$),T(qw.$$.fragment,l$),l$.forEach(t),oZr=i(Ai),zr=n(Ai,"DIV",{class:!0});var Li=s(zr);T(kP.$$.fragment,Li),rZr=i(Li),k9e=n(Li,"P",{});var yva=s(k9e);tZr=r(yva,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),yva.forEach(t),aZr=i(Li),On=n(Li,"P",{});var i$=s(On);nZr=r(i$,"The model class to instantiate is selected based on the "),S9e=n(i$,"CODE",{});var xva=s(S9e);sZr=r(xva,"model_type"),xva.forEach(t),lZr=r(i$,` property of the config object (either
passed as an argument or loaded from `),R9e=n(i$,"CODE",{});var $va=s(R9e);iZr=r($va,"pretrained_model_name_or_path"),$va.forEach(t),dZr=r(i$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P9e=n(i$,"CODE",{});var kva=s(P9e);mZr=r(kva,"pretrained_model_name_or_path"),kva.forEach(t),cZr=r(i$,":"),i$.forEach(t),fZr=i(Li),de=n(Li,"UL",{});var fe=s(de);Dw=n(fe,"LI",{});var Yoo=s(Dw);B9e=n(Yoo,"STRONG",{});var Sva=s(B9e);gZr=r(Sva,"albert"),Sva.forEach(t),hZr=r(Yoo," \u2014 "),pne=n(Yoo,"A",{href:!0});var Rva=s(pne);uZr=r(Rva,"TFAlbertForPreTraining"),Rva.forEach(t),pZr=r(Yoo," (ALBERT model)"),Yoo.forEach(t),_Zr=i(fe),jw=n(fe,"LI",{});var Zoo=s(jw);I9e=n(Zoo,"STRONG",{});var Pva=s(I9e);bZr=r(Pva,"bart"),Pva.forEach(t),vZr=r(Zoo," \u2014 "),_ne=n(Zoo,"A",{href:!0});var Bva=s(_ne);FZr=r(Bva,"TFBartForConditionalGeneration"),Bva.forEach(t),TZr=r(Zoo," (BART model)"),Zoo.forEach(t),MZr=i(fe),Gw=n(fe,"LI",{});var Koo=s(Gw);N9e=n(Koo,"STRONG",{});var Iva=s(N9e);EZr=r(Iva,"bert"),Iva.forEach(t),CZr=r(Koo," \u2014 "),bne=n(Koo,"A",{href:!0});var Nva=s(bne);wZr=r(Nva,"TFBertForPreTraining"),Nva.forEach(t),AZr=r(Koo," (BERT model)"),Koo.forEach(t),LZr=i(fe),Ow=n(fe,"LI",{});var ero=s(Ow);q9e=n(ero,"STRONG",{});var qva=s(q9e);yZr=r(qva,"camembert"),qva.forEach(t),xZr=r(ero," \u2014 "),vne=n(ero,"A",{href:!0});var Dva=s(vne);$Zr=r(Dva,"TFCamembertForMaskedLM"),Dva.forEach(t),kZr=r(ero," (CamemBERT model)"),ero.forEach(t),SZr=i(fe),Vw=n(fe,"LI",{});var oro=s(Vw);D9e=n(oro,"STRONG",{});var jva=s(D9e);RZr=r(jva,"ctrl"),jva.forEach(t),PZr=r(oro," \u2014 "),Fne=n(oro,"A",{href:!0});var Gva=s(Fne);BZr=r(Gva,"TFCTRLLMHeadModel"),Gva.forEach(t),IZr=r(oro," (CTRL model)"),oro.forEach(t),NZr=i(fe),Xw=n(fe,"LI",{});var rro=s(Xw);j9e=n(rro,"STRONG",{});var Ova=s(j9e);qZr=r(Ova,"distilbert"),Ova.forEach(t),DZr=r(rro," \u2014 "),Tne=n(rro,"A",{href:!0});var Vva=s(Tne);jZr=r(Vva,"TFDistilBertForMaskedLM"),Vva.forEach(t),GZr=r(rro," (DistilBERT model)"),rro.forEach(t),OZr=i(fe),zw=n(fe,"LI",{});var tro=s(zw);G9e=n(tro,"STRONG",{});var Xva=s(G9e);VZr=r(Xva,"electra"),Xva.forEach(t),XZr=r(tro," \u2014 "),Mne=n(tro,"A",{href:!0});var zva=s(Mne);zZr=r(zva,"TFElectraForPreTraining"),zva.forEach(t),QZr=r(tro," (ELECTRA model)"),tro.forEach(t),WZr=i(fe),Qw=n(fe,"LI",{});var aro=s(Qw);O9e=n(aro,"STRONG",{});var Qva=s(O9e);UZr=r(Qva,"flaubert"),Qva.forEach(t),HZr=r(aro," \u2014 "),Ene=n(aro,"A",{href:!0});var Wva=s(Ene);JZr=r(Wva,"TFFlaubertWithLMHeadModel"),Wva.forEach(t),YZr=r(aro," (FlauBERT model)"),aro.forEach(t),ZZr=i(fe),Ww=n(fe,"LI",{});var nro=s(Ww);V9e=n(nro,"STRONG",{});var Uva=s(V9e);KZr=r(Uva,"funnel"),Uva.forEach(t),eKr=r(nro," \u2014 "),Cne=n(nro,"A",{href:!0});var Hva=s(Cne);oKr=r(Hva,"TFFunnelForPreTraining"),Hva.forEach(t),rKr=r(nro," (Funnel Transformer model)"),nro.forEach(t),tKr=i(fe),Uw=n(fe,"LI",{});var sro=s(Uw);X9e=n(sro,"STRONG",{});var Jva=s(X9e);aKr=r(Jva,"gpt2"),Jva.forEach(t),nKr=r(sro," \u2014 "),wne=n(sro,"A",{href:!0});var Yva=s(wne);sKr=r(Yva,"TFGPT2LMHeadModel"),Yva.forEach(t),lKr=r(sro," (OpenAI GPT-2 model)"),sro.forEach(t),iKr=i(fe),Hw=n(fe,"LI",{});var lro=s(Hw);z9e=n(lro,"STRONG",{});var Zva=s(z9e);dKr=r(Zva,"layoutlm"),Zva.forEach(t),mKr=r(lro," \u2014 "),Ane=n(lro,"A",{href:!0});var Kva=s(Ane);cKr=r(Kva,"TFLayoutLMForMaskedLM"),Kva.forEach(t),fKr=r(lro," (LayoutLM model)"),lro.forEach(t),gKr=i(fe),Jw=n(fe,"LI",{});var iro=s(Jw);Q9e=n(iro,"STRONG",{});var eFa=s(Q9e);hKr=r(eFa,"lxmert"),eFa.forEach(t),uKr=r(iro," \u2014 "),Lne=n(iro,"A",{href:!0});var oFa=s(Lne);pKr=r(oFa,"TFLxmertForPreTraining"),oFa.forEach(t),_Kr=r(iro," (LXMERT model)"),iro.forEach(t),bKr=i(fe),Yw=n(fe,"LI",{});var dro=s(Yw);W9e=n(dro,"STRONG",{});var rFa=s(W9e);vKr=r(rFa,"mobilebert"),rFa.forEach(t),FKr=r(dro," \u2014 "),yne=n(dro,"A",{href:!0});var tFa=s(yne);TKr=r(tFa,"TFMobileBertForPreTraining"),tFa.forEach(t),MKr=r(dro," (MobileBERT model)"),dro.forEach(t),EKr=i(fe),Zw=n(fe,"LI",{});var mro=s(Zw);U9e=n(mro,"STRONG",{});var aFa=s(U9e);CKr=r(aFa,"mpnet"),aFa.forEach(t),wKr=r(mro," \u2014 "),xne=n(mro,"A",{href:!0});var nFa=s(xne);AKr=r(nFa,"TFMPNetForMaskedLM"),nFa.forEach(t),LKr=r(mro," (MPNet model)"),mro.forEach(t),yKr=i(fe),Kw=n(fe,"LI",{});var cro=s(Kw);H9e=n(cro,"STRONG",{});var sFa=s(H9e);xKr=r(sFa,"openai-gpt"),sFa.forEach(t),$Kr=r(cro," \u2014 "),$ne=n(cro,"A",{href:!0});var lFa=s($ne);kKr=r(lFa,"TFOpenAIGPTLMHeadModel"),lFa.forEach(t),SKr=r(cro," (OpenAI GPT model)"),cro.forEach(t),RKr=i(fe),eA=n(fe,"LI",{});var fro=s(eA);J9e=n(fro,"STRONG",{});var iFa=s(J9e);PKr=r(iFa,"roberta"),iFa.forEach(t),BKr=r(fro," \u2014 "),kne=n(fro,"A",{href:!0});var dFa=s(kne);IKr=r(dFa,"TFRobertaForMaskedLM"),dFa.forEach(t),NKr=r(fro," (RoBERTa model)"),fro.forEach(t),qKr=i(fe),oA=n(fe,"LI",{});var gro=s(oA);Y9e=n(gro,"STRONG",{});var mFa=s(Y9e);DKr=r(mFa,"t5"),mFa.forEach(t),jKr=r(gro," \u2014 "),Sne=n(gro,"A",{href:!0});var cFa=s(Sne);GKr=r(cFa,"TFT5ForConditionalGeneration"),cFa.forEach(t),OKr=r(gro," (T5 model)"),gro.forEach(t),VKr=i(fe),rA=n(fe,"LI",{});var hro=s(rA);Z9e=n(hro,"STRONG",{});var fFa=s(Z9e);XKr=r(fFa,"tapas"),fFa.forEach(t),zKr=r(hro," \u2014 "),Rne=n(hro,"A",{href:!0});var gFa=s(Rne);QKr=r(gFa,"TFTapasForMaskedLM"),gFa.forEach(t),WKr=r(hro," (TAPAS model)"),hro.forEach(t),UKr=i(fe),tA=n(fe,"LI",{});var uro=s(tA);K9e=n(uro,"STRONG",{});var hFa=s(K9e);HKr=r(hFa,"transfo-xl"),hFa.forEach(t),JKr=r(uro," \u2014 "),Pne=n(uro,"A",{href:!0});var uFa=s(Pne);YKr=r(uFa,"TFTransfoXLLMHeadModel"),uFa.forEach(t),ZKr=r(uro," (Transformer-XL model)"),uro.forEach(t),KKr=i(fe),aA=n(fe,"LI",{});var pro=s(aA);exe=n(pro,"STRONG",{});var pFa=s(exe);eet=r(pFa,"vit_mae"),pFa.forEach(t),oet=r(pro," \u2014 "),Bne=n(pro,"A",{href:!0});var _Fa=s(Bne);ret=r(_Fa,"TFViTMAEForPreTraining"),_Fa.forEach(t),tet=r(pro," (ViTMAE model)"),pro.forEach(t),aet=i(fe),nA=n(fe,"LI",{});var _ro=s(nA);oxe=n(_ro,"STRONG",{});var bFa=s(oxe);net=r(bFa,"xlm"),bFa.forEach(t),set=r(_ro," \u2014 "),Ine=n(_ro,"A",{href:!0});var vFa=s(Ine);iet=r(vFa,"TFXLMWithLMHeadModel"),vFa.forEach(t),det=r(_ro," (XLM model)"),_ro.forEach(t),met=i(fe),sA=n(fe,"LI",{});var bro=s(sA);rxe=n(bro,"STRONG",{});var FFa=s(rxe);cet=r(FFa,"xlm-roberta"),FFa.forEach(t),fet=r(bro," \u2014 "),Nne=n(bro,"A",{href:!0});var TFa=s(Nne);get=r(TFa,"TFXLMRobertaForMaskedLM"),TFa.forEach(t),het=r(bro," (XLM-RoBERTa model)"),bro.forEach(t),uet=i(fe),lA=n(fe,"LI",{});var vro=s(lA);txe=n(vro,"STRONG",{});var MFa=s(txe);pet=r(MFa,"xlnet"),MFa.forEach(t),_et=r(vro," \u2014 "),qne=n(vro,"A",{href:!0});var EFa=s(qne);bet=r(EFa,"TFXLNetLMHeadModel"),EFa.forEach(t),vet=r(vro," (XLNet model)"),vro.forEach(t),fe.forEach(t),Fet=i(Li),T(iA.$$.fragment,Li),Li.forEach(t),Ai.forEach(t),Rio=i(c),wc=n(c,"H2",{class:!0});var rco=s(wc);dA=n(rco,"A",{id:!0,class:!0,href:!0});var CFa=s(dA);axe=n(CFa,"SPAN",{});var wFa=s(axe);T(SP.$$.fragment,wFa),wFa.forEach(t),CFa.forEach(t),Tet=i(rco),nxe=n(rco,"SPAN",{});var AFa=s(nxe);Met=r(AFa,"TFAutoModelForCausalLM"),AFa.forEach(t),rco.forEach(t),Pio=i(c),pr=n(c,"DIV",{class:!0});var yi=s(pr);T(RP.$$.fragment,yi),Eet=i(yi),Ac=n(yi,"P",{});var fge=s(Ac);Cet=r(fge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Dne=n(fge,"A",{href:!0});var LFa=s(Dne);wet=r(LFa,"from_pretrained()"),LFa.forEach(t),Aet=r(fge," class method or the "),jne=n(fge,"A",{href:!0});var yFa=s(jne);Let=r(yFa,"from_config()"),yFa.forEach(t),yet=r(fge,` class
method.`),fge.forEach(t),xet=i(yi),PP=n(yi,"P",{});var tco=s(PP);$et=r(tco,"This class cannot be instantiated directly using "),sxe=n(tco,"CODE",{});var xFa=s(sxe);ket=r(xFa,"__init__()"),xFa.forEach(t),Set=r(tco," (throws an error)."),tco.forEach(t),Ret=i(yi),ta=n(yi,"DIV",{class:!0});var d$=s(ta);T(BP.$$.fragment,d$),Pet=i(d$),lxe=n(d$,"P",{});var $Fa=s(lxe);Bet=r($Fa,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),$Fa.forEach(t),Iet=i(d$),Lc=n(d$,"P",{});var gge=s(Lc);Net=r(gge,`Note:
Loading a model from its configuration file does `),ixe=n(gge,"STRONG",{});var kFa=s(ixe);qet=r(kFa,"not"),kFa.forEach(t),Det=r(gge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Gne=n(gge,"A",{href:!0});var SFa=s(Gne);jet=r(SFa,"from_pretrained()"),SFa.forEach(t),Get=r(gge," to load the model weights."),gge.forEach(t),Oet=i(d$),T(mA.$$.fragment,d$),d$.forEach(t),Vet=i(yi),Qr=n(yi,"DIV",{class:!0});var xi=s(Qr);T(IP.$$.fragment,xi),Xet=i(xi),dxe=n(xi,"P",{});var RFa=s(dxe);zet=r(RFa,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),RFa.forEach(t),Qet=i(xi),Vn=n(xi,"P",{});var m$=s(Vn);Wet=r(m$,"The model class to instantiate is selected based on the "),mxe=n(m$,"CODE",{});var PFa=s(mxe);Uet=r(PFa,"model_type"),PFa.forEach(t),Het=r(m$,` property of the config object (either
passed as an argument or loaded from `),cxe=n(m$,"CODE",{});var BFa=s(cxe);Jet=r(BFa,"pretrained_model_name_or_path"),BFa.forEach(t),Yet=r(m$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fxe=n(m$,"CODE",{});var IFa=s(fxe);Zet=r(IFa,"pretrained_model_name_or_path"),IFa.forEach(t),Ket=r(m$,":"),m$.forEach(t),eot=i(xi),Ce=n(xi,"UL",{});var Ae=s(Ce);cA=n(Ae,"LI",{});var Fro=s(cA);gxe=n(Fro,"STRONG",{});var NFa=s(gxe);oot=r(NFa,"bert"),NFa.forEach(t),rot=r(Fro," \u2014 "),One=n(Fro,"A",{href:!0});var qFa=s(One);tot=r(qFa,"TFBertLMHeadModel"),qFa.forEach(t),aot=r(Fro," (BERT model)"),Fro.forEach(t),not=i(Ae),fA=n(Ae,"LI",{});var Tro=s(fA);hxe=n(Tro,"STRONG",{});var DFa=s(hxe);sot=r(DFa,"camembert"),DFa.forEach(t),lot=r(Tro," \u2014 "),Vne=n(Tro,"A",{href:!0});var jFa=s(Vne);iot=r(jFa,"TFCamembertForCausalLM"),jFa.forEach(t),dot=r(Tro," (CamemBERT model)"),Tro.forEach(t),mot=i(Ae),gA=n(Ae,"LI",{});var Mro=s(gA);uxe=n(Mro,"STRONG",{});var GFa=s(uxe);cot=r(GFa,"ctrl"),GFa.forEach(t),fot=r(Mro," \u2014 "),Xne=n(Mro,"A",{href:!0});var OFa=s(Xne);got=r(OFa,"TFCTRLLMHeadModel"),OFa.forEach(t),hot=r(Mro," (CTRL model)"),Mro.forEach(t),uot=i(Ae),hA=n(Ae,"LI",{});var Ero=s(hA);pxe=n(Ero,"STRONG",{});var VFa=s(pxe);pot=r(VFa,"gpt2"),VFa.forEach(t),_ot=r(Ero," \u2014 "),zne=n(Ero,"A",{href:!0});var XFa=s(zne);bot=r(XFa,"TFGPT2LMHeadModel"),XFa.forEach(t),vot=r(Ero," (OpenAI GPT-2 model)"),Ero.forEach(t),Fot=i(Ae),uA=n(Ae,"LI",{});var Cro=s(uA);_xe=n(Cro,"STRONG",{});var zFa=s(_xe);Tot=r(zFa,"gptj"),zFa.forEach(t),Mot=r(Cro," \u2014 "),Qne=n(Cro,"A",{href:!0});var QFa=s(Qne);Eot=r(QFa,"TFGPTJForCausalLM"),QFa.forEach(t),Cot=r(Cro," (GPT-J model)"),Cro.forEach(t),wot=i(Ae),pA=n(Ae,"LI",{});var wro=s(pA);bxe=n(wro,"STRONG",{});var WFa=s(bxe);Aot=r(WFa,"openai-gpt"),WFa.forEach(t),Lot=r(wro," \u2014 "),Wne=n(wro,"A",{href:!0});var UFa=s(Wne);yot=r(UFa,"TFOpenAIGPTLMHeadModel"),UFa.forEach(t),xot=r(wro," (OpenAI GPT model)"),wro.forEach(t),$ot=i(Ae),_A=n(Ae,"LI",{});var Aro=s(_A);vxe=n(Aro,"STRONG",{});var HFa=s(vxe);kot=r(HFa,"opt"),HFa.forEach(t),Sot=r(Aro," \u2014 "),Une=n(Aro,"A",{href:!0});var JFa=s(Une);Rot=r(JFa,"TFOPTForCausalLM"),JFa.forEach(t),Pot=r(Aro," (OPT model)"),Aro.forEach(t),Bot=i(Ae),bA=n(Ae,"LI",{});var Lro=s(bA);Fxe=n(Lro,"STRONG",{});var YFa=s(Fxe);Iot=r(YFa,"rembert"),YFa.forEach(t),Not=r(Lro," \u2014 "),Hne=n(Lro,"A",{href:!0});var ZFa=s(Hne);qot=r(ZFa,"TFRemBertForCausalLM"),ZFa.forEach(t),Dot=r(Lro," (RemBERT model)"),Lro.forEach(t),jot=i(Ae),vA=n(Ae,"LI",{});var yro=s(vA);Txe=n(yro,"STRONG",{});var KFa=s(Txe);Got=r(KFa,"roberta"),KFa.forEach(t),Oot=r(yro," \u2014 "),Jne=n(yro,"A",{href:!0});var eTa=s(Jne);Vot=r(eTa,"TFRobertaForCausalLM"),eTa.forEach(t),Xot=r(yro," (RoBERTa model)"),yro.forEach(t),zot=i(Ae),FA=n(Ae,"LI",{});var xro=s(FA);Mxe=n(xro,"STRONG",{});var oTa=s(Mxe);Qot=r(oTa,"roformer"),oTa.forEach(t),Wot=r(xro," \u2014 "),Yne=n(xro,"A",{href:!0});var rTa=s(Yne);Uot=r(rTa,"TFRoFormerForCausalLM"),rTa.forEach(t),Hot=r(xro," (RoFormer model)"),xro.forEach(t),Jot=i(Ae),TA=n(Ae,"LI",{});var $ro=s(TA);Exe=n($ro,"STRONG",{});var tTa=s(Exe);Yot=r(tTa,"transfo-xl"),tTa.forEach(t),Zot=r($ro," \u2014 "),Zne=n($ro,"A",{href:!0});var aTa=s(Zne);Kot=r(aTa,"TFTransfoXLLMHeadModel"),aTa.forEach(t),ert=r($ro," (Transformer-XL model)"),$ro.forEach(t),ort=i(Ae),MA=n(Ae,"LI",{});var kro=s(MA);Cxe=n(kro,"STRONG",{});var nTa=s(Cxe);rrt=r(nTa,"xglm"),nTa.forEach(t),trt=r(kro," \u2014 "),Kne=n(kro,"A",{href:!0});var sTa=s(Kne);art=r(sTa,"TFXGLMForCausalLM"),sTa.forEach(t),nrt=r(kro," (XGLM model)"),kro.forEach(t),srt=i(Ae),EA=n(Ae,"LI",{});var Sro=s(EA);wxe=n(Sro,"STRONG",{});var lTa=s(wxe);lrt=r(lTa,"xlm"),lTa.forEach(t),irt=r(Sro," \u2014 "),ese=n(Sro,"A",{href:!0});var iTa=s(ese);drt=r(iTa,"TFXLMWithLMHeadModel"),iTa.forEach(t),mrt=r(Sro," (XLM model)"),Sro.forEach(t),crt=i(Ae),CA=n(Ae,"LI",{});var Rro=s(CA);Axe=n(Rro,"STRONG",{});var dTa=s(Axe);frt=r(dTa,"xlnet"),dTa.forEach(t),grt=r(Rro," \u2014 "),ose=n(Rro,"A",{href:!0});var mTa=s(ose);hrt=r(mTa,"TFXLNetLMHeadModel"),mTa.forEach(t),urt=r(Rro," (XLNet model)"),Rro.forEach(t),Ae.forEach(t),prt=i(xi),T(wA.$$.fragment,xi),xi.forEach(t),yi.forEach(t),Bio=i(c),yc=n(c,"H2",{class:!0});var aco=s(yc);AA=n(aco,"A",{id:!0,class:!0,href:!0});var cTa=s(AA);Lxe=n(cTa,"SPAN",{});var fTa=s(Lxe);T(NP.$$.fragment,fTa),fTa.forEach(t),cTa.forEach(t),_rt=i(aco),yxe=n(aco,"SPAN",{});var gTa=s(yxe);brt=r(gTa,"TFAutoModelForImageClassification"),gTa.forEach(t),aco.forEach(t),Iio=i(c),_r=n(c,"DIV",{class:!0});var $i=s(_r);T(qP.$$.fragment,$i),vrt=i($i),xc=n($i,"P",{});var hge=s(xc);Frt=r(hge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),rse=n(hge,"A",{href:!0});var hTa=s(rse);Trt=r(hTa,"from_pretrained()"),hTa.forEach(t),Mrt=r(hge," class method or the "),tse=n(hge,"A",{href:!0});var uTa=s(tse);Ert=r(uTa,"from_config()"),uTa.forEach(t),Crt=r(hge,` class
method.`),hge.forEach(t),wrt=i($i),DP=n($i,"P",{});var nco=s(DP);Art=r(nco,"This class cannot be instantiated directly using "),xxe=n(nco,"CODE",{});var pTa=s(xxe);Lrt=r(pTa,"__init__()"),pTa.forEach(t),yrt=r(nco," (throws an error)."),nco.forEach(t),xrt=i($i),aa=n($i,"DIV",{class:!0});var c$=s(aa);T(jP.$$.fragment,c$),$rt=i(c$),$xe=n(c$,"P",{});var _Ta=s($xe);krt=r(_Ta,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),_Ta.forEach(t),Srt=i(c$),$c=n(c$,"P",{});var uge=s($c);Rrt=r(uge,`Note:
Loading a model from its configuration file does `),kxe=n(uge,"STRONG",{});var bTa=s(kxe);Prt=r(bTa,"not"),bTa.forEach(t),Brt=r(uge,` load the model weights. It only affects the
model\u2019s configuration. Use `),ase=n(uge,"A",{href:!0});var vTa=s(ase);Irt=r(vTa,"from_pretrained()"),vTa.forEach(t),Nrt=r(uge," to load the model weights."),uge.forEach(t),qrt=i(c$),T(LA.$$.fragment,c$),c$.forEach(t),Drt=i($i),Wr=n($i,"DIV",{class:!0});var ki=s(Wr);T(GP.$$.fragment,ki),jrt=i(ki),Sxe=n(ki,"P",{});var FTa=s(Sxe);Grt=r(FTa,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),FTa.forEach(t),Ort=i(ki),Xn=n(ki,"P",{});var f$=s(Xn);Vrt=r(f$,"The model class to instantiate is selected based on the "),Rxe=n(f$,"CODE",{});var TTa=s(Rxe);Xrt=r(TTa,"model_type"),TTa.forEach(t),zrt=r(f$,` property of the config object (either
passed as an argument or loaded from `),Pxe=n(f$,"CODE",{});var MTa=s(Pxe);Qrt=r(MTa,"pretrained_model_name_or_path"),MTa.forEach(t),Wrt=r(f$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bxe=n(f$,"CODE",{});var ETa=s(Bxe);Urt=r(ETa,"pretrained_model_name_or_path"),ETa.forEach(t),Hrt=r(f$,":"),f$.forEach(t),Jrt=i(ki),$e=n(ki,"UL",{});var De=s($e);yA=n(De,"LI",{});var Pro=s(yA);Ixe=n(Pro,"STRONG",{});var CTa=s(Ixe);Yrt=r(CTa,"convnext"),CTa.forEach(t),Zrt=r(Pro," \u2014 "),nse=n(Pro,"A",{href:!0});var wTa=s(nse);Krt=r(wTa,"TFConvNextForImageClassification"),wTa.forEach(t),ett=r(Pro," (ConvNeXT model)"),Pro.forEach(t),ott=i(De),xA=n(De,"LI",{});var Bro=s(xA);Nxe=n(Bro,"STRONG",{});var ATa=s(Nxe);rtt=r(ATa,"cvt"),ATa.forEach(t),ttt=r(Bro," \u2014 "),sse=n(Bro,"A",{href:!0});var LTa=s(sse);att=r(LTa,"TFCvtForImageClassification"),LTa.forEach(t),ntt=r(Bro," (CvT model)"),Bro.forEach(t),stt=i(De),$A=n(De,"LI",{});var Iro=s($A);qxe=n(Iro,"STRONG",{});var yTa=s(qxe);ltt=r(yTa,"data2vec-vision"),yTa.forEach(t),itt=r(Iro," \u2014 "),lse=n(Iro,"A",{href:!0});var xTa=s(lse);dtt=r(xTa,"TFData2VecVisionForImageClassification"),xTa.forEach(t),mtt=r(Iro," (Data2VecVision model)"),Iro.forEach(t),ctt=i(De),jl=n(De,"LI",{});var $q=s(jl);Dxe=n($q,"STRONG",{});var $Ta=s(Dxe);ftt=r($Ta,"deit"),$Ta.forEach(t),gtt=r($q," \u2014 "),ise=n($q,"A",{href:!0});var kTa=s(ise);htt=r(kTa,"TFDeiTForImageClassification"),kTa.forEach(t),utt=r($q," or "),dse=n($q,"A",{href:!0});var STa=s(dse);ptt=r(STa,"TFDeiTForImageClassificationWithTeacher"),STa.forEach(t),_tt=r($q," (DeiT model)"),$q.forEach(t),btt=i(De),kA=n(De,"LI",{});var Nro=s(kA);jxe=n(Nro,"STRONG",{});var RTa=s(jxe);vtt=r(RTa,"mobilevit"),RTa.forEach(t),Ftt=r(Nro," \u2014 "),mse=n(Nro,"A",{href:!0});var PTa=s(mse);Ttt=r(PTa,"TFMobileViTForImageClassification"),PTa.forEach(t),Mtt=r(Nro," (MobileViT model)"),Nro.forEach(t),Ett=i(De),SA=n(De,"LI",{});var qro=s(SA);Gxe=n(qro,"STRONG",{});var BTa=s(Gxe);Ctt=r(BTa,"regnet"),BTa.forEach(t),wtt=r(qro," \u2014 "),cse=n(qro,"A",{href:!0});var ITa=s(cse);Att=r(ITa,"TFRegNetForImageClassification"),ITa.forEach(t),Ltt=r(qro," (RegNet model)"),qro.forEach(t),ytt=i(De),RA=n(De,"LI",{});var Dro=s(RA);Oxe=n(Dro,"STRONG",{});var NTa=s(Oxe);xtt=r(NTa,"resnet"),NTa.forEach(t),$tt=r(Dro," \u2014 "),fse=n(Dro,"A",{href:!0});var qTa=s(fse);ktt=r(qTa,"TFResNetForImageClassification"),qTa.forEach(t),Stt=r(Dro," (ResNet model)"),Dro.forEach(t),Rtt=i(De),PA=n(De,"LI",{});var jro=s(PA);Vxe=n(jro,"STRONG",{});var DTa=s(Vxe);Ptt=r(DTa,"segformer"),DTa.forEach(t),Btt=r(jro," \u2014 "),gse=n(jro,"A",{href:!0});var jTa=s(gse);Itt=r(jTa,"TFSegformerForImageClassification"),jTa.forEach(t),Ntt=r(jro," (SegFormer model)"),jro.forEach(t),qtt=i(De),BA=n(De,"LI",{});var Gro=s(BA);Xxe=n(Gro,"STRONG",{});var GTa=s(Xxe);Dtt=r(GTa,"swin"),GTa.forEach(t),jtt=r(Gro," \u2014 "),hse=n(Gro,"A",{href:!0});var OTa=s(hse);Gtt=r(OTa,"TFSwinForImageClassification"),OTa.forEach(t),Ott=r(Gro," (Swin Transformer model)"),Gro.forEach(t),Vtt=i(De),IA=n(De,"LI",{});var Oro=s(IA);zxe=n(Oro,"STRONG",{});var VTa=s(zxe);Xtt=r(VTa,"vit"),VTa.forEach(t),ztt=r(Oro," \u2014 "),use=n(Oro,"A",{href:!0});var XTa=s(use);Qtt=r(XTa,"TFViTForImageClassification"),XTa.forEach(t),Wtt=r(Oro," (ViT model)"),Oro.forEach(t),De.forEach(t),Utt=i(ki),T(NA.$$.fragment,ki),ki.forEach(t),$i.forEach(t),Nio=i(c),kc=n(c,"H2",{class:!0});var sco=s(kc);qA=n(sco,"A",{id:!0,class:!0,href:!0});var zTa=s(qA);Qxe=n(zTa,"SPAN",{});var QTa=s(Qxe);T(OP.$$.fragment,QTa),QTa.forEach(t),zTa.forEach(t),Htt=i(sco),Wxe=n(sco,"SPAN",{});var WTa=s(Wxe);Jtt=r(WTa,"TFAutoModelForSemanticSegmentation"),WTa.forEach(t),sco.forEach(t),qio=i(c),br=n(c,"DIV",{class:!0});var Si=s(br);T(VP.$$.fragment,Si),Ytt=i(Si),Sc=n(Si,"P",{});var pge=s(Sc);Ztt=r(pge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),pse=n(pge,"A",{href:!0});var UTa=s(pse);Ktt=r(UTa,"from_pretrained()"),UTa.forEach(t),eat=r(pge," class method or the "),_se=n(pge,"A",{href:!0});var HTa=s(_se);oat=r(HTa,"from_config()"),HTa.forEach(t),rat=r(pge,` class
method.`),pge.forEach(t),tat=i(Si),XP=n(Si,"P",{});var lco=s(XP);aat=r(lco,"This class cannot be instantiated directly using "),Uxe=n(lco,"CODE",{});var JTa=s(Uxe);nat=r(JTa,"__init__()"),JTa.forEach(t),sat=r(lco," (throws an error)."),lco.forEach(t),lat=i(Si),na=n(Si,"DIV",{class:!0});var g$=s(na);T(zP.$$.fragment,g$),iat=i(g$),Hxe=n(g$,"P",{});var YTa=s(Hxe);dat=r(YTa,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),YTa.forEach(t),mat=i(g$),Rc=n(g$,"P",{});var _ge=s(Rc);cat=r(_ge,`Note:
Loading a model from its configuration file does `),Jxe=n(_ge,"STRONG",{});var ZTa=s(Jxe);fat=r(ZTa,"not"),ZTa.forEach(t),gat=r(_ge,` load the model weights. It only affects the
model\u2019s configuration. Use `),bse=n(_ge,"A",{href:!0});var KTa=s(bse);hat=r(KTa,"from_pretrained()"),KTa.forEach(t),uat=r(_ge," to load the model weights."),_ge.forEach(t),pat=i(g$),T(DA.$$.fragment,g$),g$.forEach(t),_at=i(Si),Ur=n(Si,"DIV",{class:!0});var Ri=s(Ur);T(QP.$$.fragment,Ri),bat=i(Ri),Yxe=n(Ri,"P",{});var eMa=s(Yxe);vat=r(eMa,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),eMa.forEach(t),Fat=i(Ri),zn=n(Ri,"P",{});var h$=s(zn);Tat=r(h$,"The model class to instantiate is selected based on the "),Zxe=n(h$,"CODE",{});var oMa=s(Zxe);Mat=r(oMa,"model_type"),oMa.forEach(t),Eat=r(h$,` property of the config object (either
passed as an argument or loaded from `),Kxe=n(h$,"CODE",{});var rMa=s(Kxe);Cat=r(rMa,"pretrained_model_name_or_path"),rMa.forEach(t),wat=r(h$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e$e=n(h$,"CODE",{});var tMa=s(e$e);Aat=r(tMa,"pretrained_model_name_or_path"),tMa.forEach(t),Lat=r(h$,":"),h$.forEach(t),yat=i(Ri),Pc=n(Ri,"UL",{});var bge=s(Pc);jA=n(bge,"LI",{});var Vro=s(jA);o$e=n(Vro,"STRONG",{});var aMa=s(o$e);xat=r(aMa,"data2vec-vision"),aMa.forEach(t),$at=r(Vro," \u2014 "),vse=n(Vro,"A",{href:!0});var nMa=s(vse);kat=r(nMa,"TFData2VecVisionForSemanticSegmentation"),nMa.forEach(t),Sat=r(Vro," (Data2VecVision model)"),Vro.forEach(t),Rat=i(bge),GA=n(bge,"LI",{});var Xro=s(GA);r$e=n(Xro,"STRONG",{});var sMa=s(r$e);Pat=r(sMa,"mobilevit"),sMa.forEach(t),Bat=r(Xro," \u2014 "),Fse=n(Xro,"A",{href:!0});var lMa=s(Fse);Iat=r(lMa,"TFMobileViTForSemanticSegmentation"),lMa.forEach(t),Nat=r(Xro," (MobileViT model)"),Xro.forEach(t),qat=i(bge),OA=n(bge,"LI",{});var zro=s(OA);t$e=n(zro,"STRONG",{});var iMa=s(t$e);Dat=r(iMa,"segformer"),iMa.forEach(t),jat=r(zro," \u2014 "),Tse=n(zro,"A",{href:!0});var dMa=s(Tse);Gat=r(dMa,"TFSegformerForSemanticSegmentation"),dMa.forEach(t),Oat=r(zro," (SegFormer model)"),zro.forEach(t),bge.forEach(t),Vat=i(Ri),T(VA.$$.fragment,Ri),Ri.forEach(t),Si.forEach(t),Dio=i(c),Bc=n(c,"H2",{class:!0});var ico=s(Bc);XA=n(ico,"A",{id:!0,class:!0,href:!0});var mMa=s(XA);a$e=n(mMa,"SPAN",{});var cMa=s(a$e);T(WP.$$.fragment,cMa),cMa.forEach(t),mMa.forEach(t),Xat=i(ico),n$e=n(ico,"SPAN",{});var fMa=s(n$e);zat=r(fMa,"TFAutoModelForMaskedLM"),fMa.forEach(t),ico.forEach(t),jio=i(c),vr=n(c,"DIV",{class:!0});var Pi=s(vr);T(UP.$$.fragment,Pi),Qat=i(Pi),Ic=n(Pi,"P",{});var vge=s(Ic);Wat=r(vge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Mse=n(vge,"A",{href:!0});var gMa=s(Mse);Uat=r(gMa,"from_pretrained()"),gMa.forEach(t),Hat=r(vge," class method or the "),Ese=n(vge,"A",{href:!0});var hMa=s(Ese);Jat=r(hMa,"from_config()"),hMa.forEach(t),Yat=r(vge,` class
method.`),vge.forEach(t),Zat=i(Pi),HP=n(Pi,"P",{});var dco=s(HP);Kat=r(dco,"This class cannot be instantiated directly using "),s$e=n(dco,"CODE",{});var uMa=s(s$e);ent=r(uMa,"__init__()"),uMa.forEach(t),ont=r(dco," (throws an error)."),dco.forEach(t),rnt=i(Pi),sa=n(Pi,"DIV",{class:!0});var u$=s(sa);T(JP.$$.fragment,u$),tnt=i(u$),l$e=n(u$,"P",{});var pMa=s(l$e);ant=r(pMa,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),pMa.forEach(t),nnt=i(u$),Nc=n(u$,"P",{});var Fge=s(Nc);snt=r(Fge,`Note:
Loading a model from its configuration file does `),i$e=n(Fge,"STRONG",{});var _Ma=s(i$e);lnt=r(_Ma,"not"),_Ma.forEach(t),int=r(Fge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Cse=n(Fge,"A",{href:!0});var bMa=s(Cse);dnt=r(bMa,"from_pretrained()"),bMa.forEach(t),mnt=r(Fge," to load the model weights."),Fge.forEach(t),cnt=i(u$),T(zA.$$.fragment,u$),u$.forEach(t),fnt=i(Pi),Hr=n(Pi,"DIV",{class:!0});var Bi=s(Hr);T(YP.$$.fragment,Bi),gnt=i(Bi),d$e=n(Bi,"P",{});var vMa=s(d$e);hnt=r(vMa,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),vMa.forEach(t),unt=i(Bi),Qn=n(Bi,"P",{});var p$=s(Qn);pnt=r(p$,"The model class to instantiate is selected based on the "),m$e=n(p$,"CODE",{});var FMa=s(m$e);_nt=r(FMa,"model_type"),FMa.forEach(t),bnt=r(p$,` property of the config object (either
passed as an argument or loaded from `),c$e=n(p$,"CODE",{});var TMa=s(c$e);vnt=r(TMa,"pretrained_model_name_or_path"),TMa.forEach(t),Fnt=r(p$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f$e=n(p$,"CODE",{});var MMa=s(f$e);Tnt=r(MMa,"pretrained_model_name_or_path"),MMa.forEach(t),Mnt=r(p$,":"),p$.forEach(t),Ent=i(Bi),ge=n(Bi,"UL",{});var _e=s(ge);QA=n(_e,"LI",{});var Qro=s(QA);g$e=n(Qro,"STRONG",{});var EMa=s(g$e);Cnt=r(EMa,"albert"),EMa.forEach(t),wnt=r(Qro," \u2014 "),wse=n(Qro,"A",{href:!0});var CMa=s(wse);Ant=r(CMa,"TFAlbertForMaskedLM"),CMa.forEach(t),Lnt=r(Qro," (ALBERT model)"),Qro.forEach(t),ynt=i(_e),WA=n(_e,"LI",{});var Wro=s(WA);h$e=n(Wro,"STRONG",{});var wMa=s(h$e);xnt=r(wMa,"bert"),wMa.forEach(t),$nt=r(Wro," \u2014 "),Ase=n(Wro,"A",{href:!0});var AMa=s(Ase);knt=r(AMa,"TFBertForMaskedLM"),AMa.forEach(t),Snt=r(Wro," (BERT model)"),Wro.forEach(t),Rnt=i(_e),UA=n(_e,"LI",{});var Uro=s(UA);u$e=n(Uro,"STRONG",{});var LMa=s(u$e);Pnt=r(LMa,"camembert"),LMa.forEach(t),Bnt=r(Uro," \u2014 "),Lse=n(Uro,"A",{href:!0});var yMa=s(Lse);Int=r(yMa,"TFCamembertForMaskedLM"),yMa.forEach(t),Nnt=r(Uro," (CamemBERT model)"),Uro.forEach(t),qnt=i(_e),HA=n(_e,"LI",{});var Hro=s(HA);p$e=n(Hro,"STRONG",{});var xMa=s(p$e);Dnt=r(xMa,"convbert"),xMa.forEach(t),jnt=r(Hro," \u2014 "),yse=n(Hro,"A",{href:!0});var $Ma=s(yse);Gnt=r($Ma,"TFConvBertForMaskedLM"),$Ma.forEach(t),Ont=r(Hro," (ConvBERT model)"),Hro.forEach(t),Vnt=i(_e),JA=n(_e,"LI",{});var Jro=s(JA);_$e=n(Jro,"STRONG",{});var kMa=s(_$e);Xnt=r(kMa,"deberta"),kMa.forEach(t),znt=r(Jro," \u2014 "),xse=n(Jro,"A",{href:!0});var SMa=s(xse);Qnt=r(SMa,"TFDebertaForMaskedLM"),SMa.forEach(t),Wnt=r(Jro," (DeBERTa model)"),Jro.forEach(t),Unt=i(_e),YA=n(_e,"LI",{});var Yro=s(YA);b$e=n(Yro,"STRONG",{});var RMa=s(b$e);Hnt=r(RMa,"deberta-v2"),RMa.forEach(t),Jnt=r(Yro," \u2014 "),$se=n(Yro,"A",{href:!0});var PMa=s($se);Ynt=r(PMa,"TFDebertaV2ForMaskedLM"),PMa.forEach(t),Znt=r(Yro," (DeBERTa-v2 model)"),Yro.forEach(t),Knt=i(_e),ZA=n(_e,"LI",{});var Zro=s(ZA);v$e=n(Zro,"STRONG",{});var BMa=s(v$e);est=r(BMa,"distilbert"),BMa.forEach(t),ost=r(Zro," \u2014 "),kse=n(Zro,"A",{href:!0});var IMa=s(kse);rst=r(IMa,"TFDistilBertForMaskedLM"),IMa.forEach(t),tst=r(Zro," (DistilBERT model)"),Zro.forEach(t),ast=i(_e),KA=n(_e,"LI",{});var Kro=s(KA);F$e=n(Kro,"STRONG",{});var NMa=s(F$e);nst=r(NMa,"electra"),NMa.forEach(t),sst=r(Kro," \u2014 "),Sse=n(Kro,"A",{href:!0});var qMa=s(Sse);lst=r(qMa,"TFElectraForMaskedLM"),qMa.forEach(t),ist=r(Kro," (ELECTRA model)"),Kro.forEach(t),dst=i(_e),e6=n(_e,"LI",{});var eto=s(e6);T$e=n(eto,"STRONG",{});var DMa=s(T$e);mst=r(DMa,"esm"),DMa.forEach(t),cst=r(eto," \u2014 "),Rse=n(eto,"A",{href:!0});var jMa=s(Rse);fst=r(jMa,"TFEsmForMaskedLM"),jMa.forEach(t),gst=r(eto," (ESM model)"),eto.forEach(t),hst=i(_e),o6=n(_e,"LI",{});var oto=s(o6);M$e=n(oto,"STRONG",{});var GMa=s(M$e);ust=r(GMa,"flaubert"),GMa.forEach(t),pst=r(oto," \u2014 "),Pse=n(oto,"A",{href:!0});var OMa=s(Pse);_st=r(OMa,"TFFlaubertWithLMHeadModel"),OMa.forEach(t),bst=r(oto," (FlauBERT model)"),oto.forEach(t),vst=i(_e),r6=n(_e,"LI",{});var rto=s(r6);E$e=n(rto,"STRONG",{});var VMa=s(E$e);Fst=r(VMa,"funnel"),VMa.forEach(t),Tst=r(rto," \u2014 "),Bse=n(rto,"A",{href:!0});var XMa=s(Bse);Mst=r(XMa,"TFFunnelForMaskedLM"),XMa.forEach(t),Est=r(rto," (Funnel Transformer model)"),rto.forEach(t),Cst=i(_e),t6=n(_e,"LI",{});var tto=s(t6);C$e=n(tto,"STRONG",{});var zMa=s(C$e);wst=r(zMa,"layoutlm"),zMa.forEach(t),Ast=r(tto," \u2014 "),Ise=n(tto,"A",{href:!0});var QMa=s(Ise);Lst=r(QMa,"TFLayoutLMForMaskedLM"),QMa.forEach(t),yst=r(tto," (LayoutLM model)"),tto.forEach(t),xst=i(_e),a6=n(_e,"LI",{});var ato=s(a6);w$e=n(ato,"STRONG",{});var WMa=s(w$e);$st=r(WMa,"longformer"),WMa.forEach(t),kst=r(ato," \u2014 "),Nse=n(ato,"A",{href:!0});var UMa=s(Nse);Sst=r(UMa,"TFLongformerForMaskedLM"),UMa.forEach(t),Rst=r(ato," (Longformer model)"),ato.forEach(t),Pst=i(_e),n6=n(_e,"LI",{});var nto=s(n6);A$e=n(nto,"STRONG",{});var HMa=s(A$e);Bst=r(HMa,"mobilebert"),HMa.forEach(t),Ist=r(nto," \u2014 "),qse=n(nto,"A",{href:!0});var JMa=s(qse);Nst=r(JMa,"TFMobileBertForMaskedLM"),JMa.forEach(t),qst=r(nto," (MobileBERT model)"),nto.forEach(t),Dst=i(_e),s6=n(_e,"LI",{});var sto=s(s6);L$e=n(sto,"STRONG",{});var YMa=s(L$e);jst=r(YMa,"mpnet"),YMa.forEach(t),Gst=r(sto," \u2014 "),Dse=n(sto,"A",{href:!0});var ZMa=s(Dse);Ost=r(ZMa,"TFMPNetForMaskedLM"),ZMa.forEach(t),Vst=r(sto," (MPNet model)"),sto.forEach(t),Xst=i(_e),l6=n(_e,"LI",{});var lto=s(l6);y$e=n(lto,"STRONG",{});var KMa=s(y$e);zst=r(KMa,"rembert"),KMa.forEach(t),Qst=r(lto," \u2014 "),jse=n(lto,"A",{href:!0});var eEa=s(jse);Wst=r(eEa,"TFRemBertForMaskedLM"),eEa.forEach(t),Ust=r(lto," (RemBERT model)"),lto.forEach(t),Hst=i(_e),i6=n(_e,"LI",{});var ito=s(i6);x$e=n(ito,"STRONG",{});var oEa=s(x$e);Jst=r(oEa,"roberta"),oEa.forEach(t),Yst=r(ito," \u2014 "),Gse=n(ito,"A",{href:!0});var rEa=s(Gse);Zst=r(rEa,"TFRobertaForMaskedLM"),rEa.forEach(t),Kst=r(ito," (RoBERTa model)"),ito.forEach(t),elt=i(_e),d6=n(_e,"LI",{});var dto=s(d6);$$e=n(dto,"STRONG",{});var tEa=s($$e);olt=r(tEa,"roformer"),tEa.forEach(t),rlt=r(dto," \u2014 "),Ose=n(dto,"A",{href:!0});var aEa=s(Ose);tlt=r(aEa,"TFRoFormerForMaskedLM"),aEa.forEach(t),alt=r(dto," (RoFormer model)"),dto.forEach(t),nlt=i(_e),m6=n(_e,"LI",{});var mto=s(m6);k$e=n(mto,"STRONG",{});var nEa=s(k$e);slt=r(nEa,"tapas"),nEa.forEach(t),llt=r(mto," \u2014 "),Vse=n(mto,"A",{href:!0});var sEa=s(Vse);ilt=r(sEa,"TFTapasForMaskedLM"),sEa.forEach(t),dlt=r(mto," (TAPAS model)"),mto.forEach(t),mlt=i(_e),c6=n(_e,"LI",{});var cto=s(c6);S$e=n(cto,"STRONG",{});var lEa=s(S$e);clt=r(lEa,"xlm"),lEa.forEach(t),flt=r(cto," \u2014 "),Xse=n(cto,"A",{href:!0});var iEa=s(Xse);glt=r(iEa,"TFXLMWithLMHeadModel"),iEa.forEach(t),hlt=r(cto," (XLM model)"),cto.forEach(t),ult=i(_e),f6=n(_e,"LI",{});var fto=s(f6);R$e=n(fto,"STRONG",{});var dEa=s(R$e);plt=r(dEa,"xlm-roberta"),dEa.forEach(t),_lt=r(fto," \u2014 "),zse=n(fto,"A",{href:!0});var mEa=s(zse);blt=r(mEa,"TFXLMRobertaForMaskedLM"),mEa.forEach(t),vlt=r(fto," (XLM-RoBERTa model)"),fto.forEach(t),_e.forEach(t),Flt=i(Bi),T(g6.$$.fragment,Bi),Bi.forEach(t),Pi.forEach(t),Gio=i(c),qc=n(c,"H2",{class:!0});var mco=s(qc);h6=n(mco,"A",{id:!0,class:!0,href:!0});var cEa=s(h6);P$e=n(cEa,"SPAN",{});var fEa=s(P$e);T(ZP.$$.fragment,fEa),fEa.forEach(t),cEa.forEach(t),Tlt=i(mco),B$e=n(mco,"SPAN",{});var gEa=s(B$e);Mlt=r(gEa,"TFAutoModelForSeq2SeqLM"),gEa.forEach(t),mco.forEach(t),Oio=i(c),Fr=n(c,"DIV",{class:!0});var Ii=s(Fr);T(KP.$$.fragment,Ii),Elt=i(Ii),Dc=n(Ii,"P",{});var Tge=s(Dc);Clt=r(Tge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Qse=n(Tge,"A",{href:!0});var hEa=s(Qse);wlt=r(hEa,"from_pretrained()"),hEa.forEach(t),Alt=r(Tge," class method or the "),Wse=n(Tge,"A",{href:!0});var uEa=s(Wse);Llt=r(uEa,"from_config()"),uEa.forEach(t),ylt=r(Tge,` class
method.`),Tge.forEach(t),xlt=i(Ii),eB=n(Ii,"P",{});var cco=s(eB);$lt=r(cco,"This class cannot be instantiated directly using "),I$e=n(cco,"CODE",{});var pEa=s(I$e);klt=r(pEa,"__init__()"),pEa.forEach(t),Slt=r(cco," (throws an error)."),cco.forEach(t),Rlt=i(Ii),la=n(Ii,"DIV",{class:!0});var _$=s(la);T(oB.$$.fragment,_$),Plt=i(_$),N$e=n(_$,"P",{});var _Ea=s(N$e);Blt=r(_Ea,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),_Ea.forEach(t),Ilt=i(_$),jc=n(_$,"P",{});var Mge=s(jc);Nlt=r(Mge,`Note:
Loading a model from its configuration file does `),q$e=n(Mge,"STRONG",{});var bEa=s(q$e);qlt=r(bEa,"not"),bEa.forEach(t),Dlt=r(Mge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Use=n(Mge,"A",{href:!0});var vEa=s(Use);jlt=r(vEa,"from_pretrained()"),vEa.forEach(t),Glt=r(Mge," to load the model weights."),Mge.forEach(t),Olt=i(_$),T(u6.$$.fragment,_$),_$.forEach(t),Vlt=i(Ii),Jr=n(Ii,"DIV",{class:!0});var Ni=s(Jr);T(rB.$$.fragment,Ni),Xlt=i(Ni),D$e=n(Ni,"P",{});var FEa=s(D$e);zlt=r(FEa,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),FEa.forEach(t),Qlt=i(Ni),Wn=n(Ni,"P",{});var b$=s(Wn);Wlt=r(b$,"The model class to instantiate is selected based on the "),j$e=n(b$,"CODE",{});var TEa=s(j$e);Ult=r(TEa,"model_type"),TEa.forEach(t),Hlt=r(b$,` property of the config object (either
passed as an argument or loaded from `),G$e=n(b$,"CODE",{});var MEa=s(G$e);Jlt=r(MEa,"pretrained_model_name_or_path"),MEa.forEach(t),Ylt=r(b$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O$e=n(b$,"CODE",{});var EEa=s(O$e);Zlt=r(EEa,"pretrained_model_name_or_path"),EEa.forEach(t),Klt=r(b$,":"),b$.forEach(t),eit=i(Ni),ke=n(Ni,"UL",{});var je=s(ke);p6=n(je,"LI",{});var gto=s(p6);V$e=n(gto,"STRONG",{});var CEa=s(V$e);oit=r(CEa,"bart"),CEa.forEach(t),rit=r(gto," \u2014 "),Hse=n(gto,"A",{href:!0});var wEa=s(Hse);tit=r(wEa,"TFBartForConditionalGeneration"),wEa.forEach(t),ait=r(gto," (BART model)"),gto.forEach(t),nit=i(je),_6=n(je,"LI",{});var hto=s(_6);X$e=n(hto,"STRONG",{});var AEa=s(X$e);sit=r(AEa,"blenderbot"),AEa.forEach(t),lit=r(hto," \u2014 "),Jse=n(hto,"A",{href:!0});var LEa=s(Jse);iit=r(LEa,"TFBlenderbotForConditionalGeneration"),LEa.forEach(t),dit=r(hto," (Blenderbot model)"),hto.forEach(t),mit=i(je),b6=n(je,"LI",{});var uto=s(b6);z$e=n(uto,"STRONG",{});var yEa=s(z$e);cit=r(yEa,"blenderbot-small"),yEa.forEach(t),fit=r(uto," \u2014 "),Yse=n(uto,"A",{href:!0});var xEa=s(Yse);git=r(xEa,"TFBlenderbotSmallForConditionalGeneration"),xEa.forEach(t),hit=r(uto," (BlenderbotSmall model)"),uto.forEach(t),uit=i(je),v6=n(je,"LI",{});var pto=s(v6);Q$e=n(pto,"STRONG",{});var $Ea=s(Q$e);pit=r($Ea,"encoder-decoder"),$Ea.forEach(t),_it=r(pto," \u2014 "),Zse=n(pto,"A",{href:!0});var kEa=s(Zse);bit=r(kEa,"TFEncoderDecoderModel"),kEa.forEach(t),vit=r(pto," (Encoder decoder model)"),pto.forEach(t),Fit=i(je),F6=n(je,"LI",{});var _to=s(F6);W$e=n(_to,"STRONG",{});var SEa=s(W$e);Tit=r(SEa,"led"),SEa.forEach(t),Mit=r(_to," \u2014 "),Kse=n(_to,"A",{href:!0});var REa=s(Kse);Eit=r(REa,"TFLEDForConditionalGeneration"),REa.forEach(t),Cit=r(_to," (LED model)"),_to.forEach(t),wit=i(je),T6=n(je,"LI",{});var bto=s(T6);U$e=n(bto,"STRONG",{});var PEa=s(U$e);Ait=r(PEa,"marian"),PEa.forEach(t),Lit=r(bto," \u2014 "),ele=n(bto,"A",{href:!0});var BEa=s(ele);yit=r(BEa,"TFMarianMTModel"),BEa.forEach(t),xit=r(bto," (Marian model)"),bto.forEach(t),$it=i(je),M6=n(je,"LI",{});var vto=s(M6);H$e=n(vto,"STRONG",{});var IEa=s(H$e);kit=r(IEa,"mbart"),IEa.forEach(t),Sit=r(vto," \u2014 "),ole=n(vto,"A",{href:!0});var NEa=s(ole);Rit=r(NEa,"TFMBartForConditionalGeneration"),NEa.forEach(t),Pit=r(vto," (mBART model)"),vto.forEach(t),Bit=i(je),E6=n(je,"LI",{});var Fto=s(E6);J$e=n(Fto,"STRONG",{});var qEa=s(J$e);Iit=r(qEa,"mt5"),qEa.forEach(t),Nit=r(Fto," \u2014 "),rle=n(Fto,"A",{href:!0});var DEa=s(rle);qit=r(DEa,"TFMT5ForConditionalGeneration"),DEa.forEach(t),Dit=r(Fto," (MT5 model)"),Fto.forEach(t),jit=i(je),C6=n(je,"LI",{});var Tto=s(C6);Y$e=n(Tto,"STRONG",{});var jEa=s(Y$e);Git=r(jEa,"pegasus"),jEa.forEach(t),Oit=r(Tto," \u2014 "),tle=n(Tto,"A",{href:!0});var GEa=s(tle);Vit=r(GEa,"TFPegasusForConditionalGeneration"),GEa.forEach(t),Xit=r(Tto," (Pegasus model)"),Tto.forEach(t),zit=i(je),w6=n(je,"LI",{});var Mto=s(w6);Z$e=n(Mto,"STRONG",{});var OEa=s(Z$e);Qit=r(OEa,"t5"),OEa.forEach(t),Wit=r(Mto," \u2014 "),ale=n(Mto,"A",{href:!0});var VEa=s(ale);Uit=r(VEa,"TFT5ForConditionalGeneration"),VEa.forEach(t),Hit=r(Mto," (T5 model)"),Mto.forEach(t),je.forEach(t),Jit=i(Ni),T(A6.$$.fragment,Ni),Ni.forEach(t),Ii.forEach(t),Vio=i(c),Gc=n(c,"H2",{class:!0});var fco=s(Gc);L6=n(fco,"A",{id:!0,class:!0,href:!0});var XEa=s(L6);K$e=n(XEa,"SPAN",{});var zEa=s(K$e);T(tB.$$.fragment,zEa),zEa.forEach(t),XEa.forEach(t),Yit=i(fco),eke=n(fco,"SPAN",{});var QEa=s(eke);Zit=r(QEa,"TFAutoModelForSequenceClassification"),QEa.forEach(t),fco.forEach(t),Xio=i(c),Tr=n(c,"DIV",{class:!0});var qi=s(Tr);T(aB.$$.fragment,qi),Kit=i(qi),Oc=n(qi,"P",{});var Ege=s(Oc);edt=r(Ege,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),nle=n(Ege,"A",{href:!0});var WEa=s(nle);odt=r(WEa,"from_pretrained()"),WEa.forEach(t),rdt=r(Ege," class method or the "),sle=n(Ege,"A",{href:!0});var UEa=s(sle);tdt=r(UEa,"from_config()"),UEa.forEach(t),adt=r(Ege,` class
method.`),Ege.forEach(t),ndt=i(qi),nB=n(qi,"P",{});var gco=s(nB);sdt=r(gco,"This class cannot be instantiated directly using "),oke=n(gco,"CODE",{});var HEa=s(oke);ldt=r(HEa,"__init__()"),HEa.forEach(t),idt=r(gco," (throws an error)."),gco.forEach(t),ddt=i(qi),ia=n(qi,"DIV",{class:!0});var v$=s(ia);T(sB.$$.fragment,v$),mdt=i(v$),rke=n(v$,"P",{});var JEa=s(rke);cdt=r(JEa,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),JEa.forEach(t),fdt=i(v$),Vc=n(v$,"P",{});var Cge=s(Vc);gdt=r(Cge,`Note:
Loading a model from its configuration file does `),tke=n(Cge,"STRONG",{});var YEa=s(tke);hdt=r(YEa,"not"),YEa.forEach(t),udt=r(Cge,` load the model weights. It only affects the
model\u2019s configuration. Use `),lle=n(Cge,"A",{href:!0});var ZEa=s(lle);pdt=r(ZEa,"from_pretrained()"),ZEa.forEach(t),_dt=r(Cge," to load the model weights."),Cge.forEach(t),bdt=i(v$),T(y6.$$.fragment,v$),v$.forEach(t),vdt=i(qi),Yr=n(qi,"DIV",{class:!0});var Di=s(Yr);T(lB.$$.fragment,Di),Fdt=i(Di),ake=n(Di,"P",{});var KEa=s(ake);Tdt=r(KEa,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),KEa.forEach(t),Mdt=i(Di),Un=n(Di,"P",{});var F$=s(Un);Edt=r(F$,"The model class to instantiate is selected based on the "),nke=n(F$,"CODE",{});var e4a=s(nke);Cdt=r(e4a,"model_type"),e4a.forEach(t),wdt=r(F$,` property of the config object (either
passed as an argument or loaded from `),ske=n(F$,"CODE",{});var o4a=s(ske);Adt=r(o4a,"pretrained_model_name_or_path"),o4a.forEach(t),Ldt=r(F$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lke=n(F$,"CODE",{});var r4a=s(lke);ydt=r(r4a,"pretrained_model_name_or_path"),r4a.forEach(t),xdt=r(F$,":"),F$.forEach(t),$dt=i(Di),te=n(Di,"UL",{});var se=s(te);x6=n(se,"LI",{});var Eto=s(x6);ike=n(Eto,"STRONG",{});var t4a=s(ike);kdt=r(t4a,"albert"),t4a.forEach(t),Sdt=r(Eto," \u2014 "),ile=n(Eto,"A",{href:!0});var a4a=s(ile);Rdt=r(a4a,"TFAlbertForSequenceClassification"),a4a.forEach(t),Pdt=r(Eto," (ALBERT model)"),Eto.forEach(t),Bdt=i(se),$6=n(se,"LI",{});var Cto=s($6);dke=n(Cto,"STRONG",{});var n4a=s(dke);Idt=r(n4a,"bert"),n4a.forEach(t),Ndt=r(Cto," \u2014 "),dle=n(Cto,"A",{href:!0});var s4a=s(dle);qdt=r(s4a,"TFBertForSequenceClassification"),s4a.forEach(t),Ddt=r(Cto," (BERT model)"),Cto.forEach(t),jdt=i(se),k6=n(se,"LI",{});var wto=s(k6);mke=n(wto,"STRONG",{});var l4a=s(mke);Gdt=r(l4a,"camembert"),l4a.forEach(t),Odt=r(wto," \u2014 "),mle=n(wto,"A",{href:!0});var i4a=s(mle);Vdt=r(i4a,"TFCamembertForSequenceClassification"),i4a.forEach(t),Xdt=r(wto," (CamemBERT model)"),wto.forEach(t),zdt=i(se),S6=n(se,"LI",{});var Ato=s(S6);cke=n(Ato,"STRONG",{});var d4a=s(cke);Qdt=r(d4a,"convbert"),d4a.forEach(t),Wdt=r(Ato," \u2014 "),cle=n(Ato,"A",{href:!0});var m4a=s(cle);Udt=r(m4a,"TFConvBertForSequenceClassification"),m4a.forEach(t),Hdt=r(Ato," (ConvBERT model)"),Ato.forEach(t),Jdt=i(se),R6=n(se,"LI",{});var Lto=s(R6);fke=n(Lto,"STRONG",{});var c4a=s(fke);Ydt=r(c4a,"ctrl"),c4a.forEach(t),Zdt=r(Lto," \u2014 "),fle=n(Lto,"A",{href:!0});var f4a=s(fle);Kdt=r(f4a,"TFCTRLForSequenceClassification"),f4a.forEach(t),emt=r(Lto," (CTRL model)"),Lto.forEach(t),omt=i(se),P6=n(se,"LI",{});var yto=s(P6);gke=n(yto,"STRONG",{});var g4a=s(gke);rmt=r(g4a,"deberta"),g4a.forEach(t),tmt=r(yto," \u2014 "),gle=n(yto,"A",{href:!0});var h4a=s(gle);amt=r(h4a,"TFDebertaForSequenceClassification"),h4a.forEach(t),nmt=r(yto," (DeBERTa model)"),yto.forEach(t),smt=i(se),B6=n(se,"LI",{});var xto=s(B6);hke=n(xto,"STRONG",{});var u4a=s(hke);lmt=r(u4a,"deberta-v2"),u4a.forEach(t),imt=r(xto," \u2014 "),hle=n(xto,"A",{href:!0});var p4a=s(hle);dmt=r(p4a,"TFDebertaV2ForSequenceClassification"),p4a.forEach(t),mmt=r(xto," (DeBERTa-v2 model)"),xto.forEach(t),cmt=i(se),I6=n(se,"LI",{});var $to=s(I6);uke=n($to,"STRONG",{});var _4a=s(uke);fmt=r(_4a,"distilbert"),_4a.forEach(t),gmt=r($to," \u2014 "),ule=n($to,"A",{href:!0});var b4a=s(ule);hmt=r(b4a,"TFDistilBertForSequenceClassification"),b4a.forEach(t),umt=r($to," (DistilBERT model)"),$to.forEach(t),pmt=i(se),N6=n(se,"LI",{});var kto=s(N6);pke=n(kto,"STRONG",{});var v4a=s(pke);_mt=r(v4a,"electra"),v4a.forEach(t),bmt=r(kto," \u2014 "),ple=n(kto,"A",{href:!0});var F4a=s(ple);vmt=r(F4a,"TFElectraForSequenceClassification"),F4a.forEach(t),Fmt=r(kto," (ELECTRA model)"),kto.forEach(t),Tmt=i(se),q6=n(se,"LI",{});var Sto=s(q6);_ke=n(Sto,"STRONG",{});var T4a=s(_ke);Mmt=r(T4a,"esm"),T4a.forEach(t),Emt=r(Sto," \u2014 "),_le=n(Sto,"A",{href:!0});var M4a=s(_le);Cmt=r(M4a,"TFEsmForSequenceClassification"),M4a.forEach(t),wmt=r(Sto," (ESM model)"),Sto.forEach(t),Amt=i(se),D6=n(se,"LI",{});var Rto=s(D6);bke=n(Rto,"STRONG",{});var E4a=s(bke);Lmt=r(E4a,"flaubert"),E4a.forEach(t),ymt=r(Rto," \u2014 "),ble=n(Rto,"A",{href:!0});var C4a=s(ble);xmt=r(C4a,"TFFlaubertForSequenceClassification"),C4a.forEach(t),$mt=r(Rto," (FlauBERT model)"),Rto.forEach(t),kmt=i(se),j6=n(se,"LI",{});var Pto=s(j6);vke=n(Pto,"STRONG",{});var w4a=s(vke);Smt=r(w4a,"funnel"),w4a.forEach(t),Rmt=r(Pto," \u2014 "),vle=n(Pto,"A",{href:!0});var A4a=s(vle);Pmt=r(A4a,"TFFunnelForSequenceClassification"),A4a.forEach(t),Bmt=r(Pto," (Funnel Transformer model)"),Pto.forEach(t),Imt=i(se),G6=n(se,"LI",{});var Bto=s(G6);Fke=n(Bto,"STRONG",{});var L4a=s(Fke);Nmt=r(L4a,"gpt2"),L4a.forEach(t),qmt=r(Bto," \u2014 "),Fle=n(Bto,"A",{href:!0});var y4a=s(Fle);Dmt=r(y4a,"TFGPT2ForSequenceClassification"),y4a.forEach(t),jmt=r(Bto," (OpenAI GPT-2 model)"),Bto.forEach(t),Gmt=i(se),O6=n(se,"LI",{});var Ito=s(O6);Tke=n(Ito,"STRONG",{});var x4a=s(Tke);Omt=r(x4a,"gptj"),x4a.forEach(t),Vmt=r(Ito," \u2014 "),Tle=n(Ito,"A",{href:!0});var $4a=s(Tle);Xmt=r($4a,"TFGPTJForSequenceClassification"),$4a.forEach(t),zmt=r(Ito," (GPT-J model)"),Ito.forEach(t),Qmt=i(se),V6=n(se,"LI",{});var Nto=s(V6);Mke=n(Nto,"STRONG",{});var k4a=s(Mke);Wmt=r(k4a,"layoutlm"),k4a.forEach(t),Umt=r(Nto," \u2014 "),Mle=n(Nto,"A",{href:!0});var S4a=s(Mle);Hmt=r(S4a,"TFLayoutLMForSequenceClassification"),S4a.forEach(t),Jmt=r(Nto," (LayoutLM model)"),Nto.forEach(t),Ymt=i(se),X6=n(se,"LI",{});var qto=s(X6);Eke=n(qto,"STRONG",{});var R4a=s(Eke);Zmt=r(R4a,"layoutlmv3"),R4a.forEach(t),Kmt=r(qto," \u2014 "),Ele=n(qto,"A",{href:!0});var P4a=s(Ele);ect=r(P4a,"TFLayoutLMv3ForSequenceClassification"),P4a.forEach(t),oct=r(qto," (LayoutLMv3 model)"),qto.forEach(t),rct=i(se),z6=n(se,"LI",{});var Dto=s(z6);Cke=n(Dto,"STRONG",{});var B4a=s(Cke);tct=r(B4a,"longformer"),B4a.forEach(t),act=r(Dto," \u2014 "),Cle=n(Dto,"A",{href:!0});var I4a=s(Cle);nct=r(I4a,"TFLongformerForSequenceClassification"),I4a.forEach(t),sct=r(Dto," (Longformer model)"),Dto.forEach(t),lct=i(se),Q6=n(se,"LI",{});var jto=s(Q6);wke=n(jto,"STRONG",{});var N4a=s(wke);ict=r(N4a,"mobilebert"),N4a.forEach(t),dct=r(jto," \u2014 "),wle=n(jto,"A",{href:!0});var q4a=s(wle);mct=r(q4a,"TFMobileBertForSequenceClassification"),q4a.forEach(t),cct=r(jto," (MobileBERT model)"),jto.forEach(t),fct=i(se),W6=n(se,"LI",{});var Gto=s(W6);Ake=n(Gto,"STRONG",{});var D4a=s(Ake);gct=r(D4a,"mpnet"),D4a.forEach(t),hct=r(Gto," \u2014 "),Ale=n(Gto,"A",{href:!0});var j4a=s(Ale);uct=r(j4a,"TFMPNetForSequenceClassification"),j4a.forEach(t),pct=r(Gto," (MPNet model)"),Gto.forEach(t),_ct=i(se),U6=n(se,"LI",{});var Oto=s(U6);Lke=n(Oto,"STRONG",{});var G4a=s(Lke);bct=r(G4a,"openai-gpt"),G4a.forEach(t),vct=r(Oto," \u2014 "),Lle=n(Oto,"A",{href:!0});var O4a=s(Lle);Fct=r(O4a,"TFOpenAIGPTForSequenceClassification"),O4a.forEach(t),Tct=r(Oto," (OpenAI GPT model)"),Oto.forEach(t),Mct=i(se),H6=n(se,"LI",{});var Vto=s(H6);yke=n(Vto,"STRONG",{});var V4a=s(yke);Ect=r(V4a,"rembert"),V4a.forEach(t),Cct=r(Vto," \u2014 "),yle=n(Vto,"A",{href:!0});var X4a=s(yle);wct=r(X4a,"TFRemBertForSequenceClassification"),X4a.forEach(t),Act=r(Vto," (RemBERT model)"),Vto.forEach(t),Lct=i(se),J6=n(se,"LI",{});var Xto=s(J6);xke=n(Xto,"STRONG",{});var z4a=s(xke);yct=r(z4a,"roberta"),z4a.forEach(t),xct=r(Xto," \u2014 "),xle=n(Xto,"A",{href:!0});var Q4a=s(xle);$ct=r(Q4a,"TFRobertaForSequenceClassification"),Q4a.forEach(t),kct=r(Xto," (RoBERTa model)"),Xto.forEach(t),Sct=i(se),Y6=n(se,"LI",{});var zto=s(Y6);$ke=n(zto,"STRONG",{});var W4a=s($ke);Rct=r(W4a,"roformer"),W4a.forEach(t),Pct=r(zto," \u2014 "),$le=n(zto,"A",{href:!0});var U4a=s($le);Bct=r(U4a,"TFRoFormerForSequenceClassification"),U4a.forEach(t),Ict=r(zto," (RoFormer model)"),zto.forEach(t),Nct=i(se),Z6=n(se,"LI",{});var Qto=s(Z6);kke=n(Qto,"STRONG",{});var H4a=s(kke);qct=r(H4a,"tapas"),H4a.forEach(t),Dct=r(Qto," \u2014 "),kle=n(Qto,"A",{href:!0});var J4a=s(kle);jct=r(J4a,"TFTapasForSequenceClassification"),J4a.forEach(t),Gct=r(Qto," (TAPAS model)"),Qto.forEach(t),Oct=i(se),K6=n(se,"LI",{});var Wto=s(K6);Ske=n(Wto,"STRONG",{});var Y4a=s(Ske);Vct=r(Y4a,"transfo-xl"),Y4a.forEach(t),Xct=r(Wto," \u2014 "),Sle=n(Wto,"A",{href:!0});var Z4a=s(Sle);zct=r(Z4a,"TFTransfoXLForSequenceClassification"),Z4a.forEach(t),Qct=r(Wto," (Transformer-XL model)"),Wto.forEach(t),Wct=i(se),e7=n(se,"LI",{});var Uto=s(e7);Rke=n(Uto,"STRONG",{});var K4a=s(Rke);Uct=r(K4a,"xlm"),K4a.forEach(t),Hct=r(Uto," \u2014 "),Rle=n(Uto,"A",{href:!0});var eCa=s(Rle);Jct=r(eCa,"TFXLMForSequenceClassification"),eCa.forEach(t),Yct=r(Uto," (XLM model)"),Uto.forEach(t),Zct=i(se),o7=n(se,"LI",{});var Hto=s(o7);Pke=n(Hto,"STRONG",{});var oCa=s(Pke);Kct=r(oCa,"xlm-roberta"),oCa.forEach(t),eft=r(Hto," \u2014 "),Ple=n(Hto,"A",{href:!0});var rCa=s(Ple);oft=r(rCa,"TFXLMRobertaForSequenceClassification"),rCa.forEach(t),rft=r(Hto," (XLM-RoBERTa model)"),Hto.forEach(t),tft=i(se),r7=n(se,"LI",{});var Jto=s(r7);Bke=n(Jto,"STRONG",{});var tCa=s(Bke);aft=r(tCa,"xlnet"),tCa.forEach(t),nft=r(Jto," \u2014 "),Ble=n(Jto,"A",{href:!0});var aCa=s(Ble);sft=r(aCa,"TFXLNetForSequenceClassification"),aCa.forEach(t),lft=r(Jto," (XLNet model)"),Jto.forEach(t),se.forEach(t),ift=i(Di),T(t7.$$.fragment,Di),Di.forEach(t),qi.forEach(t),zio=i(c),Xc=n(c,"H2",{class:!0});var hco=s(Xc);a7=n(hco,"A",{id:!0,class:!0,href:!0});var nCa=s(a7);Ike=n(nCa,"SPAN",{});var sCa=s(Ike);T(iB.$$.fragment,sCa),sCa.forEach(t),nCa.forEach(t),dft=i(hco),Nke=n(hco,"SPAN",{});var lCa=s(Nke);mft=r(lCa,"TFAutoModelForMultipleChoice"),lCa.forEach(t),hco.forEach(t),Qio=i(c),Mr=n(c,"DIV",{class:!0});var ji=s(Mr);T(dB.$$.fragment,ji),cft=i(ji),zc=n(ji,"P",{});var wge=s(zc);fft=r(wge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Ile=n(wge,"A",{href:!0});var iCa=s(Ile);gft=r(iCa,"from_pretrained()"),iCa.forEach(t),hft=r(wge," class method or the "),Nle=n(wge,"A",{href:!0});var dCa=s(Nle);uft=r(dCa,"from_config()"),dCa.forEach(t),pft=r(wge,` class
method.`),wge.forEach(t),_ft=i(ji),mB=n(ji,"P",{});var uco=s(mB);bft=r(uco,"This class cannot be instantiated directly using "),qke=n(uco,"CODE",{});var mCa=s(qke);vft=r(mCa,"__init__()"),mCa.forEach(t),Fft=r(uco," (throws an error)."),uco.forEach(t),Tft=i(ji),da=n(ji,"DIV",{class:!0});var T$=s(da);T(cB.$$.fragment,T$),Mft=i(T$),Dke=n(T$,"P",{});var cCa=s(Dke);Eft=r(cCa,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),cCa.forEach(t),Cft=i(T$),Qc=n(T$,"P",{});var Age=s(Qc);wft=r(Age,`Note:
Loading a model from its configuration file does `),jke=n(Age,"STRONG",{});var fCa=s(jke);Aft=r(fCa,"not"),fCa.forEach(t),Lft=r(Age,` load the model weights. It only affects the
model\u2019s configuration. Use `),qle=n(Age,"A",{href:!0});var gCa=s(qle);yft=r(gCa,"from_pretrained()"),gCa.forEach(t),xft=r(Age," to load the model weights."),Age.forEach(t),$ft=i(T$),T(n7.$$.fragment,T$),T$.forEach(t),kft=i(ji),Zr=n(ji,"DIV",{class:!0});var Gi=s(Zr);T(fB.$$.fragment,Gi),Sft=i(Gi),Gke=n(Gi,"P",{});var hCa=s(Gke);Rft=r(hCa,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),hCa.forEach(t),Pft=i(Gi),Hn=n(Gi,"P",{});var M$=s(Hn);Bft=r(M$,"The model class to instantiate is selected based on the "),Oke=n(M$,"CODE",{});var uCa=s(Oke);Ift=r(uCa,"model_type"),uCa.forEach(t),Nft=r(M$,` property of the config object (either
passed as an argument or loaded from `),Vke=n(M$,"CODE",{});var pCa=s(Vke);qft=r(pCa,"pretrained_model_name_or_path"),pCa.forEach(t),Dft=r(M$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xke=n(M$,"CODE",{});var _Ca=s(Xke);jft=r(_Ca,"pretrained_model_name_or_path"),_Ca.forEach(t),Gft=r(M$,":"),M$.forEach(t),Oft=i(Gi),Te=n(Gi,"UL",{});var Ee=s(Te);s7=n(Ee,"LI",{});var Yto=s(s7);zke=n(Yto,"STRONG",{});var bCa=s(zke);Vft=r(bCa,"albert"),bCa.forEach(t),Xft=r(Yto," \u2014 "),Dle=n(Yto,"A",{href:!0});var vCa=s(Dle);zft=r(vCa,"TFAlbertForMultipleChoice"),vCa.forEach(t),Qft=r(Yto," (ALBERT model)"),Yto.forEach(t),Wft=i(Ee),l7=n(Ee,"LI",{});var Zto=s(l7);Qke=n(Zto,"STRONG",{});var FCa=s(Qke);Uft=r(FCa,"bert"),FCa.forEach(t),Hft=r(Zto," \u2014 "),jle=n(Zto,"A",{href:!0});var TCa=s(jle);Jft=r(TCa,"TFBertForMultipleChoice"),TCa.forEach(t),Yft=r(Zto," (BERT model)"),Zto.forEach(t),Zft=i(Ee),i7=n(Ee,"LI",{});var Kto=s(i7);Wke=n(Kto,"STRONG",{});var MCa=s(Wke);Kft=r(MCa,"camembert"),MCa.forEach(t),egt=r(Kto," \u2014 "),Gle=n(Kto,"A",{href:!0});var ECa=s(Gle);ogt=r(ECa,"TFCamembertForMultipleChoice"),ECa.forEach(t),rgt=r(Kto," (CamemBERT model)"),Kto.forEach(t),tgt=i(Ee),d7=n(Ee,"LI",{});var eao=s(d7);Uke=n(eao,"STRONG",{});var CCa=s(Uke);agt=r(CCa,"convbert"),CCa.forEach(t),ngt=r(eao," \u2014 "),Ole=n(eao,"A",{href:!0});var wCa=s(Ole);sgt=r(wCa,"TFConvBertForMultipleChoice"),wCa.forEach(t),lgt=r(eao," (ConvBERT model)"),eao.forEach(t),igt=i(Ee),m7=n(Ee,"LI",{});var oao=s(m7);Hke=n(oao,"STRONG",{});var ACa=s(Hke);dgt=r(ACa,"distilbert"),ACa.forEach(t),mgt=r(oao," \u2014 "),Vle=n(oao,"A",{href:!0});var LCa=s(Vle);cgt=r(LCa,"TFDistilBertForMultipleChoice"),LCa.forEach(t),fgt=r(oao," (DistilBERT model)"),oao.forEach(t),ggt=i(Ee),c7=n(Ee,"LI",{});var rao=s(c7);Jke=n(rao,"STRONG",{});var yCa=s(Jke);hgt=r(yCa,"electra"),yCa.forEach(t),ugt=r(rao," \u2014 "),Xle=n(rao,"A",{href:!0});var xCa=s(Xle);pgt=r(xCa,"TFElectraForMultipleChoice"),xCa.forEach(t),_gt=r(rao," (ELECTRA model)"),rao.forEach(t),bgt=i(Ee),f7=n(Ee,"LI",{});var tao=s(f7);Yke=n(tao,"STRONG",{});var $Ca=s(Yke);vgt=r($Ca,"flaubert"),$Ca.forEach(t),Fgt=r(tao," \u2014 "),zle=n(tao,"A",{href:!0});var kCa=s(zle);Tgt=r(kCa,"TFFlaubertForMultipleChoice"),kCa.forEach(t),Mgt=r(tao," (FlauBERT model)"),tao.forEach(t),Egt=i(Ee),g7=n(Ee,"LI",{});var aao=s(g7);Zke=n(aao,"STRONG",{});var SCa=s(Zke);Cgt=r(SCa,"funnel"),SCa.forEach(t),wgt=r(aao," \u2014 "),Qle=n(aao,"A",{href:!0});var RCa=s(Qle);Agt=r(RCa,"TFFunnelForMultipleChoice"),RCa.forEach(t),Lgt=r(aao," (Funnel Transformer model)"),aao.forEach(t),ygt=i(Ee),h7=n(Ee,"LI",{});var nao=s(h7);Kke=n(nao,"STRONG",{});var PCa=s(Kke);xgt=r(PCa,"longformer"),PCa.forEach(t),$gt=r(nao," \u2014 "),Wle=n(nao,"A",{href:!0});var BCa=s(Wle);kgt=r(BCa,"TFLongformerForMultipleChoice"),BCa.forEach(t),Sgt=r(nao," (Longformer model)"),nao.forEach(t),Rgt=i(Ee),u7=n(Ee,"LI",{});var sao=s(u7);eSe=n(sao,"STRONG",{});var ICa=s(eSe);Pgt=r(ICa,"mobilebert"),ICa.forEach(t),Bgt=r(sao," \u2014 "),Ule=n(sao,"A",{href:!0});var NCa=s(Ule);Igt=r(NCa,"TFMobileBertForMultipleChoice"),NCa.forEach(t),Ngt=r(sao," (MobileBERT model)"),sao.forEach(t),qgt=i(Ee),p7=n(Ee,"LI",{});var lao=s(p7);oSe=n(lao,"STRONG",{});var qCa=s(oSe);Dgt=r(qCa,"mpnet"),qCa.forEach(t),jgt=r(lao," \u2014 "),Hle=n(lao,"A",{href:!0});var DCa=s(Hle);Ggt=r(DCa,"TFMPNetForMultipleChoice"),DCa.forEach(t),Ogt=r(lao," (MPNet model)"),lao.forEach(t),Vgt=i(Ee),_7=n(Ee,"LI",{});var iao=s(_7);rSe=n(iao,"STRONG",{});var jCa=s(rSe);Xgt=r(jCa,"rembert"),jCa.forEach(t),zgt=r(iao," \u2014 "),Jle=n(iao,"A",{href:!0});var GCa=s(Jle);Qgt=r(GCa,"TFRemBertForMultipleChoice"),GCa.forEach(t),Wgt=r(iao," (RemBERT model)"),iao.forEach(t),Ugt=i(Ee),b7=n(Ee,"LI",{});var dao=s(b7);tSe=n(dao,"STRONG",{});var OCa=s(tSe);Hgt=r(OCa,"roberta"),OCa.forEach(t),Jgt=r(dao," \u2014 "),Yle=n(dao,"A",{href:!0});var VCa=s(Yle);Ygt=r(VCa,"TFRobertaForMultipleChoice"),VCa.forEach(t),Zgt=r(dao," (RoBERTa model)"),dao.forEach(t),Kgt=i(Ee),v7=n(Ee,"LI",{});var mao=s(v7);aSe=n(mao,"STRONG",{});var XCa=s(aSe);eht=r(XCa,"roformer"),XCa.forEach(t),oht=r(mao," \u2014 "),Zle=n(mao,"A",{href:!0});var zCa=s(Zle);rht=r(zCa,"TFRoFormerForMultipleChoice"),zCa.forEach(t),tht=r(mao," (RoFormer model)"),mao.forEach(t),aht=i(Ee),F7=n(Ee,"LI",{});var cao=s(F7);nSe=n(cao,"STRONG",{});var QCa=s(nSe);nht=r(QCa,"xlm"),QCa.forEach(t),sht=r(cao," \u2014 "),Kle=n(cao,"A",{href:!0});var WCa=s(Kle);lht=r(WCa,"TFXLMForMultipleChoice"),WCa.forEach(t),iht=r(cao," (XLM model)"),cao.forEach(t),dht=i(Ee),T7=n(Ee,"LI",{});var fao=s(T7);sSe=n(fao,"STRONG",{});var UCa=s(sSe);mht=r(UCa,"xlm-roberta"),UCa.forEach(t),cht=r(fao," \u2014 "),eie=n(fao,"A",{href:!0});var HCa=s(eie);fht=r(HCa,"TFXLMRobertaForMultipleChoice"),HCa.forEach(t),ght=r(fao," (XLM-RoBERTa model)"),fao.forEach(t),hht=i(Ee),M7=n(Ee,"LI",{});var gao=s(M7);lSe=n(gao,"STRONG",{});var JCa=s(lSe);uht=r(JCa,"xlnet"),JCa.forEach(t),pht=r(gao," \u2014 "),oie=n(gao,"A",{href:!0});var YCa=s(oie);_ht=r(YCa,"TFXLNetForMultipleChoice"),YCa.forEach(t),bht=r(gao," (XLNet model)"),gao.forEach(t),Ee.forEach(t),vht=i(Gi),T(E7.$$.fragment,Gi),Gi.forEach(t),ji.forEach(t),Wio=i(c),Wc=n(c,"H2",{class:!0});var pco=s(Wc);C7=n(pco,"A",{id:!0,class:!0,href:!0});var ZCa=s(C7);iSe=n(ZCa,"SPAN",{});var KCa=s(iSe);T(gB.$$.fragment,KCa),KCa.forEach(t),ZCa.forEach(t),Fht=i(pco),dSe=n(pco,"SPAN",{});var e3a=s(dSe);Tht=r(e3a,"TFAutoModelForNextSentencePrediction"),e3a.forEach(t),pco.forEach(t),Uio=i(c),Er=n(c,"DIV",{class:!0});var Oi=s(Er);T(hB.$$.fragment,Oi),Mht=i(Oi),Uc=n(Oi,"P",{});var Lge=s(Uc);Eht=r(Lge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),rie=n(Lge,"A",{href:!0});var o3a=s(rie);Cht=r(o3a,"from_pretrained()"),o3a.forEach(t),wht=r(Lge," class method or the "),tie=n(Lge,"A",{href:!0});var r3a=s(tie);Aht=r(r3a,"from_config()"),r3a.forEach(t),Lht=r(Lge,` class
method.`),Lge.forEach(t),yht=i(Oi),uB=n(Oi,"P",{});var _co=s(uB);xht=r(_co,"This class cannot be instantiated directly using "),mSe=n(_co,"CODE",{});var t3a=s(mSe);$ht=r(t3a,"__init__()"),t3a.forEach(t),kht=r(_co," (throws an error)."),_co.forEach(t),Sht=i(Oi),ma=n(Oi,"DIV",{class:!0});var E$=s(ma);T(pB.$$.fragment,E$),Rht=i(E$),cSe=n(E$,"P",{});var a3a=s(cSe);Pht=r(a3a,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),a3a.forEach(t),Bht=i(E$),Hc=n(E$,"P",{});var yge=s(Hc);Iht=r(yge,`Note:
Loading a model from its configuration file does `),fSe=n(yge,"STRONG",{});var n3a=s(fSe);Nht=r(n3a,"not"),n3a.forEach(t),qht=r(yge,` load the model weights. It only affects the
model\u2019s configuration. Use `),aie=n(yge,"A",{href:!0});var s3a=s(aie);Dht=r(s3a,"from_pretrained()"),s3a.forEach(t),jht=r(yge," to load the model weights."),yge.forEach(t),Ght=i(E$),T(w7.$$.fragment,E$),E$.forEach(t),Oht=i(Oi),Kr=n(Oi,"DIV",{class:!0});var Vi=s(Kr);T(_B.$$.fragment,Vi),Vht=i(Vi),gSe=n(Vi,"P",{});var l3a=s(gSe);Xht=r(l3a,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),l3a.forEach(t),zht=i(Vi),Jn=n(Vi,"P",{});var C$=s(Jn);Qht=r(C$,"The model class to instantiate is selected based on the "),hSe=n(C$,"CODE",{});var i3a=s(hSe);Wht=r(i3a,"model_type"),i3a.forEach(t),Uht=r(C$,` property of the config object (either
passed as an argument or loaded from `),uSe=n(C$,"CODE",{});var d3a=s(uSe);Hht=r(d3a,"pretrained_model_name_or_path"),d3a.forEach(t),Jht=r(C$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pSe=n(C$,"CODE",{});var m3a=s(pSe);Yht=r(m3a,"pretrained_model_name_or_path"),m3a.forEach(t),Zht=r(C$,":"),C$.forEach(t),Kht=i(Vi),bB=n(Vi,"UL",{});var bco=s(bB);A7=n(bco,"LI",{});var hao=s(A7);_Se=n(hao,"STRONG",{});var c3a=s(_Se);eut=r(c3a,"bert"),c3a.forEach(t),out=r(hao," \u2014 "),nie=n(hao,"A",{href:!0});var f3a=s(nie);rut=r(f3a,"TFBertForNextSentencePrediction"),f3a.forEach(t),tut=r(hao," (BERT model)"),hao.forEach(t),aut=i(bco),L7=n(bco,"LI",{});var uao=s(L7);bSe=n(uao,"STRONG",{});var g3a=s(bSe);nut=r(g3a,"mobilebert"),g3a.forEach(t),sut=r(uao," \u2014 "),sie=n(uao,"A",{href:!0});var h3a=s(sie);lut=r(h3a,"TFMobileBertForNextSentencePrediction"),h3a.forEach(t),iut=r(uao," (MobileBERT model)"),uao.forEach(t),bco.forEach(t),dut=i(Vi),T(y7.$$.fragment,Vi),Vi.forEach(t),Oi.forEach(t),Hio=i(c),Jc=n(c,"H2",{class:!0});var vco=s(Jc);x7=n(vco,"A",{id:!0,class:!0,href:!0});var u3a=s(x7);vSe=n(u3a,"SPAN",{});var p3a=s(vSe);T(vB.$$.fragment,p3a),p3a.forEach(t),u3a.forEach(t),mut=i(vco),FSe=n(vco,"SPAN",{});var _3a=s(FSe);cut=r(_3a,"TFAutoModelForTableQuestionAnswering"),_3a.forEach(t),vco.forEach(t),Jio=i(c),Cr=n(c,"DIV",{class:!0});var Xi=s(Cr);T(FB.$$.fragment,Xi),fut=i(Xi),Yc=n(Xi,"P",{});var xge=s(Yc);gut=r(xge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),lie=n(xge,"A",{href:!0});var b3a=s(lie);hut=r(b3a,"from_pretrained()"),b3a.forEach(t),uut=r(xge," class method or the "),iie=n(xge,"A",{href:!0});var v3a=s(iie);put=r(v3a,"from_config()"),v3a.forEach(t),_ut=r(xge,` class
method.`),xge.forEach(t),but=i(Xi),TB=n(Xi,"P",{});var Fco=s(TB);vut=r(Fco,"This class cannot be instantiated directly using "),TSe=n(Fco,"CODE",{});var F3a=s(TSe);Fut=r(F3a,"__init__()"),F3a.forEach(t),Tut=r(Fco," (throws an error)."),Fco.forEach(t),Mut=i(Xi),ca=n(Xi,"DIV",{class:!0});var w$=s(ca);T(MB.$$.fragment,w$),Eut=i(w$),MSe=n(w$,"P",{});var T3a=s(MSe);Cut=r(T3a,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),T3a.forEach(t),wut=i(w$),Zc=n(w$,"P",{});var $ge=s(Zc);Aut=r($ge,`Note:
Loading a model from its configuration file does `),ESe=n($ge,"STRONG",{});var M3a=s(ESe);Lut=r(M3a,"not"),M3a.forEach(t),yut=r($ge,` load the model weights. It only affects the
model\u2019s configuration. Use `),die=n($ge,"A",{href:!0});var E3a=s(die);xut=r(E3a,"from_pretrained()"),E3a.forEach(t),$ut=r($ge," to load the model weights."),$ge.forEach(t),kut=i(w$),T($7.$$.fragment,w$),w$.forEach(t),Sut=i(Xi),et=n(Xi,"DIV",{class:!0});var zi=s(et);T(EB.$$.fragment,zi),Rut=i(zi),CSe=n(zi,"P",{});var C3a=s(CSe);Put=r(C3a,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),C3a.forEach(t),But=i(zi),Yn=n(zi,"P",{});var A$=s(Yn);Iut=r(A$,"The model class to instantiate is selected based on the "),wSe=n(A$,"CODE",{});var w3a=s(wSe);Nut=r(w3a,"model_type"),w3a.forEach(t),qut=r(A$,` property of the config object (either
passed as an argument or loaded from `),ASe=n(A$,"CODE",{});var A3a=s(ASe);Dut=r(A3a,"pretrained_model_name_or_path"),A3a.forEach(t),jut=r(A$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LSe=n(A$,"CODE",{});var L3a=s(LSe);Gut=r(L3a,"pretrained_model_name_or_path"),L3a.forEach(t),Out=r(A$,":"),A$.forEach(t),Vut=i(zi),ySe=n(zi,"UL",{});var y3a=s(ySe);k7=n(y3a,"LI",{});var pao=s(k7);xSe=n(pao,"STRONG",{});var x3a=s(xSe);Xut=r(x3a,"tapas"),x3a.forEach(t),zut=r(pao," \u2014 "),mie=n(pao,"A",{href:!0});var $3a=s(mie);Qut=r($3a,"TFTapasForQuestionAnswering"),$3a.forEach(t),Wut=r(pao," (TAPAS model)"),pao.forEach(t),y3a.forEach(t),Uut=i(zi),T(S7.$$.fragment,zi),zi.forEach(t),Xi.forEach(t),Yio=i(c),Kc=n(c,"H2",{class:!0});var Tco=s(Kc);R7=n(Tco,"A",{id:!0,class:!0,href:!0});var k3a=s(R7);$Se=n(k3a,"SPAN",{});var S3a=s($Se);T(CB.$$.fragment,S3a),S3a.forEach(t),k3a.forEach(t),Hut=i(Tco),kSe=n(Tco,"SPAN",{});var R3a=s(kSe);Jut=r(R3a,"TFAutoModelForDocumentQuestionAnswering"),R3a.forEach(t),Tco.forEach(t),Zio=i(c),wr=n(c,"DIV",{class:!0});var Qi=s(wr);T(wB.$$.fragment,Qi),Yut=i(Qi),ef=n(Qi,"P",{});var kge=s(ef);Zut=r(kge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),cie=n(kge,"A",{href:!0});var P3a=s(cie);Kut=r(P3a,"from_pretrained()"),P3a.forEach(t),ept=r(kge," class method or the "),fie=n(kge,"A",{href:!0});var B3a=s(fie);opt=r(B3a,"from_config()"),B3a.forEach(t),rpt=r(kge,` class
method.`),kge.forEach(t),tpt=i(Qi),AB=n(Qi,"P",{});var Mco=s(AB);apt=r(Mco,"This class cannot be instantiated directly using "),SSe=n(Mco,"CODE",{});var I3a=s(SSe);npt=r(I3a,"__init__()"),I3a.forEach(t),spt=r(Mco," (throws an error)."),Mco.forEach(t),lpt=i(Qi),fa=n(Qi,"DIV",{class:!0});var L$=s(fa);T(LB.$$.fragment,L$),ipt=i(L$),RSe=n(L$,"P",{});var N3a=s(RSe);dpt=r(N3a,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),N3a.forEach(t),mpt=i(L$),of=n(L$,"P",{});var Sge=s(of);cpt=r(Sge,`Note:
Loading a model from its configuration file does `),PSe=n(Sge,"STRONG",{});var q3a=s(PSe);fpt=r(q3a,"not"),q3a.forEach(t),gpt=r(Sge,` load the model weights. It only affects the
model\u2019s configuration. Use `),gie=n(Sge,"A",{href:!0});var D3a=s(gie);hpt=r(D3a,"from_pretrained()"),D3a.forEach(t),upt=r(Sge," to load the model weights."),Sge.forEach(t),ppt=i(L$),T(P7.$$.fragment,L$),L$.forEach(t),_pt=i(Qi),ot=n(Qi,"DIV",{class:!0});var Wi=s(ot);T(yB.$$.fragment,Wi),bpt=i(Wi),BSe=n(Wi,"P",{});var j3a=s(BSe);vpt=r(j3a,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),j3a.forEach(t),Fpt=i(Wi),Zn=n(Wi,"P",{});var y$=s(Zn);Tpt=r(y$,"The model class to instantiate is selected based on the "),ISe=n(y$,"CODE",{});var G3a=s(ISe);Mpt=r(G3a,"model_type"),G3a.forEach(t),Ept=r(y$,` property of the config object (either
passed as an argument or loaded from `),NSe=n(y$,"CODE",{});var O3a=s(NSe);Cpt=r(O3a,"pretrained_model_name_or_path"),O3a.forEach(t),wpt=r(y$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qSe=n(y$,"CODE",{});var V3a=s(qSe);Apt=r(V3a,"pretrained_model_name_or_path"),V3a.forEach(t),Lpt=r(y$,":"),y$.forEach(t),ypt=i(Wi),DSe=n(Wi,"UL",{});var X3a=s(DSe);B7=n(X3a,"LI",{});var _ao=s(B7);jSe=n(_ao,"STRONG",{});var z3a=s(jSe);xpt=r(z3a,"layoutlm"),z3a.forEach(t),$pt=r(_ao," \u2014 "),hie=n(_ao,"A",{href:!0});var Q3a=s(hie);kpt=r(Q3a,"TFLayoutLMForQuestionAnswering"),Q3a.forEach(t),Spt=r(_ao," (LayoutLM model)"),_ao.forEach(t),X3a.forEach(t),Rpt=i(Wi),T(I7.$$.fragment,Wi),Wi.forEach(t),Qi.forEach(t),Kio=i(c),rf=n(c,"H2",{class:!0});var Eco=s(rf);N7=n(Eco,"A",{id:!0,class:!0,href:!0});var W3a=s(N7);GSe=n(W3a,"SPAN",{});var U3a=s(GSe);T(xB.$$.fragment,U3a),U3a.forEach(t),W3a.forEach(t),Ppt=i(Eco),OSe=n(Eco,"SPAN",{});var H3a=s(OSe);Bpt=r(H3a,"TFAutoModelForTokenClassification"),H3a.forEach(t),Eco.forEach(t),edo=i(c),Ar=n(c,"DIV",{class:!0});var Ui=s(Ar);T($B.$$.fragment,Ui),Ipt=i(Ui),tf=n(Ui,"P",{});var Rge=s(tf);Npt=r(Rge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),uie=n(Rge,"A",{href:!0});var J3a=s(uie);qpt=r(J3a,"from_pretrained()"),J3a.forEach(t),Dpt=r(Rge," class method or the "),pie=n(Rge,"A",{href:!0});var Y3a=s(pie);jpt=r(Y3a,"from_config()"),Y3a.forEach(t),Gpt=r(Rge,` class
method.`),Rge.forEach(t),Opt=i(Ui),kB=n(Ui,"P",{});var Cco=s(kB);Vpt=r(Cco,"This class cannot be instantiated directly using "),VSe=n(Cco,"CODE",{});var Z3a=s(VSe);Xpt=r(Z3a,"__init__()"),Z3a.forEach(t),zpt=r(Cco," (throws an error)."),Cco.forEach(t),Qpt=i(Ui),ga=n(Ui,"DIV",{class:!0});var x$=s(ga);T(SB.$$.fragment,x$),Wpt=i(x$),XSe=n(x$,"P",{});var K3a=s(XSe);Upt=r(K3a,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),K3a.forEach(t),Hpt=i(x$),af=n(x$,"P",{});var Pge=s(af);Jpt=r(Pge,`Note:
Loading a model from its configuration file does `),zSe=n(Pge,"STRONG",{});var e5a=s(zSe);Ypt=r(e5a,"not"),e5a.forEach(t),Zpt=r(Pge,` load the model weights. It only affects the
model\u2019s configuration. Use `),_ie=n(Pge,"A",{href:!0});var o5a=s(_ie);Kpt=r(o5a,"from_pretrained()"),o5a.forEach(t),e_t=r(Pge," to load the model weights."),Pge.forEach(t),o_t=i(x$),T(q7.$$.fragment,x$),x$.forEach(t),r_t=i(Ui),rt=n(Ui,"DIV",{class:!0});var Hi=s(rt);T(RB.$$.fragment,Hi),t_t=i(Hi),QSe=n(Hi,"P",{});var r5a=s(QSe);a_t=r(r5a,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),r5a.forEach(t),n_t=i(Hi),Kn=n(Hi,"P",{});var $$=s(Kn);s_t=r($$,"The model class to instantiate is selected based on the "),WSe=n($$,"CODE",{});var t5a=s(WSe);l_t=r(t5a,"model_type"),t5a.forEach(t),i_t=r($$,` property of the config object (either
passed as an argument or loaded from `),USe=n($$,"CODE",{});var a5a=s(USe);d_t=r(a5a,"pretrained_model_name_or_path"),a5a.forEach(t),m_t=r($$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HSe=n($$,"CODE",{});var n5a=s(HSe);c_t=r(n5a,"pretrained_model_name_or_path"),n5a.forEach(t),f_t=r($$,":"),$$.forEach(t),g_t=i(Hi),me=n(Hi,"UL",{});var ue=s(me);D7=n(ue,"LI",{});var bao=s(D7);JSe=n(bao,"STRONG",{});var s5a=s(JSe);h_t=r(s5a,"albert"),s5a.forEach(t),u_t=r(bao," \u2014 "),bie=n(bao,"A",{href:!0});var l5a=s(bie);p_t=r(l5a,"TFAlbertForTokenClassification"),l5a.forEach(t),__t=r(bao," (ALBERT model)"),bao.forEach(t),b_t=i(ue),j7=n(ue,"LI",{});var vao=s(j7);YSe=n(vao,"STRONG",{});var i5a=s(YSe);v_t=r(i5a,"bert"),i5a.forEach(t),F_t=r(vao," \u2014 "),vie=n(vao,"A",{href:!0});var d5a=s(vie);T_t=r(d5a,"TFBertForTokenClassification"),d5a.forEach(t),M_t=r(vao," (BERT model)"),vao.forEach(t),E_t=i(ue),G7=n(ue,"LI",{});var Fao=s(G7);ZSe=n(Fao,"STRONG",{});var m5a=s(ZSe);C_t=r(m5a,"camembert"),m5a.forEach(t),w_t=r(Fao," \u2014 "),Fie=n(Fao,"A",{href:!0});var c5a=s(Fie);A_t=r(c5a,"TFCamembertForTokenClassification"),c5a.forEach(t),L_t=r(Fao," (CamemBERT model)"),Fao.forEach(t),y_t=i(ue),O7=n(ue,"LI",{});var Tao=s(O7);KSe=n(Tao,"STRONG",{});var f5a=s(KSe);x_t=r(f5a,"convbert"),f5a.forEach(t),$_t=r(Tao," \u2014 "),Tie=n(Tao,"A",{href:!0});var g5a=s(Tie);k_t=r(g5a,"TFConvBertForTokenClassification"),g5a.forEach(t),S_t=r(Tao," (ConvBERT model)"),Tao.forEach(t),R_t=i(ue),V7=n(ue,"LI",{});var Mao=s(V7);eRe=n(Mao,"STRONG",{});var h5a=s(eRe);P_t=r(h5a,"deberta"),h5a.forEach(t),B_t=r(Mao," \u2014 "),Mie=n(Mao,"A",{href:!0});var u5a=s(Mie);I_t=r(u5a,"TFDebertaForTokenClassification"),u5a.forEach(t),N_t=r(Mao," (DeBERTa model)"),Mao.forEach(t),q_t=i(ue),X7=n(ue,"LI",{});var Eao=s(X7);oRe=n(Eao,"STRONG",{});var p5a=s(oRe);D_t=r(p5a,"deberta-v2"),p5a.forEach(t),j_t=r(Eao," \u2014 "),Eie=n(Eao,"A",{href:!0});var _5a=s(Eie);G_t=r(_5a,"TFDebertaV2ForTokenClassification"),_5a.forEach(t),O_t=r(Eao," (DeBERTa-v2 model)"),Eao.forEach(t),V_t=i(ue),z7=n(ue,"LI",{});var Cao=s(z7);rRe=n(Cao,"STRONG",{});var b5a=s(rRe);X_t=r(b5a,"distilbert"),b5a.forEach(t),z_t=r(Cao," \u2014 "),Cie=n(Cao,"A",{href:!0});var v5a=s(Cie);Q_t=r(v5a,"TFDistilBertForTokenClassification"),v5a.forEach(t),W_t=r(Cao," (DistilBERT model)"),Cao.forEach(t),U_t=i(ue),Q7=n(ue,"LI",{});var wao=s(Q7);tRe=n(wao,"STRONG",{});var F5a=s(tRe);H_t=r(F5a,"electra"),F5a.forEach(t),J_t=r(wao," \u2014 "),wie=n(wao,"A",{href:!0});var T5a=s(wie);Y_t=r(T5a,"TFElectraForTokenClassification"),T5a.forEach(t),Z_t=r(wao," (ELECTRA model)"),wao.forEach(t),K_t=i(ue),W7=n(ue,"LI",{});var Aao=s(W7);aRe=n(Aao,"STRONG",{});var M5a=s(aRe);e1t=r(M5a,"esm"),M5a.forEach(t),o1t=r(Aao," \u2014 "),Aie=n(Aao,"A",{href:!0});var E5a=s(Aie);r1t=r(E5a,"TFEsmForTokenClassification"),E5a.forEach(t),t1t=r(Aao," (ESM model)"),Aao.forEach(t),a1t=i(ue),U7=n(ue,"LI",{});var Lao=s(U7);nRe=n(Lao,"STRONG",{});var C5a=s(nRe);n1t=r(C5a,"flaubert"),C5a.forEach(t),s1t=r(Lao," \u2014 "),Lie=n(Lao,"A",{href:!0});var w5a=s(Lie);l1t=r(w5a,"TFFlaubertForTokenClassification"),w5a.forEach(t),i1t=r(Lao," (FlauBERT model)"),Lao.forEach(t),d1t=i(ue),H7=n(ue,"LI",{});var yao=s(H7);sRe=n(yao,"STRONG",{});var A5a=s(sRe);m1t=r(A5a,"funnel"),A5a.forEach(t),c1t=r(yao," \u2014 "),yie=n(yao,"A",{href:!0});var L5a=s(yie);f1t=r(L5a,"TFFunnelForTokenClassification"),L5a.forEach(t),g1t=r(yao," (Funnel Transformer model)"),yao.forEach(t),h1t=i(ue),J7=n(ue,"LI",{});var xao=s(J7);lRe=n(xao,"STRONG",{});var y5a=s(lRe);u1t=r(y5a,"layoutlm"),y5a.forEach(t),p1t=r(xao," \u2014 "),xie=n(xao,"A",{href:!0});var x5a=s(xie);_1t=r(x5a,"TFLayoutLMForTokenClassification"),x5a.forEach(t),b1t=r(xao," (LayoutLM model)"),xao.forEach(t),v1t=i(ue),Y7=n(ue,"LI",{});var $ao=s(Y7);iRe=n($ao,"STRONG",{});var $5a=s(iRe);F1t=r($5a,"layoutlmv3"),$5a.forEach(t),T1t=r($ao," \u2014 "),$ie=n($ao,"A",{href:!0});var k5a=s($ie);M1t=r(k5a,"TFLayoutLMv3ForTokenClassification"),k5a.forEach(t),E1t=r($ao," (LayoutLMv3 model)"),$ao.forEach(t),C1t=i(ue),Z7=n(ue,"LI",{});var kao=s(Z7);dRe=n(kao,"STRONG",{});var S5a=s(dRe);w1t=r(S5a,"longformer"),S5a.forEach(t),A1t=r(kao," \u2014 "),kie=n(kao,"A",{href:!0});var R5a=s(kie);L1t=r(R5a,"TFLongformerForTokenClassification"),R5a.forEach(t),y1t=r(kao," (Longformer model)"),kao.forEach(t),x1t=i(ue),K7=n(ue,"LI",{});var Sao=s(K7);mRe=n(Sao,"STRONG",{});var P5a=s(mRe);$1t=r(P5a,"mobilebert"),P5a.forEach(t),k1t=r(Sao," \u2014 "),Sie=n(Sao,"A",{href:!0});var B5a=s(Sie);S1t=r(B5a,"TFMobileBertForTokenClassification"),B5a.forEach(t),R1t=r(Sao," (MobileBERT model)"),Sao.forEach(t),P1t=i(ue),e8=n(ue,"LI",{});var Rao=s(e8);cRe=n(Rao,"STRONG",{});var I5a=s(cRe);B1t=r(I5a,"mpnet"),I5a.forEach(t),I1t=r(Rao," \u2014 "),Rie=n(Rao,"A",{href:!0});var N5a=s(Rie);N1t=r(N5a,"TFMPNetForTokenClassification"),N5a.forEach(t),q1t=r(Rao," (MPNet model)"),Rao.forEach(t),D1t=i(ue),o8=n(ue,"LI",{});var Pao=s(o8);fRe=n(Pao,"STRONG",{});var q5a=s(fRe);j1t=r(q5a,"rembert"),q5a.forEach(t),G1t=r(Pao," \u2014 "),Pie=n(Pao,"A",{href:!0});var D5a=s(Pie);O1t=r(D5a,"TFRemBertForTokenClassification"),D5a.forEach(t),V1t=r(Pao," (RemBERT model)"),Pao.forEach(t),X1t=i(ue),r8=n(ue,"LI",{});var Bao=s(r8);gRe=n(Bao,"STRONG",{});var j5a=s(gRe);z1t=r(j5a,"roberta"),j5a.forEach(t),Q1t=r(Bao," \u2014 "),Bie=n(Bao,"A",{href:!0});var G5a=s(Bie);W1t=r(G5a,"TFRobertaForTokenClassification"),G5a.forEach(t),U1t=r(Bao," (RoBERTa model)"),Bao.forEach(t),H1t=i(ue),t8=n(ue,"LI",{});var Iao=s(t8);hRe=n(Iao,"STRONG",{});var O5a=s(hRe);J1t=r(O5a,"roformer"),O5a.forEach(t),Y1t=r(Iao," \u2014 "),Iie=n(Iao,"A",{href:!0});var V5a=s(Iie);Z1t=r(V5a,"TFRoFormerForTokenClassification"),V5a.forEach(t),K1t=r(Iao," (RoFormer model)"),Iao.forEach(t),e2t=i(ue),a8=n(ue,"LI",{});var Nao=s(a8);uRe=n(Nao,"STRONG",{});var X5a=s(uRe);o2t=r(X5a,"xlm"),X5a.forEach(t),r2t=r(Nao," \u2014 "),Nie=n(Nao,"A",{href:!0});var z5a=s(Nie);t2t=r(z5a,"TFXLMForTokenClassification"),z5a.forEach(t),a2t=r(Nao," (XLM model)"),Nao.forEach(t),n2t=i(ue),n8=n(ue,"LI",{});var qao=s(n8);pRe=n(qao,"STRONG",{});var Q5a=s(pRe);s2t=r(Q5a,"xlm-roberta"),Q5a.forEach(t),l2t=r(qao," \u2014 "),qie=n(qao,"A",{href:!0});var W5a=s(qie);i2t=r(W5a,"TFXLMRobertaForTokenClassification"),W5a.forEach(t),d2t=r(qao," (XLM-RoBERTa model)"),qao.forEach(t),m2t=i(ue),s8=n(ue,"LI",{});var Dao=s(s8);_Re=n(Dao,"STRONG",{});var U5a=s(_Re);c2t=r(U5a,"xlnet"),U5a.forEach(t),f2t=r(Dao," \u2014 "),Die=n(Dao,"A",{href:!0});var H5a=s(Die);g2t=r(H5a,"TFXLNetForTokenClassification"),H5a.forEach(t),h2t=r(Dao," (XLNet model)"),Dao.forEach(t),ue.forEach(t),u2t=i(Hi),T(l8.$$.fragment,Hi),Hi.forEach(t),Ui.forEach(t),odo=i(c),nf=n(c,"H2",{class:!0});var wco=s(nf);i8=n(wco,"A",{id:!0,class:!0,href:!0});var J5a=s(i8);bRe=n(J5a,"SPAN",{});var Y5a=s(bRe);T(PB.$$.fragment,Y5a),Y5a.forEach(t),J5a.forEach(t),p2t=i(wco),vRe=n(wco,"SPAN",{});var Z5a=s(vRe);_2t=r(Z5a,"TFAutoModelForQuestionAnswering"),Z5a.forEach(t),wco.forEach(t),rdo=i(c),Lr=n(c,"DIV",{class:!0});var Ji=s(Lr);T(BB.$$.fragment,Ji),b2t=i(Ji),sf=n(Ji,"P",{});var Bge=s(sf);v2t=r(Bge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),jie=n(Bge,"A",{href:!0});var K5a=s(jie);F2t=r(K5a,"from_pretrained()"),K5a.forEach(t),T2t=r(Bge," class method or the "),Gie=n(Bge,"A",{href:!0});var e0a=s(Gie);M2t=r(e0a,"from_config()"),e0a.forEach(t),E2t=r(Bge,` class
method.`),Bge.forEach(t),C2t=i(Ji),IB=n(Ji,"P",{});var Aco=s(IB);w2t=r(Aco,"This class cannot be instantiated directly using "),FRe=n(Aco,"CODE",{});var o0a=s(FRe);A2t=r(o0a,"__init__()"),o0a.forEach(t),L2t=r(Aco," (throws an error)."),Aco.forEach(t),y2t=i(Ji),ha=n(Ji,"DIV",{class:!0});var k$=s(ha);T(NB.$$.fragment,k$),x2t=i(k$),TRe=n(k$,"P",{});var r0a=s(TRe);$2t=r(r0a,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),r0a.forEach(t),k2t=i(k$),lf=n(k$,"P",{});var Ige=s(lf);S2t=r(Ige,`Note:
Loading a model from its configuration file does `),MRe=n(Ige,"STRONG",{});var t0a=s(MRe);R2t=r(t0a,"not"),t0a.forEach(t),P2t=r(Ige,` load the model weights. It only affects the
model\u2019s configuration. Use `),Oie=n(Ige,"A",{href:!0});var a0a=s(Oie);B2t=r(a0a,"from_pretrained()"),a0a.forEach(t),I2t=r(Ige," to load the model weights."),Ige.forEach(t),N2t=i(k$),T(d8.$$.fragment,k$),k$.forEach(t),q2t=i(Ji),tt=n(Ji,"DIV",{class:!0});var Yi=s(tt);T(qB.$$.fragment,Yi),D2t=i(Yi),ERe=n(Yi,"P",{});var n0a=s(ERe);j2t=r(n0a,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),n0a.forEach(t),G2t=i(Yi),es=n(Yi,"P",{});var S$=s(es);O2t=r(S$,"The model class to instantiate is selected based on the "),CRe=n(S$,"CODE",{});var s0a=s(CRe);V2t=r(s0a,"model_type"),s0a.forEach(t),X2t=r(S$,` property of the config object (either
passed as an argument or loaded from `),wRe=n(S$,"CODE",{});var l0a=s(wRe);z2t=r(l0a,"pretrained_model_name_or_path"),l0a.forEach(t),Q2t=r(S$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ARe=n(S$,"CODE",{});var i0a=s(ARe);W2t=r(i0a,"pretrained_model_name_or_path"),i0a.forEach(t),U2t=r(S$,":"),S$.forEach(t),H2t=i(Yi),he=n(Yi,"UL",{});var be=s(he);m8=n(be,"LI",{});var jao=s(m8);LRe=n(jao,"STRONG",{});var d0a=s(LRe);J2t=r(d0a,"albert"),d0a.forEach(t),Y2t=r(jao," \u2014 "),Vie=n(jao,"A",{href:!0});var m0a=s(Vie);Z2t=r(m0a,"TFAlbertForQuestionAnswering"),m0a.forEach(t),K2t=r(jao," (ALBERT model)"),jao.forEach(t),ebt=i(be),c8=n(be,"LI",{});var Gao=s(c8);yRe=n(Gao,"STRONG",{});var c0a=s(yRe);obt=r(c0a,"bert"),c0a.forEach(t),rbt=r(Gao," \u2014 "),Xie=n(Gao,"A",{href:!0});var f0a=s(Xie);tbt=r(f0a,"TFBertForQuestionAnswering"),f0a.forEach(t),abt=r(Gao," (BERT model)"),Gao.forEach(t),nbt=i(be),f8=n(be,"LI",{});var Oao=s(f8);xRe=n(Oao,"STRONG",{});var g0a=s(xRe);sbt=r(g0a,"camembert"),g0a.forEach(t),lbt=r(Oao," \u2014 "),zie=n(Oao,"A",{href:!0});var h0a=s(zie);ibt=r(h0a,"TFCamembertForQuestionAnswering"),h0a.forEach(t),dbt=r(Oao," (CamemBERT model)"),Oao.forEach(t),mbt=i(be),g8=n(be,"LI",{});var Vao=s(g8);$Re=n(Vao,"STRONG",{});var u0a=s($Re);cbt=r(u0a,"convbert"),u0a.forEach(t),fbt=r(Vao," \u2014 "),Qie=n(Vao,"A",{href:!0});var p0a=s(Qie);gbt=r(p0a,"TFConvBertForQuestionAnswering"),p0a.forEach(t),hbt=r(Vao," (ConvBERT model)"),Vao.forEach(t),ubt=i(be),h8=n(be,"LI",{});var Xao=s(h8);kRe=n(Xao,"STRONG",{});var _0a=s(kRe);pbt=r(_0a,"deberta"),_0a.forEach(t),_bt=r(Xao," \u2014 "),Wie=n(Xao,"A",{href:!0});var b0a=s(Wie);bbt=r(b0a,"TFDebertaForQuestionAnswering"),b0a.forEach(t),vbt=r(Xao," (DeBERTa model)"),Xao.forEach(t),Fbt=i(be),u8=n(be,"LI",{});var zao=s(u8);SRe=n(zao,"STRONG",{});var v0a=s(SRe);Tbt=r(v0a,"deberta-v2"),v0a.forEach(t),Mbt=r(zao," \u2014 "),Uie=n(zao,"A",{href:!0});var F0a=s(Uie);Ebt=r(F0a,"TFDebertaV2ForQuestionAnswering"),F0a.forEach(t),Cbt=r(zao," (DeBERTa-v2 model)"),zao.forEach(t),wbt=i(be),p8=n(be,"LI",{});var Qao=s(p8);RRe=n(Qao,"STRONG",{});var T0a=s(RRe);Abt=r(T0a,"distilbert"),T0a.forEach(t),Lbt=r(Qao," \u2014 "),Hie=n(Qao,"A",{href:!0});var M0a=s(Hie);ybt=r(M0a,"TFDistilBertForQuestionAnswering"),M0a.forEach(t),xbt=r(Qao," (DistilBERT model)"),Qao.forEach(t),$bt=i(be),_8=n(be,"LI",{});var Wao=s(_8);PRe=n(Wao,"STRONG",{});var E0a=s(PRe);kbt=r(E0a,"electra"),E0a.forEach(t),Sbt=r(Wao," \u2014 "),Jie=n(Wao,"A",{href:!0});var C0a=s(Jie);Rbt=r(C0a,"TFElectraForQuestionAnswering"),C0a.forEach(t),Pbt=r(Wao," (ELECTRA model)"),Wao.forEach(t),Bbt=i(be),b8=n(be,"LI",{});var Uao=s(b8);BRe=n(Uao,"STRONG",{});var w0a=s(BRe);Ibt=r(w0a,"flaubert"),w0a.forEach(t),Nbt=r(Uao," \u2014 "),Yie=n(Uao,"A",{href:!0});var A0a=s(Yie);qbt=r(A0a,"TFFlaubertForQuestionAnsweringSimple"),A0a.forEach(t),Dbt=r(Uao," (FlauBERT model)"),Uao.forEach(t),jbt=i(be),v8=n(be,"LI",{});var Hao=s(v8);IRe=n(Hao,"STRONG",{});var L0a=s(IRe);Gbt=r(L0a,"funnel"),L0a.forEach(t),Obt=r(Hao," \u2014 "),Zie=n(Hao,"A",{href:!0});var y0a=s(Zie);Vbt=r(y0a,"TFFunnelForQuestionAnswering"),y0a.forEach(t),Xbt=r(Hao," (Funnel Transformer model)"),Hao.forEach(t),zbt=i(be),F8=n(be,"LI",{});var Jao=s(F8);NRe=n(Jao,"STRONG",{});var x0a=s(NRe);Qbt=r(x0a,"gptj"),x0a.forEach(t),Wbt=r(Jao," \u2014 "),Kie=n(Jao,"A",{href:!0});var $0a=s(Kie);Ubt=r($0a,"TFGPTJForQuestionAnswering"),$0a.forEach(t),Hbt=r(Jao," (GPT-J model)"),Jao.forEach(t),Jbt=i(be),T8=n(be,"LI",{});var Yao=s(T8);qRe=n(Yao,"STRONG",{});var k0a=s(qRe);Ybt=r(k0a,"layoutlmv3"),k0a.forEach(t),Zbt=r(Yao," \u2014 "),ede=n(Yao,"A",{href:!0});var S0a=s(ede);Kbt=r(S0a,"TFLayoutLMv3ForQuestionAnswering"),S0a.forEach(t),evt=r(Yao," (LayoutLMv3 model)"),Yao.forEach(t),ovt=i(be),M8=n(be,"LI",{});var Zao=s(M8);DRe=n(Zao,"STRONG",{});var R0a=s(DRe);rvt=r(R0a,"longformer"),R0a.forEach(t),tvt=r(Zao," \u2014 "),ode=n(Zao,"A",{href:!0});var P0a=s(ode);avt=r(P0a,"TFLongformerForQuestionAnswering"),P0a.forEach(t),nvt=r(Zao," (Longformer model)"),Zao.forEach(t),svt=i(be),E8=n(be,"LI",{});var Kao=s(E8);jRe=n(Kao,"STRONG",{});var B0a=s(jRe);lvt=r(B0a,"mobilebert"),B0a.forEach(t),ivt=r(Kao," \u2014 "),rde=n(Kao,"A",{href:!0});var I0a=s(rde);dvt=r(I0a,"TFMobileBertForQuestionAnswering"),I0a.forEach(t),mvt=r(Kao," (MobileBERT model)"),Kao.forEach(t),cvt=i(be),C8=n(be,"LI",{});var eno=s(C8);GRe=n(eno,"STRONG",{});var N0a=s(GRe);fvt=r(N0a,"mpnet"),N0a.forEach(t),gvt=r(eno," \u2014 "),tde=n(eno,"A",{href:!0});var q0a=s(tde);hvt=r(q0a,"TFMPNetForQuestionAnswering"),q0a.forEach(t),uvt=r(eno," (MPNet model)"),eno.forEach(t),pvt=i(be),w8=n(be,"LI",{});var ono=s(w8);ORe=n(ono,"STRONG",{});var D0a=s(ORe);_vt=r(D0a,"rembert"),D0a.forEach(t),bvt=r(ono," \u2014 "),ade=n(ono,"A",{href:!0});var j0a=s(ade);vvt=r(j0a,"TFRemBertForQuestionAnswering"),j0a.forEach(t),Fvt=r(ono," (RemBERT model)"),ono.forEach(t),Tvt=i(be),A8=n(be,"LI",{});var rno=s(A8);VRe=n(rno,"STRONG",{});var G0a=s(VRe);Mvt=r(G0a,"roberta"),G0a.forEach(t),Evt=r(rno," \u2014 "),nde=n(rno,"A",{href:!0});var O0a=s(nde);Cvt=r(O0a,"TFRobertaForQuestionAnswering"),O0a.forEach(t),wvt=r(rno," (RoBERTa model)"),rno.forEach(t),Avt=i(be),L8=n(be,"LI",{});var tno=s(L8);XRe=n(tno,"STRONG",{});var V0a=s(XRe);Lvt=r(V0a,"roformer"),V0a.forEach(t),yvt=r(tno," \u2014 "),sde=n(tno,"A",{href:!0});var X0a=s(sde);xvt=r(X0a,"TFRoFormerForQuestionAnswering"),X0a.forEach(t),$vt=r(tno," (RoFormer model)"),tno.forEach(t),kvt=i(be),y8=n(be,"LI",{});var ano=s(y8);zRe=n(ano,"STRONG",{});var z0a=s(zRe);Svt=r(z0a,"xlm"),z0a.forEach(t),Rvt=r(ano," \u2014 "),lde=n(ano,"A",{href:!0});var Q0a=s(lde);Pvt=r(Q0a,"TFXLMForQuestionAnsweringSimple"),Q0a.forEach(t),Bvt=r(ano," (XLM model)"),ano.forEach(t),Ivt=i(be),x8=n(be,"LI",{});var nno=s(x8);QRe=n(nno,"STRONG",{});var W0a=s(QRe);Nvt=r(W0a,"xlm-roberta"),W0a.forEach(t),qvt=r(nno," \u2014 "),ide=n(nno,"A",{href:!0});var U0a=s(ide);Dvt=r(U0a,"TFXLMRobertaForQuestionAnswering"),U0a.forEach(t),jvt=r(nno," (XLM-RoBERTa model)"),nno.forEach(t),Gvt=i(be),$8=n(be,"LI",{});var sno=s($8);WRe=n(sno,"STRONG",{});var H0a=s(WRe);Ovt=r(H0a,"xlnet"),H0a.forEach(t),Vvt=r(sno," \u2014 "),dde=n(sno,"A",{href:!0});var J0a=s(dde);Xvt=r(J0a,"TFXLNetForQuestionAnsweringSimple"),J0a.forEach(t),zvt=r(sno," (XLNet model)"),sno.forEach(t),be.forEach(t),Qvt=i(Yi),T(k8.$$.fragment,Yi),Yi.forEach(t),Ji.forEach(t),tdo=i(c),df=n(c,"H2",{class:!0});var Lco=s(df);S8=n(Lco,"A",{id:!0,class:!0,href:!0});var Y0a=s(S8);URe=n(Y0a,"SPAN",{});var Z0a=s(URe);T(DB.$$.fragment,Z0a),Z0a.forEach(t),Y0a.forEach(t),Wvt=i(Lco),HRe=n(Lco,"SPAN",{});var K0a=s(HRe);Uvt=r(K0a,"TFAutoModelForVision2Seq"),K0a.forEach(t),Lco.forEach(t),ado=i(c),yr=n(c,"DIV",{class:!0});var Zi=s(yr);T(jB.$$.fragment,Zi),Hvt=i(Zi),mf=n(Zi,"P",{});var Nge=s(mf);Jvt=r(Nge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),mde=n(Nge,"A",{href:!0});var ewa=s(mde);Yvt=r(ewa,"from_pretrained()"),ewa.forEach(t),Zvt=r(Nge," class method or the "),cde=n(Nge,"A",{href:!0});var owa=s(cde);Kvt=r(owa,"from_config()"),owa.forEach(t),eFt=r(Nge,` class
method.`),Nge.forEach(t),oFt=i(Zi),GB=n(Zi,"P",{});var yco=s(GB);rFt=r(yco,"This class cannot be instantiated directly using "),JRe=n(yco,"CODE",{});var rwa=s(JRe);tFt=r(rwa,"__init__()"),rwa.forEach(t),aFt=r(yco," (throws an error)."),yco.forEach(t),nFt=i(Zi),ua=n(Zi,"DIV",{class:!0});var R$=s(ua);T(OB.$$.fragment,R$),sFt=i(R$),YRe=n(R$,"P",{});var twa=s(YRe);lFt=r(twa,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),twa.forEach(t),iFt=i(R$),cf=n(R$,"P",{});var qge=s(cf);dFt=r(qge,`Note:
Loading a model from its configuration file does `),ZRe=n(qge,"STRONG",{});var awa=s(ZRe);mFt=r(awa,"not"),awa.forEach(t),cFt=r(qge,` load the model weights. It only affects the
model\u2019s configuration. Use `),fde=n(qge,"A",{href:!0});var nwa=s(fde);fFt=r(nwa,"from_pretrained()"),nwa.forEach(t),gFt=r(qge," to load the model weights."),qge.forEach(t),hFt=i(R$),T(R8.$$.fragment,R$),R$.forEach(t),uFt=i(Zi),at=n(Zi,"DIV",{class:!0});var Ki=s(at);T(VB.$$.fragment,Ki),pFt=i(Ki),KRe=n(Ki,"P",{});var swa=s(KRe);_Ft=r(swa,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),swa.forEach(t),bFt=i(Ki),os=n(Ki,"P",{});var P$=s(os);vFt=r(P$,"The model class to instantiate is selected based on the "),ePe=n(P$,"CODE",{});var lwa=s(ePe);FFt=r(lwa,"model_type"),lwa.forEach(t),TFt=r(P$,` property of the config object (either
passed as an argument or loaded from `),oPe=n(P$,"CODE",{});var iwa=s(oPe);MFt=r(iwa,"pretrained_model_name_or_path"),iwa.forEach(t),EFt=r(P$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rPe=n(P$,"CODE",{});var dwa=s(rPe);CFt=r(dwa,"pretrained_model_name_or_path"),dwa.forEach(t),wFt=r(P$,":"),P$.forEach(t),AFt=i(Ki),tPe=n(Ki,"UL",{});var mwa=s(tPe);P8=n(mwa,"LI",{});var lno=s(P8);aPe=n(lno,"STRONG",{});var cwa=s(aPe);LFt=r(cwa,"vision-encoder-decoder"),cwa.forEach(t),yFt=r(lno," \u2014 "),gde=n(lno,"A",{href:!0});var fwa=s(gde);xFt=r(fwa,"TFVisionEncoderDecoderModel"),fwa.forEach(t),$Ft=r(lno," (Vision Encoder decoder model)"),lno.forEach(t),mwa.forEach(t),kFt=i(Ki),T(B8.$$.fragment,Ki),Ki.forEach(t),Zi.forEach(t),ndo=i(c),ff=n(c,"H2",{class:!0});var xco=s(ff);I8=n(xco,"A",{id:!0,class:!0,href:!0});var gwa=s(I8);nPe=n(gwa,"SPAN",{});var hwa=s(nPe);T(XB.$$.fragment,hwa),hwa.forEach(t),gwa.forEach(t),SFt=i(xco),sPe=n(xco,"SPAN",{});var uwa=s(sPe);RFt=r(uwa,"TFAutoModelForSpeechSeq2Seq"),uwa.forEach(t),xco.forEach(t),sdo=i(c),xr=n(c,"DIV",{class:!0});var ed=s(xr);T(zB.$$.fragment,ed),PFt=i(ed),gf=n(ed,"P",{});var Dge=s(gf);BFt=r(Dge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),hde=n(Dge,"A",{href:!0});var pwa=s(hde);IFt=r(pwa,"from_pretrained()"),pwa.forEach(t),NFt=r(Dge," class method or the "),ude=n(Dge,"A",{href:!0});var _wa=s(ude);qFt=r(_wa,"from_config()"),_wa.forEach(t),DFt=r(Dge,` class
method.`),Dge.forEach(t),jFt=i(ed),QB=n(ed,"P",{});var $co=s(QB);GFt=r($co,"This class cannot be instantiated directly using "),lPe=n($co,"CODE",{});var bwa=s(lPe);OFt=r(bwa,"__init__()"),bwa.forEach(t),VFt=r($co," (throws an error)."),$co.forEach(t),XFt=i(ed),pa=n(ed,"DIV",{class:!0});var B$=s(pa);T(WB.$$.fragment,B$),zFt=i(B$),iPe=n(B$,"P",{});var vwa=s(iPe);QFt=r(vwa,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),vwa.forEach(t),WFt=i(B$),hf=n(B$,"P",{});var jge=s(hf);UFt=r(jge,`Note:
Loading a model from its configuration file does `),dPe=n(jge,"STRONG",{});var Fwa=s(dPe);HFt=r(Fwa,"not"),Fwa.forEach(t),JFt=r(jge,` load the model weights. It only affects the
model\u2019s configuration. Use `),pde=n(jge,"A",{href:!0});var Twa=s(pde);YFt=r(Twa,"from_pretrained()"),Twa.forEach(t),ZFt=r(jge," to load the model weights."),jge.forEach(t),KFt=i(B$),T(N8.$$.fragment,B$),B$.forEach(t),eTt=i(ed),nt=n(ed,"DIV",{class:!0});var od=s(nt);T(UB.$$.fragment,od),oTt=i(od),mPe=n(od,"P",{});var Mwa=s(mPe);rTt=r(Mwa,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Mwa.forEach(t),tTt=i(od),rs=n(od,"P",{});var I$=s(rs);aTt=r(I$,"The model class to instantiate is selected based on the "),cPe=n(I$,"CODE",{});var Ewa=s(cPe);nTt=r(Ewa,"model_type"),Ewa.forEach(t),sTt=r(I$,` property of the config object (either
passed as an argument or loaded from `),fPe=n(I$,"CODE",{});var Cwa=s(fPe);lTt=r(Cwa,"pretrained_model_name_or_path"),Cwa.forEach(t),iTt=r(I$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gPe=n(I$,"CODE",{});var wwa=s(gPe);dTt=r(wwa,"pretrained_model_name_or_path"),wwa.forEach(t),mTt=r(I$,":"),I$.forEach(t),cTt=i(od),HB=n(od,"UL",{});var kco=s(HB);q8=n(kco,"LI",{});var ino=s(q8);hPe=n(ino,"STRONG",{});var Awa=s(hPe);fTt=r(Awa,"speech_to_text"),Awa.forEach(t),gTt=r(ino," \u2014 "),_de=n(ino,"A",{href:!0});var Lwa=s(_de);hTt=r(Lwa,"TFSpeech2TextForConditionalGeneration"),Lwa.forEach(t),uTt=r(ino," (Speech2Text model)"),ino.forEach(t),pTt=i(kco),D8=n(kco,"LI",{});var dno=s(D8);uPe=n(dno,"STRONG",{});var ywa=s(uPe);_Tt=r(ywa,"whisper"),ywa.forEach(t),bTt=r(dno," \u2014 "),bde=n(dno,"A",{href:!0});var xwa=s(bde);vTt=r(xwa,"TFWhisperForConditionalGeneration"),xwa.forEach(t),FTt=r(dno," (Whisper model)"),dno.forEach(t),kco.forEach(t),TTt=i(od),T(j8.$$.fragment,od),od.forEach(t),ed.forEach(t),ldo=i(c),uf=n(c,"H2",{class:!0});var Sco=s(uf);G8=n(Sco,"A",{id:!0,class:!0,href:!0});var $wa=s(G8);pPe=n($wa,"SPAN",{});var kwa=s(pPe);T(JB.$$.fragment,kwa),kwa.forEach(t),$wa.forEach(t),MTt=i(Sco),_Pe=n(Sco,"SPAN",{});var Swa=s(_Pe);ETt=r(Swa,"FlaxAutoModel"),Swa.forEach(t),Sco.forEach(t),ido=i(c),$r=n(c,"DIV",{class:!0});var rd=s($r);T(YB.$$.fragment,rd),CTt=i(rd),pf=n(rd,"P",{});var Gge=s(pf);wTt=r(Gge,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),vde=n(Gge,"A",{href:!0});var Rwa=s(vde);ATt=r(Rwa,"from_pretrained()"),Rwa.forEach(t),LTt=r(Gge," class method or the "),Fde=n(Gge,"A",{href:!0});var Pwa=s(Fde);yTt=r(Pwa,"from_config()"),Pwa.forEach(t),xTt=r(Gge,` class
method.`),Gge.forEach(t),$Tt=i(rd),ZB=n(rd,"P",{});var Rco=s(ZB);kTt=r(Rco,"This class cannot be instantiated directly using "),bPe=n(Rco,"CODE",{});var Bwa=s(bPe);STt=r(Bwa,"__init__()"),Bwa.forEach(t),RTt=r(Rco," (throws an error)."),Rco.forEach(t),PTt=i(rd),_a=n(rd,"DIV",{class:!0});var N$=s(_a);T(KB.$$.fragment,N$),BTt=i(N$),vPe=n(N$,"P",{});var Iwa=s(vPe);ITt=r(Iwa,"Instantiates one of the base model classes of the library from a configuration."),Iwa.forEach(t),NTt=i(N$),_f=n(N$,"P",{});var Oge=s(_f);qTt=r(Oge,`Note:
Loading a model from its configuration file does `),FPe=n(Oge,"STRONG",{});var Nwa=s(FPe);DTt=r(Nwa,"not"),Nwa.forEach(t),jTt=r(Oge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Tde=n(Oge,"A",{href:!0});var qwa=s(Tde);GTt=r(qwa,"from_pretrained()"),qwa.forEach(t),OTt=r(Oge," to load the model weights."),Oge.forEach(t),VTt=i(N$),T(O8.$$.fragment,N$),N$.forEach(t),XTt=i(rd),st=n(rd,"DIV",{class:!0});var td=s(st);T(eI.$$.fragment,td),zTt=i(td),TPe=n(td,"P",{});var Dwa=s(TPe);QTt=r(Dwa,"Instantiate one of the base model classes of the library from a pretrained model."),Dwa.forEach(t),WTt=i(td),ts=n(td,"P",{});var q$=s(ts);UTt=r(q$,"The model class to instantiate is selected based on the "),MPe=n(q$,"CODE",{});var jwa=s(MPe);HTt=r(jwa,"model_type"),jwa.forEach(t),JTt=r(q$,` property of the config object (either
passed as an argument or loaded from `),EPe=n(q$,"CODE",{});var Gwa=s(EPe);YTt=r(Gwa,"pretrained_model_name_or_path"),Gwa.forEach(t),ZTt=r(q$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),CPe=n(q$,"CODE",{});var Owa=s(CPe);KTt=r(Owa,"pretrained_model_name_or_path"),Owa.forEach(t),eMt=r(q$,":"),q$.forEach(t),oMt=i(td),ne=n(td,"UL",{});var le=s(ne);V8=n(le,"LI",{});var mno=s(V8);wPe=n(mno,"STRONG",{});var Vwa=s(wPe);rMt=r(Vwa,"albert"),Vwa.forEach(t),tMt=r(mno," \u2014 "),Mde=n(mno,"A",{href:!0});var Xwa=s(Mde);aMt=r(Xwa,"FlaxAlbertModel"),Xwa.forEach(t),nMt=r(mno," (ALBERT model)"),mno.forEach(t),sMt=i(le),X8=n(le,"LI",{});var cno=s(X8);APe=n(cno,"STRONG",{});var zwa=s(APe);lMt=r(zwa,"bart"),zwa.forEach(t),iMt=r(cno," \u2014 "),Ede=n(cno,"A",{href:!0});var Qwa=s(Ede);dMt=r(Qwa,"FlaxBartModel"),Qwa.forEach(t),mMt=r(cno," (BART model)"),cno.forEach(t),cMt=i(le),z8=n(le,"LI",{});var fno=s(z8);LPe=n(fno,"STRONG",{});var Wwa=s(LPe);fMt=r(Wwa,"beit"),Wwa.forEach(t),gMt=r(fno," \u2014 "),Cde=n(fno,"A",{href:!0});var Uwa=s(Cde);hMt=r(Uwa,"FlaxBeitModel"),Uwa.forEach(t),uMt=r(fno," (BEiT model)"),fno.forEach(t),pMt=i(le),Q8=n(le,"LI",{});var gno=s(Q8);yPe=n(gno,"STRONG",{});var Hwa=s(yPe);_Mt=r(Hwa,"bert"),Hwa.forEach(t),bMt=r(gno," \u2014 "),wde=n(gno,"A",{href:!0});var Jwa=s(wde);vMt=r(Jwa,"FlaxBertModel"),Jwa.forEach(t),FMt=r(gno," (BERT model)"),gno.forEach(t),TMt=i(le),W8=n(le,"LI",{});var hno=s(W8);xPe=n(hno,"STRONG",{});var Ywa=s(xPe);MMt=r(Ywa,"big_bird"),Ywa.forEach(t),EMt=r(hno," \u2014 "),Ade=n(hno,"A",{href:!0});var Zwa=s(Ade);CMt=r(Zwa,"FlaxBigBirdModel"),Zwa.forEach(t),wMt=r(hno," (BigBird model)"),hno.forEach(t),AMt=i(le),U8=n(le,"LI",{});var uno=s(U8);$Pe=n(uno,"STRONG",{});var Kwa=s($Pe);LMt=r(Kwa,"blenderbot"),Kwa.forEach(t),yMt=r(uno," \u2014 "),Lde=n(uno,"A",{href:!0});var eAa=s(Lde);xMt=r(eAa,"FlaxBlenderbotModel"),eAa.forEach(t),$Mt=r(uno," (Blenderbot model)"),uno.forEach(t),kMt=i(le),H8=n(le,"LI",{});var pno=s(H8);kPe=n(pno,"STRONG",{});var oAa=s(kPe);SMt=r(oAa,"blenderbot-small"),oAa.forEach(t),RMt=r(pno," \u2014 "),yde=n(pno,"A",{href:!0});var rAa=s(yde);PMt=r(rAa,"FlaxBlenderbotSmallModel"),rAa.forEach(t),BMt=r(pno," (BlenderbotSmall model)"),pno.forEach(t),IMt=i(le),J8=n(le,"LI",{});var _no=s(J8);SPe=n(_no,"STRONG",{});var tAa=s(SPe);NMt=r(tAa,"clip"),tAa.forEach(t),qMt=r(_no," \u2014 "),xde=n(_no,"A",{href:!0});var aAa=s(xde);DMt=r(aAa,"FlaxCLIPModel"),aAa.forEach(t),jMt=r(_no," (CLIP model)"),_no.forEach(t),GMt=i(le),Y8=n(le,"LI",{});var bno=s(Y8);RPe=n(bno,"STRONG",{});var nAa=s(RPe);OMt=r(nAa,"distilbert"),nAa.forEach(t),VMt=r(bno," \u2014 "),$de=n(bno,"A",{href:!0});var sAa=s($de);XMt=r(sAa,"FlaxDistilBertModel"),sAa.forEach(t),zMt=r(bno," (DistilBERT model)"),bno.forEach(t),QMt=i(le),Z8=n(le,"LI",{});var vno=s(Z8);PPe=n(vno,"STRONG",{});var lAa=s(PPe);WMt=r(lAa,"electra"),lAa.forEach(t),UMt=r(vno," \u2014 "),kde=n(vno,"A",{href:!0});var iAa=s(kde);HMt=r(iAa,"FlaxElectraModel"),iAa.forEach(t),JMt=r(vno," (ELECTRA model)"),vno.forEach(t),YMt=i(le),K8=n(le,"LI",{});var Fno=s(K8);BPe=n(Fno,"STRONG",{});var dAa=s(BPe);ZMt=r(dAa,"gpt2"),dAa.forEach(t),KMt=r(Fno," \u2014 "),Sde=n(Fno,"A",{href:!0});var mAa=s(Sde);eEt=r(mAa,"FlaxGPT2Model"),mAa.forEach(t),oEt=r(Fno," (OpenAI GPT-2 model)"),Fno.forEach(t),rEt=i(le),eL=n(le,"LI",{});var Tno=s(eL);IPe=n(Tno,"STRONG",{});var cAa=s(IPe);tEt=r(cAa,"gpt_neo"),cAa.forEach(t),aEt=r(Tno," \u2014 "),Rde=n(Tno,"A",{href:!0});var fAa=s(Rde);nEt=r(fAa,"FlaxGPTNeoModel"),fAa.forEach(t),sEt=r(Tno," (GPT Neo model)"),Tno.forEach(t),lEt=i(le),oL=n(le,"LI",{});var Mno=s(oL);NPe=n(Mno,"STRONG",{});var gAa=s(NPe);iEt=r(gAa,"gptj"),gAa.forEach(t),dEt=r(Mno," \u2014 "),Pde=n(Mno,"A",{href:!0});var hAa=s(Pde);mEt=r(hAa,"FlaxGPTJModel"),hAa.forEach(t),cEt=r(Mno," (GPT-J model)"),Mno.forEach(t),fEt=i(le),rL=n(le,"LI",{});var Eno=s(rL);qPe=n(Eno,"STRONG",{});var uAa=s(qPe);gEt=r(uAa,"longt5"),uAa.forEach(t),hEt=r(Eno," \u2014 "),Bde=n(Eno,"A",{href:!0});var pAa=s(Bde);uEt=r(pAa,"FlaxLongT5Model"),pAa.forEach(t),pEt=r(Eno," (LongT5 model)"),Eno.forEach(t),_Et=i(le),tL=n(le,"LI",{});var Cno=s(tL);DPe=n(Cno,"STRONG",{});var _Aa=s(DPe);bEt=r(_Aa,"marian"),_Aa.forEach(t),vEt=r(Cno," \u2014 "),Ide=n(Cno,"A",{href:!0});var bAa=s(Ide);FEt=r(bAa,"FlaxMarianModel"),bAa.forEach(t),TEt=r(Cno," (Marian model)"),Cno.forEach(t),MEt=i(le),aL=n(le,"LI",{});var wno=s(aL);jPe=n(wno,"STRONG",{});var vAa=s(jPe);EEt=r(vAa,"mbart"),vAa.forEach(t),CEt=r(wno," \u2014 "),Nde=n(wno,"A",{href:!0});var FAa=s(Nde);wEt=r(FAa,"FlaxMBartModel"),FAa.forEach(t),AEt=r(wno," (mBART model)"),wno.forEach(t),LEt=i(le),nL=n(le,"LI",{});var Ano=s(nL);GPe=n(Ano,"STRONG",{});var TAa=s(GPe);yEt=r(TAa,"mt5"),TAa.forEach(t),xEt=r(Ano," \u2014 "),qde=n(Ano,"A",{href:!0});var MAa=s(qde);$Et=r(MAa,"FlaxMT5Model"),MAa.forEach(t),kEt=r(Ano," (MT5 model)"),Ano.forEach(t),SEt=i(le),sL=n(le,"LI",{});var Lno=s(sL);OPe=n(Lno,"STRONG",{});var EAa=s(OPe);REt=r(EAa,"opt"),EAa.forEach(t),PEt=r(Lno," \u2014 "),Dde=n(Lno,"A",{href:!0});var CAa=s(Dde);BEt=r(CAa,"FlaxOPTModel"),CAa.forEach(t),IEt=r(Lno," (OPT model)"),Lno.forEach(t),NEt=i(le),lL=n(le,"LI",{});var yno=s(lL);VPe=n(yno,"STRONG",{});var wAa=s(VPe);qEt=r(wAa,"pegasus"),wAa.forEach(t),DEt=r(yno," \u2014 "),jde=n(yno,"A",{href:!0});var AAa=s(jde);jEt=r(AAa,"FlaxPegasusModel"),AAa.forEach(t),GEt=r(yno," (Pegasus model)"),yno.forEach(t),OEt=i(le),iL=n(le,"LI",{});var xno=s(iL);XPe=n(xno,"STRONG",{});var LAa=s(XPe);VEt=r(LAa,"roberta"),LAa.forEach(t),XEt=r(xno," \u2014 "),Gde=n(xno,"A",{href:!0});var yAa=s(Gde);zEt=r(yAa,"FlaxRobertaModel"),yAa.forEach(t),QEt=r(xno," (RoBERTa model)"),xno.forEach(t),WEt=i(le),dL=n(le,"LI",{});var $no=s(dL);zPe=n($no,"STRONG",{});var xAa=s(zPe);UEt=r(xAa,"roformer"),xAa.forEach(t),HEt=r($no," \u2014 "),Ode=n($no,"A",{href:!0});var $Aa=s(Ode);JEt=r($Aa,"FlaxRoFormerModel"),$Aa.forEach(t),YEt=r($no," (RoFormer model)"),$no.forEach(t),ZEt=i(le),mL=n(le,"LI",{});var kno=s(mL);QPe=n(kno,"STRONG",{});var kAa=s(QPe);KEt=r(kAa,"t5"),kAa.forEach(t),e4t=r(kno," \u2014 "),Vde=n(kno,"A",{href:!0});var SAa=s(Vde);o4t=r(SAa,"FlaxT5Model"),SAa.forEach(t),r4t=r(kno," (T5 model)"),kno.forEach(t),t4t=i(le),cL=n(le,"LI",{});var Sno=s(cL);WPe=n(Sno,"STRONG",{});var RAa=s(WPe);a4t=r(RAa,"vision-text-dual-encoder"),RAa.forEach(t),n4t=r(Sno," \u2014 "),Xde=n(Sno,"A",{href:!0});var PAa=s(Xde);s4t=r(PAa,"FlaxVisionTextDualEncoderModel"),PAa.forEach(t),l4t=r(Sno," (VisionTextDualEncoder model)"),Sno.forEach(t),i4t=i(le),fL=n(le,"LI",{});var Rno=s(fL);UPe=n(Rno,"STRONG",{});var BAa=s(UPe);d4t=r(BAa,"vit"),BAa.forEach(t),m4t=r(Rno," \u2014 "),zde=n(Rno,"A",{href:!0});var IAa=s(zde);c4t=r(IAa,"FlaxViTModel"),IAa.forEach(t),f4t=r(Rno," (ViT model)"),Rno.forEach(t),g4t=i(le),gL=n(le,"LI",{});var Pno=s(gL);HPe=n(Pno,"STRONG",{});var NAa=s(HPe);h4t=r(NAa,"wav2vec2"),NAa.forEach(t),u4t=r(Pno," \u2014 "),Qde=n(Pno,"A",{href:!0});var qAa=s(Qde);p4t=r(qAa,"FlaxWav2Vec2Model"),qAa.forEach(t),_4t=r(Pno," (Wav2Vec2 model)"),Pno.forEach(t),b4t=i(le),hL=n(le,"LI",{});var Bno=s(hL);JPe=n(Bno,"STRONG",{});var DAa=s(JPe);v4t=r(DAa,"xglm"),DAa.forEach(t),F4t=r(Bno," \u2014 "),Wde=n(Bno,"A",{href:!0});var jAa=s(Wde);T4t=r(jAa,"FlaxXGLMModel"),jAa.forEach(t),M4t=r(Bno," (XGLM model)"),Bno.forEach(t),E4t=i(le),uL=n(le,"LI",{});var Ino=s(uL);YPe=n(Ino,"STRONG",{});var GAa=s(YPe);C4t=r(GAa,"xlm-roberta"),GAa.forEach(t),w4t=r(Ino," \u2014 "),Ude=n(Ino,"A",{href:!0});var OAa=s(Ude);A4t=r(OAa,"FlaxXLMRobertaModel"),OAa.forEach(t),L4t=r(Ino," (XLM-RoBERTa model)"),Ino.forEach(t),le.forEach(t),y4t=i(td),T(pL.$$.fragment,td),td.forEach(t),rd.forEach(t),ddo=i(c),bf=n(c,"H2",{class:!0});var Pco=s(bf);_L=n(Pco,"A",{id:!0,class:!0,href:!0});var VAa=s(_L);ZPe=n(VAa,"SPAN",{});var XAa=s(ZPe);T(oI.$$.fragment,XAa),XAa.forEach(t),VAa.forEach(t),x4t=i(Pco),KPe=n(Pco,"SPAN",{});var zAa=s(KPe);$4t=r(zAa,"FlaxAutoModelForCausalLM"),zAa.forEach(t),Pco.forEach(t),mdo=i(c),kr=n(c,"DIV",{class:!0});var ad=s(kr);T(rI.$$.fragment,ad),k4t=i(ad),vf=n(ad,"P",{});var Vge=s(vf);S4t=r(Vge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Hde=n(Vge,"A",{href:!0});var QAa=s(Hde);R4t=r(QAa,"from_pretrained()"),QAa.forEach(t),P4t=r(Vge," class method or the "),Jde=n(Vge,"A",{href:!0});var WAa=s(Jde);B4t=r(WAa,"from_config()"),WAa.forEach(t),I4t=r(Vge,` class
method.`),Vge.forEach(t),N4t=i(ad),tI=n(ad,"P",{});var Bco=s(tI);q4t=r(Bco,"This class cannot be instantiated directly using "),eBe=n(Bco,"CODE",{});var UAa=s(eBe);D4t=r(UAa,"__init__()"),UAa.forEach(t),j4t=r(Bco," (throws an error)."),Bco.forEach(t),G4t=i(ad),ba=n(ad,"DIV",{class:!0});var D$=s(ba);T(aI.$$.fragment,D$),O4t=i(D$),oBe=n(D$,"P",{});var HAa=s(oBe);V4t=r(HAa,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),HAa.forEach(t),X4t=i(D$),Ff=n(D$,"P",{});var Xge=s(Ff);z4t=r(Xge,`Note:
Loading a model from its configuration file does `),rBe=n(Xge,"STRONG",{});var JAa=s(rBe);Q4t=r(JAa,"not"),JAa.forEach(t),W4t=r(Xge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Yde=n(Xge,"A",{href:!0});var YAa=s(Yde);U4t=r(YAa,"from_pretrained()"),YAa.forEach(t),H4t=r(Xge," to load the model weights."),Xge.forEach(t),J4t=i(D$),T(bL.$$.fragment,D$),D$.forEach(t),Y4t=i(ad),lt=n(ad,"DIV",{class:!0});var nd=s(lt);T(nI.$$.fragment,nd),Z4t=i(nd),tBe=n(nd,"P",{});var ZAa=s(tBe);K4t=r(ZAa,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),ZAa.forEach(t),eCt=i(nd),as=n(nd,"P",{});var j$=s(as);oCt=r(j$,"The model class to instantiate is selected based on the "),aBe=n(j$,"CODE",{});var KAa=s(aBe);rCt=r(KAa,"model_type"),KAa.forEach(t),tCt=r(j$,` property of the config object (either
passed as an argument or loaded from `),nBe=n(j$,"CODE",{});var e6a=s(nBe);aCt=r(e6a,"pretrained_model_name_or_path"),e6a.forEach(t),nCt=r(j$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sBe=n(j$,"CODE",{});var o6a=s(sBe);sCt=r(o6a,"pretrained_model_name_or_path"),o6a.forEach(t),lCt=r(j$,":"),j$.forEach(t),iCt=i(nd),Se=n(nd,"UL",{});var Ge=s(Se);vL=n(Ge,"LI",{});var Nno=s(vL);lBe=n(Nno,"STRONG",{});var r6a=s(lBe);dCt=r(r6a,"bart"),r6a.forEach(t),mCt=r(Nno," \u2014 "),Zde=n(Nno,"A",{href:!0});var t6a=s(Zde);cCt=r(t6a,"FlaxBartForCausalLM"),t6a.forEach(t),fCt=r(Nno," (BART model)"),Nno.forEach(t),gCt=i(Ge),FL=n(Ge,"LI",{});var qno=s(FL);iBe=n(qno,"STRONG",{});var a6a=s(iBe);hCt=r(a6a,"bert"),a6a.forEach(t),uCt=r(qno," \u2014 "),Kde=n(qno,"A",{href:!0});var n6a=s(Kde);pCt=r(n6a,"FlaxBertForCausalLM"),n6a.forEach(t),_Ct=r(qno," (BERT model)"),qno.forEach(t),bCt=i(Ge),TL=n(Ge,"LI",{});var Dno=s(TL);dBe=n(Dno,"STRONG",{});var s6a=s(dBe);vCt=r(s6a,"big_bird"),s6a.forEach(t),FCt=r(Dno," \u2014 "),eme=n(Dno,"A",{href:!0});var l6a=s(eme);TCt=r(l6a,"FlaxBigBirdForCausalLM"),l6a.forEach(t),MCt=r(Dno," (BigBird model)"),Dno.forEach(t),ECt=i(Ge),ML=n(Ge,"LI",{});var jno=s(ML);mBe=n(jno,"STRONG",{});var i6a=s(mBe);CCt=r(i6a,"electra"),i6a.forEach(t),wCt=r(jno," \u2014 "),ome=n(jno,"A",{href:!0});var d6a=s(ome);ACt=r(d6a,"FlaxElectraForCausalLM"),d6a.forEach(t),LCt=r(jno," (ELECTRA model)"),jno.forEach(t),yCt=i(Ge),EL=n(Ge,"LI",{});var Gno=s(EL);cBe=n(Gno,"STRONG",{});var m6a=s(cBe);xCt=r(m6a,"gpt2"),m6a.forEach(t),$Ct=r(Gno," \u2014 "),rme=n(Gno,"A",{href:!0});var c6a=s(rme);kCt=r(c6a,"FlaxGPT2LMHeadModel"),c6a.forEach(t),SCt=r(Gno," (OpenAI GPT-2 model)"),Gno.forEach(t),RCt=i(Ge),CL=n(Ge,"LI",{});var Ono=s(CL);fBe=n(Ono,"STRONG",{});var f6a=s(fBe);PCt=r(f6a,"gpt_neo"),f6a.forEach(t),BCt=r(Ono," \u2014 "),tme=n(Ono,"A",{href:!0});var g6a=s(tme);ICt=r(g6a,"FlaxGPTNeoForCausalLM"),g6a.forEach(t),NCt=r(Ono," (GPT Neo model)"),Ono.forEach(t),qCt=i(Ge),wL=n(Ge,"LI",{});var Vno=s(wL);gBe=n(Vno,"STRONG",{});var h6a=s(gBe);DCt=r(h6a,"gptj"),h6a.forEach(t),jCt=r(Vno," \u2014 "),ame=n(Vno,"A",{href:!0});var u6a=s(ame);GCt=r(u6a,"FlaxGPTJForCausalLM"),u6a.forEach(t),OCt=r(Vno," (GPT-J model)"),Vno.forEach(t),VCt=i(Ge),AL=n(Ge,"LI",{});var Xno=s(AL);hBe=n(Xno,"STRONG",{});var p6a=s(hBe);XCt=r(p6a,"opt"),p6a.forEach(t),zCt=r(Xno," \u2014 "),nme=n(Xno,"A",{href:!0});var _6a=s(nme);QCt=r(_6a,"FlaxOPTForCausalLM"),_6a.forEach(t),WCt=r(Xno," (OPT model)"),Xno.forEach(t),UCt=i(Ge),LL=n(Ge,"LI",{});var zno=s(LL);uBe=n(zno,"STRONG",{});var b6a=s(uBe);HCt=r(b6a,"roberta"),b6a.forEach(t),JCt=r(zno," \u2014 "),sme=n(zno,"A",{href:!0});var v6a=s(sme);YCt=r(v6a,"FlaxRobertaForCausalLM"),v6a.forEach(t),ZCt=r(zno," (RoBERTa model)"),zno.forEach(t),KCt=i(Ge),yL=n(Ge,"LI",{});var Qno=s(yL);pBe=n(Qno,"STRONG",{});var F6a=s(pBe);e3t=r(F6a,"xglm"),F6a.forEach(t),o3t=r(Qno," \u2014 "),lme=n(Qno,"A",{href:!0});var T6a=s(lme);r3t=r(T6a,"FlaxXGLMForCausalLM"),T6a.forEach(t),t3t=r(Qno," (XGLM model)"),Qno.forEach(t),Ge.forEach(t),a3t=i(nd),T(xL.$$.fragment,nd),nd.forEach(t),ad.forEach(t),cdo=i(c),Tf=n(c,"H2",{class:!0});var Ico=s(Tf);$L=n(Ico,"A",{id:!0,class:!0,href:!0});var M6a=s($L);_Be=n(M6a,"SPAN",{});var E6a=s(_Be);T(sI.$$.fragment,E6a),E6a.forEach(t),M6a.forEach(t),n3t=i(Ico),bBe=n(Ico,"SPAN",{});var C6a=s(bBe);s3t=r(C6a,"FlaxAutoModelForPreTraining"),C6a.forEach(t),Ico.forEach(t),fdo=i(c),Sr=n(c,"DIV",{class:!0});var sd=s(Sr);T(lI.$$.fragment,sd),l3t=i(sd),Mf=n(sd,"P",{});var zge=s(Mf);i3t=r(zge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),ime=n(zge,"A",{href:!0});var w6a=s(ime);d3t=r(w6a,"from_pretrained()"),w6a.forEach(t),m3t=r(zge," class method or the "),dme=n(zge,"A",{href:!0});var A6a=s(dme);c3t=r(A6a,"from_config()"),A6a.forEach(t),f3t=r(zge,` class
method.`),zge.forEach(t),g3t=i(sd),iI=n(sd,"P",{});var Nco=s(iI);h3t=r(Nco,"This class cannot be instantiated directly using "),vBe=n(Nco,"CODE",{});var L6a=s(vBe);u3t=r(L6a,"__init__()"),L6a.forEach(t),p3t=r(Nco," (throws an error)."),Nco.forEach(t),_3t=i(sd),va=n(sd,"DIV",{class:!0});var G$=s(va);T(dI.$$.fragment,G$),b3t=i(G$),FBe=n(G$,"P",{});var y6a=s(FBe);v3t=r(y6a,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),y6a.forEach(t),F3t=i(G$),Ef=n(G$,"P",{});var Qge=s(Ef);T3t=r(Qge,`Note:
Loading a model from its configuration file does `),TBe=n(Qge,"STRONG",{});var x6a=s(TBe);M3t=r(x6a,"not"),x6a.forEach(t),E3t=r(Qge,` load the model weights. It only affects the
model\u2019s configuration. Use `),mme=n(Qge,"A",{href:!0});var $6a=s(mme);C3t=r($6a,"from_pretrained()"),$6a.forEach(t),w3t=r(Qge," to load the model weights."),Qge.forEach(t),A3t=i(G$),T(kL.$$.fragment,G$),G$.forEach(t),L3t=i(sd),it=n(sd,"DIV",{class:!0});var ld=s(it);T(mI.$$.fragment,ld),y3t=i(ld),MBe=n(ld,"P",{});var k6a=s(MBe);x3t=r(k6a,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),k6a.forEach(t),$3t=i(ld),ns=n(ld,"P",{});var O$=s(ns);k3t=r(O$,"The model class to instantiate is selected based on the "),EBe=n(O$,"CODE",{});var S6a=s(EBe);S3t=r(S6a,"model_type"),S6a.forEach(t),R3t=r(O$,` property of the config object (either
passed as an argument or loaded from `),CBe=n(O$,"CODE",{});var R6a=s(CBe);P3t=r(R6a,"pretrained_model_name_or_path"),R6a.forEach(t),B3t=r(O$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wBe=n(O$,"CODE",{});var P6a=s(wBe);I3t=r(P6a,"pretrained_model_name_or_path"),P6a.forEach(t),N3t=r(O$,":"),O$.forEach(t),q3t=i(ld),we=n(ld,"UL",{});var Le=s(we);SL=n(Le,"LI",{});var Wno=s(SL);ABe=n(Wno,"STRONG",{});var B6a=s(ABe);D3t=r(B6a,"albert"),B6a.forEach(t),j3t=r(Wno," \u2014 "),cme=n(Wno,"A",{href:!0});var I6a=s(cme);G3t=r(I6a,"FlaxAlbertForPreTraining"),I6a.forEach(t),O3t=r(Wno," (ALBERT model)"),Wno.forEach(t),V3t=i(Le),RL=n(Le,"LI",{});var Uno=s(RL);LBe=n(Uno,"STRONG",{});var N6a=s(LBe);X3t=r(N6a,"bart"),N6a.forEach(t),z3t=r(Uno," \u2014 "),fme=n(Uno,"A",{href:!0});var q6a=s(fme);Q3t=r(q6a,"FlaxBartForConditionalGeneration"),q6a.forEach(t),W3t=r(Uno," (BART model)"),Uno.forEach(t),U3t=i(Le),PL=n(Le,"LI",{});var Hno=s(PL);yBe=n(Hno,"STRONG",{});var D6a=s(yBe);H3t=r(D6a,"bert"),D6a.forEach(t),J3t=r(Hno," \u2014 "),gme=n(Hno,"A",{href:!0});var j6a=s(gme);Y3t=r(j6a,"FlaxBertForPreTraining"),j6a.forEach(t),Z3t=r(Hno," (BERT model)"),Hno.forEach(t),K3t=i(Le),BL=n(Le,"LI",{});var Jno=s(BL);xBe=n(Jno,"STRONG",{});var G6a=s(xBe);e5t=r(G6a,"big_bird"),G6a.forEach(t),o5t=r(Jno," \u2014 "),hme=n(Jno,"A",{href:!0});var O6a=s(hme);r5t=r(O6a,"FlaxBigBirdForPreTraining"),O6a.forEach(t),t5t=r(Jno," (BigBird model)"),Jno.forEach(t),a5t=i(Le),IL=n(Le,"LI",{});var Yno=s(IL);$Be=n(Yno,"STRONG",{});var V6a=s($Be);n5t=r(V6a,"electra"),V6a.forEach(t),s5t=r(Yno," \u2014 "),ume=n(Yno,"A",{href:!0});var X6a=s(ume);l5t=r(X6a,"FlaxElectraForPreTraining"),X6a.forEach(t),i5t=r(Yno," (ELECTRA model)"),Yno.forEach(t),d5t=i(Le),NL=n(Le,"LI",{});var Zno=s(NL);kBe=n(Zno,"STRONG",{});var z6a=s(kBe);m5t=r(z6a,"longt5"),z6a.forEach(t),c5t=r(Zno," \u2014 "),pme=n(Zno,"A",{href:!0});var Q6a=s(pme);f5t=r(Q6a,"FlaxLongT5ForConditionalGeneration"),Q6a.forEach(t),g5t=r(Zno," (LongT5 model)"),Zno.forEach(t),h5t=i(Le),qL=n(Le,"LI",{});var Kno=s(qL);SBe=n(Kno,"STRONG",{});var W6a=s(SBe);u5t=r(W6a,"mbart"),W6a.forEach(t),p5t=r(Kno," \u2014 "),_me=n(Kno,"A",{href:!0});var U6a=s(_me);_5t=r(U6a,"FlaxMBartForConditionalGeneration"),U6a.forEach(t),b5t=r(Kno," (mBART model)"),Kno.forEach(t),v5t=i(Le),DL=n(Le,"LI",{});var eso=s(DL);RBe=n(eso,"STRONG",{});var H6a=s(RBe);F5t=r(H6a,"mt5"),H6a.forEach(t),T5t=r(eso," \u2014 "),bme=n(eso,"A",{href:!0});var J6a=s(bme);M5t=r(J6a,"FlaxMT5ForConditionalGeneration"),J6a.forEach(t),E5t=r(eso," (MT5 model)"),eso.forEach(t),C5t=i(Le),jL=n(Le,"LI",{});var oso=s(jL);PBe=n(oso,"STRONG",{});var Y6a=s(PBe);w5t=r(Y6a,"roberta"),Y6a.forEach(t),A5t=r(oso," \u2014 "),vme=n(oso,"A",{href:!0});var Z6a=s(vme);L5t=r(Z6a,"FlaxRobertaForMaskedLM"),Z6a.forEach(t),y5t=r(oso," (RoBERTa model)"),oso.forEach(t),x5t=i(Le),GL=n(Le,"LI",{});var rso=s(GL);BBe=n(rso,"STRONG",{});var K6a=s(BBe);$5t=r(K6a,"roformer"),K6a.forEach(t),k5t=r(rso," \u2014 "),Fme=n(rso,"A",{href:!0});var e7a=s(Fme);S5t=r(e7a,"FlaxRoFormerForMaskedLM"),e7a.forEach(t),R5t=r(rso," (RoFormer model)"),rso.forEach(t),P5t=i(Le),OL=n(Le,"LI",{});var tso=s(OL);IBe=n(tso,"STRONG",{});var o7a=s(IBe);B5t=r(o7a,"t5"),o7a.forEach(t),I5t=r(tso," \u2014 "),Tme=n(tso,"A",{href:!0});var r7a=s(Tme);N5t=r(r7a,"FlaxT5ForConditionalGeneration"),r7a.forEach(t),q5t=r(tso," (T5 model)"),tso.forEach(t),D5t=i(Le),VL=n(Le,"LI",{});var aso=s(VL);NBe=n(aso,"STRONG",{});var t7a=s(NBe);j5t=r(t7a,"wav2vec2"),t7a.forEach(t),G5t=r(aso," \u2014 "),Mme=n(aso,"A",{href:!0});var a7a=s(Mme);O5t=r(a7a,"FlaxWav2Vec2ForPreTraining"),a7a.forEach(t),V5t=r(aso," (Wav2Vec2 model)"),aso.forEach(t),X5t=i(Le),XL=n(Le,"LI",{});var nso=s(XL);qBe=n(nso,"STRONG",{});var n7a=s(qBe);z5t=r(n7a,"xlm-roberta"),n7a.forEach(t),Q5t=r(nso," \u2014 "),Eme=n(nso,"A",{href:!0});var s7a=s(Eme);W5t=r(s7a,"FlaxXLMRobertaForMaskedLM"),s7a.forEach(t),U5t=r(nso," (XLM-RoBERTa model)"),nso.forEach(t),Le.forEach(t),H5t=i(ld),T(zL.$$.fragment,ld),ld.forEach(t),sd.forEach(t),gdo=i(c),Cf=n(c,"H2",{class:!0});var qco=s(Cf);QL=n(qco,"A",{id:!0,class:!0,href:!0});var l7a=s(QL);DBe=n(l7a,"SPAN",{});var i7a=s(DBe);T(cI.$$.fragment,i7a),i7a.forEach(t),l7a.forEach(t),J5t=i(qco),jBe=n(qco,"SPAN",{});var d7a=s(jBe);Y5t=r(d7a,"FlaxAutoModelForMaskedLM"),d7a.forEach(t),qco.forEach(t),hdo=i(c),Rr=n(c,"DIV",{class:!0});var id=s(Rr);T(fI.$$.fragment,id),Z5t=i(id),wf=n(id,"P",{});var Wge=s(wf);K5t=r(Wge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Cme=n(Wge,"A",{href:!0});var m7a=s(Cme);e0t=r(m7a,"from_pretrained()"),m7a.forEach(t),o0t=r(Wge," class method or the "),wme=n(Wge,"A",{href:!0});var c7a=s(wme);r0t=r(c7a,"from_config()"),c7a.forEach(t),t0t=r(Wge,` class
method.`),Wge.forEach(t),a0t=i(id),gI=n(id,"P",{});var Dco=s(gI);n0t=r(Dco,"This class cannot be instantiated directly using "),GBe=n(Dco,"CODE",{});var f7a=s(GBe);s0t=r(f7a,"__init__()"),f7a.forEach(t),l0t=r(Dco," (throws an error)."),Dco.forEach(t),i0t=i(id),Fa=n(id,"DIV",{class:!0});var V$=s(Fa);T(hI.$$.fragment,V$),d0t=i(V$),OBe=n(V$,"P",{});var g7a=s(OBe);m0t=r(g7a,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),g7a.forEach(t),c0t=i(V$),Af=n(V$,"P",{});var Uge=s(Af);f0t=r(Uge,`Note:
Loading a model from its configuration file does `),VBe=n(Uge,"STRONG",{});var h7a=s(VBe);g0t=r(h7a,"not"),h7a.forEach(t),h0t=r(Uge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ame=n(Uge,"A",{href:!0});var u7a=s(Ame);u0t=r(u7a,"from_pretrained()"),u7a.forEach(t),p0t=r(Uge," to load the model weights."),Uge.forEach(t),_0t=i(V$),T(WL.$$.fragment,V$),V$.forEach(t),b0t=i(id),dt=n(id,"DIV",{class:!0});var dd=s(dt);T(uI.$$.fragment,dd),v0t=i(dd),XBe=n(dd,"P",{});var p7a=s(XBe);F0t=r(p7a,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),p7a.forEach(t),T0t=i(dd),ss=n(dd,"P",{});var X$=s(ss);M0t=r(X$,"The model class to instantiate is selected based on the "),zBe=n(X$,"CODE",{});var _7a=s(zBe);E0t=r(_7a,"model_type"),_7a.forEach(t),C0t=r(X$,` property of the config object (either
passed as an argument or loaded from `),QBe=n(X$,"CODE",{});var b7a=s(QBe);w0t=r(b7a,"pretrained_model_name_or_path"),b7a.forEach(t),A0t=r(X$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),WBe=n(X$,"CODE",{});var v7a=s(WBe);L0t=r(v7a,"pretrained_model_name_or_path"),v7a.forEach(t),y0t=r(X$,":"),X$.forEach(t),x0t=i(dd),Re=n(dd,"UL",{});var Oe=s(Re);UL=n(Oe,"LI",{});var sso=s(UL);UBe=n(sso,"STRONG",{});var F7a=s(UBe);$0t=r(F7a,"albert"),F7a.forEach(t),k0t=r(sso," \u2014 "),Lme=n(sso,"A",{href:!0});var T7a=s(Lme);S0t=r(T7a,"FlaxAlbertForMaskedLM"),T7a.forEach(t),R0t=r(sso," (ALBERT model)"),sso.forEach(t),P0t=i(Oe),HL=n(Oe,"LI",{});var lso=s(HL);HBe=n(lso,"STRONG",{});var M7a=s(HBe);B0t=r(M7a,"bart"),M7a.forEach(t),I0t=r(lso," \u2014 "),yme=n(lso,"A",{href:!0});var E7a=s(yme);N0t=r(E7a,"FlaxBartForConditionalGeneration"),E7a.forEach(t),q0t=r(lso," (BART model)"),lso.forEach(t),D0t=i(Oe),JL=n(Oe,"LI",{});var iso=s(JL);JBe=n(iso,"STRONG",{});var C7a=s(JBe);j0t=r(C7a,"bert"),C7a.forEach(t),G0t=r(iso," \u2014 "),xme=n(iso,"A",{href:!0});var w7a=s(xme);O0t=r(w7a,"FlaxBertForMaskedLM"),w7a.forEach(t),V0t=r(iso," (BERT model)"),iso.forEach(t),X0t=i(Oe),YL=n(Oe,"LI",{});var dso=s(YL);YBe=n(dso,"STRONG",{});var A7a=s(YBe);z0t=r(A7a,"big_bird"),A7a.forEach(t),Q0t=r(dso," \u2014 "),$me=n(dso,"A",{href:!0});var L7a=s($me);W0t=r(L7a,"FlaxBigBirdForMaskedLM"),L7a.forEach(t),U0t=r(dso," (BigBird model)"),dso.forEach(t),H0t=i(Oe),ZL=n(Oe,"LI",{});var mso=s(ZL);ZBe=n(mso,"STRONG",{});var y7a=s(ZBe);J0t=r(y7a,"distilbert"),y7a.forEach(t),Y0t=r(mso," \u2014 "),kme=n(mso,"A",{href:!0});var x7a=s(kme);Z0t=r(x7a,"FlaxDistilBertForMaskedLM"),x7a.forEach(t),K0t=r(mso," (DistilBERT model)"),mso.forEach(t),ewt=i(Oe),KL=n(Oe,"LI",{});var cso=s(KL);KBe=n(cso,"STRONG",{});var $7a=s(KBe);owt=r($7a,"electra"),$7a.forEach(t),rwt=r(cso," \u2014 "),Sme=n(cso,"A",{href:!0});var k7a=s(Sme);twt=r(k7a,"FlaxElectraForMaskedLM"),k7a.forEach(t),awt=r(cso," (ELECTRA model)"),cso.forEach(t),nwt=i(Oe),ey=n(Oe,"LI",{});var fso=s(ey);eIe=n(fso,"STRONG",{});var S7a=s(eIe);swt=r(S7a,"mbart"),S7a.forEach(t),lwt=r(fso," \u2014 "),Rme=n(fso,"A",{href:!0});var R7a=s(Rme);iwt=r(R7a,"FlaxMBartForConditionalGeneration"),R7a.forEach(t),dwt=r(fso," (mBART model)"),fso.forEach(t),mwt=i(Oe),oy=n(Oe,"LI",{});var gso=s(oy);oIe=n(gso,"STRONG",{});var P7a=s(oIe);cwt=r(P7a,"roberta"),P7a.forEach(t),fwt=r(gso," \u2014 "),Pme=n(gso,"A",{href:!0});var B7a=s(Pme);gwt=r(B7a,"FlaxRobertaForMaskedLM"),B7a.forEach(t),hwt=r(gso," (RoBERTa model)"),gso.forEach(t),uwt=i(Oe),ry=n(Oe,"LI",{});var hso=s(ry);rIe=n(hso,"STRONG",{});var I7a=s(rIe);pwt=r(I7a,"roformer"),I7a.forEach(t),_wt=r(hso," \u2014 "),Bme=n(hso,"A",{href:!0});var N7a=s(Bme);bwt=r(N7a,"FlaxRoFormerForMaskedLM"),N7a.forEach(t),vwt=r(hso," (RoFormer model)"),hso.forEach(t),Fwt=i(Oe),ty=n(Oe,"LI",{});var uso=s(ty);tIe=n(uso,"STRONG",{});var q7a=s(tIe);Twt=r(q7a,"xlm-roberta"),q7a.forEach(t),Mwt=r(uso," \u2014 "),Ime=n(uso,"A",{href:!0});var D7a=s(Ime);Ewt=r(D7a,"FlaxXLMRobertaForMaskedLM"),D7a.forEach(t),Cwt=r(uso," (XLM-RoBERTa model)"),uso.forEach(t),Oe.forEach(t),wwt=i(dd),T(ay.$$.fragment,dd),dd.forEach(t),id.forEach(t),udo=i(c),Lf=n(c,"H2",{class:!0});var jco=s(Lf);ny=n(jco,"A",{id:!0,class:!0,href:!0});var j7a=s(ny);aIe=n(j7a,"SPAN",{});var G7a=s(aIe);T(pI.$$.fragment,G7a),G7a.forEach(t),j7a.forEach(t),Awt=i(jco),nIe=n(jco,"SPAN",{});var O7a=s(nIe);Lwt=r(O7a,"FlaxAutoModelForSeq2SeqLM"),O7a.forEach(t),jco.forEach(t),pdo=i(c),Pr=n(c,"DIV",{class:!0});var md=s(Pr);T(_I.$$.fragment,md),ywt=i(md),yf=n(md,"P",{});var Hge=s(yf);xwt=r(Hge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Nme=n(Hge,"A",{href:!0});var V7a=s(Nme);$wt=r(V7a,"from_pretrained()"),V7a.forEach(t),kwt=r(Hge," class method or the "),qme=n(Hge,"A",{href:!0});var X7a=s(qme);Swt=r(X7a,"from_config()"),X7a.forEach(t),Rwt=r(Hge,` class
method.`),Hge.forEach(t),Pwt=i(md),bI=n(md,"P",{});var Gco=s(bI);Bwt=r(Gco,"This class cannot be instantiated directly using "),sIe=n(Gco,"CODE",{});var z7a=s(sIe);Iwt=r(z7a,"__init__()"),z7a.forEach(t),Nwt=r(Gco," (throws an error)."),Gco.forEach(t),qwt=i(md),Ta=n(md,"DIV",{class:!0});var z$=s(Ta);T(vI.$$.fragment,z$),Dwt=i(z$),lIe=n(z$,"P",{});var Q7a=s(lIe);jwt=r(Q7a,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Q7a.forEach(t),Gwt=i(z$),xf=n(z$,"P",{});var Jge=s(xf);Owt=r(Jge,`Note:
Loading a model from its configuration file does `),iIe=n(Jge,"STRONG",{});var W7a=s(iIe);Vwt=r(W7a,"not"),W7a.forEach(t),Xwt=r(Jge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Dme=n(Jge,"A",{href:!0});var U7a=s(Dme);zwt=r(U7a,"from_pretrained()"),U7a.forEach(t),Qwt=r(Jge," to load the model weights."),Jge.forEach(t),Wwt=i(z$),T(sy.$$.fragment,z$),z$.forEach(t),Uwt=i(md),mt=n(md,"DIV",{class:!0});var cd=s(mt);T(FI.$$.fragment,cd),Hwt=i(cd),dIe=n(cd,"P",{});var H7a=s(dIe);Jwt=r(H7a,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),H7a.forEach(t),Ywt=i(cd),ls=n(cd,"P",{});var Q$=s(ls);Zwt=r(Q$,"The model class to instantiate is selected based on the "),mIe=n(Q$,"CODE",{});var J7a=s(mIe);Kwt=r(J7a,"model_type"),J7a.forEach(t),eAt=r(Q$,` property of the config object (either
passed as an argument or loaded from `),cIe=n(Q$,"CODE",{});var Y7a=s(cIe);oAt=r(Y7a,"pretrained_model_name_or_path"),Y7a.forEach(t),rAt=r(Q$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fIe=n(Q$,"CODE",{});var Z7a=s(fIe);tAt=r(Z7a,"pretrained_model_name_or_path"),Z7a.forEach(t),aAt=r(Q$,":"),Q$.forEach(t),nAt=i(cd),Pe=n(cd,"UL",{});var Ve=s(Pe);ly=n(Ve,"LI",{});var pso=s(ly);gIe=n(pso,"STRONG",{});var K7a=s(gIe);sAt=r(K7a,"bart"),K7a.forEach(t),lAt=r(pso," \u2014 "),jme=n(pso,"A",{href:!0});var e8a=s(jme);iAt=r(e8a,"FlaxBartForConditionalGeneration"),e8a.forEach(t),dAt=r(pso," (BART model)"),pso.forEach(t),mAt=i(Ve),iy=n(Ve,"LI",{});var _so=s(iy);hIe=n(_so,"STRONG",{});var o8a=s(hIe);cAt=r(o8a,"blenderbot"),o8a.forEach(t),fAt=r(_so," \u2014 "),Gme=n(_so,"A",{href:!0});var r8a=s(Gme);gAt=r(r8a,"FlaxBlenderbotForConditionalGeneration"),r8a.forEach(t),hAt=r(_so," (Blenderbot model)"),_so.forEach(t),uAt=i(Ve),dy=n(Ve,"LI",{});var bso=s(dy);uIe=n(bso,"STRONG",{});var t8a=s(uIe);pAt=r(t8a,"blenderbot-small"),t8a.forEach(t),_At=r(bso," \u2014 "),Ome=n(bso,"A",{href:!0});var a8a=s(Ome);bAt=r(a8a,"FlaxBlenderbotSmallForConditionalGeneration"),a8a.forEach(t),vAt=r(bso," (BlenderbotSmall model)"),bso.forEach(t),FAt=i(Ve),my=n(Ve,"LI",{});var vso=s(my);pIe=n(vso,"STRONG",{});var n8a=s(pIe);TAt=r(n8a,"encoder-decoder"),n8a.forEach(t),MAt=r(vso," \u2014 "),Vme=n(vso,"A",{href:!0});var s8a=s(Vme);EAt=r(s8a,"FlaxEncoderDecoderModel"),s8a.forEach(t),CAt=r(vso," (Encoder decoder model)"),vso.forEach(t),wAt=i(Ve),cy=n(Ve,"LI",{});var Fso=s(cy);_Ie=n(Fso,"STRONG",{});var l8a=s(_Ie);AAt=r(l8a,"longt5"),l8a.forEach(t),LAt=r(Fso," \u2014 "),Xme=n(Fso,"A",{href:!0});var i8a=s(Xme);yAt=r(i8a,"FlaxLongT5ForConditionalGeneration"),i8a.forEach(t),xAt=r(Fso," (LongT5 model)"),Fso.forEach(t),$At=i(Ve),fy=n(Ve,"LI",{});var Tso=s(fy);bIe=n(Tso,"STRONG",{});var d8a=s(bIe);kAt=r(d8a,"marian"),d8a.forEach(t),SAt=r(Tso," \u2014 "),zme=n(Tso,"A",{href:!0});var m8a=s(zme);RAt=r(m8a,"FlaxMarianMTModel"),m8a.forEach(t),PAt=r(Tso," (Marian model)"),Tso.forEach(t),BAt=i(Ve),gy=n(Ve,"LI",{});var Mso=s(gy);vIe=n(Mso,"STRONG",{});var c8a=s(vIe);IAt=r(c8a,"mbart"),c8a.forEach(t),NAt=r(Mso," \u2014 "),Qme=n(Mso,"A",{href:!0});var f8a=s(Qme);qAt=r(f8a,"FlaxMBartForConditionalGeneration"),f8a.forEach(t),DAt=r(Mso," (mBART model)"),Mso.forEach(t),jAt=i(Ve),hy=n(Ve,"LI",{});var Eso=s(hy);FIe=n(Eso,"STRONG",{});var g8a=s(FIe);GAt=r(g8a,"mt5"),g8a.forEach(t),OAt=r(Eso," \u2014 "),Wme=n(Eso,"A",{href:!0});var h8a=s(Wme);VAt=r(h8a,"FlaxMT5ForConditionalGeneration"),h8a.forEach(t),XAt=r(Eso," (MT5 model)"),Eso.forEach(t),zAt=i(Ve),uy=n(Ve,"LI",{});var Cso=s(uy);TIe=n(Cso,"STRONG",{});var u8a=s(TIe);QAt=r(u8a,"pegasus"),u8a.forEach(t),WAt=r(Cso," \u2014 "),Ume=n(Cso,"A",{href:!0});var p8a=s(Ume);UAt=r(p8a,"FlaxPegasusForConditionalGeneration"),p8a.forEach(t),HAt=r(Cso," (Pegasus model)"),Cso.forEach(t),JAt=i(Ve),py=n(Ve,"LI",{});var wso=s(py);MIe=n(wso,"STRONG",{});var _8a=s(MIe);YAt=r(_8a,"t5"),_8a.forEach(t),ZAt=r(wso," \u2014 "),Hme=n(wso,"A",{href:!0});var b8a=s(Hme);KAt=r(b8a,"FlaxT5ForConditionalGeneration"),b8a.forEach(t),e6t=r(wso," (T5 model)"),wso.forEach(t),Ve.forEach(t),o6t=i(cd),T(_y.$$.fragment,cd),cd.forEach(t),md.forEach(t),_do=i(c),$f=n(c,"H2",{class:!0});var Oco=s($f);by=n(Oco,"A",{id:!0,class:!0,href:!0});var v8a=s(by);EIe=n(v8a,"SPAN",{});var F8a=s(EIe);T(TI.$$.fragment,F8a),F8a.forEach(t),v8a.forEach(t),r6t=i(Oco),CIe=n(Oco,"SPAN",{});var T8a=s(CIe);t6t=r(T8a,"FlaxAutoModelForSequenceClassification"),T8a.forEach(t),Oco.forEach(t),bdo=i(c),Br=n(c,"DIV",{class:!0});var fd=s(Br);T(MI.$$.fragment,fd),a6t=i(fd),kf=n(fd,"P",{});var Yge=s(kf);n6t=r(Yge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Jme=n(Yge,"A",{href:!0});var M8a=s(Jme);s6t=r(M8a,"from_pretrained()"),M8a.forEach(t),l6t=r(Yge," class method or the "),Yme=n(Yge,"A",{href:!0});var E8a=s(Yme);i6t=r(E8a,"from_config()"),E8a.forEach(t),d6t=r(Yge,` class
method.`),Yge.forEach(t),m6t=i(fd),EI=n(fd,"P",{});var Vco=s(EI);c6t=r(Vco,"This class cannot be instantiated directly using "),wIe=n(Vco,"CODE",{});var C8a=s(wIe);f6t=r(C8a,"__init__()"),C8a.forEach(t),g6t=r(Vco," (throws an error)."),Vco.forEach(t),h6t=i(fd),Ma=n(fd,"DIV",{class:!0});var W$=s(Ma);T(CI.$$.fragment,W$),u6t=i(W$),AIe=n(W$,"P",{});var w8a=s(AIe);p6t=r(w8a,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),w8a.forEach(t),_6t=i(W$),Sf=n(W$,"P",{});var Zge=s(Sf);b6t=r(Zge,`Note:
Loading a model from its configuration file does `),LIe=n(Zge,"STRONG",{});var A8a=s(LIe);v6t=r(A8a,"not"),A8a.forEach(t),F6t=r(Zge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zme=n(Zge,"A",{href:!0});var L8a=s(Zme);T6t=r(L8a,"from_pretrained()"),L8a.forEach(t),M6t=r(Zge," to load the model weights."),Zge.forEach(t),E6t=i(W$),T(vy.$$.fragment,W$),W$.forEach(t),C6t=i(fd),ct=n(fd,"DIV",{class:!0});var gd=s(ct);T(wI.$$.fragment,gd),w6t=i(gd),yIe=n(gd,"P",{});var y8a=s(yIe);A6t=r(y8a,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),y8a.forEach(t),L6t=i(gd),is=n(gd,"P",{});var U$=s(is);y6t=r(U$,"The model class to instantiate is selected based on the "),xIe=n(U$,"CODE",{});var x8a=s(xIe);x6t=r(x8a,"model_type"),x8a.forEach(t),$6t=r(U$,` property of the config object (either
passed as an argument or loaded from `),$Ie=n(U$,"CODE",{});var $8a=s($Ie);k6t=r($8a,"pretrained_model_name_or_path"),$8a.forEach(t),S6t=r(U$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kIe=n(U$,"CODE",{});var k8a=s(kIe);R6t=r(k8a,"pretrained_model_name_or_path"),k8a.forEach(t),P6t=r(U$,":"),U$.forEach(t),B6t=i(gd),Be=n(gd,"UL",{});var Xe=s(Be);Fy=n(Xe,"LI",{});var Aso=s(Fy);SIe=n(Aso,"STRONG",{});var S8a=s(SIe);I6t=r(S8a,"albert"),S8a.forEach(t),N6t=r(Aso," \u2014 "),Kme=n(Aso,"A",{href:!0});var R8a=s(Kme);q6t=r(R8a,"FlaxAlbertForSequenceClassification"),R8a.forEach(t),D6t=r(Aso," (ALBERT model)"),Aso.forEach(t),j6t=i(Xe),Ty=n(Xe,"LI",{});var Lso=s(Ty);RIe=n(Lso,"STRONG",{});var P8a=s(RIe);G6t=r(P8a,"bart"),P8a.forEach(t),O6t=r(Lso," \u2014 "),ece=n(Lso,"A",{href:!0});var B8a=s(ece);V6t=r(B8a,"FlaxBartForSequenceClassification"),B8a.forEach(t),X6t=r(Lso," (BART model)"),Lso.forEach(t),z6t=i(Xe),My=n(Xe,"LI",{});var yso=s(My);PIe=n(yso,"STRONG",{});var I8a=s(PIe);Q6t=r(I8a,"bert"),I8a.forEach(t),W6t=r(yso," \u2014 "),oce=n(yso,"A",{href:!0});var N8a=s(oce);U6t=r(N8a,"FlaxBertForSequenceClassification"),N8a.forEach(t),H6t=r(yso," (BERT model)"),yso.forEach(t),J6t=i(Xe),Ey=n(Xe,"LI",{});var xso=s(Ey);BIe=n(xso,"STRONG",{});var q8a=s(BIe);Y6t=r(q8a,"big_bird"),q8a.forEach(t),Z6t=r(xso," \u2014 "),rce=n(xso,"A",{href:!0});var D8a=s(rce);K6t=r(D8a,"FlaxBigBirdForSequenceClassification"),D8a.forEach(t),e7t=r(xso," (BigBird model)"),xso.forEach(t),o7t=i(Xe),Cy=n(Xe,"LI",{});var $so=s(Cy);IIe=n($so,"STRONG",{});var j8a=s(IIe);r7t=r(j8a,"distilbert"),j8a.forEach(t),t7t=r($so," \u2014 "),tce=n($so,"A",{href:!0});var G8a=s(tce);a7t=r(G8a,"FlaxDistilBertForSequenceClassification"),G8a.forEach(t),n7t=r($so," (DistilBERT model)"),$so.forEach(t),s7t=i(Xe),wy=n(Xe,"LI",{});var kso=s(wy);NIe=n(kso,"STRONG",{});var O8a=s(NIe);l7t=r(O8a,"electra"),O8a.forEach(t),i7t=r(kso," \u2014 "),ace=n(kso,"A",{href:!0});var V8a=s(ace);d7t=r(V8a,"FlaxElectraForSequenceClassification"),V8a.forEach(t),m7t=r(kso," (ELECTRA model)"),kso.forEach(t),c7t=i(Xe),Ay=n(Xe,"LI",{});var Sso=s(Ay);qIe=n(Sso,"STRONG",{});var X8a=s(qIe);f7t=r(X8a,"mbart"),X8a.forEach(t),g7t=r(Sso," \u2014 "),nce=n(Sso,"A",{href:!0});var z8a=s(nce);h7t=r(z8a,"FlaxMBartForSequenceClassification"),z8a.forEach(t),u7t=r(Sso," (mBART model)"),Sso.forEach(t),p7t=i(Xe),Ly=n(Xe,"LI",{});var Rso=s(Ly);DIe=n(Rso,"STRONG",{});var Q8a=s(DIe);_7t=r(Q8a,"roberta"),Q8a.forEach(t),b7t=r(Rso," \u2014 "),sce=n(Rso,"A",{href:!0});var W8a=s(sce);v7t=r(W8a,"FlaxRobertaForSequenceClassification"),W8a.forEach(t),F7t=r(Rso," (RoBERTa model)"),Rso.forEach(t),T7t=i(Xe),yy=n(Xe,"LI",{});var Pso=s(yy);jIe=n(Pso,"STRONG",{});var U8a=s(jIe);M7t=r(U8a,"roformer"),U8a.forEach(t),E7t=r(Pso," \u2014 "),lce=n(Pso,"A",{href:!0});var H8a=s(lce);C7t=r(H8a,"FlaxRoFormerForSequenceClassification"),H8a.forEach(t),w7t=r(Pso," (RoFormer model)"),Pso.forEach(t),A7t=i(Xe),xy=n(Xe,"LI",{});var Bso=s(xy);GIe=n(Bso,"STRONG",{});var J8a=s(GIe);L7t=r(J8a,"xlm-roberta"),J8a.forEach(t),y7t=r(Bso," \u2014 "),ice=n(Bso,"A",{href:!0});var Y8a=s(ice);x7t=r(Y8a,"FlaxXLMRobertaForSequenceClassification"),Y8a.forEach(t),$7t=r(Bso," (XLM-RoBERTa model)"),Bso.forEach(t),Xe.forEach(t),k7t=i(gd),T($y.$$.fragment,gd),gd.forEach(t),fd.forEach(t),vdo=i(c),Rf=n(c,"H2",{class:!0});var Xco=s(Rf);ky=n(Xco,"A",{id:!0,class:!0,href:!0});var Z8a=s(ky);OIe=n(Z8a,"SPAN",{});var K8a=s(OIe);T(AI.$$.fragment,K8a),K8a.forEach(t),Z8a.forEach(t),S7t=i(Xco),VIe=n(Xco,"SPAN",{});var eLa=s(VIe);R7t=r(eLa,"FlaxAutoModelForQuestionAnswering"),eLa.forEach(t),Xco.forEach(t),Fdo=i(c),Ir=n(c,"DIV",{class:!0});var hd=s(Ir);T(LI.$$.fragment,hd),P7t=i(hd),Pf=n(hd,"P",{});var Kge=s(Pf);B7t=r(Kge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),dce=n(Kge,"A",{href:!0});var oLa=s(dce);I7t=r(oLa,"from_pretrained()"),oLa.forEach(t),N7t=r(Kge," class method or the "),mce=n(Kge,"A",{href:!0});var rLa=s(mce);q7t=r(rLa,"from_config()"),rLa.forEach(t),D7t=r(Kge,` class
method.`),Kge.forEach(t),j7t=i(hd),yI=n(hd,"P",{});var zco=s(yI);G7t=r(zco,"This class cannot be instantiated directly using "),XIe=n(zco,"CODE",{});var tLa=s(XIe);O7t=r(tLa,"__init__()"),tLa.forEach(t),V7t=r(zco," (throws an error)."),zco.forEach(t),X7t=i(hd),Ea=n(hd,"DIV",{class:!0});var H$=s(Ea);T(xI.$$.fragment,H$),z7t=i(H$),zIe=n(H$,"P",{});var aLa=s(zIe);Q7t=r(aLa,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),aLa.forEach(t),W7t=i(H$),Bf=n(H$,"P",{});var ehe=s(Bf);U7t=r(ehe,`Note:
Loading a model from its configuration file does `),QIe=n(ehe,"STRONG",{});var nLa=s(QIe);H7t=r(nLa,"not"),nLa.forEach(t),J7t=r(ehe,` load the model weights. It only affects the
model\u2019s configuration. Use `),cce=n(ehe,"A",{href:!0});var sLa=s(cce);Y7t=r(sLa,"from_pretrained()"),sLa.forEach(t),Z7t=r(ehe," to load the model weights."),ehe.forEach(t),K7t=i(H$),T(Sy.$$.fragment,H$),H$.forEach(t),e8t=i(hd),ft=n(hd,"DIV",{class:!0});var ud=s(ft);T($I.$$.fragment,ud),o8t=i(ud),WIe=n(ud,"P",{});var lLa=s(WIe);r8t=r(lLa,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),lLa.forEach(t),t8t=i(ud),ds=n(ud,"P",{});var J$=s(ds);a8t=r(J$,"The model class to instantiate is selected based on the "),UIe=n(J$,"CODE",{});var iLa=s(UIe);n8t=r(iLa,"model_type"),iLa.forEach(t),s8t=r(J$,` property of the config object (either
passed as an argument or loaded from `),HIe=n(J$,"CODE",{});var dLa=s(HIe);l8t=r(dLa,"pretrained_model_name_or_path"),dLa.forEach(t),i8t=r(J$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JIe=n(J$,"CODE",{});var mLa=s(JIe);d8t=r(mLa,"pretrained_model_name_or_path"),mLa.forEach(t),m8t=r(J$,":"),J$.forEach(t),c8t=i(ud),Ie=n(ud,"UL",{});var ze=s(Ie);Ry=n(ze,"LI",{});var Iso=s(Ry);YIe=n(Iso,"STRONG",{});var cLa=s(YIe);f8t=r(cLa,"albert"),cLa.forEach(t),g8t=r(Iso," \u2014 "),fce=n(Iso,"A",{href:!0});var fLa=s(fce);h8t=r(fLa,"FlaxAlbertForQuestionAnswering"),fLa.forEach(t),u8t=r(Iso," (ALBERT model)"),Iso.forEach(t),p8t=i(ze),Py=n(ze,"LI",{});var Nso=s(Py);ZIe=n(Nso,"STRONG",{});var gLa=s(ZIe);_8t=r(gLa,"bart"),gLa.forEach(t),b8t=r(Nso," \u2014 "),gce=n(Nso,"A",{href:!0});var hLa=s(gce);v8t=r(hLa,"FlaxBartForQuestionAnswering"),hLa.forEach(t),F8t=r(Nso," (BART model)"),Nso.forEach(t),T8t=i(ze),By=n(ze,"LI",{});var qso=s(By);KIe=n(qso,"STRONG",{});var uLa=s(KIe);M8t=r(uLa,"bert"),uLa.forEach(t),E8t=r(qso," \u2014 "),hce=n(qso,"A",{href:!0});var pLa=s(hce);C8t=r(pLa,"FlaxBertForQuestionAnswering"),pLa.forEach(t),w8t=r(qso," (BERT model)"),qso.forEach(t),A8t=i(ze),Iy=n(ze,"LI",{});var Dso=s(Iy);eNe=n(Dso,"STRONG",{});var _La=s(eNe);L8t=r(_La,"big_bird"),_La.forEach(t),y8t=r(Dso," \u2014 "),uce=n(Dso,"A",{href:!0});var bLa=s(uce);x8t=r(bLa,"FlaxBigBirdForQuestionAnswering"),bLa.forEach(t),$8t=r(Dso," (BigBird model)"),Dso.forEach(t),k8t=i(ze),Ny=n(ze,"LI",{});var jso=s(Ny);oNe=n(jso,"STRONG",{});var vLa=s(oNe);S8t=r(vLa,"distilbert"),vLa.forEach(t),R8t=r(jso," \u2014 "),pce=n(jso,"A",{href:!0});var FLa=s(pce);P8t=r(FLa,"FlaxDistilBertForQuestionAnswering"),FLa.forEach(t),B8t=r(jso," (DistilBERT model)"),jso.forEach(t),I8t=i(ze),qy=n(ze,"LI",{});var Gso=s(qy);rNe=n(Gso,"STRONG",{});var TLa=s(rNe);N8t=r(TLa,"electra"),TLa.forEach(t),q8t=r(Gso," \u2014 "),_ce=n(Gso,"A",{href:!0});var MLa=s(_ce);D8t=r(MLa,"FlaxElectraForQuestionAnswering"),MLa.forEach(t),j8t=r(Gso," (ELECTRA model)"),Gso.forEach(t),G8t=i(ze),Dy=n(ze,"LI",{});var Oso=s(Dy);tNe=n(Oso,"STRONG",{});var ELa=s(tNe);O8t=r(ELa,"mbart"),ELa.forEach(t),V8t=r(Oso," \u2014 "),bce=n(Oso,"A",{href:!0});var CLa=s(bce);X8t=r(CLa,"FlaxMBartForQuestionAnswering"),CLa.forEach(t),z8t=r(Oso," (mBART model)"),Oso.forEach(t),Q8t=i(ze),jy=n(ze,"LI",{});var Vso=s(jy);aNe=n(Vso,"STRONG",{});var wLa=s(aNe);W8t=r(wLa,"roberta"),wLa.forEach(t),U8t=r(Vso," \u2014 "),vce=n(Vso,"A",{href:!0});var ALa=s(vce);H8t=r(ALa,"FlaxRobertaForQuestionAnswering"),ALa.forEach(t),J8t=r(Vso," (RoBERTa model)"),Vso.forEach(t),Y8t=i(ze),Gy=n(ze,"LI",{});var Xso=s(Gy);nNe=n(Xso,"STRONG",{});var LLa=s(nNe);Z8t=r(LLa,"roformer"),LLa.forEach(t),K8t=r(Xso," \u2014 "),Fce=n(Xso,"A",{href:!0});var yLa=s(Fce);eLt=r(yLa,"FlaxRoFormerForQuestionAnswering"),yLa.forEach(t),oLt=r(Xso," (RoFormer model)"),Xso.forEach(t),rLt=i(ze),Oy=n(ze,"LI",{});var zso=s(Oy);sNe=n(zso,"STRONG",{});var xLa=s(sNe);tLt=r(xLa,"xlm-roberta"),xLa.forEach(t),aLt=r(zso," \u2014 "),Tce=n(zso,"A",{href:!0});var $La=s(Tce);nLt=r($La,"FlaxXLMRobertaForQuestionAnswering"),$La.forEach(t),sLt=r(zso," (XLM-RoBERTa model)"),zso.forEach(t),ze.forEach(t),lLt=i(ud),T(Vy.$$.fragment,ud),ud.forEach(t),hd.forEach(t),Tdo=i(c),If=n(c,"H2",{class:!0});var Qco=s(If);Xy=n(Qco,"A",{id:!0,class:!0,href:!0});var kLa=s(Xy);lNe=n(kLa,"SPAN",{});var SLa=s(lNe);T(kI.$$.fragment,SLa),SLa.forEach(t),kLa.forEach(t),iLt=i(Qco),iNe=n(Qco,"SPAN",{});var RLa=s(iNe);dLt=r(RLa,"FlaxAutoModelForTokenClassification"),RLa.forEach(t),Qco.forEach(t),Mdo=i(c),Nr=n(c,"DIV",{class:!0});var pd=s(Nr);T(SI.$$.fragment,pd),mLt=i(pd),Nf=n(pd,"P",{});var ohe=s(Nf);cLt=r(ohe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Mce=n(ohe,"A",{href:!0});var PLa=s(Mce);fLt=r(PLa,"from_pretrained()"),PLa.forEach(t),gLt=r(ohe," class method or the "),Ece=n(ohe,"A",{href:!0});var BLa=s(Ece);hLt=r(BLa,"from_config()"),BLa.forEach(t),uLt=r(ohe,` class
method.`),ohe.forEach(t),pLt=i(pd),RI=n(pd,"P",{});var Wco=s(RI);_Lt=r(Wco,"This class cannot be instantiated directly using "),dNe=n(Wco,"CODE",{});var ILa=s(dNe);bLt=r(ILa,"__init__()"),ILa.forEach(t),vLt=r(Wco," (throws an error)."),Wco.forEach(t),FLt=i(pd),Ca=n(pd,"DIV",{class:!0});var Y$=s(Ca);T(PI.$$.fragment,Y$),TLt=i(Y$),mNe=n(Y$,"P",{});var NLa=s(mNe);MLt=r(NLa,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),NLa.forEach(t),ELt=i(Y$),qf=n(Y$,"P",{});var rhe=s(qf);CLt=r(rhe,`Note:
Loading a model from its configuration file does `),cNe=n(rhe,"STRONG",{});var qLa=s(cNe);wLt=r(qLa,"not"),qLa.forEach(t),ALt=r(rhe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Cce=n(rhe,"A",{href:!0});var DLa=s(Cce);LLt=r(DLa,"from_pretrained()"),DLa.forEach(t),yLt=r(rhe," to load the model weights."),rhe.forEach(t),xLt=i(Y$),T(zy.$$.fragment,Y$),Y$.forEach(t),$Lt=i(pd),gt=n(pd,"DIV",{class:!0});var _d=s(gt);T(BI.$$.fragment,_d),kLt=i(_d),fNe=n(_d,"P",{});var jLa=s(fNe);SLt=r(jLa,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),jLa.forEach(t),RLt=i(_d),ms=n(_d,"P",{});var Z$=s(ms);PLt=r(Z$,"The model class to instantiate is selected based on the "),gNe=n(Z$,"CODE",{});var GLa=s(gNe);BLt=r(GLa,"model_type"),GLa.forEach(t),ILt=r(Z$,` property of the config object (either
passed as an argument or loaded from `),hNe=n(Z$,"CODE",{});var OLa=s(hNe);NLt=r(OLa,"pretrained_model_name_or_path"),OLa.forEach(t),qLt=r(Z$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uNe=n(Z$,"CODE",{});var VLa=s(uNe);DLt=r(VLa,"pretrained_model_name_or_path"),VLa.forEach(t),jLt=r(Z$,":"),Z$.forEach(t),GLt=i(_d),We=n(_d,"UL",{});var So=s(We);Qy=n(So,"LI",{});var Qso=s(Qy);pNe=n(Qso,"STRONG",{});var XLa=s(pNe);OLt=r(XLa,"albert"),XLa.forEach(t),VLt=r(Qso," \u2014 "),wce=n(Qso,"A",{href:!0});var zLa=s(wce);XLt=r(zLa,"FlaxAlbertForTokenClassification"),zLa.forEach(t),zLt=r(Qso," (ALBERT model)"),Qso.forEach(t),QLt=i(So),Wy=n(So,"LI",{});var Wso=s(Wy);_Ne=n(Wso,"STRONG",{});var QLa=s(_Ne);WLt=r(QLa,"bert"),QLa.forEach(t),ULt=r(Wso," \u2014 "),Ace=n(Wso,"A",{href:!0});var WLa=s(Ace);HLt=r(WLa,"FlaxBertForTokenClassification"),WLa.forEach(t),JLt=r(Wso," (BERT model)"),Wso.forEach(t),YLt=i(So),Uy=n(So,"LI",{});var Uso=s(Uy);bNe=n(Uso,"STRONG",{});var ULa=s(bNe);ZLt=r(ULa,"big_bird"),ULa.forEach(t),KLt=r(Uso," \u2014 "),Lce=n(Uso,"A",{href:!0});var HLa=s(Lce);eyt=r(HLa,"FlaxBigBirdForTokenClassification"),HLa.forEach(t),oyt=r(Uso," (BigBird model)"),Uso.forEach(t),ryt=i(So),Hy=n(So,"LI",{});var Hso=s(Hy);vNe=n(Hso,"STRONG",{});var JLa=s(vNe);tyt=r(JLa,"distilbert"),JLa.forEach(t),ayt=r(Hso," \u2014 "),yce=n(Hso,"A",{href:!0});var YLa=s(yce);nyt=r(YLa,"FlaxDistilBertForTokenClassification"),YLa.forEach(t),syt=r(Hso," (DistilBERT model)"),Hso.forEach(t),lyt=i(So),Jy=n(So,"LI",{});var Jso=s(Jy);FNe=n(Jso,"STRONG",{});var ZLa=s(FNe);iyt=r(ZLa,"electra"),ZLa.forEach(t),dyt=r(Jso," \u2014 "),xce=n(Jso,"A",{href:!0});var KLa=s(xce);myt=r(KLa,"FlaxElectraForTokenClassification"),KLa.forEach(t),cyt=r(Jso," (ELECTRA model)"),Jso.forEach(t),fyt=i(So),Yy=n(So,"LI",{});var Yso=s(Yy);TNe=n(Yso,"STRONG",{});var eya=s(TNe);gyt=r(eya,"roberta"),eya.forEach(t),hyt=r(Yso," \u2014 "),$ce=n(Yso,"A",{href:!0});var oya=s($ce);uyt=r(oya,"FlaxRobertaForTokenClassification"),oya.forEach(t),pyt=r(Yso," (RoBERTa model)"),Yso.forEach(t),_yt=i(So),Zy=n(So,"LI",{});var Zso=s(Zy);MNe=n(Zso,"STRONG",{});var rya=s(MNe);byt=r(rya,"roformer"),rya.forEach(t),vyt=r(Zso," \u2014 "),kce=n(Zso,"A",{href:!0});var tya=s(kce);Fyt=r(tya,"FlaxRoFormerForTokenClassification"),tya.forEach(t),Tyt=r(Zso," (RoFormer model)"),Zso.forEach(t),Myt=i(So),Ky=n(So,"LI",{});var Kso=s(Ky);ENe=n(Kso,"STRONG",{});var aya=s(ENe);Eyt=r(aya,"xlm-roberta"),aya.forEach(t),Cyt=r(Kso," \u2014 "),Sce=n(Kso,"A",{href:!0});var nya=s(Sce);wyt=r(nya,"FlaxXLMRobertaForTokenClassification"),nya.forEach(t),Ayt=r(Kso," (XLM-RoBERTa model)"),Kso.forEach(t),So.forEach(t),Lyt=i(_d),T(e9.$$.fragment,_d),_d.forEach(t),pd.forEach(t),Edo=i(c),Df=n(c,"H2",{class:!0});var Uco=s(Df);o9=n(Uco,"A",{id:!0,class:!0,href:!0});var sya=s(o9);CNe=n(sya,"SPAN",{});var lya=s(CNe);T(II.$$.fragment,lya),lya.forEach(t),sya.forEach(t),yyt=i(Uco),wNe=n(Uco,"SPAN",{});var iya=s(wNe);xyt=r(iya,"FlaxAutoModelForMultipleChoice"),iya.forEach(t),Uco.forEach(t),Cdo=i(c),qr=n(c,"DIV",{class:!0});var bd=s(qr);T(NI.$$.fragment,bd),$yt=i(bd),jf=n(bd,"P",{});var the=s(jf);kyt=r(the,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Rce=n(the,"A",{href:!0});var dya=s(Rce);Syt=r(dya,"from_pretrained()"),dya.forEach(t),Ryt=r(the," class method or the "),Pce=n(the,"A",{href:!0});var mya=s(Pce);Pyt=r(mya,"from_config()"),mya.forEach(t),Byt=r(the,` class
method.`),the.forEach(t),Iyt=i(bd),qI=n(bd,"P",{});var Hco=s(qI);Nyt=r(Hco,"This class cannot be instantiated directly using "),ANe=n(Hco,"CODE",{});var cya=s(ANe);qyt=r(cya,"__init__()"),cya.forEach(t),Dyt=r(Hco," (throws an error)."),Hco.forEach(t),jyt=i(bd),wa=n(bd,"DIV",{class:!0});var K$=s(wa);T(DI.$$.fragment,K$),Gyt=i(K$),LNe=n(K$,"P",{});var fya=s(LNe);Oyt=r(fya,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),fya.forEach(t),Vyt=i(K$),Gf=n(K$,"P",{});var ahe=s(Gf);Xyt=r(ahe,`Note:
Loading a model from its configuration file does `),yNe=n(ahe,"STRONG",{});var gya=s(yNe);zyt=r(gya,"not"),gya.forEach(t),Qyt=r(ahe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Bce=n(ahe,"A",{href:!0});var hya=s(Bce);Wyt=r(hya,"from_pretrained()"),hya.forEach(t),Uyt=r(ahe," to load the model weights."),ahe.forEach(t),Hyt=i(K$),T(r9.$$.fragment,K$),K$.forEach(t),Jyt=i(bd),ht=n(bd,"DIV",{class:!0});var vd=s(ht);T(jI.$$.fragment,vd),Yyt=i(vd),xNe=n(vd,"P",{});var uya=s(xNe);Zyt=r(uya,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),uya.forEach(t),Kyt=i(vd),cs=n(vd,"P",{});var ek=s(cs);e9t=r(ek,"The model class to instantiate is selected based on the "),$Ne=n(ek,"CODE",{});var pya=s($Ne);o9t=r(pya,"model_type"),pya.forEach(t),r9t=r(ek,` property of the config object (either
passed as an argument or loaded from `),kNe=n(ek,"CODE",{});var _ya=s(kNe);t9t=r(_ya,"pretrained_model_name_or_path"),_ya.forEach(t),a9t=r(ek,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SNe=n(ek,"CODE",{});var bya=s(SNe);n9t=r(bya,"pretrained_model_name_or_path"),bya.forEach(t),s9t=r(ek,":"),ek.forEach(t),l9t=i(vd),Ue=n(vd,"UL",{});var Ro=s(Ue);t9=n(Ro,"LI",{});var elo=s(t9);RNe=n(elo,"STRONG",{});var vya=s(RNe);i9t=r(vya,"albert"),vya.forEach(t),d9t=r(elo," \u2014 "),Ice=n(elo,"A",{href:!0});var Fya=s(Ice);m9t=r(Fya,"FlaxAlbertForMultipleChoice"),Fya.forEach(t),c9t=r(elo," (ALBERT model)"),elo.forEach(t),f9t=i(Ro),a9=n(Ro,"LI",{});var olo=s(a9);PNe=n(olo,"STRONG",{});var Tya=s(PNe);g9t=r(Tya,"bert"),Tya.forEach(t),h9t=r(olo," \u2014 "),Nce=n(olo,"A",{href:!0});var Mya=s(Nce);u9t=r(Mya,"FlaxBertForMultipleChoice"),Mya.forEach(t),p9t=r(olo," (BERT model)"),olo.forEach(t),_9t=i(Ro),n9=n(Ro,"LI",{});var rlo=s(n9);BNe=n(rlo,"STRONG",{});var Eya=s(BNe);b9t=r(Eya,"big_bird"),Eya.forEach(t),v9t=r(rlo," \u2014 "),qce=n(rlo,"A",{href:!0});var Cya=s(qce);F9t=r(Cya,"FlaxBigBirdForMultipleChoice"),Cya.forEach(t),T9t=r(rlo," (BigBird model)"),rlo.forEach(t),M9t=i(Ro),s9=n(Ro,"LI",{});var tlo=s(s9);INe=n(tlo,"STRONG",{});var wya=s(INe);E9t=r(wya,"distilbert"),wya.forEach(t),C9t=r(tlo," \u2014 "),Dce=n(tlo,"A",{href:!0});var Aya=s(Dce);w9t=r(Aya,"FlaxDistilBertForMultipleChoice"),Aya.forEach(t),A9t=r(tlo," (DistilBERT model)"),tlo.forEach(t),L9t=i(Ro),l9=n(Ro,"LI",{});var alo=s(l9);NNe=n(alo,"STRONG",{});var Lya=s(NNe);y9t=r(Lya,"electra"),Lya.forEach(t),x9t=r(alo," \u2014 "),jce=n(alo,"A",{href:!0});var yya=s(jce);$9t=r(yya,"FlaxElectraForMultipleChoice"),yya.forEach(t),k9t=r(alo," (ELECTRA model)"),alo.forEach(t),S9t=i(Ro),i9=n(Ro,"LI",{});var nlo=s(i9);qNe=n(nlo,"STRONG",{});var xya=s(qNe);R9t=r(xya,"roberta"),xya.forEach(t),P9t=r(nlo," \u2014 "),Gce=n(nlo,"A",{href:!0});var $ya=s(Gce);B9t=r($ya,"FlaxRobertaForMultipleChoice"),$ya.forEach(t),I9t=r(nlo," (RoBERTa model)"),nlo.forEach(t),N9t=i(Ro),d9=n(Ro,"LI",{});var slo=s(d9);DNe=n(slo,"STRONG",{});var kya=s(DNe);q9t=r(kya,"roformer"),kya.forEach(t),D9t=r(slo," \u2014 "),Oce=n(slo,"A",{href:!0});var Sya=s(Oce);j9t=r(Sya,"FlaxRoFormerForMultipleChoice"),Sya.forEach(t),G9t=r(slo," (RoFormer model)"),slo.forEach(t),O9t=i(Ro),m9=n(Ro,"LI",{});var llo=s(m9);jNe=n(llo,"STRONG",{});var Rya=s(jNe);V9t=r(Rya,"xlm-roberta"),Rya.forEach(t),X9t=r(llo," \u2014 "),Vce=n(llo,"A",{href:!0});var Pya=s(Vce);z9t=r(Pya,"FlaxXLMRobertaForMultipleChoice"),Pya.forEach(t),Q9t=r(llo," (XLM-RoBERTa model)"),llo.forEach(t),Ro.forEach(t),W9t=i(vd),T(c9.$$.fragment,vd),vd.forEach(t),bd.forEach(t),wdo=i(c),Of=n(c,"H2",{class:!0});var Jco=s(Of);f9=n(Jco,"A",{id:!0,class:!0,href:!0});var Bya=s(f9);GNe=n(Bya,"SPAN",{});var Iya=s(GNe);T(GI.$$.fragment,Iya),Iya.forEach(t),Bya.forEach(t),U9t=i(Jco),ONe=n(Jco,"SPAN",{});var Nya=s(ONe);H9t=r(Nya,"FlaxAutoModelForNextSentencePrediction"),Nya.forEach(t),Jco.forEach(t),Ado=i(c),Dr=n(c,"DIV",{class:!0});var Fd=s(Dr);T(OI.$$.fragment,Fd),J9t=i(Fd),Vf=n(Fd,"P",{});var nhe=s(Vf);Y9t=r(nhe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Xce=n(nhe,"A",{href:!0});var qya=s(Xce);Z9t=r(qya,"from_pretrained()"),qya.forEach(t),K9t=r(nhe," class method or the "),zce=n(nhe,"A",{href:!0});var Dya=s(zce);ext=r(Dya,"from_config()"),Dya.forEach(t),oxt=r(nhe,` class
method.`),nhe.forEach(t),rxt=i(Fd),VI=n(Fd,"P",{});var Yco=s(VI);txt=r(Yco,"This class cannot be instantiated directly using "),VNe=n(Yco,"CODE",{});var jya=s(VNe);axt=r(jya,"__init__()"),jya.forEach(t),nxt=r(Yco," (throws an error)."),Yco.forEach(t),sxt=i(Fd),Aa=n(Fd,"DIV",{class:!0});var ok=s(Aa);T(XI.$$.fragment,ok),lxt=i(ok),XNe=n(ok,"P",{});var Gya=s(XNe);ixt=r(Gya,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Gya.forEach(t),dxt=i(ok),Xf=n(ok,"P",{});var she=s(Xf);mxt=r(she,`Note:
Loading a model from its configuration file does `),zNe=n(she,"STRONG",{});var Oya=s(zNe);cxt=r(Oya,"not"),Oya.forEach(t),fxt=r(she,` load the model weights. It only affects the
model\u2019s configuration. Use `),Qce=n(she,"A",{href:!0});var Vya=s(Qce);gxt=r(Vya,"from_pretrained()"),Vya.forEach(t),hxt=r(she," to load the model weights."),she.forEach(t),uxt=i(ok),T(g9.$$.fragment,ok),ok.forEach(t),pxt=i(Fd),ut=n(Fd,"DIV",{class:!0});var Td=s(ut);T(zI.$$.fragment,Td),_xt=i(Td),QNe=n(Td,"P",{});var Xya=s(QNe);bxt=r(Xya,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Xya.forEach(t),vxt=i(Td),fs=n(Td,"P",{});var rk=s(fs);Fxt=r(rk,"The model class to instantiate is selected based on the "),WNe=n(rk,"CODE",{});var zya=s(WNe);Txt=r(zya,"model_type"),zya.forEach(t),Mxt=r(rk,` property of the config object (either
passed as an argument or loaded from `),UNe=n(rk,"CODE",{});var Qya=s(UNe);Ext=r(Qya,"pretrained_model_name_or_path"),Qya.forEach(t),Cxt=r(rk,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HNe=n(rk,"CODE",{});var Wya=s(HNe);wxt=r(Wya,"pretrained_model_name_or_path"),Wya.forEach(t),Axt=r(rk,":"),rk.forEach(t),Lxt=i(Td),JNe=n(Td,"UL",{});var Uya=s(JNe);h9=n(Uya,"LI",{});var ilo=s(h9);YNe=n(ilo,"STRONG",{});var Hya=s(YNe);yxt=r(Hya,"bert"),Hya.forEach(t),xxt=r(ilo," \u2014 "),Wce=n(ilo,"A",{href:!0});var Jya=s(Wce);$xt=r(Jya,"FlaxBertForNextSentencePrediction"),Jya.forEach(t),kxt=r(ilo," (BERT model)"),ilo.forEach(t),Uya.forEach(t),Sxt=i(Td),T(u9.$$.fragment,Td),Td.forEach(t),Fd.forEach(t),Ldo=i(c),zf=n(c,"H2",{class:!0});var Zco=s(zf);p9=n(Zco,"A",{id:!0,class:!0,href:!0});var Yya=s(p9);ZNe=n(Yya,"SPAN",{});var Zya=s(ZNe);T(QI.$$.fragment,Zya),Zya.forEach(t),Yya.forEach(t),Rxt=i(Zco),KNe=n(Zco,"SPAN",{});var Kya=s(KNe);Pxt=r(Kya,"FlaxAutoModelForImageClassification"),Kya.forEach(t),Zco.forEach(t),ydo=i(c),jr=n(c,"DIV",{class:!0});var Md=s(jr);T(WI.$$.fragment,Md),Bxt=i(Md),Qf=n(Md,"P",{});var lhe=s(Qf);Ixt=r(lhe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Uce=n(lhe,"A",{href:!0});var e9a=s(Uce);Nxt=r(e9a,"from_pretrained()"),e9a.forEach(t),qxt=r(lhe," class method or the "),Hce=n(lhe,"A",{href:!0});var o9a=s(Hce);Dxt=r(o9a,"from_config()"),o9a.forEach(t),jxt=r(lhe,` class
method.`),lhe.forEach(t),Gxt=i(Md),UI=n(Md,"P",{});var Kco=s(UI);Oxt=r(Kco,"This class cannot be instantiated directly using "),eqe=n(Kco,"CODE",{});var r9a=s(eqe);Vxt=r(r9a,"__init__()"),r9a.forEach(t),Xxt=r(Kco," (throws an error)."),Kco.forEach(t),zxt=i(Md),La=n(Md,"DIV",{class:!0});var tk=s(La);T(HI.$$.fragment,tk),Qxt=i(tk),oqe=n(tk,"P",{});var t9a=s(oqe);Wxt=r(t9a,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),t9a.forEach(t),Uxt=i(tk),Wf=n(tk,"P",{});var ihe=s(Wf);Hxt=r(ihe,`Note:
Loading a model from its configuration file does `),rqe=n(ihe,"STRONG",{});var a9a=s(rqe);Jxt=r(a9a,"not"),a9a.forEach(t),Yxt=r(ihe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Jce=n(ihe,"A",{href:!0});var n9a=s(Jce);Zxt=r(n9a,"from_pretrained()"),n9a.forEach(t),Kxt=r(ihe," to load the model weights."),ihe.forEach(t),e$t=i(tk),T(_9.$$.fragment,tk),tk.forEach(t),o$t=i(Md),pt=n(Md,"DIV",{class:!0});var Ed=s(pt);T(JI.$$.fragment,Ed),r$t=i(Ed),tqe=n(Ed,"P",{});var s9a=s(tqe);t$t=r(s9a,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),s9a.forEach(t),a$t=i(Ed),gs=n(Ed,"P",{});var ak=s(gs);n$t=r(ak,"The model class to instantiate is selected based on the "),aqe=n(ak,"CODE",{});var l9a=s(aqe);s$t=r(l9a,"model_type"),l9a.forEach(t),l$t=r(ak,` property of the config object (either
passed as an argument or loaded from `),nqe=n(ak,"CODE",{});var i9a=s(nqe);i$t=r(i9a,"pretrained_model_name_or_path"),i9a.forEach(t),d$t=r(ak,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sqe=n(ak,"CODE",{});var d9a=s(sqe);m$t=r(d9a,"pretrained_model_name_or_path"),d9a.forEach(t),c$t=r(ak,":"),ak.forEach(t),f$t=i(Ed),YI=n(Ed,"UL",{});var efo=s(YI);b9=n(efo,"LI",{});var dlo=s(b9);lqe=n(dlo,"STRONG",{});var m9a=s(lqe);g$t=r(m9a,"beit"),m9a.forEach(t),h$t=r(dlo," \u2014 "),Yce=n(dlo,"A",{href:!0});var c9a=s(Yce);u$t=r(c9a,"FlaxBeitForImageClassification"),c9a.forEach(t),p$t=r(dlo," (BEiT model)"),dlo.forEach(t),_$t=i(efo),v9=n(efo,"LI",{});var mlo=s(v9);iqe=n(mlo,"STRONG",{});var f9a=s(iqe);b$t=r(f9a,"vit"),f9a.forEach(t),v$t=r(mlo," \u2014 "),Zce=n(mlo,"A",{href:!0});var g9a=s(Zce);F$t=r(g9a,"FlaxViTForImageClassification"),g9a.forEach(t),T$t=r(mlo," (ViT model)"),mlo.forEach(t),efo.forEach(t),M$t=i(Ed),T(F9.$$.fragment,Ed),Ed.forEach(t),Md.forEach(t),xdo=i(c),Uf=n(c,"H2",{class:!0});var ofo=s(Uf);T9=n(ofo,"A",{id:!0,class:!0,href:!0});var h9a=s(T9);dqe=n(h9a,"SPAN",{});var u9a=s(dqe);T(ZI.$$.fragment,u9a),u9a.forEach(t),h9a.forEach(t),E$t=i(ofo),mqe=n(ofo,"SPAN",{});var p9a=s(mqe);C$t=r(p9a,"FlaxAutoModelForVision2Seq"),p9a.forEach(t),ofo.forEach(t),$do=i(c),Gr=n(c,"DIV",{class:!0});var Cd=s(Gr);T(KI.$$.fragment,Cd),w$t=i(Cd),Hf=n(Cd,"P",{});var dhe=s(Hf);A$t=r(dhe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Kce=n(dhe,"A",{href:!0});var _9a=s(Kce);L$t=r(_9a,"from_pretrained()"),_9a.forEach(t),y$t=r(dhe," class method or the "),efe=n(dhe,"A",{href:!0});var b9a=s(efe);x$t=r(b9a,"from_config()"),b9a.forEach(t),$$t=r(dhe,` class
method.`),dhe.forEach(t),k$t=i(Cd),eN=n(Cd,"P",{});var rfo=s(eN);S$t=r(rfo,"This class cannot be instantiated directly using "),cqe=n(rfo,"CODE",{});var v9a=s(cqe);R$t=r(v9a,"__init__()"),v9a.forEach(t),P$t=r(rfo," (throws an error)."),rfo.forEach(t),B$t=i(Cd),ya=n(Cd,"DIV",{class:!0});var nk=s(ya);T(oN.$$.fragment,nk),I$t=i(nk),fqe=n(nk,"P",{});var F9a=s(fqe);N$t=r(F9a,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),F9a.forEach(t),q$t=i(nk),Jf=n(nk,"P",{});var mhe=s(Jf);D$t=r(mhe,`Note:
Loading a model from its configuration file does `),gqe=n(mhe,"STRONG",{});var T9a=s(gqe);j$t=r(T9a,"not"),T9a.forEach(t),G$t=r(mhe,` load the model weights. It only affects the
model\u2019s configuration. Use `),ofe=n(mhe,"A",{href:!0});var M9a=s(ofe);O$t=r(M9a,"from_pretrained()"),M9a.forEach(t),V$t=r(mhe," to load the model weights."),mhe.forEach(t),X$t=i(nk),T(M9.$$.fragment,nk),nk.forEach(t),z$t=i(Cd),_t=n(Cd,"DIV",{class:!0});var wd=s(_t);T(rN.$$.fragment,wd),Q$t=i(wd),hqe=n(wd,"P",{});var E9a=s(hqe);W$t=r(E9a,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),E9a.forEach(t),U$t=i(wd),hs=n(wd,"P",{});var sk=s(hs);H$t=r(sk,"The model class to instantiate is selected based on the "),uqe=n(sk,"CODE",{});var C9a=s(uqe);J$t=r(C9a,"model_type"),C9a.forEach(t),Y$t=r(sk,` property of the config object (either
passed as an argument or loaded from `),pqe=n(sk,"CODE",{});var w9a=s(pqe);Z$t=r(w9a,"pretrained_model_name_or_path"),w9a.forEach(t),K$t=r(sk,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_qe=n(sk,"CODE",{});var A9a=s(_qe);ekt=r(A9a,"pretrained_model_name_or_path"),A9a.forEach(t),okt=r(sk,":"),sk.forEach(t),rkt=i(wd),bqe=n(wd,"UL",{});var L9a=s(bqe);E9=n(L9a,"LI",{});var clo=s(E9);vqe=n(clo,"STRONG",{});var y9a=s(vqe);tkt=r(y9a,"vision-encoder-decoder"),y9a.forEach(t),akt=r(clo," \u2014 "),rfe=n(clo,"A",{href:!0});var x9a=s(rfe);nkt=r(x9a,"FlaxVisionEncoderDecoderModel"),x9a.forEach(t),skt=r(clo," (Vision Encoder decoder model)"),clo.forEach(t),L9a.forEach(t),lkt=i(wd),T(C9.$$.fragment,wd),wd.forEach(t),Cd.forEach(t),this.h()},h(){d(g,"name","hf:doc:metadata"),d(g,"content",JSON.stringify(H$a)),d(f,"id","auto-classes"),d(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(f,"href","#auto-classes"),d(u,"class","relative group"),d(ps,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig"),d(bs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel"),d(vs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),d(Sd,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),d(ag,"id","extending-the-auto-classes"),d(ag,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ag,"href","#extending-the-auto-classes"),d(Rd,"class","relative group"),d(sg,"id","transformers.AutoConfig"),d(sg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(sg,"href","#transformers.AutoConfig"),d(Pd,"class","relative group"),d(Nq,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),d(qq,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig"),d(Dq,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartConfig"),d(jq,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig"),d(Gq,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertConfig"),d(Oq,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig"),d(Vq,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig"),d(Xq,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),d(zq,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig"),d(Qq,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),d(Wq,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig"),d(Uq,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig"),d(Hq,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig"),d(Jq,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig"),d(Yq,"href","/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegConfig"),d(Zq,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig"),d(Kq,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig"),d(eD,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig"),d(oD,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig"),d(rD,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig"),d(tD,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig"),d(aD,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),d(nD,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig"),d(sD,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),d(lD,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig"),d(iD,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config"),d(dD,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),d(mD,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig"),d(cD,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig"),d(fD,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig"),d(gD,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig"),d(hD,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig"),d(uD,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig"),d(pD,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig"),d(_D,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig"),d(bD,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),d(vD,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig"),d(FD,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig"),d(TD,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig"),d(MD,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig"),d(ED,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig"),d(CD,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig"),d(wD,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig"),d(AD,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig"),d(LD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config"),d(yD,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),d(xD,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),d($D,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig"),d(kD,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig"),d(SD,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig"),d(RD,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig"),d(PD,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig"),d(BD,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig"),d(ID,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig"),d(ND,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),d(qD,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),d(DD,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDConfig"),d(jD,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig"),d(GD,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig"),d(OD,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig"),d(VD,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config"),d(XD,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig"),d(zD,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig"),d(QD,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config"),d(WD,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig"),d(UD,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig"),d(HD,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig"),d(JD,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig"),d(YD,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig"),d(ZD,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),d(KD,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig"),d(ej,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig"),d(oj,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig"),d(rj,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config"),d(tj,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig"),d(aj,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig"),d(nj,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig"),d(sj,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),d(lj,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig"),d(ij,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig"),d(dj,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig"),d(mj,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig"),d(cj,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig"),d(fj,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig"),d(gj,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig"),d(hj,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig"),d(uj,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig"),d(pj,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagConfig"),d(_j,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmConfig"),d(bj,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig"),d(vj,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig"),d(Fj,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig"),d(Tj,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig"),d(Mj,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig"),d(Ej,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig"),d(Cj,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig"),d(wj,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig"),d(Aj,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig"),d(Lj,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig"),d(yj,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig"),d(xj,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),d($j,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),d(kj,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),d(Sj,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig"),d(Rj,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),d(Pj,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig"),d(Bj,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config"),d(Ij,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Config"),d(Nj,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig"),d(qj,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig"),d(Dj,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig"),d(jj,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),d(Gj,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),d(Oj,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig"),d(Vj,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig"),d(Xj,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),d(zj,"href","/docs/transformers/main/en/model_doc/van#transformers.VanConfig"),d(Qj,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig"),d(Wj,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig"),d(Uj,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),d(Hj,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),d(Jj,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig"),d(Yj,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig"),d(Zj,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig"),d(Kj,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig"),d(eG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),d(oG,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),d(rG,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig"),d(tG,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig"),d(aG,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig"),d(nG,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig"),d(sG,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig"),d(lG,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),d(iG,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),d(dG,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),d(mG,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig"),d(cG,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig"),d(fG,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig"),d(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Nu,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qu,"id","transformers.AutoTokenizer"),d(qu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(qu,"href","#transformers.AutoTokenizer"),d(Id,"class","relative group"),d(gG,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),d(hG,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),d(uG,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),d(pG,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizer"),d(_G,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizerFast"),d(bG,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizer"),d(vG,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizerFast"),d(FG,"href","/docs/transformers/main/en/model_doc/bartpho#transformers.BartphoTokenizer"),d(TG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(MG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(EG,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),d(CG,"href","/docs/transformers/main/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),d(wG,"href","/docs/transformers/main/en/model_doc/bertweet#transformers.BertweetTokenizer"),d(AG,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizer"),d(LG,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),d(yG,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),d(xG,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),d($G,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),d(kG,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),d(SG,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),d(RG,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomTokenizerFast"),d(PG,"href","/docs/transformers/main/en/model_doc/byt5#transformers.ByT5Tokenizer"),d(BG,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizer"),d(IG,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizerFast"),d(NG,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineTokenizer"),d(qG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(DG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(jG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(GG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(OG,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizer"),d(VG,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),d(XG,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizer"),d(zG,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),d(QG,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizer"),d(WG,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizerFast"),d(UG,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLTokenizer"),d(HG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),d(JG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(YG,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizer"),d(ZG,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizerFast"),d(KG,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),d(eO,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),d(oO,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizer"),d(rO,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),d(tO,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),d(aO,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),d(nO,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizer"),d(sO,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizerFast"),d(lO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(iO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(dO,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmTokenizer"),d(mO,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertTokenizer"),d(cO,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizer"),d(fO,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizerFast"),d(gO,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTTokenizer"),d(hO,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizer"),d(uO,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizerFast"),d(pO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(_O,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d(bO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(vO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d(FO,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),d(TO,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseTokenizer"),d(MO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(EO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d(CO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(wO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(AO,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizer"),d(LO,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizerFast"),d(yO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d(xO,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),d($O,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(kO,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),d(SO,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),d(RO,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),d(PO,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),d(BO,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),d(IO,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),d(NO,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),d(qO,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),d(DO,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizer"),d(jO,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizerFast"),d(GO,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),d(OO,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),d(VO,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizer"),d(XO,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizerFast"),d(zO,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),d(QO,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),d(WO,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeTokenizer"),d(UO,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizer"),d(HO,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),d(JO,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),d(YO,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianTokenizer"),d(ZO,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizer"),d(KO,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizerFast"),d(eV,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50Tokenizer"),d(oV,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50TokenizerFast"),d(rV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(tV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(aV,"href","/docs/transformers/main/en/model_doc/mluke#transformers.MLukeTokenizer"),d(nV,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),d(sV,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),d(lV,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizer"),d(iV,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),d(dV,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),d(mV,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),d(cV,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizer"),d(fV,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizerFast"),d(gV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(hV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(uV,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizer"),d(pV,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizerFast"),d(_V,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),d(bV,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),d(vV,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),d(FV,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),d(TV,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(MV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(EV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(CV,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),d(wV,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),d(AV,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),d(LV,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),d(yV,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverTokenizer"),d(xV,"href","/docs/transformers/main/en/model_doc/phobert#transformers.PhobertTokenizer"),d($V,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartTokenizer"),d(kV,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),d(SV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(RV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(PV,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagTokenizer"),d(BV,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizer"),d(IV,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizerFast"),d(NV,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizer"),d(qV,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizerFast"),d(DV,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizer"),d(jV,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizerFast"),d(GV,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizer"),d(OV,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),d(VV,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),d(XV,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(zV,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizer"),d(QV,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),d(WV,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),d(UV,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),d(HV,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizer"),d(JV,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizerFast"),d(YV,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),d(ZV,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),d(KV,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),d(eX,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),d(oX,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasTokenizer"),d(rX,"href","/docs/transformers/main/en/model_doc/tapex#transformers.TapexTokenizer"),d(tX,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),d(aX,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(nX,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(sX,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(lX,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(iX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d(dX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d(mX,"href","/docs/transformers/main/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),d(cX,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperTokenizer"),d(fX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(gX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(hX,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizer"),d(uX,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizerFast"),d(pX,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMTokenizer"),d(_X,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),d(bX,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),d(vX,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),d(FX,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),d(TX,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),d(MX,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizer"),d(EX,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),d(CX,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),d(wX,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),d(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Mp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ep,"id","transformers.AutoFeatureExtractor"),d(Ep,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ep,"href","#transformers.AutoFeatureExtractor"),d(Nd,"class","relative group"),d(AX,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),d(LX,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitImageProcessor"),d(yX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPImageProcessor"),d(xX,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d($X,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrFeatureExtractor"),d(kX,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(SX,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(RX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(PX,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitImageProcessor"),d(BX,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrFeatureExtractor"),d(IX,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTImageProcessor"),d(NX,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),d(qX,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutFeatureExtractor"),d(DX,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTImageProcessor"),d(jX,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaImageProcessor"),d(GX,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNImageProcessor"),d(OX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPImageProcessor"),d(VX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(XX,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTImageProcessor"),d(zX,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ImageProcessor"),d(QX,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor"),d(WX,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitImageProcessor"),d(UX,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),d(HX,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),d(JX,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTImageProcessor"),d(YX,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor"),d(ZX,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverImageProcessor"),d(KX,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerImageProcessor"),d(ez,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(oz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(rz,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerImageProcessor"),d(tz,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),d(az,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(nz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(sz,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),d(lz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(iz,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEImageProcessor"),d(dz,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltImageProcessor"),d(mz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(cz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(fz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(gz,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(hz,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(uz,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperFeatureExtractor"),d(pz,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPImageProcessor"),d(_z,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosFeatureExtractor"),d(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(__,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(b_,"id","transformers.AutoImageProcessor"),d(b_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(b_,"href","#transformers.AutoImageProcessor"),d(qd,"class","relative group"),d(bz,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoImageProcessor.from_pretrained"),d(vz,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitImageProcessor"),d(Fz,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPImageProcessor"),d(Tz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(Mz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(Ez,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitImageProcessor"),d(Cz,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTImageProcessor"),d(wz,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTImageProcessor"),d(Az,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaImageProcessor"),d(Lz,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNImageProcessor"),d(yz,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPImageProcessor"),d(xz,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTImageProcessor"),d($z,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ImageProcessor"),d(kz,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor"),d(Sz,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitImageProcessor"),d(Rz,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTImageProcessor"),d(Pz,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverImageProcessor"),d(Bz,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerImageProcessor"),d(Iz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(Nz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(qz,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerImageProcessor"),d(Dz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(jz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(Gz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(Oz,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEImageProcessor"),d(Vz,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltImageProcessor"),d(Xz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(zz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(Qz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(Wz,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPImageProcessor"),d(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(J_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Y_,"id","transformers.AutoProcessor"),d(Y_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Y_,"href","#transformers.AutoProcessor"),d(Dd,"class","relative group"),d(Uz,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),d(Hz,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),d(Jz,"href","/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegProcessor"),d(Yz,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaProcessor"),d(Zz,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),d(Kz,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),d(eQ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),d(oQ,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),d(rQ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMProcessor"),d(tQ,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTProcessor"),d(aQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(nQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(sQ,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),d(lQ,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),d(iQ,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRProcessor"),d(dQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(mQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(cQ,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltProcessor"),d(fQ,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),d(gQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(hQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(uQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(pQ,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperProcessor"),d(_Q,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPProcessor"),d(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(E1,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(C1,"id","transformers.AutoModel"),d(C1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(C1,"href","#transformers.AutoModel"),d(Gd,"class","relative group"),d(bQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(vQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(FQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(TQ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel"),d(MQ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartModel"),d(EQ,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitModel"),d(CQ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),d(wQ,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),d(AQ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel"),d(LQ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),d(yQ,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel"),d(xQ,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),d($Q,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel"),d(kQ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel"),d(SQ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineModel"),d(RQ,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel"),d(PQ,"href","/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegModel"),d(BQ,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel"),d(IQ,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel"),d(NQ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel"),d(qQ,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel"),d(DQ,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel"),d(jQ,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel"),d(GQ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel"),d(OQ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel"),d(VQ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel"),d(XQ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel"),d(zQ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model"),d(QQ,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),d(WQ,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel"),d(UQ,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel"),d(HQ,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrModel"),d(JQ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel"),d(YQ,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel"),d(ZQ,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder"),d(KQ,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel"),d(eW,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel"),d(oW,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel"),d(rW,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmModel"),d(tW,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel"),d(aW,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel"),d(nW,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel"),d(sW,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel"),d(lW,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel"),d(iW,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel"),d(dW,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel"),d(mW,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model"),d(cW,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel"),d(fW,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),d(gW,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel"),d(hW,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel"),d(uW,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel"),d(pW,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel"),d(_W,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel"),d(bW,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel"),d(vW,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel"),d(FW,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),d(TW,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),d(MW,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDModel"),d(EW,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitModel"),d(CW,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltModel"),d(wW,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel"),d(AW,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model"),d(LW,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeModel"),d(yW,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel"),d(xW,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),d($W,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianModel"),d(kW,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel"),d(SW,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel"),d(RW,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel"),d(PW,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel"),d(BW,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel"),d(IW,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel"),d(NW,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel"),d(qW,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel"),d(DW,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model"),d(jW,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel"),d(GW,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel"),d(OW,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),d(VW,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel"),d(XW,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),d(zW,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTModel"),d(QW,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel"),d(WW,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel"),d(UW,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel"),d(HW,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel"),d(JW,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel"),d(YW,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel"),d(ZW,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel"),d(KW,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel"),d(eU,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel"),d(oU,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel"),d(rU,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel"),d(tU,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel"),d(aU,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),d(nU,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel"),d(sU,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertModel"),d(lU,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel"),d(iU,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel"),d(dU,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWModel"),d(mU,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel"),d(cU,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel"),d(fU,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel"),d(gU,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel"),d(hU,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinModel"),d(uU,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model"),d(pU,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Model"),d(_U,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerModel"),d(bU,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel"),d(vU,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel"),d(FU,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),d(TU,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel"),d(MU,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel"),d(EU,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),d(CU,"href","/docs/transformers/main/en/model_doc/van#transformers.VanModel"),d(wU,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel"),d(AU,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel"),d(LU,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),d(yU,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel"),d(xU,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTModel"),d($U,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel"),d(kU,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel"),d(SU,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),d(RU,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),d(PU,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel"),d(BU,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel"),d(IU,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel"),d(NU,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel"),d(qU,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel"),d(DU,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),d(jU,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),d(GU,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),d(OU,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel"),d(VU,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel"),d(XU,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel"),d(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Jb,"id","transformers.AutoModelForPreTraining"),d(Jb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Jb,"href","#transformers.AutoModelForPreTraining"),d(Xd,"class","relative group"),d(zU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(QU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(WU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(UU,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining"),d(HU,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(JU,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining"),d(YU,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),d(ZU,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),d(KU,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),d(eH,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),d(oH,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),d(rH,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),d(tH,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),d(aH,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),d(nH,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining"),d(sH,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining"),d(lH,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),d(iH,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining"),d(dH,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining"),d(mH,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),d(cH,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining"),d(fH,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),d(gH,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),d(hH,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),d(uH,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),d(pH,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),d(_H,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining"),d(bH,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),d(vH,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),d(FH,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),d(TH,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),d(MH,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining"),d(EH,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),d(CH,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),d(wH,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),d(AH,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForPreTraining"),d(LH,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining"),d(yH,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),d(xH,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),d($H,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),d(kH,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),d(SH,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),d(RH,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),d(PH,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining"),d(BH,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),d(IH,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),d(NH,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),d(qH,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),d(DH,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(jH,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),d(GH,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),d(OH,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),d(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Hv,"id","transformers.AutoModelForCausalLM"),d(Hv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Hv,"href","#transformers.AutoModelForCausalLM"),d(Wd,"class","relative group"),d(VH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(XH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(zH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(QH,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM"),d(WH,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel"),d(UH,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),d(HH,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),d(JH,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),d(YH,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),d(ZH,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),d(KH,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),d(eJ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM"),d(oJ,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM"),d(rJ,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),d(tJ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),d(aJ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM"),d(nJ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM"),d(sJ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),d(lJ,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),d(iJ,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),d(dJ,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM"),d(mJ,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM"),d(cJ,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM"),d(fJ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM"),d(gJ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),d(hJ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM"),d(uJ,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),d(pJ,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM"),d(_J,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM"),d(bJ,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM"),d(vJ,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),d(FJ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),d(TJ,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),d(MJ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM"),d(EJ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM"),d(CJ,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForCausalLM"),d(wJ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM"),d(AJ,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),d(LJ,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),d(yJ,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM"),d(xJ,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM"),d($J,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(kJ,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),d(SJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),d(RJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),d(PJ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),d(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(OF,"id","transformers.AutoModelForDepthEstimation"),d(OF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(OF,"href","#transformers.AutoModelForDepthEstimation"),d(Jd,"class","relative group"),d(BJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(IJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(NJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qJ,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForDepthEstimation"),d(DJ,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNForDepthEstimation"),d(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(UF,"id","transformers.AutoModelForMaskedLM"),d(UF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(UF,"href","#transformers.AutoModelForMaskedLM"),d(Kd,"class","relative group"),d(jJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(GJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(OJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(VJ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM"),d(XJ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(zJ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM"),d(QJ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),d(WJ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),d(UJ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),d(HJ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),d(JJ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),d(YJ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),d(ZJ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),d(KJ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM"),d(eY,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM"),d(oY,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),d(rY,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM"),d(tY,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM"),d(aY,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),d(nY,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),d(sY,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),d(lY,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),d(iY,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),d(dY,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),d(mY,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),d(cY,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),d(fY,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),d(gY,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM"),d(hY,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),d(uY,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),d(pY,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),d(_Y,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM"),d(bY,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM"),d(vY,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),d(FY,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForMaskedLM"),d(TY,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),d(MY,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),d(EY,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),d(CY,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(wY,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),d(AY,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),d(LY,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM"),d(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qT,"id","transformers.AutoModelForSeq2SeqLM"),d(qT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(qT,"href","#transformers.AutoModelForSeq2SeqLM"),d(rm,"class","relative group"),d(yY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(xY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d($Y,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(kY,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(SY,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),d(RY,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),d(PY,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),d(BY,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),d(IY,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),d(NY,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration"),d(qY,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),d(DY,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),d(jY,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel"),d(GY,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),d(OY,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),d(VY,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),d(XY,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),d(zY,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),d(QY,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration"),d(WY,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),d(UY,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),d(HY,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),d(JY,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),d(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(iM,"id","transformers.AutoModelForSequenceClassification"),d(iM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(iM,"href","#transformers.AutoModelForSequenceClassification"),d(nm,"class","relative group"),d(YY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ZY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(KY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(eZ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification"),d(oZ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification"),d(rZ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification"),d(tZ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),d(aZ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),d(nZ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification"),d(sZ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),d(lZ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification"),d(iZ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),d(dZ,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),d(mZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),d(cZ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),d(fZ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),d(gZ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),d(hZ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification"),d(uZ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification"),d(pZ,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification"),d(_Z,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),d(bZ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification"),d(vZ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),d(FZ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),d(TZ,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),d(MZ,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),d(EZ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification"),d(CZ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),d(wZ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),d(AZ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),d(LZ,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification"),d(yZ,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForSequenceClassification"),d(xZ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),d($Z,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification"),d(kZ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification"),d(SZ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification"),d(RZ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),d(PZ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),d(BZ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),d(IZ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification"),d(NZ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),d(qZ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),d(DZ,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),d(jZ,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification"),d(GZ,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),d(OZ,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),d(VZ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),d(XZ,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),d(zZ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),d(QZ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),d(WZ,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForSequenceClassification"),d(UZ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),d(HZ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),d(JZ,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification"),d(YZ,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),d(ZZ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification"),d(KZ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),d(eK,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),d(oK,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),d(rK,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification"),d(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(uE,"id","transformers.AutoModelForMultipleChoice"),d(uE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(uE,"href","#transformers.AutoModelForMultipleChoice"),d(im,"class","relative group"),d(tK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(aK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(nK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(sK,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice"),d(lK,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice"),d(iK,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),d(dK,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),d(mK,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice"),d(cK,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),d(fK,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),d(gK,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),d(hK,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),d(uK,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice"),d(pK,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice"),d(_K,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),d(bK,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice"),d(vK,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),d(FK,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice"),d(TK,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),d(MK,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice"),d(EK,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),d(CK,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),d(wK,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),d(AK,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),d(LK,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),d(yK,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),d(xK,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),d($K,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),d(kK,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForMultipleChoice"),d(SK,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),d(RK,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),d(PK,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice"),d(BK,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),d(IK,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),d(NK,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),d(qK,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice"),d(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ZE,"id","transformers.AutoModelForNextSentencePrediction"),d(ZE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ZE,"href","#transformers.AutoModelForNextSentencePrediction"),d(cm,"class","relative group"),d(DK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(jK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(GK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(OK,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction"),d(VK,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction"),d(XK,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),d(zK,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),d(QK,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),d(WK,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),d(UK,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),d(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(d4,"id","transformers.AutoModelForTokenClassification"),d(d4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(d4,"href","#transformers.AutoModelForTokenClassification"),d(hm,"class","relative group"),d(HK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(JK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(YK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ZK,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification"),d(KK,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification"),d(eee,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),d(oee,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification"),d(ree,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification"),d(tee,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification"),d(aee,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),d(nee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),d(see,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification"),d(lee,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),d(iee,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),d(dee,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification"),d(mee,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification"),d(cee,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification"),d(fee,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),d(gee,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification"),d(hee,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification"),d(uee,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),d(pee,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification"),d(_ee,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),d(bee,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),d(vee,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),d(Fee,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForTokenClassification"),d(Tee,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification"),d(Mee,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification"),d(Eee,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification"),d(Cee,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),d(wee,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),d(Aee,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),d(Lee,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification"),d(yee,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),d(xee,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),d($ee,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification"),d(kee,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification"),d(See,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForTokenClassification"),d(Ree,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),d(Pee,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),d(Bee,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification"),d(Iee,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),d(Nee,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),d(qee,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),d(Dee,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification"),d(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(oC,"id","transformers.AutoModelForQuestionAnswering"),d(oC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(oC,"href","#transformers.AutoModelForQuestionAnswering"),d(_m,"class","relative group"),d(jee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Gee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Oee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Vee,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),d(Xee,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering"),d(zee,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering"),d(Qee,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),d(Wee,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),d(Uee,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering"),d(Hee,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),d(Jee,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering"),d(Yee,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),d(Zee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),d(Kee,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),d(eoe,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),d(ooe,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),d(roe,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),d(toe,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering"),d(aoe,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),d(noe,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),d(soe,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),d(loe,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),d(ioe,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),d(doe,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),d(moe,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),d(coe,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering"),d(foe,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForQuestionAnswering"),d(goe,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),d(hoe,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering"),d(uoe,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),d(poe,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering"),d(_oe,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),d(boe,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),d(voe,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),d(Foe,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),d(Toe,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),d(Moe,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),d(Eoe,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),d(Coe,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForQuestionAnswering"),d(woe,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),d(Aoe,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),d(Loe,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),d(yoe,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),d(xoe,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForQuestionAnswering"),d($oe,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),d(koe,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),d(Soe,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),d(Roe,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),d(Poe,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),d(Boe,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),d(Ioe,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),d(Noe,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),d(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(e3,"id","transformers.AutoModelForTableQuestionAnswering"),d(e3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(e3,"href","#transformers.AutoModelForTableQuestionAnswering"),d(Fm,"class","relative group"),d(qoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Doe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(joe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Goe,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),d(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(n3,"id","transformers.AutoModelForDocumentQuestionAnswering"),d(n3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(n3,"href","#transformers.AutoModelForDocumentQuestionAnswering"),d(Em,"class","relative group"),d(Ooe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Voe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Xoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(zoe,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering"),d(Qoe,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),d(Woe,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),d(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(f3,"id","transformers.AutoModelForImageClassification"),d(f3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(f3,"href","#transformers.AutoModelForImageClassification"),d(Lm,"class","relative group"),d(Uoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Hoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Joe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Yoe,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification"),d(Zoe,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification"),d(Koe,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification"),d(ere,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),d(ore,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification"),d(rre,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),d(tre,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),d(are,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification"),d(nre,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),d(sre,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification"),d(lre,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),d(ire,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),d(dre,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),d(mre,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),d(cre,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification"),d(fre,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification"),d(gre,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification"),d(hre,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification"),d(ure,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification"),d(pre,"href","/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification"),d(_re,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification"),d(bre,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification"),d(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(k3,"id","transformers.AutoModelForVideoClassification"),d(k3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(k3,"href","#transformers.AutoModelForVideoClassification"),d($m,"class","relative group"),d(vre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Fre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Tre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Mre,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification"),d(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(I3,"id","transformers.AutoModelForVision2Seq"),d(I3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(I3,"href","#transformers.AutoModelForVision2Seq"),d(Rm,"class","relative group"),d(Ere,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Cre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(wre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Are,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),d(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(G3,"id","transformers.AutoModelForVisualQuestionAnswering"),d(G3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(G3,"href","#transformers.AutoModelForVisualQuestionAnswering"),d(Im,"class","relative group"),d(Lre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(yre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(xre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($re,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),d(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Q3,"id","transformers.AutoModelForAudioClassification"),d(Q3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Q3,"href","#transformers.AutoModelForAudioClassification"),d(Dm,"class","relative group"),d(kre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Sre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Rre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Pre,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),d(Bre,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification"),d(Ire,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification"),d(Nre,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),d(qre,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),d(Dre,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),d(jre,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),d(Gre,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),d(Ore,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),d(To,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(n5,"id","transformers.AutoModelForAudioFrameClassification"),d(n5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(n5,"href","#transformers.AutoModelForAudioFrameClassification"),d(Om,"class","relative group"),d(Vre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Xre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(zre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Qre,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),d(Wre,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),d(Ure,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),d(Hre,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),d(Jre,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),d(Mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(h5,"id","transformers.AutoModelForCTC"),d(h5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(h5,"href","#transformers.AutoModelForCTC"),d(zm,"class","relative group"),d(Yre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Zre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Kre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ete,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),d(ote,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC"),d(rte,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC"),d(tte,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC"),d(ate,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC"),d(nte,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC"),d(ste,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),d(lte,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),d(ite,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),d(dte,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC"),d(Eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(y5,"id","transformers.AutoModelForSpeechSeq2Seq"),d(y5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(y5,"href","#transformers.AutoModelForSpeechSeq2Seq"),d(Um,"class","relative group"),d(mte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(cte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(fte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(gte,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),d(hte,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),d(ute,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration"),d(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(B5,"id","transformers.AutoModelForAudioXVector"),d(B5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(B5,"href","#transformers.AutoModelForAudioXVector"),d(Zm,"class","relative group"),d(pte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(_te,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(bte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(vte,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),d(Fte,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),d(Tte,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),d(Mte,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),d(Ete,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector"),d(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(X5,"id","transformers.AutoModelForMaskedImageModeling"),d(X5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(X5,"href","#transformers.AutoModelForMaskedImageModeling"),d(oc,"class","relative group"),d(Cte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(wte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Ate,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Lte,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),d(yte,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),d(xte,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling"),d($te,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),d(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Z5,"id","transformers.AutoModelForObjectDetection"),d(Z5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Z5,"href","#transformers.AutoModelForObjectDetection"),d(ac,"class","relative group"),d(kte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ste,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Rte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Pte,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection"),d(Bte,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection"),d(Ite,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection"),d(Nte,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection"),d(qte,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection"),d(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(l0,"id","transformers.AutoModelForImageSegmentation"),d(l0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(l0,"href","#transformers.AutoModelForImageSegmentation"),d(lc,"class","relative group"),d(Dte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(jte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Gte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ote,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation"),d(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(f0,"id","transformers.AutoModelForSemanticSegmentation"),d(f0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(f0,"href","#transformers.AutoModelForSemanticSegmentation"),d(mc,"class","relative group"),d(Vte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Xte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(zte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Qte,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),d(Wte,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),d(Ute,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),d(Hte,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation"),d(Jte,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),d(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(T0,"id","transformers.AutoModelForInstanceSegmentation"),d(T0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(T0,"href","#transformers.AutoModelForInstanceSegmentation"),d(gc,"class","relative group"),d(Yte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Zte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Kte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(eae,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),d($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(A0,"id","transformers.AutoModelForZeroShotObjectDetection"),d(A0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(A0,"href","#transformers.AutoModelForZeroShotObjectDetection"),d(pc,"class","relative group"),d(oae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(rae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(tae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(aae,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTForObjectDetection"),d(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(k0,"id","transformers.TFAutoModel"),d(k0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(k0,"href","#transformers.TFAutoModel"),d(vc,"class","relative group"),d(nae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(sae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(lae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(iae,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel"),d(dae,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel"),d(mae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel"),d(cae,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),d(fae,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),d(gae,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel"),d(hae,"href","/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel"),d(uae,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel"),d(pae,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel"),d(_ae,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel"),d(bae,"href","/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtModel"),d(vae,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),d(Fae,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel"),d(Tae,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),d(Mae,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel"),d(Eae,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel"),d(Cae,"href","/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),d(wae,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel"),d(Aae,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmModel"),d(Lae,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel"),d(yae,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel"),d(xae,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel"),d($ae,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model"),d(kae,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel"),d(Sae,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel"),d(Rae,"href","/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel"),d(Pae,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),d(Bae,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model"),d(Iae,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel"),d(Nae,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel"),d(qae,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel"),d(Dae,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel"),d(jae,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel"),d(Gae,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel"),d(Oae,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel"),d(Vae,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel"),d(Xae,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model"),d(zae,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),d(Qae,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel"),d(Wae,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel"),d(Uae,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel"),d(Hae,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel"),d(Jae,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel"),d(Yae,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel"),d(Zae,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel"),d(Kae,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel"),d(ene,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),d(one,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel"),d(rne,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model"),d(tne,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel"),d(ane,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),d(nne,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel"),d(sne,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel"),d(lne,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),d(ine,"href","/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperModel"),d(dne,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel"),d(mne,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel"),d(cne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),d(fne,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel"),d(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Nw,"id","transformers.TFAutoModelForPreTraining"),d(Nw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Nw,"href","#transformers.TFAutoModelForPreTraining"),d(Mc,"class","relative group"),d(gne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(hne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(une,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(pne,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining"),d(_ne,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),d(bne,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining"),d(vne,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),d(Fne,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),d(Tne,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),d(Mne,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining"),d(Ene,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),d(Cne,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),d(wne,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),d(Ane,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),d(Lne,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),d(yne,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),d(xne,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),d($ne,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),d(kne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),d(Sne,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),d(Rne,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),d(Pne,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),d(Bne,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),d(Ine,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(Nne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),d(qne,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),d(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(dA,"id","transformers.TFAutoModelForCausalLM"),d(dA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(dA,"href","#transformers.TFAutoModelForCausalLM"),d(wc,"class","relative group"),d(Dne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(jne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Gne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(One,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel"),d(Vne,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),d(Xne,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),d(zne,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),d(Qne,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),d(Wne,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),d(Une,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM"),d(Hne,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),d(Jne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),d(Yne,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),d(Zne,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),d(Kne,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM"),d(ese,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(ose,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),d(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(AA,"id","transformers.TFAutoModelForImageClassification"),d(AA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(AA,"href","#transformers.TFAutoModelForImageClassification"),d(yc,"class","relative group"),d(rse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(tse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(ase,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(nse,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),d(sse,"href","/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtForImageClassification"),d(lse,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),d(ise,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification"),d(dse,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher"),d(mse,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification"),d(cse,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),d(fse,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification"),d(gse,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification"),d(hse,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification"),d(use,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification"),d(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qA,"id","transformers.TFAutoModelForSemanticSegmentation"),d(qA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(qA,"href","#transformers.TFAutoModelForSemanticSegmentation"),d(kc,"class","relative group"),d(pse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(_se,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(bse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(na,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(vse,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation"),d(Fse,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation"),d(Tse,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation"),d(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(XA,"id","transformers.TFAutoModelForMaskedLM"),d(XA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(XA,"href","#transformers.TFAutoModelForMaskedLM"),d(Bc,"class","relative group"),d(Mse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ese,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Cse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(sa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(wse,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),d(Ase,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM"),d(Lse,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),d(yse,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),d(xse,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),d($se,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),d(kse,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),d(Sse,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM"),d(Rse,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForMaskedLM"),d(Pse,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),d(Bse,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),d(Ise,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),d(Nse,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),d(qse,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),d(Dse,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),d(jse,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),d(Gse,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),d(Ose,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),d(Vse,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),d(Xse,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(zse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),d(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(h6,"id","transformers.TFAutoModelForSeq2SeqLM"),d(h6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(h6,"href","#transformers.TFAutoModelForSeq2SeqLM"),d(qc,"class","relative group"),d(Qse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Wse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Use,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(la,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Hse,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),d(Jse,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),d(Yse,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),d(Zse,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),d(Kse,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),d(ele,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel"),d(ole,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),d(rle,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),d(tle,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),d(ale,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),d(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(L6,"id","transformers.TFAutoModelForSequenceClassification"),d(L6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(L6,"href","#transformers.TFAutoModelForSequenceClassification"),d(Gc,"class","relative group"),d(nle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(sle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(lle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ia,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ile,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),d(dle,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification"),d(mle,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),d(cle,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),d(fle,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),d(gle,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),d(hle,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),d(ule,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),d(ple,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),d(_le,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForSequenceClassification"),d(ble,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),d(vle,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),d(Fle,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),d(Tle,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),d(Mle,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),d(Ele,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification"),d(Cle,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),d(wle,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),d(Ale,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),d(Lle,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),d(yle,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),d(xle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),d($le,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),d(kle,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),d(Sle,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),d(Rle,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),d(Ple,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),d(Ble,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),d(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(a7,"id","transformers.TFAutoModelForMultipleChoice"),d(a7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(a7,"href","#transformers.TFAutoModelForMultipleChoice"),d(Xc,"class","relative group"),d(Ile,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Nle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(qle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(da,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Dle,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),d(jle,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice"),d(Gle,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),d(Ole,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),d(Vle,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),d(Xle,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),d(zle,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),d(Qle,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),d(Wle,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),d(Ule,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),d(Hle,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),d(Jle,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),d(Yle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),d(Zle,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),d(Kle,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),d(eie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),d(oie,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),d(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(C7,"id","transformers.TFAutoModelForNextSentencePrediction"),d(C7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(C7,"href","#transformers.TFAutoModelForNextSentencePrediction"),d(Wc,"class","relative group"),d(rie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(tie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(aie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(nie,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),d(sie,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),d(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(x7,"id","transformers.TFAutoModelForTableQuestionAnswering"),d(x7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(x7,"href","#transformers.TFAutoModelForTableQuestionAnswering"),d(Jc,"class","relative group"),d(lie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(iie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(die,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(mie,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),d(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(R7,"id","transformers.TFAutoModelForDocumentQuestionAnswering"),d(R7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(R7,"href","#transformers.TFAutoModelForDocumentQuestionAnswering"),d(Kc,"class","relative group"),d(cie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(fie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(gie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(hie,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering"),d(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(N7,"id","transformers.TFAutoModelForTokenClassification"),d(N7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(N7,"href","#transformers.TFAutoModelForTokenClassification"),d(rf,"class","relative group"),d(uie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(pie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(_ie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ga,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(bie,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),d(vie,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification"),d(Fie,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),d(Tie,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),d(Mie,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),d(Eie,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),d(Cie,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),d(wie,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification"),d(Aie,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForTokenClassification"),d(Lie,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),d(yie,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),d(xie,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),d($ie,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification"),d(kie,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),d(Sie,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),d(Rie,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),d(Pie,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),d(Bie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),d(Iie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),d(Nie,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),d(qie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),d(Die,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),d(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(i8,"id","transformers.TFAutoModelForQuestionAnswering"),d(i8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(i8,"href","#transformers.TFAutoModelForQuestionAnswering"),d(nf,"class","relative group"),d(jie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Gie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Oie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ha,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Vie,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),d(Xie,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),d(zie,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),d(Qie,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),d(Wie,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),d(Uie,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),d(Hie,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),d(Jie,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),d(Yie,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),d(Zie,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),d(Kie,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),d(ede,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering"),d(ode,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),d(rde,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),d(tde,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),d(ade,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),d(nde,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),d(sde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),d(lde,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),d(ide,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),d(dde,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),d(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(S8,"id","transformers.TFAutoModelForVision2Seq"),d(S8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(S8,"href","#transformers.TFAutoModelForVision2Seq"),d(df,"class","relative group"),d(mde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(cde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(fde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ua,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(gde,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),d(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(I8,"id","transformers.TFAutoModelForSpeechSeq2Seq"),d(I8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(I8,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),d(ff,"class","relative group"),d(hde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ude,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(pde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(pa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(_de,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),d(bde,"href","/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration"),d(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(G8,"id","transformers.FlaxAutoModel"),d(G8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(G8,"href","#transformers.FlaxAutoModel"),d(uf,"class","relative group"),d(vde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Fde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Tde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(_a,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Mde,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel"),d(Ede,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel"),d(Cde,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel"),d(wde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel"),d(Ade,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),d(Lde,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),d(yde,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),d(xde,"href","/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel"),d($de,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),d(kde,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel"),d(Sde,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model"),d(Rde,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),d(Pde,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel"),d(Bde,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model"),d(Ide,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel"),d(Nde,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel"),d(qde,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model"),d(Dde,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel"),d(jde,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel"),d(Gde,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel"),d(Ode,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel"),d(Vde,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model"),d(Xde,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),d(zde,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel"),d(Qde,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),d(Wde,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel"),d(Ude,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),d(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(_L,"id","transformers.FlaxAutoModelForCausalLM"),d(_L,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(_L,"href","#transformers.FlaxAutoModelForCausalLM"),d(bf,"class","relative group"),d(Hde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Jde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Yde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ba,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Zde,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM"),d(Kde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM"),d(eme,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),d(ome,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),d(rme,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),d(tme,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),d(ame,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),d(nme,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),d(sme,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),d(lme,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),d(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($L,"id","transformers.FlaxAutoModelForPreTraining"),d($L,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d($L,"href","#transformers.FlaxAutoModelForPreTraining"),d(Tf,"class","relative group"),d(ime,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(dme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(mme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(va,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(cme,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),d(fme,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(gme,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining"),d(hme,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),d(ume,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),d(pme,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),d(_me,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(bme,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),d(vme,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),d(Fme,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),d(Tme,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),d(Mme,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),d(Eme,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),d(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(QL,"id","transformers.FlaxAutoModelForMaskedLM"),d(QL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(QL,"href","#transformers.FlaxAutoModelForMaskedLM"),d(Cf,"class","relative group"),d(Cme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(wme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Ame,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Lme,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),d(yme,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(xme,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),d($me,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),d(kme,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),d(Sme,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),d(Rme,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(Pme,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),d(Bme,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),d(Ime,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),d(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ny,"id","transformers.FlaxAutoModelForSeq2SeqLM"),d(ny,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ny,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),d(Lf,"class","relative group"),d(Nme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(qme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Dme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(jme,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(Gme,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),d(Ome,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),d(Vme,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),d(Xme,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),d(zme,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel"),d(Qme,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(Wme,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),d(Ume,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),d(Hme,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),d(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(by,"id","transformers.FlaxAutoModelForSequenceClassification"),d(by,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(by,"href","#transformers.FlaxAutoModelForSequenceClassification"),d($f,"class","relative group"),d(Jme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Yme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Zme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Kme,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),d(ece,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),d(oce,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),d(rce,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),d(tce,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),d(ace,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),d(nce,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),d(sce,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),d(lce,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),d(ice,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),d(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ky,"id","transformers.FlaxAutoModelForQuestionAnswering"),d(ky,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ky,"href","#transformers.FlaxAutoModelForQuestionAnswering"),d(Rf,"class","relative group"),d(dce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(mce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(cce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(fce,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),d(gce,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),d(hce,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),d(uce,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),d(pce,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),d(_ce,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),d(bce,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),d(vce,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),d(Fce,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),d(Tce,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),d(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Xy,"id","transformers.FlaxAutoModelForTokenClassification"),d(Xy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Xy,"href","#transformers.FlaxAutoModelForTokenClassification"),d(If,"class","relative group"),d(Mce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ece,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Cce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(wce,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),d(Ace,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),d(Lce,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),d(yce,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),d(xce,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),d($ce,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),d(kce,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),d(Sce,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),d(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(o9,"id","transformers.FlaxAutoModelForMultipleChoice"),d(o9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(o9,"href","#transformers.FlaxAutoModelForMultipleChoice"),d(Df,"class","relative group"),d(Rce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Pce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Bce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(wa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ice,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),d(Nce,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),d(qce,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),d(Dce,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),d(jce,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),d(Gce,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),d(Oce,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),d(Vce,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),d(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(f9,"id","transformers.FlaxAutoModelForNextSentencePrediction"),d(f9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(f9,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),d(Of,"class","relative group"),d(Xce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(zce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Qce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Wce,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),d(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(p9,"id","transformers.FlaxAutoModelForImageClassification"),d(p9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(p9,"href","#transformers.FlaxAutoModelForImageClassification"),d(zf,"class","relative group"),d(Uce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Hce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Jce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(La,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Yce,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),d(Zce,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification"),d(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(T9,"id","transformers.FlaxAutoModelForVision2Seq"),d(T9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(T9,"href","#transformers.FlaxAutoModelForVision2Seq"),d(Uf,"class","relative group"),d(Kce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(efe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(ofe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ya,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(rfe,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),d(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(c,_){e(document.head,g),b(c,v,_),b(c,u,_),e(u,f),e(f,p),M(m,p,null),e(u,h),e(u,He),e(He,Ad),b(c,eg,_),b(c,wt,_),e(wt,Ld),e(wt,yd),e(yd,lk),e(wt,og),b(c,Qe,_),b(c,Ze,_),e(Ze,xd),e(Ze,ps),e(ps,ik),e(Ze,_s),e(Ze,bs),e(bs,dk),e(Ze,$d),e(Ze,vs),e(vs,mk),e(Ze,kd),b(c,rg,_),M(sn,c,_),b(c,Ke,_),b(c,ye,_),e(ye,kq),e(ye,Sd),e(Sd,Sq),e(ye,Rq),b(c,Po,_),b(c,ln,_),e(ln,Pq),e(ln,tg),e(tg,Bq),e(ln,afo),b(c,flo,_),b(c,Rd,_),e(Rd,ag),e(ag,che),M(ck,che,null),e(Rd,nfo),e(Rd,fhe),e(fhe,sfo),b(c,glo,_),b(c,Fs,_),e(Fs,lfo),e(Fs,ghe),e(ghe,ifo),e(Fs,dfo),e(Fs,hhe),e(hhe,mfo),e(Fs,cfo),b(c,hlo,_),M(fk,c,_),b(c,ulo,_),b(c,Iq,_),e(Iq,ffo),b(c,plo,_),M(ng,c,_),b(c,_lo,_),b(c,Pd,_),e(Pd,sg),e(sg,uhe),M(gk,uhe,null),e(Pd,gfo),e(Pd,phe),e(phe,hfo),b(c,blo,_),b(c,Bo,_),M(hk,Bo,null),e(Bo,ufo),e(Bo,uk),e(uk,pfo),e(uk,Nq),e(Nq,_fo),e(uk,bfo),e(Bo,vfo),e(Bo,pk),e(pk,Ffo),e(pk,_he),e(_he,Tfo),e(pk,Mfo),e(Bo,Efo),e(Bo,Or),M(_k,Or,null),e(Or,Cfo),e(Or,bhe),e(bhe,wfo),e(Or,Afo),e(Or,Bd),e(Bd,Lfo),e(Bd,vhe),e(vhe,yfo),e(Bd,xfo),e(Bd,Fhe),e(Fhe,$fo),e(Bd,kfo),e(Or,Sfo),e(Or,A),e(A,lg),e(lg,The),e(The,Rfo),e(lg,Pfo),e(lg,qq),e(qq,Bfo),e(lg,Ifo),e(A,Nfo),e(A,ig),e(ig,Mhe),e(Mhe,qfo),e(ig,Dfo),e(ig,Dq),e(Dq,jfo),e(ig,Gfo),e(A,Ofo),e(A,dg),e(dg,Ehe),e(Ehe,Vfo),e(dg,Xfo),e(dg,jq),e(jq,zfo),e(dg,Qfo),e(A,Wfo),e(A,mg),e(mg,Che),e(Che,Ufo),e(mg,Hfo),e(mg,Gq),e(Gq,Jfo),e(mg,Yfo),e(A,Zfo),e(A,cg),e(cg,whe),e(whe,Kfo),e(cg,ego),e(cg,Oq),e(Oq,ogo),e(cg,rgo),e(A,tgo),e(A,fg),e(fg,Ahe),e(Ahe,ago),e(fg,ngo),e(fg,Vq),e(Vq,sgo),e(fg,lgo),e(A,igo),e(A,gg),e(gg,Lhe),e(Lhe,dgo),e(gg,mgo),e(gg,Xq),e(Xq,cgo),e(gg,fgo),e(A,ggo),e(A,hg),e(hg,yhe),e(yhe,hgo),e(hg,ugo),e(hg,zq),e(zq,pgo),e(hg,_go),e(A,bgo),e(A,ug),e(ug,xhe),e(xhe,vgo),e(ug,Fgo),e(ug,Qq),e(Qq,Tgo),e(ug,Mgo),e(A,Ego),e(A,pg),e(pg,$he),e($he,Cgo),e(pg,wgo),e(pg,Wq),e(Wq,Ago),e(pg,Lgo),e(A,ygo),e(A,_g),e(_g,khe),e(khe,xgo),e(_g,$go),e(_g,Uq),e(Uq,kgo),e(_g,Sgo),e(A,Rgo),e(A,bg),e(bg,She),e(She,Pgo),e(bg,Bgo),e(bg,Hq),e(Hq,Igo),e(bg,Ngo),e(A,qgo),e(A,vg),e(vg,Rhe),e(Rhe,Dgo),e(vg,jgo),e(vg,Jq),e(Jq,Ggo),e(vg,Ogo),e(A,Vgo),e(A,Fg),e(Fg,Phe),e(Phe,Xgo),e(Fg,zgo),e(Fg,Yq),e(Yq,Qgo),e(Fg,Wgo),e(A,Ugo),e(A,Tg),e(Tg,Bhe),e(Bhe,Hgo),e(Tg,Jgo),e(Tg,Zq),e(Zq,Ygo),e(Tg,Zgo),e(A,Kgo),e(A,Mg),e(Mg,Ihe),e(Ihe,eho),e(Mg,oho),e(Mg,Kq),e(Kq,rho),e(Mg,tho),e(A,aho),e(A,Eg),e(Eg,Nhe),e(Nhe,nho),e(Eg,sho),e(Eg,eD),e(eD,lho),e(Eg,iho),e(A,dho),e(A,Cg),e(Cg,qhe),e(qhe,mho),e(Cg,cho),e(Cg,oD),e(oD,fho),e(Cg,gho),e(A,hho),e(A,wg),e(wg,Dhe),e(Dhe,uho),e(wg,pho),e(wg,rD),e(rD,_ho),e(wg,bho),e(A,vho),e(A,Ag),e(Ag,jhe),e(jhe,Fho),e(Ag,Tho),e(Ag,tD),e(tD,Mho),e(Ag,Eho),e(A,Cho),e(A,Lg),e(Lg,Ghe),e(Ghe,who),e(Lg,Aho),e(Lg,aD),e(aD,Lho),e(Lg,yho),e(A,xho),e(A,yg),e(yg,Ohe),e(Ohe,$ho),e(yg,kho),e(yg,nD),e(nD,Sho),e(yg,Rho),e(A,Pho),e(A,xg),e(xg,Vhe),e(Vhe,Bho),e(xg,Iho),e(xg,sD),e(sD,Nho),e(xg,qho),e(A,Dho),e(A,$g),e($g,Xhe),e(Xhe,jho),e($g,Gho),e($g,lD),e(lD,Oho),e($g,Vho),e(A,Xho),e(A,kg),e(kg,zhe),e(zhe,zho),e(kg,Qho),e(kg,iD),e(iD,Who),e(kg,Uho),e(A,Hho),e(A,Sg),e(Sg,Qhe),e(Qhe,Jho),e(Sg,Yho),e(Sg,dD),e(dD,Zho),e(Sg,Kho),e(A,euo),e(A,Rg),e(Rg,Whe),e(Whe,ouo),e(Rg,ruo),e(Rg,mD),e(mD,tuo),e(Rg,auo),e(A,nuo),e(A,Pg),e(Pg,Uhe),e(Uhe,suo),e(Pg,luo),e(Pg,cD),e(cD,iuo),e(Pg,duo),e(A,muo),e(A,Bg),e(Bg,Hhe),e(Hhe,cuo),e(Bg,fuo),e(Bg,fD),e(fD,guo),e(Bg,huo),e(A,uuo),e(A,Ig),e(Ig,Jhe),e(Jhe,puo),e(Ig,_uo),e(Ig,gD),e(gD,buo),e(Ig,vuo),e(A,Fuo),e(A,Ng),e(Ng,Yhe),e(Yhe,Tuo),e(Ng,Muo),e(Ng,hD),e(hD,Euo),e(Ng,Cuo),e(A,wuo),e(A,qg),e(qg,Zhe),e(Zhe,Auo),e(qg,Luo),e(qg,uD),e(uD,yuo),e(qg,xuo),e(A,$uo),e(A,Dg),e(Dg,Khe),e(Khe,kuo),e(Dg,Suo),e(Dg,pD),e(pD,Ruo),e(Dg,Puo),e(A,Buo),e(A,jg),e(jg,eue),e(eue,Iuo),e(jg,Nuo),e(jg,_D),e(_D,quo),e(jg,Duo),e(A,juo),e(A,Gg),e(Gg,oue),e(oue,Guo),e(Gg,Ouo),e(Gg,bD),e(bD,Vuo),e(Gg,Xuo),e(A,zuo),e(A,Og),e(Og,rue),e(rue,Quo),e(Og,Wuo),e(Og,vD),e(vD,Uuo),e(Og,Huo),e(A,Juo),e(A,Vg),e(Vg,tue),e(tue,Yuo),e(Vg,Zuo),e(Vg,FD),e(FD,Kuo),e(Vg,epo),e(A,opo),e(A,Xg),e(Xg,aue),e(aue,rpo),e(Xg,tpo),e(Xg,TD),e(TD,apo),e(Xg,npo),e(A,spo),e(A,zg),e(zg,nue),e(nue,lpo),e(zg,ipo),e(zg,MD),e(MD,dpo),e(zg,mpo),e(A,cpo),e(A,Qg),e(Qg,sue),e(sue,fpo),e(Qg,gpo),e(Qg,ED),e(ED,hpo),e(Qg,upo),e(A,ppo),e(A,Wg),e(Wg,lue),e(lue,_po),e(Wg,bpo),e(Wg,CD),e(CD,vpo),e(Wg,Fpo),e(A,Tpo),e(A,Ug),e(Ug,iue),e(iue,Mpo),e(Ug,Epo),e(Ug,wD),e(wD,Cpo),e(Ug,wpo),e(A,Apo),e(A,Hg),e(Hg,due),e(due,Lpo),e(Hg,ypo),e(Hg,AD),e(AD,xpo),e(Hg,$po),e(A,kpo),e(A,Jg),e(Jg,mue),e(mue,Spo),e(Jg,Rpo),e(Jg,LD),e(LD,Ppo),e(Jg,Bpo),e(A,Ipo),e(A,Yg),e(Yg,cue),e(cue,Npo),e(Yg,qpo),e(Yg,yD),e(yD,Dpo),e(Yg,jpo),e(A,Gpo),e(A,Zg),e(Zg,fue),e(fue,Opo),e(Zg,Vpo),e(Zg,xD),e(xD,Xpo),e(Zg,zpo),e(A,Qpo),e(A,Kg),e(Kg,gue),e(gue,Wpo),e(Kg,Upo),e(Kg,$D),e($D,Hpo),e(Kg,Jpo),e(A,Ypo),e(A,eh),e(eh,hue),e(hue,Zpo),e(eh,Kpo),e(eh,kD),e(kD,e_o),e(eh,o_o),e(A,r_o),e(A,oh),e(oh,uue),e(uue,t_o),e(oh,a_o),e(oh,SD),e(SD,n_o),e(oh,s_o),e(A,l_o),e(A,rh),e(rh,pue),e(pue,i_o),e(rh,d_o),e(rh,RD),e(RD,m_o),e(rh,c_o),e(A,f_o),e(A,th),e(th,_ue),e(_ue,g_o),e(th,h_o),e(th,PD),e(PD,u_o),e(th,p_o),e(A,__o),e(A,ah),e(ah,bue),e(bue,b_o),e(ah,v_o),e(ah,BD),e(BD,F_o),e(ah,T_o),e(A,M_o),e(A,nh),e(nh,vue),e(vue,E_o),e(nh,C_o),e(nh,ID),e(ID,w_o),e(nh,A_o),e(A,L_o),e(A,sh),e(sh,Fue),e(Fue,y_o),e(sh,x_o),e(sh,ND),e(ND,$_o),e(sh,k_o),e(A,S_o),e(A,lh),e(lh,Tue),e(Tue,R_o),e(lh,P_o),e(lh,qD),e(qD,B_o),e(lh,I_o),e(A,N_o),e(A,ih),e(ih,Mue),e(Mue,q_o),e(ih,D_o),e(ih,DD),e(DD,j_o),e(ih,G_o),e(A,O_o),e(A,dh),e(dh,Eue),e(Eue,V_o),e(dh,X_o),e(dh,jD),e(jD,z_o),e(dh,Q_o),e(A,W_o),e(A,mh),e(mh,Cue),e(Cue,U_o),e(mh,H_o),e(mh,GD),e(GD,J_o),e(mh,Y_o),e(A,Z_o),e(A,ch),e(ch,wue),e(wue,K_o),e(ch,e1o),e(ch,OD),e(OD,o1o),e(ch,r1o),e(A,t1o),e(A,fh),e(fh,Aue),e(Aue,a1o),e(fh,n1o),e(fh,VD),e(VD,s1o),e(fh,l1o),e(A,i1o),e(A,gh),e(gh,Lue),e(Lue,d1o),e(gh,m1o),e(gh,XD),e(XD,c1o),e(gh,f1o),e(A,g1o),e(A,hh),e(hh,yue),e(yue,h1o),e(hh,u1o),e(hh,zD),e(zD,p1o),e(hh,_1o),e(A,b1o),e(A,uh),e(uh,xue),e(xue,v1o),e(uh,F1o),e(uh,QD),e(QD,T1o),e(uh,M1o),e(A,E1o),e(A,ph),e(ph,$ue),e($ue,C1o),e(ph,w1o),e(ph,WD),e(WD,A1o),e(ph,L1o),e(A,y1o),e(A,_h),e(_h,kue),e(kue,x1o),e(_h,$1o),e(_h,UD),e(UD,k1o),e(_h,S1o),e(A,R1o),e(A,bh),e(bh,Sue),e(Sue,P1o),e(bh,B1o),e(bh,HD),e(HD,I1o),e(bh,N1o),e(A,q1o),e(A,vh),e(vh,Rue),e(Rue,D1o),e(vh,j1o),e(vh,JD),e(JD,G1o),e(vh,O1o),e(A,V1o),e(A,Fh),e(Fh,Pue),e(Pue,X1o),e(Fh,z1o),e(Fh,YD),e(YD,Q1o),e(Fh,W1o),e(A,U1o),e(A,Th),e(Th,Bue),e(Bue,H1o),e(Th,J1o),e(Th,ZD),e(ZD,Y1o),e(Th,Z1o),e(A,K1o),e(A,Mh),e(Mh,Iue),e(Iue,e2o),e(Mh,o2o),e(Mh,KD),e(KD,r2o),e(Mh,t2o),e(A,a2o),e(A,Eh),e(Eh,Nue),e(Nue,n2o),e(Eh,s2o),e(Eh,ej),e(ej,l2o),e(Eh,i2o),e(A,d2o),e(A,Ch),e(Ch,que),e(que,m2o),e(Ch,c2o),e(Ch,oj),e(oj,f2o),e(Ch,g2o),e(A,h2o),e(A,wh),e(wh,Due),e(Due,u2o),e(wh,p2o),e(wh,rj),e(rj,_2o),e(wh,b2o),e(A,v2o),e(A,Ah),e(Ah,jue),e(jue,F2o),e(Ah,T2o),e(Ah,tj),e(tj,M2o),e(Ah,E2o),e(A,C2o),e(A,Lh),e(Lh,Gue),e(Gue,w2o),e(Lh,A2o),e(Lh,aj),e(aj,L2o),e(Lh,y2o),e(A,x2o),e(A,yh),e(yh,Oue),e(Oue,$2o),e(yh,k2o),e(yh,nj),e(nj,S2o),e(yh,R2o),e(A,P2o),e(A,xh),e(xh,Vue),e(Vue,B2o),e(xh,I2o),e(xh,sj),e(sj,N2o),e(xh,q2o),e(A,D2o),e(A,$h),e($h,Xue),e(Xue,j2o),e($h,G2o),e($h,lj),e(lj,O2o),e($h,V2o),e(A,X2o),e(A,kh),e(kh,zue),e(zue,z2o),e(kh,Q2o),e(kh,ij),e(ij,W2o),e(kh,U2o),e(A,H2o),e(A,Sh),e(Sh,Que),e(Que,J2o),e(Sh,Y2o),e(Sh,dj),e(dj,Z2o),e(Sh,K2o),e(A,ebo),e(A,Rh),e(Rh,Wue),e(Wue,obo),e(Rh,rbo),e(Rh,mj),e(mj,tbo),e(Rh,abo),e(A,nbo),e(A,Ph),e(Ph,Uue),e(Uue,sbo),e(Ph,lbo),e(Ph,cj),e(cj,ibo),e(Ph,dbo),e(A,mbo),e(A,Bh),e(Bh,Hue),e(Hue,cbo),e(Bh,fbo),e(Bh,fj),e(fj,gbo),e(Bh,hbo),e(A,ubo),e(A,Ih),e(Ih,Jue),e(Jue,pbo),e(Ih,_bo),e(Ih,gj),e(gj,bbo),e(Ih,vbo),e(A,Fbo),e(A,Nh),e(Nh,Yue),e(Yue,Tbo),e(Nh,Mbo),e(Nh,hj),e(hj,Ebo),e(Nh,Cbo),e(A,wbo),e(A,qh),e(qh,Zue),e(Zue,Abo),e(qh,Lbo),e(qh,uj),e(uj,ybo),e(qh,xbo),e(A,$bo),e(A,Dh),e(Dh,Kue),e(Kue,kbo),e(Dh,Sbo),e(Dh,pj),e(pj,Rbo),e(Dh,Pbo),e(A,Bbo),e(A,jh),e(jh,epe),e(epe,Ibo),e(jh,Nbo),e(jh,_j),e(_j,qbo),e(jh,Dbo),e(A,jbo),e(A,Gh),e(Gh,ope),e(ope,Gbo),e(Gh,Obo),e(Gh,bj),e(bj,Vbo),e(Gh,Xbo),e(A,zbo),e(A,Oh),e(Oh,rpe),e(rpe,Qbo),e(Oh,Wbo),e(Oh,vj),e(vj,Ubo),e(Oh,Hbo),e(A,Jbo),e(A,Vh),e(Vh,tpe),e(tpe,Ybo),e(Vh,Zbo),e(Vh,Fj),e(Fj,Kbo),e(Vh,evo),e(A,ovo),e(A,Xh),e(Xh,ape),e(ape,rvo),e(Xh,tvo),e(Xh,Tj),e(Tj,avo),e(Xh,nvo),e(A,svo),e(A,zh),e(zh,npe),e(npe,lvo),e(zh,ivo),e(zh,Mj),e(Mj,dvo),e(zh,mvo),e(A,cvo),e(A,Qh),e(Qh,spe),e(spe,fvo),e(Qh,gvo),e(Qh,Ej),e(Ej,hvo),e(Qh,uvo),e(A,pvo),e(A,Wh),e(Wh,lpe),e(lpe,_vo),e(Wh,bvo),e(Wh,Cj),e(Cj,vvo),e(Wh,Fvo),e(A,Tvo),e(A,Uh),e(Uh,ipe),e(ipe,Mvo),e(Uh,Evo),e(Uh,wj),e(wj,Cvo),e(Uh,wvo),e(A,Avo),e(A,Hh),e(Hh,dpe),e(dpe,Lvo),e(Hh,yvo),e(Hh,Aj),e(Aj,xvo),e(Hh,$vo),e(A,kvo),e(A,Jh),e(Jh,mpe),e(mpe,Svo),e(Jh,Rvo),e(Jh,Lj),e(Lj,Pvo),e(Jh,Bvo),e(A,Ivo),e(A,Yh),e(Yh,cpe),e(cpe,Nvo),e(Yh,qvo),e(Yh,yj),e(yj,Dvo),e(Yh,jvo),e(A,Gvo),e(A,Zh),e(Zh,fpe),e(fpe,Ovo),e(Zh,Vvo),e(Zh,xj),e(xj,Xvo),e(Zh,zvo),e(A,Qvo),e(A,Kh),e(Kh,gpe),e(gpe,Wvo),e(Kh,Uvo),e(Kh,$j),e($j,Hvo),e(Kh,Jvo),e(A,Yvo),e(A,eu),e(eu,hpe),e(hpe,Zvo),e(eu,Kvo),e(eu,kj),e(kj,eFo),e(eu,oFo),e(A,rFo),e(A,ou),e(ou,upe),e(upe,tFo),e(ou,aFo),e(ou,Sj),e(Sj,nFo),e(ou,sFo),e(A,lFo),e(A,ru),e(ru,ppe),e(ppe,iFo),e(ru,dFo),e(ru,Rj),e(Rj,mFo),e(ru,cFo),e(A,fFo),e(A,tu),e(tu,_pe),e(_pe,gFo),e(tu,hFo),e(tu,Pj),e(Pj,uFo),e(tu,pFo),e(A,_Fo),e(A,au),e(au,bpe),e(bpe,bFo),e(au,vFo),e(au,Bj),e(Bj,FFo),e(au,TFo),e(A,MFo),e(A,nu),e(nu,vpe),e(vpe,EFo),e(nu,CFo),e(nu,Ij),e(Ij,wFo),e(nu,AFo),e(A,LFo),e(A,su),e(su,Fpe),e(Fpe,yFo),e(su,xFo),e(su,Nj),e(Nj,$Fo),e(su,kFo),e(A,SFo),e(A,lu),e(lu,Tpe),e(Tpe,RFo),e(lu,PFo),e(lu,qj),e(qj,BFo),e(lu,IFo),e(A,NFo),e(A,iu),e(iu,Mpe),e(Mpe,qFo),e(iu,DFo),e(iu,Dj),e(Dj,jFo),e(iu,GFo),e(A,OFo),e(A,du),e(du,Epe),e(Epe,VFo),e(du,XFo),e(du,jj),e(jj,zFo),e(du,QFo),e(A,WFo),e(A,mu),e(mu,Cpe),e(Cpe,UFo),e(mu,HFo),e(mu,Gj),e(Gj,JFo),e(mu,YFo),e(A,ZFo),e(A,cu),e(cu,wpe),e(wpe,KFo),e(cu,eTo),e(cu,Oj),e(Oj,oTo),e(cu,rTo),e(A,tTo),e(A,fu),e(fu,Ape),e(Ape,aTo),e(fu,nTo),e(fu,Vj),e(Vj,sTo),e(fu,lTo),e(A,iTo),e(A,gu),e(gu,Lpe),e(Lpe,dTo),e(gu,mTo),e(gu,Xj),e(Xj,cTo),e(gu,fTo),e(A,gTo),e(A,hu),e(hu,ype),e(ype,hTo),e(hu,uTo),e(hu,zj),e(zj,pTo),e(hu,_To),e(A,bTo),e(A,uu),e(uu,xpe),e(xpe,vTo),e(uu,FTo),e(uu,Qj),e(Qj,TTo),e(uu,MTo),e(A,ETo),e(A,pu),e(pu,$pe),e($pe,CTo),e(pu,wTo),e(pu,Wj),e(Wj,ATo),e(pu,LTo),e(A,yTo),e(A,_u),e(_u,kpe),e(kpe,xTo),e(_u,$To),e(_u,Uj),e(Uj,kTo),e(_u,STo),e(A,RTo),e(A,bu),e(bu,Spe),e(Spe,PTo),e(bu,BTo),e(bu,Hj),e(Hj,ITo),e(bu,NTo),e(A,qTo),e(A,vu),e(vu,Rpe),e(Rpe,DTo),e(vu,jTo),e(vu,Jj),e(Jj,GTo),e(vu,OTo),e(A,VTo),e(A,Fu),e(Fu,Ppe),e(Ppe,XTo),e(Fu,zTo),e(Fu,Yj),e(Yj,QTo),e(Fu,WTo),e(A,UTo),e(A,Tu),e(Tu,Bpe),e(Bpe,HTo),e(Tu,JTo),e(Tu,Zj),e(Zj,YTo),e(Tu,ZTo),e(A,KTo),e(A,Mu),e(Mu,Ipe),e(Ipe,eMo),e(Mu,oMo),e(Mu,Kj),e(Kj,rMo),e(Mu,tMo),e(A,aMo),e(A,Eu),e(Eu,Npe),e(Npe,nMo),e(Eu,sMo),e(Eu,eG),e(eG,lMo),e(Eu,iMo),e(A,dMo),e(A,Cu),e(Cu,qpe),e(qpe,mMo),e(Cu,cMo),e(Cu,oG),e(oG,fMo),e(Cu,gMo),e(A,hMo),e(A,wu),e(wu,Dpe),e(Dpe,uMo),e(wu,pMo),e(wu,rG),e(rG,_Mo),e(wu,bMo),e(A,vMo),e(A,Au),e(Au,jpe),e(jpe,FMo),e(Au,TMo),e(Au,tG),e(tG,MMo),e(Au,EMo),e(A,CMo),e(A,Lu),e(Lu,Gpe),e(Gpe,wMo),e(Lu,AMo),e(Lu,aG),e(aG,LMo),e(Lu,yMo),e(A,xMo),e(A,yu),e(yu,Ope),e(Ope,$Mo),e(yu,kMo),e(yu,nG),e(nG,SMo),e(yu,RMo),e(A,PMo),e(A,xu),e(xu,Vpe),e(Vpe,BMo),e(xu,IMo),e(xu,sG),e(sG,NMo),e(xu,qMo),e(A,DMo),e(A,$u),e($u,Xpe),e(Xpe,jMo),e($u,GMo),e($u,lG),e(lG,OMo),e($u,VMo),e(A,XMo),e(A,ku),e(ku,zpe),e(zpe,zMo),e(ku,QMo),e(ku,iG),e(iG,WMo),e(ku,UMo),e(A,HMo),e(A,Su),e(Su,Qpe),e(Qpe,JMo),e(Su,YMo),e(Su,dG),e(dG,ZMo),e(Su,KMo),e(A,eEo),e(A,Ru),e(Ru,Wpe),e(Wpe,oEo),e(Ru,rEo),e(Ru,mG),e(mG,tEo),e(Ru,aEo),e(A,nEo),e(A,Pu),e(Pu,Upe),e(Upe,sEo),e(Pu,lEo),e(Pu,cG),e(cG,iEo),e(Pu,dEo),e(A,mEo),e(A,Bu),e(Bu,Hpe),e(Hpe,cEo),e(Bu,fEo),e(Bu,fG),e(fG,gEo),e(Bu,hEo),e(Or,uEo),M(Iu,Or,null),e(Bo,pEo),e(Bo,Nu),M(bk,Nu,null),e(Nu,_Eo),e(Nu,Jpe),e(Jpe,bEo),b(c,vlo,_),b(c,Id,_),e(Id,qu),e(qu,Ype),M(vk,Ype,null),e(Id,vEo),e(Id,Zpe),e(Zpe,FEo),b(c,Flo,_),b(c,Io,_),M(Fk,Io,null),e(Io,TEo),e(Io,Tk),e(Tk,MEo),e(Tk,gG),e(gG,EEo),e(Tk,CEo),e(Io,wEo),e(Io,Mk),e(Mk,AEo),e(Mk,Kpe),e(Kpe,LEo),e(Mk,yEo),e(Io,xEo),e(Io,Vr),M(Ek,Vr,null),e(Vr,$Eo),e(Vr,e_e),e(e_e,kEo),e(Vr,SEo),e(Vr,dn),e(dn,REo),e(dn,o_e),e(o_e,PEo),e(dn,BEo),e(dn,r_e),e(r_e,IEo),e(dn,NEo),e(dn,t_e),e(t_e,qEo),e(dn,DEo),e(Vr,jEo),e(Vr,k),e(k,Ts),e(Ts,a_e),e(a_e,GEo),e(Ts,OEo),e(Ts,hG),e(hG,VEo),e(Ts,XEo),e(Ts,uG),e(uG,zEo),e(Ts,QEo),e(k,WEo),e(k,Ms),e(Ms,n_e),e(n_e,UEo),e(Ms,HEo),e(Ms,pG),e(pG,JEo),e(Ms,YEo),e(Ms,_G),e(_G,ZEo),e(Ms,KEo),e(k,e4o),e(k,Es),e(Es,s_e),e(s_e,o4o),e(Es,r4o),e(Es,bG),e(bG,t4o),e(Es,a4o),e(Es,vG),e(vG,n4o),e(Es,s4o),e(k,l4o),e(k,Du),e(Du,l_e),e(l_e,i4o),e(Du,d4o),e(Du,FG),e(FG,m4o),e(Du,c4o),e(k,f4o),e(k,Cs),e(Cs,i_e),e(i_e,g4o),e(Cs,h4o),e(Cs,TG),e(TG,u4o),e(Cs,p4o),e(Cs,MG),e(MG,_4o),e(Cs,b4o),e(k,v4o),e(k,ju),e(ju,d_e),e(d_e,F4o),e(ju,T4o),e(ju,EG),e(EG,M4o),e(ju,E4o),e(k,C4o),e(k,Gu),e(Gu,m_e),e(m_e,w4o),e(Gu,A4o),e(Gu,CG),e(CG,L4o),e(Gu,y4o),e(k,x4o),e(k,Ou),e(Ou,c_e),e(c_e,$4o),e(Ou,k4o),e(Ou,wG),e(wG,S4o),e(Ou,R4o),e(k,P4o),e(k,ws),e(ws,f_e),e(f_e,B4o),e(ws,I4o),e(ws,AG),e(AG,N4o),e(ws,q4o),e(ws,LG),e(LG,D4o),e(ws,j4o),e(k,G4o),e(k,As),e(As,g_e),e(g_e,O4o),e(As,V4o),e(As,yG),e(yG,X4o),e(As,z4o),e(As,xG),e(xG,Q4o),e(As,W4o),e(k,U4o),e(k,Ls),e(Ls,h_e),e(h_e,H4o),e(Ls,J4o),e(Ls,$G),e($G,Y4o),e(Ls,Z4o),e(Ls,kG),e(kG,K4o),e(Ls,eCo),e(k,oCo),e(k,Vu),e(Vu,u_e),e(u_e,rCo),e(Vu,tCo),e(Vu,SG),e(SG,aCo),e(Vu,nCo),e(k,sCo),e(k,Xu),e(Xu,p_e),e(p_e,lCo),e(Xu,iCo),e(Xu,RG),e(RG,dCo),e(Xu,mCo),e(k,cCo),e(k,zu),e(zu,__e),e(__e,fCo),e(zu,gCo),e(zu,PG),e(PG,hCo),e(zu,uCo),e(k,pCo),e(k,ys),e(ys,b_e),e(b_e,_Co),e(ys,bCo),e(ys,BG),e(BG,vCo),e(ys,FCo),e(ys,IG),e(IG,TCo),e(ys,MCo),e(k,ECo),e(k,Qu),e(Qu,v_e),e(v_e,CCo),e(Qu,wCo),e(Qu,NG),e(NG,ACo),e(Qu,LCo),e(k,yCo),e(k,xs),e(xs,F_e),e(F_e,xCo),e(xs,$Co),e(xs,qG),e(qG,kCo),e(xs,SCo),e(xs,DG),e(DG,RCo),e(xs,PCo),e(k,BCo),e(k,$s),e($s,T_e),e(T_e,ICo),e($s,NCo),e($s,jG),e(jG,qCo),e($s,DCo),e($s,GG),e(GG,jCo),e($s,GCo),e(k,OCo),e(k,ks),e(ks,M_e),e(M_e,VCo),e(ks,XCo),e(ks,OG),e(OG,zCo),e(ks,QCo),e(ks,VG),e(VG,WCo),e(ks,UCo),e(k,HCo),e(k,Ss),e(Ss,E_e),e(E_e,JCo),e(Ss,YCo),e(Ss,XG),e(XG,ZCo),e(Ss,KCo),e(Ss,zG),e(zG,e3o),e(Ss,o3o),e(k,r3o),e(k,Rs),e(Rs,C_e),e(C_e,t3o),e(Rs,a3o),e(Rs,QG),e(QG,n3o),e(Rs,s3o),e(Rs,WG),e(WG,l3o),e(Rs,i3o),e(k,d3o),e(k,Wu),e(Wu,w_e),e(w_e,m3o),e(Wu,c3o),e(Wu,UG),e(UG,f3o),e(Wu,g3o),e(k,h3o),e(k,Ps),e(Ps,A_e),e(A_e,u3o),e(Ps,p3o),e(Ps,HG),e(HG,_3o),e(Ps,b3o),e(Ps,JG),e(JG,v3o),e(Ps,F3o),e(k,T3o),e(k,Bs),e(Bs,L_e),e(L_e,M3o),e(Bs,E3o),e(Bs,YG),e(YG,C3o),e(Bs,w3o),e(Bs,ZG),e(ZG,A3o),e(Bs,L3o),e(k,y3o),e(k,Is),e(Is,y_e),e(y_e,x3o),e(Is,$3o),e(Is,KG),e(KG,k3o),e(Is,S3o),e(Is,eO),e(eO,R3o),e(Is,P3o),e(k,B3o),e(k,Ns),e(Ns,x_e),e(x_e,I3o),e(Ns,N3o),e(Ns,oO),e(oO,q3o),e(Ns,D3o),e(Ns,rO),e(rO,j3o),e(Ns,G3o),e(k,O3o),e(k,qs),e(qs,$_e),e($_e,V3o),e(qs,X3o),e(qs,tO),e(tO,z3o),e(qs,Q3o),e(qs,aO),e(aO,W3o),e(qs,U3o),e(k,H3o),e(k,Ds),e(Ds,k_e),e(k_e,J3o),e(Ds,Y3o),e(Ds,nO),e(nO,Z3o),e(Ds,K3o),e(Ds,sO),e(sO,e5o),e(Ds,o5o),e(k,r5o),e(k,js),e(js,S_e),e(S_e,t5o),e(js,a5o),e(js,lO),e(lO,n5o),e(js,s5o),e(js,iO),e(iO,l5o),e(js,i5o),e(k,d5o),e(k,Uu),e(Uu,R_e),e(R_e,m5o),e(Uu,c5o),e(Uu,dO),e(dO,f5o),e(Uu,g5o),e(k,h5o),e(k,Hu),e(Hu,P_e),e(P_e,u5o),e(Hu,p5o),e(Hu,mO),e(mO,_5o),e(Hu,b5o),e(k,v5o),e(k,Gs),e(Gs,B_e),e(B_e,F5o),e(Gs,T5o),e(Gs,cO),e(cO,M5o),e(Gs,E5o),e(Gs,fO),e(fO,C5o),e(Gs,w5o),e(k,A5o),e(k,Ju),e(Ju,I_e),e(I_e,L5o),e(Ju,y5o),e(Ju,gO),e(gO,x5o),e(Ju,$5o),e(k,k5o),e(k,Os),e(Os,N_e),e(N_e,S5o),e(Os,R5o),e(Os,hO),e(hO,P5o),e(Os,B5o),e(Os,uO),e(uO,I5o),e(Os,N5o),e(k,q5o),e(k,Vs),e(Vs,q_e),e(q_e,D5o),e(Vs,j5o),e(Vs,pO),e(pO,G5o),e(Vs,O5o),e(Vs,_O),e(_O,V5o),e(Vs,X5o),e(k,z5o),e(k,Xs),e(Xs,D_e),e(D_e,Q5o),e(Xs,W5o),e(Xs,bO),e(bO,U5o),e(Xs,H5o),e(Xs,vO),e(vO,J5o),e(Xs,Y5o),e(k,Z5o),e(k,Yu),e(Yu,j_e),e(j_e,K5o),e(Yu,e0o),e(Yu,FO),e(FO,o0o),e(Yu,r0o),e(k,t0o),e(k,Zu),e(Zu,G_e),e(G_e,a0o),e(Zu,n0o),e(Zu,TO),e(TO,s0o),e(Zu,l0o),e(k,i0o),e(k,zs),e(zs,O_e),e(O_e,d0o),e(zs,m0o),e(zs,MO),e(MO,c0o),e(zs,f0o),e(zs,EO),e(EO,g0o),e(zs,h0o),e(k,u0o),e(k,Qs),e(Qs,V_e),e(V_e,p0o),e(Qs,_0o),e(Qs,CO),e(CO,b0o),e(Qs,v0o),e(Qs,wO),e(wO,F0o),e(Qs,T0o),e(k,M0o),e(k,Ws),e(Ws,X_e),e(X_e,E0o),e(Ws,C0o),e(Ws,AO),e(AO,w0o),e(Ws,A0o),e(Ws,LO),e(LO,L0o),e(Ws,y0o),e(k,x0o),e(k,Ku),e(Ku,z_e),e(z_e,$0o),e(Ku,k0o),e(Ku,yO),e(yO,S0o),e(Ku,R0o),e(k,P0o),e(k,Us),e(Us,Q_e),e(Q_e,B0o),e(Us,I0o),e(Us,xO),e(xO,N0o),e(Us,q0o),e(Us,$O),e($O,D0o),e(Us,j0o),e(k,G0o),e(k,Hs),e(Hs,W_e),e(W_e,O0o),e(Hs,V0o),e(Hs,kO),e(kO,X0o),e(Hs,z0o),e(Hs,SO),e(SO,Q0o),e(Hs,W0o),e(k,U0o),e(k,Js),e(Js,U_e),e(U_e,H0o),e(Js,J0o),e(Js,RO),e(RO,Y0o),e(Js,Z0o),e(Js,PO),e(PO,K0o),e(Js,ewo),e(k,owo),e(k,Ys),e(Ys,H_e),e(H_e,rwo),e(Ys,two),e(Ys,BO),e(BO,awo),e(Ys,nwo),e(Ys,IO),e(IO,swo),e(Ys,lwo),e(k,iwo),e(k,Zs),e(Zs,J_e),e(J_e,dwo),e(Zs,mwo),e(Zs,NO),e(NO,cwo),e(Zs,fwo),e(Zs,qO),e(qO,gwo),e(Zs,hwo),e(k,uwo),e(k,Ks),e(Ks,Y_e),e(Y_e,pwo),e(Ks,_wo),e(Ks,DO),e(DO,bwo),e(Ks,vwo),e(Ks,jO),e(jO,Fwo),e(Ks,Two),e(k,Mwo),e(k,el),e(el,Z_e),e(Z_e,Ewo),e(el,Cwo),e(el,GO),e(GO,wwo),e(el,Awo),e(el,OO),e(OO,Lwo),e(el,ywo),e(k,xwo),e(k,ol),e(ol,K_e),e(K_e,$wo),e(ol,kwo),e(ol,VO),e(VO,Swo),e(ol,Rwo),e(ol,XO),e(XO,Pwo),e(ol,Bwo),e(k,Iwo),e(k,rl),e(rl,e1e),e(e1e,Nwo),e(rl,qwo),e(rl,zO),e(zO,Dwo),e(rl,jwo),e(rl,QO),e(QO,Gwo),e(rl,Owo),e(k,Vwo),e(k,ep),e(ep,o1e),e(o1e,Xwo),e(ep,zwo),e(ep,WO),e(WO,Qwo),e(ep,Wwo),e(k,Uwo),e(k,tl),e(tl,r1e),e(r1e,Hwo),e(tl,Jwo),e(tl,UO),e(UO,Ywo),e(tl,Zwo),e(tl,HO),e(HO,Kwo),e(tl,eAo),e(k,oAo),e(k,op),e(op,t1e),e(t1e,rAo),e(op,tAo),e(op,JO),e(JO,aAo),e(op,nAo),e(k,sAo),e(k,rp),e(rp,a1e),e(a1e,lAo),e(rp,iAo),e(rp,YO),e(YO,dAo),e(rp,mAo),e(k,cAo),e(k,al),e(al,n1e),e(n1e,fAo),e(al,gAo),e(al,ZO),e(ZO,hAo),e(al,uAo),e(al,KO),e(KO,pAo),e(al,_Ao),e(k,bAo),e(k,nl),e(nl,s1e),e(s1e,vAo),e(nl,FAo),e(nl,eV),e(eV,TAo),e(nl,MAo),e(nl,oV),e(oV,EAo),e(nl,CAo),e(k,wAo),e(k,sl),e(sl,l1e),e(l1e,AAo),e(sl,LAo),e(sl,rV),e(rV,yAo),e(sl,xAo),e(sl,tV),e(tV,$Ao),e(sl,kAo),e(k,SAo),e(k,tp),e(tp,i1e),e(i1e,RAo),e(tp,PAo),e(tp,aV),e(aV,BAo),e(tp,IAo),e(k,NAo),e(k,ll),e(ll,d1e),e(d1e,qAo),e(ll,DAo),e(ll,nV),e(nV,jAo),e(ll,GAo),e(ll,sV),e(sV,OAo),e(ll,VAo),e(k,XAo),e(k,il),e(il,m1e),e(m1e,zAo),e(il,QAo),e(il,lV),e(lV,WAo),e(il,UAo),e(il,iV),e(iV,HAo),e(il,JAo),e(k,YAo),e(k,dl),e(dl,c1e),e(c1e,ZAo),e(dl,KAo),e(dl,dV),e(dV,e6o),e(dl,o6o),e(dl,mV),e(mV,r6o),e(dl,t6o),e(k,a6o),e(k,ml),e(ml,f1e),e(f1e,n6o),e(ml,s6o),e(ml,cV),e(cV,l6o),e(ml,i6o),e(ml,fV),e(fV,d6o),e(ml,m6o),e(k,c6o),e(k,cl),e(cl,g1e),e(g1e,f6o),e(cl,g6o),e(cl,gV),e(gV,h6o),e(cl,u6o),e(cl,hV),e(hV,p6o),e(cl,_6o),e(k,b6o),e(k,fl),e(fl,h1e),e(h1e,v6o),e(fl,F6o),e(fl,uV),e(uV,T6o),e(fl,M6o),e(fl,pV),e(pV,E6o),e(fl,C6o),e(k,w6o),e(k,gl),e(gl,u1e),e(u1e,A6o),e(gl,L6o),e(gl,_V),e(_V,y6o),e(gl,x6o),e(gl,bV),e(bV,$6o),e(gl,k6o),e(k,S6o),e(k,hl),e(hl,p1e),e(p1e,R6o),e(hl,P6o),e(hl,vV),e(vV,B6o),e(hl,I6o),e(hl,FV),e(FV,N6o),e(hl,q6o),e(k,D6o),e(k,ap),e(ap,_1e),e(_1e,j6o),e(ap,G6o),e(ap,TV),e(TV,O6o),e(ap,V6o),e(k,X6o),e(k,ul),e(ul,b1e),e(b1e,z6o),e(ul,Q6o),e(ul,MV),e(MV,W6o),e(ul,U6o),e(ul,EV),e(EV,H6o),e(ul,J6o),e(k,Y6o),e(k,pl),e(pl,v1e),e(v1e,Z6o),e(pl,K6o),e(pl,CV),e(CV,e7o),e(pl,o7o),e(pl,wV),e(wV,r7o),e(pl,t7o),e(k,a7o),e(k,_l),e(_l,F1e),e(F1e,n7o),e(_l,s7o),e(_l,AV),e(AV,l7o),e(_l,i7o),e(_l,LV),e(LV,d7o),e(_l,m7o),e(k,c7o),e(k,np),e(np,T1e),e(T1e,f7o),e(np,g7o),e(np,yV),e(yV,h7o),e(np,u7o),e(k,p7o),e(k,sp),e(sp,M1e),e(M1e,_7o),e(sp,b7o),e(sp,xV),e(xV,v7o),e(sp,F7o),e(k,T7o),e(k,lp),e(lp,E1e),e(E1e,M7o),e(lp,E7o),e(lp,$V),e($V,C7o),e(lp,w7o),e(k,A7o),e(k,ip),e(ip,C1e),e(C1e,L7o),e(ip,y7o),e(ip,kV),e(kV,x7o),e(ip,$7o),e(k,k7o),e(k,bl),e(bl,w1e),e(w1e,S7o),e(bl,R7o),e(bl,SV),e(SV,P7o),e(bl,B7o),e(bl,RV),e(RV,I7o),e(bl,N7o),e(k,q7o),e(k,dp),e(dp,A1e),e(A1e,D7o),e(dp,j7o),e(dp,PV),e(PV,G7o),e(dp,O7o),e(k,V7o),e(k,vl),e(vl,L1e),e(L1e,X7o),e(vl,z7o),e(vl,BV),e(BV,Q7o),e(vl,W7o),e(vl,IV),e(IV,U7o),e(vl,H7o),e(k,J7o),e(k,Fl),e(Fl,y1e),e(y1e,Y7o),e(Fl,Z7o),e(Fl,NV),e(NV,K7o),e(Fl,e8o),e(Fl,qV),e(qV,o8o),e(Fl,r8o),e(k,t8o),e(k,Tl),e(Tl,x1e),e(x1e,a8o),e(Tl,n8o),e(Tl,DV),e(DV,s8o),e(Tl,l8o),e(Tl,jV),e(jV,i8o),e(Tl,d8o),e(k,m8o),e(k,Ml),e(Ml,$1e),e($1e,c8o),e(Ml,f8o),e(Ml,GV),e(GV,g8o),e(Ml,h8o),e(Ml,OV),e(OV,u8o),e(Ml,p8o),e(k,_8o),e(k,El),e(El,k1e),e(k1e,b8o),e(El,v8o),e(El,VV),e(VV,F8o),e(El,T8o),e(El,XV),e(XV,M8o),e(El,E8o),e(k,C8o),e(k,Cl),e(Cl,S1e),e(S1e,w8o),e(Cl,A8o),e(Cl,zV),e(zV,L8o),e(Cl,y8o),e(Cl,QV),e(QV,x8o),e(Cl,$8o),e(k,k8o),e(k,mp),e(mp,R1e),e(R1e,S8o),e(mp,R8o),e(mp,WV),e(WV,P8o),e(mp,B8o),e(k,I8o),e(k,cp),e(cp,P1e),e(P1e,N8o),e(cp,q8o),e(cp,UV),e(UV,D8o),e(cp,j8o),e(k,G8o),e(k,wl),e(wl,B1e),e(B1e,O8o),e(wl,V8o),e(wl,HV),e(HV,X8o),e(wl,z8o),e(wl,JV),e(JV,Q8o),e(wl,W8o),e(k,U8o),e(k,Al),e(Al,I1e),e(I1e,H8o),e(Al,J8o),e(Al,YV),e(YV,Y8o),e(Al,Z8o),e(Al,ZV),e(ZV,K8o),e(Al,eLo),e(k,oLo),e(k,Ll),e(Ll,N1e),e(N1e,rLo),e(Ll,tLo),e(Ll,KV),e(KV,aLo),e(Ll,nLo),e(Ll,eX),e(eX,sLo),e(Ll,lLo),e(k,iLo),e(k,fp),e(fp,q1e),e(q1e,dLo),e(fp,mLo),e(fp,oX),e(oX,cLo),e(fp,fLo),e(k,gLo),e(k,gp),e(gp,D1e),e(D1e,hLo),e(gp,uLo),e(gp,rX),e(rX,pLo),e(gp,_Lo),e(k,bLo),e(k,hp),e(hp,j1e),e(j1e,vLo),e(hp,FLo),e(hp,tX),e(tX,TLo),e(hp,MLo),e(k,ELo),e(k,yl),e(yl,G1e),e(G1e,CLo),e(yl,wLo),e(yl,aX),e(aX,ALo),e(yl,LLo),e(yl,nX),e(nX,yLo),e(yl,xLo),e(k,$Lo),e(k,xl),e(xl,O1e),e(O1e,kLo),e(xl,SLo),e(xl,sX),e(sX,RLo),e(xl,PLo),e(xl,lX),e(lX,BLo),e(xl,ILo),e(k,NLo),e(k,up),e(up,V1e),e(V1e,qLo),e(up,DLo),e(up,iX),e(iX,jLo),e(up,GLo),e(k,OLo),e(k,pp),e(pp,X1e),e(X1e,VLo),e(pp,XLo),e(pp,dX),e(dX,zLo),e(pp,QLo),e(k,WLo),e(k,_p),e(_p,z1e),e(z1e,ULo),e(_p,HLo),e(_p,mX),e(mX,JLo),e(_p,YLo),e(k,ZLo),e(k,bp),e(bp,Q1e),e(Q1e,KLo),e(bp,eyo),e(bp,cX),e(cX,oyo),e(bp,ryo),e(k,tyo),e(k,$l),e($l,W1e),e(W1e,ayo),e($l,nyo),e($l,fX),e(fX,syo),e($l,lyo),e($l,gX),e(gX,iyo),e($l,dyo),e(k,myo),e(k,kl),e(kl,U1e),e(U1e,cyo),e(kl,fyo),e(kl,hX),e(hX,gyo),e(kl,hyo),e(kl,uX),e(uX,uyo),e(kl,pyo),e(k,_yo),e(k,vp),e(vp,H1e),e(H1e,byo),e(vp,vyo),e(vp,pX),e(pX,Fyo),e(vp,Tyo),e(k,Myo),e(k,Fp),e(Fp,J1e),e(J1e,Eyo),e(Fp,Cyo),e(Fp,_X),e(_X,wyo),e(Fp,Ayo),e(k,Lyo),e(k,Sl),e(Sl,Y1e),e(Y1e,yyo),e(Sl,xyo),e(Sl,bX),e(bX,$yo),e(Sl,kyo),e(Sl,vX),e(vX,Syo),e(Sl,Ryo),e(k,Pyo),e(k,Rl),e(Rl,Z1e),e(Z1e,Byo),e(Rl,Iyo),e(Rl,FX),e(FX,Nyo),e(Rl,qyo),e(Rl,TX),e(TX,Dyo),e(Rl,jyo),e(k,Gyo),e(k,Pl),e(Pl,K1e),e(K1e,Oyo),e(Pl,Vyo),e(Pl,MX),e(MX,Xyo),e(Pl,zyo),e(Pl,EX),e(EX,Qyo),e(Pl,Wyo),e(k,Uyo),e(k,Bl),e(Bl,e2e),e(e2e,Hyo),e(Bl,Jyo),e(Bl,CX),e(CX,Yyo),e(Bl,Zyo),e(Bl,wX),e(wX,Kyo),e(Bl,e9o),e(Vr,o9o),M(Tp,Vr,null),e(Io,r9o),e(Io,Mp),M(Ck,Mp,null),e(Mp,t9o),e(Mp,o2e),e(o2e,a9o),b(c,Tlo,_),b(c,Nd,_),e(Nd,Ep),e(Ep,r2e),M(wk,r2e,null),e(Nd,n9o),e(Nd,t2e),e(t2e,s9o),b(c,Mlo,_),b(c,No,_),M(Ak,No,null),e(No,l9o),e(No,Lk),e(Lk,i9o),e(Lk,AX),e(AX,d9o),e(Lk,m9o),e(No,c9o),e(No,yk),e(yk,f9o),e(yk,a2e),e(a2e,g9o),e(yk,h9o),e(No,u9o),e(No,eo),M(xk,eo,null),e(eo,p9o),e(eo,n2e),e(n2e,_9o),e(eo,b9o),e(eo,mn),e(mn,v9o),e(mn,s2e),e(s2e,F9o),e(mn,T9o),e(mn,l2e),e(l2e,M9o),e(mn,E9o),e(mn,i2e),e(i2e,C9o),e(mn,w9o),e(eo,A9o),e(eo,z),e(z,Cp),e(Cp,d2e),e(d2e,L9o),e(Cp,y9o),e(Cp,LX),e(LX,x9o),e(Cp,$9o),e(z,k9o),e(z,wp),e(wp,m2e),e(m2e,S9o),e(wp,R9o),e(wp,yX),e(yX,P9o),e(wp,B9o),e(z,I9o),e(z,Ap),e(Ap,c2e),e(c2e,N9o),e(Ap,q9o),e(Ap,xX),e(xX,D9o),e(Ap,j9o),e(z,G9o),e(z,Lp),e(Lp,f2e),e(f2e,O9o),e(Lp,V9o),e(Lp,$X),e($X,X9o),e(Lp,z9o),e(z,Q9o),e(z,yp),e(yp,g2e),e(g2e,W9o),e(yp,U9o),e(yp,kX),e(kX,H9o),e(yp,J9o),e(z,Y9o),e(z,xp),e(xp,h2e),e(h2e,Z9o),e(xp,K9o),e(xp,SX),e(SX,exo),e(xp,oxo),e(z,rxo),e(z,$p),e($p,u2e),e(u2e,txo),e($p,axo),e($p,RX),e(RX,nxo),e($p,sxo),e(z,lxo),e(z,kp),e(kp,p2e),e(p2e,ixo),e(kp,dxo),e(kp,PX),e(PX,mxo),e(kp,cxo),e(z,fxo),e(z,Sp),e(Sp,_2e),e(_2e,gxo),e(Sp,hxo),e(Sp,BX),e(BX,uxo),e(Sp,pxo),e(z,_xo),e(z,Rp),e(Rp,b2e),e(b2e,bxo),e(Rp,vxo),e(Rp,IX),e(IX,Fxo),e(Rp,Txo),e(z,Mxo),e(z,Pp),e(Pp,v2e),e(v2e,Exo),e(Pp,Cxo),e(Pp,NX),e(NX,wxo),e(Pp,Axo),e(z,Lxo),e(z,Bp),e(Bp,F2e),e(F2e,yxo),e(Bp,xxo),e(Bp,qX),e(qX,$xo),e(Bp,kxo),e(z,Sxo),e(z,Ip),e(Ip,T2e),e(T2e,Rxo),e(Ip,Pxo),e(Ip,DX),e(DX,Bxo),e(Ip,Ixo),e(z,Nxo),e(z,Np),e(Np,M2e),e(M2e,qxo),e(Np,Dxo),e(Np,jX),e(jX,jxo),e(Np,Gxo),e(z,Oxo),e(z,qp),e(qp,E2e),e(E2e,Vxo),e(qp,Xxo),e(qp,GX),e(GX,zxo),e(qp,Qxo),e(z,Wxo),e(z,Dp),e(Dp,C2e),e(C2e,Uxo),e(Dp,Hxo),e(Dp,OX),e(OX,Jxo),e(Dp,Yxo),e(z,Zxo),e(z,jp),e(jp,w2e),e(w2e,Kxo),e(jp,e$o),e(jp,VX),e(VX,o$o),e(jp,r$o),e(z,t$o),e(z,Gp),e(Gp,A2e),e(A2e,a$o),e(Gp,n$o),e(Gp,XX),e(XX,s$o),e(Gp,l$o),e(z,i$o),e(z,Op),e(Op,L2e),e(L2e,d$o),e(Op,m$o),e(Op,zX),e(zX,c$o),e(Op,f$o),e(z,g$o),e(z,Vp),e(Vp,y2e),e(y2e,h$o),e(Vp,u$o),e(Vp,QX),e(QX,p$o),e(Vp,_$o),e(z,b$o),e(z,Xp),e(Xp,x2e),e(x2e,v$o),e(Xp,F$o),e(Xp,WX),e(WX,T$o),e(Xp,M$o),e(z,E$o),e(z,zp),e(zp,$2e),e($2e,C$o),e(zp,w$o),e(zp,UX),e(UX,A$o),e(zp,L$o),e(z,y$o),e(z,Qp),e(Qp,k2e),e(k2e,x$o),e(Qp,$$o),e(Qp,HX),e(HX,k$o),e(Qp,S$o),e(z,R$o),e(z,Wp),e(Wp,S2e),e(S2e,P$o),e(Wp,B$o),e(Wp,JX),e(JX,I$o),e(Wp,N$o),e(z,q$o),e(z,Up),e(Up,R2e),e(R2e,D$o),e(Up,j$o),e(Up,YX),e(YX,G$o),e(Up,O$o),e(z,V$o),e(z,Hp),e(Hp,P2e),e(P2e,X$o),e(Hp,z$o),e(Hp,ZX),e(ZX,Q$o),e(Hp,W$o),e(z,U$o),e(z,Jp),e(Jp,B2e),e(B2e,H$o),e(Jp,J$o),e(Jp,KX),e(KX,Y$o),e(Jp,Z$o),e(z,K$o),e(z,Yp),e(Yp,I2e),e(I2e,eko),e(Yp,oko),e(Yp,ez),e(ez,rko),e(Yp,tko),e(z,ako),e(z,Zp),e(Zp,N2e),e(N2e,nko),e(Zp,sko),e(Zp,oz),e(oz,lko),e(Zp,iko),e(z,dko),e(z,Kp),e(Kp,q2e),e(q2e,mko),e(Kp,cko),e(Kp,rz),e(rz,fko),e(Kp,gko),e(z,hko),e(z,e_),e(e_,D2e),e(D2e,uko),e(e_,pko),e(e_,tz),e(tz,_ko),e(e_,bko),e(z,vko),e(z,o_),e(o_,j2e),e(j2e,Fko),e(o_,Tko),e(o_,az),e(az,Mko),e(o_,Eko),e(z,Cko),e(z,r_),e(r_,G2e),e(G2e,wko),e(r_,Ako),e(r_,nz),e(nz,Lko),e(r_,yko),e(z,xko),e(z,t_),e(t_,O2e),e(O2e,$ko),e(t_,kko),e(t_,sz),e(sz,Sko),e(t_,Rko),e(z,Pko),e(z,a_),e(a_,V2e),e(V2e,Bko),e(a_,Iko),e(a_,lz),e(lz,Nko),e(a_,qko),e(z,Dko),e(z,n_),e(n_,X2e),e(X2e,jko),e(n_,Gko),e(n_,iz),e(iz,Oko),e(n_,Vko),e(z,Xko),e(z,s_),e(s_,z2e),e(z2e,zko),e(s_,Qko),e(s_,dz),e(dz,Wko),e(s_,Uko),e(z,Hko),e(z,l_),e(l_,Q2e),e(Q2e,Jko),e(l_,Yko),e(l_,mz),e(mz,Zko),e(l_,Kko),e(z,eSo),e(z,i_),e(i_,W2e),e(W2e,oSo),e(i_,rSo),e(i_,cz),e(cz,tSo),e(i_,aSo),e(z,nSo),e(z,d_),e(d_,U2e),e(U2e,sSo),e(d_,lSo),e(d_,fz),e(fz,iSo),e(d_,dSo),e(z,mSo),e(z,m_),e(m_,H2e),e(H2e,cSo),e(m_,fSo),e(m_,gz),e(gz,gSo),e(m_,hSo),e(z,uSo),e(z,c_),e(c_,J2e),e(J2e,pSo),e(c_,_So),e(c_,hz),e(hz,bSo),e(c_,vSo),e(z,FSo),e(z,f_),e(f_,Y2e),e(Y2e,TSo),e(f_,MSo),e(f_,uz),e(uz,ESo),e(f_,CSo),e(z,wSo),e(z,g_),e(g_,Z2e),e(Z2e,ASo),e(g_,LSo),e(g_,pz),e(pz,ySo),e(g_,xSo),e(z,$So),e(z,h_),e(h_,K2e),e(K2e,kSo),e(h_,SSo),e(h_,_z),e(_z,RSo),e(h_,PSo),e(eo,BSo),M(u_,eo,null),e(eo,ISo),M(p_,eo,null),e(No,NSo),e(No,__),M($k,__,null),e(__,qSo),e(__,ebe),e(ebe,DSo),b(c,Elo,_),b(c,qd,_),e(qd,b_),e(b_,obe),M(kk,obe,null),e(qd,jSo),e(qd,rbe),e(rbe,GSo),b(c,Clo,_),b(c,qo,_),M(Sk,qo,null),e(qo,OSo),e(qo,Rk),e(Rk,VSo),e(Rk,bz),e(bz,XSo),e(Rk,zSo),e(qo,QSo),e(qo,Pk),e(Pk,WSo),e(Pk,tbe),e(tbe,USo),e(Pk,HSo),e(qo,JSo),e(qo,oo),M(Bk,oo,null),e(oo,YSo),e(oo,abe),e(abe,ZSo),e(oo,KSo),e(oo,cn),e(cn,eRo),e(cn,nbe),e(nbe,oRo),e(cn,rRo),e(cn,sbe),e(sbe,tRo),e(cn,aRo),e(cn,lbe),e(lbe,nRo),e(cn,sRo),e(oo,lRo),e(oo,re),e(re,v_),e(v_,ibe),e(ibe,iRo),e(v_,dRo),e(v_,vz),e(vz,mRo),e(v_,cRo),e(re,fRo),e(re,F_),e(F_,dbe),e(dbe,gRo),e(F_,hRo),e(F_,Fz),e(Fz,uRo),e(F_,pRo),e(re,_Ro),e(re,T_),e(T_,mbe),e(mbe,bRo),e(T_,vRo),e(T_,Tz),e(Tz,FRo),e(T_,TRo),e(re,MRo),e(re,M_),e(M_,cbe),e(cbe,ERo),e(M_,CRo),e(M_,Mz),e(Mz,wRo),e(M_,ARo),e(re,LRo),e(re,E_),e(E_,fbe),e(fbe,yRo),e(E_,xRo),e(E_,Ez),e(Ez,$Ro),e(E_,kRo),e(re,SRo),e(re,C_),e(C_,gbe),e(gbe,RRo),e(C_,PRo),e(C_,Cz),e(Cz,BRo),e(C_,IRo),e(re,NRo),e(re,w_),e(w_,hbe),e(hbe,qRo),e(w_,DRo),e(w_,wz),e(wz,jRo),e(w_,GRo),e(re,ORo),e(re,A_),e(A_,ube),e(ube,VRo),e(A_,XRo),e(A_,Az),e(Az,zRo),e(A_,QRo),e(re,WRo),e(re,L_),e(L_,pbe),e(pbe,URo),e(L_,HRo),e(L_,Lz),e(Lz,JRo),e(L_,YRo),e(re,ZRo),e(re,y_),e(y_,_be),e(_be,KRo),e(y_,ePo),e(y_,yz),e(yz,oPo),e(y_,rPo),e(re,tPo),e(re,x_),e(x_,bbe),e(bbe,aPo),e(x_,nPo),e(x_,xz),e(xz,sPo),e(x_,lPo),e(re,iPo),e(re,$_),e($_,vbe),e(vbe,dPo),e($_,mPo),e($_,$z),e($z,cPo),e($_,fPo),e(re,gPo),e(re,k_),e(k_,Fbe),e(Fbe,hPo),e(k_,uPo),e(k_,kz),e(kz,pPo),e(k_,_Po),e(re,bPo),e(re,S_),e(S_,Tbe),e(Tbe,vPo),e(S_,FPo),e(S_,Sz),e(Sz,TPo),e(S_,MPo),e(re,EPo),e(re,R_),e(R_,Mbe),e(Mbe,CPo),e(R_,wPo),e(R_,Rz),e(Rz,APo),e(R_,LPo),e(re,yPo),e(re,P_),e(P_,Ebe),e(Ebe,xPo),e(P_,$Po),e(P_,Pz),e(Pz,kPo),e(P_,SPo),e(re,RPo),e(re,B_),e(B_,Cbe),e(Cbe,PPo),e(B_,BPo),e(B_,Bz),e(Bz,IPo),e(B_,NPo),e(re,qPo),e(re,I_),e(I_,wbe),e(wbe,DPo),e(I_,jPo),e(I_,Iz),e(Iz,GPo),e(I_,OPo),e(re,VPo),e(re,N_),e(N_,Abe),e(Abe,XPo),e(N_,zPo),e(N_,Nz),e(Nz,QPo),e(N_,WPo),e(re,UPo),e(re,q_),e(q_,Lbe),e(Lbe,HPo),e(q_,JPo),e(q_,qz),e(qz,YPo),e(q_,ZPo),e(re,KPo),e(re,D_),e(D_,ybe),e(ybe,eBo),e(D_,oBo),e(D_,Dz),e(Dz,rBo),e(D_,tBo),e(re,aBo),e(re,j_),e(j_,xbe),e(xbe,nBo),e(j_,sBo),e(j_,jz),e(jz,lBo),e(j_,iBo),e(re,dBo),e(re,G_),e(G_,$be),e($be,mBo),e(G_,cBo),e(G_,Gz),e(Gz,fBo),e(G_,gBo),e(re,hBo),e(re,O_),e(O_,kbe),e(kbe,uBo),e(O_,pBo),e(O_,Oz),e(Oz,_Bo),e(O_,bBo),e(re,vBo),e(re,V_),e(V_,Sbe),e(Sbe,FBo),e(V_,TBo),e(V_,Vz),e(Vz,MBo),e(V_,EBo),e(re,CBo),e(re,X_),e(X_,Rbe),e(Rbe,wBo),e(X_,ABo),e(X_,Xz),e(Xz,LBo),e(X_,yBo),e(re,xBo),e(re,z_),e(z_,Pbe),e(Pbe,$Bo),e(z_,kBo),e(z_,zz),e(zz,SBo),e(z_,RBo),e(re,PBo),e(re,Q_),e(Q_,Bbe),e(Bbe,BBo),e(Q_,IBo),e(Q_,Qz),e(Qz,NBo),e(Q_,qBo),e(re,DBo),e(re,W_),e(W_,Ibe),e(Ibe,jBo),e(W_,GBo),e(W_,Wz),e(Wz,OBo),e(W_,VBo),e(oo,XBo),M(U_,oo,null),e(oo,zBo),M(H_,oo,null),e(qo,QBo),e(qo,J_),M(Ik,J_,null),e(J_,WBo),e(J_,Nbe),e(Nbe,UBo),b(c,wlo,_),b(c,Dd,_),e(Dd,Y_),e(Y_,qbe),M(Nk,qbe,null),e(Dd,HBo),e(Dd,Dbe),e(Dbe,JBo),b(c,Alo,_),b(c,Do,_),M(qk,Do,null),e(Do,YBo),e(Do,Dk),e(Dk,ZBo),e(Dk,Uz),e(Uz,KBo),e(Dk,eIo),e(Do,oIo),e(Do,jk),e(jk,rIo),e(jk,jbe),e(jbe,tIo),e(jk,aIo),e(Do,nIo),e(Do,ro),M(Gk,ro,null),e(ro,sIo),e(ro,Gbe),e(Gbe,lIo),e(ro,iIo),e(ro,jd),e(jd,dIo),e(jd,Obe),e(Obe,mIo),e(jd,cIo),e(jd,Vbe),e(Vbe,fIo),e(jd,gIo),e(ro,hIo),e(ro,ie),e(ie,Z_),e(Z_,Xbe),e(Xbe,uIo),e(Z_,pIo),e(Z_,Hz),e(Hz,_Io),e(Z_,bIo),e(ie,vIo),e(ie,K_),e(K_,zbe),e(zbe,FIo),e(K_,TIo),e(K_,Jz),e(Jz,MIo),e(K_,EIo),e(ie,CIo),e(ie,e1),e(e1,Qbe),e(Qbe,wIo),e(e1,AIo),e(e1,Yz),e(Yz,LIo),e(e1,yIo),e(ie,xIo),e(ie,o1),e(o1,Wbe),e(Wbe,$Io),e(o1,kIo),e(o1,Zz),e(Zz,SIo),e(o1,RIo),e(ie,PIo),e(ie,r1),e(r1,Ube),e(Ube,BIo),e(r1,IIo),e(r1,Kz),e(Kz,NIo),e(r1,qIo),e(ie,DIo),e(ie,t1),e(t1,Hbe),e(Hbe,jIo),e(t1,GIo),e(t1,eQ),e(eQ,OIo),e(t1,VIo),e(ie,XIo),e(ie,a1),e(a1,Jbe),e(Jbe,zIo),e(a1,QIo),e(a1,oQ),e(oQ,WIo),e(a1,UIo),e(ie,HIo),e(ie,n1),e(n1,Ybe),e(Ybe,JIo),e(n1,YIo),e(n1,rQ),e(rQ,ZIo),e(n1,KIo),e(ie,eNo),e(ie,s1),e(s1,Zbe),e(Zbe,oNo),e(s1,rNo),e(s1,tQ),e(tQ,tNo),e(s1,aNo),e(ie,nNo),e(ie,l1),e(l1,Kbe),e(Kbe,sNo),e(l1,lNo),e(l1,aQ),e(aQ,iNo),e(l1,dNo),e(ie,mNo),e(ie,i1),e(i1,eve),e(eve,cNo),e(i1,fNo),e(i1,nQ),e(nQ,gNo),e(i1,hNo),e(ie,uNo),e(ie,d1),e(d1,ove),e(ove,pNo),e(d1,_No),e(d1,sQ),e(sQ,bNo),e(d1,vNo),e(ie,FNo),e(ie,m1),e(m1,rve),e(rve,TNo),e(m1,MNo),e(m1,lQ),e(lQ,ENo),e(m1,CNo),e(ie,wNo),e(ie,c1),e(c1,tve),e(tve,ANo),e(c1,LNo),e(c1,iQ),e(iQ,yNo),e(c1,xNo),e(ie,$No),e(ie,f1),e(f1,ave),e(ave,kNo),e(f1,SNo),e(f1,dQ),e(dQ,RNo),e(f1,PNo),e(ie,BNo),e(ie,g1),e(g1,nve),e(nve,INo),e(g1,NNo),e(g1,mQ),e(mQ,qNo),e(g1,DNo),e(ie,jNo),e(ie,h1),e(h1,sve),e(sve,GNo),e(h1,ONo),e(h1,cQ),e(cQ,VNo),e(h1,XNo),e(ie,zNo),e(ie,u1),e(u1,lve),e(lve,QNo),e(u1,WNo),e(u1,fQ),e(fQ,UNo),e(u1,HNo),e(ie,JNo),e(ie,p1),e(p1,ive),e(ive,YNo),e(p1,ZNo),e(p1,gQ),e(gQ,KNo),e(p1,eqo),e(ie,oqo),e(ie,_1),e(_1,dve),e(dve,rqo),e(_1,tqo),e(_1,hQ),e(hQ,aqo),e(_1,nqo),e(ie,sqo),e(ie,b1),e(b1,mve),e(mve,lqo),e(b1,iqo),e(b1,uQ),e(uQ,dqo),e(b1,mqo),e(ie,cqo),e(ie,v1),e(v1,cve),e(cve,fqo),e(v1,gqo),e(v1,pQ),e(pQ,hqo),e(v1,uqo),e(ie,pqo),e(ie,F1),e(F1,fve),e(fve,_qo),e(F1,bqo),e(F1,_Q),e(_Q,vqo),e(F1,Fqo),e(ro,Tqo),M(T1,ro,null),e(ro,Mqo),M(M1,ro,null),e(Do,Eqo),e(Do,E1),M(Ok,E1,null),e(E1,Cqo),e(E1,gve),e(gve,wqo),b(c,Llo,_),b(c,Gd,_),e(Gd,C1),e(C1,hve),M(Vk,hve,null),e(Gd,Aqo),e(Gd,uve),e(uve,Lqo),b(c,ylo,_),b(c,jo,_),M(Xk,jo,null),e(jo,yqo),e(jo,Od),e(Od,xqo),e(Od,bQ),e(bQ,$qo),e(Od,kqo),e(Od,vQ),e(vQ,Sqo),e(Od,Rqo),e(jo,Pqo),e(jo,zk),e(zk,Bqo),e(zk,pve),e(pve,Iqo),e(zk,Nqo),e(jo,qqo),e(jo,At),M(Qk,At,null),e(At,Dqo),e(At,_ve),e(_ve,jqo),e(At,Gqo),e(At,Vd),e(Vd,Oqo),e(Vd,bve),e(bve,Vqo),e(Vd,Xqo),e(Vd,FQ),e(FQ,zqo),e(Vd,Qqo),e(At,Wqo),M(w1,At,null),e(jo,Uqo),e(jo,to),M(Wk,to,null),e(to,Hqo),e(to,vve),e(vve,Jqo),e(to,Yqo),e(to,fn),e(fn,Zqo),e(fn,Fve),e(Fve,Kqo),e(fn,eDo),e(fn,Tve),e(Tve,oDo),e(fn,rDo),e(fn,Mve),e(Mve,tDo),e(fn,aDo),e(to,nDo),e(to,y),e(y,A1),e(A1,Eve),e(Eve,sDo),e(A1,lDo),e(A1,TQ),e(TQ,iDo),e(A1,dDo),e(y,mDo),e(y,L1),e(L1,Cve),e(Cve,cDo),e(L1,fDo),e(L1,MQ),e(MQ,gDo),e(L1,hDo),e(y,uDo),e(y,y1),e(y1,wve),e(wve,pDo),e(y1,_Do),e(y1,EQ),e(EQ,bDo),e(y1,vDo),e(y,FDo),e(y,x1),e(x1,Ave),e(Ave,TDo),e(x1,MDo),e(x1,CQ),e(CQ,EDo),e(x1,CDo),e(y,wDo),e(y,$1),e($1,Lve),e(Lve,ADo),e($1,LDo),e($1,wQ),e(wQ,yDo),e($1,xDo),e(y,$Do),e(y,k1),e(k1,yve),e(yve,kDo),e(k1,SDo),e(k1,AQ),e(AQ,RDo),e(k1,PDo),e(y,BDo),e(y,S1),e(S1,xve),e(xve,IDo),e(S1,NDo),e(S1,LQ),e(LQ,qDo),e(S1,DDo),e(y,jDo),e(y,R1),e(R1,$ve),e($ve,GDo),e(R1,ODo),e(R1,yQ),e(yQ,VDo),e(R1,XDo),e(y,zDo),e(y,P1),e(P1,kve),e(kve,QDo),e(P1,WDo),e(P1,xQ),e(xQ,UDo),e(P1,HDo),e(y,JDo),e(y,B1),e(B1,Sve),e(Sve,YDo),e(B1,ZDo),e(B1,$Q),e($Q,KDo),e(B1,ejo),e(y,ojo),e(y,I1),e(I1,Rve),e(Rve,rjo),e(I1,tjo),e(I1,kQ),e(kQ,ajo),e(I1,njo),e(y,sjo),e(y,N1),e(N1,Pve),e(Pve,ljo),e(N1,ijo),e(N1,SQ),e(SQ,djo),e(N1,mjo),e(y,cjo),e(y,q1),e(q1,Bve),e(Bve,fjo),e(q1,gjo),e(q1,RQ),e(RQ,hjo),e(q1,ujo),e(y,pjo),e(y,D1),e(D1,Ive),e(Ive,_jo),e(D1,bjo),e(D1,PQ),e(PQ,vjo),e(D1,Fjo),e(y,Tjo),e(y,j1),e(j1,Nve),e(Nve,Mjo),e(j1,Ejo),e(j1,BQ),e(BQ,Cjo),e(j1,wjo),e(y,Ajo),e(y,G1),e(G1,qve),e(qve,Ljo),e(G1,yjo),e(G1,IQ),e(IQ,xjo),e(G1,$jo),e(y,kjo),e(y,O1),e(O1,Dve),e(Dve,Sjo),e(O1,Rjo),e(O1,NQ),e(NQ,Pjo),e(O1,Bjo),e(y,Ijo),e(y,V1),e(V1,jve),e(jve,Njo),e(V1,qjo),e(V1,qQ),e(qQ,Djo),e(V1,jjo),e(y,Gjo),e(y,X1),e(X1,Gve),e(Gve,Ojo),e(X1,Vjo),e(X1,DQ),e(DQ,Xjo),e(X1,zjo),e(y,Qjo),e(y,z1),e(z1,Ove),e(Ove,Wjo),e(z1,Ujo),e(z1,jQ),e(jQ,Hjo),e(z1,Jjo),e(y,Yjo),e(y,Q1),e(Q1,Vve),e(Vve,Zjo),e(Q1,Kjo),e(Q1,GQ),e(GQ,eGo),e(Q1,oGo),e(y,rGo),e(y,W1),e(W1,Xve),e(Xve,tGo),e(W1,aGo),e(W1,OQ),e(OQ,nGo),e(W1,sGo),e(y,lGo),e(y,U1),e(U1,zve),e(zve,iGo),e(U1,dGo),e(U1,VQ),e(VQ,mGo),e(U1,cGo),e(y,fGo),e(y,H1),e(H1,Qve),e(Qve,gGo),e(H1,hGo),e(H1,XQ),e(XQ,uGo),e(H1,pGo),e(y,_Go),e(y,J1),e(J1,Wve),e(Wve,bGo),e(J1,vGo),e(J1,zQ),e(zQ,FGo),e(J1,TGo),e(y,MGo),e(y,Y1),e(Y1,Uve),e(Uve,EGo),e(Y1,CGo),e(Y1,QQ),e(QQ,wGo),e(Y1,AGo),e(y,LGo),e(y,Z1),e(Z1,Hve),e(Hve,yGo),e(Z1,xGo),e(Z1,WQ),e(WQ,$Go),e(Z1,kGo),e(y,SGo),e(y,K1),e(K1,Jve),e(Jve,RGo),e(K1,PGo),e(K1,UQ),e(UQ,BGo),e(K1,IGo),e(y,NGo),e(y,e2),e(e2,Yve),e(Yve,qGo),e(e2,DGo),e(e2,HQ),e(HQ,jGo),e(e2,GGo),e(y,OGo),e(y,o2),e(o2,Zve),e(Zve,VGo),e(o2,XGo),e(o2,JQ),e(JQ,zGo),e(o2,QGo),e(y,WGo),e(y,r2),e(r2,Kve),e(Kve,UGo),e(r2,HGo),e(r2,YQ),e(YQ,JGo),e(r2,YGo),e(y,ZGo),e(y,t2),e(t2,eFe),e(eFe,KGo),e(t2,eOo),e(t2,ZQ),e(ZQ,oOo),e(t2,rOo),e(y,tOo),e(y,a2),e(a2,oFe),e(oFe,aOo),e(a2,nOo),e(a2,KQ),e(KQ,sOo),e(a2,lOo),e(y,iOo),e(y,n2),e(n2,rFe),e(rFe,dOo),e(n2,mOo),e(n2,eW),e(eW,cOo),e(n2,fOo),e(y,gOo),e(y,s2),e(s2,tFe),e(tFe,hOo),e(s2,uOo),e(s2,oW),e(oW,pOo),e(s2,_Oo),e(y,bOo),e(y,l2),e(l2,aFe),e(aFe,vOo),e(l2,FOo),e(l2,rW),e(rW,TOo),e(l2,MOo),e(y,EOo),e(y,i2),e(i2,nFe),e(nFe,COo),e(i2,wOo),e(i2,tW),e(tW,AOo),e(i2,LOo),e(y,yOo),e(y,d2),e(d2,sFe),e(sFe,xOo),e(d2,$Oo),e(d2,aW),e(aW,kOo),e(d2,SOo),e(y,ROo),e(y,m2),e(m2,lFe),e(lFe,POo),e(m2,BOo),e(m2,nW),e(nW,IOo),e(m2,NOo),e(y,qOo),e(y,c2),e(c2,iFe),e(iFe,DOo),e(c2,jOo),e(c2,sW),e(sW,GOo),e(c2,OOo),e(y,VOo),e(y,Il),e(Il,dFe),e(dFe,XOo),e(Il,zOo),e(Il,lW),e(lW,QOo),e(Il,WOo),e(Il,iW),e(iW,UOo),e(Il,HOo),e(y,JOo),e(y,f2),e(f2,mFe),e(mFe,YOo),e(f2,ZOo),e(f2,dW),e(dW,KOo),e(f2,eVo),e(y,oVo),e(y,g2),e(g2,cFe),e(cFe,rVo),e(g2,tVo),e(g2,mW),e(mW,aVo),e(g2,nVo),e(y,sVo),e(y,h2),e(h2,fFe),e(fFe,lVo),e(h2,iVo),e(h2,cW),e(cW,dVo),e(h2,mVo),e(y,cVo),e(y,u2),e(u2,gFe),e(gFe,fVo),e(u2,gVo),e(u2,fW),e(fW,hVo),e(u2,uVo),e(y,pVo),e(y,p2),e(p2,hFe),e(hFe,_Vo),e(p2,bVo),e(p2,gW),e(gW,vVo),e(p2,FVo),e(y,TVo),e(y,_2),e(_2,uFe),e(uFe,MVo),e(_2,EVo),e(_2,hW),e(hW,CVo),e(_2,wVo),e(y,AVo),e(y,b2),e(b2,pFe),e(pFe,LVo),e(b2,yVo),e(b2,uW),e(uW,xVo),e(b2,$Vo),e(y,kVo),e(y,v2),e(v2,_Fe),e(_Fe,SVo),e(v2,RVo),e(v2,pW),e(pW,PVo),e(v2,BVo),e(y,IVo),e(y,F2),e(F2,bFe),e(bFe,NVo),e(F2,qVo),e(F2,_W),e(_W,DVo),e(F2,jVo),e(y,GVo),e(y,T2),e(T2,vFe),e(vFe,OVo),e(T2,VVo),e(T2,bW),e(bW,XVo),e(T2,zVo),e(y,QVo),e(y,M2),e(M2,FFe),e(FFe,WVo),e(M2,UVo),e(M2,vW),e(vW,HVo),e(M2,JVo),e(y,YVo),e(y,E2),e(E2,TFe),e(TFe,ZVo),e(E2,KVo),e(E2,FW),e(FW,eXo),e(E2,oXo),e(y,rXo),e(y,C2),e(C2,MFe),e(MFe,tXo),e(C2,aXo),e(C2,TW),e(TW,nXo),e(C2,sXo),e(y,lXo),e(y,w2),e(w2,EFe),e(EFe,iXo),e(w2,dXo),e(w2,MW),e(MW,mXo),e(w2,cXo),e(y,fXo),e(y,A2),e(A2,CFe),e(CFe,gXo),e(A2,hXo),e(A2,EW),e(EW,uXo),e(A2,pXo),e(y,_Xo),e(y,L2),e(L2,wFe),e(wFe,bXo),e(L2,vXo),e(L2,CW),e(CW,FXo),e(L2,TXo),e(y,MXo),e(y,y2),e(y2,AFe),e(AFe,EXo),e(y2,CXo),e(y2,wW),e(wW,wXo),e(y2,AXo),e(y,LXo),e(y,x2),e(x2,LFe),e(LFe,yXo),e(x2,xXo),e(x2,AW),e(AW,$Xo),e(x2,kXo),e(y,SXo),e(y,$2),e($2,yFe),e(yFe,RXo),e($2,PXo),e($2,LW),e(LW,BXo),e($2,IXo),e(y,NXo),e(y,k2),e(k2,xFe),e(xFe,qXo),e(k2,DXo),e(k2,yW),e(yW,jXo),e(k2,GXo),e(y,OXo),e(y,S2),e(S2,$Fe),e($Fe,VXo),e(S2,XXo),e(S2,xW),e(xW,zXo),e(S2,QXo),e(y,WXo),e(y,R2),e(R2,kFe),e(kFe,UXo),e(R2,HXo),e(R2,$W),e($W,JXo),e(R2,YXo),e(y,ZXo),e(y,P2),e(P2,SFe),e(SFe,KXo),e(P2,ezo),e(P2,kW),e(kW,ozo),e(P2,rzo),e(y,tzo),e(y,B2),e(B2,RFe),e(RFe,azo),e(B2,nzo),e(B2,SW),e(SW,szo),e(B2,lzo),e(y,izo),e(y,I2),e(I2,PFe),e(PFe,dzo),e(I2,mzo),e(I2,RW),e(RW,czo),e(I2,fzo),e(y,gzo),e(y,N2),e(N2,BFe),e(BFe,hzo),e(N2,uzo),e(N2,PW),e(PW,pzo),e(N2,_zo),e(y,bzo),e(y,q2),e(q2,IFe),e(IFe,vzo),e(q2,Fzo),e(q2,BW),e(BW,Tzo),e(q2,Mzo),e(y,Ezo),e(y,D2),e(D2,NFe),e(NFe,Czo),e(D2,wzo),e(D2,IW),e(IW,Azo),e(D2,Lzo),e(y,yzo),e(y,j2),e(j2,qFe),e(qFe,xzo),e(j2,$zo),e(j2,NW),e(NW,kzo),e(j2,Szo),e(y,Rzo),e(y,G2),e(G2,DFe),e(DFe,Pzo),e(G2,Bzo),e(G2,qW),e(qW,Izo),e(G2,Nzo),e(y,qzo),e(y,O2),e(O2,jFe),e(jFe,Dzo),e(O2,jzo),e(O2,DW),e(DW,Gzo),e(O2,Ozo),e(y,Vzo),e(y,V2),e(V2,GFe),e(GFe,Xzo),e(V2,zzo),e(V2,jW),e(jW,Qzo),e(V2,Wzo),e(y,Uzo),e(y,X2),e(X2,OFe),e(OFe,Hzo),e(X2,Jzo),e(X2,GW),e(GW,Yzo),e(X2,Zzo),e(y,Kzo),e(y,z2),e(z2,VFe),e(VFe,eQo),e(z2,oQo),e(z2,OW),e(OW,rQo),e(z2,tQo),e(y,aQo),e(y,Q2),e(Q2,XFe),e(XFe,nQo),e(Q2,sQo),e(Q2,VW),e(VW,lQo),e(Q2,iQo),e(y,dQo),e(y,W2),e(W2,zFe),e(zFe,mQo),e(W2,cQo),e(W2,XW),e(XW,fQo),e(W2,gQo),e(y,hQo),e(y,U2),e(U2,QFe),e(QFe,uQo),e(U2,pQo),e(U2,zW),e(zW,_Qo),e(U2,bQo),e(y,vQo),e(y,H2),e(H2,WFe),e(WFe,FQo),e(H2,TQo),e(H2,QW),e(QW,MQo),e(H2,EQo),e(y,CQo),e(y,J2),e(J2,UFe),e(UFe,wQo),e(J2,AQo),e(J2,WW),e(WW,LQo),e(J2,yQo),e(y,xQo),e(y,Y2),e(Y2,HFe),e(HFe,$Qo),e(Y2,kQo),e(Y2,UW),e(UW,SQo),e(Y2,RQo),e(y,PQo),e(y,Z2),e(Z2,JFe),e(JFe,BQo),e(Z2,IQo),e(Z2,HW),e(HW,NQo),e(Z2,qQo),e(y,DQo),e(y,K2),e(K2,YFe),e(YFe,jQo),e(K2,GQo),e(K2,JW),e(JW,OQo),e(K2,VQo),e(y,XQo),e(y,eb),e(eb,ZFe),e(ZFe,zQo),e(eb,QQo),e(eb,YW),e(YW,WQo),e(eb,UQo),e(y,HQo),e(y,ob),e(ob,KFe),e(KFe,JQo),e(ob,YQo),e(ob,ZW),e(ZW,ZQo),e(ob,KQo),e(y,eWo),e(y,rb),e(rb,eTe),e(eTe,oWo),e(rb,rWo),e(rb,KW),e(KW,tWo),e(rb,aWo),e(y,nWo),e(y,tb),e(tb,oTe),e(oTe,sWo),e(tb,lWo),e(tb,eU),e(eU,iWo),e(tb,dWo),e(y,mWo),e(y,ab),e(ab,rTe),e(rTe,cWo),e(ab,fWo),e(ab,oU),e(oU,gWo),e(ab,hWo),e(y,uWo),e(y,nb),e(nb,tTe),e(tTe,pWo),e(nb,_Wo),e(nb,rU),e(rU,bWo),e(nb,vWo),e(y,FWo),e(y,sb),e(sb,aTe),e(aTe,TWo),e(sb,MWo),e(sb,tU),e(tU,EWo),e(sb,CWo),e(y,wWo),e(y,lb),e(lb,nTe),e(nTe,AWo),e(lb,LWo),e(lb,aU),e(aU,yWo),e(lb,xWo),e(y,$Wo),e(y,ib),e(ib,sTe),e(sTe,kWo),e(ib,SWo),e(ib,nU),e(nU,RWo),e(ib,PWo),e(y,BWo),e(y,db),e(db,lTe),e(lTe,IWo),e(db,NWo),e(db,sU),e(sU,qWo),e(db,DWo),e(y,jWo),e(y,mb),e(mb,iTe),e(iTe,GWo),e(mb,OWo),e(mb,lU),e(lU,VWo),e(mb,XWo),e(y,zWo),e(y,cb),e(cb,dTe),e(dTe,QWo),e(cb,WWo),e(cb,iU),e(iU,UWo),e(cb,HWo),e(y,JWo),e(y,fb),e(fb,mTe),e(mTe,YWo),e(fb,ZWo),e(fb,dU),e(dU,KWo),e(fb,eUo),e(y,oUo),e(y,gb),e(gb,cTe),e(cTe,rUo),e(gb,tUo),e(gb,mU),e(mU,aUo),e(gb,nUo),e(y,sUo),e(y,hb),e(hb,fTe),e(fTe,lUo),e(hb,iUo),e(hb,cU),e(cU,dUo),e(hb,mUo),e(y,cUo),e(y,ub),e(ub,gTe),e(gTe,fUo),e(ub,gUo),e(ub,fU),e(fU,hUo),e(ub,uUo),e(y,pUo),e(y,pb),e(pb,hTe),e(hTe,_Uo),e(pb,bUo),e(pb,gU),e(gU,vUo),e(pb,FUo),e(y,TUo),e(y,_b),e(_b,uTe),e(uTe,MUo),e(_b,EUo),e(_b,hU),e(hU,CUo),e(_b,wUo),e(y,AUo),e(y,bb),e(bb,pTe),e(pTe,LUo),e(bb,yUo),e(bb,uU),e(uU,xUo),e(bb,$Uo),e(y,kUo),e(y,vb),e(vb,_Te),e(_Te,SUo),e(vb,RUo),e(vb,pU),e(pU,PUo),e(vb,BUo),e(y,IUo),e(y,Fb),e(Fb,bTe),e(bTe,NUo),e(Fb,qUo),e(Fb,_U),e(_U,DUo),e(Fb,jUo),e(y,GUo),e(y,Tb),e(Tb,vTe),e(vTe,OUo),e(Tb,VUo),e(Tb,bU),e(bU,XUo),e(Tb,zUo),e(y,QUo),e(y,Mb),e(Mb,FTe),e(FTe,WUo),e(Mb,UUo),e(Mb,vU),e(vU,HUo),e(Mb,JUo),e(y,YUo),e(y,Eb),e(Eb,TTe),e(TTe,ZUo),e(Eb,KUo),e(Eb,FU),e(FU,eHo),e(Eb,oHo),e(y,rHo),e(y,Cb),e(Cb,MTe),e(MTe,tHo),e(Cb,aHo),e(Cb,TU),e(TU,nHo),e(Cb,sHo),e(y,lHo),e(y,wb),e(wb,ETe),e(ETe,iHo),e(wb,dHo),e(wb,MU),e(MU,mHo),e(wb,cHo),e(y,fHo),e(y,Ab),e(Ab,CTe),e(CTe,gHo),e(Ab,hHo),e(Ab,EU),e(EU,uHo),e(Ab,pHo),e(y,_Ho),e(y,Lb),e(Lb,wTe),e(wTe,bHo),e(Lb,vHo),e(Lb,CU),e(CU,FHo),e(Lb,THo),e(y,MHo),e(y,yb),e(yb,ATe),e(ATe,EHo),e(yb,CHo),e(yb,wU),e(wU,wHo),e(yb,AHo),e(y,LHo),e(y,xb),e(xb,LTe),e(LTe,yHo),e(xb,xHo),e(xb,AU),e(AU,$Ho),e(xb,kHo),e(y,SHo),e(y,$b),e($b,yTe),e(yTe,RHo),e($b,PHo),e($b,LU),e(LU,BHo),e($b,IHo),e(y,NHo),e(y,kb),e(kb,xTe),e(xTe,qHo),e(kb,DHo),e(kb,yU),e(yU,jHo),e(kb,GHo),e(y,OHo),e(y,Sb),e(Sb,$Te),e($Te,VHo),e(Sb,XHo),e(Sb,xU),e(xU,zHo),e(Sb,QHo),e(y,WHo),e(y,Rb),e(Rb,kTe),e(kTe,UHo),e(Rb,HHo),e(Rb,$U),e($U,JHo),e(Rb,YHo),e(y,ZHo),e(y,Pb),e(Pb,STe),e(STe,KHo),e(Pb,eJo),e(Pb,kU),e(kU,oJo),e(Pb,rJo),e(y,tJo),e(y,Bb),e(Bb,RTe),e(RTe,aJo),e(Bb,nJo),e(Bb,SU),e(SU,sJo),e(Bb,lJo),e(y,iJo),e(y,Ib),e(Ib,PTe),e(PTe,dJo),e(Ib,mJo),e(Ib,RU),e(RU,cJo),e(Ib,fJo),e(y,gJo),e(y,Nb),e(Nb,BTe),e(BTe,hJo),e(Nb,uJo),e(Nb,PU),e(PU,pJo),e(Nb,_Jo),e(y,bJo),e(y,qb),e(qb,ITe),e(ITe,vJo),e(qb,FJo),e(qb,BU),e(BU,TJo),e(qb,MJo),e(y,EJo),e(y,Db),e(Db,NTe),e(NTe,CJo),e(Db,wJo),e(Db,IU),e(IU,AJo),e(Db,LJo),e(y,yJo),e(y,jb),e(jb,qTe),e(qTe,xJo),e(jb,$Jo),e(jb,NU),e(NU,kJo),e(jb,SJo),e(y,RJo),e(y,Gb),e(Gb,DTe),e(DTe,PJo),e(Gb,BJo),e(Gb,qU),e(qU,IJo),e(Gb,NJo),e(y,qJo),e(y,Ob),e(Ob,jTe),e(jTe,DJo),e(Ob,jJo),e(Ob,DU),e(DU,GJo),e(Ob,OJo),e(y,VJo),e(y,Vb),e(Vb,GTe),e(GTe,XJo),e(Vb,zJo),e(Vb,jU),e(jU,QJo),e(Vb,WJo),e(y,UJo),e(y,Xb),e(Xb,OTe),e(OTe,HJo),e(Xb,JJo),e(Xb,GU),e(GU,YJo),e(Xb,ZJo),e(y,KJo),e(y,zb),e(zb,VTe),e(VTe,eYo),e(zb,oYo),e(zb,OU),e(OU,rYo),e(zb,tYo),e(y,aYo),e(y,Qb),e(Qb,XTe),e(XTe,nYo),e(Qb,sYo),e(Qb,VU),e(VU,lYo),e(Qb,iYo),e(y,dYo),e(y,Wb),e(Wb,zTe),e(zTe,mYo),e(Wb,cYo),e(Wb,XU),e(XU,fYo),e(Wb,gYo),e(to,hYo),e(to,Ub),e(Ub,uYo),e(Ub,QTe),e(QTe,pYo),e(Ub,_Yo),e(Ub,WTe),e(WTe,bYo),e(to,vYo),M(Hb,to,null),b(c,xlo,_),b(c,Xd,_),e(Xd,Jb),e(Jb,UTe),M(Uk,UTe,null),e(Xd,FYo),e(Xd,HTe),e(HTe,TYo),b(c,$lo,_),b(c,Go,_),M(Hk,Go,null),e(Go,MYo),e(Go,zd),e(zd,EYo),e(zd,zU),e(zU,CYo),e(zd,wYo),e(zd,QU),e(QU,AYo),e(zd,LYo),e(Go,yYo),e(Go,Jk),e(Jk,xYo),e(Jk,JTe),e(JTe,$Yo),e(Jk,kYo),e(Go,SYo),e(Go,Lt),M(Yk,Lt,null),e(Lt,RYo),e(Lt,YTe),e(YTe,PYo),e(Lt,BYo),e(Lt,Qd),e(Qd,IYo),e(Qd,ZTe),e(ZTe,NYo),e(Qd,qYo),e(Qd,WU),e(WU,DYo),e(Qd,jYo),e(Lt,GYo),M(Yb,Lt,null),e(Go,OYo),e(Go,ao),M(Zk,ao,null),e(ao,VYo),e(ao,KTe),e(KTe,XYo),e(ao,zYo),e(ao,gn),e(gn,QYo),e(gn,eMe),e(eMe,WYo),e(gn,UYo),e(gn,oMe),e(oMe,HYo),e(gn,JYo),e(gn,rMe),e(rMe,YYo),e(gn,ZYo),e(ao,KYo),e(ao,G),e(G,Zb),e(Zb,tMe),e(tMe,eZo),e(Zb,oZo),e(Zb,UU),e(UU,rZo),e(Zb,tZo),e(G,aZo),e(G,Kb),e(Kb,aMe),e(aMe,nZo),e(Kb,sZo),e(Kb,HU),e(HU,lZo),e(Kb,iZo),e(G,dZo),e(G,ev),e(ev,nMe),e(nMe,mZo),e(ev,cZo),e(ev,JU),e(JU,fZo),e(ev,gZo),e(G,hZo),e(G,ov),e(ov,sMe),e(sMe,uZo),e(ov,pZo),e(ov,YU),e(YU,_Zo),e(ov,bZo),e(G,vZo),e(G,rv),e(rv,lMe),e(lMe,FZo),e(rv,TZo),e(rv,ZU),e(ZU,MZo),e(rv,EZo),e(G,CZo),e(G,tv),e(tv,iMe),e(iMe,wZo),e(tv,AZo),e(tv,KU),e(KU,LZo),e(tv,yZo),e(G,xZo),e(G,av),e(av,dMe),e(dMe,$Zo),e(av,kZo),e(av,eH),e(eH,SZo),e(av,RZo),e(G,PZo),e(G,nv),e(nv,mMe),e(mMe,BZo),e(nv,IZo),e(nv,oH),e(oH,NZo),e(nv,qZo),e(G,DZo),e(G,sv),e(sv,cMe),e(cMe,jZo),e(sv,GZo),e(sv,rH),e(rH,OZo),e(sv,VZo),e(G,XZo),e(G,lv),e(lv,fMe),e(fMe,zZo),e(lv,QZo),e(lv,tH),e(tH,WZo),e(lv,UZo),e(G,HZo),e(G,iv),e(iv,gMe),e(gMe,JZo),e(iv,YZo),e(iv,aH),e(aH,ZZo),e(iv,KZo),e(G,eKo),e(G,dv),e(dv,hMe),e(hMe,oKo),e(dv,rKo),e(dv,nH),e(nH,tKo),e(dv,aKo),e(G,nKo),e(G,mv),e(mv,uMe),e(uMe,sKo),e(mv,lKo),e(mv,sH),e(sH,iKo),e(mv,dKo),e(G,mKo),e(G,cv),e(cv,pMe),e(pMe,cKo),e(cv,fKo),e(cv,lH),e(lH,gKo),e(cv,hKo),e(G,uKo),e(G,fv),e(fv,_Me),e(_Me,pKo),e(fv,_Ko),e(fv,iH),e(iH,bKo),e(fv,vKo),e(G,FKo),e(G,gv),e(gv,bMe),e(bMe,TKo),e(gv,MKo),e(gv,dH),e(dH,EKo),e(gv,CKo),e(G,wKo),e(G,hv),e(hv,vMe),e(vMe,AKo),e(hv,LKo),e(hv,mH),e(mH,yKo),e(hv,xKo),e(G,$Ko),e(G,uv),e(uv,FMe),e(FMe,kKo),e(uv,SKo),e(uv,cH),e(cH,RKo),e(uv,PKo),e(G,BKo),e(G,pv),e(pv,TMe),e(TMe,IKo),e(pv,NKo),e(pv,fH),e(fH,qKo),e(pv,DKo),e(G,jKo),e(G,_v),e(_v,MMe),e(MMe,GKo),e(_v,OKo),e(_v,gH),e(gH,VKo),e(_v,XKo),e(G,zKo),e(G,bv),e(bv,EMe),e(EMe,QKo),e(bv,WKo),e(bv,hH),e(hH,UKo),e(bv,HKo),e(G,JKo),e(G,vv),e(vv,CMe),e(CMe,YKo),e(vv,ZKo),e(vv,uH),e(uH,KKo),e(vv,eer),e(G,oer),e(G,Fv),e(Fv,wMe),e(wMe,rer),e(Fv,ter),e(Fv,pH),e(pH,aer),e(Fv,ner),e(G,ser),e(G,Tv),e(Tv,AMe),e(AMe,ler),e(Tv,ier),e(Tv,_H),e(_H,der),e(Tv,mer),e(G,cer),e(G,Mv),e(Mv,LMe),e(LMe,fer),e(Mv,ger),e(Mv,bH),e(bH,her),e(Mv,uer),e(G,per),e(G,Ev),e(Ev,yMe),e(yMe,_er),e(Ev,ber),e(Ev,vH),e(vH,ver),e(Ev,Fer),e(G,Ter),e(G,Cv),e(Cv,xMe),e(xMe,Mer),e(Cv,Eer),e(Cv,FH),e(FH,Cer),e(Cv,wer),e(G,Aer),e(G,wv),e(wv,$Me),e($Me,Ler),e(wv,yer),e(wv,TH),e(TH,xer),e(wv,$er),e(G,ker),e(G,Av),e(Av,kMe),e(kMe,Ser),e(Av,Rer),e(Av,MH),e(MH,Per),e(Av,Ber),e(G,Ier),e(G,Lv),e(Lv,SMe),e(SMe,Ner),e(Lv,qer),e(Lv,EH),e(EH,Der),e(Lv,jer),e(G,Ger),e(G,yv),e(yv,RMe),e(RMe,Oer),e(yv,Ver),e(yv,CH),e(CH,Xer),e(yv,zer),e(G,Qer),e(G,xv),e(xv,PMe),e(PMe,Wer),e(xv,Uer),e(xv,wH),e(wH,Her),e(xv,Jer),e(G,Yer),e(G,$v),e($v,BMe),e(BMe,Zer),e($v,Ker),e($v,AH),e(AH,eor),e($v,oor),e(G,ror),e(G,kv),e(kv,IMe),e(IMe,tor),e(kv,aor),e(kv,LH),e(LH,nor),e(kv,sor),e(G,lor),e(G,Sv),e(Sv,NMe),e(NMe,ior),e(Sv,dor),e(Sv,yH),e(yH,mor),e(Sv,cor),e(G,gor),e(G,Rv),e(Rv,qMe),e(qMe,hor),e(Rv,uor),e(Rv,xH),e(xH,por),e(Rv,_or),e(G,bor),e(G,Pv),e(Pv,DMe),e(DMe,vor),e(Pv,For),e(Pv,$H),e($H,Tor),e(Pv,Mor),e(G,Eor),e(G,Bv),e(Bv,jMe),e(jMe,Cor),e(Bv,wor),e(Bv,kH),e(kH,Aor),e(Bv,Lor),e(G,yor),e(G,Iv),e(Iv,GMe),e(GMe,xor),e(Iv,$or),e(Iv,SH),e(SH,kor),e(Iv,Sor),e(G,Ror),e(G,Nv),e(Nv,OMe),e(OMe,Por),e(Nv,Bor),e(Nv,RH),e(RH,Ior),e(Nv,Nor),e(G,qor),e(G,qv),e(qv,VMe),e(VMe,Dor),e(qv,jor),e(qv,PH),e(PH,Gor),e(qv,Oor),e(G,Vor),e(G,Dv),e(Dv,XMe),e(XMe,Xor),e(Dv,zor),e(Dv,BH),e(BH,Qor),e(Dv,Wor),e(G,Uor),e(G,jv),e(jv,zMe),e(zMe,Hor),e(jv,Jor),e(jv,IH),e(IH,Yor),e(jv,Zor),e(G,Kor),e(G,Gv),e(Gv,QMe),e(QMe,err),e(Gv,orr),e(Gv,NH),e(NH,rrr),e(Gv,trr),e(G,arr),e(G,Ov),e(Ov,WMe),e(WMe,nrr),e(Ov,srr),e(Ov,qH),e(qH,lrr),e(Ov,irr),e(G,drr),e(G,Vv),e(Vv,UMe),e(UMe,mrr),e(Vv,crr),e(Vv,DH),e(DH,frr),e(Vv,grr),e(G,hrr),e(G,Xv),e(Xv,HMe),e(HMe,urr),e(Xv,prr),e(Xv,jH),e(jH,_rr),e(Xv,brr),e(G,vrr),e(G,zv),e(zv,JMe),e(JMe,Frr),e(zv,Trr),e(zv,GH),e(GH,Mrr),e(zv,Err),e(G,Crr),e(G,Qv),e(Qv,YMe),e(YMe,wrr),e(Qv,Arr),e(Qv,OH),e(OH,Lrr),e(Qv,yrr),e(ao,xrr),e(ao,Wv),e(Wv,$rr),e(Wv,ZMe),e(ZMe,krr),e(Wv,Srr),e(Wv,KMe),e(KMe,Rrr),e(ao,Prr),M(Uv,ao,null),b(c,klo,_),b(c,Wd,_),e(Wd,Hv),e(Hv,eEe),M(Kk,eEe,null),e(Wd,Brr),e(Wd,oEe),e(oEe,Irr),b(c,Slo,_),b(c,Oo,_),M(eS,Oo,null),e(Oo,Nrr),e(Oo,Ud),e(Ud,qrr),e(Ud,VH),e(VH,Drr),e(Ud,jrr),e(Ud,XH),e(XH,Grr),e(Ud,Orr),e(Oo,Vrr),e(Oo,oS),e(oS,Xrr),e(oS,rEe),e(rEe,zrr),e(oS,Qrr),e(Oo,Wrr),e(Oo,yt),M(rS,yt,null),e(yt,Urr),e(yt,tEe),e(tEe,Hrr),e(yt,Jrr),e(yt,Hd),e(Hd,Yrr),e(Hd,aEe),e(aEe,Zrr),e(Hd,Krr),e(Hd,zH),e(zH,etr),e(Hd,otr),e(yt,rtr),M(Jv,yt,null),e(Oo,ttr),e(Oo,no),M(tS,no,null),e(no,atr),e(no,nEe),e(nEe,ntr),e(no,str),e(no,hn),e(hn,ltr),e(hn,sEe),e(sEe,itr),e(hn,dtr),e(hn,lEe),e(lEe,mtr),e(hn,ctr),e(hn,iEe),e(iEe,ftr),e(hn,gtr),e(no,htr),e(no,W),e(W,Yv),e(Yv,dEe),e(dEe,utr),e(Yv,ptr),e(Yv,QH),e(QH,_tr),e(Yv,btr),e(W,vtr),e(W,Zv),e(Zv,mEe),e(mEe,Ftr),e(Zv,Ttr),e(Zv,WH),e(WH,Mtr),e(Zv,Etr),e(W,Ctr),e(W,Kv),e(Kv,cEe),e(cEe,wtr),e(Kv,Atr),e(Kv,UH),e(UH,Ltr),e(Kv,ytr),e(W,xtr),e(W,eF),e(eF,fEe),e(fEe,$tr),e(eF,ktr),e(eF,HH),e(HH,Str),e(eF,Rtr),e(W,Ptr),e(W,oF),e(oF,gEe),e(gEe,Btr),e(oF,Itr),e(oF,JH),e(JH,Ntr),e(oF,qtr),e(W,Dtr),e(W,rF),e(rF,hEe),e(hEe,jtr),e(rF,Gtr),e(rF,YH),e(YH,Otr),e(rF,Vtr),e(W,Xtr),e(W,tF),e(tF,uEe),e(uEe,ztr),e(tF,Qtr),e(tF,ZH),e(ZH,Wtr),e(tF,Utr),e(W,Htr),e(W,aF),e(aF,pEe),e(pEe,Jtr),e(aF,Ytr),e(aF,KH),e(KH,Ztr),e(aF,Ktr),e(W,ear),e(W,nF),e(nF,_Ee),e(_Ee,oar),e(nF,rar),e(nF,eJ),e(eJ,tar),e(nF,aar),e(W,nar),e(W,sF),e(sF,bEe),e(bEe,sar),e(sF,lar),e(sF,oJ),e(oJ,iar),e(sF,dar),e(W,mar),e(W,lF),e(lF,vEe),e(vEe,car),e(lF,far),e(lF,rJ),e(rJ,gar),e(lF,har),e(W,uar),e(W,iF),e(iF,FEe),e(FEe,par),e(iF,_ar),e(iF,tJ),e(tJ,bar),e(iF,Far),e(W,Tar),e(W,dF),e(dF,TEe),e(TEe,Mar),e(dF,Ear),e(dF,aJ),e(aJ,Car),e(dF,war),e(W,Aar),e(W,mF),e(mF,MEe),e(MEe,Lar),e(mF,yar),e(mF,nJ),e(nJ,xar),e(mF,$ar),e(W,kar),e(W,cF),e(cF,EEe),e(EEe,Sar),e(cF,Rar),e(cF,sJ),e(sJ,Par),e(cF,Bar),e(W,Iar),e(W,fF),e(fF,CEe),e(CEe,Nar),e(fF,qar),e(fF,lJ),e(lJ,Dar),e(fF,jar),e(W,Gar),e(W,gF),e(gF,wEe),e(wEe,Oar),e(gF,Var),e(gF,iJ),e(iJ,Xar),e(gF,zar),e(W,Qar),e(W,hF),e(hF,AEe),e(AEe,War),e(hF,Uar),e(hF,dJ),e(dJ,Har),e(hF,Jar),e(W,Yar),e(W,uF),e(uF,LEe),e(LEe,Zar),e(uF,Kar),e(uF,mJ),e(mJ,enr),e(uF,onr),e(W,rnr),e(W,pF),e(pF,yEe),e(yEe,tnr),e(pF,anr),e(pF,cJ),e(cJ,nnr),e(pF,snr),e(W,lnr),e(W,_F),e(_F,xEe),e(xEe,inr),e(_F,dnr),e(_F,fJ),e(fJ,mnr),e(_F,cnr),e(W,fnr),e(W,bF),e(bF,$Ee),e($Ee,gnr),e(bF,hnr),e(bF,gJ),e(gJ,unr),e(bF,pnr),e(W,_nr),e(W,vF),e(vF,kEe),e(kEe,bnr),e(vF,vnr),e(vF,hJ),e(hJ,Fnr),e(vF,Tnr),e(W,Mnr),e(W,FF),e(FF,SEe),e(SEe,Enr),e(FF,Cnr),e(FF,uJ),e(uJ,wnr),e(FF,Anr),e(W,Lnr),e(W,TF),e(TF,REe),e(REe,ynr),e(TF,xnr),e(TF,pJ),e(pJ,$nr),e(TF,knr),e(W,Snr),e(W,MF),e(MF,PEe),e(PEe,Rnr),e(MF,Pnr),e(MF,_J),e(_J,Bnr),e(MF,Inr),e(W,Nnr),e(W,EF),e(EF,BEe),e(BEe,qnr),e(EF,Dnr),e(EF,bJ),e(bJ,jnr),e(EF,Gnr),e(W,Onr),e(W,CF),e(CF,IEe),e(IEe,Vnr),e(CF,Xnr),e(CF,vJ),e(vJ,znr),e(CF,Qnr),e(W,Wnr),e(W,wF),e(wF,NEe),e(NEe,Unr),e(wF,Hnr),e(wF,FJ),e(FJ,Jnr),e(wF,Ynr),e(W,Znr),e(W,AF),e(AF,qEe),e(qEe,Knr),e(AF,esr),e(AF,TJ),e(TJ,osr),e(AF,rsr),e(W,tsr),e(W,LF),e(LF,DEe),e(DEe,asr),e(LF,nsr),e(LF,MJ),e(MJ,ssr),e(LF,lsr),e(W,isr),e(W,yF),e(yF,jEe),e(jEe,dsr),e(yF,msr),e(yF,EJ),e(EJ,csr),e(yF,fsr),e(W,gsr),e(W,xF),e(xF,GEe),e(GEe,hsr),e(xF,usr),e(xF,CJ),e(CJ,psr),e(xF,_sr),e(W,bsr),e(W,$F),e($F,OEe),e(OEe,vsr),e($F,Fsr),e($F,wJ),e(wJ,Tsr),e($F,Msr),e(W,Esr),e(W,kF),e(kF,VEe),e(VEe,Csr),e(kF,wsr),e(kF,AJ),e(AJ,Asr),e(kF,Lsr),e(W,ysr),e(W,SF),e(SF,XEe),e(XEe,xsr),e(SF,$sr),e(SF,LJ),e(LJ,ksr),e(SF,Ssr),e(W,Rsr),e(W,RF),e(RF,zEe),e(zEe,Psr),e(RF,Bsr),e(RF,yJ),e(yJ,Isr),e(RF,Nsr),e(W,qsr),e(W,PF),e(PF,QEe),e(QEe,Dsr),e(PF,jsr),e(PF,xJ),e(xJ,Gsr),e(PF,Osr),e(W,Vsr),e(W,BF),e(BF,WEe),e(WEe,Xsr),e(BF,zsr),e(BF,$J),e($J,Qsr),e(BF,Wsr),e(W,Usr),e(W,IF),e(IF,UEe),e(UEe,Hsr),e(IF,Jsr),e(IF,kJ),e(kJ,Ysr),e(IF,Zsr),e(W,Ksr),e(W,NF),e(NF,HEe),e(HEe,elr),e(NF,olr),e(NF,SJ),e(SJ,rlr),e(NF,tlr),e(W,alr),e(W,qF),e(qF,JEe),e(JEe,nlr),e(qF,slr),e(qF,RJ),e(RJ,llr),e(qF,ilr),e(W,dlr),e(W,DF),e(DF,YEe),e(YEe,mlr),e(DF,clr),e(DF,PJ),e(PJ,flr),e(DF,glr),e(no,hlr),e(no,jF),e(jF,ulr),e(jF,ZEe),e(ZEe,plr),e(jF,_lr),e(jF,KEe),e(KEe,blr),e(no,vlr),M(GF,no,null),b(c,Rlo,_),b(c,Jd,_),e(Jd,OF),e(OF,e4e),M(aS,e4e,null),e(Jd,Flr),e(Jd,o4e),e(o4e,Tlr),b(c,Plo,_),b(c,Vo,_),M(nS,Vo,null),e(Vo,Mlr),e(Vo,Yd),e(Yd,Elr),e(Yd,BJ),e(BJ,Clr),e(Yd,wlr),e(Yd,IJ),e(IJ,Alr),e(Yd,Llr),e(Vo,ylr),e(Vo,sS),e(sS,xlr),e(sS,r4e),e(r4e,$lr),e(sS,klr),e(Vo,Slr),e(Vo,xt),M(lS,xt,null),e(xt,Rlr),e(xt,t4e),e(t4e,Plr),e(xt,Blr),e(xt,Zd),e(Zd,Ilr),e(Zd,a4e),e(a4e,Nlr),e(Zd,qlr),e(Zd,NJ),e(NJ,Dlr),e(Zd,jlr),e(xt,Glr),M(VF,xt,null),e(Vo,Olr),e(Vo,so),M(iS,so,null),e(so,Vlr),e(so,n4e),e(n4e,Xlr),e(so,zlr),e(so,un),e(un,Qlr),e(un,s4e),e(s4e,Wlr),e(un,Ulr),e(un,l4e),e(l4e,Hlr),e(un,Jlr),e(un,i4e),e(i4e,Ylr),e(un,Zlr),e(so,Klr),e(so,dS),e(dS,XF),e(XF,d4e),e(d4e,eir),e(XF,oir),e(XF,qJ),e(qJ,rir),e(XF,tir),e(dS,air),e(dS,zF),e(zF,m4e),e(m4e,nir),e(zF,sir),e(zF,DJ),e(DJ,lir),e(zF,iir),e(so,dir),e(so,QF),e(QF,mir),e(QF,c4e),e(c4e,cir),e(QF,fir),e(QF,f4e),e(f4e,gir),e(so,hir),M(WF,so,null),b(c,Blo,_),b(c,Kd,_),e(Kd,UF),e(UF,g4e),M(mS,g4e,null),e(Kd,uir),e(Kd,h4e),e(h4e,pir),b(c,Ilo,_),b(c,Xo,_),M(cS,Xo,null),e(Xo,_ir),e(Xo,em),e(em,bir),e(em,jJ),e(jJ,vir),e(em,Fir),e(em,GJ),e(GJ,Tir),e(em,Mir),e(Xo,Eir),e(Xo,fS),e(fS,Cir),e(fS,u4e),e(u4e,wir),e(fS,Air),e(Xo,Lir),e(Xo,$t),M(gS,$t,null),e($t,yir),e($t,p4e),e(p4e,xir),e($t,$ir),e($t,om),e(om,kir),e(om,_4e),e(_4e,Sir),e(om,Rir),e(om,OJ),e(OJ,Pir),e(om,Bir),e($t,Iir),M(HF,$t,null),e(Xo,Nir),e(Xo,lo),M(hS,lo,null),e(lo,qir),e(lo,b4e),e(b4e,Dir),e(lo,jir),e(lo,pn),e(pn,Gir),e(pn,v4e),e(v4e,Oir),e(pn,Vir),e(pn,F4e),e(F4e,Xir),e(pn,zir),e(pn,T4e),e(T4e,Qir),e(pn,Wir),e(lo,Uir),e(lo,Y),e(Y,JF),e(JF,M4e),e(M4e,Hir),e(JF,Jir),e(JF,VJ),e(VJ,Yir),e(JF,Zir),e(Y,Kir),e(Y,YF),e(YF,E4e),e(E4e,edr),e(YF,odr),e(YF,XJ),e(XJ,rdr),e(YF,tdr),e(Y,adr),e(Y,ZF),e(ZF,C4e),e(C4e,ndr),e(ZF,sdr),e(ZF,zJ),e(zJ,ldr),e(ZF,idr),e(Y,ddr),e(Y,KF),e(KF,w4e),e(w4e,mdr),e(KF,cdr),e(KF,QJ),e(QJ,fdr),e(KF,gdr),e(Y,hdr),e(Y,eT),e(eT,A4e),e(A4e,udr),e(eT,pdr),e(eT,WJ),e(WJ,_dr),e(eT,bdr),e(Y,vdr),e(Y,oT),e(oT,L4e),e(L4e,Fdr),e(oT,Tdr),e(oT,UJ),e(UJ,Mdr),e(oT,Edr),e(Y,Cdr),e(Y,rT),e(rT,y4e),e(y4e,wdr),e(rT,Adr),e(rT,HJ),e(HJ,Ldr),e(rT,ydr),e(Y,xdr),e(Y,tT),e(tT,x4e),e(x4e,$dr),e(tT,kdr),e(tT,JJ),e(JJ,Sdr),e(tT,Rdr),e(Y,Pdr),e(Y,aT),e(aT,$4e),e($4e,Bdr),e(aT,Idr),e(aT,YJ),e(YJ,Ndr),e(aT,qdr),e(Y,Ddr),e(Y,nT),e(nT,k4e),e(k4e,jdr),e(nT,Gdr),e(nT,ZJ),e(ZJ,Odr),e(nT,Vdr),e(Y,Xdr),e(Y,sT),e(sT,S4e),e(S4e,zdr),e(sT,Qdr),e(sT,KJ),e(KJ,Wdr),e(sT,Udr),e(Y,Hdr),e(Y,lT),e(lT,R4e),e(R4e,Jdr),e(lT,Ydr),e(lT,eY),e(eY,Zdr),e(lT,Kdr),e(Y,emr),e(Y,iT),e(iT,P4e),e(P4e,omr),e(iT,rmr),e(iT,oY),e(oY,tmr),e(iT,amr),e(Y,nmr),e(Y,dT),e(dT,B4e),e(B4e,smr),e(dT,lmr),e(dT,rY),e(rY,imr),e(dT,dmr),e(Y,mmr),e(Y,mT),e(mT,I4e),e(I4e,cmr),e(mT,fmr),e(mT,tY),e(tY,gmr),e(mT,hmr),e(Y,umr),e(Y,cT),e(cT,N4e),e(N4e,pmr),e(cT,_mr),e(cT,aY),e(aY,bmr),e(cT,vmr),e(Y,Fmr),e(Y,fT),e(fT,q4e),e(q4e,Tmr),e(fT,Mmr),e(fT,nY),e(nY,Emr),e(fT,Cmr),e(Y,wmr),e(Y,gT),e(gT,D4e),e(D4e,Amr),e(gT,Lmr),e(gT,sY),e(sY,ymr),e(gT,xmr),e(Y,$mr),e(Y,hT),e(hT,j4e),e(j4e,kmr),e(hT,Smr),e(hT,lY),e(lY,Rmr),e(hT,Pmr),e(Y,Bmr),e(Y,uT),e(uT,G4e),e(G4e,Imr),e(uT,Nmr),e(uT,iY),e(iY,qmr),e(uT,Dmr),e(Y,jmr),e(Y,pT),e(pT,O4e),e(O4e,Gmr),e(pT,Omr),e(pT,dY),e(dY,Vmr),e(pT,Xmr),e(Y,zmr),e(Y,_T),e(_T,V4e),e(V4e,Qmr),e(_T,Wmr),e(_T,mY),e(mY,Umr),e(_T,Hmr),e(Y,Jmr),e(Y,bT),e(bT,X4e),e(X4e,Ymr),e(bT,Zmr),e(bT,cY),e(cY,Kmr),e(bT,ecr),e(Y,ocr),e(Y,vT),e(vT,z4e),e(z4e,rcr),e(vT,tcr),e(vT,fY),e(fY,acr),e(vT,ncr),e(Y,scr),e(Y,FT),e(FT,Q4e),e(Q4e,lcr),e(FT,icr),e(FT,gY),e(gY,dcr),e(FT,mcr),e(Y,ccr),e(Y,TT),e(TT,W4e),e(W4e,fcr),e(TT,gcr),e(TT,hY),e(hY,hcr),e(TT,ucr),e(Y,pcr),e(Y,MT),e(MT,U4e),e(U4e,_cr),e(MT,bcr),e(MT,uY),e(uY,vcr),e(MT,Fcr),e(Y,Tcr),e(Y,ET),e(ET,H4e),e(H4e,Mcr),e(ET,Ecr),e(ET,pY),e(pY,Ccr),e(ET,wcr),e(Y,Acr),e(Y,CT),e(CT,J4e),e(J4e,Lcr),e(CT,ycr),e(CT,_Y),e(_Y,xcr),e(CT,$cr),e(Y,kcr),e(Y,wT),e(wT,Y4e),e(Y4e,Scr),e(wT,Rcr),e(wT,bY),e(bY,Pcr),e(wT,Bcr),e(Y,Icr),e(Y,AT),e(AT,Z4e),e(Z4e,Ncr),e(AT,qcr),e(AT,vY),e(vY,Dcr),e(AT,jcr),e(Y,Gcr),e(Y,LT),e(LT,K4e),e(K4e,Ocr),e(LT,Vcr),e(LT,FY),e(FY,Xcr),e(LT,zcr),e(Y,Qcr),e(Y,yT),e(yT,eCe),e(eCe,Wcr),e(yT,Ucr),e(yT,TY),e(TY,Hcr),e(yT,Jcr),e(Y,Ycr),e(Y,xT),e(xT,oCe),e(oCe,Zcr),e(xT,Kcr),e(xT,MY),e(MY,efr),e(xT,ofr),e(Y,rfr),e(Y,$T),e($T,rCe),e(rCe,tfr),e($T,afr),e($T,EY),e(EY,nfr),e($T,sfr),e(Y,lfr),e(Y,kT),e(kT,tCe),e(tCe,ifr),e(kT,dfr),e(kT,aCe),e(aCe,mfr),e(kT,cfr),e(Y,ffr),e(Y,ST),e(ST,nCe),e(nCe,gfr),e(ST,hfr),e(ST,CY),e(CY,ufr),e(ST,pfr),e(Y,_fr),e(Y,RT),e(RT,sCe),e(sCe,bfr),e(RT,vfr),e(RT,wY),e(wY,Ffr),e(RT,Tfr),e(Y,Mfr),e(Y,PT),e(PT,lCe),e(lCe,Efr),e(PT,Cfr),e(PT,AY),e(AY,wfr),e(PT,Afr),e(Y,Lfr),e(Y,BT),e(BT,iCe),e(iCe,yfr),e(BT,xfr),e(BT,LY),e(LY,$fr),e(BT,kfr),e(lo,Sfr),e(lo,IT),e(IT,Rfr),e(IT,dCe),e(dCe,Pfr),e(IT,Bfr),e(IT,mCe),e(mCe,Ifr),e(lo,Nfr),M(NT,lo,null),b(c,Nlo,_),b(c,rm,_),e(rm,qT),e(qT,cCe),M(uS,cCe,null),e(rm,qfr),e(rm,fCe),e(fCe,Dfr),b(c,qlo,_),b(c,zo,_),M(pS,zo,null),e(zo,jfr),e(zo,tm),e(tm,Gfr),e(tm,yY),e(yY,Ofr),e(tm,Vfr),e(tm,xY),e(xY,Xfr),e(tm,zfr),e(zo,Qfr),e(zo,_S),e(_S,Wfr),e(_S,gCe),e(gCe,Ufr),e(_S,Hfr),e(zo,Jfr),e(zo,kt),M(bS,kt,null),e(kt,Yfr),e(kt,hCe),e(hCe,Zfr),e(kt,Kfr),e(kt,am),e(am,egr),e(am,uCe),e(uCe,ogr),e(am,rgr),e(am,$Y),e($Y,tgr),e(am,agr),e(kt,ngr),M(DT,kt,null),e(zo,sgr),e(zo,io),M(vS,io,null),e(io,lgr),e(io,pCe),e(pCe,igr),e(io,dgr),e(io,_n),e(_n,mgr),e(_n,_Ce),e(_Ce,cgr),e(_n,fgr),e(_n,bCe),e(bCe,ggr),e(_n,hgr),e(_n,vCe),e(vCe,ugr),e(_n,pgr),e(io,_gr),e(io,pe),e(pe,jT),e(jT,FCe),e(FCe,bgr),e(jT,vgr),e(jT,kY),e(kY,Fgr),e(jT,Tgr),e(pe,Mgr),e(pe,GT),e(GT,TCe),e(TCe,Egr),e(GT,Cgr),e(GT,SY),e(SY,wgr),e(GT,Agr),e(pe,Lgr),e(pe,OT),e(OT,MCe),e(MCe,ygr),e(OT,xgr),e(OT,RY),e(RY,$gr),e(OT,kgr),e(pe,Sgr),e(pe,VT),e(VT,ECe),e(ECe,Rgr),e(VT,Pgr),e(VT,PY),e(PY,Bgr),e(VT,Igr),e(pe,Ngr),e(pe,XT),e(XT,CCe),e(CCe,qgr),e(XT,Dgr),e(XT,BY),e(BY,jgr),e(XT,Ggr),e(pe,Ogr),e(pe,zT),e(zT,wCe),e(wCe,Vgr),e(zT,Xgr),e(zT,IY),e(IY,zgr),e(zT,Qgr),e(pe,Wgr),e(pe,QT),e(QT,ACe),e(ACe,Ugr),e(QT,Hgr),e(QT,NY),e(NY,Jgr),e(QT,Ygr),e(pe,Zgr),e(pe,WT),e(WT,LCe),e(LCe,Kgr),e(WT,ehr),e(WT,qY),e(qY,ohr),e(WT,rhr),e(pe,thr),e(pe,UT),e(UT,yCe),e(yCe,ahr),e(UT,nhr),e(UT,DY),e(DY,shr),e(UT,lhr),e(pe,ihr),e(pe,HT),e(HT,xCe),e(xCe,dhr),e(HT,mhr),e(HT,jY),e(jY,chr),e(HT,fhr),e(pe,ghr),e(pe,JT),e(JT,$Ce),e($Ce,hhr),e(JT,uhr),e(JT,GY),e(GY,phr),e(JT,_hr),e(pe,bhr),e(pe,YT),e(YT,kCe),e(kCe,vhr),e(YT,Fhr),e(YT,OY),e(OY,Thr),e(YT,Mhr),e(pe,Ehr),e(pe,ZT),e(ZT,SCe),e(SCe,Chr),e(ZT,whr),e(ZT,VY),e(VY,Ahr),e(ZT,Lhr),e(pe,yhr),e(pe,KT),e(KT,RCe),e(RCe,xhr),e(KT,$hr),e(KT,XY),e(XY,khr),e(KT,Shr),e(pe,Rhr),e(pe,eM),e(eM,PCe),e(PCe,Phr),e(eM,Bhr),e(eM,zY),e(zY,Ihr),e(eM,Nhr),e(pe,qhr),e(pe,oM),e(oM,BCe),e(BCe,Dhr),e(oM,jhr),e(oM,QY),e(QY,Ghr),e(oM,Ohr),e(pe,Vhr),e(pe,rM),e(rM,ICe),e(ICe,Xhr),e(rM,zhr),e(rM,WY),e(WY,Qhr),e(rM,Whr),e(pe,Uhr),e(pe,tM),e(tM,NCe),e(NCe,Hhr),e(tM,Jhr),e(tM,UY),e(UY,Yhr),e(tM,Zhr),e(pe,Khr),e(pe,aM),e(aM,qCe),e(qCe,eur),e(aM,our),e(aM,HY),e(HY,rur),e(aM,tur),e(pe,aur),e(pe,nM),e(nM,DCe),e(DCe,nur),e(nM,sur),e(nM,JY),e(JY,lur),e(nM,iur),e(io,dur),e(io,sM),e(sM,mur),e(sM,jCe),e(jCe,cur),e(sM,fur),e(sM,GCe),e(GCe,gur),e(io,hur),M(lM,io,null),b(c,Dlo,_),b(c,nm,_),e(nm,iM),e(iM,OCe),M(FS,OCe,null),e(nm,uur),e(nm,VCe),e(VCe,pur),b(c,jlo,_),b(c,Qo,_),M(TS,Qo,null),e(Qo,_ur),e(Qo,sm),e(sm,bur),e(sm,YY),e(YY,vur),e(sm,Fur),e(sm,ZY),e(ZY,Tur),e(sm,Mur),e(Qo,Eur),e(Qo,MS),e(MS,Cur),e(MS,XCe),e(XCe,wur),e(MS,Aur),e(Qo,Lur),e(Qo,St),M(ES,St,null),e(St,yur),e(St,zCe),e(zCe,xur),e(St,$ur),e(St,lm),e(lm,kur),e(lm,QCe),e(QCe,Sur),e(lm,Rur),e(lm,KY),e(KY,Pur),e(lm,Bur),e(St,Iur),M(dM,St,null),e(Qo,Nur),e(Qo,mo),M(CS,mo,null),e(mo,qur),e(mo,WCe),e(WCe,Dur),e(mo,jur),e(mo,bn),e(bn,Gur),e(bn,UCe),e(UCe,Our),e(bn,Vur),e(bn,HCe),e(HCe,Xur),e(bn,zur),e(bn,JCe),e(JCe,Qur),e(bn,Wur),e(mo,Uur),e(mo,I),e(I,mM),e(mM,YCe),e(YCe,Hur),e(mM,Jur),e(mM,eZ),e(eZ,Yur),e(mM,Zur),e(I,Kur),e(I,cM),e(cM,ZCe),e(ZCe,epr),e(cM,opr),e(cM,oZ),e(oZ,rpr),e(cM,tpr),e(I,apr),e(I,fM),e(fM,KCe),e(KCe,npr),e(fM,spr),e(fM,rZ),e(rZ,lpr),e(fM,ipr),e(I,dpr),e(I,gM),e(gM,e3e),e(e3e,mpr),e(gM,cpr),e(gM,tZ),e(tZ,fpr),e(gM,gpr),e(I,hpr),e(I,hM),e(hM,o3e),e(o3e,upr),e(hM,ppr),e(hM,aZ),e(aZ,_pr),e(hM,bpr),e(I,vpr),e(I,uM),e(uM,r3e),e(r3e,Fpr),e(uM,Tpr),e(uM,nZ),e(nZ,Mpr),e(uM,Epr),e(I,Cpr),e(I,pM),e(pM,t3e),e(t3e,wpr),e(pM,Apr),e(pM,sZ),e(sZ,Lpr),e(pM,ypr),e(I,xpr),e(I,_M),e(_M,a3e),e(a3e,$pr),e(_M,kpr),e(_M,lZ),e(lZ,Spr),e(_M,Rpr),e(I,Ppr),e(I,bM),e(bM,n3e),e(n3e,Bpr),e(bM,Ipr),e(bM,iZ),e(iZ,Npr),e(bM,qpr),e(I,Dpr),e(I,vM),e(vM,s3e),e(s3e,jpr),e(vM,Gpr),e(vM,dZ),e(dZ,Opr),e(vM,Vpr),e(I,Xpr),e(I,FM),e(FM,l3e),e(l3e,zpr),e(FM,Qpr),e(FM,mZ),e(mZ,Wpr),e(FM,Upr),e(I,Hpr),e(I,TM),e(TM,i3e),e(i3e,Jpr),e(TM,Ypr),e(TM,cZ),e(cZ,Zpr),e(TM,Kpr),e(I,e_r),e(I,MM),e(MM,d3e),e(d3e,o_r),e(MM,r_r),e(MM,fZ),e(fZ,t_r),e(MM,a_r),e(I,n_r),e(I,EM),e(EM,m3e),e(m3e,s_r),e(EM,l_r),e(EM,gZ),e(gZ,i_r),e(EM,d_r),e(I,m_r),e(I,CM),e(CM,c3e),e(c3e,c_r),e(CM,f_r),e(CM,hZ),e(hZ,g_r),e(CM,h_r),e(I,u_r),e(I,wM),e(wM,f3e),e(f3e,p_r),e(wM,__r),e(wM,uZ),e(uZ,b_r),e(wM,v_r),e(I,F_r),e(I,AM),e(AM,g3e),e(g3e,T_r),e(AM,M_r),e(AM,pZ),e(pZ,E_r),e(AM,C_r),e(I,w_r),e(I,LM),e(LM,h3e),e(h3e,A_r),e(LM,L_r),e(LM,_Z),e(_Z,y_r),e(LM,x_r),e(I,$_r),e(I,yM),e(yM,u3e),e(u3e,k_r),e(yM,S_r),e(yM,bZ),e(bZ,R_r),e(yM,P_r),e(I,B_r),e(I,xM),e(xM,p3e),e(p3e,I_r),e(xM,N_r),e(xM,vZ),e(vZ,q_r),e(xM,D_r),e(I,j_r),e(I,$M),e($M,_3e),e(_3e,G_r),e($M,O_r),e($M,FZ),e(FZ,V_r),e($M,X_r),e(I,z_r),e(I,kM),e(kM,b3e),e(b3e,Q_r),e(kM,W_r),e(kM,TZ),e(TZ,U_r),e(kM,H_r),e(I,J_r),e(I,SM),e(SM,v3e),e(v3e,Y_r),e(SM,Z_r),e(SM,MZ),e(MZ,K_r),e(SM,e1r),e(I,o1r),e(I,RM),e(RM,F3e),e(F3e,r1r),e(RM,t1r),e(RM,EZ),e(EZ,a1r),e(RM,n1r),e(I,s1r),e(I,PM),e(PM,T3e),e(T3e,l1r),e(PM,i1r),e(PM,CZ),e(CZ,d1r),e(PM,m1r),e(I,c1r),e(I,BM),e(BM,M3e),e(M3e,f1r),e(BM,g1r),e(BM,wZ),e(wZ,h1r),e(BM,u1r),e(I,p1r),e(I,IM),e(IM,E3e),e(E3e,_1r),e(IM,b1r),e(IM,AZ),e(AZ,v1r),e(IM,F1r),e(I,T1r),e(I,NM),e(NM,C3e),e(C3e,M1r),e(NM,E1r),e(NM,LZ),e(LZ,C1r),e(NM,w1r),e(I,A1r),e(I,qM),e(qM,w3e),e(w3e,L1r),e(qM,y1r),e(qM,yZ),e(yZ,x1r),e(qM,$1r),e(I,k1r),e(I,DM),e(DM,A3e),e(A3e,S1r),e(DM,R1r),e(DM,xZ),e(xZ,P1r),e(DM,B1r),e(I,I1r),e(I,jM),e(jM,L3e),e(L3e,N1r),e(jM,q1r),e(jM,$Z),e($Z,D1r),e(jM,j1r),e(I,G1r),e(I,GM),e(GM,y3e),e(y3e,O1r),e(GM,V1r),e(GM,kZ),e(kZ,X1r),e(GM,z1r),e(I,Q1r),e(I,OM),e(OM,x3e),e(x3e,W1r),e(OM,U1r),e(OM,SZ),e(SZ,H1r),e(OM,J1r),e(I,Y1r),e(I,VM),e(VM,$3e),e($3e,Z1r),e(VM,K1r),e(VM,RZ),e(RZ,e2r),e(VM,o2r),e(I,r2r),e(I,XM),e(XM,k3e),e(k3e,t2r),e(XM,a2r),e(XM,PZ),e(PZ,n2r),e(XM,s2r),e(I,l2r),e(I,zM),e(zM,S3e),e(S3e,i2r),e(zM,d2r),e(zM,BZ),e(BZ,m2r),e(zM,c2r),e(I,f2r),e(I,QM),e(QM,R3e),e(R3e,g2r),e(QM,h2r),e(QM,IZ),e(IZ,u2r),e(QM,p2r),e(I,_2r),e(I,WM),e(WM,P3e),e(P3e,b2r),e(WM,v2r),e(WM,NZ),e(NZ,F2r),e(WM,T2r),e(I,M2r),e(I,UM),e(UM,B3e),e(B3e,E2r),e(UM,C2r),e(UM,qZ),e(qZ,w2r),e(UM,A2r),e(I,L2r),e(I,HM),e(HM,I3e),e(I3e,y2r),e(HM,x2r),e(HM,DZ),e(DZ,$2r),e(HM,k2r),e(I,S2r),e(I,JM),e(JM,N3e),e(N3e,R2r),e(JM,P2r),e(JM,jZ),e(jZ,B2r),e(JM,I2r),e(I,N2r),e(I,YM),e(YM,q3e),e(q3e,q2r),e(YM,D2r),e(YM,GZ),e(GZ,j2r),e(YM,G2r),e(I,O2r),e(I,ZM),e(ZM,D3e),e(D3e,V2r),e(ZM,X2r),e(ZM,OZ),e(OZ,z2r),e(ZM,Q2r),e(I,W2r),e(I,KM),e(KM,j3e),e(j3e,U2r),e(KM,H2r),e(KM,VZ),e(VZ,J2r),e(KM,Y2r),e(I,Z2r),e(I,eE),e(eE,G3e),e(G3e,K2r),e(eE,ebr),e(eE,XZ),e(XZ,obr),e(eE,rbr),e(I,tbr),e(I,oE),e(oE,O3e),e(O3e,abr),e(oE,nbr),e(oE,zZ),e(zZ,sbr),e(oE,lbr),e(I,ibr),e(I,rE),e(rE,V3e),e(V3e,dbr),e(rE,mbr),e(rE,QZ),e(QZ,cbr),e(rE,fbr),e(I,gbr),e(I,tE),e(tE,X3e),e(X3e,hbr),e(tE,ubr),e(tE,WZ),e(WZ,pbr),e(tE,_br),e(I,bbr),e(I,aE),e(aE,z3e),e(z3e,vbr),e(aE,Fbr),e(aE,UZ),e(UZ,Tbr),e(aE,Mbr),e(I,Ebr),e(I,nE),e(nE,Q3e),e(Q3e,Cbr),e(nE,wbr),e(nE,HZ),e(HZ,Abr),e(nE,Lbr),e(I,ybr),e(I,sE),e(sE,W3e),e(W3e,xbr),e(sE,$br),e(sE,JZ),e(JZ,kbr),e(sE,Sbr),e(I,Rbr),e(I,lE),e(lE,U3e),e(U3e,Pbr),e(lE,Bbr),e(lE,YZ),e(YZ,Ibr),e(lE,Nbr),e(I,qbr),e(I,iE),e(iE,H3e),e(H3e,Dbr),e(iE,jbr),e(iE,ZZ),e(ZZ,Gbr),e(iE,Obr),e(I,Vbr),e(I,dE),e(dE,J3e),e(J3e,Xbr),e(dE,zbr),e(dE,KZ),e(KZ,Qbr),e(dE,Wbr),e(I,Ubr),e(I,mE),e(mE,Y3e),e(Y3e,Hbr),e(mE,Jbr),e(mE,eK),e(eK,Ybr),e(mE,Zbr),e(I,Kbr),e(I,cE),e(cE,Z3e),e(Z3e,evr),e(cE,ovr),e(cE,oK),e(oK,rvr),e(cE,tvr),e(I,avr),e(I,fE),e(fE,K3e),e(K3e,nvr),e(fE,svr),e(fE,rK),e(rK,lvr),e(fE,ivr),e(mo,dvr),e(mo,gE),e(gE,mvr),e(gE,e5e),e(e5e,cvr),e(gE,fvr),e(gE,o5e),e(o5e,gvr),e(mo,hvr),M(hE,mo,null),b(c,Glo,_),b(c,im,_),e(im,uE),e(uE,r5e),M(wS,r5e,null),e(im,uvr),e(im,t5e),e(t5e,pvr),b(c,Olo,_),b(c,Wo,_),M(AS,Wo,null),e(Wo,_vr),e(Wo,dm),e(dm,bvr),e(dm,tK),e(tK,vvr),e(dm,Fvr),e(dm,aK),e(aK,Tvr),e(dm,Mvr),e(Wo,Evr),e(Wo,LS),e(LS,Cvr),e(LS,a5e),e(a5e,wvr),e(LS,Avr),e(Wo,Lvr),e(Wo,Rt),M(yS,Rt,null),e(Rt,yvr),e(Rt,n5e),e(n5e,xvr),e(Rt,$vr),e(Rt,mm),e(mm,kvr),e(mm,s5e),e(s5e,Svr),e(mm,Rvr),e(mm,nK),e(nK,Pvr),e(mm,Bvr),e(Rt,Ivr),M(pE,Rt,null),e(Wo,Nvr),e(Wo,co),M(xS,co,null),e(co,qvr),e(co,l5e),e(l5e,Dvr),e(co,jvr),e(co,vn),e(vn,Gvr),e(vn,i5e),e(i5e,Ovr),e(vn,Vvr),e(vn,d5e),e(d5e,Xvr),e(vn,zvr),e(vn,m5e),e(m5e,Qvr),e(vn,Wvr),e(co,Uvr),e(co,K),e(K,_E),e(_E,c5e),e(c5e,Hvr),e(_E,Jvr),e(_E,sK),e(sK,Yvr),e(_E,Zvr),e(K,Kvr),e(K,bE),e(bE,f5e),e(f5e,eFr),e(bE,oFr),e(bE,lK),e(lK,rFr),e(bE,tFr),e(K,aFr),e(K,vE),e(vE,g5e),e(g5e,nFr),e(vE,sFr),e(vE,iK),e(iK,lFr),e(vE,iFr),e(K,dFr),e(K,FE),e(FE,h5e),e(h5e,mFr),e(FE,cFr),e(FE,dK),e(dK,fFr),e(FE,gFr),e(K,hFr),e(K,TE),e(TE,u5e),e(u5e,uFr),e(TE,pFr),e(TE,mK),e(mK,_Fr),e(TE,bFr),e(K,vFr),e(K,ME),e(ME,p5e),e(p5e,FFr),e(ME,TFr),e(ME,cK),e(cK,MFr),e(ME,EFr),e(K,CFr),e(K,EE),e(EE,_5e),e(_5e,wFr),e(EE,AFr),e(EE,fK),e(fK,LFr),e(EE,yFr),e(K,xFr),e(K,CE),e(CE,b5e),e(b5e,$Fr),e(CE,kFr),e(CE,gK),e(gK,SFr),e(CE,RFr),e(K,PFr),e(K,wE),e(wE,v5e),e(v5e,BFr),e(wE,IFr),e(wE,hK),e(hK,NFr),e(wE,qFr),e(K,DFr),e(K,AE),e(AE,F5e),e(F5e,jFr),e(AE,GFr),e(AE,uK),e(uK,OFr),e(AE,VFr),e(K,XFr),e(K,LE),e(LE,T5e),e(T5e,zFr),e(LE,QFr),e(LE,pK),e(pK,WFr),e(LE,UFr),e(K,HFr),e(K,yE),e(yE,M5e),e(M5e,JFr),e(yE,YFr),e(yE,_K),e(_K,ZFr),e(yE,KFr),e(K,eTr),e(K,xE),e(xE,E5e),e(E5e,oTr),e(xE,rTr),e(xE,bK),e(bK,tTr),e(xE,aTr),e(K,nTr),e(K,$E),e($E,C5e),e(C5e,sTr),e($E,lTr),e($E,vK),e(vK,iTr),e($E,dTr),e(K,mTr),e(K,kE),e(kE,w5e),e(w5e,cTr),e(kE,fTr),e(kE,FK),e(FK,gTr),e(kE,hTr),e(K,uTr),e(K,SE),e(SE,A5e),e(A5e,pTr),e(SE,_Tr),e(SE,TK),e(TK,bTr),e(SE,vTr),e(K,FTr),e(K,RE),e(RE,L5e),e(L5e,TTr),e(RE,MTr),e(RE,MK),e(MK,ETr),e(RE,CTr),e(K,wTr),e(K,PE),e(PE,y5e),e(y5e,ATr),e(PE,LTr),e(PE,EK),e(EK,yTr),e(PE,xTr),e(K,$Tr),e(K,BE),e(BE,x5e),e(x5e,kTr),e(BE,STr),e(BE,CK),e(CK,RTr),e(BE,PTr),e(K,BTr),e(K,IE),e(IE,$5e),e($5e,ITr),e(IE,NTr),e(IE,wK),e(wK,qTr),e(IE,DTr),e(K,jTr),e(K,NE),e(NE,k5e),e(k5e,GTr),e(NE,OTr),e(NE,AK),e(AK,VTr),e(NE,XTr),e(K,zTr),e(K,qE),e(qE,S5e),e(S5e,QTr),e(qE,WTr),e(qE,LK),e(LK,UTr),e(qE,HTr),e(K,JTr),e(K,DE),e(DE,R5e),e(R5e,YTr),e(DE,ZTr),e(DE,yK),e(yK,KTr),e(DE,eMr),e(K,oMr),e(K,jE),e(jE,P5e),e(P5e,rMr),e(jE,tMr),e(jE,xK),e(xK,aMr),e(jE,nMr),e(K,sMr),e(K,GE),e(GE,B5e),e(B5e,lMr),e(GE,iMr),e(GE,$K),e($K,dMr),e(GE,mMr),e(K,cMr),e(K,OE),e(OE,I5e),e(I5e,fMr),e(OE,gMr),e(OE,kK),e(kK,hMr),e(OE,uMr),e(K,pMr),e(K,VE),e(VE,N5e),e(N5e,_Mr),e(VE,bMr),e(VE,SK),e(SK,vMr),e(VE,FMr),e(K,TMr),e(K,XE),e(XE,q5e),e(q5e,MMr),e(XE,EMr),e(XE,RK),e(RK,CMr),e(XE,wMr),e(K,AMr),e(K,zE),e(zE,D5e),e(D5e,LMr),e(zE,yMr),e(zE,PK),e(PK,xMr),e(zE,$Mr),e(K,kMr),e(K,QE),e(QE,j5e),e(j5e,SMr),e(QE,RMr),e(QE,BK),e(BK,PMr),e(QE,BMr),e(K,IMr),e(K,WE),e(WE,G5e),e(G5e,NMr),e(WE,qMr),e(WE,IK),e(IK,DMr),e(WE,jMr),e(K,GMr),e(K,UE),e(UE,O5e),e(O5e,OMr),e(UE,VMr),e(UE,NK),e(NK,XMr),e(UE,zMr),e(K,QMr),e(K,HE),e(HE,V5e),e(V5e,WMr),e(HE,UMr),e(HE,qK),e(qK,HMr),e(HE,JMr),e(co,YMr),e(co,JE),e(JE,ZMr),e(JE,X5e),e(X5e,KMr),e(JE,eEr),e(JE,z5e),e(z5e,oEr),e(co,rEr),M(YE,co,null),b(c,Vlo,_),b(c,cm,_),e(cm,ZE),e(ZE,Q5e),M($S,Q5e,null),e(cm,tEr),e(cm,W5e),e(W5e,aEr),b(c,Xlo,_),b(c,Uo,_),M(kS,Uo,null),e(Uo,nEr),e(Uo,fm),e(fm,sEr),e(fm,DK),e(DK,lEr),e(fm,iEr),e(fm,jK),e(jK,dEr),e(fm,mEr),e(Uo,cEr),e(Uo,SS),e(SS,fEr),e(SS,U5e),e(U5e,gEr),e(SS,hEr),e(Uo,uEr),e(Uo,Pt),M(RS,Pt,null),e(Pt,pEr),e(Pt,H5e),e(H5e,_Er),e(Pt,bEr),e(Pt,gm),e(gm,vEr),e(gm,J5e),e(J5e,FEr),e(gm,TEr),e(gm,GK),e(GK,MEr),e(gm,EEr),e(Pt,CEr),M(KE,Pt,null),e(Uo,wEr),e(Uo,fo),M(PS,fo,null),e(fo,AEr),e(fo,Y5e),e(Y5e,LEr),e(fo,yEr),e(fo,Fn),e(Fn,xEr),e(Fn,Z5e),e(Z5e,$Er),e(Fn,kEr),e(Fn,K5e),e(K5e,SEr),e(Fn,REr),e(Fn,e0e),e(e0e,PEr),e(Fn,BEr),e(fo,IEr),e(fo,Ye),e(Ye,e4),e(e4,o0e),e(o0e,NEr),e(e4,qEr),e(e4,OK),e(OK,DEr),e(e4,jEr),e(Ye,GEr),e(Ye,o4),e(o4,r0e),e(r0e,OEr),e(o4,VEr),e(o4,VK),e(VK,XEr),e(o4,zEr),e(Ye,QEr),e(Ye,r4),e(r4,t0e),e(t0e,WEr),e(r4,UEr),e(r4,XK),e(XK,HEr),e(r4,JEr),e(Ye,YEr),e(Ye,t4),e(t4,a0e),e(a0e,ZEr),e(t4,KEr),e(t4,zK),e(zK,e4r),e(t4,o4r),e(Ye,r4r),e(Ye,a4),e(a4,n0e),e(n0e,t4r),e(a4,a4r),e(a4,QK),e(QK,n4r),e(a4,s4r),e(Ye,l4r),e(Ye,n4),e(n4,s0e),e(s0e,i4r),e(n4,d4r),e(n4,WK),e(WK,m4r),e(n4,c4r),e(Ye,f4r),e(Ye,s4),e(s4,l0e),e(l0e,g4r),e(s4,h4r),e(s4,UK),e(UK,u4r),e(s4,p4r),e(fo,_4r),e(fo,l4),e(l4,b4r),e(l4,i0e),e(i0e,v4r),e(l4,F4r),e(l4,d0e),e(d0e,T4r),e(fo,M4r),M(i4,fo,null),b(c,zlo,_),b(c,hm,_),e(hm,d4),e(d4,m0e),M(BS,m0e,null),e(hm,E4r),e(hm,c0e),e(c0e,C4r),b(c,Qlo,_),b(c,Ho,_),M(IS,Ho,null),e(Ho,w4r),e(Ho,um),e(um,A4r),e(um,HK),e(HK,L4r),e(um,y4r),e(um,JK),e(JK,x4r),e(um,$4r),e(Ho,k4r),e(Ho,NS),e(NS,S4r),e(NS,f0e),e(f0e,R4r),e(NS,P4r),e(Ho,B4r),e(Ho,Bt),M(qS,Bt,null),e(Bt,I4r),e(Bt,g0e),e(g0e,N4r),e(Bt,q4r),e(Bt,pm),e(pm,D4r),e(pm,h0e),e(h0e,j4r),e(pm,G4r),e(pm,YK),e(YK,O4r),e(pm,V4r),e(Bt,X4r),M(m4,Bt,null),e(Ho,z4r),e(Ho,go),M(DS,go,null),e(go,Q4r),e(go,u0e),e(u0e,W4r),e(go,U4r),e(go,Tn),e(Tn,H4r),e(Tn,p0e),e(p0e,J4r),e(Tn,Y4r),e(Tn,_0e),e(_0e,Z4r),e(Tn,K4r),e(Tn,b0e),e(b0e,eCr),e(Tn,oCr),e(go,rCr),e(go,U),e(U,c4),e(c4,v0e),e(v0e,tCr),e(c4,aCr),e(c4,ZK),e(ZK,nCr),e(c4,sCr),e(U,lCr),e(U,f4),e(f4,F0e),e(F0e,iCr),e(f4,dCr),e(f4,KK),e(KK,mCr),e(f4,cCr),e(U,fCr),e(U,g4),e(g4,T0e),e(T0e,gCr),e(g4,hCr),e(g4,eee),e(eee,uCr),e(g4,pCr),e(U,_Cr),e(U,h4),e(h4,M0e),e(M0e,bCr),e(h4,vCr),e(h4,oee),e(oee,FCr),e(h4,TCr),e(U,MCr),e(U,u4),e(u4,E0e),e(E0e,ECr),e(u4,CCr),e(u4,ree),e(ree,wCr),e(u4,ACr),e(U,LCr),e(U,p4),e(p4,C0e),e(C0e,yCr),e(p4,xCr),e(p4,tee),e(tee,$Cr),e(p4,kCr),e(U,SCr),e(U,_4),e(_4,w0e),e(w0e,RCr),e(_4,PCr),e(_4,aee),e(aee,BCr),e(_4,ICr),e(U,NCr),e(U,b4),e(b4,A0e),e(A0e,qCr),e(b4,DCr),e(b4,nee),e(nee,jCr),e(b4,GCr),e(U,OCr),e(U,v4),e(v4,L0e),e(L0e,VCr),e(v4,XCr),e(v4,see),e(see,zCr),e(v4,QCr),e(U,WCr),e(U,F4),e(F4,y0e),e(y0e,UCr),e(F4,HCr),e(F4,lee),e(lee,JCr),e(F4,YCr),e(U,ZCr),e(U,T4),e(T4,x0e),e(x0e,KCr),e(T4,e3r),e(T4,iee),e(iee,o3r),e(T4,r3r),e(U,t3r),e(U,M4),e(M4,$0e),e($0e,a3r),e(M4,n3r),e(M4,dee),e(dee,s3r),e(M4,l3r),e(U,i3r),e(U,E4),e(E4,k0e),e(k0e,d3r),e(E4,m3r),e(E4,mee),e(mee,c3r),e(E4,f3r),e(U,g3r),e(U,C4),e(C4,S0e),e(S0e,h3r),e(C4,u3r),e(C4,cee),e(cee,p3r),e(C4,_3r),e(U,b3r),e(U,w4),e(w4,R0e),e(R0e,v3r),e(w4,F3r),e(w4,fee),e(fee,T3r),e(w4,M3r),e(U,E3r),e(U,A4),e(A4,P0e),e(P0e,C3r),e(A4,w3r),e(A4,gee),e(gee,A3r),e(A4,L3r),e(U,y3r),e(U,L4),e(L4,B0e),e(B0e,x3r),e(L4,$3r),e(L4,hee),e(hee,k3r),e(L4,S3r),e(U,R3r),e(U,y4),e(y4,I0e),e(I0e,P3r),e(y4,B3r),e(y4,uee),e(uee,I3r),e(y4,N3r),e(U,q3r),e(U,x4),e(x4,N0e),e(N0e,D3r),e(x4,j3r),e(x4,pee),e(pee,G3r),e(x4,O3r),e(U,V3r),e(U,$4),e($4,q0e),e(q0e,X3r),e($4,z3r),e($4,_ee),e(_ee,Q3r),e($4,W3r),e(U,U3r),e(U,k4),e(k4,D0e),e(D0e,H3r),e(k4,J3r),e(k4,bee),e(bee,Y3r),e(k4,Z3r),e(U,K3r),e(U,S4),e(S4,j0e),e(j0e,e5r),e(S4,o5r),e(S4,vee),e(vee,r5r),e(S4,t5r),e(U,a5r),e(U,R4),e(R4,G0e),e(G0e,n5r),e(R4,s5r),e(R4,Fee),e(Fee,l5r),e(R4,i5r),e(U,d5r),e(U,P4),e(P4,O0e),e(O0e,m5r),e(P4,c5r),e(P4,Tee),e(Tee,f5r),e(P4,g5r),e(U,h5r),e(U,B4),e(B4,V0e),e(V0e,u5r),e(B4,p5r),e(B4,Mee),e(Mee,_5r),e(B4,b5r),e(U,v5r),e(U,I4),e(I4,X0e),e(X0e,F5r),e(I4,T5r),e(I4,Eee),e(Eee,M5r),e(I4,E5r),e(U,C5r),e(U,N4),e(N4,z0e),e(z0e,w5r),e(N4,A5r),e(N4,Cee),e(Cee,L5r),e(N4,y5r),e(U,x5r),e(U,q4),e(q4,Q0e),e(Q0e,$5r),e(q4,k5r),e(q4,wee),e(wee,S5r),e(q4,R5r),e(U,P5r),e(U,D4),e(D4,W0e),e(W0e,B5r),e(D4,I5r),e(D4,Aee),e(Aee,N5r),e(D4,q5r),e(U,D5r),e(U,j4),e(j4,U0e),e(U0e,j5r),e(j4,G5r),e(j4,Lee),e(Lee,O5r),e(j4,V5r),e(U,X5r),e(U,G4),e(G4,H0e),e(H0e,z5r),e(G4,Q5r),e(G4,yee),e(yee,W5r),e(G4,U5r),e(U,H5r),e(U,O4),e(O4,J0e),e(J0e,J5r),e(O4,Y5r),e(O4,xee),e(xee,Z5r),e(O4,K5r),e(U,e0r),e(U,V4),e(V4,Y0e),e(Y0e,o0r),e(V4,r0r),e(V4,$ee),e($ee,t0r),e(V4,a0r),e(U,n0r),e(U,X4),e(X4,Z0e),e(Z0e,s0r),e(X4,l0r),e(X4,kee),e(kee,i0r),e(X4,d0r),e(U,m0r),e(U,z4),e(z4,K0e),e(K0e,c0r),e(z4,f0r),e(z4,See),e(See,g0r),e(z4,h0r),e(U,u0r),e(U,Q4),e(Q4,ewe),e(ewe,p0r),e(Q4,_0r),e(Q4,Ree),e(Ree,b0r),e(Q4,v0r),e(U,F0r),e(U,W4),e(W4,owe),e(owe,T0r),e(W4,M0r),e(W4,Pee),e(Pee,E0r),e(W4,C0r),e(U,w0r),e(U,U4),e(U4,rwe),e(rwe,A0r),e(U4,L0r),e(U4,Bee),e(Bee,y0r),e(U4,x0r),e(U,$0r),e(U,H4),e(H4,twe),e(twe,k0r),e(H4,S0r),e(H4,Iee),e(Iee,R0r),e(H4,P0r),e(U,B0r),e(U,J4),e(J4,awe),e(awe,I0r),e(J4,N0r),e(J4,Nee),e(Nee,q0r),e(J4,D0r),e(U,j0r),e(U,Y4),e(Y4,nwe),e(nwe,G0r),e(Y4,O0r),e(Y4,qee),e(qee,V0r),e(Y4,X0r),e(U,z0r),e(U,Z4),e(Z4,swe),e(swe,Q0r),e(Z4,W0r),e(Z4,Dee),e(Dee,U0r),e(Z4,H0r),e(go,J0r),e(go,K4),e(K4,Y0r),e(K4,lwe),e(lwe,Z0r),e(K4,K0r),e(K4,iwe),e(iwe,ewr),e(go,owr),M(eC,go,null),b(c,Wlo,_),b(c,_m,_),e(_m,oC),e(oC,dwe),M(jS,dwe,null),e(_m,rwr),e(_m,mwe),e(mwe,twr),b(c,Ulo,_),b(c,Jo,_),M(GS,Jo,null),e(Jo,awr),e(Jo,bm),e(bm,nwr),e(bm,jee),e(jee,swr),e(bm,lwr),e(bm,Gee),e(Gee,iwr),e(bm,dwr),e(Jo,mwr),e(Jo,OS),e(OS,cwr),e(OS,cwe),e(cwe,fwr),e(OS,gwr),e(Jo,hwr),e(Jo,It),M(VS,It,null),e(It,uwr),e(It,fwe),e(fwe,pwr),e(It,_wr),e(It,vm),e(vm,bwr),e(vm,gwe),e(gwe,vwr),e(vm,Fwr),e(vm,Oee),e(Oee,Twr),e(vm,Mwr),e(It,Ewr),M(rC,It,null),e(Jo,Cwr),e(Jo,ho),M(XS,ho,null),e(ho,wwr),e(ho,hwe),e(hwe,Awr),e(ho,Lwr),e(ho,Mn),e(Mn,ywr),e(Mn,uwe),e(uwe,xwr),e(Mn,$wr),e(Mn,pwe),e(pwe,kwr),e(Mn,Swr),e(Mn,_we),e(_we,Rwr),e(Mn,Pwr),e(ho,Bwr),e(ho,O),e(O,tC),e(tC,bwe),e(bwe,Iwr),e(tC,Nwr),e(tC,Vee),e(Vee,qwr),e(tC,Dwr),e(O,jwr),e(O,aC),e(aC,vwe),e(vwe,Gwr),e(aC,Owr),e(aC,Xee),e(Xee,Vwr),e(aC,Xwr),e(O,zwr),e(O,nC),e(nC,Fwe),e(Fwe,Qwr),e(nC,Wwr),e(nC,zee),e(zee,Uwr),e(nC,Hwr),e(O,Jwr),e(O,sC),e(sC,Twe),e(Twe,Ywr),e(sC,Zwr),e(sC,Qee),e(Qee,Kwr),e(sC,eAr),e(O,oAr),e(O,lC),e(lC,Mwe),e(Mwe,rAr),e(lC,tAr),e(lC,Wee),e(Wee,aAr),e(lC,nAr),e(O,sAr),e(O,iC),e(iC,Ewe),e(Ewe,lAr),e(iC,iAr),e(iC,Uee),e(Uee,dAr),e(iC,mAr),e(O,cAr),e(O,dC),e(dC,Cwe),e(Cwe,fAr),e(dC,gAr),e(dC,Hee),e(Hee,hAr),e(dC,uAr),e(O,pAr),e(O,mC),e(mC,wwe),e(wwe,_Ar),e(mC,bAr),e(mC,Jee),e(Jee,vAr),e(mC,FAr),e(O,TAr),e(O,cC),e(cC,Awe),e(Awe,MAr),e(cC,EAr),e(cC,Yee),e(Yee,CAr),e(cC,wAr),e(O,AAr),e(O,fC),e(fC,Lwe),e(Lwe,LAr),e(fC,yAr),e(fC,Zee),e(Zee,xAr),e(fC,$Ar),e(O,kAr),e(O,gC),e(gC,ywe),e(ywe,SAr),e(gC,RAr),e(gC,Kee),e(Kee,PAr),e(gC,BAr),e(O,IAr),e(O,hC),e(hC,xwe),e(xwe,NAr),e(hC,qAr),e(hC,eoe),e(eoe,DAr),e(hC,jAr),e(O,GAr),e(O,uC),e(uC,$we),e($we,OAr),e(uC,VAr),e(uC,ooe),e(ooe,XAr),e(uC,zAr),e(O,QAr),e(O,pC),e(pC,kwe),e(kwe,WAr),e(pC,UAr),e(pC,roe),e(roe,HAr),e(pC,JAr),e(O,YAr),e(O,_C),e(_C,Swe),e(Swe,ZAr),e(_C,KAr),e(_C,toe),e(toe,e6r),e(_C,o6r),e(O,r6r),e(O,bC),e(bC,Rwe),e(Rwe,t6r),e(bC,a6r),e(bC,aoe),e(aoe,n6r),e(bC,s6r),e(O,l6r),e(O,vC),e(vC,Pwe),e(Pwe,i6r),e(vC,d6r),e(vC,noe),e(noe,m6r),e(vC,c6r),e(O,f6r),e(O,FC),e(FC,Bwe),e(Bwe,g6r),e(FC,h6r),e(FC,soe),e(soe,u6r),e(FC,p6r),e(O,_6r),e(O,TC),e(TC,Iwe),e(Iwe,b6r),e(TC,v6r),e(TC,loe),e(loe,F6r),e(TC,T6r),e(O,M6r),e(O,MC),e(MC,Nwe),e(Nwe,E6r),e(MC,C6r),e(MC,ioe),e(ioe,w6r),e(MC,A6r),e(O,L6r),e(O,EC),e(EC,qwe),e(qwe,y6r),e(EC,x6r),e(EC,doe),e(doe,$6r),e(EC,k6r),e(O,S6r),e(O,CC),e(CC,Dwe),e(Dwe,R6r),e(CC,P6r),e(CC,moe),e(moe,B6r),e(CC,I6r),e(O,N6r),e(O,wC),e(wC,jwe),e(jwe,q6r),e(wC,D6r),e(wC,coe),e(coe,j6r),e(wC,G6r),e(O,O6r),e(O,AC),e(AC,Gwe),e(Gwe,V6r),e(AC,X6r),e(AC,foe),e(foe,z6r),e(AC,Q6r),e(O,W6r),e(O,LC),e(LC,Owe),e(Owe,U6r),e(LC,H6r),e(LC,goe),e(goe,J6r),e(LC,Y6r),e(O,Z6r),e(O,yC),e(yC,Vwe),e(Vwe,K6r),e(yC,e7r),e(yC,hoe),e(hoe,o7r),e(yC,r7r),e(O,t7r),e(O,xC),e(xC,Xwe),e(Xwe,a7r),e(xC,n7r),e(xC,uoe),e(uoe,s7r),e(xC,l7r),e(O,i7r),e(O,$C),e($C,zwe),e(zwe,d7r),e($C,m7r),e($C,poe),e(poe,c7r),e($C,f7r),e(O,g7r),e(O,kC),e(kC,Qwe),e(Qwe,h7r),e(kC,u7r),e(kC,_oe),e(_oe,p7r),e(kC,_7r),e(O,b7r),e(O,SC),e(SC,Wwe),e(Wwe,v7r),e(SC,F7r),e(SC,boe),e(boe,T7r),e(SC,M7r),e(O,E7r),e(O,RC),e(RC,Uwe),e(Uwe,C7r),e(RC,w7r),e(RC,voe),e(voe,A7r),e(RC,L7r),e(O,y7r),e(O,PC),e(PC,Hwe),e(Hwe,x7r),e(PC,$7r),e(PC,Foe),e(Foe,k7r),e(PC,S7r),e(O,R7r),e(O,BC),e(BC,Jwe),e(Jwe,P7r),e(BC,B7r),e(BC,Toe),e(Toe,I7r),e(BC,N7r),e(O,q7r),e(O,IC),e(IC,Ywe),e(Ywe,D7r),e(IC,j7r),e(IC,Moe),e(Moe,G7r),e(IC,O7r),e(O,V7r),e(O,NC),e(NC,Zwe),e(Zwe,X7r),e(NC,z7r),e(NC,Eoe),e(Eoe,Q7r),e(NC,W7r),e(O,U7r),e(O,qC),e(qC,Kwe),e(Kwe,H7r),e(qC,J7r),e(qC,Coe),e(Coe,Y7r),e(qC,Z7r),e(O,K7r),e(O,DC),e(DC,eAe),e(eAe,e8r),e(DC,o8r),e(DC,woe),e(woe,r8r),e(DC,t8r),e(O,a8r),e(O,jC),e(jC,oAe),e(oAe,n8r),e(jC,s8r),e(jC,Aoe),e(Aoe,l8r),e(jC,i8r),e(O,d8r),e(O,GC),e(GC,rAe),e(rAe,m8r),e(GC,c8r),e(GC,Loe),e(Loe,f8r),e(GC,g8r),e(O,h8r),e(O,OC),e(OC,tAe),e(tAe,u8r),e(OC,p8r),e(OC,yoe),e(yoe,_8r),e(OC,b8r),e(O,v8r),e(O,VC),e(VC,aAe),e(aAe,F8r),e(VC,T8r),e(VC,xoe),e(xoe,M8r),e(VC,E8r),e(O,C8r),e(O,XC),e(XC,nAe),e(nAe,w8r),e(XC,A8r),e(XC,$oe),e($oe,L8r),e(XC,y8r),e(O,x8r),e(O,zC),e(zC,sAe),e(sAe,$8r),e(zC,k8r),e(zC,koe),e(koe,S8r),e(zC,R8r),e(O,P8r),e(O,QC),e(QC,lAe),e(lAe,B8r),e(QC,I8r),e(QC,Soe),e(Soe,N8r),e(QC,q8r),e(O,D8r),e(O,WC),e(WC,iAe),e(iAe,j8r),e(WC,G8r),e(WC,Roe),e(Roe,O8r),e(WC,V8r),e(O,X8r),e(O,UC),e(UC,dAe),e(dAe,z8r),e(UC,Q8r),e(UC,Poe),e(Poe,W8r),e(UC,U8r),e(O,H8r),e(O,HC),e(HC,mAe),e(mAe,J8r),e(HC,Y8r),e(HC,Boe),e(Boe,Z8r),e(HC,K8r),e(O,eLr),e(O,JC),e(JC,cAe),e(cAe,oLr),e(JC,rLr),e(JC,Ioe),e(Ioe,tLr),e(JC,aLr),e(O,nLr),e(O,YC),e(YC,fAe),e(fAe,sLr),e(YC,lLr),e(YC,Noe),e(Noe,iLr),e(YC,dLr),e(ho,mLr),e(ho,ZC),e(ZC,cLr),e(ZC,gAe),e(gAe,fLr),e(ZC,gLr),e(ZC,hAe),e(hAe,hLr),e(ho,uLr),M(KC,ho,null),b(c,Hlo,_),b(c,Fm,_),e(Fm,e3),e(e3,uAe),M(zS,uAe,null),e(Fm,pLr),e(Fm,pAe),e(pAe,_Lr),b(c,Jlo,_),b(c,Yo,_),M(QS,Yo,null),e(Yo,bLr),e(Yo,Tm),e(Tm,vLr),e(Tm,qoe),e(qoe,FLr),e(Tm,TLr),e(Tm,Doe),e(Doe,MLr),e(Tm,ELr),e(Yo,CLr),e(Yo,WS),e(WS,wLr),e(WS,_Ae),e(_Ae,ALr),e(WS,LLr),e(Yo,yLr),e(Yo,Nt),M(US,Nt,null),e(Nt,xLr),e(Nt,bAe),e(bAe,$Lr),e(Nt,kLr),e(Nt,Mm),e(Mm,SLr),e(Mm,vAe),e(vAe,RLr),e(Mm,PLr),e(Mm,joe),e(joe,BLr),e(Mm,ILr),e(Nt,NLr),M(o3,Nt,null),e(Yo,qLr),e(Yo,uo),M(HS,uo,null),e(uo,DLr),e(uo,FAe),e(FAe,jLr),e(uo,GLr),e(uo,En),e(En,OLr),e(En,TAe),e(TAe,VLr),e(En,XLr),e(En,MAe),e(MAe,zLr),e(En,QLr),e(En,EAe),e(EAe,WLr),e(En,ULr),e(uo,HLr),e(uo,CAe),e(CAe,r3),e(r3,wAe),e(wAe,JLr),e(r3,YLr),e(r3,Goe),e(Goe,ZLr),e(r3,KLr),e(uo,eyr),e(uo,t3),e(t3,oyr),e(t3,AAe),e(AAe,ryr),e(t3,tyr),e(t3,LAe),e(LAe,ayr),e(uo,nyr),M(a3,uo,null),b(c,Ylo,_),b(c,Em,_),e(Em,n3),e(n3,yAe),M(JS,yAe,null),e(Em,syr),e(Em,xAe),e(xAe,lyr),b(c,Zlo,_),b(c,Zo,_),M(YS,Zo,null),e(Zo,iyr),e(Zo,Cm),e(Cm,dyr),e(Cm,Ooe),e(Ooe,myr),e(Cm,cyr),e(Cm,Voe),e(Voe,fyr),e(Cm,gyr),e(Zo,hyr),e(Zo,ZS),e(ZS,uyr),e(ZS,$Ae),e($Ae,pyr),e(ZS,_yr),e(Zo,byr),e(Zo,qt),M(KS,qt,null),e(qt,vyr),e(qt,kAe),e(kAe,Fyr),e(qt,Tyr),e(qt,wm),e(wm,Myr),e(wm,SAe),e(SAe,Eyr),e(wm,Cyr),e(wm,Xoe),e(Xoe,wyr),e(wm,Ayr),e(qt,Lyr),M(s3,qt,null),e(Zo,yyr),e(Zo,po),M(eR,po,null),e(po,xyr),e(po,RAe),e(RAe,$yr),e(po,kyr),e(po,Cn),e(Cn,Syr),e(Cn,PAe),e(PAe,Ryr),e(Cn,Pyr),e(Cn,BAe),e(BAe,Byr),e(Cn,Iyr),e(Cn,IAe),e(IAe,Nyr),e(Cn,qyr),e(po,Dyr),e(po,Am),e(Am,l3),e(l3,NAe),e(NAe,jyr),e(l3,Gyr),e(l3,zoe),e(zoe,Oyr),e(l3,Vyr),e(Am,Xyr),e(Am,i3),e(i3,qAe),e(qAe,zyr),e(i3,Qyr),e(i3,Qoe),e(Qoe,Wyr),e(i3,Uyr),e(Am,Hyr),e(Am,d3),e(d3,DAe),e(DAe,Jyr),e(d3,Yyr),e(d3,Woe),e(Woe,Zyr),e(d3,Kyr),e(po,e9r),e(po,m3),e(m3,o9r),e(m3,jAe),e(jAe,r9r),e(m3,t9r),e(m3,GAe),e(GAe,a9r),e(po,n9r),M(c3,po,null),b(c,Klo,_),b(c,Lm,_),e(Lm,f3),e(f3,OAe),M(oR,OAe,null),e(Lm,s9r),e(Lm,VAe),e(VAe,l9r),b(c,eio,_),b(c,Ko,_),M(rR,Ko,null),e(Ko,i9r),e(Ko,ym),e(ym,d9r),e(ym,Uoe),e(Uoe,m9r),e(ym,c9r),e(ym,Hoe),e(Hoe,f9r),e(ym,g9r),e(Ko,h9r),e(Ko,tR),e(tR,u9r),e(tR,XAe),e(XAe,p9r),e(tR,_9r),e(Ko,b9r),e(Ko,Dt),M(aR,Dt,null),e(Dt,v9r),e(Dt,zAe),e(zAe,F9r),e(Dt,T9r),e(Dt,xm),e(xm,M9r),e(xm,QAe),e(QAe,E9r),e(xm,C9r),e(xm,Joe),e(Joe,w9r),e(xm,A9r),e(Dt,L9r),M(g3,Dt,null),e(Ko,y9r),e(Ko,_o),M(nR,_o,null),e(_o,x9r),e(_o,WAe),e(WAe,$9r),e(_o,k9r),e(_o,wn),e(wn,S9r),e(wn,UAe),e(UAe,R9r),e(wn,P9r),e(wn,HAe),e(HAe,B9r),e(wn,I9r),e(wn,JAe),e(JAe,N9r),e(wn,q9r),e(_o,D9r),e(_o,Fe),e(Fe,h3),e(h3,YAe),e(YAe,j9r),e(h3,G9r),e(h3,Yoe),e(Yoe,O9r),e(h3,V9r),e(Fe,X9r),e(Fe,u3),e(u3,ZAe),e(ZAe,z9r),e(u3,Q9r),e(u3,Zoe),e(Zoe,W9r),e(u3,U9r),e(Fe,H9r),e(Fe,p3),e(p3,KAe),e(KAe,J9r),e(p3,Y9r),e(p3,Koe),e(Koe,Z9r),e(p3,K9r),e(Fe,exr),e(Fe,_3),e(_3,e6e),e(e6e,oxr),e(_3,rxr),e(_3,ere),e(ere,txr),e(_3,axr),e(Fe,nxr),e(Fe,Nl),e(Nl,o6e),e(o6e,sxr),e(Nl,lxr),e(Nl,ore),e(ore,ixr),e(Nl,dxr),e(Nl,rre),e(rre,mxr),e(Nl,cxr),e(Fe,fxr),e(Fe,b3),e(b3,r6e),e(r6e,gxr),e(b3,hxr),e(b3,tre),e(tre,uxr),e(b3,pxr),e(Fe,_xr),e(Fe,ql),e(ql,t6e),e(t6e,bxr),e(ql,vxr),e(ql,are),e(are,Fxr),e(ql,Txr),e(ql,nre),e(nre,Mxr),e(ql,Exr),e(Fe,Cxr),e(Fe,v3),e(v3,a6e),e(a6e,wxr),e(v3,Axr),e(v3,sre),e(sre,Lxr),e(v3,yxr),e(Fe,xxr),e(Fe,jt),e(jt,n6e),e(n6e,$xr),e(jt,kxr),e(jt,lre),e(lre,Sxr),e(jt,Rxr),e(jt,ire),e(ire,Pxr),e(jt,Bxr),e(jt,dre),e(dre,Ixr),e(jt,Nxr),e(Fe,qxr),e(Fe,F3),e(F3,s6e),e(s6e,Dxr),e(F3,jxr),e(F3,mre),e(mre,Gxr),e(F3,Oxr),e(Fe,Vxr),e(Fe,T3),e(T3,l6e),e(l6e,Xxr),e(T3,zxr),e(T3,cre),e(cre,Qxr),e(T3,Wxr),e(Fe,Uxr),e(Fe,M3),e(M3,i6e),e(i6e,Hxr),e(M3,Jxr),e(M3,fre),e(fre,Yxr),e(M3,Zxr),e(Fe,Kxr),e(Fe,E3),e(E3,d6e),e(d6e,e$r),e(E3,o$r),e(E3,gre),e(gre,r$r),e(E3,t$r),e(Fe,a$r),e(Fe,C3),e(C3,m6e),e(m6e,n$r),e(C3,s$r),e(C3,hre),e(hre,l$r),e(C3,i$r),e(Fe,d$r),e(Fe,w3),e(w3,c6e),e(c6e,m$r),e(w3,c$r),e(w3,ure),e(ure,f$r),e(w3,g$r),e(Fe,h$r),e(Fe,A3),e(A3,f6e),e(f6e,u$r),e(A3,p$r),e(A3,pre),e(pre,_$r),e(A3,b$r),e(Fe,v$r),e(Fe,L3),e(L3,g6e),e(g6e,F$r),e(L3,T$r),e(L3,_re),e(_re,M$r),e(L3,E$r),e(Fe,C$r),e(Fe,y3),e(y3,h6e),e(h6e,w$r),e(y3,A$r),e(y3,bre),e(bre,L$r),e(y3,y$r),e(_o,x$r),e(_o,x3),e(x3,$$r),e(x3,u6e),e(u6e,k$r),e(x3,S$r),e(x3,p6e),e(p6e,R$r),e(_o,P$r),M($3,_o,null),b(c,oio,_),b(c,$m,_),e($m,k3),e(k3,_6e),M(sR,_6e,null),e($m,B$r),e($m,b6e),e(b6e,I$r),b(c,rio,_),b(c,er,_),M(lR,er,null),e(er,N$r),e(er,km),e(km,q$r),e(km,vre),e(vre,D$r),e(km,j$r),e(km,Fre),e(Fre,G$r),e(km,O$r),e(er,V$r),e(er,iR),e(iR,X$r),e(iR,v6e),e(v6e,z$r),e(iR,Q$r),e(er,W$r),e(er,Gt),M(dR,Gt,null),e(Gt,U$r),e(Gt,F6e),e(F6e,H$r),e(Gt,J$r),e(Gt,Sm),e(Sm,Y$r),e(Sm,T6e),e(T6e,Z$r),e(Sm,K$r),e(Sm,Tre),e(Tre,ekr),e(Sm,okr),e(Gt,rkr),M(S3,Gt,null),e(er,tkr),e(er,bo),M(mR,bo,null),e(bo,akr),e(bo,M6e),e(M6e,nkr),e(bo,skr),e(bo,An),e(An,lkr),e(An,E6e),e(E6e,ikr),e(An,dkr),e(An,C6e),e(C6e,mkr),e(An,ckr),e(An,w6e),e(w6e,fkr),e(An,gkr),e(bo,hkr),e(bo,A6e),e(A6e,R3),e(R3,L6e),e(L6e,ukr),e(R3,pkr),e(R3,Mre),e(Mre,_kr),e(R3,bkr),e(bo,vkr),e(bo,P3),e(P3,Fkr),e(P3,y6e),e(y6e,Tkr),e(P3,Mkr),e(P3,x6e),e(x6e,Ekr),e(bo,Ckr),M(B3,bo,null),b(c,tio,_),b(c,Rm,_),e(Rm,I3),e(I3,$6e),M(cR,$6e,null),e(Rm,wkr),e(Rm,k6e),e(k6e,Akr),b(c,aio,_),b(c,or,_),M(fR,or,null),e(or,Lkr),e(or,Pm),e(Pm,ykr),e(Pm,Ere),e(Ere,xkr),e(Pm,$kr),e(Pm,Cre),e(Cre,kkr),e(Pm,Skr),e(or,Rkr),e(or,gR),e(gR,Pkr),e(gR,S6e),e(S6e,Bkr),e(gR,Ikr),e(or,Nkr),e(or,Ot),M(hR,Ot,null),e(Ot,qkr),e(Ot,R6e),e(R6e,Dkr),e(Ot,jkr),e(Ot,Bm),e(Bm,Gkr),e(Bm,P6e),e(P6e,Okr),e(Bm,Vkr),e(Bm,wre),e(wre,Xkr),e(Bm,zkr),e(Ot,Qkr),M(N3,Ot,null),e(or,Wkr),e(or,vo),M(uR,vo,null),e(vo,Ukr),e(vo,B6e),e(B6e,Hkr),e(vo,Jkr),e(vo,Ln),e(Ln,Ykr),e(Ln,I6e),e(I6e,Zkr),e(Ln,Kkr),e(Ln,N6e),e(N6e,eSr),e(Ln,oSr),e(Ln,q6e),e(q6e,rSr),e(Ln,tSr),e(vo,aSr),e(vo,D6e),e(D6e,q3),e(q3,j6e),e(j6e,nSr),e(q3,sSr),e(q3,Are),e(Are,lSr),e(q3,iSr),e(vo,dSr),e(vo,D3),e(D3,mSr),e(D3,G6e),e(G6e,cSr),e(D3,fSr),e(D3,O6e),e(O6e,gSr),e(vo,hSr),M(j3,vo,null),b(c,nio,_),b(c,Im,_),e(Im,G3),e(G3,V6e),M(pR,V6e,null),e(Im,uSr),e(Im,X6e),e(X6e,pSr),b(c,sio,_),b(c,rr,_),M(_R,rr,null),e(rr,_Sr),e(rr,Nm),e(Nm,bSr),e(Nm,Lre),e(Lre,vSr),e(Nm,FSr),e(Nm,yre),e(yre,TSr),e(Nm,MSr),e(rr,ESr),e(rr,bR),e(bR,CSr),e(bR,z6e),e(z6e,wSr),e(bR,ASr),e(rr,LSr),e(rr,Vt),M(vR,Vt,null),e(Vt,ySr),e(Vt,Q6e),e(Q6e,xSr),e(Vt,$Sr),e(Vt,qm),e(qm,kSr),e(qm,W6e),e(W6e,SSr),e(qm,RSr),e(qm,xre),e(xre,PSr),e(qm,BSr),e(Vt,ISr),M(O3,Vt,null),e(rr,NSr),e(rr,Fo),M(FR,Fo,null),e(Fo,qSr),e(Fo,U6e),e(U6e,DSr),e(Fo,jSr),e(Fo,yn),e(yn,GSr),e(yn,H6e),e(H6e,OSr),e(yn,VSr),e(yn,J6e),e(J6e,XSr),e(yn,zSr),e(yn,Y6e),e(Y6e,QSr),e(yn,WSr),e(Fo,USr),e(Fo,Z6e),e(Z6e,V3),e(V3,K6e),e(K6e,HSr),e(V3,JSr),e(V3,$re),e($re,YSr),e(V3,ZSr),e(Fo,KSr),e(Fo,X3),e(X3,eRr),e(X3,e7e),e(e7e,oRr),e(X3,rRr),e(X3,o7e),e(o7e,tRr),e(Fo,aRr),M(z3,Fo,null),b(c,lio,_),b(c,Dm,_),e(Dm,Q3),e(Q3,r7e),M(TR,r7e,null),e(Dm,nRr),e(Dm,t7e),e(t7e,sRr),b(c,iio,_),b(c,tr,_),M(MR,tr,null),e(tr,lRr),e(tr,jm),e(jm,iRr),e(jm,kre),e(kre,dRr),e(jm,mRr),e(jm,Sre),e(Sre,cRr),e(jm,fRr),e(tr,gRr),e(tr,ER),e(ER,hRr),e(ER,a7e),e(a7e,uRr),e(ER,pRr),e(tr,_Rr),e(tr,Xt),M(CR,Xt,null),e(Xt,bRr),e(Xt,n7e),e(n7e,vRr),e(Xt,FRr),e(Xt,Gm),e(Gm,TRr),e(Gm,s7e),e(s7e,MRr),e(Gm,ERr),e(Gm,Rre),e(Rre,CRr),e(Gm,wRr),e(Xt,ARr),M(W3,Xt,null),e(tr,LRr),e(tr,To),M(wR,To,null),e(To,yRr),e(To,l7e),e(l7e,xRr),e(To,$Rr),e(To,xn),e(xn,kRr),e(xn,i7e),e(i7e,SRr),e(xn,RRr),e(xn,d7e),e(d7e,PRr),e(xn,BRr),e(xn,m7e),e(m7e,IRr),e(xn,NRr),e(To,qRr),e(To,Ne),e(Ne,U3),e(U3,c7e),e(c7e,DRr),e(U3,jRr),e(U3,Pre),e(Pre,GRr),e(U3,ORr),e(Ne,VRr),e(Ne,H3),e(H3,f7e),e(f7e,XRr),e(H3,zRr),e(H3,Bre),e(Bre,QRr),e(H3,WRr),e(Ne,URr),e(Ne,J3),e(J3,g7e),e(g7e,HRr),e(J3,JRr),e(J3,Ire),e(Ire,YRr),e(J3,ZRr),e(Ne,KRr),e(Ne,Y3),e(Y3,h7e),e(h7e,ePr),e(Y3,oPr),e(Y3,Nre),e(Nre,rPr),e(Y3,tPr),e(Ne,aPr),e(Ne,Z3),e(Z3,u7e),e(u7e,nPr),e(Z3,sPr),e(Z3,qre),e(qre,lPr),e(Z3,iPr),e(Ne,dPr),e(Ne,K3),e(K3,p7e),e(p7e,mPr),e(K3,cPr),e(K3,Dre),e(Dre,fPr),e(K3,gPr),e(Ne,hPr),e(Ne,e5),e(e5,_7e),e(_7e,uPr),e(e5,pPr),e(e5,jre),e(jre,_Pr),e(e5,bPr),e(Ne,vPr),e(Ne,o5),e(o5,b7e),e(b7e,FPr),e(o5,TPr),e(o5,Gre),e(Gre,MPr),e(o5,EPr),e(Ne,CPr),e(Ne,r5),e(r5,v7e),e(v7e,wPr),e(r5,APr),e(r5,Ore),e(Ore,LPr),e(r5,yPr),e(To,xPr),e(To,t5),e(t5,$Pr),e(t5,F7e),e(F7e,kPr),e(t5,SPr),e(t5,T7e),e(T7e,RPr),e(To,PPr),M(a5,To,null),b(c,dio,_),b(c,Om,_),e(Om,n5),e(n5,M7e),M(AR,M7e,null),e(Om,BPr),e(Om,E7e),e(E7e,IPr),b(c,mio,_),b(c,ar,_),M(LR,ar,null),e(ar,NPr),e(ar,Vm),e(Vm,qPr),e(Vm,Vre),e(Vre,DPr),e(Vm,jPr),e(Vm,Xre),e(Xre,GPr),e(Vm,OPr),e(ar,VPr),e(ar,yR),e(yR,XPr),e(yR,C7e),e(C7e,zPr),e(yR,QPr),e(ar,WPr),e(ar,zt),M(xR,zt,null),e(zt,UPr),e(zt,w7e),e(w7e,HPr),e(zt,JPr),e(zt,Xm),e(Xm,YPr),e(Xm,A7e),e(A7e,ZPr),e(Xm,KPr),e(Xm,zre),e(zre,eBr),e(Xm,oBr),e(zt,rBr),M(s5,zt,null),e(ar,tBr),e(ar,Mo),M($R,Mo,null),e(Mo,aBr),e(Mo,L7e),e(L7e,nBr),e(Mo,sBr),e(Mo,$n),e($n,lBr),e($n,y7e),e(y7e,iBr),e($n,dBr),e($n,x7e),e(x7e,mBr),e($n,cBr),e($n,$7e),e($7e,fBr),e($n,gBr),e(Mo,hBr),e(Mo,vt),e(vt,l5),e(l5,k7e),e(k7e,uBr),e(l5,pBr),e(l5,Qre),e(Qre,_Br),e(l5,bBr),e(vt,vBr),e(vt,i5),e(i5,S7e),e(S7e,FBr),e(i5,TBr),e(i5,Wre),e(Wre,MBr),e(i5,EBr),e(vt,CBr),e(vt,d5),e(d5,R7e),e(R7e,wBr),e(d5,ABr),e(d5,Ure),e(Ure,LBr),e(d5,yBr),e(vt,xBr),e(vt,m5),e(m5,P7e),e(P7e,$Br),e(m5,kBr),e(m5,Hre),e(Hre,SBr),e(m5,RBr),e(vt,PBr),e(vt,c5),e(c5,B7e),e(B7e,BBr),e(c5,IBr),e(c5,Jre),e(Jre,NBr),e(c5,qBr),e(Mo,DBr),e(Mo,f5),e(f5,jBr),e(f5,I7e),e(I7e,GBr),e(f5,OBr),e(f5,N7e),e(N7e,VBr),e(Mo,XBr),M(g5,Mo,null),b(c,cio,_),b(c,zm,_),e(zm,h5),e(h5,q7e),M(kR,q7e,null),e(zm,zBr),e(zm,D7e),e(D7e,QBr),b(c,fio,_),b(c,nr,_),M(SR,nr,null),e(nr,WBr),e(nr,Qm),e(Qm,UBr),e(Qm,Yre),e(Yre,HBr),e(Qm,JBr),e(Qm,Zre),e(Zre,YBr),e(Qm,ZBr),e(nr,KBr),e(nr,RR),e(RR,eIr),e(RR,j7e),e(j7e,oIr),e(RR,rIr),e(nr,tIr),e(nr,Qt),M(PR,Qt,null),e(Qt,aIr),e(Qt,G7e),e(G7e,nIr),e(Qt,sIr),e(Qt,Wm),e(Wm,lIr),e(Wm,O7e),e(O7e,iIr),e(Wm,dIr),e(Wm,Kre),e(Kre,mIr),e(Wm,cIr),e(Qt,fIr),M(u5,Qt,null),e(nr,gIr),e(nr,Eo),M(BR,Eo,null),e(Eo,hIr),e(Eo,V7e),e(V7e,uIr),e(Eo,pIr),e(Eo,kn),e(kn,_Ir),e(kn,X7e),e(X7e,bIr),e(kn,vIr),e(kn,z7e),e(z7e,FIr),e(kn,TIr),e(kn,Q7e),e(Q7e,MIr),e(kn,EIr),e(Eo,CIr),e(Eo,xe),e(xe,p5),e(p5,W7e),e(W7e,wIr),e(p5,AIr),e(p5,ete),e(ete,LIr),e(p5,yIr),e(xe,xIr),e(xe,_5),e(_5,U7e),e(U7e,$Ir),e(_5,kIr),e(_5,ote),e(ote,SIr),e(_5,RIr),e(xe,PIr),e(xe,b5),e(b5,H7e),e(H7e,BIr),e(b5,IIr),e(b5,rte),e(rte,NIr),e(b5,qIr),e(xe,DIr),e(xe,v5),e(v5,J7e),e(J7e,jIr),e(v5,GIr),e(v5,tte),e(tte,OIr),e(v5,VIr),e(xe,XIr),e(xe,F5),e(F5,Y7e),e(Y7e,zIr),e(F5,QIr),e(F5,ate),e(ate,WIr),e(F5,UIr),e(xe,HIr),e(xe,T5),e(T5,Z7e),e(Z7e,JIr),e(T5,YIr),e(T5,nte),e(nte,ZIr),e(T5,KIr),e(xe,eNr),e(xe,M5),e(M5,K7e),e(K7e,oNr),e(M5,rNr),e(M5,ste),e(ste,tNr),e(M5,aNr),e(xe,nNr),e(xe,E5),e(E5,e8e),e(e8e,sNr),e(E5,lNr),e(E5,lte),e(lte,iNr),e(E5,dNr),e(xe,mNr),e(xe,C5),e(C5,o8e),e(o8e,cNr),e(C5,fNr),e(C5,ite),e(ite,gNr),e(C5,hNr),e(xe,uNr),e(xe,w5),e(w5,r8e),e(r8e,pNr),e(w5,_Nr),e(w5,dte),e(dte,bNr),e(w5,vNr),e(Eo,FNr),e(Eo,A5),e(A5,TNr),e(A5,t8e),e(t8e,MNr),e(A5,ENr),e(A5,a8e),e(a8e,CNr),e(Eo,wNr),M(L5,Eo,null),b(c,gio,_),b(c,Um,_),e(Um,y5),e(y5,n8e),M(IR,n8e,null),e(Um,ANr),e(Um,s8e),e(s8e,LNr),b(c,hio,_),b(c,sr,_),M(NR,sr,null),e(sr,yNr),e(sr,Hm),e(Hm,xNr),e(Hm,mte),e(mte,$Nr),e(Hm,kNr),e(Hm,cte),e(cte,SNr),e(Hm,RNr),e(sr,PNr),e(sr,qR),e(qR,BNr),e(qR,l8e),e(l8e,INr),e(qR,NNr),e(sr,qNr),e(sr,Wt),M(DR,Wt,null),e(Wt,DNr),e(Wt,i8e),e(i8e,jNr),e(Wt,GNr),e(Wt,Jm),e(Jm,ONr),e(Jm,d8e),e(d8e,VNr),e(Jm,XNr),e(Jm,fte),e(fte,zNr),e(Jm,QNr),e(Wt,WNr),M(x5,Wt,null),e(sr,UNr),e(sr,Co),M(jR,Co,null),e(Co,HNr),e(Co,m8e),e(m8e,JNr),e(Co,YNr),e(Co,Sn),e(Sn,ZNr),e(Sn,c8e),e(c8e,KNr),e(Sn,eqr),e(Sn,f8e),e(f8e,oqr),e(Sn,rqr),e(Sn,g8e),e(g8e,tqr),e(Sn,aqr),e(Co,nqr),e(Co,Ym),e(Ym,$5),e($5,h8e),e(h8e,sqr),e($5,lqr),e($5,gte),e(gte,iqr),e($5,dqr),e(Ym,mqr),e(Ym,k5),e(k5,u8e),e(u8e,cqr),e(k5,fqr),e(k5,hte),e(hte,gqr),e(k5,hqr),e(Ym,uqr),e(Ym,S5),e(S5,p8e),e(p8e,pqr),e(S5,_qr),e(S5,ute),e(ute,bqr),e(S5,vqr),e(Co,Fqr),e(Co,R5),e(R5,Tqr),e(R5,_8e),e(_8e,Mqr),e(R5,Eqr),e(R5,b8e),e(b8e,Cqr),e(Co,wqr),M(P5,Co,null),b(c,uio,_),b(c,Zm,_),e(Zm,B5),e(B5,v8e),M(GR,v8e,null),e(Zm,Aqr),e(Zm,F8e),e(F8e,Lqr),b(c,pio,_),b(c,lr,_),M(OR,lr,null),e(lr,yqr),e(lr,Km),e(Km,xqr),e(Km,pte),e(pte,$qr),e(Km,kqr),e(Km,_te),e(_te,Sqr),e(Km,Rqr),e(lr,Pqr),e(lr,VR),e(VR,Bqr),e(VR,T8e),e(T8e,Iqr),e(VR,Nqr),e(lr,qqr),e(lr,Ut),M(XR,Ut,null),e(Ut,Dqr),e(Ut,M8e),e(M8e,jqr),e(Ut,Gqr),e(Ut,ec),e(ec,Oqr),e(ec,E8e),e(E8e,Vqr),e(ec,Xqr),e(ec,bte),e(bte,zqr),e(ec,Qqr),e(Ut,Wqr),M(I5,Ut,null),e(lr,Uqr),e(lr,wo),M(zR,wo,null),e(wo,Hqr),e(wo,C8e),e(C8e,Jqr),e(wo,Yqr),e(wo,Rn),e(Rn,Zqr),e(Rn,w8e),e(w8e,Kqr),e(Rn,eDr),e(Rn,A8e),e(A8e,oDr),e(Rn,rDr),e(Rn,L8e),e(L8e,tDr),e(Rn,aDr),e(wo,nDr),e(wo,Ft),e(Ft,N5),e(N5,y8e),e(y8e,sDr),e(N5,lDr),e(N5,vte),e(vte,iDr),e(N5,dDr),e(Ft,mDr),e(Ft,q5),e(q5,x8e),e(x8e,cDr),e(q5,fDr),e(q5,Fte),e(Fte,gDr),e(q5,hDr),e(Ft,uDr),e(Ft,D5),e(D5,$8e),e($8e,pDr),e(D5,_Dr),e(D5,Tte),e(Tte,bDr),e(D5,vDr),e(Ft,FDr),e(Ft,j5),e(j5,k8e),e(k8e,TDr),e(j5,MDr),e(j5,Mte),e(Mte,EDr),e(j5,CDr),e(Ft,wDr),e(Ft,G5),e(G5,S8e),e(S8e,ADr),e(G5,LDr),e(G5,Ete),e(Ete,yDr),e(G5,xDr),e(wo,$Dr),e(wo,O5),e(O5,kDr),e(O5,R8e),e(R8e,SDr),e(O5,RDr),e(O5,P8e),e(P8e,PDr),e(wo,BDr),M(V5,wo,null),b(c,_io,_),b(c,oc,_),e(oc,X5),e(X5,B8e),M(QR,B8e,null),e(oc,IDr),e(oc,I8e),e(I8e,NDr),b(c,bio,_),b(c,ir,_),M(WR,ir,null),e(ir,qDr),e(ir,rc),e(rc,DDr),e(rc,Cte),e(Cte,jDr),e(rc,GDr),e(rc,wte),e(wte,ODr),e(rc,VDr),e(ir,XDr),e(ir,UR),e(UR,zDr),e(UR,N8e),e(N8e,QDr),e(UR,WDr),e(ir,UDr),e(ir,Ht),M(HR,Ht,null),e(Ht,HDr),e(Ht,q8e),e(q8e,JDr),e(Ht,YDr),e(Ht,tc),e(tc,ZDr),e(tc,D8e),e(D8e,KDr),e(tc,ejr),e(tc,Ate),e(Ate,ojr),e(tc,rjr),e(Ht,tjr),M(z5,Ht,null),e(ir,ajr),e(ir,Ao),M(JR,Ao,null),e(Ao,njr),e(Ao,j8e),e(j8e,sjr),e(Ao,ljr),e(Ao,Pn),e(Pn,ijr),e(Pn,G8e),e(G8e,djr),e(Pn,mjr),e(Pn,O8e),e(O8e,cjr),e(Pn,fjr),e(Pn,V8e),e(V8e,gjr),e(Pn,hjr),e(Ao,ujr),e(Ao,Bn),e(Bn,Q5),e(Q5,X8e),e(X8e,pjr),e(Q5,_jr),e(Q5,Lte),e(Lte,bjr),e(Q5,vjr),e(Bn,Fjr),e(Bn,W5),e(W5,z8e),e(z8e,Tjr),e(W5,Mjr),e(W5,yte),e(yte,Ejr),e(W5,Cjr),e(Bn,wjr),e(Bn,U5),e(U5,Q8e),e(Q8e,Ajr),e(U5,Ljr),e(U5,xte),e(xte,yjr),e(U5,xjr),e(Bn,$jr),e(Bn,H5),e(H5,W8e),e(W8e,kjr),e(H5,Sjr),e(H5,$te),e($te,Rjr),e(H5,Pjr),e(Ao,Bjr),e(Ao,J5),e(J5,Ijr),e(J5,U8e),e(U8e,Njr),e(J5,qjr),e(J5,H8e),e(H8e,Djr),e(Ao,jjr),M(Y5,Ao,null),b(c,vio,_),b(c,ac,_),e(ac,Z5),e(Z5,J8e),M(YR,J8e,null),e(ac,Gjr),e(ac,Y8e),e(Y8e,Ojr),b(c,Fio,_),b(c,dr,_),M(ZR,dr,null),e(dr,Vjr),e(dr,nc),e(nc,Xjr),e(nc,kte),e(kte,zjr),e(nc,Qjr),e(nc,Ste),e(Ste,Wjr),e(nc,Ujr),e(dr,Hjr),e(dr,KR),e(KR,Jjr),e(KR,Z8e),e(Z8e,Yjr),e(KR,Zjr),e(dr,Kjr),e(dr,Jt),M(eP,Jt,null),e(Jt,eGr),e(Jt,K8e),e(K8e,oGr),e(Jt,rGr),e(Jt,sc),e(sc,tGr),e(sc,eLe),e(eLe,aGr),e(sc,nGr),e(sc,Rte),e(Rte,sGr),e(sc,lGr),e(Jt,iGr),M(K5,Jt,null),e(dr,dGr),e(dr,Lo),M(oP,Lo,null),e(Lo,mGr),e(Lo,oLe),e(oLe,cGr),e(Lo,fGr),e(Lo,In),e(In,gGr),e(In,rLe),e(rLe,hGr),e(In,uGr),e(In,tLe),e(tLe,pGr),e(In,_Gr),e(In,aLe),e(aLe,bGr),e(In,vGr),e(Lo,FGr),e(Lo,Tt),e(Tt,e0),e(e0,nLe),e(nLe,TGr),e(e0,MGr),e(e0,Pte),e(Pte,EGr),e(e0,CGr),e(Tt,wGr),e(Tt,o0),e(o0,sLe),e(sLe,AGr),e(o0,LGr),e(o0,Bte),e(Bte,yGr),e(o0,xGr),e(Tt,$Gr),e(Tt,r0),e(r0,lLe),e(lLe,kGr),e(r0,SGr),e(r0,Ite),e(Ite,RGr),e(r0,PGr),e(Tt,BGr),e(Tt,t0),e(t0,iLe),e(iLe,IGr),e(t0,NGr),e(t0,Nte),e(Nte,qGr),e(t0,DGr),e(Tt,jGr),e(Tt,a0),e(a0,dLe),e(dLe,GGr),e(a0,OGr),e(a0,qte),e(qte,VGr),e(a0,XGr),e(Lo,zGr),e(Lo,n0),e(n0,QGr),e(n0,mLe),e(mLe,WGr),e(n0,UGr),e(n0,cLe),e(cLe,HGr),e(Lo,JGr),M(s0,Lo,null),b(c,Tio,_),b(c,lc,_),e(lc,l0),e(l0,fLe),M(rP,fLe,null),e(lc,YGr),e(lc,gLe),e(gLe,ZGr),b(c,Mio,_),b(c,mr,_),M(tP,mr,null),e(mr,KGr),e(mr,ic),e(ic,eOr),e(ic,Dte),e(Dte,oOr),e(ic,rOr),e(ic,jte),e(jte,tOr),e(ic,aOr),e(mr,nOr),e(mr,aP),e(aP,sOr),e(aP,hLe),e(hLe,lOr),e(aP,iOr),e(mr,dOr),e(mr,Yt),M(nP,Yt,null),e(Yt,mOr),e(Yt,uLe),e(uLe,cOr),e(Yt,fOr),e(Yt,dc),e(dc,gOr),e(dc,pLe),e(pLe,hOr),e(dc,uOr),e(dc,Gte),e(Gte,pOr),e(dc,_Or),e(Yt,bOr),M(i0,Yt,null),e(mr,vOr),e(mr,yo),M(sP,yo,null),e(yo,FOr),e(yo,_Le),e(_Le,TOr),e(yo,MOr),e(yo,Nn),e(Nn,EOr),e(Nn,bLe),e(bLe,COr),e(Nn,wOr),e(Nn,vLe),e(vLe,AOr),e(Nn,LOr),e(Nn,FLe),e(FLe,yOr),e(Nn,xOr),e(yo,$Or),e(yo,TLe),e(TLe,d0),e(d0,MLe),e(MLe,kOr),e(d0,SOr),e(d0,Ote),e(Ote,ROr),e(d0,POr),e(yo,BOr),e(yo,m0),e(m0,IOr),e(m0,ELe),e(ELe,NOr),e(m0,qOr),e(m0,CLe),e(CLe,DOr),e(yo,jOr),M(c0,yo,null),b(c,Eio,_),b(c,mc,_),e(mc,f0),e(f0,wLe),M(lP,wLe,null),e(mc,GOr),e(mc,ALe),e(ALe,OOr),b(c,Cio,_),b(c,cr,_),M(iP,cr,null),e(cr,VOr),e(cr,cc),e(cc,XOr),e(cc,Vte),e(Vte,zOr),e(cc,QOr),e(cc,Xte),e(Xte,WOr),e(cc,UOr),e(cr,HOr),e(cr,dP),e(dP,JOr),e(dP,LLe),e(LLe,YOr),e(dP,ZOr),e(cr,KOr),e(cr,Zt),M(mP,Zt,null),e(Zt,eVr),e(Zt,yLe),e(yLe,oVr),e(Zt,rVr),e(Zt,fc),e(fc,tVr),e(fc,xLe),e(xLe,aVr),e(fc,nVr),e(fc,zte),e(zte,sVr),e(fc,lVr),e(Zt,iVr),M(g0,Zt,null),e(cr,dVr),e(cr,xo),M(cP,xo,null),e(xo,mVr),e(xo,$Le),e($Le,cVr),e(xo,fVr),e(xo,qn),e(qn,gVr),e(qn,kLe),e(kLe,hVr),e(qn,uVr),e(qn,SLe),e(SLe,pVr),e(qn,_Vr),e(qn,RLe),e(RLe,bVr),e(qn,vVr),e(xo,FVr),e(xo,Mt),e(Mt,h0),e(h0,PLe),e(PLe,TVr),e(h0,MVr),e(h0,Qte),e(Qte,EVr),e(h0,CVr),e(Mt,wVr),e(Mt,u0),e(u0,BLe),e(BLe,AVr),e(u0,LVr),e(u0,Wte),e(Wte,yVr),e(u0,xVr),e(Mt,$Vr),e(Mt,p0),e(p0,ILe),e(ILe,kVr),e(p0,SVr),e(p0,Ute),e(Ute,RVr),e(p0,PVr),e(Mt,BVr),e(Mt,_0),e(_0,NLe),e(NLe,IVr),e(_0,NVr),e(_0,Hte),e(Hte,qVr),e(_0,DVr),e(Mt,jVr),e(Mt,b0),e(b0,qLe),e(qLe,GVr),e(b0,OVr),e(b0,Jte),e(Jte,VVr),e(b0,XVr),e(xo,zVr),e(xo,v0),e(v0,QVr),e(v0,DLe),e(DLe,WVr),e(v0,UVr),e(v0,jLe),e(jLe,HVr),e(xo,JVr),M(F0,xo,null),b(c,wio,_),b(c,gc,_),e(gc,T0),e(T0,GLe),M(fP,GLe,null),e(gc,YVr),e(gc,OLe),e(OLe,ZVr),b(c,Aio,_),b(c,fr,_),M(gP,fr,null),e(fr,KVr),e(fr,hc),e(hc,eXr),e(hc,Yte),e(Yte,oXr),e(hc,rXr),e(hc,Zte),e(Zte,tXr),e(hc,aXr),e(fr,nXr),e(fr,hP),e(hP,sXr),e(hP,VLe),e(VLe,lXr),e(hP,iXr),e(fr,dXr),e(fr,Kt),M(uP,Kt,null),e(Kt,mXr),e(Kt,XLe),e(XLe,cXr),e(Kt,fXr),e(Kt,uc),e(uc,gXr),e(uc,zLe),e(zLe,hXr),e(uc,uXr),e(uc,Kte),e(Kte,pXr),e(uc,_Xr),e(Kt,bXr),M(M0,Kt,null),e(fr,vXr),e(fr,$o),M(pP,$o,null),e($o,FXr),e($o,QLe),e(QLe,TXr),e($o,MXr),e($o,Dn),e(Dn,EXr),e(Dn,WLe),e(WLe,CXr),e(Dn,wXr),e(Dn,ULe),e(ULe,AXr),e(Dn,LXr),e(Dn,HLe),e(HLe,yXr),e(Dn,xXr),e($o,$Xr),e($o,JLe),e(JLe,E0),e(E0,YLe),e(YLe,kXr),e(E0,SXr),e(E0,eae),e(eae,RXr),e(E0,PXr),e($o,BXr),e($o,C0),e(C0,IXr),e(C0,ZLe),e(ZLe,NXr),e(C0,qXr),e(C0,KLe),e(KLe,DXr),e($o,jXr),M(w0,$o,null),b(c,Lio,_),b(c,pc,_),e(pc,A0),e(A0,eye),M(_P,eye,null),e(pc,GXr),e(pc,oye),e(oye,OXr),b(c,yio,_),b(c,gr,_),M(bP,gr,null),e(gr,VXr),e(gr,_c),e(_c,XXr),e(_c,oae),e(oae,zXr),e(_c,QXr),e(_c,rae),e(rae,WXr),e(_c,UXr),e(gr,HXr),e(gr,vP),e(vP,JXr),e(vP,rye),e(rye,YXr),e(vP,ZXr),e(gr,KXr),e(gr,ea),M(FP,ea,null),e(ea,ezr),e(ea,tye),e(tye,ozr),e(ea,rzr),e(ea,bc),e(bc,tzr),e(bc,aye),e(aye,azr),e(bc,nzr),e(bc,tae),e(tae,szr),e(bc,lzr),e(ea,izr),M(L0,ea,null),e(gr,dzr),e(gr,ko),M(TP,ko,null),e(ko,mzr),e(ko,nye),e(nye,czr),e(ko,fzr),e(ko,jn),e(jn,gzr),e(jn,sye),e(sye,hzr),e(jn,uzr),e(jn,lye),e(lye,pzr),e(jn,_zr),e(jn,iye),e(iye,bzr),e(jn,vzr),e(ko,Fzr),e(ko,dye),e(dye,y0),e(y0,mye),e(mye,Tzr),e(y0,Mzr),e(y0,aae),e(aae,Ezr),e(y0,Czr),e(ko,wzr),e(ko,x0),e(x0,Azr),e(x0,cye),e(cye,Lzr),e(x0,yzr),e(x0,fye),e(fye,xzr),e(ko,$zr),M($0,ko,null),b(c,xio,_),b(c,vc,_),e(vc,k0),e(k0,gye),M(MP,gye,null),e(vc,kzr),e(vc,hye),e(hye,Szr),b(c,$io,_),b(c,hr,_),M(EP,hr,null),e(hr,Rzr),e(hr,Fc),e(Fc,Pzr),e(Fc,nae),e(nae,Bzr),e(Fc,Izr),e(Fc,sae),e(sae,Nzr),e(Fc,qzr),e(hr,Dzr),e(hr,CP),e(CP,jzr),e(CP,uye),e(uye,Gzr),e(CP,Ozr),e(hr,Vzr),e(hr,oa),M(wP,oa,null),e(oa,Xzr),e(oa,pye),e(pye,zzr),e(oa,Qzr),e(oa,Tc),e(Tc,Wzr),e(Tc,_ye),e(_ye,Uzr),e(Tc,Hzr),e(Tc,lae),e(lae,Jzr),e(Tc,Yzr),e(oa,Zzr),M(S0,oa,null),e(hr,Kzr),e(hr,Xr),M(AP,Xr,null),e(Xr,eQr),e(Xr,bye),e(bye,oQr),e(Xr,rQr),e(Xr,Gn),e(Gn,tQr),e(Gn,vye),e(vye,aQr),e(Gn,nQr),e(Gn,Fye),e(Fye,sQr),e(Gn,lQr),e(Gn,Tye),e(Tye,iQr),e(Gn,dQr),e(Xr,mQr),e(Xr,P),e(P,R0),e(R0,Mye),e(Mye,cQr),e(R0,fQr),e(R0,iae),e(iae,gQr),e(R0,hQr),e(P,uQr),e(P,P0),e(P0,Eye),e(Eye,pQr),e(P0,_Qr),e(P0,dae),e(dae,bQr),e(P0,vQr),e(P,FQr),e(P,B0),e(B0,Cye),e(Cye,TQr),e(B0,MQr),e(B0,mae),e(mae,EQr),e(B0,CQr),e(P,wQr),e(P,I0),e(I0,wye),e(wye,AQr),e(I0,LQr),e(I0,cae),e(cae,yQr),e(I0,xQr),e(P,$Qr),e(P,N0),e(N0,Aye),e(Aye,kQr),e(N0,SQr),e(N0,fae),e(fae,RQr),e(N0,PQr),e(P,BQr),e(P,q0),e(q0,Lye),e(Lye,IQr),e(q0,NQr),e(q0,gae),e(gae,qQr),e(q0,DQr),e(P,jQr),e(P,D0),e(D0,yye),e(yye,GQr),e(D0,OQr),e(D0,hae),e(hae,VQr),e(D0,XQr),e(P,zQr),e(P,j0),e(j0,xye),e(xye,QQr),e(j0,WQr),e(j0,uae),e(uae,UQr),e(j0,HQr),e(P,JQr),e(P,G0),e(G0,$ye),e($ye,YQr),e(G0,ZQr),e(G0,pae),e(pae,KQr),e(G0,eWr),e(P,oWr),e(P,O0),e(O0,kye),e(kye,rWr),e(O0,tWr),e(O0,_ae),e(_ae,aWr),e(O0,nWr),e(P,sWr),e(P,V0),e(V0,Sye),e(Sye,lWr),e(V0,iWr),e(V0,bae),e(bae,dWr),e(V0,mWr),e(P,cWr),e(P,X0),e(X0,Rye),e(Rye,fWr),e(X0,gWr),e(X0,vae),e(vae,hWr),e(X0,uWr),e(P,pWr),e(P,z0),e(z0,Pye),e(Pye,_Wr),e(z0,bWr),e(z0,Fae),e(Fae,vWr),e(z0,FWr),e(P,TWr),e(P,Q0),e(Q0,Bye),e(Bye,MWr),e(Q0,EWr),e(Q0,Tae),e(Tae,CWr),e(Q0,wWr),e(P,AWr),e(P,W0),e(W0,Iye),e(Iye,LWr),e(W0,yWr),e(W0,Mae),e(Mae,xWr),e(W0,$Wr),e(P,kWr),e(P,U0),e(U0,Nye),e(Nye,SWr),e(U0,RWr),e(U0,Eae),e(Eae,PWr),e(U0,BWr),e(P,IWr),e(P,H0),e(H0,qye),e(qye,NWr),e(H0,qWr),e(H0,Cae),e(Cae,DWr),e(H0,jWr),e(P,GWr),e(P,J0),e(J0,Dye),e(Dye,OWr),e(J0,VWr),e(J0,wae),e(wae,XWr),e(J0,zWr),e(P,QWr),e(P,Y0),e(Y0,jye),e(jye,WWr),e(Y0,UWr),e(Y0,Aae),e(Aae,HWr),e(Y0,JWr),e(P,YWr),e(P,Z0),e(Z0,Gye),e(Gye,ZWr),e(Z0,KWr),e(Z0,Lae),e(Lae,eUr),e(Z0,oUr),e(P,rUr),e(P,Dl),e(Dl,Oye),e(Oye,tUr),e(Dl,aUr),e(Dl,yae),e(yae,nUr),e(Dl,sUr),e(Dl,xae),e(xae,lUr),e(Dl,iUr),e(P,dUr),e(P,K0),e(K0,Vye),e(Vye,mUr),e(K0,cUr),e(K0,$ae),e($ae,fUr),e(K0,gUr),e(P,hUr),e(P,ew),e(ew,Xye),e(Xye,uUr),e(ew,pUr),e(ew,kae),e(kae,_Ur),e(ew,bUr),e(P,vUr),e(P,ow),e(ow,zye),e(zye,FUr),e(ow,TUr),e(ow,Sae),e(Sae,MUr),e(ow,EUr),e(P,CUr),e(P,rw),e(rw,Qye),e(Qye,wUr),e(rw,AUr),e(rw,Rae),e(Rae,LUr),e(rw,yUr),e(P,xUr),e(P,tw),e(tw,Wye),e(Wye,$Ur),e(tw,kUr),e(tw,Pae),e(Pae,SUr),e(tw,RUr),e(P,PUr),e(P,aw),e(aw,Uye),e(Uye,BUr),e(aw,IUr),e(aw,Bae),e(Bae,NUr),e(aw,qUr),e(P,DUr),e(P,nw),e(nw,Hye),e(Hye,jUr),e(nw,GUr),e(nw,Iae),e(Iae,OUr),e(nw,VUr),e(P,XUr),e(P,sw),e(sw,Jye),e(Jye,zUr),e(sw,QUr),e(sw,Nae),e(Nae,WUr),e(sw,UUr),e(P,HUr),e(P,lw),e(lw,Yye),e(Yye,JUr),e(lw,YUr),e(lw,qae),e(qae,ZUr),e(lw,KUr),e(P,eHr),e(P,iw),e(iw,Zye),e(Zye,oHr),e(iw,rHr),e(iw,Dae),e(Dae,tHr),e(iw,aHr),e(P,nHr),e(P,dw),e(dw,Kye),e(Kye,sHr),e(dw,lHr),e(dw,jae),e(jae,iHr),e(dw,dHr),e(P,mHr),e(P,mw),e(mw,e9e),e(e9e,cHr),e(mw,fHr),e(mw,Gae),e(Gae,gHr),e(mw,hHr),e(P,uHr),e(P,cw),e(cw,o9e),e(o9e,pHr),e(cw,_Hr),e(cw,Oae),e(Oae,bHr),e(cw,vHr),e(P,FHr),e(P,fw),e(fw,r9e),e(r9e,THr),e(fw,MHr),e(fw,Vae),e(Vae,EHr),e(fw,CHr),e(P,wHr),e(P,gw),e(gw,t9e),e(t9e,AHr),e(gw,LHr),e(gw,Xae),e(Xae,yHr),e(gw,xHr),e(P,$Hr),e(P,hw),e(hw,a9e),e(a9e,kHr),e(hw,SHr),e(hw,zae),e(zae,RHr),e(hw,PHr),e(P,BHr),e(P,uw),e(uw,n9e),e(n9e,IHr),e(uw,NHr),e(uw,Qae),e(Qae,qHr),e(uw,DHr),e(P,jHr),e(P,pw),e(pw,s9e),e(s9e,GHr),e(pw,OHr),e(pw,Wae),e(Wae,VHr),e(pw,XHr),e(P,zHr),e(P,_w),e(_w,l9e),e(l9e,QHr),e(_w,WHr),e(_w,Uae),e(Uae,UHr),e(_w,HHr),e(P,JHr),e(P,bw),e(bw,i9e),e(i9e,YHr),e(bw,ZHr),e(bw,Hae),e(Hae,KHr),e(bw,eJr),e(P,oJr),e(P,vw),e(vw,d9e),e(d9e,rJr),e(vw,tJr),e(vw,Jae),e(Jae,aJr),e(vw,nJr),e(P,sJr),e(P,Fw),e(Fw,m9e),e(m9e,lJr),e(Fw,iJr),e(Fw,Yae),e(Yae,dJr),e(Fw,mJr),e(P,cJr),e(P,Tw),e(Tw,c9e),e(c9e,fJr),e(Tw,gJr),e(Tw,Zae),e(Zae,hJr),e(Tw,uJr),e(P,pJr),e(P,Mw),e(Mw,f9e),e(f9e,_Jr),e(Mw,bJr),e(Mw,Kae),e(Kae,vJr),e(Mw,FJr),e(P,TJr),e(P,Ew),e(Ew,g9e),e(g9e,MJr),e(Ew,EJr),e(Ew,ene),e(ene,CJr),e(Ew,wJr),e(P,AJr),e(P,Cw),e(Cw,h9e),e(h9e,LJr),e(Cw,yJr),e(Cw,one),e(one,xJr),e(Cw,$Jr),e(P,kJr),e(P,ww),e(ww,u9e),e(u9e,SJr),e(ww,RJr),e(ww,rne),e(rne,PJr),e(ww,BJr),e(P,IJr),e(P,Aw),e(Aw,p9e),e(p9e,NJr),e(Aw,qJr),e(Aw,tne),e(tne,DJr),e(Aw,jJr),e(P,GJr),e(P,Lw),e(Lw,_9e),e(_9e,OJr),e(Lw,VJr),e(Lw,ane),e(ane,XJr),e(Lw,zJr),e(P,QJr),e(P,yw),e(yw,b9e),e(b9e,WJr),e(yw,UJr),e(yw,nne),e(nne,HJr),e(yw,JJr),e(P,YJr),e(P,xw),e(xw,v9e),e(v9e,ZJr),e(xw,KJr),e(xw,sne),e(sne,eYr),e(xw,oYr),e(P,rYr),e(P,$w),e($w,F9e),e(F9e,tYr),e($w,aYr),e($w,lne),e(lne,nYr),e($w,sYr),e(P,lYr),e(P,kw),e(kw,T9e),e(T9e,iYr),e(kw,dYr),e(kw,ine),e(ine,mYr),e(kw,cYr),e(P,fYr),e(P,Sw),e(Sw,M9e),e(M9e,gYr),e(Sw,hYr),e(Sw,dne),e(dne,uYr),e(Sw,pYr),e(P,_Yr),e(P,Rw),e(Rw,E9e),e(E9e,bYr),e(Rw,vYr),e(Rw,mne),e(mne,FYr),e(Rw,TYr),e(P,MYr),e(P,Pw),e(Pw,C9e),e(C9e,EYr),e(Pw,CYr),e(Pw,cne),e(cne,wYr),e(Pw,AYr),e(P,LYr),e(P,Bw),e(Bw,w9e),e(w9e,yYr),e(Bw,xYr),e(Bw,fne),e(fne,$Yr),e(Bw,kYr),e(Xr,SYr),M(Iw,Xr,null),b(c,kio,_),b(c,Mc,_),e(Mc,Nw),e(Nw,A9e),M(LP,A9e,null),e(Mc,RYr),e(Mc,L9e),e(L9e,PYr),b(c,Sio,_),b(c,ur,_),M(yP,ur,null),e(ur,BYr),e(ur,Ec),e(Ec,IYr),e(Ec,gne),e(gne,NYr),e(Ec,qYr),e(Ec,hne),e(hne,DYr),e(Ec,jYr),e(ur,GYr),e(ur,xP),e(xP,OYr),e(xP,y9e),e(y9e,VYr),e(xP,XYr),e(ur,zYr),e(ur,ra),M($P,ra,null),e(ra,QYr),e(ra,x9e),e(x9e,WYr),e(ra,UYr),e(ra,Cc),e(Cc,HYr),e(Cc,$9e),e($9e,JYr),e(Cc,YYr),e(Cc,une),e(une,ZYr),e(Cc,KYr),e(ra,eZr),M(qw,ra,null),e(ur,oZr),e(ur,zr),M(kP,zr,null),e(zr,rZr),e(zr,k9e),e(k9e,tZr),e(zr,aZr),e(zr,On),e(On,nZr),e(On,S9e),e(S9e,sZr),e(On,lZr),e(On,R9e),e(R9e,iZr),e(On,dZr),e(On,P9e),e(P9e,mZr),e(On,cZr),e(zr,fZr),e(zr,de),e(de,Dw),e(Dw,B9e),e(B9e,gZr),e(Dw,hZr),e(Dw,pne),e(pne,uZr),e(Dw,pZr),e(de,_Zr),e(de,jw),e(jw,I9e),e(I9e,bZr),e(jw,vZr),e(jw,_ne),e(_ne,FZr),e(jw,TZr),e(de,MZr),e(de,Gw),e(Gw,N9e),e(N9e,EZr),e(Gw,CZr),e(Gw,bne),e(bne,wZr),e(Gw,AZr),e(de,LZr),e(de,Ow),e(Ow,q9e),e(q9e,yZr),e(Ow,xZr),e(Ow,vne),e(vne,$Zr),e(Ow,kZr),e(de,SZr),e(de,Vw),e(Vw,D9e),e(D9e,RZr),e(Vw,PZr),e(Vw,Fne),e(Fne,BZr),e(Vw,IZr),e(de,NZr),e(de,Xw),e(Xw,j9e),e(j9e,qZr),e(Xw,DZr),e(Xw,Tne),e(Tne,jZr),e(Xw,GZr),e(de,OZr),e(de,zw),e(zw,G9e),e(G9e,VZr),e(zw,XZr),e(zw,Mne),e(Mne,zZr),e(zw,QZr),e(de,WZr),e(de,Qw),e(Qw,O9e),e(O9e,UZr),e(Qw,HZr),e(Qw,Ene),e(Ene,JZr),e(Qw,YZr),e(de,ZZr),e(de,Ww),e(Ww,V9e),e(V9e,KZr),e(Ww,eKr),e(Ww,Cne),e(Cne,oKr),e(Ww,rKr),e(de,tKr),e(de,Uw),e(Uw,X9e),e(X9e,aKr),e(Uw,nKr),e(Uw,wne),e(wne,sKr),e(Uw,lKr),e(de,iKr),e(de,Hw),e(Hw,z9e),e(z9e,dKr),e(Hw,mKr),e(Hw,Ane),e(Ane,cKr),e(Hw,fKr),e(de,gKr),e(de,Jw),e(Jw,Q9e),e(Q9e,hKr),e(Jw,uKr),e(Jw,Lne),e(Lne,pKr),e(Jw,_Kr),e(de,bKr),e(de,Yw),e(Yw,W9e),e(W9e,vKr),e(Yw,FKr),e(Yw,yne),e(yne,TKr),e(Yw,MKr),e(de,EKr),e(de,Zw),e(Zw,U9e),e(U9e,CKr),e(Zw,wKr),e(Zw,xne),e(xne,AKr),e(Zw,LKr),e(de,yKr),e(de,Kw),e(Kw,H9e),e(H9e,xKr),e(Kw,$Kr),e(Kw,$ne),e($ne,kKr),e(Kw,SKr),e(de,RKr),e(de,eA),e(eA,J9e),e(J9e,PKr),e(eA,BKr),e(eA,kne),e(kne,IKr),e(eA,NKr),e(de,qKr),e(de,oA),e(oA,Y9e),e(Y9e,DKr),e(oA,jKr),e(oA,Sne),e(Sne,GKr),e(oA,OKr),e(de,VKr),e(de,rA),e(rA,Z9e),e(Z9e,XKr),e(rA,zKr),e(rA,Rne),e(Rne,QKr),e(rA,WKr),e(de,UKr),e(de,tA),e(tA,K9e),e(K9e,HKr),e(tA,JKr),e(tA,Pne),e(Pne,YKr),e(tA,ZKr),e(de,KKr),e(de,aA),e(aA,exe),e(exe,eet),e(aA,oet),e(aA,Bne),e(Bne,ret),e(aA,tet),e(de,aet),e(de,nA),e(nA,oxe),e(oxe,net),e(nA,set),e(nA,Ine),e(Ine,iet),e(nA,det),e(de,met),e(de,sA),e(sA,rxe),e(rxe,cet),e(sA,fet),e(sA,Nne),e(Nne,get),e(sA,het),e(de,uet),e(de,lA),e(lA,txe),e(txe,pet),e(lA,_et),e(lA,qne),e(qne,bet),e(lA,vet),e(zr,Fet),M(iA,zr,null),b(c,Rio,_),b(c,wc,_),e(wc,dA),e(dA,axe),M(SP,axe,null),e(wc,Tet),e(wc,nxe),e(nxe,Met),b(c,Pio,_),b(c,pr,_),M(RP,pr,null),e(pr,Eet),e(pr,Ac),e(Ac,Cet),e(Ac,Dne),e(Dne,wet),e(Ac,Aet),e(Ac,jne),e(jne,Let),e(Ac,yet),e(pr,xet),e(pr,PP),e(PP,$et),e(PP,sxe),e(sxe,ket),e(PP,Set),e(pr,Ret),e(pr,ta),M(BP,ta,null),e(ta,Pet),e(ta,lxe),e(lxe,Bet),e(ta,Iet),e(ta,Lc),e(Lc,Net),e(Lc,ixe),e(ixe,qet),e(Lc,Det),e(Lc,Gne),e(Gne,jet),e(Lc,Get),e(ta,Oet),M(mA,ta,null),e(pr,Vet),e(pr,Qr),M(IP,Qr,null),e(Qr,Xet),e(Qr,dxe),e(dxe,zet),e(Qr,Qet),e(Qr,Vn),e(Vn,Wet),e(Vn,mxe),e(mxe,Uet),e(Vn,Het),e(Vn,cxe),e(cxe,Jet),e(Vn,Yet),e(Vn,fxe),e(fxe,Zet),e(Vn,Ket),e(Qr,eot),e(Qr,Ce),e(Ce,cA),e(cA,gxe),e(gxe,oot),e(cA,rot),e(cA,One),e(One,tot),e(cA,aot),e(Ce,not),e(Ce,fA),e(fA,hxe),e(hxe,sot),e(fA,lot),e(fA,Vne),e(Vne,iot),e(fA,dot),e(Ce,mot),e(Ce,gA),e(gA,uxe),e(uxe,cot),e(gA,fot),e(gA,Xne),e(Xne,got),e(gA,hot),e(Ce,uot),e(Ce,hA),e(hA,pxe),e(pxe,pot),e(hA,_ot),e(hA,zne),e(zne,bot),e(hA,vot),e(Ce,Fot),e(Ce,uA),e(uA,_xe),e(_xe,Tot),e(uA,Mot),e(uA,Qne),e(Qne,Eot),e(uA,Cot),e(Ce,wot),e(Ce,pA),e(pA,bxe),e(bxe,Aot),e(pA,Lot),e(pA,Wne),e(Wne,yot),e(pA,xot),e(Ce,$ot),e(Ce,_A),e(_A,vxe),e(vxe,kot),e(_A,Sot),e(_A,Une),e(Une,Rot),e(_A,Pot),e(Ce,Bot),e(Ce,bA),e(bA,Fxe),e(Fxe,Iot),e(bA,Not),e(bA,Hne),e(Hne,qot),e(bA,Dot),e(Ce,jot),e(Ce,vA),e(vA,Txe),e(Txe,Got),e(vA,Oot),e(vA,Jne),e(Jne,Vot),e(vA,Xot),e(Ce,zot),e(Ce,FA),e(FA,Mxe),e(Mxe,Qot),e(FA,Wot),e(FA,Yne),e(Yne,Uot),e(FA,Hot),e(Ce,Jot),e(Ce,TA),e(TA,Exe),e(Exe,Yot),e(TA,Zot),e(TA,Zne),e(Zne,Kot),e(TA,ert),e(Ce,ort),e(Ce,MA),e(MA,Cxe),e(Cxe,rrt),e(MA,trt),e(MA,Kne),e(Kne,art),e(MA,nrt),e(Ce,srt),e(Ce,EA),e(EA,wxe),e(wxe,lrt),e(EA,irt),e(EA,ese),e(ese,drt),e(EA,mrt),e(Ce,crt),e(Ce,CA),e(CA,Axe),e(Axe,frt),e(CA,grt),e(CA,ose),e(ose,hrt),e(CA,urt),e(Qr,prt),M(wA,Qr,null),b(c,Bio,_),b(c,yc,_),e(yc,AA),e(AA,Lxe),M(NP,Lxe,null),e(yc,_rt),e(yc,yxe),e(yxe,brt),b(c,Iio,_),b(c,_r,_),M(qP,_r,null),e(_r,vrt),e(_r,xc),e(xc,Frt),e(xc,rse),e(rse,Trt),e(xc,Mrt),e(xc,tse),e(tse,Ert),e(xc,Crt),e(_r,wrt),e(_r,DP),e(DP,Art),e(DP,xxe),e(xxe,Lrt),e(DP,yrt),e(_r,xrt),e(_r,aa),M(jP,aa,null),e(aa,$rt),e(aa,$xe),e($xe,krt),e(aa,Srt),e(aa,$c),e($c,Rrt),e($c,kxe),e(kxe,Prt),e($c,Brt),e($c,ase),e(ase,Irt),e($c,Nrt),e(aa,qrt),M(LA,aa,null),e(_r,Drt),e(_r,Wr),M(GP,Wr,null),e(Wr,jrt),e(Wr,Sxe),e(Sxe,Grt),e(Wr,Ort),e(Wr,Xn),e(Xn,Vrt),e(Xn,Rxe),e(Rxe,Xrt),e(Xn,zrt),e(Xn,Pxe),e(Pxe,Qrt),e(Xn,Wrt),e(Xn,Bxe),e(Bxe,Urt),e(Xn,Hrt),e(Wr,Jrt),e(Wr,$e),e($e,yA),e(yA,Ixe),e(Ixe,Yrt),e(yA,Zrt),e(yA,nse),e(nse,Krt),e(yA,ett),e($e,ott),e($e,xA),e(xA,Nxe),e(Nxe,rtt),e(xA,ttt),e(xA,sse),e(sse,att),e(xA,ntt),e($e,stt),e($e,$A),e($A,qxe),e(qxe,ltt),e($A,itt),e($A,lse),e(lse,dtt),e($A,mtt),e($e,ctt),e($e,jl),e(jl,Dxe),e(Dxe,ftt),e(jl,gtt),e(jl,ise),e(ise,htt),e(jl,utt),e(jl,dse),e(dse,ptt),e(jl,_tt),e($e,btt),e($e,kA),e(kA,jxe),e(jxe,vtt),e(kA,Ftt),e(kA,mse),e(mse,Ttt),e(kA,Mtt),e($e,Ett),e($e,SA),e(SA,Gxe),e(Gxe,Ctt),e(SA,wtt),e(SA,cse),e(cse,Att),e(SA,Ltt),e($e,ytt),e($e,RA),e(RA,Oxe),e(Oxe,xtt),e(RA,$tt),e(RA,fse),e(fse,ktt),e(RA,Stt),e($e,Rtt),e($e,PA),e(PA,Vxe),e(Vxe,Ptt),e(PA,Btt),e(PA,gse),e(gse,Itt),e(PA,Ntt),e($e,qtt),e($e,BA),e(BA,Xxe),e(Xxe,Dtt),e(BA,jtt),e(BA,hse),e(hse,Gtt),e(BA,Ott),e($e,Vtt),e($e,IA),e(IA,zxe),e(zxe,Xtt),e(IA,ztt),e(IA,use),e(use,Qtt),e(IA,Wtt),e(Wr,Utt),M(NA,Wr,null),b(c,Nio,_),b(c,kc,_),e(kc,qA),e(qA,Qxe),M(OP,Qxe,null),e(kc,Htt),e(kc,Wxe),e(Wxe,Jtt),b(c,qio,_),b(c,br,_),M(VP,br,null),e(br,Ytt),e(br,Sc),e(Sc,Ztt),e(Sc,pse),e(pse,Ktt),e(Sc,eat),e(Sc,_se),e(_se,oat),e(Sc,rat),e(br,tat),e(br,XP),e(XP,aat),e(XP,Uxe),e(Uxe,nat),e(XP,sat),e(br,lat),e(br,na),M(zP,na,null),e(na,iat),e(na,Hxe),e(Hxe,dat),e(na,mat),e(na,Rc),e(Rc,cat),e(Rc,Jxe),e(Jxe,fat),e(Rc,gat),e(Rc,bse),e(bse,hat),e(Rc,uat),e(na,pat),M(DA,na,null),e(br,_at),e(br,Ur),M(QP,Ur,null),e(Ur,bat),e(Ur,Yxe),e(Yxe,vat),e(Ur,Fat),e(Ur,zn),e(zn,Tat),e(zn,Zxe),e(Zxe,Mat),e(zn,Eat),e(zn,Kxe),e(Kxe,Cat),e(zn,wat),e(zn,e$e),e(e$e,Aat),e(zn,Lat),e(Ur,yat),e(Ur,Pc),e(Pc,jA),e(jA,o$e),e(o$e,xat),e(jA,$at),e(jA,vse),e(vse,kat),e(jA,Sat),e(Pc,Rat),e(Pc,GA),e(GA,r$e),e(r$e,Pat),e(GA,Bat),e(GA,Fse),e(Fse,Iat),e(GA,Nat),e(Pc,qat),e(Pc,OA),e(OA,t$e),e(t$e,Dat),e(OA,jat),e(OA,Tse),e(Tse,Gat),e(OA,Oat),e(Ur,Vat),M(VA,Ur,null),b(c,Dio,_),b(c,Bc,_),e(Bc,XA),e(XA,a$e),M(WP,a$e,null),e(Bc,Xat),e(Bc,n$e),e(n$e,zat),b(c,jio,_),b(c,vr,_),M(UP,vr,null),e(vr,Qat),e(vr,Ic),e(Ic,Wat),e(Ic,Mse),e(Mse,Uat),e(Ic,Hat),e(Ic,Ese),e(Ese,Jat),e(Ic,Yat),e(vr,Zat),e(vr,HP),e(HP,Kat),e(HP,s$e),e(s$e,ent),e(HP,ont),e(vr,rnt),e(vr,sa),M(JP,sa,null),e(sa,tnt),e(sa,l$e),e(l$e,ant),e(sa,nnt),e(sa,Nc),e(Nc,snt),e(Nc,i$e),e(i$e,lnt),e(Nc,int),e(Nc,Cse),e(Cse,dnt),e(Nc,mnt),e(sa,cnt),M(zA,sa,null),e(vr,fnt),e(vr,Hr),M(YP,Hr,null),e(Hr,gnt),e(Hr,d$e),e(d$e,hnt),e(Hr,unt),e(Hr,Qn),e(Qn,pnt),e(Qn,m$e),e(m$e,_nt),e(Qn,bnt),e(Qn,c$e),e(c$e,vnt),e(Qn,Fnt),e(Qn,f$e),e(f$e,Tnt),e(Qn,Mnt),e(Hr,Ent),e(Hr,ge),e(ge,QA),e(QA,g$e),e(g$e,Cnt),e(QA,wnt),e(QA,wse),e(wse,Ant),e(QA,Lnt),e(ge,ynt),e(ge,WA),e(WA,h$e),e(h$e,xnt),e(WA,$nt),e(WA,Ase),e(Ase,knt),e(WA,Snt),e(ge,Rnt),e(ge,UA),e(UA,u$e),e(u$e,Pnt),e(UA,Bnt),e(UA,Lse),e(Lse,Int),e(UA,Nnt),e(ge,qnt),e(ge,HA),e(HA,p$e),e(p$e,Dnt),e(HA,jnt),e(HA,yse),e(yse,Gnt),e(HA,Ont),e(ge,Vnt),e(ge,JA),e(JA,_$e),e(_$e,Xnt),e(JA,znt),e(JA,xse),e(xse,Qnt),e(JA,Wnt),e(ge,Unt),e(ge,YA),e(YA,b$e),e(b$e,Hnt),e(YA,Jnt),e(YA,$se),e($se,Ynt),e(YA,Znt),e(ge,Knt),e(ge,ZA),e(ZA,v$e),e(v$e,est),e(ZA,ost),e(ZA,kse),e(kse,rst),e(ZA,tst),e(ge,ast),e(ge,KA),e(KA,F$e),e(F$e,nst),e(KA,sst),e(KA,Sse),e(Sse,lst),e(KA,ist),e(ge,dst),e(ge,e6),e(e6,T$e),e(T$e,mst),e(e6,cst),e(e6,Rse),e(Rse,fst),e(e6,gst),e(ge,hst),e(ge,o6),e(o6,M$e),e(M$e,ust),e(o6,pst),e(o6,Pse),e(Pse,_st),e(o6,bst),e(ge,vst),e(ge,r6),e(r6,E$e),e(E$e,Fst),e(r6,Tst),e(r6,Bse),e(Bse,Mst),e(r6,Est),e(ge,Cst),e(ge,t6),e(t6,C$e),e(C$e,wst),e(t6,Ast),e(t6,Ise),e(Ise,Lst),e(t6,yst),e(ge,xst),e(ge,a6),e(a6,w$e),e(w$e,$st),e(a6,kst),e(a6,Nse),e(Nse,Sst),e(a6,Rst),e(ge,Pst),e(ge,n6),e(n6,A$e),e(A$e,Bst),e(n6,Ist),e(n6,qse),e(qse,Nst),e(n6,qst),e(ge,Dst),e(ge,s6),e(s6,L$e),e(L$e,jst),e(s6,Gst),e(s6,Dse),e(Dse,Ost),e(s6,Vst),e(ge,Xst),e(ge,l6),e(l6,y$e),e(y$e,zst),e(l6,Qst),e(l6,jse),e(jse,Wst),e(l6,Ust),e(ge,Hst),e(ge,i6),e(i6,x$e),e(x$e,Jst),e(i6,Yst),e(i6,Gse),e(Gse,Zst),e(i6,Kst),e(ge,elt),e(ge,d6),e(d6,$$e),e($$e,olt),e(d6,rlt),e(d6,Ose),e(Ose,tlt),e(d6,alt),e(ge,nlt),e(ge,m6),e(m6,k$e),e(k$e,slt),e(m6,llt),e(m6,Vse),e(Vse,ilt),e(m6,dlt),e(ge,mlt),e(ge,c6),e(c6,S$e),e(S$e,clt),e(c6,flt),e(c6,Xse),e(Xse,glt),e(c6,hlt),e(ge,ult),e(ge,f6),e(f6,R$e),e(R$e,plt),e(f6,_lt),e(f6,zse),e(zse,blt),e(f6,vlt),e(Hr,Flt),M(g6,Hr,null),b(c,Gio,_),b(c,qc,_),e(qc,h6),e(h6,P$e),M(ZP,P$e,null),e(qc,Tlt),e(qc,B$e),e(B$e,Mlt),b(c,Oio,_),b(c,Fr,_),M(KP,Fr,null),e(Fr,Elt),e(Fr,Dc),e(Dc,Clt),e(Dc,Qse),e(Qse,wlt),e(Dc,Alt),e(Dc,Wse),e(Wse,Llt),e(Dc,ylt),e(Fr,xlt),e(Fr,eB),e(eB,$lt),e(eB,I$e),e(I$e,klt),e(eB,Slt),e(Fr,Rlt),e(Fr,la),M(oB,la,null),e(la,Plt),e(la,N$e),e(N$e,Blt),e(la,Ilt),e(la,jc),e(jc,Nlt),e(jc,q$e),e(q$e,qlt),e(jc,Dlt),e(jc,Use),e(Use,jlt),e(jc,Glt),e(la,Olt),M(u6,la,null),e(Fr,Vlt),e(Fr,Jr),M(rB,Jr,null),e(Jr,Xlt),e(Jr,D$e),e(D$e,zlt),e(Jr,Qlt),e(Jr,Wn),e(Wn,Wlt),e(Wn,j$e),e(j$e,Ult),e(Wn,Hlt),e(Wn,G$e),e(G$e,Jlt),e(Wn,Ylt),e(Wn,O$e),e(O$e,Zlt),e(Wn,Klt),e(Jr,eit),e(Jr,ke),e(ke,p6),e(p6,V$e),e(V$e,oit),e(p6,rit),e(p6,Hse),e(Hse,tit),e(p6,ait),e(ke,nit),e(ke,_6),e(_6,X$e),e(X$e,sit),e(_6,lit),e(_6,Jse),e(Jse,iit),e(_6,dit),e(ke,mit),e(ke,b6),e(b6,z$e),e(z$e,cit),e(b6,fit),e(b6,Yse),e(Yse,git),e(b6,hit),e(ke,uit),e(ke,v6),e(v6,Q$e),e(Q$e,pit),e(v6,_it),e(v6,Zse),e(Zse,bit),e(v6,vit),e(ke,Fit),e(ke,F6),e(F6,W$e),e(W$e,Tit),e(F6,Mit),e(F6,Kse),e(Kse,Eit),e(F6,Cit),e(ke,wit),e(ke,T6),e(T6,U$e),e(U$e,Ait),e(T6,Lit),e(T6,ele),e(ele,yit),e(T6,xit),e(ke,$it),e(ke,M6),e(M6,H$e),e(H$e,kit),e(M6,Sit),e(M6,ole),e(ole,Rit),e(M6,Pit),e(ke,Bit),e(ke,E6),e(E6,J$e),e(J$e,Iit),e(E6,Nit),e(E6,rle),e(rle,qit),e(E6,Dit),e(ke,jit),e(ke,C6),e(C6,Y$e),e(Y$e,Git),e(C6,Oit),e(C6,tle),e(tle,Vit),e(C6,Xit),e(ke,zit),e(ke,w6),e(w6,Z$e),e(Z$e,Qit),e(w6,Wit),e(w6,ale),e(ale,Uit),e(w6,Hit),e(Jr,Jit),M(A6,Jr,null),b(c,Vio,_),b(c,Gc,_),e(Gc,L6),e(L6,K$e),M(tB,K$e,null),e(Gc,Yit),e(Gc,eke),e(eke,Zit),b(c,Xio,_),b(c,Tr,_),M(aB,Tr,null),e(Tr,Kit),e(Tr,Oc),e(Oc,edt),e(Oc,nle),e(nle,odt),e(Oc,rdt),e(Oc,sle),e(sle,tdt),e(Oc,adt),e(Tr,ndt),e(Tr,nB),e(nB,sdt),e(nB,oke),e(oke,ldt),e(nB,idt),e(Tr,ddt),e(Tr,ia),M(sB,ia,null),e(ia,mdt),e(ia,rke),e(rke,cdt),e(ia,fdt),e(ia,Vc),e(Vc,gdt),e(Vc,tke),e(tke,hdt),e(Vc,udt),e(Vc,lle),e(lle,pdt),e(Vc,_dt),e(ia,bdt),M(y6,ia,null),e(Tr,vdt),e(Tr,Yr),M(lB,Yr,null),e(Yr,Fdt),e(Yr,ake),e(ake,Tdt),e(Yr,Mdt),e(Yr,Un),e(Un,Edt),e(Un,nke),e(nke,Cdt),e(Un,wdt),e(Un,ske),e(ske,Adt),e(Un,Ldt),e(Un,lke),e(lke,ydt),e(Un,xdt),e(Yr,$dt),e(Yr,te),e(te,x6),e(x6,ike),e(ike,kdt),e(x6,Sdt),e(x6,ile),e(ile,Rdt),e(x6,Pdt),e(te,Bdt),e(te,$6),e($6,dke),e(dke,Idt),e($6,Ndt),e($6,dle),e(dle,qdt),e($6,Ddt),e(te,jdt),e(te,k6),e(k6,mke),e(mke,Gdt),e(k6,Odt),e(k6,mle),e(mle,Vdt),e(k6,Xdt),e(te,zdt),e(te,S6),e(S6,cke),e(cke,Qdt),e(S6,Wdt),e(S6,cle),e(cle,Udt),e(S6,Hdt),e(te,Jdt),e(te,R6),e(R6,fke),e(fke,Ydt),e(R6,Zdt),e(R6,fle),e(fle,Kdt),e(R6,emt),e(te,omt),e(te,P6),e(P6,gke),e(gke,rmt),e(P6,tmt),e(P6,gle),e(gle,amt),e(P6,nmt),e(te,smt),e(te,B6),e(B6,hke),e(hke,lmt),e(B6,imt),e(B6,hle),e(hle,dmt),e(B6,mmt),e(te,cmt),e(te,I6),e(I6,uke),e(uke,fmt),e(I6,gmt),e(I6,ule),e(ule,hmt),e(I6,umt),e(te,pmt),e(te,N6),e(N6,pke),e(pke,_mt),e(N6,bmt),e(N6,ple),e(ple,vmt),e(N6,Fmt),e(te,Tmt),e(te,q6),e(q6,_ke),e(_ke,Mmt),e(q6,Emt),e(q6,_le),e(_le,Cmt),e(q6,wmt),e(te,Amt),e(te,D6),e(D6,bke),e(bke,Lmt),e(D6,ymt),e(D6,ble),e(ble,xmt),e(D6,$mt),e(te,kmt),e(te,j6),e(j6,vke),e(vke,Smt),e(j6,Rmt),e(j6,vle),e(vle,Pmt),e(j6,Bmt),e(te,Imt),e(te,G6),e(G6,Fke),e(Fke,Nmt),e(G6,qmt),e(G6,Fle),e(Fle,Dmt),e(G6,jmt),e(te,Gmt),e(te,O6),e(O6,Tke),e(Tke,Omt),e(O6,Vmt),e(O6,Tle),e(Tle,Xmt),e(O6,zmt),e(te,Qmt),e(te,V6),e(V6,Mke),e(Mke,Wmt),e(V6,Umt),e(V6,Mle),e(Mle,Hmt),e(V6,Jmt),e(te,Ymt),e(te,X6),e(X6,Eke),e(Eke,Zmt),e(X6,Kmt),e(X6,Ele),e(Ele,ect),e(X6,oct),e(te,rct),e(te,z6),e(z6,Cke),e(Cke,tct),e(z6,act),e(z6,Cle),e(Cle,nct),e(z6,sct),e(te,lct),e(te,Q6),e(Q6,wke),e(wke,ict),e(Q6,dct),e(Q6,wle),e(wle,mct),e(Q6,cct),e(te,fct),e(te,W6),e(W6,Ake),e(Ake,gct),e(W6,hct),e(W6,Ale),e(Ale,uct),e(W6,pct),e(te,_ct),e(te,U6),e(U6,Lke),e(Lke,bct),e(U6,vct),e(U6,Lle),e(Lle,Fct),e(U6,Tct),e(te,Mct),e(te,H6),e(H6,yke),e(yke,Ect),e(H6,Cct),e(H6,yle),e(yle,wct),e(H6,Act),e(te,Lct),e(te,J6),e(J6,xke),e(xke,yct),e(J6,xct),e(J6,xle),e(xle,$ct),e(J6,kct),e(te,Sct),e(te,Y6),e(Y6,$ke),e($ke,Rct),e(Y6,Pct),e(Y6,$le),e($le,Bct),e(Y6,Ict),e(te,Nct),e(te,Z6),e(Z6,kke),e(kke,qct),e(Z6,Dct),e(Z6,kle),e(kle,jct),e(Z6,Gct),e(te,Oct),e(te,K6),e(K6,Ske),e(Ske,Vct),e(K6,Xct),e(K6,Sle),e(Sle,zct),e(K6,Qct),e(te,Wct),e(te,e7),e(e7,Rke),e(Rke,Uct),e(e7,Hct),e(e7,Rle),e(Rle,Jct),e(e7,Yct),e(te,Zct),e(te,o7),e(o7,Pke),e(Pke,Kct),e(o7,eft),e(o7,Ple),e(Ple,oft),e(o7,rft),e(te,tft),e(te,r7),e(r7,Bke),e(Bke,aft),e(r7,nft),e(r7,Ble),e(Ble,sft),e(r7,lft),e(Yr,ift),M(t7,Yr,null),b(c,zio,_),b(c,Xc,_),e(Xc,a7),e(a7,Ike),M(iB,Ike,null),e(Xc,dft),e(Xc,Nke),e(Nke,mft),b(c,Qio,_),b(c,Mr,_),M(dB,Mr,null),e(Mr,cft),e(Mr,zc),e(zc,fft),e(zc,Ile),e(Ile,gft),e(zc,hft),e(zc,Nle),e(Nle,uft),e(zc,pft),e(Mr,_ft),e(Mr,mB),e(mB,bft),e(mB,qke),e(qke,vft),e(mB,Fft),e(Mr,Tft),e(Mr,da),M(cB,da,null),e(da,Mft),e(da,Dke),e(Dke,Eft),e(da,Cft),e(da,Qc),e(Qc,wft),e(Qc,jke),e(jke,Aft),e(Qc,Lft),e(Qc,qle),e(qle,yft),e(Qc,xft),e(da,$ft),M(n7,da,null),e(Mr,kft),e(Mr,Zr),M(fB,Zr,null),e(Zr,Sft),e(Zr,Gke),e(Gke,Rft),e(Zr,Pft),e(Zr,Hn),e(Hn,Bft),e(Hn,Oke),e(Oke,Ift),e(Hn,Nft),e(Hn,Vke),e(Vke,qft),e(Hn,Dft),e(Hn,Xke),e(Xke,jft),e(Hn,Gft),e(Zr,Oft),e(Zr,Te),e(Te,s7),e(s7,zke),e(zke,Vft),e(s7,Xft),e(s7,Dle),e(Dle,zft),e(s7,Qft),e(Te,Wft),e(Te,l7),e(l7,Qke),e(Qke,Uft),e(l7,Hft),e(l7,jle),e(jle,Jft),e(l7,Yft),e(Te,Zft),e(Te,i7),e(i7,Wke),e(Wke,Kft),e(i7,egt),e(i7,Gle),e(Gle,ogt),e(i7,rgt),e(Te,tgt),e(Te,d7),e(d7,Uke),e(Uke,agt),e(d7,ngt),e(d7,Ole),e(Ole,sgt),e(d7,lgt),e(Te,igt),e(Te,m7),e(m7,Hke),e(Hke,dgt),e(m7,mgt),e(m7,Vle),e(Vle,cgt),e(m7,fgt),e(Te,ggt),e(Te,c7),e(c7,Jke),e(Jke,hgt),e(c7,ugt),e(c7,Xle),e(Xle,pgt),e(c7,_gt),e(Te,bgt),e(Te,f7),e(f7,Yke),e(Yke,vgt),e(f7,Fgt),e(f7,zle),e(zle,Tgt),e(f7,Mgt),e(Te,Egt),e(Te,g7),e(g7,Zke),e(Zke,Cgt),e(g7,wgt),e(g7,Qle),e(Qle,Agt),e(g7,Lgt),e(Te,ygt),e(Te,h7),e(h7,Kke),e(Kke,xgt),e(h7,$gt),e(h7,Wle),e(Wle,kgt),e(h7,Sgt),e(Te,Rgt),e(Te,u7),e(u7,eSe),e(eSe,Pgt),e(u7,Bgt),e(u7,Ule),e(Ule,Igt),e(u7,Ngt),e(Te,qgt),e(Te,p7),e(p7,oSe),e(oSe,Dgt),e(p7,jgt),e(p7,Hle),e(Hle,Ggt),e(p7,Ogt),e(Te,Vgt),e(Te,_7),e(_7,rSe),e(rSe,Xgt),e(_7,zgt),e(_7,Jle),e(Jle,Qgt),e(_7,Wgt),e(Te,Ugt),e(Te,b7),e(b7,tSe),e(tSe,Hgt),e(b7,Jgt),e(b7,Yle),e(Yle,Ygt),e(b7,Zgt),e(Te,Kgt),e(Te,v7),e(v7,aSe),e(aSe,eht),e(v7,oht),e(v7,Zle),e(Zle,rht),e(v7,tht),e(Te,aht),e(Te,F7),e(F7,nSe),e(nSe,nht),e(F7,sht),e(F7,Kle),e(Kle,lht),e(F7,iht),e(Te,dht),e(Te,T7),e(T7,sSe),e(sSe,mht),e(T7,cht),e(T7,eie),e(eie,fht),e(T7,ght),e(Te,hht),e(Te,M7),e(M7,lSe),e(lSe,uht),e(M7,pht),e(M7,oie),e(oie,_ht),e(M7,bht),e(Zr,vht),M(E7,Zr,null),b(c,Wio,_),b(c,Wc,_),e(Wc,C7),e(C7,iSe),M(gB,iSe,null),e(Wc,Fht),e(Wc,dSe),e(dSe,Tht),b(c,Uio,_),b(c,Er,_),M(hB,Er,null),e(Er,Mht),e(Er,Uc),e(Uc,Eht),e(Uc,rie),e(rie,Cht),e(Uc,wht),e(Uc,tie),e(tie,Aht),e(Uc,Lht),e(Er,yht),e(Er,uB),e(uB,xht),e(uB,mSe),e(mSe,$ht),e(uB,kht),e(Er,Sht),e(Er,ma),M(pB,ma,null),e(ma,Rht),e(ma,cSe),e(cSe,Pht),e(ma,Bht),e(ma,Hc),e(Hc,Iht),e(Hc,fSe),e(fSe,Nht),e(Hc,qht),e(Hc,aie),e(aie,Dht),e(Hc,jht),e(ma,Ght),M(w7,ma,null),e(Er,Oht),e(Er,Kr),M(_B,Kr,null),e(Kr,Vht),e(Kr,gSe),e(gSe,Xht),e(Kr,zht),e(Kr,Jn),e(Jn,Qht),e(Jn,hSe),e(hSe,Wht),e(Jn,Uht),e(Jn,uSe),e(uSe,Hht),e(Jn,Jht),e(Jn,pSe),e(pSe,Yht),e(Jn,Zht),e(Kr,Kht),e(Kr,bB),e(bB,A7),e(A7,_Se),e(_Se,eut),e(A7,out),e(A7,nie),e(nie,rut),e(A7,tut),e(bB,aut),e(bB,L7),e(L7,bSe),e(bSe,nut),e(L7,sut),e(L7,sie),e(sie,lut),e(L7,iut),e(Kr,dut),M(y7,Kr,null),b(c,Hio,_),b(c,Jc,_),e(Jc,x7),e(x7,vSe),M(vB,vSe,null),e(Jc,mut),e(Jc,FSe),e(FSe,cut),b(c,Jio,_),b(c,Cr,_),M(FB,Cr,null),e(Cr,fut),e(Cr,Yc),e(Yc,gut),e(Yc,lie),e(lie,hut),e(Yc,uut),e(Yc,iie),e(iie,put),e(Yc,_ut),e(Cr,but),e(Cr,TB),e(TB,vut),e(TB,TSe),e(TSe,Fut),e(TB,Tut),e(Cr,Mut),e(Cr,ca),M(MB,ca,null),e(ca,Eut),e(ca,MSe),e(MSe,Cut),e(ca,wut),e(ca,Zc),e(Zc,Aut),e(Zc,ESe),e(ESe,Lut),e(Zc,yut),e(Zc,die),e(die,xut),e(Zc,$ut),e(ca,kut),M($7,ca,null),e(Cr,Sut),e(Cr,et),M(EB,et,null),e(et,Rut),e(et,CSe),e(CSe,Put),e(et,But),e(et,Yn),e(Yn,Iut),e(Yn,wSe),e(wSe,Nut),e(Yn,qut),e(Yn,ASe),e(ASe,Dut),e(Yn,jut),e(Yn,LSe),e(LSe,Gut),e(Yn,Out),e(et,Vut),e(et,ySe),e(ySe,k7),e(k7,xSe),e(xSe,Xut),e(k7,zut),e(k7,mie),e(mie,Qut),e(k7,Wut),e(et,Uut),M(S7,et,null),b(c,Yio,_),b(c,Kc,_),e(Kc,R7),e(R7,$Se),M(CB,$Se,null),e(Kc,Hut),e(Kc,kSe),e(kSe,Jut),b(c,Zio,_),b(c,wr,_),M(wB,wr,null),e(wr,Yut),e(wr,ef),e(ef,Zut),e(ef,cie),e(cie,Kut),e(ef,ept),e(ef,fie),e(fie,opt),e(ef,rpt),e(wr,tpt),e(wr,AB),e(AB,apt),e(AB,SSe),e(SSe,npt),e(AB,spt),e(wr,lpt),e(wr,fa),M(LB,fa,null),e(fa,ipt),e(fa,RSe),e(RSe,dpt),e(fa,mpt),e(fa,of),e(of,cpt),e(of,PSe),e(PSe,fpt),e(of,gpt),e(of,gie),e(gie,hpt),e(of,upt),e(fa,ppt),M(P7,fa,null),e(wr,_pt),e(wr,ot),M(yB,ot,null),e(ot,bpt),e(ot,BSe),e(BSe,vpt),e(ot,Fpt),e(ot,Zn),e(Zn,Tpt),e(Zn,ISe),e(ISe,Mpt),e(Zn,Ept),e(Zn,NSe),e(NSe,Cpt),e(Zn,wpt),e(Zn,qSe),e(qSe,Apt),e(Zn,Lpt),e(ot,ypt),e(ot,DSe),e(DSe,B7),e(B7,jSe),e(jSe,xpt),e(B7,$pt),e(B7,hie),e(hie,kpt),e(B7,Spt),e(ot,Rpt),M(I7,ot,null),b(c,Kio,_),b(c,rf,_),e(rf,N7),e(N7,GSe),M(xB,GSe,null),e(rf,Ppt),e(rf,OSe),e(OSe,Bpt),b(c,edo,_),b(c,Ar,_),M($B,Ar,null),e(Ar,Ipt),e(Ar,tf),e(tf,Npt),e(tf,uie),e(uie,qpt),e(tf,Dpt),e(tf,pie),e(pie,jpt),e(tf,Gpt),e(Ar,Opt),e(Ar,kB),e(kB,Vpt),e(kB,VSe),e(VSe,Xpt),e(kB,zpt),e(Ar,Qpt),e(Ar,ga),M(SB,ga,null),e(ga,Wpt),e(ga,XSe),e(XSe,Upt),e(ga,Hpt),e(ga,af),e(af,Jpt),e(af,zSe),e(zSe,Ypt),e(af,Zpt),e(af,_ie),e(_ie,Kpt),e(af,e_t),e(ga,o_t),M(q7,ga,null),e(Ar,r_t),e(Ar,rt),M(RB,rt,null),e(rt,t_t),e(rt,QSe),e(QSe,a_t),e(rt,n_t),e(rt,Kn),e(Kn,s_t),e(Kn,WSe),e(WSe,l_t),e(Kn,i_t),e(Kn,USe),e(USe,d_t),e(Kn,m_t),e(Kn,HSe),e(HSe,c_t),e(Kn,f_t),e(rt,g_t),e(rt,me),e(me,D7),e(D7,JSe),e(JSe,h_t),e(D7,u_t),e(D7,bie),e(bie,p_t),e(D7,__t),e(me,b_t),e(me,j7),e(j7,YSe),e(YSe,v_t),e(j7,F_t),e(j7,vie),e(vie,T_t),e(j7,M_t),e(me,E_t),e(me,G7),e(G7,ZSe),e(ZSe,C_t),e(G7,w_t),e(G7,Fie),e(Fie,A_t),e(G7,L_t),e(me,y_t),e(me,O7),e(O7,KSe),e(KSe,x_t),e(O7,$_t),e(O7,Tie),e(Tie,k_t),e(O7,S_t),e(me,R_t),e(me,V7),e(V7,eRe),e(eRe,P_t),e(V7,B_t),e(V7,Mie),e(Mie,I_t),e(V7,N_t),e(me,q_t),e(me,X7),e(X7,oRe),e(oRe,D_t),e(X7,j_t),e(X7,Eie),e(Eie,G_t),e(X7,O_t),e(me,V_t),e(me,z7),e(z7,rRe),e(rRe,X_t),e(z7,z_t),e(z7,Cie),e(Cie,Q_t),e(z7,W_t),e(me,U_t),e(me,Q7),e(Q7,tRe),e(tRe,H_t),e(Q7,J_t),e(Q7,wie),e(wie,Y_t),e(Q7,Z_t),e(me,K_t),e(me,W7),e(W7,aRe),e(aRe,e1t),e(W7,o1t),e(W7,Aie),e(Aie,r1t),e(W7,t1t),e(me,a1t),e(me,U7),e(U7,nRe),e(nRe,n1t),e(U7,s1t),e(U7,Lie),e(Lie,l1t),e(U7,i1t),e(me,d1t),e(me,H7),e(H7,sRe),e(sRe,m1t),e(H7,c1t),e(H7,yie),e(yie,f1t),e(H7,g1t),e(me,h1t),e(me,J7),e(J7,lRe),e(lRe,u1t),e(J7,p1t),e(J7,xie),e(xie,_1t),e(J7,b1t),e(me,v1t),e(me,Y7),e(Y7,iRe),e(iRe,F1t),e(Y7,T1t),e(Y7,$ie),e($ie,M1t),e(Y7,E1t),e(me,C1t),e(me,Z7),e(Z7,dRe),e(dRe,w1t),e(Z7,A1t),e(Z7,kie),e(kie,L1t),e(Z7,y1t),e(me,x1t),e(me,K7),e(K7,mRe),e(mRe,$1t),e(K7,k1t),e(K7,Sie),e(Sie,S1t),e(K7,R1t),e(me,P1t),e(me,e8),e(e8,cRe),e(cRe,B1t),e(e8,I1t),e(e8,Rie),e(Rie,N1t),e(e8,q1t),e(me,D1t),e(me,o8),e(o8,fRe),e(fRe,j1t),e(o8,G1t),e(o8,Pie),e(Pie,O1t),e(o8,V1t),e(me,X1t),e(me,r8),e(r8,gRe),e(gRe,z1t),e(r8,Q1t),e(r8,Bie),e(Bie,W1t),e(r8,U1t),e(me,H1t),e(me,t8),e(t8,hRe),e(hRe,J1t),e(t8,Y1t),e(t8,Iie),e(Iie,Z1t),e(t8,K1t),e(me,e2t),e(me,a8),e(a8,uRe),e(uRe,o2t),e(a8,r2t),e(a8,Nie),e(Nie,t2t),e(a8,a2t),e(me,n2t),e(me,n8),e(n8,pRe),e(pRe,s2t),e(n8,l2t),e(n8,qie),e(qie,i2t),e(n8,d2t),e(me,m2t),e(me,s8),e(s8,_Re),e(_Re,c2t),e(s8,f2t),e(s8,Die),e(Die,g2t),e(s8,h2t),e(rt,u2t),M(l8,rt,null),b(c,odo,_),b(c,nf,_),e(nf,i8),e(i8,bRe),M(PB,bRe,null),e(nf,p2t),e(nf,vRe),e(vRe,_2t),b(c,rdo,_),b(c,Lr,_),M(BB,Lr,null),e(Lr,b2t),e(Lr,sf),e(sf,v2t),e(sf,jie),e(jie,F2t),e(sf,T2t),e(sf,Gie),e(Gie,M2t),e(sf,E2t),e(Lr,C2t),e(Lr,IB),e(IB,w2t),e(IB,FRe),e(FRe,A2t),e(IB,L2t),e(Lr,y2t),e(Lr,ha),M(NB,ha,null),e(ha,x2t),e(ha,TRe),e(TRe,$2t),e(ha,k2t),e(ha,lf),e(lf,S2t),e(lf,MRe),e(MRe,R2t),e(lf,P2t),e(lf,Oie),e(Oie,B2t),e(lf,I2t),e(ha,N2t),M(d8,ha,null),e(Lr,q2t),e(Lr,tt),M(qB,tt,null),e(tt,D2t),e(tt,ERe),e(ERe,j2t),e(tt,G2t),e(tt,es),e(es,O2t),e(es,CRe),e(CRe,V2t),e(es,X2t),e(es,wRe),e(wRe,z2t),e(es,Q2t),e(es,ARe),e(ARe,W2t),e(es,U2t),e(tt,H2t),e(tt,he),e(he,m8),e(m8,LRe),e(LRe,J2t),e(m8,Y2t),e(m8,Vie),e(Vie,Z2t),e(m8,K2t),e(he,ebt),e(he,c8),e(c8,yRe),e(yRe,obt),e(c8,rbt),e(c8,Xie),e(Xie,tbt),e(c8,abt),e(he,nbt),e(he,f8),e(f8,xRe),e(xRe,sbt),e(f8,lbt),e(f8,zie),e(zie,ibt),e(f8,dbt),e(he,mbt),e(he,g8),e(g8,$Re),e($Re,cbt),e(g8,fbt),e(g8,Qie),e(Qie,gbt),e(g8,hbt),e(he,ubt),e(he,h8),e(h8,kRe),e(kRe,pbt),e(h8,_bt),e(h8,Wie),e(Wie,bbt),e(h8,vbt),e(he,Fbt),e(he,u8),e(u8,SRe),e(SRe,Tbt),e(u8,Mbt),e(u8,Uie),e(Uie,Ebt),e(u8,Cbt),e(he,wbt),e(he,p8),e(p8,RRe),e(RRe,Abt),e(p8,Lbt),e(p8,Hie),e(Hie,ybt),e(p8,xbt),e(he,$bt),e(he,_8),e(_8,PRe),e(PRe,kbt),e(_8,Sbt),e(_8,Jie),e(Jie,Rbt),e(_8,Pbt),e(he,Bbt),e(he,b8),e(b8,BRe),e(BRe,Ibt),e(b8,Nbt),e(b8,Yie),e(Yie,qbt),e(b8,Dbt),e(he,jbt),e(he,v8),e(v8,IRe),e(IRe,Gbt),e(v8,Obt),e(v8,Zie),e(Zie,Vbt),e(v8,Xbt),e(he,zbt),e(he,F8),e(F8,NRe),e(NRe,Qbt),e(F8,Wbt),e(F8,Kie),e(Kie,Ubt),e(F8,Hbt),e(he,Jbt),e(he,T8),e(T8,qRe),e(qRe,Ybt),e(T8,Zbt),e(T8,ede),e(ede,Kbt),e(T8,evt),e(he,ovt),e(he,M8),e(M8,DRe),e(DRe,rvt),e(M8,tvt),e(M8,ode),e(ode,avt),e(M8,nvt),e(he,svt),e(he,E8),e(E8,jRe),e(jRe,lvt),e(E8,ivt),e(E8,rde),e(rde,dvt),e(E8,mvt),e(he,cvt),e(he,C8),e(C8,GRe),e(GRe,fvt),e(C8,gvt),e(C8,tde),e(tde,hvt),e(C8,uvt),e(he,pvt),e(he,w8),e(w8,ORe),e(ORe,_vt),e(w8,bvt),e(w8,ade),e(ade,vvt),e(w8,Fvt),e(he,Tvt),e(he,A8),e(A8,VRe),e(VRe,Mvt),e(A8,Evt),e(A8,nde),e(nde,Cvt),e(A8,wvt),e(he,Avt),e(he,L8),e(L8,XRe),e(XRe,Lvt),e(L8,yvt),e(L8,sde),e(sde,xvt),e(L8,$vt),e(he,kvt),e(he,y8),e(y8,zRe),e(zRe,Svt),e(y8,Rvt),e(y8,lde),e(lde,Pvt),e(y8,Bvt),e(he,Ivt),e(he,x8),e(x8,QRe),e(QRe,Nvt),e(x8,qvt),e(x8,ide),e(ide,Dvt),e(x8,jvt),e(he,Gvt),e(he,$8),e($8,WRe),e(WRe,Ovt),e($8,Vvt),e($8,dde),e(dde,Xvt),e($8,zvt),e(tt,Qvt),M(k8,tt,null),b(c,tdo,_),b(c,df,_),e(df,S8),e(S8,URe),M(DB,URe,null),e(df,Wvt),e(df,HRe),e(HRe,Uvt),b(c,ado,_),b(c,yr,_),M(jB,yr,null),e(yr,Hvt),e(yr,mf),e(mf,Jvt),e(mf,mde),e(mde,Yvt),e(mf,Zvt),e(mf,cde),e(cde,Kvt),e(mf,eFt),e(yr,oFt),e(yr,GB),e(GB,rFt),e(GB,JRe),e(JRe,tFt),e(GB,aFt),e(yr,nFt),e(yr,ua),M(OB,ua,null),e(ua,sFt),e(ua,YRe),e(YRe,lFt),e(ua,iFt),e(ua,cf),e(cf,dFt),e(cf,ZRe),e(ZRe,mFt),e(cf,cFt),e(cf,fde),e(fde,fFt),e(cf,gFt),e(ua,hFt),M(R8,ua,null),e(yr,uFt),e(yr,at),M(VB,at,null),e(at,pFt),e(at,KRe),e(KRe,_Ft),e(at,bFt),e(at,os),e(os,vFt),e(os,ePe),e(ePe,FFt),e(os,TFt),e(os,oPe),e(oPe,MFt),e(os,EFt),e(os,rPe),e(rPe,CFt),e(os,wFt),e(at,AFt),e(at,tPe),e(tPe,P8),e(P8,aPe),e(aPe,LFt),e(P8,yFt),e(P8,gde),e(gde,xFt),e(P8,$Ft),e(at,kFt),M(B8,at,null),b(c,ndo,_),b(c,ff,_),e(ff,I8),e(I8,nPe),M(XB,nPe,null),e(ff,SFt),e(ff,sPe),e(sPe,RFt),b(c,sdo,_),b(c,xr,_),M(zB,xr,null),e(xr,PFt),e(xr,gf),e(gf,BFt),e(gf,hde),e(hde,IFt),e(gf,NFt),e(gf,ude),e(ude,qFt),e(gf,DFt),e(xr,jFt),e(xr,QB),e(QB,GFt),e(QB,lPe),e(lPe,OFt),e(QB,VFt),e(xr,XFt),e(xr,pa),M(WB,pa,null),e(pa,zFt),e(pa,iPe),e(iPe,QFt),e(pa,WFt),e(pa,hf),e(hf,UFt),e(hf,dPe),e(dPe,HFt),e(hf,JFt),e(hf,pde),e(pde,YFt),e(hf,ZFt),e(pa,KFt),M(N8,pa,null),e(xr,eTt),e(xr,nt),M(UB,nt,null),e(nt,oTt),e(nt,mPe),e(mPe,rTt),e(nt,tTt),e(nt,rs),e(rs,aTt),e(rs,cPe),e(cPe,nTt),e(rs,sTt),e(rs,fPe),e(fPe,lTt),e(rs,iTt),e(rs,gPe),e(gPe,dTt),e(rs,mTt),e(nt,cTt),e(nt,HB),e(HB,q8),e(q8,hPe),e(hPe,fTt),e(q8,gTt),e(q8,_de),e(_de,hTt),e(q8,uTt),e(HB,pTt),e(HB,D8),e(D8,uPe),e(uPe,_Tt),e(D8,bTt),e(D8,bde),e(bde,vTt),e(D8,FTt),e(nt,TTt),M(j8,nt,null),b(c,ldo,_),b(c,uf,_),e(uf,G8),e(G8,pPe),M(JB,pPe,null),e(uf,MTt),e(uf,_Pe),e(_Pe,ETt),b(c,ido,_),b(c,$r,_),M(YB,$r,null),e($r,CTt),e($r,pf),e(pf,wTt),e(pf,vde),e(vde,ATt),e(pf,LTt),e(pf,Fde),e(Fde,yTt),e(pf,xTt),e($r,$Tt),e($r,ZB),e(ZB,kTt),e(ZB,bPe),e(bPe,STt),e(ZB,RTt),e($r,PTt),e($r,_a),M(KB,_a,null),e(_a,BTt),e(_a,vPe),e(vPe,ITt),e(_a,NTt),e(_a,_f),e(_f,qTt),e(_f,FPe),e(FPe,DTt),e(_f,jTt),e(_f,Tde),e(Tde,GTt),e(_f,OTt),e(_a,VTt),M(O8,_a,null),e($r,XTt),e($r,st),M(eI,st,null),e(st,zTt),e(st,TPe),e(TPe,QTt),e(st,WTt),e(st,ts),e(ts,UTt),e(ts,MPe),e(MPe,HTt),e(ts,JTt),e(ts,EPe),e(EPe,YTt),e(ts,ZTt),e(ts,CPe),e(CPe,KTt),e(ts,eMt),e(st,oMt),e(st,ne),e(ne,V8),e(V8,wPe),e(wPe,rMt),e(V8,tMt),e(V8,Mde),e(Mde,aMt),e(V8,nMt),e(ne,sMt),e(ne,X8),e(X8,APe),e(APe,lMt),e(X8,iMt),e(X8,Ede),e(Ede,dMt),e(X8,mMt),e(ne,cMt),e(ne,z8),e(z8,LPe),e(LPe,fMt),e(z8,gMt),e(z8,Cde),e(Cde,hMt),e(z8,uMt),e(ne,pMt),e(ne,Q8),e(Q8,yPe),e(yPe,_Mt),e(Q8,bMt),e(Q8,wde),e(wde,vMt),e(Q8,FMt),e(ne,TMt),e(ne,W8),e(W8,xPe),e(xPe,MMt),e(W8,EMt),e(W8,Ade),e(Ade,CMt),e(W8,wMt),e(ne,AMt),e(ne,U8),e(U8,$Pe),e($Pe,LMt),e(U8,yMt),e(U8,Lde),e(Lde,xMt),e(U8,$Mt),e(ne,kMt),e(ne,H8),e(H8,kPe),e(kPe,SMt),e(H8,RMt),e(H8,yde),e(yde,PMt),e(H8,BMt),e(ne,IMt),e(ne,J8),e(J8,SPe),e(SPe,NMt),e(J8,qMt),e(J8,xde),e(xde,DMt),e(J8,jMt),e(ne,GMt),e(ne,Y8),e(Y8,RPe),e(RPe,OMt),e(Y8,VMt),e(Y8,$de),e($de,XMt),e(Y8,zMt),e(ne,QMt),e(ne,Z8),e(Z8,PPe),e(PPe,WMt),e(Z8,UMt),e(Z8,kde),e(kde,HMt),e(Z8,JMt),e(ne,YMt),e(ne,K8),e(K8,BPe),e(BPe,ZMt),e(K8,KMt),e(K8,Sde),e(Sde,eEt),e(K8,oEt),e(ne,rEt),e(ne,eL),e(eL,IPe),e(IPe,tEt),e(eL,aEt),e(eL,Rde),e(Rde,nEt),e(eL,sEt),e(ne,lEt),e(ne,oL),e(oL,NPe),e(NPe,iEt),e(oL,dEt),e(oL,Pde),e(Pde,mEt),e(oL,cEt),e(ne,fEt),e(ne,rL),e(rL,qPe),e(qPe,gEt),e(rL,hEt),e(rL,Bde),e(Bde,uEt),e(rL,pEt),e(ne,_Et),e(ne,tL),e(tL,DPe),e(DPe,bEt),e(tL,vEt),e(tL,Ide),e(Ide,FEt),e(tL,TEt),e(ne,MEt),e(ne,aL),e(aL,jPe),e(jPe,EEt),e(aL,CEt),e(aL,Nde),e(Nde,wEt),e(aL,AEt),e(ne,LEt),e(ne,nL),e(nL,GPe),e(GPe,yEt),e(nL,xEt),e(nL,qde),e(qde,$Et),e(nL,kEt),e(ne,SEt),e(ne,sL),e(sL,OPe),e(OPe,REt),e(sL,PEt),e(sL,Dde),e(Dde,BEt),e(sL,IEt),e(ne,NEt),e(ne,lL),e(lL,VPe),e(VPe,qEt),e(lL,DEt),e(lL,jde),e(jde,jEt),e(lL,GEt),e(ne,OEt),e(ne,iL),e(iL,XPe),e(XPe,VEt),e(iL,XEt),e(iL,Gde),e(Gde,zEt),e(iL,QEt),e(ne,WEt),e(ne,dL),e(dL,zPe),e(zPe,UEt),e(dL,HEt),e(dL,Ode),e(Ode,JEt),e(dL,YEt),e(ne,ZEt),e(ne,mL),e(mL,QPe),e(QPe,KEt),e(mL,e4t),e(mL,Vde),e(Vde,o4t),e(mL,r4t),e(ne,t4t),e(ne,cL),e(cL,WPe),e(WPe,a4t),e(cL,n4t),e(cL,Xde),e(Xde,s4t),e(cL,l4t),e(ne,i4t),e(ne,fL),e(fL,UPe),e(UPe,d4t),e(fL,m4t),e(fL,zde),e(zde,c4t),e(fL,f4t),e(ne,g4t),e(ne,gL),e(gL,HPe),e(HPe,h4t),e(gL,u4t),e(gL,Qde),e(Qde,p4t),e(gL,_4t),e(ne,b4t),e(ne,hL),e(hL,JPe),e(JPe,v4t),e(hL,F4t),e(hL,Wde),e(Wde,T4t),e(hL,M4t),e(ne,E4t),e(ne,uL),e(uL,YPe),e(YPe,C4t),e(uL,w4t),e(uL,Ude),e(Ude,A4t),e(uL,L4t),e(st,y4t),M(pL,st,null),b(c,ddo,_),b(c,bf,_),e(bf,_L),e(_L,ZPe),M(oI,ZPe,null),e(bf,x4t),e(bf,KPe),e(KPe,$4t),b(c,mdo,_),b(c,kr,_),M(rI,kr,null),e(kr,k4t),e(kr,vf),e(vf,S4t),e(vf,Hde),e(Hde,R4t),e(vf,P4t),e(vf,Jde),e(Jde,B4t),e(vf,I4t),e(kr,N4t),e(kr,tI),e(tI,q4t),e(tI,eBe),e(eBe,D4t),e(tI,j4t),e(kr,G4t),e(kr,ba),M(aI,ba,null),e(ba,O4t),e(ba,oBe),e(oBe,V4t),e(ba,X4t),e(ba,Ff),e(Ff,z4t),e(Ff,rBe),e(rBe,Q4t),e(Ff,W4t),e(Ff,Yde),e(Yde,U4t),e(Ff,H4t),e(ba,J4t),M(bL,ba,null),e(kr,Y4t),e(kr,lt),M(nI,lt,null),e(lt,Z4t),e(lt,tBe),e(tBe,K4t),e(lt,eCt),e(lt,as),e(as,oCt),e(as,aBe),e(aBe,rCt),e(as,tCt),e(as,nBe),e(nBe,aCt),e(as,nCt),e(as,sBe),e(sBe,sCt),e(as,lCt),e(lt,iCt),e(lt,Se),e(Se,vL),e(vL,lBe),e(lBe,dCt),e(vL,mCt),e(vL,Zde),e(Zde,cCt),e(vL,fCt),e(Se,gCt),e(Se,FL),e(FL,iBe),e(iBe,hCt),e(FL,uCt),e(FL,Kde),e(Kde,pCt),e(FL,_Ct),e(Se,bCt),e(Se,TL),e(TL,dBe),e(dBe,vCt),e(TL,FCt),e(TL,eme),e(eme,TCt),e(TL,MCt),e(Se,ECt),e(Se,ML),e(ML,mBe),e(mBe,CCt),e(ML,wCt),e(ML,ome),e(ome,ACt),e(ML,LCt),e(Se,yCt),e(Se,EL),e(EL,cBe),e(cBe,xCt),e(EL,$Ct),e(EL,rme),e(rme,kCt),e(EL,SCt),e(Se,RCt),e(Se,CL),e(CL,fBe),e(fBe,PCt),e(CL,BCt),e(CL,tme),e(tme,ICt),e(CL,NCt),e(Se,qCt),e(Se,wL),e(wL,gBe),e(gBe,DCt),e(wL,jCt),e(wL,ame),e(ame,GCt),e(wL,OCt),e(Se,VCt),e(Se,AL),e(AL,hBe),e(hBe,XCt),e(AL,zCt),e(AL,nme),e(nme,QCt),e(AL,WCt),e(Se,UCt),e(Se,LL),e(LL,uBe),e(uBe,HCt),e(LL,JCt),e(LL,sme),e(sme,YCt),e(LL,ZCt),e(Se,KCt),e(Se,yL),e(yL,pBe),e(pBe,e3t),e(yL,o3t),e(yL,lme),e(lme,r3t),e(yL,t3t),e(lt,a3t),M(xL,lt,null),b(c,cdo,_),b(c,Tf,_),e(Tf,$L),e($L,_Be),M(sI,_Be,null),e(Tf,n3t),e(Tf,bBe),e(bBe,s3t),b(c,fdo,_),b(c,Sr,_),M(lI,Sr,null),e(Sr,l3t),e(Sr,Mf),e(Mf,i3t),e(Mf,ime),e(ime,d3t),e(Mf,m3t),e(Mf,dme),e(dme,c3t),e(Mf,f3t),e(Sr,g3t),e(Sr,iI),e(iI,h3t),e(iI,vBe),e(vBe,u3t),e(iI,p3t),e(Sr,_3t),e(Sr,va),M(dI,va,null),e(va,b3t),e(va,FBe),e(FBe,v3t),e(va,F3t),e(va,Ef),e(Ef,T3t),e(Ef,TBe),e(TBe,M3t),e(Ef,E3t),e(Ef,mme),e(mme,C3t),e(Ef,w3t),e(va,A3t),M(kL,va,null),e(Sr,L3t),e(Sr,it),M(mI,it,null),e(it,y3t),e(it,MBe),e(MBe,x3t),e(it,$3t),e(it,ns),e(ns,k3t),e(ns,EBe),e(EBe,S3t),e(ns,R3t),e(ns,CBe),e(CBe,P3t),e(ns,B3t),e(ns,wBe),e(wBe,I3t),e(ns,N3t),e(it,q3t),e(it,we),e(we,SL),e(SL,ABe),e(ABe,D3t),e(SL,j3t),e(SL,cme),e(cme,G3t),e(SL,O3t),e(we,V3t),e(we,RL),e(RL,LBe),e(LBe,X3t),e(RL,z3t),e(RL,fme),e(fme,Q3t),e(RL,W3t),e(we,U3t),e(we,PL),e(PL,yBe),e(yBe,H3t),e(PL,J3t),e(PL,gme),e(gme,Y3t),e(PL,Z3t),e(we,K3t),e(we,BL),e(BL,xBe),e(xBe,e5t),e(BL,o5t),e(BL,hme),e(hme,r5t),e(BL,t5t),e(we,a5t),e(we,IL),e(IL,$Be),e($Be,n5t),e(IL,s5t),e(IL,ume),e(ume,l5t),e(IL,i5t),e(we,d5t),e(we,NL),e(NL,kBe),e(kBe,m5t),e(NL,c5t),e(NL,pme),e(pme,f5t),e(NL,g5t),e(we,h5t),e(we,qL),e(qL,SBe),e(SBe,u5t),e(qL,p5t),e(qL,_me),e(_me,_5t),e(qL,b5t),e(we,v5t),e(we,DL),e(DL,RBe),e(RBe,F5t),e(DL,T5t),e(DL,bme),e(bme,M5t),e(DL,E5t),e(we,C5t),e(we,jL),e(jL,PBe),e(PBe,w5t),e(jL,A5t),e(jL,vme),e(vme,L5t),e(jL,y5t),e(we,x5t),e(we,GL),e(GL,BBe),e(BBe,$5t),e(GL,k5t),e(GL,Fme),e(Fme,S5t),e(GL,R5t),e(we,P5t),e(we,OL),e(OL,IBe),e(IBe,B5t),e(OL,I5t),e(OL,Tme),e(Tme,N5t),e(OL,q5t),e(we,D5t),e(we,VL),e(VL,NBe),e(NBe,j5t),e(VL,G5t),e(VL,Mme),e(Mme,O5t),e(VL,V5t),e(we,X5t),e(we,XL),e(XL,qBe),e(qBe,z5t),e(XL,Q5t),e(XL,Eme),e(Eme,W5t),e(XL,U5t),e(it,H5t),M(zL,it,null),b(c,gdo,_),b(c,Cf,_),e(Cf,QL),e(QL,DBe),M(cI,DBe,null),e(Cf,J5t),e(Cf,jBe),e(jBe,Y5t),b(c,hdo,_),b(c,Rr,_),M(fI,Rr,null),e(Rr,Z5t),e(Rr,wf),e(wf,K5t),e(wf,Cme),e(Cme,e0t),e(wf,o0t),e(wf,wme),e(wme,r0t),e(wf,t0t),e(Rr,a0t),e(Rr,gI),e(gI,n0t),e(gI,GBe),e(GBe,s0t),e(gI,l0t),e(Rr,i0t),e(Rr,Fa),M(hI,Fa,null),e(Fa,d0t),e(Fa,OBe),e(OBe,m0t),e(Fa,c0t),e(Fa,Af),e(Af,f0t),e(Af,VBe),e(VBe,g0t),e(Af,h0t),e(Af,Ame),e(Ame,u0t),e(Af,p0t),e(Fa,_0t),M(WL,Fa,null),e(Rr,b0t),e(Rr,dt),M(uI,dt,null),e(dt,v0t),e(dt,XBe),e(XBe,F0t),e(dt,T0t),e(dt,ss),e(ss,M0t),e(ss,zBe),e(zBe,E0t),e(ss,C0t),e(ss,QBe),e(QBe,w0t),e(ss,A0t),e(ss,WBe),e(WBe,L0t),e(ss,y0t),e(dt,x0t),e(dt,Re),e(Re,UL),e(UL,UBe),e(UBe,$0t),e(UL,k0t),e(UL,Lme),e(Lme,S0t),e(UL,R0t),e(Re,P0t),e(Re,HL),e(HL,HBe),e(HBe,B0t),e(HL,I0t),e(HL,yme),e(yme,N0t),e(HL,q0t),e(Re,D0t),e(Re,JL),e(JL,JBe),e(JBe,j0t),e(JL,G0t),e(JL,xme),e(xme,O0t),e(JL,V0t),e(Re,X0t),e(Re,YL),e(YL,YBe),e(YBe,z0t),e(YL,Q0t),e(YL,$me),e($me,W0t),e(YL,U0t),e(Re,H0t),e(Re,ZL),e(ZL,ZBe),e(ZBe,J0t),e(ZL,Y0t),e(ZL,kme),e(kme,Z0t),e(ZL,K0t),e(Re,ewt),e(Re,KL),e(KL,KBe),e(KBe,owt),e(KL,rwt),e(KL,Sme),e(Sme,twt),e(KL,awt),e(Re,nwt),e(Re,ey),e(ey,eIe),e(eIe,swt),e(ey,lwt),e(ey,Rme),e(Rme,iwt),e(ey,dwt),e(Re,mwt),e(Re,oy),e(oy,oIe),e(oIe,cwt),e(oy,fwt),e(oy,Pme),e(Pme,gwt),e(oy,hwt),e(Re,uwt),e(Re,ry),e(ry,rIe),e(rIe,pwt),e(ry,_wt),e(ry,Bme),e(Bme,bwt),e(ry,vwt),e(Re,Fwt),e(Re,ty),e(ty,tIe),e(tIe,Twt),e(ty,Mwt),e(ty,Ime),e(Ime,Ewt),e(ty,Cwt),e(dt,wwt),M(ay,dt,null),b(c,udo,_),b(c,Lf,_),e(Lf,ny),e(ny,aIe),M(pI,aIe,null),e(Lf,Awt),e(Lf,nIe),e(nIe,Lwt),b(c,pdo,_),b(c,Pr,_),M(_I,Pr,null),e(Pr,ywt),e(Pr,yf),e(yf,xwt),e(yf,Nme),e(Nme,$wt),e(yf,kwt),e(yf,qme),e(qme,Swt),e(yf,Rwt),e(Pr,Pwt),e(Pr,bI),e(bI,Bwt),e(bI,sIe),e(sIe,Iwt),e(bI,Nwt),e(Pr,qwt),e(Pr,Ta),M(vI,Ta,null),e(Ta,Dwt),e(Ta,lIe),e(lIe,jwt),e(Ta,Gwt),e(Ta,xf),e(xf,Owt),e(xf,iIe),e(iIe,Vwt),e(xf,Xwt),e(xf,Dme),e(Dme,zwt),e(xf,Qwt),e(Ta,Wwt),M(sy,Ta,null),e(Pr,Uwt),e(Pr,mt),M(FI,mt,null),e(mt,Hwt),e(mt,dIe),e(dIe,Jwt),e(mt,Ywt),e(mt,ls),e(ls,Zwt),e(ls,mIe),e(mIe,Kwt),e(ls,eAt),e(ls,cIe),e(cIe,oAt),e(ls,rAt),e(ls,fIe),e(fIe,tAt),e(ls,aAt),e(mt,nAt),e(mt,Pe),e(Pe,ly),e(ly,gIe),e(gIe,sAt),e(ly,lAt),e(ly,jme),e(jme,iAt),e(ly,dAt),e(Pe,mAt),e(Pe,iy),e(iy,hIe),e(hIe,cAt),e(iy,fAt),e(iy,Gme),e(Gme,gAt),e(iy,hAt),e(Pe,uAt),e(Pe,dy),e(dy,uIe),e(uIe,pAt),e(dy,_At),e(dy,Ome),e(Ome,bAt),e(dy,vAt),e(Pe,FAt),e(Pe,my),e(my,pIe),e(pIe,TAt),e(my,MAt),e(my,Vme),e(Vme,EAt),e(my,CAt),e(Pe,wAt),e(Pe,cy),e(cy,_Ie),e(_Ie,AAt),e(cy,LAt),e(cy,Xme),e(Xme,yAt),e(cy,xAt),e(Pe,$At),e(Pe,fy),e(fy,bIe),e(bIe,kAt),e(fy,SAt),e(fy,zme),e(zme,RAt),e(fy,PAt),e(Pe,BAt),e(Pe,gy),e(gy,vIe),e(vIe,IAt),e(gy,NAt),e(gy,Qme),e(Qme,qAt),e(gy,DAt),e(Pe,jAt),e(Pe,hy),e(hy,FIe),e(FIe,GAt),e(hy,OAt),e(hy,Wme),e(Wme,VAt),e(hy,XAt),e(Pe,zAt),e(Pe,uy),e(uy,TIe),e(TIe,QAt),e(uy,WAt),e(uy,Ume),e(Ume,UAt),e(uy,HAt),e(Pe,JAt),e(Pe,py),e(py,MIe),e(MIe,YAt),e(py,ZAt),e(py,Hme),e(Hme,KAt),e(py,e6t),e(mt,o6t),M(_y,mt,null),b(c,_do,_),b(c,$f,_),e($f,by),e(by,EIe),M(TI,EIe,null),e($f,r6t),e($f,CIe),e(CIe,t6t),b(c,bdo,_),b(c,Br,_),M(MI,Br,null),e(Br,a6t),e(Br,kf),e(kf,n6t),e(kf,Jme),e(Jme,s6t),e(kf,l6t),e(kf,Yme),e(Yme,i6t),e(kf,d6t),e(Br,m6t),e(Br,EI),e(EI,c6t),e(EI,wIe),e(wIe,f6t),e(EI,g6t),e(Br,h6t),e(Br,Ma),M(CI,Ma,null),e(Ma,u6t),e(Ma,AIe),e(AIe,p6t),e(Ma,_6t),e(Ma,Sf),e(Sf,b6t),e(Sf,LIe),e(LIe,v6t),e(Sf,F6t),e(Sf,Zme),e(Zme,T6t),e(Sf,M6t),e(Ma,E6t),M(vy,Ma,null),e(Br,C6t),e(Br,ct),M(wI,ct,null),e(ct,w6t),e(ct,yIe),e(yIe,A6t),e(ct,L6t),e(ct,is),e(is,y6t),e(is,xIe),e(xIe,x6t),e(is,$6t),e(is,$Ie),e($Ie,k6t),e(is,S6t),e(is,kIe),e(kIe,R6t),e(is,P6t),e(ct,B6t),e(ct,Be),e(Be,Fy),e(Fy,SIe),e(SIe,I6t),e(Fy,N6t),e(Fy,Kme),e(Kme,q6t),e(Fy,D6t),e(Be,j6t),e(Be,Ty),e(Ty,RIe),e(RIe,G6t),e(Ty,O6t),e(Ty,ece),e(ece,V6t),e(Ty,X6t),e(Be,z6t),e(Be,My),e(My,PIe),e(PIe,Q6t),e(My,W6t),e(My,oce),e(oce,U6t),e(My,H6t),e(Be,J6t),e(Be,Ey),e(Ey,BIe),e(BIe,Y6t),e(Ey,Z6t),e(Ey,rce),e(rce,K6t),e(Ey,e7t),e(Be,o7t),e(Be,Cy),e(Cy,IIe),e(IIe,r7t),e(Cy,t7t),e(Cy,tce),e(tce,a7t),e(Cy,n7t),e(Be,s7t),e(Be,wy),e(wy,NIe),e(NIe,l7t),e(wy,i7t),e(wy,ace),e(ace,d7t),e(wy,m7t),e(Be,c7t),e(Be,Ay),e(Ay,qIe),e(qIe,f7t),e(Ay,g7t),e(Ay,nce),e(nce,h7t),e(Ay,u7t),e(Be,p7t),e(Be,Ly),e(Ly,DIe),e(DIe,_7t),e(Ly,b7t),e(Ly,sce),e(sce,v7t),e(Ly,F7t),e(Be,T7t),e(Be,yy),e(yy,jIe),e(jIe,M7t),e(yy,E7t),e(yy,lce),e(lce,C7t),e(yy,w7t),e(Be,A7t),e(Be,xy),e(xy,GIe),e(GIe,L7t),e(xy,y7t),e(xy,ice),e(ice,x7t),e(xy,$7t),e(ct,k7t),M($y,ct,null),b(c,vdo,_),b(c,Rf,_),e(Rf,ky),e(ky,OIe),M(AI,OIe,null),e(Rf,S7t),e(Rf,VIe),e(VIe,R7t),b(c,Fdo,_),b(c,Ir,_),M(LI,Ir,null),e(Ir,P7t),e(Ir,Pf),e(Pf,B7t),e(Pf,dce),e(dce,I7t),e(Pf,N7t),e(Pf,mce),e(mce,q7t),e(Pf,D7t),e(Ir,j7t),e(Ir,yI),e(yI,G7t),e(yI,XIe),e(XIe,O7t),e(yI,V7t),e(Ir,X7t),e(Ir,Ea),M(xI,Ea,null),e(Ea,z7t),e(Ea,zIe),e(zIe,Q7t),e(Ea,W7t),e(Ea,Bf),e(Bf,U7t),e(Bf,QIe),e(QIe,H7t),e(Bf,J7t),e(Bf,cce),e(cce,Y7t),e(Bf,Z7t),e(Ea,K7t),M(Sy,Ea,null),e(Ir,e8t),e(Ir,ft),M($I,ft,null),e(ft,o8t),e(ft,WIe),e(WIe,r8t),e(ft,t8t),e(ft,ds),e(ds,a8t),e(ds,UIe),e(UIe,n8t),e(ds,s8t),e(ds,HIe),e(HIe,l8t),e(ds,i8t),e(ds,JIe),e(JIe,d8t),e(ds,m8t),e(ft,c8t),e(ft,Ie),e(Ie,Ry),e(Ry,YIe),e(YIe,f8t),e(Ry,g8t),e(Ry,fce),e(fce,h8t),e(Ry,u8t),e(Ie,p8t),e(Ie,Py),e(Py,ZIe),e(ZIe,_8t),e(Py,b8t),e(Py,gce),e(gce,v8t),e(Py,F8t),e(Ie,T8t),e(Ie,By),e(By,KIe),e(KIe,M8t),e(By,E8t),e(By,hce),e(hce,C8t),e(By,w8t),e(Ie,A8t),e(Ie,Iy),e(Iy,eNe),e(eNe,L8t),e(Iy,y8t),e(Iy,uce),e(uce,x8t),e(Iy,$8t),e(Ie,k8t),e(Ie,Ny),e(Ny,oNe),e(oNe,S8t),e(Ny,R8t),e(Ny,pce),e(pce,P8t),e(Ny,B8t),e(Ie,I8t),e(Ie,qy),e(qy,rNe),e(rNe,N8t),e(qy,q8t),e(qy,_ce),e(_ce,D8t),e(qy,j8t),e(Ie,G8t),e(Ie,Dy),e(Dy,tNe),e(tNe,O8t),e(Dy,V8t),e(Dy,bce),e(bce,X8t),e(Dy,z8t),e(Ie,Q8t),e(Ie,jy),e(jy,aNe),e(aNe,W8t),e(jy,U8t),e(jy,vce),e(vce,H8t),e(jy,J8t),e(Ie,Y8t),e(Ie,Gy),e(Gy,nNe),e(nNe,Z8t),e(Gy,K8t),e(Gy,Fce),e(Fce,eLt),e(Gy,oLt),e(Ie,rLt),e(Ie,Oy),e(Oy,sNe),e(sNe,tLt),e(Oy,aLt),e(Oy,Tce),e(Tce,nLt),e(Oy,sLt),e(ft,lLt),M(Vy,ft,null),b(c,Tdo,_),b(c,If,_),e(If,Xy),e(Xy,lNe),M(kI,lNe,null),e(If,iLt),e(If,iNe),e(iNe,dLt),b(c,Mdo,_),b(c,Nr,_),M(SI,Nr,null),e(Nr,mLt),e(Nr,Nf),e(Nf,cLt),e(Nf,Mce),e(Mce,fLt),e(Nf,gLt),e(Nf,Ece),e(Ece,hLt),e(Nf,uLt),e(Nr,pLt),e(Nr,RI),e(RI,_Lt),e(RI,dNe),e(dNe,bLt),e(RI,vLt),e(Nr,FLt),e(Nr,Ca),M(PI,Ca,null),e(Ca,TLt),e(Ca,mNe),e(mNe,MLt),e(Ca,ELt),e(Ca,qf),e(qf,CLt),e(qf,cNe),e(cNe,wLt),e(qf,ALt),e(qf,Cce),e(Cce,LLt),e(qf,yLt),e(Ca,xLt),M(zy,Ca,null),e(Nr,$Lt),e(Nr,gt),M(BI,gt,null),e(gt,kLt),e(gt,fNe),e(fNe,SLt),e(gt,RLt),e(gt,ms),e(ms,PLt),e(ms,gNe),e(gNe,BLt),e(ms,ILt),e(ms,hNe),e(hNe,NLt),e(ms,qLt),e(ms,uNe),e(uNe,DLt),e(ms,jLt),e(gt,GLt),e(gt,We),e(We,Qy),e(Qy,pNe),e(pNe,OLt),e(Qy,VLt),e(Qy,wce),e(wce,XLt),e(Qy,zLt),e(We,QLt),e(We,Wy),e(Wy,_Ne),e(_Ne,WLt),e(Wy,ULt),e(Wy,Ace),e(Ace,HLt),e(Wy,JLt),e(We,YLt),e(We,Uy),e(Uy,bNe),e(bNe,ZLt),e(Uy,KLt),e(Uy,Lce),e(Lce,eyt),e(Uy,oyt),e(We,ryt),e(We,Hy),e(Hy,vNe),e(vNe,tyt),e(Hy,ayt),e(Hy,yce),e(yce,nyt),e(Hy,syt),e(We,lyt),e(We,Jy),e(Jy,FNe),e(FNe,iyt),e(Jy,dyt),e(Jy,xce),e(xce,myt),e(Jy,cyt),e(We,fyt),e(We,Yy),e(Yy,TNe),e(TNe,gyt),e(Yy,hyt),e(Yy,$ce),e($ce,uyt),e(Yy,pyt),e(We,_yt),e(We,Zy),e(Zy,MNe),e(MNe,byt),e(Zy,vyt),e(Zy,kce),e(kce,Fyt),e(Zy,Tyt),e(We,Myt),e(We,Ky),e(Ky,ENe),e(ENe,Eyt),e(Ky,Cyt),e(Ky,Sce),e(Sce,wyt),e(Ky,Ayt),e(gt,Lyt),M(e9,gt,null),b(c,Edo,_),b(c,Df,_),e(Df,o9),e(o9,CNe),M(II,CNe,null),e(Df,yyt),e(Df,wNe),e(wNe,xyt),b(c,Cdo,_),b(c,qr,_),M(NI,qr,null),e(qr,$yt),e(qr,jf),e(jf,kyt),e(jf,Rce),e(Rce,Syt),e(jf,Ryt),e(jf,Pce),e(Pce,Pyt),e(jf,Byt),e(qr,Iyt),e(qr,qI),e(qI,Nyt),e(qI,ANe),e(ANe,qyt),e(qI,Dyt),e(qr,jyt),e(qr,wa),M(DI,wa,null),e(wa,Gyt),e(wa,LNe),e(LNe,Oyt),e(wa,Vyt),e(wa,Gf),e(Gf,Xyt),e(Gf,yNe),e(yNe,zyt),e(Gf,Qyt),e(Gf,Bce),e(Bce,Wyt),e(Gf,Uyt),e(wa,Hyt),M(r9,wa,null),e(qr,Jyt),e(qr,ht),M(jI,ht,null),e(ht,Yyt),e(ht,xNe),e(xNe,Zyt),e(ht,Kyt),e(ht,cs),e(cs,e9t),e(cs,$Ne),e($Ne,o9t),e(cs,r9t),e(cs,kNe),e(kNe,t9t),e(cs,a9t),e(cs,SNe),e(SNe,n9t),e(cs,s9t),e(ht,l9t),e(ht,Ue),e(Ue,t9),e(t9,RNe),e(RNe,i9t),e(t9,d9t),e(t9,Ice),e(Ice,m9t),e(t9,c9t),e(Ue,f9t),e(Ue,a9),e(a9,PNe),e(PNe,g9t),e(a9,h9t),e(a9,Nce),e(Nce,u9t),e(a9,p9t),e(Ue,_9t),e(Ue,n9),e(n9,BNe),e(BNe,b9t),e(n9,v9t),e(n9,qce),e(qce,F9t),e(n9,T9t),e(Ue,M9t),e(Ue,s9),e(s9,INe),e(INe,E9t),e(s9,C9t),e(s9,Dce),e(Dce,w9t),e(s9,A9t),e(Ue,L9t),e(Ue,l9),e(l9,NNe),e(NNe,y9t),e(l9,x9t),e(l9,jce),e(jce,$9t),e(l9,k9t),e(Ue,S9t),e(Ue,i9),e(i9,qNe),e(qNe,R9t),e(i9,P9t),e(i9,Gce),e(Gce,B9t),e(i9,I9t),e(Ue,N9t),e(Ue,d9),e(d9,DNe),e(DNe,q9t),e(d9,D9t),e(d9,Oce),e(Oce,j9t),e(d9,G9t),e(Ue,O9t),e(Ue,m9),e(m9,jNe),e(jNe,V9t),e(m9,X9t),e(m9,Vce),e(Vce,z9t),e(m9,Q9t),e(ht,W9t),M(c9,ht,null),b(c,wdo,_),b(c,Of,_),e(Of,f9),e(f9,GNe),M(GI,GNe,null),e(Of,U9t),e(Of,ONe),e(ONe,H9t),b(c,Ado,_),b(c,Dr,_),M(OI,Dr,null),e(Dr,J9t),e(Dr,Vf),e(Vf,Y9t),e(Vf,Xce),e(Xce,Z9t),e(Vf,K9t),e(Vf,zce),e(zce,ext),e(Vf,oxt),e(Dr,rxt),e(Dr,VI),e(VI,txt),e(VI,VNe),e(VNe,axt),e(VI,nxt),e(Dr,sxt),e(Dr,Aa),M(XI,Aa,null),e(Aa,lxt),e(Aa,XNe),e(XNe,ixt),e(Aa,dxt),e(Aa,Xf),e(Xf,mxt),e(Xf,zNe),e(zNe,cxt),e(Xf,fxt),e(Xf,Qce),e(Qce,gxt),e(Xf,hxt),e(Aa,uxt),M(g9,Aa,null),e(Dr,pxt),e(Dr,ut),M(zI,ut,null),e(ut,_xt),e(ut,QNe),e(QNe,bxt),e(ut,vxt),e(ut,fs),e(fs,Fxt),e(fs,WNe),e(WNe,Txt),e(fs,Mxt),e(fs,UNe),e(UNe,Ext),e(fs,Cxt),e(fs,HNe),e(HNe,wxt),e(fs,Axt),e(ut,Lxt),e(ut,JNe),e(JNe,h9),e(h9,YNe),e(YNe,yxt),e(h9,xxt),e(h9,Wce),e(Wce,$xt),e(h9,kxt),e(ut,Sxt),M(u9,ut,null),b(c,Ldo,_),b(c,zf,_),e(zf,p9),e(p9,ZNe),M(QI,ZNe,null),e(zf,Rxt),e(zf,KNe),e(KNe,Pxt),b(c,ydo,_),b(c,jr,_),M(WI,jr,null),e(jr,Bxt),e(jr,Qf),e(Qf,Ixt),e(Qf,Uce),e(Uce,Nxt),e(Qf,qxt),e(Qf,Hce),e(Hce,Dxt),e(Qf,jxt),e(jr,Gxt),e(jr,UI),e(UI,Oxt),e(UI,eqe),e(eqe,Vxt),e(UI,Xxt),e(jr,zxt),e(jr,La),M(HI,La,null),e(La,Qxt),e(La,oqe),e(oqe,Wxt),e(La,Uxt),e(La,Wf),e(Wf,Hxt),e(Wf,rqe),e(rqe,Jxt),e(Wf,Yxt),e(Wf,Jce),e(Jce,Zxt),e(Wf,Kxt),e(La,e$t),M(_9,La,null),e(jr,o$t),e(jr,pt),M(JI,pt,null),e(pt,r$t),e(pt,tqe),e(tqe,t$t),e(pt,a$t),e(pt,gs),e(gs,n$t),e(gs,aqe),e(aqe,s$t),e(gs,l$t),e(gs,nqe),e(nqe,i$t),e(gs,d$t),e(gs,sqe),e(sqe,m$t),e(gs,c$t),e(pt,f$t),e(pt,YI),e(YI,b9),e(b9,lqe),e(lqe,g$t),e(b9,h$t),e(b9,Yce),e(Yce,u$t),e(b9,p$t),e(YI,_$t),e(YI,v9),e(v9,iqe),e(iqe,b$t),e(v9,v$t),e(v9,Zce),e(Zce,F$t),e(v9,T$t),e(pt,M$t),M(F9,pt,null),b(c,xdo,_),b(c,Uf,_),e(Uf,T9),e(T9,dqe),M(ZI,dqe,null),e(Uf,E$t),e(Uf,mqe),e(mqe,C$t),b(c,$do,_),b(c,Gr,_),M(KI,Gr,null),e(Gr,w$t),e(Gr,Hf),e(Hf,A$t),e(Hf,Kce),e(Kce,L$t),e(Hf,y$t),e(Hf,efe),e(efe,x$t),e(Hf,$$t),e(Gr,k$t),e(Gr,eN),e(eN,S$t),e(eN,cqe),e(cqe,R$t),e(eN,P$t),e(Gr,B$t),e(Gr,ya),M(oN,ya,null),e(ya,I$t),e(ya,fqe),e(fqe,N$t),e(ya,q$t),e(ya,Jf),e(Jf,D$t),e(Jf,gqe),e(gqe,j$t),e(Jf,G$t),e(Jf,ofe),e(ofe,O$t),e(Jf,V$t),e(ya,X$t),M(M9,ya,null),e(Gr,z$t),e(Gr,_t),M(rN,_t,null),e(_t,Q$t),e(_t,hqe),e(hqe,W$t),e(_t,U$t),e(_t,hs),e(hs,H$t),e(hs,uqe),e(uqe,J$t),e(hs,Y$t),e(hs,pqe),e(pqe,Z$t),e(hs,K$t),e(hs,_qe),e(_qe,ekt),e(hs,okt),e(_t,rkt),e(_t,bqe),e(bqe,E9),e(E9,vqe),e(vqe,tkt),e(E9,akt),e(E9,rfe),e(rfe,nkt),e(E9,skt),e(_t,lkt),M(C9,_t,null),kdo=!0},p(c,[_]){const tN={};_&2&&(tN.$$scope={dirty:_,ctx:c}),ng.$set(tN);const Fqe={};_&2&&(Fqe.$$scope={dirty:_,ctx:c}),Iu.$set(Fqe);const Tqe={};_&2&&(Tqe.$$scope={dirty:_,ctx:c}),Tp.$set(Tqe);const Mqe={};_&2&&(Mqe.$$scope={dirty:_,ctx:c}),u_.$set(Mqe);const aN={};_&2&&(aN.$$scope={dirty:_,ctx:c}),p_.$set(aN);const Eqe={};_&2&&(Eqe.$$scope={dirty:_,ctx:c}),U_.$set(Eqe);const us={};_&2&&(us.$$scope={dirty:_,ctx:c}),H_.$set(us);const Cqe={};_&2&&(Cqe.$$scope={dirty:_,ctx:c}),T1.$set(Cqe);const wqe={};_&2&&(wqe.$$scope={dirty:_,ctx:c}),M1.$set(wqe);const Aqe={};_&2&&(Aqe.$$scope={dirty:_,ctx:c}),w1.$set(Aqe);const nN={};_&2&&(nN.$$scope={dirty:_,ctx:c}),Hb.$set(nN);const Lqe={};_&2&&(Lqe.$$scope={dirty:_,ctx:c}),Yb.$set(Lqe);const sN={};_&2&&(sN.$$scope={dirty:_,ctx:c}),Uv.$set(sN);const yqe={};_&2&&(yqe.$$scope={dirty:_,ctx:c}),Jv.$set(yqe);const lN={};_&2&&(lN.$$scope={dirty:_,ctx:c}),GF.$set(lN);const xqe={};_&2&&(xqe.$$scope={dirty:_,ctx:c}),VF.$set(xqe);const $qe={};_&2&&($qe.$$scope={dirty:_,ctx:c}),WF.$set($qe);const kqe={};_&2&&(kqe.$$scope={dirty:_,ctx:c}),HF.$set(kqe);const Yf={};_&2&&(Yf.$$scope={dirty:_,ctx:c}),NT.$set(Yf);const Sqe={};_&2&&(Sqe.$$scope={dirty:_,ctx:c}),DT.$set(Sqe);const Rqe={};_&2&&(Rqe.$$scope={dirty:_,ctx:c}),lM.$set(Rqe);const Pqe={};_&2&&(Pqe.$$scope={dirty:_,ctx:c}),dM.$set(Pqe);const iN={};_&2&&(iN.$$scope={dirty:_,ctx:c}),hE.$set(iN);const Bqe={};_&2&&(Bqe.$$scope={dirty:_,ctx:c}),pE.$set(Bqe);const Iqe={};_&2&&(Iqe.$$scope={dirty:_,ctx:c}),YE.$set(Iqe);const Nqe={};_&2&&(Nqe.$$scope={dirty:_,ctx:c}),KE.$set(Nqe);const Et={};_&2&&(Et.$$scope={dirty:_,ctx:c}),i4.$set(Et);const dN={};_&2&&(dN.$$scope={dirty:_,ctx:c}),m4.$set(dN);const qqe={};_&2&&(qqe.$$scope={dirty:_,ctx:c}),eC.$set(qqe);const mN={};_&2&&(mN.$$scope={dirty:_,ctx:c}),rC.$set(mN);const Dqe={};_&2&&(Dqe.$$scope={dirty:_,ctx:c}),KC.$set(Dqe);const Ct={};_&2&&(Ct.$$scope={dirty:_,ctx:c}),o3.$set(Ct);const jqe={};_&2&&(jqe.$$scope={dirty:_,ctx:c}),a3.$set(jqe);const Zf={};_&2&&(Zf.$$scope={dirty:_,ctx:c}),s3.$set(Zf);const Gqe={};_&2&&(Gqe.$$scope={dirty:_,ctx:c}),c3.$set(Gqe);const Oqe={};_&2&&(Oqe.$$scope={dirty:_,ctx:c}),g3.$set(Oqe);const L={};_&2&&(L.$$scope={dirty:_,ctx:c}),$3.$set(L);const w9={};_&2&&(w9.$$scope={dirty:_,ctx:c}),S3.$set(w9);const Vqe={};_&2&&(Vqe.$$scope={dirty:_,ctx:c}),B3.$set(Vqe);const Xqe={};_&2&&(Xqe.$$scope={dirty:_,ctx:c}),N3.$set(Xqe);const A9={};_&2&&(A9.$$scope={dirty:_,ctx:c}),j3.$set(A9);const zqe={};_&2&&(zqe.$$scope={dirty:_,ctx:c}),O3.$set(zqe);const Qqe={};_&2&&(Qqe.$$scope={dirty:_,ctx:c}),z3.$set(Qqe);const L9={};_&2&&(L9.$$scope={dirty:_,ctx:c}),W3.$set(L9);const Wqe={};_&2&&(Wqe.$$scope={dirty:_,ctx:c}),a5.$set(Wqe);const Uqe={};_&2&&(Uqe.$$scope={dirty:_,ctx:c}),s5.$set(Uqe);const y9={};_&2&&(y9.$$scope={dirty:_,ctx:c}),g5.$set(y9);const Hqe={};_&2&&(Hqe.$$scope={dirty:_,ctx:c}),u5.$set(Hqe);const Jqe={};_&2&&(Jqe.$$scope={dirty:_,ctx:c}),L5.$set(Jqe);const x9={};_&2&&(x9.$$scope={dirty:_,ctx:c}),x5.$set(x9);const Yqe={};_&2&&(Yqe.$$scope={dirty:_,ctx:c}),P5.$set(Yqe);const Zqe={};_&2&&(Zqe.$$scope={dirty:_,ctx:c}),I5.$set(Zqe);const $9={};_&2&&($9.$$scope={dirty:_,ctx:c}),V5.$set($9);const Kqe={};_&2&&(Kqe.$$scope={dirty:_,ctx:c}),z5.$set(Kqe);const eDe={};_&2&&(eDe.$$scope={dirty:_,ctx:c}),Y5.$set(eDe);const k9={};_&2&&(k9.$$scope={dirty:_,ctx:c}),K5.$set(k9);const oDe={};_&2&&(oDe.$$scope={dirty:_,ctx:c}),s0.$set(oDe);const rDe={};_&2&&(rDe.$$scope={dirty:_,ctx:c}),i0.$set(rDe);const S9={};_&2&&(S9.$$scope={dirty:_,ctx:c}),c0.$set(S9);const tDe={};_&2&&(tDe.$$scope={dirty:_,ctx:c}),g0.$set(tDe);const aDe={};_&2&&(aDe.$$scope={dirty:_,ctx:c}),F0.$set(aDe);const R9={};_&2&&(R9.$$scope={dirty:_,ctx:c}),M0.$set(R9);const nDe={};_&2&&(nDe.$$scope={dirty:_,ctx:c}),w0.$set(nDe);const sDe={};_&2&&(sDe.$$scope={dirty:_,ctx:c}),L0.$set(sDe);const P9={};_&2&&(P9.$$scope={dirty:_,ctx:c}),$0.$set(P9);const lDe={};_&2&&(lDe.$$scope={dirty:_,ctx:c}),S0.$set(lDe);const iDe={};_&2&&(iDe.$$scope={dirty:_,ctx:c}),Iw.$set(iDe);const B9={};_&2&&(B9.$$scope={dirty:_,ctx:c}),qw.$set(B9);const dDe={};_&2&&(dDe.$$scope={dirty:_,ctx:c}),iA.$set(dDe);const mDe={};_&2&&(mDe.$$scope={dirty:_,ctx:c}),mA.$set(mDe);const I9={};_&2&&(I9.$$scope={dirty:_,ctx:c}),wA.$set(I9);const cDe={};_&2&&(cDe.$$scope={dirty:_,ctx:c}),LA.$set(cDe);const fDe={};_&2&&(fDe.$$scope={dirty:_,ctx:c}),NA.$set(fDe);const N9={};_&2&&(N9.$$scope={dirty:_,ctx:c}),DA.$set(N9);const gDe={};_&2&&(gDe.$$scope={dirty:_,ctx:c}),VA.$set(gDe);const hDe={};_&2&&(hDe.$$scope={dirty:_,ctx:c}),zA.$set(hDe);const q9={};_&2&&(q9.$$scope={dirty:_,ctx:c}),g6.$set(q9);const uDe={};_&2&&(uDe.$$scope={dirty:_,ctx:c}),u6.$set(uDe);const pDe={};_&2&&(pDe.$$scope={dirty:_,ctx:c}),A6.$set(pDe);const D9={};_&2&&(D9.$$scope={dirty:_,ctx:c}),y6.$set(D9);const _De={};_&2&&(_De.$$scope={dirty:_,ctx:c}),t7.$set(_De);const bDe={};_&2&&(bDe.$$scope={dirty:_,ctx:c}),n7.$set(bDe);const j9={};_&2&&(j9.$$scope={dirty:_,ctx:c}),E7.$set(j9);const vDe={};_&2&&(vDe.$$scope={dirty:_,ctx:c}),w7.$set(vDe);const FDe={};_&2&&(FDe.$$scope={dirty:_,ctx:c}),y7.$set(FDe);const G9={};_&2&&(G9.$$scope={dirty:_,ctx:c}),$7.$set(G9);const TDe={};_&2&&(TDe.$$scope={dirty:_,ctx:c}),S7.$set(TDe);const MDe={};_&2&&(MDe.$$scope={dirty:_,ctx:c}),P7.$set(MDe);const O9={};_&2&&(O9.$$scope={dirty:_,ctx:c}),I7.$set(O9);const EDe={};_&2&&(EDe.$$scope={dirty:_,ctx:c}),q7.$set(EDe);const CDe={};_&2&&(CDe.$$scope={dirty:_,ctx:c}),l8.$set(CDe);const V9={};_&2&&(V9.$$scope={dirty:_,ctx:c}),d8.$set(V9);const wDe={};_&2&&(wDe.$$scope={dirty:_,ctx:c}),k8.$set(wDe);const ADe={};_&2&&(ADe.$$scope={dirty:_,ctx:c}),R8.$set(ADe);const X9={};_&2&&(X9.$$scope={dirty:_,ctx:c}),B8.$set(X9);const LDe={};_&2&&(LDe.$$scope={dirty:_,ctx:c}),N8.$set(LDe);const yDe={};_&2&&(yDe.$$scope={dirty:_,ctx:c}),j8.$set(yDe);const z9={};_&2&&(z9.$$scope={dirty:_,ctx:c}),O8.$set(z9);const xDe={};_&2&&(xDe.$$scope={dirty:_,ctx:c}),pL.$set(xDe);const $De={};_&2&&($De.$$scope={dirty:_,ctx:c}),bL.$set($De);const Q9={};_&2&&(Q9.$$scope={dirty:_,ctx:c}),xL.$set(Q9);const kDe={};_&2&&(kDe.$$scope={dirty:_,ctx:c}),kL.$set(kDe);const SDe={};_&2&&(SDe.$$scope={dirty:_,ctx:c}),zL.$set(SDe);const W9={};_&2&&(W9.$$scope={dirty:_,ctx:c}),WL.$set(W9);const RDe={};_&2&&(RDe.$$scope={dirty:_,ctx:c}),ay.$set(RDe);const PDe={};_&2&&(PDe.$$scope={dirty:_,ctx:c}),sy.$set(PDe);const U9={};_&2&&(U9.$$scope={dirty:_,ctx:c}),_y.$set(U9);const BDe={};_&2&&(BDe.$$scope={dirty:_,ctx:c}),vy.$set(BDe);const IDe={};_&2&&(IDe.$$scope={dirty:_,ctx:c}),$y.$set(IDe);const H9={};_&2&&(H9.$$scope={dirty:_,ctx:c}),Sy.$set(H9);const NDe={};_&2&&(NDe.$$scope={dirty:_,ctx:c}),Vy.$set(NDe);const qDe={};_&2&&(qDe.$$scope={dirty:_,ctx:c}),zy.$set(qDe);const J9={};_&2&&(J9.$$scope={dirty:_,ctx:c}),e9.$set(J9);const DDe={};_&2&&(DDe.$$scope={dirty:_,ctx:c}),r9.$set(DDe);const jDe={};_&2&&(jDe.$$scope={dirty:_,ctx:c}),c9.$set(jDe);const Y9={};_&2&&(Y9.$$scope={dirty:_,ctx:c}),g9.$set(Y9);const GDe={};_&2&&(GDe.$$scope={dirty:_,ctx:c}),u9.$set(GDe);const ODe={};_&2&&(ODe.$$scope={dirty:_,ctx:c}),_9.$set(ODe);const Z9={};_&2&&(Z9.$$scope={dirty:_,ctx:c}),F9.$set(Z9);const VDe={};_&2&&(VDe.$$scope={dirty:_,ctx:c}),M9.$set(VDe);const XDe={};_&2&&(XDe.$$scope={dirty:_,ctx:c}),C9.$set(XDe)},i(c){kdo||(E(m.$$.fragment,c),E(sn.$$.fragment,c),E(ck.$$.fragment,c),E(fk.$$.fragment,c),E(ng.$$.fragment,c),E(gk.$$.fragment,c),E(hk.$$.fragment,c),E(_k.$$.fragment,c),E(Iu.$$.fragment,c),E(bk.$$.fragment,c),E(vk.$$.fragment,c),E(Fk.$$.fragment,c),E(Ek.$$.fragment,c),E(Tp.$$.fragment,c),E(Ck.$$.fragment,c),E(wk.$$.fragment,c),E(Ak.$$.fragment,c),E(xk.$$.fragment,c),E(u_.$$.fragment,c),E(p_.$$.fragment,c),E($k.$$.fragment,c),E(kk.$$.fragment,c),E(Sk.$$.fragment,c),E(Bk.$$.fragment,c),E(U_.$$.fragment,c),E(H_.$$.fragment,c),E(Ik.$$.fragment,c),E(Nk.$$.fragment,c),E(qk.$$.fragment,c),E(Gk.$$.fragment,c),E(T1.$$.fragment,c),E(M1.$$.fragment,c),E(Ok.$$.fragment,c),E(Vk.$$.fragment,c),E(Xk.$$.fragment,c),E(Qk.$$.fragment,c),E(w1.$$.fragment,c),E(Wk.$$.fragment,c),E(Hb.$$.fragment,c),E(Uk.$$.fragment,c),E(Hk.$$.fragment,c),E(Yk.$$.fragment,c),E(Yb.$$.fragment,c),E(Zk.$$.fragment,c),E(Uv.$$.fragment,c),E(Kk.$$.fragment,c),E(eS.$$.fragment,c),E(rS.$$.fragment,c),E(Jv.$$.fragment,c),E(tS.$$.fragment,c),E(GF.$$.fragment,c),E(aS.$$.fragment,c),E(nS.$$.fragment,c),E(lS.$$.fragment,c),E(VF.$$.fragment,c),E(iS.$$.fragment,c),E(WF.$$.fragment,c),E(mS.$$.fragment,c),E(cS.$$.fragment,c),E(gS.$$.fragment,c),E(HF.$$.fragment,c),E(hS.$$.fragment,c),E(NT.$$.fragment,c),E(uS.$$.fragment,c),E(pS.$$.fragment,c),E(bS.$$.fragment,c),E(DT.$$.fragment,c),E(vS.$$.fragment,c),E(lM.$$.fragment,c),E(FS.$$.fragment,c),E(TS.$$.fragment,c),E(ES.$$.fragment,c),E(dM.$$.fragment,c),E(CS.$$.fragment,c),E(hE.$$.fragment,c),E(wS.$$.fragment,c),E(AS.$$.fragment,c),E(yS.$$.fragment,c),E(pE.$$.fragment,c),E(xS.$$.fragment,c),E(YE.$$.fragment,c),E($S.$$.fragment,c),E(kS.$$.fragment,c),E(RS.$$.fragment,c),E(KE.$$.fragment,c),E(PS.$$.fragment,c),E(i4.$$.fragment,c),E(BS.$$.fragment,c),E(IS.$$.fragment,c),E(qS.$$.fragment,c),E(m4.$$.fragment,c),E(DS.$$.fragment,c),E(eC.$$.fragment,c),E(jS.$$.fragment,c),E(GS.$$.fragment,c),E(VS.$$.fragment,c),E(rC.$$.fragment,c),E(XS.$$.fragment,c),E(KC.$$.fragment,c),E(zS.$$.fragment,c),E(QS.$$.fragment,c),E(US.$$.fragment,c),E(o3.$$.fragment,c),E(HS.$$.fragment,c),E(a3.$$.fragment,c),E(JS.$$.fragment,c),E(YS.$$.fragment,c),E(KS.$$.fragment,c),E(s3.$$.fragment,c),E(eR.$$.fragment,c),E(c3.$$.fragment,c),E(oR.$$.fragment,c),E(rR.$$.fragment,c),E(aR.$$.fragment,c),E(g3.$$.fragment,c),E(nR.$$.fragment,c),E($3.$$.fragment,c),E(sR.$$.fragment,c),E(lR.$$.fragment,c),E(dR.$$.fragment,c),E(S3.$$.fragment,c),E(mR.$$.fragment,c),E(B3.$$.fragment,c),E(cR.$$.fragment,c),E(fR.$$.fragment,c),E(hR.$$.fragment,c),E(N3.$$.fragment,c),E(uR.$$.fragment,c),E(j3.$$.fragment,c),E(pR.$$.fragment,c),E(_R.$$.fragment,c),E(vR.$$.fragment,c),E(O3.$$.fragment,c),E(FR.$$.fragment,c),E(z3.$$.fragment,c),E(TR.$$.fragment,c),E(MR.$$.fragment,c),E(CR.$$.fragment,c),E(W3.$$.fragment,c),E(wR.$$.fragment,c),E(a5.$$.fragment,c),E(AR.$$.fragment,c),E(LR.$$.fragment,c),E(xR.$$.fragment,c),E(s5.$$.fragment,c),E($R.$$.fragment,c),E(g5.$$.fragment,c),E(kR.$$.fragment,c),E(SR.$$.fragment,c),E(PR.$$.fragment,c),E(u5.$$.fragment,c),E(BR.$$.fragment,c),E(L5.$$.fragment,c),E(IR.$$.fragment,c),E(NR.$$.fragment,c),E(DR.$$.fragment,c),E(x5.$$.fragment,c),E(jR.$$.fragment,c),E(P5.$$.fragment,c),E(GR.$$.fragment,c),E(OR.$$.fragment,c),E(XR.$$.fragment,c),E(I5.$$.fragment,c),E(zR.$$.fragment,c),E(V5.$$.fragment,c),E(QR.$$.fragment,c),E(WR.$$.fragment,c),E(HR.$$.fragment,c),E(z5.$$.fragment,c),E(JR.$$.fragment,c),E(Y5.$$.fragment,c),E(YR.$$.fragment,c),E(ZR.$$.fragment,c),E(eP.$$.fragment,c),E(K5.$$.fragment,c),E(oP.$$.fragment,c),E(s0.$$.fragment,c),E(rP.$$.fragment,c),E(tP.$$.fragment,c),E(nP.$$.fragment,c),E(i0.$$.fragment,c),E(sP.$$.fragment,c),E(c0.$$.fragment,c),E(lP.$$.fragment,c),E(iP.$$.fragment,c),E(mP.$$.fragment,c),E(g0.$$.fragment,c),E(cP.$$.fragment,c),E(F0.$$.fragment,c),E(fP.$$.fragment,c),E(gP.$$.fragment,c),E(uP.$$.fragment,c),E(M0.$$.fragment,c),E(pP.$$.fragment,c),E(w0.$$.fragment,c),E(_P.$$.fragment,c),E(bP.$$.fragment,c),E(FP.$$.fragment,c),E(L0.$$.fragment,c),E(TP.$$.fragment,c),E($0.$$.fragment,c),E(MP.$$.fragment,c),E(EP.$$.fragment,c),E(wP.$$.fragment,c),E(S0.$$.fragment,c),E(AP.$$.fragment,c),E(Iw.$$.fragment,c),E(LP.$$.fragment,c),E(yP.$$.fragment,c),E($P.$$.fragment,c),E(qw.$$.fragment,c),E(kP.$$.fragment,c),E(iA.$$.fragment,c),E(SP.$$.fragment,c),E(RP.$$.fragment,c),E(BP.$$.fragment,c),E(mA.$$.fragment,c),E(IP.$$.fragment,c),E(wA.$$.fragment,c),E(NP.$$.fragment,c),E(qP.$$.fragment,c),E(jP.$$.fragment,c),E(LA.$$.fragment,c),E(GP.$$.fragment,c),E(NA.$$.fragment,c),E(OP.$$.fragment,c),E(VP.$$.fragment,c),E(zP.$$.fragment,c),E(DA.$$.fragment,c),E(QP.$$.fragment,c),E(VA.$$.fragment,c),E(WP.$$.fragment,c),E(UP.$$.fragment,c),E(JP.$$.fragment,c),E(zA.$$.fragment,c),E(YP.$$.fragment,c),E(g6.$$.fragment,c),E(ZP.$$.fragment,c),E(KP.$$.fragment,c),E(oB.$$.fragment,c),E(u6.$$.fragment,c),E(rB.$$.fragment,c),E(A6.$$.fragment,c),E(tB.$$.fragment,c),E(aB.$$.fragment,c),E(sB.$$.fragment,c),E(y6.$$.fragment,c),E(lB.$$.fragment,c),E(t7.$$.fragment,c),E(iB.$$.fragment,c),E(dB.$$.fragment,c),E(cB.$$.fragment,c),E(n7.$$.fragment,c),E(fB.$$.fragment,c),E(E7.$$.fragment,c),E(gB.$$.fragment,c),E(hB.$$.fragment,c),E(pB.$$.fragment,c),E(w7.$$.fragment,c),E(_B.$$.fragment,c),E(y7.$$.fragment,c),E(vB.$$.fragment,c),E(FB.$$.fragment,c),E(MB.$$.fragment,c),E($7.$$.fragment,c),E(EB.$$.fragment,c),E(S7.$$.fragment,c),E(CB.$$.fragment,c),E(wB.$$.fragment,c),E(LB.$$.fragment,c),E(P7.$$.fragment,c),E(yB.$$.fragment,c),E(I7.$$.fragment,c),E(xB.$$.fragment,c),E($B.$$.fragment,c),E(SB.$$.fragment,c),E(q7.$$.fragment,c),E(RB.$$.fragment,c),E(l8.$$.fragment,c),E(PB.$$.fragment,c),E(BB.$$.fragment,c),E(NB.$$.fragment,c),E(d8.$$.fragment,c),E(qB.$$.fragment,c),E(k8.$$.fragment,c),E(DB.$$.fragment,c),E(jB.$$.fragment,c),E(OB.$$.fragment,c),E(R8.$$.fragment,c),E(VB.$$.fragment,c),E(B8.$$.fragment,c),E(XB.$$.fragment,c),E(zB.$$.fragment,c),E(WB.$$.fragment,c),E(N8.$$.fragment,c),E(UB.$$.fragment,c),E(j8.$$.fragment,c),E(JB.$$.fragment,c),E(YB.$$.fragment,c),E(KB.$$.fragment,c),E(O8.$$.fragment,c),E(eI.$$.fragment,c),E(pL.$$.fragment,c),E(oI.$$.fragment,c),E(rI.$$.fragment,c),E(aI.$$.fragment,c),E(bL.$$.fragment,c),E(nI.$$.fragment,c),E(xL.$$.fragment,c),E(sI.$$.fragment,c),E(lI.$$.fragment,c),E(dI.$$.fragment,c),E(kL.$$.fragment,c),E(mI.$$.fragment,c),E(zL.$$.fragment,c),E(cI.$$.fragment,c),E(fI.$$.fragment,c),E(hI.$$.fragment,c),E(WL.$$.fragment,c),E(uI.$$.fragment,c),E(ay.$$.fragment,c),E(pI.$$.fragment,c),E(_I.$$.fragment,c),E(vI.$$.fragment,c),E(sy.$$.fragment,c),E(FI.$$.fragment,c),E(_y.$$.fragment,c),E(TI.$$.fragment,c),E(MI.$$.fragment,c),E(CI.$$.fragment,c),E(vy.$$.fragment,c),E(wI.$$.fragment,c),E($y.$$.fragment,c),E(AI.$$.fragment,c),E(LI.$$.fragment,c),E(xI.$$.fragment,c),E(Sy.$$.fragment,c),E($I.$$.fragment,c),E(Vy.$$.fragment,c),E(kI.$$.fragment,c),E(SI.$$.fragment,c),E(PI.$$.fragment,c),E(zy.$$.fragment,c),E(BI.$$.fragment,c),E(e9.$$.fragment,c),E(II.$$.fragment,c),E(NI.$$.fragment,c),E(DI.$$.fragment,c),E(r9.$$.fragment,c),E(jI.$$.fragment,c),E(c9.$$.fragment,c),E(GI.$$.fragment,c),E(OI.$$.fragment,c),E(XI.$$.fragment,c),E(g9.$$.fragment,c),E(zI.$$.fragment,c),E(u9.$$.fragment,c),E(QI.$$.fragment,c),E(WI.$$.fragment,c),E(HI.$$.fragment,c),E(_9.$$.fragment,c),E(JI.$$.fragment,c),E(F9.$$.fragment,c),E(ZI.$$.fragment,c),E(KI.$$.fragment,c),E(oN.$$.fragment,c),E(M9.$$.fragment,c),E(rN.$$.fragment,c),E(C9.$$.fragment,c),kdo=!0)},o(c){C(m.$$.fragment,c),C(sn.$$.fragment,c),C(ck.$$.fragment,c),C(fk.$$.fragment,c),C(ng.$$.fragment,c),C(gk.$$.fragment,c),C(hk.$$.fragment,c),C(_k.$$.fragment,c),C(Iu.$$.fragment,c),C(bk.$$.fragment,c),C(vk.$$.fragment,c),C(Fk.$$.fragment,c),C(Ek.$$.fragment,c),C(Tp.$$.fragment,c),C(Ck.$$.fragment,c),C(wk.$$.fragment,c),C(Ak.$$.fragment,c),C(xk.$$.fragment,c),C(u_.$$.fragment,c),C(p_.$$.fragment,c),C($k.$$.fragment,c),C(kk.$$.fragment,c),C(Sk.$$.fragment,c),C(Bk.$$.fragment,c),C(U_.$$.fragment,c),C(H_.$$.fragment,c),C(Ik.$$.fragment,c),C(Nk.$$.fragment,c),C(qk.$$.fragment,c),C(Gk.$$.fragment,c),C(T1.$$.fragment,c),C(M1.$$.fragment,c),C(Ok.$$.fragment,c),C(Vk.$$.fragment,c),C(Xk.$$.fragment,c),C(Qk.$$.fragment,c),C(w1.$$.fragment,c),C(Wk.$$.fragment,c),C(Hb.$$.fragment,c),C(Uk.$$.fragment,c),C(Hk.$$.fragment,c),C(Yk.$$.fragment,c),C(Yb.$$.fragment,c),C(Zk.$$.fragment,c),C(Uv.$$.fragment,c),C(Kk.$$.fragment,c),C(eS.$$.fragment,c),C(rS.$$.fragment,c),C(Jv.$$.fragment,c),C(tS.$$.fragment,c),C(GF.$$.fragment,c),C(aS.$$.fragment,c),C(nS.$$.fragment,c),C(lS.$$.fragment,c),C(VF.$$.fragment,c),C(iS.$$.fragment,c),C(WF.$$.fragment,c),C(mS.$$.fragment,c),C(cS.$$.fragment,c),C(gS.$$.fragment,c),C(HF.$$.fragment,c),C(hS.$$.fragment,c),C(NT.$$.fragment,c),C(uS.$$.fragment,c),C(pS.$$.fragment,c),C(bS.$$.fragment,c),C(DT.$$.fragment,c),C(vS.$$.fragment,c),C(lM.$$.fragment,c),C(FS.$$.fragment,c),C(TS.$$.fragment,c),C(ES.$$.fragment,c),C(dM.$$.fragment,c),C(CS.$$.fragment,c),C(hE.$$.fragment,c),C(wS.$$.fragment,c),C(AS.$$.fragment,c),C(yS.$$.fragment,c),C(pE.$$.fragment,c),C(xS.$$.fragment,c),C(YE.$$.fragment,c),C($S.$$.fragment,c),C(kS.$$.fragment,c),C(RS.$$.fragment,c),C(KE.$$.fragment,c),C(PS.$$.fragment,c),C(i4.$$.fragment,c),C(BS.$$.fragment,c),C(IS.$$.fragment,c),C(qS.$$.fragment,c),C(m4.$$.fragment,c),C(DS.$$.fragment,c),C(eC.$$.fragment,c),C(jS.$$.fragment,c),C(GS.$$.fragment,c),C(VS.$$.fragment,c),C(rC.$$.fragment,c),C(XS.$$.fragment,c),C(KC.$$.fragment,c),C(zS.$$.fragment,c),C(QS.$$.fragment,c),C(US.$$.fragment,c),C(o3.$$.fragment,c),C(HS.$$.fragment,c),C(a3.$$.fragment,c),C(JS.$$.fragment,c),C(YS.$$.fragment,c),C(KS.$$.fragment,c),C(s3.$$.fragment,c),C(eR.$$.fragment,c),C(c3.$$.fragment,c),C(oR.$$.fragment,c),C(rR.$$.fragment,c),C(aR.$$.fragment,c),C(g3.$$.fragment,c),C(nR.$$.fragment,c),C($3.$$.fragment,c),C(sR.$$.fragment,c),C(lR.$$.fragment,c),C(dR.$$.fragment,c),C(S3.$$.fragment,c),C(mR.$$.fragment,c),C(B3.$$.fragment,c),C(cR.$$.fragment,c),C(fR.$$.fragment,c),C(hR.$$.fragment,c),C(N3.$$.fragment,c),C(uR.$$.fragment,c),C(j3.$$.fragment,c),C(pR.$$.fragment,c),C(_R.$$.fragment,c),C(vR.$$.fragment,c),C(O3.$$.fragment,c),C(FR.$$.fragment,c),C(z3.$$.fragment,c),C(TR.$$.fragment,c),C(MR.$$.fragment,c),C(CR.$$.fragment,c),C(W3.$$.fragment,c),C(wR.$$.fragment,c),C(a5.$$.fragment,c),C(AR.$$.fragment,c),C(LR.$$.fragment,c),C(xR.$$.fragment,c),C(s5.$$.fragment,c),C($R.$$.fragment,c),C(g5.$$.fragment,c),C(kR.$$.fragment,c),C(SR.$$.fragment,c),C(PR.$$.fragment,c),C(u5.$$.fragment,c),C(BR.$$.fragment,c),C(L5.$$.fragment,c),C(IR.$$.fragment,c),C(NR.$$.fragment,c),C(DR.$$.fragment,c),C(x5.$$.fragment,c),C(jR.$$.fragment,c),C(P5.$$.fragment,c),C(GR.$$.fragment,c),C(OR.$$.fragment,c),C(XR.$$.fragment,c),C(I5.$$.fragment,c),C(zR.$$.fragment,c),C(V5.$$.fragment,c),C(QR.$$.fragment,c),C(WR.$$.fragment,c),C(HR.$$.fragment,c),C(z5.$$.fragment,c),C(JR.$$.fragment,c),C(Y5.$$.fragment,c),C(YR.$$.fragment,c),C(ZR.$$.fragment,c),C(eP.$$.fragment,c),C(K5.$$.fragment,c),C(oP.$$.fragment,c),C(s0.$$.fragment,c),C(rP.$$.fragment,c),C(tP.$$.fragment,c),C(nP.$$.fragment,c),C(i0.$$.fragment,c),C(sP.$$.fragment,c),C(c0.$$.fragment,c),C(lP.$$.fragment,c),C(iP.$$.fragment,c),C(mP.$$.fragment,c),C(g0.$$.fragment,c),C(cP.$$.fragment,c),C(F0.$$.fragment,c),C(fP.$$.fragment,c),C(gP.$$.fragment,c),C(uP.$$.fragment,c),C(M0.$$.fragment,c),C(pP.$$.fragment,c),C(w0.$$.fragment,c),C(_P.$$.fragment,c),C(bP.$$.fragment,c),C(FP.$$.fragment,c),C(L0.$$.fragment,c),C(TP.$$.fragment,c),C($0.$$.fragment,c),C(MP.$$.fragment,c),C(EP.$$.fragment,c),C(wP.$$.fragment,c),C(S0.$$.fragment,c),C(AP.$$.fragment,c),C(Iw.$$.fragment,c),C(LP.$$.fragment,c),C(yP.$$.fragment,c),C($P.$$.fragment,c),C(qw.$$.fragment,c),C(kP.$$.fragment,c),C(iA.$$.fragment,c),C(SP.$$.fragment,c),C(RP.$$.fragment,c),C(BP.$$.fragment,c),C(mA.$$.fragment,c),C(IP.$$.fragment,c),C(wA.$$.fragment,c),C(NP.$$.fragment,c),C(qP.$$.fragment,c),C(jP.$$.fragment,c),C(LA.$$.fragment,c),C(GP.$$.fragment,c),C(NA.$$.fragment,c),C(OP.$$.fragment,c),C(VP.$$.fragment,c),C(zP.$$.fragment,c),C(DA.$$.fragment,c),C(QP.$$.fragment,c),C(VA.$$.fragment,c),C(WP.$$.fragment,c),C(UP.$$.fragment,c),C(JP.$$.fragment,c),C(zA.$$.fragment,c),C(YP.$$.fragment,c),C(g6.$$.fragment,c),C(ZP.$$.fragment,c),C(KP.$$.fragment,c),C(oB.$$.fragment,c),C(u6.$$.fragment,c),C(rB.$$.fragment,c),C(A6.$$.fragment,c),C(tB.$$.fragment,c),C(aB.$$.fragment,c),C(sB.$$.fragment,c),C(y6.$$.fragment,c),C(lB.$$.fragment,c),C(t7.$$.fragment,c),C(iB.$$.fragment,c),C(dB.$$.fragment,c),C(cB.$$.fragment,c),C(n7.$$.fragment,c),C(fB.$$.fragment,c),C(E7.$$.fragment,c),C(gB.$$.fragment,c),C(hB.$$.fragment,c),C(pB.$$.fragment,c),C(w7.$$.fragment,c),C(_B.$$.fragment,c),C(y7.$$.fragment,c),C(vB.$$.fragment,c),C(FB.$$.fragment,c),C(MB.$$.fragment,c),C($7.$$.fragment,c),C(EB.$$.fragment,c),C(S7.$$.fragment,c),C(CB.$$.fragment,c),C(wB.$$.fragment,c),C(LB.$$.fragment,c),C(P7.$$.fragment,c),C(yB.$$.fragment,c),C(I7.$$.fragment,c),C(xB.$$.fragment,c),C($B.$$.fragment,c),C(SB.$$.fragment,c),C(q7.$$.fragment,c),C(RB.$$.fragment,c),C(l8.$$.fragment,c),C(PB.$$.fragment,c),C(BB.$$.fragment,c),C(NB.$$.fragment,c),C(d8.$$.fragment,c),C(qB.$$.fragment,c),C(k8.$$.fragment,c),C(DB.$$.fragment,c),C(jB.$$.fragment,c),C(OB.$$.fragment,c),C(R8.$$.fragment,c),C(VB.$$.fragment,c),C(B8.$$.fragment,c),C(XB.$$.fragment,c),C(zB.$$.fragment,c),C(WB.$$.fragment,c),C(N8.$$.fragment,c),C(UB.$$.fragment,c),C(j8.$$.fragment,c),C(JB.$$.fragment,c),C(YB.$$.fragment,c),C(KB.$$.fragment,c),C(O8.$$.fragment,c),C(eI.$$.fragment,c),C(pL.$$.fragment,c),C(oI.$$.fragment,c),C(rI.$$.fragment,c),C(aI.$$.fragment,c),C(bL.$$.fragment,c),C(nI.$$.fragment,c),C(xL.$$.fragment,c),C(sI.$$.fragment,c),C(lI.$$.fragment,c),C(dI.$$.fragment,c),C(kL.$$.fragment,c),C(mI.$$.fragment,c),C(zL.$$.fragment,c),C(cI.$$.fragment,c),C(fI.$$.fragment,c),C(hI.$$.fragment,c),C(WL.$$.fragment,c),C(uI.$$.fragment,c),C(ay.$$.fragment,c),C(pI.$$.fragment,c),C(_I.$$.fragment,c),C(vI.$$.fragment,c),C(sy.$$.fragment,c),C(FI.$$.fragment,c),C(_y.$$.fragment,c),C(TI.$$.fragment,c),C(MI.$$.fragment,c),C(CI.$$.fragment,c),C(vy.$$.fragment,c),C(wI.$$.fragment,c),C($y.$$.fragment,c),C(AI.$$.fragment,c),C(LI.$$.fragment,c),C(xI.$$.fragment,c),C(Sy.$$.fragment,c),C($I.$$.fragment,c),C(Vy.$$.fragment,c),C(kI.$$.fragment,c),C(SI.$$.fragment,c),C(PI.$$.fragment,c),C(zy.$$.fragment,c),C(BI.$$.fragment,c),C(e9.$$.fragment,c),C(II.$$.fragment,c),C(NI.$$.fragment,c),C(DI.$$.fragment,c),C(r9.$$.fragment,c),C(jI.$$.fragment,c),C(c9.$$.fragment,c),C(GI.$$.fragment,c),C(OI.$$.fragment,c),C(XI.$$.fragment,c),C(g9.$$.fragment,c),C(zI.$$.fragment,c),C(u9.$$.fragment,c),C(QI.$$.fragment,c),C(WI.$$.fragment,c),C(HI.$$.fragment,c),C(_9.$$.fragment,c),C(JI.$$.fragment,c),C(F9.$$.fragment,c),C(ZI.$$.fragment,c),C(KI.$$.fragment,c),C(oN.$$.fragment,c),C(M9.$$.fragment,c),C(rN.$$.fragment,c),C(C9.$$.fragment,c),kdo=!1},d(c){t(g),c&&t(v),c&&t(u),w(m),c&&t(eg),c&&t(wt),c&&t(Qe),c&&t(Ze),c&&t(rg),w(sn,c),c&&t(Ke),c&&t(ye),c&&t(Po),c&&t(ln),c&&t(flo),c&&t(Rd),w(ck),c&&t(glo),c&&t(Fs),c&&t(hlo),w(fk,c),c&&t(ulo),c&&t(Iq),c&&t(plo),w(ng,c),c&&t(_lo),c&&t(Pd),w(gk),c&&t(blo),c&&t(Bo),w(hk),w(_k),w(Iu),w(bk),c&&t(vlo),c&&t(Id),w(vk),c&&t(Flo),c&&t(Io),w(Fk),w(Ek),w(Tp),w(Ck),c&&t(Tlo),c&&t(Nd),w(wk),c&&t(Mlo),c&&t(No),w(Ak),w(xk),w(u_),w(p_),w($k),c&&t(Elo),c&&t(qd),w(kk),c&&t(Clo),c&&t(qo),w(Sk),w(Bk),w(U_),w(H_),w(Ik),c&&t(wlo),c&&t(Dd),w(Nk),c&&t(Alo),c&&t(Do),w(qk),w(Gk),w(T1),w(M1),w(Ok),c&&t(Llo),c&&t(Gd),w(Vk),c&&t(ylo),c&&t(jo),w(Xk),w(Qk),w(w1),w(Wk),w(Hb),c&&t(xlo),c&&t(Xd),w(Uk),c&&t($lo),c&&t(Go),w(Hk),w(Yk),w(Yb),w(Zk),w(Uv),c&&t(klo),c&&t(Wd),w(Kk),c&&t(Slo),c&&t(Oo),w(eS),w(rS),w(Jv),w(tS),w(GF),c&&t(Rlo),c&&t(Jd),w(aS),c&&t(Plo),c&&t(Vo),w(nS),w(lS),w(VF),w(iS),w(WF),c&&t(Blo),c&&t(Kd),w(mS),c&&t(Ilo),c&&t(Xo),w(cS),w(gS),w(HF),w(hS),w(NT),c&&t(Nlo),c&&t(rm),w(uS),c&&t(qlo),c&&t(zo),w(pS),w(bS),w(DT),w(vS),w(lM),c&&t(Dlo),c&&t(nm),w(FS),c&&t(jlo),c&&t(Qo),w(TS),w(ES),w(dM),w(CS),w(hE),c&&t(Glo),c&&t(im),w(wS),c&&t(Olo),c&&t(Wo),w(AS),w(yS),w(pE),w(xS),w(YE),c&&t(Vlo),c&&t(cm),w($S),c&&t(Xlo),c&&t(Uo),w(kS),w(RS),w(KE),w(PS),w(i4),c&&t(zlo),c&&t(hm),w(BS),c&&t(Qlo),c&&t(Ho),w(IS),w(qS),w(m4),w(DS),w(eC),c&&t(Wlo),c&&t(_m),w(jS),c&&t(Ulo),c&&t(Jo),w(GS),w(VS),w(rC),w(XS),w(KC),c&&t(Hlo),c&&t(Fm),w(zS),c&&t(Jlo),c&&t(Yo),w(QS),w(US),w(o3),w(HS),w(a3),c&&t(Ylo),c&&t(Em),w(JS),c&&t(Zlo),c&&t(Zo),w(YS),w(KS),w(s3),w(eR),w(c3),c&&t(Klo),c&&t(Lm),w(oR),c&&t(eio),c&&t(Ko),w(rR),w(aR),w(g3),w(nR),w($3),c&&t(oio),c&&t($m),w(sR),c&&t(rio),c&&t(er),w(lR),w(dR),w(S3),w(mR),w(B3),c&&t(tio),c&&t(Rm),w(cR),c&&t(aio),c&&t(or),w(fR),w(hR),w(N3),w(uR),w(j3),c&&t(nio),c&&t(Im),w(pR),c&&t(sio),c&&t(rr),w(_R),w(vR),w(O3),w(FR),w(z3),c&&t(lio),c&&t(Dm),w(TR),c&&t(iio),c&&t(tr),w(MR),w(CR),w(W3),w(wR),w(a5),c&&t(dio),c&&t(Om),w(AR),c&&t(mio),c&&t(ar),w(LR),w(xR),w(s5),w($R),w(g5),c&&t(cio),c&&t(zm),w(kR),c&&t(fio),c&&t(nr),w(SR),w(PR),w(u5),w(BR),w(L5),c&&t(gio),c&&t(Um),w(IR),c&&t(hio),c&&t(sr),w(NR),w(DR),w(x5),w(jR),w(P5),c&&t(uio),c&&t(Zm),w(GR),c&&t(pio),c&&t(lr),w(OR),w(XR),w(I5),w(zR),w(V5),c&&t(_io),c&&t(oc),w(QR),c&&t(bio),c&&t(ir),w(WR),w(HR),w(z5),w(JR),w(Y5),c&&t(vio),c&&t(ac),w(YR),c&&t(Fio),c&&t(dr),w(ZR),w(eP),w(K5),w(oP),w(s0),c&&t(Tio),c&&t(lc),w(rP),c&&t(Mio),c&&t(mr),w(tP),w(nP),w(i0),w(sP),w(c0),c&&t(Eio),c&&t(mc),w(lP),c&&t(Cio),c&&t(cr),w(iP),w(mP),w(g0),w(cP),w(F0),c&&t(wio),c&&t(gc),w(fP),c&&t(Aio),c&&t(fr),w(gP),w(uP),w(M0),w(pP),w(w0),c&&t(Lio),c&&t(pc),w(_P),c&&t(yio),c&&t(gr),w(bP),w(FP),w(L0),w(TP),w($0),c&&t(xio),c&&t(vc),w(MP),c&&t($io),c&&t(hr),w(EP),w(wP),w(S0),w(AP),w(Iw),c&&t(kio),c&&t(Mc),w(LP),c&&t(Sio),c&&t(ur),w(yP),w($P),w(qw),w(kP),w(iA),c&&t(Rio),c&&t(wc),w(SP),c&&t(Pio),c&&t(pr),w(RP),w(BP),w(mA),w(IP),w(wA),c&&t(Bio),c&&t(yc),w(NP),c&&t(Iio),c&&t(_r),w(qP),w(jP),w(LA),w(GP),w(NA),c&&t(Nio),c&&t(kc),w(OP),c&&t(qio),c&&t(br),w(VP),w(zP),w(DA),w(QP),w(VA),c&&t(Dio),c&&t(Bc),w(WP),c&&t(jio),c&&t(vr),w(UP),w(JP),w(zA),w(YP),w(g6),c&&t(Gio),c&&t(qc),w(ZP),c&&t(Oio),c&&t(Fr),w(KP),w(oB),w(u6),w(rB),w(A6),c&&t(Vio),c&&t(Gc),w(tB),c&&t(Xio),c&&t(Tr),w(aB),w(sB),w(y6),w(lB),w(t7),c&&t(zio),c&&t(Xc),w(iB),c&&t(Qio),c&&t(Mr),w(dB),w(cB),w(n7),w(fB),w(E7),c&&t(Wio),c&&t(Wc),w(gB),c&&t(Uio),c&&t(Er),w(hB),w(pB),w(w7),w(_B),w(y7),c&&t(Hio),c&&t(Jc),w(vB),c&&t(Jio),c&&t(Cr),w(FB),w(MB),w($7),w(EB),w(S7),c&&t(Yio),c&&t(Kc),w(CB),c&&t(Zio),c&&t(wr),w(wB),w(LB),w(P7),w(yB),w(I7),c&&t(Kio),c&&t(rf),w(xB),c&&t(edo),c&&t(Ar),w($B),w(SB),w(q7),w(RB),w(l8),c&&t(odo),c&&t(nf),w(PB),c&&t(rdo),c&&t(Lr),w(BB),w(NB),w(d8),w(qB),w(k8),c&&t(tdo),c&&t(df),w(DB),c&&t(ado),c&&t(yr),w(jB),w(OB),w(R8),w(VB),w(B8),c&&t(ndo),c&&t(ff),w(XB),c&&t(sdo),c&&t(xr),w(zB),w(WB),w(N8),w(UB),w(j8),c&&t(ldo),c&&t(uf),w(JB),c&&t(ido),c&&t($r),w(YB),w(KB),w(O8),w(eI),w(pL),c&&t(ddo),c&&t(bf),w(oI),c&&t(mdo),c&&t(kr),w(rI),w(aI),w(bL),w(nI),w(xL),c&&t(cdo),c&&t(Tf),w(sI),c&&t(fdo),c&&t(Sr),w(lI),w(dI),w(kL),w(mI),w(zL),c&&t(gdo),c&&t(Cf),w(cI),c&&t(hdo),c&&t(Rr),w(fI),w(hI),w(WL),w(uI),w(ay),c&&t(udo),c&&t(Lf),w(pI),c&&t(pdo),c&&t(Pr),w(_I),w(vI),w(sy),w(FI),w(_y),c&&t(_do),c&&t($f),w(TI),c&&t(bdo),c&&t(Br),w(MI),w(CI),w(vy),w(wI),w($y),c&&t(vdo),c&&t(Rf),w(AI),c&&t(Fdo),c&&t(Ir),w(LI),w(xI),w(Sy),w($I),w(Vy),c&&t(Tdo),c&&t(If),w(kI),c&&t(Mdo),c&&t(Nr),w(SI),w(PI),w(zy),w(BI),w(e9),c&&t(Edo),c&&t(Df),w(II),c&&t(Cdo),c&&t(qr),w(NI),w(DI),w(r9),w(jI),w(c9),c&&t(wdo),c&&t(Of),w(GI),c&&t(Ado),c&&t(Dr),w(OI),w(XI),w(g9),w(zI),w(u9),c&&t(Ldo),c&&t(zf),w(QI),c&&t(ydo),c&&t(jr),w(WI),w(HI),w(_9),w(JI),w(F9),c&&t(xdo),c&&t(Uf),w(ZI),c&&t($do),c&&t(Gr),w(KI),w(oN),w(M9),w(rN),w(C9)}}}const H$a={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoImageProcessor",title:"AutoImageProcessor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForDepthEstimation",title:"AutoModelForDepthEstimation"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForDocumentQuestionAnswering",title:"AutoModelForDocumentQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVideoClassification",title:"AutoModelForVideoClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.AutoModelForZeroShotObjectDetection",title:"AutoModelForZeroShotObjectDetection"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForSemanticSegmentation",title:"TFAutoModelForSemanticSegmentation"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForDocumentQuestionAnswering",title:"TFAutoModelForDocumentQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function J$a($){return P9a(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class tka extends $9a{constructor(g){super();k9a(this,g,J$a,U$a,S9a,{})}}export{tka as default,H$a as metadata};
