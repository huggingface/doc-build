import{S as xu,i as Mu,s as Ou,e as o,k as c,w as g,t,M as Su,c as s,d as r,m as d,a as l,x as u,h as a,b as i,G as e,g as f,y as b,q as _,o as v,B as E,v as Iu,L as Nu}from"../../chunks/vendor-hf-doc-builder.js";import{T as Pu}from"../../chunks/Tip-hf-doc-builder.js";import{D as w}from"../../chunks/Docstring-hf-doc-builder.js";import{C as jh}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as Eo}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as Fu}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function Wu(wa){let A,B,x,M,W;return M=new jh({props:{code:`class PrinterCallback(TrainerCallback):
    def on_log(self, args, state, control, logs=None, **kwargs):
        _ = logs.pop("total_flos", None)
        if state.is_local_process_zero:
            print(logs)`,highlighted:`<span class="hljs-keyword">class</span> <span class="hljs-title class_">PrinterCallback</span>(<span class="hljs-title class_ inherited__">TrainerCallback</span>):
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">on_log</span>(<span class="hljs-params">self, args, state, control, logs=<span class="hljs-literal">None</span>, **kwargs</span>):
        _ = logs.pop(<span class="hljs-string">&quot;total_flos&quot;</span>, <span class="hljs-literal">None</span>)
        <span class="hljs-keyword">if</span> state.is_local_process_zero:
            <span class="hljs-built_in">print</span>(logs)`}}),{c(){A=o("p"),B=t("Example:"),x=c(),g(M.$$.fragment)},l(y){A=s(y,"P",{});var j=l(A);B=a(j,"Example:"),j.forEach(r),x=d(y),u(M.$$.fragment,y)},m(y,j){f(y,A,j),e(A,B),f(y,x,j),b(M,y,j),W=!0},p:Nu,i(y){W||(_(M.$$.fragment,y),W=!0)},o(y){v(M.$$.fragment,y),W=!1},d(y){y&&r(A),y&&r(x),E(M,y)}}}function ju(wa){let A,B,x,M,W,y,j,oe;return{c(){A=o("p"),B=t(`In all this class, one step is to be understood as one update step. When using gradient accumulation, one update
step may require several forward and backward passes: if you use `),x=o("code"),M=t("gradient_accumulation_steps=n"),W=t(`, then one update
step requires going through `),y=o("em"),j=t("n"),oe=t(" batches.")},l(se){A=s(se,"P",{});var R=l(A);B=a(R,`In all this class, one step is to be understood as one update step. When using gradient accumulation, one update
step may require several forward and backward passes: if you use `),x=s(R,"CODE",{});var J=l(x);M=a(J,"gradient_accumulation_steps=n"),J.forEach(r),W=a(R,`, then one update
step requires going through `),y=s(R,"EM",{});var ya=l(y);j=a(ya,"n"),ya.forEach(r),oe=a(R," batches."),R.forEach(r)},m(se,R){f(se,A,R),e(A,B),e(A,x),e(x,M),e(A,W),e(A,y),e(y,j),e(A,oe)},d(se){se&&r(A)}}}function zu(wa){let A,B,x,M,W,y,j,oe,se,R,J,ya,Aa,Rs,Bs,ko,V,Vs,La,Us,qs,Da,Gs,Hs,xa,Js,Ys,To,ye,Xs,Ma,Ks,Qs,$o,L,Oa,Sa,Zs,el,tl,ae,Ia,al,rl,Na,nl,ol,Pa,sl,ll,il,Fa,Wa,cl,dl,ml,Ae,ja,fl,hl,ct,pl,gl,ul,Le,za,bl,_l,dt,vl,El,kl,De,Ra,Tl,$l,mt,Cl,wl,yl,xe,Ba,Al,Ll,ft,Dl,xl,Ml,Me,Va,Ol,Sl,ht,Il,Nl,Pl,Oe,Ua,Fl,Wl,pt,jl,zl,Rl,Se,qa,Bl,Vl,gt,Ul,ql,Co,N,Gl,Ga,Hl,Jl,Ha,Yl,Xl,Ja,Kl,Ql,Ya,Zl,ei,Xa,ti,ai,wo,le,Ie,Mr,ut,ri,Or,ni,yo,Ne,oi,Ka,si,li,Ao,Y,bt,ii,ie,ci,Qa,di,mi,_t,fi,hi,pi,U,vt,gi,Sr,ui,bi,D,_i,Ir,vi,Ei,Nr,ki,Ti,Pr,$i,Ci,Fr,wi,yi,Wr,Ai,Li,jr,Di,xi,zr,Mi,Oi,Rr,Si,Ii,Br,Ni,Pi,Fi,Et,Wi,kt,ji,zi,Lo,ce,Tt,Ri,$t,Bi,Za,Vi,Ui,Do,de,Ct,qi,wt,Gi,er,Hi,Ji,xo,me,yt,Yi,At,Xi,tr,Ki,Qi,Mo,X,Lt,Zi,Dt,ec,ar,tc,ac,rc,K,nc,rr,oc,sc,Vr,lc,ic,nr,cc,dc,Oo,fe,xt,mc,he,fc,or,hc,pc,Mt,gc,uc,So,Q,Ot,bc,pe,_c,sr,vc,Ec,St,kc,Tc,$c,q,It,Cc,Nt,wc,Ur,yc,Ac,Lc,Pt,Dc,Ft,xc,Mc,Oc,h,Sc,qr,Ic,Nc,Gr,Pc,Fc,Hr,Wc,jc,Jr,zc,Rc,Yr,Bc,Vc,Xr,Uc,qc,Kr,Gc,Hc,Qr,Jc,Yc,Zr,Xc,Kc,en,Qc,Zc,tn,ed,td,an,ad,rd,rn,nd,od,nn,sd,ld,on,id,cd,sn,dd,md,ln,fd,hd,cn,pd,gd,dn,ud,bd,Io,Z,Wt,_d,ee,vd,lr,Ed,kd,jt,Td,$d,mn,Cd,wd,yd,re,zt,Ad,fn,Ld,Dd,p,xd,hn,Md,Od,pn,Sd,Id,gn,Nd,Pd,un,Fd,Wd,ir,jd,zd,bn,Rd,Bd,_n,Vd,Ud,vn,qd,Gd,En,Hd,Jd,kn,Yd,Xd,Tn,Kd,Qd,$n,Zd,em,Cn,tm,am,wn,rm,nm,yn,om,sm,An,lm,im,Ln,cm,dm,Dn,mm,fm,xn,hm,pm,No,ge,Rt,gm,ue,um,cr,bm,_m,Bt,vm,Em,Po,be,Vt,km,Ut,Tm,dr,$m,Cm,Fo,_e,qt,wm,Gt,ym,Ht,Am,Lm,Wo,te,Jt,Dm,ve,xm,mr,Mm,Om,Yt,Sm,Im,Nm,I,Pm,Mn,Fm,Wm,On,jm,zm,Sn,Rm,Bm,In,Vm,Um,Nn,qm,Gm,Pn,Hm,Jm,jo,Ee,Pe,Fn,Xt,Ym,Wn,Xm,zo,k,Kt,Km,jn,Qm,Zm,Qt,ef,zn,tf,af,rf,P,nf,Rn,of,sf,Bn,lf,cf,Vn,df,mf,Un,ff,hf,qn,pf,gf,uf,Fe,bf,We,Zt,_f,Gn,vf,Ef,je,ea,kf,Hn,Tf,$f,ze,ta,Cf,Jn,wf,yf,Re,aa,Af,ra,Lf,fr,Df,xf,Mf,Be,na,Of,Yn,Sf,If,Ve,oa,Nf,Xn,Pf,Ff,Ue,sa,Wf,Kn,jf,zf,qe,la,Rf,Qn,Bf,Vf,Ge,ia,Uf,Zn,qf,Gf,He,ca,Hf,eo,Jf,Yf,Je,da,Xf,to,Kf,Qf,Ye,ma,Zf,ao,eh,th,Xe,fa,ah,ro,rh,Ro,Ke,nh,hr,oh,sh,Bo,ha,Vo,Qe,lh,no,ih,ch,Uo,pa,qo,ke,Ze,oo,ga,dh,so,mh,Go,F,ua,fh,Te,hh,pr,ph,gh,gr,uh,bh,_h,et,vh,tt,ba,Eh,_a,kh,lo,Th,$h,Ch,at,va,wh,Ea,yh,io,Ah,Lh,Ho,$e,rt,co,ka,Dh,mo,xh,Jo,Ce,Ta,Mh,we,Oh,ur,Sh,Ih,br,Nh,Ph,Yo;return y=new Eo({}),ut=new Eo({}),bt=new w({props:{name:"class transformers.integrations.CometCallback",anchor:"transformers.integrations.CometCallback",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/integrations.py#L771"}}),vt=new w({props:{name:"setup",anchor:"transformers.integrations.CometCallback.setup",parameters:[{name:"args",val:""},{name:"state",val:""},{name:"model",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/integrations.py#L782"}}),Tt=new w({props:{name:"class transformers.DefaultFlowCallback",anchor:"transformers.DefaultFlowCallback",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_callback.py#L415"}}),Ct=new w({props:{name:"class transformers.PrinterCallback",anchor:"transformers.PrinterCallback",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_callback.py#L513"}}),yt=new w({props:{name:"class transformers.ProgressCallback",anchor:"transformers.ProgressCallback",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_callback.py#L465"}}),Lt=new w({props:{name:"class transformers.EarlyStoppingCallback",anchor:"transformers.EarlyStoppingCallback",parameters:[{name:"early_stopping_patience",val:": int = 1"},{name:"early_stopping_threshold",val:": typing.Optional[float] = 0.0"}],parametersDescription:[{anchor:"transformers.EarlyStoppingCallback.early_stopping_patience",description:`<strong>early_stopping_patience</strong> (<code>int</code>) &#x2014;
Use with <code>metric_for_best_model</code> to stop training when the specified metric worsens for
<code>early_stopping_patience</code> evaluation calls.`,name:"early_stopping_patience"},{anchor:"transformers.EarlyStoppingCallback.early_stopping_threshold(float,",description:`<strong>early_stopping_threshold(<code>float</code>,</strong> <em>optional</em>) &#x2014;
Use with TrainingArguments <code>metric_for_best_model</code> and <code>early_stopping_patience</code> to denote how much the
specified metric must improve to satisfy early stopping conditions. \``,name:"early_stopping_threshold(float,"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_callback.py#L524"}}),xt=new w({props:{name:"class transformers.integrations.TensorBoardCallback",anchor:"transformers.integrations.TensorBoardCallback",parameters:[{name:"tb_writer",val:" = None"}],parametersDescription:[{anchor:"transformers.integrations.TensorBoardCallback.tb_writer",description:`<strong>tb_writer</strong> (<code>SummaryWriter</code>, <em>optional</em>) &#x2014;
The writer to use. Will instantiate one if not set.`,name:"tb_writer"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/integrations.py#L556"}}),Ot=new w({props:{name:"class transformers.integrations.WandbCallback",anchor:"transformers.integrations.WandbCallback",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/integrations.py#L645"}}),It=new w({props:{name:"setup",anchor:"transformers.integrations.WandbCallback.setup",parameters:[{name:"args",val:""},{name:"state",val:""},{name:"model",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/integrations.py#L662"}}),Wt=new w({props:{name:"class transformers.integrations.MLflowCallback",anchor:"transformers.integrations.MLflowCallback",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/integrations.py#L871"}}),zt=new w({props:{name:"setup",anchor:"transformers.integrations.MLflowCallback.setup",parameters:[{name:"args",val:""},{name:"state",val:""},{name:"model",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/integrations.py#L890"}}),Rt=new w({props:{name:"class transformers.integrations.AzureMLCallback",anchor:"transformers.integrations.AzureMLCallback",parameters:[{name:"azureml_run",val:" = None"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/integrations.py#L848"}}),Vt=new w({props:{name:"class transformers.integrations.CodeCarbonCallback",anchor:"transformers.integrations.CodeCarbonCallback",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/integrations.py#L1279"}}),qt=new w({props:{name:"class transformers.integrations.NeptuneCallback",anchor:"transformers.integrations.NeptuneCallback",parameters:[{name:"api_token",val:": typing.Optional[str] = None"},{name:"project",val:": typing.Optional[str] = None"},{name:"name",val:": typing.Optional[str] = None"},{name:"base_namespace",val:": str = 'finetuning'"},{name:"run",val:": typing.Optional[ForwardRef('Run')] = None"},{name:"log_parameters",val:": bool = True"},{name:"log_checkpoints",val:": typing.Optional[str] = None"},{name:"**neptune_run_kwargs",val:""}],parametersDescription:[{anchor:"transformers.integrations.NeptuneCallback.api_token",description:`<strong>api_token</strong> (<code>str</code>, optional) &#x2014;
Neptune API token obtained upon registration. You can leave this argument out if you have saved your token
to the <code>NEPTUNE_API_TOKEN</code> environment variable (strongly recommended). See full setup instructions in the
<a href="https://docs.neptune.ai/getting-started/installation" rel="nofollow">docs</a>.`,name:"api_token"},{anchor:"transformers.integrations.NeptuneCallback.project",description:`<strong>project</strong> (<code>str</code>, optional) &#x2014;
Name of an existing Neptune project, in the form: &#x201C;workspace-name/project-name&#x201D;. You can find and copy the
name from the project Settings -&gt; Properties in Neptune. If None (default), the value of the
<code>NEPTUNE_PROJECT</code> environment variable will be used.`,name:"project"},{anchor:"transformers.integrations.NeptuneCallback.name",description:"<strong>name</strong> (<code>str</code>, optional) &#x2014; Custom name for the run.",name:"name"},{anchor:"transformers.integrations.NeptuneCallback.base_namespace",description:`<strong>base_namespace</strong> (<code>str</code>, optional, defaults to &#x201C;finetuning&#x201D;) &#x2014; In the Neptune run, the root namespace
that will contain all of the logged metadata.`,name:"base_namespace"},{anchor:"transformers.integrations.NeptuneCallback.log_parameters",description:`<strong>log_parameters</strong> (<code>bool</code>, optional, defaults to True) &#x2014;
If True, logs all Trainer arguments and model parameters provided by the Trainer.`,name:"log_parameters"},{anchor:"transformers.integrations.NeptuneCallback.log_checkpoints",description:`<strong>log_checkpoints</strong> (<code>str</code>, optional, defaults to None) &#x2014;
If &#x201C;same&#x201D;, uploads checkpoints whenever they are saved by the Trainer. If &#x201C;last&#x201D;, uploads only the most
recently saved checkpoint. If &#x201C;best&#x201D;, uploads the best checkpoint (among the ones saved by the Trainer). If
None, does not upload checkpoints.`,name:"log_checkpoints"},{anchor:"transformers.integrations.NeptuneCallback.run",description:`<strong>run</strong> (<code>Run</code>, optional) &#x2014;
Pass a Neptune run object if you want to continue logging to an existing run. Read more about resuming runs
in the <a href="https://docs.neptune.ai/how-to-guides/neptune-api/resume-run" rel="nofollow">docs</a>.`,name:"run"},{anchor:"transformers.integrations.NeptuneCallback.*neptune_run_kwargs",description:`*<strong>*neptune_run_kwargs</strong> (optional) &#x2014;
Additional keyword arguments to be passed directly to the
<a href="https://docs.neptune.ai/api-reference/neptune#.init_run" rel="nofollow">neptune.init_run()</a> function when a new run is
created.`,name:"*neptune_run_kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/integrations.py#L1018"}}),Jt=new w({props:{name:"class transformers.integrations.ClearMLCallback",anchor:"transformers.integrations.ClearMLCallback",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/integrations.py#L1308"}}),Xt=new Eo({}),Kt=new w({props:{name:"class transformers.TrainerCallback",anchor:"transformers.TrainerCallback",parameters:[],parametersDescription:[{anchor:"transformers.TrainerCallback.args",description:`<strong>args</strong> (<a href="/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a>) &#x2014;
The training arguments used to instantiate the <a href="/docs/transformers/main/en/main_classes/trainer#transformers.Trainer">Trainer</a>.`,name:"args"},{anchor:"transformers.TrainerCallback.state",description:`<strong>state</strong> (<a href="/docs/transformers/main/en/main_classes/callback#transformers.TrainerState">TrainerState</a>) &#x2014;
The current state of the <a href="/docs/transformers/main/en/main_classes/trainer#transformers.Trainer">Trainer</a>.`,name:"state"},{anchor:"transformers.TrainerCallback.control",description:`<strong>control</strong> (<a href="/docs/transformers/main/en/main_classes/callback#transformers.TrainerControl">TrainerControl</a>) &#x2014;
The object that is returned to the <a href="/docs/transformers/main/en/main_classes/trainer#transformers.Trainer">Trainer</a> and can be used to make some decisions.`,name:"control"},{anchor:"transformers.TrainerCallback.model",description:`<strong>model</strong> (<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel">PreTrainedModel</a> or <code>torch.nn.Module</code>) &#x2014;
The model being trained.`,name:"model"},{anchor:"transformers.TrainerCallback.tokenizer",description:`<strong>tokenizer</strong> (<a href="/docs/transformers/main/en/main_classes/tokenizer#transformers.PreTrainedTokenizer">PreTrainedTokenizer</a>) &#x2014;
The tokenizer used for encoding the data.`,name:"tokenizer"},{anchor:"transformers.TrainerCallback.optimizer",description:`<strong>optimizer</strong> (<code>torch.optim.Optimizer</code>) &#x2014;
The optimizer used for the training steps.`,name:"optimizer"},{anchor:"transformers.TrainerCallback.lr_scheduler",description:`<strong>lr_scheduler</strong> (<code>torch.optim.lr_scheduler.LambdaLR</code>) &#x2014;
The scheduler used for setting the learning rate.`,name:"lr_scheduler"},{anchor:"transformers.TrainerCallback.train_dataloader",description:`<strong>train_dataloader</strong> (<code>torch.utils.data.DataLoader</code>, <em>optional</em>) &#x2014;
The current dataloader used for training.`,name:"train_dataloader"},{anchor:"transformers.TrainerCallback.eval_dataloader",description:`<strong>eval_dataloader</strong> (<code>torch.utils.data.DataLoader</code>, <em>optional</em>) &#x2014;
The current dataloader used for training.`,name:"eval_dataloader"},{anchor:"transformers.TrainerCallback.metrics",description:`<strong>metrics</strong> (<code>Dict[str, float]</code>) &#x2014;
The metrics computed by the last evaluation phase.</p>
<p>Those are only accessible in the event <code>on_evaluate</code>.`,name:"metrics"},{anchor:"transformers.TrainerCallback.logs",description:`<strong>logs</strong>  (<code>Dict[str, float]</code>) &#x2014;
The values to log.</p>
<p>Those are only accessible in the event <code>on_log</code>.`,name:"logs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_callback.py#L159"}}),Fe=new Fu({props:{anchor:"transformers.TrainerCallback.example",$$slots:{default:[Wu]},$$scope:{ctx:wa}}}),Zt=new w({props:{name:"on_epoch_begin",anchor:"transformers.TrainerCallback.on_epoch_begin",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_callback.py#L227"}}),ea=new w({props:{name:"on_epoch_end",anchor:"transformers.TrainerCallback.on_epoch_end",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_callback.py#L233"}}),ta=new w({props:{name:"on_evaluate",anchor:"transformers.TrainerCallback.on_evaluate",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_callback.py#L259"}}),aa=new w({props:{name:"on_init_end",anchor:"transformers.TrainerCallback.on_init_end",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_callback.py#L209"}}),na=new w({props:{name:"on_log",anchor:"transformers.TrainerCallback.on_log",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_callback.py#L277"}}),oa=new w({props:{name:"on_predict",anchor:"transformers.TrainerCallback.on_predict",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"metrics",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_callback.py#L265"}}),sa=new w({props:{name:"on_prediction_step",anchor:"transformers.TrainerCallback.on_prediction_step",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_callback.py#L283"}}),la=new w({props:{name:"on_save",anchor:"transformers.TrainerCallback.on_save",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_callback.py#L271"}}),ia=new w({props:{name:"on_step_begin",anchor:"transformers.TrainerCallback.on_step_begin",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_callback.py#L239"}}),ca=new w({props:{name:"on_step_end",anchor:"transformers.TrainerCallback.on_step_end",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_callback.py#L252"}}),da=new w({props:{name:"on_substep_end",anchor:"transformers.TrainerCallback.on_substep_end",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_callback.py#L246"}}),ma=new w({props:{name:"on_train_begin",anchor:"transformers.TrainerCallback.on_train_begin",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_callback.py#L215"}}),fa=new w({props:{name:"on_train_end",anchor:"transformers.TrainerCallback.on_train_end",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_callback.py#L221"}}),ha=new jh({props:{code:`class MyCallback(TrainerCallback):
    "A callback that prints a message at the beginning of training"

    def on_train_begin(self, args, state, control, **kwargs):
        print("Starting training")


trainer = Trainer(
    model,
    args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    callbacks=[MyCallback],  # We can either pass the callback class this way or an instance of it (MyCallback())
)`,highlighted:`<span class="hljs-keyword">class</span> <span class="hljs-title class_">MyCallback</span>(<span class="hljs-title class_ inherited__">TrainerCallback</span>):
    <span class="hljs-string">&quot;A callback that prints a message at the beginning of training&quot;</span>

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">on_train_begin</span>(<span class="hljs-params">self, args, state, control, **kwargs</span>):
        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Starting training&quot;</span>)


trainer = Trainer(
    model,
    args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    callbacks=[MyCallback],  <span class="hljs-comment"># We can either pass the callback class this way or an instance of it (MyCallback())</span>
)`}}),pa=new jh({props:{code:`trainer = Trainer(...)
trainer.add_callback(MyCallback)
# Alternatively, we can pass an instance of the callback class
trainer.add_callback(MyCallback())`,highlighted:`trainer = Trainer(...)
trainer.add_callback(MyCallback)
<span class="hljs-comment"># Alternatively, we can pass an instance of the callback class</span>
trainer.add_callback(MyCallback())`}}),ga=new Eo({}),ua=new w({props:{name:"class transformers.TrainerState",anchor:"transformers.TrainerState",parameters:[{name:"epoch",val:": typing.Optional[float] = None"},{name:"global_step",val:": int = 0"},{name:"max_steps",val:": int = 0"},{name:"num_train_epochs",val:": int = 0"},{name:"total_flos",val:": float = 0"},{name:"log_history",val:": typing.List[typing.Dict[str, float]] = None"},{name:"best_metric",val:": typing.Optional[float] = None"},{name:"best_model_checkpoint",val:": typing.Optional[str] = None"},{name:"is_local_process_zero",val:": bool = True"},{name:"is_world_process_zero",val:": bool = True"},{name:"is_hyper_param_search",val:": bool = False"},{name:"trial_name",val:": str = None"},{name:"trial_params",val:": typing.Dict[str, typing.Union[str, float, int, bool]] = None"}],parametersDescription:[{anchor:"transformers.TrainerState.epoch",description:`<strong>epoch</strong> (<code>float</code>, <em>optional</em>) &#x2014;
Only set during training, will represent the epoch the training is at (the decimal part being the
percentage of the current epoch completed).`,name:"epoch"},{anchor:"transformers.TrainerState.global_step",description:`<strong>global_step</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
During training, represents the number of update steps completed.`,name:"global_step"},{anchor:"transformers.TrainerState.max_steps",description:`<strong>max_steps</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The number of update steps to do during the current training.`,name:"max_steps"},{anchor:"transformers.TrainerState.total_flos",description:`<strong>total_flos</strong> (<code>float</code>, <em>optional</em>, defaults to 0) &#x2014;
The total number of floating operations done by the model since the beginning of training (stored as floats
to avoid overflow).`,name:"total_flos"},{anchor:"transformers.TrainerState.log_history",description:`<strong>log_history</strong> (<code>List[Dict[str, float]]</code>, <em>optional</em>) &#x2014;
The list of logs done since the beginning of training.`,name:"log_history"},{anchor:"transformers.TrainerState.best_metric",description:`<strong>best_metric</strong> (<code>float</code>, <em>optional</em>) &#x2014;
When tracking the best model, the value of the best metric encountered so far.`,name:"best_metric"},{anchor:"transformers.TrainerState.best_model_checkpoint",description:`<strong>best_model_checkpoint</strong> (<code>str</code>, <em>optional</em>) &#x2014;
When tracking the best model, the value of the name of the checkpoint for the best model encountered so
far.`,name:"best_model_checkpoint"},{anchor:"transformers.TrainerState.is_local_process_zero",description:`<strong>is_local_process_zero</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not this process is the local (e.g., on one machine if training in a distributed fashion on
several machines) main process.`,name:"is_local_process_zero"},{anchor:"transformers.TrainerState.is_world_process_zero",description:`<strong>is_world_process_zero</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not this process is the global main process (when training in a distributed fashion on several
machines, this is only going to be <code>True</code> for one process).`,name:"is_world_process_zero"},{anchor:"transformers.TrainerState.is_hyper_param_search",description:`<strong>is_hyper_param_search</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether we are in the process of a hyper parameter search using Trainer.hyperparameter_search. This will
impact the way data will be logged in TensorBoard.`,name:"is_hyper_param_search"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_callback.py#L35"}}),et=new Pu({props:{$$slots:{default:[ju]},$$scope:{ctx:wa}}}),ba=new w({props:{name:"load_from_json",anchor:"transformers.TrainerState.load_from_json",parameters:[{name:"json_path",val:": str"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_callback.py#L101"}}),va=new w({props:{name:"save_to_json",anchor:"transformers.TrainerState.save_to_json",parameters:[{name:"json_path",val:": str"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_callback.py#L95"}}),ka=new Eo({}),Ta=new w({props:{name:"class transformers.TrainerControl",anchor:"transformers.TrainerControl",parameters:[{name:"should_training_stop",val:": bool = False"},{name:"should_epoch_stop",val:": bool = False"},{name:"should_save",val:": bool = False"},{name:"should_evaluate",val:": bool = False"},{name:"should_log",val:": bool = False"}],parametersDescription:[{anchor:"transformers.TrainerControl.should_training_stop",description:`<strong>should_training_stop</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not the training should be interrupted.</p>
<p>If <code>True</code>, this variable will not be set back to <code>False</code>. The training will just stop.`,name:"should_training_stop"},{anchor:"transformers.TrainerControl.should_epoch_stop",description:`<strong>should_epoch_stop</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not the current epoch should be interrupted.</p>
<p>If <code>True</code>, this variable will be set back to <code>False</code> at the beginning of the next epoch.`,name:"should_epoch_stop"},{anchor:"transformers.TrainerControl.should_save",description:`<strong>should_save</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not the model should be saved at this step.</p>
<p>If <code>True</code>, this variable will be set back to <code>False</code> at the beginning of the next step.`,name:"should_save"},{anchor:"transformers.TrainerControl.should_evaluate",description:`<strong>should_evaluate</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not the model should be evaluated at this step.</p>
<p>If <code>True</code>, this variable will be set back to <code>False</code> at the beginning of the next step.`,name:"should_evaluate"},{anchor:"transformers.TrainerControl.should_log",description:`<strong>should_log</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not the logs should be reported at this step.</p>
<p>If <code>True</code>, this variable will be set back to <code>False</code> at the beginning of the next step.`,name:"should_log"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_callback.py#L110"}}),{c(){A=o("meta"),B=c(),x=o("h1"),M=o("a"),W=o("span"),g(y.$$.fragment),j=c(),oe=o("span"),se=t("Callbacks"),R=c(),J=o("p"),ya=t(`Callbacks are objects that can customize the behavior of the training loop in the PyTorch
`),Aa=o("a"),Rs=t("Trainer"),Bs=t(` (this feature is not yet implemented in TensorFlow) that can inspect the training loop
state (for progress reporting, logging on TensorBoard or other ML platforms\u2026) and take decisions (like early
stopping).`),ko=c(),V=o("p"),Vs=t("Callbacks are \u201Cread only\u201D pieces of code, apart from the "),La=o("a"),Us=t("TrainerControl"),qs=t(` object they return, they
cannot change anything in the training loop. For customizations that require changes in the training loop, you should
subclass `),Da=o("a"),Gs=t("Trainer"),Hs=t(" and override the methods you need (see "),xa=o("a"),Js=t("trainer"),Ys=t(" for examples)."),To=c(),ye=o("p"),Xs=t("By default a "),Ma=o("a"),Ks=t("Trainer"),Qs=t(" will use the following callbacks:"),$o=c(),L=o("ul"),Oa=o("li"),Sa=o("a"),Zs=t("DefaultFlowCallback"),el=t(" which handles the default behavior for logging, saving and evaluation."),tl=c(),ae=o("li"),Ia=o("a"),al=t("PrinterCallback"),rl=t(" or "),Na=o("a"),nl=t("ProgressCallback"),ol=t(` to display progress and print the
logs (the first one is used if you deactivate tqdm through the `),Pa=o("a"),sl=t("TrainingArguments"),ll=t(`, otherwise
it\u2019s the second one).`),il=c(),Fa=o("li"),Wa=o("a"),cl=t("TensorBoardCallback"),dl=t(` if tensorboard is accessible (either through PyTorch >= 1.4
or tensorboardX).`),ml=c(),Ae=o("li"),ja=o("a"),fl=t("WandbCallback"),hl=t(" if "),ct=o("a"),pl=t("wandb"),gl=t(" is installed."),ul=c(),Le=o("li"),za=o("a"),bl=t("CometCallback"),_l=t(" if "),dt=o("a"),vl=t("comet_ml"),El=t(" is installed."),kl=c(),De=o("li"),Ra=o("a"),Tl=t("MLflowCallback"),$l=t(" if "),mt=o("a"),Cl=t("mlflow"),wl=t(" is installed."),yl=c(),xe=o("li"),Ba=o("a"),Al=t("NeptuneCallback"),Ll=t(" if "),ft=o("a"),Dl=t("neptune"),xl=t(" is installed."),Ml=c(),Me=o("li"),Va=o("a"),Ol=t("AzureMLCallback"),Sl=t(" if "),ht=o("a"),Il=t("azureml-sdk"),Nl=t(` is
installed.`),Pl=c(),Oe=o("li"),Ua=o("a"),Fl=t("CodeCarbonCallback"),Wl=t(" if "),pt=o("a"),jl=t("codecarbon"),zl=t(` is
installed.`),Rl=c(),Se=o("li"),qa=o("a"),Bl=t("ClearMLCallback"),Vl=t(" if "),gt=o("a"),Ul=t("clearml"),ql=t(" is installed."),Co=c(),N=o("p"),Gl=t("The main class that implements callbacks is "),Ga=o("a"),Hl=t("TrainerCallback"),Jl=t(`. It gets the
`),Ha=o("a"),Yl=t("TrainingArguments"),Xl=t(" used to instantiate the "),Ja=o("a"),Kl=t("Trainer"),Ql=t(`, can access that
Trainer\u2019s internal state via `),Ya=o("a"),Zl=t("TrainerState"),ei=t(`, and can take some actions on the training loop via
`),Xa=o("a"),ti=t("TrainerControl"),ai=t("."),wo=c(),le=o("h2"),Ie=o("a"),Mr=o("span"),g(ut.$$.fragment),ri=c(),Or=o("span"),ni=t("Available Callbacks"),yo=c(),Ne=o("p"),oi=t("Here is the list of the available "),Ka=o("a"),si=t("TrainerCallback"),li=t(" in the library:"),Ao=c(),Y=o("div"),g(bt.$$.fragment),ii=c(),ie=o("p"),ci=t("A "),Qa=o("a"),di=t("TrainerCallback"),mi=t(" that sends the logs to "),_t=o("a"),fi=t("Comet ML"),hi=t("."),pi=c(),U=o("div"),g(vt.$$.fragment),gi=c(),Sr=o("p"),ui=t("Setup the optional Comet.ml integration."),bi=c(),D=o("p"),_i=t(`Environment:
COMET_MODE (`),Ir=o("code"),vi=t("str"),Ei=t(", "),Nr=o("em"),ki=t("optional"),Ti=t(`):
Whether to create an online, offline experiment or disable Comet logging. Can be \u201COFFLINE\u201D, \u201CONLINE\u201D,
or \u201CDISABLED\u201D. Defaults to \u201CONLINE\u201D.
COMET_PROJECT_NAME (`),Pr=o("code"),$i=t("str"),Ci=t(", "),Fr=o("em"),wi=t("optional"),yi=t(`):
Comet project name for experiments
COMET_OFFLINE_DIRECTORY (`),Wr=o("code"),Ai=t("str"),Li=t(", "),jr=o("em"),Di=t("optional"),xi=t(`):
Folder to use for saving offline experiments when `),zr=o("code"),Mi=t("COMET_MODE"),Oi=t(` is \u201COFFLINE\u201D
COMET_LOG_ASSETS (`),Rr=o("code"),Si=t("str"),Ii=t(", "),Br=o("em"),Ni=t("optional"),Pi=t(`):
Whether or not to log training assets (tf event logs, checkpoints, etc), to Comet. Can be \u201CTRUE\u201D, or
\u201CFALSE\u201D. Defaults to \u201CTRUE\u201D.`),Fi=c(),Et=o("p"),Wi=t(`For a number of configurable items in the environment, see
`),kt=o("a"),ji=t("here"),zi=t("."),Lo=c(),ce=o("div"),g(Tt.$$.fragment),Ri=c(),$t=o("p"),Bi=t("A "),Za=o("a"),Vi=t("TrainerCallback"),Ui=t(" that handles the default flow of the training loop for logs, evaluation and checkpoints."),Do=c(),de=o("div"),g(Ct.$$.fragment),qi=c(),wt=o("p"),Gi=t("A bare "),er=o("a"),Hi=t("TrainerCallback"),Ji=t(" that just prints the logs."),xo=c(),me=o("div"),g(yt.$$.fragment),Yi=c(),At=o("p"),Xi=t("A "),tr=o("a"),Ki=t("TrainerCallback"),Qi=t(" that displays the progress of training or evaluation."),Mo=c(),X=o("div"),g(Lt.$$.fragment),Zi=c(),Dt=o("p"),ec=t("A "),ar=o("a"),tc=t("TrainerCallback"),ac=t(" that handles early stopping."),rc=c(),K=o("p"),nc=t("This callback depends on "),rr=o("a"),oc=t("TrainingArguments"),sc=t(" argument "),Vr=o("em"),lc=t("load_best_model_at_end"),ic=t(` functionality to set best_metric
in `),nr=o("a"),cc=t("TrainerState"),dc=t("."),Oo=c(),fe=o("div"),g(xt.$$.fragment),mc=c(),he=o("p"),fc=t("A "),or=o("a"),hc=t("TrainerCallback"),pc=t(" that sends the logs to "),Mt=o("a"),gc=t("TensorBoard"),uc=t("."),So=c(),Q=o("div"),g(Ot.$$.fragment),bc=c(),pe=o("p"),_c=t("A "),sr=o("a"),vc=t("TrainerCallback"),Ec=t(" that sends the logs to "),St=o("a"),kc=t("Weight and Biases"),Tc=t("."),$c=c(),q=o("div"),g(It.$$.fragment),Cc=c(),Nt=o("p"),wc=t("Setup the optional Weights & Biases ("),Ur=o("em"),yc=t("wandb"),Ac=t(") integration."),Lc=c(),Pt=o("p"),Dc=t(`One can subclass and override this method to customize the setup if needed. Find more information
`),Ft=o("a"),xc=t("here"),Mc=t(`. You can also override the following environment
variables:`),Oc=c(),h=o("p"),Sc=t(`Environment:
WANDB_LOG_MODEL (`),qr=o("code"),Ic=t("bool"),Nc=t(", "),Gr=o("em"),Pc=t("optional"),Fc=t(", defaults to "),Hr=o("code"),Wc=t("False"),jc=t(`):
Whether or not to log model as artifact at the end of training. Use along with
`),Jr=o("em"),zc=t("TrainingArguments.load_best_model_at_end"),Rc=t(` to upload best model.
WANDB_WATCH (`),Yr=o("code"),Bc=t("str"),Vc=t(", "),Xr=o("em"),Uc=t("optional"),qc=t(" defaults to "),Kr=o("code"),Gc=t('"gradients"'),Hc=t(`):
Can be `),Qr=o("code"),Jc=t('"gradients"'),Yc=t(", "),Zr=o("code"),Xc=t('"all"'),Kc=t(" or "),en=o("code"),Qc=t('"false"'),Zc=t(". Set to "),tn=o("code"),ed=t('"false"'),td=t(" to disable gradient logging or "),an=o("code"),ad=t('"all"'),rd=t(` to
log gradients and parameters.
WANDB_PROJECT (`),rn=o("code"),nd=t("str"),od=t(", "),nn=o("em"),sd=t("optional"),ld=t(", defaults to "),on=o("code"),id=t('"huggingface"'),cd=t(`):
Set this to a custom string to store results in a different project.
WANDB_DISABLED (`),sn=o("code"),dd=t("bool"),md=t(", "),ln=o("em"),fd=t("optional"),hd=t(", defaults to "),cn=o("code"),pd=t("False"),gd=t(`):
Whether or not to disable wandb entirely. Set `),dn=o("em"),ud=t("WANDB_DISABLED=true"),bd=t(" to disable."),Io=c(),Z=o("div"),g(Wt.$$.fragment),_d=c(),ee=o("p"),vd=t("A "),lr=o("a"),Ed=t("TrainerCallback"),kd=t(" that sends the logs to "),jt=o("a"),Td=t("MLflow"),$d=t(`. Can be disabled by setting
environment variable `),mn=o("code"),Cd=t("DISABLE_MLFLOW_INTEGRATION = TRUE"),wd=t("."),yd=c(),re=o("div"),g(zt.$$.fragment),Ad=c(),fn=o("p"),Ld=t("Setup the optional MLflow integration."),Dd=c(),p=o("p"),xd=t(`Environment:
HF_MLFLOW_LOG_ARTIFACTS (`),hn=o("code"),Md=t("str"),Od=t(", "),pn=o("em"),Sd=t("optional"),Id=t(`):
Whether to use MLflow .log_artifact() facility to log artifacts. This only makes sense if logging to a
remote server, e.g. s3 or GCS. If set to `),gn=o("code"),Nd=t("True"),Pd=t(" or "),un=o("em"),Fd=t("1"),Wd=t(`, will copy each saved checkpoint on each save in
`),ir=o("a"),jd=t("TrainingArguments"),zd=t("\u2019s "),bn=o("code"),Rd=t("output_dir"),Bd=t(` to the local or remote artifact storage. Using it without a remote
storage will just copy the files to your artifact location.
MLFLOW_EXPERIMENT_NAME (`),_n=o("code"),Vd=t("str"),Ud=t(", "),vn=o("em"),qd=t("optional"),Gd=t(`):
Whether to use an MLflow experiment_name under which to launch the run. Default to \u201CNone\u201D which will
point to the \u201CDefault\u201D experiment in MLflow. Otherwise, it is a case sensitive name of the experiment
to be activated. If an experiment with this name does not exist, a new experiment with this name is
created.
MLFLOW_TAGS (`),En=o("code"),Hd=t("str"),Jd=t(", "),kn=o("em"),Yd=t("optional"),Xd=t(`):
A string dump of a dictionary of key/value pair to be added to the MLflow run as tags. Example:
os.environ[\u2018MLFLOW_TAGS\u2019]=\u2019{\u201Crelease.candidate\u201D: \u201CRC1\u201D, \u201Crelease.version\u201D: \u201C2.2.0\u201D}\u2019
MLFLOW_NESTED_RUN (`),Tn=o("code"),Kd=t("str"),Qd=t(", "),$n=o("em"),Zd=t("optional"),em=t(`):
Whether to use MLflow nested runs. If set to `),Cn=o("code"),tm=t("True"),am=t(" or "),wn=o("em"),rm=t("1"),nm=t(`, will create a nested run inside the current
run.
MLFLOW_RUN_ID (`),yn=o("code"),om=t("str"),sm=t(", "),An=o("em"),lm=t("optional"),im=t(`):
Allow to reattach to an existing run which can be usefull when resuming training from a checkpoint.
When MLFLOW_RUN_ID environment variable is set, start_run attempts to resume a run with the specified
run ID and other parameters are ignored.
MLFLOW_FLATTEN_PARAMS (`),Ln=o("code"),cm=t("str"),dm=t(", "),Dn=o("em"),mm=t("optional"),fm=t(`):
Whether to flatten the parameters dictionary before logging. Default to `),xn=o("code"),hm=t("False"),pm=t("."),No=c(),ge=o("div"),g(Rt.$$.fragment),gm=c(),ue=o("p"),um=t("A "),cr=o("a"),bm=t("TrainerCallback"),_m=t(" that sends the logs to "),Bt=o("a"),vm=t("AzureML"),Em=t("."),Po=c(),be=o("div"),g(Vt.$$.fragment),km=c(),Ut=o("p"),Tm=t("A "),dr=o("a"),$m=t("TrainerCallback"),Cm=t(" that tracks the CO2 emission of training."),Fo=c(),_e=o("div"),g(qt.$$.fragment),wm=c(),Gt=o("p"),ym=t("TrainerCallback that sends the logs to "),Ht=o("a"),Am=t("Neptune"),Lm=t("."),Wo=c(),te=o("div"),g(Jt.$$.fragment),Dm=c(),ve=o("p"),xm=t("A "),mr=o("a"),Mm=t("TrainerCallback"),Om=t(" that sends the logs to "),Yt=o("a"),Sm=t("ClearML"),Im=t("."),Nm=c(),I=o("p"),Pm=t(`Environment:
CLEARML_PROJECT (`),Mn=o("code"),Fm=t("str"),Wm=t(", "),On=o("em"),jm=t("optional"),zm=t(", defaults to "),Sn=o("code"),Rm=t('"HuggingFace Transformers"'),Bm=t(`):
ClearML project name.
CLEARML_TASK (`),In=o("code"),Vm=t("str"),Um=t(", "),Nn=o("em"),qm=t("optional"),Gm=t(" defaults to "),Pn=o("code"),Hm=t('"Trainer"'),Jm=t(`):
ClearML task name.`),jo=c(),Ee=o("h2"),Pe=o("a"),Fn=o("span"),g(Xt.$$.fragment),Ym=c(),Wn=o("span"),Xm=t("TrainerCallback"),zo=c(),k=o("div"),g(Kt.$$.fragment),Km=c(),jn=o("p"),Qm=t(`A class for objects that will inspect the state of the training loop at some events and take some decisions. At
each of those events the following arguments are available:`),Zm=c(),Qt=o("p"),ef=t("The "),zn=o("code"),tf=t("control"),af=t(` object is the only one that can be changed by the callback, in which case the event that changes it
should return the modified version.`),rf=c(),P=o("p"),nf=t("The argument "),Rn=o("code"),of=t("args"),sf=t(", "),Bn=o("code"),lf=t("state"),cf=t(" and "),Vn=o("code"),df=t("control"),mf=t(" are positionals for all events, all the others are grouped in "),Un=o("code"),ff=t("kwargs"),hf=t(`.
You can unpack the ones you need in the signature of the event using them. As an example, see the code of the
simple `),qn=o("code"),pf=t("~transformer.PrinterCallback"),gf=t("."),uf=c(),g(Fe.$$.fragment),bf=c(),We=o("div"),g(Zt.$$.fragment),_f=c(),Gn=o("p"),vf=t("Event called at the beginning of an epoch."),Ef=c(),je=o("div"),g(ea.$$.fragment),kf=c(),Hn=o("p"),Tf=t("Event called at the end of an epoch."),$f=c(),ze=o("div"),g(ta.$$.fragment),Cf=c(),Jn=o("p"),wf=t("Event called after an evaluation phase."),yf=c(),Re=o("div"),g(aa.$$.fragment),Af=c(),ra=o("p"),Lf=t("Event called at the end of the initialization of the "),fr=o("a"),Df=t("Trainer"),xf=t("."),Mf=c(),Be=o("div"),g(na.$$.fragment),Of=c(),Yn=o("p"),Sf=t("Event called after logging the last logs."),If=c(),Ve=o("div"),g(oa.$$.fragment),Nf=c(),Xn=o("p"),Pf=t("Event called after a successful prediction."),Ff=c(),Ue=o("div"),g(sa.$$.fragment),Wf=c(),Kn=o("p"),jf=t("Event called after a prediction step."),zf=c(),qe=o("div"),g(la.$$.fragment),Rf=c(),Qn=o("p"),Bf=t("Event called after a checkpoint save."),Vf=c(),Ge=o("div"),g(ia.$$.fragment),Uf=c(),Zn=o("p"),qf=t(`Event called at the beginning of a training step. If using gradient accumulation, one training step might take
several inputs.`),Gf=c(),He=o("div"),g(ca.$$.fragment),Hf=c(),eo=o("p"),Jf=t(`Event called at the end of a training step. If using gradient accumulation, one training step might take
several inputs.`),Yf=c(),Je=o("div"),g(da.$$.fragment),Xf=c(),to=o("p"),Kf=t("Event called at the end of an substep during gradient accumulation."),Qf=c(),Ye=o("div"),g(ma.$$.fragment),Zf=c(),ao=o("p"),eh=t("Event called at the beginning of training."),th=c(),Xe=o("div"),g(fa.$$.fragment),ah=c(),ro=o("p"),rh=t("Event called at the end of training."),Ro=c(),Ke=o("p"),nh=t("Here is an example of how to register a custom callback with the PyTorch "),hr=o("a"),oh=t("Trainer"),sh=t(":"),Bo=c(),g(ha.$$.fragment),Vo=c(),Qe=o("p"),lh=t("Another way to register a callback is to call "),no=o("code"),ih=t("trainer.add_callback()"),ch=t(" as follows:"),Uo=c(),g(pa.$$.fragment),qo=c(),ke=o("h2"),Ze=o("a"),oo=o("span"),g(ga.$$.fragment),dh=c(),so=o("span"),mh=t("TrainerState"),Go=c(),F=o("div"),g(ua.$$.fragment),fh=c(),Te=o("p"),hh=t("A class containing the "),pr=o("a"),ph=t("Trainer"),gh=t(` inner state that will be saved along the model and optimizer when checkpointing
and passed to the `),gr=o("a"),uh=t("TrainerCallback"),bh=t("."),_h=c(),g(et.$$.fragment),vh=c(),tt=o("div"),g(ba.$$.fragment),Eh=c(),_a=o("p"),kh=t("Create an instance from the content of "),lo=o("code"),Th=t("json_path"),$h=t("."),Ch=c(),at=o("div"),g(va.$$.fragment),wh=c(),Ea=o("p"),yh=t("Save the content of this instance in JSON format inside "),io=o("code"),Ah=t("json_path"),Lh=t("."),Ho=c(),$e=o("h2"),rt=o("a"),co=o("span"),g(ka.$$.fragment),Dh=c(),mo=o("span"),xh=t("TrainerControl"),Jo=c(),Ce=o("div"),g(Ta.$$.fragment),Mh=c(),we=o("p"),Oh=t("A class that handles the "),ur=o("a"),Sh=t("Trainer"),Ih=t(" control flow. This class is used by the "),br=o("a"),Nh=t("TrainerCallback"),Ph=t(` to activate some
switches in the training loop.`),this.h()},l(n){const m=Su('[data-svelte="svelte-1phssyn"]',document.head);A=s(m,"META",{name:!0,content:!0}),m.forEach(r),B=d(n),x=s(n,"H1",{class:!0});var $a=l(x);M=s($a,"A",{id:!0,class:!0,href:!0});var fo=l(M);W=s(fo,"SPAN",{});var zh=l(W);u(y.$$.fragment,zh),zh.forEach(r),fo.forEach(r),j=d($a),oe=s($a,"SPAN",{});var Rh=l(oe);se=a(Rh,"Callbacks"),Rh.forEach(r),$a.forEach(r),R=d(n),J=s(n,"P",{});var Xo=l(J);ya=a(Xo,`Callbacks are objects that can customize the behavior of the training loop in the PyTorch
`),Aa=s(Xo,"A",{href:!0});var Bh=l(Aa);Rs=a(Bh,"Trainer"),Bh.forEach(r),Bs=a(Xo,` (this feature is not yet implemented in TensorFlow) that can inspect the training loop
state (for progress reporting, logging on TensorBoard or other ML platforms\u2026) and take decisions (like early
stopping).`),Xo.forEach(r),ko=d(n),V=s(n,"P",{});var nt=l(V);Vs=a(nt,"Callbacks are \u201Cread only\u201D pieces of code, apart from the "),La=s(nt,"A",{href:!0});var Vh=l(La);Us=a(Vh,"TrainerControl"),Vh.forEach(r),qs=a(nt,` object they return, they
cannot change anything in the training loop. For customizations that require changes in the training loop, you should
subclass `),Da=s(nt,"A",{href:!0});var Uh=l(Da);Gs=a(Uh,"Trainer"),Uh.forEach(r),Hs=a(nt," and override the methods you need (see "),xa=s(nt,"A",{href:!0});var qh=l(xa);Js=a(qh,"trainer"),qh.forEach(r),Ys=a(nt," for examples)."),nt.forEach(r),To=d(n),ye=s(n,"P",{});var Ko=l(ye);Xs=a(Ko,"By default a "),Ma=s(Ko,"A",{href:!0});var Gh=l(Ma);Ks=a(Gh,"Trainer"),Gh.forEach(r),Qs=a(Ko," will use the following callbacks:"),Ko.forEach(r),$o=d(n),L=s(n,"UL",{});var O=l(L);Oa=s(O,"LI",{});var Fh=l(Oa);Sa=s(Fh,"A",{href:!0});var Hh=l(Sa);Zs=a(Hh,"DefaultFlowCallback"),Hh.forEach(r),el=a(Fh," which handles the default behavior for logging, saving and evaluation."),Fh.forEach(r),tl=d(O),ae=s(O,"LI",{});var Ca=l(ae);Ia=s(Ca,"A",{href:!0});var Jh=l(Ia);al=a(Jh,"PrinterCallback"),Jh.forEach(r),rl=a(Ca," or "),Na=s(Ca,"A",{href:!0});var Yh=l(Na);nl=a(Yh,"ProgressCallback"),Yh.forEach(r),ol=a(Ca,` to display progress and print the
logs (the first one is used if you deactivate tqdm through the `),Pa=s(Ca,"A",{href:!0});var Xh=l(Pa);sl=a(Xh,"TrainingArguments"),Xh.forEach(r),ll=a(Ca,`, otherwise
it\u2019s the second one).`),Ca.forEach(r),il=d(O),Fa=s(O,"LI",{});var Wh=l(Fa);Wa=s(Wh,"A",{href:!0});var Kh=l(Wa);cl=a(Kh,"TensorBoardCallback"),Kh.forEach(r),dl=a(Wh,` if tensorboard is accessible (either through PyTorch >= 1.4
or tensorboardX).`),Wh.forEach(r),ml=d(O),Ae=s(O,"LI",{});var ho=l(Ae);ja=s(ho,"A",{href:!0});var Qh=l(ja);fl=a(Qh,"WandbCallback"),Qh.forEach(r),hl=a(ho," if "),ct=s(ho,"A",{href:!0,rel:!0});var Zh=l(ct);pl=a(Zh,"wandb"),Zh.forEach(r),gl=a(ho," is installed."),ho.forEach(r),ul=d(O),Le=s(O,"LI",{});var po=l(Le);za=s(po,"A",{href:!0});var ep=l(za);bl=a(ep,"CometCallback"),ep.forEach(r),_l=a(po," if "),dt=s(po,"A",{href:!0,rel:!0});var tp=l(dt);vl=a(tp,"comet_ml"),tp.forEach(r),El=a(po," is installed."),po.forEach(r),kl=d(O),De=s(O,"LI",{});var go=l(De);Ra=s(go,"A",{href:!0});var ap=l(Ra);Tl=a(ap,"MLflowCallback"),ap.forEach(r),$l=a(go," if "),mt=s(go,"A",{href:!0,rel:!0});var rp=l(mt);Cl=a(rp,"mlflow"),rp.forEach(r),wl=a(go," is installed."),go.forEach(r),yl=d(O),xe=s(O,"LI",{});var uo=l(xe);Ba=s(uo,"A",{href:!0});var np=l(Ba);Al=a(np,"NeptuneCallback"),np.forEach(r),Ll=a(uo," if "),ft=s(uo,"A",{href:!0,rel:!0});var op=l(ft);Dl=a(op,"neptune"),op.forEach(r),xl=a(uo," is installed."),uo.forEach(r),Ml=d(O),Me=s(O,"LI",{});var bo=l(Me);Va=s(bo,"A",{href:!0});var sp=l(Va);Ol=a(sp,"AzureMLCallback"),sp.forEach(r),Sl=a(bo," if "),ht=s(bo,"A",{href:!0,rel:!0});var lp=l(ht);Il=a(lp,"azureml-sdk"),lp.forEach(r),Nl=a(bo,` is
installed.`),bo.forEach(r),Pl=d(O),Oe=s(O,"LI",{});var _o=l(Oe);Ua=s(_o,"A",{href:!0});var ip=l(Ua);Fl=a(ip,"CodeCarbonCallback"),ip.forEach(r),Wl=a(_o," if "),pt=s(_o,"A",{href:!0,rel:!0});var cp=l(pt);jl=a(cp,"codecarbon"),cp.forEach(r),zl=a(_o,` is
installed.`),_o.forEach(r),Rl=d(O),Se=s(O,"LI",{});var vo=l(Se);qa=s(vo,"A",{href:!0});var dp=l(qa);Bl=a(dp,"ClearMLCallback"),dp.forEach(r),Vl=a(vo," if "),gt=s(vo,"A",{href:!0,rel:!0});var mp=l(gt);Ul=a(mp,"clearml"),mp.forEach(r),ql=a(vo," is installed."),vo.forEach(r),O.forEach(r),Co=d(n),N=s(n,"P",{});var G=l(N);Gl=a(G,"The main class that implements callbacks is "),Ga=s(G,"A",{href:!0});var fp=l(Ga);Hl=a(fp,"TrainerCallback"),fp.forEach(r),Jl=a(G,`. It gets the
`),Ha=s(G,"A",{href:!0});var hp=l(Ha);Yl=a(hp,"TrainingArguments"),hp.forEach(r),Xl=a(G," used to instantiate the "),Ja=s(G,"A",{href:!0});var pp=l(Ja);Kl=a(pp,"Trainer"),pp.forEach(r),Ql=a(G,`, can access that
Trainer\u2019s internal state via `),Ya=s(G,"A",{href:!0});var gp=l(Ya);Zl=a(gp,"TrainerState"),gp.forEach(r),ei=a(G,`, and can take some actions on the training loop via
`),Xa=s(G,"A",{href:!0});var up=l(Xa);ti=a(up,"TrainerControl"),up.forEach(r),ai=a(G,"."),G.forEach(r),wo=d(n),le=s(n,"H2",{class:!0});var Qo=l(le);Ie=s(Qo,"A",{id:!0,class:!0,href:!0});var bp=l(Ie);Mr=s(bp,"SPAN",{});var _p=l(Mr);u(ut.$$.fragment,_p),_p.forEach(r),bp.forEach(r),ri=d(Qo),Or=s(Qo,"SPAN",{});var vp=l(Or);ni=a(vp,"Available Callbacks"),vp.forEach(r),Qo.forEach(r),yo=d(n),Ne=s(n,"P",{});var Zo=l(Ne);oi=a(Zo,"Here is the list of the available "),Ka=s(Zo,"A",{href:!0});var Ep=l(Ka);si=a(Ep,"TrainerCallback"),Ep.forEach(r),li=a(Zo," in the library:"),Zo.forEach(r),Ao=d(n),Y=s(n,"DIV",{class:!0});var _r=l(Y);u(bt.$$.fragment,_r),ii=d(_r),ie=s(_r,"P",{});var vr=l(ie);ci=a(vr,"A "),Qa=s(vr,"A",{href:!0});var kp=l(Qa);di=a(kp,"TrainerCallback"),kp.forEach(r),mi=a(vr," that sends the logs to "),_t=s(vr,"A",{href:!0,rel:!0});var Tp=l(_t);fi=a(Tp,"Comet ML"),Tp.forEach(r),hi=a(vr,"."),vr.forEach(r),pi=d(_r),U=s(_r,"DIV",{class:!0});var ot=l(U);u(vt.$$.fragment,ot),gi=d(ot),Sr=s(ot,"P",{});var $p=l(Sr);ui=a($p,"Setup the optional Comet.ml integration."),$p.forEach(r),bi=d(ot),D=s(ot,"P",{});var S=l(D);_i=a(S,`Environment:
COMET_MODE (`),Ir=s(S,"CODE",{});var Cp=l(Ir);vi=a(Cp,"str"),Cp.forEach(r),Ei=a(S,", "),Nr=s(S,"EM",{});var wp=l(Nr);ki=a(wp,"optional"),wp.forEach(r),Ti=a(S,`):
Whether to create an online, offline experiment or disable Comet logging. Can be \u201COFFLINE\u201D, \u201CONLINE\u201D,
or \u201CDISABLED\u201D. Defaults to \u201CONLINE\u201D.
COMET_PROJECT_NAME (`),Pr=s(S,"CODE",{});var yp=l(Pr);$i=a(yp,"str"),yp.forEach(r),Ci=a(S,", "),Fr=s(S,"EM",{});var Ap=l(Fr);wi=a(Ap,"optional"),Ap.forEach(r),yi=a(S,`):
Comet project name for experiments
COMET_OFFLINE_DIRECTORY (`),Wr=s(S,"CODE",{});var Lp=l(Wr);Ai=a(Lp,"str"),Lp.forEach(r),Li=a(S,", "),jr=s(S,"EM",{});var Dp=l(jr);Di=a(Dp,"optional"),Dp.forEach(r),xi=a(S,`):
Folder to use for saving offline experiments when `),zr=s(S,"CODE",{});var xp=l(zr);Mi=a(xp,"COMET_MODE"),xp.forEach(r),Oi=a(S,` is \u201COFFLINE\u201D
COMET_LOG_ASSETS (`),Rr=s(S,"CODE",{});var Mp=l(Rr);Si=a(Mp,"str"),Mp.forEach(r),Ii=a(S,", "),Br=s(S,"EM",{});var Op=l(Br);Ni=a(Op,"optional"),Op.forEach(r),Pi=a(S,`):
Whether or not to log training assets (tf event logs, checkpoints, etc), to Comet. Can be \u201CTRUE\u201D, or
\u201CFALSE\u201D. Defaults to \u201CTRUE\u201D.`),S.forEach(r),Fi=d(ot),Et=s(ot,"P",{});var es=l(Et);Wi=a(es,`For a number of configurable items in the environment, see
`),kt=s(es,"A",{href:!0,rel:!0});var Sp=l(kt);ji=a(Sp,"here"),Sp.forEach(r),zi=a(es,"."),es.forEach(r),ot.forEach(r),_r.forEach(r),Lo=d(n),ce=s(n,"DIV",{class:!0});var ts=l(ce);u(Tt.$$.fragment,ts),Ri=d(ts),$t=s(ts,"P",{});var as=l($t);Bi=a(as,"A "),Za=s(as,"A",{href:!0});var Ip=l(Za);Vi=a(Ip,"TrainerCallback"),Ip.forEach(r),Ui=a(as," that handles the default flow of the training loop for logs, evaluation and checkpoints."),as.forEach(r),ts.forEach(r),Do=d(n),de=s(n,"DIV",{class:!0});var rs=l(de);u(Ct.$$.fragment,rs),qi=d(rs),wt=s(rs,"P",{});var ns=l(wt);Gi=a(ns,"A bare "),er=s(ns,"A",{href:!0});var Np=l(er);Hi=a(Np,"TrainerCallback"),Np.forEach(r),Ji=a(ns," that just prints the logs."),ns.forEach(r),rs.forEach(r),xo=d(n),me=s(n,"DIV",{class:!0});var os=l(me);u(yt.$$.fragment,os),Yi=d(os),At=s(os,"P",{});var ss=l(At);Xi=a(ss,"A "),tr=s(ss,"A",{href:!0});var Pp=l(tr);Ki=a(Pp,"TrainerCallback"),Pp.forEach(r),Qi=a(ss," that displays the progress of training or evaluation."),ss.forEach(r),os.forEach(r),Mo=d(n),X=s(n,"DIV",{class:!0});var Er=l(X);u(Lt.$$.fragment,Er),Zi=d(Er),Dt=s(Er,"P",{});var ls=l(Dt);ec=a(ls,"A "),ar=s(ls,"A",{href:!0});var Fp=l(ar);tc=a(Fp,"TrainerCallback"),Fp.forEach(r),ac=a(ls," that handles early stopping."),ls.forEach(r),rc=d(Er),K=s(Er,"P",{});var st=l(K);nc=a(st,"This callback depends on "),rr=s(st,"A",{href:!0});var Wp=l(rr);oc=a(Wp,"TrainingArguments"),Wp.forEach(r),sc=a(st," argument "),Vr=s(st,"EM",{});var jp=l(Vr);lc=a(jp,"load_best_model_at_end"),jp.forEach(r),ic=a(st,` functionality to set best_metric
in `),nr=s(st,"A",{href:!0});var zp=l(nr);cc=a(zp,"TrainerState"),zp.forEach(r),dc=a(st,"."),st.forEach(r),Er.forEach(r),Oo=d(n),fe=s(n,"DIV",{class:!0});var is=l(fe);u(xt.$$.fragment,is),mc=d(is),he=s(is,"P",{});var kr=l(he);fc=a(kr,"A "),or=s(kr,"A",{href:!0});var Rp=l(or);hc=a(Rp,"TrainerCallback"),Rp.forEach(r),pc=a(kr," that sends the logs to "),Mt=s(kr,"A",{href:!0,rel:!0});var Bp=l(Mt);gc=a(Bp,"TensorBoard"),Bp.forEach(r),uc=a(kr,"."),kr.forEach(r),is.forEach(r),So=d(n),Q=s(n,"DIV",{class:!0});var Tr=l(Q);u(Ot.$$.fragment,Tr),bc=d(Tr),pe=s(Tr,"P",{});var $r=l(pe);_c=a($r,"A "),sr=s($r,"A",{href:!0});var Vp=l(sr);vc=a(Vp,"TrainerCallback"),Vp.forEach(r),Ec=a($r," that sends the logs to "),St=s($r,"A",{href:!0,rel:!0});var Up=l(St);kc=a(Up,"Weight and Biases"),Up.forEach(r),Tc=a($r,"."),$r.forEach(r),$c=d(Tr),q=s(Tr,"DIV",{class:!0});var lt=l(q);u(It.$$.fragment,lt),Cc=d(lt),Nt=s(lt,"P",{});var cs=l(Nt);wc=a(cs,"Setup the optional Weights & Biases ("),Ur=s(cs,"EM",{});var qp=l(Ur);yc=a(qp,"wandb"),qp.forEach(r),Ac=a(cs,") integration."),cs.forEach(r),Lc=d(lt),Pt=s(lt,"P",{});var ds=l(Pt);Dc=a(ds,`One can subclass and override this method to customize the setup if needed. Find more information
`),Ft=s(ds,"A",{href:!0,rel:!0});var Gp=l(Ft);xc=a(Gp,"here"),Gp.forEach(r),Mc=a(ds,`. You can also override the following environment
variables:`),ds.forEach(r),Oc=d(lt),h=s(lt,"P",{});var T=l(h);Sc=a(T,`Environment:
WANDB_LOG_MODEL (`),qr=s(T,"CODE",{});var Hp=l(qr);Ic=a(Hp,"bool"),Hp.forEach(r),Nc=a(T,", "),Gr=s(T,"EM",{});var Jp=l(Gr);Pc=a(Jp,"optional"),Jp.forEach(r),Fc=a(T,", defaults to "),Hr=s(T,"CODE",{});var Yp=l(Hr);Wc=a(Yp,"False"),Yp.forEach(r),jc=a(T,`):
Whether or not to log model as artifact at the end of training. Use along with
`),Jr=s(T,"EM",{});var Xp=l(Jr);zc=a(Xp,"TrainingArguments.load_best_model_at_end"),Xp.forEach(r),Rc=a(T,` to upload best model.
WANDB_WATCH (`),Yr=s(T,"CODE",{});var Kp=l(Yr);Bc=a(Kp,"str"),Kp.forEach(r),Vc=a(T,", "),Xr=s(T,"EM",{});var Qp=l(Xr);Uc=a(Qp,"optional"),Qp.forEach(r),qc=a(T," defaults to "),Kr=s(T,"CODE",{});var Zp=l(Kr);Gc=a(Zp,'"gradients"'),Zp.forEach(r),Hc=a(T,`):
Can be `),Qr=s(T,"CODE",{});var eg=l(Qr);Jc=a(eg,'"gradients"'),eg.forEach(r),Yc=a(T,", "),Zr=s(T,"CODE",{});var tg=l(Zr);Xc=a(tg,'"all"'),tg.forEach(r),Kc=a(T," or "),en=s(T,"CODE",{});var ag=l(en);Qc=a(ag,'"false"'),ag.forEach(r),Zc=a(T,". Set to "),tn=s(T,"CODE",{});var rg=l(tn);ed=a(rg,'"false"'),rg.forEach(r),td=a(T," to disable gradient logging or "),an=s(T,"CODE",{});var ng=l(an);ad=a(ng,'"all"'),ng.forEach(r),rd=a(T,` to
log gradients and parameters.
WANDB_PROJECT (`),rn=s(T,"CODE",{});var og=l(rn);nd=a(og,"str"),og.forEach(r),od=a(T,", "),nn=s(T,"EM",{});var sg=l(nn);sd=a(sg,"optional"),sg.forEach(r),ld=a(T,", defaults to "),on=s(T,"CODE",{});var lg=l(on);id=a(lg,'"huggingface"'),lg.forEach(r),cd=a(T,`):
Set this to a custom string to store results in a different project.
WANDB_DISABLED (`),sn=s(T,"CODE",{});var ig=l(sn);dd=a(ig,"bool"),ig.forEach(r),md=a(T,", "),ln=s(T,"EM",{});var cg=l(ln);fd=a(cg,"optional"),cg.forEach(r),hd=a(T,", defaults to "),cn=s(T,"CODE",{});var dg=l(cn);pd=a(dg,"False"),dg.forEach(r),gd=a(T,`):
Whether or not to disable wandb entirely. Set `),dn=s(T,"EM",{});var mg=l(dn);ud=a(mg,"WANDB_DISABLED=true"),mg.forEach(r),bd=a(T," to disable."),T.forEach(r),lt.forEach(r),Tr.forEach(r),Io=d(n),Z=s(n,"DIV",{class:!0});var Cr=l(Z);u(Wt.$$.fragment,Cr),_d=d(Cr),ee=s(Cr,"P",{});var it=l(ee);vd=a(it,"A "),lr=s(it,"A",{href:!0});var fg=l(lr);Ed=a(fg,"TrainerCallback"),fg.forEach(r),kd=a(it," that sends the logs to "),jt=s(it,"A",{href:!0,rel:!0});var hg=l(jt);Td=a(hg,"MLflow"),hg.forEach(r),$d=a(it,`. Can be disabled by setting
environment variable `),mn=s(it,"CODE",{});var pg=l(mn);Cd=a(pg,"DISABLE_MLFLOW_INTEGRATION = TRUE"),pg.forEach(r),wd=a(it,"."),it.forEach(r),yd=d(Cr),re=s(Cr,"DIV",{class:!0});var wr=l(re);u(zt.$$.fragment,wr),Ad=d(wr),fn=s(wr,"P",{});var gg=l(fn);Ld=a(gg,"Setup the optional MLflow integration."),gg.forEach(r),Dd=d(wr),p=s(wr,"P",{});var $=l(p);xd=a($,`Environment:
HF_MLFLOW_LOG_ARTIFACTS (`),hn=s($,"CODE",{});var ug=l(hn);Md=a(ug,"str"),ug.forEach(r),Od=a($,", "),pn=s($,"EM",{});var bg=l(pn);Sd=a(bg,"optional"),bg.forEach(r),Id=a($,`):
Whether to use MLflow .log_artifact() facility to log artifacts. This only makes sense if logging to a
remote server, e.g. s3 or GCS. If set to `),gn=s($,"CODE",{});var _g=l(gn);Nd=a(_g,"True"),_g.forEach(r),Pd=a($," or "),un=s($,"EM",{});var vg=l(un);Fd=a(vg,"1"),vg.forEach(r),Wd=a($,`, will copy each saved checkpoint on each save in
`),ir=s($,"A",{href:!0});var Eg=l(ir);jd=a(Eg,"TrainingArguments"),Eg.forEach(r),zd=a($,"\u2019s "),bn=s($,"CODE",{});var kg=l(bn);Rd=a(kg,"output_dir"),kg.forEach(r),Bd=a($,` to the local or remote artifact storage. Using it without a remote
storage will just copy the files to your artifact location.
MLFLOW_EXPERIMENT_NAME (`),_n=s($,"CODE",{});var Tg=l(_n);Vd=a(Tg,"str"),Tg.forEach(r),Ud=a($,", "),vn=s($,"EM",{});var $g=l(vn);qd=a($g,"optional"),$g.forEach(r),Gd=a($,`):
Whether to use an MLflow experiment_name under which to launch the run. Default to \u201CNone\u201D which will
point to the \u201CDefault\u201D experiment in MLflow. Otherwise, it is a case sensitive name of the experiment
to be activated. If an experiment with this name does not exist, a new experiment with this name is
created.
MLFLOW_TAGS (`),En=s($,"CODE",{});var Cg=l(En);Hd=a(Cg,"str"),Cg.forEach(r),Jd=a($,", "),kn=s($,"EM",{});var wg=l(kn);Yd=a(wg,"optional"),wg.forEach(r),Xd=a($,`):
A string dump of a dictionary of key/value pair to be added to the MLflow run as tags. Example:
os.environ[\u2018MLFLOW_TAGS\u2019]=\u2019{\u201Crelease.candidate\u201D: \u201CRC1\u201D, \u201Crelease.version\u201D: \u201C2.2.0\u201D}\u2019
MLFLOW_NESTED_RUN (`),Tn=s($,"CODE",{});var yg=l(Tn);Kd=a(yg,"str"),yg.forEach(r),Qd=a($,", "),$n=s($,"EM",{});var Ag=l($n);Zd=a(Ag,"optional"),Ag.forEach(r),em=a($,`):
Whether to use MLflow nested runs. If set to `),Cn=s($,"CODE",{});var Lg=l(Cn);tm=a(Lg,"True"),Lg.forEach(r),am=a($," or "),wn=s($,"EM",{});var Dg=l(wn);rm=a(Dg,"1"),Dg.forEach(r),nm=a($,`, will create a nested run inside the current
run.
MLFLOW_RUN_ID (`),yn=s($,"CODE",{});var xg=l(yn);om=a(xg,"str"),xg.forEach(r),sm=a($,", "),An=s($,"EM",{});var Mg=l(An);lm=a(Mg,"optional"),Mg.forEach(r),im=a($,`):
Allow to reattach to an existing run which can be usefull when resuming training from a checkpoint.
When MLFLOW_RUN_ID environment variable is set, start_run attempts to resume a run with the specified
run ID and other parameters are ignored.
MLFLOW_FLATTEN_PARAMS (`),Ln=s($,"CODE",{});var Og=l(Ln);cm=a(Og,"str"),Og.forEach(r),dm=a($,", "),Dn=s($,"EM",{});var Sg=l(Dn);mm=a(Sg,"optional"),Sg.forEach(r),fm=a($,`):
Whether to flatten the parameters dictionary before logging. Default to `),xn=s($,"CODE",{});var Ig=l(xn);hm=a(Ig,"False"),Ig.forEach(r),pm=a($,"."),$.forEach(r),wr.forEach(r),Cr.forEach(r),No=d(n),ge=s(n,"DIV",{class:!0});var ms=l(ge);u(Rt.$$.fragment,ms),gm=d(ms),ue=s(ms,"P",{});var yr=l(ue);um=a(yr,"A "),cr=s(yr,"A",{href:!0});var Ng=l(cr);bm=a(Ng,"TrainerCallback"),Ng.forEach(r),_m=a(yr," that sends the logs to "),Bt=s(yr,"A",{href:!0,rel:!0});var Pg=l(Bt);vm=a(Pg,"AzureML"),Pg.forEach(r),Em=a(yr,"."),yr.forEach(r),ms.forEach(r),Po=d(n),be=s(n,"DIV",{class:!0});var fs=l(be);u(Vt.$$.fragment,fs),km=d(fs),Ut=s(fs,"P",{});var hs=l(Ut);Tm=a(hs,"A "),dr=s(hs,"A",{href:!0});var Fg=l(dr);$m=a(Fg,"TrainerCallback"),Fg.forEach(r),Cm=a(hs," that tracks the CO2 emission of training."),hs.forEach(r),fs.forEach(r),Fo=d(n),_e=s(n,"DIV",{class:!0});var ps=l(_e);u(qt.$$.fragment,ps),wm=d(ps),Gt=s(ps,"P",{});var gs=l(Gt);ym=a(gs,"TrainerCallback that sends the logs to "),Ht=s(gs,"A",{href:!0,rel:!0});var Wg=l(Ht);Am=a(Wg,"Neptune"),Wg.forEach(r),Lm=a(gs,"."),gs.forEach(r),ps.forEach(r),Wo=d(n),te=s(n,"DIV",{class:!0});var Ar=l(te);u(Jt.$$.fragment,Ar),Dm=d(Ar),ve=s(Ar,"P",{});var Lr=l(ve);xm=a(Lr,"A "),mr=s(Lr,"A",{href:!0});var jg=l(mr);Mm=a(jg,"TrainerCallback"),jg.forEach(r),Om=a(Lr," that sends the logs to "),Yt=s(Lr,"A",{href:!0,rel:!0});var zg=l(Yt);Sm=a(zg,"ClearML"),zg.forEach(r),Im=a(Lr,"."),Lr.forEach(r),Nm=d(Ar),I=s(Ar,"P",{});var z=l(I);Pm=a(z,`Environment:
CLEARML_PROJECT (`),Mn=s(z,"CODE",{});var Rg=l(Mn);Fm=a(Rg,"str"),Rg.forEach(r),Wm=a(z,", "),On=s(z,"EM",{});var Bg=l(On);jm=a(Bg,"optional"),Bg.forEach(r),zm=a(z,", defaults to "),Sn=s(z,"CODE",{});var Vg=l(Sn);Rm=a(Vg,'"HuggingFace Transformers"'),Vg.forEach(r),Bm=a(z,`):
ClearML project name.
CLEARML_TASK (`),In=s(z,"CODE",{});var Ug=l(In);Vm=a(Ug,"str"),Ug.forEach(r),Um=a(z,", "),Nn=s(z,"EM",{});var qg=l(Nn);qm=a(qg,"optional"),qg.forEach(r),Gm=a(z," defaults to "),Pn=s(z,"CODE",{});var Gg=l(Pn);Hm=a(Gg,'"Trainer"'),Gg.forEach(r),Jm=a(z,`):
ClearML task name.`),z.forEach(r),Ar.forEach(r),jo=d(n),Ee=s(n,"H2",{class:!0});var us=l(Ee);Pe=s(us,"A",{id:!0,class:!0,href:!0});var Hg=l(Pe);Fn=s(Hg,"SPAN",{});var Jg=l(Fn);u(Xt.$$.fragment,Jg),Jg.forEach(r),Hg.forEach(r),Ym=d(us),Wn=s(us,"SPAN",{});var Yg=l(Wn);Xm=a(Yg,"TrainerCallback"),Yg.forEach(r),us.forEach(r),zo=d(n),k=s(n,"DIV",{class:!0});var C=l(k);u(Kt.$$.fragment,C),Km=d(C),jn=s(C,"P",{});var Xg=l(jn);Qm=a(Xg,`A class for objects that will inspect the state of the training loop at some events and take some decisions. At
each of those events the following arguments are available:`),Xg.forEach(r),Zm=d(C),Qt=s(C,"P",{});var bs=l(Qt);ef=a(bs,"The "),zn=s(bs,"CODE",{});var Kg=l(zn);tf=a(Kg,"control"),Kg.forEach(r),af=a(bs,` object is the only one that can be changed by the callback, in which case the event that changes it
should return the modified version.`),bs.forEach(r),rf=d(C),P=s(C,"P",{});var H=l(P);nf=a(H,"The argument "),Rn=s(H,"CODE",{});var Qg=l(Rn);of=a(Qg,"args"),Qg.forEach(r),sf=a(H,", "),Bn=s(H,"CODE",{});var Zg=l(Bn);lf=a(Zg,"state"),Zg.forEach(r),cf=a(H," and "),Vn=s(H,"CODE",{});var eu=l(Vn);df=a(eu,"control"),eu.forEach(r),mf=a(H," are positionals for all events, all the others are grouped in "),Un=s(H,"CODE",{});var tu=l(Un);ff=a(tu,"kwargs"),tu.forEach(r),hf=a(H,`.
You can unpack the ones you need in the signature of the event using them. As an example, see the code of the
simple `),qn=s(H,"CODE",{});var au=l(qn);pf=a(au,"~transformer.PrinterCallback"),au.forEach(r),gf=a(H,"."),H.forEach(r),uf=d(C),u(Fe.$$.fragment,C),bf=d(C),We=s(C,"DIV",{class:!0});var _s=l(We);u(Zt.$$.fragment,_s),_f=d(_s),Gn=s(_s,"P",{});var ru=l(Gn);vf=a(ru,"Event called at the beginning of an epoch."),ru.forEach(r),_s.forEach(r),Ef=d(C),je=s(C,"DIV",{class:!0});var vs=l(je);u(ea.$$.fragment,vs),kf=d(vs),Hn=s(vs,"P",{});var nu=l(Hn);Tf=a(nu,"Event called at the end of an epoch."),nu.forEach(r),vs.forEach(r),$f=d(C),ze=s(C,"DIV",{class:!0});var Es=l(ze);u(ta.$$.fragment,Es),Cf=d(Es),Jn=s(Es,"P",{});var ou=l(Jn);wf=a(ou,"Event called after an evaluation phase."),ou.forEach(r),Es.forEach(r),yf=d(C),Re=s(C,"DIV",{class:!0});var ks=l(Re);u(aa.$$.fragment,ks),Af=d(ks),ra=s(ks,"P",{});var Ts=l(ra);Lf=a(Ts,"Event called at the end of the initialization of the "),fr=s(Ts,"A",{href:!0});var su=l(fr);Df=a(su,"Trainer"),su.forEach(r),xf=a(Ts,"."),Ts.forEach(r),ks.forEach(r),Mf=d(C),Be=s(C,"DIV",{class:!0});var $s=l(Be);u(na.$$.fragment,$s),Of=d($s),Yn=s($s,"P",{});var lu=l(Yn);Sf=a(lu,"Event called after logging the last logs."),lu.forEach(r),$s.forEach(r),If=d(C),Ve=s(C,"DIV",{class:!0});var Cs=l(Ve);u(oa.$$.fragment,Cs),Nf=d(Cs),Xn=s(Cs,"P",{});var iu=l(Xn);Pf=a(iu,"Event called after a successful prediction."),iu.forEach(r),Cs.forEach(r),Ff=d(C),Ue=s(C,"DIV",{class:!0});var ws=l(Ue);u(sa.$$.fragment,ws),Wf=d(ws),Kn=s(ws,"P",{});var cu=l(Kn);jf=a(cu,"Event called after a prediction step."),cu.forEach(r),ws.forEach(r),zf=d(C),qe=s(C,"DIV",{class:!0});var ys=l(qe);u(la.$$.fragment,ys),Rf=d(ys),Qn=s(ys,"P",{});var du=l(Qn);Bf=a(du,"Event called after a checkpoint save."),du.forEach(r),ys.forEach(r),Vf=d(C),Ge=s(C,"DIV",{class:!0});var As=l(Ge);u(ia.$$.fragment,As),Uf=d(As),Zn=s(As,"P",{});var mu=l(Zn);qf=a(mu,`Event called at the beginning of a training step. If using gradient accumulation, one training step might take
several inputs.`),mu.forEach(r),As.forEach(r),Gf=d(C),He=s(C,"DIV",{class:!0});var Ls=l(He);u(ca.$$.fragment,Ls),Hf=d(Ls),eo=s(Ls,"P",{});var fu=l(eo);Jf=a(fu,`Event called at the end of a training step. If using gradient accumulation, one training step might take
several inputs.`),fu.forEach(r),Ls.forEach(r),Yf=d(C),Je=s(C,"DIV",{class:!0});var Ds=l(Je);u(da.$$.fragment,Ds),Xf=d(Ds),to=s(Ds,"P",{});var hu=l(to);Kf=a(hu,"Event called at the end of an substep during gradient accumulation."),hu.forEach(r),Ds.forEach(r),Qf=d(C),Ye=s(C,"DIV",{class:!0});var xs=l(Ye);u(ma.$$.fragment,xs),Zf=d(xs),ao=s(xs,"P",{});var pu=l(ao);eh=a(pu,"Event called at the beginning of training."),pu.forEach(r),xs.forEach(r),th=d(C),Xe=s(C,"DIV",{class:!0});var Ms=l(Xe);u(fa.$$.fragment,Ms),ah=d(Ms),ro=s(Ms,"P",{});var gu=l(ro);rh=a(gu,"Event called at the end of training."),gu.forEach(r),Ms.forEach(r),C.forEach(r),Ro=d(n),Ke=s(n,"P",{});var Os=l(Ke);nh=a(Os,"Here is an example of how to register a custom callback with the PyTorch "),hr=s(Os,"A",{href:!0});var uu=l(hr);oh=a(uu,"Trainer"),uu.forEach(r),sh=a(Os,":"),Os.forEach(r),Bo=d(n),u(ha.$$.fragment,n),Vo=d(n),Qe=s(n,"P",{});var Ss=l(Qe);lh=a(Ss,"Another way to register a callback is to call "),no=s(Ss,"CODE",{});var bu=l(no);ih=a(bu,"trainer.add_callback()"),bu.forEach(r),ch=a(Ss," as follows:"),Ss.forEach(r),Uo=d(n),u(pa.$$.fragment,n),qo=d(n),ke=s(n,"H2",{class:!0});var Is=l(ke);Ze=s(Is,"A",{id:!0,class:!0,href:!0});var _u=l(Ze);oo=s(_u,"SPAN",{});var vu=l(oo);u(ga.$$.fragment,vu),vu.forEach(r),_u.forEach(r),dh=d(Is),so=s(Is,"SPAN",{});var Eu=l(so);mh=a(Eu,"TrainerState"),Eu.forEach(r),Is.forEach(r),Go=d(n),F=s(n,"DIV",{class:!0});var ne=l(F);u(ua.$$.fragment,ne),fh=d(ne),Te=s(ne,"P",{});var Dr=l(Te);hh=a(Dr,"A class containing the "),pr=s(Dr,"A",{href:!0});var ku=l(pr);ph=a(ku,"Trainer"),ku.forEach(r),gh=a(Dr,` inner state that will be saved along the model and optimizer when checkpointing
and passed to the `),gr=s(Dr,"A",{href:!0});var Tu=l(gr);uh=a(Tu,"TrainerCallback"),Tu.forEach(r),bh=a(Dr,"."),Dr.forEach(r),_h=d(ne),u(et.$$.fragment,ne),vh=d(ne),tt=s(ne,"DIV",{class:!0});var Ns=l(tt);u(ba.$$.fragment,Ns),Eh=d(Ns),_a=s(Ns,"P",{});var Ps=l(_a);kh=a(Ps,"Create an instance from the content of "),lo=s(Ps,"CODE",{});var $u=l(lo);Th=a($u,"json_path"),$u.forEach(r),$h=a(Ps,"."),Ps.forEach(r),Ns.forEach(r),Ch=d(ne),at=s(ne,"DIV",{class:!0});var Fs=l(at);u(va.$$.fragment,Fs),wh=d(Fs),Ea=s(Fs,"P",{});var Ws=l(Ea);yh=a(Ws,"Save the content of this instance in JSON format inside "),io=s(Ws,"CODE",{});var Cu=l(io);Ah=a(Cu,"json_path"),Cu.forEach(r),Lh=a(Ws,"."),Ws.forEach(r),Fs.forEach(r),ne.forEach(r),Ho=d(n),$e=s(n,"H2",{class:!0});var js=l($e);rt=s(js,"A",{id:!0,class:!0,href:!0});var wu=l(rt);co=s(wu,"SPAN",{});var yu=l(co);u(ka.$$.fragment,yu),yu.forEach(r),wu.forEach(r),Dh=d(js),mo=s(js,"SPAN",{});var Au=l(mo);xh=a(Au,"TrainerControl"),Au.forEach(r),js.forEach(r),Jo=d(n),Ce=s(n,"DIV",{class:!0});var zs=l(Ce);u(Ta.$$.fragment,zs),Mh=d(zs),we=s(zs,"P",{});var xr=l(we);Oh=a(xr,"A class that handles the "),ur=s(xr,"A",{href:!0});var Lu=l(ur);Sh=a(Lu,"Trainer"),Lu.forEach(r),Ih=a(xr," control flow. This class is used by the "),br=s(xr,"A",{href:!0});var Du=l(br);Nh=a(Du,"TrainerCallback"),Du.forEach(r),Ph=a(xr,` to activate some
switches in the training loop.`),xr.forEach(r),zs.forEach(r),this.h()},h(){i(A,"name","hf:doc:metadata"),i(A,"content",JSON.stringify(Ru)),i(M,"id","callbacks"),i(M,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(M,"href","#callbacks"),i(x,"class","relative group"),i(Aa,"href","/docs/transformers/main/en/main_classes/trainer#transformers.Trainer"),i(La,"href","/docs/transformers/main/en/main_classes/callback#transformers.TrainerControl"),i(Da,"href","/docs/transformers/main/en/main_classes/trainer#transformers.Trainer"),i(xa,"href","trainer"),i(Ma,"href","/docs/transformers/main/en/main_classes/trainer#transformers.Trainer"),i(Sa,"href","/docs/transformers/main/en/main_classes/callback#transformers.DefaultFlowCallback"),i(Ia,"href","/docs/transformers/main/en/main_classes/callback#transformers.PrinterCallback"),i(Na,"href","/docs/transformers/main/en/main_classes/callback#transformers.ProgressCallback"),i(Pa,"href","/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments"),i(Wa,"href","/docs/transformers/main/en/main_classes/callback#transformers.integrations.TensorBoardCallback"),i(ja,"href","/docs/transformers/main/en/main_classes/callback#transformers.integrations.WandbCallback"),i(ct,"href","https://www.wandb.com/"),i(ct,"rel","nofollow"),i(za,"href","/docs/transformers/main/en/main_classes/callback#transformers.integrations.CometCallback"),i(dt,"href","https://www.comet.ml/site/"),i(dt,"rel","nofollow"),i(Ra,"href","/docs/transformers/main/en/main_classes/callback#transformers.integrations.MLflowCallback"),i(mt,"href","https://www.mlflow.org/"),i(mt,"rel","nofollow"),i(Ba,"href","/docs/transformers/main/en/main_classes/callback#transformers.integrations.NeptuneCallback"),i(ft,"href","https://neptune.ai/"),i(ft,"rel","nofollow"),i(Va,"href","/docs/transformers/main/en/main_classes/callback#transformers.integrations.AzureMLCallback"),i(ht,"href","https://pypi.org/project/azureml-sdk/"),i(ht,"rel","nofollow"),i(Ua,"href","/docs/transformers/main/en/main_classes/callback#transformers.integrations.CodeCarbonCallback"),i(pt,"href","https://pypi.org/project/codecarbon/"),i(pt,"rel","nofollow"),i(qa,"href","/docs/transformers/main/en/main_classes/callback#transformers.integrations.ClearMLCallback"),i(gt,"href","https://github.com/allegroai/clearml"),i(gt,"rel","nofollow"),i(Ga,"href","/docs/transformers/main/en/main_classes/callback#transformers.TrainerCallback"),i(Ha,"href","/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments"),i(Ja,"href","/docs/transformers/main/en/main_classes/trainer#transformers.Trainer"),i(Ya,"href","/docs/transformers/main/en/main_classes/callback#transformers.TrainerState"),i(Xa,"href","/docs/transformers/main/en/main_classes/callback#transformers.TrainerControl"),i(Ie,"id","transformers.integrations.CometCallback"),i(Ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(Ie,"href","#transformers.integrations.CometCallback"),i(le,"class","relative group"),i(Ka,"href","/docs/transformers/main/en/main_classes/callback#transformers.TrainerCallback"),i(Qa,"href","/docs/transformers/main/en/main_classes/callback#transformers.TrainerCallback"),i(_t,"href","https://www.comet.ml/site/"),i(_t,"rel","nofollow"),i(kt,"href","https://www.comet.ml/docs/python-sdk/advanced/#comet-configuration-variables"),i(kt,"rel","nofollow"),i(U,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(Y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(Za,"href","/docs/transformers/main/en/main_classes/callback#transformers.TrainerCallback"),i(ce,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(er,"href","/docs/transformers/main/en/main_classes/callback#transformers.TrainerCallback"),i(de,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(tr,"href","/docs/transformers/main/en/main_classes/callback#transformers.TrainerCallback"),i(me,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(ar,"href","/docs/transformers/main/en/main_classes/callback#transformers.TrainerCallback"),i(rr,"href","/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments"),i(nr,"href","/docs/transformers/main/en/main_classes/callback#transformers.TrainerState"),i(X,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(or,"href","/docs/transformers/main/en/main_classes/callback#transformers.TrainerCallback"),i(Mt,"href","https://www.tensorflow.org/tensorboard"),i(Mt,"rel","nofollow"),i(fe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(sr,"href","/docs/transformers/main/en/main_classes/callback#transformers.TrainerCallback"),i(St,"href","https://www.wandb.com/"),i(St,"rel","nofollow"),i(Ft,"href","https://docs.wandb.ai/integrations/huggingface"),i(Ft,"rel","nofollow"),i(q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(Q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(lr,"href","/docs/transformers/main/en/main_classes/callback#transformers.TrainerCallback"),i(jt,"href","https://www.mlflow.org/"),i(jt,"rel","nofollow"),i(ir,"href","/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments"),i(re,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(Z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(cr,"href","/docs/transformers/main/en/main_classes/callback#transformers.TrainerCallback"),i(Bt,"href","https://pypi.org/project/azureml-sdk/"),i(Bt,"rel","nofollow"),i(ge,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(dr,"href","/docs/transformers/main/en/main_classes/callback#transformers.TrainerCallback"),i(be,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(Ht,"href","https://neptune.ai"),i(Ht,"rel","nofollow"),i(_e,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(mr,"href","/docs/transformers/main/en/main_classes/callback#transformers.TrainerCallback"),i(Yt,"href","https://clear.ml/"),i(Yt,"rel","nofollow"),i(te,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(Pe,"id","transformers.TrainerCallback"),i(Pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(Pe,"href","#transformers.TrainerCallback"),i(Ee,"class","relative group"),i(We,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(fr,"href","/docs/transformers/main/en/main_classes/trainer#transformers.Trainer"),i(Re,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(Be,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(Ve,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(qe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(Ge,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(Xe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(k,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(hr,"href","/docs/transformers/main/en/main_classes/trainer#transformers.Trainer"),i(Ze,"id","transformers.TrainerState"),i(Ze,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(Ze,"href","#transformers.TrainerState"),i(ke,"class","relative group"),i(pr,"href","/docs/transformers/main/en/main_classes/trainer#transformers.Trainer"),i(gr,"href","/docs/transformers/main/en/main_classes/callback#transformers.TrainerCallback"),i(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(F,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),i(rt,"id","transformers.TrainerControl"),i(rt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(rt,"href","#transformers.TrainerControl"),i($e,"class","relative group"),i(ur,"href","/docs/transformers/main/en/main_classes/trainer#transformers.Trainer"),i(br,"href","/docs/transformers/main/en/main_classes/callback#transformers.TrainerCallback"),i(Ce,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(n,m){e(document.head,A),f(n,B,m),f(n,x,m),e(x,M),e(M,W),b(y,W,null),e(x,j),e(x,oe),e(oe,se),f(n,R,m),f(n,J,m),e(J,ya),e(J,Aa),e(Aa,Rs),e(J,Bs),f(n,ko,m),f(n,V,m),e(V,Vs),e(V,La),e(La,Us),e(V,qs),e(V,Da),e(Da,Gs),e(V,Hs),e(V,xa),e(xa,Js),e(V,Ys),f(n,To,m),f(n,ye,m),e(ye,Xs),e(ye,Ma),e(Ma,Ks),e(ye,Qs),f(n,$o,m),f(n,L,m),e(L,Oa),e(Oa,Sa),e(Sa,Zs),e(Oa,el),e(L,tl),e(L,ae),e(ae,Ia),e(Ia,al),e(ae,rl),e(ae,Na),e(Na,nl),e(ae,ol),e(ae,Pa),e(Pa,sl),e(ae,ll),e(L,il),e(L,Fa),e(Fa,Wa),e(Wa,cl),e(Fa,dl),e(L,ml),e(L,Ae),e(Ae,ja),e(ja,fl),e(Ae,hl),e(Ae,ct),e(ct,pl),e(Ae,gl),e(L,ul),e(L,Le),e(Le,za),e(za,bl),e(Le,_l),e(Le,dt),e(dt,vl),e(Le,El),e(L,kl),e(L,De),e(De,Ra),e(Ra,Tl),e(De,$l),e(De,mt),e(mt,Cl),e(De,wl),e(L,yl),e(L,xe),e(xe,Ba),e(Ba,Al),e(xe,Ll),e(xe,ft),e(ft,Dl),e(xe,xl),e(L,Ml),e(L,Me),e(Me,Va),e(Va,Ol),e(Me,Sl),e(Me,ht),e(ht,Il),e(Me,Nl),e(L,Pl),e(L,Oe),e(Oe,Ua),e(Ua,Fl),e(Oe,Wl),e(Oe,pt),e(pt,jl),e(Oe,zl),e(L,Rl),e(L,Se),e(Se,qa),e(qa,Bl),e(Se,Vl),e(Se,gt),e(gt,Ul),e(Se,ql),f(n,Co,m),f(n,N,m),e(N,Gl),e(N,Ga),e(Ga,Hl),e(N,Jl),e(N,Ha),e(Ha,Yl),e(N,Xl),e(N,Ja),e(Ja,Kl),e(N,Ql),e(N,Ya),e(Ya,Zl),e(N,ei),e(N,Xa),e(Xa,ti),e(N,ai),f(n,wo,m),f(n,le,m),e(le,Ie),e(Ie,Mr),b(ut,Mr,null),e(le,ri),e(le,Or),e(Or,ni),f(n,yo,m),f(n,Ne,m),e(Ne,oi),e(Ne,Ka),e(Ka,si),e(Ne,li),f(n,Ao,m),f(n,Y,m),b(bt,Y,null),e(Y,ii),e(Y,ie),e(ie,ci),e(ie,Qa),e(Qa,di),e(ie,mi),e(ie,_t),e(_t,fi),e(ie,hi),e(Y,pi),e(Y,U),b(vt,U,null),e(U,gi),e(U,Sr),e(Sr,ui),e(U,bi),e(U,D),e(D,_i),e(D,Ir),e(Ir,vi),e(D,Ei),e(D,Nr),e(Nr,ki),e(D,Ti),e(D,Pr),e(Pr,$i),e(D,Ci),e(D,Fr),e(Fr,wi),e(D,yi),e(D,Wr),e(Wr,Ai),e(D,Li),e(D,jr),e(jr,Di),e(D,xi),e(D,zr),e(zr,Mi),e(D,Oi),e(D,Rr),e(Rr,Si),e(D,Ii),e(D,Br),e(Br,Ni),e(D,Pi),e(U,Fi),e(U,Et),e(Et,Wi),e(Et,kt),e(kt,ji),e(Et,zi),f(n,Lo,m),f(n,ce,m),b(Tt,ce,null),e(ce,Ri),e(ce,$t),e($t,Bi),e($t,Za),e(Za,Vi),e($t,Ui),f(n,Do,m),f(n,de,m),b(Ct,de,null),e(de,qi),e(de,wt),e(wt,Gi),e(wt,er),e(er,Hi),e(wt,Ji),f(n,xo,m),f(n,me,m),b(yt,me,null),e(me,Yi),e(me,At),e(At,Xi),e(At,tr),e(tr,Ki),e(At,Qi),f(n,Mo,m),f(n,X,m),b(Lt,X,null),e(X,Zi),e(X,Dt),e(Dt,ec),e(Dt,ar),e(ar,tc),e(Dt,ac),e(X,rc),e(X,K),e(K,nc),e(K,rr),e(rr,oc),e(K,sc),e(K,Vr),e(Vr,lc),e(K,ic),e(K,nr),e(nr,cc),e(K,dc),f(n,Oo,m),f(n,fe,m),b(xt,fe,null),e(fe,mc),e(fe,he),e(he,fc),e(he,or),e(or,hc),e(he,pc),e(he,Mt),e(Mt,gc),e(he,uc),f(n,So,m),f(n,Q,m),b(Ot,Q,null),e(Q,bc),e(Q,pe),e(pe,_c),e(pe,sr),e(sr,vc),e(pe,Ec),e(pe,St),e(St,kc),e(pe,Tc),e(Q,$c),e(Q,q),b(It,q,null),e(q,Cc),e(q,Nt),e(Nt,wc),e(Nt,Ur),e(Ur,yc),e(Nt,Ac),e(q,Lc),e(q,Pt),e(Pt,Dc),e(Pt,Ft),e(Ft,xc),e(Pt,Mc),e(q,Oc),e(q,h),e(h,Sc),e(h,qr),e(qr,Ic),e(h,Nc),e(h,Gr),e(Gr,Pc),e(h,Fc),e(h,Hr),e(Hr,Wc),e(h,jc),e(h,Jr),e(Jr,zc),e(h,Rc),e(h,Yr),e(Yr,Bc),e(h,Vc),e(h,Xr),e(Xr,Uc),e(h,qc),e(h,Kr),e(Kr,Gc),e(h,Hc),e(h,Qr),e(Qr,Jc),e(h,Yc),e(h,Zr),e(Zr,Xc),e(h,Kc),e(h,en),e(en,Qc),e(h,Zc),e(h,tn),e(tn,ed),e(h,td),e(h,an),e(an,ad),e(h,rd),e(h,rn),e(rn,nd),e(h,od),e(h,nn),e(nn,sd),e(h,ld),e(h,on),e(on,id),e(h,cd),e(h,sn),e(sn,dd),e(h,md),e(h,ln),e(ln,fd),e(h,hd),e(h,cn),e(cn,pd),e(h,gd),e(h,dn),e(dn,ud),e(h,bd),f(n,Io,m),f(n,Z,m),b(Wt,Z,null),e(Z,_d),e(Z,ee),e(ee,vd),e(ee,lr),e(lr,Ed),e(ee,kd),e(ee,jt),e(jt,Td),e(ee,$d),e(ee,mn),e(mn,Cd),e(ee,wd),e(Z,yd),e(Z,re),b(zt,re,null),e(re,Ad),e(re,fn),e(fn,Ld),e(re,Dd),e(re,p),e(p,xd),e(p,hn),e(hn,Md),e(p,Od),e(p,pn),e(pn,Sd),e(p,Id),e(p,gn),e(gn,Nd),e(p,Pd),e(p,un),e(un,Fd),e(p,Wd),e(p,ir),e(ir,jd),e(p,zd),e(p,bn),e(bn,Rd),e(p,Bd),e(p,_n),e(_n,Vd),e(p,Ud),e(p,vn),e(vn,qd),e(p,Gd),e(p,En),e(En,Hd),e(p,Jd),e(p,kn),e(kn,Yd),e(p,Xd),e(p,Tn),e(Tn,Kd),e(p,Qd),e(p,$n),e($n,Zd),e(p,em),e(p,Cn),e(Cn,tm),e(p,am),e(p,wn),e(wn,rm),e(p,nm),e(p,yn),e(yn,om),e(p,sm),e(p,An),e(An,lm),e(p,im),e(p,Ln),e(Ln,cm),e(p,dm),e(p,Dn),e(Dn,mm),e(p,fm),e(p,xn),e(xn,hm),e(p,pm),f(n,No,m),f(n,ge,m),b(Rt,ge,null),e(ge,gm),e(ge,ue),e(ue,um),e(ue,cr),e(cr,bm),e(ue,_m),e(ue,Bt),e(Bt,vm),e(ue,Em),f(n,Po,m),f(n,be,m),b(Vt,be,null),e(be,km),e(be,Ut),e(Ut,Tm),e(Ut,dr),e(dr,$m),e(Ut,Cm),f(n,Fo,m),f(n,_e,m),b(qt,_e,null),e(_e,wm),e(_e,Gt),e(Gt,ym),e(Gt,Ht),e(Ht,Am),e(Gt,Lm),f(n,Wo,m),f(n,te,m),b(Jt,te,null),e(te,Dm),e(te,ve),e(ve,xm),e(ve,mr),e(mr,Mm),e(ve,Om),e(ve,Yt),e(Yt,Sm),e(ve,Im),e(te,Nm),e(te,I),e(I,Pm),e(I,Mn),e(Mn,Fm),e(I,Wm),e(I,On),e(On,jm),e(I,zm),e(I,Sn),e(Sn,Rm),e(I,Bm),e(I,In),e(In,Vm),e(I,Um),e(I,Nn),e(Nn,qm),e(I,Gm),e(I,Pn),e(Pn,Hm),e(I,Jm),f(n,jo,m),f(n,Ee,m),e(Ee,Pe),e(Pe,Fn),b(Xt,Fn,null),e(Ee,Ym),e(Ee,Wn),e(Wn,Xm),f(n,zo,m),f(n,k,m),b(Kt,k,null),e(k,Km),e(k,jn),e(jn,Qm),e(k,Zm),e(k,Qt),e(Qt,ef),e(Qt,zn),e(zn,tf),e(Qt,af),e(k,rf),e(k,P),e(P,nf),e(P,Rn),e(Rn,of),e(P,sf),e(P,Bn),e(Bn,lf),e(P,cf),e(P,Vn),e(Vn,df),e(P,mf),e(P,Un),e(Un,ff),e(P,hf),e(P,qn),e(qn,pf),e(P,gf),e(k,uf),b(Fe,k,null),e(k,bf),e(k,We),b(Zt,We,null),e(We,_f),e(We,Gn),e(Gn,vf),e(k,Ef),e(k,je),b(ea,je,null),e(je,kf),e(je,Hn),e(Hn,Tf),e(k,$f),e(k,ze),b(ta,ze,null),e(ze,Cf),e(ze,Jn),e(Jn,wf),e(k,yf),e(k,Re),b(aa,Re,null),e(Re,Af),e(Re,ra),e(ra,Lf),e(ra,fr),e(fr,Df),e(ra,xf),e(k,Mf),e(k,Be),b(na,Be,null),e(Be,Of),e(Be,Yn),e(Yn,Sf),e(k,If),e(k,Ve),b(oa,Ve,null),e(Ve,Nf),e(Ve,Xn),e(Xn,Pf),e(k,Ff),e(k,Ue),b(sa,Ue,null),e(Ue,Wf),e(Ue,Kn),e(Kn,jf),e(k,zf),e(k,qe),b(la,qe,null),e(qe,Rf),e(qe,Qn),e(Qn,Bf),e(k,Vf),e(k,Ge),b(ia,Ge,null),e(Ge,Uf),e(Ge,Zn),e(Zn,qf),e(k,Gf),e(k,He),b(ca,He,null),e(He,Hf),e(He,eo),e(eo,Jf),e(k,Yf),e(k,Je),b(da,Je,null),e(Je,Xf),e(Je,to),e(to,Kf),e(k,Qf),e(k,Ye),b(ma,Ye,null),e(Ye,Zf),e(Ye,ao),e(ao,eh),e(k,th),e(k,Xe),b(fa,Xe,null),e(Xe,ah),e(Xe,ro),e(ro,rh),f(n,Ro,m),f(n,Ke,m),e(Ke,nh),e(Ke,hr),e(hr,oh),e(Ke,sh),f(n,Bo,m),b(ha,n,m),f(n,Vo,m),f(n,Qe,m),e(Qe,lh),e(Qe,no),e(no,ih),e(Qe,ch),f(n,Uo,m),b(pa,n,m),f(n,qo,m),f(n,ke,m),e(ke,Ze),e(Ze,oo),b(ga,oo,null),e(ke,dh),e(ke,so),e(so,mh),f(n,Go,m),f(n,F,m),b(ua,F,null),e(F,fh),e(F,Te),e(Te,hh),e(Te,pr),e(pr,ph),e(Te,gh),e(Te,gr),e(gr,uh),e(Te,bh),e(F,_h),b(et,F,null),e(F,vh),e(F,tt),b(ba,tt,null),e(tt,Eh),e(tt,_a),e(_a,kh),e(_a,lo),e(lo,Th),e(_a,$h),e(F,Ch),e(F,at),b(va,at,null),e(at,wh),e(at,Ea),e(Ea,yh),e(Ea,io),e(io,Ah),e(Ea,Lh),f(n,Ho,m),f(n,$e,m),e($e,rt),e(rt,co),b(ka,co,null),e($e,Dh),e($e,mo),e(mo,xh),f(n,Jo,m),f(n,Ce,m),b(Ta,Ce,null),e(Ce,Mh),e(Ce,we),e(we,Oh),e(we,ur),e(ur,Sh),e(we,Ih),e(we,br),e(br,Nh),e(we,Ph),Yo=!0},p(n,[m]){const $a={};m&2&&($a.$$scope={dirty:m,ctx:n}),Fe.$set($a);const fo={};m&2&&(fo.$$scope={dirty:m,ctx:n}),et.$set(fo)},i(n){Yo||(_(y.$$.fragment,n),_(ut.$$.fragment,n),_(bt.$$.fragment,n),_(vt.$$.fragment,n),_(Tt.$$.fragment,n),_(Ct.$$.fragment,n),_(yt.$$.fragment,n),_(Lt.$$.fragment,n),_(xt.$$.fragment,n),_(Ot.$$.fragment,n),_(It.$$.fragment,n),_(Wt.$$.fragment,n),_(zt.$$.fragment,n),_(Rt.$$.fragment,n),_(Vt.$$.fragment,n),_(qt.$$.fragment,n),_(Jt.$$.fragment,n),_(Xt.$$.fragment,n),_(Kt.$$.fragment,n),_(Fe.$$.fragment,n),_(Zt.$$.fragment,n),_(ea.$$.fragment,n),_(ta.$$.fragment,n),_(aa.$$.fragment,n),_(na.$$.fragment,n),_(oa.$$.fragment,n),_(sa.$$.fragment,n),_(la.$$.fragment,n),_(ia.$$.fragment,n),_(ca.$$.fragment,n),_(da.$$.fragment,n),_(ma.$$.fragment,n),_(fa.$$.fragment,n),_(ha.$$.fragment,n),_(pa.$$.fragment,n),_(ga.$$.fragment,n),_(ua.$$.fragment,n),_(et.$$.fragment,n),_(ba.$$.fragment,n),_(va.$$.fragment,n),_(ka.$$.fragment,n),_(Ta.$$.fragment,n),Yo=!0)},o(n){v(y.$$.fragment,n),v(ut.$$.fragment,n),v(bt.$$.fragment,n),v(vt.$$.fragment,n),v(Tt.$$.fragment,n),v(Ct.$$.fragment,n),v(yt.$$.fragment,n),v(Lt.$$.fragment,n),v(xt.$$.fragment,n),v(Ot.$$.fragment,n),v(It.$$.fragment,n),v(Wt.$$.fragment,n),v(zt.$$.fragment,n),v(Rt.$$.fragment,n),v(Vt.$$.fragment,n),v(qt.$$.fragment,n),v(Jt.$$.fragment,n),v(Xt.$$.fragment,n),v(Kt.$$.fragment,n),v(Fe.$$.fragment,n),v(Zt.$$.fragment,n),v(ea.$$.fragment,n),v(ta.$$.fragment,n),v(aa.$$.fragment,n),v(na.$$.fragment,n),v(oa.$$.fragment,n),v(sa.$$.fragment,n),v(la.$$.fragment,n),v(ia.$$.fragment,n),v(ca.$$.fragment,n),v(da.$$.fragment,n),v(ma.$$.fragment,n),v(fa.$$.fragment,n),v(ha.$$.fragment,n),v(pa.$$.fragment,n),v(ga.$$.fragment,n),v(ua.$$.fragment,n),v(et.$$.fragment,n),v(ba.$$.fragment,n),v(va.$$.fragment,n),v(ka.$$.fragment,n),v(Ta.$$.fragment,n),Yo=!1},d(n){r(A),n&&r(B),n&&r(x),E(y),n&&r(R),n&&r(J),n&&r(ko),n&&r(V),n&&r(To),n&&r(ye),n&&r($o),n&&r(L),n&&r(Co),n&&r(N),n&&r(wo),n&&r(le),E(ut),n&&r(yo),n&&r(Ne),n&&r(Ao),n&&r(Y),E(bt),E(vt),n&&r(Lo),n&&r(ce),E(Tt),n&&r(Do),n&&r(de),E(Ct),n&&r(xo),n&&r(me),E(yt),n&&r(Mo),n&&r(X),E(Lt),n&&r(Oo),n&&r(fe),E(xt),n&&r(So),n&&r(Q),E(Ot),E(It),n&&r(Io),n&&r(Z),E(Wt),E(zt),n&&r(No),n&&r(ge),E(Rt),n&&r(Po),n&&r(be),E(Vt),n&&r(Fo),n&&r(_e),E(qt),n&&r(Wo),n&&r(te),E(Jt),n&&r(jo),n&&r(Ee),E(Xt),n&&r(zo),n&&r(k),E(Kt),E(Fe),E(Zt),E(ea),E(ta),E(aa),E(na),E(oa),E(sa),E(la),E(ia),E(ca),E(da),E(ma),E(fa),n&&r(Ro),n&&r(Ke),n&&r(Bo),E(ha,n),n&&r(Vo),n&&r(Qe),n&&r(Uo),E(pa,n),n&&r(qo),n&&r(ke),E(ga),n&&r(Go),n&&r(F),E(ua),E(et),E(ba),E(va),n&&r(Ho),n&&r($e),E(ka),n&&r(Jo),n&&r(Ce),E(Ta)}}}const Ru={local:"callbacks",sections:[{local:"transformers.integrations.CometCallback",title:"Available Callbacks"},{local:"transformers.TrainerCallback",title:"TrainerCallback"},{local:"transformers.TrainerState",title:"TrainerState"},{local:"transformers.TrainerControl",title:"TrainerControl"}],title:"Callbacks"};function Bu(wa){return Iu(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Yu extends xu{constructor(A){super();Mu(this,A,Bu,zu,Ou,{})}}export{Yu as default,Ru as metadata};
