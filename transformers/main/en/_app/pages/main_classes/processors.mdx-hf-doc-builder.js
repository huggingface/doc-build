import{S as cp,i as mp,s as fp,e as s,k as i,w as g,t as n,M as hp,c as a,d as r,m as d,a as o,x as v,h as l,b as m,G as t,g as c,y as $,q as b,o as x,B as E,v as up,L as vi}from"../../chunks/vendor-hf-doc-builder.js";import{T as _i}from"../../chunks/Tip-hf-doc-builder.js";import{D as I}from"../../chunks/Docstring-hf-doc-builder.js";import{C as As}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as Oe}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as gi}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function _p(M){let h,y,_,u,P,f,w,z;return{c(){h=s("p"),y=n(`This class method is simply calling the feature extractor
`),_=s("a"),u=n("from_pretrained()"),P=n(` and the tokenizer
`),f=s("code"),w=n("from_pretrained"),z=n(` methods. Please refer to the docstrings of the
methods above for more information.`),this.h()},l(T){h=a(T,"P",{});var q=o(h);y=l(q,`This class method is simply calling the feature extractor
`),_=a(q,"A",{href:!0});var C=o(_);u=l(C,"from_pretrained()"),C.forEach(r),P=l(q,` and the tokenizer
`),f=a(q,"CODE",{});var K=o(f);w=l(K,"from_pretrained"),K.forEach(r),z=l(q,` methods. Please refer to the docstrings of the
methods above for more information.`),q.forEach(r),this.h()},h(){m(_,"href","/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained")},m(T,q){c(T,h,q),t(h,y),t(h,_),t(_,u),t(h,P),t(h,f),t(f,w),t(h,z)},d(T){T&&r(h)}}}function gp(M){let h,y,_,u,P;return u=new As({props:{code:`from transformers import AutoProcessor

processor = AutoProcessor.from_pretrained("bert-base-cased")

# Push the processor to your namespace with the name "my-finetuned-bert".
processor.push_to_hub("my-finetuned-bert")

# Push the processor to an organization with the name "my-finetuned-bert".
processor.push_to_hub("huggingface/my-finetuned-bert")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-comment"># Push the processor to your namespace with the name &quot;my-finetuned-bert&quot;.</span>
processor.push_to_hub(<span class="hljs-string">&quot;my-finetuned-bert&quot;</span>)

<span class="hljs-comment"># Push the processor to an organization with the name &quot;my-finetuned-bert&quot;.</span>
processor.push_to_hub(<span class="hljs-string">&quot;huggingface/my-finetuned-bert&quot;</span>)`}}),{c(){h=s("p"),y=n("Examples:"),_=i(),g(u.$$.fragment)},l(f){h=a(f,"P",{});var w=o(h);y=l(w,"Examples:"),w.forEach(r),_=d(f),v(u.$$.fragment,f)},m(f,w){c(f,h,w),t(h,y),c(f,_,w),$(u,f,w),P=!0},p:vi,i(f){P||(b(u.$$.fragment,f),P=!0)},o(f){x(u.$$.fragment,f),P=!1},d(f){f&&r(h),f&&r(_),E(u,f)}}}function vp(M){let h,y;return{c(){h=s("p"),y=n("This API is experimental and may have some slight breaking changes in the next releases.")},l(_){h=a(_,"P",{});var u=o(h);y=l(u,"This API is experimental and may have some slight breaking changes in the next releases."),u.forEach(r)},m(_,u){c(_,h,u),t(h,y)},d(_){_&&r(h)}}}function $p(M){let h,y,_,u,P,f,w,z;return{c(){h=s("p"),y=n("This class method is simply calling "),_=s("a"),u=n("save_pretrained()"),P=n(` and
`),f=s("code"),w=n("save_pretrained"),z=n(`. Please refer to the docstrings of the methods
above for more information.`),this.h()},l(T){h=a(T,"P",{});var q=o(h);y=l(q,"This class method is simply calling "),_=a(q,"A",{href:!0});var C=o(_);u=l(C,"save_pretrained()"),C.forEach(r),P=l(q,` and
`),f=a(q,"CODE",{});var K=o(f);w=l(K,"save_pretrained"),K.forEach(r),z=l(q,`. Please refer to the docstrings of the methods
above for more information.`),q.forEach(r),this.h()},h(){m(_,"href","/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained")},m(T,q){c(T,h,q),t(h,y),t(h,_),t(_,u),t(h,P),t(h,f),t(f,w),t(h,z)},d(T){T&&r(h)}}}function bp(M){let h,y,_,u,P;return u=new As({props:{code:`import tensorflow_datasets as tfds

dataset = tfds.load("squad")

training_examples = get_examples_from_dataset(dataset, evaluate=False)
evaluation_examples = get_examples_from_dataset(dataset, evaluate=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow_datasets <span class="hljs-keyword">as</span> tfds

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = tfds.load(<span class="hljs-string">&quot;squad&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>training_examples = get_examples_from_dataset(dataset, evaluate=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>evaluation_examples = get_examples_from_dataset(dataset, evaluate=<span class="hljs-literal">True</span>)`}}),{c(){h=s("p"),y=n("Examples:"),_=i(),g(u.$$.fragment)},l(f){h=a(f,"P",{});var w=o(h);y=l(w,"Examples:"),w.forEach(r),_=d(f),v(u.$$.fragment,f)},m(f,w){c(f,h,w),t(h,y),c(f,_,w),$(u,f,w),P=!0},p:vi,i(f){P||(b(u.$$.fragment,f),P=!0)},o(f){x(u.$$.fragment,f),P=!1},d(f){f&&r(h),f&&r(_),E(u,f)}}}function xp(M){let h,y,_,u,P;return u=new As({props:{code:`processor = SquadV2Processor()
examples = processor.get_dev_examples(data_dir)

features = squad_convert_examples_to_features(
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=args.max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=args.max_query_length,
    is_training=not evaluate,
)`,highlighted:`processor = SquadV2Processor()
examples = processor.get_dev_examples(data_dir)

features = squad_convert_examples_to_features(
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=args.max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=args.max_query_length,
    is_training=<span class="hljs-keyword">not</span> evaluate,
)`}}),{c(){h=s("p"),y=n("Example:"),_=i(),g(u.$$.fragment)},l(f){h=a(f,"P",{});var w=o(h);y=l(w,"Example:"),w.forEach(r),_=d(f),v(u.$$.fragment,f)},m(f,w){c(f,h,w),t(h,y),c(f,_,w),$(u,f,w),P=!0},p:vi,i(f){P||(b(u.$$.fragment,f),P=!0)},o(f){x(u.$$.fragment,f),P=!1},d(f){f&&r(h),f&&r(_),E(u,f)}}}function Ep(M){let h,y,_,u,P,f,w,z,T,q,C,K,Ls,ie,Y,Ya,Ot,Za,eo,Qt,to,ro,so,gr,ao,Ds,Z,de,vr,Qe,oo,$r,no,Ts,Ut,lo,Ns,Ft,io,Ms,L,Ue,po,br,co,mo,G,Fe,fo,xr,ho,uo,pe,_o,R,Ge,go,Re,vo,Er,$o,bo,xo,ce,Eo,H,He,wo,We,yo,wr,Po,qo,ko,me,Io,W,Xe,So,Be,Ao,Gt,Lo,Do,To,fe,Vs,ee,he,yr,Je,No,Pr,Mo,zs,V,Vo,Rt,zo,Co,Ht,jo,Oo,Wt,Qo,Uo,Xt,Fo,Go,Cs,S,Ke,Ro,qr,Ho,Wo,ue,Ye,Xo,Ze,Bo,Bt,Jo,Ko,Yo,_e,et,Zo,kr,en,tn,ge,tt,rn,Ir,sn,an,ve,rt,on,st,nn,Jt,ln,dn,pn,$e,at,cn,ot,mn,Kt,fn,hn,un,be,nt,_n,Sr,gn,js,O,lt,vn,Ar,$n,bn,xe,it,xn,Lr,En,Os,Q,dt,wn,Dr,yn,Pn,Ee,pt,qn,Tr,kn,Qs,te,we,Nr,ct,In,Mr,Sn,Us,ye,mt,An,Ln,ft,Dn,Fs,Yt,Tn,Gs,Zt,Nn,Rs,k,Vr,zr,Mn,Vn,Cr,jr,zn,Cn,Or,Qr,jn,On,Ur,Fr,Qn,Un,Gr,Rr,Fn,Gn,Hr,Wr,Rn,Hn,Xr,Br,Wn,Xn,Jr,Kr,Bn,Jn,Yr,Zr,Kn,Hs,Pe,Yn,er,Zn,el,Ws,re,ht,tl,tr,rl,es,sl,Xs,se,qe,ts,ut,al,rs,ol,Bs,ae,_t,nl,ll,gt,ss,il,dl,Js,vt,pl,$t,cl,Ks,rr,ml,Ys,sr,as,os,fl,Zs,ar,hl,ea,ke,ul,bt,_l,gl,ta,oe,Ie,ns,xt,vl,ls,$l,ra,U,Et,bl,xl,wt,El,wl,yt,yl,Pl,sa,or,ql,aa,ne,Se,is,Pt,kl,ds,Il,oa,nr,Sl,na,Ae,ps,cs,Al,Ll,ms,fs,Dl,la,qt,Tl,hs,Nl,ia,N,kt,Ml,us,Vl,zl,Le,It,Cl,_s,jl,Ol,X,St,Ql,At,Ul,gs,Fl,Gl,Rl,De,Hl,Te,Lt,Wl,vs,Xl,da,Ne,Bl,$s,Jl,Kl,pa,F,Dt,Yl,bs,Zl,ei,Me,ca,Ve,ti,xs,ri,si,ma,le,ze,Es,Tt,ai,ws,oi,fa,lr,ni,ha,Nt,ua,Ce,li,ys,ii,di,_a,Mt,ga,je,pi,Vt,ci,mi,va;return f=new Oe({}),Qe=new Oe({}),Ue=new I({props:{name:"class transformers.ProcessorMixin",anchor:"transformers.ProcessorMixin",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/processing_utils.py#L43"}}),Fe=new I({props:{name:"from_pretrained",anchor:"transformers.ProcessorMixin.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.ProcessorMixin.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.
**kwargs &#x2014;
Additional keyword arguments passed along to both
<a href="/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.from_pretrained">from_pretrained()</a> and
<code>from_pretrained</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/processing_utils.py#L152"}}),pe=new _i({props:{$$slots:{default:[_p]},$$scope:{ctx:M}}}),Ge=new I({props:{name:"push_to_hub",anchor:"transformers.ProcessorMixin.push_to_hub",parameters:[{name:"repo_id",val:": str"},{name:"use_temp_dir",val:": typing.Optional[bool] = None"},{name:"commit_message",val:": typing.Optional[str] = None"},{name:"private",val:": typing.Optional[bool] = None"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = None"},{name:"max_shard_size",val:": typing.Union[int, str, NoneType] = '10GB'"},{name:"create_pr",val:": bool = False"},{name:"**deprecated_kwargs",val:""}],parametersDescription:[{anchor:"transformers.ProcessorMixin.push_to_hub.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
The name of the repository you want to push your processor to. It should contain your organization name
when pushing to a given organization.`,name:"repo_id"},{anchor:"transformers.ProcessorMixin.push_to_hub.use_temp_dir",description:`<strong>use_temp_dir</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to use a temporary directory to store the files saved before they are pushed to the Hub.
Will default to <code>True</code> if there is no directory named like <code>repo_id</code>, <code>False</code> otherwise.`,name:"use_temp_dir"},{anchor:"transformers.ProcessorMixin.push_to_hub.commit_message",description:`<strong>commit_message</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Message to commit while pushing. Will default to <code>&quot;Upload processor&quot;</code>.`,name:"commit_message"},{anchor:"transformers.ProcessorMixin.push_to_hub.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not the repository created should be private (requires a paying subscription).`,name:"private"},{anchor:"transformers.ProcessorMixin.push_to_hub.use_auth_token",description:`<strong>use_auth_token</strong> (<code>bool</code> or <code>str</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>). Will default to <code>True</code> if <code>repo_url</code>
is not specified.`,name:"use_auth_token"},{anchor:"transformers.ProcessorMixin.push_to_hub.max_shard_size",description:`<strong>max_shard_size</strong> (<code>int</code> or <code>str</code>, <em>optional</em>, defaults to <code>&quot;10GB&quot;</code>) &#x2014;
Only applicable for models. The maximum size for a checkpoint before being sharded. Checkpoints shard
will then be each of size lower than this size. If expressed as a string, needs to be digits followed
by a unit (like <code>&quot;5MB&quot;</code>).`,name:"max_shard_size"},{anchor:"transformers.ProcessorMixin.push_to_hub.create_pr",description:`<strong>create_pr</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to create a PR with the uploaded files or directly commit.`,name:"create_pr"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/utils/hub.py#L711"}}),ce=new gi({props:{anchor:"transformers.ProcessorMixin.push_to_hub.example",$$slots:{default:[gp]},$$scope:{ctx:M}}}),He=new I({props:{name:"register_for_auto_class",anchor:"transformers.ProcessorMixin.register_for_auto_class",parameters:[{name:"auto_class",val:" = 'AutoProcessor'"}],parametersDescription:[{anchor:"transformers.ProcessorMixin.register_for_auto_class.auto_class",description:`<strong>auto_class</strong> (<code>str</code> or <code>type</code>, <em>optional</em>, defaults to <code>&quot;AutoProcessor&quot;</code>) &#x2014;
The auto class to register this new feature extractor with.`,name:"auto_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/processing_utils.py#L185"}}),me=new _i({props:{warning:!0,$$slots:{default:[vp]},$$scope:{ctx:M}}}),Xe=new I({props:{name:"save_pretrained",anchor:"transformers.ProcessorMixin.save_pretrained",parameters:[{name:"save_directory",val:""},{name:"push_to_hub",val:": bool = False"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.ProcessorMixin.save_pretrained.save_directory",description:`<strong>save_directory</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Directory where the feature extractor JSON file and the tokenizer files will be saved (directory will
be created if it does not exist).`,name:"save_directory"},{anchor:"transformers.ProcessorMixin.save_pretrained.push_to_hub",description:`<strong>push_to_hub</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to push your model to the Hugging Face model hub after saving it. You can specify the
repository you want to push to with <code>repo_id</code> (will default to the name of <code>save_directory</code> in your
namespace).
kwargs &#x2014;
Additional key word arguments passed along to the <a href="/docs/transformers/main/en/main_classes/processors#transformers.ProcessorMixin.push_to_hub">push_to_hub()</a> method.`,name:"push_to_hub"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/processing_utils.py#L94"}}),fe=new _i({props:{$$slots:{default:[$p]},$$scope:{ctx:M}}}),Je=new Oe({}),Ke=new I({props:{name:"class transformers.DataProcessor",anchor:"transformers.DataProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/data/processors/utils.py#L80"}}),Ye=new I({props:{name:"get_dev_examples",anchor:"transformers.DataProcessor.get_dev_examples",parameters:[{name:"data_dir",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/data/processors/utils.py#L97"}}),et=new I({props:{name:"get_example_from_tensor_dict",anchor:"transformers.DataProcessor.get_example_from_tensor_dict",parameters:[{name:"tensor_dict",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/data/processors/utils.py#L83"}}),tt=new I({props:{name:"get_labels",anchor:"transformers.DataProcessor.get_labels",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/data/processors/utils.py#L105"}}),rt=new I({props:{name:"get_test_examples",anchor:"transformers.DataProcessor.get_test_examples",parameters:[{name:"data_dir",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/data/processors/utils.py#L101"}}),at=new I({props:{name:"get_train_examples",anchor:"transformers.DataProcessor.get_train_examples",parameters:[{name:"data_dir",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/data/processors/utils.py#L93"}}),nt=new I({props:{name:"tfds_map",anchor:"transformers.DataProcessor.tfds_map",parameters:[{name:"example",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/data/processors/utils.py#L109"}}),lt=new I({props:{name:"class transformers.InputExample",anchor:"transformers.InputExample",parameters:[{name:"guid",val:": str"},{name:"text_a",val:": str"},{name:"text_b",val:": typing.Optional[str] = None"},{name:"label",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/data/processors/utils.py#L30"}}),it=new I({props:{name:"to_json_string",anchor:"transformers.InputExample.to_json_string",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/data/processors/utils.py#L49"}}),dt=new I({props:{name:"class transformers.InputFeatures",anchor:"transformers.InputFeatures",parameters:[{name:"input_ids",val:": typing.List[int]"},{name:"attention_mask",val:": typing.Optional[typing.List[int]] = None"},{name:"token_type_ids",val:": typing.Optional[typing.List[int]] = None"},{name:"label",val:": typing.Union[int, float, NoneType] = None"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/data/processors/utils.py#L55"}}),pt=new I({props:{name:"to_json_string",anchor:"transformers.InputFeatures.to_json_string",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/data/processors/utils.py#L75"}}),ct=new Oe({}),ht=new I({props:{name:"transformers.glue_convert_examples_to_features",anchor:"transformers.glue_convert_examples_to_features",parameters:[{name:"examples",val:": typing.Union[typing.List[transformers.data.processors.utils.InputExample], ForwardRef('tf.data.Dataset')]"},{name:"tokenizer",val:": PreTrainedTokenizer"},{name:"max_length",val:": typing.Optional[int] = None"},{name:"task",val:" = None"},{name:"label_list",val:" = None"},{name:"output_mode",val:" = None"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/data/processors/glue.py#L41",returnDescription:`
<p>If the <code>examples</code> input is a <code>tf.data.Dataset</code>, will return a <code>tf.data.Dataset</code> containing the task-specific
features. If the input is a list of <code>InputExamples</code>, will return a list of task-specific <code>InputFeatures</code> which
can be fed to the model.</p>
`}}),ut=new Oe({}),xt=new Oe({}),Pt=new Oe({}),kt=new I({props:{name:"class transformers.data.processors.squad.SquadProcessor",anchor:"transformers.data.processors.squad.SquadProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/data/processors/squad.py#L542"}}),It=new I({props:{name:"get_dev_examples",anchor:"transformers.data.processors.squad.SquadProcessor.get_dev_examples",parameters:[{name:"data_dir",val:""},{name:"filename",val:" = None"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/data/processors/squad.py#L630"}}),St=new I({props:{name:"get_examples_from_dataset",anchor:"transformers.data.processors.squad.SquadProcessor.get_examples_from_dataset",parameters:[{name:"dataset",val:""},{name:"evaluate",val:" = False"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/data/processors/squad.py#L575",returnDescription:`
<p>List of SquadExample</p>
`}}),De=new gi({props:{anchor:"transformers.data.processors.squad.SquadProcessor.get_examples_from_dataset.example",$$slots:{default:[bp]},$$scope:{ctx:M}}}),Lt=new I({props:{name:"get_train_examples",anchor:"transformers.data.processors.squad.SquadProcessor.get_train_examples",parameters:[{name:"data_dir",val:""},{name:"filename",val:" = None"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/data/processors/squad.py#L608"}}),Dt=new I({props:{name:"transformers.squad_convert_examples_to_features",anchor:"transformers.squad_convert_examples_to_features",parameters:[{name:"examples",val:""},{name:"tokenizer",val:""},{name:"max_seq_length",val:""},{name:"doc_stride",val:""},{name:"max_query_length",val:""},{name:"is_training",val:""},{name:"padding_strategy",val:" = 'max_length'"},{name:"return_dataset",val:" = False"},{name:"threads",val:" = 1"},{name:"tqdm_enabled",val:" = True"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/data/processors/squad.py#L317",returnDescription:`
<p>list of <code>SquadFeatures</code></p>
`}}),Me=new gi({props:{anchor:"transformers.squad_convert_examples_to_features.example",$$slots:{default:[xp]},$$scope:{ctx:M}}}),Tt=new Oe({}),Nt=new As({props:{code:`# Loading a V2 processor
processor = SquadV2Processor()
examples = processor.get_dev_examples(squad_v2_data_dir)

# Loading a V1 processor
processor = SquadV1Processor()
examples = processor.get_dev_examples(squad_v1_data_dir)

features = squad_convert_examples_to_features(
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=max_query_length,
    is_training=not evaluate,
)`,highlighted:`<span class="hljs-comment"># Loading a V2 processor</span>
processor = SquadV2Processor()
examples = processor.get_dev_examples(squad_v2_data_dir)

<span class="hljs-comment"># Loading a V1 processor</span>
processor = SquadV1Processor()
examples = processor.get_dev_examples(squad_v1_data_dir)

features = squad_convert_examples_to_features(
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=max_query_length,
    is_training=<span class="hljs-keyword">not</span> evaluate,
)`}}),Mt=new As({props:{code:`# tensorflow_datasets only handle Squad V1.
tfds_examples = tfds.load("squad")
examples = SquadV1Processor().get_examples_from_dataset(tfds_examples, evaluate=evaluate)

features = squad_convert_examples_to_features(
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=max_query_length,
    is_training=not evaluate,
)`,highlighted:`<span class="hljs-comment"># tensorflow_datasets only handle Squad V1.</span>
tfds_examples = tfds.load(<span class="hljs-string">&quot;squad&quot;</span>)
examples = SquadV1Processor().get_examples_from_dataset(tfds_examples, evaluate=evaluate)

features = squad_convert_examples_to_features(
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=max_query_length,
    is_training=<span class="hljs-keyword">not</span> evaluate,
)`}}),{c(){h=s("meta"),y=i(),_=s("h1"),u=s("a"),P=s("span"),g(f.$$.fragment),w=i(),z=s("span"),T=n("Processors"),q=i(),C=s("p"),K=n("Processors can mean two different things in the Transformers library:"),Ls=i(),ie=s("ul"),Y=s("li"),Ya=n("the objects that pre-process inputs for multi-modal models such as "),Ot=s("a"),Za=n("Wav2Vec2"),eo=n(` (speech and text)
or `),Qt=s("a"),to=n("CLIP"),ro=n(" (text and vision)"),so=i(),gr=s("li"),ao=n("deprecated objects that were used in older versions of the library to preprocess data for GLUE or SQUAD."),Ds=i(),Z=s("h2"),de=s("a"),vr=s("span"),g(Qe.$$.fragment),oo=i(),$r=s("span"),no=n("Multi-modal processors"),Ts=i(),Ut=s("p"),lo=n(`Any multi-modal model will require an object to encode or decode the data that groups several modalities (among text,
vision and audio). This is handled by objects called processors, which group tokenizers (for the text modality) and
feature extractors (for vision and audio).`),Ns=i(),Ft=s("p"),io=n("Those processors inherit from the following base class that implements the saving and loading functionality:"),Ms=i(),L=s("div"),g(Ue.$$.fragment),po=i(),br=s("p"),co=n("This is a mixin used to provide saving/loading functionality for all processor classes."),mo=i(),G=s("div"),g(Fe.$$.fragment),fo=i(),xr=s("p"),ho=n("Instantiate a processor associated with a pretrained model."),uo=i(),g(pe.$$.fragment),_o=i(),R=s("div"),g(Ge.$$.fragment),go=i(),Re=s("p"),vo=n(`Upload the processor files to the \u{1F917} Model Hub while synchronizing a local clone of the repo in
`),Er=s("code"),$o=n("repo_path_or_name"),bo=n("."),xo=i(),g(ce.$$.fragment),Eo=i(),H=s("div"),g(He.$$.fragment),wo=i(),We=s("p"),yo=n(`Register this class with a given auto class. This should only be used for custom feature extractors as the ones
in the library are already mapped with `),wr=s("code"),Po=n("AutoProcessor"),qo=n("."),ko=i(),g(me.$$.fragment),Io=i(),W=s("div"),g(Xe.$$.fragment),So=i(),Be=s("p"),Ao=n(`Saves the attributes of this processor (feature extractor, tokenizer\u2026) in the specified directory so that it
can be reloaded using the `),Gt=s("a"),Lo=n("from_pretrained()"),Do=n(" method."),To=i(),g(fe.$$.fragment),Vs=i(),ee=s("h2"),he=s("a"),yr=s("span"),g(Je.$$.fragment),No=i(),Pr=s("span"),Mo=n("Deprecated processors"),zs=i(),V=s("p"),Vo=n(`All processors follow the same architecture which is that of the
`),Rt=s("a"),zo=n("DataProcessor"),Co=n(`. The processor returns a list of
`),Ht=s("a"),jo=n("InputExample"),Oo=n(`. These
`),Wt=s("a"),Qo=n("InputExample"),Uo=n(` can be converted to
`),Xt=s("a"),Fo=n("InputFeatures"),Go=n(" in order to be fed to the model."),Cs=i(),S=s("div"),g(Ke.$$.fragment),Ro=i(),qr=s("p"),Ho=n("Base class for data converters for sequence classification data sets."),Wo=i(),ue=s("div"),g(Ye.$$.fragment),Xo=i(),Ze=s("p"),Bo=n("Gets a collection of "),Bt=s("a"),Jo=n("InputExample"),Ko=n(" for the dev set."),Yo=i(),_e=s("div"),g(et.$$.fragment),Zo=i(),kr=s("p"),en=n("Gets an example from a dict with tensorflow tensors."),tn=i(),ge=s("div"),g(tt.$$.fragment),rn=i(),Ir=s("p"),sn=n("Gets the list of labels for this data set."),an=i(),ve=s("div"),g(rt.$$.fragment),on=i(),st=s("p"),nn=n("Gets a collection of "),Jt=s("a"),ln=n("InputExample"),dn=n(" for the test set."),pn=i(),$e=s("div"),g(at.$$.fragment),cn=i(),ot=s("p"),mn=n("Gets a collection of "),Kt=s("a"),fn=n("InputExample"),hn=n(" for the train set."),un=i(),be=s("div"),g(nt.$$.fragment),_n=i(),Sr=s("p"),gn=n(`Some tensorflow_datasets datasets are not formatted the same way the GLUE datasets are. This method converts
examples to the correct format.`),js=i(),O=s("div"),g(lt.$$.fragment),vn=i(),Ar=s("p"),$n=n("A single training/test example for simple sequence classification."),bn=i(),xe=s("div"),g(it.$$.fragment),xn=i(),Lr=s("p"),En=n("Serializes this instance to a JSON string."),Os=i(),Q=s("div"),g(dt.$$.fragment),wn=i(),Dr=s("p"),yn=n("A single set of features of data. Property names are the same names as the corresponding inputs to a model."),Pn=i(),Ee=s("div"),g(pt.$$.fragment),qn=i(),Tr=s("p"),kn=n("Serializes this instance to a JSON string."),Qs=i(),te=s("h2"),we=s("a"),Nr=s("span"),g(ct.$$.fragment),In=i(),Mr=s("span"),Sn=n("GLUE"),Us=i(),ye=s("p"),mt=s("a"),An=n("General Language Understanding Evaluation (GLUE)"),Ln=n(` is a benchmark that evaluates the
performance of models across a diverse set of existing NLU tasks. It was released together with the paper `),ft=s("a"),Dn=n(`GLUE: A
multi-task benchmark and analysis platform for natural language understanding`),Fs=i(),Yt=s("p"),Tn=n(`This library hosts a total of 10 processors for the following tasks: MRPC, MNLI, MNLI (mismatched), CoLA, SST2, STSB,
QQP, QNLI, RTE and WNLI.`),Gs=i(),Zt=s("p"),Nn=n("Those processors are:"),Rs=i(),k=s("ul"),Vr=s("li"),zr=s("code"),Mn=n("MrpcProcessor"),Vn=i(),Cr=s("li"),jr=s("code"),zn=n("MnliProcessor"),Cn=i(),Or=s("li"),Qr=s("code"),jn=n("MnliMismatchedProcessor"),On=i(),Ur=s("li"),Fr=s("code"),Qn=n("Sst2Processor"),Un=i(),Gr=s("li"),Rr=s("code"),Fn=n("StsbProcessor"),Gn=i(),Hr=s("li"),Wr=s("code"),Rn=n("QqpProcessor"),Hn=i(),Xr=s("li"),Br=s("code"),Wn=n("QnliProcessor"),Xn=i(),Jr=s("li"),Kr=s("code"),Bn=n("RteProcessor"),Jn=i(),Yr=s("li"),Zr=s("code"),Kn=n("WnliProcessor"),Hs=i(),Pe=s("p"),Yn=n(`Additionally, the following method can be used to load values from a data file and convert them to a list of
`),er=s("a"),Zn=n("InputExample"),el=n("."),Ws=i(),re=s("div"),g(ht.$$.fragment),tl=i(),tr=s("p"),rl=n("Loads a data file into a list of "),es=s("code"),sl=n("InputFeatures"),Xs=i(),se=s("h2"),qe=s("a"),ts=s("span"),g(ut.$$.fragment),al=i(),rs=s("span"),ol=n("XNLI"),Bs=i(),ae=s("p"),_t=s("a"),nl=n("The Cross-Lingual NLI Corpus (XNLI)"),ll=n(` is a benchmark that evaluates the
quality of cross-lingual text representations. XNLI is crowd-sourced dataset based on `),gt=s("a"),ss=s("em"),il=n("MultiNLI"),dl=n(`: pairs of text are labeled with textual entailment annotations for 15
different languages (including both high-resource language such as English and low-resource languages such as Swahili).`),Js=i(),vt=s("p"),pl=n("It was released together with the paper "),$t=s("a"),cl=n("XNLI: Evaluating Cross-lingual Sentence Representations"),Ks=i(),rr=s("p"),ml=n("This library hosts the processor to load the XNLI data:"),Ys=i(),sr=s("ul"),as=s("li"),os=s("code"),fl=n("XnliProcessor"),Zs=i(),ar=s("p"),hl=n("Please note that since the gold labels are available on the test set, evaluation is performed on the test set."),ea=i(),ke=s("p"),ul=n("An example using these processors is given in the "),bt=s("a"),_l=n("run_xnli.py"),gl=n(" script."),ta=i(),oe=s("h2"),Ie=s("a"),ns=s("span"),g(xt.$$.fragment),vl=i(),ls=s("span"),$l=n("SQuAD"),ra=i(),U=s("p"),Et=s("a"),bl=n("The Stanford Question Answering Dataset (SQuAD)"),xl=n(` is a benchmark that
evaluates the performance of models on question answering. Two versions are available, v1.1 and v2.0. The first version
(v1.1) was released together with the paper `),wt=s("a"),El=n("SQuAD: 100,000+ Questions for Machine Comprehension of Text"),wl=n(". The second version (v2.0) was released alongside the paper "),yt=s("a"),yl=n(`Know What You Don\u2019t
Know: Unanswerable Questions for SQuAD`),Pl=n("."),sa=i(),or=s("p"),ql=n("This library hosts a processor for each of the two versions:"),aa=i(),ne=s("h3"),Se=s("a"),is=s("span"),g(Pt.$$.fragment),kl=i(),ds=s("span"),Il=n("Processors"),oa=i(),nr=s("p"),Sl=n("Those processors are:"),na=i(),Ae=s("ul"),ps=s("li"),cs=s("code"),Al=n("SquadV1Processor"),Ll=i(),ms=s("li"),fs=s("code"),Dl=n("SquadV2Processor"),la=i(),qt=s("p"),Tl=n("They both inherit from the abstract class "),hs=s("code"),Nl=n("SquadProcessor"),ia=i(),N=s("div"),g(kt.$$.fragment),Ml=i(),us=s("p"),Vl=n(`Processor for the SQuAD data set. overridden by SquadV1Processor and SquadV2Processor, used by the version 1.1 and
version 2.0 of SQuAD, respectively.`),zl=i(),Le=s("div"),g(It.$$.fragment),Cl=i(),_s=s("p"),jl=n("Returns the evaluation example from the data directory."),Ol=i(),X=s("div"),g(St.$$.fragment),Ql=i(),At=s("p"),Ul=n("Creates a list of "),gs=s("code"),Fl=n("SquadExample"),Gl=n(" using a TFDS dataset."),Rl=i(),g(De.$$.fragment),Hl=i(),Te=s("div"),g(Lt.$$.fragment),Wl=i(),vs=s("p"),Xl=n("Returns the training examples from the data directory."),da=i(),Ne=s("p"),Bl=n(`Additionally, the following method can be used to convert SQuAD examples into
`),$s=s("code"),Jl=n("SquadFeatures"),Kl=n(" that can be used as model inputs."),pa=i(),F=s("div"),g(Dt.$$.fragment),Yl=i(),bs=s("p"),Zl=n(`Converts a list of examples into a list of features that can be directly given as input to a model. It is
model-dependant and takes advantage of many of the tokenizer\u2019s features to create the model\u2019s inputs.`),ei=i(),g(Me.$$.fragment),ca=i(),Ve=s("p"),ti=n(`These processors as well as the aforementionned method can be used with files containing the data as well as with the
`),xs=s("em"),ri=n("tensorflow_datasets"),si=n(" package. Examples are given below."),ma=i(),le=s("h3"),ze=s("a"),Es=s("span"),g(Tt.$$.fragment),ai=i(),ws=s("span"),oi=n("Example usage"),fa=i(),lr=s("p"),ni=n("Here is an example using the processors as well as the conversion method using data files:"),ha=i(),g(Nt.$$.fragment),ua=i(),Ce=s("p"),li=n("Using "),ys=s("em"),ii=n("tensorflow_datasets"),di=n(" is as easy as using a data file:"),_a=i(),g(Mt.$$.fragment),ga=i(),je=s("p"),pi=n("Another example using these processors is given in the "),Vt=s("a"),ci=n("run_squad.py"),mi=n(" script."),this.h()},l(e){const p=hp('[data-svelte="svelte-1phssyn"]',document.head);h=a(p,"META",{name:!0,content:!0}),p.forEach(r),y=d(e),_=a(e,"H1",{class:!0});var zt=o(_);u=a(zt,"A",{id:!0,class:!0,href:!0});var Ps=o(u);P=a(Ps,"SPAN",{});var qs=o(P);v(f.$$.fragment,qs),qs.forEach(r),Ps.forEach(r),w=d(zt),z=a(zt,"SPAN",{});var ks=o(z);T=l(ks,"Processors"),ks.forEach(r),zt.forEach(r),q=d(e),C=a(e,"P",{});var Is=o(C);K=l(Is,"Processors can mean two different things in the Transformers library:"),Is.forEach(r),Ls=d(e),ie=a(e,"UL",{});var Ct=o(ie);Y=a(Ct,"LI",{});var ir=o(Y);Ya=l(ir,"the objects that pre-process inputs for multi-modal models such as "),Ot=a(ir,"A",{href:!0});var $i=o(Ot);Za=l($i,"Wav2Vec2"),$i.forEach(r),eo=l(ir,` (speech and text)
or `),Qt=a(ir,"A",{href:!0});var bi=o(Qt);to=l(bi,"CLIP"),bi.forEach(r),ro=l(ir," (text and vision)"),ir.forEach(r),so=d(Ct),gr=a(Ct,"LI",{});var xi=o(gr);ao=l(xi,"deprecated objects that were used in older versions of the library to preprocess data for GLUE or SQUAD."),xi.forEach(r),Ct.forEach(r),Ds=d(e),Z=a(e,"H2",{class:!0});var $a=o(Z);de=a($a,"A",{id:!0,class:!0,href:!0});var Ei=o(de);vr=a(Ei,"SPAN",{});var wi=o(vr);v(Qe.$$.fragment,wi),wi.forEach(r),Ei.forEach(r),oo=d($a),$r=a($a,"SPAN",{});var yi=o($r);no=l(yi,"Multi-modal processors"),yi.forEach(r),$a.forEach(r),Ts=d(e),Ut=a(e,"P",{});var Pi=o(Ut);lo=l(Pi,`Any multi-modal model will require an object to encode or decode the data that groups several modalities (among text,
vision and audio). This is handled by objects called processors, which group tokenizers (for the text modality) and
feature extractors (for vision and audio).`),Pi.forEach(r),Ns=d(e),Ft=a(e,"P",{});var qi=o(Ft);io=l(qi,"Those processors inherit from the following base class that implements the saving and loading functionality:"),qi.forEach(r),Ms=d(e),L=a(e,"DIV",{class:!0});var j=o(L);v(Ue.$$.fragment,j),po=d(j),br=a(j,"P",{});var ki=o(br);co=l(ki,"This is a mixin used to provide saving/loading functionality for all processor classes."),ki.forEach(r),mo=d(j),G=a(j,"DIV",{class:!0});var dr=o(G);v(Fe.$$.fragment,dr),fo=d(dr),xr=a(dr,"P",{});var Ii=o(xr);ho=l(Ii,"Instantiate a processor associated with a pretrained model."),Ii.forEach(r),uo=d(dr),v(pe.$$.fragment,dr),dr.forEach(r),_o=d(j),R=a(j,"DIV",{class:!0});var pr=o(R);v(Ge.$$.fragment,pr),go=d(pr),Re=a(pr,"P",{});var ba=o(Re);vo=l(ba,`Upload the processor files to the \u{1F917} Model Hub while synchronizing a local clone of the repo in
`),Er=a(ba,"CODE",{});var Si=o(Er);$o=l(Si,"repo_path_or_name"),Si.forEach(r),bo=l(ba,"."),ba.forEach(r),xo=d(pr),v(ce.$$.fragment,pr),pr.forEach(r),Eo=d(j),H=a(j,"DIV",{class:!0});var cr=o(H);v(He.$$.fragment,cr),wo=d(cr),We=a(cr,"P",{});var xa=o(We);yo=l(xa,`Register this class with a given auto class. This should only be used for custom feature extractors as the ones
in the library are already mapped with `),wr=a(xa,"CODE",{});var Ai=o(wr);Po=l(Ai,"AutoProcessor"),Ai.forEach(r),qo=l(xa,"."),xa.forEach(r),ko=d(cr),v(me.$$.fragment,cr),cr.forEach(r),Io=d(j),W=a(j,"DIV",{class:!0});var mr=o(W);v(Xe.$$.fragment,mr),So=d(mr),Be=a(mr,"P",{});var Ea=o(Be);Ao=l(Ea,`Saves the attributes of this processor (feature extractor, tokenizer\u2026) in the specified directory so that it
can be reloaded using the `),Gt=a(Ea,"A",{href:!0});var Li=o(Gt);Lo=l(Li,"from_pretrained()"),Li.forEach(r),Do=l(Ea," method."),Ea.forEach(r),To=d(mr),v(fe.$$.fragment,mr),mr.forEach(r),j.forEach(r),Vs=d(e),ee=a(e,"H2",{class:!0});var wa=o(ee);he=a(wa,"A",{id:!0,class:!0,href:!0});var Di=o(he);yr=a(Di,"SPAN",{});var Ti=o(yr);v(Je.$$.fragment,Ti),Ti.forEach(r),Di.forEach(r),No=d(wa),Pr=a(wa,"SPAN",{});var Ni=o(Pr);Mo=l(Ni,"Deprecated processors"),Ni.forEach(r),wa.forEach(r),zs=d(e),V=a(e,"P",{});var B=o(V);Vo=l(B,`All processors follow the same architecture which is that of the
`),Rt=a(B,"A",{href:!0});var Mi=o(Rt);zo=l(Mi,"DataProcessor"),Mi.forEach(r),Co=l(B,`. The processor returns a list of
`),Ht=a(B,"A",{href:!0});var Vi=o(Ht);jo=l(Vi,"InputExample"),Vi.forEach(r),Oo=l(B,`. These
`),Wt=a(B,"A",{href:!0});var zi=o(Wt);Qo=l(zi,"InputExample"),zi.forEach(r),Uo=l(B,` can be converted to
`),Xt=a(B,"A",{href:!0});var Ci=o(Xt);Fo=l(Ci,"InputFeatures"),Ci.forEach(r),Go=l(B," in order to be fed to the model."),B.forEach(r),Cs=d(e),S=a(e,"DIV",{class:!0});var D=o(S);v(Ke.$$.fragment,D),Ro=d(D),qr=a(D,"P",{});var ji=o(qr);Ho=l(ji,"Base class for data converters for sequence classification data sets."),ji.forEach(r),Wo=d(D),ue=a(D,"DIV",{class:!0});var ya=o(ue);v(Ye.$$.fragment,ya),Xo=d(ya),Ze=a(ya,"P",{});var Pa=o(Ze);Bo=l(Pa,"Gets a collection of "),Bt=a(Pa,"A",{href:!0});var Oi=o(Bt);Jo=l(Oi,"InputExample"),Oi.forEach(r),Ko=l(Pa," for the dev set."),Pa.forEach(r),ya.forEach(r),Yo=d(D),_e=a(D,"DIV",{class:!0});var qa=o(_e);v(et.$$.fragment,qa),Zo=d(qa),kr=a(qa,"P",{});var Qi=o(kr);en=l(Qi,"Gets an example from a dict with tensorflow tensors."),Qi.forEach(r),qa.forEach(r),tn=d(D),ge=a(D,"DIV",{class:!0});var ka=o(ge);v(tt.$$.fragment,ka),rn=d(ka),Ir=a(ka,"P",{});var Ui=o(Ir);sn=l(Ui,"Gets the list of labels for this data set."),Ui.forEach(r),ka.forEach(r),an=d(D),ve=a(D,"DIV",{class:!0});var Ia=o(ve);v(rt.$$.fragment,Ia),on=d(Ia),st=a(Ia,"P",{});var Sa=o(st);nn=l(Sa,"Gets a collection of "),Jt=a(Sa,"A",{href:!0});var Fi=o(Jt);ln=l(Fi,"InputExample"),Fi.forEach(r),dn=l(Sa," for the test set."),Sa.forEach(r),Ia.forEach(r),pn=d(D),$e=a(D,"DIV",{class:!0});var Aa=o($e);v(at.$$.fragment,Aa),cn=d(Aa),ot=a(Aa,"P",{});var La=o(ot);mn=l(La,"Gets a collection of "),Kt=a(La,"A",{href:!0});var Gi=o(Kt);fn=l(Gi,"InputExample"),Gi.forEach(r),hn=l(La," for the train set."),La.forEach(r),Aa.forEach(r),un=d(D),be=a(D,"DIV",{class:!0});var Da=o(be);v(nt.$$.fragment,Da),_n=d(Da),Sr=a(Da,"P",{});var Ri=o(Sr);gn=l(Ri,`Some tensorflow_datasets datasets are not formatted the same way the GLUE datasets are. This method converts
examples to the correct format.`),Ri.forEach(r),Da.forEach(r),D.forEach(r),js=d(e),O=a(e,"DIV",{class:!0});var fr=o(O);v(lt.$$.fragment,fr),vn=d(fr),Ar=a(fr,"P",{});var Hi=o(Ar);$n=l(Hi,"A single training/test example for simple sequence classification."),Hi.forEach(r),bn=d(fr),xe=a(fr,"DIV",{class:!0});var Ta=o(xe);v(it.$$.fragment,Ta),xn=d(Ta),Lr=a(Ta,"P",{});var Wi=o(Lr);En=l(Wi,"Serializes this instance to a JSON string."),Wi.forEach(r),Ta.forEach(r),fr.forEach(r),Os=d(e),Q=a(e,"DIV",{class:!0});var hr=o(Q);v(dt.$$.fragment,hr),wn=d(hr),Dr=a(hr,"P",{});var Xi=o(Dr);yn=l(Xi,"A single set of features of data. Property names are the same names as the corresponding inputs to a model."),Xi.forEach(r),Pn=d(hr),Ee=a(hr,"DIV",{class:!0});var Na=o(Ee);v(pt.$$.fragment,Na),qn=d(Na),Tr=a(Na,"P",{});var Bi=o(Tr);kn=l(Bi,"Serializes this instance to a JSON string."),Bi.forEach(r),Na.forEach(r),hr.forEach(r),Qs=d(e),te=a(e,"H2",{class:!0});var Ma=o(te);we=a(Ma,"A",{id:!0,class:!0,href:!0});var Ji=o(we);Nr=a(Ji,"SPAN",{});var Ki=o(Nr);v(ct.$$.fragment,Ki),Ki.forEach(r),Ji.forEach(r),In=d(Ma),Mr=a(Ma,"SPAN",{});var Yi=o(Mr);Sn=l(Yi,"GLUE"),Yi.forEach(r),Ma.forEach(r),Us=d(e),ye=a(e,"P",{});var Va=o(ye);mt=a(Va,"A",{href:!0,rel:!0});var Zi=o(mt);An=l(Zi,"General Language Understanding Evaluation (GLUE)"),Zi.forEach(r),Ln=l(Va,` is a benchmark that evaluates the
performance of models across a diverse set of existing NLU tasks. It was released together with the paper `),ft=a(Va,"A",{href:!0,rel:!0});var ed=o(ft);Dn=l(ed,`GLUE: A
multi-task benchmark and analysis platform for natural language understanding`),ed.forEach(r),Va.forEach(r),Fs=d(e),Yt=a(e,"P",{});var td=o(Yt);Tn=l(td,`This library hosts a total of 10 processors for the following tasks: MRPC, MNLI, MNLI (mismatched), CoLA, SST2, STSB,
QQP, QNLI, RTE and WNLI.`),td.forEach(r),Gs=d(e),Zt=a(e,"P",{});var rd=o(Zt);Nn=l(rd,"Those processors are:"),rd.forEach(r),Rs=d(e),k=a(e,"UL",{});var A=o(k);Vr=a(A,"LI",{});var sd=o(Vr);zr=a(sd,"CODE",{});var ad=o(zr);Mn=l(ad,"MrpcProcessor"),ad.forEach(r),sd.forEach(r),Vn=d(A),Cr=a(A,"LI",{});var od=o(Cr);jr=a(od,"CODE",{});var nd=o(jr);zn=l(nd,"MnliProcessor"),nd.forEach(r),od.forEach(r),Cn=d(A),Or=a(A,"LI",{});var ld=o(Or);Qr=a(ld,"CODE",{});var id=o(Qr);jn=l(id,"MnliMismatchedProcessor"),id.forEach(r),ld.forEach(r),On=d(A),Ur=a(A,"LI",{});var dd=o(Ur);Fr=a(dd,"CODE",{});var pd=o(Fr);Qn=l(pd,"Sst2Processor"),pd.forEach(r),dd.forEach(r),Un=d(A),Gr=a(A,"LI",{});var cd=o(Gr);Rr=a(cd,"CODE",{});var md=o(Rr);Fn=l(md,"StsbProcessor"),md.forEach(r),cd.forEach(r),Gn=d(A),Hr=a(A,"LI",{});var fd=o(Hr);Wr=a(fd,"CODE",{});var hd=o(Wr);Rn=l(hd,"QqpProcessor"),hd.forEach(r),fd.forEach(r),Hn=d(A),Xr=a(A,"LI",{});var ud=o(Xr);Br=a(ud,"CODE",{});var _d=o(Br);Wn=l(_d,"QnliProcessor"),_d.forEach(r),ud.forEach(r),Xn=d(A),Jr=a(A,"LI",{});var gd=o(Jr);Kr=a(gd,"CODE",{});var vd=o(Kr);Bn=l(vd,"RteProcessor"),vd.forEach(r),gd.forEach(r),Jn=d(A),Yr=a(A,"LI",{});var $d=o(Yr);Zr=a($d,"CODE",{});var bd=o(Zr);Kn=l(bd,"WnliProcessor"),bd.forEach(r),$d.forEach(r),A.forEach(r),Hs=d(e),Pe=a(e,"P",{});var za=o(Pe);Yn=l(za,`Additionally, the following method can be used to load values from a data file and convert them to a list of
`),er=a(za,"A",{href:!0});var xd=o(er);Zn=l(xd,"InputExample"),xd.forEach(r),el=l(za,"."),za.forEach(r),Ws=d(e),re=a(e,"DIV",{class:!0});var Ca=o(re);v(ht.$$.fragment,Ca),tl=d(Ca),tr=a(Ca,"P",{});var fi=o(tr);rl=l(fi,"Loads a data file into a list of "),es=a(fi,"CODE",{});var Ed=o(es);sl=l(Ed,"InputFeatures"),Ed.forEach(r),fi.forEach(r),Ca.forEach(r),Xs=d(e),se=a(e,"H2",{class:!0});var ja=o(se);qe=a(ja,"A",{id:!0,class:!0,href:!0});var wd=o(qe);ts=a(wd,"SPAN",{});var yd=o(ts);v(ut.$$.fragment,yd),yd.forEach(r),wd.forEach(r),al=d(ja),rs=a(ja,"SPAN",{});var Pd=o(rs);ol=l(Pd,"XNLI"),Pd.forEach(r),ja.forEach(r),Bs=d(e),ae=a(e,"P",{});var Ss=o(ae);_t=a(Ss,"A",{href:!0,rel:!0});var qd=o(_t);nl=l(qd,"The Cross-Lingual NLI Corpus (XNLI)"),qd.forEach(r),ll=l(Ss,` is a benchmark that evaluates the
quality of cross-lingual text representations. XNLI is crowd-sourced dataset based on `),gt=a(Ss,"A",{href:!0,rel:!0});var kd=o(gt);ss=a(kd,"EM",{});var Id=o(ss);il=l(Id,"MultiNLI"),Id.forEach(r),kd.forEach(r),dl=l(Ss,`: pairs of text are labeled with textual entailment annotations for 15
different languages (including both high-resource language such as English and low-resource languages such as Swahili).`),Ss.forEach(r),Js=d(e),vt=a(e,"P",{});var hi=o(vt);pl=l(hi,"It was released together with the paper "),$t=a(hi,"A",{href:!0,rel:!0});var Sd=o($t);cl=l(Sd,"XNLI: Evaluating Cross-lingual Sentence Representations"),Sd.forEach(r),hi.forEach(r),Ks=d(e),rr=a(e,"P",{});var Ad=o(rr);ml=l(Ad,"This library hosts the processor to load the XNLI data:"),Ad.forEach(r),Ys=d(e),sr=a(e,"UL",{});var Ld=o(sr);as=a(Ld,"LI",{});var Dd=o(as);os=a(Dd,"CODE",{});var Td=o(os);fl=l(Td,"XnliProcessor"),Td.forEach(r),Dd.forEach(r),Ld.forEach(r),Zs=d(e),ar=a(e,"P",{});var Nd=o(ar);hl=l(Nd,"Please note that since the gold labels are available on the test set, evaluation is performed on the test set."),Nd.forEach(r),ea=d(e),ke=a(e,"P",{});var Oa=o(ke);ul=l(Oa,"An example using these processors is given in the "),bt=a(Oa,"A",{href:!0,rel:!0});var Md=o(bt);_l=l(Md,"run_xnli.py"),Md.forEach(r),gl=l(Oa," script."),Oa.forEach(r),ta=d(e),oe=a(e,"H2",{class:!0});var Qa=o(oe);Ie=a(Qa,"A",{id:!0,class:!0,href:!0});var Vd=o(Ie);ns=a(Vd,"SPAN",{});var zd=o(ns);v(xt.$$.fragment,zd),zd.forEach(r),Vd.forEach(r),vl=d(Qa),ls=a(Qa,"SPAN",{});var Cd=o(ls);$l=l(Cd,"SQuAD"),Cd.forEach(r),Qa.forEach(r),ra=d(e),U=a(e,"P",{});var jt=o(U);Et=a(jt,"A",{href:!0,rel:!0});var jd=o(Et);bl=l(jd,"The Stanford Question Answering Dataset (SQuAD)"),jd.forEach(r),xl=l(jt,` is a benchmark that
evaluates the performance of models on question answering. Two versions are available, v1.1 and v2.0. The first version
(v1.1) was released together with the paper `),wt=a(jt,"A",{href:!0,rel:!0});var Od=o(wt);El=l(Od,"SQuAD: 100,000+ Questions for Machine Comprehension of Text"),Od.forEach(r),wl=l(jt,". The second version (v2.0) was released alongside the paper "),yt=a(jt,"A",{href:!0,rel:!0});var Qd=o(yt);yl=l(Qd,`Know What You Don\u2019t
Know: Unanswerable Questions for SQuAD`),Qd.forEach(r),Pl=l(jt,"."),jt.forEach(r),sa=d(e),or=a(e,"P",{});var Ud=o(or);ql=l(Ud,"This library hosts a processor for each of the two versions:"),Ud.forEach(r),aa=d(e),ne=a(e,"H3",{class:!0});var Ua=o(ne);Se=a(Ua,"A",{id:!0,class:!0,href:!0});var Fd=o(Se);is=a(Fd,"SPAN",{});var Gd=o(is);v(Pt.$$.fragment,Gd),Gd.forEach(r),Fd.forEach(r),kl=d(Ua),ds=a(Ua,"SPAN",{});var Rd=o(ds);Il=l(Rd,"Processors"),Rd.forEach(r),Ua.forEach(r),oa=d(e),nr=a(e,"P",{});var Hd=o(nr);Sl=l(Hd,"Those processors are:"),Hd.forEach(r),na=d(e),Ae=a(e,"UL",{});var Fa=o(Ae);ps=a(Fa,"LI",{});var Wd=o(ps);cs=a(Wd,"CODE",{});var Xd=o(cs);Al=l(Xd,"SquadV1Processor"),Xd.forEach(r),Wd.forEach(r),Ll=d(Fa),ms=a(Fa,"LI",{});var Bd=o(ms);fs=a(Bd,"CODE",{});var Jd=o(fs);Dl=l(Jd,"SquadV2Processor"),Jd.forEach(r),Bd.forEach(r),Fa.forEach(r),la=d(e),qt=a(e,"P",{});var ui=o(qt);Tl=l(ui,"They both inherit from the abstract class "),hs=a(ui,"CODE",{});var Kd=o(hs);Nl=l(Kd,"SquadProcessor"),Kd.forEach(r),ui.forEach(r),ia=d(e),N=a(e,"DIV",{class:!0});var J=o(N);v(kt.$$.fragment,J),Ml=d(J),us=a(J,"P",{});var Yd=o(us);Vl=l(Yd,`Processor for the SQuAD data set. overridden by SquadV1Processor and SquadV2Processor, used by the version 1.1 and
version 2.0 of SQuAD, respectively.`),Yd.forEach(r),zl=d(J),Le=a(J,"DIV",{class:!0});var Ga=o(Le);v(It.$$.fragment,Ga),Cl=d(Ga),_s=a(Ga,"P",{});var Zd=o(_s);jl=l(Zd,"Returns the evaluation example from the data directory."),Zd.forEach(r),Ga.forEach(r),Ol=d(J),X=a(J,"DIV",{class:!0});var ur=o(X);v(St.$$.fragment,ur),Ql=d(ur),At=a(ur,"P",{});var Ra=o(At);Ul=l(Ra,"Creates a list of "),gs=a(Ra,"CODE",{});var ep=o(gs);Fl=l(ep,"SquadExample"),ep.forEach(r),Gl=l(Ra," using a TFDS dataset."),Ra.forEach(r),Rl=d(ur),v(De.$$.fragment,ur),ur.forEach(r),Hl=d(J),Te=a(J,"DIV",{class:!0});var Ha=o(Te);v(Lt.$$.fragment,Ha),Wl=d(Ha),vs=a(Ha,"P",{});var tp=o(vs);Xl=l(tp,"Returns the training examples from the data directory."),tp.forEach(r),Ha.forEach(r),J.forEach(r),da=d(e),Ne=a(e,"P",{});var Wa=o(Ne);Bl=l(Wa,`Additionally, the following method can be used to convert SQuAD examples into
`),$s=a(Wa,"CODE",{});var rp=o($s);Jl=l(rp,"SquadFeatures"),rp.forEach(r),Kl=l(Wa," that can be used as model inputs."),Wa.forEach(r),pa=d(e),F=a(e,"DIV",{class:!0});var _r=o(F);v(Dt.$$.fragment,_r),Yl=d(_r),bs=a(_r,"P",{});var sp=o(bs);Zl=l(sp,`Converts a list of examples into a list of features that can be directly given as input to a model. It is
model-dependant and takes advantage of many of the tokenizer\u2019s features to create the model\u2019s inputs.`),sp.forEach(r),ei=d(_r),v(Me.$$.fragment,_r),_r.forEach(r),ca=d(e),Ve=a(e,"P",{});var Xa=o(Ve);ti=l(Xa,`These processors as well as the aforementionned method can be used with files containing the data as well as with the
`),xs=a(Xa,"EM",{});var ap=o(xs);ri=l(ap,"tensorflow_datasets"),ap.forEach(r),si=l(Xa," package. Examples are given below."),Xa.forEach(r),ma=d(e),le=a(e,"H3",{class:!0});var Ba=o(le);ze=a(Ba,"A",{id:!0,class:!0,href:!0});var op=o(ze);Es=a(op,"SPAN",{});var np=o(Es);v(Tt.$$.fragment,np),np.forEach(r),op.forEach(r),ai=d(Ba),ws=a(Ba,"SPAN",{});var lp=o(ws);oi=l(lp,"Example usage"),lp.forEach(r),Ba.forEach(r),fa=d(e),lr=a(e,"P",{});var ip=o(lr);ni=l(ip,"Here is an example using the processors as well as the conversion method using data files:"),ip.forEach(r),ha=d(e),v(Nt.$$.fragment,e),ua=d(e),Ce=a(e,"P",{});var Ja=o(Ce);li=l(Ja,"Using "),ys=a(Ja,"EM",{});var dp=o(ys);ii=l(dp,"tensorflow_datasets"),dp.forEach(r),di=l(Ja," is as easy as using a data file:"),Ja.forEach(r),_a=d(e),v(Mt.$$.fragment,e),ga=d(e),je=a(e,"P",{});var Ka=o(je);pi=l(Ka,"Another example using these processors is given in the "),Vt=a(Ka,"A",{href:!0,rel:!0});var pp=o(Vt);ci=l(pp,"run_squad.py"),pp.forEach(r),mi=l(Ka," script."),Ka.forEach(r),this.h()},h(){m(h,"name","hf:doc:metadata"),m(h,"content",JSON.stringify(wp)),m(u,"id","processors"),m(u,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(u,"href","#processors"),m(_,"class","relative group"),m(Ot,"href","../model_doc/wav2vec2"),m(Qt,"href","../model_doc/clip"),m(de,"id","transformers.ProcessorMixin"),m(de,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(de,"href","#transformers.ProcessorMixin"),m(Z,"class","relative group"),m(G,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(R,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(H,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Gt,"href","/docs/transformers/main/en/main_classes/processors#transformers.ProcessorMixin.from_pretrained"),m(W,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(L,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(he,"id","transformers.DataProcessor"),m(he,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(he,"href","#transformers.DataProcessor"),m(ee,"class","relative group"),m(Rt,"href","/docs/transformers/main/en/main_classes/processors#transformers.DataProcessor"),m(Ht,"href","/docs/transformers/main/en/main_classes/processors#transformers.InputExample"),m(Wt,"href","/docs/transformers/main/en/main_classes/processors#transformers.InputExample"),m(Xt,"href","/docs/transformers/main/en/main_classes/processors#transformers.InputFeatures"),m(Bt,"href","/docs/transformers/main/en/main_classes/processors#transformers.InputExample"),m(ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(_e,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ge,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Jt,"href","/docs/transformers/main/en/main_classes/processors#transformers.InputExample"),m(ve,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Kt,"href","/docs/transformers/main/en/main_classes/processors#transformers.InputExample"),m($e,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(be,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(S,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(xe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(O,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ee,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(we,"id","transformers.glue_convert_examples_to_features"),m(we,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(we,"href","#transformers.glue_convert_examples_to_features"),m(te,"class","relative group"),m(mt,"href","https://gluebenchmark.com/"),m(mt,"rel","nofollow"),m(ft,"href","https://openreview.net/pdf?id=rJ4km2R5t7"),m(ft,"rel","nofollow"),m(er,"href","/docs/transformers/main/en/main_classes/processors#transformers.InputExample"),m(re,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(qe,"id","xnli"),m(qe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(qe,"href","#xnli"),m(se,"class","relative group"),m(_t,"href","https://www.nyu.edu/projects/bowman/xnli/"),m(_t,"rel","nofollow"),m(gt,"href","http://www.nyu.edu/projects/bowman/multinli/"),m(gt,"rel","nofollow"),m($t,"href","https://arxiv.org/abs/1809.05053"),m($t,"rel","nofollow"),m(bt,"href","https://github.com/huggingface/transformers/tree/main/examples/legacy/text-classification/run_xnli.py"),m(bt,"rel","nofollow"),m(Ie,"id","squad"),m(Ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Ie,"href","#squad"),m(oe,"class","relative group"),m(Et,"href","https://rajpurkar.github.io/SQuAD-explorer//"),m(Et,"rel","nofollow"),m(wt,"href","https://arxiv.org/abs/1606.05250"),m(wt,"rel","nofollow"),m(yt,"href","https://arxiv.org/abs/1806.03822"),m(yt,"rel","nofollow"),m(Se,"id","transformers.data.processors.squad.SquadProcessor"),m(Se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Se,"href","#transformers.data.processors.squad.SquadProcessor"),m(ne,"class","relative group"),m(Le,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(X,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Te,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(N,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(F,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ze,"id","example-usage"),m(ze,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ze,"href","#example-usage"),m(le,"class","relative group"),m(Vt,"href","https://github.com/huggingface/transformers/tree/main/examples/legacy/question-answering/run_squad.py"),m(Vt,"rel","nofollow")},m(e,p){t(document.head,h),c(e,y,p),c(e,_,p),t(_,u),t(u,P),$(f,P,null),t(_,w),t(_,z),t(z,T),c(e,q,p),c(e,C,p),t(C,K),c(e,Ls,p),c(e,ie,p),t(ie,Y),t(Y,Ya),t(Y,Ot),t(Ot,Za),t(Y,eo),t(Y,Qt),t(Qt,to),t(Y,ro),t(ie,so),t(ie,gr),t(gr,ao),c(e,Ds,p),c(e,Z,p),t(Z,de),t(de,vr),$(Qe,vr,null),t(Z,oo),t(Z,$r),t($r,no),c(e,Ts,p),c(e,Ut,p),t(Ut,lo),c(e,Ns,p),c(e,Ft,p),t(Ft,io),c(e,Ms,p),c(e,L,p),$(Ue,L,null),t(L,po),t(L,br),t(br,co),t(L,mo),t(L,G),$(Fe,G,null),t(G,fo),t(G,xr),t(xr,ho),t(G,uo),$(pe,G,null),t(L,_o),t(L,R),$(Ge,R,null),t(R,go),t(R,Re),t(Re,vo),t(Re,Er),t(Er,$o),t(Re,bo),t(R,xo),$(ce,R,null),t(L,Eo),t(L,H),$(He,H,null),t(H,wo),t(H,We),t(We,yo),t(We,wr),t(wr,Po),t(We,qo),t(H,ko),$(me,H,null),t(L,Io),t(L,W),$(Xe,W,null),t(W,So),t(W,Be),t(Be,Ao),t(Be,Gt),t(Gt,Lo),t(Be,Do),t(W,To),$(fe,W,null),c(e,Vs,p),c(e,ee,p),t(ee,he),t(he,yr),$(Je,yr,null),t(ee,No),t(ee,Pr),t(Pr,Mo),c(e,zs,p),c(e,V,p),t(V,Vo),t(V,Rt),t(Rt,zo),t(V,Co),t(V,Ht),t(Ht,jo),t(V,Oo),t(V,Wt),t(Wt,Qo),t(V,Uo),t(V,Xt),t(Xt,Fo),t(V,Go),c(e,Cs,p),c(e,S,p),$(Ke,S,null),t(S,Ro),t(S,qr),t(qr,Ho),t(S,Wo),t(S,ue),$(Ye,ue,null),t(ue,Xo),t(ue,Ze),t(Ze,Bo),t(Ze,Bt),t(Bt,Jo),t(Ze,Ko),t(S,Yo),t(S,_e),$(et,_e,null),t(_e,Zo),t(_e,kr),t(kr,en),t(S,tn),t(S,ge),$(tt,ge,null),t(ge,rn),t(ge,Ir),t(Ir,sn),t(S,an),t(S,ve),$(rt,ve,null),t(ve,on),t(ve,st),t(st,nn),t(st,Jt),t(Jt,ln),t(st,dn),t(S,pn),t(S,$e),$(at,$e,null),t($e,cn),t($e,ot),t(ot,mn),t(ot,Kt),t(Kt,fn),t(ot,hn),t(S,un),t(S,be),$(nt,be,null),t(be,_n),t(be,Sr),t(Sr,gn),c(e,js,p),c(e,O,p),$(lt,O,null),t(O,vn),t(O,Ar),t(Ar,$n),t(O,bn),t(O,xe),$(it,xe,null),t(xe,xn),t(xe,Lr),t(Lr,En),c(e,Os,p),c(e,Q,p),$(dt,Q,null),t(Q,wn),t(Q,Dr),t(Dr,yn),t(Q,Pn),t(Q,Ee),$(pt,Ee,null),t(Ee,qn),t(Ee,Tr),t(Tr,kn),c(e,Qs,p),c(e,te,p),t(te,we),t(we,Nr),$(ct,Nr,null),t(te,In),t(te,Mr),t(Mr,Sn),c(e,Us,p),c(e,ye,p),t(ye,mt),t(mt,An),t(ye,Ln),t(ye,ft),t(ft,Dn),c(e,Fs,p),c(e,Yt,p),t(Yt,Tn),c(e,Gs,p),c(e,Zt,p),t(Zt,Nn),c(e,Rs,p),c(e,k,p),t(k,Vr),t(Vr,zr),t(zr,Mn),t(k,Vn),t(k,Cr),t(Cr,jr),t(jr,zn),t(k,Cn),t(k,Or),t(Or,Qr),t(Qr,jn),t(k,On),t(k,Ur),t(Ur,Fr),t(Fr,Qn),t(k,Un),t(k,Gr),t(Gr,Rr),t(Rr,Fn),t(k,Gn),t(k,Hr),t(Hr,Wr),t(Wr,Rn),t(k,Hn),t(k,Xr),t(Xr,Br),t(Br,Wn),t(k,Xn),t(k,Jr),t(Jr,Kr),t(Kr,Bn),t(k,Jn),t(k,Yr),t(Yr,Zr),t(Zr,Kn),c(e,Hs,p),c(e,Pe,p),t(Pe,Yn),t(Pe,er),t(er,Zn),t(Pe,el),c(e,Ws,p),c(e,re,p),$(ht,re,null),t(re,tl),t(re,tr),t(tr,rl),t(tr,es),t(es,sl),c(e,Xs,p),c(e,se,p),t(se,qe),t(qe,ts),$(ut,ts,null),t(se,al),t(se,rs),t(rs,ol),c(e,Bs,p),c(e,ae,p),t(ae,_t),t(_t,nl),t(ae,ll),t(ae,gt),t(gt,ss),t(ss,il),t(ae,dl),c(e,Js,p),c(e,vt,p),t(vt,pl),t(vt,$t),t($t,cl),c(e,Ks,p),c(e,rr,p),t(rr,ml),c(e,Ys,p),c(e,sr,p),t(sr,as),t(as,os),t(os,fl),c(e,Zs,p),c(e,ar,p),t(ar,hl),c(e,ea,p),c(e,ke,p),t(ke,ul),t(ke,bt),t(bt,_l),t(ke,gl),c(e,ta,p),c(e,oe,p),t(oe,Ie),t(Ie,ns),$(xt,ns,null),t(oe,vl),t(oe,ls),t(ls,$l),c(e,ra,p),c(e,U,p),t(U,Et),t(Et,bl),t(U,xl),t(U,wt),t(wt,El),t(U,wl),t(U,yt),t(yt,yl),t(U,Pl),c(e,sa,p),c(e,or,p),t(or,ql),c(e,aa,p),c(e,ne,p),t(ne,Se),t(Se,is),$(Pt,is,null),t(ne,kl),t(ne,ds),t(ds,Il),c(e,oa,p),c(e,nr,p),t(nr,Sl),c(e,na,p),c(e,Ae,p),t(Ae,ps),t(ps,cs),t(cs,Al),t(Ae,Ll),t(Ae,ms),t(ms,fs),t(fs,Dl),c(e,la,p),c(e,qt,p),t(qt,Tl),t(qt,hs),t(hs,Nl),c(e,ia,p),c(e,N,p),$(kt,N,null),t(N,Ml),t(N,us),t(us,Vl),t(N,zl),t(N,Le),$(It,Le,null),t(Le,Cl),t(Le,_s),t(_s,jl),t(N,Ol),t(N,X),$(St,X,null),t(X,Ql),t(X,At),t(At,Ul),t(At,gs),t(gs,Fl),t(At,Gl),t(X,Rl),$(De,X,null),t(N,Hl),t(N,Te),$(Lt,Te,null),t(Te,Wl),t(Te,vs),t(vs,Xl),c(e,da,p),c(e,Ne,p),t(Ne,Bl),t(Ne,$s),t($s,Jl),t(Ne,Kl),c(e,pa,p),c(e,F,p),$(Dt,F,null),t(F,Yl),t(F,bs),t(bs,Zl),t(F,ei),$(Me,F,null),c(e,ca,p),c(e,Ve,p),t(Ve,ti),t(Ve,xs),t(xs,ri),t(Ve,si),c(e,ma,p),c(e,le,p),t(le,ze),t(ze,Es),$(Tt,Es,null),t(le,ai),t(le,ws),t(ws,oi),c(e,fa,p),c(e,lr,p),t(lr,ni),c(e,ha,p),$(Nt,e,p),c(e,ua,p),c(e,Ce,p),t(Ce,li),t(Ce,ys),t(ys,ii),t(Ce,di),c(e,_a,p),$(Mt,e,p),c(e,ga,p),c(e,je,p),t(je,pi),t(je,Vt),t(Vt,ci),t(je,mi),va=!0},p(e,[p]){const zt={};p&2&&(zt.$$scope={dirty:p,ctx:e}),pe.$set(zt);const Ps={};p&2&&(Ps.$$scope={dirty:p,ctx:e}),ce.$set(Ps);const qs={};p&2&&(qs.$$scope={dirty:p,ctx:e}),me.$set(qs);const ks={};p&2&&(ks.$$scope={dirty:p,ctx:e}),fe.$set(ks);const Is={};p&2&&(Is.$$scope={dirty:p,ctx:e}),De.$set(Is);const Ct={};p&2&&(Ct.$$scope={dirty:p,ctx:e}),Me.$set(Ct)},i(e){va||(b(f.$$.fragment,e),b(Qe.$$.fragment,e),b(Ue.$$.fragment,e),b(Fe.$$.fragment,e),b(pe.$$.fragment,e),b(Ge.$$.fragment,e),b(ce.$$.fragment,e),b(He.$$.fragment,e),b(me.$$.fragment,e),b(Xe.$$.fragment,e),b(fe.$$.fragment,e),b(Je.$$.fragment,e),b(Ke.$$.fragment,e),b(Ye.$$.fragment,e),b(et.$$.fragment,e),b(tt.$$.fragment,e),b(rt.$$.fragment,e),b(at.$$.fragment,e),b(nt.$$.fragment,e),b(lt.$$.fragment,e),b(it.$$.fragment,e),b(dt.$$.fragment,e),b(pt.$$.fragment,e),b(ct.$$.fragment,e),b(ht.$$.fragment,e),b(ut.$$.fragment,e),b(xt.$$.fragment,e),b(Pt.$$.fragment,e),b(kt.$$.fragment,e),b(It.$$.fragment,e),b(St.$$.fragment,e),b(De.$$.fragment,e),b(Lt.$$.fragment,e),b(Dt.$$.fragment,e),b(Me.$$.fragment,e),b(Tt.$$.fragment,e),b(Nt.$$.fragment,e),b(Mt.$$.fragment,e),va=!0)},o(e){x(f.$$.fragment,e),x(Qe.$$.fragment,e),x(Ue.$$.fragment,e),x(Fe.$$.fragment,e),x(pe.$$.fragment,e),x(Ge.$$.fragment,e),x(ce.$$.fragment,e),x(He.$$.fragment,e),x(me.$$.fragment,e),x(Xe.$$.fragment,e),x(fe.$$.fragment,e),x(Je.$$.fragment,e),x(Ke.$$.fragment,e),x(Ye.$$.fragment,e),x(et.$$.fragment,e),x(tt.$$.fragment,e),x(rt.$$.fragment,e),x(at.$$.fragment,e),x(nt.$$.fragment,e),x(lt.$$.fragment,e),x(it.$$.fragment,e),x(dt.$$.fragment,e),x(pt.$$.fragment,e),x(ct.$$.fragment,e),x(ht.$$.fragment,e),x(ut.$$.fragment,e),x(xt.$$.fragment,e),x(Pt.$$.fragment,e),x(kt.$$.fragment,e),x(It.$$.fragment,e),x(St.$$.fragment,e),x(De.$$.fragment,e),x(Lt.$$.fragment,e),x(Dt.$$.fragment,e),x(Me.$$.fragment,e),x(Tt.$$.fragment,e),x(Nt.$$.fragment,e),x(Mt.$$.fragment,e),va=!1},d(e){r(h),e&&r(y),e&&r(_),E(f),e&&r(q),e&&r(C),e&&r(Ls),e&&r(ie),e&&r(Ds),e&&r(Z),E(Qe),e&&r(Ts),e&&r(Ut),e&&r(Ns),e&&r(Ft),e&&r(Ms),e&&r(L),E(Ue),E(Fe),E(pe),E(Ge),E(ce),E(He),E(me),E(Xe),E(fe),e&&r(Vs),e&&r(ee),E(Je),e&&r(zs),e&&r(V),e&&r(Cs),e&&r(S),E(Ke),E(Ye),E(et),E(tt),E(rt),E(at),E(nt),e&&r(js),e&&r(O),E(lt),E(it),e&&r(Os),e&&r(Q),E(dt),E(pt),e&&r(Qs),e&&r(te),E(ct),e&&r(Us),e&&r(ye),e&&r(Fs),e&&r(Yt),e&&r(Gs),e&&r(Zt),e&&r(Rs),e&&r(k),e&&r(Hs),e&&r(Pe),e&&r(Ws),e&&r(re),E(ht),e&&r(Xs),e&&r(se),E(ut),e&&r(Bs),e&&r(ae),e&&r(Js),e&&r(vt),e&&r(Ks),e&&r(rr),e&&r(Ys),e&&r(sr),e&&r(Zs),e&&r(ar),e&&r(ea),e&&r(ke),e&&r(ta),e&&r(oe),E(xt),e&&r(ra),e&&r(U),e&&r(sa),e&&r(or),e&&r(aa),e&&r(ne),E(Pt),e&&r(oa),e&&r(nr),e&&r(na),e&&r(Ae),e&&r(la),e&&r(qt),e&&r(ia),e&&r(N),E(kt),E(It),E(St),E(De),E(Lt),e&&r(da),e&&r(Ne),e&&r(pa),e&&r(F),E(Dt),E(Me),e&&r(ca),e&&r(Ve),e&&r(ma),e&&r(le),E(Tt),e&&r(fa),e&&r(lr),e&&r(ha),E(Nt,e),e&&r(ua),e&&r(Ce),e&&r(_a),E(Mt,e),e&&r(ga),e&&r(je)}}}const wp={local:"processors",sections:[{local:"transformers.ProcessorMixin",title:"Multi-modal processors"},{local:"transformers.DataProcessor",title:"Deprecated processors"},{local:"transformers.glue_convert_examples_to_features",title:"GLUE"},{local:"xnli",title:"XNLI"},{local:"squad",sections:[{local:"transformers.data.processors.squad.SquadProcessor",title:"Processors"},{local:"example-usage",title:"Example usage"}],title:"SQuAD"}],title:"Processors"};function yp(M){return up(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Lp extends cp{constructor(h){super();mp(this,h,yp,Ep,fp,{})}}export{Lp as default,wp as metadata};
