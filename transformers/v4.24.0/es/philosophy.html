<meta charset="utf-8" /><meta http-equiv="content-security-policy" content=""><meta name="hf:doc:metadata" content="{&quot;local&quot;:&quot;filosofa&quot;,&quot;sections&quot;:[{&quot;local&quot;:&quot;conceptos-principales&quot;,&quot;title&quot;:&quot;Conceptos principales &quot;}],&quot;title&quot;:&quot;Filosof√≠a&quot;}" data-svelte="svelte-1phssyn">
	<link rel="modulepreload" href="/docs/transformers/v4.24.0/es/_app/assets/pages/__layout.svelte-hf-doc-builder.css">
	<link rel="modulepreload" href="/docs/transformers/v4.24.0/es/_app/start-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/transformers/v4.24.0/es/_app/chunks/vendor-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/transformers/v4.24.0/es/_app/chunks/paths-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/transformers/v4.24.0/es/_app/pages/__layout.svelte-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/transformers/v4.24.0/es/_app/pages/philosophy.mdx-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/transformers/v4.24.0/es/_app/chunks/IconCopyLink-hf-doc-builder.js"> 






<h1 class="relative group"><a id="filosofa" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#filosofa"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Filosof√≠a
	</span></h1>

<p>ü§ó Transformers es una biblioteca construida para:</p>
<ul><li>Los investigadores y educadores de NLP que busquen usar/estudiar/extender modelos transformers a gran escala </li>
<li>Profesionales que quieren optimizar esos modelos y/o ponerlos en producci√≥n </li>
<li>Ingenieros que solo quieren descargar un modelo preentrenado y usarlo para resolver una tarea NLP dada. </li></ul>
<p>La biblioteca fue dise√±ada con dos fuertes objetivos en mente:</p>
<ul><li><p>Que sea tan f√°cil y r√°pida de utilizar como sea posible:</p>
<ul><li>Hemos limitado enormemente el n√∫mero de abstracciones que el usuario tiene que aprender. De hecho, no hay casi abstracciones,
solo tres clases est√°ndar necesarias para usar cada modelo: <a href="main_classes/configuration">configuration</a>,
<a href="main_classes/model">models</a> y <a href="main_classes/tokenizer">tokenizer</a>.</li>
<li>Todas estas clases pueden ser inicializadas de forma simple y unificada a partir de ejemplos pre-entrenados mediante el uso de un m√©todo
<code>from_pretrained()</code> com√∫n de solicitud que se encargar√° de descargar (si es necesario), almacenar y cargar la solicitud de clase relacionada y datos asociados
(configurations‚Äô hyper-parameters, tokenizers‚Äô vocabulary, and models‚Äô weights) a partir de un control pre-entrenado proporcionado en
<a href="https://huggingface.co/models" rel="nofollow">Hugging Face Hub</a> o de tu propio control guardado.</li>
<li>Por encima de esas tres clases est√°ndar, la biblioteca proporciona dos APIs: <code>pipeline()</code> para usar r√°pidamente un modelo (junto a su configuracion y tokenizer asociados)
sobre una tarea dada, y <code>Trainer</code>/<code>Keras.fit</code> para entrenar u optimizar de forma r√°pida un modelo dado.</li>
<li>Como consecuencia, esta biblioteca NO es una caja de herramientas modular de bloques individuales para redes neuronales. Si quieres extender/construir sobre la biblioteca,
usa simplemente los m√≥dulos regulares de Python/PyTorch/TensorFlow/Keras y emplea las clases est√°ndar de la biblioteca como punto de partida para reutilizar funcionalidades
tales como abrir/guardar modelo.</li></ul></li>
<li><p>Proporciona modelos modernos con rendimientos lo m√°s parecido posible a los modelos originales:</p>
<ul><li>Proporcionamos al menos un ejemplo para cada arquitectura que reproduce un resultado proporcionado por los autores de dicha arquitectura.</li>
<li>El c√≥digo normalmente es parecido al c√≥digo base original, lo cual significa que alg√∫n c√≥digo Pytorch puede no ser tan
<em>pytorchic</em> como podr√≠a ser por haber sido convertido a c√≥digo TensorFlow, y viceversa. </li></ul></li></ul>
<p>Unos cuantos objetivos adicionales:</p>
<ul><li><p>Exponer las caracter√≠sticas internas de los modelos de la forma m√°s coherente posible:</p>
<ul><li>Damos acceso, mediante una sola API, a todos los estados ocultos y pesos de atenci√≥n.</li>
<li>Tokenizer y el modelo de API base est√°n estandarizados para cambiar f√°cilmente entre modelos.</li></ul></li>
<li><p>Incorporar una selecci√≥n subjetiva de herramientas de gran potencial para la optimizaci√≥n/investigaci√≥n de estos modelos:</p>
<ul><li>Una forma sencilla/coherente de a√±adir nuevos tokens al vocabulario e incrustraciones (embeddings, en ingl√©s) para optimizaci√≥n.</li>
<li>Formas sencillas de camuflar y reducir ‚Äútransformer heads‚Äù.</li></ul></li>
<li><p>Cambiar f√°cilmente entre PyTorch y TensorFlow 2.0, permitiendo el entrenamiento usando un marco y la inferencia usando otro.</p></li></ul>
<h2 class="relative group"><a id="conceptos-principales" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#conceptos-principales"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Conceptos principales 
	</span></h2>

<p>La biblioteca est√° construida alrededor de tres tipos de clases para cada modelo:</p>
<ul><li><strong>Model classes</strong> como <code>BertModel</code>, que consisten en m√°s de 30 modelos PyTorch (<a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module" rel="nofollow">torch.nn.Module</a>) o modelos Keras (<a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model" rel="nofollow">tf.keras.Model</a>) que funcionan con pesos pre-entrenados proporcionados en la
biblioteca.</li>
<li><strong>Configuration classes</strong> como <code>BertConfig</code>, que almacena todos los par√°metros necesarios para construir un modelo.
No siempre tienes que generarla tu. En particular, si estas usando un modelo pre-entrenado sin ninguna modificaci√≥n,
la creaci√≥n del modelo se encargar√° autom√°ticamente de generar la configuraci√≥n (que es parte del modelo).</li>
<li><strong>Tokenizer classes</strong> como <code>BertTokenizer</code>, que almacena el vocabulario para cada modelo y proporciona m√©todos para
codificar/decodificar strings en una lista de √≠ndices de ‚Äútoken embeddings‚Äù para ser empleados en un modelo.          </li></ul>
<p>Todas estas clases pueden ser generadas a partir de ejemplos pre-entrenados, y guardados localmente usando dos m√©todos:</p>
<ul><li><code>from_pretrained()</code> permite generar un modelo/configuraci√≥n/tokenizer a partir de una versi√≥n pre-entrenada proporcionada ya sea por
la propia biblioteca (los modelos compatibles se pueden encontrar en <a href="https://huggingface.co/models" rel="nofollow">Model Hub</a>) o
guardados localmente (o en un servidor) por el usuario. </li>
<li><code>save_pretrained()</code> permite guardar un modelo/configuraci√≥n/tokenizer localmente, de forma que puede ser empleado de nuevo usando
<code>from_pretrained()</code>.</li></ul>


		<script type="module" data-hydrate="kwonoh">
		import { start } from "/docs/transformers/v4.24.0/es/_app/start-hf-doc-builder.js";
		start({
			target: document.querySelector('[data-hydrate="kwonoh"]').parentNode,
			paths: {"base":"/docs/transformers/v4.24.0/es","assets":"/docs/transformers/v4.24.0/es"},
			session: {},
			route: false,
			spa: false,
			trailing_slash: "never",
			hydrate: {
				status: 200,
				error: null,
				nodes: [
					import("/docs/transformers/v4.24.0/es/_app/pages/__layout.svelte-hf-doc-builder.js"),
						import("/docs/transformers/v4.24.0/es/_app/pages/philosophy.mdx-hf-doc-builder.js")
				],
				params: {}
			}
		});
	</script>
