import{S as Xr,i as Yr,s as Zr,e as r,k as i,w as Kr,t as l,M as es,c as s,d as o,m as d,a as t,x as Gr,h as n,b as p,G as e,g as u,y as Rr,L as os,q as Qr,o as Jr,B as Vr,v as as}from"../chunks/vendor-hf-doc-builder.js";import{I as Wr}from"../chunks/IconCopyLink-hf-doc-builder.js";function rs(Wa){let g,Ge,y,I,ie,O,_o,de,bo,Re,W,Eo,Qe,_,ce,go,yo,ue,qo,Po,pe,Lo,Je,X,Io,Ve,w,x,me,wo,zo,f,h,ko,Y,To,Co,Z,Ao,$o,ee,jo,Mo,No,q,Oo,fe,xo,Do,D,Uo,Fo,So,v,Ho,he,Bo,Ko,ve,Go,Ro,_e,Qo,Jo,Vo,be,Wo,Xo,U,Ee,Yo,Zo,F,ge,ea,oa,S,aa,ye,ra,sa,We,oe,ta,Xe,b,H,qe,la,na,B,Pe,ia,da,Le,ca,ua,K,Ie,pa,ma,G,we,fa,ha,ze,va,_a,ke,Te,ba,Ye,P,z,Ce,R,Ea,Ae,ga,Ze,ae,ya,eo,E,m,$e,qa,Pa,je,La,Ia,Q,wa,za,J,ka,Ta,Ca,k,Me,Aa,$a,Ne,ja,Ma,Na,T,Oe,Oa,xa,xe,Da,Ua,oo,re,Fa,ao,C,A,De,Sa,Ha,V,Ba,Ka,Ga,$,Ue,Ra,Qa,Fe,Ja,Va,ro;return O=new Wr({}),R=new Wr({}),{c(){g=r("meta"),Ge=i(),y=r("h1"),I=r("a"),ie=r("span"),Kr(O.$$.fragment),_o=i(),de=r("span"),bo=l("Filosof\xEDa"),Re=i(),W=r("p"),Eo=l("\u{1F917} Transformers es una biblioteca construida para:"),Qe=i(),_=r("ul"),ce=r("li"),go=l("Los investigadores y educadores de NLP que busquen usar/estudiar/extender modelos transformers a gran escala"),yo=i(),ue=r("li"),qo=l("Profesionales que quieren optimizar esos modelos y/o ponerlos en producci\xF3n"),Po=i(),pe=r("li"),Lo=l("Ingenieros que solo quieren descargar un modelo preentrenado y usarlo para resolver una tarea NLP dada."),Je=i(),X=r("p"),Io=l("La biblioteca fue dise\xF1ada con dos fuertes objetivos en mente:"),Ve=i(),w=r("ul"),x=r("li"),me=r("p"),wo=l("Que sea tan f\xE1cil y r\xE1pida de utilizar como sea posible:"),zo=i(),f=r("ul"),h=r("li"),ko=l(`Hemos limitado enormemente el n\xFAmero de abstracciones que el usuario tiene que aprender. De hecho, no hay casi abstracciones,
solo tres clases est\xE1ndar necesarias para usar cada modelo: `),Y=r("a"),To=l("configuration"),Co=l(`,
`),Z=r("a"),Ao=l("models"),$o=l(" y "),ee=r("a"),jo=l("tokenizer"),Mo=l("."),No=i(),q=r("li"),Oo=l(`Todas estas clases pueden ser inicializadas de forma simple y unificada a partir de ejemplos pre-entrenados mediante el uso de un m\xE9todo
`),fe=r("code"),xo=l("from_pretrained()"),Do=l(` com\xFAn de solicitud que se encargar\xE1 de descargar (si es necesario), almacenar y cargar la solicitud de clase relacionada y datos asociados
(configurations\u2019 hyper-parameters, tokenizers\u2019 vocabulary, and models\u2019 weights) a partir de un control pre-entrenado proporcionado en
`),D=r("a"),Uo=l("Hugging Face Hub"),Fo=l(" o de tu propio control guardado."),So=i(),v=r("li"),Ho=l("Por encima de esas tres clases est\xE1ndar, la biblioteca proporciona dos APIs: "),he=r("code"),Bo=l("pipeline()"),Ko=l(` para usar r\xE1pidamente un modelo (junto a su configuracion y tokenizer asociados)
sobre una tarea dada, y `),ve=r("code"),Go=l("Trainer"),Ro=l("/"),_e=r("code"),Qo=l("Keras.fit"),Jo=l(" para entrenar u optimizar de forma r\xE1pida un modelo dado."),Vo=i(),be=r("li"),Wo=l(`Como consecuencia, esta biblioteca NO es una caja de herramientas modular de bloques individuales para redes neuronales. Si quieres extender/construir sobre la biblioteca,
usa simplemente los m\xF3dulos regulares de Python/PyTorch/TensorFlow/Keras y emplea las clases est\xE1ndar de la biblioteca como punto de partida para reutilizar funcionalidades
tales como abrir/guardar modelo.`),Xo=i(),U=r("li"),Ee=r("p"),Yo=l("Proporciona modelos modernos con rendimientos lo m\xE1s parecido posible a los modelos originales:"),Zo=i(),F=r("ul"),ge=r("li"),ea=l("Proporcionamos al menos un ejemplo para cada arquitectura que reproduce un resultado proporcionado por los autores de dicha arquitectura."),oa=i(),S=r("li"),aa=l(`El c\xF3digo normalmente es parecido al c\xF3digo base original, lo cual significa que alg\xFAn c\xF3digo Pytorch puede no ser tan
`),ye=r("em"),ra=l("pytorchic"),sa=l(" como podr\xEDa ser por haber sido convertido a c\xF3digo TensorFlow, y viceversa."),We=i(),oe=r("p"),ta=l("Unos cuantos objetivos adicionales:"),Xe=i(),b=r("ul"),H=r("li"),qe=r("p"),la=l("Exponer las caracter\xEDsticas internas de los modelos de la forma m\xE1s coherente posible:"),na=i(),B=r("ul"),Pe=r("li"),ia=l("Damos acceso, mediante una sola API, a todos los estados ocultos y pesos de atenci\xF3n."),da=i(),Le=r("li"),ca=l("Tokenizer y el modelo de API base est\xE1n estandarizados para cambiar f\xE1cilmente entre modelos."),ua=i(),K=r("li"),Ie=r("p"),pa=l("Incorporar una selecci\xF3n subjetiva de herramientas de gran potencial para la optimizaci\xF3n/investigaci\xF3n de estos modelos:"),ma=i(),G=r("ul"),we=r("li"),fa=l("Una forma sencilla/coherente de a\xF1adir nuevos tokens al vocabulario e incrustraciones (embeddings, en ingl\xE9s) para optimizaci\xF3n."),ha=i(),ze=r("li"),va=l("Formas sencillas de camuflar y reducir \u201Ctransformer heads\u201D."),_a=i(),ke=r("li"),Te=r("p"),ba=l("Cambiar f\xE1cilmente entre PyTorch y TensorFlow 2.0, permitiendo el entrenamiento usando un marco y la inferencia usando otro."),Ye=i(),P=r("h2"),z=r("a"),Ce=r("span"),Kr(R.$$.fragment),Ea=i(),Ae=r("span"),ga=l("Conceptos principales"),Ze=i(),ae=r("p"),ya=l("La biblioteca est\xE1 construida alrededor de tres tipos de clases para cada modelo:"),eo=i(),E=r("ul"),m=r("li"),$e=r("strong"),qa=l("Model classes"),Pa=l(" como "),je=r("code"),La=l("BertModel"),Ia=l(", que consisten en m\xE1s de 30 modelos PyTorch ("),Q=r("a"),wa=l("torch.nn.Module"),za=l(") o modelos Keras ("),J=r("a"),ka=l("tf.keras.Model"),Ta=l(`) que funcionan con pesos pre-entrenados proporcionados en la
biblioteca.`),Ca=i(),k=r("li"),Me=r("strong"),Aa=l("Configuration classes"),$a=l(" como "),Ne=r("code"),ja=l("BertConfig"),Ma=l(`, que almacena todos los par\xE1metros necesarios para construir un modelo.
No siempre tienes que generarla tu. En particular, si estas usando un modelo pre-entrenado sin ninguna modificaci\xF3n,
la creaci\xF3n del modelo se encargar\xE1 autom\xE1ticamente de generar la configuraci\xF3n (que es parte del modelo).`),Na=i(),T=r("li"),Oe=r("strong"),Oa=l("Tokenizer classes"),xa=l(" como "),xe=r("code"),Da=l("BertTokenizer"),Ua=l(`, que almacena el vocabulario para cada modelo y proporciona m\xE9todos para
codificar/decodificar strings en una lista de \xEDndices de \u201Ctoken embeddings\u201D para ser empleados en un modelo.`),oo=i(),re=r("p"),Fa=l("Todas estas clases pueden ser generadas a partir de ejemplos pre-entrenados, y guardados localmente usando dos m\xE9todos:"),ao=i(),C=r("ul"),A=r("li"),De=r("code"),Sa=l("from_pretrained()"),Ha=l(` permite generar un modelo/configuraci\xF3n/tokenizer a partir de una versi\xF3n pre-entrenada proporcionada ya sea por
la propia biblioteca (los modelos compatibles se pueden encontrar en `),V=r("a"),Ba=l("Model Hub"),Ka=l(`) o
guardados localmente (o en un servidor) por el usuario.`),Ga=i(),$=r("li"),Ue=r("code"),Ra=l("save_pretrained()"),Qa=l(` permite guardar un modelo/configuraci\xF3n/tokenizer localmente, de forma que puede ser empleado de nuevo usando
`),Fe=r("code"),Ja=l("from_pretrained()"),Va=l("."),this.h()},l(a){const c=es('[data-svelte="svelte-1phssyn"]',document.head);g=s(c,"META",{name:!0,content:!0}),c.forEach(o),Ge=d(a),y=s(a,"H1",{class:!0});var so=t(y);I=s(so,"A",{id:!0,class:!0,href:!0});var Xa=t(I);ie=s(Xa,"SPAN",{});var Ya=t(ie);Gr(O.$$.fragment,Ya),Ya.forEach(o),Xa.forEach(o),_o=d(so),de=s(so,"SPAN",{});var Za=t(de);bo=n(Za,"Filosof\xEDa"),Za.forEach(o),so.forEach(o),Re=d(a),W=s(a,"P",{});var er=t(W);Eo=n(er,"\u{1F917} Transformers es una biblioteca construida para:"),er.forEach(o),Qe=d(a),_=s(a,"UL",{});var se=t(_);ce=s(se,"LI",{});var or=t(ce);go=n(or,"Los investigadores y educadores de NLP que busquen usar/estudiar/extender modelos transformers a gran escala"),or.forEach(o),yo=d(se),ue=s(se,"LI",{});var ar=t(ue);qo=n(ar,"Profesionales que quieren optimizar esos modelos y/o ponerlos en producci\xF3n"),ar.forEach(o),Po=d(se),pe=s(se,"LI",{});var rr=t(pe);Lo=n(rr,"Ingenieros que solo quieren descargar un modelo preentrenado y usarlo para resolver una tarea NLP dada."),rr.forEach(o),se.forEach(o),Je=d(a),X=s(a,"P",{});var sr=t(X);Io=n(sr,"La biblioteca fue dise\xF1ada con dos fuertes objetivos en mente:"),sr.forEach(o),Ve=d(a),w=s(a,"UL",{});var to=t(w);x=s(to,"LI",{});var lo=t(x);me=s(lo,"P",{});var tr=t(me);wo=n(tr,"Que sea tan f\xE1cil y r\xE1pida de utilizar como sea posible:"),tr.forEach(o),zo=d(lo),f=s(lo,"UL",{});var j=t(f);h=s(j,"LI",{});var M=t(h);ko=n(M,`Hemos limitado enormemente el n\xFAmero de abstracciones que el usuario tiene que aprender. De hecho, no hay casi abstracciones,
solo tres clases est\xE1ndar necesarias para usar cada modelo: `),Y=s(M,"A",{href:!0});var lr=t(Y);To=n(lr,"configuration"),lr.forEach(o),Co=n(M,`,
`),Z=s(M,"A",{href:!0});var nr=t(Z);Ao=n(nr,"models"),nr.forEach(o),$o=n(M," y "),ee=s(M,"A",{href:!0});var ir=t(ee);jo=n(ir,"tokenizer"),ir.forEach(o),Mo=n(M,"."),M.forEach(o),No=d(j),q=s(j,"LI",{});var te=t(q);Oo=n(te,`Todas estas clases pueden ser inicializadas de forma simple y unificada a partir de ejemplos pre-entrenados mediante el uso de un m\xE9todo
`),fe=s(te,"CODE",{});var dr=t(fe);xo=n(dr,"from_pretrained()"),dr.forEach(o),Do=n(te,` com\xFAn de solicitud que se encargar\xE1 de descargar (si es necesario), almacenar y cargar la solicitud de clase relacionada y datos asociados
(configurations\u2019 hyper-parameters, tokenizers\u2019 vocabulary, and models\u2019 weights) a partir de un control pre-entrenado proporcionado en
`),D=s(te,"A",{href:!0,rel:!0});var cr=t(D);Uo=n(cr,"Hugging Face Hub"),cr.forEach(o),Fo=n(te," o de tu propio control guardado."),te.forEach(o),So=d(j),v=s(j,"LI",{});var N=t(v);Ho=n(N,"Por encima de esas tres clases est\xE1ndar, la biblioteca proporciona dos APIs: "),he=s(N,"CODE",{});var ur=t(he);Bo=n(ur,"pipeline()"),ur.forEach(o),Ko=n(N,` para usar r\xE1pidamente un modelo (junto a su configuracion y tokenizer asociados)
sobre una tarea dada, y `),ve=s(N,"CODE",{});var pr=t(ve);Go=n(pr,"Trainer"),pr.forEach(o),Ro=n(N,"/"),_e=s(N,"CODE",{});var mr=t(_e);Qo=n(mr,"Keras.fit"),mr.forEach(o),Jo=n(N," para entrenar u optimizar de forma r\xE1pida un modelo dado."),N.forEach(o),Vo=d(j),be=s(j,"LI",{});var fr=t(be);Wo=n(fr,`Como consecuencia, esta biblioteca NO es una caja de herramientas modular de bloques individuales para redes neuronales. Si quieres extender/construir sobre la biblioteca,
usa simplemente los m\xF3dulos regulares de Python/PyTorch/TensorFlow/Keras y emplea las clases est\xE1ndar de la biblioteca como punto de partida para reutilizar funcionalidades
tales como abrir/guardar modelo.`),fr.forEach(o),j.forEach(o),lo.forEach(o),Xo=d(to),U=s(to,"LI",{});var no=t(U);Ee=s(no,"P",{});var hr=t(Ee);Yo=n(hr,"Proporciona modelos modernos con rendimientos lo m\xE1s parecido posible a los modelos originales:"),hr.forEach(o),Zo=d(no),F=s(no,"UL",{});var io=t(F);ge=s(io,"LI",{});var vr=t(ge);ea=n(vr,"Proporcionamos al menos un ejemplo para cada arquitectura que reproduce un resultado proporcionado por los autores de dicha arquitectura."),vr.forEach(o),oa=d(io),S=s(io,"LI",{});var co=t(S);aa=n(co,`El c\xF3digo normalmente es parecido al c\xF3digo base original, lo cual significa que alg\xFAn c\xF3digo Pytorch puede no ser tan
`),ye=s(co,"EM",{});var _r=t(ye);ra=n(_r,"pytorchic"),_r.forEach(o),sa=n(co," como podr\xEDa ser por haber sido convertido a c\xF3digo TensorFlow, y viceversa."),co.forEach(o),io.forEach(o),no.forEach(o),to.forEach(o),We=d(a),oe=s(a,"P",{});var br=t(oe);ta=n(br,"Unos cuantos objetivos adicionales:"),br.forEach(o),Xe=d(a),b=s(a,"UL",{});var le=t(b);H=s(le,"LI",{});var uo=t(H);qe=s(uo,"P",{});var Er=t(qe);la=n(Er,"Exponer las caracter\xEDsticas internas de los modelos de la forma m\xE1s coherente posible:"),Er.forEach(o),na=d(uo),B=s(uo,"UL",{});var po=t(B);Pe=s(po,"LI",{});var gr=t(Pe);ia=n(gr,"Damos acceso, mediante una sola API, a todos los estados ocultos y pesos de atenci\xF3n."),gr.forEach(o),da=d(po),Le=s(po,"LI",{});var yr=t(Le);ca=n(yr,"Tokenizer y el modelo de API base est\xE1n estandarizados para cambiar f\xE1cilmente entre modelos."),yr.forEach(o),po.forEach(o),uo.forEach(o),ua=d(le),K=s(le,"LI",{});var mo=t(K);Ie=s(mo,"P",{});var qr=t(Ie);pa=n(qr,"Incorporar una selecci\xF3n subjetiva de herramientas de gran potencial para la optimizaci\xF3n/investigaci\xF3n de estos modelos:"),qr.forEach(o),ma=d(mo),G=s(mo,"UL",{});var fo=t(G);we=s(fo,"LI",{});var Pr=t(we);fa=n(Pr,"Una forma sencilla/coherente de a\xF1adir nuevos tokens al vocabulario e incrustraciones (embeddings, en ingl\xE9s) para optimizaci\xF3n."),Pr.forEach(o),ha=d(fo),ze=s(fo,"LI",{});var Lr=t(ze);va=n(Lr,"Formas sencillas de camuflar y reducir \u201Ctransformer heads\u201D."),Lr.forEach(o),fo.forEach(o),mo.forEach(o),_a=d(le),ke=s(le,"LI",{});var Ir=t(ke);Te=s(Ir,"P",{});var wr=t(Te);ba=n(wr,"Cambiar f\xE1cilmente entre PyTorch y TensorFlow 2.0, permitiendo el entrenamiento usando un marco y la inferencia usando otro."),wr.forEach(o),Ir.forEach(o),le.forEach(o),Ye=d(a),P=s(a,"H2",{class:!0});var ho=t(P);z=s(ho,"A",{id:!0,class:!0,href:!0});var zr=t(z);Ce=s(zr,"SPAN",{});var kr=t(Ce);Gr(R.$$.fragment,kr),kr.forEach(o),zr.forEach(o),Ea=d(ho),Ae=s(ho,"SPAN",{});var Tr=t(Ae);ga=n(Tr,"Conceptos principales"),Tr.forEach(o),ho.forEach(o),Ze=d(a),ae=s(a,"P",{});var Cr=t(ae);ya=n(Cr,"La biblioteca est\xE1 construida alrededor de tres tipos de clases para cada modelo:"),Cr.forEach(o),eo=d(a),E=s(a,"UL",{});var ne=t(E);m=s(ne,"LI",{});var L=t(m);$e=s(L,"STRONG",{});var Ar=t($e);qa=n(Ar,"Model classes"),Ar.forEach(o),Pa=n(L," como "),je=s(L,"CODE",{});var $r=t(je);La=n($r,"BertModel"),$r.forEach(o),Ia=n(L,", que consisten en m\xE1s de 30 modelos PyTorch ("),Q=s(L,"A",{href:!0,rel:!0});var jr=t(Q);wa=n(jr,"torch.nn.Module"),jr.forEach(o),za=n(L,") o modelos Keras ("),J=s(L,"A",{href:!0,rel:!0});var Mr=t(J);ka=n(Mr,"tf.keras.Model"),Mr.forEach(o),Ta=n(L,`) que funcionan con pesos pre-entrenados proporcionados en la
biblioteca.`),L.forEach(o),Ca=d(ne),k=s(ne,"LI",{});var Se=t(k);Me=s(Se,"STRONG",{});var Nr=t(Me);Aa=n(Nr,"Configuration classes"),Nr.forEach(o),$a=n(Se," como "),Ne=s(Se,"CODE",{});var Or=t(Ne);ja=n(Or,"BertConfig"),Or.forEach(o),Ma=n(Se,`, que almacena todos los par\xE1metros necesarios para construir un modelo.
No siempre tienes que generarla tu. En particular, si estas usando un modelo pre-entrenado sin ninguna modificaci\xF3n,
la creaci\xF3n del modelo se encargar\xE1 autom\xE1ticamente de generar la configuraci\xF3n (que es parte del modelo).`),Se.forEach(o),Na=d(ne),T=s(ne,"LI",{});var He=t(T);Oe=s(He,"STRONG",{});var xr=t(Oe);Oa=n(xr,"Tokenizer classes"),xr.forEach(o),xa=n(He," como "),xe=s(He,"CODE",{});var Dr=t(xe);Da=n(Dr,"BertTokenizer"),Dr.forEach(o),Ua=n(He,`, que almacena el vocabulario para cada modelo y proporciona m\xE9todos para
codificar/decodificar strings en una lista de \xEDndices de \u201Ctoken embeddings\u201D para ser empleados en un modelo.`),He.forEach(o),ne.forEach(o),oo=d(a),re=s(a,"P",{});var Ur=t(re);Fa=n(Ur,"Todas estas clases pueden ser generadas a partir de ejemplos pre-entrenados, y guardados localmente usando dos m\xE9todos:"),Ur.forEach(o),ao=d(a),C=s(a,"UL",{});var vo=t(C);A=s(vo,"LI",{});var Be=t(A);De=s(Be,"CODE",{});var Fr=t(De);Sa=n(Fr,"from_pretrained()"),Fr.forEach(o),Ha=n(Be,` permite generar un modelo/configuraci\xF3n/tokenizer a partir de una versi\xF3n pre-entrenada proporcionada ya sea por
la propia biblioteca (los modelos compatibles se pueden encontrar en `),V=s(Be,"A",{href:!0,rel:!0});var Sr=t(V);Ba=n(Sr,"Model Hub"),Sr.forEach(o),Ka=n(Be,`) o
guardados localmente (o en un servidor) por el usuario.`),Be.forEach(o),Ga=d(vo),$=s(vo,"LI",{});var Ke=t($);Ue=s(Ke,"CODE",{});var Hr=t(Ue);Ra=n(Hr,"save_pretrained()"),Hr.forEach(o),Qa=n(Ke,` permite guardar un modelo/configuraci\xF3n/tokenizer localmente, de forma que puede ser empleado de nuevo usando
`),Fe=s(Ke,"CODE",{});var Br=t(Fe);Ja=n(Br,"from_pretrained()"),Br.forEach(o),Va=n(Ke,"."),Ke.forEach(o),vo.forEach(o),this.h()},h(){p(g,"name","hf:doc:metadata"),p(g,"content",JSON.stringify(ss)),p(I,"id","filosofa"),p(I,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(I,"href","#filosofa"),p(y,"class","relative group"),p(Y,"href","main_classes/configuration"),p(Z,"href","main_classes/model"),p(ee,"href","main_classes/tokenizer"),p(D,"href","https://huggingface.co/models"),p(D,"rel","nofollow"),p(z,"id","conceptos-principales"),p(z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(z,"href","#conceptos-principales"),p(P,"class","relative group"),p(Q,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),p(Q,"rel","nofollow"),p(J,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),p(J,"rel","nofollow"),p(V,"href","https://huggingface.co/models"),p(V,"rel","nofollow")},m(a,c){e(document.head,g),u(a,Ge,c),u(a,y,c),e(y,I),e(I,ie),Rr(O,ie,null),e(y,_o),e(y,de),e(de,bo),u(a,Re,c),u(a,W,c),e(W,Eo),u(a,Qe,c),u(a,_,c),e(_,ce),e(ce,go),e(_,yo),e(_,ue),e(ue,qo),e(_,Po),e(_,pe),e(pe,Lo),u(a,Je,c),u(a,X,c),e(X,Io),u(a,Ve,c),u(a,w,c),e(w,x),e(x,me),e(me,wo),e(x,zo),e(x,f),e(f,h),e(h,ko),e(h,Y),e(Y,To),e(h,Co),e(h,Z),e(Z,Ao),e(h,$o),e(h,ee),e(ee,jo),e(h,Mo),e(f,No),e(f,q),e(q,Oo),e(q,fe),e(fe,xo),e(q,Do),e(q,D),e(D,Uo),e(q,Fo),e(f,So),e(f,v),e(v,Ho),e(v,he),e(he,Bo),e(v,Ko),e(v,ve),e(ve,Go),e(v,Ro),e(v,_e),e(_e,Qo),e(v,Jo),e(f,Vo),e(f,be),e(be,Wo),e(w,Xo),e(w,U),e(U,Ee),e(Ee,Yo),e(U,Zo),e(U,F),e(F,ge),e(ge,ea),e(F,oa),e(F,S),e(S,aa),e(S,ye),e(ye,ra),e(S,sa),u(a,We,c),u(a,oe,c),e(oe,ta),u(a,Xe,c),u(a,b,c),e(b,H),e(H,qe),e(qe,la),e(H,na),e(H,B),e(B,Pe),e(Pe,ia),e(B,da),e(B,Le),e(Le,ca),e(b,ua),e(b,K),e(K,Ie),e(Ie,pa),e(K,ma),e(K,G),e(G,we),e(we,fa),e(G,ha),e(G,ze),e(ze,va),e(b,_a),e(b,ke),e(ke,Te),e(Te,ba),u(a,Ye,c),u(a,P,c),e(P,z),e(z,Ce),Rr(R,Ce,null),e(P,Ea),e(P,Ae),e(Ae,ga),u(a,Ze,c),u(a,ae,c),e(ae,ya),u(a,eo,c),u(a,E,c),e(E,m),e(m,$e),e($e,qa),e(m,Pa),e(m,je),e(je,La),e(m,Ia),e(m,Q),e(Q,wa),e(m,za),e(m,J),e(J,ka),e(m,Ta),e(E,Ca),e(E,k),e(k,Me),e(Me,Aa),e(k,$a),e(k,Ne),e(Ne,ja),e(k,Ma),e(E,Na),e(E,T),e(T,Oe),e(Oe,Oa),e(T,xa),e(T,xe),e(xe,Da),e(T,Ua),u(a,oo,c),u(a,re,c),e(re,Fa),u(a,ao,c),u(a,C,c),e(C,A),e(A,De),e(De,Sa),e(A,Ha),e(A,V),e(V,Ba),e(A,Ka),e(C,Ga),e(C,$),e($,Ue),e(Ue,Ra),e($,Qa),e($,Fe),e(Fe,Ja),e($,Va),ro=!0},p:os,i(a){ro||(Qr(O.$$.fragment,a),Qr(R.$$.fragment,a),ro=!0)},o(a){Jr(O.$$.fragment,a),Jr(R.$$.fragment,a),ro=!1},d(a){o(g),a&&o(Ge),a&&o(y),Vr(O),a&&o(Re),a&&o(W),a&&o(Qe),a&&o(_),a&&o(Je),a&&o(X),a&&o(Ve),a&&o(w),a&&o(We),a&&o(oe),a&&o(Xe),a&&o(b),a&&o(Ye),a&&o(P),Vr(R),a&&o(Ze),a&&o(ae),a&&o(eo),a&&o(E),a&&o(oo),a&&o(re),a&&o(ao),a&&o(C)}}}const ss={local:"filosofa",sections:[{local:"conceptos-principales",title:"Conceptos principales "}],title:"Filosof\xEDa"};function ts(Wa){return as(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class is extends Xr{constructor(g){super();Yr(this,g,ts,rs,Zr,{})}}export{is as default,ss as metadata};
