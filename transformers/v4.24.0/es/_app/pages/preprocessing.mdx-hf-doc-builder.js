import{S as Sj,i as Lj,s as Nj,e as n,k as c,t as r,c as t,a as l,m as i,h as o,d as e,b as d,g as u,G as a,Q as Go,q as _,l as nv,n as eu,o as g,B as k,p as nu,w as x,y,j as hv,K as fv,U as pv,x as w,V as bv,T as jv,Y as cv,Z as iv,M as _v,N as tv,v as gv}from"../chunks/vendor-hf-doc-builder.js";import{T as vv}from"../chunks/Tip-hf-doc-builder.js";import{Y as Ev}from"../chunks/Youtube-hf-doc-builder.js";import{I as R}from"../chunks/IconCopyLink-hf-doc-builder.js";import{a as uv,C as O}from"../chunks/CodeBlock-hf-doc-builder.js";import{b as dv,I as $v,a as kv}from"../chunks/IconTensorflow-hf-doc-builder.js";import{D as xv}from"../chunks/DocNotebookDropdown-hf-doc-builder.js";function lv(T,m,f){const b=T.slice();return b[8]=m[f],b[10]=f,b}function rv(T){let m,f,b;var v=T[8].icon;function j(q){return{props:{classNames:"mr-1.5"}}}return v&&(m=new v(j())),{c(){m&&x(m.$$.fragment),f=nv()},l(q){m&&w(m.$$.fragment,q),f=nv()},m(q,E){m&&y(m,q,E),u(q,f,E),b=!0},p(q,E){if(v!==(v=q[8].icon)){if(m){eu();const $=m;g($.$$.fragment,1,0,()=>{k($,1)}),nu()}v?(m=new v(j()),x(m.$$.fragment),_(m.$$.fragment,1),y(m,f.parentNode,f)):m=null}},i(q){b||(m&&_(m.$$.fragment,q),b=!0)},o(q){m&&g(m.$$.fragment,q),b=!1},d(q){q&&e(f),m&&k(m,q)}}}function ov(T){let m,f,b,v=T[8].name+"",j,q,E,$,h,z,D,A=T[8].icon&&rv(T);function Zs(){return T[6](T[8])}return{c(){m=n("button"),A&&A.c(),f=c(),b=n("p"),j=r(v),E=c(),this.h()},l(H){m=t(H,"BUTTON",{class:!0});var S=l(m);A&&A.l(S),f=i(S),b=t(S,"P",{class:!0});var U=l(b);j=o(U,v),U.forEach(e),E=i(S),S.forEach(e),this.h()},h(){d(b,"class",q="!m-0 "+T[8].classNames),d(m,"class",$="flex justify-center py-1.5 px-2.5 focus:outline-none rounded-"+(T[10]?"r":"l")+" "+(T[8].group!==T[1]&&"text-gray-500 filter grayscale"))},m(H,S){u(H,m,S),A&&A.m(m,null),a(m,f),a(m,b),a(b,j),a(m,E),h=!0,z||(D=Go(m,"click",Zs),z=!0)},p(H,S){T=H,T[8].icon?A?(A.p(T,S),S&1&&_(A,1)):(A=rv(T),A.c(),_(A,1),A.m(m,f)):A&&(eu(),g(A,1,1,()=>{A=null}),nu()),(!h||S&1)&&v!==(v=T[8].name+"")&&hv(j,v),(!h||S&1&&q!==(q="!m-0 "+T[8].classNames))&&d(b,"class",q),(!h||S&3&&$!==($="flex justify-center py-1.5 px-2.5 focus:outline-none rounded-"+(T[10]?"r":"l")+" "+(T[8].group!==T[1]&&"text-gray-500 filter grayscale")))&&d(m,"class",$)},i(H){h||(_(A),h=!0)},o(H){g(A),h=!1},d(H){H&&e(m),A&&A.d(),z=!1,D()}}}function yv(T){let m,f,b,v=T[3].filter(T[5]),j=[];for(let E=0;E<v.length;E+=1)j[E]=ov(lv(T,v,E));const q=E=>g(j[E],1,1,()=>{j[E]=null});return{c(){m=n("div"),f=n("div");for(let E=0;E<j.length;E+=1)j[E].c();this.h()},l(E){m=t(E,"DIV",{});var $=l(m);f=t($,"DIV",{class:!0});var h=l(f);for(let z=0;z<j.length;z+=1)j[z].l(h);h.forEach(e),$.forEach(e),this.h()},h(){d(f,"class","bg-white leading-none border border-gray-100 rounded-lg inline-flex p-0.5 text-sm mb-4 select-none")},m(E,$){u(E,m,$),a(m,f);for(let h=0;h<j.length;h+=1)j[h].m(f,null);b=!0},p(E,[$]){if($&27){v=E[3].filter(E[5]);let h;for(h=0;h<v.length;h+=1){const z=lv(E,v,h);j[h]?(j[h].p(z,$),_(j[h],1)):(j[h]=ov(z),j[h].c(),_(j[h],1),j[h].m(f,null))}for(eu(),h=v.length;h<j.length;h+=1)q(h);nu()}},i(E){if(!b){for(let $=0;$<v.length;$+=1)_(j[$]);b=!0}},o(E){j=j.filter(Boolean);for(let $=0;$<j.length;$+=1)g(j[$]);b=!1},d(E){E&&e(m),fv(j,E)}}}function wv(T,m,f){let b,{ids:v}=m;const j=v.join("-"),q=dv(j);pv(T,q,D=>f(1,b=D));const E=[{id:"pt",classNames:"",icon:$v,name:"Pytorch",group:"group1"},{id:"tf",classNames:"",icon:kv,name:"TensorFlow",group:"group2"},{id:"stringapi",classNames:"text-blue-600",name:"String API",group:"group1"},{id:"readinstruction",classNames:"text-blue-600",name:"ReadInstruction",group:"group2"}];function $(D){bv(q,b=D,b)}const h=D=>v.includes(D.id),z=D=>$(D.group);return T.$$set=D=>{"ids"in D&&f(0,v=D.ids)},[v,b,q,E,$,h,z]}class mv extends Sj{constructor(m){super();Lj(this,m,wv,yv,Nj,{ids:0})}}function qv(T){let m,f,b,v,j,q,E=T[1].highlighted+"",$;return f=new uv({props:{classNames:"transition duration-200 ease-in-out "+(T[2]&&"opacity-0"),title:"Copy code excerpt to clipboard",value:T[1].code}}),j=new mv({props:{ids:T[4]}}),{c(){m=n("div"),x(f.$$.fragment),b=c(),v=n("pre"),x(j.$$.fragment),q=new cv,this.h()},l(h){m=t(h,"DIV",{class:!0});var z=l(m);w(f.$$.fragment,z),z.forEach(e),b=i(h),v=t(h,"PRE",{});var D=l(v);w(j.$$.fragment,D),q=iv(D),D.forEach(e),this.h()},h(){d(m,"class","absolute top-2.5 right-4"),q.a=null},m(h,z){u(h,m,z),y(f,m,null),u(h,b,z),u(h,v,z),y(j,v,null),q.m(E,v),$=!0},p(h,z){const D={};z&4&&(D.classNames="transition duration-200 ease-in-out "+(h[2]&&"opacity-0")),z&2&&(D.value=h[1].code),f.$set(D),(!$||z&2)&&E!==(E=h[1].highlighted+"")&&q.p(E)},i(h){$||(_(f.$$.fragment,h),_(j.$$.fragment,h),$=!0)},o(h){g(f.$$.fragment,h),g(j.$$.fragment,h),$=!1},d(h){h&&e(m),k(f),h&&e(b),h&&e(v),k(j)}}}function Tv(T){let m,f,b,v,j,q,E=T[0].highlighted+"",$;return f=new uv({props:{classNames:"transition duration-200 ease-in-out "+(T[2]&&"opacity-0"),title:"Copy code excerpt to clipboard",value:T[0].code}}),j=new mv({props:{ids:T[4]}}),{c(){m=n("div"),x(f.$$.fragment),b=c(),v=n("pre"),x(j.$$.fragment),q=new cv,this.h()},l(h){m=t(h,"DIV",{class:!0});var z=l(m);w(f.$$.fragment,z),z.forEach(e),b=i(h),v=t(h,"PRE",{});var D=l(v);w(j.$$.fragment,D),q=iv(D),D.forEach(e),this.h()},h(){d(m,"class","absolute top-2.5 right-4"),q.a=null},m(h,z){u(h,m,z),y(f,m,null),u(h,b,z),u(h,v,z),y(j,v,null),q.m(E,v),$=!0},p(h,z){const D={};z&4&&(D.classNames="transition duration-200 ease-in-out "+(h[2]&&"opacity-0")),z&1&&(D.value=h[0].code),f.$set(D),(!$||z&1)&&E!==(E=h[0].highlighted+"")&&q.p(E)},i(h){$||(_(f.$$.fragment,h),_(j.$$.fragment,h),$=!0)},o(h){g(f.$$.fragment,h),g(j.$$.fragment,h),$=!1},d(h){h&&e(m),k(f),h&&e(b),h&&e(v),k(j)}}}function zv(T){let m,f,b,v,j,q;const E=[Tv,qv],$=[];function h(z,D){return z[3]==="group1"?0:1}return f=h(T),b=$[f]=E[f](T),{c(){m=n("div"),b.c(),this.h()},l(z){m=t(z,"DIV",{class:!0});var D=l(m);b.l(D),D.forEach(e),this.h()},h(){d(m,"class","code-block relative")},m(z,D){u(z,m,D),$[f].m(m,null),v=!0,j||(q=[Go(m,"mouseover",T[6]),Go(m,"focus",T[6]),Go(m,"mouseout",T[7]),Go(m,"focus",T[7])],j=!0)},p(z,[D]){let A=f;f=h(z),f===A?$[f].p(z,D):(eu(),g($[A],1,1,()=>{$[A]=null}),nu(),b=$[f],b?b.p(z,D):(b=$[f]=E[f](z),b.c()),_(b,1),b.m(m,null))},i(z){v||(_(b),v=!0)},o(z){g(b),v=!1},d(z){z&&e(m),$[f].d(),j=!1,jv(q)}}}function Dv(T,m,f){let b,{group1:v}=m,{group2:j}=m;const q=[v.id,j.id],E=q.join("-"),$=dv(E);pv(T,$,A=>f(3,b=A));let h=!0;function z(){f(2,h=!1)}function D(){f(2,h=!0)}return T.$$set=A=>{"group1"in A&&f(0,v=A.group1),"group2"in A&&f(1,j=A.group2)},[v,j,h,b,q,$,z,D]}class Pv extends Sj{constructor(m){super();Lj(this,m,Dv,zv,Nj,{group1:0,group2:1})}}function Cv(T){let m,f,b,v,j;return{c(){m=n("p"),f=r("Si tienes previsto utilizar un modelo pre-entrenado, es importante que utilices el tokenizador pre-entrenado asociado. Esto te asegura que el texto se divide de la misma manera que el corpus de pre-entrenamiento y utiliza el mismo \xEDndice de tokens correspondiente (usualmente referido como el "),b=n("em"),v=r("vocab"),j=r(") durante el pre-entrenamiento.")},l(q){m=t(q,"P",{});var E=l(m);f=o(E,"Si tienes previsto utilizar un modelo pre-entrenado, es importante que utilices el tokenizador pre-entrenado asociado. Esto te asegura que el texto se divide de la misma manera que el corpus de pre-entrenamiento y utiliza el mismo \xEDndice de tokens correspondiente (usualmente referido como el "),b=t(E,"EM",{});var $=l(b);v=o($,"vocab"),$.forEach(e),j=o(E,") durante el pre-entrenamiento."),E.forEach(e)},m(q,E){u(q,m,E),a(m,f),a(m,b),a(b,v),a(m,j)},d(q){q&&e(m)}}}function Av(T){let m,f,b,v,j,q,E,$,h,z,D,A,Zs,H,S,U,Nt,tu,lu,Rt,ru,ou,It,pu,Jo,ms,Xs,Ht,La,cu,Ut,iu,Vo,Na,Yo,Q,uu,ln,du,mu,Ft,hu,fu,Mo,sa,Wo,Z,bu,Bt,ju,_u,Gt,gu,vu,Ko,hs,aa,Jt,Ra,Eu,Vt,$u,Qo,ea,ku,Yt,xu,yu,Zo,Ia,Xo,rn,wu,sp,Ha,ap,on,qu,ep,X,pn,cn,Tu,zu,Du,un,dn,Pu,Cu,Au,mn,hn,Ou,Su,np,na,Lu,Mt,Nu,Ru,tp,Ua,lp,ss,Iu,Wt,Hu,Uu,Kt,Fu,Bu,rp,fn,Gu,op,Fa,pp,fs,ta,Qt,Ba,Ju,Zt,Vu,cp,bn,Yu,ip,as,Mu,Xt,Wu,Ku,sl,Qu,Zu,up,Ga,dp,jn,Xu,mp,bs,la,al,Ja,sd,el,ad,hp,_n,ed,fp,es,nd,nl,td,ld,tl,rd,od,bp,Va,jp,js,ra,ll,Ya,pd,rl,cd,_p,gn,id,gp,B,ud,ol,dd,md,pl,hd,fd,cl,bd,jd,vp,Ma,Ep,_s,oa,il,Wa,_d,ul,gd,$p,pa,vd,vn,Ed,$d,kp,Ka,xp,ns,kd,Qa,xd,yd,Za,wd,qd,yp,Xa,wp,ts,Td,dl,zd,Dd,ml,Pd,Cd,qp,se,Tp,En,Ad,zp,ls,$n,hl,Od,Sd,Ld,kn,fl,Nd,Rd,Id,xn,bl,Hd,Ud,Dp,gs,ca,jl,ae,Fd,_l,Bd,Pp,ia,Gd,ee,Jd,Vd,Cp,ua,Yd,ne,Md,Wd,Ap,te,Op,yn,le,Kd,re,gl,Qd,Zd,Sp,oe,Lp,pe,vl,Xd,Np,ce,Rp,da,sm,El,am,em,Ip,vs,ma,$l,ie,nm,kl,tm,Hp,wn,lm,Up,ha,rm,xl,om,pm,Fp,ue,Bp,rs,cm,yl,im,um,wl,dm,mm,Gp,de,Jp,Es,fa,ql,me,hm,Tl,fm,Vp,qn,bm,Yp,he,Mp,ba,jm,zl,_m,gm,Wp,fe,Kp,Tn,vm,Qp,be,Zp,zn,Em,Xp,je,sc,Dn,$m,ac,$s,ja,Dl,_e,km,Pl,xm,ec,Pn,ym,nc,os,wm,ge,qm,Tm,Cl,zm,Dm,tc,ve,lc,_a,Pm,Ee,Al,Cm,Am,rc,$e,oc,Cn,An,Rj,pc,ks,ga,Ol,ke,Om,Sl,Sm,cc,va,Lm,Ll,Nm,Rm,ic,xe,uc,xs,Ea,Nl,ye,Im,Rl,Hm,dc,$a,Um,we,Il,Fm,Bm,mc,On,M,Gm,qe,Hl,Jm,Vm,Te,Ul,Ym,Mm,ze,Fl,Wm,Km,hc,De,fc,Pe,ys,Qm,Sn,Bl,Zm,Xm,Gl,sh,ah,bc,Ce,jc,Ae,Oe,eh,Se,Jl,nh,th,_c,Le,gc,Ne,Re,lh,Vl,rh,oh,vc,Ie,Ec,Ln,ph,$c,He,kc,Nn,Rn,Ij,xc,ws,ka,Yl,Ue,ch,Ml,ih,yc,In,uh,wc,xa,Wl,dh,mh,Kl,hh,qc,ya,fh,Fe,bh,jh,Tc,Be,zc,ps,_h,Ql,gh,vh,Zl,Eh,$h,Dc,Ge,Pc,cs,kh,Xl,xh,yh,sr,wh,qh,Cc,Je,Ac,wa,Th,Hn,zh,Dh,Oc,Ve,Sc,qs,qa,ar,Ye,Ph,er,Ch,Lc,Un,Ah,Nc,Me,Rc,Fn,Ts,Oh,nr,Sh,Lh,tr,Nh,Rh,Ic,We,Hc,Ke,Qe,Ih,lr,Hh,Uh,Uc,Ze,Fc,is,Fh,rr,Bh,Gh,or,Jh,Vh,Bc,Bn,Yh,Gc,zs,Ta,pr,Xe,Mh,cr,Wh,Jc,G,Kh,ir,Qh,Zh,ur,Xh,sf,dr,af,ef,Vc,us,sn,Gn,mr,nf,tf,lf,an,za,hr,rf,of,fr,pf,cf,uf,L,br,df,mf,jr,hf,ff,_r,bf,jf,gr,_f,gf,vr,vf,Ef,Er,$f,kf,xf,en,Jn,$r,yf,wf,qf,W,I,kr,Tf,zf,xr,Df,Pf,yr,Cf,Af,wr,Of,Sf,qr,Lf,Nf,Rf,J,Tr,If,Hf,zr,Uf,Ff,Dr,Bf,Gf,Pr,Jf,Vf,Yf,V,Cr,Mf,Wf,Ar,Kf,Qf,Or,Zf,Xf,Sr,sb,ab,eb,Da,Lr,nb,tb,Nr,lb,rb,ob,Rr,ds,Ir,pb,cb,Hr,ib,ub,Ur,db,mb,Yc,N,hb,Fr,fb,bb,Br,jb,_b,Gr,gb,vb,Jr,Eb,$b,Vr,kb,xb,Mc,Pa,Yr,Ds,Mr,yb,wb,Wr,qb,Tb,Kr,zb,Db,P,Ps,Qr,Pb,Cb,Zr,Ab,Ob,Xr,so,Sb,Lb,Cs,Wc,Nb,ao,Rb,Ib,Vn,eo,Hb,Ub,Fb,As,Kc,Bb,Qc,Gb,no,to,Jb,Vb,Os,Zc,Yb,lo,Mb,Wb,ro,oo,Kb,Qb,Ss,Xc,Zb,po,Xb,s1,co,io,a1,e1,Ls,uo,n1,t1,mo,l1,r1,Yn,ho,o1,p1,c1,Ns,si,i1,ai,u1,fo,bo,d1,m1,Rs,ei,h1,jo,f1,b1,Mn,_o,j1,_1,g1,Is,ni,v1,ti,E1,go,vo,$1,k1,Hs,li,x1,Eo,y1,w1,Wn,$o,q1,T1,z1,Us,ri,D1,oi,P1,ko,xo,C1,A1,Fs,pi,O1,yo,S1,L1,wo,N1,R1,Bs,qo,I1,H1,To,U1,F1,Kn,zo,B1,G1,J1,Gs,ci,V1,ii,Y1,Do,Po,M1,W1,Js,ui,K1,Co,Q1,Z1,Qn,Ao,X1,sj,aj,Vs,di,ej,mi,nj,Oo,So,tj,lj,Ys,hi,rj,Lo,oj,pj,No,cj,ij,Ms,fi,uj,Ro,dj,mj,Zn,Io,hj,fj,bj,Ws,bi,jj,ji,_j,Ho,Uo,gj,_i;return q=new R({}),D=new xv({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/es/preprocessing.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/es/pytorch/preprocessing.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/es/tensorflow/preprocessing.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/es/preprocessing.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/es/pytorch/preprocessing.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/es/tensorflow/preprocessing.ipynb"}]}}),La=new R({}),Na=new Ev({props:{id:"Yffk5aydLzg"}}),sa=new vv({props:{$$slots:{default:[Cv]},$$scope:{ctx:T}}}),Ra=new R({}),Ia=new O({props:{code:`from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)`}}),Ha=new O({props:{code:`encoded_input = tokenizer("Do not meddle in the affairs of wizards, for they are subtle and quick to anger.")
print(encoded_input)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_input = tokenizer(<span class="hljs-string">&quot;Do not meddle in the affairs of wizards, for they are subtle and quick to anger.&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoded_input)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">2079</span>, <span class="hljs-number">2025</span>, <span class="hljs-number">19960</span>, <span class="hljs-number">10362</span>, <span class="hljs-number">1999</span>, <span class="hljs-number">1996</span>, <span class="hljs-number">3821</span>, <span class="hljs-number">1997</span>, <span class="hljs-number">16657</span>, <span class="hljs-number">1010</span>, <span class="hljs-number">2005</span>, <span class="hljs-number">2027</span>, <span class="hljs-number">2024</span>, <span class="hljs-number">11259</span>, <span class="hljs-number">1998</span>, <span class="hljs-number">4248</span>, <span class="hljs-number">2000</span>, <span class="hljs-number">4963</span>, <span class="hljs-number">1012</span>, <span class="hljs-number">102</span>], 
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`}}),Ua=new O({props:{code:'tokenizer.decode(encoded_input["input_ids"])',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.decode(encoded_input[<span class="hljs-string">&quot;input_ids&quot;</span>])
<span class="hljs-string">&#x27;[CLS] Do not meddle in the affairs of wizards, for they are subtle and quick to anger. [SEP]&#x27;</span>`}}),Fa=new O({props:{code:`batch_sentences = [
    "But what about second breakfast?",
    "Don't think he knows about second breakfast, Pip.",
    "What about elevensies?",
]
encoded_inputs = tokenizer(batch_sentences)
print(encoded_inputs)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>batch_sentences = [
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;But what about second breakfast?&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Don&#x27;t think he knows about second breakfast, Pip.&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;What about elevensies?&quot;</span>,
<span class="hljs-meta">... </span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_inputs = tokenizer(batch_sentences)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoded_inputs)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [[<span class="hljs-number">101</span>, <span class="hljs-number">1252</span>, <span class="hljs-number">1184</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">1248</span>, <span class="hljs-number">6462</span>, <span class="hljs-number">136</span>, <span class="hljs-number">102</span>], 
               [<span class="hljs-number">101</span>, <span class="hljs-number">1790</span>, <span class="hljs-number">112</span>, <span class="hljs-number">189</span>, <span class="hljs-number">1341</span>, <span class="hljs-number">1119</span>, <span class="hljs-number">3520</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">1248</span>, <span class="hljs-number">6462</span>, <span class="hljs-number">117</span>, <span class="hljs-number">21902</span>, <span class="hljs-number">1643</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>], 
               [<span class="hljs-number">101</span>, <span class="hljs-number">1327</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">5450</span>, <span class="hljs-number">23434</span>, <span class="hljs-number">136</span>, <span class="hljs-number">102</span>]], 
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
                    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
                    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]], 
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], 
                    [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], 
                    [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]]}`}}),Ba=new R({}),Ga=new O({props:{code:`batch_sentences = [
    "But what about second breakfast?",
    "Don't think he knows about second breakfast, Pip.",
    "What about elevensies?",
]
encoded_input = tokenizer(batch_sentences, padding=True)
print(encoded_input)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>batch_sentences = [
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;But what about second breakfast?&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Don&#x27;t think he knows about second breakfast, Pip.&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;What about elevensies?&quot;</span>,
<span class="hljs-meta">... </span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_input = tokenizer(batch_sentences, padding=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoded_input)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [[<span class="hljs-number">101</span>, <span class="hljs-number">1252</span>, <span class="hljs-number">1184</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">1248</span>, <span class="hljs-number">6462</span>, <span class="hljs-number">136</span>, <span class="hljs-number">102</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
               [<span class="hljs-number">101</span>, <span class="hljs-number">1790</span>, <span class="hljs-number">112</span>, <span class="hljs-number">189</span>, <span class="hljs-number">1341</span>, <span class="hljs-number">1119</span>, <span class="hljs-number">3520</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">1248</span>, <span class="hljs-number">6462</span>, <span class="hljs-number">117</span>, <span class="hljs-number">21902</span>, <span class="hljs-number">1643</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>], 
               [<span class="hljs-number">101</span>, <span class="hljs-number">1327</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">5450</span>, <span class="hljs-number">23434</span>, <span class="hljs-number">136</span>, <span class="hljs-number">102</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]], 
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
                    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
                    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]], 
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
                    [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], 
                    [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]]}`}}),Ja=new R({}),Va=new O({props:{code:`batch_sentences = [
    "But what about second breakfast?",
    "Don't think he knows about second breakfast, Pip.",
    "What about elevensies?",
]
encoded_input = tokenizer(batch_sentences, padding=True, truncation=True)
print(encoded_input)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>batch_sentences = [
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;But what about second breakfast?&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Don&#x27;t think he knows about second breakfast, Pip.&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;What about elevensies?&quot;</span>,
<span class="hljs-meta">... </span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_input = tokenizer(batch_sentences, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoded_input)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [[<span class="hljs-number">101</span>, <span class="hljs-number">1252</span>, <span class="hljs-number">1184</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">1248</span>, <span class="hljs-number">6462</span>, <span class="hljs-number">136</span>, <span class="hljs-number">102</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
               [<span class="hljs-number">101</span>, <span class="hljs-number">1790</span>, <span class="hljs-number">112</span>, <span class="hljs-number">189</span>, <span class="hljs-number">1341</span>, <span class="hljs-number">1119</span>, <span class="hljs-number">3520</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">1248</span>, <span class="hljs-number">6462</span>, <span class="hljs-number">117</span>, <span class="hljs-number">21902</span>, <span class="hljs-number">1643</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>], 
               [<span class="hljs-number">101</span>, <span class="hljs-number">1327</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">5450</span>, <span class="hljs-number">23434</span>, <span class="hljs-number">136</span>, <span class="hljs-number">102</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]], 
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
                    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
                    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]], 
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
                    [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], 
                    [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]]}`}}),Ya=new R({}),Ma=new Pv({props:{group1:{id:"pt",code:`batch_sentences = [
    "But what about second breakfast?",
    "Don't think he knows about second breakfast, Pip.",
    "What about elevensies?",
]
encoded_input = tokenizer(batch, padding=True, truncation=True, return_tensors="pt")
print(encoded_input)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>batch_sentences = [
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;But what about second breakfast?&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Don&#x27;t think he knows about second breakfast, Pip.&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;What about elevensies?&quot;</span>,
<span class="hljs-meta">... </span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_input = tokenizer(batch, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoded_input)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: tensor([[  <span class="hljs-number">101</span>,   <span class="hljs-number">153</span>,  <span class="hljs-number">7719</span>, <span class="hljs-number">21490</span>,  <span class="hljs-number">1122</span>,  <span class="hljs-number">1114</span>,  <span class="hljs-number">9582</span>,  <span class="hljs-number">1623</span>,   <span class="hljs-number">102</span>],
                      [  <span class="hljs-number">101</span>,  <span class="hljs-number">5226</span>,  <span class="hljs-number">1122</span>,  <span class="hljs-number">9649</span>,  <span class="hljs-number">1199</span>,  <span class="hljs-number">2610</span>,  <span class="hljs-number">1236</span>,   <span class="hljs-number">102</span>,     <span class="hljs-number">0</span>]]), 
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: tensor([[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
                           [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]]), 
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
                           [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>]])}`},group2:{id:"tf",code:`batch_sentences = [
    "But what about second breakfast?",
    "Don't think he knows about second breakfast, Pip.",
    "What about elevensies?",
]
encoded_input = tokenizer(batch, padding=True, truncation=True, return_tensors="tf")
print(encoded_input)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>batch_sentences = [
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;But what about second breakfast?&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Don&#x27;t think he knows about second breakfast, Pip.&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;What about elevensies?&quot;</span>,
<span class="hljs-meta">... </span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_input = tokenizer(batch, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoded_input)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: &lt;tf.Tensor: shape=(<span class="hljs-number">2</span>, <span class="hljs-number">9</span>), dtype=int32, numpy=
array([[  <span class="hljs-number">101</span>,   <span class="hljs-number">153</span>,  <span class="hljs-number">7719</span>, <span class="hljs-number">21490</span>,  <span class="hljs-number">1122</span>,  <span class="hljs-number">1114</span>,  <span class="hljs-number">9582</span>,  <span class="hljs-number">1623</span>,   <span class="hljs-number">102</span>],
       [  <span class="hljs-number">101</span>,  <span class="hljs-number">5226</span>,  <span class="hljs-number">1122</span>,  <span class="hljs-number">9649</span>,  <span class="hljs-number">1199</span>,  <span class="hljs-number">2610</span>,  <span class="hljs-number">1236</span>,   <span class="hljs-number">102</span>,     <span class="hljs-number">0</span>]],
      dtype=int32)&gt;, 
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: &lt;tf.Tensor: shape=(<span class="hljs-number">2</span>, <span class="hljs-number">9</span>), dtype=int32, numpy=
array([[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
       [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]], dtype=int32)&gt;, 
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: &lt;tf.Tensor: shape=(<span class="hljs-number">2</span>, <span class="hljs-number">9</span>), dtype=int32, numpy=
array([[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
       [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>]], dtype=int32)&gt;}`}}}),Wa=new R({}),Ka=new O({props:{code:"pip install datasets",highlighted:"pip install datasets"}}),Xa=new O({props:{code:`from datasets import load_dataset, Audio

dataset = load_dataset("superb", "ks")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Audio

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;superb&quot;</span>, <span class="hljs-string">&quot;ks&quot;</span>)`}}),se=new O({props:{code:'dataset["train"][0]["audio"]',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>]
{<span class="hljs-string">&#x27;array&#x27;</span>: array([ <span class="hljs-number">0.</span>        ,  <span class="hljs-number">0.</span>        ,  <span class="hljs-number">0.</span>        , ..., -<span class="hljs-number">0.00592041</span>,
        -<span class="hljs-number">0.00405884</span>, -<span class="hljs-number">0.00253296</span>], dtype=float32),
 <span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/05734a36d88019a09725c20cc024e1c4e7982e37d7d55c0c1ca1742ea1cdd47f/_background_noise_/doing_the_dishes.wav&#x27;</span>,
 <span class="hljs-string">&#x27;sampling_rate&#x27;</span>: <span class="hljs-number">16000</span>}`}}),ae=new R({}),te=new O({props:{code:`lj_speech = load_dataset("lj_speech", split="train")
lj_speech[0]["audio"]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>lj_speech = load_dataset(<span class="hljs-string">&quot;lj_speech&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>lj_speech[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>]
{<span class="hljs-string">&#x27;array&#x27;</span>: array([-<span class="hljs-number">7.3242188e-04</span>, -<span class="hljs-number">7.6293945e-04</span>, -<span class="hljs-number">6.4086914e-04</span>, ...,
         <span class="hljs-number">7.3242188e-04</span>,  <span class="hljs-number">2.1362305e-04</span>,  <span class="hljs-number">6.1035156e-05</span>], dtype=float32),
 <span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/917ece08c95cf0c4115e45294e3cd0dee724a1165b7fc11798369308a465bd26/LJSpeech-1.1/wavs/LJ001-0001.wav&#x27;</span>,
 <span class="hljs-string">&#x27;sampling_rate&#x27;</span>: <span class="hljs-number">22050</span>}`}}),oe=new O({props:{code:'lj_speech = lj_speech.cast_column("audio", Audio(sampling_rate=16_000))',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>lj_speech = lj_speech.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=<span class="hljs-number">16_000</span>))'}}),ce=new O({props:{code:'lj_speech[0]["audio"]',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>lj_speech[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>]
{<span class="hljs-string">&#x27;array&#x27;</span>: array([-<span class="hljs-number">0.00064146</span>, -<span class="hljs-number">0.00074657</span>, -<span class="hljs-number">0.00068768</span>, ...,  <span class="hljs-number">0.00068341</span>,
         <span class="hljs-number">0.00014045</span>,  <span class="hljs-number">0.</span>        ], dtype=float32),
 <span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/917ece08c95cf0c4115e45294e3cd0dee724a1165b7fc11798369308a465bd26/LJSpeech-1.1/wavs/LJ001-0001.wav&#x27;</span>,
 <span class="hljs-string">&#x27;sampling_rate&#x27;</span>: <span class="hljs-number">16000</span>}`}}),ie=new R({}),ue=new O({props:{code:`from transformers import AutoFeatureExtractor

feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base&quot;</span>)`}}),de=new O({props:{code:`audio_input = [dataset["train"][0]["audio"]["array"]]
feature_extractor(audio_input, sampling_rate=16000)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>audio_input = [dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>][<span class="hljs-string">&quot;array&quot;</span>]]
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor(audio_input, sampling_rate=<span class="hljs-number">16000</span>)
{<span class="hljs-string">&#x27;input_values&#x27;</span>: [array([ <span class="hljs-number">0.00045439</span>,  <span class="hljs-number">0.00045439</span>,  <span class="hljs-number">0.00045439</span>, ..., -<span class="hljs-number">0.1578519</span> , -<span class="hljs-number">0.10807519</span>, -<span class="hljs-number">0.06727459</span>], dtype=float32)]}`}}),me=new R({}),he=new O({props:{code:`dataset["train"][0]["audio"]["array"].shape

dataset["train"][1]["audio"]["array"].shape`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>][<span class="hljs-string">&quot;array&quot;</span>].shape
(<span class="hljs-number">1522930</span>,)

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&quot;audio&quot;</span>][<span class="hljs-string">&quot;array&quot;</span>].shape
(<span class="hljs-number">988891</span>,)`}}),fe=new O({props:{code:`def preprocess_function(examples):
    audio_arrays = [x["array"] for x in examples["audio"]]
    inputs = feature_extractor(
        audio_arrays,
        sampling_rate=16000,
        padding=True,
        max_length=1000000,
        truncation=True,
    )
    return inputs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    audio_arrays = [x[<span class="hljs-string">&quot;array&quot;</span>] <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;audio&quot;</span>]]
<span class="hljs-meta">... </span>    inputs = feature_extractor(
<span class="hljs-meta">... </span>        audio_arrays,
<span class="hljs-meta">... </span>        sampling_rate=<span class="hljs-number">16000</span>,
<span class="hljs-meta">... </span>        padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>        max_length=<span class="hljs-number">1000000</span>,
<span class="hljs-meta">... </span>        truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    )
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> inputs`}}),be=new O({props:{code:'processed_dataset = preprocess_function(dataset["train"][:5])',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>processed_dataset = preprocess_function(dataset[<span class="hljs-string">&quot;train&quot;</span>][:<span class="hljs-number">5</span>])'}}),je=new O({props:{code:`processed_dataset["input_values"][0].shape

processed_dataset["input_values"][1].shape`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>processed_dataset[<span class="hljs-string">&quot;input_values&quot;</span>][<span class="hljs-number">0</span>].shape
(<span class="hljs-number">1000000</span>,)

<span class="hljs-meta">&gt;&gt;&gt; </span>processed_dataset[<span class="hljs-string">&quot;input_values&quot;</span>][<span class="hljs-number">1</span>].shape
(<span class="hljs-number">1000000</span>,)`}}),_e=new R({}),ve=new O({props:{code:`from datasets import load_dataset

dataset = load_dataset("food101", split="train[:100]")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;food101&quot;</span>, split=<span class="hljs-string">&quot;train[:100]&quot;</span>)`}}),$e=new O({props:{code:'dataset[0]["image"]',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;image&quot;</span>]'}}),ke=new R({}),xe=new O({props:{code:`from transformers import AutoFeatureExtractor

feature_extractor = AutoFeatureExtractor.from_pretrained("google/vit-base-patch16-224")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;google/vit-base-patch16-224&quot;</span>)`}}),ye=new R({}),De=new O({props:{code:`from torchvision.transforms import Compose, Normalize, RandomResizedCrop, ColorJitter, ToTensor

normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)
_transforms = Compose(
    [RandomResizedCrop(feature_extractor.size), ColorJitter(brightness=0.5, hue=0.5), ToTensor(), normalize]
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torchvision.transforms <span class="hljs-keyword">import</span> Compose, Normalize, RandomResizedCrop, ColorJitter, ToTensor

<span class="hljs-meta">&gt;&gt;&gt; </span>normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)
<span class="hljs-meta">&gt;&gt;&gt; </span>_transforms = Compose(
<span class="hljs-meta">... </span>    [RandomResizedCrop(feature_extractor.size), ColorJitter(brightness=<span class="hljs-number">0.5</span>, hue=<span class="hljs-number">0.5</span>), ToTensor(), normalize]
<span class="hljs-meta">... </span>)`}}),Ce=new O({props:{code:`def transforms(examples):
    examples["pixel_values"] = [_transforms(image.convert("RGB")) for image in examples["image"]]
    return examples`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">transforms</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    examples[<span class="hljs-string">&quot;pixel_values&quot;</span>] = [_transforms(image.convert(<span class="hljs-string">&quot;RGB&quot;</span>)) <span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;image&quot;</span>]]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> examples`}}),Le=new O({props:{code:"dataset.set_transform(transforms)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.set_transform(transforms)'}}),Ie=new O({props:{code:'dataset[0]["image"]',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;image&quot;</span>]
{<span class="hljs-string">&#x27;image&#x27;</span>: &lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at <span class="hljs-number">0x7F1A7B0630D0</span>&gt;,
 <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">6</span>,
 <span class="hljs-string">&#x27;pixel_values&#x27;</span>: tensor([[[ <span class="hljs-number">0.0353</span>,  <span class="hljs-number">0.0745</span>,  <span class="hljs-number">0.1216</span>,  ..., -<span class="hljs-number">0.9922</span>, -<span class="hljs-number">0.9922</span>, -<span class="hljs-number">0.9922</span>],
          [-<span class="hljs-number">0.0196</span>,  <span class="hljs-number">0.0667</span>,  <span class="hljs-number">0.1294</span>,  ..., -<span class="hljs-number">0.9765</span>, -<span class="hljs-number">0.9843</span>, -<span class="hljs-number">0.9922</span>],
          [ <span class="hljs-number">0.0196</span>,  <span class="hljs-number">0.0824</span>,  <span class="hljs-number">0.1137</span>,  ..., -<span class="hljs-number">0.9765</span>, -<span class="hljs-number">0.9686</span>, -<span class="hljs-number">0.8667</span>],
          ...,
          [ <span class="hljs-number">0.0275</span>,  <span class="hljs-number">0.0745</span>,  <span class="hljs-number">0.0510</span>,  ..., -<span class="hljs-number">0.1137</span>, -<span class="hljs-number">0.1216</span>, -<span class="hljs-number">0.0824</span>],
          [ <span class="hljs-number">0.0667</span>,  <span class="hljs-number">0.0824</span>,  <span class="hljs-number">0.0667</span>,  ..., -<span class="hljs-number">0.0588</span>, -<span class="hljs-number">0.0745</span>, -<span class="hljs-number">0.0980</span>],
          [ <span class="hljs-number">0.0353</span>,  <span class="hljs-number">0.0353</span>,  <span class="hljs-number">0.0431</span>,  ..., -<span class="hljs-number">0.0039</span>, -<span class="hljs-number">0.0039</span>, -<span class="hljs-number">0.0588</span>]],
 
         [[ <span class="hljs-number">0.2078</span>,  <span class="hljs-number">0.2471</span>,  <span class="hljs-number">0.2863</span>,  ..., -<span class="hljs-number">0.9451</span>, -<span class="hljs-number">0.9373</span>, -<span class="hljs-number">0.9451</span>],
          [ <span class="hljs-number">0.1608</span>,  <span class="hljs-number">0.2471</span>,  <span class="hljs-number">0.3098</span>,  ..., -<span class="hljs-number">0.9373</span>, -<span class="hljs-number">0.9451</span>, -<span class="hljs-number">0.9373</span>],
          [ <span class="hljs-number">0.2078</span>,  <span class="hljs-number">0.2706</span>,  <span class="hljs-number">0.3020</span>,  ..., -<span class="hljs-number">0.9608</span>, -<span class="hljs-number">0.9373</span>, -<span class="hljs-number">0.8275</span>],
          ...,
          [-<span class="hljs-number">0.0353</span>,  <span class="hljs-number">0.0118</span>, -<span class="hljs-number">0.0039</span>,  ..., -<span class="hljs-number">0.2392</span>, -<span class="hljs-number">0.2471</span>, -<span class="hljs-number">0.2078</span>],
          [ <span class="hljs-number">0.0196</span>,  <span class="hljs-number">0.0353</span>,  <span class="hljs-number">0.0196</span>,  ..., -<span class="hljs-number">0.1843</span>, -<span class="hljs-number">0.2000</span>, -<span class="hljs-number">0.2235</span>],
          [-<span class="hljs-number">0.0118</span>, -<span class="hljs-number">0.0039</span>, -<span class="hljs-number">0.0039</span>,  ..., -<span class="hljs-number">0.0980</span>, -<span class="hljs-number">0.0980</span>, -<span class="hljs-number">0.1529</span>]],
 
         [[ <span class="hljs-number">0.3961</span>,  <span class="hljs-number">0.4431</span>,  <span class="hljs-number">0.4980</span>,  ..., -<span class="hljs-number">0.9216</span>, -<span class="hljs-number">0.9137</span>, -<span class="hljs-number">0.9216</span>],
          [ <span class="hljs-number">0.3569</span>,  <span class="hljs-number">0.4510</span>,  <span class="hljs-number">0.5216</span>,  ..., -<span class="hljs-number">0.9059</span>, -<span class="hljs-number">0.9137</span>, -<span class="hljs-number">0.9137</span>],
          [ <span class="hljs-number">0.4118</span>,  <span class="hljs-number">0.4745</span>,  <span class="hljs-number">0.5216</span>,  ..., -<span class="hljs-number">0.9137</span>, -<span class="hljs-number">0.8902</span>, -<span class="hljs-number">0.7804</span>],
          ...,
          [-<span class="hljs-number">0.2314</span>, -<span class="hljs-number">0.1922</span>, -<span class="hljs-number">0.2078</span>,  ..., -<span class="hljs-number">0.4196</span>, -<span class="hljs-number">0.4275</span>, -<span class="hljs-number">0.3882</span>],
          [-<span class="hljs-number">0.1843</span>, -<span class="hljs-number">0.1686</span>, -<span class="hljs-number">0.2000</span>,  ..., -<span class="hljs-number">0.3647</span>, -<span class="hljs-number">0.3804</span>, -<span class="hljs-number">0.4039</span>],
          [-<span class="hljs-number">0.1922</span>, -<span class="hljs-number">0.1922</span>, -<span class="hljs-number">0.1922</span>,  ..., -<span class="hljs-number">0.2941</span>, -<span class="hljs-number">0.2863</span>, -<span class="hljs-number">0.3412</span>]]])}`}}),He=new O({props:{code:`import numpy as np
import matplotlib.pyplot as plt

img = dataset[0]["pixel_values"]
plt.imshow(img.permute(1, 2, 0))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt

<span class="hljs-meta">&gt;&gt;&gt; </span>img = dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;pixel_values&quot;</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>plt.imshow(img.permute(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>))`}}),Ue=new R({}),Be=new O({props:{code:`from datasets import load_dataset

lj_speech = load_dataset("lj_speech", split="train")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>lj_speech = load_dataset(<span class="hljs-string">&quot;lj_speech&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`}}),Ge=new O({props:{code:'lj_speech = lj_speech.map(remove_columns=["file", "id", "normalized_text"])',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>lj_speech = lj_speech.<span class="hljs-built_in">map</span>(remove_columns=[<span class="hljs-string">&quot;file&quot;</span>, <span class="hljs-string">&quot;id&quot;</span>, <span class="hljs-string">&quot;normalized_text&quot;</span>])'}}),Je=new O({props:{code:`lj_speech[0]["audio"]

lj_speech[0]["text"]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>lj_speech[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>]
{<span class="hljs-string">&#x27;array&#x27;</span>: array([-<span class="hljs-number">7.3242188e-04</span>, -<span class="hljs-number">7.6293945e-04</span>, -<span class="hljs-number">6.4086914e-04</span>, ...,
         <span class="hljs-number">7.3242188e-04</span>,  <span class="hljs-number">2.1362305e-04</span>,  <span class="hljs-number">6.1035156e-05</span>], dtype=float32),
 <span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/917ece08c95cf0c4115e45294e3cd0dee724a1165b7fc11798369308a465bd26/LJSpeech-1.1/wavs/LJ001-0001.wav&#x27;</span>,
 <span class="hljs-string">&#x27;sampling_rate&#x27;</span>: <span class="hljs-number">22050</span>}

<span class="hljs-meta">&gt;&gt;&gt; </span>lj_speech[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;text&quot;</span>]
<span class="hljs-string">&#x27;Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition&#x27;</span>`}}),Ve=new O({props:{code:'lj_speech = lj_speech.cast_column("audio", Audio(sampling_rate=16_000))',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>lj_speech = lj_speech.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=<span class="hljs-number">16_000</span>))'}}),Ye=new R({}),Me=new O({props:{code:`from transformers import AutoProcessor

processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)`}}),We=new O({props:{code:`def prepare_dataset(example):
    audio = example["audio"]

    example.update(processor(audio=audio["array"], text=example["text"], sampling_rate=16000))

    return example`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">prepare_dataset</span>(<span class="hljs-params">example</span>):
<span class="hljs-meta">... </span>    audio = example[<span class="hljs-string">&quot;audio&quot;</span>]

<span class="hljs-meta">... </span>    example.update(processor(audio=audio[<span class="hljs-string">&quot;array&quot;</span>], text=example[<span class="hljs-string">&quot;text&quot;</span>], sampling_rate=<span class="hljs-number">16000</span>))

<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> example`}}),Ze=new O({props:{code:"prepare_dataset(lj_speech[0])",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>prepare_dataset(lj_speech[<span class="hljs-number">0</span>])'}}),Xe=new R({}),{c(){m=n("meta"),f=c(),b=n("h1"),v=n("a"),j=n("span"),x(q.$$.fragment),E=c(),$=n("span"),h=r("Preprocesamiento"),z=c(),x(D.$$.fragment),A=c(),Zs=n("p"),H=r("Antes de que puedas utilizar los datos en un modelo, debes procesarlos en un formato aceptable para el modelo. Un modelo no entiende el texto en bruto, las im\xE1genes o el audio. Estas entradas necesitan ser convertidas en n\xFAmeros y ensambladas en tensores. En este tutorial, podr\xE1s:"),S=c(),U=n("ul"),Nt=n("li"),tu=r("Preprocesar los datos textuales con un tokenizador."),lu=c(),Rt=n("li"),ru=r("Preprocesar datos de imagen o audio con un extractor de caracter\xEDsticas."),ou=c(),It=n("li"),pu=r("Preprocesar datos para una tarea multimodal con un procesador."),Jo=c(),ms=n("h2"),Xs=n("a"),Ht=n("span"),x(La.$$.fragment),cu=c(),Ut=n("span"),iu=r("NLP"),Vo=c(),x(Na.$$.fragment),Yo=c(),Q=n("p"),uu=r("La principal herramienta para procesar datos textuales es un "),ln=n("a"),du=r("tokenizador"),mu=r(". Un tokenizador comienza dividiendo el texto en "),Ft=n("em"),hu=r("tokens"),fu=r(" seg\xFAn un conjunto de reglas. Los tokens se convierten en n\xFAmeros, que se utilizan para construir tensores como entrada a un modelo. El tokenizador tambi\xE9n a\xF1ade cualquier entrada adicional que requiera el modelo."),Mo=c(),x(sa.$$.fragment),Wo=c(),Z=n("p"),bu=r("Comienza r\xE1pidamente cargando un tokenizador pre-entrenado con la clase "),Bt=n("code"),ju=r("AutoTokenizer"),_u=r(". Esto descarga el "),Gt=n("em"),gu=r("vocab"),vu=r(" utilizado cuando un modelo es pre-entrenado."),Ko=c(),hs=n("h3"),aa=n("a"),Jt=n("span"),x(Ra.$$.fragment),Eu=c(),Vt=n("span"),$u=r("Tokenizar"),Qo=c(),ea=n("p"),ku=r("Carga un tokenizador pre-entrenado con "),Yt=n("code"),xu=r("AutoTokenizer.from_pretrained()"),yu=r(":"),Zo=c(),x(Ia.$$.fragment),Xo=c(),rn=n("p"),wu=r("A continuaci\xF3n, pasa tu frase al tokenizador:"),sp=c(),x(Ha.$$.fragment),ap=c(),on=n("p"),qu=r("El tokenizador devuelve un diccionario con tres \xEDtems importantes:"),ep=c(),X=n("ul"),pn=n("li"),cn=n("a"),Tu=r("input_ids"),zu=r(" son los \xEDndices correspondientes a cada token de la frase."),Du=c(),un=n("li"),dn=n("a"),Pu=r("attention_mask"),Cu=r(" indica si un token debe ser atendido o no."),Au=c(),mn=n("li"),hn=n("a"),Ou=r("token_type_ids"),Su=r(" identifica a qu\xE9 secuencia pertenece un token cuando hay m\xE1s de una secuencia."),np=c(),na=n("p"),Lu=r("Tu puedes decodificar el "),Mt=n("code"),Nu=r("input_ids"),Ru=r(" para devolver la entrada original:"),tp=c(),x(Ua.$$.fragment),lp=c(),ss=n("p"),Iu=r("Como puedes ver, el tokenizador ha a\xF1adido dos tokens especiales - "),Wt=n("code"),Hu=r("CLS"),Uu=r(" y "),Kt=n("code"),Fu=r("SEP"),Bu=r(` (clasificador y separador) - a la frase. No todos los modelos necesitan
tokens especiales, pero si lo llegas a necesitar,  el tokenizador los a\xF1adir\xE1 autom\xE1ticamente.`),rp=c(),fn=n("p"),Gu=r("Si hay varias frases que quieres preprocesar, pasa las frases como una lista al tokenizador:"),op=c(),x(Fa.$$.fragment),pp=c(),fs=n("h3"),ta=n("a"),Qt=n("span"),x(Ba.$$.fragment),Ju=c(),Zt=n("span"),Vu=r("Pad"),cp=c(),bn=n("p"),Yu=r("Esto nos lleva a un tema importante. Cuando se procesa un batch de frases, no siempre tienen la misma longitud. Esto es un problema porque los tensores que se introducen en el modelo deben tener una forma uniforme. El pad es una estrategia para asegurar que los tensores sean rectangulares a\xF1adiendo un \u201Cpadding token\u201D especial a las oraciones con menos tokens."),ip=c(),as=n("p"),Mu=r("Establece el par\xE1metro "),Xt=n("code"),Wu=r("padding"),Ku=r(" en "),sl=n("code"),Qu=r("True"),Zu=r(" aplicando el pad a las secuencias m\xE1s cortas del batch para que coincidan con la secuencia m\xE1s larga:"),up=c(),x(Ga.$$.fragment),dp=c(),jn=n("p"),Xu=r("Observa que el tokenizador ha aplicado el pad a la primera y la tercera frase con un \u201C0\u201D porque son m\xE1s cortas."),mp=c(),bs=n("h3"),la=n("a"),al=n("span"),x(Ja.$$.fragment),sd=c(),el=n("span"),ad=r("Truncamiento"),hp=c(),_n=n("p"),ed=r("En el otro extremo del espectro, a veces una secuencia puede ser demasiado larga para un modelo. En este caso, tendr\xE1s que truncar la secuencia a una longitud m\xE1s corta."),fp=c(),es=n("p"),nd=r("Establece el par\xE1metro "),nl=n("code"),td=r("truncation"),ld=r(" a "),tl=n("code"),rd=r("True"),od=r(" para truncar una secuencia a la longitud m\xE1xima aceptada por el modelo:"),bp=c(),x(Va.$$.fragment),jp=c(),js=n("h3"),ra=n("a"),ll=n("span"),x(Ya.$$.fragment),pd=c(),rl=n("span"),cd=r("Construye tensores"),_p=c(),gn=n("p"),id=r("Finalmente, si quieres que el tokenizador devuelva los tensores reales que se introducen en el modelo."),gp=c(),B=n("p"),ud=r("Establece el par\xE1metro "),ol=n("code"),dd=r("return_tensors"),md=r(" como "),pl=n("code"),hd=r("pt"),fd=r(" para PyTorch, o "),cl=n("code"),bd=r("tf"),jd=r(" para TensorFlow:"),vp=c(),x(Ma.$$.fragment),Ep=c(),_s=n("h2"),oa=n("a"),il=n("span"),x(Wa.$$.fragment),_d=c(),ul=n("span"),gd=r("Audio"),$p=c(),pa=n("p"),vd=r("Las entradas de audio se preprocesan de forma diferente a las entradas textuales, pero el objetivo final es el mismo: crear secuencias num\xE9ricas que el modelo pueda entender. Un "),vn=n("a"),Ed=r("extractor de caracter\xEDsticas"),$d=r(" (o feature extractor en ingl\xE9s) est\xE1 dise\xF1ado para extraer caracter\xEDsticas de datos provenientes de im\xE1genes o audio sin procesar y convertirlos en tensores. Antes de empezar, instala \u{1F917} Datasets para cargar un dataset de audio para experimentar:"),kp=c(),x(Ka.$$.fragment),xp=c(),ns=n("p"),kd=r("Carga la tarea de detecci\xF3n de palabras clave del benchmark "),Qa=n("a"),xd=r("SUPERB"),yd=r(" (consulta el "),Za=n("a"),wd=r("tutorial \u{1F917} Dataset"),qd=r(" para que obtengas m\xE1s detalles sobre c\xF3mo cargar un dataset):"),yp=c(),x(Xa.$$.fragment),wp=c(),ts=n("p"),Td=r("Accede al primer elemento de la columna "),dl=n("code"),zd=r("audio"),Dd=r(" para echar un vistazo a la entrada. Al llamar a la columna "),ml=n("code"),Pd=r("audio"),Cd=r(" se cargar\xE1 y volver\xE1 a muestrear autom\xE1ticamente el archivo de audio:"),qp=c(),x(se.$$.fragment),Tp=c(),En=n("p"),Ad=r("Esto devuelve tres elementos:"),zp=c(),ls=n("ul"),$n=n("li"),hl=n("code"),Od=r("array"),Sd=r(" es la se\xF1al de voz cargada - y potencialmente remuestreada - como un array 1D."),Ld=c(),kn=n("li"),fl=n("code"),Nd=r("path"),Rd=r(" apunta a la ubicaci\xF3n del archivo de audio."),Id=c(),xn=n("li"),bl=n("code"),Hd=r("sampling_rate"),Ud=r(" se refiere a cu\xE1ntos puntos de datos de la se\xF1al de voz se miden por segundo."),Dp=c(),gs=n("h3"),ca=n("a"),jl=n("span"),x(ae.$$.fragment),Fd=c(),_l=n("span"),Bd=r("Resample"),Pp=c(),ia=n("p"),Gd=r("Para este tutorial, se utilizar\xE1 el modelo "),ee=n("a"),Jd=r("Wav2Vec2"),Vd=r(". Como puedes ver en la model card, el modelo Wav2Vec2 est\xE1 pre-entrenado en audio de voz muestreado a 16kHz. Es importante que la tasa de muestreo de tus datos de audio coincida con la tasa de muestreo del dataset utilizado para pre-entrenar el modelo. Si la tasa de muestreo de tus datos no es la misma, deber\xE1s volver a muestrear tus datos de audio."),Cp=c(),ua=n("p"),Yd=r("Por ejemplo, carga el dataset "),ne=n("a"),Md=r("LJ Speech"),Wd=r(" que tiene una tasa de muestreo de 22050kHz. Para utilizar el modelo Wav2Vec2 con este dataset, reduce la tasa de muestreo a 16kHz:"),Ap=c(),x(te.$$.fragment),Op=c(),yn=n("ol"),le=n("li"),Kd=r("Usa el m\xE9todo \u{1F917} Datasets\u2019 "),re=n("a"),gl=n("code"),Qd=r("cast_column"),Zd=r(" para reducir la tasa de muestreo a 16kHz:"),Sp=c(),x(oe.$$.fragment),Lp=c(),pe=n("ol"),vl=n("li"),Xd=r("Carga el archivo de audio:"),Np=c(),x(ce.$$.fragment),Rp=c(),da=n("p"),sm=r("Como puedes ver, el "),El=n("code"),am=r("sampling_rate"),em=r(" se ha reducido a 16kHz. Ahora que sabes c\xF3mo funciona el resampling, volvamos a nuestro ejemplo anterior con el dataset SUPERB."),Ip=c(),vs=n("h3"),ma=n("a"),$l=n("span"),x(ie.$$.fragment),nm=c(),kl=n("span"),tm=r("Extractor de caracter\xEDsticas"),Hp=c(),wn=n("p"),lm=r("El siguiente paso es cargar un extractor de caracter\xEDsticas para normalizar y aplicar el pad a la entrada. Cuando se aplica padding a los datos textuales, se a\xF1ade un \u201C0\u201D para las secuencias m\xE1s cortas. La misma idea se aplica a los datos de audio y el extractor de caracter\xEDsticas de audio a\xF1adir\xE1 un \u201C0\u201D - interpretado como silencio - al \u201Carray\u201D."),Up=c(),ha=n("p"),rm=r("Carga el extractor de caracter\xEDsticas con "),xl=n("code"),om=r("AutoFeatureExtractor.from_pretrained()"),pm=r(":"),Fp=c(),x(ue.$$.fragment),Bp=c(),rs=n("p"),cm=r("Pasa el "),yl=n("code"),im=r("array"),um=r(" de audio al extractor de caracter\xEDsticas. Tambi\xE9n te recomendamos a\xF1adir el argumento "),wl=n("code"),dm=r("sampling_rate"),mm=r(" en el extractor de caracter\xEDsticas para poder depurar mejor los errores silenciosos que puedan producirse."),Gp=c(),x(de.$$.fragment),Jp=c(),Es=n("h3"),fa=n("a"),ql=n("span"),x(me.$$.fragment),hm=c(),Tl=n("span"),fm=r("Pad y truncamiento"),Vp=c(),qn=n("p"),bm=r("Al igual que el tokenizador, puedes aplicar padding o truncamiento para manejar secuencias variables en un batch. F\xEDjate en la longitud de la secuencia de estas dos muestras de audio:"),Yp=c(),x(he.$$.fragment),Mp=c(),ba=n("p"),jm=r("Como puedes ver, el "),zl=n("code"),_m=r("sampling_rate"),gm=r(" se ha reducido a 16kHz."),Wp=c(),x(fe.$$.fragment),Kp=c(),Tn=n("p"),vm=r("Aplica la funci\xF3n a los primeros ejemplos del dataset:"),Qp=c(),x(be.$$.fragment),Zp=c(),zn=n("p"),Em=r("Ahora echa un vistazo a las longitudes de las muestras procesadas:"),Xp=c(),x(je.$$.fragment),sc=c(),Dn=n("p"),$m=r("Las longitudes de las dos primeras muestras coinciden ahora con la longitud m\xE1xima especificada."),ac=c(),$s=n("h2"),ja=n("a"),Dl=n("span"),x(_e.$$.fragment),km=c(),Pl=n("span"),xm=r("Visi\xF3n"),ec=c(),Pn=n("p"),ym=r("Tambi\xE9n se utiliza un extractor de caracter\xEDsticas para procesar im\xE1genes para tareas de visi\xF3n por computadora. Una vez m\xE1s, el objetivo es convertir la imagen en bruto en un batch de tensores como entrada."),nc=c(),os=n("p"),wm=r("Vamos a cargar el dataset "),ge=n("a"),qm=r("food101"),Tm=r(" para este tutorial. Usa el par\xE1metro \u{1F917} Datasets "),Cl=n("code"),zm=r("split"),Dm=r(" para cargar solo una peque\xF1a muestra de la divisi\xF3n de entrenamiento ya que el dataset es bastante grande:"),tc=c(),x(ve.$$.fragment),lc=c(),_a=n("p"),Pm=r("A continuaci\xF3n, observa la imagen con la funci\xF3n \u{1F917} Datasets "),Ee=n("a"),Al=n("code"),Cm=r("Image"),Am=r(":"),rc=c(),x($e.$$.fragment),oc=c(),Cn=n("p"),An=n("img"),pc=c(),ks=n("h3"),ga=n("a"),Ol=n("span"),x(ke.$$.fragment),Om=c(),Sl=n("span"),Sm=r("Extractor de caracter\xEDsticas"),cc=c(),va=n("p"),Lm=r("Carga el extractor de caracter\xEDsticas con "),Ll=n("code"),Nm=r("AutoFeatureExtractor.from_pretrained()"),Rm=r(":"),ic=c(),x(xe.$$.fragment),uc=c(),xs=n("h3"),Ea=n("a"),Nl=n("span"),x(ye.$$.fragment),Im=c(),Rl=n("span"),Hm=r("Aumento de Datos"),dc=c(),$a=n("p"),Um=r("Para las tareas de visi\xF3n por computadora es com\xFAn a\xF1adir alg\xFAn tipo de aumento de datos (o data augmentation) a las im\xE1genes como parte del preprocesamiento. Puedes a\xF1adir el m\xE9todo de aumento de datos con cualquier librer\xEDa que quieras, pero en este tutorial utilizar\xE1s el m\xF3dulo "),we=n("a"),Il=n("code"),Fm=r("transforms"),Bm=r(" de torchvision."),mc=c(),On=n("ol"),M=n("li"),Gm=r("Normaliza la imagen y utiliza "),qe=n("a"),Hl=n("code"),Jm=r("Compose"),Vm=r(" para encadenar algunas transformaciones - "),Te=n("a"),Ul=n("code"),Ym=r("RandomResizedCrop"),Mm=r(" y "),ze=n("a"),Fl=n("code"),Wm=r("ColorJitter"),Km=r(" - juntas:"),hc=c(),x(De.$$.fragment),fc=c(),Pe=n("ol"),ys=n("li"),Qm=r("El modelo acepta "),Sn=n("a"),Bl=n("code"),Zm=r("pixel_values"),Xm=r(" como entrada. Este valor es generado por el extractor de caracter\xEDsticas. Crea una funci\xF3n que genere "),Gl=n("code"),sh=r("pixel_values"),ah=r(" a partir de las transformaciones:"),bc=c(),x(Ce.$$.fragment),jc=c(),Ae=n("ol"),Oe=n("li"),eh=r("A continuaci\xF3n, utiliza \u{1F917} Datasets "),Se=n("a"),Jl=n("code"),nh=r("set_transform"),th=r(" para aplicar las transformaciones sobre la marcha:"),_c=c(),x(Le.$$.fragment),gc=c(),Ne=n("ol"),Re=n("li"),lh=r("Ahora, cuando accedes a la imagen, observar\xE1s que el extractor de caracter\xEDsticas ha a\xF1adido a la entrada del modelo "),Vl=n("code"),rh=r("pixel_values"),oh=r(":"),vc=c(),x(Ie.$$.fragment),Ec=c(),Ln=n("p"),ph=r("Este es el aspecto de la imagen despu\xE9s de preprocesarla. Como era de esperar por las transformaciones aplicadas, la imagen ha sido recortada aleatoriamente y sus propiedades de color son diferentes."),$c=c(),x(He.$$.fragment),kc=c(),Nn=n("p"),Rn=n("img"),xc=c(),ws=n("h2"),ka=n("a"),Yl=n("span"),x(Ue.$$.fragment),ch=c(),Ml=n("span"),ih=r("Multimodal"),yc=c(),In=n("p"),uh=r("Para las tareas multimodales utilizar\xE1s una combinaci\xF3n de todo lo que has aprendido hasta ahora y aplicar\xE1s tus habilidades a una tarea de reconocimiento autom\xE1tico de voz (ASR). Esto significa que necesitar\xE1s un:"),wc=c(),xa=n("ul"),Wl=n("li"),dh=r("Extractor de caracter\xEDsticas para preprocesar los datos de audio."),mh=c(),Kl=n("li"),hh=r("Un tokenizador para procesar el texto."),qc=c(),ya=n("p"),fh=r("Volvamos al dataset "),Fe=n("a"),bh=r("LJ Speech"),jh=r(":"),Tc=c(),x(Be.$$.fragment),zc=c(),ps=n("p"),_h=r("Suponiendo que te interesan principalmente las columnas "),Ql=n("code"),gh=r("audio"),vh=r(" y "),Zl=n("code"),Eh=r("texto"),$h=r(", elimina las dem\xE1s columnas:"),Dc=c(),x(Ge.$$.fragment),Pc=c(),cs=n("p"),kh=r("Ahora echa un vistazo a las columnas "),Xl=n("code"),xh=r("audio"),yh=r(" y "),sr=n("code"),wh=r("texto"),qh=r(":"),Cc=c(),x(Je.$$.fragment),Ac=c(),wa=n("p"),Th=r("Recuerda la secci\xF3n anterior sobre el procesamiento de datos de audio, siempre debes "),Hn=n("a"),zh=r("volver a muestrear"),Dh=r(" la tasa de muestreo de tus datos de audio para que coincida con la tasa de muestreo del dataset utilizado para preentrenar un modelo:"),Oc=c(),x(Ve.$$.fragment),Sc=c(),qs=n("h3"),qa=n("a"),ar=n("span"),x(Ye.$$.fragment),Ph=c(),er=n("span"),Ch=r("Processor"),Lc=c(),Un=n("p"),Ah=r("Un processor combina un extractor de caracter\xEDsticas y un tokenizador. Cargue un procesador con [`AutoProcessor.from_pretrained]:"),Nc=c(),x(Me.$$.fragment),Rc=c(),Fn=n("ol"),Ts=n("li"),Oh=r("Crea una funci\xF3n para procesar los datos de audio en "),nr=n("code"),Sh=r("input_values"),Lh=r(", y tokeniza el texto en "),tr=n("code"),Nh=r("labels"),Rh=r(". Estas son las entradas del modelo:"),Ic=c(),x(We.$$.fragment),Hc=c(),Ke=n("ol"),Qe=n("li"),Ih=r("Aplica la funci\xF3n "),lr=n("code"),Hh=r("prepare_dataset"),Uh=r(" a una muestra:"),Uc=c(),x(Ze.$$.fragment),Fc=c(),is=n("p"),Fh=r("Observa que el m\xE9todo processor ha a\xF1adido "),rr=n("code"),Bh=r("input_values"),Gh=r(" y "),or=n("code"),Jh=r("labels"),Vh=r(". La tasa de muestreo tambi\xE9n se ha reducido correctamente a 16kHz."),Bc=c(),Bn=n("p"),Yh=r("Genial, ahora deber\xEDas ser capaz de preprocesar datos para cualquier modalidad e incluso combinar diferentes modalidades. En el siguiente tutorial, aprender\xE1s aplicar fine tuning a un modelo en tus datos reci\xE9n preprocesados."),Gc=c(),zs=n("h2"),Ta=n("a"),pr=n("span"),x(Xe.$$.fragment),Mh=c(),cr=n("span"),Wh=r("Todo lo que siempre quisiste saber sobre el padding y el truncamiento"),Jc=c(),G=n("p"),Kh=r(`Hemos visto los comandos que funcionar\xE1n para la mayor\xEDa de los casos (hacer pad a tu batch teniendo en cuenta la longitud de la frase m\xE1xima y
truncar a la longitud m\xE1xima que el modelo puede aceptar). Sin embargo, la API admite m\xE1s estrategias si las necesitas. Los
tres argumentos que necesitas conocer para ello son `),ir=n("code"),Qh=r("padding"),Zh=r(", "),ur=n("code"),Xh=r("truncation"),sf=r(" y "),dr=n("code"),af=r("max_length"),ef=r("."),Vc=c(),us=n("ul"),sn=n("li"),Gn=n("p"),mr=n("code"),nf=r("padding"),tf=r(" controla el aplicarme padding al texto. Puede ser un booleano o una cadena que debe ser:"),lf=c(),an=n("ul"),za=n("li"),hr=n("code"),rf=r("True"),of=r(" o "),fr=n("code"),pf=r("'longest'"),cf=r(` para aplicar el pad hasta la secuencia m\xE1s larga del batch (no apliques el padding si s\xF3lo le proporcionas
una sola secuencia).`),uf=c(),L=n("li"),br=n("code"),df=r("'max_length'"),mf=r(" para aplicar el pad hasta la longitud especificada por el argumento "),jr=n("code"),hf=r("max_length"),ff=r(` o la longitud m\xE1xima aceptada
por el modelo si no le proporcionas `),_r=n("code"),bf=r("longitud_m\xE1xima"),jf=r(" ("),gr=n("code"),_f=r("longitud_m\xE1xima=None"),gf=r(`). Si s\xF3lo le proporcionas una \xFAnica secuencia
se le aplicar\xE1 el padding.
`),vr=n("code"),vf=r("False"),Ef=r(" o "),Er=n("code"),$f=r("'do_not_pad'"),kf=r(` para no aplicar pad a las secuencias. Como hemos visto antes, este es el comportamiento por
defecto.`),xf=c(),en=n("li"),Jn=n("p"),$r=n("code"),yf=r("truncation"),wf=r(" controla el truncamiento. Puede ser un booleano o una string que debe ser:"),qf=c(),W=n("ul"),I=n("li"),kr=n("code"),Tf=r("True"),zf=r(" o "),xr=n("code"),Df=r("'longest_first'"),Pf=r(" truncan hasta la longitud m\xE1xima especificada por el argumento "),yr=n("code"),Cf=r("max_length"),Af=r(` o
la longitud m\xE1xima aceptada por el modelo si no le proporcionas `),wr=n("code"),Of=r("max_length"),Sf=r(" ("),qr=n("code"),Lf=r("max_length=None"),Nf=r(`). Esto
truncar\xE1 token por token, eliminando un token de la secuencia m\xE1s larga del par hasta alcanzar la longitud
adecuada.`),Rf=c(),J=n("li"),Tr=n("code"),If=r("'only_second'"),Hf=r(" trunca hasta la longitud m\xE1xima especificada por el argumento "),zr=n("code"),Uf=r("max_length"),Ff=r(` o la
longitud m\xE1xima aceptada por el modelo si no le proporcionas `),Dr=n("code"),Bf=r("max_length"),Gf=r(" ("),Pr=n("code"),Jf=r("max_length=None"),Vf=r(`). Esto s\xF3lo truncar\xE1
la segunda frase de un par si le proporcionas un par de secuencias (o un batch de pares de secuencias).`),Yf=c(),V=n("li"),Cr=n("code"),Mf=r("'only_first'"),Wf=r(" trunca hasta la longitud m\xE1xima especificada por el argumento "),Ar=n("code"),Kf=r("max_length"),Qf=r(` o la longitud m\xE1xima
aceptada por el modelo si no se proporciona `),Or=n("code"),Zf=r("max_length"),Xf=r(" ("),Sr=n("code"),sb=r("max_length=None"),ab=r(`). Esto s\xF3lo truncar\xE1
la primera frase de un par si se proporciona un par de secuencias (o un lote de pares de secuencias).`),eb=c(),Da=n("li"),Lr=n("code"),nb=r("False"),tb=r(" o "),Nr=n("code"),lb=r("'do_not_truncate'"),rb=r(` para no truncar las secuencias. Como hemos visto antes, este es el comportamiento
por defecto.`),ob=c(),Rr=n("li"),ds=n("p"),Ir=n("code"),pb=r("max_length"),cb=r(" para controlar la longitud del padding/truncamiento. Puede ser un n\xFAmero entero o "),Hr=n("code"),ib=r("None"),ub=r(`, en cuyo caso
ser\xE1 por defecto la longitud m\xE1xima que el modelo puede aceptar. Si el modelo no tiene una longitud m\xE1xima de entrada espec\xEDfica, el
padding/truncamiento a `),Ur=n("code"),db=r("longitud_m\xE1xima"),mb=r(" se desactiva."),Yc=c(),N=n("p"),hb=r(`A continuaci\xF3n te mostramos en una tabla que resume la forma recomendada de configurar el padding y el truncamiento. Si utilizas un par de secuencias de entrada en
algunos de los siguientes ejemplos, puedes sustituir `),Fr=n("code"),fb=r("truncation=True"),bb=r(" por una "),Br=n("code"),jb=r("STRATEGY"),_b=r(` seleccionada en
`),Gr=n("code"),gb=r("['only_first', 'only_second', 'longest_first']"),vb=r(", es decir, "),Jr=n("code"),Eb=r("truncation='only_second'"),$b=r(" o "),Vr=n("code"),kb=r("truncation= 'longest_first'"),xb=r(" para controlar c\xF3mo se truncan ambas secuencias del par como se ha detallado anteriormente."),Mc=c(),Pa=n("table"),Yr=n("thead"),Ds=n("tr"),Mr=n("th"),yb=r("Truncation"),wb=c(),Wr=n("th"),qb=r("Padding"),Tb=c(),Kr=n("th"),zb=r("Instrucciones"),Db=c(),P=n("tbody"),Ps=n("tr"),Qr=n("td"),Pb=r("no truncation"),Cb=c(),Zr=n("td"),Ab=r("no padding"),Ob=c(),Xr=n("td"),so=n("code"),Sb=r("tokenizer(batch_sentences)"),Lb=c(),Cs=n("tr"),Wc=n("td"),Nb=c(),ao=n("td"),Rb=r("padding secuencia max del batch"),Ib=c(),Vn=n("td"),eo=n("code"),Hb=r("tokenizer(batch_sentences, padding=True)"),Ub=r(" or"),Fb=c(),As=n("tr"),Kc=n("td"),Bb=c(),Qc=n("td"),Gb=c(),no=n("td"),to=n("code"),Jb=r("tokenizer(batch_sentences, padding='longest')"),Vb=c(),Os=n("tr"),Zc=n("td"),Yb=c(),lo=n("td"),Mb=r("padding long max de input model"),Wb=c(),ro=n("td"),oo=n("code"),Kb=r("tokenizer(batch_sentences, padding='max_length')"),Qb=c(),Ss=n("tr"),Xc=n("td"),Zb=c(),po=n("td"),Xb=r("padding a una long especifica"),s1=c(),co=n("td"),io=n("code"),a1=r("tokenizer(batch_sentences, padding='max_length', max_length=42)"),e1=c(),Ls=n("tr"),uo=n("td"),n1=r("truncation long max del input model"),t1=c(),mo=n("td"),l1=r("no padding"),r1=c(),Yn=n("td"),ho=n("code"),o1=r("tokenizer(batch_sentences, truncation=True)"),p1=r(" or"),c1=c(),Ns=n("tr"),si=n("td"),i1=c(),ai=n("td"),u1=c(),fo=n("td"),bo=n("code"),d1=r("tokenizer(batch_sentences, truncation=STRATEGY)"),m1=c(),Rs=n("tr"),ei=n("td"),h1=c(),jo=n("td"),f1=r("padding secuencia max del batch"),b1=c(),Mn=n("td"),_o=n("code"),j1=r("tokenizer(batch_sentences, padding=True, truncation=True)"),_1=r(" or"),g1=c(),Is=n("tr"),ni=n("td"),v1=c(),ti=n("td"),E1=c(),go=n("td"),vo=n("code"),$1=r("tokenizer(batch_sentences, padding=True, truncation=STRATEGY)"),k1=c(),Hs=n("tr"),li=n("td"),x1=c(),Eo=n("td"),y1=r("padding long max de input model"),w1=c(),Wn=n("td"),$o=n("code"),q1=r("tokenizer(batch_sentences, padding='max_length', truncation=True)"),T1=r(" or"),z1=c(),Us=n("tr"),ri=n("td"),D1=c(),oi=n("td"),P1=c(),ko=n("td"),xo=n("code"),C1=r("tokenizer(batch_sentences, padding='max_length', truncation=STRATEGY)"),A1=c(),Fs=n("tr"),pi=n("td"),O1=c(),yo=n("td"),S1=r("padding a una long especifica"),L1=c(),wo=n("td"),N1=r("Not possible"),R1=c(),Bs=n("tr"),qo=n("td"),I1=r("truncation a una long especifica"),H1=c(),To=n("td"),U1=r("no padding"),F1=c(),Kn=n("td"),zo=n("code"),B1=r("tokenizer(batch_sentences, truncation=True, max_length=42)"),G1=r(" or"),J1=c(),Gs=n("tr"),ci=n("td"),V1=c(),ii=n("td"),Y1=c(),Do=n("td"),Po=n("code"),M1=r("tokenizer(batch_sentences, truncation=STRATEGY, max_length=42)"),W1=c(),Js=n("tr"),ui=n("td"),K1=c(),Co=n("td"),Q1=r("padding secuencia max del batch"),Z1=c(),Qn=n("td"),Ao=n("code"),X1=r("tokenizer(batch_sentences, padding=True, truncation=True, max_length=42)"),sj=r(" or"),aj=c(),Vs=n("tr"),di=n("td"),ej=c(),mi=n("td"),nj=c(),Oo=n("td"),So=n("code"),tj=r("tokenizer(batch_sentences, padding=True, truncation=STRATEGY, max_length=42)"),lj=c(),Ys=n("tr"),hi=n("td"),rj=c(),Lo=n("td"),oj=r("padding long max de input model"),pj=c(),No=n("td"),cj=r("Not possible"),ij=c(),Ms=n("tr"),fi=n("td"),uj=c(),Ro=n("td"),dj=r("padding a una long especifica"),mj=c(),Zn=n("td"),Io=n("code"),hj=r("tokenizer(batch_sentences, padding='max_length', truncation=True, max_length=42)"),fj=r(" or"),bj=c(),Ws=n("tr"),bi=n("td"),jj=c(),ji=n("td"),_j=c(),Ho=n("td"),Uo=n("code"),gj=r("tokenizer(batch_sentences, padding='max_length', truncation=STRATEGY, max_length=42)"),this.h()},l(s){const p=_v('[data-svelte="svelte-1phssyn"]',document.head);m=t(p,"META",{name:!0,content:!0}),p.forEach(e),f=i(s),b=t(s,"H1",{class:!0});var nn=l(b);v=t(nn,"A",{id:!0,class:!0,href:!0});var Hj=l(v);j=t(Hj,"SPAN",{});var Uj=l(j);w(q.$$.fragment,Uj),Uj.forEach(e),Hj.forEach(e),E=i(nn),$=t(nn,"SPAN",{});var Fj=l($);h=o(Fj,"Preprocesamiento"),Fj.forEach(e),nn.forEach(e),z=i(s),w(D.$$.fragment,s),A=i(s),Zs=t(s,"P",{});var Bj=l(Zs);H=o(Bj,"Antes de que puedas utilizar los datos en un modelo, debes procesarlos en un formato aceptable para el modelo. Un modelo no entiende el texto en bruto, las im\xE1genes o el audio. Estas entradas necesitan ser convertidas en n\xFAmeros y ensambladas en tensores. En este tutorial, podr\xE1s:"),Bj.forEach(e),S=i(s),U=t(s,"UL",{});var Xn=l(U);Nt=t(Xn,"LI",{});var Gj=l(Nt);tu=o(Gj,"Preprocesar los datos textuales con un tokenizador."),Gj.forEach(e),lu=i(Xn),Rt=t(Xn,"LI",{});var Jj=l(Rt);ru=o(Jj,"Preprocesar datos de imagen o audio con un extractor de caracter\xEDsticas."),Jj.forEach(e),ou=i(Xn),It=t(Xn,"LI",{});var Vj=l(It);pu=o(Vj,"Preprocesar datos para una tarea multimodal con un procesador."),Vj.forEach(e),Xn.forEach(e),Jo=i(s),ms=t(s,"H2",{class:!0});var gi=l(ms);Xs=t(gi,"A",{id:!0,class:!0,href:!0});var Yj=l(Xs);Ht=t(Yj,"SPAN",{});var Mj=l(Ht);w(La.$$.fragment,Mj),Mj.forEach(e),Yj.forEach(e),cu=i(gi),Ut=t(gi,"SPAN",{});var Wj=l(Ut);iu=o(Wj,"NLP"),Wj.forEach(e),gi.forEach(e),Vo=i(s),w(Na.$$.fragment,s),Yo=i(s),Q=t(s,"P",{});var st=l(Q);uu=o(st,"La principal herramienta para procesar datos textuales es un "),ln=t(st,"A",{href:!0});var Kj=l(ln);du=o(Kj,"tokenizador"),Kj.forEach(e),mu=o(st,". Un tokenizador comienza dividiendo el texto en "),Ft=t(st,"EM",{});var Qj=l(Ft);hu=o(Qj,"tokens"),Qj.forEach(e),fu=o(st," seg\xFAn un conjunto de reglas. Los tokens se convierten en n\xFAmeros, que se utilizan para construir tensores como entrada a un modelo. El tokenizador tambi\xE9n a\xF1ade cualquier entrada adicional que requiera el modelo."),st.forEach(e),Mo=i(s),w(sa.$$.fragment,s),Wo=i(s),Z=t(s,"P",{});var at=l(Z);bu=o(at,"Comienza r\xE1pidamente cargando un tokenizador pre-entrenado con la clase "),Bt=t(at,"CODE",{});var Zj=l(Bt);ju=o(Zj,"AutoTokenizer"),Zj.forEach(e),_u=o(at,". Esto descarga el "),Gt=t(at,"EM",{});var Xj=l(Gt);gu=o(Xj,"vocab"),Xj.forEach(e),vu=o(at," utilizado cuando un modelo es pre-entrenado."),at.forEach(e),Ko=i(s),hs=t(s,"H3",{class:!0});var vi=l(hs);aa=t(vi,"A",{id:!0,class:!0,href:!0});var s0=l(aa);Jt=t(s0,"SPAN",{});var a0=l(Jt);w(Ra.$$.fragment,a0),a0.forEach(e),s0.forEach(e),Eu=i(vi),Vt=t(vi,"SPAN",{});var e0=l(Vt);$u=o(e0,"Tokenizar"),e0.forEach(e),vi.forEach(e),Qo=i(s),ea=t(s,"P",{});var Ei=l(ea);ku=o(Ei,"Carga un tokenizador pre-entrenado con "),Yt=t(Ei,"CODE",{});var n0=l(Yt);xu=o(n0,"AutoTokenizer.from_pretrained()"),n0.forEach(e),yu=o(Ei,":"),Ei.forEach(e),Zo=i(s),w(Ia.$$.fragment,s),Xo=i(s),rn=t(s,"P",{});var t0=l(rn);wu=o(t0,"A continuaci\xF3n, pasa tu frase al tokenizador:"),t0.forEach(e),sp=i(s),w(Ha.$$.fragment,s),ap=i(s),on=t(s,"P",{});var l0=l(on);qu=o(l0,"El tokenizador devuelve un diccionario con tres \xEDtems importantes:"),l0.forEach(e),ep=i(s),X=t(s,"UL",{});var et=l(X);pn=t(et,"LI",{});var vj=l(pn);cn=t(vj,"A",{href:!0});var r0=l(cn);Tu=o(r0,"input_ids"),r0.forEach(e),zu=o(vj," son los \xEDndices correspondientes a cada token de la frase."),vj.forEach(e),Du=i(et),un=t(et,"LI",{});var Ej=l(un);dn=t(Ej,"A",{href:!0});var o0=l(dn);Pu=o(o0,"attention_mask"),o0.forEach(e),Cu=o(Ej," indica si un token debe ser atendido o no."),Ej.forEach(e),Au=i(et),mn=t(et,"LI",{});var $j=l(mn);hn=t($j,"A",{href:!0});var p0=l(hn);Ou=o(p0,"token_type_ids"),p0.forEach(e),Su=o($j," identifica a qu\xE9 secuencia pertenece un token cuando hay m\xE1s de una secuencia."),$j.forEach(e),et.forEach(e),np=i(s),na=t(s,"P",{});var $i=l(na);Lu=o($i,"Tu puedes decodificar el "),Mt=t($i,"CODE",{});var c0=l(Mt);Nu=o(c0,"input_ids"),c0.forEach(e),Ru=o($i," para devolver la entrada original:"),$i.forEach(e),tp=i(s),w(Ua.$$.fragment,s),lp=i(s),ss=t(s,"P",{});var nt=l(ss);Iu=o(nt,"Como puedes ver, el tokenizador ha a\xF1adido dos tokens especiales - "),Wt=t(nt,"CODE",{});var i0=l(Wt);Hu=o(i0,"CLS"),i0.forEach(e),Uu=o(nt," y "),Kt=t(nt,"CODE",{});var u0=l(Kt);Fu=o(u0,"SEP"),u0.forEach(e),Bu=o(nt,` (clasificador y separador) - a la frase. No todos los modelos necesitan
tokens especiales, pero si lo llegas a necesitar,  el tokenizador los a\xF1adir\xE1 autom\xE1ticamente.`),nt.forEach(e),rp=i(s),fn=t(s,"P",{});var d0=l(fn);Gu=o(d0,"Si hay varias frases que quieres preprocesar, pasa las frases como una lista al tokenizador:"),d0.forEach(e),op=i(s),w(Fa.$$.fragment,s),pp=i(s),fs=t(s,"H3",{class:!0});var ki=l(fs);ta=t(ki,"A",{id:!0,class:!0,href:!0});var m0=l(ta);Qt=t(m0,"SPAN",{});var h0=l(Qt);w(Ba.$$.fragment,h0),h0.forEach(e),m0.forEach(e),Ju=i(ki),Zt=t(ki,"SPAN",{});var f0=l(Zt);Vu=o(f0,"Pad"),f0.forEach(e),ki.forEach(e),cp=i(s),bn=t(s,"P",{});var b0=l(bn);Yu=o(b0,"Esto nos lleva a un tema importante. Cuando se procesa un batch de frases, no siempre tienen la misma longitud. Esto es un problema porque los tensores que se introducen en el modelo deben tener una forma uniforme. El pad es una estrategia para asegurar que los tensores sean rectangulares a\xF1adiendo un \u201Cpadding token\u201D especial a las oraciones con menos tokens."),b0.forEach(e),ip=i(s),as=t(s,"P",{});var tt=l(as);Mu=o(tt,"Establece el par\xE1metro "),Xt=t(tt,"CODE",{});var j0=l(Xt);Wu=o(j0,"padding"),j0.forEach(e),Ku=o(tt," en "),sl=t(tt,"CODE",{});var _0=l(sl);Qu=o(_0,"True"),_0.forEach(e),Zu=o(tt," aplicando el pad a las secuencias m\xE1s cortas del batch para que coincidan con la secuencia m\xE1s larga:"),tt.forEach(e),up=i(s),w(Ga.$$.fragment,s),dp=i(s),jn=t(s,"P",{});var g0=l(jn);Xu=o(g0,"Observa que el tokenizador ha aplicado el pad a la primera y la tercera frase con un \u201C0\u201D porque son m\xE1s cortas."),g0.forEach(e),mp=i(s),bs=t(s,"H3",{class:!0});var xi=l(bs);la=t(xi,"A",{id:!0,class:!0,href:!0});var v0=l(la);al=t(v0,"SPAN",{});var E0=l(al);w(Ja.$$.fragment,E0),E0.forEach(e),v0.forEach(e),sd=i(xi),el=t(xi,"SPAN",{});var $0=l(el);ad=o($0,"Truncamiento"),$0.forEach(e),xi.forEach(e),hp=i(s),_n=t(s,"P",{});var k0=l(_n);ed=o(k0,"En el otro extremo del espectro, a veces una secuencia puede ser demasiado larga para un modelo. En este caso, tendr\xE1s que truncar la secuencia a una longitud m\xE1s corta."),k0.forEach(e),fp=i(s),es=t(s,"P",{});var lt=l(es);nd=o(lt,"Establece el par\xE1metro "),nl=t(lt,"CODE",{});var x0=l(nl);td=o(x0,"truncation"),x0.forEach(e),ld=o(lt," a "),tl=t(lt,"CODE",{});var y0=l(tl);rd=o(y0,"True"),y0.forEach(e),od=o(lt," para truncar una secuencia a la longitud m\xE1xima aceptada por el modelo:"),lt.forEach(e),bp=i(s),w(Va.$$.fragment,s),jp=i(s),js=t(s,"H3",{class:!0});var yi=l(js);ra=t(yi,"A",{id:!0,class:!0,href:!0});var w0=l(ra);ll=t(w0,"SPAN",{});var q0=l(ll);w(Ya.$$.fragment,q0),q0.forEach(e),w0.forEach(e),pd=i(yi),rl=t(yi,"SPAN",{});var T0=l(rl);cd=o(T0,"Construye tensores"),T0.forEach(e),yi.forEach(e),_p=i(s),gn=t(s,"P",{});var z0=l(gn);id=o(z0,"Finalmente, si quieres que el tokenizador devuelva los tensores reales que se introducen en el modelo."),z0.forEach(e),gp=i(s),B=t(s,"P",{});var Ca=l(B);ud=o(Ca,"Establece el par\xE1metro "),ol=t(Ca,"CODE",{});var D0=l(ol);dd=o(D0,"return_tensors"),D0.forEach(e),md=o(Ca," como "),pl=t(Ca,"CODE",{});var P0=l(pl);hd=o(P0,"pt"),P0.forEach(e),fd=o(Ca," para PyTorch, o "),cl=t(Ca,"CODE",{});var C0=l(cl);bd=o(C0,"tf"),C0.forEach(e),jd=o(Ca," para TensorFlow:"),Ca.forEach(e),vp=i(s),w(Ma.$$.fragment,s),Ep=i(s),_s=t(s,"H2",{class:!0});var wi=l(_s);oa=t(wi,"A",{id:!0,class:!0,href:!0});var A0=l(oa);il=t(A0,"SPAN",{});var O0=l(il);w(Wa.$$.fragment,O0),O0.forEach(e),A0.forEach(e),_d=i(wi),ul=t(wi,"SPAN",{});var S0=l(ul);gd=o(S0,"Audio"),S0.forEach(e),wi.forEach(e),$p=i(s),pa=t(s,"P",{});var qi=l(pa);vd=o(qi,"Las entradas de audio se preprocesan de forma diferente a las entradas textuales, pero el objetivo final es el mismo: crear secuencias num\xE9ricas que el modelo pueda entender. Un "),vn=t(qi,"A",{href:!0});var L0=l(vn);Ed=o(L0,"extractor de caracter\xEDsticas"),L0.forEach(e),$d=o(qi," (o feature extractor en ingl\xE9s) est\xE1 dise\xF1ado para extraer caracter\xEDsticas de datos provenientes de im\xE1genes o audio sin procesar y convertirlos en tensores. Antes de empezar, instala \u{1F917} Datasets para cargar un dataset de audio para experimentar:"),qi.forEach(e),kp=i(s),w(Ka.$$.fragment,s),xp=i(s),ns=t(s,"P",{});var rt=l(ns);kd=o(rt,"Carga la tarea de detecci\xF3n de palabras clave del benchmark "),Qa=t(rt,"A",{href:!0,rel:!0});var N0=l(Qa);xd=o(N0,"SUPERB"),N0.forEach(e),yd=o(rt," (consulta el "),Za=t(rt,"A",{href:!0,rel:!0});var R0=l(Za);wd=o(R0,"tutorial \u{1F917} Dataset"),R0.forEach(e),qd=o(rt," para que obtengas m\xE1s detalles sobre c\xF3mo cargar un dataset):"),rt.forEach(e),yp=i(s),w(Xa.$$.fragment,s),wp=i(s),ts=t(s,"P",{});var ot=l(ts);Td=o(ot,"Accede al primer elemento de la columna "),dl=t(ot,"CODE",{});var I0=l(dl);zd=o(I0,"audio"),I0.forEach(e),Dd=o(ot," para echar un vistazo a la entrada. Al llamar a la columna "),ml=t(ot,"CODE",{});var H0=l(ml);Pd=o(H0,"audio"),H0.forEach(e),Cd=o(ot," se cargar\xE1 y volver\xE1 a muestrear autom\xE1ticamente el archivo de audio:"),ot.forEach(e),qp=i(s),w(se.$$.fragment,s),Tp=i(s),En=t(s,"P",{});var U0=l(En);Ad=o(U0,"Esto devuelve tres elementos:"),U0.forEach(e),zp=i(s),ls=t(s,"UL",{});var pt=l(ls);$n=t(pt,"LI",{});var kj=l($n);hl=t(kj,"CODE",{});var F0=l(hl);Od=o(F0,"array"),F0.forEach(e),Sd=o(kj," es la se\xF1al de voz cargada - y potencialmente remuestreada - como un array 1D."),kj.forEach(e),Ld=i(pt),kn=t(pt,"LI",{});var xj=l(kn);fl=t(xj,"CODE",{});var B0=l(fl);Nd=o(B0,"path"),B0.forEach(e),Rd=o(xj," apunta a la ubicaci\xF3n del archivo de audio."),xj.forEach(e),Id=i(pt),xn=t(pt,"LI",{});var yj=l(xn);bl=t(yj,"CODE",{});var G0=l(bl);Hd=o(G0,"sampling_rate"),G0.forEach(e),Ud=o(yj," se refiere a cu\xE1ntos puntos de datos de la se\xF1al de voz se miden por segundo."),yj.forEach(e),pt.forEach(e),Dp=i(s),gs=t(s,"H3",{class:!0});var Ti=l(gs);ca=t(Ti,"A",{id:!0,class:!0,href:!0});var J0=l(ca);jl=t(J0,"SPAN",{});var V0=l(jl);w(ae.$$.fragment,V0),V0.forEach(e),J0.forEach(e),Fd=i(Ti),_l=t(Ti,"SPAN",{});var Y0=l(_l);Bd=o(Y0,"Resample"),Y0.forEach(e),Ti.forEach(e),Pp=i(s),ia=t(s,"P",{});var zi=l(ia);Gd=o(zi,"Para este tutorial, se utilizar\xE1 el modelo "),ee=t(zi,"A",{href:!0,rel:!0});var M0=l(ee);Jd=o(M0,"Wav2Vec2"),M0.forEach(e),Vd=o(zi,". Como puedes ver en la model card, el modelo Wav2Vec2 est\xE1 pre-entrenado en audio de voz muestreado a 16kHz. Es importante que la tasa de muestreo de tus datos de audio coincida con la tasa de muestreo del dataset utilizado para pre-entrenar el modelo. Si la tasa de muestreo de tus datos no es la misma, deber\xE1s volver a muestrear tus datos de audio."),zi.forEach(e),Cp=i(s),ua=t(s,"P",{});var Di=l(ua);Yd=o(Di,"Por ejemplo, carga el dataset "),ne=t(Di,"A",{href:!0,rel:!0});var W0=l(ne);Md=o(W0,"LJ Speech"),W0.forEach(e),Wd=o(Di," que tiene una tasa de muestreo de 22050kHz. Para utilizar el modelo Wav2Vec2 con este dataset, reduce la tasa de muestreo a 16kHz:"),Di.forEach(e),Ap=i(s),w(te.$$.fragment,s),Op=i(s),yn=t(s,"OL",{});var K0=l(yn);le=t(K0,"LI",{});var Pi=l(le);Kd=o(Pi,"Usa el m\xE9todo \u{1F917} Datasets\u2019 "),re=t(Pi,"A",{href:!0,rel:!0});var Q0=l(re);gl=t(Q0,"CODE",{});var Z0=l(gl);Qd=o(Z0,"cast_column"),Z0.forEach(e),Q0.forEach(e),Zd=o(Pi," para reducir la tasa de muestreo a 16kHz:"),Pi.forEach(e),K0.forEach(e),Sp=i(s),w(oe.$$.fragment,s),Lp=i(s),pe=t(s,"OL",{start:!0});var X0=l(pe);vl=t(X0,"LI",{});var s_=l(vl);Xd=o(s_,"Carga el archivo de audio:"),s_.forEach(e),X0.forEach(e),Np=i(s),w(ce.$$.fragment,s),Rp=i(s),da=t(s,"P",{});var Ci=l(da);sm=o(Ci,"Como puedes ver, el "),El=t(Ci,"CODE",{});var a_=l(El);am=o(a_,"sampling_rate"),a_.forEach(e),em=o(Ci," se ha reducido a 16kHz. Ahora que sabes c\xF3mo funciona el resampling, volvamos a nuestro ejemplo anterior con el dataset SUPERB."),Ci.forEach(e),Ip=i(s),vs=t(s,"H3",{class:!0});var Ai=l(vs);ma=t(Ai,"A",{id:!0,class:!0,href:!0});var e_=l(ma);$l=t(e_,"SPAN",{});var n_=l($l);w(ie.$$.fragment,n_),n_.forEach(e),e_.forEach(e),nm=i(Ai),kl=t(Ai,"SPAN",{});var t_=l(kl);tm=o(t_,"Extractor de caracter\xEDsticas"),t_.forEach(e),Ai.forEach(e),Hp=i(s),wn=t(s,"P",{});var l_=l(wn);lm=o(l_,"El siguiente paso es cargar un extractor de caracter\xEDsticas para normalizar y aplicar el pad a la entrada. Cuando se aplica padding a los datos textuales, se a\xF1ade un \u201C0\u201D para las secuencias m\xE1s cortas. La misma idea se aplica a los datos de audio y el extractor de caracter\xEDsticas de audio a\xF1adir\xE1 un \u201C0\u201D - interpretado como silencio - al \u201Carray\u201D."),l_.forEach(e),Up=i(s),ha=t(s,"P",{});var Oi=l(ha);rm=o(Oi,"Carga el extractor de caracter\xEDsticas con "),xl=t(Oi,"CODE",{});var r_=l(xl);om=o(r_,"AutoFeatureExtractor.from_pretrained()"),r_.forEach(e),pm=o(Oi,":"),Oi.forEach(e),Fp=i(s),w(ue.$$.fragment,s),Bp=i(s),rs=t(s,"P",{});var ct=l(rs);cm=o(ct,"Pasa el "),yl=t(ct,"CODE",{});var o_=l(yl);im=o(o_,"array"),o_.forEach(e),um=o(ct," de audio al extractor de caracter\xEDsticas. Tambi\xE9n te recomendamos a\xF1adir el argumento "),wl=t(ct,"CODE",{});var p_=l(wl);dm=o(p_,"sampling_rate"),p_.forEach(e),mm=o(ct," en el extractor de caracter\xEDsticas para poder depurar mejor los errores silenciosos que puedan producirse."),ct.forEach(e),Gp=i(s),w(de.$$.fragment,s),Jp=i(s),Es=t(s,"H3",{class:!0});var Si=l(Es);fa=t(Si,"A",{id:!0,class:!0,href:!0});var c_=l(fa);ql=t(c_,"SPAN",{});var i_=l(ql);w(me.$$.fragment,i_),i_.forEach(e),c_.forEach(e),hm=i(Si),Tl=t(Si,"SPAN",{});var u_=l(Tl);fm=o(u_,"Pad y truncamiento"),u_.forEach(e),Si.forEach(e),Vp=i(s),qn=t(s,"P",{});var d_=l(qn);bm=o(d_,"Al igual que el tokenizador, puedes aplicar padding o truncamiento para manejar secuencias variables en un batch. F\xEDjate en la longitud de la secuencia de estas dos muestras de audio:"),d_.forEach(e),Yp=i(s),w(he.$$.fragment,s),Mp=i(s),ba=t(s,"P",{});var Li=l(ba);jm=o(Li,"Como puedes ver, el "),zl=t(Li,"CODE",{});var m_=l(zl);_m=o(m_,"sampling_rate"),m_.forEach(e),gm=o(Li," se ha reducido a 16kHz."),Li.forEach(e),Wp=i(s),w(fe.$$.fragment,s),Kp=i(s),Tn=t(s,"P",{});var h_=l(Tn);vm=o(h_,"Aplica la funci\xF3n a los primeros ejemplos del dataset:"),h_.forEach(e),Qp=i(s),w(be.$$.fragment,s),Zp=i(s),zn=t(s,"P",{});var f_=l(zn);Em=o(f_,"Ahora echa un vistazo a las longitudes de las muestras procesadas:"),f_.forEach(e),Xp=i(s),w(je.$$.fragment,s),sc=i(s),Dn=t(s,"P",{});var b_=l(Dn);$m=o(b_,"Las longitudes de las dos primeras muestras coinciden ahora con la longitud m\xE1xima especificada."),b_.forEach(e),ac=i(s),$s=t(s,"H2",{class:!0});var Ni=l($s);ja=t(Ni,"A",{id:!0,class:!0,href:!0});var j_=l(ja);Dl=t(j_,"SPAN",{});var __=l(Dl);w(_e.$$.fragment,__),__.forEach(e),j_.forEach(e),km=i(Ni),Pl=t(Ni,"SPAN",{});var g_=l(Pl);xm=o(g_,"Visi\xF3n"),g_.forEach(e),Ni.forEach(e),ec=i(s),Pn=t(s,"P",{});var v_=l(Pn);ym=o(v_,"Tambi\xE9n se utiliza un extractor de caracter\xEDsticas para procesar im\xE1genes para tareas de visi\xF3n por computadora. Una vez m\xE1s, el objetivo es convertir la imagen en bruto en un batch de tensores como entrada."),v_.forEach(e),nc=i(s),os=t(s,"P",{});var it=l(os);wm=o(it,"Vamos a cargar el dataset "),ge=t(it,"A",{href:!0,rel:!0});var E_=l(ge);qm=o(E_,"food101"),E_.forEach(e),Tm=o(it," para este tutorial. Usa el par\xE1metro \u{1F917} Datasets "),Cl=t(it,"CODE",{});var $_=l(Cl);zm=o($_,"split"),$_.forEach(e),Dm=o(it," para cargar solo una peque\xF1a muestra de la divisi\xF3n de entrenamiento ya que el dataset es bastante grande:"),it.forEach(e),tc=i(s),w(ve.$$.fragment,s),lc=i(s),_a=t(s,"P",{});var Ri=l(_a);Pm=o(Ri,"A continuaci\xF3n, observa la imagen con la funci\xF3n \u{1F917} Datasets "),Ee=t(Ri,"A",{href:!0,rel:!0});var k_=l(Ee);Al=t(k_,"CODE",{});var x_=l(Al);Cm=o(x_,"Image"),x_.forEach(e),k_.forEach(e),Am=o(Ri,":"),Ri.forEach(e),rc=i(s),w($e.$$.fragment,s),oc=i(s),Cn=t(s,"P",{});var y_=l(Cn);An=t(y_,"IMG",{src:!0,alt:!0}),y_.forEach(e),pc=i(s),ks=t(s,"H3",{class:!0});var Ii=l(ks);ga=t(Ii,"A",{id:!0,class:!0,href:!0});var w_=l(ga);Ol=t(w_,"SPAN",{});var q_=l(Ol);w(ke.$$.fragment,q_),q_.forEach(e),w_.forEach(e),Om=i(Ii),Sl=t(Ii,"SPAN",{});var T_=l(Sl);Sm=o(T_,"Extractor de caracter\xEDsticas"),T_.forEach(e),Ii.forEach(e),cc=i(s),va=t(s,"P",{});var Hi=l(va);Lm=o(Hi,"Carga el extractor de caracter\xEDsticas con "),Ll=t(Hi,"CODE",{});var z_=l(Ll);Nm=o(z_,"AutoFeatureExtractor.from_pretrained()"),z_.forEach(e),Rm=o(Hi,":"),Hi.forEach(e),ic=i(s),w(xe.$$.fragment,s),uc=i(s),xs=t(s,"H3",{class:!0});var Ui=l(xs);Ea=t(Ui,"A",{id:!0,class:!0,href:!0});var D_=l(Ea);Nl=t(D_,"SPAN",{});var P_=l(Nl);w(ye.$$.fragment,P_),P_.forEach(e),D_.forEach(e),Im=i(Ui),Rl=t(Ui,"SPAN",{});var C_=l(Rl);Hm=o(C_,"Aumento de Datos"),C_.forEach(e),Ui.forEach(e),dc=i(s),$a=t(s,"P",{});var Fi=l($a);Um=o(Fi,"Para las tareas de visi\xF3n por computadora es com\xFAn a\xF1adir alg\xFAn tipo de aumento de datos (o data augmentation) a las im\xE1genes como parte del preprocesamiento. Puedes a\xF1adir el m\xE9todo de aumento de datos con cualquier librer\xEDa que quieras, pero en este tutorial utilizar\xE1s el m\xF3dulo "),we=t(Fi,"A",{href:!0,rel:!0});var A_=l(we);Il=t(A_,"CODE",{});var O_=l(Il);Fm=o(O_,"transforms"),O_.forEach(e),A_.forEach(e),Bm=o(Fi," de torchvision."),Fi.forEach(e),mc=i(s),On=t(s,"OL",{});var S_=l(On);M=t(S_,"LI",{});var Aa=l(M);Gm=o(Aa,"Normaliza la imagen y utiliza "),qe=t(Aa,"A",{href:!0,rel:!0});var L_=l(qe);Hl=t(L_,"CODE",{});var N_=l(Hl);Jm=o(N_,"Compose"),N_.forEach(e),L_.forEach(e),Vm=o(Aa," para encadenar algunas transformaciones - "),Te=t(Aa,"A",{href:!0,rel:!0});var R_=l(Te);Ul=t(R_,"CODE",{});var I_=l(Ul);Ym=o(I_,"RandomResizedCrop"),I_.forEach(e),R_.forEach(e),Mm=o(Aa," y "),ze=t(Aa,"A",{href:!0,rel:!0});var H_=l(ze);Fl=t(H_,"CODE",{});var U_=l(Fl);Wm=o(U_,"ColorJitter"),U_.forEach(e),H_.forEach(e),Km=o(Aa," - juntas:"),Aa.forEach(e),S_.forEach(e),hc=i(s),w(De.$$.fragment,s),fc=i(s),Pe=t(s,"OL",{start:!0});var F_=l(Pe);ys=t(F_,"LI",{});var ut=l(ys);Qm=o(ut,"El modelo acepta "),Sn=t(ut,"A",{href:!0});var B_=l(Sn);Bl=t(B_,"CODE",{});var G_=l(Bl);Zm=o(G_,"pixel_values"),G_.forEach(e),B_.forEach(e),Xm=o(ut," como entrada. Este valor es generado por el extractor de caracter\xEDsticas. Crea una funci\xF3n que genere "),Gl=t(ut,"CODE",{});var J_=l(Gl);sh=o(J_,"pixel_values"),J_.forEach(e),ah=o(ut," a partir de las transformaciones:"),ut.forEach(e),F_.forEach(e),bc=i(s),w(Ce.$$.fragment,s),jc=i(s),Ae=t(s,"OL",{start:!0});var V_=l(Ae);Oe=t(V_,"LI",{});var Bi=l(Oe);eh=o(Bi,"A continuaci\xF3n, utiliza \u{1F917} Datasets "),Se=t(Bi,"A",{href:!0,rel:!0});var Y_=l(Se);Jl=t(Y_,"CODE",{});var M_=l(Jl);nh=o(M_,"set_transform"),M_.forEach(e),Y_.forEach(e),th=o(Bi," para aplicar las transformaciones sobre la marcha:"),Bi.forEach(e),V_.forEach(e),_c=i(s),w(Le.$$.fragment,s),gc=i(s),Ne=t(s,"OL",{start:!0});var W_=l(Ne);Re=t(W_,"LI",{});var Gi=l(Re);lh=o(Gi,"Ahora, cuando accedes a la imagen, observar\xE1s que el extractor de caracter\xEDsticas ha a\xF1adido a la entrada del modelo "),Vl=t(Gi,"CODE",{});var K_=l(Vl);rh=o(K_,"pixel_values"),K_.forEach(e),oh=o(Gi,":"),Gi.forEach(e),W_.forEach(e),vc=i(s),w(Ie.$$.fragment,s),Ec=i(s),Ln=t(s,"P",{});var Q_=l(Ln);ph=o(Q_,"Este es el aspecto de la imagen despu\xE9s de preprocesarla. Como era de esperar por las transformaciones aplicadas, la imagen ha sido recortada aleatoriamente y sus propiedades de color son diferentes."),Q_.forEach(e),$c=i(s),w(He.$$.fragment,s),kc=i(s),Nn=t(s,"P",{});var Z_=l(Nn);Rn=t(Z_,"IMG",{src:!0,alt:!0}),Z_.forEach(e),xc=i(s),ws=t(s,"H2",{class:!0});var Ji=l(ws);ka=t(Ji,"A",{id:!0,class:!0,href:!0});var X_=l(ka);Yl=t(X_,"SPAN",{});var sg=l(Yl);w(Ue.$$.fragment,sg),sg.forEach(e),X_.forEach(e),ch=i(Ji),Ml=t(Ji,"SPAN",{});var ag=l(Ml);ih=o(ag,"Multimodal"),ag.forEach(e),Ji.forEach(e),yc=i(s),In=t(s,"P",{});var eg=l(In);uh=o(eg,"Para las tareas multimodales utilizar\xE1s una combinaci\xF3n de todo lo que has aprendido hasta ahora y aplicar\xE1s tus habilidades a una tarea de reconocimiento autom\xE1tico de voz (ASR). Esto significa que necesitar\xE1s un:"),eg.forEach(e),wc=i(s),xa=t(s,"UL",{});var Vi=l(xa);Wl=t(Vi,"LI",{});var ng=l(Wl);dh=o(ng,"Extractor de caracter\xEDsticas para preprocesar los datos de audio."),ng.forEach(e),mh=i(Vi),Kl=t(Vi,"LI",{});var tg=l(Kl);hh=o(tg,"Un tokenizador para procesar el texto."),tg.forEach(e),Vi.forEach(e),qc=i(s),ya=t(s,"P",{});var Yi=l(ya);fh=o(Yi,"Volvamos al dataset "),Fe=t(Yi,"A",{href:!0,rel:!0});var lg=l(Fe);bh=o(lg,"LJ Speech"),lg.forEach(e),jh=o(Yi,":"),Yi.forEach(e),Tc=i(s),w(Be.$$.fragment,s),zc=i(s),ps=t(s,"P",{});var dt=l(ps);_h=o(dt,"Suponiendo que te interesan principalmente las columnas "),Ql=t(dt,"CODE",{});var rg=l(Ql);gh=o(rg,"audio"),rg.forEach(e),vh=o(dt," y "),Zl=t(dt,"CODE",{});var og=l(Zl);Eh=o(og,"texto"),og.forEach(e),$h=o(dt,", elimina las dem\xE1s columnas:"),dt.forEach(e),Dc=i(s),w(Ge.$$.fragment,s),Pc=i(s),cs=t(s,"P",{});var mt=l(cs);kh=o(mt,"Ahora echa un vistazo a las columnas "),Xl=t(mt,"CODE",{});var pg=l(Xl);xh=o(pg,"audio"),pg.forEach(e),yh=o(mt," y "),sr=t(mt,"CODE",{});var cg=l(sr);wh=o(cg,"texto"),cg.forEach(e),qh=o(mt,":"),mt.forEach(e),Cc=i(s),w(Je.$$.fragment,s),Ac=i(s),wa=t(s,"P",{});var Mi=l(wa);Th=o(Mi,"Recuerda la secci\xF3n anterior sobre el procesamiento de datos de audio, siempre debes "),Hn=t(Mi,"A",{href:!0});var ig=l(Hn);zh=o(ig,"volver a muestrear"),ig.forEach(e),Dh=o(Mi," la tasa de muestreo de tus datos de audio para que coincida con la tasa de muestreo del dataset utilizado para preentrenar un modelo:"),Mi.forEach(e),Oc=i(s),w(Ve.$$.fragment,s),Sc=i(s),qs=t(s,"H3",{class:!0});var Wi=l(qs);qa=t(Wi,"A",{id:!0,class:!0,href:!0});var ug=l(qa);ar=t(ug,"SPAN",{});var dg=l(ar);w(Ye.$$.fragment,dg),dg.forEach(e),ug.forEach(e),Ph=i(Wi),er=t(Wi,"SPAN",{});var mg=l(er);Ch=o(mg,"Processor"),mg.forEach(e),Wi.forEach(e),Lc=i(s),Un=t(s,"P",{});var hg=l(Un);Ah=o(hg,"Un processor combina un extractor de caracter\xEDsticas y un tokenizador. Cargue un procesador con [`AutoProcessor.from_pretrained]:"),hg.forEach(e),Nc=i(s),w(Me.$$.fragment,s),Rc=i(s),Fn=t(s,"OL",{});var fg=l(Fn);Ts=t(fg,"LI",{});var ht=l(Ts);Oh=o(ht,"Crea una funci\xF3n para procesar los datos de audio en "),nr=t(ht,"CODE",{});var bg=l(nr);Sh=o(bg,"input_values"),bg.forEach(e),Lh=o(ht,", y tokeniza el texto en "),tr=t(ht,"CODE",{});var jg=l(tr);Nh=o(jg,"labels"),jg.forEach(e),Rh=o(ht,". Estas son las entradas del modelo:"),ht.forEach(e),fg.forEach(e),Ic=i(s),w(We.$$.fragment,s),Hc=i(s),Ke=t(s,"OL",{start:!0});var _g=l(Ke);Qe=t(_g,"LI",{});var Ki=l(Qe);Ih=o(Ki,"Aplica la funci\xF3n "),lr=t(Ki,"CODE",{});var gg=l(lr);Hh=o(gg,"prepare_dataset"),gg.forEach(e),Uh=o(Ki," a una muestra:"),Ki.forEach(e),_g.forEach(e),Uc=i(s),w(Ze.$$.fragment,s),Fc=i(s),is=t(s,"P",{});var ft=l(is);Fh=o(ft,"Observa que el m\xE9todo processor ha a\xF1adido "),rr=t(ft,"CODE",{});var vg=l(rr);Bh=o(vg,"input_values"),vg.forEach(e),Gh=o(ft," y "),or=t(ft,"CODE",{});var Eg=l(or);Jh=o(Eg,"labels"),Eg.forEach(e),Vh=o(ft,". La tasa de muestreo tambi\xE9n se ha reducido correctamente a 16kHz."),ft.forEach(e),Bc=i(s),Bn=t(s,"P",{});var $g=l(Bn);Yh=o($g,"Genial, ahora deber\xEDas ser capaz de preprocesar datos para cualquier modalidad e incluso combinar diferentes modalidades. En el siguiente tutorial, aprender\xE1s aplicar fine tuning a un modelo en tus datos reci\xE9n preprocesados."),$g.forEach(e),Gc=i(s),zs=t(s,"H2",{class:!0});var Qi=l(zs);Ta=t(Qi,"A",{id:!0,class:!0,href:!0});var kg=l(Ta);pr=t(kg,"SPAN",{});var xg=l(pr);w(Xe.$$.fragment,xg),xg.forEach(e),kg.forEach(e),Mh=i(Qi),cr=t(Qi,"SPAN",{});var yg=l(cr);Wh=o(yg,"Todo lo que siempre quisiste saber sobre el padding y el truncamiento"),yg.forEach(e),Qi.forEach(e),Jc=i(s),G=t(s,"P",{});var Oa=l(G);Kh=o(Oa,`Hemos visto los comandos que funcionar\xE1n para la mayor\xEDa de los casos (hacer pad a tu batch teniendo en cuenta la longitud de la frase m\xE1xima y
truncar a la longitud m\xE1xima que el modelo puede aceptar). Sin embargo, la API admite m\xE1s estrategias si las necesitas. Los
tres argumentos que necesitas conocer para ello son `),ir=t(Oa,"CODE",{});var wg=l(ir);Qh=o(wg,"padding"),wg.forEach(e),Zh=o(Oa,", "),ur=t(Oa,"CODE",{});var qg=l(ur);Xh=o(qg,"truncation"),qg.forEach(e),sf=o(Oa," y "),dr=t(Oa,"CODE",{});var Tg=l(dr);af=o(Tg,"max_length"),Tg.forEach(e),ef=o(Oa,"."),Oa.forEach(e),Vc=i(s),us=t(s,"UL",{});var bt=l(us);sn=t(bt,"LI",{});var Zi=l(sn);Gn=t(Zi,"P",{});var wj=l(Gn);mr=t(wj,"CODE",{});var zg=l(mr);nf=o(zg,"padding"),zg.forEach(e),tf=o(wj," controla el aplicarme padding al texto. Puede ser un booleano o una cadena que debe ser:"),wj.forEach(e),lf=i(Zi),an=t(Zi,"UL",{});var Xi=l(an);za=t(Xi,"LI",{});var Fo=l(za);hr=t(Fo,"CODE",{});var Dg=l(hr);rf=o(Dg,"True"),Dg.forEach(e),of=o(Fo," o "),fr=t(Fo,"CODE",{});var Pg=l(fr);pf=o(Pg,"'longest'"),Pg.forEach(e),cf=o(Fo,` para aplicar el pad hasta la secuencia m\xE1s larga del batch (no apliques el padding si s\xF3lo le proporcionas
una sola secuencia).`),Fo.forEach(e),uf=i(Xi),L=t(Xi,"LI",{});var F=l(L);br=t(F,"CODE",{});var Cg=l(br);df=o(Cg,"'max_length'"),Cg.forEach(e),mf=o(F," para aplicar el pad hasta la longitud especificada por el argumento "),jr=t(F,"CODE",{});var Ag=l(jr);hf=o(Ag,"max_length"),Ag.forEach(e),ff=o(F,` o la longitud m\xE1xima aceptada
por el modelo si no le proporcionas `),_r=t(F,"CODE",{});var Og=l(_r);bf=o(Og,"longitud_m\xE1xima"),Og.forEach(e),jf=o(F," ("),gr=t(F,"CODE",{});var Sg=l(gr);_f=o(Sg,"longitud_m\xE1xima=None"),Sg.forEach(e),gf=o(F,`). Si s\xF3lo le proporcionas una \xFAnica secuencia
se le aplicar\xE1 el padding.
`),vr=t(F,"CODE",{});var Lg=l(vr);vf=o(Lg,"False"),Lg.forEach(e),Ef=o(F," o "),Er=t(F,"CODE",{});var Ng=l(Er);$f=o(Ng,"'do_not_pad'"),Ng.forEach(e),kf=o(F,` para no aplicar pad a las secuencias. Como hemos visto antes, este es el comportamiento por
defecto.`),F.forEach(e),Xi.forEach(e),Zi.forEach(e),xf=i(bt),en=t(bt,"LI",{});var su=l(en);Jn=t(su,"P",{});var qj=l(Jn);$r=t(qj,"CODE",{});var Rg=l($r);yf=o(Rg,"truncation"),Rg.forEach(e),wf=o(qj," controla el truncamiento. Puede ser un booleano o una string que debe ser:"),qj.forEach(e),qf=i(su),W=t(su,"UL",{});var Sa=l(W);I=t(Sa,"LI",{});var K=l(I);kr=t(K,"CODE",{});var Ig=l(kr);Tf=o(Ig,"True"),Ig.forEach(e),zf=o(K," o "),xr=t(K,"CODE",{});var Hg=l(xr);Df=o(Hg,"'longest_first'"),Hg.forEach(e),Pf=o(K," truncan hasta la longitud m\xE1xima especificada por el argumento "),yr=t(K,"CODE",{});var Ug=l(yr);Cf=o(Ug,"max_length"),Ug.forEach(e),Af=o(K,` o
la longitud m\xE1xima aceptada por el modelo si no le proporcionas `),wr=t(K,"CODE",{});var Fg=l(wr);Of=o(Fg,"max_length"),Fg.forEach(e),Sf=o(K," ("),qr=t(K,"CODE",{});var Bg=l(qr);Lf=o(Bg,"max_length=None"),Bg.forEach(e),Nf=o(K,`). Esto
truncar\xE1 token por token, eliminando un token de la secuencia m\xE1s larga del par hasta alcanzar la longitud
adecuada.`),K.forEach(e),Rf=i(Sa),J=t(Sa,"LI",{});var Ks=l(J);Tr=t(Ks,"CODE",{});var Gg=l(Tr);If=o(Gg,"'only_second'"),Gg.forEach(e),Hf=o(Ks," trunca hasta la longitud m\xE1xima especificada por el argumento "),zr=t(Ks,"CODE",{});var Jg=l(zr);Uf=o(Jg,"max_length"),Jg.forEach(e),Ff=o(Ks,` o la
longitud m\xE1xima aceptada por el modelo si no le proporcionas `),Dr=t(Ks,"CODE",{});var Vg=l(Dr);Bf=o(Vg,"max_length"),Vg.forEach(e),Gf=o(Ks," ("),Pr=t(Ks,"CODE",{});var Yg=l(Pr);Jf=o(Yg,"max_length=None"),Yg.forEach(e),Vf=o(Ks,`). Esto s\xF3lo truncar\xE1
la segunda frase de un par si le proporcionas un par de secuencias (o un batch de pares de secuencias).`),Ks.forEach(e),Yf=i(Sa),V=t(Sa,"LI",{});var Qs=l(V);Cr=t(Qs,"CODE",{});var Mg=l(Cr);Mf=o(Mg,"'only_first'"),Mg.forEach(e),Wf=o(Qs," trunca hasta la longitud m\xE1xima especificada por el argumento "),Ar=t(Qs,"CODE",{});var Wg=l(Ar);Kf=o(Wg,"max_length"),Wg.forEach(e),Qf=o(Qs,` o la longitud m\xE1xima
aceptada por el modelo si no se proporciona `),Or=t(Qs,"CODE",{});var Kg=l(Or);Zf=o(Kg,"max_length"),Kg.forEach(e),Xf=o(Qs," ("),Sr=t(Qs,"CODE",{});var Qg=l(Sr);sb=o(Qg,"max_length=None"),Qg.forEach(e),ab=o(Qs,`). Esto s\xF3lo truncar\xE1
la primera frase de un par si se proporciona un par de secuencias (o un lote de pares de secuencias).`),Qs.forEach(e),eb=i(Sa),Da=t(Sa,"LI",{});var Bo=l(Da);Lr=t(Bo,"CODE",{});var Zg=l(Lr);nb=o(Zg,"False"),Zg.forEach(e),tb=o(Bo," o "),Nr=t(Bo,"CODE",{});var Xg=l(Nr);lb=o(Xg,"'do_not_truncate'"),Xg.forEach(e),rb=o(Bo,` para no truncar las secuencias. Como hemos visto antes, este es el comportamiento
por defecto.`),Bo.forEach(e),Sa.forEach(e),su.forEach(e),ob=i(bt),Rr=t(bt,"LI",{});var s2=l(Rr);ds=t(s2,"P",{});var tn=l(ds);Ir=t(tn,"CODE",{});var a2=l(Ir);pb=o(a2,"max_length"),a2.forEach(e),cb=o(tn," para controlar la longitud del padding/truncamiento. Puede ser un n\xFAmero entero o "),Hr=t(tn,"CODE",{});var e2=l(Hr);ib=o(e2,"None"),e2.forEach(e),ub=o(tn,`, en cuyo caso
ser\xE1 por defecto la longitud m\xE1xima que el modelo puede aceptar. Si el modelo no tiene una longitud m\xE1xima de entrada espec\xEDfica, el
padding/truncamiento a `),Ur=t(tn,"CODE",{});var n2=l(Ur);db=o(n2,"longitud_m\xE1xima"),n2.forEach(e),mb=o(tn," se desactiva."),tn.forEach(e),s2.forEach(e),bt.forEach(e),Yc=i(s),N=t(s,"P",{});var Y=l(N);hb=o(Y,`A continuaci\xF3n te mostramos en una tabla que resume la forma recomendada de configurar el padding y el truncamiento. Si utilizas un par de secuencias de entrada en
algunos de los siguientes ejemplos, puedes sustituir `),Fr=t(Y,"CODE",{});var t2=l(Fr);fb=o(t2,"truncation=True"),t2.forEach(e),bb=o(Y," por una "),Br=t(Y,"CODE",{});var l2=l(Br);jb=o(l2,"STRATEGY"),l2.forEach(e),_b=o(Y,` seleccionada en
`),Gr=t(Y,"CODE",{});var r2=l(Gr);gb=o(r2,"['only_first', 'only_second', 'longest_first']"),r2.forEach(e),vb=o(Y,", es decir, "),Jr=t(Y,"CODE",{});var o2=l(Jr);Eb=o(o2,"truncation='only_second'"),o2.forEach(e),$b=o(Y," o "),Vr=t(Y,"CODE",{});var p2=l(Vr);kb=o(p2,"truncation= 'longest_first'"),p2.forEach(e),xb=o(Y," para controlar c\xF3mo se truncan ambas secuencias del par como se ha detallado anteriormente."),Y.forEach(e),Mc=i(s),Pa=t(s,"TABLE",{});var au=l(Pa);Yr=t(au,"THEAD",{});var c2=l(Yr);Ds=t(c2,"TR",{});var jt=l(Ds);Mr=t(jt,"TH",{});var i2=l(Mr);yb=o(i2,"Truncation"),i2.forEach(e),wb=i(jt),Wr=t(jt,"TH",{});var u2=l(Wr);qb=o(u2,"Padding"),u2.forEach(e),Tb=i(jt),Kr=t(jt,"TH",{});var d2=l(Kr);zb=o(d2,"Instrucciones"),d2.forEach(e),jt.forEach(e),c2.forEach(e),Db=i(au),P=t(au,"TBODY",{});var C=l(P);Ps=t(C,"TR",{});var _t=l(Ps);Qr=t(_t,"TD",{});var m2=l(Qr);Pb=o(m2,"no truncation"),m2.forEach(e),Cb=i(_t),Zr=t(_t,"TD",{});var h2=l(Zr);Ab=o(h2,"no padding"),h2.forEach(e),Ob=i(_t),Xr=t(_t,"TD",{});var f2=l(Xr);so=t(f2,"CODE",{});var b2=l(so);Sb=o(b2,"tokenizer(batch_sentences)"),b2.forEach(e),f2.forEach(e),_t.forEach(e),Lb=i(C),Cs=t(C,"TR",{});var gt=l(Cs);Wc=t(gt,"TD",{}),l(Wc).forEach(e),Nb=i(gt),ao=t(gt,"TD",{});var j2=l(ao);Rb=o(j2,"padding secuencia max del batch"),j2.forEach(e),Ib=i(gt),Vn=t(gt,"TD",{});var Tj=l(Vn);eo=t(Tj,"CODE",{});var _2=l(eo);Hb=o(_2,"tokenizer(batch_sentences, padding=True)"),_2.forEach(e),Ub=o(Tj," or"),Tj.forEach(e),gt.forEach(e),Fb=i(C),As=t(C,"TR",{});var vt=l(As);Kc=t(vt,"TD",{}),l(Kc).forEach(e),Bb=i(vt),Qc=t(vt,"TD",{}),l(Qc).forEach(e),Gb=i(vt),no=t(vt,"TD",{});var g2=l(no);to=t(g2,"CODE",{});var v2=l(to);Jb=o(v2,"tokenizer(batch_sentences, padding='longest')"),v2.forEach(e),g2.forEach(e),vt.forEach(e),Vb=i(C),Os=t(C,"TR",{});var Et=l(Os);Zc=t(Et,"TD",{}),l(Zc).forEach(e),Yb=i(Et),lo=t(Et,"TD",{});var E2=l(lo);Mb=o(E2,"padding long max de input model"),E2.forEach(e),Wb=i(Et),ro=t(Et,"TD",{});var $2=l(ro);oo=t($2,"CODE",{});var k2=l(oo);Kb=o(k2,"tokenizer(batch_sentences, padding='max_length')"),k2.forEach(e),$2.forEach(e),Et.forEach(e),Qb=i(C),Ss=t(C,"TR",{});var $t=l(Ss);Xc=t($t,"TD",{}),l(Xc).forEach(e),Zb=i($t),po=t($t,"TD",{});var x2=l(po);Xb=o(x2,"padding a una long especifica"),x2.forEach(e),s1=i($t),co=t($t,"TD",{});var y2=l(co);io=t(y2,"CODE",{});var w2=l(io);a1=o(w2,"tokenizer(batch_sentences, padding='max_length', max_length=42)"),w2.forEach(e),y2.forEach(e),$t.forEach(e),e1=i(C),Ls=t(C,"TR",{});var kt=l(Ls);uo=t(kt,"TD",{});var q2=l(uo);n1=o(q2,"truncation long max del input model"),q2.forEach(e),t1=i(kt),mo=t(kt,"TD",{});var T2=l(mo);l1=o(T2,"no padding"),T2.forEach(e),r1=i(kt),Yn=t(kt,"TD",{});var zj=l(Yn);ho=t(zj,"CODE",{});var z2=l(ho);o1=o(z2,"tokenizer(batch_sentences, truncation=True)"),z2.forEach(e),p1=o(zj," or"),zj.forEach(e),kt.forEach(e),c1=i(C),Ns=t(C,"TR",{});var xt=l(Ns);si=t(xt,"TD",{}),l(si).forEach(e),i1=i(xt),ai=t(xt,"TD",{}),l(ai).forEach(e),u1=i(xt),fo=t(xt,"TD",{});var D2=l(fo);bo=t(D2,"CODE",{});var P2=l(bo);d1=o(P2,"tokenizer(batch_sentences, truncation=STRATEGY)"),P2.forEach(e),D2.forEach(e),xt.forEach(e),m1=i(C),Rs=t(C,"TR",{});var yt=l(Rs);ei=t(yt,"TD",{}),l(ei).forEach(e),h1=i(yt),jo=t(yt,"TD",{});var C2=l(jo);f1=o(C2,"padding secuencia max del batch"),C2.forEach(e),b1=i(yt),Mn=t(yt,"TD",{});var Dj=l(Mn);_o=t(Dj,"CODE",{});var A2=l(_o);j1=o(A2,"tokenizer(batch_sentences, padding=True, truncation=True)"),A2.forEach(e),_1=o(Dj," or"),Dj.forEach(e),yt.forEach(e),g1=i(C),Is=t(C,"TR",{});var wt=l(Is);ni=t(wt,"TD",{}),l(ni).forEach(e),v1=i(wt),ti=t(wt,"TD",{}),l(ti).forEach(e),E1=i(wt),go=t(wt,"TD",{});var O2=l(go);vo=t(O2,"CODE",{});var S2=l(vo);$1=o(S2,"tokenizer(batch_sentences, padding=True, truncation=STRATEGY)"),S2.forEach(e),O2.forEach(e),wt.forEach(e),k1=i(C),Hs=t(C,"TR",{});var qt=l(Hs);li=t(qt,"TD",{}),l(li).forEach(e),x1=i(qt),Eo=t(qt,"TD",{});var L2=l(Eo);y1=o(L2,"padding long max de input model"),L2.forEach(e),w1=i(qt),Wn=t(qt,"TD",{});var Pj=l(Wn);$o=t(Pj,"CODE",{});var N2=l($o);q1=o(N2,"tokenizer(batch_sentences, padding='max_length', truncation=True)"),N2.forEach(e),T1=o(Pj," or"),Pj.forEach(e),qt.forEach(e),z1=i(C),Us=t(C,"TR",{});var Tt=l(Us);ri=t(Tt,"TD",{}),l(ri).forEach(e),D1=i(Tt),oi=t(Tt,"TD",{}),l(oi).forEach(e),P1=i(Tt),ko=t(Tt,"TD",{});var R2=l(ko);xo=t(R2,"CODE",{});var I2=l(xo);C1=o(I2,"tokenizer(batch_sentences, padding='max_length', truncation=STRATEGY)"),I2.forEach(e),R2.forEach(e),Tt.forEach(e),A1=i(C),Fs=t(C,"TR",{});var zt=l(Fs);pi=t(zt,"TD",{}),l(pi).forEach(e),O1=i(zt),yo=t(zt,"TD",{});var H2=l(yo);S1=o(H2,"padding a una long especifica"),H2.forEach(e),L1=i(zt),wo=t(zt,"TD",{});var U2=l(wo);N1=o(U2,"Not possible"),U2.forEach(e),zt.forEach(e),R1=i(C),Bs=t(C,"TR",{});var Dt=l(Bs);qo=t(Dt,"TD",{});var F2=l(qo);I1=o(F2,"truncation a una long especifica"),F2.forEach(e),H1=i(Dt),To=t(Dt,"TD",{});var B2=l(To);U1=o(B2,"no padding"),B2.forEach(e),F1=i(Dt),Kn=t(Dt,"TD",{});var Cj=l(Kn);zo=t(Cj,"CODE",{});var G2=l(zo);B1=o(G2,"tokenizer(batch_sentences, truncation=True, max_length=42)"),G2.forEach(e),G1=o(Cj," or"),Cj.forEach(e),Dt.forEach(e),J1=i(C),Gs=t(C,"TR",{});var Pt=l(Gs);ci=t(Pt,"TD",{}),l(ci).forEach(e),V1=i(Pt),ii=t(Pt,"TD",{}),l(ii).forEach(e),Y1=i(Pt),Do=t(Pt,"TD",{});var J2=l(Do);Po=t(J2,"CODE",{});var V2=l(Po);M1=o(V2,"tokenizer(batch_sentences, truncation=STRATEGY, max_length=42)"),V2.forEach(e),J2.forEach(e),Pt.forEach(e),W1=i(C),Js=t(C,"TR",{});var Ct=l(Js);ui=t(Ct,"TD",{}),l(ui).forEach(e),K1=i(Ct),Co=t(Ct,"TD",{});var Y2=l(Co);Q1=o(Y2,"padding secuencia max del batch"),Y2.forEach(e),Z1=i(Ct),Qn=t(Ct,"TD",{});var Aj=l(Qn);Ao=t(Aj,"CODE",{});var M2=l(Ao);X1=o(M2,"tokenizer(batch_sentences, padding=True, truncation=True, max_length=42)"),M2.forEach(e),sj=o(Aj," or"),Aj.forEach(e),Ct.forEach(e),aj=i(C),Vs=t(C,"TR",{});var At=l(Vs);di=t(At,"TD",{}),l(di).forEach(e),ej=i(At),mi=t(At,"TD",{}),l(mi).forEach(e),nj=i(At),Oo=t(At,"TD",{});var W2=l(Oo);So=t(W2,"CODE",{});var K2=l(So);tj=o(K2,"tokenizer(batch_sentences, padding=True, truncation=STRATEGY, max_length=42)"),K2.forEach(e),W2.forEach(e),At.forEach(e),lj=i(C),Ys=t(C,"TR",{});var Ot=l(Ys);hi=t(Ot,"TD",{}),l(hi).forEach(e),rj=i(Ot),Lo=t(Ot,"TD",{});var Q2=l(Lo);oj=o(Q2,"padding long max de input model"),Q2.forEach(e),pj=i(Ot),No=t(Ot,"TD",{});var Z2=l(No);cj=o(Z2,"Not possible"),Z2.forEach(e),Ot.forEach(e),ij=i(C),Ms=t(C,"TR",{});var St=l(Ms);fi=t(St,"TD",{}),l(fi).forEach(e),uj=i(St),Ro=t(St,"TD",{});var X2=l(Ro);dj=o(X2,"padding a una long especifica"),X2.forEach(e),mj=i(St),Zn=t(St,"TD",{});var Oj=l(Zn);Io=t(Oj,"CODE",{});var sv=l(Io);hj=o(sv,"tokenizer(batch_sentences, padding='max_length', truncation=True, max_length=42)"),sv.forEach(e),fj=o(Oj," or"),Oj.forEach(e),St.forEach(e),bj=i(C),Ws=t(C,"TR",{});var Lt=l(Ws);bi=t(Lt,"TD",{}),l(bi).forEach(e),jj=i(Lt),ji=t(Lt,"TD",{}),l(ji).forEach(e),_j=i(Lt),Ho=t(Lt,"TD",{});var av=l(Ho);Uo=t(av,"CODE",{});var ev=l(Uo);gj=o(ev,"tokenizer(batch_sentences, padding='max_length', truncation=STRATEGY, max_length=42)"),ev.forEach(e),av.forEach(e),Lt.forEach(e),C.forEach(e),au.forEach(e),this.h()},h(){d(m,"name","hf:doc:metadata"),d(m,"content",JSON.stringify(Ov)),d(v,"id","preprocesamiento"),d(v,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(v,"href","#preprocesamiento"),d(b,"class","relative group"),d(Xs,"id","nlp"),d(Xs,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Xs,"href","#nlp"),d(ms,"class","relative group"),d(ln,"href","main_classes/tokenizer"),d(aa,"id","tokenizar"),d(aa,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(aa,"href","#tokenizar"),d(hs,"class","relative group"),d(cn,"href","glossary#input-ids"),d(dn,"href","glossary#attention-mask"),d(hn,"href","glossary#token-type-ids"),d(ta,"id","pad"),d(ta,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ta,"href","#pad"),d(fs,"class","relative group"),d(la,"id","truncamiento"),d(la,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(la,"href","#truncamiento"),d(bs,"class","relative group"),d(ra,"id","construye-tensores"),d(ra,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ra,"href","#construye-tensores"),d(js,"class","relative group"),d(oa,"id","audio"),d(oa,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(oa,"href","#audio"),d(_s,"class","relative group"),d(vn,"href","main_classes/feature_extractor"),d(Qa,"href","https://huggingface.co/datasets/superb"),d(Qa,"rel","nofollow"),d(Za,"href","https://huggingface.co/docs/datasets/load_hub.html"),d(Za,"rel","nofollow"),d(ca,"id","resample"),d(ca,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ca,"href","#resample"),d(gs,"class","relative group"),d(ee,"href","https://huggingface.co/facebook/wav2vec2-base"),d(ee,"rel","nofollow"),d(ne,"href","https://huggingface.co/datasets/lj_speech"),d(ne,"rel","nofollow"),d(re,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.cast_column"),d(re,"rel","nofollow"),d(pe,"start","2"),d(ma,"id","extractor-de-caractersticas"),d(ma,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ma,"href","#extractor-de-caractersticas"),d(vs,"class","relative group"),d(fa,"id","pad-y-truncamiento"),d(fa,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(fa,"href","#pad-y-truncamiento"),d(Es,"class","relative group"),d(ja,"id","visin"),d(ja,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ja,"href","#visin"),d($s,"class","relative group"),d(ge,"href","https://huggingface.co/datasets/food101"),d(ge,"rel","nofollow"),d(Ee,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html?highlight=image#datasets.Image"),d(Ee,"rel","nofollow"),tv(An.src,Rj="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/vision-preprocess-tutorial.png")||d(An,"src",Rj),d(An,"alt","vision-preprocess-tutorial.png"),d(ga,"id","extractor-de-caractersticas"),d(ga,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ga,"href","#extractor-de-caractersticas"),d(ks,"class","relative group"),d(Ea,"id","aumento-de-datos"),d(Ea,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ea,"href","#aumento-de-datos"),d(xs,"class","relative group"),d(we,"href","https://pytorch.org/vision/stable/transforms.html"),d(we,"rel","nofollow"),d(qe,"href","https://pytorch.org/vision/master/generated/torchvision.transforms.Compose.html"),d(qe,"rel","nofollow"),d(Te,"href","https://pytorch.org/vision/main/generated/torchvision.transforms.RandomResizedCrop.html"),d(Te,"rel","nofollow"),d(ze,"href","https://pytorch.org/vision/main/generated/torchvision.transforms.ColorJitter.html"),d(ze,"rel","nofollow"),d(Sn,"href","model_doc/visionencoderdecoder#transformers.VisionEncoderDecoderModel.forward.pixel_values"),d(Pe,"start","2"),d(Se,"href","https://huggingface.co/docs/datasets/process.html#format-transform"),d(Se,"rel","nofollow"),d(Ae,"start","3"),d(Ne,"start","4"),tv(Rn.src,Ij="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/preprocessed_image.png")||d(Rn,"src",Ij),d(Rn,"alt","preprocessed_image"),d(ka,"id","multimodal"),d(ka,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ka,"href","#multimodal"),d(ws,"class","relative group"),d(Fe,"href","https://huggingface.co/datasets/lj_speech"),d(Fe,"rel","nofollow"),d(Hn,"href","preprocessing#audio"),d(qa,"id","processor"),d(qa,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(qa,"href","#processor"),d(qs,"class","relative group"),d(Ke,"start","2"),d(Ta,"id","todo-lo-que-siempre-quisiste-saber-sobre-el-padding-y-el-truncamiento"),d(Ta,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ta,"href","#todo-lo-que-siempre-quisiste-saber-sobre-el-padding-y-el-truncamiento"),d(zs,"class","relative group")},m(s,p){a(document.head,m),u(s,f,p),u(s,b,p),a(b,v),a(v,j),y(q,j,null),a(b,E),a(b,$),a($,h),u(s,z,p),y(D,s,p),u(s,A,p),u(s,Zs,p),a(Zs,H),u(s,S,p),u(s,U,p),a(U,Nt),a(Nt,tu),a(U,lu),a(U,Rt),a(Rt,ru),a(U,ou),a(U,It),a(It,pu),u(s,Jo,p),u(s,ms,p),a(ms,Xs),a(Xs,Ht),y(La,Ht,null),a(ms,cu),a(ms,Ut),a(Ut,iu),u(s,Vo,p),y(Na,s,p),u(s,Yo,p),u(s,Q,p),a(Q,uu),a(Q,ln),a(ln,du),a(Q,mu),a(Q,Ft),a(Ft,hu),a(Q,fu),u(s,Mo,p),y(sa,s,p),u(s,Wo,p),u(s,Z,p),a(Z,bu),a(Z,Bt),a(Bt,ju),a(Z,_u),a(Z,Gt),a(Gt,gu),a(Z,vu),u(s,Ko,p),u(s,hs,p),a(hs,aa),a(aa,Jt),y(Ra,Jt,null),a(hs,Eu),a(hs,Vt),a(Vt,$u),u(s,Qo,p),u(s,ea,p),a(ea,ku),a(ea,Yt),a(Yt,xu),a(ea,yu),u(s,Zo,p),y(Ia,s,p),u(s,Xo,p),u(s,rn,p),a(rn,wu),u(s,sp,p),y(Ha,s,p),u(s,ap,p),u(s,on,p),a(on,qu),u(s,ep,p),u(s,X,p),a(X,pn),a(pn,cn),a(cn,Tu),a(pn,zu),a(X,Du),a(X,un),a(un,dn),a(dn,Pu),a(un,Cu),a(X,Au),a(X,mn),a(mn,hn),a(hn,Ou),a(mn,Su),u(s,np,p),u(s,na,p),a(na,Lu),a(na,Mt),a(Mt,Nu),a(na,Ru),u(s,tp,p),y(Ua,s,p),u(s,lp,p),u(s,ss,p),a(ss,Iu),a(ss,Wt),a(Wt,Hu),a(ss,Uu),a(ss,Kt),a(Kt,Fu),a(ss,Bu),u(s,rp,p),u(s,fn,p),a(fn,Gu),u(s,op,p),y(Fa,s,p),u(s,pp,p),u(s,fs,p),a(fs,ta),a(ta,Qt),y(Ba,Qt,null),a(fs,Ju),a(fs,Zt),a(Zt,Vu),u(s,cp,p),u(s,bn,p),a(bn,Yu),u(s,ip,p),u(s,as,p),a(as,Mu),a(as,Xt),a(Xt,Wu),a(as,Ku),a(as,sl),a(sl,Qu),a(as,Zu),u(s,up,p),y(Ga,s,p),u(s,dp,p),u(s,jn,p),a(jn,Xu),u(s,mp,p),u(s,bs,p),a(bs,la),a(la,al),y(Ja,al,null),a(bs,sd),a(bs,el),a(el,ad),u(s,hp,p),u(s,_n,p),a(_n,ed),u(s,fp,p),u(s,es,p),a(es,nd),a(es,nl),a(nl,td),a(es,ld),a(es,tl),a(tl,rd),a(es,od),u(s,bp,p),y(Va,s,p),u(s,jp,p),u(s,js,p),a(js,ra),a(ra,ll),y(Ya,ll,null),a(js,pd),a(js,rl),a(rl,cd),u(s,_p,p),u(s,gn,p),a(gn,id),u(s,gp,p),u(s,B,p),a(B,ud),a(B,ol),a(ol,dd),a(B,md),a(B,pl),a(pl,hd),a(B,fd),a(B,cl),a(cl,bd),a(B,jd),u(s,vp,p),y(Ma,s,p),u(s,Ep,p),u(s,_s,p),a(_s,oa),a(oa,il),y(Wa,il,null),a(_s,_d),a(_s,ul),a(ul,gd),u(s,$p,p),u(s,pa,p),a(pa,vd),a(pa,vn),a(vn,Ed),a(pa,$d),u(s,kp,p),y(Ka,s,p),u(s,xp,p),u(s,ns,p),a(ns,kd),a(ns,Qa),a(Qa,xd),a(ns,yd),a(ns,Za),a(Za,wd),a(ns,qd),u(s,yp,p),y(Xa,s,p),u(s,wp,p),u(s,ts,p),a(ts,Td),a(ts,dl),a(dl,zd),a(ts,Dd),a(ts,ml),a(ml,Pd),a(ts,Cd),u(s,qp,p),y(se,s,p),u(s,Tp,p),u(s,En,p),a(En,Ad),u(s,zp,p),u(s,ls,p),a(ls,$n),a($n,hl),a(hl,Od),a($n,Sd),a(ls,Ld),a(ls,kn),a(kn,fl),a(fl,Nd),a(kn,Rd),a(ls,Id),a(ls,xn),a(xn,bl),a(bl,Hd),a(xn,Ud),u(s,Dp,p),u(s,gs,p),a(gs,ca),a(ca,jl),y(ae,jl,null),a(gs,Fd),a(gs,_l),a(_l,Bd),u(s,Pp,p),u(s,ia,p),a(ia,Gd),a(ia,ee),a(ee,Jd),a(ia,Vd),u(s,Cp,p),u(s,ua,p),a(ua,Yd),a(ua,ne),a(ne,Md),a(ua,Wd),u(s,Ap,p),y(te,s,p),u(s,Op,p),u(s,yn,p),a(yn,le),a(le,Kd),a(le,re),a(re,gl),a(gl,Qd),a(le,Zd),u(s,Sp,p),y(oe,s,p),u(s,Lp,p),u(s,pe,p),a(pe,vl),a(vl,Xd),u(s,Np,p),y(ce,s,p),u(s,Rp,p),u(s,da,p),a(da,sm),a(da,El),a(El,am),a(da,em),u(s,Ip,p),u(s,vs,p),a(vs,ma),a(ma,$l),y(ie,$l,null),a(vs,nm),a(vs,kl),a(kl,tm),u(s,Hp,p),u(s,wn,p),a(wn,lm),u(s,Up,p),u(s,ha,p),a(ha,rm),a(ha,xl),a(xl,om),a(ha,pm),u(s,Fp,p),y(ue,s,p),u(s,Bp,p),u(s,rs,p),a(rs,cm),a(rs,yl),a(yl,im),a(rs,um),a(rs,wl),a(wl,dm),a(rs,mm),u(s,Gp,p),y(de,s,p),u(s,Jp,p),u(s,Es,p),a(Es,fa),a(fa,ql),y(me,ql,null),a(Es,hm),a(Es,Tl),a(Tl,fm),u(s,Vp,p),u(s,qn,p),a(qn,bm),u(s,Yp,p),y(he,s,p),u(s,Mp,p),u(s,ba,p),a(ba,jm),a(ba,zl),a(zl,_m),a(ba,gm),u(s,Wp,p),y(fe,s,p),u(s,Kp,p),u(s,Tn,p),a(Tn,vm),u(s,Qp,p),y(be,s,p),u(s,Zp,p),u(s,zn,p),a(zn,Em),u(s,Xp,p),y(je,s,p),u(s,sc,p),u(s,Dn,p),a(Dn,$m),u(s,ac,p),u(s,$s,p),a($s,ja),a(ja,Dl),y(_e,Dl,null),a($s,km),a($s,Pl),a(Pl,xm),u(s,ec,p),u(s,Pn,p),a(Pn,ym),u(s,nc,p),u(s,os,p),a(os,wm),a(os,ge),a(ge,qm),a(os,Tm),a(os,Cl),a(Cl,zm),a(os,Dm),u(s,tc,p),y(ve,s,p),u(s,lc,p),u(s,_a,p),a(_a,Pm),a(_a,Ee),a(Ee,Al),a(Al,Cm),a(_a,Am),u(s,rc,p),y($e,s,p),u(s,oc,p),u(s,Cn,p),a(Cn,An),u(s,pc,p),u(s,ks,p),a(ks,ga),a(ga,Ol),y(ke,Ol,null),a(ks,Om),a(ks,Sl),a(Sl,Sm),u(s,cc,p),u(s,va,p),a(va,Lm),a(va,Ll),a(Ll,Nm),a(va,Rm),u(s,ic,p),y(xe,s,p),u(s,uc,p),u(s,xs,p),a(xs,Ea),a(Ea,Nl),y(ye,Nl,null),a(xs,Im),a(xs,Rl),a(Rl,Hm),u(s,dc,p),u(s,$a,p),a($a,Um),a($a,we),a(we,Il),a(Il,Fm),a($a,Bm),u(s,mc,p),u(s,On,p),a(On,M),a(M,Gm),a(M,qe),a(qe,Hl),a(Hl,Jm),a(M,Vm),a(M,Te),a(Te,Ul),a(Ul,Ym),a(M,Mm),a(M,ze),a(ze,Fl),a(Fl,Wm),a(M,Km),u(s,hc,p),y(De,s,p),u(s,fc,p),u(s,Pe,p),a(Pe,ys),a(ys,Qm),a(ys,Sn),a(Sn,Bl),a(Bl,Zm),a(ys,Xm),a(ys,Gl),a(Gl,sh),a(ys,ah),u(s,bc,p),y(Ce,s,p),u(s,jc,p),u(s,Ae,p),a(Ae,Oe),a(Oe,eh),a(Oe,Se),a(Se,Jl),a(Jl,nh),a(Oe,th),u(s,_c,p),y(Le,s,p),u(s,gc,p),u(s,Ne,p),a(Ne,Re),a(Re,lh),a(Re,Vl),a(Vl,rh),a(Re,oh),u(s,vc,p),y(Ie,s,p),u(s,Ec,p),u(s,Ln,p),a(Ln,ph),u(s,$c,p),y(He,s,p),u(s,kc,p),u(s,Nn,p),a(Nn,Rn),u(s,xc,p),u(s,ws,p),a(ws,ka),a(ka,Yl),y(Ue,Yl,null),a(ws,ch),a(ws,Ml),a(Ml,ih),u(s,yc,p),u(s,In,p),a(In,uh),u(s,wc,p),u(s,xa,p),a(xa,Wl),a(Wl,dh),a(xa,mh),a(xa,Kl),a(Kl,hh),u(s,qc,p),u(s,ya,p),a(ya,fh),a(ya,Fe),a(Fe,bh),a(ya,jh),u(s,Tc,p),y(Be,s,p),u(s,zc,p),u(s,ps,p),a(ps,_h),a(ps,Ql),a(Ql,gh),a(ps,vh),a(ps,Zl),a(Zl,Eh),a(ps,$h),u(s,Dc,p),y(Ge,s,p),u(s,Pc,p),u(s,cs,p),a(cs,kh),a(cs,Xl),a(Xl,xh),a(cs,yh),a(cs,sr),a(sr,wh),a(cs,qh),u(s,Cc,p),y(Je,s,p),u(s,Ac,p),u(s,wa,p),a(wa,Th),a(wa,Hn),a(Hn,zh),a(wa,Dh),u(s,Oc,p),y(Ve,s,p),u(s,Sc,p),u(s,qs,p),a(qs,qa),a(qa,ar),y(Ye,ar,null),a(qs,Ph),a(qs,er),a(er,Ch),u(s,Lc,p),u(s,Un,p),a(Un,Ah),u(s,Nc,p),y(Me,s,p),u(s,Rc,p),u(s,Fn,p),a(Fn,Ts),a(Ts,Oh),a(Ts,nr),a(nr,Sh),a(Ts,Lh),a(Ts,tr),a(tr,Nh),a(Ts,Rh),u(s,Ic,p),y(We,s,p),u(s,Hc,p),u(s,Ke,p),a(Ke,Qe),a(Qe,Ih),a(Qe,lr),a(lr,Hh),a(Qe,Uh),u(s,Uc,p),y(Ze,s,p),u(s,Fc,p),u(s,is,p),a(is,Fh),a(is,rr),a(rr,Bh),a(is,Gh),a(is,or),a(or,Jh),a(is,Vh),u(s,Bc,p),u(s,Bn,p),a(Bn,Yh),u(s,Gc,p),u(s,zs,p),a(zs,Ta),a(Ta,pr),y(Xe,pr,null),a(zs,Mh),a(zs,cr),a(cr,Wh),u(s,Jc,p),u(s,G,p),a(G,Kh),a(G,ir),a(ir,Qh),a(G,Zh),a(G,ur),a(ur,Xh),a(G,sf),a(G,dr),a(dr,af),a(G,ef),u(s,Vc,p),u(s,us,p),a(us,sn),a(sn,Gn),a(Gn,mr),a(mr,nf),a(Gn,tf),a(sn,lf),a(sn,an),a(an,za),a(za,hr),a(hr,rf),a(za,of),a(za,fr),a(fr,pf),a(za,cf),a(an,uf),a(an,L),a(L,br),a(br,df),a(L,mf),a(L,jr),a(jr,hf),a(L,ff),a(L,_r),a(_r,bf),a(L,jf),a(L,gr),a(gr,_f),a(L,gf),a(L,vr),a(vr,vf),a(L,Ef),a(L,Er),a(Er,$f),a(L,kf),a(us,xf),a(us,en),a(en,Jn),a(Jn,$r),a($r,yf),a(Jn,wf),a(en,qf),a(en,W),a(W,I),a(I,kr),a(kr,Tf),a(I,zf),a(I,xr),a(xr,Df),a(I,Pf),a(I,yr),a(yr,Cf),a(I,Af),a(I,wr),a(wr,Of),a(I,Sf),a(I,qr),a(qr,Lf),a(I,Nf),a(W,Rf),a(W,J),a(J,Tr),a(Tr,If),a(J,Hf),a(J,zr),a(zr,Uf),a(J,Ff),a(J,Dr),a(Dr,Bf),a(J,Gf),a(J,Pr),a(Pr,Jf),a(J,Vf),a(W,Yf),a(W,V),a(V,Cr),a(Cr,Mf),a(V,Wf),a(V,Ar),a(Ar,Kf),a(V,Qf),a(V,Or),a(Or,Zf),a(V,Xf),a(V,Sr),a(Sr,sb),a(V,ab),a(W,eb),a(W,Da),a(Da,Lr),a(Lr,nb),a(Da,tb),a(Da,Nr),a(Nr,lb),a(Da,rb),a(us,ob),a(us,Rr),a(Rr,ds),a(ds,Ir),a(Ir,pb),a(ds,cb),a(ds,Hr),a(Hr,ib),a(ds,ub),a(ds,Ur),a(Ur,db),a(ds,mb),u(s,Yc,p),u(s,N,p),a(N,hb),a(N,Fr),a(Fr,fb),a(N,bb),a(N,Br),a(Br,jb),a(N,_b),a(N,Gr),a(Gr,gb),a(N,vb),a(N,Jr),a(Jr,Eb),a(N,$b),a(N,Vr),a(Vr,kb),a(N,xb),u(s,Mc,p),u(s,Pa,p),a(Pa,Yr),a(Yr,Ds),a(Ds,Mr),a(Mr,yb),a(Ds,wb),a(Ds,Wr),a(Wr,qb),a(Ds,Tb),a(Ds,Kr),a(Kr,zb),a(Pa,Db),a(Pa,P),a(P,Ps),a(Ps,Qr),a(Qr,Pb),a(Ps,Cb),a(Ps,Zr),a(Zr,Ab),a(Ps,Ob),a(Ps,Xr),a(Xr,so),a(so,Sb),a(P,Lb),a(P,Cs),a(Cs,Wc),a(Cs,Nb),a(Cs,ao),a(ao,Rb),a(Cs,Ib),a(Cs,Vn),a(Vn,eo),a(eo,Hb),a(Vn,Ub),a(P,Fb),a(P,As),a(As,Kc),a(As,Bb),a(As,Qc),a(As,Gb),a(As,no),a(no,to),a(to,Jb),a(P,Vb),a(P,Os),a(Os,Zc),a(Os,Yb),a(Os,lo),a(lo,Mb),a(Os,Wb),a(Os,ro),a(ro,oo),a(oo,Kb),a(P,Qb),a(P,Ss),a(Ss,Xc),a(Ss,Zb),a(Ss,po),a(po,Xb),a(Ss,s1),a(Ss,co),a(co,io),a(io,a1),a(P,e1),a(P,Ls),a(Ls,uo),a(uo,n1),a(Ls,t1),a(Ls,mo),a(mo,l1),a(Ls,r1),a(Ls,Yn),a(Yn,ho),a(ho,o1),a(Yn,p1),a(P,c1),a(P,Ns),a(Ns,si),a(Ns,i1),a(Ns,ai),a(Ns,u1),a(Ns,fo),a(fo,bo),a(bo,d1),a(P,m1),a(P,Rs),a(Rs,ei),a(Rs,h1),a(Rs,jo),a(jo,f1),a(Rs,b1),a(Rs,Mn),a(Mn,_o),a(_o,j1),a(Mn,_1),a(P,g1),a(P,Is),a(Is,ni),a(Is,v1),a(Is,ti),a(Is,E1),a(Is,go),a(go,vo),a(vo,$1),a(P,k1),a(P,Hs),a(Hs,li),a(Hs,x1),a(Hs,Eo),a(Eo,y1),a(Hs,w1),a(Hs,Wn),a(Wn,$o),a($o,q1),a(Wn,T1),a(P,z1),a(P,Us),a(Us,ri),a(Us,D1),a(Us,oi),a(Us,P1),a(Us,ko),a(ko,xo),a(xo,C1),a(P,A1),a(P,Fs),a(Fs,pi),a(Fs,O1),a(Fs,yo),a(yo,S1),a(Fs,L1),a(Fs,wo),a(wo,N1),a(P,R1),a(P,Bs),a(Bs,qo),a(qo,I1),a(Bs,H1),a(Bs,To),a(To,U1),a(Bs,F1),a(Bs,Kn),a(Kn,zo),a(zo,B1),a(Kn,G1),a(P,J1),a(P,Gs),a(Gs,ci),a(Gs,V1),a(Gs,ii),a(Gs,Y1),a(Gs,Do),a(Do,Po),a(Po,M1),a(P,W1),a(P,Js),a(Js,ui),a(Js,K1),a(Js,Co),a(Co,Q1),a(Js,Z1),a(Js,Qn),a(Qn,Ao),a(Ao,X1),a(Qn,sj),a(P,aj),a(P,Vs),a(Vs,di),a(Vs,ej),a(Vs,mi),a(Vs,nj),a(Vs,Oo),a(Oo,So),a(So,tj),a(P,lj),a(P,Ys),a(Ys,hi),a(Ys,rj),a(Ys,Lo),a(Lo,oj),a(Ys,pj),a(Ys,No),a(No,cj),a(P,ij),a(P,Ms),a(Ms,fi),a(Ms,uj),a(Ms,Ro),a(Ro,dj),a(Ms,mj),a(Ms,Zn),a(Zn,Io),a(Io,hj),a(Zn,fj),a(P,bj),a(P,Ws),a(Ws,bi),a(Ws,jj),a(Ws,ji),a(Ws,_j),a(Ws,Ho),a(Ho,Uo),a(Uo,gj),_i=!0},p(s,[p]){const nn={};p&2&&(nn.$$scope={dirty:p,ctx:s}),sa.$set(nn)},i(s){_i||(_(q.$$.fragment,s),_(D.$$.fragment,s),_(La.$$.fragment,s),_(Na.$$.fragment,s),_(sa.$$.fragment,s),_(Ra.$$.fragment,s),_(Ia.$$.fragment,s),_(Ha.$$.fragment,s),_(Ua.$$.fragment,s),_(Fa.$$.fragment,s),_(Ba.$$.fragment,s),_(Ga.$$.fragment,s),_(Ja.$$.fragment,s),_(Va.$$.fragment,s),_(Ya.$$.fragment,s),_(Ma.$$.fragment,s),_(Wa.$$.fragment,s),_(Ka.$$.fragment,s),_(Xa.$$.fragment,s),_(se.$$.fragment,s),_(ae.$$.fragment,s),_(te.$$.fragment,s),_(oe.$$.fragment,s),_(ce.$$.fragment,s),_(ie.$$.fragment,s),_(ue.$$.fragment,s),_(de.$$.fragment,s),_(me.$$.fragment,s),_(he.$$.fragment,s),_(fe.$$.fragment,s),_(be.$$.fragment,s),_(je.$$.fragment,s),_(_e.$$.fragment,s),_(ve.$$.fragment,s),_($e.$$.fragment,s),_(ke.$$.fragment,s),_(xe.$$.fragment,s),_(ye.$$.fragment,s),_(De.$$.fragment,s),_(Ce.$$.fragment,s),_(Le.$$.fragment,s),_(Ie.$$.fragment,s),_(He.$$.fragment,s),_(Ue.$$.fragment,s),_(Be.$$.fragment,s),_(Ge.$$.fragment,s),_(Je.$$.fragment,s),_(Ve.$$.fragment,s),_(Ye.$$.fragment,s),_(Me.$$.fragment,s),_(We.$$.fragment,s),_(Ze.$$.fragment,s),_(Xe.$$.fragment,s),_i=!0)},o(s){g(q.$$.fragment,s),g(D.$$.fragment,s),g(La.$$.fragment,s),g(Na.$$.fragment,s),g(sa.$$.fragment,s),g(Ra.$$.fragment,s),g(Ia.$$.fragment,s),g(Ha.$$.fragment,s),g(Ua.$$.fragment,s),g(Fa.$$.fragment,s),g(Ba.$$.fragment,s),g(Ga.$$.fragment,s),g(Ja.$$.fragment,s),g(Va.$$.fragment,s),g(Ya.$$.fragment,s),g(Ma.$$.fragment,s),g(Wa.$$.fragment,s),g(Ka.$$.fragment,s),g(Xa.$$.fragment,s),g(se.$$.fragment,s),g(ae.$$.fragment,s),g(te.$$.fragment,s),g(oe.$$.fragment,s),g(ce.$$.fragment,s),g(ie.$$.fragment,s),g(ue.$$.fragment,s),g(de.$$.fragment,s),g(me.$$.fragment,s),g(he.$$.fragment,s),g(fe.$$.fragment,s),g(be.$$.fragment,s),g(je.$$.fragment,s),g(_e.$$.fragment,s),g(ve.$$.fragment,s),g($e.$$.fragment,s),g(ke.$$.fragment,s),g(xe.$$.fragment,s),g(ye.$$.fragment,s),g(De.$$.fragment,s),g(Ce.$$.fragment,s),g(Le.$$.fragment,s),g(Ie.$$.fragment,s),g(He.$$.fragment,s),g(Ue.$$.fragment,s),g(Be.$$.fragment,s),g(Ge.$$.fragment,s),g(Je.$$.fragment,s),g(Ve.$$.fragment,s),g(Ye.$$.fragment,s),g(Me.$$.fragment,s),g(We.$$.fragment,s),g(Ze.$$.fragment,s),g(Xe.$$.fragment,s),_i=!1},d(s){e(m),s&&e(f),s&&e(b),k(q),s&&e(z),k(D,s),s&&e(A),s&&e(Zs),s&&e(S),s&&e(U),s&&e(Jo),s&&e(ms),k(La),s&&e(Vo),k(Na,s),s&&e(Yo),s&&e(Q),s&&e(Mo),k(sa,s),s&&e(Wo),s&&e(Z),s&&e(Ko),s&&e(hs),k(Ra),s&&e(Qo),s&&e(ea),s&&e(Zo),k(Ia,s),s&&e(Xo),s&&e(rn),s&&e(sp),k(Ha,s),s&&e(ap),s&&e(on),s&&e(ep),s&&e(X),s&&e(np),s&&e(na),s&&e(tp),k(Ua,s),s&&e(lp),s&&e(ss),s&&e(rp),s&&e(fn),s&&e(op),k(Fa,s),s&&e(pp),s&&e(fs),k(Ba),s&&e(cp),s&&e(bn),s&&e(ip),s&&e(as),s&&e(up),k(Ga,s),s&&e(dp),s&&e(jn),s&&e(mp),s&&e(bs),k(Ja),s&&e(hp),s&&e(_n),s&&e(fp),s&&e(es),s&&e(bp),k(Va,s),s&&e(jp),s&&e(js),k(Ya),s&&e(_p),s&&e(gn),s&&e(gp),s&&e(B),s&&e(vp),k(Ma,s),s&&e(Ep),s&&e(_s),k(Wa),s&&e($p),s&&e(pa),s&&e(kp),k(Ka,s),s&&e(xp),s&&e(ns),s&&e(yp),k(Xa,s),s&&e(wp),s&&e(ts),s&&e(qp),k(se,s),s&&e(Tp),s&&e(En),s&&e(zp),s&&e(ls),s&&e(Dp),s&&e(gs),k(ae),s&&e(Pp),s&&e(ia),s&&e(Cp),s&&e(ua),s&&e(Ap),k(te,s),s&&e(Op),s&&e(yn),s&&e(Sp),k(oe,s),s&&e(Lp),s&&e(pe),s&&e(Np),k(ce,s),s&&e(Rp),s&&e(da),s&&e(Ip),s&&e(vs),k(ie),s&&e(Hp),s&&e(wn),s&&e(Up),s&&e(ha),s&&e(Fp),k(ue,s),s&&e(Bp),s&&e(rs),s&&e(Gp),k(de,s),s&&e(Jp),s&&e(Es),k(me),s&&e(Vp),s&&e(qn),s&&e(Yp),k(he,s),s&&e(Mp),s&&e(ba),s&&e(Wp),k(fe,s),s&&e(Kp),s&&e(Tn),s&&e(Qp),k(be,s),s&&e(Zp),s&&e(zn),s&&e(Xp),k(je,s),s&&e(sc),s&&e(Dn),s&&e(ac),s&&e($s),k(_e),s&&e(ec),s&&e(Pn),s&&e(nc),s&&e(os),s&&e(tc),k(ve,s),s&&e(lc),s&&e(_a),s&&e(rc),k($e,s),s&&e(oc),s&&e(Cn),s&&e(pc),s&&e(ks),k(ke),s&&e(cc),s&&e(va),s&&e(ic),k(xe,s),s&&e(uc),s&&e(xs),k(ye),s&&e(dc),s&&e($a),s&&e(mc),s&&e(On),s&&e(hc),k(De,s),s&&e(fc),s&&e(Pe),s&&e(bc),k(Ce,s),s&&e(jc),s&&e(Ae),s&&e(_c),k(Le,s),s&&e(gc),s&&e(Ne),s&&e(vc),k(Ie,s),s&&e(Ec),s&&e(Ln),s&&e($c),k(He,s),s&&e(kc),s&&e(Nn),s&&e(xc),s&&e(ws),k(Ue),s&&e(yc),s&&e(In),s&&e(wc),s&&e(xa),s&&e(qc),s&&e(ya),s&&e(Tc),k(Be,s),s&&e(zc),s&&e(ps),s&&e(Dc),k(Ge,s),s&&e(Pc),s&&e(cs),s&&e(Cc),k(Je,s),s&&e(Ac),s&&e(wa),s&&e(Oc),k(Ve,s),s&&e(Sc),s&&e(qs),k(Ye),s&&e(Lc),s&&e(Un),s&&e(Nc),k(Me,s),s&&e(Rc),s&&e(Fn),s&&e(Ic),k(We,s),s&&e(Hc),s&&e(Ke),s&&e(Uc),k(Ze,s),s&&e(Fc),s&&e(is),s&&e(Bc),s&&e(Bn),s&&e(Gc),s&&e(zs),k(Xe),s&&e(Jc),s&&e(G),s&&e(Vc),s&&e(us),s&&e(Yc),s&&e(N),s&&e(Mc),s&&e(Pa)}}}const Ov={local:"preprocesamiento",sections:[{local:"nlp",sections:[{local:"tokenizar",title:"Tokenizar"},{local:"pad",title:"Pad"},{local:"truncamiento",title:"Truncamiento"},{local:"construye-tensores",title:"Construye tensores"}],title:"NLP"},{local:"audio",sections:[{local:"resample",title:"Resample"},{local:"extractor-de-caractersticas",title:"Extractor de caracter\xEDsticas"},{local:"pad-y-truncamiento",title:"Pad y truncamiento"}],title:"Audio"},{local:"visin",sections:[{local:"extractor-de-caractersticas",title:"Extractor de caracter\xEDsticas"},{local:"aumento-de-datos",title:"Aumento de Datos"}],title:"Visi\xF3n"},{local:"multimodal",sections:[{local:"processor",title:"Processor"}],title:"Multimodal"},{local:"todo-lo-que-siempre-quisiste-saber-sobre-el-padding-y-el-truncamiento",title:"Todo lo que siempre quisiste saber sobre el padding y el truncamiento"}],title:"Preprocesamiento"};function Sv(T){return gv(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Bv extends Sj{constructor(m){super();Lj(this,m,Sv,Av,Nj,{})}}export{Bv as default,Ov as metadata};
