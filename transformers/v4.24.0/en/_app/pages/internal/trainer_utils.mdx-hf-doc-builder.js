import{S as ap,i as rp,s as sp,e as r,k as i,w as $,t as o,M as np,c as s,d as t,m as p,a as n,x as y,h as l,b as u,G as e,g as b,y as E,q as D,o as j,B as x,v as op,L as qa}from"../../chunks/vendor-hf-doc-builder.js";import{D as A}from"../../chunks/Docstring-hf-doc-builder.js";import{C as Ba}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as vt}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as Ra}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function lp(U){let g,T,w,f,k;return f=new Ba({props:{code:"debug_overflow = DebugUnderflowOverflow(model)",highlighted:"debug_overflow = DebugUnderflowOverflow(model)"}}),{c(){g=r("p"),T=o("To activate the underflow/overflow detection, initialize the object with the model :"),w=i(),$(f.$$.fragment)},l(c){g=s(c,"P",{});var _=n(g);T=l(_,"To activate the underflow/overflow detection, initialize the object with the model :"),_.forEach(t),w=p(c),y(f.$$.fragment,c)},m(c,_){b(c,g,_),e(g,T),b(c,w,_),E(f,c,_),k=!0},p:qa,i(c){k||(D(f.$$.fragment,c),k=!0)},o(c){j(f.$$.fragment,c),k=!1},d(c){c&&t(g),c&&t(w),x(f,c)}}}function ip(U){let g,T,w,f,k;return f=new Ba({props:{code:`Detected inf/nan during batch_number=0
Last 21 forward frames:
abs min  abs max  metadata
[...]
                  encoder.block.2.layer.1.DenseReluDense.wi_0 Linear
2.17e-07 4.50e+00 weight
1.79e-06 4.65e+00 input[0]
2.68e-06 3.70e+01 output
                  encoder.block.2.layer.1.DenseReluDense.wi_1 Linear
8.08e-07 2.66e+01 weight
1.79e-06 4.65e+00 input[0]
1.27e-04 2.37e+02 output
                  encoder.block.2.layer.1.DenseReluDense.wo Linear
1.01e-06 6.44e+00 weight
0.00e+00 9.74e+03 input[0]
3.18e-04 6.27e+04 output
                  encoder.block.2.layer.1.DenseReluDense T5DenseGatedGeluDense
1.79e-06 4.65e+00 input[0]
3.18e-04 6.27e+04 output
                  encoder.block.2.layer.1.dropout Dropout
3.18e-04 6.27e+04 input[0]
0.00e+00      inf output`,highlighted:`<span class="hljs-attribute">Detected</span> inf/nan during batch_number=<span class="hljs-number">0</span>
<span class="hljs-attribute">Last</span> <span class="hljs-number">21</span> forward frames:
<span class="hljs-attribute">abs</span> min  abs max  metadata<span class="hljs-meta">
[...]</span>
                  <span class="hljs-attribute">encoder</span>.block.<span class="hljs-number">2</span>.layer.<span class="hljs-number">1</span>.DenseReluDense.wi_0 Linear
<span class="hljs-attribute">2</span>.<span class="hljs-number">17</span>e-<span class="hljs-number">07</span> <span class="hljs-number">4</span>.<span class="hljs-number">50</span>e+<span class="hljs-number">00</span> weight
<span class="hljs-attribute">1</span>.<span class="hljs-number">79</span>e-<span class="hljs-number">06</span> <span class="hljs-number">4</span>.<span class="hljs-number">65</span>e+<span class="hljs-number">00</span> input[<span class="hljs-number">0</span>]
<span class="hljs-attribute">2</span>.<span class="hljs-number">68</span>e-<span class="hljs-number">06</span> <span class="hljs-number">3</span>.<span class="hljs-number">70</span>e+<span class="hljs-number">01</span> output
                  <span class="hljs-attribute">encoder</span>.block.<span class="hljs-number">2</span>.layer.<span class="hljs-number">1</span>.DenseReluDense.wi_1 Linear
<span class="hljs-attribute">8</span>.<span class="hljs-number">08</span>e-<span class="hljs-number">07</span> <span class="hljs-number">2</span>.<span class="hljs-number">66</span>e+<span class="hljs-number">01</span> weight
<span class="hljs-attribute">1</span>.<span class="hljs-number">79</span>e-<span class="hljs-number">06</span> <span class="hljs-number">4</span>.<span class="hljs-number">65</span>e+<span class="hljs-number">00</span> input[<span class="hljs-number">0</span>]
<span class="hljs-attribute">1</span>.<span class="hljs-number">27</span>e-<span class="hljs-number">04</span> <span class="hljs-number">2</span>.<span class="hljs-number">37</span>e+<span class="hljs-number">02</span> output
                  <span class="hljs-attribute">encoder</span>.block.<span class="hljs-number">2</span>.layer.<span class="hljs-number">1</span>.DenseReluDense.wo Linear
<span class="hljs-attribute">1</span>.<span class="hljs-number">01</span>e-<span class="hljs-number">06</span> <span class="hljs-number">6</span>.<span class="hljs-number">44</span>e+<span class="hljs-number">00</span> weight
<span class="hljs-attribute">0</span>.<span class="hljs-number">00</span>e+<span class="hljs-number">00</span> <span class="hljs-number">9</span>.<span class="hljs-number">74</span>e+<span class="hljs-number">03</span> input[<span class="hljs-number">0</span>]
<span class="hljs-attribute">3</span>.<span class="hljs-number">18</span>e-<span class="hljs-number">04</span> <span class="hljs-number">6</span>.<span class="hljs-number">27</span>e+<span class="hljs-number">04</span> output
                  <span class="hljs-attribute">encoder</span>.block.<span class="hljs-number">2</span>.layer.<span class="hljs-number">1</span>.DenseReluDense T5DenseGatedGeluDense
<span class="hljs-attribute">1</span>.<span class="hljs-number">79</span>e-<span class="hljs-number">06</span> <span class="hljs-number">4</span>.<span class="hljs-number">65</span>e+<span class="hljs-number">00</span> input[<span class="hljs-number">0</span>]
<span class="hljs-attribute">3</span>.<span class="hljs-number">18</span>e-<span class="hljs-number">04</span> <span class="hljs-number">6</span>.<span class="hljs-number">27</span>e+<span class="hljs-number">04</span> output
                  <span class="hljs-attribute">encoder</span>.block.<span class="hljs-number">2</span>.layer.<span class="hljs-number">1</span>.dropout Dropout
<span class="hljs-attribute">3</span>.<span class="hljs-number">18</span>e-<span class="hljs-number">04</span> <span class="hljs-number">6</span>.<span class="hljs-number">27</span>e+<span class="hljs-number">04</span> input[<span class="hljs-number">0</span>]
<span class="hljs-attribute">0</span>.<span class="hljs-number">00</span>e+<span class="hljs-number">00</span>      inf output`}}),{c(){g=r("p"),T=o("mixed precision :"),w=i(),$(f.$$.fragment)},l(c){g=s(c,"P",{});var _=n(g);T=l(_,"mixed precision :"),_.forEach(t),w=p(c),y(f.$$.fragment,c)},m(c,_){b(c,g,_),e(g,T),b(c,w,_),E(f,c,_),k=!0},p:qa,i(c){k||(D(f.$$.fragment,c),k=!0)},o(c){j(f.$$.fragment,c),k=!1},d(c){c&&t(g),c&&t(w),x(f,c)}}}function pp(U){let g,T,w,f,k;return f=new Ba({props:{code:"debug_overflow = DebugUnderflowOverflow(model, max_frames_to_save=100)",highlighted:'debug_overflow = DebugUnderflowOverflow(model, max_frames_to_save=<span class="hljs-number">100</span>)'}}),{c(){g=r("p"),T=o("By default the last 21 frames are printed. You can change the default to adjust for your needs. For example :"),w=i(),$(f.$$.fragment)},l(c){g=s(c,"P",{});var _=n(g);T=l(_,"By default the last 21 frames are printed. You can change the default to adjust for your needs. For example :"),_.forEach(t),w=p(c),y(f.$$.fragment,c)},m(c,_){b(c,g,_),e(g,T),b(c,w,_),E(f,c,_),k=!0},p:qa,i(c){k||(D(f.$$.fragment,c),k=!0)},o(c){j(f.$$.fragment,c),k=!1},d(c){c&&t(g),c&&t(w),x(f,c)}}}function cp(U){let g,T,w,f,k;return f=new Ba({props:{code:"debug_overflow = DebugUnderflowOverflow(model, trace_batch_nums=[1, 3])",highlighted:'debug_overflow = DebugUnderflowOverflow(model, trace_batch_nums=[<span class="hljs-number">1</span>, <span class="hljs-number">3</span>])'}}),{c(){g=r("p"),T=o("given batch, and only do that for batches 1 and 3. Then you instantiate this class as :"),w=i(),$(f.$$.fragment)},l(c){g=s(c,"P",{});var _=n(g);T=l(_,"given batch, and only do that for batches 1 and 3. Then you instantiate this class as :"),_.forEach(t),w=p(c),y(f.$$.fragment,c)},m(c,_){b(c,g,_),e(g,T),b(c,w,_),E(f,c,_),k=!0},p:qa,i(c){k||(D(f.$$.fragment,c),k=!0)},o(c){j(f.$$.fragment,c),k=!1},d(c){c&&t(g),c&&t(w),x(f,c)}}}function dp(U){let g,T,w,f,k;return f=new Ba({props:{code:"debug_overflow = DebugUnderflowOverflow(model, trace_batch_nums=[1, 3], abort_after_batch_num=3)",highlighted:'debug_overflow = DebugUnderflowOverflow(model, trace_batch_nums=[<span class="hljs-number">1</span>, <span class="hljs-number">3</span>], abort_after_batch_num=<span class="hljs-number">3</span>)'}}),{c(){g=r("p"),T=o("You can also specify the batch number after which to stop the training, with :"),w=i(),$(f.$$.fragment)},l(c){g=s(c,"P",{});var _=n(g);T=l(_,"You can also specify the batch number after which to stop the training, with :"),_.forEach(t),w=p(c),y(f.$$.fragment,c)},m(c,_){b(c,g,_),e(g,T),b(c,w,_),E(f,c,_),k=!0},p:qa,i(c){k||(D(f.$$.fragment,c),k=!0)},o(c){j(f.$$.fragment,c),k=!1},d(c){c&&t(g),c&&t(w),x(f,c)}}}function hp(U){let g,T,w,f,k,c,_,wt,Nr,Ka,ee,Fr,tt,Gr,Vr,Ya,at,Mr,Wa,N,te,$t,be,Rr,yt,qr,Ja,F,_e,Br,Et,Kr,Qa,G,ve,Yr,Dt,Wr,Xa,I,we,Jr,jt,Qr,Xr,$e,rt,ye,Zr,es,ts,st,Ee,as,rs,Za,V,De,ss,L,ns,xt,os,ls,kt,is,ps,Pt,cs,ds,Tt,hs,fs,er,M,je,ms,Ot,us,tr,R,ae,At,xe,gs,Ct,bs,ar,q,ke,_s,Lt,vs,rr,B,re,Ut,Pe,ws,It,$s,sr,v,Te,ys,zt,Es,Ds,Ht,js,xs,St,Nt,ks,Ps,Ft,Ts,Os,K,nt,As,Gt,Cs,Ls,ot,Us,Vt,Is,zs,lt,Hs,Mt,Ss,Ns,Rt,Fs,Gs,Y,it,Vs,qt,Ms,Rs,pt,qs,Bt,Bs,Ks,ct,Ys,Kt,Ws,Js,Yt,Qs,Xs,Wt,Jt,Zs,en,Qt,tn,an,Xt,Zt,rn,sn,ea,nn,on,se,Oe,ln,Ae,pn,ta,cn,dn,hn,ne,Ce,fn,aa,mn,nr,W,oe,ra,Le,un,sa,gn,or,O,Ue,bn,Ie,_n,na,vn,wn,$n,ze,yn,oa,En,Dn,jn,H,He,xn,la,kn,Pn,Se,Tn,ia,On,An,Cn,le,Ne,Ln,Fe,Un,pa,In,zn,Hn,ie,Ge,Sn,Ve,Nn,ca,Fn,Gn,Vn,pe,Me,Mn,Re,Rn,da,qn,Bn,lr,J,ce,ha,qe,Kn,fa,Yn,ir,d,Be,Wn,Q,Jn,ma,Qn,Xn,ua,Zn,eo,to,ga,ao,ro,Ke,ba,so,no,_a,oo,lo,va,io,po,de,co,z,ho,wa,fo,mo,$a,uo,go,ya,bo,_o,vo,Ye,We,wo,Ea,$o,yo,Eo,Da,Do,jo,Je,xo,ja,ko,Po,To,he,Oo,X,Ao,xa,Co,Lo,ka,Uo,Io,zo,Pa,Ho,So,Qe,No,Ta,Fo,Go,Vo,fe,Mo,Oa,Ro,qo,Aa,Bo,Ko,Ca,Yo,Wo,Xe,Jo,La,Qo,Xo,Zo,me,el,Ua,tl,al,Ia,rl,sl,za,nl,ol,ue,ll,Ha,il,pl,dt,Sa,cl,dl,hl,Z,fl,Na,ml,ul,Fa,gl,bl,pr;return c=new vt({}),be=new vt({}),_e=new A({props:{name:"class transformers.EvalPrediction",anchor:"transformers.EvalPrediction",parameters:[{name:"predictions",val:": typing.Union[numpy.ndarray, typing.Tuple[numpy.ndarray]]"},{name:"label_ids",val:": typing.Union[numpy.ndarray, typing.Tuple[numpy.ndarray]]"},{name:"inputs",val:": typing.Union[numpy.ndarray, typing.Tuple[numpy.ndarray], NoneType] = None"}],parametersDescription:[{anchor:"transformers.EvalPrediction.predictions",description:"<strong>predictions</strong> (<code>np.ndarray</code>) &#x2014; Predictions of the model.",name:"predictions"},{anchor:"transformers.EvalPrediction.label_ids",description:"<strong>label_ids</strong> (<code>np.ndarray</code>) &#x2014; Targets to be matched.",name:"label_ids"},{anchor:"transformers.EvalPrediction.inputs",description:"<strong>inputs</strong> (<code>np.ndarray</code>, <em>optional</em>) &#x2014;",name:"inputs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/trainer_utils.py#L100"}}),ve=new A({props:{name:"class transformers.IntervalStrategy",anchor:"transformers.IntervalStrategy",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/trainer_utils.py#L174"}}),we=new A({props:{name:"transformers.enable_full_determinism",anchor:"transformers.enable_full_determinism",parameters:[{name:"seed",val:": int"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/trainer_utils.py#L58"}}),De=new A({props:{name:"transformers.set_seed",anchor:"transformers.set_seed",parameters:[{name:"seed",val:": int"}],parametersDescription:[{anchor:"transformers.set_seed.seed",description:"<strong>seed</strong> (<code>int</code>) &#x2014; The seed to set.",name:"seed"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/trainer_utils.py#L83"}}),je=new A({props:{name:"transformers.torch_distributed_zero_first",anchor:"transformers.torch_distributed_zero_first",parameters:[{name:"local_rank",val:": int"}],parametersDescription:[{anchor:"transformers.torch_distributed_zero_first.local_rank",description:"<strong>local_rank</strong> (<code>int</code>) &#x2014; The rank of the local process.",name:"local_rank"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/trainer_pt_utils.py#L232"}}),xe=new vt({}),ke=new A({props:{name:"class transformers.trainer_callback.CallbackHandler",anchor:"transformers.trainer_callback.CallbackHandler",parameters:[{name:"callbacks",val:""},{name:"model",val:""},{name:"tokenizer",val:""},{name:"optimizer",val:""},{name:"lr_scheduler",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/trainer_callback.py#L290"}}),Pe=new vt({}),Te=new A({props:{name:"class transformers.trainer_pt_utils.DistributedTensorGatherer",anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer",parameters:[{name:"world_size",val:""},{name:"num_samples",val:""},{name:"make_multiple_of",val:" = None"},{name:"padding_index",val:" = -100"}],parametersDescription:[{anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer.world_size",description:`<strong>world_size</strong> (<code>int</code>) &#x2014;
The number of processes used in the distributed training.`,name:"world_size"},{anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer.num_samples",description:`<strong>num_samples</strong> (<code>int</code>) &#x2014;
The number of samples in our dataset.`,name:"num_samples"},{anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer.make_multiple_of",description:`<strong>make_multiple_of</strong> (<code>int</code>, <em>optional</em>) &#x2014;
If passed, the class assumes the datasets passed to each process are made to be a multiple of this argument
(by adding samples).`,name:"make_multiple_of"},{anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer.padding_index",description:`<strong>padding_index</strong> (<code>int</code>, <em>optional</em>, defaults to -100) &#x2014;
The padding index to use if the arrays don&#x2019;t all have the same sequence length.`,name:"padding_index"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/trainer_pt_utils.py#L361"}}),Oe=new A({props:{name:"add_arrays",anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer.add_arrays",parameters:[{name:"arrays",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/trainer_pt_utils.py#L421"}}),Ce=new A({props:{name:"finalize",anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer.finalize",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/trainer_pt_utils.py#L457"}}),Le=new vt({}),Ue=new A({props:{name:"class transformers.HfArgumentParser",anchor:"transformers.HfArgumentParser",parameters:[{name:"dataclass_types",val:": typing.Union[DataClassType, typing.Iterable[DataClassType]]"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/hf_argparser.py#L46"}}),He=new A({props:{name:"parse_args_into_dataclasses",anchor:"transformers.HfArgumentParser.parse_args_into_dataclasses",parameters:[{name:"args",val:" = None"},{name:"return_remaining_strings",val:" = False"},{name:"look_for_args_file",val:" = True"},{name:"args_filename",val:" = None"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/hf_argparser.py#L180",returnDescription:`
<ul>
<li>the dataclass instances in the same order as they were passed to the initializer.abspath</li>
<li>if applicable, an additional namespace for more (non-dataclass backed) arguments added to the parser
after initialization.</li>
<li>The potential list of remaining argument strings. (same as argparse.ArgumentParser.parse_known_args)</li>
</ul>
`,returnType:`
<p>Tuple consisting of</p>
`}}),Ne=new A({props:{name:"parse_dict",anchor:"transformers.HfArgumentParser.parse_dict",parameters:[{name:"args",val:": typing.Dict[str, typing.Any]"},{name:"allow_extra_keys",val:": bool = False"}],parametersDescription:[{anchor:"transformers.HfArgumentParser.parse_dict.args",description:`<strong>args</strong> (<code>dict</code>) &#x2014;
dict containing config values`,name:"args"},{anchor:"transformers.HfArgumentParser.parse_dict.allow_extra_keys",description:`<strong>allow_extra_keys</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Defaults to False. If False, will raise an exception if the dict contains keys that are not parsed.`,name:"allow_extra_keys"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/hf_argparser.py#L239",returnDescription:`
<ul>
<li>the dataclass instances in the same order as they were passed to the initializer.</li>
</ul>
`,returnType:`
<p>Tuple consisting of</p>
`}}),Ge=new A({props:{name:"parse_json_file",anchor:"transformers.HfArgumentParser.parse_json_file",parameters:[{name:"json_file",val:": str"},{name:"allow_extra_keys",val:": bool = False"}],parametersDescription:[{anchor:"transformers.HfArgumentParser.parse_json_file.json_file",description:`<strong>json_file</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
File name of the json file to parse`,name:"json_file"},{anchor:"transformers.HfArgumentParser.parse_json_file.allow_extra_keys",description:`<strong>allow_extra_keys</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Defaults to False. If False, will raise an exception if the json file contains keys that are not
parsed.`,name:"allow_extra_keys"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/hf_argparser.py#L267",returnDescription:`
<ul>
<li>the dataclass instances in the same order as they were passed to the initializer.</li>
</ul>
`,returnType:`
<p>Tuple consisting of</p>
`}}),Me=new A({props:{name:"parse_yaml_file",anchor:"transformers.HfArgumentParser.parse_yaml_file",parameters:[{name:"yaml_file",val:": str"},{name:"allow_extra_keys",val:": bool = False"}],parametersDescription:[{anchor:"transformers.HfArgumentParser.parse_yaml_file.yaml_file",description:`<strong>yaml_file</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
File name of the yaml file to parse`,name:"yaml_file"},{anchor:"transformers.HfArgumentParser.parse_yaml_file.allow_extra_keys",description:`<strong>allow_extra_keys</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Defaults to False. If False, will raise an exception if the json file contains keys that are not
parsed.`,name:"allow_extra_keys"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/hf_argparser.py#L289",returnDescription:`
<ul>
<li>the dataclass instances in the same order as they were passed to the initializer.</li>
</ul>
`,returnType:`
<p>Tuple consisting of</p>
`}}),qe=new vt({}),Be=new A({props:{name:"class transformers.debug_utils.DebugUnderflowOverflow",anchor:"transformers.debug_utils.DebugUnderflowOverflow",parameters:[{name:"model",val:""},{name:"max_frames_to_save",val:" = 21"},{name:"trace_batch_nums",val:" = []"},{name:"abort_after_batch_num",val:" = None"}],parametersDescription:[{anchor:"transformers.debug_utils.DebugUnderflowOverflow.model",description:`<strong>model</strong> (<code>nn.Module</code>) &#x2014;
The model to debug.`,name:"model"},{anchor:"transformers.debug_utils.DebugUnderflowOverflow.max_frames_to_save",description:`<strong>max_frames_to_save</strong> (<code>int</code>, <em>optional</em>, defaults to 21) &#x2014;
How many frames back to record`,name:"max_frames_to_save"},{anchor:"transformers.debug_utils.DebugUnderflowOverflow.trace_batch_nums(List[int],",description:`<strong>trace_batch_nums(<code>List[int]</code>,</strong> <em>optional</em>, defaults to <code>[]</code>) &#x2014;
Which batch numbers to trace (turns detection off)`,name:"trace_batch_nums(List[int],"},{anchor:"transformers.debug_utils.DebugUnderflowOverflow.abort_after_batch_num",description:"<strong>abort_after_batch_num</strong>  (`int&#x201C;, <em>optional</em>) &#x2014;\nWhether to abort after a certain batch number has finished",name:"abort_after_batch_num"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/debug_utils.py#L27"}}),de=new Ra({props:{anchor:"transformers.debug_utils.DebugUnderflowOverflow.example",$$slots:{default:[lp]},$$scope:{ctx:U}}}),he=new Ra({props:{anchor:"transformers.debug_utils.DebugUnderflowOverflow.example-2",$$slots:{default:[ip]},$$scope:{ctx:U}}}),fe=new Ra({props:{anchor:"transformers.debug_utils.DebugUnderflowOverflow.example-3",$$slots:{default:[pp]},$$scope:{ctx:U}}}),me=new Ra({props:{anchor:"transformers.debug_utils.DebugUnderflowOverflow.example-4",$$slots:{default:[cp]},$$scope:{ctx:U}}}),ue=new Ra({props:{anchor:"transformers.debug_utils.DebugUnderflowOverflow.example-5",$$slots:{default:[dp]},$$scope:{ctx:U}}}),{c(){g=r("meta"),T=i(),w=r("h1"),f=r("a"),k=r("span"),$(c.$$.fragment),_=i(),wt=r("span"),Nr=o("Utilities for Trainer"),Ka=i(),ee=r("p"),Fr=o("This page lists all the utility functions used by "),tt=r("a"),Gr=o("Trainer"),Vr=o("."),Ya=i(),at=r("p"),Mr=o("Most of those are only useful if you are studying the code of the Trainer in the library."),Wa=i(),N=r("h2"),te=r("a"),$t=r("span"),$(be.$$.fragment),Rr=i(),yt=r("span"),qr=o("Utilities"),Ja=i(),F=r("div"),$(_e.$$.fragment),Br=i(),Et=r("p"),Kr=o("Evaluation output (always contains labels), to be used to compute metrics."),Qa=i(),G=r("div"),$(ve.$$.fragment),Yr=i(),Dt=r("p"),Wr=o("An enumeration."),Xa=i(),I=r("div"),$(we.$$.fragment),Jr=i(),jt=r("p"),Qr=o("Helper function for reproducible behavior during distributed training. See"),Xr=i(),$e=r("ul"),rt=r("li"),ye=r("a"),Zr=o("https://pytorch.org/docs/stable/notes/randomness.html"),es=o(" for pytorch"),ts=i(),st=r("li"),Ee=r("a"),as=o("https://www.tensorflow.org/api_docs/python/tf/config/experimental/enable_op_determinism"),rs=o(" for tensorflow"),Za=i(),V=r("div"),$(De.$$.fragment),ss=i(),L=r("p"),ns=o("Helper function for reproducible behavior to set the seed in "),xt=r("code"),os=o("random"),ls=o(", "),kt=r("code"),is=o("numpy"),ps=o(", "),Pt=r("code"),cs=o("torch"),ds=o(" and/or "),Tt=r("code"),hs=o("tf"),fs=o(" (if installed)."),er=i(),M=r("div"),$(je.$$.fragment),ms=i(),Ot=r("p"),us=o("Decorator to make all processes in distributed training wait for each local_master to do something."),tr=i(),R=r("h2"),ae=r("a"),At=r("span"),$(xe.$$.fragment),gs=i(),Ct=r("span"),bs=o("Callbacks internals"),ar=i(),q=r("div"),$(ke.$$.fragment),_s=i(),Lt=r("p"),vs=o("Internal class that just calls the list of callbacks in order."),rr=i(),B=r("h2"),re=r("a"),Ut=r("span"),$(Pe.$$.fragment),ws=i(),It=r("span"),$s=o("Distributed Evaluation"),sr=i(),v=r("div"),$(Te.$$.fragment),ys=i(),zt=r("p"),Es=o("A class responsible for properly gathering tensors (or nested list/tuple of tensors) on the CPU by chunks."),Ds=i(),Ht=r("p"),js=o(`If our dataset has 16 samples with a batch size of 2 on 3 processes and we gather then transfer on CPU at every
step, our sampler will generate the following indices:`),xs=i(),St=r("p"),Nt=r("code"),ks=o("[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 0, 1]"),Ps=i(),Ft=r("p"),Ts=o(`to get something of size a multiple of 3 (so that each process gets the same dataset length). Then process 0, 1 and
2 will be responsible of making predictions for the following samples:`),Os=i(),K=r("ul"),nt=r("li"),As=o("P0: "),Gt=r("code"),Cs=o("[0, 1, 2, 3, 4, 5]"),Ls=i(),ot=r("li"),Us=o("P1: "),Vt=r("code"),Is=o("[6, 7, 8, 9, 10, 11]"),zs=i(),lt=r("li"),Hs=o("P2: "),Mt=r("code"),Ss=o("[12, 13, 14, 15, 0, 1]"),Ns=i(),Rt=r("p"),Fs=o("The first batch treated on each process will be"),Gs=i(),Y=r("ul"),it=r("li"),Vs=o("P0: "),qt=r("code"),Ms=o("[0, 1]"),Rs=i(),pt=r("li"),qs=o("P1: "),Bt=r("code"),Bs=o("[6, 7]"),Ks=i(),ct=r("li"),Ys=o("P2: "),Kt=r("code"),Ws=o("[12, 13]"),Js=i(),Yt=r("p"),Qs=o(`So if we gather at the end of the first batch, we will get a tensor (nested list/tuple of tensor) corresponding to
the following indices:`),Xs=i(),Wt=r("p"),Jt=r("code"),Zs=o("[0, 1, 6, 7, 12, 13]"),en=i(),Qt=r("p"),tn=o(`If we directly concatenate our results without taking any precautions, the user will then get the predictions for
the indices in this order at the end of the prediction loop:`),an=i(),Xt=r("p"),Zt=r("code"),rn=o("[0, 1, 6, 7, 12, 13, 2, 3, 8, 9, 14, 15, 4, 5, 10, 11, 0, 1]"),sn=i(),ea=r("p"),nn=o("For some reason, that\u2019s not going to roll their boat. This class is there to solve that problem."),on=i(),se=r("div"),$(Oe.$$.fragment),ln=i(),Ae=r("p"),pn=o("Add "),ta=r("code"),cn=o("arrays"),dn=o(` to the internal storage, Will initialize the storage to the full size at the first arrays passed
so that if we\u2019re bound to get an OOM, it happens at the beginning.`),hn=i(),ne=r("div"),$(Ce.$$.fragment),fn=i(),aa=r("p"),mn=o(`Return the properly gathered arrays and truncate to the number of samples (since the sampler added some extras
to get each process a dataset of the same length).`),nr=i(),W=r("h2"),oe=r("a"),ra=r("span"),$(Le.$$.fragment),un=i(),sa=r("span"),gn=o("Distributed Evaluation"),or=i(),O=r("div"),$(Ue.$$.fragment),bn=i(),Ie=r("p"),_n=o("This subclass of "),na=r("code"),vn=o("argparse.ArgumentParser"),wn=o(" uses type hints on dataclasses to generate arguments."),$n=i(),ze=r("p"),yn=o(`The class is designed to play well with the native argparse. In particular, you can add more (non-dataclass backed)
arguments to the parser after initialization and you\u2019ll get the output back after parsing as an additional
namespace. Optional: To create sub argument groups use the `),oa=r("code"),En=o("_argument_group_name"),Dn=o(" attribute in the dataclass."),jn=i(),H=r("div"),$(He.$$.fragment),xn=i(),la=r("p"),kn=o("Parse command-line args into instances of the specified dataclass types."),Pn=i(),Se=r("p"),Tn=o("This relies on argparse\u2019s "),ia=r("code"),On=o("ArgumentParser.parse_known_args"),An=o(`. See the doc at:
docs.python.org/3.7/library/argparse.html#argparse.ArgumentParser.parse_args`),Cn=i(),le=r("div"),$(Ne.$$.fragment),Ln=i(),Fe=r("p"),Un=o("Alternative helper method that does not use "),pa=r("code"),In=o("argparse"),zn=o(` at all, instead uses a dict and populating the dataclass
types.`),Hn=i(),ie=r("div"),$(Ge.$$.fragment),Sn=i(),Ve=r("p"),Nn=o("Alternative helper method that does not use "),ca=r("code"),Fn=o("argparse"),Gn=o(` at all, instead loading a json file and populating the
dataclass types.`),Vn=i(),pe=r("div"),$(Me.$$.fragment),Mn=i(),Re=r("p"),Rn=o("Alternative helper method that does not use "),da=r("code"),qn=o("argparse"),Bn=o(` at all, instead loading a json file and populating the
dataclass types.`),lr=i(),J=r("h2"),ce=r("a"),ha=r("span"),$(qe.$$.fragment),Kn=i(),fa=r("span"),Yn=o("Debug Utilities"),ir=i(),d=r("div"),$(Be.$$.fragment),Wn=i(),Q=r("p"),Jn=o(`This debug class helps detect and understand where the model starts getting very large or very small, and more
importantly `),ma=r("code"),Qn=o("nan"),Xn=o(" or "),ua=r("code"),Zn=o("inf"),eo=o(" weight and activation elements."),to=i(),ga=r("p"),ao=o("There are 2 working modes:"),ro=i(),Ke=r("ol"),ba=r("li"),so=o("Underflow/overflow detection (default)"),no=i(),_a=r("li"),oo=o("Specific batch absolute min/max tracing without detection"),lo=i(),va=r("p"),io=o("Mode 1: Underflow/overflow detection"),po=i(),$(de.$$.fragment),co=i(),z=r("p"),ho=o("then run the training as normal and if "),wa=r("code"),fo=o("nan"),mo=o(" or "),$a=r("code"),uo=o("inf"),go=o(` gets detected in at least one of the weight, input or output
elements this module will throw an exception and will print `),ya=r("code"),bo=o("max_frames_to_save"),_o=o(` frames that lead to this event,
each frame reporting`),vo=i(),Ye=r("ol"),We=r("li"),wo=o("the fully qualified module name plus the class name whose "),Ea=r("code"),$o=o("forward"),yo=o(" was run"),Eo=i(),Da=r("li"),Do=o("the absolute min and max value of all elements for each module weights, and the inputs and output"),jo=i(),Je=r("p"),xo=o("For example, here is the header and the last few frames in detection report for "),ja=r("code"),ko=o("google/mt5-small"),Po=o(" run in fp16"),To=i(),$(he.$$.fragment),Oo=i(),X=r("p"),Ao=o("You can see here, that "),xa=r("code"),Co=o("T5DenseGatedGeluDense.forward"),Lo=o(` resulted in output activations, whose absolute max value was
around 62.7K, which is very close to fp16\u2019s top limit of 64K. In the next frame we have `),ka=r("code"),Uo=o("Dropout"),Io=o(` which
renormalizes the weights, after it zeroed some of the elements, which pushes the absolute max value to more than
64K, and we get an overlow.`),zo=i(),Pa=r("p"),Ho=o(`As you can see it\u2019s the previous frames that we need to look into when the numbers start going into very large for
fp16 numbers.`),So=i(),Qe=r("p"),No=o("The tracking is done in a forward hook, which gets invoked immediately after "),Ta=r("code"),Fo=o("forward"),Go=o(" has completed."),Vo=i(),$(fe.$$.fragment),Mo=i(),Oa=r("p"),Ro=o(`To validate that you have set up this debugging feature correctly, and you intend to use it in a training that
may take hours to complete, first run it with normal tracing enabled for one of a few batches as explained in
the next section.`),qo=i(),Aa=r("p"),Bo=o("Mode 2. Specific batch absolute min/max tracing without detection"),Ko=i(),Ca=r("p"),Yo=o("The second work mode is per-batch tracing with the underflow/overflow detection feature turned off."),Wo=i(),Xe=r("p"),Jo=o("Let\u2019s say you want to watch the absolute min and max values for all the ingredients of each "),La=r("code"),Qo=o("forward"),Xo=o(" call of a"),Zo=i(),$(me.$$.fragment),el=i(),Ua=r("p"),tl=o("And now full batches 1 and 3 will be traced using the same format as explained above. Batches are 0-indexed."),al=i(),Ia=r("p"),rl=o(`This is helpful if you know that the program starts misbehaving after a certain batch number, so you can
fast-forward right to that area.`),sl=i(),za=r("p"),nl=o("Early stopping:"),ol=i(),$(ue.$$.fragment),ll=i(),Ha=r("p"),il=o("This feature is mainly useful in the tracing mode, but you can use it for any mode."),pl=i(),dt=r("p"),Sa=r("strong"),cl=o("Performance"),dl=o(":"),hl=i(),Z=r("p"),fl=o("As this module measures absolute "),Na=r("code"),ml=o("min"),ul=o("/`"),Fa=r("code"),gl=o("max"),bl=o(` of each weight of the model on every forward it\u2019ll slow the training
down. Therefore remember to turn it off once the debugging needs have been met.`),this.h()},l(a){const m=np('[data-svelte="svelte-1phssyn"]',document.head);g=s(m,"META",{name:!0,content:!0}),m.forEach(t),T=p(a),w=s(a,"H1",{class:!0});var Ze=n(w);f=s(Ze,"A",{id:!0,class:!0,href:!0});var Ga=n(f);k=s(Ga,"SPAN",{});var Va=n(k);y(c.$$.fragment,Va),Va.forEach(t),Ga.forEach(t),_=p(Ze),wt=s(Ze,"SPAN",{});var Ma=n(wt);Nr=l(Ma,"Utilities for Trainer"),Ma.forEach(t),Ze.forEach(t),Ka=p(a),ee=s(a,"P",{});var et=n(ee);Fr=l(et,"This page lists all the utility functions used by "),tt=s(et,"A",{href:!0});var kl=n(tt);Gr=l(kl,"Trainer"),kl.forEach(t),Vr=l(et,"."),et.forEach(t),Ya=p(a),at=s(a,"P",{});var Pl=n(at);Mr=l(Pl,"Most of those are only useful if you are studying the code of the Trainer in the library."),Pl.forEach(t),Wa=p(a),N=s(a,"H2",{class:!0});var cr=n(N);te=s(cr,"A",{id:!0,class:!0,href:!0});var Tl=n(te);$t=s(Tl,"SPAN",{});var Ol=n($t);y(be.$$.fragment,Ol),Ol.forEach(t),Tl.forEach(t),Rr=p(cr),yt=s(cr,"SPAN",{});var Al=n(yt);qr=l(Al,"Utilities"),Al.forEach(t),cr.forEach(t),Ja=p(a),F=s(a,"DIV",{class:!0});var dr=n(F);y(_e.$$.fragment,dr),Br=p(dr),Et=s(dr,"P",{});var Cl=n(Et);Kr=l(Cl,"Evaluation output (always contains labels), to be used to compute metrics."),Cl.forEach(t),dr.forEach(t),Qa=p(a),G=s(a,"DIV",{class:!0});var hr=n(G);y(ve.$$.fragment,hr),Yr=p(hr),Dt=s(hr,"P",{});var Ll=n(Dt);Wr=l(Ll,"An enumeration."),Ll.forEach(t),hr.forEach(t),Xa=p(a),I=s(a,"DIV",{class:!0});var ht=n(I);y(we.$$.fragment,ht),Jr=p(ht),jt=s(ht,"P",{});var Ul=n(jt);Qr=l(Ul,"Helper function for reproducible behavior during distributed training. See"),Ul.forEach(t),Xr=p(ht),$e=s(ht,"UL",{});var fr=n($e);rt=s(fr,"LI",{});var _l=n(rt);ye=s(_l,"A",{href:!0,rel:!0});var Il=n(ye);Zr=l(Il,"https://pytorch.org/docs/stable/notes/randomness.html"),Il.forEach(t),es=l(_l," for pytorch"),_l.forEach(t),ts=p(fr),st=s(fr,"LI",{});var vl=n(st);Ee=s(vl,"A",{href:!0,rel:!0});var zl=n(Ee);as=l(zl,"https://www.tensorflow.org/api_docs/python/tf/config/experimental/enable_op_determinism"),zl.forEach(t),rs=l(vl," for tensorflow"),vl.forEach(t),fr.forEach(t),ht.forEach(t),Za=p(a),V=s(a,"DIV",{class:!0});var mr=n(V);y(De.$$.fragment,mr),ss=p(mr),L=s(mr,"P",{});var S=n(L);ns=l(S,"Helper function for reproducible behavior to set the seed in "),xt=s(S,"CODE",{});var Hl=n(xt);os=l(Hl,"random"),Hl.forEach(t),ls=l(S,", "),kt=s(S,"CODE",{});var Sl=n(kt);is=l(Sl,"numpy"),Sl.forEach(t),ps=l(S,", "),Pt=s(S,"CODE",{});var Nl=n(Pt);cs=l(Nl,"torch"),Nl.forEach(t),ds=l(S," and/or "),Tt=s(S,"CODE",{});var Fl=n(Tt);hs=l(Fl,"tf"),Fl.forEach(t),fs=l(S," (if installed)."),S.forEach(t),mr.forEach(t),er=p(a),M=s(a,"DIV",{class:!0});var ur=n(M);y(je.$$.fragment,ur),ms=p(ur),Ot=s(ur,"P",{});var Gl=n(Ot);us=l(Gl,"Decorator to make all processes in distributed training wait for each local_master to do something."),Gl.forEach(t),ur.forEach(t),tr=p(a),R=s(a,"H2",{class:!0});var gr=n(R);ae=s(gr,"A",{id:!0,class:!0,href:!0});var Vl=n(ae);At=s(Vl,"SPAN",{});var Ml=n(At);y(xe.$$.fragment,Ml),Ml.forEach(t),Vl.forEach(t),gs=p(gr),Ct=s(gr,"SPAN",{});var Rl=n(Ct);bs=l(Rl,"Callbacks internals"),Rl.forEach(t),gr.forEach(t),ar=p(a),q=s(a,"DIV",{class:!0});var br=n(q);y(ke.$$.fragment,br),_s=p(br),Lt=s(br,"P",{});var ql=n(Lt);vs=l(ql,"Internal class that just calls the list of callbacks in order."),ql.forEach(t),br.forEach(t),rr=p(a),B=s(a,"H2",{class:!0});var _r=n(B);re=s(_r,"A",{id:!0,class:!0,href:!0});var Bl=n(re);Ut=s(Bl,"SPAN",{});var Kl=n(Ut);y(Pe.$$.fragment,Kl),Kl.forEach(t),Bl.forEach(t),ws=p(_r),It=s(_r,"SPAN",{});var Yl=n(It);$s=l(Yl,"Distributed Evaluation"),Yl.forEach(t),_r.forEach(t),sr=p(a),v=s(a,"DIV",{class:!0});var P=n(v);y(Te.$$.fragment,P),ys=p(P),zt=s(P,"P",{});var Wl=n(zt);Es=l(Wl,"A class responsible for properly gathering tensors (or nested list/tuple of tensors) on the CPU by chunks."),Wl.forEach(t),Ds=p(P),Ht=s(P,"P",{});var Jl=n(Ht);js=l(Jl,`If our dataset has 16 samples with a batch size of 2 on 3 processes and we gather then transfer on CPU at every
step, our sampler will generate the following indices:`),Jl.forEach(t),xs=p(P),St=s(P,"P",{});var Ql=n(St);Nt=s(Ql,"CODE",{});var Xl=n(Nt);ks=l(Xl,"[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 0, 1]"),Xl.forEach(t),Ql.forEach(t),Ps=p(P),Ft=s(P,"P",{});var Zl=n(Ft);Ts=l(Zl,`to get something of size a multiple of 3 (so that each process gets the same dataset length). Then process 0, 1 and
2 will be responsible of making predictions for the following samples:`),Zl.forEach(t),Os=p(P),K=s(P,"UL",{});var ft=n(K);nt=s(ft,"LI",{});var wl=n(nt);As=l(wl,"P0: "),Gt=s(wl,"CODE",{});var ei=n(Gt);Cs=l(ei,"[0, 1, 2, 3, 4, 5]"),ei.forEach(t),wl.forEach(t),Ls=p(ft),ot=s(ft,"LI",{});var $l=n(ot);Us=l($l,"P1: "),Vt=s($l,"CODE",{});var ti=n(Vt);Is=l(ti,"[6, 7, 8, 9, 10, 11]"),ti.forEach(t),$l.forEach(t),zs=p(ft),lt=s(ft,"LI",{});var yl=n(lt);Hs=l(yl,"P2: "),Mt=s(yl,"CODE",{});var ai=n(Mt);Ss=l(ai,"[12, 13, 14, 15, 0, 1]"),ai.forEach(t),yl.forEach(t),ft.forEach(t),Ns=p(P),Rt=s(P,"P",{});var ri=n(Rt);Fs=l(ri,"The first batch treated on each process will be"),ri.forEach(t),Gs=p(P),Y=s(P,"UL",{});var mt=n(Y);it=s(mt,"LI",{});var El=n(it);Vs=l(El,"P0: "),qt=s(El,"CODE",{});var si=n(qt);Ms=l(si,"[0, 1]"),si.forEach(t),El.forEach(t),Rs=p(mt),pt=s(mt,"LI",{});var Dl=n(pt);qs=l(Dl,"P1: "),Bt=s(Dl,"CODE",{});var ni=n(Bt);Bs=l(ni,"[6, 7]"),ni.forEach(t),Dl.forEach(t),Ks=p(mt),ct=s(mt,"LI",{});var jl=n(ct);Ys=l(jl,"P2: "),Kt=s(jl,"CODE",{});var oi=n(Kt);Ws=l(oi,"[12, 13]"),oi.forEach(t),jl.forEach(t),mt.forEach(t),Js=p(P),Yt=s(P,"P",{});var li=n(Yt);Qs=l(li,`So if we gather at the end of the first batch, we will get a tensor (nested list/tuple of tensor) corresponding to
the following indices:`),li.forEach(t),Xs=p(P),Wt=s(P,"P",{});var ii=n(Wt);Jt=s(ii,"CODE",{});var pi=n(Jt);Zs=l(pi,"[0, 1, 6, 7, 12, 13]"),pi.forEach(t),ii.forEach(t),en=p(P),Qt=s(P,"P",{});var ci=n(Qt);tn=l(ci,`If we directly concatenate our results without taking any precautions, the user will then get the predictions for
the indices in this order at the end of the prediction loop:`),ci.forEach(t),an=p(P),Xt=s(P,"P",{});var di=n(Xt);Zt=s(di,"CODE",{});var hi=n(Zt);rn=l(hi,"[0, 1, 6, 7, 12, 13, 2, 3, 8, 9, 14, 15, 4, 5, 10, 11, 0, 1]"),hi.forEach(t),di.forEach(t),sn=p(P),ea=s(P,"P",{});var fi=n(ea);nn=l(fi,"For some reason, that\u2019s not going to roll their boat. This class is there to solve that problem."),fi.forEach(t),on=p(P),se=s(P,"DIV",{class:!0});var vr=n(se);y(Oe.$$.fragment,vr),ln=p(vr),Ae=s(vr,"P",{});var wr=n(Ae);pn=l(wr,"Add "),ta=s(wr,"CODE",{});var mi=n(ta);cn=l(mi,"arrays"),mi.forEach(t),dn=l(wr,` to the internal storage, Will initialize the storage to the full size at the first arrays passed
so that if we\u2019re bound to get an OOM, it happens at the beginning.`),wr.forEach(t),vr.forEach(t),hn=p(P),ne=s(P,"DIV",{class:!0});var $r=n(ne);y(Ce.$$.fragment,$r),fn=p($r),aa=s($r,"P",{});var ui=n(aa);mn=l(ui,`Return the properly gathered arrays and truncate to the number of samples (since the sampler added some extras
to get each process a dataset of the same length).`),ui.forEach(t),$r.forEach(t),P.forEach(t),nr=p(a),W=s(a,"H2",{class:!0});var yr=n(W);oe=s(yr,"A",{id:!0,class:!0,href:!0});var gi=n(oe);ra=s(gi,"SPAN",{});var bi=n(ra);y(Le.$$.fragment,bi),bi.forEach(t),gi.forEach(t),un=p(yr),sa=s(yr,"SPAN",{});var _i=n(sa);gn=l(_i,"Distributed Evaluation"),_i.forEach(t),yr.forEach(t),or=p(a),O=s(a,"DIV",{class:!0});var C=n(O);y(Ue.$$.fragment,C),bn=p(C),Ie=s(C,"P",{});var Er=n(Ie);_n=l(Er,"This subclass of "),na=s(Er,"CODE",{});var vi=n(na);vn=l(vi,"argparse.ArgumentParser"),vi.forEach(t),wn=l(Er," uses type hints on dataclasses to generate arguments."),Er.forEach(t),$n=p(C),ze=s(C,"P",{});var Dr=n(ze);yn=l(Dr,`The class is designed to play well with the native argparse. In particular, you can add more (non-dataclass backed)
arguments to the parser after initialization and you\u2019ll get the output back after parsing as an additional
namespace. Optional: To create sub argument groups use the `),oa=s(Dr,"CODE",{});var wi=n(oa);En=l(wi,"_argument_group_name"),wi.forEach(t),Dn=l(Dr," attribute in the dataclass."),Dr.forEach(t),jn=p(C),H=s(C,"DIV",{class:!0});var ut=n(H);y(He.$$.fragment,ut),xn=p(ut),la=s(ut,"P",{});var $i=n(la);kn=l($i,"Parse command-line args into instances of the specified dataclass types."),$i.forEach(t),Pn=p(ut),Se=s(ut,"P",{});var jr=n(Se);Tn=l(jr,"This relies on argparse\u2019s "),ia=s(jr,"CODE",{});var yi=n(ia);On=l(yi,"ArgumentParser.parse_known_args"),yi.forEach(t),An=l(jr,`. See the doc at:
docs.python.org/3.7/library/argparse.html#argparse.ArgumentParser.parse_args`),jr.forEach(t),ut.forEach(t),Cn=p(C),le=s(C,"DIV",{class:!0});var xr=n(le);y(Ne.$$.fragment,xr),Ln=p(xr),Fe=s(xr,"P",{});var kr=n(Fe);Un=l(kr,"Alternative helper method that does not use "),pa=s(kr,"CODE",{});var Ei=n(pa);In=l(Ei,"argparse"),Ei.forEach(t),zn=l(kr,` at all, instead uses a dict and populating the dataclass
types.`),kr.forEach(t),xr.forEach(t),Hn=p(C),ie=s(C,"DIV",{class:!0});var Pr=n(ie);y(Ge.$$.fragment,Pr),Sn=p(Pr),Ve=s(Pr,"P",{});var Tr=n(Ve);Nn=l(Tr,"Alternative helper method that does not use "),ca=s(Tr,"CODE",{});var Di=n(ca);Fn=l(Di,"argparse"),Di.forEach(t),Gn=l(Tr,` at all, instead loading a json file and populating the
dataclass types.`),Tr.forEach(t),Pr.forEach(t),Vn=p(C),pe=s(C,"DIV",{class:!0});var Or=n(pe);y(Me.$$.fragment,Or),Mn=p(Or),Re=s(Or,"P",{});var Ar=n(Re);Rn=l(Ar,"Alternative helper method that does not use "),da=s(Ar,"CODE",{});var ji=n(da);qn=l(ji,"argparse"),ji.forEach(t),Bn=l(Ar,` at all, instead loading a json file and populating the
dataclass types.`),Ar.forEach(t),Or.forEach(t),C.forEach(t),lr=p(a),J=s(a,"H2",{class:!0});var Cr=n(J);ce=s(Cr,"A",{id:!0,class:!0,href:!0});var xi=n(ce);ha=s(xi,"SPAN",{});var ki=n(ha);y(qe.$$.fragment,ki),ki.forEach(t),xi.forEach(t),Kn=p(Cr),fa=s(Cr,"SPAN",{});var Pi=n(fa);Yn=l(Pi,"Debug Utilities"),Pi.forEach(t),Cr.forEach(t),ir=p(a),d=s(a,"DIV",{class:!0});var h=n(d);y(Be.$$.fragment,h),Wn=p(h),Q=s(h,"P",{});var gt=n(Q);Jn=l(gt,`This debug class helps detect and understand where the model starts getting very large or very small, and more
importantly `),ma=s(gt,"CODE",{});var Ti=n(ma);Qn=l(Ti,"nan"),Ti.forEach(t),Xn=l(gt," or "),ua=s(gt,"CODE",{});var Oi=n(ua);Zn=l(Oi,"inf"),Oi.forEach(t),eo=l(gt," weight and activation elements."),gt.forEach(t),to=p(h),ga=s(h,"P",{});var Ai=n(ga);ao=l(Ai,"There are 2 working modes:"),Ai.forEach(t),ro=p(h),Ke=s(h,"OL",{});var Lr=n(Ke);ba=s(Lr,"LI",{});var Ci=n(ba);so=l(Ci,"Underflow/overflow detection (default)"),Ci.forEach(t),no=p(Lr),_a=s(Lr,"LI",{});var Li=n(_a);oo=l(Li,"Specific batch absolute min/max tracing without detection"),Li.forEach(t),Lr.forEach(t),lo=p(h),va=s(h,"P",{});var Ui=n(va);io=l(Ui,"Mode 1: Underflow/overflow detection"),Ui.forEach(t),po=p(h),y(de.$$.fragment,h),co=p(h),z=s(h,"P",{});var ge=n(z);ho=l(ge,"then run the training as normal and if "),wa=s(ge,"CODE",{});var Ii=n(wa);fo=l(Ii,"nan"),Ii.forEach(t),mo=l(ge," or "),$a=s(ge,"CODE",{});var zi=n($a);uo=l(zi,"inf"),zi.forEach(t),go=l(ge,` gets detected in at least one of the weight, input or output
elements this module will throw an exception and will print `),ya=s(ge,"CODE",{});var Hi=n(ya);bo=l(Hi,"max_frames_to_save"),Hi.forEach(t),_o=l(ge,` frames that lead to this event,
each frame reporting`),ge.forEach(t),vo=p(h),Ye=s(h,"OL",{});var Ur=n(Ye);We=s(Ur,"LI",{});var Ir=n(We);wo=l(Ir,"the fully qualified module name plus the class name whose "),Ea=s(Ir,"CODE",{});var Si=n(Ea);$o=l(Si,"forward"),Si.forEach(t),yo=l(Ir," was run"),Ir.forEach(t),Eo=p(Ur),Da=s(Ur,"LI",{});var Ni=n(Da);Do=l(Ni,"the absolute min and max value of all elements for each module weights, and the inputs and output"),Ni.forEach(t),Ur.forEach(t),jo=p(h),Je=s(h,"P",{});var zr=n(Je);xo=l(zr,"For example, here is the header and the last few frames in detection report for "),ja=s(zr,"CODE",{});var Fi=n(ja);ko=l(Fi,"google/mt5-small"),Fi.forEach(t),Po=l(zr," run in fp16"),zr.forEach(t),To=p(h),y(he.$$.fragment,h),Oo=p(h),X=s(h,"P",{});var bt=n(X);Ao=l(bt,"You can see here, that "),xa=s(bt,"CODE",{});var Gi=n(xa);Co=l(Gi,"T5DenseGatedGeluDense.forward"),Gi.forEach(t),Lo=l(bt,` resulted in output activations, whose absolute max value was
around 62.7K, which is very close to fp16\u2019s top limit of 64K. In the next frame we have `),ka=s(bt,"CODE",{});var Vi=n(ka);Uo=l(Vi,"Dropout"),Vi.forEach(t),Io=l(bt,` which
renormalizes the weights, after it zeroed some of the elements, which pushes the absolute max value to more than
64K, and we get an overlow.`),bt.forEach(t),zo=p(h),Pa=s(h,"P",{});var Mi=n(Pa);Ho=l(Mi,`As you can see it\u2019s the previous frames that we need to look into when the numbers start going into very large for
fp16 numbers.`),Mi.forEach(t),So=p(h),Qe=s(h,"P",{});var Hr=n(Qe);No=l(Hr,"The tracking is done in a forward hook, which gets invoked immediately after "),Ta=s(Hr,"CODE",{});var Ri=n(Ta);Fo=l(Ri,"forward"),Ri.forEach(t),Go=l(Hr," has completed."),Hr.forEach(t),Vo=p(h),y(fe.$$.fragment,h),Mo=p(h),Oa=s(h,"P",{});var qi=n(Oa);Ro=l(qi,`To validate that you have set up this debugging feature correctly, and you intend to use it in a training that
may take hours to complete, first run it with normal tracing enabled for one of a few batches as explained in
the next section.`),qi.forEach(t),qo=p(h),Aa=s(h,"P",{});var Bi=n(Aa);Bo=l(Bi,"Mode 2. Specific batch absolute min/max tracing without detection"),Bi.forEach(t),Ko=p(h),Ca=s(h,"P",{});var Ki=n(Ca);Yo=l(Ki,"The second work mode is per-batch tracing with the underflow/overflow detection feature turned off."),Ki.forEach(t),Wo=p(h),Xe=s(h,"P",{});var Sr=n(Xe);Jo=l(Sr,"Let\u2019s say you want to watch the absolute min and max values for all the ingredients of each "),La=s(Sr,"CODE",{});var Yi=n(La);Qo=l(Yi,"forward"),Yi.forEach(t),Xo=l(Sr," call of a"),Sr.forEach(t),Zo=p(h),y(me.$$.fragment,h),el=p(h),Ua=s(h,"P",{});var Wi=n(Ua);tl=l(Wi,"And now full batches 1 and 3 will be traced using the same format as explained above. Batches are 0-indexed."),Wi.forEach(t),al=p(h),Ia=s(h,"P",{});var Ji=n(Ia);rl=l(Ji,`This is helpful if you know that the program starts misbehaving after a certain batch number, so you can
fast-forward right to that area.`),Ji.forEach(t),sl=p(h),za=s(h,"P",{});var Qi=n(za);nl=l(Qi,"Early stopping:"),Qi.forEach(t),ol=p(h),y(ue.$$.fragment,h),ll=p(h),Ha=s(h,"P",{});var Xi=n(Ha);il=l(Xi,"This feature is mainly useful in the tracing mode, but you can use it for any mode."),Xi.forEach(t),pl=p(h),dt=s(h,"P",{});var xl=n(dt);Sa=s(xl,"STRONG",{});var Zi=n(Sa);cl=l(Zi,"Performance"),Zi.forEach(t),dl=l(xl,":"),xl.forEach(t),hl=p(h),Z=s(h,"P",{});var _t=n(Z);fl=l(_t,"As this module measures absolute "),Na=s(_t,"CODE",{});var ep=n(Na);ml=l(ep,"min"),ep.forEach(t),ul=l(_t,"/`"),Fa=s(_t,"CODE",{});var tp=n(Fa);gl=l(tp,"max"),tp.forEach(t),bl=l(_t,` of each weight of the model on every forward it\u2019ll slow the training
down. Therefore remember to turn it off once the debugging needs have been met.`),_t.forEach(t),h.forEach(t),this.h()},h(){u(g,"name","hf:doc:metadata"),u(g,"content",JSON.stringify(fp)),u(f,"id","utilities-for-trainer"),u(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(f,"href","#utilities-for-trainer"),u(w,"class","relative group"),u(tt,"href","/docs/transformers/v4.24.0/en/main_classes/trainer#transformers.Trainer"),u(te,"id","transformers.EvalPrediction"),u(te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(te,"href","#transformers.EvalPrediction"),u(N,"class","relative group"),u(F,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(G,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(ye,"href","https://pytorch.org/docs/stable/notes/randomness.html"),u(ye,"rel","nofollow"),u(Ee,"href","https://www.tensorflow.org/api_docs/python/tf/config/experimental/enable_op_determinism"),u(Ee,"rel","nofollow"),u(I,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(V,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(M,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(ae,"id","transformers.trainer_callback.CallbackHandler"),u(ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ae,"href","#transformers.trainer_callback.CallbackHandler"),u(R,"class","relative group"),u(q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(re,"id","transformers.trainer_pt_utils.DistributedTensorGatherer"),u(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(re,"href","#transformers.trainer_pt_utils.DistributedTensorGatherer"),u(B,"class","relative group"),u(se,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(ne,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(v,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(oe,"id","transformers.HfArgumentParser"),u(oe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(oe,"href","#transformers.HfArgumentParser"),u(W,"class","relative group"),u(H,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(le,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(ie,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(pe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(O,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(ce,"id","transformers.debug_utils.DebugUnderflowOverflow"),u(ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ce,"href","#transformers.debug_utils.DebugUnderflowOverflow"),u(J,"class","relative group"),u(d,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(a,m){e(document.head,g),b(a,T,m),b(a,w,m),e(w,f),e(f,k),E(c,k,null),e(w,_),e(w,wt),e(wt,Nr),b(a,Ka,m),b(a,ee,m),e(ee,Fr),e(ee,tt),e(tt,Gr),e(ee,Vr),b(a,Ya,m),b(a,at,m),e(at,Mr),b(a,Wa,m),b(a,N,m),e(N,te),e(te,$t),E(be,$t,null),e(N,Rr),e(N,yt),e(yt,qr),b(a,Ja,m),b(a,F,m),E(_e,F,null),e(F,Br),e(F,Et),e(Et,Kr),b(a,Qa,m),b(a,G,m),E(ve,G,null),e(G,Yr),e(G,Dt),e(Dt,Wr),b(a,Xa,m),b(a,I,m),E(we,I,null),e(I,Jr),e(I,jt),e(jt,Qr),e(I,Xr),e(I,$e),e($e,rt),e(rt,ye),e(ye,Zr),e(rt,es),e($e,ts),e($e,st),e(st,Ee),e(Ee,as),e(st,rs),b(a,Za,m),b(a,V,m),E(De,V,null),e(V,ss),e(V,L),e(L,ns),e(L,xt),e(xt,os),e(L,ls),e(L,kt),e(kt,is),e(L,ps),e(L,Pt),e(Pt,cs),e(L,ds),e(L,Tt),e(Tt,hs),e(L,fs),b(a,er,m),b(a,M,m),E(je,M,null),e(M,ms),e(M,Ot),e(Ot,us),b(a,tr,m),b(a,R,m),e(R,ae),e(ae,At),E(xe,At,null),e(R,gs),e(R,Ct),e(Ct,bs),b(a,ar,m),b(a,q,m),E(ke,q,null),e(q,_s),e(q,Lt),e(Lt,vs),b(a,rr,m),b(a,B,m),e(B,re),e(re,Ut),E(Pe,Ut,null),e(B,ws),e(B,It),e(It,$s),b(a,sr,m),b(a,v,m),E(Te,v,null),e(v,ys),e(v,zt),e(zt,Es),e(v,Ds),e(v,Ht),e(Ht,js),e(v,xs),e(v,St),e(St,Nt),e(Nt,ks),e(v,Ps),e(v,Ft),e(Ft,Ts),e(v,Os),e(v,K),e(K,nt),e(nt,As),e(nt,Gt),e(Gt,Cs),e(K,Ls),e(K,ot),e(ot,Us),e(ot,Vt),e(Vt,Is),e(K,zs),e(K,lt),e(lt,Hs),e(lt,Mt),e(Mt,Ss),e(v,Ns),e(v,Rt),e(Rt,Fs),e(v,Gs),e(v,Y),e(Y,it),e(it,Vs),e(it,qt),e(qt,Ms),e(Y,Rs),e(Y,pt),e(pt,qs),e(pt,Bt),e(Bt,Bs),e(Y,Ks),e(Y,ct),e(ct,Ys),e(ct,Kt),e(Kt,Ws),e(v,Js),e(v,Yt),e(Yt,Qs),e(v,Xs),e(v,Wt),e(Wt,Jt),e(Jt,Zs),e(v,en),e(v,Qt),e(Qt,tn),e(v,an),e(v,Xt),e(Xt,Zt),e(Zt,rn),e(v,sn),e(v,ea),e(ea,nn),e(v,on),e(v,se),E(Oe,se,null),e(se,ln),e(se,Ae),e(Ae,pn),e(Ae,ta),e(ta,cn),e(Ae,dn),e(v,hn),e(v,ne),E(Ce,ne,null),e(ne,fn),e(ne,aa),e(aa,mn),b(a,nr,m),b(a,W,m),e(W,oe),e(oe,ra),E(Le,ra,null),e(W,un),e(W,sa),e(sa,gn),b(a,or,m),b(a,O,m),E(Ue,O,null),e(O,bn),e(O,Ie),e(Ie,_n),e(Ie,na),e(na,vn),e(Ie,wn),e(O,$n),e(O,ze),e(ze,yn),e(ze,oa),e(oa,En),e(ze,Dn),e(O,jn),e(O,H),E(He,H,null),e(H,xn),e(H,la),e(la,kn),e(H,Pn),e(H,Se),e(Se,Tn),e(Se,ia),e(ia,On),e(Se,An),e(O,Cn),e(O,le),E(Ne,le,null),e(le,Ln),e(le,Fe),e(Fe,Un),e(Fe,pa),e(pa,In),e(Fe,zn),e(O,Hn),e(O,ie),E(Ge,ie,null),e(ie,Sn),e(ie,Ve),e(Ve,Nn),e(Ve,ca),e(ca,Fn),e(Ve,Gn),e(O,Vn),e(O,pe),E(Me,pe,null),e(pe,Mn),e(pe,Re),e(Re,Rn),e(Re,da),e(da,qn),e(Re,Bn),b(a,lr,m),b(a,J,m),e(J,ce),e(ce,ha),E(qe,ha,null),e(J,Kn),e(J,fa),e(fa,Yn),b(a,ir,m),b(a,d,m),E(Be,d,null),e(d,Wn),e(d,Q),e(Q,Jn),e(Q,ma),e(ma,Qn),e(Q,Xn),e(Q,ua),e(ua,Zn),e(Q,eo),e(d,to),e(d,ga),e(ga,ao),e(d,ro),e(d,Ke),e(Ke,ba),e(ba,so),e(Ke,no),e(Ke,_a),e(_a,oo),e(d,lo),e(d,va),e(va,io),e(d,po),E(de,d,null),e(d,co),e(d,z),e(z,ho),e(z,wa),e(wa,fo),e(z,mo),e(z,$a),e($a,uo),e(z,go),e(z,ya),e(ya,bo),e(z,_o),e(d,vo),e(d,Ye),e(Ye,We),e(We,wo),e(We,Ea),e(Ea,$o),e(We,yo),e(Ye,Eo),e(Ye,Da),e(Da,Do),e(d,jo),e(d,Je),e(Je,xo),e(Je,ja),e(ja,ko),e(Je,Po),e(d,To),E(he,d,null),e(d,Oo),e(d,X),e(X,Ao),e(X,xa),e(xa,Co),e(X,Lo),e(X,ka),e(ka,Uo),e(X,Io),e(d,zo),e(d,Pa),e(Pa,Ho),e(d,So),e(d,Qe),e(Qe,No),e(Qe,Ta),e(Ta,Fo),e(Qe,Go),e(d,Vo),E(fe,d,null),e(d,Mo),e(d,Oa),e(Oa,Ro),e(d,qo),e(d,Aa),e(Aa,Bo),e(d,Ko),e(d,Ca),e(Ca,Yo),e(d,Wo),e(d,Xe),e(Xe,Jo),e(Xe,La),e(La,Qo),e(Xe,Xo),e(d,Zo),E(me,d,null),e(d,el),e(d,Ua),e(Ua,tl),e(d,al),e(d,Ia),e(Ia,rl),e(d,sl),e(d,za),e(za,nl),e(d,ol),E(ue,d,null),e(d,ll),e(d,Ha),e(Ha,il),e(d,pl),e(d,dt),e(dt,Sa),e(Sa,cl),e(dt,dl),e(d,hl),e(d,Z),e(Z,fl),e(Z,Na),e(Na,ml),e(Z,ul),e(Z,Fa),e(Fa,gl),e(Z,bl),pr=!0},p(a,[m]){const Ze={};m&2&&(Ze.$$scope={dirty:m,ctx:a}),de.$set(Ze);const Ga={};m&2&&(Ga.$$scope={dirty:m,ctx:a}),he.$set(Ga);const Va={};m&2&&(Va.$$scope={dirty:m,ctx:a}),fe.$set(Va);const Ma={};m&2&&(Ma.$$scope={dirty:m,ctx:a}),me.$set(Ma);const et={};m&2&&(et.$$scope={dirty:m,ctx:a}),ue.$set(et)},i(a){pr||(D(c.$$.fragment,a),D(be.$$.fragment,a),D(_e.$$.fragment,a),D(ve.$$.fragment,a),D(we.$$.fragment,a),D(De.$$.fragment,a),D(je.$$.fragment,a),D(xe.$$.fragment,a),D(ke.$$.fragment,a),D(Pe.$$.fragment,a),D(Te.$$.fragment,a),D(Oe.$$.fragment,a),D(Ce.$$.fragment,a),D(Le.$$.fragment,a),D(Ue.$$.fragment,a),D(He.$$.fragment,a),D(Ne.$$.fragment,a),D(Ge.$$.fragment,a),D(Me.$$.fragment,a),D(qe.$$.fragment,a),D(Be.$$.fragment,a),D(de.$$.fragment,a),D(he.$$.fragment,a),D(fe.$$.fragment,a),D(me.$$.fragment,a),D(ue.$$.fragment,a),pr=!0)},o(a){j(c.$$.fragment,a),j(be.$$.fragment,a),j(_e.$$.fragment,a),j(ve.$$.fragment,a),j(we.$$.fragment,a),j(De.$$.fragment,a),j(je.$$.fragment,a),j(xe.$$.fragment,a),j(ke.$$.fragment,a),j(Pe.$$.fragment,a),j(Te.$$.fragment,a),j(Oe.$$.fragment,a),j(Ce.$$.fragment,a),j(Le.$$.fragment,a),j(Ue.$$.fragment,a),j(He.$$.fragment,a),j(Ne.$$.fragment,a),j(Ge.$$.fragment,a),j(Me.$$.fragment,a),j(qe.$$.fragment,a),j(Be.$$.fragment,a),j(de.$$.fragment,a),j(he.$$.fragment,a),j(fe.$$.fragment,a),j(me.$$.fragment,a),j(ue.$$.fragment,a),pr=!1},d(a){t(g),a&&t(T),a&&t(w),x(c),a&&t(Ka),a&&t(ee),a&&t(Ya),a&&t(at),a&&t(Wa),a&&t(N),x(be),a&&t(Ja),a&&t(F),x(_e),a&&t(Qa),a&&t(G),x(ve),a&&t(Xa),a&&t(I),x(we),a&&t(Za),a&&t(V),x(De),a&&t(er),a&&t(M),x(je),a&&t(tr),a&&t(R),x(xe),a&&t(ar),a&&t(q),x(ke),a&&t(rr),a&&t(B),x(Pe),a&&t(sr),a&&t(v),x(Te),x(Oe),x(Ce),a&&t(nr),a&&t(W),x(Le),a&&t(or),a&&t(O),x(Ue),x(He),x(Ne),x(Ge),x(Me),a&&t(lr),a&&t(J),x(qe),a&&t(ir),a&&t(d),x(Be),x(de),x(he),x(fe),x(me),x(ue)}}}const fp={local:"utilities-for-trainer",sections:[{local:"transformers.EvalPrediction",title:"Utilities"},{local:"transformers.trainer_callback.CallbackHandler",title:"Callbacks internals"},{local:"transformers.trainer_pt_utils.DistributedTensorGatherer",title:"Distributed Evaluation"},{local:"transformers.HfArgumentParser",title:"Distributed Evaluation"},{local:"transformers.debug_utils.DebugUnderflowOverflow",title:"Debug Utilities"}],title:"Utilities for Trainer"};function mp(U){return op(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class wp extends ap{constructor(g){super();rp(this,g,mp,hp,sp,{})}}export{wp as default,fp as metadata};
