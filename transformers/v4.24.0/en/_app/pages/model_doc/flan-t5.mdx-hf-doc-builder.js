import{S as xt,i as Lt,s as Tt,e as o,k as h,w as Je,t as i,M as $t,c as l,d as t,m as u,a as s,x as Re,h as f,b as r,G as a,g as p,y as De,L as yt,q as Ke,o as Qe,B as Ve,v as qt}from"../../chunks/vendor-hf-doc-builder.js";import{I as bt}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as Pt}from"../../chunks/CodeBlock-hf-doc-builder.js";function Ft(We){let g,Y,d,_,C,x,ge,G,de,Z,v,w,B,L,ve,H,_e,ee,A,we,T,Ae,Ee,te,M,ke,ae,$,oe,E,be,y,xe,Le,le,z,Te,se,c,U,J,q,$e,ye,R,D,P,qe,Pe,K,Q,F,Fe,Se,V,W,S,Ne,je,X,I,N,Me,ze,re,k,Ie,O,Oe,Ce,ne,b,Ge,j,Be,He,ie;return x=new bt({}),L=new bt({}),$=new Pt({props:{code:`from transformers import AutoModelForSeq2SeqLM, AutoTokenizer

model = AutoModelForSeq2SeqLM.from_pretrained("google/flan-t5-small")
tokenizer = AutoTokenizer.from_pretrained("google/flan-t5-small")

inputs = tokenizer("A step by step recipe to make bolognese pasta:", return_tensors="pt")
outputs = model.generate(**inputs)
print(tokenizer.batch_decode(outputs, skip_special_tokens=True))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSeq2SeqLM, AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;google/flan-t5-small&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;google/flan-t5-small&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;A step by step recipe to make bolognese pasta:&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model.generate(**inputs)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(tokenizer.batch_decode(outputs, skip_special_tokens=<span class="hljs-literal">True</span>))
[<span class="hljs-string">&#x27;Pour a cup of bolognese into a large bowl and add the pasta&#x27;</span>]`}}),{c(){g=o("meta"),Y=h(),d=o("h1"),_=o("a"),C=o("span"),Je(x.$$.fragment),ge=h(),G=o("span"),de=i("FLAN-T5"),Z=h(),v=o("h2"),w=o("a"),B=o("span"),Je(L.$$.fragment),ve=h(),H=o("span"),_e=i("Overview"),ee=h(),A=o("p"),we=i("FLAN-T5 was released in the paper "),T=o("a"),Ae=i("Scaling Instruction-Finetuned Language Models"),Ee=i(" - it is an enhanced version of T5 that has been finetuned in a mixture of tasks."),te=h(),M=o("p"),ke=i("One can directly use FLAN-T5 weights without finetuning the model:"),ae=h(),Je($.$$.fragment),oe=h(),E=o("p"),be=i("FLAN-T5 includes the same improvements as T5 version 1.1 (see "),y=o("a"),xe=i("here"),Le=i(" for the full details of the model\u2019s improvements.)"),le=h(),z=o("p"),Te=i("Google has released the following variants:"),se=h(),c=o("ul"),U=o("li"),J=o("p"),q=o("a"),$e=i("google/flan-t5-small"),ye=h(),R=o("li"),D=o("p"),P=o("a"),qe=i("google/flan-t5-base"),Pe=h(),K=o("li"),Q=o("p"),F=o("a"),Fe=i("google/flan-t5-large"),Se=h(),V=o("li"),W=o("p"),S=o("a"),Ne=i("google/flan-t5-xl"),je=h(),X=o("li"),I=o("p"),N=o("a"),Me=i("google/flan-t5-xxl"),ze=i("."),re=h(),k=o("p"),Ie=i("One can refer to "),O=o("a"),Oe=i("T5\u2019s documentation page"),Ce=i(" for all tips, code examples and notebooks. As well as the FLAN-T5 model card for more details regarding training and evaluation of the model."),ne=h(),b=o("p"),Ge=i("The original checkpoints can be found "),j=o("a"),Be=i("here"),He=i("."),this.h()},l(e){const n=$t('[data-svelte="svelte-1phssyn"]',document.head);g=l(n,"META",{name:!0,content:!0}),n.forEach(t),Y=u(e),d=l(e,"H1",{class:!0});var fe=s(d);_=l(fe,"A",{id:!0,class:!0,href:!0});var Xe=s(_);C=l(Xe,"SPAN",{});var Ye=s(C);Re(x.$$.fragment,Ye),Ye.forEach(t),Xe.forEach(t),ge=u(fe),G=l(fe,"SPAN",{});var Ze=s(G);de=f(Ze,"FLAN-T5"),Ze.forEach(t),fe.forEach(t),Z=u(e),v=l(e,"H2",{class:!0});var pe=s(v);w=l(pe,"A",{id:!0,class:!0,href:!0});var et=s(w);B=l(et,"SPAN",{});var tt=s(B);Re(L.$$.fragment,tt),tt.forEach(t),et.forEach(t),ve=u(pe),H=l(pe,"SPAN",{});var at=s(H);_e=f(at,"Overview"),at.forEach(t),pe.forEach(t),ee=u(e),A=l(e,"P",{});var he=s(A);we=f(he,"FLAN-T5 was released in the paper "),T=l(he,"A",{href:!0,rel:!0});var ot=s(T);Ae=f(ot,"Scaling Instruction-Finetuned Language Models"),ot.forEach(t),Ee=f(he," - it is an enhanced version of T5 that has been finetuned in a mixture of tasks."),he.forEach(t),te=u(e),M=l(e,"P",{});var lt=s(M);ke=f(lt,"One can directly use FLAN-T5 weights without finetuning the model:"),lt.forEach(t),ae=u(e),Re($.$$.fragment,e),oe=u(e),E=l(e,"P",{});var ue=s(E);be=f(ue,"FLAN-T5 includes the same improvements as T5 version 1.1 (see "),y=l(ue,"A",{href:!0,rel:!0});var st=s(y);xe=f(st,"here"),st.forEach(t),Le=f(ue," for the full details of the model\u2019s improvements.)"),ue.forEach(t),le=u(e),z=l(e,"P",{});var rt=s(z);Te=f(rt,"Google has released the following variants:"),rt.forEach(t),se=u(e),c=l(e,"UL",{});var m=s(c);U=l(m,"LI",{});var nt=s(U);J=l(nt,"P",{});var it=s(J);q=l(it,"A",{href:!0,rel:!0});var ft=s(q);$e=f(ft,"google/flan-t5-small"),ft.forEach(t),it.forEach(t),nt.forEach(t),ye=u(m),R=l(m,"LI",{});var pt=s(R);D=l(pt,"P",{});var ht=s(D);P=l(ht,"A",{href:!0,rel:!0});var ut=s(P);qe=f(ut,"google/flan-t5-base"),ut.forEach(t),ht.forEach(t),pt.forEach(t),Pe=u(m),K=l(m,"LI",{});var ct=s(K);Q=l(ct,"P",{});var mt=s(Q);F=l(mt,"A",{href:!0,rel:!0});var gt=s(F);Fe=f(gt,"google/flan-t5-large"),gt.forEach(t),mt.forEach(t),ct.forEach(t),Se=u(m),V=l(m,"LI",{});var dt=s(V);W=l(dt,"P",{});var vt=s(W);S=l(vt,"A",{href:!0,rel:!0});var _t=s(S);Ne=f(_t,"google/flan-t5-xl"),_t.forEach(t),vt.forEach(t),dt.forEach(t),je=u(m),X=l(m,"LI",{});var wt=s(X);I=l(wt,"P",{});var Ue=s(I);N=l(Ue,"A",{href:!0,rel:!0});var At=s(N);Me=f(At,"google/flan-t5-xxl"),At.forEach(t),ze=f(Ue,"."),Ue.forEach(t),wt.forEach(t),m.forEach(t),re=u(e),k=l(e,"P",{});var ce=s(k);Ie=f(ce,"One can refer to "),O=l(ce,"A",{href:!0});var Et=s(O);Oe=f(Et,"T5\u2019s documentation page"),Et.forEach(t),Ce=f(ce," for all tips, code examples and notebooks. As well as the FLAN-T5 model card for more details regarding training and evaluation of the model."),ce.forEach(t),ne=u(e),b=l(e,"P",{});var me=s(b);Ge=f(me,"The original checkpoints can be found "),j=l(me,"A",{href:!0,rel:!0});var kt=s(j);Be=f(kt,"here"),kt.forEach(t),He=f(me,"."),me.forEach(t),this.h()},h(){r(g,"name","hf:doc:metadata"),r(g,"content",JSON.stringify(St)),r(_,"id","flant5"),r(_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),r(_,"href","#flant5"),r(d,"class","relative group"),r(w,"id","overview"),r(w,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),r(w,"href","#overview"),r(v,"class","relative group"),r(T,"href","https://arxiv.org/pdf/2210.11416.pdf"),r(T,"rel","nofollow"),r(y,"href","https://huggingface.co/docs/transformers/model_doc/t5v1.1"),r(y,"rel","nofollow"),r(q,"href","https://huggingface.co/google/flan-t5-small"),r(q,"rel","nofollow"),r(P,"href","https://huggingface.co/google/flan-t5-base"),r(P,"rel","nofollow"),r(F,"href","https://huggingface.co/google/flan-t5-base"),r(F,"rel","nofollow"),r(S,"href","https://huggingface.co/google/flan-t5-xl"),r(S,"rel","nofollow"),r(N,"href","https://huggingface.co/google/flan-t5-xxl"),r(N,"rel","nofollow"),r(O,"href","t5"),r(j,"href","https://github.com/google-research/t5x/blob/main/docs/models.md#mixture-of-experts-moe-checkpoints"),r(j,"rel","nofollow")},m(e,n){a(document.head,g),p(e,Y,n),p(e,d,n),a(d,_),a(_,C),De(x,C,null),a(d,ge),a(d,G),a(G,de),p(e,Z,n),p(e,v,n),a(v,w),a(w,B),De(L,B,null),a(v,ve),a(v,H),a(H,_e),p(e,ee,n),p(e,A,n),a(A,we),a(A,T),a(T,Ae),a(A,Ee),p(e,te,n),p(e,M,n),a(M,ke),p(e,ae,n),De($,e,n),p(e,oe,n),p(e,E,n),a(E,be),a(E,y),a(y,xe),a(E,Le),p(e,le,n),p(e,z,n),a(z,Te),p(e,se,n),p(e,c,n),a(c,U),a(U,J),a(J,q),a(q,$e),a(c,ye),a(c,R),a(R,D),a(D,P),a(P,qe),a(c,Pe),a(c,K),a(K,Q),a(Q,F),a(F,Fe),a(c,Se),a(c,V),a(V,W),a(W,S),a(S,Ne),a(c,je),a(c,X),a(X,I),a(I,N),a(N,Me),a(I,ze),p(e,re,n),p(e,k,n),a(k,Ie),a(k,O),a(O,Oe),a(k,Ce),p(e,ne,n),p(e,b,n),a(b,Ge),a(b,j),a(j,Be),a(b,He),ie=!0},p:yt,i(e){ie||(Ke(x.$$.fragment,e),Ke(L.$$.fragment,e),Ke($.$$.fragment,e),ie=!0)},o(e){Qe(x.$$.fragment,e),Qe(L.$$.fragment,e),Qe($.$$.fragment,e),ie=!1},d(e){t(g),e&&t(Y),e&&t(d),Ve(x),e&&t(Z),e&&t(v),Ve(L),e&&t(ee),e&&t(A),e&&t(te),e&&t(M),e&&t(ae),Ve($,e),e&&t(oe),e&&t(E),e&&t(le),e&&t(z),e&&t(se),e&&t(c),e&&t(re),e&&t(k),e&&t(ne),e&&t(b)}}}const St={local:"flant5",sections:[{local:"overview",title:"Overview"}],title:"FLAN-T5"};function Nt(We){return qt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class It extends xt{constructor(g){super();Lt(this,g,Nt,Ft,Tt,{})}}export{It as default,St as metadata};
