import{S as ECa,i as CCa,s as wCa,e as a,k as l,w as F,t as o,M as ACa,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as v,y as M,q as E,o as C,B as w,v as LCa,L as q}from"../../chunks/vendor-hf-doc-builder.js";import{T as GAt}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as B}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as oe}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as N}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function yCa($){let g,b,u,m,p,d,h,$o,vd,zm,Tt,bd,Fd,n$,Qm,Xe,He,Td,cs,s$,fs,ms,l$,Md,gs,i$,Ed,Wm,on;return{c(){g=a("p"),b=o("If your "),u=a("code"),m=o("NewModelConfig"),p=o(" is a subclass of "),d=a("code"),h=o("~transformer.PretrainedConfig"),$o=o(`, make sure its
`),vd=a("code"),zm=o("model_type"),Tt=o(" attribute is set to the same key you use when registering the config (here "),bd=a("code"),Fd=o('"new-model"'),n$=o(")."),Qm=l(),Xe=a("p"),He=o("Likewise, if your "),Td=a("code"),cs=o("NewModel"),s$=o(" is a subclass of "),fs=a("a"),ms=o("PreTrainedModel"),l$=o(`, make sure its
`),Md=a("code"),gs=o("config_class"),i$=o(` attribute is set to the same class you use when registering the model (here
`),Ed=a("code"),Wm=o("NewModelConfig"),on=o(")."),this.h()},l(Je){g=n(Je,"P",{});var Ae=s(g);b=r(Ae,"If your "),u=n(Ae,"CODE",{});var MN=s(u);m=r(MN,"NewModelConfig"),MN.forEach(t),p=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var Cd=s(d);h=r(Cd,"~transformer.PretrainedConfig"),Cd.forEach(t),$o=r(Ae,`, make sure its
`),vd=n(Ae,"CODE",{});var EN=s(vd);zm=r(EN,"model_type"),EN.forEach(t),Tt=r(Ae," attribute is set to the same key you use when registering the config (here "),bd=n(Ae,"CODE",{});var CN=s(bd);Fd=r(CN,'"new-model"'),CN.forEach(t),n$=r(Ae,")."),Ae.forEach(t),Qm=i(Je),Xe=n(Je,"P",{});var ko=s(Xe);He=r(ko,"Likewise, if your "),Td=n(ko,"CODE",{});var rn=s(Td);cs=r(rn,"NewModel"),rn.forEach(t),s$=r(ko," is a subclass of "),fs=n(ko,"A",{href:!0});var wN=s(fs);ms=r(wN,"PreTrainedModel"),wN.forEach(t),l$=r(ko,`, make sure its
`),Md=n(ko,"CODE",{});var Um=s(Md);gs=r(Um,"config_class"),Um.forEach(t),i$=r(ko,` attribute is set to the same class you use when registering the model (here
`),Ed=n(ko,"CODE",{});var AN=s(Ed);Wm=r(AN,"NewModelConfig"),AN.forEach(t),on=r(ko,")."),ko.forEach(t),this.h()},h(){c(fs,"href","/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel")},m(Je,Ae){v(Je,g,Ae),e(g,b),e(g,u),e(u,m),e(g,p),e(g,d),e(d,h),e(g,$o),e(g,vd),e(vd,zm),e(g,Tt),e(g,bd),e(bd,Fd),e(g,n$),v(Je,Qm,Ae),v(Je,Xe,Ae),e(Xe,He),e(Xe,Td),e(Td,cs),e(Xe,s$),e(Xe,fs),e(fs,ms),e(Xe,l$),e(Xe,Md),e(Md,gs),e(Xe,i$),e(Xe,Ed),e(Ed,Wm),e(Xe,on)},d(Je){Je&&t(g),Je&&t(Qm),Je&&t(Xe)}}}function xCa($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function $Ca($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function kCa($){let g,b,u,m,p;return{c(){g=a("p"),b=o("Passing "),u=a("code"),m=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Passing "),u=n(h,"CODE",{});var $o=s(u);m=r($o,"use_auth_token=True"),$o.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){v(d,g,h),e(g,b),e(g,u),e(u,m),e(g,p)},d(d){d&&t(g)}}}function SCa($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function RCa($){let g,b,u,m,p;return{c(){g=a("p"),b=o("Passing "),u=a("code"),m=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Passing "),u=n(h,"CODE",{});var $o=s(u);m=r($o,"use_auth_token=True"),$o.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){v(d,g,h),e(g,b),e(g,u),e(u,m),e(g,p)},d(d){d&&t(g)}}}function PCa($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function BCa($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function ICa($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function NCa($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function qCa($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function jCa($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function DCa($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function GCa($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForDepthEstimation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForDepthEstimation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDepthEstimation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function OCa($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForDepthEstimation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDepthEstimation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForDepthEstimation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForDepthEstimation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDepthEstimation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function VCa($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function XCa($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function zCa($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function QCa($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function WCa($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function UCa($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function HCa($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function JCa($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function YCa($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function ZCa($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function KCa($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function e3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function o3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function r3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function t3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function a3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function n3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = AutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function s3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/layoutlm_tf_model_config.json")
model = AutoModelForDocumentQuestionAnswering.from_pretrained(
    "./tf_model/layoutlm_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/layoutlm_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/layoutlm_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function l3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function i3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function d3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVideoClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function c3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVideoClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function f3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function m3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function g3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function h3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function u3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function p3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function _3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function v3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function b3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function F3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function T3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function M3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function E3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function C3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function w3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function A3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function L3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function y3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function x3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function $3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function k3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function S3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function R3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function P3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function B3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForZeroShotObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function I3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForZeroShotObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function N3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function q3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function j3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function D3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function G3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function O3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function V3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function X3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function z3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Q3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSemanticSegmentation.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function W3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function U3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function H3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function J3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Y3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Z3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function K3a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function e5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function o5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function r5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function t5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function a5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function n5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function s5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/layoutlm_pt_model_config.json")
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
    "./pt_model/layoutlm_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/layoutlm_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/layoutlm_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function l5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function i5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function d5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function c5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function f5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function m5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function g5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function h5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function u5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function p5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function _5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function v5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function b5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function F5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function T5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function M5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function E5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function C5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function w5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function A5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function L5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function y5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function x5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function $5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function k5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function S5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function R5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function P5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function B5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function I5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function N5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function q5a($){let g,b,u,m,p;return m=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:q,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function j5a($){let g,b,u,m,p,d,h,$o,vd,zm,Tt,bd,Fd,n$,Qm,Xe,He,Td,cs,s$,fs,ms,l$,Md,gs,i$,Ed,Wm,on,Je,Ae,MN,Cd,EN,CN,ko,rn,wN,Um,AN,cio,wto,wd,Hm,fme,d$,fio,mme,mio,Ato,hs,gio,gme,hio,uio,hme,pio,_io,Lto,c$,yto,LN,vio,xto,Jm,$to,Ad,Ym,ume,f$,bio,pme,Fio,kto,So,m$,Tio,g$,Mio,yN,Eio,Cio,wio,h$,Aio,_me,Lio,yio,xio,qr,u$,$io,vme,kio,Sio,Ld,Rio,bme,Pio,Bio,Fme,Iio,Nio,qio,A,Zm,Tme,jio,Dio,xN,Gio,Oio,Vio,Km,Mme,Xio,zio,$N,Qio,Wio,Uio,eg,Eme,Hio,Jio,kN,Yio,Zio,Kio,og,Cme,edo,odo,SN,rdo,tdo,ado,rg,wme,ndo,sdo,RN,ldo,ido,ddo,tg,Ame,cdo,fdo,PN,mdo,gdo,hdo,ag,Lme,udo,pdo,BN,_do,vdo,bdo,ng,yme,Fdo,Tdo,IN,Mdo,Edo,Cdo,sg,xme,wdo,Ado,NN,Ldo,ydo,xdo,lg,$me,$do,kdo,qN,Sdo,Rdo,Pdo,ig,kme,Bdo,Ido,jN,Ndo,qdo,jdo,dg,Sme,Ddo,Gdo,DN,Odo,Vdo,Xdo,cg,Rme,zdo,Qdo,GN,Wdo,Udo,Hdo,fg,Pme,Jdo,Ydo,ON,Zdo,Kdo,eco,mg,Bme,oco,rco,VN,tco,aco,nco,gg,Ime,sco,lco,XN,ico,dco,cco,hg,Nme,fco,mco,zN,gco,hco,uco,ug,qme,pco,_co,QN,vco,bco,Fco,pg,jme,Tco,Mco,WN,Eco,Cco,wco,_g,Dme,Aco,Lco,UN,yco,xco,$co,vg,Gme,kco,Sco,HN,Rco,Pco,Bco,bg,Ome,Ico,Nco,JN,qco,jco,Dco,Fg,Vme,Gco,Oco,YN,Vco,Xco,zco,Tg,Xme,Qco,Wco,ZN,Uco,Hco,Jco,Mg,zme,Yco,Zco,KN,Kco,efo,ofo,Eg,Qme,rfo,tfo,eq,afo,nfo,sfo,Cg,Wme,lfo,ifo,oq,dfo,cfo,ffo,wg,Ume,mfo,gfo,rq,hfo,ufo,pfo,Ag,Hme,_fo,vfo,tq,bfo,Ffo,Tfo,Lg,Jme,Mfo,Efo,aq,Cfo,wfo,Afo,yg,Yme,Lfo,yfo,nq,xfo,$fo,kfo,xg,Zme,Sfo,Rfo,sq,Pfo,Bfo,Ifo,$g,Kme,Nfo,qfo,lq,jfo,Dfo,Gfo,kg,ege,Ofo,Vfo,iq,Xfo,zfo,Qfo,Sg,oge,Wfo,Ufo,dq,Hfo,Jfo,Yfo,Rg,rge,Zfo,Kfo,cq,emo,omo,rmo,Pg,tge,tmo,amo,fq,nmo,smo,lmo,Bg,age,imo,dmo,mq,cmo,fmo,mmo,Ig,nge,gmo,hmo,gq,umo,pmo,_mo,Ng,sge,vmo,bmo,hq,Fmo,Tmo,Mmo,qg,lge,Emo,Cmo,uq,wmo,Amo,Lmo,jg,ige,ymo,xmo,pq,$mo,kmo,Smo,Dg,dge,Rmo,Pmo,_q,Bmo,Imo,Nmo,Gg,cge,qmo,jmo,vq,Dmo,Gmo,Omo,Og,fge,Vmo,Xmo,bq,zmo,Qmo,Wmo,Vg,mge,Umo,Hmo,Fq,Jmo,Ymo,Zmo,Xg,gge,Kmo,ego,Tq,ogo,rgo,tgo,zg,hge,ago,ngo,Mq,sgo,lgo,igo,Qg,uge,dgo,cgo,Eq,fgo,mgo,ggo,Wg,pge,hgo,ugo,Cq,pgo,_go,vgo,Ug,_ge,bgo,Fgo,wq,Tgo,Mgo,Ego,Hg,vge,Cgo,wgo,Aq,Ago,Lgo,ygo,Jg,bge,xgo,$go,Lq,kgo,Sgo,Rgo,Yg,Fge,Pgo,Bgo,yq,Igo,Ngo,qgo,Zg,Tge,jgo,Dgo,xq,Ggo,Ogo,Vgo,Kg,Mge,Xgo,zgo,$q,Qgo,Wgo,Ugo,eh,Ege,Hgo,Jgo,kq,Ygo,Zgo,Kgo,oh,Cge,eho,oho,Sq,rho,tho,aho,rh,wge,nho,sho,Rq,lho,iho,dho,th,Age,cho,fho,Pq,mho,gho,hho,ah,Lge,uho,pho,Bq,_ho,vho,bho,nh,yge,Fho,Tho,Iq,Mho,Eho,Cho,sh,xge,who,Aho,Nq,Lho,yho,xho,lh,$ge,$ho,kho,qq,Sho,Rho,Pho,ih,kge,Bho,Iho,jq,Nho,qho,jho,dh,Sge,Dho,Gho,Dq,Oho,Vho,Xho,ch,Rge,zho,Qho,Gq,Who,Uho,Hho,fh,Pge,Jho,Yho,Oq,Zho,Kho,euo,mh,Bge,ouo,ruo,Vq,tuo,auo,nuo,gh,Ige,suo,luo,Xq,iuo,duo,cuo,hh,Nge,fuo,muo,zq,guo,huo,uuo,uh,qge,puo,_uo,Qq,vuo,buo,Fuo,ph,jge,Tuo,Muo,Wq,Euo,Cuo,wuo,_h,Dge,Auo,Luo,Uq,yuo,xuo,$uo,vh,Gge,kuo,Suo,Hq,Ruo,Puo,Buo,bh,Oge,Iuo,Nuo,Jq,quo,juo,Duo,Fh,Vge,Guo,Ouo,Yq,Vuo,Xuo,zuo,Th,Xge,Quo,Wuo,Zq,Uuo,Huo,Juo,Mh,zge,Yuo,Zuo,Kq,Kuo,epo,opo,Eh,Qge,rpo,tpo,ej,apo,npo,spo,Ch,Wge,lpo,ipo,oj,dpo,cpo,fpo,wh,Uge,mpo,gpo,rj,hpo,upo,ppo,Ah,Hge,_po,vpo,tj,bpo,Fpo,Tpo,Lh,Jge,Mpo,Epo,aj,Cpo,wpo,Apo,yh,Yge,Lpo,ypo,nj,xpo,$po,kpo,xh,Zge,Spo,Rpo,sj,Ppo,Bpo,Ipo,$h,Kge,Npo,qpo,lj,jpo,Dpo,Gpo,kh,ehe,Opo,Vpo,ij,Xpo,zpo,Qpo,Sh,ohe,Wpo,Upo,dj,Hpo,Jpo,Ypo,Rh,rhe,Zpo,Kpo,cj,e_o,o_o,r_o,Ph,the,t_o,a_o,fj,n_o,s_o,l_o,Bh,ahe,i_o,d_o,mj,c_o,f_o,m_o,Ih,nhe,g_o,h_o,gj,u_o,p_o,__o,Nh,she,v_o,b_o,hj,F_o,T_o,M_o,qh,lhe,E_o,C_o,uj,w_o,A_o,L_o,jh,ihe,y_o,x_o,pj,$_o,k_o,S_o,Dh,dhe,R_o,P_o,_j,B_o,I_o,N_o,Gh,che,q_o,j_o,vj,D_o,G_o,O_o,Oh,fhe,V_o,X_o,bj,z_o,Q_o,W_o,Vh,mhe,U_o,H_o,Fj,J_o,Y_o,Z_o,Xh,ghe,K_o,e4o,Tj,o4o,r4o,t4o,zh,hhe,a4o,n4o,Mj,s4o,l4o,i4o,Qh,uhe,d4o,c4o,Ej,f4o,m4o,g4o,Wh,phe,h4o,u4o,Cj,p4o,_4o,v4o,Uh,_he,b4o,F4o,wj,T4o,M4o,E4o,Hh,vhe,C4o,w4o,Aj,A4o,L4o,y4o,Jh,bhe,x4o,$4o,Lj,k4o,S4o,R4o,Yh,Fhe,P4o,B4o,yj,I4o,N4o,q4o,Zh,The,j4o,D4o,xj,G4o,O4o,V4o,Kh,Mhe,X4o,z4o,$j,Q4o,W4o,U4o,eu,Ehe,H4o,J4o,kj,Y4o,Z4o,K4o,ou,Che,e2o,o2o,Sj,r2o,t2o,a2o,ru,whe,n2o,s2o,Rj,l2o,i2o,d2o,tu,Ahe,c2o,f2o,Pj,m2o,g2o,h2o,au,Lhe,u2o,p2o,Bj,_2o,v2o,b2o,nu,yhe,F2o,T2o,Ij,M2o,E2o,C2o,su,xhe,w2o,A2o,Nj,L2o,y2o,x2o,lu,$he,$2o,k2o,qj,S2o,R2o,P2o,iu,khe,B2o,I2o,jj,N2o,q2o,j2o,du,She,D2o,G2o,Dj,O2o,V2o,X2o,cu,Rhe,z2o,Q2o,Gj,W2o,U2o,H2o,fu,Phe,J2o,Y2o,Oj,Z2o,K2o,evo,mu,Bhe,ovo,rvo,Vj,tvo,avo,nvo,gu,Ihe,svo,lvo,Xj,ivo,dvo,cvo,hu,Nhe,fvo,mvo,zj,gvo,hvo,uvo,uu,qhe,pvo,_vo,Qj,vvo,bvo,Fvo,pu,jhe,Tvo,Mvo,Wj,Evo,Cvo,wvo,_u,Dhe,Avo,Lvo,Uj,yvo,xvo,$vo,vu,Ghe,kvo,Svo,Hj,Rvo,Pvo,Bvo,bu,Ohe,Ivo,Nvo,Jj,qvo,jvo,Dvo,Fu,Vhe,Gvo,Ovo,Yj,Vvo,Xvo,zvo,Tu,Xhe,Qvo,Wvo,Zj,Uvo,Hvo,Jvo,Mu,zhe,Yvo,Zvo,Kj,Kvo,e1o,o1o,Eu,Qhe,r1o,t1o,eD,a1o,n1o,s1o,Cu,Whe,l1o,i1o,oD,d1o,c1o,f1o,wu,m1o,Au,p$,g1o,Uhe,h1o,Sto,yd,Lu,Hhe,_$,u1o,Jhe,p1o,Rto,Ro,v$,_1o,b$,v1o,rD,b1o,F1o,T1o,F$,M1o,Yhe,E1o,C1o,w1o,jr,T$,A1o,Zhe,L1o,y1o,tn,x1o,Khe,$1o,k1o,eue,S1o,R1o,oue,P1o,B1o,I1o,k,us,rue,N1o,q1o,tD,j1o,D1o,aD,G1o,O1o,V1o,ps,tue,X1o,z1o,nD,Q1o,W1o,sD,U1o,H1o,J1o,_s,aue,Y1o,Z1o,lD,K1o,ebo,iD,obo,rbo,tbo,yu,nue,abo,nbo,dD,sbo,lbo,ibo,vs,sue,dbo,cbo,cD,fbo,mbo,fD,gbo,hbo,ubo,xu,lue,pbo,_bo,mD,vbo,bbo,Fbo,$u,iue,Tbo,Mbo,gD,Ebo,Cbo,wbo,ku,due,Abo,Lbo,hD,ybo,xbo,$bo,bs,cue,kbo,Sbo,uD,Rbo,Pbo,pD,Bbo,Ibo,Nbo,Fs,fue,qbo,jbo,_D,Dbo,Gbo,vD,Obo,Vbo,Xbo,Ts,mue,zbo,Qbo,bD,Wbo,Ubo,FD,Hbo,Jbo,Ybo,Su,gue,Zbo,Kbo,TD,e0o,o0o,r0o,Ru,hue,t0o,a0o,MD,n0o,s0o,l0o,Pu,uue,i0o,d0o,ED,c0o,f0o,m0o,Ms,pue,g0o,h0o,CD,u0o,p0o,wD,_0o,v0o,b0o,Bu,_ue,F0o,T0o,AD,M0o,E0o,C0o,Es,vue,w0o,A0o,LD,L0o,y0o,yD,x0o,$0o,k0o,Cs,bue,S0o,R0o,xD,P0o,B0o,$D,I0o,N0o,q0o,ws,Fue,j0o,D0o,kD,G0o,O0o,SD,V0o,X0o,z0o,As,Tue,Q0o,W0o,RD,U0o,H0o,PD,J0o,Y0o,Z0o,Iu,Mue,K0o,eFo,BD,oFo,rFo,tFo,Ls,Eue,aFo,nFo,ID,sFo,lFo,ND,iFo,dFo,cFo,ys,Cue,fFo,mFo,qD,gFo,hFo,jD,uFo,pFo,_Fo,xs,wue,vFo,bFo,DD,FFo,TFo,GD,MFo,EFo,CFo,$s,Aue,wFo,AFo,OD,LFo,yFo,VD,xFo,$Fo,kFo,ks,Lue,SFo,RFo,XD,PFo,BFo,zD,IFo,NFo,qFo,Ss,yue,jFo,DFo,QD,GFo,OFo,WD,VFo,XFo,zFo,Rs,xue,QFo,WFo,UD,UFo,HFo,HD,JFo,YFo,ZFo,Nu,$ue,KFo,eTo,JD,oTo,rTo,tTo,qu,kue,aTo,nTo,YD,sTo,lTo,iTo,Ps,Sue,dTo,cTo,ZD,fTo,mTo,KD,gTo,hTo,uTo,ju,Rue,pTo,_To,eG,vTo,bTo,FTo,Bs,Pue,TTo,MTo,oG,ETo,CTo,rG,wTo,ATo,LTo,Is,Bue,yTo,xTo,tG,$To,kTo,aG,STo,RTo,PTo,Ns,Iue,BTo,ITo,nG,NTo,qTo,sG,jTo,DTo,GTo,Du,Nue,OTo,VTo,lG,XTo,zTo,QTo,Gu,que,WTo,UTo,iG,HTo,JTo,YTo,qs,jue,ZTo,KTo,dG,eMo,oMo,cG,rMo,tMo,aMo,js,Due,nMo,sMo,fG,lMo,iMo,mG,dMo,cMo,fMo,Ds,Gue,mMo,gMo,gG,hMo,uMo,hG,pMo,_Mo,vMo,Ou,Oue,bMo,FMo,uG,TMo,MMo,EMo,Gs,Vue,CMo,wMo,pG,AMo,LMo,_G,yMo,xMo,$Mo,Os,Xue,kMo,SMo,vG,RMo,PMo,bG,BMo,IMo,NMo,Vs,zue,qMo,jMo,FG,DMo,GMo,TG,OMo,VMo,XMo,Xs,Que,zMo,QMo,MG,WMo,UMo,EG,HMo,JMo,YMo,zs,Wue,ZMo,KMo,CG,eEo,oEo,wG,rEo,tEo,aEo,Qs,Uue,nEo,sEo,AG,lEo,iEo,LG,dEo,cEo,fEo,Ws,Hue,mEo,gEo,yG,hEo,uEo,xG,pEo,_Eo,vEo,Us,Jue,bEo,FEo,$G,TEo,MEo,kG,EEo,CEo,wEo,Hs,Yue,AEo,LEo,SG,yEo,xEo,RG,$Eo,kEo,SEo,Vu,Zue,REo,PEo,PG,BEo,IEo,NEo,Js,Kue,qEo,jEo,BG,DEo,GEo,IG,OEo,VEo,XEo,Xu,epe,zEo,QEo,NG,WEo,UEo,HEo,zu,ope,JEo,YEo,qG,ZEo,KEo,eCo,Ys,rpe,oCo,rCo,jG,tCo,aCo,DG,nCo,sCo,lCo,Zs,tpe,iCo,dCo,GG,cCo,fCo,OG,mCo,gCo,hCo,Ks,ape,uCo,pCo,VG,_Co,vCo,XG,bCo,FCo,TCo,Qu,npe,MCo,ECo,zG,CCo,wCo,ACo,el,spe,LCo,yCo,QG,xCo,$Co,WG,kCo,SCo,RCo,ol,lpe,PCo,BCo,UG,ICo,NCo,HG,qCo,jCo,DCo,rl,ipe,GCo,OCo,JG,VCo,XCo,YG,zCo,QCo,WCo,tl,dpe,UCo,HCo,ZG,JCo,YCo,KG,ZCo,KCo,e3o,al,cpe,o3o,r3o,eO,t3o,a3o,oO,n3o,s3o,l3o,nl,fpe,i3o,d3o,rO,c3o,f3o,tO,m3o,g3o,h3o,sl,mpe,u3o,p3o,aO,_3o,v3o,nO,b3o,F3o,T3o,ll,gpe,M3o,E3o,sO,C3o,w3o,lO,A3o,L3o,y3o,Wu,hpe,x3o,$3o,iO,k3o,S3o,R3o,il,upe,P3o,B3o,dO,I3o,N3o,cO,q3o,j3o,D3o,dl,ppe,G3o,O3o,fO,V3o,X3o,mO,z3o,Q3o,W3o,cl,_pe,U3o,H3o,gO,J3o,Y3o,hO,Z3o,K3o,e5o,Uu,vpe,o5o,r5o,uO,t5o,a5o,n5o,Hu,bpe,s5o,l5o,pO,i5o,d5o,c5o,Ju,Fpe,f5o,m5o,_O,g5o,h5o,u5o,Yu,Tpe,p5o,_5o,vO,v5o,b5o,F5o,fl,Mpe,T5o,M5o,bO,E5o,C5o,FO,w5o,A5o,L5o,Zu,Epe,y5o,x5o,TO,$5o,k5o,S5o,ml,Cpe,R5o,P5o,MO,B5o,I5o,EO,N5o,q5o,j5o,gl,wpe,D5o,G5o,CO,O5o,V5o,wO,X5o,z5o,Q5o,hl,Ape,W5o,U5o,AO,H5o,J5o,LO,Y5o,Z5o,K5o,ul,Lpe,ewo,owo,yO,rwo,two,xO,awo,nwo,swo,pl,ype,lwo,iwo,$O,dwo,cwo,kO,fwo,mwo,gwo,_l,xpe,hwo,uwo,SO,pwo,_wo,RO,vwo,bwo,Fwo,Ku,$pe,Two,Mwo,PO,Ewo,Cwo,wwo,ep,kpe,Awo,Lwo,BO,ywo,xwo,$wo,vl,Spe,kwo,Swo,IO,Rwo,Pwo,NO,Bwo,Iwo,Nwo,bl,Rpe,qwo,jwo,qO,Dwo,Gwo,jO,Owo,Vwo,Xwo,Fl,Ppe,zwo,Qwo,DO,Wwo,Uwo,GO,Hwo,Jwo,Ywo,op,Bpe,Zwo,Kwo,OO,eAo,oAo,rAo,rp,Ipe,tAo,aAo,VO,nAo,sAo,lAo,tp,Npe,iAo,dAo,XO,cAo,fAo,mAo,Tl,qpe,gAo,hAo,zO,uAo,pAo,QO,_Ao,vAo,bAo,Ml,jpe,FAo,TAo,WO,MAo,EAo,UO,CAo,wAo,AAo,ap,Dpe,LAo,yAo,HO,xAo,$Ao,kAo,np,Gpe,SAo,RAo,JO,PAo,BAo,IAo,sp,Ope,NAo,qAo,YO,jAo,DAo,GAo,lp,Vpe,OAo,VAo,ZO,XAo,zAo,QAo,El,Xpe,WAo,UAo,KO,HAo,JAo,eV,YAo,ZAo,KAo,Cl,zpe,e6o,o6o,oV,r6o,t6o,rV,a6o,n6o,s6o,ip,Qpe,l6o,i6o,tV,d6o,c6o,f6o,dp,Wpe,m6o,g6o,aV,h6o,u6o,p6o,wl,Upe,_6o,v6o,nV,b6o,F6o,sV,T6o,M6o,E6o,Al,Hpe,C6o,w6o,lV,A6o,L6o,iV,y6o,x6o,$6o,Ll,Jpe,k6o,S6o,dV,R6o,P6o,cV,B6o,I6o,N6o,yl,Ype,q6o,j6o,fV,D6o,G6o,mV,O6o,V6o,X6o,cp,z6o,fp,M$,Q6o,Zpe,W6o,Pto,xd,mp,Kpe,E$,U6o,e_e,H6o,Bto,Po,C$,J6o,w$,Y6o,gV,Z6o,K6o,e7o,A$,o7o,o_e,r7o,t7o,a7o,Ye,L$,n7o,r_e,s7o,l7o,an,i7o,t_e,d7o,c7o,a_e,f7o,m7o,n_e,g7o,h7o,u7o,z,gp,s_e,p7o,_7o,hV,v7o,b7o,F7o,hp,l_e,T7o,M7o,uV,E7o,C7o,w7o,up,i_e,A7o,L7o,pV,y7o,x7o,$7o,pp,d_e,k7o,S7o,_V,R7o,P7o,B7o,_p,c_e,I7o,N7o,vV,q7o,j7o,D7o,vp,f_e,G7o,O7o,bV,V7o,X7o,z7o,bp,m_e,Q7o,W7o,FV,U7o,H7o,J7o,Fp,g_e,Y7o,Z7o,TV,K7o,e8o,o8o,Tp,h_e,r8o,t8o,MV,a8o,n8o,s8o,Mp,u_e,l8o,i8o,EV,d8o,c8o,f8o,Ep,p_e,m8o,g8o,CV,h8o,u8o,p8o,Cp,__e,_8o,v8o,wV,b8o,F8o,T8o,wp,v_e,M8o,E8o,AV,C8o,w8o,A8o,Ap,b_e,L8o,y8o,LV,x8o,$8o,k8o,Lp,F_e,S8o,R8o,yV,P8o,B8o,I8o,yp,T_e,N8o,q8o,xV,j8o,D8o,G8o,xp,M_e,O8o,V8o,$V,X8o,z8o,Q8o,$p,E_e,W8o,U8o,kV,H8o,J8o,Y8o,kp,C_e,Z8o,K8o,SV,eLo,oLo,rLo,Sp,w_e,tLo,aLo,RV,nLo,sLo,lLo,Rp,A_e,iLo,dLo,PV,cLo,fLo,mLo,Pp,L_e,gLo,hLo,BV,uLo,pLo,_Lo,Bp,y_e,vLo,bLo,IV,FLo,TLo,MLo,Ip,x_e,ELo,CLo,NV,wLo,ALo,LLo,Np,$_e,yLo,xLo,qV,$Lo,kLo,SLo,qp,k_e,RLo,PLo,jV,BLo,ILo,NLo,jp,S_e,qLo,jLo,DV,DLo,GLo,OLo,Dp,R_e,VLo,XLo,GV,zLo,QLo,WLo,Gp,P_e,ULo,HLo,OV,JLo,YLo,ZLo,Op,B_e,KLo,eyo,VV,oyo,ryo,tyo,Vp,I_e,ayo,nyo,XV,syo,lyo,iyo,Xp,N_e,dyo,cyo,zV,fyo,myo,gyo,zp,q_e,hyo,uyo,QV,pyo,_yo,vyo,Qp,j_e,byo,Fyo,WV,Tyo,Myo,Eyo,Wp,D_e,Cyo,wyo,UV,Ayo,Lyo,yyo,Up,G_e,xyo,$yo,HV,kyo,Syo,Ryo,Hp,O_e,Pyo,Byo,JV,Iyo,Nyo,qyo,Jp,V_e,jyo,Dyo,YV,Gyo,Oyo,Vyo,Yp,X_e,Xyo,zyo,ZV,Qyo,Wyo,Uyo,Zp,z_e,Hyo,Jyo,KV,Yyo,Zyo,Kyo,Kp,Q_e,e9o,o9o,eX,r9o,t9o,a9o,e_,W_e,n9o,s9o,oX,l9o,i9o,d9o,o_,U_e,c9o,f9o,rX,m9o,g9o,h9o,r_,H_e,u9o,p9o,tX,_9o,v9o,b9o,t_,F9o,a_,T9o,n_,y$,M9o,J_e,E9o,Ito,$d,s_,Y_e,x$,C9o,Z_e,w9o,Nto,Bo,$$,A9o,k$,L9o,aX,y9o,x9o,$9o,S$,k9o,K_e,S9o,R9o,P9o,Ze,R$,B9o,e4e,I9o,N9o,kd,q9o,o4e,j9o,D9o,r4e,G9o,O9o,V9o,le,l_,t4e,X9o,z9o,nX,Q9o,W9o,U9o,i_,a4e,H9o,J9o,sX,Y9o,Z9o,K9o,d_,n4e,exo,oxo,lX,rxo,txo,axo,c_,s4e,nxo,sxo,iX,lxo,ixo,dxo,f_,l4e,cxo,fxo,dX,mxo,gxo,hxo,m_,i4e,uxo,pxo,cX,_xo,vxo,bxo,g_,d4e,Fxo,Txo,fX,Mxo,Exo,Cxo,h_,c4e,wxo,Axo,mX,Lxo,yxo,xxo,u_,f4e,$xo,kxo,gX,Sxo,Rxo,Pxo,p_,m4e,Bxo,Ixo,hX,Nxo,qxo,jxo,__,g4e,Dxo,Gxo,uX,Oxo,Vxo,Xxo,v_,h4e,zxo,Qxo,pX,Wxo,Uxo,Hxo,b_,u4e,Jxo,Yxo,_X,Zxo,Kxo,e$o,F_,p4e,o$o,r$o,vX,t$o,a$o,n$o,T_,_4e,s$o,l$o,bX,i$o,d$o,c$o,M_,v4e,f$o,m$o,FX,g$o,h$o,u$o,E_,b4e,p$o,_$o,TX,v$o,b$o,F$o,C_,F4e,T$o,M$o,MX,E$o,C$o,w$o,w_,T4e,A$o,L$o,EX,y$o,x$o,$$o,A_,M4e,k$o,S$o,CX,R$o,P$o,B$o,L_,E4e,I$o,N$o,wX,q$o,j$o,D$o,y_,C4e,G$o,O$o,AX,V$o,X$o,z$o,x_,Q$o,$_,W$o,k_,P$,U$o,w4e,H$o,qto,Sd,S_,A4e,B$,J$o,L4e,Y$o,jto,Io,I$,Z$o,Rd,K$o,LX,eko,oko,yX,rko,tko,ako,N$,nko,y4e,sko,lko,iko,Mt,q$,dko,x4e,cko,fko,Pd,mko,$4e,gko,hko,xX,uko,pko,_ko,R_,vko,Ke,j$,bko,k4e,Fko,Tko,nn,Mko,S4e,Eko,Cko,R4e,wko,Ako,P4e,Lko,yko,xko,y,P_,B4e,$ko,kko,$X,Sko,Rko,Pko,B_,I4e,Bko,Iko,kX,Nko,qko,jko,I_,N4e,Dko,Gko,SX,Oko,Vko,Xko,N_,q4e,zko,Qko,RX,Wko,Uko,Hko,q_,j4e,Jko,Yko,PX,Zko,Kko,eSo,j_,D4e,oSo,rSo,BX,tSo,aSo,nSo,D_,G4e,sSo,lSo,IX,iSo,dSo,cSo,G_,O4e,fSo,mSo,NX,gSo,hSo,uSo,O_,V4e,pSo,_So,qX,vSo,bSo,FSo,V_,X4e,TSo,MSo,jX,ESo,CSo,wSo,X_,z4e,ASo,LSo,DX,ySo,xSo,$So,z_,Q4e,kSo,SSo,GX,RSo,PSo,BSo,Q_,W4e,ISo,NSo,OX,qSo,jSo,DSo,W_,U4e,GSo,OSo,VX,VSo,XSo,zSo,U_,H4e,QSo,WSo,XX,USo,HSo,JSo,H_,J4e,YSo,ZSo,zX,KSo,eRo,oRo,J_,Y4e,rRo,tRo,QX,aRo,nRo,sRo,Y_,Z4e,lRo,iRo,WX,dRo,cRo,fRo,Z_,K4e,mRo,gRo,UX,hRo,uRo,pRo,K_,e2e,_Ro,vRo,HX,bRo,FRo,TRo,e4,o2e,MRo,ERo,JX,CRo,wRo,ARo,o4,r2e,LRo,yRo,YX,xRo,$Ro,kRo,r4,t2e,SRo,RRo,ZX,PRo,BRo,IRo,t4,a2e,NRo,qRo,KX,jRo,DRo,GRo,a4,n2e,ORo,VRo,ez,XRo,zRo,QRo,n4,s2e,WRo,URo,oz,HRo,JRo,YRo,s4,l2e,ZRo,KRo,rz,ePo,oPo,rPo,l4,i2e,tPo,aPo,tz,nPo,sPo,lPo,i4,d2e,iPo,dPo,az,cPo,fPo,mPo,d4,c2e,gPo,hPo,nz,uPo,pPo,_Po,c4,f2e,vPo,bPo,sz,FPo,TPo,MPo,f4,m2e,EPo,CPo,lz,wPo,APo,LPo,m4,g2e,yPo,xPo,iz,$Po,kPo,SPo,g4,h2e,RPo,PPo,dz,BPo,IPo,NPo,h4,u2e,qPo,jPo,cz,DPo,GPo,OPo,u4,p2e,VPo,XPo,fz,zPo,QPo,WPo,p4,_2e,UPo,HPo,mz,JPo,YPo,ZPo,_4,v2e,KPo,eBo,gz,oBo,rBo,tBo,v4,b2e,aBo,nBo,hz,sBo,lBo,iBo,xl,F2e,dBo,cBo,uz,fBo,mBo,pz,gBo,hBo,uBo,b4,T2e,pBo,_Bo,_z,vBo,bBo,FBo,F4,M2e,TBo,MBo,vz,EBo,CBo,wBo,T4,E2e,ABo,LBo,bz,yBo,xBo,$Bo,M4,C2e,kBo,SBo,Fz,RBo,PBo,BBo,E4,w2e,IBo,NBo,Tz,qBo,jBo,DBo,C4,A2e,GBo,OBo,Mz,VBo,XBo,zBo,w4,L2e,QBo,WBo,Ez,UBo,HBo,JBo,A4,y2e,YBo,ZBo,Cz,KBo,eIo,oIo,L4,x2e,rIo,tIo,wz,aIo,nIo,sIo,y4,$2e,lIo,iIo,Az,dIo,cIo,fIo,x4,k2e,mIo,gIo,Lz,hIo,uIo,pIo,$4,S2e,_Io,vIo,yz,bIo,FIo,TIo,k4,R2e,MIo,EIo,xz,CIo,wIo,AIo,S4,P2e,LIo,yIo,$z,xIo,$Io,kIo,R4,B2e,SIo,RIo,kz,PIo,BIo,IIo,P4,I2e,NIo,qIo,Sz,jIo,DIo,GIo,B4,N2e,OIo,VIo,Rz,XIo,zIo,QIo,I4,q2e,WIo,UIo,Pz,HIo,JIo,YIo,N4,j2e,ZIo,KIo,Bz,eNo,oNo,rNo,q4,D2e,tNo,aNo,Iz,nNo,sNo,lNo,j4,G2e,iNo,dNo,Nz,cNo,fNo,mNo,D4,O2e,gNo,hNo,qz,uNo,pNo,_No,G4,V2e,vNo,bNo,jz,FNo,TNo,MNo,O4,X2e,ENo,CNo,Dz,wNo,ANo,LNo,V4,z2e,yNo,xNo,Gz,$No,kNo,SNo,X4,Q2e,RNo,PNo,Oz,BNo,INo,NNo,z4,W2e,qNo,jNo,Vz,DNo,GNo,ONo,Q4,U2e,VNo,XNo,Xz,zNo,QNo,WNo,W4,H2e,UNo,HNo,zz,JNo,YNo,ZNo,U4,J2e,KNo,eqo,Qz,oqo,rqo,tqo,H4,Y2e,aqo,nqo,Wz,sqo,lqo,iqo,J4,Z2e,dqo,cqo,Uz,fqo,mqo,gqo,Y4,K2e,hqo,uqo,Hz,pqo,_qo,vqo,Z4,eve,bqo,Fqo,Jz,Tqo,Mqo,Eqo,K4,ove,Cqo,wqo,Yz,Aqo,Lqo,yqo,e2,rve,xqo,$qo,Zz,kqo,Sqo,Rqo,o2,tve,Pqo,Bqo,Kz,Iqo,Nqo,qqo,r2,ave,jqo,Dqo,eQ,Gqo,Oqo,Vqo,t2,nve,Xqo,zqo,oQ,Qqo,Wqo,Uqo,a2,sve,Hqo,Jqo,rQ,Yqo,Zqo,Kqo,n2,lve,ejo,ojo,tQ,rjo,tjo,ajo,s2,ive,njo,sjo,aQ,ljo,ijo,djo,l2,dve,cjo,fjo,nQ,mjo,gjo,hjo,i2,cve,ujo,pjo,sQ,_jo,vjo,bjo,d2,fve,Fjo,Tjo,lQ,Mjo,Ejo,Cjo,c2,mve,wjo,Ajo,iQ,Ljo,yjo,xjo,f2,gve,$jo,kjo,dQ,Sjo,Rjo,Pjo,m2,hve,Bjo,Ijo,cQ,Njo,qjo,jjo,g2,uve,Djo,Gjo,fQ,Ojo,Vjo,Xjo,h2,pve,zjo,Qjo,mQ,Wjo,Ujo,Hjo,u2,_ve,Jjo,Yjo,gQ,Zjo,Kjo,eDo,p2,vve,oDo,rDo,hQ,tDo,aDo,nDo,_2,bve,sDo,lDo,uQ,iDo,dDo,cDo,v2,Fve,fDo,mDo,pQ,gDo,hDo,uDo,b2,Tve,pDo,_Do,_Q,vDo,bDo,FDo,F2,Mve,TDo,MDo,vQ,EDo,CDo,wDo,T2,Eve,ADo,LDo,bQ,yDo,xDo,$Do,M2,Cve,kDo,SDo,FQ,RDo,PDo,BDo,E2,wve,IDo,NDo,TQ,qDo,jDo,DDo,C2,Ave,GDo,ODo,MQ,VDo,XDo,zDo,w2,Lve,QDo,WDo,EQ,UDo,HDo,JDo,A2,yve,YDo,ZDo,CQ,KDo,eGo,oGo,L2,xve,rGo,tGo,wQ,aGo,nGo,sGo,y2,$ve,lGo,iGo,AQ,dGo,cGo,fGo,x2,kve,mGo,gGo,LQ,hGo,uGo,pGo,$2,Sve,_Go,vGo,yQ,bGo,FGo,TGo,k2,Rve,MGo,EGo,xQ,CGo,wGo,AGo,S2,Pve,LGo,yGo,$Q,xGo,$Go,kGo,R2,Bve,SGo,RGo,kQ,PGo,BGo,IGo,P2,Ive,NGo,qGo,SQ,jGo,DGo,GGo,B2,Nve,OGo,VGo,RQ,XGo,zGo,QGo,I2,qve,WGo,UGo,PQ,HGo,JGo,YGo,N2,jve,ZGo,KGo,BQ,eOo,oOo,rOo,q2,Dve,tOo,aOo,IQ,nOo,sOo,lOo,j2,Gve,iOo,dOo,NQ,cOo,fOo,mOo,D2,Ove,gOo,hOo,qQ,uOo,pOo,_Oo,G2,Vve,vOo,bOo,jQ,FOo,TOo,MOo,O2,Xve,EOo,COo,DQ,wOo,AOo,LOo,V2,zve,yOo,xOo,GQ,$Oo,kOo,SOo,X2,Qve,ROo,POo,OQ,BOo,IOo,NOo,z2,Wve,qOo,jOo,VQ,DOo,GOo,OOo,Q2,Uve,VOo,XOo,XQ,zOo,QOo,WOo,W2,Hve,UOo,HOo,zQ,JOo,YOo,ZOo,U2,Jve,KOo,eVo,QQ,oVo,rVo,tVo,H2,Yve,aVo,nVo,WQ,sVo,lVo,iVo,J2,Zve,dVo,cVo,UQ,fVo,mVo,gVo,Y2,Kve,hVo,uVo,HQ,pVo,_Vo,vVo,Z2,e1e,bVo,FVo,JQ,TVo,MVo,EVo,K2,o1e,CVo,wVo,YQ,AVo,LVo,yVo,ev,xVo,r1e,$Vo,kVo,t1e,SVo,RVo,ov,Dto,Bd,rv,a1e,D$,PVo,n1e,BVo,Gto,No,G$,IVo,Id,NVo,ZQ,qVo,jVo,KQ,DVo,GVo,OVo,O$,VVo,s1e,XVo,zVo,QVo,Et,V$,WVo,l1e,UVo,HVo,Nd,JVo,i1e,YVo,ZVo,eW,KVo,eXo,oXo,tv,rXo,eo,X$,tXo,d1e,aXo,nXo,sn,sXo,c1e,lXo,iXo,f1e,dXo,cXo,m1e,fXo,mXo,gXo,G,av,g1e,hXo,uXo,oW,pXo,_Xo,vXo,nv,h1e,bXo,FXo,rW,TXo,MXo,EXo,sv,u1e,CXo,wXo,tW,AXo,LXo,yXo,lv,p1e,xXo,$Xo,aW,kXo,SXo,RXo,iv,_1e,PXo,BXo,nW,IXo,NXo,qXo,dv,v1e,jXo,DXo,sW,GXo,OXo,VXo,cv,b1e,XXo,zXo,lW,QXo,WXo,UXo,fv,F1e,HXo,JXo,iW,YXo,ZXo,KXo,mv,T1e,ezo,ozo,dW,rzo,tzo,azo,gv,M1e,nzo,szo,cW,lzo,izo,dzo,hv,E1e,czo,fzo,fW,mzo,gzo,hzo,uv,C1e,uzo,pzo,mW,_zo,vzo,bzo,pv,w1e,Fzo,Tzo,gW,Mzo,Ezo,Czo,_v,A1e,wzo,Azo,hW,Lzo,yzo,xzo,vv,L1e,$zo,kzo,uW,Szo,Rzo,Pzo,bv,y1e,Bzo,Izo,pW,Nzo,qzo,jzo,Fv,x1e,Dzo,Gzo,_W,Ozo,Vzo,Xzo,Tv,$1e,zzo,Qzo,vW,Wzo,Uzo,Hzo,Mv,k1e,Jzo,Yzo,bW,Zzo,Kzo,eQo,Ev,S1e,oQo,rQo,FW,tQo,aQo,nQo,Cv,R1e,sQo,lQo,TW,iQo,dQo,cQo,wv,P1e,fQo,mQo,MW,gQo,hQo,uQo,Av,B1e,pQo,_Qo,EW,vQo,bQo,FQo,Lv,I1e,TQo,MQo,CW,EQo,CQo,wQo,yv,N1e,AQo,LQo,wW,yQo,xQo,$Qo,xv,q1e,kQo,SQo,AW,RQo,PQo,BQo,$v,j1e,IQo,NQo,LW,qQo,jQo,DQo,kv,D1e,GQo,OQo,yW,VQo,XQo,zQo,Sv,G1e,QQo,WQo,xW,UQo,HQo,JQo,Rv,O1e,YQo,ZQo,$W,KQo,eWo,oWo,Pv,V1e,rWo,tWo,kW,aWo,nWo,sWo,Bv,X1e,lWo,iWo,SW,dWo,cWo,fWo,Iv,z1e,mWo,gWo,RW,hWo,uWo,pWo,Nv,Q1e,_Wo,vWo,PW,bWo,FWo,TWo,qv,W1e,MWo,EWo,BW,CWo,wWo,AWo,jv,U1e,LWo,yWo,IW,xWo,$Wo,kWo,Dv,H1e,SWo,RWo,NW,PWo,BWo,IWo,Gv,J1e,NWo,qWo,qW,jWo,DWo,GWo,Ov,Y1e,OWo,VWo,jW,XWo,zWo,QWo,Vv,Z1e,WWo,UWo,DW,HWo,JWo,YWo,Xv,K1e,ZWo,KWo,GW,eUo,oUo,rUo,zv,ebe,tUo,aUo,OW,nUo,sUo,lUo,Qv,obe,iUo,dUo,VW,cUo,fUo,mUo,Wv,rbe,gUo,hUo,XW,uUo,pUo,_Uo,Uv,tbe,vUo,bUo,zW,FUo,TUo,MUo,Hv,abe,EUo,CUo,QW,wUo,AUo,LUo,Jv,nbe,yUo,xUo,WW,$Uo,kUo,SUo,Yv,sbe,RUo,PUo,UW,BUo,IUo,NUo,Zv,qUo,lbe,jUo,DUo,ibe,GUo,OUo,Kv,Oto,qd,e1,dbe,z$,VUo,cbe,XUo,Vto,qo,Q$,zUo,jd,QUo,HW,WUo,UUo,JW,HUo,JUo,YUo,W$,ZUo,fbe,KUo,eHo,oHo,Ct,U$,rHo,mbe,tHo,aHo,Dd,nHo,gbe,sHo,lHo,YW,iHo,dHo,cHo,o1,fHo,oo,H$,mHo,hbe,gHo,hHo,ln,uHo,ube,pHo,_Ho,pbe,vHo,bHo,_be,FHo,THo,MHo,W,r1,vbe,EHo,CHo,ZW,wHo,AHo,LHo,t1,bbe,yHo,xHo,KW,$Ho,kHo,SHo,a1,Fbe,RHo,PHo,eU,BHo,IHo,NHo,n1,Tbe,qHo,jHo,oU,DHo,GHo,OHo,s1,Mbe,VHo,XHo,rU,zHo,QHo,WHo,l1,Ebe,UHo,HHo,tU,JHo,YHo,ZHo,i1,Cbe,KHo,eJo,aU,oJo,rJo,tJo,d1,wbe,aJo,nJo,nU,sJo,lJo,iJo,c1,Abe,dJo,cJo,sU,fJo,mJo,gJo,f1,Lbe,hJo,uJo,lU,pJo,_Jo,vJo,m1,ybe,bJo,FJo,iU,TJo,MJo,EJo,g1,xbe,CJo,wJo,dU,AJo,LJo,yJo,h1,$be,xJo,$Jo,cU,kJo,SJo,RJo,u1,kbe,PJo,BJo,fU,IJo,NJo,qJo,p1,Sbe,jJo,DJo,mU,GJo,OJo,VJo,_1,Rbe,XJo,zJo,gU,QJo,WJo,UJo,v1,Pbe,HJo,JJo,hU,YJo,ZJo,KJo,b1,Bbe,eYo,oYo,uU,rYo,tYo,aYo,F1,Ibe,nYo,sYo,pU,lYo,iYo,dYo,T1,Nbe,cYo,fYo,_U,mYo,gYo,hYo,M1,qbe,uYo,pYo,vU,_Yo,vYo,bYo,E1,jbe,FYo,TYo,bU,MYo,EYo,CYo,C1,Dbe,wYo,AYo,FU,LYo,yYo,xYo,w1,Gbe,$Yo,kYo,TU,SYo,RYo,PYo,A1,Obe,BYo,IYo,MU,NYo,qYo,jYo,L1,Vbe,DYo,GYo,EU,OYo,VYo,XYo,y1,Xbe,zYo,QYo,CU,WYo,UYo,HYo,x1,zbe,JYo,YYo,wU,ZYo,KYo,eZo,$1,Qbe,oZo,rZo,AU,tZo,aZo,nZo,k1,Wbe,sZo,lZo,LU,iZo,dZo,cZo,S1,Ube,fZo,mZo,yU,gZo,hZo,uZo,R1,Hbe,pZo,_Zo,xU,vZo,bZo,FZo,P1,Jbe,TZo,MZo,$U,EZo,CZo,wZo,B1,Ybe,AZo,LZo,kU,yZo,xZo,$Zo,I1,Zbe,kZo,SZo,SU,RZo,PZo,BZo,N1,Kbe,IZo,NZo,RU,qZo,jZo,DZo,q1,e0e,GZo,OZo,PU,VZo,XZo,zZo,j1,o0e,QZo,WZo,BU,UZo,HZo,JZo,D1,r0e,YZo,ZZo,IU,KZo,eKo,oKo,G1,t0e,rKo,tKo,NU,aKo,nKo,sKo,O1,a0e,lKo,iKo,qU,dKo,cKo,fKo,V1,n0e,mKo,gKo,jU,hKo,uKo,pKo,X1,_Ko,s0e,vKo,bKo,l0e,FKo,TKo,z1,Xto,Gd,Q1,i0e,J$,MKo,d0e,EKo,zto,jo,Y$,CKo,Od,wKo,DU,AKo,LKo,GU,yKo,xKo,$Ko,Z$,kKo,c0e,SKo,RKo,PKo,wt,K$,BKo,f0e,IKo,NKo,Vd,qKo,m0e,jKo,DKo,OU,GKo,OKo,VKo,W1,XKo,ro,ek,zKo,g0e,QKo,WKo,dn,UKo,h0e,HKo,JKo,u0e,YKo,ZKo,p0e,KKo,eer,oer,ok,U1,_0e,rer,ter,VU,aer,ner,ser,H1,v0e,ler,ier,XU,der,cer,fer,J1,mer,b0e,ger,her,F0e,uer,per,Y1,Qto,Xd,Z1,T0e,rk,_er,M0e,ver,Wto,Do,tk,ber,zd,Fer,zU,Ter,Mer,QU,Eer,Cer,wer,ak,Aer,E0e,Ler,yer,xer,At,nk,$er,C0e,ker,Ser,Qd,Rer,w0e,Per,Ber,WU,Ier,Ner,qer,K1,jer,to,sk,Der,A0e,Ger,Oer,cn,Ver,L0e,Xer,zer,y0e,Qer,Wer,x0e,Uer,Her,Jer,Y,eb,$0e,Yer,Zer,UU,Ker,eor,oor,ob,k0e,ror,tor,HU,aor,nor,sor,rb,S0e,lor,ior,JU,dor,cor,mor,tb,R0e,gor,hor,YU,uor,por,_or,ab,P0e,vor,bor,ZU,For,Tor,Mor,nb,B0e,Eor,Cor,KU,wor,Aor,Lor,sb,I0e,yor,xor,eH,$or,kor,Sor,lb,N0e,Ror,Por,oH,Bor,Ior,Nor,ib,q0e,qor,jor,rH,Dor,Gor,Oor,db,j0e,Vor,Xor,tH,zor,Qor,Wor,cb,D0e,Uor,Hor,aH,Jor,Yor,Zor,fb,G0e,Kor,err,nH,orr,rrr,trr,mb,O0e,arr,nrr,sH,srr,lrr,irr,gb,V0e,drr,crr,lH,frr,mrr,grr,hb,X0e,hrr,urr,iH,prr,_rr,vrr,ub,z0e,brr,Frr,dH,Trr,Mrr,Err,pb,Q0e,Crr,wrr,cH,Arr,Lrr,yrr,_b,W0e,xrr,$rr,fH,krr,Srr,Rrr,vb,U0e,Prr,Brr,mH,Irr,Nrr,qrr,bb,H0e,jrr,Drr,gH,Grr,Orr,Vrr,Fb,J0e,Xrr,zrr,hH,Qrr,Wrr,Urr,Tb,Y0e,Hrr,Jrr,uH,Yrr,Zrr,Krr,Mb,Z0e,etr,otr,pH,rtr,ttr,atr,Eb,K0e,ntr,str,_H,ltr,itr,dtr,Cb,eFe,ctr,ftr,vH,mtr,gtr,htr,wb,oFe,utr,ptr,bH,_tr,vtr,btr,Ab,rFe,Ftr,Ttr,FH,Mtr,Etr,Ctr,Lb,tFe,wtr,Atr,TH,Ltr,ytr,xtr,yb,aFe,$tr,ktr,MH,Str,Rtr,Ptr,xb,nFe,Btr,Itr,EH,Ntr,qtr,jtr,$b,sFe,Dtr,Gtr,CH,Otr,Vtr,Xtr,kb,lFe,ztr,Qtr,wH,Wtr,Utr,Htr,Sb,iFe,Jtr,Ytr,AH,Ztr,Ktr,ear,Rb,dFe,oar,rar,LH,tar,aar,nar,Pb,cFe,sar,lar,fFe,iar,dar,car,Bb,mFe,far,mar,yH,gar,har,uar,Ib,gFe,par,_ar,xH,bar,Far,Tar,Nb,hFe,Mar,Ear,$H,Car,war,Aar,qb,uFe,Lar,yar,kH,xar,$ar,kar,jb,Sar,pFe,Rar,Par,_Fe,Bar,Iar,Db,Uto,Wd,Gb,vFe,lk,Nar,bFe,qar,Hto,Go,ik,jar,Ud,Dar,SH,Gar,Oar,RH,Var,Xar,zar,dk,Qar,FFe,War,Uar,Har,Lt,ck,Jar,TFe,Yar,Zar,Hd,Kar,MFe,enr,onr,PH,rnr,tnr,anr,Ob,nnr,ao,fk,snr,EFe,lnr,inr,fn,dnr,CFe,cnr,fnr,wFe,mnr,gnr,AFe,hnr,unr,pnr,he,Vb,LFe,_nr,vnr,BH,bnr,Fnr,Tnr,Xb,yFe,Mnr,Enr,IH,Cnr,wnr,Anr,zb,xFe,Lnr,ynr,NH,xnr,$nr,knr,Qb,$Fe,Snr,Rnr,qH,Pnr,Bnr,Inr,Wb,kFe,Nnr,qnr,jH,jnr,Dnr,Gnr,Ub,SFe,Onr,Vnr,DH,Xnr,znr,Qnr,Hb,RFe,Wnr,Unr,GH,Hnr,Jnr,Ynr,Jb,PFe,Znr,Knr,OH,esr,osr,rsr,Yb,BFe,tsr,asr,VH,nsr,ssr,lsr,Zb,IFe,isr,dsr,XH,csr,fsr,msr,Kb,NFe,gsr,hsr,zH,usr,psr,_sr,e0,qFe,vsr,bsr,QH,Fsr,Tsr,Msr,o0,jFe,Esr,Csr,WH,wsr,Asr,Lsr,r0,DFe,ysr,xsr,UH,$sr,ksr,Ssr,t0,GFe,Rsr,Psr,HH,Bsr,Isr,Nsr,a0,OFe,qsr,jsr,JH,Dsr,Gsr,Osr,n0,VFe,Vsr,Xsr,YH,zsr,Qsr,Wsr,s0,XFe,Usr,Hsr,ZH,Jsr,Ysr,Zsr,l0,zFe,Ksr,elr,KH,olr,rlr,tlr,i0,QFe,alr,nlr,eJ,slr,llr,ilr,d0,dlr,WFe,clr,flr,UFe,mlr,glr,c0,Jto,Jd,f0,HFe,mk,hlr,JFe,ulr,Yto,Oo,gk,plr,Yd,_lr,oJ,vlr,blr,rJ,Flr,Tlr,Mlr,hk,Elr,YFe,Clr,wlr,Alr,yt,uk,Llr,ZFe,ylr,xlr,Zd,$lr,KFe,klr,Slr,tJ,Rlr,Plr,Blr,m0,Ilr,no,pk,Nlr,eTe,qlr,jlr,mn,Dlr,oTe,Glr,Olr,rTe,Vlr,Xlr,tTe,zlr,Qlr,Wlr,j,g0,aTe,Ulr,Hlr,aJ,Jlr,Ylr,Zlr,h0,nTe,Klr,eir,nJ,oir,rir,tir,u0,sTe,air,nir,sJ,sir,lir,iir,p0,lTe,dir,cir,lJ,fir,mir,gir,_0,iTe,hir,uir,iJ,pir,_ir,vir,v0,dTe,bir,Fir,dJ,Tir,Mir,Eir,b0,cTe,Cir,wir,cJ,Air,Lir,yir,F0,fTe,xir,$ir,fJ,kir,Sir,Rir,T0,mTe,Pir,Bir,mJ,Iir,Nir,qir,M0,gTe,jir,Dir,gJ,Gir,Oir,Vir,E0,hTe,Xir,zir,hJ,Qir,Wir,Uir,C0,uTe,Hir,Jir,uJ,Yir,Zir,Kir,w0,pTe,edr,odr,pJ,rdr,tdr,adr,A0,_Te,ndr,sdr,_J,ldr,idr,ddr,L0,vTe,cdr,fdr,vJ,mdr,gdr,hdr,y0,bTe,udr,pdr,bJ,_dr,vdr,bdr,x0,FTe,Fdr,Tdr,FJ,Mdr,Edr,Cdr,$0,TTe,wdr,Adr,TJ,Ldr,ydr,xdr,k0,MTe,$dr,kdr,MJ,Sdr,Rdr,Pdr,S0,ETe,Bdr,Idr,EJ,Ndr,qdr,jdr,R0,CTe,Ddr,Gdr,CJ,Odr,Vdr,Xdr,P0,wTe,zdr,Qdr,wJ,Wdr,Udr,Hdr,B0,ATe,Jdr,Ydr,AJ,Zdr,Kdr,ecr,I0,LTe,ocr,rcr,LJ,tcr,acr,ncr,N0,yTe,scr,lcr,yJ,icr,dcr,ccr,q0,xTe,fcr,mcr,xJ,gcr,hcr,ucr,j0,$Te,pcr,_cr,$J,vcr,bcr,Fcr,D0,kTe,Tcr,Mcr,kJ,Ecr,Ccr,wcr,G0,STe,Acr,Lcr,SJ,ycr,xcr,$cr,O0,RTe,kcr,Scr,RJ,Rcr,Pcr,Bcr,V0,PTe,Icr,Ncr,PJ,qcr,jcr,Dcr,X0,BTe,Gcr,Ocr,BJ,Vcr,Xcr,zcr,z0,ITe,Qcr,Wcr,IJ,Ucr,Hcr,Jcr,Q0,NTe,Ycr,Zcr,NJ,Kcr,efr,ofr,W0,qTe,rfr,tfr,qJ,afr,nfr,sfr,U0,jTe,lfr,ifr,jJ,dfr,cfr,ffr,H0,DTe,mfr,gfr,DJ,hfr,ufr,pfr,J0,GTe,_fr,vfr,GJ,bfr,Ffr,Tfr,Y0,OTe,Mfr,Efr,OJ,Cfr,wfr,Afr,Z0,VTe,Lfr,yfr,VJ,xfr,$fr,kfr,K0,XTe,Sfr,Rfr,XJ,Pfr,Bfr,Ifr,eF,zTe,Nfr,qfr,zJ,jfr,Dfr,Gfr,oF,QTe,Ofr,Vfr,QJ,Xfr,zfr,Qfr,rF,WTe,Wfr,Ufr,WJ,Hfr,Jfr,Yfr,tF,UTe,Zfr,Kfr,UJ,emr,omr,rmr,aF,HTe,tmr,amr,HJ,nmr,smr,lmr,nF,JTe,imr,dmr,JJ,cmr,fmr,mmr,sF,YTe,gmr,hmr,YJ,umr,pmr,_mr,lF,ZTe,vmr,bmr,ZJ,Fmr,Tmr,Mmr,iF,KTe,Emr,Cmr,KJ,wmr,Amr,Lmr,dF,eMe,ymr,xmr,eY,$mr,kmr,Smr,cF,oMe,Rmr,Pmr,oY,Bmr,Imr,Nmr,fF,rMe,qmr,jmr,rY,Dmr,Gmr,Omr,mF,tMe,Vmr,Xmr,tY,zmr,Qmr,Wmr,gF,aMe,Umr,Hmr,aY,Jmr,Ymr,Zmr,hF,nMe,Kmr,egr,nY,ogr,rgr,tgr,uF,agr,sMe,ngr,sgr,lMe,lgr,igr,pF,Zto,Kd,_F,iMe,_k,dgr,dMe,cgr,Kto,Vo,vk,fgr,ec,mgr,sY,ggr,hgr,lY,ugr,pgr,_gr,bk,vgr,cMe,bgr,Fgr,Tgr,xt,Fk,Mgr,fMe,Egr,Cgr,oc,wgr,mMe,Agr,Lgr,iY,ygr,xgr,$gr,vF,kgr,so,Tk,Sgr,gMe,Rgr,Pgr,gn,Bgr,hMe,Igr,Ngr,uMe,qgr,jgr,pMe,Dgr,Ggr,Ogr,K,bF,_Me,Vgr,Xgr,dY,zgr,Qgr,Wgr,FF,vMe,Ugr,Hgr,cY,Jgr,Ygr,Zgr,TF,bMe,Kgr,ehr,fY,ohr,rhr,thr,MF,FMe,ahr,nhr,mY,shr,lhr,ihr,EF,TMe,dhr,chr,gY,fhr,mhr,ghr,CF,MMe,hhr,uhr,hY,phr,_hr,vhr,wF,EMe,bhr,Fhr,uY,Thr,Mhr,Ehr,AF,CMe,Chr,whr,pY,Ahr,Lhr,yhr,LF,wMe,xhr,$hr,_Y,khr,Shr,Rhr,yF,AMe,Phr,Bhr,vY,Ihr,Nhr,qhr,xF,LMe,jhr,Dhr,bY,Ghr,Ohr,Vhr,$F,yMe,Xhr,zhr,FY,Qhr,Whr,Uhr,kF,xMe,Hhr,Jhr,TY,Yhr,Zhr,Khr,SF,$Me,eur,our,MY,rur,tur,aur,RF,kMe,nur,sur,EY,lur,iur,dur,PF,SMe,cur,fur,CY,mur,gur,hur,BF,RMe,uur,pur,wY,_ur,vur,bur,IF,PMe,Fur,Tur,AY,Mur,Eur,Cur,NF,BMe,wur,Aur,LY,Lur,yur,xur,qF,IMe,$ur,kur,yY,Sur,Rur,Pur,jF,NMe,Bur,Iur,xY,Nur,qur,jur,DF,qMe,Dur,Gur,$Y,Our,Vur,Xur,GF,jMe,zur,Qur,kY,Wur,Uur,Hur,OF,DMe,Jur,Yur,SY,Zur,Kur,epr,VF,GMe,opr,rpr,RY,tpr,apr,npr,XF,OMe,spr,lpr,PY,ipr,dpr,cpr,zF,VMe,fpr,mpr,BY,gpr,hpr,upr,QF,XMe,ppr,_pr,IY,vpr,bpr,Fpr,WF,zMe,Tpr,Mpr,NY,Epr,Cpr,wpr,UF,QMe,Apr,Lpr,qY,ypr,xpr,$pr,HF,WMe,kpr,Spr,jY,Rpr,Ppr,Bpr,JF,UMe,Ipr,Npr,DY,qpr,jpr,Dpr,YF,Gpr,HMe,Opr,Vpr,JMe,Xpr,zpr,ZF,eao,rc,KF,YMe,Mk,Qpr,ZMe,Wpr,oao,Xo,Ek,Upr,tc,Hpr,GY,Jpr,Ypr,OY,Zpr,Kpr,e_r,Ck,o_r,KMe,r_r,t_r,a_r,$t,wk,n_r,eEe,s_r,l_r,ac,i_r,oEe,d_r,c_r,VY,f_r,m_r,g_r,eT,h_r,lo,Ak,u_r,rEe,p_r,__r,hn,v_r,tEe,b_r,F_r,aEe,T_r,M_r,nEe,E_r,C_r,w_r,Ue,oT,sEe,A_r,L_r,XY,y_r,x_r,$_r,rT,lEe,k_r,S_r,zY,R_r,P_r,B_r,tT,iEe,I_r,N_r,QY,q_r,j_r,D_r,aT,dEe,G_r,O_r,WY,V_r,X_r,z_r,nT,cEe,Q_r,W_r,UY,U_r,H_r,J_r,sT,fEe,Y_r,Z_r,HY,K_r,e4r,o4r,lT,mEe,r4r,t4r,JY,a4r,n4r,s4r,iT,l4r,gEe,i4r,d4r,hEe,c4r,f4r,dT,rao,nc,cT,uEe,Lk,m4r,pEe,g4r,tao,zo,yk,h4r,sc,u4r,YY,p4r,_4r,ZY,v4r,b4r,F4r,xk,T4r,_Ee,M4r,E4r,C4r,kt,$k,w4r,vEe,A4r,L4r,lc,y4r,bEe,x4r,$4r,KY,k4r,S4r,R4r,fT,P4r,io,kk,B4r,FEe,I4r,N4r,un,q4r,TEe,j4r,D4r,MEe,G4r,O4r,EEe,V4r,X4r,z4r,U,mT,CEe,Q4r,W4r,eZ,U4r,H4r,J4r,gT,wEe,Y4r,Z4r,oZ,K4r,e2r,o2r,hT,AEe,r2r,t2r,rZ,a2r,n2r,s2r,uT,LEe,l2r,i2r,tZ,d2r,c2r,f2r,pT,yEe,m2r,g2r,aZ,h2r,u2r,p2r,_T,xEe,_2r,v2r,nZ,b2r,F2r,T2r,vT,$Ee,M2r,E2r,sZ,C2r,w2r,A2r,bT,kEe,L2r,y2r,lZ,x2r,$2r,k2r,FT,SEe,S2r,R2r,iZ,P2r,B2r,I2r,TT,REe,N2r,q2r,dZ,j2r,D2r,G2r,MT,PEe,O2r,V2r,cZ,X2r,z2r,Q2r,ET,BEe,W2r,U2r,fZ,H2r,J2r,Y2r,CT,IEe,Z2r,K2r,mZ,evr,ovr,rvr,wT,NEe,tvr,avr,gZ,nvr,svr,lvr,AT,qEe,ivr,dvr,hZ,cvr,fvr,mvr,LT,jEe,gvr,hvr,uZ,uvr,pvr,_vr,yT,DEe,vvr,bvr,pZ,Fvr,Tvr,Mvr,xT,GEe,Evr,Cvr,_Z,wvr,Avr,Lvr,$T,OEe,yvr,xvr,vZ,$vr,kvr,Svr,kT,VEe,Rvr,Pvr,bZ,Bvr,Ivr,Nvr,ST,XEe,qvr,jvr,FZ,Dvr,Gvr,Ovr,RT,zEe,Vvr,Xvr,TZ,zvr,Qvr,Wvr,PT,QEe,Uvr,Hvr,MZ,Jvr,Yvr,Zvr,BT,WEe,Kvr,e1r,EZ,o1r,r1r,t1r,IT,UEe,a1r,n1r,CZ,s1r,l1r,i1r,NT,HEe,d1r,c1r,wZ,f1r,m1r,g1r,qT,JEe,h1r,u1r,AZ,p1r,_1r,v1r,jT,YEe,b1r,F1r,LZ,T1r,M1r,E1r,DT,ZEe,C1r,w1r,yZ,A1r,L1r,y1r,GT,KEe,x1r,$1r,xZ,k1r,S1r,R1r,OT,eCe,P1r,B1r,$Z,I1r,N1r,q1r,VT,oCe,j1r,D1r,kZ,G1r,O1r,V1r,XT,rCe,X1r,z1r,SZ,Q1r,W1r,U1r,zT,tCe,H1r,J1r,RZ,Y1r,Z1r,K1r,QT,aCe,ebr,obr,PZ,rbr,tbr,abr,WT,nCe,nbr,sbr,BZ,lbr,ibr,dbr,UT,sCe,cbr,fbr,IZ,mbr,gbr,hbr,HT,lCe,ubr,pbr,NZ,_br,vbr,bbr,JT,iCe,Fbr,Tbr,qZ,Mbr,Ebr,Cbr,YT,dCe,wbr,Abr,jZ,Lbr,ybr,xbr,ZT,cCe,$br,kbr,DZ,Sbr,Rbr,Pbr,KT,Bbr,fCe,Ibr,Nbr,mCe,qbr,jbr,eM,aao,ic,oM,gCe,Sk,Dbr,hCe,Gbr,nao,Qo,Rk,Obr,dc,Vbr,GZ,Xbr,zbr,OZ,Qbr,Wbr,Ubr,Pk,Hbr,uCe,Jbr,Ybr,Zbr,St,Bk,Kbr,pCe,e0r,o0r,cc,r0r,_Ce,t0r,a0r,VZ,n0r,s0r,l0r,rM,i0r,co,Ik,d0r,vCe,c0r,f0r,pn,m0r,bCe,g0r,h0r,FCe,u0r,p0r,TCe,_0r,v0r,b0r,O,tM,MCe,F0r,T0r,XZ,M0r,E0r,C0r,aM,ECe,w0r,A0r,zZ,L0r,y0r,x0r,nM,CCe,$0r,k0r,QZ,S0r,R0r,P0r,sM,wCe,B0r,I0r,WZ,N0r,q0r,j0r,lM,ACe,D0r,G0r,UZ,O0r,V0r,X0r,iM,LCe,z0r,Q0r,HZ,W0r,U0r,H0r,dM,yCe,J0r,Y0r,JZ,Z0r,K0r,eFr,cM,xCe,oFr,rFr,YZ,tFr,aFr,nFr,fM,$Ce,sFr,lFr,ZZ,iFr,dFr,cFr,mM,kCe,fFr,mFr,KZ,gFr,hFr,uFr,gM,SCe,pFr,_Fr,eK,vFr,bFr,FFr,hM,RCe,TFr,MFr,oK,EFr,CFr,wFr,uM,PCe,AFr,LFr,rK,yFr,xFr,$Fr,pM,BCe,kFr,SFr,tK,RFr,PFr,BFr,_M,ICe,IFr,NFr,aK,qFr,jFr,DFr,vM,NCe,GFr,OFr,nK,VFr,XFr,zFr,bM,qCe,QFr,WFr,sK,UFr,HFr,JFr,FM,jCe,YFr,ZFr,lK,KFr,eTr,oTr,TM,DCe,rTr,tTr,iK,aTr,nTr,sTr,MM,GCe,lTr,iTr,dK,dTr,cTr,fTr,EM,OCe,mTr,gTr,cK,hTr,uTr,pTr,CM,VCe,_Tr,vTr,fK,bTr,FTr,TTr,wM,XCe,MTr,ETr,mK,CTr,wTr,ATr,AM,zCe,LTr,yTr,gK,xTr,$Tr,kTr,LM,QCe,STr,RTr,hK,PTr,BTr,ITr,yM,WCe,NTr,qTr,uK,jTr,DTr,GTr,xM,UCe,OTr,VTr,pK,XTr,zTr,QTr,$M,HCe,WTr,UTr,_K,HTr,JTr,YTr,kM,JCe,ZTr,KTr,vK,eMr,oMr,rMr,SM,YCe,tMr,aMr,bK,nMr,sMr,lMr,RM,ZCe,iMr,dMr,FK,cMr,fMr,mMr,PM,KCe,gMr,hMr,TK,uMr,pMr,_Mr,BM,e3e,vMr,bMr,MK,FMr,TMr,MMr,IM,o3e,EMr,CMr,EK,wMr,AMr,LMr,NM,r3e,yMr,xMr,CK,$Mr,kMr,SMr,qM,t3e,RMr,PMr,wK,BMr,IMr,NMr,jM,a3e,qMr,jMr,AK,DMr,GMr,OMr,DM,n3e,VMr,XMr,LK,zMr,QMr,WMr,GM,s3e,UMr,HMr,yK,JMr,YMr,ZMr,OM,l3e,KMr,eEr,xK,oEr,rEr,tEr,VM,i3e,aEr,nEr,$K,sEr,lEr,iEr,XM,d3e,dEr,cEr,kK,fEr,mEr,gEr,zM,c3e,hEr,uEr,SK,pEr,_Er,vEr,QM,f3e,bEr,FEr,RK,TEr,MEr,EEr,WM,m3e,CEr,wEr,PK,AEr,LEr,yEr,UM,g3e,xEr,$Er,BK,kEr,SEr,REr,HM,h3e,PEr,BEr,IK,IEr,NEr,qEr,JM,u3e,jEr,DEr,NK,GEr,OEr,VEr,YM,XEr,p3e,zEr,QEr,_3e,WEr,UEr,ZM,sao,fc,KM,v3e,Nk,HEr,b3e,JEr,lao,Wo,qk,YEr,mc,ZEr,qK,KEr,eCr,jK,oCr,rCr,tCr,jk,aCr,F3e,nCr,sCr,lCr,Rt,Dk,iCr,T3e,dCr,cCr,gc,fCr,M3e,mCr,gCr,DK,hCr,uCr,pCr,eE,_Cr,fo,Gk,vCr,E3e,bCr,FCr,_n,TCr,C3e,MCr,ECr,w3e,CCr,wCr,A3e,ACr,LCr,yCr,L3e,oE,y3e,xCr,$Cr,GK,kCr,SCr,RCr,rE,PCr,x3e,BCr,ICr,$3e,NCr,qCr,tE,iao,hc,aE,k3e,Ok,jCr,S3e,DCr,dao,Uo,Vk,GCr,uc,OCr,OK,VCr,XCr,VK,zCr,QCr,WCr,Xk,UCr,R3e,HCr,JCr,YCr,Pt,zk,ZCr,P3e,KCr,e3r,pc,o3r,B3e,r3r,t3r,XK,a3r,n3r,s3r,nE,l3r,mo,Qk,i3r,I3e,d3r,c3r,vn,f3r,N3e,m3r,g3r,q3e,h3r,u3r,j3e,p3r,_3r,v3r,_c,sE,D3e,b3r,F3r,zK,T3r,M3r,E3r,lE,G3e,C3r,w3r,QK,A3r,L3r,y3r,iE,O3e,x3r,$3r,WK,k3r,S3r,R3r,dE,P3r,V3e,B3r,I3r,X3e,N3r,q3r,cE,cao,vc,fE,z3e,Wk,j3r,Q3e,D3r,fao,Ho,Uk,G3r,bc,O3r,UK,V3r,X3r,HK,z3r,Q3r,W3r,Hk,U3r,W3e,H3r,J3r,Y3r,Bt,Jk,Z3r,U3e,K3r,e5r,Fc,o5r,H3e,r5r,t5r,JK,a5r,n5r,s5r,mE,l5r,go,Yk,i5r,J3e,d5r,c5r,bn,f5r,Y3e,m5r,g5r,Z3e,h5r,u5r,K3e,p5r,_5r,v5r,ve,gE,e5e,b5r,F5r,YK,T5r,M5r,E5r,hE,o5e,C5r,w5r,ZK,A5r,L5r,y5r,uE,r5e,x5r,$5r,KK,k5r,S5r,R5r,pE,t5e,P5r,B5r,eee,I5r,N5r,q5r,$l,a5e,j5r,D5r,oee,G5r,O5r,ree,V5r,X5r,z5r,_E,n5e,Q5r,W5r,tee,U5r,H5r,J5r,kl,s5e,Y5r,Z5r,aee,K5r,ewr,nee,owr,rwr,twr,vE,l5e,awr,nwr,see,swr,lwr,iwr,It,i5e,dwr,cwr,lee,fwr,mwr,iee,gwr,hwr,dee,uwr,pwr,_wr,bE,d5e,vwr,bwr,cee,Fwr,Twr,Mwr,FE,c5e,Ewr,Cwr,fee,wwr,Awr,Lwr,TE,f5e,ywr,xwr,mee,$wr,kwr,Swr,ME,m5e,Rwr,Pwr,gee,Bwr,Iwr,Nwr,EE,g5e,qwr,jwr,hee,Dwr,Gwr,Owr,CE,h5e,Vwr,Xwr,uee,zwr,Qwr,Wwr,wE,u5e,Uwr,Hwr,pee,Jwr,Ywr,Zwr,AE,p5e,Kwr,eAr,_ee,oAr,rAr,tAr,LE,_5e,aAr,nAr,vee,sAr,lAr,iAr,yE,dAr,v5e,cAr,fAr,b5e,mAr,gAr,xE,mao,Tc,$E,F5e,Zk,hAr,T5e,uAr,gao,Jo,Kk,pAr,Mc,_Ar,bee,vAr,bAr,Fee,FAr,TAr,MAr,eS,EAr,M5e,CAr,wAr,AAr,Nt,oS,LAr,E5e,yAr,xAr,Ec,$Ar,C5e,kAr,SAr,Tee,RAr,PAr,BAr,kE,IAr,ho,rS,NAr,w5e,qAr,jAr,Fn,DAr,A5e,GAr,OAr,L5e,VAr,XAr,y5e,zAr,QAr,WAr,x5e,SE,$5e,UAr,HAr,Mee,JAr,YAr,ZAr,RE,KAr,k5e,e6r,o6r,S5e,r6r,t6r,PE,hao,Cc,BE,R5e,tS,a6r,P5e,n6r,uao,Yo,aS,s6r,wc,l6r,Eee,i6r,d6r,Cee,c6r,f6r,m6r,nS,g6r,B5e,h6r,u6r,p6r,qt,sS,_6r,I5e,v6r,b6r,Ac,F6r,N5e,T6r,M6r,wee,E6r,C6r,w6r,IE,A6r,uo,lS,L6r,q5e,y6r,x6r,Tn,$6r,j5e,k6r,S6r,D5e,R6r,P6r,G5e,B6r,I6r,N6r,O5e,NE,V5e,q6r,j6r,Aee,D6r,G6r,O6r,qE,V6r,X5e,X6r,z6r,z5e,Q6r,W6r,jE,pao,Lc,DE,Q5e,iS,U6r,W5e,H6r,_ao,Zo,dS,J6r,yc,Y6r,Lee,Z6r,K6r,yee,e7r,o7r,r7r,cS,t7r,U5e,a7r,n7r,s7r,jt,fS,l7r,H5e,i7r,d7r,xc,c7r,J5e,f7r,m7r,xee,g7r,h7r,u7r,GE,p7r,po,mS,_7r,Y5e,v7r,b7r,Mn,F7r,Z5e,T7r,M7r,K5e,E7r,C7r,ewe,w7r,A7r,L7r,owe,OE,rwe,y7r,x7r,$ee,$7r,k7r,S7r,VE,R7r,twe,P7r,B7r,awe,I7r,N7r,XE,vao,$c,zE,nwe,gS,q7r,swe,j7r,bao,Ko,hS,D7r,kc,G7r,kee,O7r,V7r,See,X7r,z7r,Q7r,uS,W7r,lwe,U7r,H7r,J7r,Dt,pS,Y7r,iwe,Z7r,K7r,Sc,e8r,dwe,o8r,r8r,Ree,t8r,a8r,n8r,QE,s8r,_o,_S,l8r,cwe,i8r,d8r,En,c8r,fwe,f8r,m8r,mwe,g8r,h8r,gwe,u8r,p8r,_8r,Be,WE,hwe,v8r,b8r,Pee,F8r,T8r,M8r,UE,uwe,E8r,C8r,Bee,w8r,A8r,L8r,HE,pwe,y8r,x8r,Iee,$8r,k8r,S8r,JE,_we,R8r,P8r,Nee,B8r,I8r,N8r,YE,vwe,q8r,j8r,qee,D8r,G8r,O8r,ZE,bwe,V8r,X8r,jee,z8r,Q8r,W8r,KE,Fwe,U8r,H8r,Dee,J8r,Y8r,Z8r,eC,Twe,K8r,eLr,Gee,oLr,rLr,tLr,oC,Mwe,aLr,nLr,Oee,sLr,lLr,iLr,rC,dLr,Ewe,cLr,fLr,Cwe,mLr,gLr,tC,Fao,Rc,aC,wwe,vS,hLr,Awe,uLr,Tao,er,bS,pLr,Pc,_Lr,Vee,vLr,bLr,Xee,FLr,TLr,MLr,FS,ELr,Lwe,CLr,wLr,ALr,Gt,TS,LLr,ywe,yLr,xLr,Bc,$Lr,xwe,kLr,SLr,zee,RLr,PLr,BLr,nC,ILr,vo,MS,NLr,$we,qLr,jLr,Cn,DLr,kwe,GLr,OLr,Swe,VLr,XLr,Rwe,zLr,QLr,WLr,ut,sC,Pwe,ULr,HLr,Qee,JLr,YLr,ZLr,lC,Bwe,KLr,eyr,Wee,oyr,ryr,tyr,iC,Iwe,ayr,nyr,Uee,syr,lyr,iyr,dC,Nwe,dyr,cyr,Hee,fyr,myr,gyr,cC,qwe,hyr,uyr,Jee,pyr,_yr,vyr,fC,byr,jwe,Fyr,Tyr,Dwe,Myr,Eyr,mC,Mao,Ic,gC,Gwe,ES,Cyr,Owe,wyr,Eao,or,CS,Ayr,Nc,Lyr,Yee,yyr,xyr,Zee,$yr,kyr,Syr,wS,Ryr,Vwe,Pyr,Byr,Iyr,Ot,AS,Nyr,Xwe,qyr,jyr,qc,Dyr,zwe,Gyr,Oyr,Kee,Vyr,Xyr,zyr,hC,Qyr,bo,LS,Wyr,Qwe,Uyr,Hyr,wn,Jyr,Wwe,Yyr,Zyr,Uwe,Kyr,e9r,Hwe,o9r,r9r,t9r,Le,uC,Jwe,a9r,n9r,eoe,s9r,l9r,i9r,pC,Ywe,d9r,c9r,ooe,f9r,m9r,g9r,_C,Zwe,h9r,u9r,roe,p9r,_9r,v9r,vC,Kwe,b9r,F9r,toe,T9r,M9r,E9r,bC,eAe,C9r,w9r,aoe,A9r,L9r,y9r,FC,oAe,x9r,$9r,noe,k9r,S9r,R9r,TC,rAe,P9r,B9r,soe,I9r,N9r,q9r,MC,tAe,j9r,D9r,loe,G9r,O9r,V9r,EC,aAe,X9r,z9r,ioe,Q9r,W9r,U9r,CC,nAe,H9r,J9r,doe,Y9r,Z9r,K9r,wC,exr,sAe,oxr,rxr,lAe,txr,axr,AC,Cao,jc,LC,iAe,yS,nxr,dAe,sxr,wao,rr,xS,lxr,Dc,ixr,coe,dxr,cxr,foe,fxr,mxr,gxr,$S,hxr,cAe,uxr,pxr,_xr,Vt,kS,vxr,fAe,bxr,Fxr,Gc,Txr,mAe,Mxr,Exr,moe,Cxr,wxr,Axr,yC,Lxr,Fo,SS,yxr,gAe,xxr,$xr,An,kxr,hAe,Sxr,Rxr,uAe,Pxr,Bxr,pAe,Ixr,Nxr,qxr,Oc,xC,_Ae,jxr,Dxr,goe,Gxr,Oxr,Vxr,$C,vAe,Xxr,zxr,hoe,Qxr,Wxr,Uxr,kC,bAe,Hxr,Jxr,uoe,Yxr,Zxr,Kxr,SC,e$r,FAe,o$r,r$r,TAe,t$r,a$r,RC,Aao,Vc,PC,MAe,RS,n$r,EAe,s$r,Lao,tr,PS,l$r,Xc,i$r,poe,d$r,c$r,_oe,f$r,m$r,g$r,BS,h$r,CAe,u$r,p$r,_$r,Xt,IS,v$r,wAe,b$r,F$r,zc,T$r,AAe,M$r,E$r,voe,C$r,w$r,A$r,BC,L$r,To,NS,y$r,LAe,x$r,$$r,Ln,k$r,yAe,S$r,R$r,xAe,P$r,B$r,$Ae,I$r,N$r,q$r,pt,IC,kAe,j$r,D$r,boe,G$r,O$r,V$r,NC,SAe,X$r,z$r,Foe,Q$r,W$r,U$r,qC,RAe,H$r,J$r,Toe,Y$r,Z$r,K$r,jC,PAe,ekr,okr,Moe,rkr,tkr,akr,DC,BAe,nkr,skr,Eoe,lkr,ikr,dkr,GC,ckr,IAe,fkr,mkr,NAe,gkr,hkr,OC,yao,Qc,VC,qAe,qS,ukr,jAe,pkr,xao,ar,jS,_kr,Wc,vkr,Coe,bkr,Fkr,woe,Tkr,Mkr,Ekr,DS,Ckr,DAe,wkr,Akr,Lkr,zt,GS,ykr,GAe,xkr,$kr,Uc,kkr,OAe,Skr,Rkr,Aoe,Pkr,Bkr,Ikr,XC,Nkr,Mo,OS,qkr,VAe,jkr,Dkr,yn,Gkr,XAe,Okr,Vkr,zAe,Xkr,zkr,QAe,Qkr,Wkr,Ukr,xn,zC,WAe,Hkr,Jkr,Loe,Ykr,Zkr,Kkr,QC,UAe,eSr,oSr,yoe,rSr,tSr,aSr,WC,HAe,nSr,sSr,xoe,lSr,iSr,dSr,UC,JAe,cSr,fSr,$oe,mSr,gSr,hSr,HC,uSr,YAe,pSr,_Sr,ZAe,vSr,bSr,JC,$ao,Hc,YC,KAe,VS,FSr,e6e,TSr,kao,nr,XS,MSr,Jc,ESr,koe,CSr,wSr,Soe,ASr,LSr,ySr,zS,xSr,o6e,$Sr,kSr,SSr,Qt,QS,RSr,r6e,PSr,BSr,Yc,ISr,t6e,NSr,qSr,Roe,jSr,DSr,GSr,ZC,OSr,Eo,WS,VSr,a6e,XSr,zSr,$n,QSr,n6e,WSr,USr,s6e,HSr,JSr,l6e,YSr,ZSr,KSr,_t,KC,i6e,eRr,oRr,Poe,rRr,tRr,aRr,e3,d6e,nRr,sRr,Boe,lRr,iRr,dRr,o3,c6e,cRr,fRr,Ioe,mRr,gRr,hRr,r3,f6e,uRr,pRr,Noe,_Rr,vRr,bRr,t3,m6e,FRr,TRr,qoe,MRr,ERr,CRr,a3,wRr,g6e,ARr,LRr,h6e,yRr,xRr,n3,Sao,Zc,s3,u6e,US,$Rr,p6e,kRr,Rao,sr,HS,SRr,Kc,RRr,joe,PRr,BRr,Doe,IRr,NRr,qRr,JS,jRr,_6e,DRr,GRr,ORr,Wt,YS,VRr,v6e,XRr,zRr,ef,QRr,b6e,WRr,URr,Goe,HRr,JRr,YRr,l3,ZRr,Co,ZS,KRr,F6e,ePr,oPr,kn,rPr,T6e,tPr,aPr,M6e,nPr,sPr,E6e,lPr,iPr,dPr,C6e,i3,w6e,cPr,fPr,Ooe,mPr,gPr,hPr,d3,uPr,A6e,pPr,_Pr,L6e,vPr,bPr,c3,Pao,of,f3,y6e,KS,FPr,x6e,TPr,Bao,lr,eR,MPr,rf,EPr,Voe,CPr,wPr,Xoe,APr,LPr,yPr,oR,xPr,$6e,$Pr,kPr,SPr,Ut,rR,RPr,k6e,PPr,BPr,tf,IPr,S6e,NPr,qPr,zoe,jPr,DPr,GPr,m3,OPr,wo,tR,VPr,R6e,XPr,zPr,Sn,QPr,P6e,WPr,UPr,B6e,HPr,JPr,I6e,YPr,ZPr,KPr,vt,g3,N6e,eBr,oBr,Qoe,rBr,tBr,aBr,h3,q6e,nBr,sBr,Woe,lBr,iBr,dBr,u3,j6e,cBr,fBr,Uoe,mBr,gBr,hBr,p3,D6e,uBr,pBr,Hoe,_Br,vBr,bBr,_3,G6e,FBr,TBr,Joe,MBr,EBr,CBr,v3,wBr,O6e,ABr,LBr,V6e,yBr,xBr,b3,Iao,af,F3,X6e,aR,$Br,z6e,kBr,Nao,ir,nR,SBr,nf,RBr,Yoe,PBr,BBr,Zoe,IBr,NBr,qBr,sR,jBr,Q6e,DBr,GBr,OBr,Ht,lR,VBr,W6e,XBr,zBr,sf,QBr,U6e,WBr,UBr,Koe,HBr,JBr,YBr,T3,ZBr,Ao,iR,KBr,H6e,eIr,oIr,Rn,rIr,J6e,tIr,aIr,Y6e,nIr,sIr,Z6e,lIr,iIr,dIr,K6e,M3,e7e,cIr,fIr,ere,mIr,gIr,hIr,E3,uIr,o7e,pIr,_Ir,r7e,vIr,bIr,C3,qao,lf,w3,t7e,dR,FIr,a7e,TIr,jao,dr,cR,MIr,df,EIr,ore,CIr,wIr,rre,AIr,LIr,yIr,fR,xIr,n7e,$Ir,kIr,SIr,Jt,mR,RIr,s7e,PIr,BIr,cf,IIr,l7e,NIr,qIr,tre,jIr,DIr,GIr,A3,OIr,Lo,gR,VIr,i7e,XIr,zIr,Pn,QIr,d7e,WIr,UIr,c7e,HIr,JIr,f7e,YIr,ZIr,KIr,m7e,L3,g7e,eNr,oNr,are,rNr,tNr,aNr,y3,nNr,h7e,sNr,lNr,u7e,iNr,dNr,x3,Dao,ff,$3,p7e,hR,cNr,_7e,fNr,Gao,cr,uR,mNr,mf,gNr,nre,hNr,uNr,sre,pNr,_Nr,vNr,pR,bNr,v7e,FNr,TNr,MNr,Yt,_R,ENr,b7e,CNr,wNr,gf,ANr,F7e,LNr,yNr,lre,xNr,$Nr,kNr,k3,SNr,Dr,vR,RNr,T7e,PNr,BNr,Bn,INr,M7e,NNr,qNr,E7e,jNr,DNr,C7e,GNr,ONr,VNr,P,S3,w7e,XNr,zNr,ire,QNr,WNr,UNr,R3,A7e,HNr,JNr,dre,YNr,ZNr,KNr,P3,L7e,eqr,oqr,cre,rqr,tqr,aqr,B3,y7e,nqr,sqr,fre,lqr,iqr,dqr,I3,x7e,cqr,fqr,mre,mqr,gqr,hqr,N3,$7e,uqr,pqr,gre,_qr,vqr,bqr,q3,k7e,Fqr,Tqr,hre,Mqr,Eqr,Cqr,j3,S7e,wqr,Aqr,ure,Lqr,yqr,xqr,D3,R7e,$qr,kqr,pre,Sqr,Rqr,Pqr,G3,P7e,Bqr,Iqr,_re,Nqr,qqr,jqr,O3,B7e,Dqr,Gqr,vre,Oqr,Vqr,Xqr,V3,I7e,zqr,Qqr,bre,Wqr,Uqr,Hqr,X3,N7e,Jqr,Yqr,Fre,Zqr,Kqr,ejr,z3,q7e,ojr,rjr,Tre,tjr,ajr,njr,Q3,j7e,sjr,ljr,Mre,ijr,djr,cjr,W3,D7e,fjr,mjr,Ere,gjr,hjr,ujr,U3,G7e,pjr,_jr,Cre,vjr,bjr,Fjr,H3,O7e,Tjr,Mjr,wre,Ejr,Cjr,wjr,J3,V7e,Ajr,Ljr,Are,yjr,xjr,$jr,Y3,X7e,kjr,Sjr,Lre,Rjr,Pjr,Bjr,Sl,z7e,Ijr,Njr,yre,qjr,jjr,xre,Djr,Gjr,Ojr,Z3,Q7e,Vjr,Xjr,$re,zjr,Qjr,Wjr,K3,W7e,Ujr,Hjr,kre,Jjr,Yjr,Zjr,e5,U7e,Kjr,eDr,Sre,oDr,rDr,tDr,o5,H7e,aDr,nDr,Rre,sDr,lDr,iDr,r5,J7e,dDr,cDr,Pre,fDr,mDr,gDr,t5,Y7e,hDr,uDr,Bre,pDr,_Dr,vDr,a5,Z7e,bDr,FDr,Ire,TDr,MDr,EDr,n5,K7e,CDr,wDr,Nre,ADr,LDr,yDr,s5,e8e,xDr,$Dr,qre,kDr,SDr,RDr,l5,o8e,PDr,BDr,jre,IDr,NDr,qDr,i5,r8e,jDr,DDr,Dre,GDr,ODr,VDr,d5,t8e,XDr,zDr,Gre,QDr,WDr,UDr,c5,a8e,HDr,JDr,Ore,YDr,ZDr,KDr,f5,n8e,eGr,oGr,Vre,rGr,tGr,aGr,m5,s8e,nGr,sGr,Xre,lGr,iGr,dGr,g5,l8e,cGr,fGr,zre,mGr,gGr,hGr,h5,i8e,uGr,pGr,Qre,_Gr,vGr,bGr,u5,d8e,FGr,TGr,Wre,MGr,EGr,CGr,p5,c8e,wGr,AGr,Ure,LGr,yGr,xGr,_5,f8e,$Gr,kGr,Hre,SGr,RGr,PGr,v5,m8e,BGr,IGr,Jre,NGr,qGr,jGr,b5,g8e,DGr,GGr,Yre,OGr,VGr,XGr,F5,h8e,zGr,QGr,Zre,WGr,UGr,HGr,T5,u8e,JGr,YGr,Kre,ZGr,KGr,eOr,M5,p8e,oOr,rOr,ete,tOr,aOr,nOr,E5,_8e,sOr,lOr,ote,iOr,dOr,cOr,C5,v8e,fOr,mOr,rte,gOr,hOr,uOr,w5,b8e,pOr,_Or,tte,vOr,bOr,FOr,A5,F8e,TOr,MOr,ate,EOr,COr,wOr,L5,T8e,AOr,LOr,nte,yOr,xOr,$Or,y5,M8e,kOr,SOr,ste,ROr,POr,BOr,x5,E8e,IOr,NOr,lte,qOr,jOr,DOr,$5,C8e,GOr,OOr,ite,VOr,XOr,zOr,k5,w8e,QOr,WOr,dte,UOr,HOr,JOr,S5,A8e,YOr,ZOr,cte,KOr,eVr,oVr,R5,L8e,rVr,tVr,fte,aVr,nVr,sVr,P5,y8e,lVr,iVr,mte,dVr,cVr,fVr,B5,Oao,hf,I5,x8e,bR,mVr,$8e,gVr,Vao,fr,FR,hVr,uf,uVr,gte,pVr,_Vr,hte,vVr,bVr,FVr,TR,TVr,k8e,MVr,EVr,CVr,Zt,MR,wVr,S8e,AVr,LVr,pf,yVr,R8e,xVr,$Vr,ute,kVr,SVr,RVr,N5,PVr,Gr,ER,BVr,P8e,IVr,NVr,In,qVr,B8e,jVr,DVr,I8e,GVr,OVr,N8e,VVr,XVr,zVr,se,q5,q8e,QVr,WVr,pte,UVr,HVr,JVr,j5,j8e,YVr,ZVr,_te,KVr,eXr,oXr,D5,D8e,rXr,tXr,vte,aXr,nXr,sXr,G5,G8e,lXr,iXr,bte,dXr,cXr,fXr,O5,O8e,mXr,gXr,Fte,hXr,uXr,pXr,V5,V8e,_Xr,vXr,Tte,bXr,FXr,TXr,X5,X8e,MXr,EXr,Mte,CXr,wXr,AXr,z5,z8e,LXr,yXr,Ete,xXr,$Xr,kXr,Q5,Q8e,SXr,RXr,Cte,PXr,BXr,IXr,W5,W8e,NXr,qXr,wte,jXr,DXr,GXr,U5,U8e,OXr,VXr,Ate,XXr,zXr,QXr,H5,H8e,WXr,UXr,Lte,HXr,JXr,YXr,J5,J8e,ZXr,KXr,yte,ezr,ozr,rzr,Y5,Y8e,tzr,azr,xte,nzr,szr,lzr,Z5,Z8e,izr,dzr,$te,czr,fzr,mzr,K5,K8e,gzr,hzr,kte,uzr,pzr,_zr,ew,eLe,vzr,bzr,Ste,Fzr,Tzr,Mzr,ow,oLe,Ezr,Czr,Rte,wzr,Azr,Lzr,rw,rLe,yzr,xzr,Pte,$zr,kzr,Szr,tw,tLe,Rzr,Pzr,Bte,Bzr,Izr,Nzr,aw,aLe,qzr,jzr,Ite,Dzr,Gzr,Ozr,nw,nLe,Vzr,Xzr,Nte,zzr,Qzr,Wzr,sw,sLe,Uzr,Hzr,qte,Jzr,Yzr,Zzr,lw,Xao,_f,iw,lLe,CR,Kzr,iLe,eQr,zao,mr,wR,oQr,vf,rQr,jte,tQr,aQr,Dte,nQr,sQr,lQr,AR,iQr,dLe,dQr,cQr,fQr,Kt,LR,mQr,cLe,gQr,hQr,bf,uQr,fLe,pQr,_Qr,Gte,vQr,bQr,FQr,dw,TQr,Or,yR,MQr,mLe,EQr,CQr,Nn,wQr,gLe,AQr,LQr,hLe,yQr,xQr,uLe,$Qr,kQr,SQr,Me,cw,pLe,RQr,PQr,Ote,BQr,IQr,NQr,fw,_Le,qQr,jQr,Vte,DQr,GQr,OQr,mw,vLe,VQr,XQr,Xte,zQr,QQr,WQr,gw,bLe,UQr,HQr,zte,JQr,YQr,ZQr,hw,FLe,KQr,eWr,Qte,oWr,rWr,tWr,uw,TLe,aWr,nWr,Wte,sWr,lWr,iWr,pw,MLe,dWr,cWr,Ute,fWr,mWr,gWr,_w,ELe,hWr,uWr,Hte,pWr,_Wr,vWr,vw,CLe,bWr,FWr,Jte,TWr,MWr,EWr,bw,wLe,CWr,wWr,Yte,AWr,LWr,yWr,Fw,ALe,xWr,$Wr,Zte,kWr,SWr,RWr,Tw,LLe,PWr,BWr,Kte,IWr,NWr,qWr,Mw,yLe,jWr,DWr,eae,GWr,OWr,VWr,Ew,xLe,XWr,zWr,oae,QWr,WWr,UWr,Cw,Qao,Ff,ww,$Le,xR,HWr,kLe,JWr,Wao,gr,$R,YWr,Tf,ZWr,rae,KWr,eUr,tae,oUr,rUr,tUr,kR,aUr,SLe,nUr,sUr,lUr,ea,SR,iUr,RLe,dUr,cUr,Mf,fUr,PLe,mUr,gUr,aae,hUr,uUr,pUr,Aw,_Ur,Vr,RR,vUr,BLe,bUr,FUr,qn,TUr,ILe,MUr,EUr,NLe,CUr,wUr,qLe,AUr,LUr,yUr,ye,Lw,jLe,xUr,$Ur,nae,kUr,SUr,RUr,yw,DLe,PUr,BUr,sae,IUr,NUr,qUr,xw,GLe,jUr,DUr,lae,GUr,OUr,VUr,Rl,OLe,XUr,zUr,iae,QUr,WUr,dae,UUr,HUr,JUr,$w,VLe,YUr,ZUr,cae,KUr,eHr,oHr,kw,XLe,rHr,tHr,fae,aHr,nHr,sHr,Sw,zLe,lHr,iHr,mae,dHr,cHr,fHr,Rw,QLe,mHr,gHr,gae,hHr,uHr,pHr,Pw,WLe,_Hr,vHr,hae,bHr,FHr,THr,Bw,ULe,MHr,EHr,uae,CHr,wHr,AHr,Iw,Uao,Ef,Nw,HLe,PR,LHr,JLe,yHr,Hao,hr,BR,xHr,Cf,$Hr,pae,kHr,SHr,_ae,RHr,PHr,BHr,IR,IHr,YLe,NHr,qHr,jHr,oa,NR,DHr,ZLe,GHr,OHr,wf,VHr,KLe,XHr,zHr,vae,QHr,WHr,UHr,qw,HHr,Xr,qR,JHr,eye,YHr,ZHr,jn,KHr,oye,eJr,oJr,rye,rJr,tJr,tye,aJr,nJr,sJr,Af,jw,aye,lJr,iJr,bae,dJr,cJr,fJr,Dw,nye,mJr,gJr,Fae,hJr,uJr,pJr,Gw,sye,_Jr,vJr,Tae,bJr,FJr,TJr,Ow,Jao,Lf,Vw,lye,jR,MJr,iye,EJr,Yao,ur,DR,CJr,yf,wJr,Mae,AJr,LJr,Eae,yJr,xJr,$Jr,GR,kJr,dye,SJr,RJr,PJr,ra,OR,BJr,cye,IJr,NJr,xf,qJr,fye,jJr,DJr,Cae,GJr,OJr,VJr,Xw,XJr,zr,VR,zJr,mye,QJr,WJr,Dn,UJr,gye,HJr,JJr,hye,YJr,ZJr,uye,KJr,eYr,oYr,ce,zw,pye,rYr,tYr,wae,aYr,nYr,sYr,Qw,_ye,lYr,iYr,Aae,dYr,cYr,fYr,Ww,vye,mYr,gYr,Lae,hYr,uYr,pYr,Uw,bye,_Yr,vYr,yae,bYr,FYr,TYr,Hw,Fye,MYr,EYr,xae,CYr,wYr,AYr,Jw,Tye,LYr,yYr,$ae,xYr,$Yr,kYr,Yw,Mye,SYr,RYr,kae,PYr,BYr,IYr,Zw,Eye,NYr,qYr,Sae,jYr,DYr,GYr,Kw,Cye,OYr,VYr,Rae,XYr,zYr,QYr,eA,wye,WYr,UYr,Pae,HYr,JYr,YYr,oA,Aye,ZYr,KYr,Bae,eZr,oZr,rZr,rA,Lye,tZr,aZr,Iae,nZr,sZr,lZr,tA,yye,iZr,dZr,Nae,cZr,fZr,mZr,aA,xye,gZr,hZr,qae,uZr,pZr,_Zr,nA,$ye,vZr,bZr,jae,FZr,TZr,MZr,sA,kye,EZr,CZr,Dae,wZr,AZr,LZr,lA,Sye,yZr,xZr,Gae,$Zr,kZr,SZr,iA,Rye,RZr,PZr,Oae,BZr,IZr,NZr,dA,Pye,qZr,jZr,Vae,DZr,GZr,OZr,cA,Bye,VZr,XZr,Xae,zZr,QZr,WZr,fA,Iye,UZr,HZr,zae,JZr,YZr,ZZr,mA,Zao,$f,gA,Nye,XR,KZr,qye,eKr,Kao,pr,zR,oKr,kf,rKr,Qae,tKr,aKr,Wae,nKr,sKr,lKr,QR,iKr,jye,dKr,cKr,fKr,ta,WR,mKr,Dye,gKr,hKr,Sf,uKr,Gye,pKr,_Kr,Uae,vKr,bKr,FKr,hA,TKr,Qr,UR,MKr,Oye,EKr,CKr,Gn,wKr,Vye,AKr,LKr,Xye,yKr,xKr,zye,$Kr,kKr,SKr,xe,uA,Qye,RKr,PKr,Hae,BKr,IKr,NKr,pA,Wye,qKr,jKr,Jae,DKr,GKr,OKr,_A,Uye,VKr,XKr,Yae,zKr,QKr,WKr,vA,Hye,UKr,HKr,Zae,JKr,YKr,ZKr,bA,Jye,KKr,eet,Kae,oet,ret,tet,FA,Yye,aet,net,ene,set,iet,det,TA,Zye,cet,fet,one,met,get,het,MA,Kye,uet,pet,rne,_et,vet,bet,EA,e9e,Fet,Tet,tne,Met,Eet,Cet,CA,o9e,wet,Aet,ane,Let,yet,xet,wA,eno,Rf,AA,r9e,HR,$et,t9e,ket,ono,_r,JR,Set,Pf,Ret,nne,Pet,Bet,sne,Iet,Net,qet,YR,jet,a9e,Det,Get,Oet,aa,ZR,Vet,n9e,Xet,zet,Bf,Qet,s9e,Wet,Uet,lne,Het,Jet,Yet,LA,Zet,Wr,KR,Ket,l9e,eot,oot,On,rot,i9e,tot,aot,d9e,not,sot,c9e,lot,iot,dot,re,yA,f9e,cot,fot,ine,mot,got,hot,xA,m9e,uot,pot,dne,_ot,vot,bot,$A,g9e,Fot,Tot,cne,Mot,Eot,Cot,kA,h9e,wot,Aot,fne,Lot,yot,xot,SA,u9e,$ot,kot,mne,Sot,Rot,Pot,RA,p9e,Bot,Iot,gne,Not,qot,jot,PA,_9e,Dot,Got,hne,Oot,Vot,Xot,BA,v9e,zot,Qot,une,Wot,Uot,Hot,IA,b9e,Jot,Yot,pne,Zot,Kot,ert,NA,F9e,ort,rrt,_ne,trt,art,nrt,qA,T9e,srt,lrt,vne,irt,drt,crt,jA,M9e,frt,mrt,bne,grt,hrt,urt,DA,E9e,prt,_rt,Fne,vrt,brt,Frt,GA,C9e,Trt,Mrt,Tne,Ert,Crt,wrt,OA,w9e,Art,Lrt,Mne,yrt,xrt,$rt,VA,A9e,krt,Srt,Ene,Rrt,Prt,Brt,XA,L9e,Irt,Nrt,Cne,qrt,jrt,Drt,zA,y9e,Grt,Ort,wne,Vrt,Xrt,zrt,QA,x9e,Qrt,Wrt,Ane,Urt,Hrt,Jrt,WA,$9e,Yrt,Zrt,Lne,Krt,ett,ott,UA,k9e,rtt,ttt,yne,att,ntt,stt,HA,S9e,ltt,itt,xne,dtt,ctt,ftt,JA,R9e,mtt,gtt,$ne,htt,utt,ptt,YA,P9e,_tt,vtt,kne,btt,Ftt,Ttt,ZA,B9e,Mtt,Ett,Sne,Ctt,wtt,Att,KA,I9e,Ltt,ytt,Rne,xtt,$tt,ktt,e6,N9e,Stt,Rtt,Pne,Ptt,Btt,Itt,o6,q9e,Ntt,qtt,Bne,jtt,Dtt,Gtt,r6,rno,If,t6,j9e,eP,Ott,D9e,Vtt,tno,vr,oP,Xtt,Nf,ztt,Ine,Qtt,Wtt,Nne,Utt,Htt,Jtt,rP,Ytt,G9e,Ztt,Ktt,eat,na,tP,oat,O9e,rat,tat,qf,aat,V9e,nat,sat,qne,lat,iat,dat,a6,cat,Ur,aP,fat,X9e,mat,gat,Vn,hat,z9e,uat,pat,Q9e,_at,vat,W9e,bat,Fat,Tat,be,n6,U9e,Mat,Eat,jne,Cat,wat,Aat,s6,H9e,Lat,yat,Dne,xat,$at,kat,l6,J9e,Sat,Rat,Gne,Pat,Bat,Iat,i6,Y9e,Nat,qat,One,jat,Dat,Gat,d6,Z9e,Oat,Vat,Vne,Xat,zat,Qat,c6,K9e,Wat,Uat,Xne,Hat,Jat,Yat,f6,exe,Zat,Kat,zne,ent,ont,rnt,m6,oxe,tnt,ant,Qne,nnt,snt,lnt,g6,rxe,int,dnt,Wne,cnt,fnt,mnt,h6,txe,gnt,hnt,Une,unt,pnt,_nt,u6,axe,vnt,bnt,Hne,Fnt,Tnt,Mnt,p6,nxe,Ent,Cnt,Jne,wnt,Ant,Lnt,_6,sxe,ynt,xnt,Yne,$nt,knt,Snt,v6,lxe,Rnt,Pnt,Zne,Bnt,Int,Nnt,b6,ixe,qnt,jnt,Kne,Dnt,Gnt,Ont,F6,dxe,Vnt,Xnt,ese,znt,Qnt,Wnt,T6,cxe,Unt,Hnt,ose,Jnt,Ynt,Znt,M6,ano,jf,E6,fxe,nP,Knt,mxe,est,nno,br,sP,ost,Df,rst,rse,tst,ast,tse,nst,sst,lst,lP,ist,gxe,dst,cst,fst,sa,iP,mst,hxe,gst,hst,Gf,ust,uxe,pst,_st,ase,vst,bst,Fst,C6,Tst,Hr,dP,Mst,pxe,Est,Cst,Xn,wst,_xe,Ast,Lst,vxe,yst,xst,bxe,$st,kst,Sst,cP,w6,Fxe,Rst,Pst,nse,Bst,Ist,Nst,A6,Txe,qst,jst,sse,Dst,Gst,Ost,L6,sno,Of,y6,Mxe,fP,Vst,Exe,Xst,lno,Fr,mP,zst,Vf,Qst,lse,Wst,Ust,ise,Hst,Jst,Yst,gP,Zst,Cxe,Kst,elt,olt,la,hP,rlt,wxe,tlt,alt,Xf,nlt,Axe,slt,llt,dse,ilt,dlt,clt,x6,flt,Jr,uP,mlt,Lxe,glt,hlt,zn,ult,yxe,plt,_lt,xxe,vlt,blt,$xe,Flt,Tlt,Mlt,kxe,$6,Sxe,Elt,Clt,cse,wlt,Alt,Llt,k6,ino,zf,S6,Rxe,pP,ylt,Pxe,xlt,dno,Tr,_P,$lt,Qf,klt,fse,Slt,Rlt,mse,Plt,Blt,Ilt,vP,Nlt,Bxe,qlt,jlt,Dlt,ia,bP,Glt,Ixe,Olt,Vlt,Wf,Xlt,Nxe,zlt,Qlt,gse,Wlt,Ult,Hlt,R6,Jlt,Yr,FP,Ylt,qxe,Zlt,Klt,Qn,eit,jxe,oit,rit,Dxe,tit,ait,Gxe,nit,sit,lit,Oxe,P6,Vxe,iit,dit,hse,cit,fit,mit,B6,cno,Uf,I6,Xxe,TP,git,zxe,hit,fno,Mr,MP,uit,Hf,pit,use,_it,vit,pse,bit,Fit,Tit,EP,Mit,Qxe,Eit,Cit,wit,da,CP,Ait,Wxe,Lit,yit,Jf,xit,Uxe,$it,kit,_se,Sit,Rit,Pit,N6,Bit,Zr,wP,Iit,Hxe,Nit,qit,Wn,jit,Jxe,Dit,Git,Yxe,Oit,Vit,Zxe,Xit,zit,Qit,ie,q6,Kxe,Wit,Uit,vse,Hit,Jit,Yit,j6,e$e,Zit,Kit,bse,edt,odt,rdt,D6,o$e,tdt,adt,Fse,ndt,sdt,ldt,G6,r$e,idt,ddt,Tse,cdt,fdt,mdt,O6,t$e,gdt,hdt,Mse,udt,pdt,_dt,V6,a$e,vdt,bdt,Ese,Fdt,Tdt,Mdt,X6,n$e,Edt,Cdt,Cse,wdt,Adt,Ldt,z6,s$e,ydt,xdt,wse,$dt,kdt,Sdt,Q6,l$e,Rdt,Pdt,Ase,Bdt,Idt,Ndt,W6,i$e,qdt,jdt,Lse,Ddt,Gdt,Odt,U6,d$e,Vdt,Xdt,yse,zdt,Qdt,Wdt,H6,c$e,Udt,Hdt,xse,Jdt,Ydt,Zdt,J6,f$e,Kdt,ect,$se,oct,rct,tct,Y6,m$e,act,nct,kse,sct,lct,ict,Z6,g$e,dct,cct,Sse,fct,mct,gct,K6,h$e,hct,uct,Rse,pct,_ct,vct,e7,u$e,bct,Fct,Pse,Tct,Mct,Ect,o7,p$e,Cct,wct,Bse,Act,Lct,yct,r7,_$e,xct,$ct,Ise,kct,Sct,Rct,t7,v$e,Pct,Bct,Nse,Ict,Nct,qct,a7,b$e,jct,Dct,qse,Gct,Oct,Vct,n7,F$e,Xct,zct,jse,Qct,Wct,Uct,s7,mno,Yf,l7,T$e,AP,Hct,M$e,Jct,gno,Er,LP,Yct,Zf,Zct,Dse,Kct,eft,Gse,oft,rft,tft,yP,aft,E$e,nft,sft,lft,ca,xP,ift,C$e,dft,cft,Kf,fft,w$e,mft,gft,Ose,hft,uft,pft,i7,_ft,Kr,$P,vft,A$e,bft,Fft,Un,Tft,L$e,Mft,Eft,y$e,Cft,wft,x$e,Aft,Lft,yft,fe,d7,$$e,xft,$ft,Vse,kft,Sft,Rft,c7,k$e,Pft,Bft,Xse,Ift,Nft,qft,f7,S$e,jft,Dft,zse,Gft,Oft,Vft,m7,R$e,Xft,zft,Qse,Qft,Wft,Uft,g7,P$e,Hft,Jft,Wse,Yft,Zft,Kft,h7,B$e,emt,omt,Use,rmt,tmt,amt,u7,I$e,nmt,smt,Hse,lmt,imt,dmt,p7,N$e,cmt,fmt,Jse,mmt,gmt,hmt,_7,q$e,umt,pmt,Yse,_mt,vmt,bmt,v7,j$e,Fmt,Tmt,Zse,Mmt,Emt,Cmt,b7,D$e,wmt,Amt,Kse,Lmt,ymt,xmt,F7,G$e,$mt,kmt,ele,Smt,Rmt,Pmt,T7,O$e,Bmt,Imt,ole,Nmt,qmt,jmt,M7,V$e,Dmt,Gmt,rle,Omt,Vmt,Xmt,E7,X$e,zmt,Qmt,tle,Wmt,Umt,Hmt,C7,z$e,Jmt,Ymt,ale,Zmt,Kmt,egt,w7,Q$e,ogt,rgt,nle,tgt,agt,ngt,A7,W$e,sgt,lgt,sle,igt,dgt,cgt,L7,U$e,fgt,mgt,lle,ggt,hgt,ugt,y7,H$e,pgt,_gt,ile,vgt,bgt,Fgt,x7,J$e,Tgt,Mgt,dle,Egt,Cgt,wgt,$7,hno,em,k7,Y$e,kP,Agt,Z$e,Lgt,uno,Cr,SP,ygt,om,xgt,cle,$gt,kgt,fle,Sgt,Rgt,Pgt,RP,Bgt,K$e,Igt,Ngt,qgt,fa,PP,jgt,eke,Dgt,Ggt,rm,Ogt,oke,Vgt,Xgt,mle,zgt,Qgt,Wgt,S7,Ugt,et,BP,Hgt,rke,Jgt,Ygt,Hn,Zgt,tke,Kgt,eht,ake,oht,rht,nke,tht,aht,nht,ske,R7,lke,sht,lht,gle,iht,dht,cht,P7,pno,tm,B7,ike,IP,fht,dke,mht,_no,wr,NP,ght,am,hht,hle,uht,pht,ule,_ht,vht,bht,qP,Fht,cke,Tht,Mht,Eht,ma,jP,Cht,fke,wht,Aht,nm,Lht,mke,yht,xht,ple,$ht,kht,Sht,I7,Rht,ot,DP,Pht,gke,Bht,Iht,Jn,Nht,hke,qht,jht,uke,Dht,Ght,pke,Oht,Vht,Xht,GP,N7,_ke,zht,Qht,_le,Wht,Uht,Hht,q7,vke,Jht,Yht,vle,Zht,Kht,eut,j7,vno,sm,D7,bke,OP,out,Fke,rut,bno,Ar,VP,tut,lm,aut,ble,nut,sut,Fle,lut,iut,dut,XP,cut,Tke,fut,mut,gut,ga,zP,hut,Mke,uut,put,im,_ut,Eke,vut,but,Tle,Fut,Tut,Mut,G7,Eut,rt,QP,Cut,Cke,wut,Aut,Yn,Lut,wke,yut,xut,Ake,$ut,kut,Lke,Sut,Rut,Put,te,O7,yke,But,Iut,Mle,Nut,qut,jut,V7,xke,Dut,Gut,Ele,Out,Vut,Xut,X7,$ke,zut,Qut,Cle,Wut,Uut,Hut,z7,kke,Jut,Yut,wle,Zut,Kut,ept,Q7,Ske,opt,rpt,Ale,tpt,apt,npt,W7,Rke,spt,lpt,Lle,ipt,dpt,cpt,U7,Pke,fpt,mpt,yle,gpt,hpt,upt,H7,Bke,ppt,_pt,xle,vpt,bpt,Fpt,J7,Ike,Tpt,Mpt,$le,Ept,Cpt,wpt,Y7,Nke,Apt,Lpt,kle,ypt,xpt,$pt,Z7,qke,kpt,Spt,Sle,Rpt,Ppt,Bpt,K7,jke,Ipt,Npt,Rle,qpt,jpt,Dpt,e8,Dke,Gpt,Opt,Ple,Vpt,Xpt,zpt,o8,Gke,Qpt,Wpt,Ble,Upt,Hpt,Jpt,r8,Oke,Ypt,Zpt,Ile,Kpt,e_t,o_t,t8,Vke,r_t,t_t,Nle,a_t,n_t,s_t,a8,Xke,l_t,i_t,qle,d_t,c_t,f_t,n8,zke,m_t,g_t,jle,h_t,u_t,p_t,s8,Qke,__t,v_t,Dle,b_t,F_t,T_t,l8,Wke,M_t,E_t,Gle,C_t,w_t,A_t,i8,Uke,L_t,y_t,Ole,x_t,$_t,k_t,d8,Hke,S_t,R_t,Vle,P_t,B_t,I_t,c8,Jke,N_t,q_t,Xle,j_t,D_t,G_t,f8,Yke,O_t,V_t,zle,X_t,z_t,Q_t,m8,Zke,W_t,U_t,Qle,H_t,J_t,Y_t,g8,Kke,Z_t,K_t,Wle,e4t,o4t,r4t,h8,eSe,t4t,a4t,Ule,n4t,s4t,l4t,u8,Fno,dm,p8,oSe,WP,i4t,rSe,d4t,Tno,Lr,UP,c4t,cm,f4t,Hle,m4t,g4t,Jle,h4t,u4t,p4t,HP,_4t,tSe,v4t,b4t,F4t,ha,JP,T4t,aSe,M4t,E4t,fm,C4t,nSe,w4t,A4t,Yle,L4t,y4t,x4t,_8,$4t,tt,YP,k4t,sSe,S4t,R4t,Zn,P4t,lSe,B4t,I4t,iSe,N4t,q4t,dSe,j4t,D4t,G4t,$e,v8,cSe,O4t,V4t,Zle,X4t,z4t,Q4t,b8,fSe,W4t,U4t,Kle,H4t,J4t,Y4t,F8,mSe,Z4t,K4t,eie,e2t,o2t,r2t,T8,gSe,t2t,a2t,oie,n2t,s2t,l2t,M8,hSe,i2t,d2t,rie,c2t,f2t,m2t,E8,uSe,g2t,h2t,tie,u2t,p2t,_2t,C8,pSe,v2t,b2t,aie,F2t,T2t,M2t,w8,_Se,E2t,C2t,nie,w2t,A2t,L2t,A8,vSe,y2t,x2t,sie,$2t,k2t,S2t,L8,bSe,R2t,P2t,lie,B2t,I2t,N2t,y8,Mno,mm,x8,FSe,ZP,q2t,TSe,j2t,Eno,yr,KP,D2t,gm,G2t,iie,O2t,V2t,die,X2t,z2t,Q2t,eB,W2t,MSe,U2t,H2t,J2t,ua,oB,Y2t,ESe,Z2t,K2t,hm,evt,CSe,ovt,rvt,cie,tvt,avt,nvt,$8,svt,at,rB,lvt,wSe,ivt,dvt,Kn,cvt,ASe,fvt,mvt,LSe,gvt,hvt,ySe,uvt,pvt,_vt,Ee,k8,xSe,vvt,bvt,fie,Fvt,Tvt,Mvt,S8,$Se,Evt,Cvt,mie,wvt,Avt,Lvt,R8,kSe,yvt,xvt,gie,$vt,kvt,Svt,P8,SSe,Rvt,Pvt,hie,Bvt,Ivt,Nvt,B8,RSe,qvt,jvt,uie,Dvt,Gvt,Ovt,I8,PSe,Vvt,Xvt,pie,zvt,Qvt,Wvt,N8,BSe,Uvt,Hvt,_ie,Jvt,Yvt,Zvt,q8,ISe,Kvt,e1t,vie,o1t,r1t,t1t,j8,NSe,a1t,n1t,bie,s1t,l1t,i1t,D8,qSe,d1t,c1t,Fie,f1t,m1t,g1t,G8,jSe,h1t,u1t,Tie,p1t,_1t,v1t,O8,DSe,b1t,F1t,Mie,T1t,M1t,E1t,V8,GSe,C1t,w1t,Eie,A1t,L1t,y1t,X8,Cno,um,z8,OSe,tB,x1t,VSe,$1t,wno,xr,aB,k1t,pm,S1t,Cie,R1t,P1t,wie,B1t,I1t,N1t,nB,q1t,XSe,j1t,D1t,G1t,pa,sB,O1t,zSe,V1t,X1t,_m,z1t,QSe,Q1t,W1t,Aie,U1t,H1t,J1t,Q8,Y1t,nt,lB,Z1t,WSe,K1t,ebt,es,obt,USe,rbt,tbt,HSe,abt,nbt,JSe,sbt,lbt,ibt,ke,W8,YSe,dbt,cbt,Lie,fbt,mbt,gbt,U8,ZSe,hbt,ubt,yie,pbt,_bt,vbt,H8,KSe,bbt,Fbt,xie,Tbt,Mbt,Ebt,J8,eRe,Cbt,wbt,$ie,Abt,Lbt,ybt,Y8,oRe,xbt,$bt,kie,kbt,Sbt,Rbt,Z8,rRe,Pbt,Bbt,Sie,Ibt,Nbt,qbt,K8,tRe,jbt,Dbt,Rie,Gbt,Obt,Vbt,eL,aRe,Xbt,zbt,Pie,Qbt,Wbt,Ubt,oL,nRe,Hbt,Jbt,Bie,Ybt,Zbt,Kbt,rL,sRe,e0t,o0t,Iie,r0t,t0t,a0t,tL,Ano,vm,aL,lRe,iB,n0t,iRe,s0t,Lno,$r,dB,l0t,bm,i0t,Nie,d0t,c0t,qie,f0t,m0t,g0t,cB,h0t,dRe,u0t,p0t,_0t,_a,fB,v0t,cRe,b0t,F0t,Fm,T0t,fRe,M0t,E0t,jie,C0t,w0t,A0t,nL,L0t,st,mB,y0t,mRe,x0t,$0t,os,k0t,gRe,S0t,R0t,hRe,P0t,B0t,uRe,I0t,N0t,q0t,Se,sL,pRe,j0t,D0t,Die,G0t,O0t,V0t,lL,_Re,X0t,z0t,Gie,Q0t,W0t,U0t,iL,vRe,H0t,J0t,Oie,Y0t,Z0t,K0t,dL,bRe,eFt,oFt,Vie,rFt,tFt,aFt,cL,FRe,nFt,sFt,Xie,lFt,iFt,dFt,fL,TRe,cFt,fFt,zie,mFt,gFt,hFt,mL,MRe,uFt,pFt,Qie,_Ft,vFt,bFt,gL,ERe,FFt,TFt,Wie,MFt,EFt,CFt,hL,CRe,wFt,AFt,Uie,LFt,yFt,xFt,uL,wRe,$Ft,kFt,Hie,SFt,RFt,PFt,pL,yno,Tm,_L,ARe,gB,BFt,LRe,IFt,xno,kr,hB,NFt,Mm,qFt,Jie,jFt,DFt,Yie,GFt,OFt,VFt,uB,XFt,yRe,zFt,QFt,WFt,va,pB,UFt,xRe,HFt,JFt,Em,YFt,$Re,ZFt,KFt,Zie,eTt,oTt,rTt,vL,tTt,lt,_B,aTt,kRe,nTt,sTt,rs,lTt,SRe,iTt,dTt,RRe,cTt,fTt,PRe,mTt,gTt,hTt,Re,bL,BRe,uTt,pTt,Kie,_Tt,vTt,bTt,FL,IRe,FTt,TTt,ede,MTt,ETt,CTt,TL,NRe,wTt,ATt,ode,LTt,yTt,xTt,ML,qRe,$Tt,kTt,rde,STt,RTt,PTt,EL,jRe,BTt,ITt,tde,NTt,qTt,jTt,CL,DRe,DTt,GTt,ade,OTt,VTt,XTt,wL,GRe,zTt,QTt,nde,WTt,UTt,HTt,AL,ORe,JTt,YTt,sde,ZTt,KTt,eMt,LL,VRe,oMt,rMt,lde,tMt,aMt,nMt,yL,XRe,sMt,lMt,ide,iMt,dMt,cMt,xL,$no,Cm,$L,zRe,vB,fMt,QRe,mMt,kno,Sr,bB,gMt,wm,hMt,dde,uMt,pMt,cde,_Mt,vMt,bMt,FB,FMt,WRe,TMt,MMt,EMt,ba,TB,CMt,URe,wMt,AMt,Am,LMt,HRe,yMt,xMt,fde,$Mt,kMt,SMt,kL,RMt,it,MB,PMt,JRe,BMt,IMt,ts,NMt,YRe,qMt,jMt,ZRe,DMt,GMt,KRe,OMt,VMt,XMt,Pe,SL,ePe,zMt,QMt,mde,WMt,UMt,HMt,RL,oPe,JMt,YMt,gde,ZMt,KMt,eEt,PL,rPe,oEt,rEt,hde,tEt,aEt,nEt,BL,tPe,sEt,lEt,ude,iEt,dEt,cEt,IL,aPe,fEt,mEt,pde,gEt,hEt,uEt,NL,nPe,pEt,_Et,_de,vEt,bEt,FEt,qL,sPe,TEt,MEt,vde,EEt,CEt,wEt,jL,lPe,AEt,LEt,bde,yEt,xEt,$Et,DL,iPe,kEt,SEt,Fde,REt,PEt,BEt,GL,dPe,IEt,NEt,Tde,qEt,jEt,DEt,OL,Sno,Lm,VL,cPe,EB,GEt,fPe,OEt,Rno,Rr,CB,VEt,ym,XEt,Mde,zEt,QEt,Ede,WEt,UEt,HEt,wB,JEt,mPe,YEt,ZEt,KEt,Fa,AB,eCt,gPe,oCt,rCt,xm,tCt,hPe,aCt,nCt,Cde,sCt,lCt,iCt,XL,dCt,dt,LB,cCt,uPe,fCt,mCt,as,gCt,pPe,hCt,uCt,_Pe,pCt,_Ct,vPe,vCt,bCt,FCt,ze,zL,bPe,TCt,MCt,wde,ECt,CCt,wCt,QL,FPe,ACt,LCt,Ade,yCt,xCt,$Ct,WL,TPe,kCt,SCt,Lde,RCt,PCt,BCt,UL,MPe,ICt,NCt,yde,qCt,jCt,DCt,HL,EPe,GCt,OCt,xde,VCt,XCt,zCt,JL,CPe,QCt,WCt,$de,UCt,HCt,JCt,YL,wPe,YCt,ZCt,kde,KCt,e3t,o3t,ZL,APe,r3t,t3t,Sde,a3t,n3t,s3t,KL,Pno,$m,ey,LPe,yB,l3t,yPe,i3t,Bno,Pr,xB,d3t,km,c3t,Rde,f3t,m3t,Pde,g3t,h3t,u3t,$B,p3t,xPe,_3t,v3t,b3t,Ta,kB,F3t,$Pe,T3t,M3t,Sm,E3t,kPe,C3t,w3t,Bde,A3t,L3t,y3t,oy,x3t,ct,SB,$3t,SPe,k3t,S3t,ns,R3t,RPe,P3t,B3t,PPe,I3t,N3t,BPe,q3t,j3t,D3t,Qe,ry,IPe,G3t,O3t,Ide,V3t,X3t,z3t,ty,NPe,Q3t,W3t,Nde,U3t,H3t,J3t,ay,qPe,Y3t,Z3t,qde,K3t,e5t,o5t,ny,jPe,r5t,t5t,jde,a5t,n5t,s5t,sy,DPe,l5t,i5t,Dde,d5t,c5t,f5t,ly,GPe,m5t,g5t,Gde,h5t,u5t,p5t,iy,OPe,_5t,v5t,Ode,b5t,F5t,T5t,dy,VPe,M5t,E5t,Vde,C5t,w5t,A5t,cy,Ino,Rm,fy,XPe,RB,L5t,zPe,y5t,Nno,Br,PB,x5t,Pm,$5t,Xde,k5t,S5t,zde,R5t,P5t,B5t,BB,I5t,QPe,N5t,q5t,j5t,Ma,IB,D5t,WPe,G5t,O5t,Bm,V5t,UPe,X5t,z5t,Qde,Q5t,W5t,U5t,my,H5t,ft,NB,J5t,HPe,Y5t,Z5t,ss,K5t,JPe,ewt,owt,YPe,rwt,twt,ZPe,awt,nwt,swt,KPe,gy,eBe,lwt,iwt,Wde,dwt,cwt,fwt,hy,qno,Im,uy,oBe,qB,mwt,rBe,gwt,jno,Ir,jB,hwt,Nm,uwt,Ude,pwt,_wt,Hde,vwt,bwt,Fwt,DB,Twt,tBe,Mwt,Ewt,Cwt,Ea,GB,wwt,aBe,Awt,Lwt,qm,ywt,nBe,xwt,$wt,Jde,kwt,Swt,Rwt,py,Pwt,mt,OB,Bwt,sBe,Iwt,Nwt,ls,qwt,lBe,jwt,Dwt,iBe,Gwt,Owt,dBe,Vwt,Xwt,zwt,VB,_y,cBe,Qwt,Wwt,Yde,Uwt,Hwt,Jwt,vy,fBe,Ywt,Zwt,Zde,Kwt,eAt,oAt,by,Dno,jm,Fy,mBe,XB,rAt,gBe,tAt,Gno,Nr,zB,aAt,Dm,nAt,Kde,sAt,lAt,ece,iAt,dAt,cAt,QB,fAt,hBe,mAt,gAt,hAt,Ca,WB,uAt,uBe,pAt,_At,Gm,vAt,pBe,bAt,FAt,oce,TAt,MAt,EAt,Ty,CAt,gt,UB,wAt,_Be,AAt,LAt,is,yAt,vBe,xAt,$At,bBe,kAt,SAt,FBe,RAt,PAt,BAt,TBe,My,MBe,IAt,NAt,rce,qAt,jAt,DAt,Ey,Ono;return d=new oe({}),on=new B({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),d$=new oe({}),c$=new B({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Jm=new GAt({props:{warning:!0,$$slots:{default:[yCa]},$$scope:{ctx:$}}}),f$=new oe({}),m$=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/configuration_auto.py#L665"}}),u$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/configuration_auto.py#L688"}}),wu=new N({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[xCa]},$$scope:{ctx:$}}}),p$=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/configuration_auto.py#L811"}}),_$=new oe({}),v$=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/tokenization_auto.py#L437"}}),T$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/v4.24.0/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/tokenization_auto.py#L451"}}),cp=new N({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[$Ca]},$$scope:{ctx:$}}}),M$=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/tokenization_auto.py#L652"}}),E$=new oe({}),C$=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/feature_extraction_auto.py#L204"}}),L$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/v4.24.0/en/internal/image_processing_utils#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/feature_extraction_auto.py#L218"}}),t_=new GAt({props:{$$slots:{default:[kCa]},$$scope:{ctx:$}}}),a_=new N({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[SCa]},$$scope:{ctx:$}}}),y$=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/feature_extraction_auto.py#L345"}}),x$=new oe({}),$$=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/processing_auto.py#L95"}}),R$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/processing_auto.py#L109"}}),x_=new GAt({props:{$$slots:{default:[RCa]},$$scope:{ctx:$}}}),$_=new N({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[PCa]},$$scope:{ctx:$}}}),P$=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/processing_auto.py#L276"}}),B$=new oe({}),I$=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L887"}}),q$=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/conditional_detr#transformers.ConditionalDetrModel">ConditionalDetrModel</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deformable_detr#transformers.DeformableDetrModel">DeformableDetrModel</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/donut#transformers.DonutSwinConfig">DonutSwinConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/donut#transformers.DonutSwinModel">DonutSwinModel</a> (DonutSwin model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieModel">ErnieModel</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/esm#transformers.EsmModel">EsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel">GPTNeoXJapaneseModel</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/lilt#transformers.LiltModel">LiltModel</a> (LiLT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/markuplm#transformers.MarkupLMModel">MarkupLMModel</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mobilevit#transformers.MobileViTModel">MobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/owlvit#transformers.OwlViTModel">OwlViTModel</a> (OWL-ViT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/pegasus_x#transformers.PegasusXModel">PegasusXModel</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/swinv2#transformers.Swinv2Model">Swinv2Model</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/table-transformer#transformers.TableTransformerConfig">TableTransformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/table-transformer#transformers.TableTransformerModel">TableTransformerModel</a> (Table Transformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig">TimeSeriesTransformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel">TimeSeriesTransformerModel</a> (Time Series Transformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/vit_msn#transformers.ViTMSNModel">ViTMSNModel</a> (ViTMSN model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/videomae#transformers.VideoMAEModel">VideoMAEModel</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/whisper#transformers.WhisperModel">WhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xclip#transformers.XCLIPConfig">XCLIPConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xclip#transformers.XCLIPModel">XCLIPModel</a> (X-CLIP model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),R_=new N({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[BCa]},$$scope:{ctx:$}}}),j$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),ov=new N({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[ICa]},$$scope:{ctx:$}}}),D$=new oe({}),G$=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L894"}}),V$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieForPreTraining">ErnieForPreTraining</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/videomae#transformers.VideoMAEForPreTraining">VideoMAEForPreTraining</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),tv=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[NCa]},$$scope:{ctx:$}}}),X$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),Kv=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[qCa]},$$scope:{ctx:$}}}),z$=new oe({}),Q$=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L909"}}),U$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieForCausalLM">ErnieForCausalLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM">GPTNeoXJapaneseForCausalLM</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),o1=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[jCa]},$$scope:{ctx:$}}}),H$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),z1=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[DCa]},$$scope:{ctx:$}}}),J$=new oe({}),Y$=new R({props:{name:"class transformers.AutoModelForDepthEstimation",anchor:"transformers.AutoModelForDepthEstimation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L1052"}}),K$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDepthEstimation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDepthEstimation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/dpt#transformers.DPTForDepthEstimation">DPTForDepthEstimation</a> (DPT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/glpn#transformers.GLPNForDepthEstimation">GLPNForDepthEstimation</a> (GLPN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),W1=new N({props:{anchor:"transformers.AutoModelForDepthEstimation.from_config.example",$$slots:{default:[GCa]},$$scope:{ctx:$}}}),ek=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDepthEstimation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),Y1=new N({props:{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.example",$$slots:{default:[OCa]},$$scope:{ctx:$}}}),rk=new oe({}),tk=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L916"}}),nk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieForMaskedLM">ErnieForMaskedLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),K1=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[VCa]},$$scope:{ctx:$}}}),sk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),Db=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[XCa]},$$scope:{ctx:$}}}),lk=new oe({}),ik=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L923"}}),ck=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration">PegasusXForConditionalGeneration</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),Ob=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[zCa]},$$scope:{ctx:$}}}),fk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),c0=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[QCa]},$$scope:{ctx:$}}}),mk=new oe({}),gk=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L932"}}),uk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieForSequenceClassification">ErnieForSequenceClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/esm#transformers.EsmForSequenceClassification">EsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/lilt#transformers.LiltForSequenceClassification">LiltForSequenceClassification</a> (LiLT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/luke#transformers.LukeForSequenceClassification">LukeForSequenceClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification">MarkupLMForSequenceClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/opt#transformers.OPTForSequenceClassification">OPTForSequenceClassification</a> (OPT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),m0=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[WCa]},$$scope:{ctx:$}}}),pk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),pF=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[UCa]},$$scope:{ctx:$}}}),_k=new oe({}),vk=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L988"}}),Fk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieForMultipleChoice">ErnieForMultipleChoice</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/luke#transformers.LukeForMultipleChoice">LukeForMultipleChoice</a> (LUKE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),vF=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[HCa]},$$scope:{ctx:$}}}),Tk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),ZF=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[JCa]},$$scope:{ctx:$}}}),Mk=new oe({}),Ek=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L995"}}),wk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction">ErnieForNextSentencePrediction</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),eT=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[YCa]},$$scope:{ctx:$}}}),Ak=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),dT=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[ZCa]},$$scope:{ctx:$}}}),Lk=new oe({}),yk=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L981"}}),$k=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieForTokenClassification">ErnieForTokenClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/esm#transformers.EsmForTokenClassification">EsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/lilt#transformers.LiltForTokenClassification">LiltForTokenClassification</a> (LiLT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/luke#transformers.LukeForTokenClassification">LukeForTokenClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification">MarkupLMForTokenClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),fT=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[KCa]},$$scope:{ctx:$}}}),kk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),eM=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[e3a]},$$scope:{ctx:$}}}),Sk=new oe({}),Rk=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L941"}}),Bk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bloom#transformers.BloomForQuestionAnswering">BloomForQuestionAnswering</a> (BLOOM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieForQuestionAnswering">ErnieForQuestionAnswering</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/lilt#transformers.LiltForQuestionAnswering">LiltForQuestionAnswering</a> (LiLT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/luke#transformers.LukeForQuestionAnswering">LukeForQuestionAnswering</a> (LUKE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering">MarkupLMForQuestionAnswering</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/opt#transformers.OPTForQuestionAnswering">OPTForQuestionAnswering</a> (OPT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),rM=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[o3a]},$$scope:{ctx:$}}}),Ik=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),ZM=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[r3a]},$$scope:{ctx:$}}}),Nk=new oe({}),qk=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L948"}}),Dk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),eE=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[t3a]},$$scope:{ctx:$}}}),Gk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),tE=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[a3a]},$$scope:{ctx:$}}}),Ok=new oe({}),Vk=new R({props:{name:"class transformers.AutoModelForDocumentQuestionAnswering",anchor:"transformers.AutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L970"}}),zk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering">LayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),nE=new N({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[n3a]},$$scope:{ctx:$}}}),Qk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),cE=new N({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[s3a]},$$scope:{ctx:$}}}),Wk=new oe({}),Uk=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L1004"}}),Jk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/v4.24.0/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/v4.24.0/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mobilevit#transformers.MobileViTForImageClassification">MobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/v4.24.0/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/v4.24.0/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/swinv2#transformers.Swinv2ForImageClassification">Swinv2ForImageClassification</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification">ViTMSNForImageClassification</a> (ViTMSN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),mE=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[l3a]},$$scope:{ctx:$}}}),Yk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),xE=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[i3a]},$$scope:{ctx:$}}}),Zk=new oe({}),Kk=new R({props:{name:"class transformers.AutoModelForVideoClassification",anchor:"transformers.AutoModelForVideoClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L1059"}}),oS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVideoClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/videomae#transformers.VideoMAEForVideoClassification">VideoMAEForVideoClassification</a> (VideoMAE model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),kE=new N({props:{anchor:"transformers.AutoModelForVideoClassification.from_config.example",$$slots:{default:[d3a]},$$scope:{ctx:$}}}),rS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVideoClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),PE=new N({props:{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.example",$$slots:{default:[c3a]},$$scope:{ctx:$}}}),tS=new oe({}),aS=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L1066"}}),sS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),IE=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[f3a]},$$scope:{ctx:$}}}),lS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),jE=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[m3a]},$$scope:{ctx:$}}}),iS=new oe({}),dS=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L959"}}),fS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),GE=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[g3a]},$$scope:{ctx:$}}}),mS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),XE=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[h3a]},$$scope:{ctx:$}}}),gS=new oe({}),hS=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L1073"}}),pS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),QE=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[u3a]},$$scope:{ctx:$}}}),_S=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),tC=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[p3a]},$$scope:{ctx:$}}}),vS=new oe({}),bS=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L1096"}}),TS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),nC=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[_3a]},$$scope:{ctx:$}}}),MS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),mC=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[v3a]},$$scope:{ctx:$}}}),ES=new oe({}),CS=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L1080"}}),AS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),hC=new N({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[b3a]},$$scope:{ctx:$}}}),LS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),AC=new N({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[F3a]},$$scope:{ctx:$}}}),yS=new oe({}),xS=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L1087"}}),kS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/whisper#transformers.WhisperForConditionalGeneration">WhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),yC=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[T3a]},$$scope:{ctx:$}}}),SS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),RC=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[M3a]},$$scope:{ctx:$}}}),RS=new oe({}),PS=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L1105"}}),IS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),BC=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[E3a]},$$scope:{ctx:$}}}),NS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),OC=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[C3a]},$$scope:{ctx:$}}}),qS=new oe({}),jS=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L1112"}}),GS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling">Swinv2ForMaskedImageModeling</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),XC=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[w3a]},$$scope:{ctx:$}}}),OS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),JC=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[A3a]},$$scope:{ctx:$}}}),VS=new oe({}),XS=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L1036"}}),QS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection">ConditionalDetrForObjectDetection</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection">DeformableDetrForObjectDetection</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/table-transformer#transformers.TableTransformerConfig">TableTransformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection">TableTransformerForObjectDetection</a> (Table Transformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),ZC=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[L3a]},$$scope:{ctx:$}}}),WS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),n3=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[y3a]},$$scope:{ctx:$}}}),US=new oe({}),HS=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L1011"}}),YS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),l3=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[x3a]},$$scope:{ctx:$}}}),ZS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),c3=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[$3a]},$$scope:{ctx:$}}}),KS=new oe({}),eR=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L1018"}}),rR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation">MobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),m3=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[k3a]},$$scope:{ctx:$}}}),tR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),b3=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[S3a]},$$scope:{ctx:$}}}),aR=new oe({}),nR=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L1027"}}),lR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),T3=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[R3a]},$$scope:{ctx:$}}}),iR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),C3=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[P3a]},$$scope:{ctx:$}}}),dR=new oe({}),cR=new R({props:{name:"class transformers.AutoModelForZeroShotObjectDetection",anchor:"transformers.AutoModelForZeroShotObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_auto.py#L1043"}}),mR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/owlvit#transformers.OwlViTForObjectDetection">OwlViTForObjectDetection</a> (OWL-ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),A3=new N({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.example",$$slots:{default:[B3a]},$$scope:{ctx:$}}}),gR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),x3=new N({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.example",$$slots:{default:[I3a]},$$scope:{ctx:$}}}),hR=new oe({}),uR=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_tf_auto.py#L444"}}),_R=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/cvt#transformers.TFCvtModel">TFCvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deit#transformers.TFDeiTModel">TFDeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/esm#transformers.TFEsmModel">TFEsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/groupvit#transformers.TFGroupViTModel">TFGroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model">TFLayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mobilevit#transformers.TFMobileViTModel">TFMobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/segformer#transformers.TFSegformerModel">TFSegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/whisper#transformers.TFWhisperModel">TFWhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xglm#transformers.TFXGLMModel">TFXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),k3=new N({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[N3a]},$$scope:{ctx:$}}}),vR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),B5=new N({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[q3a]},$$scope:{ctx:$}}}),bR=new oe({}),FR=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_tf_auto.py#L451"}}),MR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),N5=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[j3a]},$$scope:{ctx:$}}}),ER=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),lw=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[D3a]},$$scope:{ctx:$}}}),CR=new oe({}),wR=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_tf_auto.py#L466"}}),LR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xglm#transformers.TFXGLMForCausalLM">TFXGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),dw=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[G3a]},$$scope:{ctx:$}}}),yR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),Cw=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[O3a]},$$scope:{ctx:$}}}),xR=new oe({}),$R=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_tf_auto.py#L482"}}),SR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/cvt#transformers.TFCvtForImageClassification">TFCvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deit#transformers.TFDeiTForImageClassification">TFDeiTForImageClassification</a> or <a href="/docs/transformers/v4.24.0/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher">TFDeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification">TFMobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/segformer#transformers.TFSegformerForImageClassification">TFSegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),Aw=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[V3a]},$$scope:{ctx:$}}}),RR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),Iw=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[X3a]},$$scope:{ctx:$}}}),PR=new oe({}),BR=new R({props:{name:"class transformers.TFAutoModelForSemanticSegmentation",anchor:"transformers.TFAutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_tf_auto.py#L491"}}),NR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation">TFData2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation">TFMobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation">TFSegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),qw=new N({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[z3a]},$$scope:{ctx:$}}}),qR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),Ow=new N({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[Q3a]},$$scope:{ctx:$}}}),jR=new oe({}),DR=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_tf_auto.py#L507"}}),OR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/esm#transformers.TFEsmForMaskedLM">TFEsmForMaskedLM</a> (ESM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),Xw=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[W3a]},$$scope:{ctx:$}}}),VR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),mA=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[U3a]},$$scope:{ctx:$}}}),XR=new oe({}),zR=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_tf_auto.py#L514"}}),WR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),hA=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[H3a]},$$scope:{ctx:$}}}),UR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),wA=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[J3a]},$$scope:{ctx:$}}}),HR=new oe({}),JR=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_tf_auto.py#L523"}}),ZR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/esm#transformers.TFEsmForSequenceClassification">TFEsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification">TFLayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),LA=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[Y3a]},$$scope:{ctx:$}}}),KR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),r6=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Z3a]},$$scope:{ctx:$}}}),eP=new oe({}),oP=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_tf_auto.py#L570"}}),tP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),a6=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[K3a]},$$scope:{ctx:$}}}),aP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),M6=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[e5a]},$$scope:{ctx:$}}}),nP=new oe({}),sP=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_tf_auto.py#L577"}}),iP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),C6=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[o5a]},$$scope:{ctx:$}}}),dP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),L6=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[r5a]},$$scope:{ctx:$}}}),fP=new oe({}),mP=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_tf_auto.py#L550"}}),hP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),x6=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[t5a]},$$scope:{ctx:$}}}),uP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),k6=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[a5a]},$$scope:{ctx:$}}}),pP=new oe({}),_P=new R({props:{name:"class transformers.TFAutoModelForDocumentQuestionAnswering",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_tf_auto.py#L539"}}),bP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering">TFLayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),R6=new N({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[n5a]},$$scope:{ctx:$}}}),FP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),B6=new N({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[s5a]},$$scope:{ctx:$}}}),TP=new oe({}),MP=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_tf_auto.py#L561"}}),CP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/esm#transformers.TFEsmForTokenClassification">TFEsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification">TFLayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),N6=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[l5a]},$$scope:{ctx:$}}}),wP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),s7=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[i5a]},$$scope:{ctx:$}}}),AP=new oe({}),LP=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_tf_auto.py#L532"}}),xP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering">TFLayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),i7=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[d5a]},$$scope:{ctx:$}}}),$P=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),$7=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[c5a]},$$scope:{ctx:$}}}),kP=new oe({}),SP=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_tf_auto.py#L500"}}),PP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),S7=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[f5a]},$$scope:{ctx:$}}}),BP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),P7=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[m5a]},$$scope:{ctx:$}}}),IP=new oe({}),NP=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_tf_auto.py#L586"}}),jP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration">TFWhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),I7=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[g5a]},$$scope:{ctx:$}}}),DP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),j7=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[h5a]},$$scope:{ctx:$}}}),OP=new oe({}),VP=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),zP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),G7=new N({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[u5a]},$$scope:{ctx:$}}}),QP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),u8=new N({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[p5a]},$$scope:{ctx:$}}}),WP=new oe({}),UP=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),JP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),_8=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[_5a]},$$scope:{ctx:$}}}),YP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),y8=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[v5a]},$$scope:{ctx:$}}}),ZP=new oe({}),KP=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),oB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),$8=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[b5a]},$$scope:{ctx:$}}}),rB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),X8=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[F5a]},$$scope:{ctx:$}}}),tB=new oe({}),aB=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),sB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),Q8=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[T5a]},$$scope:{ctx:$}}}),lB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),tL=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[M5a]},$$scope:{ctx:$}}}),iB=new oe({}),dB=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),fB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),nL=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[E5a]},$$scope:{ctx:$}}}),mB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),pL=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[C5a]},$$scope:{ctx:$}}}),gB=new oe({}),hB=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),pB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),vL=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[w5a]},$$scope:{ctx:$}}}),_B=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),xL=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[A5a]},$$scope:{ctx:$}}}),vB=new oe({}),bB=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),TB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),kL=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[L5a]},$$scope:{ctx:$}}}),MB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),OL=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[y5a]},$$scope:{ctx:$}}}),EB=new oe({}),CB=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),AB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),XL=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[x5a]},$$scope:{ctx:$}}}),LB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),KL=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[$5a]},$$scope:{ctx:$}}}),yB=new oe({}),xB=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),kB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),oy=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[k5a]},$$scope:{ctx:$}}}),SB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),cy=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[S5a]},$$scope:{ctx:$}}}),RB=new oe({}),PB=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),IB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),my=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[R5a]},$$scope:{ctx:$}}}),NB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),hy=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[P5a]},$$scope:{ctx:$}}}),qB=new oe({}),jB=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),GB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),py=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[B5a]},$$scope:{ctx:$}}}),OB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),by=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[I5a]},$$scope:{ctx:$}}}),XB=new oe({}),zB=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),WB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.24.0/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.24.0/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L389"}}),Ty=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[N5a]},$$scope:{ctx:$}}}),UB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.24.0/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/auto/auto_factory.py#L417"}}),Ey=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[q5a]},$$scope:{ctx:$}}}),{c(){g=a("meta"),b=l(),u=a("h1"),m=a("a"),p=a("span"),F(d.$$.fragment),h=l(),$o=a("span"),vd=o("Auto Classes"),zm=l(),Tt=a("p"),bd=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Fd=a("code"),n$=o("from_pretrained()"),Qm=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Xe=l(),He=a("p"),Td=o("Instantiating one of "),cs=a("a"),s$=o("AutoConfig"),fs=o(", "),ms=a("a"),l$=o("AutoModel"),Md=o(`, and
`),gs=a("a"),i$=o("AutoTokenizer"),Ed=o(" will directly create a class of the relevant architecture. For instance"),Wm=l(),F(on.$$.fragment),Je=l(),Ae=a("p"),MN=o("will create a model that is an instance of "),Cd=a("a"),EN=o("BertModel"),CN=o("."),ko=l(),rn=a("p"),wN=o("There is one class of "),Um=a("code"),AN=o("AutoModel"),cio=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),wto=l(),wd=a("h2"),Hm=a("a"),fme=a("span"),F(d$.$$.fragment),fio=l(),mme=a("span"),mio=o("Extending the Auto Classes"),Ato=l(),hs=a("p"),gio=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),gme=a("code"),hio=o("NewModel"),uio=o(", make sure you have a "),hme=a("code"),pio=o("NewModelConfig"),_io=o(` then you can add those to the auto
classes like this:`),Lto=l(),F(c$.$$.fragment),yto=l(),LN=a("p"),vio=o("You will then be able to use the auto classes like you would usually do!"),xto=l(),F(Jm.$$.fragment),$to=l(),Ad=a("h2"),Ym=a("a"),ume=a("span"),F(f$.$$.fragment),bio=l(),pme=a("span"),Fio=o("AutoConfig"),kto=l(),So=a("div"),F(m$.$$.fragment),Tio=l(),g$=a("p"),Mio=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),yN=a("a"),Eio=o("from_pretrained()"),Cio=o(" class method."),wio=l(),h$=a("p"),Aio=o("This class cannot be instantiated directly using "),_me=a("code"),Lio=o("__init__()"),yio=o(" (throws an error)."),xio=l(),qr=a("div"),F(u$.$$.fragment),$io=l(),vme=a("p"),kio=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),Sio=l(),Ld=a("p"),Rio=o("The configuration class to instantiate is selected based on the "),bme=a("code"),Pio=o("model_type"),Bio=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Fme=a("code"),Iio=o("pretrained_model_name_or_path"),Nio=o(":"),qio=l(),A=a("ul"),Zm=a("li"),Tme=a("strong"),jio=o("albert"),Dio=o(" \u2014 "),xN=a("a"),Gio=o("AlbertConfig"),Oio=o(" (ALBERT model)"),Vio=l(),Km=a("li"),Mme=a("strong"),Xio=o("bart"),zio=o(" \u2014 "),$N=a("a"),Qio=o("BartConfig"),Wio=o(" (BART model)"),Uio=l(),eg=a("li"),Eme=a("strong"),Hio=o("beit"),Jio=o(" \u2014 "),kN=a("a"),Yio=o("BeitConfig"),Zio=o(" (BEiT model)"),Kio=l(),og=a("li"),Cme=a("strong"),edo=o("bert"),odo=o(" \u2014 "),SN=a("a"),rdo=o("BertConfig"),tdo=o(" (BERT model)"),ado=l(),rg=a("li"),wme=a("strong"),ndo=o("bert-generation"),sdo=o(" \u2014 "),RN=a("a"),ldo=o("BertGenerationConfig"),ido=o(" (Bert Generation model)"),ddo=l(),tg=a("li"),Ame=a("strong"),cdo=o("big_bird"),fdo=o(" \u2014 "),PN=a("a"),mdo=o("BigBirdConfig"),gdo=o(" (BigBird model)"),hdo=l(),ag=a("li"),Lme=a("strong"),udo=o("bigbird_pegasus"),pdo=o(" \u2014 "),BN=a("a"),_do=o("BigBirdPegasusConfig"),vdo=o(" (BigBird-Pegasus model)"),bdo=l(),ng=a("li"),yme=a("strong"),Fdo=o("blenderbot"),Tdo=o(" \u2014 "),IN=a("a"),Mdo=o("BlenderbotConfig"),Edo=o(" (Blenderbot model)"),Cdo=l(),sg=a("li"),xme=a("strong"),wdo=o("blenderbot-small"),Ado=o(" \u2014 "),NN=a("a"),Ldo=o("BlenderbotSmallConfig"),ydo=o(" (BlenderbotSmall model)"),xdo=l(),lg=a("li"),$me=a("strong"),$do=o("bloom"),kdo=o(" \u2014 "),qN=a("a"),Sdo=o("BloomConfig"),Rdo=o(" (BLOOM model)"),Pdo=l(),ig=a("li"),kme=a("strong"),Bdo=o("camembert"),Ido=o(" \u2014 "),jN=a("a"),Ndo=o("CamembertConfig"),qdo=o(" (CamemBERT model)"),jdo=l(),dg=a("li"),Sme=a("strong"),Ddo=o("canine"),Gdo=o(" \u2014 "),DN=a("a"),Odo=o("CanineConfig"),Vdo=o(" (CANINE model)"),Xdo=l(),cg=a("li"),Rme=a("strong"),zdo=o("clip"),Qdo=o(" \u2014 "),GN=a("a"),Wdo=o("CLIPConfig"),Udo=o(" (CLIP model)"),Hdo=l(),fg=a("li"),Pme=a("strong"),Jdo=o("codegen"),Ydo=o(" \u2014 "),ON=a("a"),Zdo=o("CodeGenConfig"),Kdo=o(" (CodeGen model)"),eco=l(),mg=a("li"),Bme=a("strong"),oco=o("conditional_detr"),rco=o(" \u2014 "),VN=a("a"),tco=o("ConditionalDetrConfig"),aco=o(" (Conditional DETR model)"),nco=l(),gg=a("li"),Ime=a("strong"),sco=o("convbert"),lco=o(" \u2014 "),XN=a("a"),ico=o("ConvBertConfig"),dco=o(" (ConvBERT model)"),cco=l(),hg=a("li"),Nme=a("strong"),fco=o("convnext"),mco=o(" \u2014 "),zN=a("a"),gco=o("ConvNextConfig"),hco=o(" (ConvNeXT model)"),uco=l(),ug=a("li"),qme=a("strong"),pco=o("ctrl"),_co=o(" \u2014 "),QN=a("a"),vco=o("CTRLConfig"),bco=o(" (CTRL model)"),Fco=l(),pg=a("li"),jme=a("strong"),Tco=o("cvt"),Mco=o(" \u2014 "),WN=a("a"),Eco=o("CvtConfig"),Cco=o(" (CvT model)"),wco=l(),_g=a("li"),Dme=a("strong"),Aco=o("data2vec-audio"),Lco=o(" \u2014 "),UN=a("a"),yco=o("Data2VecAudioConfig"),xco=o(" (Data2VecAudio model)"),$co=l(),vg=a("li"),Gme=a("strong"),kco=o("data2vec-text"),Sco=o(" \u2014 "),HN=a("a"),Rco=o("Data2VecTextConfig"),Pco=o(" (Data2VecText model)"),Bco=l(),bg=a("li"),Ome=a("strong"),Ico=o("data2vec-vision"),Nco=o(" \u2014 "),JN=a("a"),qco=o("Data2VecVisionConfig"),jco=o(" (Data2VecVision model)"),Dco=l(),Fg=a("li"),Vme=a("strong"),Gco=o("deberta"),Oco=o(" \u2014 "),YN=a("a"),Vco=o("DebertaConfig"),Xco=o(" (DeBERTa model)"),zco=l(),Tg=a("li"),Xme=a("strong"),Qco=o("deberta-v2"),Wco=o(" \u2014 "),ZN=a("a"),Uco=o("DebertaV2Config"),Hco=o(" (DeBERTa-v2 model)"),Jco=l(),Mg=a("li"),zme=a("strong"),Yco=o("decision_transformer"),Zco=o(" \u2014 "),KN=a("a"),Kco=o("DecisionTransformerConfig"),efo=o(" (Decision Transformer model)"),ofo=l(),Eg=a("li"),Qme=a("strong"),rfo=o("deformable_detr"),tfo=o(" \u2014 "),eq=a("a"),afo=o("DeformableDetrConfig"),nfo=o(" (Deformable DETR model)"),sfo=l(),Cg=a("li"),Wme=a("strong"),lfo=o("deit"),ifo=o(" \u2014 "),oq=a("a"),dfo=o("DeiTConfig"),cfo=o(" (DeiT model)"),ffo=l(),wg=a("li"),Ume=a("strong"),mfo=o("detr"),gfo=o(" \u2014 "),rq=a("a"),hfo=o("DetrConfig"),ufo=o(" (DETR model)"),pfo=l(),Ag=a("li"),Hme=a("strong"),_fo=o("distilbert"),vfo=o(" \u2014 "),tq=a("a"),bfo=o("DistilBertConfig"),Ffo=o(" (DistilBERT model)"),Tfo=l(),Lg=a("li"),Jme=a("strong"),Mfo=o("donut-swin"),Efo=o(" \u2014 "),aq=a("a"),Cfo=o("DonutSwinConfig"),wfo=o(" (DonutSwin model)"),Afo=l(),yg=a("li"),Yme=a("strong"),Lfo=o("dpr"),yfo=o(" \u2014 "),nq=a("a"),xfo=o("DPRConfig"),$fo=o(" (DPR model)"),kfo=l(),xg=a("li"),Zme=a("strong"),Sfo=o("dpt"),Rfo=o(" \u2014 "),sq=a("a"),Pfo=o("DPTConfig"),Bfo=o(" (DPT model)"),Ifo=l(),$g=a("li"),Kme=a("strong"),Nfo=o("electra"),qfo=o(" \u2014 "),lq=a("a"),jfo=o("ElectraConfig"),Dfo=o(" (ELECTRA model)"),Gfo=l(),kg=a("li"),ege=a("strong"),Ofo=o("encoder-decoder"),Vfo=o(" \u2014 "),iq=a("a"),Xfo=o("EncoderDecoderConfig"),zfo=o(" (Encoder decoder model)"),Qfo=l(),Sg=a("li"),oge=a("strong"),Wfo=o("ernie"),Ufo=o(" \u2014 "),dq=a("a"),Hfo=o("ErnieConfig"),Jfo=o(" (ERNIE model)"),Yfo=l(),Rg=a("li"),rge=a("strong"),Zfo=o("esm"),Kfo=o(" \u2014 "),cq=a("a"),emo=o("EsmConfig"),omo=o(" (ESM model)"),rmo=l(),Pg=a("li"),tge=a("strong"),tmo=o("flaubert"),amo=o(" \u2014 "),fq=a("a"),nmo=o("FlaubertConfig"),smo=o(" (FlauBERT model)"),lmo=l(),Bg=a("li"),age=a("strong"),imo=o("flava"),dmo=o(" \u2014 "),mq=a("a"),cmo=o("FlavaConfig"),fmo=o(" (FLAVA model)"),mmo=l(),Ig=a("li"),nge=a("strong"),gmo=o("fnet"),hmo=o(" \u2014 "),gq=a("a"),umo=o("FNetConfig"),pmo=o(" (FNet model)"),_mo=l(),Ng=a("li"),sge=a("strong"),vmo=o("fsmt"),bmo=o(" \u2014 "),hq=a("a"),Fmo=o("FSMTConfig"),Tmo=o(" (FairSeq Machine-Translation model)"),Mmo=l(),qg=a("li"),lge=a("strong"),Emo=o("funnel"),Cmo=o(" \u2014 "),uq=a("a"),wmo=o("FunnelConfig"),Amo=o(" (Funnel Transformer model)"),Lmo=l(),jg=a("li"),ige=a("strong"),ymo=o("glpn"),xmo=o(" \u2014 "),pq=a("a"),$mo=o("GLPNConfig"),kmo=o(" (GLPN model)"),Smo=l(),Dg=a("li"),dge=a("strong"),Rmo=o("gpt2"),Pmo=o(" \u2014 "),_q=a("a"),Bmo=o("GPT2Config"),Imo=o(" (OpenAI GPT-2 model)"),Nmo=l(),Gg=a("li"),cge=a("strong"),qmo=o("gpt_neo"),jmo=o(" \u2014 "),vq=a("a"),Dmo=o("GPTNeoConfig"),Gmo=o(" (GPT Neo model)"),Omo=l(),Og=a("li"),fge=a("strong"),Vmo=o("gpt_neox"),Xmo=o(" \u2014 "),bq=a("a"),zmo=o("GPTNeoXConfig"),Qmo=o(" (GPT NeoX model)"),Wmo=l(),Vg=a("li"),mge=a("strong"),Umo=o("gpt_neox_japanese"),Hmo=o(" \u2014 "),Fq=a("a"),Jmo=o("GPTNeoXJapaneseConfig"),Ymo=o(" (GPT NeoX Japanese model)"),Zmo=l(),Xg=a("li"),gge=a("strong"),Kmo=o("gptj"),ego=o(" \u2014 "),Tq=a("a"),ogo=o("GPTJConfig"),rgo=o(" (GPT-J model)"),tgo=l(),zg=a("li"),hge=a("strong"),ago=o("groupvit"),ngo=o(" \u2014 "),Mq=a("a"),sgo=o("GroupViTConfig"),lgo=o(" (GroupViT model)"),igo=l(),Qg=a("li"),uge=a("strong"),dgo=o("hubert"),cgo=o(" \u2014 "),Eq=a("a"),fgo=o("HubertConfig"),mgo=o(" (Hubert model)"),ggo=l(),Wg=a("li"),pge=a("strong"),hgo=o("ibert"),ugo=o(" \u2014 "),Cq=a("a"),pgo=o("IBertConfig"),_go=o(" (I-BERT model)"),vgo=l(),Ug=a("li"),_ge=a("strong"),bgo=o("imagegpt"),Fgo=o(" \u2014 "),wq=a("a"),Tgo=o("ImageGPTConfig"),Mgo=o(" (ImageGPT model)"),Ego=l(),Hg=a("li"),vge=a("strong"),Cgo=o("layoutlm"),wgo=o(" \u2014 "),Aq=a("a"),Ago=o("LayoutLMConfig"),Lgo=o(" (LayoutLM model)"),ygo=l(),Jg=a("li"),bge=a("strong"),xgo=o("layoutlmv2"),$go=o(" \u2014 "),Lq=a("a"),kgo=o("LayoutLMv2Config"),Sgo=o(" (LayoutLMv2 model)"),Rgo=l(),Yg=a("li"),Fge=a("strong"),Pgo=o("layoutlmv3"),Bgo=o(" \u2014 "),yq=a("a"),Igo=o("LayoutLMv3Config"),Ngo=o(" (LayoutLMv3 model)"),qgo=l(),Zg=a("li"),Tge=a("strong"),jgo=o("led"),Dgo=o(" \u2014 "),xq=a("a"),Ggo=o("LEDConfig"),Ogo=o(" (LED model)"),Vgo=l(),Kg=a("li"),Mge=a("strong"),Xgo=o("levit"),zgo=o(" \u2014 "),$q=a("a"),Qgo=o("LevitConfig"),Wgo=o(" (LeViT model)"),Ugo=l(),eh=a("li"),Ege=a("strong"),Hgo=o("lilt"),Jgo=o(" \u2014 "),kq=a("a"),Ygo=o("LiltConfig"),Zgo=o(" (LiLT model)"),Kgo=l(),oh=a("li"),Cge=a("strong"),eho=o("longformer"),oho=o(" \u2014 "),Sq=a("a"),rho=o("LongformerConfig"),tho=o(" (Longformer model)"),aho=l(),rh=a("li"),wge=a("strong"),nho=o("longt5"),sho=o(" \u2014 "),Rq=a("a"),lho=o("LongT5Config"),iho=o(" (LongT5 model)"),dho=l(),th=a("li"),Age=a("strong"),cho=o("luke"),fho=o(" \u2014 "),Pq=a("a"),mho=o("LukeConfig"),gho=o(" (LUKE model)"),hho=l(),ah=a("li"),Lge=a("strong"),uho=o("lxmert"),pho=o(" \u2014 "),Bq=a("a"),_ho=o("LxmertConfig"),vho=o(" (LXMERT model)"),bho=l(),nh=a("li"),yge=a("strong"),Fho=o("m2m_100"),Tho=o(" \u2014 "),Iq=a("a"),Mho=o("M2M100Config"),Eho=o(" (M2M100 model)"),Cho=l(),sh=a("li"),xge=a("strong"),who=o("marian"),Aho=o(" \u2014 "),Nq=a("a"),Lho=o("MarianConfig"),yho=o(" (Marian model)"),xho=l(),lh=a("li"),$ge=a("strong"),$ho=o("markuplm"),kho=o(" \u2014 "),qq=a("a"),Sho=o("MarkupLMConfig"),Rho=o(" (MarkupLM model)"),Pho=l(),ih=a("li"),kge=a("strong"),Bho=o("maskformer"),Iho=o(" \u2014 "),jq=a("a"),Nho=o("MaskFormerConfig"),qho=o(" (MaskFormer model)"),jho=l(),dh=a("li"),Sge=a("strong"),Dho=o("mbart"),Gho=o(" \u2014 "),Dq=a("a"),Oho=o("MBartConfig"),Vho=o(" (mBART model)"),Xho=l(),ch=a("li"),Rge=a("strong"),zho=o("mctct"),Qho=o(" \u2014 "),Gq=a("a"),Who=o("MCTCTConfig"),Uho=o(" (M-CTC-T model)"),Hho=l(),fh=a("li"),Pge=a("strong"),Jho=o("megatron-bert"),Yho=o(" \u2014 "),Oq=a("a"),Zho=o("MegatronBertConfig"),Kho=o(" (Megatron-BERT model)"),euo=l(),mh=a("li"),Bge=a("strong"),ouo=o("mobilebert"),ruo=o(" \u2014 "),Vq=a("a"),tuo=o("MobileBertConfig"),auo=o(" (MobileBERT model)"),nuo=l(),gh=a("li"),Ige=a("strong"),suo=o("mobilevit"),luo=o(" \u2014 "),Xq=a("a"),iuo=o("MobileViTConfig"),duo=o(" (MobileViT model)"),cuo=l(),hh=a("li"),Nge=a("strong"),fuo=o("mpnet"),muo=o(" \u2014 "),zq=a("a"),guo=o("MPNetConfig"),huo=o(" (MPNet model)"),uuo=l(),uh=a("li"),qge=a("strong"),puo=o("mt5"),_uo=o(" \u2014 "),Qq=a("a"),vuo=o("MT5Config"),buo=o(" (MT5 model)"),Fuo=l(),ph=a("li"),jge=a("strong"),Tuo=o("mvp"),Muo=o(" \u2014 "),Wq=a("a"),Euo=o("MvpConfig"),Cuo=o(" (MVP model)"),wuo=l(),_h=a("li"),Dge=a("strong"),Auo=o("nezha"),Luo=o(" \u2014 "),Uq=a("a"),yuo=o("NezhaConfig"),xuo=o(" (Nezha model)"),$uo=l(),vh=a("li"),Gge=a("strong"),kuo=o("nystromformer"),Suo=o(" \u2014 "),Hq=a("a"),Ruo=o("NystromformerConfig"),Puo=o(" (Nystr\xF6mformer model)"),Buo=l(),bh=a("li"),Oge=a("strong"),Iuo=o("openai-gpt"),Nuo=o(" \u2014 "),Jq=a("a"),quo=o("OpenAIGPTConfig"),juo=o(" (OpenAI GPT model)"),Duo=l(),Fh=a("li"),Vge=a("strong"),Guo=o("opt"),Ouo=o(" \u2014 "),Yq=a("a"),Vuo=o("OPTConfig"),Xuo=o(" (OPT model)"),zuo=l(),Th=a("li"),Xge=a("strong"),Quo=o("owlvit"),Wuo=o(" \u2014 "),Zq=a("a"),Uuo=o("OwlViTConfig"),Huo=o(" (OWL-ViT model)"),Juo=l(),Mh=a("li"),zge=a("strong"),Yuo=o("pegasus"),Zuo=o(" \u2014 "),Kq=a("a"),Kuo=o("PegasusConfig"),epo=o(" (Pegasus model)"),opo=l(),Eh=a("li"),Qge=a("strong"),rpo=o("pegasus_x"),tpo=o(" \u2014 "),ej=a("a"),apo=o("PegasusXConfig"),npo=o(" (PEGASUS-X model)"),spo=l(),Ch=a("li"),Wge=a("strong"),lpo=o("perceiver"),ipo=o(" \u2014 "),oj=a("a"),dpo=o("PerceiverConfig"),cpo=o(" (Perceiver model)"),fpo=l(),wh=a("li"),Uge=a("strong"),mpo=o("plbart"),gpo=o(" \u2014 "),rj=a("a"),hpo=o("PLBartConfig"),upo=o(" (PLBart model)"),ppo=l(),Ah=a("li"),Hge=a("strong"),_po=o("poolformer"),vpo=o(" \u2014 "),tj=a("a"),bpo=o("PoolFormerConfig"),Fpo=o(" (PoolFormer model)"),Tpo=l(),Lh=a("li"),Jge=a("strong"),Mpo=o("prophetnet"),Epo=o(" \u2014 "),aj=a("a"),Cpo=o("ProphetNetConfig"),wpo=o(" (ProphetNet model)"),Apo=l(),yh=a("li"),Yge=a("strong"),Lpo=o("qdqbert"),ypo=o(" \u2014 "),nj=a("a"),xpo=o("QDQBertConfig"),$po=o(" (QDQBert model)"),kpo=l(),xh=a("li"),Zge=a("strong"),Spo=o("rag"),Rpo=o(" \u2014 "),sj=a("a"),Ppo=o("RagConfig"),Bpo=o(" (RAG model)"),Ipo=l(),$h=a("li"),Kge=a("strong"),Npo=o("realm"),qpo=o(" \u2014 "),lj=a("a"),jpo=o("RealmConfig"),Dpo=o(" (REALM model)"),Gpo=l(),kh=a("li"),ehe=a("strong"),Opo=o("reformer"),Vpo=o(" \u2014 "),ij=a("a"),Xpo=o("ReformerConfig"),zpo=o(" (Reformer model)"),Qpo=l(),Sh=a("li"),ohe=a("strong"),Wpo=o("regnet"),Upo=o(" \u2014 "),dj=a("a"),Hpo=o("RegNetConfig"),Jpo=o(" (RegNet model)"),Ypo=l(),Rh=a("li"),rhe=a("strong"),Zpo=o("rembert"),Kpo=o(" \u2014 "),cj=a("a"),e_o=o("RemBertConfig"),o_o=o(" (RemBERT model)"),r_o=l(),Ph=a("li"),the=a("strong"),t_o=o("resnet"),a_o=o(" \u2014 "),fj=a("a"),n_o=o("ResNetConfig"),s_o=o(" (ResNet model)"),l_o=l(),Bh=a("li"),ahe=a("strong"),i_o=o("retribert"),d_o=o(" \u2014 "),mj=a("a"),c_o=o("RetriBertConfig"),f_o=o(" (RetriBERT model)"),m_o=l(),Ih=a("li"),nhe=a("strong"),g_o=o("roberta"),h_o=o(" \u2014 "),gj=a("a"),u_o=o("RobertaConfig"),p_o=o(" (RoBERTa model)"),__o=l(),Nh=a("li"),she=a("strong"),v_o=o("roformer"),b_o=o(" \u2014 "),hj=a("a"),F_o=o("RoFormerConfig"),T_o=o(" (RoFormer model)"),M_o=l(),qh=a("li"),lhe=a("strong"),E_o=o("segformer"),C_o=o(" \u2014 "),uj=a("a"),w_o=o("SegformerConfig"),A_o=o(" (SegFormer model)"),L_o=l(),jh=a("li"),ihe=a("strong"),y_o=o("sew"),x_o=o(" \u2014 "),pj=a("a"),$_o=o("SEWConfig"),k_o=o(" (SEW model)"),S_o=l(),Dh=a("li"),dhe=a("strong"),R_o=o("sew-d"),P_o=o(" \u2014 "),_j=a("a"),B_o=o("SEWDConfig"),I_o=o(" (SEW-D model)"),N_o=l(),Gh=a("li"),che=a("strong"),q_o=o("speech-encoder-decoder"),j_o=o(" \u2014 "),vj=a("a"),D_o=o("SpeechEncoderDecoderConfig"),G_o=o(" (Speech Encoder decoder model)"),O_o=l(),Oh=a("li"),fhe=a("strong"),V_o=o("speech_to_text"),X_o=o(" \u2014 "),bj=a("a"),z_o=o("Speech2TextConfig"),Q_o=o(" (Speech2Text model)"),W_o=l(),Vh=a("li"),mhe=a("strong"),U_o=o("speech_to_text_2"),H_o=o(" \u2014 "),Fj=a("a"),J_o=o("Speech2Text2Config"),Y_o=o(" (Speech2Text2 model)"),Z_o=l(),Xh=a("li"),ghe=a("strong"),K_o=o("splinter"),e4o=o(" \u2014 "),Tj=a("a"),o4o=o("SplinterConfig"),r4o=o(" (Splinter model)"),t4o=l(),zh=a("li"),hhe=a("strong"),a4o=o("squeezebert"),n4o=o(" \u2014 "),Mj=a("a"),s4o=o("SqueezeBertConfig"),l4o=o(" (SqueezeBERT model)"),i4o=l(),Qh=a("li"),uhe=a("strong"),d4o=o("swin"),c4o=o(" \u2014 "),Ej=a("a"),f4o=o("SwinConfig"),m4o=o(" (Swin Transformer model)"),g4o=l(),Wh=a("li"),phe=a("strong"),h4o=o("swinv2"),u4o=o(" \u2014 "),Cj=a("a"),p4o=o("Swinv2Config"),_4o=o(" (Swin Transformer V2 model)"),v4o=l(),Uh=a("li"),_he=a("strong"),b4o=o("t5"),F4o=o(" \u2014 "),wj=a("a"),T4o=o("T5Config"),M4o=o(" (T5 model)"),E4o=l(),Hh=a("li"),vhe=a("strong"),C4o=o("table-transformer"),w4o=o(" \u2014 "),Aj=a("a"),A4o=o("TableTransformerConfig"),L4o=o(" (Table Transformer model)"),y4o=l(),Jh=a("li"),bhe=a("strong"),x4o=o("tapas"),$4o=o(" \u2014 "),Lj=a("a"),k4o=o("TapasConfig"),S4o=o(" (TAPAS model)"),R4o=l(),Yh=a("li"),Fhe=a("strong"),P4o=o("time_series_transformer"),B4o=o(" \u2014 "),yj=a("a"),I4o=o("TimeSeriesTransformerConfig"),N4o=o(" (Time Series Transformer model)"),q4o=l(),Zh=a("li"),The=a("strong"),j4o=o("trajectory_transformer"),D4o=o(" \u2014 "),xj=a("a"),G4o=o("TrajectoryTransformerConfig"),O4o=o(" (Trajectory Transformer model)"),V4o=l(),Kh=a("li"),Mhe=a("strong"),X4o=o("transfo-xl"),z4o=o(" \u2014 "),$j=a("a"),Q4o=o("TransfoXLConfig"),W4o=o(" (Transformer-XL model)"),U4o=l(),eu=a("li"),Ehe=a("strong"),H4o=o("trocr"),J4o=o(" \u2014 "),kj=a("a"),Y4o=o("TrOCRConfig"),Z4o=o(" (TrOCR model)"),K4o=l(),ou=a("li"),Che=a("strong"),e2o=o("unispeech"),o2o=o(" \u2014 "),Sj=a("a"),r2o=o("UniSpeechConfig"),t2o=o(" (UniSpeech model)"),a2o=l(),ru=a("li"),whe=a("strong"),n2o=o("unispeech-sat"),s2o=o(" \u2014 "),Rj=a("a"),l2o=o("UniSpeechSatConfig"),i2o=o(" (UniSpeechSat model)"),d2o=l(),tu=a("li"),Ahe=a("strong"),c2o=o("van"),f2o=o(" \u2014 "),Pj=a("a"),m2o=o("VanConfig"),g2o=o(" (VAN model)"),h2o=l(),au=a("li"),Lhe=a("strong"),u2o=o("videomae"),p2o=o(" \u2014 "),Bj=a("a"),_2o=o("VideoMAEConfig"),v2o=o(" (VideoMAE model)"),b2o=l(),nu=a("li"),yhe=a("strong"),F2o=o("vilt"),T2o=o(" \u2014 "),Ij=a("a"),M2o=o("ViltConfig"),E2o=o(" (ViLT model)"),C2o=l(),su=a("li"),xhe=a("strong"),w2o=o("vision-encoder-decoder"),A2o=o(" \u2014 "),Nj=a("a"),L2o=o("VisionEncoderDecoderConfig"),y2o=o(" (Vision Encoder decoder model)"),x2o=l(),lu=a("li"),$he=a("strong"),$2o=o("vision-text-dual-encoder"),k2o=o(" \u2014 "),qj=a("a"),S2o=o("VisionTextDualEncoderConfig"),R2o=o(" (VisionTextDualEncoder model)"),P2o=l(),iu=a("li"),khe=a("strong"),B2o=o("visual_bert"),I2o=o(" \u2014 "),jj=a("a"),N2o=o("VisualBertConfig"),q2o=o(" (VisualBERT model)"),j2o=l(),du=a("li"),She=a("strong"),D2o=o("vit"),G2o=o(" \u2014 "),Dj=a("a"),O2o=o("ViTConfig"),V2o=o(" (ViT model)"),X2o=l(),cu=a("li"),Rhe=a("strong"),z2o=o("vit_mae"),Q2o=o(" \u2014 "),Gj=a("a"),W2o=o("ViTMAEConfig"),U2o=o(" (ViTMAE model)"),H2o=l(),fu=a("li"),Phe=a("strong"),J2o=o("vit_msn"),Y2o=o(" \u2014 "),Oj=a("a"),Z2o=o("ViTMSNConfig"),K2o=o(" (ViTMSN model)"),evo=l(),mu=a("li"),Bhe=a("strong"),ovo=o("wav2vec2"),rvo=o(" \u2014 "),Vj=a("a"),tvo=o("Wav2Vec2Config"),avo=o(" (Wav2Vec2 model)"),nvo=l(),gu=a("li"),Ihe=a("strong"),svo=o("wav2vec2-conformer"),lvo=o(" \u2014 "),Xj=a("a"),ivo=o("Wav2Vec2ConformerConfig"),dvo=o(" (Wav2Vec2-Conformer model)"),cvo=l(),hu=a("li"),Nhe=a("strong"),fvo=o("wavlm"),mvo=o(" \u2014 "),zj=a("a"),gvo=o("WavLMConfig"),hvo=o(" (WavLM model)"),uvo=l(),uu=a("li"),qhe=a("strong"),pvo=o("whisper"),_vo=o(" \u2014 "),Qj=a("a"),vvo=o("WhisperConfig"),bvo=o(" (Whisper model)"),Fvo=l(),pu=a("li"),jhe=a("strong"),Tvo=o("xclip"),Mvo=o(" \u2014 "),Wj=a("a"),Evo=o("XCLIPConfig"),Cvo=o(" (X-CLIP model)"),wvo=l(),_u=a("li"),Dhe=a("strong"),Avo=o("xglm"),Lvo=o(" \u2014 "),Uj=a("a"),yvo=o("XGLMConfig"),xvo=o(" (XGLM model)"),$vo=l(),vu=a("li"),Ghe=a("strong"),kvo=o("xlm"),Svo=o(" \u2014 "),Hj=a("a"),Rvo=o("XLMConfig"),Pvo=o(" (XLM model)"),Bvo=l(),bu=a("li"),Ohe=a("strong"),Ivo=o("xlm-prophetnet"),Nvo=o(" \u2014 "),Jj=a("a"),qvo=o("XLMProphetNetConfig"),jvo=o(" (XLM-ProphetNet model)"),Dvo=l(),Fu=a("li"),Vhe=a("strong"),Gvo=o("xlm-roberta"),Ovo=o(" \u2014 "),Yj=a("a"),Vvo=o("XLMRobertaConfig"),Xvo=o(" (XLM-RoBERTa model)"),zvo=l(),Tu=a("li"),Xhe=a("strong"),Qvo=o("xlm-roberta-xl"),Wvo=o(" \u2014 "),Zj=a("a"),Uvo=o("XLMRobertaXLConfig"),Hvo=o(" (XLM-RoBERTa-XL model)"),Jvo=l(),Mu=a("li"),zhe=a("strong"),Yvo=o("xlnet"),Zvo=o(" \u2014 "),Kj=a("a"),Kvo=o("XLNetConfig"),e1o=o(" (XLNet model)"),o1o=l(),Eu=a("li"),Qhe=a("strong"),r1o=o("yolos"),t1o=o(" \u2014 "),eD=a("a"),a1o=o("YolosConfig"),n1o=o(" (YOLOS model)"),s1o=l(),Cu=a("li"),Whe=a("strong"),l1o=o("yoso"),i1o=o(" \u2014 "),oD=a("a"),d1o=o("YosoConfig"),c1o=o(" (YOSO model)"),f1o=l(),F(wu.$$.fragment),m1o=l(),Au=a("div"),F(p$.$$.fragment),g1o=l(),Uhe=a("p"),h1o=o("Register a new configuration for this class."),Sto=l(),yd=a("h2"),Lu=a("a"),Hhe=a("span"),F(_$.$$.fragment),u1o=l(),Jhe=a("span"),p1o=o("AutoTokenizer"),Rto=l(),Ro=a("div"),F(v$.$$.fragment),_1o=l(),b$=a("p"),v1o=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),rD=a("a"),b1o=o("AutoTokenizer.from_pretrained()"),F1o=o(" class method."),T1o=l(),F$=a("p"),M1o=o("This class cannot be instantiated directly using "),Yhe=a("code"),E1o=o("__init__()"),C1o=o(" (throws an error)."),w1o=l(),jr=a("div"),F(T$.$$.fragment),A1o=l(),Zhe=a("p"),L1o=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),y1o=l(),tn=a("p"),x1o=o("The tokenizer class to instantiate is selected based on the "),Khe=a("code"),$1o=o("model_type"),k1o=o(` property of the config object (either
passed as an argument or loaded from `),eue=a("code"),S1o=o("pretrained_model_name_or_path"),R1o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oue=a("code"),P1o=o("pretrained_model_name_or_path"),B1o=o(":"),I1o=l(),k=a("ul"),us=a("li"),rue=a("strong"),N1o=o("albert"),q1o=o(" \u2014 "),tD=a("a"),j1o=o("AlbertTokenizer"),D1o=o(" or "),aD=a("a"),G1o=o("AlbertTokenizerFast"),O1o=o(" (ALBERT model)"),V1o=l(),ps=a("li"),tue=a("strong"),X1o=o("bart"),z1o=o(" \u2014 "),nD=a("a"),Q1o=o("BartTokenizer"),W1o=o(" or "),sD=a("a"),U1o=o("BartTokenizerFast"),H1o=o(" (BART model)"),J1o=l(),_s=a("li"),aue=a("strong"),Y1o=o("barthez"),Z1o=o(" \u2014 "),lD=a("a"),K1o=o("BarthezTokenizer"),ebo=o(" or "),iD=a("a"),obo=o("BarthezTokenizerFast"),rbo=o(" (BARThez model)"),tbo=l(),yu=a("li"),nue=a("strong"),abo=o("bartpho"),nbo=o(" \u2014 "),dD=a("a"),sbo=o("BartphoTokenizer"),lbo=o(" (BARTpho model)"),ibo=l(),vs=a("li"),sue=a("strong"),dbo=o("bert"),cbo=o(" \u2014 "),cD=a("a"),fbo=o("BertTokenizer"),mbo=o(" or "),fD=a("a"),gbo=o("BertTokenizerFast"),hbo=o(" (BERT model)"),ubo=l(),xu=a("li"),lue=a("strong"),pbo=o("bert-generation"),_bo=o(" \u2014 "),mD=a("a"),vbo=o("BertGenerationTokenizer"),bbo=o(" (Bert Generation model)"),Fbo=l(),$u=a("li"),iue=a("strong"),Tbo=o("bert-japanese"),Mbo=o(" \u2014 "),gD=a("a"),Ebo=o("BertJapaneseTokenizer"),Cbo=o(" (BertJapanese model)"),wbo=l(),ku=a("li"),due=a("strong"),Abo=o("bertweet"),Lbo=o(" \u2014 "),hD=a("a"),ybo=o("BertweetTokenizer"),xbo=o(" (BERTweet model)"),$bo=l(),bs=a("li"),cue=a("strong"),kbo=o("big_bird"),Sbo=o(" \u2014 "),uD=a("a"),Rbo=o("BigBirdTokenizer"),Pbo=o(" or "),pD=a("a"),Bbo=o("BigBirdTokenizerFast"),Ibo=o(" (BigBird model)"),Nbo=l(),Fs=a("li"),fue=a("strong"),qbo=o("bigbird_pegasus"),jbo=o(" \u2014 "),_D=a("a"),Dbo=o("PegasusTokenizer"),Gbo=o(" or "),vD=a("a"),Obo=o("PegasusTokenizerFast"),Vbo=o(" (BigBird-Pegasus model)"),Xbo=l(),Ts=a("li"),mue=a("strong"),zbo=o("blenderbot"),Qbo=o(" \u2014 "),bD=a("a"),Wbo=o("BlenderbotTokenizer"),Ubo=o(" or "),FD=a("a"),Hbo=o("BlenderbotTokenizerFast"),Jbo=o(" (Blenderbot model)"),Ybo=l(),Su=a("li"),gue=a("strong"),Zbo=o("blenderbot-small"),Kbo=o(" \u2014 "),TD=a("a"),e0o=o("BlenderbotSmallTokenizer"),o0o=o(" (BlenderbotSmall model)"),r0o=l(),Ru=a("li"),hue=a("strong"),t0o=o("bloom"),a0o=o(" \u2014 "),MD=a("a"),n0o=o("BloomTokenizerFast"),s0o=o(" (BLOOM model)"),l0o=l(),Pu=a("li"),uue=a("strong"),i0o=o("byt5"),d0o=o(" \u2014 "),ED=a("a"),c0o=o("ByT5Tokenizer"),f0o=o(" (ByT5 model)"),m0o=l(),Ms=a("li"),pue=a("strong"),g0o=o("camembert"),h0o=o(" \u2014 "),CD=a("a"),u0o=o("CamembertTokenizer"),p0o=o(" or "),wD=a("a"),_0o=o("CamembertTokenizerFast"),v0o=o(" (CamemBERT model)"),b0o=l(),Bu=a("li"),_ue=a("strong"),F0o=o("canine"),T0o=o(" \u2014 "),AD=a("a"),M0o=o("CanineTokenizer"),E0o=o(" (CANINE model)"),C0o=l(),Es=a("li"),vue=a("strong"),w0o=o("clip"),A0o=o(" \u2014 "),LD=a("a"),L0o=o("CLIPTokenizer"),y0o=o(" or "),yD=a("a"),x0o=o("CLIPTokenizerFast"),$0o=o(" (CLIP model)"),k0o=l(),Cs=a("li"),bue=a("strong"),S0o=o("codegen"),R0o=o(" \u2014 "),xD=a("a"),P0o=o("CodeGenTokenizer"),B0o=o(" or "),$D=a("a"),I0o=o("CodeGenTokenizerFast"),N0o=o(" (CodeGen model)"),q0o=l(),ws=a("li"),Fue=a("strong"),j0o=o("convbert"),D0o=o(" \u2014 "),kD=a("a"),G0o=o("ConvBertTokenizer"),O0o=o(" or "),SD=a("a"),V0o=o("ConvBertTokenizerFast"),X0o=o(" (ConvBERT model)"),z0o=l(),As=a("li"),Tue=a("strong"),Q0o=o("cpm"),W0o=o(" \u2014 "),RD=a("a"),U0o=o("CpmTokenizer"),H0o=o(" or "),PD=a("a"),J0o=o("CpmTokenizerFast"),Y0o=o(" (CPM model)"),Z0o=l(),Iu=a("li"),Mue=a("strong"),K0o=o("ctrl"),eFo=o(" \u2014 "),BD=a("a"),oFo=o("CTRLTokenizer"),rFo=o(" (CTRL model)"),tFo=l(),Ls=a("li"),Eue=a("strong"),aFo=o("data2vec-text"),nFo=o(" \u2014 "),ID=a("a"),sFo=o("RobertaTokenizer"),lFo=o(" or "),ND=a("a"),iFo=o("RobertaTokenizerFast"),dFo=o(" (Data2VecText model)"),cFo=l(),ys=a("li"),Cue=a("strong"),fFo=o("deberta"),mFo=o(" \u2014 "),qD=a("a"),gFo=o("DebertaTokenizer"),hFo=o(" or "),jD=a("a"),uFo=o("DebertaTokenizerFast"),pFo=o(" (DeBERTa model)"),_Fo=l(),xs=a("li"),wue=a("strong"),vFo=o("deberta-v2"),bFo=o(" \u2014 "),DD=a("a"),FFo=o("DebertaV2Tokenizer"),TFo=o(" or "),GD=a("a"),MFo=o("DebertaV2TokenizerFast"),EFo=o(" (DeBERTa-v2 model)"),CFo=l(),$s=a("li"),Aue=a("strong"),wFo=o("distilbert"),AFo=o(" \u2014 "),OD=a("a"),LFo=o("DistilBertTokenizer"),yFo=o(" or "),VD=a("a"),xFo=o("DistilBertTokenizerFast"),$Fo=o(" (DistilBERT model)"),kFo=l(),ks=a("li"),Lue=a("strong"),SFo=o("dpr"),RFo=o(" \u2014 "),XD=a("a"),PFo=o("DPRQuestionEncoderTokenizer"),BFo=o(" or "),zD=a("a"),IFo=o("DPRQuestionEncoderTokenizerFast"),NFo=o(" (DPR model)"),qFo=l(),Ss=a("li"),yue=a("strong"),jFo=o("electra"),DFo=o(" \u2014 "),QD=a("a"),GFo=o("ElectraTokenizer"),OFo=o(" or "),WD=a("a"),VFo=o("ElectraTokenizerFast"),XFo=o(" (ELECTRA model)"),zFo=l(),Rs=a("li"),xue=a("strong"),QFo=o("ernie"),WFo=o(" \u2014 "),UD=a("a"),UFo=o("BertTokenizer"),HFo=o(" or "),HD=a("a"),JFo=o("BertTokenizerFast"),YFo=o(" (ERNIE model)"),ZFo=l(),Nu=a("li"),$ue=a("strong"),KFo=o("esm"),eTo=o(" \u2014 "),JD=a("a"),oTo=o("EsmTokenizer"),rTo=o(" (ESM model)"),tTo=l(),qu=a("li"),kue=a("strong"),aTo=o("flaubert"),nTo=o(" \u2014 "),YD=a("a"),sTo=o("FlaubertTokenizer"),lTo=o(" (FlauBERT model)"),iTo=l(),Ps=a("li"),Sue=a("strong"),dTo=o("fnet"),cTo=o(" \u2014 "),ZD=a("a"),fTo=o("FNetTokenizer"),mTo=o(" or "),KD=a("a"),gTo=o("FNetTokenizerFast"),hTo=o(" (FNet model)"),uTo=l(),ju=a("li"),Rue=a("strong"),pTo=o("fsmt"),_To=o(" \u2014 "),eG=a("a"),vTo=o("FSMTTokenizer"),bTo=o(" (FairSeq Machine-Translation model)"),FTo=l(),Bs=a("li"),Pue=a("strong"),TTo=o("funnel"),MTo=o(" \u2014 "),oG=a("a"),ETo=o("FunnelTokenizer"),CTo=o(" or "),rG=a("a"),wTo=o("FunnelTokenizerFast"),ATo=o(" (Funnel Transformer model)"),LTo=l(),Is=a("li"),Bue=a("strong"),yTo=o("gpt2"),xTo=o(" \u2014 "),tG=a("a"),$To=o("GPT2Tokenizer"),kTo=o(" or "),aG=a("a"),STo=o("GPT2TokenizerFast"),RTo=o(" (OpenAI GPT-2 model)"),PTo=l(),Ns=a("li"),Iue=a("strong"),BTo=o("gpt_neo"),ITo=o(" \u2014 "),nG=a("a"),NTo=o("GPT2Tokenizer"),qTo=o(" or "),sG=a("a"),jTo=o("GPT2TokenizerFast"),DTo=o(" (GPT Neo model)"),GTo=l(),Du=a("li"),Nue=a("strong"),OTo=o("gpt_neox"),VTo=o(" \u2014 "),lG=a("a"),XTo=o("GPTNeoXTokenizerFast"),zTo=o(" (GPT NeoX model)"),QTo=l(),Gu=a("li"),que=a("strong"),WTo=o("gpt_neox_japanese"),UTo=o(" \u2014 "),iG=a("a"),HTo=o("GPTNeoXJapaneseTokenizer"),JTo=o(" (GPT NeoX Japanese model)"),YTo=l(),qs=a("li"),jue=a("strong"),ZTo=o("gptj"),KTo=o(" \u2014 "),dG=a("a"),eMo=o("GPT2Tokenizer"),oMo=o(" or "),cG=a("a"),rMo=o("GPT2TokenizerFast"),tMo=o(" (GPT-J model)"),aMo=l(),js=a("li"),Due=a("strong"),nMo=o("groupvit"),sMo=o(" \u2014 "),fG=a("a"),lMo=o("CLIPTokenizer"),iMo=o(" or "),mG=a("a"),dMo=o("CLIPTokenizerFast"),cMo=o(" (GroupViT model)"),fMo=l(),Ds=a("li"),Gue=a("strong"),mMo=o("herbert"),gMo=o(" \u2014 "),gG=a("a"),hMo=o("HerbertTokenizer"),uMo=o(" or "),hG=a("a"),pMo=o("HerbertTokenizerFast"),_Mo=o(" (HerBERT model)"),vMo=l(),Ou=a("li"),Oue=a("strong"),bMo=o("hubert"),FMo=o(" \u2014 "),uG=a("a"),TMo=o("Wav2Vec2CTCTokenizer"),MMo=o(" (Hubert model)"),EMo=l(),Gs=a("li"),Vue=a("strong"),CMo=o("ibert"),wMo=o(" \u2014 "),pG=a("a"),AMo=o("RobertaTokenizer"),LMo=o(" or "),_G=a("a"),yMo=o("RobertaTokenizerFast"),xMo=o(" (I-BERT model)"),$Mo=l(),Os=a("li"),Xue=a("strong"),kMo=o("layoutlm"),SMo=o(" \u2014 "),vG=a("a"),RMo=o("LayoutLMTokenizer"),PMo=o(" or "),bG=a("a"),BMo=o("LayoutLMTokenizerFast"),IMo=o(" (LayoutLM model)"),NMo=l(),Vs=a("li"),zue=a("strong"),qMo=o("layoutlmv2"),jMo=o(" \u2014 "),FG=a("a"),DMo=o("LayoutLMv2Tokenizer"),GMo=o(" or "),TG=a("a"),OMo=o("LayoutLMv2TokenizerFast"),VMo=o(" (LayoutLMv2 model)"),XMo=l(),Xs=a("li"),Que=a("strong"),zMo=o("layoutlmv3"),QMo=o(" \u2014 "),MG=a("a"),WMo=o("LayoutLMv3Tokenizer"),UMo=o(" or "),EG=a("a"),HMo=o("LayoutLMv3TokenizerFast"),JMo=o(" (LayoutLMv3 model)"),YMo=l(),zs=a("li"),Wue=a("strong"),ZMo=o("layoutxlm"),KMo=o(" \u2014 "),CG=a("a"),eEo=o("LayoutXLMTokenizer"),oEo=o(" or "),wG=a("a"),rEo=o("LayoutXLMTokenizerFast"),tEo=o(" (LayoutXLM model)"),aEo=l(),Qs=a("li"),Uue=a("strong"),nEo=o("led"),sEo=o(" \u2014 "),AG=a("a"),lEo=o("LEDTokenizer"),iEo=o(" or "),LG=a("a"),dEo=o("LEDTokenizerFast"),cEo=o(" (LED model)"),fEo=l(),Ws=a("li"),Hue=a("strong"),mEo=o("lilt"),gEo=o(" \u2014 "),yG=a("a"),hEo=o("LayoutLMv3Tokenizer"),uEo=o(" or "),xG=a("a"),pEo=o("LayoutLMv3TokenizerFast"),_Eo=o(" (LiLT model)"),vEo=l(),Us=a("li"),Jue=a("strong"),bEo=o("longformer"),FEo=o(" \u2014 "),$G=a("a"),TEo=o("LongformerTokenizer"),MEo=o(" or "),kG=a("a"),EEo=o("LongformerTokenizerFast"),CEo=o(" (Longformer model)"),wEo=l(),Hs=a("li"),Yue=a("strong"),AEo=o("longt5"),LEo=o(" \u2014 "),SG=a("a"),yEo=o("T5Tokenizer"),xEo=o(" or "),RG=a("a"),$Eo=o("T5TokenizerFast"),kEo=o(" (LongT5 model)"),SEo=l(),Vu=a("li"),Zue=a("strong"),REo=o("luke"),PEo=o(" \u2014 "),PG=a("a"),BEo=o("LukeTokenizer"),IEo=o(" (LUKE model)"),NEo=l(),Js=a("li"),Kue=a("strong"),qEo=o("lxmert"),jEo=o(" \u2014 "),BG=a("a"),DEo=o("LxmertTokenizer"),GEo=o(" or "),IG=a("a"),OEo=o("LxmertTokenizerFast"),VEo=o(" (LXMERT model)"),XEo=l(),Xu=a("li"),epe=a("strong"),zEo=o("m2m_100"),QEo=o(" \u2014 "),NG=a("a"),WEo=o("M2M100Tokenizer"),UEo=o(" (M2M100 model)"),HEo=l(),zu=a("li"),ope=a("strong"),JEo=o("marian"),YEo=o(" \u2014 "),qG=a("a"),ZEo=o("MarianTokenizer"),KEo=o(" (Marian model)"),eCo=l(),Ys=a("li"),rpe=a("strong"),oCo=o("mbart"),rCo=o(" \u2014 "),jG=a("a"),tCo=o("MBartTokenizer"),aCo=o(" or "),DG=a("a"),nCo=o("MBartTokenizerFast"),sCo=o(" (mBART model)"),lCo=l(),Zs=a("li"),tpe=a("strong"),iCo=o("mbart50"),dCo=o(" \u2014 "),GG=a("a"),cCo=o("MBart50Tokenizer"),fCo=o(" or "),OG=a("a"),mCo=o("MBart50TokenizerFast"),gCo=o(" (mBART-50 model)"),hCo=l(),Ks=a("li"),ape=a("strong"),uCo=o("megatron-bert"),pCo=o(" \u2014 "),VG=a("a"),_Co=o("BertTokenizer"),vCo=o(" or "),XG=a("a"),bCo=o("BertTokenizerFast"),FCo=o(" (Megatron-BERT model)"),TCo=l(),Qu=a("li"),npe=a("strong"),MCo=o("mluke"),ECo=o(" \u2014 "),zG=a("a"),CCo=o("MLukeTokenizer"),wCo=o(" (mLUKE model)"),ACo=l(),el=a("li"),spe=a("strong"),LCo=o("mobilebert"),yCo=o(" \u2014 "),QG=a("a"),xCo=o("MobileBertTokenizer"),$Co=o(" or "),WG=a("a"),kCo=o("MobileBertTokenizerFast"),SCo=o(" (MobileBERT model)"),RCo=l(),ol=a("li"),lpe=a("strong"),PCo=o("mpnet"),BCo=o(" \u2014 "),UG=a("a"),ICo=o("MPNetTokenizer"),NCo=o(" or "),HG=a("a"),qCo=o("MPNetTokenizerFast"),jCo=o(" (MPNet model)"),DCo=l(),rl=a("li"),ipe=a("strong"),GCo=o("mt5"),OCo=o(" \u2014 "),JG=a("a"),VCo=o("MT5Tokenizer"),XCo=o(" or "),YG=a("a"),zCo=o("MT5TokenizerFast"),QCo=o(" (MT5 model)"),WCo=l(),tl=a("li"),dpe=a("strong"),UCo=o("mvp"),HCo=o(" \u2014 "),ZG=a("a"),JCo=o("MvpTokenizer"),YCo=o(" or "),KG=a("a"),ZCo=o("MvpTokenizerFast"),KCo=o(" (MVP model)"),e3o=l(),al=a("li"),cpe=a("strong"),o3o=o("nezha"),r3o=o(" \u2014 "),eO=a("a"),t3o=o("BertTokenizer"),a3o=o(" or "),oO=a("a"),n3o=o("BertTokenizerFast"),s3o=o(" (Nezha model)"),l3o=l(),nl=a("li"),fpe=a("strong"),i3o=o("nllb"),d3o=o(" \u2014 "),rO=a("a"),c3o=o("NllbTokenizer"),f3o=o(" or "),tO=a("a"),m3o=o("NllbTokenizerFast"),g3o=o(" (NLLB model)"),h3o=l(),sl=a("li"),mpe=a("strong"),u3o=o("nystromformer"),p3o=o(" \u2014 "),aO=a("a"),_3o=o("AlbertTokenizer"),v3o=o(" or "),nO=a("a"),b3o=o("AlbertTokenizerFast"),F3o=o(" (Nystr\xF6mformer model)"),T3o=l(),ll=a("li"),gpe=a("strong"),M3o=o("openai-gpt"),E3o=o(" \u2014 "),sO=a("a"),C3o=o("OpenAIGPTTokenizer"),w3o=o(" or "),lO=a("a"),A3o=o("OpenAIGPTTokenizerFast"),L3o=o(" (OpenAI GPT model)"),y3o=l(),Wu=a("li"),hpe=a("strong"),x3o=o("opt"),$3o=o(" \u2014 "),iO=a("a"),k3o=o("GPT2Tokenizer"),S3o=o(" (OPT model)"),R3o=l(),il=a("li"),upe=a("strong"),P3o=o("owlvit"),B3o=o(" \u2014 "),dO=a("a"),I3o=o("CLIPTokenizer"),N3o=o(" or "),cO=a("a"),q3o=o("CLIPTokenizerFast"),j3o=o(" (OWL-ViT model)"),D3o=l(),dl=a("li"),ppe=a("strong"),G3o=o("pegasus"),O3o=o(" \u2014 "),fO=a("a"),V3o=o("PegasusTokenizer"),X3o=o(" or "),mO=a("a"),z3o=o("PegasusTokenizerFast"),Q3o=o(" (Pegasus model)"),W3o=l(),cl=a("li"),_pe=a("strong"),U3o=o("pegasus_x"),H3o=o(" \u2014 "),gO=a("a"),J3o=o("PegasusTokenizer"),Y3o=o(" or "),hO=a("a"),Z3o=o("PegasusTokenizerFast"),K3o=o(" (PEGASUS-X model)"),e5o=l(),Uu=a("li"),vpe=a("strong"),o5o=o("perceiver"),r5o=o(" \u2014 "),uO=a("a"),t5o=o("PerceiverTokenizer"),a5o=o(" (Perceiver model)"),n5o=l(),Hu=a("li"),bpe=a("strong"),s5o=o("phobert"),l5o=o(" \u2014 "),pO=a("a"),i5o=o("PhobertTokenizer"),d5o=o(" (PhoBERT model)"),c5o=l(),Ju=a("li"),Fpe=a("strong"),f5o=o("plbart"),m5o=o(" \u2014 "),_O=a("a"),g5o=o("PLBartTokenizer"),h5o=o(" (PLBart model)"),u5o=l(),Yu=a("li"),Tpe=a("strong"),p5o=o("prophetnet"),_5o=o(" \u2014 "),vO=a("a"),v5o=o("ProphetNetTokenizer"),b5o=o(" (ProphetNet model)"),F5o=l(),fl=a("li"),Mpe=a("strong"),T5o=o("qdqbert"),M5o=o(" \u2014 "),bO=a("a"),E5o=o("BertTokenizer"),C5o=o(" or "),FO=a("a"),w5o=o("BertTokenizerFast"),A5o=o(" (QDQBert model)"),L5o=l(),Zu=a("li"),Epe=a("strong"),y5o=o("rag"),x5o=o(" \u2014 "),TO=a("a"),$5o=o("RagTokenizer"),k5o=o(" (RAG model)"),S5o=l(),ml=a("li"),Cpe=a("strong"),R5o=o("realm"),P5o=o(" \u2014 "),MO=a("a"),B5o=o("RealmTokenizer"),I5o=o(" or "),EO=a("a"),N5o=o("RealmTokenizerFast"),q5o=o(" (REALM model)"),j5o=l(),gl=a("li"),wpe=a("strong"),D5o=o("reformer"),G5o=o(" \u2014 "),CO=a("a"),O5o=o("ReformerTokenizer"),V5o=o(" or "),wO=a("a"),X5o=o("ReformerTokenizerFast"),z5o=o(" (Reformer model)"),Q5o=l(),hl=a("li"),Ape=a("strong"),W5o=o("rembert"),U5o=o(" \u2014 "),AO=a("a"),H5o=o("RemBertTokenizer"),J5o=o(" or "),LO=a("a"),Y5o=o("RemBertTokenizerFast"),Z5o=o(" (RemBERT model)"),K5o=l(),ul=a("li"),Lpe=a("strong"),ewo=o("retribert"),owo=o(" \u2014 "),yO=a("a"),rwo=o("RetriBertTokenizer"),two=o(" or "),xO=a("a"),awo=o("RetriBertTokenizerFast"),nwo=o(" (RetriBERT model)"),swo=l(),pl=a("li"),ype=a("strong"),lwo=o("roberta"),iwo=o(" \u2014 "),$O=a("a"),dwo=o("RobertaTokenizer"),cwo=o(" or "),kO=a("a"),fwo=o("RobertaTokenizerFast"),mwo=o(" (RoBERTa model)"),gwo=l(),_l=a("li"),xpe=a("strong"),hwo=o("roformer"),uwo=o(" \u2014 "),SO=a("a"),pwo=o("RoFormerTokenizer"),_wo=o(" or "),RO=a("a"),vwo=o("RoFormerTokenizerFast"),bwo=o(" (RoFormer model)"),Fwo=l(),Ku=a("li"),$pe=a("strong"),Two=o("speech_to_text"),Mwo=o(" \u2014 "),PO=a("a"),Ewo=o("Speech2TextTokenizer"),Cwo=o(" (Speech2Text model)"),wwo=l(),ep=a("li"),kpe=a("strong"),Awo=o("speech_to_text_2"),Lwo=o(" \u2014 "),BO=a("a"),ywo=o("Speech2Text2Tokenizer"),xwo=o(" (Speech2Text2 model)"),$wo=l(),vl=a("li"),Spe=a("strong"),kwo=o("splinter"),Swo=o(" \u2014 "),IO=a("a"),Rwo=o("SplinterTokenizer"),Pwo=o(" or "),NO=a("a"),Bwo=o("SplinterTokenizerFast"),Iwo=o(" (Splinter model)"),Nwo=l(),bl=a("li"),Rpe=a("strong"),qwo=o("squeezebert"),jwo=o(" \u2014 "),qO=a("a"),Dwo=o("SqueezeBertTokenizer"),Gwo=o(" or "),jO=a("a"),Owo=o("SqueezeBertTokenizerFast"),Vwo=o(" (SqueezeBERT model)"),Xwo=l(),Fl=a("li"),Ppe=a("strong"),zwo=o("t5"),Qwo=o(" \u2014 "),DO=a("a"),Wwo=o("T5Tokenizer"),Uwo=o(" or "),GO=a("a"),Hwo=o("T5TokenizerFast"),Jwo=o(" (T5 model)"),Ywo=l(),op=a("li"),Bpe=a("strong"),Zwo=o("tapas"),Kwo=o(" \u2014 "),OO=a("a"),eAo=o("TapasTokenizer"),oAo=o(" (TAPAS model)"),rAo=l(),rp=a("li"),Ipe=a("strong"),tAo=o("tapex"),aAo=o(" \u2014 "),VO=a("a"),nAo=o("TapexTokenizer"),sAo=o(" (TAPEX model)"),lAo=l(),tp=a("li"),Npe=a("strong"),iAo=o("transfo-xl"),dAo=o(" \u2014 "),XO=a("a"),cAo=o("TransfoXLTokenizer"),fAo=o(" (Transformer-XL model)"),mAo=l(),Tl=a("li"),qpe=a("strong"),gAo=o("vilt"),hAo=o(" \u2014 "),zO=a("a"),uAo=o("BertTokenizer"),pAo=o(" or "),QO=a("a"),_Ao=o("BertTokenizerFast"),vAo=o(" (ViLT model)"),bAo=l(),Ml=a("li"),jpe=a("strong"),FAo=o("visual_bert"),TAo=o(" \u2014 "),WO=a("a"),MAo=o("BertTokenizer"),EAo=o(" or "),UO=a("a"),CAo=o("BertTokenizerFast"),wAo=o(" (VisualBERT model)"),AAo=l(),ap=a("li"),Dpe=a("strong"),LAo=o("wav2vec2"),yAo=o(" \u2014 "),HO=a("a"),xAo=o("Wav2Vec2CTCTokenizer"),$Ao=o(" (Wav2Vec2 model)"),kAo=l(),np=a("li"),Gpe=a("strong"),SAo=o("wav2vec2-conformer"),RAo=o(" \u2014 "),JO=a("a"),PAo=o("Wav2Vec2CTCTokenizer"),BAo=o(" (Wav2Vec2-Conformer model)"),IAo=l(),sp=a("li"),Ope=a("strong"),NAo=o("wav2vec2_phoneme"),qAo=o(" \u2014 "),YO=a("a"),jAo=o("Wav2Vec2PhonemeCTCTokenizer"),DAo=o(" (Wav2Vec2Phoneme model)"),GAo=l(),lp=a("li"),Vpe=a("strong"),OAo=o("whisper"),VAo=o(" \u2014 "),ZO=a("a"),XAo=o("WhisperTokenizer"),zAo=o(" (Whisper model)"),QAo=l(),El=a("li"),Xpe=a("strong"),WAo=o("xclip"),UAo=o(" \u2014 "),KO=a("a"),HAo=o("CLIPTokenizer"),JAo=o(" or "),eV=a("a"),YAo=o("CLIPTokenizerFast"),ZAo=o(" (X-CLIP model)"),KAo=l(),Cl=a("li"),zpe=a("strong"),e6o=o("xglm"),o6o=o(" \u2014 "),oV=a("a"),r6o=o("XGLMTokenizer"),t6o=o(" or "),rV=a("a"),a6o=o("XGLMTokenizerFast"),n6o=o(" (XGLM model)"),s6o=l(),ip=a("li"),Qpe=a("strong"),l6o=o("xlm"),i6o=o(" \u2014 "),tV=a("a"),d6o=o("XLMTokenizer"),c6o=o(" (XLM model)"),f6o=l(),dp=a("li"),Wpe=a("strong"),m6o=o("xlm-prophetnet"),g6o=o(" \u2014 "),aV=a("a"),h6o=o("XLMProphetNetTokenizer"),u6o=o(" (XLM-ProphetNet model)"),p6o=l(),wl=a("li"),Upe=a("strong"),_6o=o("xlm-roberta"),v6o=o(" \u2014 "),nV=a("a"),b6o=o("XLMRobertaTokenizer"),F6o=o(" or "),sV=a("a"),T6o=o("XLMRobertaTokenizerFast"),M6o=o(" (XLM-RoBERTa model)"),E6o=l(),Al=a("li"),Hpe=a("strong"),C6o=o("xlm-roberta-xl"),w6o=o(" \u2014 "),lV=a("a"),A6o=o("XLMRobertaTokenizer"),L6o=o(" or "),iV=a("a"),y6o=o("XLMRobertaTokenizerFast"),x6o=o(" (XLM-RoBERTa-XL model)"),$6o=l(),Ll=a("li"),Jpe=a("strong"),k6o=o("xlnet"),S6o=o(" \u2014 "),dV=a("a"),R6o=o("XLNetTokenizer"),P6o=o(" or "),cV=a("a"),B6o=o("XLNetTokenizerFast"),I6o=o(" (XLNet model)"),N6o=l(),yl=a("li"),Ype=a("strong"),q6o=o("yoso"),j6o=o(" \u2014 "),fV=a("a"),D6o=o("AlbertTokenizer"),G6o=o(" or "),mV=a("a"),O6o=o("AlbertTokenizerFast"),V6o=o(" (YOSO model)"),X6o=l(),F(cp.$$.fragment),z6o=l(),fp=a("div"),F(M$.$$.fragment),Q6o=l(),Zpe=a("p"),W6o=o("Register a new tokenizer in this mapping."),Pto=l(),xd=a("h2"),mp=a("a"),Kpe=a("span"),F(E$.$$.fragment),U6o=l(),e_e=a("span"),H6o=o("AutoFeatureExtractor"),Bto=l(),Po=a("div"),F(C$.$$.fragment),J6o=l(),w$=a("p"),Y6o=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),gV=a("a"),Z6o=o("AutoFeatureExtractor.from_pretrained()"),K6o=o(" class method."),e7o=l(),A$=a("p"),o7o=o("This class cannot be instantiated directly using "),o_e=a("code"),r7o=o("__init__()"),t7o=o(" (throws an error)."),a7o=l(),Ye=a("div"),F(L$.$$.fragment),n7o=l(),r_e=a("p"),s7o=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),l7o=l(),an=a("p"),i7o=o("The feature extractor class to instantiate is selected based on the "),t_e=a("code"),d7o=o("model_type"),c7o=o(` property of the config object
(either passed as an argument or loaded from `),a_e=a("code"),f7o=o("pretrained_model_name_or_path"),m7o=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),n_e=a("code"),g7o=o("pretrained_model_name_or_path"),h7o=o(":"),u7o=l(),z=a("ul"),gp=a("li"),s_e=a("strong"),p7o=o("beit"),_7o=o(" \u2014 "),hV=a("a"),v7o=o("BeitFeatureExtractor"),b7o=o(" (BEiT model)"),F7o=l(),hp=a("li"),l_e=a("strong"),T7o=o("clip"),M7o=o(" \u2014 "),uV=a("a"),E7o=o("CLIPFeatureExtractor"),C7o=o(" (CLIP model)"),w7o=l(),up=a("li"),i_e=a("strong"),A7o=o("conditional_detr"),L7o=o(" \u2014 "),pV=a("a"),y7o=o("ConditionalDetrFeatureExtractor"),x7o=o(" (Conditional DETR model)"),$7o=l(),pp=a("li"),d_e=a("strong"),k7o=o("convnext"),S7o=o(" \u2014 "),_V=a("a"),R7o=o("ConvNextFeatureExtractor"),P7o=o(" (ConvNeXT model)"),B7o=l(),_p=a("li"),c_e=a("strong"),I7o=o("cvt"),N7o=o(" \u2014 "),vV=a("a"),q7o=o("ConvNextFeatureExtractor"),j7o=o(" (CvT model)"),D7o=l(),vp=a("li"),f_e=a("strong"),G7o=o("data2vec-audio"),O7o=o(" \u2014 "),bV=a("a"),V7o=o("Wav2Vec2FeatureExtractor"),X7o=o(" (Data2VecAudio model)"),z7o=l(),bp=a("li"),m_e=a("strong"),Q7o=o("data2vec-vision"),W7o=o(" \u2014 "),FV=a("a"),U7o=o("BeitFeatureExtractor"),H7o=o(" (Data2VecVision model)"),J7o=l(),Fp=a("li"),g_e=a("strong"),Y7o=o("deformable_detr"),Z7o=o(" \u2014 "),TV=a("a"),K7o=o("DeformableDetrFeatureExtractor"),e8o=o(" (Deformable DETR model)"),o8o=l(),Tp=a("li"),h_e=a("strong"),r8o=o("deit"),t8o=o(" \u2014 "),MV=a("a"),a8o=o("DeiTFeatureExtractor"),n8o=o(" (DeiT model)"),s8o=l(),Mp=a("li"),u_e=a("strong"),l8o=o("detr"),i8o=o(" \u2014 "),EV=a("a"),d8o=o("DetrFeatureExtractor"),c8o=o(" (DETR model)"),f8o=l(),Ep=a("li"),p_e=a("strong"),m8o=o("donut-swin"),g8o=o(" \u2014 "),CV=a("a"),h8o=o("DonutFeatureExtractor"),u8o=o(" (DonutSwin model)"),p8o=l(),Cp=a("li"),__e=a("strong"),_8o=o("dpt"),v8o=o(" \u2014 "),wV=a("a"),b8o=o("DPTFeatureExtractor"),F8o=o(" (DPT model)"),T8o=l(),wp=a("li"),v_e=a("strong"),M8o=o("flava"),E8o=o(" \u2014 "),AV=a("a"),C8o=o("FlavaFeatureExtractor"),w8o=o(" (FLAVA model)"),A8o=l(),Ap=a("li"),b_e=a("strong"),L8o=o("glpn"),y8o=o(" \u2014 "),LV=a("a"),x8o=o("GLPNFeatureExtractor"),$8o=o(" (GLPN model)"),k8o=l(),Lp=a("li"),F_e=a("strong"),S8o=o("groupvit"),R8o=o(" \u2014 "),yV=a("a"),P8o=o("CLIPFeatureExtractor"),B8o=o(" (GroupViT model)"),I8o=l(),yp=a("li"),T_e=a("strong"),N8o=o("hubert"),q8o=o(" \u2014 "),xV=a("a"),j8o=o("Wav2Vec2FeatureExtractor"),D8o=o(" (Hubert model)"),G8o=l(),xp=a("li"),M_e=a("strong"),O8o=o("imagegpt"),V8o=o(" \u2014 "),$V=a("a"),X8o=o("ImageGPTFeatureExtractor"),z8o=o(" (ImageGPT model)"),Q8o=l(),$p=a("li"),E_e=a("strong"),W8o=o("layoutlmv2"),U8o=o(" \u2014 "),kV=a("a"),H8o=o("LayoutLMv2FeatureExtractor"),J8o=o(" (LayoutLMv2 model)"),Y8o=l(),kp=a("li"),C_e=a("strong"),Z8o=o("layoutlmv3"),K8o=o(" \u2014 "),SV=a("a"),eLo=o("LayoutLMv3FeatureExtractor"),oLo=o(" (LayoutLMv3 model)"),rLo=l(),Sp=a("li"),w_e=a("strong"),tLo=o("levit"),aLo=o(" \u2014 "),RV=a("a"),nLo=o("LevitFeatureExtractor"),sLo=o(" (LeViT model)"),lLo=l(),Rp=a("li"),A_e=a("strong"),iLo=o("maskformer"),dLo=o(" \u2014 "),PV=a("a"),cLo=o("MaskFormerFeatureExtractor"),fLo=o(" (MaskFormer model)"),mLo=l(),Pp=a("li"),L_e=a("strong"),gLo=o("mctct"),hLo=o(" \u2014 "),BV=a("a"),uLo=o("MCTCTFeatureExtractor"),pLo=o(" (M-CTC-T model)"),_Lo=l(),Bp=a("li"),y_e=a("strong"),vLo=o("mobilevit"),bLo=o(" \u2014 "),IV=a("a"),FLo=o("MobileViTFeatureExtractor"),TLo=o(" (MobileViT model)"),MLo=l(),Ip=a("li"),x_e=a("strong"),ELo=o("owlvit"),CLo=o(" \u2014 "),NV=a("a"),wLo=o("OwlViTFeatureExtractor"),ALo=o(" (OWL-ViT model)"),LLo=l(),Np=a("li"),$_e=a("strong"),yLo=o("perceiver"),xLo=o(" \u2014 "),qV=a("a"),$Lo=o("PerceiverFeatureExtractor"),kLo=o(" (Perceiver model)"),SLo=l(),qp=a("li"),k_e=a("strong"),RLo=o("poolformer"),PLo=o(" \u2014 "),jV=a("a"),BLo=o("PoolFormerFeatureExtractor"),ILo=o(" (PoolFormer model)"),NLo=l(),jp=a("li"),S_e=a("strong"),qLo=o("regnet"),jLo=o(" \u2014 "),DV=a("a"),DLo=o("ConvNextFeatureExtractor"),GLo=o(" (RegNet model)"),OLo=l(),Dp=a("li"),R_e=a("strong"),VLo=o("resnet"),XLo=o(" \u2014 "),GV=a("a"),zLo=o("ConvNextFeatureExtractor"),QLo=o(" (ResNet model)"),WLo=l(),Gp=a("li"),P_e=a("strong"),ULo=o("segformer"),HLo=o(" \u2014 "),OV=a("a"),JLo=o("SegformerFeatureExtractor"),YLo=o(" (SegFormer model)"),ZLo=l(),Op=a("li"),B_e=a("strong"),KLo=o("speech_to_text"),eyo=o(" \u2014 "),VV=a("a"),oyo=o("Speech2TextFeatureExtractor"),ryo=o(" (Speech2Text model)"),tyo=l(),Vp=a("li"),I_e=a("strong"),ayo=o("swin"),nyo=o(" \u2014 "),XV=a("a"),syo=o("ViTFeatureExtractor"),lyo=o(" (Swin Transformer model)"),iyo=l(),Xp=a("li"),N_e=a("strong"),dyo=o("swinv2"),cyo=o(" \u2014 "),zV=a("a"),fyo=o("ViTFeatureExtractor"),myo=o(" (Swin Transformer V2 model)"),gyo=l(),zp=a("li"),q_e=a("strong"),hyo=o("table-transformer"),uyo=o(" \u2014 "),QV=a("a"),pyo=o("DetrFeatureExtractor"),_yo=o(" (Table Transformer model)"),vyo=l(),Qp=a("li"),j_e=a("strong"),byo=o("van"),Fyo=o(" \u2014 "),WV=a("a"),Tyo=o("ConvNextFeatureExtractor"),Myo=o(" (VAN model)"),Eyo=l(),Wp=a("li"),D_e=a("strong"),Cyo=o("videomae"),wyo=o(" \u2014 "),UV=a("a"),Ayo=o("VideoMAEFeatureExtractor"),Lyo=o(" (VideoMAE model)"),yyo=l(),Up=a("li"),G_e=a("strong"),xyo=o("vilt"),$yo=o(" \u2014 "),HV=a("a"),kyo=o("ViltFeatureExtractor"),Syo=o(" (ViLT model)"),Ryo=l(),Hp=a("li"),O_e=a("strong"),Pyo=o("vit"),Byo=o(" \u2014 "),JV=a("a"),Iyo=o("ViTFeatureExtractor"),Nyo=o(" (ViT model)"),qyo=l(),Jp=a("li"),V_e=a("strong"),jyo=o("vit_mae"),Dyo=o(" \u2014 "),YV=a("a"),Gyo=o("ViTFeatureExtractor"),Oyo=o(" (ViTMAE model)"),Vyo=l(),Yp=a("li"),X_e=a("strong"),Xyo=o("vit_msn"),zyo=o(" \u2014 "),ZV=a("a"),Qyo=o("ViTFeatureExtractor"),Wyo=o(" (ViTMSN model)"),Uyo=l(),Zp=a("li"),z_e=a("strong"),Hyo=o("wav2vec2"),Jyo=o(" \u2014 "),KV=a("a"),Yyo=o("Wav2Vec2FeatureExtractor"),Zyo=o(" (Wav2Vec2 model)"),Kyo=l(),Kp=a("li"),Q_e=a("strong"),e9o=o("wav2vec2-conformer"),o9o=o(" \u2014 "),eX=a("a"),r9o=o("Wav2Vec2FeatureExtractor"),t9o=o(" (Wav2Vec2-Conformer model)"),a9o=l(),e_=a("li"),W_e=a("strong"),n9o=o("whisper"),s9o=o(" \u2014 "),oX=a("a"),l9o=o("WhisperFeatureExtractor"),i9o=o(" (Whisper model)"),d9o=l(),o_=a("li"),U_e=a("strong"),c9o=o("xclip"),f9o=o(" \u2014 "),rX=a("a"),m9o=o("CLIPFeatureExtractor"),g9o=o(" (X-CLIP model)"),h9o=l(),r_=a("li"),H_e=a("strong"),u9o=o("yolos"),p9o=o(" \u2014 "),tX=a("a"),_9o=o("YolosFeatureExtractor"),v9o=o(" (YOLOS model)"),b9o=l(),F(t_.$$.fragment),F9o=l(),F(a_.$$.fragment),T9o=l(),n_=a("div"),F(y$.$$.fragment),M9o=l(),J_e=a("p"),E9o=o("Register a new feature extractor for this class."),Ito=l(),$d=a("h2"),s_=a("a"),Y_e=a("span"),F(x$.$$.fragment),C9o=l(),Z_e=a("span"),w9o=o("AutoProcessor"),Nto=l(),Bo=a("div"),F($$.$$.fragment),A9o=l(),k$=a("p"),L9o=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),aX=a("a"),y9o=o("AutoProcessor.from_pretrained()"),x9o=o(" class method."),$9o=l(),S$=a("p"),k9o=o("This class cannot be instantiated directly using "),K_e=a("code"),S9o=o("__init__()"),R9o=o(" (throws an error)."),P9o=l(),Ze=a("div"),F(R$.$$.fragment),B9o=l(),e4e=a("p"),I9o=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),N9o=l(),kd=a("p"),q9o=o("The processor class to instantiate is selected based on the "),o4e=a("code"),j9o=o("model_type"),D9o=o(` property of the config object (either
passed as an argument or loaded from `),r4e=a("code"),G9o=o("pretrained_model_name_or_path"),O9o=o(" if possible):"),V9o=l(),le=a("ul"),l_=a("li"),t4e=a("strong"),X9o=o("clip"),z9o=o(" \u2014 "),nX=a("a"),Q9o=o("CLIPProcessor"),W9o=o(" (CLIP model)"),U9o=l(),i_=a("li"),a4e=a("strong"),H9o=o("flava"),J9o=o(" \u2014 "),sX=a("a"),Y9o=o("FlavaProcessor"),Z9o=o(" (FLAVA model)"),K9o=l(),d_=a("li"),n4e=a("strong"),exo=o("groupvit"),oxo=o(" \u2014 "),lX=a("a"),rxo=o("CLIPProcessor"),txo=o(" (GroupViT model)"),axo=l(),c_=a("li"),s4e=a("strong"),nxo=o("layoutlmv2"),sxo=o(" \u2014 "),iX=a("a"),lxo=o("LayoutLMv2Processor"),ixo=o(" (LayoutLMv2 model)"),dxo=l(),f_=a("li"),l4e=a("strong"),cxo=o("layoutlmv3"),fxo=o(" \u2014 "),dX=a("a"),mxo=o("LayoutLMv3Processor"),gxo=o(" (LayoutLMv3 model)"),hxo=l(),m_=a("li"),i4e=a("strong"),uxo=o("layoutxlm"),pxo=o(" \u2014 "),cX=a("a"),_xo=o("LayoutXLMProcessor"),vxo=o(" (LayoutXLM model)"),bxo=l(),g_=a("li"),d4e=a("strong"),Fxo=o("markuplm"),Txo=o(" \u2014 "),fX=a("a"),Mxo=o("MarkupLMProcessor"),Exo=o(" (MarkupLM model)"),Cxo=l(),h_=a("li"),c4e=a("strong"),wxo=o("owlvit"),Axo=o(" \u2014 "),mX=a("a"),Lxo=o("OwlViTProcessor"),yxo=o(" (OWL-ViT model)"),xxo=l(),u_=a("li"),f4e=a("strong"),$xo=o("sew"),kxo=o(" \u2014 "),gX=a("a"),Sxo=o("Wav2Vec2Processor"),Rxo=o(" (SEW model)"),Pxo=l(),p_=a("li"),m4e=a("strong"),Bxo=o("sew-d"),Ixo=o(" \u2014 "),hX=a("a"),Nxo=o("Wav2Vec2Processor"),qxo=o(" (SEW-D model)"),jxo=l(),__=a("li"),g4e=a("strong"),Dxo=o("speech_to_text"),Gxo=o(" \u2014 "),uX=a("a"),Oxo=o("Speech2TextProcessor"),Vxo=o(" (Speech2Text model)"),Xxo=l(),v_=a("li"),h4e=a("strong"),zxo=o("speech_to_text_2"),Qxo=o(" \u2014 "),pX=a("a"),Wxo=o("Speech2Text2Processor"),Uxo=o(" (Speech2Text2 model)"),Hxo=l(),b_=a("li"),u4e=a("strong"),Jxo=o("trocr"),Yxo=o(" \u2014 "),_X=a("a"),Zxo=o("TrOCRProcessor"),Kxo=o(" (TrOCR model)"),e$o=l(),F_=a("li"),p4e=a("strong"),o$o=o("unispeech"),r$o=o(" \u2014 "),vX=a("a"),t$o=o("Wav2Vec2Processor"),a$o=o(" (UniSpeech model)"),n$o=l(),T_=a("li"),_4e=a("strong"),s$o=o("unispeech-sat"),l$o=o(" \u2014 "),bX=a("a"),i$o=o("Wav2Vec2Processor"),d$o=o(" (UniSpeechSat model)"),c$o=l(),M_=a("li"),v4e=a("strong"),f$o=o("vilt"),m$o=o(" \u2014 "),FX=a("a"),g$o=o("ViltProcessor"),h$o=o(" (ViLT model)"),u$o=l(),E_=a("li"),b4e=a("strong"),p$o=o("vision-text-dual-encoder"),_$o=o(" \u2014 "),TX=a("a"),v$o=o("VisionTextDualEncoderProcessor"),b$o=o(" (VisionTextDualEncoder model)"),F$o=l(),C_=a("li"),F4e=a("strong"),T$o=o("wav2vec2"),M$o=o(" \u2014 "),MX=a("a"),E$o=o("Wav2Vec2Processor"),C$o=o(" (Wav2Vec2 model)"),w$o=l(),w_=a("li"),T4e=a("strong"),A$o=o("wav2vec2-conformer"),L$o=o(" \u2014 "),EX=a("a"),y$o=o("Wav2Vec2Processor"),x$o=o(" (Wav2Vec2-Conformer model)"),$$o=l(),A_=a("li"),M4e=a("strong"),k$o=o("wavlm"),S$o=o(" \u2014 "),CX=a("a"),R$o=o("Wav2Vec2Processor"),P$o=o(" (WavLM model)"),B$o=l(),L_=a("li"),E4e=a("strong"),I$o=o("whisper"),N$o=o(" \u2014 "),wX=a("a"),q$o=o("WhisperProcessor"),j$o=o(" (Whisper model)"),D$o=l(),y_=a("li"),C4e=a("strong"),G$o=o("xclip"),O$o=o(" \u2014 "),AX=a("a"),V$o=o("XCLIPProcessor"),X$o=o(" (X-CLIP model)"),z$o=l(),F(x_.$$.fragment),Q$o=l(),F($_.$$.fragment),W$o=l(),k_=a("div"),F(P$.$$.fragment),U$o=l(),w4e=a("p"),H$o=o("Register a new processor for this class."),qto=l(),Sd=a("h2"),S_=a("a"),A4e=a("span"),F(B$.$$.fragment),J$o=l(),L4e=a("span"),Y$o=o("AutoModel"),jto=l(),Io=a("div"),F(I$.$$.fragment),Z$o=l(),Rd=a("p"),K$o=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),LX=a("a"),eko=o("from_pretrained()"),oko=o(" class method or the "),yX=a("a"),rko=o("from_config()"),tko=o(` class
method.`),ako=l(),N$=a("p"),nko=o("This class cannot be instantiated directly using "),y4e=a("code"),sko=o("__init__()"),lko=o(" (throws an error)."),iko=l(),Mt=a("div"),F(q$.$$.fragment),dko=l(),x4e=a("p"),cko=o("Instantiates one of the base model classes of the library from a configuration."),fko=l(),Pd=a("p"),mko=o(`Note:
Loading a model from its configuration file does `),$4e=a("strong"),gko=o("not"),hko=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xX=a("a"),uko=o("from_pretrained()"),pko=o(" to load the model weights."),_ko=l(),F(R_.$$.fragment),vko=l(),Ke=a("div"),F(j$.$$.fragment),bko=l(),k4e=a("p"),Fko=o("Instantiate one of the base model classes of the library from a pretrained model."),Tko=l(),nn=a("p"),Mko=o("The model class to instantiate is selected based on the "),S4e=a("code"),Eko=o("model_type"),Cko=o(` property of the config object (either
passed as an argument or loaded from `),R4e=a("code"),wko=o("pretrained_model_name_or_path"),Ako=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P4e=a("code"),Lko=o("pretrained_model_name_or_path"),yko=o(":"),xko=l(),y=a("ul"),P_=a("li"),B4e=a("strong"),$ko=o("albert"),kko=o(" \u2014 "),$X=a("a"),Sko=o("AlbertModel"),Rko=o(" (ALBERT model)"),Pko=l(),B_=a("li"),I4e=a("strong"),Bko=o("bart"),Iko=o(" \u2014 "),kX=a("a"),Nko=o("BartModel"),qko=o(" (BART model)"),jko=l(),I_=a("li"),N4e=a("strong"),Dko=o("beit"),Gko=o(" \u2014 "),SX=a("a"),Oko=o("BeitModel"),Vko=o(" (BEiT model)"),Xko=l(),N_=a("li"),q4e=a("strong"),zko=o("bert"),Qko=o(" \u2014 "),RX=a("a"),Wko=o("BertModel"),Uko=o(" (BERT model)"),Hko=l(),q_=a("li"),j4e=a("strong"),Jko=o("bert-generation"),Yko=o(" \u2014 "),PX=a("a"),Zko=o("BertGenerationEncoder"),Kko=o(" (Bert Generation model)"),eSo=l(),j_=a("li"),D4e=a("strong"),oSo=o("big_bird"),rSo=o(" \u2014 "),BX=a("a"),tSo=o("BigBirdModel"),aSo=o(" (BigBird model)"),nSo=l(),D_=a("li"),G4e=a("strong"),sSo=o("bigbird_pegasus"),lSo=o(" \u2014 "),IX=a("a"),iSo=o("BigBirdPegasusModel"),dSo=o(" (BigBird-Pegasus model)"),cSo=l(),G_=a("li"),O4e=a("strong"),fSo=o("blenderbot"),mSo=o(" \u2014 "),NX=a("a"),gSo=o("BlenderbotModel"),hSo=o(" (Blenderbot model)"),uSo=l(),O_=a("li"),V4e=a("strong"),pSo=o("blenderbot-small"),_So=o(" \u2014 "),qX=a("a"),vSo=o("BlenderbotSmallModel"),bSo=o(" (BlenderbotSmall model)"),FSo=l(),V_=a("li"),X4e=a("strong"),TSo=o("bloom"),MSo=o(" \u2014 "),jX=a("a"),ESo=o("BloomModel"),CSo=o(" (BLOOM model)"),wSo=l(),X_=a("li"),z4e=a("strong"),ASo=o("camembert"),LSo=o(" \u2014 "),DX=a("a"),ySo=o("CamembertModel"),xSo=o(" (CamemBERT model)"),$So=l(),z_=a("li"),Q4e=a("strong"),kSo=o("canine"),SSo=o(" \u2014 "),GX=a("a"),RSo=o("CanineModel"),PSo=o(" (CANINE model)"),BSo=l(),Q_=a("li"),W4e=a("strong"),ISo=o("clip"),NSo=o(" \u2014 "),OX=a("a"),qSo=o("CLIPModel"),jSo=o(" (CLIP model)"),DSo=l(),W_=a("li"),U4e=a("strong"),GSo=o("codegen"),OSo=o(" \u2014 "),VX=a("a"),VSo=o("CodeGenModel"),XSo=o(" (CodeGen model)"),zSo=l(),U_=a("li"),H4e=a("strong"),QSo=o("conditional_detr"),WSo=o(" \u2014 "),XX=a("a"),USo=o("ConditionalDetrModel"),HSo=o(" (Conditional DETR model)"),JSo=l(),H_=a("li"),J4e=a("strong"),YSo=o("convbert"),ZSo=o(" \u2014 "),zX=a("a"),KSo=o("ConvBertModel"),eRo=o(" (ConvBERT model)"),oRo=l(),J_=a("li"),Y4e=a("strong"),rRo=o("convnext"),tRo=o(" \u2014 "),QX=a("a"),aRo=o("ConvNextModel"),nRo=o(" (ConvNeXT model)"),sRo=l(),Y_=a("li"),Z4e=a("strong"),lRo=o("ctrl"),iRo=o(" \u2014 "),WX=a("a"),dRo=o("CTRLModel"),cRo=o(" (CTRL model)"),fRo=l(),Z_=a("li"),K4e=a("strong"),mRo=o("cvt"),gRo=o(" \u2014 "),UX=a("a"),hRo=o("CvtModel"),uRo=o(" (CvT model)"),pRo=l(),K_=a("li"),e2e=a("strong"),_Ro=o("data2vec-audio"),vRo=o(" \u2014 "),HX=a("a"),bRo=o("Data2VecAudioModel"),FRo=o(" (Data2VecAudio model)"),TRo=l(),e4=a("li"),o2e=a("strong"),MRo=o("data2vec-text"),ERo=o(" \u2014 "),JX=a("a"),CRo=o("Data2VecTextModel"),wRo=o(" (Data2VecText model)"),ARo=l(),o4=a("li"),r2e=a("strong"),LRo=o("data2vec-vision"),yRo=o(" \u2014 "),YX=a("a"),xRo=o("Data2VecVisionModel"),$Ro=o(" (Data2VecVision model)"),kRo=l(),r4=a("li"),t2e=a("strong"),SRo=o("deberta"),RRo=o(" \u2014 "),ZX=a("a"),PRo=o("DebertaModel"),BRo=o(" (DeBERTa model)"),IRo=l(),t4=a("li"),a2e=a("strong"),NRo=o("deberta-v2"),qRo=o(" \u2014 "),KX=a("a"),jRo=o("DebertaV2Model"),DRo=o(" (DeBERTa-v2 model)"),GRo=l(),a4=a("li"),n2e=a("strong"),ORo=o("decision_transformer"),VRo=o(" \u2014 "),ez=a("a"),XRo=o("DecisionTransformerModel"),zRo=o(" (Decision Transformer model)"),QRo=l(),n4=a("li"),s2e=a("strong"),WRo=o("deformable_detr"),URo=o(" \u2014 "),oz=a("a"),HRo=o("DeformableDetrModel"),JRo=o(" (Deformable DETR model)"),YRo=l(),s4=a("li"),l2e=a("strong"),ZRo=o("deit"),KRo=o(" \u2014 "),rz=a("a"),ePo=o("DeiTModel"),oPo=o(" (DeiT model)"),rPo=l(),l4=a("li"),i2e=a("strong"),tPo=o("detr"),aPo=o(" \u2014 "),tz=a("a"),nPo=o("DetrModel"),sPo=o(" (DETR model)"),lPo=l(),i4=a("li"),d2e=a("strong"),iPo=o("distilbert"),dPo=o(" \u2014 "),az=a("a"),cPo=o("DistilBertModel"),fPo=o(" (DistilBERT model)"),mPo=l(),d4=a("li"),c2e=a("strong"),gPo=o("donut-swin"),hPo=o(" \u2014 "),nz=a("a"),uPo=o("DonutSwinModel"),pPo=o(" (DonutSwin model)"),_Po=l(),c4=a("li"),f2e=a("strong"),vPo=o("dpr"),bPo=o(" \u2014 "),sz=a("a"),FPo=o("DPRQuestionEncoder"),TPo=o(" (DPR model)"),MPo=l(),f4=a("li"),m2e=a("strong"),EPo=o("dpt"),CPo=o(" \u2014 "),lz=a("a"),wPo=o("DPTModel"),APo=o(" (DPT model)"),LPo=l(),m4=a("li"),g2e=a("strong"),yPo=o("electra"),xPo=o(" \u2014 "),iz=a("a"),$Po=o("ElectraModel"),kPo=o(" (ELECTRA model)"),SPo=l(),g4=a("li"),h2e=a("strong"),RPo=o("ernie"),PPo=o(" \u2014 "),dz=a("a"),BPo=o("ErnieModel"),IPo=o(" (ERNIE model)"),NPo=l(),h4=a("li"),u2e=a("strong"),qPo=o("esm"),jPo=o(" \u2014 "),cz=a("a"),DPo=o("EsmModel"),GPo=o(" (ESM model)"),OPo=l(),u4=a("li"),p2e=a("strong"),VPo=o("flaubert"),XPo=o(" \u2014 "),fz=a("a"),zPo=o("FlaubertModel"),QPo=o(" (FlauBERT model)"),WPo=l(),p4=a("li"),_2e=a("strong"),UPo=o("flava"),HPo=o(" \u2014 "),mz=a("a"),JPo=o("FlavaModel"),YPo=o(" (FLAVA model)"),ZPo=l(),_4=a("li"),v2e=a("strong"),KPo=o("fnet"),eBo=o(" \u2014 "),gz=a("a"),oBo=o("FNetModel"),rBo=o(" (FNet model)"),tBo=l(),v4=a("li"),b2e=a("strong"),aBo=o("fsmt"),nBo=o(" \u2014 "),hz=a("a"),sBo=o("FSMTModel"),lBo=o(" (FairSeq Machine-Translation model)"),iBo=l(),xl=a("li"),F2e=a("strong"),dBo=o("funnel"),cBo=o(" \u2014 "),uz=a("a"),fBo=o("FunnelModel"),mBo=o(" or "),pz=a("a"),gBo=o("FunnelBaseModel"),hBo=o(" (Funnel Transformer model)"),uBo=l(),b4=a("li"),T2e=a("strong"),pBo=o("glpn"),_Bo=o(" \u2014 "),_z=a("a"),vBo=o("GLPNModel"),bBo=o(" (GLPN model)"),FBo=l(),F4=a("li"),M2e=a("strong"),TBo=o("gpt2"),MBo=o(" \u2014 "),vz=a("a"),EBo=o("GPT2Model"),CBo=o(" (OpenAI GPT-2 model)"),wBo=l(),T4=a("li"),E2e=a("strong"),ABo=o("gpt_neo"),LBo=o(" \u2014 "),bz=a("a"),yBo=o("GPTNeoModel"),xBo=o(" (GPT Neo model)"),$Bo=l(),M4=a("li"),C2e=a("strong"),kBo=o("gpt_neox"),SBo=o(" \u2014 "),Fz=a("a"),RBo=o("GPTNeoXModel"),PBo=o(" (GPT NeoX model)"),BBo=l(),E4=a("li"),w2e=a("strong"),IBo=o("gpt_neox_japanese"),NBo=o(" \u2014 "),Tz=a("a"),qBo=o("GPTNeoXJapaneseModel"),jBo=o(" (GPT NeoX Japanese model)"),DBo=l(),C4=a("li"),A2e=a("strong"),GBo=o("gptj"),OBo=o(" \u2014 "),Mz=a("a"),VBo=o("GPTJModel"),XBo=o(" (GPT-J model)"),zBo=l(),w4=a("li"),L2e=a("strong"),QBo=o("groupvit"),WBo=o(" \u2014 "),Ez=a("a"),UBo=o("GroupViTModel"),HBo=o(" (GroupViT model)"),JBo=l(),A4=a("li"),y2e=a("strong"),YBo=o("hubert"),ZBo=o(" \u2014 "),Cz=a("a"),KBo=o("HubertModel"),eIo=o(" (Hubert model)"),oIo=l(),L4=a("li"),x2e=a("strong"),rIo=o("ibert"),tIo=o(" \u2014 "),wz=a("a"),aIo=o("IBertModel"),nIo=o(" (I-BERT model)"),sIo=l(),y4=a("li"),$2e=a("strong"),lIo=o("imagegpt"),iIo=o(" \u2014 "),Az=a("a"),dIo=o("ImageGPTModel"),cIo=o(" (ImageGPT model)"),fIo=l(),x4=a("li"),k2e=a("strong"),mIo=o("layoutlm"),gIo=o(" \u2014 "),Lz=a("a"),hIo=o("LayoutLMModel"),uIo=o(" (LayoutLM model)"),pIo=l(),$4=a("li"),S2e=a("strong"),_Io=o("layoutlmv2"),vIo=o(" \u2014 "),yz=a("a"),bIo=o("LayoutLMv2Model"),FIo=o(" (LayoutLMv2 model)"),TIo=l(),k4=a("li"),R2e=a("strong"),MIo=o("layoutlmv3"),EIo=o(" \u2014 "),xz=a("a"),CIo=o("LayoutLMv3Model"),wIo=o(" (LayoutLMv3 model)"),AIo=l(),S4=a("li"),P2e=a("strong"),LIo=o("led"),yIo=o(" \u2014 "),$z=a("a"),xIo=o("LEDModel"),$Io=o(" (LED model)"),kIo=l(),R4=a("li"),B2e=a("strong"),SIo=o("levit"),RIo=o(" \u2014 "),kz=a("a"),PIo=o("LevitModel"),BIo=o(" (LeViT model)"),IIo=l(),P4=a("li"),I2e=a("strong"),NIo=o("lilt"),qIo=o(" \u2014 "),Sz=a("a"),jIo=o("LiltModel"),DIo=o(" (LiLT model)"),GIo=l(),B4=a("li"),N2e=a("strong"),OIo=o("longformer"),VIo=o(" \u2014 "),Rz=a("a"),XIo=o("LongformerModel"),zIo=o(" (Longformer model)"),QIo=l(),I4=a("li"),q2e=a("strong"),WIo=o("longt5"),UIo=o(" \u2014 "),Pz=a("a"),HIo=o("LongT5Model"),JIo=o(" (LongT5 model)"),YIo=l(),N4=a("li"),j2e=a("strong"),ZIo=o("luke"),KIo=o(" \u2014 "),Bz=a("a"),eNo=o("LukeModel"),oNo=o(" (LUKE model)"),rNo=l(),q4=a("li"),D2e=a("strong"),tNo=o("lxmert"),aNo=o(" \u2014 "),Iz=a("a"),nNo=o("LxmertModel"),sNo=o(" (LXMERT model)"),lNo=l(),j4=a("li"),G2e=a("strong"),iNo=o("m2m_100"),dNo=o(" \u2014 "),Nz=a("a"),cNo=o("M2M100Model"),fNo=o(" (M2M100 model)"),mNo=l(),D4=a("li"),O2e=a("strong"),gNo=o("marian"),hNo=o(" \u2014 "),qz=a("a"),uNo=o("MarianModel"),pNo=o(" (Marian model)"),_No=l(),G4=a("li"),V2e=a("strong"),vNo=o("markuplm"),bNo=o(" \u2014 "),jz=a("a"),FNo=o("MarkupLMModel"),TNo=o(" (MarkupLM model)"),MNo=l(),O4=a("li"),X2e=a("strong"),ENo=o("maskformer"),CNo=o(" \u2014 "),Dz=a("a"),wNo=o("MaskFormerModel"),ANo=o(" (MaskFormer model)"),LNo=l(),V4=a("li"),z2e=a("strong"),yNo=o("mbart"),xNo=o(" \u2014 "),Gz=a("a"),$No=o("MBartModel"),kNo=o(" (mBART model)"),SNo=l(),X4=a("li"),Q2e=a("strong"),RNo=o("mctct"),PNo=o(" \u2014 "),Oz=a("a"),BNo=o("MCTCTModel"),INo=o(" (M-CTC-T model)"),NNo=l(),z4=a("li"),W2e=a("strong"),qNo=o("megatron-bert"),jNo=o(" \u2014 "),Vz=a("a"),DNo=o("MegatronBertModel"),GNo=o(" (Megatron-BERT model)"),ONo=l(),Q4=a("li"),U2e=a("strong"),VNo=o("mobilebert"),XNo=o(" \u2014 "),Xz=a("a"),zNo=o("MobileBertModel"),QNo=o(" (MobileBERT model)"),WNo=l(),W4=a("li"),H2e=a("strong"),UNo=o("mobilevit"),HNo=o(" \u2014 "),zz=a("a"),JNo=o("MobileViTModel"),YNo=o(" (MobileViT model)"),ZNo=l(),U4=a("li"),J2e=a("strong"),KNo=o("mpnet"),eqo=o(" \u2014 "),Qz=a("a"),oqo=o("MPNetModel"),rqo=o(" (MPNet model)"),tqo=l(),H4=a("li"),Y2e=a("strong"),aqo=o("mt5"),nqo=o(" \u2014 "),Wz=a("a"),sqo=o("MT5Model"),lqo=o(" (MT5 model)"),iqo=l(),J4=a("li"),Z2e=a("strong"),dqo=o("mvp"),cqo=o(" \u2014 "),Uz=a("a"),fqo=o("MvpModel"),mqo=o(" (MVP model)"),gqo=l(),Y4=a("li"),K2e=a("strong"),hqo=o("nezha"),uqo=o(" \u2014 "),Hz=a("a"),pqo=o("NezhaModel"),_qo=o(" (Nezha model)"),vqo=l(),Z4=a("li"),eve=a("strong"),bqo=o("nllb"),Fqo=o(" \u2014 "),Jz=a("a"),Tqo=o("M2M100Model"),Mqo=o(" (NLLB model)"),Eqo=l(),K4=a("li"),ove=a("strong"),Cqo=o("nystromformer"),wqo=o(" \u2014 "),Yz=a("a"),Aqo=o("NystromformerModel"),Lqo=o(" (Nystr\xF6mformer model)"),yqo=l(),e2=a("li"),rve=a("strong"),xqo=o("openai-gpt"),$qo=o(" \u2014 "),Zz=a("a"),kqo=o("OpenAIGPTModel"),Sqo=o(" (OpenAI GPT model)"),Rqo=l(),o2=a("li"),tve=a("strong"),Pqo=o("opt"),Bqo=o(" \u2014 "),Kz=a("a"),Iqo=o("OPTModel"),Nqo=o(" (OPT model)"),qqo=l(),r2=a("li"),ave=a("strong"),jqo=o("owlvit"),Dqo=o(" \u2014 "),eQ=a("a"),Gqo=o("OwlViTModel"),Oqo=o(" (OWL-ViT model)"),Vqo=l(),t2=a("li"),nve=a("strong"),Xqo=o("pegasus"),zqo=o(" \u2014 "),oQ=a("a"),Qqo=o("PegasusModel"),Wqo=o(" (Pegasus model)"),Uqo=l(),a2=a("li"),sve=a("strong"),Hqo=o("pegasus_x"),Jqo=o(" \u2014 "),rQ=a("a"),Yqo=o("PegasusXModel"),Zqo=o(" (PEGASUS-X model)"),Kqo=l(),n2=a("li"),lve=a("strong"),ejo=o("perceiver"),ojo=o(" \u2014 "),tQ=a("a"),rjo=o("PerceiverModel"),tjo=o(" (Perceiver model)"),ajo=l(),s2=a("li"),ive=a("strong"),njo=o("plbart"),sjo=o(" \u2014 "),aQ=a("a"),ljo=o("PLBartModel"),ijo=o(" (PLBart model)"),djo=l(),l2=a("li"),dve=a("strong"),cjo=o("poolformer"),fjo=o(" \u2014 "),nQ=a("a"),mjo=o("PoolFormerModel"),gjo=o(" (PoolFormer model)"),hjo=l(),i2=a("li"),cve=a("strong"),ujo=o("prophetnet"),pjo=o(" \u2014 "),sQ=a("a"),_jo=o("ProphetNetModel"),vjo=o(" (ProphetNet model)"),bjo=l(),d2=a("li"),fve=a("strong"),Fjo=o("qdqbert"),Tjo=o(" \u2014 "),lQ=a("a"),Mjo=o("QDQBertModel"),Ejo=o(" (QDQBert model)"),Cjo=l(),c2=a("li"),mve=a("strong"),wjo=o("reformer"),Ajo=o(" \u2014 "),iQ=a("a"),Ljo=o("ReformerModel"),yjo=o(" (Reformer model)"),xjo=l(),f2=a("li"),gve=a("strong"),$jo=o("regnet"),kjo=o(" \u2014 "),dQ=a("a"),Sjo=o("RegNetModel"),Rjo=o(" (RegNet model)"),Pjo=l(),m2=a("li"),hve=a("strong"),Bjo=o("rembert"),Ijo=o(" \u2014 "),cQ=a("a"),Njo=o("RemBertModel"),qjo=o(" (RemBERT model)"),jjo=l(),g2=a("li"),uve=a("strong"),Djo=o("resnet"),Gjo=o(" \u2014 "),fQ=a("a"),Ojo=o("ResNetModel"),Vjo=o(" (ResNet model)"),Xjo=l(),h2=a("li"),pve=a("strong"),zjo=o("retribert"),Qjo=o(" \u2014 "),mQ=a("a"),Wjo=o("RetriBertModel"),Ujo=o(" (RetriBERT model)"),Hjo=l(),u2=a("li"),_ve=a("strong"),Jjo=o("roberta"),Yjo=o(" \u2014 "),gQ=a("a"),Zjo=o("RobertaModel"),Kjo=o(" (RoBERTa model)"),eDo=l(),p2=a("li"),vve=a("strong"),oDo=o("roformer"),rDo=o(" \u2014 "),hQ=a("a"),tDo=o("RoFormerModel"),aDo=o(" (RoFormer model)"),nDo=l(),_2=a("li"),bve=a("strong"),sDo=o("segformer"),lDo=o(" \u2014 "),uQ=a("a"),iDo=o("SegformerModel"),dDo=o(" (SegFormer model)"),cDo=l(),v2=a("li"),Fve=a("strong"),fDo=o("sew"),mDo=o(" \u2014 "),pQ=a("a"),gDo=o("SEWModel"),hDo=o(" (SEW model)"),uDo=l(),b2=a("li"),Tve=a("strong"),pDo=o("sew-d"),_Do=o(" \u2014 "),_Q=a("a"),vDo=o("SEWDModel"),bDo=o(" (SEW-D model)"),FDo=l(),F2=a("li"),Mve=a("strong"),TDo=o("speech_to_text"),MDo=o(" \u2014 "),vQ=a("a"),EDo=o("Speech2TextModel"),CDo=o(" (Speech2Text model)"),wDo=l(),T2=a("li"),Eve=a("strong"),ADo=o("splinter"),LDo=o(" \u2014 "),bQ=a("a"),yDo=o("SplinterModel"),xDo=o(" (Splinter model)"),$Do=l(),M2=a("li"),Cve=a("strong"),kDo=o("squeezebert"),SDo=o(" \u2014 "),FQ=a("a"),RDo=o("SqueezeBertModel"),PDo=o(" (SqueezeBERT model)"),BDo=l(),E2=a("li"),wve=a("strong"),IDo=o("swin"),NDo=o(" \u2014 "),TQ=a("a"),qDo=o("SwinModel"),jDo=o(" (Swin Transformer model)"),DDo=l(),C2=a("li"),Ave=a("strong"),GDo=o("swinv2"),ODo=o(" \u2014 "),MQ=a("a"),VDo=o("Swinv2Model"),XDo=o(" (Swin Transformer V2 model)"),zDo=l(),w2=a("li"),Lve=a("strong"),QDo=o("t5"),WDo=o(" \u2014 "),EQ=a("a"),UDo=o("T5Model"),HDo=o(" (T5 model)"),JDo=l(),A2=a("li"),yve=a("strong"),YDo=o("table-transformer"),ZDo=o(" \u2014 "),CQ=a("a"),KDo=o("TableTransformerModel"),eGo=o(" (Table Transformer model)"),oGo=l(),L2=a("li"),xve=a("strong"),rGo=o("tapas"),tGo=o(" \u2014 "),wQ=a("a"),aGo=o("TapasModel"),nGo=o(" (TAPAS model)"),sGo=l(),y2=a("li"),$ve=a("strong"),lGo=o("time_series_transformer"),iGo=o(" \u2014 "),AQ=a("a"),dGo=o("TimeSeriesTransformerModel"),cGo=o(" (Time Series Transformer model)"),fGo=l(),x2=a("li"),kve=a("strong"),mGo=o("trajectory_transformer"),gGo=o(" \u2014 "),LQ=a("a"),hGo=o("TrajectoryTransformerModel"),uGo=o(" (Trajectory Transformer model)"),pGo=l(),$2=a("li"),Sve=a("strong"),_Go=o("transfo-xl"),vGo=o(" \u2014 "),yQ=a("a"),bGo=o("TransfoXLModel"),FGo=o(" (Transformer-XL model)"),TGo=l(),k2=a("li"),Rve=a("strong"),MGo=o("unispeech"),EGo=o(" \u2014 "),xQ=a("a"),CGo=o("UniSpeechModel"),wGo=o(" (UniSpeech model)"),AGo=l(),S2=a("li"),Pve=a("strong"),LGo=o("unispeech-sat"),yGo=o(" \u2014 "),$Q=a("a"),xGo=o("UniSpeechSatModel"),$Go=o(" (UniSpeechSat model)"),kGo=l(),R2=a("li"),Bve=a("strong"),SGo=o("van"),RGo=o(" \u2014 "),kQ=a("a"),PGo=o("VanModel"),BGo=o(" (VAN model)"),IGo=l(),P2=a("li"),Ive=a("strong"),NGo=o("videomae"),qGo=o(" \u2014 "),SQ=a("a"),jGo=o("VideoMAEModel"),DGo=o(" (VideoMAE model)"),GGo=l(),B2=a("li"),Nve=a("strong"),OGo=o("vilt"),VGo=o(" \u2014 "),RQ=a("a"),XGo=o("ViltModel"),zGo=o(" (ViLT model)"),QGo=l(),I2=a("li"),qve=a("strong"),WGo=o("vision-text-dual-encoder"),UGo=o(" \u2014 "),PQ=a("a"),HGo=o("VisionTextDualEncoderModel"),JGo=o(" (VisionTextDualEncoder model)"),YGo=l(),N2=a("li"),jve=a("strong"),ZGo=o("visual_bert"),KGo=o(" \u2014 "),BQ=a("a"),eOo=o("VisualBertModel"),oOo=o(" (VisualBERT model)"),rOo=l(),q2=a("li"),Dve=a("strong"),tOo=o("vit"),aOo=o(" \u2014 "),IQ=a("a"),nOo=o("ViTModel"),sOo=o(" (ViT model)"),lOo=l(),j2=a("li"),Gve=a("strong"),iOo=o("vit_mae"),dOo=o(" \u2014 "),NQ=a("a"),cOo=o("ViTMAEModel"),fOo=o(" (ViTMAE model)"),mOo=l(),D2=a("li"),Ove=a("strong"),gOo=o("vit_msn"),hOo=o(" \u2014 "),qQ=a("a"),uOo=o("ViTMSNModel"),pOo=o(" (ViTMSN model)"),_Oo=l(),G2=a("li"),Vve=a("strong"),vOo=o("wav2vec2"),bOo=o(" \u2014 "),jQ=a("a"),FOo=o("Wav2Vec2Model"),TOo=o(" (Wav2Vec2 model)"),MOo=l(),O2=a("li"),Xve=a("strong"),EOo=o("wav2vec2-conformer"),COo=o(" \u2014 "),DQ=a("a"),wOo=o("Wav2Vec2ConformerModel"),AOo=o(" (Wav2Vec2-Conformer model)"),LOo=l(),V2=a("li"),zve=a("strong"),yOo=o("wavlm"),xOo=o(" \u2014 "),GQ=a("a"),$Oo=o("WavLMModel"),kOo=o(" (WavLM model)"),SOo=l(),X2=a("li"),Qve=a("strong"),ROo=o("whisper"),POo=o(" \u2014 "),OQ=a("a"),BOo=o("WhisperModel"),IOo=o(" (Whisper model)"),NOo=l(),z2=a("li"),Wve=a("strong"),qOo=o("xclip"),jOo=o(" \u2014 "),VQ=a("a"),DOo=o("XCLIPModel"),GOo=o(" (X-CLIP model)"),OOo=l(),Q2=a("li"),Uve=a("strong"),VOo=o("xglm"),XOo=o(" \u2014 "),XQ=a("a"),zOo=o("XGLMModel"),QOo=o(" (XGLM model)"),WOo=l(),W2=a("li"),Hve=a("strong"),UOo=o("xlm"),HOo=o(" \u2014 "),zQ=a("a"),JOo=o("XLMModel"),YOo=o(" (XLM model)"),ZOo=l(),U2=a("li"),Jve=a("strong"),KOo=o("xlm-prophetnet"),eVo=o(" \u2014 "),QQ=a("a"),oVo=o("XLMProphetNetModel"),rVo=o(" (XLM-ProphetNet model)"),tVo=l(),H2=a("li"),Yve=a("strong"),aVo=o("xlm-roberta"),nVo=o(" \u2014 "),WQ=a("a"),sVo=o("XLMRobertaModel"),lVo=o(" (XLM-RoBERTa model)"),iVo=l(),J2=a("li"),Zve=a("strong"),dVo=o("xlm-roberta-xl"),cVo=o(" \u2014 "),UQ=a("a"),fVo=o("XLMRobertaXLModel"),mVo=o(" (XLM-RoBERTa-XL model)"),gVo=l(),Y2=a("li"),Kve=a("strong"),hVo=o("xlnet"),uVo=o(" \u2014 "),HQ=a("a"),pVo=o("XLNetModel"),_Vo=o(" (XLNet model)"),vVo=l(),Z2=a("li"),e1e=a("strong"),bVo=o("yolos"),FVo=o(" \u2014 "),JQ=a("a"),TVo=o("YolosModel"),MVo=o(" (YOLOS model)"),EVo=l(),K2=a("li"),o1e=a("strong"),CVo=o("yoso"),wVo=o(" \u2014 "),YQ=a("a"),AVo=o("YosoModel"),LVo=o(" (YOSO model)"),yVo=l(),ev=a("p"),xVo=o("The model is set in evaluation mode by default using "),r1e=a("code"),$Vo=o("model.eval()"),kVo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),t1e=a("code"),SVo=o("model.train()"),RVo=l(),F(ov.$$.fragment),Dto=l(),Bd=a("h2"),rv=a("a"),a1e=a("span"),F(D$.$$.fragment),PVo=l(),n1e=a("span"),BVo=o("AutoModelForPreTraining"),Gto=l(),No=a("div"),F(G$.$$.fragment),IVo=l(),Id=a("p"),NVo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),ZQ=a("a"),qVo=o("from_pretrained()"),jVo=o(" class method or the "),KQ=a("a"),DVo=o("from_config()"),GVo=o(` class
method.`),OVo=l(),O$=a("p"),VVo=o("This class cannot be instantiated directly using "),s1e=a("code"),XVo=o("__init__()"),zVo=o(" (throws an error)."),QVo=l(),Et=a("div"),F(V$.$$.fragment),WVo=l(),l1e=a("p"),UVo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),HVo=l(),Nd=a("p"),JVo=o(`Note:
Loading a model from its configuration file does `),i1e=a("strong"),YVo=o("not"),ZVo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eW=a("a"),KVo=o("from_pretrained()"),eXo=o(" to load the model weights."),oXo=l(),F(tv.$$.fragment),rXo=l(),eo=a("div"),F(X$.$$.fragment),tXo=l(),d1e=a("p"),aXo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),nXo=l(),sn=a("p"),sXo=o("The model class to instantiate is selected based on the "),c1e=a("code"),lXo=o("model_type"),iXo=o(` property of the config object (either
passed as an argument or loaded from `),f1e=a("code"),dXo=o("pretrained_model_name_or_path"),cXo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m1e=a("code"),fXo=o("pretrained_model_name_or_path"),mXo=o(":"),gXo=l(),G=a("ul"),av=a("li"),g1e=a("strong"),hXo=o("albert"),uXo=o(" \u2014 "),oW=a("a"),pXo=o("AlbertForPreTraining"),_Xo=o(" (ALBERT model)"),vXo=l(),nv=a("li"),h1e=a("strong"),bXo=o("bart"),FXo=o(" \u2014 "),rW=a("a"),TXo=o("BartForConditionalGeneration"),MXo=o(" (BART model)"),EXo=l(),sv=a("li"),u1e=a("strong"),CXo=o("bert"),wXo=o(" \u2014 "),tW=a("a"),AXo=o("BertForPreTraining"),LXo=o(" (BERT model)"),yXo=l(),lv=a("li"),p1e=a("strong"),xXo=o("big_bird"),$Xo=o(" \u2014 "),aW=a("a"),kXo=o("BigBirdForPreTraining"),SXo=o(" (BigBird model)"),RXo=l(),iv=a("li"),_1e=a("strong"),PXo=o("bloom"),BXo=o(" \u2014 "),nW=a("a"),IXo=o("BloomForCausalLM"),NXo=o(" (BLOOM model)"),qXo=l(),dv=a("li"),v1e=a("strong"),jXo=o("camembert"),DXo=o(" \u2014 "),sW=a("a"),GXo=o("CamembertForMaskedLM"),OXo=o(" (CamemBERT model)"),VXo=l(),cv=a("li"),b1e=a("strong"),XXo=o("ctrl"),zXo=o(" \u2014 "),lW=a("a"),QXo=o("CTRLLMHeadModel"),WXo=o(" (CTRL model)"),UXo=l(),fv=a("li"),F1e=a("strong"),HXo=o("data2vec-text"),JXo=o(" \u2014 "),iW=a("a"),YXo=o("Data2VecTextForMaskedLM"),ZXo=o(" (Data2VecText model)"),KXo=l(),mv=a("li"),T1e=a("strong"),ezo=o("deberta"),ozo=o(" \u2014 "),dW=a("a"),rzo=o("DebertaForMaskedLM"),tzo=o(" (DeBERTa model)"),azo=l(),gv=a("li"),M1e=a("strong"),nzo=o("deberta-v2"),szo=o(" \u2014 "),cW=a("a"),lzo=o("DebertaV2ForMaskedLM"),izo=o(" (DeBERTa-v2 model)"),dzo=l(),hv=a("li"),E1e=a("strong"),czo=o("distilbert"),fzo=o(" \u2014 "),fW=a("a"),mzo=o("DistilBertForMaskedLM"),gzo=o(" (DistilBERT model)"),hzo=l(),uv=a("li"),C1e=a("strong"),uzo=o("electra"),pzo=o(" \u2014 "),mW=a("a"),_zo=o("ElectraForPreTraining"),vzo=o(" (ELECTRA model)"),bzo=l(),pv=a("li"),w1e=a("strong"),Fzo=o("ernie"),Tzo=o(" \u2014 "),gW=a("a"),Mzo=o("ErnieForPreTraining"),Ezo=o(" (ERNIE model)"),Czo=l(),_v=a("li"),A1e=a("strong"),wzo=o("flaubert"),Azo=o(" \u2014 "),hW=a("a"),Lzo=o("FlaubertWithLMHeadModel"),yzo=o(" (FlauBERT model)"),xzo=l(),vv=a("li"),L1e=a("strong"),$zo=o("flava"),kzo=o(" \u2014 "),uW=a("a"),Szo=o("FlavaForPreTraining"),Rzo=o(" (FLAVA model)"),Pzo=l(),bv=a("li"),y1e=a("strong"),Bzo=o("fnet"),Izo=o(" \u2014 "),pW=a("a"),Nzo=o("FNetForPreTraining"),qzo=o(" (FNet model)"),jzo=l(),Fv=a("li"),x1e=a("strong"),Dzo=o("fsmt"),Gzo=o(" \u2014 "),_W=a("a"),Ozo=o("FSMTForConditionalGeneration"),Vzo=o(" (FairSeq Machine-Translation model)"),Xzo=l(),Tv=a("li"),$1e=a("strong"),zzo=o("funnel"),Qzo=o(" \u2014 "),vW=a("a"),Wzo=o("FunnelForPreTraining"),Uzo=o(" (Funnel Transformer model)"),Hzo=l(),Mv=a("li"),k1e=a("strong"),Jzo=o("gpt2"),Yzo=o(" \u2014 "),bW=a("a"),Zzo=o("GPT2LMHeadModel"),Kzo=o(" (OpenAI GPT-2 model)"),eQo=l(),Ev=a("li"),S1e=a("strong"),oQo=o("ibert"),rQo=o(" \u2014 "),FW=a("a"),tQo=o("IBertForMaskedLM"),aQo=o(" (I-BERT model)"),nQo=l(),Cv=a("li"),R1e=a("strong"),sQo=o("layoutlm"),lQo=o(" \u2014 "),TW=a("a"),iQo=o("LayoutLMForMaskedLM"),dQo=o(" (LayoutLM model)"),cQo=l(),wv=a("li"),P1e=a("strong"),fQo=o("longformer"),mQo=o(" \u2014 "),MW=a("a"),gQo=o("LongformerForMaskedLM"),hQo=o(" (Longformer model)"),uQo=l(),Av=a("li"),B1e=a("strong"),pQo=o("luke"),_Qo=o(" \u2014 "),EW=a("a"),vQo=o("LukeForMaskedLM"),bQo=o(" (LUKE model)"),FQo=l(),Lv=a("li"),I1e=a("strong"),TQo=o("lxmert"),MQo=o(" \u2014 "),CW=a("a"),EQo=o("LxmertForPreTraining"),CQo=o(" (LXMERT model)"),wQo=l(),yv=a("li"),N1e=a("strong"),AQo=o("megatron-bert"),LQo=o(" \u2014 "),wW=a("a"),yQo=o("MegatronBertForPreTraining"),xQo=o(" (Megatron-BERT model)"),$Qo=l(),xv=a("li"),q1e=a("strong"),kQo=o("mobilebert"),SQo=o(" \u2014 "),AW=a("a"),RQo=o("MobileBertForPreTraining"),PQo=o(" (MobileBERT model)"),BQo=l(),$v=a("li"),j1e=a("strong"),IQo=o("mpnet"),NQo=o(" \u2014 "),LW=a("a"),qQo=o("MPNetForMaskedLM"),jQo=o(" (MPNet model)"),DQo=l(),kv=a("li"),D1e=a("strong"),GQo=o("mvp"),OQo=o(" \u2014 "),yW=a("a"),VQo=o("MvpForConditionalGeneration"),XQo=o(" (MVP model)"),zQo=l(),Sv=a("li"),G1e=a("strong"),QQo=o("nezha"),WQo=o(" \u2014 "),xW=a("a"),UQo=o("NezhaForPreTraining"),HQo=o(" (Nezha model)"),JQo=l(),Rv=a("li"),O1e=a("strong"),YQo=o("openai-gpt"),ZQo=o(" \u2014 "),$W=a("a"),KQo=o("OpenAIGPTLMHeadModel"),eWo=o(" (OpenAI GPT model)"),oWo=l(),Pv=a("li"),V1e=a("strong"),rWo=o("retribert"),tWo=o(" \u2014 "),kW=a("a"),aWo=o("RetriBertModel"),nWo=o(" (RetriBERT model)"),sWo=l(),Bv=a("li"),X1e=a("strong"),lWo=o("roberta"),iWo=o(" \u2014 "),SW=a("a"),dWo=o("RobertaForMaskedLM"),cWo=o(" (RoBERTa model)"),fWo=l(),Iv=a("li"),z1e=a("strong"),mWo=o("splinter"),gWo=o(" \u2014 "),RW=a("a"),hWo=o("SplinterForPreTraining"),uWo=o(" (Splinter model)"),pWo=l(),Nv=a("li"),Q1e=a("strong"),_Wo=o("squeezebert"),vWo=o(" \u2014 "),PW=a("a"),bWo=o("SqueezeBertForMaskedLM"),FWo=o(" (SqueezeBERT model)"),TWo=l(),qv=a("li"),W1e=a("strong"),MWo=o("t5"),EWo=o(" \u2014 "),BW=a("a"),CWo=o("T5ForConditionalGeneration"),wWo=o(" (T5 model)"),AWo=l(),jv=a("li"),U1e=a("strong"),LWo=o("tapas"),yWo=o(" \u2014 "),IW=a("a"),xWo=o("TapasForMaskedLM"),$Wo=o(" (TAPAS model)"),kWo=l(),Dv=a("li"),H1e=a("strong"),SWo=o("transfo-xl"),RWo=o(" \u2014 "),NW=a("a"),PWo=o("TransfoXLLMHeadModel"),BWo=o(" (Transformer-XL model)"),IWo=l(),Gv=a("li"),J1e=a("strong"),NWo=o("unispeech"),qWo=o(" \u2014 "),qW=a("a"),jWo=o("UniSpeechForPreTraining"),DWo=o(" (UniSpeech model)"),GWo=l(),Ov=a("li"),Y1e=a("strong"),OWo=o("unispeech-sat"),VWo=o(" \u2014 "),jW=a("a"),XWo=o("UniSpeechSatForPreTraining"),zWo=o(" (UniSpeechSat model)"),QWo=l(),Vv=a("li"),Z1e=a("strong"),WWo=o("videomae"),UWo=o(" \u2014 "),DW=a("a"),HWo=o("VideoMAEForPreTraining"),JWo=o(" (VideoMAE model)"),YWo=l(),Xv=a("li"),K1e=a("strong"),ZWo=o("visual_bert"),KWo=o(" \u2014 "),GW=a("a"),eUo=o("VisualBertForPreTraining"),oUo=o(" (VisualBERT model)"),rUo=l(),zv=a("li"),ebe=a("strong"),tUo=o("vit_mae"),aUo=o(" \u2014 "),OW=a("a"),nUo=o("ViTMAEForPreTraining"),sUo=o(" (ViTMAE model)"),lUo=l(),Qv=a("li"),obe=a("strong"),iUo=o("wav2vec2"),dUo=o(" \u2014 "),VW=a("a"),cUo=o("Wav2Vec2ForPreTraining"),fUo=o(" (Wav2Vec2 model)"),mUo=l(),Wv=a("li"),rbe=a("strong"),gUo=o("wav2vec2-conformer"),hUo=o(" \u2014 "),XW=a("a"),uUo=o("Wav2Vec2ConformerForPreTraining"),pUo=o(" (Wav2Vec2-Conformer model)"),_Uo=l(),Uv=a("li"),tbe=a("strong"),vUo=o("xlm"),bUo=o(" \u2014 "),zW=a("a"),FUo=o("XLMWithLMHeadModel"),TUo=o(" (XLM model)"),MUo=l(),Hv=a("li"),abe=a("strong"),EUo=o("xlm-roberta"),CUo=o(" \u2014 "),QW=a("a"),wUo=o("XLMRobertaForMaskedLM"),AUo=o(" (XLM-RoBERTa model)"),LUo=l(),Jv=a("li"),nbe=a("strong"),yUo=o("xlm-roberta-xl"),xUo=o(" \u2014 "),WW=a("a"),$Uo=o("XLMRobertaXLForMaskedLM"),kUo=o(" (XLM-RoBERTa-XL model)"),SUo=l(),Yv=a("li"),sbe=a("strong"),RUo=o("xlnet"),PUo=o(" \u2014 "),UW=a("a"),BUo=o("XLNetLMHeadModel"),IUo=o(" (XLNet model)"),NUo=l(),Zv=a("p"),qUo=o("The model is set in evaluation mode by default using "),lbe=a("code"),jUo=o("model.eval()"),DUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ibe=a("code"),GUo=o("model.train()"),OUo=l(),F(Kv.$$.fragment),Oto=l(),qd=a("h2"),e1=a("a"),dbe=a("span"),F(z$.$$.fragment),VUo=l(),cbe=a("span"),XUo=o("AutoModelForCausalLM"),Vto=l(),qo=a("div"),F(Q$.$$.fragment),zUo=l(),jd=a("p"),QUo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),HW=a("a"),WUo=o("from_pretrained()"),UUo=o(" class method or the "),JW=a("a"),HUo=o("from_config()"),JUo=o(` class
method.`),YUo=l(),W$=a("p"),ZUo=o("This class cannot be instantiated directly using "),fbe=a("code"),KUo=o("__init__()"),eHo=o(" (throws an error)."),oHo=l(),Ct=a("div"),F(U$.$$.fragment),rHo=l(),mbe=a("p"),tHo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),aHo=l(),Dd=a("p"),nHo=o(`Note:
Loading a model from its configuration file does `),gbe=a("strong"),sHo=o("not"),lHo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YW=a("a"),iHo=o("from_pretrained()"),dHo=o(" to load the model weights."),cHo=l(),F(o1.$$.fragment),fHo=l(),oo=a("div"),F(H$.$$.fragment),mHo=l(),hbe=a("p"),gHo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),hHo=l(),ln=a("p"),uHo=o("The model class to instantiate is selected based on the "),ube=a("code"),pHo=o("model_type"),_Ho=o(` property of the config object (either
passed as an argument or loaded from `),pbe=a("code"),vHo=o("pretrained_model_name_or_path"),bHo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_be=a("code"),FHo=o("pretrained_model_name_or_path"),THo=o(":"),MHo=l(),W=a("ul"),r1=a("li"),vbe=a("strong"),EHo=o("bart"),CHo=o(" \u2014 "),ZW=a("a"),wHo=o("BartForCausalLM"),AHo=o(" (BART model)"),LHo=l(),t1=a("li"),bbe=a("strong"),yHo=o("bert"),xHo=o(" \u2014 "),KW=a("a"),$Ho=o("BertLMHeadModel"),kHo=o(" (BERT model)"),SHo=l(),a1=a("li"),Fbe=a("strong"),RHo=o("bert-generation"),PHo=o(" \u2014 "),eU=a("a"),BHo=o("BertGenerationDecoder"),IHo=o(" (Bert Generation model)"),NHo=l(),n1=a("li"),Tbe=a("strong"),qHo=o("big_bird"),jHo=o(" \u2014 "),oU=a("a"),DHo=o("BigBirdForCausalLM"),GHo=o(" (BigBird model)"),OHo=l(),s1=a("li"),Mbe=a("strong"),VHo=o("bigbird_pegasus"),XHo=o(" \u2014 "),rU=a("a"),zHo=o("BigBirdPegasusForCausalLM"),QHo=o(" (BigBird-Pegasus model)"),WHo=l(),l1=a("li"),Ebe=a("strong"),UHo=o("blenderbot"),HHo=o(" \u2014 "),tU=a("a"),JHo=o("BlenderbotForCausalLM"),YHo=o(" (Blenderbot model)"),ZHo=l(),i1=a("li"),Cbe=a("strong"),KHo=o("blenderbot-small"),eJo=o(" \u2014 "),aU=a("a"),oJo=o("BlenderbotSmallForCausalLM"),rJo=o(" (BlenderbotSmall model)"),tJo=l(),d1=a("li"),wbe=a("strong"),aJo=o("bloom"),nJo=o(" \u2014 "),nU=a("a"),sJo=o("BloomForCausalLM"),lJo=o(" (BLOOM model)"),iJo=l(),c1=a("li"),Abe=a("strong"),dJo=o("camembert"),cJo=o(" \u2014 "),sU=a("a"),fJo=o("CamembertForCausalLM"),mJo=o(" (CamemBERT model)"),gJo=l(),f1=a("li"),Lbe=a("strong"),hJo=o("codegen"),uJo=o(" \u2014 "),lU=a("a"),pJo=o("CodeGenForCausalLM"),_Jo=o(" (CodeGen model)"),vJo=l(),m1=a("li"),ybe=a("strong"),bJo=o("ctrl"),FJo=o(" \u2014 "),iU=a("a"),TJo=o("CTRLLMHeadModel"),MJo=o(" (CTRL model)"),EJo=l(),g1=a("li"),xbe=a("strong"),CJo=o("data2vec-text"),wJo=o(" \u2014 "),dU=a("a"),AJo=o("Data2VecTextForCausalLM"),LJo=o(" (Data2VecText model)"),yJo=l(),h1=a("li"),$be=a("strong"),xJo=o("electra"),$Jo=o(" \u2014 "),cU=a("a"),kJo=o("ElectraForCausalLM"),SJo=o(" (ELECTRA model)"),RJo=l(),u1=a("li"),kbe=a("strong"),PJo=o("ernie"),BJo=o(" \u2014 "),fU=a("a"),IJo=o("ErnieForCausalLM"),NJo=o(" (ERNIE model)"),qJo=l(),p1=a("li"),Sbe=a("strong"),jJo=o("gpt2"),DJo=o(" \u2014 "),mU=a("a"),GJo=o("GPT2LMHeadModel"),OJo=o(" (OpenAI GPT-2 model)"),VJo=l(),_1=a("li"),Rbe=a("strong"),XJo=o("gpt_neo"),zJo=o(" \u2014 "),gU=a("a"),QJo=o("GPTNeoForCausalLM"),WJo=o(" (GPT Neo model)"),UJo=l(),v1=a("li"),Pbe=a("strong"),HJo=o("gpt_neox"),JJo=o(" \u2014 "),hU=a("a"),YJo=o("GPTNeoXForCausalLM"),ZJo=o(" (GPT NeoX model)"),KJo=l(),b1=a("li"),Bbe=a("strong"),eYo=o("gpt_neox_japanese"),oYo=o(" \u2014 "),uU=a("a"),rYo=o("GPTNeoXJapaneseForCausalLM"),tYo=o(" (GPT NeoX Japanese model)"),aYo=l(),F1=a("li"),Ibe=a("strong"),nYo=o("gptj"),sYo=o(" \u2014 "),pU=a("a"),lYo=o("GPTJForCausalLM"),iYo=o(" (GPT-J model)"),dYo=l(),T1=a("li"),Nbe=a("strong"),cYo=o("marian"),fYo=o(" \u2014 "),_U=a("a"),mYo=o("MarianForCausalLM"),gYo=o(" (Marian model)"),hYo=l(),M1=a("li"),qbe=a("strong"),uYo=o("mbart"),pYo=o(" \u2014 "),vU=a("a"),_Yo=o("MBartForCausalLM"),vYo=o(" (mBART model)"),bYo=l(),E1=a("li"),jbe=a("strong"),FYo=o("megatron-bert"),TYo=o(" \u2014 "),bU=a("a"),MYo=o("MegatronBertForCausalLM"),EYo=o(" (Megatron-BERT model)"),CYo=l(),C1=a("li"),Dbe=a("strong"),wYo=o("mvp"),AYo=o(" \u2014 "),FU=a("a"),LYo=o("MvpForCausalLM"),yYo=o(" (MVP model)"),xYo=l(),w1=a("li"),Gbe=a("strong"),$Yo=o("openai-gpt"),kYo=o(" \u2014 "),TU=a("a"),SYo=o("OpenAIGPTLMHeadModel"),RYo=o(" (OpenAI GPT model)"),PYo=l(),A1=a("li"),Obe=a("strong"),BYo=o("opt"),IYo=o(" \u2014 "),MU=a("a"),NYo=o("OPTForCausalLM"),qYo=o(" (OPT model)"),jYo=l(),L1=a("li"),Vbe=a("strong"),DYo=o("pegasus"),GYo=o(" \u2014 "),EU=a("a"),OYo=o("PegasusForCausalLM"),VYo=o(" (Pegasus model)"),XYo=l(),y1=a("li"),Xbe=a("strong"),zYo=o("plbart"),QYo=o(" \u2014 "),CU=a("a"),WYo=o("PLBartForCausalLM"),UYo=o(" (PLBart model)"),HYo=l(),x1=a("li"),zbe=a("strong"),JYo=o("prophetnet"),YYo=o(" \u2014 "),wU=a("a"),ZYo=o("ProphetNetForCausalLM"),KYo=o(" (ProphetNet model)"),eZo=l(),$1=a("li"),Qbe=a("strong"),oZo=o("qdqbert"),rZo=o(" \u2014 "),AU=a("a"),tZo=o("QDQBertLMHeadModel"),aZo=o(" (QDQBert model)"),nZo=l(),k1=a("li"),Wbe=a("strong"),sZo=o("reformer"),lZo=o(" \u2014 "),LU=a("a"),iZo=o("ReformerModelWithLMHead"),dZo=o(" (Reformer model)"),cZo=l(),S1=a("li"),Ube=a("strong"),fZo=o("rembert"),mZo=o(" \u2014 "),yU=a("a"),gZo=o("RemBertForCausalLM"),hZo=o(" (RemBERT model)"),uZo=l(),R1=a("li"),Hbe=a("strong"),pZo=o("roberta"),_Zo=o(" \u2014 "),xU=a("a"),vZo=o("RobertaForCausalLM"),bZo=o(" (RoBERTa model)"),FZo=l(),P1=a("li"),Jbe=a("strong"),TZo=o("roformer"),MZo=o(" \u2014 "),$U=a("a"),EZo=o("RoFormerForCausalLM"),CZo=o(" (RoFormer model)"),wZo=l(),B1=a("li"),Ybe=a("strong"),AZo=o("speech_to_text_2"),LZo=o(" \u2014 "),kU=a("a"),yZo=o("Speech2Text2ForCausalLM"),xZo=o(" (Speech2Text2 model)"),$Zo=l(),I1=a("li"),Zbe=a("strong"),kZo=o("transfo-xl"),SZo=o(" \u2014 "),SU=a("a"),RZo=o("TransfoXLLMHeadModel"),PZo=o(" (Transformer-XL model)"),BZo=l(),N1=a("li"),Kbe=a("strong"),IZo=o("trocr"),NZo=o(" \u2014 "),RU=a("a"),qZo=o("TrOCRForCausalLM"),jZo=o(" (TrOCR model)"),DZo=l(),q1=a("li"),e0e=a("strong"),GZo=o("xglm"),OZo=o(" \u2014 "),PU=a("a"),VZo=o("XGLMForCausalLM"),XZo=o(" (XGLM model)"),zZo=l(),j1=a("li"),o0e=a("strong"),QZo=o("xlm"),WZo=o(" \u2014 "),BU=a("a"),UZo=o("XLMWithLMHeadModel"),HZo=o(" (XLM model)"),JZo=l(),D1=a("li"),r0e=a("strong"),YZo=o("xlm-prophetnet"),ZZo=o(" \u2014 "),IU=a("a"),KZo=o("XLMProphetNetForCausalLM"),eKo=o(" (XLM-ProphetNet model)"),oKo=l(),G1=a("li"),t0e=a("strong"),rKo=o("xlm-roberta"),tKo=o(" \u2014 "),NU=a("a"),aKo=o("XLMRobertaForCausalLM"),nKo=o(" (XLM-RoBERTa model)"),sKo=l(),O1=a("li"),a0e=a("strong"),lKo=o("xlm-roberta-xl"),iKo=o(" \u2014 "),qU=a("a"),dKo=o("XLMRobertaXLForCausalLM"),cKo=o(" (XLM-RoBERTa-XL model)"),fKo=l(),V1=a("li"),n0e=a("strong"),mKo=o("xlnet"),gKo=o(" \u2014 "),jU=a("a"),hKo=o("XLNetLMHeadModel"),uKo=o(" (XLNet model)"),pKo=l(),X1=a("p"),_Ko=o("The model is set in evaluation mode by default using "),s0e=a("code"),vKo=o("model.eval()"),bKo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l0e=a("code"),FKo=o("model.train()"),TKo=l(),F(z1.$$.fragment),Xto=l(),Gd=a("h2"),Q1=a("a"),i0e=a("span"),F(J$.$$.fragment),MKo=l(),d0e=a("span"),EKo=o("AutoModelForDepthEstimation"),zto=l(),jo=a("div"),F(Y$.$$.fragment),CKo=l(),Od=a("p"),wKo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a depth estimation head) when created
with the `),DU=a("a"),AKo=o("from_pretrained()"),LKo=o(" class method or the "),GU=a("a"),yKo=o("from_config()"),xKo=o(` class
method.`),$Ko=l(),Z$=a("p"),kKo=o("This class cannot be instantiated directly using "),c0e=a("code"),SKo=o("__init__()"),RKo=o(" (throws an error)."),PKo=l(),wt=a("div"),F(K$.$$.fragment),BKo=l(),f0e=a("p"),IKo=o("Instantiates one of the model classes of the library (with a depth estimation head) from a configuration."),NKo=l(),Vd=a("p"),qKo=o(`Note:
Loading a model from its configuration file does `),m0e=a("strong"),jKo=o("not"),DKo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),OU=a("a"),GKo=o("from_pretrained()"),OKo=o(" to load the model weights."),VKo=l(),F(W1.$$.fragment),XKo=l(),ro=a("div"),F(ek.$$.fragment),zKo=l(),g0e=a("p"),QKo=o("Instantiate one of the model classes of the library (with a depth estimation head) from a pretrained model."),WKo=l(),dn=a("p"),UKo=o("The model class to instantiate is selected based on the "),h0e=a("code"),HKo=o("model_type"),JKo=o(` property of the config object (either
passed as an argument or loaded from `),u0e=a("code"),YKo=o("pretrained_model_name_or_path"),ZKo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p0e=a("code"),KKo=o("pretrained_model_name_or_path"),eer=o(":"),oer=l(),ok=a("ul"),U1=a("li"),_0e=a("strong"),rer=o("dpt"),ter=o(" \u2014 "),VU=a("a"),aer=o("DPTForDepthEstimation"),ner=o(" (DPT model)"),ser=l(),H1=a("li"),v0e=a("strong"),ler=o("glpn"),ier=o(" \u2014 "),XU=a("a"),der=o("GLPNForDepthEstimation"),cer=o(" (GLPN model)"),fer=l(),J1=a("p"),mer=o("The model is set in evaluation mode by default using "),b0e=a("code"),ger=o("model.eval()"),her=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F0e=a("code"),uer=o("model.train()"),per=l(),F(Y1.$$.fragment),Qto=l(),Xd=a("h2"),Z1=a("a"),T0e=a("span"),F(rk.$$.fragment),_er=l(),M0e=a("span"),ver=o("AutoModelForMaskedLM"),Wto=l(),Do=a("div"),F(tk.$$.fragment),ber=l(),zd=a("p"),Fer=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),zU=a("a"),Ter=o("from_pretrained()"),Mer=o(" class method or the "),QU=a("a"),Eer=o("from_config()"),Cer=o(` class
method.`),wer=l(),ak=a("p"),Aer=o("This class cannot be instantiated directly using "),E0e=a("code"),Ler=o("__init__()"),yer=o(" (throws an error)."),xer=l(),At=a("div"),F(nk.$$.fragment),$er=l(),C0e=a("p"),ker=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Ser=l(),Qd=a("p"),Rer=o(`Note:
Loading a model from its configuration file does `),w0e=a("strong"),Per=o("not"),Ber=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WU=a("a"),Ier=o("from_pretrained()"),Ner=o(" to load the model weights."),qer=l(),F(K1.$$.fragment),jer=l(),to=a("div"),F(sk.$$.fragment),Der=l(),A0e=a("p"),Ger=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Oer=l(),cn=a("p"),Ver=o("The model class to instantiate is selected based on the "),L0e=a("code"),Xer=o("model_type"),zer=o(` property of the config object (either
passed as an argument or loaded from `),y0e=a("code"),Qer=o("pretrained_model_name_or_path"),Wer=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x0e=a("code"),Uer=o("pretrained_model_name_or_path"),Her=o(":"),Jer=l(),Y=a("ul"),eb=a("li"),$0e=a("strong"),Yer=o("albert"),Zer=o(" \u2014 "),UU=a("a"),Ker=o("AlbertForMaskedLM"),eor=o(" (ALBERT model)"),oor=l(),ob=a("li"),k0e=a("strong"),ror=o("bart"),tor=o(" \u2014 "),HU=a("a"),aor=o("BartForConditionalGeneration"),nor=o(" (BART model)"),sor=l(),rb=a("li"),S0e=a("strong"),lor=o("bert"),ior=o(" \u2014 "),JU=a("a"),dor=o("BertForMaskedLM"),cor=o(" (BERT model)"),mor=l(),tb=a("li"),R0e=a("strong"),gor=o("big_bird"),hor=o(" \u2014 "),YU=a("a"),uor=o("BigBirdForMaskedLM"),por=o(" (BigBird model)"),_or=l(),ab=a("li"),P0e=a("strong"),vor=o("camembert"),bor=o(" \u2014 "),ZU=a("a"),For=o("CamembertForMaskedLM"),Tor=o(" (CamemBERT model)"),Mor=l(),nb=a("li"),B0e=a("strong"),Eor=o("convbert"),Cor=o(" \u2014 "),KU=a("a"),wor=o("ConvBertForMaskedLM"),Aor=o(" (ConvBERT model)"),Lor=l(),sb=a("li"),I0e=a("strong"),yor=o("data2vec-text"),xor=o(" \u2014 "),eH=a("a"),$or=o("Data2VecTextForMaskedLM"),kor=o(" (Data2VecText model)"),Sor=l(),lb=a("li"),N0e=a("strong"),Ror=o("deberta"),Por=o(" \u2014 "),oH=a("a"),Bor=o("DebertaForMaskedLM"),Ior=o(" (DeBERTa model)"),Nor=l(),ib=a("li"),q0e=a("strong"),qor=o("deberta-v2"),jor=o(" \u2014 "),rH=a("a"),Dor=o("DebertaV2ForMaskedLM"),Gor=o(" (DeBERTa-v2 model)"),Oor=l(),db=a("li"),j0e=a("strong"),Vor=o("distilbert"),Xor=o(" \u2014 "),tH=a("a"),zor=o("DistilBertForMaskedLM"),Qor=o(" (DistilBERT model)"),Wor=l(),cb=a("li"),D0e=a("strong"),Uor=o("electra"),Hor=o(" \u2014 "),aH=a("a"),Jor=o("ElectraForMaskedLM"),Yor=o(" (ELECTRA model)"),Zor=l(),fb=a("li"),G0e=a("strong"),Kor=o("ernie"),err=o(" \u2014 "),nH=a("a"),orr=o("ErnieForMaskedLM"),rrr=o(" (ERNIE model)"),trr=l(),mb=a("li"),O0e=a("strong"),arr=o("flaubert"),nrr=o(" \u2014 "),sH=a("a"),srr=o("FlaubertWithLMHeadModel"),lrr=o(" (FlauBERT model)"),irr=l(),gb=a("li"),V0e=a("strong"),drr=o("fnet"),crr=o(" \u2014 "),lH=a("a"),frr=o("FNetForMaskedLM"),mrr=o(" (FNet model)"),grr=l(),hb=a("li"),X0e=a("strong"),hrr=o("funnel"),urr=o(" \u2014 "),iH=a("a"),prr=o("FunnelForMaskedLM"),_rr=o(" (Funnel Transformer model)"),vrr=l(),ub=a("li"),z0e=a("strong"),brr=o("ibert"),Frr=o(" \u2014 "),dH=a("a"),Trr=o("IBertForMaskedLM"),Mrr=o(" (I-BERT model)"),Err=l(),pb=a("li"),Q0e=a("strong"),Crr=o("layoutlm"),wrr=o(" \u2014 "),cH=a("a"),Arr=o("LayoutLMForMaskedLM"),Lrr=o(" (LayoutLM model)"),yrr=l(),_b=a("li"),W0e=a("strong"),xrr=o("longformer"),$rr=o(" \u2014 "),fH=a("a"),krr=o("LongformerForMaskedLM"),Srr=o(" (Longformer model)"),Rrr=l(),vb=a("li"),U0e=a("strong"),Prr=o("luke"),Brr=o(" \u2014 "),mH=a("a"),Irr=o("LukeForMaskedLM"),Nrr=o(" (LUKE model)"),qrr=l(),bb=a("li"),H0e=a("strong"),jrr=o("mbart"),Drr=o(" \u2014 "),gH=a("a"),Grr=o("MBartForConditionalGeneration"),Orr=o(" (mBART model)"),Vrr=l(),Fb=a("li"),J0e=a("strong"),Xrr=o("megatron-bert"),zrr=o(" \u2014 "),hH=a("a"),Qrr=o("MegatronBertForMaskedLM"),Wrr=o(" (Megatron-BERT model)"),Urr=l(),Tb=a("li"),Y0e=a("strong"),Hrr=o("mobilebert"),Jrr=o(" \u2014 "),uH=a("a"),Yrr=o("MobileBertForMaskedLM"),Zrr=o(" (MobileBERT model)"),Krr=l(),Mb=a("li"),Z0e=a("strong"),etr=o("mpnet"),otr=o(" \u2014 "),pH=a("a"),rtr=o("MPNetForMaskedLM"),ttr=o(" (MPNet model)"),atr=l(),Eb=a("li"),K0e=a("strong"),ntr=o("mvp"),str=o(" \u2014 "),_H=a("a"),ltr=o("MvpForConditionalGeneration"),itr=o(" (MVP model)"),dtr=l(),Cb=a("li"),eFe=a("strong"),ctr=o("nezha"),ftr=o(" \u2014 "),vH=a("a"),mtr=o("NezhaForMaskedLM"),gtr=o(" (Nezha model)"),htr=l(),wb=a("li"),oFe=a("strong"),utr=o("nystromformer"),ptr=o(" \u2014 "),bH=a("a"),_tr=o("NystromformerForMaskedLM"),vtr=o(" (Nystr\xF6mformer model)"),btr=l(),Ab=a("li"),rFe=a("strong"),Ftr=o("perceiver"),Ttr=o(" \u2014 "),FH=a("a"),Mtr=o("PerceiverForMaskedLM"),Etr=o(" (Perceiver model)"),Ctr=l(),Lb=a("li"),tFe=a("strong"),wtr=o("qdqbert"),Atr=o(" \u2014 "),TH=a("a"),Ltr=o("QDQBertForMaskedLM"),ytr=o(" (QDQBert model)"),xtr=l(),yb=a("li"),aFe=a("strong"),$tr=o("reformer"),ktr=o(" \u2014 "),MH=a("a"),Str=o("ReformerForMaskedLM"),Rtr=o(" (Reformer model)"),Ptr=l(),xb=a("li"),nFe=a("strong"),Btr=o("rembert"),Itr=o(" \u2014 "),EH=a("a"),Ntr=o("RemBertForMaskedLM"),qtr=o(" (RemBERT model)"),jtr=l(),$b=a("li"),sFe=a("strong"),Dtr=o("roberta"),Gtr=o(" \u2014 "),CH=a("a"),Otr=o("RobertaForMaskedLM"),Vtr=o(" (RoBERTa model)"),Xtr=l(),kb=a("li"),lFe=a("strong"),ztr=o("roformer"),Qtr=o(" \u2014 "),wH=a("a"),Wtr=o("RoFormerForMaskedLM"),Utr=o(" (RoFormer model)"),Htr=l(),Sb=a("li"),iFe=a("strong"),Jtr=o("squeezebert"),Ytr=o(" \u2014 "),AH=a("a"),Ztr=o("SqueezeBertForMaskedLM"),Ktr=o(" (SqueezeBERT model)"),ear=l(),Rb=a("li"),dFe=a("strong"),oar=o("tapas"),rar=o(" \u2014 "),LH=a("a"),tar=o("TapasForMaskedLM"),aar=o(" (TAPAS model)"),nar=l(),Pb=a("li"),cFe=a("strong"),sar=o("wav2vec2"),lar=o(" \u2014 "),fFe=a("code"),iar=o("Wav2Vec2ForMaskedLM"),dar=o(" (Wav2Vec2 model)"),car=l(),Bb=a("li"),mFe=a("strong"),far=o("xlm"),mar=o(" \u2014 "),yH=a("a"),gar=o("XLMWithLMHeadModel"),har=o(" (XLM model)"),uar=l(),Ib=a("li"),gFe=a("strong"),par=o("xlm-roberta"),_ar=o(" \u2014 "),xH=a("a"),bar=o("XLMRobertaForMaskedLM"),Far=o(" (XLM-RoBERTa model)"),Tar=l(),Nb=a("li"),hFe=a("strong"),Mar=o("xlm-roberta-xl"),Ear=o(" \u2014 "),$H=a("a"),Car=o("XLMRobertaXLForMaskedLM"),war=o(" (XLM-RoBERTa-XL model)"),Aar=l(),qb=a("li"),uFe=a("strong"),Lar=o("yoso"),yar=o(" \u2014 "),kH=a("a"),xar=o("YosoForMaskedLM"),$ar=o(" (YOSO model)"),kar=l(),jb=a("p"),Sar=o("The model is set in evaluation mode by default using "),pFe=a("code"),Rar=o("model.eval()"),Par=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_Fe=a("code"),Bar=o("model.train()"),Iar=l(),F(Db.$$.fragment),Uto=l(),Wd=a("h2"),Gb=a("a"),vFe=a("span"),F(lk.$$.fragment),Nar=l(),bFe=a("span"),qar=o("AutoModelForSeq2SeqLM"),Hto=l(),Go=a("div"),F(ik.$$.fragment),jar=l(),Ud=a("p"),Dar=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),SH=a("a"),Gar=o("from_pretrained()"),Oar=o(" class method or the "),RH=a("a"),Var=o("from_config()"),Xar=o(` class
method.`),zar=l(),dk=a("p"),Qar=o("This class cannot be instantiated directly using "),FFe=a("code"),War=o("__init__()"),Uar=o(" (throws an error)."),Har=l(),Lt=a("div"),F(ck.$$.fragment),Jar=l(),TFe=a("p"),Yar=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Zar=l(),Hd=a("p"),Kar=o(`Note:
Loading a model from its configuration file does `),MFe=a("strong"),enr=o("not"),onr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),PH=a("a"),rnr=o("from_pretrained()"),tnr=o(" to load the model weights."),anr=l(),F(Ob.$$.fragment),nnr=l(),ao=a("div"),F(fk.$$.fragment),snr=l(),EFe=a("p"),lnr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),inr=l(),fn=a("p"),dnr=o("The model class to instantiate is selected based on the "),CFe=a("code"),cnr=o("model_type"),fnr=o(` property of the config object (either
passed as an argument or loaded from `),wFe=a("code"),mnr=o("pretrained_model_name_or_path"),gnr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),AFe=a("code"),hnr=o("pretrained_model_name_or_path"),unr=o(":"),pnr=l(),he=a("ul"),Vb=a("li"),LFe=a("strong"),_nr=o("bart"),vnr=o(" \u2014 "),BH=a("a"),bnr=o("BartForConditionalGeneration"),Fnr=o(" (BART model)"),Tnr=l(),Xb=a("li"),yFe=a("strong"),Mnr=o("bigbird_pegasus"),Enr=o(" \u2014 "),IH=a("a"),Cnr=o("BigBirdPegasusForConditionalGeneration"),wnr=o(" (BigBird-Pegasus model)"),Anr=l(),zb=a("li"),xFe=a("strong"),Lnr=o("blenderbot"),ynr=o(" \u2014 "),NH=a("a"),xnr=o("BlenderbotForConditionalGeneration"),$nr=o(" (Blenderbot model)"),knr=l(),Qb=a("li"),$Fe=a("strong"),Snr=o("blenderbot-small"),Rnr=o(" \u2014 "),qH=a("a"),Pnr=o("BlenderbotSmallForConditionalGeneration"),Bnr=o(" (BlenderbotSmall model)"),Inr=l(),Wb=a("li"),kFe=a("strong"),Nnr=o("encoder-decoder"),qnr=o(" \u2014 "),jH=a("a"),jnr=o("EncoderDecoderModel"),Dnr=o(" (Encoder decoder model)"),Gnr=l(),Ub=a("li"),SFe=a("strong"),Onr=o("fsmt"),Vnr=o(" \u2014 "),DH=a("a"),Xnr=o("FSMTForConditionalGeneration"),znr=o(" (FairSeq Machine-Translation model)"),Qnr=l(),Hb=a("li"),RFe=a("strong"),Wnr=o("led"),Unr=o(" \u2014 "),GH=a("a"),Hnr=o("LEDForConditionalGeneration"),Jnr=o(" (LED model)"),Ynr=l(),Jb=a("li"),PFe=a("strong"),Znr=o("longt5"),Knr=o(" \u2014 "),OH=a("a"),esr=o("LongT5ForConditionalGeneration"),osr=o(" (LongT5 model)"),rsr=l(),Yb=a("li"),BFe=a("strong"),tsr=o("m2m_100"),asr=o(" \u2014 "),VH=a("a"),nsr=o("M2M100ForConditionalGeneration"),ssr=o(" (M2M100 model)"),lsr=l(),Zb=a("li"),IFe=a("strong"),isr=o("marian"),dsr=o(" \u2014 "),XH=a("a"),csr=o("MarianMTModel"),fsr=o(" (Marian model)"),msr=l(),Kb=a("li"),NFe=a("strong"),gsr=o("mbart"),hsr=o(" \u2014 "),zH=a("a"),usr=o("MBartForConditionalGeneration"),psr=o(" (mBART model)"),_sr=l(),e0=a("li"),qFe=a("strong"),vsr=o("mt5"),bsr=o(" \u2014 "),QH=a("a"),Fsr=o("MT5ForConditionalGeneration"),Tsr=o(" (MT5 model)"),Msr=l(),o0=a("li"),jFe=a("strong"),Esr=o("mvp"),Csr=o(" \u2014 "),WH=a("a"),wsr=o("MvpForConditionalGeneration"),Asr=o(" (MVP model)"),Lsr=l(),r0=a("li"),DFe=a("strong"),ysr=o("nllb"),xsr=o(" \u2014 "),UH=a("a"),$sr=o("M2M100ForConditionalGeneration"),ksr=o(" (NLLB model)"),Ssr=l(),t0=a("li"),GFe=a("strong"),Rsr=o("pegasus"),Psr=o(" \u2014 "),HH=a("a"),Bsr=o("PegasusForConditionalGeneration"),Isr=o(" (Pegasus model)"),Nsr=l(),a0=a("li"),OFe=a("strong"),qsr=o("pegasus_x"),jsr=o(" \u2014 "),JH=a("a"),Dsr=o("PegasusXForConditionalGeneration"),Gsr=o(" (PEGASUS-X model)"),Osr=l(),n0=a("li"),VFe=a("strong"),Vsr=o("plbart"),Xsr=o(" \u2014 "),YH=a("a"),zsr=o("PLBartForConditionalGeneration"),Qsr=o(" (PLBart model)"),Wsr=l(),s0=a("li"),XFe=a("strong"),Usr=o("prophetnet"),Hsr=o(" \u2014 "),ZH=a("a"),Jsr=o("ProphetNetForConditionalGeneration"),Ysr=o(" (ProphetNet model)"),Zsr=l(),l0=a("li"),zFe=a("strong"),Ksr=o("t5"),elr=o(" \u2014 "),KH=a("a"),olr=o("T5ForConditionalGeneration"),rlr=o(" (T5 model)"),tlr=l(),i0=a("li"),QFe=a("strong"),alr=o("xlm-prophetnet"),nlr=o(" \u2014 "),eJ=a("a"),slr=o("XLMProphetNetForConditionalGeneration"),llr=o(" (XLM-ProphetNet model)"),ilr=l(),d0=a("p"),dlr=o("The model is set in evaluation mode by default using "),WFe=a("code"),clr=o("model.eval()"),flr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),UFe=a("code"),mlr=o("model.train()"),glr=l(),F(c0.$$.fragment),Jto=l(),Jd=a("h2"),f0=a("a"),HFe=a("span"),F(mk.$$.fragment),hlr=l(),JFe=a("span"),ulr=o("AutoModelForSequenceClassification"),Yto=l(),Oo=a("div"),F(gk.$$.fragment),plr=l(),Yd=a("p"),_lr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),oJ=a("a"),vlr=o("from_pretrained()"),blr=o(" class method or the "),rJ=a("a"),Flr=o("from_config()"),Tlr=o(` class
method.`),Mlr=l(),hk=a("p"),Elr=o("This class cannot be instantiated directly using "),YFe=a("code"),Clr=o("__init__()"),wlr=o(" (throws an error)."),Alr=l(),yt=a("div"),F(uk.$$.fragment),Llr=l(),ZFe=a("p"),ylr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),xlr=l(),Zd=a("p"),$lr=o(`Note:
Loading a model from its configuration file does `),KFe=a("strong"),klr=o("not"),Slr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tJ=a("a"),Rlr=o("from_pretrained()"),Plr=o(" to load the model weights."),Blr=l(),F(m0.$$.fragment),Ilr=l(),no=a("div"),F(pk.$$.fragment),Nlr=l(),eTe=a("p"),qlr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),jlr=l(),mn=a("p"),Dlr=o("The model class to instantiate is selected based on the "),oTe=a("code"),Glr=o("model_type"),Olr=o(` property of the config object (either
passed as an argument or loaded from `),rTe=a("code"),Vlr=o("pretrained_model_name_or_path"),Xlr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tTe=a("code"),zlr=o("pretrained_model_name_or_path"),Qlr=o(":"),Wlr=l(),j=a("ul"),g0=a("li"),aTe=a("strong"),Ulr=o("albert"),Hlr=o(" \u2014 "),aJ=a("a"),Jlr=o("AlbertForSequenceClassification"),Ylr=o(" (ALBERT model)"),Zlr=l(),h0=a("li"),nTe=a("strong"),Klr=o("bart"),eir=o(" \u2014 "),nJ=a("a"),oir=o("BartForSequenceClassification"),rir=o(" (BART model)"),tir=l(),u0=a("li"),sTe=a("strong"),air=o("bert"),nir=o(" \u2014 "),sJ=a("a"),sir=o("BertForSequenceClassification"),lir=o(" (BERT model)"),iir=l(),p0=a("li"),lTe=a("strong"),dir=o("big_bird"),cir=o(" \u2014 "),lJ=a("a"),fir=o("BigBirdForSequenceClassification"),mir=o(" (BigBird model)"),gir=l(),_0=a("li"),iTe=a("strong"),hir=o("bigbird_pegasus"),uir=o(" \u2014 "),iJ=a("a"),pir=o("BigBirdPegasusForSequenceClassification"),_ir=o(" (BigBird-Pegasus model)"),vir=l(),v0=a("li"),dTe=a("strong"),bir=o("bloom"),Fir=o(" \u2014 "),dJ=a("a"),Tir=o("BloomForSequenceClassification"),Mir=o(" (BLOOM model)"),Eir=l(),b0=a("li"),cTe=a("strong"),Cir=o("camembert"),wir=o(" \u2014 "),cJ=a("a"),Air=o("CamembertForSequenceClassification"),Lir=o(" (CamemBERT model)"),yir=l(),F0=a("li"),fTe=a("strong"),xir=o("canine"),$ir=o(" \u2014 "),fJ=a("a"),kir=o("CanineForSequenceClassification"),Sir=o(" (CANINE model)"),Rir=l(),T0=a("li"),mTe=a("strong"),Pir=o("convbert"),Bir=o(" \u2014 "),mJ=a("a"),Iir=o("ConvBertForSequenceClassification"),Nir=o(" (ConvBERT model)"),qir=l(),M0=a("li"),gTe=a("strong"),jir=o("ctrl"),Dir=o(" \u2014 "),gJ=a("a"),Gir=o("CTRLForSequenceClassification"),Oir=o(" (CTRL model)"),Vir=l(),E0=a("li"),hTe=a("strong"),Xir=o("data2vec-text"),zir=o(" \u2014 "),hJ=a("a"),Qir=o("Data2VecTextForSequenceClassification"),Wir=o(" (Data2VecText model)"),Uir=l(),C0=a("li"),uTe=a("strong"),Hir=o("deberta"),Jir=o(" \u2014 "),uJ=a("a"),Yir=o("DebertaForSequenceClassification"),Zir=o(" (DeBERTa model)"),Kir=l(),w0=a("li"),pTe=a("strong"),edr=o("deberta-v2"),odr=o(" \u2014 "),pJ=a("a"),rdr=o("DebertaV2ForSequenceClassification"),tdr=o(" (DeBERTa-v2 model)"),adr=l(),A0=a("li"),_Te=a("strong"),ndr=o("distilbert"),sdr=o(" \u2014 "),_J=a("a"),ldr=o("DistilBertForSequenceClassification"),idr=o(" (DistilBERT model)"),ddr=l(),L0=a("li"),vTe=a("strong"),cdr=o("electra"),fdr=o(" \u2014 "),vJ=a("a"),mdr=o("ElectraForSequenceClassification"),gdr=o(" (ELECTRA model)"),hdr=l(),y0=a("li"),bTe=a("strong"),udr=o("ernie"),pdr=o(" \u2014 "),bJ=a("a"),_dr=o("ErnieForSequenceClassification"),vdr=o(" (ERNIE model)"),bdr=l(),x0=a("li"),FTe=a("strong"),Fdr=o("esm"),Tdr=o(" \u2014 "),FJ=a("a"),Mdr=o("EsmForSequenceClassification"),Edr=o(" (ESM model)"),Cdr=l(),$0=a("li"),TTe=a("strong"),wdr=o("flaubert"),Adr=o(" \u2014 "),TJ=a("a"),Ldr=o("FlaubertForSequenceClassification"),ydr=o(" (FlauBERT model)"),xdr=l(),k0=a("li"),MTe=a("strong"),$dr=o("fnet"),kdr=o(" \u2014 "),MJ=a("a"),Sdr=o("FNetForSequenceClassification"),Rdr=o(" (FNet model)"),Pdr=l(),S0=a("li"),ETe=a("strong"),Bdr=o("funnel"),Idr=o(" \u2014 "),EJ=a("a"),Ndr=o("FunnelForSequenceClassification"),qdr=o(" (Funnel Transformer model)"),jdr=l(),R0=a("li"),CTe=a("strong"),Ddr=o("gpt2"),Gdr=o(" \u2014 "),CJ=a("a"),Odr=o("GPT2ForSequenceClassification"),Vdr=o(" (OpenAI GPT-2 model)"),Xdr=l(),P0=a("li"),wTe=a("strong"),zdr=o("gpt_neo"),Qdr=o(" \u2014 "),wJ=a("a"),Wdr=o("GPTNeoForSequenceClassification"),Udr=o(" (GPT Neo model)"),Hdr=l(),B0=a("li"),ATe=a("strong"),Jdr=o("gptj"),Ydr=o(" \u2014 "),AJ=a("a"),Zdr=o("GPTJForSequenceClassification"),Kdr=o(" (GPT-J model)"),ecr=l(),I0=a("li"),LTe=a("strong"),ocr=o("ibert"),rcr=o(" \u2014 "),LJ=a("a"),tcr=o("IBertForSequenceClassification"),acr=o(" (I-BERT model)"),ncr=l(),N0=a("li"),yTe=a("strong"),scr=o("layoutlm"),lcr=o(" \u2014 "),yJ=a("a"),icr=o("LayoutLMForSequenceClassification"),dcr=o(" (LayoutLM model)"),ccr=l(),q0=a("li"),xTe=a("strong"),fcr=o("layoutlmv2"),mcr=o(" \u2014 "),xJ=a("a"),gcr=o("LayoutLMv2ForSequenceClassification"),hcr=o(" (LayoutLMv2 model)"),ucr=l(),j0=a("li"),$Te=a("strong"),pcr=o("layoutlmv3"),_cr=o(" \u2014 "),$J=a("a"),vcr=o("LayoutLMv3ForSequenceClassification"),bcr=o(" (LayoutLMv3 model)"),Fcr=l(),D0=a("li"),kTe=a("strong"),Tcr=o("led"),Mcr=o(" \u2014 "),kJ=a("a"),Ecr=o("LEDForSequenceClassification"),Ccr=o(" (LED model)"),wcr=l(),G0=a("li"),STe=a("strong"),Acr=o("lilt"),Lcr=o(" \u2014 "),SJ=a("a"),ycr=o("LiltForSequenceClassification"),xcr=o(" (LiLT model)"),$cr=l(),O0=a("li"),RTe=a("strong"),kcr=o("longformer"),Scr=o(" \u2014 "),RJ=a("a"),Rcr=o("LongformerForSequenceClassification"),Pcr=o(" (Longformer model)"),Bcr=l(),V0=a("li"),PTe=a("strong"),Icr=o("luke"),Ncr=o(" \u2014 "),PJ=a("a"),qcr=o("LukeForSequenceClassification"),jcr=o(" (LUKE model)"),Dcr=l(),X0=a("li"),BTe=a("strong"),Gcr=o("markuplm"),Ocr=o(" \u2014 "),BJ=a("a"),Vcr=o("MarkupLMForSequenceClassification"),Xcr=o(" (MarkupLM model)"),zcr=l(),z0=a("li"),ITe=a("strong"),Qcr=o("mbart"),Wcr=o(" \u2014 "),IJ=a("a"),Ucr=o("MBartForSequenceClassification"),Hcr=o(" (mBART model)"),Jcr=l(),Q0=a("li"),NTe=a("strong"),Ycr=o("megatron-bert"),Zcr=o(" \u2014 "),NJ=a("a"),Kcr=o("MegatronBertForSequenceClassification"),efr=o(" (Megatron-BERT model)"),ofr=l(),W0=a("li"),qTe=a("strong"),rfr=o("mobilebert"),tfr=o(" \u2014 "),qJ=a("a"),afr=o("MobileBertForSequenceClassification"),nfr=o(" (MobileBERT model)"),sfr=l(),U0=a("li"),jTe=a("strong"),lfr=o("mpnet"),ifr=o(" \u2014 "),jJ=a("a"),dfr=o("MPNetForSequenceClassification"),cfr=o(" (MPNet model)"),ffr=l(),H0=a("li"),DTe=a("strong"),mfr=o("mvp"),gfr=o(" \u2014 "),DJ=a("a"),hfr=o("MvpForSequenceClassification"),ufr=o(" (MVP model)"),pfr=l(),J0=a("li"),GTe=a("strong"),_fr=o("nezha"),vfr=o(" \u2014 "),GJ=a("a"),bfr=o("NezhaForSequenceClassification"),Ffr=o(" (Nezha model)"),Tfr=l(),Y0=a("li"),OTe=a("strong"),Mfr=o("nystromformer"),Efr=o(" \u2014 "),OJ=a("a"),Cfr=o("NystromformerForSequenceClassification"),wfr=o(" (Nystr\xF6mformer model)"),Afr=l(),Z0=a("li"),VTe=a("strong"),Lfr=o("openai-gpt"),yfr=o(" \u2014 "),VJ=a("a"),xfr=o("OpenAIGPTForSequenceClassification"),$fr=o(" (OpenAI GPT model)"),kfr=l(),K0=a("li"),XTe=a("strong"),Sfr=o("opt"),Rfr=o(" \u2014 "),XJ=a("a"),Pfr=o("OPTForSequenceClassification"),Bfr=o(" (OPT model)"),Ifr=l(),eF=a("li"),zTe=a("strong"),Nfr=o("perceiver"),qfr=o(" \u2014 "),zJ=a("a"),jfr=o("PerceiverForSequenceClassification"),Dfr=o(" (Perceiver model)"),Gfr=l(),oF=a("li"),QTe=a("strong"),Ofr=o("plbart"),Vfr=o(" \u2014 "),QJ=a("a"),Xfr=o("PLBartForSequenceClassification"),zfr=o(" (PLBart model)"),Qfr=l(),rF=a("li"),WTe=a("strong"),Wfr=o("qdqbert"),Ufr=o(" \u2014 "),WJ=a("a"),Hfr=o("QDQBertForSequenceClassification"),Jfr=o(" (QDQBert model)"),Yfr=l(),tF=a("li"),UTe=a("strong"),Zfr=o("reformer"),Kfr=o(" \u2014 "),UJ=a("a"),emr=o("ReformerForSequenceClassification"),omr=o(" (Reformer model)"),rmr=l(),aF=a("li"),HTe=a("strong"),tmr=o("rembert"),amr=o(" \u2014 "),HJ=a("a"),nmr=o("RemBertForSequenceClassification"),smr=o(" (RemBERT model)"),lmr=l(),nF=a("li"),JTe=a("strong"),imr=o("roberta"),dmr=o(" \u2014 "),JJ=a("a"),cmr=o("RobertaForSequenceClassification"),fmr=o(" (RoBERTa model)"),mmr=l(),sF=a("li"),YTe=a("strong"),gmr=o("roformer"),hmr=o(" \u2014 "),YJ=a("a"),umr=o("RoFormerForSequenceClassification"),pmr=o(" (RoFormer model)"),_mr=l(),lF=a("li"),ZTe=a("strong"),vmr=o("squeezebert"),bmr=o(" \u2014 "),ZJ=a("a"),Fmr=o("SqueezeBertForSequenceClassification"),Tmr=o(" (SqueezeBERT model)"),Mmr=l(),iF=a("li"),KTe=a("strong"),Emr=o("tapas"),Cmr=o(" \u2014 "),KJ=a("a"),wmr=o("TapasForSequenceClassification"),Amr=o(" (TAPAS model)"),Lmr=l(),dF=a("li"),eMe=a("strong"),ymr=o("transfo-xl"),xmr=o(" \u2014 "),eY=a("a"),$mr=o("TransfoXLForSequenceClassification"),kmr=o(" (Transformer-XL model)"),Smr=l(),cF=a("li"),oMe=a("strong"),Rmr=o("xlm"),Pmr=o(" \u2014 "),oY=a("a"),Bmr=o("XLMForSequenceClassification"),Imr=o(" (XLM model)"),Nmr=l(),fF=a("li"),rMe=a("strong"),qmr=o("xlm-roberta"),jmr=o(" \u2014 "),rY=a("a"),Dmr=o("XLMRobertaForSequenceClassification"),Gmr=o(" (XLM-RoBERTa model)"),Omr=l(),mF=a("li"),tMe=a("strong"),Vmr=o("xlm-roberta-xl"),Xmr=o(" \u2014 "),tY=a("a"),zmr=o("XLMRobertaXLForSequenceClassification"),Qmr=o(" (XLM-RoBERTa-XL model)"),Wmr=l(),gF=a("li"),aMe=a("strong"),Umr=o("xlnet"),Hmr=o(" \u2014 "),aY=a("a"),Jmr=o("XLNetForSequenceClassification"),Ymr=o(" (XLNet model)"),Zmr=l(),hF=a("li"),nMe=a("strong"),Kmr=o("yoso"),egr=o(" \u2014 "),nY=a("a"),ogr=o("YosoForSequenceClassification"),rgr=o(" (YOSO model)"),tgr=l(),uF=a("p"),agr=o("The model is set in evaluation mode by default using "),sMe=a("code"),ngr=o("model.eval()"),sgr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lMe=a("code"),lgr=o("model.train()"),igr=l(),F(pF.$$.fragment),Zto=l(),Kd=a("h2"),_F=a("a"),iMe=a("span"),F(_k.$$.fragment),dgr=l(),dMe=a("span"),cgr=o("AutoModelForMultipleChoice"),Kto=l(),Vo=a("div"),F(vk.$$.fragment),fgr=l(),ec=a("p"),mgr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),sY=a("a"),ggr=o("from_pretrained()"),hgr=o(" class method or the "),lY=a("a"),ugr=o("from_config()"),pgr=o(` class
method.`),_gr=l(),bk=a("p"),vgr=o("This class cannot be instantiated directly using "),cMe=a("code"),bgr=o("__init__()"),Fgr=o(" (throws an error)."),Tgr=l(),xt=a("div"),F(Fk.$$.fragment),Mgr=l(),fMe=a("p"),Egr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Cgr=l(),oc=a("p"),wgr=o(`Note:
Loading a model from its configuration file does `),mMe=a("strong"),Agr=o("not"),Lgr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iY=a("a"),ygr=o("from_pretrained()"),xgr=o(" to load the model weights."),$gr=l(),F(vF.$$.fragment),kgr=l(),so=a("div"),F(Tk.$$.fragment),Sgr=l(),gMe=a("p"),Rgr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Pgr=l(),gn=a("p"),Bgr=o("The model class to instantiate is selected based on the "),hMe=a("code"),Igr=o("model_type"),Ngr=o(` property of the config object (either
passed as an argument or loaded from `),uMe=a("code"),qgr=o("pretrained_model_name_or_path"),jgr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pMe=a("code"),Dgr=o("pretrained_model_name_or_path"),Ggr=o(":"),Ogr=l(),K=a("ul"),bF=a("li"),_Me=a("strong"),Vgr=o("albert"),Xgr=o(" \u2014 "),dY=a("a"),zgr=o("AlbertForMultipleChoice"),Qgr=o(" (ALBERT model)"),Wgr=l(),FF=a("li"),vMe=a("strong"),Ugr=o("bert"),Hgr=o(" \u2014 "),cY=a("a"),Jgr=o("BertForMultipleChoice"),Ygr=o(" (BERT model)"),Zgr=l(),TF=a("li"),bMe=a("strong"),Kgr=o("big_bird"),ehr=o(" \u2014 "),fY=a("a"),ohr=o("BigBirdForMultipleChoice"),rhr=o(" (BigBird model)"),thr=l(),MF=a("li"),FMe=a("strong"),ahr=o("camembert"),nhr=o(" \u2014 "),mY=a("a"),shr=o("CamembertForMultipleChoice"),lhr=o(" (CamemBERT model)"),ihr=l(),EF=a("li"),TMe=a("strong"),dhr=o("canine"),chr=o(" \u2014 "),gY=a("a"),fhr=o("CanineForMultipleChoice"),mhr=o(" (CANINE model)"),ghr=l(),CF=a("li"),MMe=a("strong"),hhr=o("convbert"),uhr=o(" \u2014 "),hY=a("a"),phr=o("ConvBertForMultipleChoice"),_hr=o(" (ConvBERT model)"),vhr=l(),wF=a("li"),EMe=a("strong"),bhr=o("data2vec-text"),Fhr=o(" \u2014 "),uY=a("a"),Thr=o("Data2VecTextForMultipleChoice"),Mhr=o(" (Data2VecText model)"),Ehr=l(),AF=a("li"),CMe=a("strong"),Chr=o("deberta-v2"),whr=o(" \u2014 "),pY=a("a"),Ahr=o("DebertaV2ForMultipleChoice"),Lhr=o(" (DeBERTa-v2 model)"),yhr=l(),LF=a("li"),wMe=a("strong"),xhr=o("distilbert"),$hr=o(" \u2014 "),_Y=a("a"),khr=o("DistilBertForMultipleChoice"),Shr=o(" (DistilBERT model)"),Rhr=l(),yF=a("li"),AMe=a("strong"),Phr=o("electra"),Bhr=o(" \u2014 "),vY=a("a"),Ihr=o("ElectraForMultipleChoice"),Nhr=o(" (ELECTRA model)"),qhr=l(),xF=a("li"),LMe=a("strong"),jhr=o("ernie"),Dhr=o(" \u2014 "),bY=a("a"),Ghr=o("ErnieForMultipleChoice"),Ohr=o(" (ERNIE model)"),Vhr=l(),$F=a("li"),yMe=a("strong"),Xhr=o("flaubert"),zhr=o(" \u2014 "),FY=a("a"),Qhr=o("FlaubertForMultipleChoice"),Whr=o(" (FlauBERT model)"),Uhr=l(),kF=a("li"),xMe=a("strong"),Hhr=o("fnet"),Jhr=o(" \u2014 "),TY=a("a"),Yhr=o("FNetForMultipleChoice"),Zhr=o(" (FNet model)"),Khr=l(),SF=a("li"),$Me=a("strong"),eur=o("funnel"),our=o(" \u2014 "),MY=a("a"),rur=o("FunnelForMultipleChoice"),tur=o(" (Funnel Transformer model)"),aur=l(),RF=a("li"),kMe=a("strong"),nur=o("ibert"),sur=o(" \u2014 "),EY=a("a"),lur=o("IBertForMultipleChoice"),iur=o(" (I-BERT model)"),dur=l(),PF=a("li"),SMe=a("strong"),cur=o("longformer"),fur=o(" \u2014 "),CY=a("a"),mur=o("LongformerForMultipleChoice"),gur=o(" (Longformer model)"),hur=l(),BF=a("li"),RMe=a("strong"),uur=o("luke"),pur=o(" \u2014 "),wY=a("a"),_ur=o("LukeForMultipleChoice"),vur=o(" (LUKE model)"),bur=l(),IF=a("li"),PMe=a("strong"),Fur=o("megatron-bert"),Tur=o(" \u2014 "),AY=a("a"),Mur=o("MegatronBertForMultipleChoice"),Eur=o(" (Megatron-BERT model)"),Cur=l(),NF=a("li"),BMe=a("strong"),wur=o("mobilebert"),Aur=o(" \u2014 "),LY=a("a"),Lur=o("MobileBertForMultipleChoice"),yur=o(" (MobileBERT model)"),xur=l(),qF=a("li"),IMe=a("strong"),$ur=o("mpnet"),kur=o(" \u2014 "),yY=a("a"),Sur=o("MPNetForMultipleChoice"),Rur=o(" (MPNet model)"),Pur=l(),jF=a("li"),NMe=a("strong"),Bur=o("nezha"),Iur=o(" \u2014 "),xY=a("a"),Nur=o("NezhaForMultipleChoice"),qur=o(" (Nezha model)"),jur=l(),DF=a("li"),qMe=a("strong"),Dur=o("nystromformer"),Gur=o(" \u2014 "),$Y=a("a"),Our=o("NystromformerForMultipleChoice"),Vur=o(" (Nystr\xF6mformer model)"),Xur=l(),GF=a("li"),jMe=a("strong"),zur=o("qdqbert"),Qur=o(" \u2014 "),kY=a("a"),Wur=o("QDQBertForMultipleChoice"),Uur=o(" (QDQBert model)"),Hur=l(),OF=a("li"),DMe=a("strong"),Jur=o("rembert"),Yur=o(" \u2014 "),SY=a("a"),Zur=o("RemBertForMultipleChoice"),Kur=o(" (RemBERT model)"),epr=l(),VF=a("li"),GMe=a("strong"),opr=o("roberta"),rpr=o(" \u2014 "),RY=a("a"),tpr=o("RobertaForMultipleChoice"),apr=o(" (RoBERTa model)"),npr=l(),XF=a("li"),OMe=a("strong"),spr=o("roformer"),lpr=o(" \u2014 "),PY=a("a"),ipr=o("RoFormerForMultipleChoice"),dpr=o(" (RoFormer model)"),cpr=l(),zF=a("li"),VMe=a("strong"),fpr=o("squeezebert"),mpr=o(" \u2014 "),BY=a("a"),gpr=o("SqueezeBertForMultipleChoice"),hpr=o(" (SqueezeBERT model)"),upr=l(),QF=a("li"),XMe=a("strong"),ppr=o("xlm"),_pr=o(" \u2014 "),IY=a("a"),vpr=o("XLMForMultipleChoice"),bpr=o(" (XLM model)"),Fpr=l(),WF=a("li"),zMe=a("strong"),Tpr=o("xlm-roberta"),Mpr=o(" \u2014 "),NY=a("a"),Epr=o("XLMRobertaForMultipleChoice"),Cpr=o(" (XLM-RoBERTa model)"),wpr=l(),UF=a("li"),QMe=a("strong"),Apr=o("xlm-roberta-xl"),Lpr=o(" \u2014 "),qY=a("a"),ypr=o("XLMRobertaXLForMultipleChoice"),xpr=o(" (XLM-RoBERTa-XL model)"),$pr=l(),HF=a("li"),WMe=a("strong"),kpr=o("xlnet"),Spr=o(" \u2014 "),jY=a("a"),Rpr=o("XLNetForMultipleChoice"),Ppr=o(" (XLNet model)"),Bpr=l(),JF=a("li"),UMe=a("strong"),Ipr=o("yoso"),Npr=o(" \u2014 "),DY=a("a"),qpr=o("YosoForMultipleChoice"),jpr=o(" (YOSO model)"),Dpr=l(),YF=a("p"),Gpr=o("The model is set in evaluation mode by default using "),HMe=a("code"),Opr=o("model.eval()"),Vpr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),JMe=a("code"),Xpr=o("model.train()"),zpr=l(),F(ZF.$$.fragment),eao=l(),rc=a("h2"),KF=a("a"),YMe=a("span"),F(Mk.$$.fragment),Qpr=l(),ZMe=a("span"),Wpr=o("AutoModelForNextSentencePrediction"),oao=l(),Xo=a("div"),F(Ek.$$.fragment),Upr=l(),tc=a("p"),Hpr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),GY=a("a"),Jpr=o("from_pretrained()"),Ypr=o(" class method or the "),OY=a("a"),Zpr=o("from_config()"),Kpr=o(` class
method.`),e_r=l(),Ck=a("p"),o_r=o("This class cannot be instantiated directly using "),KMe=a("code"),r_r=o("__init__()"),t_r=o(" (throws an error)."),a_r=l(),$t=a("div"),F(wk.$$.fragment),n_r=l(),eEe=a("p"),s_r=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),l_r=l(),ac=a("p"),i_r=o(`Note:
Loading a model from its configuration file does `),oEe=a("strong"),d_r=o("not"),c_r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VY=a("a"),f_r=o("from_pretrained()"),m_r=o(" to load the model weights."),g_r=l(),F(eT.$$.fragment),h_r=l(),lo=a("div"),F(Ak.$$.fragment),u_r=l(),rEe=a("p"),p_r=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),__r=l(),hn=a("p"),v_r=o("The model class to instantiate is selected based on the "),tEe=a("code"),b_r=o("model_type"),F_r=o(` property of the config object (either
passed as an argument or loaded from `),aEe=a("code"),T_r=o("pretrained_model_name_or_path"),M_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nEe=a("code"),E_r=o("pretrained_model_name_or_path"),C_r=o(":"),w_r=l(),Ue=a("ul"),oT=a("li"),sEe=a("strong"),A_r=o("bert"),L_r=o(" \u2014 "),XY=a("a"),y_r=o("BertForNextSentencePrediction"),x_r=o(" (BERT model)"),$_r=l(),rT=a("li"),lEe=a("strong"),k_r=o("ernie"),S_r=o(" \u2014 "),zY=a("a"),R_r=o("ErnieForNextSentencePrediction"),P_r=o(" (ERNIE model)"),B_r=l(),tT=a("li"),iEe=a("strong"),I_r=o("fnet"),N_r=o(" \u2014 "),QY=a("a"),q_r=o("FNetForNextSentencePrediction"),j_r=o(" (FNet model)"),D_r=l(),aT=a("li"),dEe=a("strong"),G_r=o("megatron-bert"),O_r=o(" \u2014 "),WY=a("a"),V_r=o("MegatronBertForNextSentencePrediction"),X_r=o(" (Megatron-BERT model)"),z_r=l(),nT=a("li"),cEe=a("strong"),Q_r=o("mobilebert"),W_r=o(" \u2014 "),UY=a("a"),U_r=o("MobileBertForNextSentencePrediction"),H_r=o(" (MobileBERT model)"),J_r=l(),sT=a("li"),fEe=a("strong"),Y_r=o("nezha"),Z_r=o(" \u2014 "),HY=a("a"),K_r=o("NezhaForNextSentencePrediction"),e4r=o(" (Nezha model)"),o4r=l(),lT=a("li"),mEe=a("strong"),r4r=o("qdqbert"),t4r=o(" \u2014 "),JY=a("a"),a4r=o("QDQBertForNextSentencePrediction"),n4r=o(" (QDQBert model)"),s4r=l(),iT=a("p"),l4r=o("The model is set in evaluation mode by default using "),gEe=a("code"),i4r=o("model.eval()"),d4r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),hEe=a("code"),c4r=o("model.train()"),f4r=l(),F(dT.$$.fragment),rao=l(),nc=a("h2"),cT=a("a"),uEe=a("span"),F(Lk.$$.fragment),m4r=l(),pEe=a("span"),g4r=o("AutoModelForTokenClassification"),tao=l(),zo=a("div"),F(yk.$$.fragment),h4r=l(),sc=a("p"),u4r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),YY=a("a"),p4r=o("from_pretrained()"),_4r=o(" class method or the "),ZY=a("a"),v4r=o("from_config()"),b4r=o(` class
method.`),F4r=l(),xk=a("p"),T4r=o("This class cannot be instantiated directly using "),_Ee=a("code"),M4r=o("__init__()"),E4r=o(" (throws an error)."),C4r=l(),kt=a("div"),F($k.$$.fragment),w4r=l(),vEe=a("p"),A4r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),L4r=l(),lc=a("p"),y4r=o(`Note:
Loading a model from its configuration file does `),bEe=a("strong"),x4r=o("not"),$4r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),KY=a("a"),k4r=o("from_pretrained()"),S4r=o(" to load the model weights."),R4r=l(),F(fT.$$.fragment),P4r=l(),io=a("div"),F(kk.$$.fragment),B4r=l(),FEe=a("p"),I4r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),N4r=l(),un=a("p"),q4r=o("The model class to instantiate is selected based on the "),TEe=a("code"),j4r=o("model_type"),D4r=o(` property of the config object (either
passed as an argument or loaded from `),MEe=a("code"),G4r=o("pretrained_model_name_or_path"),O4r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),EEe=a("code"),V4r=o("pretrained_model_name_or_path"),X4r=o(":"),z4r=l(),U=a("ul"),mT=a("li"),CEe=a("strong"),Q4r=o("albert"),W4r=o(" \u2014 "),eZ=a("a"),U4r=o("AlbertForTokenClassification"),H4r=o(" (ALBERT model)"),J4r=l(),gT=a("li"),wEe=a("strong"),Y4r=o("bert"),Z4r=o(" \u2014 "),oZ=a("a"),K4r=o("BertForTokenClassification"),e2r=o(" (BERT model)"),o2r=l(),hT=a("li"),AEe=a("strong"),r2r=o("big_bird"),t2r=o(" \u2014 "),rZ=a("a"),a2r=o("BigBirdForTokenClassification"),n2r=o(" (BigBird model)"),s2r=l(),uT=a("li"),LEe=a("strong"),l2r=o("bloom"),i2r=o(" \u2014 "),tZ=a("a"),d2r=o("BloomForTokenClassification"),c2r=o(" (BLOOM model)"),f2r=l(),pT=a("li"),yEe=a("strong"),m2r=o("camembert"),g2r=o(" \u2014 "),aZ=a("a"),h2r=o("CamembertForTokenClassification"),u2r=o(" (CamemBERT model)"),p2r=l(),_T=a("li"),xEe=a("strong"),_2r=o("canine"),v2r=o(" \u2014 "),nZ=a("a"),b2r=o("CanineForTokenClassification"),F2r=o(" (CANINE model)"),T2r=l(),vT=a("li"),$Ee=a("strong"),M2r=o("convbert"),E2r=o(" \u2014 "),sZ=a("a"),C2r=o("ConvBertForTokenClassification"),w2r=o(" (ConvBERT model)"),A2r=l(),bT=a("li"),kEe=a("strong"),L2r=o("data2vec-text"),y2r=o(" \u2014 "),lZ=a("a"),x2r=o("Data2VecTextForTokenClassification"),$2r=o(" (Data2VecText model)"),k2r=l(),FT=a("li"),SEe=a("strong"),S2r=o("deberta"),R2r=o(" \u2014 "),iZ=a("a"),P2r=o("DebertaForTokenClassification"),B2r=o(" (DeBERTa model)"),I2r=l(),TT=a("li"),REe=a("strong"),N2r=o("deberta-v2"),q2r=o(" \u2014 "),dZ=a("a"),j2r=o("DebertaV2ForTokenClassification"),D2r=o(" (DeBERTa-v2 model)"),G2r=l(),MT=a("li"),PEe=a("strong"),O2r=o("distilbert"),V2r=o(" \u2014 "),cZ=a("a"),X2r=o("DistilBertForTokenClassification"),z2r=o(" (DistilBERT model)"),Q2r=l(),ET=a("li"),BEe=a("strong"),W2r=o("electra"),U2r=o(" \u2014 "),fZ=a("a"),H2r=o("ElectraForTokenClassification"),J2r=o(" (ELECTRA model)"),Y2r=l(),CT=a("li"),IEe=a("strong"),Z2r=o("ernie"),K2r=o(" \u2014 "),mZ=a("a"),evr=o("ErnieForTokenClassification"),ovr=o(" (ERNIE model)"),rvr=l(),wT=a("li"),NEe=a("strong"),tvr=o("esm"),avr=o(" \u2014 "),gZ=a("a"),nvr=o("EsmForTokenClassification"),svr=o(" (ESM model)"),lvr=l(),AT=a("li"),qEe=a("strong"),ivr=o("flaubert"),dvr=o(" \u2014 "),hZ=a("a"),cvr=o("FlaubertForTokenClassification"),fvr=o(" (FlauBERT model)"),mvr=l(),LT=a("li"),jEe=a("strong"),gvr=o("fnet"),hvr=o(" \u2014 "),uZ=a("a"),uvr=o("FNetForTokenClassification"),pvr=o(" (FNet model)"),_vr=l(),yT=a("li"),DEe=a("strong"),vvr=o("funnel"),bvr=o(" \u2014 "),pZ=a("a"),Fvr=o("FunnelForTokenClassification"),Tvr=o(" (Funnel Transformer model)"),Mvr=l(),xT=a("li"),GEe=a("strong"),Evr=o("gpt2"),Cvr=o(" \u2014 "),_Z=a("a"),wvr=o("GPT2ForTokenClassification"),Avr=o(" (OpenAI GPT-2 model)"),Lvr=l(),$T=a("li"),OEe=a("strong"),yvr=o("ibert"),xvr=o(" \u2014 "),vZ=a("a"),$vr=o("IBertForTokenClassification"),kvr=o(" (I-BERT model)"),Svr=l(),kT=a("li"),VEe=a("strong"),Rvr=o("layoutlm"),Pvr=o(" \u2014 "),bZ=a("a"),Bvr=o("LayoutLMForTokenClassification"),Ivr=o(" (LayoutLM model)"),Nvr=l(),ST=a("li"),XEe=a("strong"),qvr=o("layoutlmv2"),jvr=o(" \u2014 "),FZ=a("a"),Dvr=o("LayoutLMv2ForTokenClassification"),Gvr=o(" (LayoutLMv2 model)"),Ovr=l(),RT=a("li"),zEe=a("strong"),Vvr=o("layoutlmv3"),Xvr=o(" \u2014 "),TZ=a("a"),zvr=o("LayoutLMv3ForTokenClassification"),Qvr=o(" (LayoutLMv3 model)"),Wvr=l(),PT=a("li"),QEe=a("strong"),Uvr=o("lilt"),Hvr=o(" \u2014 "),MZ=a("a"),Jvr=o("LiltForTokenClassification"),Yvr=o(" (LiLT model)"),Zvr=l(),BT=a("li"),WEe=a("strong"),Kvr=o("longformer"),e1r=o(" \u2014 "),EZ=a("a"),o1r=o("LongformerForTokenClassification"),r1r=o(" (Longformer model)"),t1r=l(),IT=a("li"),UEe=a("strong"),a1r=o("luke"),n1r=o(" \u2014 "),CZ=a("a"),s1r=o("LukeForTokenClassification"),l1r=o(" (LUKE model)"),i1r=l(),NT=a("li"),HEe=a("strong"),d1r=o("markuplm"),c1r=o(" \u2014 "),wZ=a("a"),f1r=o("MarkupLMForTokenClassification"),m1r=o(" (MarkupLM model)"),g1r=l(),qT=a("li"),JEe=a("strong"),h1r=o("megatron-bert"),u1r=o(" \u2014 "),AZ=a("a"),p1r=o("MegatronBertForTokenClassification"),_1r=o(" (Megatron-BERT model)"),v1r=l(),jT=a("li"),YEe=a("strong"),b1r=o("mobilebert"),F1r=o(" \u2014 "),LZ=a("a"),T1r=o("MobileBertForTokenClassification"),M1r=o(" (MobileBERT model)"),E1r=l(),DT=a("li"),ZEe=a("strong"),C1r=o("mpnet"),w1r=o(" \u2014 "),yZ=a("a"),A1r=o("MPNetForTokenClassification"),L1r=o(" (MPNet model)"),y1r=l(),GT=a("li"),KEe=a("strong"),x1r=o("nezha"),$1r=o(" \u2014 "),xZ=a("a"),k1r=o("NezhaForTokenClassification"),S1r=o(" (Nezha model)"),R1r=l(),OT=a("li"),eCe=a("strong"),P1r=o("nystromformer"),B1r=o(" \u2014 "),$Z=a("a"),I1r=o("NystromformerForTokenClassification"),N1r=o(" (Nystr\xF6mformer model)"),q1r=l(),VT=a("li"),oCe=a("strong"),j1r=o("qdqbert"),D1r=o(" \u2014 "),kZ=a("a"),G1r=o("QDQBertForTokenClassification"),O1r=o(" (QDQBert model)"),V1r=l(),XT=a("li"),rCe=a("strong"),X1r=o("rembert"),z1r=o(" \u2014 "),SZ=a("a"),Q1r=o("RemBertForTokenClassification"),W1r=o(" (RemBERT model)"),U1r=l(),zT=a("li"),tCe=a("strong"),H1r=o("roberta"),J1r=o(" \u2014 "),RZ=a("a"),Y1r=o("RobertaForTokenClassification"),Z1r=o(" (RoBERTa model)"),K1r=l(),QT=a("li"),aCe=a("strong"),ebr=o("roformer"),obr=o(" \u2014 "),PZ=a("a"),rbr=o("RoFormerForTokenClassification"),tbr=o(" (RoFormer model)"),abr=l(),WT=a("li"),nCe=a("strong"),nbr=o("squeezebert"),sbr=o(" \u2014 "),BZ=a("a"),lbr=o("SqueezeBertForTokenClassification"),ibr=o(" (SqueezeBERT model)"),dbr=l(),UT=a("li"),sCe=a("strong"),cbr=o("xlm"),fbr=o(" \u2014 "),IZ=a("a"),mbr=o("XLMForTokenClassification"),gbr=o(" (XLM model)"),hbr=l(),HT=a("li"),lCe=a("strong"),ubr=o("xlm-roberta"),pbr=o(" \u2014 "),NZ=a("a"),_br=o("XLMRobertaForTokenClassification"),vbr=o(" (XLM-RoBERTa model)"),bbr=l(),JT=a("li"),iCe=a("strong"),Fbr=o("xlm-roberta-xl"),Tbr=o(" \u2014 "),qZ=a("a"),Mbr=o("XLMRobertaXLForTokenClassification"),Ebr=o(" (XLM-RoBERTa-XL model)"),Cbr=l(),YT=a("li"),dCe=a("strong"),wbr=o("xlnet"),Abr=o(" \u2014 "),jZ=a("a"),Lbr=o("XLNetForTokenClassification"),ybr=o(" (XLNet model)"),xbr=l(),ZT=a("li"),cCe=a("strong"),$br=o("yoso"),kbr=o(" \u2014 "),DZ=a("a"),Sbr=o("YosoForTokenClassification"),Rbr=o(" (YOSO model)"),Pbr=l(),KT=a("p"),Bbr=o("The model is set in evaluation mode by default using "),fCe=a("code"),Ibr=o("model.eval()"),Nbr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mCe=a("code"),qbr=o("model.train()"),jbr=l(),F(eM.$$.fragment),aao=l(),ic=a("h2"),oM=a("a"),gCe=a("span"),F(Sk.$$.fragment),Dbr=l(),hCe=a("span"),Gbr=o("AutoModelForQuestionAnswering"),nao=l(),Qo=a("div"),F(Rk.$$.fragment),Obr=l(),dc=a("p"),Vbr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),GZ=a("a"),Xbr=o("from_pretrained()"),zbr=o(" class method or the "),OZ=a("a"),Qbr=o("from_config()"),Wbr=o(` class
method.`),Ubr=l(),Pk=a("p"),Hbr=o("This class cannot be instantiated directly using "),uCe=a("code"),Jbr=o("__init__()"),Ybr=o(" (throws an error)."),Zbr=l(),St=a("div"),F(Bk.$$.fragment),Kbr=l(),pCe=a("p"),e0r=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),o0r=l(),cc=a("p"),r0r=o(`Note:
Loading a model from its configuration file does `),_Ce=a("strong"),t0r=o("not"),a0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VZ=a("a"),n0r=o("from_pretrained()"),s0r=o(" to load the model weights."),l0r=l(),F(rM.$$.fragment),i0r=l(),co=a("div"),F(Ik.$$.fragment),d0r=l(),vCe=a("p"),c0r=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),f0r=l(),pn=a("p"),m0r=o("The model class to instantiate is selected based on the "),bCe=a("code"),g0r=o("model_type"),h0r=o(` property of the config object (either
passed as an argument or loaded from `),FCe=a("code"),u0r=o("pretrained_model_name_or_path"),p0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TCe=a("code"),_0r=o("pretrained_model_name_or_path"),v0r=o(":"),b0r=l(),O=a("ul"),tM=a("li"),MCe=a("strong"),F0r=o("albert"),T0r=o(" \u2014 "),XZ=a("a"),M0r=o("AlbertForQuestionAnswering"),E0r=o(" (ALBERT model)"),C0r=l(),aM=a("li"),ECe=a("strong"),w0r=o("bart"),A0r=o(" \u2014 "),zZ=a("a"),L0r=o("BartForQuestionAnswering"),y0r=o(" (BART model)"),x0r=l(),nM=a("li"),CCe=a("strong"),$0r=o("bert"),k0r=o(" \u2014 "),QZ=a("a"),S0r=o("BertForQuestionAnswering"),R0r=o(" (BERT model)"),P0r=l(),sM=a("li"),wCe=a("strong"),B0r=o("big_bird"),I0r=o(" \u2014 "),WZ=a("a"),N0r=o("BigBirdForQuestionAnswering"),q0r=o(" (BigBird model)"),j0r=l(),lM=a("li"),ACe=a("strong"),D0r=o("bigbird_pegasus"),G0r=o(" \u2014 "),UZ=a("a"),O0r=o("BigBirdPegasusForQuestionAnswering"),V0r=o(" (BigBird-Pegasus model)"),X0r=l(),iM=a("li"),LCe=a("strong"),z0r=o("bloom"),Q0r=o(" \u2014 "),HZ=a("a"),W0r=o("BloomForQuestionAnswering"),U0r=o(" (BLOOM model)"),H0r=l(),dM=a("li"),yCe=a("strong"),J0r=o("camembert"),Y0r=o(" \u2014 "),JZ=a("a"),Z0r=o("CamembertForQuestionAnswering"),K0r=o(" (CamemBERT model)"),eFr=l(),cM=a("li"),xCe=a("strong"),oFr=o("canine"),rFr=o(" \u2014 "),YZ=a("a"),tFr=o("CanineForQuestionAnswering"),aFr=o(" (CANINE model)"),nFr=l(),fM=a("li"),$Ce=a("strong"),sFr=o("convbert"),lFr=o(" \u2014 "),ZZ=a("a"),iFr=o("ConvBertForQuestionAnswering"),dFr=o(" (ConvBERT model)"),cFr=l(),mM=a("li"),kCe=a("strong"),fFr=o("data2vec-text"),mFr=o(" \u2014 "),KZ=a("a"),gFr=o("Data2VecTextForQuestionAnswering"),hFr=o(" (Data2VecText model)"),uFr=l(),gM=a("li"),SCe=a("strong"),pFr=o("deberta"),_Fr=o(" \u2014 "),eK=a("a"),vFr=o("DebertaForQuestionAnswering"),bFr=o(" (DeBERTa model)"),FFr=l(),hM=a("li"),RCe=a("strong"),TFr=o("deberta-v2"),MFr=o(" \u2014 "),oK=a("a"),EFr=o("DebertaV2ForQuestionAnswering"),CFr=o(" (DeBERTa-v2 model)"),wFr=l(),uM=a("li"),PCe=a("strong"),AFr=o("distilbert"),LFr=o(" \u2014 "),rK=a("a"),yFr=o("DistilBertForQuestionAnswering"),xFr=o(" (DistilBERT model)"),$Fr=l(),pM=a("li"),BCe=a("strong"),kFr=o("electra"),SFr=o(" \u2014 "),tK=a("a"),RFr=o("ElectraForQuestionAnswering"),PFr=o(" (ELECTRA model)"),BFr=l(),_M=a("li"),ICe=a("strong"),IFr=o("ernie"),NFr=o(" \u2014 "),aK=a("a"),qFr=o("ErnieForQuestionAnswering"),jFr=o(" (ERNIE model)"),DFr=l(),vM=a("li"),NCe=a("strong"),GFr=o("flaubert"),OFr=o(" \u2014 "),nK=a("a"),VFr=o("FlaubertForQuestionAnsweringSimple"),XFr=o(" (FlauBERT model)"),zFr=l(),bM=a("li"),qCe=a("strong"),QFr=o("fnet"),WFr=o(" \u2014 "),sK=a("a"),UFr=o("FNetForQuestionAnswering"),HFr=o(" (FNet model)"),JFr=l(),FM=a("li"),jCe=a("strong"),YFr=o("funnel"),ZFr=o(" \u2014 "),lK=a("a"),KFr=o("FunnelForQuestionAnswering"),eTr=o(" (Funnel Transformer model)"),oTr=l(),TM=a("li"),DCe=a("strong"),rTr=o("gptj"),tTr=o(" \u2014 "),iK=a("a"),aTr=o("GPTJForQuestionAnswering"),nTr=o(" (GPT-J model)"),sTr=l(),MM=a("li"),GCe=a("strong"),lTr=o("ibert"),iTr=o(" \u2014 "),dK=a("a"),dTr=o("IBertForQuestionAnswering"),cTr=o(" (I-BERT model)"),fTr=l(),EM=a("li"),OCe=a("strong"),mTr=o("layoutlmv2"),gTr=o(" \u2014 "),cK=a("a"),hTr=o("LayoutLMv2ForQuestionAnswering"),uTr=o(" (LayoutLMv2 model)"),pTr=l(),CM=a("li"),VCe=a("strong"),_Tr=o("layoutlmv3"),vTr=o(" \u2014 "),fK=a("a"),bTr=o("LayoutLMv3ForQuestionAnswering"),FTr=o(" (LayoutLMv3 model)"),TTr=l(),wM=a("li"),XCe=a("strong"),MTr=o("led"),ETr=o(" \u2014 "),mK=a("a"),CTr=o("LEDForQuestionAnswering"),wTr=o(" (LED model)"),ATr=l(),AM=a("li"),zCe=a("strong"),LTr=o("lilt"),yTr=o(" \u2014 "),gK=a("a"),xTr=o("LiltForQuestionAnswering"),$Tr=o(" (LiLT model)"),kTr=l(),LM=a("li"),QCe=a("strong"),STr=o("longformer"),RTr=o(" \u2014 "),hK=a("a"),PTr=o("LongformerForQuestionAnswering"),BTr=o(" (Longformer model)"),ITr=l(),yM=a("li"),WCe=a("strong"),NTr=o("luke"),qTr=o(" \u2014 "),uK=a("a"),jTr=o("LukeForQuestionAnswering"),DTr=o(" (LUKE model)"),GTr=l(),xM=a("li"),UCe=a("strong"),OTr=o("lxmert"),VTr=o(" \u2014 "),pK=a("a"),XTr=o("LxmertForQuestionAnswering"),zTr=o(" (LXMERT model)"),QTr=l(),$M=a("li"),HCe=a("strong"),WTr=o("markuplm"),UTr=o(" \u2014 "),_K=a("a"),HTr=o("MarkupLMForQuestionAnswering"),JTr=o(" (MarkupLM model)"),YTr=l(),kM=a("li"),JCe=a("strong"),ZTr=o("mbart"),KTr=o(" \u2014 "),vK=a("a"),eMr=o("MBartForQuestionAnswering"),oMr=o(" (mBART model)"),rMr=l(),SM=a("li"),YCe=a("strong"),tMr=o("megatron-bert"),aMr=o(" \u2014 "),bK=a("a"),nMr=o("MegatronBertForQuestionAnswering"),sMr=o(" (Megatron-BERT model)"),lMr=l(),RM=a("li"),ZCe=a("strong"),iMr=o("mobilebert"),dMr=o(" \u2014 "),FK=a("a"),cMr=o("MobileBertForQuestionAnswering"),fMr=o(" (MobileBERT model)"),mMr=l(),PM=a("li"),KCe=a("strong"),gMr=o("mpnet"),hMr=o(" \u2014 "),TK=a("a"),uMr=o("MPNetForQuestionAnswering"),pMr=o(" (MPNet model)"),_Mr=l(),BM=a("li"),e3e=a("strong"),vMr=o("mvp"),bMr=o(" \u2014 "),MK=a("a"),FMr=o("MvpForQuestionAnswering"),TMr=o(" (MVP model)"),MMr=l(),IM=a("li"),o3e=a("strong"),EMr=o("nezha"),CMr=o(" \u2014 "),EK=a("a"),wMr=o("NezhaForQuestionAnswering"),AMr=o(" (Nezha model)"),LMr=l(),NM=a("li"),r3e=a("strong"),yMr=o("nystromformer"),xMr=o(" \u2014 "),CK=a("a"),$Mr=o("NystromformerForQuestionAnswering"),kMr=o(" (Nystr\xF6mformer model)"),SMr=l(),qM=a("li"),t3e=a("strong"),RMr=o("opt"),PMr=o(" \u2014 "),wK=a("a"),BMr=o("OPTForQuestionAnswering"),IMr=o(" (OPT model)"),NMr=l(),jM=a("li"),a3e=a("strong"),qMr=o("qdqbert"),jMr=o(" \u2014 "),AK=a("a"),DMr=o("QDQBertForQuestionAnswering"),GMr=o(" (QDQBert model)"),OMr=l(),DM=a("li"),n3e=a("strong"),VMr=o("reformer"),XMr=o(" \u2014 "),LK=a("a"),zMr=o("ReformerForQuestionAnswering"),QMr=o(" (Reformer model)"),WMr=l(),GM=a("li"),s3e=a("strong"),UMr=o("rembert"),HMr=o(" \u2014 "),yK=a("a"),JMr=o("RemBertForQuestionAnswering"),YMr=o(" (RemBERT model)"),ZMr=l(),OM=a("li"),l3e=a("strong"),KMr=o("roberta"),eEr=o(" \u2014 "),xK=a("a"),oEr=o("RobertaForQuestionAnswering"),rEr=o(" (RoBERTa model)"),tEr=l(),VM=a("li"),i3e=a("strong"),aEr=o("roformer"),nEr=o(" \u2014 "),$K=a("a"),sEr=o("RoFormerForQuestionAnswering"),lEr=o(" (RoFormer model)"),iEr=l(),XM=a("li"),d3e=a("strong"),dEr=o("splinter"),cEr=o(" \u2014 "),kK=a("a"),fEr=o("SplinterForQuestionAnswering"),mEr=o(" (Splinter model)"),gEr=l(),zM=a("li"),c3e=a("strong"),hEr=o("squeezebert"),uEr=o(" \u2014 "),SK=a("a"),pEr=o("SqueezeBertForQuestionAnswering"),_Er=o(" (SqueezeBERT model)"),vEr=l(),QM=a("li"),f3e=a("strong"),bEr=o("xlm"),FEr=o(" \u2014 "),RK=a("a"),TEr=o("XLMForQuestionAnsweringSimple"),MEr=o(" (XLM model)"),EEr=l(),WM=a("li"),m3e=a("strong"),CEr=o("xlm-roberta"),wEr=o(" \u2014 "),PK=a("a"),AEr=o("XLMRobertaForQuestionAnswering"),LEr=o(" (XLM-RoBERTa model)"),yEr=l(),UM=a("li"),g3e=a("strong"),xEr=o("xlm-roberta-xl"),$Er=o(" \u2014 "),BK=a("a"),kEr=o("XLMRobertaXLForQuestionAnswering"),SEr=o(" (XLM-RoBERTa-XL model)"),REr=l(),HM=a("li"),h3e=a("strong"),PEr=o("xlnet"),BEr=o(" \u2014 "),IK=a("a"),IEr=o("XLNetForQuestionAnsweringSimple"),NEr=o(" (XLNet model)"),qEr=l(),JM=a("li"),u3e=a("strong"),jEr=o("yoso"),DEr=o(" \u2014 "),NK=a("a"),GEr=o("YosoForQuestionAnswering"),OEr=o(" (YOSO model)"),VEr=l(),YM=a("p"),XEr=o("The model is set in evaluation mode by default using "),p3e=a("code"),zEr=o("model.eval()"),QEr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_3e=a("code"),WEr=o("model.train()"),UEr=l(),F(ZM.$$.fragment),sao=l(),fc=a("h2"),KM=a("a"),v3e=a("span"),F(Nk.$$.fragment),HEr=l(),b3e=a("span"),JEr=o("AutoModelForTableQuestionAnswering"),lao=l(),Wo=a("div"),F(qk.$$.fragment),YEr=l(),mc=a("p"),ZEr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),qK=a("a"),KEr=o("from_pretrained()"),eCr=o(" class method or the "),jK=a("a"),oCr=o("from_config()"),rCr=o(` class
method.`),tCr=l(),jk=a("p"),aCr=o("This class cannot be instantiated directly using "),F3e=a("code"),nCr=o("__init__()"),sCr=o(" (throws an error)."),lCr=l(),Rt=a("div"),F(Dk.$$.fragment),iCr=l(),T3e=a("p"),dCr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),cCr=l(),gc=a("p"),fCr=o(`Note:
Loading a model from its configuration file does `),M3e=a("strong"),mCr=o("not"),gCr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DK=a("a"),hCr=o("from_pretrained()"),uCr=o(" to load the model weights."),pCr=l(),F(eE.$$.fragment),_Cr=l(),fo=a("div"),F(Gk.$$.fragment),vCr=l(),E3e=a("p"),bCr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),FCr=l(),_n=a("p"),TCr=o("The model class to instantiate is selected based on the "),C3e=a("code"),MCr=o("model_type"),ECr=o(` property of the config object (either
passed as an argument or loaded from `),w3e=a("code"),CCr=o("pretrained_model_name_or_path"),wCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A3e=a("code"),ACr=o("pretrained_model_name_or_path"),LCr=o(":"),yCr=l(),L3e=a("ul"),oE=a("li"),y3e=a("strong"),xCr=o("tapas"),$Cr=o(" \u2014 "),GK=a("a"),kCr=o("TapasForQuestionAnswering"),SCr=o(" (TAPAS model)"),RCr=l(),rE=a("p"),PCr=o("The model is set in evaluation mode by default using "),x3e=a("code"),BCr=o("model.eval()"),ICr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$3e=a("code"),NCr=o("model.train()"),qCr=l(),F(tE.$$.fragment),iao=l(),hc=a("h2"),aE=a("a"),k3e=a("span"),F(Ok.$$.fragment),jCr=l(),S3e=a("span"),DCr=o("AutoModelForDocumentQuestionAnswering"),dao=l(),Uo=a("div"),F(Vk.$$.fragment),GCr=l(),uc=a("p"),OCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),OK=a("a"),VCr=o("from_pretrained()"),XCr=o(" class method or the "),VK=a("a"),zCr=o("from_config()"),QCr=o(` class
method.`),WCr=l(),Xk=a("p"),UCr=o("This class cannot be instantiated directly using "),R3e=a("code"),HCr=o("__init__()"),JCr=o(" (throws an error)."),YCr=l(),Pt=a("div"),F(zk.$$.fragment),ZCr=l(),P3e=a("p"),KCr=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),e3r=l(),pc=a("p"),o3r=o(`Note:
Loading a model from its configuration file does `),B3e=a("strong"),r3r=o("not"),t3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XK=a("a"),a3r=o("from_pretrained()"),n3r=o(" to load the model weights."),s3r=l(),F(nE.$$.fragment),l3r=l(),mo=a("div"),F(Qk.$$.fragment),i3r=l(),I3e=a("p"),d3r=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),c3r=l(),vn=a("p"),f3r=o("The model class to instantiate is selected based on the "),N3e=a("code"),m3r=o("model_type"),g3r=o(` property of the config object (either
passed as an argument or loaded from `),q3e=a("code"),h3r=o("pretrained_model_name_or_path"),u3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j3e=a("code"),p3r=o("pretrained_model_name_or_path"),_3r=o(":"),v3r=l(),_c=a("ul"),sE=a("li"),D3e=a("strong"),b3r=o("layoutlm"),F3r=o(" \u2014 "),zK=a("a"),T3r=o("LayoutLMForQuestionAnswering"),M3r=o(" (LayoutLM model)"),E3r=l(),lE=a("li"),G3e=a("strong"),C3r=o("layoutlmv2"),w3r=o(" \u2014 "),QK=a("a"),A3r=o("LayoutLMv2ForQuestionAnswering"),L3r=o(" (LayoutLMv2 model)"),y3r=l(),iE=a("li"),O3e=a("strong"),x3r=o("layoutlmv3"),$3r=o(" \u2014 "),WK=a("a"),k3r=o("LayoutLMv3ForQuestionAnswering"),S3r=o(" (LayoutLMv3 model)"),R3r=l(),dE=a("p"),P3r=o("The model is set in evaluation mode by default using "),V3e=a("code"),B3r=o("model.eval()"),I3r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),X3e=a("code"),N3r=o("model.train()"),q3r=l(),F(cE.$$.fragment),cao=l(),vc=a("h2"),fE=a("a"),z3e=a("span"),F(Wk.$$.fragment),j3r=l(),Q3e=a("span"),D3r=o("AutoModelForImageClassification"),fao=l(),Ho=a("div"),F(Uk.$$.fragment),G3r=l(),bc=a("p"),O3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),UK=a("a"),V3r=o("from_pretrained()"),X3r=o(" class method or the "),HK=a("a"),z3r=o("from_config()"),Q3r=o(` class
method.`),W3r=l(),Hk=a("p"),U3r=o("This class cannot be instantiated directly using "),W3e=a("code"),H3r=o("__init__()"),J3r=o(" (throws an error)."),Y3r=l(),Bt=a("div"),F(Jk.$$.fragment),Z3r=l(),U3e=a("p"),K3r=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),e5r=l(),Fc=a("p"),o5r=o(`Note:
Loading a model from its configuration file does `),H3e=a("strong"),r5r=o("not"),t5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JK=a("a"),a5r=o("from_pretrained()"),n5r=o(" to load the model weights."),s5r=l(),F(mE.$$.fragment),l5r=l(),go=a("div"),F(Yk.$$.fragment),i5r=l(),J3e=a("p"),d5r=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),c5r=l(),bn=a("p"),f5r=o("The model class to instantiate is selected based on the "),Y3e=a("code"),m5r=o("model_type"),g5r=o(` property of the config object (either
passed as an argument or loaded from `),Z3e=a("code"),h5r=o("pretrained_model_name_or_path"),u5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K3e=a("code"),p5r=o("pretrained_model_name_or_path"),_5r=o(":"),v5r=l(),ve=a("ul"),gE=a("li"),e5e=a("strong"),b5r=o("beit"),F5r=o(" \u2014 "),YK=a("a"),T5r=o("BeitForImageClassification"),M5r=o(" (BEiT model)"),E5r=l(),hE=a("li"),o5e=a("strong"),C5r=o("convnext"),w5r=o(" \u2014 "),ZK=a("a"),A5r=o("ConvNextForImageClassification"),L5r=o(" (ConvNeXT model)"),y5r=l(),uE=a("li"),r5e=a("strong"),x5r=o("cvt"),$5r=o(" \u2014 "),KK=a("a"),k5r=o("CvtForImageClassification"),S5r=o(" (CvT model)"),R5r=l(),pE=a("li"),t5e=a("strong"),P5r=o("data2vec-vision"),B5r=o(" \u2014 "),eee=a("a"),I5r=o("Data2VecVisionForImageClassification"),N5r=o(" (Data2VecVision model)"),q5r=l(),$l=a("li"),a5e=a("strong"),j5r=o("deit"),D5r=o(" \u2014 "),oee=a("a"),G5r=o("DeiTForImageClassification"),O5r=o(" or "),ree=a("a"),V5r=o("DeiTForImageClassificationWithTeacher"),X5r=o(" (DeiT model)"),z5r=l(),_E=a("li"),n5e=a("strong"),Q5r=o("imagegpt"),W5r=o(" \u2014 "),tee=a("a"),U5r=o("ImageGPTForImageClassification"),H5r=o(" (ImageGPT model)"),J5r=l(),kl=a("li"),s5e=a("strong"),Y5r=o("levit"),Z5r=o(" \u2014 "),aee=a("a"),K5r=o("LevitForImageClassification"),ewr=o(" or "),nee=a("a"),owr=o("LevitForImageClassificationWithTeacher"),rwr=o(" (LeViT model)"),twr=l(),vE=a("li"),l5e=a("strong"),awr=o("mobilevit"),nwr=o(" \u2014 "),see=a("a"),swr=o("MobileViTForImageClassification"),lwr=o(" (MobileViT model)"),iwr=l(),It=a("li"),i5e=a("strong"),dwr=o("perceiver"),cwr=o(" \u2014 "),lee=a("a"),fwr=o("PerceiverForImageClassificationLearned"),mwr=o(" or "),iee=a("a"),gwr=o("PerceiverForImageClassificationFourier"),hwr=o(" or "),dee=a("a"),uwr=o("PerceiverForImageClassificationConvProcessing"),pwr=o(" (Perceiver model)"),_wr=l(),bE=a("li"),d5e=a("strong"),vwr=o("poolformer"),bwr=o(" \u2014 "),cee=a("a"),Fwr=o("PoolFormerForImageClassification"),Twr=o(" (PoolFormer model)"),Mwr=l(),FE=a("li"),c5e=a("strong"),Ewr=o("regnet"),Cwr=o(" \u2014 "),fee=a("a"),wwr=o("RegNetForImageClassification"),Awr=o(" (RegNet model)"),Lwr=l(),TE=a("li"),f5e=a("strong"),ywr=o("resnet"),xwr=o(" \u2014 "),mee=a("a"),$wr=o("ResNetForImageClassification"),kwr=o(" (ResNet model)"),Swr=l(),ME=a("li"),m5e=a("strong"),Rwr=o("segformer"),Pwr=o(" \u2014 "),gee=a("a"),Bwr=o("SegformerForImageClassification"),Iwr=o(" (SegFormer model)"),Nwr=l(),EE=a("li"),g5e=a("strong"),qwr=o("swin"),jwr=o(" \u2014 "),hee=a("a"),Dwr=o("SwinForImageClassification"),Gwr=o(" (Swin Transformer model)"),Owr=l(),CE=a("li"),h5e=a("strong"),Vwr=o("swinv2"),Xwr=o(" \u2014 "),uee=a("a"),zwr=o("Swinv2ForImageClassification"),Qwr=o(" (Swin Transformer V2 model)"),Wwr=l(),wE=a("li"),u5e=a("strong"),Uwr=o("van"),Hwr=o(" \u2014 "),pee=a("a"),Jwr=o("VanForImageClassification"),Ywr=o(" (VAN model)"),Zwr=l(),AE=a("li"),p5e=a("strong"),Kwr=o("vit"),eAr=o(" \u2014 "),_ee=a("a"),oAr=o("ViTForImageClassification"),rAr=o(" (ViT model)"),tAr=l(),LE=a("li"),_5e=a("strong"),aAr=o("vit_msn"),nAr=o(" \u2014 "),vee=a("a"),sAr=o("ViTMSNForImageClassification"),lAr=o(" (ViTMSN model)"),iAr=l(),yE=a("p"),dAr=o("The model is set in evaluation mode by default using "),v5e=a("code"),cAr=o("model.eval()"),fAr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b5e=a("code"),mAr=o("model.train()"),gAr=l(),F(xE.$$.fragment),mao=l(),Tc=a("h2"),$E=a("a"),F5e=a("span"),F(Zk.$$.fragment),hAr=l(),T5e=a("span"),uAr=o("AutoModelForVideoClassification"),gao=l(),Jo=a("div"),F(Kk.$$.fragment),pAr=l(),Mc=a("p"),_Ar=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),bee=a("a"),vAr=o("from_pretrained()"),bAr=o(" class method or the "),Fee=a("a"),FAr=o("from_config()"),TAr=o(` class
method.`),MAr=l(),eS=a("p"),EAr=o("This class cannot be instantiated directly using "),M5e=a("code"),CAr=o("__init__()"),wAr=o(" (throws an error)."),AAr=l(),Nt=a("div"),F(oS.$$.fragment),LAr=l(),E5e=a("p"),yAr=o("Instantiates one of the model classes of the library (with a video classification head) from a configuration."),xAr=l(),Ec=a("p"),$Ar=o(`Note:
Loading a model from its configuration file does `),C5e=a("strong"),kAr=o("not"),SAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Tee=a("a"),RAr=o("from_pretrained()"),PAr=o(" to load the model weights."),BAr=l(),F(kE.$$.fragment),IAr=l(),ho=a("div"),F(rS.$$.fragment),NAr=l(),w5e=a("p"),qAr=o("Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),jAr=l(),Fn=a("p"),DAr=o("The model class to instantiate is selected based on the "),A5e=a("code"),GAr=o("model_type"),OAr=o(` property of the config object (either
passed as an argument or loaded from `),L5e=a("code"),VAr=o("pretrained_model_name_or_path"),XAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y5e=a("code"),zAr=o("pretrained_model_name_or_path"),QAr=o(":"),WAr=l(),x5e=a("ul"),SE=a("li"),$5e=a("strong"),UAr=o("videomae"),HAr=o(" \u2014 "),Mee=a("a"),JAr=o("VideoMAEForVideoClassification"),YAr=o(" (VideoMAE model)"),ZAr=l(),RE=a("p"),KAr=o("The model is set in evaluation mode by default using "),k5e=a("code"),e6r=o("model.eval()"),o6r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),S5e=a("code"),r6r=o("model.train()"),t6r=l(),F(PE.$$.fragment),hao=l(),Cc=a("h2"),BE=a("a"),R5e=a("span"),F(tS.$$.fragment),a6r=l(),P5e=a("span"),n6r=o("AutoModelForVision2Seq"),uao=l(),Yo=a("div"),F(aS.$$.fragment),s6r=l(),wc=a("p"),l6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Eee=a("a"),i6r=o("from_pretrained()"),d6r=o(" class method or the "),Cee=a("a"),c6r=o("from_config()"),f6r=o(` class
method.`),m6r=l(),nS=a("p"),g6r=o("This class cannot be instantiated directly using "),B5e=a("code"),h6r=o("__init__()"),u6r=o(" (throws an error)."),p6r=l(),qt=a("div"),F(sS.$$.fragment),_6r=l(),I5e=a("p"),v6r=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),b6r=l(),Ac=a("p"),F6r=o(`Note:
Loading a model from its configuration file does `),N5e=a("strong"),T6r=o("not"),M6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wee=a("a"),E6r=o("from_pretrained()"),C6r=o(" to load the model weights."),w6r=l(),F(IE.$$.fragment),A6r=l(),uo=a("div"),F(lS.$$.fragment),L6r=l(),q5e=a("p"),y6r=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),x6r=l(),Tn=a("p"),$6r=o("The model class to instantiate is selected based on the "),j5e=a("code"),k6r=o("model_type"),S6r=o(` property of the config object (either
passed as an argument or loaded from `),D5e=a("code"),R6r=o("pretrained_model_name_or_path"),P6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G5e=a("code"),B6r=o("pretrained_model_name_or_path"),I6r=o(":"),N6r=l(),O5e=a("ul"),NE=a("li"),V5e=a("strong"),q6r=o("vision-encoder-decoder"),j6r=o(" \u2014 "),Aee=a("a"),D6r=o("VisionEncoderDecoderModel"),G6r=o(" (Vision Encoder decoder model)"),O6r=l(),qE=a("p"),V6r=o("The model is set in evaluation mode by default using "),X5e=a("code"),X6r=o("model.eval()"),z6r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),z5e=a("code"),Q6r=o("model.train()"),W6r=l(),F(jE.$$.fragment),pao=l(),Lc=a("h2"),DE=a("a"),Q5e=a("span"),F(iS.$$.fragment),U6r=l(),W5e=a("span"),H6r=o("AutoModelForVisualQuestionAnswering"),_ao=l(),Zo=a("div"),F(dS.$$.fragment),J6r=l(),yc=a("p"),Y6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),Lee=a("a"),Z6r=o("from_pretrained()"),K6r=o(" class method or the "),yee=a("a"),e7r=o("from_config()"),o7r=o(` class
method.`),r7r=l(),cS=a("p"),t7r=o("This class cannot be instantiated directly using "),U5e=a("code"),a7r=o("__init__()"),n7r=o(" (throws an error)."),s7r=l(),jt=a("div"),F(fS.$$.fragment),l7r=l(),H5e=a("p"),i7r=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),d7r=l(),xc=a("p"),c7r=o(`Note:
Loading a model from its configuration file does `),J5e=a("strong"),f7r=o("not"),m7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xee=a("a"),g7r=o("from_pretrained()"),h7r=o(" to load the model weights."),u7r=l(),F(GE.$$.fragment),p7r=l(),po=a("div"),F(mS.$$.fragment),_7r=l(),Y5e=a("p"),v7r=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),b7r=l(),Mn=a("p"),F7r=o("The model class to instantiate is selected based on the "),Z5e=a("code"),T7r=o("model_type"),M7r=o(` property of the config object (either
passed as an argument or loaded from `),K5e=a("code"),E7r=o("pretrained_model_name_or_path"),C7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ewe=a("code"),w7r=o("pretrained_model_name_or_path"),A7r=o(":"),L7r=l(),owe=a("ul"),OE=a("li"),rwe=a("strong"),y7r=o("vilt"),x7r=o(" \u2014 "),$ee=a("a"),$7r=o("ViltForQuestionAnswering"),k7r=o(" (ViLT model)"),S7r=l(),VE=a("p"),R7r=o("The model is set in evaluation mode by default using "),twe=a("code"),P7r=o("model.eval()"),B7r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),awe=a("code"),I7r=o("model.train()"),N7r=l(),F(XE.$$.fragment),vao=l(),$c=a("h2"),zE=a("a"),nwe=a("span"),F(gS.$$.fragment),q7r=l(),swe=a("span"),j7r=o("AutoModelForAudioClassification"),bao=l(),Ko=a("div"),F(hS.$$.fragment),D7r=l(),kc=a("p"),G7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),kee=a("a"),O7r=o("from_pretrained()"),V7r=o(" class method or the "),See=a("a"),X7r=o("from_config()"),z7r=o(` class
method.`),Q7r=l(),uS=a("p"),W7r=o("This class cannot be instantiated directly using "),lwe=a("code"),U7r=o("__init__()"),H7r=o(" (throws an error)."),J7r=l(),Dt=a("div"),F(pS.$$.fragment),Y7r=l(),iwe=a("p"),Z7r=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),K7r=l(),Sc=a("p"),e8r=o(`Note:
Loading a model from its configuration file does `),dwe=a("strong"),o8r=o("not"),r8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ree=a("a"),t8r=o("from_pretrained()"),a8r=o(" to load the model weights."),n8r=l(),F(QE.$$.fragment),s8r=l(),_o=a("div"),F(_S.$$.fragment),l8r=l(),cwe=a("p"),i8r=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),d8r=l(),En=a("p"),c8r=o("The model class to instantiate is selected based on the "),fwe=a("code"),f8r=o("model_type"),m8r=o(` property of the config object (either
passed as an argument or loaded from `),mwe=a("code"),g8r=o("pretrained_model_name_or_path"),h8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gwe=a("code"),u8r=o("pretrained_model_name_or_path"),p8r=o(":"),_8r=l(),Be=a("ul"),WE=a("li"),hwe=a("strong"),v8r=o("data2vec-audio"),b8r=o(" \u2014 "),Pee=a("a"),F8r=o("Data2VecAudioForSequenceClassification"),T8r=o(" (Data2VecAudio model)"),M8r=l(),UE=a("li"),uwe=a("strong"),E8r=o("hubert"),C8r=o(" \u2014 "),Bee=a("a"),w8r=o("HubertForSequenceClassification"),A8r=o(" (Hubert model)"),L8r=l(),HE=a("li"),pwe=a("strong"),y8r=o("sew"),x8r=o(" \u2014 "),Iee=a("a"),$8r=o("SEWForSequenceClassification"),k8r=o(" (SEW model)"),S8r=l(),JE=a("li"),_we=a("strong"),R8r=o("sew-d"),P8r=o(" \u2014 "),Nee=a("a"),B8r=o("SEWDForSequenceClassification"),I8r=o(" (SEW-D model)"),N8r=l(),YE=a("li"),vwe=a("strong"),q8r=o("unispeech"),j8r=o(" \u2014 "),qee=a("a"),D8r=o("UniSpeechForSequenceClassification"),G8r=o(" (UniSpeech model)"),O8r=l(),ZE=a("li"),bwe=a("strong"),V8r=o("unispeech-sat"),X8r=o(" \u2014 "),jee=a("a"),z8r=o("UniSpeechSatForSequenceClassification"),Q8r=o(" (UniSpeechSat model)"),W8r=l(),KE=a("li"),Fwe=a("strong"),U8r=o("wav2vec2"),H8r=o(" \u2014 "),Dee=a("a"),J8r=o("Wav2Vec2ForSequenceClassification"),Y8r=o(" (Wav2Vec2 model)"),Z8r=l(),eC=a("li"),Twe=a("strong"),K8r=o("wav2vec2-conformer"),eLr=o(" \u2014 "),Gee=a("a"),oLr=o("Wav2Vec2ConformerForSequenceClassification"),rLr=o(" (Wav2Vec2-Conformer model)"),tLr=l(),oC=a("li"),Mwe=a("strong"),aLr=o("wavlm"),nLr=o(" \u2014 "),Oee=a("a"),sLr=o("WavLMForSequenceClassification"),lLr=o(" (WavLM model)"),iLr=l(),rC=a("p"),dLr=o("The model is set in evaluation mode by default using "),Ewe=a("code"),cLr=o("model.eval()"),fLr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Cwe=a("code"),mLr=o("model.train()"),gLr=l(),F(tC.$$.fragment),Fao=l(),Rc=a("h2"),aC=a("a"),wwe=a("span"),F(vS.$$.fragment),hLr=l(),Awe=a("span"),uLr=o("AutoModelForAudioFrameClassification"),Tao=l(),er=a("div"),F(bS.$$.fragment),pLr=l(),Pc=a("p"),_Lr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),Vee=a("a"),vLr=o("from_pretrained()"),bLr=o(" class method or the "),Xee=a("a"),FLr=o("from_config()"),TLr=o(` class
method.`),MLr=l(),FS=a("p"),ELr=o("This class cannot be instantiated directly using "),Lwe=a("code"),CLr=o("__init__()"),wLr=o(" (throws an error)."),ALr=l(),Gt=a("div"),F(TS.$$.fragment),LLr=l(),ywe=a("p"),yLr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),xLr=l(),Bc=a("p"),$Lr=o(`Note:
Loading a model from its configuration file does `),xwe=a("strong"),kLr=o("not"),SLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zee=a("a"),RLr=o("from_pretrained()"),PLr=o(" to load the model weights."),BLr=l(),F(nC.$$.fragment),ILr=l(),vo=a("div"),F(MS.$$.fragment),NLr=l(),$we=a("p"),qLr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),jLr=l(),Cn=a("p"),DLr=o("The model class to instantiate is selected based on the "),kwe=a("code"),GLr=o("model_type"),OLr=o(` property of the config object (either
passed as an argument or loaded from `),Swe=a("code"),VLr=o("pretrained_model_name_or_path"),XLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rwe=a("code"),zLr=o("pretrained_model_name_or_path"),QLr=o(":"),WLr=l(),ut=a("ul"),sC=a("li"),Pwe=a("strong"),ULr=o("data2vec-audio"),HLr=o(" \u2014 "),Qee=a("a"),JLr=o("Data2VecAudioForAudioFrameClassification"),YLr=o(" (Data2VecAudio model)"),ZLr=l(),lC=a("li"),Bwe=a("strong"),KLr=o("unispeech-sat"),eyr=o(" \u2014 "),Wee=a("a"),oyr=o("UniSpeechSatForAudioFrameClassification"),ryr=o(" (UniSpeechSat model)"),tyr=l(),iC=a("li"),Iwe=a("strong"),ayr=o("wav2vec2"),nyr=o(" \u2014 "),Uee=a("a"),syr=o("Wav2Vec2ForAudioFrameClassification"),lyr=o(" (Wav2Vec2 model)"),iyr=l(),dC=a("li"),Nwe=a("strong"),dyr=o("wav2vec2-conformer"),cyr=o(" \u2014 "),Hee=a("a"),fyr=o("Wav2Vec2ConformerForAudioFrameClassification"),myr=o(" (Wav2Vec2-Conformer model)"),gyr=l(),cC=a("li"),qwe=a("strong"),hyr=o("wavlm"),uyr=o(" \u2014 "),Jee=a("a"),pyr=o("WavLMForAudioFrameClassification"),_yr=o(" (WavLM model)"),vyr=l(),fC=a("p"),byr=o("The model is set in evaluation mode by default using "),jwe=a("code"),Fyr=o("model.eval()"),Tyr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Dwe=a("code"),Myr=o("model.train()"),Eyr=l(),F(mC.$$.fragment),Mao=l(),Ic=a("h2"),gC=a("a"),Gwe=a("span"),F(ES.$$.fragment),Cyr=l(),Owe=a("span"),wyr=o("AutoModelForCTC"),Eao=l(),or=a("div"),F(CS.$$.fragment),Ayr=l(),Nc=a("p"),Lyr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),Yee=a("a"),yyr=o("from_pretrained()"),xyr=o(" class method or the "),Zee=a("a"),$yr=o("from_config()"),kyr=o(` class
method.`),Syr=l(),wS=a("p"),Ryr=o("This class cannot be instantiated directly using "),Vwe=a("code"),Pyr=o("__init__()"),Byr=o(" (throws an error)."),Iyr=l(),Ot=a("div"),F(AS.$$.fragment),Nyr=l(),Xwe=a("p"),qyr=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),jyr=l(),qc=a("p"),Dyr=o(`Note:
Loading a model from its configuration file does `),zwe=a("strong"),Gyr=o("not"),Oyr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Kee=a("a"),Vyr=o("from_pretrained()"),Xyr=o(" to load the model weights."),zyr=l(),F(hC.$$.fragment),Qyr=l(),bo=a("div"),F(LS.$$.fragment),Wyr=l(),Qwe=a("p"),Uyr=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),Hyr=l(),wn=a("p"),Jyr=o("The model class to instantiate is selected based on the "),Wwe=a("code"),Yyr=o("model_type"),Zyr=o(` property of the config object (either
passed as an argument or loaded from `),Uwe=a("code"),Kyr=o("pretrained_model_name_or_path"),e9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hwe=a("code"),o9r=o("pretrained_model_name_or_path"),r9r=o(":"),t9r=l(),Le=a("ul"),uC=a("li"),Jwe=a("strong"),a9r=o("data2vec-audio"),n9r=o(" \u2014 "),eoe=a("a"),s9r=o("Data2VecAudioForCTC"),l9r=o(" (Data2VecAudio model)"),i9r=l(),pC=a("li"),Ywe=a("strong"),d9r=o("hubert"),c9r=o(" \u2014 "),ooe=a("a"),f9r=o("HubertForCTC"),m9r=o(" (Hubert model)"),g9r=l(),_C=a("li"),Zwe=a("strong"),h9r=o("mctct"),u9r=o(" \u2014 "),roe=a("a"),p9r=o("MCTCTForCTC"),_9r=o(" (M-CTC-T model)"),v9r=l(),vC=a("li"),Kwe=a("strong"),b9r=o("sew"),F9r=o(" \u2014 "),toe=a("a"),T9r=o("SEWForCTC"),M9r=o(" (SEW model)"),E9r=l(),bC=a("li"),eAe=a("strong"),C9r=o("sew-d"),w9r=o(" \u2014 "),aoe=a("a"),A9r=o("SEWDForCTC"),L9r=o(" (SEW-D model)"),y9r=l(),FC=a("li"),oAe=a("strong"),x9r=o("unispeech"),$9r=o(" \u2014 "),noe=a("a"),k9r=o("UniSpeechForCTC"),S9r=o(" (UniSpeech model)"),R9r=l(),TC=a("li"),rAe=a("strong"),P9r=o("unispeech-sat"),B9r=o(" \u2014 "),soe=a("a"),I9r=o("UniSpeechSatForCTC"),N9r=o(" (UniSpeechSat model)"),q9r=l(),MC=a("li"),tAe=a("strong"),j9r=o("wav2vec2"),D9r=o(" \u2014 "),loe=a("a"),G9r=o("Wav2Vec2ForCTC"),O9r=o(" (Wav2Vec2 model)"),V9r=l(),EC=a("li"),aAe=a("strong"),X9r=o("wav2vec2-conformer"),z9r=o(" \u2014 "),ioe=a("a"),Q9r=o("Wav2Vec2ConformerForCTC"),W9r=o(" (Wav2Vec2-Conformer model)"),U9r=l(),CC=a("li"),nAe=a("strong"),H9r=o("wavlm"),J9r=o(" \u2014 "),doe=a("a"),Y9r=o("WavLMForCTC"),Z9r=o(" (WavLM model)"),K9r=l(),wC=a("p"),exr=o("The model is set in evaluation mode by default using "),sAe=a("code"),oxr=o("model.eval()"),rxr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lAe=a("code"),txr=o("model.train()"),axr=l(),F(AC.$$.fragment),Cao=l(),jc=a("h2"),LC=a("a"),iAe=a("span"),F(yS.$$.fragment),nxr=l(),dAe=a("span"),sxr=o("AutoModelForSpeechSeq2Seq"),wao=l(),rr=a("div"),F(xS.$$.fragment),lxr=l(),Dc=a("p"),ixr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),coe=a("a"),dxr=o("from_pretrained()"),cxr=o(" class method or the "),foe=a("a"),fxr=o("from_config()"),mxr=o(` class
method.`),gxr=l(),$S=a("p"),hxr=o("This class cannot be instantiated directly using "),cAe=a("code"),uxr=o("__init__()"),pxr=o(" (throws an error)."),_xr=l(),Vt=a("div"),F(kS.$$.fragment),vxr=l(),fAe=a("p"),bxr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Fxr=l(),Gc=a("p"),Txr=o(`Note:
Loading a model from its configuration file does `),mAe=a("strong"),Mxr=o("not"),Exr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),moe=a("a"),Cxr=o("from_pretrained()"),wxr=o(" to load the model weights."),Axr=l(),F(yC.$$.fragment),Lxr=l(),Fo=a("div"),F(SS.$$.fragment),yxr=l(),gAe=a("p"),xxr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),$xr=l(),An=a("p"),kxr=o("The model class to instantiate is selected based on the "),hAe=a("code"),Sxr=o("model_type"),Rxr=o(` property of the config object (either
passed as an argument or loaded from `),uAe=a("code"),Pxr=o("pretrained_model_name_or_path"),Bxr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pAe=a("code"),Ixr=o("pretrained_model_name_or_path"),Nxr=o(":"),qxr=l(),Oc=a("ul"),xC=a("li"),_Ae=a("strong"),jxr=o("speech-encoder-decoder"),Dxr=o(" \u2014 "),goe=a("a"),Gxr=o("SpeechEncoderDecoderModel"),Oxr=o(" (Speech Encoder decoder model)"),Vxr=l(),$C=a("li"),vAe=a("strong"),Xxr=o("speech_to_text"),zxr=o(" \u2014 "),hoe=a("a"),Qxr=o("Speech2TextForConditionalGeneration"),Wxr=o(" (Speech2Text model)"),Uxr=l(),kC=a("li"),bAe=a("strong"),Hxr=o("whisper"),Jxr=o(" \u2014 "),uoe=a("a"),Yxr=o("WhisperForConditionalGeneration"),Zxr=o(" (Whisper model)"),Kxr=l(),SC=a("p"),e$r=o("The model is set in evaluation mode by default using "),FAe=a("code"),o$r=o("model.eval()"),r$r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),TAe=a("code"),t$r=o("model.train()"),a$r=l(),F(RC.$$.fragment),Aao=l(),Vc=a("h2"),PC=a("a"),MAe=a("span"),F(RS.$$.fragment),n$r=l(),EAe=a("span"),s$r=o("AutoModelForAudioXVector"),Lao=l(),tr=a("div"),F(PS.$$.fragment),l$r=l(),Xc=a("p"),i$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),poe=a("a"),d$r=o("from_pretrained()"),c$r=o(" class method or the "),_oe=a("a"),f$r=o("from_config()"),m$r=o(` class
method.`),g$r=l(),BS=a("p"),h$r=o("This class cannot be instantiated directly using "),CAe=a("code"),u$r=o("__init__()"),p$r=o(" (throws an error)."),_$r=l(),Xt=a("div"),F(IS.$$.fragment),v$r=l(),wAe=a("p"),b$r=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),F$r=l(),zc=a("p"),T$r=o(`Note:
Loading a model from its configuration file does `),AAe=a("strong"),M$r=o("not"),E$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),voe=a("a"),C$r=o("from_pretrained()"),w$r=o(" to load the model weights."),A$r=l(),F(BC.$$.fragment),L$r=l(),To=a("div"),F(NS.$$.fragment),y$r=l(),LAe=a("p"),x$r=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),$$r=l(),Ln=a("p"),k$r=o("The model class to instantiate is selected based on the "),yAe=a("code"),S$r=o("model_type"),R$r=o(` property of the config object (either
passed as an argument or loaded from `),xAe=a("code"),P$r=o("pretrained_model_name_or_path"),B$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Ae=a("code"),I$r=o("pretrained_model_name_or_path"),N$r=o(":"),q$r=l(),pt=a("ul"),IC=a("li"),kAe=a("strong"),j$r=o("data2vec-audio"),D$r=o(" \u2014 "),boe=a("a"),G$r=o("Data2VecAudioForXVector"),O$r=o(" (Data2VecAudio model)"),V$r=l(),NC=a("li"),SAe=a("strong"),X$r=o("unispeech-sat"),z$r=o(" \u2014 "),Foe=a("a"),Q$r=o("UniSpeechSatForXVector"),W$r=o(" (UniSpeechSat model)"),U$r=l(),qC=a("li"),RAe=a("strong"),H$r=o("wav2vec2"),J$r=o(" \u2014 "),Toe=a("a"),Y$r=o("Wav2Vec2ForXVector"),Z$r=o(" (Wav2Vec2 model)"),K$r=l(),jC=a("li"),PAe=a("strong"),ekr=o("wav2vec2-conformer"),okr=o(" \u2014 "),Moe=a("a"),rkr=o("Wav2Vec2ConformerForXVector"),tkr=o(" (Wav2Vec2-Conformer model)"),akr=l(),DC=a("li"),BAe=a("strong"),nkr=o("wavlm"),skr=o(" \u2014 "),Eoe=a("a"),lkr=o("WavLMForXVector"),ikr=o(" (WavLM model)"),dkr=l(),GC=a("p"),ckr=o("The model is set in evaluation mode by default using "),IAe=a("code"),fkr=o("model.eval()"),mkr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),NAe=a("code"),gkr=o("model.train()"),hkr=l(),F(OC.$$.fragment),yao=l(),Qc=a("h2"),VC=a("a"),qAe=a("span"),F(qS.$$.fragment),ukr=l(),jAe=a("span"),pkr=o("AutoModelForMaskedImageModeling"),xao=l(),ar=a("div"),F(jS.$$.fragment),_kr=l(),Wc=a("p"),vkr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),Coe=a("a"),bkr=o("from_pretrained()"),Fkr=o(" class method or the "),woe=a("a"),Tkr=o("from_config()"),Mkr=o(` class
method.`),Ekr=l(),DS=a("p"),Ckr=o("This class cannot be instantiated directly using "),DAe=a("code"),wkr=o("__init__()"),Akr=o(" (throws an error)."),Lkr=l(),zt=a("div"),F(GS.$$.fragment),ykr=l(),GAe=a("p"),xkr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),$kr=l(),Uc=a("p"),kkr=o(`Note:
Loading a model from its configuration file does `),OAe=a("strong"),Skr=o("not"),Rkr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Aoe=a("a"),Pkr=o("from_pretrained()"),Bkr=o(" to load the model weights."),Ikr=l(),F(XC.$$.fragment),Nkr=l(),Mo=a("div"),F(OS.$$.fragment),qkr=l(),VAe=a("p"),jkr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),Dkr=l(),yn=a("p"),Gkr=o("The model class to instantiate is selected based on the "),XAe=a("code"),Okr=o("model_type"),Vkr=o(` property of the config object (either
passed as an argument or loaded from `),zAe=a("code"),Xkr=o("pretrained_model_name_or_path"),zkr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QAe=a("code"),Qkr=o("pretrained_model_name_or_path"),Wkr=o(":"),Ukr=l(),xn=a("ul"),zC=a("li"),WAe=a("strong"),Hkr=o("deit"),Jkr=o(" \u2014 "),Loe=a("a"),Ykr=o("DeiTForMaskedImageModeling"),Zkr=o(" (DeiT model)"),Kkr=l(),QC=a("li"),UAe=a("strong"),eSr=o("swin"),oSr=o(" \u2014 "),yoe=a("a"),rSr=o("SwinForMaskedImageModeling"),tSr=o(" (Swin Transformer model)"),aSr=l(),WC=a("li"),HAe=a("strong"),nSr=o("swinv2"),sSr=o(" \u2014 "),xoe=a("a"),lSr=o("Swinv2ForMaskedImageModeling"),iSr=o(" (Swin Transformer V2 model)"),dSr=l(),UC=a("li"),JAe=a("strong"),cSr=o("vit"),fSr=o(" \u2014 "),$oe=a("a"),mSr=o("ViTForMaskedImageModeling"),gSr=o(" (ViT model)"),hSr=l(),HC=a("p"),uSr=o("The model is set in evaluation mode by default using "),YAe=a("code"),pSr=o("model.eval()"),_Sr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ZAe=a("code"),vSr=o("model.train()"),bSr=l(),F(JC.$$.fragment),$ao=l(),Hc=a("h2"),YC=a("a"),KAe=a("span"),F(VS.$$.fragment),FSr=l(),e6e=a("span"),TSr=o("AutoModelForObjectDetection"),kao=l(),nr=a("div"),F(XS.$$.fragment),MSr=l(),Jc=a("p"),ESr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),koe=a("a"),CSr=o("from_pretrained()"),wSr=o(" class method or the "),Soe=a("a"),ASr=o("from_config()"),LSr=o(` class
method.`),ySr=l(),zS=a("p"),xSr=o("This class cannot be instantiated directly using "),o6e=a("code"),$Sr=o("__init__()"),kSr=o(" (throws an error)."),SSr=l(),Qt=a("div"),F(QS.$$.fragment),RSr=l(),r6e=a("p"),PSr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),BSr=l(),Yc=a("p"),ISr=o(`Note:
Loading a model from its configuration file does `),t6e=a("strong"),NSr=o("not"),qSr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Roe=a("a"),jSr=o("from_pretrained()"),DSr=o(" to load the model weights."),GSr=l(),F(ZC.$$.fragment),OSr=l(),Eo=a("div"),F(WS.$$.fragment),VSr=l(),a6e=a("p"),XSr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),zSr=l(),$n=a("p"),QSr=o("The model class to instantiate is selected based on the "),n6e=a("code"),WSr=o("model_type"),USr=o(` property of the config object (either
passed as an argument or loaded from `),s6e=a("code"),HSr=o("pretrained_model_name_or_path"),JSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l6e=a("code"),YSr=o("pretrained_model_name_or_path"),ZSr=o(":"),KSr=l(),_t=a("ul"),KC=a("li"),i6e=a("strong"),eRr=o("conditional_detr"),oRr=o(" \u2014 "),Poe=a("a"),rRr=o("ConditionalDetrForObjectDetection"),tRr=o(" (Conditional DETR model)"),aRr=l(),e3=a("li"),d6e=a("strong"),nRr=o("deformable_detr"),sRr=o(" \u2014 "),Boe=a("a"),lRr=o("DeformableDetrForObjectDetection"),iRr=o(" (Deformable DETR model)"),dRr=l(),o3=a("li"),c6e=a("strong"),cRr=o("detr"),fRr=o(" \u2014 "),Ioe=a("a"),mRr=o("DetrForObjectDetection"),gRr=o(" (DETR model)"),hRr=l(),r3=a("li"),f6e=a("strong"),uRr=o("table-transformer"),pRr=o(" \u2014 "),Noe=a("a"),_Rr=o("TableTransformerForObjectDetection"),vRr=o(" (Table Transformer model)"),bRr=l(),t3=a("li"),m6e=a("strong"),FRr=o("yolos"),TRr=o(" \u2014 "),qoe=a("a"),MRr=o("YolosForObjectDetection"),ERr=o(" (YOLOS model)"),CRr=l(),a3=a("p"),wRr=o("The model is set in evaluation mode by default using "),g6e=a("code"),ARr=o("model.eval()"),LRr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),h6e=a("code"),yRr=o("model.train()"),xRr=l(),F(n3.$$.fragment),Sao=l(),Zc=a("h2"),s3=a("a"),u6e=a("span"),F(US.$$.fragment),$Rr=l(),p6e=a("span"),kRr=o("AutoModelForImageSegmentation"),Rao=l(),sr=a("div"),F(HS.$$.fragment),SRr=l(),Kc=a("p"),RRr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),joe=a("a"),PRr=o("from_pretrained()"),BRr=o(" class method or the "),Doe=a("a"),IRr=o("from_config()"),NRr=o(` class
method.`),qRr=l(),JS=a("p"),jRr=o("This class cannot be instantiated directly using "),_6e=a("code"),DRr=o("__init__()"),GRr=o(" (throws an error)."),ORr=l(),Wt=a("div"),F(YS.$$.fragment),VRr=l(),v6e=a("p"),XRr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),zRr=l(),ef=a("p"),QRr=o(`Note:
Loading a model from its configuration file does `),b6e=a("strong"),WRr=o("not"),URr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Goe=a("a"),HRr=o("from_pretrained()"),JRr=o(" to load the model weights."),YRr=l(),F(l3.$$.fragment),ZRr=l(),Co=a("div"),F(ZS.$$.fragment),KRr=l(),F6e=a("p"),ePr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),oPr=l(),kn=a("p"),rPr=o("The model class to instantiate is selected based on the "),T6e=a("code"),tPr=o("model_type"),aPr=o(` property of the config object (either
passed as an argument or loaded from `),M6e=a("code"),nPr=o("pretrained_model_name_or_path"),sPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E6e=a("code"),lPr=o("pretrained_model_name_or_path"),iPr=o(":"),dPr=l(),C6e=a("ul"),i3=a("li"),w6e=a("strong"),cPr=o("detr"),fPr=o(" \u2014 "),Ooe=a("a"),mPr=o("DetrForSegmentation"),gPr=o(" (DETR model)"),hPr=l(),d3=a("p"),uPr=o("The model is set in evaluation mode by default using "),A6e=a("code"),pPr=o("model.eval()"),_Pr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),L6e=a("code"),vPr=o("model.train()"),bPr=l(),F(c3.$$.fragment),Pao=l(),of=a("h2"),f3=a("a"),y6e=a("span"),F(KS.$$.fragment),FPr=l(),x6e=a("span"),TPr=o("AutoModelForSemanticSegmentation"),Bao=l(),lr=a("div"),F(eR.$$.fragment),MPr=l(),rf=a("p"),EPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Voe=a("a"),CPr=o("from_pretrained()"),wPr=o(" class method or the "),Xoe=a("a"),APr=o("from_config()"),LPr=o(` class
method.`),yPr=l(),oR=a("p"),xPr=o("This class cannot be instantiated directly using "),$6e=a("code"),$Pr=o("__init__()"),kPr=o(" (throws an error)."),SPr=l(),Ut=a("div"),F(rR.$$.fragment),RPr=l(),k6e=a("p"),PPr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),BPr=l(),tf=a("p"),IPr=o(`Note:
Loading a model from its configuration file does `),S6e=a("strong"),NPr=o("not"),qPr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zoe=a("a"),jPr=o("from_pretrained()"),DPr=o(" to load the model weights."),GPr=l(),F(m3.$$.fragment),OPr=l(),wo=a("div"),F(tR.$$.fragment),VPr=l(),R6e=a("p"),XPr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),zPr=l(),Sn=a("p"),QPr=o("The model class to instantiate is selected based on the "),P6e=a("code"),WPr=o("model_type"),UPr=o(` property of the config object (either
passed as an argument or loaded from `),B6e=a("code"),HPr=o("pretrained_model_name_or_path"),JPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I6e=a("code"),YPr=o("pretrained_model_name_or_path"),ZPr=o(":"),KPr=l(),vt=a("ul"),g3=a("li"),N6e=a("strong"),eBr=o("beit"),oBr=o(" \u2014 "),Qoe=a("a"),rBr=o("BeitForSemanticSegmentation"),tBr=o(" (BEiT model)"),aBr=l(),h3=a("li"),q6e=a("strong"),nBr=o("data2vec-vision"),sBr=o(" \u2014 "),Woe=a("a"),lBr=o("Data2VecVisionForSemanticSegmentation"),iBr=o(" (Data2VecVision model)"),dBr=l(),u3=a("li"),j6e=a("strong"),cBr=o("dpt"),fBr=o(" \u2014 "),Uoe=a("a"),mBr=o("DPTForSemanticSegmentation"),gBr=o(" (DPT model)"),hBr=l(),p3=a("li"),D6e=a("strong"),uBr=o("mobilevit"),pBr=o(" \u2014 "),Hoe=a("a"),_Br=o("MobileViTForSemanticSegmentation"),vBr=o(" (MobileViT model)"),bBr=l(),_3=a("li"),G6e=a("strong"),FBr=o("segformer"),TBr=o(" \u2014 "),Joe=a("a"),MBr=o("SegformerForSemanticSegmentation"),EBr=o(" (SegFormer model)"),CBr=l(),v3=a("p"),wBr=o("The model is set in evaluation mode by default using "),O6e=a("code"),ABr=o("model.eval()"),LBr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),V6e=a("code"),yBr=o("model.train()"),xBr=l(),F(b3.$$.fragment),Iao=l(),af=a("h2"),F3=a("a"),X6e=a("span"),F(aR.$$.fragment),$Br=l(),z6e=a("span"),kBr=o("AutoModelForInstanceSegmentation"),Nao=l(),ir=a("div"),F(nR.$$.fragment),SBr=l(),nf=a("p"),RBr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Yoe=a("a"),PBr=o("from_pretrained()"),BBr=o(" class method or the "),Zoe=a("a"),IBr=o("from_config()"),NBr=o(` class
method.`),qBr=l(),sR=a("p"),jBr=o("This class cannot be instantiated directly using "),Q6e=a("code"),DBr=o("__init__()"),GBr=o(" (throws an error)."),OBr=l(),Ht=a("div"),F(lR.$$.fragment),VBr=l(),W6e=a("p"),XBr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),zBr=l(),sf=a("p"),QBr=o(`Note:
Loading a model from its configuration file does `),U6e=a("strong"),WBr=o("not"),UBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Koe=a("a"),HBr=o("from_pretrained()"),JBr=o(" to load the model weights."),YBr=l(),F(T3.$$.fragment),ZBr=l(),Ao=a("div"),F(iR.$$.fragment),KBr=l(),H6e=a("p"),eIr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),oIr=l(),Rn=a("p"),rIr=o("The model class to instantiate is selected based on the "),J6e=a("code"),tIr=o("model_type"),aIr=o(` property of the config object (either
passed as an argument or loaded from `),Y6e=a("code"),nIr=o("pretrained_model_name_or_path"),sIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z6e=a("code"),lIr=o("pretrained_model_name_or_path"),iIr=o(":"),dIr=l(),K6e=a("ul"),M3=a("li"),e7e=a("strong"),cIr=o("maskformer"),fIr=o(" \u2014 "),ere=a("a"),mIr=o("MaskFormerForInstanceSegmentation"),gIr=o(" (MaskFormer model)"),hIr=l(),E3=a("p"),uIr=o("The model is set in evaluation mode by default using "),o7e=a("code"),pIr=o("model.eval()"),_Ir=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),r7e=a("code"),vIr=o("model.train()"),bIr=l(),F(C3.$$.fragment),qao=l(),lf=a("h2"),w3=a("a"),t7e=a("span"),F(dR.$$.fragment),FIr=l(),a7e=a("span"),TIr=o("AutoModelForZeroShotObjectDetection"),jao=l(),dr=a("div"),F(cR.$$.fragment),MIr=l(),df=a("p"),EIr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),ore=a("a"),CIr=o("from_pretrained()"),wIr=o(" class method or the "),rre=a("a"),AIr=o("from_config()"),LIr=o(` class
method.`),yIr=l(),fR=a("p"),xIr=o("This class cannot be instantiated directly using "),n7e=a("code"),$Ir=o("__init__()"),kIr=o(" (throws an error)."),SIr=l(),Jt=a("div"),F(mR.$$.fragment),RIr=l(),s7e=a("p"),PIr=o("Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),BIr=l(),cf=a("p"),IIr=o(`Note:
Loading a model from its configuration file does `),l7e=a("strong"),NIr=o("not"),qIr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tre=a("a"),jIr=o("from_pretrained()"),DIr=o(" to load the model weights."),GIr=l(),F(A3.$$.fragment),OIr=l(),Lo=a("div"),F(gR.$$.fragment),VIr=l(),i7e=a("p"),XIr=o("Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),zIr=l(),Pn=a("p"),QIr=o("The model class to instantiate is selected based on the "),d7e=a("code"),WIr=o("model_type"),UIr=o(` property of the config object (either
passed as an argument or loaded from `),c7e=a("code"),HIr=o("pretrained_model_name_or_path"),JIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f7e=a("code"),YIr=o("pretrained_model_name_or_path"),ZIr=o(":"),KIr=l(),m7e=a("ul"),L3=a("li"),g7e=a("strong"),eNr=o("owlvit"),oNr=o(" \u2014 "),are=a("a"),rNr=o("OwlViTForObjectDetection"),tNr=o(" (OWL-ViT model)"),aNr=l(),y3=a("p"),nNr=o("The model is set in evaluation mode by default using "),h7e=a("code"),sNr=o("model.eval()"),lNr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u7e=a("code"),iNr=o("model.train()"),dNr=l(),F(x3.$$.fragment),Dao=l(),ff=a("h2"),$3=a("a"),p7e=a("span"),F(hR.$$.fragment),cNr=l(),_7e=a("span"),fNr=o("TFAutoModel"),Gao=l(),cr=a("div"),F(uR.$$.fragment),mNr=l(),mf=a("p"),gNr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),nre=a("a"),hNr=o("from_pretrained()"),uNr=o(" class method or the "),sre=a("a"),pNr=o("from_config()"),_Nr=o(` class
method.`),vNr=l(),pR=a("p"),bNr=o("This class cannot be instantiated directly using "),v7e=a("code"),FNr=o("__init__()"),TNr=o(" (throws an error)."),MNr=l(),Yt=a("div"),F(_R.$$.fragment),ENr=l(),b7e=a("p"),CNr=o("Instantiates one of the base model classes of the library from a configuration."),wNr=l(),gf=a("p"),ANr=o(`Note:
Loading a model from its configuration file does `),F7e=a("strong"),LNr=o("not"),yNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lre=a("a"),xNr=o("from_pretrained()"),$Nr=o(" to load the model weights."),kNr=l(),F(k3.$$.fragment),SNr=l(),Dr=a("div"),F(vR.$$.fragment),RNr=l(),T7e=a("p"),PNr=o("Instantiate one of the base model classes of the library from a pretrained model."),BNr=l(),Bn=a("p"),INr=o("The model class to instantiate is selected based on the "),M7e=a("code"),NNr=o("model_type"),qNr=o(` property of the config object (either
passed as an argument or loaded from `),E7e=a("code"),jNr=o("pretrained_model_name_or_path"),DNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C7e=a("code"),GNr=o("pretrained_model_name_or_path"),ONr=o(":"),VNr=l(),P=a("ul"),S3=a("li"),w7e=a("strong"),XNr=o("albert"),zNr=o(" \u2014 "),ire=a("a"),QNr=o("TFAlbertModel"),WNr=o(" (ALBERT model)"),UNr=l(),R3=a("li"),A7e=a("strong"),HNr=o("bart"),JNr=o(" \u2014 "),dre=a("a"),YNr=o("TFBartModel"),ZNr=o(" (BART model)"),KNr=l(),P3=a("li"),L7e=a("strong"),eqr=o("bert"),oqr=o(" \u2014 "),cre=a("a"),rqr=o("TFBertModel"),tqr=o(" (BERT model)"),aqr=l(),B3=a("li"),y7e=a("strong"),nqr=o("blenderbot"),sqr=o(" \u2014 "),fre=a("a"),lqr=o("TFBlenderbotModel"),iqr=o(" (Blenderbot model)"),dqr=l(),I3=a("li"),x7e=a("strong"),cqr=o("blenderbot-small"),fqr=o(" \u2014 "),mre=a("a"),mqr=o("TFBlenderbotSmallModel"),gqr=o(" (BlenderbotSmall model)"),hqr=l(),N3=a("li"),$7e=a("strong"),uqr=o("camembert"),pqr=o(" \u2014 "),gre=a("a"),_qr=o("TFCamembertModel"),vqr=o(" (CamemBERT model)"),bqr=l(),q3=a("li"),k7e=a("strong"),Fqr=o("clip"),Tqr=o(" \u2014 "),hre=a("a"),Mqr=o("TFCLIPModel"),Eqr=o(" (CLIP model)"),Cqr=l(),j3=a("li"),S7e=a("strong"),wqr=o("convbert"),Aqr=o(" \u2014 "),ure=a("a"),Lqr=o("TFConvBertModel"),yqr=o(" (ConvBERT model)"),xqr=l(),D3=a("li"),R7e=a("strong"),$qr=o("convnext"),kqr=o(" \u2014 "),pre=a("a"),Sqr=o("TFConvNextModel"),Rqr=o(" (ConvNeXT model)"),Pqr=l(),G3=a("li"),P7e=a("strong"),Bqr=o("ctrl"),Iqr=o(" \u2014 "),_re=a("a"),Nqr=o("TFCTRLModel"),qqr=o(" (CTRL model)"),jqr=l(),O3=a("li"),B7e=a("strong"),Dqr=o("cvt"),Gqr=o(" \u2014 "),vre=a("a"),Oqr=o("TFCvtModel"),Vqr=o(" (CvT model)"),Xqr=l(),V3=a("li"),I7e=a("strong"),zqr=o("data2vec-vision"),Qqr=o(" \u2014 "),bre=a("a"),Wqr=o("TFData2VecVisionModel"),Uqr=o(" (Data2VecVision model)"),Hqr=l(),X3=a("li"),N7e=a("strong"),Jqr=o("deberta"),Yqr=o(" \u2014 "),Fre=a("a"),Zqr=o("TFDebertaModel"),Kqr=o(" (DeBERTa model)"),ejr=l(),z3=a("li"),q7e=a("strong"),ojr=o("deberta-v2"),rjr=o(" \u2014 "),Tre=a("a"),tjr=o("TFDebertaV2Model"),ajr=o(" (DeBERTa-v2 model)"),njr=l(),Q3=a("li"),j7e=a("strong"),sjr=o("deit"),ljr=o(" \u2014 "),Mre=a("a"),ijr=o("TFDeiTModel"),djr=o(" (DeiT model)"),cjr=l(),W3=a("li"),D7e=a("strong"),fjr=o("distilbert"),mjr=o(" \u2014 "),Ere=a("a"),gjr=o("TFDistilBertModel"),hjr=o(" (DistilBERT model)"),ujr=l(),U3=a("li"),G7e=a("strong"),pjr=o("dpr"),_jr=o(" \u2014 "),Cre=a("a"),vjr=o("TFDPRQuestionEncoder"),bjr=o(" (DPR model)"),Fjr=l(),H3=a("li"),O7e=a("strong"),Tjr=o("electra"),Mjr=o(" \u2014 "),wre=a("a"),Ejr=o("TFElectraModel"),Cjr=o(" (ELECTRA model)"),wjr=l(),J3=a("li"),V7e=a("strong"),Ajr=o("esm"),Ljr=o(" \u2014 "),Are=a("a"),yjr=o("TFEsmModel"),xjr=o(" (ESM model)"),$jr=l(),Y3=a("li"),X7e=a("strong"),kjr=o("flaubert"),Sjr=o(" \u2014 "),Lre=a("a"),Rjr=o("TFFlaubertModel"),Pjr=o(" (FlauBERT model)"),Bjr=l(),Sl=a("li"),z7e=a("strong"),Ijr=o("funnel"),Njr=o(" \u2014 "),yre=a("a"),qjr=o("TFFunnelModel"),jjr=o(" or "),xre=a("a"),Djr=o("TFFunnelBaseModel"),Gjr=o(" (Funnel Transformer model)"),Ojr=l(),Z3=a("li"),Q7e=a("strong"),Vjr=o("gpt2"),Xjr=o(" \u2014 "),$re=a("a"),zjr=o("TFGPT2Model"),Qjr=o(" (OpenAI GPT-2 model)"),Wjr=l(),K3=a("li"),W7e=a("strong"),Ujr=o("gptj"),Hjr=o(" \u2014 "),kre=a("a"),Jjr=o("TFGPTJModel"),Yjr=o(" (GPT-J model)"),Zjr=l(),e5=a("li"),U7e=a("strong"),Kjr=o("groupvit"),eDr=o(" \u2014 "),Sre=a("a"),oDr=o("TFGroupViTModel"),rDr=o(" (GroupViT model)"),tDr=l(),o5=a("li"),H7e=a("strong"),aDr=o("hubert"),nDr=o(" \u2014 "),Rre=a("a"),sDr=o("TFHubertModel"),lDr=o(" (Hubert model)"),iDr=l(),r5=a("li"),J7e=a("strong"),dDr=o("layoutlm"),cDr=o(" \u2014 "),Pre=a("a"),fDr=o("TFLayoutLMModel"),mDr=o(" (LayoutLM model)"),gDr=l(),t5=a("li"),Y7e=a("strong"),hDr=o("layoutlmv3"),uDr=o(" \u2014 "),Bre=a("a"),pDr=o("TFLayoutLMv3Model"),_Dr=o(" (LayoutLMv3 model)"),vDr=l(),a5=a("li"),Z7e=a("strong"),bDr=o("led"),FDr=o(" \u2014 "),Ire=a("a"),TDr=o("TFLEDModel"),MDr=o(" (LED model)"),EDr=l(),n5=a("li"),K7e=a("strong"),CDr=o("longformer"),wDr=o(" \u2014 "),Nre=a("a"),ADr=o("TFLongformerModel"),LDr=o(" (Longformer model)"),yDr=l(),s5=a("li"),e8e=a("strong"),xDr=o("lxmert"),$Dr=o(" \u2014 "),qre=a("a"),kDr=o("TFLxmertModel"),SDr=o(" (LXMERT model)"),RDr=l(),l5=a("li"),o8e=a("strong"),PDr=o("marian"),BDr=o(" \u2014 "),jre=a("a"),IDr=o("TFMarianModel"),NDr=o(" (Marian model)"),qDr=l(),i5=a("li"),r8e=a("strong"),jDr=o("mbart"),DDr=o(" \u2014 "),Dre=a("a"),GDr=o("TFMBartModel"),ODr=o(" (mBART model)"),VDr=l(),d5=a("li"),t8e=a("strong"),XDr=o("mobilebert"),zDr=o(" \u2014 "),Gre=a("a"),QDr=o("TFMobileBertModel"),WDr=o(" (MobileBERT model)"),UDr=l(),c5=a("li"),a8e=a("strong"),HDr=o("mobilevit"),JDr=o(" \u2014 "),Ore=a("a"),YDr=o("TFMobileViTModel"),ZDr=o(" (MobileViT model)"),KDr=l(),f5=a("li"),n8e=a("strong"),eGr=o("mpnet"),oGr=o(" \u2014 "),Vre=a("a"),rGr=o("TFMPNetModel"),tGr=o(" (MPNet model)"),aGr=l(),m5=a("li"),s8e=a("strong"),nGr=o("mt5"),sGr=o(" \u2014 "),Xre=a("a"),lGr=o("TFMT5Model"),iGr=o(" (MT5 model)"),dGr=l(),g5=a("li"),l8e=a("strong"),cGr=o("openai-gpt"),fGr=o(" \u2014 "),zre=a("a"),mGr=o("TFOpenAIGPTModel"),gGr=o(" (OpenAI GPT model)"),hGr=l(),h5=a("li"),i8e=a("strong"),uGr=o("opt"),pGr=o(" \u2014 "),Qre=a("a"),_Gr=o("TFOPTModel"),vGr=o(" (OPT model)"),bGr=l(),u5=a("li"),d8e=a("strong"),FGr=o("pegasus"),TGr=o(" \u2014 "),Wre=a("a"),MGr=o("TFPegasusModel"),EGr=o(" (Pegasus model)"),CGr=l(),p5=a("li"),c8e=a("strong"),wGr=o("regnet"),AGr=o(" \u2014 "),Ure=a("a"),LGr=o("TFRegNetModel"),yGr=o(" (RegNet model)"),xGr=l(),_5=a("li"),f8e=a("strong"),$Gr=o("rembert"),kGr=o(" \u2014 "),Hre=a("a"),SGr=o("TFRemBertModel"),RGr=o(" (RemBERT model)"),PGr=l(),v5=a("li"),m8e=a("strong"),BGr=o("resnet"),IGr=o(" \u2014 "),Jre=a("a"),NGr=o("TFResNetModel"),qGr=o(" (ResNet model)"),jGr=l(),b5=a("li"),g8e=a("strong"),DGr=o("roberta"),GGr=o(" \u2014 "),Yre=a("a"),OGr=o("TFRobertaModel"),VGr=o(" (RoBERTa model)"),XGr=l(),F5=a("li"),h8e=a("strong"),zGr=o("roformer"),QGr=o(" \u2014 "),Zre=a("a"),WGr=o("TFRoFormerModel"),UGr=o(" (RoFormer model)"),HGr=l(),T5=a("li"),u8e=a("strong"),JGr=o("segformer"),YGr=o(" \u2014 "),Kre=a("a"),ZGr=o("TFSegformerModel"),KGr=o(" (SegFormer model)"),eOr=l(),M5=a("li"),p8e=a("strong"),oOr=o("speech_to_text"),rOr=o(" \u2014 "),ete=a("a"),tOr=o("TFSpeech2TextModel"),aOr=o(" (Speech2Text model)"),nOr=l(),E5=a("li"),_8e=a("strong"),sOr=o("swin"),lOr=o(" \u2014 "),ote=a("a"),iOr=o("TFSwinModel"),dOr=o(" (Swin Transformer model)"),cOr=l(),C5=a("li"),v8e=a("strong"),fOr=o("t5"),mOr=o(" \u2014 "),rte=a("a"),gOr=o("TFT5Model"),hOr=o(" (T5 model)"),uOr=l(),w5=a("li"),b8e=a("strong"),pOr=o("tapas"),_Or=o(" \u2014 "),tte=a("a"),vOr=o("TFTapasModel"),bOr=o(" (TAPAS model)"),FOr=l(),A5=a("li"),F8e=a("strong"),TOr=o("transfo-xl"),MOr=o(" \u2014 "),ate=a("a"),EOr=o("TFTransfoXLModel"),COr=o(" (Transformer-XL model)"),wOr=l(),L5=a("li"),T8e=a("strong"),AOr=o("vit"),LOr=o(" \u2014 "),nte=a("a"),yOr=o("TFViTModel"),xOr=o(" (ViT model)"),$Or=l(),y5=a("li"),M8e=a("strong"),kOr=o("vit_mae"),SOr=o(" \u2014 "),ste=a("a"),ROr=o("TFViTMAEModel"),POr=o(" (ViTMAE model)"),BOr=l(),x5=a("li"),E8e=a("strong"),IOr=o("wav2vec2"),NOr=o(" \u2014 "),lte=a("a"),qOr=o("TFWav2Vec2Model"),jOr=o(" (Wav2Vec2 model)"),DOr=l(),$5=a("li"),C8e=a("strong"),GOr=o("whisper"),OOr=o(" \u2014 "),ite=a("a"),VOr=o("TFWhisperModel"),XOr=o(" (Whisper model)"),zOr=l(),k5=a("li"),w8e=a("strong"),QOr=o("xglm"),WOr=o(" \u2014 "),dte=a("a"),UOr=o("TFXGLMModel"),HOr=o(" (XGLM model)"),JOr=l(),S5=a("li"),A8e=a("strong"),YOr=o("xlm"),ZOr=o(" \u2014 "),cte=a("a"),KOr=o("TFXLMModel"),eVr=o(" (XLM model)"),oVr=l(),R5=a("li"),L8e=a("strong"),rVr=o("xlm-roberta"),tVr=o(" \u2014 "),fte=a("a"),aVr=o("TFXLMRobertaModel"),nVr=o(" (XLM-RoBERTa model)"),sVr=l(),P5=a("li"),y8e=a("strong"),lVr=o("xlnet"),iVr=o(" \u2014 "),mte=a("a"),dVr=o("TFXLNetModel"),cVr=o(" (XLNet model)"),fVr=l(),F(B5.$$.fragment),Oao=l(),hf=a("h2"),I5=a("a"),x8e=a("span"),F(bR.$$.fragment),mVr=l(),$8e=a("span"),gVr=o("TFAutoModelForPreTraining"),Vao=l(),fr=a("div"),F(FR.$$.fragment),hVr=l(),uf=a("p"),uVr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),gte=a("a"),pVr=o("from_pretrained()"),_Vr=o(" class method or the "),hte=a("a"),vVr=o("from_config()"),bVr=o(` class
method.`),FVr=l(),TR=a("p"),TVr=o("This class cannot be instantiated directly using "),k8e=a("code"),MVr=o("__init__()"),EVr=o(" (throws an error)."),CVr=l(),Zt=a("div"),F(MR.$$.fragment),wVr=l(),S8e=a("p"),AVr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),LVr=l(),pf=a("p"),yVr=o(`Note:
Loading a model from its configuration file does `),R8e=a("strong"),xVr=o("not"),$Vr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ute=a("a"),kVr=o("from_pretrained()"),SVr=o(" to load the model weights."),RVr=l(),F(N5.$$.fragment),PVr=l(),Gr=a("div"),F(ER.$$.fragment),BVr=l(),P8e=a("p"),IVr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),NVr=l(),In=a("p"),qVr=o("The model class to instantiate is selected based on the "),B8e=a("code"),jVr=o("model_type"),DVr=o(` property of the config object (either
passed as an argument or loaded from `),I8e=a("code"),GVr=o("pretrained_model_name_or_path"),OVr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N8e=a("code"),VVr=o("pretrained_model_name_or_path"),XVr=o(":"),zVr=l(),se=a("ul"),q5=a("li"),q8e=a("strong"),QVr=o("albert"),WVr=o(" \u2014 "),pte=a("a"),UVr=o("TFAlbertForPreTraining"),HVr=o(" (ALBERT model)"),JVr=l(),j5=a("li"),j8e=a("strong"),YVr=o("bart"),ZVr=o(" \u2014 "),_te=a("a"),KVr=o("TFBartForConditionalGeneration"),eXr=o(" (BART model)"),oXr=l(),D5=a("li"),D8e=a("strong"),rXr=o("bert"),tXr=o(" \u2014 "),vte=a("a"),aXr=o("TFBertForPreTraining"),nXr=o(" (BERT model)"),sXr=l(),G5=a("li"),G8e=a("strong"),lXr=o("camembert"),iXr=o(" \u2014 "),bte=a("a"),dXr=o("TFCamembertForMaskedLM"),cXr=o(" (CamemBERT model)"),fXr=l(),O5=a("li"),O8e=a("strong"),mXr=o("ctrl"),gXr=o(" \u2014 "),Fte=a("a"),hXr=o("TFCTRLLMHeadModel"),uXr=o(" (CTRL model)"),pXr=l(),V5=a("li"),V8e=a("strong"),_Xr=o("distilbert"),vXr=o(" \u2014 "),Tte=a("a"),bXr=o("TFDistilBertForMaskedLM"),FXr=o(" (DistilBERT model)"),TXr=l(),X5=a("li"),X8e=a("strong"),MXr=o("electra"),EXr=o(" \u2014 "),Mte=a("a"),CXr=o("TFElectraForPreTraining"),wXr=o(" (ELECTRA model)"),AXr=l(),z5=a("li"),z8e=a("strong"),LXr=o("flaubert"),yXr=o(" \u2014 "),Ete=a("a"),xXr=o("TFFlaubertWithLMHeadModel"),$Xr=o(" (FlauBERT model)"),kXr=l(),Q5=a("li"),Q8e=a("strong"),SXr=o("funnel"),RXr=o(" \u2014 "),Cte=a("a"),PXr=o("TFFunnelForPreTraining"),BXr=o(" (Funnel Transformer model)"),IXr=l(),W5=a("li"),W8e=a("strong"),NXr=o("gpt2"),qXr=o(" \u2014 "),wte=a("a"),jXr=o("TFGPT2LMHeadModel"),DXr=o(" (OpenAI GPT-2 model)"),GXr=l(),U5=a("li"),U8e=a("strong"),OXr=o("layoutlm"),VXr=o(" \u2014 "),Ate=a("a"),XXr=o("TFLayoutLMForMaskedLM"),zXr=o(" (LayoutLM model)"),QXr=l(),H5=a("li"),H8e=a("strong"),WXr=o("lxmert"),UXr=o(" \u2014 "),Lte=a("a"),HXr=o("TFLxmertForPreTraining"),JXr=o(" (LXMERT model)"),YXr=l(),J5=a("li"),J8e=a("strong"),ZXr=o("mobilebert"),KXr=o(" \u2014 "),yte=a("a"),ezr=o("TFMobileBertForPreTraining"),ozr=o(" (MobileBERT model)"),rzr=l(),Y5=a("li"),Y8e=a("strong"),tzr=o("mpnet"),azr=o(" \u2014 "),xte=a("a"),nzr=o("TFMPNetForMaskedLM"),szr=o(" (MPNet model)"),lzr=l(),Z5=a("li"),Z8e=a("strong"),izr=o("openai-gpt"),dzr=o(" \u2014 "),$te=a("a"),czr=o("TFOpenAIGPTLMHeadModel"),fzr=o(" (OpenAI GPT model)"),mzr=l(),K5=a("li"),K8e=a("strong"),gzr=o("roberta"),hzr=o(" \u2014 "),kte=a("a"),uzr=o("TFRobertaForMaskedLM"),pzr=o(" (RoBERTa model)"),_zr=l(),ew=a("li"),eLe=a("strong"),vzr=o("t5"),bzr=o(" \u2014 "),Ste=a("a"),Fzr=o("TFT5ForConditionalGeneration"),Tzr=o(" (T5 model)"),Mzr=l(),ow=a("li"),oLe=a("strong"),Ezr=o("tapas"),Czr=o(" \u2014 "),Rte=a("a"),wzr=o("TFTapasForMaskedLM"),Azr=o(" (TAPAS model)"),Lzr=l(),rw=a("li"),rLe=a("strong"),yzr=o("transfo-xl"),xzr=o(" \u2014 "),Pte=a("a"),$zr=o("TFTransfoXLLMHeadModel"),kzr=o(" (Transformer-XL model)"),Szr=l(),tw=a("li"),tLe=a("strong"),Rzr=o("vit_mae"),Pzr=o(" \u2014 "),Bte=a("a"),Bzr=o("TFViTMAEForPreTraining"),Izr=o(" (ViTMAE model)"),Nzr=l(),aw=a("li"),aLe=a("strong"),qzr=o("xlm"),jzr=o(" \u2014 "),Ite=a("a"),Dzr=o("TFXLMWithLMHeadModel"),Gzr=o(" (XLM model)"),Ozr=l(),nw=a("li"),nLe=a("strong"),Vzr=o("xlm-roberta"),Xzr=o(" \u2014 "),Nte=a("a"),zzr=o("TFXLMRobertaForMaskedLM"),Qzr=o(" (XLM-RoBERTa model)"),Wzr=l(),sw=a("li"),sLe=a("strong"),Uzr=o("xlnet"),Hzr=o(" \u2014 "),qte=a("a"),Jzr=o("TFXLNetLMHeadModel"),Yzr=o(" (XLNet model)"),Zzr=l(),F(lw.$$.fragment),Xao=l(),_f=a("h2"),iw=a("a"),lLe=a("span"),F(CR.$$.fragment),Kzr=l(),iLe=a("span"),eQr=o("TFAutoModelForCausalLM"),zao=l(),mr=a("div"),F(wR.$$.fragment),oQr=l(),vf=a("p"),rQr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),jte=a("a"),tQr=o("from_pretrained()"),aQr=o(" class method or the "),Dte=a("a"),nQr=o("from_config()"),sQr=o(` class
method.`),lQr=l(),AR=a("p"),iQr=o("This class cannot be instantiated directly using "),dLe=a("code"),dQr=o("__init__()"),cQr=o(" (throws an error)."),fQr=l(),Kt=a("div"),F(LR.$$.fragment),mQr=l(),cLe=a("p"),gQr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),hQr=l(),bf=a("p"),uQr=o(`Note:
Loading a model from its configuration file does `),fLe=a("strong"),pQr=o("not"),_Qr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Gte=a("a"),vQr=o("from_pretrained()"),bQr=o(" to load the model weights."),FQr=l(),F(dw.$$.fragment),TQr=l(),Or=a("div"),F(yR.$$.fragment),MQr=l(),mLe=a("p"),EQr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),CQr=l(),Nn=a("p"),wQr=o("The model class to instantiate is selected based on the "),gLe=a("code"),AQr=o("model_type"),LQr=o(` property of the config object (either
passed as an argument or loaded from `),hLe=a("code"),yQr=o("pretrained_model_name_or_path"),xQr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uLe=a("code"),$Qr=o("pretrained_model_name_or_path"),kQr=o(":"),SQr=l(),Me=a("ul"),cw=a("li"),pLe=a("strong"),RQr=o("bert"),PQr=o(" \u2014 "),Ote=a("a"),BQr=o("TFBertLMHeadModel"),IQr=o(" (BERT model)"),NQr=l(),fw=a("li"),_Le=a("strong"),qQr=o("camembert"),jQr=o(" \u2014 "),Vte=a("a"),DQr=o("TFCamembertForCausalLM"),GQr=o(" (CamemBERT model)"),OQr=l(),mw=a("li"),vLe=a("strong"),VQr=o("ctrl"),XQr=o(" \u2014 "),Xte=a("a"),zQr=o("TFCTRLLMHeadModel"),QQr=o(" (CTRL model)"),WQr=l(),gw=a("li"),bLe=a("strong"),UQr=o("gpt2"),HQr=o(" \u2014 "),zte=a("a"),JQr=o("TFGPT2LMHeadModel"),YQr=o(" (OpenAI GPT-2 model)"),ZQr=l(),hw=a("li"),FLe=a("strong"),KQr=o("gptj"),eWr=o(" \u2014 "),Qte=a("a"),oWr=o("TFGPTJForCausalLM"),rWr=o(" (GPT-J model)"),tWr=l(),uw=a("li"),TLe=a("strong"),aWr=o("openai-gpt"),nWr=o(" \u2014 "),Wte=a("a"),sWr=o("TFOpenAIGPTLMHeadModel"),lWr=o(" (OpenAI GPT model)"),iWr=l(),pw=a("li"),MLe=a("strong"),dWr=o("opt"),cWr=o(" \u2014 "),Ute=a("a"),fWr=o("TFOPTForCausalLM"),mWr=o(" (OPT model)"),gWr=l(),_w=a("li"),ELe=a("strong"),hWr=o("rembert"),uWr=o(" \u2014 "),Hte=a("a"),pWr=o("TFRemBertForCausalLM"),_Wr=o(" (RemBERT model)"),vWr=l(),vw=a("li"),CLe=a("strong"),bWr=o("roberta"),FWr=o(" \u2014 "),Jte=a("a"),TWr=o("TFRobertaForCausalLM"),MWr=o(" (RoBERTa model)"),EWr=l(),bw=a("li"),wLe=a("strong"),CWr=o("roformer"),wWr=o(" \u2014 "),Yte=a("a"),AWr=o("TFRoFormerForCausalLM"),LWr=o(" (RoFormer model)"),yWr=l(),Fw=a("li"),ALe=a("strong"),xWr=o("transfo-xl"),$Wr=o(" \u2014 "),Zte=a("a"),kWr=o("TFTransfoXLLMHeadModel"),SWr=o(" (Transformer-XL model)"),RWr=l(),Tw=a("li"),LLe=a("strong"),PWr=o("xglm"),BWr=o(" \u2014 "),Kte=a("a"),IWr=o("TFXGLMForCausalLM"),NWr=o(" (XGLM model)"),qWr=l(),Mw=a("li"),yLe=a("strong"),jWr=o("xlm"),DWr=o(" \u2014 "),eae=a("a"),GWr=o("TFXLMWithLMHeadModel"),OWr=o(" (XLM model)"),VWr=l(),Ew=a("li"),xLe=a("strong"),XWr=o("xlnet"),zWr=o(" \u2014 "),oae=a("a"),QWr=o("TFXLNetLMHeadModel"),WWr=o(" (XLNet model)"),UWr=l(),F(Cw.$$.fragment),Qao=l(),Ff=a("h2"),ww=a("a"),$Le=a("span"),F(xR.$$.fragment),HWr=l(),kLe=a("span"),JWr=o("TFAutoModelForImageClassification"),Wao=l(),gr=a("div"),F($R.$$.fragment),YWr=l(),Tf=a("p"),ZWr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),rae=a("a"),KWr=o("from_pretrained()"),eUr=o(" class method or the "),tae=a("a"),oUr=o("from_config()"),rUr=o(` class
method.`),tUr=l(),kR=a("p"),aUr=o("This class cannot be instantiated directly using "),SLe=a("code"),nUr=o("__init__()"),sUr=o(" (throws an error)."),lUr=l(),ea=a("div"),F(SR.$$.fragment),iUr=l(),RLe=a("p"),dUr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),cUr=l(),Mf=a("p"),fUr=o(`Note:
Loading a model from its configuration file does `),PLe=a("strong"),mUr=o("not"),gUr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aae=a("a"),hUr=o("from_pretrained()"),uUr=o(" to load the model weights."),pUr=l(),F(Aw.$$.fragment),_Ur=l(),Vr=a("div"),F(RR.$$.fragment),vUr=l(),BLe=a("p"),bUr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),FUr=l(),qn=a("p"),TUr=o("The model class to instantiate is selected based on the "),ILe=a("code"),MUr=o("model_type"),EUr=o(` property of the config object (either
passed as an argument or loaded from `),NLe=a("code"),CUr=o("pretrained_model_name_or_path"),wUr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qLe=a("code"),AUr=o("pretrained_model_name_or_path"),LUr=o(":"),yUr=l(),ye=a("ul"),Lw=a("li"),jLe=a("strong"),xUr=o("convnext"),$Ur=o(" \u2014 "),nae=a("a"),kUr=o("TFConvNextForImageClassification"),SUr=o(" (ConvNeXT model)"),RUr=l(),yw=a("li"),DLe=a("strong"),PUr=o("cvt"),BUr=o(" \u2014 "),sae=a("a"),IUr=o("TFCvtForImageClassification"),NUr=o(" (CvT model)"),qUr=l(),xw=a("li"),GLe=a("strong"),jUr=o("data2vec-vision"),DUr=o(" \u2014 "),lae=a("a"),GUr=o("TFData2VecVisionForImageClassification"),OUr=o(" (Data2VecVision model)"),VUr=l(),Rl=a("li"),OLe=a("strong"),XUr=o("deit"),zUr=o(" \u2014 "),iae=a("a"),QUr=o("TFDeiTForImageClassification"),WUr=o(" or "),dae=a("a"),UUr=o("TFDeiTForImageClassificationWithTeacher"),HUr=o(" (DeiT model)"),JUr=l(),$w=a("li"),VLe=a("strong"),YUr=o("mobilevit"),ZUr=o(" \u2014 "),cae=a("a"),KUr=o("TFMobileViTForImageClassification"),eHr=o(" (MobileViT model)"),oHr=l(),kw=a("li"),XLe=a("strong"),rHr=o("regnet"),tHr=o(" \u2014 "),fae=a("a"),aHr=o("TFRegNetForImageClassification"),nHr=o(" (RegNet model)"),sHr=l(),Sw=a("li"),zLe=a("strong"),lHr=o("resnet"),iHr=o(" \u2014 "),mae=a("a"),dHr=o("TFResNetForImageClassification"),cHr=o(" (ResNet model)"),fHr=l(),Rw=a("li"),QLe=a("strong"),mHr=o("segformer"),gHr=o(" \u2014 "),gae=a("a"),hHr=o("TFSegformerForImageClassification"),uHr=o(" (SegFormer model)"),pHr=l(),Pw=a("li"),WLe=a("strong"),_Hr=o("swin"),vHr=o(" \u2014 "),hae=a("a"),bHr=o("TFSwinForImageClassification"),FHr=o(" (Swin Transformer model)"),THr=l(),Bw=a("li"),ULe=a("strong"),MHr=o("vit"),EHr=o(" \u2014 "),uae=a("a"),CHr=o("TFViTForImageClassification"),wHr=o(" (ViT model)"),AHr=l(),F(Iw.$$.fragment),Uao=l(),Ef=a("h2"),Nw=a("a"),HLe=a("span"),F(PR.$$.fragment),LHr=l(),JLe=a("span"),yHr=o("TFAutoModelForSemanticSegmentation"),Hao=l(),hr=a("div"),F(BR.$$.fragment),xHr=l(),Cf=a("p"),$Hr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),pae=a("a"),kHr=o("from_pretrained()"),SHr=o(" class method or the "),_ae=a("a"),RHr=o("from_config()"),PHr=o(` class
method.`),BHr=l(),IR=a("p"),IHr=o("This class cannot be instantiated directly using "),YLe=a("code"),NHr=o("__init__()"),qHr=o(" (throws an error)."),jHr=l(),oa=a("div"),F(NR.$$.fragment),DHr=l(),ZLe=a("p"),GHr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),OHr=l(),wf=a("p"),VHr=o(`Note:
Loading a model from its configuration file does `),KLe=a("strong"),XHr=o("not"),zHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vae=a("a"),QHr=o("from_pretrained()"),WHr=o(" to load the model weights."),UHr=l(),F(qw.$$.fragment),HHr=l(),Xr=a("div"),F(qR.$$.fragment),JHr=l(),eye=a("p"),YHr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),ZHr=l(),jn=a("p"),KHr=o("The model class to instantiate is selected based on the "),oye=a("code"),eJr=o("model_type"),oJr=o(` property of the config object (either
passed as an argument or loaded from `),rye=a("code"),rJr=o("pretrained_model_name_or_path"),tJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tye=a("code"),aJr=o("pretrained_model_name_or_path"),nJr=o(":"),sJr=l(),Af=a("ul"),jw=a("li"),aye=a("strong"),lJr=o("data2vec-vision"),iJr=o(" \u2014 "),bae=a("a"),dJr=o("TFData2VecVisionForSemanticSegmentation"),cJr=o(" (Data2VecVision model)"),fJr=l(),Dw=a("li"),nye=a("strong"),mJr=o("mobilevit"),gJr=o(" \u2014 "),Fae=a("a"),hJr=o("TFMobileViTForSemanticSegmentation"),uJr=o(" (MobileViT model)"),pJr=l(),Gw=a("li"),sye=a("strong"),_Jr=o("segformer"),vJr=o(" \u2014 "),Tae=a("a"),bJr=o("TFSegformerForSemanticSegmentation"),FJr=o(" (SegFormer model)"),TJr=l(),F(Ow.$$.fragment),Jao=l(),Lf=a("h2"),Vw=a("a"),lye=a("span"),F(jR.$$.fragment),MJr=l(),iye=a("span"),EJr=o("TFAutoModelForMaskedLM"),Yao=l(),ur=a("div"),F(DR.$$.fragment),CJr=l(),yf=a("p"),wJr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Mae=a("a"),AJr=o("from_pretrained()"),LJr=o(" class method or the "),Eae=a("a"),yJr=o("from_config()"),xJr=o(` class
method.`),$Jr=l(),GR=a("p"),kJr=o("This class cannot be instantiated directly using "),dye=a("code"),SJr=o("__init__()"),RJr=o(" (throws an error)."),PJr=l(),ra=a("div"),F(OR.$$.fragment),BJr=l(),cye=a("p"),IJr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),NJr=l(),xf=a("p"),qJr=o(`Note:
Loading a model from its configuration file does `),fye=a("strong"),jJr=o("not"),DJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Cae=a("a"),GJr=o("from_pretrained()"),OJr=o(" to load the model weights."),VJr=l(),F(Xw.$$.fragment),XJr=l(),zr=a("div"),F(VR.$$.fragment),zJr=l(),mye=a("p"),QJr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),WJr=l(),Dn=a("p"),UJr=o("The model class to instantiate is selected based on the "),gye=a("code"),HJr=o("model_type"),JJr=o(` property of the config object (either
passed as an argument or loaded from `),hye=a("code"),YJr=o("pretrained_model_name_or_path"),ZJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uye=a("code"),KJr=o("pretrained_model_name_or_path"),eYr=o(":"),oYr=l(),ce=a("ul"),zw=a("li"),pye=a("strong"),rYr=o("albert"),tYr=o(" \u2014 "),wae=a("a"),aYr=o("TFAlbertForMaskedLM"),nYr=o(" (ALBERT model)"),sYr=l(),Qw=a("li"),_ye=a("strong"),lYr=o("bert"),iYr=o(" \u2014 "),Aae=a("a"),dYr=o("TFBertForMaskedLM"),cYr=o(" (BERT model)"),fYr=l(),Ww=a("li"),vye=a("strong"),mYr=o("camembert"),gYr=o(" \u2014 "),Lae=a("a"),hYr=o("TFCamembertForMaskedLM"),uYr=o(" (CamemBERT model)"),pYr=l(),Uw=a("li"),bye=a("strong"),_Yr=o("convbert"),vYr=o(" \u2014 "),yae=a("a"),bYr=o("TFConvBertForMaskedLM"),FYr=o(" (ConvBERT model)"),TYr=l(),Hw=a("li"),Fye=a("strong"),MYr=o("deberta"),EYr=o(" \u2014 "),xae=a("a"),CYr=o("TFDebertaForMaskedLM"),wYr=o(" (DeBERTa model)"),AYr=l(),Jw=a("li"),Tye=a("strong"),LYr=o("deberta-v2"),yYr=o(" \u2014 "),$ae=a("a"),xYr=o("TFDebertaV2ForMaskedLM"),$Yr=o(" (DeBERTa-v2 model)"),kYr=l(),Yw=a("li"),Mye=a("strong"),SYr=o("distilbert"),RYr=o(" \u2014 "),kae=a("a"),PYr=o("TFDistilBertForMaskedLM"),BYr=o(" (DistilBERT model)"),IYr=l(),Zw=a("li"),Eye=a("strong"),NYr=o("electra"),qYr=o(" \u2014 "),Sae=a("a"),jYr=o("TFElectraForMaskedLM"),DYr=o(" (ELECTRA model)"),GYr=l(),Kw=a("li"),Cye=a("strong"),OYr=o("esm"),VYr=o(" \u2014 "),Rae=a("a"),XYr=o("TFEsmForMaskedLM"),zYr=o(" (ESM model)"),QYr=l(),eA=a("li"),wye=a("strong"),WYr=o("flaubert"),UYr=o(" \u2014 "),Pae=a("a"),HYr=o("TFFlaubertWithLMHeadModel"),JYr=o(" (FlauBERT model)"),YYr=l(),oA=a("li"),Aye=a("strong"),ZYr=o("funnel"),KYr=o(" \u2014 "),Bae=a("a"),eZr=o("TFFunnelForMaskedLM"),oZr=o(" (Funnel Transformer model)"),rZr=l(),rA=a("li"),Lye=a("strong"),tZr=o("layoutlm"),aZr=o(" \u2014 "),Iae=a("a"),nZr=o("TFLayoutLMForMaskedLM"),sZr=o(" (LayoutLM model)"),lZr=l(),tA=a("li"),yye=a("strong"),iZr=o("longformer"),dZr=o(" \u2014 "),Nae=a("a"),cZr=o("TFLongformerForMaskedLM"),fZr=o(" (Longformer model)"),mZr=l(),aA=a("li"),xye=a("strong"),gZr=o("mobilebert"),hZr=o(" \u2014 "),qae=a("a"),uZr=o("TFMobileBertForMaskedLM"),pZr=o(" (MobileBERT model)"),_Zr=l(),nA=a("li"),$ye=a("strong"),vZr=o("mpnet"),bZr=o(" \u2014 "),jae=a("a"),FZr=o("TFMPNetForMaskedLM"),TZr=o(" (MPNet model)"),MZr=l(),sA=a("li"),kye=a("strong"),EZr=o("rembert"),CZr=o(" \u2014 "),Dae=a("a"),wZr=o("TFRemBertForMaskedLM"),AZr=o(" (RemBERT model)"),LZr=l(),lA=a("li"),Sye=a("strong"),yZr=o("roberta"),xZr=o(" \u2014 "),Gae=a("a"),$Zr=o("TFRobertaForMaskedLM"),kZr=o(" (RoBERTa model)"),SZr=l(),iA=a("li"),Rye=a("strong"),RZr=o("roformer"),PZr=o(" \u2014 "),Oae=a("a"),BZr=o("TFRoFormerForMaskedLM"),IZr=o(" (RoFormer model)"),NZr=l(),dA=a("li"),Pye=a("strong"),qZr=o("tapas"),jZr=o(" \u2014 "),Vae=a("a"),DZr=o("TFTapasForMaskedLM"),GZr=o(" (TAPAS model)"),OZr=l(),cA=a("li"),Bye=a("strong"),VZr=o("xlm"),XZr=o(" \u2014 "),Xae=a("a"),zZr=o("TFXLMWithLMHeadModel"),QZr=o(" (XLM model)"),WZr=l(),fA=a("li"),Iye=a("strong"),UZr=o("xlm-roberta"),HZr=o(" \u2014 "),zae=a("a"),JZr=o("TFXLMRobertaForMaskedLM"),YZr=o(" (XLM-RoBERTa model)"),ZZr=l(),F(mA.$$.fragment),Zao=l(),$f=a("h2"),gA=a("a"),Nye=a("span"),F(XR.$$.fragment),KZr=l(),qye=a("span"),eKr=o("TFAutoModelForSeq2SeqLM"),Kao=l(),pr=a("div"),F(zR.$$.fragment),oKr=l(),kf=a("p"),rKr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Qae=a("a"),tKr=o("from_pretrained()"),aKr=o(" class method or the "),Wae=a("a"),nKr=o("from_config()"),sKr=o(` class
method.`),lKr=l(),QR=a("p"),iKr=o("This class cannot be instantiated directly using "),jye=a("code"),dKr=o("__init__()"),cKr=o(" (throws an error)."),fKr=l(),ta=a("div"),F(WR.$$.fragment),mKr=l(),Dye=a("p"),gKr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),hKr=l(),Sf=a("p"),uKr=o(`Note:
Loading a model from its configuration file does `),Gye=a("strong"),pKr=o("not"),_Kr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Uae=a("a"),vKr=o("from_pretrained()"),bKr=o(" to load the model weights."),FKr=l(),F(hA.$$.fragment),TKr=l(),Qr=a("div"),F(UR.$$.fragment),MKr=l(),Oye=a("p"),EKr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),CKr=l(),Gn=a("p"),wKr=o("The model class to instantiate is selected based on the "),Vye=a("code"),AKr=o("model_type"),LKr=o(` property of the config object (either
passed as an argument or loaded from `),Xye=a("code"),yKr=o("pretrained_model_name_or_path"),xKr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zye=a("code"),$Kr=o("pretrained_model_name_or_path"),kKr=o(":"),SKr=l(),xe=a("ul"),uA=a("li"),Qye=a("strong"),RKr=o("bart"),PKr=o(" \u2014 "),Hae=a("a"),BKr=o("TFBartForConditionalGeneration"),IKr=o(" (BART model)"),NKr=l(),pA=a("li"),Wye=a("strong"),qKr=o("blenderbot"),jKr=o(" \u2014 "),Jae=a("a"),DKr=o("TFBlenderbotForConditionalGeneration"),GKr=o(" (Blenderbot model)"),OKr=l(),_A=a("li"),Uye=a("strong"),VKr=o("blenderbot-small"),XKr=o(" \u2014 "),Yae=a("a"),zKr=o("TFBlenderbotSmallForConditionalGeneration"),QKr=o(" (BlenderbotSmall model)"),WKr=l(),vA=a("li"),Hye=a("strong"),UKr=o("encoder-decoder"),HKr=o(" \u2014 "),Zae=a("a"),JKr=o("TFEncoderDecoderModel"),YKr=o(" (Encoder decoder model)"),ZKr=l(),bA=a("li"),Jye=a("strong"),KKr=o("led"),eet=o(" \u2014 "),Kae=a("a"),oet=o("TFLEDForConditionalGeneration"),ret=o(" (LED model)"),tet=l(),FA=a("li"),Yye=a("strong"),aet=o("marian"),net=o(" \u2014 "),ene=a("a"),set=o("TFMarianMTModel"),iet=o(" (Marian model)"),det=l(),TA=a("li"),Zye=a("strong"),cet=o("mbart"),fet=o(" \u2014 "),one=a("a"),met=o("TFMBartForConditionalGeneration"),get=o(" (mBART model)"),het=l(),MA=a("li"),Kye=a("strong"),uet=o("mt5"),pet=o(" \u2014 "),rne=a("a"),_et=o("TFMT5ForConditionalGeneration"),vet=o(" (MT5 model)"),bet=l(),EA=a("li"),e9e=a("strong"),Fet=o("pegasus"),Tet=o(" \u2014 "),tne=a("a"),Met=o("TFPegasusForConditionalGeneration"),Eet=o(" (Pegasus model)"),Cet=l(),CA=a("li"),o9e=a("strong"),wet=o("t5"),Aet=o(" \u2014 "),ane=a("a"),Let=o("TFT5ForConditionalGeneration"),yet=o(" (T5 model)"),xet=l(),F(wA.$$.fragment),eno=l(),Rf=a("h2"),AA=a("a"),r9e=a("span"),F(HR.$$.fragment),$et=l(),t9e=a("span"),ket=o("TFAutoModelForSequenceClassification"),ono=l(),_r=a("div"),F(JR.$$.fragment),Set=l(),Pf=a("p"),Ret=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),nne=a("a"),Pet=o("from_pretrained()"),Bet=o(" class method or the "),sne=a("a"),Iet=o("from_config()"),Net=o(` class
method.`),qet=l(),YR=a("p"),jet=o("This class cannot be instantiated directly using "),a9e=a("code"),Det=o("__init__()"),Get=o(" (throws an error)."),Oet=l(),aa=a("div"),F(ZR.$$.fragment),Vet=l(),n9e=a("p"),Xet=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),zet=l(),Bf=a("p"),Qet=o(`Note:
Loading a model from its configuration file does `),s9e=a("strong"),Wet=o("not"),Uet=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lne=a("a"),Het=o("from_pretrained()"),Jet=o(" to load the model weights."),Yet=l(),F(LA.$$.fragment),Zet=l(),Wr=a("div"),F(KR.$$.fragment),Ket=l(),l9e=a("p"),eot=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),oot=l(),On=a("p"),rot=o("The model class to instantiate is selected based on the "),i9e=a("code"),tot=o("model_type"),aot=o(` property of the config object (either
passed as an argument or loaded from `),d9e=a("code"),not=o("pretrained_model_name_or_path"),sot=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c9e=a("code"),lot=o("pretrained_model_name_or_path"),iot=o(":"),dot=l(),re=a("ul"),yA=a("li"),f9e=a("strong"),cot=o("albert"),fot=o(" \u2014 "),ine=a("a"),mot=o("TFAlbertForSequenceClassification"),got=o(" (ALBERT model)"),hot=l(),xA=a("li"),m9e=a("strong"),uot=o("bert"),pot=o(" \u2014 "),dne=a("a"),_ot=o("TFBertForSequenceClassification"),vot=o(" (BERT model)"),bot=l(),$A=a("li"),g9e=a("strong"),Fot=o("camembert"),Tot=o(" \u2014 "),cne=a("a"),Mot=o("TFCamembertForSequenceClassification"),Eot=o(" (CamemBERT model)"),Cot=l(),kA=a("li"),h9e=a("strong"),wot=o("convbert"),Aot=o(" \u2014 "),fne=a("a"),Lot=o("TFConvBertForSequenceClassification"),yot=o(" (ConvBERT model)"),xot=l(),SA=a("li"),u9e=a("strong"),$ot=o("ctrl"),kot=o(" \u2014 "),mne=a("a"),Sot=o("TFCTRLForSequenceClassification"),Rot=o(" (CTRL model)"),Pot=l(),RA=a("li"),p9e=a("strong"),Bot=o("deberta"),Iot=o(" \u2014 "),gne=a("a"),Not=o("TFDebertaForSequenceClassification"),qot=o(" (DeBERTa model)"),jot=l(),PA=a("li"),_9e=a("strong"),Dot=o("deberta-v2"),Got=o(" \u2014 "),hne=a("a"),Oot=o("TFDebertaV2ForSequenceClassification"),Vot=o(" (DeBERTa-v2 model)"),Xot=l(),BA=a("li"),v9e=a("strong"),zot=o("distilbert"),Qot=o(" \u2014 "),une=a("a"),Wot=o("TFDistilBertForSequenceClassification"),Uot=o(" (DistilBERT model)"),Hot=l(),IA=a("li"),b9e=a("strong"),Jot=o("electra"),Yot=o(" \u2014 "),pne=a("a"),Zot=o("TFElectraForSequenceClassification"),Kot=o(" (ELECTRA model)"),ert=l(),NA=a("li"),F9e=a("strong"),ort=o("esm"),rrt=o(" \u2014 "),_ne=a("a"),trt=o("TFEsmForSequenceClassification"),art=o(" (ESM model)"),nrt=l(),qA=a("li"),T9e=a("strong"),srt=o("flaubert"),lrt=o(" \u2014 "),vne=a("a"),irt=o("TFFlaubertForSequenceClassification"),drt=o(" (FlauBERT model)"),crt=l(),jA=a("li"),M9e=a("strong"),frt=o("funnel"),mrt=o(" \u2014 "),bne=a("a"),grt=o("TFFunnelForSequenceClassification"),hrt=o(" (Funnel Transformer model)"),urt=l(),DA=a("li"),E9e=a("strong"),prt=o("gpt2"),_rt=o(" \u2014 "),Fne=a("a"),vrt=o("TFGPT2ForSequenceClassification"),brt=o(" (OpenAI GPT-2 model)"),Frt=l(),GA=a("li"),C9e=a("strong"),Trt=o("gptj"),Mrt=o(" \u2014 "),Tne=a("a"),Ert=o("TFGPTJForSequenceClassification"),Crt=o(" (GPT-J model)"),wrt=l(),OA=a("li"),w9e=a("strong"),Art=o("layoutlm"),Lrt=o(" \u2014 "),Mne=a("a"),yrt=o("TFLayoutLMForSequenceClassification"),xrt=o(" (LayoutLM model)"),$rt=l(),VA=a("li"),A9e=a("strong"),krt=o("layoutlmv3"),Srt=o(" \u2014 "),Ene=a("a"),Rrt=o("TFLayoutLMv3ForSequenceClassification"),Prt=o(" (LayoutLMv3 model)"),Brt=l(),XA=a("li"),L9e=a("strong"),Irt=o("longformer"),Nrt=o(" \u2014 "),Cne=a("a"),qrt=o("TFLongformerForSequenceClassification"),jrt=o(" (Longformer model)"),Drt=l(),zA=a("li"),y9e=a("strong"),Grt=o("mobilebert"),Ort=o(" \u2014 "),wne=a("a"),Vrt=o("TFMobileBertForSequenceClassification"),Xrt=o(" (MobileBERT model)"),zrt=l(),QA=a("li"),x9e=a("strong"),Qrt=o("mpnet"),Wrt=o(" \u2014 "),Ane=a("a"),Urt=o("TFMPNetForSequenceClassification"),Hrt=o(" (MPNet model)"),Jrt=l(),WA=a("li"),$9e=a("strong"),Yrt=o("openai-gpt"),Zrt=o(" \u2014 "),Lne=a("a"),Krt=o("TFOpenAIGPTForSequenceClassification"),ett=o(" (OpenAI GPT model)"),ott=l(),UA=a("li"),k9e=a("strong"),rtt=o("rembert"),ttt=o(" \u2014 "),yne=a("a"),att=o("TFRemBertForSequenceClassification"),ntt=o(" (RemBERT model)"),stt=l(),HA=a("li"),S9e=a("strong"),ltt=o("roberta"),itt=o(" \u2014 "),xne=a("a"),dtt=o("TFRobertaForSequenceClassification"),ctt=o(" (RoBERTa model)"),ftt=l(),JA=a("li"),R9e=a("strong"),mtt=o("roformer"),gtt=o(" \u2014 "),$ne=a("a"),htt=o("TFRoFormerForSequenceClassification"),utt=o(" (RoFormer model)"),ptt=l(),YA=a("li"),P9e=a("strong"),_tt=o("tapas"),vtt=o(" \u2014 "),kne=a("a"),btt=o("TFTapasForSequenceClassification"),Ftt=o(" (TAPAS model)"),Ttt=l(),ZA=a("li"),B9e=a("strong"),Mtt=o("transfo-xl"),Ett=o(" \u2014 "),Sne=a("a"),Ctt=o("TFTransfoXLForSequenceClassification"),wtt=o(" (Transformer-XL model)"),Att=l(),KA=a("li"),I9e=a("strong"),Ltt=o("xlm"),ytt=o(" \u2014 "),Rne=a("a"),xtt=o("TFXLMForSequenceClassification"),$tt=o(" (XLM model)"),ktt=l(),e6=a("li"),N9e=a("strong"),Stt=o("xlm-roberta"),Rtt=o(" \u2014 "),Pne=a("a"),Ptt=o("TFXLMRobertaForSequenceClassification"),Btt=o(" (XLM-RoBERTa model)"),Itt=l(),o6=a("li"),q9e=a("strong"),Ntt=o("xlnet"),qtt=o(" \u2014 "),Bne=a("a"),jtt=o("TFXLNetForSequenceClassification"),Dtt=o(" (XLNet model)"),Gtt=l(),F(r6.$$.fragment),rno=l(),If=a("h2"),t6=a("a"),j9e=a("span"),F(eP.$$.fragment),Ott=l(),D9e=a("span"),Vtt=o("TFAutoModelForMultipleChoice"),tno=l(),vr=a("div"),F(oP.$$.fragment),Xtt=l(),Nf=a("p"),ztt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Ine=a("a"),Qtt=o("from_pretrained()"),Wtt=o(" class method or the "),Nne=a("a"),Utt=o("from_config()"),Htt=o(` class
method.`),Jtt=l(),rP=a("p"),Ytt=o("This class cannot be instantiated directly using "),G9e=a("code"),Ztt=o("__init__()"),Ktt=o(" (throws an error)."),eat=l(),na=a("div"),F(tP.$$.fragment),oat=l(),O9e=a("p"),rat=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),tat=l(),qf=a("p"),aat=o(`Note:
Loading a model from its configuration file does `),V9e=a("strong"),nat=o("not"),sat=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qne=a("a"),lat=o("from_pretrained()"),iat=o(" to load the model weights."),dat=l(),F(a6.$$.fragment),cat=l(),Ur=a("div"),F(aP.$$.fragment),fat=l(),X9e=a("p"),mat=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),gat=l(),Vn=a("p"),hat=o("The model class to instantiate is selected based on the "),z9e=a("code"),uat=o("model_type"),pat=o(` property of the config object (either
passed as an argument or loaded from `),Q9e=a("code"),_at=o("pretrained_model_name_or_path"),vat=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W9e=a("code"),bat=o("pretrained_model_name_or_path"),Fat=o(":"),Tat=l(),be=a("ul"),n6=a("li"),U9e=a("strong"),Mat=o("albert"),Eat=o(" \u2014 "),jne=a("a"),Cat=o("TFAlbertForMultipleChoice"),wat=o(" (ALBERT model)"),Aat=l(),s6=a("li"),H9e=a("strong"),Lat=o("bert"),yat=o(" \u2014 "),Dne=a("a"),xat=o("TFBertForMultipleChoice"),$at=o(" (BERT model)"),kat=l(),l6=a("li"),J9e=a("strong"),Sat=o("camembert"),Rat=o(" \u2014 "),Gne=a("a"),Pat=o("TFCamembertForMultipleChoice"),Bat=o(" (CamemBERT model)"),Iat=l(),i6=a("li"),Y9e=a("strong"),Nat=o("convbert"),qat=o(" \u2014 "),One=a("a"),jat=o("TFConvBertForMultipleChoice"),Dat=o(" (ConvBERT model)"),Gat=l(),d6=a("li"),Z9e=a("strong"),Oat=o("distilbert"),Vat=o(" \u2014 "),Vne=a("a"),Xat=o("TFDistilBertForMultipleChoice"),zat=o(" (DistilBERT model)"),Qat=l(),c6=a("li"),K9e=a("strong"),Wat=o("electra"),Uat=o(" \u2014 "),Xne=a("a"),Hat=o("TFElectraForMultipleChoice"),Jat=o(" (ELECTRA model)"),Yat=l(),f6=a("li"),exe=a("strong"),Zat=o("flaubert"),Kat=o(" \u2014 "),zne=a("a"),ent=o("TFFlaubertForMultipleChoice"),ont=o(" (FlauBERT model)"),rnt=l(),m6=a("li"),oxe=a("strong"),tnt=o("funnel"),ant=o(" \u2014 "),Qne=a("a"),nnt=o("TFFunnelForMultipleChoice"),snt=o(" (Funnel Transformer model)"),lnt=l(),g6=a("li"),rxe=a("strong"),int=o("longformer"),dnt=o(" \u2014 "),Wne=a("a"),cnt=o("TFLongformerForMultipleChoice"),fnt=o(" (Longformer model)"),mnt=l(),h6=a("li"),txe=a("strong"),gnt=o("mobilebert"),hnt=o(" \u2014 "),Une=a("a"),unt=o("TFMobileBertForMultipleChoice"),pnt=o(" (MobileBERT model)"),_nt=l(),u6=a("li"),axe=a("strong"),vnt=o("mpnet"),bnt=o(" \u2014 "),Hne=a("a"),Fnt=o("TFMPNetForMultipleChoice"),Tnt=o(" (MPNet model)"),Mnt=l(),p6=a("li"),nxe=a("strong"),Ent=o("rembert"),Cnt=o(" \u2014 "),Jne=a("a"),wnt=o("TFRemBertForMultipleChoice"),Ant=o(" (RemBERT model)"),Lnt=l(),_6=a("li"),sxe=a("strong"),ynt=o("roberta"),xnt=o(" \u2014 "),Yne=a("a"),$nt=o("TFRobertaForMultipleChoice"),knt=o(" (RoBERTa model)"),Snt=l(),v6=a("li"),lxe=a("strong"),Rnt=o("roformer"),Pnt=o(" \u2014 "),Zne=a("a"),Bnt=o("TFRoFormerForMultipleChoice"),Int=o(" (RoFormer model)"),Nnt=l(),b6=a("li"),ixe=a("strong"),qnt=o("xlm"),jnt=o(" \u2014 "),Kne=a("a"),Dnt=o("TFXLMForMultipleChoice"),Gnt=o(" (XLM model)"),Ont=l(),F6=a("li"),dxe=a("strong"),Vnt=o("xlm-roberta"),Xnt=o(" \u2014 "),ese=a("a"),znt=o("TFXLMRobertaForMultipleChoice"),Qnt=o(" (XLM-RoBERTa model)"),Wnt=l(),T6=a("li"),cxe=a("strong"),Unt=o("xlnet"),Hnt=o(" \u2014 "),ose=a("a"),Jnt=o("TFXLNetForMultipleChoice"),Ynt=o(" (XLNet model)"),Znt=l(),F(M6.$$.fragment),ano=l(),jf=a("h2"),E6=a("a"),fxe=a("span"),F(nP.$$.fragment),Knt=l(),mxe=a("span"),est=o("TFAutoModelForNextSentencePrediction"),nno=l(),br=a("div"),F(sP.$$.fragment),ost=l(),Df=a("p"),rst=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),rse=a("a"),tst=o("from_pretrained()"),ast=o(" class method or the "),tse=a("a"),nst=o("from_config()"),sst=o(` class
method.`),lst=l(),lP=a("p"),ist=o("This class cannot be instantiated directly using "),gxe=a("code"),dst=o("__init__()"),cst=o(" (throws an error)."),fst=l(),sa=a("div"),F(iP.$$.fragment),mst=l(),hxe=a("p"),gst=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),hst=l(),Gf=a("p"),ust=o(`Note:
Loading a model from its configuration file does `),uxe=a("strong"),pst=o("not"),_st=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ase=a("a"),vst=o("from_pretrained()"),bst=o(" to load the model weights."),Fst=l(),F(C6.$$.fragment),Tst=l(),Hr=a("div"),F(dP.$$.fragment),Mst=l(),pxe=a("p"),Est=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Cst=l(),Xn=a("p"),wst=o("The model class to instantiate is selected based on the "),_xe=a("code"),Ast=o("model_type"),Lst=o(` property of the config object (either
passed as an argument or loaded from `),vxe=a("code"),yst=o("pretrained_model_name_or_path"),xst=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bxe=a("code"),$st=o("pretrained_model_name_or_path"),kst=o(":"),Sst=l(),cP=a("ul"),w6=a("li"),Fxe=a("strong"),Rst=o("bert"),Pst=o(" \u2014 "),nse=a("a"),Bst=o("TFBertForNextSentencePrediction"),Ist=o(" (BERT model)"),Nst=l(),A6=a("li"),Txe=a("strong"),qst=o("mobilebert"),jst=o(" \u2014 "),sse=a("a"),Dst=o("TFMobileBertForNextSentencePrediction"),Gst=o(" (MobileBERT model)"),Ost=l(),F(L6.$$.fragment),sno=l(),Of=a("h2"),y6=a("a"),Mxe=a("span"),F(fP.$$.fragment),Vst=l(),Exe=a("span"),Xst=o("TFAutoModelForTableQuestionAnswering"),lno=l(),Fr=a("div"),F(mP.$$.fragment),zst=l(),Vf=a("p"),Qst=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),lse=a("a"),Wst=o("from_pretrained()"),Ust=o(" class method or the "),ise=a("a"),Hst=o("from_config()"),Jst=o(` class
method.`),Yst=l(),gP=a("p"),Zst=o("This class cannot be instantiated directly using "),Cxe=a("code"),Kst=o("__init__()"),elt=o(" (throws an error)."),olt=l(),la=a("div"),F(hP.$$.fragment),rlt=l(),wxe=a("p"),tlt=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),alt=l(),Xf=a("p"),nlt=o(`Note:
Loading a model from its configuration file does `),Axe=a("strong"),slt=o("not"),llt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dse=a("a"),ilt=o("from_pretrained()"),dlt=o(" to load the model weights."),clt=l(),F(x6.$$.fragment),flt=l(),Jr=a("div"),F(uP.$$.fragment),mlt=l(),Lxe=a("p"),glt=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),hlt=l(),zn=a("p"),ult=o("The model class to instantiate is selected based on the "),yxe=a("code"),plt=o("model_type"),_lt=o(` property of the config object (either
passed as an argument or loaded from `),xxe=a("code"),vlt=o("pretrained_model_name_or_path"),blt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$xe=a("code"),Flt=o("pretrained_model_name_or_path"),Tlt=o(":"),Mlt=l(),kxe=a("ul"),$6=a("li"),Sxe=a("strong"),Elt=o("tapas"),Clt=o(" \u2014 "),cse=a("a"),wlt=o("TFTapasForQuestionAnswering"),Alt=o(" (TAPAS model)"),Llt=l(),F(k6.$$.fragment),ino=l(),zf=a("h2"),S6=a("a"),Rxe=a("span"),F(pP.$$.fragment),ylt=l(),Pxe=a("span"),xlt=o("TFAutoModelForDocumentQuestionAnswering"),dno=l(),Tr=a("div"),F(_P.$$.fragment),$lt=l(),Qf=a("p"),klt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),fse=a("a"),Slt=o("from_pretrained()"),Rlt=o(" class method or the "),mse=a("a"),Plt=o("from_config()"),Blt=o(` class
method.`),Ilt=l(),vP=a("p"),Nlt=o("This class cannot be instantiated directly using "),Bxe=a("code"),qlt=o("__init__()"),jlt=o(" (throws an error)."),Dlt=l(),ia=a("div"),F(bP.$$.fragment),Glt=l(),Ixe=a("p"),Olt=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Vlt=l(),Wf=a("p"),Xlt=o(`Note:
Loading a model from its configuration file does `),Nxe=a("strong"),zlt=o("not"),Qlt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gse=a("a"),Wlt=o("from_pretrained()"),Ult=o(" to load the model weights."),Hlt=l(),F(R6.$$.fragment),Jlt=l(),Yr=a("div"),F(FP.$$.fragment),Ylt=l(),qxe=a("p"),Zlt=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),Klt=l(),Qn=a("p"),eit=o("The model class to instantiate is selected based on the "),jxe=a("code"),oit=o("model_type"),rit=o(` property of the config object (either
passed as an argument or loaded from `),Dxe=a("code"),tit=o("pretrained_model_name_or_path"),ait=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gxe=a("code"),nit=o("pretrained_model_name_or_path"),sit=o(":"),lit=l(),Oxe=a("ul"),P6=a("li"),Vxe=a("strong"),iit=o("layoutlm"),dit=o(" \u2014 "),hse=a("a"),cit=o("TFLayoutLMForQuestionAnswering"),fit=o(" (LayoutLM model)"),mit=l(),F(B6.$$.fragment),cno=l(),Uf=a("h2"),I6=a("a"),Xxe=a("span"),F(TP.$$.fragment),git=l(),zxe=a("span"),hit=o("TFAutoModelForTokenClassification"),fno=l(),Mr=a("div"),F(MP.$$.fragment),uit=l(),Hf=a("p"),pit=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),use=a("a"),_it=o("from_pretrained()"),vit=o(" class method or the "),pse=a("a"),bit=o("from_config()"),Fit=o(` class
method.`),Tit=l(),EP=a("p"),Mit=o("This class cannot be instantiated directly using "),Qxe=a("code"),Eit=o("__init__()"),Cit=o(" (throws an error)."),wit=l(),da=a("div"),F(CP.$$.fragment),Ait=l(),Wxe=a("p"),Lit=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),yit=l(),Jf=a("p"),xit=o(`Note:
Loading a model from its configuration file does `),Uxe=a("strong"),$it=o("not"),kit=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_se=a("a"),Sit=o("from_pretrained()"),Rit=o(" to load the model weights."),Pit=l(),F(N6.$$.fragment),Bit=l(),Zr=a("div"),F(wP.$$.fragment),Iit=l(),Hxe=a("p"),Nit=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),qit=l(),Wn=a("p"),jit=o("The model class to instantiate is selected based on the "),Jxe=a("code"),Dit=o("model_type"),Git=o(` property of the config object (either
passed as an argument or loaded from `),Yxe=a("code"),Oit=o("pretrained_model_name_or_path"),Vit=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zxe=a("code"),Xit=o("pretrained_model_name_or_path"),zit=o(":"),Qit=l(),ie=a("ul"),q6=a("li"),Kxe=a("strong"),Wit=o("albert"),Uit=o(" \u2014 "),vse=a("a"),Hit=o("TFAlbertForTokenClassification"),Jit=o(" (ALBERT model)"),Yit=l(),j6=a("li"),e$e=a("strong"),Zit=o("bert"),Kit=o(" \u2014 "),bse=a("a"),edt=o("TFBertForTokenClassification"),odt=o(" (BERT model)"),rdt=l(),D6=a("li"),o$e=a("strong"),tdt=o("camembert"),adt=o(" \u2014 "),Fse=a("a"),ndt=o("TFCamembertForTokenClassification"),sdt=o(" (CamemBERT model)"),ldt=l(),G6=a("li"),r$e=a("strong"),idt=o("convbert"),ddt=o(" \u2014 "),Tse=a("a"),cdt=o("TFConvBertForTokenClassification"),fdt=o(" (ConvBERT model)"),mdt=l(),O6=a("li"),t$e=a("strong"),gdt=o("deberta"),hdt=o(" \u2014 "),Mse=a("a"),udt=o("TFDebertaForTokenClassification"),pdt=o(" (DeBERTa model)"),_dt=l(),V6=a("li"),a$e=a("strong"),vdt=o("deberta-v2"),bdt=o(" \u2014 "),Ese=a("a"),Fdt=o("TFDebertaV2ForTokenClassification"),Tdt=o(" (DeBERTa-v2 model)"),Mdt=l(),X6=a("li"),n$e=a("strong"),Edt=o("distilbert"),Cdt=o(" \u2014 "),Cse=a("a"),wdt=o("TFDistilBertForTokenClassification"),Adt=o(" (DistilBERT model)"),Ldt=l(),z6=a("li"),s$e=a("strong"),ydt=o("electra"),xdt=o(" \u2014 "),wse=a("a"),$dt=o("TFElectraForTokenClassification"),kdt=o(" (ELECTRA model)"),Sdt=l(),Q6=a("li"),l$e=a("strong"),Rdt=o("esm"),Pdt=o(" \u2014 "),Ase=a("a"),Bdt=o("TFEsmForTokenClassification"),Idt=o(" (ESM model)"),Ndt=l(),W6=a("li"),i$e=a("strong"),qdt=o("flaubert"),jdt=o(" \u2014 "),Lse=a("a"),Ddt=o("TFFlaubertForTokenClassification"),Gdt=o(" (FlauBERT model)"),Odt=l(),U6=a("li"),d$e=a("strong"),Vdt=o("funnel"),Xdt=o(" \u2014 "),yse=a("a"),zdt=o("TFFunnelForTokenClassification"),Qdt=o(" (Funnel Transformer model)"),Wdt=l(),H6=a("li"),c$e=a("strong"),Udt=o("layoutlm"),Hdt=o(" \u2014 "),xse=a("a"),Jdt=o("TFLayoutLMForTokenClassification"),Ydt=o(" (LayoutLM model)"),Zdt=l(),J6=a("li"),f$e=a("strong"),Kdt=o("layoutlmv3"),ect=o(" \u2014 "),$se=a("a"),oct=o("TFLayoutLMv3ForTokenClassification"),rct=o(" (LayoutLMv3 model)"),tct=l(),Y6=a("li"),m$e=a("strong"),act=o("longformer"),nct=o(" \u2014 "),kse=a("a"),sct=o("TFLongformerForTokenClassification"),lct=o(" (Longformer model)"),ict=l(),Z6=a("li"),g$e=a("strong"),dct=o("mobilebert"),cct=o(" \u2014 "),Sse=a("a"),fct=o("TFMobileBertForTokenClassification"),mct=o(" (MobileBERT model)"),gct=l(),K6=a("li"),h$e=a("strong"),hct=o("mpnet"),uct=o(" \u2014 "),Rse=a("a"),pct=o("TFMPNetForTokenClassification"),_ct=o(" (MPNet model)"),vct=l(),e7=a("li"),u$e=a("strong"),bct=o("rembert"),Fct=o(" \u2014 "),Pse=a("a"),Tct=o("TFRemBertForTokenClassification"),Mct=o(" (RemBERT model)"),Ect=l(),o7=a("li"),p$e=a("strong"),Cct=o("roberta"),wct=o(" \u2014 "),Bse=a("a"),Act=o("TFRobertaForTokenClassification"),Lct=o(" (RoBERTa model)"),yct=l(),r7=a("li"),_$e=a("strong"),xct=o("roformer"),$ct=o(" \u2014 "),Ise=a("a"),kct=o("TFRoFormerForTokenClassification"),Sct=o(" (RoFormer model)"),Rct=l(),t7=a("li"),v$e=a("strong"),Pct=o("xlm"),Bct=o(" \u2014 "),Nse=a("a"),Ict=o("TFXLMForTokenClassification"),Nct=o(" (XLM model)"),qct=l(),a7=a("li"),b$e=a("strong"),jct=o("xlm-roberta"),Dct=o(" \u2014 "),qse=a("a"),Gct=o("TFXLMRobertaForTokenClassification"),Oct=o(" (XLM-RoBERTa model)"),Vct=l(),n7=a("li"),F$e=a("strong"),Xct=o("xlnet"),zct=o(" \u2014 "),jse=a("a"),Qct=o("TFXLNetForTokenClassification"),Wct=o(" (XLNet model)"),Uct=l(),F(s7.$$.fragment),mno=l(),Yf=a("h2"),l7=a("a"),T$e=a("span"),F(AP.$$.fragment),Hct=l(),M$e=a("span"),Jct=o("TFAutoModelForQuestionAnswering"),gno=l(),Er=a("div"),F(LP.$$.fragment),Yct=l(),Zf=a("p"),Zct=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Dse=a("a"),Kct=o("from_pretrained()"),eft=o(" class method or the "),Gse=a("a"),oft=o("from_config()"),rft=o(` class
method.`),tft=l(),yP=a("p"),aft=o("This class cannot be instantiated directly using "),E$e=a("code"),nft=o("__init__()"),sft=o(" (throws an error)."),lft=l(),ca=a("div"),F(xP.$$.fragment),ift=l(),C$e=a("p"),dft=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),cft=l(),Kf=a("p"),fft=o(`Note:
Loading a model from its configuration file does `),w$e=a("strong"),mft=o("not"),gft=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ose=a("a"),hft=o("from_pretrained()"),uft=o(" to load the model weights."),pft=l(),F(i7.$$.fragment),_ft=l(),Kr=a("div"),F($P.$$.fragment),vft=l(),A$e=a("p"),bft=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Fft=l(),Un=a("p"),Tft=o("The model class to instantiate is selected based on the "),L$e=a("code"),Mft=o("model_type"),Eft=o(` property of the config object (either
passed as an argument or loaded from `),y$e=a("code"),Cft=o("pretrained_model_name_or_path"),wft=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x$e=a("code"),Aft=o("pretrained_model_name_or_path"),Lft=o(":"),yft=l(),fe=a("ul"),d7=a("li"),$$e=a("strong"),xft=o("albert"),$ft=o(" \u2014 "),Vse=a("a"),kft=o("TFAlbertForQuestionAnswering"),Sft=o(" (ALBERT model)"),Rft=l(),c7=a("li"),k$e=a("strong"),Pft=o("bert"),Bft=o(" \u2014 "),Xse=a("a"),Ift=o("TFBertForQuestionAnswering"),Nft=o(" (BERT model)"),qft=l(),f7=a("li"),S$e=a("strong"),jft=o("camembert"),Dft=o(" \u2014 "),zse=a("a"),Gft=o("TFCamembertForQuestionAnswering"),Oft=o(" (CamemBERT model)"),Vft=l(),m7=a("li"),R$e=a("strong"),Xft=o("convbert"),zft=o(" \u2014 "),Qse=a("a"),Qft=o("TFConvBertForQuestionAnswering"),Wft=o(" (ConvBERT model)"),Uft=l(),g7=a("li"),P$e=a("strong"),Hft=o("deberta"),Jft=o(" \u2014 "),Wse=a("a"),Yft=o("TFDebertaForQuestionAnswering"),Zft=o(" (DeBERTa model)"),Kft=l(),h7=a("li"),B$e=a("strong"),emt=o("deberta-v2"),omt=o(" \u2014 "),Use=a("a"),rmt=o("TFDebertaV2ForQuestionAnswering"),tmt=o(" (DeBERTa-v2 model)"),amt=l(),u7=a("li"),I$e=a("strong"),nmt=o("distilbert"),smt=o(" \u2014 "),Hse=a("a"),lmt=o("TFDistilBertForQuestionAnswering"),imt=o(" (DistilBERT model)"),dmt=l(),p7=a("li"),N$e=a("strong"),cmt=o("electra"),fmt=o(" \u2014 "),Jse=a("a"),mmt=o("TFElectraForQuestionAnswering"),gmt=o(" (ELECTRA model)"),hmt=l(),_7=a("li"),q$e=a("strong"),umt=o("flaubert"),pmt=o(" \u2014 "),Yse=a("a"),_mt=o("TFFlaubertForQuestionAnsweringSimple"),vmt=o(" (FlauBERT model)"),bmt=l(),v7=a("li"),j$e=a("strong"),Fmt=o("funnel"),Tmt=o(" \u2014 "),Zse=a("a"),Mmt=o("TFFunnelForQuestionAnswering"),Emt=o(" (Funnel Transformer model)"),Cmt=l(),b7=a("li"),D$e=a("strong"),wmt=o("gptj"),Amt=o(" \u2014 "),Kse=a("a"),Lmt=o("TFGPTJForQuestionAnswering"),ymt=o(" (GPT-J model)"),xmt=l(),F7=a("li"),G$e=a("strong"),$mt=o("layoutlmv3"),kmt=o(" \u2014 "),ele=a("a"),Smt=o("TFLayoutLMv3ForQuestionAnswering"),Rmt=o(" (LayoutLMv3 model)"),Pmt=l(),T7=a("li"),O$e=a("strong"),Bmt=o("longformer"),Imt=o(" \u2014 "),ole=a("a"),Nmt=o("TFLongformerForQuestionAnswering"),qmt=o(" (Longformer model)"),jmt=l(),M7=a("li"),V$e=a("strong"),Dmt=o("mobilebert"),Gmt=o(" \u2014 "),rle=a("a"),Omt=o("TFMobileBertForQuestionAnswering"),Vmt=o(" (MobileBERT model)"),Xmt=l(),E7=a("li"),X$e=a("strong"),zmt=o("mpnet"),Qmt=o(" \u2014 "),tle=a("a"),Wmt=o("TFMPNetForQuestionAnswering"),Umt=o(" (MPNet model)"),Hmt=l(),C7=a("li"),z$e=a("strong"),Jmt=o("rembert"),Ymt=o(" \u2014 "),ale=a("a"),Zmt=o("TFRemBertForQuestionAnswering"),Kmt=o(" (RemBERT model)"),egt=l(),w7=a("li"),Q$e=a("strong"),ogt=o("roberta"),rgt=o(" \u2014 "),nle=a("a"),tgt=o("TFRobertaForQuestionAnswering"),agt=o(" (RoBERTa model)"),ngt=l(),A7=a("li"),W$e=a("strong"),sgt=o("roformer"),lgt=o(" \u2014 "),sle=a("a"),igt=o("TFRoFormerForQuestionAnswering"),dgt=o(" (RoFormer model)"),cgt=l(),L7=a("li"),U$e=a("strong"),fgt=o("xlm"),mgt=o(" \u2014 "),lle=a("a"),ggt=o("TFXLMForQuestionAnsweringSimple"),hgt=o(" (XLM model)"),ugt=l(),y7=a("li"),H$e=a("strong"),pgt=o("xlm-roberta"),_gt=o(" \u2014 "),ile=a("a"),vgt=o("TFXLMRobertaForQuestionAnswering"),bgt=o(" (XLM-RoBERTa model)"),Fgt=l(),x7=a("li"),J$e=a("strong"),Tgt=o("xlnet"),Mgt=o(" \u2014 "),dle=a("a"),Egt=o("TFXLNetForQuestionAnsweringSimple"),Cgt=o(" (XLNet model)"),wgt=l(),F($7.$$.fragment),hno=l(),em=a("h2"),k7=a("a"),Y$e=a("span"),F(kP.$$.fragment),Agt=l(),Z$e=a("span"),Lgt=o("TFAutoModelForVision2Seq"),uno=l(),Cr=a("div"),F(SP.$$.fragment),ygt=l(),om=a("p"),xgt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),cle=a("a"),$gt=o("from_pretrained()"),kgt=o(" class method or the "),fle=a("a"),Sgt=o("from_config()"),Rgt=o(` class
method.`),Pgt=l(),RP=a("p"),Bgt=o("This class cannot be instantiated directly using "),K$e=a("code"),Igt=o("__init__()"),Ngt=o(" (throws an error)."),qgt=l(),fa=a("div"),F(PP.$$.fragment),jgt=l(),eke=a("p"),Dgt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Ggt=l(),rm=a("p"),Ogt=o(`Note:
Loading a model from its configuration file does `),oke=a("strong"),Vgt=o("not"),Xgt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mle=a("a"),zgt=o("from_pretrained()"),Qgt=o(" to load the model weights."),Wgt=l(),F(S7.$$.fragment),Ugt=l(),et=a("div"),F(BP.$$.fragment),Hgt=l(),rke=a("p"),Jgt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Ygt=l(),Hn=a("p"),Zgt=o("The model class to instantiate is selected based on the "),tke=a("code"),Kgt=o("model_type"),eht=o(` property of the config object (either
passed as an argument or loaded from `),ake=a("code"),oht=o("pretrained_model_name_or_path"),rht=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nke=a("code"),tht=o("pretrained_model_name_or_path"),aht=o(":"),nht=l(),ske=a("ul"),R7=a("li"),lke=a("strong"),sht=o("vision-encoder-decoder"),lht=o(" \u2014 "),gle=a("a"),iht=o("TFVisionEncoderDecoderModel"),dht=o(" (Vision Encoder decoder model)"),cht=l(),F(P7.$$.fragment),pno=l(),tm=a("h2"),B7=a("a"),ike=a("span"),F(IP.$$.fragment),fht=l(),dke=a("span"),mht=o("TFAutoModelForSpeechSeq2Seq"),_no=l(),wr=a("div"),F(NP.$$.fragment),ght=l(),am=a("p"),hht=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),hle=a("a"),uht=o("from_pretrained()"),pht=o(" class method or the "),ule=a("a"),_ht=o("from_config()"),vht=o(` class
method.`),bht=l(),qP=a("p"),Fht=o("This class cannot be instantiated directly using "),cke=a("code"),Tht=o("__init__()"),Mht=o(" (throws an error)."),Eht=l(),ma=a("div"),F(jP.$$.fragment),Cht=l(),fke=a("p"),wht=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Aht=l(),nm=a("p"),Lht=o(`Note:
Loading a model from its configuration file does `),mke=a("strong"),yht=o("not"),xht=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ple=a("a"),$ht=o("from_pretrained()"),kht=o(" to load the model weights."),Sht=l(),F(I7.$$.fragment),Rht=l(),ot=a("div"),F(DP.$$.fragment),Pht=l(),gke=a("p"),Bht=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Iht=l(),Jn=a("p"),Nht=o("The model class to instantiate is selected based on the "),hke=a("code"),qht=o("model_type"),jht=o(` property of the config object (either
passed as an argument or loaded from `),uke=a("code"),Dht=o("pretrained_model_name_or_path"),Ght=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pke=a("code"),Oht=o("pretrained_model_name_or_path"),Vht=o(":"),Xht=l(),GP=a("ul"),N7=a("li"),_ke=a("strong"),zht=o("speech_to_text"),Qht=o(" \u2014 "),_le=a("a"),Wht=o("TFSpeech2TextForConditionalGeneration"),Uht=o(" (Speech2Text model)"),Hht=l(),q7=a("li"),vke=a("strong"),Jht=o("whisper"),Yht=o(" \u2014 "),vle=a("a"),Zht=o("TFWhisperForConditionalGeneration"),Kht=o(" (Whisper model)"),eut=l(),F(j7.$$.fragment),vno=l(),sm=a("h2"),D7=a("a"),bke=a("span"),F(OP.$$.fragment),out=l(),Fke=a("span"),rut=o("FlaxAutoModel"),bno=l(),Ar=a("div"),F(VP.$$.fragment),tut=l(),lm=a("p"),aut=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),ble=a("a"),nut=o("from_pretrained()"),sut=o(" class method or the "),Fle=a("a"),lut=o("from_config()"),iut=o(` class
method.`),dut=l(),XP=a("p"),cut=o("This class cannot be instantiated directly using "),Tke=a("code"),fut=o("__init__()"),mut=o(" (throws an error)."),gut=l(),ga=a("div"),F(zP.$$.fragment),hut=l(),Mke=a("p"),uut=o("Instantiates one of the base model classes of the library from a configuration."),put=l(),im=a("p"),_ut=o(`Note:
Loading a model from its configuration file does `),Eke=a("strong"),vut=o("not"),but=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Tle=a("a"),Fut=o("from_pretrained()"),Tut=o(" to load the model weights."),Mut=l(),F(G7.$$.fragment),Eut=l(),rt=a("div"),F(QP.$$.fragment),Cut=l(),Cke=a("p"),wut=o("Instantiate one of the base model classes of the library from a pretrained model."),Aut=l(),Yn=a("p"),Lut=o("The model class to instantiate is selected based on the "),wke=a("code"),yut=o("model_type"),xut=o(` property of the config object (either
passed as an argument or loaded from `),Ake=a("code"),$ut=o("pretrained_model_name_or_path"),kut=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lke=a("code"),Sut=o("pretrained_model_name_or_path"),Rut=o(":"),Put=l(),te=a("ul"),O7=a("li"),yke=a("strong"),But=o("albert"),Iut=o(" \u2014 "),Mle=a("a"),Nut=o("FlaxAlbertModel"),qut=o(" (ALBERT model)"),jut=l(),V7=a("li"),xke=a("strong"),Dut=o("bart"),Gut=o(" \u2014 "),Ele=a("a"),Out=o("FlaxBartModel"),Vut=o(" (BART model)"),Xut=l(),X7=a("li"),$ke=a("strong"),zut=o("beit"),Qut=o(" \u2014 "),Cle=a("a"),Wut=o("FlaxBeitModel"),Uut=o(" (BEiT model)"),Hut=l(),z7=a("li"),kke=a("strong"),Jut=o("bert"),Yut=o(" \u2014 "),wle=a("a"),Zut=o("FlaxBertModel"),Kut=o(" (BERT model)"),ept=l(),Q7=a("li"),Ske=a("strong"),opt=o("big_bird"),rpt=o(" \u2014 "),Ale=a("a"),tpt=o("FlaxBigBirdModel"),apt=o(" (BigBird model)"),npt=l(),W7=a("li"),Rke=a("strong"),spt=o("blenderbot"),lpt=o(" \u2014 "),Lle=a("a"),ipt=o("FlaxBlenderbotModel"),dpt=o(" (Blenderbot model)"),cpt=l(),U7=a("li"),Pke=a("strong"),fpt=o("blenderbot-small"),mpt=o(" \u2014 "),yle=a("a"),gpt=o("FlaxBlenderbotSmallModel"),hpt=o(" (BlenderbotSmall model)"),upt=l(),H7=a("li"),Bke=a("strong"),ppt=o("clip"),_pt=o(" \u2014 "),xle=a("a"),vpt=o("FlaxCLIPModel"),bpt=o(" (CLIP model)"),Fpt=l(),J7=a("li"),Ike=a("strong"),Tpt=o("distilbert"),Mpt=o(" \u2014 "),$le=a("a"),Ept=o("FlaxDistilBertModel"),Cpt=o(" (DistilBERT model)"),wpt=l(),Y7=a("li"),Nke=a("strong"),Apt=o("electra"),Lpt=o(" \u2014 "),kle=a("a"),ypt=o("FlaxElectraModel"),xpt=o(" (ELECTRA model)"),$pt=l(),Z7=a("li"),qke=a("strong"),kpt=o("gpt2"),Spt=o(" \u2014 "),Sle=a("a"),Rpt=o("FlaxGPT2Model"),Ppt=o(" (OpenAI GPT-2 model)"),Bpt=l(),K7=a("li"),jke=a("strong"),Ipt=o("gpt_neo"),Npt=o(" \u2014 "),Rle=a("a"),qpt=o("FlaxGPTNeoModel"),jpt=o(" (GPT Neo model)"),Dpt=l(),e8=a("li"),Dke=a("strong"),Gpt=o("gptj"),Opt=o(" \u2014 "),Ple=a("a"),Vpt=o("FlaxGPTJModel"),Xpt=o(" (GPT-J model)"),zpt=l(),o8=a("li"),Gke=a("strong"),Qpt=o("longt5"),Wpt=o(" \u2014 "),Ble=a("a"),Upt=o("FlaxLongT5Model"),Hpt=o(" (LongT5 model)"),Jpt=l(),r8=a("li"),Oke=a("strong"),Ypt=o("marian"),Zpt=o(" \u2014 "),Ile=a("a"),Kpt=o("FlaxMarianModel"),e_t=o(" (Marian model)"),o_t=l(),t8=a("li"),Vke=a("strong"),r_t=o("mbart"),t_t=o(" \u2014 "),Nle=a("a"),a_t=o("FlaxMBartModel"),n_t=o(" (mBART model)"),s_t=l(),a8=a("li"),Xke=a("strong"),l_t=o("mt5"),i_t=o(" \u2014 "),qle=a("a"),d_t=o("FlaxMT5Model"),c_t=o(" (MT5 model)"),f_t=l(),n8=a("li"),zke=a("strong"),m_t=o("opt"),g_t=o(" \u2014 "),jle=a("a"),h_t=o("FlaxOPTModel"),u_t=o(" (OPT model)"),p_t=l(),s8=a("li"),Qke=a("strong"),__t=o("pegasus"),v_t=o(" \u2014 "),Dle=a("a"),b_t=o("FlaxPegasusModel"),F_t=o(" (Pegasus model)"),T_t=l(),l8=a("li"),Wke=a("strong"),M_t=o("roberta"),E_t=o(" \u2014 "),Gle=a("a"),C_t=o("FlaxRobertaModel"),w_t=o(" (RoBERTa model)"),A_t=l(),i8=a("li"),Uke=a("strong"),L_t=o("roformer"),y_t=o(" \u2014 "),Ole=a("a"),x_t=o("FlaxRoFormerModel"),$_t=o(" (RoFormer model)"),k_t=l(),d8=a("li"),Hke=a("strong"),S_t=o("t5"),R_t=o(" \u2014 "),Vle=a("a"),P_t=o("FlaxT5Model"),B_t=o(" (T5 model)"),I_t=l(),c8=a("li"),Jke=a("strong"),N_t=o("vision-text-dual-encoder"),q_t=o(" \u2014 "),Xle=a("a"),j_t=o("FlaxVisionTextDualEncoderModel"),D_t=o(" (VisionTextDualEncoder model)"),G_t=l(),f8=a("li"),Yke=a("strong"),O_t=o("vit"),V_t=o(" \u2014 "),zle=a("a"),X_t=o("FlaxViTModel"),z_t=o(" (ViT model)"),Q_t=l(),m8=a("li"),Zke=a("strong"),W_t=o("wav2vec2"),U_t=o(" \u2014 "),Qle=a("a"),H_t=o("FlaxWav2Vec2Model"),J_t=o(" (Wav2Vec2 model)"),Y_t=l(),g8=a("li"),Kke=a("strong"),Z_t=o("xglm"),K_t=o(" \u2014 "),Wle=a("a"),e4t=o("FlaxXGLMModel"),o4t=o(" (XGLM model)"),r4t=l(),h8=a("li"),eSe=a("strong"),t4t=o("xlm-roberta"),a4t=o(" \u2014 "),Ule=a("a"),n4t=o("FlaxXLMRobertaModel"),s4t=o(" (XLM-RoBERTa model)"),l4t=l(),F(u8.$$.fragment),Fno=l(),dm=a("h2"),p8=a("a"),oSe=a("span"),F(WP.$$.fragment),i4t=l(),rSe=a("span"),d4t=o("FlaxAutoModelForCausalLM"),Tno=l(),Lr=a("div"),F(UP.$$.fragment),c4t=l(),cm=a("p"),f4t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Hle=a("a"),m4t=o("from_pretrained()"),g4t=o(" class method or the "),Jle=a("a"),h4t=o("from_config()"),u4t=o(` class
method.`),p4t=l(),HP=a("p"),_4t=o("This class cannot be instantiated directly using "),tSe=a("code"),v4t=o("__init__()"),b4t=o(" (throws an error)."),F4t=l(),ha=a("div"),F(JP.$$.fragment),T4t=l(),aSe=a("p"),M4t=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),E4t=l(),fm=a("p"),C4t=o(`Note:
Loading a model from its configuration file does `),nSe=a("strong"),w4t=o("not"),A4t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Yle=a("a"),L4t=o("from_pretrained()"),y4t=o(" to load the model weights."),x4t=l(),F(_8.$$.fragment),$4t=l(),tt=a("div"),F(YP.$$.fragment),k4t=l(),sSe=a("p"),S4t=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),R4t=l(),Zn=a("p"),P4t=o("The model class to instantiate is selected based on the "),lSe=a("code"),B4t=o("model_type"),I4t=o(` property of the config object (either
passed as an argument or loaded from `),iSe=a("code"),N4t=o("pretrained_model_name_or_path"),q4t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dSe=a("code"),j4t=o("pretrained_model_name_or_path"),D4t=o(":"),G4t=l(),$e=a("ul"),v8=a("li"),cSe=a("strong"),O4t=o("bart"),V4t=o(" \u2014 "),Zle=a("a"),X4t=o("FlaxBartForCausalLM"),z4t=o(" (BART model)"),Q4t=l(),b8=a("li"),fSe=a("strong"),W4t=o("bert"),U4t=o(" \u2014 "),Kle=a("a"),H4t=o("FlaxBertForCausalLM"),J4t=o(" (BERT model)"),Y4t=l(),F8=a("li"),mSe=a("strong"),Z4t=o("big_bird"),K4t=o(" \u2014 "),eie=a("a"),e2t=o("FlaxBigBirdForCausalLM"),o2t=o(" (BigBird model)"),r2t=l(),T8=a("li"),gSe=a("strong"),t2t=o("electra"),a2t=o(" \u2014 "),oie=a("a"),n2t=o("FlaxElectraForCausalLM"),s2t=o(" (ELECTRA model)"),l2t=l(),M8=a("li"),hSe=a("strong"),i2t=o("gpt2"),d2t=o(" \u2014 "),rie=a("a"),c2t=o("FlaxGPT2LMHeadModel"),f2t=o(" (OpenAI GPT-2 model)"),m2t=l(),E8=a("li"),uSe=a("strong"),g2t=o("gpt_neo"),h2t=o(" \u2014 "),tie=a("a"),u2t=o("FlaxGPTNeoForCausalLM"),p2t=o(" (GPT Neo model)"),_2t=l(),C8=a("li"),pSe=a("strong"),v2t=o("gptj"),b2t=o(" \u2014 "),aie=a("a"),F2t=o("FlaxGPTJForCausalLM"),T2t=o(" (GPT-J model)"),M2t=l(),w8=a("li"),_Se=a("strong"),E2t=o("opt"),C2t=o(" \u2014 "),nie=a("a"),w2t=o("FlaxOPTForCausalLM"),A2t=o(" (OPT model)"),L2t=l(),A8=a("li"),vSe=a("strong"),y2t=o("roberta"),x2t=o(" \u2014 "),sie=a("a"),$2t=o("FlaxRobertaForCausalLM"),k2t=o(" (RoBERTa model)"),S2t=l(),L8=a("li"),bSe=a("strong"),R2t=o("xglm"),P2t=o(" \u2014 "),lie=a("a"),B2t=o("FlaxXGLMForCausalLM"),I2t=o(" (XGLM model)"),N2t=l(),F(y8.$$.fragment),Mno=l(),mm=a("h2"),x8=a("a"),FSe=a("span"),F(ZP.$$.fragment),q2t=l(),TSe=a("span"),j2t=o("FlaxAutoModelForPreTraining"),Eno=l(),yr=a("div"),F(KP.$$.fragment),D2t=l(),gm=a("p"),G2t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),iie=a("a"),O2t=o("from_pretrained()"),V2t=o(" class method or the "),die=a("a"),X2t=o("from_config()"),z2t=o(` class
method.`),Q2t=l(),eB=a("p"),W2t=o("This class cannot be instantiated directly using "),MSe=a("code"),U2t=o("__init__()"),H2t=o(" (throws an error)."),J2t=l(),ua=a("div"),F(oB.$$.fragment),Y2t=l(),ESe=a("p"),Z2t=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),K2t=l(),hm=a("p"),evt=o(`Note:
Loading a model from its configuration file does `),CSe=a("strong"),ovt=o("not"),rvt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cie=a("a"),tvt=o("from_pretrained()"),avt=o(" to load the model weights."),nvt=l(),F($8.$$.fragment),svt=l(),at=a("div"),F(rB.$$.fragment),lvt=l(),wSe=a("p"),ivt=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),dvt=l(),Kn=a("p"),cvt=o("The model class to instantiate is selected based on the "),ASe=a("code"),fvt=o("model_type"),mvt=o(` property of the config object (either
passed as an argument or loaded from `),LSe=a("code"),gvt=o("pretrained_model_name_or_path"),hvt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ySe=a("code"),uvt=o("pretrained_model_name_or_path"),pvt=o(":"),_vt=l(),Ee=a("ul"),k8=a("li"),xSe=a("strong"),vvt=o("albert"),bvt=o(" \u2014 "),fie=a("a"),Fvt=o("FlaxAlbertForPreTraining"),Tvt=o(" (ALBERT model)"),Mvt=l(),S8=a("li"),$Se=a("strong"),Evt=o("bart"),Cvt=o(" \u2014 "),mie=a("a"),wvt=o("FlaxBartForConditionalGeneration"),Avt=o(" (BART model)"),Lvt=l(),R8=a("li"),kSe=a("strong"),yvt=o("bert"),xvt=o(" \u2014 "),gie=a("a"),$vt=o("FlaxBertForPreTraining"),kvt=o(" (BERT model)"),Svt=l(),P8=a("li"),SSe=a("strong"),Rvt=o("big_bird"),Pvt=o(" \u2014 "),hie=a("a"),Bvt=o("FlaxBigBirdForPreTraining"),Ivt=o(" (BigBird model)"),Nvt=l(),B8=a("li"),RSe=a("strong"),qvt=o("electra"),jvt=o(" \u2014 "),uie=a("a"),Dvt=o("FlaxElectraForPreTraining"),Gvt=o(" (ELECTRA model)"),Ovt=l(),I8=a("li"),PSe=a("strong"),Vvt=o("longt5"),Xvt=o(" \u2014 "),pie=a("a"),zvt=o("FlaxLongT5ForConditionalGeneration"),Qvt=o(" (LongT5 model)"),Wvt=l(),N8=a("li"),BSe=a("strong"),Uvt=o("mbart"),Hvt=o(" \u2014 "),_ie=a("a"),Jvt=o("FlaxMBartForConditionalGeneration"),Yvt=o(" (mBART model)"),Zvt=l(),q8=a("li"),ISe=a("strong"),Kvt=o("mt5"),e1t=o(" \u2014 "),vie=a("a"),o1t=o("FlaxMT5ForConditionalGeneration"),r1t=o(" (MT5 model)"),t1t=l(),j8=a("li"),NSe=a("strong"),a1t=o("roberta"),n1t=o(" \u2014 "),bie=a("a"),s1t=o("FlaxRobertaForMaskedLM"),l1t=o(" (RoBERTa model)"),i1t=l(),D8=a("li"),qSe=a("strong"),d1t=o("roformer"),c1t=o(" \u2014 "),Fie=a("a"),f1t=o("FlaxRoFormerForMaskedLM"),m1t=o(" (RoFormer model)"),g1t=l(),G8=a("li"),jSe=a("strong"),h1t=o("t5"),u1t=o(" \u2014 "),Tie=a("a"),p1t=o("FlaxT5ForConditionalGeneration"),_1t=o(" (T5 model)"),v1t=l(),O8=a("li"),DSe=a("strong"),b1t=o("wav2vec2"),F1t=o(" \u2014 "),Mie=a("a"),T1t=o("FlaxWav2Vec2ForPreTraining"),M1t=o(" (Wav2Vec2 model)"),E1t=l(),V8=a("li"),GSe=a("strong"),C1t=o("xlm-roberta"),w1t=o(" \u2014 "),Eie=a("a"),A1t=o("FlaxXLMRobertaForMaskedLM"),L1t=o(" (XLM-RoBERTa model)"),y1t=l(),F(X8.$$.fragment),Cno=l(),um=a("h2"),z8=a("a"),OSe=a("span"),F(tB.$$.fragment),x1t=l(),VSe=a("span"),$1t=o("FlaxAutoModelForMaskedLM"),wno=l(),xr=a("div"),F(aB.$$.fragment),k1t=l(),pm=a("p"),S1t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Cie=a("a"),R1t=o("from_pretrained()"),P1t=o(" class method or the "),wie=a("a"),B1t=o("from_config()"),I1t=o(` class
method.`),N1t=l(),nB=a("p"),q1t=o("This class cannot be instantiated directly using "),XSe=a("code"),j1t=o("__init__()"),D1t=o(" (throws an error)."),G1t=l(),pa=a("div"),F(sB.$$.fragment),O1t=l(),zSe=a("p"),V1t=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),X1t=l(),_m=a("p"),z1t=o(`Note:
Loading a model from its configuration file does `),QSe=a("strong"),Q1t=o("not"),W1t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Aie=a("a"),U1t=o("from_pretrained()"),H1t=o(" to load the model weights."),J1t=l(),F(Q8.$$.fragment),Y1t=l(),nt=a("div"),F(lB.$$.fragment),Z1t=l(),WSe=a("p"),K1t=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),ebt=l(),es=a("p"),obt=o("The model class to instantiate is selected based on the "),USe=a("code"),rbt=o("model_type"),tbt=o(` property of the config object (either
passed as an argument or loaded from `),HSe=a("code"),abt=o("pretrained_model_name_or_path"),nbt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JSe=a("code"),sbt=o("pretrained_model_name_or_path"),lbt=o(":"),ibt=l(),ke=a("ul"),W8=a("li"),YSe=a("strong"),dbt=o("albert"),cbt=o(" \u2014 "),Lie=a("a"),fbt=o("FlaxAlbertForMaskedLM"),mbt=o(" (ALBERT model)"),gbt=l(),U8=a("li"),ZSe=a("strong"),hbt=o("bart"),ubt=o(" \u2014 "),yie=a("a"),pbt=o("FlaxBartForConditionalGeneration"),_bt=o(" (BART model)"),vbt=l(),H8=a("li"),KSe=a("strong"),bbt=o("bert"),Fbt=o(" \u2014 "),xie=a("a"),Tbt=o("FlaxBertForMaskedLM"),Mbt=o(" (BERT model)"),Ebt=l(),J8=a("li"),eRe=a("strong"),Cbt=o("big_bird"),wbt=o(" \u2014 "),$ie=a("a"),Abt=o("FlaxBigBirdForMaskedLM"),Lbt=o(" (BigBird model)"),ybt=l(),Y8=a("li"),oRe=a("strong"),xbt=o("distilbert"),$bt=o(" \u2014 "),kie=a("a"),kbt=o("FlaxDistilBertForMaskedLM"),Sbt=o(" (DistilBERT model)"),Rbt=l(),Z8=a("li"),rRe=a("strong"),Pbt=o("electra"),Bbt=o(" \u2014 "),Sie=a("a"),Ibt=o("FlaxElectraForMaskedLM"),Nbt=o(" (ELECTRA model)"),qbt=l(),K8=a("li"),tRe=a("strong"),jbt=o("mbart"),Dbt=o(" \u2014 "),Rie=a("a"),Gbt=o("FlaxMBartForConditionalGeneration"),Obt=o(" (mBART model)"),Vbt=l(),eL=a("li"),aRe=a("strong"),Xbt=o("roberta"),zbt=o(" \u2014 "),Pie=a("a"),Qbt=o("FlaxRobertaForMaskedLM"),Wbt=o(" (RoBERTa model)"),Ubt=l(),oL=a("li"),nRe=a("strong"),Hbt=o("roformer"),Jbt=o(" \u2014 "),Bie=a("a"),Ybt=o("FlaxRoFormerForMaskedLM"),Zbt=o(" (RoFormer model)"),Kbt=l(),rL=a("li"),sRe=a("strong"),e0t=o("xlm-roberta"),o0t=o(" \u2014 "),Iie=a("a"),r0t=o("FlaxXLMRobertaForMaskedLM"),t0t=o(" (XLM-RoBERTa model)"),a0t=l(),F(tL.$$.fragment),Ano=l(),vm=a("h2"),aL=a("a"),lRe=a("span"),F(iB.$$.fragment),n0t=l(),iRe=a("span"),s0t=o("FlaxAutoModelForSeq2SeqLM"),Lno=l(),$r=a("div"),F(dB.$$.fragment),l0t=l(),bm=a("p"),i0t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Nie=a("a"),d0t=o("from_pretrained()"),c0t=o(" class method or the "),qie=a("a"),f0t=o("from_config()"),m0t=o(` class
method.`),g0t=l(),cB=a("p"),h0t=o("This class cannot be instantiated directly using "),dRe=a("code"),u0t=o("__init__()"),p0t=o(" (throws an error)."),_0t=l(),_a=a("div"),F(fB.$$.fragment),v0t=l(),cRe=a("p"),b0t=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),F0t=l(),Fm=a("p"),T0t=o(`Note:
Loading a model from its configuration file does `),fRe=a("strong"),M0t=o("not"),E0t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jie=a("a"),C0t=o("from_pretrained()"),w0t=o(" to load the model weights."),A0t=l(),F(nL.$$.fragment),L0t=l(),st=a("div"),F(mB.$$.fragment),y0t=l(),mRe=a("p"),x0t=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),$0t=l(),os=a("p"),k0t=o("The model class to instantiate is selected based on the "),gRe=a("code"),S0t=o("model_type"),R0t=o(` property of the config object (either
passed as an argument or loaded from `),hRe=a("code"),P0t=o("pretrained_model_name_or_path"),B0t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uRe=a("code"),I0t=o("pretrained_model_name_or_path"),N0t=o(":"),q0t=l(),Se=a("ul"),sL=a("li"),pRe=a("strong"),j0t=o("bart"),D0t=o(" \u2014 "),Die=a("a"),G0t=o("FlaxBartForConditionalGeneration"),O0t=o(" (BART model)"),V0t=l(),lL=a("li"),_Re=a("strong"),X0t=o("blenderbot"),z0t=o(" \u2014 "),Gie=a("a"),Q0t=o("FlaxBlenderbotForConditionalGeneration"),W0t=o(" (Blenderbot model)"),U0t=l(),iL=a("li"),vRe=a("strong"),H0t=o("blenderbot-small"),J0t=o(" \u2014 "),Oie=a("a"),Y0t=o("FlaxBlenderbotSmallForConditionalGeneration"),Z0t=o(" (BlenderbotSmall model)"),K0t=l(),dL=a("li"),bRe=a("strong"),eFt=o("encoder-decoder"),oFt=o(" \u2014 "),Vie=a("a"),rFt=o("FlaxEncoderDecoderModel"),tFt=o(" (Encoder decoder model)"),aFt=l(),cL=a("li"),FRe=a("strong"),nFt=o("longt5"),sFt=o(" \u2014 "),Xie=a("a"),lFt=o("FlaxLongT5ForConditionalGeneration"),iFt=o(" (LongT5 model)"),dFt=l(),fL=a("li"),TRe=a("strong"),cFt=o("marian"),fFt=o(" \u2014 "),zie=a("a"),mFt=o("FlaxMarianMTModel"),gFt=o(" (Marian model)"),hFt=l(),mL=a("li"),MRe=a("strong"),uFt=o("mbart"),pFt=o(" \u2014 "),Qie=a("a"),_Ft=o("FlaxMBartForConditionalGeneration"),vFt=o(" (mBART model)"),bFt=l(),gL=a("li"),ERe=a("strong"),FFt=o("mt5"),TFt=o(" \u2014 "),Wie=a("a"),MFt=o("FlaxMT5ForConditionalGeneration"),EFt=o(" (MT5 model)"),CFt=l(),hL=a("li"),CRe=a("strong"),wFt=o("pegasus"),AFt=o(" \u2014 "),Uie=a("a"),LFt=o("FlaxPegasusForConditionalGeneration"),yFt=o(" (Pegasus model)"),xFt=l(),uL=a("li"),wRe=a("strong"),$Ft=o("t5"),kFt=o(" \u2014 "),Hie=a("a"),SFt=o("FlaxT5ForConditionalGeneration"),RFt=o(" (T5 model)"),PFt=l(),F(pL.$$.fragment),yno=l(),Tm=a("h2"),_L=a("a"),ARe=a("span"),F(gB.$$.fragment),BFt=l(),LRe=a("span"),IFt=o("FlaxAutoModelForSequenceClassification"),xno=l(),kr=a("div"),F(hB.$$.fragment),NFt=l(),Mm=a("p"),qFt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Jie=a("a"),jFt=o("from_pretrained()"),DFt=o(" class method or the "),Yie=a("a"),GFt=o("from_config()"),OFt=o(` class
method.`),VFt=l(),uB=a("p"),XFt=o("This class cannot be instantiated directly using "),yRe=a("code"),zFt=o("__init__()"),QFt=o(" (throws an error)."),WFt=l(),va=a("div"),F(pB.$$.fragment),UFt=l(),xRe=a("p"),HFt=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),JFt=l(),Em=a("p"),YFt=o(`Note:
Loading a model from its configuration file does `),$Re=a("strong"),ZFt=o("not"),KFt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zie=a("a"),eTt=o("from_pretrained()"),oTt=o(" to load the model weights."),rTt=l(),F(vL.$$.fragment),tTt=l(),lt=a("div"),F(_B.$$.fragment),aTt=l(),kRe=a("p"),nTt=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),sTt=l(),rs=a("p"),lTt=o("The model class to instantiate is selected based on the "),SRe=a("code"),iTt=o("model_type"),dTt=o(` property of the config object (either
passed as an argument or loaded from `),RRe=a("code"),cTt=o("pretrained_model_name_or_path"),fTt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),PRe=a("code"),mTt=o("pretrained_model_name_or_path"),gTt=o(":"),hTt=l(),Re=a("ul"),bL=a("li"),BRe=a("strong"),uTt=o("albert"),pTt=o(" \u2014 "),Kie=a("a"),_Tt=o("FlaxAlbertForSequenceClassification"),vTt=o(" (ALBERT model)"),bTt=l(),FL=a("li"),IRe=a("strong"),FTt=o("bart"),TTt=o(" \u2014 "),ede=a("a"),MTt=o("FlaxBartForSequenceClassification"),ETt=o(" (BART model)"),CTt=l(),TL=a("li"),NRe=a("strong"),wTt=o("bert"),ATt=o(" \u2014 "),ode=a("a"),LTt=o("FlaxBertForSequenceClassification"),yTt=o(" (BERT model)"),xTt=l(),ML=a("li"),qRe=a("strong"),$Tt=o("big_bird"),kTt=o(" \u2014 "),rde=a("a"),STt=o("FlaxBigBirdForSequenceClassification"),RTt=o(" (BigBird model)"),PTt=l(),EL=a("li"),jRe=a("strong"),BTt=o("distilbert"),ITt=o(" \u2014 "),tde=a("a"),NTt=o("FlaxDistilBertForSequenceClassification"),qTt=o(" (DistilBERT model)"),jTt=l(),CL=a("li"),DRe=a("strong"),DTt=o("electra"),GTt=o(" \u2014 "),ade=a("a"),OTt=o("FlaxElectraForSequenceClassification"),VTt=o(" (ELECTRA model)"),XTt=l(),wL=a("li"),GRe=a("strong"),zTt=o("mbart"),QTt=o(" \u2014 "),nde=a("a"),WTt=o("FlaxMBartForSequenceClassification"),UTt=o(" (mBART model)"),HTt=l(),AL=a("li"),ORe=a("strong"),JTt=o("roberta"),YTt=o(" \u2014 "),sde=a("a"),ZTt=o("FlaxRobertaForSequenceClassification"),KTt=o(" (RoBERTa model)"),eMt=l(),LL=a("li"),VRe=a("strong"),oMt=o("roformer"),rMt=o(" \u2014 "),lde=a("a"),tMt=o("FlaxRoFormerForSequenceClassification"),aMt=o(" (RoFormer model)"),nMt=l(),yL=a("li"),XRe=a("strong"),sMt=o("xlm-roberta"),lMt=o(" \u2014 "),ide=a("a"),iMt=o("FlaxXLMRobertaForSequenceClassification"),dMt=o(" (XLM-RoBERTa model)"),cMt=l(),F(xL.$$.fragment),$no=l(),Cm=a("h2"),$L=a("a"),zRe=a("span"),F(vB.$$.fragment),fMt=l(),QRe=a("span"),mMt=o("FlaxAutoModelForQuestionAnswering"),kno=l(),Sr=a("div"),F(bB.$$.fragment),gMt=l(),wm=a("p"),hMt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),dde=a("a"),uMt=o("from_pretrained()"),pMt=o(" class method or the "),cde=a("a"),_Mt=o("from_config()"),vMt=o(` class
method.`),bMt=l(),FB=a("p"),FMt=o("This class cannot be instantiated directly using "),WRe=a("code"),TMt=o("__init__()"),MMt=o(" (throws an error)."),EMt=l(),ba=a("div"),F(TB.$$.fragment),CMt=l(),URe=a("p"),wMt=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),AMt=l(),Am=a("p"),LMt=o(`Note:
Loading a model from its configuration file does `),HRe=a("strong"),yMt=o("not"),xMt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fde=a("a"),$Mt=o("from_pretrained()"),kMt=o(" to load the model weights."),SMt=l(),F(kL.$$.fragment),RMt=l(),it=a("div"),F(MB.$$.fragment),PMt=l(),JRe=a("p"),BMt=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),IMt=l(),ts=a("p"),NMt=o("The model class to instantiate is selected based on the "),YRe=a("code"),qMt=o("model_type"),jMt=o(` property of the config object (either
passed as an argument or loaded from `),ZRe=a("code"),DMt=o("pretrained_model_name_or_path"),GMt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KRe=a("code"),OMt=o("pretrained_model_name_or_path"),VMt=o(":"),XMt=l(),Pe=a("ul"),SL=a("li"),ePe=a("strong"),zMt=o("albert"),QMt=o(" \u2014 "),mde=a("a"),WMt=o("FlaxAlbertForQuestionAnswering"),UMt=o(" (ALBERT model)"),HMt=l(),RL=a("li"),oPe=a("strong"),JMt=o("bart"),YMt=o(" \u2014 "),gde=a("a"),ZMt=o("FlaxBartForQuestionAnswering"),KMt=o(" (BART model)"),eEt=l(),PL=a("li"),rPe=a("strong"),oEt=o("bert"),rEt=o(" \u2014 "),hde=a("a"),tEt=o("FlaxBertForQuestionAnswering"),aEt=o(" (BERT model)"),nEt=l(),BL=a("li"),tPe=a("strong"),sEt=o("big_bird"),lEt=o(" \u2014 "),ude=a("a"),iEt=o("FlaxBigBirdForQuestionAnswering"),dEt=o(" (BigBird model)"),cEt=l(),IL=a("li"),aPe=a("strong"),fEt=o("distilbert"),mEt=o(" \u2014 "),pde=a("a"),gEt=o("FlaxDistilBertForQuestionAnswering"),hEt=o(" (DistilBERT model)"),uEt=l(),NL=a("li"),nPe=a("strong"),pEt=o("electra"),_Et=o(" \u2014 "),_de=a("a"),vEt=o("FlaxElectraForQuestionAnswering"),bEt=o(" (ELECTRA model)"),FEt=l(),qL=a("li"),sPe=a("strong"),TEt=o("mbart"),MEt=o(" \u2014 "),vde=a("a"),EEt=o("FlaxMBartForQuestionAnswering"),CEt=o(" (mBART model)"),wEt=l(),jL=a("li"),lPe=a("strong"),AEt=o("roberta"),LEt=o(" \u2014 "),bde=a("a"),yEt=o("FlaxRobertaForQuestionAnswering"),xEt=o(" (RoBERTa model)"),$Et=l(),DL=a("li"),iPe=a("strong"),kEt=o("roformer"),SEt=o(" \u2014 "),Fde=a("a"),REt=o("FlaxRoFormerForQuestionAnswering"),PEt=o(" (RoFormer model)"),BEt=l(),GL=a("li"),dPe=a("strong"),IEt=o("xlm-roberta"),NEt=o(" \u2014 "),Tde=a("a"),qEt=o("FlaxXLMRobertaForQuestionAnswering"),jEt=o(" (XLM-RoBERTa model)"),DEt=l(),F(OL.$$.fragment),Sno=l(),Lm=a("h2"),VL=a("a"),cPe=a("span"),F(EB.$$.fragment),GEt=l(),fPe=a("span"),OEt=o("FlaxAutoModelForTokenClassification"),Rno=l(),Rr=a("div"),F(CB.$$.fragment),VEt=l(),ym=a("p"),XEt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Mde=a("a"),zEt=o("from_pretrained()"),QEt=o(" class method or the "),Ede=a("a"),WEt=o("from_config()"),UEt=o(` class
method.`),HEt=l(),wB=a("p"),JEt=o("This class cannot be instantiated directly using "),mPe=a("code"),YEt=o("__init__()"),ZEt=o(" (throws an error)."),KEt=l(),Fa=a("div"),F(AB.$$.fragment),eCt=l(),gPe=a("p"),oCt=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),rCt=l(),xm=a("p"),tCt=o(`Note:
Loading a model from its configuration file does `),hPe=a("strong"),aCt=o("not"),nCt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Cde=a("a"),sCt=o("from_pretrained()"),lCt=o(" to load the model weights."),iCt=l(),F(XL.$$.fragment),dCt=l(),dt=a("div"),F(LB.$$.fragment),cCt=l(),uPe=a("p"),fCt=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),mCt=l(),as=a("p"),gCt=o("The model class to instantiate is selected based on the "),pPe=a("code"),hCt=o("model_type"),uCt=o(` property of the config object (either
passed as an argument or loaded from `),_Pe=a("code"),pCt=o("pretrained_model_name_or_path"),_Ct=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vPe=a("code"),vCt=o("pretrained_model_name_or_path"),bCt=o(":"),FCt=l(),ze=a("ul"),zL=a("li"),bPe=a("strong"),TCt=o("albert"),MCt=o(" \u2014 "),wde=a("a"),ECt=o("FlaxAlbertForTokenClassification"),CCt=o(" (ALBERT model)"),wCt=l(),QL=a("li"),FPe=a("strong"),ACt=o("bert"),LCt=o(" \u2014 "),Ade=a("a"),yCt=o("FlaxBertForTokenClassification"),xCt=o(" (BERT model)"),$Ct=l(),WL=a("li"),TPe=a("strong"),kCt=o("big_bird"),SCt=o(" \u2014 "),Lde=a("a"),RCt=o("FlaxBigBirdForTokenClassification"),PCt=o(" (BigBird model)"),BCt=l(),UL=a("li"),MPe=a("strong"),ICt=o("distilbert"),NCt=o(" \u2014 "),yde=a("a"),qCt=o("FlaxDistilBertForTokenClassification"),jCt=o(" (DistilBERT model)"),DCt=l(),HL=a("li"),EPe=a("strong"),GCt=o("electra"),OCt=o(" \u2014 "),xde=a("a"),VCt=o("FlaxElectraForTokenClassification"),XCt=o(" (ELECTRA model)"),zCt=l(),JL=a("li"),CPe=a("strong"),QCt=o("roberta"),WCt=o(" \u2014 "),$de=a("a"),UCt=o("FlaxRobertaForTokenClassification"),HCt=o(" (RoBERTa model)"),JCt=l(),YL=a("li"),wPe=a("strong"),YCt=o("roformer"),ZCt=o(" \u2014 "),kde=a("a"),KCt=o("FlaxRoFormerForTokenClassification"),e3t=o(" (RoFormer model)"),o3t=l(),ZL=a("li"),APe=a("strong"),r3t=o("xlm-roberta"),t3t=o(" \u2014 "),Sde=a("a"),a3t=o("FlaxXLMRobertaForTokenClassification"),n3t=o(" (XLM-RoBERTa model)"),s3t=l(),F(KL.$$.fragment),Pno=l(),$m=a("h2"),ey=a("a"),LPe=a("span"),F(yB.$$.fragment),l3t=l(),yPe=a("span"),i3t=o("FlaxAutoModelForMultipleChoice"),Bno=l(),Pr=a("div"),F(xB.$$.fragment),d3t=l(),km=a("p"),c3t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Rde=a("a"),f3t=o("from_pretrained()"),m3t=o(" class method or the "),Pde=a("a"),g3t=o("from_config()"),h3t=o(` class
method.`),u3t=l(),$B=a("p"),p3t=o("This class cannot be instantiated directly using "),xPe=a("code"),_3t=o("__init__()"),v3t=o(" (throws an error)."),b3t=l(),Ta=a("div"),F(kB.$$.fragment),F3t=l(),$Pe=a("p"),T3t=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),M3t=l(),Sm=a("p"),E3t=o(`Note:
Loading a model from its configuration file does `),kPe=a("strong"),C3t=o("not"),w3t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Bde=a("a"),A3t=o("from_pretrained()"),L3t=o(" to load the model weights."),y3t=l(),F(oy.$$.fragment),x3t=l(),ct=a("div"),F(SB.$$.fragment),$3t=l(),SPe=a("p"),k3t=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),S3t=l(),ns=a("p"),R3t=o("The model class to instantiate is selected based on the "),RPe=a("code"),P3t=o("model_type"),B3t=o(` property of the config object (either
passed as an argument or loaded from `),PPe=a("code"),I3t=o("pretrained_model_name_or_path"),N3t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),BPe=a("code"),q3t=o("pretrained_model_name_or_path"),j3t=o(":"),D3t=l(),Qe=a("ul"),ry=a("li"),IPe=a("strong"),G3t=o("albert"),O3t=o(" \u2014 "),Ide=a("a"),V3t=o("FlaxAlbertForMultipleChoice"),X3t=o(" (ALBERT model)"),z3t=l(),ty=a("li"),NPe=a("strong"),Q3t=o("bert"),W3t=o(" \u2014 "),Nde=a("a"),U3t=o("FlaxBertForMultipleChoice"),H3t=o(" (BERT model)"),J3t=l(),ay=a("li"),qPe=a("strong"),Y3t=o("big_bird"),Z3t=o(" \u2014 "),qde=a("a"),K3t=o("FlaxBigBirdForMultipleChoice"),e5t=o(" (BigBird model)"),o5t=l(),ny=a("li"),jPe=a("strong"),r5t=o("distilbert"),t5t=o(" \u2014 "),jde=a("a"),a5t=o("FlaxDistilBertForMultipleChoice"),n5t=o(" (DistilBERT model)"),s5t=l(),sy=a("li"),DPe=a("strong"),l5t=o("electra"),i5t=o(" \u2014 "),Dde=a("a"),d5t=o("FlaxElectraForMultipleChoice"),c5t=o(" (ELECTRA model)"),f5t=l(),ly=a("li"),GPe=a("strong"),m5t=o("roberta"),g5t=o(" \u2014 "),Gde=a("a"),h5t=o("FlaxRobertaForMultipleChoice"),u5t=o(" (RoBERTa model)"),p5t=l(),iy=a("li"),OPe=a("strong"),_5t=o("roformer"),v5t=o(" \u2014 "),Ode=a("a"),b5t=o("FlaxRoFormerForMultipleChoice"),F5t=o(" (RoFormer model)"),T5t=l(),dy=a("li"),VPe=a("strong"),M5t=o("xlm-roberta"),E5t=o(" \u2014 "),Vde=a("a"),C5t=o("FlaxXLMRobertaForMultipleChoice"),w5t=o(" (XLM-RoBERTa model)"),A5t=l(),F(cy.$$.fragment),Ino=l(),Rm=a("h2"),fy=a("a"),XPe=a("span"),F(RB.$$.fragment),L5t=l(),zPe=a("span"),y5t=o("FlaxAutoModelForNextSentencePrediction"),Nno=l(),Br=a("div"),F(PB.$$.fragment),x5t=l(),Pm=a("p"),$5t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Xde=a("a"),k5t=o("from_pretrained()"),S5t=o(" class method or the "),zde=a("a"),R5t=o("from_config()"),P5t=o(` class
method.`),B5t=l(),BB=a("p"),I5t=o("This class cannot be instantiated directly using "),QPe=a("code"),N5t=o("__init__()"),q5t=o(" (throws an error)."),j5t=l(),Ma=a("div"),F(IB.$$.fragment),D5t=l(),WPe=a("p"),G5t=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),O5t=l(),Bm=a("p"),V5t=o(`Note:
Loading a model from its configuration file does `),UPe=a("strong"),X5t=o("not"),z5t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Qde=a("a"),Q5t=o("from_pretrained()"),W5t=o(" to load the model weights."),U5t=l(),F(my.$$.fragment),H5t=l(),ft=a("div"),F(NB.$$.fragment),J5t=l(),HPe=a("p"),Y5t=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Z5t=l(),ss=a("p"),K5t=o("The model class to instantiate is selected based on the "),JPe=a("code"),ewt=o("model_type"),owt=o(` property of the config object (either
passed as an argument or loaded from `),YPe=a("code"),rwt=o("pretrained_model_name_or_path"),twt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZPe=a("code"),awt=o("pretrained_model_name_or_path"),nwt=o(":"),swt=l(),KPe=a("ul"),gy=a("li"),eBe=a("strong"),lwt=o("bert"),iwt=o(" \u2014 "),Wde=a("a"),dwt=o("FlaxBertForNextSentencePrediction"),cwt=o(" (BERT model)"),fwt=l(),F(hy.$$.fragment),qno=l(),Im=a("h2"),uy=a("a"),oBe=a("span"),F(qB.$$.fragment),mwt=l(),rBe=a("span"),gwt=o("FlaxAutoModelForImageClassification"),jno=l(),Ir=a("div"),F(jB.$$.fragment),hwt=l(),Nm=a("p"),uwt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Ude=a("a"),pwt=o("from_pretrained()"),_wt=o(" class method or the "),Hde=a("a"),vwt=o("from_config()"),bwt=o(` class
method.`),Fwt=l(),DB=a("p"),Twt=o("This class cannot be instantiated directly using "),tBe=a("code"),Mwt=o("__init__()"),Ewt=o(" (throws an error)."),Cwt=l(),Ea=a("div"),F(GB.$$.fragment),wwt=l(),aBe=a("p"),Awt=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Lwt=l(),qm=a("p"),ywt=o(`Note:
Loading a model from its configuration file does `),nBe=a("strong"),xwt=o("not"),$wt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Jde=a("a"),kwt=o("from_pretrained()"),Swt=o(" to load the model weights."),Rwt=l(),F(py.$$.fragment),Pwt=l(),mt=a("div"),F(OB.$$.fragment),Bwt=l(),sBe=a("p"),Iwt=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Nwt=l(),ls=a("p"),qwt=o("The model class to instantiate is selected based on the "),lBe=a("code"),jwt=o("model_type"),Dwt=o(` property of the config object (either
passed as an argument or loaded from `),iBe=a("code"),Gwt=o("pretrained_model_name_or_path"),Owt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dBe=a("code"),Vwt=o("pretrained_model_name_or_path"),Xwt=o(":"),zwt=l(),VB=a("ul"),_y=a("li"),cBe=a("strong"),Qwt=o("beit"),Wwt=o(" \u2014 "),Yde=a("a"),Uwt=o("FlaxBeitForImageClassification"),Hwt=o(" (BEiT model)"),Jwt=l(),vy=a("li"),fBe=a("strong"),Ywt=o("vit"),Zwt=o(" \u2014 "),Zde=a("a"),Kwt=o("FlaxViTForImageClassification"),eAt=o(" (ViT model)"),oAt=l(),F(by.$$.fragment),Dno=l(),jm=a("h2"),Fy=a("a"),mBe=a("span"),F(XB.$$.fragment),rAt=l(),gBe=a("span"),tAt=o("FlaxAutoModelForVision2Seq"),Gno=l(),Nr=a("div"),F(zB.$$.fragment),aAt=l(),Dm=a("p"),nAt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Kde=a("a"),sAt=o("from_pretrained()"),lAt=o(" class method or the "),ece=a("a"),iAt=o("from_config()"),dAt=o(` class
method.`),cAt=l(),QB=a("p"),fAt=o("This class cannot be instantiated directly using "),hBe=a("code"),mAt=o("__init__()"),gAt=o(" (throws an error)."),hAt=l(),Ca=a("div"),F(WB.$$.fragment),uAt=l(),uBe=a("p"),pAt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),_At=l(),Gm=a("p"),vAt=o(`Note:
Loading a model from its configuration file does `),pBe=a("strong"),bAt=o("not"),FAt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oce=a("a"),TAt=o("from_pretrained()"),MAt=o(" to load the model weights."),EAt=l(),F(Ty.$$.fragment),CAt=l(),gt=a("div"),F(UB.$$.fragment),wAt=l(),_Be=a("p"),AAt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),LAt=l(),is=a("p"),yAt=o("The model class to instantiate is selected based on the "),vBe=a("code"),xAt=o("model_type"),$At=o(` property of the config object (either
passed as an argument or loaded from `),bBe=a("code"),kAt=o("pretrained_model_name_or_path"),SAt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FBe=a("code"),RAt=o("pretrained_model_name_or_path"),PAt=o(":"),BAt=l(),TBe=a("ul"),My=a("li"),MBe=a("strong"),IAt=o("vision-encoder-decoder"),NAt=o(" \u2014 "),rce=a("a"),qAt=o("FlaxVisionEncoderDecoderModel"),jAt=o(" (Vision Encoder decoder model)"),DAt=l(),F(Ey.$$.fragment),this.h()},l(f){const _=ACa('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),b=i(f),u=n(f,"H1",{class:!0});var HB=s(u);m=n(HB,"A",{id:!0,class:!0,href:!0});var EBe=s(m);p=n(EBe,"SPAN",{});var CBe=s(p);T(d.$$.fragment,CBe),CBe.forEach(t),EBe.forEach(t),h=i(HB),$o=n(HB,"SPAN",{});var wBe=s($o);vd=r(wBe,"Auto Classes"),wBe.forEach(t),HB.forEach(t),zm=i(f),Tt=n(f,"P",{});var JB=s(Tt);bd=r(JB,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Fd=n(JB,"CODE",{});var ABe=s(Fd);n$=r(ABe,"from_pretrained()"),ABe.forEach(t),Qm=r(JB,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),JB.forEach(t),Xe=i(f),He=n(f,"P",{});var ds=s(He);Td=r(ds,"Instantiating one of "),cs=n(ds,"A",{href:!0});var LBe=s(cs);s$=r(LBe,"AutoConfig"),LBe.forEach(t),fs=r(ds,", "),ms=n(ds,"A",{href:!0});var yBe=s(ms);l$=r(yBe,"AutoModel"),yBe.forEach(t),Md=r(ds,`, and
`),gs=n(ds,"A",{href:!0});var xBe=s(gs);i$=r(xBe,"AutoTokenizer"),xBe.forEach(t),Ed=r(ds," will directly create a class of the relevant architecture. For instance"),ds.forEach(t),Wm=i(f),T(on.$$.fragment,f),Je=i(f),Ae=n(f,"P",{});var YB=s(Ae);MN=r(YB,"will create a model that is an instance of "),Cd=n(YB,"A",{href:!0});var $Be=s(Cd);EN=r($Be,"BertModel"),$Be.forEach(t),CN=r(YB,"."),YB.forEach(t),ko=i(f),rn=n(f,"P",{});var ZB=s(rn);wN=r(ZB,"There is one class of "),Um=n(ZB,"CODE",{});var kBe=s(Um);AN=r(kBe,"AutoModel"),kBe.forEach(t),cio=r(ZB," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),ZB.forEach(t),wto=i(f),wd=n(f,"H2",{class:!0});var KB=s(wd);Hm=n(KB,"A",{id:!0,class:!0,href:!0});var SBe=s(Hm);fme=n(SBe,"SPAN",{});var RBe=s(fme);T(d$.$$.fragment,RBe),RBe.forEach(t),SBe.forEach(t),fio=i(KB),mme=n(KB,"SPAN",{});var PBe=s(mme);mio=r(PBe,"Extending the Auto Classes"),PBe.forEach(t),KB.forEach(t),Ato=i(f),hs=n(f,"P",{});var Om=s(hs);gio=r(Om,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),gme=n(Om,"CODE",{});var BBe=s(gme);hio=r(BBe,"NewModel"),BBe.forEach(t),uio=r(Om,", make sure you have a "),hme=n(Om,"CODE",{});var IBe=s(hme);pio=r(IBe,"NewModelConfig"),IBe.forEach(t),_io=r(Om,` then you can add those to the auto
classes like this:`),Om.forEach(t),Lto=i(f),T(c$.$$.fragment,f),yto=i(f),LN=n(f,"P",{});var NBe=s(LN);vio=r(NBe,"You will then be able to use the auto classes like you would usually do!"),NBe.forEach(t),xto=i(f),T(Jm.$$.fragment,f),$to=i(f),Ad=n(f,"H2",{class:!0});var eI=s(Ad);Ym=n(eI,"A",{id:!0,class:!0,href:!0});var qBe=s(Ym);ume=n(qBe,"SPAN",{});var jBe=s(ume);T(f$.$$.fragment,jBe),jBe.forEach(t),qBe.forEach(t),bio=i(eI),pme=n(eI,"SPAN",{});var DBe=s(pme);Fio=r(DBe,"AutoConfig"),DBe.forEach(t),eI.forEach(t),kto=i(f),So=n(f,"DIV",{class:!0});var bt=s(So);T(m$.$$.fragment,bt),Tio=i(bt),g$=n(bt,"P",{});var oI=s(g$);Mio=r(oI,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),yN=n(oI,"A",{href:!0});var GBe=s(yN);Eio=r(GBe,"from_pretrained()"),GBe.forEach(t),Cio=r(oI," class method."),oI.forEach(t),wio=i(bt),h$=n(bt,"P",{});var rI=s(h$);Aio=r(rI,"This class cannot be instantiated directly using "),_me=n(rI,"CODE",{});var OBe=s(_me);Lio=r(OBe,"__init__()"),OBe.forEach(t),yio=r(rI," (throws an error)."),rI.forEach(t),xio=i(bt),qr=n(bt,"DIV",{class:!0});var Ft=s(qr);T(u$.$$.fragment,Ft),$io=i(Ft),vme=n(Ft,"P",{});var VBe=s(vme);kio=r(VBe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),VBe.forEach(t),Sio=i(Ft),Ld=n(Ft,"P",{});var Vm=s(Ld);Rio=r(Vm,"The configuration class to instantiate is selected based on the "),bme=n(Vm,"CODE",{});var XBe=s(bme);Pio=r(XBe,"model_type"),XBe.forEach(t),Bio=r(Vm,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Fme=n(Vm,"CODE",{});var zBe=s(Fme);Iio=r(zBe,"pretrained_model_name_or_path"),zBe.forEach(t),Nio=r(Vm,":"),Vm.forEach(t),qio=i(Ft),A=n(Ft,"UL",{});var L=s(A);Zm=n(L,"LI",{});var Cy=s(Zm);Tme=n(Cy,"STRONG",{});var QBe=s(Tme);jio=r(QBe,"albert"),QBe.forEach(t),Dio=r(Cy," \u2014 "),xN=n(Cy,"A",{href:!0});var WBe=s(xN);Gio=r(WBe,"AlbertConfig"),WBe.forEach(t),Oio=r(Cy," (ALBERT model)"),Cy.forEach(t),Vio=i(L),Km=n(L,"LI",{});var wy=s(Km);Mme=n(wy,"STRONG",{});var UBe=s(Mme);Xio=r(UBe,"bart"),UBe.forEach(t),zio=r(wy," \u2014 "),$N=n(wy,"A",{href:!0});var HBe=s($N);Qio=r(HBe,"BartConfig"),HBe.forEach(t),Wio=r(wy," (BART model)"),wy.forEach(t),Uio=i(L),eg=n(L,"LI",{});var Ay=s(eg);Eme=n(Ay,"STRONG",{});var JBe=s(Eme);Hio=r(JBe,"beit"),JBe.forEach(t),Jio=r(Ay," \u2014 "),kN=n(Ay,"A",{href:!0});var YBe=s(kN);Yio=r(YBe,"BeitConfig"),YBe.forEach(t),Zio=r(Ay," (BEiT model)"),Ay.forEach(t),Kio=i(L),og=n(L,"LI",{});var Ly=s(og);Cme=n(Ly,"STRONG",{});var ZBe=s(Cme);edo=r(ZBe,"bert"),ZBe.forEach(t),odo=r(Ly," \u2014 "),SN=n(Ly,"A",{href:!0});var KBe=s(SN);rdo=r(KBe,"BertConfig"),KBe.forEach(t),tdo=r(Ly," (BERT model)"),Ly.forEach(t),ado=i(L),rg=n(L,"LI",{});var yy=s(rg);wme=n(yy,"STRONG",{});var eIe=s(wme);ndo=r(eIe,"bert-generation"),eIe.forEach(t),sdo=r(yy," \u2014 "),RN=n(yy,"A",{href:!0});var oIe=s(RN);ldo=r(oIe,"BertGenerationConfig"),oIe.forEach(t),ido=r(yy," (Bert Generation model)"),yy.forEach(t),ddo=i(L),tg=n(L,"LI",{});var xy=s(tg);Ame=n(xy,"STRONG",{});var rIe=s(Ame);cdo=r(rIe,"big_bird"),rIe.forEach(t),fdo=r(xy," \u2014 "),PN=n(xy,"A",{href:!0});var tIe=s(PN);mdo=r(tIe,"BigBirdConfig"),tIe.forEach(t),gdo=r(xy," (BigBird model)"),xy.forEach(t),hdo=i(L),ag=n(L,"LI",{});var $y=s(ag);Lme=n($y,"STRONG",{});var aIe=s(Lme);udo=r(aIe,"bigbird_pegasus"),aIe.forEach(t),pdo=r($y," \u2014 "),BN=n($y,"A",{href:!0});var nIe=s(BN);_do=r(nIe,"BigBirdPegasusConfig"),nIe.forEach(t),vdo=r($y," (BigBird-Pegasus model)"),$y.forEach(t),bdo=i(L),ng=n(L,"LI",{});var ky=s(ng);yme=n(ky,"STRONG",{});var sIe=s(yme);Fdo=r(sIe,"blenderbot"),sIe.forEach(t),Tdo=r(ky," \u2014 "),IN=n(ky,"A",{href:!0});var lIe=s(IN);Mdo=r(lIe,"BlenderbotConfig"),lIe.forEach(t),Edo=r(ky," (Blenderbot model)"),ky.forEach(t),Cdo=i(L),sg=n(L,"LI",{});var Sy=s(sg);xme=n(Sy,"STRONG",{});var iIe=s(xme);wdo=r(iIe,"blenderbot-small"),iIe.forEach(t),Ado=r(Sy," \u2014 "),NN=n(Sy,"A",{href:!0});var dIe=s(NN);Ldo=r(dIe,"BlenderbotSmallConfig"),dIe.forEach(t),ydo=r(Sy," (BlenderbotSmall model)"),Sy.forEach(t),xdo=i(L),lg=n(L,"LI",{});var Ry=s(lg);$me=n(Ry,"STRONG",{});var cIe=s($me);$do=r(cIe,"bloom"),cIe.forEach(t),kdo=r(Ry," \u2014 "),qN=n(Ry,"A",{href:!0});var fIe=s(qN);Sdo=r(fIe,"BloomConfig"),fIe.forEach(t),Rdo=r(Ry," (BLOOM model)"),Ry.forEach(t),Pdo=i(L),ig=n(L,"LI",{});var Py=s(ig);kme=n(Py,"STRONG",{});var mIe=s(kme);Bdo=r(mIe,"camembert"),mIe.forEach(t),Ido=r(Py," \u2014 "),jN=n(Py,"A",{href:!0});var gIe=s(jN);Ndo=r(gIe,"CamembertConfig"),gIe.forEach(t),qdo=r(Py," (CamemBERT model)"),Py.forEach(t),jdo=i(L),dg=n(L,"LI",{});var By=s(dg);Sme=n(By,"STRONG",{});var hIe=s(Sme);Ddo=r(hIe,"canine"),hIe.forEach(t),Gdo=r(By," \u2014 "),DN=n(By,"A",{href:!0});var uIe=s(DN);Odo=r(uIe,"CanineConfig"),uIe.forEach(t),Vdo=r(By," (CANINE model)"),By.forEach(t),Xdo=i(L),cg=n(L,"LI",{});var Iy=s(cg);Rme=n(Iy,"STRONG",{});var pIe=s(Rme);zdo=r(pIe,"clip"),pIe.forEach(t),Qdo=r(Iy," \u2014 "),GN=n(Iy,"A",{href:!0});var _Ie=s(GN);Wdo=r(_Ie,"CLIPConfig"),_Ie.forEach(t),Udo=r(Iy," (CLIP model)"),Iy.forEach(t),Hdo=i(L),fg=n(L,"LI",{});var Ny=s(fg);Pme=n(Ny,"STRONG",{});var vIe=s(Pme);Jdo=r(vIe,"codegen"),vIe.forEach(t),Ydo=r(Ny," \u2014 "),ON=n(Ny,"A",{href:!0});var bIe=s(ON);Zdo=r(bIe,"CodeGenConfig"),bIe.forEach(t),Kdo=r(Ny," (CodeGen model)"),Ny.forEach(t),eco=i(L),mg=n(L,"LI",{});var qy=s(mg);Bme=n(qy,"STRONG",{});var FIe=s(Bme);oco=r(FIe,"conditional_detr"),FIe.forEach(t),rco=r(qy," \u2014 "),VN=n(qy,"A",{href:!0});var TIe=s(VN);tco=r(TIe,"ConditionalDetrConfig"),TIe.forEach(t),aco=r(qy," (Conditional DETR model)"),qy.forEach(t),nco=i(L),gg=n(L,"LI",{});var jy=s(gg);Ime=n(jy,"STRONG",{});var MIe=s(Ime);sco=r(MIe,"convbert"),MIe.forEach(t),lco=r(jy," \u2014 "),XN=n(jy,"A",{href:!0});var EIe=s(XN);ico=r(EIe,"ConvBertConfig"),EIe.forEach(t),dco=r(jy," (ConvBERT model)"),jy.forEach(t),cco=i(L),hg=n(L,"LI",{});var Dy=s(hg);Nme=n(Dy,"STRONG",{});var CIe=s(Nme);fco=r(CIe,"convnext"),CIe.forEach(t),mco=r(Dy," \u2014 "),zN=n(Dy,"A",{href:!0});var wIe=s(zN);gco=r(wIe,"ConvNextConfig"),wIe.forEach(t),hco=r(Dy," (ConvNeXT model)"),Dy.forEach(t),uco=i(L),ug=n(L,"LI",{});var Gy=s(ug);qme=n(Gy,"STRONG",{});var AIe=s(qme);pco=r(AIe,"ctrl"),AIe.forEach(t),_co=r(Gy," \u2014 "),QN=n(Gy,"A",{href:!0});var LIe=s(QN);vco=r(LIe,"CTRLConfig"),LIe.forEach(t),bco=r(Gy," (CTRL model)"),Gy.forEach(t),Fco=i(L),pg=n(L,"LI",{});var Oy=s(pg);jme=n(Oy,"STRONG",{});var yIe=s(jme);Tco=r(yIe,"cvt"),yIe.forEach(t),Mco=r(Oy," \u2014 "),WN=n(Oy,"A",{href:!0});var xIe=s(WN);Eco=r(xIe,"CvtConfig"),xIe.forEach(t),Cco=r(Oy," (CvT model)"),Oy.forEach(t),wco=i(L),_g=n(L,"LI",{});var Vy=s(_g);Dme=n(Vy,"STRONG",{});var $Ie=s(Dme);Aco=r($Ie,"data2vec-audio"),$Ie.forEach(t),Lco=r(Vy," \u2014 "),UN=n(Vy,"A",{href:!0});var kIe=s(UN);yco=r(kIe,"Data2VecAudioConfig"),kIe.forEach(t),xco=r(Vy," (Data2VecAudio model)"),Vy.forEach(t),$co=i(L),vg=n(L,"LI",{});var Xy=s(vg);Gme=n(Xy,"STRONG",{});var SIe=s(Gme);kco=r(SIe,"data2vec-text"),SIe.forEach(t),Sco=r(Xy," \u2014 "),HN=n(Xy,"A",{href:!0});var RIe=s(HN);Rco=r(RIe,"Data2VecTextConfig"),RIe.forEach(t),Pco=r(Xy," (Data2VecText model)"),Xy.forEach(t),Bco=i(L),bg=n(L,"LI",{});var zy=s(bg);Ome=n(zy,"STRONG",{});var PIe=s(Ome);Ico=r(PIe,"data2vec-vision"),PIe.forEach(t),Nco=r(zy," \u2014 "),JN=n(zy,"A",{href:!0});var BIe=s(JN);qco=r(BIe,"Data2VecVisionConfig"),BIe.forEach(t),jco=r(zy," (Data2VecVision model)"),zy.forEach(t),Dco=i(L),Fg=n(L,"LI",{});var Qy=s(Fg);Vme=n(Qy,"STRONG",{});var IIe=s(Vme);Gco=r(IIe,"deberta"),IIe.forEach(t),Oco=r(Qy," \u2014 "),YN=n(Qy,"A",{href:!0});var NIe=s(YN);Vco=r(NIe,"DebertaConfig"),NIe.forEach(t),Xco=r(Qy," (DeBERTa model)"),Qy.forEach(t),zco=i(L),Tg=n(L,"LI",{});var Wy=s(Tg);Xme=n(Wy,"STRONG",{});var qIe=s(Xme);Qco=r(qIe,"deberta-v2"),qIe.forEach(t),Wco=r(Wy," \u2014 "),ZN=n(Wy,"A",{href:!0});var jIe=s(ZN);Uco=r(jIe,"DebertaV2Config"),jIe.forEach(t),Hco=r(Wy," (DeBERTa-v2 model)"),Wy.forEach(t),Jco=i(L),Mg=n(L,"LI",{});var Uy=s(Mg);zme=n(Uy,"STRONG",{});var DIe=s(zme);Yco=r(DIe,"decision_transformer"),DIe.forEach(t),Zco=r(Uy," \u2014 "),KN=n(Uy,"A",{href:!0});var GIe=s(KN);Kco=r(GIe,"DecisionTransformerConfig"),GIe.forEach(t),efo=r(Uy," (Decision Transformer model)"),Uy.forEach(t),ofo=i(L),Eg=n(L,"LI",{});var Hy=s(Eg);Qme=n(Hy,"STRONG",{});var OIe=s(Qme);rfo=r(OIe,"deformable_detr"),OIe.forEach(t),tfo=r(Hy," \u2014 "),eq=n(Hy,"A",{href:!0});var VIe=s(eq);afo=r(VIe,"DeformableDetrConfig"),VIe.forEach(t),nfo=r(Hy," (Deformable DETR model)"),Hy.forEach(t),sfo=i(L),Cg=n(L,"LI",{});var Jy=s(Cg);Wme=n(Jy,"STRONG",{});var XIe=s(Wme);lfo=r(XIe,"deit"),XIe.forEach(t),ifo=r(Jy," \u2014 "),oq=n(Jy,"A",{href:!0});var zIe=s(oq);dfo=r(zIe,"DeiTConfig"),zIe.forEach(t),cfo=r(Jy," (DeiT model)"),Jy.forEach(t),ffo=i(L),wg=n(L,"LI",{});var Yy=s(wg);Ume=n(Yy,"STRONG",{});var OAt=s(Ume);mfo=r(OAt,"detr"),OAt.forEach(t),gfo=r(Yy," \u2014 "),rq=n(Yy,"A",{href:!0});var VAt=s(rq);hfo=r(VAt,"DetrConfig"),VAt.forEach(t),ufo=r(Yy," (DETR model)"),Yy.forEach(t),pfo=i(L),Ag=n(L,"LI",{});var QIe=s(Ag);Hme=n(QIe,"STRONG",{});var XAt=s(Hme);_fo=r(XAt,"distilbert"),XAt.forEach(t),vfo=r(QIe," \u2014 "),tq=n(QIe,"A",{href:!0});var zAt=s(tq);bfo=r(zAt,"DistilBertConfig"),zAt.forEach(t),Ffo=r(QIe," (DistilBERT model)"),QIe.forEach(t),Tfo=i(L),Lg=n(L,"LI",{});var WIe=s(Lg);Jme=n(WIe,"STRONG",{});var QAt=s(Jme);Mfo=r(QAt,"donut-swin"),QAt.forEach(t),Efo=r(WIe," \u2014 "),aq=n(WIe,"A",{href:!0});var WAt=s(aq);Cfo=r(WAt,"DonutSwinConfig"),WAt.forEach(t),wfo=r(WIe," (DonutSwin model)"),WIe.forEach(t),Afo=i(L),yg=n(L,"LI",{});var UIe=s(yg);Yme=n(UIe,"STRONG",{});var UAt=s(Yme);Lfo=r(UAt,"dpr"),UAt.forEach(t),yfo=r(UIe," \u2014 "),nq=n(UIe,"A",{href:!0});var HAt=s(nq);xfo=r(HAt,"DPRConfig"),HAt.forEach(t),$fo=r(UIe," (DPR model)"),UIe.forEach(t),kfo=i(L),xg=n(L,"LI",{});var HIe=s(xg);Zme=n(HIe,"STRONG",{});var JAt=s(Zme);Sfo=r(JAt,"dpt"),JAt.forEach(t),Rfo=r(HIe," \u2014 "),sq=n(HIe,"A",{href:!0});var YAt=s(sq);Pfo=r(YAt,"DPTConfig"),YAt.forEach(t),Bfo=r(HIe," (DPT model)"),HIe.forEach(t),Ifo=i(L),$g=n(L,"LI",{});var JIe=s($g);Kme=n(JIe,"STRONG",{});var ZAt=s(Kme);Nfo=r(ZAt,"electra"),ZAt.forEach(t),qfo=r(JIe," \u2014 "),lq=n(JIe,"A",{href:!0});var KAt=s(lq);jfo=r(KAt,"ElectraConfig"),KAt.forEach(t),Dfo=r(JIe," (ELECTRA model)"),JIe.forEach(t),Gfo=i(L),kg=n(L,"LI",{});var YIe=s(kg);ege=n(YIe,"STRONG",{});var e6t=s(ege);Ofo=r(e6t,"encoder-decoder"),e6t.forEach(t),Vfo=r(YIe," \u2014 "),iq=n(YIe,"A",{href:!0});var o6t=s(iq);Xfo=r(o6t,"EncoderDecoderConfig"),o6t.forEach(t),zfo=r(YIe," (Encoder decoder model)"),YIe.forEach(t),Qfo=i(L),Sg=n(L,"LI",{});var ZIe=s(Sg);oge=n(ZIe,"STRONG",{});var r6t=s(oge);Wfo=r(r6t,"ernie"),r6t.forEach(t),Ufo=r(ZIe," \u2014 "),dq=n(ZIe,"A",{href:!0});var t6t=s(dq);Hfo=r(t6t,"ErnieConfig"),t6t.forEach(t),Jfo=r(ZIe," (ERNIE model)"),ZIe.forEach(t),Yfo=i(L),Rg=n(L,"LI",{});var KIe=s(Rg);rge=n(KIe,"STRONG",{});var a6t=s(rge);Zfo=r(a6t,"esm"),a6t.forEach(t),Kfo=r(KIe," \u2014 "),cq=n(KIe,"A",{href:!0});var n6t=s(cq);emo=r(n6t,"EsmConfig"),n6t.forEach(t),omo=r(KIe," (ESM model)"),KIe.forEach(t),rmo=i(L),Pg=n(L,"LI",{});var eNe=s(Pg);tge=n(eNe,"STRONG",{});var s6t=s(tge);tmo=r(s6t,"flaubert"),s6t.forEach(t),amo=r(eNe," \u2014 "),fq=n(eNe,"A",{href:!0});var l6t=s(fq);nmo=r(l6t,"FlaubertConfig"),l6t.forEach(t),smo=r(eNe," (FlauBERT model)"),eNe.forEach(t),lmo=i(L),Bg=n(L,"LI",{});var oNe=s(Bg);age=n(oNe,"STRONG",{});var i6t=s(age);imo=r(i6t,"flava"),i6t.forEach(t),dmo=r(oNe," \u2014 "),mq=n(oNe,"A",{href:!0});var d6t=s(mq);cmo=r(d6t,"FlavaConfig"),d6t.forEach(t),fmo=r(oNe," (FLAVA model)"),oNe.forEach(t),mmo=i(L),Ig=n(L,"LI",{});var rNe=s(Ig);nge=n(rNe,"STRONG",{});var c6t=s(nge);gmo=r(c6t,"fnet"),c6t.forEach(t),hmo=r(rNe," \u2014 "),gq=n(rNe,"A",{href:!0});var f6t=s(gq);umo=r(f6t,"FNetConfig"),f6t.forEach(t),pmo=r(rNe," (FNet model)"),rNe.forEach(t),_mo=i(L),Ng=n(L,"LI",{});var tNe=s(Ng);sge=n(tNe,"STRONG",{});var m6t=s(sge);vmo=r(m6t,"fsmt"),m6t.forEach(t),bmo=r(tNe," \u2014 "),hq=n(tNe,"A",{href:!0});var g6t=s(hq);Fmo=r(g6t,"FSMTConfig"),g6t.forEach(t),Tmo=r(tNe," (FairSeq Machine-Translation model)"),tNe.forEach(t),Mmo=i(L),qg=n(L,"LI",{});var aNe=s(qg);lge=n(aNe,"STRONG",{});var h6t=s(lge);Emo=r(h6t,"funnel"),h6t.forEach(t),Cmo=r(aNe," \u2014 "),uq=n(aNe,"A",{href:!0});var u6t=s(uq);wmo=r(u6t,"FunnelConfig"),u6t.forEach(t),Amo=r(aNe," (Funnel Transformer model)"),aNe.forEach(t),Lmo=i(L),jg=n(L,"LI",{});var nNe=s(jg);ige=n(nNe,"STRONG",{});var p6t=s(ige);ymo=r(p6t,"glpn"),p6t.forEach(t),xmo=r(nNe," \u2014 "),pq=n(nNe,"A",{href:!0});var _6t=s(pq);$mo=r(_6t,"GLPNConfig"),_6t.forEach(t),kmo=r(nNe," (GLPN model)"),nNe.forEach(t),Smo=i(L),Dg=n(L,"LI",{});var sNe=s(Dg);dge=n(sNe,"STRONG",{});var v6t=s(dge);Rmo=r(v6t,"gpt2"),v6t.forEach(t),Pmo=r(sNe," \u2014 "),_q=n(sNe,"A",{href:!0});var b6t=s(_q);Bmo=r(b6t,"GPT2Config"),b6t.forEach(t),Imo=r(sNe," (OpenAI GPT-2 model)"),sNe.forEach(t),Nmo=i(L),Gg=n(L,"LI",{});var lNe=s(Gg);cge=n(lNe,"STRONG",{});var F6t=s(cge);qmo=r(F6t,"gpt_neo"),F6t.forEach(t),jmo=r(lNe," \u2014 "),vq=n(lNe,"A",{href:!0});var T6t=s(vq);Dmo=r(T6t,"GPTNeoConfig"),T6t.forEach(t),Gmo=r(lNe," (GPT Neo model)"),lNe.forEach(t),Omo=i(L),Og=n(L,"LI",{});var iNe=s(Og);fge=n(iNe,"STRONG",{});var M6t=s(fge);Vmo=r(M6t,"gpt_neox"),M6t.forEach(t),Xmo=r(iNe," \u2014 "),bq=n(iNe,"A",{href:!0});var E6t=s(bq);zmo=r(E6t,"GPTNeoXConfig"),E6t.forEach(t),Qmo=r(iNe," (GPT NeoX model)"),iNe.forEach(t),Wmo=i(L),Vg=n(L,"LI",{});var dNe=s(Vg);mge=n(dNe,"STRONG",{});var C6t=s(mge);Umo=r(C6t,"gpt_neox_japanese"),C6t.forEach(t),Hmo=r(dNe," \u2014 "),Fq=n(dNe,"A",{href:!0});var w6t=s(Fq);Jmo=r(w6t,"GPTNeoXJapaneseConfig"),w6t.forEach(t),Ymo=r(dNe," (GPT NeoX Japanese model)"),dNe.forEach(t),Zmo=i(L),Xg=n(L,"LI",{});var cNe=s(Xg);gge=n(cNe,"STRONG",{});var A6t=s(gge);Kmo=r(A6t,"gptj"),A6t.forEach(t),ego=r(cNe," \u2014 "),Tq=n(cNe,"A",{href:!0});var L6t=s(Tq);ogo=r(L6t,"GPTJConfig"),L6t.forEach(t),rgo=r(cNe," (GPT-J model)"),cNe.forEach(t),tgo=i(L),zg=n(L,"LI",{});var fNe=s(zg);hge=n(fNe,"STRONG",{});var y6t=s(hge);ago=r(y6t,"groupvit"),y6t.forEach(t),ngo=r(fNe," \u2014 "),Mq=n(fNe,"A",{href:!0});var x6t=s(Mq);sgo=r(x6t,"GroupViTConfig"),x6t.forEach(t),lgo=r(fNe," (GroupViT model)"),fNe.forEach(t),igo=i(L),Qg=n(L,"LI",{});var mNe=s(Qg);uge=n(mNe,"STRONG",{});var $6t=s(uge);dgo=r($6t,"hubert"),$6t.forEach(t),cgo=r(mNe," \u2014 "),Eq=n(mNe,"A",{href:!0});var k6t=s(Eq);fgo=r(k6t,"HubertConfig"),k6t.forEach(t),mgo=r(mNe," (Hubert model)"),mNe.forEach(t),ggo=i(L),Wg=n(L,"LI",{});var gNe=s(Wg);pge=n(gNe,"STRONG",{});var S6t=s(pge);hgo=r(S6t,"ibert"),S6t.forEach(t),ugo=r(gNe," \u2014 "),Cq=n(gNe,"A",{href:!0});var R6t=s(Cq);pgo=r(R6t,"IBertConfig"),R6t.forEach(t),_go=r(gNe," (I-BERT model)"),gNe.forEach(t),vgo=i(L),Ug=n(L,"LI",{});var hNe=s(Ug);_ge=n(hNe,"STRONG",{});var P6t=s(_ge);bgo=r(P6t,"imagegpt"),P6t.forEach(t),Fgo=r(hNe," \u2014 "),wq=n(hNe,"A",{href:!0});var B6t=s(wq);Tgo=r(B6t,"ImageGPTConfig"),B6t.forEach(t),Mgo=r(hNe," (ImageGPT model)"),hNe.forEach(t),Ego=i(L),Hg=n(L,"LI",{});var uNe=s(Hg);vge=n(uNe,"STRONG",{});var I6t=s(vge);Cgo=r(I6t,"layoutlm"),I6t.forEach(t),wgo=r(uNe," \u2014 "),Aq=n(uNe,"A",{href:!0});var N6t=s(Aq);Ago=r(N6t,"LayoutLMConfig"),N6t.forEach(t),Lgo=r(uNe," (LayoutLM model)"),uNe.forEach(t),ygo=i(L),Jg=n(L,"LI",{});var pNe=s(Jg);bge=n(pNe,"STRONG",{});var q6t=s(bge);xgo=r(q6t,"layoutlmv2"),q6t.forEach(t),$go=r(pNe," \u2014 "),Lq=n(pNe,"A",{href:!0});var j6t=s(Lq);kgo=r(j6t,"LayoutLMv2Config"),j6t.forEach(t),Sgo=r(pNe," (LayoutLMv2 model)"),pNe.forEach(t),Rgo=i(L),Yg=n(L,"LI",{});var _Ne=s(Yg);Fge=n(_Ne,"STRONG",{});var D6t=s(Fge);Pgo=r(D6t,"layoutlmv3"),D6t.forEach(t),Bgo=r(_Ne," \u2014 "),yq=n(_Ne,"A",{href:!0});var G6t=s(yq);Igo=r(G6t,"LayoutLMv3Config"),G6t.forEach(t),Ngo=r(_Ne," (LayoutLMv3 model)"),_Ne.forEach(t),qgo=i(L),Zg=n(L,"LI",{});var vNe=s(Zg);Tge=n(vNe,"STRONG",{});var O6t=s(Tge);jgo=r(O6t,"led"),O6t.forEach(t),Dgo=r(vNe," \u2014 "),xq=n(vNe,"A",{href:!0});var V6t=s(xq);Ggo=r(V6t,"LEDConfig"),V6t.forEach(t),Ogo=r(vNe," (LED model)"),vNe.forEach(t),Vgo=i(L),Kg=n(L,"LI",{});var bNe=s(Kg);Mge=n(bNe,"STRONG",{});var X6t=s(Mge);Xgo=r(X6t,"levit"),X6t.forEach(t),zgo=r(bNe," \u2014 "),$q=n(bNe,"A",{href:!0});var z6t=s($q);Qgo=r(z6t,"LevitConfig"),z6t.forEach(t),Wgo=r(bNe," (LeViT model)"),bNe.forEach(t),Ugo=i(L),eh=n(L,"LI",{});var FNe=s(eh);Ege=n(FNe,"STRONG",{});var Q6t=s(Ege);Hgo=r(Q6t,"lilt"),Q6t.forEach(t),Jgo=r(FNe," \u2014 "),kq=n(FNe,"A",{href:!0});var W6t=s(kq);Ygo=r(W6t,"LiltConfig"),W6t.forEach(t),Zgo=r(FNe," (LiLT model)"),FNe.forEach(t),Kgo=i(L),oh=n(L,"LI",{});var TNe=s(oh);Cge=n(TNe,"STRONG",{});var U6t=s(Cge);eho=r(U6t,"longformer"),U6t.forEach(t),oho=r(TNe," \u2014 "),Sq=n(TNe,"A",{href:!0});var H6t=s(Sq);rho=r(H6t,"LongformerConfig"),H6t.forEach(t),tho=r(TNe," (Longformer model)"),TNe.forEach(t),aho=i(L),rh=n(L,"LI",{});var MNe=s(rh);wge=n(MNe,"STRONG",{});var J6t=s(wge);nho=r(J6t,"longt5"),J6t.forEach(t),sho=r(MNe," \u2014 "),Rq=n(MNe,"A",{href:!0});var Y6t=s(Rq);lho=r(Y6t,"LongT5Config"),Y6t.forEach(t),iho=r(MNe," (LongT5 model)"),MNe.forEach(t),dho=i(L),th=n(L,"LI",{});var ENe=s(th);Age=n(ENe,"STRONG",{});var Z6t=s(Age);cho=r(Z6t,"luke"),Z6t.forEach(t),fho=r(ENe," \u2014 "),Pq=n(ENe,"A",{href:!0});var K6t=s(Pq);mho=r(K6t,"LukeConfig"),K6t.forEach(t),gho=r(ENe," (LUKE model)"),ENe.forEach(t),hho=i(L),ah=n(L,"LI",{});var CNe=s(ah);Lge=n(CNe,"STRONG",{});var e7t=s(Lge);uho=r(e7t,"lxmert"),e7t.forEach(t),pho=r(CNe," \u2014 "),Bq=n(CNe,"A",{href:!0});var o7t=s(Bq);_ho=r(o7t,"LxmertConfig"),o7t.forEach(t),vho=r(CNe," (LXMERT model)"),CNe.forEach(t),bho=i(L),nh=n(L,"LI",{});var wNe=s(nh);yge=n(wNe,"STRONG",{});var r7t=s(yge);Fho=r(r7t,"m2m_100"),r7t.forEach(t),Tho=r(wNe," \u2014 "),Iq=n(wNe,"A",{href:!0});var t7t=s(Iq);Mho=r(t7t,"M2M100Config"),t7t.forEach(t),Eho=r(wNe," (M2M100 model)"),wNe.forEach(t),Cho=i(L),sh=n(L,"LI",{});var ANe=s(sh);xge=n(ANe,"STRONG",{});var a7t=s(xge);who=r(a7t,"marian"),a7t.forEach(t),Aho=r(ANe," \u2014 "),Nq=n(ANe,"A",{href:!0});var n7t=s(Nq);Lho=r(n7t,"MarianConfig"),n7t.forEach(t),yho=r(ANe," (Marian model)"),ANe.forEach(t),xho=i(L),lh=n(L,"LI",{});var LNe=s(lh);$ge=n(LNe,"STRONG",{});var s7t=s($ge);$ho=r(s7t,"markuplm"),s7t.forEach(t),kho=r(LNe," \u2014 "),qq=n(LNe,"A",{href:!0});var l7t=s(qq);Sho=r(l7t,"MarkupLMConfig"),l7t.forEach(t),Rho=r(LNe," (MarkupLM model)"),LNe.forEach(t),Pho=i(L),ih=n(L,"LI",{});var yNe=s(ih);kge=n(yNe,"STRONG",{});var i7t=s(kge);Bho=r(i7t,"maskformer"),i7t.forEach(t),Iho=r(yNe," \u2014 "),jq=n(yNe,"A",{href:!0});var d7t=s(jq);Nho=r(d7t,"MaskFormerConfig"),d7t.forEach(t),qho=r(yNe," (MaskFormer model)"),yNe.forEach(t),jho=i(L),dh=n(L,"LI",{});var xNe=s(dh);Sge=n(xNe,"STRONG",{});var c7t=s(Sge);Dho=r(c7t,"mbart"),c7t.forEach(t),Gho=r(xNe," \u2014 "),Dq=n(xNe,"A",{href:!0});var f7t=s(Dq);Oho=r(f7t,"MBartConfig"),f7t.forEach(t),Vho=r(xNe," (mBART model)"),xNe.forEach(t),Xho=i(L),ch=n(L,"LI",{});var $Ne=s(ch);Rge=n($Ne,"STRONG",{});var m7t=s(Rge);zho=r(m7t,"mctct"),m7t.forEach(t),Qho=r($Ne," \u2014 "),Gq=n($Ne,"A",{href:!0});var g7t=s(Gq);Who=r(g7t,"MCTCTConfig"),g7t.forEach(t),Uho=r($Ne," (M-CTC-T model)"),$Ne.forEach(t),Hho=i(L),fh=n(L,"LI",{});var kNe=s(fh);Pge=n(kNe,"STRONG",{});var h7t=s(Pge);Jho=r(h7t,"megatron-bert"),h7t.forEach(t),Yho=r(kNe," \u2014 "),Oq=n(kNe,"A",{href:!0});var u7t=s(Oq);Zho=r(u7t,"MegatronBertConfig"),u7t.forEach(t),Kho=r(kNe," (Megatron-BERT model)"),kNe.forEach(t),euo=i(L),mh=n(L,"LI",{});var SNe=s(mh);Bge=n(SNe,"STRONG",{});var p7t=s(Bge);ouo=r(p7t,"mobilebert"),p7t.forEach(t),ruo=r(SNe," \u2014 "),Vq=n(SNe,"A",{href:!0});var _7t=s(Vq);tuo=r(_7t,"MobileBertConfig"),_7t.forEach(t),auo=r(SNe," (MobileBERT model)"),SNe.forEach(t),nuo=i(L),gh=n(L,"LI",{});var RNe=s(gh);Ige=n(RNe,"STRONG",{});var v7t=s(Ige);suo=r(v7t,"mobilevit"),v7t.forEach(t),luo=r(RNe," \u2014 "),Xq=n(RNe,"A",{href:!0});var b7t=s(Xq);iuo=r(b7t,"MobileViTConfig"),b7t.forEach(t),duo=r(RNe," (MobileViT model)"),RNe.forEach(t),cuo=i(L),hh=n(L,"LI",{});var PNe=s(hh);Nge=n(PNe,"STRONG",{});var F7t=s(Nge);fuo=r(F7t,"mpnet"),F7t.forEach(t),muo=r(PNe," \u2014 "),zq=n(PNe,"A",{href:!0});var T7t=s(zq);guo=r(T7t,"MPNetConfig"),T7t.forEach(t),huo=r(PNe," (MPNet model)"),PNe.forEach(t),uuo=i(L),uh=n(L,"LI",{});var BNe=s(uh);qge=n(BNe,"STRONG",{});var M7t=s(qge);puo=r(M7t,"mt5"),M7t.forEach(t),_uo=r(BNe," \u2014 "),Qq=n(BNe,"A",{href:!0});var E7t=s(Qq);vuo=r(E7t,"MT5Config"),E7t.forEach(t),buo=r(BNe," (MT5 model)"),BNe.forEach(t),Fuo=i(L),ph=n(L,"LI",{});var INe=s(ph);jge=n(INe,"STRONG",{});var C7t=s(jge);Tuo=r(C7t,"mvp"),C7t.forEach(t),Muo=r(INe," \u2014 "),Wq=n(INe,"A",{href:!0});var w7t=s(Wq);Euo=r(w7t,"MvpConfig"),w7t.forEach(t),Cuo=r(INe," (MVP model)"),INe.forEach(t),wuo=i(L),_h=n(L,"LI",{});var NNe=s(_h);Dge=n(NNe,"STRONG",{});var A7t=s(Dge);Auo=r(A7t,"nezha"),A7t.forEach(t),Luo=r(NNe," \u2014 "),Uq=n(NNe,"A",{href:!0});var L7t=s(Uq);yuo=r(L7t,"NezhaConfig"),L7t.forEach(t),xuo=r(NNe," (Nezha model)"),NNe.forEach(t),$uo=i(L),vh=n(L,"LI",{});var qNe=s(vh);Gge=n(qNe,"STRONG",{});var y7t=s(Gge);kuo=r(y7t,"nystromformer"),y7t.forEach(t),Suo=r(qNe," \u2014 "),Hq=n(qNe,"A",{href:!0});var x7t=s(Hq);Ruo=r(x7t,"NystromformerConfig"),x7t.forEach(t),Puo=r(qNe," (Nystr\xF6mformer model)"),qNe.forEach(t),Buo=i(L),bh=n(L,"LI",{});var jNe=s(bh);Oge=n(jNe,"STRONG",{});var $7t=s(Oge);Iuo=r($7t,"openai-gpt"),$7t.forEach(t),Nuo=r(jNe," \u2014 "),Jq=n(jNe,"A",{href:!0});var k7t=s(Jq);quo=r(k7t,"OpenAIGPTConfig"),k7t.forEach(t),juo=r(jNe," (OpenAI GPT model)"),jNe.forEach(t),Duo=i(L),Fh=n(L,"LI",{});var DNe=s(Fh);Vge=n(DNe,"STRONG",{});var S7t=s(Vge);Guo=r(S7t,"opt"),S7t.forEach(t),Ouo=r(DNe," \u2014 "),Yq=n(DNe,"A",{href:!0});var R7t=s(Yq);Vuo=r(R7t,"OPTConfig"),R7t.forEach(t),Xuo=r(DNe," (OPT model)"),DNe.forEach(t),zuo=i(L),Th=n(L,"LI",{});var GNe=s(Th);Xge=n(GNe,"STRONG",{});var P7t=s(Xge);Quo=r(P7t,"owlvit"),P7t.forEach(t),Wuo=r(GNe," \u2014 "),Zq=n(GNe,"A",{href:!0});var B7t=s(Zq);Uuo=r(B7t,"OwlViTConfig"),B7t.forEach(t),Huo=r(GNe," (OWL-ViT model)"),GNe.forEach(t),Juo=i(L),Mh=n(L,"LI",{});var ONe=s(Mh);zge=n(ONe,"STRONG",{});var I7t=s(zge);Yuo=r(I7t,"pegasus"),I7t.forEach(t),Zuo=r(ONe," \u2014 "),Kq=n(ONe,"A",{href:!0});var N7t=s(Kq);Kuo=r(N7t,"PegasusConfig"),N7t.forEach(t),epo=r(ONe," (Pegasus model)"),ONe.forEach(t),opo=i(L),Eh=n(L,"LI",{});var VNe=s(Eh);Qge=n(VNe,"STRONG",{});var q7t=s(Qge);rpo=r(q7t,"pegasus_x"),q7t.forEach(t),tpo=r(VNe," \u2014 "),ej=n(VNe,"A",{href:!0});var j7t=s(ej);apo=r(j7t,"PegasusXConfig"),j7t.forEach(t),npo=r(VNe," (PEGASUS-X model)"),VNe.forEach(t),spo=i(L),Ch=n(L,"LI",{});var XNe=s(Ch);Wge=n(XNe,"STRONG",{});var D7t=s(Wge);lpo=r(D7t,"perceiver"),D7t.forEach(t),ipo=r(XNe," \u2014 "),oj=n(XNe,"A",{href:!0});var G7t=s(oj);dpo=r(G7t,"PerceiverConfig"),G7t.forEach(t),cpo=r(XNe," (Perceiver model)"),XNe.forEach(t),fpo=i(L),wh=n(L,"LI",{});var zNe=s(wh);Uge=n(zNe,"STRONG",{});var O7t=s(Uge);mpo=r(O7t,"plbart"),O7t.forEach(t),gpo=r(zNe," \u2014 "),rj=n(zNe,"A",{href:!0});var V7t=s(rj);hpo=r(V7t,"PLBartConfig"),V7t.forEach(t),upo=r(zNe," (PLBart model)"),zNe.forEach(t),ppo=i(L),Ah=n(L,"LI",{});var QNe=s(Ah);Hge=n(QNe,"STRONG",{});var X7t=s(Hge);_po=r(X7t,"poolformer"),X7t.forEach(t),vpo=r(QNe," \u2014 "),tj=n(QNe,"A",{href:!0});var z7t=s(tj);bpo=r(z7t,"PoolFormerConfig"),z7t.forEach(t),Fpo=r(QNe," (PoolFormer model)"),QNe.forEach(t),Tpo=i(L),Lh=n(L,"LI",{});var WNe=s(Lh);Jge=n(WNe,"STRONG",{});var Q7t=s(Jge);Mpo=r(Q7t,"prophetnet"),Q7t.forEach(t),Epo=r(WNe," \u2014 "),aj=n(WNe,"A",{href:!0});var W7t=s(aj);Cpo=r(W7t,"ProphetNetConfig"),W7t.forEach(t),wpo=r(WNe," (ProphetNet model)"),WNe.forEach(t),Apo=i(L),yh=n(L,"LI",{});var UNe=s(yh);Yge=n(UNe,"STRONG",{});var U7t=s(Yge);Lpo=r(U7t,"qdqbert"),U7t.forEach(t),ypo=r(UNe," \u2014 "),nj=n(UNe,"A",{href:!0});var H7t=s(nj);xpo=r(H7t,"QDQBertConfig"),H7t.forEach(t),$po=r(UNe," (QDQBert model)"),UNe.forEach(t),kpo=i(L),xh=n(L,"LI",{});var HNe=s(xh);Zge=n(HNe,"STRONG",{});var J7t=s(Zge);Spo=r(J7t,"rag"),J7t.forEach(t),Rpo=r(HNe," \u2014 "),sj=n(HNe,"A",{href:!0});var Y7t=s(sj);Ppo=r(Y7t,"RagConfig"),Y7t.forEach(t),Bpo=r(HNe," (RAG model)"),HNe.forEach(t),Ipo=i(L),$h=n(L,"LI",{});var JNe=s($h);Kge=n(JNe,"STRONG",{});var Z7t=s(Kge);Npo=r(Z7t,"realm"),Z7t.forEach(t),qpo=r(JNe," \u2014 "),lj=n(JNe,"A",{href:!0});var K7t=s(lj);jpo=r(K7t,"RealmConfig"),K7t.forEach(t),Dpo=r(JNe," (REALM model)"),JNe.forEach(t),Gpo=i(L),kh=n(L,"LI",{});var YNe=s(kh);ehe=n(YNe,"STRONG",{});var e8t=s(ehe);Opo=r(e8t,"reformer"),e8t.forEach(t),Vpo=r(YNe," \u2014 "),ij=n(YNe,"A",{href:!0});var o8t=s(ij);Xpo=r(o8t,"ReformerConfig"),o8t.forEach(t),zpo=r(YNe," (Reformer model)"),YNe.forEach(t),Qpo=i(L),Sh=n(L,"LI",{});var ZNe=s(Sh);ohe=n(ZNe,"STRONG",{});var r8t=s(ohe);Wpo=r(r8t,"regnet"),r8t.forEach(t),Upo=r(ZNe," \u2014 "),dj=n(ZNe,"A",{href:!0});var t8t=s(dj);Hpo=r(t8t,"RegNetConfig"),t8t.forEach(t),Jpo=r(ZNe," (RegNet model)"),ZNe.forEach(t),Ypo=i(L),Rh=n(L,"LI",{});var KNe=s(Rh);rhe=n(KNe,"STRONG",{});var a8t=s(rhe);Zpo=r(a8t,"rembert"),a8t.forEach(t),Kpo=r(KNe," \u2014 "),cj=n(KNe,"A",{href:!0});var n8t=s(cj);e_o=r(n8t,"RemBertConfig"),n8t.forEach(t),o_o=r(KNe," (RemBERT model)"),KNe.forEach(t),r_o=i(L),Ph=n(L,"LI",{});var eqe=s(Ph);the=n(eqe,"STRONG",{});var s8t=s(the);t_o=r(s8t,"resnet"),s8t.forEach(t),a_o=r(eqe," \u2014 "),fj=n(eqe,"A",{href:!0});var l8t=s(fj);n_o=r(l8t,"ResNetConfig"),l8t.forEach(t),s_o=r(eqe," (ResNet model)"),eqe.forEach(t),l_o=i(L),Bh=n(L,"LI",{});var oqe=s(Bh);ahe=n(oqe,"STRONG",{});var i8t=s(ahe);i_o=r(i8t,"retribert"),i8t.forEach(t),d_o=r(oqe," \u2014 "),mj=n(oqe,"A",{href:!0});var d8t=s(mj);c_o=r(d8t,"RetriBertConfig"),d8t.forEach(t),f_o=r(oqe," (RetriBERT model)"),oqe.forEach(t),m_o=i(L),Ih=n(L,"LI",{});var rqe=s(Ih);nhe=n(rqe,"STRONG",{});var c8t=s(nhe);g_o=r(c8t,"roberta"),c8t.forEach(t),h_o=r(rqe," \u2014 "),gj=n(rqe,"A",{href:!0});var f8t=s(gj);u_o=r(f8t,"RobertaConfig"),f8t.forEach(t),p_o=r(rqe," (RoBERTa model)"),rqe.forEach(t),__o=i(L),Nh=n(L,"LI",{});var tqe=s(Nh);she=n(tqe,"STRONG",{});var m8t=s(she);v_o=r(m8t,"roformer"),m8t.forEach(t),b_o=r(tqe," \u2014 "),hj=n(tqe,"A",{href:!0});var g8t=s(hj);F_o=r(g8t,"RoFormerConfig"),g8t.forEach(t),T_o=r(tqe," (RoFormer model)"),tqe.forEach(t),M_o=i(L),qh=n(L,"LI",{});var aqe=s(qh);lhe=n(aqe,"STRONG",{});var h8t=s(lhe);E_o=r(h8t,"segformer"),h8t.forEach(t),C_o=r(aqe," \u2014 "),uj=n(aqe,"A",{href:!0});var u8t=s(uj);w_o=r(u8t,"SegformerConfig"),u8t.forEach(t),A_o=r(aqe," (SegFormer model)"),aqe.forEach(t),L_o=i(L),jh=n(L,"LI",{});var nqe=s(jh);ihe=n(nqe,"STRONG",{});var p8t=s(ihe);y_o=r(p8t,"sew"),p8t.forEach(t),x_o=r(nqe," \u2014 "),pj=n(nqe,"A",{href:!0});var _8t=s(pj);$_o=r(_8t,"SEWConfig"),_8t.forEach(t),k_o=r(nqe," (SEW model)"),nqe.forEach(t),S_o=i(L),Dh=n(L,"LI",{});var sqe=s(Dh);dhe=n(sqe,"STRONG",{});var v8t=s(dhe);R_o=r(v8t,"sew-d"),v8t.forEach(t),P_o=r(sqe," \u2014 "),_j=n(sqe,"A",{href:!0});var b8t=s(_j);B_o=r(b8t,"SEWDConfig"),b8t.forEach(t),I_o=r(sqe," (SEW-D model)"),sqe.forEach(t),N_o=i(L),Gh=n(L,"LI",{});var lqe=s(Gh);che=n(lqe,"STRONG",{});var F8t=s(che);q_o=r(F8t,"speech-encoder-decoder"),F8t.forEach(t),j_o=r(lqe," \u2014 "),vj=n(lqe,"A",{href:!0});var T8t=s(vj);D_o=r(T8t,"SpeechEncoderDecoderConfig"),T8t.forEach(t),G_o=r(lqe," (Speech Encoder decoder model)"),lqe.forEach(t),O_o=i(L),Oh=n(L,"LI",{});var iqe=s(Oh);fhe=n(iqe,"STRONG",{});var M8t=s(fhe);V_o=r(M8t,"speech_to_text"),M8t.forEach(t),X_o=r(iqe," \u2014 "),bj=n(iqe,"A",{href:!0});var E8t=s(bj);z_o=r(E8t,"Speech2TextConfig"),E8t.forEach(t),Q_o=r(iqe," (Speech2Text model)"),iqe.forEach(t),W_o=i(L),Vh=n(L,"LI",{});var dqe=s(Vh);mhe=n(dqe,"STRONG",{});var C8t=s(mhe);U_o=r(C8t,"speech_to_text_2"),C8t.forEach(t),H_o=r(dqe," \u2014 "),Fj=n(dqe,"A",{href:!0});var w8t=s(Fj);J_o=r(w8t,"Speech2Text2Config"),w8t.forEach(t),Y_o=r(dqe," (Speech2Text2 model)"),dqe.forEach(t),Z_o=i(L),Xh=n(L,"LI",{});var cqe=s(Xh);ghe=n(cqe,"STRONG",{});var A8t=s(ghe);K_o=r(A8t,"splinter"),A8t.forEach(t),e4o=r(cqe," \u2014 "),Tj=n(cqe,"A",{href:!0});var L8t=s(Tj);o4o=r(L8t,"SplinterConfig"),L8t.forEach(t),r4o=r(cqe," (Splinter model)"),cqe.forEach(t),t4o=i(L),zh=n(L,"LI",{});var fqe=s(zh);hhe=n(fqe,"STRONG",{});var y8t=s(hhe);a4o=r(y8t,"squeezebert"),y8t.forEach(t),n4o=r(fqe," \u2014 "),Mj=n(fqe,"A",{href:!0});var x8t=s(Mj);s4o=r(x8t,"SqueezeBertConfig"),x8t.forEach(t),l4o=r(fqe," (SqueezeBERT model)"),fqe.forEach(t),i4o=i(L),Qh=n(L,"LI",{});var mqe=s(Qh);uhe=n(mqe,"STRONG",{});var $8t=s(uhe);d4o=r($8t,"swin"),$8t.forEach(t),c4o=r(mqe," \u2014 "),Ej=n(mqe,"A",{href:!0});var k8t=s(Ej);f4o=r(k8t,"SwinConfig"),k8t.forEach(t),m4o=r(mqe," (Swin Transformer model)"),mqe.forEach(t),g4o=i(L),Wh=n(L,"LI",{});var gqe=s(Wh);phe=n(gqe,"STRONG",{});var S8t=s(phe);h4o=r(S8t,"swinv2"),S8t.forEach(t),u4o=r(gqe," \u2014 "),Cj=n(gqe,"A",{href:!0});var R8t=s(Cj);p4o=r(R8t,"Swinv2Config"),R8t.forEach(t),_4o=r(gqe," (Swin Transformer V2 model)"),gqe.forEach(t),v4o=i(L),Uh=n(L,"LI",{});var hqe=s(Uh);_he=n(hqe,"STRONG",{});var P8t=s(_he);b4o=r(P8t,"t5"),P8t.forEach(t),F4o=r(hqe," \u2014 "),wj=n(hqe,"A",{href:!0});var B8t=s(wj);T4o=r(B8t,"T5Config"),B8t.forEach(t),M4o=r(hqe," (T5 model)"),hqe.forEach(t),E4o=i(L),Hh=n(L,"LI",{});var uqe=s(Hh);vhe=n(uqe,"STRONG",{});var I8t=s(vhe);C4o=r(I8t,"table-transformer"),I8t.forEach(t),w4o=r(uqe," \u2014 "),Aj=n(uqe,"A",{href:!0});var N8t=s(Aj);A4o=r(N8t,"TableTransformerConfig"),N8t.forEach(t),L4o=r(uqe," (Table Transformer model)"),uqe.forEach(t),y4o=i(L),Jh=n(L,"LI",{});var pqe=s(Jh);bhe=n(pqe,"STRONG",{});var q8t=s(bhe);x4o=r(q8t,"tapas"),q8t.forEach(t),$4o=r(pqe," \u2014 "),Lj=n(pqe,"A",{href:!0});var j8t=s(Lj);k4o=r(j8t,"TapasConfig"),j8t.forEach(t),S4o=r(pqe," (TAPAS model)"),pqe.forEach(t),R4o=i(L),Yh=n(L,"LI",{});var _qe=s(Yh);Fhe=n(_qe,"STRONG",{});var D8t=s(Fhe);P4o=r(D8t,"time_series_transformer"),D8t.forEach(t),B4o=r(_qe," \u2014 "),yj=n(_qe,"A",{href:!0});var G8t=s(yj);I4o=r(G8t,"TimeSeriesTransformerConfig"),G8t.forEach(t),N4o=r(_qe," (Time Series Transformer model)"),_qe.forEach(t),q4o=i(L),Zh=n(L,"LI",{});var vqe=s(Zh);The=n(vqe,"STRONG",{});var O8t=s(The);j4o=r(O8t,"trajectory_transformer"),O8t.forEach(t),D4o=r(vqe," \u2014 "),xj=n(vqe,"A",{href:!0});var V8t=s(xj);G4o=r(V8t,"TrajectoryTransformerConfig"),V8t.forEach(t),O4o=r(vqe," (Trajectory Transformer model)"),vqe.forEach(t),V4o=i(L),Kh=n(L,"LI",{});var bqe=s(Kh);Mhe=n(bqe,"STRONG",{});var X8t=s(Mhe);X4o=r(X8t,"transfo-xl"),X8t.forEach(t),z4o=r(bqe," \u2014 "),$j=n(bqe,"A",{href:!0});var z8t=s($j);Q4o=r(z8t,"TransfoXLConfig"),z8t.forEach(t),W4o=r(bqe," (Transformer-XL model)"),bqe.forEach(t),U4o=i(L),eu=n(L,"LI",{});var Fqe=s(eu);Ehe=n(Fqe,"STRONG",{});var Q8t=s(Ehe);H4o=r(Q8t,"trocr"),Q8t.forEach(t),J4o=r(Fqe," \u2014 "),kj=n(Fqe,"A",{href:!0});var W8t=s(kj);Y4o=r(W8t,"TrOCRConfig"),W8t.forEach(t),Z4o=r(Fqe," (TrOCR model)"),Fqe.forEach(t),K4o=i(L),ou=n(L,"LI",{});var Tqe=s(ou);Che=n(Tqe,"STRONG",{});var U8t=s(Che);e2o=r(U8t,"unispeech"),U8t.forEach(t),o2o=r(Tqe," \u2014 "),Sj=n(Tqe,"A",{href:!0});var H8t=s(Sj);r2o=r(H8t,"UniSpeechConfig"),H8t.forEach(t),t2o=r(Tqe," (UniSpeech model)"),Tqe.forEach(t),a2o=i(L),ru=n(L,"LI",{});var Mqe=s(ru);whe=n(Mqe,"STRONG",{});var J8t=s(whe);n2o=r(J8t,"unispeech-sat"),J8t.forEach(t),s2o=r(Mqe," \u2014 "),Rj=n(Mqe,"A",{href:!0});var Y8t=s(Rj);l2o=r(Y8t,"UniSpeechSatConfig"),Y8t.forEach(t),i2o=r(Mqe," (UniSpeechSat model)"),Mqe.forEach(t),d2o=i(L),tu=n(L,"LI",{});var Eqe=s(tu);Ahe=n(Eqe,"STRONG",{});var Z8t=s(Ahe);c2o=r(Z8t,"van"),Z8t.forEach(t),f2o=r(Eqe," \u2014 "),Pj=n(Eqe,"A",{href:!0});var K8t=s(Pj);m2o=r(K8t,"VanConfig"),K8t.forEach(t),g2o=r(Eqe," (VAN model)"),Eqe.forEach(t),h2o=i(L),au=n(L,"LI",{});var Cqe=s(au);Lhe=n(Cqe,"STRONG",{});var eLt=s(Lhe);u2o=r(eLt,"videomae"),eLt.forEach(t),p2o=r(Cqe," \u2014 "),Bj=n(Cqe,"A",{href:!0});var oLt=s(Bj);_2o=r(oLt,"VideoMAEConfig"),oLt.forEach(t),v2o=r(Cqe," (VideoMAE model)"),Cqe.forEach(t),b2o=i(L),nu=n(L,"LI",{});var wqe=s(nu);yhe=n(wqe,"STRONG",{});var rLt=s(yhe);F2o=r(rLt,"vilt"),rLt.forEach(t),T2o=r(wqe," \u2014 "),Ij=n(wqe,"A",{href:!0});var tLt=s(Ij);M2o=r(tLt,"ViltConfig"),tLt.forEach(t),E2o=r(wqe," (ViLT model)"),wqe.forEach(t),C2o=i(L),su=n(L,"LI",{});var Aqe=s(su);xhe=n(Aqe,"STRONG",{});var aLt=s(xhe);w2o=r(aLt,"vision-encoder-decoder"),aLt.forEach(t),A2o=r(Aqe," \u2014 "),Nj=n(Aqe,"A",{href:!0});var nLt=s(Nj);L2o=r(nLt,"VisionEncoderDecoderConfig"),nLt.forEach(t),y2o=r(Aqe," (Vision Encoder decoder model)"),Aqe.forEach(t),x2o=i(L),lu=n(L,"LI",{});var Lqe=s(lu);$he=n(Lqe,"STRONG",{});var sLt=s($he);$2o=r(sLt,"vision-text-dual-encoder"),sLt.forEach(t),k2o=r(Lqe," \u2014 "),qj=n(Lqe,"A",{href:!0});var lLt=s(qj);S2o=r(lLt,"VisionTextDualEncoderConfig"),lLt.forEach(t),R2o=r(Lqe," (VisionTextDualEncoder model)"),Lqe.forEach(t),P2o=i(L),iu=n(L,"LI",{});var yqe=s(iu);khe=n(yqe,"STRONG",{});var iLt=s(khe);B2o=r(iLt,"visual_bert"),iLt.forEach(t),I2o=r(yqe," \u2014 "),jj=n(yqe,"A",{href:!0});var dLt=s(jj);N2o=r(dLt,"VisualBertConfig"),dLt.forEach(t),q2o=r(yqe," (VisualBERT model)"),yqe.forEach(t),j2o=i(L),du=n(L,"LI",{});var xqe=s(du);She=n(xqe,"STRONG",{});var cLt=s(She);D2o=r(cLt,"vit"),cLt.forEach(t),G2o=r(xqe," \u2014 "),Dj=n(xqe,"A",{href:!0});var fLt=s(Dj);O2o=r(fLt,"ViTConfig"),fLt.forEach(t),V2o=r(xqe," (ViT model)"),xqe.forEach(t),X2o=i(L),cu=n(L,"LI",{});var $qe=s(cu);Rhe=n($qe,"STRONG",{});var mLt=s(Rhe);z2o=r(mLt,"vit_mae"),mLt.forEach(t),Q2o=r($qe," \u2014 "),Gj=n($qe,"A",{href:!0});var gLt=s(Gj);W2o=r(gLt,"ViTMAEConfig"),gLt.forEach(t),U2o=r($qe," (ViTMAE model)"),$qe.forEach(t),H2o=i(L),fu=n(L,"LI",{});var kqe=s(fu);Phe=n(kqe,"STRONG",{});var hLt=s(Phe);J2o=r(hLt,"vit_msn"),hLt.forEach(t),Y2o=r(kqe," \u2014 "),Oj=n(kqe,"A",{href:!0});var uLt=s(Oj);Z2o=r(uLt,"ViTMSNConfig"),uLt.forEach(t),K2o=r(kqe," (ViTMSN model)"),kqe.forEach(t),evo=i(L),mu=n(L,"LI",{});var Sqe=s(mu);Bhe=n(Sqe,"STRONG",{});var pLt=s(Bhe);ovo=r(pLt,"wav2vec2"),pLt.forEach(t),rvo=r(Sqe," \u2014 "),Vj=n(Sqe,"A",{href:!0});var _Lt=s(Vj);tvo=r(_Lt,"Wav2Vec2Config"),_Lt.forEach(t),avo=r(Sqe," (Wav2Vec2 model)"),Sqe.forEach(t),nvo=i(L),gu=n(L,"LI",{});var Rqe=s(gu);Ihe=n(Rqe,"STRONG",{});var vLt=s(Ihe);svo=r(vLt,"wav2vec2-conformer"),vLt.forEach(t),lvo=r(Rqe," \u2014 "),Xj=n(Rqe,"A",{href:!0});var bLt=s(Xj);ivo=r(bLt,"Wav2Vec2ConformerConfig"),bLt.forEach(t),dvo=r(Rqe," (Wav2Vec2-Conformer model)"),Rqe.forEach(t),cvo=i(L),hu=n(L,"LI",{});var Pqe=s(hu);Nhe=n(Pqe,"STRONG",{});var FLt=s(Nhe);fvo=r(FLt,"wavlm"),FLt.forEach(t),mvo=r(Pqe," \u2014 "),zj=n(Pqe,"A",{href:!0});var TLt=s(zj);gvo=r(TLt,"WavLMConfig"),TLt.forEach(t),hvo=r(Pqe," (WavLM model)"),Pqe.forEach(t),uvo=i(L),uu=n(L,"LI",{});var Bqe=s(uu);qhe=n(Bqe,"STRONG",{});var MLt=s(qhe);pvo=r(MLt,"whisper"),MLt.forEach(t),_vo=r(Bqe," \u2014 "),Qj=n(Bqe,"A",{href:!0});var ELt=s(Qj);vvo=r(ELt,"WhisperConfig"),ELt.forEach(t),bvo=r(Bqe," (Whisper model)"),Bqe.forEach(t),Fvo=i(L),pu=n(L,"LI",{});var Iqe=s(pu);jhe=n(Iqe,"STRONG",{});var CLt=s(jhe);Tvo=r(CLt,"xclip"),CLt.forEach(t),Mvo=r(Iqe," \u2014 "),Wj=n(Iqe,"A",{href:!0});var wLt=s(Wj);Evo=r(wLt,"XCLIPConfig"),wLt.forEach(t),Cvo=r(Iqe," (X-CLIP model)"),Iqe.forEach(t),wvo=i(L),_u=n(L,"LI",{});var Nqe=s(_u);Dhe=n(Nqe,"STRONG",{});var ALt=s(Dhe);Avo=r(ALt,"xglm"),ALt.forEach(t),Lvo=r(Nqe," \u2014 "),Uj=n(Nqe,"A",{href:!0});var LLt=s(Uj);yvo=r(LLt,"XGLMConfig"),LLt.forEach(t),xvo=r(Nqe," (XGLM model)"),Nqe.forEach(t),$vo=i(L),vu=n(L,"LI",{});var qqe=s(vu);Ghe=n(qqe,"STRONG",{});var yLt=s(Ghe);kvo=r(yLt,"xlm"),yLt.forEach(t),Svo=r(qqe," \u2014 "),Hj=n(qqe,"A",{href:!0});var xLt=s(Hj);Rvo=r(xLt,"XLMConfig"),xLt.forEach(t),Pvo=r(qqe," (XLM model)"),qqe.forEach(t),Bvo=i(L),bu=n(L,"LI",{});var jqe=s(bu);Ohe=n(jqe,"STRONG",{});var $Lt=s(Ohe);Ivo=r($Lt,"xlm-prophetnet"),$Lt.forEach(t),Nvo=r(jqe," \u2014 "),Jj=n(jqe,"A",{href:!0});var kLt=s(Jj);qvo=r(kLt,"XLMProphetNetConfig"),kLt.forEach(t),jvo=r(jqe," (XLM-ProphetNet model)"),jqe.forEach(t),Dvo=i(L),Fu=n(L,"LI",{});var Dqe=s(Fu);Vhe=n(Dqe,"STRONG",{});var SLt=s(Vhe);Gvo=r(SLt,"xlm-roberta"),SLt.forEach(t),Ovo=r(Dqe," \u2014 "),Yj=n(Dqe,"A",{href:!0});var RLt=s(Yj);Vvo=r(RLt,"XLMRobertaConfig"),RLt.forEach(t),Xvo=r(Dqe," (XLM-RoBERTa model)"),Dqe.forEach(t),zvo=i(L),Tu=n(L,"LI",{});var Gqe=s(Tu);Xhe=n(Gqe,"STRONG",{});var PLt=s(Xhe);Qvo=r(PLt,"xlm-roberta-xl"),PLt.forEach(t),Wvo=r(Gqe," \u2014 "),Zj=n(Gqe,"A",{href:!0});var BLt=s(Zj);Uvo=r(BLt,"XLMRobertaXLConfig"),BLt.forEach(t),Hvo=r(Gqe," (XLM-RoBERTa-XL model)"),Gqe.forEach(t),Jvo=i(L),Mu=n(L,"LI",{});var Oqe=s(Mu);zhe=n(Oqe,"STRONG",{});var ILt=s(zhe);Yvo=r(ILt,"xlnet"),ILt.forEach(t),Zvo=r(Oqe," \u2014 "),Kj=n(Oqe,"A",{href:!0});var NLt=s(Kj);Kvo=r(NLt,"XLNetConfig"),NLt.forEach(t),e1o=r(Oqe," (XLNet model)"),Oqe.forEach(t),o1o=i(L),Eu=n(L,"LI",{});var Vqe=s(Eu);Qhe=n(Vqe,"STRONG",{});var qLt=s(Qhe);r1o=r(qLt,"yolos"),qLt.forEach(t),t1o=r(Vqe," \u2014 "),eD=n(Vqe,"A",{href:!0});var jLt=s(eD);a1o=r(jLt,"YolosConfig"),jLt.forEach(t),n1o=r(Vqe," (YOLOS model)"),Vqe.forEach(t),s1o=i(L),Cu=n(L,"LI",{});var Xqe=s(Cu);Whe=n(Xqe,"STRONG",{});var DLt=s(Whe);l1o=r(DLt,"yoso"),DLt.forEach(t),i1o=r(Xqe," \u2014 "),oD=n(Xqe,"A",{href:!0});var GLt=s(oD);d1o=r(GLt,"YosoConfig"),GLt.forEach(t),c1o=r(Xqe," (YOSO model)"),Xqe.forEach(t),L.forEach(t),f1o=i(Ft),T(wu.$$.fragment,Ft),Ft.forEach(t),m1o=i(bt),Au=n(bt,"DIV",{class:!0});var Vno=s(Au);T(p$.$$.fragment,Vno),g1o=i(Vno),Uhe=n(Vno,"P",{});var OLt=s(Uhe);h1o=r(OLt,"Register a new configuration for this class."),OLt.forEach(t),Vno.forEach(t),bt.forEach(t),Sto=i(f),yd=n(f,"H2",{class:!0});var Xno=s(yd);Lu=n(Xno,"A",{id:!0,class:!0,href:!0});var VLt=s(Lu);Hhe=n(VLt,"SPAN",{});var XLt=s(Hhe);T(_$.$$.fragment,XLt),XLt.forEach(t),VLt.forEach(t),u1o=i(Xno),Jhe=n(Xno,"SPAN",{});var zLt=s(Jhe);p1o=r(zLt,"AutoTokenizer"),zLt.forEach(t),Xno.forEach(t),Rto=i(f),Ro=n(f,"DIV",{class:!0});var Pl=s(Ro);T(v$.$$.fragment,Pl),_1o=i(Pl),b$=n(Pl,"P",{});var zno=s(b$);v1o=r(zno,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),rD=n(zno,"A",{href:!0});var QLt=s(rD);b1o=r(QLt,"AutoTokenizer.from_pretrained()"),QLt.forEach(t),F1o=r(zno," class method."),zno.forEach(t),T1o=i(Pl),F$=n(Pl,"P",{});var Qno=s(F$);M1o=r(Qno,"This class cannot be instantiated directly using "),Yhe=n(Qno,"CODE",{});var WLt=s(Yhe);E1o=r(WLt,"__init__()"),WLt.forEach(t),C1o=r(Qno," (throws an error)."),Qno.forEach(t),w1o=i(Pl),jr=n(Pl,"DIV",{class:!0});var Bl=s(jr);T(T$.$$.fragment,Bl),A1o=i(Bl),Zhe=n(Bl,"P",{});var ULt=s(Zhe);L1o=r(ULt,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),ULt.forEach(t),y1o=i(Bl),tn=n(Bl,"P",{});var Zy=s(tn);x1o=r(Zy,"The tokenizer class to instantiate is selected based on the "),Khe=n(Zy,"CODE",{});var HLt=s(Khe);$1o=r(HLt,"model_type"),HLt.forEach(t),k1o=r(Zy,` property of the config object (either
passed as an argument or loaded from `),eue=n(Zy,"CODE",{});var JLt=s(eue);S1o=r(JLt,"pretrained_model_name_or_path"),JLt.forEach(t),R1o=r(Zy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oue=n(Zy,"CODE",{});var YLt=s(oue);P1o=r(YLt,"pretrained_model_name_or_path"),YLt.forEach(t),B1o=r(Zy,":"),Zy.forEach(t),I1o=i(Bl),k=n(Bl,"UL",{});var S=s(k);us=n(S,"LI",{});var tI=s(us);rue=n(tI,"STRONG",{});var ZLt=s(rue);N1o=r(ZLt,"albert"),ZLt.forEach(t),q1o=r(tI," \u2014 "),tD=n(tI,"A",{href:!0});var KLt=s(tD);j1o=r(KLt,"AlbertTokenizer"),KLt.forEach(t),D1o=r(tI," or "),aD=n(tI,"A",{href:!0});var eyt=s(aD);G1o=r(eyt,"AlbertTokenizerFast"),eyt.forEach(t),O1o=r(tI," (ALBERT model)"),tI.forEach(t),V1o=i(S),ps=n(S,"LI",{});var aI=s(ps);tue=n(aI,"STRONG",{});var oyt=s(tue);X1o=r(oyt,"bart"),oyt.forEach(t),z1o=r(aI," \u2014 "),nD=n(aI,"A",{href:!0});var ryt=s(nD);Q1o=r(ryt,"BartTokenizer"),ryt.forEach(t),W1o=r(aI," or "),sD=n(aI,"A",{href:!0});var tyt=s(sD);U1o=r(tyt,"BartTokenizerFast"),tyt.forEach(t),H1o=r(aI," (BART model)"),aI.forEach(t),J1o=i(S),_s=n(S,"LI",{});var nI=s(_s);aue=n(nI,"STRONG",{});var ayt=s(aue);Y1o=r(ayt,"barthez"),ayt.forEach(t),Z1o=r(nI," \u2014 "),lD=n(nI,"A",{href:!0});var nyt=s(lD);K1o=r(nyt,"BarthezTokenizer"),nyt.forEach(t),ebo=r(nI," or "),iD=n(nI,"A",{href:!0});var syt=s(iD);obo=r(syt,"BarthezTokenizerFast"),syt.forEach(t),rbo=r(nI," (BARThez model)"),nI.forEach(t),tbo=i(S),yu=n(S,"LI",{});var zqe=s(yu);nue=n(zqe,"STRONG",{});var lyt=s(nue);abo=r(lyt,"bartpho"),lyt.forEach(t),nbo=r(zqe," \u2014 "),dD=n(zqe,"A",{href:!0});var iyt=s(dD);sbo=r(iyt,"BartphoTokenizer"),iyt.forEach(t),lbo=r(zqe," (BARTpho model)"),zqe.forEach(t),ibo=i(S),vs=n(S,"LI",{});var sI=s(vs);sue=n(sI,"STRONG",{});var dyt=s(sue);dbo=r(dyt,"bert"),dyt.forEach(t),cbo=r(sI," \u2014 "),cD=n(sI,"A",{href:!0});var cyt=s(cD);fbo=r(cyt,"BertTokenizer"),cyt.forEach(t),mbo=r(sI," or "),fD=n(sI,"A",{href:!0});var fyt=s(fD);gbo=r(fyt,"BertTokenizerFast"),fyt.forEach(t),hbo=r(sI," (BERT model)"),sI.forEach(t),ubo=i(S),xu=n(S,"LI",{});var Qqe=s(xu);lue=n(Qqe,"STRONG",{});var myt=s(lue);pbo=r(myt,"bert-generation"),myt.forEach(t),_bo=r(Qqe," \u2014 "),mD=n(Qqe,"A",{href:!0});var gyt=s(mD);vbo=r(gyt,"BertGenerationTokenizer"),gyt.forEach(t),bbo=r(Qqe," (Bert Generation model)"),Qqe.forEach(t),Fbo=i(S),$u=n(S,"LI",{});var Wqe=s($u);iue=n(Wqe,"STRONG",{});var hyt=s(iue);Tbo=r(hyt,"bert-japanese"),hyt.forEach(t),Mbo=r(Wqe," \u2014 "),gD=n(Wqe,"A",{href:!0});var uyt=s(gD);Ebo=r(uyt,"BertJapaneseTokenizer"),uyt.forEach(t),Cbo=r(Wqe," (BertJapanese model)"),Wqe.forEach(t),wbo=i(S),ku=n(S,"LI",{});var Uqe=s(ku);due=n(Uqe,"STRONG",{});var pyt=s(due);Abo=r(pyt,"bertweet"),pyt.forEach(t),Lbo=r(Uqe," \u2014 "),hD=n(Uqe,"A",{href:!0});var _yt=s(hD);ybo=r(_yt,"BertweetTokenizer"),_yt.forEach(t),xbo=r(Uqe," (BERTweet model)"),Uqe.forEach(t),$bo=i(S),bs=n(S,"LI",{});var lI=s(bs);cue=n(lI,"STRONG",{});var vyt=s(cue);kbo=r(vyt,"big_bird"),vyt.forEach(t),Sbo=r(lI," \u2014 "),uD=n(lI,"A",{href:!0});var byt=s(uD);Rbo=r(byt,"BigBirdTokenizer"),byt.forEach(t),Pbo=r(lI," or "),pD=n(lI,"A",{href:!0});var Fyt=s(pD);Bbo=r(Fyt,"BigBirdTokenizerFast"),Fyt.forEach(t),Ibo=r(lI," (BigBird model)"),lI.forEach(t),Nbo=i(S),Fs=n(S,"LI",{});var iI=s(Fs);fue=n(iI,"STRONG",{});var Tyt=s(fue);qbo=r(Tyt,"bigbird_pegasus"),Tyt.forEach(t),jbo=r(iI," \u2014 "),_D=n(iI,"A",{href:!0});var Myt=s(_D);Dbo=r(Myt,"PegasusTokenizer"),Myt.forEach(t),Gbo=r(iI," or "),vD=n(iI,"A",{href:!0});var Eyt=s(vD);Obo=r(Eyt,"PegasusTokenizerFast"),Eyt.forEach(t),Vbo=r(iI," (BigBird-Pegasus model)"),iI.forEach(t),Xbo=i(S),Ts=n(S,"LI",{});var dI=s(Ts);mue=n(dI,"STRONG",{});var Cyt=s(mue);zbo=r(Cyt,"blenderbot"),Cyt.forEach(t),Qbo=r(dI," \u2014 "),bD=n(dI,"A",{href:!0});var wyt=s(bD);Wbo=r(wyt,"BlenderbotTokenizer"),wyt.forEach(t),Ubo=r(dI," or "),FD=n(dI,"A",{href:!0});var Ayt=s(FD);Hbo=r(Ayt,"BlenderbotTokenizerFast"),Ayt.forEach(t),Jbo=r(dI," (Blenderbot model)"),dI.forEach(t),Ybo=i(S),Su=n(S,"LI",{});var Hqe=s(Su);gue=n(Hqe,"STRONG",{});var Lyt=s(gue);Zbo=r(Lyt,"blenderbot-small"),Lyt.forEach(t),Kbo=r(Hqe," \u2014 "),TD=n(Hqe,"A",{href:!0});var yyt=s(TD);e0o=r(yyt,"BlenderbotSmallTokenizer"),yyt.forEach(t),o0o=r(Hqe," (BlenderbotSmall model)"),Hqe.forEach(t),r0o=i(S),Ru=n(S,"LI",{});var Jqe=s(Ru);hue=n(Jqe,"STRONG",{});var xyt=s(hue);t0o=r(xyt,"bloom"),xyt.forEach(t),a0o=r(Jqe," \u2014 "),MD=n(Jqe,"A",{href:!0});var $yt=s(MD);n0o=r($yt,"BloomTokenizerFast"),$yt.forEach(t),s0o=r(Jqe," (BLOOM model)"),Jqe.forEach(t),l0o=i(S),Pu=n(S,"LI",{});var Yqe=s(Pu);uue=n(Yqe,"STRONG",{});var kyt=s(uue);i0o=r(kyt,"byt5"),kyt.forEach(t),d0o=r(Yqe," \u2014 "),ED=n(Yqe,"A",{href:!0});var Syt=s(ED);c0o=r(Syt,"ByT5Tokenizer"),Syt.forEach(t),f0o=r(Yqe," (ByT5 model)"),Yqe.forEach(t),m0o=i(S),Ms=n(S,"LI",{});var cI=s(Ms);pue=n(cI,"STRONG",{});var Ryt=s(pue);g0o=r(Ryt,"camembert"),Ryt.forEach(t),h0o=r(cI," \u2014 "),CD=n(cI,"A",{href:!0});var Pyt=s(CD);u0o=r(Pyt,"CamembertTokenizer"),Pyt.forEach(t),p0o=r(cI," or "),wD=n(cI,"A",{href:!0});var Byt=s(wD);_0o=r(Byt,"CamembertTokenizerFast"),Byt.forEach(t),v0o=r(cI," (CamemBERT model)"),cI.forEach(t),b0o=i(S),Bu=n(S,"LI",{});var Zqe=s(Bu);_ue=n(Zqe,"STRONG",{});var Iyt=s(_ue);F0o=r(Iyt,"canine"),Iyt.forEach(t),T0o=r(Zqe," \u2014 "),AD=n(Zqe,"A",{href:!0});var Nyt=s(AD);M0o=r(Nyt,"CanineTokenizer"),Nyt.forEach(t),E0o=r(Zqe," (CANINE model)"),Zqe.forEach(t),C0o=i(S),Es=n(S,"LI",{});var fI=s(Es);vue=n(fI,"STRONG",{});var qyt=s(vue);w0o=r(qyt,"clip"),qyt.forEach(t),A0o=r(fI," \u2014 "),LD=n(fI,"A",{href:!0});var jyt=s(LD);L0o=r(jyt,"CLIPTokenizer"),jyt.forEach(t),y0o=r(fI," or "),yD=n(fI,"A",{href:!0});var Dyt=s(yD);x0o=r(Dyt,"CLIPTokenizerFast"),Dyt.forEach(t),$0o=r(fI," (CLIP model)"),fI.forEach(t),k0o=i(S),Cs=n(S,"LI",{});var mI=s(Cs);bue=n(mI,"STRONG",{});var Gyt=s(bue);S0o=r(Gyt,"codegen"),Gyt.forEach(t),R0o=r(mI," \u2014 "),xD=n(mI,"A",{href:!0});var Oyt=s(xD);P0o=r(Oyt,"CodeGenTokenizer"),Oyt.forEach(t),B0o=r(mI," or "),$D=n(mI,"A",{href:!0});var Vyt=s($D);I0o=r(Vyt,"CodeGenTokenizerFast"),Vyt.forEach(t),N0o=r(mI," (CodeGen model)"),mI.forEach(t),q0o=i(S),ws=n(S,"LI",{});var gI=s(ws);Fue=n(gI,"STRONG",{});var Xyt=s(Fue);j0o=r(Xyt,"convbert"),Xyt.forEach(t),D0o=r(gI," \u2014 "),kD=n(gI,"A",{href:!0});var zyt=s(kD);G0o=r(zyt,"ConvBertTokenizer"),zyt.forEach(t),O0o=r(gI," or "),SD=n(gI,"A",{href:!0});var Qyt=s(SD);V0o=r(Qyt,"ConvBertTokenizerFast"),Qyt.forEach(t),X0o=r(gI," (ConvBERT model)"),gI.forEach(t),z0o=i(S),As=n(S,"LI",{});var hI=s(As);Tue=n(hI,"STRONG",{});var Wyt=s(Tue);Q0o=r(Wyt,"cpm"),Wyt.forEach(t),W0o=r(hI," \u2014 "),RD=n(hI,"A",{href:!0});var Uyt=s(RD);U0o=r(Uyt,"CpmTokenizer"),Uyt.forEach(t),H0o=r(hI," or "),PD=n(hI,"A",{href:!0});var Hyt=s(PD);J0o=r(Hyt,"CpmTokenizerFast"),Hyt.forEach(t),Y0o=r(hI," (CPM model)"),hI.forEach(t),Z0o=i(S),Iu=n(S,"LI",{});var Kqe=s(Iu);Mue=n(Kqe,"STRONG",{});var Jyt=s(Mue);K0o=r(Jyt,"ctrl"),Jyt.forEach(t),eFo=r(Kqe," \u2014 "),BD=n(Kqe,"A",{href:!0});var Yyt=s(BD);oFo=r(Yyt,"CTRLTokenizer"),Yyt.forEach(t),rFo=r(Kqe," (CTRL model)"),Kqe.forEach(t),tFo=i(S),Ls=n(S,"LI",{});var uI=s(Ls);Eue=n(uI,"STRONG",{});var Zyt=s(Eue);aFo=r(Zyt,"data2vec-text"),Zyt.forEach(t),nFo=r(uI," \u2014 "),ID=n(uI,"A",{href:!0});var Kyt=s(ID);sFo=r(Kyt,"RobertaTokenizer"),Kyt.forEach(t),lFo=r(uI," or "),ND=n(uI,"A",{href:!0});var e9t=s(ND);iFo=r(e9t,"RobertaTokenizerFast"),e9t.forEach(t),dFo=r(uI," (Data2VecText model)"),uI.forEach(t),cFo=i(S),ys=n(S,"LI",{});var pI=s(ys);Cue=n(pI,"STRONG",{});var o9t=s(Cue);fFo=r(o9t,"deberta"),o9t.forEach(t),mFo=r(pI," \u2014 "),qD=n(pI,"A",{href:!0});var r9t=s(qD);gFo=r(r9t,"DebertaTokenizer"),r9t.forEach(t),hFo=r(pI," or "),jD=n(pI,"A",{href:!0});var t9t=s(jD);uFo=r(t9t,"DebertaTokenizerFast"),t9t.forEach(t),pFo=r(pI," (DeBERTa model)"),pI.forEach(t),_Fo=i(S),xs=n(S,"LI",{});var _I=s(xs);wue=n(_I,"STRONG",{});var a9t=s(wue);vFo=r(a9t,"deberta-v2"),a9t.forEach(t),bFo=r(_I," \u2014 "),DD=n(_I,"A",{href:!0});var n9t=s(DD);FFo=r(n9t,"DebertaV2Tokenizer"),n9t.forEach(t),TFo=r(_I," or "),GD=n(_I,"A",{href:!0});var s9t=s(GD);MFo=r(s9t,"DebertaV2TokenizerFast"),s9t.forEach(t),EFo=r(_I," (DeBERTa-v2 model)"),_I.forEach(t),CFo=i(S),$s=n(S,"LI",{});var vI=s($s);Aue=n(vI,"STRONG",{});var l9t=s(Aue);wFo=r(l9t,"distilbert"),l9t.forEach(t),AFo=r(vI," \u2014 "),OD=n(vI,"A",{href:!0});var i9t=s(OD);LFo=r(i9t,"DistilBertTokenizer"),i9t.forEach(t),yFo=r(vI," or "),VD=n(vI,"A",{href:!0});var d9t=s(VD);xFo=r(d9t,"DistilBertTokenizerFast"),d9t.forEach(t),$Fo=r(vI," (DistilBERT model)"),vI.forEach(t),kFo=i(S),ks=n(S,"LI",{});var bI=s(ks);Lue=n(bI,"STRONG",{});var c9t=s(Lue);SFo=r(c9t,"dpr"),c9t.forEach(t),RFo=r(bI," \u2014 "),XD=n(bI,"A",{href:!0});var f9t=s(XD);PFo=r(f9t,"DPRQuestionEncoderTokenizer"),f9t.forEach(t),BFo=r(bI," or "),zD=n(bI,"A",{href:!0});var m9t=s(zD);IFo=r(m9t,"DPRQuestionEncoderTokenizerFast"),m9t.forEach(t),NFo=r(bI," (DPR model)"),bI.forEach(t),qFo=i(S),Ss=n(S,"LI",{});var FI=s(Ss);yue=n(FI,"STRONG",{});var g9t=s(yue);jFo=r(g9t,"electra"),g9t.forEach(t),DFo=r(FI," \u2014 "),QD=n(FI,"A",{href:!0});var h9t=s(QD);GFo=r(h9t,"ElectraTokenizer"),h9t.forEach(t),OFo=r(FI," or "),WD=n(FI,"A",{href:!0});var u9t=s(WD);VFo=r(u9t,"ElectraTokenizerFast"),u9t.forEach(t),XFo=r(FI," (ELECTRA model)"),FI.forEach(t),zFo=i(S),Rs=n(S,"LI",{});var TI=s(Rs);xue=n(TI,"STRONG",{});var p9t=s(xue);QFo=r(p9t,"ernie"),p9t.forEach(t),WFo=r(TI," \u2014 "),UD=n(TI,"A",{href:!0});var _9t=s(UD);UFo=r(_9t,"BertTokenizer"),_9t.forEach(t),HFo=r(TI," or "),HD=n(TI,"A",{href:!0});var v9t=s(HD);JFo=r(v9t,"BertTokenizerFast"),v9t.forEach(t),YFo=r(TI," (ERNIE model)"),TI.forEach(t),ZFo=i(S),Nu=n(S,"LI",{});var eje=s(Nu);$ue=n(eje,"STRONG",{});var b9t=s($ue);KFo=r(b9t,"esm"),b9t.forEach(t),eTo=r(eje," \u2014 "),JD=n(eje,"A",{href:!0});var F9t=s(JD);oTo=r(F9t,"EsmTokenizer"),F9t.forEach(t),rTo=r(eje," (ESM model)"),eje.forEach(t),tTo=i(S),qu=n(S,"LI",{});var oje=s(qu);kue=n(oje,"STRONG",{});var T9t=s(kue);aTo=r(T9t,"flaubert"),T9t.forEach(t),nTo=r(oje," \u2014 "),YD=n(oje,"A",{href:!0});var M9t=s(YD);sTo=r(M9t,"FlaubertTokenizer"),M9t.forEach(t),lTo=r(oje," (FlauBERT model)"),oje.forEach(t),iTo=i(S),Ps=n(S,"LI",{});var MI=s(Ps);Sue=n(MI,"STRONG",{});var E9t=s(Sue);dTo=r(E9t,"fnet"),E9t.forEach(t),cTo=r(MI," \u2014 "),ZD=n(MI,"A",{href:!0});var C9t=s(ZD);fTo=r(C9t,"FNetTokenizer"),C9t.forEach(t),mTo=r(MI," or "),KD=n(MI,"A",{href:!0});var w9t=s(KD);gTo=r(w9t,"FNetTokenizerFast"),w9t.forEach(t),hTo=r(MI," (FNet model)"),MI.forEach(t),uTo=i(S),ju=n(S,"LI",{});var rje=s(ju);Rue=n(rje,"STRONG",{});var A9t=s(Rue);pTo=r(A9t,"fsmt"),A9t.forEach(t),_To=r(rje," \u2014 "),eG=n(rje,"A",{href:!0});var L9t=s(eG);vTo=r(L9t,"FSMTTokenizer"),L9t.forEach(t),bTo=r(rje," (FairSeq Machine-Translation model)"),rje.forEach(t),FTo=i(S),Bs=n(S,"LI",{});var EI=s(Bs);Pue=n(EI,"STRONG",{});var y9t=s(Pue);TTo=r(y9t,"funnel"),y9t.forEach(t),MTo=r(EI," \u2014 "),oG=n(EI,"A",{href:!0});var x9t=s(oG);ETo=r(x9t,"FunnelTokenizer"),x9t.forEach(t),CTo=r(EI," or "),rG=n(EI,"A",{href:!0});var $9t=s(rG);wTo=r($9t,"FunnelTokenizerFast"),$9t.forEach(t),ATo=r(EI," (Funnel Transformer model)"),EI.forEach(t),LTo=i(S),Is=n(S,"LI",{});var CI=s(Is);Bue=n(CI,"STRONG",{});var k9t=s(Bue);yTo=r(k9t,"gpt2"),k9t.forEach(t),xTo=r(CI," \u2014 "),tG=n(CI,"A",{href:!0});var S9t=s(tG);$To=r(S9t,"GPT2Tokenizer"),S9t.forEach(t),kTo=r(CI," or "),aG=n(CI,"A",{href:!0});var R9t=s(aG);STo=r(R9t,"GPT2TokenizerFast"),R9t.forEach(t),RTo=r(CI," (OpenAI GPT-2 model)"),CI.forEach(t),PTo=i(S),Ns=n(S,"LI",{});var wI=s(Ns);Iue=n(wI,"STRONG",{});var P9t=s(Iue);BTo=r(P9t,"gpt_neo"),P9t.forEach(t),ITo=r(wI," \u2014 "),nG=n(wI,"A",{href:!0});var B9t=s(nG);NTo=r(B9t,"GPT2Tokenizer"),B9t.forEach(t),qTo=r(wI," or "),sG=n(wI,"A",{href:!0});var I9t=s(sG);jTo=r(I9t,"GPT2TokenizerFast"),I9t.forEach(t),DTo=r(wI," (GPT Neo model)"),wI.forEach(t),GTo=i(S),Du=n(S,"LI",{});var tje=s(Du);Nue=n(tje,"STRONG",{});var N9t=s(Nue);OTo=r(N9t,"gpt_neox"),N9t.forEach(t),VTo=r(tje," \u2014 "),lG=n(tje,"A",{href:!0});var q9t=s(lG);XTo=r(q9t,"GPTNeoXTokenizerFast"),q9t.forEach(t),zTo=r(tje," (GPT NeoX model)"),tje.forEach(t),QTo=i(S),Gu=n(S,"LI",{});var aje=s(Gu);que=n(aje,"STRONG",{});var j9t=s(que);WTo=r(j9t,"gpt_neox_japanese"),j9t.forEach(t),UTo=r(aje," \u2014 "),iG=n(aje,"A",{href:!0});var D9t=s(iG);HTo=r(D9t,"GPTNeoXJapaneseTokenizer"),D9t.forEach(t),JTo=r(aje," (GPT NeoX Japanese model)"),aje.forEach(t),YTo=i(S),qs=n(S,"LI",{});var AI=s(qs);jue=n(AI,"STRONG",{});var G9t=s(jue);ZTo=r(G9t,"gptj"),G9t.forEach(t),KTo=r(AI," \u2014 "),dG=n(AI,"A",{href:!0});var O9t=s(dG);eMo=r(O9t,"GPT2Tokenizer"),O9t.forEach(t),oMo=r(AI," or "),cG=n(AI,"A",{href:!0});var V9t=s(cG);rMo=r(V9t,"GPT2TokenizerFast"),V9t.forEach(t),tMo=r(AI," (GPT-J model)"),AI.forEach(t),aMo=i(S),js=n(S,"LI",{});var LI=s(js);Due=n(LI,"STRONG",{});var X9t=s(Due);nMo=r(X9t,"groupvit"),X9t.forEach(t),sMo=r(LI," \u2014 "),fG=n(LI,"A",{href:!0});var z9t=s(fG);lMo=r(z9t,"CLIPTokenizer"),z9t.forEach(t),iMo=r(LI," or "),mG=n(LI,"A",{href:!0});var Q9t=s(mG);dMo=r(Q9t,"CLIPTokenizerFast"),Q9t.forEach(t),cMo=r(LI," (GroupViT model)"),LI.forEach(t),fMo=i(S),Ds=n(S,"LI",{});var yI=s(Ds);Gue=n(yI,"STRONG",{});var W9t=s(Gue);mMo=r(W9t,"herbert"),W9t.forEach(t),gMo=r(yI," \u2014 "),gG=n(yI,"A",{href:!0});var U9t=s(gG);hMo=r(U9t,"HerbertTokenizer"),U9t.forEach(t),uMo=r(yI," or "),hG=n(yI,"A",{href:!0});var H9t=s(hG);pMo=r(H9t,"HerbertTokenizerFast"),H9t.forEach(t),_Mo=r(yI," (HerBERT model)"),yI.forEach(t),vMo=i(S),Ou=n(S,"LI",{});var nje=s(Ou);Oue=n(nje,"STRONG",{});var J9t=s(Oue);bMo=r(J9t,"hubert"),J9t.forEach(t),FMo=r(nje," \u2014 "),uG=n(nje,"A",{href:!0});var Y9t=s(uG);TMo=r(Y9t,"Wav2Vec2CTCTokenizer"),Y9t.forEach(t),MMo=r(nje," (Hubert model)"),nje.forEach(t),EMo=i(S),Gs=n(S,"LI",{});var xI=s(Gs);Vue=n(xI,"STRONG",{});var Z9t=s(Vue);CMo=r(Z9t,"ibert"),Z9t.forEach(t),wMo=r(xI," \u2014 "),pG=n(xI,"A",{href:!0});var K9t=s(pG);AMo=r(K9t,"RobertaTokenizer"),K9t.forEach(t),LMo=r(xI," or "),_G=n(xI,"A",{href:!0});var ext=s(_G);yMo=r(ext,"RobertaTokenizerFast"),ext.forEach(t),xMo=r(xI," (I-BERT model)"),xI.forEach(t),$Mo=i(S),Os=n(S,"LI",{});var $I=s(Os);Xue=n($I,"STRONG",{});var oxt=s(Xue);kMo=r(oxt,"layoutlm"),oxt.forEach(t),SMo=r($I," \u2014 "),vG=n($I,"A",{href:!0});var rxt=s(vG);RMo=r(rxt,"LayoutLMTokenizer"),rxt.forEach(t),PMo=r($I," or "),bG=n($I,"A",{href:!0});var txt=s(bG);BMo=r(txt,"LayoutLMTokenizerFast"),txt.forEach(t),IMo=r($I," (LayoutLM model)"),$I.forEach(t),NMo=i(S),Vs=n(S,"LI",{});var kI=s(Vs);zue=n(kI,"STRONG",{});var axt=s(zue);qMo=r(axt,"layoutlmv2"),axt.forEach(t),jMo=r(kI," \u2014 "),FG=n(kI,"A",{href:!0});var nxt=s(FG);DMo=r(nxt,"LayoutLMv2Tokenizer"),nxt.forEach(t),GMo=r(kI," or "),TG=n(kI,"A",{href:!0});var sxt=s(TG);OMo=r(sxt,"LayoutLMv2TokenizerFast"),sxt.forEach(t),VMo=r(kI," (LayoutLMv2 model)"),kI.forEach(t),XMo=i(S),Xs=n(S,"LI",{});var SI=s(Xs);Que=n(SI,"STRONG",{});var lxt=s(Que);zMo=r(lxt,"layoutlmv3"),lxt.forEach(t),QMo=r(SI," \u2014 "),MG=n(SI,"A",{href:!0});var ixt=s(MG);WMo=r(ixt,"LayoutLMv3Tokenizer"),ixt.forEach(t),UMo=r(SI," or "),EG=n(SI,"A",{href:!0});var dxt=s(EG);HMo=r(dxt,"LayoutLMv3TokenizerFast"),dxt.forEach(t),JMo=r(SI," (LayoutLMv3 model)"),SI.forEach(t),YMo=i(S),zs=n(S,"LI",{});var RI=s(zs);Wue=n(RI,"STRONG",{});var cxt=s(Wue);ZMo=r(cxt,"layoutxlm"),cxt.forEach(t),KMo=r(RI," \u2014 "),CG=n(RI,"A",{href:!0});var fxt=s(CG);eEo=r(fxt,"LayoutXLMTokenizer"),fxt.forEach(t),oEo=r(RI," or "),wG=n(RI,"A",{href:!0});var mxt=s(wG);rEo=r(mxt,"LayoutXLMTokenizerFast"),mxt.forEach(t),tEo=r(RI," (LayoutXLM model)"),RI.forEach(t),aEo=i(S),Qs=n(S,"LI",{});var PI=s(Qs);Uue=n(PI,"STRONG",{});var gxt=s(Uue);nEo=r(gxt,"led"),gxt.forEach(t),sEo=r(PI," \u2014 "),AG=n(PI,"A",{href:!0});var hxt=s(AG);lEo=r(hxt,"LEDTokenizer"),hxt.forEach(t),iEo=r(PI," or "),LG=n(PI,"A",{href:!0});var uxt=s(LG);dEo=r(uxt,"LEDTokenizerFast"),uxt.forEach(t),cEo=r(PI," (LED model)"),PI.forEach(t),fEo=i(S),Ws=n(S,"LI",{});var BI=s(Ws);Hue=n(BI,"STRONG",{});var pxt=s(Hue);mEo=r(pxt,"lilt"),pxt.forEach(t),gEo=r(BI," \u2014 "),yG=n(BI,"A",{href:!0});var _xt=s(yG);hEo=r(_xt,"LayoutLMv3Tokenizer"),_xt.forEach(t),uEo=r(BI," or "),xG=n(BI,"A",{href:!0});var vxt=s(xG);pEo=r(vxt,"LayoutLMv3TokenizerFast"),vxt.forEach(t),_Eo=r(BI," (LiLT model)"),BI.forEach(t),vEo=i(S),Us=n(S,"LI",{});var II=s(Us);Jue=n(II,"STRONG",{});var bxt=s(Jue);bEo=r(bxt,"longformer"),bxt.forEach(t),FEo=r(II," \u2014 "),$G=n(II,"A",{href:!0});var Fxt=s($G);TEo=r(Fxt,"LongformerTokenizer"),Fxt.forEach(t),MEo=r(II," or "),kG=n(II,"A",{href:!0});var Txt=s(kG);EEo=r(Txt,"LongformerTokenizerFast"),Txt.forEach(t),CEo=r(II," (Longformer model)"),II.forEach(t),wEo=i(S),Hs=n(S,"LI",{});var NI=s(Hs);Yue=n(NI,"STRONG",{});var Mxt=s(Yue);AEo=r(Mxt,"longt5"),Mxt.forEach(t),LEo=r(NI," \u2014 "),SG=n(NI,"A",{href:!0});var Ext=s(SG);yEo=r(Ext,"T5Tokenizer"),Ext.forEach(t),xEo=r(NI," or "),RG=n(NI,"A",{href:!0});var Cxt=s(RG);$Eo=r(Cxt,"T5TokenizerFast"),Cxt.forEach(t),kEo=r(NI," (LongT5 model)"),NI.forEach(t),SEo=i(S),Vu=n(S,"LI",{});var sje=s(Vu);Zue=n(sje,"STRONG",{});var wxt=s(Zue);REo=r(wxt,"luke"),wxt.forEach(t),PEo=r(sje," \u2014 "),PG=n(sje,"A",{href:!0});var Axt=s(PG);BEo=r(Axt,"LukeTokenizer"),Axt.forEach(t),IEo=r(sje," (LUKE model)"),sje.forEach(t),NEo=i(S),Js=n(S,"LI",{});var qI=s(Js);Kue=n(qI,"STRONG",{});var Lxt=s(Kue);qEo=r(Lxt,"lxmert"),Lxt.forEach(t),jEo=r(qI," \u2014 "),BG=n(qI,"A",{href:!0});var yxt=s(BG);DEo=r(yxt,"LxmertTokenizer"),yxt.forEach(t),GEo=r(qI," or "),IG=n(qI,"A",{href:!0});var xxt=s(IG);OEo=r(xxt,"LxmertTokenizerFast"),xxt.forEach(t),VEo=r(qI," (LXMERT model)"),qI.forEach(t),XEo=i(S),Xu=n(S,"LI",{});var lje=s(Xu);epe=n(lje,"STRONG",{});var $xt=s(epe);zEo=r($xt,"m2m_100"),$xt.forEach(t),QEo=r(lje," \u2014 "),NG=n(lje,"A",{href:!0});var kxt=s(NG);WEo=r(kxt,"M2M100Tokenizer"),kxt.forEach(t),UEo=r(lje," (M2M100 model)"),lje.forEach(t),HEo=i(S),zu=n(S,"LI",{});var ije=s(zu);ope=n(ije,"STRONG",{});var Sxt=s(ope);JEo=r(Sxt,"marian"),Sxt.forEach(t),YEo=r(ije," \u2014 "),qG=n(ije,"A",{href:!0});var Rxt=s(qG);ZEo=r(Rxt,"MarianTokenizer"),Rxt.forEach(t),KEo=r(ije," (Marian model)"),ije.forEach(t),eCo=i(S),Ys=n(S,"LI",{});var jI=s(Ys);rpe=n(jI,"STRONG",{});var Pxt=s(rpe);oCo=r(Pxt,"mbart"),Pxt.forEach(t),rCo=r(jI," \u2014 "),jG=n(jI,"A",{href:!0});var Bxt=s(jG);tCo=r(Bxt,"MBartTokenizer"),Bxt.forEach(t),aCo=r(jI," or "),DG=n(jI,"A",{href:!0});var Ixt=s(DG);nCo=r(Ixt,"MBartTokenizerFast"),Ixt.forEach(t),sCo=r(jI," (mBART model)"),jI.forEach(t),lCo=i(S),Zs=n(S,"LI",{});var DI=s(Zs);tpe=n(DI,"STRONG",{});var Nxt=s(tpe);iCo=r(Nxt,"mbart50"),Nxt.forEach(t),dCo=r(DI," \u2014 "),GG=n(DI,"A",{href:!0});var qxt=s(GG);cCo=r(qxt,"MBart50Tokenizer"),qxt.forEach(t),fCo=r(DI," or "),OG=n(DI,"A",{href:!0});var jxt=s(OG);mCo=r(jxt,"MBart50TokenizerFast"),jxt.forEach(t),gCo=r(DI," (mBART-50 model)"),DI.forEach(t),hCo=i(S),Ks=n(S,"LI",{});var GI=s(Ks);ape=n(GI,"STRONG",{});var Dxt=s(ape);uCo=r(Dxt,"megatron-bert"),Dxt.forEach(t),pCo=r(GI," \u2014 "),VG=n(GI,"A",{href:!0});var Gxt=s(VG);_Co=r(Gxt,"BertTokenizer"),Gxt.forEach(t),vCo=r(GI," or "),XG=n(GI,"A",{href:!0});var Oxt=s(XG);bCo=r(Oxt,"BertTokenizerFast"),Oxt.forEach(t),FCo=r(GI," (Megatron-BERT model)"),GI.forEach(t),TCo=i(S),Qu=n(S,"LI",{});var dje=s(Qu);npe=n(dje,"STRONG",{});var Vxt=s(npe);MCo=r(Vxt,"mluke"),Vxt.forEach(t),ECo=r(dje," \u2014 "),zG=n(dje,"A",{href:!0});var Xxt=s(zG);CCo=r(Xxt,"MLukeTokenizer"),Xxt.forEach(t),wCo=r(dje," (mLUKE model)"),dje.forEach(t),ACo=i(S),el=n(S,"LI",{});var OI=s(el);spe=n(OI,"STRONG",{});var zxt=s(spe);LCo=r(zxt,"mobilebert"),zxt.forEach(t),yCo=r(OI," \u2014 "),QG=n(OI,"A",{href:!0});var Qxt=s(QG);xCo=r(Qxt,"MobileBertTokenizer"),Qxt.forEach(t),$Co=r(OI," or "),WG=n(OI,"A",{href:!0});var Wxt=s(WG);kCo=r(Wxt,"MobileBertTokenizerFast"),Wxt.forEach(t),SCo=r(OI," (MobileBERT model)"),OI.forEach(t),RCo=i(S),ol=n(S,"LI",{});var VI=s(ol);lpe=n(VI,"STRONG",{});var Uxt=s(lpe);PCo=r(Uxt,"mpnet"),Uxt.forEach(t),BCo=r(VI," \u2014 "),UG=n(VI,"A",{href:!0});var Hxt=s(UG);ICo=r(Hxt,"MPNetTokenizer"),Hxt.forEach(t),NCo=r(VI," or "),HG=n(VI,"A",{href:!0});var Jxt=s(HG);qCo=r(Jxt,"MPNetTokenizerFast"),Jxt.forEach(t),jCo=r(VI," (MPNet model)"),VI.forEach(t),DCo=i(S),rl=n(S,"LI",{});var XI=s(rl);ipe=n(XI,"STRONG",{});var Yxt=s(ipe);GCo=r(Yxt,"mt5"),Yxt.forEach(t),OCo=r(XI," \u2014 "),JG=n(XI,"A",{href:!0});var Zxt=s(JG);VCo=r(Zxt,"MT5Tokenizer"),Zxt.forEach(t),XCo=r(XI," or "),YG=n(XI,"A",{href:!0});var Kxt=s(YG);zCo=r(Kxt,"MT5TokenizerFast"),Kxt.forEach(t),QCo=r(XI," (MT5 model)"),XI.forEach(t),WCo=i(S),tl=n(S,"LI",{});var zI=s(tl);dpe=n(zI,"STRONG",{});var e$t=s(dpe);UCo=r(e$t,"mvp"),e$t.forEach(t),HCo=r(zI," \u2014 "),ZG=n(zI,"A",{href:!0});var o$t=s(ZG);JCo=r(o$t,"MvpTokenizer"),o$t.forEach(t),YCo=r(zI," or "),KG=n(zI,"A",{href:!0});var r$t=s(KG);ZCo=r(r$t,"MvpTokenizerFast"),r$t.forEach(t),KCo=r(zI," (MVP model)"),zI.forEach(t),e3o=i(S),al=n(S,"LI",{});var QI=s(al);cpe=n(QI,"STRONG",{});var t$t=s(cpe);o3o=r(t$t,"nezha"),t$t.forEach(t),r3o=r(QI," \u2014 "),eO=n(QI,"A",{href:!0});var a$t=s(eO);t3o=r(a$t,"BertTokenizer"),a$t.forEach(t),a3o=r(QI," or "),oO=n(QI,"A",{href:!0});var n$t=s(oO);n3o=r(n$t,"BertTokenizerFast"),n$t.forEach(t),s3o=r(QI," (Nezha model)"),QI.forEach(t),l3o=i(S),nl=n(S,"LI",{});var WI=s(nl);fpe=n(WI,"STRONG",{});var s$t=s(fpe);i3o=r(s$t,"nllb"),s$t.forEach(t),d3o=r(WI," \u2014 "),rO=n(WI,"A",{href:!0});var l$t=s(rO);c3o=r(l$t,"NllbTokenizer"),l$t.forEach(t),f3o=r(WI," or "),tO=n(WI,"A",{href:!0});var i$t=s(tO);m3o=r(i$t,"NllbTokenizerFast"),i$t.forEach(t),g3o=r(WI," (NLLB model)"),WI.forEach(t),h3o=i(S),sl=n(S,"LI",{});var UI=s(sl);mpe=n(UI,"STRONG",{});var d$t=s(mpe);u3o=r(d$t,"nystromformer"),d$t.forEach(t),p3o=r(UI," \u2014 "),aO=n(UI,"A",{href:!0});var c$t=s(aO);_3o=r(c$t,"AlbertTokenizer"),c$t.forEach(t),v3o=r(UI," or "),nO=n(UI,"A",{href:!0});var f$t=s(nO);b3o=r(f$t,"AlbertTokenizerFast"),f$t.forEach(t),F3o=r(UI," (Nystr\xF6mformer model)"),UI.forEach(t),T3o=i(S),ll=n(S,"LI",{});var HI=s(ll);gpe=n(HI,"STRONG",{});var m$t=s(gpe);M3o=r(m$t,"openai-gpt"),m$t.forEach(t),E3o=r(HI," \u2014 "),sO=n(HI,"A",{href:!0});var g$t=s(sO);C3o=r(g$t,"OpenAIGPTTokenizer"),g$t.forEach(t),w3o=r(HI," or "),lO=n(HI,"A",{href:!0});var h$t=s(lO);A3o=r(h$t,"OpenAIGPTTokenizerFast"),h$t.forEach(t),L3o=r(HI," (OpenAI GPT model)"),HI.forEach(t),y3o=i(S),Wu=n(S,"LI",{});var cje=s(Wu);hpe=n(cje,"STRONG",{});var u$t=s(hpe);x3o=r(u$t,"opt"),u$t.forEach(t),$3o=r(cje," \u2014 "),iO=n(cje,"A",{href:!0});var p$t=s(iO);k3o=r(p$t,"GPT2Tokenizer"),p$t.forEach(t),S3o=r(cje," (OPT model)"),cje.forEach(t),R3o=i(S),il=n(S,"LI",{});var JI=s(il);upe=n(JI,"STRONG",{});var _$t=s(upe);P3o=r(_$t,"owlvit"),_$t.forEach(t),B3o=r(JI," \u2014 "),dO=n(JI,"A",{href:!0});var v$t=s(dO);I3o=r(v$t,"CLIPTokenizer"),v$t.forEach(t),N3o=r(JI," or "),cO=n(JI,"A",{href:!0});var b$t=s(cO);q3o=r(b$t,"CLIPTokenizerFast"),b$t.forEach(t),j3o=r(JI," (OWL-ViT model)"),JI.forEach(t),D3o=i(S),dl=n(S,"LI",{});var YI=s(dl);ppe=n(YI,"STRONG",{});var F$t=s(ppe);G3o=r(F$t,"pegasus"),F$t.forEach(t),O3o=r(YI," \u2014 "),fO=n(YI,"A",{href:!0});var T$t=s(fO);V3o=r(T$t,"PegasusTokenizer"),T$t.forEach(t),X3o=r(YI," or "),mO=n(YI,"A",{href:!0});var M$t=s(mO);z3o=r(M$t,"PegasusTokenizerFast"),M$t.forEach(t),Q3o=r(YI," (Pegasus model)"),YI.forEach(t),W3o=i(S),cl=n(S,"LI",{});var ZI=s(cl);_pe=n(ZI,"STRONG",{});var E$t=s(_pe);U3o=r(E$t,"pegasus_x"),E$t.forEach(t),H3o=r(ZI," \u2014 "),gO=n(ZI,"A",{href:!0});var C$t=s(gO);J3o=r(C$t,"PegasusTokenizer"),C$t.forEach(t),Y3o=r(ZI," or "),hO=n(ZI,"A",{href:!0});var w$t=s(hO);Z3o=r(w$t,"PegasusTokenizerFast"),w$t.forEach(t),K3o=r(ZI," (PEGASUS-X model)"),ZI.forEach(t),e5o=i(S),Uu=n(S,"LI",{});var fje=s(Uu);vpe=n(fje,"STRONG",{});var A$t=s(vpe);o5o=r(A$t,"perceiver"),A$t.forEach(t),r5o=r(fje," \u2014 "),uO=n(fje,"A",{href:!0});var L$t=s(uO);t5o=r(L$t,"PerceiverTokenizer"),L$t.forEach(t),a5o=r(fje," (Perceiver model)"),fje.forEach(t),n5o=i(S),Hu=n(S,"LI",{});var mje=s(Hu);bpe=n(mje,"STRONG",{});var y$t=s(bpe);s5o=r(y$t,"phobert"),y$t.forEach(t),l5o=r(mje," \u2014 "),pO=n(mje,"A",{href:!0});var x$t=s(pO);i5o=r(x$t,"PhobertTokenizer"),x$t.forEach(t),d5o=r(mje," (PhoBERT model)"),mje.forEach(t),c5o=i(S),Ju=n(S,"LI",{});var gje=s(Ju);Fpe=n(gje,"STRONG",{});var $$t=s(Fpe);f5o=r($$t,"plbart"),$$t.forEach(t),m5o=r(gje," \u2014 "),_O=n(gje,"A",{href:!0});var k$t=s(_O);g5o=r(k$t,"PLBartTokenizer"),k$t.forEach(t),h5o=r(gje," (PLBart model)"),gje.forEach(t),u5o=i(S),Yu=n(S,"LI",{});var hje=s(Yu);Tpe=n(hje,"STRONG",{});var S$t=s(Tpe);p5o=r(S$t,"prophetnet"),S$t.forEach(t),_5o=r(hje," \u2014 "),vO=n(hje,"A",{href:!0});var R$t=s(vO);v5o=r(R$t,"ProphetNetTokenizer"),R$t.forEach(t),b5o=r(hje," (ProphetNet model)"),hje.forEach(t),F5o=i(S),fl=n(S,"LI",{});var KI=s(fl);Mpe=n(KI,"STRONG",{});var P$t=s(Mpe);T5o=r(P$t,"qdqbert"),P$t.forEach(t),M5o=r(KI," \u2014 "),bO=n(KI,"A",{href:!0});var B$t=s(bO);E5o=r(B$t,"BertTokenizer"),B$t.forEach(t),C5o=r(KI," or "),FO=n(KI,"A",{href:!0});var I$t=s(FO);w5o=r(I$t,"BertTokenizerFast"),I$t.forEach(t),A5o=r(KI," (QDQBert model)"),KI.forEach(t),L5o=i(S),Zu=n(S,"LI",{});var uje=s(Zu);Epe=n(uje,"STRONG",{});var N$t=s(Epe);y5o=r(N$t,"rag"),N$t.forEach(t),x5o=r(uje," \u2014 "),TO=n(uje,"A",{href:!0});var q$t=s(TO);$5o=r(q$t,"RagTokenizer"),q$t.forEach(t),k5o=r(uje," (RAG model)"),uje.forEach(t),S5o=i(S),ml=n(S,"LI",{});var eN=s(ml);Cpe=n(eN,"STRONG",{});var j$t=s(Cpe);R5o=r(j$t,"realm"),j$t.forEach(t),P5o=r(eN," \u2014 "),MO=n(eN,"A",{href:!0});var D$t=s(MO);B5o=r(D$t,"RealmTokenizer"),D$t.forEach(t),I5o=r(eN," or "),EO=n(eN,"A",{href:!0});var G$t=s(EO);N5o=r(G$t,"RealmTokenizerFast"),G$t.forEach(t),q5o=r(eN," (REALM model)"),eN.forEach(t),j5o=i(S),gl=n(S,"LI",{});var oN=s(gl);wpe=n(oN,"STRONG",{});var O$t=s(wpe);D5o=r(O$t,"reformer"),O$t.forEach(t),G5o=r(oN," \u2014 "),CO=n(oN,"A",{href:!0});var V$t=s(CO);O5o=r(V$t,"ReformerTokenizer"),V$t.forEach(t),V5o=r(oN," or "),wO=n(oN,"A",{href:!0});var X$t=s(wO);X5o=r(X$t,"ReformerTokenizerFast"),X$t.forEach(t),z5o=r(oN," (Reformer model)"),oN.forEach(t),Q5o=i(S),hl=n(S,"LI",{});var rN=s(hl);Ape=n(rN,"STRONG",{});var z$t=s(Ape);W5o=r(z$t,"rembert"),z$t.forEach(t),U5o=r(rN," \u2014 "),AO=n(rN,"A",{href:!0});var Q$t=s(AO);H5o=r(Q$t,"RemBertTokenizer"),Q$t.forEach(t),J5o=r(rN," or "),LO=n(rN,"A",{href:!0});var W$t=s(LO);Y5o=r(W$t,"RemBertTokenizerFast"),W$t.forEach(t),Z5o=r(rN," (RemBERT model)"),rN.forEach(t),K5o=i(S),ul=n(S,"LI",{});var tN=s(ul);Lpe=n(tN,"STRONG",{});var U$t=s(Lpe);ewo=r(U$t,"retribert"),U$t.forEach(t),owo=r(tN," \u2014 "),yO=n(tN,"A",{href:!0});var H$t=s(yO);rwo=r(H$t,"RetriBertTokenizer"),H$t.forEach(t),two=r(tN," or "),xO=n(tN,"A",{href:!0});var J$t=s(xO);awo=r(J$t,"RetriBertTokenizerFast"),J$t.forEach(t),nwo=r(tN," (RetriBERT model)"),tN.forEach(t),swo=i(S),pl=n(S,"LI",{});var aN=s(pl);ype=n(aN,"STRONG",{});var Y$t=s(ype);lwo=r(Y$t,"roberta"),Y$t.forEach(t),iwo=r(aN," \u2014 "),$O=n(aN,"A",{href:!0});var Z$t=s($O);dwo=r(Z$t,"RobertaTokenizer"),Z$t.forEach(t),cwo=r(aN," or "),kO=n(aN,"A",{href:!0});var K$t=s(kO);fwo=r(K$t,"RobertaTokenizerFast"),K$t.forEach(t),mwo=r(aN," (RoBERTa model)"),aN.forEach(t),gwo=i(S),_l=n(S,"LI",{});var nN=s(_l);xpe=n(nN,"STRONG",{});var ekt=s(xpe);hwo=r(ekt,"roformer"),ekt.forEach(t),uwo=r(nN," \u2014 "),SO=n(nN,"A",{href:!0});var okt=s(SO);pwo=r(okt,"RoFormerTokenizer"),okt.forEach(t),_wo=r(nN," or "),RO=n(nN,"A",{href:!0});var rkt=s(RO);vwo=r(rkt,"RoFormerTokenizerFast"),rkt.forEach(t),bwo=r(nN," (RoFormer model)"),nN.forEach(t),Fwo=i(S),Ku=n(S,"LI",{});var pje=s(Ku);$pe=n(pje,"STRONG",{});var tkt=s($pe);Two=r(tkt,"speech_to_text"),tkt.forEach(t),Mwo=r(pje," \u2014 "),PO=n(pje,"A",{href:!0});var akt=s(PO);Ewo=r(akt,"Speech2TextTokenizer"),akt.forEach(t),Cwo=r(pje," (Speech2Text model)"),pje.forEach(t),wwo=i(S),ep=n(S,"LI",{});var _je=s(ep);kpe=n(_je,"STRONG",{});var nkt=s(kpe);Awo=r(nkt,"speech_to_text_2"),nkt.forEach(t),Lwo=r(_je," \u2014 "),BO=n(_je,"A",{href:!0});var skt=s(BO);ywo=r(skt,"Speech2Text2Tokenizer"),skt.forEach(t),xwo=r(_je," (Speech2Text2 model)"),_je.forEach(t),$wo=i(S),vl=n(S,"LI",{});var sN=s(vl);Spe=n(sN,"STRONG",{});var lkt=s(Spe);kwo=r(lkt,"splinter"),lkt.forEach(t),Swo=r(sN," \u2014 "),IO=n(sN,"A",{href:!0});var ikt=s(IO);Rwo=r(ikt,"SplinterTokenizer"),ikt.forEach(t),Pwo=r(sN," or "),NO=n(sN,"A",{href:!0});var dkt=s(NO);Bwo=r(dkt,"SplinterTokenizerFast"),dkt.forEach(t),Iwo=r(sN," (Splinter model)"),sN.forEach(t),Nwo=i(S),bl=n(S,"LI",{});var lN=s(bl);Rpe=n(lN,"STRONG",{});var ckt=s(Rpe);qwo=r(ckt,"squeezebert"),ckt.forEach(t),jwo=r(lN," \u2014 "),qO=n(lN,"A",{href:!0});var fkt=s(qO);Dwo=r(fkt,"SqueezeBertTokenizer"),fkt.forEach(t),Gwo=r(lN," or "),jO=n(lN,"A",{href:!0});var mkt=s(jO);Owo=r(mkt,"SqueezeBertTokenizerFast"),mkt.forEach(t),Vwo=r(lN," (SqueezeBERT model)"),lN.forEach(t),Xwo=i(S),Fl=n(S,"LI",{});var iN=s(Fl);Ppe=n(iN,"STRONG",{});var gkt=s(Ppe);zwo=r(gkt,"t5"),gkt.forEach(t),Qwo=r(iN," \u2014 "),DO=n(iN,"A",{href:!0});var hkt=s(DO);Wwo=r(hkt,"T5Tokenizer"),hkt.forEach(t),Uwo=r(iN," or "),GO=n(iN,"A",{href:!0});var ukt=s(GO);Hwo=r(ukt,"T5TokenizerFast"),ukt.forEach(t),Jwo=r(iN," (T5 model)"),iN.forEach(t),Ywo=i(S),op=n(S,"LI",{});var vje=s(op);Bpe=n(vje,"STRONG",{});var pkt=s(Bpe);Zwo=r(pkt,"tapas"),pkt.forEach(t),Kwo=r(vje," \u2014 "),OO=n(vje,"A",{href:!0});var _kt=s(OO);eAo=r(_kt,"TapasTokenizer"),_kt.forEach(t),oAo=r(vje," (TAPAS model)"),vje.forEach(t),rAo=i(S),rp=n(S,"LI",{});var bje=s(rp);Ipe=n(bje,"STRONG",{});var vkt=s(Ipe);tAo=r(vkt,"tapex"),vkt.forEach(t),aAo=r(bje," \u2014 "),VO=n(bje,"A",{href:!0});var bkt=s(VO);nAo=r(bkt,"TapexTokenizer"),bkt.forEach(t),sAo=r(bje," (TAPEX model)"),bje.forEach(t),lAo=i(S),tp=n(S,"LI",{});var Fje=s(tp);Npe=n(Fje,"STRONG",{});var Fkt=s(Npe);iAo=r(Fkt,"transfo-xl"),Fkt.forEach(t),dAo=r(Fje," \u2014 "),XO=n(Fje,"A",{href:!0});var Tkt=s(XO);cAo=r(Tkt,"TransfoXLTokenizer"),Tkt.forEach(t),fAo=r(Fje," (Transformer-XL model)"),Fje.forEach(t),mAo=i(S),Tl=n(S,"LI",{});var dN=s(Tl);qpe=n(dN,"STRONG",{});var Mkt=s(qpe);gAo=r(Mkt,"vilt"),Mkt.forEach(t),hAo=r(dN," \u2014 "),zO=n(dN,"A",{href:!0});var Ekt=s(zO);uAo=r(Ekt,"BertTokenizer"),Ekt.forEach(t),pAo=r(dN," or "),QO=n(dN,"A",{href:!0});var Ckt=s(QO);_Ao=r(Ckt,"BertTokenizerFast"),Ckt.forEach(t),vAo=r(dN," (ViLT model)"),dN.forEach(t),bAo=i(S),Ml=n(S,"LI",{});var cN=s(Ml);jpe=n(cN,"STRONG",{});var wkt=s(jpe);FAo=r(wkt,"visual_bert"),wkt.forEach(t),TAo=r(cN," \u2014 "),WO=n(cN,"A",{href:!0});var Akt=s(WO);MAo=r(Akt,"BertTokenizer"),Akt.forEach(t),EAo=r(cN," or "),UO=n(cN,"A",{href:!0});var Lkt=s(UO);CAo=r(Lkt,"BertTokenizerFast"),Lkt.forEach(t),wAo=r(cN," (VisualBERT model)"),cN.forEach(t),AAo=i(S),ap=n(S,"LI",{});var Tje=s(ap);Dpe=n(Tje,"STRONG",{});var ykt=s(Dpe);LAo=r(ykt,"wav2vec2"),ykt.forEach(t),yAo=r(Tje," \u2014 "),HO=n(Tje,"A",{href:!0});var xkt=s(HO);xAo=r(xkt,"Wav2Vec2CTCTokenizer"),xkt.forEach(t),$Ao=r(Tje," (Wav2Vec2 model)"),Tje.forEach(t),kAo=i(S),np=n(S,"LI",{});var Mje=s(np);Gpe=n(Mje,"STRONG",{});var $kt=s(Gpe);SAo=r($kt,"wav2vec2-conformer"),$kt.forEach(t),RAo=r(Mje," \u2014 "),JO=n(Mje,"A",{href:!0});var kkt=s(JO);PAo=r(kkt,"Wav2Vec2CTCTokenizer"),kkt.forEach(t),BAo=r(Mje," (Wav2Vec2-Conformer model)"),Mje.forEach(t),IAo=i(S),sp=n(S,"LI",{});var Eje=s(sp);Ope=n(Eje,"STRONG",{});var Skt=s(Ope);NAo=r(Skt,"wav2vec2_phoneme"),Skt.forEach(t),qAo=r(Eje," \u2014 "),YO=n(Eje,"A",{href:!0});var Rkt=s(YO);jAo=r(Rkt,"Wav2Vec2PhonemeCTCTokenizer"),Rkt.forEach(t),DAo=r(Eje," (Wav2Vec2Phoneme model)"),Eje.forEach(t),GAo=i(S),lp=n(S,"LI",{});var Cje=s(lp);Vpe=n(Cje,"STRONG",{});var Pkt=s(Vpe);OAo=r(Pkt,"whisper"),Pkt.forEach(t),VAo=r(Cje," \u2014 "),ZO=n(Cje,"A",{href:!0});var Bkt=s(ZO);XAo=r(Bkt,"WhisperTokenizer"),Bkt.forEach(t),zAo=r(Cje," (Whisper model)"),Cje.forEach(t),QAo=i(S),El=n(S,"LI",{});var fN=s(El);Xpe=n(fN,"STRONG",{});var Ikt=s(Xpe);WAo=r(Ikt,"xclip"),Ikt.forEach(t),UAo=r(fN," \u2014 "),KO=n(fN,"A",{href:!0});var Nkt=s(KO);HAo=r(Nkt,"CLIPTokenizer"),Nkt.forEach(t),JAo=r(fN," or "),eV=n(fN,"A",{href:!0});var qkt=s(eV);YAo=r(qkt,"CLIPTokenizerFast"),qkt.forEach(t),ZAo=r(fN," (X-CLIP model)"),fN.forEach(t),KAo=i(S),Cl=n(S,"LI",{});var mN=s(Cl);zpe=n(mN,"STRONG",{});var jkt=s(zpe);e6o=r(jkt,"xglm"),jkt.forEach(t),o6o=r(mN," \u2014 "),oV=n(mN,"A",{href:!0});var Dkt=s(oV);r6o=r(Dkt,"XGLMTokenizer"),Dkt.forEach(t),t6o=r(mN," or "),rV=n(mN,"A",{href:!0});var Gkt=s(rV);a6o=r(Gkt,"XGLMTokenizerFast"),Gkt.forEach(t),n6o=r(mN," (XGLM model)"),mN.forEach(t),s6o=i(S),ip=n(S,"LI",{});var wje=s(ip);Qpe=n(wje,"STRONG",{});var Okt=s(Qpe);l6o=r(Okt,"xlm"),Okt.forEach(t),i6o=r(wje," \u2014 "),tV=n(wje,"A",{href:!0});var Vkt=s(tV);d6o=r(Vkt,"XLMTokenizer"),Vkt.forEach(t),c6o=r(wje," (XLM model)"),wje.forEach(t),f6o=i(S),dp=n(S,"LI",{});var Aje=s(dp);Wpe=n(Aje,"STRONG",{});var Xkt=s(Wpe);m6o=r(Xkt,"xlm-prophetnet"),Xkt.forEach(t),g6o=r(Aje," \u2014 "),aV=n(Aje,"A",{href:!0});var zkt=s(aV);h6o=r(zkt,"XLMProphetNetTokenizer"),zkt.forEach(t),u6o=r(Aje," (XLM-ProphetNet model)"),Aje.forEach(t),p6o=i(S),wl=n(S,"LI",{});var gN=s(wl);Upe=n(gN,"STRONG",{});var Qkt=s(Upe);_6o=r(Qkt,"xlm-roberta"),Qkt.forEach(t),v6o=r(gN," \u2014 "),nV=n(gN,"A",{href:!0});var Wkt=s(nV);b6o=r(Wkt,"XLMRobertaTokenizer"),Wkt.forEach(t),F6o=r(gN," or "),sV=n(gN,"A",{href:!0});var Ukt=s(sV);T6o=r(Ukt,"XLMRobertaTokenizerFast"),Ukt.forEach(t),M6o=r(gN," (XLM-RoBERTa model)"),gN.forEach(t),E6o=i(S),Al=n(S,"LI",{});var hN=s(Al);Hpe=n(hN,"STRONG",{});var Hkt=s(Hpe);C6o=r(Hkt,"xlm-roberta-xl"),Hkt.forEach(t),w6o=r(hN," \u2014 "),lV=n(hN,"A",{href:!0});var Jkt=s(lV);A6o=r(Jkt,"XLMRobertaTokenizer"),Jkt.forEach(t),L6o=r(hN," or "),iV=n(hN,"A",{href:!0});var Ykt=s(iV);y6o=r(Ykt,"XLMRobertaTokenizerFast"),Ykt.forEach(t),x6o=r(hN," (XLM-RoBERTa-XL model)"),hN.forEach(t),$6o=i(S),Ll=n(S,"LI",{});var uN=s(Ll);Jpe=n(uN,"STRONG",{});var Zkt=s(Jpe);k6o=r(Zkt,"xlnet"),Zkt.forEach(t),S6o=r(uN," \u2014 "),dV=n(uN,"A",{href:!0});var Kkt=s(dV);R6o=r(Kkt,"XLNetTokenizer"),Kkt.forEach(t),P6o=r(uN," or "),cV=n(uN,"A",{href:!0});var eSt=s(cV);B6o=r(eSt,"XLNetTokenizerFast"),eSt.forEach(t),I6o=r(uN," (XLNet model)"),uN.forEach(t),N6o=i(S),yl=n(S,"LI",{});var pN=s(yl);Ype=n(pN,"STRONG",{});var oSt=s(Ype);q6o=r(oSt,"yoso"),oSt.forEach(t),j6o=r(pN," \u2014 "),fV=n(pN,"A",{href:!0});var rSt=s(fV);D6o=r(rSt,"AlbertTokenizer"),rSt.forEach(t),G6o=r(pN," or "),mV=n(pN,"A",{href:!0});var tSt=s(mV);O6o=r(tSt,"AlbertTokenizerFast"),tSt.forEach(t),V6o=r(pN," (YOSO model)"),pN.forEach(t),S.forEach(t),X6o=i(Bl),T(cp.$$.fragment,Bl),Bl.forEach(t),z6o=i(Pl),fp=n(Pl,"DIV",{class:!0});var Wno=s(fp);T(M$.$$.fragment,Wno),Q6o=i(Wno),Zpe=n(Wno,"P",{});var aSt=s(Zpe);W6o=r(aSt,"Register a new tokenizer in this mapping."),aSt.forEach(t),Wno.forEach(t),Pl.forEach(t),Pto=i(f),xd=n(f,"H2",{class:!0});var Uno=s(xd);mp=n(Uno,"A",{id:!0,class:!0,href:!0});var nSt=s(mp);Kpe=n(nSt,"SPAN",{});var sSt=s(Kpe);T(E$.$$.fragment,sSt),sSt.forEach(t),nSt.forEach(t),U6o=i(Uno),e_e=n(Uno,"SPAN",{});var lSt=s(e_e);H6o=r(lSt,"AutoFeatureExtractor"),lSt.forEach(t),Uno.forEach(t),Bto=i(f),Po=n(f,"DIV",{class:!0});var Il=s(Po);T(C$.$$.fragment,Il),J6o=i(Il),w$=n(Il,"P",{});var Hno=s(w$);Y6o=r(Hno,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),gV=n(Hno,"A",{href:!0});var iSt=s(gV);Z6o=r(iSt,"AutoFeatureExtractor.from_pretrained()"),iSt.forEach(t),K6o=r(Hno," class method."),Hno.forEach(t),e7o=i(Il),A$=n(Il,"P",{});var Jno=s(A$);o7o=r(Jno,"This class cannot be instantiated directly using "),o_e=n(Jno,"CODE",{});var dSt=s(o_e);r7o=r(dSt,"__init__()"),dSt.forEach(t),t7o=r(Jno," (throws an error)."),Jno.forEach(t),a7o=i(Il),Ye=n(Il,"DIV",{class:!0});var wa=s(Ye);T(L$.$$.fragment,wa),n7o=i(wa),r_e=n(wa,"P",{});var cSt=s(r_e);s7o=r(cSt,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),cSt.forEach(t),l7o=i(wa),an=n(wa,"P",{});var Ky=s(an);i7o=r(Ky,"The feature extractor class to instantiate is selected based on the "),t_e=n(Ky,"CODE",{});var fSt=s(t_e);d7o=r(fSt,"model_type"),fSt.forEach(t),c7o=r(Ky,` property of the config object
(either passed as an argument or loaded from `),a_e=n(Ky,"CODE",{});var mSt=s(a_e);f7o=r(mSt,"pretrained_model_name_or_path"),mSt.forEach(t),m7o=r(Ky,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),n_e=n(Ky,"CODE",{});var gSt=s(n_e);g7o=r(gSt,"pretrained_model_name_or_path"),gSt.forEach(t),h7o=r(Ky,":"),Ky.forEach(t),u7o=i(wa),z=n(wa,"UL",{});var Q=s(z);gp=n(Q,"LI",{});var Lje=s(gp);s_e=n(Lje,"STRONG",{});var hSt=s(s_e);p7o=r(hSt,"beit"),hSt.forEach(t),_7o=r(Lje," \u2014 "),hV=n(Lje,"A",{href:!0});var uSt=s(hV);v7o=r(uSt,"BeitFeatureExtractor"),uSt.forEach(t),b7o=r(Lje," (BEiT model)"),Lje.forEach(t),F7o=i(Q),hp=n(Q,"LI",{});var yje=s(hp);l_e=n(yje,"STRONG",{});var pSt=s(l_e);T7o=r(pSt,"clip"),pSt.forEach(t),M7o=r(yje," \u2014 "),uV=n(yje,"A",{href:!0});var _St=s(uV);E7o=r(_St,"CLIPFeatureExtractor"),_St.forEach(t),C7o=r(yje," (CLIP model)"),yje.forEach(t),w7o=i(Q),up=n(Q,"LI",{});var xje=s(up);i_e=n(xje,"STRONG",{});var vSt=s(i_e);A7o=r(vSt,"conditional_detr"),vSt.forEach(t),L7o=r(xje," \u2014 "),pV=n(xje,"A",{href:!0});var bSt=s(pV);y7o=r(bSt,"ConditionalDetrFeatureExtractor"),bSt.forEach(t),x7o=r(xje," (Conditional DETR model)"),xje.forEach(t),$7o=i(Q),pp=n(Q,"LI",{});var $je=s(pp);d_e=n($je,"STRONG",{});var FSt=s(d_e);k7o=r(FSt,"convnext"),FSt.forEach(t),S7o=r($je," \u2014 "),_V=n($je,"A",{href:!0});var TSt=s(_V);R7o=r(TSt,"ConvNextFeatureExtractor"),TSt.forEach(t),P7o=r($je," (ConvNeXT model)"),$je.forEach(t),B7o=i(Q),_p=n(Q,"LI",{});var kje=s(_p);c_e=n(kje,"STRONG",{});var MSt=s(c_e);I7o=r(MSt,"cvt"),MSt.forEach(t),N7o=r(kje," \u2014 "),vV=n(kje,"A",{href:!0});var ESt=s(vV);q7o=r(ESt,"ConvNextFeatureExtractor"),ESt.forEach(t),j7o=r(kje," (CvT model)"),kje.forEach(t),D7o=i(Q),vp=n(Q,"LI",{});var Sje=s(vp);f_e=n(Sje,"STRONG",{});var CSt=s(f_e);G7o=r(CSt,"data2vec-audio"),CSt.forEach(t),O7o=r(Sje," \u2014 "),bV=n(Sje,"A",{href:!0});var wSt=s(bV);V7o=r(wSt,"Wav2Vec2FeatureExtractor"),wSt.forEach(t),X7o=r(Sje," (Data2VecAudio model)"),Sje.forEach(t),z7o=i(Q),bp=n(Q,"LI",{});var Rje=s(bp);m_e=n(Rje,"STRONG",{});var ASt=s(m_e);Q7o=r(ASt,"data2vec-vision"),ASt.forEach(t),W7o=r(Rje," \u2014 "),FV=n(Rje,"A",{href:!0});var LSt=s(FV);U7o=r(LSt,"BeitFeatureExtractor"),LSt.forEach(t),H7o=r(Rje," (Data2VecVision model)"),Rje.forEach(t),J7o=i(Q),Fp=n(Q,"LI",{});var Pje=s(Fp);g_e=n(Pje,"STRONG",{});var ySt=s(g_e);Y7o=r(ySt,"deformable_detr"),ySt.forEach(t),Z7o=r(Pje," \u2014 "),TV=n(Pje,"A",{href:!0});var xSt=s(TV);K7o=r(xSt,"DeformableDetrFeatureExtractor"),xSt.forEach(t),e8o=r(Pje," (Deformable DETR model)"),Pje.forEach(t),o8o=i(Q),Tp=n(Q,"LI",{});var Bje=s(Tp);h_e=n(Bje,"STRONG",{});var $St=s(h_e);r8o=r($St,"deit"),$St.forEach(t),t8o=r(Bje," \u2014 "),MV=n(Bje,"A",{href:!0});var kSt=s(MV);a8o=r(kSt,"DeiTFeatureExtractor"),kSt.forEach(t),n8o=r(Bje," (DeiT model)"),Bje.forEach(t),s8o=i(Q),Mp=n(Q,"LI",{});var Ije=s(Mp);u_e=n(Ije,"STRONG",{});var SSt=s(u_e);l8o=r(SSt,"detr"),SSt.forEach(t),i8o=r(Ije," \u2014 "),EV=n(Ije,"A",{href:!0});var RSt=s(EV);d8o=r(RSt,"DetrFeatureExtractor"),RSt.forEach(t),c8o=r(Ije," (DETR model)"),Ije.forEach(t),f8o=i(Q),Ep=n(Q,"LI",{});var Nje=s(Ep);p_e=n(Nje,"STRONG",{});var PSt=s(p_e);m8o=r(PSt,"donut-swin"),PSt.forEach(t),g8o=r(Nje," \u2014 "),CV=n(Nje,"A",{href:!0});var BSt=s(CV);h8o=r(BSt,"DonutFeatureExtractor"),BSt.forEach(t),u8o=r(Nje," (DonutSwin model)"),Nje.forEach(t),p8o=i(Q),Cp=n(Q,"LI",{});var qje=s(Cp);__e=n(qje,"STRONG",{});var ISt=s(__e);_8o=r(ISt,"dpt"),ISt.forEach(t),v8o=r(qje," \u2014 "),wV=n(qje,"A",{href:!0});var NSt=s(wV);b8o=r(NSt,"DPTFeatureExtractor"),NSt.forEach(t),F8o=r(qje," (DPT model)"),qje.forEach(t),T8o=i(Q),wp=n(Q,"LI",{});var jje=s(wp);v_e=n(jje,"STRONG",{});var qSt=s(v_e);M8o=r(qSt,"flava"),qSt.forEach(t),E8o=r(jje," \u2014 "),AV=n(jje,"A",{href:!0});var jSt=s(AV);C8o=r(jSt,"FlavaFeatureExtractor"),jSt.forEach(t),w8o=r(jje," (FLAVA model)"),jje.forEach(t),A8o=i(Q),Ap=n(Q,"LI",{});var Dje=s(Ap);b_e=n(Dje,"STRONG",{});var DSt=s(b_e);L8o=r(DSt,"glpn"),DSt.forEach(t),y8o=r(Dje," \u2014 "),LV=n(Dje,"A",{href:!0});var GSt=s(LV);x8o=r(GSt,"GLPNFeatureExtractor"),GSt.forEach(t),$8o=r(Dje," (GLPN model)"),Dje.forEach(t),k8o=i(Q),Lp=n(Q,"LI",{});var Gje=s(Lp);F_e=n(Gje,"STRONG",{});var OSt=s(F_e);S8o=r(OSt,"groupvit"),OSt.forEach(t),R8o=r(Gje," \u2014 "),yV=n(Gje,"A",{href:!0});var VSt=s(yV);P8o=r(VSt,"CLIPFeatureExtractor"),VSt.forEach(t),B8o=r(Gje," (GroupViT model)"),Gje.forEach(t),I8o=i(Q),yp=n(Q,"LI",{});var Oje=s(yp);T_e=n(Oje,"STRONG",{});var XSt=s(T_e);N8o=r(XSt,"hubert"),XSt.forEach(t),q8o=r(Oje," \u2014 "),xV=n(Oje,"A",{href:!0});var zSt=s(xV);j8o=r(zSt,"Wav2Vec2FeatureExtractor"),zSt.forEach(t),D8o=r(Oje," (Hubert model)"),Oje.forEach(t),G8o=i(Q),xp=n(Q,"LI",{});var Vje=s(xp);M_e=n(Vje,"STRONG",{});var QSt=s(M_e);O8o=r(QSt,"imagegpt"),QSt.forEach(t),V8o=r(Vje," \u2014 "),$V=n(Vje,"A",{href:!0});var WSt=s($V);X8o=r(WSt,"ImageGPTFeatureExtractor"),WSt.forEach(t),z8o=r(Vje," (ImageGPT model)"),Vje.forEach(t),Q8o=i(Q),$p=n(Q,"LI",{});var Xje=s($p);E_e=n(Xje,"STRONG",{});var USt=s(E_e);W8o=r(USt,"layoutlmv2"),USt.forEach(t),U8o=r(Xje," \u2014 "),kV=n(Xje,"A",{href:!0});var HSt=s(kV);H8o=r(HSt,"LayoutLMv2FeatureExtractor"),HSt.forEach(t),J8o=r(Xje," (LayoutLMv2 model)"),Xje.forEach(t),Y8o=i(Q),kp=n(Q,"LI",{});var zje=s(kp);C_e=n(zje,"STRONG",{});var JSt=s(C_e);Z8o=r(JSt,"layoutlmv3"),JSt.forEach(t),K8o=r(zje," \u2014 "),SV=n(zje,"A",{href:!0});var YSt=s(SV);eLo=r(YSt,"LayoutLMv3FeatureExtractor"),YSt.forEach(t),oLo=r(zje," (LayoutLMv3 model)"),zje.forEach(t),rLo=i(Q),Sp=n(Q,"LI",{});var Qje=s(Sp);w_e=n(Qje,"STRONG",{});var ZSt=s(w_e);tLo=r(ZSt,"levit"),ZSt.forEach(t),aLo=r(Qje," \u2014 "),RV=n(Qje,"A",{href:!0});var KSt=s(RV);nLo=r(KSt,"LevitFeatureExtractor"),KSt.forEach(t),sLo=r(Qje," (LeViT model)"),Qje.forEach(t),lLo=i(Q),Rp=n(Q,"LI",{});var Wje=s(Rp);A_e=n(Wje,"STRONG",{});var eRt=s(A_e);iLo=r(eRt,"maskformer"),eRt.forEach(t),dLo=r(Wje," \u2014 "),PV=n(Wje,"A",{href:!0});var oRt=s(PV);cLo=r(oRt,"MaskFormerFeatureExtractor"),oRt.forEach(t),fLo=r(Wje," (MaskFormer model)"),Wje.forEach(t),mLo=i(Q),Pp=n(Q,"LI",{});var Uje=s(Pp);L_e=n(Uje,"STRONG",{});var rRt=s(L_e);gLo=r(rRt,"mctct"),rRt.forEach(t),hLo=r(Uje," \u2014 "),BV=n(Uje,"A",{href:!0});var tRt=s(BV);uLo=r(tRt,"MCTCTFeatureExtractor"),tRt.forEach(t),pLo=r(Uje," (M-CTC-T model)"),Uje.forEach(t),_Lo=i(Q),Bp=n(Q,"LI",{});var Hje=s(Bp);y_e=n(Hje,"STRONG",{});var aRt=s(y_e);vLo=r(aRt,"mobilevit"),aRt.forEach(t),bLo=r(Hje," \u2014 "),IV=n(Hje,"A",{href:!0});var nRt=s(IV);FLo=r(nRt,"MobileViTFeatureExtractor"),nRt.forEach(t),TLo=r(Hje," (MobileViT model)"),Hje.forEach(t),MLo=i(Q),Ip=n(Q,"LI",{});var Jje=s(Ip);x_e=n(Jje,"STRONG",{});var sRt=s(x_e);ELo=r(sRt,"owlvit"),sRt.forEach(t),CLo=r(Jje," \u2014 "),NV=n(Jje,"A",{href:!0});var lRt=s(NV);wLo=r(lRt,"OwlViTFeatureExtractor"),lRt.forEach(t),ALo=r(Jje," (OWL-ViT model)"),Jje.forEach(t),LLo=i(Q),Np=n(Q,"LI",{});var Yje=s(Np);$_e=n(Yje,"STRONG",{});var iRt=s($_e);yLo=r(iRt,"perceiver"),iRt.forEach(t),xLo=r(Yje," \u2014 "),qV=n(Yje,"A",{href:!0});var dRt=s(qV);$Lo=r(dRt,"PerceiverFeatureExtractor"),dRt.forEach(t),kLo=r(Yje," (Perceiver model)"),Yje.forEach(t),SLo=i(Q),qp=n(Q,"LI",{});var Zje=s(qp);k_e=n(Zje,"STRONG",{});var cRt=s(k_e);RLo=r(cRt,"poolformer"),cRt.forEach(t),PLo=r(Zje," \u2014 "),jV=n(Zje,"A",{href:!0});var fRt=s(jV);BLo=r(fRt,"PoolFormerFeatureExtractor"),fRt.forEach(t),ILo=r(Zje," (PoolFormer model)"),Zje.forEach(t),NLo=i(Q),jp=n(Q,"LI",{});var Kje=s(jp);S_e=n(Kje,"STRONG",{});var mRt=s(S_e);qLo=r(mRt,"regnet"),mRt.forEach(t),jLo=r(Kje," \u2014 "),DV=n(Kje,"A",{href:!0});var gRt=s(DV);DLo=r(gRt,"ConvNextFeatureExtractor"),gRt.forEach(t),GLo=r(Kje," (RegNet model)"),Kje.forEach(t),OLo=i(Q),Dp=n(Q,"LI",{});var eDe=s(Dp);R_e=n(eDe,"STRONG",{});var hRt=s(R_e);VLo=r(hRt,"resnet"),hRt.forEach(t),XLo=r(eDe," \u2014 "),GV=n(eDe,"A",{href:!0});var uRt=s(GV);zLo=r(uRt,"ConvNextFeatureExtractor"),uRt.forEach(t),QLo=r(eDe," (ResNet model)"),eDe.forEach(t),WLo=i(Q),Gp=n(Q,"LI",{});var oDe=s(Gp);P_e=n(oDe,"STRONG",{});var pRt=s(P_e);ULo=r(pRt,"segformer"),pRt.forEach(t),HLo=r(oDe," \u2014 "),OV=n(oDe,"A",{href:!0});var _Rt=s(OV);JLo=r(_Rt,"SegformerFeatureExtractor"),_Rt.forEach(t),YLo=r(oDe," (SegFormer model)"),oDe.forEach(t),ZLo=i(Q),Op=n(Q,"LI",{});var rDe=s(Op);B_e=n(rDe,"STRONG",{});var vRt=s(B_e);KLo=r(vRt,"speech_to_text"),vRt.forEach(t),eyo=r(rDe," \u2014 "),VV=n(rDe,"A",{href:!0});var bRt=s(VV);oyo=r(bRt,"Speech2TextFeatureExtractor"),bRt.forEach(t),ryo=r(rDe," (Speech2Text model)"),rDe.forEach(t),tyo=i(Q),Vp=n(Q,"LI",{});var tDe=s(Vp);I_e=n(tDe,"STRONG",{});var FRt=s(I_e);ayo=r(FRt,"swin"),FRt.forEach(t),nyo=r(tDe," \u2014 "),XV=n(tDe,"A",{href:!0});var TRt=s(XV);syo=r(TRt,"ViTFeatureExtractor"),TRt.forEach(t),lyo=r(tDe," (Swin Transformer model)"),tDe.forEach(t),iyo=i(Q),Xp=n(Q,"LI",{});var aDe=s(Xp);N_e=n(aDe,"STRONG",{});var MRt=s(N_e);dyo=r(MRt,"swinv2"),MRt.forEach(t),cyo=r(aDe," \u2014 "),zV=n(aDe,"A",{href:!0});var ERt=s(zV);fyo=r(ERt,"ViTFeatureExtractor"),ERt.forEach(t),myo=r(aDe," (Swin Transformer V2 model)"),aDe.forEach(t),gyo=i(Q),zp=n(Q,"LI",{});var nDe=s(zp);q_e=n(nDe,"STRONG",{});var CRt=s(q_e);hyo=r(CRt,"table-transformer"),CRt.forEach(t),uyo=r(nDe," \u2014 "),QV=n(nDe,"A",{href:!0});var wRt=s(QV);pyo=r(wRt,"DetrFeatureExtractor"),wRt.forEach(t),_yo=r(nDe," (Table Transformer model)"),nDe.forEach(t),vyo=i(Q),Qp=n(Q,"LI",{});var sDe=s(Qp);j_e=n(sDe,"STRONG",{});var ARt=s(j_e);byo=r(ARt,"van"),ARt.forEach(t),Fyo=r(sDe," \u2014 "),WV=n(sDe,"A",{href:!0});var LRt=s(WV);Tyo=r(LRt,"ConvNextFeatureExtractor"),LRt.forEach(t),Myo=r(sDe," (VAN model)"),sDe.forEach(t),Eyo=i(Q),Wp=n(Q,"LI",{});var lDe=s(Wp);D_e=n(lDe,"STRONG",{});var yRt=s(D_e);Cyo=r(yRt,"videomae"),yRt.forEach(t),wyo=r(lDe," \u2014 "),UV=n(lDe,"A",{href:!0});var xRt=s(UV);Ayo=r(xRt,"VideoMAEFeatureExtractor"),xRt.forEach(t),Lyo=r(lDe," (VideoMAE model)"),lDe.forEach(t),yyo=i(Q),Up=n(Q,"LI",{});var iDe=s(Up);G_e=n(iDe,"STRONG",{});var $Rt=s(G_e);xyo=r($Rt,"vilt"),$Rt.forEach(t),$yo=r(iDe," \u2014 "),HV=n(iDe,"A",{href:!0});var kRt=s(HV);kyo=r(kRt,"ViltFeatureExtractor"),kRt.forEach(t),Syo=r(iDe," (ViLT model)"),iDe.forEach(t),Ryo=i(Q),Hp=n(Q,"LI",{});var dDe=s(Hp);O_e=n(dDe,"STRONG",{});var SRt=s(O_e);Pyo=r(SRt,"vit"),SRt.forEach(t),Byo=r(dDe," \u2014 "),JV=n(dDe,"A",{href:!0});var RRt=s(JV);Iyo=r(RRt,"ViTFeatureExtractor"),RRt.forEach(t),Nyo=r(dDe," (ViT model)"),dDe.forEach(t),qyo=i(Q),Jp=n(Q,"LI",{});var cDe=s(Jp);V_e=n(cDe,"STRONG",{});var PRt=s(V_e);jyo=r(PRt,"vit_mae"),PRt.forEach(t),Dyo=r(cDe," \u2014 "),YV=n(cDe,"A",{href:!0});var BRt=s(YV);Gyo=r(BRt,"ViTFeatureExtractor"),BRt.forEach(t),Oyo=r(cDe," (ViTMAE model)"),cDe.forEach(t),Vyo=i(Q),Yp=n(Q,"LI",{});var fDe=s(Yp);X_e=n(fDe,"STRONG",{});var IRt=s(X_e);Xyo=r(IRt,"vit_msn"),IRt.forEach(t),zyo=r(fDe," \u2014 "),ZV=n(fDe,"A",{href:!0});var NRt=s(ZV);Qyo=r(NRt,"ViTFeatureExtractor"),NRt.forEach(t),Wyo=r(fDe," (ViTMSN model)"),fDe.forEach(t),Uyo=i(Q),Zp=n(Q,"LI",{});var mDe=s(Zp);z_e=n(mDe,"STRONG",{});var qRt=s(z_e);Hyo=r(qRt,"wav2vec2"),qRt.forEach(t),Jyo=r(mDe," \u2014 "),KV=n(mDe,"A",{href:!0});var jRt=s(KV);Yyo=r(jRt,"Wav2Vec2FeatureExtractor"),jRt.forEach(t),Zyo=r(mDe," (Wav2Vec2 model)"),mDe.forEach(t),Kyo=i(Q),Kp=n(Q,"LI",{});var gDe=s(Kp);Q_e=n(gDe,"STRONG",{});var DRt=s(Q_e);e9o=r(DRt,"wav2vec2-conformer"),DRt.forEach(t),o9o=r(gDe," \u2014 "),eX=n(gDe,"A",{href:!0});var GRt=s(eX);r9o=r(GRt,"Wav2Vec2FeatureExtractor"),GRt.forEach(t),t9o=r(gDe," (Wav2Vec2-Conformer model)"),gDe.forEach(t),a9o=i(Q),e_=n(Q,"LI",{});var hDe=s(e_);W_e=n(hDe,"STRONG",{});var ORt=s(W_e);n9o=r(ORt,"whisper"),ORt.forEach(t),s9o=r(hDe," \u2014 "),oX=n(hDe,"A",{href:!0});var VRt=s(oX);l9o=r(VRt,"WhisperFeatureExtractor"),VRt.forEach(t),i9o=r(hDe," (Whisper model)"),hDe.forEach(t),d9o=i(Q),o_=n(Q,"LI",{});var uDe=s(o_);U_e=n(uDe,"STRONG",{});var XRt=s(U_e);c9o=r(XRt,"xclip"),XRt.forEach(t),f9o=r(uDe," \u2014 "),rX=n(uDe,"A",{href:!0});var zRt=s(rX);m9o=r(zRt,"CLIPFeatureExtractor"),zRt.forEach(t),g9o=r(uDe," (X-CLIP model)"),uDe.forEach(t),h9o=i(Q),r_=n(Q,"LI",{});var pDe=s(r_);H_e=n(pDe,"STRONG",{});var QRt=s(H_e);u9o=r(QRt,"yolos"),QRt.forEach(t),p9o=r(pDe," \u2014 "),tX=n(pDe,"A",{href:!0});var WRt=s(tX);_9o=r(WRt,"YolosFeatureExtractor"),WRt.forEach(t),v9o=r(pDe," (YOLOS model)"),pDe.forEach(t),Q.forEach(t),b9o=i(wa),T(t_.$$.fragment,wa),F9o=i(wa),T(a_.$$.fragment,wa),wa.forEach(t),T9o=i(Il),n_=n(Il,"DIV",{class:!0});var Yno=s(n_);T(y$.$$.fragment,Yno),M9o=i(Yno),J_e=n(Yno,"P",{});var URt=s(J_e);E9o=r(URt,"Register a new feature extractor for this class."),URt.forEach(t),Yno.forEach(t),Il.forEach(t),Ito=i(f),$d=n(f,"H2",{class:!0});var Zno=s($d);s_=n(Zno,"A",{id:!0,class:!0,href:!0});var HRt=s(s_);Y_e=n(HRt,"SPAN",{});var JRt=s(Y_e);T(x$.$$.fragment,JRt),JRt.forEach(t),HRt.forEach(t),C9o=i(Zno),Z_e=n(Zno,"SPAN",{});var YRt=s(Z_e);w9o=r(YRt,"AutoProcessor"),YRt.forEach(t),Zno.forEach(t),Nto=i(f),Bo=n(f,"DIV",{class:!0});var Nl=s(Bo);T($$.$$.fragment,Nl),A9o=i(Nl),k$=n(Nl,"P",{});var Kno=s(k$);L9o=r(Kno,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),aX=n(Kno,"A",{href:!0});var ZRt=s(aX);y9o=r(ZRt,"AutoProcessor.from_pretrained()"),ZRt.forEach(t),x9o=r(Kno," class method."),Kno.forEach(t),$9o=i(Nl),S$=n(Nl,"P",{});var eso=s(S$);k9o=r(eso,"This class cannot be instantiated directly using "),K_e=n(eso,"CODE",{});var KRt=s(K_e);S9o=r(KRt,"__init__()"),KRt.forEach(t),R9o=r(eso," (throws an error)."),eso.forEach(t),P9o=i(Nl),Ze=n(Nl,"DIV",{class:!0});var Aa=s(Ze);T(R$.$$.fragment,Aa),B9o=i(Aa),e4e=n(Aa,"P",{});var ePt=s(e4e);I9o=r(ePt,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),ePt.forEach(t),N9o=i(Aa),kd=n(Aa,"P",{});var tce=s(kd);q9o=r(tce,"The processor class to instantiate is selected based on the "),o4e=n(tce,"CODE",{});var oPt=s(o4e);j9o=r(oPt,"model_type"),oPt.forEach(t),D9o=r(tce,` property of the config object (either
passed as an argument or loaded from `),r4e=n(tce,"CODE",{});var rPt=s(r4e);G9o=r(rPt,"pretrained_model_name_or_path"),rPt.forEach(t),O9o=r(tce," if possible):"),tce.forEach(t),V9o=i(Aa),le=n(Aa,"UL",{});var me=s(le);l_=n(me,"LI",{});var _De=s(l_);t4e=n(_De,"STRONG",{});var tPt=s(t4e);X9o=r(tPt,"clip"),tPt.forEach(t),z9o=r(_De," \u2014 "),nX=n(_De,"A",{href:!0});var aPt=s(nX);Q9o=r(aPt,"CLIPProcessor"),aPt.forEach(t),W9o=r(_De," (CLIP model)"),_De.forEach(t),U9o=i(me),i_=n(me,"LI",{});var vDe=s(i_);a4e=n(vDe,"STRONG",{});var nPt=s(a4e);H9o=r(nPt,"flava"),nPt.forEach(t),J9o=r(vDe," \u2014 "),sX=n(vDe,"A",{href:!0});var sPt=s(sX);Y9o=r(sPt,"FlavaProcessor"),sPt.forEach(t),Z9o=r(vDe," (FLAVA model)"),vDe.forEach(t),K9o=i(me),d_=n(me,"LI",{});var bDe=s(d_);n4e=n(bDe,"STRONG",{});var lPt=s(n4e);exo=r(lPt,"groupvit"),lPt.forEach(t),oxo=r(bDe," \u2014 "),lX=n(bDe,"A",{href:!0});var iPt=s(lX);rxo=r(iPt,"CLIPProcessor"),iPt.forEach(t),txo=r(bDe," (GroupViT model)"),bDe.forEach(t),axo=i(me),c_=n(me,"LI",{});var FDe=s(c_);s4e=n(FDe,"STRONG",{});var dPt=s(s4e);nxo=r(dPt,"layoutlmv2"),dPt.forEach(t),sxo=r(FDe," \u2014 "),iX=n(FDe,"A",{href:!0});var cPt=s(iX);lxo=r(cPt,"LayoutLMv2Processor"),cPt.forEach(t),ixo=r(FDe," (LayoutLMv2 model)"),FDe.forEach(t),dxo=i(me),f_=n(me,"LI",{});var TDe=s(f_);l4e=n(TDe,"STRONG",{});var fPt=s(l4e);cxo=r(fPt,"layoutlmv3"),fPt.forEach(t),fxo=r(TDe," \u2014 "),dX=n(TDe,"A",{href:!0});var mPt=s(dX);mxo=r(mPt,"LayoutLMv3Processor"),mPt.forEach(t),gxo=r(TDe," (LayoutLMv3 model)"),TDe.forEach(t),hxo=i(me),m_=n(me,"LI",{});var MDe=s(m_);i4e=n(MDe,"STRONG",{});var gPt=s(i4e);uxo=r(gPt,"layoutxlm"),gPt.forEach(t),pxo=r(MDe," \u2014 "),cX=n(MDe,"A",{href:!0});var hPt=s(cX);_xo=r(hPt,"LayoutXLMProcessor"),hPt.forEach(t),vxo=r(MDe," (LayoutXLM model)"),MDe.forEach(t),bxo=i(me),g_=n(me,"LI",{});var EDe=s(g_);d4e=n(EDe,"STRONG",{});var uPt=s(d4e);Fxo=r(uPt,"markuplm"),uPt.forEach(t),Txo=r(EDe," \u2014 "),fX=n(EDe,"A",{href:!0});var pPt=s(fX);Mxo=r(pPt,"MarkupLMProcessor"),pPt.forEach(t),Exo=r(EDe," (MarkupLM model)"),EDe.forEach(t),Cxo=i(me),h_=n(me,"LI",{});var CDe=s(h_);c4e=n(CDe,"STRONG",{});var _Pt=s(c4e);wxo=r(_Pt,"owlvit"),_Pt.forEach(t),Axo=r(CDe," \u2014 "),mX=n(CDe,"A",{href:!0});var vPt=s(mX);Lxo=r(vPt,"OwlViTProcessor"),vPt.forEach(t),yxo=r(CDe," (OWL-ViT model)"),CDe.forEach(t),xxo=i(me),u_=n(me,"LI",{});var wDe=s(u_);f4e=n(wDe,"STRONG",{});var bPt=s(f4e);$xo=r(bPt,"sew"),bPt.forEach(t),kxo=r(wDe," \u2014 "),gX=n(wDe,"A",{href:!0});var FPt=s(gX);Sxo=r(FPt,"Wav2Vec2Processor"),FPt.forEach(t),Rxo=r(wDe," (SEW model)"),wDe.forEach(t),Pxo=i(me),p_=n(me,"LI",{});var ADe=s(p_);m4e=n(ADe,"STRONG",{});var TPt=s(m4e);Bxo=r(TPt,"sew-d"),TPt.forEach(t),Ixo=r(ADe," \u2014 "),hX=n(ADe,"A",{href:!0});var MPt=s(hX);Nxo=r(MPt,"Wav2Vec2Processor"),MPt.forEach(t),qxo=r(ADe," (SEW-D model)"),ADe.forEach(t),jxo=i(me),__=n(me,"LI",{});var LDe=s(__);g4e=n(LDe,"STRONG",{});var EPt=s(g4e);Dxo=r(EPt,"speech_to_text"),EPt.forEach(t),Gxo=r(LDe," \u2014 "),uX=n(LDe,"A",{href:!0});var CPt=s(uX);Oxo=r(CPt,"Speech2TextProcessor"),CPt.forEach(t),Vxo=r(LDe," (Speech2Text model)"),LDe.forEach(t),Xxo=i(me),v_=n(me,"LI",{});var yDe=s(v_);h4e=n(yDe,"STRONG",{});var wPt=s(h4e);zxo=r(wPt,"speech_to_text_2"),wPt.forEach(t),Qxo=r(yDe," \u2014 "),pX=n(yDe,"A",{href:!0});var APt=s(pX);Wxo=r(APt,"Speech2Text2Processor"),APt.forEach(t),Uxo=r(yDe," (Speech2Text2 model)"),yDe.forEach(t),Hxo=i(me),b_=n(me,"LI",{});var xDe=s(b_);u4e=n(xDe,"STRONG",{});var LPt=s(u4e);Jxo=r(LPt,"trocr"),LPt.forEach(t),Yxo=r(xDe," \u2014 "),_X=n(xDe,"A",{href:!0});var yPt=s(_X);Zxo=r(yPt,"TrOCRProcessor"),yPt.forEach(t),Kxo=r(xDe," (TrOCR model)"),xDe.forEach(t),e$o=i(me),F_=n(me,"LI",{});var $De=s(F_);p4e=n($De,"STRONG",{});var xPt=s(p4e);o$o=r(xPt,"unispeech"),xPt.forEach(t),r$o=r($De," \u2014 "),vX=n($De,"A",{href:!0});var $Pt=s(vX);t$o=r($Pt,"Wav2Vec2Processor"),$Pt.forEach(t),a$o=r($De," (UniSpeech model)"),$De.forEach(t),n$o=i(me),T_=n(me,"LI",{});var kDe=s(T_);_4e=n(kDe,"STRONG",{});var kPt=s(_4e);s$o=r(kPt,"unispeech-sat"),kPt.forEach(t),l$o=r(kDe," \u2014 "),bX=n(kDe,"A",{href:!0});var SPt=s(bX);i$o=r(SPt,"Wav2Vec2Processor"),SPt.forEach(t),d$o=r(kDe," (UniSpeechSat model)"),kDe.forEach(t),c$o=i(me),M_=n(me,"LI",{});var SDe=s(M_);v4e=n(SDe,"STRONG",{});var RPt=s(v4e);f$o=r(RPt,"vilt"),RPt.forEach(t),m$o=r(SDe," \u2014 "),FX=n(SDe,"A",{href:!0});var PPt=s(FX);g$o=r(PPt,"ViltProcessor"),PPt.forEach(t),h$o=r(SDe," (ViLT model)"),SDe.forEach(t),u$o=i(me),E_=n(me,"LI",{});var RDe=s(E_);b4e=n(RDe,"STRONG",{});var BPt=s(b4e);p$o=r(BPt,"vision-text-dual-encoder"),BPt.forEach(t),_$o=r(RDe," \u2014 "),TX=n(RDe,"A",{href:!0});var IPt=s(TX);v$o=r(IPt,"VisionTextDualEncoderProcessor"),IPt.forEach(t),b$o=r(RDe," (VisionTextDualEncoder model)"),RDe.forEach(t),F$o=i(me),C_=n(me,"LI",{});var PDe=s(C_);F4e=n(PDe,"STRONG",{});var NPt=s(F4e);T$o=r(NPt,"wav2vec2"),NPt.forEach(t),M$o=r(PDe," \u2014 "),MX=n(PDe,"A",{href:!0});var qPt=s(MX);E$o=r(qPt,"Wav2Vec2Processor"),qPt.forEach(t),C$o=r(PDe," (Wav2Vec2 model)"),PDe.forEach(t),w$o=i(me),w_=n(me,"LI",{});var BDe=s(w_);T4e=n(BDe,"STRONG",{});var jPt=s(T4e);A$o=r(jPt,"wav2vec2-conformer"),jPt.forEach(t),L$o=r(BDe," \u2014 "),EX=n(BDe,"A",{href:!0});var DPt=s(EX);y$o=r(DPt,"Wav2Vec2Processor"),DPt.forEach(t),x$o=r(BDe," (Wav2Vec2-Conformer model)"),BDe.forEach(t),$$o=i(me),A_=n(me,"LI",{});var IDe=s(A_);M4e=n(IDe,"STRONG",{});var GPt=s(M4e);k$o=r(GPt,"wavlm"),GPt.forEach(t),S$o=r(IDe," \u2014 "),CX=n(IDe,"A",{href:!0});var OPt=s(CX);R$o=r(OPt,"Wav2Vec2Processor"),OPt.forEach(t),P$o=r(IDe," (WavLM model)"),IDe.forEach(t),B$o=i(me),L_=n(me,"LI",{});var NDe=s(L_);E4e=n(NDe,"STRONG",{});var VPt=s(E4e);I$o=r(VPt,"whisper"),VPt.forEach(t),N$o=r(NDe," \u2014 "),wX=n(NDe,"A",{href:!0});var XPt=s(wX);q$o=r(XPt,"WhisperProcessor"),XPt.forEach(t),j$o=r(NDe," (Whisper model)"),NDe.forEach(t),D$o=i(me),y_=n(me,"LI",{});var qDe=s(y_);C4e=n(qDe,"STRONG",{});var zPt=s(C4e);G$o=r(zPt,"xclip"),zPt.forEach(t),O$o=r(qDe," \u2014 "),AX=n(qDe,"A",{href:!0});var QPt=s(AX);V$o=r(QPt,"XCLIPProcessor"),QPt.forEach(t),X$o=r(qDe," (X-CLIP model)"),qDe.forEach(t),me.forEach(t),z$o=i(Aa),T(x_.$$.fragment,Aa),Q$o=i(Aa),T($_.$$.fragment,Aa),Aa.forEach(t),W$o=i(Nl),k_=n(Nl,"DIV",{class:!0});var oso=s(k_);T(P$.$$.fragment,oso),U$o=i(oso),w4e=n(oso,"P",{});var WPt=s(w4e);H$o=r(WPt,"Register a new processor for this class."),WPt.forEach(t),oso.forEach(t),Nl.forEach(t),qto=i(f),Sd=n(f,"H2",{class:!0});var rso=s(Sd);S_=n(rso,"A",{id:!0,class:!0,href:!0});var UPt=s(S_);A4e=n(UPt,"SPAN",{});var HPt=s(A4e);T(B$.$$.fragment,HPt),HPt.forEach(t),UPt.forEach(t),J$o=i(rso),L4e=n(rso,"SPAN",{});var JPt=s(L4e);Y$o=r(JPt,"AutoModel"),JPt.forEach(t),rso.forEach(t),jto=i(f),Io=n(f,"DIV",{class:!0});var ql=s(Io);T(I$.$$.fragment,ql),Z$o=i(ql),Rd=n(ql,"P",{});var ace=s(Rd);K$o=r(ace,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),LX=n(ace,"A",{href:!0});var YPt=s(LX);eko=r(YPt,"from_pretrained()"),YPt.forEach(t),oko=r(ace," class method or the "),yX=n(ace,"A",{href:!0});var ZPt=s(yX);rko=r(ZPt,"from_config()"),ZPt.forEach(t),tko=r(ace,` class
method.`),ace.forEach(t),ako=i(ql),N$=n(ql,"P",{});var tso=s(N$);nko=r(tso,"This class cannot be instantiated directly using "),y4e=n(tso,"CODE",{});var KPt=s(y4e);sko=r(KPt,"__init__()"),KPt.forEach(t),lko=r(tso," (throws an error)."),tso.forEach(t),iko=i(ql),Mt=n(ql,"DIV",{class:!0});var e9=s(Mt);T(q$.$$.fragment,e9),dko=i(e9),x4e=n(e9,"P",{});var eBt=s(x4e);cko=r(eBt,"Instantiates one of the base model classes of the library from a configuration."),eBt.forEach(t),fko=i(e9),Pd=n(e9,"P",{});var nce=s(Pd);mko=r(nce,`Note:
Loading a model from its configuration file does `),$4e=n(nce,"STRONG",{});var oBt=s($4e);gko=r(oBt,"not"),oBt.forEach(t),hko=r(nce,` load the model weights. It only affects the
model\u2019s configuration. Use `),xX=n(nce,"A",{href:!0});var rBt=s(xX);uko=r(rBt,"from_pretrained()"),rBt.forEach(t),pko=r(nce," to load the model weights."),nce.forEach(t),_ko=i(e9),T(R_.$$.fragment,e9),e9.forEach(t),vko=i(ql),Ke=n(ql,"DIV",{class:!0});var La=s(Ke);T(j$.$$.fragment,La),bko=i(La),k4e=n(La,"P",{});var tBt=s(k4e);Fko=r(tBt,"Instantiate one of the base model classes of the library from a pretrained model."),tBt.forEach(t),Tko=i(La),nn=n(La,"P",{});var o9=s(nn);Mko=r(o9,"The model class to instantiate is selected based on the "),S4e=n(o9,"CODE",{});var aBt=s(S4e);Eko=r(aBt,"model_type"),aBt.forEach(t),Cko=r(o9,` property of the config object (either
passed as an argument or loaded from `),R4e=n(o9,"CODE",{});var nBt=s(R4e);wko=r(nBt,"pretrained_model_name_or_path"),nBt.forEach(t),Ako=r(o9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P4e=n(o9,"CODE",{});var sBt=s(P4e);Lko=r(sBt,"pretrained_model_name_or_path"),sBt.forEach(t),yko=r(o9,":"),o9.forEach(t),xko=i(La),y=n(La,"UL",{});var x=s(y);P_=n(x,"LI",{});var jDe=s(P_);B4e=n(jDe,"STRONG",{});var lBt=s(B4e);$ko=r(lBt,"albert"),lBt.forEach(t),kko=r(jDe," \u2014 "),$X=n(jDe,"A",{href:!0});var iBt=s($X);Sko=r(iBt,"AlbertModel"),iBt.forEach(t),Rko=r(jDe," (ALBERT model)"),jDe.forEach(t),Pko=i(x),B_=n(x,"LI",{});var DDe=s(B_);I4e=n(DDe,"STRONG",{});var dBt=s(I4e);Bko=r(dBt,"bart"),dBt.forEach(t),Iko=r(DDe," \u2014 "),kX=n(DDe,"A",{href:!0});var cBt=s(kX);Nko=r(cBt,"BartModel"),cBt.forEach(t),qko=r(DDe," (BART model)"),DDe.forEach(t),jko=i(x),I_=n(x,"LI",{});var GDe=s(I_);N4e=n(GDe,"STRONG",{});var fBt=s(N4e);Dko=r(fBt,"beit"),fBt.forEach(t),Gko=r(GDe," \u2014 "),SX=n(GDe,"A",{href:!0});var mBt=s(SX);Oko=r(mBt,"BeitModel"),mBt.forEach(t),Vko=r(GDe," (BEiT model)"),GDe.forEach(t),Xko=i(x),N_=n(x,"LI",{});var ODe=s(N_);q4e=n(ODe,"STRONG",{});var gBt=s(q4e);zko=r(gBt,"bert"),gBt.forEach(t),Qko=r(ODe," \u2014 "),RX=n(ODe,"A",{href:!0});var hBt=s(RX);Wko=r(hBt,"BertModel"),hBt.forEach(t),Uko=r(ODe," (BERT model)"),ODe.forEach(t),Hko=i(x),q_=n(x,"LI",{});var VDe=s(q_);j4e=n(VDe,"STRONG",{});var uBt=s(j4e);Jko=r(uBt,"bert-generation"),uBt.forEach(t),Yko=r(VDe," \u2014 "),PX=n(VDe,"A",{href:!0});var pBt=s(PX);Zko=r(pBt,"BertGenerationEncoder"),pBt.forEach(t),Kko=r(VDe," (Bert Generation model)"),VDe.forEach(t),eSo=i(x),j_=n(x,"LI",{});var XDe=s(j_);D4e=n(XDe,"STRONG",{});var _Bt=s(D4e);oSo=r(_Bt,"big_bird"),_Bt.forEach(t),rSo=r(XDe," \u2014 "),BX=n(XDe,"A",{href:!0});var vBt=s(BX);tSo=r(vBt,"BigBirdModel"),vBt.forEach(t),aSo=r(XDe," (BigBird model)"),XDe.forEach(t),nSo=i(x),D_=n(x,"LI",{});var zDe=s(D_);G4e=n(zDe,"STRONG",{});var bBt=s(G4e);sSo=r(bBt,"bigbird_pegasus"),bBt.forEach(t),lSo=r(zDe," \u2014 "),IX=n(zDe,"A",{href:!0});var FBt=s(IX);iSo=r(FBt,"BigBirdPegasusModel"),FBt.forEach(t),dSo=r(zDe," (BigBird-Pegasus model)"),zDe.forEach(t),cSo=i(x),G_=n(x,"LI",{});var QDe=s(G_);O4e=n(QDe,"STRONG",{});var TBt=s(O4e);fSo=r(TBt,"blenderbot"),TBt.forEach(t),mSo=r(QDe," \u2014 "),NX=n(QDe,"A",{href:!0});var MBt=s(NX);gSo=r(MBt,"BlenderbotModel"),MBt.forEach(t),hSo=r(QDe," (Blenderbot model)"),QDe.forEach(t),uSo=i(x),O_=n(x,"LI",{});var WDe=s(O_);V4e=n(WDe,"STRONG",{});var EBt=s(V4e);pSo=r(EBt,"blenderbot-small"),EBt.forEach(t),_So=r(WDe," \u2014 "),qX=n(WDe,"A",{href:!0});var CBt=s(qX);vSo=r(CBt,"BlenderbotSmallModel"),CBt.forEach(t),bSo=r(WDe," (BlenderbotSmall model)"),WDe.forEach(t),FSo=i(x),V_=n(x,"LI",{});var UDe=s(V_);X4e=n(UDe,"STRONG",{});var wBt=s(X4e);TSo=r(wBt,"bloom"),wBt.forEach(t),MSo=r(UDe," \u2014 "),jX=n(UDe,"A",{href:!0});var ABt=s(jX);ESo=r(ABt,"BloomModel"),ABt.forEach(t),CSo=r(UDe," (BLOOM model)"),UDe.forEach(t),wSo=i(x),X_=n(x,"LI",{});var HDe=s(X_);z4e=n(HDe,"STRONG",{});var LBt=s(z4e);ASo=r(LBt,"camembert"),LBt.forEach(t),LSo=r(HDe," \u2014 "),DX=n(HDe,"A",{href:!0});var yBt=s(DX);ySo=r(yBt,"CamembertModel"),yBt.forEach(t),xSo=r(HDe," (CamemBERT model)"),HDe.forEach(t),$So=i(x),z_=n(x,"LI",{});var JDe=s(z_);Q4e=n(JDe,"STRONG",{});var xBt=s(Q4e);kSo=r(xBt,"canine"),xBt.forEach(t),SSo=r(JDe," \u2014 "),GX=n(JDe,"A",{href:!0});var $Bt=s(GX);RSo=r($Bt,"CanineModel"),$Bt.forEach(t),PSo=r(JDe," (CANINE model)"),JDe.forEach(t),BSo=i(x),Q_=n(x,"LI",{});var YDe=s(Q_);W4e=n(YDe,"STRONG",{});var kBt=s(W4e);ISo=r(kBt,"clip"),kBt.forEach(t),NSo=r(YDe," \u2014 "),OX=n(YDe,"A",{href:!0});var SBt=s(OX);qSo=r(SBt,"CLIPModel"),SBt.forEach(t),jSo=r(YDe," (CLIP model)"),YDe.forEach(t),DSo=i(x),W_=n(x,"LI",{});var ZDe=s(W_);U4e=n(ZDe,"STRONG",{});var RBt=s(U4e);GSo=r(RBt,"codegen"),RBt.forEach(t),OSo=r(ZDe," \u2014 "),VX=n(ZDe,"A",{href:!0});var PBt=s(VX);VSo=r(PBt,"CodeGenModel"),PBt.forEach(t),XSo=r(ZDe," (CodeGen model)"),ZDe.forEach(t),zSo=i(x),U_=n(x,"LI",{});var KDe=s(U_);H4e=n(KDe,"STRONG",{});var BBt=s(H4e);QSo=r(BBt,"conditional_detr"),BBt.forEach(t),WSo=r(KDe," \u2014 "),XX=n(KDe,"A",{href:!0});var IBt=s(XX);USo=r(IBt,"ConditionalDetrModel"),IBt.forEach(t),HSo=r(KDe," (Conditional DETR model)"),KDe.forEach(t),JSo=i(x),H_=n(x,"LI",{});var eGe=s(H_);J4e=n(eGe,"STRONG",{});var NBt=s(J4e);YSo=r(NBt,"convbert"),NBt.forEach(t),ZSo=r(eGe," \u2014 "),zX=n(eGe,"A",{href:!0});var qBt=s(zX);KSo=r(qBt,"ConvBertModel"),qBt.forEach(t),eRo=r(eGe," (ConvBERT model)"),eGe.forEach(t),oRo=i(x),J_=n(x,"LI",{});var oGe=s(J_);Y4e=n(oGe,"STRONG",{});var jBt=s(Y4e);rRo=r(jBt,"convnext"),jBt.forEach(t),tRo=r(oGe," \u2014 "),QX=n(oGe,"A",{href:!0});var DBt=s(QX);aRo=r(DBt,"ConvNextModel"),DBt.forEach(t),nRo=r(oGe," (ConvNeXT model)"),oGe.forEach(t),sRo=i(x),Y_=n(x,"LI",{});var rGe=s(Y_);Z4e=n(rGe,"STRONG",{});var GBt=s(Z4e);lRo=r(GBt,"ctrl"),GBt.forEach(t),iRo=r(rGe," \u2014 "),WX=n(rGe,"A",{href:!0});var OBt=s(WX);dRo=r(OBt,"CTRLModel"),OBt.forEach(t),cRo=r(rGe," (CTRL model)"),rGe.forEach(t),fRo=i(x),Z_=n(x,"LI",{});var tGe=s(Z_);K4e=n(tGe,"STRONG",{});var VBt=s(K4e);mRo=r(VBt,"cvt"),VBt.forEach(t),gRo=r(tGe," \u2014 "),UX=n(tGe,"A",{href:!0});var XBt=s(UX);hRo=r(XBt,"CvtModel"),XBt.forEach(t),uRo=r(tGe," (CvT model)"),tGe.forEach(t),pRo=i(x),K_=n(x,"LI",{});var aGe=s(K_);e2e=n(aGe,"STRONG",{});var zBt=s(e2e);_Ro=r(zBt,"data2vec-audio"),zBt.forEach(t),vRo=r(aGe," \u2014 "),HX=n(aGe,"A",{href:!0});var QBt=s(HX);bRo=r(QBt,"Data2VecAudioModel"),QBt.forEach(t),FRo=r(aGe," (Data2VecAudio model)"),aGe.forEach(t),TRo=i(x),e4=n(x,"LI",{});var nGe=s(e4);o2e=n(nGe,"STRONG",{});var WBt=s(o2e);MRo=r(WBt,"data2vec-text"),WBt.forEach(t),ERo=r(nGe," \u2014 "),JX=n(nGe,"A",{href:!0});var UBt=s(JX);CRo=r(UBt,"Data2VecTextModel"),UBt.forEach(t),wRo=r(nGe," (Data2VecText model)"),nGe.forEach(t),ARo=i(x),o4=n(x,"LI",{});var sGe=s(o4);r2e=n(sGe,"STRONG",{});var HBt=s(r2e);LRo=r(HBt,"data2vec-vision"),HBt.forEach(t),yRo=r(sGe," \u2014 "),YX=n(sGe,"A",{href:!0});var JBt=s(YX);xRo=r(JBt,"Data2VecVisionModel"),JBt.forEach(t),$Ro=r(sGe," (Data2VecVision model)"),sGe.forEach(t),kRo=i(x),r4=n(x,"LI",{});var lGe=s(r4);t2e=n(lGe,"STRONG",{});var YBt=s(t2e);SRo=r(YBt,"deberta"),YBt.forEach(t),RRo=r(lGe," \u2014 "),ZX=n(lGe,"A",{href:!0});var ZBt=s(ZX);PRo=r(ZBt,"DebertaModel"),ZBt.forEach(t),BRo=r(lGe," (DeBERTa model)"),lGe.forEach(t),IRo=i(x),t4=n(x,"LI",{});var iGe=s(t4);a2e=n(iGe,"STRONG",{});var KBt=s(a2e);NRo=r(KBt,"deberta-v2"),KBt.forEach(t),qRo=r(iGe," \u2014 "),KX=n(iGe,"A",{href:!0});var eIt=s(KX);jRo=r(eIt,"DebertaV2Model"),eIt.forEach(t),DRo=r(iGe," (DeBERTa-v2 model)"),iGe.forEach(t),GRo=i(x),a4=n(x,"LI",{});var dGe=s(a4);n2e=n(dGe,"STRONG",{});var oIt=s(n2e);ORo=r(oIt,"decision_transformer"),oIt.forEach(t),VRo=r(dGe," \u2014 "),ez=n(dGe,"A",{href:!0});var rIt=s(ez);XRo=r(rIt,"DecisionTransformerModel"),rIt.forEach(t),zRo=r(dGe," (Decision Transformer model)"),dGe.forEach(t),QRo=i(x),n4=n(x,"LI",{});var cGe=s(n4);s2e=n(cGe,"STRONG",{});var tIt=s(s2e);WRo=r(tIt,"deformable_detr"),tIt.forEach(t),URo=r(cGe," \u2014 "),oz=n(cGe,"A",{href:!0});var aIt=s(oz);HRo=r(aIt,"DeformableDetrModel"),aIt.forEach(t),JRo=r(cGe," (Deformable DETR model)"),cGe.forEach(t),YRo=i(x),s4=n(x,"LI",{});var fGe=s(s4);l2e=n(fGe,"STRONG",{});var nIt=s(l2e);ZRo=r(nIt,"deit"),nIt.forEach(t),KRo=r(fGe," \u2014 "),rz=n(fGe,"A",{href:!0});var sIt=s(rz);ePo=r(sIt,"DeiTModel"),sIt.forEach(t),oPo=r(fGe," (DeiT model)"),fGe.forEach(t),rPo=i(x),l4=n(x,"LI",{});var mGe=s(l4);i2e=n(mGe,"STRONG",{});var lIt=s(i2e);tPo=r(lIt,"detr"),lIt.forEach(t),aPo=r(mGe," \u2014 "),tz=n(mGe,"A",{href:!0});var iIt=s(tz);nPo=r(iIt,"DetrModel"),iIt.forEach(t),sPo=r(mGe," (DETR model)"),mGe.forEach(t),lPo=i(x),i4=n(x,"LI",{});var gGe=s(i4);d2e=n(gGe,"STRONG",{});var dIt=s(d2e);iPo=r(dIt,"distilbert"),dIt.forEach(t),dPo=r(gGe," \u2014 "),az=n(gGe,"A",{href:!0});var cIt=s(az);cPo=r(cIt,"DistilBertModel"),cIt.forEach(t),fPo=r(gGe," (DistilBERT model)"),gGe.forEach(t),mPo=i(x),d4=n(x,"LI",{});var hGe=s(d4);c2e=n(hGe,"STRONG",{});var fIt=s(c2e);gPo=r(fIt,"donut-swin"),fIt.forEach(t),hPo=r(hGe," \u2014 "),nz=n(hGe,"A",{href:!0});var mIt=s(nz);uPo=r(mIt,"DonutSwinModel"),mIt.forEach(t),pPo=r(hGe," (DonutSwin model)"),hGe.forEach(t),_Po=i(x),c4=n(x,"LI",{});var uGe=s(c4);f2e=n(uGe,"STRONG",{});var gIt=s(f2e);vPo=r(gIt,"dpr"),gIt.forEach(t),bPo=r(uGe," \u2014 "),sz=n(uGe,"A",{href:!0});var hIt=s(sz);FPo=r(hIt,"DPRQuestionEncoder"),hIt.forEach(t),TPo=r(uGe," (DPR model)"),uGe.forEach(t),MPo=i(x),f4=n(x,"LI",{});var pGe=s(f4);m2e=n(pGe,"STRONG",{});var uIt=s(m2e);EPo=r(uIt,"dpt"),uIt.forEach(t),CPo=r(pGe," \u2014 "),lz=n(pGe,"A",{href:!0});var pIt=s(lz);wPo=r(pIt,"DPTModel"),pIt.forEach(t),APo=r(pGe," (DPT model)"),pGe.forEach(t),LPo=i(x),m4=n(x,"LI",{});var _Ge=s(m4);g2e=n(_Ge,"STRONG",{});var _It=s(g2e);yPo=r(_It,"electra"),_It.forEach(t),xPo=r(_Ge," \u2014 "),iz=n(_Ge,"A",{href:!0});var vIt=s(iz);$Po=r(vIt,"ElectraModel"),vIt.forEach(t),kPo=r(_Ge," (ELECTRA model)"),_Ge.forEach(t),SPo=i(x),g4=n(x,"LI",{});var vGe=s(g4);h2e=n(vGe,"STRONG",{});var bIt=s(h2e);RPo=r(bIt,"ernie"),bIt.forEach(t),PPo=r(vGe," \u2014 "),dz=n(vGe,"A",{href:!0});var FIt=s(dz);BPo=r(FIt,"ErnieModel"),FIt.forEach(t),IPo=r(vGe," (ERNIE model)"),vGe.forEach(t),NPo=i(x),h4=n(x,"LI",{});var bGe=s(h4);u2e=n(bGe,"STRONG",{});var TIt=s(u2e);qPo=r(TIt,"esm"),TIt.forEach(t),jPo=r(bGe," \u2014 "),cz=n(bGe,"A",{href:!0});var MIt=s(cz);DPo=r(MIt,"EsmModel"),MIt.forEach(t),GPo=r(bGe," (ESM model)"),bGe.forEach(t),OPo=i(x),u4=n(x,"LI",{});var FGe=s(u4);p2e=n(FGe,"STRONG",{});var EIt=s(p2e);VPo=r(EIt,"flaubert"),EIt.forEach(t),XPo=r(FGe," \u2014 "),fz=n(FGe,"A",{href:!0});var CIt=s(fz);zPo=r(CIt,"FlaubertModel"),CIt.forEach(t),QPo=r(FGe," (FlauBERT model)"),FGe.forEach(t),WPo=i(x),p4=n(x,"LI",{});var TGe=s(p4);_2e=n(TGe,"STRONG",{});var wIt=s(_2e);UPo=r(wIt,"flava"),wIt.forEach(t),HPo=r(TGe," \u2014 "),mz=n(TGe,"A",{href:!0});var AIt=s(mz);JPo=r(AIt,"FlavaModel"),AIt.forEach(t),YPo=r(TGe," (FLAVA model)"),TGe.forEach(t),ZPo=i(x),_4=n(x,"LI",{});var MGe=s(_4);v2e=n(MGe,"STRONG",{});var LIt=s(v2e);KPo=r(LIt,"fnet"),LIt.forEach(t),eBo=r(MGe," \u2014 "),gz=n(MGe,"A",{href:!0});var yIt=s(gz);oBo=r(yIt,"FNetModel"),yIt.forEach(t),rBo=r(MGe," (FNet model)"),MGe.forEach(t),tBo=i(x),v4=n(x,"LI",{});var EGe=s(v4);b2e=n(EGe,"STRONG",{});var xIt=s(b2e);aBo=r(xIt,"fsmt"),xIt.forEach(t),nBo=r(EGe," \u2014 "),hz=n(EGe,"A",{href:!0});var $It=s(hz);sBo=r($It,"FSMTModel"),$It.forEach(t),lBo=r(EGe," (FairSeq Machine-Translation model)"),EGe.forEach(t),iBo=i(x),xl=n(x,"LI",{});var _N=s(xl);F2e=n(_N,"STRONG",{});var kIt=s(F2e);dBo=r(kIt,"funnel"),kIt.forEach(t),cBo=r(_N," \u2014 "),uz=n(_N,"A",{href:!0});var SIt=s(uz);fBo=r(SIt,"FunnelModel"),SIt.forEach(t),mBo=r(_N," or "),pz=n(_N,"A",{href:!0});var RIt=s(pz);gBo=r(RIt,"FunnelBaseModel"),RIt.forEach(t),hBo=r(_N," (Funnel Transformer model)"),_N.forEach(t),uBo=i(x),b4=n(x,"LI",{});var CGe=s(b4);T2e=n(CGe,"STRONG",{});var PIt=s(T2e);pBo=r(PIt,"glpn"),PIt.forEach(t),_Bo=r(CGe," \u2014 "),_z=n(CGe,"A",{href:!0});var BIt=s(_z);vBo=r(BIt,"GLPNModel"),BIt.forEach(t),bBo=r(CGe," (GLPN model)"),CGe.forEach(t),FBo=i(x),F4=n(x,"LI",{});var wGe=s(F4);M2e=n(wGe,"STRONG",{});var IIt=s(M2e);TBo=r(IIt,"gpt2"),IIt.forEach(t),MBo=r(wGe," \u2014 "),vz=n(wGe,"A",{href:!0});var NIt=s(vz);EBo=r(NIt,"GPT2Model"),NIt.forEach(t),CBo=r(wGe," (OpenAI GPT-2 model)"),wGe.forEach(t),wBo=i(x),T4=n(x,"LI",{});var AGe=s(T4);E2e=n(AGe,"STRONG",{});var qIt=s(E2e);ABo=r(qIt,"gpt_neo"),qIt.forEach(t),LBo=r(AGe," \u2014 "),bz=n(AGe,"A",{href:!0});var jIt=s(bz);yBo=r(jIt,"GPTNeoModel"),jIt.forEach(t),xBo=r(AGe," (GPT Neo model)"),AGe.forEach(t),$Bo=i(x),M4=n(x,"LI",{});var LGe=s(M4);C2e=n(LGe,"STRONG",{});var DIt=s(C2e);kBo=r(DIt,"gpt_neox"),DIt.forEach(t),SBo=r(LGe," \u2014 "),Fz=n(LGe,"A",{href:!0});var GIt=s(Fz);RBo=r(GIt,"GPTNeoXModel"),GIt.forEach(t),PBo=r(LGe," (GPT NeoX model)"),LGe.forEach(t),BBo=i(x),E4=n(x,"LI",{});var yGe=s(E4);w2e=n(yGe,"STRONG",{});var OIt=s(w2e);IBo=r(OIt,"gpt_neox_japanese"),OIt.forEach(t),NBo=r(yGe," \u2014 "),Tz=n(yGe,"A",{href:!0});var VIt=s(Tz);qBo=r(VIt,"GPTNeoXJapaneseModel"),VIt.forEach(t),jBo=r(yGe," (GPT NeoX Japanese model)"),yGe.forEach(t),DBo=i(x),C4=n(x,"LI",{});var xGe=s(C4);A2e=n(xGe,"STRONG",{});var XIt=s(A2e);GBo=r(XIt,"gptj"),XIt.forEach(t),OBo=r(xGe," \u2014 "),Mz=n(xGe,"A",{href:!0});var zIt=s(Mz);VBo=r(zIt,"GPTJModel"),zIt.forEach(t),XBo=r(xGe," (GPT-J model)"),xGe.forEach(t),zBo=i(x),w4=n(x,"LI",{});var $Ge=s(w4);L2e=n($Ge,"STRONG",{});var QIt=s(L2e);QBo=r(QIt,"groupvit"),QIt.forEach(t),WBo=r($Ge," \u2014 "),Ez=n($Ge,"A",{href:!0});var WIt=s(Ez);UBo=r(WIt,"GroupViTModel"),WIt.forEach(t),HBo=r($Ge," (GroupViT model)"),$Ge.forEach(t),JBo=i(x),A4=n(x,"LI",{});var kGe=s(A4);y2e=n(kGe,"STRONG",{});var UIt=s(y2e);YBo=r(UIt,"hubert"),UIt.forEach(t),ZBo=r(kGe," \u2014 "),Cz=n(kGe,"A",{href:!0});var HIt=s(Cz);KBo=r(HIt,"HubertModel"),HIt.forEach(t),eIo=r(kGe," (Hubert model)"),kGe.forEach(t),oIo=i(x),L4=n(x,"LI",{});var SGe=s(L4);x2e=n(SGe,"STRONG",{});var JIt=s(x2e);rIo=r(JIt,"ibert"),JIt.forEach(t),tIo=r(SGe," \u2014 "),wz=n(SGe,"A",{href:!0});var YIt=s(wz);aIo=r(YIt,"IBertModel"),YIt.forEach(t),nIo=r(SGe," (I-BERT model)"),SGe.forEach(t),sIo=i(x),y4=n(x,"LI",{});var RGe=s(y4);$2e=n(RGe,"STRONG",{});var ZIt=s($2e);lIo=r(ZIt,"imagegpt"),ZIt.forEach(t),iIo=r(RGe," \u2014 "),Az=n(RGe,"A",{href:!0});var KIt=s(Az);dIo=r(KIt,"ImageGPTModel"),KIt.forEach(t),cIo=r(RGe," (ImageGPT model)"),RGe.forEach(t),fIo=i(x),x4=n(x,"LI",{});var PGe=s(x4);k2e=n(PGe,"STRONG",{});var eNt=s(k2e);mIo=r(eNt,"layoutlm"),eNt.forEach(t),gIo=r(PGe," \u2014 "),Lz=n(PGe,"A",{href:!0});var oNt=s(Lz);hIo=r(oNt,"LayoutLMModel"),oNt.forEach(t),uIo=r(PGe," (LayoutLM model)"),PGe.forEach(t),pIo=i(x),$4=n(x,"LI",{});var BGe=s($4);S2e=n(BGe,"STRONG",{});var rNt=s(S2e);_Io=r(rNt,"layoutlmv2"),rNt.forEach(t),vIo=r(BGe," \u2014 "),yz=n(BGe,"A",{href:!0});var tNt=s(yz);bIo=r(tNt,"LayoutLMv2Model"),tNt.forEach(t),FIo=r(BGe," (LayoutLMv2 model)"),BGe.forEach(t),TIo=i(x),k4=n(x,"LI",{});var IGe=s(k4);R2e=n(IGe,"STRONG",{});var aNt=s(R2e);MIo=r(aNt,"layoutlmv3"),aNt.forEach(t),EIo=r(IGe," \u2014 "),xz=n(IGe,"A",{href:!0});var nNt=s(xz);CIo=r(nNt,"LayoutLMv3Model"),nNt.forEach(t),wIo=r(IGe," (LayoutLMv3 model)"),IGe.forEach(t),AIo=i(x),S4=n(x,"LI",{});var NGe=s(S4);P2e=n(NGe,"STRONG",{});var sNt=s(P2e);LIo=r(sNt,"led"),sNt.forEach(t),yIo=r(NGe," \u2014 "),$z=n(NGe,"A",{href:!0});var lNt=s($z);xIo=r(lNt,"LEDModel"),lNt.forEach(t),$Io=r(NGe," (LED model)"),NGe.forEach(t),kIo=i(x),R4=n(x,"LI",{});var qGe=s(R4);B2e=n(qGe,"STRONG",{});var iNt=s(B2e);SIo=r(iNt,"levit"),iNt.forEach(t),RIo=r(qGe," \u2014 "),kz=n(qGe,"A",{href:!0});var dNt=s(kz);PIo=r(dNt,"LevitModel"),dNt.forEach(t),BIo=r(qGe," (LeViT model)"),qGe.forEach(t),IIo=i(x),P4=n(x,"LI",{});var jGe=s(P4);I2e=n(jGe,"STRONG",{});var cNt=s(I2e);NIo=r(cNt,"lilt"),cNt.forEach(t),qIo=r(jGe," \u2014 "),Sz=n(jGe,"A",{href:!0});var fNt=s(Sz);jIo=r(fNt,"LiltModel"),fNt.forEach(t),DIo=r(jGe," (LiLT model)"),jGe.forEach(t),GIo=i(x),B4=n(x,"LI",{});var DGe=s(B4);N2e=n(DGe,"STRONG",{});var mNt=s(N2e);OIo=r(mNt,"longformer"),mNt.forEach(t),VIo=r(DGe," \u2014 "),Rz=n(DGe,"A",{href:!0});var gNt=s(Rz);XIo=r(gNt,"LongformerModel"),gNt.forEach(t),zIo=r(DGe," (Longformer model)"),DGe.forEach(t),QIo=i(x),I4=n(x,"LI",{});var GGe=s(I4);q2e=n(GGe,"STRONG",{});var hNt=s(q2e);WIo=r(hNt,"longt5"),hNt.forEach(t),UIo=r(GGe," \u2014 "),Pz=n(GGe,"A",{href:!0});var uNt=s(Pz);HIo=r(uNt,"LongT5Model"),uNt.forEach(t),JIo=r(GGe," (LongT5 model)"),GGe.forEach(t),YIo=i(x),N4=n(x,"LI",{});var OGe=s(N4);j2e=n(OGe,"STRONG",{});var pNt=s(j2e);ZIo=r(pNt,"luke"),pNt.forEach(t),KIo=r(OGe," \u2014 "),Bz=n(OGe,"A",{href:!0});var _Nt=s(Bz);eNo=r(_Nt,"LukeModel"),_Nt.forEach(t),oNo=r(OGe," (LUKE model)"),OGe.forEach(t),rNo=i(x),q4=n(x,"LI",{});var VGe=s(q4);D2e=n(VGe,"STRONG",{});var vNt=s(D2e);tNo=r(vNt,"lxmert"),vNt.forEach(t),aNo=r(VGe," \u2014 "),Iz=n(VGe,"A",{href:!0});var bNt=s(Iz);nNo=r(bNt,"LxmertModel"),bNt.forEach(t),sNo=r(VGe," (LXMERT model)"),VGe.forEach(t),lNo=i(x),j4=n(x,"LI",{});var XGe=s(j4);G2e=n(XGe,"STRONG",{});var FNt=s(G2e);iNo=r(FNt,"m2m_100"),FNt.forEach(t),dNo=r(XGe," \u2014 "),Nz=n(XGe,"A",{href:!0});var TNt=s(Nz);cNo=r(TNt,"M2M100Model"),TNt.forEach(t),fNo=r(XGe," (M2M100 model)"),XGe.forEach(t),mNo=i(x),D4=n(x,"LI",{});var zGe=s(D4);O2e=n(zGe,"STRONG",{});var MNt=s(O2e);gNo=r(MNt,"marian"),MNt.forEach(t),hNo=r(zGe," \u2014 "),qz=n(zGe,"A",{href:!0});var ENt=s(qz);uNo=r(ENt,"MarianModel"),ENt.forEach(t),pNo=r(zGe," (Marian model)"),zGe.forEach(t),_No=i(x),G4=n(x,"LI",{});var QGe=s(G4);V2e=n(QGe,"STRONG",{});var CNt=s(V2e);vNo=r(CNt,"markuplm"),CNt.forEach(t),bNo=r(QGe," \u2014 "),jz=n(QGe,"A",{href:!0});var wNt=s(jz);FNo=r(wNt,"MarkupLMModel"),wNt.forEach(t),TNo=r(QGe," (MarkupLM model)"),QGe.forEach(t),MNo=i(x),O4=n(x,"LI",{});var WGe=s(O4);X2e=n(WGe,"STRONG",{});var ANt=s(X2e);ENo=r(ANt,"maskformer"),ANt.forEach(t),CNo=r(WGe," \u2014 "),Dz=n(WGe,"A",{href:!0});var LNt=s(Dz);wNo=r(LNt,"MaskFormerModel"),LNt.forEach(t),ANo=r(WGe," (MaskFormer model)"),WGe.forEach(t),LNo=i(x),V4=n(x,"LI",{});var UGe=s(V4);z2e=n(UGe,"STRONG",{});var yNt=s(z2e);yNo=r(yNt,"mbart"),yNt.forEach(t),xNo=r(UGe," \u2014 "),Gz=n(UGe,"A",{href:!0});var xNt=s(Gz);$No=r(xNt,"MBartModel"),xNt.forEach(t),kNo=r(UGe," (mBART model)"),UGe.forEach(t),SNo=i(x),X4=n(x,"LI",{});var HGe=s(X4);Q2e=n(HGe,"STRONG",{});var $Nt=s(Q2e);RNo=r($Nt,"mctct"),$Nt.forEach(t),PNo=r(HGe," \u2014 "),Oz=n(HGe,"A",{href:!0});var kNt=s(Oz);BNo=r(kNt,"MCTCTModel"),kNt.forEach(t),INo=r(HGe," (M-CTC-T model)"),HGe.forEach(t),NNo=i(x),z4=n(x,"LI",{});var JGe=s(z4);W2e=n(JGe,"STRONG",{});var SNt=s(W2e);qNo=r(SNt,"megatron-bert"),SNt.forEach(t),jNo=r(JGe," \u2014 "),Vz=n(JGe,"A",{href:!0});var RNt=s(Vz);DNo=r(RNt,"MegatronBertModel"),RNt.forEach(t),GNo=r(JGe," (Megatron-BERT model)"),JGe.forEach(t),ONo=i(x),Q4=n(x,"LI",{});var YGe=s(Q4);U2e=n(YGe,"STRONG",{});var PNt=s(U2e);VNo=r(PNt,"mobilebert"),PNt.forEach(t),XNo=r(YGe," \u2014 "),Xz=n(YGe,"A",{href:!0});var BNt=s(Xz);zNo=r(BNt,"MobileBertModel"),BNt.forEach(t),QNo=r(YGe," (MobileBERT model)"),YGe.forEach(t),WNo=i(x),W4=n(x,"LI",{});var ZGe=s(W4);H2e=n(ZGe,"STRONG",{});var INt=s(H2e);UNo=r(INt,"mobilevit"),INt.forEach(t),HNo=r(ZGe," \u2014 "),zz=n(ZGe,"A",{href:!0});var NNt=s(zz);JNo=r(NNt,"MobileViTModel"),NNt.forEach(t),YNo=r(ZGe," (MobileViT model)"),ZGe.forEach(t),ZNo=i(x),U4=n(x,"LI",{});var KGe=s(U4);J2e=n(KGe,"STRONG",{});var qNt=s(J2e);KNo=r(qNt,"mpnet"),qNt.forEach(t),eqo=r(KGe," \u2014 "),Qz=n(KGe,"A",{href:!0});var jNt=s(Qz);oqo=r(jNt,"MPNetModel"),jNt.forEach(t),rqo=r(KGe," (MPNet model)"),KGe.forEach(t),tqo=i(x),H4=n(x,"LI",{});var eOe=s(H4);Y2e=n(eOe,"STRONG",{});var DNt=s(Y2e);aqo=r(DNt,"mt5"),DNt.forEach(t),nqo=r(eOe," \u2014 "),Wz=n(eOe,"A",{href:!0});var GNt=s(Wz);sqo=r(GNt,"MT5Model"),GNt.forEach(t),lqo=r(eOe," (MT5 model)"),eOe.forEach(t),iqo=i(x),J4=n(x,"LI",{});var oOe=s(J4);Z2e=n(oOe,"STRONG",{});var ONt=s(Z2e);dqo=r(ONt,"mvp"),ONt.forEach(t),cqo=r(oOe," \u2014 "),Uz=n(oOe,"A",{href:!0});var VNt=s(Uz);fqo=r(VNt,"MvpModel"),VNt.forEach(t),mqo=r(oOe," (MVP model)"),oOe.forEach(t),gqo=i(x),Y4=n(x,"LI",{});var rOe=s(Y4);K2e=n(rOe,"STRONG",{});var XNt=s(K2e);hqo=r(XNt,"nezha"),XNt.forEach(t),uqo=r(rOe," \u2014 "),Hz=n(rOe,"A",{href:!0});var zNt=s(Hz);pqo=r(zNt,"NezhaModel"),zNt.forEach(t),_qo=r(rOe," (Nezha model)"),rOe.forEach(t),vqo=i(x),Z4=n(x,"LI",{});var tOe=s(Z4);eve=n(tOe,"STRONG",{});var QNt=s(eve);bqo=r(QNt,"nllb"),QNt.forEach(t),Fqo=r(tOe," \u2014 "),Jz=n(tOe,"A",{href:!0});var WNt=s(Jz);Tqo=r(WNt,"M2M100Model"),WNt.forEach(t),Mqo=r(tOe," (NLLB model)"),tOe.forEach(t),Eqo=i(x),K4=n(x,"LI",{});var aOe=s(K4);ove=n(aOe,"STRONG",{});var UNt=s(ove);Cqo=r(UNt,"nystromformer"),UNt.forEach(t),wqo=r(aOe," \u2014 "),Yz=n(aOe,"A",{href:!0});var HNt=s(Yz);Aqo=r(HNt,"NystromformerModel"),HNt.forEach(t),Lqo=r(aOe," (Nystr\xF6mformer model)"),aOe.forEach(t),yqo=i(x),e2=n(x,"LI",{});var nOe=s(e2);rve=n(nOe,"STRONG",{});var JNt=s(rve);xqo=r(JNt,"openai-gpt"),JNt.forEach(t),$qo=r(nOe," \u2014 "),Zz=n(nOe,"A",{href:!0});var YNt=s(Zz);kqo=r(YNt,"OpenAIGPTModel"),YNt.forEach(t),Sqo=r(nOe," (OpenAI GPT model)"),nOe.forEach(t),Rqo=i(x),o2=n(x,"LI",{});var sOe=s(o2);tve=n(sOe,"STRONG",{});var ZNt=s(tve);Pqo=r(ZNt,"opt"),ZNt.forEach(t),Bqo=r(sOe," \u2014 "),Kz=n(sOe,"A",{href:!0});var KNt=s(Kz);Iqo=r(KNt,"OPTModel"),KNt.forEach(t),Nqo=r(sOe," (OPT model)"),sOe.forEach(t),qqo=i(x),r2=n(x,"LI",{});var lOe=s(r2);ave=n(lOe,"STRONG",{});var eqt=s(ave);jqo=r(eqt,"owlvit"),eqt.forEach(t),Dqo=r(lOe," \u2014 "),eQ=n(lOe,"A",{href:!0});var oqt=s(eQ);Gqo=r(oqt,"OwlViTModel"),oqt.forEach(t),Oqo=r(lOe," (OWL-ViT model)"),lOe.forEach(t),Vqo=i(x),t2=n(x,"LI",{});var iOe=s(t2);nve=n(iOe,"STRONG",{});var rqt=s(nve);Xqo=r(rqt,"pegasus"),rqt.forEach(t),zqo=r(iOe," \u2014 "),oQ=n(iOe,"A",{href:!0});var tqt=s(oQ);Qqo=r(tqt,"PegasusModel"),tqt.forEach(t),Wqo=r(iOe," (Pegasus model)"),iOe.forEach(t),Uqo=i(x),a2=n(x,"LI",{});var dOe=s(a2);sve=n(dOe,"STRONG",{});var aqt=s(sve);Hqo=r(aqt,"pegasus_x"),aqt.forEach(t),Jqo=r(dOe," \u2014 "),rQ=n(dOe,"A",{href:!0});var nqt=s(rQ);Yqo=r(nqt,"PegasusXModel"),nqt.forEach(t),Zqo=r(dOe," (PEGASUS-X model)"),dOe.forEach(t),Kqo=i(x),n2=n(x,"LI",{});var cOe=s(n2);lve=n(cOe,"STRONG",{});var sqt=s(lve);ejo=r(sqt,"perceiver"),sqt.forEach(t),ojo=r(cOe," \u2014 "),tQ=n(cOe,"A",{href:!0});var lqt=s(tQ);rjo=r(lqt,"PerceiverModel"),lqt.forEach(t),tjo=r(cOe," (Perceiver model)"),cOe.forEach(t),ajo=i(x),s2=n(x,"LI",{});var fOe=s(s2);ive=n(fOe,"STRONG",{});var iqt=s(ive);njo=r(iqt,"plbart"),iqt.forEach(t),sjo=r(fOe," \u2014 "),aQ=n(fOe,"A",{href:!0});var dqt=s(aQ);ljo=r(dqt,"PLBartModel"),dqt.forEach(t),ijo=r(fOe," (PLBart model)"),fOe.forEach(t),djo=i(x),l2=n(x,"LI",{});var mOe=s(l2);dve=n(mOe,"STRONG",{});var cqt=s(dve);cjo=r(cqt,"poolformer"),cqt.forEach(t),fjo=r(mOe," \u2014 "),nQ=n(mOe,"A",{href:!0});var fqt=s(nQ);mjo=r(fqt,"PoolFormerModel"),fqt.forEach(t),gjo=r(mOe," (PoolFormer model)"),mOe.forEach(t),hjo=i(x),i2=n(x,"LI",{});var gOe=s(i2);cve=n(gOe,"STRONG",{});var mqt=s(cve);ujo=r(mqt,"prophetnet"),mqt.forEach(t),pjo=r(gOe," \u2014 "),sQ=n(gOe,"A",{href:!0});var gqt=s(sQ);_jo=r(gqt,"ProphetNetModel"),gqt.forEach(t),vjo=r(gOe," (ProphetNet model)"),gOe.forEach(t),bjo=i(x),d2=n(x,"LI",{});var hOe=s(d2);fve=n(hOe,"STRONG",{});var hqt=s(fve);Fjo=r(hqt,"qdqbert"),hqt.forEach(t),Tjo=r(hOe," \u2014 "),lQ=n(hOe,"A",{href:!0});var uqt=s(lQ);Mjo=r(uqt,"QDQBertModel"),uqt.forEach(t),Ejo=r(hOe," (QDQBert model)"),hOe.forEach(t),Cjo=i(x),c2=n(x,"LI",{});var uOe=s(c2);mve=n(uOe,"STRONG",{});var pqt=s(mve);wjo=r(pqt,"reformer"),pqt.forEach(t),Ajo=r(uOe," \u2014 "),iQ=n(uOe,"A",{href:!0});var _qt=s(iQ);Ljo=r(_qt,"ReformerModel"),_qt.forEach(t),yjo=r(uOe," (Reformer model)"),uOe.forEach(t),xjo=i(x),f2=n(x,"LI",{});var pOe=s(f2);gve=n(pOe,"STRONG",{});var vqt=s(gve);$jo=r(vqt,"regnet"),vqt.forEach(t),kjo=r(pOe," \u2014 "),dQ=n(pOe,"A",{href:!0});var bqt=s(dQ);Sjo=r(bqt,"RegNetModel"),bqt.forEach(t),Rjo=r(pOe," (RegNet model)"),pOe.forEach(t),Pjo=i(x),m2=n(x,"LI",{});var _Oe=s(m2);hve=n(_Oe,"STRONG",{});var Fqt=s(hve);Bjo=r(Fqt,"rembert"),Fqt.forEach(t),Ijo=r(_Oe," \u2014 "),cQ=n(_Oe,"A",{href:!0});var Tqt=s(cQ);Njo=r(Tqt,"RemBertModel"),Tqt.forEach(t),qjo=r(_Oe," (RemBERT model)"),_Oe.forEach(t),jjo=i(x),g2=n(x,"LI",{});var vOe=s(g2);uve=n(vOe,"STRONG",{});var Mqt=s(uve);Djo=r(Mqt,"resnet"),Mqt.forEach(t),Gjo=r(vOe," \u2014 "),fQ=n(vOe,"A",{href:!0});var Eqt=s(fQ);Ojo=r(Eqt,"ResNetModel"),Eqt.forEach(t),Vjo=r(vOe," (ResNet model)"),vOe.forEach(t),Xjo=i(x),h2=n(x,"LI",{});var bOe=s(h2);pve=n(bOe,"STRONG",{});var Cqt=s(pve);zjo=r(Cqt,"retribert"),Cqt.forEach(t),Qjo=r(bOe," \u2014 "),mQ=n(bOe,"A",{href:!0});var wqt=s(mQ);Wjo=r(wqt,"RetriBertModel"),wqt.forEach(t),Ujo=r(bOe," (RetriBERT model)"),bOe.forEach(t),Hjo=i(x),u2=n(x,"LI",{});var FOe=s(u2);_ve=n(FOe,"STRONG",{});var Aqt=s(_ve);Jjo=r(Aqt,"roberta"),Aqt.forEach(t),Yjo=r(FOe," \u2014 "),gQ=n(FOe,"A",{href:!0});var Lqt=s(gQ);Zjo=r(Lqt,"RobertaModel"),Lqt.forEach(t),Kjo=r(FOe," (RoBERTa model)"),FOe.forEach(t),eDo=i(x),p2=n(x,"LI",{});var TOe=s(p2);vve=n(TOe,"STRONG",{});var yqt=s(vve);oDo=r(yqt,"roformer"),yqt.forEach(t),rDo=r(TOe," \u2014 "),hQ=n(TOe,"A",{href:!0});var xqt=s(hQ);tDo=r(xqt,"RoFormerModel"),xqt.forEach(t),aDo=r(TOe," (RoFormer model)"),TOe.forEach(t),nDo=i(x),_2=n(x,"LI",{});var MOe=s(_2);bve=n(MOe,"STRONG",{});var $qt=s(bve);sDo=r($qt,"segformer"),$qt.forEach(t),lDo=r(MOe," \u2014 "),uQ=n(MOe,"A",{href:!0});var kqt=s(uQ);iDo=r(kqt,"SegformerModel"),kqt.forEach(t),dDo=r(MOe," (SegFormer model)"),MOe.forEach(t),cDo=i(x),v2=n(x,"LI",{});var EOe=s(v2);Fve=n(EOe,"STRONG",{});var Sqt=s(Fve);fDo=r(Sqt,"sew"),Sqt.forEach(t),mDo=r(EOe," \u2014 "),pQ=n(EOe,"A",{href:!0});var Rqt=s(pQ);gDo=r(Rqt,"SEWModel"),Rqt.forEach(t),hDo=r(EOe," (SEW model)"),EOe.forEach(t),uDo=i(x),b2=n(x,"LI",{});var COe=s(b2);Tve=n(COe,"STRONG",{});var Pqt=s(Tve);pDo=r(Pqt,"sew-d"),Pqt.forEach(t),_Do=r(COe," \u2014 "),_Q=n(COe,"A",{href:!0});var Bqt=s(_Q);vDo=r(Bqt,"SEWDModel"),Bqt.forEach(t),bDo=r(COe," (SEW-D model)"),COe.forEach(t),FDo=i(x),F2=n(x,"LI",{});var wOe=s(F2);Mve=n(wOe,"STRONG",{});var Iqt=s(Mve);TDo=r(Iqt,"speech_to_text"),Iqt.forEach(t),MDo=r(wOe," \u2014 "),vQ=n(wOe,"A",{href:!0});var Nqt=s(vQ);EDo=r(Nqt,"Speech2TextModel"),Nqt.forEach(t),CDo=r(wOe," (Speech2Text model)"),wOe.forEach(t),wDo=i(x),T2=n(x,"LI",{});var AOe=s(T2);Eve=n(AOe,"STRONG",{});var qqt=s(Eve);ADo=r(qqt,"splinter"),qqt.forEach(t),LDo=r(AOe," \u2014 "),bQ=n(AOe,"A",{href:!0});var jqt=s(bQ);yDo=r(jqt,"SplinterModel"),jqt.forEach(t),xDo=r(AOe," (Splinter model)"),AOe.forEach(t),$Do=i(x),M2=n(x,"LI",{});var LOe=s(M2);Cve=n(LOe,"STRONG",{});var Dqt=s(Cve);kDo=r(Dqt,"squeezebert"),Dqt.forEach(t),SDo=r(LOe," \u2014 "),FQ=n(LOe,"A",{href:!0});var Gqt=s(FQ);RDo=r(Gqt,"SqueezeBertModel"),Gqt.forEach(t),PDo=r(LOe," (SqueezeBERT model)"),LOe.forEach(t),BDo=i(x),E2=n(x,"LI",{});var yOe=s(E2);wve=n(yOe,"STRONG",{});var Oqt=s(wve);IDo=r(Oqt,"swin"),Oqt.forEach(t),NDo=r(yOe," \u2014 "),TQ=n(yOe,"A",{href:!0});var Vqt=s(TQ);qDo=r(Vqt,"SwinModel"),Vqt.forEach(t),jDo=r(yOe," (Swin Transformer model)"),yOe.forEach(t),DDo=i(x),C2=n(x,"LI",{});var xOe=s(C2);Ave=n(xOe,"STRONG",{});var Xqt=s(Ave);GDo=r(Xqt,"swinv2"),Xqt.forEach(t),ODo=r(xOe," \u2014 "),MQ=n(xOe,"A",{href:!0});var zqt=s(MQ);VDo=r(zqt,"Swinv2Model"),zqt.forEach(t),XDo=r(xOe," (Swin Transformer V2 model)"),xOe.forEach(t),zDo=i(x),w2=n(x,"LI",{});var $Oe=s(w2);Lve=n($Oe,"STRONG",{});var Qqt=s(Lve);QDo=r(Qqt,"t5"),Qqt.forEach(t),WDo=r($Oe," \u2014 "),EQ=n($Oe,"A",{href:!0});var Wqt=s(EQ);UDo=r(Wqt,"T5Model"),Wqt.forEach(t),HDo=r($Oe," (T5 model)"),$Oe.forEach(t),JDo=i(x),A2=n(x,"LI",{});var kOe=s(A2);yve=n(kOe,"STRONG",{});var Uqt=s(yve);YDo=r(Uqt,"table-transformer"),Uqt.forEach(t),ZDo=r(kOe," \u2014 "),CQ=n(kOe,"A",{href:!0});var Hqt=s(CQ);KDo=r(Hqt,"TableTransformerModel"),Hqt.forEach(t),eGo=r(kOe," (Table Transformer model)"),kOe.forEach(t),oGo=i(x),L2=n(x,"LI",{});var SOe=s(L2);xve=n(SOe,"STRONG",{});var Jqt=s(xve);rGo=r(Jqt,"tapas"),Jqt.forEach(t),tGo=r(SOe," \u2014 "),wQ=n(SOe,"A",{href:!0});var Yqt=s(wQ);aGo=r(Yqt,"TapasModel"),Yqt.forEach(t),nGo=r(SOe," (TAPAS model)"),SOe.forEach(t),sGo=i(x),y2=n(x,"LI",{});var ROe=s(y2);$ve=n(ROe,"STRONG",{});var Zqt=s($ve);lGo=r(Zqt,"time_series_transformer"),Zqt.forEach(t),iGo=r(ROe," \u2014 "),AQ=n(ROe,"A",{href:!0});var Kqt=s(AQ);dGo=r(Kqt,"TimeSeriesTransformerModel"),Kqt.forEach(t),cGo=r(ROe," (Time Series Transformer model)"),ROe.forEach(t),fGo=i(x),x2=n(x,"LI",{});var POe=s(x2);kve=n(POe,"STRONG",{});var ejt=s(kve);mGo=r(ejt,"trajectory_transformer"),ejt.forEach(t),gGo=r(POe," \u2014 "),LQ=n(POe,"A",{href:!0});var ojt=s(LQ);hGo=r(ojt,"TrajectoryTransformerModel"),ojt.forEach(t),uGo=r(POe," (Trajectory Transformer model)"),POe.forEach(t),pGo=i(x),$2=n(x,"LI",{});var BOe=s($2);Sve=n(BOe,"STRONG",{});var rjt=s(Sve);_Go=r(rjt,"transfo-xl"),rjt.forEach(t),vGo=r(BOe," \u2014 "),yQ=n(BOe,"A",{href:!0});var tjt=s(yQ);bGo=r(tjt,"TransfoXLModel"),tjt.forEach(t),FGo=r(BOe," (Transformer-XL model)"),BOe.forEach(t),TGo=i(x),k2=n(x,"LI",{});var IOe=s(k2);Rve=n(IOe,"STRONG",{});var ajt=s(Rve);MGo=r(ajt,"unispeech"),ajt.forEach(t),EGo=r(IOe," \u2014 "),xQ=n(IOe,"A",{href:!0});var njt=s(xQ);CGo=r(njt,"UniSpeechModel"),njt.forEach(t),wGo=r(IOe," (UniSpeech model)"),IOe.forEach(t),AGo=i(x),S2=n(x,"LI",{});var NOe=s(S2);Pve=n(NOe,"STRONG",{});var sjt=s(Pve);LGo=r(sjt,"unispeech-sat"),sjt.forEach(t),yGo=r(NOe," \u2014 "),$Q=n(NOe,"A",{href:!0});var ljt=s($Q);xGo=r(ljt,"UniSpeechSatModel"),ljt.forEach(t),$Go=r(NOe," (UniSpeechSat model)"),NOe.forEach(t),kGo=i(x),R2=n(x,"LI",{});var qOe=s(R2);Bve=n(qOe,"STRONG",{});var ijt=s(Bve);SGo=r(ijt,"van"),ijt.forEach(t),RGo=r(qOe," \u2014 "),kQ=n(qOe,"A",{href:!0});var djt=s(kQ);PGo=r(djt,"VanModel"),djt.forEach(t),BGo=r(qOe," (VAN model)"),qOe.forEach(t),IGo=i(x),P2=n(x,"LI",{});var jOe=s(P2);Ive=n(jOe,"STRONG",{});var cjt=s(Ive);NGo=r(cjt,"videomae"),cjt.forEach(t),qGo=r(jOe," \u2014 "),SQ=n(jOe,"A",{href:!0});var fjt=s(SQ);jGo=r(fjt,"VideoMAEModel"),fjt.forEach(t),DGo=r(jOe," (VideoMAE model)"),jOe.forEach(t),GGo=i(x),B2=n(x,"LI",{});var DOe=s(B2);Nve=n(DOe,"STRONG",{});var mjt=s(Nve);OGo=r(mjt,"vilt"),mjt.forEach(t),VGo=r(DOe," \u2014 "),RQ=n(DOe,"A",{href:!0});var gjt=s(RQ);XGo=r(gjt,"ViltModel"),gjt.forEach(t),zGo=r(DOe," (ViLT model)"),DOe.forEach(t),QGo=i(x),I2=n(x,"LI",{});var GOe=s(I2);qve=n(GOe,"STRONG",{});var hjt=s(qve);WGo=r(hjt,"vision-text-dual-encoder"),hjt.forEach(t),UGo=r(GOe," \u2014 "),PQ=n(GOe,"A",{href:!0});var ujt=s(PQ);HGo=r(ujt,"VisionTextDualEncoderModel"),ujt.forEach(t),JGo=r(GOe," (VisionTextDualEncoder model)"),GOe.forEach(t),YGo=i(x),N2=n(x,"LI",{});var OOe=s(N2);jve=n(OOe,"STRONG",{});var pjt=s(jve);ZGo=r(pjt,"visual_bert"),pjt.forEach(t),KGo=r(OOe," \u2014 "),BQ=n(OOe,"A",{href:!0});var _jt=s(BQ);eOo=r(_jt,"VisualBertModel"),_jt.forEach(t),oOo=r(OOe," (VisualBERT model)"),OOe.forEach(t),rOo=i(x),q2=n(x,"LI",{});var VOe=s(q2);Dve=n(VOe,"STRONG",{});var vjt=s(Dve);tOo=r(vjt,"vit"),vjt.forEach(t),aOo=r(VOe," \u2014 "),IQ=n(VOe,"A",{href:!0});var bjt=s(IQ);nOo=r(bjt,"ViTModel"),bjt.forEach(t),sOo=r(VOe," (ViT model)"),VOe.forEach(t),lOo=i(x),j2=n(x,"LI",{});var XOe=s(j2);Gve=n(XOe,"STRONG",{});var Fjt=s(Gve);iOo=r(Fjt,"vit_mae"),Fjt.forEach(t),dOo=r(XOe," \u2014 "),NQ=n(XOe,"A",{href:!0});var Tjt=s(NQ);cOo=r(Tjt,"ViTMAEModel"),Tjt.forEach(t),fOo=r(XOe," (ViTMAE model)"),XOe.forEach(t),mOo=i(x),D2=n(x,"LI",{});var zOe=s(D2);Ove=n(zOe,"STRONG",{});var Mjt=s(Ove);gOo=r(Mjt,"vit_msn"),Mjt.forEach(t),hOo=r(zOe," \u2014 "),qQ=n(zOe,"A",{href:!0});var Ejt=s(qQ);uOo=r(Ejt,"ViTMSNModel"),Ejt.forEach(t),pOo=r(zOe," (ViTMSN model)"),zOe.forEach(t),_Oo=i(x),G2=n(x,"LI",{});var QOe=s(G2);Vve=n(QOe,"STRONG",{});var Cjt=s(Vve);vOo=r(Cjt,"wav2vec2"),Cjt.forEach(t),bOo=r(QOe," \u2014 "),jQ=n(QOe,"A",{href:!0});var wjt=s(jQ);FOo=r(wjt,"Wav2Vec2Model"),wjt.forEach(t),TOo=r(QOe," (Wav2Vec2 model)"),QOe.forEach(t),MOo=i(x),O2=n(x,"LI",{});var WOe=s(O2);Xve=n(WOe,"STRONG",{});var Ajt=s(Xve);EOo=r(Ajt,"wav2vec2-conformer"),Ajt.forEach(t),COo=r(WOe," \u2014 "),DQ=n(WOe,"A",{href:!0});var Ljt=s(DQ);wOo=r(Ljt,"Wav2Vec2ConformerModel"),Ljt.forEach(t),AOo=r(WOe," (Wav2Vec2-Conformer model)"),WOe.forEach(t),LOo=i(x),V2=n(x,"LI",{});var UOe=s(V2);zve=n(UOe,"STRONG",{});var yjt=s(zve);yOo=r(yjt,"wavlm"),yjt.forEach(t),xOo=r(UOe," \u2014 "),GQ=n(UOe,"A",{href:!0});var xjt=s(GQ);$Oo=r(xjt,"WavLMModel"),xjt.forEach(t),kOo=r(UOe," (WavLM model)"),UOe.forEach(t),SOo=i(x),X2=n(x,"LI",{});var HOe=s(X2);Qve=n(HOe,"STRONG",{});var $jt=s(Qve);ROo=r($jt,"whisper"),$jt.forEach(t),POo=r(HOe," \u2014 "),OQ=n(HOe,"A",{href:!0});var kjt=s(OQ);BOo=r(kjt,"WhisperModel"),kjt.forEach(t),IOo=r(HOe," (Whisper model)"),HOe.forEach(t),NOo=i(x),z2=n(x,"LI",{});var JOe=s(z2);Wve=n(JOe,"STRONG",{});var Sjt=s(Wve);qOo=r(Sjt,"xclip"),Sjt.forEach(t),jOo=r(JOe," \u2014 "),VQ=n(JOe,"A",{href:!0});var Rjt=s(VQ);DOo=r(Rjt,"XCLIPModel"),Rjt.forEach(t),GOo=r(JOe," (X-CLIP model)"),JOe.forEach(t),OOo=i(x),Q2=n(x,"LI",{});var YOe=s(Q2);Uve=n(YOe,"STRONG",{});var Pjt=s(Uve);VOo=r(Pjt,"xglm"),Pjt.forEach(t),XOo=r(YOe," \u2014 "),XQ=n(YOe,"A",{href:!0});var Bjt=s(XQ);zOo=r(Bjt,"XGLMModel"),Bjt.forEach(t),QOo=r(YOe," (XGLM model)"),YOe.forEach(t),WOo=i(x),W2=n(x,"LI",{});var ZOe=s(W2);Hve=n(ZOe,"STRONG",{});var Ijt=s(Hve);UOo=r(Ijt,"xlm"),Ijt.forEach(t),HOo=r(ZOe," \u2014 "),zQ=n(ZOe,"A",{href:!0});var Njt=s(zQ);JOo=r(Njt,"XLMModel"),Njt.forEach(t),YOo=r(ZOe," (XLM model)"),ZOe.forEach(t),ZOo=i(x),U2=n(x,"LI",{});var KOe=s(U2);Jve=n(KOe,"STRONG",{});var qjt=s(Jve);KOo=r(qjt,"xlm-prophetnet"),qjt.forEach(t),eVo=r(KOe," \u2014 "),QQ=n(KOe,"A",{href:!0});var jjt=s(QQ);oVo=r(jjt,"XLMProphetNetModel"),jjt.forEach(t),rVo=r(KOe," (XLM-ProphetNet model)"),KOe.forEach(t),tVo=i(x),H2=n(x,"LI",{});var eVe=s(H2);Yve=n(eVe,"STRONG",{});var Djt=s(Yve);aVo=r(Djt,"xlm-roberta"),Djt.forEach(t),nVo=r(eVe," \u2014 "),WQ=n(eVe,"A",{href:!0});var Gjt=s(WQ);sVo=r(Gjt,"XLMRobertaModel"),Gjt.forEach(t),lVo=r(eVe," (XLM-RoBERTa model)"),eVe.forEach(t),iVo=i(x),J2=n(x,"LI",{});var oVe=s(J2);Zve=n(oVe,"STRONG",{});var Ojt=s(Zve);dVo=r(Ojt,"xlm-roberta-xl"),Ojt.forEach(t),cVo=r(oVe," \u2014 "),UQ=n(oVe,"A",{href:!0});var Vjt=s(UQ);fVo=r(Vjt,"XLMRobertaXLModel"),Vjt.forEach(t),mVo=r(oVe," (XLM-RoBERTa-XL model)"),oVe.forEach(t),gVo=i(x),Y2=n(x,"LI",{});var rVe=s(Y2);Kve=n(rVe,"STRONG",{});var Xjt=s(Kve);hVo=r(Xjt,"xlnet"),Xjt.forEach(t),uVo=r(rVe," \u2014 "),HQ=n(rVe,"A",{href:!0});var zjt=s(HQ);pVo=r(zjt,"XLNetModel"),zjt.forEach(t),_Vo=r(rVe," (XLNet model)"),rVe.forEach(t),vVo=i(x),Z2=n(x,"LI",{});var tVe=s(Z2);e1e=n(tVe,"STRONG",{});var Qjt=s(e1e);bVo=r(Qjt,"yolos"),Qjt.forEach(t),FVo=r(tVe," \u2014 "),JQ=n(tVe,"A",{href:!0});var Wjt=s(JQ);TVo=r(Wjt,"YolosModel"),Wjt.forEach(t),MVo=r(tVe," (YOLOS model)"),tVe.forEach(t),EVo=i(x),K2=n(x,"LI",{});var aVe=s(K2);o1e=n(aVe,"STRONG",{});var Ujt=s(o1e);CVo=r(Ujt,"yoso"),Ujt.forEach(t),wVo=r(aVe," \u2014 "),YQ=n(aVe,"A",{href:!0});var Hjt=s(YQ);AVo=r(Hjt,"YosoModel"),Hjt.forEach(t),LVo=r(aVe," (YOSO model)"),aVe.forEach(t),x.forEach(t),yVo=i(La),ev=n(La,"P",{});var nVe=s(ev);xVo=r(nVe,"The model is set in evaluation mode by default using "),r1e=n(nVe,"CODE",{});var Jjt=s(r1e);$Vo=r(Jjt,"model.eval()"),Jjt.forEach(t),kVo=r(nVe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),t1e=n(nVe,"CODE",{});var Yjt=s(t1e);SVo=r(Yjt,"model.train()"),Yjt.forEach(t),nVe.forEach(t),RVo=i(La),T(ov.$$.fragment,La),La.forEach(t),ql.forEach(t),Dto=i(f),Bd=n(f,"H2",{class:!0});var aso=s(Bd);rv=n(aso,"A",{id:!0,class:!0,href:!0});var Zjt=s(rv);a1e=n(Zjt,"SPAN",{});var Kjt=s(a1e);T(D$.$$.fragment,Kjt),Kjt.forEach(t),Zjt.forEach(t),PVo=i(aso),n1e=n(aso,"SPAN",{});var eDt=s(n1e);BVo=r(eDt,"AutoModelForPreTraining"),eDt.forEach(t),aso.forEach(t),Gto=i(f),No=n(f,"DIV",{class:!0});var jl=s(No);T(G$.$$.fragment,jl),IVo=i(jl),Id=n(jl,"P",{});var sce=s(Id);NVo=r(sce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),ZQ=n(sce,"A",{href:!0});var oDt=s(ZQ);qVo=r(oDt,"from_pretrained()"),oDt.forEach(t),jVo=r(sce," class method or the "),KQ=n(sce,"A",{href:!0});var rDt=s(KQ);DVo=r(rDt,"from_config()"),rDt.forEach(t),GVo=r(sce,` class
method.`),sce.forEach(t),OVo=i(jl),O$=n(jl,"P",{});var nso=s(O$);VVo=r(nso,"This class cannot be instantiated directly using "),s1e=n(nso,"CODE",{});var tDt=s(s1e);XVo=r(tDt,"__init__()"),tDt.forEach(t),zVo=r(nso," (throws an error)."),nso.forEach(t),QVo=i(jl),Et=n(jl,"DIV",{class:!0});var r9=s(Et);T(V$.$$.fragment,r9),WVo=i(r9),l1e=n(r9,"P",{});var aDt=s(l1e);UVo=r(aDt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),aDt.forEach(t),HVo=i(r9),Nd=n(r9,"P",{});var lce=s(Nd);JVo=r(lce,`Note:
Loading a model from its configuration file does `),i1e=n(lce,"STRONG",{});var nDt=s(i1e);YVo=r(nDt,"not"),nDt.forEach(t),ZVo=r(lce,` load the model weights. It only affects the
model\u2019s configuration. Use `),eW=n(lce,"A",{href:!0});var sDt=s(eW);KVo=r(sDt,"from_pretrained()"),sDt.forEach(t),eXo=r(lce," to load the model weights."),lce.forEach(t),oXo=i(r9),T(tv.$$.fragment,r9),r9.forEach(t),rXo=i(jl),eo=n(jl,"DIV",{class:!0});var ya=s(eo);T(X$.$$.fragment,ya),tXo=i(ya),d1e=n(ya,"P",{});var lDt=s(d1e);aXo=r(lDt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),lDt.forEach(t),nXo=i(ya),sn=n(ya,"P",{});var t9=s(sn);sXo=r(t9,"The model class to instantiate is selected based on the "),c1e=n(t9,"CODE",{});var iDt=s(c1e);lXo=r(iDt,"model_type"),iDt.forEach(t),iXo=r(t9,` property of the config object (either
passed as an argument or loaded from `),f1e=n(t9,"CODE",{});var dDt=s(f1e);dXo=r(dDt,"pretrained_model_name_or_path"),dDt.forEach(t),cXo=r(t9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m1e=n(t9,"CODE",{});var cDt=s(m1e);fXo=r(cDt,"pretrained_model_name_or_path"),cDt.forEach(t),mXo=r(t9,":"),t9.forEach(t),gXo=i(ya),G=n(ya,"UL",{});var V=s(G);av=n(V,"LI",{});var sVe=s(av);g1e=n(sVe,"STRONG",{});var fDt=s(g1e);hXo=r(fDt,"albert"),fDt.forEach(t),uXo=r(sVe," \u2014 "),oW=n(sVe,"A",{href:!0});var mDt=s(oW);pXo=r(mDt,"AlbertForPreTraining"),mDt.forEach(t),_Xo=r(sVe," (ALBERT model)"),sVe.forEach(t),vXo=i(V),nv=n(V,"LI",{});var lVe=s(nv);h1e=n(lVe,"STRONG",{});var gDt=s(h1e);bXo=r(gDt,"bart"),gDt.forEach(t),FXo=r(lVe," \u2014 "),rW=n(lVe,"A",{href:!0});var hDt=s(rW);TXo=r(hDt,"BartForConditionalGeneration"),hDt.forEach(t),MXo=r(lVe," (BART model)"),lVe.forEach(t),EXo=i(V),sv=n(V,"LI",{});var iVe=s(sv);u1e=n(iVe,"STRONG",{});var uDt=s(u1e);CXo=r(uDt,"bert"),uDt.forEach(t),wXo=r(iVe," \u2014 "),tW=n(iVe,"A",{href:!0});var pDt=s(tW);AXo=r(pDt,"BertForPreTraining"),pDt.forEach(t),LXo=r(iVe," (BERT model)"),iVe.forEach(t),yXo=i(V),lv=n(V,"LI",{});var dVe=s(lv);p1e=n(dVe,"STRONG",{});var _Dt=s(p1e);xXo=r(_Dt,"big_bird"),_Dt.forEach(t),$Xo=r(dVe," \u2014 "),aW=n(dVe,"A",{href:!0});var vDt=s(aW);kXo=r(vDt,"BigBirdForPreTraining"),vDt.forEach(t),SXo=r(dVe," (BigBird model)"),dVe.forEach(t),RXo=i(V),iv=n(V,"LI",{});var cVe=s(iv);_1e=n(cVe,"STRONG",{});var bDt=s(_1e);PXo=r(bDt,"bloom"),bDt.forEach(t),BXo=r(cVe," \u2014 "),nW=n(cVe,"A",{href:!0});var FDt=s(nW);IXo=r(FDt,"BloomForCausalLM"),FDt.forEach(t),NXo=r(cVe," (BLOOM model)"),cVe.forEach(t),qXo=i(V),dv=n(V,"LI",{});var fVe=s(dv);v1e=n(fVe,"STRONG",{});var TDt=s(v1e);jXo=r(TDt,"camembert"),TDt.forEach(t),DXo=r(fVe," \u2014 "),sW=n(fVe,"A",{href:!0});var MDt=s(sW);GXo=r(MDt,"CamembertForMaskedLM"),MDt.forEach(t),OXo=r(fVe," (CamemBERT model)"),fVe.forEach(t),VXo=i(V),cv=n(V,"LI",{});var mVe=s(cv);b1e=n(mVe,"STRONG",{});var EDt=s(b1e);XXo=r(EDt,"ctrl"),EDt.forEach(t),zXo=r(mVe," \u2014 "),lW=n(mVe,"A",{href:!0});var CDt=s(lW);QXo=r(CDt,"CTRLLMHeadModel"),CDt.forEach(t),WXo=r(mVe," (CTRL model)"),mVe.forEach(t),UXo=i(V),fv=n(V,"LI",{});var gVe=s(fv);F1e=n(gVe,"STRONG",{});var wDt=s(F1e);HXo=r(wDt,"data2vec-text"),wDt.forEach(t),JXo=r(gVe," \u2014 "),iW=n(gVe,"A",{href:!0});var ADt=s(iW);YXo=r(ADt,"Data2VecTextForMaskedLM"),ADt.forEach(t),ZXo=r(gVe," (Data2VecText model)"),gVe.forEach(t),KXo=i(V),mv=n(V,"LI",{});var hVe=s(mv);T1e=n(hVe,"STRONG",{});var LDt=s(T1e);ezo=r(LDt,"deberta"),LDt.forEach(t),ozo=r(hVe," \u2014 "),dW=n(hVe,"A",{href:!0});var yDt=s(dW);rzo=r(yDt,"DebertaForMaskedLM"),yDt.forEach(t),tzo=r(hVe," (DeBERTa model)"),hVe.forEach(t),azo=i(V),gv=n(V,"LI",{});var uVe=s(gv);M1e=n(uVe,"STRONG",{});var xDt=s(M1e);nzo=r(xDt,"deberta-v2"),xDt.forEach(t),szo=r(uVe," \u2014 "),cW=n(uVe,"A",{href:!0});var $Dt=s(cW);lzo=r($Dt,"DebertaV2ForMaskedLM"),$Dt.forEach(t),izo=r(uVe," (DeBERTa-v2 model)"),uVe.forEach(t),dzo=i(V),hv=n(V,"LI",{});var pVe=s(hv);E1e=n(pVe,"STRONG",{});var kDt=s(E1e);czo=r(kDt,"distilbert"),kDt.forEach(t),fzo=r(pVe," \u2014 "),fW=n(pVe,"A",{href:!0});var SDt=s(fW);mzo=r(SDt,"DistilBertForMaskedLM"),SDt.forEach(t),gzo=r(pVe," (DistilBERT model)"),pVe.forEach(t),hzo=i(V),uv=n(V,"LI",{});var _Ve=s(uv);C1e=n(_Ve,"STRONG",{});var RDt=s(C1e);uzo=r(RDt,"electra"),RDt.forEach(t),pzo=r(_Ve," \u2014 "),mW=n(_Ve,"A",{href:!0});var PDt=s(mW);_zo=r(PDt,"ElectraForPreTraining"),PDt.forEach(t),vzo=r(_Ve," (ELECTRA model)"),_Ve.forEach(t),bzo=i(V),pv=n(V,"LI",{});var vVe=s(pv);w1e=n(vVe,"STRONG",{});var BDt=s(w1e);Fzo=r(BDt,"ernie"),BDt.forEach(t),Tzo=r(vVe," \u2014 "),gW=n(vVe,"A",{href:!0});var IDt=s(gW);Mzo=r(IDt,"ErnieForPreTraining"),IDt.forEach(t),Ezo=r(vVe," (ERNIE model)"),vVe.forEach(t),Czo=i(V),_v=n(V,"LI",{});var bVe=s(_v);A1e=n(bVe,"STRONG",{});var NDt=s(A1e);wzo=r(NDt,"flaubert"),NDt.forEach(t),Azo=r(bVe," \u2014 "),hW=n(bVe,"A",{href:!0});var qDt=s(hW);Lzo=r(qDt,"FlaubertWithLMHeadModel"),qDt.forEach(t),yzo=r(bVe," (FlauBERT model)"),bVe.forEach(t),xzo=i(V),vv=n(V,"LI",{});var FVe=s(vv);L1e=n(FVe,"STRONG",{});var jDt=s(L1e);$zo=r(jDt,"flava"),jDt.forEach(t),kzo=r(FVe," \u2014 "),uW=n(FVe,"A",{href:!0});var DDt=s(uW);Szo=r(DDt,"FlavaForPreTraining"),DDt.forEach(t),Rzo=r(FVe," (FLAVA model)"),FVe.forEach(t),Pzo=i(V),bv=n(V,"LI",{});var TVe=s(bv);y1e=n(TVe,"STRONG",{});var GDt=s(y1e);Bzo=r(GDt,"fnet"),GDt.forEach(t),Izo=r(TVe," \u2014 "),pW=n(TVe,"A",{href:!0});var ODt=s(pW);Nzo=r(ODt,"FNetForPreTraining"),ODt.forEach(t),qzo=r(TVe," (FNet model)"),TVe.forEach(t),jzo=i(V),Fv=n(V,"LI",{});var MVe=s(Fv);x1e=n(MVe,"STRONG",{});var VDt=s(x1e);Dzo=r(VDt,"fsmt"),VDt.forEach(t),Gzo=r(MVe," \u2014 "),_W=n(MVe,"A",{href:!0});var XDt=s(_W);Ozo=r(XDt,"FSMTForConditionalGeneration"),XDt.forEach(t),Vzo=r(MVe," (FairSeq Machine-Translation model)"),MVe.forEach(t),Xzo=i(V),Tv=n(V,"LI",{});var EVe=s(Tv);$1e=n(EVe,"STRONG",{});var zDt=s($1e);zzo=r(zDt,"funnel"),zDt.forEach(t),Qzo=r(EVe," \u2014 "),vW=n(EVe,"A",{href:!0});var QDt=s(vW);Wzo=r(QDt,"FunnelForPreTraining"),QDt.forEach(t),Uzo=r(EVe," (Funnel Transformer model)"),EVe.forEach(t),Hzo=i(V),Mv=n(V,"LI",{});var CVe=s(Mv);k1e=n(CVe,"STRONG",{});var WDt=s(k1e);Jzo=r(WDt,"gpt2"),WDt.forEach(t),Yzo=r(CVe," \u2014 "),bW=n(CVe,"A",{href:!0});var UDt=s(bW);Zzo=r(UDt,"GPT2LMHeadModel"),UDt.forEach(t),Kzo=r(CVe," (OpenAI GPT-2 model)"),CVe.forEach(t),eQo=i(V),Ev=n(V,"LI",{});var wVe=s(Ev);S1e=n(wVe,"STRONG",{});var HDt=s(S1e);oQo=r(HDt,"ibert"),HDt.forEach(t),rQo=r(wVe," \u2014 "),FW=n(wVe,"A",{href:!0});var JDt=s(FW);tQo=r(JDt,"IBertForMaskedLM"),JDt.forEach(t),aQo=r(wVe," (I-BERT model)"),wVe.forEach(t),nQo=i(V),Cv=n(V,"LI",{});var AVe=s(Cv);R1e=n(AVe,"STRONG",{});var YDt=s(R1e);sQo=r(YDt,"layoutlm"),YDt.forEach(t),lQo=r(AVe," \u2014 "),TW=n(AVe,"A",{href:!0});var ZDt=s(TW);iQo=r(ZDt,"LayoutLMForMaskedLM"),ZDt.forEach(t),dQo=r(AVe," (LayoutLM model)"),AVe.forEach(t),cQo=i(V),wv=n(V,"LI",{});var LVe=s(wv);P1e=n(LVe,"STRONG",{});var KDt=s(P1e);fQo=r(KDt,"longformer"),KDt.forEach(t),mQo=r(LVe," \u2014 "),MW=n(LVe,"A",{href:!0});var eGt=s(MW);gQo=r(eGt,"LongformerForMaskedLM"),eGt.forEach(t),hQo=r(LVe," (Longformer model)"),LVe.forEach(t),uQo=i(V),Av=n(V,"LI",{});var yVe=s(Av);B1e=n(yVe,"STRONG",{});var oGt=s(B1e);pQo=r(oGt,"luke"),oGt.forEach(t),_Qo=r(yVe," \u2014 "),EW=n(yVe,"A",{href:!0});var rGt=s(EW);vQo=r(rGt,"LukeForMaskedLM"),rGt.forEach(t),bQo=r(yVe," (LUKE model)"),yVe.forEach(t),FQo=i(V),Lv=n(V,"LI",{});var xVe=s(Lv);I1e=n(xVe,"STRONG",{});var tGt=s(I1e);TQo=r(tGt,"lxmert"),tGt.forEach(t),MQo=r(xVe," \u2014 "),CW=n(xVe,"A",{href:!0});var aGt=s(CW);EQo=r(aGt,"LxmertForPreTraining"),aGt.forEach(t),CQo=r(xVe," (LXMERT model)"),xVe.forEach(t),wQo=i(V),yv=n(V,"LI",{});var $Ve=s(yv);N1e=n($Ve,"STRONG",{});var nGt=s(N1e);AQo=r(nGt,"megatron-bert"),nGt.forEach(t),LQo=r($Ve," \u2014 "),wW=n($Ve,"A",{href:!0});var sGt=s(wW);yQo=r(sGt,"MegatronBertForPreTraining"),sGt.forEach(t),xQo=r($Ve," (Megatron-BERT model)"),$Ve.forEach(t),$Qo=i(V),xv=n(V,"LI",{});var kVe=s(xv);q1e=n(kVe,"STRONG",{});var lGt=s(q1e);kQo=r(lGt,"mobilebert"),lGt.forEach(t),SQo=r(kVe," \u2014 "),AW=n(kVe,"A",{href:!0});var iGt=s(AW);RQo=r(iGt,"MobileBertForPreTraining"),iGt.forEach(t),PQo=r(kVe," (MobileBERT model)"),kVe.forEach(t),BQo=i(V),$v=n(V,"LI",{});var SVe=s($v);j1e=n(SVe,"STRONG",{});var dGt=s(j1e);IQo=r(dGt,"mpnet"),dGt.forEach(t),NQo=r(SVe," \u2014 "),LW=n(SVe,"A",{href:!0});var cGt=s(LW);qQo=r(cGt,"MPNetForMaskedLM"),cGt.forEach(t),jQo=r(SVe," (MPNet model)"),SVe.forEach(t),DQo=i(V),kv=n(V,"LI",{});var RVe=s(kv);D1e=n(RVe,"STRONG",{});var fGt=s(D1e);GQo=r(fGt,"mvp"),fGt.forEach(t),OQo=r(RVe," \u2014 "),yW=n(RVe,"A",{href:!0});var mGt=s(yW);VQo=r(mGt,"MvpForConditionalGeneration"),mGt.forEach(t),XQo=r(RVe," (MVP model)"),RVe.forEach(t),zQo=i(V),Sv=n(V,"LI",{});var PVe=s(Sv);G1e=n(PVe,"STRONG",{});var gGt=s(G1e);QQo=r(gGt,"nezha"),gGt.forEach(t),WQo=r(PVe," \u2014 "),xW=n(PVe,"A",{href:!0});var hGt=s(xW);UQo=r(hGt,"NezhaForPreTraining"),hGt.forEach(t),HQo=r(PVe," (Nezha model)"),PVe.forEach(t),JQo=i(V),Rv=n(V,"LI",{});var BVe=s(Rv);O1e=n(BVe,"STRONG",{});var uGt=s(O1e);YQo=r(uGt,"openai-gpt"),uGt.forEach(t),ZQo=r(BVe," \u2014 "),$W=n(BVe,"A",{href:!0});var pGt=s($W);KQo=r(pGt,"OpenAIGPTLMHeadModel"),pGt.forEach(t),eWo=r(BVe," (OpenAI GPT model)"),BVe.forEach(t),oWo=i(V),Pv=n(V,"LI",{});var IVe=s(Pv);V1e=n(IVe,"STRONG",{});var _Gt=s(V1e);rWo=r(_Gt,"retribert"),_Gt.forEach(t),tWo=r(IVe," \u2014 "),kW=n(IVe,"A",{href:!0});var vGt=s(kW);aWo=r(vGt,"RetriBertModel"),vGt.forEach(t),nWo=r(IVe," (RetriBERT model)"),IVe.forEach(t),sWo=i(V),Bv=n(V,"LI",{});var NVe=s(Bv);X1e=n(NVe,"STRONG",{});var bGt=s(X1e);lWo=r(bGt,"roberta"),bGt.forEach(t),iWo=r(NVe," \u2014 "),SW=n(NVe,"A",{href:!0});var FGt=s(SW);dWo=r(FGt,"RobertaForMaskedLM"),FGt.forEach(t),cWo=r(NVe," (RoBERTa model)"),NVe.forEach(t),fWo=i(V),Iv=n(V,"LI",{});var qVe=s(Iv);z1e=n(qVe,"STRONG",{});var TGt=s(z1e);mWo=r(TGt,"splinter"),TGt.forEach(t),gWo=r(qVe," \u2014 "),RW=n(qVe,"A",{href:!0});var MGt=s(RW);hWo=r(MGt,"SplinterForPreTraining"),MGt.forEach(t),uWo=r(qVe," (Splinter model)"),qVe.forEach(t),pWo=i(V),Nv=n(V,"LI",{});var jVe=s(Nv);Q1e=n(jVe,"STRONG",{});var EGt=s(Q1e);_Wo=r(EGt,"squeezebert"),EGt.forEach(t),vWo=r(jVe," \u2014 "),PW=n(jVe,"A",{href:!0});var CGt=s(PW);bWo=r(CGt,"SqueezeBertForMaskedLM"),CGt.forEach(t),FWo=r(jVe," (SqueezeBERT model)"),jVe.forEach(t),TWo=i(V),qv=n(V,"LI",{});var DVe=s(qv);W1e=n(DVe,"STRONG",{});var wGt=s(W1e);MWo=r(wGt,"t5"),wGt.forEach(t),EWo=r(DVe," \u2014 "),BW=n(DVe,"A",{href:!0});var AGt=s(BW);CWo=r(AGt,"T5ForConditionalGeneration"),AGt.forEach(t),wWo=r(DVe," (T5 model)"),DVe.forEach(t),AWo=i(V),jv=n(V,"LI",{});var GVe=s(jv);U1e=n(GVe,"STRONG",{});var LGt=s(U1e);LWo=r(LGt,"tapas"),LGt.forEach(t),yWo=r(GVe," \u2014 "),IW=n(GVe,"A",{href:!0});var yGt=s(IW);xWo=r(yGt,"TapasForMaskedLM"),yGt.forEach(t),$Wo=r(GVe," (TAPAS model)"),GVe.forEach(t),kWo=i(V),Dv=n(V,"LI",{});var OVe=s(Dv);H1e=n(OVe,"STRONG",{});var xGt=s(H1e);SWo=r(xGt,"transfo-xl"),xGt.forEach(t),RWo=r(OVe," \u2014 "),NW=n(OVe,"A",{href:!0});var $Gt=s(NW);PWo=r($Gt,"TransfoXLLMHeadModel"),$Gt.forEach(t),BWo=r(OVe," (Transformer-XL model)"),OVe.forEach(t),IWo=i(V),Gv=n(V,"LI",{});var VVe=s(Gv);J1e=n(VVe,"STRONG",{});var kGt=s(J1e);NWo=r(kGt,"unispeech"),kGt.forEach(t),qWo=r(VVe," \u2014 "),qW=n(VVe,"A",{href:!0});var SGt=s(qW);jWo=r(SGt,"UniSpeechForPreTraining"),SGt.forEach(t),DWo=r(VVe," (UniSpeech model)"),VVe.forEach(t),GWo=i(V),Ov=n(V,"LI",{});var XVe=s(Ov);Y1e=n(XVe,"STRONG",{});var RGt=s(Y1e);OWo=r(RGt,"unispeech-sat"),RGt.forEach(t),VWo=r(XVe," \u2014 "),jW=n(XVe,"A",{href:!0});var PGt=s(jW);XWo=r(PGt,"UniSpeechSatForPreTraining"),PGt.forEach(t),zWo=r(XVe," (UniSpeechSat model)"),XVe.forEach(t),QWo=i(V),Vv=n(V,"LI",{});var zVe=s(Vv);Z1e=n(zVe,"STRONG",{});var BGt=s(Z1e);WWo=r(BGt,"videomae"),BGt.forEach(t),UWo=r(zVe," \u2014 "),DW=n(zVe,"A",{href:!0});var IGt=s(DW);HWo=r(IGt,"VideoMAEForPreTraining"),IGt.forEach(t),JWo=r(zVe," (VideoMAE model)"),zVe.forEach(t),YWo=i(V),Xv=n(V,"LI",{});var QVe=s(Xv);K1e=n(QVe,"STRONG",{});var NGt=s(K1e);ZWo=r(NGt,"visual_bert"),NGt.forEach(t),KWo=r(QVe," \u2014 "),GW=n(QVe,"A",{href:!0});var qGt=s(GW);eUo=r(qGt,"VisualBertForPreTraining"),qGt.forEach(t),oUo=r(QVe," (VisualBERT model)"),QVe.forEach(t),rUo=i(V),zv=n(V,"LI",{});var WVe=s(zv);ebe=n(WVe,"STRONG",{});var jGt=s(ebe);tUo=r(jGt,"vit_mae"),jGt.forEach(t),aUo=r(WVe," \u2014 "),OW=n(WVe,"A",{href:!0});var DGt=s(OW);nUo=r(DGt,"ViTMAEForPreTraining"),DGt.forEach(t),sUo=r(WVe," (ViTMAE model)"),WVe.forEach(t),lUo=i(V),Qv=n(V,"LI",{});var UVe=s(Qv);obe=n(UVe,"STRONG",{});var GGt=s(obe);iUo=r(GGt,"wav2vec2"),GGt.forEach(t),dUo=r(UVe," \u2014 "),VW=n(UVe,"A",{href:!0});var OGt=s(VW);cUo=r(OGt,"Wav2Vec2ForPreTraining"),OGt.forEach(t),fUo=r(UVe," (Wav2Vec2 model)"),UVe.forEach(t),mUo=i(V),Wv=n(V,"LI",{});var HVe=s(Wv);rbe=n(HVe,"STRONG",{});var VGt=s(rbe);gUo=r(VGt,"wav2vec2-conformer"),VGt.forEach(t),hUo=r(HVe," \u2014 "),XW=n(HVe,"A",{href:!0});var XGt=s(XW);uUo=r(XGt,"Wav2Vec2ConformerForPreTraining"),XGt.forEach(t),pUo=r(HVe," (Wav2Vec2-Conformer model)"),HVe.forEach(t),_Uo=i(V),Uv=n(V,"LI",{});var JVe=s(Uv);tbe=n(JVe,"STRONG",{});var zGt=s(tbe);vUo=r(zGt,"xlm"),zGt.forEach(t),bUo=r(JVe," \u2014 "),zW=n(JVe,"A",{href:!0});var QGt=s(zW);FUo=r(QGt,"XLMWithLMHeadModel"),QGt.forEach(t),TUo=r(JVe," (XLM model)"),JVe.forEach(t),MUo=i(V),Hv=n(V,"LI",{});var YVe=s(Hv);abe=n(YVe,"STRONG",{});var WGt=s(abe);EUo=r(WGt,"xlm-roberta"),WGt.forEach(t),CUo=r(YVe," \u2014 "),QW=n(YVe,"A",{href:!0});var UGt=s(QW);wUo=r(UGt,"XLMRobertaForMaskedLM"),UGt.forEach(t),AUo=r(YVe," (XLM-RoBERTa model)"),YVe.forEach(t),LUo=i(V),Jv=n(V,"LI",{});var ZVe=s(Jv);nbe=n(ZVe,"STRONG",{});var HGt=s(nbe);yUo=r(HGt,"xlm-roberta-xl"),HGt.forEach(t),xUo=r(ZVe," \u2014 "),WW=n(ZVe,"A",{href:!0});var JGt=s(WW);$Uo=r(JGt,"XLMRobertaXLForMaskedLM"),JGt.forEach(t),kUo=r(ZVe," (XLM-RoBERTa-XL model)"),ZVe.forEach(t),SUo=i(V),Yv=n(V,"LI",{});var KVe=s(Yv);sbe=n(KVe,"STRONG",{});var YGt=s(sbe);RUo=r(YGt,"xlnet"),YGt.forEach(t),PUo=r(KVe," \u2014 "),UW=n(KVe,"A",{href:!0});var ZGt=s(UW);BUo=r(ZGt,"XLNetLMHeadModel"),ZGt.forEach(t),IUo=r(KVe," (XLNet model)"),KVe.forEach(t),V.forEach(t),NUo=i(ya),Zv=n(ya,"P",{});var eXe=s(Zv);qUo=r(eXe,"The model is set in evaluation mode by default using "),lbe=n(eXe,"CODE",{});var KGt=s(lbe);jUo=r(KGt,"model.eval()"),KGt.forEach(t),DUo=r(eXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ibe=n(eXe,"CODE",{});var eOt=s(ibe);GUo=r(eOt,"model.train()"),eOt.forEach(t),eXe.forEach(t),OUo=i(ya),T(Kv.$$.fragment,ya),ya.forEach(t),jl.forEach(t),Oto=i(f),qd=n(f,"H2",{class:!0});var sso=s(qd);e1=n(sso,"A",{id:!0,class:!0,href:!0});var oOt=s(e1);dbe=n(oOt,"SPAN",{});var rOt=s(dbe);T(z$.$$.fragment,rOt),rOt.forEach(t),oOt.forEach(t),VUo=i(sso),cbe=n(sso,"SPAN",{});var tOt=s(cbe);XUo=r(tOt,"AutoModelForCausalLM"),tOt.forEach(t),sso.forEach(t),Vto=i(f),qo=n(f,"DIV",{class:!0});var Dl=s(qo);T(Q$.$$.fragment,Dl),zUo=i(Dl),jd=n(Dl,"P",{});var ice=s(jd);QUo=r(ice,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),HW=n(ice,"A",{href:!0});var aOt=s(HW);WUo=r(aOt,"from_pretrained()"),aOt.forEach(t),UUo=r(ice," class method or the "),JW=n(ice,"A",{href:!0});var nOt=s(JW);HUo=r(nOt,"from_config()"),nOt.forEach(t),JUo=r(ice,` class
method.`),ice.forEach(t),YUo=i(Dl),W$=n(Dl,"P",{});var lso=s(W$);ZUo=r(lso,"This class cannot be instantiated directly using "),fbe=n(lso,"CODE",{});var sOt=s(fbe);KUo=r(sOt,"__init__()"),sOt.forEach(t),eHo=r(lso," (throws an error)."),lso.forEach(t),oHo=i(Dl),Ct=n(Dl,"DIV",{class:!0});var a9=s(Ct);T(U$.$$.fragment,a9),rHo=i(a9),mbe=n(a9,"P",{});var lOt=s(mbe);tHo=r(lOt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),lOt.forEach(t),aHo=i(a9),Dd=n(a9,"P",{});var dce=s(Dd);nHo=r(dce,`Note:
Loading a model from its configuration file does `),gbe=n(dce,"STRONG",{});var iOt=s(gbe);sHo=r(iOt,"not"),iOt.forEach(t),lHo=r(dce,` load the model weights. It only affects the
model\u2019s configuration. Use `),YW=n(dce,"A",{href:!0});var dOt=s(YW);iHo=r(dOt,"from_pretrained()"),dOt.forEach(t),dHo=r(dce," to load the model weights."),dce.forEach(t),cHo=i(a9),T(o1.$$.fragment,a9),a9.forEach(t),fHo=i(Dl),oo=n(Dl,"DIV",{class:!0});var xa=s(oo);T(H$.$$.fragment,xa),mHo=i(xa),hbe=n(xa,"P",{});var cOt=s(hbe);gHo=r(cOt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),cOt.forEach(t),hHo=i(xa),ln=n(xa,"P",{});var n9=s(ln);uHo=r(n9,"The model class to instantiate is selected based on the "),ube=n(n9,"CODE",{});var fOt=s(ube);pHo=r(fOt,"model_type"),fOt.forEach(t),_Ho=r(n9,` property of the config object (either
passed as an argument or loaded from `),pbe=n(n9,"CODE",{});var mOt=s(pbe);vHo=r(mOt,"pretrained_model_name_or_path"),mOt.forEach(t),bHo=r(n9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_be=n(n9,"CODE",{});var gOt=s(_be);FHo=r(gOt,"pretrained_model_name_or_path"),gOt.forEach(t),THo=r(n9,":"),n9.forEach(t),MHo=i(xa),W=n(xa,"UL",{});var H=s(W);r1=n(H,"LI",{});var oXe=s(r1);vbe=n(oXe,"STRONG",{});var hOt=s(vbe);EHo=r(hOt,"bart"),hOt.forEach(t),CHo=r(oXe," \u2014 "),ZW=n(oXe,"A",{href:!0});var uOt=s(ZW);wHo=r(uOt,"BartForCausalLM"),uOt.forEach(t),AHo=r(oXe," (BART model)"),oXe.forEach(t),LHo=i(H),t1=n(H,"LI",{});var rXe=s(t1);bbe=n(rXe,"STRONG",{});var pOt=s(bbe);yHo=r(pOt,"bert"),pOt.forEach(t),xHo=r(rXe," \u2014 "),KW=n(rXe,"A",{href:!0});var _Ot=s(KW);$Ho=r(_Ot,"BertLMHeadModel"),_Ot.forEach(t),kHo=r(rXe," (BERT model)"),rXe.forEach(t),SHo=i(H),a1=n(H,"LI",{});var tXe=s(a1);Fbe=n(tXe,"STRONG",{});var vOt=s(Fbe);RHo=r(vOt,"bert-generation"),vOt.forEach(t),PHo=r(tXe," \u2014 "),eU=n(tXe,"A",{href:!0});var bOt=s(eU);BHo=r(bOt,"BertGenerationDecoder"),bOt.forEach(t),IHo=r(tXe," (Bert Generation model)"),tXe.forEach(t),NHo=i(H),n1=n(H,"LI",{});var aXe=s(n1);Tbe=n(aXe,"STRONG",{});var FOt=s(Tbe);qHo=r(FOt,"big_bird"),FOt.forEach(t),jHo=r(aXe," \u2014 "),oU=n(aXe,"A",{href:!0});var TOt=s(oU);DHo=r(TOt,"BigBirdForCausalLM"),TOt.forEach(t),GHo=r(aXe," (BigBird model)"),aXe.forEach(t),OHo=i(H),s1=n(H,"LI",{});var nXe=s(s1);Mbe=n(nXe,"STRONG",{});var MOt=s(Mbe);VHo=r(MOt,"bigbird_pegasus"),MOt.forEach(t),XHo=r(nXe," \u2014 "),rU=n(nXe,"A",{href:!0});var EOt=s(rU);zHo=r(EOt,"BigBirdPegasusForCausalLM"),EOt.forEach(t),QHo=r(nXe," (BigBird-Pegasus model)"),nXe.forEach(t),WHo=i(H),l1=n(H,"LI",{});var sXe=s(l1);Ebe=n(sXe,"STRONG",{});var COt=s(Ebe);UHo=r(COt,"blenderbot"),COt.forEach(t),HHo=r(sXe," \u2014 "),tU=n(sXe,"A",{href:!0});var wOt=s(tU);JHo=r(wOt,"BlenderbotForCausalLM"),wOt.forEach(t),YHo=r(sXe," (Blenderbot model)"),sXe.forEach(t),ZHo=i(H),i1=n(H,"LI",{});var lXe=s(i1);Cbe=n(lXe,"STRONG",{});var AOt=s(Cbe);KHo=r(AOt,"blenderbot-small"),AOt.forEach(t),eJo=r(lXe," \u2014 "),aU=n(lXe,"A",{href:!0});var LOt=s(aU);oJo=r(LOt,"BlenderbotSmallForCausalLM"),LOt.forEach(t),rJo=r(lXe," (BlenderbotSmall model)"),lXe.forEach(t),tJo=i(H),d1=n(H,"LI",{});var iXe=s(d1);wbe=n(iXe,"STRONG",{});var yOt=s(wbe);aJo=r(yOt,"bloom"),yOt.forEach(t),nJo=r(iXe," \u2014 "),nU=n(iXe,"A",{href:!0});var xOt=s(nU);sJo=r(xOt,"BloomForCausalLM"),xOt.forEach(t),lJo=r(iXe," (BLOOM model)"),iXe.forEach(t),iJo=i(H),c1=n(H,"LI",{});var dXe=s(c1);Abe=n(dXe,"STRONG",{});var $Ot=s(Abe);dJo=r($Ot,"camembert"),$Ot.forEach(t),cJo=r(dXe," \u2014 "),sU=n(dXe,"A",{href:!0});var kOt=s(sU);fJo=r(kOt,"CamembertForCausalLM"),kOt.forEach(t),mJo=r(dXe," (CamemBERT model)"),dXe.forEach(t),gJo=i(H),f1=n(H,"LI",{});var cXe=s(f1);Lbe=n(cXe,"STRONG",{});var SOt=s(Lbe);hJo=r(SOt,"codegen"),SOt.forEach(t),uJo=r(cXe," \u2014 "),lU=n(cXe,"A",{href:!0});var ROt=s(lU);pJo=r(ROt,"CodeGenForCausalLM"),ROt.forEach(t),_Jo=r(cXe," (CodeGen model)"),cXe.forEach(t),vJo=i(H),m1=n(H,"LI",{});var fXe=s(m1);ybe=n(fXe,"STRONG",{});var POt=s(ybe);bJo=r(POt,"ctrl"),POt.forEach(t),FJo=r(fXe," \u2014 "),iU=n(fXe,"A",{href:!0});var BOt=s(iU);TJo=r(BOt,"CTRLLMHeadModel"),BOt.forEach(t),MJo=r(fXe," (CTRL model)"),fXe.forEach(t),EJo=i(H),g1=n(H,"LI",{});var mXe=s(g1);xbe=n(mXe,"STRONG",{});var IOt=s(xbe);CJo=r(IOt,"data2vec-text"),IOt.forEach(t),wJo=r(mXe," \u2014 "),dU=n(mXe,"A",{href:!0});var NOt=s(dU);AJo=r(NOt,"Data2VecTextForCausalLM"),NOt.forEach(t),LJo=r(mXe," (Data2VecText model)"),mXe.forEach(t),yJo=i(H),h1=n(H,"LI",{});var gXe=s(h1);$be=n(gXe,"STRONG",{});var qOt=s($be);xJo=r(qOt,"electra"),qOt.forEach(t),$Jo=r(gXe," \u2014 "),cU=n(gXe,"A",{href:!0});var jOt=s(cU);kJo=r(jOt,"ElectraForCausalLM"),jOt.forEach(t),SJo=r(gXe," (ELECTRA model)"),gXe.forEach(t),RJo=i(H),u1=n(H,"LI",{});var hXe=s(u1);kbe=n(hXe,"STRONG",{});var DOt=s(kbe);PJo=r(DOt,"ernie"),DOt.forEach(t),BJo=r(hXe," \u2014 "),fU=n(hXe,"A",{href:!0});var GOt=s(fU);IJo=r(GOt,"ErnieForCausalLM"),GOt.forEach(t),NJo=r(hXe," (ERNIE model)"),hXe.forEach(t),qJo=i(H),p1=n(H,"LI",{});var uXe=s(p1);Sbe=n(uXe,"STRONG",{});var OOt=s(Sbe);jJo=r(OOt,"gpt2"),OOt.forEach(t),DJo=r(uXe," \u2014 "),mU=n(uXe,"A",{href:!0});var VOt=s(mU);GJo=r(VOt,"GPT2LMHeadModel"),VOt.forEach(t),OJo=r(uXe," (OpenAI GPT-2 model)"),uXe.forEach(t),VJo=i(H),_1=n(H,"LI",{});var pXe=s(_1);Rbe=n(pXe,"STRONG",{});var XOt=s(Rbe);XJo=r(XOt,"gpt_neo"),XOt.forEach(t),zJo=r(pXe," \u2014 "),gU=n(pXe,"A",{href:!0});var zOt=s(gU);QJo=r(zOt,"GPTNeoForCausalLM"),zOt.forEach(t),WJo=r(pXe," (GPT Neo model)"),pXe.forEach(t),UJo=i(H),v1=n(H,"LI",{});var _Xe=s(v1);Pbe=n(_Xe,"STRONG",{});var QOt=s(Pbe);HJo=r(QOt,"gpt_neox"),QOt.forEach(t),JJo=r(_Xe," \u2014 "),hU=n(_Xe,"A",{href:!0});var WOt=s(hU);YJo=r(WOt,"GPTNeoXForCausalLM"),WOt.forEach(t),ZJo=r(_Xe," (GPT NeoX model)"),_Xe.forEach(t),KJo=i(H),b1=n(H,"LI",{});var vXe=s(b1);Bbe=n(vXe,"STRONG",{});var UOt=s(Bbe);eYo=r(UOt,"gpt_neox_japanese"),UOt.forEach(t),oYo=r(vXe," \u2014 "),uU=n(vXe,"A",{href:!0});var HOt=s(uU);rYo=r(HOt,"GPTNeoXJapaneseForCausalLM"),HOt.forEach(t),tYo=r(vXe," (GPT NeoX Japanese model)"),vXe.forEach(t),aYo=i(H),F1=n(H,"LI",{});var bXe=s(F1);Ibe=n(bXe,"STRONG",{});var JOt=s(Ibe);nYo=r(JOt,"gptj"),JOt.forEach(t),sYo=r(bXe," \u2014 "),pU=n(bXe,"A",{href:!0});var YOt=s(pU);lYo=r(YOt,"GPTJForCausalLM"),YOt.forEach(t),iYo=r(bXe," (GPT-J model)"),bXe.forEach(t),dYo=i(H),T1=n(H,"LI",{});var FXe=s(T1);Nbe=n(FXe,"STRONG",{});var ZOt=s(Nbe);cYo=r(ZOt,"marian"),ZOt.forEach(t),fYo=r(FXe," \u2014 "),_U=n(FXe,"A",{href:!0});var KOt=s(_U);mYo=r(KOt,"MarianForCausalLM"),KOt.forEach(t),gYo=r(FXe," (Marian model)"),FXe.forEach(t),hYo=i(H),M1=n(H,"LI",{});var TXe=s(M1);qbe=n(TXe,"STRONG",{});var eVt=s(qbe);uYo=r(eVt,"mbart"),eVt.forEach(t),pYo=r(TXe," \u2014 "),vU=n(TXe,"A",{href:!0});var oVt=s(vU);_Yo=r(oVt,"MBartForCausalLM"),oVt.forEach(t),vYo=r(TXe," (mBART model)"),TXe.forEach(t),bYo=i(H),E1=n(H,"LI",{});var MXe=s(E1);jbe=n(MXe,"STRONG",{});var rVt=s(jbe);FYo=r(rVt,"megatron-bert"),rVt.forEach(t),TYo=r(MXe," \u2014 "),bU=n(MXe,"A",{href:!0});var tVt=s(bU);MYo=r(tVt,"MegatronBertForCausalLM"),tVt.forEach(t),EYo=r(MXe," (Megatron-BERT model)"),MXe.forEach(t),CYo=i(H),C1=n(H,"LI",{});var EXe=s(C1);Dbe=n(EXe,"STRONG",{});var aVt=s(Dbe);wYo=r(aVt,"mvp"),aVt.forEach(t),AYo=r(EXe," \u2014 "),FU=n(EXe,"A",{href:!0});var nVt=s(FU);LYo=r(nVt,"MvpForCausalLM"),nVt.forEach(t),yYo=r(EXe," (MVP model)"),EXe.forEach(t),xYo=i(H),w1=n(H,"LI",{});var CXe=s(w1);Gbe=n(CXe,"STRONG",{});var sVt=s(Gbe);$Yo=r(sVt,"openai-gpt"),sVt.forEach(t),kYo=r(CXe," \u2014 "),TU=n(CXe,"A",{href:!0});var lVt=s(TU);SYo=r(lVt,"OpenAIGPTLMHeadModel"),lVt.forEach(t),RYo=r(CXe," (OpenAI GPT model)"),CXe.forEach(t),PYo=i(H),A1=n(H,"LI",{});var wXe=s(A1);Obe=n(wXe,"STRONG",{});var iVt=s(Obe);BYo=r(iVt,"opt"),iVt.forEach(t),IYo=r(wXe," \u2014 "),MU=n(wXe,"A",{href:!0});var dVt=s(MU);NYo=r(dVt,"OPTForCausalLM"),dVt.forEach(t),qYo=r(wXe," (OPT model)"),wXe.forEach(t),jYo=i(H),L1=n(H,"LI",{});var AXe=s(L1);Vbe=n(AXe,"STRONG",{});var cVt=s(Vbe);DYo=r(cVt,"pegasus"),cVt.forEach(t),GYo=r(AXe," \u2014 "),EU=n(AXe,"A",{href:!0});var fVt=s(EU);OYo=r(fVt,"PegasusForCausalLM"),fVt.forEach(t),VYo=r(AXe," (Pegasus model)"),AXe.forEach(t),XYo=i(H),y1=n(H,"LI",{});var LXe=s(y1);Xbe=n(LXe,"STRONG",{});var mVt=s(Xbe);zYo=r(mVt,"plbart"),mVt.forEach(t),QYo=r(LXe," \u2014 "),CU=n(LXe,"A",{href:!0});var gVt=s(CU);WYo=r(gVt,"PLBartForCausalLM"),gVt.forEach(t),UYo=r(LXe," (PLBart model)"),LXe.forEach(t),HYo=i(H),x1=n(H,"LI",{});var yXe=s(x1);zbe=n(yXe,"STRONG",{});var hVt=s(zbe);JYo=r(hVt,"prophetnet"),hVt.forEach(t),YYo=r(yXe," \u2014 "),wU=n(yXe,"A",{href:!0});var uVt=s(wU);ZYo=r(uVt,"ProphetNetForCausalLM"),uVt.forEach(t),KYo=r(yXe," (ProphetNet model)"),yXe.forEach(t),eZo=i(H),$1=n(H,"LI",{});var xXe=s($1);Qbe=n(xXe,"STRONG",{});var pVt=s(Qbe);oZo=r(pVt,"qdqbert"),pVt.forEach(t),rZo=r(xXe," \u2014 "),AU=n(xXe,"A",{href:!0});var _Vt=s(AU);tZo=r(_Vt,"QDQBertLMHeadModel"),_Vt.forEach(t),aZo=r(xXe," (QDQBert model)"),xXe.forEach(t),nZo=i(H),k1=n(H,"LI",{});var $Xe=s(k1);Wbe=n($Xe,"STRONG",{});var vVt=s(Wbe);sZo=r(vVt,"reformer"),vVt.forEach(t),lZo=r($Xe," \u2014 "),LU=n($Xe,"A",{href:!0});var bVt=s(LU);iZo=r(bVt,"ReformerModelWithLMHead"),bVt.forEach(t),dZo=r($Xe," (Reformer model)"),$Xe.forEach(t),cZo=i(H),S1=n(H,"LI",{});var kXe=s(S1);Ube=n(kXe,"STRONG",{});var FVt=s(Ube);fZo=r(FVt,"rembert"),FVt.forEach(t),mZo=r(kXe," \u2014 "),yU=n(kXe,"A",{href:!0});var TVt=s(yU);gZo=r(TVt,"RemBertForCausalLM"),TVt.forEach(t),hZo=r(kXe," (RemBERT model)"),kXe.forEach(t),uZo=i(H),R1=n(H,"LI",{});var SXe=s(R1);Hbe=n(SXe,"STRONG",{});var MVt=s(Hbe);pZo=r(MVt,"roberta"),MVt.forEach(t),_Zo=r(SXe," \u2014 "),xU=n(SXe,"A",{href:!0});var EVt=s(xU);vZo=r(EVt,"RobertaForCausalLM"),EVt.forEach(t),bZo=r(SXe," (RoBERTa model)"),SXe.forEach(t),FZo=i(H),P1=n(H,"LI",{});var RXe=s(P1);Jbe=n(RXe,"STRONG",{});var CVt=s(Jbe);TZo=r(CVt,"roformer"),CVt.forEach(t),MZo=r(RXe," \u2014 "),$U=n(RXe,"A",{href:!0});var wVt=s($U);EZo=r(wVt,"RoFormerForCausalLM"),wVt.forEach(t),CZo=r(RXe," (RoFormer model)"),RXe.forEach(t),wZo=i(H),B1=n(H,"LI",{});var PXe=s(B1);Ybe=n(PXe,"STRONG",{});var AVt=s(Ybe);AZo=r(AVt,"speech_to_text_2"),AVt.forEach(t),LZo=r(PXe," \u2014 "),kU=n(PXe,"A",{href:!0});var LVt=s(kU);yZo=r(LVt,"Speech2Text2ForCausalLM"),LVt.forEach(t),xZo=r(PXe," (Speech2Text2 model)"),PXe.forEach(t),$Zo=i(H),I1=n(H,"LI",{});var BXe=s(I1);Zbe=n(BXe,"STRONG",{});var yVt=s(Zbe);kZo=r(yVt,"transfo-xl"),yVt.forEach(t),SZo=r(BXe," \u2014 "),SU=n(BXe,"A",{href:!0});var xVt=s(SU);RZo=r(xVt,"TransfoXLLMHeadModel"),xVt.forEach(t),PZo=r(BXe," (Transformer-XL model)"),BXe.forEach(t),BZo=i(H),N1=n(H,"LI",{});var IXe=s(N1);Kbe=n(IXe,"STRONG",{});var $Vt=s(Kbe);IZo=r($Vt,"trocr"),$Vt.forEach(t),NZo=r(IXe," \u2014 "),RU=n(IXe,"A",{href:!0});var kVt=s(RU);qZo=r(kVt,"TrOCRForCausalLM"),kVt.forEach(t),jZo=r(IXe," (TrOCR model)"),IXe.forEach(t),DZo=i(H),q1=n(H,"LI",{});var NXe=s(q1);e0e=n(NXe,"STRONG",{});var SVt=s(e0e);GZo=r(SVt,"xglm"),SVt.forEach(t),OZo=r(NXe," \u2014 "),PU=n(NXe,"A",{href:!0});var RVt=s(PU);VZo=r(RVt,"XGLMForCausalLM"),RVt.forEach(t),XZo=r(NXe," (XGLM model)"),NXe.forEach(t),zZo=i(H),j1=n(H,"LI",{});var qXe=s(j1);o0e=n(qXe,"STRONG",{});var PVt=s(o0e);QZo=r(PVt,"xlm"),PVt.forEach(t),WZo=r(qXe," \u2014 "),BU=n(qXe,"A",{href:!0});var BVt=s(BU);UZo=r(BVt,"XLMWithLMHeadModel"),BVt.forEach(t),HZo=r(qXe," (XLM model)"),qXe.forEach(t),JZo=i(H),D1=n(H,"LI",{});var jXe=s(D1);r0e=n(jXe,"STRONG",{});var IVt=s(r0e);YZo=r(IVt,"xlm-prophetnet"),IVt.forEach(t),ZZo=r(jXe," \u2014 "),IU=n(jXe,"A",{href:!0});var NVt=s(IU);KZo=r(NVt,"XLMProphetNetForCausalLM"),NVt.forEach(t),eKo=r(jXe," (XLM-ProphetNet model)"),jXe.forEach(t),oKo=i(H),G1=n(H,"LI",{});var DXe=s(G1);t0e=n(DXe,"STRONG",{});var qVt=s(t0e);rKo=r(qVt,"xlm-roberta"),qVt.forEach(t),tKo=r(DXe," \u2014 "),NU=n(DXe,"A",{href:!0});var jVt=s(NU);aKo=r(jVt,"XLMRobertaForCausalLM"),jVt.forEach(t),nKo=r(DXe," (XLM-RoBERTa model)"),DXe.forEach(t),sKo=i(H),O1=n(H,"LI",{});var GXe=s(O1);a0e=n(GXe,"STRONG",{});var DVt=s(a0e);lKo=r(DVt,"xlm-roberta-xl"),DVt.forEach(t),iKo=r(GXe," \u2014 "),qU=n(GXe,"A",{href:!0});var GVt=s(qU);dKo=r(GVt,"XLMRobertaXLForCausalLM"),GVt.forEach(t),cKo=r(GXe," (XLM-RoBERTa-XL model)"),GXe.forEach(t),fKo=i(H),V1=n(H,"LI",{});var OXe=s(V1);n0e=n(OXe,"STRONG",{});var OVt=s(n0e);mKo=r(OVt,"xlnet"),OVt.forEach(t),gKo=r(OXe," \u2014 "),jU=n(OXe,"A",{href:!0});var VVt=s(jU);hKo=r(VVt,"XLNetLMHeadModel"),VVt.forEach(t),uKo=r(OXe," (XLNet model)"),OXe.forEach(t),H.forEach(t),pKo=i(xa),X1=n(xa,"P",{});var VXe=s(X1);_Ko=r(VXe,"The model is set in evaluation mode by default using "),s0e=n(VXe,"CODE",{});var XVt=s(s0e);vKo=r(XVt,"model.eval()"),XVt.forEach(t),bKo=r(VXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l0e=n(VXe,"CODE",{});var zVt=s(l0e);FKo=r(zVt,"model.train()"),zVt.forEach(t),VXe.forEach(t),TKo=i(xa),T(z1.$$.fragment,xa),xa.forEach(t),Dl.forEach(t),Xto=i(f),Gd=n(f,"H2",{class:!0});var iso=s(Gd);Q1=n(iso,"A",{id:!0,class:!0,href:!0});var QVt=s(Q1);i0e=n(QVt,"SPAN",{});var WVt=s(i0e);T(J$.$$.fragment,WVt),WVt.forEach(t),QVt.forEach(t),MKo=i(iso),d0e=n(iso,"SPAN",{});var UVt=s(d0e);EKo=r(UVt,"AutoModelForDepthEstimation"),UVt.forEach(t),iso.forEach(t),zto=i(f),jo=n(f,"DIV",{class:!0});var Gl=s(jo);T(Y$.$$.fragment,Gl),CKo=i(Gl),Od=n(Gl,"P",{});var cce=s(Od);wKo=r(cce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a depth estimation head) when created
with the `),DU=n(cce,"A",{href:!0});var HVt=s(DU);AKo=r(HVt,"from_pretrained()"),HVt.forEach(t),LKo=r(cce," class method or the "),GU=n(cce,"A",{href:!0});var JVt=s(GU);yKo=r(JVt,"from_config()"),JVt.forEach(t),xKo=r(cce,` class
method.`),cce.forEach(t),$Ko=i(Gl),Z$=n(Gl,"P",{});var dso=s(Z$);kKo=r(dso,"This class cannot be instantiated directly using "),c0e=n(dso,"CODE",{});var YVt=s(c0e);SKo=r(YVt,"__init__()"),YVt.forEach(t),RKo=r(dso," (throws an error)."),dso.forEach(t),PKo=i(Gl),wt=n(Gl,"DIV",{class:!0});var s9=s(wt);T(K$.$$.fragment,s9),BKo=i(s9),f0e=n(s9,"P",{});var ZVt=s(f0e);IKo=r(ZVt,"Instantiates one of the model classes of the library (with a depth estimation head) from a configuration."),ZVt.forEach(t),NKo=i(s9),Vd=n(s9,"P",{});var fce=s(Vd);qKo=r(fce,`Note:
Loading a model from its configuration file does `),m0e=n(fce,"STRONG",{});var KVt=s(m0e);jKo=r(KVt,"not"),KVt.forEach(t),DKo=r(fce,` load the model weights. It only affects the
model\u2019s configuration. Use `),OU=n(fce,"A",{href:!0});var eXt=s(OU);GKo=r(eXt,"from_pretrained()"),eXt.forEach(t),OKo=r(fce," to load the model weights."),fce.forEach(t),VKo=i(s9),T(W1.$$.fragment,s9),s9.forEach(t),XKo=i(Gl),ro=n(Gl,"DIV",{class:!0});var $a=s(ro);T(ek.$$.fragment,$a),zKo=i($a),g0e=n($a,"P",{});var oXt=s(g0e);QKo=r(oXt,"Instantiate one of the model classes of the library (with a depth estimation head) from a pretrained model."),oXt.forEach(t),WKo=i($a),dn=n($a,"P",{});var l9=s(dn);UKo=r(l9,"The model class to instantiate is selected based on the "),h0e=n(l9,"CODE",{});var rXt=s(h0e);HKo=r(rXt,"model_type"),rXt.forEach(t),JKo=r(l9,` property of the config object (either
passed as an argument or loaded from `),u0e=n(l9,"CODE",{});var tXt=s(u0e);YKo=r(tXt,"pretrained_model_name_or_path"),tXt.forEach(t),ZKo=r(l9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p0e=n(l9,"CODE",{});var aXt=s(p0e);KKo=r(aXt,"pretrained_model_name_or_path"),aXt.forEach(t),eer=r(l9,":"),l9.forEach(t),oer=i($a),ok=n($a,"UL",{});var cso=s(ok);U1=n(cso,"LI",{});var XXe=s(U1);_0e=n(XXe,"STRONG",{});var nXt=s(_0e);rer=r(nXt,"dpt"),nXt.forEach(t),ter=r(XXe," \u2014 "),VU=n(XXe,"A",{href:!0});var sXt=s(VU);aer=r(sXt,"DPTForDepthEstimation"),sXt.forEach(t),ner=r(XXe," (DPT model)"),XXe.forEach(t),ser=i(cso),H1=n(cso,"LI",{});var zXe=s(H1);v0e=n(zXe,"STRONG",{});var lXt=s(v0e);ler=r(lXt,"glpn"),lXt.forEach(t),ier=r(zXe," \u2014 "),XU=n(zXe,"A",{href:!0});var iXt=s(XU);der=r(iXt,"GLPNForDepthEstimation"),iXt.forEach(t),cer=r(zXe," (GLPN model)"),zXe.forEach(t),cso.forEach(t),fer=i($a),J1=n($a,"P",{});var QXe=s(J1);mer=r(QXe,"The model is set in evaluation mode by default using "),b0e=n(QXe,"CODE",{});var dXt=s(b0e);ger=r(dXt,"model.eval()"),dXt.forEach(t),her=r(QXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F0e=n(QXe,"CODE",{});var cXt=s(F0e);uer=r(cXt,"model.train()"),cXt.forEach(t),QXe.forEach(t),per=i($a),T(Y1.$$.fragment,$a),$a.forEach(t),Gl.forEach(t),Qto=i(f),Xd=n(f,"H2",{class:!0});var fso=s(Xd);Z1=n(fso,"A",{id:!0,class:!0,href:!0});var fXt=s(Z1);T0e=n(fXt,"SPAN",{});var mXt=s(T0e);T(rk.$$.fragment,mXt),mXt.forEach(t),fXt.forEach(t),_er=i(fso),M0e=n(fso,"SPAN",{});var gXt=s(M0e);ver=r(gXt,"AutoModelForMaskedLM"),gXt.forEach(t),fso.forEach(t),Wto=i(f),Do=n(f,"DIV",{class:!0});var Ol=s(Do);T(tk.$$.fragment,Ol),ber=i(Ol),zd=n(Ol,"P",{});var mce=s(zd);Fer=r(mce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),zU=n(mce,"A",{href:!0});var hXt=s(zU);Ter=r(hXt,"from_pretrained()"),hXt.forEach(t),Mer=r(mce," class method or the "),QU=n(mce,"A",{href:!0});var uXt=s(QU);Eer=r(uXt,"from_config()"),uXt.forEach(t),Cer=r(mce,` class
method.`),mce.forEach(t),wer=i(Ol),ak=n(Ol,"P",{});var mso=s(ak);Aer=r(mso,"This class cannot be instantiated directly using "),E0e=n(mso,"CODE",{});var pXt=s(E0e);Ler=r(pXt,"__init__()"),pXt.forEach(t),yer=r(mso," (throws an error)."),mso.forEach(t),xer=i(Ol),At=n(Ol,"DIV",{class:!0});var i9=s(At);T(nk.$$.fragment,i9),$er=i(i9),C0e=n(i9,"P",{});var _Xt=s(C0e);ker=r(_Xt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),_Xt.forEach(t),Ser=i(i9),Qd=n(i9,"P",{});var gce=s(Qd);Rer=r(gce,`Note:
Loading a model from its configuration file does `),w0e=n(gce,"STRONG",{});var vXt=s(w0e);Per=r(vXt,"not"),vXt.forEach(t),Ber=r(gce,` load the model weights. It only affects the
model\u2019s configuration. Use `),WU=n(gce,"A",{href:!0});var bXt=s(WU);Ier=r(bXt,"from_pretrained()"),bXt.forEach(t),Ner=r(gce," to load the model weights."),gce.forEach(t),qer=i(i9),T(K1.$$.fragment,i9),i9.forEach(t),jer=i(Ol),to=n(Ol,"DIV",{class:!0});var ka=s(to);T(sk.$$.fragment,ka),Der=i(ka),A0e=n(ka,"P",{});var FXt=s(A0e);Ger=r(FXt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),FXt.forEach(t),Oer=i(ka),cn=n(ka,"P",{});var d9=s(cn);Ver=r(d9,"The model class to instantiate is selected based on the "),L0e=n(d9,"CODE",{});var TXt=s(L0e);Xer=r(TXt,"model_type"),TXt.forEach(t),zer=r(d9,` property of the config object (either
passed as an argument or loaded from `),y0e=n(d9,"CODE",{});var MXt=s(y0e);Qer=r(MXt,"pretrained_model_name_or_path"),MXt.forEach(t),Wer=r(d9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x0e=n(d9,"CODE",{});var EXt=s(x0e);Uer=r(EXt,"pretrained_model_name_or_path"),EXt.forEach(t),Her=r(d9,":"),d9.forEach(t),Jer=i(ka),Y=n(ka,"UL",{});var Z=s(Y);eb=n(Z,"LI",{});var WXe=s(eb);$0e=n(WXe,"STRONG",{});var CXt=s($0e);Yer=r(CXt,"albert"),CXt.forEach(t),Zer=r(WXe," \u2014 "),UU=n(WXe,"A",{href:!0});var wXt=s(UU);Ker=r(wXt,"AlbertForMaskedLM"),wXt.forEach(t),eor=r(WXe," (ALBERT model)"),WXe.forEach(t),oor=i(Z),ob=n(Z,"LI",{});var UXe=s(ob);k0e=n(UXe,"STRONG",{});var AXt=s(k0e);ror=r(AXt,"bart"),AXt.forEach(t),tor=r(UXe," \u2014 "),HU=n(UXe,"A",{href:!0});var LXt=s(HU);aor=r(LXt,"BartForConditionalGeneration"),LXt.forEach(t),nor=r(UXe," (BART model)"),UXe.forEach(t),sor=i(Z),rb=n(Z,"LI",{});var HXe=s(rb);S0e=n(HXe,"STRONG",{});var yXt=s(S0e);lor=r(yXt,"bert"),yXt.forEach(t),ior=r(HXe," \u2014 "),JU=n(HXe,"A",{href:!0});var xXt=s(JU);dor=r(xXt,"BertForMaskedLM"),xXt.forEach(t),cor=r(HXe," (BERT model)"),HXe.forEach(t),mor=i(Z),tb=n(Z,"LI",{});var JXe=s(tb);R0e=n(JXe,"STRONG",{});var $Xt=s(R0e);gor=r($Xt,"big_bird"),$Xt.forEach(t),hor=r(JXe," \u2014 "),YU=n(JXe,"A",{href:!0});var kXt=s(YU);uor=r(kXt,"BigBirdForMaskedLM"),kXt.forEach(t),por=r(JXe," (BigBird model)"),JXe.forEach(t),_or=i(Z),ab=n(Z,"LI",{});var YXe=s(ab);P0e=n(YXe,"STRONG",{});var SXt=s(P0e);vor=r(SXt,"camembert"),SXt.forEach(t),bor=r(YXe," \u2014 "),ZU=n(YXe,"A",{href:!0});var RXt=s(ZU);For=r(RXt,"CamembertForMaskedLM"),RXt.forEach(t),Tor=r(YXe," (CamemBERT model)"),YXe.forEach(t),Mor=i(Z),nb=n(Z,"LI",{});var ZXe=s(nb);B0e=n(ZXe,"STRONG",{});var PXt=s(B0e);Eor=r(PXt,"convbert"),PXt.forEach(t),Cor=r(ZXe," \u2014 "),KU=n(ZXe,"A",{href:!0});var BXt=s(KU);wor=r(BXt,"ConvBertForMaskedLM"),BXt.forEach(t),Aor=r(ZXe," (ConvBERT model)"),ZXe.forEach(t),Lor=i(Z),sb=n(Z,"LI",{});var KXe=s(sb);I0e=n(KXe,"STRONG",{});var IXt=s(I0e);yor=r(IXt,"data2vec-text"),IXt.forEach(t),xor=r(KXe," \u2014 "),eH=n(KXe,"A",{href:!0});var NXt=s(eH);$or=r(NXt,"Data2VecTextForMaskedLM"),NXt.forEach(t),kor=r(KXe," (Data2VecText model)"),KXe.forEach(t),Sor=i(Z),lb=n(Z,"LI",{});var eze=s(lb);N0e=n(eze,"STRONG",{});var qXt=s(N0e);Ror=r(qXt,"deberta"),qXt.forEach(t),Por=r(eze," \u2014 "),oH=n(eze,"A",{href:!0});var jXt=s(oH);Bor=r(jXt,"DebertaForMaskedLM"),jXt.forEach(t),Ior=r(eze," (DeBERTa model)"),eze.forEach(t),Nor=i(Z),ib=n(Z,"LI",{});var oze=s(ib);q0e=n(oze,"STRONG",{});var DXt=s(q0e);qor=r(DXt,"deberta-v2"),DXt.forEach(t),jor=r(oze," \u2014 "),rH=n(oze,"A",{href:!0});var GXt=s(rH);Dor=r(GXt,"DebertaV2ForMaskedLM"),GXt.forEach(t),Gor=r(oze," (DeBERTa-v2 model)"),oze.forEach(t),Oor=i(Z),db=n(Z,"LI",{});var rze=s(db);j0e=n(rze,"STRONG",{});var OXt=s(j0e);Vor=r(OXt,"distilbert"),OXt.forEach(t),Xor=r(rze," \u2014 "),tH=n(rze,"A",{href:!0});var VXt=s(tH);zor=r(VXt,"DistilBertForMaskedLM"),VXt.forEach(t),Qor=r(rze," (DistilBERT model)"),rze.forEach(t),Wor=i(Z),cb=n(Z,"LI",{});var tze=s(cb);D0e=n(tze,"STRONG",{});var XXt=s(D0e);Uor=r(XXt,"electra"),XXt.forEach(t),Hor=r(tze," \u2014 "),aH=n(tze,"A",{href:!0});var zXt=s(aH);Jor=r(zXt,"ElectraForMaskedLM"),zXt.forEach(t),Yor=r(tze," (ELECTRA model)"),tze.forEach(t),Zor=i(Z),fb=n(Z,"LI",{});var aze=s(fb);G0e=n(aze,"STRONG",{});var QXt=s(G0e);Kor=r(QXt,"ernie"),QXt.forEach(t),err=r(aze," \u2014 "),nH=n(aze,"A",{href:!0});var WXt=s(nH);orr=r(WXt,"ErnieForMaskedLM"),WXt.forEach(t),rrr=r(aze," (ERNIE model)"),aze.forEach(t),trr=i(Z),mb=n(Z,"LI",{});var nze=s(mb);O0e=n(nze,"STRONG",{});var UXt=s(O0e);arr=r(UXt,"flaubert"),UXt.forEach(t),nrr=r(nze," \u2014 "),sH=n(nze,"A",{href:!0});var HXt=s(sH);srr=r(HXt,"FlaubertWithLMHeadModel"),HXt.forEach(t),lrr=r(nze," (FlauBERT model)"),nze.forEach(t),irr=i(Z),gb=n(Z,"LI",{});var sze=s(gb);V0e=n(sze,"STRONG",{});var JXt=s(V0e);drr=r(JXt,"fnet"),JXt.forEach(t),crr=r(sze," \u2014 "),lH=n(sze,"A",{href:!0});var YXt=s(lH);frr=r(YXt,"FNetForMaskedLM"),YXt.forEach(t),mrr=r(sze," (FNet model)"),sze.forEach(t),grr=i(Z),hb=n(Z,"LI",{});var lze=s(hb);X0e=n(lze,"STRONG",{});var ZXt=s(X0e);hrr=r(ZXt,"funnel"),ZXt.forEach(t),urr=r(lze," \u2014 "),iH=n(lze,"A",{href:!0});var KXt=s(iH);prr=r(KXt,"FunnelForMaskedLM"),KXt.forEach(t),_rr=r(lze," (Funnel Transformer model)"),lze.forEach(t),vrr=i(Z),ub=n(Z,"LI",{});var ize=s(ub);z0e=n(ize,"STRONG",{});var ezt=s(z0e);brr=r(ezt,"ibert"),ezt.forEach(t),Frr=r(ize," \u2014 "),dH=n(ize,"A",{href:!0});var ozt=s(dH);Trr=r(ozt,"IBertForMaskedLM"),ozt.forEach(t),Mrr=r(ize," (I-BERT model)"),ize.forEach(t),Err=i(Z),pb=n(Z,"LI",{});var dze=s(pb);Q0e=n(dze,"STRONG",{});var rzt=s(Q0e);Crr=r(rzt,"layoutlm"),rzt.forEach(t),wrr=r(dze," \u2014 "),cH=n(dze,"A",{href:!0});var tzt=s(cH);Arr=r(tzt,"LayoutLMForMaskedLM"),tzt.forEach(t),Lrr=r(dze," (LayoutLM model)"),dze.forEach(t),yrr=i(Z),_b=n(Z,"LI",{});var cze=s(_b);W0e=n(cze,"STRONG",{});var azt=s(W0e);xrr=r(azt,"longformer"),azt.forEach(t),$rr=r(cze," \u2014 "),fH=n(cze,"A",{href:!0});var nzt=s(fH);krr=r(nzt,"LongformerForMaskedLM"),nzt.forEach(t),Srr=r(cze," (Longformer model)"),cze.forEach(t),Rrr=i(Z),vb=n(Z,"LI",{});var fze=s(vb);U0e=n(fze,"STRONG",{});var szt=s(U0e);Prr=r(szt,"luke"),szt.forEach(t),Brr=r(fze," \u2014 "),mH=n(fze,"A",{href:!0});var lzt=s(mH);Irr=r(lzt,"LukeForMaskedLM"),lzt.forEach(t),Nrr=r(fze," (LUKE model)"),fze.forEach(t),qrr=i(Z),bb=n(Z,"LI",{});var mze=s(bb);H0e=n(mze,"STRONG",{});var izt=s(H0e);jrr=r(izt,"mbart"),izt.forEach(t),Drr=r(mze," \u2014 "),gH=n(mze,"A",{href:!0});var dzt=s(gH);Grr=r(dzt,"MBartForConditionalGeneration"),dzt.forEach(t),Orr=r(mze," (mBART model)"),mze.forEach(t),Vrr=i(Z),Fb=n(Z,"LI",{});var gze=s(Fb);J0e=n(gze,"STRONG",{});var czt=s(J0e);Xrr=r(czt,"megatron-bert"),czt.forEach(t),zrr=r(gze," \u2014 "),hH=n(gze,"A",{href:!0});var fzt=s(hH);Qrr=r(fzt,"MegatronBertForMaskedLM"),fzt.forEach(t),Wrr=r(gze," (Megatron-BERT model)"),gze.forEach(t),Urr=i(Z),Tb=n(Z,"LI",{});var hze=s(Tb);Y0e=n(hze,"STRONG",{});var mzt=s(Y0e);Hrr=r(mzt,"mobilebert"),mzt.forEach(t),Jrr=r(hze," \u2014 "),uH=n(hze,"A",{href:!0});var gzt=s(uH);Yrr=r(gzt,"MobileBertForMaskedLM"),gzt.forEach(t),Zrr=r(hze," (MobileBERT model)"),hze.forEach(t),Krr=i(Z),Mb=n(Z,"LI",{});var uze=s(Mb);Z0e=n(uze,"STRONG",{});var hzt=s(Z0e);etr=r(hzt,"mpnet"),hzt.forEach(t),otr=r(uze," \u2014 "),pH=n(uze,"A",{href:!0});var uzt=s(pH);rtr=r(uzt,"MPNetForMaskedLM"),uzt.forEach(t),ttr=r(uze," (MPNet model)"),uze.forEach(t),atr=i(Z),Eb=n(Z,"LI",{});var pze=s(Eb);K0e=n(pze,"STRONG",{});var pzt=s(K0e);ntr=r(pzt,"mvp"),pzt.forEach(t),str=r(pze," \u2014 "),_H=n(pze,"A",{href:!0});var _zt=s(_H);ltr=r(_zt,"MvpForConditionalGeneration"),_zt.forEach(t),itr=r(pze," (MVP model)"),pze.forEach(t),dtr=i(Z),Cb=n(Z,"LI",{});var _ze=s(Cb);eFe=n(_ze,"STRONG",{});var vzt=s(eFe);ctr=r(vzt,"nezha"),vzt.forEach(t),ftr=r(_ze," \u2014 "),vH=n(_ze,"A",{href:!0});var bzt=s(vH);mtr=r(bzt,"NezhaForMaskedLM"),bzt.forEach(t),gtr=r(_ze," (Nezha model)"),_ze.forEach(t),htr=i(Z),wb=n(Z,"LI",{});var vze=s(wb);oFe=n(vze,"STRONG",{});var Fzt=s(oFe);utr=r(Fzt,"nystromformer"),Fzt.forEach(t),ptr=r(vze," \u2014 "),bH=n(vze,"A",{href:!0});var Tzt=s(bH);_tr=r(Tzt,"NystromformerForMaskedLM"),Tzt.forEach(t),vtr=r(vze," (Nystr\xF6mformer model)"),vze.forEach(t),btr=i(Z),Ab=n(Z,"LI",{});var bze=s(Ab);rFe=n(bze,"STRONG",{});var Mzt=s(rFe);Ftr=r(Mzt,"perceiver"),Mzt.forEach(t),Ttr=r(bze," \u2014 "),FH=n(bze,"A",{href:!0});var Ezt=s(FH);Mtr=r(Ezt,"PerceiverForMaskedLM"),Ezt.forEach(t),Etr=r(bze," (Perceiver model)"),bze.forEach(t),Ctr=i(Z),Lb=n(Z,"LI",{});var Fze=s(Lb);tFe=n(Fze,"STRONG",{});var Czt=s(tFe);wtr=r(Czt,"qdqbert"),Czt.forEach(t),Atr=r(Fze," \u2014 "),TH=n(Fze,"A",{href:!0});var wzt=s(TH);Ltr=r(wzt,"QDQBertForMaskedLM"),wzt.forEach(t),ytr=r(Fze," (QDQBert model)"),Fze.forEach(t),xtr=i(Z),yb=n(Z,"LI",{});var Tze=s(yb);aFe=n(Tze,"STRONG",{});var Azt=s(aFe);$tr=r(Azt,"reformer"),Azt.forEach(t),ktr=r(Tze," \u2014 "),MH=n(Tze,"A",{href:!0});var Lzt=s(MH);Str=r(Lzt,"ReformerForMaskedLM"),Lzt.forEach(t),Rtr=r(Tze," (Reformer model)"),Tze.forEach(t),Ptr=i(Z),xb=n(Z,"LI",{});var Mze=s(xb);nFe=n(Mze,"STRONG",{});var yzt=s(nFe);Btr=r(yzt,"rembert"),yzt.forEach(t),Itr=r(Mze," \u2014 "),EH=n(Mze,"A",{href:!0});var xzt=s(EH);Ntr=r(xzt,"RemBertForMaskedLM"),xzt.forEach(t),qtr=r(Mze," (RemBERT model)"),Mze.forEach(t),jtr=i(Z),$b=n(Z,"LI",{});var Eze=s($b);sFe=n(Eze,"STRONG",{});var $zt=s(sFe);Dtr=r($zt,"roberta"),$zt.forEach(t),Gtr=r(Eze," \u2014 "),CH=n(Eze,"A",{href:!0});var kzt=s(CH);Otr=r(kzt,"RobertaForMaskedLM"),kzt.forEach(t),Vtr=r(Eze," (RoBERTa model)"),Eze.forEach(t),Xtr=i(Z),kb=n(Z,"LI",{});var Cze=s(kb);lFe=n(Cze,"STRONG",{});var Szt=s(lFe);ztr=r(Szt,"roformer"),Szt.forEach(t),Qtr=r(Cze," \u2014 "),wH=n(Cze,"A",{href:!0});var Rzt=s(wH);Wtr=r(Rzt,"RoFormerForMaskedLM"),Rzt.forEach(t),Utr=r(Cze," (RoFormer model)"),Cze.forEach(t),Htr=i(Z),Sb=n(Z,"LI",{});var wze=s(Sb);iFe=n(wze,"STRONG",{});var Pzt=s(iFe);Jtr=r(Pzt,"squeezebert"),Pzt.forEach(t),Ytr=r(wze," \u2014 "),AH=n(wze,"A",{href:!0});var Bzt=s(AH);Ztr=r(Bzt,"SqueezeBertForMaskedLM"),Bzt.forEach(t),Ktr=r(wze," (SqueezeBERT model)"),wze.forEach(t),ear=i(Z),Rb=n(Z,"LI",{});var Aze=s(Rb);dFe=n(Aze,"STRONG",{});var Izt=s(dFe);oar=r(Izt,"tapas"),Izt.forEach(t),rar=r(Aze," \u2014 "),LH=n(Aze,"A",{href:!0});var Nzt=s(LH);tar=r(Nzt,"TapasForMaskedLM"),Nzt.forEach(t),aar=r(Aze," (TAPAS model)"),Aze.forEach(t),nar=i(Z),Pb=n(Z,"LI",{});var Lze=s(Pb);cFe=n(Lze,"STRONG",{});var qzt=s(cFe);sar=r(qzt,"wav2vec2"),qzt.forEach(t),lar=r(Lze," \u2014 "),fFe=n(Lze,"CODE",{});var jzt=s(fFe);iar=r(jzt,"Wav2Vec2ForMaskedLM"),jzt.forEach(t),dar=r(Lze," (Wav2Vec2 model)"),Lze.forEach(t),car=i(Z),Bb=n(Z,"LI",{});var yze=s(Bb);mFe=n(yze,"STRONG",{});var Dzt=s(mFe);far=r(Dzt,"xlm"),Dzt.forEach(t),mar=r(yze," \u2014 "),yH=n(yze,"A",{href:!0});var Gzt=s(yH);gar=r(Gzt,"XLMWithLMHeadModel"),Gzt.forEach(t),har=r(yze," (XLM model)"),yze.forEach(t),uar=i(Z),Ib=n(Z,"LI",{});var xze=s(Ib);gFe=n(xze,"STRONG",{});var Ozt=s(gFe);par=r(Ozt,"xlm-roberta"),Ozt.forEach(t),_ar=r(xze," \u2014 "),xH=n(xze,"A",{href:!0});var Vzt=s(xH);bar=r(Vzt,"XLMRobertaForMaskedLM"),Vzt.forEach(t),Far=r(xze," (XLM-RoBERTa model)"),xze.forEach(t),Tar=i(Z),Nb=n(Z,"LI",{});var $ze=s(Nb);hFe=n($ze,"STRONG",{});var Xzt=s(hFe);Mar=r(Xzt,"xlm-roberta-xl"),Xzt.forEach(t),Ear=r($ze," \u2014 "),$H=n($ze,"A",{href:!0});var zzt=s($H);Car=r(zzt,"XLMRobertaXLForMaskedLM"),zzt.forEach(t),war=r($ze," (XLM-RoBERTa-XL model)"),$ze.forEach(t),Aar=i(Z),qb=n(Z,"LI",{});var kze=s(qb);uFe=n(kze,"STRONG",{});var Qzt=s(uFe);Lar=r(Qzt,"yoso"),Qzt.forEach(t),yar=r(kze," \u2014 "),kH=n(kze,"A",{href:!0});var Wzt=s(kH);xar=r(Wzt,"YosoForMaskedLM"),Wzt.forEach(t),$ar=r(kze," (YOSO model)"),kze.forEach(t),Z.forEach(t),kar=i(ka),jb=n(ka,"P",{});var Sze=s(jb);Sar=r(Sze,"The model is set in evaluation mode by default using "),pFe=n(Sze,"CODE",{});var Uzt=s(pFe);Rar=r(Uzt,"model.eval()"),Uzt.forEach(t),Par=r(Sze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_Fe=n(Sze,"CODE",{});var Hzt=s(_Fe);Bar=r(Hzt,"model.train()"),Hzt.forEach(t),Sze.forEach(t),Iar=i(ka),T(Db.$$.fragment,ka),ka.forEach(t),Ol.forEach(t),Uto=i(f),Wd=n(f,"H2",{class:!0});var gso=s(Wd);Gb=n(gso,"A",{id:!0,class:!0,href:!0});var Jzt=s(Gb);vFe=n(Jzt,"SPAN",{});var Yzt=s(vFe);T(lk.$$.fragment,Yzt),Yzt.forEach(t),Jzt.forEach(t),Nar=i(gso),bFe=n(gso,"SPAN",{});var Zzt=s(bFe);qar=r(Zzt,"AutoModelForSeq2SeqLM"),Zzt.forEach(t),gso.forEach(t),Hto=i(f),Go=n(f,"DIV",{class:!0});var Vl=s(Go);T(ik.$$.fragment,Vl),jar=i(Vl),Ud=n(Vl,"P",{});var hce=s(Ud);Dar=r(hce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),SH=n(hce,"A",{href:!0});var Kzt=s(SH);Gar=r(Kzt,"from_pretrained()"),Kzt.forEach(t),Oar=r(hce," class method or the "),RH=n(hce,"A",{href:!0});var eQt=s(RH);Var=r(eQt,"from_config()"),eQt.forEach(t),Xar=r(hce,` class
method.`),hce.forEach(t),zar=i(Vl),dk=n(Vl,"P",{});var hso=s(dk);Qar=r(hso,"This class cannot be instantiated directly using "),FFe=n(hso,"CODE",{});var oQt=s(FFe);War=r(oQt,"__init__()"),oQt.forEach(t),Uar=r(hso," (throws an error)."),hso.forEach(t),Har=i(Vl),Lt=n(Vl,"DIV",{class:!0});var c9=s(Lt);T(ck.$$.fragment,c9),Jar=i(c9),TFe=n(c9,"P",{});var rQt=s(TFe);Yar=r(rQt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),rQt.forEach(t),Zar=i(c9),Hd=n(c9,"P",{});var uce=s(Hd);Kar=r(uce,`Note:
Loading a model from its configuration file does `),MFe=n(uce,"STRONG",{});var tQt=s(MFe);enr=r(tQt,"not"),tQt.forEach(t),onr=r(uce,` load the model weights. It only affects the
model\u2019s configuration. Use `),PH=n(uce,"A",{href:!0});var aQt=s(PH);rnr=r(aQt,"from_pretrained()"),aQt.forEach(t),tnr=r(uce," to load the model weights."),uce.forEach(t),anr=i(c9),T(Ob.$$.fragment,c9),c9.forEach(t),nnr=i(Vl),ao=n(Vl,"DIV",{class:!0});var Sa=s(ao);T(fk.$$.fragment,Sa),snr=i(Sa),EFe=n(Sa,"P",{});var nQt=s(EFe);lnr=r(nQt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),nQt.forEach(t),inr=i(Sa),fn=n(Sa,"P",{});var f9=s(fn);dnr=r(f9,"The model class to instantiate is selected based on the "),CFe=n(f9,"CODE",{});var sQt=s(CFe);cnr=r(sQt,"model_type"),sQt.forEach(t),fnr=r(f9,` property of the config object (either
passed as an argument or loaded from `),wFe=n(f9,"CODE",{});var lQt=s(wFe);mnr=r(lQt,"pretrained_model_name_or_path"),lQt.forEach(t),gnr=r(f9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),AFe=n(f9,"CODE",{});var iQt=s(AFe);hnr=r(iQt,"pretrained_model_name_or_path"),iQt.forEach(t),unr=r(f9,":"),f9.forEach(t),pnr=i(Sa),he=n(Sa,"UL",{});var _e=s(he);Vb=n(_e,"LI",{});var Rze=s(Vb);LFe=n(Rze,"STRONG",{});var dQt=s(LFe);_nr=r(dQt,"bart"),dQt.forEach(t),vnr=r(Rze," \u2014 "),BH=n(Rze,"A",{href:!0});var cQt=s(BH);bnr=r(cQt,"BartForConditionalGeneration"),cQt.forEach(t),Fnr=r(Rze," (BART model)"),Rze.forEach(t),Tnr=i(_e),Xb=n(_e,"LI",{});var Pze=s(Xb);yFe=n(Pze,"STRONG",{});var fQt=s(yFe);Mnr=r(fQt,"bigbird_pegasus"),fQt.forEach(t),Enr=r(Pze," \u2014 "),IH=n(Pze,"A",{href:!0});var mQt=s(IH);Cnr=r(mQt,"BigBirdPegasusForConditionalGeneration"),mQt.forEach(t),wnr=r(Pze," (BigBird-Pegasus model)"),Pze.forEach(t),Anr=i(_e),zb=n(_e,"LI",{});var Bze=s(zb);xFe=n(Bze,"STRONG",{});var gQt=s(xFe);Lnr=r(gQt,"blenderbot"),gQt.forEach(t),ynr=r(Bze," \u2014 "),NH=n(Bze,"A",{href:!0});var hQt=s(NH);xnr=r(hQt,"BlenderbotForConditionalGeneration"),hQt.forEach(t),$nr=r(Bze," (Blenderbot model)"),Bze.forEach(t),knr=i(_e),Qb=n(_e,"LI",{});var Ize=s(Qb);$Fe=n(Ize,"STRONG",{});var uQt=s($Fe);Snr=r(uQt,"blenderbot-small"),uQt.forEach(t),Rnr=r(Ize," \u2014 "),qH=n(Ize,"A",{href:!0});var pQt=s(qH);Pnr=r(pQt,"BlenderbotSmallForConditionalGeneration"),pQt.forEach(t),Bnr=r(Ize," (BlenderbotSmall model)"),Ize.forEach(t),Inr=i(_e),Wb=n(_e,"LI",{});var Nze=s(Wb);kFe=n(Nze,"STRONG",{});var _Qt=s(kFe);Nnr=r(_Qt,"encoder-decoder"),_Qt.forEach(t),qnr=r(Nze," \u2014 "),jH=n(Nze,"A",{href:!0});var vQt=s(jH);jnr=r(vQt,"EncoderDecoderModel"),vQt.forEach(t),Dnr=r(Nze," (Encoder decoder model)"),Nze.forEach(t),Gnr=i(_e),Ub=n(_e,"LI",{});var qze=s(Ub);SFe=n(qze,"STRONG",{});var bQt=s(SFe);Onr=r(bQt,"fsmt"),bQt.forEach(t),Vnr=r(qze," \u2014 "),DH=n(qze,"A",{href:!0});var FQt=s(DH);Xnr=r(FQt,"FSMTForConditionalGeneration"),FQt.forEach(t),znr=r(qze," (FairSeq Machine-Translation model)"),qze.forEach(t),Qnr=i(_e),Hb=n(_e,"LI",{});var jze=s(Hb);RFe=n(jze,"STRONG",{});var TQt=s(RFe);Wnr=r(TQt,"led"),TQt.forEach(t),Unr=r(jze," \u2014 "),GH=n(jze,"A",{href:!0});var MQt=s(GH);Hnr=r(MQt,"LEDForConditionalGeneration"),MQt.forEach(t),Jnr=r(jze," (LED model)"),jze.forEach(t),Ynr=i(_e),Jb=n(_e,"LI",{});var Dze=s(Jb);PFe=n(Dze,"STRONG",{});var EQt=s(PFe);Znr=r(EQt,"longt5"),EQt.forEach(t),Knr=r(Dze," \u2014 "),OH=n(Dze,"A",{href:!0});var CQt=s(OH);esr=r(CQt,"LongT5ForConditionalGeneration"),CQt.forEach(t),osr=r(Dze," (LongT5 model)"),Dze.forEach(t),rsr=i(_e),Yb=n(_e,"LI",{});var Gze=s(Yb);BFe=n(Gze,"STRONG",{});var wQt=s(BFe);tsr=r(wQt,"m2m_100"),wQt.forEach(t),asr=r(Gze," \u2014 "),VH=n(Gze,"A",{href:!0});var AQt=s(VH);nsr=r(AQt,"M2M100ForConditionalGeneration"),AQt.forEach(t),ssr=r(Gze," (M2M100 model)"),Gze.forEach(t),lsr=i(_e),Zb=n(_e,"LI",{});var Oze=s(Zb);IFe=n(Oze,"STRONG",{});var LQt=s(IFe);isr=r(LQt,"marian"),LQt.forEach(t),dsr=r(Oze," \u2014 "),XH=n(Oze,"A",{href:!0});var yQt=s(XH);csr=r(yQt,"MarianMTModel"),yQt.forEach(t),fsr=r(Oze," (Marian model)"),Oze.forEach(t),msr=i(_e),Kb=n(_e,"LI",{});var Vze=s(Kb);NFe=n(Vze,"STRONG",{});var xQt=s(NFe);gsr=r(xQt,"mbart"),xQt.forEach(t),hsr=r(Vze," \u2014 "),zH=n(Vze,"A",{href:!0});var $Qt=s(zH);usr=r($Qt,"MBartForConditionalGeneration"),$Qt.forEach(t),psr=r(Vze," (mBART model)"),Vze.forEach(t),_sr=i(_e),e0=n(_e,"LI",{});var Xze=s(e0);qFe=n(Xze,"STRONG",{});var kQt=s(qFe);vsr=r(kQt,"mt5"),kQt.forEach(t),bsr=r(Xze," \u2014 "),QH=n(Xze,"A",{href:!0});var SQt=s(QH);Fsr=r(SQt,"MT5ForConditionalGeneration"),SQt.forEach(t),Tsr=r(Xze," (MT5 model)"),Xze.forEach(t),Msr=i(_e),o0=n(_e,"LI",{});var zze=s(o0);jFe=n(zze,"STRONG",{});var RQt=s(jFe);Esr=r(RQt,"mvp"),RQt.forEach(t),Csr=r(zze," \u2014 "),WH=n(zze,"A",{href:!0});var PQt=s(WH);wsr=r(PQt,"MvpForConditionalGeneration"),PQt.forEach(t),Asr=r(zze," (MVP model)"),zze.forEach(t),Lsr=i(_e),r0=n(_e,"LI",{});var Qze=s(r0);DFe=n(Qze,"STRONG",{});var BQt=s(DFe);ysr=r(BQt,"nllb"),BQt.forEach(t),xsr=r(Qze," \u2014 "),UH=n(Qze,"A",{href:!0});var IQt=s(UH);$sr=r(IQt,"M2M100ForConditionalGeneration"),IQt.forEach(t),ksr=r(Qze," (NLLB model)"),Qze.forEach(t),Ssr=i(_e),t0=n(_e,"LI",{});var Wze=s(t0);GFe=n(Wze,"STRONG",{});var NQt=s(GFe);Rsr=r(NQt,"pegasus"),NQt.forEach(t),Psr=r(Wze," \u2014 "),HH=n(Wze,"A",{href:!0});var qQt=s(HH);Bsr=r(qQt,"PegasusForConditionalGeneration"),qQt.forEach(t),Isr=r(Wze," (Pegasus model)"),Wze.forEach(t),Nsr=i(_e),a0=n(_e,"LI",{});var Uze=s(a0);OFe=n(Uze,"STRONG",{});var jQt=s(OFe);qsr=r(jQt,"pegasus_x"),jQt.forEach(t),jsr=r(Uze," \u2014 "),JH=n(Uze,"A",{href:!0});var DQt=s(JH);Dsr=r(DQt,"PegasusXForConditionalGeneration"),DQt.forEach(t),Gsr=r(Uze," (PEGASUS-X model)"),Uze.forEach(t),Osr=i(_e),n0=n(_e,"LI",{});var Hze=s(n0);VFe=n(Hze,"STRONG",{});var GQt=s(VFe);Vsr=r(GQt,"plbart"),GQt.forEach(t),Xsr=r(Hze," \u2014 "),YH=n(Hze,"A",{href:!0});var OQt=s(YH);zsr=r(OQt,"PLBartForConditionalGeneration"),OQt.forEach(t),Qsr=r(Hze," (PLBart model)"),Hze.forEach(t),Wsr=i(_e),s0=n(_e,"LI",{});var Jze=s(s0);XFe=n(Jze,"STRONG",{});var VQt=s(XFe);Usr=r(VQt,"prophetnet"),VQt.forEach(t),Hsr=r(Jze," \u2014 "),ZH=n(Jze,"A",{href:!0});var XQt=s(ZH);Jsr=r(XQt,"ProphetNetForConditionalGeneration"),XQt.forEach(t),Ysr=r(Jze," (ProphetNet model)"),Jze.forEach(t),Zsr=i(_e),l0=n(_e,"LI",{});var Yze=s(l0);zFe=n(Yze,"STRONG",{});var zQt=s(zFe);Ksr=r(zQt,"t5"),zQt.forEach(t),elr=r(Yze," \u2014 "),KH=n(Yze,"A",{href:!0});var QQt=s(KH);olr=r(QQt,"T5ForConditionalGeneration"),QQt.forEach(t),rlr=r(Yze," (T5 model)"),Yze.forEach(t),tlr=i(_e),i0=n(_e,"LI",{});var Zze=s(i0);QFe=n(Zze,"STRONG",{});var WQt=s(QFe);alr=r(WQt,"xlm-prophetnet"),WQt.forEach(t),nlr=r(Zze," \u2014 "),eJ=n(Zze,"A",{href:!0});var UQt=s(eJ);slr=r(UQt,"XLMProphetNetForConditionalGeneration"),UQt.forEach(t),llr=r(Zze," (XLM-ProphetNet model)"),Zze.forEach(t),_e.forEach(t),ilr=i(Sa),d0=n(Sa,"P",{});var Kze=s(d0);dlr=r(Kze,"The model is set in evaluation mode by default using "),WFe=n(Kze,"CODE",{});var HQt=s(WFe);clr=r(HQt,"model.eval()"),HQt.forEach(t),flr=r(Kze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),UFe=n(Kze,"CODE",{});var JQt=s(UFe);mlr=r(JQt,"model.train()"),JQt.forEach(t),Kze.forEach(t),glr=i(Sa),T(c0.$$.fragment,Sa),Sa.forEach(t),Vl.forEach(t),Jto=i(f),Jd=n(f,"H2",{class:!0});var uso=s(Jd);f0=n(uso,"A",{id:!0,class:!0,href:!0});var YQt=s(f0);HFe=n(YQt,"SPAN",{});var ZQt=s(HFe);T(mk.$$.fragment,ZQt),ZQt.forEach(t),YQt.forEach(t),hlr=i(uso),JFe=n(uso,"SPAN",{});var KQt=s(JFe);ulr=r(KQt,"AutoModelForSequenceClassification"),KQt.forEach(t),uso.forEach(t),Yto=i(f),Oo=n(f,"DIV",{class:!0});var Xl=s(Oo);T(gk.$$.fragment,Xl),plr=i(Xl),Yd=n(Xl,"P",{});var pce=s(Yd);_lr=r(pce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),oJ=n(pce,"A",{href:!0});var eWt=s(oJ);vlr=r(eWt,"from_pretrained()"),eWt.forEach(t),blr=r(pce," class method or the "),rJ=n(pce,"A",{href:!0});var oWt=s(rJ);Flr=r(oWt,"from_config()"),oWt.forEach(t),Tlr=r(pce,` class
method.`),pce.forEach(t),Mlr=i(Xl),hk=n(Xl,"P",{});var pso=s(hk);Elr=r(pso,"This class cannot be instantiated directly using "),YFe=n(pso,"CODE",{});var rWt=s(YFe);Clr=r(rWt,"__init__()"),rWt.forEach(t),wlr=r(pso," (throws an error)."),pso.forEach(t),Alr=i(Xl),yt=n(Xl,"DIV",{class:!0});var m9=s(yt);T(uk.$$.fragment,m9),Llr=i(m9),ZFe=n(m9,"P",{});var tWt=s(ZFe);ylr=r(tWt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),tWt.forEach(t),xlr=i(m9),Zd=n(m9,"P",{});var _ce=s(Zd);$lr=r(_ce,`Note:
Loading a model from its configuration file does `),KFe=n(_ce,"STRONG",{});var aWt=s(KFe);klr=r(aWt,"not"),aWt.forEach(t),Slr=r(_ce,` load the model weights. It only affects the
model\u2019s configuration. Use `),tJ=n(_ce,"A",{href:!0});var nWt=s(tJ);Rlr=r(nWt,"from_pretrained()"),nWt.forEach(t),Plr=r(_ce," to load the model weights."),_ce.forEach(t),Blr=i(m9),T(m0.$$.fragment,m9),m9.forEach(t),Ilr=i(Xl),no=n(Xl,"DIV",{class:!0});var Ra=s(no);T(pk.$$.fragment,Ra),Nlr=i(Ra),eTe=n(Ra,"P",{});var sWt=s(eTe);qlr=r(sWt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),sWt.forEach(t),jlr=i(Ra),mn=n(Ra,"P",{});var g9=s(mn);Dlr=r(g9,"The model class to instantiate is selected based on the "),oTe=n(g9,"CODE",{});var lWt=s(oTe);Glr=r(lWt,"model_type"),lWt.forEach(t),Olr=r(g9,` property of the config object (either
passed as an argument or loaded from `),rTe=n(g9,"CODE",{});var iWt=s(rTe);Vlr=r(iWt,"pretrained_model_name_or_path"),iWt.forEach(t),Xlr=r(g9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tTe=n(g9,"CODE",{});var dWt=s(tTe);zlr=r(dWt,"pretrained_model_name_or_path"),dWt.forEach(t),Qlr=r(g9,":"),g9.forEach(t),Wlr=i(Ra),j=n(Ra,"UL",{});var D=s(j);g0=n(D,"LI",{});var eQe=s(g0);aTe=n(eQe,"STRONG",{});var cWt=s(aTe);Ulr=r(cWt,"albert"),cWt.forEach(t),Hlr=r(eQe," \u2014 "),aJ=n(eQe,"A",{href:!0});var fWt=s(aJ);Jlr=r(fWt,"AlbertForSequenceClassification"),fWt.forEach(t),Ylr=r(eQe," (ALBERT model)"),eQe.forEach(t),Zlr=i(D),h0=n(D,"LI",{});var oQe=s(h0);nTe=n(oQe,"STRONG",{});var mWt=s(nTe);Klr=r(mWt,"bart"),mWt.forEach(t),eir=r(oQe," \u2014 "),nJ=n(oQe,"A",{href:!0});var gWt=s(nJ);oir=r(gWt,"BartForSequenceClassification"),gWt.forEach(t),rir=r(oQe," (BART model)"),oQe.forEach(t),tir=i(D),u0=n(D,"LI",{});var rQe=s(u0);sTe=n(rQe,"STRONG",{});var hWt=s(sTe);air=r(hWt,"bert"),hWt.forEach(t),nir=r(rQe," \u2014 "),sJ=n(rQe,"A",{href:!0});var uWt=s(sJ);sir=r(uWt,"BertForSequenceClassification"),uWt.forEach(t),lir=r(rQe," (BERT model)"),rQe.forEach(t),iir=i(D),p0=n(D,"LI",{});var tQe=s(p0);lTe=n(tQe,"STRONG",{});var pWt=s(lTe);dir=r(pWt,"big_bird"),pWt.forEach(t),cir=r(tQe," \u2014 "),lJ=n(tQe,"A",{href:!0});var _Wt=s(lJ);fir=r(_Wt,"BigBirdForSequenceClassification"),_Wt.forEach(t),mir=r(tQe," (BigBird model)"),tQe.forEach(t),gir=i(D),_0=n(D,"LI",{});var aQe=s(_0);iTe=n(aQe,"STRONG",{});var vWt=s(iTe);hir=r(vWt,"bigbird_pegasus"),vWt.forEach(t),uir=r(aQe," \u2014 "),iJ=n(aQe,"A",{href:!0});var bWt=s(iJ);pir=r(bWt,"BigBirdPegasusForSequenceClassification"),bWt.forEach(t),_ir=r(aQe," (BigBird-Pegasus model)"),aQe.forEach(t),vir=i(D),v0=n(D,"LI",{});var nQe=s(v0);dTe=n(nQe,"STRONG",{});var FWt=s(dTe);bir=r(FWt,"bloom"),FWt.forEach(t),Fir=r(nQe," \u2014 "),dJ=n(nQe,"A",{href:!0});var TWt=s(dJ);Tir=r(TWt,"BloomForSequenceClassification"),TWt.forEach(t),Mir=r(nQe," (BLOOM model)"),nQe.forEach(t),Eir=i(D),b0=n(D,"LI",{});var sQe=s(b0);cTe=n(sQe,"STRONG",{});var MWt=s(cTe);Cir=r(MWt,"camembert"),MWt.forEach(t),wir=r(sQe," \u2014 "),cJ=n(sQe,"A",{href:!0});var EWt=s(cJ);Air=r(EWt,"CamembertForSequenceClassification"),EWt.forEach(t),Lir=r(sQe," (CamemBERT model)"),sQe.forEach(t),yir=i(D),F0=n(D,"LI",{});var lQe=s(F0);fTe=n(lQe,"STRONG",{});var CWt=s(fTe);xir=r(CWt,"canine"),CWt.forEach(t),$ir=r(lQe," \u2014 "),fJ=n(lQe,"A",{href:!0});var wWt=s(fJ);kir=r(wWt,"CanineForSequenceClassification"),wWt.forEach(t),Sir=r(lQe," (CANINE model)"),lQe.forEach(t),Rir=i(D),T0=n(D,"LI",{});var iQe=s(T0);mTe=n(iQe,"STRONG",{});var AWt=s(mTe);Pir=r(AWt,"convbert"),AWt.forEach(t),Bir=r(iQe," \u2014 "),mJ=n(iQe,"A",{href:!0});var LWt=s(mJ);Iir=r(LWt,"ConvBertForSequenceClassification"),LWt.forEach(t),Nir=r(iQe," (ConvBERT model)"),iQe.forEach(t),qir=i(D),M0=n(D,"LI",{});var dQe=s(M0);gTe=n(dQe,"STRONG",{});var yWt=s(gTe);jir=r(yWt,"ctrl"),yWt.forEach(t),Dir=r(dQe," \u2014 "),gJ=n(dQe,"A",{href:!0});var xWt=s(gJ);Gir=r(xWt,"CTRLForSequenceClassification"),xWt.forEach(t),Oir=r(dQe," (CTRL model)"),dQe.forEach(t),Vir=i(D),E0=n(D,"LI",{});var cQe=s(E0);hTe=n(cQe,"STRONG",{});var $Wt=s(hTe);Xir=r($Wt,"data2vec-text"),$Wt.forEach(t),zir=r(cQe," \u2014 "),hJ=n(cQe,"A",{href:!0});var kWt=s(hJ);Qir=r(kWt,"Data2VecTextForSequenceClassification"),kWt.forEach(t),Wir=r(cQe," (Data2VecText model)"),cQe.forEach(t),Uir=i(D),C0=n(D,"LI",{});var fQe=s(C0);uTe=n(fQe,"STRONG",{});var SWt=s(uTe);Hir=r(SWt,"deberta"),SWt.forEach(t),Jir=r(fQe," \u2014 "),uJ=n(fQe,"A",{href:!0});var RWt=s(uJ);Yir=r(RWt,"DebertaForSequenceClassification"),RWt.forEach(t),Zir=r(fQe," (DeBERTa model)"),fQe.forEach(t),Kir=i(D),w0=n(D,"LI",{});var mQe=s(w0);pTe=n(mQe,"STRONG",{});var PWt=s(pTe);edr=r(PWt,"deberta-v2"),PWt.forEach(t),odr=r(mQe," \u2014 "),pJ=n(mQe,"A",{href:!0});var BWt=s(pJ);rdr=r(BWt,"DebertaV2ForSequenceClassification"),BWt.forEach(t),tdr=r(mQe," (DeBERTa-v2 model)"),mQe.forEach(t),adr=i(D),A0=n(D,"LI",{});var gQe=s(A0);_Te=n(gQe,"STRONG",{});var IWt=s(_Te);ndr=r(IWt,"distilbert"),IWt.forEach(t),sdr=r(gQe," \u2014 "),_J=n(gQe,"A",{href:!0});var NWt=s(_J);ldr=r(NWt,"DistilBertForSequenceClassification"),NWt.forEach(t),idr=r(gQe," (DistilBERT model)"),gQe.forEach(t),ddr=i(D),L0=n(D,"LI",{});var hQe=s(L0);vTe=n(hQe,"STRONG",{});var qWt=s(vTe);cdr=r(qWt,"electra"),qWt.forEach(t),fdr=r(hQe," \u2014 "),vJ=n(hQe,"A",{href:!0});var jWt=s(vJ);mdr=r(jWt,"ElectraForSequenceClassification"),jWt.forEach(t),gdr=r(hQe," (ELECTRA model)"),hQe.forEach(t),hdr=i(D),y0=n(D,"LI",{});var uQe=s(y0);bTe=n(uQe,"STRONG",{});var DWt=s(bTe);udr=r(DWt,"ernie"),DWt.forEach(t),pdr=r(uQe," \u2014 "),bJ=n(uQe,"A",{href:!0});var GWt=s(bJ);_dr=r(GWt,"ErnieForSequenceClassification"),GWt.forEach(t),vdr=r(uQe," (ERNIE model)"),uQe.forEach(t),bdr=i(D),x0=n(D,"LI",{});var pQe=s(x0);FTe=n(pQe,"STRONG",{});var OWt=s(FTe);Fdr=r(OWt,"esm"),OWt.forEach(t),Tdr=r(pQe," \u2014 "),FJ=n(pQe,"A",{href:!0});var VWt=s(FJ);Mdr=r(VWt,"EsmForSequenceClassification"),VWt.forEach(t),Edr=r(pQe," (ESM model)"),pQe.forEach(t),Cdr=i(D),$0=n(D,"LI",{});var _Qe=s($0);TTe=n(_Qe,"STRONG",{});var XWt=s(TTe);wdr=r(XWt,"flaubert"),XWt.forEach(t),Adr=r(_Qe," \u2014 "),TJ=n(_Qe,"A",{href:!0});var zWt=s(TJ);Ldr=r(zWt,"FlaubertForSequenceClassification"),zWt.forEach(t),ydr=r(_Qe," (FlauBERT model)"),_Qe.forEach(t),xdr=i(D),k0=n(D,"LI",{});var vQe=s(k0);MTe=n(vQe,"STRONG",{});var QWt=s(MTe);$dr=r(QWt,"fnet"),QWt.forEach(t),kdr=r(vQe," \u2014 "),MJ=n(vQe,"A",{href:!0});var WWt=s(MJ);Sdr=r(WWt,"FNetForSequenceClassification"),WWt.forEach(t),Rdr=r(vQe," (FNet model)"),vQe.forEach(t),Pdr=i(D),S0=n(D,"LI",{});var bQe=s(S0);ETe=n(bQe,"STRONG",{});var UWt=s(ETe);Bdr=r(UWt,"funnel"),UWt.forEach(t),Idr=r(bQe," \u2014 "),EJ=n(bQe,"A",{href:!0});var HWt=s(EJ);Ndr=r(HWt,"FunnelForSequenceClassification"),HWt.forEach(t),qdr=r(bQe," (Funnel Transformer model)"),bQe.forEach(t),jdr=i(D),R0=n(D,"LI",{});var FQe=s(R0);CTe=n(FQe,"STRONG",{});var JWt=s(CTe);Ddr=r(JWt,"gpt2"),JWt.forEach(t),Gdr=r(FQe," \u2014 "),CJ=n(FQe,"A",{href:!0});var YWt=s(CJ);Odr=r(YWt,"GPT2ForSequenceClassification"),YWt.forEach(t),Vdr=r(FQe," (OpenAI GPT-2 model)"),FQe.forEach(t),Xdr=i(D),P0=n(D,"LI",{});var TQe=s(P0);wTe=n(TQe,"STRONG",{});var ZWt=s(wTe);zdr=r(ZWt,"gpt_neo"),ZWt.forEach(t),Qdr=r(TQe," \u2014 "),wJ=n(TQe,"A",{href:!0});var KWt=s(wJ);Wdr=r(KWt,"GPTNeoForSequenceClassification"),KWt.forEach(t),Udr=r(TQe," (GPT Neo model)"),TQe.forEach(t),Hdr=i(D),B0=n(D,"LI",{});var MQe=s(B0);ATe=n(MQe,"STRONG",{});var eUt=s(ATe);Jdr=r(eUt,"gptj"),eUt.forEach(t),Ydr=r(MQe," \u2014 "),AJ=n(MQe,"A",{href:!0});var oUt=s(AJ);Zdr=r(oUt,"GPTJForSequenceClassification"),oUt.forEach(t),Kdr=r(MQe," (GPT-J model)"),MQe.forEach(t),ecr=i(D),I0=n(D,"LI",{});var EQe=s(I0);LTe=n(EQe,"STRONG",{});var rUt=s(LTe);ocr=r(rUt,"ibert"),rUt.forEach(t),rcr=r(EQe," \u2014 "),LJ=n(EQe,"A",{href:!0});var tUt=s(LJ);tcr=r(tUt,"IBertForSequenceClassification"),tUt.forEach(t),acr=r(EQe," (I-BERT model)"),EQe.forEach(t),ncr=i(D),N0=n(D,"LI",{});var CQe=s(N0);yTe=n(CQe,"STRONG",{});var aUt=s(yTe);scr=r(aUt,"layoutlm"),aUt.forEach(t),lcr=r(CQe," \u2014 "),yJ=n(CQe,"A",{href:!0});var nUt=s(yJ);icr=r(nUt,"LayoutLMForSequenceClassification"),nUt.forEach(t),dcr=r(CQe," (LayoutLM model)"),CQe.forEach(t),ccr=i(D),q0=n(D,"LI",{});var wQe=s(q0);xTe=n(wQe,"STRONG",{});var sUt=s(xTe);fcr=r(sUt,"layoutlmv2"),sUt.forEach(t),mcr=r(wQe," \u2014 "),xJ=n(wQe,"A",{href:!0});var lUt=s(xJ);gcr=r(lUt,"LayoutLMv2ForSequenceClassification"),lUt.forEach(t),hcr=r(wQe," (LayoutLMv2 model)"),wQe.forEach(t),ucr=i(D),j0=n(D,"LI",{});var AQe=s(j0);$Te=n(AQe,"STRONG",{});var iUt=s($Te);pcr=r(iUt,"layoutlmv3"),iUt.forEach(t),_cr=r(AQe," \u2014 "),$J=n(AQe,"A",{href:!0});var dUt=s($J);vcr=r(dUt,"LayoutLMv3ForSequenceClassification"),dUt.forEach(t),bcr=r(AQe," (LayoutLMv3 model)"),AQe.forEach(t),Fcr=i(D),D0=n(D,"LI",{});var LQe=s(D0);kTe=n(LQe,"STRONG",{});var cUt=s(kTe);Tcr=r(cUt,"led"),cUt.forEach(t),Mcr=r(LQe," \u2014 "),kJ=n(LQe,"A",{href:!0});var fUt=s(kJ);Ecr=r(fUt,"LEDForSequenceClassification"),fUt.forEach(t),Ccr=r(LQe," (LED model)"),LQe.forEach(t),wcr=i(D),G0=n(D,"LI",{});var yQe=s(G0);STe=n(yQe,"STRONG",{});var mUt=s(STe);Acr=r(mUt,"lilt"),mUt.forEach(t),Lcr=r(yQe," \u2014 "),SJ=n(yQe,"A",{href:!0});var gUt=s(SJ);ycr=r(gUt,"LiltForSequenceClassification"),gUt.forEach(t),xcr=r(yQe," (LiLT model)"),yQe.forEach(t),$cr=i(D),O0=n(D,"LI",{});var xQe=s(O0);RTe=n(xQe,"STRONG",{});var hUt=s(RTe);kcr=r(hUt,"longformer"),hUt.forEach(t),Scr=r(xQe," \u2014 "),RJ=n(xQe,"A",{href:!0});var uUt=s(RJ);Rcr=r(uUt,"LongformerForSequenceClassification"),uUt.forEach(t),Pcr=r(xQe," (Longformer model)"),xQe.forEach(t),Bcr=i(D),V0=n(D,"LI",{});var $Qe=s(V0);PTe=n($Qe,"STRONG",{});var pUt=s(PTe);Icr=r(pUt,"luke"),pUt.forEach(t),Ncr=r($Qe," \u2014 "),PJ=n($Qe,"A",{href:!0});var _Ut=s(PJ);qcr=r(_Ut,"LukeForSequenceClassification"),_Ut.forEach(t),jcr=r($Qe," (LUKE model)"),$Qe.forEach(t),Dcr=i(D),X0=n(D,"LI",{});var kQe=s(X0);BTe=n(kQe,"STRONG",{});var vUt=s(BTe);Gcr=r(vUt,"markuplm"),vUt.forEach(t),Ocr=r(kQe," \u2014 "),BJ=n(kQe,"A",{href:!0});var bUt=s(BJ);Vcr=r(bUt,"MarkupLMForSequenceClassification"),bUt.forEach(t),Xcr=r(kQe," (MarkupLM model)"),kQe.forEach(t),zcr=i(D),z0=n(D,"LI",{});var SQe=s(z0);ITe=n(SQe,"STRONG",{});var FUt=s(ITe);Qcr=r(FUt,"mbart"),FUt.forEach(t),Wcr=r(SQe," \u2014 "),IJ=n(SQe,"A",{href:!0});var TUt=s(IJ);Ucr=r(TUt,"MBartForSequenceClassification"),TUt.forEach(t),Hcr=r(SQe," (mBART model)"),SQe.forEach(t),Jcr=i(D),Q0=n(D,"LI",{});var RQe=s(Q0);NTe=n(RQe,"STRONG",{});var MUt=s(NTe);Ycr=r(MUt,"megatron-bert"),MUt.forEach(t),Zcr=r(RQe," \u2014 "),NJ=n(RQe,"A",{href:!0});var EUt=s(NJ);Kcr=r(EUt,"MegatronBertForSequenceClassification"),EUt.forEach(t),efr=r(RQe," (Megatron-BERT model)"),RQe.forEach(t),ofr=i(D),W0=n(D,"LI",{});var PQe=s(W0);qTe=n(PQe,"STRONG",{});var CUt=s(qTe);rfr=r(CUt,"mobilebert"),CUt.forEach(t),tfr=r(PQe," \u2014 "),qJ=n(PQe,"A",{href:!0});var wUt=s(qJ);afr=r(wUt,"MobileBertForSequenceClassification"),wUt.forEach(t),nfr=r(PQe," (MobileBERT model)"),PQe.forEach(t),sfr=i(D),U0=n(D,"LI",{});var BQe=s(U0);jTe=n(BQe,"STRONG",{});var AUt=s(jTe);lfr=r(AUt,"mpnet"),AUt.forEach(t),ifr=r(BQe," \u2014 "),jJ=n(BQe,"A",{href:!0});var LUt=s(jJ);dfr=r(LUt,"MPNetForSequenceClassification"),LUt.forEach(t),cfr=r(BQe," (MPNet model)"),BQe.forEach(t),ffr=i(D),H0=n(D,"LI",{});var IQe=s(H0);DTe=n(IQe,"STRONG",{});var yUt=s(DTe);mfr=r(yUt,"mvp"),yUt.forEach(t),gfr=r(IQe," \u2014 "),DJ=n(IQe,"A",{href:!0});var xUt=s(DJ);hfr=r(xUt,"MvpForSequenceClassification"),xUt.forEach(t),ufr=r(IQe," (MVP model)"),IQe.forEach(t),pfr=i(D),J0=n(D,"LI",{});var NQe=s(J0);GTe=n(NQe,"STRONG",{});var $Ut=s(GTe);_fr=r($Ut,"nezha"),$Ut.forEach(t),vfr=r(NQe," \u2014 "),GJ=n(NQe,"A",{href:!0});var kUt=s(GJ);bfr=r(kUt,"NezhaForSequenceClassification"),kUt.forEach(t),Ffr=r(NQe," (Nezha model)"),NQe.forEach(t),Tfr=i(D),Y0=n(D,"LI",{});var qQe=s(Y0);OTe=n(qQe,"STRONG",{});var SUt=s(OTe);Mfr=r(SUt,"nystromformer"),SUt.forEach(t),Efr=r(qQe," \u2014 "),OJ=n(qQe,"A",{href:!0});var RUt=s(OJ);Cfr=r(RUt,"NystromformerForSequenceClassification"),RUt.forEach(t),wfr=r(qQe," (Nystr\xF6mformer model)"),qQe.forEach(t),Afr=i(D),Z0=n(D,"LI",{});var jQe=s(Z0);VTe=n(jQe,"STRONG",{});var PUt=s(VTe);Lfr=r(PUt,"openai-gpt"),PUt.forEach(t),yfr=r(jQe," \u2014 "),VJ=n(jQe,"A",{href:!0});var BUt=s(VJ);xfr=r(BUt,"OpenAIGPTForSequenceClassification"),BUt.forEach(t),$fr=r(jQe," (OpenAI GPT model)"),jQe.forEach(t),kfr=i(D),K0=n(D,"LI",{});var DQe=s(K0);XTe=n(DQe,"STRONG",{});var IUt=s(XTe);Sfr=r(IUt,"opt"),IUt.forEach(t),Rfr=r(DQe," \u2014 "),XJ=n(DQe,"A",{href:!0});var NUt=s(XJ);Pfr=r(NUt,"OPTForSequenceClassification"),NUt.forEach(t),Bfr=r(DQe," (OPT model)"),DQe.forEach(t),Ifr=i(D),eF=n(D,"LI",{});var GQe=s(eF);zTe=n(GQe,"STRONG",{});var qUt=s(zTe);Nfr=r(qUt,"perceiver"),qUt.forEach(t),qfr=r(GQe," \u2014 "),zJ=n(GQe,"A",{href:!0});var jUt=s(zJ);jfr=r(jUt,"PerceiverForSequenceClassification"),jUt.forEach(t),Dfr=r(GQe," (Perceiver model)"),GQe.forEach(t),Gfr=i(D),oF=n(D,"LI",{});var OQe=s(oF);QTe=n(OQe,"STRONG",{});var DUt=s(QTe);Ofr=r(DUt,"plbart"),DUt.forEach(t),Vfr=r(OQe," \u2014 "),QJ=n(OQe,"A",{href:!0});var GUt=s(QJ);Xfr=r(GUt,"PLBartForSequenceClassification"),GUt.forEach(t),zfr=r(OQe," (PLBart model)"),OQe.forEach(t),Qfr=i(D),rF=n(D,"LI",{});var VQe=s(rF);WTe=n(VQe,"STRONG",{});var OUt=s(WTe);Wfr=r(OUt,"qdqbert"),OUt.forEach(t),Ufr=r(VQe," \u2014 "),WJ=n(VQe,"A",{href:!0});var VUt=s(WJ);Hfr=r(VUt,"QDQBertForSequenceClassification"),VUt.forEach(t),Jfr=r(VQe," (QDQBert model)"),VQe.forEach(t),Yfr=i(D),tF=n(D,"LI",{});var XQe=s(tF);UTe=n(XQe,"STRONG",{});var XUt=s(UTe);Zfr=r(XUt,"reformer"),XUt.forEach(t),Kfr=r(XQe," \u2014 "),UJ=n(XQe,"A",{href:!0});var zUt=s(UJ);emr=r(zUt,"ReformerForSequenceClassification"),zUt.forEach(t),omr=r(XQe," (Reformer model)"),XQe.forEach(t),rmr=i(D),aF=n(D,"LI",{});var zQe=s(aF);HTe=n(zQe,"STRONG",{});var QUt=s(HTe);tmr=r(QUt,"rembert"),QUt.forEach(t),amr=r(zQe," \u2014 "),HJ=n(zQe,"A",{href:!0});var WUt=s(HJ);nmr=r(WUt,"RemBertForSequenceClassification"),WUt.forEach(t),smr=r(zQe," (RemBERT model)"),zQe.forEach(t),lmr=i(D),nF=n(D,"LI",{});var QQe=s(nF);JTe=n(QQe,"STRONG",{});var UUt=s(JTe);imr=r(UUt,"roberta"),UUt.forEach(t),dmr=r(QQe," \u2014 "),JJ=n(QQe,"A",{href:!0});var HUt=s(JJ);cmr=r(HUt,"RobertaForSequenceClassification"),HUt.forEach(t),fmr=r(QQe," (RoBERTa model)"),QQe.forEach(t),mmr=i(D),sF=n(D,"LI",{});var WQe=s(sF);YTe=n(WQe,"STRONG",{});var JUt=s(YTe);gmr=r(JUt,"roformer"),JUt.forEach(t),hmr=r(WQe," \u2014 "),YJ=n(WQe,"A",{href:!0});var YUt=s(YJ);umr=r(YUt,"RoFormerForSequenceClassification"),YUt.forEach(t),pmr=r(WQe," (RoFormer model)"),WQe.forEach(t),_mr=i(D),lF=n(D,"LI",{});var UQe=s(lF);ZTe=n(UQe,"STRONG",{});var ZUt=s(ZTe);vmr=r(ZUt,"squeezebert"),ZUt.forEach(t),bmr=r(UQe," \u2014 "),ZJ=n(UQe,"A",{href:!0});var KUt=s(ZJ);Fmr=r(KUt,"SqueezeBertForSequenceClassification"),KUt.forEach(t),Tmr=r(UQe," (SqueezeBERT model)"),UQe.forEach(t),Mmr=i(D),iF=n(D,"LI",{});var HQe=s(iF);KTe=n(HQe,"STRONG",{});var eHt=s(KTe);Emr=r(eHt,"tapas"),eHt.forEach(t),Cmr=r(HQe," \u2014 "),KJ=n(HQe,"A",{href:!0});var oHt=s(KJ);wmr=r(oHt,"TapasForSequenceClassification"),oHt.forEach(t),Amr=r(HQe," (TAPAS model)"),HQe.forEach(t),Lmr=i(D),dF=n(D,"LI",{});var JQe=s(dF);eMe=n(JQe,"STRONG",{});var rHt=s(eMe);ymr=r(rHt,"transfo-xl"),rHt.forEach(t),xmr=r(JQe," \u2014 "),eY=n(JQe,"A",{href:!0});var tHt=s(eY);$mr=r(tHt,"TransfoXLForSequenceClassification"),tHt.forEach(t),kmr=r(JQe," (Transformer-XL model)"),JQe.forEach(t),Smr=i(D),cF=n(D,"LI",{});var YQe=s(cF);oMe=n(YQe,"STRONG",{});var aHt=s(oMe);Rmr=r(aHt,"xlm"),aHt.forEach(t),Pmr=r(YQe," \u2014 "),oY=n(YQe,"A",{href:!0});var nHt=s(oY);Bmr=r(nHt,"XLMForSequenceClassification"),nHt.forEach(t),Imr=r(YQe," (XLM model)"),YQe.forEach(t),Nmr=i(D),fF=n(D,"LI",{});var ZQe=s(fF);rMe=n(ZQe,"STRONG",{});var sHt=s(rMe);qmr=r(sHt,"xlm-roberta"),sHt.forEach(t),jmr=r(ZQe," \u2014 "),rY=n(ZQe,"A",{href:!0});var lHt=s(rY);Dmr=r(lHt,"XLMRobertaForSequenceClassification"),lHt.forEach(t),Gmr=r(ZQe," (XLM-RoBERTa model)"),ZQe.forEach(t),Omr=i(D),mF=n(D,"LI",{});var KQe=s(mF);tMe=n(KQe,"STRONG",{});var iHt=s(tMe);Vmr=r(iHt,"xlm-roberta-xl"),iHt.forEach(t),Xmr=r(KQe," \u2014 "),tY=n(KQe,"A",{href:!0});var dHt=s(tY);zmr=r(dHt,"XLMRobertaXLForSequenceClassification"),dHt.forEach(t),Qmr=r(KQe," (XLM-RoBERTa-XL model)"),KQe.forEach(t),Wmr=i(D),gF=n(D,"LI",{});var eWe=s(gF);aMe=n(eWe,"STRONG",{});var cHt=s(aMe);Umr=r(cHt,"xlnet"),cHt.forEach(t),Hmr=r(eWe," \u2014 "),aY=n(eWe,"A",{href:!0});var fHt=s(aY);Jmr=r(fHt,"XLNetForSequenceClassification"),fHt.forEach(t),Ymr=r(eWe," (XLNet model)"),eWe.forEach(t),Zmr=i(D),hF=n(D,"LI",{});var oWe=s(hF);nMe=n(oWe,"STRONG",{});var mHt=s(nMe);Kmr=r(mHt,"yoso"),mHt.forEach(t),egr=r(oWe," \u2014 "),nY=n(oWe,"A",{href:!0});var gHt=s(nY);ogr=r(gHt,"YosoForSequenceClassification"),gHt.forEach(t),rgr=r(oWe," (YOSO model)"),oWe.forEach(t),D.forEach(t),tgr=i(Ra),uF=n(Ra,"P",{});var rWe=s(uF);agr=r(rWe,"The model is set in evaluation mode by default using "),sMe=n(rWe,"CODE",{});var hHt=s(sMe);ngr=r(hHt,"model.eval()"),hHt.forEach(t),sgr=r(rWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lMe=n(rWe,"CODE",{});var uHt=s(lMe);lgr=r(uHt,"model.train()"),uHt.forEach(t),rWe.forEach(t),igr=i(Ra),T(pF.$$.fragment,Ra),Ra.forEach(t),Xl.forEach(t),Zto=i(f),Kd=n(f,"H2",{class:!0});var _so=s(Kd);_F=n(_so,"A",{id:!0,class:!0,href:!0});var pHt=s(_F);iMe=n(pHt,"SPAN",{});var _Ht=s(iMe);T(_k.$$.fragment,_Ht),_Ht.forEach(t),pHt.forEach(t),dgr=i(_so),dMe=n(_so,"SPAN",{});var vHt=s(dMe);cgr=r(vHt,"AutoModelForMultipleChoice"),vHt.forEach(t),_so.forEach(t),Kto=i(f),Vo=n(f,"DIV",{class:!0});var zl=s(Vo);T(vk.$$.fragment,zl),fgr=i(zl),ec=n(zl,"P",{});var vce=s(ec);mgr=r(vce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),sY=n(vce,"A",{href:!0});var bHt=s(sY);ggr=r(bHt,"from_pretrained()"),bHt.forEach(t),hgr=r(vce," class method or the "),lY=n(vce,"A",{href:!0});var FHt=s(lY);ugr=r(FHt,"from_config()"),FHt.forEach(t),pgr=r(vce,` class
method.`),vce.forEach(t),_gr=i(zl),bk=n(zl,"P",{});var vso=s(bk);vgr=r(vso,"This class cannot be instantiated directly using "),cMe=n(vso,"CODE",{});var THt=s(cMe);bgr=r(THt,"__init__()"),THt.forEach(t),Fgr=r(vso," (throws an error)."),vso.forEach(t),Tgr=i(zl),xt=n(zl,"DIV",{class:!0});var h9=s(xt);T(Fk.$$.fragment,h9),Mgr=i(h9),fMe=n(h9,"P",{});var MHt=s(fMe);Egr=r(MHt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),MHt.forEach(t),Cgr=i(h9),oc=n(h9,"P",{});var bce=s(oc);wgr=r(bce,`Note:
Loading a model from its configuration file does `),mMe=n(bce,"STRONG",{});var EHt=s(mMe);Agr=r(EHt,"not"),EHt.forEach(t),Lgr=r(bce,` load the model weights. It only affects the
model\u2019s configuration. Use `),iY=n(bce,"A",{href:!0});var CHt=s(iY);ygr=r(CHt,"from_pretrained()"),CHt.forEach(t),xgr=r(bce," to load the model weights."),bce.forEach(t),$gr=i(h9),T(vF.$$.fragment,h9),h9.forEach(t),kgr=i(zl),so=n(zl,"DIV",{class:!0});var Pa=s(so);T(Tk.$$.fragment,Pa),Sgr=i(Pa),gMe=n(Pa,"P",{});var wHt=s(gMe);Rgr=r(wHt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),wHt.forEach(t),Pgr=i(Pa),gn=n(Pa,"P",{});var u9=s(gn);Bgr=r(u9,"The model class to instantiate is selected based on the "),hMe=n(u9,"CODE",{});var AHt=s(hMe);Igr=r(AHt,"model_type"),AHt.forEach(t),Ngr=r(u9,` property of the config object (either
passed as an argument or loaded from `),uMe=n(u9,"CODE",{});var LHt=s(uMe);qgr=r(LHt,"pretrained_model_name_or_path"),LHt.forEach(t),jgr=r(u9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pMe=n(u9,"CODE",{});var yHt=s(pMe);Dgr=r(yHt,"pretrained_model_name_or_path"),yHt.forEach(t),Ggr=r(u9,":"),u9.forEach(t),Ogr=i(Pa),K=n(Pa,"UL",{});var ee=s(K);bF=n(ee,"LI",{});var tWe=s(bF);_Me=n(tWe,"STRONG",{});var xHt=s(_Me);Vgr=r(xHt,"albert"),xHt.forEach(t),Xgr=r(tWe," \u2014 "),dY=n(tWe,"A",{href:!0});var $Ht=s(dY);zgr=r($Ht,"AlbertForMultipleChoice"),$Ht.forEach(t),Qgr=r(tWe," (ALBERT model)"),tWe.forEach(t),Wgr=i(ee),FF=n(ee,"LI",{});var aWe=s(FF);vMe=n(aWe,"STRONG",{});var kHt=s(vMe);Ugr=r(kHt,"bert"),kHt.forEach(t),Hgr=r(aWe," \u2014 "),cY=n(aWe,"A",{href:!0});var SHt=s(cY);Jgr=r(SHt,"BertForMultipleChoice"),SHt.forEach(t),Ygr=r(aWe," (BERT model)"),aWe.forEach(t),Zgr=i(ee),TF=n(ee,"LI",{});var nWe=s(TF);bMe=n(nWe,"STRONG",{});var RHt=s(bMe);Kgr=r(RHt,"big_bird"),RHt.forEach(t),ehr=r(nWe," \u2014 "),fY=n(nWe,"A",{href:!0});var PHt=s(fY);ohr=r(PHt,"BigBirdForMultipleChoice"),PHt.forEach(t),rhr=r(nWe," (BigBird model)"),nWe.forEach(t),thr=i(ee),MF=n(ee,"LI",{});var sWe=s(MF);FMe=n(sWe,"STRONG",{});var BHt=s(FMe);ahr=r(BHt,"camembert"),BHt.forEach(t),nhr=r(sWe," \u2014 "),mY=n(sWe,"A",{href:!0});var IHt=s(mY);shr=r(IHt,"CamembertForMultipleChoice"),IHt.forEach(t),lhr=r(sWe," (CamemBERT model)"),sWe.forEach(t),ihr=i(ee),EF=n(ee,"LI",{});var lWe=s(EF);TMe=n(lWe,"STRONG",{});var NHt=s(TMe);dhr=r(NHt,"canine"),NHt.forEach(t),chr=r(lWe," \u2014 "),gY=n(lWe,"A",{href:!0});var qHt=s(gY);fhr=r(qHt,"CanineForMultipleChoice"),qHt.forEach(t),mhr=r(lWe," (CANINE model)"),lWe.forEach(t),ghr=i(ee),CF=n(ee,"LI",{});var iWe=s(CF);MMe=n(iWe,"STRONG",{});var jHt=s(MMe);hhr=r(jHt,"convbert"),jHt.forEach(t),uhr=r(iWe," \u2014 "),hY=n(iWe,"A",{href:!0});var DHt=s(hY);phr=r(DHt,"ConvBertForMultipleChoice"),DHt.forEach(t),_hr=r(iWe," (ConvBERT model)"),iWe.forEach(t),vhr=i(ee),wF=n(ee,"LI",{});var dWe=s(wF);EMe=n(dWe,"STRONG",{});var GHt=s(EMe);bhr=r(GHt,"data2vec-text"),GHt.forEach(t),Fhr=r(dWe," \u2014 "),uY=n(dWe,"A",{href:!0});var OHt=s(uY);Thr=r(OHt,"Data2VecTextForMultipleChoice"),OHt.forEach(t),Mhr=r(dWe," (Data2VecText model)"),dWe.forEach(t),Ehr=i(ee),AF=n(ee,"LI",{});var cWe=s(AF);CMe=n(cWe,"STRONG",{});var VHt=s(CMe);Chr=r(VHt,"deberta-v2"),VHt.forEach(t),whr=r(cWe," \u2014 "),pY=n(cWe,"A",{href:!0});var XHt=s(pY);Ahr=r(XHt,"DebertaV2ForMultipleChoice"),XHt.forEach(t),Lhr=r(cWe," (DeBERTa-v2 model)"),cWe.forEach(t),yhr=i(ee),LF=n(ee,"LI",{});var fWe=s(LF);wMe=n(fWe,"STRONG",{});var zHt=s(wMe);xhr=r(zHt,"distilbert"),zHt.forEach(t),$hr=r(fWe," \u2014 "),_Y=n(fWe,"A",{href:!0});var QHt=s(_Y);khr=r(QHt,"DistilBertForMultipleChoice"),QHt.forEach(t),Shr=r(fWe," (DistilBERT model)"),fWe.forEach(t),Rhr=i(ee),yF=n(ee,"LI",{});var mWe=s(yF);AMe=n(mWe,"STRONG",{});var WHt=s(AMe);Phr=r(WHt,"electra"),WHt.forEach(t),Bhr=r(mWe," \u2014 "),vY=n(mWe,"A",{href:!0});var UHt=s(vY);Ihr=r(UHt,"ElectraForMultipleChoice"),UHt.forEach(t),Nhr=r(mWe," (ELECTRA model)"),mWe.forEach(t),qhr=i(ee),xF=n(ee,"LI",{});var gWe=s(xF);LMe=n(gWe,"STRONG",{});var HHt=s(LMe);jhr=r(HHt,"ernie"),HHt.forEach(t),Dhr=r(gWe," \u2014 "),bY=n(gWe,"A",{href:!0});var JHt=s(bY);Ghr=r(JHt,"ErnieForMultipleChoice"),JHt.forEach(t),Ohr=r(gWe," (ERNIE model)"),gWe.forEach(t),Vhr=i(ee),$F=n(ee,"LI",{});var hWe=s($F);yMe=n(hWe,"STRONG",{});var YHt=s(yMe);Xhr=r(YHt,"flaubert"),YHt.forEach(t),zhr=r(hWe," \u2014 "),FY=n(hWe,"A",{href:!0});var ZHt=s(FY);Qhr=r(ZHt,"FlaubertForMultipleChoice"),ZHt.forEach(t),Whr=r(hWe," (FlauBERT model)"),hWe.forEach(t),Uhr=i(ee),kF=n(ee,"LI",{});var uWe=s(kF);xMe=n(uWe,"STRONG",{});var KHt=s(xMe);Hhr=r(KHt,"fnet"),KHt.forEach(t),Jhr=r(uWe," \u2014 "),TY=n(uWe,"A",{href:!0});var eJt=s(TY);Yhr=r(eJt,"FNetForMultipleChoice"),eJt.forEach(t),Zhr=r(uWe," (FNet model)"),uWe.forEach(t),Khr=i(ee),SF=n(ee,"LI",{});var pWe=s(SF);$Me=n(pWe,"STRONG",{});var oJt=s($Me);eur=r(oJt,"funnel"),oJt.forEach(t),our=r(pWe," \u2014 "),MY=n(pWe,"A",{href:!0});var rJt=s(MY);rur=r(rJt,"FunnelForMultipleChoice"),rJt.forEach(t),tur=r(pWe," (Funnel Transformer model)"),pWe.forEach(t),aur=i(ee),RF=n(ee,"LI",{});var _We=s(RF);kMe=n(_We,"STRONG",{});var tJt=s(kMe);nur=r(tJt,"ibert"),tJt.forEach(t),sur=r(_We," \u2014 "),EY=n(_We,"A",{href:!0});var aJt=s(EY);lur=r(aJt,"IBertForMultipleChoice"),aJt.forEach(t),iur=r(_We," (I-BERT model)"),_We.forEach(t),dur=i(ee),PF=n(ee,"LI",{});var vWe=s(PF);SMe=n(vWe,"STRONG",{});var nJt=s(SMe);cur=r(nJt,"longformer"),nJt.forEach(t),fur=r(vWe," \u2014 "),CY=n(vWe,"A",{href:!0});var sJt=s(CY);mur=r(sJt,"LongformerForMultipleChoice"),sJt.forEach(t),gur=r(vWe," (Longformer model)"),vWe.forEach(t),hur=i(ee),BF=n(ee,"LI",{});var bWe=s(BF);RMe=n(bWe,"STRONG",{});var lJt=s(RMe);uur=r(lJt,"luke"),lJt.forEach(t),pur=r(bWe," \u2014 "),wY=n(bWe,"A",{href:!0});var iJt=s(wY);_ur=r(iJt,"LukeForMultipleChoice"),iJt.forEach(t),vur=r(bWe," (LUKE model)"),bWe.forEach(t),bur=i(ee),IF=n(ee,"LI",{});var FWe=s(IF);PMe=n(FWe,"STRONG",{});var dJt=s(PMe);Fur=r(dJt,"megatron-bert"),dJt.forEach(t),Tur=r(FWe," \u2014 "),AY=n(FWe,"A",{href:!0});var cJt=s(AY);Mur=r(cJt,"MegatronBertForMultipleChoice"),cJt.forEach(t),Eur=r(FWe," (Megatron-BERT model)"),FWe.forEach(t),Cur=i(ee),NF=n(ee,"LI",{});var TWe=s(NF);BMe=n(TWe,"STRONG",{});var fJt=s(BMe);wur=r(fJt,"mobilebert"),fJt.forEach(t),Aur=r(TWe," \u2014 "),LY=n(TWe,"A",{href:!0});var mJt=s(LY);Lur=r(mJt,"MobileBertForMultipleChoice"),mJt.forEach(t),yur=r(TWe," (MobileBERT model)"),TWe.forEach(t),xur=i(ee),qF=n(ee,"LI",{});var MWe=s(qF);IMe=n(MWe,"STRONG",{});var gJt=s(IMe);$ur=r(gJt,"mpnet"),gJt.forEach(t),kur=r(MWe," \u2014 "),yY=n(MWe,"A",{href:!0});var hJt=s(yY);Sur=r(hJt,"MPNetForMultipleChoice"),hJt.forEach(t),Rur=r(MWe," (MPNet model)"),MWe.forEach(t),Pur=i(ee),jF=n(ee,"LI",{});var EWe=s(jF);NMe=n(EWe,"STRONG",{});var uJt=s(NMe);Bur=r(uJt,"nezha"),uJt.forEach(t),Iur=r(EWe," \u2014 "),xY=n(EWe,"A",{href:!0});var pJt=s(xY);Nur=r(pJt,"NezhaForMultipleChoice"),pJt.forEach(t),qur=r(EWe," (Nezha model)"),EWe.forEach(t),jur=i(ee),DF=n(ee,"LI",{});var CWe=s(DF);qMe=n(CWe,"STRONG",{});var _Jt=s(qMe);Dur=r(_Jt,"nystromformer"),_Jt.forEach(t),Gur=r(CWe," \u2014 "),$Y=n(CWe,"A",{href:!0});var vJt=s($Y);Our=r(vJt,"NystromformerForMultipleChoice"),vJt.forEach(t),Vur=r(CWe," (Nystr\xF6mformer model)"),CWe.forEach(t),Xur=i(ee),GF=n(ee,"LI",{});var wWe=s(GF);jMe=n(wWe,"STRONG",{});var bJt=s(jMe);zur=r(bJt,"qdqbert"),bJt.forEach(t),Qur=r(wWe," \u2014 "),kY=n(wWe,"A",{href:!0});var FJt=s(kY);Wur=r(FJt,"QDQBertForMultipleChoice"),FJt.forEach(t),Uur=r(wWe," (QDQBert model)"),wWe.forEach(t),Hur=i(ee),OF=n(ee,"LI",{});var AWe=s(OF);DMe=n(AWe,"STRONG",{});var TJt=s(DMe);Jur=r(TJt,"rembert"),TJt.forEach(t),Yur=r(AWe," \u2014 "),SY=n(AWe,"A",{href:!0});var MJt=s(SY);Zur=r(MJt,"RemBertForMultipleChoice"),MJt.forEach(t),Kur=r(AWe," (RemBERT model)"),AWe.forEach(t),epr=i(ee),VF=n(ee,"LI",{});var LWe=s(VF);GMe=n(LWe,"STRONG",{});var EJt=s(GMe);opr=r(EJt,"roberta"),EJt.forEach(t),rpr=r(LWe," \u2014 "),RY=n(LWe,"A",{href:!0});var CJt=s(RY);tpr=r(CJt,"RobertaForMultipleChoice"),CJt.forEach(t),apr=r(LWe," (RoBERTa model)"),LWe.forEach(t),npr=i(ee),XF=n(ee,"LI",{});var yWe=s(XF);OMe=n(yWe,"STRONG",{});var wJt=s(OMe);spr=r(wJt,"roformer"),wJt.forEach(t),lpr=r(yWe," \u2014 "),PY=n(yWe,"A",{href:!0});var AJt=s(PY);ipr=r(AJt,"RoFormerForMultipleChoice"),AJt.forEach(t),dpr=r(yWe," (RoFormer model)"),yWe.forEach(t),cpr=i(ee),zF=n(ee,"LI",{});var xWe=s(zF);VMe=n(xWe,"STRONG",{});var LJt=s(VMe);fpr=r(LJt,"squeezebert"),LJt.forEach(t),mpr=r(xWe," \u2014 "),BY=n(xWe,"A",{href:!0});var yJt=s(BY);gpr=r(yJt,"SqueezeBertForMultipleChoice"),yJt.forEach(t),hpr=r(xWe," (SqueezeBERT model)"),xWe.forEach(t),upr=i(ee),QF=n(ee,"LI",{});var $We=s(QF);XMe=n($We,"STRONG",{});var xJt=s(XMe);ppr=r(xJt,"xlm"),xJt.forEach(t),_pr=r($We," \u2014 "),IY=n($We,"A",{href:!0});var $Jt=s(IY);vpr=r($Jt,"XLMForMultipleChoice"),$Jt.forEach(t),bpr=r($We," (XLM model)"),$We.forEach(t),Fpr=i(ee),WF=n(ee,"LI",{});var kWe=s(WF);zMe=n(kWe,"STRONG",{});var kJt=s(zMe);Tpr=r(kJt,"xlm-roberta"),kJt.forEach(t),Mpr=r(kWe," \u2014 "),NY=n(kWe,"A",{href:!0});var SJt=s(NY);Epr=r(SJt,"XLMRobertaForMultipleChoice"),SJt.forEach(t),Cpr=r(kWe," (XLM-RoBERTa model)"),kWe.forEach(t),wpr=i(ee),UF=n(ee,"LI",{});var SWe=s(UF);QMe=n(SWe,"STRONG",{});var RJt=s(QMe);Apr=r(RJt,"xlm-roberta-xl"),RJt.forEach(t),Lpr=r(SWe," \u2014 "),qY=n(SWe,"A",{href:!0});var PJt=s(qY);ypr=r(PJt,"XLMRobertaXLForMultipleChoice"),PJt.forEach(t),xpr=r(SWe," (XLM-RoBERTa-XL model)"),SWe.forEach(t),$pr=i(ee),HF=n(ee,"LI",{});var RWe=s(HF);WMe=n(RWe,"STRONG",{});var BJt=s(WMe);kpr=r(BJt,"xlnet"),BJt.forEach(t),Spr=r(RWe," \u2014 "),jY=n(RWe,"A",{href:!0});var IJt=s(jY);Rpr=r(IJt,"XLNetForMultipleChoice"),IJt.forEach(t),Ppr=r(RWe," (XLNet model)"),RWe.forEach(t),Bpr=i(ee),JF=n(ee,"LI",{});var PWe=s(JF);UMe=n(PWe,"STRONG",{});var NJt=s(UMe);Ipr=r(NJt,"yoso"),NJt.forEach(t),Npr=r(PWe," \u2014 "),DY=n(PWe,"A",{href:!0});var qJt=s(DY);qpr=r(qJt,"YosoForMultipleChoice"),qJt.forEach(t),jpr=r(PWe," (YOSO model)"),PWe.forEach(t),ee.forEach(t),Dpr=i(Pa),YF=n(Pa,"P",{});var BWe=s(YF);Gpr=r(BWe,"The model is set in evaluation mode by default using "),HMe=n(BWe,"CODE",{});var jJt=s(HMe);Opr=r(jJt,"model.eval()"),jJt.forEach(t),Vpr=r(BWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),JMe=n(BWe,"CODE",{});var DJt=s(JMe);Xpr=r(DJt,"model.train()"),DJt.forEach(t),BWe.forEach(t),zpr=i(Pa),T(ZF.$$.fragment,Pa),Pa.forEach(t),zl.forEach(t),eao=i(f),rc=n(f,"H2",{class:!0});var bso=s(rc);KF=n(bso,"A",{id:!0,class:!0,href:!0});var GJt=s(KF);YMe=n(GJt,"SPAN",{});var OJt=s(YMe);T(Mk.$$.fragment,OJt),OJt.forEach(t),GJt.forEach(t),Qpr=i(bso),ZMe=n(bso,"SPAN",{});var VJt=s(ZMe);Wpr=r(VJt,"AutoModelForNextSentencePrediction"),VJt.forEach(t),bso.forEach(t),oao=i(f),Xo=n(f,"DIV",{class:!0});var Ql=s(Xo);T(Ek.$$.fragment,Ql),Upr=i(Ql),tc=n(Ql,"P",{});var Fce=s(tc);Hpr=r(Fce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),GY=n(Fce,"A",{href:!0});var XJt=s(GY);Jpr=r(XJt,"from_pretrained()"),XJt.forEach(t),Ypr=r(Fce," class method or the "),OY=n(Fce,"A",{href:!0});var zJt=s(OY);Zpr=r(zJt,"from_config()"),zJt.forEach(t),Kpr=r(Fce,` class
method.`),Fce.forEach(t),e_r=i(Ql),Ck=n(Ql,"P",{});var Fso=s(Ck);o_r=r(Fso,"This class cannot be instantiated directly using "),KMe=n(Fso,"CODE",{});var QJt=s(KMe);r_r=r(QJt,"__init__()"),QJt.forEach(t),t_r=r(Fso," (throws an error)."),Fso.forEach(t),a_r=i(Ql),$t=n(Ql,"DIV",{class:!0});var p9=s($t);T(wk.$$.fragment,p9),n_r=i(p9),eEe=n(p9,"P",{});var WJt=s(eEe);s_r=r(WJt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),WJt.forEach(t),l_r=i(p9),ac=n(p9,"P",{});var Tce=s(ac);i_r=r(Tce,`Note:
Loading a model from its configuration file does `),oEe=n(Tce,"STRONG",{});var UJt=s(oEe);d_r=r(UJt,"not"),UJt.forEach(t),c_r=r(Tce,` load the model weights. It only affects the
model\u2019s configuration. Use `),VY=n(Tce,"A",{href:!0});var HJt=s(VY);f_r=r(HJt,"from_pretrained()"),HJt.forEach(t),m_r=r(Tce," to load the model weights."),Tce.forEach(t),g_r=i(p9),T(eT.$$.fragment,p9),p9.forEach(t),h_r=i(Ql),lo=n(Ql,"DIV",{class:!0});var Ba=s(lo);T(Ak.$$.fragment,Ba),u_r=i(Ba),rEe=n(Ba,"P",{});var JJt=s(rEe);p_r=r(JJt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),JJt.forEach(t),__r=i(Ba),hn=n(Ba,"P",{});var _9=s(hn);v_r=r(_9,"The model class to instantiate is selected based on the "),tEe=n(_9,"CODE",{});var YJt=s(tEe);b_r=r(YJt,"model_type"),YJt.forEach(t),F_r=r(_9,` property of the config object (either
passed as an argument or loaded from `),aEe=n(_9,"CODE",{});var ZJt=s(aEe);T_r=r(ZJt,"pretrained_model_name_or_path"),ZJt.forEach(t),M_r=r(_9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nEe=n(_9,"CODE",{});var KJt=s(nEe);E_r=r(KJt,"pretrained_model_name_or_path"),KJt.forEach(t),C_r=r(_9,":"),_9.forEach(t),w_r=i(Ba),Ue=n(Ba,"UL",{});var ht=s(Ue);oT=n(ht,"LI",{});var IWe=s(oT);sEe=n(IWe,"STRONG",{});var eYt=s(sEe);A_r=r(eYt,"bert"),eYt.forEach(t),L_r=r(IWe," \u2014 "),XY=n(IWe,"A",{href:!0});var oYt=s(XY);y_r=r(oYt,"BertForNextSentencePrediction"),oYt.forEach(t),x_r=r(IWe," (BERT model)"),IWe.forEach(t),$_r=i(ht),rT=n(ht,"LI",{});var NWe=s(rT);lEe=n(NWe,"STRONG",{});var rYt=s(lEe);k_r=r(rYt,"ernie"),rYt.forEach(t),S_r=r(NWe," \u2014 "),zY=n(NWe,"A",{href:!0});var tYt=s(zY);R_r=r(tYt,"ErnieForNextSentencePrediction"),tYt.forEach(t),P_r=r(NWe," (ERNIE model)"),NWe.forEach(t),B_r=i(ht),tT=n(ht,"LI",{});var qWe=s(tT);iEe=n(qWe,"STRONG",{});var aYt=s(iEe);I_r=r(aYt,"fnet"),aYt.forEach(t),N_r=r(qWe," \u2014 "),QY=n(qWe,"A",{href:!0});var nYt=s(QY);q_r=r(nYt,"FNetForNextSentencePrediction"),nYt.forEach(t),j_r=r(qWe," (FNet model)"),qWe.forEach(t),D_r=i(ht),aT=n(ht,"LI",{});var jWe=s(aT);dEe=n(jWe,"STRONG",{});var sYt=s(dEe);G_r=r(sYt,"megatron-bert"),sYt.forEach(t),O_r=r(jWe," \u2014 "),WY=n(jWe,"A",{href:!0});var lYt=s(WY);V_r=r(lYt,"MegatronBertForNextSentencePrediction"),lYt.forEach(t),X_r=r(jWe," (Megatron-BERT model)"),jWe.forEach(t),z_r=i(ht),nT=n(ht,"LI",{});var DWe=s(nT);cEe=n(DWe,"STRONG",{});var iYt=s(cEe);Q_r=r(iYt,"mobilebert"),iYt.forEach(t),W_r=r(DWe," \u2014 "),UY=n(DWe,"A",{href:!0});var dYt=s(UY);U_r=r(dYt,"MobileBertForNextSentencePrediction"),dYt.forEach(t),H_r=r(DWe," (MobileBERT model)"),DWe.forEach(t),J_r=i(ht),sT=n(ht,"LI",{});var GWe=s(sT);fEe=n(GWe,"STRONG",{});var cYt=s(fEe);Y_r=r(cYt,"nezha"),cYt.forEach(t),Z_r=r(GWe," \u2014 "),HY=n(GWe,"A",{href:!0});var fYt=s(HY);K_r=r(fYt,"NezhaForNextSentencePrediction"),fYt.forEach(t),e4r=r(GWe," (Nezha model)"),GWe.forEach(t),o4r=i(ht),lT=n(ht,"LI",{});var OWe=s(lT);mEe=n(OWe,"STRONG",{});var mYt=s(mEe);r4r=r(mYt,"qdqbert"),mYt.forEach(t),t4r=r(OWe," \u2014 "),JY=n(OWe,"A",{href:!0});var gYt=s(JY);a4r=r(gYt,"QDQBertForNextSentencePrediction"),gYt.forEach(t),n4r=r(OWe," (QDQBert model)"),OWe.forEach(t),ht.forEach(t),s4r=i(Ba),iT=n(Ba,"P",{});var VWe=s(iT);l4r=r(VWe,"The model is set in evaluation mode by default using "),gEe=n(VWe,"CODE",{});var hYt=s(gEe);i4r=r(hYt,"model.eval()"),hYt.forEach(t),d4r=r(VWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),hEe=n(VWe,"CODE",{});var uYt=s(hEe);c4r=r(uYt,"model.train()"),uYt.forEach(t),VWe.forEach(t),f4r=i(Ba),T(dT.$$.fragment,Ba),Ba.forEach(t),Ql.forEach(t),rao=i(f),nc=n(f,"H2",{class:!0});var Tso=s(nc);cT=n(Tso,"A",{id:!0,class:!0,href:!0});var pYt=s(cT);uEe=n(pYt,"SPAN",{});var _Yt=s(uEe);T(Lk.$$.fragment,_Yt),_Yt.forEach(t),pYt.forEach(t),m4r=i(Tso),pEe=n(Tso,"SPAN",{});var vYt=s(pEe);g4r=r(vYt,"AutoModelForTokenClassification"),vYt.forEach(t),Tso.forEach(t),tao=i(f),zo=n(f,"DIV",{class:!0});var Wl=s(zo);T(yk.$$.fragment,Wl),h4r=i(Wl),sc=n(Wl,"P",{});var Mce=s(sc);u4r=r(Mce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),YY=n(Mce,"A",{href:!0});var bYt=s(YY);p4r=r(bYt,"from_pretrained()"),bYt.forEach(t),_4r=r(Mce," class method or the "),ZY=n(Mce,"A",{href:!0});var FYt=s(ZY);v4r=r(FYt,"from_config()"),FYt.forEach(t),b4r=r(Mce,` class
method.`),Mce.forEach(t),F4r=i(Wl),xk=n(Wl,"P",{});var Mso=s(xk);T4r=r(Mso,"This class cannot be instantiated directly using "),_Ee=n(Mso,"CODE",{});var TYt=s(_Ee);M4r=r(TYt,"__init__()"),TYt.forEach(t),E4r=r(Mso," (throws an error)."),Mso.forEach(t),C4r=i(Wl),kt=n(Wl,"DIV",{class:!0});var v9=s(kt);T($k.$$.fragment,v9),w4r=i(v9),vEe=n(v9,"P",{});var MYt=s(vEe);A4r=r(MYt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),MYt.forEach(t),L4r=i(v9),lc=n(v9,"P",{});var Ece=s(lc);y4r=r(Ece,`Note:
Loading a model from its configuration file does `),bEe=n(Ece,"STRONG",{});var EYt=s(bEe);x4r=r(EYt,"not"),EYt.forEach(t),$4r=r(Ece,` load the model weights. It only affects the
model\u2019s configuration. Use `),KY=n(Ece,"A",{href:!0});var CYt=s(KY);k4r=r(CYt,"from_pretrained()"),CYt.forEach(t),S4r=r(Ece," to load the model weights."),Ece.forEach(t),R4r=i(v9),T(fT.$$.fragment,v9),v9.forEach(t),P4r=i(Wl),io=n(Wl,"DIV",{class:!0});var Ia=s(io);T(kk.$$.fragment,Ia),B4r=i(Ia),FEe=n(Ia,"P",{});var wYt=s(FEe);I4r=r(wYt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),wYt.forEach(t),N4r=i(Ia),un=n(Ia,"P",{});var b9=s(un);q4r=r(b9,"The model class to instantiate is selected based on the "),TEe=n(b9,"CODE",{});var AYt=s(TEe);j4r=r(AYt,"model_type"),AYt.forEach(t),D4r=r(b9,` property of the config object (either
passed as an argument or loaded from `),MEe=n(b9,"CODE",{});var LYt=s(MEe);G4r=r(LYt,"pretrained_model_name_or_path"),LYt.forEach(t),O4r=r(b9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),EEe=n(b9,"CODE",{});var yYt=s(EEe);V4r=r(yYt,"pretrained_model_name_or_path"),yYt.forEach(t),X4r=r(b9,":"),b9.forEach(t),z4r=i(Ia),U=n(Ia,"UL",{});var J=s(U);mT=n(J,"LI",{});var XWe=s(mT);CEe=n(XWe,"STRONG",{});var xYt=s(CEe);Q4r=r(xYt,"albert"),xYt.forEach(t),W4r=r(XWe," \u2014 "),eZ=n(XWe,"A",{href:!0});var $Yt=s(eZ);U4r=r($Yt,"AlbertForTokenClassification"),$Yt.forEach(t),H4r=r(XWe," (ALBERT model)"),XWe.forEach(t),J4r=i(J),gT=n(J,"LI",{});var zWe=s(gT);wEe=n(zWe,"STRONG",{});var kYt=s(wEe);Y4r=r(kYt,"bert"),kYt.forEach(t),Z4r=r(zWe," \u2014 "),oZ=n(zWe,"A",{href:!0});var SYt=s(oZ);K4r=r(SYt,"BertForTokenClassification"),SYt.forEach(t),e2r=r(zWe," (BERT model)"),zWe.forEach(t),o2r=i(J),hT=n(J,"LI",{});var QWe=s(hT);AEe=n(QWe,"STRONG",{});var RYt=s(AEe);r2r=r(RYt,"big_bird"),RYt.forEach(t),t2r=r(QWe," \u2014 "),rZ=n(QWe,"A",{href:!0});var PYt=s(rZ);a2r=r(PYt,"BigBirdForTokenClassification"),PYt.forEach(t),n2r=r(QWe," (BigBird model)"),QWe.forEach(t),s2r=i(J),uT=n(J,"LI",{});var WWe=s(uT);LEe=n(WWe,"STRONG",{});var BYt=s(LEe);l2r=r(BYt,"bloom"),BYt.forEach(t),i2r=r(WWe," \u2014 "),tZ=n(WWe,"A",{href:!0});var IYt=s(tZ);d2r=r(IYt,"BloomForTokenClassification"),IYt.forEach(t),c2r=r(WWe," (BLOOM model)"),WWe.forEach(t),f2r=i(J),pT=n(J,"LI",{});var UWe=s(pT);yEe=n(UWe,"STRONG",{});var NYt=s(yEe);m2r=r(NYt,"camembert"),NYt.forEach(t),g2r=r(UWe," \u2014 "),aZ=n(UWe,"A",{href:!0});var qYt=s(aZ);h2r=r(qYt,"CamembertForTokenClassification"),qYt.forEach(t),u2r=r(UWe," (CamemBERT model)"),UWe.forEach(t),p2r=i(J),_T=n(J,"LI",{});var HWe=s(_T);xEe=n(HWe,"STRONG",{});var jYt=s(xEe);_2r=r(jYt,"canine"),jYt.forEach(t),v2r=r(HWe," \u2014 "),nZ=n(HWe,"A",{href:!0});var DYt=s(nZ);b2r=r(DYt,"CanineForTokenClassification"),DYt.forEach(t),F2r=r(HWe," (CANINE model)"),HWe.forEach(t),T2r=i(J),vT=n(J,"LI",{});var JWe=s(vT);$Ee=n(JWe,"STRONG",{});var GYt=s($Ee);M2r=r(GYt,"convbert"),GYt.forEach(t),E2r=r(JWe," \u2014 "),sZ=n(JWe,"A",{href:!0});var OYt=s(sZ);C2r=r(OYt,"ConvBertForTokenClassification"),OYt.forEach(t),w2r=r(JWe," (ConvBERT model)"),JWe.forEach(t),A2r=i(J),bT=n(J,"LI",{});var YWe=s(bT);kEe=n(YWe,"STRONG",{});var VYt=s(kEe);L2r=r(VYt,"data2vec-text"),VYt.forEach(t),y2r=r(YWe," \u2014 "),lZ=n(YWe,"A",{href:!0});var XYt=s(lZ);x2r=r(XYt,"Data2VecTextForTokenClassification"),XYt.forEach(t),$2r=r(YWe," (Data2VecText model)"),YWe.forEach(t),k2r=i(J),FT=n(J,"LI",{});var ZWe=s(FT);SEe=n(ZWe,"STRONG",{});var zYt=s(SEe);S2r=r(zYt,"deberta"),zYt.forEach(t),R2r=r(ZWe," \u2014 "),iZ=n(ZWe,"A",{href:!0});var QYt=s(iZ);P2r=r(QYt,"DebertaForTokenClassification"),QYt.forEach(t),B2r=r(ZWe," (DeBERTa model)"),ZWe.forEach(t),I2r=i(J),TT=n(J,"LI",{});var KWe=s(TT);REe=n(KWe,"STRONG",{});var WYt=s(REe);N2r=r(WYt,"deberta-v2"),WYt.forEach(t),q2r=r(KWe," \u2014 "),dZ=n(KWe,"A",{href:!0});var UYt=s(dZ);j2r=r(UYt,"DebertaV2ForTokenClassification"),UYt.forEach(t),D2r=r(KWe," (DeBERTa-v2 model)"),KWe.forEach(t),G2r=i(J),MT=n(J,"LI",{});var eUe=s(MT);PEe=n(eUe,"STRONG",{});var HYt=s(PEe);O2r=r(HYt,"distilbert"),HYt.forEach(t),V2r=r(eUe," \u2014 "),cZ=n(eUe,"A",{href:!0});var JYt=s(cZ);X2r=r(JYt,"DistilBertForTokenClassification"),JYt.forEach(t),z2r=r(eUe," (DistilBERT model)"),eUe.forEach(t),Q2r=i(J),ET=n(J,"LI",{});var oUe=s(ET);BEe=n(oUe,"STRONG",{});var YYt=s(BEe);W2r=r(YYt,"electra"),YYt.forEach(t),U2r=r(oUe," \u2014 "),fZ=n(oUe,"A",{href:!0});var ZYt=s(fZ);H2r=r(ZYt,"ElectraForTokenClassification"),ZYt.forEach(t),J2r=r(oUe," (ELECTRA model)"),oUe.forEach(t),Y2r=i(J),CT=n(J,"LI",{});var rUe=s(CT);IEe=n(rUe,"STRONG",{});var KYt=s(IEe);Z2r=r(KYt,"ernie"),KYt.forEach(t),K2r=r(rUe," \u2014 "),mZ=n(rUe,"A",{href:!0});var eZt=s(mZ);evr=r(eZt,"ErnieForTokenClassification"),eZt.forEach(t),ovr=r(rUe," (ERNIE model)"),rUe.forEach(t),rvr=i(J),wT=n(J,"LI",{});var tUe=s(wT);NEe=n(tUe,"STRONG",{});var oZt=s(NEe);tvr=r(oZt,"esm"),oZt.forEach(t),avr=r(tUe," \u2014 "),gZ=n(tUe,"A",{href:!0});var rZt=s(gZ);nvr=r(rZt,"EsmForTokenClassification"),rZt.forEach(t),svr=r(tUe," (ESM model)"),tUe.forEach(t),lvr=i(J),AT=n(J,"LI",{});var aUe=s(AT);qEe=n(aUe,"STRONG",{});var tZt=s(qEe);ivr=r(tZt,"flaubert"),tZt.forEach(t),dvr=r(aUe," \u2014 "),hZ=n(aUe,"A",{href:!0});var aZt=s(hZ);cvr=r(aZt,"FlaubertForTokenClassification"),aZt.forEach(t),fvr=r(aUe," (FlauBERT model)"),aUe.forEach(t),mvr=i(J),LT=n(J,"LI",{});var nUe=s(LT);jEe=n(nUe,"STRONG",{});var nZt=s(jEe);gvr=r(nZt,"fnet"),nZt.forEach(t),hvr=r(nUe," \u2014 "),uZ=n(nUe,"A",{href:!0});var sZt=s(uZ);uvr=r(sZt,"FNetForTokenClassification"),sZt.forEach(t),pvr=r(nUe," (FNet model)"),nUe.forEach(t),_vr=i(J),yT=n(J,"LI",{});var sUe=s(yT);DEe=n(sUe,"STRONG",{});var lZt=s(DEe);vvr=r(lZt,"funnel"),lZt.forEach(t),bvr=r(sUe," \u2014 "),pZ=n(sUe,"A",{href:!0});var iZt=s(pZ);Fvr=r(iZt,"FunnelForTokenClassification"),iZt.forEach(t),Tvr=r(sUe," (Funnel Transformer model)"),sUe.forEach(t),Mvr=i(J),xT=n(J,"LI",{});var lUe=s(xT);GEe=n(lUe,"STRONG",{});var dZt=s(GEe);Evr=r(dZt,"gpt2"),dZt.forEach(t),Cvr=r(lUe," \u2014 "),_Z=n(lUe,"A",{href:!0});var cZt=s(_Z);wvr=r(cZt,"GPT2ForTokenClassification"),cZt.forEach(t),Avr=r(lUe," (OpenAI GPT-2 model)"),lUe.forEach(t),Lvr=i(J),$T=n(J,"LI",{});var iUe=s($T);OEe=n(iUe,"STRONG",{});var fZt=s(OEe);yvr=r(fZt,"ibert"),fZt.forEach(t),xvr=r(iUe," \u2014 "),vZ=n(iUe,"A",{href:!0});var mZt=s(vZ);$vr=r(mZt,"IBertForTokenClassification"),mZt.forEach(t),kvr=r(iUe," (I-BERT model)"),iUe.forEach(t),Svr=i(J),kT=n(J,"LI",{});var dUe=s(kT);VEe=n(dUe,"STRONG",{});var gZt=s(VEe);Rvr=r(gZt,"layoutlm"),gZt.forEach(t),Pvr=r(dUe," \u2014 "),bZ=n(dUe,"A",{href:!0});var hZt=s(bZ);Bvr=r(hZt,"LayoutLMForTokenClassification"),hZt.forEach(t),Ivr=r(dUe," (LayoutLM model)"),dUe.forEach(t),Nvr=i(J),ST=n(J,"LI",{});var cUe=s(ST);XEe=n(cUe,"STRONG",{});var uZt=s(XEe);qvr=r(uZt,"layoutlmv2"),uZt.forEach(t),jvr=r(cUe," \u2014 "),FZ=n(cUe,"A",{href:!0});var pZt=s(FZ);Dvr=r(pZt,"LayoutLMv2ForTokenClassification"),pZt.forEach(t),Gvr=r(cUe," (LayoutLMv2 model)"),cUe.forEach(t),Ovr=i(J),RT=n(J,"LI",{});var fUe=s(RT);zEe=n(fUe,"STRONG",{});var _Zt=s(zEe);Vvr=r(_Zt,"layoutlmv3"),_Zt.forEach(t),Xvr=r(fUe," \u2014 "),TZ=n(fUe,"A",{href:!0});var vZt=s(TZ);zvr=r(vZt,"LayoutLMv3ForTokenClassification"),vZt.forEach(t),Qvr=r(fUe," (LayoutLMv3 model)"),fUe.forEach(t),Wvr=i(J),PT=n(J,"LI",{});var mUe=s(PT);QEe=n(mUe,"STRONG",{});var bZt=s(QEe);Uvr=r(bZt,"lilt"),bZt.forEach(t),Hvr=r(mUe," \u2014 "),MZ=n(mUe,"A",{href:!0});var FZt=s(MZ);Jvr=r(FZt,"LiltForTokenClassification"),FZt.forEach(t),Yvr=r(mUe," (LiLT model)"),mUe.forEach(t),Zvr=i(J),BT=n(J,"LI",{});var gUe=s(BT);WEe=n(gUe,"STRONG",{});var TZt=s(WEe);Kvr=r(TZt,"longformer"),TZt.forEach(t),e1r=r(gUe," \u2014 "),EZ=n(gUe,"A",{href:!0});var MZt=s(EZ);o1r=r(MZt,"LongformerForTokenClassification"),MZt.forEach(t),r1r=r(gUe," (Longformer model)"),gUe.forEach(t),t1r=i(J),IT=n(J,"LI",{});var hUe=s(IT);UEe=n(hUe,"STRONG",{});var EZt=s(UEe);a1r=r(EZt,"luke"),EZt.forEach(t),n1r=r(hUe," \u2014 "),CZ=n(hUe,"A",{href:!0});var CZt=s(CZ);s1r=r(CZt,"LukeForTokenClassification"),CZt.forEach(t),l1r=r(hUe," (LUKE model)"),hUe.forEach(t),i1r=i(J),NT=n(J,"LI",{});var uUe=s(NT);HEe=n(uUe,"STRONG",{});var wZt=s(HEe);d1r=r(wZt,"markuplm"),wZt.forEach(t),c1r=r(uUe," \u2014 "),wZ=n(uUe,"A",{href:!0});var AZt=s(wZ);f1r=r(AZt,"MarkupLMForTokenClassification"),AZt.forEach(t),m1r=r(uUe," (MarkupLM model)"),uUe.forEach(t),g1r=i(J),qT=n(J,"LI",{});var pUe=s(qT);JEe=n(pUe,"STRONG",{});var LZt=s(JEe);h1r=r(LZt,"megatron-bert"),LZt.forEach(t),u1r=r(pUe," \u2014 "),AZ=n(pUe,"A",{href:!0});var yZt=s(AZ);p1r=r(yZt,"MegatronBertForTokenClassification"),yZt.forEach(t),_1r=r(pUe," (Megatron-BERT model)"),pUe.forEach(t),v1r=i(J),jT=n(J,"LI",{});var _Ue=s(jT);YEe=n(_Ue,"STRONG",{});var xZt=s(YEe);b1r=r(xZt,"mobilebert"),xZt.forEach(t),F1r=r(_Ue," \u2014 "),LZ=n(_Ue,"A",{href:!0});var $Zt=s(LZ);T1r=r($Zt,"MobileBertForTokenClassification"),$Zt.forEach(t),M1r=r(_Ue," (MobileBERT model)"),_Ue.forEach(t),E1r=i(J),DT=n(J,"LI",{});var vUe=s(DT);ZEe=n(vUe,"STRONG",{});var kZt=s(ZEe);C1r=r(kZt,"mpnet"),kZt.forEach(t),w1r=r(vUe," \u2014 "),yZ=n(vUe,"A",{href:!0});var SZt=s(yZ);A1r=r(SZt,"MPNetForTokenClassification"),SZt.forEach(t),L1r=r(vUe," (MPNet model)"),vUe.forEach(t),y1r=i(J),GT=n(J,"LI",{});var bUe=s(GT);KEe=n(bUe,"STRONG",{});var RZt=s(KEe);x1r=r(RZt,"nezha"),RZt.forEach(t),$1r=r(bUe," \u2014 "),xZ=n(bUe,"A",{href:!0});var PZt=s(xZ);k1r=r(PZt,"NezhaForTokenClassification"),PZt.forEach(t),S1r=r(bUe," (Nezha model)"),bUe.forEach(t),R1r=i(J),OT=n(J,"LI",{});var FUe=s(OT);eCe=n(FUe,"STRONG",{});var BZt=s(eCe);P1r=r(BZt,"nystromformer"),BZt.forEach(t),B1r=r(FUe," \u2014 "),$Z=n(FUe,"A",{href:!0});var IZt=s($Z);I1r=r(IZt,"NystromformerForTokenClassification"),IZt.forEach(t),N1r=r(FUe," (Nystr\xF6mformer model)"),FUe.forEach(t),q1r=i(J),VT=n(J,"LI",{});var TUe=s(VT);oCe=n(TUe,"STRONG",{});var NZt=s(oCe);j1r=r(NZt,"qdqbert"),NZt.forEach(t),D1r=r(TUe," \u2014 "),kZ=n(TUe,"A",{href:!0});var qZt=s(kZ);G1r=r(qZt,"QDQBertForTokenClassification"),qZt.forEach(t),O1r=r(TUe," (QDQBert model)"),TUe.forEach(t),V1r=i(J),XT=n(J,"LI",{});var MUe=s(XT);rCe=n(MUe,"STRONG",{});var jZt=s(rCe);X1r=r(jZt,"rembert"),jZt.forEach(t),z1r=r(MUe," \u2014 "),SZ=n(MUe,"A",{href:!0});var DZt=s(SZ);Q1r=r(DZt,"RemBertForTokenClassification"),DZt.forEach(t),W1r=r(MUe," (RemBERT model)"),MUe.forEach(t),U1r=i(J),zT=n(J,"LI",{});var EUe=s(zT);tCe=n(EUe,"STRONG",{});var GZt=s(tCe);H1r=r(GZt,"roberta"),GZt.forEach(t),J1r=r(EUe," \u2014 "),RZ=n(EUe,"A",{href:!0});var OZt=s(RZ);Y1r=r(OZt,"RobertaForTokenClassification"),OZt.forEach(t),Z1r=r(EUe," (RoBERTa model)"),EUe.forEach(t),K1r=i(J),QT=n(J,"LI",{});var CUe=s(QT);aCe=n(CUe,"STRONG",{});var VZt=s(aCe);ebr=r(VZt,"roformer"),VZt.forEach(t),obr=r(CUe," \u2014 "),PZ=n(CUe,"A",{href:!0});var XZt=s(PZ);rbr=r(XZt,"RoFormerForTokenClassification"),XZt.forEach(t),tbr=r(CUe," (RoFormer model)"),CUe.forEach(t),abr=i(J),WT=n(J,"LI",{});var wUe=s(WT);nCe=n(wUe,"STRONG",{});var zZt=s(nCe);nbr=r(zZt,"squeezebert"),zZt.forEach(t),sbr=r(wUe," \u2014 "),BZ=n(wUe,"A",{href:!0});var QZt=s(BZ);lbr=r(QZt,"SqueezeBertForTokenClassification"),QZt.forEach(t),ibr=r(wUe," (SqueezeBERT model)"),wUe.forEach(t),dbr=i(J),UT=n(J,"LI",{});var AUe=s(UT);sCe=n(AUe,"STRONG",{});var WZt=s(sCe);cbr=r(WZt,"xlm"),WZt.forEach(t),fbr=r(AUe," \u2014 "),IZ=n(AUe,"A",{href:!0});var UZt=s(IZ);mbr=r(UZt,"XLMForTokenClassification"),UZt.forEach(t),gbr=r(AUe," (XLM model)"),AUe.forEach(t),hbr=i(J),HT=n(J,"LI",{});var LUe=s(HT);lCe=n(LUe,"STRONG",{});var HZt=s(lCe);ubr=r(HZt,"xlm-roberta"),HZt.forEach(t),pbr=r(LUe," \u2014 "),NZ=n(LUe,"A",{href:!0});var JZt=s(NZ);_br=r(JZt,"XLMRobertaForTokenClassification"),JZt.forEach(t),vbr=r(LUe," (XLM-RoBERTa model)"),LUe.forEach(t),bbr=i(J),JT=n(J,"LI",{});var yUe=s(JT);iCe=n(yUe,"STRONG",{});var YZt=s(iCe);Fbr=r(YZt,"xlm-roberta-xl"),YZt.forEach(t),Tbr=r(yUe," \u2014 "),qZ=n(yUe,"A",{href:!0});var ZZt=s(qZ);Mbr=r(ZZt,"XLMRobertaXLForTokenClassification"),ZZt.forEach(t),Ebr=r(yUe," (XLM-RoBERTa-XL model)"),yUe.forEach(t),Cbr=i(J),YT=n(J,"LI",{});var xUe=s(YT);dCe=n(xUe,"STRONG",{});var KZt=s(dCe);wbr=r(KZt,"xlnet"),KZt.forEach(t),Abr=r(xUe," \u2014 "),jZ=n(xUe,"A",{href:!0});var eKt=s(jZ);Lbr=r(eKt,"XLNetForTokenClassification"),eKt.forEach(t),ybr=r(xUe," (XLNet model)"),xUe.forEach(t),xbr=i(J),ZT=n(J,"LI",{});var $Ue=s(ZT);cCe=n($Ue,"STRONG",{});var oKt=s(cCe);$br=r(oKt,"yoso"),oKt.forEach(t),kbr=r($Ue," \u2014 "),DZ=n($Ue,"A",{href:!0});var rKt=s(DZ);Sbr=r(rKt,"YosoForTokenClassification"),rKt.forEach(t),Rbr=r($Ue," (YOSO model)"),$Ue.forEach(t),J.forEach(t),Pbr=i(Ia),KT=n(Ia,"P",{});var kUe=s(KT);Bbr=r(kUe,"The model is set in evaluation mode by default using "),fCe=n(kUe,"CODE",{});var tKt=s(fCe);Ibr=r(tKt,"model.eval()"),tKt.forEach(t),Nbr=r(kUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mCe=n(kUe,"CODE",{});var aKt=s(mCe);qbr=r(aKt,"model.train()"),aKt.forEach(t),kUe.forEach(t),jbr=i(Ia),T(eM.$$.fragment,Ia),Ia.forEach(t),Wl.forEach(t),aao=i(f),ic=n(f,"H2",{class:!0});var Eso=s(ic);oM=n(Eso,"A",{id:!0,class:!0,href:!0});var nKt=s(oM);gCe=n(nKt,"SPAN",{});var sKt=s(gCe);T(Sk.$$.fragment,sKt),sKt.forEach(t),nKt.forEach(t),Dbr=i(Eso),hCe=n(Eso,"SPAN",{});var lKt=s(hCe);Gbr=r(lKt,"AutoModelForQuestionAnswering"),lKt.forEach(t),Eso.forEach(t),nao=i(f),Qo=n(f,"DIV",{class:!0});var Ul=s(Qo);T(Rk.$$.fragment,Ul),Obr=i(Ul),dc=n(Ul,"P",{});var Cce=s(dc);Vbr=r(Cce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),GZ=n(Cce,"A",{href:!0});var iKt=s(GZ);Xbr=r(iKt,"from_pretrained()"),iKt.forEach(t),zbr=r(Cce," class method or the "),OZ=n(Cce,"A",{href:!0});var dKt=s(OZ);Qbr=r(dKt,"from_config()"),dKt.forEach(t),Wbr=r(Cce,` class
method.`),Cce.forEach(t),Ubr=i(Ul),Pk=n(Ul,"P",{});var Cso=s(Pk);Hbr=r(Cso,"This class cannot be instantiated directly using "),uCe=n(Cso,"CODE",{});var cKt=s(uCe);Jbr=r(cKt,"__init__()"),cKt.forEach(t),Ybr=r(Cso," (throws an error)."),Cso.forEach(t),Zbr=i(Ul),St=n(Ul,"DIV",{class:!0});var F9=s(St);T(Bk.$$.fragment,F9),Kbr=i(F9),pCe=n(F9,"P",{});var fKt=s(pCe);e0r=r(fKt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),fKt.forEach(t),o0r=i(F9),cc=n(F9,"P",{});var wce=s(cc);r0r=r(wce,`Note:
Loading a model from its configuration file does `),_Ce=n(wce,"STRONG",{});var mKt=s(_Ce);t0r=r(mKt,"not"),mKt.forEach(t),a0r=r(wce,` load the model weights. It only affects the
model\u2019s configuration. Use `),VZ=n(wce,"A",{href:!0});var gKt=s(VZ);n0r=r(gKt,"from_pretrained()"),gKt.forEach(t),s0r=r(wce," to load the model weights."),wce.forEach(t),l0r=i(F9),T(rM.$$.fragment,F9),F9.forEach(t),i0r=i(Ul),co=n(Ul,"DIV",{class:!0});var Na=s(co);T(Ik.$$.fragment,Na),d0r=i(Na),vCe=n(Na,"P",{});var hKt=s(vCe);c0r=r(hKt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),hKt.forEach(t),f0r=i(Na),pn=n(Na,"P",{});var T9=s(pn);m0r=r(T9,"The model class to instantiate is selected based on the "),bCe=n(T9,"CODE",{});var uKt=s(bCe);g0r=r(uKt,"model_type"),uKt.forEach(t),h0r=r(T9,` property of the config object (either
passed as an argument or loaded from `),FCe=n(T9,"CODE",{});var pKt=s(FCe);u0r=r(pKt,"pretrained_model_name_or_path"),pKt.forEach(t),p0r=r(T9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TCe=n(T9,"CODE",{});var _Kt=s(TCe);_0r=r(_Kt,"pretrained_model_name_or_path"),_Kt.forEach(t),v0r=r(T9,":"),T9.forEach(t),b0r=i(Na),O=n(Na,"UL",{});var X=s(O);tM=n(X,"LI",{});var SUe=s(tM);MCe=n(SUe,"STRONG",{});var vKt=s(MCe);F0r=r(vKt,"albert"),vKt.forEach(t),T0r=r(SUe," \u2014 "),XZ=n(SUe,"A",{href:!0});var bKt=s(XZ);M0r=r(bKt,"AlbertForQuestionAnswering"),bKt.forEach(t),E0r=r(SUe," (ALBERT model)"),SUe.forEach(t),C0r=i(X),aM=n(X,"LI",{});var RUe=s(aM);ECe=n(RUe,"STRONG",{});var FKt=s(ECe);w0r=r(FKt,"bart"),FKt.forEach(t),A0r=r(RUe," \u2014 "),zZ=n(RUe,"A",{href:!0});var TKt=s(zZ);L0r=r(TKt,"BartForQuestionAnswering"),TKt.forEach(t),y0r=r(RUe," (BART model)"),RUe.forEach(t),x0r=i(X),nM=n(X,"LI",{});var PUe=s(nM);CCe=n(PUe,"STRONG",{});var MKt=s(CCe);$0r=r(MKt,"bert"),MKt.forEach(t),k0r=r(PUe," \u2014 "),QZ=n(PUe,"A",{href:!0});var EKt=s(QZ);S0r=r(EKt,"BertForQuestionAnswering"),EKt.forEach(t),R0r=r(PUe," (BERT model)"),PUe.forEach(t),P0r=i(X),sM=n(X,"LI",{});var BUe=s(sM);wCe=n(BUe,"STRONG",{});var CKt=s(wCe);B0r=r(CKt,"big_bird"),CKt.forEach(t),I0r=r(BUe," \u2014 "),WZ=n(BUe,"A",{href:!0});var wKt=s(WZ);N0r=r(wKt,"BigBirdForQuestionAnswering"),wKt.forEach(t),q0r=r(BUe," (BigBird model)"),BUe.forEach(t),j0r=i(X),lM=n(X,"LI",{});var IUe=s(lM);ACe=n(IUe,"STRONG",{});var AKt=s(ACe);D0r=r(AKt,"bigbird_pegasus"),AKt.forEach(t),G0r=r(IUe," \u2014 "),UZ=n(IUe,"A",{href:!0});var LKt=s(UZ);O0r=r(LKt,"BigBirdPegasusForQuestionAnswering"),LKt.forEach(t),V0r=r(IUe," (BigBird-Pegasus model)"),IUe.forEach(t),X0r=i(X),iM=n(X,"LI",{});var NUe=s(iM);LCe=n(NUe,"STRONG",{});var yKt=s(LCe);z0r=r(yKt,"bloom"),yKt.forEach(t),Q0r=r(NUe," \u2014 "),HZ=n(NUe,"A",{href:!0});var xKt=s(HZ);W0r=r(xKt,"BloomForQuestionAnswering"),xKt.forEach(t),U0r=r(NUe," (BLOOM model)"),NUe.forEach(t),H0r=i(X),dM=n(X,"LI",{});var qUe=s(dM);yCe=n(qUe,"STRONG",{});var $Kt=s(yCe);J0r=r($Kt,"camembert"),$Kt.forEach(t),Y0r=r(qUe," \u2014 "),JZ=n(qUe,"A",{href:!0});var kKt=s(JZ);Z0r=r(kKt,"CamembertForQuestionAnswering"),kKt.forEach(t),K0r=r(qUe," (CamemBERT model)"),qUe.forEach(t),eFr=i(X),cM=n(X,"LI",{});var jUe=s(cM);xCe=n(jUe,"STRONG",{});var SKt=s(xCe);oFr=r(SKt,"canine"),SKt.forEach(t),rFr=r(jUe," \u2014 "),YZ=n(jUe,"A",{href:!0});var RKt=s(YZ);tFr=r(RKt,"CanineForQuestionAnswering"),RKt.forEach(t),aFr=r(jUe," (CANINE model)"),jUe.forEach(t),nFr=i(X),fM=n(X,"LI",{});var DUe=s(fM);$Ce=n(DUe,"STRONG",{});var PKt=s($Ce);sFr=r(PKt,"convbert"),PKt.forEach(t),lFr=r(DUe," \u2014 "),ZZ=n(DUe,"A",{href:!0});var BKt=s(ZZ);iFr=r(BKt,"ConvBertForQuestionAnswering"),BKt.forEach(t),dFr=r(DUe," (ConvBERT model)"),DUe.forEach(t),cFr=i(X),mM=n(X,"LI",{});var GUe=s(mM);kCe=n(GUe,"STRONG",{});var IKt=s(kCe);fFr=r(IKt,"data2vec-text"),IKt.forEach(t),mFr=r(GUe," \u2014 "),KZ=n(GUe,"A",{href:!0});var NKt=s(KZ);gFr=r(NKt,"Data2VecTextForQuestionAnswering"),NKt.forEach(t),hFr=r(GUe," (Data2VecText model)"),GUe.forEach(t),uFr=i(X),gM=n(X,"LI",{});var OUe=s(gM);SCe=n(OUe,"STRONG",{});var qKt=s(SCe);pFr=r(qKt,"deberta"),qKt.forEach(t),_Fr=r(OUe," \u2014 "),eK=n(OUe,"A",{href:!0});var jKt=s(eK);vFr=r(jKt,"DebertaForQuestionAnswering"),jKt.forEach(t),bFr=r(OUe," (DeBERTa model)"),OUe.forEach(t),FFr=i(X),hM=n(X,"LI",{});var VUe=s(hM);RCe=n(VUe,"STRONG",{});var DKt=s(RCe);TFr=r(DKt,"deberta-v2"),DKt.forEach(t),MFr=r(VUe," \u2014 "),oK=n(VUe,"A",{href:!0});var GKt=s(oK);EFr=r(GKt,"DebertaV2ForQuestionAnswering"),GKt.forEach(t),CFr=r(VUe," (DeBERTa-v2 model)"),VUe.forEach(t),wFr=i(X),uM=n(X,"LI",{});var XUe=s(uM);PCe=n(XUe,"STRONG",{});var OKt=s(PCe);AFr=r(OKt,"distilbert"),OKt.forEach(t),LFr=r(XUe," \u2014 "),rK=n(XUe,"A",{href:!0});var VKt=s(rK);yFr=r(VKt,"DistilBertForQuestionAnswering"),VKt.forEach(t),xFr=r(XUe," (DistilBERT model)"),XUe.forEach(t),$Fr=i(X),pM=n(X,"LI",{});var zUe=s(pM);BCe=n(zUe,"STRONG",{});var XKt=s(BCe);kFr=r(XKt,"electra"),XKt.forEach(t),SFr=r(zUe," \u2014 "),tK=n(zUe,"A",{href:!0});var zKt=s(tK);RFr=r(zKt,"ElectraForQuestionAnswering"),zKt.forEach(t),PFr=r(zUe," (ELECTRA model)"),zUe.forEach(t),BFr=i(X),_M=n(X,"LI",{});var QUe=s(_M);ICe=n(QUe,"STRONG",{});var QKt=s(ICe);IFr=r(QKt,"ernie"),QKt.forEach(t),NFr=r(QUe," \u2014 "),aK=n(QUe,"A",{href:!0});var WKt=s(aK);qFr=r(WKt,"ErnieForQuestionAnswering"),WKt.forEach(t),jFr=r(QUe," (ERNIE model)"),QUe.forEach(t),DFr=i(X),vM=n(X,"LI",{});var WUe=s(vM);NCe=n(WUe,"STRONG",{});var UKt=s(NCe);GFr=r(UKt,"flaubert"),UKt.forEach(t),OFr=r(WUe," \u2014 "),nK=n(WUe,"A",{href:!0});var HKt=s(nK);VFr=r(HKt,"FlaubertForQuestionAnsweringSimple"),HKt.forEach(t),XFr=r(WUe," (FlauBERT model)"),WUe.forEach(t),zFr=i(X),bM=n(X,"LI",{});var UUe=s(bM);qCe=n(UUe,"STRONG",{});var JKt=s(qCe);QFr=r(JKt,"fnet"),JKt.forEach(t),WFr=r(UUe," \u2014 "),sK=n(UUe,"A",{href:!0});var YKt=s(sK);UFr=r(YKt,"FNetForQuestionAnswering"),YKt.forEach(t),HFr=r(UUe," (FNet model)"),UUe.forEach(t),JFr=i(X),FM=n(X,"LI",{});var HUe=s(FM);jCe=n(HUe,"STRONG",{});var ZKt=s(jCe);YFr=r(ZKt,"funnel"),ZKt.forEach(t),ZFr=r(HUe," \u2014 "),lK=n(HUe,"A",{href:!0});var KKt=s(lK);KFr=r(KKt,"FunnelForQuestionAnswering"),KKt.forEach(t),eTr=r(HUe," (Funnel Transformer model)"),HUe.forEach(t),oTr=i(X),TM=n(X,"LI",{});var JUe=s(TM);DCe=n(JUe,"STRONG",{});var eea=s(DCe);rTr=r(eea,"gptj"),eea.forEach(t),tTr=r(JUe," \u2014 "),iK=n(JUe,"A",{href:!0});var oea=s(iK);aTr=r(oea,"GPTJForQuestionAnswering"),oea.forEach(t),nTr=r(JUe," (GPT-J model)"),JUe.forEach(t),sTr=i(X),MM=n(X,"LI",{});var YUe=s(MM);GCe=n(YUe,"STRONG",{});var rea=s(GCe);lTr=r(rea,"ibert"),rea.forEach(t),iTr=r(YUe," \u2014 "),dK=n(YUe,"A",{href:!0});var tea=s(dK);dTr=r(tea,"IBertForQuestionAnswering"),tea.forEach(t),cTr=r(YUe," (I-BERT model)"),YUe.forEach(t),fTr=i(X),EM=n(X,"LI",{});var ZUe=s(EM);OCe=n(ZUe,"STRONG",{});var aea=s(OCe);mTr=r(aea,"layoutlmv2"),aea.forEach(t),gTr=r(ZUe," \u2014 "),cK=n(ZUe,"A",{href:!0});var nea=s(cK);hTr=r(nea,"LayoutLMv2ForQuestionAnswering"),nea.forEach(t),uTr=r(ZUe," (LayoutLMv2 model)"),ZUe.forEach(t),pTr=i(X),CM=n(X,"LI",{});var KUe=s(CM);VCe=n(KUe,"STRONG",{});var sea=s(VCe);_Tr=r(sea,"layoutlmv3"),sea.forEach(t),vTr=r(KUe," \u2014 "),fK=n(KUe,"A",{href:!0});var lea=s(fK);bTr=r(lea,"LayoutLMv3ForQuestionAnswering"),lea.forEach(t),FTr=r(KUe," (LayoutLMv3 model)"),KUe.forEach(t),TTr=i(X),wM=n(X,"LI",{});var eHe=s(wM);XCe=n(eHe,"STRONG",{});var iea=s(XCe);MTr=r(iea,"led"),iea.forEach(t),ETr=r(eHe," \u2014 "),mK=n(eHe,"A",{href:!0});var dea=s(mK);CTr=r(dea,"LEDForQuestionAnswering"),dea.forEach(t),wTr=r(eHe," (LED model)"),eHe.forEach(t),ATr=i(X),AM=n(X,"LI",{});var oHe=s(AM);zCe=n(oHe,"STRONG",{});var cea=s(zCe);LTr=r(cea,"lilt"),cea.forEach(t),yTr=r(oHe," \u2014 "),gK=n(oHe,"A",{href:!0});var fea=s(gK);xTr=r(fea,"LiltForQuestionAnswering"),fea.forEach(t),$Tr=r(oHe," (LiLT model)"),oHe.forEach(t),kTr=i(X),LM=n(X,"LI",{});var rHe=s(LM);QCe=n(rHe,"STRONG",{});var mea=s(QCe);STr=r(mea,"longformer"),mea.forEach(t),RTr=r(rHe," \u2014 "),hK=n(rHe,"A",{href:!0});var gea=s(hK);PTr=r(gea,"LongformerForQuestionAnswering"),gea.forEach(t),BTr=r(rHe," (Longformer model)"),rHe.forEach(t),ITr=i(X),yM=n(X,"LI",{});var tHe=s(yM);WCe=n(tHe,"STRONG",{});var hea=s(WCe);NTr=r(hea,"luke"),hea.forEach(t),qTr=r(tHe," \u2014 "),uK=n(tHe,"A",{href:!0});var uea=s(uK);jTr=r(uea,"LukeForQuestionAnswering"),uea.forEach(t),DTr=r(tHe," (LUKE model)"),tHe.forEach(t),GTr=i(X),xM=n(X,"LI",{});var aHe=s(xM);UCe=n(aHe,"STRONG",{});var pea=s(UCe);OTr=r(pea,"lxmert"),pea.forEach(t),VTr=r(aHe," \u2014 "),pK=n(aHe,"A",{href:!0});var _ea=s(pK);XTr=r(_ea,"LxmertForQuestionAnswering"),_ea.forEach(t),zTr=r(aHe," (LXMERT model)"),aHe.forEach(t),QTr=i(X),$M=n(X,"LI",{});var nHe=s($M);HCe=n(nHe,"STRONG",{});var vea=s(HCe);WTr=r(vea,"markuplm"),vea.forEach(t),UTr=r(nHe," \u2014 "),_K=n(nHe,"A",{href:!0});var bea=s(_K);HTr=r(bea,"MarkupLMForQuestionAnswering"),bea.forEach(t),JTr=r(nHe," (MarkupLM model)"),nHe.forEach(t),YTr=i(X),kM=n(X,"LI",{});var sHe=s(kM);JCe=n(sHe,"STRONG",{});var Fea=s(JCe);ZTr=r(Fea,"mbart"),Fea.forEach(t),KTr=r(sHe," \u2014 "),vK=n(sHe,"A",{href:!0});var Tea=s(vK);eMr=r(Tea,"MBartForQuestionAnswering"),Tea.forEach(t),oMr=r(sHe," (mBART model)"),sHe.forEach(t),rMr=i(X),SM=n(X,"LI",{});var lHe=s(SM);YCe=n(lHe,"STRONG",{});var Mea=s(YCe);tMr=r(Mea,"megatron-bert"),Mea.forEach(t),aMr=r(lHe," \u2014 "),bK=n(lHe,"A",{href:!0});var Eea=s(bK);nMr=r(Eea,"MegatronBertForQuestionAnswering"),Eea.forEach(t),sMr=r(lHe," (Megatron-BERT model)"),lHe.forEach(t),lMr=i(X),RM=n(X,"LI",{});var iHe=s(RM);ZCe=n(iHe,"STRONG",{});var Cea=s(ZCe);iMr=r(Cea,"mobilebert"),Cea.forEach(t),dMr=r(iHe," \u2014 "),FK=n(iHe,"A",{href:!0});var wea=s(FK);cMr=r(wea,"MobileBertForQuestionAnswering"),wea.forEach(t),fMr=r(iHe," (MobileBERT model)"),iHe.forEach(t),mMr=i(X),PM=n(X,"LI",{});var dHe=s(PM);KCe=n(dHe,"STRONG",{});var Aea=s(KCe);gMr=r(Aea,"mpnet"),Aea.forEach(t),hMr=r(dHe," \u2014 "),TK=n(dHe,"A",{href:!0});var Lea=s(TK);uMr=r(Lea,"MPNetForQuestionAnswering"),Lea.forEach(t),pMr=r(dHe," (MPNet model)"),dHe.forEach(t),_Mr=i(X),BM=n(X,"LI",{});var cHe=s(BM);e3e=n(cHe,"STRONG",{});var yea=s(e3e);vMr=r(yea,"mvp"),yea.forEach(t),bMr=r(cHe," \u2014 "),MK=n(cHe,"A",{href:!0});var xea=s(MK);FMr=r(xea,"MvpForQuestionAnswering"),xea.forEach(t),TMr=r(cHe," (MVP model)"),cHe.forEach(t),MMr=i(X),IM=n(X,"LI",{});var fHe=s(IM);o3e=n(fHe,"STRONG",{});var $ea=s(o3e);EMr=r($ea,"nezha"),$ea.forEach(t),CMr=r(fHe," \u2014 "),EK=n(fHe,"A",{href:!0});var kea=s(EK);wMr=r(kea,"NezhaForQuestionAnswering"),kea.forEach(t),AMr=r(fHe," (Nezha model)"),fHe.forEach(t),LMr=i(X),NM=n(X,"LI",{});var mHe=s(NM);r3e=n(mHe,"STRONG",{});var Sea=s(r3e);yMr=r(Sea,"nystromformer"),Sea.forEach(t),xMr=r(mHe," \u2014 "),CK=n(mHe,"A",{href:!0});var Rea=s(CK);$Mr=r(Rea,"NystromformerForQuestionAnswering"),Rea.forEach(t),kMr=r(mHe," (Nystr\xF6mformer model)"),mHe.forEach(t),SMr=i(X),qM=n(X,"LI",{});var gHe=s(qM);t3e=n(gHe,"STRONG",{});var Pea=s(t3e);RMr=r(Pea,"opt"),Pea.forEach(t),PMr=r(gHe," \u2014 "),wK=n(gHe,"A",{href:!0});var Bea=s(wK);BMr=r(Bea,"OPTForQuestionAnswering"),Bea.forEach(t),IMr=r(gHe," (OPT model)"),gHe.forEach(t),NMr=i(X),jM=n(X,"LI",{});var hHe=s(jM);a3e=n(hHe,"STRONG",{});var Iea=s(a3e);qMr=r(Iea,"qdqbert"),Iea.forEach(t),jMr=r(hHe," \u2014 "),AK=n(hHe,"A",{href:!0});var Nea=s(AK);DMr=r(Nea,"QDQBertForQuestionAnswering"),Nea.forEach(t),GMr=r(hHe," (QDQBert model)"),hHe.forEach(t),OMr=i(X),DM=n(X,"LI",{});var uHe=s(DM);n3e=n(uHe,"STRONG",{});var qea=s(n3e);VMr=r(qea,"reformer"),qea.forEach(t),XMr=r(uHe," \u2014 "),LK=n(uHe,"A",{href:!0});var jea=s(LK);zMr=r(jea,"ReformerForQuestionAnswering"),jea.forEach(t),QMr=r(uHe," (Reformer model)"),uHe.forEach(t),WMr=i(X),GM=n(X,"LI",{});var pHe=s(GM);s3e=n(pHe,"STRONG",{});var Dea=s(s3e);UMr=r(Dea,"rembert"),Dea.forEach(t),HMr=r(pHe," \u2014 "),yK=n(pHe,"A",{href:!0});var Gea=s(yK);JMr=r(Gea,"RemBertForQuestionAnswering"),Gea.forEach(t),YMr=r(pHe," (RemBERT model)"),pHe.forEach(t),ZMr=i(X),OM=n(X,"LI",{});var _He=s(OM);l3e=n(_He,"STRONG",{});var Oea=s(l3e);KMr=r(Oea,"roberta"),Oea.forEach(t),eEr=r(_He," \u2014 "),xK=n(_He,"A",{href:!0});var Vea=s(xK);oEr=r(Vea,"RobertaForQuestionAnswering"),Vea.forEach(t),rEr=r(_He," (RoBERTa model)"),_He.forEach(t),tEr=i(X),VM=n(X,"LI",{});var vHe=s(VM);i3e=n(vHe,"STRONG",{});var Xea=s(i3e);aEr=r(Xea,"roformer"),Xea.forEach(t),nEr=r(vHe," \u2014 "),$K=n(vHe,"A",{href:!0});var zea=s($K);sEr=r(zea,"RoFormerForQuestionAnswering"),zea.forEach(t),lEr=r(vHe," (RoFormer model)"),vHe.forEach(t),iEr=i(X),XM=n(X,"LI",{});var bHe=s(XM);d3e=n(bHe,"STRONG",{});var Qea=s(d3e);dEr=r(Qea,"splinter"),Qea.forEach(t),cEr=r(bHe," \u2014 "),kK=n(bHe,"A",{href:!0});var Wea=s(kK);fEr=r(Wea,"SplinterForQuestionAnswering"),Wea.forEach(t),mEr=r(bHe," (Splinter model)"),bHe.forEach(t),gEr=i(X),zM=n(X,"LI",{});var FHe=s(zM);c3e=n(FHe,"STRONG",{});var Uea=s(c3e);hEr=r(Uea,"squeezebert"),Uea.forEach(t),uEr=r(FHe," \u2014 "),SK=n(FHe,"A",{href:!0});var Hea=s(SK);pEr=r(Hea,"SqueezeBertForQuestionAnswering"),Hea.forEach(t),_Er=r(FHe," (SqueezeBERT model)"),FHe.forEach(t),vEr=i(X),QM=n(X,"LI",{});var THe=s(QM);f3e=n(THe,"STRONG",{});var Jea=s(f3e);bEr=r(Jea,"xlm"),Jea.forEach(t),FEr=r(THe," \u2014 "),RK=n(THe,"A",{href:!0});var Yea=s(RK);TEr=r(Yea,"XLMForQuestionAnsweringSimple"),Yea.forEach(t),MEr=r(THe," (XLM model)"),THe.forEach(t),EEr=i(X),WM=n(X,"LI",{});var MHe=s(WM);m3e=n(MHe,"STRONG",{});var Zea=s(m3e);CEr=r(Zea,"xlm-roberta"),Zea.forEach(t),wEr=r(MHe," \u2014 "),PK=n(MHe,"A",{href:!0});var Kea=s(PK);AEr=r(Kea,"XLMRobertaForQuestionAnswering"),Kea.forEach(t),LEr=r(MHe," (XLM-RoBERTa model)"),MHe.forEach(t),yEr=i(X),UM=n(X,"LI",{});var EHe=s(UM);g3e=n(EHe,"STRONG",{});var eoa=s(g3e);xEr=r(eoa,"xlm-roberta-xl"),eoa.forEach(t),$Er=r(EHe," \u2014 "),BK=n(EHe,"A",{href:!0});var ooa=s(BK);kEr=r(ooa,"XLMRobertaXLForQuestionAnswering"),ooa.forEach(t),SEr=r(EHe," (XLM-RoBERTa-XL model)"),EHe.forEach(t),REr=i(X),HM=n(X,"LI",{});var CHe=s(HM);h3e=n(CHe,"STRONG",{});var roa=s(h3e);PEr=r(roa,"xlnet"),roa.forEach(t),BEr=r(CHe," \u2014 "),IK=n(CHe,"A",{href:!0});var toa=s(IK);IEr=r(toa,"XLNetForQuestionAnsweringSimple"),toa.forEach(t),NEr=r(CHe," (XLNet model)"),CHe.forEach(t),qEr=i(X),JM=n(X,"LI",{});var wHe=s(JM);u3e=n(wHe,"STRONG",{});var aoa=s(u3e);jEr=r(aoa,"yoso"),aoa.forEach(t),DEr=r(wHe," \u2014 "),NK=n(wHe,"A",{href:!0});var noa=s(NK);GEr=r(noa,"YosoForQuestionAnswering"),noa.forEach(t),OEr=r(wHe," (YOSO model)"),wHe.forEach(t),X.forEach(t),VEr=i(Na),YM=n(Na,"P",{});var AHe=s(YM);XEr=r(AHe,"The model is set in evaluation mode by default using "),p3e=n(AHe,"CODE",{});var soa=s(p3e);zEr=r(soa,"model.eval()"),soa.forEach(t),QEr=r(AHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_3e=n(AHe,"CODE",{});var loa=s(_3e);WEr=r(loa,"model.train()"),loa.forEach(t),AHe.forEach(t),UEr=i(Na),T(ZM.$$.fragment,Na),Na.forEach(t),Ul.forEach(t),sao=i(f),fc=n(f,"H2",{class:!0});var wso=s(fc);KM=n(wso,"A",{id:!0,class:!0,href:!0});var ioa=s(KM);v3e=n(ioa,"SPAN",{});var doa=s(v3e);T(Nk.$$.fragment,doa),doa.forEach(t),ioa.forEach(t),HEr=i(wso),b3e=n(wso,"SPAN",{});var coa=s(b3e);JEr=r(coa,"AutoModelForTableQuestionAnswering"),coa.forEach(t),wso.forEach(t),lao=i(f),Wo=n(f,"DIV",{class:!0});var Hl=s(Wo);T(qk.$$.fragment,Hl),YEr=i(Hl),mc=n(Hl,"P",{});var Ace=s(mc);ZEr=r(Ace,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),qK=n(Ace,"A",{href:!0});var foa=s(qK);KEr=r(foa,"from_pretrained()"),foa.forEach(t),eCr=r(Ace," class method or the "),jK=n(Ace,"A",{href:!0});var moa=s(jK);oCr=r(moa,"from_config()"),moa.forEach(t),rCr=r(Ace,` class
method.`),Ace.forEach(t),tCr=i(Hl),jk=n(Hl,"P",{});var Aso=s(jk);aCr=r(Aso,"This class cannot be instantiated directly using "),F3e=n(Aso,"CODE",{});var goa=s(F3e);nCr=r(goa,"__init__()"),goa.forEach(t),sCr=r(Aso," (throws an error)."),Aso.forEach(t),lCr=i(Hl),Rt=n(Hl,"DIV",{class:!0});var M9=s(Rt);T(Dk.$$.fragment,M9),iCr=i(M9),T3e=n(M9,"P",{});var hoa=s(T3e);dCr=r(hoa,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),hoa.forEach(t),cCr=i(M9),gc=n(M9,"P",{});var Lce=s(gc);fCr=r(Lce,`Note:
Loading a model from its configuration file does `),M3e=n(Lce,"STRONG",{});var uoa=s(M3e);mCr=r(uoa,"not"),uoa.forEach(t),gCr=r(Lce,` load the model weights. It only affects the
model\u2019s configuration. Use `),DK=n(Lce,"A",{href:!0});var poa=s(DK);hCr=r(poa,"from_pretrained()"),poa.forEach(t),uCr=r(Lce," to load the model weights."),Lce.forEach(t),pCr=i(M9),T(eE.$$.fragment,M9),M9.forEach(t),_Cr=i(Hl),fo=n(Hl,"DIV",{class:!0});var qa=s(fo);T(Gk.$$.fragment,qa),vCr=i(qa),E3e=n(qa,"P",{});var _oa=s(E3e);bCr=r(_oa,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),_oa.forEach(t),FCr=i(qa),_n=n(qa,"P",{});var E9=s(_n);TCr=r(E9,"The model class to instantiate is selected based on the "),C3e=n(E9,"CODE",{});var voa=s(C3e);MCr=r(voa,"model_type"),voa.forEach(t),ECr=r(E9,` property of the config object (either
passed as an argument or loaded from `),w3e=n(E9,"CODE",{});var boa=s(w3e);CCr=r(boa,"pretrained_model_name_or_path"),boa.forEach(t),wCr=r(E9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A3e=n(E9,"CODE",{});var Foa=s(A3e);ACr=r(Foa,"pretrained_model_name_or_path"),Foa.forEach(t),LCr=r(E9,":"),E9.forEach(t),yCr=i(qa),L3e=n(qa,"UL",{});var Toa=s(L3e);oE=n(Toa,"LI",{});var LHe=s(oE);y3e=n(LHe,"STRONG",{});var Moa=s(y3e);xCr=r(Moa,"tapas"),Moa.forEach(t),$Cr=r(LHe," \u2014 "),GK=n(LHe,"A",{href:!0});var Eoa=s(GK);kCr=r(Eoa,"TapasForQuestionAnswering"),Eoa.forEach(t),SCr=r(LHe," (TAPAS model)"),LHe.forEach(t),Toa.forEach(t),RCr=i(qa),rE=n(qa,"P",{});var yHe=s(rE);PCr=r(yHe,"The model is set in evaluation mode by default using "),x3e=n(yHe,"CODE",{});var Coa=s(x3e);BCr=r(Coa,"model.eval()"),Coa.forEach(t),ICr=r(yHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$3e=n(yHe,"CODE",{});var woa=s($3e);NCr=r(woa,"model.train()"),woa.forEach(t),yHe.forEach(t),qCr=i(qa),T(tE.$$.fragment,qa),qa.forEach(t),Hl.forEach(t),iao=i(f),hc=n(f,"H2",{class:!0});var Lso=s(hc);aE=n(Lso,"A",{id:!0,class:!0,href:!0});var Aoa=s(aE);k3e=n(Aoa,"SPAN",{});var Loa=s(k3e);T(Ok.$$.fragment,Loa),Loa.forEach(t),Aoa.forEach(t),jCr=i(Lso),S3e=n(Lso,"SPAN",{});var yoa=s(S3e);DCr=r(yoa,"AutoModelForDocumentQuestionAnswering"),yoa.forEach(t),Lso.forEach(t),dao=i(f),Uo=n(f,"DIV",{class:!0});var Jl=s(Uo);T(Vk.$$.fragment,Jl),GCr=i(Jl),uc=n(Jl,"P",{});var yce=s(uc);OCr=r(yce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),OK=n(yce,"A",{href:!0});var xoa=s(OK);VCr=r(xoa,"from_pretrained()"),xoa.forEach(t),XCr=r(yce," class method or the "),VK=n(yce,"A",{href:!0});var $oa=s(VK);zCr=r($oa,"from_config()"),$oa.forEach(t),QCr=r(yce,` class
method.`),yce.forEach(t),WCr=i(Jl),Xk=n(Jl,"P",{});var yso=s(Xk);UCr=r(yso,"This class cannot be instantiated directly using "),R3e=n(yso,"CODE",{});var koa=s(R3e);HCr=r(koa,"__init__()"),koa.forEach(t),JCr=r(yso," (throws an error)."),yso.forEach(t),YCr=i(Jl),Pt=n(Jl,"DIV",{class:!0});var C9=s(Pt);T(zk.$$.fragment,C9),ZCr=i(C9),P3e=n(C9,"P",{});var Soa=s(P3e);KCr=r(Soa,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Soa.forEach(t),e3r=i(C9),pc=n(C9,"P",{});var xce=s(pc);o3r=r(xce,`Note:
Loading a model from its configuration file does `),B3e=n(xce,"STRONG",{});var Roa=s(B3e);r3r=r(Roa,"not"),Roa.forEach(t),t3r=r(xce,` load the model weights. It only affects the
model\u2019s configuration. Use `),XK=n(xce,"A",{href:!0});var Poa=s(XK);a3r=r(Poa,"from_pretrained()"),Poa.forEach(t),n3r=r(xce," to load the model weights."),xce.forEach(t),s3r=i(C9),T(nE.$$.fragment,C9),C9.forEach(t),l3r=i(Jl),mo=n(Jl,"DIV",{class:!0});var ja=s(mo);T(Qk.$$.fragment,ja),i3r=i(ja),I3e=n(ja,"P",{});var Boa=s(I3e);d3r=r(Boa,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),Boa.forEach(t),c3r=i(ja),vn=n(ja,"P",{});var w9=s(vn);f3r=r(w9,"The model class to instantiate is selected based on the "),N3e=n(w9,"CODE",{});var Ioa=s(N3e);m3r=r(Ioa,"model_type"),Ioa.forEach(t),g3r=r(w9,` property of the config object (either
passed as an argument or loaded from `),q3e=n(w9,"CODE",{});var Noa=s(q3e);h3r=r(Noa,"pretrained_model_name_or_path"),Noa.forEach(t),u3r=r(w9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j3e=n(w9,"CODE",{});var qoa=s(j3e);p3r=r(qoa,"pretrained_model_name_or_path"),qoa.forEach(t),_3r=r(w9,":"),w9.forEach(t),v3r=i(ja),_c=n(ja,"UL",{});var $ce=s(_c);sE=n($ce,"LI",{});var xHe=s(sE);D3e=n(xHe,"STRONG",{});var joa=s(D3e);b3r=r(joa,"layoutlm"),joa.forEach(t),F3r=r(xHe," \u2014 "),zK=n(xHe,"A",{href:!0});var Doa=s(zK);T3r=r(Doa,"LayoutLMForQuestionAnswering"),Doa.forEach(t),M3r=r(xHe," (LayoutLM model)"),xHe.forEach(t),E3r=i($ce),lE=n($ce,"LI",{});var $He=s(lE);G3e=n($He,"STRONG",{});var Goa=s(G3e);C3r=r(Goa,"layoutlmv2"),Goa.forEach(t),w3r=r($He," \u2014 "),QK=n($He,"A",{href:!0});var Ooa=s(QK);A3r=r(Ooa,"LayoutLMv2ForQuestionAnswering"),Ooa.forEach(t),L3r=r($He," (LayoutLMv2 model)"),$He.forEach(t),y3r=i($ce),iE=n($ce,"LI",{});var kHe=s(iE);O3e=n(kHe,"STRONG",{});var Voa=s(O3e);x3r=r(Voa,"layoutlmv3"),Voa.forEach(t),$3r=r(kHe," \u2014 "),WK=n(kHe,"A",{href:!0});var Xoa=s(WK);k3r=r(Xoa,"LayoutLMv3ForQuestionAnswering"),Xoa.forEach(t),S3r=r(kHe," (LayoutLMv3 model)"),kHe.forEach(t),$ce.forEach(t),R3r=i(ja),dE=n(ja,"P",{});var SHe=s(dE);P3r=r(SHe,"The model is set in evaluation mode by default using "),V3e=n(SHe,"CODE",{});var zoa=s(V3e);B3r=r(zoa,"model.eval()"),zoa.forEach(t),I3r=r(SHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),X3e=n(SHe,"CODE",{});var Qoa=s(X3e);N3r=r(Qoa,"model.train()"),Qoa.forEach(t),SHe.forEach(t),q3r=i(ja),T(cE.$$.fragment,ja),ja.forEach(t),Jl.forEach(t),cao=i(f),vc=n(f,"H2",{class:!0});var xso=s(vc);fE=n(xso,"A",{id:!0,class:!0,href:!0});var Woa=s(fE);z3e=n(Woa,"SPAN",{});var Uoa=s(z3e);T(Wk.$$.fragment,Uoa),Uoa.forEach(t),Woa.forEach(t),j3r=i(xso),Q3e=n(xso,"SPAN",{});var Hoa=s(Q3e);D3r=r(Hoa,"AutoModelForImageClassification"),Hoa.forEach(t),xso.forEach(t),fao=i(f),Ho=n(f,"DIV",{class:!0});var Yl=s(Ho);T(Uk.$$.fragment,Yl),G3r=i(Yl),bc=n(Yl,"P",{});var kce=s(bc);O3r=r(kce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),UK=n(kce,"A",{href:!0});var Joa=s(UK);V3r=r(Joa,"from_pretrained()"),Joa.forEach(t),X3r=r(kce," class method or the "),HK=n(kce,"A",{href:!0});var Yoa=s(HK);z3r=r(Yoa,"from_config()"),Yoa.forEach(t),Q3r=r(kce,` class
method.`),kce.forEach(t),W3r=i(Yl),Hk=n(Yl,"P",{});var $so=s(Hk);U3r=r($so,"This class cannot be instantiated directly using "),W3e=n($so,"CODE",{});var Zoa=s(W3e);H3r=r(Zoa,"__init__()"),Zoa.forEach(t),J3r=r($so," (throws an error)."),$so.forEach(t),Y3r=i(Yl),Bt=n(Yl,"DIV",{class:!0});var A9=s(Bt);T(Jk.$$.fragment,A9),Z3r=i(A9),U3e=n(A9,"P",{});var Koa=s(U3e);K3r=r(Koa,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Koa.forEach(t),e5r=i(A9),Fc=n(A9,"P",{});var Sce=s(Fc);o5r=r(Sce,`Note:
Loading a model from its configuration file does `),H3e=n(Sce,"STRONG",{});var era=s(H3e);r5r=r(era,"not"),era.forEach(t),t5r=r(Sce,` load the model weights. It only affects the
model\u2019s configuration. Use `),JK=n(Sce,"A",{href:!0});var ora=s(JK);a5r=r(ora,"from_pretrained()"),ora.forEach(t),n5r=r(Sce," to load the model weights."),Sce.forEach(t),s5r=i(A9),T(mE.$$.fragment,A9),A9.forEach(t),l5r=i(Yl),go=n(Yl,"DIV",{class:!0});var Da=s(go);T(Yk.$$.fragment,Da),i5r=i(Da),J3e=n(Da,"P",{});var rra=s(J3e);d5r=r(rra,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),rra.forEach(t),c5r=i(Da),bn=n(Da,"P",{});var L9=s(bn);f5r=r(L9,"The model class to instantiate is selected based on the "),Y3e=n(L9,"CODE",{});var tra=s(Y3e);m5r=r(tra,"model_type"),tra.forEach(t),g5r=r(L9,` property of the config object (either
passed as an argument or loaded from `),Z3e=n(L9,"CODE",{});var ara=s(Z3e);h5r=r(ara,"pretrained_model_name_or_path"),ara.forEach(t),u5r=r(L9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K3e=n(L9,"CODE",{});var nra=s(K3e);p5r=r(nra,"pretrained_model_name_or_path"),nra.forEach(t),_5r=r(L9,":"),L9.forEach(t),v5r=i(Da),ve=n(Da,"UL",{});var Fe=s(ve);gE=n(Fe,"LI",{});var RHe=s(gE);e5e=n(RHe,"STRONG",{});var sra=s(e5e);b5r=r(sra,"beit"),sra.forEach(t),F5r=r(RHe," \u2014 "),YK=n(RHe,"A",{href:!0});var lra=s(YK);T5r=r(lra,"BeitForImageClassification"),lra.forEach(t),M5r=r(RHe," (BEiT model)"),RHe.forEach(t),E5r=i(Fe),hE=n(Fe,"LI",{});var PHe=s(hE);o5e=n(PHe,"STRONG",{});var ira=s(o5e);C5r=r(ira,"convnext"),ira.forEach(t),w5r=r(PHe," \u2014 "),ZK=n(PHe,"A",{href:!0});var dra=s(ZK);A5r=r(dra,"ConvNextForImageClassification"),dra.forEach(t),L5r=r(PHe," (ConvNeXT model)"),PHe.forEach(t),y5r=i(Fe),uE=n(Fe,"LI",{});var BHe=s(uE);r5e=n(BHe,"STRONG",{});var cra=s(r5e);x5r=r(cra,"cvt"),cra.forEach(t),$5r=r(BHe," \u2014 "),KK=n(BHe,"A",{href:!0});var fra=s(KK);k5r=r(fra,"CvtForImageClassification"),fra.forEach(t),S5r=r(BHe," (CvT model)"),BHe.forEach(t),R5r=i(Fe),pE=n(Fe,"LI",{});var IHe=s(pE);t5e=n(IHe,"STRONG",{});var mra=s(t5e);P5r=r(mra,"data2vec-vision"),mra.forEach(t),B5r=r(IHe," \u2014 "),eee=n(IHe,"A",{href:!0});var gra=s(eee);I5r=r(gra,"Data2VecVisionForImageClassification"),gra.forEach(t),N5r=r(IHe," (Data2VecVision model)"),IHe.forEach(t),q5r=i(Fe),$l=n(Fe,"LI",{});var vN=s($l);a5e=n(vN,"STRONG",{});var hra=s(a5e);j5r=r(hra,"deit"),hra.forEach(t),D5r=r(vN," \u2014 "),oee=n(vN,"A",{href:!0});var ura=s(oee);G5r=r(ura,"DeiTForImageClassification"),ura.forEach(t),O5r=r(vN," or "),ree=n(vN,"A",{href:!0});var pra=s(ree);V5r=r(pra,"DeiTForImageClassificationWithTeacher"),pra.forEach(t),X5r=r(vN," (DeiT model)"),vN.forEach(t),z5r=i(Fe),_E=n(Fe,"LI",{});var NHe=s(_E);n5e=n(NHe,"STRONG",{});var _ra=s(n5e);Q5r=r(_ra,"imagegpt"),_ra.forEach(t),W5r=r(NHe," \u2014 "),tee=n(NHe,"A",{href:!0});var vra=s(tee);U5r=r(vra,"ImageGPTForImageClassification"),vra.forEach(t),H5r=r(NHe," (ImageGPT model)"),NHe.forEach(t),J5r=i(Fe),kl=n(Fe,"LI",{});var bN=s(kl);s5e=n(bN,"STRONG",{});var bra=s(s5e);Y5r=r(bra,"levit"),bra.forEach(t),Z5r=r(bN," \u2014 "),aee=n(bN,"A",{href:!0});var Fra=s(aee);K5r=r(Fra,"LevitForImageClassification"),Fra.forEach(t),ewr=r(bN," or "),nee=n(bN,"A",{href:!0});var Tra=s(nee);owr=r(Tra,"LevitForImageClassificationWithTeacher"),Tra.forEach(t),rwr=r(bN," (LeViT model)"),bN.forEach(t),twr=i(Fe),vE=n(Fe,"LI",{});var qHe=s(vE);l5e=n(qHe,"STRONG",{});var Mra=s(l5e);awr=r(Mra,"mobilevit"),Mra.forEach(t),nwr=r(qHe," \u2014 "),see=n(qHe,"A",{href:!0});var Era=s(see);swr=r(Era,"MobileViTForImageClassification"),Era.forEach(t),lwr=r(qHe," (MobileViT model)"),qHe.forEach(t),iwr=i(Fe),It=n(Fe,"LI",{});var Xm=s(It);i5e=n(Xm,"STRONG",{});var Cra=s(i5e);dwr=r(Cra,"perceiver"),Cra.forEach(t),cwr=r(Xm," \u2014 "),lee=n(Xm,"A",{href:!0});var wra=s(lee);fwr=r(wra,"PerceiverForImageClassificationLearned"),wra.forEach(t),mwr=r(Xm," or "),iee=n(Xm,"A",{href:!0});var Ara=s(iee);gwr=r(Ara,"PerceiverForImageClassificationFourier"),Ara.forEach(t),hwr=r(Xm," or "),dee=n(Xm,"A",{href:!0});var Lra=s(dee);uwr=r(Lra,"PerceiverForImageClassificationConvProcessing"),Lra.forEach(t),pwr=r(Xm," (Perceiver model)"),Xm.forEach(t),_wr=i(Fe),bE=n(Fe,"LI",{});var jHe=s(bE);d5e=n(jHe,"STRONG",{});var yra=s(d5e);vwr=r(yra,"poolformer"),yra.forEach(t),bwr=r(jHe," \u2014 "),cee=n(jHe,"A",{href:!0});var xra=s(cee);Fwr=r(xra,"PoolFormerForImageClassification"),xra.forEach(t),Twr=r(jHe," (PoolFormer model)"),jHe.forEach(t),Mwr=i(Fe),FE=n(Fe,"LI",{});var DHe=s(FE);c5e=n(DHe,"STRONG",{});var $ra=s(c5e);Ewr=r($ra,"regnet"),$ra.forEach(t),Cwr=r(DHe," \u2014 "),fee=n(DHe,"A",{href:!0});var kra=s(fee);wwr=r(kra,"RegNetForImageClassification"),kra.forEach(t),Awr=r(DHe," (RegNet model)"),DHe.forEach(t),Lwr=i(Fe),TE=n(Fe,"LI",{});var GHe=s(TE);f5e=n(GHe,"STRONG",{});var Sra=s(f5e);ywr=r(Sra,"resnet"),Sra.forEach(t),xwr=r(GHe," \u2014 "),mee=n(GHe,"A",{href:!0});var Rra=s(mee);$wr=r(Rra,"ResNetForImageClassification"),Rra.forEach(t),kwr=r(GHe," (ResNet model)"),GHe.forEach(t),Swr=i(Fe),ME=n(Fe,"LI",{});var OHe=s(ME);m5e=n(OHe,"STRONG",{});var Pra=s(m5e);Rwr=r(Pra,"segformer"),Pra.forEach(t),Pwr=r(OHe," \u2014 "),gee=n(OHe,"A",{href:!0});var Bra=s(gee);Bwr=r(Bra,"SegformerForImageClassification"),Bra.forEach(t),Iwr=r(OHe," (SegFormer model)"),OHe.forEach(t),Nwr=i(Fe),EE=n(Fe,"LI",{});var VHe=s(EE);g5e=n(VHe,"STRONG",{});var Ira=s(g5e);qwr=r(Ira,"swin"),Ira.forEach(t),jwr=r(VHe," \u2014 "),hee=n(VHe,"A",{href:!0});var Nra=s(hee);Dwr=r(Nra,"SwinForImageClassification"),Nra.forEach(t),Gwr=r(VHe," (Swin Transformer model)"),VHe.forEach(t),Owr=i(Fe),CE=n(Fe,"LI",{});var XHe=s(CE);h5e=n(XHe,"STRONG",{});var qra=s(h5e);Vwr=r(qra,"swinv2"),qra.forEach(t),Xwr=r(XHe," \u2014 "),uee=n(XHe,"A",{href:!0});var jra=s(uee);zwr=r(jra,"Swinv2ForImageClassification"),jra.forEach(t),Qwr=r(XHe," (Swin Transformer V2 model)"),XHe.forEach(t),Wwr=i(Fe),wE=n(Fe,"LI",{});var zHe=s(wE);u5e=n(zHe,"STRONG",{});var Dra=s(u5e);Uwr=r(Dra,"van"),Dra.forEach(t),Hwr=r(zHe," \u2014 "),pee=n(zHe,"A",{href:!0});var Gra=s(pee);Jwr=r(Gra,"VanForImageClassification"),Gra.forEach(t),Ywr=r(zHe," (VAN model)"),zHe.forEach(t),Zwr=i(Fe),AE=n(Fe,"LI",{});var QHe=s(AE);p5e=n(QHe,"STRONG",{});var Ora=s(p5e);Kwr=r(Ora,"vit"),Ora.forEach(t),eAr=r(QHe," \u2014 "),_ee=n(QHe,"A",{href:!0});var Vra=s(_ee);oAr=r(Vra,"ViTForImageClassification"),Vra.forEach(t),rAr=r(QHe," (ViT model)"),QHe.forEach(t),tAr=i(Fe),LE=n(Fe,"LI",{});var WHe=s(LE);_5e=n(WHe,"STRONG",{});var Xra=s(_5e);aAr=r(Xra,"vit_msn"),Xra.forEach(t),nAr=r(WHe," \u2014 "),vee=n(WHe,"A",{href:!0});var zra=s(vee);sAr=r(zra,"ViTMSNForImageClassification"),zra.forEach(t),lAr=r(WHe," (ViTMSN model)"),WHe.forEach(t),Fe.forEach(t),iAr=i(Da),yE=n(Da,"P",{});var UHe=s(yE);dAr=r(UHe,"The model is set in evaluation mode by default using "),v5e=n(UHe,"CODE",{});var Qra=s(v5e);cAr=r(Qra,"model.eval()"),Qra.forEach(t),fAr=r(UHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b5e=n(UHe,"CODE",{});var Wra=s(b5e);mAr=r(Wra,"model.train()"),Wra.forEach(t),UHe.forEach(t),gAr=i(Da),T(xE.$$.fragment,Da),Da.forEach(t),Yl.forEach(t),mao=i(f),Tc=n(f,"H2",{class:!0});var kso=s(Tc);$E=n(kso,"A",{id:!0,class:!0,href:!0});var Ura=s($E);F5e=n(Ura,"SPAN",{});var Hra=s(F5e);T(Zk.$$.fragment,Hra),Hra.forEach(t),Ura.forEach(t),hAr=i(kso),T5e=n(kso,"SPAN",{});var Jra=s(T5e);uAr=r(Jra,"AutoModelForVideoClassification"),Jra.forEach(t),kso.forEach(t),gao=i(f),Jo=n(f,"DIV",{class:!0});var Zl=s(Jo);T(Kk.$$.fragment,Zl),pAr=i(Zl),Mc=n(Zl,"P",{});var Rce=s(Mc);_Ar=r(Rce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),bee=n(Rce,"A",{href:!0});var Yra=s(bee);vAr=r(Yra,"from_pretrained()"),Yra.forEach(t),bAr=r(Rce," class method or the "),Fee=n(Rce,"A",{href:!0});var Zra=s(Fee);FAr=r(Zra,"from_config()"),Zra.forEach(t),TAr=r(Rce,` class
method.`),Rce.forEach(t),MAr=i(Zl),eS=n(Zl,"P",{});var Sso=s(eS);EAr=r(Sso,"This class cannot be instantiated directly using "),M5e=n(Sso,"CODE",{});var Kra=s(M5e);CAr=r(Kra,"__init__()"),Kra.forEach(t),wAr=r(Sso," (throws an error)."),Sso.forEach(t),AAr=i(Zl),Nt=n(Zl,"DIV",{class:!0});var y9=s(Nt);T(oS.$$.fragment,y9),LAr=i(y9),E5e=n(y9,"P",{});var eta=s(E5e);yAr=r(eta,"Instantiates one of the model classes of the library (with a video classification head) from a configuration."),eta.forEach(t),xAr=i(y9),Ec=n(y9,"P",{});var Pce=s(Ec);$Ar=r(Pce,`Note:
Loading a model from its configuration file does `),C5e=n(Pce,"STRONG",{});var ota=s(C5e);kAr=r(ota,"not"),ota.forEach(t),SAr=r(Pce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Tee=n(Pce,"A",{href:!0});var rta=s(Tee);RAr=r(rta,"from_pretrained()"),rta.forEach(t),PAr=r(Pce," to load the model weights."),Pce.forEach(t),BAr=i(y9),T(kE.$$.fragment,y9),y9.forEach(t),IAr=i(Zl),ho=n(Zl,"DIV",{class:!0});var Ga=s(ho);T(rS.$$.fragment,Ga),NAr=i(Ga),w5e=n(Ga,"P",{});var tta=s(w5e);qAr=r(tta,"Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),tta.forEach(t),jAr=i(Ga),Fn=n(Ga,"P",{});var x9=s(Fn);DAr=r(x9,"The model class to instantiate is selected based on the "),A5e=n(x9,"CODE",{});var ata=s(A5e);GAr=r(ata,"model_type"),ata.forEach(t),OAr=r(x9,` property of the config object (either
passed as an argument or loaded from `),L5e=n(x9,"CODE",{});var nta=s(L5e);VAr=r(nta,"pretrained_model_name_or_path"),nta.forEach(t),XAr=r(x9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y5e=n(x9,"CODE",{});var sta=s(y5e);zAr=r(sta,"pretrained_model_name_or_path"),sta.forEach(t),QAr=r(x9,":"),x9.forEach(t),WAr=i(Ga),x5e=n(Ga,"UL",{});var lta=s(x5e);SE=n(lta,"LI",{});var HHe=s(SE);$5e=n(HHe,"STRONG",{});var ita=s($5e);UAr=r(ita,"videomae"),ita.forEach(t),HAr=r(HHe," \u2014 "),Mee=n(HHe,"A",{href:!0});var dta=s(Mee);JAr=r(dta,"VideoMAEForVideoClassification"),dta.forEach(t),YAr=r(HHe," (VideoMAE model)"),HHe.forEach(t),lta.forEach(t),ZAr=i(Ga),RE=n(Ga,"P",{});var JHe=s(RE);KAr=r(JHe,"The model is set in evaluation mode by default using "),k5e=n(JHe,"CODE",{});var cta=s(k5e);e6r=r(cta,"model.eval()"),cta.forEach(t),o6r=r(JHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),S5e=n(JHe,"CODE",{});var fta=s(S5e);r6r=r(fta,"model.train()"),fta.forEach(t),JHe.forEach(t),t6r=i(Ga),T(PE.$$.fragment,Ga),Ga.forEach(t),Zl.forEach(t),hao=i(f),Cc=n(f,"H2",{class:!0});var Rso=s(Cc);BE=n(Rso,"A",{id:!0,class:!0,href:!0});var mta=s(BE);R5e=n(mta,"SPAN",{});var gta=s(R5e);T(tS.$$.fragment,gta),gta.forEach(t),mta.forEach(t),a6r=i(Rso),P5e=n(Rso,"SPAN",{});var hta=s(P5e);n6r=r(hta,"AutoModelForVision2Seq"),hta.forEach(t),Rso.forEach(t),uao=i(f),Yo=n(f,"DIV",{class:!0});var Kl=s(Yo);T(aS.$$.fragment,Kl),s6r=i(Kl),wc=n(Kl,"P",{});var Bce=s(wc);l6r=r(Bce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Eee=n(Bce,"A",{href:!0});var uta=s(Eee);i6r=r(uta,"from_pretrained()"),uta.forEach(t),d6r=r(Bce," class method or the "),Cee=n(Bce,"A",{href:!0});var pta=s(Cee);c6r=r(pta,"from_config()"),pta.forEach(t),f6r=r(Bce,` class
method.`),Bce.forEach(t),m6r=i(Kl),nS=n(Kl,"P",{});var Pso=s(nS);g6r=r(Pso,"This class cannot be instantiated directly using "),B5e=n(Pso,"CODE",{});var _ta=s(B5e);h6r=r(_ta,"__init__()"),_ta.forEach(t),u6r=r(Pso," (throws an error)."),Pso.forEach(t),p6r=i(Kl),qt=n(Kl,"DIV",{class:!0});var $9=s(qt);T(sS.$$.fragment,$9),_6r=i($9),I5e=n($9,"P",{});var vta=s(I5e);v6r=r(vta,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),vta.forEach(t),b6r=i($9),Ac=n($9,"P",{});var Ice=s(Ac);F6r=r(Ice,`Note:
Loading a model from its configuration file does `),N5e=n(Ice,"STRONG",{});var bta=s(N5e);T6r=r(bta,"not"),bta.forEach(t),M6r=r(Ice,` load the model weights. It only affects the
model\u2019s configuration. Use `),wee=n(Ice,"A",{href:!0});var Fta=s(wee);E6r=r(Fta,"from_pretrained()"),Fta.forEach(t),C6r=r(Ice," to load the model weights."),Ice.forEach(t),w6r=i($9),T(IE.$$.fragment,$9),$9.forEach(t),A6r=i(Kl),uo=n(Kl,"DIV",{class:!0});var Oa=s(uo);T(lS.$$.fragment,Oa),L6r=i(Oa),q5e=n(Oa,"P",{});var Tta=s(q5e);y6r=r(Tta,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Tta.forEach(t),x6r=i(Oa),Tn=n(Oa,"P",{});var k9=s(Tn);$6r=r(k9,"The model class to instantiate is selected based on the "),j5e=n(k9,"CODE",{});var Mta=s(j5e);k6r=r(Mta,"model_type"),Mta.forEach(t),S6r=r(k9,` property of the config object (either
passed as an argument or loaded from `),D5e=n(k9,"CODE",{});var Eta=s(D5e);R6r=r(Eta,"pretrained_model_name_or_path"),Eta.forEach(t),P6r=r(k9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G5e=n(k9,"CODE",{});var Cta=s(G5e);B6r=r(Cta,"pretrained_model_name_or_path"),Cta.forEach(t),I6r=r(k9,":"),k9.forEach(t),N6r=i(Oa),O5e=n(Oa,"UL",{});var wta=s(O5e);NE=n(wta,"LI",{});var YHe=s(NE);V5e=n(YHe,"STRONG",{});var Ata=s(V5e);q6r=r(Ata,"vision-encoder-decoder"),Ata.forEach(t),j6r=r(YHe," \u2014 "),Aee=n(YHe,"A",{href:!0});var Lta=s(Aee);D6r=r(Lta,"VisionEncoderDecoderModel"),Lta.forEach(t),G6r=r(YHe," (Vision Encoder decoder model)"),YHe.forEach(t),wta.forEach(t),O6r=i(Oa),qE=n(Oa,"P",{});var ZHe=s(qE);V6r=r(ZHe,"The model is set in evaluation mode by default using "),X5e=n(ZHe,"CODE",{});var yta=s(X5e);X6r=r(yta,"model.eval()"),yta.forEach(t),z6r=r(ZHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),z5e=n(ZHe,"CODE",{});var xta=s(z5e);Q6r=r(xta,"model.train()"),xta.forEach(t),ZHe.forEach(t),W6r=i(Oa),T(jE.$$.fragment,Oa),Oa.forEach(t),Kl.forEach(t),pao=i(f),Lc=n(f,"H2",{class:!0});var Bso=s(Lc);DE=n(Bso,"A",{id:!0,class:!0,href:!0});var $ta=s(DE);Q5e=n($ta,"SPAN",{});var kta=s(Q5e);T(iS.$$.fragment,kta),kta.forEach(t),$ta.forEach(t),U6r=i(Bso),W5e=n(Bso,"SPAN",{});var Sta=s(W5e);H6r=r(Sta,"AutoModelForVisualQuestionAnswering"),Sta.forEach(t),Bso.forEach(t),_ao=i(f),Zo=n(f,"DIV",{class:!0});var ei=s(Zo);T(dS.$$.fragment,ei),J6r=i(ei),yc=n(ei,"P",{});var Nce=s(yc);Y6r=r(Nce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),Lee=n(Nce,"A",{href:!0});var Rta=s(Lee);Z6r=r(Rta,"from_pretrained()"),Rta.forEach(t),K6r=r(Nce," class method or the "),yee=n(Nce,"A",{href:!0});var Pta=s(yee);e7r=r(Pta,"from_config()"),Pta.forEach(t),o7r=r(Nce,` class
method.`),Nce.forEach(t),r7r=i(ei),cS=n(ei,"P",{});var Iso=s(cS);t7r=r(Iso,"This class cannot be instantiated directly using "),U5e=n(Iso,"CODE",{});var Bta=s(U5e);a7r=r(Bta,"__init__()"),Bta.forEach(t),n7r=r(Iso," (throws an error)."),Iso.forEach(t),s7r=i(ei),jt=n(ei,"DIV",{class:!0});var S9=s(jt);T(fS.$$.fragment,S9),l7r=i(S9),H5e=n(S9,"P",{});var Ita=s(H5e);i7r=r(Ita,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),Ita.forEach(t),d7r=i(S9),xc=n(S9,"P",{});var qce=s(xc);c7r=r(qce,`Note:
Loading a model from its configuration file does `),J5e=n(qce,"STRONG",{});var Nta=s(J5e);f7r=r(Nta,"not"),Nta.forEach(t),m7r=r(qce,` load the model weights. It only affects the
model\u2019s configuration. Use `),xee=n(qce,"A",{href:!0});var qta=s(xee);g7r=r(qta,"from_pretrained()"),qta.forEach(t),h7r=r(qce," to load the model weights."),qce.forEach(t),u7r=i(S9),T(GE.$$.fragment,S9),S9.forEach(t),p7r=i(ei),po=n(ei,"DIV",{class:!0});var Va=s(po);T(mS.$$.fragment,Va),_7r=i(Va),Y5e=n(Va,"P",{});var jta=s(Y5e);v7r=r(jta,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),jta.forEach(t),b7r=i(Va),Mn=n(Va,"P",{});var R9=s(Mn);F7r=r(R9,"The model class to instantiate is selected based on the "),Z5e=n(R9,"CODE",{});var Dta=s(Z5e);T7r=r(Dta,"model_type"),Dta.forEach(t),M7r=r(R9,` property of the config object (either
passed as an argument or loaded from `),K5e=n(R9,"CODE",{});var Gta=s(K5e);E7r=r(Gta,"pretrained_model_name_or_path"),Gta.forEach(t),C7r=r(R9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ewe=n(R9,"CODE",{});var Ota=s(ewe);w7r=r(Ota,"pretrained_model_name_or_path"),Ota.forEach(t),A7r=r(R9,":"),R9.forEach(t),L7r=i(Va),owe=n(Va,"UL",{});var Vta=s(owe);OE=n(Vta,"LI",{});var KHe=s(OE);rwe=n(KHe,"STRONG",{});var Xta=s(rwe);y7r=r(Xta,"vilt"),Xta.forEach(t),x7r=r(KHe," \u2014 "),$ee=n(KHe,"A",{href:!0});var zta=s($ee);$7r=r(zta,"ViltForQuestionAnswering"),zta.forEach(t),k7r=r(KHe," (ViLT model)"),KHe.forEach(t),Vta.forEach(t),S7r=i(Va),VE=n(Va,"P",{});var eJe=s(VE);R7r=r(eJe,"The model is set in evaluation mode by default using "),twe=n(eJe,"CODE",{});var Qta=s(twe);P7r=r(Qta,"model.eval()"),Qta.forEach(t),B7r=r(eJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),awe=n(eJe,"CODE",{});var Wta=s(awe);I7r=r(Wta,"model.train()"),Wta.forEach(t),eJe.forEach(t),N7r=i(Va),T(XE.$$.fragment,Va),Va.forEach(t),ei.forEach(t),vao=i(f),$c=n(f,"H2",{class:!0});var Nso=s($c);zE=n(Nso,"A",{id:!0,class:!0,href:!0});var Uta=s(zE);nwe=n(Uta,"SPAN",{});var Hta=s(nwe);T(gS.$$.fragment,Hta),Hta.forEach(t),Uta.forEach(t),q7r=i(Nso),swe=n(Nso,"SPAN",{});var Jta=s(swe);j7r=r(Jta,"AutoModelForAudioClassification"),Jta.forEach(t),Nso.forEach(t),bao=i(f),Ko=n(f,"DIV",{class:!0});var oi=s(Ko);T(hS.$$.fragment,oi),D7r=i(oi),kc=n(oi,"P",{});var jce=s(kc);G7r=r(jce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),kee=n(jce,"A",{href:!0});var Yta=s(kee);O7r=r(Yta,"from_pretrained()"),Yta.forEach(t),V7r=r(jce," class method or the "),See=n(jce,"A",{href:!0});var Zta=s(See);X7r=r(Zta,"from_config()"),Zta.forEach(t),z7r=r(jce,` class
method.`),jce.forEach(t),Q7r=i(oi),uS=n(oi,"P",{});var qso=s(uS);W7r=r(qso,"This class cannot be instantiated directly using "),lwe=n(qso,"CODE",{});var Kta=s(lwe);U7r=r(Kta,"__init__()"),Kta.forEach(t),H7r=r(qso," (throws an error)."),qso.forEach(t),J7r=i(oi),Dt=n(oi,"DIV",{class:!0});var P9=s(Dt);T(pS.$$.fragment,P9),Y7r=i(P9),iwe=n(P9,"P",{});var eaa=s(iwe);Z7r=r(eaa,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),eaa.forEach(t),K7r=i(P9),Sc=n(P9,"P",{});var Dce=s(Sc);e8r=r(Dce,`Note:
Loading a model from its configuration file does `),dwe=n(Dce,"STRONG",{});var oaa=s(dwe);o8r=r(oaa,"not"),oaa.forEach(t),r8r=r(Dce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ree=n(Dce,"A",{href:!0});var raa=s(Ree);t8r=r(raa,"from_pretrained()"),raa.forEach(t),a8r=r(Dce," to load the model weights."),Dce.forEach(t),n8r=i(P9),T(QE.$$.fragment,P9),P9.forEach(t),s8r=i(oi),_o=n(oi,"DIV",{class:!0});var Xa=s(_o);T(_S.$$.fragment,Xa),l8r=i(Xa),cwe=n(Xa,"P",{});var taa=s(cwe);i8r=r(taa,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),taa.forEach(t),d8r=i(Xa),En=n(Xa,"P",{});var B9=s(En);c8r=r(B9,"The model class to instantiate is selected based on the "),fwe=n(B9,"CODE",{});var aaa=s(fwe);f8r=r(aaa,"model_type"),aaa.forEach(t),m8r=r(B9,` property of the config object (either
passed as an argument or loaded from `),mwe=n(B9,"CODE",{});var naa=s(mwe);g8r=r(naa,"pretrained_model_name_or_path"),naa.forEach(t),h8r=r(B9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gwe=n(B9,"CODE",{});var saa=s(gwe);u8r=r(saa,"pretrained_model_name_or_path"),saa.forEach(t),p8r=r(B9,":"),B9.forEach(t),_8r=i(Xa),Be=n(Xa,"UL",{});var We=s(Be);WE=n(We,"LI",{});var oJe=s(WE);hwe=n(oJe,"STRONG",{});var laa=s(hwe);v8r=r(laa,"data2vec-audio"),laa.forEach(t),b8r=r(oJe," \u2014 "),Pee=n(oJe,"A",{href:!0});var iaa=s(Pee);F8r=r(iaa,"Data2VecAudioForSequenceClassification"),iaa.forEach(t),T8r=r(oJe," (Data2VecAudio model)"),oJe.forEach(t),M8r=i(We),UE=n(We,"LI",{});var rJe=s(UE);uwe=n(rJe,"STRONG",{});var daa=s(uwe);E8r=r(daa,"hubert"),daa.forEach(t),C8r=r(rJe," \u2014 "),Bee=n(rJe,"A",{href:!0});var caa=s(Bee);w8r=r(caa,"HubertForSequenceClassification"),caa.forEach(t),A8r=r(rJe," (Hubert model)"),rJe.forEach(t),L8r=i(We),HE=n(We,"LI",{});var tJe=s(HE);pwe=n(tJe,"STRONG",{});var faa=s(pwe);y8r=r(faa,"sew"),faa.forEach(t),x8r=r(tJe," \u2014 "),Iee=n(tJe,"A",{href:!0});var maa=s(Iee);$8r=r(maa,"SEWForSequenceClassification"),maa.forEach(t),k8r=r(tJe," (SEW model)"),tJe.forEach(t),S8r=i(We),JE=n(We,"LI",{});var aJe=s(JE);_we=n(aJe,"STRONG",{});var gaa=s(_we);R8r=r(gaa,"sew-d"),gaa.forEach(t),P8r=r(aJe," \u2014 "),Nee=n(aJe,"A",{href:!0});var haa=s(Nee);B8r=r(haa,"SEWDForSequenceClassification"),haa.forEach(t),I8r=r(aJe," (SEW-D model)"),aJe.forEach(t),N8r=i(We),YE=n(We,"LI",{});var nJe=s(YE);vwe=n(nJe,"STRONG",{});var uaa=s(vwe);q8r=r(uaa,"unispeech"),uaa.forEach(t),j8r=r(nJe," \u2014 "),qee=n(nJe,"A",{href:!0});var paa=s(qee);D8r=r(paa,"UniSpeechForSequenceClassification"),paa.forEach(t),G8r=r(nJe," (UniSpeech model)"),nJe.forEach(t),O8r=i(We),ZE=n(We,"LI",{});var sJe=s(ZE);bwe=n(sJe,"STRONG",{});var _aa=s(bwe);V8r=r(_aa,"unispeech-sat"),_aa.forEach(t),X8r=r(sJe," \u2014 "),jee=n(sJe,"A",{href:!0});var vaa=s(jee);z8r=r(vaa,"UniSpeechSatForSequenceClassification"),vaa.forEach(t),Q8r=r(sJe," (UniSpeechSat model)"),sJe.forEach(t),W8r=i(We),KE=n(We,"LI",{});var lJe=s(KE);Fwe=n(lJe,"STRONG",{});var baa=s(Fwe);U8r=r(baa,"wav2vec2"),baa.forEach(t),H8r=r(lJe," \u2014 "),Dee=n(lJe,"A",{href:!0});var Faa=s(Dee);J8r=r(Faa,"Wav2Vec2ForSequenceClassification"),Faa.forEach(t),Y8r=r(lJe," (Wav2Vec2 model)"),lJe.forEach(t),Z8r=i(We),eC=n(We,"LI",{});var iJe=s(eC);Twe=n(iJe,"STRONG",{});var Taa=s(Twe);K8r=r(Taa,"wav2vec2-conformer"),Taa.forEach(t),eLr=r(iJe," \u2014 "),Gee=n(iJe,"A",{href:!0});var Maa=s(Gee);oLr=r(Maa,"Wav2Vec2ConformerForSequenceClassification"),Maa.forEach(t),rLr=r(iJe," (Wav2Vec2-Conformer model)"),iJe.forEach(t),tLr=i(We),oC=n(We,"LI",{});var dJe=s(oC);Mwe=n(dJe,"STRONG",{});var Eaa=s(Mwe);aLr=r(Eaa,"wavlm"),Eaa.forEach(t),nLr=r(dJe," \u2014 "),Oee=n(dJe,"A",{href:!0});var Caa=s(Oee);sLr=r(Caa,"WavLMForSequenceClassification"),Caa.forEach(t),lLr=r(dJe," (WavLM model)"),dJe.forEach(t),We.forEach(t),iLr=i(Xa),rC=n(Xa,"P",{});var cJe=s(rC);dLr=r(cJe,"The model is set in evaluation mode by default using "),Ewe=n(cJe,"CODE",{});var waa=s(Ewe);cLr=r(waa,"model.eval()"),waa.forEach(t),fLr=r(cJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Cwe=n(cJe,"CODE",{});var Aaa=s(Cwe);mLr=r(Aaa,"model.train()"),Aaa.forEach(t),cJe.forEach(t),gLr=i(Xa),T(tC.$$.fragment,Xa),Xa.forEach(t),oi.forEach(t),Fao=i(f),Rc=n(f,"H2",{class:!0});var jso=s(Rc);aC=n(jso,"A",{id:!0,class:!0,href:!0});var Laa=s(aC);wwe=n(Laa,"SPAN",{});var yaa=s(wwe);T(vS.$$.fragment,yaa),yaa.forEach(t),Laa.forEach(t),hLr=i(jso),Awe=n(jso,"SPAN",{});var xaa=s(Awe);uLr=r(xaa,"AutoModelForAudioFrameClassification"),xaa.forEach(t),jso.forEach(t),Tao=i(f),er=n(f,"DIV",{class:!0});var ri=s(er);T(bS.$$.fragment,ri),pLr=i(ri),Pc=n(ri,"P",{});var Gce=s(Pc);_Lr=r(Gce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),Vee=n(Gce,"A",{href:!0});var $aa=s(Vee);vLr=r($aa,"from_pretrained()"),$aa.forEach(t),bLr=r(Gce," class method or the "),Xee=n(Gce,"A",{href:!0});var kaa=s(Xee);FLr=r(kaa,"from_config()"),kaa.forEach(t),TLr=r(Gce,` class
method.`),Gce.forEach(t),MLr=i(ri),FS=n(ri,"P",{});var Dso=s(FS);ELr=r(Dso,"This class cannot be instantiated directly using "),Lwe=n(Dso,"CODE",{});var Saa=s(Lwe);CLr=r(Saa,"__init__()"),Saa.forEach(t),wLr=r(Dso," (throws an error)."),Dso.forEach(t),ALr=i(ri),Gt=n(ri,"DIV",{class:!0});var I9=s(Gt);T(TS.$$.fragment,I9),LLr=i(I9),ywe=n(I9,"P",{});var Raa=s(ywe);yLr=r(Raa,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),Raa.forEach(t),xLr=i(I9),Bc=n(I9,"P",{});var Oce=s(Bc);$Lr=r(Oce,`Note:
Loading a model from its configuration file does `),xwe=n(Oce,"STRONG",{});var Paa=s(xwe);kLr=r(Paa,"not"),Paa.forEach(t),SLr=r(Oce,` load the model weights. It only affects the
model\u2019s configuration. Use `),zee=n(Oce,"A",{href:!0});var Baa=s(zee);RLr=r(Baa,"from_pretrained()"),Baa.forEach(t),PLr=r(Oce," to load the model weights."),Oce.forEach(t),BLr=i(I9),T(nC.$$.fragment,I9),I9.forEach(t),ILr=i(ri),vo=n(ri,"DIV",{class:!0});var za=s(vo);T(MS.$$.fragment,za),NLr=i(za),$we=n(za,"P",{});var Iaa=s($we);qLr=r(Iaa,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),Iaa.forEach(t),jLr=i(za),Cn=n(za,"P",{});var N9=s(Cn);DLr=r(N9,"The model class to instantiate is selected based on the "),kwe=n(N9,"CODE",{});var Naa=s(kwe);GLr=r(Naa,"model_type"),Naa.forEach(t),OLr=r(N9,` property of the config object (either
passed as an argument or loaded from `),Swe=n(N9,"CODE",{});var qaa=s(Swe);VLr=r(qaa,"pretrained_model_name_or_path"),qaa.forEach(t),XLr=r(N9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rwe=n(N9,"CODE",{});var jaa=s(Rwe);zLr=r(jaa,"pretrained_model_name_or_path"),jaa.forEach(t),QLr=r(N9,":"),N9.forEach(t),WLr=i(za),ut=n(za,"UL",{});var ti=s(ut);sC=n(ti,"LI",{});var fJe=s(sC);Pwe=n(fJe,"STRONG",{});var Daa=s(Pwe);ULr=r(Daa,"data2vec-audio"),Daa.forEach(t),HLr=r(fJe," \u2014 "),Qee=n(fJe,"A",{href:!0});var Gaa=s(Qee);JLr=r(Gaa,"Data2VecAudioForAudioFrameClassification"),Gaa.forEach(t),YLr=r(fJe," (Data2VecAudio model)"),fJe.forEach(t),ZLr=i(ti),lC=n(ti,"LI",{});var mJe=s(lC);Bwe=n(mJe,"STRONG",{});var Oaa=s(Bwe);KLr=r(Oaa,"unispeech-sat"),Oaa.forEach(t),eyr=r(mJe," \u2014 "),Wee=n(mJe,"A",{href:!0});var Vaa=s(Wee);oyr=r(Vaa,"UniSpeechSatForAudioFrameClassification"),Vaa.forEach(t),ryr=r(mJe," (UniSpeechSat model)"),mJe.forEach(t),tyr=i(ti),iC=n(ti,"LI",{});var gJe=s(iC);Iwe=n(gJe,"STRONG",{});var Xaa=s(Iwe);ayr=r(Xaa,"wav2vec2"),Xaa.forEach(t),nyr=r(gJe," \u2014 "),Uee=n(gJe,"A",{href:!0});var zaa=s(Uee);syr=r(zaa,"Wav2Vec2ForAudioFrameClassification"),zaa.forEach(t),lyr=r(gJe," (Wav2Vec2 model)"),gJe.forEach(t),iyr=i(ti),dC=n(ti,"LI",{});var hJe=s(dC);Nwe=n(hJe,"STRONG",{});var Qaa=s(Nwe);dyr=r(Qaa,"wav2vec2-conformer"),Qaa.forEach(t),cyr=r(hJe," \u2014 "),Hee=n(hJe,"A",{href:!0});var Waa=s(Hee);fyr=r(Waa,"Wav2Vec2ConformerForAudioFrameClassification"),Waa.forEach(t),myr=r(hJe," (Wav2Vec2-Conformer model)"),hJe.forEach(t),gyr=i(ti),cC=n(ti,"LI",{});var uJe=s(cC);qwe=n(uJe,"STRONG",{});var Uaa=s(qwe);hyr=r(Uaa,"wavlm"),Uaa.forEach(t),uyr=r(uJe," \u2014 "),Jee=n(uJe,"A",{href:!0});var Haa=s(Jee);pyr=r(Haa,"WavLMForAudioFrameClassification"),Haa.forEach(t),_yr=r(uJe," (WavLM model)"),uJe.forEach(t),ti.forEach(t),vyr=i(za),fC=n(za,"P",{});var pJe=s(fC);byr=r(pJe,"The model is set in evaluation mode by default using "),jwe=n(pJe,"CODE",{});var Jaa=s(jwe);Fyr=r(Jaa,"model.eval()"),Jaa.forEach(t),Tyr=r(pJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Dwe=n(pJe,"CODE",{});var Yaa=s(Dwe);Myr=r(Yaa,"model.train()"),Yaa.forEach(t),pJe.forEach(t),Eyr=i(za),T(mC.$$.fragment,za),za.forEach(t),ri.forEach(t),Mao=i(f),Ic=n(f,"H2",{class:!0});var Gso=s(Ic);gC=n(Gso,"A",{id:!0,class:!0,href:!0});var Zaa=s(gC);Gwe=n(Zaa,"SPAN",{});var Kaa=s(Gwe);T(ES.$$.fragment,Kaa),Kaa.forEach(t),Zaa.forEach(t),Cyr=i(Gso),Owe=n(Gso,"SPAN",{});var ena=s(Owe);wyr=r(ena,"AutoModelForCTC"),ena.forEach(t),Gso.forEach(t),Eao=i(f),or=n(f,"DIV",{class:!0});var ai=s(or);T(CS.$$.fragment,ai),Ayr=i(ai),Nc=n(ai,"P",{});var Vce=s(Nc);Lyr=r(Vce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),Yee=n(Vce,"A",{href:!0});var ona=s(Yee);yyr=r(ona,"from_pretrained()"),ona.forEach(t),xyr=r(Vce," class method or the "),Zee=n(Vce,"A",{href:!0});var rna=s(Zee);$yr=r(rna,"from_config()"),rna.forEach(t),kyr=r(Vce,` class
method.`),Vce.forEach(t),Syr=i(ai),wS=n(ai,"P",{});var Oso=s(wS);Ryr=r(Oso,"This class cannot be instantiated directly using "),Vwe=n(Oso,"CODE",{});var tna=s(Vwe);Pyr=r(tna,"__init__()"),tna.forEach(t),Byr=r(Oso," (throws an error)."),Oso.forEach(t),Iyr=i(ai),Ot=n(ai,"DIV",{class:!0});var q9=s(Ot);T(AS.$$.fragment,q9),Nyr=i(q9),Xwe=n(q9,"P",{});var ana=s(Xwe);qyr=r(ana,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),ana.forEach(t),jyr=i(q9),qc=n(q9,"P",{});var Xce=s(qc);Dyr=r(Xce,`Note:
Loading a model from its configuration file does `),zwe=n(Xce,"STRONG",{});var nna=s(zwe);Gyr=r(nna,"not"),nna.forEach(t),Oyr=r(Xce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Kee=n(Xce,"A",{href:!0});var sna=s(Kee);Vyr=r(sna,"from_pretrained()"),sna.forEach(t),Xyr=r(Xce," to load the model weights."),Xce.forEach(t),zyr=i(q9),T(hC.$$.fragment,q9),q9.forEach(t),Qyr=i(ai),bo=n(ai,"DIV",{class:!0});var Qa=s(bo);T(LS.$$.fragment,Qa),Wyr=i(Qa),Qwe=n(Qa,"P",{});var lna=s(Qwe);Uyr=r(lna,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),lna.forEach(t),Hyr=i(Qa),wn=n(Qa,"P",{});var j9=s(wn);Jyr=r(j9,"The model class to instantiate is selected based on the "),Wwe=n(j9,"CODE",{});var ina=s(Wwe);Yyr=r(ina,"model_type"),ina.forEach(t),Zyr=r(j9,` property of the config object (either
passed as an argument or loaded from `),Uwe=n(j9,"CODE",{});var dna=s(Uwe);Kyr=r(dna,"pretrained_model_name_or_path"),dna.forEach(t),e9r=r(j9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hwe=n(j9,"CODE",{});var cna=s(Hwe);o9r=r(cna,"pretrained_model_name_or_path"),cna.forEach(t),r9r=r(j9,":"),j9.forEach(t),t9r=i(Qa),Le=n(Qa,"UL",{});var Ie=s(Le);uC=n(Ie,"LI",{});var _Je=s(uC);Jwe=n(_Je,"STRONG",{});var fna=s(Jwe);a9r=r(fna,"data2vec-audio"),fna.forEach(t),n9r=r(_Je," \u2014 "),eoe=n(_Je,"A",{href:!0});var mna=s(eoe);s9r=r(mna,"Data2VecAudioForCTC"),mna.forEach(t),l9r=r(_Je," (Data2VecAudio model)"),_Je.forEach(t),i9r=i(Ie),pC=n(Ie,"LI",{});var vJe=s(pC);Ywe=n(vJe,"STRONG",{});var gna=s(Ywe);d9r=r(gna,"hubert"),gna.forEach(t),c9r=r(vJe," \u2014 "),ooe=n(vJe,"A",{href:!0});var hna=s(ooe);f9r=r(hna,"HubertForCTC"),hna.forEach(t),m9r=r(vJe," (Hubert model)"),vJe.forEach(t),g9r=i(Ie),_C=n(Ie,"LI",{});var bJe=s(_C);Zwe=n(bJe,"STRONG",{});var una=s(Zwe);h9r=r(una,"mctct"),una.forEach(t),u9r=r(bJe," \u2014 "),roe=n(bJe,"A",{href:!0});var pna=s(roe);p9r=r(pna,"MCTCTForCTC"),pna.forEach(t),_9r=r(bJe," (M-CTC-T model)"),bJe.forEach(t),v9r=i(Ie),vC=n(Ie,"LI",{});var FJe=s(vC);Kwe=n(FJe,"STRONG",{});var _na=s(Kwe);b9r=r(_na,"sew"),_na.forEach(t),F9r=r(FJe," \u2014 "),toe=n(FJe,"A",{href:!0});var vna=s(toe);T9r=r(vna,"SEWForCTC"),vna.forEach(t),M9r=r(FJe," (SEW model)"),FJe.forEach(t),E9r=i(Ie),bC=n(Ie,"LI",{});var TJe=s(bC);eAe=n(TJe,"STRONG",{});var bna=s(eAe);C9r=r(bna,"sew-d"),bna.forEach(t),w9r=r(TJe," \u2014 "),aoe=n(TJe,"A",{href:!0});var Fna=s(aoe);A9r=r(Fna,"SEWDForCTC"),Fna.forEach(t),L9r=r(TJe," (SEW-D model)"),TJe.forEach(t),y9r=i(Ie),FC=n(Ie,"LI",{});var MJe=s(FC);oAe=n(MJe,"STRONG",{});var Tna=s(oAe);x9r=r(Tna,"unispeech"),Tna.forEach(t),$9r=r(MJe," \u2014 "),noe=n(MJe,"A",{href:!0});var Mna=s(noe);k9r=r(Mna,"UniSpeechForCTC"),Mna.forEach(t),S9r=r(MJe," (UniSpeech model)"),MJe.forEach(t),R9r=i(Ie),TC=n(Ie,"LI",{});var EJe=s(TC);rAe=n(EJe,"STRONG",{});var Ena=s(rAe);P9r=r(Ena,"unispeech-sat"),Ena.forEach(t),B9r=r(EJe," \u2014 "),soe=n(EJe,"A",{href:!0});var Cna=s(soe);I9r=r(Cna,"UniSpeechSatForCTC"),Cna.forEach(t),N9r=r(EJe," (UniSpeechSat model)"),EJe.forEach(t),q9r=i(Ie),MC=n(Ie,"LI",{});var CJe=s(MC);tAe=n(CJe,"STRONG",{});var wna=s(tAe);j9r=r(wna,"wav2vec2"),wna.forEach(t),D9r=r(CJe," \u2014 "),loe=n(CJe,"A",{href:!0});var Ana=s(loe);G9r=r(Ana,"Wav2Vec2ForCTC"),Ana.forEach(t),O9r=r(CJe," (Wav2Vec2 model)"),CJe.forEach(t),V9r=i(Ie),EC=n(Ie,"LI",{});var wJe=s(EC);aAe=n(wJe,"STRONG",{});var Lna=s(aAe);X9r=r(Lna,"wav2vec2-conformer"),Lna.forEach(t),z9r=r(wJe," \u2014 "),ioe=n(wJe,"A",{href:!0});var yna=s(ioe);Q9r=r(yna,"Wav2Vec2ConformerForCTC"),yna.forEach(t),W9r=r(wJe," (Wav2Vec2-Conformer model)"),wJe.forEach(t),U9r=i(Ie),CC=n(Ie,"LI",{});var AJe=s(CC);nAe=n(AJe,"STRONG",{});var xna=s(nAe);H9r=r(xna,"wavlm"),xna.forEach(t),J9r=r(AJe," \u2014 "),doe=n(AJe,"A",{href:!0});var $na=s(doe);Y9r=r($na,"WavLMForCTC"),$na.forEach(t),Z9r=r(AJe," (WavLM model)"),AJe.forEach(t),Ie.forEach(t),K9r=i(Qa),wC=n(Qa,"P",{});var LJe=s(wC);exr=r(LJe,"The model is set in evaluation mode by default using "),sAe=n(LJe,"CODE",{});var kna=s(sAe);oxr=r(kna,"model.eval()"),kna.forEach(t),rxr=r(LJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lAe=n(LJe,"CODE",{});var Sna=s(lAe);txr=r(Sna,"model.train()"),Sna.forEach(t),LJe.forEach(t),axr=i(Qa),T(AC.$$.fragment,Qa),Qa.forEach(t),ai.forEach(t),Cao=i(f),jc=n(f,"H2",{class:!0});var Vso=s(jc);LC=n(Vso,"A",{id:!0,class:!0,href:!0});var Rna=s(LC);iAe=n(Rna,"SPAN",{});var Pna=s(iAe);T(yS.$$.fragment,Pna),Pna.forEach(t),Rna.forEach(t),nxr=i(Vso),dAe=n(Vso,"SPAN",{});var Bna=s(dAe);sxr=r(Bna,"AutoModelForSpeechSeq2Seq"),Bna.forEach(t),Vso.forEach(t),wao=i(f),rr=n(f,"DIV",{class:!0});var ni=s(rr);T(xS.$$.fragment,ni),lxr=i(ni),Dc=n(ni,"P",{});var zce=s(Dc);ixr=r(zce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),coe=n(zce,"A",{href:!0});var Ina=s(coe);dxr=r(Ina,"from_pretrained()"),Ina.forEach(t),cxr=r(zce," class method or the "),foe=n(zce,"A",{href:!0});var Nna=s(foe);fxr=r(Nna,"from_config()"),Nna.forEach(t),mxr=r(zce,` class
method.`),zce.forEach(t),gxr=i(ni),$S=n(ni,"P",{});var Xso=s($S);hxr=r(Xso,"This class cannot be instantiated directly using "),cAe=n(Xso,"CODE",{});var qna=s(cAe);uxr=r(qna,"__init__()"),qna.forEach(t),pxr=r(Xso," (throws an error)."),Xso.forEach(t),_xr=i(ni),Vt=n(ni,"DIV",{class:!0});var D9=s(Vt);T(kS.$$.fragment,D9),vxr=i(D9),fAe=n(D9,"P",{});var jna=s(fAe);bxr=r(jna,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),jna.forEach(t),Fxr=i(D9),Gc=n(D9,"P",{});var Qce=s(Gc);Txr=r(Qce,`Note:
Loading a model from its configuration file does `),mAe=n(Qce,"STRONG",{});var Dna=s(mAe);Mxr=r(Dna,"not"),Dna.forEach(t),Exr=r(Qce,` load the model weights. It only affects the
model\u2019s configuration. Use `),moe=n(Qce,"A",{href:!0});var Gna=s(moe);Cxr=r(Gna,"from_pretrained()"),Gna.forEach(t),wxr=r(Qce," to load the model weights."),Qce.forEach(t),Axr=i(D9),T(yC.$$.fragment,D9),D9.forEach(t),Lxr=i(ni),Fo=n(ni,"DIV",{class:!0});var Wa=s(Fo);T(SS.$$.fragment,Wa),yxr=i(Wa),gAe=n(Wa,"P",{});var Ona=s(gAe);xxr=r(Ona,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Ona.forEach(t),$xr=i(Wa),An=n(Wa,"P",{});var G9=s(An);kxr=r(G9,"The model class to instantiate is selected based on the "),hAe=n(G9,"CODE",{});var Vna=s(hAe);Sxr=r(Vna,"model_type"),Vna.forEach(t),Rxr=r(G9,` property of the config object (either
passed as an argument or loaded from `),uAe=n(G9,"CODE",{});var Xna=s(uAe);Pxr=r(Xna,"pretrained_model_name_or_path"),Xna.forEach(t),Bxr=r(G9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pAe=n(G9,"CODE",{});var zna=s(pAe);Ixr=r(zna,"pretrained_model_name_or_path"),zna.forEach(t),Nxr=r(G9,":"),G9.forEach(t),qxr=i(Wa),Oc=n(Wa,"UL",{});var Wce=s(Oc);xC=n(Wce,"LI",{});var yJe=s(xC);_Ae=n(yJe,"STRONG",{});var Qna=s(_Ae);jxr=r(Qna,"speech-encoder-decoder"),Qna.forEach(t),Dxr=r(yJe," \u2014 "),goe=n(yJe,"A",{href:!0});var Wna=s(goe);Gxr=r(Wna,"SpeechEncoderDecoderModel"),Wna.forEach(t),Oxr=r(yJe," (Speech Encoder decoder model)"),yJe.forEach(t),Vxr=i(Wce),$C=n(Wce,"LI",{});var xJe=s($C);vAe=n(xJe,"STRONG",{});var Una=s(vAe);Xxr=r(Una,"speech_to_text"),Una.forEach(t),zxr=r(xJe," \u2014 "),hoe=n(xJe,"A",{href:!0});var Hna=s(hoe);Qxr=r(Hna,"Speech2TextForConditionalGeneration"),Hna.forEach(t),Wxr=r(xJe," (Speech2Text model)"),xJe.forEach(t),Uxr=i(Wce),kC=n(Wce,"LI",{});var $Je=s(kC);bAe=n($Je,"STRONG",{});var Jna=s(bAe);Hxr=r(Jna,"whisper"),Jna.forEach(t),Jxr=r($Je," \u2014 "),uoe=n($Je,"A",{href:!0});var Yna=s(uoe);Yxr=r(Yna,"WhisperForConditionalGeneration"),Yna.forEach(t),Zxr=r($Je," (Whisper model)"),$Je.forEach(t),Wce.forEach(t),Kxr=i(Wa),SC=n(Wa,"P",{});var kJe=s(SC);e$r=r(kJe,"The model is set in evaluation mode by default using "),FAe=n(kJe,"CODE",{});var Zna=s(FAe);o$r=r(Zna,"model.eval()"),Zna.forEach(t),r$r=r(kJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),TAe=n(kJe,"CODE",{});var Kna=s(TAe);t$r=r(Kna,"model.train()"),Kna.forEach(t),kJe.forEach(t),a$r=i(Wa),T(RC.$$.fragment,Wa),Wa.forEach(t),ni.forEach(t),Aao=i(f),Vc=n(f,"H2",{class:!0});var zso=s(Vc);PC=n(zso,"A",{id:!0,class:!0,href:!0});var esa=s(PC);MAe=n(esa,"SPAN",{});var osa=s(MAe);T(RS.$$.fragment,osa),osa.forEach(t),esa.forEach(t),n$r=i(zso),EAe=n(zso,"SPAN",{});var rsa=s(EAe);s$r=r(rsa,"AutoModelForAudioXVector"),rsa.forEach(t),zso.forEach(t),Lao=i(f),tr=n(f,"DIV",{class:!0});var si=s(tr);T(PS.$$.fragment,si),l$r=i(si),Xc=n(si,"P",{});var Uce=s(Xc);i$r=r(Uce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),poe=n(Uce,"A",{href:!0});var tsa=s(poe);d$r=r(tsa,"from_pretrained()"),tsa.forEach(t),c$r=r(Uce," class method or the "),_oe=n(Uce,"A",{href:!0});var asa=s(_oe);f$r=r(asa,"from_config()"),asa.forEach(t),m$r=r(Uce,` class
method.`),Uce.forEach(t),g$r=i(si),BS=n(si,"P",{});var Qso=s(BS);h$r=r(Qso,"This class cannot be instantiated directly using "),CAe=n(Qso,"CODE",{});var nsa=s(CAe);u$r=r(nsa,"__init__()"),nsa.forEach(t),p$r=r(Qso," (throws an error)."),Qso.forEach(t),_$r=i(si),Xt=n(si,"DIV",{class:!0});var O9=s(Xt);T(IS.$$.fragment,O9),v$r=i(O9),wAe=n(O9,"P",{});var ssa=s(wAe);b$r=r(ssa,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),ssa.forEach(t),F$r=i(O9),zc=n(O9,"P",{});var Hce=s(zc);T$r=r(Hce,`Note:
Loading a model from its configuration file does `),AAe=n(Hce,"STRONG",{});var lsa=s(AAe);M$r=r(lsa,"not"),lsa.forEach(t),E$r=r(Hce,` load the model weights. It only affects the
model\u2019s configuration. Use `),voe=n(Hce,"A",{href:!0});var isa=s(voe);C$r=r(isa,"from_pretrained()"),isa.forEach(t),w$r=r(Hce," to load the model weights."),Hce.forEach(t),A$r=i(O9),T(BC.$$.fragment,O9),O9.forEach(t),L$r=i(si),To=n(si,"DIV",{class:!0});var Ua=s(To);T(NS.$$.fragment,Ua),y$r=i(Ua),LAe=n(Ua,"P",{});var dsa=s(LAe);x$r=r(dsa,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),dsa.forEach(t),$$r=i(Ua),Ln=n(Ua,"P",{});var V9=s(Ln);k$r=r(V9,"The model class to instantiate is selected based on the "),yAe=n(V9,"CODE",{});var csa=s(yAe);S$r=r(csa,"model_type"),csa.forEach(t),R$r=r(V9,` property of the config object (either
passed as an argument or loaded from `),xAe=n(V9,"CODE",{});var fsa=s(xAe);P$r=r(fsa,"pretrained_model_name_or_path"),fsa.forEach(t),B$r=r(V9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Ae=n(V9,"CODE",{});var msa=s($Ae);I$r=r(msa,"pretrained_model_name_or_path"),msa.forEach(t),N$r=r(V9,":"),V9.forEach(t),q$r=i(Ua),pt=n(Ua,"UL",{});var li=s(pt);IC=n(li,"LI",{});var SJe=s(IC);kAe=n(SJe,"STRONG",{});var gsa=s(kAe);j$r=r(gsa,"data2vec-audio"),gsa.forEach(t),D$r=r(SJe," \u2014 "),boe=n(SJe,"A",{href:!0});var hsa=s(boe);G$r=r(hsa,"Data2VecAudioForXVector"),hsa.forEach(t),O$r=r(SJe," (Data2VecAudio model)"),SJe.forEach(t),V$r=i(li),NC=n(li,"LI",{});var RJe=s(NC);SAe=n(RJe,"STRONG",{});var usa=s(SAe);X$r=r(usa,"unispeech-sat"),usa.forEach(t),z$r=r(RJe," \u2014 "),Foe=n(RJe,"A",{href:!0});var psa=s(Foe);Q$r=r(psa,"UniSpeechSatForXVector"),psa.forEach(t),W$r=r(RJe," (UniSpeechSat model)"),RJe.forEach(t),U$r=i(li),qC=n(li,"LI",{});var PJe=s(qC);RAe=n(PJe,"STRONG",{});var _sa=s(RAe);H$r=r(_sa,"wav2vec2"),_sa.forEach(t),J$r=r(PJe," \u2014 "),Toe=n(PJe,"A",{href:!0});var vsa=s(Toe);Y$r=r(vsa,"Wav2Vec2ForXVector"),vsa.forEach(t),Z$r=r(PJe," (Wav2Vec2 model)"),PJe.forEach(t),K$r=i(li),jC=n(li,"LI",{});var BJe=s(jC);PAe=n(BJe,"STRONG",{});var bsa=s(PAe);ekr=r(bsa,"wav2vec2-conformer"),bsa.forEach(t),okr=r(BJe," \u2014 "),Moe=n(BJe,"A",{href:!0});var Fsa=s(Moe);rkr=r(Fsa,"Wav2Vec2ConformerForXVector"),Fsa.forEach(t),tkr=r(BJe," (Wav2Vec2-Conformer model)"),BJe.forEach(t),akr=i(li),DC=n(li,"LI",{});var IJe=s(DC);BAe=n(IJe,"STRONG",{});var Tsa=s(BAe);nkr=r(Tsa,"wavlm"),Tsa.forEach(t),skr=r(IJe," \u2014 "),Eoe=n(IJe,"A",{href:!0});var Msa=s(Eoe);lkr=r(Msa,"WavLMForXVector"),Msa.forEach(t),ikr=r(IJe," (WavLM model)"),IJe.forEach(t),li.forEach(t),dkr=i(Ua),GC=n(Ua,"P",{});var NJe=s(GC);ckr=r(NJe,"The model is set in evaluation mode by default using "),IAe=n(NJe,"CODE",{});var Esa=s(IAe);fkr=r(Esa,"model.eval()"),Esa.forEach(t),mkr=r(NJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),NAe=n(NJe,"CODE",{});var Csa=s(NAe);gkr=r(Csa,"model.train()"),Csa.forEach(t),NJe.forEach(t),hkr=i(Ua),T(OC.$$.fragment,Ua),Ua.forEach(t),si.forEach(t),yao=i(f),Qc=n(f,"H2",{class:!0});var Wso=s(Qc);VC=n(Wso,"A",{id:!0,class:!0,href:!0});var wsa=s(VC);qAe=n(wsa,"SPAN",{});var Asa=s(qAe);T(qS.$$.fragment,Asa),Asa.forEach(t),wsa.forEach(t),ukr=i(Wso),jAe=n(Wso,"SPAN",{});var Lsa=s(jAe);pkr=r(Lsa,"AutoModelForMaskedImageModeling"),Lsa.forEach(t),Wso.forEach(t),xao=i(f),ar=n(f,"DIV",{class:!0});var ii=s(ar);T(jS.$$.fragment,ii),_kr=i(ii),Wc=n(ii,"P",{});var Jce=s(Wc);vkr=r(Jce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),Coe=n(Jce,"A",{href:!0});var ysa=s(Coe);bkr=r(ysa,"from_pretrained()"),ysa.forEach(t),Fkr=r(Jce," class method or the "),woe=n(Jce,"A",{href:!0});var xsa=s(woe);Tkr=r(xsa,"from_config()"),xsa.forEach(t),Mkr=r(Jce,` class
method.`),Jce.forEach(t),Ekr=i(ii),DS=n(ii,"P",{});var Uso=s(DS);Ckr=r(Uso,"This class cannot be instantiated directly using "),DAe=n(Uso,"CODE",{});var $sa=s(DAe);wkr=r($sa,"__init__()"),$sa.forEach(t),Akr=r(Uso," (throws an error)."),Uso.forEach(t),Lkr=i(ii),zt=n(ii,"DIV",{class:!0});var X9=s(zt);T(GS.$$.fragment,X9),ykr=i(X9),GAe=n(X9,"P",{});var ksa=s(GAe);xkr=r(ksa,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),ksa.forEach(t),$kr=i(X9),Uc=n(X9,"P",{});var Yce=s(Uc);kkr=r(Yce,`Note:
Loading a model from its configuration file does `),OAe=n(Yce,"STRONG",{});var Ssa=s(OAe);Skr=r(Ssa,"not"),Ssa.forEach(t),Rkr=r(Yce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Aoe=n(Yce,"A",{href:!0});var Rsa=s(Aoe);Pkr=r(Rsa,"from_pretrained()"),Rsa.forEach(t),Bkr=r(Yce," to load the model weights."),Yce.forEach(t),Ikr=i(X9),T(XC.$$.fragment,X9),X9.forEach(t),Nkr=i(ii),Mo=n(ii,"DIV",{class:!0});var Ha=s(Mo);T(OS.$$.fragment,Ha),qkr=i(Ha),VAe=n(Ha,"P",{});var Psa=s(VAe);jkr=r(Psa,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),Psa.forEach(t),Dkr=i(Ha),yn=n(Ha,"P",{});var z9=s(yn);Gkr=r(z9,"The model class to instantiate is selected based on the "),XAe=n(z9,"CODE",{});var Bsa=s(XAe);Okr=r(Bsa,"model_type"),Bsa.forEach(t),Vkr=r(z9,` property of the config object (either
passed as an argument or loaded from `),zAe=n(z9,"CODE",{});var Isa=s(zAe);Xkr=r(Isa,"pretrained_model_name_or_path"),Isa.forEach(t),zkr=r(z9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QAe=n(z9,"CODE",{});var Nsa=s(QAe);Qkr=r(Nsa,"pretrained_model_name_or_path"),Nsa.forEach(t),Wkr=r(z9,":"),z9.forEach(t),Ukr=i(Ha),xn=n(Ha,"UL",{});var Q9=s(xn);zC=n(Q9,"LI",{});var qJe=s(zC);WAe=n(qJe,"STRONG",{});var qsa=s(WAe);Hkr=r(qsa,"deit"),qsa.forEach(t),Jkr=r(qJe," \u2014 "),Loe=n(qJe,"A",{href:!0});var jsa=s(Loe);Ykr=r(jsa,"DeiTForMaskedImageModeling"),jsa.forEach(t),Zkr=r(qJe," (DeiT model)"),qJe.forEach(t),Kkr=i(Q9),QC=n(Q9,"LI",{});var jJe=s(QC);UAe=n(jJe,"STRONG",{});var Dsa=s(UAe);eSr=r(Dsa,"swin"),Dsa.forEach(t),oSr=r(jJe," \u2014 "),yoe=n(jJe,"A",{href:!0});var Gsa=s(yoe);rSr=r(Gsa,"SwinForMaskedImageModeling"),Gsa.forEach(t),tSr=r(jJe," (Swin Transformer model)"),jJe.forEach(t),aSr=i(Q9),WC=n(Q9,"LI",{});var DJe=s(WC);HAe=n(DJe,"STRONG",{});var Osa=s(HAe);nSr=r(Osa,"swinv2"),Osa.forEach(t),sSr=r(DJe," \u2014 "),xoe=n(DJe,"A",{href:!0});var Vsa=s(xoe);lSr=r(Vsa,"Swinv2ForMaskedImageModeling"),Vsa.forEach(t),iSr=r(DJe," (Swin Transformer V2 model)"),DJe.forEach(t),dSr=i(Q9),UC=n(Q9,"LI",{});var GJe=s(UC);JAe=n(GJe,"STRONG",{});var Xsa=s(JAe);cSr=r(Xsa,"vit"),Xsa.forEach(t),fSr=r(GJe," \u2014 "),$oe=n(GJe,"A",{href:!0});var zsa=s($oe);mSr=r(zsa,"ViTForMaskedImageModeling"),zsa.forEach(t),gSr=r(GJe," (ViT model)"),GJe.forEach(t),Q9.forEach(t),hSr=i(Ha),HC=n(Ha,"P",{});var OJe=s(HC);uSr=r(OJe,"The model is set in evaluation mode by default using "),YAe=n(OJe,"CODE",{});var Qsa=s(YAe);pSr=r(Qsa,"model.eval()"),Qsa.forEach(t),_Sr=r(OJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ZAe=n(OJe,"CODE",{});var Wsa=s(ZAe);vSr=r(Wsa,"model.train()"),Wsa.forEach(t),OJe.forEach(t),bSr=i(Ha),T(JC.$$.fragment,Ha),Ha.forEach(t),ii.forEach(t),$ao=i(f),Hc=n(f,"H2",{class:!0});var Hso=s(Hc);YC=n(Hso,"A",{id:!0,class:!0,href:!0});var Usa=s(YC);KAe=n(Usa,"SPAN",{});var Hsa=s(KAe);T(VS.$$.fragment,Hsa),Hsa.forEach(t),Usa.forEach(t),FSr=i(Hso),e6e=n(Hso,"SPAN",{});var Jsa=s(e6e);TSr=r(Jsa,"AutoModelForObjectDetection"),Jsa.forEach(t),Hso.forEach(t),kao=i(f),nr=n(f,"DIV",{class:!0});var di=s(nr);T(XS.$$.fragment,di),MSr=i(di),Jc=n(di,"P",{});var Zce=s(Jc);ESr=r(Zce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),koe=n(Zce,"A",{href:!0});var Ysa=s(koe);CSr=r(Ysa,"from_pretrained()"),Ysa.forEach(t),wSr=r(Zce," class method or the "),Soe=n(Zce,"A",{href:!0});var Zsa=s(Soe);ASr=r(Zsa,"from_config()"),Zsa.forEach(t),LSr=r(Zce,` class
method.`),Zce.forEach(t),ySr=i(di),zS=n(di,"P",{});var Jso=s(zS);xSr=r(Jso,"This class cannot be instantiated directly using "),o6e=n(Jso,"CODE",{});var Ksa=s(o6e);$Sr=r(Ksa,"__init__()"),Ksa.forEach(t),kSr=r(Jso," (throws an error)."),Jso.forEach(t),SSr=i(di),Qt=n(di,"DIV",{class:!0});var W9=s(Qt);T(QS.$$.fragment,W9),RSr=i(W9),r6e=n(W9,"P",{});var ela=s(r6e);PSr=r(ela,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),ela.forEach(t),BSr=i(W9),Yc=n(W9,"P",{});var Kce=s(Yc);ISr=r(Kce,`Note:
Loading a model from its configuration file does `),t6e=n(Kce,"STRONG",{});var ola=s(t6e);NSr=r(ola,"not"),ola.forEach(t),qSr=r(Kce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Roe=n(Kce,"A",{href:!0});var rla=s(Roe);jSr=r(rla,"from_pretrained()"),rla.forEach(t),DSr=r(Kce," to load the model weights."),Kce.forEach(t),GSr=i(W9),T(ZC.$$.fragment,W9),W9.forEach(t),OSr=i(di),Eo=n(di,"DIV",{class:!0});var Ja=s(Eo);T(WS.$$.fragment,Ja),VSr=i(Ja),a6e=n(Ja,"P",{});var tla=s(a6e);XSr=r(tla,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),tla.forEach(t),zSr=i(Ja),$n=n(Ja,"P",{});var U9=s($n);QSr=r(U9,"The model class to instantiate is selected based on the "),n6e=n(U9,"CODE",{});var ala=s(n6e);WSr=r(ala,"model_type"),ala.forEach(t),USr=r(U9,` property of the config object (either
passed as an argument or loaded from `),s6e=n(U9,"CODE",{});var nla=s(s6e);HSr=r(nla,"pretrained_model_name_or_path"),nla.forEach(t),JSr=r(U9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l6e=n(U9,"CODE",{});var sla=s(l6e);YSr=r(sla,"pretrained_model_name_or_path"),sla.forEach(t),ZSr=r(U9,":"),U9.forEach(t),KSr=i(Ja),_t=n(Ja,"UL",{});var ci=s(_t);KC=n(ci,"LI",{});var VJe=s(KC);i6e=n(VJe,"STRONG",{});var lla=s(i6e);eRr=r(lla,"conditional_detr"),lla.forEach(t),oRr=r(VJe," \u2014 "),Poe=n(VJe,"A",{href:!0});var ila=s(Poe);rRr=r(ila,"ConditionalDetrForObjectDetection"),ila.forEach(t),tRr=r(VJe," (Conditional DETR model)"),VJe.forEach(t),aRr=i(ci),e3=n(ci,"LI",{});var XJe=s(e3);d6e=n(XJe,"STRONG",{});var dla=s(d6e);nRr=r(dla,"deformable_detr"),dla.forEach(t),sRr=r(XJe," \u2014 "),Boe=n(XJe,"A",{href:!0});var cla=s(Boe);lRr=r(cla,"DeformableDetrForObjectDetection"),cla.forEach(t),iRr=r(XJe," (Deformable DETR model)"),XJe.forEach(t),dRr=i(ci),o3=n(ci,"LI",{});var zJe=s(o3);c6e=n(zJe,"STRONG",{});var fla=s(c6e);cRr=r(fla,"detr"),fla.forEach(t),fRr=r(zJe," \u2014 "),Ioe=n(zJe,"A",{href:!0});var mla=s(Ioe);mRr=r(mla,"DetrForObjectDetection"),mla.forEach(t),gRr=r(zJe," (DETR model)"),zJe.forEach(t),hRr=i(ci),r3=n(ci,"LI",{});var QJe=s(r3);f6e=n(QJe,"STRONG",{});var gla=s(f6e);uRr=r(gla,"table-transformer"),gla.forEach(t),pRr=r(QJe," \u2014 "),Noe=n(QJe,"A",{href:!0});var hla=s(Noe);_Rr=r(hla,"TableTransformerForObjectDetection"),hla.forEach(t),vRr=r(QJe," (Table Transformer model)"),QJe.forEach(t),bRr=i(ci),t3=n(ci,"LI",{});var WJe=s(t3);m6e=n(WJe,"STRONG",{});var ula=s(m6e);FRr=r(ula,"yolos"),ula.forEach(t),TRr=r(WJe," \u2014 "),qoe=n(WJe,"A",{href:!0});var pla=s(qoe);MRr=r(pla,"YolosForObjectDetection"),pla.forEach(t),ERr=r(WJe," (YOLOS model)"),WJe.forEach(t),ci.forEach(t),CRr=i(Ja),a3=n(Ja,"P",{});var UJe=s(a3);wRr=r(UJe,"The model is set in evaluation mode by default using "),g6e=n(UJe,"CODE",{});var _la=s(g6e);ARr=r(_la,"model.eval()"),_la.forEach(t),LRr=r(UJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),h6e=n(UJe,"CODE",{});var vla=s(h6e);yRr=r(vla,"model.train()"),vla.forEach(t),UJe.forEach(t),xRr=i(Ja),T(n3.$$.fragment,Ja),Ja.forEach(t),di.forEach(t),Sao=i(f),Zc=n(f,"H2",{class:!0});var Yso=s(Zc);s3=n(Yso,"A",{id:!0,class:!0,href:!0});var bla=s(s3);u6e=n(bla,"SPAN",{});var Fla=s(u6e);T(US.$$.fragment,Fla),Fla.forEach(t),bla.forEach(t),$Rr=i(Yso),p6e=n(Yso,"SPAN",{});var Tla=s(p6e);kRr=r(Tla,"AutoModelForImageSegmentation"),Tla.forEach(t),Yso.forEach(t),Rao=i(f),sr=n(f,"DIV",{class:!0});var fi=s(sr);T(HS.$$.fragment,fi),SRr=i(fi),Kc=n(fi,"P",{});var efe=s(Kc);RRr=r(efe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),joe=n(efe,"A",{href:!0});var Mla=s(joe);PRr=r(Mla,"from_pretrained()"),Mla.forEach(t),BRr=r(efe," class method or the "),Doe=n(efe,"A",{href:!0});var Ela=s(Doe);IRr=r(Ela,"from_config()"),Ela.forEach(t),NRr=r(efe,` class
method.`),efe.forEach(t),qRr=i(fi),JS=n(fi,"P",{});var Zso=s(JS);jRr=r(Zso,"This class cannot be instantiated directly using "),_6e=n(Zso,"CODE",{});var Cla=s(_6e);DRr=r(Cla,"__init__()"),Cla.forEach(t),GRr=r(Zso," (throws an error)."),Zso.forEach(t),ORr=i(fi),Wt=n(fi,"DIV",{class:!0});var H9=s(Wt);T(YS.$$.fragment,H9),VRr=i(H9),v6e=n(H9,"P",{});var wla=s(v6e);XRr=r(wla,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),wla.forEach(t),zRr=i(H9),ef=n(H9,"P",{});var ofe=s(ef);QRr=r(ofe,`Note:
Loading a model from its configuration file does `),b6e=n(ofe,"STRONG",{});var Ala=s(b6e);WRr=r(Ala,"not"),Ala.forEach(t),URr=r(ofe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Goe=n(ofe,"A",{href:!0});var Lla=s(Goe);HRr=r(Lla,"from_pretrained()"),Lla.forEach(t),JRr=r(ofe," to load the model weights."),ofe.forEach(t),YRr=i(H9),T(l3.$$.fragment,H9),H9.forEach(t),ZRr=i(fi),Co=n(fi,"DIV",{class:!0});var Ya=s(Co);T(ZS.$$.fragment,Ya),KRr=i(Ya),F6e=n(Ya,"P",{});var yla=s(F6e);ePr=r(yla,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),yla.forEach(t),oPr=i(Ya),kn=n(Ya,"P",{});var J9=s(kn);rPr=r(J9,"The model class to instantiate is selected based on the "),T6e=n(J9,"CODE",{});var xla=s(T6e);tPr=r(xla,"model_type"),xla.forEach(t),aPr=r(J9,` property of the config object (either
passed as an argument or loaded from `),M6e=n(J9,"CODE",{});var $la=s(M6e);nPr=r($la,"pretrained_model_name_or_path"),$la.forEach(t),sPr=r(J9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E6e=n(J9,"CODE",{});var kla=s(E6e);lPr=r(kla,"pretrained_model_name_or_path"),kla.forEach(t),iPr=r(J9,":"),J9.forEach(t),dPr=i(Ya),C6e=n(Ya,"UL",{});var Sla=s(C6e);i3=n(Sla,"LI",{});var HJe=s(i3);w6e=n(HJe,"STRONG",{});var Rla=s(w6e);cPr=r(Rla,"detr"),Rla.forEach(t),fPr=r(HJe," \u2014 "),Ooe=n(HJe,"A",{href:!0});var Pla=s(Ooe);mPr=r(Pla,"DetrForSegmentation"),Pla.forEach(t),gPr=r(HJe," (DETR model)"),HJe.forEach(t),Sla.forEach(t),hPr=i(Ya),d3=n(Ya,"P",{});var JJe=s(d3);uPr=r(JJe,"The model is set in evaluation mode by default using "),A6e=n(JJe,"CODE",{});var Bla=s(A6e);pPr=r(Bla,"model.eval()"),Bla.forEach(t),_Pr=r(JJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),L6e=n(JJe,"CODE",{});var Ila=s(L6e);vPr=r(Ila,"model.train()"),Ila.forEach(t),JJe.forEach(t),bPr=i(Ya),T(c3.$$.fragment,Ya),Ya.forEach(t),fi.forEach(t),Pao=i(f),of=n(f,"H2",{class:!0});var Kso=s(of);f3=n(Kso,"A",{id:!0,class:!0,href:!0});var Nla=s(f3);y6e=n(Nla,"SPAN",{});var qla=s(y6e);T(KS.$$.fragment,qla),qla.forEach(t),Nla.forEach(t),FPr=i(Kso),x6e=n(Kso,"SPAN",{});var jla=s(x6e);TPr=r(jla,"AutoModelForSemanticSegmentation"),jla.forEach(t),Kso.forEach(t),Bao=i(f),lr=n(f,"DIV",{class:!0});var mi=s(lr);T(eR.$$.fragment,mi),MPr=i(mi),rf=n(mi,"P",{});var rfe=s(rf);EPr=r(rfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Voe=n(rfe,"A",{href:!0});var Dla=s(Voe);CPr=r(Dla,"from_pretrained()"),Dla.forEach(t),wPr=r(rfe," class method or the "),Xoe=n(rfe,"A",{href:!0});var Gla=s(Xoe);APr=r(Gla,"from_config()"),Gla.forEach(t),LPr=r(rfe,` class
method.`),rfe.forEach(t),yPr=i(mi),oR=n(mi,"P",{});var elo=s(oR);xPr=r(elo,"This class cannot be instantiated directly using "),$6e=n(elo,"CODE",{});var Ola=s($6e);$Pr=r(Ola,"__init__()"),Ola.forEach(t),kPr=r(elo," (throws an error)."),elo.forEach(t),SPr=i(mi),Ut=n(mi,"DIV",{class:!0});var Y9=s(Ut);T(rR.$$.fragment,Y9),RPr=i(Y9),k6e=n(Y9,"P",{});var Vla=s(k6e);PPr=r(Vla,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Vla.forEach(t),BPr=i(Y9),tf=n(Y9,"P",{});var tfe=s(tf);IPr=r(tfe,`Note:
Loading a model from its configuration file does `),S6e=n(tfe,"STRONG",{});var Xla=s(S6e);NPr=r(Xla,"not"),Xla.forEach(t),qPr=r(tfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),zoe=n(tfe,"A",{href:!0});var zla=s(zoe);jPr=r(zla,"from_pretrained()"),zla.forEach(t),DPr=r(tfe," to load the model weights."),tfe.forEach(t),GPr=i(Y9),T(m3.$$.fragment,Y9),Y9.forEach(t),OPr=i(mi),wo=n(mi,"DIV",{class:!0});var Za=s(wo);T(tR.$$.fragment,Za),VPr=i(Za),R6e=n(Za,"P",{});var Qla=s(R6e);XPr=r(Qla,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Qla.forEach(t),zPr=i(Za),Sn=n(Za,"P",{});var Z9=s(Sn);QPr=r(Z9,"The model class to instantiate is selected based on the "),P6e=n(Z9,"CODE",{});var Wla=s(P6e);WPr=r(Wla,"model_type"),Wla.forEach(t),UPr=r(Z9,` property of the config object (either
passed as an argument or loaded from `),B6e=n(Z9,"CODE",{});var Ula=s(B6e);HPr=r(Ula,"pretrained_model_name_or_path"),Ula.forEach(t),JPr=r(Z9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I6e=n(Z9,"CODE",{});var Hla=s(I6e);YPr=r(Hla,"pretrained_model_name_or_path"),Hla.forEach(t),ZPr=r(Z9,":"),Z9.forEach(t),KPr=i(Za),vt=n(Za,"UL",{});var gi=s(vt);g3=n(gi,"LI",{});var YJe=s(g3);N6e=n(YJe,"STRONG",{});var Jla=s(N6e);eBr=r(Jla,"beit"),Jla.forEach(t),oBr=r(YJe," \u2014 "),Qoe=n(YJe,"A",{href:!0});var Yla=s(Qoe);rBr=r(Yla,"BeitForSemanticSegmentation"),Yla.forEach(t),tBr=r(YJe," (BEiT model)"),YJe.forEach(t),aBr=i(gi),h3=n(gi,"LI",{});var ZJe=s(h3);q6e=n(ZJe,"STRONG",{});var Zla=s(q6e);nBr=r(Zla,"data2vec-vision"),Zla.forEach(t),sBr=r(ZJe," \u2014 "),Woe=n(ZJe,"A",{href:!0});var Kla=s(Woe);lBr=r(Kla,"Data2VecVisionForSemanticSegmentation"),Kla.forEach(t),iBr=r(ZJe," (Data2VecVision model)"),ZJe.forEach(t),dBr=i(gi),u3=n(gi,"LI",{});var KJe=s(u3);j6e=n(KJe,"STRONG",{});var eia=s(j6e);cBr=r(eia,"dpt"),eia.forEach(t),fBr=r(KJe," \u2014 "),Uoe=n(KJe,"A",{href:!0});var oia=s(Uoe);mBr=r(oia,"DPTForSemanticSegmentation"),oia.forEach(t),gBr=r(KJe," (DPT model)"),KJe.forEach(t),hBr=i(gi),p3=n(gi,"LI",{});var eYe=s(p3);D6e=n(eYe,"STRONG",{});var ria=s(D6e);uBr=r(ria,"mobilevit"),ria.forEach(t),pBr=r(eYe," \u2014 "),Hoe=n(eYe,"A",{href:!0});var tia=s(Hoe);_Br=r(tia,"MobileViTForSemanticSegmentation"),tia.forEach(t),vBr=r(eYe," (MobileViT model)"),eYe.forEach(t),bBr=i(gi),_3=n(gi,"LI",{});var oYe=s(_3);G6e=n(oYe,"STRONG",{});var aia=s(G6e);FBr=r(aia,"segformer"),aia.forEach(t),TBr=r(oYe," \u2014 "),Joe=n(oYe,"A",{href:!0});var nia=s(Joe);MBr=r(nia,"SegformerForSemanticSegmentation"),nia.forEach(t),EBr=r(oYe," (SegFormer model)"),oYe.forEach(t),gi.forEach(t),CBr=i(Za),v3=n(Za,"P",{});var rYe=s(v3);wBr=r(rYe,"The model is set in evaluation mode by default using "),O6e=n(rYe,"CODE",{});var sia=s(O6e);ABr=r(sia,"model.eval()"),sia.forEach(t),LBr=r(rYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),V6e=n(rYe,"CODE",{});var lia=s(V6e);yBr=r(lia,"model.train()"),lia.forEach(t),rYe.forEach(t),xBr=i(Za),T(b3.$$.fragment,Za),Za.forEach(t),mi.forEach(t),Iao=i(f),af=n(f,"H2",{class:!0});var olo=s(af);F3=n(olo,"A",{id:!0,class:!0,href:!0});var iia=s(F3);X6e=n(iia,"SPAN",{});var dia=s(X6e);T(aR.$$.fragment,dia),dia.forEach(t),iia.forEach(t),$Br=i(olo),z6e=n(olo,"SPAN",{});var cia=s(z6e);kBr=r(cia,"AutoModelForInstanceSegmentation"),cia.forEach(t),olo.forEach(t),Nao=i(f),ir=n(f,"DIV",{class:!0});var hi=s(ir);T(nR.$$.fragment,hi),SBr=i(hi),nf=n(hi,"P",{});var afe=s(nf);RBr=r(afe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Yoe=n(afe,"A",{href:!0});var fia=s(Yoe);PBr=r(fia,"from_pretrained()"),fia.forEach(t),BBr=r(afe," class method or the "),Zoe=n(afe,"A",{href:!0});var mia=s(Zoe);IBr=r(mia,"from_config()"),mia.forEach(t),NBr=r(afe,` class
method.`),afe.forEach(t),qBr=i(hi),sR=n(hi,"P",{});var rlo=s(sR);jBr=r(rlo,"This class cannot be instantiated directly using "),Q6e=n(rlo,"CODE",{});var gia=s(Q6e);DBr=r(gia,"__init__()"),gia.forEach(t),GBr=r(rlo," (throws an error)."),rlo.forEach(t),OBr=i(hi),Ht=n(hi,"DIV",{class:!0});var K9=s(Ht);T(lR.$$.fragment,K9),VBr=i(K9),W6e=n(K9,"P",{});var hia=s(W6e);XBr=r(hia,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),hia.forEach(t),zBr=i(K9),sf=n(K9,"P",{});var nfe=s(sf);QBr=r(nfe,`Note:
Loading a model from its configuration file does `),U6e=n(nfe,"STRONG",{});var uia=s(U6e);WBr=r(uia,"not"),uia.forEach(t),UBr=r(nfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Koe=n(nfe,"A",{href:!0});var pia=s(Koe);HBr=r(pia,"from_pretrained()"),pia.forEach(t),JBr=r(nfe," to load the model weights."),nfe.forEach(t),YBr=i(K9),T(T3.$$.fragment,K9),K9.forEach(t),ZBr=i(hi),Ao=n(hi,"DIV",{class:!0});var Ka=s(Ao);T(iR.$$.fragment,Ka),KBr=i(Ka),H6e=n(Ka,"P",{});var _ia=s(H6e);eIr=r(_ia,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),_ia.forEach(t),oIr=i(Ka),Rn=n(Ka,"P",{});var ex=s(Rn);rIr=r(ex,"The model class to instantiate is selected based on the "),J6e=n(ex,"CODE",{});var via=s(J6e);tIr=r(via,"model_type"),via.forEach(t),aIr=r(ex,` property of the config object (either
passed as an argument or loaded from `),Y6e=n(ex,"CODE",{});var bia=s(Y6e);nIr=r(bia,"pretrained_model_name_or_path"),bia.forEach(t),sIr=r(ex,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z6e=n(ex,"CODE",{});var Fia=s(Z6e);lIr=r(Fia,"pretrained_model_name_or_path"),Fia.forEach(t),iIr=r(ex,":"),ex.forEach(t),dIr=i(Ka),K6e=n(Ka,"UL",{});var Tia=s(K6e);M3=n(Tia,"LI",{});var tYe=s(M3);e7e=n(tYe,"STRONG",{});var Mia=s(e7e);cIr=r(Mia,"maskformer"),Mia.forEach(t),fIr=r(tYe," \u2014 "),ere=n(tYe,"A",{href:!0});var Eia=s(ere);mIr=r(Eia,"MaskFormerForInstanceSegmentation"),Eia.forEach(t),gIr=r(tYe," (MaskFormer model)"),tYe.forEach(t),Tia.forEach(t),hIr=i(Ka),E3=n(Ka,"P",{});var aYe=s(E3);uIr=r(aYe,"The model is set in evaluation mode by default using "),o7e=n(aYe,"CODE",{});var Cia=s(o7e);pIr=r(Cia,"model.eval()"),Cia.forEach(t),_Ir=r(aYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),r7e=n(aYe,"CODE",{});var wia=s(r7e);vIr=r(wia,"model.train()"),wia.forEach(t),aYe.forEach(t),bIr=i(Ka),T(C3.$$.fragment,Ka),Ka.forEach(t),hi.forEach(t),qao=i(f),lf=n(f,"H2",{class:!0});var tlo=s(lf);w3=n(tlo,"A",{id:!0,class:!0,href:!0});var Aia=s(w3);t7e=n(Aia,"SPAN",{});var Lia=s(t7e);T(dR.$$.fragment,Lia),Lia.forEach(t),Aia.forEach(t),FIr=i(tlo),a7e=n(tlo,"SPAN",{});var yia=s(a7e);TIr=r(yia,"AutoModelForZeroShotObjectDetection"),yia.forEach(t),tlo.forEach(t),jao=i(f),dr=n(f,"DIV",{class:!0});var ui=s(dr);T(cR.$$.fragment,ui),MIr=i(ui),df=n(ui,"P",{});var sfe=s(df);EIr=r(sfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),ore=n(sfe,"A",{href:!0});var xia=s(ore);CIr=r(xia,"from_pretrained()"),xia.forEach(t),wIr=r(sfe," class method or the "),rre=n(sfe,"A",{href:!0});var $ia=s(rre);AIr=r($ia,"from_config()"),$ia.forEach(t),LIr=r(sfe,` class
method.`),sfe.forEach(t),yIr=i(ui),fR=n(ui,"P",{});var alo=s(fR);xIr=r(alo,"This class cannot be instantiated directly using "),n7e=n(alo,"CODE",{});var kia=s(n7e);$Ir=r(kia,"__init__()"),kia.forEach(t),kIr=r(alo," (throws an error)."),alo.forEach(t),SIr=i(ui),Jt=n(ui,"DIV",{class:!0});var ox=s(Jt);T(mR.$$.fragment,ox),RIr=i(ox),s7e=n(ox,"P",{});var Sia=s(s7e);PIr=r(Sia,"Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),Sia.forEach(t),BIr=i(ox),cf=n(ox,"P",{});var lfe=s(cf);IIr=r(lfe,`Note:
Loading a model from its configuration file does `),l7e=n(lfe,"STRONG",{});var Ria=s(l7e);NIr=r(Ria,"not"),Ria.forEach(t),qIr=r(lfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),tre=n(lfe,"A",{href:!0});var Pia=s(tre);jIr=r(Pia,"from_pretrained()"),Pia.forEach(t),DIr=r(lfe," to load the model weights."),lfe.forEach(t),GIr=i(ox),T(A3.$$.fragment,ox),ox.forEach(t),OIr=i(ui),Lo=n(ui,"DIV",{class:!0});var en=s(Lo);T(gR.$$.fragment,en),VIr=i(en),i7e=n(en,"P",{});var Bia=s(i7e);XIr=r(Bia,"Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),Bia.forEach(t),zIr=i(en),Pn=n(en,"P",{});var rx=s(Pn);QIr=r(rx,"The model class to instantiate is selected based on the "),d7e=n(rx,"CODE",{});var Iia=s(d7e);WIr=r(Iia,"model_type"),Iia.forEach(t),UIr=r(rx,` property of the config object (either
passed as an argument or loaded from `),c7e=n(rx,"CODE",{});var Nia=s(c7e);HIr=r(Nia,"pretrained_model_name_or_path"),Nia.forEach(t),JIr=r(rx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f7e=n(rx,"CODE",{});var qia=s(f7e);YIr=r(qia,"pretrained_model_name_or_path"),qia.forEach(t),ZIr=r(rx,":"),rx.forEach(t),KIr=i(en),m7e=n(en,"UL",{});var jia=s(m7e);L3=n(jia,"LI",{});var nYe=s(L3);g7e=n(nYe,"STRONG",{});var Dia=s(g7e);eNr=r(Dia,"owlvit"),Dia.forEach(t),oNr=r(nYe," \u2014 "),are=n(nYe,"A",{href:!0});var Gia=s(are);rNr=r(Gia,"OwlViTForObjectDetection"),Gia.forEach(t),tNr=r(nYe," (OWL-ViT model)"),nYe.forEach(t),jia.forEach(t),aNr=i(en),y3=n(en,"P",{});var sYe=s(y3);nNr=r(sYe,"The model is set in evaluation mode by default using "),h7e=n(sYe,"CODE",{});var Oia=s(h7e);sNr=r(Oia,"model.eval()"),Oia.forEach(t),lNr=r(sYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u7e=n(sYe,"CODE",{});var Via=s(u7e);iNr=r(Via,"model.train()"),Via.forEach(t),sYe.forEach(t),dNr=i(en),T(x3.$$.fragment,en),en.forEach(t),ui.forEach(t),Dao=i(f),ff=n(f,"H2",{class:!0});var nlo=s(ff);$3=n(nlo,"A",{id:!0,class:!0,href:!0});var Xia=s($3);p7e=n(Xia,"SPAN",{});var zia=s(p7e);T(hR.$$.fragment,zia),zia.forEach(t),Xia.forEach(t),cNr=i(nlo),_7e=n(nlo,"SPAN",{});var Qia=s(_7e);fNr=r(Qia,"TFAutoModel"),Qia.forEach(t),nlo.forEach(t),Gao=i(f),cr=n(f,"DIV",{class:!0});var pi=s(cr);T(uR.$$.fragment,pi),mNr=i(pi),mf=n(pi,"P",{});var ife=s(mf);gNr=r(ife,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),nre=n(ife,"A",{href:!0});var Wia=s(nre);hNr=r(Wia,"from_pretrained()"),Wia.forEach(t),uNr=r(ife," class method or the "),sre=n(ife,"A",{href:!0});var Uia=s(sre);pNr=r(Uia,"from_config()"),Uia.forEach(t),_Nr=r(ife,` class
method.`),ife.forEach(t),vNr=i(pi),pR=n(pi,"P",{});var slo=s(pR);bNr=r(slo,"This class cannot be instantiated directly using "),v7e=n(slo,"CODE",{});var Hia=s(v7e);FNr=r(Hia,"__init__()"),Hia.forEach(t),TNr=r(slo," (throws an error)."),slo.forEach(t),MNr=i(pi),Yt=n(pi,"DIV",{class:!0});var tx=s(Yt);T(_R.$$.fragment,tx),ENr=i(tx),b7e=n(tx,"P",{});var Jia=s(b7e);CNr=r(Jia,"Instantiates one of the base model classes of the library from a configuration."),Jia.forEach(t),wNr=i(tx),gf=n(tx,"P",{});var dfe=s(gf);ANr=r(dfe,`Note:
Loading a model from its configuration file does `),F7e=n(dfe,"STRONG",{});var Yia=s(F7e);LNr=r(Yia,"not"),Yia.forEach(t),yNr=r(dfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),lre=n(dfe,"A",{href:!0});var Zia=s(lre);xNr=r(Zia,"from_pretrained()"),Zia.forEach(t),$Nr=r(dfe," to load the model weights."),dfe.forEach(t),kNr=i(tx),T(k3.$$.fragment,tx),tx.forEach(t),SNr=i(pi),Dr=n(pi,"DIV",{class:!0});var _i=s(Dr);T(vR.$$.fragment,_i),RNr=i(_i),T7e=n(_i,"P",{});var Kia=s(T7e);PNr=r(Kia,"Instantiate one of the base model classes of the library from a pretrained model."),Kia.forEach(t),BNr=i(_i),Bn=n(_i,"P",{});var ax=s(Bn);INr=r(ax,"The model class to instantiate is selected based on the "),M7e=n(ax,"CODE",{});var eda=s(M7e);NNr=r(eda,"model_type"),eda.forEach(t),qNr=r(ax,` property of the config object (either
passed as an argument or loaded from `),E7e=n(ax,"CODE",{});var oda=s(E7e);jNr=r(oda,"pretrained_model_name_or_path"),oda.forEach(t),DNr=r(ax,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C7e=n(ax,"CODE",{});var rda=s(C7e);GNr=r(rda,"pretrained_model_name_or_path"),rda.forEach(t),ONr=r(ax,":"),ax.forEach(t),VNr=i(_i),P=n(_i,"UL",{});var I=s(P);S3=n(I,"LI",{});var lYe=s(S3);w7e=n(lYe,"STRONG",{});var tda=s(w7e);XNr=r(tda,"albert"),tda.forEach(t),zNr=r(lYe," \u2014 "),ire=n(lYe,"A",{href:!0});var ada=s(ire);QNr=r(ada,"TFAlbertModel"),ada.forEach(t),WNr=r(lYe," (ALBERT model)"),lYe.forEach(t),UNr=i(I),R3=n(I,"LI",{});var iYe=s(R3);A7e=n(iYe,"STRONG",{});var nda=s(A7e);HNr=r(nda,"bart"),nda.forEach(t),JNr=r(iYe," \u2014 "),dre=n(iYe,"A",{href:!0});var sda=s(dre);YNr=r(sda,"TFBartModel"),sda.forEach(t),ZNr=r(iYe," (BART model)"),iYe.forEach(t),KNr=i(I),P3=n(I,"LI",{});var dYe=s(P3);L7e=n(dYe,"STRONG",{});var lda=s(L7e);eqr=r(lda,"bert"),lda.forEach(t),oqr=r(dYe," \u2014 "),cre=n(dYe,"A",{href:!0});var ida=s(cre);rqr=r(ida,"TFBertModel"),ida.forEach(t),tqr=r(dYe," (BERT model)"),dYe.forEach(t),aqr=i(I),B3=n(I,"LI",{});var cYe=s(B3);y7e=n(cYe,"STRONG",{});var dda=s(y7e);nqr=r(dda,"blenderbot"),dda.forEach(t),sqr=r(cYe," \u2014 "),fre=n(cYe,"A",{href:!0});var cda=s(fre);lqr=r(cda,"TFBlenderbotModel"),cda.forEach(t),iqr=r(cYe," (Blenderbot model)"),cYe.forEach(t),dqr=i(I),I3=n(I,"LI",{});var fYe=s(I3);x7e=n(fYe,"STRONG",{});var fda=s(x7e);cqr=r(fda,"blenderbot-small"),fda.forEach(t),fqr=r(fYe," \u2014 "),mre=n(fYe,"A",{href:!0});var mda=s(mre);mqr=r(mda,"TFBlenderbotSmallModel"),mda.forEach(t),gqr=r(fYe," (BlenderbotSmall model)"),fYe.forEach(t),hqr=i(I),N3=n(I,"LI",{});var mYe=s(N3);$7e=n(mYe,"STRONG",{});var gda=s($7e);uqr=r(gda,"camembert"),gda.forEach(t),pqr=r(mYe," \u2014 "),gre=n(mYe,"A",{href:!0});var hda=s(gre);_qr=r(hda,"TFCamembertModel"),hda.forEach(t),vqr=r(mYe," (CamemBERT model)"),mYe.forEach(t),bqr=i(I),q3=n(I,"LI",{});var gYe=s(q3);k7e=n(gYe,"STRONG",{});var uda=s(k7e);Fqr=r(uda,"clip"),uda.forEach(t),Tqr=r(gYe," \u2014 "),hre=n(gYe,"A",{href:!0});var pda=s(hre);Mqr=r(pda,"TFCLIPModel"),pda.forEach(t),Eqr=r(gYe," (CLIP model)"),gYe.forEach(t),Cqr=i(I),j3=n(I,"LI",{});var hYe=s(j3);S7e=n(hYe,"STRONG",{});var _da=s(S7e);wqr=r(_da,"convbert"),_da.forEach(t),Aqr=r(hYe," \u2014 "),ure=n(hYe,"A",{href:!0});var vda=s(ure);Lqr=r(vda,"TFConvBertModel"),vda.forEach(t),yqr=r(hYe," (ConvBERT model)"),hYe.forEach(t),xqr=i(I),D3=n(I,"LI",{});var uYe=s(D3);R7e=n(uYe,"STRONG",{});var bda=s(R7e);$qr=r(bda,"convnext"),bda.forEach(t),kqr=r(uYe," \u2014 "),pre=n(uYe,"A",{href:!0});var Fda=s(pre);Sqr=r(Fda,"TFConvNextModel"),Fda.forEach(t),Rqr=r(uYe," (ConvNeXT model)"),uYe.forEach(t),Pqr=i(I),G3=n(I,"LI",{});var pYe=s(G3);P7e=n(pYe,"STRONG",{});var Tda=s(P7e);Bqr=r(Tda,"ctrl"),Tda.forEach(t),Iqr=r(pYe," \u2014 "),_re=n(pYe,"A",{href:!0});var Mda=s(_re);Nqr=r(Mda,"TFCTRLModel"),Mda.forEach(t),qqr=r(pYe," (CTRL model)"),pYe.forEach(t),jqr=i(I),O3=n(I,"LI",{});var _Ye=s(O3);B7e=n(_Ye,"STRONG",{});var Eda=s(B7e);Dqr=r(Eda,"cvt"),Eda.forEach(t),Gqr=r(_Ye," \u2014 "),vre=n(_Ye,"A",{href:!0});var Cda=s(vre);Oqr=r(Cda,"TFCvtModel"),Cda.forEach(t),Vqr=r(_Ye," (CvT model)"),_Ye.forEach(t),Xqr=i(I),V3=n(I,"LI",{});var vYe=s(V3);I7e=n(vYe,"STRONG",{});var wda=s(I7e);zqr=r(wda,"data2vec-vision"),wda.forEach(t),Qqr=r(vYe," \u2014 "),bre=n(vYe,"A",{href:!0});var Ada=s(bre);Wqr=r(Ada,"TFData2VecVisionModel"),Ada.forEach(t),Uqr=r(vYe," (Data2VecVision model)"),vYe.forEach(t),Hqr=i(I),X3=n(I,"LI",{});var bYe=s(X3);N7e=n(bYe,"STRONG",{});var Lda=s(N7e);Jqr=r(Lda,"deberta"),Lda.forEach(t),Yqr=r(bYe," \u2014 "),Fre=n(bYe,"A",{href:!0});var yda=s(Fre);Zqr=r(yda,"TFDebertaModel"),yda.forEach(t),Kqr=r(bYe," (DeBERTa model)"),bYe.forEach(t),ejr=i(I),z3=n(I,"LI",{});var FYe=s(z3);q7e=n(FYe,"STRONG",{});var xda=s(q7e);ojr=r(xda,"deberta-v2"),xda.forEach(t),rjr=r(FYe," \u2014 "),Tre=n(FYe,"A",{href:!0});var $da=s(Tre);tjr=r($da,"TFDebertaV2Model"),$da.forEach(t),ajr=r(FYe," (DeBERTa-v2 model)"),FYe.forEach(t),njr=i(I),Q3=n(I,"LI",{});var TYe=s(Q3);j7e=n(TYe,"STRONG",{});var kda=s(j7e);sjr=r(kda,"deit"),kda.forEach(t),ljr=r(TYe," \u2014 "),Mre=n(TYe,"A",{href:!0});var Sda=s(Mre);ijr=r(Sda,"TFDeiTModel"),Sda.forEach(t),djr=r(TYe," (DeiT model)"),TYe.forEach(t),cjr=i(I),W3=n(I,"LI",{});var MYe=s(W3);D7e=n(MYe,"STRONG",{});var Rda=s(D7e);fjr=r(Rda,"distilbert"),Rda.forEach(t),mjr=r(MYe," \u2014 "),Ere=n(MYe,"A",{href:!0});var Pda=s(Ere);gjr=r(Pda,"TFDistilBertModel"),Pda.forEach(t),hjr=r(MYe," (DistilBERT model)"),MYe.forEach(t),ujr=i(I),U3=n(I,"LI",{});var EYe=s(U3);G7e=n(EYe,"STRONG",{});var Bda=s(G7e);pjr=r(Bda,"dpr"),Bda.forEach(t),_jr=r(EYe," \u2014 "),Cre=n(EYe,"A",{href:!0});var Ida=s(Cre);vjr=r(Ida,"TFDPRQuestionEncoder"),Ida.forEach(t),bjr=r(EYe," (DPR model)"),EYe.forEach(t),Fjr=i(I),H3=n(I,"LI",{});var CYe=s(H3);O7e=n(CYe,"STRONG",{});var Nda=s(O7e);Tjr=r(Nda,"electra"),Nda.forEach(t),Mjr=r(CYe," \u2014 "),wre=n(CYe,"A",{href:!0});var qda=s(wre);Ejr=r(qda,"TFElectraModel"),qda.forEach(t),Cjr=r(CYe," (ELECTRA model)"),CYe.forEach(t),wjr=i(I),J3=n(I,"LI",{});var wYe=s(J3);V7e=n(wYe,"STRONG",{});var jda=s(V7e);Ajr=r(jda,"esm"),jda.forEach(t),Ljr=r(wYe," \u2014 "),Are=n(wYe,"A",{href:!0});var Dda=s(Are);yjr=r(Dda,"TFEsmModel"),Dda.forEach(t),xjr=r(wYe," (ESM model)"),wYe.forEach(t),$jr=i(I),Y3=n(I,"LI",{});var AYe=s(Y3);X7e=n(AYe,"STRONG",{});var Gda=s(X7e);kjr=r(Gda,"flaubert"),Gda.forEach(t),Sjr=r(AYe," \u2014 "),Lre=n(AYe,"A",{href:!0});var Oda=s(Lre);Rjr=r(Oda,"TFFlaubertModel"),Oda.forEach(t),Pjr=r(AYe," (FlauBERT model)"),AYe.forEach(t),Bjr=i(I),Sl=n(I,"LI",{});var FN=s(Sl);z7e=n(FN,"STRONG",{});var Vda=s(z7e);Ijr=r(Vda,"funnel"),Vda.forEach(t),Njr=r(FN," \u2014 "),yre=n(FN,"A",{href:!0});var Xda=s(yre);qjr=r(Xda,"TFFunnelModel"),Xda.forEach(t),jjr=r(FN," or "),xre=n(FN,"A",{href:!0});var zda=s(xre);Djr=r(zda,"TFFunnelBaseModel"),zda.forEach(t),Gjr=r(FN," (Funnel Transformer model)"),FN.forEach(t),Ojr=i(I),Z3=n(I,"LI",{});var LYe=s(Z3);Q7e=n(LYe,"STRONG",{});var Qda=s(Q7e);Vjr=r(Qda,"gpt2"),Qda.forEach(t),Xjr=r(LYe," \u2014 "),$re=n(LYe,"A",{href:!0});var Wda=s($re);zjr=r(Wda,"TFGPT2Model"),Wda.forEach(t),Qjr=r(LYe," (OpenAI GPT-2 model)"),LYe.forEach(t),Wjr=i(I),K3=n(I,"LI",{});var yYe=s(K3);W7e=n(yYe,"STRONG",{});var Uda=s(W7e);Ujr=r(Uda,"gptj"),Uda.forEach(t),Hjr=r(yYe," \u2014 "),kre=n(yYe,"A",{href:!0});var Hda=s(kre);Jjr=r(Hda,"TFGPTJModel"),Hda.forEach(t),Yjr=r(yYe," (GPT-J model)"),yYe.forEach(t),Zjr=i(I),e5=n(I,"LI",{});var xYe=s(e5);U7e=n(xYe,"STRONG",{});var Jda=s(U7e);Kjr=r(Jda,"groupvit"),Jda.forEach(t),eDr=r(xYe," \u2014 "),Sre=n(xYe,"A",{href:!0});var Yda=s(Sre);oDr=r(Yda,"TFGroupViTModel"),Yda.forEach(t),rDr=r(xYe," (GroupViT model)"),xYe.forEach(t),tDr=i(I),o5=n(I,"LI",{});var $Ye=s(o5);H7e=n($Ye,"STRONG",{});var Zda=s(H7e);aDr=r(Zda,"hubert"),Zda.forEach(t),nDr=r($Ye," \u2014 "),Rre=n($Ye,"A",{href:!0});var Kda=s(Rre);sDr=r(Kda,"TFHubertModel"),Kda.forEach(t),lDr=r($Ye," (Hubert model)"),$Ye.forEach(t),iDr=i(I),r5=n(I,"LI",{});var kYe=s(r5);J7e=n(kYe,"STRONG",{});var eca=s(J7e);dDr=r(eca,"layoutlm"),eca.forEach(t),cDr=r(kYe," \u2014 "),Pre=n(kYe,"A",{href:!0});var oca=s(Pre);fDr=r(oca,"TFLayoutLMModel"),oca.forEach(t),mDr=r(kYe," (LayoutLM model)"),kYe.forEach(t),gDr=i(I),t5=n(I,"LI",{});var SYe=s(t5);Y7e=n(SYe,"STRONG",{});var rca=s(Y7e);hDr=r(rca,"layoutlmv3"),rca.forEach(t),uDr=r(SYe," \u2014 "),Bre=n(SYe,"A",{href:!0});var tca=s(Bre);pDr=r(tca,"TFLayoutLMv3Model"),tca.forEach(t),_Dr=r(SYe," (LayoutLMv3 model)"),SYe.forEach(t),vDr=i(I),a5=n(I,"LI",{});var RYe=s(a5);Z7e=n(RYe,"STRONG",{});var aca=s(Z7e);bDr=r(aca,"led"),aca.forEach(t),FDr=r(RYe," \u2014 "),Ire=n(RYe,"A",{href:!0});var nca=s(Ire);TDr=r(nca,"TFLEDModel"),nca.forEach(t),MDr=r(RYe," (LED model)"),RYe.forEach(t),EDr=i(I),n5=n(I,"LI",{});var PYe=s(n5);K7e=n(PYe,"STRONG",{});var sca=s(K7e);CDr=r(sca,"longformer"),sca.forEach(t),wDr=r(PYe," \u2014 "),Nre=n(PYe,"A",{href:!0});var lca=s(Nre);ADr=r(lca,"TFLongformerModel"),lca.forEach(t),LDr=r(PYe," (Longformer model)"),PYe.forEach(t),yDr=i(I),s5=n(I,"LI",{});var BYe=s(s5);e8e=n(BYe,"STRONG",{});var ica=s(e8e);xDr=r(ica,"lxmert"),ica.forEach(t),$Dr=r(BYe," \u2014 "),qre=n(BYe,"A",{href:!0});var dca=s(qre);kDr=r(dca,"TFLxmertModel"),dca.forEach(t),SDr=r(BYe," (LXMERT model)"),BYe.forEach(t),RDr=i(I),l5=n(I,"LI",{});var IYe=s(l5);o8e=n(IYe,"STRONG",{});var cca=s(o8e);PDr=r(cca,"marian"),cca.forEach(t),BDr=r(IYe," \u2014 "),jre=n(IYe,"A",{href:!0});var fca=s(jre);IDr=r(fca,"TFMarianModel"),fca.forEach(t),NDr=r(IYe," (Marian model)"),IYe.forEach(t),qDr=i(I),i5=n(I,"LI",{});var NYe=s(i5);r8e=n(NYe,"STRONG",{});var mca=s(r8e);jDr=r(mca,"mbart"),mca.forEach(t),DDr=r(NYe," \u2014 "),Dre=n(NYe,"A",{href:!0});var gca=s(Dre);GDr=r(gca,"TFMBartModel"),gca.forEach(t),ODr=r(NYe," (mBART model)"),NYe.forEach(t),VDr=i(I),d5=n(I,"LI",{});var qYe=s(d5);t8e=n(qYe,"STRONG",{});var hca=s(t8e);XDr=r(hca,"mobilebert"),hca.forEach(t),zDr=r(qYe," \u2014 "),Gre=n(qYe,"A",{href:!0});var uca=s(Gre);QDr=r(uca,"TFMobileBertModel"),uca.forEach(t),WDr=r(qYe," (MobileBERT model)"),qYe.forEach(t),UDr=i(I),c5=n(I,"LI",{});var jYe=s(c5);a8e=n(jYe,"STRONG",{});var pca=s(a8e);HDr=r(pca,"mobilevit"),pca.forEach(t),JDr=r(jYe," \u2014 "),Ore=n(jYe,"A",{href:!0});var _ca=s(Ore);YDr=r(_ca,"TFMobileViTModel"),_ca.forEach(t),ZDr=r(jYe," (MobileViT model)"),jYe.forEach(t),KDr=i(I),f5=n(I,"LI",{});var DYe=s(f5);n8e=n(DYe,"STRONG",{});var vca=s(n8e);eGr=r(vca,"mpnet"),vca.forEach(t),oGr=r(DYe," \u2014 "),Vre=n(DYe,"A",{href:!0});var bca=s(Vre);rGr=r(bca,"TFMPNetModel"),bca.forEach(t),tGr=r(DYe," (MPNet model)"),DYe.forEach(t),aGr=i(I),m5=n(I,"LI",{});var GYe=s(m5);s8e=n(GYe,"STRONG",{});var Fca=s(s8e);nGr=r(Fca,"mt5"),Fca.forEach(t),sGr=r(GYe," \u2014 "),Xre=n(GYe,"A",{href:!0});var Tca=s(Xre);lGr=r(Tca,"TFMT5Model"),Tca.forEach(t),iGr=r(GYe," (MT5 model)"),GYe.forEach(t),dGr=i(I),g5=n(I,"LI",{});var OYe=s(g5);l8e=n(OYe,"STRONG",{});var Mca=s(l8e);cGr=r(Mca,"openai-gpt"),Mca.forEach(t),fGr=r(OYe," \u2014 "),zre=n(OYe,"A",{href:!0});var Eca=s(zre);mGr=r(Eca,"TFOpenAIGPTModel"),Eca.forEach(t),gGr=r(OYe," (OpenAI GPT model)"),OYe.forEach(t),hGr=i(I),h5=n(I,"LI",{});var VYe=s(h5);i8e=n(VYe,"STRONG",{});var Cca=s(i8e);uGr=r(Cca,"opt"),Cca.forEach(t),pGr=r(VYe," \u2014 "),Qre=n(VYe,"A",{href:!0});var wca=s(Qre);_Gr=r(wca,"TFOPTModel"),wca.forEach(t),vGr=r(VYe," (OPT model)"),VYe.forEach(t),bGr=i(I),u5=n(I,"LI",{});var XYe=s(u5);d8e=n(XYe,"STRONG",{});var Aca=s(d8e);FGr=r(Aca,"pegasus"),Aca.forEach(t),TGr=r(XYe," \u2014 "),Wre=n(XYe,"A",{href:!0});var Lca=s(Wre);MGr=r(Lca,"TFPegasusModel"),Lca.forEach(t),EGr=r(XYe," (Pegasus model)"),XYe.forEach(t),CGr=i(I),p5=n(I,"LI",{});var zYe=s(p5);c8e=n(zYe,"STRONG",{});var yca=s(c8e);wGr=r(yca,"regnet"),yca.forEach(t),AGr=r(zYe," \u2014 "),Ure=n(zYe,"A",{href:!0});var xca=s(Ure);LGr=r(xca,"TFRegNetModel"),xca.forEach(t),yGr=r(zYe," (RegNet model)"),zYe.forEach(t),xGr=i(I),_5=n(I,"LI",{});var QYe=s(_5);f8e=n(QYe,"STRONG",{});var $ca=s(f8e);$Gr=r($ca,"rembert"),$ca.forEach(t),kGr=r(QYe," \u2014 "),Hre=n(QYe,"A",{href:!0});var kca=s(Hre);SGr=r(kca,"TFRemBertModel"),kca.forEach(t),RGr=r(QYe," (RemBERT model)"),QYe.forEach(t),PGr=i(I),v5=n(I,"LI",{});var WYe=s(v5);m8e=n(WYe,"STRONG",{});var Sca=s(m8e);BGr=r(Sca,"resnet"),Sca.forEach(t),IGr=r(WYe," \u2014 "),Jre=n(WYe,"A",{href:!0});var Rca=s(Jre);NGr=r(Rca,"TFResNetModel"),Rca.forEach(t),qGr=r(WYe," (ResNet model)"),WYe.forEach(t),jGr=i(I),b5=n(I,"LI",{});var UYe=s(b5);g8e=n(UYe,"STRONG",{});var Pca=s(g8e);DGr=r(Pca,"roberta"),Pca.forEach(t),GGr=r(UYe," \u2014 "),Yre=n(UYe,"A",{href:!0});var Bca=s(Yre);OGr=r(Bca,"TFRobertaModel"),Bca.forEach(t),VGr=r(UYe," (RoBERTa model)"),UYe.forEach(t),XGr=i(I),F5=n(I,"LI",{});var HYe=s(F5);h8e=n(HYe,"STRONG",{});var Ica=s(h8e);zGr=r(Ica,"roformer"),Ica.forEach(t),QGr=r(HYe," \u2014 "),Zre=n(HYe,"A",{href:!0});var Nca=s(Zre);WGr=r(Nca,"TFRoFormerModel"),Nca.forEach(t),UGr=r(HYe," (RoFormer model)"),HYe.forEach(t),HGr=i(I),T5=n(I,"LI",{});var JYe=s(T5);u8e=n(JYe,"STRONG",{});var qca=s(u8e);JGr=r(qca,"segformer"),qca.forEach(t),YGr=r(JYe," \u2014 "),Kre=n(JYe,"A",{href:!0});var jca=s(Kre);ZGr=r(jca,"TFSegformerModel"),jca.forEach(t),KGr=r(JYe," (SegFormer model)"),JYe.forEach(t),eOr=i(I),M5=n(I,"LI",{});var YYe=s(M5);p8e=n(YYe,"STRONG",{});var Dca=s(p8e);oOr=r(Dca,"speech_to_text"),Dca.forEach(t),rOr=r(YYe," \u2014 "),ete=n(YYe,"A",{href:!0});var Gca=s(ete);tOr=r(Gca,"TFSpeech2TextModel"),Gca.forEach(t),aOr=r(YYe," (Speech2Text model)"),YYe.forEach(t),nOr=i(I),E5=n(I,"LI",{});var ZYe=s(E5);_8e=n(ZYe,"STRONG",{});var Oca=s(_8e);sOr=r(Oca,"swin"),Oca.forEach(t),lOr=r(ZYe," \u2014 "),ote=n(ZYe,"A",{href:!0});var Vca=s(ote);iOr=r(Vca,"TFSwinModel"),Vca.forEach(t),dOr=r(ZYe," (Swin Transformer model)"),ZYe.forEach(t),cOr=i(I),C5=n(I,"LI",{});var KYe=s(C5);v8e=n(KYe,"STRONG",{});var Xca=s(v8e);fOr=r(Xca,"t5"),Xca.forEach(t),mOr=r(KYe," \u2014 "),rte=n(KYe,"A",{href:!0});var zca=s(rte);gOr=r(zca,"TFT5Model"),zca.forEach(t),hOr=r(KYe," (T5 model)"),KYe.forEach(t),uOr=i(I),w5=n(I,"LI",{});var eZe=s(w5);b8e=n(eZe,"STRONG",{});var Qca=s(b8e);pOr=r(Qca,"tapas"),Qca.forEach(t),_Or=r(eZe," \u2014 "),tte=n(eZe,"A",{href:!0});var Wca=s(tte);vOr=r(Wca,"TFTapasModel"),Wca.forEach(t),bOr=r(eZe," (TAPAS model)"),eZe.forEach(t),FOr=i(I),A5=n(I,"LI",{});var oZe=s(A5);F8e=n(oZe,"STRONG",{});var Uca=s(F8e);TOr=r(Uca,"transfo-xl"),Uca.forEach(t),MOr=r(oZe," \u2014 "),ate=n(oZe,"A",{href:!0});var Hca=s(ate);EOr=r(Hca,"TFTransfoXLModel"),Hca.forEach(t),COr=r(oZe," (Transformer-XL model)"),oZe.forEach(t),wOr=i(I),L5=n(I,"LI",{});var rZe=s(L5);T8e=n(rZe,"STRONG",{});var Jca=s(T8e);AOr=r(Jca,"vit"),Jca.forEach(t),LOr=r(rZe," \u2014 "),nte=n(rZe,"A",{href:!0});var Yca=s(nte);yOr=r(Yca,"TFViTModel"),Yca.forEach(t),xOr=r(rZe," (ViT model)"),rZe.forEach(t),$Or=i(I),y5=n(I,"LI",{});var tZe=s(y5);M8e=n(tZe,"STRONG",{});var Zca=s(M8e);kOr=r(Zca,"vit_mae"),Zca.forEach(t),SOr=r(tZe," \u2014 "),ste=n(tZe,"A",{href:!0});var Kca=s(ste);ROr=r(Kca,"TFViTMAEModel"),Kca.forEach(t),POr=r(tZe," (ViTMAE model)"),tZe.forEach(t),BOr=i(I),x5=n(I,"LI",{});var aZe=s(x5);E8e=n(aZe,"STRONG",{});var efa=s(E8e);IOr=r(efa,"wav2vec2"),efa.forEach(t),NOr=r(aZe," \u2014 "),lte=n(aZe,"A",{href:!0});var ofa=s(lte);qOr=r(ofa,"TFWav2Vec2Model"),ofa.forEach(t),jOr=r(aZe," (Wav2Vec2 model)"),aZe.forEach(t),DOr=i(I),$5=n(I,"LI",{});var nZe=s($5);C8e=n(nZe,"STRONG",{});var rfa=s(C8e);GOr=r(rfa,"whisper"),rfa.forEach(t),OOr=r(nZe," \u2014 "),ite=n(nZe,"A",{href:!0});var tfa=s(ite);VOr=r(tfa,"TFWhisperModel"),tfa.forEach(t),XOr=r(nZe," (Whisper model)"),nZe.forEach(t),zOr=i(I),k5=n(I,"LI",{});var sZe=s(k5);w8e=n(sZe,"STRONG",{});var afa=s(w8e);QOr=r(afa,"xglm"),afa.forEach(t),WOr=r(sZe," \u2014 "),dte=n(sZe,"A",{href:!0});var nfa=s(dte);UOr=r(nfa,"TFXGLMModel"),nfa.forEach(t),HOr=r(sZe," (XGLM model)"),sZe.forEach(t),JOr=i(I),S5=n(I,"LI",{});var lZe=s(S5);A8e=n(lZe,"STRONG",{});var sfa=s(A8e);YOr=r(sfa,"xlm"),sfa.forEach(t),ZOr=r(lZe," \u2014 "),cte=n(lZe,"A",{href:!0});var lfa=s(cte);KOr=r(lfa,"TFXLMModel"),lfa.forEach(t),eVr=r(lZe," (XLM model)"),lZe.forEach(t),oVr=i(I),R5=n(I,"LI",{});var iZe=s(R5);L8e=n(iZe,"STRONG",{});var ifa=s(L8e);rVr=r(ifa,"xlm-roberta"),ifa.forEach(t),tVr=r(iZe," \u2014 "),fte=n(iZe,"A",{href:!0});var dfa=s(fte);aVr=r(dfa,"TFXLMRobertaModel"),dfa.forEach(t),nVr=r(iZe," (XLM-RoBERTa model)"),iZe.forEach(t),sVr=i(I),P5=n(I,"LI",{});var dZe=s(P5);y8e=n(dZe,"STRONG",{});var cfa=s(y8e);lVr=r(cfa,"xlnet"),cfa.forEach(t),iVr=r(dZe," \u2014 "),mte=n(dZe,"A",{href:!0});var ffa=s(mte);dVr=r(ffa,"TFXLNetModel"),ffa.forEach(t),cVr=r(dZe," (XLNet model)"),dZe.forEach(t),I.forEach(t),fVr=i(_i),T(B5.$$.fragment,_i),_i.forEach(t),pi.forEach(t),Oao=i(f),hf=n(f,"H2",{class:!0});var llo=s(hf);I5=n(llo,"A",{id:!0,class:!0,href:!0});var mfa=s(I5);x8e=n(mfa,"SPAN",{});var gfa=s(x8e);T(bR.$$.fragment,gfa),gfa.forEach(t),mfa.forEach(t),mVr=i(llo),$8e=n(llo,"SPAN",{});var hfa=s($8e);gVr=r(hfa,"TFAutoModelForPreTraining"),hfa.forEach(t),llo.forEach(t),Vao=i(f),fr=n(f,"DIV",{class:!0});var vi=s(fr);T(FR.$$.fragment,vi),hVr=i(vi),uf=n(vi,"P",{});var cfe=s(uf);uVr=r(cfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),gte=n(cfe,"A",{href:!0});var ufa=s(gte);pVr=r(ufa,"from_pretrained()"),ufa.forEach(t),_Vr=r(cfe," class method or the "),hte=n(cfe,"A",{href:!0});var pfa=s(hte);vVr=r(pfa,"from_config()"),pfa.forEach(t),bVr=r(cfe,` class
method.`),cfe.forEach(t),FVr=i(vi),TR=n(vi,"P",{});var ilo=s(TR);TVr=r(ilo,"This class cannot be instantiated directly using "),k8e=n(ilo,"CODE",{});var _fa=s(k8e);MVr=r(_fa,"__init__()"),_fa.forEach(t),EVr=r(ilo," (throws an error)."),ilo.forEach(t),CVr=i(vi),Zt=n(vi,"DIV",{class:!0});var nx=s(Zt);T(MR.$$.fragment,nx),wVr=i(nx),S8e=n(nx,"P",{});var vfa=s(S8e);AVr=r(vfa,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),vfa.forEach(t),LVr=i(nx),pf=n(nx,"P",{});var ffe=s(pf);yVr=r(ffe,`Note:
Loading a model from its configuration file does `),R8e=n(ffe,"STRONG",{});var bfa=s(R8e);xVr=r(bfa,"not"),bfa.forEach(t),$Vr=r(ffe,` load the model weights. It only affects the
model\u2019s configuration. Use `),ute=n(ffe,"A",{href:!0});var Ffa=s(ute);kVr=r(Ffa,"from_pretrained()"),Ffa.forEach(t),SVr=r(ffe," to load the model weights."),ffe.forEach(t),RVr=i(nx),T(N5.$$.fragment,nx),nx.forEach(t),PVr=i(vi),Gr=n(vi,"DIV",{class:!0});var bi=s(Gr);T(ER.$$.fragment,bi),BVr=i(bi),P8e=n(bi,"P",{});var Tfa=s(P8e);IVr=r(Tfa,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Tfa.forEach(t),NVr=i(bi),In=n(bi,"P",{});var sx=s(In);qVr=r(sx,"The model class to instantiate is selected based on the "),B8e=n(sx,"CODE",{});var Mfa=s(B8e);jVr=r(Mfa,"model_type"),Mfa.forEach(t),DVr=r(sx,` property of the config object (either
passed as an argument or loaded from `),I8e=n(sx,"CODE",{});var Efa=s(I8e);GVr=r(Efa,"pretrained_model_name_or_path"),Efa.forEach(t),OVr=r(sx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N8e=n(sx,"CODE",{});var Cfa=s(N8e);VVr=r(Cfa,"pretrained_model_name_or_path"),Cfa.forEach(t),XVr=r(sx,":"),sx.forEach(t),zVr=i(bi),se=n(bi,"UL",{});var de=s(se);q5=n(de,"LI",{});var cZe=s(q5);q8e=n(cZe,"STRONG",{});var wfa=s(q8e);QVr=r(wfa,"albert"),wfa.forEach(t),WVr=r(cZe," \u2014 "),pte=n(cZe,"A",{href:!0});var Afa=s(pte);UVr=r(Afa,"TFAlbertForPreTraining"),Afa.forEach(t),HVr=r(cZe," (ALBERT model)"),cZe.forEach(t),JVr=i(de),j5=n(de,"LI",{});var fZe=s(j5);j8e=n(fZe,"STRONG",{});var Lfa=s(j8e);YVr=r(Lfa,"bart"),Lfa.forEach(t),ZVr=r(fZe," \u2014 "),_te=n(fZe,"A",{href:!0});var yfa=s(_te);KVr=r(yfa,"TFBartForConditionalGeneration"),yfa.forEach(t),eXr=r(fZe," (BART model)"),fZe.forEach(t),oXr=i(de),D5=n(de,"LI",{});var mZe=s(D5);D8e=n(mZe,"STRONG",{});var xfa=s(D8e);rXr=r(xfa,"bert"),xfa.forEach(t),tXr=r(mZe," \u2014 "),vte=n(mZe,"A",{href:!0});var $fa=s(vte);aXr=r($fa,"TFBertForPreTraining"),$fa.forEach(t),nXr=r(mZe," (BERT model)"),mZe.forEach(t),sXr=i(de),G5=n(de,"LI",{});var gZe=s(G5);G8e=n(gZe,"STRONG",{});var kfa=s(G8e);lXr=r(kfa,"camembert"),kfa.forEach(t),iXr=r(gZe," \u2014 "),bte=n(gZe,"A",{href:!0});var Sfa=s(bte);dXr=r(Sfa,"TFCamembertForMaskedLM"),Sfa.forEach(t),cXr=r(gZe," (CamemBERT model)"),gZe.forEach(t),fXr=i(de),O5=n(de,"LI",{});var hZe=s(O5);O8e=n(hZe,"STRONG",{});var Rfa=s(O8e);mXr=r(Rfa,"ctrl"),Rfa.forEach(t),gXr=r(hZe," \u2014 "),Fte=n(hZe,"A",{href:!0});var Pfa=s(Fte);hXr=r(Pfa,"TFCTRLLMHeadModel"),Pfa.forEach(t),uXr=r(hZe," (CTRL model)"),hZe.forEach(t),pXr=i(de),V5=n(de,"LI",{});var uZe=s(V5);V8e=n(uZe,"STRONG",{});var Bfa=s(V8e);_Xr=r(Bfa,"distilbert"),Bfa.forEach(t),vXr=r(uZe," \u2014 "),Tte=n(uZe,"A",{href:!0});var Ifa=s(Tte);bXr=r(Ifa,"TFDistilBertForMaskedLM"),Ifa.forEach(t),FXr=r(uZe," (DistilBERT model)"),uZe.forEach(t),TXr=i(de),X5=n(de,"LI",{});var pZe=s(X5);X8e=n(pZe,"STRONG",{});var Nfa=s(X8e);MXr=r(Nfa,"electra"),Nfa.forEach(t),EXr=r(pZe," \u2014 "),Mte=n(pZe,"A",{href:!0});var qfa=s(Mte);CXr=r(qfa,"TFElectraForPreTraining"),qfa.forEach(t),wXr=r(pZe," (ELECTRA model)"),pZe.forEach(t),AXr=i(de),z5=n(de,"LI",{});var _Ze=s(z5);z8e=n(_Ze,"STRONG",{});var jfa=s(z8e);LXr=r(jfa,"flaubert"),jfa.forEach(t),yXr=r(_Ze," \u2014 "),Ete=n(_Ze,"A",{href:!0});var Dfa=s(Ete);xXr=r(Dfa,"TFFlaubertWithLMHeadModel"),Dfa.forEach(t),$Xr=r(_Ze," (FlauBERT model)"),_Ze.forEach(t),kXr=i(de),Q5=n(de,"LI",{});var vZe=s(Q5);Q8e=n(vZe,"STRONG",{});var Gfa=s(Q8e);SXr=r(Gfa,"funnel"),Gfa.forEach(t),RXr=r(vZe," \u2014 "),Cte=n(vZe,"A",{href:!0});var Ofa=s(Cte);PXr=r(Ofa,"TFFunnelForPreTraining"),Ofa.forEach(t),BXr=r(vZe," (Funnel Transformer model)"),vZe.forEach(t),IXr=i(de),W5=n(de,"LI",{});var bZe=s(W5);W8e=n(bZe,"STRONG",{});var Vfa=s(W8e);NXr=r(Vfa,"gpt2"),Vfa.forEach(t),qXr=r(bZe," \u2014 "),wte=n(bZe,"A",{href:!0});var Xfa=s(wte);jXr=r(Xfa,"TFGPT2LMHeadModel"),Xfa.forEach(t),DXr=r(bZe," (OpenAI GPT-2 model)"),bZe.forEach(t),GXr=i(de),U5=n(de,"LI",{});var FZe=s(U5);U8e=n(FZe,"STRONG",{});var zfa=s(U8e);OXr=r(zfa,"layoutlm"),zfa.forEach(t),VXr=r(FZe," \u2014 "),Ate=n(FZe,"A",{href:!0});var Qfa=s(Ate);XXr=r(Qfa,"TFLayoutLMForMaskedLM"),Qfa.forEach(t),zXr=r(FZe," (LayoutLM model)"),FZe.forEach(t),QXr=i(de),H5=n(de,"LI",{});var TZe=s(H5);H8e=n(TZe,"STRONG",{});var Wfa=s(H8e);WXr=r(Wfa,"lxmert"),Wfa.forEach(t),UXr=r(TZe," \u2014 "),Lte=n(TZe,"A",{href:!0});var Ufa=s(Lte);HXr=r(Ufa,"TFLxmertForPreTraining"),Ufa.forEach(t),JXr=r(TZe," (LXMERT model)"),TZe.forEach(t),YXr=i(de),J5=n(de,"LI",{});var MZe=s(J5);J8e=n(MZe,"STRONG",{});var Hfa=s(J8e);ZXr=r(Hfa,"mobilebert"),Hfa.forEach(t),KXr=r(MZe," \u2014 "),yte=n(MZe,"A",{href:!0});var Jfa=s(yte);ezr=r(Jfa,"TFMobileBertForPreTraining"),Jfa.forEach(t),ozr=r(MZe," (MobileBERT model)"),MZe.forEach(t),rzr=i(de),Y5=n(de,"LI",{});var EZe=s(Y5);Y8e=n(EZe,"STRONG",{});var Yfa=s(Y8e);tzr=r(Yfa,"mpnet"),Yfa.forEach(t),azr=r(EZe," \u2014 "),xte=n(EZe,"A",{href:!0});var Zfa=s(xte);nzr=r(Zfa,"TFMPNetForMaskedLM"),Zfa.forEach(t),szr=r(EZe," (MPNet model)"),EZe.forEach(t),lzr=i(de),Z5=n(de,"LI",{});var CZe=s(Z5);Z8e=n(CZe,"STRONG",{});var Kfa=s(Z8e);izr=r(Kfa,"openai-gpt"),Kfa.forEach(t),dzr=r(CZe," \u2014 "),$te=n(CZe,"A",{href:!0});var ema=s($te);czr=r(ema,"TFOpenAIGPTLMHeadModel"),ema.forEach(t),fzr=r(CZe," (OpenAI GPT model)"),CZe.forEach(t),mzr=i(de),K5=n(de,"LI",{});var wZe=s(K5);K8e=n(wZe,"STRONG",{});var oma=s(K8e);gzr=r(oma,"roberta"),oma.forEach(t),hzr=r(wZe," \u2014 "),kte=n(wZe,"A",{href:!0});var rma=s(kte);uzr=r(rma,"TFRobertaForMaskedLM"),rma.forEach(t),pzr=r(wZe," (RoBERTa model)"),wZe.forEach(t),_zr=i(de),ew=n(de,"LI",{});var AZe=s(ew);eLe=n(AZe,"STRONG",{});var tma=s(eLe);vzr=r(tma,"t5"),tma.forEach(t),bzr=r(AZe," \u2014 "),Ste=n(AZe,"A",{href:!0});var ama=s(Ste);Fzr=r(ama,"TFT5ForConditionalGeneration"),ama.forEach(t),Tzr=r(AZe," (T5 model)"),AZe.forEach(t),Mzr=i(de),ow=n(de,"LI",{});var LZe=s(ow);oLe=n(LZe,"STRONG",{});var nma=s(oLe);Ezr=r(nma,"tapas"),nma.forEach(t),Czr=r(LZe," \u2014 "),Rte=n(LZe,"A",{href:!0});var sma=s(Rte);wzr=r(sma,"TFTapasForMaskedLM"),sma.forEach(t),Azr=r(LZe," (TAPAS model)"),LZe.forEach(t),Lzr=i(de),rw=n(de,"LI",{});var yZe=s(rw);rLe=n(yZe,"STRONG",{});var lma=s(rLe);yzr=r(lma,"transfo-xl"),lma.forEach(t),xzr=r(yZe," \u2014 "),Pte=n(yZe,"A",{href:!0});var ima=s(Pte);$zr=r(ima,"TFTransfoXLLMHeadModel"),ima.forEach(t),kzr=r(yZe," (Transformer-XL model)"),yZe.forEach(t),Szr=i(de),tw=n(de,"LI",{});var xZe=s(tw);tLe=n(xZe,"STRONG",{});var dma=s(tLe);Rzr=r(dma,"vit_mae"),dma.forEach(t),Pzr=r(xZe," \u2014 "),Bte=n(xZe,"A",{href:!0});var cma=s(Bte);Bzr=r(cma,"TFViTMAEForPreTraining"),cma.forEach(t),Izr=r(xZe," (ViTMAE model)"),xZe.forEach(t),Nzr=i(de),aw=n(de,"LI",{});var $Ze=s(aw);aLe=n($Ze,"STRONG",{});var fma=s(aLe);qzr=r(fma,"xlm"),fma.forEach(t),jzr=r($Ze," \u2014 "),Ite=n($Ze,"A",{href:!0});var mma=s(Ite);Dzr=r(mma,"TFXLMWithLMHeadModel"),mma.forEach(t),Gzr=r($Ze," (XLM model)"),$Ze.forEach(t),Ozr=i(de),nw=n(de,"LI",{});var kZe=s(nw);nLe=n(kZe,"STRONG",{});var gma=s(nLe);Vzr=r(gma,"xlm-roberta"),gma.forEach(t),Xzr=r(kZe," \u2014 "),Nte=n(kZe,"A",{href:!0});var hma=s(Nte);zzr=r(hma,"TFXLMRobertaForMaskedLM"),hma.forEach(t),Qzr=r(kZe," (XLM-RoBERTa model)"),kZe.forEach(t),Wzr=i(de),sw=n(de,"LI",{});var SZe=s(sw);sLe=n(SZe,"STRONG",{});var uma=s(sLe);Uzr=r(uma,"xlnet"),uma.forEach(t),Hzr=r(SZe," \u2014 "),qte=n(SZe,"A",{href:!0});var pma=s(qte);Jzr=r(pma,"TFXLNetLMHeadModel"),pma.forEach(t),Yzr=r(SZe," (XLNet model)"),SZe.forEach(t),de.forEach(t),Zzr=i(bi),T(lw.$$.fragment,bi),bi.forEach(t),vi.forEach(t),Xao=i(f),_f=n(f,"H2",{class:!0});var dlo=s(_f);iw=n(dlo,"A",{id:!0,class:!0,href:!0});var _ma=s(iw);lLe=n(_ma,"SPAN",{});var vma=s(lLe);T(CR.$$.fragment,vma),vma.forEach(t),_ma.forEach(t),Kzr=i(dlo),iLe=n(dlo,"SPAN",{});var bma=s(iLe);eQr=r(bma,"TFAutoModelForCausalLM"),bma.forEach(t),dlo.forEach(t),zao=i(f),mr=n(f,"DIV",{class:!0});var Fi=s(mr);T(wR.$$.fragment,Fi),oQr=i(Fi),vf=n(Fi,"P",{});var mfe=s(vf);rQr=r(mfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),jte=n(mfe,"A",{href:!0});var Fma=s(jte);tQr=r(Fma,"from_pretrained()"),Fma.forEach(t),aQr=r(mfe," class method or the "),Dte=n(mfe,"A",{href:!0});var Tma=s(Dte);nQr=r(Tma,"from_config()"),Tma.forEach(t),sQr=r(mfe,` class
method.`),mfe.forEach(t),lQr=i(Fi),AR=n(Fi,"P",{});var clo=s(AR);iQr=r(clo,"This class cannot be instantiated directly using "),dLe=n(clo,"CODE",{});var Mma=s(dLe);dQr=r(Mma,"__init__()"),Mma.forEach(t),cQr=r(clo," (throws an error)."),clo.forEach(t),fQr=i(Fi),Kt=n(Fi,"DIV",{class:!0});var lx=s(Kt);T(LR.$$.fragment,lx),mQr=i(lx),cLe=n(lx,"P",{});var Ema=s(cLe);gQr=r(Ema,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Ema.forEach(t),hQr=i(lx),bf=n(lx,"P",{});var gfe=s(bf);uQr=r(gfe,`Note:
Loading a model from its configuration file does `),fLe=n(gfe,"STRONG",{});var Cma=s(fLe);pQr=r(Cma,"not"),Cma.forEach(t),_Qr=r(gfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Gte=n(gfe,"A",{href:!0});var wma=s(Gte);vQr=r(wma,"from_pretrained()"),wma.forEach(t),bQr=r(gfe," to load the model weights."),gfe.forEach(t),FQr=i(lx),T(dw.$$.fragment,lx),lx.forEach(t),TQr=i(Fi),Or=n(Fi,"DIV",{class:!0});var Ti=s(Or);T(yR.$$.fragment,Ti),MQr=i(Ti),mLe=n(Ti,"P",{});var Ama=s(mLe);EQr=r(Ama,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Ama.forEach(t),CQr=i(Ti),Nn=n(Ti,"P",{});var ix=s(Nn);wQr=r(ix,"The model class to instantiate is selected based on the "),gLe=n(ix,"CODE",{});var Lma=s(gLe);AQr=r(Lma,"model_type"),Lma.forEach(t),LQr=r(ix,` property of the config object (either
passed as an argument or loaded from `),hLe=n(ix,"CODE",{});var yma=s(hLe);yQr=r(yma,"pretrained_model_name_or_path"),yma.forEach(t),xQr=r(ix,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uLe=n(ix,"CODE",{});var xma=s(uLe);$Qr=r(xma,"pretrained_model_name_or_path"),xma.forEach(t),kQr=r(ix,":"),ix.forEach(t),SQr=i(Ti),Me=n(Ti,"UL",{});var Ce=s(Me);cw=n(Ce,"LI",{});var RZe=s(cw);pLe=n(RZe,"STRONG",{});var $ma=s(pLe);RQr=r($ma,"bert"),$ma.forEach(t),PQr=r(RZe," \u2014 "),Ote=n(RZe,"A",{href:!0});var kma=s(Ote);BQr=r(kma,"TFBertLMHeadModel"),kma.forEach(t),IQr=r(RZe," (BERT model)"),RZe.forEach(t),NQr=i(Ce),fw=n(Ce,"LI",{});var PZe=s(fw);_Le=n(PZe,"STRONG",{});var Sma=s(_Le);qQr=r(Sma,"camembert"),Sma.forEach(t),jQr=r(PZe," \u2014 "),Vte=n(PZe,"A",{href:!0});var Rma=s(Vte);DQr=r(Rma,"TFCamembertForCausalLM"),Rma.forEach(t),GQr=r(PZe," (CamemBERT model)"),PZe.forEach(t),OQr=i(Ce),mw=n(Ce,"LI",{});var BZe=s(mw);vLe=n(BZe,"STRONG",{});var Pma=s(vLe);VQr=r(Pma,"ctrl"),Pma.forEach(t),XQr=r(BZe," \u2014 "),Xte=n(BZe,"A",{href:!0});var Bma=s(Xte);zQr=r(Bma,"TFCTRLLMHeadModel"),Bma.forEach(t),QQr=r(BZe," (CTRL model)"),BZe.forEach(t),WQr=i(Ce),gw=n(Ce,"LI",{});var IZe=s(gw);bLe=n(IZe,"STRONG",{});var Ima=s(bLe);UQr=r(Ima,"gpt2"),Ima.forEach(t),HQr=r(IZe," \u2014 "),zte=n(IZe,"A",{href:!0});var Nma=s(zte);JQr=r(Nma,"TFGPT2LMHeadModel"),Nma.forEach(t),YQr=r(IZe," (OpenAI GPT-2 model)"),IZe.forEach(t),ZQr=i(Ce),hw=n(Ce,"LI",{});var NZe=s(hw);FLe=n(NZe,"STRONG",{});var qma=s(FLe);KQr=r(qma,"gptj"),qma.forEach(t),eWr=r(NZe," \u2014 "),Qte=n(NZe,"A",{href:!0});var jma=s(Qte);oWr=r(jma,"TFGPTJForCausalLM"),jma.forEach(t),rWr=r(NZe," (GPT-J model)"),NZe.forEach(t),tWr=i(Ce),uw=n(Ce,"LI",{});var qZe=s(uw);TLe=n(qZe,"STRONG",{});var Dma=s(TLe);aWr=r(Dma,"openai-gpt"),Dma.forEach(t),nWr=r(qZe," \u2014 "),Wte=n(qZe,"A",{href:!0});var Gma=s(Wte);sWr=r(Gma,"TFOpenAIGPTLMHeadModel"),Gma.forEach(t),lWr=r(qZe," (OpenAI GPT model)"),qZe.forEach(t),iWr=i(Ce),pw=n(Ce,"LI",{});var jZe=s(pw);MLe=n(jZe,"STRONG",{});var Oma=s(MLe);dWr=r(Oma,"opt"),Oma.forEach(t),cWr=r(jZe," \u2014 "),Ute=n(jZe,"A",{href:!0});var Vma=s(Ute);fWr=r(Vma,"TFOPTForCausalLM"),Vma.forEach(t),mWr=r(jZe," (OPT model)"),jZe.forEach(t),gWr=i(Ce),_w=n(Ce,"LI",{});var DZe=s(_w);ELe=n(DZe,"STRONG",{});var Xma=s(ELe);hWr=r(Xma,"rembert"),Xma.forEach(t),uWr=r(DZe," \u2014 "),Hte=n(DZe,"A",{href:!0});var zma=s(Hte);pWr=r(zma,"TFRemBertForCausalLM"),zma.forEach(t),_Wr=r(DZe," (RemBERT model)"),DZe.forEach(t),vWr=i(Ce),vw=n(Ce,"LI",{});var GZe=s(vw);CLe=n(GZe,"STRONG",{});var Qma=s(CLe);bWr=r(Qma,"roberta"),Qma.forEach(t),FWr=r(GZe," \u2014 "),Jte=n(GZe,"A",{href:!0});var Wma=s(Jte);TWr=r(Wma,"TFRobertaForCausalLM"),Wma.forEach(t),MWr=r(GZe," (RoBERTa model)"),GZe.forEach(t),EWr=i(Ce),bw=n(Ce,"LI",{});var OZe=s(bw);wLe=n(OZe,"STRONG",{});var Uma=s(wLe);CWr=r(Uma,"roformer"),Uma.forEach(t),wWr=r(OZe," \u2014 "),Yte=n(OZe,"A",{href:!0});var Hma=s(Yte);AWr=r(Hma,"TFRoFormerForCausalLM"),Hma.forEach(t),LWr=r(OZe," (RoFormer model)"),OZe.forEach(t),yWr=i(Ce),Fw=n(Ce,"LI",{});var VZe=s(Fw);ALe=n(VZe,"STRONG",{});var Jma=s(ALe);xWr=r(Jma,"transfo-xl"),Jma.forEach(t),$Wr=r(VZe," \u2014 "),Zte=n(VZe,"A",{href:!0});var Yma=s(Zte);kWr=r(Yma,"TFTransfoXLLMHeadModel"),Yma.forEach(t),SWr=r(VZe," (Transformer-XL model)"),VZe.forEach(t),RWr=i(Ce),Tw=n(Ce,"LI",{});var XZe=s(Tw);LLe=n(XZe,"STRONG",{});var Zma=s(LLe);PWr=r(Zma,"xglm"),Zma.forEach(t),BWr=r(XZe," \u2014 "),Kte=n(XZe,"A",{href:!0});var Kma=s(Kte);IWr=r(Kma,"TFXGLMForCausalLM"),Kma.forEach(t),NWr=r(XZe," (XGLM model)"),XZe.forEach(t),qWr=i(Ce),Mw=n(Ce,"LI",{});var zZe=s(Mw);yLe=n(zZe,"STRONG",{});var ega=s(yLe);jWr=r(ega,"xlm"),ega.forEach(t),DWr=r(zZe," \u2014 "),eae=n(zZe,"A",{href:!0});var oga=s(eae);GWr=r(oga,"TFXLMWithLMHeadModel"),oga.forEach(t),OWr=r(zZe," (XLM model)"),zZe.forEach(t),VWr=i(Ce),Ew=n(Ce,"LI",{});var QZe=s(Ew);xLe=n(QZe,"STRONG",{});var rga=s(xLe);XWr=r(rga,"xlnet"),rga.forEach(t),zWr=r(QZe," \u2014 "),oae=n(QZe,"A",{href:!0});var tga=s(oae);QWr=r(tga,"TFXLNetLMHeadModel"),tga.forEach(t),WWr=r(QZe," (XLNet model)"),QZe.forEach(t),Ce.forEach(t),UWr=i(Ti),T(Cw.$$.fragment,Ti),Ti.forEach(t),Fi.forEach(t),Qao=i(f),Ff=n(f,"H2",{class:!0});var flo=s(Ff);ww=n(flo,"A",{id:!0,class:!0,href:!0});var aga=s(ww);$Le=n(aga,"SPAN",{});var nga=s($Le);T(xR.$$.fragment,nga),nga.forEach(t),aga.forEach(t),HWr=i(flo),kLe=n(flo,"SPAN",{});var sga=s(kLe);JWr=r(sga,"TFAutoModelForImageClassification"),sga.forEach(t),flo.forEach(t),Wao=i(f),gr=n(f,"DIV",{class:!0});var Mi=s(gr);T($R.$$.fragment,Mi),YWr=i(Mi),Tf=n(Mi,"P",{});var hfe=s(Tf);ZWr=r(hfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),rae=n(hfe,"A",{href:!0});var lga=s(rae);KWr=r(lga,"from_pretrained()"),lga.forEach(t),eUr=r(hfe," class method or the "),tae=n(hfe,"A",{href:!0});var iga=s(tae);oUr=r(iga,"from_config()"),iga.forEach(t),rUr=r(hfe,` class
method.`),hfe.forEach(t),tUr=i(Mi),kR=n(Mi,"P",{});var mlo=s(kR);aUr=r(mlo,"This class cannot be instantiated directly using "),SLe=n(mlo,"CODE",{});var dga=s(SLe);nUr=r(dga,"__init__()"),dga.forEach(t),sUr=r(mlo," (throws an error)."),mlo.forEach(t),lUr=i(Mi),ea=n(Mi,"DIV",{class:!0});var dx=s(ea);T(SR.$$.fragment,dx),iUr=i(dx),RLe=n(dx,"P",{});var cga=s(RLe);dUr=r(cga,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),cga.forEach(t),cUr=i(dx),Mf=n(dx,"P",{});var ufe=s(Mf);fUr=r(ufe,`Note:
Loading a model from its configuration file does `),PLe=n(ufe,"STRONG",{});var fga=s(PLe);mUr=r(fga,"not"),fga.forEach(t),gUr=r(ufe,` load the model weights. It only affects the
model\u2019s configuration. Use `),aae=n(ufe,"A",{href:!0});var mga=s(aae);hUr=r(mga,"from_pretrained()"),mga.forEach(t),uUr=r(ufe," to load the model weights."),ufe.forEach(t),pUr=i(dx),T(Aw.$$.fragment,dx),dx.forEach(t),_Ur=i(Mi),Vr=n(Mi,"DIV",{class:!0});var Ei=s(Vr);T(RR.$$.fragment,Ei),vUr=i(Ei),BLe=n(Ei,"P",{});var gga=s(BLe);bUr=r(gga,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),gga.forEach(t),FUr=i(Ei),qn=n(Ei,"P",{});var cx=s(qn);TUr=r(cx,"The model class to instantiate is selected based on the "),ILe=n(cx,"CODE",{});var hga=s(ILe);MUr=r(hga,"model_type"),hga.forEach(t),EUr=r(cx,` property of the config object (either
passed as an argument or loaded from `),NLe=n(cx,"CODE",{});var uga=s(NLe);CUr=r(uga,"pretrained_model_name_or_path"),uga.forEach(t),wUr=r(cx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qLe=n(cx,"CODE",{});var pga=s(qLe);AUr=r(pga,"pretrained_model_name_or_path"),pga.forEach(t),LUr=r(cx,":"),cx.forEach(t),yUr=i(Ei),ye=n(Ei,"UL",{});var Ne=s(ye);Lw=n(Ne,"LI",{});var WZe=s(Lw);jLe=n(WZe,"STRONG",{});var _ga=s(jLe);xUr=r(_ga,"convnext"),_ga.forEach(t),$Ur=r(WZe," \u2014 "),nae=n(WZe,"A",{href:!0});var vga=s(nae);kUr=r(vga,"TFConvNextForImageClassification"),vga.forEach(t),SUr=r(WZe," (ConvNeXT model)"),WZe.forEach(t),RUr=i(Ne),yw=n(Ne,"LI",{});var UZe=s(yw);DLe=n(UZe,"STRONG",{});var bga=s(DLe);PUr=r(bga,"cvt"),bga.forEach(t),BUr=r(UZe," \u2014 "),sae=n(UZe,"A",{href:!0});var Fga=s(sae);IUr=r(Fga,"TFCvtForImageClassification"),Fga.forEach(t),NUr=r(UZe," (CvT model)"),UZe.forEach(t),qUr=i(Ne),xw=n(Ne,"LI",{});var HZe=s(xw);GLe=n(HZe,"STRONG",{});var Tga=s(GLe);jUr=r(Tga,"data2vec-vision"),Tga.forEach(t),DUr=r(HZe," \u2014 "),lae=n(HZe,"A",{href:!0});var Mga=s(lae);GUr=r(Mga,"TFData2VecVisionForImageClassification"),Mga.forEach(t),OUr=r(HZe," (Data2VecVision model)"),HZe.forEach(t),VUr=i(Ne),Rl=n(Ne,"LI",{});var TN=s(Rl);OLe=n(TN,"STRONG",{});var Ega=s(OLe);XUr=r(Ega,"deit"),Ega.forEach(t),zUr=r(TN," \u2014 "),iae=n(TN,"A",{href:!0});var Cga=s(iae);QUr=r(Cga,"TFDeiTForImageClassification"),Cga.forEach(t),WUr=r(TN," or "),dae=n(TN,"A",{href:!0});var wga=s(dae);UUr=r(wga,"TFDeiTForImageClassificationWithTeacher"),wga.forEach(t),HUr=r(TN," (DeiT model)"),TN.forEach(t),JUr=i(Ne),$w=n(Ne,"LI",{});var JZe=s($w);VLe=n(JZe,"STRONG",{});var Aga=s(VLe);YUr=r(Aga,"mobilevit"),Aga.forEach(t),ZUr=r(JZe," \u2014 "),cae=n(JZe,"A",{href:!0});var Lga=s(cae);KUr=r(Lga,"TFMobileViTForImageClassification"),Lga.forEach(t),eHr=r(JZe," (MobileViT model)"),JZe.forEach(t),oHr=i(Ne),kw=n(Ne,"LI",{});var YZe=s(kw);XLe=n(YZe,"STRONG",{});var yga=s(XLe);rHr=r(yga,"regnet"),yga.forEach(t),tHr=r(YZe," \u2014 "),fae=n(YZe,"A",{href:!0});var xga=s(fae);aHr=r(xga,"TFRegNetForImageClassification"),xga.forEach(t),nHr=r(YZe," (RegNet model)"),YZe.forEach(t),sHr=i(Ne),Sw=n(Ne,"LI",{});var ZZe=s(Sw);zLe=n(ZZe,"STRONG",{});var $ga=s(zLe);lHr=r($ga,"resnet"),$ga.forEach(t),iHr=r(ZZe," \u2014 "),mae=n(ZZe,"A",{href:!0});var kga=s(mae);dHr=r(kga,"TFResNetForImageClassification"),kga.forEach(t),cHr=r(ZZe," (ResNet model)"),ZZe.forEach(t),fHr=i(Ne),Rw=n(Ne,"LI",{});var KZe=s(Rw);QLe=n(KZe,"STRONG",{});var Sga=s(QLe);mHr=r(Sga,"segformer"),Sga.forEach(t),gHr=r(KZe," \u2014 "),gae=n(KZe,"A",{href:!0});var Rga=s(gae);hHr=r(Rga,"TFSegformerForImageClassification"),Rga.forEach(t),uHr=r(KZe," (SegFormer model)"),KZe.forEach(t),pHr=i(Ne),Pw=n(Ne,"LI",{});var eKe=s(Pw);WLe=n(eKe,"STRONG",{});var Pga=s(WLe);_Hr=r(Pga,"swin"),Pga.forEach(t),vHr=r(eKe," \u2014 "),hae=n(eKe,"A",{href:!0});var Bga=s(hae);bHr=r(Bga,"TFSwinForImageClassification"),Bga.forEach(t),FHr=r(eKe," (Swin Transformer model)"),eKe.forEach(t),THr=i(Ne),Bw=n(Ne,"LI",{});var oKe=s(Bw);ULe=n(oKe,"STRONG",{});var Iga=s(ULe);MHr=r(Iga,"vit"),Iga.forEach(t),EHr=r(oKe," \u2014 "),uae=n(oKe,"A",{href:!0});var Nga=s(uae);CHr=r(Nga,"TFViTForImageClassification"),Nga.forEach(t),wHr=r(oKe," (ViT model)"),oKe.forEach(t),Ne.forEach(t),AHr=i(Ei),T(Iw.$$.fragment,Ei),Ei.forEach(t),Mi.forEach(t),Uao=i(f),Ef=n(f,"H2",{class:!0});var glo=s(Ef);Nw=n(glo,"A",{id:!0,class:!0,href:!0});var qga=s(Nw);HLe=n(qga,"SPAN",{});var jga=s(HLe);T(PR.$$.fragment,jga),jga.forEach(t),qga.forEach(t),LHr=i(glo),JLe=n(glo,"SPAN",{});var Dga=s(JLe);yHr=r(Dga,"TFAutoModelForSemanticSegmentation"),Dga.forEach(t),glo.forEach(t),Hao=i(f),hr=n(f,"DIV",{class:!0});var Ci=s(hr);T(BR.$$.fragment,Ci),xHr=i(Ci),Cf=n(Ci,"P",{});var pfe=s(Cf);$Hr=r(pfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),pae=n(pfe,"A",{href:!0});var Gga=s(pae);kHr=r(Gga,"from_pretrained()"),Gga.forEach(t),SHr=r(pfe," class method or the "),_ae=n(pfe,"A",{href:!0});var Oga=s(_ae);RHr=r(Oga,"from_config()"),Oga.forEach(t),PHr=r(pfe,` class
method.`),pfe.forEach(t),BHr=i(Ci),IR=n(Ci,"P",{});var hlo=s(IR);IHr=r(hlo,"This class cannot be instantiated directly using "),YLe=n(hlo,"CODE",{});var Vga=s(YLe);NHr=r(Vga,"__init__()"),Vga.forEach(t),qHr=r(hlo," (throws an error)."),hlo.forEach(t),jHr=i(Ci),oa=n(Ci,"DIV",{class:!0});var fx=s(oa);T(NR.$$.fragment,fx),DHr=i(fx),ZLe=n(fx,"P",{});var Xga=s(ZLe);GHr=r(Xga,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Xga.forEach(t),OHr=i(fx),wf=n(fx,"P",{});var _fe=s(wf);VHr=r(_fe,`Note:
Loading a model from its configuration file does `),KLe=n(_fe,"STRONG",{});var zga=s(KLe);XHr=r(zga,"not"),zga.forEach(t),zHr=r(_fe,` load the model weights. It only affects the
model\u2019s configuration. Use `),vae=n(_fe,"A",{href:!0});var Qga=s(vae);QHr=r(Qga,"from_pretrained()"),Qga.forEach(t),WHr=r(_fe," to load the model weights."),_fe.forEach(t),UHr=i(fx),T(qw.$$.fragment,fx),fx.forEach(t),HHr=i(Ci),Xr=n(Ci,"DIV",{class:!0});var wi=s(Xr);T(qR.$$.fragment,wi),JHr=i(wi),eye=n(wi,"P",{});var Wga=s(eye);YHr=r(Wga,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Wga.forEach(t),ZHr=i(wi),jn=n(wi,"P",{});var mx=s(jn);KHr=r(mx,"The model class to instantiate is selected based on the "),oye=n(mx,"CODE",{});var Uga=s(oye);eJr=r(Uga,"model_type"),Uga.forEach(t),oJr=r(mx,` property of the config object (either
passed as an argument or loaded from `),rye=n(mx,"CODE",{});var Hga=s(rye);rJr=r(Hga,"pretrained_model_name_or_path"),Hga.forEach(t),tJr=r(mx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tye=n(mx,"CODE",{});var Jga=s(tye);aJr=r(Jga,"pretrained_model_name_or_path"),Jga.forEach(t),nJr=r(mx,":"),mx.forEach(t),sJr=i(wi),Af=n(wi,"UL",{});var vfe=s(Af);jw=n(vfe,"LI",{});var rKe=s(jw);aye=n(rKe,"STRONG",{});var Yga=s(aye);lJr=r(Yga,"data2vec-vision"),Yga.forEach(t),iJr=r(rKe," \u2014 "),bae=n(rKe,"A",{href:!0});var Zga=s(bae);dJr=r(Zga,"TFData2VecVisionForSemanticSegmentation"),Zga.forEach(t),cJr=r(rKe," (Data2VecVision model)"),rKe.forEach(t),fJr=i(vfe),Dw=n(vfe,"LI",{});var tKe=s(Dw);nye=n(tKe,"STRONG",{});var Kga=s(nye);mJr=r(Kga,"mobilevit"),Kga.forEach(t),gJr=r(tKe," \u2014 "),Fae=n(tKe,"A",{href:!0});var eha=s(Fae);hJr=r(eha,"TFMobileViTForSemanticSegmentation"),eha.forEach(t),uJr=r(tKe," (MobileViT model)"),tKe.forEach(t),pJr=i(vfe),Gw=n(vfe,"LI",{});var aKe=s(Gw);sye=n(aKe,"STRONG",{});var oha=s(sye);_Jr=r(oha,"segformer"),oha.forEach(t),vJr=r(aKe," \u2014 "),Tae=n(aKe,"A",{href:!0});var rha=s(Tae);bJr=r(rha,"TFSegformerForSemanticSegmentation"),rha.forEach(t),FJr=r(aKe," (SegFormer model)"),aKe.forEach(t),vfe.forEach(t),TJr=i(wi),T(Ow.$$.fragment,wi),wi.forEach(t),Ci.forEach(t),Jao=i(f),Lf=n(f,"H2",{class:!0});var ulo=s(Lf);Vw=n(ulo,"A",{id:!0,class:!0,href:!0});var tha=s(Vw);lye=n(tha,"SPAN",{});var aha=s(lye);T(jR.$$.fragment,aha),aha.forEach(t),tha.forEach(t),MJr=i(ulo),iye=n(ulo,"SPAN",{});var nha=s(iye);EJr=r(nha,"TFAutoModelForMaskedLM"),nha.forEach(t),ulo.forEach(t),Yao=i(f),ur=n(f,"DIV",{class:!0});var Ai=s(ur);T(DR.$$.fragment,Ai),CJr=i(Ai),yf=n(Ai,"P",{});var bfe=s(yf);wJr=r(bfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Mae=n(bfe,"A",{href:!0});var sha=s(Mae);AJr=r(sha,"from_pretrained()"),sha.forEach(t),LJr=r(bfe," class method or the "),Eae=n(bfe,"A",{href:!0});var lha=s(Eae);yJr=r(lha,"from_config()"),lha.forEach(t),xJr=r(bfe,` class
method.`),bfe.forEach(t),$Jr=i(Ai),GR=n(Ai,"P",{});var plo=s(GR);kJr=r(plo,"This class cannot be instantiated directly using "),dye=n(plo,"CODE",{});var iha=s(dye);SJr=r(iha,"__init__()"),iha.forEach(t),RJr=r(plo," (throws an error)."),plo.forEach(t),PJr=i(Ai),ra=n(Ai,"DIV",{class:!0});var gx=s(ra);T(OR.$$.fragment,gx),BJr=i(gx),cye=n(gx,"P",{});var dha=s(cye);IJr=r(dha,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),dha.forEach(t),NJr=i(gx),xf=n(gx,"P",{});var Ffe=s(xf);qJr=r(Ffe,`Note:
Loading a model from its configuration file does `),fye=n(Ffe,"STRONG",{});var cha=s(fye);jJr=r(cha,"not"),cha.forEach(t),DJr=r(Ffe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Cae=n(Ffe,"A",{href:!0});var fha=s(Cae);GJr=r(fha,"from_pretrained()"),fha.forEach(t),OJr=r(Ffe," to load the model weights."),Ffe.forEach(t),VJr=i(gx),T(Xw.$$.fragment,gx),gx.forEach(t),XJr=i(Ai),zr=n(Ai,"DIV",{class:!0});var Li=s(zr);T(VR.$$.fragment,Li),zJr=i(Li),mye=n(Li,"P",{});var mha=s(mye);QJr=r(mha,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),mha.forEach(t),WJr=i(Li),Dn=n(Li,"P",{});var hx=s(Dn);UJr=r(hx,"The model class to instantiate is selected based on the "),gye=n(hx,"CODE",{});var gha=s(gye);HJr=r(gha,"model_type"),gha.forEach(t),JJr=r(hx,` property of the config object (either
passed as an argument or loaded from `),hye=n(hx,"CODE",{});var hha=s(hye);YJr=r(hha,"pretrained_model_name_or_path"),hha.forEach(t),ZJr=r(hx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uye=n(hx,"CODE",{});var uha=s(uye);KJr=r(uha,"pretrained_model_name_or_path"),uha.forEach(t),eYr=r(hx,":"),hx.forEach(t),oYr=i(Li),ce=n(Li,"UL",{});var ue=s(ce);zw=n(ue,"LI",{});var nKe=s(zw);pye=n(nKe,"STRONG",{});var pha=s(pye);rYr=r(pha,"albert"),pha.forEach(t),tYr=r(nKe," \u2014 "),wae=n(nKe,"A",{href:!0});var _ha=s(wae);aYr=r(_ha,"TFAlbertForMaskedLM"),_ha.forEach(t),nYr=r(nKe," (ALBERT model)"),nKe.forEach(t),sYr=i(ue),Qw=n(ue,"LI",{});var sKe=s(Qw);_ye=n(sKe,"STRONG",{});var vha=s(_ye);lYr=r(vha,"bert"),vha.forEach(t),iYr=r(sKe," \u2014 "),Aae=n(sKe,"A",{href:!0});var bha=s(Aae);dYr=r(bha,"TFBertForMaskedLM"),bha.forEach(t),cYr=r(sKe," (BERT model)"),sKe.forEach(t),fYr=i(ue),Ww=n(ue,"LI",{});var lKe=s(Ww);vye=n(lKe,"STRONG",{});var Fha=s(vye);mYr=r(Fha,"camembert"),Fha.forEach(t),gYr=r(lKe," \u2014 "),Lae=n(lKe,"A",{href:!0});var Tha=s(Lae);hYr=r(Tha,"TFCamembertForMaskedLM"),Tha.forEach(t),uYr=r(lKe," (CamemBERT model)"),lKe.forEach(t),pYr=i(ue),Uw=n(ue,"LI",{});var iKe=s(Uw);bye=n(iKe,"STRONG",{});var Mha=s(bye);_Yr=r(Mha,"convbert"),Mha.forEach(t),vYr=r(iKe," \u2014 "),yae=n(iKe,"A",{href:!0});var Eha=s(yae);bYr=r(Eha,"TFConvBertForMaskedLM"),Eha.forEach(t),FYr=r(iKe," (ConvBERT model)"),iKe.forEach(t),TYr=i(ue),Hw=n(ue,"LI",{});var dKe=s(Hw);Fye=n(dKe,"STRONG",{});var Cha=s(Fye);MYr=r(Cha,"deberta"),Cha.forEach(t),EYr=r(dKe," \u2014 "),xae=n(dKe,"A",{href:!0});var wha=s(xae);CYr=r(wha,"TFDebertaForMaskedLM"),wha.forEach(t),wYr=r(dKe," (DeBERTa model)"),dKe.forEach(t),AYr=i(ue),Jw=n(ue,"LI",{});var cKe=s(Jw);Tye=n(cKe,"STRONG",{});var Aha=s(Tye);LYr=r(Aha,"deberta-v2"),Aha.forEach(t),yYr=r(cKe," \u2014 "),$ae=n(cKe,"A",{href:!0});var Lha=s($ae);xYr=r(Lha,"TFDebertaV2ForMaskedLM"),Lha.forEach(t),$Yr=r(cKe," (DeBERTa-v2 model)"),cKe.forEach(t),kYr=i(ue),Yw=n(ue,"LI",{});var fKe=s(Yw);Mye=n(fKe,"STRONG",{});var yha=s(Mye);SYr=r(yha,"distilbert"),yha.forEach(t),RYr=r(fKe," \u2014 "),kae=n(fKe,"A",{href:!0});var xha=s(kae);PYr=r(xha,"TFDistilBertForMaskedLM"),xha.forEach(t),BYr=r(fKe," (DistilBERT model)"),fKe.forEach(t),IYr=i(ue),Zw=n(ue,"LI",{});var mKe=s(Zw);Eye=n(mKe,"STRONG",{});var $ha=s(Eye);NYr=r($ha,"electra"),$ha.forEach(t),qYr=r(mKe," \u2014 "),Sae=n(mKe,"A",{href:!0});var kha=s(Sae);jYr=r(kha,"TFElectraForMaskedLM"),kha.forEach(t),DYr=r(mKe," (ELECTRA model)"),mKe.forEach(t),GYr=i(ue),Kw=n(ue,"LI",{});var gKe=s(Kw);Cye=n(gKe,"STRONG",{});var Sha=s(Cye);OYr=r(Sha,"esm"),Sha.forEach(t),VYr=r(gKe," \u2014 "),Rae=n(gKe,"A",{href:!0});var Rha=s(Rae);XYr=r(Rha,"TFEsmForMaskedLM"),Rha.forEach(t),zYr=r(gKe," (ESM model)"),gKe.forEach(t),QYr=i(ue),eA=n(ue,"LI",{});var hKe=s(eA);wye=n(hKe,"STRONG",{});var Pha=s(wye);WYr=r(Pha,"flaubert"),Pha.forEach(t),UYr=r(hKe," \u2014 "),Pae=n(hKe,"A",{href:!0});var Bha=s(Pae);HYr=r(Bha,"TFFlaubertWithLMHeadModel"),Bha.forEach(t),JYr=r(hKe," (FlauBERT model)"),hKe.forEach(t),YYr=i(ue),oA=n(ue,"LI",{});var uKe=s(oA);Aye=n(uKe,"STRONG",{});var Iha=s(Aye);ZYr=r(Iha,"funnel"),Iha.forEach(t),KYr=r(uKe," \u2014 "),Bae=n(uKe,"A",{href:!0});var Nha=s(Bae);eZr=r(Nha,"TFFunnelForMaskedLM"),Nha.forEach(t),oZr=r(uKe," (Funnel Transformer model)"),uKe.forEach(t),rZr=i(ue),rA=n(ue,"LI",{});var pKe=s(rA);Lye=n(pKe,"STRONG",{});var qha=s(Lye);tZr=r(qha,"layoutlm"),qha.forEach(t),aZr=r(pKe," \u2014 "),Iae=n(pKe,"A",{href:!0});var jha=s(Iae);nZr=r(jha,"TFLayoutLMForMaskedLM"),jha.forEach(t),sZr=r(pKe," (LayoutLM model)"),pKe.forEach(t),lZr=i(ue),tA=n(ue,"LI",{});var _Ke=s(tA);yye=n(_Ke,"STRONG",{});var Dha=s(yye);iZr=r(Dha,"longformer"),Dha.forEach(t),dZr=r(_Ke," \u2014 "),Nae=n(_Ke,"A",{href:!0});var Gha=s(Nae);cZr=r(Gha,"TFLongformerForMaskedLM"),Gha.forEach(t),fZr=r(_Ke," (Longformer model)"),_Ke.forEach(t),mZr=i(ue),aA=n(ue,"LI",{});var vKe=s(aA);xye=n(vKe,"STRONG",{});var Oha=s(xye);gZr=r(Oha,"mobilebert"),Oha.forEach(t),hZr=r(vKe," \u2014 "),qae=n(vKe,"A",{href:!0});var Vha=s(qae);uZr=r(Vha,"TFMobileBertForMaskedLM"),Vha.forEach(t),pZr=r(vKe," (MobileBERT model)"),vKe.forEach(t),_Zr=i(ue),nA=n(ue,"LI",{});var bKe=s(nA);$ye=n(bKe,"STRONG",{});var Xha=s($ye);vZr=r(Xha,"mpnet"),Xha.forEach(t),bZr=r(bKe," \u2014 "),jae=n(bKe,"A",{href:!0});var zha=s(jae);FZr=r(zha,"TFMPNetForMaskedLM"),zha.forEach(t),TZr=r(bKe," (MPNet model)"),bKe.forEach(t),MZr=i(ue),sA=n(ue,"LI",{});var FKe=s(sA);kye=n(FKe,"STRONG",{});var Qha=s(kye);EZr=r(Qha,"rembert"),Qha.forEach(t),CZr=r(FKe," \u2014 "),Dae=n(FKe,"A",{href:!0});var Wha=s(Dae);wZr=r(Wha,"TFRemBertForMaskedLM"),Wha.forEach(t),AZr=r(FKe," (RemBERT model)"),FKe.forEach(t),LZr=i(ue),lA=n(ue,"LI",{});var TKe=s(lA);Sye=n(TKe,"STRONG",{});var Uha=s(Sye);yZr=r(Uha,"roberta"),Uha.forEach(t),xZr=r(TKe," \u2014 "),Gae=n(TKe,"A",{href:!0});var Hha=s(Gae);$Zr=r(Hha,"TFRobertaForMaskedLM"),Hha.forEach(t),kZr=r(TKe," (RoBERTa model)"),TKe.forEach(t),SZr=i(ue),iA=n(ue,"LI",{});var MKe=s(iA);Rye=n(MKe,"STRONG",{});var Jha=s(Rye);RZr=r(Jha,"roformer"),Jha.forEach(t),PZr=r(MKe," \u2014 "),Oae=n(MKe,"A",{href:!0});var Yha=s(Oae);BZr=r(Yha,"TFRoFormerForMaskedLM"),Yha.forEach(t),IZr=r(MKe," (RoFormer model)"),MKe.forEach(t),NZr=i(ue),dA=n(ue,"LI",{});var EKe=s(dA);Pye=n(EKe,"STRONG",{});var Zha=s(Pye);qZr=r(Zha,"tapas"),Zha.forEach(t),jZr=r(EKe," \u2014 "),Vae=n(EKe,"A",{href:!0});var Kha=s(Vae);DZr=r(Kha,"TFTapasForMaskedLM"),Kha.forEach(t),GZr=r(EKe," (TAPAS model)"),EKe.forEach(t),OZr=i(ue),cA=n(ue,"LI",{});var CKe=s(cA);Bye=n(CKe,"STRONG",{});var eua=s(Bye);VZr=r(eua,"xlm"),eua.forEach(t),XZr=r(CKe," \u2014 "),Xae=n(CKe,"A",{href:!0});var oua=s(Xae);zZr=r(oua,"TFXLMWithLMHeadModel"),oua.forEach(t),QZr=r(CKe," (XLM model)"),CKe.forEach(t),WZr=i(ue),fA=n(ue,"LI",{});var wKe=s(fA);Iye=n(wKe,"STRONG",{});var rua=s(Iye);UZr=r(rua,"xlm-roberta"),rua.forEach(t),HZr=r(wKe," \u2014 "),zae=n(wKe,"A",{href:!0});var tua=s(zae);JZr=r(tua,"TFXLMRobertaForMaskedLM"),tua.forEach(t),YZr=r(wKe," (XLM-RoBERTa model)"),wKe.forEach(t),ue.forEach(t),ZZr=i(Li),T(mA.$$.fragment,Li),Li.forEach(t),Ai.forEach(t),Zao=i(f),$f=n(f,"H2",{class:!0});var _lo=s($f);gA=n(_lo,"A",{id:!0,class:!0,href:!0});var aua=s(gA);Nye=n(aua,"SPAN",{});var nua=s(Nye);T(XR.$$.fragment,nua),nua.forEach(t),aua.forEach(t),KZr=i(_lo),qye=n(_lo,"SPAN",{});var sua=s(qye);eKr=r(sua,"TFAutoModelForSeq2SeqLM"),sua.forEach(t),_lo.forEach(t),Kao=i(f),pr=n(f,"DIV",{class:!0});var yi=s(pr);T(zR.$$.fragment,yi),oKr=i(yi),kf=n(yi,"P",{});var Tfe=s(kf);rKr=r(Tfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Qae=n(Tfe,"A",{href:!0});var lua=s(Qae);tKr=r(lua,"from_pretrained()"),lua.forEach(t),aKr=r(Tfe," class method or the "),Wae=n(Tfe,"A",{href:!0});var iua=s(Wae);nKr=r(iua,"from_config()"),iua.forEach(t),sKr=r(Tfe,` class
method.`),Tfe.forEach(t),lKr=i(yi),QR=n(yi,"P",{});var vlo=s(QR);iKr=r(vlo,"This class cannot be instantiated directly using "),jye=n(vlo,"CODE",{});var dua=s(jye);dKr=r(dua,"__init__()"),dua.forEach(t),cKr=r(vlo," (throws an error)."),vlo.forEach(t),fKr=i(yi),ta=n(yi,"DIV",{class:!0});var ux=s(ta);T(WR.$$.fragment,ux),mKr=i(ux),Dye=n(ux,"P",{});var cua=s(Dye);gKr=r(cua,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),cua.forEach(t),hKr=i(ux),Sf=n(ux,"P",{});var Mfe=s(Sf);uKr=r(Mfe,`Note:
Loading a model from its configuration file does `),Gye=n(Mfe,"STRONG",{});var fua=s(Gye);pKr=r(fua,"not"),fua.forEach(t),_Kr=r(Mfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Uae=n(Mfe,"A",{href:!0});var mua=s(Uae);vKr=r(mua,"from_pretrained()"),mua.forEach(t),bKr=r(Mfe," to load the model weights."),Mfe.forEach(t),FKr=i(ux),T(hA.$$.fragment,ux),ux.forEach(t),TKr=i(yi),Qr=n(yi,"DIV",{class:!0});var xi=s(Qr);T(UR.$$.fragment,xi),MKr=i(xi),Oye=n(xi,"P",{});var gua=s(Oye);EKr=r(gua,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),gua.forEach(t),CKr=i(xi),Gn=n(xi,"P",{});var px=s(Gn);wKr=r(px,"The model class to instantiate is selected based on the "),Vye=n(px,"CODE",{});var hua=s(Vye);AKr=r(hua,"model_type"),hua.forEach(t),LKr=r(px,` property of the config object (either
passed as an argument or loaded from `),Xye=n(px,"CODE",{});var uua=s(Xye);yKr=r(uua,"pretrained_model_name_or_path"),uua.forEach(t),xKr=r(px,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zye=n(px,"CODE",{});var pua=s(zye);$Kr=r(pua,"pretrained_model_name_or_path"),pua.forEach(t),kKr=r(px,":"),px.forEach(t),SKr=i(xi),xe=n(xi,"UL",{});var qe=s(xe);uA=n(qe,"LI",{});var AKe=s(uA);Qye=n(AKe,"STRONG",{});var _ua=s(Qye);RKr=r(_ua,"bart"),_ua.forEach(t),PKr=r(AKe," \u2014 "),Hae=n(AKe,"A",{href:!0});var vua=s(Hae);BKr=r(vua,"TFBartForConditionalGeneration"),vua.forEach(t),IKr=r(AKe," (BART model)"),AKe.forEach(t),NKr=i(qe),pA=n(qe,"LI",{});var LKe=s(pA);Wye=n(LKe,"STRONG",{});var bua=s(Wye);qKr=r(bua,"blenderbot"),bua.forEach(t),jKr=r(LKe," \u2014 "),Jae=n(LKe,"A",{href:!0});var Fua=s(Jae);DKr=r(Fua,"TFBlenderbotForConditionalGeneration"),Fua.forEach(t),GKr=r(LKe," (Blenderbot model)"),LKe.forEach(t),OKr=i(qe),_A=n(qe,"LI",{});var yKe=s(_A);Uye=n(yKe,"STRONG",{});var Tua=s(Uye);VKr=r(Tua,"blenderbot-small"),Tua.forEach(t),XKr=r(yKe," \u2014 "),Yae=n(yKe,"A",{href:!0});var Mua=s(Yae);zKr=r(Mua,"TFBlenderbotSmallForConditionalGeneration"),Mua.forEach(t),QKr=r(yKe," (BlenderbotSmall model)"),yKe.forEach(t),WKr=i(qe),vA=n(qe,"LI",{});var xKe=s(vA);Hye=n(xKe,"STRONG",{});var Eua=s(Hye);UKr=r(Eua,"encoder-decoder"),Eua.forEach(t),HKr=r(xKe," \u2014 "),Zae=n(xKe,"A",{href:!0});var Cua=s(Zae);JKr=r(Cua,"TFEncoderDecoderModel"),Cua.forEach(t),YKr=r(xKe," (Encoder decoder model)"),xKe.forEach(t),ZKr=i(qe),bA=n(qe,"LI",{});var $Ke=s(bA);Jye=n($Ke,"STRONG",{});var wua=s(Jye);KKr=r(wua,"led"),wua.forEach(t),eet=r($Ke," \u2014 "),Kae=n($Ke,"A",{href:!0});var Aua=s(Kae);oet=r(Aua,"TFLEDForConditionalGeneration"),Aua.forEach(t),ret=r($Ke," (LED model)"),$Ke.forEach(t),tet=i(qe),FA=n(qe,"LI",{});var kKe=s(FA);Yye=n(kKe,"STRONG",{});var Lua=s(Yye);aet=r(Lua,"marian"),Lua.forEach(t),net=r(kKe," \u2014 "),ene=n(kKe,"A",{href:!0});var yua=s(ene);set=r(yua,"TFMarianMTModel"),yua.forEach(t),iet=r(kKe," (Marian model)"),kKe.forEach(t),det=i(qe),TA=n(qe,"LI",{});var SKe=s(TA);Zye=n(SKe,"STRONG",{});var xua=s(Zye);cet=r(xua,"mbart"),xua.forEach(t),fet=r(SKe," \u2014 "),one=n(SKe,"A",{href:!0});var $ua=s(one);met=r($ua,"TFMBartForConditionalGeneration"),$ua.forEach(t),get=r(SKe," (mBART model)"),SKe.forEach(t),het=i(qe),MA=n(qe,"LI",{});var RKe=s(MA);Kye=n(RKe,"STRONG",{});var kua=s(Kye);uet=r(kua,"mt5"),kua.forEach(t),pet=r(RKe," \u2014 "),rne=n(RKe,"A",{href:!0});var Sua=s(rne);_et=r(Sua,"TFMT5ForConditionalGeneration"),Sua.forEach(t),vet=r(RKe," (MT5 model)"),RKe.forEach(t),bet=i(qe),EA=n(qe,"LI",{});var PKe=s(EA);e9e=n(PKe,"STRONG",{});var Rua=s(e9e);Fet=r(Rua,"pegasus"),Rua.forEach(t),Tet=r(PKe," \u2014 "),tne=n(PKe,"A",{href:!0});var Pua=s(tne);Met=r(Pua,"TFPegasusForConditionalGeneration"),Pua.forEach(t),Eet=r(PKe," (Pegasus model)"),PKe.forEach(t),Cet=i(qe),CA=n(qe,"LI",{});var BKe=s(CA);o9e=n(BKe,"STRONG",{});var Bua=s(o9e);wet=r(Bua,"t5"),Bua.forEach(t),Aet=r(BKe," \u2014 "),ane=n(BKe,"A",{href:!0});var Iua=s(ane);Let=r(Iua,"TFT5ForConditionalGeneration"),Iua.forEach(t),yet=r(BKe," (T5 model)"),BKe.forEach(t),qe.forEach(t),xet=i(xi),T(wA.$$.fragment,xi),xi.forEach(t),yi.forEach(t),eno=i(f),Rf=n(f,"H2",{class:!0});var blo=s(Rf);AA=n(blo,"A",{id:!0,class:!0,href:!0});var Nua=s(AA);r9e=n(Nua,"SPAN",{});var qua=s(r9e);T(HR.$$.fragment,qua),qua.forEach(t),Nua.forEach(t),$et=i(blo),t9e=n(blo,"SPAN",{});var jua=s(t9e);ket=r(jua,"TFAutoModelForSequenceClassification"),jua.forEach(t),blo.forEach(t),ono=i(f),_r=n(f,"DIV",{class:!0});var $i=s(_r);T(JR.$$.fragment,$i),Set=i($i),Pf=n($i,"P",{});var Efe=s(Pf);Ret=r(Efe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),nne=n(Efe,"A",{href:!0});var Dua=s(nne);Pet=r(Dua,"from_pretrained()"),Dua.forEach(t),Bet=r(Efe," class method or the "),sne=n(Efe,"A",{href:!0});var Gua=s(sne);Iet=r(Gua,"from_config()"),Gua.forEach(t),Net=r(Efe,` class
method.`),Efe.forEach(t),qet=i($i),YR=n($i,"P",{});var Flo=s(YR);jet=r(Flo,"This class cannot be instantiated directly using "),a9e=n(Flo,"CODE",{});var Oua=s(a9e);Det=r(Oua,"__init__()"),Oua.forEach(t),Get=r(Flo," (throws an error)."),Flo.forEach(t),Oet=i($i),aa=n($i,"DIV",{class:!0});var _x=s(aa);T(ZR.$$.fragment,_x),Vet=i(_x),n9e=n(_x,"P",{});var Vua=s(n9e);Xet=r(Vua,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Vua.forEach(t),zet=i(_x),Bf=n(_x,"P",{});var Cfe=s(Bf);Qet=r(Cfe,`Note:
Loading a model from its configuration file does `),s9e=n(Cfe,"STRONG",{});var Xua=s(s9e);Wet=r(Xua,"not"),Xua.forEach(t),Uet=r(Cfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),lne=n(Cfe,"A",{href:!0});var zua=s(lne);Het=r(zua,"from_pretrained()"),zua.forEach(t),Jet=r(Cfe," to load the model weights."),Cfe.forEach(t),Yet=i(_x),T(LA.$$.fragment,_x),_x.forEach(t),Zet=i($i),Wr=n($i,"DIV",{class:!0});var ki=s(Wr);T(KR.$$.fragment,ki),Ket=i(ki),l9e=n(ki,"P",{});var Qua=s(l9e);eot=r(Qua,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Qua.forEach(t),oot=i(ki),On=n(ki,"P",{});var vx=s(On);rot=r(vx,"The model class to instantiate is selected based on the "),i9e=n(vx,"CODE",{});var Wua=s(i9e);tot=r(Wua,"model_type"),Wua.forEach(t),aot=r(vx,` property of the config object (either
passed as an argument or loaded from `),d9e=n(vx,"CODE",{});var Uua=s(d9e);not=r(Uua,"pretrained_model_name_or_path"),Uua.forEach(t),sot=r(vx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c9e=n(vx,"CODE",{});var Hua=s(c9e);lot=r(Hua,"pretrained_model_name_or_path"),Hua.forEach(t),iot=r(vx,":"),vx.forEach(t),dot=i(ki),re=n(ki,"UL",{});var ae=s(re);yA=n(ae,"LI",{});var IKe=s(yA);f9e=n(IKe,"STRONG",{});var Jua=s(f9e);cot=r(Jua,"albert"),Jua.forEach(t),fot=r(IKe," \u2014 "),ine=n(IKe,"A",{href:!0});var Yua=s(ine);mot=r(Yua,"TFAlbertForSequenceClassification"),Yua.forEach(t),got=r(IKe," (ALBERT model)"),IKe.forEach(t),hot=i(ae),xA=n(ae,"LI",{});var NKe=s(xA);m9e=n(NKe,"STRONG",{});var Zua=s(m9e);uot=r(Zua,"bert"),Zua.forEach(t),pot=r(NKe," \u2014 "),dne=n(NKe,"A",{href:!0});var Kua=s(dne);_ot=r(Kua,"TFBertForSequenceClassification"),Kua.forEach(t),vot=r(NKe," (BERT model)"),NKe.forEach(t),bot=i(ae),$A=n(ae,"LI",{});var qKe=s($A);g9e=n(qKe,"STRONG",{});var epa=s(g9e);Fot=r(epa,"camembert"),epa.forEach(t),Tot=r(qKe," \u2014 "),cne=n(qKe,"A",{href:!0});var opa=s(cne);Mot=r(opa,"TFCamembertForSequenceClassification"),opa.forEach(t),Eot=r(qKe," (CamemBERT model)"),qKe.forEach(t),Cot=i(ae),kA=n(ae,"LI",{});var jKe=s(kA);h9e=n(jKe,"STRONG",{});var rpa=s(h9e);wot=r(rpa,"convbert"),rpa.forEach(t),Aot=r(jKe," \u2014 "),fne=n(jKe,"A",{href:!0});var tpa=s(fne);Lot=r(tpa,"TFConvBertForSequenceClassification"),tpa.forEach(t),yot=r(jKe," (ConvBERT model)"),jKe.forEach(t),xot=i(ae),SA=n(ae,"LI",{});var DKe=s(SA);u9e=n(DKe,"STRONG",{});var apa=s(u9e);$ot=r(apa,"ctrl"),apa.forEach(t),kot=r(DKe," \u2014 "),mne=n(DKe,"A",{href:!0});var npa=s(mne);Sot=r(npa,"TFCTRLForSequenceClassification"),npa.forEach(t),Rot=r(DKe," (CTRL model)"),DKe.forEach(t),Pot=i(ae),RA=n(ae,"LI",{});var GKe=s(RA);p9e=n(GKe,"STRONG",{});var spa=s(p9e);Bot=r(spa,"deberta"),spa.forEach(t),Iot=r(GKe," \u2014 "),gne=n(GKe,"A",{href:!0});var lpa=s(gne);Not=r(lpa,"TFDebertaForSequenceClassification"),lpa.forEach(t),qot=r(GKe," (DeBERTa model)"),GKe.forEach(t),jot=i(ae),PA=n(ae,"LI",{});var OKe=s(PA);_9e=n(OKe,"STRONG",{});var ipa=s(_9e);Dot=r(ipa,"deberta-v2"),ipa.forEach(t),Got=r(OKe," \u2014 "),hne=n(OKe,"A",{href:!0});var dpa=s(hne);Oot=r(dpa,"TFDebertaV2ForSequenceClassification"),dpa.forEach(t),Vot=r(OKe," (DeBERTa-v2 model)"),OKe.forEach(t),Xot=i(ae),BA=n(ae,"LI",{});var VKe=s(BA);v9e=n(VKe,"STRONG",{});var cpa=s(v9e);zot=r(cpa,"distilbert"),cpa.forEach(t),Qot=r(VKe," \u2014 "),une=n(VKe,"A",{href:!0});var fpa=s(une);Wot=r(fpa,"TFDistilBertForSequenceClassification"),fpa.forEach(t),Uot=r(VKe," (DistilBERT model)"),VKe.forEach(t),Hot=i(ae),IA=n(ae,"LI",{});var XKe=s(IA);b9e=n(XKe,"STRONG",{});var mpa=s(b9e);Jot=r(mpa,"electra"),mpa.forEach(t),Yot=r(XKe," \u2014 "),pne=n(XKe,"A",{href:!0});var gpa=s(pne);Zot=r(gpa,"TFElectraForSequenceClassification"),gpa.forEach(t),Kot=r(XKe," (ELECTRA model)"),XKe.forEach(t),ert=i(ae),NA=n(ae,"LI",{});var zKe=s(NA);F9e=n(zKe,"STRONG",{});var hpa=s(F9e);ort=r(hpa,"esm"),hpa.forEach(t),rrt=r(zKe," \u2014 "),_ne=n(zKe,"A",{href:!0});var upa=s(_ne);trt=r(upa,"TFEsmForSequenceClassification"),upa.forEach(t),art=r(zKe," (ESM model)"),zKe.forEach(t),nrt=i(ae),qA=n(ae,"LI",{});var QKe=s(qA);T9e=n(QKe,"STRONG",{});var ppa=s(T9e);srt=r(ppa,"flaubert"),ppa.forEach(t),lrt=r(QKe," \u2014 "),vne=n(QKe,"A",{href:!0});var _pa=s(vne);irt=r(_pa,"TFFlaubertForSequenceClassification"),_pa.forEach(t),drt=r(QKe," (FlauBERT model)"),QKe.forEach(t),crt=i(ae),jA=n(ae,"LI",{});var WKe=s(jA);M9e=n(WKe,"STRONG",{});var vpa=s(M9e);frt=r(vpa,"funnel"),vpa.forEach(t),mrt=r(WKe," \u2014 "),bne=n(WKe,"A",{href:!0});var bpa=s(bne);grt=r(bpa,"TFFunnelForSequenceClassification"),bpa.forEach(t),hrt=r(WKe," (Funnel Transformer model)"),WKe.forEach(t),urt=i(ae),DA=n(ae,"LI",{});var UKe=s(DA);E9e=n(UKe,"STRONG",{});var Fpa=s(E9e);prt=r(Fpa,"gpt2"),Fpa.forEach(t),_rt=r(UKe," \u2014 "),Fne=n(UKe,"A",{href:!0});var Tpa=s(Fne);vrt=r(Tpa,"TFGPT2ForSequenceClassification"),Tpa.forEach(t),brt=r(UKe," (OpenAI GPT-2 model)"),UKe.forEach(t),Frt=i(ae),GA=n(ae,"LI",{});var HKe=s(GA);C9e=n(HKe,"STRONG",{});var Mpa=s(C9e);Trt=r(Mpa,"gptj"),Mpa.forEach(t),Mrt=r(HKe," \u2014 "),Tne=n(HKe,"A",{href:!0});var Epa=s(Tne);Ert=r(Epa,"TFGPTJForSequenceClassification"),Epa.forEach(t),Crt=r(HKe," (GPT-J model)"),HKe.forEach(t),wrt=i(ae),OA=n(ae,"LI",{});var JKe=s(OA);w9e=n(JKe,"STRONG",{});var Cpa=s(w9e);Art=r(Cpa,"layoutlm"),Cpa.forEach(t),Lrt=r(JKe," \u2014 "),Mne=n(JKe,"A",{href:!0});var wpa=s(Mne);yrt=r(wpa,"TFLayoutLMForSequenceClassification"),wpa.forEach(t),xrt=r(JKe," (LayoutLM model)"),JKe.forEach(t),$rt=i(ae),VA=n(ae,"LI",{});var YKe=s(VA);A9e=n(YKe,"STRONG",{});var Apa=s(A9e);krt=r(Apa,"layoutlmv3"),Apa.forEach(t),Srt=r(YKe," \u2014 "),Ene=n(YKe,"A",{href:!0});var Lpa=s(Ene);Rrt=r(Lpa,"TFLayoutLMv3ForSequenceClassification"),Lpa.forEach(t),Prt=r(YKe," (LayoutLMv3 model)"),YKe.forEach(t),Brt=i(ae),XA=n(ae,"LI",{});var ZKe=s(XA);L9e=n(ZKe,"STRONG",{});var ypa=s(L9e);Irt=r(ypa,"longformer"),ypa.forEach(t),Nrt=r(ZKe," \u2014 "),Cne=n(ZKe,"A",{href:!0});var xpa=s(Cne);qrt=r(xpa,"TFLongformerForSequenceClassification"),xpa.forEach(t),jrt=r(ZKe," (Longformer model)"),ZKe.forEach(t),Drt=i(ae),zA=n(ae,"LI",{});var KKe=s(zA);y9e=n(KKe,"STRONG",{});var $pa=s(y9e);Grt=r($pa,"mobilebert"),$pa.forEach(t),Ort=r(KKe," \u2014 "),wne=n(KKe,"A",{href:!0});var kpa=s(wne);Vrt=r(kpa,"TFMobileBertForSequenceClassification"),kpa.forEach(t),Xrt=r(KKe," (MobileBERT model)"),KKe.forEach(t),zrt=i(ae),QA=n(ae,"LI",{});var eeo=s(QA);x9e=n(eeo,"STRONG",{});var Spa=s(x9e);Qrt=r(Spa,"mpnet"),Spa.forEach(t),Wrt=r(eeo," \u2014 "),Ane=n(eeo,"A",{href:!0});var Rpa=s(Ane);Urt=r(Rpa,"TFMPNetForSequenceClassification"),Rpa.forEach(t),Hrt=r(eeo," (MPNet model)"),eeo.forEach(t),Jrt=i(ae),WA=n(ae,"LI",{});var oeo=s(WA);$9e=n(oeo,"STRONG",{});var Ppa=s($9e);Yrt=r(Ppa,"openai-gpt"),Ppa.forEach(t),Zrt=r(oeo," \u2014 "),Lne=n(oeo,"A",{href:!0});var Bpa=s(Lne);Krt=r(Bpa,"TFOpenAIGPTForSequenceClassification"),Bpa.forEach(t),ett=r(oeo," (OpenAI GPT model)"),oeo.forEach(t),ott=i(ae),UA=n(ae,"LI",{});var reo=s(UA);k9e=n(reo,"STRONG",{});var Ipa=s(k9e);rtt=r(Ipa,"rembert"),Ipa.forEach(t),ttt=r(reo," \u2014 "),yne=n(reo,"A",{href:!0});var Npa=s(yne);att=r(Npa,"TFRemBertForSequenceClassification"),Npa.forEach(t),ntt=r(reo," (RemBERT model)"),reo.forEach(t),stt=i(ae),HA=n(ae,"LI",{});var teo=s(HA);S9e=n(teo,"STRONG",{});var qpa=s(S9e);ltt=r(qpa,"roberta"),qpa.forEach(t),itt=r(teo," \u2014 "),xne=n(teo,"A",{href:!0});var jpa=s(xne);dtt=r(jpa,"TFRobertaForSequenceClassification"),jpa.forEach(t),ctt=r(teo," (RoBERTa model)"),teo.forEach(t),ftt=i(ae),JA=n(ae,"LI",{});var aeo=s(JA);R9e=n(aeo,"STRONG",{});var Dpa=s(R9e);mtt=r(Dpa,"roformer"),Dpa.forEach(t),gtt=r(aeo," \u2014 "),$ne=n(aeo,"A",{href:!0});var Gpa=s($ne);htt=r(Gpa,"TFRoFormerForSequenceClassification"),Gpa.forEach(t),utt=r(aeo," (RoFormer model)"),aeo.forEach(t),ptt=i(ae),YA=n(ae,"LI",{});var neo=s(YA);P9e=n(neo,"STRONG",{});var Opa=s(P9e);_tt=r(Opa,"tapas"),Opa.forEach(t),vtt=r(neo," \u2014 "),kne=n(neo,"A",{href:!0});var Vpa=s(kne);btt=r(Vpa,"TFTapasForSequenceClassification"),Vpa.forEach(t),Ftt=r(neo," (TAPAS model)"),neo.forEach(t),Ttt=i(ae),ZA=n(ae,"LI",{});var seo=s(ZA);B9e=n(seo,"STRONG",{});var Xpa=s(B9e);Mtt=r(Xpa,"transfo-xl"),Xpa.forEach(t),Ett=r(seo," \u2014 "),Sne=n(seo,"A",{href:!0});var zpa=s(Sne);Ctt=r(zpa,"TFTransfoXLForSequenceClassification"),zpa.forEach(t),wtt=r(seo," (Transformer-XL model)"),seo.forEach(t),Att=i(ae),KA=n(ae,"LI",{});var leo=s(KA);I9e=n(leo,"STRONG",{});var Qpa=s(I9e);Ltt=r(Qpa,"xlm"),Qpa.forEach(t),ytt=r(leo," \u2014 "),Rne=n(leo,"A",{href:!0});var Wpa=s(Rne);xtt=r(Wpa,"TFXLMForSequenceClassification"),Wpa.forEach(t),$tt=r(leo," (XLM model)"),leo.forEach(t),ktt=i(ae),e6=n(ae,"LI",{});var ieo=s(e6);N9e=n(ieo,"STRONG",{});var Upa=s(N9e);Stt=r(Upa,"xlm-roberta"),Upa.forEach(t),Rtt=r(ieo," \u2014 "),Pne=n(ieo,"A",{href:!0});var Hpa=s(Pne);Ptt=r(Hpa,"TFXLMRobertaForSequenceClassification"),Hpa.forEach(t),Btt=r(ieo," (XLM-RoBERTa model)"),ieo.forEach(t),Itt=i(ae),o6=n(ae,"LI",{});var deo=s(o6);q9e=n(deo,"STRONG",{});var Jpa=s(q9e);Ntt=r(Jpa,"xlnet"),Jpa.forEach(t),qtt=r(deo," \u2014 "),Bne=n(deo,"A",{href:!0});var Ypa=s(Bne);jtt=r(Ypa,"TFXLNetForSequenceClassification"),Ypa.forEach(t),Dtt=r(deo," (XLNet model)"),deo.forEach(t),ae.forEach(t),Gtt=i(ki),T(r6.$$.fragment,ki),ki.forEach(t),$i.forEach(t),rno=i(f),If=n(f,"H2",{class:!0});var Tlo=s(If);t6=n(Tlo,"A",{id:!0,class:!0,href:!0});var Zpa=s(t6);j9e=n(Zpa,"SPAN",{});var Kpa=s(j9e);T(eP.$$.fragment,Kpa),Kpa.forEach(t),Zpa.forEach(t),Ott=i(Tlo),D9e=n(Tlo,"SPAN",{});var e_a=s(D9e);Vtt=r(e_a,"TFAutoModelForMultipleChoice"),e_a.forEach(t),Tlo.forEach(t),tno=i(f),vr=n(f,"DIV",{class:!0});var Si=s(vr);T(oP.$$.fragment,Si),Xtt=i(Si),Nf=n(Si,"P",{});var wfe=s(Nf);ztt=r(wfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Ine=n(wfe,"A",{href:!0});var o_a=s(Ine);Qtt=r(o_a,"from_pretrained()"),o_a.forEach(t),Wtt=r(wfe," class method or the "),Nne=n(wfe,"A",{href:!0});var r_a=s(Nne);Utt=r(r_a,"from_config()"),r_a.forEach(t),Htt=r(wfe,` class
method.`),wfe.forEach(t),Jtt=i(Si),rP=n(Si,"P",{});var Mlo=s(rP);Ytt=r(Mlo,"This class cannot be instantiated directly using "),G9e=n(Mlo,"CODE",{});var t_a=s(G9e);Ztt=r(t_a,"__init__()"),t_a.forEach(t),Ktt=r(Mlo," (throws an error)."),Mlo.forEach(t),eat=i(Si),na=n(Si,"DIV",{class:!0});var bx=s(na);T(tP.$$.fragment,bx),oat=i(bx),O9e=n(bx,"P",{});var a_a=s(O9e);rat=r(a_a,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),a_a.forEach(t),tat=i(bx),qf=n(bx,"P",{});var Afe=s(qf);aat=r(Afe,`Note:
Loading a model from its configuration file does `),V9e=n(Afe,"STRONG",{});var n_a=s(V9e);nat=r(n_a,"not"),n_a.forEach(t),sat=r(Afe,` load the model weights. It only affects the
model\u2019s configuration. Use `),qne=n(Afe,"A",{href:!0});var s_a=s(qne);lat=r(s_a,"from_pretrained()"),s_a.forEach(t),iat=r(Afe," to load the model weights."),Afe.forEach(t),dat=i(bx),T(a6.$$.fragment,bx),bx.forEach(t),cat=i(Si),Ur=n(Si,"DIV",{class:!0});var Ri=s(Ur);T(aP.$$.fragment,Ri),fat=i(Ri),X9e=n(Ri,"P",{});var l_a=s(X9e);mat=r(l_a,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),l_a.forEach(t),gat=i(Ri),Vn=n(Ri,"P",{});var Fx=s(Vn);hat=r(Fx,"The model class to instantiate is selected based on the "),z9e=n(Fx,"CODE",{});var i_a=s(z9e);uat=r(i_a,"model_type"),i_a.forEach(t),pat=r(Fx,` property of the config object (either
passed as an argument or loaded from `),Q9e=n(Fx,"CODE",{});var d_a=s(Q9e);_at=r(d_a,"pretrained_model_name_or_path"),d_a.forEach(t),vat=r(Fx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W9e=n(Fx,"CODE",{});var c_a=s(W9e);bat=r(c_a,"pretrained_model_name_or_path"),c_a.forEach(t),Fat=r(Fx,":"),Fx.forEach(t),Tat=i(Ri),be=n(Ri,"UL",{});var Te=s(be);n6=n(Te,"LI",{});var ceo=s(n6);U9e=n(ceo,"STRONG",{});var f_a=s(U9e);Mat=r(f_a,"albert"),f_a.forEach(t),Eat=r(ceo," \u2014 "),jne=n(ceo,"A",{href:!0});var m_a=s(jne);Cat=r(m_a,"TFAlbertForMultipleChoice"),m_a.forEach(t),wat=r(ceo," (ALBERT model)"),ceo.forEach(t),Aat=i(Te),s6=n(Te,"LI",{});var feo=s(s6);H9e=n(feo,"STRONG",{});var g_a=s(H9e);Lat=r(g_a,"bert"),g_a.forEach(t),yat=r(feo," \u2014 "),Dne=n(feo,"A",{href:!0});var h_a=s(Dne);xat=r(h_a,"TFBertForMultipleChoice"),h_a.forEach(t),$at=r(feo," (BERT model)"),feo.forEach(t),kat=i(Te),l6=n(Te,"LI",{});var meo=s(l6);J9e=n(meo,"STRONG",{});var u_a=s(J9e);Sat=r(u_a,"camembert"),u_a.forEach(t),Rat=r(meo," \u2014 "),Gne=n(meo,"A",{href:!0});var p_a=s(Gne);Pat=r(p_a,"TFCamembertForMultipleChoice"),p_a.forEach(t),Bat=r(meo," (CamemBERT model)"),meo.forEach(t),Iat=i(Te),i6=n(Te,"LI",{});var geo=s(i6);Y9e=n(geo,"STRONG",{});var __a=s(Y9e);Nat=r(__a,"convbert"),__a.forEach(t),qat=r(geo," \u2014 "),One=n(geo,"A",{href:!0});var v_a=s(One);jat=r(v_a,"TFConvBertForMultipleChoice"),v_a.forEach(t),Dat=r(geo," (ConvBERT model)"),geo.forEach(t),Gat=i(Te),d6=n(Te,"LI",{});var heo=s(d6);Z9e=n(heo,"STRONG",{});var b_a=s(Z9e);Oat=r(b_a,"distilbert"),b_a.forEach(t),Vat=r(heo," \u2014 "),Vne=n(heo,"A",{href:!0});var F_a=s(Vne);Xat=r(F_a,"TFDistilBertForMultipleChoice"),F_a.forEach(t),zat=r(heo," (DistilBERT model)"),heo.forEach(t),Qat=i(Te),c6=n(Te,"LI",{});var ueo=s(c6);K9e=n(ueo,"STRONG",{});var T_a=s(K9e);Wat=r(T_a,"electra"),T_a.forEach(t),Uat=r(ueo," \u2014 "),Xne=n(ueo,"A",{href:!0});var M_a=s(Xne);Hat=r(M_a,"TFElectraForMultipleChoice"),M_a.forEach(t),Jat=r(ueo," (ELECTRA model)"),ueo.forEach(t),Yat=i(Te),f6=n(Te,"LI",{});var peo=s(f6);exe=n(peo,"STRONG",{});var E_a=s(exe);Zat=r(E_a,"flaubert"),E_a.forEach(t),Kat=r(peo," \u2014 "),zne=n(peo,"A",{href:!0});var C_a=s(zne);ent=r(C_a,"TFFlaubertForMultipleChoice"),C_a.forEach(t),ont=r(peo," (FlauBERT model)"),peo.forEach(t),rnt=i(Te),m6=n(Te,"LI",{});var _eo=s(m6);oxe=n(_eo,"STRONG",{});var w_a=s(oxe);tnt=r(w_a,"funnel"),w_a.forEach(t),ant=r(_eo," \u2014 "),Qne=n(_eo,"A",{href:!0});var A_a=s(Qne);nnt=r(A_a,"TFFunnelForMultipleChoice"),A_a.forEach(t),snt=r(_eo," (Funnel Transformer model)"),_eo.forEach(t),lnt=i(Te),g6=n(Te,"LI",{});var veo=s(g6);rxe=n(veo,"STRONG",{});var L_a=s(rxe);int=r(L_a,"longformer"),L_a.forEach(t),dnt=r(veo," \u2014 "),Wne=n(veo,"A",{href:!0});var y_a=s(Wne);cnt=r(y_a,"TFLongformerForMultipleChoice"),y_a.forEach(t),fnt=r(veo," (Longformer model)"),veo.forEach(t),mnt=i(Te),h6=n(Te,"LI",{});var beo=s(h6);txe=n(beo,"STRONG",{});var x_a=s(txe);gnt=r(x_a,"mobilebert"),x_a.forEach(t),hnt=r(beo," \u2014 "),Une=n(beo,"A",{href:!0});var $_a=s(Une);unt=r($_a,"TFMobileBertForMultipleChoice"),$_a.forEach(t),pnt=r(beo," (MobileBERT model)"),beo.forEach(t),_nt=i(Te),u6=n(Te,"LI",{});var Feo=s(u6);axe=n(Feo,"STRONG",{});var k_a=s(axe);vnt=r(k_a,"mpnet"),k_a.forEach(t),bnt=r(Feo," \u2014 "),Hne=n(Feo,"A",{href:!0});var S_a=s(Hne);Fnt=r(S_a,"TFMPNetForMultipleChoice"),S_a.forEach(t),Tnt=r(Feo," (MPNet model)"),Feo.forEach(t),Mnt=i(Te),p6=n(Te,"LI",{});var Teo=s(p6);nxe=n(Teo,"STRONG",{});var R_a=s(nxe);Ent=r(R_a,"rembert"),R_a.forEach(t),Cnt=r(Teo," \u2014 "),Jne=n(Teo,"A",{href:!0});var P_a=s(Jne);wnt=r(P_a,"TFRemBertForMultipleChoice"),P_a.forEach(t),Ant=r(Teo," (RemBERT model)"),Teo.forEach(t),Lnt=i(Te),_6=n(Te,"LI",{});var Meo=s(_6);sxe=n(Meo,"STRONG",{});var B_a=s(sxe);ynt=r(B_a,"roberta"),B_a.forEach(t),xnt=r(Meo," \u2014 "),Yne=n(Meo,"A",{href:!0});var I_a=s(Yne);$nt=r(I_a,"TFRobertaForMultipleChoice"),I_a.forEach(t),knt=r(Meo," (RoBERTa model)"),Meo.forEach(t),Snt=i(Te),v6=n(Te,"LI",{});var Eeo=s(v6);lxe=n(Eeo,"STRONG",{});var N_a=s(lxe);Rnt=r(N_a,"roformer"),N_a.forEach(t),Pnt=r(Eeo," \u2014 "),Zne=n(Eeo,"A",{href:!0});var q_a=s(Zne);Bnt=r(q_a,"TFRoFormerForMultipleChoice"),q_a.forEach(t),Int=r(Eeo," (RoFormer model)"),Eeo.forEach(t),Nnt=i(Te),b6=n(Te,"LI",{});var Ceo=s(b6);ixe=n(Ceo,"STRONG",{});var j_a=s(ixe);qnt=r(j_a,"xlm"),j_a.forEach(t),jnt=r(Ceo," \u2014 "),Kne=n(Ceo,"A",{href:!0});var D_a=s(Kne);Dnt=r(D_a,"TFXLMForMultipleChoice"),D_a.forEach(t),Gnt=r(Ceo," (XLM model)"),Ceo.forEach(t),Ont=i(Te),F6=n(Te,"LI",{});var weo=s(F6);dxe=n(weo,"STRONG",{});var G_a=s(dxe);Vnt=r(G_a,"xlm-roberta"),G_a.forEach(t),Xnt=r(weo," \u2014 "),ese=n(weo,"A",{href:!0});var O_a=s(ese);znt=r(O_a,"TFXLMRobertaForMultipleChoice"),O_a.forEach(t),Qnt=r(weo," (XLM-RoBERTa model)"),weo.forEach(t),Wnt=i(Te),T6=n(Te,"LI",{});var Aeo=s(T6);cxe=n(Aeo,"STRONG",{});var V_a=s(cxe);Unt=r(V_a,"xlnet"),V_a.forEach(t),Hnt=r(Aeo," \u2014 "),ose=n(Aeo,"A",{href:!0});var X_a=s(ose);Jnt=r(X_a,"TFXLNetForMultipleChoice"),X_a.forEach(t),Ynt=r(Aeo," (XLNet model)"),Aeo.forEach(t),Te.forEach(t),Znt=i(Ri),T(M6.$$.fragment,Ri),Ri.forEach(t),Si.forEach(t),ano=i(f),jf=n(f,"H2",{class:!0});var Elo=s(jf);E6=n(Elo,"A",{id:!0,class:!0,href:!0});var z_a=s(E6);fxe=n(z_a,"SPAN",{});var Q_a=s(fxe);T(nP.$$.fragment,Q_a),Q_a.forEach(t),z_a.forEach(t),Knt=i(Elo),mxe=n(Elo,"SPAN",{});var W_a=s(mxe);est=r(W_a,"TFAutoModelForNextSentencePrediction"),W_a.forEach(t),Elo.forEach(t),nno=i(f),br=n(f,"DIV",{class:!0});var Pi=s(br);T(sP.$$.fragment,Pi),ost=i(Pi),Df=n(Pi,"P",{});var Lfe=s(Df);rst=r(Lfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),rse=n(Lfe,"A",{href:!0});var U_a=s(rse);tst=r(U_a,"from_pretrained()"),U_a.forEach(t),ast=r(Lfe," class method or the "),tse=n(Lfe,"A",{href:!0});var H_a=s(tse);nst=r(H_a,"from_config()"),H_a.forEach(t),sst=r(Lfe,` class
method.`),Lfe.forEach(t),lst=i(Pi),lP=n(Pi,"P",{});var Clo=s(lP);ist=r(Clo,"This class cannot be instantiated directly using "),gxe=n(Clo,"CODE",{});var J_a=s(gxe);dst=r(J_a,"__init__()"),J_a.forEach(t),cst=r(Clo," (throws an error)."),Clo.forEach(t),fst=i(Pi),sa=n(Pi,"DIV",{class:!0});var Tx=s(sa);T(iP.$$.fragment,Tx),mst=i(Tx),hxe=n(Tx,"P",{});var Y_a=s(hxe);gst=r(Y_a,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Y_a.forEach(t),hst=i(Tx),Gf=n(Tx,"P",{});var yfe=s(Gf);ust=r(yfe,`Note:
Loading a model from its configuration file does `),uxe=n(yfe,"STRONG",{});var Z_a=s(uxe);pst=r(Z_a,"not"),Z_a.forEach(t),_st=r(yfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),ase=n(yfe,"A",{href:!0});var K_a=s(ase);vst=r(K_a,"from_pretrained()"),K_a.forEach(t),bst=r(yfe," to load the model weights."),yfe.forEach(t),Fst=i(Tx),T(C6.$$.fragment,Tx),Tx.forEach(t),Tst=i(Pi),Hr=n(Pi,"DIV",{class:!0});var Bi=s(Hr);T(dP.$$.fragment,Bi),Mst=i(Bi),pxe=n(Bi,"P",{});var e4a=s(pxe);Est=r(e4a,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),e4a.forEach(t),Cst=i(Bi),Xn=n(Bi,"P",{});var Mx=s(Xn);wst=r(Mx,"The model class to instantiate is selected based on the "),_xe=n(Mx,"CODE",{});var o4a=s(_xe);Ast=r(o4a,"model_type"),o4a.forEach(t),Lst=r(Mx,` property of the config object (either
passed as an argument or loaded from `),vxe=n(Mx,"CODE",{});var r4a=s(vxe);yst=r(r4a,"pretrained_model_name_or_path"),r4a.forEach(t),xst=r(Mx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bxe=n(Mx,"CODE",{});var t4a=s(bxe);$st=r(t4a,"pretrained_model_name_or_path"),t4a.forEach(t),kst=r(Mx,":"),Mx.forEach(t),Sst=i(Bi),cP=n(Bi,"UL",{});var wlo=s(cP);w6=n(wlo,"LI",{});var Leo=s(w6);Fxe=n(Leo,"STRONG",{});var a4a=s(Fxe);Rst=r(a4a,"bert"),a4a.forEach(t),Pst=r(Leo," \u2014 "),nse=n(Leo,"A",{href:!0});var n4a=s(nse);Bst=r(n4a,"TFBertForNextSentencePrediction"),n4a.forEach(t),Ist=r(Leo," (BERT model)"),Leo.forEach(t),Nst=i(wlo),A6=n(wlo,"LI",{});var yeo=s(A6);Txe=n(yeo,"STRONG",{});var s4a=s(Txe);qst=r(s4a,"mobilebert"),s4a.forEach(t),jst=r(yeo," \u2014 "),sse=n(yeo,"A",{href:!0});var l4a=s(sse);Dst=r(l4a,"TFMobileBertForNextSentencePrediction"),l4a.forEach(t),Gst=r(yeo," (MobileBERT model)"),yeo.forEach(t),wlo.forEach(t),Ost=i(Bi),T(L6.$$.fragment,Bi),Bi.forEach(t),Pi.forEach(t),sno=i(f),Of=n(f,"H2",{class:!0});var Alo=s(Of);y6=n(Alo,"A",{id:!0,class:!0,href:!0});var i4a=s(y6);Mxe=n(i4a,"SPAN",{});var d4a=s(Mxe);T(fP.$$.fragment,d4a),d4a.forEach(t),i4a.forEach(t),Vst=i(Alo),Exe=n(Alo,"SPAN",{});var c4a=s(Exe);Xst=r(c4a,"TFAutoModelForTableQuestionAnswering"),c4a.forEach(t),Alo.forEach(t),lno=i(f),Fr=n(f,"DIV",{class:!0});var Ii=s(Fr);T(mP.$$.fragment,Ii),zst=i(Ii),Vf=n(Ii,"P",{});var xfe=s(Vf);Qst=r(xfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),lse=n(xfe,"A",{href:!0});var f4a=s(lse);Wst=r(f4a,"from_pretrained()"),f4a.forEach(t),Ust=r(xfe," class method or the "),ise=n(xfe,"A",{href:!0});var m4a=s(ise);Hst=r(m4a,"from_config()"),m4a.forEach(t),Jst=r(xfe,` class
method.`),xfe.forEach(t),Yst=i(Ii),gP=n(Ii,"P",{});var Llo=s(gP);Zst=r(Llo,"This class cannot be instantiated directly using "),Cxe=n(Llo,"CODE",{});var g4a=s(Cxe);Kst=r(g4a,"__init__()"),g4a.forEach(t),elt=r(Llo," (throws an error)."),Llo.forEach(t),olt=i(Ii),la=n(Ii,"DIV",{class:!0});var Ex=s(la);T(hP.$$.fragment,Ex),rlt=i(Ex),wxe=n(Ex,"P",{});var h4a=s(wxe);tlt=r(h4a,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),h4a.forEach(t),alt=i(Ex),Xf=n(Ex,"P",{});var $fe=s(Xf);nlt=r($fe,`Note:
Loading a model from its configuration file does `),Axe=n($fe,"STRONG",{});var u4a=s(Axe);slt=r(u4a,"not"),u4a.forEach(t),llt=r($fe,` load the model weights. It only affects the
model\u2019s configuration. Use `),dse=n($fe,"A",{href:!0});var p4a=s(dse);ilt=r(p4a,"from_pretrained()"),p4a.forEach(t),dlt=r($fe," to load the model weights."),$fe.forEach(t),clt=i(Ex),T(x6.$$.fragment,Ex),Ex.forEach(t),flt=i(Ii),Jr=n(Ii,"DIV",{class:!0});var Ni=s(Jr);T(uP.$$.fragment,Ni),mlt=i(Ni),Lxe=n(Ni,"P",{});var _4a=s(Lxe);glt=r(_4a,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),_4a.forEach(t),hlt=i(Ni),zn=n(Ni,"P",{});var Cx=s(zn);ult=r(Cx,"The model class to instantiate is selected based on the "),yxe=n(Cx,"CODE",{});var v4a=s(yxe);plt=r(v4a,"model_type"),v4a.forEach(t),_lt=r(Cx,` property of the config object (either
passed as an argument or loaded from `),xxe=n(Cx,"CODE",{});var b4a=s(xxe);vlt=r(b4a,"pretrained_model_name_or_path"),b4a.forEach(t),blt=r(Cx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$xe=n(Cx,"CODE",{});var F4a=s($xe);Flt=r(F4a,"pretrained_model_name_or_path"),F4a.forEach(t),Tlt=r(Cx,":"),Cx.forEach(t),Mlt=i(Ni),kxe=n(Ni,"UL",{});var T4a=s(kxe);$6=n(T4a,"LI",{});var xeo=s($6);Sxe=n(xeo,"STRONG",{});var M4a=s(Sxe);Elt=r(M4a,"tapas"),M4a.forEach(t),Clt=r(xeo," \u2014 "),cse=n(xeo,"A",{href:!0});var E4a=s(cse);wlt=r(E4a,"TFTapasForQuestionAnswering"),E4a.forEach(t),Alt=r(xeo," (TAPAS model)"),xeo.forEach(t),T4a.forEach(t),Llt=i(Ni),T(k6.$$.fragment,Ni),Ni.forEach(t),Ii.forEach(t),ino=i(f),zf=n(f,"H2",{class:!0});var ylo=s(zf);S6=n(ylo,"A",{id:!0,class:!0,href:!0});var C4a=s(S6);Rxe=n(C4a,"SPAN",{});var w4a=s(Rxe);T(pP.$$.fragment,w4a),w4a.forEach(t),C4a.forEach(t),ylt=i(ylo),Pxe=n(ylo,"SPAN",{});var A4a=s(Pxe);xlt=r(A4a,"TFAutoModelForDocumentQuestionAnswering"),A4a.forEach(t),ylo.forEach(t),dno=i(f),Tr=n(f,"DIV",{class:!0});var qi=s(Tr);T(_P.$$.fragment,qi),$lt=i(qi),Qf=n(qi,"P",{});var kfe=s(Qf);klt=r(kfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),fse=n(kfe,"A",{href:!0});var L4a=s(fse);Slt=r(L4a,"from_pretrained()"),L4a.forEach(t),Rlt=r(kfe," class method or the "),mse=n(kfe,"A",{href:!0});var y4a=s(mse);Plt=r(y4a,"from_config()"),y4a.forEach(t),Blt=r(kfe,` class
method.`),kfe.forEach(t),Ilt=i(qi),vP=n(qi,"P",{});var xlo=s(vP);Nlt=r(xlo,"This class cannot be instantiated directly using "),Bxe=n(xlo,"CODE",{});var x4a=s(Bxe);qlt=r(x4a,"__init__()"),x4a.forEach(t),jlt=r(xlo," (throws an error)."),xlo.forEach(t),Dlt=i(qi),ia=n(qi,"DIV",{class:!0});var wx=s(ia);T(bP.$$.fragment,wx),Glt=i(wx),Ixe=n(wx,"P",{});var $4a=s(Ixe);Olt=r($4a,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),$4a.forEach(t),Vlt=i(wx),Wf=n(wx,"P",{});var Sfe=s(Wf);Xlt=r(Sfe,`Note:
Loading a model from its configuration file does `),Nxe=n(Sfe,"STRONG",{});var k4a=s(Nxe);zlt=r(k4a,"not"),k4a.forEach(t),Qlt=r(Sfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),gse=n(Sfe,"A",{href:!0});var S4a=s(gse);Wlt=r(S4a,"from_pretrained()"),S4a.forEach(t),Ult=r(Sfe," to load the model weights."),Sfe.forEach(t),Hlt=i(wx),T(R6.$$.fragment,wx),wx.forEach(t),Jlt=i(qi),Yr=n(qi,"DIV",{class:!0});var ji=s(Yr);T(FP.$$.fragment,ji),Ylt=i(ji),qxe=n(ji,"P",{});var R4a=s(qxe);Zlt=r(R4a,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),R4a.forEach(t),Klt=i(ji),Qn=n(ji,"P",{});var Ax=s(Qn);eit=r(Ax,"The model class to instantiate is selected based on the "),jxe=n(Ax,"CODE",{});var P4a=s(jxe);oit=r(P4a,"model_type"),P4a.forEach(t),rit=r(Ax,` property of the config object (either
passed as an argument or loaded from `),Dxe=n(Ax,"CODE",{});var B4a=s(Dxe);tit=r(B4a,"pretrained_model_name_or_path"),B4a.forEach(t),ait=r(Ax,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gxe=n(Ax,"CODE",{});var I4a=s(Gxe);nit=r(I4a,"pretrained_model_name_or_path"),I4a.forEach(t),sit=r(Ax,":"),Ax.forEach(t),lit=i(ji),Oxe=n(ji,"UL",{});var N4a=s(Oxe);P6=n(N4a,"LI",{});var $eo=s(P6);Vxe=n($eo,"STRONG",{});var q4a=s(Vxe);iit=r(q4a,"layoutlm"),q4a.forEach(t),dit=r($eo," \u2014 "),hse=n($eo,"A",{href:!0});var j4a=s(hse);cit=r(j4a,"TFLayoutLMForQuestionAnswering"),j4a.forEach(t),fit=r($eo," (LayoutLM model)"),$eo.forEach(t),N4a.forEach(t),mit=i(ji),T(B6.$$.fragment,ji),ji.forEach(t),qi.forEach(t),cno=i(f),Uf=n(f,"H2",{class:!0});var $lo=s(Uf);I6=n($lo,"A",{id:!0,class:!0,href:!0});var D4a=s(I6);Xxe=n(D4a,"SPAN",{});var G4a=s(Xxe);T(TP.$$.fragment,G4a),G4a.forEach(t),D4a.forEach(t),git=i($lo),zxe=n($lo,"SPAN",{});var O4a=s(zxe);hit=r(O4a,"TFAutoModelForTokenClassification"),O4a.forEach(t),$lo.forEach(t),fno=i(f),Mr=n(f,"DIV",{class:!0});var Di=s(Mr);T(MP.$$.fragment,Di),uit=i(Di),Hf=n(Di,"P",{});var Rfe=s(Hf);pit=r(Rfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),use=n(Rfe,"A",{href:!0});var V4a=s(use);_it=r(V4a,"from_pretrained()"),V4a.forEach(t),vit=r(Rfe," class method or the "),pse=n(Rfe,"A",{href:!0});var X4a=s(pse);bit=r(X4a,"from_config()"),X4a.forEach(t),Fit=r(Rfe,` class
method.`),Rfe.forEach(t),Tit=i(Di),EP=n(Di,"P",{});var klo=s(EP);Mit=r(klo,"This class cannot be instantiated directly using "),Qxe=n(klo,"CODE",{});var z4a=s(Qxe);Eit=r(z4a,"__init__()"),z4a.forEach(t),Cit=r(klo," (throws an error)."),klo.forEach(t),wit=i(Di),da=n(Di,"DIV",{class:!0});var Lx=s(da);T(CP.$$.fragment,Lx),Ait=i(Lx),Wxe=n(Lx,"P",{});var Q4a=s(Wxe);Lit=r(Q4a,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Q4a.forEach(t),yit=i(Lx),Jf=n(Lx,"P",{});var Pfe=s(Jf);xit=r(Pfe,`Note:
Loading a model from its configuration file does `),Uxe=n(Pfe,"STRONG",{});var W4a=s(Uxe);$it=r(W4a,"not"),W4a.forEach(t),kit=r(Pfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),_se=n(Pfe,"A",{href:!0});var U4a=s(_se);Sit=r(U4a,"from_pretrained()"),U4a.forEach(t),Rit=r(Pfe," to load the model weights."),Pfe.forEach(t),Pit=i(Lx),T(N6.$$.fragment,Lx),Lx.forEach(t),Bit=i(Di),Zr=n(Di,"DIV",{class:!0});var Gi=s(Zr);T(wP.$$.fragment,Gi),Iit=i(Gi),Hxe=n(Gi,"P",{});var H4a=s(Hxe);Nit=r(H4a,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),H4a.forEach(t),qit=i(Gi),Wn=n(Gi,"P",{});var yx=s(Wn);jit=r(yx,"The model class to instantiate is selected based on the "),Jxe=n(yx,"CODE",{});var J4a=s(Jxe);Dit=r(J4a,"model_type"),J4a.forEach(t),Git=r(yx,` property of the config object (either
passed as an argument or loaded from `),Yxe=n(yx,"CODE",{});var Y4a=s(Yxe);Oit=r(Y4a,"pretrained_model_name_or_path"),Y4a.forEach(t),Vit=r(yx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zxe=n(yx,"CODE",{});var Z4a=s(Zxe);Xit=r(Z4a,"pretrained_model_name_or_path"),Z4a.forEach(t),zit=r(yx,":"),yx.forEach(t),Qit=i(Gi),ie=n(Gi,"UL",{});var ge=s(ie);q6=n(ge,"LI",{});var keo=s(q6);Kxe=n(keo,"STRONG",{});var K4a=s(Kxe);Wit=r(K4a,"albert"),K4a.forEach(t),Uit=r(keo," \u2014 "),vse=n(keo,"A",{href:!0});var e2a=s(vse);Hit=r(e2a,"TFAlbertForTokenClassification"),e2a.forEach(t),Jit=r(keo," (ALBERT model)"),keo.forEach(t),Yit=i(ge),j6=n(ge,"LI",{});var Seo=s(j6);e$e=n(Seo,"STRONG",{});var o2a=s(e$e);Zit=r(o2a,"bert"),o2a.forEach(t),Kit=r(Seo," \u2014 "),bse=n(Seo,"A",{href:!0});var r2a=s(bse);edt=r(r2a,"TFBertForTokenClassification"),r2a.forEach(t),odt=r(Seo," (BERT model)"),Seo.forEach(t),rdt=i(ge),D6=n(ge,"LI",{});var Reo=s(D6);o$e=n(Reo,"STRONG",{});var t2a=s(o$e);tdt=r(t2a,"camembert"),t2a.forEach(t),adt=r(Reo," \u2014 "),Fse=n(Reo,"A",{href:!0});var a2a=s(Fse);ndt=r(a2a,"TFCamembertForTokenClassification"),a2a.forEach(t),sdt=r(Reo," (CamemBERT model)"),Reo.forEach(t),ldt=i(ge),G6=n(ge,"LI",{});var Peo=s(G6);r$e=n(Peo,"STRONG",{});var n2a=s(r$e);idt=r(n2a,"convbert"),n2a.forEach(t),ddt=r(Peo," \u2014 "),Tse=n(Peo,"A",{href:!0});var s2a=s(Tse);cdt=r(s2a,"TFConvBertForTokenClassification"),s2a.forEach(t),fdt=r(Peo," (ConvBERT model)"),Peo.forEach(t),mdt=i(ge),O6=n(ge,"LI",{});var Beo=s(O6);t$e=n(Beo,"STRONG",{});var l2a=s(t$e);gdt=r(l2a,"deberta"),l2a.forEach(t),hdt=r(Beo," \u2014 "),Mse=n(Beo,"A",{href:!0});var i2a=s(Mse);udt=r(i2a,"TFDebertaForTokenClassification"),i2a.forEach(t),pdt=r(Beo," (DeBERTa model)"),Beo.forEach(t),_dt=i(ge),V6=n(ge,"LI",{});var Ieo=s(V6);a$e=n(Ieo,"STRONG",{});var d2a=s(a$e);vdt=r(d2a,"deberta-v2"),d2a.forEach(t),bdt=r(Ieo," \u2014 "),Ese=n(Ieo,"A",{href:!0});var c2a=s(Ese);Fdt=r(c2a,"TFDebertaV2ForTokenClassification"),c2a.forEach(t),Tdt=r(Ieo," (DeBERTa-v2 model)"),Ieo.forEach(t),Mdt=i(ge),X6=n(ge,"LI",{});var Neo=s(X6);n$e=n(Neo,"STRONG",{});var f2a=s(n$e);Edt=r(f2a,"distilbert"),f2a.forEach(t),Cdt=r(Neo," \u2014 "),Cse=n(Neo,"A",{href:!0});var m2a=s(Cse);wdt=r(m2a,"TFDistilBertForTokenClassification"),m2a.forEach(t),Adt=r(Neo," (DistilBERT model)"),Neo.forEach(t),Ldt=i(ge),z6=n(ge,"LI",{});var qeo=s(z6);s$e=n(qeo,"STRONG",{});var g2a=s(s$e);ydt=r(g2a,"electra"),g2a.forEach(t),xdt=r(qeo," \u2014 "),wse=n(qeo,"A",{href:!0});var h2a=s(wse);$dt=r(h2a,"TFElectraForTokenClassification"),h2a.forEach(t),kdt=r(qeo," (ELECTRA model)"),qeo.forEach(t),Sdt=i(ge),Q6=n(ge,"LI",{});var jeo=s(Q6);l$e=n(jeo,"STRONG",{});var u2a=s(l$e);Rdt=r(u2a,"esm"),u2a.forEach(t),Pdt=r(jeo," \u2014 "),Ase=n(jeo,"A",{href:!0});var p2a=s(Ase);Bdt=r(p2a,"TFEsmForTokenClassification"),p2a.forEach(t),Idt=r(jeo," (ESM model)"),jeo.forEach(t),Ndt=i(ge),W6=n(ge,"LI",{});var Deo=s(W6);i$e=n(Deo,"STRONG",{});var _2a=s(i$e);qdt=r(_2a,"flaubert"),_2a.forEach(t),jdt=r(Deo," \u2014 "),Lse=n(Deo,"A",{href:!0});var v2a=s(Lse);Ddt=r(v2a,"TFFlaubertForTokenClassification"),v2a.forEach(t),Gdt=r(Deo," (FlauBERT model)"),Deo.forEach(t),Odt=i(ge),U6=n(ge,"LI",{});var Geo=s(U6);d$e=n(Geo,"STRONG",{});var b2a=s(d$e);Vdt=r(b2a,"funnel"),b2a.forEach(t),Xdt=r(Geo," \u2014 "),yse=n(Geo,"A",{href:!0});var F2a=s(yse);zdt=r(F2a,"TFFunnelForTokenClassification"),F2a.forEach(t),Qdt=r(Geo," (Funnel Transformer model)"),Geo.forEach(t),Wdt=i(ge),H6=n(ge,"LI",{});var Oeo=s(H6);c$e=n(Oeo,"STRONG",{});var T2a=s(c$e);Udt=r(T2a,"layoutlm"),T2a.forEach(t),Hdt=r(Oeo," \u2014 "),xse=n(Oeo,"A",{href:!0});var M2a=s(xse);Jdt=r(M2a,"TFLayoutLMForTokenClassification"),M2a.forEach(t),Ydt=r(Oeo," (LayoutLM model)"),Oeo.forEach(t),Zdt=i(ge),J6=n(ge,"LI",{});var Veo=s(J6);f$e=n(Veo,"STRONG",{});var E2a=s(f$e);Kdt=r(E2a,"layoutlmv3"),E2a.forEach(t),ect=r(Veo," \u2014 "),$se=n(Veo,"A",{href:!0});var C2a=s($se);oct=r(C2a,"TFLayoutLMv3ForTokenClassification"),C2a.forEach(t),rct=r(Veo," (LayoutLMv3 model)"),Veo.forEach(t),tct=i(ge),Y6=n(ge,"LI",{});var Xeo=s(Y6);m$e=n(Xeo,"STRONG",{});var w2a=s(m$e);act=r(w2a,"longformer"),w2a.forEach(t),nct=r(Xeo," \u2014 "),kse=n(Xeo,"A",{href:!0});var A2a=s(kse);sct=r(A2a,"TFLongformerForTokenClassification"),A2a.forEach(t),lct=r(Xeo," (Longformer model)"),Xeo.forEach(t),ict=i(ge),Z6=n(ge,"LI",{});var zeo=s(Z6);g$e=n(zeo,"STRONG",{});var L2a=s(g$e);dct=r(L2a,"mobilebert"),L2a.forEach(t),cct=r(zeo," \u2014 "),Sse=n(zeo,"A",{href:!0});var y2a=s(Sse);fct=r(y2a,"TFMobileBertForTokenClassification"),y2a.forEach(t),mct=r(zeo," (MobileBERT model)"),zeo.forEach(t),gct=i(ge),K6=n(ge,"LI",{});var Qeo=s(K6);h$e=n(Qeo,"STRONG",{});var x2a=s(h$e);hct=r(x2a,"mpnet"),x2a.forEach(t),uct=r(Qeo," \u2014 "),Rse=n(Qeo,"A",{href:!0});var $2a=s(Rse);pct=r($2a,"TFMPNetForTokenClassification"),$2a.forEach(t),_ct=r(Qeo," (MPNet model)"),Qeo.forEach(t),vct=i(ge),e7=n(ge,"LI",{});var Weo=s(e7);u$e=n(Weo,"STRONG",{});var k2a=s(u$e);bct=r(k2a,"rembert"),k2a.forEach(t),Fct=r(Weo," \u2014 "),Pse=n(Weo,"A",{href:!0});var S2a=s(Pse);Tct=r(S2a,"TFRemBertForTokenClassification"),S2a.forEach(t),Mct=r(Weo," (RemBERT model)"),Weo.forEach(t),Ect=i(ge),o7=n(ge,"LI",{});var Ueo=s(o7);p$e=n(Ueo,"STRONG",{});var R2a=s(p$e);Cct=r(R2a,"roberta"),R2a.forEach(t),wct=r(Ueo," \u2014 "),Bse=n(Ueo,"A",{href:!0});var P2a=s(Bse);Act=r(P2a,"TFRobertaForTokenClassification"),P2a.forEach(t),Lct=r(Ueo," (RoBERTa model)"),Ueo.forEach(t),yct=i(ge),r7=n(ge,"LI",{});var Heo=s(r7);_$e=n(Heo,"STRONG",{});var B2a=s(_$e);xct=r(B2a,"roformer"),B2a.forEach(t),$ct=r(Heo," \u2014 "),Ise=n(Heo,"A",{href:!0});var I2a=s(Ise);kct=r(I2a,"TFRoFormerForTokenClassification"),I2a.forEach(t),Sct=r(Heo," (RoFormer model)"),Heo.forEach(t),Rct=i(ge),t7=n(ge,"LI",{});var Jeo=s(t7);v$e=n(Jeo,"STRONG",{});var N2a=s(v$e);Pct=r(N2a,"xlm"),N2a.forEach(t),Bct=r(Jeo," \u2014 "),Nse=n(Jeo,"A",{href:!0});var q2a=s(Nse);Ict=r(q2a,"TFXLMForTokenClassification"),q2a.forEach(t),Nct=r(Jeo," (XLM model)"),Jeo.forEach(t),qct=i(ge),a7=n(ge,"LI",{});var Yeo=s(a7);b$e=n(Yeo,"STRONG",{});var j2a=s(b$e);jct=r(j2a,"xlm-roberta"),j2a.forEach(t),Dct=r(Yeo," \u2014 "),qse=n(Yeo,"A",{href:!0});var D2a=s(qse);Gct=r(D2a,"TFXLMRobertaForTokenClassification"),D2a.forEach(t),Oct=r(Yeo," (XLM-RoBERTa model)"),Yeo.forEach(t),Vct=i(ge),n7=n(ge,"LI",{});var Zeo=s(n7);F$e=n(Zeo,"STRONG",{});var G2a=s(F$e);Xct=r(G2a,"xlnet"),G2a.forEach(t),zct=r(Zeo," \u2014 "),jse=n(Zeo,"A",{href:!0});var O2a=s(jse);Qct=r(O2a,"TFXLNetForTokenClassification"),O2a.forEach(t),Wct=r(Zeo," (XLNet model)"),Zeo.forEach(t),ge.forEach(t),Uct=i(Gi),T(s7.$$.fragment,Gi),Gi.forEach(t),Di.forEach(t),mno=i(f),Yf=n(f,"H2",{class:!0});var Slo=s(Yf);l7=n(Slo,"A",{id:!0,class:!0,href:!0});var V2a=s(l7);T$e=n(V2a,"SPAN",{});var X2a=s(T$e);T(AP.$$.fragment,X2a),X2a.forEach(t),V2a.forEach(t),Hct=i(Slo),M$e=n(Slo,"SPAN",{});var z2a=s(M$e);Jct=r(z2a,"TFAutoModelForQuestionAnswering"),z2a.forEach(t),Slo.forEach(t),gno=i(f),Er=n(f,"DIV",{class:!0});var Oi=s(Er);T(LP.$$.fragment,Oi),Yct=i(Oi),Zf=n(Oi,"P",{});var Bfe=s(Zf);Zct=r(Bfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Dse=n(Bfe,"A",{href:!0});var Q2a=s(Dse);Kct=r(Q2a,"from_pretrained()"),Q2a.forEach(t),eft=r(Bfe," class method or the "),Gse=n(Bfe,"A",{href:!0});var W2a=s(Gse);oft=r(W2a,"from_config()"),W2a.forEach(t),rft=r(Bfe,` class
method.`),Bfe.forEach(t),tft=i(Oi),yP=n(Oi,"P",{});var Rlo=s(yP);aft=r(Rlo,"This class cannot be instantiated directly using "),E$e=n(Rlo,"CODE",{});var U2a=s(E$e);nft=r(U2a,"__init__()"),U2a.forEach(t),sft=r(Rlo," (throws an error)."),Rlo.forEach(t),lft=i(Oi),ca=n(Oi,"DIV",{class:!0});var xx=s(ca);T(xP.$$.fragment,xx),ift=i(xx),C$e=n(xx,"P",{});var H2a=s(C$e);dft=r(H2a,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),H2a.forEach(t),cft=i(xx),Kf=n(xx,"P",{});var Ife=s(Kf);fft=r(Ife,`Note:
Loading a model from its configuration file does `),w$e=n(Ife,"STRONG",{});var J2a=s(w$e);mft=r(J2a,"not"),J2a.forEach(t),gft=r(Ife,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ose=n(Ife,"A",{href:!0});var Y2a=s(Ose);hft=r(Y2a,"from_pretrained()"),Y2a.forEach(t),uft=r(Ife," to load the model weights."),Ife.forEach(t),pft=i(xx),T(i7.$$.fragment,xx),xx.forEach(t),_ft=i(Oi),Kr=n(Oi,"DIV",{class:!0});var Vi=s(Kr);T($P.$$.fragment,Vi),vft=i(Vi),A$e=n(Vi,"P",{});var Z2a=s(A$e);bft=r(Z2a,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Z2a.forEach(t),Fft=i(Vi),Un=n(Vi,"P",{});var $x=s(Un);Tft=r($x,"The model class to instantiate is selected based on the "),L$e=n($x,"CODE",{});var K2a=s(L$e);Mft=r(K2a,"model_type"),K2a.forEach(t),Eft=r($x,` property of the config object (either
passed as an argument or loaded from `),y$e=n($x,"CODE",{});var eva=s(y$e);Cft=r(eva,"pretrained_model_name_or_path"),eva.forEach(t),wft=r($x,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x$e=n($x,"CODE",{});var ova=s(x$e);Aft=r(ova,"pretrained_model_name_or_path"),ova.forEach(t),Lft=r($x,":"),$x.forEach(t),yft=i(Vi),fe=n(Vi,"UL",{});var pe=s(fe);d7=n(pe,"LI",{});var Keo=s(d7);$$e=n(Keo,"STRONG",{});var rva=s($$e);xft=r(rva,"albert"),rva.forEach(t),$ft=r(Keo," \u2014 "),Vse=n(Keo,"A",{href:!0});var tva=s(Vse);kft=r(tva,"TFAlbertForQuestionAnswering"),tva.forEach(t),Sft=r(Keo," (ALBERT model)"),Keo.forEach(t),Rft=i(pe),c7=n(pe,"LI",{});var eoo=s(c7);k$e=n(eoo,"STRONG",{});var ava=s(k$e);Pft=r(ava,"bert"),ava.forEach(t),Bft=r(eoo," \u2014 "),Xse=n(eoo,"A",{href:!0});var nva=s(Xse);Ift=r(nva,"TFBertForQuestionAnswering"),nva.forEach(t),Nft=r(eoo," (BERT model)"),eoo.forEach(t),qft=i(pe),f7=n(pe,"LI",{});var ooo=s(f7);S$e=n(ooo,"STRONG",{});var sva=s(S$e);jft=r(sva,"camembert"),sva.forEach(t),Dft=r(ooo," \u2014 "),zse=n(ooo,"A",{href:!0});var lva=s(zse);Gft=r(lva,"TFCamembertForQuestionAnswering"),lva.forEach(t),Oft=r(ooo," (CamemBERT model)"),ooo.forEach(t),Vft=i(pe),m7=n(pe,"LI",{});var roo=s(m7);R$e=n(roo,"STRONG",{});var iva=s(R$e);Xft=r(iva,"convbert"),iva.forEach(t),zft=r(roo," \u2014 "),Qse=n(roo,"A",{href:!0});var dva=s(Qse);Qft=r(dva,"TFConvBertForQuestionAnswering"),dva.forEach(t),Wft=r(roo," (ConvBERT model)"),roo.forEach(t),Uft=i(pe),g7=n(pe,"LI",{});var too=s(g7);P$e=n(too,"STRONG",{});var cva=s(P$e);Hft=r(cva,"deberta"),cva.forEach(t),Jft=r(too," \u2014 "),Wse=n(too,"A",{href:!0});var fva=s(Wse);Yft=r(fva,"TFDebertaForQuestionAnswering"),fva.forEach(t),Zft=r(too," (DeBERTa model)"),too.forEach(t),Kft=i(pe),h7=n(pe,"LI",{});var aoo=s(h7);B$e=n(aoo,"STRONG",{});var mva=s(B$e);emt=r(mva,"deberta-v2"),mva.forEach(t),omt=r(aoo," \u2014 "),Use=n(aoo,"A",{href:!0});var gva=s(Use);rmt=r(gva,"TFDebertaV2ForQuestionAnswering"),gva.forEach(t),tmt=r(aoo," (DeBERTa-v2 model)"),aoo.forEach(t),amt=i(pe),u7=n(pe,"LI",{});var noo=s(u7);I$e=n(noo,"STRONG",{});var hva=s(I$e);nmt=r(hva,"distilbert"),hva.forEach(t),smt=r(noo," \u2014 "),Hse=n(noo,"A",{href:!0});var uva=s(Hse);lmt=r(uva,"TFDistilBertForQuestionAnswering"),uva.forEach(t),imt=r(noo," (DistilBERT model)"),noo.forEach(t),dmt=i(pe),p7=n(pe,"LI",{});var soo=s(p7);N$e=n(soo,"STRONG",{});var pva=s(N$e);cmt=r(pva,"electra"),pva.forEach(t),fmt=r(soo," \u2014 "),Jse=n(soo,"A",{href:!0});var _va=s(Jse);mmt=r(_va,"TFElectraForQuestionAnswering"),_va.forEach(t),gmt=r(soo," (ELECTRA model)"),soo.forEach(t),hmt=i(pe),_7=n(pe,"LI",{});var loo=s(_7);q$e=n(loo,"STRONG",{});var vva=s(q$e);umt=r(vva,"flaubert"),vva.forEach(t),pmt=r(loo," \u2014 "),Yse=n(loo,"A",{href:!0});var bva=s(Yse);_mt=r(bva,"TFFlaubertForQuestionAnsweringSimple"),bva.forEach(t),vmt=r(loo," (FlauBERT model)"),loo.forEach(t),bmt=i(pe),v7=n(pe,"LI",{});var ioo=s(v7);j$e=n(ioo,"STRONG",{});var Fva=s(j$e);Fmt=r(Fva,"funnel"),Fva.forEach(t),Tmt=r(ioo," \u2014 "),Zse=n(ioo,"A",{href:!0});var Tva=s(Zse);Mmt=r(Tva,"TFFunnelForQuestionAnswering"),Tva.forEach(t),Emt=r(ioo," (Funnel Transformer model)"),ioo.forEach(t),Cmt=i(pe),b7=n(pe,"LI",{});var doo=s(b7);D$e=n(doo,"STRONG",{});var Mva=s(D$e);wmt=r(Mva,"gptj"),Mva.forEach(t),Amt=r(doo," \u2014 "),Kse=n(doo,"A",{href:!0});var Eva=s(Kse);Lmt=r(Eva,"TFGPTJForQuestionAnswering"),Eva.forEach(t),ymt=r(doo," (GPT-J model)"),doo.forEach(t),xmt=i(pe),F7=n(pe,"LI",{});var coo=s(F7);G$e=n(coo,"STRONG",{});var Cva=s(G$e);$mt=r(Cva,"layoutlmv3"),Cva.forEach(t),kmt=r(coo," \u2014 "),ele=n(coo,"A",{href:!0});var wva=s(ele);Smt=r(wva,"TFLayoutLMv3ForQuestionAnswering"),wva.forEach(t),Rmt=r(coo," (LayoutLMv3 model)"),coo.forEach(t),Pmt=i(pe),T7=n(pe,"LI",{});var foo=s(T7);O$e=n(foo,"STRONG",{});var Ava=s(O$e);Bmt=r(Ava,"longformer"),Ava.forEach(t),Imt=r(foo," \u2014 "),ole=n(foo,"A",{href:!0});var Lva=s(ole);Nmt=r(Lva,"TFLongformerForQuestionAnswering"),Lva.forEach(t),qmt=r(foo," (Longformer model)"),foo.forEach(t),jmt=i(pe),M7=n(pe,"LI",{});var moo=s(M7);V$e=n(moo,"STRONG",{});var yva=s(V$e);Dmt=r(yva,"mobilebert"),yva.forEach(t),Gmt=r(moo," \u2014 "),rle=n(moo,"A",{href:!0});var xva=s(rle);Omt=r(xva,"TFMobileBertForQuestionAnswering"),xva.forEach(t),Vmt=r(moo," (MobileBERT model)"),moo.forEach(t),Xmt=i(pe),E7=n(pe,"LI",{});var goo=s(E7);X$e=n(goo,"STRONG",{});var $va=s(X$e);zmt=r($va,"mpnet"),$va.forEach(t),Qmt=r(goo," \u2014 "),tle=n(goo,"A",{href:!0});var kva=s(tle);Wmt=r(kva,"TFMPNetForQuestionAnswering"),kva.forEach(t),Umt=r(goo," (MPNet model)"),goo.forEach(t),Hmt=i(pe),C7=n(pe,"LI",{});var hoo=s(C7);z$e=n(hoo,"STRONG",{});var Sva=s(z$e);Jmt=r(Sva,"rembert"),Sva.forEach(t),Ymt=r(hoo," \u2014 "),ale=n(hoo,"A",{href:!0});var Rva=s(ale);Zmt=r(Rva,"TFRemBertForQuestionAnswering"),Rva.forEach(t),Kmt=r(hoo," (RemBERT model)"),hoo.forEach(t),egt=i(pe),w7=n(pe,"LI",{});var uoo=s(w7);Q$e=n(uoo,"STRONG",{});var Pva=s(Q$e);ogt=r(Pva,"roberta"),Pva.forEach(t),rgt=r(uoo," \u2014 "),nle=n(uoo,"A",{href:!0});var Bva=s(nle);tgt=r(Bva,"TFRobertaForQuestionAnswering"),Bva.forEach(t),agt=r(uoo," (RoBERTa model)"),uoo.forEach(t),ngt=i(pe),A7=n(pe,"LI",{});var poo=s(A7);W$e=n(poo,"STRONG",{});var Iva=s(W$e);sgt=r(Iva,"roformer"),Iva.forEach(t),lgt=r(poo," \u2014 "),sle=n(poo,"A",{href:!0});var Nva=s(sle);igt=r(Nva,"TFRoFormerForQuestionAnswering"),Nva.forEach(t),dgt=r(poo," (RoFormer model)"),poo.forEach(t),cgt=i(pe),L7=n(pe,"LI",{});var _oo=s(L7);U$e=n(_oo,"STRONG",{});var qva=s(U$e);fgt=r(qva,"xlm"),qva.forEach(t),mgt=r(_oo," \u2014 "),lle=n(_oo,"A",{href:!0});var jva=s(lle);ggt=r(jva,"TFXLMForQuestionAnsweringSimple"),jva.forEach(t),hgt=r(_oo," (XLM model)"),_oo.forEach(t),ugt=i(pe),y7=n(pe,"LI",{});var voo=s(y7);H$e=n(voo,"STRONG",{});var Dva=s(H$e);pgt=r(Dva,"xlm-roberta"),Dva.forEach(t),_gt=r(voo," \u2014 "),ile=n(voo,"A",{href:!0});var Gva=s(ile);vgt=r(Gva,"TFXLMRobertaForQuestionAnswering"),Gva.forEach(t),bgt=r(voo," (XLM-RoBERTa model)"),voo.forEach(t),Fgt=i(pe),x7=n(pe,"LI",{});var boo=s(x7);J$e=n(boo,"STRONG",{});var Ova=s(J$e);Tgt=r(Ova,"xlnet"),Ova.forEach(t),Mgt=r(boo," \u2014 "),dle=n(boo,"A",{href:!0});var Vva=s(dle);Egt=r(Vva,"TFXLNetForQuestionAnsweringSimple"),Vva.forEach(t),Cgt=r(boo," (XLNet model)"),boo.forEach(t),pe.forEach(t),wgt=i(Vi),T($7.$$.fragment,Vi),Vi.forEach(t),Oi.forEach(t),hno=i(f),em=n(f,"H2",{class:!0});var Plo=s(em);k7=n(Plo,"A",{id:!0,class:!0,href:!0});var Xva=s(k7);Y$e=n(Xva,"SPAN",{});var zva=s(Y$e);T(kP.$$.fragment,zva),zva.forEach(t),Xva.forEach(t),Agt=i(Plo),Z$e=n(Plo,"SPAN",{});var Qva=s(Z$e);Lgt=r(Qva,"TFAutoModelForVision2Seq"),Qva.forEach(t),Plo.forEach(t),uno=i(f),Cr=n(f,"DIV",{class:!0});var Xi=s(Cr);T(SP.$$.fragment,Xi),ygt=i(Xi),om=n(Xi,"P",{});var Nfe=s(om);xgt=r(Nfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),cle=n(Nfe,"A",{href:!0});var Wva=s(cle);$gt=r(Wva,"from_pretrained()"),Wva.forEach(t),kgt=r(Nfe," class method or the "),fle=n(Nfe,"A",{href:!0});var Uva=s(fle);Sgt=r(Uva,"from_config()"),Uva.forEach(t),Rgt=r(Nfe,` class
method.`),Nfe.forEach(t),Pgt=i(Xi),RP=n(Xi,"P",{});var Blo=s(RP);Bgt=r(Blo,"This class cannot be instantiated directly using "),K$e=n(Blo,"CODE",{});var Hva=s(K$e);Igt=r(Hva,"__init__()"),Hva.forEach(t),Ngt=r(Blo," (throws an error)."),Blo.forEach(t),qgt=i(Xi),fa=n(Xi,"DIV",{class:!0});var kx=s(fa);T(PP.$$.fragment,kx),jgt=i(kx),eke=n(kx,"P",{});var Jva=s(eke);Dgt=r(Jva,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Jva.forEach(t),Ggt=i(kx),rm=n(kx,"P",{});var qfe=s(rm);Ogt=r(qfe,`Note:
Loading a model from its configuration file does `),oke=n(qfe,"STRONG",{});var Yva=s(oke);Vgt=r(Yva,"not"),Yva.forEach(t),Xgt=r(qfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),mle=n(qfe,"A",{href:!0});var Zva=s(mle);zgt=r(Zva,"from_pretrained()"),Zva.forEach(t),Qgt=r(qfe," to load the model weights."),qfe.forEach(t),Wgt=i(kx),T(S7.$$.fragment,kx),kx.forEach(t),Ugt=i(Xi),et=n(Xi,"DIV",{class:!0});var zi=s(et);T(BP.$$.fragment,zi),Hgt=i(zi),rke=n(zi,"P",{});var Kva=s(rke);Jgt=r(Kva,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Kva.forEach(t),Ygt=i(zi),Hn=n(zi,"P",{});var Sx=s(Hn);Zgt=r(Sx,"The model class to instantiate is selected based on the "),tke=n(Sx,"CODE",{});var e1a=s(tke);Kgt=r(e1a,"model_type"),e1a.forEach(t),eht=r(Sx,` property of the config object (either
passed as an argument or loaded from `),ake=n(Sx,"CODE",{});var o1a=s(ake);oht=r(o1a,"pretrained_model_name_or_path"),o1a.forEach(t),rht=r(Sx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nke=n(Sx,"CODE",{});var r1a=s(nke);tht=r(r1a,"pretrained_model_name_or_path"),r1a.forEach(t),aht=r(Sx,":"),Sx.forEach(t),nht=i(zi),ske=n(zi,"UL",{});var t1a=s(ske);R7=n(t1a,"LI",{});var Foo=s(R7);lke=n(Foo,"STRONG",{});var a1a=s(lke);sht=r(a1a,"vision-encoder-decoder"),a1a.forEach(t),lht=r(Foo," \u2014 "),gle=n(Foo,"A",{href:!0});var n1a=s(gle);iht=r(n1a,"TFVisionEncoderDecoderModel"),n1a.forEach(t),dht=r(Foo," (Vision Encoder decoder model)"),Foo.forEach(t),t1a.forEach(t),cht=i(zi),T(P7.$$.fragment,zi),zi.forEach(t),Xi.forEach(t),pno=i(f),tm=n(f,"H2",{class:!0});var Ilo=s(tm);B7=n(Ilo,"A",{id:!0,class:!0,href:!0});var s1a=s(B7);ike=n(s1a,"SPAN",{});var l1a=s(ike);T(IP.$$.fragment,l1a),l1a.forEach(t),s1a.forEach(t),fht=i(Ilo),dke=n(Ilo,"SPAN",{});var i1a=s(dke);mht=r(i1a,"TFAutoModelForSpeechSeq2Seq"),i1a.forEach(t),Ilo.forEach(t),_no=i(f),wr=n(f,"DIV",{class:!0});var Qi=s(wr);T(NP.$$.fragment,Qi),ght=i(Qi),am=n(Qi,"P",{});var jfe=s(am);hht=r(jfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),hle=n(jfe,"A",{href:!0});var d1a=s(hle);uht=r(d1a,"from_pretrained()"),d1a.forEach(t),pht=r(jfe," class method or the "),ule=n(jfe,"A",{href:!0});var c1a=s(ule);_ht=r(c1a,"from_config()"),c1a.forEach(t),vht=r(jfe,` class
method.`),jfe.forEach(t),bht=i(Qi),qP=n(Qi,"P",{});var Nlo=s(qP);Fht=r(Nlo,"This class cannot be instantiated directly using "),cke=n(Nlo,"CODE",{});var f1a=s(cke);Tht=r(f1a,"__init__()"),f1a.forEach(t),Mht=r(Nlo," (throws an error)."),Nlo.forEach(t),Eht=i(Qi),ma=n(Qi,"DIV",{class:!0});var Rx=s(ma);T(jP.$$.fragment,Rx),Cht=i(Rx),fke=n(Rx,"P",{});var m1a=s(fke);wht=r(m1a,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),m1a.forEach(t),Aht=i(Rx),nm=n(Rx,"P",{});var Dfe=s(nm);Lht=r(Dfe,`Note:
Loading a model from its configuration file does `),mke=n(Dfe,"STRONG",{});var g1a=s(mke);yht=r(g1a,"not"),g1a.forEach(t),xht=r(Dfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),ple=n(Dfe,"A",{href:!0});var h1a=s(ple);$ht=r(h1a,"from_pretrained()"),h1a.forEach(t),kht=r(Dfe," to load the model weights."),Dfe.forEach(t),Sht=i(Rx),T(I7.$$.fragment,Rx),Rx.forEach(t),Rht=i(Qi),ot=n(Qi,"DIV",{class:!0});var Wi=s(ot);T(DP.$$.fragment,Wi),Pht=i(Wi),gke=n(Wi,"P",{});var u1a=s(gke);Bht=r(u1a,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),u1a.forEach(t),Iht=i(Wi),Jn=n(Wi,"P",{});var Px=s(Jn);Nht=r(Px,"The model class to instantiate is selected based on the "),hke=n(Px,"CODE",{});var p1a=s(hke);qht=r(p1a,"model_type"),p1a.forEach(t),jht=r(Px,` property of the config object (either
passed as an argument or loaded from `),uke=n(Px,"CODE",{});var _1a=s(uke);Dht=r(_1a,"pretrained_model_name_or_path"),_1a.forEach(t),Ght=r(Px,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pke=n(Px,"CODE",{});var v1a=s(pke);Oht=r(v1a,"pretrained_model_name_or_path"),v1a.forEach(t),Vht=r(Px,":"),Px.forEach(t),Xht=i(Wi),GP=n(Wi,"UL",{});var qlo=s(GP);N7=n(qlo,"LI",{});var Too=s(N7);_ke=n(Too,"STRONG",{});var b1a=s(_ke);zht=r(b1a,"speech_to_text"),b1a.forEach(t),Qht=r(Too," \u2014 "),_le=n(Too,"A",{href:!0});var F1a=s(_le);Wht=r(F1a,"TFSpeech2TextForConditionalGeneration"),F1a.forEach(t),Uht=r(Too," (Speech2Text model)"),Too.forEach(t),Hht=i(qlo),q7=n(qlo,"LI",{});var Moo=s(q7);vke=n(Moo,"STRONG",{});var T1a=s(vke);Jht=r(T1a,"whisper"),T1a.forEach(t),Yht=r(Moo," \u2014 "),vle=n(Moo,"A",{href:!0});var M1a=s(vle);Zht=r(M1a,"TFWhisperForConditionalGeneration"),M1a.forEach(t),Kht=r(Moo," (Whisper model)"),Moo.forEach(t),qlo.forEach(t),eut=i(Wi),T(j7.$$.fragment,Wi),Wi.forEach(t),Qi.forEach(t),vno=i(f),sm=n(f,"H2",{class:!0});var jlo=s(sm);D7=n(jlo,"A",{id:!0,class:!0,href:!0});var E1a=s(D7);bke=n(E1a,"SPAN",{});var C1a=s(bke);T(OP.$$.fragment,C1a),C1a.forEach(t),E1a.forEach(t),out=i(jlo),Fke=n(jlo,"SPAN",{});var w1a=s(Fke);rut=r(w1a,"FlaxAutoModel"),w1a.forEach(t),jlo.forEach(t),bno=i(f),Ar=n(f,"DIV",{class:!0});var Ui=s(Ar);T(VP.$$.fragment,Ui),tut=i(Ui),lm=n(Ui,"P",{});var Gfe=s(lm);aut=r(Gfe,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),ble=n(Gfe,"A",{href:!0});var A1a=s(ble);nut=r(A1a,"from_pretrained()"),A1a.forEach(t),sut=r(Gfe," class method or the "),Fle=n(Gfe,"A",{href:!0});var L1a=s(Fle);lut=r(L1a,"from_config()"),L1a.forEach(t),iut=r(Gfe,` class
method.`),Gfe.forEach(t),dut=i(Ui),XP=n(Ui,"P",{});var Dlo=s(XP);cut=r(Dlo,"This class cannot be instantiated directly using "),Tke=n(Dlo,"CODE",{});var y1a=s(Tke);fut=r(y1a,"__init__()"),y1a.forEach(t),mut=r(Dlo," (throws an error)."),Dlo.forEach(t),gut=i(Ui),ga=n(Ui,"DIV",{class:!0});var Bx=s(ga);T(zP.$$.fragment,Bx),hut=i(Bx),Mke=n(Bx,"P",{});var x1a=s(Mke);uut=r(x1a,"Instantiates one of the base model classes of the library from a configuration."),x1a.forEach(t),put=i(Bx),im=n(Bx,"P",{});var Ofe=s(im);_ut=r(Ofe,`Note:
Loading a model from its configuration file does `),Eke=n(Ofe,"STRONG",{});var $1a=s(Eke);vut=r($1a,"not"),$1a.forEach(t),but=r(Ofe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Tle=n(Ofe,"A",{href:!0});var k1a=s(Tle);Fut=r(k1a,"from_pretrained()"),k1a.forEach(t),Tut=r(Ofe," to load the model weights."),Ofe.forEach(t),Mut=i(Bx),T(G7.$$.fragment,Bx),Bx.forEach(t),Eut=i(Ui),rt=n(Ui,"DIV",{class:!0});var Hi=s(rt);T(QP.$$.fragment,Hi),Cut=i(Hi),Cke=n(Hi,"P",{});var S1a=s(Cke);wut=r(S1a,"Instantiate one of the base model classes of the library from a pretrained model."),S1a.forEach(t),Aut=i(Hi),Yn=n(Hi,"P",{});var Ix=s(Yn);Lut=r(Ix,"The model class to instantiate is selected based on the "),wke=n(Ix,"CODE",{});var R1a=s(wke);yut=r(R1a,"model_type"),R1a.forEach(t),xut=r(Ix,` property of the config object (either
passed as an argument or loaded from `),Ake=n(Ix,"CODE",{});var P1a=s(Ake);$ut=r(P1a,"pretrained_model_name_or_path"),P1a.forEach(t),kut=r(Ix,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lke=n(Ix,"CODE",{});var B1a=s(Lke);Sut=r(B1a,"pretrained_model_name_or_path"),B1a.forEach(t),Rut=r(Ix,":"),Ix.forEach(t),Put=i(Hi),te=n(Hi,"UL",{});var ne=s(te);O7=n(ne,"LI",{});var Eoo=s(O7);yke=n(Eoo,"STRONG",{});var I1a=s(yke);But=r(I1a,"albert"),I1a.forEach(t),Iut=r(Eoo," \u2014 "),Mle=n(Eoo,"A",{href:!0});var N1a=s(Mle);Nut=r(N1a,"FlaxAlbertModel"),N1a.forEach(t),qut=r(Eoo," (ALBERT model)"),Eoo.forEach(t),jut=i(ne),V7=n(ne,"LI",{});var Coo=s(V7);xke=n(Coo,"STRONG",{});var q1a=s(xke);Dut=r(q1a,"bart"),q1a.forEach(t),Gut=r(Coo," \u2014 "),Ele=n(Coo,"A",{href:!0});var j1a=s(Ele);Out=r(j1a,"FlaxBartModel"),j1a.forEach(t),Vut=r(Coo," (BART model)"),Coo.forEach(t),Xut=i(ne),X7=n(ne,"LI",{});var woo=s(X7);$ke=n(woo,"STRONG",{});var D1a=s($ke);zut=r(D1a,"beit"),D1a.forEach(t),Qut=r(woo," \u2014 "),Cle=n(woo,"A",{href:!0});var G1a=s(Cle);Wut=r(G1a,"FlaxBeitModel"),G1a.forEach(t),Uut=r(woo," (BEiT model)"),woo.forEach(t),Hut=i(ne),z7=n(ne,"LI",{});var Aoo=s(z7);kke=n(Aoo,"STRONG",{});var O1a=s(kke);Jut=r(O1a,"bert"),O1a.forEach(t),Yut=r(Aoo," \u2014 "),wle=n(Aoo,"A",{href:!0});var V1a=s(wle);Zut=r(V1a,"FlaxBertModel"),V1a.forEach(t),Kut=r(Aoo," (BERT model)"),Aoo.forEach(t),ept=i(ne),Q7=n(ne,"LI",{});var Loo=s(Q7);Ske=n(Loo,"STRONG",{});var X1a=s(Ske);opt=r(X1a,"big_bird"),X1a.forEach(t),rpt=r(Loo," \u2014 "),Ale=n(Loo,"A",{href:!0});var z1a=s(Ale);tpt=r(z1a,"FlaxBigBirdModel"),z1a.forEach(t),apt=r(Loo," (BigBird model)"),Loo.forEach(t),npt=i(ne),W7=n(ne,"LI",{});var yoo=s(W7);Rke=n(yoo,"STRONG",{});var Q1a=s(Rke);spt=r(Q1a,"blenderbot"),Q1a.forEach(t),lpt=r(yoo," \u2014 "),Lle=n(yoo,"A",{href:!0});var W1a=s(Lle);ipt=r(W1a,"FlaxBlenderbotModel"),W1a.forEach(t),dpt=r(yoo," (Blenderbot model)"),yoo.forEach(t),cpt=i(ne),U7=n(ne,"LI",{});var xoo=s(U7);Pke=n(xoo,"STRONG",{});var U1a=s(Pke);fpt=r(U1a,"blenderbot-small"),U1a.forEach(t),mpt=r(xoo," \u2014 "),yle=n(xoo,"A",{href:!0});var H1a=s(yle);gpt=r(H1a,"FlaxBlenderbotSmallModel"),H1a.forEach(t),hpt=r(xoo," (BlenderbotSmall model)"),xoo.forEach(t),upt=i(ne),H7=n(ne,"LI",{});var $oo=s(H7);Bke=n($oo,"STRONG",{});var J1a=s(Bke);ppt=r(J1a,"clip"),J1a.forEach(t),_pt=r($oo," \u2014 "),xle=n($oo,"A",{href:!0});var Y1a=s(xle);vpt=r(Y1a,"FlaxCLIPModel"),Y1a.forEach(t),bpt=r($oo," (CLIP model)"),$oo.forEach(t),Fpt=i(ne),J7=n(ne,"LI",{});var koo=s(J7);Ike=n(koo,"STRONG",{});var Z1a=s(Ike);Tpt=r(Z1a,"distilbert"),Z1a.forEach(t),Mpt=r(koo," \u2014 "),$le=n(koo,"A",{href:!0});var K1a=s($le);Ept=r(K1a,"FlaxDistilBertModel"),K1a.forEach(t),Cpt=r(koo," (DistilBERT model)"),koo.forEach(t),wpt=i(ne),Y7=n(ne,"LI",{});var Soo=s(Y7);Nke=n(Soo,"STRONG",{});var eba=s(Nke);Apt=r(eba,"electra"),eba.forEach(t),Lpt=r(Soo," \u2014 "),kle=n(Soo,"A",{href:!0});var oba=s(kle);ypt=r(oba,"FlaxElectraModel"),oba.forEach(t),xpt=r(Soo," (ELECTRA model)"),Soo.forEach(t),$pt=i(ne),Z7=n(ne,"LI",{});var Roo=s(Z7);qke=n(Roo,"STRONG",{});var rba=s(qke);kpt=r(rba,"gpt2"),rba.forEach(t),Spt=r(Roo," \u2014 "),Sle=n(Roo,"A",{href:!0});var tba=s(Sle);Rpt=r(tba,"FlaxGPT2Model"),tba.forEach(t),Ppt=r(Roo," (OpenAI GPT-2 model)"),Roo.forEach(t),Bpt=i(ne),K7=n(ne,"LI",{});var Poo=s(K7);jke=n(Poo,"STRONG",{});var aba=s(jke);Ipt=r(aba,"gpt_neo"),aba.forEach(t),Npt=r(Poo," \u2014 "),Rle=n(Poo,"A",{href:!0});var nba=s(Rle);qpt=r(nba,"FlaxGPTNeoModel"),nba.forEach(t),jpt=r(Poo," (GPT Neo model)"),Poo.forEach(t),Dpt=i(ne),e8=n(ne,"LI",{});var Boo=s(e8);Dke=n(Boo,"STRONG",{});var sba=s(Dke);Gpt=r(sba,"gptj"),sba.forEach(t),Opt=r(Boo," \u2014 "),Ple=n(Boo,"A",{href:!0});var lba=s(Ple);Vpt=r(lba,"FlaxGPTJModel"),lba.forEach(t),Xpt=r(Boo," (GPT-J model)"),Boo.forEach(t),zpt=i(ne),o8=n(ne,"LI",{});var Ioo=s(o8);Gke=n(Ioo,"STRONG",{});var iba=s(Gke);Qpt=r(iba,"longt5"),iba.forEach(t),Wpt=r(Ioo," \u2014 "),Ble=n(Ioo,"A",{href:!0});var dba=s(Ble);Upt=r(dba,"FlaxLongT5Model"),dba.forEach(t),Hpt=r(Ioo," (LongT5 model)"),Ioo.forEach(t),Jpt=i(ne),r8=n(ne,"LI",{});var Noo=s(r8);Oke=n(Noo,"STRONG",{});var cba=s(Oke);Ypt=r(cba,"marian"),cba.forEach(t),Zpt=r(Noo," \u2014 "),Ile=n(Noo,"A",{href:!0});var fba=s(Ile);Kpt=r(fba,"FlaxMarianModel"),fba.forEach(t),e_t=r(Noo," (Marian model)"),Noo.forEach(t),o_t=i(ne),t8=n(ne,"LI",{});var qoo=s(t8);Vke=n(qoo,"STRONG",{});var mba=s(Vke);r_t=r(mba,"mbart"),mba.forEach(t),t_t=r(qoo," \u2014 "),Nle=n(qoo,"A",{href:!0});var gba=s(Nle);a_t=r(gba,"FlaxMBartModel"),gba.forEach(t),n_t=r(qoo," (mBART model)"),qoo.forEach(t),s_t=i(ne),a8=n(ne,"LI",{});var joo=s(a8);Xke=n(joo,"STRONG",{});var hba=s(Xke);l_t=r(hba,"mt5"),hba.forEach(t),i_t=r(joo," \u2014 "),qle=n(joo,"A",{href:!0});var uba=s(qle);d_t=r(uba,"FlaxMT5Model"),uba.forEach(t),c_t=r(joo," (MT5 model)"),joo.forEach(t),f_t=i(ne),n8=n(ne,"LI",{});var Doo=s(n8);zke=n(Doo,"STRONG",{});var pba=s(zke);m_t=r(pba,"opt"),pba.forEach(t),g_t=r(Doo," \u2014 "),jle=n(Doo,"A",{href:!0});var _ba=s(jle);h_t=r(_ba,"FlaxOPTModel"),_ba.forEach(t),u_t=r(Doo," (OPT model)"),Doo.forEach(t),p_t=i(ne),s8=n(ne,"LI",{});var Goo=s(s8);Qke=n(Goo,"STRONG",{});var vba=s(Qke);__t=r(vba,"pegasus"),vba.forEach(t),v_t=r(Goo," \u2014 "),Dle=n(Goo,"A",{href:!0});var bba=s(Dle);b_t=r(bba,"FlaxPegasusModel"),bba.forEach(t),F_t=r(Goo," (Pegasus model)"),Goo.forEach(t),T_t=i(ne),l8=n(ne,"LI",{});var Ooo=s(l8);Wke=n(Ooo,"STRONG",{});var Fba=s(Wke);M_t=r(Fba,"roberta"),Fba.forEach(t),E_t=r(Ooo," \u2014 "),Gle=n(Ooo,"A",{href:!0});var Tba=s(Gle);C_t=r(Tba,"FlaxRobertaModel"),Tba.forEach(t),w_t=r(Ooo," (RoBERTa model)"),Ooo.forEach(t),A_t=i(ne),i8=n(ne,"LI",{});var Voo=s(i8);Uke=n(Voo,"STRONG",{});var Mba=s(Uke);L_t=r(Mba,"roformer"),Mba.forEach(t),y_t=r(Voo," \u2014 "),Ole=n(Voo,"A",{href:!0});var Eba=s(Ole);x_t=r(Eba,"FlaxRoFormerModel"),Eba.forEach(t),$_t=r(Voo," (RoFormer model)"),Voo.forEach(t),k_t=i(ne),d8=n(ne,"LI",{});var Xoo=s(d8);Hke=n(Xoo,"STRONG",{});var Cba=s(Hke);S_t=r(Cba,"t5"),Cba.forEach(t),R_t=r(Xoo," \u2014 "),Vle=n(Xoo,"A",{href:!0});var wba=s(Vle);P_t=r(wba,"FlaxT5Model"),wba.forEach(t),B_t=r(Xoo," (T5 model)"),Xoo.forEach(t),I_t=i(ne),c8=n(ne,"LI",{});var zoo=s(c8);Jke=n(zoo,"STRONG",{});var Aba=s(Jke);N_t=r(Aba,"vision-text-dual-encoder"),Aba.forEach(t),q_t=r(zoo," \u2014 "),Xle=n(zoo,"A",{href:!0});var Lba=s(Xle);j_t=r(Lba,"FlaxVisionTextDualEncoderModel"),Lba.forEach(t),D_t=r(zoo," (VisionTextDualEncoder model)"),zoo.forEach(t),G_t=i(ne),f8=n(ne,"LI",{});var Qoo=s(f8);Yke=n(Qoo,"STRONG",{});var yba=s(Yke);O_t=r(yba,"vit"),yba.forEach(t),V_t=r(Qoo," \u2014 "),zle=n(Qoo,"A",{href:!0});var xba=s(zle);X_t=r(xba,"FlaxViTModel"),xba.forEach(t),z_t=r(Qoo," (ViT model)"),Qoo.forEach(t),Q_t=i(ne),m8=n(ne,"LI",{});var Woo=s(m8);Zke=n(Woo,"STRONG",{});var $ba=s(Zke);W_t=r($ba,"wav2vec2"),$ba.forEach(t),U_t=r(Woo," \u2014 "),Qle=n(Woo,"A",{href:!0});var kba=s(Qle);H_t=r(kba,"FlaxWav2Vec2Model"),kba.forEach(t),J_t=r(Woo," (Wav2Vec2 model)"),Woo.forEach(t),Y_t=i(ne),g8=n(ne,"LI",{});var Uoo=s(g8);Kke=n(Uoo,"STRONG",{});var Sba=s(Kke);Z_t=r(Sba,"xglm"),Sba.forEach(t),K_t=r(Uoo," \u2014 "),Wle=n(Uoo,"A",{href:!0});var Rba=s(Wle);e4t=r(Rba,"FlaxXGLMModel"),Rba.forEach(t),o4t=r(Uoo," (XGLM model)"),Uoo.forEach(t),r4t=i(ne),h8=n(ne,"LI",{});var Hoo=s(h8);eSe=n(Hoo,"STRONG",{});var Pba=s(eSe);t4t=r(Pba,"xlm-roberta"),Pba.forEach(t),a4t=r(Hoo," \u2014 "),Ule=n(Hoo,"A",{href:!0});var Bba=s(Ule);n4t=r(Bba,"FlaxXLMRobertaModel"),Bba.forEach(t),s4t=r(Hoo," (XLM-RoBERTa model)"),Hoo.forEach(t),ne.forEach(t),l4t=i(Hi),T(u8.$$.fragment,Hi),Hi.forEach(t),Ui.forEach(t),Fno=i(f),dm=n(f,"H2",{class:!0});var Glo=s(dm);p8=n(Glo,"A",{id:!0,class:!0,href:!0});var Iba=s(p8);oSe=n(Iba,"SPAN",{});var Nba=s(oSe);T(WP.$$.fragment,Nba),Nba.forEach(t),Iba.forEach(t),i4t=i(Glo),rSe=n(Glo,"SPAN",{});var qba=s(rSe);d4t=r(qba,"FlaxAutoModelForCausalLM"),qba.forEach(t),Glo.forEach(t),Tno=i(f),Lr=n(f,"DIV",{class:!0});var Ji=s(Lr);T(UP.$$.fragment,Ji),c4t=i(Ji),cm=n(Ji,"P",{});var Vfe=s(cm);f4t=r(Vfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Hle=n(Vfe,"A",{href:!0});var jba=s(Hle);m4t=r(jba,"from_pretrained()"),jba.forEach(t),g4t=r(Vfe," class method or the "),Jle=n(Vfe,"A",{href:!0});var Dba=s(Jle);h4t=r(Dba,"from_config()"),Dba.forEach(t),u4t=r(Vfe,` class
method.`),Vfe.forEach(t),p4t=i(Ji),HP=n(Ji,"P",{});var Olo=s(HP);_4t=r(Olo,"This class cannot be instantiated directly using "),tSe=n(Olo,"CODE",{});var Gba=s(tSe);v4t=r(Gba,"__init__()"),Gba.forEach(t),b4t=r(Olo," (throws an error)."),Olo.forEach(t),F4t=i(Ji),ha=n(Ji,"DIV",{class:!0});var Nx=s(ha);T(JP.$$.fragment,Nx),T4t=i(Nx),aSe=n(Nx,"P",{});var Oba=s(aSe);M4t=r(Oba,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Oba.forEach(t),E4t=i(Nx),fm=n(Nx,"P",{});var Xfe=s(fm);C4t=r(Xfe,`Note:
Loading a model from its configuration file does `),nSe=n(Xfe,"STRONG",{});var Vba=s(nSe);w4t=r(Vba,"not"),Vba.forEach(t),A4t=r(Xfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Yle=n(Xfe,"A",{href:!0});var Xba=s(Yle);L4t=r(Xba,"from_pretrained()"),Xba.forEach(t),y4t=r(Xfe," to load the model weights."),Xfe.forEach(t),x4t=i(Nx),T(_8.$$.fragment,Nx),Nx.forEach(t),$4t=i(Ji),tt=n(Ji,"DIV",{class:!0});var Yi=s(tt);T(YP.$$.fragment,Yi),k4t=i(Yi),sSe=n(Yi,"P",{});var zba=s(sSe);S4t=r(zba,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),zba.forEach(t),R4t=i(Yi),Zn=n(Yi,"P",{});var qx=s(Zn);P4t=r(qx,"The model class to instantiate is selected based on the "),lSe=n(qx,"CODE",{});var Qba=s(lSe);B4t=r(Qba,"model_type"),Qba.forEach(t),I4t=r(qx,` property of the config object (either
passed as an argument or loaded from `),iSe=n(qx,"CODE",{});var Wba=s(iSe);N4t=r(Wba,"pretrained_model_name_or_path"),Wba.forEach(t),q4t=r(qx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dSe=n(qx,"CODE",{});var Uba=s(dSe);j4t=r(Uba,"pretrained_model_name_or_path"),Uba.forEach(t),D4t=r(qx,":"),qx.forEach(t),G4t=i(Yi),$e=n(Yi,"UL",{});var je=s($e);v8=n(je,"LI",{});var Joo=s(v8);cSe=n(Joo,"STRONG",{});var Hba=s(cSe);O4t=r(Hba,"bart"),Hba.forEach(t),V4t=r(Joo," \u2014 "),Zle=n(Joo,"A",{href:!0});var Jba=s(Zle);X4t=r(Jba,"FlaxBartForCausalLM"),Jba.forEach(t),z4t=r(Joo," (BART model)"),Joo.forEach(t),Q4t=i(je),b8=n(je,"LI",{});var Yoo=s(b8);fSe=n(Yoo,"STRONG",{});var Yba=s(fSe);W4t=r(Yba,"bert"),Yba.forEach(t),U4t=r(Yoo," \u2014 "),Kle=n(Yoo,"A",{href:!0});var Zba=s(Kle);H4t=r(Zba,"FlaxBertForCausalLM"),Zba.forEach(t),J4t=r(Yoo," (BERT model)"),Yoo.forEach(t),Y4t=i(je),F8=n(je,"LI",{});var Zoo=s(F8);mSe=n(Zoo,"STRONG",{});var Kba=s(mSe);Z4t=r(Kba,"big_bird"),Kba.forEach(t),K4t=r(Zoo," \u2014 "),eie=n(Zoo,"A",{href:!0});var e0a=s(eie);e2t=r(e0a,"FlaxBigBirdForCausalLM"),e0a.forEach(t),o2t=r(Zoo," (BigBird model)"),Zoo.forEach(t),r2t=i(je),T8=n(je,"LI",{});var Koo=s(T8);gSe=n(Koo,"STRONG",{});var o0a=s(gSe);t2t=r(o0a,"electra"),o0a.forEach(t),a2t=r(Koo," \u2014 "),oie=n(Koo,"A",{href:!0});var r0a=s(oie);n2t=r(r0a,"FlaxElectraForCausalLM"),r0a.forEach(t),s2t=r(Koo," (ELECTRA model)"),Koo.forEach(t),l2t=i(je),M8=n(je,"LI",{});var ero=s(M8);hSe=n(ero,"STRONG",{});var t0a=s(hSe);i2t=r(t0a,"gpt2"),t0a.forEach(t),d2t=r(ero," \u2014 "),rie=n(ero,"A",{href:!0});var a0a=s(rie);c2t=r(a0a,"FlaxGPT2LMHeadModel"),a0a.forEach(t),f2t=r(ero," (OpenAI GPT-2 model)"),ero.forEach(t),m2t=i(je),E8=n(je,"LI",{});var oro=s(E8);uSe=n(oro,"STRONG",{});var n0a=s(uSe);g2t=r(n0a,"gpt_neo"),n0a.forEach(t),h2t=r(oro," \u2014 "),tie=n(oro,"A",{href:!0});var s0a=s(tie);u2t=r(s0a,"FlaxGPTNeoForCausalLM"),s0a.forEach(t),p2t=r(oro," (GPT Neo model)"),oro.forEach(t),_2t=i(je),C8=n(je,"LI",{});var rro=s(C8);pSe=n(rro,"STRONG",{});var l0a=s(pSe);v2t=r(l0a,"gptj"),l0a.forEach(t),b2t=r(rro," \u2014 "),aie=n(rro,"A",{href:!0});var i0a=s(aie);F2t=r(i0a,"FlaxGPTJForCausalLM"),i0a.forEach(t),T2t=r(rro," (GPT-J model)"),rro.forEach(t),M2t=i(je),w8=n(je,"LI",{});var tro=s(w8);_Se=n(tro,"STRONG",{});var d0a=s(_Se);E2t=r(d0a,"opt"),d0a.forEach(t),C2t=r(tro," \u2014 "),nie=n(tro,"A",{href:!0});var c0a=s(nie);w2t=r(c0a,"FlaxOPTForCausalLM"),c0a.forEach(t),A2t=r(tro," (OPT model)"),tro.forEach(t),L2t=i(je),A8=n(je,"LI",{});var aro=s(A8);vSe=n(aro,"STRONG",{});var f0a=s(vSe);y2t=r(f0a,"roberta"),f0a.forEach(t),x2t=r(aro," \u2014 "),sie=n(aro,"A",{href:!0});var m0a=s(sie);$2t=r(m0a,"FlaxRobertaForCausalLM"),m0a.forEach(t),k2t=r(aro," (RoBERTa model)"),aro.forEach(t),S2t=i(je),L8=n(je,"LI",{});var nro=s(L8);bSe=n(nro,"STRONG",{});var g0a=s(bSe);R2t=r(g0a,"xglm"),g0a.forEach(t),P2t=r(nro," \u2014 "),lie=n(nro,"A",{href:!0});var h0a=s(lie);B2t=r(h0a,"FlaxXGLMForCausalLM"),h0a.forEach(t),I2t=r(nro," (XGLM model)"),nro.forEach(t),je.forEach(t),N2t=i(Yi),T(y8.$$.fragment,Yi),Yi.forEach(t),Ji.forEach(t),Mno=i(f),mm=n(f,"H2",{class:!0});var Vlo=s(mm);x8=n(Vlo,"A",{id:!0,class:!0,href:!0});var u0a=s(x8);FSe=n(u0a,"SPAN",{});var p0a=s(FSe);T(ZP.$$.fragment,p0a),p0a.forEach(t),u0a.forEach(t),q2t=i(Vlo),TSe=n(Vlo,"SPAN",{});var _0a=s(TSe);j2t=r(_0a,"FlaxAutoModelForPreTraining"),_0a.forEach(t),Vlo.forEach(t),Eno=i(f),yr=n(f,"DIV",{class:!0});var Zi=s(yr);T(KP.$$.fragment,Zi),D2t=i(Zi),gm=n(Zi,"P",{});var zfe=s(gm);G2t=r(zfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),iie=n(zfe,"A",{href:!0});var v0a=s(iie);O2t=r(v0a,"from_pretrained()"),v0a.forEach(t),V2t=r(zfe," class method or the "),die=n(zfe,"A",{href:!0});var b0a=s(die);X2t=r(b0a,"from_config()"),b0a.forEach(t),z2t=r(zfe,` class
method.`),zfe.forEach(t),Q2t=i(Zi),eB=n(Zi,"P",{});var Xlo=s(eB);W2t=r(Xlo,"This class cannot be instantiated directly using "),MSe=n(Xlo,"CODE",{});var F0a=s(MSe);U2t=r(F0a,"__init__()"),F0a.forEach(t),H2t=r(Xlo," (throws an error)."),Xlo.forEach(t),J2t=i(Zi),ua=n(Zi,"DIV",{class:!0});var jx=s(ua);T(oB.$$.fragment,jx),Y2t=i(jx),ESe=n(jx,"P",{});var T0a=s(ESe);Z2t=r(T0a,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),T0a.forEach(t),K2t=i(jx),hm=n(jx,"P",{});var Qfe=s(hm);evt=r(Qfe,`Note:
Loading a model from its configuration file does `),CSe=n(Qfe,"STRONG",{});var M0a=s(CSe);ovt=r(M0a,"not"),M0a.forEach(t),rvt=r(Qfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),cie=n(Qfe,"A",{href:!0});var E0a=s(cie);tvt=r(E0a,"from_pretrained()"),E0a.forEach(t),avt=r(Qfe," to load the model weights."),Qfe.forEach(t),nvt=i(jx),T($8.$$.fragment,jx),jx.forEach(t),svt=i(Zi),at=n(Zi,"DIV",{class:!0});var Ki=s(at);T(rB.$$.fragment,Ki),lvt=i(Ki),wSe=n(Ki,"P",{});var C0a=s(wSe);ivt=r(C0a,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),C0a.forEach(t),dvt=i(Ki),Kn=n(Ki,"P",{});var Dx=s(Kn);cvt=r(Dx,"The model class to instantiate is selected based on the "),ASe=n(Dx,"CODE",{});var w0a=s(ASe);fvt=r(w0a,"model_type"),w0a.forEach(t),mvt=r(Dx,` property of the config object (either
passed as an argument or loaded from `),LSe=n(Dx,"CODE",{});var A0a=s(LSe);gvt=r(A0a,"pretrained_model_name_or_path"),A0a.forEach(t),hvt=r(Dx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ySe=n(Dx,"CODE",{});var L0a=s(ySe);uvt=r(L0a,"pretrained_model_name_or_path"),L0a.forEach(t),pvt=r(Dx,":"),Dx.forEach(t),_vt=i(Ki),Ee=n(Ki,"UL",{});var we=s(Ee);k8=n(we,"LI",{});var sro=s(k8);xSe=n(sro,"STRONG",{});var y0a=s(xSe);vvt=r(y0a,"albert"),y0a.forEach(t),bvt=r(sro," \u2014 "),fie=n(sro,"A",{href:!0});var x0a=s(fie);Fvt=r(x0a,"FlaxAlbertForPreTraining"),x0a.forEach(t),Tvt=r(sro," (ALBERT model)"),sro.forEach(t),Mvt=i(we),S8=n(we,"LI",{});var lro=s(S8);$Se=n(lro,"STRONG",{});var $0a=s($Se);Evt=r($0a,"bart"),$0a.forEach(t),Cvt=r(lro," \u2014 "),mie=n(lro,"A",{href:!0});var k0a=s(mie);wvt=r(k0a,"FlaxBartForConditionalGeneration"),k0a.forEach(t),Avt=r(lro," (BART model)"),lro.forEach(t),Lvt=i(we),R8=n(we,"LI",{});var iro=s(R8);kSe=n(iro,"STRONG",{});var S0a=s(kSe);yvt=r(S0a,"bert"),S0a.forEach(t),xvt=r(iro," \u2014 "),gie=n(iro,"A",{href:!0});var R0a=s(gie);$vt=r(R0a,"FlaxBertForPreTraining"),R0a.forEach(t),kvt=r(iro," (BERT model)"),iro.forEach(t),Svt=i(we),P8=n(we,"LI",{});var dro=s(P8);SSe=n(dro,"STRONG",{});var P0a=s(SSe);Rvt=r(P0a,"big_bird"),P0a.forEach(t),Pvt=r(dro," \u2014 "),hie=n(dro,"A",{href:!0});var B0a=s(hie);Bvt=r(B0a,"FlaxBigBirdForPreTraining"),B0a.forEach(t),Ivt=r(dro," (BigBird model)"),dro.forEach(t),Nvt=i(we),B8=n(we,"LI",{});var cro=s(B8);RSe=n(cro,"STRONG",{});var I0a=s(RSe);qvt=r(I0a,"electra"),I0a.forEach(t),jvt=r(cro," \u2014 "),uie=n(cro,"A",{href:!0});var N0a=s(uie);Dvt=r(N0a,"FlaxElectraForPreTraining"),N0a.forEach(t),Gvt=r(cro," (ELECTRA model)"),cro.forEach(t),Ovt=i(we),I8=n(we,"LI",{});var fro=s(I8);PSe=n(fro,"STRONG",{});var q0a=s(PSe);Vvt=r(q0a,"longt5"),q0a.forEach(t),Xvt=r(fro," \u2014 "),pie=n(fro,"A",{href:!0});var j0a=s(pie);zvt=r(j0a,"FlaxLongT5ForConditionalGeneration"),j0a.forEach(t),Qvt=r(fro," (LongT5 model)"),fro.forEach(t),Wvt=i(we),N8=n(we,"LI",{});var mro=s(N8);BSe=n(mro,"STRONG",{});var D0a=s(BSe);Uvt=r(D0a,"mbart"),D0a.forEach(t),Hvt=r(mro," \u2014 "),_ie=n(mro,"A",{href:!0});var G0a=s(_ie);Jvt=r(G0a,"FlaxMBartForConditionalGeneration"),G0a.forEach(t),Yvt=r(mro," (mBART model)"),mro.forEach(t),Zvt=i(we),q8=n(we,"LI",{});var gro=s(q8);ISe=n(gro,"STRONG",{});var O0a=s(ISe);Kvt=r(O0a,"mt5"),O0a.forEach(t),e1t=r(gro," \u2014 "),vie=n(gro,"A",{href:!0});var V0a=s(vie);o1t=r(V0a,"FlaxMT5ForConditionalGeneration"),V0a.forEach(t),r1t=r(gro," (MT5 model)"),gro.forEach(t),t1t=i(we),j8=n(we,"LI",{});var hro=s(j8);NSe=n(hro,"STRONG",{});var X0a=s(NSe);a1t=r(X0a,"roberta"),X0a.forEach(t),n1t=r(hro," \u2014 "),bie=n(hro,"A",{href:!0});var z0a=s(bie);s1t=r(z0a,"FlaxRobertaForMaskedLM"),z0a.forEach(t),l1t=r(hro," (RoBERTa model)"),hro.forEach(t),i1t=i(we),D8=n(we,"LI",{});var uro=s(D8);qSe=n(uro,"STRONG",{});var Q0a=s(qSe);d1t=r(Q0a,"roformer"),Q0a.forEach(t),c1t=r(uro," \u2014 "),Fie=n(uro,"A",{href:!0});var W0a=s(Fie);f1t=r(W0a,"FlaxRoFormerForMaskedLM"),W0a.forEach(t),m1t=r(uro," (RoFormer model)"),uro.forEach(t),g1t=i(we),G8=n(we,"LI",{});var pro=s(G8);jSe=n(pro,"STRONG",{});var U0a=s(jSe);h1t=r(U0a,"t5"),U0a.forEach(t),u1t=r(pro," \u2014 "),Tie=n(pro,"A",{href:!0});var H0a=s(Tie);p1t=r(H0a,"FlaxT5ForConditionalGeneration"),H0a.forEach(t),_1t=r(pro," (T5 model)"),pro.forEach(t),v1t=i(we),O8=n(we,"LI",{});var _ro=s(O8);DSe=n(_ro,"STRONG",{});var J0a=s(DSe);b1t=r(J0a,"wav2vec2"),J0a.forEach(t),F1t=r(_ro," \u2014 "),Mie=n(_ro,"A",{href:!0});var Y0a=s(Mie);T1t=r(Y0a,"FlaxWav2Vec2ForPreTraining"),Y0a.forEach(t),M1t=r(_ro," (Wav2Vec2 model)"),_ro.forEach(t),E1t=i(we),V8=n(we,"LI",{});var vro=s(V8);GSe=n(vro,"STRONG",{});var Z0a=s(GSe);C1t=r(Z0a,"xlm-roberta"),Z0a.forEach(t),w1t=r(vro," \u2014 "),Eie=n(vro,"A",{href:!0});var K0a=s(Eie);A1t=r(K0a,"FlaxXLMRobertaForMaskedLM"),K0a.forEach(t),L1t=r(vro," (XLM-RoBERTa model)"),vro.forEach(t),we.forEach(t),y1t=i(Ki),T(X8.$$.fragment,Ki),Ki.forEach(t),Zi.forEach(t),Cno=i(f),um=n(f,"H2",{class:!0});var zlo=s(um);z8=n(zlo,"A",{id:!0,class:!0,href:!0});var eFa=s(z8);OSe=n(eFa,"SPAN",{});var oFa=s(OSe);T(tB.$$.fragment,oFa),oFa.forEach(t),eFa.forEach(t),x1t=i(zlo),VSe=n(zlo,"SPAN",{});var rFa=s(VSe);$1t=r(rFa,"FlaxAutoModelForMaskedLM"),rFa.forEach(t),zlo.forEach(t),wno=i(f),xr=n(f,"DIV",{class:!0});var ed=s(xr);T(aB.$$.fragment,ed),k1t=i(ed),pm=n(ed,"P",{});var Wfe=s(pm);S1t=r(Wfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Cie=n(Wfe,"A",{href:!0});var tFa=s(Cie);R1t=r(tFa,"from_pretrained()"),tFa.forEach(t),P1t=r(Wfe," class method or the "),wie=n(Wfe,"A",{href:!0});var aFa=s(wie);B1t=r(aFa,"from_config()"),aFa.forEach(t),I1t=r(Wfe,` class
method.`),Wfe.forEach(t),N1t=i(ed),nB=n(ed,"P",{});var Qlo=s(nB);q1t=r(Qlo,"This class cannot be instantiated directly using "),XSe=n(Qlo,"CODE",{});var nFa=s(XSe);j1t=r(nFa,"__init__()"),nFa.forEach(t),D1t=r(Qlo," (throws an error)."),Qlo.forEach(t),G1t=i(ed),pa=n(ed,"DIV",{class:!0});var Gx=s(pa);T(sB.$$.fragment,Gx),O1t=i(Gx),zSe=n(Gx,"P",{});var sFa=s(zSe);V1t=r(sFa,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),sFa.forEach(t),X1t=i(Gx),_m=n(Gx,"P",{});var Ufe=s(_m);z1t=r(Ufe,`Note:
Loading a model from its configuration file does `),QSe=n(Ufe,"STRONG",{});var lFa=s(QSe);Q1t=r(lFa,"not"),lFa.forEach(t),W1t=r(Ufe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Aie=n(Ufe,"A",{href:!0});var iFa=s(Aie);U1t=r(iFa,"from_pretrained()"),iFa.forEach(t),H1t=r(Ufe," to load the model weights."),Ufe.forEach(t),J1t=i(Gx),T(Q8.$$.fragment,Gx),Gx.forEach(t),Y1t=i(ed),nt=n(ed,"DIV",{class:!0});var od=s(nt);T(lB.$$.fragment,od),Z1t=i(od),WSe=n(od,"P",{});var dFa=s(WSe);K1t=r(dFa,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),dFa.forEach(t),ebt=i(od),es=n(od,"P",{});var Ox=s(es);obt=r(Ox,"The model class to instantiate is selected based on the "),USe=n(Ox,"CODE",{});var cFa=s(USe);rbt=r(cFa,"model_type"),cFa.forEach(t),tbt=r(Ox,` property of the config object (either
passed as an argument or loaded from `),HSe=n(Ox,"CODE",{});var fFa=s(HSe);abt=r(fFa,"pretrained_model_name_or_path"),fFa.forEach(t),nbt=r(Ox,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JSe=n(Ox,"CODE",{});var mFa=s(JSe);sbt=r(mFa,"pretrained_model_name_or_path"),mFa.forEach(t),lbt=r(Ox,":"),Ox.forEach(t),ibt=i(od),ke=n(od,"UL",{});var De=s(ke);W8=n(De,"LI",{});var bro=s(W8);YSe=n(bro,"STRONG",{});var gFa=s(YSe);dbt=r(gFa,"albert"),gFa.forEach(t),cbt=r(bro," \u2014 "),Lie=n(bro,"A",{href:!0});var hFa=s(Lie);fbt=r(hFa,"FlaxAlbertForMaskedLM"),hFa.forEach(t),mbt=r(bro," (ALBERT model)"),bro.forEach(t),gbt=i(De),U8=n(De,"LI",{});var Fro=s(U8);ZSe=n(Fro,"STRONG",{});var uFa=s(ZSe);hbt=r(uFa,"bart"),uFa.forEach(t),ubt=r(Fro," \u2014 "),yie=n(Fro,"A",{href:!0});var pFa=s(yie);pbt=r(pFa,"FlaxBartForConditionalGeneration"),pFa.forEach(t),_bt=r(Fro," (BART model)"),Fro.forEach(t),vbt=i(De),H8=n(De,"LI",{});var Tro=s(H8);KSe=n(Tro,"STRONG",{});var _Fa=s(KSe);bbt=r(_Fa,"bert"),_Fa.forEach(t),Fbt=r(Tro," \u2014 "),xie=n(Tro,"A",{href:!0});var vFa=s(xie);Tbt=r(vFa,"FlaxBertForMaskedLM"),vFa.forEach(t),Mbt=r(Tro," (BERT model)"),Tro.forEach(t),Ebt=i(De),J8=n(De,"LI",{});var Mro=s(J8);eRe=n(Mro,"STRONG",{});var bFa=s(eRe);Cbt=r(bFa,"big_bird"),bFa.forEach(t),wbt=r(Mro," \u2014 "),$ie=n(Mro,"A",{href:!0});var FFa=s($ie);Abt=r(FFa,"FlaxBigBirdForMaskedLM"),FFa.forEach(t),Lbt=r(Mro," (BigBird model)"),Mro.forEach(t),ybt=i(De),Y8=n(De,"LI",{});var Ero=s(Y8);oRe=n(Ero,"STRONG",{});var TFa=s(oRe);xbt=r(TFa,"distilbert"),TFa.forEach(t),$bt=r(Ero," \u2014 "),kie=n(Ero,"A",{href:!0});var MFa=s(kie);kbt=r(MFa,"FlaxDistilBertForMaskedLM"),MFa.forEach(t),Sbt=r(Ero," (DistilBERT model)"),Ero.forEach(t),Rbt=i(De),Z8=n(De,"LI",{});var Cro=s(Z8);rRe=n(Cro,"STRONG",{});var EFa=s(rRe);Pbt=r(EFa,"electra"),EFa.forEach(t),Bbt=r(Cro," \u2014 "),Sie=n(Cro,"A",{href:!0});var CFa=s(Sie);Ibt=r(CFa,"FlaxElectraForMaskedLM"),CFa.forEach(t),Nbt=r(Cro," (ELECTRA model)"),Cro.forEach(t),qbt=i(De),K8=n(De,"LI",{});var wro=s(K8);tRe=n(wro,"STRONG",{});var wFa=s(tRe);jbt=r(wFa,"mbart"),wFa.forEach(t),Dbt=r(wro," \u2014 "),Rie=n(wro,"A",{href:!0});var AFa=s(Rie);Gbt=r(AFa,"FlaxMBartForConditionalGeneration"),AFa.forEach(t),Obt=r(wro," (mBART model)"),wro.forEach(t),Vbt=i(De),eL=n(De,"LI",{});var Aro=s(eL);aRe=n(Aro,"STRONG",{});var LFa=s(aRe);Xbt=r(LFa,"roberta"),LFa.forEach(t),zbt=r(Aro," \u2014 "),Pie=n(Aro,"A",{href:!0});var yFa=s(Pie);Qbt=r(yFa,"FlaxRobertaForMaskedLM"),yFa.forEach(t),Wbt=r(Aro," (RoBERTa model)"),Aro.forEach(t),Ubt=i(De),oL=n(De,"LI",{});var Lro=s(oL);nRe=n(Lro,"STRONG",{});var xFa=s(nRe);Hbt=r(xFa,"roformer"),xFa.forEach(t),Jbt=r(Lro," \u2014 "),Bie=n(Lro,"A",{href:!0});var $Fa=s(Bie);Ybt=r($Fa,"FlaxRoFormerForMaskedLM"),$Fa.forEach(t),Zbt=r(Lro," (RoFormer model)"),Lro.forEach(t),Kbt=i(De),rL=n(De,"LI",{});var yro=s(rL);sRe=n(yro,"STRONG",{});var kFa=s(sRe);e0t=r(kFa,"xlm-roberta"),kFa.forEach(t),o0t=r(yro," \u2014 "),Iie=n(yro,"A",{href:!0});var SFa=s(Iie);r0t=r(SFa,"FlaxXLMRobertaForMaskedLM"),SFa.forEach(t),t0t=r(yro," (XLM-RoBERTa model)"),yro.forEach(t),De.forEach(t),a0t=i(od),T(tL.$$.fragment,od),od.forEach(t),ed.forEach(t),Ano=i(f),vm=n(f,"H2",{class:!0});var Wlo=s(vm);aL=n(Wlo,"A",{id:!0,class:!0,href:!0});var RFa=s(aL);lRe=n(RFa,"SPAN",{});var PFa=s(lRe);T(iB.$$.fragment,PFa),PFa.forEach(t),RFa.forEach(t),n0t=i(Wlo),iRe=n(Wlo,"SPAN",{});var BFa=s(iRe);s0t=r(BFa,"FlaxAutoModelForSeq2SeqLM"),BFa.forEach(t),Wlo.forEach(t),Lno=i(f),$r=n(f,"DIV",{class:!0});var rd=s($r);T(dB.$$.fragment,rd),l0t=i(rd),bm=n(rd,"P",{});var Hfe=s(bm);i0t=r(Hfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Nie=n(Hfe,"A",{href:!0});var IFa=s(Nie);d0t=r(IFa,"from_pretrained()"),IFa.forEach(t),c0t=r(Hfe," class method or the "),qie=n(Hfe,"A",{href:!0});var NFa=s(qie);f0t=r(NFa,"from_config()"),NFa.forEach(t),m0t=r(Hfe,` class
method.`),Hfe.forEach(t),g0t=i(rd),cB=n(rd,"P",{});var Ulo=s(cB);h0t=r(Ulo,"This class cannot be instantiated directly using "),dRe=n(Ulo,"CODE",{});var qFa=s(dRe);u0t=r(qFa,"__init__()"),qFa.forEach(t),p0t=r(Ulo," (throws an error)."),Ulo.forEach(t),_0t=i(rd),_a=n(rd,"DIV",{class:!0});var Vx=s(_a);T(fB.$$.fragment,Vx),v0t=i(Vx),cRe=n(Vx,"P",{});var jFa=s(cRe);b0t=r(jFa,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),jFa.forEach(t),F0t=i(Vx),Fm=n(Vx,"P",{});var Jfe=s(Fm);T0t=r(Jfe,`Note:
Loading a model from its configuration file does `),fRe=n(Jfe,"STRONG",{});var DFa=s(fRe);M0t=r(DFa,"not"),DFa.forEach(t),E0t=r(Jfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),jie=n(Jfe,"A",{href:!0});var GFa=s(jie);C0t=r(GFa,"from_pretrained()"),GFa.forEach(t),w0t=r(Jfe," to load the model weights."),Jfe.forEach(t),A0t=i(Vx),T(nL.$$.fragment,Vx),Vx.forEach(t),L0t=i(rd),st=n(rd,"DIV",{class:!0});var td=s(st);T(mB.$$.fragment,td),y0t=i(td),mRe=n(td,"P",{});var OFa=s(mRe);x0t=r(OFa,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),OFa.forEach(t),$0t=i(td),os=n(td,"P",{});var Xx=s(os);k0t=r(Xx,"The model class to instantiate is selected based on the "),gRe=n(Xx,"CODE",{});var VFa=s(gRe);S0t=r(VFa,"model_type"),VFa.forEach(t),R0t=r(Xx,` property of the config object (either
passed as an argument or loaded from `),hRe=n(Xx,"CODE",{});var XFa=s(hRe);P0t=r(XFa,"pretrained_model_name_or_path"),XFa.forEach(t),B0t=r(Xx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uRe=n(Xx,"CODE",{});var zFa=s(uRe);I0t=r(zFa,"pretrained_model_name_or_path"),zFa.forEach(t),N0t=r(Xx,":"),Xx.forEach(t),q0t=i(td),Se=n(td,"UL",{});var Ge=s(Se);sL=n(Ge,"LI",{});var xro=s(sL);pRe=n(xro,"STRONG",{});var QFa=s(pRe);j0t=r(QFa,"bart"),QFa.forEach(t),D0t=r(xro," \u2014 "),Die=n(xro,"A",{href:!0});var WFa=s(Die);G0t=r(WFa,"FlaxBartForConditionalGeneration"),WFa.forEach(t),O0t=r(xro," (BART model)"),xro.forEach(t),V0t=i(Ge),lL=n(Ge,"LI",{});var $ro=s(lL);_Re=n($ro,"STRONG",{});var UFa=s(_Re);X0t=r(UFa,"blenderbot"),UFa.forEach(t),z0t=r($ro," \u2014 "),Gie=n($ro,"A",{href:!0});var HFa=s(Gie);Q0t=r(HFa,"FlaxBlenderbotForConditionalGeneration"),HFa.forEach(t),W0t=r($ro," (Blenderbot model)"),$ro.forEach(t),U0t=i(Ge),iL=n(Ge,"LI",{});var kro=s(iL);vRe=n(kro,"STRONG",{});var JFa=s(vRe);H0t=r(JFa,"blenderbot-small"),JFa.forEach(t),J0t=r(kro," \u2014 "),Oie=n(kro,"A",{href:!0});var YFa=s(Oie);Y0t=r(YFa,"FlaxBlenderbotSmallForConditionalGeneration"),YFa.forEach(t),Z0t=r(kro," (BlenderbotSmall model)"),kro.forEach(t),K0t=i(Ge),dL=n(Ge,"LI",{});var Sro=s(dL);bRe=n(Sro,"STRONG",{});var ZFa=s(bRe);eFt=r(ZFa,"encoder-decoder"),ZFa.forEach(t),oFt=r(Sro," \u2014 "),Vie=n(Sro,"A",{href:!0});var KFa=s(Vie);rFt=r(KFa,"FlaxEncoderDecoderModel"),KFa.forEach(t),tFt=r(Sro," (Encoder decoder model)"),Sro.forEach(t),aFt=i(Ge),cL=n(Ge,"LI",{});var Rro=s(cL);FRe=n(Rro,"STRONG",{});var eTa=s(FRe);nFt=r(eTa,"longt5"),eTa.forEach(t),sFt=r(Rro," \u2014 "),Xie=n(Rro,"A",{href:!0});var oTa=s(Xie);lFt=r(oTa,"FlaxLongT5ForConditionalGeneration"),oTa.forEach(t),iFt=r(Rro," (LongT5 model)"),Rro.forEach(t),dFt=i(Ge),fL=n(Ge,"LI",{});var Pro=s(fL);TRe=n(Pro,"STRONG",{});var rTa=s(TRe);cFt=r(rTa,"marian"),rTa.forEach(t),fFt=r(Pro," \u2014 "),zie=n(Pro,"A",{href:!0});var tTa=s(zie);mFt=r(tTa,"FlaxMarianMTModel"),tTa.forEach(t),gFt=r(Pro," (Marian model)"),Pro.forEach(t),hFt=i(Ge),mL=n(Ge,"LI",{});var Bro=s(mL);MRe=n(Bro,"STRONG",{});var aTa=s(MRe);uFt=r(aTa,"mbart"),aTa.forEach(t),pFt=r(Bro," \u2014 "),Qie=n(Bro,"A",{href:!0});var nTa=s(Qie);_Ft=r(nTa,"FlaxMBartForConditionalGeneration"),nTa.forEach(t),vFt=r(Bro," (mBART model)"),Bro.forEach(t),bFt=i(Ge),gL=n(Ge,"LI",{});var Iro=s(gL);ERe=n(Iro,"STRONG",{});var sTa=s(ERe);FFt=r(sTa,"mt5"),sTa.forEach(t),TFt=r(Iro," \u2014 "),Wie=n(Iro,"A",{href:!0});var lTa=s(Wie);MFt=r(lTa,"FlaxMT5ForConditionalGeneration"),lTa.forEach(t),EFt=r(Iro," (MT5 model)"),Iro.forEach(t),CFt=i(Ge),hL=n(Ge,"LI",{});var Nro=s(hL);CRe=n(Nro,"STRONG",{});var iTa=s(CRe);wFt=r(iTa,"pegasus"),iTa.forEach(t),AFt=r(Nro," \u2014 "),Uie=n(Nro,"A",{href:!0});var dTa=s(Uie);LFt=r(dTa,"FlaxPegasusForConditionalGeneration"),dTa.forEach(t),yFt=r(Nro," (Pegasus model)"),Nro.forEach(t),xFt=i(Ge),uL=n(Ge,"LI",{});var qro=s(uL);wRe=n(qro,"STRONG",{});var cTa=s(wRe);$Ft=r(cTa,"t5"),cTa.forEach(t),kFt=r(qro," \u2014 "),Hie=n(qro,"A",{href:!0});var fTa=s(Hie);SFt=r(fTa,"FlaxT5ForConditionalGeneration"),fTa.forEach(t),RFt=r(qro," (T5 model)"),qro.forEach(t),Ge.forEach(t),PFt=i(td),T(pL.$$.fragment,td),td.forEach(t),rd.forEach(t),yno=i(f),Tm=n(f,"H2",{class:!0});var Hlo=s(Tm);_L=n(Hlo,"A",{id:!0,class:!0,href:!0});var mTa=s(_L);ARe=n(mTa,"SPAN",{});var gTa=s(ARe);T(gB.$$.fragment,gTa),gTa.forEach(t),mTa.forEach(t),BFt=i(Hlo),LRe=n(Hlo,"SPAN",{});var hTa=s(LRe);IFt=r(hTa,"FlaxAutoModelForSequenceClassification"),hTa.forEach(t),Hlo.forEach(t),xno=i(f),kr=n(f,"DIV",{class:!0});var ad=s(kr);T(hB.$$.fragment,ad),NFt=i(ad),Mm=n(ad,"P",{});var Yfe=s(Mm);qFt=r(Yfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Jie=n(Yfe,"A",{href:!0});var uTa=s(Jie);jFt=r(uTa,"from_pretrained()"),uTa.forEach(t),DFt=r(Yfe," class method or the "),Yie=n(Yfe,"A",{href:!0});var pTa=s(Yie);GFt=r(pTa,"from_config()"),pTa.forEach(t),OFt=r(Yfe,` class
method.`),Yfe.forEach(t),VFt=i(ad),uB=n(ad,"P",{});var Jlo=s(uB);XFt=r(Jlo,"This class cannot be instantiated directly using "),yRe=n(Jlo,"CODE",{});var _Ta=s(yRe);zFt=r(_Ta,"__init__()"),_Ta.forEach(t),QFt=r(Jlo," (throws an error)."),Jlo.forEach(t),WFt=i(ad),va=n(ad,"DIV",{class:!0});var zx=s(va);T(pB.$$.fragment,zx),UFt=i(zx),xRe=n(zx,"P",{});var vTa=s(xRe);HFt=r(vTa,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),vTa.forEach(t),JFt=i(zx),Em=n(zx,"P",{});var Zfe=s(Em);YFt=r(Zfe,`Note:
Loading a model from its configuration file does `),$Re=n(Zfe,"STRONG",{});var bTa=s($Re);ZFt=r(bTa,"not"),bTa.forEach(t),KFt=r(Zfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zie=n(Zfe,"A",{href:!0});var FTa=s(Zie);eTt=r(FTa,"from_pretrained()"),FTa.forEach(t),oTt=r(Zfe," to load the model weights."),Zfe.forEach(t),rTt=i(zx),T(vL.$$.fragment,zx),zx.forEach(t),tTt=i(ad),lt=n(ad,"DIV",{class:!0});var nd=s(lt);T(_B.$$.fragment,nd),aTt=i(nd),kRe=n(nd,"P",{});var TTa=s(kRe);nTt=r(TTa,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),TTa.forEach(t),sTt=i(nd),rs=n(nd,"P",{});var Qx=s(rs);lTt=r(Qx,"The model class to instantiate is selected based on the "),SRe=n(Qx,"CODE",{});var MTa=s(SRe);iTt=r(MTa,"model_type"),MTa.forEach(t),dTt=r(Qx,` property of the config object (either
passed as an argument or loaded from `),RRe=n(Qx,"CODE",{});var ETa=s(RRe);cTt=r(ETa,"pretrained_model_name_or_path"),ETa.forEach(t),fTt=r(Qx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),PRe=n(Qx,"CODE",{});var CTa=s(PRe);mTt=r(CTa,"pretrained_model_name_or_path"),CTa.forEach(t),gTt=r(Qx,":"),Qx.forEach(t),hTt=i(nd),Re=n(nd,"UL",{});var Oe=s(Re);bL=n(Oe,"LI",{});var jro=s(bL);BRe=n(jro,"STRONG",{});var wTa=s(BRe);uTt=r(wTa,"albert"),wTa.forEach(t),pTt=r(jro," \u2014 "),Kie=n(jro,"A",{href:!0});var ATa=s(Kie);_Tt=r(ATa,"FlaxAlbertForSequenceClassification"),ATa.forEach(t),vTt=r(jro," (ALBERT model)"),jro.forEach(t),bTt=i(Oe),FL=n(Oe,"LI",{});var Dro=s(FL);IRe=n(Dro,"STRONG",{});var LTa=s(IRe);FTt=r(LTa,"bart"),LTa.forEach(t),TTt=r(Dro," \u2014 "),ede=n(Dro,"A",{href:!0});var yTa=s(ede);MTt=r(yTa,"FlaxBartForSequenceClassification"),yTa.forEach(t),ETt=r(Dro," (BART model)"),Dro.forEach(t),CTt=i(Oe),TL=n(Oe,"LI",{});var Gro=s(TL);NRe=n(Gro,"STRONG",{});var xTa=s(NRe);wTt=r(xTa,"bert"),xTa.forEach(t),ATt=r(Gro," \u2014 "),ode=n(Gro,"A",{href:!0});var $Ta=s(ode);LTt=r($Ta,"FlaxBertForSequenceClassification"),$Ta.forEach(t),yTt=r(Gro," (BERT model)"),Gro.forEach(t),xTt=i(Oe),ML=n(Oe,"LI",{});var Oro=s(ML);qRe=n(Oro,"STRONG",{});var kTa=s(qRe);$Tt=r(kTa,"big_bird"),kTa.forEach(t),kTt=r(Oro," \u2014 "),rde=n(Oro,"A",{href:!0});var STa=s(rde);STt=r(STa,"FlaxBigBirdForSequenceClassification"),STa.forEach(t),RTt=r(Oro," (BigBird model)"),Oro.forEach(t),PTt=i(Oe),EL=n(Oe,"LI",{});var Vro=s(EL);jRe=n(Vro,"STRONG",{});var RTa=s(jRe);BTt=r(RTa,"distilbert"),RTa.forEach(t),ITt=r(Vro," \u2014 "),tde=n(Vro,"A",{href:!0});var PTa=s(tde);NTt=r(PTa,"FlaxDistilBertForSequenceClassification"),PTa.forEach(t),qTt=r(Vro," (DistilBERT model)"),Vro.forEach(t),jTt=i(Oe),CL=n(Oe,"LI",{});var Xro=s(CL);DRe=n(Xro,"STRONG",{});var BTa=s(DRe);DTt=r(BTa,"electra"),BTa.forEach(t),GTt=r(Xro," \u2014 "),ade=n(Xro,"A",{href:!0});var ITa=s(ade);OTt=r(ITa,"FlaxElectraForSequenceClassification"),ITa.forEach(t),VTt=r(Xro," (ELECTRA model)"),Xro.forEach(t),XTt=i(Oe),wL=n(Oe,"LI",{});var zro=s(wL);GRe=n(zro,"STRONG",{});var NTa=s(GRe);zTt=r(NTa,"mbart"),NTa.forEach(t),QTt=r(zro," \u2014 "),nde=n(zro,"A",{href:!0});var qTa=s(nde);WTt=r(qTa,"FlaxMBartForSequenceClassification"),qTa.forEach(t),UTt=r(zro," (mBART model)"),zro.forEach(t),HTt=i(Oe),AL=n(Oe,"LI",{});var Qro=s(AL);ORe=n(Qro,"STRONG",{});var jTa=s(ORe);JTt=r(jTa,"roberta"),jTa.forEach(t),YTt=r(Qro," \u2014 "),sde=n(Qro,"A",{href:!0});var DTa=s(sde);ZTt=r(DTa,"FlaxRobertaForSequenceClassification"),DTa.forEach(t),KTt=r(Qro," (RoBERTa model)"),Qro.forEach(t),eMt=i(Oe),LL=n(Oe,"LI",{});var Wro=s(LL);VRe=n(Wro,"STRONG",{});var GTa=s(VRe);oMt=r(GTa,"roformer"),GTa.forEach(t),rMt=r(Wro," \u2014 "),lde=n(Wro,"A",{href:!0});var OTa=s(lde);tMt=r(OTa,"FlaxRoFormerForSequenceClassification"),OTa.forEach(t),aMt=r(Wro," (RoFormer model)"),Wro.forEach(t),nMt=i(Oe),yL=n(Oe,"LI",{});var Uro=s(yL);XRe=n(Uro,"STRONG",{});var VTa=s(XRe);sMt=r(VTa,"xlm-roberta"),VTa.forEach(t),lMt=r(Uro," \u2014 "),ide=n(Uro,"A",{href:!0});var XTa=s(ide);iMt=r(XTa,"FlaxXLMRobertaForSequenceClassification"),XTa.forEach(t),dMt=r(Uro," (XLM-RoBERTa model)"),Uro.forEach(t),Oe.forEach(t),cMt=i(nd),T(xL.$$.fragment,nd),nd.forEach(t),ad.forEach(t),$no=i(f),Cm=n(f,"H2",{class:!0});var Ylo=s(Cm);$L=n(Ylo,"A",{id:!0,class:!0,href:!0});var zTa=s($L);zRe=n(zTa,"SPAN",{});var QTa=s(zRe);T(vB.$$.fragment,QTa),QTa.forEach(t),zTa.forEach(t),fMt=i(Ylo),QRe=n(Ylo,"SPAN",{});var WTa=s(QRe);mMt=r(WTa,"FlaxAutoModelForQuestionAnswering"),WTa.forEach(t),Ylo.forEach(t),kno=i(f),Sr=n(f,"DIV",{class:!0});var sd=s(Sr);T(bB.$$.fragment,sd),gMt=i(sd),wm=n(sd,"P",{});var Kfe=s(wm);hMt=r(Kfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),dde=n(Kfe,"A",{href:!0});var UTa=s(dde);uMt=r(UTa,"from_pretrained()"),UTa.forEach(t),pMt=r(Kfe," class method or the "),cde=n(Kfe,"A",{href:!0});var HTa=s(cde);_Mt=r(HTa,"from_config()"),HTa.forEach(t),vMt=r(Kfe,` class
method.`),Kfe.forEach(t),bMt=i(sd),FB=n(sd,"P",{});var Zlo=s(FB);FMt=r(Zlo,"This class cannot be instantiated directly using "),WRe=n(Zlo,"CODE",{});var JTa=s(WRe);TMt=r(JTa,"__init__()"),JTa.forEach(t),MMt=r(Zlo," (throws an error)."),Zlo.forEach(t),EMt=i(sd),ba=n(sd,"DIV",{class:!0});var Wx=s(ba);T(TB.$$.fragment,Wx),CMt=i(Wx),URe=n(Wx,"P",{});var YTa=s(URe);wMt=r(YTa,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),YTa.forEach(t),AMt=i(Wx),Am=n(Wx,"P",{});var eme=s(Am);LMt=r(eme,`Note:
Loading a model from its configuration file does `),HRe=n(eme,"STRONG",{});var ZTa=s(HRe);yMt=r(ZTa,"not"),ZTa.forEach(t),xMt=r(eme,` load the model weights. It only affects the
model\u2019s configuration. Use `),fde=n(eme,"A",{href:!0});var KTa=s(fde);$Mt=r(KTa,"from_pretrained()"),KTa.forEach(t),kMt=r(eme," to load the model weights."),eme.forEach(t),SMt=i(Wx),T(kL.$$.fragment,Wx),Wx.forEach(t),RMt=i(sd),it=n(sd,"DIV",{class:!0});var ld=s(it);T(MB.$$.fragment,ld),PMt=i(ld),JRe=n(ld,"P",{});var eMa=s(JRe);BMt=r(eMa,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),eMa.forEach(t),IMt=i(ld),ts=n(ld,"P",{});var Ux=s(ts);NMt=r(Ux,"The model class to instantiate is selected based on the "),YRe=n(Ux,"CODE",{});var oMa=s(YRe);qMt=r(oMa,"model_type"),oMa.forEach(t),jMt=r(Ux,` property of the config object (either
passed as an argument or loaded from `),ZRe=n(Ux,"CODE",{});var rMa=s(ZRe);DMt=r(rMa,"pretrained_model_name_or_path"),rMa.forEach(t),GMt=r(Ux,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KRe=n(Ux,"CODE",{});var tMa=s(KRe);OMt=r(tMa,"pretrained_model_name_or_path"),tMa.forEach(t),VMt=r(Ux,":"),Ux.forEach(t),XMt=i(ld),Pe=n(ld,"UL",{});var Ve=s(Pe);SL=n(Ve,"LI",{});var Hro=s(SL);ePe=n(Hro,"STRONG",{});var aMa=s(ePe);zMt=r(aMa,"albert"),aMa.forEach(t),QMt=r(Hro," \u2014 "),mde=n(Hro,"A",{href:!0});var nMa=s(mde);WMt=r(nMa,"FlaxAlbertForQuestionAnswering"),nMa.forEach(t),UMt=r(Hro," (ALBERT model)"),Hro.forEach(t),HMt=i(Ve),RL=n(Ve,"LI",{});var Jro=s(RL);oPe=n(Jro,"STRONG",{});var sMa=s(oPe);JMt=r(sMa,"bart"),sMa.forEach(t),YMt=r(Jro," \u2014 "),gde=n(Jro,"A",{href:!0});var lMa=s(gde);ZMt=r(lMa,"FlaxBartForQuestionAnswering"),lMa.forEach(t),KMt=r(Jro," (BART model)"),Jro.forEach(t),eEt=i(Ve),PL=n(Ve,"LI",{});var Yro=s(PL);rPe=n(Yro,"STRONG",{});var iMa=s(rPe);oEt=r(iMa,"bert"),iMa.forEach(t),rEt=r(Yro," \u2014 "),hde=n(Yro,"A",{href:!0});var dMa=s(hde);tEt=r(dMa,"FlaxBertForQuestionAnswering"),dMa.forEach(t),aEt=r(Yro," (BERT model)"),Yro.forEach(t),nEt=i(Ve),BL=n(Ve,"LI",{});var Zro=s(BL);tPe=n(Zro,"STRONG",{});var cMa=s(tPe);sEt=r(cMa,"big_bird"),cMa.forEach(t),lEt=r(Zro," \u2014 "),ude=n(Zro,"A",{href:!0});var fMa=s(ude);iEt=r(fMa,"FlaxBigBirdForQuestionAnswering"),fMa.forEach(t),dEt=r(Zro," (BigBird model)"),Zro.forEach(t),cEt=i(Ve),IL=n(Ve,"LI",{});var Kro=s(IL);aPe=n(Kro,"STRONG",{});var mMa=s(aPe);fEt=r(mMa,"distilbert"),mMa.forEach(t),mEt=r(Kro," \u2014 "),pde=n(Kro,"A",{href:!0});var gMa=s(pde);gEt=r(gMa,"FlaxDistilBertForQuestionAnswering"),gMa.forEach(t),hEt=r(Kro," (DistilBERT model)"),Kro.forEach(t),uEt=i(Ve),NL=n(Ve,"LI",{});var eto=s(NL);nPe=n(eto,"STRONG",{});var hMa=s(nPe);pEt=r(hMa,"electra"),hMa.forEach(t),_Et=r(eto," \u2014 "),_de=n(eto,"A",{href:!0});var uMa=s(_de);vEt=r(uMa,"FlaxElectraForQuestionAnswering"),uMa.forEach(t),bEt=r(eto," (ELECTRA model)"),eto.forEach(t),FEt=i(Ve),qL=n(Ve,"LI",{});var oto=s(qL);sPe=n(oto,"STRONG",{});var pMa=s(sPe);TEt=r(pMa,"mbart"),pMa.forEach(t),MEt=r(oto," \u2014 "),vde=n(oto,"A",{href:!0});var _Ma=s(vde);EEt=r(_Ma,"FlaxMBartForQuestionAnswering"),_Ma.forEach(t),CEt=r(oto," (mBART model)"),oto.forEach(t),wEt=i(Ve),jL=n(Ve,"LI",{});var rto=s(jL);lPe=n(rto,"STRONG",{});var vMa=s(lPe);AEt=r(vMa,"roberta"),vMa.forEach(t),LEt=r(rto," \u2014 "),bde=n(rto,"A",{href:!0});var bMa=s(bde);yEt=r(bMa,"FlaxRobertaForQuestionAnswering"),bMa.forEach(t),xEt=r(rto," (RoBERTa model)"),rto.forEach(t),$Et=i(Ve),DL=n(Ve,"LI",{});var tto=s(DL);iPe=n(tto,"STRONG",{});var FMa=s(iPe);kEt=r(FMa,"roformer"),FMa.forEach(t),SEt=r(tto," \u2014 "),Fde=n(tto,"A",{href:!0});var TMa=s(Fde);REt=r(TMa,"FlaxRoFormerForQuestionAnswering"),TMa.forEach(t),PEt=r(tto," (RoFormer model)"),tto.forEach(t),BEt=i(Ve),GL=n(Ve,"LI",{});var ato=s(GL);dPe=n(ato,"STRONG",{});var MMa=s(dPe);IEt=r(MMa,"xlm-roberta"),MMa.forEach(t),NEt=r(ato," \u2014 "),Tde=n(ato,"A",{href:!0});var EMa=s(Tde);qEt=r(EMa,"FlaxXLMRobertaForQuestionAnswering"),EMa.forEach(t),jEt=r(ato," (XLM-RoBERTa model)"),ato.forEach(t),Ve.forEach(t),DEt=i(ld),T(OL.$$.fragment,ld),ld.forEach(t),sd.forEach(t),Sno=i(f),Lm=n(f,"H2",{class:!0});var Klo=s(Lm);VL=n(Klo,"A",{id:!0,class:!0,href:!0});var CMa=s(VL);cPe=n(CMa,"SPAN",{});var wMa=s(cPe);T(EB.$$.fragment,wMa),wMa.forEach(t),CMa.forEach(t),GEt=i(Klo),fPe=n(Klo,"SPAN",{});var AMa=s(fPe);OEt=r(AMa,"FlaxAutoModelForTokenClassification"),AMa.forEach(t),Klo.forEach(t),Rno=i(f),Rr=n(f,"DIV",{class:!0});var id=s(Rr);T(CB.$$.fragment,id),VEt=i(id),ym=n(id,"P",{});var ome=s(ym);XEt=r(ome,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Mde=n(ome,"A",{href:!0});var LMa=s(Mde);zEt=r(LMa,"from_pretrained()"),LMa.forEach(t),QEt=r(ome," class method or the "),Ede=n(ome,"A",{href:!0});var yMa=s(Ede);WEt=r(yMa,"from_config()"),yMa.forEach(t),UEt=r(ome,` class
method.`),ome.forEach(t),HEt=i(id),wB=n(id,"P",{});var eio=s(wB);JEt=r(eio,"This class cannot be instantiated directly using "),mPe=n(eio,"CODE",{});var xMa=s(mPe);YEt=r(xMa,"__init__()"),xMa.forEach(t),ZEt=r(eio," (throws an error)."),eio.forEach(t),KEt=i(id),Fa=n(id,"DIV",{class:!0});var Hx=s(Fa);T(AB.$$.fragment,Hx),eCt=i(Hx),gPe=n(Hx,"P",{});var $Ma=s(gPe);oCt=r($Ma,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),$Ma.forEach(t),rCt=i(Hx),xm=n(Hx,"P",{});var rme=s(xm);tCt=r(rme,`Note:
Loading a model from its configuration file does `),hPe=n(rme,"STRONG",{});var kMa=s(hPe);aCt=r(kMa,"not"),kMa.forEach(t),nCt=r(rme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Cde=n(rme,"A",{href:!0});var SMa=s(Cde);sCt=r(SMa,"from_pretrained()"),SMa.forEach(t),lCt=r(rme," to load the model weights."),rme.forEach(t),iCt=i(Hx),T(XL.$$.fragment,Hx),Hx.forEach(t),dCt=i(id),dt=n(id,"DIV",{class:!0});var dd=s(dt);T(LB.$$.fragment,dd),cCt=i(dd),uPe=n(dd,"P",{});var RMa=s(uPe);fCt=r(RMa,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),RMa.forEach(t),mCt=i(dd),as=n(dd,"P",{});var Jx=s(as);gCt=r(Jx,"The model class to instantiate is selected based on the "),pPe=n(Jx,"CODE",{});var PMa=s(pPe);hCt=r(PMa,"model_type"),PMa.forEach(t),uCt=r(Jx,` property of the config object (either
passed as an argument or loaded from `),_Pe=n(Jx,"CODE",{});var BMa=s(_Pe);pCt=r(BMa,"pretrained_model_name_or_path"),BMa.forEach(t),_Ct=r(Jx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vPe=n(Jx,"CODE",{});var IMa=s(vPe);vCt=r(IMa,"pretrained_model_name_or_path"),IMa.forEach(t),bCt=r(Jx,":"),Jx.forEach(t),FCt=i(dd),ze=n(dd,"UL",{});var yo=s(ze);zL=n(yo,"LI",{});var nto=s(zL);bPe=n(nto,"STRONG",{});var NMa=s(bPe);TCt=r(NMa,"albert"),NMa.forEach(t),MCt=r(nto," \u2014 "),wde=n(nto,"A",{href:!0});var qMa=s(wde);ECt=r(qMa,"FlaxAlbertForTokenClassification"),qMa.forEach(t),CCt=r(nto," (ALBERT model)"),nto.forEach(t),wCt=i(yo),QL=n(yo,"LI",{});var sto=s(QL);FPe=n(sto,"STRONG",{});var jMa=s(FPe);ACt=r(jMa,"bert"),jMa.forEach(t),LCt=r(sto," \u2014 "),Ade=n(sto,"A",{href:!0});var DMa=s(Ade);yCt=r(DMa,"FlaxBertForTokenClassification"),DMa.forEach(t),xCt=r(sto," (BERT model)"),sto.forEach(t),$Ct=i(yo),WL=n(yo,"LI",{});var lto=s(WL);TPe=n(lto,"STRONG",{});var GMa=s(TPe);kCt=r(GMa,"big_bird"),GMa.forEach(t),SCt=r(lto," \u2014 "),Lde=n(lto,"A",{href:!0});var OMa=s(Lde);RCt=r(OMa,"FlaxBigBirdForTokenClassification"),OMa.forEach(t),PCt=r(lto," (BigBird model)"),lto.forEach(t),BCt=i(yo),UL=n(yo,"LI",{});var ito=s(UL);MPe=n(ito,"STRONG",{});var VMa=s(MPe);ICt=r(VMa,"distilbert"),VMa.forEach(t),NCt=r(ito," \u2014 "),yde=n(ito,"A",{href:!0});var XMa=s(yde);qCt=r(XMa,"FlaxDistilBertForTokenClassification"),XMa.forEach(t),jCt=r(ito," (DistilBERT model)"),ito.forEach(t),DCt=i(yo),HL=n(yo,"LI",{});var dto=s(HL);EPe=n(dto,"STRONG",{});var zMa=s(EPe);GCt=r(zMa,"electra"),zMa.forEach(t),OCt=r(dto," \u2014 "),xde=n(dto,"A",{href:!0});var QMa=s(xde);VCt=r(QMa,"FlaxElectraForTokenClassification"),QMa.forEach(t),XCt=r(dto," (ELECTRA model)"),dto.forEach(t),zCt=i(yo),JL=n(yo,"LI",{});var cto=s(JL);CPe=n(cto,"STRONG",{});var WMa=s(CPe);QCt=r(WMa,"roberta"),WMa.forEach(t),WCt=r(cto," \u2014 "),$de=n(cto,"A",{href:!0});var UMa=s($de);UCt=r(UMa,"FlaxRobertaForTokenClassification"),UMa.forEach(t),HCt=r(cto," (RoBERTa model)"),cto.forEach(t),JCt=i(yo),YL=n(yo,"LI",{});var fto=s(YL);wPe=n(fto,"STRONG",{});var HMa=s(wPe);YCt=r(HMa,"roformer"),HMa.forEach(t),ZCt=r(fto," \u2014 "),kde=n(fto,"A",{href:!0});var JMa=s(kde);KCt=r(JMa,"FlaxRoFormerForTokenClassification"),JMa.forEach(t),e3t=r(fto," (RoFormer model)"),fto.forEach(t),o3t=i(yo),ZL=n(yo,"LI",{});var mto=s(ZL);APe=n(mto,"STRONG",{});var YMa=s(APe);r3t=r(YMa,"xlm-roberta"),YMa.forEach(t),t3t=r(mto," \u2014 "),Sde=n(mto,"A",{href:!0});var ZMa=s(Sde);a3t=r(ZMa,"FlaxXLMRobertaForTokenClassification"),ZMa.forEach(t),n3t=r(mto," (XLM-RoBERTa model)"),mto.forEach(t),yo.forEach(t),s3t=i(dd),T(KL.$$.fragment,dd),dd.forEach(t),id.forEach(t),Pno=i(f),$m=n(f,"H2",{class:!0});var oio=s($m);ey=n(oio,"A",{id:!0,class:!0,href:!0});var KMa=s(ey);LPe=n(KMa,"SPAN",{});var eEa=s(LPe);T(yB.$$.fragment,eEa),eEa.forEach(t),KMa.forEach(t),l3t=i(oio),yPe=n(oio,"SPAN",{});var oEa=s(yPe);i3t=r(oEa,"FlaxAutoModelForMultipleChoice"),oEa.forEach(t),oio.forEach(t),Bno=i(f),Pr=n(f,"DIV",{class:!0});var cd=s(Pr);T(xB.$$.fragment,cd),d3t=i(cd),km=n(cd,"P",{});var tme=s(km);c3t=r(tme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Rde=n(tme,"A",{href:!0});var rEa=s(Rde);f3t=r(rEa,"from_pretrained()"),rEa.forEach(t),m3t=r(tme," class method or the "),Pde=n(tme,"A",{href:!0});var tEa=s(Pde);g3t=r(tEa,"from_config()"),tEa.forEach(t),h3t=r(tme,` class
method.`),tme.forEach(t),u3t=i(cd),$B=n(cd,"P",{});var rio=s($B);p3t=r(rio,"This class cannot be instantiated directly using "),xPe=n(rio,"CODE",{});var aEa=s(xPe);_3t=r(aEa,"__init__()"),aEa.forEach(t),v3t=r(rio," (throws an error)."),rio.forEach(t),b3t=i(cd),Ta=n(cd,"DIV",{class:!0});var Yx=s(Ta);T(kB.$$.fragment,Yx),F3t=i(Yx),$Pe=n(Yx,"P",{});var nEa=s($Pe);T3t=r(nEa,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),nEa.forEach(t),M3t=i(Yx),Sm=n(Yx,"P",{});var ame=s(Sm);E3t=r(ame,`Note:
Loading a model from its configuration file does `),kPe=n(ame,"STRONG",{});var sEa=s(kPe);C3t=r(sEa,"not"),sEa.forEach(t),w3t=r(ame,` load the model weights. It only affects the
model\u2019s configuration. Use `),Bde=n(ame,"A",{href:!0});var lEa=s(Bde);A3t=r(lEa,"from_pretrained()"),lEa.forEach(t),L3t=r(ame," to load the model weights."),ame.forEach(t),y3t=i(Yx),T(oy.$$.fragment,Yx),Yx.forEach(t),x3t=i(cd),ct=n(cd,"DIV",{class:!0});var fd=s(ct);T(SB.$$.fragment,fd),$3t=i(fd),SPe=n(fd,"P",{});var iEa=s(SPe);k3t=r(iEa,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),iEa.forEach(t),S3t=i(fd),ns=n(fd,"P",{});var Zx=s(ns);R3t=r(Zx,"The model class to instantiate is selected based on the "),RPe=n(Zx,"CODE",{});var dEa=s(RPe);P3t=r(dEa,"model_type"),dEa.forEach(t),B3t=r(Zx,` property of the config object (either
passed as an argument or loaded from `),PPe=n(Zx,"CODE",{});var cEa=s(PPe);I3t=r(cEa,"pretrained_model_name_or_path"),cEa.forEach(t),N3t=r(Zx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),BPe=n(Zx,"CODE",{});var fEa=s(BPe);q3t=r(fEa,"pretrained_model_name_or_path"),fEa.forEach(t),j3t=r(Zx,":"),Zx.forEach(t),D3t=i(fd),Qe=n(fd,"UL",{});var xo=s(Qe);ry=n(xo,"LI",{});var gto=s(ry);IPe=n(gto,"STRONG",{});var mEa=s(IPe);G3t=r(mEa,"albert"),mEa.forEach(t),O3t=r(gto," \u2014 "),Ide=n(gto,"A",{href:!0});var gEa=s(Ide);V3t=r(gEa,"FlaxAlbertForMultipleChoice"),gEa.forEach(t),X3t=r(gto," (ALBERT model)"),gto.forEach(t),z3t=i(xo),ty=n(xo,"LI",{});var hto=s(ty);NPe=n(hto,"STRONG",{});var hEa=s(NPe);Q3t=r(hEa,"bert"),hEa.forEach(t),W3t=r(hto," \u2014 "),Nde=n(hto,"A",{href:!0});var uEa=s(Nde);U3t=r(uEa,"FlaxBertForMultipleChoice"),uEa.forEach(t),H3t=r(hto," (BERT model)"),hto.forEach(t),J3t=i(xo),ay=n(xo,"LI",{});var uto=s(ay);qPe=n(uto,"STRONG",{});var pEa=s(qPe);Y3t=r(pEa,"big_bird"),pEa.forEach(t),Z3t=r(uto," \u2014 "),qde=n(uto,"A",{href:!0});var _Ea=s(qde);K3t=r(_Ea,"FlaxBigBirdForMultipleChoice"),_Ea.forEach(t),e5t=r(uto," (BigBird model)"),uto.forEach(t),o5t=i(xo),ny=n(xo,"LI",{});var pto=s(ny);jPe=n(pto,"STRONG",{});var vEa=s(jPe);r5t=r(vEa,"distilbert"),vEa.forEach(t),t5t=r(pto," \u2014 "),jde=n(pto,"A",{href:!0});var bEa=s(jde);a5t=r(bEa,"FlaxDistilBertForMultipleChoice"),bEa.forEach(t),n5t=r(pto," (DistilBERT model)"),pto.forEach(t),s5t=i(xo),sy=n(xo,"LI",{});var _to=s(sy);DPe=n(_to,"STRONG",{});var FEa=s(DPe);l5t=r(FEa,"electra"),FEa.forEach(t),i5t=r(_to," \u2014 "),Dde=n(_to,"A",{href:!0});var TEa=s(Dde);d5t=r(TEa,"FlaxElectraForMultipleChoice"),TEa.forEach(t),c5t=r(_to," (ELECTRA model)"),_to.forEach(t),f5t=i(xo),ly=n(xo,"LI",{});var vto=s(ly);GPe=n(vto,"STRONG",{});var MEa=s(GPe);m5t=r(MEa,"roberta"),MEa.forEach(t),g5t=r(vto," \u2014 "),Gde=n(vto,"A",{href:!0});var EEa=s(Gde);h5t=r(EEa,"FlaxRobertaForMultipleChoice"),EEa.forEach(t),u5t=r(vto," (RoBERTa model)"),vto.forEach(t),p5t=i(xo),iy=n(xo,"LI",{});var bto=s(iy);OPe=n(bto,"STRONG",{});var CEa=s(OPe);_5t=r(CEa,"roformer"),CEa.forEach(t),v5t=r(bto," \u2014 "),Ode=n(bto,"A",{href:!0});var wEa=s(Ode);b5t=r(wEa,"FlaxRoFormerForMultipleChoice"),wEa.forEach(t),F5t=r(bto," (RoFormer model)"),bto.forEach(t),T5t=i(xo),dy=n(xo,"LI",{});var Fto=s(dy);VPe=n(Fto,"STRONG",{});var AEa=s(VPe);M5t=r(AEa,"xlm-roberta"),AEa.forEach(t),E5t=r(Fto," \u2014 "),Vde=n(Fto,"A",{href:!0});var LEa=s(Vde);C5t=r(LEa,"FlaxXLMRobertaForMultipleChoice"),LEa.forEach(t),w5t=r(Fto," (XLM-RoBERTa model)"),Fto.forEach(t),xo.forEach(t),A5t=i(fd),T(cy.$$.fragment,fd),fd.forEach(t),cd.forEach(t),Ino=i(f),Rm=n(f,"H2",{class:!0});var tio=s(Rm);fy=n(tio,"A",{id:!0,class:!0,href:!0});var yEa=s(fy);XPe=n(yEa,"SPAN",{});var xEa=s(XPe);T(RB.$$.fragment,xEa),xEa.forEach(t),yEa.forEach(t),L5t=i(tio),zPe=n(tio,"SPAN",{});var $Ea=s(zPe);y5t=r($Ea,"FlaxAutoModelForNextSentencePrediction"),$Ea.forEach(t),tio.forEach(t),Nno=i(f),Br=n(f,"DIV",{class:!0});var md=s(Br);T(PB.$$.fragment,md),x5t=i(md),Pm=n(md,"P",{});var nme=s(Pm);$5t=r(nme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Xde=n(nme,"A",{href:!0});var kEa=s(Xde);k5t=r(kEa,"from_pretrained()"),kEa.forEach(t),S5t=r(nme," class method or the "),zde=n(nme,"A",{href:!0});var SEa=s(zde);R5t=r(SEa,"from_config()"),SEa.forEach(t),P5t=r(nme,` class
method.`),nme.forEach(t),B5t=i(md),BB=n(md,"P",{});var aio=s(BB);I5t=r(aio,"This class cannot be instantiated directly using "),QPe=n(aio,"CODE",{});var REa=s(QPe);N5t=r(REa,"__init__()"),REa.forEach(t),q5t=r(aio," (throws an error)."),aio.forEach(t),j5t=i(md),Ma=n(md,"DIV",{class:!0});var Kx=s(Ma);T(IB.$$.fragment,Kx),D5t=i(Kx),WPe=n(Kx,"P",{});var PEa=s(WPe);G5t=r(PEa,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),PEa.forEach(t),O5t=i(Kx),Bm=n(Kx,"P",{});var sme=s(Bm);V5t=r(sme,`Note:
Loading a model from its configuration file does `),UPe=n(sme,"STRONG",{});var BEa=s(UPe);X5t=r(BEa,"not"),BEa.forEach(t),z5t=r(sme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Qde=n(sme,"A",{href:!0});var IEa=s(Qde);Q5t=r(IEa,"from_pretrained()"),IEa.forEach(t),W5t=r(sme," to load the model weights."),sme.forEach(t),U5t=i(Kx),T(my.$$.fragment,Kx),Kx.forEach(t),H5t=i(md),ft=n(md,"DIV",{class:!0});var gd=s(ft);T(NB.$$.fragment,gd),J5t=i(gd),HPe=n(gd,"P",{});var NEa=s(HPe);Y5t=r(NEa,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),NEa.forEach(t),Z5t=i(gd),ss=n(gd,"P",{});var e$=s(ss);K5t=r(e$,"The model class to instantiate is selected based on the "),JPe=n(e$,"CODE",{});var qEa=s(JPe);ewt=r(qEa,"model_type"),qEa.forEach(t),owt=r(e$,` property of the config object (either
passed as an argument or loaded from `),YPe=n(e$,"CODE",{});var jEa=s(YPe);rwt=r(jEa,"pretrained_model_name_or_path"),jEa.forEach(t),twt=r(e$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZPe=n(e$,"CODE",{});var DEa=s(ZPe);awt=r(DEa,"pretrained_model_name_or_path"),DEa.forEach(t),nwt=r(e$,":"),e$.forEach(t),swt=i(gd),KPe=n(gd,"UL",{});var GEa=s(KPe);gy=n(GEa,"LI",{});var Tto=s(gy);eBe=n(Tto,"STRONG",{});var OEa=s(eBe);lwt=r(OEa,"bert"),OEa.forEach(t),iwt=r(Tto," \u2014 "),Wde=n(Tto,"A",{href:!0});var VEa=s(Wde);dwt=r(VEa,"FlaxBertForNextSentencePrediction"),VEa.forEach(t),cwt=r(Tto," (BERT model)"),Tto.forEach(t),GEa.forEach(t),fwt=i(gd),T(hy.$$.fragment,gd),gd.forEach(t),md.forEach(t),qno=i(f),Im=n(f,"H2",{class:!0});var nio=s(Im);uy=n(nio,"A",{id:!0,class:!0,href:!0});var XEa=s(uy);oBe=n(XEa,"SPAN",{});var zEa=s(oBe);T(qB.$$.fragment,zEa),zEa.forEach(t),XEa.forEach(t),mwt=i(nio),rBe=n(nio,"SPAN",{});var QEa=s(rBe);gwt=r(QEa,"FlaxAutoModelForImageClassification"),QEa.forEach(t),nio.forEach(t),jno=i(f),Ir=n(f,"DIV",{class:!0});var hd=s(Ir);T(jB.$$.fragment,hd),hwt=i(hd),Nm=n(hd,"P",{});var lme=s(Nm);uwt=r(lme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Ude=n(lme,"A",{href:!0});var WEa=s(Ude);pwt=r(WEa,"from_pretrained()"),WEa.forEach(t),_wt=r(lme," class method or the "),Hde=n(lme,"A",{href:!0});var UEa=s(Hde);vwt=r(UEa,"from_config()"),UEa.forEach(t),bwt=r(lme,` class
method.`),lme.forEach(t),Fwt=i(hd),DB=n(hd,"P",{});var sio=s(DB);Twt=r(sio,"This class cannot be instantiated directly using "),tBe=n(sio,"CODE",{});var HEa=s(tBe);Mwt=r(HEa,"__init__()"),HEa.forEach(t),Ewt=r(sio," (throws an error)."),sio.forEach(t),Cwt=i(hd),Ea=n(hd,"DIV",{class:!0});var o$=s(Ea);T(GB.$$.fragment,o$),wwt=i(o$),aBe=n(o$,"P",{});var JEa=s(aBe);Awt=r(JEa,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),JEa.forEach(t),Lwt=i(o$),qm=n(o$,"P",{});var ime=s(qm);ywt=r(ime,`Note:
Loading a model from its configuration file does `),nBe=n(ime,"STRONG",{});var YEa=s(nBe);xwt=r(YEa,"not"),YEa.forEach(t),$wt=r(ime,` load the model weights. It only affects the
model\u2019s configuration. Use `),Jde=n(ime,"A",{href:!0});var ZEa=s(Jde);kwt=r(ZEa,"from_pretrained()"),ZEa.forEach(t),Swt=r(ime," to load the model weights."),ime.forEach(t),Rwt=i(o$),T(py.$$.fragment,o$),o$.forEach(t),Pwt=i(hd),mt=n(hd,"DIV",{class:!0});var ud=s(mt);T(OB.$$.fragment,ud),Bwt=i(ud),sBe=n(ud,"P",{});var KEa=s(sBe);Iwt=r(KEa,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),KEa.forEach(t),Nwt=i(ud),ls=n(ud,"P",{});var r$=s(ls);qwt=r(r$,"The model class to instantiate is selected based on the "),lBe=n(r$,"CODE",{});var eCa=s(lBe);jwt=r(eCa,"model_type"),eCa.forEach(t),Dwt=r(r$,` property of the config object (either
passed as an argument or loaded from `),iBe=n(r$,"CODE",{});var oCa=s(iBe);Gwt=r(oCa,"pretrained_model_name_or_path"),oCa.forEach(t),Owt=r(r$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dBe=n(r$,"CODE",{});var rCa=s(dBe);Vwt=r(rCa,"pretrained_model_name_or_path"),rCa.forEach(t),Xwt=r(r$,":"),r$.forEach(t),zwt=i(ud),VB=n(ud,"UL",{});var lio=s(VB);_y=n(lio,"LI",{});var Mto=s(_y);cBe=n(Mto,"STRONG",{});var tCa=s(cBe);Qwt=r(tCa,"beit"),tCa.forEach(t),Wwt=r(Mto," \u2014 "),Yde=n(Mto,"A",{href:!0});var aCa=s(Yde);Uwt=r(aCa,"FlaxBeitForImageClassification"),aCa.forEach(t),Hwt=r(Mto," (BEiT model)"),Mto.forEach(t),Jwt=i(lio),vy=n(lio,"LI",{});var Eto=s(vy);fBe=n(Eto,"STRONG",{});var nCa=s(fBe);Ywt=r(nCa,"vit"),nCa.forEach(t),Zwt=r(Eto," \u2014 "),Zde=n(Eto,"A",{href:!0});var sCa=s(Zde);Kwt=r(sCa,"FlaxViTForImageClassification"),sCa.forEach(t),eAt=r(Eto," (ViT model)"),Eto.forEach(t),lio.forEach(t),oAt=i(ud),T(by.$$.fragment,ud),ud.forEach(t),hd.forEach(t),Dno=i(f),jm=n(f,"H2",{class:!0});var iio=s(jm);Fy=n(iio,"A",{id:!0,class:!0,href:!0});var lCa=s(Fy);mBe=n(lCa,"SPAN",{});var iCa=s(mBe);T(XB.$$.fragment,iCa),iCa.forEach(t),lCa.forEach(t),rAt=i(iio),gBe=n(iio,"SPAN",{});var dCa=s(gBe);tAt=r(dCa,"FlaxAutoModelForVision2Seq"),dCa.forEach(t),iio.forEach(t),Gno=i(f),Nr=n(f,"DIV",{class:!0});var pd=s(Nr);T(zB.$$.fragment,pd),aAt=i(pd),Dm=n(pd,"P",{});var dme=s(Dm);nAt=r(dme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Kde=n(dme,"A",{href:!0});var cCa=s(Kde);sAt=r(cCa,"from_pretrained()"),cCa.forEach(t),lAt=r(dme," class method or the "),ece=n(dme,"A",{href:!0});var fCa=s(ece);iAt=r(fCa,"from_config()"),fCa.forEach(t),dAt=r(dme,` class
method.`),dme.forEach(t),cAt=i(pd),QB=n(pd,"P",{});var dio=s(QB);fAt=r(dio,"This class cannot be instantiated directly using "),hBe=n(dio,"CODE",{});var mCa=s(hBe);mAt=r(mCa,"__init__()"),mCa.forEach(t),gAt=r(dio," (throws an error)."),dio.forEach(t),hAt=i(pd),Ca=n(pd,"DIV",{class:!0});var t$=s(Ca);T(WB.$$.fragment,t$),uAt=i(t$),uBe=n(t$,"P",{});var gCa=s(uBe);pAt=r(gCa,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),gCa.forEach(t),_At=i(t$),Gm=n(t$,"P",{});var cme=s(Gm);vAt=r(cme,`Note:
Loading a model from its configuration file does `),pBe=n(cme,"STRONG",{});var hCa=s(pBe);bAt=r(hCa,"not"),hCa.forEach(t),FAt=r(cme,` load the model weights. It only affects the
model\u2019s configuration. Use `),oce=n(cme,"A",{href:!0});var uCa=s(oce);TAt=r(uCa,"from_pretrained()"),uCa.forEach(t),MAt=r(cme," to load the model weights."),cme.forEach(t),EAt=i(t$),T(Ty.$$.fragment,t$),t$.forEach(t),CAt=i(pd),gt=n(pd,"DIV",{class:!0});var _d=s(gt);T(UB.$$.fragment,_d),wAt=i(_d),_Be=n(_d,"P",{});var pCa=s(_Be);AAt=r(pCa,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),pCa.forEach(t),LAt=i(_d),is=n(_d,"P",{});var a$=s(is);yAt=r(a$,"The model class to instantiate is selected based on the "),vBe=n(a$,"CODE",{});var _Ca=s(vBe);xAt=r(_Ca,"model_type"),_Ca.forEach(t),$At=r(a$,` property of the config object (either
passed as an argument or loaded from `),bBe=n(a$,"CODE",{});var vCa=s(bBe);kAt=r(vCa,"pretrained_model_name_or_path"),vCa.forEach(t),SAt=r(a$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FBe=n(a$,"CODE",{});var bCa=s(FBe);RAt=r(bCa,"pretrained_model_name_or_path"),bCa.forEach(t),PAt=r(a$,":"),a$.forEach(t),BAt=i(_d),TBe=n(_d,"UL",{});var FCa=s(TBe);My=n(FCa,"LI",{});var Cto=s(My);MBe=n(Cto,"STRONG",{});var TCa=s(MBe);IAt=r(TCa,"vision-encoder-decoder"),TCa.forEach(t),NAt=r(Cto," \u2014 "),rce=n(Cto,"A",{href:!0});var MCa=s(rce);qAt=r(MCa,"FlaxVisionEncoderDecoderModel"),MCa.forEach(t),jAt=r(Cto," (Vision Encoder decoder model)"),Cto.forEach(t),FCa.forEach(t),DAt=i(_d),T(Ey.$$.fragment,_d),_d.forEach(t),pd.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(D5a)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(u,"class","relative group"),c(cs,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.AutoConfig"),c(ms,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.AutoModel"),c(gs,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.AutoTokenizer"),c(Cd,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertModel"),c(Hm,"id","extending-the-auto-classes"),c(Hm,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Hm,"href","#extending-the-auto-classes"),c(wd,"class","relative group"),c(Ym,"id","transformers.AutoConfig"),c(Ym,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ym,"href","#transformers.AutoConfig"),c(Ad,"class","relative group"),c(yN,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(xN,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertConfig"),c($N,"href","/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartConfig"),c(kN,"href","/docs/transformers/v4.24.0/en/model_doc/beit#transformers.BeitConfig"),c(SN,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig"),c(RN,"href","/docs/transformers/v4.24.0/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(PN,"href","/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdConfig"),c(BN,"href","/docs/transformers/v4.24.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(IN,"href","/docs/transformers/v4.24.0/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(NN,"href","/docs/transformers/v4.24.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(qN,"href","/docs/transformers/v4.24.0/en/model_doc/bloom#transformers.BloomConfig"),c(jN,"href","/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertConfig"),c(DN,"href","/docs/transformers/v4.24.0/en/model_doc/canine#transformers.CanineConfig"),c(GN,"href","/docs/transformers/v4.24.0/en/model_doc/clip#transformers.CLIPConfig"),c(ON,"href","/docs/transformers/v4.24.0/en/model_doc/codegen#transformers.CodeGenConfig"),c(VN,"href","/docs/transformers/v4.24.0/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig"),c(XN,"href","/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertConfig"),c(zN,"href","/docs/transformers/v4.24.0/en/model_doc/convnext#transformers.ConvNextConfig"),c(QN,"href","/docs/transformers/v4.24.0/en/model_doc/ctrl#transformers.CTRLConfig"),c(WN,"href","/docs/transformers/v4.24.0/en/model_doc/cvt#transformers.CvtConfig"),c(UN,"href","/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(HN,"href","/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(JN,"href","/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(YN,"href","/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.DebertaConfig"),c(ZN,"href","/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(KN,"href","/docs/transformers/v4.24.0/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(eq,"href","/docs/transformers/v4.24.0/en/model_doc/deformable_detr#transformers.DeformableDetrConfig"),c(oq,"href","/docs/transformers/v4.24.0/en/model_doc/deit#transformers.DeiTConfig"),c(rq,"href","/docs/transformers/v4.24.0/en/model_doc/detr#transformers.DetrConfig"),c(tq,"href","/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertConfig"),c(aq,"href","/docs/transformers/v4.24.0/en/model_doc/donut#transformers.DonutSwinConfig"),c(nq,"href","/docs/transformers/v4.24.0/en/model_doc/dpr#transformers.DPRConfig"),c(sq,"href","/docs/transformers/v4.24.0/en/model_doc/dpt#transformers.DPTConfig"),c(lq,"href","/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraConfig"),c(iq,"href","/docs/transformers/v4.24.0/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(dq,"href","/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieConfig"),c(cq,"href","/docs/transformers/v4.24.0/en/model_doc/esm#transformers.EsmConfig"),c(fq,"href","/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertConfig"),c(mq,"href","/docs/transformers/v4.24.0/en/model_doc/flava#transformers.FlavaConfig"),c(gq,"href","/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetConfig"),c(hq,"href","/docs/transformers/v4.24.0/en/model_doc/fsmt#transformers.FSMTConfig"),c(uq,"href","/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelConfig"),c(pq,"href","/docs/transformers/v4.24.0/en/model_doc/glpn#transformers.GLPNConfig"),c(_q,"href","/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2Config"),c(vq,"href","/docs/transformers/v4.24.0/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(bq,"href","/docs/transformers/v4.24.0/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(Fq,"href","/docs/transformers/v4.24.0/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig"),c(Tq,"href","/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.GPTJConfig"),c(Mq,"href","/docs/transformers/v4.24.0/en/model_doc/groupvit#transformers.GroupViTConfig"),c(Eq,"href","/docs/transformers/v4.24.0/en/model_doc/hubert#transformers.HubertConfig"),c(Cq,"href","/docs/transformers/v4.24.0/en/model_doc/ibert#transformers.IBertConfig"),c(wq,"href","/docs/transformers/v4.24.0/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(Aq,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(Lq,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(yq,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(xq,"href","/docs/transformers/v4.24.0/en/model_doc/led#transformers.LEDConfig"),c($q,"href","/docs/transformers/v4.24.0/en/model_doc/levit#transformers.LevitConfig"),c(kq,"href","/docs/transformers/v4.24.0/en/model_doc/lilt#transformers.LiltConfig"),c(Sq,"href","/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerConfig"),c(Rq,"href","/docs/transformers/v4.24.0/en/model_doc/longt5#transformers.LongT5Config"),c(Pq,"href","/docs/transformers/v4.24.0/en/model_doc/luke#transformers.LukeConfig"),c(Bq,"href","/docs/transformers/v4.24.0/en/model_doc/lxmert#transformers.LxmertConfig"),c(Iq,"href","/docs/transformers/v4.24.0/en/model_doc/m2m_100#transformers.M2M100Config"),c(Nq,"href","/docs/transformers/v4.24.0/en/model_doc/marian#transformers.MarianConfig"),c(qq,"href","/docs/transformers/v4.24.0/en/model_doc/markuplm#transformers.MarkupLMConfig"),c(jq,"href","/docs/transformers/v4.24.0/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(Dq,"href","/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartConfig"),c(Gq,"href","/docs/transformers/v4.24.0/en/model_doc/mctct#transformers.MCTCTConfig"),c(Oq,"href","/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(Vq,"href","/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(Xq,"href","/docs/transformers/v4.24.0/en/model_doc/mobilevit#transformers.MobileViTConfig"),c(zq,"href","/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetConfig"),c(Qq,"href","/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.MT5Config"),c(Wq,"href","/docs/transformers/v4.24.0/en/model_doc/mvp#transformers.MvpConfig"),c(Uq,"href","/docs/transformers/v4.24.0/en/model_doc/nezha#transformers.NezhaConfig"),c(Hq,"href","/docs/transformers/v4.24.0/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(Jq,"href","/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(Yq,"href","/docs/transformers/v4.24.0/en/model_doc/opt#transformers.OPTConfig"),c(Zq,"href","/docs/transformers/v4.24.0/en/model_doc/owlvit#transformers.OwlViTConfig"),c(Kq,"href","/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.PegasusConfig"),c(ej,"href","/docs/transformers/v4.24.0/en/model_doc/pegasus_x#transformers.PegasusXConfig"),c(oj,"href","/docs/transformers/v4.24.0/en/model_doc/perceiver#transformers.PerceiverConfig"),c(rj,"href","/docs/transformers/v4.24.0/en/model_doc/plbart#transformers.PLBartConfig"),c(tj,"href","/docs/transformers/v4.24.0/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(aj,"href","/docs/transformers/v4.24.0/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(nj,"href","/docs/transformers/v4.24.0/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(sj,"href","/docs/transformers/v4.24.0/en/model_doc/rag#transformers.RagConfig"),c(lj,"href","/docs/transformers/v4.24.0/en/model_doc/realm#transformers.RealmConfig"),c(ij,"href","/docs/transformers/v4.24.0/en/model_doc/reformer#transformers.ReformerConfig"),c(dj,"href","/docs/transformers/v4.24.0/en/model_doc/regnet#transformers.RegNetConfig"),c(cj,"href","/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertConfig"),c(fj,"href","/docs/transformers/v4.24.0/en/model_doc/resnet#transformers.ResNetConfig"),c(mj,"href","/docs/transformers/v4.24.0/en/model_doc/retribert#transformers.RetriBertConfig"),c(gj,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaConfig"),c(hj,"href","/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerConfig"),c(uj,"href","/docs/transformers/v4.24.0/en/model_doc/segformer#transformers.SegformerConfig"),c(pj,"href","/docs/transformers/v4.24.0/en/model_doc/sew#transformers.SEWConfig"),c(_j,"href","/docs/transformers/v4.24.0/en/model_doc/sew-d#transformers.SEWDConfig"),c(vj,"href","/docs/transformers/v4.24.0/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(bj,"href","/docs/transformers/v4.24.0/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(Fj,"href","/docs/transformers/v4.24.0/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(Tj,"href","/docs/transformers/v4.24.0/en/model_doc/splinter#transformers.SplinterConfig"),c(Mj,"href","/docs/transformers/v4.24.0/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(Ej,"href","/docs/transformers/v4.24.0/en/model_doc/swin#transformers.SwinConfig"),c(Cj,"href","/docs/transformers/v4.24.0/en/model_doc/swinv2#transformers.Swinv2Config"),c(wj,"href","/docs/transformers/v4.24.0/en/model_doc/t5#transformers.T5Config"),c(Aj,"href","/docs/transformers/v4.24.0/en/model_doc/table-transformer#transformers.TableTransformerConfig"),c(Lj,"href","/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TapasConfig"),c(yj,"href","/docs/transformers/v4.24.0/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig"),c(xj,"href","/docs/transformers/v4.24.0/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c($j,"href","/docs/transformers/v4.24.0/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(kj,"href","/docs/transformers/v4.24.0/en/model_doc/trocr#transformers.TrOCRConfig"),c(Sj,"href","/docs/transformers/v4.24.0/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(Rj,"href","/docs/transformers/v4.24.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(Pj,"href","/docs/transformers/v4.24.0/en/model_doc/van#transformers.VanConfig"),c(Bj,"href","/docs/transformers/v4.24.0/en/model_doc/videomae#transformers.VideoMAEConfig"),c(Ij,"href","/docs/transformers/v4.24.0/en/model_doc/vilt#transformers.ViltConfig"),c(Nj,"href","/docs/transformers/v4.24.0/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(qj,"href","/docs/transformers/v4.24.0/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(jj,"href","/docs/transformers/v4.24.0/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(Dj,"href","/docs/transformers/v4.24.0/en/model_doc/vit#transformers.ViTConfig"),c(Gj,"href","/docs/transformers/v4.24.0/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(Oj,"href","/docs/transformers/v4.24.0/en/model_doc/vit_msn#transformers.ViTMSNConfig"),c(Vj,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(Xj,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(zj,"href","/docs/transformers/v4.24.0/en/model_doc/wavlm#transformers.WavLMConfig"),c(Qj,"href","/docs/transformers/v4.24.0/en/model_doc/whisper#transformers.WhisperConfig"),c(Wj,"href","/docs/transformers/v4.24.0/en/model_doc/xclip#transformers.XCLIPConfig"),c(Uj,"href","/docs/transformers/v4.24.0/en/model_doc/xglm#transformers.XGLMConfig"),c(Hj,"href","/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMConfig"),c(Jj,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(Yj,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(Zj,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(Kj,"href","/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetConfig"),c(eD,"href","/docs/transformers/v4.24.0/en/model_doc/yolos#transformers.YolosConfig"),c(oD,"href","/docs/transformers/v4.24.0/en/model_doc/yoso#transformers.YosoConfig"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Au,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lu,"id","transformers.AutoTokenizer"),c(Lu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Lu,"href","#transformers.AutoTokenizer"),c(yd,"class","relative group"),c(rD,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(tD,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertTokenizer"),c(aD,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(nD,"href","/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartTokenizer"),c(sD,"href","/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartTokenizerFast"),c(lD,"href","/docs/transformers/v4.24.0/en/model_doc/barthez#transformers.BarthezTokenizer"),c(iD,"href","/docs/transformers/v4.24.0/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(dD,"href","/docs/transformers/v4.24.0/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(cD,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertTokenizer"),c(fD,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertTokenizerFast"),c(mD,"href","/docs/transformers/v4.24.0/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(gD,"href","/docs/transformers/v4.24.0/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(hD,"href","/docs/transformers/v4.24.0/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(uD,"href","/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(pD,"href","/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(_D,"href","/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(vD,"href","/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(bD,"href","/docs/transformers/v4.24.0/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(FD,"href","/docs/transformers/v4.24.0/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(TD,"href","/docs/transformers/v4.24.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(MD,"href","/docs/transformers/v4.24.0/en/model_doc/bloom#transformers.BloomTokenizerFast"),c(ED,"href","/docs/transformers/v4.24.0/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(CD,"href","/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertTokenizer"),c(wD,"href","/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(AD,"href","/docs/transformers/v4.24.0/en/model_doc/canine#transformers.CanineTokenizer"),c(LD,"href","/docs/transformers/v4.24.0/en/model_doc/clip#transformers.CLIPTokenizer"),c(yD,"href","/docs/transformers/v4.24.0/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(xD,"href","/docs/transformers/v4.24.0/en/model_doc/codegen#transformers.CodeGenTokenizer"),c($D,"href","/docs/transformers/v4.24.0/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),c(kD,"href","/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(SD,"href","/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(RD,"href","/docs/transformers/v4.24.0/en/model_doc/cpm#transformers.CpmTokenizer"),c(PD,"href","/docs/transformers/v4.24.0/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(BD,"href","/docs/transformers/v4.24.0/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(ID,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaTokenizer"),c(ND,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(qD,"href","/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.DebertaTokenizer"),c(jD,"href","/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(DD,"href","/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(GD,"href","/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(OD,"href","/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(VD,"href","/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(XD,"href","/docs/transformers/v4.24.0/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(zD,"href","/docs/transformers/v4.24.0/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(QD,"href","/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraTokenizer"),c(WD,"href","/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(UD,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertTokenizer"),c(HD,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertTokenizerFast"),c(JD,"href","/docs/transformers/v4.24.0/en/model_doc/esm#transformers.EsmTokenizer"),c(YD,"href","/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(ZD,"href","/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetTokenizer"),c(KD,"href","/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(eG,"href","/docs/transformers/v4.24.0/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(oG,"href","/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelTokenizer"),c(rG,"href","/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(tG,"href","/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(aG,"href","/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(nG,"href","/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(sG,"href","/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(lG,"href","/docs/transformers/v4.24.0/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(iG,"href","/docs/transformers/v4.24.0/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseTokenizer"),c(dG,"href","/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(cG,"href","/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(fG,"href","/docs/transformers/v4.24.0/en/model_doc/clip#transformers.CLIPTokenizer"),c(mG,"href","/docs/transformers/v4.24.0/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(gG,"href","/docs/transformers/v4.24.0/en/model_doc/herbert#transformers.HerbertTokenizer"),c(hG,"href","/docs/transformers/v4.24.0/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(uG,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(pG,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaTokenizer"),c(_G,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(vG,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(bG,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(FG,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(TG,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(MG,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(EG,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(CG,"href","/docs/transformers/v4.24.0/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(wG,"href","/docs/transformers/v4.24.0/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(AG,"href","/docs/transformers/v4.24.0/en/model_doc/led#transformers.LEDTokenizer"),c(LG,"href","/docs/transformers/v4.24.0/en/model_doc/led#transformers.LEDTokenizerFast"),c(yG,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(xG,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c($G,"href","/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerTokenizer"),c(kG,"href","/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(SG,"href","/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.T5Tokenizer"),c(RG,"href","/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.T5TokenizerFast"),c(PG,"href","/docs/transformers/v4.24.0/en/model_doc/luke#transformers.LukeTokenizer"),c(BG,"href","/docs/transformers/v4.24.0/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(IG,"href","/docs/transformers/v4.24.0/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(NG,"href","/docs/transformers/v4.24.0/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(qG,"href","/docs/transformers/v4.24.0/en/model_doc/marian#transformers.MarianTokenizer"),c(jG,"href","/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartTokenizer"),c(DG,"href","/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(GG,"href","/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(OG,"href","/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(VG,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertTokenizer"),c(XG,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertTokenizerFast"),c(zG,"href","/docs/transformers/v4.24.0/en/model_doc/mluke#transformers.MLukeTokenizer"),c(QG,"href","/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(WG,"href","/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(UG,"href","/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(HG,"href","/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(JG,"href","/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.T5Tokenizer"),c(YG,"href","/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.T5TokenizerFast"),c(ZG,"href","/docs/transformers/v4.24.0/en/model_doc/mvp#transformers.MvpTokenizer"),c(KG,"href","/docs/transformers/v4.24.0/en/model_doc/mvp#transformers.MvpTokenizerFast"),c(eO,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertTokenizer"),c(oO,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertTokenizerFast"),c(rO,"href","/docs/transformers/v4.24.0/en/model_doc/nllb#transformers.NllbTokenizer"),c(tO,"href","/docs/transformers/v4.24.0/en/model_doc/nllb#transformers.NllbTokenizerFast"),c(aO,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertTokenizer"),c(nO,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(sO,"href","/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(lO,"href","/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(iO,"href","/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(dO,"href","/docs/transformers/v4.24.0/en/model_doc/clip#transformers.CLIPTokenizer"),c(cO,"href","/docs/transformers/v4.24.0/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(fO,"href","/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(mO,"href","/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(gO,"href","/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(hO,"href","/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(uO,"href","/docs/transformers/v4.24.0/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(pO,"href","/docs/transformers/v4.24.0/en/model_doc/phobert#transformers.PhobertTokenizer"),c(_O,"href","/docs/transformers/v4.24.0/en/model_doc/plbart#transformers.PLBartTokenizer"),c(vO,"href","/docs/transformers/v4.24.0/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(bO,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertTokenizer"),c(FO,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertTokenizerFast"),c(TO,"href","/docs/transformers/v4.24.0/en/model_doc/rag#transformers.RagTokenizer"),c(MO,"href","/docs/transformers/v4.24.0/en/model_doc/realm#transformers.RealmTokenizer"),c(EO,"href","/docs/transformers/v4.24.0/en/model_doc/realm#transformers.RealmTokenizerFast"),c(CO,"href","/docs/transformers/v4.24.0/en/model_doc/reformer#transformers.ReformerTokenizer"),c(wO,"href","/docs/transformers/v4.24.0/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(AO,"href","/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertTokenizer"),c(LO,"href","/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(yO,"href","/docs/transformers/v4.24.0/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(xO,"href","/docs/transformers/v4.24.0/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c($O,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaTokenizer"),c(kO,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(SO,"href","/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(RO,"href","/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(PO,"href","/docs/transformers/v4.24.0/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(BO,"href","/docs/transformers/v4.24.0/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(IO,"href","/docs/transformers/v4.24.0/en/model_doc/splinter#transformers.SplinterTokenizer"),c(NO,"href","/docs/transformers/v4.24.0/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(qO,"href","/docs/transformers/v4.24.0/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(jO,"href","/docs/transformers/v4.24.0/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(DO,"href","/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.T5Tokenizer"),c(GO,"href","/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.T5TokenizerFast"),c(OO,"href","/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TapasTokenizer"),c(VO,"href","/docs/transformers/v4.24.0/en/model_doc/tapex#transformers.TapexTokenizer"),c(XO,"href","/docs/transformers/v4.24.0/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(zO,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertTokenizer"),c(QO,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertTokenizerFast"),c(WO,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertTokenizer"),c(UO,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertTokenizerFast"),c(HO,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(JO,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(YO,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(ZO,"href","/docs/transformers/v4.24.0/en/model_doc/whisper#transformers.WhisperTokenizer"),c(KO,"href","/docs/transformers/v4.24.0/en/model_doc/clip#transformers.CLIPTokenizer"),c(eV,"href","/docs/transformers/v4.24.0/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(oV,"href","/docs/transformers/v4.24.0/en/model_doc/xglm#transformers.XGLMTokenizer"),c(rV,"href","/docs/transformers/v4.24.0/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(tV,"href","/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMTokenizer"),c(aV,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(nV,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(sV,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(lV,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(iV,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(dV,"href","/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(cV,"href","/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(fV,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertTokenizer"),c(mV,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mp,"id","transformers.AutoFeatureExtractor"),c(mp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(mp,"href","#transformers.AutoFeatureExtractor"),c(xd,"class","relative group"),c(gV,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(hV,"href","/docs/transformers/v4.24.0/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(uV,"href","/docs/transformers/v4.24.0/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(pV,"href","/docs/transformers/v4.24.0/en/model_doc/conditional_detr#transformers.ConditionalDetrFeatureExtractor"),c(_V,"href","/docs/transformers/v4.24.0/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(vV,"href","/docs/transformers/v4.24.0/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(bV,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(FV,"href","/docs/transformers/v4.24.0/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(TV,"href","/docs/transformers/v4.24.0/en/model_doc/deformable_detr#transformers.DeformableDetrFeatureExtractor"),c(MV,"href","/docs/transformers/v4.24.0/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(EV,"href","/docs/transformers/v4.24.0/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(CV,"href","/docs/transformers/v4.24.0/en/model_doc/donut#transformers.DonutFeatureExtractor"),c(wV,"href","/docs/transformers/v4.24.0/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(AV,"href","/docs/transformers/v4.24.0/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(LV,"href","/docs/transformers/v4.24.0/en/model_doc/glpn#transformers.models.glpn.image_processing_glpn.GLPNImageProcessor"),c(yV,"href","/docs/transformers/v4.24.0/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(xV,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c($V,"href","/docs/transformers/v4.24.0/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(kV,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(SV,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(RV,"href","/docs/transformers/v4.24.0/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(PV,"href","/docs/transformers/v4.24.0/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(BV,"href","/docs/transformers/v4.24.0/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),c(IV,"href","/docs/transformers/v4.24.0/en/model_doc/mobilevit#transformers.MobileViTFeatureExtractor"),c(NV,"href","/docs/transformers/v4.24.0/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor"),c(qV,"href","/docs/transformers/v4.24.0/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(jV,"href","/docs/transformers/v4.24.0/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(DV,"href","/docs/transformers/v4.24.0/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(GV,"href","/docs/transformers/v4.24.0/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(OV,"href","/docs/transformers/v4.24.0/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(VV,"href","/docs/transformers/v4.24.0/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(XV,"href","/docs/transformers/v4.24.0/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(zV,"href","/docs/transformers/v4.24.0/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(QV,"href","/docs/transformers/v4.24.0/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(WV,"href","/docs/transformers/v4.24.0/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(UV,"href","/docs/transformers/v4.24.0/en/model_doc/videomae#transformers.VideoMAEFeatureExtractor"),c(HV,"href","/docs/transformers/v4.24.0/en/model_doc/vilt#transformers.ViltFeatureExtractor"),c(JV,"href","/docs/transformers/v4.24.0/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(YV,"href","/docs/transformers/v4.24.0/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(ZV,"href","/docs/transformers/v4.24.0/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(KV,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(eX,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(oX,"href","/docs/transformers/v4.24.0/en/model_doc/whisper#transformers.WhisperFeatureExtractor"),c(rX,"href","/docs/transformers/v4.24.0/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(tX,"href","/docs/transformers/v4.24.0/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(n_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(s_,"id","transformers.AutoProcessor"),c(s_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(s_,"href","#transformers.AutoProcessor"),c($d,"class","relative group"),c(aX,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(nX,"href","/docs/transformers/v4.24.0/en/model_doc/clip#transformers.CLIPProcessor"),c(sX,"href","/docs/transformers/v4.24.0/en/model_doc/flava#transformers.FlavaProcessor"),c(lX,"href","/docs/transformers/v4.24.0/en/model_doc/clip#transformers.CLIPProcessor"),c(iX,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(dX,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(cX,"href","/docs/transformers/v4.24.0/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(fX,"href","/docs/transformers/v4.24.0/en/model_doc/markuplm#transformers.MarkupLMProcessor"),c(mX,"href","/docs/transformers/v4.24.0/en/model_doc/owlvit#transformers.OwlViTProcessor"),c(gX,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(hX,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(uX,"href","/docs/transformers/v4.24.0/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(pX,"href","/docs/transformers/v4.24.0/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(_X,"href","/docs/transformers/v4.24.0/en/model_doc/trocr#transformers.TrOCRProcessor"),c(vX,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(bX,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(FX,"href","/docs/transformers/v4.24.0/en/model_doc/vilt#transformers.ViltProcessor"),c(TX,"href","/docs/transformers/v4.24.0/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(MX,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(EX,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(CX,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(wX,"href","/docs/transformers/v4.24.0/en/model_doc/whisper#transformers.WhisperProcessor"),c(AX,"href","/docs/transformers/v4.24.0/en/model_doc/xclip#transformers.XCLIPProcessor"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(k_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(S_,"id","transformers.AutoModel"),c(S_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(S_,"href","#transformers.AutoModel"),c(Sd,"class","relative group"),c(LX,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yX,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xX,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($X,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertModel"),c(kX,"href","/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartModel"),c(SX,"href","/docs/transformers/v4.24.0/en/model_doc/beit#transformers.BeitModel"),c(RX,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertModel"),c(PX,"href","/docs/transformers/v4.24.0/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(BX,"href","/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdModel"),c(IX,"href","/docs/transformers/v4.24.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(NX,"href","/docs/transformers/v4.24.0/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(qX,"href","/docs/transformers/v4.24.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(jX,"href","/docs/transformers/v4.24.0/en/model_doc/bloom#transformers.BloomModel"),c(DX,"href","/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertModel"),c(GX,"href","/docs/transformers/v4.24.0/en/model_doc/canine#transformers.CanineModel"),c(OX,"href","/docs/transformers/v4.24.0/en/model_doc/clip#transformers.CLIPModel"),c(VX,"href","/docs/transformers/v4.24.0/en/model_doc/codegen#transformers.CodeGenModel"),c(XX,"href","/docs/transformers/v4.24.0/en/model_doc/conditional_detr#transformers.ConditionalDetrModel"),c(zX,"href","/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertModel"),c(QX,"href","/docs/transformers/v4.24.0/en/model_doc/convnext#transformers.ConvNextModel"),c(WX,"href","/docs/transformers/v4.24.0/en/model_doc/ctrl#transformers.CTRLModel"),c(UX,"href","/docs/transformers/v4.24.0/en/model_doc/cvt#transformers.CvtModel"),c(HX,"href","/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(JX,"href","/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(YX,"href","/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(ZX,"href","/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.DebertaModel"),c(KX,"href","/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(ez,"href","/docs/transformers/v4.24.0/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(oz,"href","/docs/transformers/v4.24.0/en/model_doc/deformable_detr#transformers.DeformableDetrModel"),c(rz,"href","/docs/transformers/v4.24.0/en/model_doc/deit#transformers.DeiTModel"),c(tz,"href","/docs/transformers/v4.24.0/en/model_doc/detr#transformers.DetrModel"),c(az,"href","/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertModel"),c(nz,"href","/docs/transformers/v4.24.0/en/model_doc/donut#transformers.DonutSwinModel"),c(sz,"href","/docs/transformers/v4.24.0/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(lz,"href","/docs/transformers/v4.24.0/en/model_doc/dpt#transformers.DPTModel"),c(iz,"href","/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraModel"),c(dz,"href","/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieModel"),c(cz,"href","/docs/transformers/v4.24.0/en/model_doc/esm#transformers.EsmModel"),c(fz,"href","/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertModel"),c(mz,"href","/docs/transformers/v4.24.0/en/model_doc/flava#transformers.FlavaModel"),c(gz,"href","/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetModel"),c(hz,"href","/docs/transformers/v4.24.0/en/model_doc/fsmt#transformers.FSMTModel"),c(uz,"href","/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelModel"),c(pz,"href","/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelBaseModel"),c(_z,"href","/docs/transformers/v4.24.0/en/model_doc/glpn#transformers.GLPNModel"),c(vz,"href","/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2Model"),c(bz,"href","/docs/transformers/v4.24.0/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(Fz,"href","/docs/transformers/v4.24.0/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(Tz,"href","/docs/transformers/v4.24.0/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel"),c(Mz,"href","/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.GPTJModel"),c(Ez,"href","/docs/transformers/v4.24.0/en/model_doc/groupvit#transformers.GroupViTModel"),c(Cz,"href","/docs/transformers/v4.24.0/en/model_doc/hubert#transformers.HubertModel"),c(wz,"href","/docs/transformers/v4.24.0/en/model_doc/ibert#transformers.IBertModel"),c(Az,"href","/docs/transformers/v4.24.0/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(Lz,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(yz,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(xz,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c($z,"href","/docs/transformers/v4.24.0/en/model_doc/led#transformers.LEDModel"),c(kz,"href","/docs/transformers/v4.24.0/en/model_doc/levit#transformers.LevitModel"),c(Sz,"href","/docs/transformers/v4.24.0/en/model_doc/lilt#transformers.LiltModel"),c(Rz,"href","/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerModel"),c(Pz,"href","/docs/transformers/v4.24.0/en/model_doc/longt5#transformers.LongT5Model"),c(Bz,"href","/docs/transformers/v4.24.0/en/model_doc/luke#transformers.LukeModel"),c(Iz,"href","/docs/transformers/v4.24.0/en/model_doc/lxmert#transformers.LxmertModel"),c(Nz,"href","/docs/transformers/v4.24.0/en/model_doc/m2m_100#transformers.M2M100Model"),c(qz,"href","/docs/transformers/v4.24.0/en/model_doc/marian#transformers.MarianModel"),c(jz,"href","/docs/transformers/v4.24.0/en/model_doc/markuplm#transformers.MarkupLMModel"),c(Dz,"href","/docs/transformers/v4.24.0/en/model_doc/maskformer#transformers.MaskFormerModel"),c(Gz,"href","/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartModel"),c(Oz,"href","/docs/transformers/v4.24.0/en/model_doc/mctct#transformers.MCTCTModel"),c(Vz,"href","/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(Xz,"href","/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertModel"),c(zz,"href","/docs/transformers/v4.24.0/en/model_doc/mobilevit#transformers.MobileViTModel"),c(Qz,"href","/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetModel"),c(Wz,"href","/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.MT5Model"),c(Uz,"href","/docs/transformers/v4.24.0/en/model_doc/mvp#transformers.MvpModel"),c(Hz,"href","/docs/transformers/v4.24.0/en/model_doc/nezha#transformers.NezhaModel"),c(Jz,"href","/docs/transformers/v4.24.0/en/model_doc/m2m_100#transformers.M2M100Model"),c(Yz,"href","/docs/transformers/v4.24.0/en/model_doc/nystromformer#transformers.NystromformerModel"),c(Zz,"href","/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(Kz,"href","/docs/transformers/v4.24.0/en/model_doc/opt#transformers.OPTModel"),c(eQ,"href","/docs/transformers/v4.24.0/en/model_doc/owlvit#transformers.OwlViTModel"),c(oQ,"href","/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.PegasusModel"),c(rQ,"href","/docs/transformers/v4.24.0/en/model_doc/pegasus_x#transformers.PegasusXModel"),c(tQ,"href","/docs/transformers/v4.24.0/en/model_doc/perceiver#transformers.PerceiverModel"),c(aQ,"href","/docs/transformers/v4.24.0/en/model_doc/plbart#transformers.PLBartModel"),c(nQ,"href","/docs/transformers/v4.24.0/en/model_doc/poolformer#transformers.PoolFormerModel"),c(sQ,"href","/docs/transformers/v4.24.0/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(lQ,"href","/docs/transformers/v4.24.0/en/model_doc/qdqbert#transformers.QDQBertModel"),c(iQ,"href","/docs/transformers/v4.24.0/en/model_doc/reformer#transformers.ReformerModel"),c(dQ,"href","/docs/transformers/v4.24.0/en/model_doc/regnet#transformers.RegNetModel"),c(cQ,"href","/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertModel"),c(fQ,"href","/docs/transformers/v4.24.0/en/model_doc/resnet#transformers.ResNetModel"),c(mQ,"href","/docs/transformers/v4.24.0/en/model_doc/retribert#transformers.RetriBertModel"),c(gQ,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaModel"),c(hQ,"href","/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerModel"),c(uQ,"href","/docs/transformers/v4.24.0/en/model_doc/segformer#transformers.SegformerModel"),c(pQ,"href","/docs/transformers/v4.24.0/en/model_doc/sew#transformers.SEWModel"),c(_Q,"href","/docs/transformers/v4.24.0/en/model_doc/sew-d#transformers.SEWDModel"),c(vQ,"href","/docs/transformers/v4.24.0/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(bQ,"href","/docs/transformers/v4.24.0/en/model_doc/splinter#transformers.SplinterModel"),c(FQ,"href","/docs/transformers/v4.24.0/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(TQ,"href","/docs/transformers/v4.24.0/en/model_doc/swin#transformers.SwinModel"),c(MQ,"href","/docs/transformers/v4.24.0/en/model_doc/swinv2#transformers.Swinv2Model"),c(EQ,"href","/docs/transformers/v4.24.0/en/model_doc/t5#transformers.T5Model"),c(CQ,"href","/docs/transformers/v4.24.0/en/model_doc/table-transformer#transformers.TableTransformerModel"),c(wQ,"href","/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TapasModel"),c(AQ,"href","/docs/transformers/v4.24.0/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel"),c(LQ,"href","/docs/transformers/v4.24.0/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(yQ,"href","/docs/transformers/v4.24.0/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(xQ,"href","/docs/transformers/v4.24.0/en/model_doc/unispeech#transformers.UniSpeechModel"),c($Q,"href","/docs/transformers/v4.24.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(kQ,"href","/docs/transformers/v4.24.0/en/model_doc/van#transformers.VanModel"),c(SQ,"href","/docs/transformers/v4.24.0/en/model_doc/videomae#transformers.VideoMAEModel"),c(RQ,"href","/docs/transformers/v4.24.0/en/model_doc/vilt#transformers.ViltModel"),c(PQ,"href","/docs/transformers/v4.24.0/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(BQ,"href","/docs/transformers/v4.24.0/en/model_doc/visual_bert#transformers.VisualBertModel"),c(IQ,"href","/docs/transformers/v4.24.0/en/model_doc/vit#transformers.ViTModel"),c(NQ,"href","/docs/transformers/v4.24.0/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(qQ,"href","/docs/transformers/v4.24.0/en/model_doc/vit_msn#transformers.ViTMSNModel"),c(jQ,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(DQ,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(GQ,"href","/docs/transformers/v4.24.0/en/model_doc/wavlm#transformers.WavLMModel"),c(OQ,"href","/docs/transformers/v4.24.0/en/model_doc/whisper#transformers.WhisperModel"),c(VQ,"href","/docs/transformers/v4.24.0/en/model_doc/xclip#transformers.XCLIPModel"),c(XQ,"href","/docs/transformers/v4.24.0/en/model_doc/xglm#transformers.XGLMModel"),c(zQ,"href","/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMModel"),c(QQ,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(WQ,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(UQ,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(HQ,"href","/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetModel"),c(JQ,"href","/docs/transformers/v4.24.0/en/model_doc/yolos#transformers.YolosModel"),c(YQ,"href","/docs/transformers/v4.24.0/en/model_doc/yoso#transformers.YosoModel"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rv,"id","transformers.AutoModelForPreTraining"),c(rv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(rv,"href","#transformers.AutoModelForPreTraining"),c(Bd,"class","relative group"),c(ZQ,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(KQ,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eW,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oW,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertForPreTraining"),c(rW,"href","/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(tW,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertForPreTraining"),c(aW,"href","/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(nW,"href","/docs/transformers/v4.24.0/en/model_doc/bloom#transformers.BloomForCausalLM"),c(sW,"href","/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(lW,"href","/docs/transformers/v4.24.0/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(iW,"href","/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(dW,"href","/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(cW,"href","/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(fW,"href","/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(mW,"href","/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraForPreTraining"),c(gW,"href","/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieForPreTraining"),c(hW,"href","/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(uW,"href","/docs/transformers/v4.24.0/en/model_doc/flava#transformers.FlavaForPreTraining"),c(pW,"href","/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetForPreTraining"),c(_W,"href","/docs/transformers/v4.24.0/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(vW,"href","/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(bW,"href","/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(FW,"href","/docs/transformers/v4.24.0/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(TW,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(MW,"href","/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(EW,"href","/docs/transformers/v4.24.0/en/model_doc/luke#transformers.LukeForMaskedLM"),c(CW,"href","/docs/transformers/v4.24.0/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(wW,"href","/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(AW,"href","/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(LW,"href","/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(yW,"href","/docs/transformers/v4.24.0/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(xW,"href","/docs/transformers/v4.24.0/en/model_doc/nezha#transformers.NezhaForPreTraining"),c($W,"href","/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(kW,"href","/docs/transformers/v4.24.0/en/model_doc/retribert#transformers.RetriBertModel"),c(SW,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(RW,"href","/docs/transformers/v4.24.0/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(PW,"href","/docs/transformers/v4.24.0/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(BW,"href","/docs/transformers/v4.24.0/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(IW,"href","/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(NW,"href","/docs/transformers/v4.24.0/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(qW,"href","/docs/transformers/v4.24.0/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(jW,"href","/docs/transformers/v4.24.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(DW,"href","/docs/transformers/v4.24.0/en/model_doc/videomae#transformers.VideoMAEForPreTraining"),c(GW,"href","/docs/transformers/v4.24.0/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(OW,"href","/docs/transformers/v4.24.0/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(VW,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(XW,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(zW,"href","/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(QW,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(WW,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(UW,"href","/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(e1,"id","transformers.AutoModelForCausalLM"),c(e1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(e1,"href","#transformers.AutoModelForCausalLM"),c(qd,"class","relative group"),c(HW,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JW,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YW,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZW,"href","/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartForCausalLM"),c(KW,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertLMHeadModel"),c(eU,"href","/docs/transformers/v4.24.0/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(oU,"href","/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(rU,"href","/docs/transformers/v4.24.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(tU,"href","/docs/transformers/v4.24.0/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(aU,"href","/docs/transformers/v4.24.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(nU,"href","/docs/transformers/v4.24.0/en/model_doc/bloom#transformers.BloomForCausalLM"),c(sU,"href","/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(lU,"href","/docs/transformers/v4.24.0/en/model_doc/codegen#transformers.CodeGenForCausalLM"),c(iU,"href","/docs/transformers/v4.24.0/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(dU,"href","/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(cU,"href","/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraForCausalLM"),c(fU,"href","/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieForCausalLM"),c(mU,"href","/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(gU,"href","/docs/transformers/v4.24.0/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(hU,"href","/docs/transformers/v4.24.0/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(uU,"href","/docs/transformers/v4.24.0/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM"),c(pU,"href","/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(_U,"href","/docs/transformers/v4.24.0/en/model_doc/marian#transformers.MarianForCausalLM"),c(vU,"href","/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartForCausalLM"),c(bU,"href","/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(FU,"href","/docs/transformers/v4.24.0/en/model_doc/mvp#transformers.MvpForCausalLM"),c(TU,"href","/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(MU,"href","/docs/transformers/v4.24.0/en/model_doc/opt#transformers.OPTForCausalLM"),c(EU,"href","/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(CU,"href","/docs/transformers/v4.24.0/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(wU,"href","/docs/transformers/v4.24.0/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(AU,"href","/docs/transformers/v4.24.0/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(LU,"href","/docs/transformers/v4.24.0/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(yU,"href","/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(xU,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaForCausalLM"),c($U,"href","/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(kU,"href","/docs/transformers/v4.24.0/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(SU,"href","/docs/transformers/v4.24.0/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(RU,"href","/docs/transformers/v4.24.0/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(PU,"href","/docs/transformers/v4.24.0/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(BU,"href","/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(IU,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(NU,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(qU,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(jU,"href","/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Q1,"id","transformers.AutoModelForDepthEstimation"),c(Q1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Q1,"href","#transformers.AutoModelForDepthEstimation"),c(Gd,"class","relative group"),c(DU,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(GU,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(OU,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(VU,"href","/docs/transformers/v4.24.0/en/model_doc/dpt#transformers.DPTForDepthEstimation"),c(XU,"href","/docs/transformers/v4.24.0/en/model_doc/glpn#transformers.GLPNForDepthEstimation"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Z1,"id","transformers.AutoModelForMaskedLM"),c(Z1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z1,"href","#transformers.AutoModelForMaskedLM"),c(Xd,"class","relative group"),c(zU,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QU,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WU,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UU,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(HU,"href","/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(JU,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertForMaskedLM"),c(YU,"href","/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(ZU,"href","/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(KU,"href","/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(eH,"href","/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(oH,"href","/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(rH,"href","/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(tH,"href","/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(aH,"href","/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(nH,"href","/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieForMaskedLM"),c(sH,"href","/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(lH,"href","/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(iH,"href","/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(dH,"href","/docs/transformers/v4.24.0/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(cH,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(fH,"href","/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(mH,"href","/docs/transformers/v4.24.0/en/model_doc/luke#transformers.LukeForMaskedLM"),c(gH,"href","/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(hH,"href","/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(uH,"href","/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(pH,"href","/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(_H,"href","/docs/transformers/v4.24.0/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(vH,"href","/docs/transformers/v4.24.0/en/model_doc/nezha#transformers.NezhaForMaskedLM"),c(bH,"href","/docs/transformers/v4.24.0/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(FH,"href","/docs/transformers/v4.24.0/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(TH,"href","/docs/transformers/v4.24.0/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(MH,"href","/docs/transformers/v4.24.0/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(EH,"href","/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(CH,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(wH,"href","/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(AH,"href","/docs/transformers/v4.24.0/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(LH,"href","/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(yH,"href","/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(xH,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c($H,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(kH,"href","/docs/transformers/v4.24.0/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Gb,"id","transformers.AutoModelForSeq2SeqLM"),c(Gb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Gb,"href","#transformers.AutoModelForSeq2SeqLM"),c(Wd,"class","relative group"),c(SH,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(RH,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(PH,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BH,"href","/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(IH,"href","/docs/transformers/v4.24.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(NH,"href","/docs/transformers/v4.24.0/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(qH,"href","/docs/transformers/v4.24.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(jH,"href","/docs/transformers/v4.24.0/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(DH,"href","/docs/transformers/v4.24.0/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(GH,"href","/docs/transformers/v4.24.0/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(OH,"href","/docs/transformers/v4.24.0/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),c(VH,"href","/docs/transformers/v4.24.0/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(XH,"href","/docs/transformers/v4.24.0/en/model_doc/marian#transformers.MarianMTModel"),c(zH,"href","/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(QH,"href","/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(WH,"href","/docs/transformers/v4.24.0/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(UH,"href","/docs/transformers/v4.24.0/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(HH,"href","/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(JH,"href","/docs/transformers/v4.24.0/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration"),c(YH,"href","/docs/transformers/v4.24.0/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(ZH,"href","/docs/transformers/v4.24.0/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(KH,"href","/docs/transformers/v4.24.0/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(eJ,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(f0,"id","transformers.AutoModelForSequenceClassification"),c(f0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(f0,"href","#transformers.AutoModelForSequenceClassification"),c(Jd,"class","relative group"),c(oJ,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rJ,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tJ,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aJ,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(nJ,"href","/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartForSequenceClassification"),c(sJ,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertForSequenceClassification"),c(lJ,"href","/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(iJ,"href","/docs/transformers/v4.24.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(dJ,"href","/docs/transformers/v4.24.0/en/model_doc/bloom#transformers.BloomForSequenceClassification"),c(cJ,"href","/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(fJ,"href","/docs/transformers/v4.24.0/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(mJ,"href","/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(gJ,"href","/docs/transformers/v4.24.0/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(hJ,"href","/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(uJ,"href","/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(pJ,"href","/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(_J,"href","/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(vJ,"href","/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(bJ,"href","/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieForSequenceClassification"),c(FJ,"href","/docs/transformers/v4.24.0/en/model_doc/esm#transformers.EsmForSequenceClassification"),c(TJ,"href","/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(MJ,"href","/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(EJ,"href","/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(CJ,"href","/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(wJ,"href","/docs/transformers/v4.24.0/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(AJ,"href","/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(LJ,"href","/docs/transformers/v4.24.0/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(yJ,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(xJ,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c($J,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(kJ,"href","/docs/transformers/v4.24.0/en/model_doc/led#transformers.LEDForSequenceClassification"),c(SJ,"href","/docs/transformers/v4.24.0/en/model_doc/lilt#transformers.LiltForSequenceClassification"),c(RJ,"href","/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(PJ,"href","/docs/transformers/v4.24.0/en/model_doc/luke#transformers.LukeForSequenceClassification"),c(BJ,"href","/docs/transformers/v4.24.0/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification"),c(IJ,"href","/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(NJ,"href","/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(qJ,"href","/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(jJ,"href","/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(DJ,"href","/docs/transformers/v4.24.0/en/model_doc/mvp#transformers.MvpForSequenceClassification"),c(GJ,"href","/docs/transformers/v4.24.0/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),c(OJ,"href","/docs/transformers/v4.24.0/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(VJ,"href","/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(XJ,"href","/docs/transformers/v4.24.0/en/model_doc/opt#transformers.OPTForSequenceClassification"),c(zJ,"href","/docs/transformers/v4.24.0/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(QJ,"href","/docs/transformers/v4.24.0/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(WJ,"href","/docs/transformers/v4.24.0/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(UJ,"href","/docs/transformers/v4.24.0/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(HJ,"href","/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(JJ,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(YJ,"href","/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(ZJ,"href","/docs/transformers/v4.24.0/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(KJ,"href","/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(eY,"href","/docs/transformers/v4.24.0/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(oY,"href","/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(rY,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(tY,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(aY,"href","/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(nY,"href","/docs/transformers/v4.24.0/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_F,"id","transformers.AutoModelForMultipleChoice"),c(_F,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_F,"href","#transformers.AutoModelForMultipleChoice"),c(Kd,"class","relative group"),c(sY,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lY,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iY,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dY,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(cY,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertForMultipleChoice"),c(fY,"href","/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(mY,"href","/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(gY,"href","/docs/transformers/v4.24.0/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(hY,"href","/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(uY,"href","/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(pY,"href","/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(_Y,"href","/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(vY,"href","/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(bY,"href","/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieForMultipleChoice"),c(FY,"href","/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(TY,"href","/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(MY,"href","/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(EY,"href","/docs/transformers/v4.24.0/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(CY,"href","/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(wY,"href","/docs/transformers/v4.24.0/en/model_doc/luke#transformers.LukeForMultipleChoice"),c(AY,"href","/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(LY,"href","/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(yY,"href","/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(xY,"href","/docs/transformers/v4.24.0/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),c($Y,"href","/docs/transformers/v4.24.0/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(kY,"href","/docs/transformers/v4.24.0/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(SY,"href","/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(RY,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(PY,"href","/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(BY,"href","/docs/transformers/v4.24.0/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(IY,"href","/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(NY,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(qY,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(jY,"href","/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(DY,"href","/docs/transformers/v4.24.0/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KF,"id","transformers.AutoModelForNextSentencePrediction"),c(KF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(KF,"href","#transformers.AutoModelForNextSentencePrediction"),c(rc,"class","relative group"),c(GY,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OY,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VY,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XY,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(zY,"href","/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction"),c(QY,"href","/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(WY,"href","/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(UY,"href","/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(HY,"href","/docs/transformers/v4.24.0/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),c(JY,"href","/docs/transformers/v4.24.0/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cT,"id","transformers.AutoModelForTokenClassification"),c(cT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(cT,"href","#transformers.AutoModelForTokenClassification"),c(nc,"class","relative group"),c(YY,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZY,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(KY,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eZ,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(oZ,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertForTokenClassification"),c(rZ,"href","/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(tZ,"href","/docs/transformers/v4.24.0/en/model_doc/bloom#transformers.BloomForTokenClassification"),c(aZ,"href","/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(nZ,"href","/docs/transformers/v4.24.0/en/model_doc/canine#transformers.CanineForTokenClassification"),c(sZ,"href","/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(lZ,"href","/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(iZ,"href","/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(dZ,"href","/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(cZ,"href","/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(fZ,"href","/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(mZ,"href","/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieForTokenClassification"),c(gZ,"href","/docs/transformers/v4.24.0/en/model_doc/esm#transformers.EsmForTokenClassification"),c(hZ,"href","/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(uZ,"href","/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(pZ,"href","/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(_Z,"href","/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(vZ,"href","/docs/transformers/v4.24.0/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(bZ,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(FZ,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(TZ,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(MZ,"href","/docs/transformers/v4.24.0/en/model_doc/lilt#transformers.LiltForTokenClassification"),c(EZ,"href","/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(CZ,"href","/docs/transformers/v4.24.0/en/model_doc/luke#transformers.LukeForTokenClassification"),c(wZ,"href","/docs/transformers/v4.24.0/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification"),c(AZ,"href","/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(LZ,"href","/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(yZ,"href","/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(xZ,"href","/docs/transformers/v4.24.0/en/model_doc/nezha#transformers.NezhaForTokenClassification"),c($Z,"href","/docs/transformers/v4.24.0/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(kZ,"href","/docs/transformers/v4.24.0/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(SZ,"href","/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(RZ,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(PZ,"href","/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(BZ,"href","/docs/transformers/v4.24.0/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(IZ,"href","/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(NZ,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(qZ,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(jZ,"href","/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(DZ,"href","/docs/transformers/v4.24.0/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oM,"id","transformers.AutoModelForQuestionAnswering"),c(oM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(oM,"href","#transformers.AutoModelForQuestionAnswering"),c(ic,"class","relative group"),c(GZ,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OZ,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VZ,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XZ,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(zZ,"href","/docs/transformers/v4.24.0/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(QZ,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(WZ,"href","/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(UZ,"href","/docs/transformers/v4.24.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(HZ,"href","/docs/transformers/v4.24.0/en/model_doc/bloom#transformers.BloomForQuestionAnswering"),c(JZ,"href","/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(YZ,"href","/docs/transformers/v4.24.0/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(ZZ,"href","/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(KZ,"href","/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(eK,"href","/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(oK,"href","/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(rK,"href","/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(tK,"href","/docs/transformers/v4.24.0/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(aK,"href","/docs/transformers/v4.24.0/en/model_doc/ernie#transformers.ErnieForQuestionAnswering"),c(nK,"href","/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(sK,"href","/docs/transformers/v4.24.0/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(lK,"href","/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(iK,"href","/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(dK,"href","/docs/transformers/v4.24.0/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(cK,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(fK,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(mK,"href","/docs/transformers/v4.24.0/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(gK,"href","/docs/transformers/v4.24.0/en/model_doc/lilt#transformers.LiltForQuestionAnswering"),c(hK,"href","/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(uK,"href","/docs/transformers/v4.24.0/en/model_doc/luke#transformers.LukeForQuestionAnswering"),c(pK,"href","/docs/transformers/v4.24.0/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(_K,"href","/docs/transformers/v4.24.0/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering"),c(vK,"href","/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(bK,"href","/docs/transformers/v4.24.0/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(FK,"href","/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(TK,"href","/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(MK,"href","/docs/transformers/v4.24.0/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),c(EK,"href","/docs/transformers/v4.24.0/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),c(CK,"href","/docs/transformers/v4.24.0/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(wK,"href","/docs/transformers/v4.24.0/en/model_doc/opt#transformers.OPTForQuestionAnswering"),c(AK,"href","/docs/transformers/v4.24.0/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(LK,"href","/docs/transformers/v4.24.0/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(yK,"href","/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(xK,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c($K,"href","/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(kK,"href","/docs/transformers/v4.24.0/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(SK,"href","/docs/transformers/v4.24.0/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(RK,"href","/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(PK,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(BK,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(IK,"href","/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(NK,"href","/docs/transformers/v4.24.0/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KM,"id","transformers.AutoModelForTableQuestionAnswering"),c(KM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(KM,"href","#transformers.AutoModelForTableQuestionAnswering"),c(fc,"class","relative group"),c(qK,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jK,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DK,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GK,"href","/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aE,"id","transformers.AutoModelForDocumentQuestionAnswering"),c(aE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(aE,"href","#transformers.AutoModelForDocumentQuestionAnswering"),c(hc,"class","relative group"),c(OK,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(VK,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(XK,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zK,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering"),c(QK,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(WK,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fE,"id","transformers.AutoModelForImageClassification"),c(fE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(fE,"href","#transformers.AutoModelForImageClassification"),c(vc,"class","relative group"),c(UK,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(HK,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(JK,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YK,"href","/docs/transformers/v4.24.0/en/model_doc/beit#transformers.BeitForImageClassification"),c(ZK,"href","/docs/transformers/v4.24.0/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(KK,"href","/docs/transformers/v4.24.0/en/model_doc/cvt#transformers.CvtForImageClassification"),c(eee,"href","/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(oee,"href","/docs/transformers/v4.24.0/en/model_doc/deit#transformers.DeiTForImageClassification"),c(ree,"href","/docs/transformers/v4.24.0/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(tee,"href","/docs/transformers/v4.24.0/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(aee,"href","/docs/transformers/v4.24.0/en/model_doc/levit#transformers.LevitForImageClassification"),c(nee,"href","/docs/transformers/v4.24.0/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(see,"href","/docs/transformers/v4.24.0/en/model_doc/mobilevit#transformers.MobileViTForImageClassification"),c(lee,"href","/docs/transformers/v4.24.0/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(iee,"href","/docs/transformers/v4.24.0/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(dee,"href","/docs/transformers/v4.24.0/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(cee,"href","/docs/transformers/v4.24.0/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(fee,"href","/docs/transformers/v4.24.0/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(mee,"href","/docs/transformers/v4.24.0/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(gee,"href","/docs/transformers/v4.24.0/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(hee,"href","/docs/transformers/v4.24.0/en/model_doc/swin#transformers.SwinForImageClassification"),c(uee,"href","/docs/transformers/v4.24.0/en/model_doc/swinv2#transformers.Swinv2ForImageClassification"),c(pee,"href","/docs/transformers/v4.24.0/en/model_doc/van#transformers.VanForImageClassification"),c(_ee,"href","/docs/transformers/v4.24.0/en/model_doc/vit#transformers.ViTForImageClassification"),c(vee,"href","/docs/transformers/v4.24.0/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($E,"id","transformers.AutoModelForVideoClassification"),c($E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($E,"href","#transformers.AutoModelForVideoClassification"),c(Tc,"class","relative group"),c(bee,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Fee,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Tee,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mee,"href","/docs/transformers/v4.24.0/en/model_doc/videomae#transformers.VideoMAEForVideoClassification"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BE,"id","transformers.AutoModelForVision2Seq"),c(BE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(BE,"href","#transformers.AutoModelForVision2Seq"),c(Cc,"class","relative group"),c(Eee,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Cee,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wee,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Aee,"href","/docs/transformers/v4.24.0/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DE,"id","transformers.AutoModelForVisualQuestionAnswering"),c(DE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DE,"href","#transformers.AutoModelForVisualQuestionAnswering"),c(Lc,"class","relative group"),c(Lee,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yee,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xee,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($ee,"href","/docs/transformers/v4.24.0/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zE,"id","transformers.AutoModelForAudioClassification"),c(zE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zE,"href","#transformers.AutoModelForAudioClassification"),c($c,"class","relative group"),c(kee,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(See,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Ree,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Pee,"href","/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(Bee,"href","/docs/transformers/v4.24.0/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(Iee,"href","/docs/transformers/v4.24.0/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(Nee,"href","/docs/transformers/v4.24.0/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(qee,"href","/docs/transformers/v4.24.0/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(jee,"href","/docs/transformers/v4.24.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(Dee,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(Gee,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(Oee,"href","/docs/transformers/v4.24.0/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aC,"id","transformers.AutoModelForAudioFrameClassification"),c(aC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(aC,"href","#transformers.AutoModelForAudioFrameClassification"),c(Rc,"class","relative group"),c(Vee,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xee,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zee,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qee,"href","/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(Wee,"href","/docs/transformers/v4.24.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(Uee,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(Hee,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(Jee,"href","/docs/transformers/v4.24.0/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gC,"id","transformers.AutoModelForCTC"),c(gC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(gC,"href","#transformers.AutoModelForCTC"),c(Ic,"class","relative group"),c(Yee,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zee,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Kee,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eoe,"href","/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(ooe,"href","/docs/transformers/v4.24.0/en/model_doc/hubert#transformers.HubertForCTC"),c(roe,"href","/docs/transformers/v4.24.0/en/model_doc/mctct#transformers.MCTCTForCTC"),c(toe,"href","/docs/transformers/v4.24.0/en/model_doc/sew#transformers.SEWForCTC"),c(aoe,"href","/docs/transformers/v4.24.0/en/model_doc/sew-d#transformers.SEWDForCTC"),c(noe,"href","/docs/transformers/v4.24.0/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(soe,"href","/docs/transformers/v4.24.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(loe,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(ioe,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(doe,"href","/docs/transformers/v4.24.0/en/model_doc/wavlm#transformers.WavLMForCTC"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LC,"id","transformers.AutoModelForSpeechSeq2Seq"),c(LC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(LC,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(jc,"class","relative group"),c(coe,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(foe,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(moe,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(goe,"href","/docs/transformers/v4.24.0/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(hoe,"href","/docs/transformers/v4.24.0/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(uoe,"href","/docs/transformers/v4.24.0/en/model_doc/whisper#transformers.WhisperForConditionalGeneration"),c(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PC,"id","transformers.AutoModelForAudioXVector"),c(PC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(PC,"href","#transformers.AutoModelForAudioXVector"),c(Vc,"class","relative group"),c(poe,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_oe,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(voe,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(boe,"href","/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(Foe,"href","/docs/transformers/v4.24.0/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(Toe,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(Moe,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(Eoe,"href","/docs/transformers/v4.24.0/en/model_doc/wavlm#transformers.WavLMForXVector"),c(To,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(VC,"id","transformers.AutoModelForMaskedImageModeling"),c(VC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(VC,"href","#transformers.AutoModelForMaskedImageModeling"),c(Qc,"class","relative group"),c(Coe,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(woe,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Aoe,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Loe,"href","/docs/transformers/v4.24.0/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(yoe,"href","/docs/transformers/v4.24.0/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(xoe,"href","/docs/transformers/v4.24.0/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling"),c($oe,"href","/docs/transformers/v4.24.0/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(Mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YC,"id","transformers.AutoModelForObjectDetection"),c(YC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(YC,"href","#transformers.AutoModelForObjectDetection"),c(Hc,"class","relative group"),c(koe,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Soe,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Roe,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Poe,"href","/docs/transformers/v4.24.0/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection"),c(Boe,"href","/docs/transformers/v4.24.0/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection"),c(Ioe,"href","/docs/transformers/v4.24.0/en/model_doc/detr#transformers.DetrForObjectDetection"),c(Noe,"href","/docs/transformers/v4.24.0/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection"),c(qoe,"href","/docs/transformers/v4.24.0/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(Eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(s3,"id","transformers.AutoModelForImageSegmentation"),c(s3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(s3,"href","#transformers.AutoModelForImageSegmentation"),c(Zc,"class","relative group"),c(joe,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Doe,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Goe,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ooe,"href","/docs/transformers/v4.24.0/en/model_doc/detr#transformers.DetrForSegmentation"),c(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(f3,"id","transformers.AutoModelForSemanticSegmentation"),c(f3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(f3,"href","#transformers.AutoModelForSemanticSegmentation"),c(of,"class","relative group"),c(Voe,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xoe,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zoe,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qoe,"href","/docs/transformers/v4.24.0/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(Woe,"href","/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(Uoe,"href","/docs/transformers/v4.24.0/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(Hoe,"href","/docs/transformers/v4.24.0/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation"),c(Joe,"href","/docs/transformers/v4.24.0/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(F3,"id","transformers.AutoModelForInstanceSegmentation"),c(F3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(F3,"href","#transformers.AutoModelForInstanceSegmentation"),c(af,"class","relative group"),c(Yoe,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zoe,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Koe,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ere,"href","/docs/transformers/v4.24.0/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(w3,"id","transformers.AutoModelForZeroShotObjectDetection"),c(w3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(w3,"href","#transformers.AutoModelForZeroShotObjectDetection"),c(lf,"class","relative group"),c(ore,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rre,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tre,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(are,"href","/docs/transformers/v4.24.0/en/model_doc/owlvit#transformers.OwlViTForObjectDetection"),c(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($3,"id","transformers.TFAutoModel"),c($3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($3,"href","#transformers.TFAutoModel"),c(ff,"class","relative group"),c(nre,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sre,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lre,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ire,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.TFAlbertModel"),c(dre,"href","/docs/transformers/v4.24.0/en/model_doc/bart#transformers.TFBartModel"),c(cre,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.TFBertModel"),c(fre,"href","/docs/transformers/v4.24.0/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(mre,"href","/docs/transformers/v4.24.0/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(gre,"href","/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.TFCamembertModel"),c(hre,"href","/docs/transformers/v4.24.0/en/model_doc/clip#transformers.TFCLIPModel"),c(ure,"href","/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.TFConvBertModel"),c(pre,"href","/docs/transformers/v4.24.0/en/model_doc/convnext#transformers.TFConvNextModel"),c(_re,"href","/docs/transformers/v4.24.0/en/model_doc/ctrl#transformers.TFCTRLModel"),c(vre,"href","/docs/transformers/v4.24.0/en/model_doc/cvt#transformers.TFCvtModel"),c(bre,"href","/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(Fre,"href","/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.TFDebertaModel"),c(Tre,"href","/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(Mre,"href","/docs/transformers/v4.24.0/en/model_doc/deit#transformers.TFDeiTModel"),c(Ere,"href","/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(Cre,"href","/docs/transformers/v4.24.0/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(wre,"href","/docs/transformers/v4.24.0/en/model_doc/electra#transformers.TFElectraModel"),c(Are,"href","/docs/transformers/v4.24.0/en/model_doc/esm#transformers.TFEsmModel"),c(Lre,"href","/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(yre,"href","/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.TFFunnelModel"),c(xre,"href","/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c($re,"href","/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.TFGPT2Model"),c(kre,"href","/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.TFGPTJModel"),c(Sre,"href","/docs/transformers/v4.24.0/en/model_doc/groupvit#transformers.TFGroupViTModel"),c(Rre,"href","/docs/transformers/v4.24.0/en/model_doc/hubert#transformers.TFHubertModel"),c(Pre,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(Bre,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model"),c(Ire,"href","/docs/transformers/v4.24.0/en/model_doc/led#transformers.TFLEDModel"),c(Nre,"href","/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.TFLongformerModel"),c(qre,"href","/docs/transformers/v4.24.0/en/model_doc/lxmert#transformers.TFLxmertModel"),c(jre,"href","/docs/transformers/v4.24.0/en/model_doc/marian#transformers.TFMarianModel"),c(Dre,"href","/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.TFMBartModel"),c(Gre,"href","/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(Ore,"href","/docs/transformers/v4.24.0/en/model_doc/mobilevit#transformers.TFMobileViTModel"),c(Vre,"href","/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.TFMPNetModel"),c(Xre,"href","/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.TFMT5Model"),c(zre,"href","/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(Qre,"href","/docs/transformers/v4.24.0/en/model_doc/opt#transformers.TFOPTModel"),c(Wre,"href","/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.TFPegasusModel"),c(Ure,"href","/docs/transformers/v4.24.0/en/model_doc/regnet#transformers.TFRegNetModel"),c(Hre,"href","/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.TFRemBertModel"),c(Jre,"href","/docs/transformers/v4.24.0/en/model_doc/resnet#transformers.TFResNetModel"),c(Yre,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.TFRobertaModel"),c(Zre,"href","/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.TFRoFormerModel"),c(Kre,"href","/docs/transformers/v4.24.0/en/model_doc/segformer#transformers.TFSegformerModel"),c(ete,"href","/docs/transformers/v4.24.0/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(ote,"href","/docs/transformers/v4.24.0/en/model_doc/swin#transformers.TFSwinModel"),c(rte,"href","/docs/transformers/v4.24.0/en/model_doc/t5#transformers.TFT5Model"),c(tte,"href","/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TFTapasModel"),c(ate,"href","/docs/transformers/v4.24.0/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(nte,"href","/docs/transformers/v4.24.0/en/model_doc/vit#transformers.TFViTModel"),c(ste,"href","/docs/transformers/v4.24.0/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(lte,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(ite,"href","/docs/transformers/v4.24.0/en/model_doc/whisper#transformers.TFWhisperModel"),c(dte,"href","/docs/transformers/v4.24.0/en/model_doc/xglm#transformers.TFXGLMModel"),c(cte,"href","/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.TFXLMModel"),c(fte,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(mte,"href","/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.TFXLNetModel"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(I5,"id","transformers.TFAutoModelForPreTraining"),c(I5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(I5,"href","#transformers.TFAutoModelForPreTraining"),c(hf,"class","relative group"),c(gte,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hte,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ute,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pte,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(_te,"href","/docs/transformers/v4.24.0/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(vte,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.TFBertForPreTraining"),c(bte,"href","/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(Fte,"href","/docs/transformers/v4.24.0/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(Tte,"href","/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(Mte,"href","/docs/transformers/v4.24.0/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(Ete,"href","/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(Cte,"href","/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(wte,"href","/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(Ate,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(Lte,"href","/docs/transformers/v4.24.0/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(yte,"href","/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(xte,"href","/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c($te,"href","/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(kte,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(Ste,"href","/docs/transformers/v4.24.0/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Rte,"href","/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(Pte,"href","/docs/transformers/v4.24.0/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(Bte,"href","/docs/transformers/v4.24.0/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(Ite,"href","/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(Nte,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(qte,"href","/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iw,"id","transformers.TFAutoModelForCausalLM"),c(iw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(iw,"href","#transformers.TFAutoModelForCausalLM"),c(_f,"class","relative group"),c(jte,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dte,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Gte,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ote,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(Vte,"href","/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(Xte,"href","/docs/transformers/v4.24.0/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(zte,"href","/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(Qte,"href","/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(Wte,"href","/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(Ute,"href","/docs/transformers/v4.24.0/en/model_doc/opt#transformers.TFOPTForCausalLM"),c(Hte,"href","/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(Jte,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(Yte,"href","/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(Zte,"href","/docs/transformers/v4.24.0/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(Kte,"href","/docs/transformers/v4.24.0/en/model_doc/xglm#transformers.TFXGLMForCausalLM"),c(eae,"href","/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(oae,"href","/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ww,"id","transformers.TFAutoModelForImageClassification"),c(ww,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ww,"href","#transformers.TFAutoModelForImageClassification"),c(Ff,"class","relative group"),c(rae,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tae,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(aae,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nae,"href","/docs/transformers/v4.24.0/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(sae,"href","/docs/transformers/v4.24.0/en/model_doc/cvt#transformers.TFCvtForImageClassification"),c(lae,"href","/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(iae,"href","/docs/transformers/v4.24.0/en/model_doc/deit#transformers.TFDeiTForImageClassification"),c(dae,"href","/docs/transformers/v4.24.0/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher"),c(cae,"href","/docs/transformers/v4.24.0/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification"),c(fae,"href","/docs/transformers/v4.24.0/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),c(mae,"href","/docs/transformers/v4.24.0/en/model_doc/resnet#transformers.TFResNetForImageClassification"),c(gae,"href","/docs/transformers/v4.24.0/en/model_doc/segformer#transformers.TFSegformerForImageClassification"),c(hae,"href","/docs/transformers/v4.24.0/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(uae,"href","/docs/transformers/v4.24.0/en/model_doc/vit#transformers.TFViTForImageClassification"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Nw,"id","transformers.TFAutoModelForSemanticSegmentation"),c(Nw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Nw,"href","#transformers.TFAutoModelForSemanticSegmentation"),c(Ef,"class","relative group"),c(pae,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_ae,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vae,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bae,"href","/docs/transformers/v4.24.0/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation"),c(Fae,"href","/docs/transformers/v4.24.0/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation"),c(Tae,"href","/docs/transformers/v4.24.0/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vw,"id","transformers.TFAutoModelForMaskedLM"),c(Vw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Vw,"href","#transformers.TFAutoModelForMaskedLM"),c(Lf,"class","relative group"),c(Mae,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Eae,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Cae,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wae,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(Aae,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(Lae,"href","/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(yae,"href","/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(xae,"href","/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c($ae,"href","/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(kae,"href","/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(Sae,"href","/docs/transformers/v4.24.0/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(Rae,"href","/docs/transformers/v4.24.0/en/model_doc/esm#transformers.TFEsmForMaskedLM"),c(Pae,"href","/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(Bae,"href","/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(Iae,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(Nae,"href","/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(qae,"href","/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(jae,"href","/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(Dae,"href","/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(Gae,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(Oae,"href","/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(Vae,"href","/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(Xae,"href","/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(zae,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gA,"id","transformers.TFAutoModelForSeq2SeqLM"),c(gA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(gA,"href","#transformers.TFAutoModelForSeq2SeqLM"),c($f,"class","relative group"),c(Qae,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wae,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Uae,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Hae,"href","/docs/transformers/v4.24.0/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(Jae,"href","/docs/transformers/v4.24.0/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(Yae,"href","/docs/transformers/v4.24.0/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(Zae,"href","/docs/transformers/v4.24.0/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(Kae,"href","/docs/transformers/v4.24.0/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(ene,"href","/docs/transformers/v4.24.0/en/model_doc/marian#transformers.TFMarianMTModel"),c(one,"href","/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(rne,"href","/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(tne,"href","/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(ane,"href","/docs/transformers/v4.24.0/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AA,"id","transformers.TFAutoModelForSequenceClassification"),c(AA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(AA,"href","#transformers.TFAutoModelForSequenceClassification"),c(Rf,"class","relative group"),c(nne,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sne,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lne,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ine,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(dne,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(cne,"href","/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(fne,"href","/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(mne,"href","/docs/transformers/v4.24.0/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(gne,"href","/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(hne,"href","/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(une,"href","/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(pne,"href","/docs/transformers/v4.24.0/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(_ne,"href","/docs/transformers/v4.24.0/en/model_doc/esm#transformers.TFEsmForSequenceClassification"),c(vne,"href","/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(bne,"href","/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(Fne,"href","/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(Tne,"href","/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(Mne,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(Ene,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification"),c(Cne,"href","/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(wne,"href","/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(Ane,"href","/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(Lne,"href","/docs/transformers/v4.24.0/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(yne,"href","/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(xne,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c($ne,"href","/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(kne,"href","/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(Sne,"href","/docs/transformers/v4.24.0/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(Rne,"href","/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(Pne,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(Bne,"href","/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(t6,"id","transformers.TFAutoModelForMultipleChoice"),c(t6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(t6,"href","#transformers.TFAutoModelForMultipleChoice"),c(If,"class","relative group"),c(Ine,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nne,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(qne,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(na,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jne,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(Dne,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(Gne,"href","/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(One,"href","/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(Vne,"href","/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(Xne,"href","/docs/transformers/v4.24.0/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(zne,"href","/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(Qne,"href","/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(Wne,"href","/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(Une,"href","/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(Hne,"href","/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(Jne,"href","/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(Yne,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(Zne,"href","/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(Kne,"href","/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(ese,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(ose,"href","/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(E6,"id","transformers.TFAutoModelForNextSentencePrediction"),c(E6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(E6,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(jf,"class","relative group"),c(rse,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tse,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ase,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nse,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(sse,"href","/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(y6,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(y6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(y6,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(Of,"class","relative group"),c(lse,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ise,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(dse,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(la,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cse,"href","/docs/transformers/v4.24.0/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(S6,"id","transformers.TFAutoModelForDocumentQuestionAnswering"),c(S6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(S6,"href","#transformers.TFAutoModelForDocumentQuestionAnswering"),c(zf,"class","relative group"),c(fse,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mse,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gse,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ia,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hse,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering"),c(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(I6,"id","transformers.TFAutoModelForTokenClassification"),c(I6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(I6,"href","#transformers.TFAutoModelForTokenClassification"),c(Uf,"class","relative group"),c(use,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pse,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_se,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(da,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vse,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(bse,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(Fse,"href","/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(Tse,"href","/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(Mse,"href","/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(Ese,"href","/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(Cse,"href","/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(wse,"href","/docs/transformers/v4.24.0/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(Ase,"href","/docs/transformers/v4.24.0/en/model_doc/esm#transformers.TFEsmForTokenClassification"),c(Lse,"href","/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(yse,"href","/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(xse,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c($se,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification"),c(kse,"href","/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(Sse,"href","/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(Rse,"href","/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(Pse,"href","/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(Bse,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(Ise,"href","/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(Nse,"href","/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(qse,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(jse,"href","/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(l7,"id","transformers.TFAutoModelForQuestionAnswering"),c(l7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(l7,"href","#transformers.TFAutoModelForQuestionAnswering"),c(Yf,"class","relative group"),c(Dse,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gse,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Ose,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vse,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(Xse,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(zse,"href","/docs/transformers/v4.24.0/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(Qse,"href","/docs/transformers/v4.24.0/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(Wse,"href","/docs/transformers/v4.24.0/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(Use,"href","/docs/transformers/v4.24.0/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(Hse,"href","/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(Jse,"href","/docs/transformers/v4.24.0/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(Yse,"href","/docs/transformers/v4.24.0/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(Zse,"href","/docs/transformers/v4.24.0/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(Kse,"href","/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(ele,"href","/docs/transformers/v4.24.0/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering"),c(ole,"href","/docs/transformers/v4.24.0/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(rle,"href","/docs/transformers/v4.24.0/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(tle,"href","/docs/transformers/v4.24.0/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(ale,"href","/docs/transformers/v4.24.0/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(nle,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(sle,"href","/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(lle,"href","/docs/transformers/v4.24.0/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(ile,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(dle,"href","/docs/transformers/v4.24.0/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(k7,"id","transformers.TFAutoModelForVision2Seq"),c(k7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(k7,"href","#transformers.TFAutoModelForVision2Seq"),c(em,"class","relative group"),c(cle,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fle,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(mle,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gle,"href","/docs/transformers/v4.24.0/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(B7,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(B7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(B7,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(tm,"class","relative group"),c(hle,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ule,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ple,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_le,"href","/docs/transformers/v4.24.0/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(vle,"href","/docs/transformers/v4.24.0/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration"),c(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(D7,"id","transformers.FlaxAutoModel"),c(D7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(D7,"href","#transformers.FlaxAutoModel"),c(sm,"class","relative group"),c(ble,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Fle,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Tle,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ga,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mle,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.FlaxAlbertModel"),c(Ele,"href","/docs/transformers/v4.24.0/en/model_doc/bart#transformers.FlaxBartModel"),c(Cle,"href","/docs/transformers/v4.24.0/en/model_doc/beit#transformers.FlaxBeitModel"),c(wle,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.FlaxBertModel"),c(Ale,"href","/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(Lle,"href","/docs/transformers/v4.24.0/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(yle,"href","/docs/transformers/v4.24.0/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(xle,"href","/docs/transformers/v4.24.0/en/model_doc/clip#transformers.FlaxCLIPModel"),c($le,"href","/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(kle,"href","/docs/transformers/v4.24.0/en/model_doc/electra#transformers.FlaxElectraModel"),c(Sle,"href","/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(Rle,"href","/docs/transformers/v4.24.0/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(Ple,"href","/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(Ble,"href","/docs/transformers/v4.24.0/en/model_doc/longt5#transformers.FlaxLongT5Model"),c(Ile,"href","/docs/transformers/v4.24.0/en/model_doc/marian#transformers.FlaxMarianModel"),c(Nle,"href","/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.FlaxMBartModel"),c(qle,"href","/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.FlaxMT5Model"),c(jle,"href","/docs/transformers/v4.24.0/en/model_doc/opt#transformers.FlaxOPTModel"),c(Dle,"href","/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(Gle,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(Ole,"href","/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(Vle,"href","/docs/transformers/v4.24.0/en/model_doc/t5#transformers.FlaxT5Model"),c(Xle,"href","/docs/transformers/v4.24.0/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(zle,"href","/docs/transformers/v4.24.0/en/model_doc/vit#transformers.FlaxViTModel"),c(Qle,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(Wle,"href","/docs/transformers/v4.24.0/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(Ule,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(p8,"id","transformers.FlaxAutoModelForCausalLM"),c(p8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(p8,"href","#transformers.FlaxAutoModelForCausalLM"),c(dm,"class","relative group"),c(Hle,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jle,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Yle,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ha,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zle,"href","/docs/transformers/v4.24.0/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(Kle,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(eie,"href","/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(oie,"href","/docs/transformers/v4.24.0/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(rie,"href","/docs/transformers/v4.24.0/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(tie,"href","/docs/transformers/v4.24.0/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(aie,"href","/docs/transformers/v4.24.0/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(nie,"href","/docs/transformers/v4.24.0/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(sie,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(lie,"href","/docs/transformers/v4.24.0/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(x8,"id","transformers.FlaxAutoModelForPreTraining"),c(x8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(x8,"href","#transformers.FlaxAutoModelForPreTraining"),c(mm,"class","relative group"),c(iie,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(die,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cie,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ua,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fie,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(mie,"href","/docs/transformers/v4.24.0/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(gie,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(hie,"href","/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(uie,"href","/docs/transformers/v4.24.0/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(pie,"href","/docs/transformers/v4.24.0/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(_ie,"href","/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(vie,"href","/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(bie,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(Fie,"href","/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(Tie,"href","/docs/transformers/v4.24.0/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Mie,"href","/docs/transformers/v4.24.0/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(Eie,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(z8,"id","transformers.FlaxAutoModelForMaskedLM"),c(z8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(z8,"href","#transformers.FlaxAutoModelForMaskedLM"),c(um,"class","relative group"),c(Cie,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wie,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Aie,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lie,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(yie,"href","/docs/transformers/v4.24.0/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(xie,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c($ie,"href","/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(kie,"href","/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(Sie,"href","/docs/transformers/v4.24.0/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(Rie,"href","/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(Pie,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(Bie,"href","/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(Iie,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aL,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(aL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(aL,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(vm,"class","relative group"),c(Nie,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qie,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jie,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_a,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Die,"href","/docs/transformers/v4.24.0/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(Gie,"href","/docs/transformers/v4.24.0/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(Oie,"href","/docs/transformers/v4.24.0/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(Vie,"href","/docs/transformers/v4.24.0/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(Xie,"href","/docs/transformers/v4.24.0/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(zie,"href","/docs/transformers/v4.24.0/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(Qie,"href","/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(Wie,"href","/docs/transformers/v4.24.0/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(Uie,"href","/docs/transformers/v4.24.0/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(Hie,"href","/docs/transformers/v4.24.0/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_L,"id","transformers.FlaxAutoModelForSequenceClassification"),c(_L,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_L,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(Tm,"class","relative group"),c(Jie,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yie,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Zie,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(va,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Kie,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(ede,"href","/docs/transformers/v4.24.0/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(ode,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(rde,"href","/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(tde,"href","/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(ade,"href","/docs/transformers/v4.24.0/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(nde,"href","/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(sde,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(lde,"href","/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(ide,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($L,"id","transformers.FlaxAutoModelForQuestionAnswering"),c($L,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($L,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(Cm,"class","relative group"),c(dde,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(cde,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(fde,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ba,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mde,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(gde,"href","/docs/transformers/v4.24.0/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(hde,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(ude,"href","/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(pde,"href","/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(_de,"href","/docs/transformers/v4.24.0/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(vde,"href","/docs/transformers/v4.24.0/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(bde,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(Fde,"href","/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(Tde,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(VL,"id","transformers.FlaxAutoModelForTokenClassification"),c(VL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(VL,"href","#transformers.FlaxAutoModelForTokenClassification"),c(Lm,"class","relative group"),c(Mde,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ede,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Cde,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wde,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(Ade,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(Lde,"href","/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(yde,"href","/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(xde,"href","/docs/transformers/v4.24.0/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c($de,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(kde,"href","/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(Sde,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ey,"id","transformers.FlaxAutoModelForMultipleChoice"),c(ey,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ey,"href","#transformers.FlaxAutoModelForMultipleChoice"),c($m,"class","relative group"),c(Rde,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pde,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Bde,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ide,"href","/docs/transformers/v4.24.0/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(Nde,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(qde,"href","/docs/transformers/v4.24.0/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(jde,"href","/docs/transformers/v4.24.0/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(Dde,"href","/docs/transformers/v4.24.0/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(Gde,"href","/docs/transformers/v4.24.0/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(Ode,"href","/docs/transformers/v4.24.0/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(Vde,"href","/docs/transformers/v4.24.0/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fy,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(fy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(fy,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(Rm,"class","relative group"),c(Xde,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zde,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Qde,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wde,"href","/docs/transformers/v4.24.0/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uy,"id","transformers.FlaxAutoModelForImageClassification"),c(uy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(uy,"href","#transformers.FlaxAutoModelForImageClassification"),c(Im,"class","relative group"),c(Ude,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Hde,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Jde,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yde,"href","/docs/transformers/v4.24.0/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(Zde,"href","/docs/transformers/v4.24.0/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fy,"id","transformers.FlaxAutoModelForVision2Seq"),c(Fy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Fy,"href","#transformers.FlaxAutoModelForVision2Seq"),c(jm,"class","relative group"),c(Kde,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ece,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oce,"href","/docs/transformers/v4.24.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rce,"href","/docs/transformers/v4.24.0/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,_){e(document.head,g),v(f,b,_),v(f,u,_),e(u,m),e(m,p),M(d,p,null),e(u,h),e(u,$o),e($o,vd),v(f,zm,_),v(f,Tt,_),e(Tt,bd),e(Tt,Fd),e(Fd,n$),e(Tt,Qm),v(f,Xe,_),v(f,He,_),e(He,Td),e(He,cs),e(cs,s$),e(He,fs),e(He,ms),e(ms,l$),e(He,Md),e(He,gs),e(gs,i$),e(He,Ed),v(f,Wm,_),M(on,f,_),v(f,Je,_),v(f,Ae,_),e(Ae,MN),e(Ae,Cd),e(Cd,EN),e(Ae,CN),v(f,ko,_),v(f,rn,_),e(rn,wN),e(rn,Um),e(Um,AN),e(rn,cio),v(f,wto,_),v(f,wd,_),e(wd,Hm),e(Hm,fme),M(d$,fme,null),e(wd,fio),e(wd,mme),e(mme,mio),v(f,Ato,_),v(f,hs,_),e(hs,gio),e(hs,gme),e(gme,hio),e(hs,uio),e(hs,hme),e(hme,pio),e(hs,_io),v(f,Lto,_),M(c$,f,_),v(f,yto,_),v(f,LN,_),e(LN,vio),v(f,xto,_),M(Jm,f,_),v(f,$to,_),v(f,Ad,_),e(Ad,Ym),e(Ym,ume),M(f$,ume,null),e(Ad,bio),e(Ad,pme),e(pme,Fio),v(f,kto,_),v(f,So,_),M(m$,So,null),e(So,Tio),e(So,g$),e(g$,Mio),e(g$,yN),e(yN,Eio),e(g$,Cio),e(So,wio),e(So,h$),e(h$,Aio),e(h$,_me),e(_me,Lio),e(h$,yio),e(So,xio),e(So,qr),M(u$,qr,null),e(qr,$io),e(qr,vme),e(vme,kio),e(qr,Sio),e(qr,Ld),e(Ld,Rio),e(Ld,bme),e(bme,Pio),e(Ld,Bio),e(Ld,Fme),e(Fme,Iio),e(Ld,Nio),e(qr,qio),e(qr,A),e(A,Zm),e(Zm,Tme),e(Tme,jio),e(Zm,Dio),e(Zm,xN),e(xN,Gio),e(Zm,Oio),e(A,Vio),e(A,Km),e(Km,Mme),e(Mme,Xio),e(Km,zio),e(Km,$N),e($N,Qio),e(Km,Wio),e(A,Uio),e(A,eg),e(eg,Eme),e(Eme,Hio),e(eg,Jio),e(eg,kN),e(kN,Yio),e(eg,Zio),e(A,Kio),e(A,og),e(og,Cme),e(Cme,edo),e(og,odo),e(og,SN),e(SN,rdo),e(og,tdo),e(A,ado),e(A,rg),e(rg,wme),e(wme,ndo),e(rg,sdo),e(rg,RN),e(RN,ldo),e(rg,ido),e(A,ddo),e(A,tg),e(tg,Ame),e(Ame,cdo),e(tg,fdo),e(tg,PN),e(PN,mdo),e(tg,gdo),e(A,hdo),e(A,ag),e(ag,Lme),e(Lme,udo),e(ag,pdo),e(ag,BN),e(BN,_do),e(ag,vdo),e(A,bdo),e(A,ng),e(ng,yme),e(yme,Fdo),e(ng,Tdo),e(ng,IN),e(IN,Mdo),e(ng,Edo),e(A,Cdo),e(A,sg),e(sg,xme),e(xme,wdo),e(sg,Ado),e(sg,NN),e(NN,Ldo),e(sg,ydo),e(A,xdo),e(A,lg),e(lg,$me),e($me,$do),e(lg,kdo),e(lg,qN),e(qN,Sdo),e(lg,Rdo),e(A,Pdo),e(A,ig),e(ig,kme),e(kme,Bdo),e(ig,Ido),e(ig,jN),e(jN,Ndo),e(ig,qdo),e(A,jdo),e(A,dg),e(dg,Sme),e(Sme,Ddo),e(dg,Gdo),e(dg,DN),e(DN,Odo),e(dg,Vdo),e(A,Xdo),e(A,cg),e(cg,Rme),e(Rme,zdo),e(cg,Qdo),e(cg,GN),e(GN,Wdo),e(cg,Udo),e(A,Hdo),e(A,fg),e(fg,Pme),e(Pme,Jdo),e(fg,Ydo),e(fg,ON),e(ON,Zdo),e(fg,Kdo),e(A,eco),e(A,mg),e(mg,Bme),e(Bme,oco),e(mg,rco),e(mg,VN),e(VN,tco),e(mg,aco),e(A,nco),e(A,gg),e(gg,Ime),e(Ime,sco),e(gg,lco),e(gg,XN),e(XN,ico),e(gg,dco),e(A,cco),e(A,hg),e(hg,Nme),e(Nme,fco),e(hg,mco),e(hg,zN),e(zN,gco),e(hg,hco),e(A,uco),e(A,ug),e(ug,qme),e(qme,pco),e(ug,_co),e(ug,QN),e(QN,vco),e(ug,bco),e(A,Fco),e(A,pg),e(pg,jme),e(jme,Tco),e(pg,Mco),e(pg,WN),e(WN,Eco),e(pg,Cco),e(A,wco),e(A,_g),e(_g,Dme),e(Dme,Aco),e(_g,Lco),e(_g,UN),e(UN,yco),e(_g,xco),e(A,$co),e(A,vg),e(vg,Gme),e(Gme,kco),e(vg,Sco),e(vg,HN),e(HN,Rco),e(vg,Pco),e(A,Bco),e(A,bg),e(bg,Ome),e(Ome,Ico),e(bg,Nco),e(bg,JN),e(JN,qco),e(bg,jco),e(A,Dco),e(A,Fg),e(Fg,Vme),e(Vme,Gco),e(Fg,Oco),e(Fg,YN),e(YN,Vco),e(Fg,Xco),e(A,zco),e(A,Tg),e(Tg,Xme),e(Xme,Qco),e(Tg,Wco),e(Tg,ZN),e(ZN,Uco),e(Tg,Hco),e(A,Jco),e(A,Mg),e(Mg,zme),e(zme,Yco),e(Mg,Zco),e(Mg,KN),e(KN,Kco),e(Mg,efo),e(A,ofo),e(A,Eg),e(Eg,Qme),e(Qme,rfo),e(Eg,tfo),e(Eg,eq),e(eq,afo),e(Eg,nfo),e(A,sfo),e(A,Cg),e(Cg,Wme),e(Wme,lfo),e(Cg,ifo),e(Cg,oq),e(oq,dfo),e(Cg,cfo),e(A,ffo),e(A,wg),e(wg,Ume),e(Ume,mfo),e(wg,gfo),e(wg,rq),e(rq,hfo),e(wg,ufo),e(A,pfo),e(A,Ag),e(Ag,Hme),e(Hme,_fo),e(Ag,vfo),e(Ag,tq),e(tq,bfo),e(Ag,Ffo),e(A,Tfo),e(A,Lg),e(Lg,Jme),e(Jme,Mfo),e(Lg,Efo),e(Lg,aq),e(aq,Cfo),e(Lg,wfo),e(A,Afo),e(A,yg),e(yg,Yme),e(Yme,Lfo),e(yg,yfo),e(yg,nq),e(nq,xfo),e(yg,$fo),e(A,kfo),e(A,xg),e(xg,Zme),e(Zme,Sfo),e(xg,Rfo),e(xg,sq),e(sq,Pfo),e(xg,Bfo),e(A,Ifo),e(A,$g),e($g,Kme),e(Kme,Nfo),e($g,qfo),e($g,lq),e(lq,jfo),e($g,Dfo),e(A,Gfo),e(A,kg),e(kg,ege),e(ege,Ofo),e(kg,Vfo),e(kg,iq),e(iq,Xfo),e(kg,zfo),e(A,Qfo),e(A,Sg),e(Sg,oge),e(oge,Wfo),e(Sg,Ufo),e(Sg,dq),e(dq,Hfo),e(Sg,Jfo),e(A,Yfo),e(A,Rg),e(Rg,rge),e(rge,Zfo),e(Rg,Kfo),e(Rg,cq),e(cq,emo),e(Rg,omo),e(A,rmo),e(A,Pg),e(Pg,tge),e(tge,tmo),e(Pg,amo),e(Pg,fq),e(fq,nmo),e(Pg,smo),e(A,lmo),e(A,Bg),e(Bg,age),e(age,imo),e(Bg,dmo),e(Bg,mq),e(mq,cmo),e(Bg,fmo),e(A,mmo),e(A,Ig),e(Ig,nge),e(nge,gmo),e(Ig,hmo),e(Ig,gq),e(gq,umo),e(Ig,pmo),e(A,_mo),e(A,Ng),e(Ng,sge),e(sge,vmo),e(Ng,bmo),e(Ng,hq),e(hq,Fmo),e(Ng,Tmo),e(A,Mmo),e(A,qg),e(qg,lge),e(lge,Emo),e(qg,Cmo),e(qg,uq),e(uq,wmo),e(qg,Amo),e(A,Lmo),e(A,jg),e(jg,ige),e(ige,ymo),e(jg,xmo),e(jg,pq),e(pq,$mo),e(jg,kmo),e(A,Smo),e(A,Dg),e(Dg,dge),e(dge,Rmo),e(Dg,Pmo),e(Dg,_q),e(_q,Bmo),e(Dg,Imo),e(A,Nmo),e(A,Gg),e(Gg,cge),e(cge,qmo),e(Gg,jmo),e(Gg,vq),e(vq,Dmo),e(Gg,Gmo),e(A,Omo),e(A,Og),e(Og,fge),e(fge,Vmo),e(Og,Xmo),e(Og,bq),e(bq,zmo),e(Og,Qmo),e(A,Wmo),e(A,Vg),e(Vg,mge),e(mge,Umo),e(Vg,Hmo),e(Vg,Fq),e(Fq,Jmo),e(Vg,Ymo),e(A,Zmo),e(A,Xg),e(Xg,gge),e(gge,Kmo),e(Xg,ego),e(Xg,Tq),e(Tq,ogo),e(Xg,rgo),e(A,tgo),e(A,zg),e(zg,hge),e(hge,ago),e(zg,ngo),e(zg,Mq),e(Mq,sgo),e(zg,lgo),e(A,igo),e(A,Qg),e(Qg,uge),e(uge,dgo),e(Qg,cgo),e(Qg,Eq),e(Eq,fgo),e(Qg,mgo),e(A,ggo),e(A,Wg),e(Wg,pge),e(pge,hgo),e(Wg,ugo),e(Wg,Cq),e(Cq,pgo),e(Wg,_go),e(A,vgo),e(A,Ug),e(Ug,_ge),e(_ge,bgo),e(Ug,Fgo),e(Ug,wq),e(wq,Tgo),e(Ug,Mgo),e(A,Ego),e(A,Hg),e(Hg,vge),e(vge,Cgo),e(Hg,wgo),e(Hg,Aq),e(Aq,Ago),e(Hg,Lgo),e(A,ygo),e(A,Jg),e(Jg,bge),e(bge,xgo),e(Jg,$go),e(Jg,Lq),e(Lq,kgo),e(Jg,Sgo),e(A,Rgo),e(A,Yg),e(Yg,Fge),e(Fge,Pgo),e(Yg,Bgo),e(Yg,yq),e(yq,Igo),e(Yg,Ngo),e(A,qgo),e(A,Zg),e(Zg,Tge),e(Tge,jgo),e(Zg,Dgo),e(Zg,xq),e(xq,Ggo),e(Zg,Ogo),e(A,Vgo),e(A,Kg),e(Kg,Mge),e(Mge,Xgo),e(Kg,zgo),e(Kg,$q),e($q,Qgo),e(Kg,Wgo),e(A,Ugo),e(A,eh),e(eh,Ege),e(Ege,Hgo),e(eh,Jgo),e(eh,kq),e(kq,Ygo),e(eh,Zgo),e(A,Kgo),e(A,oh),e(oh,Cge),e(Cge,eho),e(oh,oho),e(oh,Sq),e(Sq,rho),e(oh,tho),e(A,aho),e(A,rh),e(rh,wge),e(wge,nho),e(rh,sho),e(rh,Rq),e(Rq,lho),e(rh,iho),e(A,dho),e(A,th),e(th,Age),e(Age,cho),e(th,fho),e(th,Pq),e(Pq,mho),e(th,gho),e(A,hho),e(A,ah),e(ah,Lge),e(Lge,uho),e(ah,pho),e(ah,Bq),e(Bq,_ho),e(ah,vho),e(A,bho),e(A,nh),e(nh,yge),e(yge,Fho),e(nh,Tho),e(nh,Iq),e(Iq,Mho),e(nh,Eho),e(A,Cho),e(A,sh),e(sh,xge),e(xge,who),e(sh,Aho),e(sh,Nq),e(Nq,Lho),e(sh,yho),e(A,xho),e(A,lh),e(lh,$ge),e($ge,$ho),e(lh,kho),e(lh,qq),e(qq,Sho),e(lh,Rho),e(A,Pho),e(A,ih),e(ih,kge),e(kge,Bho),e(ih,Iho),e(ih,jq),e(jq,Nho),e(ih,qho),e(A,jho),e(A,dh),e(dh,Sge),e(Sge,Dho),e(dh,Gho),e(dh,Dq),e(Dq,Oho),e(dh,Vho),e(A,Xho),e(A,ch),e(ch,Rge),e(Rge,zho),e(ch,Qho),e(ch,Gq),e(Gq,Who),e(ch,Uho),e(A,Hho),e(A,fh),e(fh,Pge),e(Pge,Jho),e(fh,Yho),e(fh,Oq),e(Oq,Zho),e(fh,Kho),e(A,euo),e(A,mh),e(mh,Bge),e(Bge,ouo),e(mh,ruo),e(mh,Vq),e(Vq,tuo),e(mh,auo),e(A,nuo),e(A,gh),e(gh,Ige),e(Ige,suo),e(gh,luo),e(gh,Xq),e(Xq,iuo),e(gh,duo),e(A,cuo),e(A,hh),e(hh,Nge),e(Nge,fuo),e(hh,muo),e(hh,zq),e(zq,guo),e(hh,huo),e(A,uuo),e(A,uh),e(uh,qge),e(qge,puo),e(uh,_uo),e(uh,Qq),e(Qq,vuo),e(uh,buo),e(A,Fuo),e(A,ph),e(ph,jge),e(jge,Tuo),e(ph,Muo),e(ph,Wq),e(Wq,Euo),e(ph,Cuo),e(A,wuo),e(A,_h),e(_h,Dge),e(Dge,Auo),e(_h,Luo),e(_h,Uq),e(Uq,yuo),e(_h,xuo),e(A,$uo),e(A,vh),e(vh,Gge),e(Gge,kuo),e(vh,Suo),e(vh,Hq),e(Hq,Ruo),e(vh,Puo),e(A,Buo),e(A,bh),e(bh,Oge),e(Oge,Iuo),e(bh,Nuo),e(bh,Jq),e(Jq,quo),e(bh,juo),e(A,Duo),e(A,Fh),e(Fh,Vge),e(Vge,Guo),e(Fh,Ouo),e(Fh,Yq),e(Yq,Vuo),e(Fh,Xuo),e(A,zuo),e(A,Th),e(Th,Xge),e(Xge,Quo),e(Th,Wuo),e(Th,Zq),e(Zq,Uuo),e(Th,Huo),e(A,Juo),e(A,Mh),e(Mh,zge),e(zge,Yuo),e(Mh,Zuo),e(Mh,Kq),e(Kq,Kuo),e(Mh,epo),e(A,opo),e(A,Eh),e(Eh,Qge),e(Qge,rpo),e(Eh,tpo),e(Eh,ej),e(ej,apo),e(Eh,npo),e(A,spo),e(A,Ch),e(Ch,Wge),e(Wge,lpo),e(Ch,ipo),e(Ch,oj),e(oj,dpo),e(Ch,cpo),e(A,fpo),e(A,wh),e(wh,Uge),e(Uge,mpo),e(wh,gpo),e(wh,rj),e(rj,hpo),e(wh,upo),e(A,ppo),e(A,Ah),e(Ah,Hge),e(Hge,_po),e(Ah,vpo),e(Ah,tj),e(tj,bpo),e(Ah,Fpo),e(A,Tpo),e(A,Lh),e(Lh,Jge),e(Jge,Mpo),e(Lh,Epo),e(Lh,aj),e(aj,Cpo),e(Lh,wpo),e(A,Apo),e(A,yh),e(yh,Yge),e(Yge,Lpo),e(yh,ypo),e(yh,nj),e(nj,xpo),e(yh,$po),e(A,kpo),e(A,xh),e(xh,Zge),e(Zge,Spo),e(xh,Rpo),e(xh,sj),e(sj,Ppo),e(xh,Bpo),e(A,Ipo),e(A,$h),e($h,Kge),e(Kge,Npo),e($h,qpo),e($h,lj),e(lj,jpo),e($h,Dpo),e(A,Gpo),e(A,kh),e(kh,ehe),e(ehe,Opo),e(kh,Vpo),e(kh,ij),e(ij,Xpo),e(kh,zpo),e(A,Qpo),e(A,Sh),e(Sh,ohe),e(ohe,Wpo),e(Sh,Upo),e(Sh,dj),e(dj,Hpo),e(Sh,Jpo),e(A,Ypo),e(A,Rh),e(Rh,rhe),e(rhe,Zpo),e(Rh,Kpo),e(Rh,cj),e(cj,e_o),e(Rh,o_o),e(A,r_o),e(A,Ph),e(Ph,the),e(the,t_o),e(Ph,a_o),e(Ph,fj),e(fj,n_o),e(Ph,s_o),e(A,l_o),e(A,Bh),e(Bh,ahe),e(ahe,i_o),e(Bh,d_o),e(Bh,mj),e(mj,c_o),e(Bh,f_o),e(A,m_o),e(A,Ih),e(Ih,nhe),e(nhe,g_o),e(Ih,h_o),e(Ih,gj),e(gj,u_o),e(Ih,p_o),e(A,__o),e(A,Nh),e(Nh,she),e(she,v_o),e(Nh,b_o),e(Nh,hj),e(hj,F_o),e(Nh,T_o),e(A,M_o),e(A,qh),e(qh,lhe),e(lhe,E_o),e(qh,C_o),e(qh,uj),e(uj,w_o),e(qh,A_o),e(A,L_o),e(A,jh),e(jh,ihe),e(ihe,y_o),e(jh,x_o),e(jh,pj),e(pj,$_o),e(jh,k_o),e(A,S_o),e(A,Dh),e(Dh,dhe),e(dhe,R_o),e(Dh,P_o),e(Dh,_j),e(_j,B_o),e(Dh,I_o),e(A,N_o),e(A,Gh),e(Gh,che),e(che,q_o),e(Gh,j_o),e(Gh,vj),e(vj,D_o),e(Gh,G_o),e(A,O_o),e(A,Oh),e(Oh,fhe),e(fhe,V_o),e(Oh,X_o),e(Oh,bj),e(bj,z_o),e(Oh,Q_o),e(A,W_o),e(A,Vh),e(Vh,mhe),e(mhe,U_o),e(Vh,H_o),e(Vh,Fj),e(Fj,J_o),e(Vh,Y_o),e(A,Z_o),e(A,Xh),e(Xh,ghe),e(ghe,K_o),e(Xh,e4o),e(Xh,Tj),e(Tj,o4o),e(Xh,r4o),e(A,t4o),e(A,zh),e(zh,hhe),e(hhe,a4o),e(zh,n4o),e(zh,Mj),e(Mj,s4o),e(zh,l4o),e(A,i4o),e(A,Qh),e(Qh,uhe),e(uhe,d4o),e(Qh,c4o),e(Qh,Ej),e(Ej,f4o),e(Qh,m4o),e(A,g4o),e(A,Wh),e(Wh,phe),e(phe,h4o),e(Wh,u4o),e(Wh,Cj),e(Cj,p4o),e(Wh,_4o),e(A,v4o),e(A,Uh),e(Uh,_he),e(_he,b4o),e(Uh,F4o),e(Uh,wj),e(wj,T4o),e(Uh,M4o),e(A,E4o),e(A,Hh),e(Hh,vhe),e(vhe,C4o),e(Hh,w4o),e(Hh,Aj),e(Aj,A4o),e(Hh,L4o),e(A,y4o),e(A,Jh),e(Jh,bhe),e(bhe,x4o),e(Jh,$4o),e(Jh,Lj),e(Lj,k4o),e(Jh,S4o),e(A,R4o),e(A,Yh),e(Yh,Fhe),e(Fhe,P4o),e(Yh,B4o),e(Yh,yj),e(yj,I4o),e(Yh,N4o),e(A,q4o),e(A,Zh),e(Zh,The),e(The,j4o),e(Zh,D4o),e(Zh,xj),e(xj,G4o),e(Zh,O4o),e(A,V4o),e(A,Kh),e(Kh,Mhe),e(Mhe,X4o),e(Kh,z4o),e(Kh,$j),e($j,Q4o),e(Kh,W4o),e(A,U4o),e(A,eu),e(eu,Ehe),e(Ehe,H4o),e(eu,J4o),e(eu,kj),e(kj,Y4o),e(eu,Z4o),e(A,K4o),e(A,ou),e(ou,Che),e(Che,e2o),e(ou,o2o),e(ou,Sj),e(Sj,r2o),e(ou,t2o),e(A,a2o),e(A,ru),e(ru,whe),e(whe,n2o),e(ru,s2o),e(ru,Rj),e(Rj,l2o),e(ru,i2o),e(A,d2o),e(A,tu),e(tu,Ahe),e(Ahe,c2o),e(tu,f2o),e(tu,Pj),e(Pj,m2o),e(tu,g2o),e(A,h2o),e(A,au),e(au,Lhe),e(Lhe,u2o),e(au,p2o),e(au,Bj),e(Bj,_2o),e(au,v2o),e(A,b2o),e(A,nu),e(nu,yhe),e(yhe,F2o),e(nu,T2o),e(nu,Ij),e(Ij,M2o),e(nu,E2o),e(A,C2o),e(A,su),e(su,xhe),e(xhe,w2o),e(su,A2o),e(su,Nj),e(Nj,L2o),e(su,y2o),e(A,x2o),e(A,lu),e(lu,$he),e($he,$2o),e(lu,k2o),e(lu,qj),e(qj,S2o),e(lu,R2o),e(A,P2o),e(A,iu),e(iu,khe),e(khe,B2o),e(iu,I2o),e(iu,jj),e(jj,N2o),e(iu,q2o),e(A,j2o),e(A,du),e(du,She),e(She,D2o),e(du,G2o),e(du,Dj),e(Dj,O2o),e(du,V2o),e(A,X2o),e(A,cu),e(cu,Rhe),e(Rhe,z2o),e(cu,Q2o),e(cu,Gj),e(Gj,W2o),e(cu,U2o),e(A,H2o),e(A,fu),e(fu,Phe),e(Phe,J2o),e(fu,Y2o),e(fu,Oj),e(Oj,Z2o),e(fu,K2o),e(A,evo),e(A,mu),e(mu,Bhe),e(Bhe,ovo),e(mu,rvo),e(mu,Vj),e(Vj,tvo),e(mu,avo),e(A,nvo),e(A,gu),e(gu,Ihe),e(Ihe,svo),e(gu,lvo),e(gu,Xj),e(Xj,ivo),e(gu,dvo),e(A,cvo),e(A,hu),e(hu,Nhe),e(Nhe,fvo),e(hu,mvo),e(hu,zj),e(zj,gvo),e(hu,hvo),e(A,uvo),e(A,uu),e(uu,qhe),e(qhe,pvo),e(uu,_vo),e(uu,Qj),e(Qj,vvo),e(uu,bvo),e(A,Fvo),e(A,pu),e(pu,jhe),e(jhe,Tvo),e(pu,Mvo),e(pu,Wj),e(Wj,Evo),e(pu,Cvo),e(A,wvo),e(A,_u),e(_u,Dhe),e(Dhe,Avo),e(_u,Lvo),e(_u,Uj),e(Uj,yvo),e(_u,xvo),e(A,$vo),e(A,vu),e(vu,Ghe),e(Ghe,kvo),e(vu,Svo),e(vu,Hj),e(Hj,Rvo),e(vu,Pvo),e(A,Bvo),e(A,bu),e(bu,Ohe),e(Ohe,Ivo),e(bu,Nvo),e(bu,Jj),e(Jj,qvo),e(bu,jvo),e(A,Dvo),e(A,Fu),e(Fu,Vhe),e(Vhe,Gvo),e(Fu,Ovo),e(Fu,Yj),e(Yj,Vvo),e(Fu,Xvo),e(A,zvo),e(A,Tu),e(Tu,Xhe),e(Xhe,Qvo),e(Tu,Wvo),e(Tu,Zj),e(Zj,Uvo),e(Tu,Hvo),e(A,Jvo),e(A,Mu),e(Mu,zhe),e(zhe,Yvo),e(Mu,Zvo),e(Mu,Kj),e(Kj,Kvo),e(Mu,e1o),e(A,o1o),e(A,Eu),e(Eu,Qhe),e(Qhe,r1o),e(Eu,t1o),e(Eu,eD),e(eD,a1o),e(Eu,n1o),e(A,s1o),e(A,Cu),e(Cu,Whe),e(Whe,l1o),e(Cu,i1o),e(Cu,oD),e(oD,d1o),e(Cu,c1o),e(qr,f1o),M(wu,qr,null),e(So,m1o),e(So,Au),M(p$,Au,null),e(Au,g1o),e(Au,Uhe),e(Uhe,h1o),v(f,Sto,_),v(f,yd,_),e(yd,Lu),e(Lu,Hhe),M(_$,Hhe,null),e(yd,u1o),e(yd,Jhe),e(Jhe,p1o),v(f,Rto,_),v(f,Ro,_),M(v$,Ro,null),e(Ro,_1o),e(Ro,b$),e(b$,v1o),e(b$,rD),e(rD,b1o),e(b$,F1o),e(Ro,T1o),e(Ro,F$),e(F$,M1o),e(F$,Yhe),e(Yhe,E1o),e(F$,C1o),e(Ro,w1o),e(Ro,jr),M(T$,jr,null),e(jr,A1o),e(jr,Zhe),e(Zhe,L1o),e(jr,y1o),e(jr,tn),e(tn,x1o),e(tn,Khe),e(Khe,$1o),e(tn,k1o),e(tn,eue),e(eue,S1o),e(tn,R1o),e(tn,oue),e(oue,P1o),e(tn,B1o),e(jr,I1o),e(jr,k),e(k,us),e(us,rue),e(rue,N1o),e(us,q1o),e(us,tD),e(tD,j1o),e(us,D1o),e(us,aD),e(aD,G1o),e(us,O1o),e(k,V1o),e(k,ps),e(ps,tue),e(tue,X1o),e(ps,z1o),e(ps,nD),e(nD,Q1o),e(ps,W1o),e(ps,sD),e(sD,U1o),e(ps,H1o),e(k,J1o),e(k,_s),e(_s,aue),e(aue,Y1o),e(_s,Z1o),e(_s,lD),e(lD,K1o),e(_s,ebo),e(_s,iD),e(iD,obo),e(_s,rbo),e(k,tbo),e(k,yu),e(yu,nue),e(nue,abo),e(yu,nbo),e(yu,dD),e(dD,sbo),e(yu,lbo),e(k,ibo),e(k,vs),e(vs,sue),e(sue,dbo),e(vs,cbo),e(vs,cD),e(cD,fbo),e(vs,mbo),e(vs,fD),e(fD,gbo),e(vs,hbo),e(k,ubo),e(k,xu),e(xu,lue),e(lue,pbo),e(xu,_bo),e(xu,mD),e(mD,vbo),e(xu,bbo),e(k,Fbo),e(k,$u),e($u,iue),e(iue,Tbo),e($u,Mbo),e($u,gD),e(gD,Ebo),e($u,Cbo),e(k,wbo),e(k,ku),e(ku,due),e(due,Abo),e(ku,Lbo),e(ku,hD),e(hD,ybo),e(ku,xbo),e(k,$bo),e(k,bs),e(bs,cue),e(cue,kbo),e(bs,Sbo),e(bs,uD),e(uD,Rbo),e(bs,Pbo),e(bs,pD),e(pD,Bbo),e(bs,Ibo),e(k,Nbo),e(k,Fs),e(Fs,fue),e(fue,qbo),e(Fs,jbo),e(Fs,_D),e(_D,Dbo),e(Fs,Gbo),e(Fs,vD),e(vD,Obo),e(Fs,Vbo),e(k,Xbo),e(k,Ts),e(Ts,mue),e(mue,zbo),e(Ts,Qbo),e(Ts,bD),e(bD,Wbo),e(Ts,Ubo),e(Ts,FD),e(FD,Hbo),e(Ts,Jbo),e(k,Ybo),e(k,Su),e(Su,gue),e(gue,Zbo),e(Su,Kbo),e(Su,TD),e(TD,e0o),e(Su,o0o),e(k,r0o),e(k,Ru),e(Ru,hue),e(hue,t0o),e(Ru,a0o),e(Ru,MD),e(MD,n0o),e(Ru,s0o),e(k,l0o),e(k,Pu),e(Pu,uue),e(uue,i0o),e(Pu,d0o),e(Pu,ED),e(ED,c0o),e(Pu,f0o),e(k,m0o),e(k,Ms),e(Ms,pue),e(pue,g0o),e(Ms,h0o),e(Ms,CD),e(CD,u0o),e(Ms,p0o),e(Ms,wD),e(wD,_0o),e(Ms,v0o),e(k,b0o),e(k,Bu),e(Bu,_ue),e(_ue,F0o),e(Bu,T0o),e(Bu,AD),e(AD,M0o),e(Bu,E0o),e(k,C0o),e(k,Es),e(Es,vue),e(vue,w0o),e(Es,A0o),e(Es,LD),e(LD,L0o),e(Es,y0o),e(Es,yD),e(yD,x0o),e(Es,$0o),e(k,k0o),e(k,Cs),e(Cs,bue),e(bue,S0o),e(Cs,R0o),e(Cs,xD),e(xD,P0o),e(Cs,B0o),e(Cs,$D),e($D,I0o),e(Cs,N0o),e(k,q0o),e(k,ws),e(ws,Fue),e(Fue,j0o),e(ws,D0o),e(ws,kD),e(kD,G0o),e(ws,O0o),e(ws,SD),e(SD,V0o),e(ws,X0o),e(k,z0o),e(k,As),e(As,Tue),e(Tue,Q0o),e(As,W0o),e(As,RD),e(RD,U0o),e(As,H0o),e(As,PD),e(PD,J0o),e(As,Y0o),e(k,Z0o),e(k,Iu),e(Iu,Mue),e(Mue,K0o),e(Iu,eFo),e(Iu,BD),e(BD,oFo),e(Iu,rFo),e(k,tFo),e(k,Ls),e(Ls,Eue),e(Eue,aFo),e(Ls,nFo),e(Ls,ID),e(ID,sFo),e(Ls,lFo),e(Ls,ND),e(ND,iFo),e(Ls,dFo),e(k,cFo),e(k,ys),e(ys,Cue),e(Cue,fFo),e(ys,mFo),e(ys,qD),e(qD,gFo),e(ys,hFo),e(ys,jD),e(jD,uFo),e(ys,pFo),e(k,_Fo),e(k,xs),e(xs,wue),e(wue,vFo),e(xs,bFo),e(xs,DD),e(DD,FFo),e(xs,TFo),e(xs,GD),e(GD,MFo),e(xs,EFo),e(k,CFo),e(k,$s),e($s,Aue),e(Aue,wFo),e($s,AFo),e($s,OD),e(OD,LFo),e($s,yFo),e($s,VD),e(VD,xFo),e($s,$Fo),e(k,kFo),e(k,ks),e(ks,Lue),e(Lue,SFo),e(ks,RFo),e(ks,XD),e(XD,PFo),e(ks,BFo),e(ks,zD),e(zD,IFo),e(ks,NFo),e(k,qFo),e(k,Ss),e(Ss,yue),e(yue,jFo),e(Ss,DFo),e(Ss,QD),e(QD,GFo),e(Ss,OFo),e(Ss,WD),e(WD,VFo),e(Ss,XFo),e(k,zFo),e(k,Rs),e(Rs,xue),e(xue,QFo),e(Rs,WFo),e(Rs,UD),e(UD,UFo),e(Rs,HFo),e(Rs,HD),e(HD,JFo),e(Rs,YFo),e(k,ZFo),e(k,Nu),e(Nu,$ue),e($ue,KFo),e(Nu,eTo),e(Nu,JD),e(JD,oTo),e(Nu,rTo),e(k,tTo),e(k,qu),e(qu,kue),e(kue,aTo),e(qu,nTo),e(qu,YD),e(YD,sTo),e(qu,lTo),e(k,iTo),e(k,Ps),e(Ps,Sue),e(Sue,dTo),e(Ps,cTo),e(Ps,ZD),e(ZD,fTo),e(Ps,mTo),e(Ps,KD),e(KD,gTo),e(Ps,hTo),e(k,uTo),e(k,ju),e(ju,Rue),e(Rue,pTo),e(ju,_To),e(ju,eG),e(eG,vTo),e(ju,bTo),e(k,FTo),e(k,Bs),e(Bs,Pue),e(Pue,TTo),e(Bs,MTo),e(Bs,oG),e(oG,ETo),e(Bs,CTo),e(Bs,rG),e(rG,wTo),e(Bs,ATo),e(k,LTo),e(k,Is),e(Is,Bue),e(Bue,yTo),e(Is,xTo),e(Is,tG),e(tG,$To),e(Is,kTo),e(Is,aG),e(aG,STo),e(Is,RTo),e(k,PTo),e(k,Ns),e(Ns,Iue),e(Iue,BTo),e(Ns,ITo),e(Ns,nG),e(nG,NTo),e(Ns,qTo),e(Ns,sG),e(sG,jTo),e(Ns,DTo),e(k,GTo),e(k,Du),e(Du,Nue),e(Nue,OTo),e(Du,VTo),e(Du,lG),e(lG,XTo),e(Du,zTo),e(k,QTo),e(k,Gu),e(Gu,que),e(que,WTo),e(Gu,UTo),e(Gu,iG),e(iG,HTo),e(Gu,JTo),e(k,YTo),e(k,qs),e(qs,jue),e(jue,ZTo),e(qs,KTo),e(qs,dG),e(dG,eMo),e(qs,oMo),e(qs,cG),e(cG,rMo),e(qs,tMo),e(k,aMo),e(k,js),e(js,Due),e(Due,nMo),e(js,sMo),e(js,fG),e(fG,lMo),e(js,iMo),e(js,mG),e(mG,dMo),e(js,cMo),e(k,fMo),e(k,Ds),e(Ds,Gue),e(Gue,mMo),e(Ds,gMo),e(Ds,gG),e(gG,hMo),e(Ds,uMo),e(Ds,hG),e(hG,pMo),e(Ds,_Mo),e(k,vMo),e(k,Ou),e(Ou,Oue),e(Oue,bMo),e(Ou,FMo),e(Ou,uG),e(uG,TMo),e(Ou,MMo),e(k,EMo),e(k,Gs),e(Gs,Vue),e(Vue,CMo),e(Gs,wMo),e(Gs,pG),e(pG,AMo),e(Gs,LMo),e(Gs,_G),e(_G,yMo),e(Gs,xMo),e(k,$Mo),e(k,Os),e(Os,Xue),e(Xue,kMo),e(Os,SMo),e(Os,vG),e(vG,RMo),e(Os,PMo),e(Os,bG),e(bG,BMo),e(Os,IMo),e(k,NMo),e(k,Vs),e(Vs,zue),e(zue,qMo),e(Vs,jMo),e(Vs,FG),e(FG,DMo),e(Vs,GMo),e(Vs,TG),e(TG,OMo),e(Vs,VMo),e(k,XMo),e(k,Xs),e(Xs,Que),e(Que,zMo),e(Xs,QMo),e(Xs,MG),e(MG,WMo),e(Xs,UMo),e(Xs,EG),e(EG,HMo),e(Xs,JMo),e(k,YMo),e(k,zs),e(zs,Wue),e(Wue,ZMo),e(zs,KMo),e(zs,CG),e(CG,eEo),e(zs,oEo),e(zs,wG),e(wG,rEo),e(zs,tEo),e(k,aEo),e(k,Qs),e(Qs,Uue),e(Uue,nEo),e(Qs,sEo),e(Qs,AG),e(AG,lEo),e(Qs,iEo),e(Qs,LG),e(LG,dEo),e(Qs,cEo),e(k,fEo),e(k,Ws),e(Ws,Hue),e(Hue,mEo),e(Ws,gEo),e(Ws,yG),e(yG,hEo),e(Ws,uEo),e(Ws,xG),e(xG,pEo),e(Ws,_Eo),e(k,vEo),e(k,Us),e(Us,Jue),e(Jue,bEo),e(Us,FEo),e(Us,$G),e($G,TEo),e(Us,MEo),e(Us,kG),e(kG,EEo),e(Us,CEo),e(k,wEo),e(k,Hs),e(Hs,Yue),e(Yue,AEo),e(Hs,LEo),e(Hs,SG),e(SG,yEo),e(Hs,xEo),e(Hs,RG),e(RG,$Eo),e(Hs,kEo),e(k,SEo),e(k,Vu),e(Vu,Zue),e(Zue,REo),e(Vu,PEo),e(Vu,PG),e(PG,BEo),e(Vu,IEo),e(k,NEo),e(k,Js),e(Js,Kue),e(Kue,qEo),e(Js,jEo),e(Js,BG),e(BG,DEo),e(Js,GEo),e(Js,IG),e(IG,OEo),e(Js,VEo),e(k,XEo),e(k,Xu),e(Xu,epe),e(epe,zEo),e(Xu,QEo),e(Xu,NG),e(NG,WEo),e(Xu,UEo),e(k,HEo),e(k,zu),e(zu,ope),e(ope,JEo),e(zu,YEo),e(zu,qG),e(qG,ZEo),e(zu,KEo),e(k,eCo),e(k,Ys),e(Ys,rpe),e(rpe,oCo),e(Ys,rCo),e(Ys,jG),e(jG,tCo),e(Ys,aCo),e(Ys,DG),e(DG,nCo),e(Ys,sCo),e(k,lCo),e(k,Zs),e(Zs,tpe),e(tpe,iCo),e(Zs,dCo),e(Zs,GG),e(GG,cCo),e(Zs,fCo),e(Zs,OG),e(OG,mCo),e(Zs,gCo),e(k,hCo),e(k,Ks),e(Ks,ape),e(ape,uCo),e(Ks,pCo),e(Ks,VG),e(VG,_Co),e(Ks,vCo),e(Ks,XG),e(XG,bCo),e(Ks,FCo),e(k,TCo),e(k,Qu),e(Qu,npe),e(npe,MCo),e(Qu,ECo),e(Qu,zG),e(zG,CCo),e(Qu,wCo),e(k,ACo),e(k,el),e(el,spe),e(spe,LCo),e(el,yCo),e(el,QG),e(QG,xCo),e(el,$Co),e(el,WG),e(WG,kCo),e(el,SCo),e(k,RCo),e(k,ol),e(ol,lpe),e(lpe,PCo),e(ol,BCo),e(ol,UG),e(UG,ICo),e(ol,NCo),e(ol,HG),e(HG,qCo),e(ol,jCo),e(k,DCo),e(k,rl),e(rl,ipe),e(ipe,GCo),e(rl,OCo),e(rl,JG),e(JG,VCo),e(rl,XCo),e(rl,YG),e(YG,zCo),e(rl,QCo),e(k,WCo),e(k,tl),e(tl,dpe),e(dpe,UCo),e(tl,HCo),e(tl,ZG),e(ZG,JCo),e(tl,YCo),e(tl,KG),e(KG,ZCo),e(tl,KCo),e(k,e3o),e(k,al),e(al,cpe),e(cpe,o3o),e(al,r3o),e(al,eO),e(eO,t3o),e(al,a3o),e(al,oO),e(oO,n3o),e(al,s3o),e(k,l3o),e(k,nl),e(nl,fpe),e(fpe,i3o),e(nl,d3o),e(nl,rO),e(rO,c3o),e(nl,f3o),e(nl,tO),e(tO,m3o),e(nl,g3o),e(k,h3o),e(k,sl),e(sl,mpe),e(mpe,u3o),e(sl,p3o),e(sl,aO),e(aO,_3o),e(sl,v3o),e(sl,nO),e(nO,b3o),e(sl,F3o),e(k,T3o),e(k,ll),e(ll,gpe),e(gpe,M3o),e(ll,E3o),e(ll,sO),e(sO,C3o),e(ll,w3o),e(ll,lO),e(lO,A3o),e(ll,L3o),e(k,y3o),e(k,Wu),e(Wu,hpe),e(hpe,x3o),e(Wu,$3o),e(Wu,iO),e(iO,k3o),e(Wu,S3o),e(k,R3o),e(k,il),e(il,upe),e(upe,P3o),e(il,B3o),e(il,dO),e(dO,I3o),e(il,N3o),e(il,cO),e(cO,q3o),e(il,j3o),e(k,D3o),e(k,dl),e(dl,ppe),e(ppe,G3o),e(dl,O3o),e(dl,fO),e(fO,V3o),e(dl,X3o),e(dl,mO),e(mO,z3o),e(dl,Q3o),e(k,W3o),e(k,cl),e(cl,_pe),e(_pe,U3o),e(cl,H3o),e(cl,gO),e(gO,J3o),e(cl,Y3o),e(cl,hO),e(hO,Z3o),e(cl,K3o),e(k,e5o),e(k,Uu),e(Uu,vpe),e(vpe,o5o),e(Uu,r5o),e(Uu,uO),e(uO,t5o),e(Uu,a5o),e(k,n5o),e(k,Hu),e(Hu,bpe),e(bpe,s5o),e(Hu,l5o),e(Hu,pO),e(pO,i5o),e(Hu,d5o),e(k,c5o),e(k,Ju),e(Ju,Fpe),e(Fpe,f5o),e(Ju,m5o),e(Ju,_O),e(_O,g5o),e(Ju,h5o),e(k,u5o),e(k,Yu),e(Yu,Tpe),e(Tpe,p5o),e(Yu,_5o),e(Yu,vO),e(vO,v5o),e(Yu,b5o),e(k,F5o),e(k,fl),e(fl,Mpe),e(Mpe,T5o),e(fl,M5o),e(fl,bO),e(bO,E5o),e(fl,C5o),e(fl,FO),e(FO,w5o),e(fl,A5o),e(k,L5o),e(k,Zu),e(Zu,Epe),e(Epe,y5o),e(Zu,x5o),e(Zu,TO),e(TO,$5o),e(Zu,k5o),e(k,S5o),e(k,ml),e(ml,Cpe),e(Cpe,R5o),e(ml,P5o),e(ml,MO),e(MO,B5o),e(ml,I5o),e(ml,EO),e(EO,N5o),e(ml,q5o),e(k,j5o),e(k,gl),e(gl,wpe),e(wpe,D5o),e(gl,G5o),e(gl,CO),e(CO,O5o),e(gl,V5o),e(gl,wO),e(wO,X5o),e(gl,z5o),e(k,Q5o),e(k,hl),e(hl,Ape),e(Ape,W5o),e(hl,U5o),e(hl,AO),e(AO,H5o),e(hl,J5o),e(hl,LO),e(LO,Y5o),e(hl,Z5o),e(k,K5o),e(k,ul),e(ul,Lpe),e(Lpe,ewo),e(ul,owo),e(ul,yO),e(yO,rwo),e(ul,two),e(ul,xO),e(xO,awo),e(ul,nwo),e(k,swo),e(k,pl),e(pl,ype),e(ype,lwo),e(pl,iwo),e(pl,$O),e($O,dwo),e(pl,cwo),e(pl,kO),e(kO,fwo),e(pl,mwo),e(k,gwo),e(k,_l),e(_l,xpe),e(xpe,hwo),e(_l,uwo),e(_l,SO),e(SO,pwo),e(_l,_wo),e(_l,RO),e(RO,vwo),e(_l,bwo),e(k,Fwo),e(k,Ku),e(Ku,$pe),e($pe,Two),e(Ku,Mwo),e(Ku,PO),e(PO,Ewo),e(Ku,Cwo),e(k,wwo),e(k,ep),e(ep,kpe),e(kpe,Awo),e(ep,Lwo),e(ep,BO),e(BO,ywo),e(ep,xwo),e(k,$wo),e(k,vl),e(vl,Spe),e(Spe,kwo),e(vl,Swo),e(vl,IO),e(IO,Rwo),e(vl,Pwo),e(vl,NO),e(NO,Bwo),e(vl,Iwo),e(k,Nwo),e(k,bl),e(bl,Rpe),e(Rpe,qwo),e(bl,jwo),e(bl,qO),e(qO,Dwo),e(bl,Gwo),e(bl,jO),e(jO,Owo),e(bl,Vwo),e(k,Xwo),e(k,Fl),e(Fl,Ppe),e(Ppe,zwo),e(Fl,Qwo),e(Fl,DO),e(DO,Wwo),e(Fl,Uwo),e(Fl,GO),e(GO,Hwo),e(Fl,Jwo),e(k,Ywo),e(k,op),e(op,Bpe),e(Bpe,Zwo),e(op,Kwo),e(op,OO),e(OO,eAo),e(op,oAo),e(k,rAo),e(k,rp),e(rp,Ipe),e(Ipe,tAo),e(rp,aAo),e(rp,VO),e(VO,nAo),e(rp,sAo),e(k,lAo),e(k,tp),e(tp,Npe),e(Npe,iAo),e(tp,dAo),e(tp,XO),e(XO,cAo),e(tp,fAo),e(k,mAo),e(k,Tl),e(Tl,qpe),e(qpe,gAo),e(Tl,hAo),e(Tl,zO),e(zO,uAo),e(Tl,pAo),e(Tl,QO),e(QO,_Ao),e(Tl,vAo),e(k,bAo),e(k,Ml),e(Ml,jpe),e(jpe,FAo),e(Ml,TAo),e(Ml,WO),e(WO,MAo),e(Ml,EAo),e(Ml,UO),e(UO,CAo),e(Ml,wAo),e(k,AAo),e(k,ap),e(ap,Dpe),e(Dpe,LAo),e(ap,yAo),e(ap,HO),e(HO,xAo),e(ap,$Ao),e(k,kAo),e(k,np),e(np,Gpe),e(Gpe,SAo),e(np,RAo),e(np,JO),e(JO,PAo),e(np,BAo),e(k,IAo),e(k,sp),e(sp,Ope),e(Ope,NAo),e(sp,qAo),e(sp,YO),e(YO,jAo),e(sp,DAo),e(k,GAo),e(k,lp),e(lp,Vpe),e(Vpe,OAo),e(lp,VAo),e(lp,ZO),e(ZO,XAo),e(lp,zAo),e(k,QAo),e(k,El),e(El,Xpe),e(Xpe,WAo),e(El,UAo),e(El,KO),e(KO,HAo),e(El,JAo),e(El,eV),e(eV,YAo),e(El,ZAo),e(k,KAo),e(k,Cl),e(Cl,zpe),e(zpe,e6o),e(Cl,o6o),e(Cl,oV),e(oV,r6o),e(Cl,t6o),e(Cl,rV),e(rV,a6o),e(Cl,n6o),e(k,s6o),e(k,ip),e(ip,Qpe),e(Qpe,l6o),e(ip,i6o),e(ip,tV),e(tV,d6o),e(ip,c6o),e(k,f6o),e(k,dp),e(dp,Wpe),e(Wpe,m6o),e(dp,g6o),e(dp,aV),e(aV,h6o),e(dp,u6o),e(k,p6o),e(k,wl),e(wl,Upe),e(Upe,_6o),e(wl,v6o),e(wl,nV),e(nV,b6o),e(wl,F6o),e(wl,sV),e(sV,T6o),e(wl,M6o),e(k,E6o),e(k,Al),e(Al,Hpe),e(Hpe,C6o),e(Al,w6o),e(Al,lV),e(lV,A6o),e(Al,L6o),e(Al,iV),e(iV,y6o),e(Al,x6o),e(k,$6o),e(k,Ll),e(Ll,Jpe),e(Jpe,k6o),e(Ll,S6o),e(Ll,dV),e(dV,R6o),e(Ll,P6o),e(Ll,cV),e(cV,B6o),e(Ll,I6o),e(k,N6o),e(k,yl),e(yl,Ype),e(Ype,q6o),e(yl,j6o),e(yl,fV),e(fV,D6o),e(yl,G6o),e(yl,mV),e(mV,O6o),e(yl,V6o),e(jr,X6o),M(cp,jr,null),e(Ro,z6o),e(Ro,fp),M(M$,fp,null),e(fp,Q6o),e(fp,Zpe),e(Zpe,W6o),v(f,Pto,_),v(f,xd,_),e(xd,mp),e(mp,Kpe),M(E$,Kpe,null),e(xd,U6o),e(xd,e_e),e(e_e,H6o),v(f,Bto,_),v(f,Po,_),M(C$,Po,null),e(Po,J6o),e(Po,w$),e(w$,Y6o),e(w$,gV),e(gV,Z6o),e(w$,K6o),e(Po,e7o),e(Po,A$),e(A$,o7o),e(A$,o_e),e(o_e,r7o),e(A$,t7o),e(Po,a7o),e(Po,Ye),M(L$,Ye,null),e(Ye,n7o),e(Ye,r_e),e(r_e,s7o),e(Ye,l7o),e(Ye,an),e(an,i7o),e(an,t_e),e(t_e,d7o),e(an,c7o),e(an,a_e),e(a_e,f7o),e(an,m7o),e(an,n_e),e(n_e,g7o),e(an,h7o),e(Ye,u7o),e(Ye,z),e(z,gp),e(gp,s_e),e(s_e,p7o),e(gp,_7o),e(gp,hV),e(hV,v7o),e(gp,b7o),e(z,F7o),e(z,hp),e(hp,l_e),e(l_e,T7o),e(hp,M7o),e(hp,uV),e(uV,E7o),e(hp,C7o),e(z,w7o),e(z,up),e(up,i_e),e(i_e,A7o),e(up,L7o),e(up,pV),e(pV,y7o),e(up,x7o),e(z,$7o),e(z,pp),e(pp,d_e),e(d_e,k7o),e(pp,S7o),e(pp,_V),e(_V,R7o),e(pp,P7o),e(z,B7o),e(z,_p),e(_p,c_e),e(c_e,I7o),e(_p,N7o),e(_p,vV),e(vV,q7o),e(_p,j7o),e(z,D7o),e(z,vp),e(vp,f_e),e(f_e,G7o),e(vp,O7o),e(vp,bV),e(bV,V7o),e(vp,X7o),e(z,z7o),e(z,bp),e(bp,m_e),e(m_e,Q7o),e(bp,W7o),e(bp,FV),e(FV,U7o),e(bp,H7o),e(z,J7o),e(z,Fp),e(Fp,g_e),e(g_e,Y7o),e(Fp,Z7o),e(Fp,TV),e(TV,K7o),e(Fp,e8o),e(z,o8o),e(z,Tp),e(Tp,h_e),e(h_e,r8o),e(Tp,t8o),e(Tp,MV),e(MV,a8o),e(Tp,n8o),e(z,s8o),e(z,Mp),e(Mp,u_e),e(u_e,l8o),e(Mp,i8o),e(Mp,EV),e(EV,d8o),e(Mp,c8o),e(z,f8o),e(z,Ep),e(Ep,p_e),e(p_e,m8o),e(Ep,g8o),e(Ep,CV),e(CV,h8o),e(Ep,u8o),e(z,p8o),e(z,Cp),e(Cp,__e),e(__e,_8o),e(Cp,v8o),e(Cp,wV),e(wV,b8o),e(Cp,F8o),e(z,T8o),e(z,wp),e(wp,v_e),e(v_e,M8o),e(wp,E8o),e(wp,AV),e(AV,C8o),e(wp,w8o),e(z,A8o),e(z,Ap),e(Ap,b_e),e(b_e,L8o),e(Ap,y8o),e(Ap,LV),e(LV,x8o),e(Ap,$8o),e(z,k8o),e(z,Lp),e(Lp,F_e),e(F_e,S8o),e(Lp,R8o),e(Lp,yV),e(yV,P8o),e(Lp,B8o),e(z,I8o),e(z,yp),e(yp,T_e),e(T_e,N8o),e(yp,q8o),e(yp,xV),e(xV,j8o),e(yp,D8o),e(z,G8o),e(z,xp),e(xp,M_e),e(M_e,O8o),e(xp,V8o),e(xp,$V),e($V,X8o),e(xp,z8o),e(z,Q8o),e(z,$p),e($p,E_e),e(E_e,W8o),e($p,U8o),e($p,kV),e(kV,H8o),e($p,J8o),e(z,Y8o),e(z,kp),e(kp,C_e),e(C_e,Z8o),e(kp,K8o),e(kp,SV),e(SV,eLo),e(kp,oLo),e(z,rLo),e(z,Sp),e(Sp,w_e),e(w_e,tLo),e(Sp,aLo),e(Sp,RV),e(RV,nLo),e(Sp,sLo),e(z,lLo),e(z,Rp),e(Rp,A_e),e(A_e,iLo),e(Rp,dLo),e(Rp,PV),e(PV,cLo),e(Rp,fLo),e(z,mLo),e(z,Pp),e(Pp,L_e),e(L_e,gLo),e(Pp,hLo),e(Pp,BV),e(BV,uLo),e(Pp,pLo),e(z,_Lo),e(z,Bp),e(Bp,y_e),e(y_e,vLo),e(Bp,bLo),e(Bp,IV),e(IV,FLo),e(Bp,TLo),e(z,MLo),e(z,Ip),e(Ip,x_e),e(x_e,ELo),e(Ip,CLo),e(Ip,NV),e(NV,wLo),e(Ip,ALo),e(z,LLo),e(z,Np),e(Np,$_e),e($_e,yLo),e(Np,xLo),e(Np,qV),e(qV,$Lo),e(Np,kLo),e(z,SLo),e(z,qp),e(qp,k_e),e(k_e,RLo),e(qp,PLo),e(qp,jV),e(jV,BLo),e(qp,ILo),e(z,NLo),e(z,jp),e(jp,S_e),e(S_e,qLo),e(jp,jLo),e(jp,DV),e(DV,DLo),e(jp,GLo),e(z,OLo),e(z,Dp),e(Dp,R_e),e(R_e,VLo),e(Dp,XLo),e(Dp,GV),e(GV,zLo),e(Dp,QLo),e(z,WLo),e(z,Gp),e(Gp,P_e),e(P_e,ULo),e(Gp,HLo),e(Gp,OV),e(OV,JLo),e(Gp,YLo),e(z,ZLo),e(z,Op),e(Op,B_e),e(B_e,KLo),e(Op,eyo),e(Op,VV),e(VV,oyo),e(Op,ryo),e(z,tyo),e(z,Vp),e(Vp,I_e),e(I_e,ayo),e(Vp,nyo),e(Vp,XV),e(XV,syo),e(Vp,lyo),e(z,iyo),e(z,Xp),e(Xp,N_e),e(N_e,dyo),e(Xp,cyo),e(Xp,zV),e(zV,fyo),e(Xp,myo),e(z,gyo),e(z,zp),e(zp,q_e),e(q_e,hyo),e(zp,uyo),e(zp,QV),e(QV,pyo),e(zp,_yo),e(z,vyo),e(z,Qp),e(Qp,j_e),e(j_e,byo),e(Qp,Fyo),e(Qp,WV),e(WV,Tyo),e(Qp,Myo),e(z,Eyo),e(z,Wp),e(Wp,D_e),e(D_e,Cyo),e(Wp,wyo),e(Wp,UV),e(UV,Ayo),e(Wp,Lyo),e(z,yyo),e(z,Up),e(Up,G_e),e(G_e,xyo),e(Up,$yo),e(Up,HV),e(HV,kyo),e(Up,Syo),e(z,Ryo),e(z,Hp),e(Hp,O_e),e(O_e,Pyo),e(Hp,Byo),e(Hp,JV),e(JV,Iyo),e(Hp,Nyo),e(z,qyo),e(z,Jp),e(Jp,V_e),e(V_e,jyo),e(Jp,Dyo),e(Jp,YV),e(YV,Gyo),e(Jp,Oyo),e(z,Vyo),e(z,Yp),e(Yp,X_e),e(X_e,Xyo),e(Yp,zyo),e(Yp,ZV),e(ZV,Qyo),e(Yp,Wyo),e(z,Uyo),e(z,Zp),e(Zp,z_e),e(z_e,Hyo),e(Zp,Jyo),e(Zp,KV),e(KV,Yyo),e(Zp,Zyo),e(z,Kyo),e(z,Kp),e(Kp,Q_e),e(Q_e,e9o),e(Kp,o9o),e(Kp,eX),e(eX,r9o),e(Kp,t9o),e(z,a9o),e(z,e_),e(e_,W_e),e(W_e,n9o),e(e_,s9o),e(e_,oX),e(oX,l9o),e(e_,i9o),e(z,d9o),e(z,o_),e(o_,U_e),e(U_e,c9o),e(o_,f9o),e(o_,rX),e(rX,m9o),e(o_,g9o),e(z,h9o),e(z,r_),e(r_,H_e),e(H_e,u9o),e(r_,p9o),e(r_,tX),e(tX,_9o),e(r_,v9o),e(Ye,b9o),M(t_,Ye,null),e(Ye,F9o),M(a_,Ye,null),e(Po,T9o),e(Po,n_),M(y$,n_,null),e(n_,M9o),e(n_,J_e),e(J_e,E9o),v(f,Ito,_),v(f,$d,_),e($d,s_),e(s_,Y_e),M(x$,Y_e,null),e($d,C9o),e($d,Z_e),e(Z_e,w9o),v(f,Nto,_),v(f,Bo,_),M($$,Bo,null),e(Bo,A9o),e(Bo,k$),e(k$,L9o),e(k$,aX),e(aX,y9o),e(k$,x9o),e(Bo,$9o),e(Bo,S$),e(S$,k9o),e(S$,K_e),e(K_e,S9o),e(S$,R9o),e(Bo,P9o),e(Bo,Ze),M(R$,Ze,null),e(Ze,B9o),e(Ze,e4e),e(e4e,I9o),e(Ze,N9o),e(Ze,kd),e(kd,q9o),e(kd,o4e),e(o4e,j9o),e(kd,D9o),e(kd,r4e),e(r4e,G9o),e(kd,O9o),e(Ze,V9o),e(Ze,le),e(le,l_),e(l_,t4e),e(t4e,X9o),e(l_,z9o),e(l_,nX),e(nX,Q9o),e(l_,W9o),e(le,U9o),e(le,i_),e(i_,a4e),e(a4e,H9o),e(i_,J9o),e(i_,sX),e(sX,Y9o),e(i_,Z9o),e(le,K9o),e(le,d_),e(d_,n4e),e(n4e,exo),e(d_,oxo),e(d_,lX),e(lX,rxo),e(d_,txo),e(le,axo),e(le,c_),e(c_,s4e),e(s4e,nxo),e(c_,sxo),e(c_,iX),e(iX,lxo),e(c_,ixo),e(le,dxo),e(le,f_),e(f_,l4e),e(l4e,cxo),e(f_,fxo),e(f_,dX),e(dX,mxo),e(f_,gxo),e(le,hxo),e(le,m_),e(m_,i4e),e(i4e,uxo),e(m_,pxo),e(m_,cX),e(cX,_xo),e(m_,vxo),e(le,bxo),e(le,g_),e(g_,d4e),e(d4e,Fxo),e(g_,Txo),e(g_,fX),e(fX,Mxo),e(g_,Exo),e(le,Cxo),e(le,h_),e(h_,c4e),e(c4e,wxo),e(h_,Axo),e(h_,mX),e(mX,Lxo),e(h_,yxo),e(le,xxo),e(le,u_),e(u_,f4e),e(f4e,$xo),e(u_,kxo),e(u_,gX),e(gX,Sxo),e(u_,Rxo),e(le,Pxo),e(le,p_),e(p_,m4e),e(m4e,Bxo),e(p_,Ixo),e(p_,hX),e(hX,Nxo),e(p_,qxo),e(le,jxo),e(le,__),e(__,g4e),e(g4e,Dxo),e(__,Gxo),e(__,uX),e(uX,Oxo),e(__,Vxo),e(le,Xxo),e(le,v_),e(v_,h4e),e(h4e,zxo),e(v_,Qxo),e(v_,pX),e(pX,Wxo),e(v_,Uxo),e(le,Hxo),e(le,b_),e(b_,u4e),e(u4e,Jxo),e(b_,Yxo),e(b_,_X),e(_X,Zxo),e(b_,Kxo),e(le,e$o),e(le,F_),e(F_,p4e),e(p4e,o$o),e(F_,r$o),e(F_,vX),e(vX,t$o),e(F_,a$o),e(le,n$o),e(le,T_),e(T_,_4e),e(_4e,s$o),e(T_,l$o),e(T_,bX),e(bX,i$o),e(T_,d$o),e(le,c$o),e(le,M_),e(M_,v4e),e(v4e,f$o),e(M_,m$o),e(M_,FX),e(FX,g$o),e(M_,h$o),e(le,u$o),e(le,E_),e(E_,b4e),e(b4e,p$o),e(E_,_$o),e(E_,TX),e(TX,v$o),e(E_,b$o),e(le,F$o),e(le,C_),e(C_,F4e),e(F4e,T$o),e(C_,M$o),e(C_,MX),e(MX,E$o),e(C_,C$o),e(le,w$o),e(le,w_),e(w_,T4e),e(T4e,A$o),e(w_,L$o),e(w_,EX),e(EX,y$o),e(w_,x$o),e(le,$$o),e(le,A_),e(A_,M4e),e(M4e,k$o),e(A_,S$o),e(A_,CX),e(CX,R$o),e(A_,P$o),e(le,B$o),e(le,L_),e(L_,E4e),e(E4e,I$o),e(L_,N$o),e(L_,wX),e(wX,q$o),e(L_,j$o),e(le,D$o),e(le,y_),e(y_,C4e),e(C4e,G$o),e(y_,O$o),e(y_,AX),e(AX,V$o),e(y_,X$o),e(Ze,z$o),M(x_,Ze,null),e(Ze,Q$o),M($_,Ze,null),e(Bo,W$o),e(Bo,k_),M(P$,k_,null),e(k_,U$o),e(k_,w4e),e(w4e,H$o),v(f,qto,_),v(f,Sd,_),e(Sd,S_),e(S_,A4e),M(B$,A4e,null),e(Sd,J$o),e(Sd,L4e),e(L4e,Y$o),v(f,jto,_),v(f,Io,_),M(I$,Io,null),e(Io,Z$o),e(Io,Rd),e(Rd,K$o),e(Rd,LX),e(LX,eko),e(Rd,oko),e(Rd,yX),e(yX,rko),e(Rd,tko),e(Io,ako),e(Io,N$),e(N$,nko),e(N$,y4e),e(y4e,sko),e(N$,lko),e(Io,iko),e(Io,Mt),M(q$,Mt,null),e(Mt,dko),e(Mt,x4e),e(x4e,cko),e(Mt,fko),e(Mt,Pd),e(Pd,mko),e(Pd,$4e),e($4e,gko),e(Pd,hko),e(Pd,xX),e(xX,uko),e(Pd,pko),e(Mt,_ko),M(R_,Mt,null),e(Io,vko),e(Io,Ke),M(j$,Ke,null),e(Ke,bko),e(Ke,k4e),e(k4e,Fko),e(Ke,Tko),e(Ke,nn),e(nn,Mko),e(nn,S4e),e(S4e,Eko),e(nn,Cko),e(nn,R4e),e(R4e,wko),e(nn,Ako),e(nn,P4e),e(P4e,Lko),e(nn,yko),e(Ke,xko),e(Ke,y),e(y,P_),e(P_,B4e),e(B4e,$ko),e(P_,kko),e(P_,$X),e($X,Sko),e(P_,Rko),e(y,Pko),e(y,B_),e(B_,I4e),e(I4e,Bko),e(B_,Iko),e(B_,kX),e(kX,Nko),e(B_,qko),e(y,jko),e(y,I_),e(I_,N4e),e(N4e,Dko),e(I_,Gko),e(I_,SX),e(SX,Oko),e(I_,Vko),e(y,Xko),e(y,N_),e(N_,q4e),e(q4e,zko),e(N_,Qko),e(N_,RX),e(RX,Wko),e(N_,Uko),e(y,Hko),e(y,q_),e(q_,j4e),e(j4e,Jko),e(q_,Yko),e(q_,PX),e(PX,Zko),e(q_,Kko),e(y,eSo),e(y,j_),e(j_,D4e),e(D4e,oSo),e(j_,rSo),e(j_,BX),e(BX,tSo),e(j_,aSo),e(y,nSo),e(y,D_),e(D_,G4e),e(G4e,sSo),e(D_,lSo),e(D_,IX),e(IX,iSo),e(D_,dSo),e(y,cSo),e(y,G_),e(G_,O4e),e(O4e,fSo),e(G_,mSo),e(G_,NX),e(NX,gSo),e(G_,hSo),e(y,uSo),e(y,O_),e(O_,V4e),e(V4e,pSo),e(O_,_So),e(O_,qX),e(qX,vSo),e(O_,bSo),e(y,FSo),e(y,V_),e(V_,X4e),e(X4e,TSo),e(V_,MSo),e(V_,jX),e(jX,ESo),e(V_,CSo),e(y,wSo),e(y,X_),e(X_,z4e),e(z4e,ASo),e(X_,LSo),e(X_,DX),e(DX,ySo),e(X_,xSo),e(y,$So),e(y,z_),e(z_,Q4e),e(Q4e,kSo),e(z_,SSo),e(z_,GX),e(GX,RSo),e(z_,PSo),e(y,BSo),e(y,Q_),e(Q_,W4e),e(W4e,ISo),e(Q_,NSo),e(Q_,OX),e(OX,qSo),e(Q_,jSo),e(y,DSo),e(y,W_),e(W_,U4e),e(U4e,GSo),e(W_,OSo),e(W_,VX),e(VX,VSo),e(W_,XSo),e(y,zSo),e(y,U_),e(U_,H4e),e(H4e,QSo),e(U_,WSo),e(U_,XX),e(XX,USo),e(U_,HSo),e(y,JSo),e(y,H_),e(H_,J4e),e(J4e,YSo),e(H_,ZSo),e(H_,zX),e(zX,KSo),e(H_,eRo),e(y,oRo),e(y,J_),e(J_,Y4e),e(Y4e,rRo),e(J_,tRo),e(J_,QX),e(QX,aRo),e(J_,nRo),e(y,sRo),e(y,Y_),e(Y_,Z4e),e(Z4e,lRo),e(Y_,iRo),e(Y_,WX),e(WX,dRo),e(Y_,cRo),e(y,fRo),e(y,Z_),e(Z_,K4e),e(K4e,mRo),e(Z_,gRo),e(Z_,UX),e(UX,hRo),e(Z_,uRo),e(y,pRo),e(y,K_),e(K_,e2e),e(e2e,_Ro),e(K_,vRo),e(K_,HX),e(HX,bRo),e(K_,FRo),e(y,TRo),e(y,e4),e(e4,o2e),e(o2e,MRo),e(e4,ERo),e(e4,JX),e(JX,CRo),e(e4,wRo),e(y,ARo),e(y,o4),e(o4,r2e),e(r2e,LRo),e(o4,yRo),e(o4,YX),e(YX,xRo),e(o4,$Ro),e(y,kRo),e(y,r4),e(r4,t2e),e(t2e,SRo),e(r4,RRo),e(r4,ZX),e(ZX,PRo),e(r4,BRo),e(y,IRo),e(y,t4),e(t4,a2e),e(a2e,NRo),e(t4,qRo),e(t4,KX),e(KX,jRo),e(t4,DRo),e(y,GRo),e(y,a4),e(a4,n2e),e(n2e,ORo),e(a4,VRo),e(a4,ez),e(ez,XRo),e(a4,zRo),e(y,QRo),e(y,n4),e(n4,s2e),e(s2e,WRo),e(n4,URo),e(n4,oz),e(oz,HRo),e(n4,JRo),e(y,YRo),e(y,s4),e(s4,l2e),e(l2e,ZRo),e(s4,KRo),e(s4,rz),e(rz,ePo),e(s4,oPo),e(y,rPo),e(y,l4),e(l4,i2e),e(i2e,tPo),e(l4,aPo),e(l4,tz),e(tz,nPo),e(l4,sPo),e(y,lPo),e(y,i4),e(i4,d2e),e(d2e,iPo),e(i4,dPo),e(i4,az),e(az,cPo),e(i4,fPo),e(y,mPo),e(y,d4),e(d4,c2e),e(c2e,gPo),e(d4,hPo),e(d4,nz),e(nz,uPo),e(d4,pPo),e(y,_Po),e(y,c4),e(c4,f2e),e(f2e,vPo),e(c4,bPo),e(c4,sz),e(sz,FPo),e(c4,TPo),e(y,MPo),e(y,f4),e(f4,m2e),e(m2e,EPo),e(f4,CPo),e(f4,lz),e(lz,wPo),e(f4,APo),e(y,LPo),e(y,m4),e(m4,g2e),e(g2e,yPo),e(m4,xPo),e(m4,iz),e(iz,$Po),e(m4,kPo),e(y,SPo),e(y,g4),e(g4,h2e),e(h2e,RPo),e(g4,PPo),e(g4,dz),e(dz,BPo),e(g4,IPo),e(y,NPo),e(y,h4),e(h4,u2e),e(u2e,qPo),e(h4,jPo),e(h4,cz),e(cz,DPo),e(h4,GPo),e(y,OPo),e(y,u4),e(u4,p2e),e(p2e,VPo),e(u4,XPo),e(u4,fz),e(fz,zPo),e(u4,QPo),e(y,WPo),e(y,p4),e(p4,_2e),e(_2e,UPo),e(p4,HPo),e(p4,mz),e(mz,JPo),e(p4,YPo),e(y,ZPo),e(y,_4),e(_4,v2e),e(v2e,KPo),e(_4,eBo),e(_4,gz),e(gz,oBo),e(_4,rBo),e(y,tBo),e(y,v4),e(v4,b2e),e(b2e,aBo),e(v4,nBo),e(v4,hz),e(hz,sBo),e(v4,lBo),e(y,iBo),e(y,xl),e(xl,F2e),e(F2e,dBo),e(xl,cBo),e(xl,uz),e(uz,fBo),e(xl,mBo),e(xl,pz),e(pz,gBo),e(xl,hBo),e(y,uBo),e(y,b4),e(b4,T2e),e(T2e,pBo),e(b4,_Bo),e(b4,_z),e(_z,vBo),e(b4,bBo),e(y,FBo),e(y,F4),e(F4,M2e),e(M2e,TBo),e(F4,MBo),e(F4,vz),e(vz,EBo),e(F4,CBo),e(y,wBo),e(y,T4),e(T4,E2e),e(E2e,ABo),e(T4,LBo),e(T4,bz),e(bz,yBo),e(T4,xBo),e(y,$Bo),e(y,M4),e(M4,C2e),e(C2e,kBo),e(M4,SBo),e(M4,Fz),e(Fz,RBo),e(M4,PBo),e(y,BBo),e(y,E4),e(E4,w2e),e(w2e,IBo),e(E4,NBo),e(E4,Tz),e(Tz,qBo),e(E4,jBo),e(y,DBo),e(y,C4),e(C4,A2e),e(A2e,GBo),e(C4,OBo),e(C4,Mz),e(Mz,VBo),e(C4,XBo),e(y,zBo),e(y,w4),e(w4,L2e),e(L2e,QBo),e(w4,WBo),e(w4,Ez),e(Ez,UBo),e(w4,HBo),e(y,JBo),e(y,A4),e(A4,y2e),e(y2e,YBo),e(A4,ZBo),e(A4,Cz),e(Cz,KBo),e(A4,eIo),e(y,oIo),e(y,L4),e(L4,x2e),e(x2e,rIo),e(L4,tIo),e(L4,wz),e(wz,aIo),e(L4,nIo),e(y,sIo),e(y,y4),e(y4,$2e),e($2e,lIo),e(y4,iIo),e(y4,Az),e(Az,dIo),e(y4,cIo),e(y,fIo),e(y,x4),e(x4,k2e),e(k2e,mIo),e(x4,gIo),e(x4,Lz),e(Lz,hIo),e(x4,uIo),e(y,pIo),e(y,$4),e($4,S2e),e(S2e,_Io),e($4,vIo),e($4,yz),e(yz,bIo),e($4,FIo),e(y,TIo),e(y,k4),e(k4,R2e),e(R2e,MIo),e(k4,EIo),e(k4,xz),e(xz,CIo),e(k4,wIo),e(y,AIo),e(y,S4),e(S4,P2e),e(P2e,LIo),e(S4,yIo),e(S4,$z),e($z,xIo),e(S4,$Io),e(y,kIo),e(y,R4),e(R4,B2e),e(B2e,SIo),e(R4,RIo),e(R4,kz),e(kz,PIo),e(R4,BIo),e(y,IIo),e(y,P4),e(P4,I2e),e(I2e,NIo),e(P4,qIo),e(P4,Sz),e(Sz,jIo),e(P4,DIo),e(y,GIo),e(y,B4),e(B4,N2e),e(N2e,OIo),e(B4,VIo),e(B4,Rz),e(Rz,XIo),e(B4,zIo),e(y,QIo),e(y,I4),e(I4,q2e),e(q2e,WIo),e(I4,UIo),e(I4,Pz),e(Pz,HIo),e(I4,JIo),e(y,YIo),e(y,N4),e(N4,j2e),e(j2e,ZIo),e(N4,KIo),e(N4,Bz),e(Bz,eNo),e(N4,oNo),e(y,rNo),e(y,q4),e(q4,D2e),e(D2e,tNo),e(q4,aNo),e(q4,Iz),e(Iz,nNo),e(q4,sNo),e(y,lNo),e(y,j4),e(j4,G2e),e(G2e,iNo),e(j4,dNo),e(j4,Nz),e(Nz,cNo),e(j4,fNo),e(y,mNo),e(y,D4),e(D4,O2e),e(O2e,gNo),e(D4,hNo),e(D4,qz),e(qz,uNo),e(D4,pNo),e(y,_No),e(y,G4),e(G4,V2e),e(V2e,vNo),e(G4,bNo),e(G4,jz),e(jz,FNo),e(G4,TNo),e(y,MNo),e(y,O4),e(O4,X2e),e(X2e,ENo),e(O4,CNo),e(O4,Dz),e(Dz,wNo),e(O4,ANo),e(y,LNo),e(y,V4),e(V4,z2e),e(z2e,yNo),e(V4,xNo),e(V4,Gz),e(Gz,$No),e(V4,kNo),e(y,SNo),e(y,X4),e(X4,Q2e),e(Q2e,RNo),e(X4,PNo),e(X4,Oz),e(Oz,BNo),e(X4,INo),e(y,NNo),e(y,z4),e(z4,W2e),e(W2e,qNo),e(z4,jNo),e(z4,Vz),e(Vz,DNo),e(z4,GNo),e(y,ONo),e(y,Q4),e(Q4,U2e),e(U2e,VNo),e(Q4,XNo),e(Q4,Xz),e(Xz,zNo),e(Q4,QNo),e(y,WNo),e(y,W4),e(W4,H2e),e(H2e,UNo),e(W4,HNo),e(W4,zz),e(zz,JNo),e(W4,YNo),e(y,ZNo),e(y,U4),e(U4,J2e),e(J2e,KNo),e(U4,eqo),e(U4,Qz),e(Qz,oqo),e(U4,rqo),e(y,tqo),e(y,H4),e(H4,Y2e),e(Y2e,aqo),e(H4,nqo),e(H4,Wz),e(Wz,sqo),e(H4,lqo),e(y,iqo),e(y,J4),e(J4,Z2e),e(Z2e,dqo),e(J4,cqo),e(J4,Uz),e(Uz,fqo),e(J4,mqo),e(y,gqo),e(y,Y4),e(Y4,K2e),e(K2e,hqo),e(Y4,uqo),e(Y4,Hz),e(Hz,pqo),e(Y4,_qo),e(y,vqo),e(y,Z4),e(Z4,eve),e(eve,bqo),e(Z4,Fqo),e(Z4,Jz),e(Jz,Tqo),e(Z4,Mqo),e(y,Eqo),e(y,K4),e(K4,ove),e(ove,Cqo),e(K4,wqo),e(K4,Yz),e(Yz,Aqo),e(K4,Lqo),e(y,yqo),e(y,e2),e(e2,rve),e(rve,xqo),e(e2,$qo),e(e2,Zz),e(Zz,kqo),e(e2,Sqo),e(y,Rqo),e(y,o2),e(o2,tve),e(tve,Pqo),e(o2,Bqo),e(o2,Kz),e(Kz,Iqo),e(o2,Nqo),e(y,qqo),e(y,r2),e(r2,ave),e(ave,jqo),e(r2,Dqo),e(r2,eQ),e(eQ,Gqo),e(r2,Oqo),e(y,Vqo),e(y,t2),e(t2,nve),e(nve,Xqo),e(t2,zqo),e(t2,oQ),e(oQ,Qqo),e(t2,Wqo),e(y,Uqo),e(y,a2),e(a2,sve),e(sve,Hqo),e(a2,Jqo),e(a2,rQ),e(rQ,Yqo),e(a2,Zqo),e(y,Kqo),e(y,n2),e(n2,lve),e(lve,ejo),e(n2,ojo),e(n2,tQ),e(tQ,rjo),e(n2,tjo),e(y,ajo),e(y,s2),e(s2,ive),e(ive,njo),e(s2,sjo),e(s2,aQ),e(aQ,ljo),e(s2,ijo),e(y,djo),e(y,l2),e(l2,dve),e(dve,cjo),e(l2,fjo),e(l2,nQ),e(nQ,mjo),e(l2,gjo),e(y,hjo),e(y,i2),e(i2,cve),e(cve,ujo),e(i2,pjo),e(i2,sQ),e(sQ,_jo),e(i2,vjo),e(y,bjo),e(y,d2),e(d2,fve),e(fve,Fjo),e(d2,Tjo),e(d2,lQ),e(lQ,Mjo),e(d2,Ejo),e(y,Cjo),e(y,c2),e(c2,mve),e(mve,wjo),e(c2,Ajo),e(c2,iQ),e(iQ,Ljo),e(c2,yjo),e(y,xjo),e(y,f2),e(f2,gve),e(gve,$jo),e(f2,kjo),e(f2,dQ),e(dQ,Sjo),e(f2,Rjo),e(y,Pjo),e(y,m2),e(m2,hve),e(hve,Bjo),e(m2,Ijo),e(m2,cQ),e(cQ,Njo),e(m2,qjo),e(y,jjo),e(y,g2),e(g2,uve),e(uve,Djo),e(g2,Gjo),e(g2,fQ),e(fQ,Ojo),e(g2,Vjo),e(y,Xjo),e(y,h2),e(h2,pve),e(pve,zjo),e(h2,Qjo),e(h2,mQ),e(mQ,Wjo),e(h2,Ujo),e(y,Hjo),e(y,u2),e(u2,_ve),e(_ve,Jjo),e(u2,Yjo),e(u2,gQ),e(gQ,Zjo),e(u2,Kjo),e(y,eDo),e(y,p2),e(p2,vve),e(vve,oDo),e(p2,rDo),e(p2,hQ),e(hQ,tDo),e(p2,aDo),e(y,nDo),e(y,_2),e(_2,bve),e(bve,sDo),e(_2,lDo),e(_2,uQ),e(uQ,iDo),e(_2,dDo),e(y,cDo),e(y,v2),e(v2,Fve),e(Fve,fDo),e(v2,mDo),e(v2,pQ),e(pQ,gDo),e(v2,hDo),e(y,uDo),e(y,b2),e(b2,Tve),e(Tve,pDo),e(b2,_Do),e(b2,_Q),e(_Q,vDo),e(b2,bDo),e(y,FDo),e(y,F2),e(F2,Mve),e(Mve,TDo),e(F2,MDo),e(F2,vQ),e(vQ,EDo),e(F2,CDo),e(y,wDo),e(y,T2),e(T2,Eve),e(Eve,ADo),e(T2,LDo),e(T2,bQ),e(bQ,yDo),e(T2,xDo),e(y,$Do),e(y,M2),e(M2,Cve),e(Cve,kDo),e(M2,SDo),e(M2,FQ),e(FQ,RDo),e(M2,PDo),e(y,BDo),e(y,E2),e(E2,wve),e(wve,IDo),e(E2,NDo),e(E2,TQ),e(TQ,qDo),e(E2,jDo),e(y,DDo),e(y,C2),e(C2,Ave),e(Ave,GDo),e(C2,ODo),e(C2,MQ),e(MQ,VDo),e(C2,XDo),e(y,zDo),e(y,w2),e(w2,Lve),e(Lve,QDo),e(w2,WDo),e(w2,EQ),e(EQ,UDo),e(w2,HDo),e(y,JDo),e(y,A2),e(A2,yve),e(yve,YDo),e(A2,ZDo),e(A2,CQ),e(CQ,KDo),e(A2,eGo),e(y,oGo),e(y,L2),e(L2,xve),e(xve,rGo),e(L2,tGo),e(L2,wQ),e(wQ,aGo),e(L2,nGo),e(y,sGo),e(y,y2),e(y2,$ve),e($ve,lGo),e(y2,iGo),e(y2,AQ),e(AQ,dGo),e(y2,cGo),e(y,fGo),e(y,x2),e(x2,kve),e(kve,mGo),e(x2,gGo),e(x2,LQ),e(LQ,hGo),e(x2,uGo),e(y,pGo),e(y,$2),e($2,Sve),e(Sve,_Go),e($2,vGo),e($2,yQ),e(yQ,bGo),e($2,FGo),e(y,TGo),e(y,k2),e(k2,Rve),e(Rve,MGo),e(k2,EGo),e(k2,xQ),e(xQ,CGo),e(k2,wGo),e(y,AGo),e(y,S2),e(S2,Pve),e(Pve,LGo),e(S2,yGo),e(S2,$Q),e($Q,xGo),e(S2,$Go),e(y,kGo),e(y,R2),e(R2,Bve),e(Bve,SGo),e(R2,RGo),e(R2,kQ),e(kQ,PGo),e(R2,BGo),e(y,IGo),e(y,P2),e(P2,Ive),e(Ive,NGo),e(P2,qGo),e(P2,SQ),e(SQ,jGo),e(P2,DGo),e(y,GGo),e(y,B2),e(B2,Nve),e(Nve,OGo),e(B2,VGo),e(B2,RQ),e(RQ,XGo),e(B2,zGo),e(y,QGo),e(y,I2),e(I2,qve),e(qve,WGo),e(I2,UGo),e(I2,PQ),e(PQ,HGo),e(I2,JGo),e(y,YGo),e(y,N2),e(N2,jve),e(jve,ZGo),e(N2,KGo),e(N2,BQ),e(BQ,eOo),e(N2,oOo),e(y,rOo),e(y,q2),e(q2,Dve),e(Dve,tOo),e(q2,aOo),e(q2,IQ),e(IQ,nOo),e(q2,sOo),e(y,lOo),e(y,j2),e(j2,Gve),e(Gve,iOo),e(j2,dOo),e(j2,NQ),e(NQ,cOo),e(j2,fOo),e(y,mOo),e(y,D2),e(D2,Ove),e(Ove,gOo),e(D2,hOo),e(D2,qQ),e(qQ,uOo),e(D2,pOo),e(y,_Oo),e(y,G2),e(G2,Vve),e(Vve,vOo),e(G2,bOo),e(G2,jQ),e(jQ,FOo),e(G2,TOo),e(y,MOo),e(y,O2),e(O2,Xve),e(Xve,EOo),e(O2,COo),e(O2,DQ),e(DQ,wOo),e(O2,AOo),e(y,LOo),e(y,V2),e(V2,zve),e(zve,yOo),e(V2,xOo),e(V2,GQ),e(GQ,$Oo),e(V2,kOo),e(y,SOo),e(y,X2),e(X2,Qve),e(Qve,ROo),e(X2,POo),e(X2,OQ),e(OQ,BOo),e(X2,IOo),e(y,NOo),e(y,z2),e(z2,Wve),e(Wve,qOo),e(z2,jOo),e(z2,VQ),e(VQ,DOo),e(z2,GOo),e(y,OOo),e(y,Q2),e(Q2,Uve),e(Uve,VOo),e(Q2,XOo),e(Q2,XQ),e(XQ,zOo),e(Q2,QOo),e(y,WOo),e(y,W2),e(W2,Hve),e(Hve,UOo),e(W2,HOo),e(W2,zQ),e(zQ,JOo),e(W2,YOo),e(y,ZOo),e(y,U2),e(U2,Jve),e(Jve,KOo),e(U2,eVo),e(U2,QQ),e(QQ,oVo),e(U2,rVo),e(y,tVo),e(y,H2),e(H2,Yve),e(Yve,aVo),e(H2,nVo),e(H2,WQ),e(WQ,sVo),e(H2,lVo),e(y,iVo),e(y,J2),e(J2,Zve),e(Zve,dVo),e(J2,cVo),e(J2,UQ),e(UQ,fVo),e(J2,mVo),e(y,gVo),e(y,Y2),e(Y2,Kve),e(Kve,hVo),e(Y2,uVo),e(Y2,HQ),e(HQ,pVo),e(Y2,_Vo),e(y,vVo),e(y,Z2),e(Z2,e1e),e(e1e,bVo),e(Z2,FVo),e(Z2,JQ),e(JQ,TVo),e(Z2,MVo),e(y,EVo),e(y,K2),e(K2,o1e),e(o1e,CVo),e(K2,wVo),e(K2,YQ),e(YQ,AVo),e(K2,LVo),e(Ke,yVo),e(Ke,ev),e(ev,xVo),e(ev,r1e),e(r1e,$Vo),e(ev,kVo),e(ev,t1e),e(t1e,SVo),e(Ke,RVo),M(ov,Ke,null),v(f,Dto,_),v(f,Bd,_),e(Bd,rv),e(rv,a1e),M(D$,a1e,null),e(Bd,PVo),e(Bd,n1e),e(n1e,BVo),v(f,Gto,_),v(f,No,_),M(G$,No,null),e(No,IVo),e(No,Id),e(Id,NVo),e(Id,ZQ),e(ZQ,qVo),e(Id,jVo),e(Id,KQ),e(KQ,DVo),e(Id,GVo),e(No,OVo),e(No,O$),e(O$,VVo),e(O$,s1e),e(s1e,XVo),e(O$,zVo),e(No,QVo),e(No,Et),M(V$,Et,null),e(Et,WVo),e(Et,l1e),e(l1e,UVo),e(Et,HVo),e(Et,Nd),e(Nd,JVo),e(Nd,i1e),e(i1e,YVo),e(Nd,ZVo),e(Nd,eW),e(eW,KVo),e(Nd,eXo),e(Et,oXo),M(tv,Et,null),e(No,rXo),e(No,eo),M(X$,eo,null),e(eo,tXo),e(eo,d1e),e(d1e,aXo),e(eo,nXo),e(eo,sn),e(sn,sXo),e(sn,c1e),e(c1e,lXo),e(sn,iXo),e(sn,f1e),e(f1e,dXo),e(sn,cXo),e(sn,m1e),e(m1e,fXo),e(sn,mXo),e(eo,gXo),e(eo,G),e(G,av),e(av,g1e),e(g1e,hXo),e(av,uXo),e(av,oW),e(oW,pXo),e(av,_Xo),e(G,vXo),e(G,nv),e(nv,h1e),e(h1e,bXo),e(nv,FXo),e(nv,rW),e(rW,TXo),e(nv,MXo),e(G,EXo),e(G,sv),e(sv,u1e),e(u1e,CXo),e(sv,wXo),e(sv,tW),e(tW,AXo),e(sv,LXo),e(G,yXo),e(G,lv),e(lv,p1e),e(p1e,xXo),e(lv,$Xo),e(lv,aW),e(aW,kXo),e(lv,SXo),e(G,RXo),e(G,iv),e(iv,_1e),e(_1e,PXo),e(iv,BXo),e(iv,nW),e(nW,IXo),e(iv,NXo),e(G,qXo),e(G,dv),e(dv,v1e),e(v1e,jXo),e(dv,DXo),e(dv,sW),e(sW,GXo),e(dv,OXo),e(G,VXo),e(G,cv),e(cv,b1e),e(b1e,XXo),e(cv,zXo),e(cv,lW),e(lW,QXo),e(cv,WXo),e(G,UXo),e(G,fv),e(fv,F1e),e(F1e,HXo),e(fv,JXo),e(fv,iW),e(iW,YXo),e(fv,ZXo),e(G,KXo),e(G,mv),e(mv,T1e),e(T1e,ezo),e(mv,ozo),e(mv,dW),e(dW,rzo),e(mv,tzo),e(G,azo),e(G,gv),e(gv,M1e),e(M1e,nzo),e(gv,szo),e(gv,cW),e(cW,lzo),e(gv,izo),e(G,dzo),e(G,hv),e(hv,E1e),e(E1e,czo),e(hv,fzo),e(hv,fW),e(fW,mzo),e(hv,gzo),e(G,hzo),e(G,uv),e(uv,C1e),e(C1e,uzo),e(uv,pzo),e(uv,mW),e(mW,_zo),e(uv,vzo),e(G,bzo),e(G,pv),e(pv,w1e),e(w1e,Fzo),e(pv,Tzo),e(pv,gW),e(gW,Mzo),e(pv,Ezo),e(G,Czo),e(G,_v),e(_v,A1e),e(A1e,wzo),e(_v,Azo),e(_v,hW),e(hW,Lzo),e(_v,yzo),e(G,xzo),e(G,vv),e(vv,L1e),e(L1e,$zo),e(vv,kzo),e(vv,uW),e(uW,Szo),e(vv,Rzo),e(G,Pzo),e(G,bv),e(bv,y1e),e(y1e,Bzo),e(bv,Izo),e(bv,pW),e(pW,Nzo),e(bv,qzo),e(G,jzo),e(G,Fv),e(Fv,x1e),e(x1e,Dzo),e(Fv,Gzo),e(Fv,_W),e(_W,Ozo),e(Fv,Vzo),e(G,Xzo),e(G,Tv),e(Tv,$1e),e($1e,zzo),e(Tv,Qzo),e(Tv,vW),e(vW,Wzo),e(Tv,Uzo),e(G,Hzo),e(G,Mv),e(Mv,k1e),e(k1e,Jzo),e(Mv,Yzo),e(Mv,bW),e(bW,Zzo),e(Mv,Kzo),e(G,eQo),e(G,Ev),e(Ev,S1e),e(S1e,oQo),e(Ev,rQo),e(Ev,FW),e(FW,tQo),e(Ev,aQo),e(G,nQo),e(G,Cv),e(Cv,R1e),e(R1e,sQo),e(Cv,lQo),e(Cv,TW),e(TW,iQo),e(Cv,dQo),e(G,cQo),e(G,wv),e(wv,P1e),e(P1e,fQo),e(wv,mQo),e(wv,MW),e(MW,gQo),e(wv,hQo),e(G,uQo),e(G,Av),e(Av,B1e),e(B1e,pQo),e(Av,_Qo),e(Av,EW),e(EW,vQo),e(Av,bQo),e(G,FQo),e(G,Lv),e(Lv,I1e),e(I1e,TQo),e(Lv,MQo),e(Lv,CW),e(CW,EQo),e(Lv,CQo),e(G,wQo),e(G,yv),e(yv,N1e),e(N1e,AQo),e(yv,LQo),e(yv,wW),e(wW,yQo),e(yv,xQo),e(G,$Qo),e(G,xv),e(xv,q1e),e(q1e,kQo),e(xv,SQo),e(xv,AW),e(AW,RQo),e(xv,PQo),e(G,BQo),e(G,$v),e($v,j1e),e(j1e,IQo),e($v,NQo),e($v,LW),e(LW,qQo),e($v,jQo),e(G,DQo),e(G,kv),e(kv,D1e),e(D1e,GQo),e(kv,OQo),e(kv,yW),e(yW,VQo),e(kv,XQo),e(G,zQo),e(G,Sv),e(Sv,G1e),e(G1e,QQo),e(Sv,WQo),e(Sv,xW),e(xW,UQo),e(Sv,HQo),e(G,JQo),e(G,Rv),e(Rv,O1e),e(O1e,YQo),e(Rv,ZQo),e(Rv,$W),e($W,KQo),e(Rv,eWo),e(G,oWo),e(G,Pv),e(Pv,V1e),e(V1e,rWo),e(Pv,tWo),e(Pv,kW),e(kW,aWo),e(Pv,nWo),e(G,sWo),e(G,Bv),e(Bv,X1e),e(X1e,lWo),e(Bv,iWo),e(Bv,SW),e(SW,dWo),e(Bv,cWo),e(G,fWo),e(G,Iv),e(Iv,z1e),e(z1e,mWo),e(Iv,gWo),e(Iv,RW),e(RW,hWo),e(Iv,uWo),e(G,pWo),e(G,Nv),e(Nv,Q1e),e(Q1e,_Wo),e(Nv,vWo),e(Nv,PW),e(PW,bWo),e(Nv,FWo),e(G,TWo),e(G,qv),e(qv,W1e),e(W1e,MWo),e(qv,EWo),e(qv,BW),e(BW,CWo),e(qv,wWo),e(G,AWo),e(G,jv),e(jv,U1e),e(U1e,LWo),e(jv,yWo),e(jv,IW),e(IW,xWo),e(jv,$Wo),e(G,kWo),e(G,Dv),e(Dv,H1e),e(H1e,SWo),e(Dv,RWo),e(Dv,NW),e(NW,PWo),e(Dv,BWo),e(G,IWo),e(G,Gv),e(Gv,J1e),e(J1e,NWo),e(Gv,qWo),e(Gv,qW),e(qW,jWo),e(Gv,DWo),e(G,GWo),e(G,Ov),e(Ov,Y1e),e(Y1e,OWo),e(Ov,VWo),e(Ov,jW),e(jW,XWo),e(Ov,zWo),e(G,QWo),e(G,Vv),e(Vv,Z1e),e(Z1e,WWo),e(Vv,UWo),e(Vv,DW),e(DW,HWo),e(Vv,JWo),e(G,YWo),e(G,Xv),e(Xv,K1e),e(K1e,ZWo),e(Xv,KWo),e(Xv,GW),e(GW,eUo),e(Xv,oUo),e(G,rUo),e(G,zv),e(zv,ebe),e(ebe,tUo),e(zv,aUo),e(zv,OW),e(OW,nUo),e(zv,sUo),e(G,lUo),e(G,Qv),e(Qv,obe),e(obe,iUo),e(Qv,dUo),e(Qv,VW),e(VW,cUo),e(Qv,fUo),e(G,mUo),e(G,Wv),e(Wv,rbe),e(rbe,gUo),e(Wv,hUo),e(Wv,XW),e(XW,uUo),e(Wv,pUo),e(G,_Uo),e(G,Uv),e(Uv,tbe),e(tbe,vUo),e(Uv,bUo),e(Uv,zW),e(zW,FUo),e(Uv,TUo),e(G,MUo),e(G,Hv),e(Hv,abe),e(abe,EUo),e(Hv,CUo),e(Hv,QW),e(QW,wUo),e(Hv,AUo),e(G,LUo),e(G,Jv),e(Jv,nbe),e(nbe,yUo),e(Jv,xUo),e(Jv,WW),e(WW,$Uo),e(Jv,kUo),e(G,SUo),e(G,Yv),e(Yv,sbe),e(sbe,RUo),e(Yv,PUo),e(Yv,UW),e(UW,BUo),e(Yv,IUo),e(eo,NUo),e(eo,Zv),e(Zv,qUo),e(Zv,lbe),e(lbe,jUo),e(Zv,DUo),e(Zv,ibe),e(ibe,GUo),e(eo,OUo),M(Kv,eo,null),v(f,Oto,_),v(f,qd,_),e(qd,e1),e(e1,dbe),M(z$,dbe,null),e(qd,VUo),e(qd,cbe),e(cbe,XUo),v(f,Vto,_),v(f,qo,_),M(Q$,qo,null),e(qo,zUo),e(qo,jd),e(jd,QUo),e(jd,HW),e(HW,WUo),e(jd,UUo),e(jd,JW),e(JW,HUo),e(jd,JUo),e(qo,YUo),e(qo,W$),e(W$,ZUo),e(W$,fbe),e(fbe,KUo),e(W$,eHo),e(qo,oHo),e(qo,Ct),M(U$,Ct,null),e(Ct,rHo),e(Ct,mbe),e(mbe,tHo),e(Ct,aHo),e(Ct,Dd),e(Dd,nHo),e(Dd,gbe),e(gbe,sHo),e(Dd,lHo),e(Dd,YW),e(YW,iHo),e(Dd,dHo),e(Ct,cHo),M(o1,Ct,null),e(qo,fHo),e(qo,oo),M(H$,oo,null),e(oo,mHo),e(oo,hbe),e(hbe,gHo),e(oo,hHo),e(oo,ln),e(ln,uHo),e(ln,ube),e(ube,pHo),e(ln,_Ho),e(ln,pbe),e(pbe,vHo),e(ln,bHo),e(ln,_be),e(_be,FHo),e(ln,THo),e(oo,MHo),e(oo,W),e(W,r1),e(r1,vbe),e(vbe,EHo),e(r1,CHo),e(r1,ZW),e(ZW,wHo),e(r1,AHo),e(W,LHo),e(W,t1),e(t1,bbe),e(bbe,yHo),e(t1,xHo),e(t1,KW),e(KW,$Ho),e(t1,kHo),e(W,SHo),e(W,a1),e(a1,Fbe),e(Fbe,RHo),e(a1,PHo),e(a1,eU),e(eU,BHo),e(a1,IHo),e(W,NHo),e(W,n1),e(n1,Tbe),e(Tbe,qHo),e(n1,jHo),e(n1,oU),e(oU,DHo),e(n1,GHo),e(W,OHo),e(W,s1),e(s1,Mbe),e(Mbe,VHo),e(s1,XHo),e(s1,rU),e(rU,zHo),e(s1,QHo),e(W,WHo),e(W,l1),e(l1,Ebe),e(Ebe,UHo),e(l1,HHo),e(l1,tU),e(tU,JHo),e(l1,YHo),e(W,ZHo),e(W,i1),e(i1,Cbe),e(Cbe,KHo),e(i1,eJo),e(i1,aU),e(aU,oJo),e(i1,rJo),e(W,tJo),e(W,d1),e(d1,wbe),e(wbe,aJo),e(d1,nJo),e(d1,nU),e(nU,sJo),e(d1,lJo),e(W,iJo),e(W,c1),e(c1,Abe),e(Abe,dJo),e(c1,cJo),e(c1,sU),e(sU,fJo),e(c1,mJo),e(W,gJo),e(W,f1),e(f1,Lbe),e(Lbe,hJo),e(f1,uJo),e(f1,lU),e(lU,pJo),e(f1,_Jo),e(W,vJo),e(W,m1),e(m1,ybe),e(ybe,bJo),e(m1,FJo),e(m1,iU),e(iU,TJo),e(m1,MJo),e(W,EJo),e(W,g1),e(g1,xbe),e(xbe,CJo),e(g1,wJo),e(g1,dU),e(dU,AJo),e(g1,LJo),e(W,yJo),e(W,h1),e(h1,$be),e($be,xJo),e(h1,$Jo),e(h1,cU),e(cU,kJo),e(h1,SJo),e(W,RJo),e(W,u1),e(u1,kbe),e(kbe,PJo),e(u1,BJo),e(u1,fU),e(fU,IJo),e(u1,NJo),e(W,qJo),e(W,p1),e(p1,Sbe),e(Sbe,jJo),e(p1,DJo),e(p1,mU),e(mU,GJo),e(p1,OJo),e(W,VJo),e(W,_1),e(_1,Rbe),e(Rbe,XJo),e(_1,zJo),e(_1,gU),e(gU,QJo),e(_1,WJo),e(W,UJo),e(W,v1),e(v1,Pbe),e(Pbe,HJo),e(v1,JJo),e(v1,hU),e(hU,YJo),e(v1,ZJo),e(W,KJo),e(W,b1),e(b1,Bbe),e(Bbe,eYo),e(b1,oYo),e(b1,uU),e(uU,rYo),e(b1,tYo),e(W,aYo),e(W,F1),e(F1,Ibe),e(Ibe,nYo),e(F1,sYo),e(F1,pU),e(pU,lYo),e(F1,iYo),e(W,dYo),e(W,T1),e(T1,Nbe),e(Nbe,cYo),e(T1,fYo),e(T1,_U),e(_U,mYo),e(T1,gYo),e(W,hYo),e(W,M1),e(M1,qbe),e(qbe,uYo),e(M1,pYo),e(M1,vU),e(vU,_Yo),e(M1,vYo),e(W,bYo),e(W,E1),e(E1,jbe),e(jbe,FYo),e(E1,TYo),e(E1,bU),e(bU,MYo),e(E1,EYo),e(W,CYo),e(W,C1),e(C1,Dbe),e(Dbe,wYo),e(C1,AYo),e(C1,FU),e(FU,LYo),e(C1,yYo),e(W,xYo),e(W,w1),e(w1,Gbe),e(Gbe,$Yo),e(w1,kYo),e(w1,TU),e(TU,SYo),e(w1,RYo),e(W,PYo),e(W,A1),e(A1,Obe),e(Obe,BYo),e(A1,IYo),e(A1,MU),e(MU,NYo),e(A1,qYo),e(W,jYo),e(W,L1),e(L1,Vbe),e(Vbe,DYo),e(L1,GYo),e(L1,EU),e(EU,OYo),e(L1,VYo),e(W,XYo),e(W,y1),e(y1,Xbe),e(Xbe,zYo),e(y1,QYo),e(y1,CU),e(CU,WYo),e(y1,UYo),e(W,HYo),e(W,x1),e(x1,zbe),e(zbe,JYo),e(x1,YYo),e(x1,wU),e(wU,ZYo),e(x1,KYo),e(W,eZo),e(W,$1),e($1,Qbe),e(Qbe,oZo),e($1,rZo),e($1,AU),e(AU,tZo),e($1,aZo),e(W,nZo),e(W,k1),e(k1,Wbe),e(Wbe,sZo),e(k1,lZo),e(k1,LU),e(LU,iZo),e(k1,dZo),e(W,cZo),e(W,S1),e(S1,Ube),e(Ube,fZo),e(S1,mZo),e(S1,yU),e(yU,gZo),e(S1,hZo),e(W,uZo),e(W,R1),e(R1,Hbe),e(Hbe,pZo),e(R1,_Zo),e(R1,xU),e(xU,vZo),e(R1,bZo),e(W,FZo),e(W,P1),e(P1,Jbe),e(Jbe,TZo),e(P1,MZo),e(P1,$U),e($U,EZo),e(P1,CZo),e(W,wZo),e(W,B1),e(B1,Ybe),e(Ybe,AZo),e(B1,LZo),e(B1,kU),e(kU,yZo),e(B1,xZo),e(W,$Zo),e(W,I1),e(I1,Zbe),e(Zbe,kZo),e(I1,SZo),e(I1,SU),e(SU,RZo),e(I1,PZo),e(W,BZo),e(W,N1),e(N1,Kbe),e(Kbe,IZo),e(N1,NZo),e(N1,RU),e(RU,qZo),e(N1,jZo),e(W,DZo),e(W,q1),e(q1,e0e),e(e0e,GZo),e(q1,OZo),e(q1,PU),e(PU,VZo),e(q1,XZo),e(W,zZo),e(W,j1),e(j1,o0e),e(o0e,QZo),e(j1,WZo),e(j1,BU),e(BU,UZo),e(j1,HZo),e(W,JZo),e(W,D1),e(D1,r0e),e(r0e,YZo),e(D1,ZZo),e(D1,IU),e(IU,KZo),e(D1,eKo),e(W,oKo),e(W,G1),e(G1,t0e),e(t0e,rKo),e(G1,tKo),e(G1,NU),e(NU,aKo),e(G1,nKo),e(W,sKo),e(W,O1),e(O1,a0e),e(a0e,lKo),e(O1,iKo),e(O1,qU),e(qU,dKo),e(O1,cKo),e(W,fKo),e(W,V1),e(V1,n0e),e(n0e,mKo),e(V1,gKo),e(V1,jU),e(jU,hKo),e(V1,uKo),e(oo,pKo),e(oo,X1),e(X1,_Ko),e(X1,s0e),e(s0e,vKo),e(X1,bKo),e(X1,l0e),e(l0e,FKo),e(oo,TKo),M(z1,oo,null),v(f,Xto,_),v(f,Gd,_),e(Gd,Q1),e(Q1,i0e),M(J$,i0e,null),e(Gd,MKo),e(Gd,d0e),e(d0e,EKo),v(f,zto,_),v(f,jo,_),M(Y$,jo,null),e(jo,CKo),e(jo,Od),e(Od,wKo),e(Od,DU),e(DU,AKo),e(Od,LKo),e(Od,GU),e(GU,yKo),e(Od,xKo),e(jo,$Ko),e(jo,Z$),e(Z$,kKo),e(Z$,c0e),e(c0e,SKo),e(Z$,RKo),e(jo,PKo),e(jo,wt),M(K$,wt,null),e(wt,BKo),e(wt,f0e),e(f0e,IKo),e(wt,NKo),e(wt,Vd),e(Vd,qKo),e(Vd,m0e),e(m0e,jKo),e(Vd,DKo),e(Vd,OU),e(OU,GKo),e(Vd,OKo),e(wt,VKo),M(W1,wt,null),e(jo,XKo),e(jo,ro),M(ek,ro,null),e(ro,zKo),e(ro,g0e),e(g0e,QKo),e(ro,WKo),e(ro,dn),e(dn,UKo),e(dn,h0e),e(h0e,HKo),e(dn,JKo),e(dn,u0e),e(u0e,YKo),e(dn,ZKo),e(dn,p0e),e(p0e,KKo),e(dn,eer),e(ro,oer),e(ro,ok),e(ok,U1),e(U1,_0e),e(_0e,rer),e(U1,ter),e(U1,VU),e(VU,aer),e(U1,ner),e(ok,ser),e(ok,H1),e(H1,v0e),e(v0e,ler),e(H1,ier),e(H1,XU),e(XU,der),e(H1,cer),e(ro,fer),e(ro,J1),e(J1,mer),e(J1,b0e),e(b0e,ger),e(J1,her),e(J1,F0e),e(F0e,uer),e(ro,per),M(Y1,ro,null),v(f,Qto,_),v(f,Xd,_),e(Xd,Z1),e(Z1,T0e),M(rk,T0e,null),e(Xd,_er),e(Xd,M0e),e(M0e,ver),v(f,Wto,_),v(f,Do,_),M(tk,Do,null),e(Do,ber),e(Do,zd),e(zd,Fer),e(zd,zU),e(zU,Ter),e(zd,Mer),e(zd,QU),e(QU,Eer),e(zd,Cer),e(Do,wer),e(Do,ak),e(ak,Aer),e(ak,E0e),e(E0e,Ler),e(ak,yer),e(Do,xer),e(Do,At),M(nk,At,null),e(At,$er),e(At,C0e),e(C0e,ker),e(At,Ser),e(At,Qd),e(Qd,Rer),e(Qd,w0e),e(w0e,Per),e(Qd,Ber),e(Qd,WU),e(WU,Ier),e(Qd,Ner),e(At,qer),M(K1,At,null),e(Do,jer),e(Do,to),M(sk,to,null),e(to,Der),e(to,A0e),e(A0e,Ger),e(to,Oer),e(to,cn),e(cn,Ver),e(cn,L0e),e(L0e,Xer),e(cn,zer),e(cn,y0e),e(y0e,Qer),e(cn,Wer),e(cn,x0e),e(x0e,Uer),e(cn,Her),e(to,Jer),e(to,Y),e(Y,eb),e(eb,$0e),e($0e,Yer),e(eb,Zer),e(eb,UU),e(UU,Ker),e(eb,eor),e(Y,oor),e(Y,ob),e(ob,k0e),e(k0e,ror),e(ob,tor),e(ob,HU),e(HU,aor),e(ob,nor),e(Y,sor),e(Y,rb),e(rb,S0e),e(S0e,lor),e(rb,ior),e(rb,JU),e(JU,dor),e(rb,cor),e(Y,mor),e(Y,tb),e(tb,R0e),e(R0e,gor),e(tb,hor),e(tb,YU),e(YU,uor),e(tb,por),e(Y,_or),e(Y,ab),e(ab,P0e),e(P0e,vor),e(ab,bor),e(ab,ZU),e(ZU,For),e(ab,Tor),e(Y,Mor),e(Y,nb),e(nb,B0e),e(B0e,Eor),e(nb,Cor),e(nb,KU),e(KU,wor),e(nb,Aor),e(Y,Lor),e(Y,sb),e(sb,I0e),e(I0e,yor),e(sb,xor),e(sb,eH),e(eH,$or),e(sb,kor),e(Y,Sor),e(Y,lb),e(lb,N0e),e(N0e,Ror),e(lb,Por),e(lb,oH),e(oH,Bor),e(lb,Ior),e(Y,Nor),e(Y,ib),e(ib,q0e),e(q0e,qor),e(ib,jor),e(ib,rH),e(rH,Dor),e(ib,Gor),e(Y,Oor),e(Y,db),e(db,j0e),e(j0e,Vor),e(db,Xor),e(db,tH),e(tH,zor),e(db,Qor),e(Y,Wor),e(Y,cb),e(cb,D0e),e(D0e,Uor),e(cb,Hor),e(cb,aH),e(aH,Jor),e(cb,Yor),e(Y,Zor),e(Y,fb),e(fb,G0e),e(G0e,Kor),e(fb,err),e(fb,nH),e(nH,orr),e(fb,rrr),e(Y,trr),e(Y,mb),e(mb,O0e),e(O0e,arr),e(mb,nrr),e(mb,sH),e(sH,srr),e(mb,lrr),e(Y,irr),e(Y,gb),e(gb,V0e),e(V0e,drr),e(gb,crr),e(gb,lH),e(lH,frr),e(gb,mrr),e(Y,grr),e(Y,hb),e(hb,X0e),e(X0e,hrr),e(hb,urr),e(hb,iH),e(iH,prr),e(hb,_rr),e(Y,vrr),e(Y,ub),e(ub,z0e),e(z0e,brr),e(ub,Frr),e(ub,dH),e(dH,Trr),e(ub,Mrr),e(Y,Err),e(Y,pb),e(pb,Q0e),e(Q0e,Crr),e(pb,wrr),e(pb,cH),e(cH,Arr),e(pb,Lrr),e(Y,yrr),e(Y,_b),e(_b,W0e),e(W0e,xrr),e(_b,$rr),e(_b,fH),e(fH,krr),e(_b,Srr),e(Y,Rrr),e(Y,vb),e(vb,U0e),e(U0e,Prr),e(vb,Brr),e(vb,mH),e(mH,Irr),e(vb,Nrr),e(Y,qrr),e(Y,bb),e(bb,H0e),e(H0e,jrr),e(bb,Drr),e(bb,gH),e(gH,Grr),e(bb,Orr),e(Y,Vrr),e(Y,Fb),e(Fb,J0e),e(J0e,Xrr),e(Fb,zrr),e(Fb,hH),e(hH,Qrr),e(Fb,Wrr),e(Y,Urr),e(Y,Tb),e(Tb,Y0e),e(Y0e,Hrr),e(Tb,Jrr),e(Tb,uH),e(uH,Yrr),e(Tb,Zrr),e(Y,Krr),e(Y,Mb),e(Mb,Z0e),e(Z0e,etr),e(Mb,otr),e(Mb,pH),e(pH,rtr),e(Mb,ttr),e(Y,atr),e(Y,Eb),e(Eb,K0e),e(K0e,ntr),e(Eb,str),e(Eb,_H),e(_H,ltr),e(Eb,itr),e(Y,dtr),e(Y,Cb),e(Cb,eFe),e(eFe,ctr),e(Cb,ftr),e(Cb,vH),e(vH,mtr),e(Cb,gtr),e(Y,htr),e(Y,wb),e(wb,oFe),e(oFe,utr),e(wb,ptr),e(wb,bH),e(bH,_tr),e(wb,vtr),e(Y,btr),e(Y,Ab),e(Ab,rFe),e(rFe,Ftr),e(Ab,Ttr),e(Ab,FH),e(FH,Mtr),e(Ab,Etr),e(Y,Ctr),e(Y,Lb),e(Lb,tFe),e(tFe,wtr),e(Lb,Atr),e(Lb,TH),e(TH,Ltr),e(Lb,ytr),e(Y,xtr),e(Y,yb),e(yb,aFe),e(aFe,$tr),e(yb,ktr),e(yb,MH),e(MH,Str),e(yb,Rtr),e(Y,Ptr),e(Y,xb),e(xb,nFe),e(nFe,Btr),e(xb,Itr),e(xb,EH),e(EH,Ntr),e(xb,qtr),e(Y,jtr),e(Y,$b),e($b,sFe),e(sFe,Dtr),e($b,Gtr),e($b,CH),e(CH,Otr),e($b,Vtr),e(Y,Xtr),e(Y,kb),e(kb,lFe),e(lFe,ztr),e(kb,Qtr),e(kb,wH),e(wH,Wtr),e(kb,Utr),e(Y,Htr),e(Y,Sb),e(Sb,iFe),e(iFe,Jtr),e(Sb,Ytr),e(Sb,AH),e(AH,Ztr),e(Sb,Ktr),e(Y,ear),e(Y,Rb),e(Rb,dFe),e(dFe,oar),e(Rb,rar),e(Rb,LH),e(LH,tar),e(Rb,aar),e(Y,nar),e(Y,Pb),e(Pb,cFe),e(cFe,sar),e(Pb,lar),e(Pb,fFe),e(fFe,iar),e(Pb,dar),e(Y,car),e(Y,Bb),e(Bb,mFe),e(mFe,far),e(Bb,mar),e(Bb,yH),e(yH,gar),e(Bb,har),e(Y,uar),e(Y,Ib),e(Ib,gFe),e(gFe,par),e(Ib,_ar),e(Ib,xH),e(xH,bar),e(Ib,Far),e(Y,Tar),e(Y,Nb),e(Nb,hFe),e(hFe,Mar),e(Nb,Ear),e(Nb,$H),e($H,Car),e(Nb,war),e(Y,Aar),e(Y,qb),e(qb,uFe),e(uFe,Lar),e(qb,yar),e(qb,kH),e(kH,xar),e(qb,$ar),e(to,kar),e(to,jb),e(jb,Sar),e(jb,pFe),e(pFe,Rar),e(jb,Par),e(jb,_Fe),e(_Fe,Bar),e(to,Iar),M(Db,to,null),v(f,Uto,_),v(f,Wd,_),e(Wd,Gb),e(Gb,vFe),M(lk,vFe,null),e(Wd,Nar),e(Wd,bFe),e(bFe,qar),v(f,Hto,_),v(f,Go,_),M(ik,Go,null),e(Go,jar),e(Go,Ud),e(Ud,Dar),e(Ud,SH),e(SH,Gar),e(Ud,Oar),e(Ud,RH),e(RH,Var),e(Ud,Xar),e(Go,zar),e(Go,dk),e(dk,Qar),e(dk,FFe),e(FFe,War),e(dk,Uar),e(Go,Har),e(Go,Lt),M(ck,Lt,null),e(Lt,Jar),e(Lt,TFe),e(TFe,Yar),e(Lt,Zar),e(Lt,Hd),e(Hd,Kar),e(Hd,MFe),e(MFe,enr),e(Hd,onr),e(Hd,PH),e(PH,rnr),e(Hd,tnr),e(Lt,anr),M(Ob,Lt,null),e(Go,nnr),e(Go,ao),M(fk,ao,null),e(ao,snr),e(ao,EFe),e(EFe,lnr),e(ao,inr),e(ao,fn),e(fn,dnr),e(fn,CFe),e(CFe,cnr),e(fn,fnr),e(fn,wFe),e(wFe,mnr),e(fn,gnr),e(fn,AFe),e(AFe,hnr),e(fn,unr),e(ao,pnr),e(ao,he),e(he,Vb),e(Vb,LFe),e(LFe,_nr),e(Vb,vnr),e(Vb,BH),e(BH,bnr),e(Vb,Fnr),e(he,Tnr),e(he,Xb),e(Xb,yFe),e(yFe,Mnr),e(Xb,Enr),e(Xb,IH),e(IH,Cnr),e(Xb,wnr),e(he,Anr),e(he,zb),e(zb,xFe),e(xFe,Lnr),e(zb,ynr),e(zb,NH),e(NH,xnr),e(zb,$nr),e(he,knr),e(he,Qb),e(Qb,$Fe),e($Fe,Snr),e(Qb,Rnr),e(Qb,qH),e(qH,Pnr),e(Qb,Bnr),e(he,Inr),e(he,Wb),e(Wb,kFe),e(kFe,Nnr),e(Wb,qnr),e(Wb,jH),e(jH,jnr),e(Wb,Dnr),e(he,Gnr),e(he,Ub),e(Ub,SFe),e(SFe,Onr),e(Ub,Vnr),e(Ub,DH),e(DH,Xnr),e(Ub,znr),e(he,Qnr),e(he,Hb),e(Hb,RFe),e(RFe,Wnr),e(Hb,Unr),e(Hb,GH),e(GH,Hnr),e(Hb,Jnr),e(he,Ynr),e(he,Jb),e(Jb,PFe),e(PFe,Znr),e(Jb,Knr),e(Jb,OH),e(OH,esr),e(Jb,osr),e(he,rsr),e(he,Yb),e(Yb,BFe),e(BFe,tsr),e(Yb,asr),e(Yb,VH),e(VH,nsr),e(Yb,ssr),e(he,lsr),e(he,Zb),e(Zb,IFe),e(IFe,isr),e(Zb,dsr),e(Zb,XH),e(XH,csr),e(Zb,fsr),e(he,msr),e(he,Kb),e(Kb,NFe),e(NFe,gsr),e(Kb,hsr),e(Kb,zH),e(zH,usr),e(Kb,psr),e(he,_sr),e(he,e0),e(e0,qFe),e(qFe,vsr),e(e0,bsr),e(e0,QH),e(QH,Fsr),e(e0,Tsr),e(he,Msr),e(he,o0),e(o0,jFe),e(jFe,Esr),e(o0,Csr),e(o0,WH),e(WH,wsr),e(o0,Asr),e(he,Lsr),e(he,r0),e(r0,DFe),e(DFe,ysr),e(r0,xsr),e(r0,UH),e(UH,$sr),e(r0,ksr),e(he,Ssr),e(he,t0),e(t0,GFe),e(GFe,Rsr),e(t0,Psr),e(t0,HH),e(HH,Bsr),e(t0,Isr),e(he,Nsr),e(he,a0),e(a0,OFe),e(OFe,qsr),e(a0,jsr),e(a0,JH),e(JH,Dsr),e(a0,Gsr),e(he,Osr),e(he,n0),e(n0,VFe),e(VFe,Vsr),e(n0,Xsr),e(n0,YH),e(YH,zsr),e(n0,Qsr),e(he,Wsr),e(he,s0),e(s0,XFe),e(XFe,Usr),e(s0,Hsr),e(s0,ZH),e(ZH,Jsr),e(s0,Ysr),e(he,Zsr),e(he,l0),e(l0,zFe),e(zFe,Ksr),e(l0,elr),e(l0,KH),e(KH,olr),e(l0,rlr),e(he,tlr),e(he,i0),e(i0,QFe),e(QFe,alr),e(i0,nlr),e(i0,eJ),e(eJ,slr),e(i0,llr),e(ao,ilr),e(ao,d0),e(d0,dlr),e(d0,WFe),e(WFe,clr),e(d0,flr),e(d0,UFe),e(UFe,mlr),e(ao,glr),M(c0,ao,null),v(f,Jto,_),v(f,Jd,_),e(Jd,f0),e(f0,HFe),M(mk,HFe,null),e(Jd,hlr),e(Jd,JFe),e(JFe,ulr),v(f,Yto,_),v(f,Oo,_),M(gk,Oo,null),e(Oo,plr),e(Oo,Yd),e(Yd,_lr),e(Yd,oJ),e(oJ,vlr),e(Yd,blr),e(Yd,rJ),e(rJ,Flr),e(Yd,Tlr),e(Oo,Mlr),e(Oo,hk),e(hk,Elr),e(hk,YFe),e(YFe,Clr),e(hk,wlr),e(Oo,Alr),e(Oo,yt),M(uk,yt,null),e(yt,Llr),e(yt,ZFe),e(ZFe,ylr),e(yt,xlr),e(yt,Zd),e(Zd,$lr),e(Zd,KFe),e(KFe,klr),e(Zd,Slr),e(Zd,tJ),e(tJ,Rlr),e(Zd,Plr),e(yt,Blr),M(m0,yt,null),e(Oo,Ilr),e(Oo,no),M(pk,no,null),e(no,Nlr),e(no,eTe),e(eTe,qlr),e(no,jlr),e(no,mn),e(mn,Dlr),e(mn,oTe),e(oTe,Glr),e(mn,Olr),e(mn,rTe),e(rTe,Vlr),e(mn,Xlr),e(mn,tTe),e(tTe,zlr),e(mn,Qlr),e(no,Wlr),e(no,j),e(j,g0),e(g0,aTe),e(aTe,Ulr),e(g0,Hlr),e(g0,aJ),e(aJ,Jlr),e(g0,Ylr),e(j,Zlr),e(j,h0),e(h0,nTe),e(nTe,Klr),e(h0,eir),e(h0,nJ),e(nJ,oir),e(h0,rir),e(j,tir),e(j,u0),e(u0,sTe),e(sTe,air),e(u0,nir),e(u0,sJ),e(sJ,sir),e(u0,lir),e(j,iir),e(j,p0),e(p0,lTe),e(lTe,dir),e(p0,cir),e(p0,lJ),e(lJ,fir),e(p0,mir),e(j,gir),e(j,_0),e(_0,iTe),e(iTe,hir),e(_0,uir),e(_0,iJ),e(iJ,pir),e(_0,_ir),e(j,vir),e(j,v0),e(v0,dTe),e(dTe,bir),e(v0,Fir),e(v0,dJ),e(dJ,Tir),e(v0,Mir),e(j,Eir),e(j,b0),e(b0,cTe),e(cTe,Cir),e(b0,wir),e(b0,cJ),e(cJ,Air),e(b0,Lir),e(j,yir),e(j,F0),e(F0,fTe),e(fTe,xir),e(F0,$ir),e(F0,fJ),e(fJ,kir),e(F0,Sir),e(j,Rir),e(j,T0),e(T0,mTe),e(mTe,Pir),e(T0,Bir),e(T0,mJ),e(mJ,Iir),e(T0,Nir),e(j,qir),e(j,M0),e(M0,gTe),e(gTe,jir),e(M0,Dir),e(M0,gJ),e(gJ,Gir),e(M0,Oir),e(j,Vir),e(j,E0),e(E0,hTe),e(hTe,Xir),e(E0,zir),e(E0,hJ),e(hJ,Qir),e(E0,Wir),e(j,Uir),e(j,C0),e(C0,uTe),e(uTe,Hir),e(C0,Jir),e(C0,uJ),e(uJ,Yir),e(C0,Zir),e(j,Kir),e(j,w0),e(w0,pTe),e(pTe,edr),e(w0,odr),e(w0,pJ),e(pJ,rdr),e(w0,tdr),e(j,adr),e(j,A0),e(A0,_Te),e(_Te,ndr),e(A0,sdr),e(A0,_J),e(_J,ldr),e(A0,idr),e(j,ddr),e(j,L0),e(L0,vTe),e(vTe,cdr),e(L0,fdr),e(L0,vJ),e(vJ,mdr),e(L0,gdr),e(j,hdr),e(j,y0),e(y0,bTe),e(bTe,udr),e(y0,pdr),e(y0,bJ),e(bJ,_dr),e(y0,vdr),e(j,bdr),e(j,x0),e(x0,FTe),e(FTe,Fdr),e(x0,Tdr),e(x0,FJ),e(FJ,Mdr),e(x0,Edr),e(j,Cdr),e(j,$0),e($0,TTe),e(TTe,wdr),e($0,Adr),e($0,TJ),e(TJ,Ldr),e($0,ydr),e(j,xdr),e(j,k0),e(k0,MTe),e(MTe,$dr),e(k0,kdr),e(k0,MJ),e(MJ,Sdr),e(k0,Rdr),e(j,Pdr),e(j,S0),e(S0,ETe),e(ETe,Bdr),e(S0,Idr),e(S0,EJ),e(EJ,Ndr),e(S0,qdr),e(j,jdr),e(j,R0),e(R0,CTe),e(CTe,Ddr),e(R0,Gdr),e(R0,CJ),e(CJ,Odr),e(R0,Vdr),e(j,Xdr),e(j,P0),e(P0,wTe),e(wTe,zdr),e(P0,Qdr),e(P0,wJ),e(wJ,Wdr),e(P0,Udr),e(j,Hdr),e(j,B0),e(B0,ATe),e(ATe,Jdr),e(B0,Ydr),e(B0,AJ),e(AJ,Zdr),e(B0,Kdr),e(j,ecr),e(j,I0),e(I0,LTe),e(LTe,ocr),e(I0,rcr),e(I0,LJ),e(LJ,tcr),e(I0,acr),e(j,ncr),e(j,N0),e(N0,yTe),e(yTe,scr),e(N0,lcr),e(N0,yJ),e(yJ,icr),e(N0,dcr),e(j,ccr),e(j,q0),e(q0,xTe),e(xTe,fcr),e(q0,mcr),e(q0,xJ),e(xJ,gcr),e(q0,hcr),e(j,ucr),e(j,j0),e(j0,$Te),e($Te,pcr),e(j0,_cr),e(j0,$J),e($J,vcr),e(j0,bcr),e(j,Fcr),e(j,D0),e(D0,kTe),e(kTe,Tcr),e(D0,Mcr),e(D0,kJ),e(kJ,Ecr),e(D0,Ccr),e(j,wcr),e(j,G0),e(G0,STe),e(STe,Acr),e(G0,Lcr),e(G0,SJ),e(SJ,ycr),e(G0,xcr),e(j,$cr),e(j,O0),e(O0,RTe),e(RTe,kcr),e(O0,Scr),e(O0,RJ),e(RJ,Rcr),e(O0,Pcr),e(j,Bcr),e(j,V0),e(V0,PTe),e(PTe,Icr),e(V0,Ncr),e(V0,PJ),e(PJ,qcr),e(V0,jcr),e(j,Dcr),e(j,X0),e(X0,BTe),e(BTe,Gcr),e(X0,Ocr),e(X0,BJ),e(BJ,Vcr),e(X0,Xcr),e(j,zcr),e(j,z0),e(z0,ITe),e(ITe,Qcr),e(z0,Wcr),e(z0,IJ),e(IJ,Ucr),e(z0,Hcr),e(j,Jcr),e(j,Q0),e(Q0,NTe),e(NTe,Ycr),e(Q0,Zcr),e(Q0,NJ),e(NJ,Kcr),e(Q0,efr),e(j,ofr),e(j,W0),e(W0,qTe),e(qTe,rfr),e(W0,tfr),e(W0,qJ),e(qJ,afr),e(W0,nfr),e(j,sfr),e(j,U0),e(U0,jTe),e(jTe,lfr),e(U0,ifr),e(U0,jJ),e(jJ,dfr),e(U0,cfr),e(j,ffr),e(j,H0),e(H0,DTe),e(DTe,mfr),e(H0,gfr),e(H0,DJ),e(DJ,hfr),e(H0,ufr),e(j,pfr),e(j,J0),e(J0,GTe),e(GTe,_fr),e(J0,vfr),e(J0,GJ),e(GJ,bfr),e(J0,Ffr),e(j,Tfr),e(j,Y0),e(Y0,OTe),e(OTe,Mfr),e(Y0,Efr),e(Y0,OJ),e(OJ,Cfr),e(Y0,wfr),e(j,Afr),e(j,Z0),e(Z0,VTe),e(VTe,Lfr),e(Z0,yfr),e(Z0,VJ),e(VJ,xfr),e(Z0,$fr),e(j,kfr),e(j,K0),e(K0,XTe),e(XTe,Sfr),e(K0,Rfr),e(K0,XJ),e(XJ,Pfr),e(K0,Bfr),e(j,Ifr),e(j,eF),e(eF,zTe),e(zTe,Nfr),e(eF,qfr),e(eF,zJ),e(zJ,jfr),e(eF,Dfr),e(j,Gfr),e(j,oF),e(oF,QTe),e(QTe,Ofr),e(oF,Vfr),e(oF,QJ),e(QJ,Xfr),e(oF,zfr),e(j,Qfr),e(j,rF),e(rF,WTe),e(WTe,Wfr),e(rF,Ufr),e(rF,WJ),e(WJ,Hfr),e(rF,Jfr),e(j,Yfr),e(j,tF),e(tF,UTe),e(UTe,Zfr),e(tF,Kfr),e(tF,UJ),e(UJ,emr),e(tF,omr),e(j,rmr),e(j,aF),e(aF,HTe),e(HTe,tmr),e(aF,amr),e(aF,HJ),e(HJ,nmr),e(aF,smr),e(j,lmr),e(j,nF),e(nF,JTe),e(JTe,imr),e(nF,dmr),e(nF,JJ),e(JJ,cmr),e(nF,fmr),e(j,mmr),e(j,sF),e(sF,YTe),e(YTe,gmr),e(sF,hmr),e(sF,YJ),e(YJ,umr),e(sF,pmr),e(j,_mr),e(j,lF),e(lF,ZTe),e(ZTe,vmr),e(lF,bmr),e(lF,ZJ),e(ZJ,Fmr),e(lF,Tmr),e(j,Mmr),e(j,iF),e(iF,KTe),e(KTe,Emr),e(iF,Cmr),e(iF,KJ),e(KJ,wmr),e(iF,Amr),e(j,Lmr),e(j,dF),e(dF,eMe),e(eMe,ymr),e(dF,xmr),e(dF,eY),e(eY,$mr),e(dF,kmr),e(j,Smr),e(j,cF),e(cF,oMe),e(oMe,Rmr),e(cF,Pmr),e(cF,oY),e(oY,Bmr),e(cF,Imr),e(j,Nmr),e(j,fF),e(fF,rMe),e(rMe,qmr),e(fF,jmr),e(fF,rY),e(rY,Dmr),e(fF,Gmr),e(j,Omr),e(j,mF),e(mF,tMe),e(tMe,Vmr),e(mF,Xmr),e(mF,tY),e(tY,zmr),e(mF,Qmr),e(j,Wmr),e(j,gF),e(gF,aMe),e(aMe,Umr),e(gF,Hmr),e(gF,aY),e(aY,Jmr),e(gF,Ymr),e(j,Zmr),e(j,hF),e(hF,nMe),e(nMe,Kmr),e(hF,egr),e(hF,nY),e(nY,ogr),e(hF,rgr),e(no,tgr),e(no,uF),e(uF,agr),e(uF,sMe),e(sMe,ngr),e(uF,sgr),e(uF,lMe),e(lMe,lgr),e(no,igr),M(pF,no,null),v(f,Zto,_),v(f,Kd,_),e(Kd,_F),e(_F,iMe),M(_k,iMe,null),e(Kd,dgr),e(Kd,dMe),e(dMe,cgr),v(f,Kto,_),v(f,Vo,_),M(vk,Vo,null),e(Vo,fgr),e(Vo,ec),e(ec,mgr),e(ec,sY),e(sY,ggr),e(ec,hgr),e(ec,lY),e(lY,ugr),e(ec,pgr),e(Vo,_gr),e(Vo,bk),e(bk,vgr),e(bk,cMe),e(cMe,bgr),e(bk,Fgr),e(Vo,Tgr),e(Vo,xt),M(Fk,xt,null),e(xt,Mgr),e(xt,fMe),e(fMe,Egr),e(xt,Cgr),e(xt,oc),e(oc,wgr),e(oc,mMe),e(mMe,Agr),e(oc,Lgr),e(oc,iY),e(iY,ygr),e(oc,xgr),e(xt,$gr),M(vF,xt,null),e(Vo,kgr),e(Vo,so),M(Tk,so,null),e(so,Sgr),e(so,gMe),e(gMe,Rgr),e(so,Pgr),e(so,gn),e(gn,Bgr),e(gn,hMe),e(hMe,Igr),e(gn,Ngr),e(gn,uMe),e(uMe,qgr),e(gn,jgr),e(gn,pMe),e(pMe,Dgr),e(gn,Ggr),e(so,Ogr),e(so,K),e(K,bF),e(bF,_Me),e(_Me,Vgr),e(bF,Xgr),e(bF,dY),e(dY,zgr),e(bF,Qgr),e(K,Wgr),e(K,FF),e(FF,vMe),e(vMe,Ugr),e(FF,Hgr),e(FF,cY),e(cY,Jgr),e(FF,Ygr),e(K,Zgr),e(K,TF),e(TF,bMe),e(bMe,Kgr),e(TF,ehr),e(TF,fY),e(fY,ohr),e(TF,rhr),e(K,thr),e(K,MF),e(MF,FMe),e(FMe,ahr),e(MF,nhr),e(MF,mY),e(mY,shr),e(MF,lhr),e(K,ihr),e(K,EF),e(EF,TMe),e(TMe,dhr),e(EF,chr),e(EF,gY),e(gY,fhr),e(EF,mhr),e(K,ghr),e(K,CF),e(CF,MMe),e(MMe,hhr),e(CF,uhr),e(CF,hY),e(hY,phr),e(CF,_hr),e(K,vhr),e(K,wF),e(wF,EMe),e(EMe,bhr),e(wF,Fhr),e(wF,uY),e(uY,Thr),e(wF,Mhr),e(K,Ehr),e(K,AF),e(AF,CMe),e(CMe,Chr),e(AF,whr),e(AF,pY),e(pY,Ahr),e(AF,Lhr),e(K,yhr),e(K,LF),e(LF,wMe),e(wMe,xhr),e(LF,$hr),e(LF,_Y),e(_Y,khr),e(LF,Shr),e(K,Rhr),e(K,yF),e(yF,AMe),e(AMe,Phr),e(yF,Bhr),e(yF,vY),e(vY,Ihr),e(yF,Nhr),e(K,qhr),e(K,xF),e(xF,LMe),e(LMe,jhr),e(xF,Dhr),e(xF,bY),e(bY,Ghr),e(xF,Ohr),e(K,Vhr),e(K,$F),e($F,yMe),e(yMe,Xhr),e($F,zhr),e($F,FY),e(FY,Qhr),e($F,Whr),e(K,Uhr),e(K,kF),e(kF,xMe),e(xMe,Hhr),e(kF,Jhr),e(kF,TY),e(TY,Yhr),e(kF,Zhr),e(K,Khr),e(K,SF),e(SF,$Me),e($Me,eur),e(SF,our),e(SF,MY),e(MY,rur),e(SF,tur),e(K,aur),e(K,RF),e(RF,kMe),e(kMe,nur),e(RF,sur),e(RF,EY),e(EY,lur),e(RF,iur),e(K,dur),e(K,PF),e(PF,SMe),e(SMe,cur),e(PF,fur),e(PF,CY),e(CY,mur),e(PF,gur),e(K,hur),e(K,BF),e(BF,RMe),e(RMe,uur),e(BF,pur),e(BF,wY),e(wY,_ur),e(BF,vur),e(K,bur),e(K,IF),e(IF,PMe),e(PMe,Fur),e(IF,Tur),e(IF,AY),e(AY,Mur),e(IF,Eur),e(K,Cur),e(K,NF),e(NF,BMe),e(BMe,wur),e(NF,Aur),e(NF,LY),e(LY,Lur),e(NF,yur),e(K,xur),e(K,qF),e(qF,IMe),e(IMe,$ur),e(qF,kur),e(qF,yY),e(yY,Sur),e(qF,Rur),e(K,Pur),e(K,jF),e(jF,NMe),e(NMe,Bur),e(jF,Iur),e(jF,xY),e(xY,Nur),e(jF,qur),e(K,jur),e(K,DF),e(DF,qMe),e(qMe,Dur),e(DF,Gur),e(DF,$Y),e($Y,Our),e(DF,Vur),e(K,Xur),e(K,GF),e(GF,jMe),e(jMe,zur),e(GF,Qur),e(GF,kY),e(kY,Wur),e(GF,Uur),e(K,Hur),e(K,OF),e(OF,DMe),e(DMe,Jur),e(OF,Yur),e(OF,SY),e(SY,Zur),e(OF,Kur),e(K,epr),e(K,VF),e(VF,GMe),e(GMe,opr),e(VF,rpr),e(VF,RY),e(RY,tpr),e(VF,apr),e(K,npr),e(K,XF),e(XF,OMe),e(OMe,spr),e(XF,lpr),e(XF,PY),e(PY,ipr),e(XF,dpr),e(K,cpr),e(K,zF),e(zF,VMe),e(VMe,fpr),e(zF,mpr),e(zF,BY),e(BY,gpr),e(zF,hpr),e(K,upr),e(K,QF),e(QF,XMe),e(XMe,ppr),e(QF,_pr),e(QF,IY),e(IY,vpr),e(QF,bpr),e(K,Fpr),e(K,WF),e(WF,zMe),e(zMe,Tpr),e(WF,Mpr),e(WF,NY),e(NY,Epr),e(WF,Cpr),e(K,wpr),e(K,UF),e(UF,QMe),e(QMe,Apr),e(UF,Lpr),e(UF,qY),e(qY,ypr),e(UF,xpr),e(K,$pr),e(K,HF),e(HF,WMe),e(WMe,kpr),e(HF,Spr),e(HF,jY),e(jY,Rpr),e(HF,Ppr),e(K,Bpr),e(K,JF),e(JF,UMe),e(UMe,Ipr),e(JF,Npr),e(JF,DY),e(DY,qpr),e(JF,jpr),e(so,Dpr),e(so,YF),e(YF,Gpr),e(YF,HMe),e(HMe,Opr),e(YF,Vpr),e(YF,JMe),e(JMe,Xpr),e(so,zpr),M(ZF,so,null),v(f,eao,_),v(f,rc,_),e(rc,KF),e(KF,YMe),M(Mk,YMe,null),e(rc,Qpr),e(rc,ZMe),e(ZMe,Wpr),v(f,oao,_),v(f,Xo,_),M(Ek,Xo,null),e(Xo,Upr),e(Xo,tc),e(tc,Hpr),e(tc,GY),e(GY,Jpr),e(tc,Ypr),e(tc,OY),e(OY,Zpr),e(tc,Kpr),e(Xo,e_r),e(Xo,Ck),e(Ck,o_r),e(Ck,KMe),e(KMe,r_r),e(Ck,t_r),e(Xo,a_r),e(Xo,$t),M(wk,$t,null),e($t,n_r),e($t,eEe),e(eEe,s_r),e($t,l_r),e($t,ac),e(ac,i_r),e(ac,oEe),e(oEe,d_r),e(ac,c_r),e(ac,VY),e(VY,f_r),e(ac,m_r),e($t,g_r),M(eT,$t,null),e(Xo,h_r),e(Xo,lo),M(Ak,lo,null),e(lo,u_r),e(lo,rEe),e(rEe,p_r),e(lo,__r),e(lo,hn),e(hn,v_r),e(hn,tEe),e(tEe,b_r),e(hn,F_r),e(hn,aEe),e(aEe,T_r),e(hn,M_r),e(hn,nEe),e(nEe,E_r),e(hn,C_r),e(lo,w_r),e(lo,Ue),e(Ue,oT),e(oT,sEe),e(sEe,A_r),e(oT,L_r),e(oT,XY),e(XY,y_r),e(oT,x_r),e(Ue,$_r),e(Ue,rT),e(rT,lEe),e(lEe,k_r),e(rT,S_r),e(rT,zY),e(zY,R_r),e(rT,P_r),e(Ue,B_r),e(Ue,tT),e(tT,iEe),e(iEe,I_r),e(tT,N_r),e(tT,QY),e(QY,q_r),e(tT,j_r),e(Ue,D_r),e(Ue,aT),e(aT,dEe),e(dEe,G_r),e(aT,O_r),e(aT,WY),e(WY,V_r),e(aT,X_r),e(Ue,z_r),e(Ue,nT),e(nT,cEe),e(cEe,Q_r),e(nT,W_r),e(nT,UY),e(UY,U_r),e(nT,H_r),e(Ue,J_r),e(Ue,sT),e(sT,fEe),e(fEe,Y_r),e(sT,Z_r),e(sT,HY),e(HY,K_r),e(sT,e4r),e(Ue,o4r),e(Ue,lT),e(lT,mEe),e(mEe,r4r),e(lT,t4r),e(lT,JY),e(JY,a4r),e(lT,n4r),e(lo,s4r),e(lo,iT),e(iT,l4r),e(iT,gEe),e(gEe,i4r),e(iT,d4r),e(iT,hEe),e(hEe,c4r),e(lo,f4r),M(dT,lo,null),v(f,rao,_),v(f,nc,_),e(nc,cT),e(cT,uEe),M(Lk,uEe,null),e(nc,m4r),e(nc,pEe),e(pEe,g4r),v(f,tao,_),v(f,zo,_),M(yk,zo,null),e(zo,h4r),e(zo,sc),e(sc,u4r),e(sc,YY),e(YY,p4r),e(sc,_4r),e(sc,ZY),e(ZY,v4r),e(sc,b4r),e(zo,F4r),e(zo,xk),e(xk,T4r),e(xk,_Ee),e(_Ee,M4r),e(xk,E4r),e(zo,C4r),e(zo,kt),M($k,kt,null),e(kt,w4r),e(kt,vEe),e(vEe,A4r),e(kt,L4r),e(kt,lc),e(lc,y4r),e(lc,bEe),e(bEe,x4r),e(lc,$4r),e(lc,KY),e(KY,k4r),e(lc,S4r),e(kt,R4r),M(fT,kt,null),e(zo,P4r),e(zo,io),M(kk,io,null),e(io,B4r),e(io,FEe),e(FEe,I4r),e(io,N4r),e(io,un),e(un,q4r),e(un,TEe),e(TEe,j4r),e(un,D4r),e(un,MEe),e(MEe,G4r),e(un,O4r),e(un,EEe),e(EEe,V4r),e(un,X4r),e(io,z4r),e(io,U),e(U,mT),e(mT,CEe),e(CEe,Q4r),e(mT,W4r),e(mT,eZ),e(eZ,U4r),e(mT,H4r),e(U,J4r),e(U,gT),e(gT,wEe),e(wEe,Y4r),e(gT,Z4r),e(gT,oZ),e(oZ,K4r),e(gT,e2r),e(U,o2r),e(U,hT),e(hT,AEe),e(AEe,r2r),e(hT,t2r),e(hT,rZ),e(rZ,a2r),e(hT,n2r),e(U,s2r),e(U,uT),e(uT,LEe),e(LEe,l2r),e(uT,i2r),e(uT,tZ),e(tZ,d2r),e(uT,c2r),e(U,f2r),e(U,pT),e(pT,yEe),e(yEe,m2r),e(pT,g2r),e(pT,aZ),e(aZ,h2r),e(pT,u2r),e(U,p2r),e(U,_T),e(_T,xEe),e(xEe,_2r),e(_T,v2r),e(_T,nZ),e(nZ,b2r),e(_T,F2r),e(U,T2r),e(U,vT),e(vT,$Ee),e($Ee,M2r),e(vT,E2r),e(vT,sZ),e(sZ,C2r),e(vT,w2r),e(U,A2r),e(U,bT),e(bT,kEe),e(kEe,L2r),e(bT,y2r),e(bT,lZ),e(lZ,x2r),e(bT,$2r),e(U,k2r),e(U,FT),e(FT,SEe),e(SEe,S2r),e(FT,R2r),e(FT,iZ),e(iZ,P2r),e(FT,B2r),e(U,I2r),e(U,TT),e(TT,REe),e(REe,N2r),e(TT,q2r),e(TT,dZ),e(dZ,j2r),e(TT,D2r),e(U,G2r),e(U,MT),e(MT,PEe),e(PEe,O2r),e(MT,V2r),e(MT,cZ),e(cZ,X2r),e(MT,z2r),e(U,Q2r),e(U,ET),e(ET,BEe),e(BEe,W2r),e(ET,U2r),e(ET,fZ),e(fZ,H2r),e(ET,J2r),e(U,Y2r),e(U,CT),e(CT,IEe),e(IEe,Z2r),e(CT,K2r),e(CT,mZ),e(mZ,evr),e(CT,ovr),e(U,rvr),e(U,wT),e(wT,NEe),e(NEe,tvr),e(wT,avr),e(wT,gZ),e(gZ,nvr),e(wT,svr),e(U,lvr),e(U,AT),e(AT,qEe),e(qEe,ivr),e(AT,dvr),e(AT,hZ),e(hZ,cvr),e(AT,fvr),e(U,mvr),e(U,LT),e(LT,jEe),e(jEe,gvr),e(LT,hvr),e(LT,uZ),e(uZ,uvr),e(LT,pvr),e(U,_vr),e(U,yT),e(yT,DEe),e(DEe,vvr),e(yT,bvr),e(yT,pZ),e(pZ,Fvr),e(yT,Tvr),e(U,Mvr),e(U,xT),e(xT,GEe),e(GEe,Evr),e(xT,Cvr),e(xT,_Z),e(_Z,wvr),e(xT,Avr),e(U,Lvr),e(U,$T),e($T,OEe),e(OEe,yvr),e($T,xvr),e($T,vZ),e(vZ,$vr),e($T,kvr),e(U,Svr),e(U,kT),e(kT,VEe),e(VEe,Rvr),e(kT,Pvr),e(kT,bZ),e(bZ,Bvr),e(kT,Ivr),e(U,Nvr),e(U,ST),e(ST,XEe),e(XEe,qvr),e(ST,jvr),e(ST,FZ),e(FZ,Dvr),e(ST,Gvr),e(U,Ovr),e(U,RT),e(RT,zEe),e(zEe,Vvr),e(RT,Xvr),e(RT,TZ),e(TZ,zvr),e(RT,Qvr),e(U,Wvr),e(U,PT),e(PT,QEe),e(QEe,Uvr),e(PT,Hvr),e(PT,MZ),e(MZ,Jvr),e(PT,Yvr),e(U,Zvr),e(U,BT),e(BT,WEe),e(WEe,Kvr),e(BT,e1r),e(BT,EZ),e(EZ,o1r),e(BT,r1r),e(U,t1r),e(U,IT),e(IT,UEe),e(UEe,a1r),e(IT,n1r),e(IT,CZ),e(CZ,s1r),e(IT,l1r),e(U,i1r),e(U,NT),e(NT,HEe),e(HEe,d1r),e(NT,c1r),e(NT,wZ),e(wZ,f1r),e(NT,m1r),e(U,g1r),e(U,qT),e(qT,JEe),e(JEe,h1r),e(qT,u1r),e(qT,AZ),e(AZ,p1r),e(qT,_1r),e(U,v1r),e(U,jT),e(jT,YEe),e(YEe,b1r),e(jT,F1r),e(jT,LZ),e(LZ,T1r),e(jT,M1r),e(U,E1r),e(U,DT),e(DT,ZEe),e(ZEe,C1r),e(DT,w1r),e(DT,yZ),e(yZ,A1r),e(DT,L1r),e(U,y1r),e(U,GT),e(GT,KEe),e(KEe,x1r),e(GT,$1r),e(GT,xZ),e(xZ,k1r),e(GT,S1r),e(U,R1r),e(U,OT),e(OT,eCe),e(eCe,P1r),e(OT,B1r),e(OT,$Z),e($Z,I1r),e(OT,N1r),e(U,q1r),e(U,VT),e(VT,oCe),e(oCe,j1r),e(VT,D1r),e(VT,kZ),e(kZ,G1r),e(VT,O1r),e(U,V1r),e(U,XT),e(XT,rCe),e(rCe,X1r),e(XT,z1r),e(XT,SZ),e(SZ,Q1r),e(XT,W1r),e(U,U1r),e(U,zT),e(zT,tCe),e(tCe,H1r),e(zT,J1r),e(zT,RZ),e(RZ,Y1r),e(zT,Z1r),e(U,K1r),e(U,QT),e(QT,aCe),e(aCe,ebr),e(QT,obr),e(QT,PZ),e(PZ,rbr),e(QT,tbr),e(U,abr),e(U,WT),e(WT,nCe),e(nCe,nbr),e(WT,sbr),e(WT,BZ),e(BZ,lbr),e(WT,ibr),e(U,dbr),e(U,UT),e(UT,sCe),e(sCe,cbr),e(UT,fbr),e(UT,IZ),e(IZ,mbr),e(UT,gbr),e(U,hbr),e(U,HT),e(HT,lCe),e(lCe,ubr),e(HT,pbr),e(HT,NZ),e(NZ,_br),e(HT,vbr),e(U,bbr),e(U,JT),e(JT,iCe),e(iCe,Fbr),e(JT,Tbr),e(JT,qZ),e(qZ,Mbr),e(JT,Ebr),e(U,Cbr),e(U,YT),e(YT,dCe),e(dCe,wbr),e(YT,Abr),e(YT,jZ),e(jZ,Lbr),e(YT,ybr),e(U,xbr),e(U,ZT),e(ZT,cCe),e(cCe,$br),e(ZT,kbr),e(ZT,DZ),e(DZ,Sbr),e(ZT,Rbr),e(io,Pbr),e(io,KT),e(KT,Bbr),e(KT,fCe),e(fCe,Ibr),e(KT,Nbr),e(KT,mCe),e(mCe,qbr),e(io,jbr),M(eM,io,null),v(f,aao,_),v(f,ic,_),e(ic,oM),e(oM,gCe),M(Sk,gCe,null),e(ic,Dbr),e(ic,hCe),e(hCe,Gbr),v(f,nao,_),v(f,Qo,_),M(Rk,Qo,null),e(Qo,Obr),e(Qo,dc),e(dc,Vbr),e(dc,GZ),e(GZ,Xbr),e(dc,zbr),e(dc,OZ),e(OZ,Qbr),e(dc,Wbr),e(Qo,Ubr),e(Qo,Pk),e(Pk,Hbr),e(Pk,uCe),e(uCe,Jbr),e(Pk,Ybr),e(Qo,Zbr),e(Qo,St),M(Bk,St,null),e(St,Kbr),e(St,pCe),e(pCe,e0r),e(St,o0r),e(St,cc),e(cc,r0r),e(cc,_Ce),e(_Ce,t0r),e(cc,a0r),e(cc,VZ),e(VZ,n0r),e(cc,s0r),e(St,l0r),M(rM,St,null),e(Qo,i0r),e(Qo,co),M(Ik,co,null),e(co,d0r),e(co,vCe),e(vCe,c0r),e(co,f0r),e(co,pn),e(pn,m0r),e(pn,bCe),e(bCe,g0r),e(pn,h0r),e(pn,FCe),e(FCe,u0r),e(pn,p0r),e(pn,TCe),e(TCe,_0r),e(pn,v0r),e(co,b0r),e(co,O),e(O,tM),e(tM,MCe),e(MCe,F0r),e(tM,T0r),e(tM,XZ),e(XZ,M0r),e(tM,E0r),e(O,C0r),e(O,aM),e(aM,ECe),e(ECe,w0r),e(aM,A0r),e(aM,zZ),e(zZ,L0r),e(aM,y0r),e(O,x0r),e(O,nM),e(nM,CCe),e(CCe,$0r),e(nM,k0r),e(nM,QZ),e(QZ,S0r),e(nM,R0r),e(O,P0r),e(O,sM),e(sM,wCe),e(wCe,B0r),e(sM,I0r),e(sM,WZ),e(WZ,N0r),e(sM,q0r),e(O,j0r),e(O,lM),e(lM,ACe),e(ACe,D0r),e(lM,G0r),e(lM,UZ),e(UZ,O0r),e(lM,V0r),e(O,X0r),e(O,iM),e(iM,LCe),e(LCe,z0r),e(iM,Q0r),e(iM,HZ),e(HZ,W0r),e(iM,U0r),e(O,H0r),e(O,dM),e(dM,yCe),e(yCe,J0r),e(dM,Y0r),e(dM,JZ),e(JZ,Z0r),e(dM,K0r),e(O,eFr),e(O,cM),e(cM,xCe),e(xCe,oFr),e(cM,rFr),e(cM,YZ),e(YZ,tFr),e(cM,aFr),e(O,nFr),e(O,fM),e(fM,$Ce),e($Ce,sFr),e(fM,lFr),e(fM,ZZ),e(ZZ,iFr),e(fM,dFr),e(O,cFr),e(O,mM),e(mM,kCe),e(kCe,fFr),e(mM,mFr),e(mM,KZ),e(KZ,gFr),e(mM,hFr),e(O,uFr),e(O,gM),e(gM,SCe),e(SCe,pFr),e(gM,_Fr),e(gM,eK),e(eK,vFr),e(gM,bFr),e(O,FFr),e(O,hM),e(hM,RCe),e(RCe,TFr),e(hM,MFr),e(hM,oK),e(oK,EFr),e(hM,CFr),e(O,wFr),e(O,uM),e(uM,PCe),e(PCe,AFr),e(uM,LFr),e(uM,rK),e(rK,yFr),e(uM,xFr),e(O,$Fr),e(O,pM),e(pM,BCe),e(BCe,kFr),e(pM,SFr),e(pM,tK),e(tK,RFr),e(pM,PFr),e(O,BFr),e(O,_M),e(_M,ICe),e(ICe,IFr),e(_M,NFr),e(_M,aK),e(aK,qFr),e(_M,jFr),e(O,DFr),e(O,vM),e(vM,NCe),e(NCe,GFr),e(vM,OFr),e(vM,nK),e(nK,VFr),e(vM,XFr),e(O,zFr),e(O,bM),e(bM,qCe),e(qCe,QFr),e(bM,WFr),e(bM,sK),e(sK,UFr),e(bM,HFr),e(O,JFr),e(O,FM),e(FM,jCe),e(jCe,YFr),e(FM,ZFr),e(FM,lK),e(lK,KFr),e(FM,eTr),e(O,oTr),e(O,TM),e(TM,DCe),e(DCe,rTr),e(TM,tTr),e(TM,iK),e(iK,aTr),e(TM,nTr),e(O,sTr),e(O,MM),e(MM,GCe),e(GCe,lTr),e(MM,iTr),e(MM,dK),e(dK,dTr),e(MM,cTr),e(O,fTr),e(O,EM),e(EM,OCe),e(OCe,mTr),e(EM,gTr),e(EM,cK),e(cK,hTr),e(EM,uTr),e(O,pTr),e(O,CM),e(CM,VCe),e(VCe,_Tr),e(CM,vTr),e(CM,fK),e(fK,bTr),e(CM,FTr),e(O,TTr),e(O,wM),e(wM,XCe),e(XCe,MTr),e(wM,ETr),e(wM,mK),e(mK,CTr),e(wM,wTr),e(O,ATr),e(O,AM),e(AM,zCe),e(zCe,LTr),e(AM,yTr),e(AM,gK),e(gK,xTr),e(AM,$Tr),e(O,kTr),e(O,LM),e(LM,QCe),e(QCe,STr),e(LM,RTr),e(LM,hK),e(hK,PTr),e(LM,BTr),e(O,ITr),e(O,yM),e(yM,WCe),e(WCe,NTr),e(yM,qTr),e(yM,uK),e(uK,jTr),e(yM,DTr),e(O,GTr),e(O,xM),e(xM,UCe),e(UCe,OTr),e(xM,VTr),e(xM,pK),e(pK,XTr),e(xM,zTr),e(O,QTr),e(O,$M),e($M,HCe),e(HCe,WTr),e($M,UTr),e($M,_K),e(_K,HTr),e($M,JTr),e(O,YTr),e(O,kM),e(kM,JCe),e(JCe,ZTr),e(kM,KTr),e(kM,vK),e(vK,eMr),e(kM,oMr),e(O,rMr),e(O,SM),e(SM,YCe),e(YCe,tMr),e(SM,aMr),e(SM,bK),e(bK,nMr),e(SM,sMr),e(O,lMr),e(O,RM),e(RM,ZCe),e(ZCe,iMr),e(RM,dMr),e(RM,FK),e(FK,cMr),e(RM,fMr),e(O,mMr),e(O,PM),e(PM,KCe),e(KCe,gMr),e(PM,hMr),e(PM,TK),e(TK,uMr),e(PM,pMr),e(O,_Mr),e(O,BM),e(BM,e3e),e(e3e,vMr),e(BM,bMr),e(BM,MK),e(MK,FMr),e(BM,TMr),e(O,MMr),e(O,IM),e(IM,o3e),e(o3e,EMr),e(IM,CMr),e(IM,EK),e(EK,wMr),e(IM,AMr),e(O,LMr),e(O,NM),e(NM,r3e),e(r3e,yMr),e(NM,xMr),e(NM,CK),e(CK,$Mr),e(NM,kMr),e(O,SMr),e(O,qM),e(qM,t3e),e(t3e,RMr),e(qM,PMr),e(qM,wK),e(wK,BMr),e(qM,IMr),e(O,NMr),e(O,jM),e(jM,a3e),e(a3e,qMr),e(jM,jMr),e(jM,AK),e(AK,DMr),e(jM,GMr),e(O,OMr),e(O,DM),e(DM,n3e),e(n3e,VMr),e(DM,XMr),e(DM,LK),e(LK,zMr),e(DM,QMr),e(O,WMr),e(O,GM),e(GM,s3e),e(s3e,UMr),e(GM,HMr),e(GM,yK),e(yK,JMr),e(GM,YMr),e(O,ZMr),e(O,OM),e(OM,l3e),e(l3e,KMr),e(OM,eEr),e(OM,xK),e(xK,oEr),e(OM,rEr),e(O,tEr),e(O,VM),e(VM,i3e),e(i3e,aEr),e(VM,nEr),e(VM,$K),e($K,sEr),e(VM,lEr),e(O,iEr),e(O,XM),e(XM,d3e),e(d3e,dEr),e(XM,cEr),e(XM,kK),e(kK,fEr),e(XM,mEr),e(O,gEr),e(O,zM),e(zM,c3e),e(c3e,hEr),e(zM,uEr),e(zM,SK),e(SK,pEr),e(zM,_Er),e(O,vEr),e(O,QM),e(QM,f3e),e(f3e,bEr),e(QM,FEr),e(QM,RK),e(RK,TEr),e(QM,MEr),e(O,EEr),e(O,WM),e(WM,m3e),e(m3e,CEr),e(WM,wEr),e(WM,PK),e(PK,AEr),e(WM,LEr),e(O,yEr),e(O,UM),e(UM,g3e),e(g3e,xEr),e(UM,$Er),e(UM,BK),e(BK,kEr),e(UM,SEr),e(O,REr),e(O,HM),e(HM,h3e),e(h3e,PEr),e(HM,BEr),e(HM,IK),e(IK,IEr),e(HM,NEr),e(O,qEr),e(O,JM),e(JM,u3e),e(u3e,jEr),e(JM,DEr),e(JM,NK),e(NK,GEr),e(JM,OEr),e(co,VEr),e(co,YM),e(YM,XEr),e(YM,p3e),e(p3e,zEr),e(YM,QEr),e(YM,_3e),e(_3e,WEr),e(co,UEr),M(ZM,co,null),v(f,sao,_),v(f,fc,_),e(fc,KM),e(KM,v3e),M(Nk,v3e,null),e(fc,HEr),e(fc,b3e),e(b3e,JEr),v(f,lao,_),v(f,Wo,_),M(qk,Wo,null),e(Wo,YEr),e(Wo,mc),e(mc,ZEr),e(mc,qK),e(qK,KEr),e(mc,eCr),e(mc,jK),e(jK,oCr),e(mc,rCr),e(Wo,tCr),e(Wo,jk),e(jk,aCr),e(jk,F3e),e(F3e,nCr),e(jk,sCr),e(Wo,lCr),e(Wo,Rt),M(Dk,Rt,null),e(Rt,iCr),e(Rt,T3e),e(T3e,dCr),e(Rt,cCr),e(Rt,gc),e(gc,fCr),e(gc,M3e),e(M3e,mCr),e(gc,gCr),e(gc,DK),e(DK,hCr),e(gc,uCr),e(Rt,pCr),M(eE,Rt,null),e(Wo,_Cr),e(Wo,fo),M(Gk,fo,null),e(fo,vCr),e(fo,E3e),e(E3e,bCr),e(fo,FCr),e(fo,_n),e(_n,TCr),e(_n,C3e),e(C3e,MCr),e(_n,ECr),e(_n,w3e),e(w3e,CCr),e(_n,wCr),e(_n,A3e),e(A3e,ACr),e(_n,LCr),e(fo,yCr),e(fo,L3e),e(L3e,oE),e(oE,y3e),e(y3e,xCr),e(oE,$Cr),e(oE,GK),e(GK,kCr),e(oE,SCr),e(fo,RCr),e(fo,rE),e(rE,PCr),e(rE,x3e),e(x3e,BCr),e(rE,ICr),e(rE,$3e),e($3e,NCr),e(fo,qCr),M(tE,fo,null),v(f,iao,_),v(f,hc,_),e(hc,aE),e(aE,k3e),M(Ok,k3e,null),e(hc,jCr),e(hc,S3e),e(S3e,DCr),v(f,dao,_),v(f,Uo,_),M(Vk,Uo,null),e(Uo,GCr),e(Uo,uc),e(uc,OCr),e(uc,OK),e(OK,VCr),e(uc,XCr),e(uc,VK),e(VK,zCr),e(uc,QCr),e(Uo,WCr),e(Uo,Xk),e(Xk,UCr),e(Xk,R3e),e(R3e,HCr),e(Xk,JCr),e(Uo,YCr),e(Uo,Pt),M(zk,Pt,null),e(Pt,ZCr),e(Pt,P3e),e(P3e,KCr),e(Pt,e3r),e(Pt,pc),e(pc,o3r),e(pc,B3e),e(B3e,r3r),e(pc,t3r),e(pc,XK),e(XK,a3r),e(pc,n3r),e(Pt,s3r),M(nE,Pt,null),e(Uo,l3r),e(Uo,mo),M(Qk,mo,null),e(mo,i3r),e(mo,I3e),e(I3e,d3r),e(mo,c3r),e(mo,vn),e(vn,f3r),e(vn,N3e),e(N3e,m3r),e(vn,g3r),e(vn,q3e),e(q3e,h3r),e(vn,u3r),e(vn,j3e),e(j3e,p3r),e(vn,_3r),e(mo,v3r),e(mo,_c),e(_c,sE),e(sE,D3e),e(D3e,b3r),e(sE,F3r),e(sE,zK),e(zK,T3r),e(sE,M3r),e(_c,E3r),e(_c,lE),e(lE,G3e),e(G3e,C3r),e(lE,w3r),e(lE,QK),e(QK,A3r),e(lE,L3r),e(_c,y3r),e(_c,iE),e(iE,O3e),e(O3e,x3r),e(iE,$3r),e(iE,WK),e(WK,k3r),e(iE,S3r),e(mo,R3r),e(mo,dE),e(dE,P3r),e(dE,V3e),e(V3e,B3r),e(dE,I3r),e(dE,X3e),e(X3e,N3r),e(mo,q3r),M(cE,mo,null),v(f,cao,_),v(f,vc,_),e(vc,fE),e(fE,z3e),M(Wk,z3e,null),e(vc,j3r),e(vc,Q3e),e(Q3e,D3r),v(f,fao,_),v(f,Ho,_),M(Uk,Ho,null),e(Ho,G3r),e(Ho,bc),e(bc,O3r),e(bc,UK),e(UK,V3r),e(bc,X3r),e(bc,HK),e(HK,z3r),e(bc,Q3r),e(Ho,W3r),e(Ho,Hk),e(Hk,U3r),e(Hk,W3e),e(W3e,H3r),e(Hk,J3r),e(Ho,Y3r),e(Ho,Bt),M(Jk,Bt,null),e(Bt,Z3r),e(Bt,U3e),e(U3e,K3r),e(Bt,e5r),e(Bt,Fc),e(Fc,o5r),e(Fc,H3e),e(H3e,r5r),e(Fc,t5r),e(Fc,JK),e(JK,a5r),e(Fc,n5r),e(Bt,s5r),M(mE,Bt,null),e(Ho,l5r),e(Ho,go),M(Yk,go,null),e(go,i5r),e(go,J3e),e(J3e,d5r),e(go,c5r),e(go,bn),e(bn,f5r),e(bn,Y3e),e(Y3e,m5r),e(bn,g5r),e(bn,Z3e),e(Z3e,h5r),e(bn,u5r),e(bn,K3e),e(K3e,p5r),e(bn,_5r),e(go,v5r),e(go,ve),e(ve,gE),e(gE,e5e),e(e5e,b5r),e(gE,F5r),e(gE,YK),e(YK,T5r),e(gE,M5r),e(ve,E5r),e(ve,hE),e(hE,o5e),e(o5e,C5r),e(hE,w5r),e(hE,ZK),e(ZK,A5r),e(hE,L5r),e(ve,y5r),e(ve,uE),e(uE,r5e),e(r5e,x5r),e(uE,$5r),e(uE,KK),e(KK,k5r),e(uE,S5r),e(ve,R5r),e(ve,pE),e(pE,t5e),e(t5e,P5r),e(pE,B5r),e(pE,eee),e(eee,I5r),e(pE,N5r),e(ve,q5r),e(ve,$l),e($l,a5e),e(a5e,j5r),e($l,D5r),e($l,oee),e(oee,G5r),e($l,O5r),e($l,ree),e(ree,V5r),e($l,X5r),e(ve,z5r),e(ve,_E),e(_E,n5e),e(n5e,Q5r),e(_E,W5r),e(_E,tee),e(tee,U5r),e(_E,H5r),e(ve,J5r),e(ve,kl),e(kl,s5e),e(s5e,Y5r),e(kl,Z5r),e(kl,aee),e(aee,K5r),e(kl,ewr),e(kl,nee),e(nee,owr),e(kl,rwr),e(ve,twr),e(ve,vE),e(vE,l5e),e(l5e,awr),e(vE,nwr),e(vE,see),e(see,swr),e(vE,lwr),e(ve,iwr),e(ve,It),e(It,i5e),e(i5e,dwr),e(It,cwr),e(It,lee),e(lee,fwr),e(It,mwr),e(It,iee),e(iee,gwr),e(It,hwr),e(It,dee),e(dee,uwr),e(It,pwr),e(ve,_wr),e(ve,bE),e(bE,d5e),e(d5e,vwr),e(bE,bwr),e(bE,cee),e(cee,Fwr),e(bE,Twr),e(ve,Mwr),e(ve,FE),e(FE,c5e),e(c5e,Ewr),e(FE,Cwr),e(FE,fee),e(fee,wwr),e(FE,Awr),e(ve,Lwr),e(ve,TE),e(TE,f5e),e(f5e,ywr),e(TE,xwr),e(TE,mee),e(mee,$wr),e(TE,kwr),e(ve,Swr),e(ve,ME),e(ME,m5e),e(m5e,Rwr),e(ME,Pwr),e(ME,gee),e(gee,Bwr),e(ME,Iwr),e(ve,Nwr),e(ve,EE),e(EE,g5e),e(g5e,qwr),e(EE,jwr),e(EE,hee),e(hee,Dwr),e(EE,Gwr),e(ve,Owr),e(ve,CE),e(CE,h5e),e(h5e,Vwr),e(CE,Xwr),e(CE,uee),e(uee,zwr),e(CE,Qwr),e(ve,Wwr),e(ve,wE),e(wE,u5e),e(u5e,Uwr),e(wE,Hwr),e(wE,pee),e(pee,Jwr),e(wE,Ywr),e(ve,Zwr),e(ve,AE),e(AE,p5e),e(p5e,Kwr),e(AE,eAr),e(AE,_ee),e(_ee,oAr),e(AE,rAr),e(ve,tAr),e(ve,LE),e(LE,_5e),e(_5e,aAr),e(LE,nAr),e(LE,vee),e(vee,sAr),e(LE,lAr),e(go,iAr),e(go,yE),e(yE,dAr),e(yE,v5e),e(v5e,cAr),e(yE,fAr),e(yE,b5e),e(b5e,mAr),e(go,gAr),M(xE,go,null),v(f,mao,_),v(f,Tc,_),e(Tc,$E),e($E,F5e),M(Zk,F5e,null),e(Tc,hAr),e(Tc,T5e),e(T5e,uAr),v(f,gao,_),v(f,Jo,_),M(Kk,Jo,null),e(Jo,pAr),e(Jo,Mc),e(Mc,_Ar),e(Mc,bee),e(bee,vAr),e(Mc,bAr),e(Mc,Fee),e(Fee,FAr),e(Mc,TAr),e(Jo,MAr),e(Jo,eS),e(eS,EAr),e(eS,M5e),e(M5e,CAr),e(eS,wAr),e(Jo,AAr),e(Jo,Nt),M(oS,Nt,null),e(Nt,LAr),e(Nt,E5e),e(E5e,yAr),e(Nt,xAr),e(Nt,Ec),e(Ec,$Ar),e(Ec,C5e),e(C5e,kAr),e(Ec,SAr),e(Ec,Tee),e(Tee,RAr),e(Ec,PAr),e(Nt,BAr),M(kE,Nt,null),e(Jo,IAr),e(Jo,ho),M(rS,ho,null),e(ho,NAr),e(ho,w5e),e(w5e,qAr),e(ho,jAr),e(ho,Fn),e(Fn,DAr),e(Fn,A5e),e(A5e,GAr),e(Fn,OAr),e(Fn,L5e),e(L5e,VAr),e(Fn,XAr),e(Fn,y5e),e(y5e,zAr),e(Fn,QAr),e(ho,WAr),e(ho,x5e),e(x5e,SE),e(SE,$5e),e($5e,UAr),e(SE,HAr),e(SE,Mee),e(Mee,JAr),e(SE,YAr),e(ho,ZAr),e(ho,RE),e(RE,KAr),e(RE,k5e),e(k5e,e6r),e(RE,o6r),e(RE,S5e),e(S5e,r6r),e(ho,t6r),M(PE,ho,null),v(f,hao,_),v(f,Cc,_),e(Cc,BE),e(BE,R5e),M(tS,R5e,null),e(Cc,a6r),e(Cc,P5e),e(P5e,n6r),v(f,uao,_),v(f,Yo,_),M(aS,Yo,null),e(Yo,s6r),e(Yo,wc),e(wc,l6r),e(wc,Eee),e(Eee,i6r),e(wc,d6r),e(wc,Cee),e(Cee,c6r),e(wc,f6r),e(Yo,m6r),e(Yo,nS),e(nS,g6r),e(nS,B5e),e(B5e,h6r),e(nS,u6r),e(Yo,p6r),e(Yo,qt),M(sS,qt,null),e(qt,_6r),e(qt,I5e),e(I5e,v6r),e(qt,b6r),e(qt,Ac),e(Ac,F6r),e(Ac,N5e),e(N5e,T6r),e(Ac,M6r),e(Ac,wee),e(wee,E6r),e(Ac,C6r),e(qt,w6r),M(IE,qt,null),e(Yo,A6r),e(Yo,uo),M(lS,uo,null),e(uo,L6r),e(uo,q5e),e(q5e,y6r),e(uo,x6r),e(uo,Tn),e(Tn,$6r),e(Tn,j5e),e(j5e,k6r),e(Tn,S6r),e(Tn,D5e),e(D5e,R6r),e(Tn,P6r),e(Tn,G5e),e(G5e,B6r),e(Tn,I6r),e(uo,N6r),e(uo,O5e),e(O5e,NE),e(NE,V5e),e(V5e,q6r),e(NE,j6r),e(NE,Aee),e(Aee,D6r),e(NE,G6r),e(uo,O6r),e(uo,qE),e(qE,V6r),e(qE,X5e),e(X5e,X6r),e(qE,z6r),e(qE,z5e),e(z5e,Q6r),e(uo,W6r),M(jE,uo,null),v(f,pao,_),v(f,Lc,_),e(Lc,DE),e(DE,Q5e),M(iS,Q5e,null),e(Lc,U6r),e(Lc,W5e),e(W5e,H6r),v(f,_ao,_),v(f,Zo,_),M(dS,Zo,null),e(Zo,J6r),e(Zo,yc),e(yc,Y6r),e(yc,Lee),e(Lee,Z6r),e(yc,K6r),e(yc,yee),e(yee,e7r),e(yc,o7r),e(Zo,r7r),e(Zo,cS),e(cS,t7r),e(cS,U5e),e(U5e,a7r),e(cS,n7r),e(Zo,s7r),e(Zo,jt),M(fS,jt,null),e(jt,l7r),e(jt,H5e),e(H5e,i7r),e(jt,d7r),e(jt,xc),e(xc,c7r),e(xc,J5e),e(J5e,f7r),e(xc,m7r),e(xc,xee),e(xee,g7r),e(xc,h7r),e(jt,u7r),M(GE,jt,null),e(Zo,p7r),e(Zo,po),M(mS,po,null),e(po,_7r),e(po,Y5e),e(Y5e,v7r),e(po,b7r),e(po,Mn),e(Mn,F7r),e(Mn,Z5e),e(Z5e,T7r),e(Mn,M7r),e(Mn,K5e),e(K5e,E7r),e(Mn,C7r),e(Mn,ewe),e(ewe,w7r),e(Mn,A7r),e(po,L7r),e(po,owe),e(owe,OE),e(OE,rwe),e(rwe,y7r),e(OE,x7r),e(OE,$ee),e($ee,$7r),e(OE,k7r),e(po,S7r),e(po,VE),e(VE,R7r),e(VE,twe),e(twe,P7r),e(VE,B7r),e(VE,awe),e(awe,I7r),e(po,N7r),M(XE,po,null),v(f,vao,_),v(f,$c,_),e($c,zE),e(zE,nwe),M(gS,nwe,null),e($c,q7r),e($c,swe),e(swe,j7r),v(f,bao,_),v(f,Ko,_),M(hS,Ko,null),e(Ko,D7r),e(Ko,kc),e(kc,G7r),e(kc,kee),e(kee,O7r),e(kc,V7r),e(kc,See),e(See,X7r),e(kc,z7r),e(Ko,Q7r),e(Ko,uS),e(uS,W7r),e(uS,lwe),e(lwe,U7r),e(uS,H7r),e(Ko,J7r),e(Ko,Dt),M(pS,Dt,null),e(Dt,Y7r),e(Dt,iwe),e(iwe,Z7r),e(Dt,K7r),e(Dt,Sc),e(Sc,e8r),e(Sc,dwe),e(dwe,o8r),e(Sc,r8r),e(Sc,Ree),e(Ree,t8r),e(Sc,a8r),e(Dt,n8r),M(QE,Dt,null),e(Ko,s8r),e(Ko,_o),M(_S,_o,null),e(_o,l8r),e(_o,cwe),e(cwe,i8r),e(_o,d8r),e(_o,En),e(En,c8r),e(En,fwe),e(fwe,f8r),e(En,m8r),e(En,mwe),e(mwe,g8r),e(En,h8r),e(En,gwe),e(gwe,u8r),e(En,p8r),e(_o,_8r),e(_o,Be),e(Be,WE),e(WE,hwe),e(hwe,v8r),e(WE,b8r),e(WE,Pee),e(Pee,F8r),e(WE,T8r),e(Be,M8r),e(Be,UE),e(UE,uwe),e(uwe,E8r),e(UE,C8r),e(UE,Bee),e(Bee,w8r),e(UE,A8r),e(Be,L8r),e(Be,HE),e(HE,pwe),e(pwe,y8r),e(HE,x8r),e(HE,Iee),e(Iee,$8r),e(HE,k8r),e(Be,S8r),e(Be,JE),e(JE,_we),e(_we,R8r),e(JE,P8r),e(JE,Nee),e(Nee,B8r),e(JE,I8r),e(Be,N8r),e(Be,YE),e(YE,vwe),e(vwe,q8r),e(YE,j8r),e(YE,qee),e(qee,D8r),e(YE,G8r),e(Be,O8r),e(Be,ZE),e(ZE,bwe),e(bwe,V8r),e(ZE,X8r),e(ZE,jee),e(jee,z8r),e(ZE,Q8r),e(Be,W8r),e(Be,KE),e(KE,Fwe),e(Fwe,U8r),e(KE,H8r),e(KE,Dee),e(Dee,J8r),e(KE,Y8r),e(Be,Z8r),e(Be,eC),e(eC,Twe),e(Twe,K8r),e(eC,eLr),e(eC,Gee),e(Gee,oLr),e(eC,rLr),e(Be,tLr),e(Be,oC),e(oC,Mwe),e(Mwe,aLr),e(oC,nLr),e(oC,Oee),e(Oee,sLr),e(oC,lLr),e(_o,iLr),e(_o,rC),e(rC,dLr),e(rC,Ewe),e(Ewe,cLr),e(rC,fLr),e(rC,Cwe),e(Cwe,mLr),e(_o,gLr),M(tC,_o,null),v(f,Fao,_),v(f,Rc,_),e(Rc,aC),e(aC,wwe),M(vS,wwe,null),e(Rc,hLr),e(Rc,Awe),e(Awe,uLr),v(f,Tao,_),v(f,er,_),M(bS,er,null),e(er,pLr),e(er,Pc),e(Pc,_Lr),e(Pc,Vee),e(Vee,vLr),e(Pc,bLr),e(Pc,Xee),e(Xee,FLr),e(Pc,TLr),e(er,MLr),e(er,FS),e(FS,ELr),e(FS,Lwe),e(Lwe,CLr),e(FS,wLr),e(er,ALr),e(er,Gt),M(TS,Gt,null),e(Gt,LLr),e(Gt,ywe),e(ywe,yLr),e(Gt,xLr),e(Gt,Bc),e(Bc,$Lr),e(Bc,xwe),e(xwe,kLr),e(Bc,SLr),e(Bc,zee),e(zee,RLr),e(Bc,PLr),e(Gt,BLr),M(nC,Gt,null),e(er,ILr),e(er,vo),M(MS,vo,null),e(vo,NLr),e(vo,$we),e($we,qLr),e(vo,jLr),e(vo,Cn),e(Cn,DLr),e(Cn,kwe),e(kwe,GLr),e(Cn,OLr),e(Cn,Swe),e(Swe,VLr),e(Cn,XLr),e(Cn,Rwe),e(Rwe,zLr),e(Cn,QLr),e(vo,WLr),e(vo,ut),e(ut,sC),e(sC,Pwe),e(Pwe,ULr),e(sC,HLr),e(sC,Qee),e(Qee,JLr),e(sC,YLr),e(ut,ZLr),e(ut,lC),e(lC,Bwe),e(Bwe,KLr),e(lC,eyr),e(lC,Wee),e(Wee,oyr),e(lC,ryr),e(ut,tyr),e(ut,iC),e(iC,Iwe),e(Iwe,ayr),e(iC,nyr),e(iC,Uee),e(Uee,syr),e(iC,lyr),e(ut,iyr),e(ut,dC),e(dC,Nwe),e(Nwe,dyr),e(dC,cyr),e(dC,Hee),e(Hee,fyr),e(dC,myr),e(ut,gyr),e(ut,cC),e(cC,qwe),e(qwe,hyr),e(cC,uyr),e(cC,Jee),e(Jee,pyr),e(cC,_yr),e(vo,vyr),e(vo,fC),e(fC,byr),e(fC,jwe),e(jwe,Fyr),e(fC,Tyr),e(fC,Dwe),e(Dwe,Myr),e(vo,Eyr),M(mC,vo,null),v(f,Mao,_),v(f,Ic,_),e(Ic,gC),e(gC,Gwe),M(ES,Gwe,null),e(Ic,Cyr),e(Ic,Owe),e(Owe,wyr),v(f,Eao,_),v(f,or,_),M(CS,or,null),e(or,Ayr),e(or,Nc),e(Nc,Lyr),e(Nc,Yee),e(Yee,yyr),e(Nc,xyr),e(Nc,Zee),e(Zee,$yr),e(Nc,kyr),e(or,Syr),e(or,wS),e(wS,Ryr),e(wS,Vwe),e(Vwe,Pyr),e(wS,Byr),e(or,Iyr),e(or,Ot),M(AS,Ot,null),e(Ot,Nyr),e(Ot,Xwe),e(Xwe,qyr),e(Ot,jyr),e(Ot,qc),e(qc,Dyr),e(qc,zwe),e(zwe,Gyr),e(qc,Oyr),e(qc,Kee),e(Kee,Vyr),e(qc,Xyr),e(Ot,zyr),M(hC,Ot,null),e(or,Qyr),e(or,bo),M(LS,bo,null),e(bo,Wyr),e(bo,Qwe),e(Qwe,Uyr),e(bo,Hyr),e(bo,wn),e(wn,Jyr),e(wn,Wwe),e(Wwe,Yyr),e(wn,Zyr),e(wn,Uwe),e(Uwe,Kyr),e(wn,e9r),e(wn,Hwe),e(Hwe,o9r),e(wn,r9r),e(bo,t9r),e(bo,Le),e(Le,uC),e(uC,Jwe),e(Jwe,a9r),e(uC,n9r),e(uC,eoe),e(eoe,s9r),e(uC,l9r),e(Le,i9r),e(Le,pC),e(pC,Ywe),e(Ywe,d9r),e(pC,c9r),e(pC,ooe),e(ooe,f9r),e(pC,m9r),e(Le,g9r),e(Le,_C),e(_C,Zwe),e(Zwe,h9r),e(_C,u9r),e(_C,roe),e(roe,p9r),e(_C,_9r),e(Le,v9r),e(Le,vC),e(vC,Kwe),e(Kwe,b9r),e(vC,F9r),e(vC,toe),e(toe,T9r),e(vC,M9r),e(Le,E9r),e(Le,bC),e(bC,eAe),e(eAe,C9r),e(bC,w9r),e(bC,aoe),e(aoe,A9r),e(bC,L9r),e(Le,y9r),e(Le,FC),e(FC,oAe),e(oAe,x9r),e(FC,$9r),e(FC,noe),e(noe,k9r),e(FC,S9r),e(Le,R9r),e(Le,TC),e(TC,rAe),e(rAe,P9r),e(TC,B9r),e(TC,soe),e(soe,I9r),e(TC,N9r),e(Le,q9r),e(Le,MC),e(MC,tAe),e(tAe,j9r),e(MC,D9r),e(MC,loe),e(loe,G9r),e(MC,O9r),e(Le,V9r),e(Le,EC),e(EC,aAe),e(aAe,X9r),e(EC,z9r),e(EC,ioe),e(ioe,Q9r),e(EC,W9r),e(Le,U9r),e(Le,CC),e(CC,nAe),e(nAe,H9r),e(CC,J9r),e(CC,doe),e(doe,Y9r),e(CC,Z9r),e(bo,K9r),e(bo,wC),e(wC,exr),e(wC,sAe),e(sAe,oxr),e(wC,rxr),e(wC,lAe),e(lAe,txr),e(bo,axr),M(AC,bo,null),v(f,Cao,_),v(f,jc,_),e(jc,LC),e(LC,iAe),M(yS,iAe,null),e(jc,nxr),e(jc,dAe),e(dAe,sxr),v(f,wao,_),v(f,rr,_),M(xS,rr,null),e(rr,lxr),e(rr,Dc),e(Dc,ixr),e(Dc,coe),e(coe,dxr),e(Dc,cxr),e(Dc,foe),e(foe,fxr),e(Dc,mxr),e(rr,gxr),e(rr,$S),e($S,hxr),e($S,cAe),e(cAe,uxr),e($S,pxr),e(rr,_xr),e(rr,Vt),M(kS,Vt,null),e(Vt,vxr),e(Vt,fAe),e(fAe,bxr),e(Vt,Fxr),e(Vt,Gc),e(Gc,Txr),e(Gc,mAe),e(mAe,Mxr),e(Gc,Exr),e(Gc,moe),e(moe,Cxr),e(Gc,wxr),e(Vt,Axr),M(yC,Vt,null),e(rr,Lxr),e(rr,Fo),M(SS,Fo,null),e(Fo,yxr),e(Fo,gAe),e(gAe,xxr),e(Fo,$xr),e(Fo,An),e(An,kxr),e(An,hAe),e(hAe,Sxr),e(An,Rxr),e(An,uAe),e(uAe,Pxr),e(An,Bxr),e(An,pAe),e(pAe,Ixr),e(An,Nxr),e(Fo,qxr),e(Fo,Oc),e(Oc,xC),e(xC,_Ae),e(_Ae,jxr),e(xC,Dxr),e(xC,goe),e(goe,Gxr),e(xC,Oxr),e(Oc,Vxr),e(Oc,$C),e($C,vAe),e(vAe,Xxr),e($C,zxr),e($C,hoe),e(hoe,Qxr),e($C,Wxr),e(Oc,Uxr),e(Oc,kC),e(kC,bAe),e(bAe,Hxr),e(kC,Jxr),e(kC,uoe),e(uoe,Yxr),e(kC,Zxr),e(Fo,Kxr),e(Fo,SC),e(SC,e$r),e(SC,FAe),e(FAe,o$r),e(SC,r$r),e(SC,TAe),e(TAe,t$r),e(Fo,a$r),M(RC,Fo,null),v(f,Aao,_),v(f,Vc,_),e(Vc,PC),e(PC,MAe),M(RS,MAe,null),e(Vc,n$r),e(Vc,EAe),e(EAe,s$r),v(f,Lao,_),v(f,tr,_),M(PS,tr,null),e(tr,l$r),e(tr,Xc),e(Xc,i$r),e(Xc,poe),e(poe,d$r),e(Xc,c$r),e(Xc,_oe),e(_oe,f$r),e(Xc,m$r),e(tr,g$r),e(tr,BS),e(BS,h$r),e(BS,CAe),e(CAe,u$r),e(BS,p$r),e(tr,_$r),e(tr,Xt),M(IS,Xt,null),e(Xt,v$r),e(Xt,wAe),e(wAe,b$r),e(Xt,F$r),e(Xt,zc),e(zc,T$r),e(zc,AAe),e(AAe,M$r),e(zc,E$r),e(zc,voe),e(voe,C$r),e(zc,w$r),e(Xt,A$r),M(BC,Xt,null),e(tr,L$r),e(tr,To),M(NS,To,null),e(To,y$r),e(To,LAe),e(LAe,x$r),e(To,$$r),e(To,Ln),e(Ln,k$r),e(Ln,yAe),e(yAe,S$r),e(Ln,R$r),e(Ln,xAe),e(xAe,P$r),e(Ln,B$r),e(Ln,$Ae),e($Ae,I$r),e(Ln,N$r),e(To,q$r),e(To,pt),e(pt,IC),e(IC,kAe),e(kAe,j$r),e(IC,D$r),e(IC,boe),e(boe,G$r),e(IC,O$r),e(pt,V$r),e(pt,NC),e(NC,SAe),e(SAe,X$r),e(NC,z$r),e(NC,Foe),e(Foe,Q$r),e(NC,W$r),e(pt,U$r),e(pt,qC),e(qC,RAe),e(RAe,H$r),e(qC,J$r),e(qC,Toe),e(Toe,Y$r),e(qC,Z$r),e(pt,K$r),e(pt,jC),e(jC,PAe),e(PAe,ekr),e(jC,okr),e(jC,Moe),e(Moe,rkr),e(jC,tkr),e(pt,akr),e(pt,DC),e(DC,BAe),e(BAe,nkr),e(DC,skr),e(DC,Eoe),e(Eoe,lkr),e(DC,ikr),e(To,dkr),e(To,GC),e(GC,ckr),e(GC,IAe),e(IAe,fkr),e(GC,mkr),e(GC,NAe),e(NAe,gkr),e(To,hkr),M(OC,To,null),v(f,yao,_),v(f,Qc,_),e(Qc,VC),e(VC,qAe),M(qS,qAe,null),e(Qc,ukr),e(Qc,jAe),e(jAe,pkr),v(f,xao,_),v(f,ar,_),M(jS,ar,null),e(ar,_kr),e(ar,Wc),e(Wc,vkr),e(Wc,Coe),e(Coe,bkr),e(Wc,Fkr),e(Wc,woe),e(woe,Tkr),e(Wc,Mkr),e(ar,Ekr),e(ar,DS),e(DS,Ckr),e(DS,DAe),e(DAe,wkr),e(DS,Akr),e(ar,Lkr),e(ar,zt),M(GS,zt,null),e(zt,ykr),e(zt,GAe),e(GAe,xkr),e(zt,$kr),e(zt,Uc),e(Uc,kkr),e(Uc,OAe),e(OAe,Skr),e(Uc,Rkr),e(Uc,Aoe),e(Aoe,Pkr),e(Uc,Bkr),e(zt,Ikr),M(XC,zt,null),e(ar,Nkr),e(ar,Mo),M(OS,Mo,null),e(Mo,qkr),e(Mo,VAe),e(VAe,jkr),e(Mo,Dkr),e(Mo,yn),e(yn,Gkr),e(yn,XAe),e(XAe,Okr),e(yn,Vkr),e(yn,zAe),e(zAe,Xkr),e(yn,zkr),e(yn,QAe),e(QAe,Qkr),e(yn,Wkr),e(Mo,Ukr),e(Mo,xn),e(xn,zC),e(zC,WAe),e(WAe,Hkr),e(zC,Jkr),e(zC,Loe),e(Loe,Ykr),e(zC,Zkr),e(xn,Kkr),e(xn,QC),e(QC,UAe),e(UAe,eSr),e(QC,oSr),e(QC,yoe),e(yoe,rSr),e(QC,tSr),e(xn,aSr),e(xn,WC),e(WC,HAe),e(HAe,nSr),e(WC,sSr),e(WC,xoe),e(xoe,lSr),e(WC,iSr),e(xn,dSr),e(xn,UC),e(UC,JAe),e(JAe,cSr),e(UC,fSr),e(UC,$oe),e($oe,mSr),e(UC,gSr),e(Mo,hSr),e(Mo,HC),e(HC,uSr),e(HC,YAe),e(YAe,pSr),e(HC,_Sr),e(HC,ZAe),e(ZAe,vSr),e(Mo,bSr),M(JC,Mo,null),v(f,$ao,_),v(f,Hc,_),e(Hc,YC),e(YC,KAe),M(VS,KAe,null),e(Hc,FSr),e(Hc,e6e),e(e6e,TSr),v(f,kao,_),v(f,nr,_),M(XS,nr,null),e(nr,MSr),e(nr,Jc),e(Jc,ESr),e(Jc,koe),e(koe,CSr),e(Jc,wSr),e(Jc,Soe),e(Soe,ASr),e(Jc,LSr),e(nr,ySr),e(nr,zS),e(zS,xSr),e(zS,o6e),e(o6e,$Sr),e(zS,kSr),e(nr,SSr),e(nr,Qt),M(QS,Qt,null),e(Qt,RSr),e(Qt,r6e),e(r6e,PSr),e(Qt,BSr),e(Qt,Yc),e(Yc,ISr),e(Yc,t6e),e(t6e,NSr),e(Yc,qSr),e(Yc,Roe),e(Roe,jSr),e(Yc,DSr),e(Qt,GSr),M(ZC,Qt,null),e(nr,OSr),e(nr,Eo),M(WS,Eo,null),e(Eo,VSr),e(Eo,a6e),e(a6e,XSr),e(Eo,zSr),e(Eo,$n),e($n,QSr),e($n,n6e),e(n6e,WSr),e($n,USr),e($n,s6e),e(s6e,HSr),e($n,JSr),e($n,l6e),e(l6e,YSr),e($n,ZSr),e(Eo,KSr),e(Eo,_t),e(_t,KC),e(KC,i6e),e(i6e,eRr),e(KC,oRr),e(KC,Poe),e(Poe,rRr),e(KC,tRr),e(_t,aRr),e(_t,e3),e(e3,d6e),e(d6e,nRr),e(e3,sRr),e(e3,Boe),e(Boe,lRr),e(e3,iRr),e(_t,dRr),e(_t,o3),e(o3,c6e),e(c6e,cRr),e(o3,fRr),e(o3,Ioe),e(Ioe,mRr),e(o3,gRr),e(_t,hRr),e(_t,r3),e(r3,f6e),e(f6e,uRr),e(r3,pRr),e(r3,Noe),e(Noe,_Rr),e(r3,vRr),e(_t,bRr),e(_t,t3),e(t3,m6e),e(m6e,FRr),e(t3,TRr),e(t3,qoe),e(qoe,MRr),e(t3,ERr),e(Eo,CRr),e(Eo,a3),e(a3,wRr),e(a3,g6e),e(g6e,ARr),e(a3,LRr),e(a3,h6e),e(h6e,yRr),e(Eo,xRr),M(n3,Eo,null),v(f,Sao,_),v(f,Zc,_),e(Zc,s3),e(s3,u6e),M(US,u6e,null),e(Zc,$Rr),e(Zc,p6e),e(p6e,kRr),v(f,Rao,_),v(f,sr,_),M(HS,sr,null),e(sr,SRr),e(sr,Kc),e(Kc,RRr),e(Kc,joe),e(joe,PRr),e(Kc,BRr),e(Kc,Doe),e(Doe,IRr),e(Kc,NRr),e(sr,qRr),e(sr,JS),e(JS,jRr),e(JS,_6e),e(_6e,DRr),e(JS,GRr),e(sr,ORr),e(sr,Wt),M(YS,Wt,null),e(Wt,VRr),e(Wt,v6e),e(v6e,XRr),e(Wt,zRr),e(Wt,ef),e(ef,QRr),e(ef,b6e),e(b6e,WRr),e(ef,URr),e(ef,Goe),e(Goe,HRr),e(ef,JRr),e(Wt,YRr),M(l3,Wt,null),e(sr,ZRr),e(sr,Co),M(ZS,Co,null),e(Co,KRr),e(Co,F6e),e(F6e,ePr),e(Co,oPr),e(Co,kn),e(kn,rPr),e(kn,T6e),e(T6e,tPr),e(kn,aPr),e(kn,M6e),e(M6e,nPr),e(kn,sPr),e(kn,E6e),e(E6e,lPr),e(kn,iPr),e(Co,dPr),e(Co,C6e),e(C6e,i3),e(i3,w6e),e(w6e,cPr),e(i3,fPr),e(i3,Ooe),e(Ooe,mPr),e(i3,gPr),e(Co,hPr),e(Co,d3),e(d3,uPr),e(d3,A6e),e(A6e,pPr),e(d3,_Pr),e(d3,L6e),e(L6e,vPr),e(Co,bPr),M(c3,Co,null),v(f,Pao,_),v(f,of,_),e(of,f3),e(f3,y6e),M(KS,y6e,null),e(of,FPr),e(of,x6e),e(x6e,TPr),v(f,Bao,_),v(f,lr,_),M(eR,lr,null),e(lr,MPr),e(lr,rf),e(rf,EPr),e(rf,Voe),e(Voe,CPr),e(rf,wPr),e(rf,Xoe),e(Xoe,APr),e(rf,LPr),e(lr,yPr),e(lr,oR),e(oR,xPr),e(oR,$6e),e($6e,$Pr),e(oR,kPr),e(lr,SPr),e(lr,Ut),M(rR,Ut,null),e(Ut,RPr),e(Ut,k6e),e(k6e,PPr),e(Ut,BPr),e(Ut,tf),e(tf,IPr),e(tf,S6e),e(S6e,NPr),e(tf,qPr),e(tf,zoe),e(zoe,jPr),e(tf,DPr),e(Ut,GPr),M(m3,Ut,null),e(lr,OPr),e(lr,wo),M(tR,wo,null),e(wo,VPr),e(wo,R6e),e(R6e,XPr),e(wo,zPr),e(wo,Sn),e(Sn,QPr),e(Sn,P6e),e(P6e,WPr),e(Sn,UPr),e(Sn,B6e),e(B6e,HPr),e(Sn,JPr),e(Sn,I6e),e(I6e,YPr),e(Sn,ZPr),e(wo,KPr),e(wo,vt),e(vt,g3),e(g3,N6e),e(N6e,eBr),e(g3,oBr),e(g3,Qoe),e(Qoe,rBr),e(g3,tBr),e(vt,aBr),e(vt,h3),e(h3,q6e),e(q6e,nBr),e(h3,sBr),e(h3,Woe),e(Woe,lBr),e(h3,iBr),e(vt,dBr),e(vt,u3),e(u3,j6e),e(j6e,cBr),e(u3,fBr),e(u3,Uoe),e(Uoe,mBr),e(u3,gBr),e(vt,hBr),e(vt,p3),e(p3,D6e),e(D6e,uBr),e(p3,pBr),e(p3,Hoe),e(Hoe,_Br),e(p3,vBr),e(vt,bBr),e(vt,_3),e(_3,G6e),e(G6e,FBr),e(_3,TBr),e(_3,Joe),e(Joe,MBr),e(_3,EBr),e(wo,CBr),e(wo,v3),e(v3,wBr),e(v3,O6e),e(O6e,ABr),e(v3,LBr),e(v3,V6e),e(V6e,yBr),e(wo,xBr),M(b3,wo,null),v(f,Iao,_),v(f,af,_),e(af,F3),e(F3,X6e),M(aR,X6e,null),e(af,$Br),e(af,z6e),e(z6e,kBr),v(f,Nao,_),v(f,ir,_),M(nR,ir,null),e(ir,SBr),e(ir,nf),e(nf,RBr),e(nf,Yoe),e(Yoe,PBr),e(nf,BBr),e(nf,Zoe),e(Zoe,IBr),e(nf,NBr),e(ir,qBr),e(ir,sR),e(sR,jBr),e(sR,Q6e),e(Q6e,DBr),e(sR,GBr),e(ir,OBr),e(ir,Ht),M(lR,Ht,null),e(Ht,VBr),e(Ht,W6e),e(W6e,XBr),e(Ht,zBr),e(Ht,sf),e(sf,QBr),e(sf,U6e),e(U6e,WBr),e(sf,UBr),e(sf,Koe),e(Koe,HBr),e(sf,JBr),e(Ht,YBr),M(T3,Ht,null),e(ir,ZBr),e(ir,Ao),M(iR,Ao,null),e(Ao,KBr),e(Ao,H6e),e(H6e,eIr),e(Ao,oIr),e(Ao,Rn),e(Rn,rIr),e(Rn,J6e),e(J6e,tIr),e(Rn,aIr),e(Rn,Y6e),e(Y6e,nIr),e(Rn,sIr),e(Rn,Z6e),e(Z6e,lIr),e(Rn,iIr),e(Ao,dIr),e(Ao,K6e),e(K6e,M3),e(M3,e7e),e(e7e,cIr),e(M3,fIr),e(M3,ere),e(ere,mIr),e(M3,gIr),e(Ao,hIr),e(Ao,E3),e(E3,uIr),e(E3,o7e),e(o7e,pIr),e(E3,_Ir),e(E3,r7e),e(r7e,vIr),e(Ao,bIr),M(C3,Ao,null),v(f,qao,_),v(f,lf,_),e(lf,w3),e(w3,t7e),M(dR,t7e,null),e(lf,FIr),e(lf,a7e),e(a7e,TIr),v(f,jao,_),v(f,dr,_),M(cR,dr,null),e(dr,MIr),e(dr,df),e(df,EIr),e(df,ore),e(ore,CIr),e(df,wIr),e(df,rre),e(rre,AIr),e(df,LIr),e(dr,yIr),e(dr,fR),e(fR,xIr),e(fR,n7e),e(n7e,$Ir),e(fR,kIr),e(dr,SIr),e(dr,Jt),M(mR,Jt,null),e(Jt,RIr),e(Jt,s7e),e(s7e,PIr),e(Jt,BIr),e(Jt,cf),e(cf,IIr),e(cf,l7e),e(l7e,NIr),e(cf,qIr),e(cf,tre),e(tre,jIr),e(cf,DIr),e(Jt,GIr),M(A3,Jt,null),e(dr,OIr),e(dr,Lo),M(gR,Lo,null),e(Lo,VIr),e(Lo,i7e),e(i7e,XIr),e(Lo,zIr),e(Lo,Pn),e(Pn,QIr),e(Pn,d7e),e(d7e,WIr),e(Pn,UIr),e(Pn,c7e),e(c7e,HIr),e(Pn,JIr),e(Pn,f7e),e(f7e,YIr),e(Pn,ZIr),e(Lo,KIr),e(Lo,m7e),e(m7e,L3),e(L3,g7e),e(g7e,eNr),e(L3,oNr),e(L3,are),e(are,rNr),e(L3,tNr),e(Lo,aNr),e(Lo,y3),e(y3,nNr),e(y3,h7e),e(h7e,sNr),e(y3,lNr),e(y3,u7e),e(u7e,iNr),e(Lo,dNr),M(x3,Lo,null),v(f,Dao,_),v(f,ff,_),e(ff,$3),e($3,p7e),M(hR,p7e,null),e(ff,cNr),e(ff,_7e),e(_7e,fNr),v(f,Gao,_),v(f,cr,_),M(uR,cr,null),e(cr,mNr),e(cr,mf),e(mf,gNr),e(mf,nre),e(nre,hNr),e(mf,uNr),e(mf,sre),e(sre,pNr),e(mf,_Nr),e(cr,vNr),e(cr,pR),e(pR,bNr),e(pR,v7e),e(v7e,FNr),e(pR,TNr),e(cr,MNr),e(cr,Yt),M(_R,Yt,null),e(Yt,ENr),e(Yt,b7e),e(b7e,CNr),e(Yt,wNr),e(Yt,gf),e(gf,ANr),e(gf,F7e),e(F7e,LNr),e(gf,yNr),e(gf,lre),e(lre,xNr),e(gf,$Nr),e(Yt,kNr),M(k3,Yt,null),e(cr,SNr),e(cr,Dr),M(vR,Dr,null),e(Dr,RNr),e(Dr,T7e),e(T7e,PNr),e(Dr,BNr),e(Dr,Bn),e(Bn,INr),e(Bn,M7e),e(M7e,NNr),e(Bn,qNr),e(Bn,E7e),e(E7e,jNr),e(Bn,DNr),e(Bn,C7e),e(C7e,GNr),e(Bn,ONr),e(Dr,VNr),e(Dr,P),e(P,S3),e(S3,w7e),e(w7e,XNr),e(S3,zNr),e(S3,ire),e(ire,QNr),e(S3,WNr),e(P,UNr),e(P,R3),e(R3,A7e),e(A7e,HNr),e(R3,JNr),e(R3,dre),e(dre,YNr),e(R3,ZNr),e(P,KNr),e(P,P3),e(P3,L7e),e(L7e,eqr),e(P3,oqr),e(P3,cre),e(cre,rqr),e(P3,tqr),e(P,aqr),e(P,B3),e(B3,y7e),e(y7e,nqr),e(B3,sqr),e(B3,fre),e(fre,lqr),e(B3,iqr),e(P,dqr),e(P,I3),e(I3,x7e),e(x7e,cqr),e(I3,fqr),e(I3,mre),e(mre,mqr),e(I3,gqr),e(P,hqr),e(P,N3),e(N3,$7e),e($7e,uqr),e(N3,pqr),e(N3,gre),e(gre,_qr),e(N3,vqr),e(P,bqr),e(P,q3),e(q3,k7e),e(k7e,Fqr),e(q3,Tqr),e(q3,hre),e(hre,Mqr),e(q3,Eqr),e(P,Cqr),e(P,j3),e(j3,S7e),e(S7e,wqr),e(j3,Aqr),e(j3,ure),e(ure,Lqr),e(j3,yqr),e(P,xqr),e(P,D3),e(D3,R7e),e(R7e,$qr),e(D3,kqr),e(D3,pre),e(pre,Sqr),e(D3,Rqr),e(P,Pqr),e(P,G3),e(G3,P7e),e(P7e,Bqr),e(G3,Iqr),e(G3,_re),e(_re,Nqr),e(G3,qqr),e(P,jqr),e(P,O3),e(O3,B7e),e(B7e,Dqr),e(O3,Gqr),e(O3,vre),e(vre,Oqr),e(O3,Vqr),e(P,Xqr),e(P,V3),e(V3,I7e),e(I7e,zqr),e(V3,Qqr),e(V3,bre),e(bre,Wqr),e(V3,Uqr),e(P,Hqr),e(P,X3),e(X3,N7e),e(N7e,Jqr),e(X3,Yqr),e(X3,Fre),e(Fre,Zqr),e(X3,Kqr),e(P,ejr),e(P,z3),e(z3,q7e),e(q7e,ojr),e(z3,rjr),e(z3,Tre),e(Tre,tjr),e(z3,ajr),e(P,njr),e(P,Q3),e(Q3,j7e),e(j7e,sjr),e(Q3,ljr),e(Q3,Mre),e(Mre,ijr),e(Q3,djr),e(P,cjr),e(P,W3),e(W3,D7e),e(D7e,fjr),e(W3,mjr),e(W3,Ere),e(Ere,gjr),e(W3,hjr),e(P,ujr),e(P,U3),e(U3,G7e),e(G7e,pjr),e(U3,_jr),e(U3,Cre),e(Cre,vjr),e(U3,bjr),e(P,Fjr),e(P,H3),e(H3,O7e),e(O7e,Tjr),e(H3,Mjr),e(H3,wre),e(wre,Ejr),e(H3,Cjr),e(P,wjr),e(P,J3),e(J3,V7e),e(V7e,Ajr),e(J3,Ljr),e(J3,Are),e(Are,yjr),e(J3,xjr),e(P,$jr),e(P,Y3),e(Y3,X7e),e(X7e,kjr),e(Y3,Sjr),e(Y3,Lre),e(Lre,Rjr),e(Y3,Pjr),e(P,Bjr),e(P,Sl),e(Sl,z7e),e(z7e,Ijr),e(Sl,Njr),e(Sl,yre),e(yre,qjr),e(Sl,jjr),e(Sl,xre),e(xre,Djr),e(Sl,Gjr),e(P,Ojr),e(P,Z3),e(Z3,Q7e),e(Q7e,Vjr),e(Z3,Xjr),e(Z3,$re),e($re,zjr),e(Z3,Qjr),e(P,Wjr),e(P,K3),e(K3,W7e),e(W7e,Ujr),e(K3,Hjr),e(K3,kre),e(kre,Jjr),e(K3,Yjr),e(P,Zjr),e(P,e5),e(e5,U7e),e(U7e,Kjr),e(e5,eDr),e(e5,Sre),e(Sre,oDr),e(e5,rDr),e(P,tDr),e(P,o5),e(o5,H7e),e(H7e,aDr),e(o5,nDr),e(o5,Rre),e(Rre,sDr),e(o5,lDr),e(P,iDr),e(P,r5),e(r5,J7e),e(J7e,dDr),e(r5,cDr),e(r5,Pre),e(Pre,fDr),e(r5,mDr),e(P,gDr),e(P,t5),e(t5,Y7e),e(Y7e,hDr),e(t5,uDr),e(t5,Bre),e(Bre,pDr),e(t5,_Dr),e(P,vDr),e(P,a5),e(a5,Z7e),e(Z7e,bDr),e(a5,FDr),e(a5,Ire),e(Ire,TDr),e(a5,MDr),e(P,EDr),e(P,n5),e(n5,K7e),e(K7e,CDr),e(n5,wDr),e(n5,Nre),e(Nre,ADr),e(n5,LDr),e(P,yDr),e(P,s5),e(s5,e8e),e(e8e,xDr),e(s5,$Dr),e(s5,qre),e(qre,kDr),e(s5,SDr),e(P,RDr),e(P,l5),e(l5,o8e),e(o8e,PDr),e(l5,BDr),e(l5,jre),e(jre,IDr),e(l5,NDr),e(P,qDr),e(P,i5),e(i5,r8e),e(r8e,jDr),e(i5,DDr),e(i5,Dre),e(Dre,GDr),e(i5,ODr),e(P,VDr),e(P,d5),e(d5,t8e),e(t8e,XDr),e(d5,zDr),e(d5,Gre),e(Gre,QDr),e(d5,WDr),e(P,UDr),e(P,c5),e(c5,a8e),e(a8e,HDr),e(c5,JDr),e(c5,Ore),e(Ore,YDr),e(c5,ZDr),e(P,KDr),e(P,f5),e(f5,n8e),e(n8e,eGr),e(f5,oGr),e(f5,Vre),e(Vre,rGr),e(f5,tGr),e(P,aGr),e(P,m5),e(m5,s8e),e(s8e,nGr),e(m5,sGr),e(m5,Xre),e(Xre,lGr),e(m5,iGr),e(P,dGr),e(P,g5),e(g5,l8e),e(l8e,cGr),e(g5,fGr),e(g5,zre),e(zre,mGr),e(g5,gGr),e(P,hGr),e(P,h5),e(h5,i8e),e(i8e,uGr),e(h5,pGr),e(h5,Qre),e(Qre,_Gr),e(h5,vGr),e(P,bGr),e(P,u5),e(u5,d8e),e(d8e,FGr),e(u5,TGr),e(u5,Wre),e(Wre,MGr),e(u5,EGr),e(P,CGr),e(P,p5),e(p5,c8e),e(c8e,wGr),e(p5,AGr),e(p5,Ure),e(Ure,LGr),e(p5,yGr),e(P,xGr),e(P,_5),e(_5,f8e),e(f8e,$Gr),e(_5,kGr),e(_5,Hre),e(Hre,SGr),e(_5,RGr),e(P,PGr),e(P,v5),e(v5,m8e),e(m8e,BGr),e(v5,IGr),e(v5,Jre),e(Jre,NGr),e(v5,qGr),e(P,jGr),e(P,b5),e(b5,g8e),e(g8e,DGr),e(b5,GGr),e(b5,Yre),e(Yre,OGr),e(b5,VGr),e(P,XGr),e(P,F5),e(F5,h8e),e(h8e,zGr),e(F5,QGr),e(F5,Zre),e(Zre,WGr),e(F5,UGr),e(P,HGr),e(P,T5),e(T5,u8e),e(u8e,JGr),e(T5,YGr),e(T5,Kre),e(Kre,ZGr),e(T5,KGr),e(P,eOr),e(P,M5),e(M5,p8e),e(p8e,oOr),e(M5,rOr),e(M5,ete),e(ete,tOr),e(M5,aOr),e(P,nOr),e(P,E5),e(E5,_8e),e(_8e,sOr),e(E5,lOr),e(E5,ote),e(ote,iOr),e(E5,dOr),e(P,cOr),e(P,C5),e(C5,v8e),e(v8e,fOr),e(C5,mOr),e(C5,rte),e(rte,gOr),e(C5,hOr),e(P,uOr),e(P,w5),e(w5,b8e),e(b8e,pOr),e(w5,_Or),e(w5,tte),e(tte,vOr),e(w5,bOr),e(P,FOr),e(P,A5),e(A5,F8e),e(F8e,TOr),e(A5,MOr),e(A5,ate),e(ate,EOr),e(A5,COr),e(P,wOr),e(P,L5),e(L5,T8e),e(T8e,AOr),e(L5,LOr),e(L5,nte),e(nte,yOr),e(L5,xOr),e(P,$Or),e(P,y5),e(y5,M8e),e(M8e,kOr),e(y5,SOr),e(y5,ste),e(ste,ROr),e(y5,POr),e(P,BOr),e(P,x5),e(x5,E8e),e(E8e,IOr),e(x5,NOr),e(x5,lte),e(lte,qOr),e(x5,jOr),e(P,DOr),e(P,$5),e($5,C8e),e(C8e,GOr),e($5,OOr),e($5,ite),e(ite,VOr),e($5,XOr),e(P,zOr),e(P,k5),e(k5,w8e),e(w8e,QOr),e(k5,WOr),e(k5,dte),e(dte,UOr),e(k5,HOr),e(P,JOr),e(P,S5),e(S5,A8e),e(A8e,YOr),e(S5,ZOr),e(S5,cte),e(cte,KOr),e(S5,eVr),e(P,oVr),e(P,R5),e(R5,L8e),e(L8e,rVr),e(R5,tVr),e(R5,fte),e(fte,aVr),e(R5,nVr),e(P,sVr),e(P,P5),e(P5,y8e),e(y8e,lVr),e(P5,iVr),e(P5,mte),e(mte,dVr),e(P5,cVr),e(Dr,fVr),M(B5,Dr,null),v(f,Oao,_),v(f,hf,_),e(hf,I5),e(I5,x8e),M(bR,x8e,null),e(hf,mVr),e(hf,$8e),e($8e,gVr),v(f,Vao,_),v(f,fr,_),M(FR,fr,null),e(fr,hVr),e(fr,uf),e(uf,uVr),e(uf,gte),e(gte,pVr),e(uf,_Vr),e(uf,hte),e(hte,vVr),e(uf,bVr),e(fr,FVr),e(fr,TR),e(TR,TVr),e(TR,k8e),e(k8e,MVr),e(TR,EVr),e(fr,CVr),e(fr,Zt),M(MR,Zt,null),e(Zt,wVr),e(Zt,S8e),e(S8e,AVr),e(Zt,LVr),e(Zt,pf),e(pf,yVr),e(pf,R8e),e(R8e,xVr),e(pf,$Vr),e(pf,ute),e(ute,kVr),e(pf,SVr),e(Zt,RVr),M(N5,Zt,null),e(fr,PVr),e(fr,Gr),M(ER,Gr,null),e(Gr,BVr),e(Gr,P8e),e(P8e,IVr),e(Gr,NVr),e(Gr,In),e(In,qVr),e(In,B8e),e(B8e,jVr),e(In,DVr),e(In,I8e),e(I8e,GVr),e(In,OVr),e(In,N8e),e(N8e,VVr),e(In,XVr),e(Gr,zVr),e(Gr,se),e(se,q5),e(q5,q8e),e(q8e,QVr),e(q5,WVr),e(q5,pte),e(pte,UVr),e(q5,HVr),e(se,JVr),e(se,j5),e(j5,j8e),e(j8e,YVr),e(j5,ZVr),e(j5,_te),e(_te,KVr),e(j5,eXr),e(se,oXr),e(se,D5),e(D5,D8e),e(D8e,rXr),e(D5,tXr),e(D5,vte),e(vte,aXr),e(D5,nXr),e(se,sXr),e(se,G5),e(G5,G8e),e(G8e,lXr),e(G5,iXr),e(G5,bte),e(bte,dXr),e(G5,cXr),e(se,fXr),e(se,O5),e(O5,O8e),e(O8e,mXr),e(O5,gXr),e(O5,Fte),e(Fte,hXr),e(O5,uXr),e(se,pXr),e(se,V5),e(V5,V8e),e(V8e,_Xr),e(V5,vXr),e(V5,Tte),e(Tte,bXr),e(V5,FXr),e(se,TXr),e(se,X5),e(X5,X8e),e(X8e,MXr),e(X5,EXr),e(X5,Mte),e(Mte,CXr),e(X5,wXr),e(se,AXr),e(se,z5),e(z5,z8e),e(z8e,LXr),e(z5,yXr),e(z5,Ete),e(Ete,xXr),e(z5,$Xr),e(se,kXr),e(se,Q5),e(Q5,Q8e),e(Q8e,SXr),e(Q5,RXr),e(Q5,Cte),e(Cte,PXr),e(Q5,BXr),e(se,IXr),e(se,W5),e(W5,W8e),e(W8e,NXr),e(W5,qXr),e(W5,wte),e(wte,jXr),e(W5,DXr),e(se,GXr),e(se,U5),e(U5,U8e),e(U8e,OXr),e(U5,VXr),e(U5,Ate),e(Ate,XXr),e(U5,zXr),e(se,QXr),e(se,H5),e(H5,H8e),e(H8e,WXr),e(H5,UXr),e(H5,Lte),e(Lte,HXr),e(H5,JXr),e(se,YXr),e(se,J5),e(J5,J8e),e(J8e,ZXr),e(J5,KXr),e(J5,yte),e(yte,ezr),e(J5,ozr),e(se,rzr),e(se,Y5),e(Y5,Y8e),e(Y8e,tzr),e(Y5,azr),e(Y5,xte),e(xte,nzr),e(Y5,szr),e(se,lzr),e(se,Z5),e(Z5,Z8e),e(Z8e,izr),e(Z5,dzr),e(Z5,$te),e($te,czr),e(Z5,fzr),e(se,mzr),e(se,K5),e(K5,K8e),e(K8e,gzr),e(K5,hzr),e(K5,kte),e(kte,uzr),e(K5,pzr),e(se,_zr),e(se,ew),e(ew,eLe),e(eLe,vzr),e(ew,bzr),e(ew,Ste),e(Ste,Fzr),e(ew,Tzr),e(se,Mzr),e(se,ow),e(ow,oLe),e(oLe,Ezr),e(ow,Czr),e(ow,Rte),e(Rte,wzr),e(ow,Azr),e(se,Lzr),e(se,rw),e(rw,rLe),e(rLe,yzr),e(rw,xzr),e(rw,Pte),e(Pte,$zr),e(rw,kzr),e(se,Szr),e(se,tw),e(tw,tLe),e(tLe,Rzr),e(tw,Pzr),e(tw,Bte),e(Bte,Bzr),e(tw,Izr),e(se,Nzr),e(se,aw),e(aw,aLe),e(aLe,qzr),e(aw,jzr),e(aw,Ite),e(Ite,Dzr),e(aw,Gzr),e(se,Ozr),e(se,nw),e(nw,nLe),e(nLe,Vzr),e(nw,Xzr),e(nw,Nte),e(Nte,zzr),e(nw,Qzr),e(se,Wzr),e(se,sw),e(sw,sLe),e(sLe,Uzr),e(sw,Hzr),e(sw,qte),e(qte,Jzr),e(sw,Yzr),e(Gr,Zzr),M(lw,Gr,null),v(f,Xao,_),v(f,_f,_),e(_f,iw),e(iw,lLe),M(CR,lLe,null),e(_f,Kzr),e(_f,iLe),e(iLe,eQr),v(f,zao,_),v(f,mr,_),M(wR,mr,null),e(mr,oQr),e(mr,vf),e(vf,rQr),e(vf,jte),e(jte,tQr),e(vf,aQr),e(vf,Dte),e(Dte,nQr),e(vf,sQr),e(mr,lQr),e(mr,AR),e(AR,iQr),e(AR,dLe),e(dLe,dQr),e(AR,cQr),e(mr,fQr),e(mr,Kt),M(LR,Kt,null),e(Kt,mQr),e(Kt,cLe),e(cLe,gQr),e(Kt,hQr),e(Kt,bf),e(bf,uQr),e(bf,fLe),e(fLe,pQr),e(bf,_Qr),e(bf,Gte),e(Gte,vQr),e(bf,bQr),e(Kt,FQr),M(dw,Kt,null),e(mr,TQr),e(mr,Or),M(yR,Or,null),e(Or,MQr),e(Or,mLe),e(mLe,EQr),e(Or,CQr),e(Or,Nn),e(Nn,wQr),e(Nn,gLe),e(gLe,AQr),e(Nn,LQr),e(Nn,hLe),e(hLe,yQr),e(Nn,xQr),e(Nn,uLe),e(uLe,$Qr),e(Nn,kQr),e(Or,SQr),e(Or,Me),e(Me,cw),e(cw,pLe),e(pLe,RQr),e(cw,PQr),e(cw,Ote),e(Ote,BQr),e(cw,IQr),e(Me,NQr),e(Me,fw),e(fw,_Le),e(_Le,qQr),e(fw,jQr),e(fw,Vte),e(Vte,DQr),e(fw,GQr),e(Me,OQr),e(Me,mw),e(mw,vLe),e(vLe,VQr),e(mw,XQr),e(mw,Xte),e(Xte,zQr),e(mw,QQr),e(Me,WQr),e(Me,gw),e(gw,bLe),e(bLe,UQr),e(gw,HQr),e(gw,zte),e(zte,JQr),e(gw,YQr),e(Me,ZQr),e(Me,hw),e(hw,FLe),e(FLe,KQr),e(hw,eWr),e(hw,Qte),e(Qte,oWr),e(hw,rWr),e(Me,tWr),e(Me,uw),e(uw,TLe),e(TLe,aWr),e(uw,nWr),e(uw,Wte),e(Wte,sWr),e(uw,lWr),e(Me,iWr),e(Me,pw),e(pw,MLe),e(MLe,dWr),e(pw,cWr),e(pw,Ute),e(Ute,fWr),e(pw,mWr),e(Me,gWr),e(Me,_w),e(_w,ELe),e(ELe,hWr),e(_w,uWr),e(_w,Hte),e(Hte,pWr),e(_w,_Wr),e(Me,vWr),e(Me,vw),e(vw,CLe),e(CLe,bWr),e(vw,FWr),e(vw,Jte),e(Jte,TWr),e(vw,MWr),e(Me,EWr),e(Me,bw),e(bw,wLe),e(wLe,CWr),e(bw,wWr),e(bw,Yte),e(Yte,AWr),e(bw,LWr),e(Me,yWr),e(Me,Fw),e(Fw,ALe),e(ALe,xWr),e(Fw,$Wr),e(Fw,Zte),e(Zte,kWr),e(Fw,SWr),e(Me,RWr),e(Me,Tw),e(Tw,LLe),e(LLe,PWr),e(Tw,BWr),e(Tw,Kte),e(Kte,IWr),e(Tw,NWr),e(Me,qWr),e(Me,Mw),e(Mw,yLe),e(yLe,jWr),e(Mw,DWr),e(Mw,eae),e(eae,GWr),e(Mw,OWr),e(Me,VWr),e(Me,Ew),e(Ew,xLe),e(xLe,XWr),e(Ew,zWr),e(Ew,oae),e(oae,QWr),e(Ew,WWr),e(Or,UWr),M(Cw,Or,null),v(f,Qao,_),v(f,Ff,_),e(Ff,ww),e(ww,$Le),M(xR,$Le,null),e(Ff,HWr),e(Ff,kLe),e(kLe,JWr),v(f,Wao,_),v(f,gr,_),M($R,gr,null),e(gr,YWr),e(gr,Tf),e(Tf,ZWr),e(Tf,rae),e(rae,KWr),e(Tf,eUr),e(Tf,tae),e(tae,oUr),e(Tf,rUr),e(gr,tUr),e(gr,kR),e(kR,aUr),e(kR,SLe),e(SLe,nUr),e(kR,sUr),e(gr,lUr),e(gr,ea),M(SR,ea,null),e(ea,iUr),e(ea,RLe),e(RLe,dUr),e(ea,cUr),e(ea,Mf),e(Mf,fUr),e(Mf,PLe),e(PLe,mUr),e(Mf,gUr),e(Mf,aae),e(aae,hUr),e(Mf,uUr),e(ea,pUr),M(Aw,ea,null),e(gr,_Ur),e(gr,Vr),M(RR,Vr,null),e(Vr,vUr),e(Vr,BLe),e(BLe,bUr),e(Vr,FUr),e(Vr,qn),e(qn,TUr),e(qn,ILe),e(ILe,MUr),e(qn,EUr),e(qn,NLe),e(NLe,CUr),e(qn,wUr),e(qn,qLe),e(qLe,AUr),e(qn,LUr),e(Vr,yUr),e(Vr,ye),e(ye,Lw),e(Lw,jLe),e(jLe,xUr),e(Lw,$Ur),e(Lw,nae),e(nae,kUr),e(Lw,SUr),e(ye,RUr),e(ye,yw),e(yw,DLe),e(DLe,PUr),e(yw,BUr),e(yw,sae),e(sae,IUr),e(yw,NUr),e(ye,qUr),e(ye,xw),e(xw,GLe),e(GLe,jUr),e(xw,DUr),e(xw,lae),e(lae,GUr),e(xw,OUr),e(ye,VUr),e(ye,Rl),e(Rl,OLe),e(OLe,XUr),e(Rl,zUr),e(Rl,iae),e(iae,QUr),e(Rl,WUr),e(Rl,dae),e(dae,UUr),e(Rl,HUr),e(ye,JUr),e(ye,$w),e($w,VLe),e(VLe,YUr),e($w,ZUr),e($w,cae),e(cae,KUr),e($w,eHr),e(ye,oHr),e(ye,kw),e(kw,XLe),e(XLe,rHr),e(kw,tHr),e(kw,fae),e(fae,aHr),e(kw,nHr),e(ye,sHr),e(ye,Sw),e(Sw,zLe),e(zLe,lHr),e(Sw,iHr),e(Sw,mae),e(mae,dHr),e(Sw,cHr),e(ye,fHr),e(ye,Rw),e(Rw,QLe),e(QLe,mHr),e(Rw,gHr),e(Rw,gae),e(gae,hHr),e(Rw,uHr),e(ye,pHr),e(ye,Pw),e(Pw,WLe),e(WLe,_Hr),e(Pw,vHr),e(Pw,hae),e(hae,bHr),e(Pw,FHr),e(ye,THr),e(ye,Bw),e(Bw,ULe),e(ULe,MHr),e(Bw,EHr),e(Bw,uae),e(uae,CHr),e(Bw,wHr),e(Vr,AHr),M(Iw,Vr,null),v(f,Uao,_),v(f,Ef,_),e(Ef,Nw),e(Nw,HLe),M(PR,HLe,null),e(Ef,LHr),e(Ef,JLe),e(JLe,yHr),v(f,Hao,_),v(f,hr,_),M(BR,hr,null),e(hr,xHr),e(hr,Cf),e(Cf,$Hr),e(Cf,pae),e(pae,kHr),e(Cf,SHr),e(Cf,_ae),e(_ae,RHr),e(Cf,PHr),e(hr,BHr),e(hr,IR),e(IR,IHr),e(IR,YLe),e(YLe,NHr),e(IR,qHr),e(hr,jHr),e(hr,oa),M(NR,oa,null),e(oa,DHr),e(oa,ZLe),e(ZLe,GHr),e(oa,OHr),e(oa,wf),e(wf,VHr),e(wf,KLe),e(KLe,XHr),e(wf,zHr),e(wf,vae),e(vae,QHr),e(wf,WHr),e(oa,UHr),M(qw,oa,null),e(hr,HHr),e(hr,Xr),M(qR,Xr,null),e(Xr,JHr),e(Xr,eye),e(eye,YHr),e(Xr,ZHr),e(Xr,jn),e(jn,KHr),e(jn,oye),e(oye,eJr),e(jn,oJr),e(jn,rye),e(rye,rJr),e(jn,tJr),e(jn,tye),e(tye,aJr),e(jn,nJr),e(Xr,sJr),e(Xr,Af),e(Af,jw),e(jw,aye),e(aye,lJr),e(jw,iJr),e(jw,bae),e(bae,dJr),e(jw,cJr),e(Af,fJr),e(Af,Dw),e(Dw,nye),e(nye,mJr),e(Dw,gJr),e(Dw,Fae),e(Fae,hJr),e(Dw,uJr),e(Af,pJr),e(Af,Gw),e(Gw,sye),e(sye,_Jr),e(Gw,vJr),e(Gw,Tae),e(Tae,bJr),e(Gw,FJr),e(Xr,TJr),M(Ow,Xr,null),v(f,Jao,_),v(f,Lf,_),e(Lf,Vw),e(Vw,lye),M(jR,lye,null),e(Lf,MJr),e(Lf,iye),e(iye,EJr),v(f,Yao,_),v(f,ur,_),M(DR,ur,null),e(ur,CJr),e(ur,yf),e(yf,wJr),e(yf,Mae),e(Mae,AJr),e(yf,LJr),e(yf,Eae),e(Eae,yJr),e(yf,xJr),e(ur,$Jr),e(ur,GR),e(GR,kJr),e(GR,dye),e(dye,SJr),e(GR,RJr),e(ur,PJr),e(ur,ra),M(OR,ra,null),e(ra,BJr),e(ra,cye),e(cye,IJr),e(ra,NJr),e(ra,xf),e(xf,qJr),e(xf,fye),e(fye,jJr),e(xf,DJr),e(xf,Cae),e(Cae,GJr),e(xf,OJr),e(ra,VJr),M(Xw,ra,null),e(ur,XJr),e(ur,zr),M(VR,zr,null),e(zr,zJr),e(zr,mye),e(mye,QJr),e(zr,WJr),e(zr,Dn),e(Dn,UJr),e(Dn,gye),e(gye,HJr),e(Dn,JJr),e(Dn,hye),e(hye,YJr),e(Dn,ZJr),e(Dn,uye),e(uye,KJr),e(Dn,eYr),e(zr,oYr),e(zr,ce),e(ce,zw),e(zw,pye),e(pye,rYr),e(zw,tYr),e(zw,wae),e(wae,aYr),e(zw,nYr),e(ce,sYr),e(ce,Qw),e(Qw,_ye),e(_ye,lYr),e(Qw,iYr),e(Qw,Aae),e(Aae,dYr),e(Qw,cYr),e(ce,fYr),e(ce,Ww),e(Ww,vye),e(vye,mYr),e(Ww,gYr),e(Ww,Lae),e(Lae,hYr),e(Ww,uYr),e(ce,pYr),e(ce,Uw),e(Uw,bye),e(bye,_Yr),e(Uw,vYr),e(Uw,yae),e(yae,bYr),e(Uw,FYr),e(ce,TYr),e(ce,Hw),e(Hw,Fye),e(Fye,MYr),e(Hw,EYr),e(Hw,xae),e(xae,CYr),e(Hw,wYr),e(ce,AYr),e(ce,Jw),e(Jw,Tye),e(Tye,LYr),e(Jw,yYr),e(Jw,$ae),e($ae,xYr),e(Jw,$Yr),e(ce,kYr),e(ce,Yw),e(Yw,Mye),e(Mye,SYr),e(Yw,RYr),e(Yw,kae),e(kae,PYr),e(Yw,BYr),e(ce,IYr),e(ce,Zw),e(Zw,Eye),e(Eye,NYr),e(Zw,qYr),e(Zw,Sae),e(Sae,jYr),e(Zw,DYr),e(ce,GYr),e(ce,Kw),e(Kw,Cye),e(Cye,OYr),e(Kw,VYr),e(Kw,Rae),e(Rae,XYr),e(Kw,zYr),e(ce,QYr),e(ce,eA),e(eA,wye),e(wye,WYr),e(eA,UYr),e(eA,Pae),e(Pae,HYr),e(eA,JYr),e(ce,YYr),e(ce,oA),e(oA,Aye),e(Aye,ZYr),e(oA,KYr),e(oA,Bae),e(Bae,eZr),e(oA,oZr),e(ce,rZr),e(ce,rA),e(rA,Lye),e(Lye,tZr),e(rA,aZr),e(rA,Iae),e(Iae,nZr),e(rA,sZr),e(ce,lZr),e(ce,tA),e(tA,yye),e(yye,iZr),e(tA,dZr),e(tA,Nae),e(Nae,cZr),e(tA,fZr),e(ce,mZr),e(ce,aA),e(aA,xye),e(xye,gZr),e(aA,hZr),e(aA,qae),e(qae,uZr),e(aA,pZr),e(ce,_Zr),e(ce,nA),e(nA,$ye),e($ye,vZr),e(nA,bZr),e(nA,jae),e(jae,FZr),e(nA,TZr),e(ce,MZr),e(ce,sA),e(sA,kye),e(kye,EZr),e(sA,CZr),e(sA,Dae),e(Dae,wZr),e(sA,AZr),e(ce,LZr),e(ce,lA),e(lA,Sye),e(Sye,yZr),e(lA,xZr),e(lA,Gae),e(Gae,$Zr),e(lA,kZr),e(ce,SZr),e(ce,iA),e(iA,Rye),e(Rye,RZr),e(iA,PZr),e(iA,Oae),e(Oae,BZr),e(iA,IZr),e(ce,NZr),e(ce,dA),e(dA,Pye),e(Pye,qZr),e(dA,jZr),e(dA,Vae),e(Vae,DZr),e(dA,GZr),e(ce,OZr),e(ce,cA),e(cA,Bye),e(Bye,VZr),e(cA,XZr),e(cA,Xae),e(Xae,zZr),e(cA,QZr),e(ce,WZr),e(ce,fA),e(fA,Iye),e(Iye,UZr),e(fA,HZr),e(fA,zae),e(zae,JZr),e(fA,YZr),e(zr,ZZr),M(mA,zr,null),v(f,Zao,_),v(f,$f,_),e($f,gA),e(gA,Nye),M(XR,Nye,null),e($f,KZr),e($f,qye),e(qye,eKr),v(f,Kao,_),v(f,pr,_),M(zR,pr,null),e(pr,oKr),e(pr,kf),e(kf,rKr),e(kf,Qae),e(Qae,tKr),e(kf,aKr),e(kf,Wae),e(Wae,nKr),e(kf,sKr),e(pr,lKr),e(pr,QR),e(QR,iKr),e(QR,jye),e(jye,dKr),e(QR,cKr),e(pr,fKr),e(pr,ta),M(WR,ta,null),e(ta,mKr),e(ta,Dye),e(Dye,gKr),e(ta,hKr),e(ta,Sf),e(Sf,uKr),e(Sf,Gye),e(Gye,pKr),e(Sf,_Kr),e(Sf,Uae),e(Uae,vKr),e(Sf,bKr),e(ta,FKr),M(hA,ta,null),e(pr,TKr),e(pr,Qr),M(UR,Qr,null),e(Qr,MKr),e(Qr,Oye),e(Oye,EKr),e(Qr,CKr),e(Qr,Gn),e(Gn,wKr),e(Gn,Vye),e(Vye,AKr),e(Gn,LKr),e(Gn,Xye),e(Xye,yKr),e(Gn,xKr),e(Gn,zye),e(zye,$Kr),e(Gn,kKr),e(Qr,SKr),e(Qr,xe),e(xe,uA),e(uA,Qye),e(Qye,RKr),e(uA,PKr),e(uA,Hae),e(Hae,BKr),e(uA,IKr),e(xe,NKr),e(xe,pA),e(pA,Wye),e(Wye,qKr),e(pA,jKr),e(pA,Jae),e(Jae,DKr),e(pA,GKr),e(xe,OKr),e(xe,_A),e(_A,Uye),e(Uye,VKr),e(_A,XKr),e(_A,Yae),e(Yae,zKr),e(_A,QKr),e(xe,WKr),e(xe,vA),e(vA,Hye),e(Hye,UKr),e(vA,HKr),e(vA,Zae),e(Zae,JKr),e(vA,YKr),e(xe,ZKr),e(xe,bA),e(bA,Jye),e(Jye,KKr),e(bA,eet),e(bA,Kae),e(Kae,oet),e(bA,ret),e(xe,tet),e(xe,FA),e(FA,Yye),e(Yye,aet),e(FA,net),e(FA,ene),e(ene,set),e(FA,iet),e(xe,det),e(xe,TA),e(TA,Zye),e(Zye,cet),e(TA,fet),e(TA,one),e(one,met),e(TA,get),e(xe,het),e(xe,MA),e(MA,Kye),e(Kye,uet),e(MA,pet),e(MA,rne),e(rne,_et),e(MA,vet),e(xe,bet),e(xe,EA),e(EA,e9e),e(e9e,Fet),e(EA,Tet),e(EA,tne),e(tne,Met),e(EA,Eet),e(xe,Cet),e(xe,CA),e(CA,o9e),e(o9e,wet),e(CA,Aet),e(CA,ane),e(ane,Let),e(CA,yet),e(Qr,xet),M(wA,Qr,null),v(f,eno,_),v(f,Rf,_),e(Rf,AA),e(AA,r9e),M(HR,r9e,null),e(Rf,$et),e(Rf,t9e),e(t9e,ket),v(f,ono,_),v(f,_r,_),M(JR,_r,null),e(_r,Set),e(_r,Pf),e(Pf,Ret),e(Pf,nne),e(nne,Pet),e(Pf,Bet),e(Pf,sne),e(sne,Iet),e(Pf,Net),e(_r,qet),e(_r,YR),e(YR,jet),e(YR,a9e),e(a9e,Det),e(YR,Get),e(_r,Oet),e(_r,aa),M(ZR,aa,null),e(aa,Vet),e(aa,n9e),e(n9e,Xet),e(aa,zet),e(aa,Bf),e(Bf,Qet),e(Bf,s9e),e(s9e,Wet),e(Bf,Uet),e(Bf,lne),e(lne,Het),e(Bf,Jet),e(aa,Yet),M(LA,aa,null),e(_r,Zet),e(_r,Wr),M(KR,Wr,null),e(Wr,Ket),e(Wr,l9e),e(l9e,eot),e(Wr,oot),e(Wr,On),e(On,rot),e(On,i9e),e(i9e,tot),e(On,aot),e(On,d9e),e(d9e,not),e(On,sot),e(On,c9e),e(c9e,lot),e(On,iot),e(Wr,dot),e(Wr,re),e(re,yA),e(yA,f9e),e(f9e,cot),e(yA,fot),e(yA,ine),e(ine,mot),e(yA,got),e(re,hot),e(re,xA),e(xA,m9e),e(m9e,uot),e(xA,pot),e(xA,dne),e(dne,_ot),e(xA,vot),e(re,bot),e(re,$A),e($A,g9e),e(g9e,Fot),e($A,Tot),e($A,cne),e(cne,Mot),e($A,Eot),e(re,Cot),e(re,kA),e(kA,h9e),e(h9e,wot),e(kA,Aot),e(kA,fne),e(fne,Lot),e(kA,yot),e(re,xot),e(re,SA),e(SA,u9e),e(u9e,$ot),e(SA,kot),e(SA,mne),e(mne,Sot),e(SA,Rot),e(re,Pot),e(re,RA),e(RA,p9e),e(p9e,Bot),e(RA,Iot),e(RA,gne),e(gne,Not),e(RA,qot),e(re,jot),e(re,PA),e(PA,_9e),e(_9e,Dot),e(PA,Got),e(PA,hne),e(hne,Oot),e(PA,Vot),e(re,Xot),e(re,BA),e(BA,v9e),e(v9e,zot),e(BA,Qot),e(BA,une),e(une,Wot),e(BA,Uot),e(re,Hot),e(re,IA),e(IA,b9e),e(b9e,Jot),e(IA,Yot),e(IA,pne),e(pne,Zot),e(IA,Kot),e(re,ert),e(re,NA),e(NA,F9e),e(F9e,ort),e(NA,rrt),e(NA,_ne),e(_ne,trt),e(NA,art),e(re,nrt),e(re,qA),e(qA,T9e),e(T9e,srt),e(qA,lrt),e(qA,vne),e(vne,irt),e(qA,drt),e(re,crt),e(re,jA),e(jA,M9e),e(M9e,frt),e(jA,mrt),e(jA,bne),e(bne,grt),e(jA,hrt),e(re,urt),e(re,DA),e(DA,E9e),e(E9e,prt),e(DA,_rt),e(DA,Fne),e(Fne,vrt),e(DA,brt),e(re,Frt),e(re,GA),e(GA,C9e),e(C9e,Trt),e(GA,Mrt),e(GA,Tne),e(Tne,Ert),e(GA,Crt),e(re,wrt),e(re,OA),e(OA,w9e),e(w9e,Art),e(OA,Lrt),e(OA,Mne),e(Mne,yrt),e(OA,xrt),e(re,$rt),e(re,VA),e(VA,A9e),e(A9e,krt),e(VA,Srt),e(VA,Ene),e(Ene,Rrt),e(VA,Prt),e(re,Brt),e(re,XA),e(XA,L9e),e(L9e,Irt),e(XA,Nrt),e(XA,Cne),e(Cne,qrt),e(XA,jrt),e(re,Drt),e(re,zA),e(zA,y9e),e(y9e,Grt),e(zA,Ort),e(zA,wne),e(wne,Vrt),e(zA,Xrt),e(re,zrt),e(re,QA),e(QA,x9e),e(x9e,Qrt),e(QA,Wrt),e(QA,Ane),e(Ane,Urt),e(QA,Hrt),e(re,Jrt),e(re,WA),e(WA,$9e),e($9e,Yrt),e(WA,Zrt),e(WA,Lne),e(Lne,Krt),e(WA,ett),e(re,ott),e(re,UA),e(UA,k9e),e(k9e,rtt),e(UA,ttt),e(UA,yne),e(yne,att),e(UA,ntt),e(re,stt),e(re,HA),e(HA,S9e),e(S9e,ltt),e(HA,itt),e(HA,xne),e(xne,dtt),e(HA,ctt),e(re,ftt),e(re,JA),e(JA,R9e),e(R9e,mtt),e(JA,gtt),e(JA,$ne),e($ne,htt),e(JA,utt),e(re,ptt),e(re,YA),e(YA,P9e),e(P9e,_tt),e(YA,vtt),e(YA,kne),e(kne,btt),e(YA,Ftt),e(re,Ttt),e(re,ZA),e(ZA,B9e),e(B9e,Mtt),e(ZA,Ett),e(ZA,Sne),e(Sne,Ctt),e(ZA,wtt),e(re,Att),e(re,KA),e(KA,I9e),e(I9e,Ltt),e(KA,ytt),e(KA,Rne),e(Rne,xtt),e(KA,$tt),e(re,ktt),e(re,e6),e(e6,N9e),e(N9e,Stt),e(e6,Rtt),e(e6,Pne),e(Pne,Ptt),e(e6,Btt),e(re,Itt),e(re,o6),e(o6,q9e),e(q9e,Ntt),e(o6,qtt),e(o6,Bne),e(Bne,jtt),e(o6,Dtt),e(Wr,Gtt),M(r6,Wr,null),v(f,rno,_),v(f,If,_),e(If,t6),e(t6,j9e),M(eP,j9e,null),e(If,Ott),e(If,D9e),e(D9e,Vtt),v(f,tno,_),v(f,vr,_),M(oP,vr,null),e(vr,Xtt),e(vr,Nf),e(Nf,ztt),e(Nf,Ine),e(Ine,Qtt),e(Nf,Wtt),e(Nf,Nne),e(Nne,Utt),e(Nf,Htt),e(vr,Jtt),e(vr,rP),e(rP,Ytt),e(rP,G9e),e(G9e,Ztt),e(rP,Ktt),e(vr,eat),e(vr,na),M(tP,na,null),e(na,oat),e(na,O9e),e(O9e,rat),e(na,tat),e(na,qf),e(qf,aat),e(qf,V9e),e(V9e,nat),e(qf,sat),e(qf,qne),e(qne,lat),e(qf,iat),e(na,dat),M(a6,na,null),e(vr,cat),e(vr,Ur),M(aP,Ur,null),e(Ur,fat),e(Ur,X9e),e(X9e,mat),e(Ur,gat),e(Ur,Vn),e(Vn,hat),e(Vn,z9e),e(z9e,uat),e(Vn,pat),e(Vn,Q9e),e(Q9e,_at),e(Vn,vat),e(Vn,W9e),e(W9e,bat),e(Vn,Fat),e(Ur,Tat),e(Ur,be),e(be,n6),e(n6,U9e),e(U9e,Mat),e(n6,Eat),e(n6,jne),e(jne,Cat),e(n6,wat),e(be,Aat),e(be,s6),e(s6,H9e),e(H9e,Lat),e(s6,yat),e(s6,Dne),e(Dne,xat),e(s6,$at),e(be,kat),e(be,l6),e(l6,J9e),e(J9e,Sat),e(l6,Rat),e(l6,Gne),e(Gne,Pat),e(l6,Bat),e(be,Iat),e(be,i6),e(i6,Y9e),e(Y9e,Nat),e(i6,qat),e(i6,One),e(One,jat),e(i6,Dat),e(be,Gat),e(be,d6),e(d6,Z9e),e(Z9e,Oat),e(d6,Vat),e(d6,Vne),e(Vne,Xat),e(d6,zat),e(be,Qat),e(be,c6),e(c6,K9e),e(K9e,Wat),e(c6,Uat),e(c6,Xne),e(Xne,Hat),e(c6,Jat),e(be,Yat),e(be,f6),e(f6,exe),e(exe,Zat),e(f6,Kat),e(f6,zne),e(zne,ent),e(f6,ont),e(be,rnt),e(be,m6),e(m6,oxe),e(oxe,tnt),e(m6,ant),e(m6,Qne),e(Qne,nnt),e(m6,snt),e(be,lnt),e(be,g6),e(g6,rxe),e(rxe,int),e(g6,dnt),e(g6,Wne),e(Wne,cnt),e(g6,fnt),e(be,mnt),e(be,h6),e(h6,txe),e(txe,gnt),e(h6,hnt),e(h6,Une),e(Une,unt),e(h6,pnt),e(be,_nt),e(be,u6),e(u6,axe),e(axe,vnt),e(u6,bnt),e(u6,Hne),e(Hne,Fnt),e(u6,Tnt),e(be,Mnt),e(be,p6),e(p6,nxe),e(nxe,Ent),e(p6,Cnt),e(p6,Jne),e(Jne,wnt),e(p6,Ant),e(be,Lnt),e(be,_6),e(_6,sxe),e(sxe,ynt),e(_6,xnt),e(_6,Yne),e(Yne,$nt),e(_6,knt),e(be,Snt),e(be,v6),e(v6,lxe),e(lxe,Rnt),e(v6,Pnt),e(v6,Zne),e(Zne,Bnt),e(v6,Int),e(be,Nnt),e(be,b6),e(b6,ixe),e(ixe,qnt),e(b6,jnt),e(b6,Kne),e(Kne,Dnt),e(b6,Gnt),e(be,Ont),e(be,F6),e(F6,dxe),e(dxe,Vnt),e(F6,Xnt),e(F6,ese),e(ese,znt),e(F6,Qnt),e(be,Wnt),e(be,T6),e(T6,cxe),e(cxe,Unt),e(T6,Hnt),e(T6,ose),e(ose,Jnt),e(T6,Ynt),e(Ur,Znt),M(M6,Ur,null),v(f,ano,_),v(f,jf,_),e(jf,E6),e(E6,fxe),M(nP,fxe,null),e(jf,Knt),e(jf,mxe),e(mxe,est),v(f,nno,_),v(f,br,_),M(sP,br,null),e(br,ost),e(br,Df),e(Df,rst),e(Df,rse),e(rse,tst),e(Df,ast),e(Df,tse),e(tse,nst),e(Df,sst),e(br,lst),e(br,lP),e(lP,ist),e(lP,gxe),e(gxe,dst),e(lP,cst),e(br,fst),e(br,sa),M(iP,sa,null),e(sa,mst),e(sa,hxe),e(hxe,gst),e(sa,hst),e(sa,Gf),e(Gf,ust),e(Gf,uxe),e(uxe,pst),e(Gf,_st),e(Gf,ase),e(ase,vst),e(Gf,bst),e(sa,Fst),M(C6,sa,null),e(br,Tst),e(br,Hr),M(dP,Hr,null),e(Hr,Mst),e(Hr,pxe),e(pxe,Est),e(Hr,Cst),e(Hr,Xn),e(Xn,wst),e(Xn,_xe),e(_xe,Ast),e(Xn,Lst),e(Xn,vxe),e(vxe,yst),e(Xn,xst),e(Xn,bxe),e(bxe,$st),e(Xn,kst),e(Hr,Sst),e(Hr,cP),e(cP,w6),e(w6,Fxe),e(Fxe,Rst),e(w6,Pst),e(w6,nse),e(nse,Bst),e(w6,Ist),e(cP,Nst),e(cP,A6),e(A6,Txe),e(Txe,qst),e(A6,jst),e(A6,sse),e(sse,Dst),e(A6,Gst),e(Hr,Ost),M(L6,Hr,null),v(f,sno,_),v(f,Of,_),e(Of,y6),e(y6,Mxe),M(fP,Mxe,null),e(Of,Vst),e(Of,Exe),e(Exe,Xst),v(f,lno,_),v(f,Fr,_),M(mP,Fr,null),e(Fr,zst),e(Fr,Vf),e(Vf,Qst),e(Vf,lse),e(lse,Wst),e(Vf,Ust),e(Vf,ise),e(ise,Hst),e(Vf,Jst),e(Fr,Yst),e(Fr,gP),e(gP,Zst),e(gP,Cxe),e(Cxe,Kst),e(gP,elt),e(Fr,olt),e(Fr,la),M(hP,la,null),e(la,rlt),e(la,wxe),e(wxe,tlt),e(la,alt),e(la,Xf),e(Xf,nlt),e(Xf,Axe),e(Axe,slt),e(Xf,llt),e(Xf,dse),e(dse,ilt),e(Xf,dlt),e(la,clt),M(x6,la,null),e(Fr,flt),e(Fr,Jr),M(uP,Jr,null),e(Jr,mlt),e(Jr,Lxe),e(Lxe,glt),e(Jr,hlt),e(Jr,zn),e(zn,ult),e(zn,yxe),e(yxe,plt),e(zn,_lt),e(zn,xxe),e(xxe,vlt),e(zn,blt),e(zn,$xe),e($xe,Flt),e(zn,Tlt),e(Jr,Mlt),e(Jr,kxe),e(kxe,$6),e($6,Sxe),e(Sxe,Elt),e($6,Clt),e($6,cse),e(cse,wlt),e($6,Alt),e(Jr,Llt),M(k6,Jr,null),v(f,ino,_),v(f,zf,_),e(zf,S6),e(S6,Rxe),M(pP,Rxe,null),e(zf,ylt),e(zf,Pxe),e(Pxe,xlt),v(f,dno,_),v(f,Tr,_),M(_P,Tr,null),e(Tr,$lt),e(Tr,Qf),e(Qf,klt),e(Qf,fse),e(fse,Slt),e(Qf,Rlt),e(Qf,mse),e(mse,Plt),e(Qf,Blt),e(Tr,Ilt),e(Tr,vP),e(vP,Nlt),e(vP,Bxe),e(Bxe,qlt),e(vP,jlt),e(Tr,Dlt),e(Tr,ia),M(bP,ia,null),e(ia,Glt),e(ia,Ixe),e(Ixe,Olt),e(ia,Vlt),e(ia,Wf),e(Wf,Xlt),e(Wf,Nxe),e(Nxe,zlt),e(Wf,Qlt),e(Wf,gse),e(gse,Wlt),e(Wf,Ult),e(ia,Hlt),M(R6,ia,null),e(Tr,Jlt),e(Tr,Yr),M(FP,Yr,null),e(Yr,Ylt),e(Yr,qxe),e(qxe,Zlt),e(Yr,Klt),e(Yr,Qn),e(Qn,eit),e(Qn,jxe),e(jxe,oit),e(Qn,rit),e(Qn,Dxe),e(Dxe,tit),e(Qn,ait),e(Qn,Gxe),e(Gxe,nit),e(Qn,sit),e(Yr,lit),e(Yr,Oxe),e(Oxe,P6),e(P6,Vxe),e(Vxe,iit),e(P6,dit),e(P6,hse),e(hse,cit),e(P6,fit),e(Yr,mit),M(B6,Yr,null),v(f,cno,_),v(f,Uf,_),e(Uf,I6),e(I6,Xxe),M(TP,Xxe,null),e(Uf,git),e(Uf,zxe),e(zxe,hit),v(f,fno,_),v(f,Mr,_),M(MP,Mr,null),e(Mr,uit),e(Mr,Hf),e(Hf,pit),e(Hf,use),e(use,_it),e(Hf,vit),e(Hf,pse),e(pse,bit),e(Hf,Fit),e(Mr,Tit),e(Mr,EP),e(EP,Mit),e(EP,Qxe),e(Qxe,Eit),e(EP,Cit),e(Mr,wit),e(Mr,da),M(CP,da,null),e(da,Ait),e(da,Wxe),e(Wxe,Lit),e(da,yit),e(da,Jf),e(Jf,xit),e(Jf,Uxe),e(Uxe,$it),e(Jf,kit),e(Jf,_se),e(_se,Sit),e(Jf,Rit),e(da,Pit),M(N6,da,null),e(Mr,Bit),e(Mr,Zr),M(wP,Zr,null),e(Zr,Iit),e(Zr,Hxe),e(Hxe,Nit),e(Zr,qit),e(Zr,Wn),e(Wn,jit),e(Wn,Jxe),e(Jxe,Dit),e(Wn,Git),e(Wn,Yxe),e(Yxe,Oit),e(Wn,Vit),e(Wn,Zxe),e(Zxe,Xit),e(Wn,zit),e(Zr,Qit),e(Zr,ie),e(ie,q6),e(q6,Kxe),e(Kxe,Wit),e(q6,Uit),e(q6,vse),e(vse,Hit),e(q6,Jit),e(ie,Yit),e(ie,j6),e(j6,e$e),e(e$e,Zit),e(j6,Kit),e(j6,bse),e(bse,edt),e(j6,odt),e(ie,rdt),e(ie,D6),e(D6,o$e),e(o$e,tdt),e(D6,adt),e(D6,Fse),e(Fse,ndt),e(D6,sdt),e(ie,ldt),e(ie,G6),e(G6,r$e),e(r$e,idt),e(G6,ddt),e(G6,Tse),e(Tse,cdt),e(G6,fdt),e(ie,mdt),e(ie,O6),e(O6,t$e),e(t$e,gdt),e(O6,hdt),e(O6,Mse),e(Mse,udt),e(O6,pdt),e(ie,_dt),e(ie,V6),e(V6,a$e),e(a$e,vdt),e(V6,bdt),e(V6,Ese),e(Ese,Fdt),e(V6,Tdt),e(ie,Mdt),e(ie,X6),e(X6,n$e),e(n$e,Edt),e(X6,Cdt),e(X6,Cse),e(Cse,wdt),e(X6,Adt),e(ie,Ldt),e(ie,z6),e(z6,s$e),e(s$e,ydt),e(z6,xdt),e(z6,wse),e(wse,$dt),e(z6,kdt),e(ie,Sdt),e(ie,Q6),e(Q6,l$e),e(l$e,Rdt),e(Q6,Pdt),e(Q6,Ase),e(Ase,Bdt),e(Q6,Idt),e(ie,Ndt),e(ie,W6),e(W6,i$e),e(i$e,qdt),e(W6,jdt),e(W6,Lse),e(Lse,Ddt),e(W6,Gdt),e(ie,Odt),e(ie,U6),e(U6,d$e),e(d$e,Vdt),e(U6,Xdt),e(U6,yse),e(yse,zdt),e(U6,Qdt),e(ie,Wdt),e(ie,H6),e(H6,c$e),e(c$e,Udt),e(H6,Hdt),e(H6,xse),e(xse,Jdt),e(H6,Ydt),e(ie,Zdt),e(ie,J6),e(J6,f$e),e(f$e,Kdt),e(J6,ect),e(J6,$se),e($se,oct),e(J6,rct),e(ie,tct),e(ie,Y6),e(Y6,m$e),e(m$e,act),e(Y6,nct),e(Y6,kse),e(kse,sct),e(Y6,lct),e(ie,ict),e(ie,Z6),e(Z6,g$e),e(g$e,dct),e(Z6,cct),e(Z6,Sse),e(Sse,fct),e(Z6,mct),e(ie,gct),e(ie,K6),e(K6,h$e),e(h$e,hct),e(K6,uct),e(K6,Rse),e(Rse,pct),e(K6,_ct),e(ie,vct),e(ie,e7),e(e7,u$e),e(u$e,bct),e(e7,Fct),e(e7,Pse),e(Pse,Tct),e(e7,Mct),e(ie,Ect),e(ie,o7),e(o7,p$e),e(p$e,Cct),e(o7,wct),e(o7,Bse),e(Bse,Act),e(o7,Lct),e(ie,yct),e(ie,r7),e(r7,_$e),e(_$e,xct),e(r7,$ct),e(r7,Ise),e(Ise,kct),e(r7,Sct),e(ie,Rct),e(ie,t7),e(t7,v$e),e(v$e,Pct),e(t7,Bct),e(t7,Nse),e(Nse,Ict),e(t7,Nct),e(ie,qct),e(ie,a7),e(a7,b$e),e(b$e,jct),e(a7,Dct),e(a7,qse),e(qse,Gct),e(a7,Oct),e(ie,Vct),e(ie,n7),e(n7,F$e),e(F$e,Xct),e(n7,zct),e(n7,jse),e(jse,Qct),e(n7,Wct),e(Zr,Uct),M(s7,Zr,null),v(f,mno,_),v(f,Yf,_),e(Yf,l7),e(l7,T$e),M(AP,T$e,null),e(Yf,Hct),e(Yf,M$e),e(M$e,Jct),v(f,gno,_),v(f,Er,_),M(LP,Er,null),e(Er,Yct),e(Er,Zf),e(Zf,Zct),e(Zf,Dse),e(Dse,Kct),e(Zf,eft),e(Zf,Gse),e(Gse,oft),e(Zf,rft),e(Er,tft),e(Er,yP),e(yP,aft),e(yP,E$e),e(E$e,nft),e(yP,sft),e(Er,lft),e(Er,ca),M(xP,ca,null),e(ca,ift),e(ca,C$e),e(C$e,dft),e(ca,cft),e(ca,Kf),e(Kf,fft),e(Kf,w$e),e(w$e,mft),e(Kf,gft),e(Kf,Ose),e(Ose,hft),e(Kf,uft),e(ca,pft),M(i7,ca,null),e(Er,_ft),e(Er,Kr),M($P,Kr,null),e(Kr,vft),e(Kr,A$e),e(A$e,bft),e(Kr,Fft),e(Kr,Un),e(Un,Tft),e(Un,L$e),e(L$e,Mft),e(Un,Eft),e(Un,y$e),e(y$e,Cft),e(Un,wft),e(Un,x$e),e(x$e,Aft),e(Un,Lft),e(Kr,yft),e(Kr,fe),e(fe,d7),e(d7,$$e),e($$e,xft),e(d7,$ft),e(d7,Vse),e(Vse,kft),e(d7,Sft),e(fe,Rft),e(fe,c7),e(c7,k$e),e(k$e,Pft),e(c7,Bft),e(c7,Xse),e(Xse,Ift),e(c7,Nft),e(fe,qft),e(fe,f7),e(f7,S$e),e(S$e,jft),e(f7,Dft),e(f7,zse),e(zse,Gft),e(f7,Oft),e(fe,Vft),e(fe,m7),e(m7,R$e),e(R$e,Xft),e(m7,zft),e(m7,Qse),e(Qse,Qft),e(m7,Wft),e(fe,Uft),e(fe,g7),e(g7,P$e),e(P$e,Hft),e(g7,Jft),e(g7,Wse),e(Wse,Yft),e(g7,Zft),e(fe,Kft),e(fe,h7),e(h7,B$e),e(B$e,emt),e(h7,omt),e(h7,Use),e(Use,rmt),e(h7,tmt),e(fe,amt),e(fe,u7),e(u7,I$e),e(I$e,nmt),e(u7,smt),e(u7,Hse),e(Hse,lmt),e(u7,imt),e(fe,dmt),e(fe,p7),e(p7,N$e),e(N$e,cmt),e(p7,fmt),e(p7,Jse),e(Jse,mmt),e(p7,gmt),e(fe,hmt),e(fe,_7),e(_7,q$e),e(q$e,umt),e(_7,pmt),e(_7,Yse),e(Yse,_mt),e(_7,vmt),e(fe,bmt),e(fe,v7),e(v7,j$e),e(j$e,Fmt),e(v7,Tmt),e(v7,Zse),e(Zse,Mmt),e(v7,Emt),e(fe,Cmt),e(fe,b7),e(b7,D$e),e(D$e,wmt),e(b7,Amt),e(b7,Kse),e(Kse,Lmt),e(b7,ymt),e(fe,xmt),e(fe,F7),e(F7,G$e),e(G$e,$mt),e(F7,kmt),e(F7,ele),e(ele,Smt),e(F7,Rmt),e(fe,Pmt),e(fe,T7),e(T7,O$e),e(O$e,Bmt),e(T7,Imt),e(T7,ole),e(ole,Nmt),e(T7,qmt),e(fe,jmt),e(fe,M7),e(M7,V$e),e(V$e,Dmt),e(M7,Gmt),e(M7,rle),e(rle,Omt),e(M7,Vmt),e(fe,Xmt),e(fe,E7),e(E7,X$e),e(X$e,zmt),e(E7,Qmt),e(E7,tle),e(tle,Wmt),e(E7,Umt),e(fe,Hmt),e(fe,C7),e(C7,z$e),e(z$e,Jmt),e(C7,Ymt),e(C7,ale),e(ale,Zmt),e(C7,Kmt),e(fe,egt),e(fe,w7),e(w7,Q$e),e(Q$e,ogt),e(w7,rgt),e(w7,nle),e(nle,tgt),e(w7,agt),e(fe,ngt),e(fe,A7),e(A7,W$e),e(W$e,sgt),e(A7,lgt),e(A7,sle),e(sle,igt),e(A7,dgt),e(fe,cgt),e(fe,L7),e(L7,U$e),e(U$e,fgt),e(L7,mgt),e(L7,lle),e(lle,ggt),e(L7,hgt),e(fe,ugt),e(fe,y7),e(y7,H$e),e(H$e,pgt),e(y7,_gt),e(y7,ile),e(ile,vgt),e(y7,bgt),e(fe,Fgt),e(fe,x7),e(x7,J$e),e(J$e,Tgt),e(x7,Mgt),e(x7,dle),e(dle,Egt),e(x7,Cgt),e(Kr,wgt),M($7,Kr,null),v(f,hno,_),v(f,em,_),e(em,k7),e(k7,Y$e),M(kP,Y$e,null),e(em,Agt),e(em,Z$e),e(Z$e,Lgt),v(f,uno,_),v(f,Cr,_),M(SP,Cr,null),e(Cr,ygt),e(Cr,om),e(om,xgt),e(om,cle),e(cle,$gt),e(om,kgt),e(om,fle),e(fle,Sgt),e(om,Rgt),e(Cr,Pgt),e(Cr,RP),e(RP,Bgt),e(RP,K$e),e(K$e,Igt),e(RP,Ngt),e(Cr,qgt),e(Cr,fa),M(PP,fa,null),e(fa,jgt),e(fa,eke),e(eke,Dgt),e(fa,Ggt),e(fa,rm),e(rm,Ogt),e(rm,oke),e(oke,Vgt),e(rm,Xgt),e(rm,mle),e(mle,zgt),e(rm,Qgt),e(fa,Wgt),M(S7,fa,null),e(Cr,Ugt),e(Cr,et),M(BP,et,null),e(et,Hgt),e(et,rke),e(rke,Jgt),e(et,Ygt),e(et,Hn),e(Hn,Zgt),e(Hn,tke),e(tke,Kgt),e(Hn,eht),e(Hn,ake),e(ake,oht),e(Hn,rht),e(Hn,nke),e(nke,tht),e(Hn,aht),e(et,nht),e(et,ske),e(ske,R7),e(R7,lke),e(lke,sht),e(R7,lht),e(R7,gle),e(gle,iht),e(R7,dht),e(et,cht),M(P7,et,null),v(f,pno,_),v(f,tm,_),e(tm,B7),e(B7,ike),M(IP,ike,null),e(tm,fht),e(tm,dke),e(dke,mht),v(f,_no,_),v(f,wr,_),M(NP,wr,null),e(wr,ght),e(wr,am),e(am,hht),e(am,hle),e(hle,uht),e(am,pht),e(am,ule),e(ule,_ht),e(am,vht),e(wr,bht),e(wr,qP),e(qP,Fht),e(qP,cke),e(cke,Tht),e(qP,Mht),e(wr,Eht),e(wr,ma),M(jP,ma,null),e(ma,Cht),e(ma,fke),e(fke,wht),e(ma,Aht),e(ma,nm),e(nm,Lht),e(nm,mke),e(mke,yht),e(nm,xht),e(nm,ple),e(ple,$ht),e(nm,kht),e(ma,Sht),M(I7,ma,null),e(wr,Rht),e(wr,ot),M(DP,ot,null),e(ot,Pht),e(ot,gke),e(gke,Bht),e(ot,Iht),e(ot,Jn),e(Jn,Nht),e(Jn,hke),e(hke,qht),e(Jn,jht),e(Jn,uke),e(uke,Dht),e(Jn,Ght),e(Jn,pke),e(pke,Oht),e(Jn,Vht),e(ot,Xht),e(ot,GP),e(GP,N7),e(N7,_ke),e(_ke,zht),e(N7,Qht),e(N7,_le),e(_le,Wht),e(N7,Uht),e(GP,Hht),e(GP,q7),e(q7,vke),e(vke,Jht),e(q7,Yht),e(q7,vle),e(vle,Zht),e(q7,Kht),e(ot,eut),M(j7,ot,null),v(f,vno,_),v(f,sm,_),e(sm,D7),e(D7,bke),M(OP,bke,null),e(sm,out),e(sm,Fke),e(Fke,rut),v(f,bno,_),v(f,Ar,_),M(VP,Ar,null),e(Ar,tut),e(Ar,lm),e(lm,aut),e(lm,ble),e(ble,nut),e(lm,sut),e(lm,Fle),e(Fle,lut),e(lm,iut),e(Ar,dut),e(Ar,XP),e(XP,cut),e(XP,Tke),e(Tke,fut),e(XP,mut),e(Ar,gut),e(Ar,ga),M(zP,ga,null),e(ga,hut),e(ga,Mke),e(Mke,uut),e(ga,put),e(ga,im),e(im,_ut),e(im,Eke),e(Eke,vut),e(im,but),e(im,Tle),e(Tle,Fut),e(im,Tut),e(ga,Mut),M(G7,ga,null),e(Ar,Eut),e(Ar,rt),M(QP,rt,null),e(rt,Cut),e(rt,Cke),e(Cke,wut),e(rt,Aut),e(rt,Yn),e(Yn,Lut),e(Yn,wke),e(wke,yut),e(Yn,xut),e(Yn,Ake),e(Ake,$ut),e(Yn,kut),e(Yn,Lke),e(Lke,Sut),e(Yn,Rut),e(rt,Put),e(rt,te),e(te,O7),e(O7,yke),e(yke,But),e(O7,Iut),e(O7,Mle),e(Mle,Nut),e(O7,qut),e(te,jut),e(te,V7),e(V7,xke),e(xke,Dut),e(V7,Gut),e(V7,Ele),e(Ele,Out),e(V7,Vut),e(te,Xut),e(te,X7),e(X7,$ke),e($ke,zut),e(X7,Qut),e(X7,Cle),e(Cle,Wut),e(X7,Uut),e(te,Hut),e(te,z7),e(z7,kke),e(kke,Jut),e(z7,Yut),e(z7,wle),e(wle,Zut),e(z7,Kut),e(te,ept),e(te,Q7),e(Q7,Ske),e(Ske,opt),e(Q7,rpt),e(Q7,Ale),e(Ale,tpt),e(Q7,apt),e(te,npt),e(te,W7),e(W7,Rke),e(Rke,spt),e(W7,lpt),e(W7,Lle),e(Lle,ipt),e(W7,dpt),e(te,cpt),e(te,U7),e(U7,Pke),e(Pke,fpt),e(U7,mpt),e(U7,yle),e(yle,gpt),e(U7,hpt),e(te,upt),e(te,H7),e(H7,Bke),e(Bke,ppt),e(H7,_pt),e(H7,xle),e(xle,vpt),e(H7,bpt),e(te,Fpt),e(te,J7),e(J7,Ike),e(Ike,Tpt),e(J7,Mpt),e(J7,$le),e($le,Ept),e(J7,Cpt),e(te,wpt),e(te,Y7),e(Y7,Nke),e(Nke,Apt),e(Y7,Lpt),e(Y7,kle),e(kle,ypt),e(Y7,xpt),e(te,$pt),e(te,Z7),e(Z7,qke),e(qke,kpt),e(Z7,Spt),e(Z7,Sle),e(Sle,Rpt),e(Z7,Ppt),e(te,Bpt),e(te,K7),e(K7,jke),e(jke,Ipt),e(K7,Npt),e(K7,Rle),e(Rle,qpt),e(K7,jpt),e(te,Dpt),e(te,e8),e(e8,Dke),e(Dke,Gpt),e(e8,Opt),e(e8,Ple),e(Ple,Vpt),e(e8,Xpt),e(te,zpt),e(te,o8),e(o8,Gke),e(Gke,Qpt),e(o8,Wpt),e(o8,Ble),e(Ble,Upt),e(o8,Hpt),e(te,Jpt),e(te,r8),e(r8,Oke),e(Oke,Ypt),e(r8,Zpt),e(r8,Ile),e(Ile,Kpt),e(r8,e_t),e(te,o_t),e(te,t8),e(t8,Vke),e(Vke,r_t),e(t8,t_t),e(t8,Nle),e(Nle,a_t),e(t8,n_t),e(te,s_t),e(te,a8),e(a8,Xke),e(Xke,l_t),e(a8,i_t),e(a8,qle),e(qle,d_t),e(a8,c_t),e(te,f_t),e(te,n8),e(n8,zke),e(zke,m_t),e(n8,g_t),e(n8,jle),e(jle,h_t),e(n8,u_t),e(te,p_t),e(te,s8),e(s8,Qke),e(Qke,__t),e(s8,v_t),e(s8,Dle),e(Dle,b_t),e(s8,F_t),e(te,T_t),e(te,l8),e(l8,Wke),e(Wke,M_t),e(l8,E_t),e(l8,Gle),e(Gle,C_t),e(l8,w_t),e(te,A_t),e(te,i8),e(i8,Uke),e(Uke,L_t),e(i8,y_t),e(i8,Ole),e(Ole,x_t),e(i8,$_t),e(te,k_t),e(te,d8),e(d8,Hke),e(Hke,S_t),e(d8,R_t),e(d8,Vle),e(Vle,P_t),e(d8,B_t),e(te,I_t),e(te,c8),e(c8,Jke),e(Jke,N_t),e(c8,q_t),e(c8,Xle),e(Xle,j_t),e(c8,D_t),e(te,G_t),e(te,f8),e(f8,Yke),e(Yke,O_t),e(f8,V_t),e(f8,zle),e(zle,X_t),e(f8,z_t),e(te,Q_t),e(te,m8),e(m8,Zke),e(Zke,W_t),e(m8,U_t),e(m8,Qle),e(Qle,H_t),e(m8,J_t),e(te,Y_t),e(te,g8),e(g8,Kke),e(Kke,Z_t),e(g8,K_t),e(g8,Wle),e(Wle,e4t),e(g8,o4t),e(te,r4t),e(te,h8),e(h8,eSe),e(eSe,t4t),e(h8,a4t),e(h8,Ule),e(Ule,n4t),e(h8,s4t),e(rt,l4t),M(u8,rt,null),v(f,Fno,_),v(f,dm,_),e(dm,p8),e(p8,oSe),M(WP,oSe,null),e(dm,i4t),e(dm,rSe),e(rSe,d4t),v(f,Tno,_),v(f,Lr,_),M(UP,Lr,null),e(Lr,c4t),e(Lr,cm),e(cm,f4t),e(cm,Hle),e(Hle,m4t),e(cm,g4t),e(cm,Jle),e(Jle,h4t),e(cm,u4t),e(Lr,p4t),e(Lr,HP),e(HP,_4t),e(HP,tSe),e(tSe,v4t),e(HP,b4t),e(Lr,F4t),e(Lr,ha),M(JP,ha,null),e(ha,T4t),e(ha,aSe),e(aSe,M4t),e(ha,E4t),e(ha,fm),e(fm,C4t),e(fm,nSe),e(nSe,w4t),e(fm,A4t),e(fm,Yle),e(Yle,L4t),e(fm,y4t),e(ha,x4t),M(_8,ha,null),e(Lr,$4t),e(Lr,tt),M(YP,tt,null),e(tt,k4t),e(tt,sSe),e(sSe,S4t),e(tt,R4t),e(tt,Zn),e(Zn,P4t),e(Zn,lSe),e(lSe,B4t),e(Zn,I4t),e(Zn,iSe),e(iSe,N4t),e(Zn,q4t),e(Zn,dSe),e(dSe,j4t),e(Zn,D4t),e(tt,G4t),e(tt,$e),e($e,v8),e(v8,cSe),e(cSe,O4t),e(v8,V4t),e(v8,Zle),e(Zle,X4t),e(v8,z4t),e($e,Q4t),e($e,b8),e(b8,fSe),e(fSe,W4t),e(b8,U4t),e(b8,Kle),e(Kle,H4t),e(b8,J4t),e($e,Y4t),e($e,F8),e(F8,mSe),e(mSe,Z4t),e(F8,K4t),e(F8,eie),e(eie,e2t),e(F8,o2t),e($e,r2t),e($e,T8),e(T8,gSe),e(gSe,t2t),e(T8,a2t),e(T8,oie),e(oie,n2t),e(T8,s2t),e($e,l2t),e($e,M8),e(M8,hSe),e(hSe,i2t),e(M8,d2t),e(M8,rie),e(rie,c2t),e(M8,f2t),e($e,m2t),e($e,E8),e(E8,uSe),e(uSe,g2t),e(E8,h2t),e(E8,tie),e(tie,u2t),e(E8,p2t),e($e,_2t),e($e,C8),e(C8,pSe),e(pSe,v2t),e(C8,b2t),e(C8,aie),e(aie,F2t),e(C8,T2t),e($e,M2t),e($e,w8),e(w8,_Se),e(_Se,E2t),e(w8,C2t),e(w8,nie),e(nie,w2t),e(w8,A2t),e($e,L2t),e($e,A8),e(A8,vSe),e(vSe,y2t),e(A8,x2t),e(A8,sie),e(sie,$2t),e(A8,k2t),e($e,S2t),e($e,L8),e(L8,bSe),e(bSe,R2t),e(L8,P2t),e(L8,lie),e(lie,B2t),e(L8,I2t),e(tt,N2t),M(y8,tt,null),v(f,Mno,_),v(f,mm,_),e(mm,x8),e(x8,FSe),M(ZP,FSe,null),e(mm,q2t),e(mm,TSe),e(TSe,j2t),v(f,Eno,_),v(f,yr,_),M(KP,yr,null),e(yr,D2t),e(yr,gm),e(gm,G2t),e(gm,iie),e(iie,O2t),e(gm,V2t),e(gm,die),e(die,X2t),e(gm,z2t),e(yr,Q2t),e(yr,eB),e(eB,W2t),e(eB,MSe),e(MSe,U2t),e(eB,H2t),e(yr,J2t),e(yr,ua),M(oB,ua,null),e(ua,Y2t),e(ua,ESe),e(ESe,Z2t),e(ua,K2t),e(ua,hm),e(hm,evt),e(hm,CSe),e(CSe,ovt),e(hm,rvt),e(hm,cie),e(cie,tvt),e(hm,avt),e(ua,nvt),M($8,ua,null),e(yr,svt),e(yr,at),M(rB,at,null),e(at,lvt),e(at,wSe),e(wSe,ivt),e(at,dvt),e(at,Kn),e(Kn,cvt),e(Kn,ASe),e(ASe,fvt),e(Kn,mvt),e(Kn,LSe),e(LSe,gvt),e(Kn,hvt),e(Kn,ySe),e(ySe,uvt),e(Kn,pvt),e(at,_vt),e(at,Ee),e(Ee,k8),e(k8,xSe),e(xSe,vvt),e(k8,bvt),e(k8,fie),e(fie,Fvt),e(k8,Tvt),e(Ee,Mvt),e(Ee,S8),e(S8,$Se),e($Se,Evt),e(S8,Cvt),e(S8,mie),e(mie,wvt),e(S8,Avt),e(Ee,Lvt),e(Ee,R8),e(R8,kSe),e(kSe,yvt),e(R8,xvt),e(R8,gie),e(gie,$vt),e(R8,kvt),e(Ee,Svt),e(Ee,P8),e(P8,SSe),e(SSe,Rvt),e(P8,Pvt),e(P8,hie),e(hie,Bvt),e(P8,Ivt),e(Ee,Nvt),e(Ee,B8),e(B8,RSe),e(RSe,qvt),e(B8,jvt),e(B8,uie),e(uie,Dvt),e(B8,Gvt),e(Ee,Ovt),e(Ee,I8),e(I8,PSe),e(PSe,Vvt),e(I8,Xvt),e(I8,pie),e(pie,zvt),e(I8,Qvt),e(Ee,Wvt),e(Ee,N8),e(N8,BSe),e(BSe,Uvt),e(N8,Hvt),e(N8,_ie),e(_ie,Jvt),e(N8,Yvt),e(Ee,Zvt),e(Ee,q8),e(q8,ISe),e(ISe,Kvt),e(q8,e1t),e(q8,vie),e(vie,o1t),e(q8,r1t),e(Ee,t1t),e(Ee,j8),e(j8,NSe),e(NSe,a1t),e(j8,n1t),e(j8,bie),e(bie,s1t),e(j8,l1t),e(Ee,i1t),e(Ee,D8),e(D8,qSe),e(qSe,d1t),e(D8,c1t),e(D8,Fie),e(Fie,f1t),e(D8,m1t),e(Ee,g1t),e(Ee,G8),e(G8,jSe),e(jSe,h1t),e(G8,u1t),e(G8,Tie),e(Tie,p1t),e(G8,_1t),e(Ee,v1t),e(Ee,O8),e(O8,DSe),e(DSe,b1t),e(O8,F1t),e(O8,Mie),e(Mie,T1t),e(O8,M1t),e(Ee,E1t),e(Ee,V8),e(V8,GSe),e(GSe,C1t),e(V8,w1t),e(V8,Eie),e(Eie,A1t),e(V8,L1t),e(at,y1t),M(X8,at,null),v(f,Cno,_),v(f,um,_),e(um,z8),e(z8,OSe),M(tB,OSe,null),e(um,x1t),e(um,VSe),e(VSe,$1t),v(f,wno,_),v(f,xr,_),M(aB,xr,null),e(xr,k1t),e(xr,pm),e(pm,S1t),e(pm,Cie),e(Cie,R1t),e(pm,P1t),e(pm,wie),e(wie,B1t),e(pm,I1t),e(xr,N1t),e(xr,nB),e(nB,q1t),e(nB,XSe),e(XSe,j1t),e(nB,D1t),e(xr,G1t),e(xr,pa),M(sB,pa,null),e(pa,O1t),e(pa,zSe),e(zSe,V1t),e(pa,X1t),e(pa,_m),e(_m,z1t),e(_m,QSe),e(QSe,Q1t),e(_m,W1t),e(_m,Aie),e(Aie,U1t),e(_m,H1t),e(pa,J1t),M(Q8,pa,null),e(xr,Y1t),e(xr,nt),M(lB,nt,null),e(nt,Z1t),e(nt,WSe),e(WSe,K1t),e(nt,ebt),e(nt,es),e(es,obt),e(es,USe),e(USe,rbt),e(es,tbt),e(es,HSe),e(HSe,abt),e(es,nbt),e(es,JSe),e(JSe,sbt),e(es,lbt),e(nt,ibt),e(nt,ke),e(ke,W8),e(W8,YSe),e(YSe,dbt),e(W8,cbt),e(W8,Lie),e(Lie,fbt),e(W8,mbt),e(ke,gbt),e(ke,U8),e(U8,ZSe),e(ZSe,hbt),e(U8,ubt),e(U8,yie),e(yie,pbt),e(U8,_bt),e(ke,vbt),e(ke,H8),e(H8,KSe),e(KSe,bbt),e(H8,Fbt),e(H8,xie),e(xie,Tbt),e(H8,Mbt),e(ke,Ebt),e(ke,J8),e(J8,eRe),e(eRe,Cbt),e(J8,wbt),e(J8,$ie),e($ie,Abt),e(J8,Lbt),e(ke,ybt),e(ke,Y8),e(Y8,oRe),e(oRe,xbt),e(Y8,$bt),e(Y8,kie),e(kie,kbt),e(Y8,Sbt),e(ke,Rbt),e(ke,Z8),e(Z8,rRe),e(rRe,Pbt),e(Z8,Bbt),e(Z8,Sie),e(Sie,Ibt),e(Z8,Nbt),e(ke,qbt),e(ke,K8),e(K8,tRe),e(tRe,jbt),e(K8,Dbt),e(K8,Rie),e(Rie,Gbt),e(K8,Obt),e(ke,Vbt),e(ke,eL),e(eL,aRe),e(aRe,Xbt),e(eL,zbt),e(eL,Pie),e(Pie,Qbt),e(eL,Wbt),e(ke,Ubt),e(ke,oL),e(oL,nRe),e(nRe,Hbt),e(oL,Jbt),e(oL,Bie),e(Bie,Ybt),e(oL,Zbt),e(ke,Kbt),e(ke,rL),e(rL,sRe),e(sRe,e0t),e(rL,o0t),e(rL,Iie),e(Iie,r0t),e(rL,t0t),e(nt,a0t),M(tL,nt,null),v(f,Ano,_),v(f,vm,_),e(vm,aL),e(aL,lRe),M(iB,lRe,null),e(vm,n0t),e(vm,iRe),e(iRe,s0t),v(f,Lno,_),v(f,$r,_),M(dB,$r,null),e($r,l0t),e($r,bm),e(bm,i0t),e(bm,Nie),e(Nie,d0t),e(bm,c0t),e(bm,qie),e(qie,f0t),e(bm,m0t),e($r,g0t),e($r,cB),e(cB,h0t),e(cB,dRe),e(dRe,u0t),e(cB,p0t),e($r,_0t),e($r,_a),M(fB,_a,null),e(_a,v0t),e(_a,cRe),e(cRe,b0t),e(_a,F0t),e(_a,Fm),e(Fm,T0t),e(Fm,fRe),e(fRe,M0t),e(Fm,E0t),e(Fm,jie),e(jie,C0t),e(Fm,w0t),e(_a,A0t),M(nL,_a,null),e($r,L0t),e($r,st),M(mB,st,null),e(st,y0t),e(st,mRe),e(mRe,x0t),e(st,$0t),e(st,os),e(os,k0t),e(os,gRe),e(gRe,S0t),e(os,R0t),e(os,hRe),e(hRe,P0t),e(os,B0t),e(os,uRe),e(uRe,I0t),e(os,N0t),e(st,q0t),e(st,Se),e(Se,sL),e(sL,pRe),e(pRe,j0t),e(sL,D0t),e(sL,Die),e(Die,G0t),e(sL,O0t),e(Se,V0t),e(Se,lL),e(lL,_Re),e(_Re,X0t),e(lL,z0t),e(lL,Gie),e(Gie,Q0t),e(lL,W0t),e(Se,U0t),e(Se,iL),e(iL,vRe),e(vRe,H0t),e(iL,J0t),e(iL,Oie),e(Oie,Y0t),e(iL,Z0t),e(Se,K0t),e(Se,dL),e(dL,bRe),e(bRe,eFt),e(dL,oFt),e(dL,Vie),e(Vie,rFt),e(dL,tFt),e(Se,aFt),e(Se,cL),e(cL,FRe),e(FRe,nFt),e(cL,sFt),e(cL,Xie),e(Xie,lFt),e(cL,iFt),e(Se,dFt),e(Se,fL),e(fL,TRe),e(TRe,cFt),e(fL,fFt),e(fL,zie),e(zie,mFt),e(fL,gFt),e(Se,hFt),e(Se,mL),e(mL,MRe),e(MRe,uFt),e(mL,pFt),e(mL,Qie),e(Qie,_Ft),e(mL,vFt),e(Se,bFt),e(Se,gL),e(gL,ERe),e(ERe,FFt),e(gL,TFt),e(gL,Wie),e(Wie,MFt),e(gL,EFt),e(Se,CFt),e(Se,hL),e(hL,CRe),e(CRe,wFt),e(hL,AFt),e(hL,Uie),e(Uie,LFt),e(hL,yFt),e(Se,xFt),e(Se,uL),e(uL,wRe),e(wRe,$Ft),e(uL,kFt),e(uL,Hie),e(Hie,SFt),e(uL,RFt),e(st,PFt),M(pL,st,null),v(f,yno,_),v(f,Tm,_),e(Tm,_L),e(_L,ARe),M(gB,ARe,null),e(Tm,BFt),e(Tm,LRe),e(LRe,IFt),v(f,xno,_),v(f,kr,_),M(hB,kr,null),e(kr,NFt),e(kr,Mm),e(Mm,qFt),e(Mm,Jie),e(Jie,jFt),e(Mm,DFt),e(Mm,Yie),e(Yie,GFt),e(Mm,OFt),e(kr,VFt),e(kr,uB),e(uB,XFt),e(uB,yRe),e(yRe,zFt),e(uB,QFt),e(kr,WFt),e(kr,va),M(pB,va,null),e(va,UFt),e(va,xRe),e(xRe,HFt),e(va,JFt),e(va,Em),e(Em,YFt),e(Em,$Re),e($Re,ZFt),e(Em,KFt),e(Em,Zie),e(Zie,eTt),e(Em,oTt),e(va,rTt),M(vL,va,null),e(kr,tTt),e(kr,lt),M(_B,lt,null),e(lt,aTt),e(lt,kRe),e(kRe,nTt),e(lt,sTt),e(lt,rs),e(rs,lTt),e(rs,SRe),e(SRe,iTt),e(rs,dTt),e(rs,RRe),e(RRe,cTt),e(rs,fTt),e(rs,PRe),e(PRe,mTt),e(rs,gTt),e(lt,hTt),e(lt,Re),e(Re,bL),e(bL,BRe),e(BRe,uTt),e(bL,pTt),e(bL,Kie),e(Kie,_Tt),e(bL,vTt),e(Re,bTt),e(Re,FL),e(FL,IRe),e(IRe,FTt),e(FL,TTt),e(FL,ede),e(ede,MTt),e(FL,ETt),e(Re,CTt),e(Re,TL),e(TL,NRe),e(NRe,wTt),e(TL,ATt),e(TL,ode),e(ode,LTt),e(TL,yTt),e(Re,xTt),e(Re,ML),e(ML,qRe),e(qRe,$Tt),e(ML,kTt),e(ML,rde),e(rde,STt),e(ML,RTt),e(Re,PTt),e(Re,EL),e(EL,jRe),e(jRe,BTt),e(EL,ITt),e(EL,tde),e(tde,NTt),e(EL,qTt),e(Re,jTt),e(Re,CL),e(CL,DRe),e(DRe,DTt),e(CL,GTt),e(CL,ade),e(ade,OTt),e(CL,VTt),e(Re,XTt),e(Re,wL),e(wL,GRe),e(GRe,zTt),e(wL,QTt),e(wL,nde),e(nde,WTt),e(wL,UTt),e(Re,HTt),e(Re,AL),e(AL,ORe),e(ORe,JTt),e(AL,YTt),e(AL,sde),e(sde,ZTt),e(AL,KTt),e(Re,eMt),e(Re,LL),e(LL,VRe),e(VRe,oMt),e(LL,rMt),e(LL,lde),e(lde,tMt),e(LL,aMt),e(Re,nMt),e(Re,yL),e(yL,XRe),e(XRe,sMt),e(yL,lMt),e(yL,ide),e(ide,iMt),e(yL,dMt),e(lt,cMt),M(xL,lt,null),v(f,$no,_),v(f,Cm,_),e(Cm,$L),e($L,zRe),M(vB,zRe,null),e(Cm,fMt),e(Cm,QRe),e(QRe,mMt),v(f,kno,_),v(f,Sr,_),M(bB,Sr,null),e(Sr,gMt),e(Sr,wm),e(wm,hMt),e(wm,dde),e(dde,uMt),e(wm,pMt),e(wm,cde),e(cde,_Mt),e(wm,vMt),e(Sr,bMt),e(Sr,FB),e(FB,FMt),e(FB,WRe),e(WRe,TMt),e(FB,MMt),e(Sr,EMt),e(Sr,ba),M(TB,ba,null),e(ba,CMt),e(ba,URe),e(URe,wMt),e(ba,AMt),e(ba,Am),e(Am,LMt),e(Am,HRe),e(HRe,yMt),e(Am,xMt),e(Am,fde),e(fde,$Mt),e(Am,kMt),e(ba,SMt),M(kL,ba,null),e(Sr,RMt),e(Sr,it),M(MB,it,null),e(it,PMt),e(it,JRe),e(JRe,BMt),e(it,IMt),e(it,ts),e(ts,NMt),e(ts,YRe),e(YRe,qMt),e(ts,jMt),e(ts,ZRe),e(ZRe,DMt),e(ts,GMt),e(ts,KRe),e(KRe,OMt),e(ts,VMt),e(it,XMt),e(it,Pe),e(Pe,SL),e(SL,ePe),e(ePe,zMt),e(SL,QMt),e(SL,mde),e(mde,WMt),e(SL,UMt),e(Pe,HMt),e(Pe,RL),e(RL,oPe),e(oPe,JMt),e(RL,YMt),e(RL,gde),e(gde,ZMt),e(RL,KMt),e(Pe,eEt),e(Pe,PL),e(PL,rPe),e(rPe,oEt),e(PL,rEt),e(PL,hde),e(hde,tEt),e(PL,aEt),e(Pe,nEt),e(Pe,BL),e(BL,tPe),e(tPe,sEt),e(BL,lEt),e(BL,ude),e(ude,iEt),e(BL,dEt),e(Pe,cEt),e(Pe,IL),e(IL,aPe),e(aPe,fEt),e(IL,mEt),e(IL,pde),e(pde,gEt),e(IL,hEt),e(Pe,uEt),e(Pe,NL),e(NL,nPe),e(nPe,pEt),e(NL,_Et),e(NL,_de),e(_de,vEt),e(NL,bEt),e(Pe,FEt),e(Pe,qL),e(qL,sPe),e(sPe,TEt),e(qL,MEt),e(qL,vde),e(vde,EEt),e(qL,CEt),e(Pe,wEt),e(Pe,jL),e(jL,lPe),e(lPe,AEt),e(jL,LEt),e(jL,bde),e(bde,yEt),e(jL,xEt),e(Pe,$Et),e(Pe,DL),e(DL,iPe),e(iPe,kEt),e(DL,SEt),e(DL,Fde),e(Fde,REt),e(DL,PEt),e(Pe,BEt),e(Pe,GL),e(GL,dPe),e(dPe,IEt),e(GL,NEt),e(GL,Tde),e(Tde,qEt),e(GL,jEt),e(it,DEt),M(OL,it,null),v(f,Sno,_),v(f,Lm,_),e(Lm,VL),e(VL,cPe),M(EB,cPe,null),e(Lm,GEt),e(Lm,fPe),e(fPe,OEt),v(f,Rno,_),v(f,Rr,_),M(CB,Rr,null),e(Rr,VEt),e(Rr,ym),e(ym,XEt),e(ym,Mde),e(Mde,zEt),e(ym,QEt),e(ym,Ede),e(Ede,WEt),e(ym,UEt),e(Rr,HEt),e(Rr,wB),e(wB,JEt),e(wB,mPe),e(mPe,YEt),e(wB,ZEt),e(Rr,KEt),e(Rr,Fa),M(AB,Fa,null),e(Fa,eCt),e(Fa,gPe),e(gPe,oCt),e(Fa,rCt),e(Fa,xm),e(xm,tCt),e(xm,hPe),e(hPe,aCt),e(xm,nCt),e(xm,Cde),e(Cde,sCt),e(xm,lCt),e(Fa,iCt),M(XL,Fa,null),e(Rr,dCt),e(Rr,dt),M(LB,dt,null),e(dt,cCt),e(dt,uPe),e(uPe,fCt),e(dt,mCt),e(dt,as),e(as,gCt),e(as,pPe),e(pPe,hCt),e(as,uCt),e(as,_Pe),e(_Pe,pCt),e(as,_Ct),e(as,vPe),e(vPe,vCt),e(as,bCt),e(dt,FCt),e(dt,ze),e(ze,zL),e(zL,bPe),e(bPe,TCt),e(zL,MCt),e(zL,wde),e(wde,ECt),e(zL,CCt),e(ze,wCt),e(ze,QL),e(QL,FPe),e(FPe,ACt),e(QL,LCt),e(QL,Ade),e(Ade,yCt),e(QL,xCt),e(ze,$Ct),e(ze,WL),e(WL,TPe),e(TPe,kCt),e(WL,SCt),e(WL,Lde),e(Lde,RCt),e(WL,PCt),e(ze,BCt),e(ze,UL),e(UL,MPe),e(MPe,ICt),e(UL,NCt),e(UL,yde),e(yde,qCt),e(UL,jCt),e(ze,DCt),e(ze,HL),e(HL,EPe),e(EPe,GCt),e(HL,OCt),e(HL,xde),e(xde,VCt),e(HL,XCt),e(ze,zCt),e(ze,JL),e(JL,CPe),e(CPe,QCt),e(JL,WCt),e(JL,$de),e($de,UCt),e(JL,HCt),e(ze,JCt),e(ze,YL),e(YL,wPe),e(wPe,YCt),e(YL,ZCt),e(YL,kde),e(kde,KCt),e(YL,e3t),e(ze,o3t),e(ze,ZL),e(ZL,APe),e(APe,r3t),e(ZL,t3t),e(ZL,Sde),e(Sde,a3t),e(ZL,n3t),e(dt,s3t),M(KL,dt,null),v(f,Pno,_),v(f,$m,_),e($m,ey),e(ey,LPe),M(yB,LPe,null),e($m,l3t),e($m,yPe),e(yPe,i3t),v(f,Bno,_),v(f,Pr,_),M(xB,Pr,null),e(Pr,d3t),e(Pr,km),e(km,c3t),e(km,Rde),e(Rde,f3t),e(km,m3t),e(km,Pde),e(Pde,g3t),e(km,h3t),e(Pr,u3t),e(Pr,$B),e($B,p3t),e($B,xPe),e(xPe,_3t),e($B,v3t),e(Pr,b3t),e(Pr,Ta),M(kB,Ta,null),e(Ta,F3t),e(Ta,$Pe),e($Pe,T3t),e(Ta,M3t),e(Ta,Sm),e(Sm,E3t),e(Sm,kPe),e(kPe,C3t),e(Sm,w3t),e(Sm,Bde),e(Bde,A3t),e(Sm,L3t),e(Ta,y3t),M(oy,Ta,null),e(Pr,x3t),e(Pr,ct),M(SB,ct,null),e(ct,$3t),e(ct,SPe),e(SPe,k3t),e(ct,S3t),e(ct,ns),e(ns,R3t),e(ns,RPe),e(RPe,P3t),e(ns,B3t),e(ns,PPe),e(PPe,I3t),e(ns,N3t),e(ns,BPe),e(BPe,q3t),e(ns,j3t),e(ct,D3t),e(ct,Qe),e(Qe,ry),e(ry,IPe),e(IPe,G3t),e(ry,O3t),e(ry,Ide),e(Ide,V3t),e(ry,X3t),e(Qe,z3t),e(Qe,ty),e(ty,NPe),e(NPe,Q3t),e(ty,W3t),e(ty,Nde),e(Nde,U3t),e(ty,H3t),e(Qe,J3t),e(Qe,ay),e(ay,qPe),e(qPe,Y3t),e(ay,Z3t),e(ay,qde),e(qde,K3t),e(ay,e5t),e(Qe,o5t),e(Qe,ny),e(ny,jPe),e(jPe,r5t),e(ny,t5t),e(ny,jde),e(jde,a5t),e(ny,n5t),e(Qe,s5t),e(Qe,sy),e(sy,DPe),e(DPe,l5t),e(sy,i5t),e(sy,Dde),e(Dde,d5t),e(sy,c5t),e(Qe,f5t),e(Qe,ly),e(ly,GPe),e(GPe,m5t),e(ly,g5t),e(ly,Gde),e(Gde,h5t),e(ly,u5t),e(Qe,p5t),e(Qe,iy),e(iy,OPe),e(OPe,_5t),e(iy,v5t),e(iy,Ode),e(Ode,b5t),e(iy,F5t),e(Qe,T5t),e(Qe,dy),e(dy,VPe),e(VPe,M5t),e(dy,E5t),e(dy,Vde),e(Vde,C5t),e(dy,w5t),e(ct,A5t),M(cy,ct,null),v(f,Ino,_),v(f,Rm,_),e(Rm,fy),e(fy,XPe),M(RB,XPe,null),e(Rm,L5t),e(Rm,zPe),e(zPe,y5t),v(f,Nno,_),v(f,Br,_),M(PB,Br,null),e(Br,x5t),e(Br,Pm),e(Pm,$5t),e(Pm,Xde),e(Xde,k5t),e(Pm,S5t),e(Pm,zde),e(zde,R5t),e(Pm,P5t),e(Br,B5t),e(Br,BB),e(BB,I5t),e(BB,QPe),e(QPe,N5t),e(BB,q5t),e(Br,j5t),e(Br,Ma),M(IB,Ma,null),e(Ma,D5t),e(Ma,WPe),e(WPe,G5t),e(Ma,O5t),e(Ma,Bm),e(Bm,V5t),e(Bm,UPe),e(UPe,X5t),e(Bm,z5t),e(Bm,Qde),e(Qde,Q5t),e(Bm,W5t),e(Ma,U5t),M(my,Ma,null),e(Br,H5t),e(Br,ft),M(NB,ft,null),e(ft,J5t),e(ft,HPe),e(HPe,Y5t),e(ft,Z5t),e(ft,ss),e(ss,K5t),e(ss,JPe),e(JPe,ewt),e(ss,owt),e(ss,YPe),e(YPe,rwt),e(ss,twt),e(ss,ZPe),e(ZPe,awt),e(ss,nwt),e(ft,swt),e(ft,KPe),e(KPe,gy),e(gy,eBe),e(eBe,lwt),e(gy,iwt),e(gy,Wde),e(Wde,dwt),e(gy,cwt),e(ft,fwt),M(hy,ft,null),v(f,qno,_),v(f,Im,_),e(Im,uy),e(uy,oBe),M(qB,oBe,null),e(Im,mwt),e(Im,rBe),e(rBe,gwt),v(f,jno,_),v(f,Ir,_),M(jB,Ir,null),e(Ir,hwt),e(Ir,Nm),e(Nm,uwt),e(Nm,Ude),e(Ude,pwt),e(Nm,_wt),e(Nm,Hde),e(Hde,vwt),e(Nm,bwt),e(Ir,Fwt),e(Ir,DB),e(DB,Twt),e(DB,tBe),e(tBe,Mwt),e(DB,Ewt),e(Ir,Cwt),e(Ir,Ea),M(GB,Ea,null),e(Ea,wwt),e(Ea,aBe),e(aBe,Awt),e(Ea,Lwt),e(Ea,qm),e(qm,ywt),e(qm,nBe),e(nBe,xwt),e(qm,$wt),e(qm,Jde),e(Jde,kwt),e(qm,Swt),e(Ea,Rwt),M(py,Ea,null),e(Ir,Pwt),e(Ir,mt),M(OB,mt,null),e(mt,Bwt),e(mt,sBe),e(sBe,Iwt),e(mt,Nwt),e(mt,ls),e(ls,qwt),e(ls,lBe),e(lBe,jwt),e(ls,Dwt),e(ls,iBe),e(iBe,Gwt),e(ls,Owt),e(ls,dBe),e(dBe,Vwt),e(ls,Xwt),e(mt,zwt),e(mt,VB),e(VB,_y),e(_y,cBe),e(cBe,Qwt),e(_y,Wwt),e(_y,Yde),e(Yde,Uwt),e(_y,Hwt),e(VB,Jwt),e(VB,vy),e(vy,fBe),e(fBe,Ywt),e(vy,Zwt),e(vy,Zde),e(Zde,Kwt),e(vy,eAt),e(mt,oAt),M(by,mt,null),v(f,Dno,_),v(f,jm,_),e(jm,Fy),e(Fy,mBe),M(XB,mBe,null),e(jm,rAt),e(jm,gBe),e(gBe,tAt),v(f,Gno,_),v(f,Nr,_),M(zB,Nr,null),e(Nr,aAt),e(Nr,Dm),e(Dm,nAt),e(Dm,Kde),e(Kde,sAt),e(Dm,lAt),e(Dm,ece),e(ece,iAt),e(Dm,dAt),e(Nr,cAt),e(Nr,QB),e(QB,fAt),e(QB,hBe),e(hBe,mAt),e(QB,gAt),e(Nr,hAt),e(Nr,Ca),M(WB,Ca,null),e(Ca,uAt),e(Ca,uBe),e(uBe,pAt),e(Ca,_At),e(Ca,Gm),e(Gm,vAt),e(Gm,pBe),e(pBe,bAt),e(Gm,FAt),e(Gm,oce),e(oce,TAt),e(Gm,MAt),e(Ca,EAt),M(Ty,Ca,null),e(Nr,CAt),e(Nr,gt),M(UB,gt,null),e(gt,wAt),e(gt,_Be),e(_Be,AAt),e(gt,LAt),e(gt,is),e(is,yAt),e(is,vBe),e(vBe,xAt),e(is,$At),e(is,bBe),e(bBe,kAt),e(is,SAt),e(is,FBe),e(FBe,RAt),e(is,PAt),e(gt,BAt),e(gt,TBe),e(TBe,My),e(My,MBe),e(MBe,IAt),e(My,NAt),e(My,rce),e(rce,qAt),e(My,jAt),e(gt,DAt),M(Ey,gt,null),Ono=!0},p(f,[_]){const HB={};_&2&&(HB.$$scope={dirty:_,ctx:f}),Jm.$set(HB);const EBe={};_&2&&(EBe.$$scope={dirty:_,ctx:f}),wu.$set(EBe);const CBe={};_&2&&(CBe.$$scope={dirty:_,ctx:f}),cp.$set(CBe);const wBe={};_&2&&(wBe.$$scope={dirty:_,ctx:f}),t_.$set(wBe);const JB={};_&2&&(JB.$$scope={dirty:_,ctx:f}),a_.$set(JB);const ABe={};_&2&&(ABe.$$scope={dirty:_,ctx:f}),x_.$set(ABe);const ds={};_&2&&(ds.$$scope={dirty:_,ctx:f}),$_.$set(ds);const LBe={};_&2&&(LBe.$$scope={dirty:_,ctx:f}),R_.$set(LBe);const yBe={};_&2&&(yBe.$$scope={dirty:_,ctx:f}),ov.$set(yBe);const xBe={};_&2&&(xBe.$$scope={dirty:_,ctx:f}),tv.$set(xBe);const YB={};_&2&&(YB.$$scope={dirty:_,ctx:f}),Kv.$set(YB);const $Be={};_&2&&($Be.$$scope={dirty:_,ctx:f}),o1.$set($Be);const ZB={};_&2&&(ZB.$$scope={dirty:_,ctx:f}),z1.$set(ZB);const kBe={};_&2&&(kBe.$$scope={dirty:_,ctx:f}),W1.$set(kBe);const KB={};_&2&&(KB.$$scope={dirty:_,ctx:f}),Y1.$set(KB);const SBe={};_&2&&(SBe.$$scope={dirty:_,ctx:f}),K1.$set(SBe);const RBe={};_&2&&(RBe.$$scope={dirty:_,ctx:f}),Db.$set(RBe);const PBe={};_&2&&(PBe.$$scope={dirty:_,ctx:f}),Ob.$set(PBe);const Om={};_&2&&(Om.$$scope={dirty:_,ctx:f}),c0.$set(Om);const BBe={};_&2&&(BBe.$$scope={dirty:_,ctx:f}),m0.$set(BBe);const IBe={};_&2&&(IBe.$$scope={dirty:_,ctx:f}),pF.$set(IBe);const NBe={};_&2&&(NBe.$$scope={dirty:_,ctx:f}),vF.$set(NBe);const eI={};_&2&&(eI.$$scope={dirty:_,ctx:f}),ZF.$set(eI);const qBe={};_&2&&(qBe.$$scope={dirty:_,ctx:f}),eT.$set(qBe);const jBe={};_&2&&(jBe.$$scope={dirty:_,ctx:f}),dT.$set(jBe);const DBe={};_&2&&(DBe.$$scope={dirty:_,ctx:f}),fT.$set(DBe);const bt={};_&2&&(bt.$$scope={dirty:_,ctx:f}),eM.$set(bt);const oI={};_&2&&(oI.$$scope={dirty:_,ctx:f}),rM.$set(oI);const GBe={};_&2&&(GBe.$$scope={dirty:_,ctx:f}),ZM.$set(GBe);const rI={};_&2&&(rI.$$scope={dirty:_,ctx:f}),eE.$set(rI);const OBe={};_&2&&(OBe.$$scope={dirty:_,ctx:f}),tE.$set(OBe);const Ft={};_&2&&(Ft.$$scope={dirty:_,ctx:f}),nE.$set(Ft);const VBe={};_&2&&(VBe.$$scope={dirty:_,ctx:f}),cE.$set(VBe);const Vm={};_&2&&(Vm.$$scope={dirty:_,ctx:f}),mE.$set(Vm);const XBe={};_&2&&(XBe.$$scope={dirty:_,ctx:f}),xE.$set(XBe);const zBe={};_&2&&(zBe.$$scope={dirty:_,ctx:f}),kE.$set(zBe);const L={};_&2&&(L.$$scope={dirty:_,ctx:f}),PE.$set(L);const Cy={};_&2&&(Cy.$$scope={dirty:_,ctx:f}),IE.$set(Cy);const QBe={};_&2&&(QBe.$$scope={dirty:_,ctx:f}),jE.$set(QBe);const WBe={};_&2&&(WBe.$$scope={dirty:_,ctx:f}),GE.$set(WBe);const wy={};_&2&&(wy.$$scope={dirty:_,ctx:f}),XE.$set(wy);const UBe={};_&2&&(UBe.$$scope={dirty:_,ctx:f}),QE.$set(UBe);const HBe={};_&2&&(HBe.$$scope={dirty:_,ctx:f}),tC.$set(HBe);const Ay={};_&2&&(Ay.$$scope={dirty:_,ctx:f}),nC.$set(Ay);const JBe={};_&2&&(JBe.$$scope={dirty:_,ctx:f}),mC.$set(JBe);const YBe={};_&2&&(YBe.$$scope={dirty:_,ctx:f}),hC.$set(YBe);const Ly={};_&2&&(Ly.$$scope={dirty:_,ctx:f}),AC.$set(Ly);const ZBe={};_&2&&(ZBe.$$scope={dirty:_,ctx:f}),yC.$set(ZBe);const KBe={};_&2&&(KBe.$$scope={dirty:_,ctx:f}),RC.$set(KBe);const yy={};_&2&&(yy.$$scope={dirty:_,ctx:f}),BC.$set(yy);const eIe={};_&2&&(eIe.$$scope={dirty:_,ctx:f}),OC.$set(eIe);const oIe={};_&2&&(oIe.$$scope={dirty:_,ctx:f}),XC.$set(oIe);const xy={};_&2&&(xy.$$scope={dirty:_,ctx:f}),JC.$set(xy);const rIe={};_&2&&(rIe.$$scope={dirty:_,ctx:f}),ZC.$set(rIe);const tIe={};_&2&&(tIe.$$scope={dirty:_,ctx:f}),n3.$set(tIe);const $y={};_&2&&($y.$$scope={dirty:_,ctx:f}),l3.$set($y);const aIe={};_&2&&(aIe.$$scope={dirty:_,ctx:f}),c3.$set(aIe);const nIe={};_&2&&(nIe.$$scope={dirty:_,ctx:f}),m3.$set(nIe);const ky={};_&2&&(ky.$$scope={dirty:_,ctx:f}),b3.$set(ky);const sIe={};_&2&&(sIe.$$scope={dirty:_,ctx:f}),T3.$set(sIe);const lIe={};_&2&&(lIe.$$scope={dirty:_,ctx:f}),C3.$set(lIe);const Sy={};_&2&&(Sy.$$scope={dirty:_,ctx:f}),A3.$set(Sy);const iIe={};_&2&&(iIe.$$scope={dirty:_,ctx:f}),x3.$set(iIe);const dIe={};_&2&&(dIe.$$scope={dirty:_,ctx:f}),k3.$set(dIe);const Ry={};_&2&&(Ry.$$scope={dirty:_,ctx:f}),B5.$set(Ry);const cIe={};_&2&&(cIe.$$scope={dirty:_,ctx:f}),N5.$set(cIe);const fIe={};_&2&&(fIe.$$scope={dirty:_,ctx:f}),lw.$set(fIe);const Py={};_&2&&(Py.$$scope={dirty:_,ctx:f}),dw.$set(Py);const mIe={};_&2&&(mIe.$$scope={dirty:_,ctx:f}),Cw.$set(mIe);const gIe={};_&2&&(gIe.$$scope={dirty:_,ctx:f}),Aw.$set(gIe);const By={};_&2&&(By.$$scope={dirty:_,ctx:f}),Iw.$set(By);const hIe={};_&2&&(hIe.$$scope={dirty:_,ctx:f}),qw.$set(hIe);const uIe={};_&2&&(uIe.$$scope={dirty:_,ctx:f}),Ow.$set(uIe);const Iy={};_&2&&(Iy.$$scope={dirty:_,ctx:f}),Xw.$set(Iy);const pIe={};_&2&&(pIe.$$scope={dirty:_,ctx:f}),mA.$set(pIe);const _Ie={};_&2&&(_Ie.$$scope={dirty:_,ctx:f}),hA.$set(_Ie);const Ny={};_&2&&(Ny.$$scope={dirty:_,ctx:f}),wA.$set(Ny);const vIe={};_&2&&(vIe.$$scope={dirty:_,ctx:f}),LA.$set(vIe);const bIe={};_&2&&(bIe.$$scope={dirty:_,ctx:f}),r6.$set(bIe);const qy={};_&2&&(qy.$$scope={dirty:_,ctx:f}),a6.$set(qy);const FIe={};_&2&&(FIe.$$scope={dirty:_,ctx:f}),M6.$set(FIe);const TIe={};_&2&&(TIe.$$scope={dirty:_,ctx:f}),C6.$set(TIe);const jy={};_&2&&(jy.$$scope={dirty:_,ctx:f}),L6.$set(jy);const MIe={};_&2&&(MIe.$$scope={dirty:_,ctx:f}),x6.$set(MIe);const EIe={};_&2&&(EIe.$$scope={dirty:_,ctx:f}),k6.$set(EIe);const Dy={};_&2&&(Dy.$$scope={dirty:_,ctx:f}),R6.$set(Dy);const CIe={};_&2&&(CIe.$$scope={dirty:_,ctx:f}),B6.$set(CIe);const wIe={};_&2&&(wIe.$$scope={dirty:_,ctx:f}),N6.$set(wIe);const Gy={};_&2&&(Gy.$$scope={dirty:_,ctx:f}),s7.$set(Gy);const AIe={};_&2&&(AIe.$$scope={dirty:_,ctx:f}),i7.$set(AIe);const LIe={};_&2&&(LIe.$$scope={dirty:_,ctx:f}),$7.$set(LIe);const Oy={};_&2&&(Oy.$$scope={dirty:_,ctx:f}),S7.$set(Oy);const yIe={};_&2&&(yIe.$$scope={dirty:_,ctx:f}),P7.$set(yIe);const xIe={};_&2&&(xIe.$$scope={dirty:_,ctx:f}),I7.$set(xIe);const Vy={};_&2&&(Vy.$$scope={dirty:_,ctx:f}),j7.$set(Vy);const $Ie={};_&2&&($Ie.$$scope={dirty:_,ctx:f}),G7.$set($Ie);const kIe={};_&2&&(kIe.$$scope={dirty:_,ctx:f}),u8.$set(kIe);const Xy={};_&2&&(Xy.$$scope={dirty:_,ctx:f}),_8.$set(Xy);const SIe={};_&2&&(SIe.$$scope={dirty:_,ctx:f}),y8.$set(SIe);const RIe={};_&2&&(RIe.$$scope={dirty:_,ctx:f}),$8.$set(RIe);const zy={};_&2&&(zy.$$scope={dirty:_,ctx:f}),X8.$set(zy);const PIe={};_&2&&(PIe.$$scope={dirty:_,ctx:f}),Q8.$set(PIe);const BIe={};_&2&&(BIe.$$scope={dirty:_,ctx:f}),tL.$set(BIe);const Qy={};_&2&&(Qy.$$scope={dirty:_,ctx:f}),nL.$set(Qy);const IIe={};_&2&&(IIe.$$scope={dirty:_,ctx:f}),pL.$set(IIe);const NIe={};_&2&&(NIe.$$scope={dirty:_,ctx:f}),vL.$set(NIe);const Wy={};_&2&&(Wy.$$scope={dirty:_,ctx:f}),xL.$set(Wy);const qIe={};_&2&&(qIe.$$scope={dirty:_,ctx:f}),kL.$set(qIe);const jIe={};_&2&&(jIe.$$scope={dirty:_,ctx:f}),OL.$set(jIe);const Uy={};_&2&&(Uy.$$scope={dirty:_,ctx:f}),XL.$set(Uy);const DIe={};_&2&&(DIe.$$scope={dirty:_,ctx:f}),KL.$set(DIe);const GIe={};_&2&&(GIe.$$scope={dirty:_,ctx:f}),oy.$set(GIe);const Hy={};_&2&&(Hy.$$scope={dirty:_,ctx:f}),cy.$set(Hy);const OIe={};_&2&&(OIe.$$scope={dirty:_,ctx:f}),my.$set(OIe);const VIe={};_&2&&(VIe.$$scope={dirty:_,ctx:f}),hy.$set(VIe);const Jy={};_&2&&(Jy.$$scope={dirty:_,ctx:f}),py.$set(Jy);const XIe={};_&2&&(XIe.$$scope={dirty:_,ctx:f}),by.$set(XIe);const zIe={};_&2&&(zIe.$$scope={dirty:_,ctx:f}),Ty.$set(zIe);const Yy={};_&2&&(Yy.$$scope={dirty:_,ctx:f}),Ey.$set(Yy)},i(f){Ono||(E(d.$$.fragment,f),E(on.$$.fragment,f),E(d$.$$.fragment,f),E(c$.$$.fragment,f),E(Jm.$$.fragment,f),E(f$.$$.fragment,f),E(m$.$$.fragment,f),E(u$.$$.fragment,f),E(wu.$$.fragment,f),E(p$.$$.fragment,f),E(_$.$$.fragment,f),E(v$.$$.fragment,f),E(T$.$$.fragment,f),E(cp.$$.fragment,f),E(M$.$$.fragment,f),E(E$.$$.fragment,f),E(C$.$$.fragment,f),E(L$.$$.fragment,f),E(t_.$$.fragment,f),E(a_.$$.fragment,f),E(y$.$$.fragment,f),E(x$.$$.fragment,f),E($$.$$.fragment,f),E(R$.$$.fragment,f),E(x_.$$.fragment,f),E($_.$$.fragment,f),E(P$.$$.fragment,f),E(B$.$$.fragment,f),E(I$.$$.fragment,f),E(q$.$$.fragment,f),E(R_.$$.fragment,f),E(j$.$$.fragment,f),E(ov.$$.fragment,f),E(D$.$$.fragment,f),E(G$.$$.fragment,f),E(V$.$$.fragment,f),E(tv.$$.fragment,f),E(X$.$$.fragment,f),E(Kv.$$.fragment,f),E(z$.$$.fragment,f),E(Q$.$$.fragment,f),E(U$.$$.fragment,f),E(o1.$$.fragment,f),E(H$.$$.fragment,f),E(z1.$$.fragment,f),E(J$.$$.fragment,f),E(Y$.$$.fragment,f),E(K$.$$.fragment,f),E(W1.$$.fragment,f),E(ek.$$.fragment,f),E(Y1.$$.fragment,f),E(rk.$$.fragment,f),E(tk.$$.fragment,f),E(nk.$$.fragment,f),E(K1.$$.fragment,f),E(sk.$$.fragment,f),E(Db.$$.fragment,f),E(lk.$$.fragment,f),E(ik.$$.fragment,f),E(ck.$$.fragment,f),E(Ob.$$.fragment,f),E(fk.$$.fragment,f),E(c0.$$.fragment,f),E(mk.$$.fragment,f),E(gk.$$.fragment,f),E(uk.$$.fragment,f),E(m0.$$.fragment,f),E(pk.$$.fragment,f),E(pF.$$.fragment,f),E(_k.$$.fragment,f),E(vk.$$.fragment,f),E(Fk.$$.fragment,f),E(vF.$$.fragment,f),E(Tk.$$.fragment,f),E(ZF.$$.fragment,f),E(Mk.$$.fragment,f),E(Ek.$$.fragment,f),E(wk.$$.fragment,f),E(eT.$$.fragment,f),E(Ak.$$.fragment,f),E(dT.$$.fragment,f),E(Lk.$$.fragment,f),E(yk.$$.fragment,f),E($k.$$.fragment,f),E(fT.$$.fragment,f),E(kk.$$.fragment,f),E(eM.$$.fragment,f),E(Sk.$$.fragment,f),E(Rk.$$.fragment,f),E(Bk.$$.fragment,f),E(rM.$$.fragment,f),E(Ik.$$.fragment,f),E(ZM.$$.fragment,f),E(Nk.$$.fragment,f),E(qk.$$.fragment,f),E(Dk.$$.fragment,f),E(eE.$$.fragment,f),E(Gk.$$.fragment,f),E(tE.$$.fragment,f),E(Ok.$$.fragment,f),E(Vk.$$.fragment,f),E(zk.$$.fragment,f),E(nE.$$.fragment,f),E(Qk.$$.fragment,f),E(cE.$$.fragment,f),E(Wk.$$.fragment,f),E(Uk.$$.fragment,f),E(Jk.$$.fragment,f),E(mE.$$.fragment,f),E(Yk.$$.fragment,f),E(xE.$$.fragment,f),E(Zk.$$.fragment,f),E(Kk.$$.fragment,f),E(oS.$$.fragment,f),E(kE.$$.fragment,f),E(rS.$$.fragment,f),E(PE.$$.fragment,f),E(tS.$$.fragment,f),E(aS.$$.fragment,f),E(sS.$$.fragment,f),E(IE.$$.fragment,f),E(lS.$$.fragment,f),E(jE.$$.fragment,f),E(iS.$$.fragment,f),E(dS.$$.fragment,f),E(fS.$$.fragment,f),E(GE.$$.fragment,f),E(mS.$$.fragment,f),E(XE.$$.fragment,f),E(gS.$$.fragment,f),E(hS.$$.fragment,f),E(pS.$$.fragment,f),E(QE.$$.fragment,f),E(_S.$$.fragment,f),E(tC.$$.fragment,f),E(vS.$$.fragment,f),E(bS.$$.fragment,f),E(TS.$$.fragment,f),E(nC.$$.fragment,f),E(MS.$$.fragment,f),E(mC.$$.fragment,f),E(ES.$$.fragment,f),E(CS.$$.fragment,f),E(AS.$$.fragment,f),E(hC.$$.fragment,f),E(LS.$$.fragment,f),E(AC.$$.fragment,f),E(yS.$$.fragment,f),E(xS.$$.fragment,f),E(kS.$$.fragment,f),E(yC.$$.fragment,f),E(SS.$$.fragment,f),E(RC.$$.fragment,f),E(RS.$$.fragment,f),E(PS.$$.fragment,f),E(IS.$$.fragment,f),E(BC.$$.fragment,f),E(NS.$$.fragment,f),E(OC.$$.fragment,f),E(qS.$$.fragment,f),E(jS.$$.fragment,f),E(GS.$$.fragment,f),E(XC.$$.fragment,f),E(OS.$$.fragment,f),E(JC.$$.fragment,f),E(VS.$$.fragment,f),E(XS.$$.fragment,f),E(QS.$$.fragment,f),E(ZC.$$.fragment,f),E(WS.$$.fragment,f),E(n3.$$.fragment,f),E(US.$$.fragment,f),E(HS.$$.fragment,f),E(YS.$$.fragment,f),E(l3.$$.fragment,f),E(ZS.$$.fragment,f),E(c3.$$.fragment,f),E(KS.$$.fragment,f),E(eR.$$.fragment,f),E(rR.$$.fragment,f),E(m3.$$.fragment,f),E(tR.$$.fragment,f),E(b3.$$.fragment,f),E(aR.$$.fragment,f),E(nR.$$.fragment,f),E(lR.$$.fragment,f),E(T3.$$.fragment,f),E(iR.$$.fragment,f),E(C3.$$.fragment,f),E(dR.$$.fragment,f),E(cR.$$.fragment,f),E(mR.$$.fragment,f),E(A3.$$.fragment,f),E(gR.$$.fragment,f),E(x3.$$.fragment,f),E(hR.$$.fragment,f),E(uR.$$.fragment,f),E(_R.$$.fragment,f),E(k3.$$.fragment,f),E(vR.$$.fragment,f),E(B5.$$.fragment,f),E(bR.$$.fragment,f),E(FR.$$.fragment,f),E(MR.$$.fragment,f),E(N5.$$.fragment,f),E(ER.$$.fragment,f),E(lw.$$.fragment,f),E(CR.$$.fragment,f),E(wR.$$.fragment,f),E(LR.$$.fragment,f),E(dw.$$.fragment,f),E(yR.$$.fragment,f),E(Cw.$$.fragment,f),E(xR.$$.fragment,f),E($R.$$.fragment,f),E(SR.$$.fragment,f),E(Aw.$$.fragment,f),E(RR.$$.fragment,f),E(Iw.$$.fragment,f),E(PR.$$.fragment,f),E(BR.$$.fragment,f),E(NR.$$.fragment,f),E(qw.$$.fragment,f),E(qR.$$.fragment,f),E(Ow.$$.fragment,f),E(jR.$$.fragment,f),E(DR.$$.fragment,f),E(OR.$$.fragment,f),E(Xw.$$.fragment,f),E(VR.$$.fragment,f),E(mA.$$.fragment,f),E(XR.$$.fragment,f),E(zR.$$.fragment,f),E(WR.$$.fragment,f),E(hA.$$.fragment,f),E(UR.$$.fragment,f),E(wA.$$.fragment,f),E(HR.$$.fragment,f),E(JR.$$.fragment,f),E(ZR.$$.fragment,f),E(LA.$$.fragment,f),E(KR.$$.fragment,f),E(r6.$$.fragment,f),E(eP.$$.fragment,f),E(oP.$$.fragment,f),E(tP.$$.fragment,f),E(a6.$$.fragment,f),E(aP.$$.fragment,f),E(M6.$$.fragment,f),E(nP.$$.fragment,f),E(sP.$$.fragment,f),E(iP.$$.fragment,f),E(C6.$$.fragment,f),E(dP.$$.fragment,f),E(L6.$$.fragment,f),E(fP.$$.fragment,f),E(mP.$$.fragment,f),E(hP.$$.fragment,f),E(x6.$$.fragment,f),E(uP.$$.fragment,f),E(k6.$$.fragment,f),E(pP.$$.fragment,f),E(_P.$$.fragment,f),E(bP.$$.fragment,f),E(R6.$$.fragment,f),E(FP.$$.fragment,f),E(B6.$$.fragment,f),E(TP.$$.fragment,f),E(MP.$$.fragment,f),E(CP.$$.fragment,f),E(N6.$$.fragment,f),E(wP.$$.fragment,f),E(s7.$$.fragment,f),E(AP.$$.fragment,f),E(LP.$$.fragment,f),E(xP.$$.fragment,f),E(i7.$$.fragment,f),E($P.$$.fragment,f),E($7.$$.fragment,f),E(kP.$$.fragment,f),E(SP.$$.fragment,f),E(PP.$$.fragment,f),E(S7.$$.fragment,f),E(BP.$$.fragment,f),E(P7.$$.fragment,f),E(IP.$$.fragment,f),E(NP.$$.fragment,f),E(jP.$$.fragment,f),E(I7.$$.fragment,f),E(DP.$$.fragment,f),E(j7.$$.fragment,f),E(OP.$$.fragment,f),E(VP.$$.fragment,f),E(zP.$$.fragment,f),E(G7.$$.fragment,f),E(QP.$$.fragment,f),E(u8.$$.fragment,f),E(WP.$$.fragment,f),E(UP.$$.fragment,f),E(JP.$$.fragment,f),E(_8.$$.fragment,f),E(YP.$$.fragment,f),E(y8.$$.fragment,f),E(ZP.$$.fragment,f),E(KP.$$.fragment,f),E(oB.$$.fragment,f),E($8.$$.fragment,f),E(rB.$$.fragment,f),E(X8.$$.fragment,f),E(tB.$$.fragment,f),E(aB.$$.fragment,f),E(sB.$$.fragment,f),E(Q8.$$.fragment,f),E(lB.$$.fragment,f),E(tL.$$.fragment,f),E(iB.$$.fragment,f),E(dB.$$.fragment,f),E(fB.$$.fragment,f),E(nL.$$.fragment,f),E(mB.$$.fragment,f),E(pL.$$.fragment,f),E(gB.$$.fragment,f),E(hB.$$.fragment,f),E(pB.$$.fragment,f),E(vL.$$.fragment,f),E(_B.$$.fragment,f),E(xL.$$.fragment,f),E(vB.$$.fragment,f),E(bB.$$.fragment,f),E(TB.$$.fragment,f),E(kL.$$.fragment,f),E(MB.$$.fragment,f),E(OL.$$.fragment,f),E(EB.$$.fragment,f),E(CB.$$.fragment,f),E(AB.$$.fragment,f),E(XL.$$.fragment,f),E(LB.$$.fragment,f),E(KL.$$.fragment,f),E(yB.$$.fragment,f),E(xB.$$.fragment,f),E(kB.$$.fragment,f),E(oy.$$.fragment,f),E(SB.$$.fragment,f),E(cy.$$.fragment,f),E(RB.$$.fragment,f),E(PB.$$.fragment,f),E(IB.$$.fragment,f),E(my.$$.fragment,f),E(NB.$$.fragment,f),E(hy.$$.fragment,f),E(qB.$$.fragment,f),E(jB.$$.fragment,f),E(GB.$$.fragment,f),E(py.$$.fragment,f),E(OB.$$.fragment,f),E(by.$$.fragment,f),E(XB.$$.fragment,f),E(zB.$$.fragment,f),E(WB.$$.fragment,f),E(Ty.$$.fragment,f),E(UB.$$.fragment,f),E(Ey.$$.fragment,f),Ono=!0)},o(f){C(d.$$.fragment,f),C(on.$$.fragment,f),C(d$.$$.fragment,f),C(c$.$$.fragment,f),C(Jm.$$.fragment,f),C(f$.$$.fragment,f),C(m$.$$.fragment,f),C(u$.$$.fragment,f),C(wu.$$.fragment,f),C(p$.$$.fragment,f),C(_$.$$.fragment,f),C(v$.$$.fragment,f),C(T$.$$.fragment,f),C(cp.$$.fragment,f),C(M$.$$.fragment,f),C(E$.$$.fragment,f),C(C$.$$.fragment,f),C(L$.$$.fragment,f),C(t_.$$.fragment,f),C(a_.$$.fragment,f),C(y$.$$.fragment,f),C(x$.$$.fragment,f),C($$.$$.fragment,f),C(R$.$$.fragment,f),C(x_.$$.fragment,f),C($_.$$.fragment,f),C(P$.$$.fragment,f),C(B$.$$.fragment,f),C(I$.$$.fragment,f),C(q$.$$.fragment,f),C(R_.$$.fragment,f),C(j$.$$.fragment,f),C(ov.$$.fragment,f),C(D$.$$.fragment,f),C(G$.$$.fragment,f),C(V$.$$.fragment,f),C(tv.$$.fragment,f),C(X$.$$.fragment,f),C(Kv.$$.fragment,f),C(z$.$$.fragment,f),C(Q$.$$.fragment,f),C(U$.$$.fragment,f),C(o1.$$.fragment,f),C(H$.$$.fragment,f),C(z1.$$.fragment,f),C(J$.$$.fragment,f),C(Y$.$$.fragment,f),C(K$.$$.fragment,f),C(W1.$$.fragment,f),C(ek.$$.fragment,f),C(Y1.$$.fragment,f),C(rk.$$.fragment,f),C(tk.$$.fragment,f),C(nk.$$.fragment,f),C(K1.$$.fragment,f),C(sk.$$.fragment,f),C(Db.$$.fragment,f),C(lk.$$.fragment,f),C(ik.$$.fragment,f),C(ck.$$.fragment,f),C(Ob.$$.fragment,f),C(fk.$$.fragment,f),C(c0.$$.fragment,f),C(mk.$$.fragment,f),C(gk.$$.fragment,f),C(uk.$$.fragment,f),C(m0.$$.fragment,f),C(pk.$$.fragment,f),C(pF.$$.fragment,f),C(_k.$$.fragment,f),C(vk.$$.fragment,f),C(Fk.$$.fragment,f),C(vF.$$.fragment,f),C(Tk.$$.fragment,f),C(ZF.$$.fragment,f),C(Mk.$$.fragment,f),C(Ek.$$.fragment,f),C(wk.$$.fragment,f),C(eT.$$.fragment,f),C(Ak.$$.fragment,f),C(dT.$$.fragment,f),C(Lk.$$.fragment,f),C(yk.$$.fragment,f),C($k.$$.fragment,f),C(fT.$$.fragment,f),C(kk.$$.fragment,f),C(eM.$$.fragment,f),C(Sk.$$.fragment,f),C(Rk.$$.fragment,f),C(Bk.$$.fragment,f),C(rM.$$.fragment,f),C(Ik.$$.fragment,f),C(ZM.$$.fragment,f),C(Nk.$$.fragment,f),C(qk.$$.fragment,f),C(Dk.$$.fragment,f),C(eE.$$.fragment,f),C(Gk.$$.fragment,f),C(tE.$$.fragment,f),C(Ok.$$.fragment,f),C(Vk.$$.fragment,f),C(zk.$$.fragment,f),C(nE.$$.fragment,f),C(Qk.$$.fragment,f),C(cE.$$.fragment,f),C(Wk.$$.fragment,f),C(Uk.$$.fragment,f),C(Jk.$$.fragment,f),C(mE.$$.fragment,f),C(Yk.$$.fragment,f),C(xE.$$.fragment,f),C(Zk.$$.fragment,f),C(Kk.$$.fragment,f),C(oS.$$.fragment,f),C(kE.$$.fragment,f),C(rS.$$.fragment,f),C(PE.$$.fragment,f),C(tS.$$.fragment,f),C(aS.$$.fragment,f),C(sS.$$.fragment,f),C(IE.$$.fragment,f),C(lS.$$.fragment,f),C(jE.$$.fragment,f),C(iS.$$.fragment,f),C(dS.$$.fragment,f),C(fS.$$.fragment,f),C(GE.$$.fragment,f),C(mS.$$.fragment,f),C(XE.$$.fragment,f),C(gS.$$.fragment,f),C(hS.$$.fragment,f),C(pS.$$.fragment,f),C(QE.$$.fragment,f),C(_S.$$.fragment,f),C(tC.$$.fragment,f),C(vS.$$.fragment,f),C(bS.$$.fragment,f),C(TS.$$.fragment,f),C(nC.$$.fragment,f),C(MS.$$.fragment,f),C(mC.$$.fragment,f),C(ES.$$.fragment,f),C(CS.$$.fragment,f),C(AS.$$.fragment,f),C(hC.$$.fragment,f),C(LS.$$.fragment,f),C(AC.$$.fragment,f),C(yS.$$.fragment,f),C(xS.$$.fragment,f),C(kS.$$.fragment,f),C(yC.$$.fragment,f),C(SS.$$.fragment,f),C(RC.$$.fragment,f),C(RS.$$.fragment,f),C(PS.$$.fragment,f),C(IS.$$.fragment,f),C(BC.$$.fragment,f),C(NS.$$.fragment,f),C(OC.$$.fragment,f),C(qS.$$.fragment,f),C(jS.$$.fragment,f),C(GS.$$.fragment,f),C(XC.$$.fragment,f),C(OS.$$.fragment,f),C(JC.$$.fragment,f),C(VS.$$.fragment,f),C(XS.$$.fragment,f),C(QS.$$.fragment,f),C(ZC.$$.fragment,f),C(WS.$$.fragment,f),C(n3.$$.fragment,f),C(US.$$.fragment,f),C(HS.$$.fragment,f),C(YS.$$.fragment,f),C(l3.$$.fragment,f),C(ZS.$$.fragment,f),C(c3.$$.fragment,f),C(KS.$$.fragment,f),C(eR.$$.fragment,f),C(rR.$$.fragment,f),C(m3.$$.fragment,f),C(tR.$$.fragment,f),C(b3.$$.fragment,f),C(aR.$$.fragment,f),C(nR.$$.fragment,f),C(lR.$$.fragment,f),C(T3.$$.fragment,f),C(iR.$$.fragment,f),C(C3.$$.fragment,f),C(dR.$$.fragment,f),C(cR.$$.fragment,f),C(mR.$$.fragment,f),C(A3.$$.fragment,f),C(gR.$$.fragment,f),C(x3.$$.fragment,f),C(hR.$$.fragment,f),C(uR.$$.fragment,f),C(_R.$$.fragment,f),C(k3.$$.fragment,f),C(vR.$$.fragment,f),C(B5.$$.fragment,f),C(bR.$$.fragment,f),C(FR.$$.fragment,f),C(MR.$$.fragment,f),C(N5.$$.fragment,f),C(ER.$$.fragment,f),C(lw.$$.fragment,f),C(CR.$$.fragment,f),C(wR.$$.fragment,f),C(LR.$$.fragment,f),C(dw.$$.fragment,f),C(yR.$$.fragment,f),C(Cw.$$.fragment,f),C(xR.$$.fragment,f),C($R.$$.fragment,f),C(SR.$$.fragment,f),C(Aw.$$.fragment,f),C(RR.$$.fragment,f),C(Iw.$$.fragment,f),C(PR.$$.fragment,f),C(BR.$$.fragment,f),C(NR.$$.fragment,f),C(qw.$$.fragment,f),C(qR.$$.fragment,f),C(Ow.$$.fragment,f),C(jR.$$.fragment,f),C(DR.$$.fragment,f),C(OR.$$.fragment,f),C(Xw.$$.fragment,f),C(VR.$$.fragment,f),C(mA.$$.fragment,f),C(XR.$$.fragment,f),C(zR.$$.fragment,f),C(WR.$$.fragment,f),C(hA.$$.fragment,f),C(UR.$$.fragment,f),C(wA.$$.fragment,f),C(HR.$$.fragment,f),C(JR.$$.fragment,f),C(ZR.$$.fragment,f),C(LA.$$.fragment,f),C(KR.$$.fragment,f),C(r6.$$.fragment,f),C(eP.$$.fragment,f),C(oP.$$.fragment,f),C(tP.$$.fragment,f),C(a6.$$.fragment,f),C(aP.$$.fragment,f),C(M6.$$.fragment,f),C(nP.$$.fragment,f),C(sP.$$.fragment,f),C(iP.$$.fragment,f),C(C6.$$.fragment,f),C(dP.$$.fragment,f),C(L6.$$.fragment,f),C(fP.$$.fragment,f),C(mP.$$.fragment,f),C(hP.$$.fragment,f),C(x6.$$.fragment,f),C(uP.$$.fragment,f),C(k6.$$.fragment,f),C(pP.$$.fragment,f),C(_P.$$.fragment,f),C(bP.$$.fragment,f),C(R6.$$.fragment,f),C(FP.$$.fragment,f),C(B6.$$.fragment,f),C(TP.$$.fragment,f),C(MP.$$.fragment,f),C(CP.$$.fragment,f),C(N6.$$.fragment,f),C(wP.$$.fragment,f),C(s7.$$.fragment,f),C(AP.$$.fragment,f),C(LP.$$.fragment,f),C(xP.$$.fragment,f),C(i7.$$.fragment,f),C($P.$$.fragment,f),C($7.$$.fragment,f),C(kP.$$.fragment,f),C(SP.$$.fragment,f),C(PP.$$.fragment,f),C(S7.$$.fragment,f),C(BP.$$.fragment,f),C(P7.$$.fragment,f),C(IP.$$.fragment,f),C(NP.$$.fragment,f),C(jP.$$.fragment,f),C(I7.$$.fragment,f),C(DP.$$.fragment,f),C(j7.$$.fragment,f),C(OP.$$.fragment,f),C(VP.$$.fragment,f),C(zP.$$.fragment,f),C(G7.$$.fragment,f),C(QP.$$.fragment,f),C(u8.$$.fragment,f),C(WP.$$.fragment,f),C(UP.$$.fragment,f),C(JP.$$.fragment,f),C(_8.$$.fragment,f),C(YP.$$.fragment,f),C(y8.$$.fragment,f),C(ZP.$$.fragment,f),C(KP.$$.fragment,f),C(oB.$$.fragment,f),C($8.$$.fragment,f),C(rB.$$.fragment,f),C(X8.$$.fragment,f),C(tB.$$.fragment,f),C(aB.$$.fragment,f),C(sB.$$.fragment,f),C(Q8.$$.fragment,f),C(lB.$$.fragment,f),C(tL.$$.fragment,f),C(iB.$$.fragment,f),C(dB.$$.fragment,f),C(fB.$$.fragment,f),C(nL.$$.fragment,f),C(mB.$$.fragment,f),C(pL.$$.fragment,f),C(gB.$$.fragment,f),C(hB.$$.fragment,f),C(pB.$$.fragment,f),C(vL.$$.fragment,f),C(_B.$$.fragment,f),C(xL.$$.fragment,f),C(vB.$$.fragment,f),C(bB.$$.fragment,f),C(TB.$$.fragment,f),C(kL.$$.fragment,f),C(MB.$$.fragment,f),C(OL.$$.fragment,f),C(EB.$$.fragment,f),C(CB.$$.fragment,f),C(AB.$$.fragment,f),C(XL.$$.fragment,f),C(LB.$$.fragment,f),C(KL.$$.fragment,f),C(yB.$$.fragment,f),C(xB.$$.fragment,f),C(kB.$$.fragment,f),C(oy.$$.fragment,f),C(SB.$$.fragment,f),C(cy.$$.fragment,f),C(RB.$$.fragment,f),C(PB.$$.fragment,f),C(IB.$$.fragment,f),C(my.$$.fragment,f),C(NB.$$.fragment,f),C(hy.$$.fragment,f),C(qB.$$.fragment,f),C(jB.$$.fragment,f),C(GB.$$.fragment,f),C(py.$$.fragment,f),C(OB.$$.fragment,f),C(by.$$.fragment,f),C(XB.$$.fragment,f),C(zB.$$.fragment,f),C(WB.$$.fragment,f),C(Ty.$$.fragment,f),C(UB.$$.fragment,f),C(Ey.$$.fragment,f),Ono=!1},d(f){t(g),f&&t(b),f&&t(u),w(d),f&&t(zm),f&&t(Tt),f&&t(Xe),f&&t(He),f&&t(Wm),w(on,f),f&&t(Je),f&&t(Ae),f&&t(ko),f&&t(rn),f&&t(wto),f&&t(wd),w(d$),f&&t(Ato),f&&t(hs),f&&t(Lto),w(c$,f),f&&t(yto),f&&t(LN),f&&t(xto),w(Jm,f),f&&t($to),f&&t(Ad),w(f$),f&&t(kto),f&&t(So),w(m$),w(u$),w(wu),w(p$),f&&t(Sto),f&&t(yd),w(_$),f&&t(Rto),f&&t(Ro),w(v$),w(T$),w(cp),w(M$),f&&t(Pto),f&&t(xd),w(E$),f&&t(Bto),f&&t(Po),w(C$),w(L$),w(t_),w(a_),w(y$),f&&t(Ito),f&&t($d),w(x$),f&&t(Nto),f&&t(Bo),w($$),w(R$),w(x_),w($_),w(P$),f&&t(qto),f&&t(Sd),w(B$),f&&t(jto),f&&t(Io),w(I$),w(q$),w(R_),w(j$),w(ov),f&&t(Dto),f&&t(Bd),w(D$),f&&t(Gto),f&&t(No),w(G$),w(V$),w(tv),w(X$),w(Kv),f&&t(Oto),f&&t(qd),w(z$),f&&t(Vto),f&&t(qo),w(Q$),w(U$),w(o1),w(H$),w(z1),f&&t(Xto),f&&t(Gd),w(J$),f&&t(zto),f&&t(jo),w(Y$),w(K$),w(W1),w(ek),w(Y1),f&&t(Qto),f&&t(Xd),w(rk),f&&t(Wto),f&&t(Do),w(tk),w(nk),w(K1),w(sk),w(Db),f&&t(Uto),f&&t(Wd),w(lk),f&&t(Hto),f&&t(Go),w(ik),w(ck),w(Ob),w(fk),w(c0),f&&t(Jto),f&&t(Jd),w(mk),f&&t(Yto),f&&t(Oo),w(gk),w(uk),w(m0),w(pk),w(pF),f&&t(Zto),f&&t(Kd),w(_k),f&&t(Kto),f&&t(Vo),w(vk),w(Fk),w(vF),w(Tk),w(ZF),f&&t(eao),f&&t(rc),w(Mk),f&&t(oao),f&&t(Xo),w(Ek),w(wk),w(eT),w(Ak),w(dT),f&&t(rao),f&&t(nc),w(Lk),f&&t(tao),f&&t(zo),w(yk),w($k),w(fT),w(kk),w(eM),f&&t(aao),f&&t(ic),w(Sk),f&&t(nao),f&&t(Qo),w(Rk),w(Bk),w(rM),w(Ik),w(ZM),f&&t(sao),f&&t(fc),w(Nk),f&&t(lao),f&&t(Wo),w(qk),w(Dk),w(eE),w(Gk),w(tE),f&&t(iao),f&&t(hc),w(Ok),f&&t(dao),f&&t(Uo),w(Vk),w(zk),w(nE),w(Qk),w(cE),f&&t(cao),f&&t(vc),w(Wk),f&&t(fao),f&&t(Ho),w(Uk),w(Jk),w(mE),w(Yk),w(xE),f&&t(mao),f&&t(Tc),w(Zk),f&&t(gao),f&&t(Jo),w(Kk),w(oS),w(kE),w(rS),w(PE),f&&t(hao),f&&t(Cc),w(tS),f&&t(uao),f&&t(Yo),w(aS),w(sS),w(IE),w(lS),w(jE),f&&t(pao),f&&t(Lc),w(iS),f&&t(_ao),f&&t(Zo),w(dS),w(fS),w(GE),w(mS),w(XE),f&&t(vao),f&&t($c),w(gS),f&&t(bao),f&&t(Ko),w(hS),w(pS),w(QE),w(_S),w(tC),f&&t(Fao),f&&t(Rc),w(vS),f&&t(Tao),f&&t(er),w(bS),w(TS),w(nC),w(MS),w(mC),f&&t(Mao),f&&t(Ic),w(ES),f&&t(Eao),f&&t(or),w(CS),w(AS),w(hC),w(LS),w(AC),f&&t(Cao),f&&t(jc),w(yS),f&&t(wao),f&&t(rr),w(xS),w(kS),w(yC),w(SS),w(RC),f&&t(Aao),f&&t(Vc),w(RS),f&&t(Lao),f&&t(tr),w(PS),w(IS),w(BC),w(NS),w(OC),f&&t(yao),f&&t(Qc),w(qS),f&&t(xao),f&&t(ar),w(jS),w(GS),w(XC),w(OS),w(JC),f&&t($ao),f&&t(Hc),w(VS),f&&t(kao),f&&t(nr),w(XS),w(QS),w(ZC),w(WS),w(n3),f&&t(Sao),f&&t(Zc),w(US),f&&t(Rao),f&&t(sr),w(HS),w(YS),w(l3),w(ZS),w(c3),f&&t(Pao),f&&t(of),w(KS),f&&t(Bao),f&&t(lr),w(eR),w(rR),w(m3),w(tR),w(b3),f&&t(Iao),f&&t(af),w(aR),f&&t(Nao),f&&t(ir),w(nR),w(lR),w(T3),w(iR),w(C3),f&&t(qao),f&&t(lf),w(dR),f&&t(jao),f&&t(dr),w(cR),w(mR),w(A3),w(gR),w(x3),f&&t(Dao),f&&t(ff),w(hR),f&&t(Gao),f&&t(cr),w(uR),w(_R),w(k3),w(vR),w(B5),f&&t(Oao),f&&t(hf),w(bR),f&&t(Vao),f&&t(fr),w(FR),w(MR),w(N5),w(ER),w(lw),f&&t(Xao),f&&t(_f),w(CR),f&&t(zao),f&&t(mr),w(wR),w(LR),w(dw),w(yR),w(Cw),f&&t(Qao),f&&t(Ff),w(xR),f&&t(Wao),f&&t(gr),w($R),w(SR),w(Aw),w(RR),w(Iw),f&&t(Uao),f&&t(Ef),w(PR),f&&t(Hao),f&&t(hr),w(BR),w(NR),w(qw),w(qR),w(Ow),f&&t(Jao),f&&t(Lf),w(jR),f&&t(Yao),f&&t(ur),w(DR),w(OR),w(Xw),w(VR),w(mA),f&&t(Zao),f&&t($f),w(XR),f&&t(Kao),f&&t(pr),w(zR),w(WR),w(hA),w(UR),w(wA),f&&t(eno),f&&t(Rf),w(HR),f&&t(ono),f&&t(_r),w(JR),w(ZR),w(LA),w(KR),w(r6),f&&t(rno),f&&t(If),w(eP),f&&t(tno),f&&t(vr),w(oP),w(tP),w(a6),w(aP),w(M6),f&&t(ano),f&&t(jf),w(nP),f&&t(nno),f&&t(br),w(sP),w(iP),w(C6),w(dP),w(L6),f&&t(sno),f&&t(Of),w(fP),f&&t(lno),f&&t(Fr),w(mP),w(hP),w(x6),w(uP),w(k6),f&&t(ino),f&&t(zf),w(pP),f&&t(dno),f&&t(Tr),w(_P),w(bP),w(R6),w(FP),w(B6),f&&t(cno),f&&t(Uf),w(TP),f&&t(fno),f&&t(Mr),w(MP),w(CP),w(N6),w(wP),w(s7),f&&t(mno),f&&t(Yf),w(AP),f&&t(gno),f&&t(Er),w(LP),w(xP),w(i7),w($P),w($7),f&&t(hno),f&&t(em),w(kP),f&&t(uno),f&&t(Cr),w(SP),w(PP),w(S7),w(BP),w(P7),f&&t(pno),f&&t(tm),w(IP),f&&t(_no),f&&t(wr),w(NP),w(jP),w(I7),w(DP),w(j7),f&&t(vno),f&&t(sm),w(OP),f&&t(bno),f&&t(Ar),w(VP),w(zP),w(G7),w(QP),w(u8),f&&t(Fno),f&&t(dm),w(WP),f&&t(Tno),f&&t(Lr),w(UP),w(JP),w(_8),w(YP),w(y8),f&&t(Mno),f&&t(mm),w(ZP),f&&t(Eno),f&&t(yr),w(KP),w(oB),w($8),w(rB),w(X8),f&&t(Cno),f&&t(um),w(tB),f&&t(wno),f&&t(xr),w(aB),w(sB),w(Q8),w(lB),w(tL),f&&t(Ano),f&&t(vm),w(iB),f&&t(Lno),f&&t($r),w(dB),w(fB),w(nL),w(mB),w(pL),f&&t(yno),f&&t(Tm),w(gB),f&&t(xno),f&&t(kr),w(hB),w(pB),w(vL),w(_B),w(xL),f&&t($no),f&&t(Cm),w(vB),f&&t(kno),f&&t(Sr),w(bB),w(TB),w(kL),w(MB),w(OL),f&&t(Sno),f&&t(Lm),w(EB),f&&t(Rno),f&&t(Rr),w(CB),w(AB),w(XL),w(LB),w(KL),f&&t(Pno),f&&t($m),w(yB),f&&t(Bno),f&&t(Pr),w(xB),w(kB),w(oy),w(SB),w(cy),f&&t(Ino),f&&t(Rm),w(RB),f&&t(Nno),f&&t(Br),w(PB),w(IB),w(my),w(NB),w(hy),f&&t(qno),f&&t(Im),w(qB),f&&t(jno),f&&t(Ir),w(jB),w(GB),w(py),w(OB),w(by),f&&t(Dno),f&&t(jm),w(XB),f&&t(Gno),f&&t(Nr),w(zB),w(WB),w(Ty),w(UB),w(Ey)}}}const D5a={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForDepthEstimation",title:"AutoModelForDepthEstimation"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForDocumentQuestionAnswering",title:"AutoModelForDocumentQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVideoClassification",title:"AutoModelForVideoClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.AutoModelForZeroShotObjectDetection",title:"AutoModelForZeroShotObjectDetection"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForSemanticSegmentation",title:"TFAutoModelForSemanticSegmentation"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForDocumentQuestionAnswering",title:"TFAutoModelForDocumentQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function G5a($){return LCa(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class U5a extends ECa{constructor(g){super();CCa(this,g,G5a,j5a,wCa,{})}}export{U5a as default,D5a as metadata};
