import{S as Vo,i as zo,s as Go,e as n,k as s,w as c,t as f,M as Ro,c as o,d as t,m as i,a,x as h,h as m,b as l,G as e,g as p,y as g,L as Ho,q as u,o as _,B as v,v as Uo}from"../../chunks/vendor-hf-doc-builder.js";import{D as b}from"../../chunks/Docstring-hf-doc-builder.js";import{I as qe}from"../../chunks/IconCopyLink-hf-doc-builder.js";function Bo(Un){let C,Or,P,A,Re,ae,dt,He,pt,Er,I,ct,Ue,ht,gt,kr,L,ut,Se,_t,vt,Cr,N,W,Be,se,xt,je,$t,Pr,De,bt,Nr,k,Me,yt,Ae,wt,Ot,Ie,Et,Le,kt,Ct,We,Pt,Xe,Nt,Tr,T,X,Je,ie,Tt,Ke,Ft,Fr,x,le,qt,Qe,St,Dt,V,fe,Mt,Ye,At,It,z,me,Lt,Ze,Wt,Xt,G,de,Vt,er,zt,Gt,R,pe,Rt,rr,Ht,Ut,H,ce,Bt,tr,jt,qr,F,U,nr,he,Jt,or,Kt,Sr,E,ge,Qt,B,ue,Yt,ar,Zt,en,j,_e,rn,ve,tn,sr,nn,on,Dr,q,J,ir,xe,an,lr,sn,Mr,$e,be,Ar,S,K,fr,ye,ln,mr,fn,Ir,Q,mn,dr,dn,pn,Lr,D,Y,pr,we,cn,cr,hn,Wr,$,Oe,gn,Z,Ee,un,hr,_n,vn,O,ke,xn,gr,$n,bn,ur,yn,wn,M,Ce,On,_r,En,kn,Cn,vr,Pn,Nn,xr,Tn,Fn,ee,Pe,qn,$r,Sn,Dn,re,Ne,Mn,br,An,In,te,Te,Ln,yr,Wn,Xn,ne,Fe,Vn,wr,zn,Xr;return ae=new qe({}),se=new qe({}),ie=new qe({}),le=new b({props:{name:"class transformers.onnx.OnnxConfig",anchor:"transformers.onnx.OnnxConfig",parameters:[{name:"config",val:": PretrainedConfig"},{name:"task",val:": str = 'default'"},{name:"patching_specs",val:": typing.List[transformers.onnx.config.PatchingSpec] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/onnx/config.py#L67"}}),fe=new b({props:{name:"flatten_output_collection_property",anchor:"transformers.onnx.OnnxConfig.flatten_output_collection_property",parameters:[{name:"name",val:": str"},{name:"field",val:": typing.Iterable[typing.Any]"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/onnx/config.py#L412",returnDescription:`
<p>Outputs with flattened structure and key mapping this new structure.</p>
`,returnType:`
<p>(Dict[str, Any])</p>
`}}),me=new b({props:{name:"from_model_config",anchor:"transformers.onnx.OnnxConfig.from_model_config",parameters:[{name:"config",val:": PretrainedConfig"},{name:"task",val:": str = 'default'"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/onnx/config.py#L126",returnDescription:`
<p>OnnxConfig for this model</p>
`}}),de=new b({props:{name:"generate_dummy_inputs",anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs",parameters:[{name:"preprocessor",val:": typing.Union[ForwardRef('PreTrainedTokenizerBase'), ForwardRef('FeatureExtractionMixin')]"},{name:"batch_size",val:": int = -1"},{name:"seq_length",val:": int = -1"},{name:"num_choices",val:": int = -1"},{name:"is_pair",val:": bool = False"},{name:"framework",val:": typing.Optional[transformers.utils.generic.TensorType] = None"},{name:"num_channels",val:": int = 3"},{name:"image_width",val:": int = 40"},{name:"image_height",val:": int = 40"},{name:"sampling_rate",val:": int = 22050"},{name:"time_duration",val:": float = 5.0"},{name:"frequency",val:": int = 220"},{name:"tokenizer",val:": PreTrainedTokenizerBase = None"}],parametersDescription:[{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.batch_size",description:`<strong>batch_size</strong> (<code>int</code>, <em>optional</em>, defaults to -1) &#x2014;
The batch size to export the model for (-1 means dynamic axis).`,name:"batch_size"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.num_choices",description:`<strong>num_choices</strong> (<code>int</code>, <em>optional</em>, defaults to -1) &#x2014;
The number of candidate answers provided for multiple choice task (-1 means dynamic axis).`,name:"num_choices"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.seq_length",description:`<strong>seq_length</strong> (<code>int</code>, <em>optional</em>, defaults to -1) &#x2014;
The sequence length to export the model for (-1 means dynamic axis).`,name:"seq_length"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.is_pair",description:`<strong>is_pair</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Indicate if the input is a pair (sentence 1, sentence 2)`,name:"is_pair"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.framework",description:`<strong>framework</strong> (<code>TensorType</code>, <em>optional</em>, defaults to <code>None</code>) &#x2014;
The framework (PyTorch or TensorFlow) that the tokenizer will generate tensors for.`,name:"framework"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.num_channels",description:`<strong>num_channels</strong> (<code>int</code>, <em>optional</em>, defaults to 3) &#x2014;
The number of channels of the generated images.`,name:"num_channels"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.image_width",description:`<strong>image_width</strong> (<code>int</code>, <em>optional</em>, defaults to 40) &#x2014;
The width of the generated images.`,name:"image_width"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.image_height",description:`<strong>image_height</strong> (<code>int</code>, <em>optional</em>, defaults to 40) &#x2014;
The height of the generated images.`,name:"image_height"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.sampling_rate",description:`<strong>sampling_rate</strong> (<code>int</code>, <em>optional</em> defaults to 22050) &#x2014;
The sampling rate for audio data generation.`,name:"sampling_rate"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.time_duration",description:`<strong>time_duration</strong> (<code>float</code>, <em>optional</em> defaults to 5.0) &#x2014;
Total seconds of sampling for audio data generation.`,name:"time_duration"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.frequency",description:`<strong>frequency</strong> (<code>int</code>, <em>optional</em> defaults to 220) &#x2014;
The desired natural frequency of generated audio.`,name:"frequency"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/onnx/config.py#L279",returnDescription:`
<p>Mapping[str, Tensor] holding the kwargs to provide to the model\u2019s forward function</p>
`}}),pe=new b({props:{name:"generate_dummy_inputs_onnxruntime",anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs_onnxruntime",parameters:[{name:"reference_model_inputs",val:": typing.Mapping[str, typing.Any]"}],parametersDescription:[{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs_onnxruntime.reference_model_inputs",description:`<strong>reference_model_inputs</strong> ([<code>Mapping[str, Tensor]</code>) &#x2014;
Reference inputs for the model.`,name:"reference_model_inputs"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/onnx/config.py#L388",returnDescription:`
<p>The mapping holding the kwargs to provide to the model\u2019s forward function</p>
`,returnType:`
<p><code>Mapping[str, Tensor]</code></p>
`}}),ce=new b({props:{name:"use_external_data_format",anchor:"transformers.onnx.OnnxConfig.use_external_data_format",parameters:[{name:"num_parameters",val:": int"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/onnx/config.py#L240",returnDescription:`
<p>True if model.num_parameters() * size_of(float32) >= 2Gb False otherwise</p>
`}}),he=new qe({}),ge=new b({props:{name:"class transformers.onnx.OnnxConfigWithPast",anchor:"transformers.onnx.OnnxConfigWithPast",parameters:[{name:"config",val:": PretrainedConfig"},{name:"task",val:": str = 'default'"},{name:"patching_specs",val:": typing.List[transformers.onnx.config.PatchingSpec] = None"},{name:"use_past",val:": bool = False"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/onnx/config.py#L431"}}),ue=new b({props:{name:"fill_with_past_key_values_",anchor:"transformers.onnx.OnnxConfigWithPast.fill_with_past_key_values_",parameters:[{name:"inputs_or_outputs",val:": typing.Mapping[str, typing.Mapping[int, str]]"},{name:"direction",val:": str"},{name:"inverted_values_shape",val:": bool = False"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/onnx/config.py#L538"}}),_e=new b({props:{name:"with_past",anchor:"transformers.onnx.OnnxConfigWithPast.with_past",parameters:[{name:"config",val:": PretrainedConfig"},{name:"task",val:": str = 'default'"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/onnx/config.py#L442",returnDescription:`
<p>OnnxConfig with <code>.use_past = True</code></p>
`}}),xe=new qe({}),be=new b({props:{name:"class transformers.onnx.OnnxSeq2SeqConfigWithPast",anchor:"transformers.onnx.OnnxSeq2SeqConfigWithPast",parameters:[{name:"config",val:": PretrainedConfig"},{name:"task",val:": str = 'default'"},{name:"patching_specs",val:": typing.List[transformers.onnx.config.PatchingSpec] = None"},{name:"use_past",val:": bool = False"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/onnx/config.py#L578"}}),ye=new qe({}),we=new qe({}),Oe=new b({props:{name:"class transformers.onnx.FeaturesManager",anchor:"transformers.onnx.FeaturesManager",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/onnx/features.py#L85"}}),Ee=new b({props:{name:"check_supported_model_or_raise",anchor:"transformers.onnx.FeaturesManager.check_supported_model_or_raise",parameters:[{name:"model",val:": typing.Union[ForwardRef('PreTrainedModel'), ForwardRef('TFPreTrainedModel')]"},{name:"feature",val:": str = 'default'"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/onnx/features.py#L688",returnDescription:`
<p>(str) The type of the model (OnnxConfig) The OnnxConfig instance holding the model export properties.</p>
`}}),ke=new b({props:{name:"determine_framework",anchor:"transformers.onnx.FeaturesManager.determine_framework",parameters:[{name:"model",val:": str"},{name:"framework",val:": str = None"}],parametersDescription:[{anchor:"transformers.onnx.FeaturesManager.determine_framework.model",description:`<strong>model</strong> (<code>str</code>) &#x2014;
The name of the model to export.`,name:"model"},{anchor:"transformers.onnx.FeaturesManager.determine_framework.framework",description:`<strong>framework</strong> (<code>str</code>, <em>optional</em>, defaults to <code>None</code>) &#x2014;
The framework to use for the export. See above for priority if none provided.`,name:"framework"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/onnx/features.py#L605",returnDescription:`
<p>The framework to use for the export.</p>
`}}),Pe=new b({props:{name:"get_config",anchor:"transformers.onnx.FeaturesManager.get_config",parameters:[{name:"model_type",val:": str"},{name:"feature",val:": str"}],parametersDescription:[{anchor:"transformers.onnx.FeaturesManager.get_config.model_type",description:`<strong>model_type</strong> (<code>str</code>) &#x2014;
The model type to retrieve the config for.`,name:"model_type"},{anchor:"transformers.onnx.FeaturesManager.get_config.feature",description:`<strong>feature</strong> (<code>str</code>) &#x2014;
The feature to retrieve the config for.`,name:"feature"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/onnx/features.py#L713",returnDescription:`
<p>config for the combination</p>
`,returnType:`
<p><code>OnnxConfig</code></p>
`}}),Ne=new b({props:{name:"get_model_class_for_feature",anchor:"transformers.onnx.FeaturesManager.get_model_class_for_feature",parameters:[{name:"feature",val:": str"},{name:"framework",val:": str = 'pt'"}],parametersDescription:[{anchor:"transformers.onnx.FeaturesManager.get_model_class_for_feature.feature",description:`<strong>feature</strong> (<code>str</code>) &#x2014;
The feature required.`,name:"feature"},{anchor:"transformers.onnx.FeaturesManager.get_model_class_for_feature.framework",description:`<strong>framework</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;pt&quot;</code>) &#x2014;
The framework to use for the export.`,name:"framework"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/onnx/features.py#L578",returnDescription:`
<p>The AutoModel class corresponding to the feature.</p>
`}}),Te=new b({props:{name:"get_model_from_feature",anchor:"transformers.onnx.FeaturesManager.get_model_from_feature",parameters:[{name:"feature",val:": str"},{name:"model",val:": str"},{name:"framework",val:": str = None"},{name:"cache_dir",val:": str = None"}],parametersDescription:[{anchor:"transformers.onnx.FeaturesManager.get_model_from_feature.feature",description:`<strong>feature</strong> (<code>str</code>) &#x2014;
The feature required.`,name:"feature"},{anchor:"transformers.onnx.FeaturesManager.get_model_from_feature.model",description:`<strong>model</strong> (<code>str</code>) &#x2014;
The name of the model to export.`,name:"model"},{anchor:"transformers.onnx.FeaturesManager.get_model_from_feature.framework",description:`<strong>framework</strong> (<code>str</code>, <em>optional</em>, defaults to <code>None</code>) &#x2014;
The framework to use for the export. See <code>FeaturesManager.determine_framework</code> for the priority should
none be provided.`,name:"framework"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/onnx/features.py#L655",returnDescription:`
<p>The instance of the model.</p>
`}}),Fe=new b({props:{name:"get_supported_features_for_model_type",anchor:"transformers.onnx.FeaturesManager.get_supported_features_for_model_type",parameters:[{name:"model_type",val:": str"},{name:"model_name",val:": typing.Optional[str] = None"}],parametersDescription:[{anchor:"transformers.onnx.FeaturesManager.get_supported_features_for_model_type.model_type",description:`<strong>model_type</strong> (<code>str</code>) &#x2014;
The model type to retrieve the supported features for.`,name:"model_type"},{anchor:"transformers.onnx.FeaturesManager.get_supported_features_for_model_type.model_name",description:`<strong>model_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The name attribute of the model object, only used for the exception message.`,name:"model_name"}],source:"https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/onnx/features.py#L533",returnDescription:`
<p>The dictionary mapping each feature to a corresponding OnnxConfig constructor.</p>
`}}),{c(){C=n("meta"),Or=s(),P=n("h1"),A=n("a"),Re=n("span"),c(ae.$$.fragment),dt=s(),He=n("span"),pt=f("Exporting \u{1F917} Transformers models to ONNX"),Er=s(),I=n("p"),ct=f("\u{1F917} Transformers provides a "),Ue=n("code"),ht=f("transformers.onnx"),gt=f(` package that enables you to
convert model checkpoints to an ONNX graph by leveraging configuration objects.`),kr=s(),L=n("p"),ut=f("See the "),Se=n("a"),_t=f("guide"),vt=f(` on exporting \u{1F917} Transformers models for more
details.`),Cr=s(),N=n("h2"),W=n("a"),Be=n("span"),c(se.$$.fragment),xt=s(),je=n("span"),$t=f("ONNX Configurations"),Pr=s(),De=n("p"),bt=f(`We provide three abstract classes that you should inherit from, depending on the
type of model architecture you wish to export:`),Nr=s(),k=n("ul"),Me=n("li"),yt=f("Encoder-based models inherit from "),Ae=n("a"),wt=f("OnnxConfig"),Ot=s(),Ie=n("li"),Et=f("Decoder-based models inherit from "),Le=n("a"),kt=f("OnnxConfigWithPast"),Ct=s(),We=n("li"),Pt=f("Encoder-decoder models inherit from "),Xe=n("a"),Nt=f("OnnxSeq2SeqConfigWithPast"),Tr=s(),T=n("h3"),X=n("a"),Je=n("span"),c(ie.$$.fragment),Tt=s(),Ke=n("span"),Ft=f("OnnxConfig"),Fr=s(),x=n("div"),c(le.$$.fragment),qt=s(),Qe=n("p"),St=f("Base class for ONNX exportable model describing metadata on how to export the model through the ONNX format."),Dt=s(),V=n("div"),c(fe.$$.fragment),Mt=s(),Ye=n("p"),At=f(`Flatten any potential nested structure expanding the name of the field with the index of the element within the
structure.`),It=s(),z=n("div"),c(me.$$.fragment),Lt=s(),Ze=n("p"),Wt=f("Instantiate a OnnxConfig for a specific model"),Xt=s(),G=n("div"),c(de.$$.fragment),Vt=s(),er=n("p"),zt=f("Generate inputs to provide to the ONNX exporter for the specific framework"),Gt=s(),R=n("div"),c(pe.$$.fragment),Rt=s(),rr=n("p"),Ht=f(`Generate inputs for ONNX Runtime using the reference model inputs. Override this to run inference with seq2seq
models which have the encoder and decoder exported as separate ONNX files.`),Ut=s(),H=n("div"),c(ce.$$.fragment),Bt=s(),tr=n("p"),jt=f("Flag indicating if the model requires using external data format"),qr=s(),F=n("h3"),U=n("a"),nr=n("span"),c(he.$$.fragment),Jt=s(),or=n("span"),Kt=f("OnnxConfigWithPast"),Sr=s(),E=n("div"),c(ge.$$.fragment),Qt=s(),B=n("div"),c(ue.$$.fragment),Yt=s(),ar=n("p"),Zt=f("Fill the input_or_outputs mapping with past_key_values dynamic axes considering."),en=s(),j=n("div"),c(_e.$$.fragment),rn=s(),ve=n("p"),tn=f("Instantiate a OnnxConfig with "),sr=n("code"),nn=f("use_past"),on=f(" attribute set to True"),Dr=s(),q=n("h3"),J=n("a"),ir=n("span"),c(xe.$$.fragment),an=s(),lr=n("span"),sn=f("OnnxSeq2SeqConfigWithPast"),Mr=s(),$e=n("div"),c(be.$$.fragment),Ar=s(),S=n("h2"),K=n("a"),fr=n("span"),c(ye.$$.fragment),ln=s(),mr=n("span"),fn=f("ONNX Features"),Ir=s(),Q=n("p"),mn=f("Each ONNX configuration is associated with a set of "),dr=n("em"),dn=f("features"),pn=f(` that enable you
to export models for different types of topologies or tasks.`),Lr=s(),D=n("h3"),Y=n("a"),pr=n("span"),c(we.$$.fragment),cn=s(),cr=n("span"),hn=f("FeaturesManager"),Wr=s(),$=n("div"),c(Oe.$$.fragment),gn=s(),Z=n("div"),c(Ee.$$.fragment),un=s(),hr=n("p"),_n=f("Check whether or not the model has the requested features."),vn=s(),O=n("div"),c(ke.$$.fragment),xn=s(),gr=n("p"),$n=f("Determines the framework to use for the export."),bn=s(),ur=n("p"),yn=f("The priority is in the following order:"),wn=s(),M=n("ol"),Ce=n("li"),On=f("User input via "),_r=n("code"),En=f("framework"),kn=f("."),Cn=s(),vr=n("li"),Pn=f("If local checkpoint is provided, use the same framework as the checkpoint."),Nn=s(),xr=n("li"),Tn=f("Available framework in environment, with priority given to PyTorch"),Fn=s(),ee=n("div"),c(Pe.$$.fragment),qn=s(),$r=n("p"),Sn=f("Gets the OnnxConfig for a model_type and feature combination."),Dn=s(),re=n("div"),c(Ne.$$.fragment),Mn=s(),br=n("p"),An=f("Attempts to retrieve an AutoModel class from a feature name."),In=s(),te=n("div"),c(Te.$$.fragment),Ln=s(),yr=n("p"),Wn=f("Attempts to retrieve a model from a model\u2019s name and the feature to be enabled."),Xn=s(),ne=n("div"),c(Fe.$$.fragment),Vn=s(),wr=n("p"),zn=f("Tries to retrieve the feature -> OnnxConfig constructor map from the model type."),this.h()},l(r){const d=Ro('[data-svelte="svelte-1phssyn"]',document.head);C=o(d,"META",{name:!0,content:!0}),d.forEach(t),Or=i(r),P=o(r,"H1",{class:!0});var Vr=a(P);A=o(Vr,"A",{id:!0,class:!0,href:!0});var Bn=a(A);Re=o(Bn,"SPAN",{});var jn=a(Re);h(ae.$$.fragment,jn),jn.forEach(t),Bn.forEach(t),dt=i(Vr),He=o(Vr,"SPAN",{});var Jn=a(He);pt=m(Jn,"Exporting \u{1F917} Transformers models to ONNX"),Jn.forEach(t),Vr.forEach(t),Er=i(r),I=o(r,"P",{});var zr=a(I);ct=m(zr,"\u{1F917} Transformers provides a "),Ue=o(zr,"CODE",{});var Kn=a(Ue);ht=m(Kn,"transformers.onnx"),Kn.forEach(t),gt=m(zr,` package that enables you to
convert model checkpoints to an ONNX graph by leveraging configuration objects.`),zr.forEach(t),kr=i(r),L=o(r,"P",{});var Gr=a(L);ut=m(Gr,"See the "),Se=o(Gr,"A",{href:!0});var Qn=a(Se);_t=m(Qn,"guide"),Qn.forEach(t),vt=m(Gr,` on exporting \u{1F917} Transformers models for more
details.`),Gr.forEach(t),Cr=i(r),N=o(r,"H2",{class:!0});var Rr=a(N);W=o(Rr,"A",{id:!0,class:!0,href:!0});var Yn=a(W);Be=o(Yn,"SPAN",{});var Zn=a(Be);h(se.$$.fragment,Zn),Zn.forEach(t),Yn.forEach(t),xt=i(Rr),je=o(Rr,"SPAN",{});var eo=a(je);$t=m(eo,"ONNX Configurations"),eo.forEach(t),Rr.forEach(t),Pr=i(r),De=o(r,"P",{});var ro=a(De);bt=m(ro,`We provide three abstract classes that you should inherit from, depending on the
type of model architecture you wish to export:`),ro.forEach(t),Nr=i(r),k=o(r,"UL",{});var Ve=a(k);Me=o(Ve,"LI",{});var Gn=a(Me);yt=m(Gn,"Encoder-based models inherit from "),Ae=o(Gn,"A",{href:!0});var to=a(Ae);wt=m(to,"OnnxConfig"),to.forEach(t),Gn.forEach(t),Ot=i(Ve),Ie=o(Ve,"LI",{});var Rn=a(Ie);Et=m(Rn,"Decoder-based models inherit from "),Le=o(Rn,"A",{href:!0});var no=a(Le);kt=m(no,"OnnxConfigWithPast"),no.forEach(t),Rn.forEach(t),Ct=i(Ve),We=o(Ve,"LI",{});var Hn=a(We);Pt=m(Hn,"Encoder-decoder models inherit from "),Xe=o(Hn,"A",{href:!0});var oo=a(Xe);Nt=m(oo,"OnnxSeq2SeqConfigWithPast"),oo.forEach(t),Hn.forEach(t),Ve.forEach(t),Tr=i(r),T=o(r,"H3",{class:!0});var Hr=a(T);X=o(Hr,"A",{id:!0,class:!0,href:!0});var ao=a(X);Je=o(ao,"SPAN",{});var so=a(Je);h(ie.$$.fragment,so),so.forEach(t),ao.forEach(t),Tt=i(Hr),Ke=o(Hr,"SPAN",{});var io=a(Ke);Ft=m(io,"OnnxConfig"),io.forEach(t),Hr.forEach(t),Fr=i(r),x=o(r,"DIV",{class:!0});var y=a(x);h(le.$$.fragment,y),qt=i(y),Qe=o(y,"P",{});var lo=a(Qe);St=m(lo,"Base class for ONNX exportable model describing metadata on how to export the model through the ONNX format."),lo.forEach(t),Dt=i(y),V=o(y,"DIV",{class:!0});var Ur=a(V);h(fe.$$.fragment,Ur),Mt=i(Ur),Ye=o(Ur,"P",{});var fo=a(Ye);At=m(fo,`Flatten any potential nested structure expanding the name of the field with the index of the element within the
structure.`),fo.forEach(t),Ur.forEach(t),It=i(y),z=o(y,"DIV",{class:!0});var Br=a(z);h(me.$$.fragment,Br),Lt=i(Br),Ze=o(Br,"P",{});var mo=a(Ze);Wt=m(mo,"Instantiate a OnnxConfig for a specific model"),mo.forEach(t),Br.forEach(t),Xt=i(y),G=o(y,"DIV",{class:!0});var jr=a(G);h(de.$$.fragment,jr),Vt=i(jr),er=o(jr,"P",{});var po=a(er);zt=m(po,"Generate inputs to provide to the ONNX exporter for the specific framework"),po.forEach(t),jr.forEach(t),Gt=i(y),R=o(y,"DIV",{class:!0});var Jr=a(R);h(pe.$$.fragment,Jr),Rt=i(Jr),rr=o(Jr,"P",{});var co=a(rr);Ht=m(co,`Generate inputs for ONNX Runtime using the reference model inputs. Override this to run inference with seq2seq
models which have the encoder and decoder exported as separate ONNX files.`),co.forEach(t),Jr.forEach(t),Ut=i(y),H=o(y,"DIV",{class:!0});var Kr=a(H);h(ce.$$.fragment,Kr),Bt=i(Kr),tr=o(Kr,"P",{});var ho=a(tr);jt=m(ho,"Flag indicating if the model requires using external data format"),ho.forEach(t),Kr.forEach(t),y.forEach(t),qr=i(r),F=o(r,"H3",{class:!0});var Qr=a(F);U=o(Qr,"A",{id:!0,class:!0,href:!0});var go=a(U);nr=o(go,"SPAN",{});var uo=a(nr);h(he.$$.fragment,uo),uo.forEach(t),go.forEach(t),Jt=i(Qr),or=o(Qr,"SPAN",{});var _o=a(or);Kt=m(_o,"OnnxConfigWithPast"),_o.forEach(t),Qr.forEach(t),Sr=i(r),E=o(r,"DIV",{class:!0});var ze=a(E);h(ge.$$.fragment,ze),Qt=i(ze),B=o(ze,"DIV",{class:!0});var Yr=a(B);h(ue.$$.fragment,Yr),Yt=i(Yr),ar=o(Yr,"P",{});var vo=a(ar);Zt=m(vo,"Fill the input_or_outputs mapping with past_key_values dynamic axes considering."),vo.forEach(t),Yr.forEach(t),en=i(ze),j=o(ze,"DIV",{class:!0});var Zr=a(j);h(_e.$$.fragment,Zr),rn=i(Zr),ve=o(Zr,"P",{});var et=a(ve);tn=m(et,"Instantiate a OnnxConfig with "),sr=o(et,"CODE",{});var xo=a(sr);nn=m(xo,"use_past"),xo.forEach(t),on=m(et," attribute set to True"),et.forEach(t),Zr.forEach(t),ze.forEach(t),Dr=i(r),q=o(r,"H3",{class:!0});var rt=a(q);J=o(rt,"A",{id:!0,class:!0,href:!0});var $o=a(J);ir=o($o,"SPAN",{});var bo=a(ir);h(xe.$$.fragment,bo),bo.forEach(t),$o.forEach(t),an=i(rt),lr=o(rt,"SPAN",{});var yo=a(lr);sn=m(yo,"OnnxSeq2SeqConfigWithPast"),yo.forEach(t),rt.forEach(t),Mr=i(r),$e=o(r,"DIV",{class:!0});var wo=a($e);h(be.$$.fragment,wo),wo.forEach(t),Ar=i(r),S=o(r,"H2",{class:!0});var tt=a(S);K=o(tt,"A",{id:!0,class:!0,href:!0});var Oo=a(K);fr=o(Oo,"SPAN",{});var Eo=a(fr);h(ye.$$.fragment,Eo),Eo.forEach(t),Oo.forEach(t),ln=i(tt),mr=o(tt,"SPAN",{});var ko=a(mr);fn=m(ko,"ONNX Features"),ko.forEach(t),tt.forEach(t),Ir=i(r),Q=o(r,"P",{});var nt=a(Q);mn=m(nt,"Each ONNX configuration is associated with a set of "),dr=o(nt,"EM",{});var Co=a(dr);dn=m(Co,"features"),Co.forEach(t),pn=m(nt,` that enable you
to export models for different types of topologies or tasks.`),nt.forEach(t),Lr=i(r),D=o(r,"H3",{class:!0});var ot=a(D);Y=o(ot,"A",{id:!0,class:!0,href:!0});var Po=a(Y);pr=o(Po,"SPAN",{});var No=a(pr);h(we.$$.fragment,No),No.forEach(t),Po.forEach(t),cn=i(ot),cr=o(ot,"SPAN",{});var To=a(cr);hn=m(To,"FeaturesManager"),To.forEach(t),ot.forEach(t),Wr=i(r),$=o(r,"DIV",{class:!0});var w=a($);h(Oe.$$.fragment,w),gn=i(w),Z=o(w,"DIV",{class:!0});var at=a(Z);h(Ee.$$.fragment,at),un=i(at),hr=o(at,"P",{});var Fo=a(hr);_n=m(Fo,"Check whether or not the model has the requested features."),Fo.forEach(t),at.forEach(t),vn=i(w),O=o(w,"DIV",{class:!0});var oe=a(O);h(ke.$$.fragment,oe),xn=i(oe),gr=o(oe,"P",{});var qo=a(gr);$n=m(qo,"Determines the framework to use for the export."),qo.forEach(t),bn=i(oe),ur=o(oe,"P",{});var So=a(ur);yn=m(So,"The priority is in the following order:"),So.forEach(t),wn=i(oe),M=o(oe,"OL",{});var Ge=a(M);Ce=o(Ge,"LI",{});var st=a(Ce);On=m(st,"User input via "),_r=o(st,"CODE",{});var Do=a(_r);En=m(Do,"framework"),Do.forEach(t),kn=m(st,"."),st.forEach(t),Cn=i(Ge),vr=o(Ge,"LI",{});var Mo=a(vr);Pn=m(Mo,"If local checkpoint is provided, use the same framework as the checkpoint."),Mo.forEach(t),Nn=i(Ge),xr=o(Ge,"LI",{});var Ao=a(xr);Tn=m(Ao,"Available framework in environment, with priority given to PyTorch"),Ao.forEach(t),Ge.forEach(t),oe.forEach(t),Fn=i(w),ee=o(w,"DIV",{class:!0});var it=a(ee);h(Pe.$$.fragment,it),qn=i(it),$r=o(it,"P",{});var Io=a($r);Sn=m(Io,"Gets the OnnxConfig for a model_type and feature combination."),Io.forEach(t),it.forEach(t),Dn=i(w),re=o(w,"DIV",{class:!0});var lt=a(re);h(Ne.$$.fragment,lt),Mn=i(lt),br=o(lt,"P",{});var Lo=a(br);An=m(Lo,"Attempts to retrieve an AutoModel class from a feature name."),Lo.forEach(t),lt.forEach(t),In=i(w),te=o(w,"DIV",{class:!0});var ft=a(te);h(Te.$$.fragment,ft),Ln=i(ft),yr=o(ft,"P",{});var Wo=a(yr);Wn=m(Wo,"Attempts to retrieve a model from a model\u2019s name and the feature to be enabled."),Wo.forEach(t),ft.forEach(t),Xn=i(w),ne=o(w,"DIV",{class:!0});var mt=a(ne);h(Fe.$$.fragment,mt),Vn=i(mt),wr=o(mt,"P",{});var Xo=a(wr);zn=m(Xo,"Tries to retrieve the feature -> OnnxConfig constructor map from the model type."),Xo.forEach(t),mt.forEach(t),w.forEach(t),this.h()},h(){l(C,"name","hf:doc:metadata"),l(C,"content",JSON.stringify(jo)),l(A,"id","exporting-transformers-models-to-onnx"),l(A,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(A,"href","#exporting-transformers-models-to-onnx"),l(P,"class","relative group"),l(Se,"href","../serialization"),l(W,"id","onnx-configurations"),l(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(W,"href","#onnx-configurations"),l(N,"class","relative group"),l(Ae,"href","/docs/transformers/v4.24.0/en/main_classes/onnx#transformers.onnx.OnnxConfig"),l(Le,"href","/docs/transformers/v4.24.0/en/main_classes/onnx#transformers.onnx.OnnxConfigWithPast"),l(Xe,"href","/docs/transformers/v4.24.0/en/main_classes/onnx#transformers.onnx.OnnxSeq2SeqConfigWithPast"),l(X,"id","transformers.onnx.OnnxConfig"),l(X,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(X,"href","#transformers.onnx.OnnxConfig"),l(T,"class","relative group"),l(V,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(G,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(R,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(H,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(x,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(U,"id","transformers.onnx.OnnxConfigWithPast"),l(U,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(U,"href","#transformers.onnx.OnnxConfigWithPast"),l(F,"class","relative group"),l(B,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(j,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(E,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(J,"id","transformers.onnx.OnnxSeq2SeqConfigWithPast"),l(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(J,"href","#transformers.onnx.OnnxSeq2SeqConfigWithPast"),l(q,"class","relative group"),l($e,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(K,"id","onnx-features"),l(K,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(K,"href","#onnx-features"),l(S,"class","relative group"),l(Y,"id","transformers.onnx.FeaturesManager"),l(Y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(Y,"href","#transformers.onnx.FeaturesManager"),l(D,"class","relative group"),l(Z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(O,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(ee,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(re,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(te,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(ne,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l($,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(r,d){e(document.head,C),p(r,Or,d),p(r,P,d),e(P,A),e(A,Re),g(ae,Re,null),e(P,dt),e(P,He),e(He,pt),p(r,Er,d),p(r,I,d),e(I,ct),e(I,Ue),e(Ue,ht),e(I,gt),p(r,kr,d),p(r,L,d),e(L,ut),e(L,Se),e(Se,_t),e(L,vt),p(r,Cr,d),p(r,N,d),e(N,W),e(W,Be),g(se,Be,null),e(N,xt),e(N,je),e(je,$t),p(r,Pr,d),p(r,De,d),e(De,bt),p(r,Nr,d),p(r,k,d),e(k,Me),e(Me,yt),e(Me,Ae),e(Ae,wt),e(k,Ot),e(k,Ie),e(Ie,Et),e(Ie,Le),e(Le,kt),e(k,Ct),e(k,We),e(We,Pt),e(We,Xe),e(Xe,Nt),p(r,Tr,d),p(r,T,d),e(T,X),e(X,Je),g(ie,Je,null),e(T,Tt),e(T,Ke),e(Ke,Ft),p(r,Fr,d),p(r,x,d),g(le,x,null),e(x,qt),e(x,Qe),e(Qe,St),e(x,Dt),e(x,V),g(fe,V,null),e(V,Mt),e(V,Ye),e(Ye,At),e(x,It),e(x,z),g(me,z,null),e(z,Lt),e(z,Ze),e(Ze,Wt),e(x,Xt),e(x,G),g(de,G,null),e(G,Vt),e(G,er),e(er,zt),e(x,Gt),e(x,R),g(pe,R,null),e(R,Rt),e(R,rr),e(rr,Ht),e(x,Ut),e(x,H),g(ce,H,null),e(H,Bt),e(H,tr),e(tr,jt),p(r,qr,d),p(r,F,d),e(F,U),e(U,nr),g(he,nr,null),e(F,Jt),e(F,or),e(or,Kt),p(r,Sr,d),p(r,E,d),g(ge,E,null),e(E,Qt),e(E,B),g(ue,B,null),e(B,Yt),e(B,ar),e(ar,Zt),e(E,en),e(E,j),g(_e,j,null),e(j,rn),e(j,ve),e(ve,tn),e(ve,sr),e(sr,nn),e(ve,on),p(r,Dr,d),p(r,q,d),e(q,J),e(J,ir),g(xe,ir,null),e(q,an),e(q,lr),e(lr,sn),p(r,Mr,d),p(r,$e,d),g(be,$e,null),p(r,Ar,d),p(r,S,d),e(S,K),e(K,fr),g(ye,fr,null),e(S,ln),e(S,mr),e(mr,fn),p(r,Ir,d),p(r,Q,d),e(Q,mn),e(Q,dr),e(dr,dn),e(Q,pn),p(r,Lr,d),p(r,D,d),e(D,Y),e(Y,pr),g(we,pr,null),e(D,cn),e(D,cr),e(cr,hn),p(r,Wr,d),p(r,$,d),g(Oe,$,null),e($,gn),e($,Z),g(Ee,Z,null),e(Z,un),e(Z,hr),e(hr,_n),e($,vn),e($,O),g(ke,O,null),e(O,xn),e(O,gr),e(gr,$n),e(O,bn),e(O,ur),e(ur,yn),e(O,wn),e(O,M),e(M,Ce),e(Ce,On),e(Ce,_r),e(_r,En),e(Ce,kn),e(M,Cn),e(M,vr),e(vr,Pn),e(M,Nn),e(M,xr),e(xr,Tn),e($,Fn),e($,ee),g(Pe,ee,null),e(ee,qn),e(ee,$r),e($r,Sn),e($,Dn),e($,re),g(Ne,re,null),e(re,Mn),e(re,br),e(br,An),e($,In),e($,te),g(Te,te,null),e(te,Ln),e(te,yr),e(yr,Wn),e($,Xn),e($,ne),g(Fe,ne,null),e(ne,Vn),e(ne,wr),e(wr,zn),Xr=!0},p:Ho,i(r){Xr||(u(ae.$$.fragment,r),u(se.$$.fragment,r),u(ie.$$.fragment,r),u(le.$$.fragment,r),u(fe.$$.fragment,r),u(me.$$.fragment,r),u(de.$$.fragment,r),u(pe.$$.fragment,r),u(ce.$$.fragment,r),u(he.$$.fragment,r),u(ge.$$.fragment,r),u(ue.$$.fragment,r),u(_e.$$.fragment,r),u(xe.$$.fragment,r),u(be.$$.fragment,r),u(ye.$$.fragment,r),u(we.$$.fragment,r),u(Oe.$$.fragment,r),u(Ee.$$.fragment,r),u(ke.$$.fragment,r),u(Pe.$$.fragment,r),u(Ne.$$.fragment,r),u(Te.$$.fragment,r),u(Fe.$$.fragment,r),Xr=!0)},o(r){_(ae.$$.fragment,r),_(se.$$.fragment,r),_(ie.$$.fragment,r),_(le.$$.fragment,r),_(fe.$$.fragment,r),_(me.$$.fragment,r),_(de.$$.fragment,r),_(pe.$$.fragment,r),_(ce.$$.fragment,r),_(he.$$.fragment,r),_(ge.$$.fragment,r),_(ue.$$.fragment,r),_(_e.$$.fragment,r),_(xe.$$.fragment,r),_(be.$$.fragment,r),_(ye.$$.fragment,r),_(we.$$.fragment,r),_(Oe.$$.fragment,r),_(Ee.$$.fragment,r),_(ke.$$.fragment,r),_(Pe.$$.fragment,r),_(Ne.$$.fragment,r),_(Te.$$.fragment,r),_(Fe.$$.fragment,r),Xr=!1},d(r){t(C),r&&t(Or),r&&t(P),v(ae),r&&t(Er),r&&t(I),r&&t(kr),r&&t(L),r&&t(Cr),r&&t(N),v(se),r&&t(Pr),r&&t(De),r&&t(Nr),r&&t(k),r&&t(Tr),r&&t(T),v(ie),r&&t(Fr),r&&t(x),v(le),v(fe),v(me),v(de),v(pe),v(ce),r&&t(qr),r&&t(F),v(he),r&&t(Sr),r&&t(E),v(ge),v(ue),v(_e),r&&t(Dr),r&&t(q),v(xe),r&&t(Mr),r&&t($e),v(be),r&&t(Ar),r&&t(S),v(ye),r&&t(Ir),r&&t(Q),r&&t(Lr),r&&t(D),v(we),r&&t(Wr),r&&t($),v(Oe),v(Ee),v(ke),v(Pe),v(Ne),v(Te),v(Fe)}}}const jo={local:"exporting-transformers-models-to-onnx",sections:[{local:"onnx-configurations",sections:[{local:"transformers.onnx.OnnxConfig",title:"OnnxConfig"},{local:"transformers.onnx.OnnxConfigWithPast",title:"OnnxConfigWithPast"},{local:"transformers.onnx.OnnxSeq2SeqConfigWithPast",title:"OnnxSeq2SeqConfigWithPast"}],title:"ONNX Configurations"},{local:"onnx-features",sections:[{local:"transformers.onnx.FeaturesManager",title:"FeaturesManager"}],title:"ONNX Features"}],title:"Exporting \u{1F917} Transformers models to ONNX"};function Jo(Un){return Uo(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Zo extends Vo{constructor(C){super();zo(this,C,Jo,Bo,Go,{})}}export{Zo as default,jo as metadata};
