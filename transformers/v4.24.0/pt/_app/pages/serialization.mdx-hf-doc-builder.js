import{S as $v,i as Ov,s as bv,e as r,k as d,w as g,t,M as qv,c as n,d as a,m as p,a as l,x,h as s,b as _,G as e,g as m,y as $,q as O,o as b,B as q,v as jv}from"../chunks/vendor-hf-doc-builder.js";import{T as va}from"../chunks/Tip-hf-doc-builder.js";import{I as lo}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as z}from"../chunks/CodeBlock-hf-doc-builder.js";function Nv(B){let f,D,h,j,T;return{c(){f=r("p"),D=t(`Uma vez exportado, um modelo pode ser otimizado para infer\xEAncia por meio de t\xE9cnicas como
quantiza\xE7\xE3o e poda. Se voc\xEA estiver interessado em otimizar seus modelos para serem executados com
m\xE1xima efici\xEAncia, confira a biblioteca `),h=r("a"),j=t(`\u{1F917} Optimum
`),T=t("."),this.h()},l(v){f=n(v,"P",{});var E=l(f);D=s(E,`Uma vez exportado, um modelo pode ser otimizado para infer\xEAncia por meio de t\xE9cnicas como
quantiza\xE7\xE3o e poda. Se voc\xEA estiver interessado em otimizar seus modelos para serem executados com
m\xE1xima efici\xEAncia, confira a biblioteca `),h=n(E,"A",{href:!0,rel:!0});var C=l(h);j=s(C,`\u{1F917} Optimum
`),C.forEach(a),T=s(E,"."),E.forEach(a),this.h()},h(){_(h,"href","https://github.com/huggingface/optimum"),_(h,"rel","nofollow")},m(v,E){m(v,f,E),e(f,D),e(f,h),e(h,j),e(f,T)},d(v){v&&a(f)}}}function kv(B){let f,D,h,j,T,v,E,C;return{c(){f=r("p"),D=t("Os recursos que t\xEAm um sufixo "),h=r("code"),j=t("with-pass"),T=t(" (como "),v=r("code"),E=t("causal-lm-with-pass"),C=t(`) correspondem a
classes de modelo com estados ocultos pr\xE9-computados (chave e valores nos blocos de aten\xE7\xE3o)
que pode ser usado para decodifica\xE7\xE3o autorregressiva r\xE1pida.`)},l(N){f=n(N,"P",{});var k=l(f);D=s(k,"Os recursos que t\xEAm um sufixo "),h=n(k,"CODE",{});var A=l(h);j=s(A,"with-pass"),A.forEach(a),T=s(k," (como "),v=n(k,"CODE",{});var P=l(v);E=s(P,"causal-lm-with-pass"),P.forEach(a),C=s(k,`) correspondem a
classes de modelo com estados ocultos pr\xE9-computados (chave e valores nos blocos de aten\xE7\xE3o)
que pode ser usado para decodifica\xE7\xE3o autorregressiva r\xE1pida.`),k.forEach(a)},m(N,k){m(N,f,k),e(f,D),e(f,h),e(h,j),e(f,T),e(f,v),e(v,E),e(f,C)},d(N){N&&a(f)}}}function Tv(B){let f,D,h,j,T,v,E,C,N,k,A;return{c(){f=r("p"),D=t("Para modelos do tipo "),h=r("code"),j=t("VisionEncoderDecoder"),T=t(`, as partes do codificador e do decodificador s\xE3o
exportados separadamente como dois arquivos ONNX chamados `),v=r("code"),E=t("encoder_model.onnx"),C=t(" e "),N=r("code"),k=t("decoder_model.onnx"),A=t(" respectivamente.")},l(P){f=n(P,"P",{});var w=l(f);D=s(w,"Para modelos do tipo "),h=n(w,"CODE",{});var U=l(h);j=s(U,"VisionEncoderDecoder"),U.forEach(a),T=s(w,`, as partes do codificador e do decodificador s\xE3o
exportados separadamente como dois arquivos ONNX chamados `),v=n(w,"CODE",{});var S=l(v);E=s(S,"encoder_model.onnx"),S.forEach(a),C=s(w," e "),N=n(w,"CODE",{});var F=l(N);k=s(F,"decoder_model.onnx"),F.forEach(a),A=s(w," respectivamente."),w.forEach(a)},m(P,w){m(P,f,w),e(f,D),e(f,h),e(h,j),e(f,T),e(f,v),e(v,E),e(f,C),e(f,N),e(N,k),e(f,A)},d(P){P&&a(f)}}}function wv(B){let f,D,h,j,T;return{c(){f=r("p"),D=t(`Uma boa maneira de implementar uma configura\xE7\xE3o ONNX personalizada \xE9 observar as
implementa\xE7\xE3o no arquivo `),h=r("code"),j=t("configuration_<model_name>.py"),T=t(" de uma arquitetura semelhante.")},l(v){f=n(v,"P",{});var E=l(f);D=s(E,`Uma boa maneira de implementar uma configura\xE7\xE3o ONNX personalizada \xE9 observar as
implementa\xE7\xE3o no arquivo `),h=n(E,"CODE",{});var C=l(h);j=s(C,"configuration_<model_name>.py"),C.forEach(a),T=s(E," de uma arquitetura semelhante."),E.forEach(a)},m(v,E){m(v,f,E),e(f,D),e(f,h),e(h,j),e(f,T)},d(v){v&&a(f)}}}function Dv(B){let f,D,h,j,T,v,E,C,N,k,A,P,w,U,S,F,W,re,K,io,oe,po,mo,xe,L,co,ne,Q,uo,J,$e,fo,Oe,Ce,le,be,Pe,c,ae,ho,vo,te,_o,Eo,se,go,xo;return{c(){f=r("p"),D=t("Notice that "),h=r("code"),j=t("inputs"),T=t(" property for "),v=r("code"),E=t("DistilBertOnnxConfig"),C=t(" returns an "),N=r("code"),k=t("OrderedDict"),A=t(`. This
ensures that the inputs are matched with their relative position within the
`),P=r("code"),w=t("PreTrainedModel.forward()"),U=t(` method when tracing the graph. We recommend using an
`),S=r("code"),F=t("OrderedDict"),W=t(" for the "),re=r("code"),K=t("inputs"),io=t(" and "),oe=r("code"),po=t("outputs"),mo=t(` properties when implementing custom ONNX
configurations.`),xe=d(),L=r("p"),co=t("Observe que a propriedade "),ne=r("code"),Q=t("inputs"),uo=t(" para "),J=r("code"),$e=t("DistilBertOnnxConfig"),fo=t(" retorna um "),Oe=r("code"),Ce=t("OrderedDict"),le=t(`. Este
garante que as entradas sejam combinadas com sua posi\xE7\xE3o relativa dentro do
m\xE9todo `),be=r("code"),Pe=t("PreTrainedModel.forward()"),c=t(` ao tra\xE7ar o grafo. Recomendamos o uso de um
`),ae=r("code"),ho=t("OrderedDict"),vo=t(" para as propriedades "),te=r("code"),_o=t("inputs"),Eo=t(" e "),se=r("code"),go=t("outputs"),xo=t(" ao implementar configura\xE7\xF5es personalizadas ONNX.")},l(M){f=n(M,"P",{});var y=l(f);D=s(y,"Notice that "),h=n(y,"CODE",{});var _a=l(h);j=s(_a,"inputs"),_a.forEach(a),T=s(y," property for "),v=n(y,"CODE",{});var Le=l(v);E=s(Le,"DistilBertOnnxConfig"),Le.forEach(a),C=s(y," returns an "),N=n(y,"CODE",{});var Ea=l(N);k=s(Ea,"OrderedDict"),Ea.forEach(a),A=s(y,`. This
ensures that the inputs are matched with their relative position within the
`),P=n(y,"CODE",{});var ga=l(P);w=s(ga,"PreTrainedModel.forward()"),ga.forEach(a),U=s(y,` method when tracing the graph. We recommend using an
`),S=n(y,"CODE",{});var Ae=l(S);F=s(Ae,"OrderedDict"),Ae.forEach(a),W=s(y," for the "),re=n(y,"CODE",{});var xa=l(re);K=s(xa,"inputs"),xa.forEach(a),io=s(y," and "),oe=n(y,"CODE",{});var $a=l(oe);po=s($a,"outputs"),$a.forEach(a),mo=s(y,` properties when implementing custom ONNX
configurations.`),y.forEach(a),xe=p(M),L=n(M,"P",{});var I=l(L);co=s(I,"Observe que a propriedade "),ne=n(I,"CODE",{});var Oa=l(ne);Q=s(Oa,"inputs"),Oa.forEach(a),uo=s(I," para "),J=n(I,"CODE",{});var ba=l(J);$e=s(ba,"DistilBertOnnxConfig"),ba.forEach(a),fo=s(I," retorna um "),Oe=n(I,"CODE",{});var ye=l(Oe);Ce=s(ye,"OrderedDict"),ye.forEach(a),le=s(I,`. Este
garante que as entradas sejam combinadas com sua posi\xE7\xE3o relativa dentro do
m\xE9todo `),be=n(I,"CODE",{});var qa=l(be);Pe=s(qa,"PreTrainedModel.forward()"),qa.forEach(a),c=s(I,` ao tra\xE7ar o grafo. Recomendamos o uso de um
`),ae=n(I,"CODE",{});var ja=l(ae);ho=s(ja,"OrderedDict"),ja.forEach(a),vo=s(I," para as propriedades "),te=n(I,"CODE",{});var Ie=l(te);_o=s(Ie,"inputs"),Ie.forEach(a),Eo=s(I," e "),se=n(I,"CODE",{});var Na=l(se);go=s(Na,"outputs"),Na.forEach(a),xo=s(I," ao implementar configura\xE7\xF5es personalizadas ONNX."),I.forEach(a)},m(M,y){m(M,f,y),e(f,D),e(f,h),e(h,j),e(f,T),e(f,v),e(v,E),e(f,C),e(f,N),e(N,k),e(f,A),e(f,P),e(P,w),e(f,U),e(f,S),e(S,F),e(f,W),e(f,re),e(re,K),e(f,io),e(f,oe),e(oe,po),e(f,mo),m(M,xe,y),m(M,L,y),e(L,co),e(L,ne),e(ne,Q),e(L,uo),e(L,J),e(J,$e),e(L,fo),e(L,Oe),e(Oe,Ce),e(L,le),e(L,be),e(be,Pe),e(L,c),e(L,ae),e(ae,ho),e(L,vo),e(L,te),e(te,_o),e(L,Eo),e(L,se),e(se,go),e(L,xo)},d(M){M&&a(f),M&&a(xe),M&&a(L)}}}function Cv(B){let f,D,h,j,T,v,E,C;return{c(){f=r("p"),D=t("Todas as propriedades e m\xE9todos b\xE1sicos associados a "),h=r("code"),j=t("OnnxConfig"),T=t(` e
as outras classes de configura\xE7\xE3o podem ser substitu\xEDdas se necess\xE1rio. Confira `),v=r("code"),E=t("BartOnnxConfig"),C=t(`
para um exemplo avan\xE7ado.`)},l(N){f=n(N,"P",{});var k=l(f);D=s(k,"Todas as propriedades e m\xE9todos b\xE1sicos associados a "),h=n(k,"CODE",{});var A=l(h);j=s(A,"OnnxConfig"),A.forEach(a),T=s(k,` e
as outras classes de configura\xE7\xE3o podem ser substitu\xEDdas se necess\xE1rio. Confira `),v=n(k,"CODE",{});var P=l(v);E=s(P,"BartOnnxConfig"),P.forEach(a),C=s(k,`
para um exemplo avan\xE7ado.`),k.forEach(a)},m(N,k){m(N,f,k),e(f,D),e(f,h),e(h,j),e(f,T),e(f,v),e(v,E),e(f,C)},d(N){N&&a(f)}}}function Pv(B){let f,D,h,j,T,v,E,C,N,k,A;return{c(){f=r("p"),D=t(`Se o seu modelo for maior que 2GB, voc\xEA ver\xE1 que muitos arquivos adicionais s\xE3o criados
durante a exporta\xE7\xE3o. Isso \xE9 `),h=r("em"),j=t("esperado"),T=t(" porque o ONNX usa "),v=r("a"),E=t(`Protocol
Buffers`),C=t(` para armazenar o modelo e estes
t\xEAm um limite de tamanho de 2GB. Veja a `),N=r("a"),k=t(`ONNX
documenta\xE7\xE3o`),A=t(` para
instru\xE7\xF5es sobre como carregar modelos com dados externos.`),this.h()},l(P){f=n(P,"P",{});var w=l(f);D=s(w,`Se o seu modelo for maior que 2GB, voc\xEA ver\xE1 que muitos arquivos adicionais s\xE3o criados
durante a exporta\xE7\xE3o. Isso \xE9 `),h=n(w,"EM",{});var U=l(h);j=s(U,"esperado"),U.forEach(a),T=s(w," porque o ONNX usa "),v=n(w,"A",{href:!0,rel:!0});var S=l(v);E=s(S,`Protocol
Buffers`),S.forEach(a),C=s(w,` para armazenar o modelo e estes
t\xEAm um limite de tamanho de 2GB. Veja a `),N=n(w,"A",{href:!0,rel:!0});var F=l(N);k=s(F,`ONNX
documenta\xE7\xE3o`),F.forEach(a),A=s(w,` para
instru\xE7\xF5es sobre como carregar modelos com dados externos.`),w.forEach(a),this.h()},h(){_(v,"href","https://developers.google.com/protocol-buffers/"),_(v,"rel","nofollow"),_(N,"href","https://github.com/onnx/onnx/blob/master/docs/ExternalData.md"),_(N,"rel","nofollow")},m(P,w){m(P,f,w),e(f,D),e(f,h),e(h,j),e(f,T),e(f,v),e(v,E),e(f,C),e(f,N),e(N,k),e(f,A)},d(P){P&&a(f)}}}function Lv(B){let f,D,h,j,T,v,E,C,N,k,A,P,w,U,S,F,W,re,K,io,oe,po,mo,xe,L,co,ne,Q,uo,J,$e,fo,Oe,Ce,le,be,Pe,c,ae,ho,vo,te,_o,Eo,se,go,xo,M,y,_a,Le,Ea,ga,Ae,xa,$a,I,Oa,ba,ye,qa,ja,Ie,Na,Al,ot,yl,Il,at,zl,Ml,tt,Xl,Bl,st,Rl,Sl,rt,Fl,Vl,nt,Hl,Gl,lt,Ul,Wl,it,Kl,Ql,dt,Jl,Yl,pt,Zl,ei,mt,oi,ai,ct,ti,si,ut,ri,ni,ft,li,ii,ht,di,pi,vt,mi,ci,_t,ui,fi,Et,hi,vi,gt,_i,Ei,xt,gi,xi,$t,$i,Oi,Ot,bi,qi,bt,ji,Ni,qt,ki,Ti,jt,wi,Di,Nt,Ci,Pi,kt,Li,Ai,Tt,yi,Ii,wt,zi,Mi,Dt,Xi,Bi,Ct,Ri,Si,Pt,Fi,Vi,Lt,Hi,Gi,At,Ui,Wi,yt,Ki,Qi,It,Ji,Yi,zt,Zi,ed,Mt,od,ad,Xt,td,sd,Bt,rd,nd,Rt,ld,id,St,dd,pd,Ft,md,cd,Vt,ud,fd,Ht,hd,vd,Gt,_d,Ed,Ut,gd,xd,Wt,$d,Od,Kt,bd,Mr,ka,qd,Xr,ze,$o,jd,Qt,Nd,kd,Td,Jt,wd,Br,qe,Me,Yt,Oo,Dd,Zt,Cd,Rr,Ta,Pd,Sr,bo,Fr,Xe,Ld,es,Ad,yd,Vr,qo,Hr,wa,Id,Gr,jo,Ur,Da,zd,Wr,No,Kr,ie,Md,os,Xd,Bd,as,Rd,Sd,Qr,Y,Fd,ts,Vd,Hd,ko,Gd,Ud,To,Wd,Kd,Jr,wo,Yr,Be,Qd,ss,Jd,Yd,Zr,Do,en,Re,Zd,Co,ep,op,on,Po,an,Ca,ap,tn,Lo,sn,de,tp,rs,sp,rp,ns,np,lp,rn,Ao,nn,yo,ln,pe,ip,ls,dp,pp,is,mp,cp,dn,Io,pn,je,Se,ds,zo,up,ps,fp,mn,me,hp,ms,vp,_p,cs,Ep,gp,cn,Fe,us,Mo,fs,xp,$p,hs,Op,bp,X,Xo,Bo,vs,qp,jp,_s,Np,kp,Es,gs,Tp,wp,Ro,So,xs,Dp,Cp,$s,Pp,Lp,Os,bs,Ap,yp,Fo,qs,js,Ip,zp,Ns,ks,Mp,Xp,Vo,Ts,ws,Bp,Rp,Ds,Cs,Sp,Fp,Ho,Go,Ps,Vp,Hp,Ls,Gp,Up,As,ys,Wp,Kp,Uo,Is,zs,Qp,Jp,Ms,Xs,Yp,Zp,Wo,Bs,Rs,em,om,Ss,Fs,am,un,Ve,tm,Vs,sm,rm,fn,Ko,hn,ce,nm,Hs,lm,im,Gs,dm,pm,vn,Qo,_n,Pa,mm,En,Jo,gn,Z,cm,Us,um,fm,Ws,hm,vm,Ks,_m,Em,xn,He,$n,Ge,On,Ne,Ue,Qs,Yo,gm,Js,xm,bn,La,$m,qn,ue,Ys,Om,bm,Zs,qm,jm,er,Nm,jn,Aa,km,Nn,ke,We,or,Zo,Tm,ar,wm,kn,ya,Dm,Tn,fe,Ia,Cm,tr,Pm,Lm,za,Am,sr,ym,Im,Ma,zm,rr,Mm,wn,Ke,Dn,Qe,Xm,nr,Bm,Rm,Cn,ea,Pn,V,Sm,lr,Fm,Vm,ir,Hm,Gm,dr,Um,Wm,pr,Km,Qm,Ln,Je,An,Xa,Jm,yn,oa,In,Ba,Ym,zn,aa,Mn,Ra,Zm,Xn,ta,Bn,H,ec,mr,oc,ac,cr,tc,sc,ur,rc,nc,fr,lc,ic,Rn,sa,Sn,Ye,Fn,Te,Ze,hr,ra,dc,vr,pc,Vn,he,mc,_r,cc,uc,Er,fc,hc,Hn,na,Gn,R,vc,gr,_c,Ec,xr,gc,xc,$r,$c,Oc,Or,bc,qc,br,jc,Nc,Un,la,Wn,eo,Kn,we,oo,qr,ia,kc,jr,Tc,Qn,ve,wc,Nr,Dc,Cc,kr,Pc,Lc,Jn,da,Yn,ao,Ac,Tr,yc,Ic,Zn,De,to,wr,pa,zc,Dr,Mc,el,Sa,Xc,ol,_e,ma,Bc,Cr,Rc,Sc,Fc,Fa,Vc,Pr,Hc,Gc,Va,Uc,Lr,Wc,al,so,Kc,ca,Qc,Jc,tl;return v=new lo({}),W=new va({props:{$$slots:{default:[Nv]},$$scope:{ctx:B}}}),Oo=new lo({}),bo=new z({props:{code:"pip install transformers[onnx]",highlighted:"pip install transformers[onnx]"}}),qo=new z({props:{code:`python -m transformers.onnx --help

usage: Hugging Face Transformers ONNX exporter [-h] -m MODEL [--feature {causal-lm, ...}] [--opset OPSET] [--atol ATOL] output

positional arguments:
  output                Path indicating where to store generated ONNX model.

optional arguments:
  -h, --help            show this help message and exit
  -m MODEL, --model MODEL
                        Model ID on huggingface.co or path on disk to load model from.
  --feature {causal-lm, ...}
                        The type of features to export the model with.
  --opset OPSET         ONNX opset version to export the model with.
  --atol ATOL           Absolute difference tolerence when validating the model.`,highlighted:`python -m transformers.onnx --<span class="hljs-built_in">help</span>

usage: Hugging Face Transformers ONNX exporter [-h] -m MODEL [--feature {causal-lm, ...}] [--opset OPSET] [--atol ATOL] output

positional arguments:
  output                Path indicating <span class="hljs-built_in">where</span> to store generated ONNX model.

optional arguments:
  -h, --<span class="hljs-built_in">help</span>            show this <span class="hljs-built_in">help</span> message and <span class="hljs-built_in">exit</span>
  -m MODEL, --model MODEL
                        Model ID on huggingface.co or path on disk to load model from.
  --feature {causal-lm, ...}
                        The <span class="hljs-built_in">type</span> of features to <span class="hljs-built_in">export</span> the model with.
  --opset OPSET         ONNX opset version to <span class="hljs-built_in">export</span> the model with.
  --atol ATOL           Absolute difference tolerence when validating the model.`}}),jo=new z({props:{code:"python -m transformers.onnx --model=distilbert-base-uncased onnx/",highlighted:"python -m transformers.onnx --model=distilbert-base-uncased onnx/"}}),No=new z({props:{code:`Validating ONNX model...
        -[\u2713] ONNX model output names match reference model ({'last_hidden_state'})
        - Validating ONNX Model output "last_hidden_state":
                -[\u2713] (2, 8, 768) matches (2, 8, 768)
                -[\u2713] all values close (atol: 1e-05)
All good, model saved at: onnx/model.onnx`,highlighted:`Validating ONNX model...
        -[\u2713] ONNX model output names match reference model ({<span class="hljs-string">&#x27;last_hidden_state&#x27;</span>})
        - Validating ONNX Model output <span class="hljs-string">&quot;last_hidden_state&quot;</span>:
                -[\u2713] (2, 8, 768) matches (2, 8, 768)
                -[\u2713] all values close (atol: 1e-05)
All good, model saved at: onnx/model.onnx`}}),wo=new z({props:{code:`from transformers import AutoTokenizer
from onnxruntime import InferenceSession

tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
session = InferenceSession("onnx/model.onnx")
# ONNX Runtime expects NumPy arrays as input
inputs = tokenizer("Using DistilBERT with ONNX Runtime!", return_tensors="np")
outputs = session.run(output_names=["last_hidden_state"], input_feed=dict(inputs))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> onnxruntime <span class="hljs-keyword">import</span> InferenceSession

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>session = InferenceSession(<span class="hljs-string">&quot;onnx/model.onnx&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># ONNX Runtime expects NumPy arrays as input</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;Using DistilBERT with ONNX Runtime!&quot;</span>, return_tensors=<span class="hljs-string">&quot;np&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = session.run(output_names=[<span class="hljs-string">&quot;last_hidden_state&quot;</span>], input_feed=<span class="hljs-built_in">dict</span>(inputs))`}}),Do=new z({props:{code:`from transformers.models.distilbert import DistilBertConfig, DistilBertOnnxConfig

config = DistilBertConfig()
onnx_config = DistilBertOnnxConfig(config)
print(list(onnx_config.outputs.keys()))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.models.distilbert <span class="hljs-keyword">import</span> DistilBertConfig, DistilBertOnnxConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>config = DistilBertConfig()
<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_config = DistilBertOnnxConfig(config)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-built_in">list</span>(onnx_config.outputs.keys()))
[<span class="hljs-string">&quot;last_hidden_state&quot;</span>]`}}),Po=new z({props:{code:"python -m transformers.onnx --model=keras-io/transformers-qa onnx/",highlighted:"python -m transformers.onnx --model=keras-io/transformers-qa onnx/"}}),Lo=new z({props:{code:`from transformers import AutoTokenizer, AutoModelForSequenceClassification

# Load tokenizer and PyTorch weights form the Hub
tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
pt_model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased")
# Save to disk
tokenizer.save_pretrained("local-pt-checkpoint")
pt_model.save_pretrained("local-pt-checkpoint")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load tokenizer and PyTorch weights form the Hub</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Save to disk</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(<span class="hljs-string">&quot;local-pt-checkpoint&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model.save_pretrained(<span class="hljs-string">&quot;local-pt-checkpoint&quot;</span>)`}}),Ao=new z({props:{code:"python -m transformers.onnx --model=local-pt-checkpoint onnx/",highlighted:"python -m transformers.onnx --model=local-pt-checkpoint onnx/"}}),yo=new z({props:{code:`from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

# Load tokenizer and TensorFlow weights from the Hub
tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
tf_model = TFAutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased")
# Save to disk
tokenizer.save_pretrained("local-tf-checkpoint")
tf_model.save_pretrained("local-tf-checkpoint")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load tokenizer and TensorFlow weights from the Hub</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Save to disk</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(<span class="hljs-string">&quot;local-tf-checkpoint&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model.save_pretrained(<span class="hljs-string">&quot;local-tf-checkpoint&quot;</span>)`}}),Io=new z({props:{code:"python -m transformers.onnx --model=local-tf-checkpoint onnx/",highlighted:"python -m transformers.onnx --model=local-tf-checkpoint onnx/"}}),zo=new lo({}),Ko=new z({props:{code:`from transformers.onnx.features import FeaturesManager

distilbert_features = list(FeaturesManager.get_supported_features_for_model_type("distilbert").keys())
print(distilbert_features)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.onnx.features <span class="hljs-keyword">import</span> FeaturesManager

<span class="hljs-meta">&gt;&gt;&gt; </span>distilbert_features = <span class="hljs-built_in">list</span>(FeaturesManager.get_supported_features_for_model_type(<span class="hljs-string">&quot;distilbert&quot;</span>).keys())
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(distilbert_features)
[<span class="hljs-string">&quot;default&quot;</span>, <span class="hljs-string">&quot;masked-lm&quot;</span>, <span class="hljs-string">&quot;causal-lm&quot;</span>, <span class="hljs-string">&quot;sequence-classification&quot;</span>, <span class="hljs-string">&quot;token-classification&quot;</span>, <span class="hljs-string">&quot;question-answering&quot;</span>]`}}),Qo=new z({props:{code:`python -m transformers.onnx --model=distilbert-base-uncased-finetuned-sst-2-english \\
                            --feature=sequence-classification onnx/`,highlighted:`python -m transformers.onnx --model=distilbert-base-uncased-finetuned-sst-2-english \\
                            --feature=sequence-classification onnx/`}}),Jo=new z({props:{code:`Validating ONNX model...
        -[\u2713] ONNX model output names match reference model ({'logits'})
        - Validating ONNX Model output "logits":
                -[\u2713] (2, 2) matches (2, 2)
                -[\u2713] all values close (atol: 1e-05)
All good, model saved at: onnx/model.onnx`,highlighted:`Validating ONNX model...
        -[\u2713] ONNX model output names match reference model ({<span class="hljs-string">&#x27;logits&#x27;</span>})
        - Validating ONNX Model output <span class="hljs-string">&quot;logits&quot;</span>:
                -[\u2713] (2, 2) matches (2, 2)
                -[\u2713] all values close (atol: 1e-05)
All good, model saved at: onnx/model.onnx`}}),He=new va({props:{$$slots:{default:[kv]},$$scope:{ctx:B}}}),Ge=new va({props:{$$slots:{default:[Tv]},$$scope:{ctx:B}}}),Yo=new lo({}),Zo=new lo({}),Ke=new va({props:{$$slots:{default:[wv]},$$scope:{ctx:B}}}),ea=new z({props:{code:`from typing import Mapping, OrderedDict
from transformers.onnx import OnnxConfig


class DistilBertOnnxConfig(OnnxConfig):
    @property
    def inputs(self) -> Mapping[str, Mapping[int, str]]:
        return OrderedDict(
            [
                ("input_ids", {0: "batch", 1: "sequence"}),
                ("attention_mask", {0: "batch", 1: "sequence"}),
            ]
        )`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> Mapping, OrderedDict
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.onnx <span class="hljs-keyword">import</span> OnnxConfig


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">class</span> <span class="hljs-title class_">DistilBertOnnxConfig</span>(<span class="hljs-title class_ inherited__">OnnxConfig</span>):
<span class="hljs-meta">... </span>    @<span class="hljs-built_in">property</span>
<span class="hljs-meta">... </span>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">inputs</span>(<span class="hljs-params">self</span>) -&gt; Mapping[<span class="hljs-built_in">str</span>, Mapping[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">str</span>]]:
<span class="hljs-meta">... </span>        <span class="hljs-keyword">return</span> OrderedDict(
<span class="hljs-meta">... </span>            [
<span class="hljs-meta">... </span>                (<span class="hljs-string">&quot;input_ids&quot;</span>, {<span class="hljs-number">0</span>: <span class="hljs-string">&quot;batch&quot;</span>, <span class="hljs-number">1</span>: <span class="hljs-string">&quot;sequence&quot;</span>}),
<span class="hljs-meta">... </span>                (<span class="hljs-string">&quot;attention_mask&quot;</span>, {<span class="hljs-number">0</span>: <span class="hljs-string">&quot;batch&quot;</span>, <span class="hljs-number">1</span>: <span class="hljs-string">&quot;sequence&quot;</span>}),
<span class="hljs-meta">... </span>            ]
<span class="hljs-meta">... </span>        )`}}),Je=new va({props:{$$slots:{default:[Dv]},$$scope:{ctx:B}}}),oa=new z({props:{code:`from transformers import AutoConfig

config = AutoConfig.from_pretrained("distilbert-base-uncased")
onnx_config = DistilBertOnnxConfig(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_config = DistilBertOnnxConfig(config)`}}),aa=new z({props:{code:"print(onnx_config.default_onnx_opset)",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(onnx_config.default_onnx_opset)
<span class="hljs-number">11</span>`}}),ta=new z({props:{code:"print(onnx_config.outputs)",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(onnx_config.outputs)
OrderedDict([(<span class="hljs-string">&quot;last_hidden_state&quot;</span>, {<span class="hljs-number">0</span>: <span class="hljs-string">&quot;batch&quot;</span>, <span class="hljs-number">1</span>: <span class="hljs-string">&quot;sequence&quot;</span>})])`}}),sa=new z({props:{code:`from transformers import AutoConfig

config = AutoConfig.from_pretrained("distilbert-base-uncased")
onnx_config_for_seq_clf = DistilBertOnnxConfig(config, task="sequence-classification")
print(onnx_config_for_seq_clf.outputs)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_config_for_seq_clf = DistilBertOnnxConfig(config, task=<span class="hljs-string">&quot;sequence-classification&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(onnx_config_for_seq_clf.outputs)
OrderedDict([(<span class="hljs-string">&#x27;logits&#x27;</span>, {<span class="hljs-number">0</span>: <span class="hljs-string">&#x27;batch&#x27;</span>})])`}}),Ye=new va({props:{$$slots:{default:[Cv]},$$scope:{ctx:B}}}),ra=new lo({}),na=new z({props:{code:`from pathlib import Path
from transformers.onnx import export
from transformers import AutoTokenizer, AutoModel

onnx_path = Path("model.onnx")
model_ckpt = "distilbert-base-uncased"
base_model = AutoModel.from_pretrained(model_ckpt)
tokenizer = AutoTokenizer.from_pretrained(model_ckpt)

onnx_inputs, onnx_outputs = export(tokenizer, base_model, onnx_config, onnx_config.default_onnx_opset, onnx_path)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> Path
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.onnx <span class="hljs-keyword">import</span> export
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_path = Path(<span class="hljs-string">&quot;model.onnx&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model_ckpt = <span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>base_model = AutoModel.from_pretrained(model_ckpt)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_ckpt)

<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_inputs, onnx_outputs = export(tokenizer, base_model, onnx_config, onnx_config.default_onnx_opset, onnx_path)`}}),la=new z({props:{code:`import onnx

onnx_model = onnx.load("model.onnx")
onnx.checker.check_model(onnx_model)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> onnx

<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_model = onnx.load(<span class="hljs-string">&quot;model.onnx&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>onnx.checker.check_model(onnx_model)`}}),eo=new va({props:{$$slots:{default:[Pv]},$$scope:{ctx:B}}}),ia=new lo({}),da=new z({props:{code:`from transformers.onnx import validate_model_outputs

validate_model_outputs(
    onnx_config, tokenizer, base_model, onnx_path, onnx_outputs, onnx_config.atol_for_validation
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.onnx <span class="hljs-keyword">import</span> validate_model_outputs

<span class="hljs-meta">&gt;&gt;&gt; </span>validate_model_outputs(
<span class="hljs-meta">... </span>    onnx_config, tokenizer, base_model, onnx_path, onnx_outputs, onnx_config.atol_for_validation
<span class="hljs-meta">... </span>)`}}),pa=new lo({}),{c(){f=r("meta"),D=d(),h=r("h1"),j=r("a"),T=r("span"),g(v.$$.fragment),E=d(),C=r("span"),N=t("Exportando modelos para ONNX"),k=d(),A=r("p"),P=t(`Se voc\xEA precisar implantar modelos \u{1F917} Transformers em ambientes de produ\xE7\xE3o, recomendamos
exporta-los para um formato serializado que pode ser carregado e executado em
tempos de execu\xE7\xE3o e hardware. Neste guia, mostraremos como exportar modelos \u{1F917} Transformers
para `),w=r("a"),U=t("ONNX (Open Neural Network eXchange)"),S=t("."),F=d(),g(W.$$.fragment),re=d(),K=r("p"),io=t(`ONNX \xE9 um padr\xE3o aberto que define um conjunto comum de operadores e um formato de arquivo comum
para representar modelos de aprendizado profundo em uma ampla variedade de estruturas, incluindo PyTorch e
TensorFlow. Quando um modelo \xE9 exportado para o formato ONNX, esses operadores s\xE3o usados para
construir um grafo computacional (muitas vezes chamado de `),oe=r("em"),po=t("representa\xE7\xE3o intermedi\xE1ria"),mo=t(`) que
representa o fluxo de dados atrav\xE9s da rede neural.`),xe=d(),L=r("p"),co=t(`Ao expor um grafo com operadores e tipos de dados padronizados, o ONNX facilita a
alternar entre os frameworks. Por exemplo, um modelo treinado em PyTorch pode ser exportado para
formato ONNX e depois importado no TensorFlow (e vice-versa).`),ne=d(),Q=r("p"),uo=t("\u{1F917} Transformers fornece um pacote "),J=r("a"),$e=r("code"),fo=t("transformers.onnx"),Oe=t(` que permite
que voc\xEA converta os checkpoints do modelo em um grafo ONNX aproveitando os objetos de configura\xE7\xE3o.
Esses objetos de configura\xE7\xE3o v\xEAm prontos para v\xE1rias arquiteturas de modelo e s\xE3o
projetado para ser facilmente extens\xEDvel a outras arquiteturas.`),Ce=d(),le=r("p"),be=t("As configura\xE7\xF5es prontas incluem as seguintes arquiteturas:"),Pe=d(),c=r("ul"),ae=r("li"),ho=t("ALBERT"),vo=d(),te=r("li"),_o=t("BART"),Eo=d(),se=r("li"),go=t("BEiT"),xo=d(),M=r("li"),y=t("BERT"),_a=d(),Le=r("li"),Ea=t("BigBird"),ga=d(),Ae=r("li"),xa=t("BigBird-Pegasus"),$a=d(),I=r("li"),Oa=t("Blenderbot"),ba=d(),ye=r("li"),qa=t("BlenderbotSmall"),ja=d(),Ie=r("li"),Na=t("BLOOM"),Al=d(),ot=r("li"),yl=t("CamemBERT"),Il=d(),at=r("li"),zl=t("CLIP"),Ml=d(),tt=r("li"),Xl=t("CodeGen"),Bl=d(),st=r("li"),Rl=t("Conditional DETR"),Sl=d(),rt=r("li"),Fl=t("ConvBERT"),Vl=d(),nt=r("li"),Hl=t("ConvNeXT"),Gl=d(),lt=r("li"),Ul=t("Data2VecText"),Wl=d(),it=r("li"),Kl=t("Data2VecVision"),Ql=d(),dt=r("li"),Jl=t("DeBERTa"),Yl=d(),pt=r("li"),Zl=t("DeBERTa-v2"),ei=d(),mt=r("li"),oi=t("DeiT"),ai=d(),ct=r("li"),ti=t("DETR"),si=d(),ut=r("li"),ri=t("DistilBERT"),ni=d(),ft=r("li"),li=t("ELECTRA"),ii=d(),ht=r("li"),di=t("ERNIE"),pi=d(),vt=r("li"),mi=t("FlauBERT"),ci=d(),_t=r("li"),ui=t("GPT Neo"),fi=d(),Et=r("li"),hi=t("GPT-J"),vi=d(),gt=r("li"),_i=t("GroupViT"),Ei=d(),xt=r("li"),gi=t("I-BERT"),xi=d(),$t=r("li"),$i=t("LayoutLM"),Oi=d(),Ot=r("li"),bi=t("LayoutLMv3"),qi=d(),bt=r("li"),ji=t("LeViT"),Ni=d(),qt=r("li"),ki=t("Longformer"),Ti=d(),jt=r("li"),wi=t("LongT5"),Di=d(),Nt=r("li"),Ci=t("M2M100"),Pi=d(),kt=r("li"),Li=t("Marian"),Ai=d(),Tt=r("li"),yi=t("mBART"),Ii=d(),wt=r("li"),zi=t("MobileBERT"),Mi=d(),Dt=r("li"),Xi=t("MobileViT"),Bi=d(),Ct=r("li"),Ri=t("MT5"),Si=d(),Pt=r("li"),Fi=t("OpenAI GPT-2"),Vi=d(),Lt=r("li"),Hi=t("OWL-ViT"),Gi=d(),At=r("li"),Ui=t("Perceiver"),Wi=d(),yt=r("li"),Ki=t("PLBart"),Qi=d(),It=r("li"),Ji=t("ResNet"),Yi=d(),zt=r("li"),Zi=t("RoBERTa"),ed=d(),Mt=r("li"),od=t("RoFormer"),ad=d(),Xt=r("li"),td=t("SegFormer"),sd=d(),Bt=r("li"),rd=t("SqueezeBERT"),nd=d(),Rt=r("li"),ld=t("Swin Transformer"),id=d(),St=r("li"),dd=t("T5"),pd=d(),Ft=r("li"),md=t("Table Transformer"),cd=d(),Vt=r("li"),ud=t("Vision Encoder decoder"),fd=d(),Ht=r("li"),hd=t("ViT"),vd=d(),Gt=r("li"),_d=t("XLM"),Ed=d(),Ut=r("li"),gd=t("XLM-RoBERTa"),xd=d(),Wt=r("li"),$d=t("XLM-RoBERTa-XL"),Od=d(),Kt=r("li"),bd=t("YOLOS"),Mr=d(),ka=r("p"),qd=t("Nas pr\xF3ximas duas se\xE7\xF5es, mostraremos como:"),Xr=d(),ze=r("ul"),$o=r("li"),jd=t("Exportar um modelo suportado usando o pacote "),Qt=r("code"),Nd=t("transformers.onnx"),kd=t("."),Td=d(),Jt=r("li"),wd=t("Exportar um modelo personalizado para uma arquitetura sem suporte."),Br=d(),qe=r("h2"),Me=r("a"),Yt=r("span"),g(Oo.$$.fragment),Dd=d(),Zt=r("span"),Cd=t("Exportando um modelo para ONNX"),Rr=d(),Ta=r("p"),Pd=t(`Para exportar um modelo \u{1F917} Transformers para o ONNX, primeiro voc\xEA precisa instalar algumas
depend\xEAncias extras:`),Sr=d(),g(bo.$$.fragment),Fr=d(),Xe=r("p"),Ld=t("O pacote "),es=r("code"),Ad=t("transformers.onnx"),yd=t(" pode ent\xE3o ser usado como um m\xF3dulo Python:"),Vr=d(),g(qo.$$.fragment),Hr=d(),wa=r("p"),Id=t("A exporta\xE7\xE3o de um checkpoint usando uma configura\xE7\xE3o pronta pode ser feita da seguinte forma:"),Gr=d(),g(jo.$$.fragment),Ur=d(),Da=r("p"),zd=t("Voc\xEA deve ver os seguintes logs:"),Wr=d(),g(No.$$.fragment),Kr=d(),ie=r("p"),Md=t("Isso exporta um grafo ONNX do ponto de verifica\xE7\xE3o definido pelo argumento "),os=r("code"),Xd=t("--model"),Bd=t(`. Nisso
Por exemplo, \xE9 `),as=r("code"),Rd=t("distilbert-base-uncased"),Sd=t(`, mas pode ser qualquer checkpoint no Hugging
Face Hub ou um armazenado localmente.`),Qr=d(),Y=r("p"),Fd=t("O arquivo "),ts=r("code"),Vd=t("model.onnx"),Hd=t(" resultante pode ser executado em um dos "),ko=r("a"),Gd=t(`muitos
aceleradores`),Ud=t(` que suportam o ONNX
padr\xE3o. Por exemplo, podemos carregar e executar o modelo com `),To=r("a"),Wd=t(`ONNX
Tempo de execu\xE7\xE3o`),Kd=t(" da seguinte forma:"),Jr=d(),g(wo.$$.fragment),Yr=d(),Be=r("p"),Qd=t("Os nomes de sa\xEDda necess\xE1rios (como "),ss=r("code"),Jd=t('["last_hidden_state"]'),Yd=t(`) podem ser obtidos pegando uma
configura\xE7\xE3o ONNX de cada modelo. Por exemplo, para DistilBERT temos:`),Zr=d(),g(Do.$$.fragment),en=d(),Re=r("p"),Zd=t(`O processo \xE9 id\xEAntico para os checkpoints do TensorFlow no Hub. Por exemplo, podemos
exportar um checkpoint TensorFlow puro do `),Co=r("a"),ep=t("Keras"),op=t(" da seguinte forma:"),on=d(),g(Po.$$.fragment),an=d(),Ca=r("p"),ap=t(`Para exportar um modelo armazenado localmente, voc\xEA precisar\xE1 ter os pesos e
arquivos tokenizer armazenados em um diret\xF3rio. Por exemplo, podemos carregar e salvar um checkpoint como:`),tn=d(),g(Lo.$$.fragment),sn=d(),de=r("p"),tp=t("Uma vez que o checkpoint \xE9 salvo, podemos export\xE1-lo para o ONNX apontando o "),rs=r("code"),sp=t("--model"),rp=t(`
argumento do pacote `),ns=r("code"),np=t("transformers.onnx"),lp=t(" para o diret\xF3rio desejado:"),rn=d(),g(Ao.$$.fragment),nn=d(),g(yo.$$.fragment),ln=d(),pe=r("p"),ip=t("Uma vez que o checkpoint \xE9 salvo, podemos export\xE1-lo para o ONNX apontando o "),ls=r("code"),dp=t("--model"),pp=t(`
argumento do pacote `),is=r("code"),mp=t("transformers.onnx"),cp=t(" para o diret\xF3rio desejado:"),dn=d(),g(Io.$$.fragment),pn=d(),je=r("h2"),Se=r("a"),ds=r("span"),g(zo.$$.fragment),up=d(),ps=r("span"),fp=t("Selecionando features para diferentes tarefas do modelo"),mn=d(),me=r("p"),hp=t("Cada configura\xE7\xE3o pronta vem com um conjunto de "),ms=r("em"),vp=t("features"),_p=t(` que permitem exportar
modelos para diferentes tipos de tarefas. Conforme mostrado na tabela abaixo, cada recurso \xE9
associado a uma `),cs=r("code"),Ep=t("AutoClass"),gp=t(" diferente:"),cn=d(),Fe=r("table"),us=r("thead"),Mo=r("tr"),fs=r("th"),xp=t("Feature"),$p=d(),hs=r("th"),Op=t("Auto Class"),bp=d(),X=r("tbody"),Xo=r("tr"),Bo=r("td"),vs=r("code"),qp=t("causal-lm"),jp=t(", "),_s=r("code"),Np=t("causal-lm-with-past"),kp=d(),Es=r("td"),gs=r("code"),Tp=t("AutoModelForCausalLM"),wp=d(),Ro=r("tr"),So=r("td"),xs=r("code"),Dp=t("default"),Cp=t(", "),$s=r("code"),Pp=t("default-with-past"),Lp=d(),Os=r("td"),bs=r("code"),Ap=t("AutoModel"),yp=d(),Fo=r("tr"),qs=r("td"),js=r("code"),Ip=t("masked-lm"),zp=d(),Ns=r("td"),ks=r("code"),Mp=t("AutoModelForMaskedLM"),Xp=d(),Vo=r("tr"),Ts=r("td"),ws=r("code"),Bp=t("question-answering"),Rp=d(),Ds=r("td"),Cs=r("code"),Sp=t("AutoModelForQuestionAnswering"),Fp=d(),Ho=r("tr"),Go=r("td"),Ps=r("code"),Vp=t("seq2seq-lm"),Hp=t(", "),Ls=r("code"),Gp=t("seq2seq-lm-with-past"),Up=d(),As=r("td"),ys=r("code"),Wp=t("AutoModelForSeq2SeqLM"),Kp=d(),Uo=r("tr"),Is=r("td"),zs=r("code"),Qp=t("sequence-classification"),Jp=d(),Ms=r("td"),Xs=r("code"),Yp=t("AutoModelForSequenceClassification"),Zp=d(),Wo=r("tr"),Bs=r("td"),Rs=r("code"),em=t("token-classification"),om=d(),Ss=r("td"),Fs=r("code"),am=t("AutoModelForTokenClassification"),un=d(),Ve=r("p"),tm=t(`Para cada configura\xE7\xE3o, voc\xEA pode encontrar a lista de recursos suportados por meio do
`),Vs=r("code"),sm=t("FeaturesManager"),rm=t(". Por exemplo, para DistilBERT temos:"),fn=d(),g(Ko.$$.fragment),hn=d(),ce=r("p"),nm=t("Voc\xEA pode ent\xE3o passar um desses recursos para o argumento "),Hs=r("code"),lm=t("--feature"),im=t(` no
pacote `),Gs=r("code"),dm=t("transformers.onnx"),pm=t(`. Por exemplo, para exportar um modelo de classifica\xE7\xE3o de texto, podemos
escolher um modelo ajustado no Hub e executar:`),vn=d(),g(Qo.$$.fragment),_n=d(),Pa=r("p"),mm=t("Isso exibe os seguintes logs:"),En=d(),g(Jo.$$.fragment),gn=d(),Z=r("p"),cm=t("Observe que, neste caso, os nomes de sa\xEDda do modelo ajustado s\xE3o "),Us=r("code"),um=t("logits"),fm=t(`
em vez do `),Ws=r("code"),hm=t("last_hidden_state"),vm=t(" que vimos com o checkpoint "),Ks=r("code"),_m=t("distilbert-base-uncased"),Em=t(`
mais cedo. Isso \xE9 esperado, pois o modelo ajustado (fine-tuned) possui uma cabe\xE7a de classifica\xE7\xE3o de sequ\xEAncia.`),xn=d(),g(He.$$.fragment),$n=d(),g(Ge.$$.fragment),On=d(),Ne=r("h2"),Ue=r("a"),Qs=r("span"),g(Yo.$$.fragment),gm=d(),Js=r("span"),xm=t("Exportando um modelo para uma arquitetura sem suporte"),bn=d(),La=r("p"),$m=t(`Se voc\xEA deseja exportar um modelo cuja arquitetura n\xE3o \xE9 suportada nativamente pela
biblioteca, h\xE1 tr\xEAs etapas principais a seguir:`),qn=d(),ue=r("ol"),Ys=r("li"),Om=t("Implemente uma configura\xE7\xE3o ONNX personalizada."),bm=d(),Zs=r("li"),qm=t("Exporte o modelo para o ONNX."),jm=d(),er=r("li"),Nm=t("Valide as sa\xEDdas do PyTorch e dos modelos exportados."),jn=d(),Aa=r("p"),km=t(`Nesta se\xE7\xE3o, veremos como o DistilBERT foi implementado para mostrar o que est\xE1 envolvido
em cada passo.`),Nn=d(),ke=r("h3"),We=r("a"),or=r("span"),g(Zo.$$.fragment),Tm=d(),ar=r("span"),wm=t("Implementando uma configura\xE7\xE3o ONNX personalizada"),kn=d(),ya=r("p"),Dm=t(`Vamos come\xE7ar com o objeto de configura\xE7\xE3o ONNX. Fornecemos tr\xEAs classes abstratas que
voc\xEA deve herdar, dependendo do tipo de arquitetura de modelo que deseja exportar:`),Tn=d(),fe=r("ul"),Ia=r("li"),Cm=t("Modelos baseados em codificador herdam de "),tr=r("code"),Pm=t("OnnxConfig"),Lm=d(),za=r("li"),Am=t("Modelos baseados em decodificador herdam de "),sr=r("code"),ym=t("OnnxConfigWithPast"),Im=d(),Ma=r("li"),zm=t("Os modelos codificador-decodificador herdam de "),rr=r("code"),Mm=t("OnnxSeq2SeqConfigWithPast"),wn=d(),g(Ke.$$.fragment),Dn=d(),Qe=r("p"),Xm=t(`Como o DistilBERT \xE9 um modelo baseado em codificador, sua configura\xE7\xE3o \xE9 herdada de
`),nr=r("code"),Bm=t("OnnxConfig"),Rm=t(":"),Cn=d(),g(ea.$$.fragment),Pn=d(),V=r("p"),Sm=t("Todo objeto de configura\xE7\xE3o deve implementar a propriedade "),lr=r("code"),Fm=t("inputs"),Vm=t(` e retornar um mapeamento,
onde cada chave corresponde a uma entrada esperada e cada valor indica o eixo
dessa entrada. Para o DistilBERT, podemos ver que duas entradas s\xE3o necess\xE1rias: `),ir=r("code"),Hm=t("input_ids"),Gm=t(` e
`),dr=r("code"),Um=t("attention_mask"),Wm=t(". Essas entradas t\xEAm a mesma forma de "),pr=r("code"),Km=t("(batch_size, sequence_length)"),Qm=t(`
\xE9 por isso que vemos os mesmos eixos usados na configura\xE7\xE3o.`),Ln=d(),g(Je.$$.fragment),An=d(),Xa=r("p"),Jm=t(`Depois de implementar uma configura\xE7\xE3o ONNX, voc\xEA pode instanci\xE1-la fornecendo a
configura\xE7\xE3o do modelo base da seguinte forma:`),yn=d(),g(oa.$$.fragment),In=d(),Ba=r("p"),Ym=t(`O objeto resultante tem v\xE1rias propriedades \xFAteis. Por exemplo, voc\xEA pode visualizar o conjunto de operadores ONNX
que ser\xE1 usado durante a exporta\xE7\xE3o:`),zn=d(),g(aa.$$.fragment),Mn=d(),Ra=r("p"),Zm=t("Voc\xEA tamb\xE9m pode visualizar as sa\xEDdas associadas ao modelo da seguinte forma:"),Xn=d(),g(ta.$$.fragment),Bn=d(),H=r("p"),ec=t(`Observe que a propriedade outputs segue a mesma estrutura das entradas; ele retorna um
`),mr=r("code"),oc=t("OrderedDict"),ac=t(` de sa\xEDdas nomeadas e suas formas. A estrutura de sa\xEDda est\xE1 ligada a
escolha do recurso com o qual a configura\xE7\xE3o \xE9 inicializada. Por padr\xE3o, a configura\xE7\xE3o do ONNX
\xE9 inicializada com o recurso `),cr=r("code"),tc=t("default"),sc=t(` que corresponde \xE0 exporta\xE7\xE3o de um
modelo carregado com a classe `),ur=r("code"),rc=t("AutoModel"),nc=t(`. Se voc\xEA deseja exportar um modelo para outra tarefa,
apenas forne\xE7a um recurso diferente para o argumento `),fr=r("code"),lc=t("task"),ic=t(` quando voc\xEA inicializar a configura\xE7\xE3o ONNX
. Por exemplo, se quisermos exportar o DistilBERT com uma sequ\xEAncia
de classifica\xE7\xE3o, poder\xEDamos usar:`),Rn=d(),g(sa.$$.fragment),Sn=d(),g(Ye.$$.fragment),Fn=d(),Te=r("h3"),Ze=r("a"),hr=r("span"),g(ra.$$.fragment),dc=d(),vr=r("span"),pc=t("Exportando um modelo"),Vn=d(),he=r("p"),mc=t(`Depois de ter implementado a configura\xE7\xE3o do ONNX, o pr\xF3ximo passo \xE9 exportar o modelo.
Aqui podemos usar a fun\xE7\xE3o `),_r=r("code"),cc=t("export()"),uc=t(" fornecida pelo pacote "),Er=r("code"),fc=t("transformers.onnx"),hc=t(`.
Esta fun\xE7\xE3o espera a configura\xE7\xE3o do ONNX, juntamente com o modelo base e o tokenizer,
e o caminho para salvar o arquivo exportado:`),Hn=d(),g(na.$$.fragment),Gn=d(),R=r("p"),vc=t("Os "),gr=r("code"),_c=t("onnx_inputs"),Ec=t(" e "),xr=r("code"),gc=t("onnx_outputs"),xc=t(" retornados pela fun\xE7\xE3o "),$r=r("code"),$c=t("export()"),Oc=t(` s\xE3o listas de
chaves definidas nas propriedades `),Or=r("code"),bc=t("inputs"),qc=t(" e "),br=r("code"),jc=t("outputs"),Nc=t(` da configura\xE7\xE3o. Uma vez que o
modelo \xE9 exportado, voc\xEA pode testar se o modelo est\xE1 bem formado da seguinte forma:`),Un=d(),g(la.$$.fragment),Wn=d(),g(eo.$$.fragment),Kn=d(),we=r("h3"),oo=r("a"),qr=r("span"),g(ia.$$.fragment),kc=d(),jr=r("span"),Tc=t("Validando a sa\xEDda dos modelos"),Qn=d(),ve=r("p"),wc=t(`A etapa final \xE9 validar se as sa\xEDdas do modelo base e exportado concordam
dentro de alguma toler\xE2ncia absoluta. Aqui podemos usar a fun\xE7\xE3o `),Nr=r("code"),Dc=t("validate_model_outputs()"),Cc=t(`
fornecida pelo pacote `),kr=r("code"),Pc=t("transformers.onnx"),Lc=t(" da seguinte forma:"),Jn=d(),g(da.$$.fragment),Yn=d(),ao=r("p"),Ac=t("Esta fun\xE7\xE3o usa o m\xE9todo "),Tr=r("code"),yc=t("generate_dummy_inputs()"),Ic=t(` para
gerar entradas para o modelo base e o exportado, e a toler\xE2ncia absoluta pode ser
definida na configura\xE7\xE3o. Geralmente encontramos concord\xE2ncia num\xE9rica em 1e-6 a 1e-4
de alcance, embora qualquer coisa menor que 1e-3 provavelmente esteja OK.`),Zn=d(),De=r("h2"),to=r("a"),wr=r("span"),g(pa.$$.fragment),zc=d(),Dr=r("span"),Mc=t("Contribuindo com uma nova configura\xE7\xE3o para \u{1F917} Transformers"),el=d(),Sa=r("p"),Xc=t(`Estamos procurando expandir o conjunto de configura\xE7\xF5es prontas e receber contribui\xE7\xF5es
da comunidade! Se voc\xEA gostaria de contribuir para a biblioteca, voc\xEA
precisar\xE1:`),ol=d(),_e=r("ul"),ma=r("li"),Bc=t("Implemente a configura\xE7\xE3o do ONNX no arquivo "),Cr=r("code"),Rc=t("configuration_<model_name>.py"),Sc=t(` correspondente
Arquivo`),Fc=d(),Fa=r("li"),Vc=t(`Incluir a arquitetura do modelo e recursos correspondentes em
`),Pr=r("code"),Hc=t("~onnx.features.FeatureManager"),Gc=d(),Va=r("li"),Uc=t("Adicione sua arquitetura de modelo aos testes em "),Lr=r("code"),Wc=t("test_onnx_v2.py"),al=d(),so=r("p"),Kc=t("Confira como ficou a configura\xE7\xE3o do "),ca=r("a"),Qc=t("IBERT"),Jc=t(` para obter uma
id\xE9ia do que est\xE1 envolvido.`),this.h()},l(o){const i=qv('[data-svelte="svelte-1phssyn"]',document.head);f=n(i,"META",{name:!0,content:!0}),i.forEach(a),D=p(o),h=n(o,"H1",{class:!0});var ua=l(h);j=n(ua,"A",{id:!0,class:!0,href:!0});var Ar=l(j);T=n(Ar,"SPAN",{});var yr=l(T);x(v.$$.fragment,yr),yr.forEach(a),Ar.forEach(a),E=p(ua),C=n(ua,"SPAN",{});var Ir=l(C);N=s(Ir,"Exportando modelos para ONNX"),Ir.forEach(a),ua.forEach(a),k=p(o),A=n(o,"P",{});var fa=l(A);P=s(fa,`Se voc\xEA precisar implantar modelos \u{1F917} Transformers em ambientes de produ\xE7\xE3o, recomendamos
exporta-los para um formato serializado que pode ser carregado e executado em
tempos de execu\xE7\xE3o e hardware. Neste guia, mostraremos como exportar modelos \u{1F917} Transformers
para `),w=n(fa,"A",{href:!0,rel:!0});var zr=l(w);U=s(zr,"ONNX (Open Neural Network eXchange)"),zr.forEach(a),S=s(fa,"."),fa.forEach(a),F=p(o),x(W.$$.fragment,o),re=p(o),K=n(o,"P",{});var ha=l(K);io=s(ha,`ONNX \xE9 um padr\xE3o aberto que define um conjunto comum de operadores e um formato de arquivo comum
para representar modelos de aprendizado profundo em uma ampla variedade de estruturas, incluindo PyTorch e
TensorFlow. Quando um modelo \xE9 exportado para o formato ONNX, esses operadores s\xE3o usados para
construir um grafo computacional (muitas vezes chamado de `),oe=n(ha,"EM",{});var tu=l(oe);po=s(tu,"representa\xE7\xE3o intermedi\xE1ria"),tu.forEach(a),mo=s(ha,`) que
representa o fluxo de dados atrav\xE9s da rede neural.`),ha.forEach(a),xe=p(o),L=n(o,"P",{});var su=l(L);co=s(su,`Ao expor um grafo com operadores e tipos de dados padronizados, o ONNX facilita a
alternar entre os frameworks. Por exemplo, um modelo treinado em PyTorch pode ser exportado para
formato ONNX e depois importado no TensorFlow (e vice-versa).`),su.forEach(a),ne=p(o),Q=n(o,"P",{});var sl=l(Q);uo=s(sl,"\u{1F917} Transformers fornece um pacote "),J=n(sl,"A",{href:!0});var ru=l(J);$e=n(ru,"CODE",{});var nu=l($e);fo=s(nu,"transformers.onnx"),nu.forEach(a),ru.forEach(a),Oe=s(sl,` que permite
que voc\xEA converta os checkpoints do modelo em um grafo ONNX aproveitando os objetos de configura\xE7\xE3o.
Esses objetos de configura\xE7\xE3o v\xEAm prontos para v\xE1rias arquiteturas de modelo e s\xE3o
projetado para ser facilmente extens\xEDvel a outras arquiteturas.`),sl.forEach(a),Ce=p(o),le=n(o,"P",{});var lu=l(le);be=s(lu,"As configura\xE7\xF5es prontas incluem as seguintes arquiteturas:"),lu.forEach(a),Pe=p(o),c=n(o,"UL",{});var u=l(c);ae=n(u,"LI",{});var iu=l(ae);ho=s(iu,"ALBERT"),iu.forEach(a),vo=p(u),te=n(u,"LI",{});var du=l(te);_o=s(du,"BART"),du.forEach(a),Eo=p(u),se=n(u,"LI",{});var pu=l(se);go=s(pu,"BEiT"),pu.forEach(a),xo=p(u),M=n(u,"LI",{});var mu=l(M);y=s(mu,"BERT"),mu.forEach(a),_a=p(u),Le=n(u,"LI",{});var cu=l(Le);Ea=s(cu,"BigBird"),cu.forEach(a),ga=p(u),Ae=n(u,"LI",{});var uu=l(Ae);xa=s(uu,"BigBird-Pegasus"),uu.forEach(a),$a=p(u),I=n(u,"LI",{});var fu=l(I);Oa=s(fu,"Blenderbot"),fu.forEach(a),ba=p(u),ye=n(u,"LI",{});var hu=l(ye);qa=s(hu,"BlenderbotSmall"),hu.forEach(a),ja=p(u),Ie=n(u,"LI",{});var vu=l(Ie);Na=s(vu,"BLOOM"),vu.forEach(a),Al=p(u),ot=n(u,"LI",{});var _u=l(ot);yl=s(_u,"CamemBERT"),_u.forEach(a),Il=p(u),at=n(u,"LI",{});var Eu=l(at);zl=s(Eu,"CLIP"),Eu.forEach(a),Ml=p(u),tt=n(u,"LI",{});var gu=l(tt);Xl=s(gu,"CodeGen"),gu.forEach(a),Bl=p(u),st=n(u,"LI",{});var xu=l(st);Rl=s(xu,"Conditional DETR"),xu.forEach(a),Sl=p(u),rt=n(u,"LI",{});var $u=l(rt);Fl=s($u,"ConvBERT"),$u.forEach(a),Vl=p(u),nt=n(u,"LI",{});var Ou=l(nt);Hl=s(Ou,"ConvNeXT"),Ou.forEach(a),Gl=p(u),lt=n(u,"LI",{});var bu=l(lt);Ul=s(bu,"Data2VecText"),bu.forEach(a),Wl=p(u),it=n(u,"LI",{});var qu=l(it);Kl=s(qu,"Data2VecVision"),qu.forEach(a),Ql=p(u),dt=n(u,"LI",{});var ju=l(dt);Jl=s(ju,"DeBERTa"),ju.forEach(a),Yl=p(u),pt=n(u,"LI",{});var Nu=l(pt);Zl=s(Nu,"DeBERTa-v2"),Nu.forEach(a),ei=p(u),mt=n(u,"LI",{});var ku=l(mt);oi=s(ku,"DeiT"),ku.forEach(a),ai=p(u),ct=n(u,"LI",{});var Tu=l(ct);ti=s(Tu,"DETR"),Tu.forEach(a),si=p(u),ut=n(u,"LI",{});var wu=l(ut);ri=s(wu,"DistilBERT"),wu.forEach(a),ni=p(u),ft=n(u,"LI",{});var Du=l(ft);li=s(Du,"ELECTRA"),Du.forEach(a),ii=p(u),ht=n(u,"LI",{});var Cu=l(ht);di=s(Cu,"ERNIE"),Cu.forEach(a),pi=p(u),vt=n(u,"LI",{});var Pu=l(vt);mi=s(Pu,"FlauBERT"),Pu.forEach(a),ci=p(u),_t=n(u,"LI",{});var Lu=l(_t);ui=s(Lu,"GPT Neo"),Lu.forEach(a),fi=p(u),Et=n(u,"LI",{});var Au=l(Et);hi=s(Au,"GPT-J"),Au.forEach(a),vi=p(u),gt=n(u,"LI",{});var yu=l(gt);_i=s(yu,"GroupViT"),yu.forEach(a),Ei=p(u),xt=n(u,"LI",{});var Iu=l(xt);gi=s(Iu,"I-BERT"),Iu.forEach(a),xi=p(u),$t=n(u,"LI",{});var zu=l($t);$i=s(zu,"LayoutLM"),zu.forEach(a),Oi=p(u),Ot=n(u,"LI",{});var Mu=l(Ot);bi=s(Mu,"LayoutLMv3"),Mu.forEach(a),qi=p(u),bt=n(u,"LI",{});var Xu=l(bt);ji=s(Xu,"LeViT"),Xu.forEach(a),Ni=p(u),qt=n(u,"LI",{});var Bu=l(qt);ki=s(Bu,"Longformer"),Bu.forEach(a),Ti=p(u),jt=n(u,"LI",{});var Ru=l(jt);wi=s(Ru,"LongT5"),Ru.forEach(a),Di=p(u),Nt=n(u,"LI",{});var Su=l(Nt);Ci=s(Su,"M2M100"),Su.forEach(a),Pi=p(u),kt=n(u,"LI",{});var Fu=l(kt);Li=s(Fu,"Marian"),Fu.forEach(a),Ai=p(u),Tt=n(u,"LI",{});var Vu=l(Tt);yi=s(Vu,"mBART"),Vu.forEach(a),Ii=p(u),wt=n(u,"LI",{});var Hu=l(wt);zi=s(Hu,"MobileBERT"),Hu.forEach(a),Mi=p(u),Dt=n(u,"LI",{});var Gu=l(Dt);Xi=s(Gu,"MobileViT"),Gu.forEach(a),Bi=p(u),Ct=n(u,"LI",{});var Uu=l(Ct);Ri=s(Uu,"MT5"),Uu.forEach(a),Si=p(u),Pt=n(u,"LI",{});var Wu=l(Pt);Fi=s(Wu,"OpenAI GPT-2"),Wu.forEach(a),Vi=p(u),Lt=n(u,"LI",{});var Ku=l(Lt);Hi=s(Ku,"OWL-ViT"),Ku.forEach(a),Gi=p(u),At=n(u,"LI",{});var Qu=l(At);Ui=s(Qu,"Perceiver"),Qu.forEach(a),Wi=p(u),yt=n(u,"LI",{});var Ju=l(yt);Ki=s(Ju,"PLBart"),Ju.forEach(a),Qi=p(u),It=n(u,"LI",{});var Yu=l(It);Ji=s(Yu,"ResNet"),Yu.forEach(a),Yi=p(u),zt=n(u,"LI",{});var Zu=l(zt);Zi=s(Zu,"RoBERTa"),Zu.forEach(a),ed=p(u),Mt=n(u,"LI",{});var ef=l(Mt);od=s(ef,"RoFormer"),ef.forEach(a),ad=p(u),Xt=n(u,"LI",{});var of=l(Xt);td=s(of,"SegFormer"),of.forEach(a),sd=p(u),Bt=n(u,"LI",{});var af=l(Bt);rd=s(af,"SqueezeBERT"),af.forEach(a),nd=p(u),Rt=n(u,"LI",{});var tf=l(Rt);ld=s(tf,"Swin Transformer"),tf.forEach(a),id=p(u),St=n(u,"LI",{});var sf=l(St);dd=s(sf,"T5"),sf.forEach(a),pd=p(u),Ft=n(u,"LI",{});var rf=l(Ft);md=s(rf,"Table Transformer"),rf.forEach(a),cd=p(u),Vt=n(u,"LI",{});var nf=l(Vt);ud=s(nf,"Vision Encoder decoder"),nf.forEach(a),fd=p(u),Ht=n(u,"LI",{});var lf=l(Ht);hd=s(lf,"ViT"),lf.forEach(a),vd=p(u),Gt=n(u,"LI",{});var df=l(Gt);_d=s(df,"XLM"),df.forEach(a),Ed=p(u),Ut=n(u,"LI",{});var pf=l(Ut);gd=s(pf,"XLM-RoBERTa"),pf.forEach(a),xd=p(u),Wt=n(u,"LI",{});var mf=l(Wt);$d=s(mf,"XLM-RoBERTa-XL"),mf.forEach(a),Od=p(u),Kt=n(u,"LI",{});var cf=l(Kt);bd=s(cf,"YOLOS"),cf.forEach(a),u.forEach(a),Mr=p(o),ka=n(o,"P",{});var uf=l(ka);qd=s(uf,"Nas pr\xF3ximas duas se\xE7\xF5es, mostraremos como:"),uf.forEach(a),Xr=p(o),ze=n(o,"UL",{});var rl=l(ze);$o=n(rl,"LI",{});var nl=l($o);jd=s(nl,"Exportar um modelo suportado usando o pacote "),Qt=n(nl,"CODE",{});var ff=l(Qt);Nd=s(ff,"transformers.onnx"),ff.forEach(a),kd=s(nl,"."),nl.forEach(a),Td=p(rl),Jt=n(rl,"LI",{});var hf=l(Jt);wd=s(hf,"Exportar um modelo personalizado para uma arquitetura sem suporte."),hf.forEach(a),rl.forEach(a),Br=p(o),qe=n(o,"H2",{class:!0});var ll=l(qe);Me=n(ll,"A",{id:!0,class:!0,href:!0});var vf=l(Me);Yt=n(vf,"SPAN",{});var _f=l(Yt);x(Oo.$$.fragment,_f),_f.forEach(a),vf.forEach(a),Dd=p(ll),Zt=n(ll,"SPAN",{});var Ef=l(Zt);Cd=s(Ef,"Exportando um modelo para ONNX"),Ef.forEach(a),ll.forEach(a),Rr=p(o),Ta=n(o,"P",{});var gf=l(Ta);Pd=s(gf,`Para exportar um modelo \u{1F917} Transformers para o ONNX, primeiro voc\xEA precisa instalar algumas
depend\xEAncias extras:`),gf.forEach(a),Sr=p(o),x(bo.$$.fragment,o),Fr=p(o),Xe=n(o,"P",{});var il=l(Xe);Ld=s(il,"O pacote "),es=n(il,"CODE",{});var xf=l(es);Ad=s(xf,"transformers.onnx"),xf.forEach(a),yd=s(il," pode ent\xE3o ser usado como um m\xF3dulo Python:"),il.forEach(a),Vr=p(o),x(qo.$$.fragment,o),Hr=p(o),wa=n(o,"P",{});var $f=l(wa);Id=s($f,"A exporta\xE7\xE3o de um checkpoint usando uma configura\xE7\xE3o pronta pode ser feita da seguinte forma:"),$f.forEach(a),Gr=p(o),x(jo.$$.fragment,o),Ur=p(o),Da=n(o,"P",{});var Of=l(Da);zd=s(Of,"Voc\xEA deve ver os seguintes logs:"),Of.forEach(a),Wr=p(o),x(No.$$.fragment,o),Kr=p(o),ie=n(o,"P",{});var Ha=l(ie);Md=s(Ha,"Isso exporta um grafo ONNX do ponto de verifica\xE7\xE3o definido pelo argumento "),os=n(Ha,"CODE",{});var bf=l(os);Xd=s(bf,"--model"),bf.forEach(a),Bd=s(Ha,`. Nisso
Por exemplo, \xE9 `),as=n(Ha,"CODE",{});var qf=l(as);Rd=s(qf,"distilbert-base-uncased"),qf.forEach(a),Sd=s(Ha,`, mas pode ser qualquer checkpoint no Hugging
Face Hub ou um armazenado localmente.`),Ha.forEach(a),Qr=p(o),Y=n(o,"P",{});var ro=l(Y);Fd=s(ro,"O arquivo "),ts=n(ro,"CODE",{});var jf=l(ts);Vd=s(jf,"model.onnx"),jf.forEach(a),Hd=s(ro," resultante pode ser executado em um dos "),ko=n(ro,"A",{href:!0,rel:!0});var Nf=l(ko);Gd=s(Nf,`muitos
aceleradores`),Nf.forEach(a),Ud=s(ro,` que suportam o ONNX
padr\xE3o. Por exemplo, podemos carregar e executar o modelo com `),To=n(ro,"A",{href:!0,rel:!0});var kf=l(To);Wd=s(kf,`ONNX
Tempo de execu\xE7\xE3o`),kf.forEach(a),Kd=s(ro," da seguinte forma:"),ro.forEach(a),Jr=p(o),x(wo.$$.fragment,o),Yr=p(o),Be=n(o,"P",{});var dl=l(Be);Qd=s(dl,"Os nomes de sa\xEDda necess\xE1rios (como "),ss=n(dl,"CODE",{});var Tf=l(ss);Jd=s(Tf,'["last_hidden_state"]'),Tf.forEach(a),Yd=s(dl,`) podem ser obtidos pegando uma
configura\xE7\xE3o ONNX de cada modelo. Por exemplo, para DistilBERT temos:`),dl.forEach(a),Zr=p(o),x(Do.$$.fragment,o),en=p(o),Re=n(o,"P",{});var pl=l(Re);Zd=s(pl,`O processo \xE9 id\xEAntico para os checkpoints do TensorFlow no Hub. Por exemplo, podemos
exportar um checkpoint TensorFlow puro do `),Co=n(pl,"A",{href:!0,rel:!0});var wf=l(Co);ep=s(wf,"Keras"),wf.forEach(a),op=s(pl," da seguinte forma:"),pl.forEach(a),on=p(o),x(Po.$$.fragment,o),an=p(o),Ca=n(o,"P",{});var Df=l(Ca);ap=s(Df,`Para exportar um modelo armazenado localmente, voc\xEA precisar\xE1 ter os pesos e
arquivos tokenizer armazenados em um diret\xF3rio. Por exemplo, podemos carregar e salvar um checkpoint como:`),Df.forEach(a),tn=p(o),x(Lo.$$.fragment,o),sn=p(o),de=n(o,"P",{});var Ga=l(de);tp=s(Ga,"Uma vez que o checkpoint \xE9 salvo, podemos export\xE1-lo para o ONNX apontando o "),rs=n(Ga,"CODE",{});var Cf=l(rs);sp=s(Cf,"--model"),Cf.forEach(a),rp=s(Ga,`
argumento do pacote `),ns=n(Ga,"CODE",{});var Pf=l(ns);np=s(Pf,"transformers.onnx"),Pf.forEach(a),lp=s(Ga," para o diret\xF3rio desejado:"),Ga.forEach(a),rn=p(o),x(Ao.$$.fragment,o),nn=p(o),x(yo.$$.fragment,o),ln=p(o),pe=n(o,"P",{});var Ua=l(pe);ip=s(Ua,"Uma vez que o checkpoint \xE9 salvo, podemos export\xE1-lo para o ONNX apontando o "),ls=n(Ua,"CODE",{});var Lf=l(ls);dp=s(Lf,"--model"),Lf.forEach(a),pp=s(Ua,`
argumento do pacote `),is=n(Ua,"CODE",{});var Af=l(is);mp=s(Af,"transformers.onnx"),Af.forEach(a),cp=s(Ua," para o diret\xF3rio desejado:"),Ua.forEach(a),dn=p(o),x(Io.$$.fragment,o),pn=p(o),je=n(o,"H2",{class:!0});var ml=l(je);Se=n(ml,"A",{id:!0,class:!0,href:!0});var yf=l(Se);ds=n(yf,"SPAN",{});var If=l(ds);x(zo.$$.fragment,If),If.forEach(a),yf.forEach(a),up=p(ml),ps=n(ml,"SPAN",{});var zf=l(ps);fp=s(zf,"Selecionando features para diferentes tarefas do modelo"),zf.forEach(a),ml.forEach(a),mn=p(o),me=n(o,"P",{});var Wa=l(me);hp=s(Wa,"Cada configura\xE7\xE3o pronta vem com um conjunto de "),ms=n(Wa,"EM",{});var Mf=l(ms);vp=s(Mf,"features"),Mf.forEach(a),_p=s(Wa,` que permitem exportar
modelos para diferentes tipos de tarefas. Conforme mostrado na tabela abaixo, cada recurso \xE9
associado a uma `),cs=n(Wa,"CODE",{});var Xf=l(cs);Ep=s(Xf,"AutoClass"),Xf.forEach(a),gp=s(Wa," diferente:"),Wa.forEach(a),cn=p(o),Fe=n(o,"TABLE",{});var cl=l(Fe);us=n(cl,"THEAD",{});var Bf=l(us);Mo=n(Bf,"TR",{});var ul=l(Mo);fs=n(ul,"TH",{});var Rf=l(fs);xp=s(Rf,"Feature"),Rf.forEach(a),$p=p(ul),hs=n(ul,"TH",{});var Sf=l(hs);Op=s(Sf,"Auto Class"),Sf.forEach(a),ul.forEach(a),Bf.forEach(a),bp=p(cl),X=n(cl,"TBODY",{});var G=l(X);Xo=n(G,"TR",{});var fl=l(Xo);Bo=n(fl,"TD",{});var hl=l(Bo);vs=n(hl,"CODE",{});var Ff=l(vs);qp=s(Ff,"causal-lm"),Ff.forEach(a),jp=s(hl,", "),_s=n(hl,"CODE",{});var Vf=l(_s);Np=s(Vf,"causal-lm-with-past"),Vf.forEach(a),hl.forEach(a),kp=p(fl),Es=n(fl,"TD",{});var Hf=l(Es);gs=n(Hf,"CODE",{});var Gf=l(gs);Tp=s(Gf,"AutoModelForCausalLM"),Gf.forEach(a),Hf.forEach(a),fl.forEach(a),wp=p(G),Ro=n(G,"TR",{});var vl=l(Ro);So=n(vl,"TD",{});var _l=l(So);xs=n(_l,"CODE",{});var Uf=l(xs);Dp=s(Uf,"default"),Uf.forEach(a),Cp=s(_l,", "),$s=n(_l,"CODE",{});var Wf=l($s);Pp=s(Wf,"default-with-past"),Wf.forEach(a),_l.forEach(a),Lp=p(vl),Os=n(vl,"TD",{});var Kf=l(Os);bs=n(Kf,"CODE",{});var Qf=l(bs);Ap=s(Qf,"AutoModel"),Qf.forEach(a),Kf.forEach(a),vl.forEach(a),yp=p(G),Fo=n(G,"TR",{});var El=l(Fo);qs=n(El,"TD",{});var Jf=l(qs);js=n(Jf,"CODE",{});var Yf=l(js);Ip=s(Yf,"masked-lm"),Yf.forEach(a),Jf.forEach(a),zp=p(El),Ns=n(El,"TD",{});var Zf=l(Ns);ks=n(Zf,"CODE",{});var eh=l(ks);Mp=s(eh,"AutoModelForMaskedLM"),eh.forEach(a),Zf.forEach(a),El.forEach(a),Xp=p(G),Vo=n(G,"TR",{});var gl=l(Vo);Ts=n(gl,"TD",{});var oh=l(Ts);ws=n(oh,"CODE",{});var ah=l(ws);Bp=s(ah,"question-answering"),ah.forEach(a),oh.forEach(a),Rp=p(gl),Ds=n(gl,"TD",{});var th=l(Ds);Cs=n(th,"CODE",{});var sh=l(Cs);Sp=s(sh,"AutoModelForQuestionAnswering"),sh.forEach(a),th.forEach(a),gl.forEach(a),Fp=p(G),Ho=n(G,"TR",{});var xl=l(Ho);Go=n(xl,"TD",{});var $l=l(Go);Ps=n($l,"CODE",{});var rh=l(Ps);Vp=s(rh,"seq2seq-lm"),rh.forEach(a),Hp=s($l,", "),Ls=n($l,"CODE",{});var nh=l(Ls);Gp=s(nh,"seq2seq-lm-with-past"),nh.forEach(a),$l.forEach(a),Up=p(xl),As=n(xl,"TD",{});var lh=l(As);ys=n(lh,"CODE",{});var ih=l(ys);Wp=s(ih,"AutoModelForSeq2SeqLM"),ih.forEach(a),lh.forEach(a),xl.forEach(a),Kp=p(G),Uo=n(G,"TR",{});var Ol=l(Uo);Is=n(Ol,"TD",{});var dh=l(Is);zs=n(dh,"CODE",{});var ph=l(zs);Qp=s(ph,"sequence-classification"),ph.forEach(a),dh.forEach(a),Jp=p(Ol),Ms=n(Ol,"TD",{});var mh=l(Ms);Xs=n(mh,"CODE",{});var ch=l(Xs);Yp=s(ch,"AutoModelForSequenceClassification"),ch.forEach(a),mh.forEach(a),Ol.forEach(a),Zp=p(G),Wo=n(G,"TR",{});var bl=l(Wo);Bs=n(bl,"TD",{});var uh=l(Bs);Rs=n(uh,"CODE",{});var fh=l(Rs);em=s(fh,"token-classification"),fh.forEach(a),uh.forEach(a),om=p(bl),Ss=n(bl,"TD",{});var hh=l(Ss);Fs=n(hh,"CODE",{});var vh=l(Fs);am=s(vh,"AutoModelForTokenClassification"),vh.forEach(a),hh.forEach(a),bl.forEach(a),G.forEach(a),cl.forEach(a),un=p(o),Ve=n(o,"P",{});var ql=l(Ve);tm=s(ql,`Para cada configura\xE7\xE3o, voc\xEA pode encontrar a lista de recursos suportados por meio do
`),Vs=n(ql,"CODE",{});var _h=l(Vs);sm=s(_h,"FeaturesManager"),_h.forEach(a),rm=s(ql,". Por exemplo, para DistilBERT temos:"),ql.forEach(a),fn=p(o),x(Ko.$$.fragment,o),hn=p(o),ce=n(o,"P",{});var Ka=l(ce);nm=s(Ka,"Voc\xEA pode ent\xE3o passar um desses recursos para o argumento "),Hs=n(Ka,"CODE",{});var Eh=l(Hs);lm=s(Eh,"--feature"),Eh.forEach(a),im=s(Ka,` no
pacote `),Gs=n(Ka,"CODE",{});var gh=l(Gs);dm=s(gh,"transformers.onnx"),gh.forEach(a),pm=s(Ka,`. Por exemplo, para exportar um modelo de classifica\xE7\xE3o de texto, podemos
escolher um modelo ajustado no Hub e executar:`),Ka.forEach(a),vn=p(o),x(Qo.$$.fragment,o),_n=p(o),Pa=n(o,"P",{});var xh=l(Pa);mm=s(xh,"Isso exibe os seguintes logs:"),xh.forEach(a),En=p(o),x(Jo.$$.fragment,o),gn=p(o),Z=n(o,"P",{});var no=l(Z);cm=s(no,"Observe que, neste caso, os nomes de sa\xEDda do modelo ajustado s\xE3o "),Us=n(no,"CODE",{});var $h=l(Us);um=s($h,"logits"),$h.forEach(a),fm=s(no,`
em vez do `),Ws=n(no,"CODE",{});var Oh=l(Ws);hm=s(Oh,"last_hidden_state"),Oh.forEach(a),vm=s(no," que vimos com o checkpoint "),Ks=n(no,"CODE",{});var bh=l(Ks);_m=s(bh,"distilbert-base-uncased"),bh.forEach(a),Em=s(no,`
mais cedo. Isso \xE9 esperado, pois o modelo ajustado (fine-tuned) possui uma cabe\xE7a de classifica\xE7\xE3o de sequ\xEAncia.`),no.forEach(a),xn=p(o),x(He.$$.fragment,o),$n=p(o),x(Ge.$$.fragment,o),On=p(o),Ne=n(o,"H2",{class:!0});var jl=l(Ne);Ue=n(jl,"A",{id:!0,class:!0,href:!0});var qh=l(Ue);Qs=n(qh,"SPAN",{});var jh=l(Qs);x(Yo.$$.fragment,jh),jh.forEach(a),qh.forEach(a),gm=p(jl),Js=n(jl,"SPAN",{});var Nh=l(Js);xm=s(Nh,"Exportando um modelo para uma arquitetura sem suporte"),Nh.forEach(a),jl.forEach(a),bn=p(o),La=n(o,"P",{});var kh=l(La);$m=s(kh,`Se voc\xEA deseja exportar um modelo cuja arquitetura n\xE3o \xE9 suportada nativamente pela
biblioteca, h\xE1 tr\xEAs etapas principais a seguir:`),kh.forEach(a),qn=p(o),ue=n(o,"OL",{});var Qa=l(ue);Ys=n(Qa,"LI",{});var Th=l(Ys);Om=s(Th,"Implemente uma configura\xE7\xE3o ONNX personalizada."),Th.forEach(a),bm=p(Qa),Zs=n(Qa,"LI",{});var wh=l(Zs);qm=s(wh,"Exporte o modelo para o ONNX."),wh.forEach(a),jm=p(Qa),er=n(Qa,"LI",{});var Dh=l(er);Nm=s(Dh,"Valide as sa\xEDdas do PyTorch e dos modelos exportados."),Dh.forEach(a),Qa.forEach(a),jn=p(o),Aa=n(o,"P",{});var Ch=l(Aa);km=s(Ch,`Nesta se\xE7\xE3o, veremos como o DistilBERT foi implementado para mostrar o que est\xE1 envolvido
em cada passo.`),Ch.forEach(a),Nn=p(o),ke=n(o,"H3",{class:!0});var Nl=l(ke);We=n(Nl,"A",{id:!0,class:!0,href:!0});var Ph=l(We);or=n(Ph,"SPAN",{});var Lh=l(or);x(Zo.$$.fragment,Lh),Lh.forEach(a),Ph.forEach(a),Tm=p(Nl),ar=n(Nl,"SPAN",{});var Ah=l(ar);wm=s(Ah,"Implementando uma configura\xE7\xE3o ONNX personalizada"),Ah.forEach(a),Nl.forEach(a),kn=p(o),ya=n(o,"P",{});var yh=l(ya);Dm=s(yh,`Vamos come\xE7ar com o objeto de configura\xE7\xE3o ONNX. Fornecemos tr\xEAs classes abstratas que
voc\xEA deve herdar, dependendo do tipo de arquitetura de modelo que deseja exportar:`),yh.forEach(a),Tn=p(o),fe=n(o,"UL",{});var Ja=l(fe);Ia=n(Ja,"LI",{});var Yc=l(Ia);Cm=s(Yc,"Modelos baseados em codificador herdam de "),tr=n(Yc,"CODE",{});var Ih=l(tr);Pm=s(Ih,"OnnxConfig"),Ih.forEach(a),Yc.forEach(a),Lm=p(Ja),za=n(Ja,"LI",{});var Zc=l(za);Am=s(Zc,"Modelos baseados em decodificador herdam de "),sr=n(Zc,"CODE",{});var zh=l(sr);ym=s(zh,"OnnxConfigWithPast"),zh.forEach(a),Zc.forEach(a),Im=p(Ja),Ma=n(Ja,"LI",{});var eu=l(Ma);zm=s(eu,"Os modelos codificador-decodificador herdam de "),rr=n(eu,"CODE",{});var Mh=l(rr);Mm=s(Mh,"OnnxSeq2SeqConfigWithPast"),Mh.forEach(a),eu.forEach(a),Ja.forEach(a),wn=p(o),x(Ke.$$.fragment,o),Dn=p(o),Qe=n(o,"P",{});var kl=l(Qe);Xm=s(kl,`Como o DistilBERT \xE9 um modelo baseado em codificador, sua configura\xE7\xE3o \xE9 herdada de
`),nr=n(kl,"CODE",{});var Xh=l(nr);Bm=s(Xh,"OnnxConfig"),Xh.forEach(a),Rm=s(kl,":"),kl.forEach(a),Cn=p(o),x(ea.$$.fragment,o),Pn=p(o),V=n(o,"P",{});var Ee=l(V);Sm=s(Ee,"Todo objeto de configura\xE7\xE3o deve implementar a propriedade "),lr=n(Ee,"CODE",{});var Bh=l(lr);Fm=s(Bh,"inputs"),Bh.forEach(a),Vm=s(Ee,` e retornar um mapeamento,
onde cada chave corresponde a uma entrada esperada e cada valor indica o eixo
dessa entrada. Para o DistilBERT, podemos ver que duas entradas s\xE3o necess\xE1rias: `),ir=n(Ee,"CODE",{});var Rh=l(ir);Hm=s(Rh,"input_ids"),Rh.forEach(a),Gm=s(Ee,` e
`),dr=n(Ee,"CODE",{});var Sh=l(dr);Um=s(Sh,"attention_mask"),Sh.forEach(a),Wm=s(Ee,". Essas entradas t\xEAm a mesma forma de "),pr=n(Ee,"CODE",{});var Fh=l(pr);Km=s(Fh,"(batch_size, sequence_length)"),Fh.forEach(a),Qm=s(Ee,`
\xE9 por isso que vemos os mesmos eixos usados na configura\xE7\xE3o.`),Ee.forEach(a),Ln=p(o),x(Je.$$.fragment,o),An=p(o),Xa=n(o,"P",{});var Vh=l(Xa);Jm=s(Vh,`Depois de implementar uma configura\xE7\xE3o ONNX, voc\xEA pode instanci\xE1-la fornecendo a
configura\xE7\xE3o do modelo base da seguinte forma:`),Vh.forEach(a),yn=p(o),x(oa.$$.fragment,o),In=p(o),Ba=n(o,"P",{});var Hh=l(Ba);Ym=s(Hh,`O objeto resultante tem v\xE1rias propriedades \xFAteis. Por exemplo, voc\xEA pode visualizar o conjunto de operadores ONNX
que ser\xE1 usado durante a exporta\xE7\xE3o:`),Hh.forEach(a),zn=p(o),x(aa.$$.fragment,o),Mn=p(o),Ra=n(o,"P",{});var Gh=l(Ra);Zm=s(Gh,"Voc\xEA tamb\xE9m pode visualizar as sa\xEDdas associadas ao modelo da seguinte forma:"),Gh.forEach(a),Xn=p(o),x(ta.$$.fragment,o),Bn=p(o),H=n(o,"P",{});var ge=l(H);ec=s(ge,`Observe que a propriedade outputs segue a mesma estrutura das entradas; ele retorna um
`),mr=n(ge,"CODE",{});var Uh=l(mr);oc=s(Uh,"OrderedDict"),Uh.forEach(a),ac=s(ge,` de sa\xEDdas nomeadas e suas formas. A estrutura de sa\xEDda est\xE1 ligada a
escolha do recurso com o qual a configura\xE7\xE3o \xE9 inicializada. Por padr\xE3o, a configura\xE7\xE3o do ONNX
\xE9 inicializada com o recurso `),cr=n(ge,"CODE",{});var Wh=l(cr);tc=s(Wh,"default"),Wh.forEach(a),sc=s(ge,` que corresponde \xE0 exporta\xE7\xE3o de um
modelo carregado com a classe `),ur=n(ge,"CODE",{});var Kh=l(ur);rc=s(Kh,"AutoModel"),Kh.forEach(a),nc=s(ge,`. Se voc\xEA deseja exportar um modelo para outra tarefa,
apenas forne\xE7a um recurso diferente para o argumento `),fr=n(ge,"CODE",{});var Qh=l(fr);lc=s(Qh,"task"),Qh.forEach(a),ic=s(ge,` quando voc\xEA inicializar a configura\xE7\xE3o ONNX
. Por exemplo, se quisermos exportar o DistilBERT com uma sequ\xEAncia
de classifica\xE7\xE3o, poder\xEDamos usar:`),ge.forEach(a),Rn=p(o),x(sa.$$.fragment,o),Sn=p(o),x(Ye.$$.fragment,o),Fn=p(o),Te=n(o,"H3",{class:!0});var Tl=l(Te);Ze=n(Tl,"A",{id:!0,class:!0,href:!0});var Jh=l(Ze);hr=n(Jh,"SPAN",{});var Yh=l(hr);x(ra.$$.fragment,Yh),Yh.forEach(a),Jh.forEach(a),dc=p(Tl),vr=n(Tl,"SPAN",{});var Zh=l(vr);pc=s(Zh,"Exportando um modelo"),Zh.forEach(a),Tl.forEach(a),Vn=p(o),he=n(o,"P",{});var Ya=l(he);mc=s(Ya,`Depois de ter implementado a configura\xE7\xE3o do ONNX, o pr\xF3ximo passo \xE9 exportar o modelo.
Aqui podemos usar a fun\xE7\xE3o `),_r=n(Ya,"CODE",{});var ev=l(_r);cc=s(ev,"export()"),ev.forEach(a),uc=s(Ya," fornecida pelo pacote "),Er=n(Ya,"CODE",{});var ov=l(Er);fc=s(ov,"transformers.onnx"),ov.forEach(a),hc=s(Ya,`.
Esta fun\xE7\xE3o espera a configura\xE7\xE3o do ONNX, juntamente com o modelo base e o tokenizer,
e o caminho para salvar o arquivo exportado:`),Ya.forEach(a),Hn=p(o),x(na.$$.fragment,o),Gn=p(o),R=n(o,"P",{});var ee=l(R);vc=s(ee,"Os "),gr=n(ee,"CODE",{});var av=l(gr);_c=s(av,"onnx_inputs"),av.forEach(a),Ec=s(ee," e "),xr=n(ee,"CODE",{});var tv=l(xr);gc=s(tv,"onnx_outputs"),tv.forEach(a),xc=s(ee," retornados pela fun\xE7\xE3o "),$r=n(ee,"CODE",{});var sv=l($r);$c=s(sv,"export()"),sv.forEach(a),Oc=s(ee,` s\xE3o listas de
chaves definidas nas propriedades `),Or=n(ee,"CODE",{});var rv=l(Or);bc=s(rv,"inputs"),rv.forEach(a),qc=s(ee," e "),br=n(ee,"CODE",{});var nv=l(br);jc=s(nv,"outputs"),nv.forEach(a),Nc=s(ee,` da configura\xE7\xE3o. Uma vez que o
modelo \xE9 exportado, voc\xEA pode testar se o modelo est\xE1 bem formado da seguinte forma:`),ee.forEach(a),Un=p(o),x(la.$$.fragment,o),Wn=p(o),x(eo.$$.fragment,o),Kn=p(o),we=n(o,"H3",{class:!0});var wl=l(we);oo=n(wl,"A",{id:!0,class:!0,href:!0});var lv=l(oo);qr=n(lv,"SPAN",{});var iv=l(qr);x(ia.$$.fragment,iv),iv.forEach(a),lv.forEach(a),kc=p(wl),jr=n(wl,"SPAN",{});var dv=l(jr);Tc=s(dv,"Validando a sa\xEDda dos modelos"),dv.forEach(a),wl.forEach(a),Qn=p(o),ve=n(o,"P",{});var Za=l(ve);wc=s(Za,`A etapa final \xE9 validar se as sa\xEDdas do modelo base e exportado concordam
dentro de alguma toler\xE2ncia absoluta. Aqui podemos usar a fun\xE7\xE3o `),Nr=n(Za,"CODE",{});var pv=l(Nr);Dc=s(pv,"validate_model_outputs()"),pv.forEach(a),Cc=s(Za,`
fornecida pelo pacote `),kr=n(Za,"CODE",{});var mv=l(kr);Pc=s(mv,"transformers.onnx"),mv.forEach(a),Lc=s(Za," da seguinte forma:"),Za.forEach(a),Jn=p(o),x(da.$$.fragment,o),Yn=p(o),ao=n(o,"P",{});var Dl=l(ao);Ac=s(Dl,"Esta fun\xE7\xE3o usa o m\xE9todo "),Tr=n(Dl,"CODE",{});var cv=l(Tr);yc=s(cv,"generate_dummy_inputs()"),cv.forEach(a),Ic=s(Dl,` para
gerar entradas para o modelo base e o exportado, e a toler\xE2ncia absoluta pode ser
definida na configura\xE7\xE3o. Geralmente encontramos concord\xE2ncia num\xE9rica em 1e-6 a 1e-4
de alcance, embora qualquer coisa menor que 1e-3 provavelmente esteja OK.`),Dl.forEach(a),Zn=p(o),De=n(o,"H2",{class:!0});var Cl=l(De);to=n(Cl,"A",{id:!0,class:!0,href:!0});var uv=l(to);wr=n(uv,"SPAN",{});var fv=l(wr);x(pa.$$.fragment,fv),fv.forEach(a),uv.forEach(a),zc=p(Cl),Dr=n(Cl,"SPAN",{});var hv=l(Dr);Mc=s(hv,"Contribuindo com uma nova configura\xE7\xE3o para \u{1F917} Transformers"),hv.forEach(a),Cl.forEach(a),el=p(o),Sa=n(o,"P",{});var vv=l(Sa);Xc=s(vv,`Estamos procurando expandir o conjunto de configura\xE7\xF5es prontas e receber contribui\xE7\xF5es
da comunidade! Se voc\xEA gostaria de contribuir para a biblioteca, voc\xEA
precisar\xE1:`),vv.forEach(a),ol=p(o),_e=n(o,"UL",{});var et=l(_e);ma=n(et,"LI",{});var Pl=l(ma);Bc=s(Pl,"Implemente a configura\xE7\xE3o do ONNX no arquivo "),Cr=n(Pl,"CODE",{});var _v=l(Cr);Rc=s(_v,"configuration_<model_name>.py"),_v.forEach(a),Sc=s(Pl,` correspondente
Arquivo`),Pl.forEach(a),Fc=p(et),Fa=n(et,"LI",{});var ou=l(Fa);Vc=s(ou,`Incluir a arquitetura do modelo e recursos correspondentes em
`),Pr=n(ou,"CODE",{});var Ev=l(Pr);Hc=s(Ev,"~onnx.features.FeatureManager"),Ev.forEach(a),ou.forEach(a),Gc=p(et),Va=n(et,"LI",{});var au=l(Va);Uc=s(au,"Adicione sua arquitetura de modelo aos testes em "),Lr=n(au,"CODE",{});var gv=l(Lr);Wc=s(gv,"test_onnx_v2.py"),gv.forEach(a),au.forEach(a),et.forEach(a),al=p(o),so=n(o,"P",{});var Ll=l(so);Kc=s(Ll,"Confira como ficou a configura\xE7\xE3o do "),ca=n(Ll,"A",{href:!0,rel:!0});var xv=l(ca);Qc=s(xv,"IBERT"),xv.forEach(a),Jc=s(Ll,` para obter uma
id\xE9ia do que est\xE1 envolvido.`),Ll.forEach(a),this.h()},h(){_(f,"name","hf:doc:metadata"),_(f,"content",JSON.stringify(Av)),_(j,"id","exportando-modelos-para-onnx"),_(j,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(j,"href","#exportando-modelos-para-onnx"),_(h,"class","relative group"),_(w,"href","http://onnx.ai"),_(w,"rel","nofollow"),_(J,"href","main_classes/onnx"),_(Me,"id","exportando-um-modelo-para-onnx"),_(Me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Me,"href","#exportando-um-modelo-para-onnx"),_(qe,"class","relative group"),_(ko,"href","https://onnx.ai/supported-tools.html#deployModel"),_(ko,"rel","nofollow"),_(To,"href","https://onnxruntime.ai/"),_(To,"rel","nofollow"),_(Co,"href","https://huggingface.co/keras-io"),_(Co,"rel","nofollow"),_(Se,"id","selecionando-features-para-diferentes-tarefas-do-modelo"),_(Se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Se,"href","#selecionando-features-para-diferentes-tarefas-do-modelo"),_(je,"class","relative group"),_(Ue,"id","exportando-um-modelo-para-uma-arquitetura-sem-suporte"),_(Ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Ue,"href","#exportando-um-modelo-para-uma-arquitetura-sem-suporte"),_(Ne,"class","relative group"),_(We,"id","implementando-uma-configurao-onnx-personalizada"),_(We,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(We,"href","#implementando-uma-configurao-onnx-personalizada"),_(ke,"class","relative group"),_(Ze,"id","exportando-um-modelo"),_(Ze,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Ze,"href","#exportando-um-modelo"),_(Te,"class","relative group"),_(oo,"id","validando-a-sada-dos-modelos"),_(oo,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(oo,"href","#validando-a-sada-dos-modelos"),_(we,"class","relative group"),_(to,"id","contribuindo-com-uma-nova-configurao-para-transformers"),_(to,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(to,"href","#contribuindo-com-uma-nova-configurao-para-transformers"),_(De,"class","relative group"),_(ca,"href","https://github.com/huggingface/transformers/pull/14868/files"),_(ca,"rel","nofollow")},m(o,i){e(document.head,f),m(o,D,i),m(o,h,i),e(h,j),e(j,T),$(v,T,null),e(h,E),e(h,C),e(C,N),m(o,k,i),m(o,A,i),e(A,P),e(A,w),e(w,U),e(A,S),m(o,F,i),$(W,o,i),m(o,re,i),m(o,K,i),e(K,io),e(K,oe),e(oe,po),e(K,mo),m(o,xe,i),m(o,L,i),e(L,co),m(o,ne,i),m(o,Q,i),e(Q,uo),e(Q,J),e(J,$e),e($e,fo),e(Q,Oe),m(o,Ce,i),m(o,le,i),e(le,be),m(o,Pe,i),m(o,c,i),e(c,ae),e(ae,ho),e(c,vo),e(c,te),e(te,_o),e(c,Eo),e(c,se),e(se,go),e(c,xo),e(c,M),e(M,y),e(c,_a),e(c,Le),e(Le,Ea),e(c,ga),e(c,Ae),e(Ae,xa),e(c,$a),e(c,I),e(I,Oa),e(c,ba),e(c,ye),e(ye,qa),e(c,ja),e(c,Ie),e(Ie,Na),e(c,Al),e(c,ot),e(ot,yl),e(c,Il),e(c,at),e(at,zl),e(c,Ml),e(c,tt),e(tt,Xl),e(c,Bl),e(c,st),e(st,Rl),e(c,Sl),e(c,rt),e(rt,Fl),e(c,Vl),e(c,nt),e(nt,Hl),e(c,Gl),e(c,lt),e(lt,Ul),e(c,Wl),e(c,it),e(it,Kl),e(c,Ql),e(c,dt),e(dt,Jl),e(c,Yl),e(c,pt),e(pt,Zl),e(c,ei),e(c,mt),e(mt,oi),e(c,ai),e(c,ct),e(ct,ti),e(c,si),e(c,ut),e(ut,ri),e(c,ni),e(c,ft),e(ft,li),e(c,ii),e(c,ht),e(ht,di),e(c,pi),e(c,vt),e(vt,mi),e(c,ci),e(c,_t),e(_t,ui),e(c,fi),e(c,Et),e(Et,hi),e(c,vi),e(c,gt),e(gt,_i),e(c,Ei),e(c,xt),e(xt,gi),e(c,xi),e(c,$t),e($t,$i),e(c,Oi),e(c,Ot),e(Ot,bi),e(c,qi),e(c,bt),e(bt,ji),e(c,Ni),e(c,qt),e(qt,ki),e(c,Ti),e(c,jt),e(jt,wi),e(c,Di),e(c,Nt),e(Nt,Ci),e(c,Pi),e(c,kt),e(kt,Li),e(c,Ai),e(c,Tt),e(Tt,yi),e(c,Ii),e(c,wt),e(wt,zi),e(c,Mi),e(c,Dt),e(Dt,Xi),e(c,Bi),e(c,Ct),e(Ct,Ri),e(c,Si),e(c,Pt),e(Pt,Fi),e(c,Vi),e(c,Lt),e(Lt,Hi),e(c,Gi),e(c,At),e(At,Ui),e(c,Wi),e(c,yt),e(yt,Ki),e(c,Qi),e(c,It),e(It,Ji),e(c,Yi),e(c,zt),e(zt,Zi),e(c,ed),e(c,Mt),e(Mt,od),e(c,ad),e(c,Xt),e(Xt,td),e(c,sd),e(c,Bt),e(Bt,rd),e(c,nd),e(c,Rt),e(Rt,ld),e(c,id),e(c,St),e(St,dd),e(c,pd),e(c,Ft),e(Ft,md),e(c,cd),e(c,Vt),e(Vt,ud),e(c,fd),e(c,Ht),e(Ht,hd),e(c,vd),e(c,Gt),e(Gt,_d),e(c,Ed),e(c,Ut),e(Ut,gd),e(c,xd),e(c,Wt),e(Wt,$d),e(c,Od),e(c,Kt),e(Kt,bd),m(o,Mr,i),m(o,ka,i),e(ka,qd),m(o,Xr,i),m(o,ze,i),e(ze,$o),e($o,jd),e($o,Qt),e(Qt,Nd),e($o,kd),e(ze,Td),e(ze,Jt),e(Jt,wd),m(o,Br,i),m(o,qe,i),e(qe,Me),e(Me,Yt),$(Oo,Yt,null),e(qe,Dd),e(qe,Zt),e(Zt,Cd),m(o,Rr,i),m(o,Ta,i),e(Ta,Pd),m(o,Sr,i),$(bo,o,i),m(o,Fr,i),m(o,Xe,i),e(Xe,Ld),e(Xe,es),e(es,Ad),e(Xe,yd),m(o,Vr,i),$(qo,o,i),m(o,Hr,i),m(o,wa,i),e(wa,Id),m(o,Gr,i),$(jo,o,i),m(o,Ur,i),m(o,Da,i),e(Da,zd),m(o,Wr,i),$(No,o,i),m(o,Kr,i),m(o,ie,i),e(ie,Md),e(ie,os),e(os,Xd),e(ie,Bd),e(ie,as),e(as,Rd),e(ie,Sd),m(o,Qr,i),m(o,Y,i),e(Y,Fd),e(Y,ts),e(ts,Vd),e(Y,Hd),e(Y,ko),e(ko,Gd),e(Y,Ud),e(Y,To),e(To,Wd),e(Y,Kd),m(o,Jr,i),$(wo,o,i),m(o,Yr,i),m(o,Be,i),e(Be,Qd),e(Be,ss),e(ss,Jd),e(Be,Yd),m(o,Zr,i),$(Do,o,i),m(o,en,i),m(o,Re,i),e(Re,Zd),e(Re,Co),e(Co,ep),e(Re,op),m(o,on,i),$(Po,o,i),m(o,an,i),m(o,Ca,i),e(Ca,ap),m(o,tn,i),$(Lo,o,i),m(o,sn,i),m(o,de,i),e(de,tp),e(de,rs),e(rs,sp),e(de,rp),e(de,ns),e(ns,np),e(de,lp),m(o,rn,i),$(Ao,o,i),m(o,nn,i),$(yo,o,i),m(o,ln,i),m(o,pe,i),e(pe,ip),e(pe,ls),e(ls,dp),e(pe,pp),e(pe,is),e(is,mp),e(pe,cp),m(o,dn,i),$(Io,o,i),m(o,pn,i),m(o,je,i),e(je,Se),e(Se,ds),$(zo,ds,null),e(je,up),e(je,ps),e(ps,fp),m(o,mn,i),m(o,me,i),e(me,hp),e(me,ms),e(ms,vp),e(me,_p),e(me,cs),e(cs,Ep),e(me,gp),m(o,cn,i),m(o,Fe,i),e(Fe,us),e(us,Mo),e(Mo,fs),e(fs,xp),e(Mo,$p),e(Mo,hs),e(hs,Op),e(Fe,bp),e(Fe,X),e(X,Xo),e(Xo,Bo),e(Bo,vs),e(vs,qp),e(Bo,jp),e(Bo,_s),e(_s,Np),e(Xo,kp),e(Xo,Es),e(Es,gs),e(gs,Tp),e(X,wp),e(X,Ro),e(Ro,So),e(So,xs),e(xs,Dp),e(So,Cp),e(So,$s),e($s,Pp),e(Ro,Lp),e(Ro,Os),e(Os,bs),e(bs,Ap),e(X,yp),e(X,Fo),e(Fo,qs),e(qs,js),e(js,Ip),e(Fo,zp),e(Fo,Ns),e(Ns,ks),e(ks,Mp),e(X,Xp),e(X,Vo),e(Vo,Ts),e(Ts,ws),e(ws,Bp),e(Vo,Rp),e(Vo,Ds),e(Ds,Cs),e(Cs,Sp),e(X,Fp),e(X,Ho),e(Ho,Go),e(Go,Ps),e(Ps,Vp),e(Go,Hp),e(Go,Ls),e(Ls,Gp),e(Ho,Up),e(Ho,As),e(As,ys),e(ys,Wp),e(X,Kp),e(X,Uo),e(Uo,Is),e(Is,zs),e(zs,Qp),e(Uo,Jp),e(Uo,Ms),e(Ms,Xs),e(Xs,Yp),e(X,Zp),e(X,Wo),e(Wo,Bs),e(Bs,Rs),e(Rs,em),e(Wo,om),e(Wo,Ss),e(Ss,Fs),e(Fs,am),m(o,un,i),m(o,Ve,i),e(Ve,tm),e(Ve,Vs),e(Vs,sm),e(Ve,rm),m(o,fn,i),$(Ko,o,i),m(o,hn,i),m(o,ce,i),e(ce,nm),e(ce,Hs),e(Hs,lm),e(ce,im),e(ce,Gs),e(Gs,dm),e(ce,pm),m(o,vn,i),$(Qo,o,i),m(o,_n,i),m(o,Pa,i),e(Pa,mm),m(o,En,i),$(Jo,o,i),m(o,gn,i),m(o,Z,i),e(Z,cm),e(Z,Us),e(Us,um),e(Z,fm),e(Z,Ws),e(Ws,hm),e(Z,vm),e(Z,Ks),e(Ks,_m),e(Z,Em),m(o,xn,i),$(He,o,i),m(o,$n,i),$(Ge,o,i),m(o,On,i),m(o,Ne,i),e(Ne,Ue),e(Ue,Qs),$(Yo,Qs,null),e(Ne,gm),e(Ne,Js),e(Js,xm),m(o,bn,i),m(o,La,i),e(La,$m),m(o,qn,i),m(o,ue,i),e(ue,Ys),e(Ys,Om),e(ue,bm),e(ue,Zs),e(Zs,qm),e(ue,jm),e(ue,er),e(er,Nm),m(o,jn,i),m(o,Aa,i),e(Aa,km),m(o,Nn,i),m(o,ke,i),e(ke,We),e(We,or),$(Zo,or,null),e(ke,Tm),e(ke,ar),e(ar,wm),m(o,kn,i),m(o,ya,i),e(ya,Dm),m(o,Tn,i),m(o,fe,i),e(fe,Ia),e(Ia,Cm),e(Ia,tr),e(tr,Pm),e(fe,Lm),e(fe,za),e(za,Am),e(za,sr),e(sr,ym),e(fe,Im),e(fe,Ma),e(Ma,zm),e(Ma,rr),e(rr,Mm),m(o,wn,i),$(Ke,o,i),m(o,Dn,i),m(o,Qe,i),e(Qe,Xm),e(Qe,nr),e(nr,Bm),e(Qe,Rm),m(o,Cn,i),$(ea,o,i),m(o,Pn,i),m(o,V,i),e(V,Sm),e(V,lr),e(lr,Fm),e(V,Vm),e(V,ir),e(ir,Hm),e(V,Gm),e(V,dr),e(dr,Um),e(V,Wm),e(V,pr),e(pr,Km),e(V,Qm),m(o,Ln,i),$(Je,o,i),m(o,An,i),m(o,Xa,i),e(Xa,Jm),m(o,yn,i),$(oa,o,i),m(o,In,i),m(o,Ba,i),e(Ba,Ym),m(o,zn,i),$(aa,o,i),m(o,Mn,i),m(o,Ra,i),e(Ra,Zm),m(o,Xn,i),$(ta,o,i),m(o,Bn,i),m(o,H,i),e(H,ec),e(H,mr),e(mr,oc),e(H,ac),e(H,cr),e(cr,tc),e(H,sc),e(H,ur),e(ur,rc),e(H,nc),e(H,fr),e(fr,lc),e(H,ic),m(o,Rn,i),$(sa,o,i),m(o,Sn,i),$(Ye,o,i),m(o,Fn,i),m(o,Te,i),e(Te,Ze),e(Ze,hr),$(ra,hr,null),e(Te,dc),e(Te,vr),e(vr,pc),m(o,Vn,i),m(o,he,i),e(he,mc),e(he,_r),e(_r,cc),e(he,uc),e(he,Er),e(Er,fc),e(he,hc),m(o,Hn,i),$(na,o,i),m(o,Gn,i),m(o,R,i),e(R,vc),e(R,gr),e(gr,_c),e(R,Ec),e(R,xr),e(xr,gc),e(R,xc),e(R,$r),e($r,$c),e(R,Oc),e(R,Or),e(Or,bc),e(R,qc),e(R,br),e(br,jc),e(R,Nc),m(o,Un,i),$(la,o,i),m(o,Wn,i),$(eo,o,i),m(o,Kn,i),m(o,we,i),e(we,oo),e(oo,qr),$(ia,qr,null),e(we,kc),e(we,jr),e(jr,Tc),m(o,Qn,i),m(o,ve,i),e(ve,wc),e(ve,Nr),e(Nr,Dc),e(ve,Cc),e(ve,kr),e(kr,Pc),e(ve,Lc),m(o,Jn,i),$(da,o,i),m(o,Yn,i),m(o,ao,i),e(ao,Ac),e(ao,Tr),e(Tr,yc),e(ao,Ic),m(o,Zn,i),m(o,De,i),e(De,to),e(to,wr),$(pa,wr,null),e(De,zc),e(De,Dr),e(Dr,Mc),m(o,el,i),m(o,Sa,i),e(Sa,Xc),m(o,ol,i),m(o,_e,i),e(_e,ma),e(ma,Bc),e(ma,Cr),e(Cr,Rc),e(ma,Sc),e(_e,Fc),e(_e,Fa),e(Fa,Vc),e(Fa,Pr),e(Pr,Hc),e(_e,Gc),e(_e,Va),e(Va,Uc),e(Va,Lr),e(Lr,Wc),m(o,al,i),m(o,so,i),e(so,Kc),e(so,ca),e(ca,Qc),e(so,Jc),tl=!0},p(o,[i]){const ua={};i&2&&(ua.$$scope={dirty:i,ctx:o}),W.$set(ua);const Ar={};i&2&&(Ar.$$scope={dirty:i,ctx:o}),He.$set(Ar);const yr={};i&2&&(yr.$$scope={dirty:i,ctx:o}),Ge.$set(yr);const Ir={};i&2&&(Ir.$$scope={dirty:i,ctx:o}),Ke.$set(Ir);const fa={};i&2&&(fa.$$scope={dirty:i,ctx:o}),Je.$set(fa);const zr={};i&2&&(zr.$$scope={dirty:i,ctx:o}),Ye.$set(zr);const ha={};i&2&&(ha.$$scope={dirty:i,ctx:o}),eo.$set(ha)},i(o){tl||(O(v.$$.fragment,o),O(W.$$.fragment,o),O(Oo.$$.fragment,o),O(bo.$$.fragment,o),O(qo.$$.fragment,o),O(jo.$$.fragment,o),O(No.$$.fragment,o),O(wo.$$.fragment,o),O(Do.$$.fragment,o),O(Po.$$.fragment,o),O(Lo.$$.fragment,o),O(Ao.$$.fragment,o),O(yo.$$.fragment,o),O(Io.$$.fragment,o),O(zo.$$.fragment,o),O(Ko.$$.fragment,o),O(Qo.$$.fragment,o),O(Jo.$$.fragment,o),O(He.$$.fragment,o),O(Ge.$$.fragment,o),O(Yo.$$.fragment,o),O(Zo.$$.fragment,o),O(Ke.$$.fragment,o),O(ea.$$.fragment,o),O(Je.$$.fragment,o),O(oa.$$.fragment,o),O(aa.$$.fragment,o),O(ta.$$.fragment,o),O(sa.$$.fragment,o),O(Ye.$$.fragment,o),O(ra.$$.fragment,o),O(na.$$.fragment,o),O(la.$$.fragment,o),O(eo.$$.fragment,o),O(ia.$$.fragment,o),O(da.$$.fragment,o),O(pa.$$.fragment,o),tl=!0)},o(o){b(v.$$.fragment,o),b(W.$$.fragment,o),b(Oo.$$.fragment,o),b(bo.$$.fragment,o),b(qo.$$.fragment,o),b(jo.$$.fragment,o),b(No.$$.fragment,o),b(wo.$$.fragment,o),b(Do.$$.fragment,o),b(Po.$$.fragment,o),b(Lo.$$.fragment,o),b(Ao.$$.fragment,o),b(yo.$$.fragment,o),b(Io.$$.fragment,o),b(zo.$$.fragment,o),b(Ko.$$.fragment,o),b(Qo.$$.fragment,o),b(Jo.$$.fragment,o),b(He.$$.fragment,o),b(Ge.$$.fragment,o),b(Yo.$$.fragment,o),b(Zo.$$.fragment,o),b(Ke.$$.fragment,o),b(ea.$$.fragment,o),b(Je.$$.fragment,o),b(oa.$$.fragment,o),b(aa.$$.fragment,o),b(ta.$$.fragment,o),b(sa.$$.fragment,o),b(Ye.$$.fragment,o),b(ra.$$.fragment,o),b(na.$$.fragment,o),b(la.$$.fragment,o),b(eo.$$.fragment,o),b(ia.$$.fragment,o),b(da.$$.fragment,o),b(pa.$$.fragment,o),tl=!1},d(o){a(f),o&&a(D),o&&a(h),q(v),o&&a(k),o&&a(A),o&&a(F),q(W,o),o&&a(re),o&&a(K),o&&a(xe),o&&a(L),o&&a(ne),o&&a(Q),o&&a(Ce),o&&a(le),o&&a(Pe),o&&a(c),o&&a(Mr),o&&a(ka),o&&a(Xr),o&&a(ze),o&&a(Br),o&&a(qe),q(Oo),o&&a(Rr),o&&a(Ta),o&&a(Sr),q(bo,o),o&&a(Fr),o&&a(Xe),o&&a(Vr),q(qo,o),o&&a(Hr),o&&a(wa),o&&a(Gr),q(jo,o),o&&a(Ur),o&&a(Da),o&&a(Wr),q(No,o),o&&a(Kr),o&&a(ie),o&&a(Qr),o&&a(Y),o&&a(Jr),q(wo,o),o&&a(Yr),o&&a(Be),o&&a(Zr),q(Do,o),o&&a(en),o&&a(Re),o&&a(on),q(Po,o),o&&a(an),o&&a(Ca),o&&a(tn),q(Lo,o),o&&a(sn),o&&a(de),o&&a(rn),q(Ao,o),o&&a(nn),q(yo,o),o&&a(ln),o&&a(pe),o&&a(dn),q(Io,o),o&&a(pn),o&&a(je),q(zo),o&&a(mn),o&&a(me),o&&a(cn),o&&a(Fe),o&&a(un),o&&a(Ve),o&&a(fn),q(Ko,o),o&&a(hn),o&&a(ce),o&&a(vn),q(Qo,o),o&&a(_n),o&&a(Pa),o&&a(En),q(Jo,o),o&&a(gn),o&&a(Z),o&&a(xn),q(He,o),o&&a($n),q(Ge,o),o&&a(On),o&&a(Ne),q(Yo),o&&a(bn),o&&a(La),o&&a(qn),o&&a(ue),o&&a(jn),o&&a(Aa),o&&a(Nn),o&&a(ke),q(Zo),o&&a(kn),o&&a(ya),o&&a(Tn),o&&a(fe),o&&a(wn),q(Ke,o),o&&a(Dn),o&&a(Qe),o&&a(Cn),q(ea,o),o&&a(Pn),o&&a(V),o&&a(Ln),q(Je,o),o&&a(An),o&&a(Xa),o&&a(yn),q(oa,o),o&&a(In),o&&a(Ba),o&&a(zn),q(aa,o),o&&a(Mn),o&&a(Ra),o&&a(Xn),q(ta,o),o&&a(Bn),o&&a(H),o&&a(Rn),q(sa,o),o&&a(Sn),q(Ye,o),o&&a(Fn),o&&a(Te),q(ra),o&&a(Vn),o&&a(he),o&&a(Hn),q(na,o),o&&a(Gn),o&&a(R),o&&a(Un),q(la,o),o&&a(Wn),q(eo,o),o&&a(Kn),o&&a(we),q(ia),o&&a(Qn),o&&a(ve),o&&a(Jn),q(da,o),o&&a(Yn),o&&a(ao),o&&a(Zn),o&&a(De),q(pa),o&&a(el),o&&a(Sa),o&&a(ol),o&&a(_e),o&&a(al),o&&a(so)}}}const Av={local:"exportando-modelos-para-onnx",sections:[{local:"exportando-um-modelo-para-onnx",title:"Exportando um modelo para ONNX"},{local:"selecionando-features-para-diferentes-tarefas-do-modelo",title:"Selecionando features para diferentes tarefas do modelo"},{local:"exportando-um-modelo-para-uma-arquitetura-sem-suporte",sections:[{local:"implementando-uma-configurao-onnx-personalizada",title:"Implementando uma configura\xE7\xE3o ONNX personalizada"},{local:"exportando-um-modelo",title:"Exportando um modelo"},{local:"validando-a-sada-dos-modelos",title:"Validando a sa\xEDda dos modelos"}],title:"Exportando um modelo para uma arquitetura sem suporte"},{local:"contribuindo-com-uma-nova-configurao-para-transformers",title:"Contribuindo com uma nova configura\xE7\xE3o para \u{1F917} Transformers"}],title:"Exportando modelos para ONNX "};function yv(B){return jv(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Bv extends $v{constructor(f){super();Ov(this,f,yv,Lv,bv,{})}}export{Bv as default,Av as metadata};
