import{S as wn,i as zn,s as xn,e as r,k as c,w as j,t as o,M as Dn,c as i,d as s,m as f,a as n,x as k,h as t,b,G as a,g as p,y as w,q as z,o as x,B as D,v as Cn,L as Qo}from"../chunks/vendor-hf-doc-builder.js";import{T as Lo}from"../chunks/Tip-hf-doc-builder.js";import{I as da}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as I}from"../chunks/CodeBlock-hf-doc-builder.js";import{F as kn,M as Uo}from"../chunks/Markdown-hf-doc-builder.js";function yn(S){let m,g,u,_,q;return{c(){m=r("p"),g=o("Voc\xEA pode tamb\xE9m salvar seu arquivo de configura\xE7\xF5es como um dicion\xE1rio ou at\xE9 mesmo com a diferen\xE7a entre as seus atributos de configura\xE7\xE3o customizados e os atributos de configura\xE7\xE3o padr\xF5es! Olhe a documenta\xE7\xE3o "),u=r("a"),_=o("configuration"),q=o(" para mais detalhes."),this.h()},l(v){m=i(v,"P",{});var $=n(m);g=t($,"Voc\xEA pode tamb\xE9m salvar seu arquivo de configura\xE7\xF5es como um dicion\xE1rio ou at\xE9 mesmo com a diferen\xE7a entre as seus atributos de configura\xE7\xE3o customizados e os atributos de configura\xE7\xE3o padr\xF5es! Olhe a documenta\xE7\xE3o "),u=i($,"A",{href:!0});var y=n(u);_=t(y,"configuration"),y.forEach(s),q=t($," para mais detalhes."),$.forEach(s),this.h()},h(){b(u,"href","main_classes/configuration")},m(v,$){p(v,m,$),a(m,g),a(m,u),a(u,_),a(m,q)},d(v){v&&s(m)}}}function Tn(S){let m,g,u,_,q,v,$,y,E,N,C,M,B,O,T,V,h,F,R,A,L;return _=new I({props:{code:`from transformers import DistilBertModel

my_config = DistilBertConfig.from_pretrained("./your_model_save_path/my_config.json")
model = DistilBertModel(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertModel

<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;./your_model_save_path/my_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertModel(my_config)`}}),T=new I({props:{code:'model = DistilBertModel.from_pretrained("distilbert-base-uncased")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)'}}),A=new I({props:{code:'model = DistilBertModel.from_pretrained("distilbert-base-uncased", config=my_config)',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>, config=my_config)'}}),{c(){m=r("p"),g=o("Carregar seus atributos de configura\xE7\xE3o customizados em um modelo:"),u=c(),j(_.$$.fragment),q=c(),v=r("p"),$=o("Isso cria um modelo com valores aleat\xF3rios ao inv\xE9s de pr\xE9-treinar os pesos. Voc\xEA n\xE3o ir\xE1 conseguir usar usar esse modelo para nada \xFAtil ainda, at\xE9 voc\xEA treinar ele. Treino \xE9 um processo caro e demorado. Geralmente \xE9 melhor utilizar um modelo pr\xE9-treinado para obter melhores resultados mais r\xE1pido, enquanto usa apenas uma fra\xE7\xE3o dos recursos necess\xE1rios para treinar."),y=c(),E=r("p"),N=o("Criar um modelo pr\xE9-treinado com "),C=r("code"),M=o("from_pretrained()"),B=o(":"),O=c(),j(T.$$.fragment),V=c(),h=r("p"),F=o("Quando voc\xEA carregar os pesos pr\xE9-treinados, a configura\xE7\xE3o padr\xE3o do modelo \xE9 automaticamente carregada se o modelo \xE9 provido pelo \u{1F917} Transformers. No entanto, voc\xEA ainda consegue mudar - alguns ou todos - os atributos padr\xF5es de configura\xE7\xE3o do modelo com os seus pr\xF3prio atributos, se voc\xEA preferir:"),R=c(),j(A.$$.fragment)},l(d){m=i(d,"P",{});var P=n(m);g=t(P,"Carregar seus atributos de configura\xE7\xE3o customizados em um modelo:"),P.forEach(s),u=f(d),k(_.$$.fragment,d),q=f(d),v=i(d,"P",{});var W=n(v);$=t(W,"Isso cria um modelo com valores aleat\xF3rios ao inv\xE9s de pr\xE9-treinar os pesos. Voc\xEA n\xE3o ir\xE1 conseguir usar usar esse modelo para nada \xFAtil ainda, at\xE9 voc\xEA treinar ele. Treino \xE9 um processo caro e demorado. Geralmente \xE9 melhor utilizar um modelo pr\xE9-treinado para obter melhores resultados mais r\xE1pido, enquanto usa apenas uma fra\xE7\xE3o dos recursos necess\xE1rios para treinar."),W.forEach(s),y=f(d),E=i(d,"P",{});var H=n(E);N=t(H,"Criar um modelo pr\xE9-treinado com "),C=i(H,"CODE",{});var se=n(C);M=t(se,"from_pretrained()"),se.forEach(s),B=t(H,":"),H.forEach(s),O=f(d),k(T.$$.fragment,d),V=f(d),h=i(d,"P",{});var oe=n(h);F=t(oe,"Quando voc\xEA carregar os pesos pr\xE9-treinados, a configura\xE7\xE3o padr\xE3o do modelo \xE9 automaticamente carregada se o modelo \xE9 provido pelo \u{1F917} Transformers. No entanto, voc\xEA ainda consegue mudar - alguns ou todos - os atributos padr\xF5es de configura\xE7\xE3o do modelo com os seus pr\xF3prio atributos, se voc\xEA preferir:"),oe.forEach(s),R=f(d),k(A.$$.fragment,d)},m(d,P){p(d,m,P),a(m,g),p(d,u,P),w(_,d,P),p(d,q,P),p(d,v,P),a(v,$),p(d,y,P),p(d,E,P),a(E,N),a(E,C),a(C,M),a(E,B),p(d,O,P),w(T,d,P),p(d,V,P),p(d,h,P),a(h,F),p(d,R,P),w(A,d,P),L=!0},p:Qo,i(d){L||(z(_.$$.fragment,d),z(T.$$.fragment,d),z(A.$$.fragment,d),L=!0)},o(d){x(_.$$.fragment,d),x(T.$$.fragment,d),x(A.$$.fragment,d),L=!1},d(d){d&&s(m),d&&s(u),D(_,d),d&&s(q),d&&s(v),d&&s(y),d&&s(E),d&&s(O),D(T,d),d&&s(V),d&&s(h),d&&s(R),D(A,d)}}}function Pn(S){let m,g;return m=new Uo({props:{$$slots:{default:[Tn]},$$scope:{ctx:S}}}),{c(){j(m.$$.fragment)},l(u){k(m.$$.fragment,u)},m(u,_){w(m,u,_),g=!0},p(u,_){const q={};_&2&&(q.$$scope={dirty:_,ctx:u}),m.$set(q)},i(u){g||(z(m.$$.fragment,u),g=!0)},o(u){x(m.$$.fragment,u),g=!1},d(u){D(m,u)}}}function Fn(S){let m,g,u,_,q,v,$,y,E,N,C,M,B,O,T,V,h,F,R,A,L;return _=new I({props:{code:`from transformers import TFDistilBertModel

my_config = DistilBertConfig.from_pretrained("./your_model_save_path/my_config.json")
tf_model = TFDistilBertModel(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFDistilBertModel

<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;./your_model_save_path/my_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertModel(my_config)`}}),T=new I({props:{code:'tf_model = TFDistilBertModel.from_pretrained("distilbert-base-uncased")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)'}}),A=new I({props:{code:'tf_model = TFDistilBertModel.from_pretrained("distilbert-base-uncased", config=my_config)',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>, config=my_config)'}}),{c(){m=r("p"),g=o("Carregar os seus pr\xF3prios atributos padr\xF5es de contigura\xE7\xE3o no modelo:"),u=c(),j(_.$$.fragment),q=c(),v=r("p"),$=o("Isso cria um modelo com valores aleat\xF3rios ao inv\xE9s de pr\xE9-treinar os pesos. Voc\xEA n\xE3o ir\xE1 conseguir usar usar esse modelo para nada \xFAtil ainda, at\xE9 voc\xEA treinar ele. Treino \xE9 um processo caro e demorado. Geralmente \xE9 melhor utilizar um modelo pr\xE9-treinado para obter melhores resultados mais r\xE1pido, enquanto usa apenas uma fra\xE7\xE3o dos recursos necess\xE1rios para treinar."),y=c(),E=r("p"),N=o("Criar um modelo pr\xE9-treinado com "),C=r("code"),M=o("from_pretrained()"),B=o(":"),O=c(),j(T.$$.fragment),V=c(),h=r("p"),F=o("Quando voc\xEA carregar os pesos pr\xE9-treinados, a configura\xE7\xE3o padr\xE3o do modelo \xE9 automaticamente carregada se o modelo \xE9 provido pelo \u{1F917} Transformers. No entanto, voc\xEA ainda consegue mudar - alguns ou todos - os atributos padr\xF5es de configura\xE7\xE3o do modelo com os seus pr\xF3prio atributos, se voc\xEA preferir:"),R=c(),j(A.$$.fragment)},l(d){m=i(d,"P",{});var P=n(m);g=t(P,"Carregar os seus pr\xF3prios atributos padr\xF5es de contigura\xE7\xE3o no modelo:"),P.forEach(s),u=f(d),k(_.$$.fragment,d),q=f(d),v=i(d,"P",{});var W=n(v);$=t(W,"Isso cria um modelo com valores aleat\xF3rios ao inv\xE9s de pr\xE9-treinar os pesos. Voc\xEA n\xE3o ir\xE1 conseguir usar usar esse modelo para nada \xFAtil ainda, at\xE9 voc\xEA treinar ele. Treino \xE9 um processo caro e demorado. Geralmente \xE9 melhor utilizar um modelo pr\xE9-treinado para obter melhores resultados mais r\xE1pido, enquanto usa apenas uma fra\xE7\xE3o dos recursos necess\xE1rios para treinar."),W.forEach(s),y=f(d),E=i(d,"P",{});var H=n(E);N=t(H,"Criar um modelo pr\xE9-treinado com "),C=i(H,"CODE",{});var se=n(C);M=t(se,"from_pretrained()"),se.forEach(s),B=t(H,":"),H.forEach(s),O=f(d),k(T.$$.fragment,d),V=f(d),h=i(d,"P",{});var oe=n(h);F=t(oe,"Quando voc\xEA carregar os pesos pr\xE9-treinados, a configura\xE7\xE3o padr\xE3o do modelo \xE9 automaticamente carregada se o modelo \xE9 provido pelo \u{1F917} Transformers. No entanto, voc\xEA ainda consegue mudar - alguns ou todos - os atributos padr\xF5es de configura\xE7\xE3o do modelo com os seus pr\xF3prio atributos, se voc\xEA preferir:"),oe.forEach(s),R=f(d),k(A.$$.fragment,d)},m(d,P){p(d,m,P),a(m,g),p(d,u,P),w(_,d,P),p(d,q,P),p(d,v,P),a(v,$),p(d,y,P),p(d,E,P),a(E,N),a(E,C),a(C,M),a(E,B),p(d,O,P),w(T,d,P),p(d,V,P),p(d,h,P),a(h,F),p(d,R,P),w(A,d,P),L=!0},p:Qo,i(d){L||(z(_.$$.fragment,d),z(T.$$.fragment,d),z(A.$$.fragment,d),L=!0)},o(d){x(_.$$.fragment,d),x(T.$$.fragment,d),x(A.$$.fragment,d),L=!1},d(d){d&&s(m),d&&s(u),D(_,d),d&&s(q),d&&s(v),d&&s(y),d&&s(E),d&&s(O),D(T,d),d&&s(V),d&&s(h),d&&s(R),D(A,d)}}}function Bn(S){let m,g;return m=new Uo({props:{$$slots:{default:[Fn]},$$scope:{ctx:S}}}),{c(){j(m.$$.fragment)},l(u){k(m.$$.fragment,u)},m(u,_){w(m,u,_),g=!0},p(u,_){const q={};_&2&&(q.$$scope={dirty:_,ctx:u}),m.$set(q)},i(u){g||(z(m.$$.fragment,u),g=!0)},o(u){x(m.$$.fragment,u),g=!1},d(u){D(m,u)}}}function An(S){let m,g,u,_,q,v,$,y,E,N,C,M,B,O,T,V;return $=new I({props:{code:`from transformers import DistilBertForSequenceClassification

model = DistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),T=new I({props:{code:`from transformers import DistilBertForQuestionAnswering

model = DistilBertForQuestionAnswering.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),{c(){m=r("p"),g=o("Por exemplo, "),u=r("code"),_=o("DistilBertForSequenceClassification"),q=o(" \xE9 um modelo DistilBERT base com uma head de classifica\xE7\xE3o de sequ\xEAncia. A head de calssifica\xE7\xE3o de sequ\xEAncia \xE9 uma camada linear no topo das sa\xEDdas agrupadas."),v=c(),j($.$$.fragment),y=c(),E=r("p"),N=o("Reutilize facilmente esse ponto de parada para outra tarefe mudando para uma head de modelo diferente. Para uma tarefe de responder quest\xF5es, voc\xEA usaria a head do modelo "),C=r("code"),M=o("DistilBertForQuestionAnswering"),B=o(". A head de responder quest\xF5es \xE9 similar com a de classifica\xE7\xE3o de sequ\xEAncias exceto o fato de que ela \xE9 uma camada no topo dos estados das sa\xEDdas ocultas."),O=c(),j(T.$$.fragment)},l(h){m=i(h,"P",{});var F=n(m);g=t(F,"Por exemplo, "),u=i(F,"CODE",{});var R=n(u);_=t(R,"DistilBertForSequenceClassification"),R.forEach(s),q=t(F," \xE9 um modelo DistilBERT base com uma head de classifica\xE7\xE3o de sequ\xEAncia. A head de calssifica\xE7\xE3o de sequ\xEAncia \xE9 uma camada linear no topo das sa\xEDdas agrupadas."),F.forEach(s),v=f(h),k($.$$.fragment,h),y=f(h),E=i(h,"P",{});var A=n(E);N=t(A,"Reutilize facilmente esse ponto de parada para outra tarefe mudando para uma head de modelo diferente. Para uma tarefe de responder quest\xF5es, voc\xEA usaria a head do modelo "),C=i(A,"CODE",{});var L=n(C);M=t(L,"DistilBertForQuestionAnswering"),L.forEach(s),B=t(A,". A head de responder quest\xF5es \xE9 similar com a de classifica\xE7\xE3o de sequ\xEAncias exceto o fato de que ela \xE9 uma camada no topo dos estados das sa\xEDdas ocultas."),A.forEach(s),O=f(h),k(T.$$.fragment,h)},m(h,F){p(h,m,F),a(m,g),a(m,u),a(u,_),a(m,q),p(h,v,F),w($,h,F),p(h,y,F),p(h,E,F),a(E,N),a(E,C),a(C,M),a(E,B),p(h,O,F),w(T,h,F),V=!0},p:Qo,i(h){V||(z($.$$.fragment,h),z(T.$$.fragment,h),V=!0)},o(h){x($.$$.fragment,h),x(T.$$.fragment,h),V=!1},d(h){h&&s(m),h&&s(v),D($,h),h&&s(y),h&&s(E),h&&s(O),D(T,h)}}}function On(S){let m,g;return m=new Uo({props:{$$slots:{default:[An]},$$scope:{ctx:S}}}),{c(){j(m.$$.fragment)},l(u){k(m.$$.fragment,u)},m(u,_){w(m,u,_),g=!0},p(u,_){const q={};_&2&&(q.$$scope={dirty:_,ctx:u}),m.$set(q)},i(u){g||(z(m.$$.fragment,u),g=!0)},o(u){x(m.$$.fragment,u),g=!1},d(u){D(m,u)}}}function Vn(S){let m,g,u,_,q,v,$,y,E,N,C,M,B,O,T,V;return $=new I({props:{code:`from transformers import TFDistilBertForSequenceClassification

tf_model = TFDistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFDistilBertForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),T=new I({props:{code:`from transformers import TFDistilBertForQuestionAnswering

tf_model = TFDistilBertForQuestionAnswering.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFDistilBertForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),{c(){m=r("p"),g=o("Por exemplo, "),u=r("code"),_=o("TFDistilBertForSequenceClassification"),q=o(" \xE9 um modelo DistilBERT base com uma head de classifica\xE7\xE3o de sequ\xEAncia. A head de calssifica\xE7\xE3o de sequ\xEAncia \xE9 uma camada linear no topo das sa\xEDdas agrupadas."),v=c(),j($.$$.fragment),y=c(),E=r("p"),N=o("Reutilize facilmente esse ponto de parada para outra tarefe mudando para uma head de modelo diferente. Para uma tarefe de responder quest\xF5es, voc\xEA usaria a head do modelo "),C=r("code"),M=o("TFDistilBertForQuestionAnswering"),B=o(". A head de responder quest\xF5es \xE9 similar com a de classifica\xE7\xE3o de sequ\xEAncias exceto o fato de que ela \xE9 uma camada no topo dos estados das sa\xEDdas ocultas."),O=c(),j(T.$$.fragment)},l(h){m=i(h,"P",{});var F=n(m);g=t(F,"Por exemplo, "),u=i(F,"CODE",{});var R=n(u);_=t(R,"TFDistilBertForSequenceClassification"),R.forEach(s),q=t(F," \xE9 um modelo DistilBERT base com uma head de classifica\xE7\xE3o de sequ\xEAncia. A head de calssifica\xE7\xE3o de sequ\xEAncia \xE9 uma camada linear no topo das sa\xEDdas agrupadas."),F.forEach(s),v=f(h),k($.$$.fragment,h),y=f(h),E=i(h,"P",{});var A=n(E);N=t(A,"Reutilize facilmente esse ponto de parada para outra tarefe mudando para uma head de modelo diferente. Para uma tarefe de responder quest\xF5es, voc\xEA usaria a head do modelo "),C=i(A,"CODE",{});var L=n(C);M=t(L,"TFDistilBertForQuestionAnswering"),L.forEach(s),B=t(A,". A head de responder quest\xF5es \xE9 similar com a de classifica\xE7\xE3o de sequ\xEAncias exceto o fato de que ela \xE9 uma camada no topo dos estados das sa\xEDdas ocultas."),A.forEach(s),O=f(h),k(T.$$.fragment,h)},m(h,F){p(h,m,F),a(m,g),a(m,u),a(u,_),a(m,q),p(h,v,F),w($,h,F),p(h,y,F),p(h,E,F),a(E,N),a(E,C),a(C,M),a(E,B),p(h,O,F),w(T,h,F),V=!0},p:Qo,i(h){V||(z($.$$.fragment,h),z(T.$$.fragment,h),V=!0)},o(h){x($.$$.fragment,h),x(T.$$.fragment,h),V=!1},d(h){h&&s(m),h&&s(v),D($,h),h&&s(y),h&&s(E),h&&s(O),D(T,h)}}}function Mn(S){let m,g;return m=new Uo({props:{$$slots:{default:[Vn]},$$scope:{ctx:S}}}),{c(){j(m.$$.fragment)},l(u){k(m.$$.fragment,u)},m(u,_){w(m,u,_),g=!0},p(u,_){const q={};_&2&&(q.$$scope={dirty:_,ctx:u}),m.$set(q)},i(u){g||(z(m.$$.fragment,u),g=!0)},o(u){x(m.$$.fragment,u),g=!1},d(u){D(m,u)}}}function Sn(S){let m,g,u,_,q;return{c(){m=r("p"),g=o("Nem todo modelo suporta um \u2018fast tokenizer\u2019. De uma olhada aqui "),u=r("a"),_=o("table"),q=o(" pra checar se um modelo suporta \u2018fast tokenizer\u2019."),this.h()},l(v){m=i(v,"P",{});var $=n(m);g=t($,"Nem todo modelo suporta um \u2018fast tokenizer\u2019. De uma olhada aqui "),u=i($,"A",{href:!0});var y=n(u);_=t(y,"table"),y.forEach(s),q=t($," pra checar se um modelo suporta \u2018fast tokenizer\u2019."),$.forEach(s),this.h()},h(){b(u,"href","index#supported-frameworks")},m(v,$){p(v,m,$),a(m,g),a(m,u),a(u,_),a(m,q)},d(v){v&&s(m)}}}function Nn(S){let m,g,u,_,q,v,$,y,E,N,C;return{c(){m=r("p"),g=o("Pos padr\xE3o, "),u=r("code"),_=o("AutoTokenizer"),q=o(" tentar\xE1 carregar um \u2018fast tokenizer\u2019. Voc\xEA pode disabilitar esse comportamento colocando "),v=r("code"),$=o("use_fast=False"),y=o(" no "),E=r("code"),N=o("from_pretrained"),C=o(".")},l(M){m=i(M,"P",{});var B=n(m);g=t(B,"Pos padr\xE3o, "),u=i(B,"CODE",{});var O=n(u);_=t(O,"AutoTokenizer"),O.forEach(s),q=t(B," tentar\xE1 carregar um \u2018fast tokenizer\u2019. Voc\xEA pode disabilitar esse comportamento colocando "),v=i(B,"CODE",{});var T=n(v);$=t(T,"use_fast=False"),T.forEach(s),y=t(B," no "),E=i(B,"CODE",{});var V=n(E);N=t(V,"from_pretrained"),V.forEach(s),C=t(B,"."),B.forEach(s)},m(M,B){p(M,m,B),a(m,g),a(m,u),a(u,_),a(m,q),a(m,v),a(v,$),a(m,y),a(m,E),a(E,N),a(m,C)},d(M){M&&s(m)}}}function In(S){let m,g,u,_,q;return{c(){m=r("p"),g=o("Se voc\xEA n\xE3o estiver procurando por nenhuma customiza\xE7\xE3o, apenas use o m\xE9todo "),u=r("code"),_=o("from_pretrained"),q=o(" para carregar par\xE2metros do modelo de extrator de features padr\xE3o.")},l(v){m=i(v,"P",{});var $=n(m);g=t($,"Se voc\xEA n\xE3o estiver procurando por nenhuma customiza\xE7\xE3o, apenas use o m\xE9todo "),u=i($,"CODE",{});var y=n(u);_=t(y,"from_pretrained"),y.forEach(s),q=t($," para carregar par\xE2metros do modelo de extrator de features padr\xE3o."),$.forEach(s)},m(v,$){p(v,m,$),a(m,g),a(m,u),a(u,_),a(m,q)},d(v){v&&s(m)}}}function Wn(S){let m,g,u,_,q,v,$,y,E,N,C,M,B,O,T,V,h,F,R,A,L,d,P,W,H,se,oe,wa,Ho,Go,za,Jo,Xo,xa,Ko,Yo,Da,Zo,ks,te,ue,Ca,Me,et,ya,at,ws,U,st,ca,ot,tt,Ta,rt,it,Pa,nt,lt,Fa,pt,mt,Ba,ut,dt,zs,Y,ct,fa,ft,ht,Aa,_t,gt,xs,Se,Ds,re,Oa,vt,$t,Va,qt,bt,Cs,de,Ne,Et,Ma,jt,kt,wt,Ie,zt,Sa,xt,Dt,ys,We,Ts,ce,Ct,Na,yt,Tt,Ps,Re,Fs,fe,Pt,Ia,Ft,Bt,Bs,Le,As,he,At,Wa,Ot,Vt,Os,Qe,Vs,_e,Ms,ie,ge,Ra,Ue,Mt,La,St,Ss,Q,Nt,ha,It,Wt,Qa,Rt,Lt,Ua,Qt,Ut,He,Ha,Ht,Gt,Ge,Ga,Jt,Xt,Je,Ja,Kt,Yt,Ns,ve,Is,ne,$e,Xa,Xe,Zt,Ka,er,Ws,qe,ar,Ya,sr,or,Rs,be,Ls,le,Ee,Za,Ke,tr,es,rr,Qs,je,ir,_a,nr,lr,Us,ke,ga,as,pr,mr,ur,Z,ss,dr,cr,Ye,fr,hr,os,_r,gr,Hs,va,vr,Gs,we,Js,ze,$r,ts,qr,br,Xs,Ze,Ks,xe,Er,rs,jr,kr,Ys,ea,Zs,De,wr,is,zr,xr,eo,aa,ao,Ce,so,pe,ye,ns,sa,Dr,ls,Cr,oo,J,yr,ps,Tr,Pr,ms,Fr,Br,us,Ar,Or,to,ee,Vr,ds,Mr,Sr,$a,Nr,Ir,ro,oa,io,Te,no,Pe,Wr,cs,Rr,Lr,lo,ta,po,Fe,Qr,fs,Ur,Hr,mo,ra,uo,me,Be,hs,ia,Gr,_s,Jr,co,Ae,Xr,gs,Kr,Yr,fo,qa,Zr,ho,na,_o,ba,ei,go,la,vo,Oe,ai,vs,si,oi,$o,pa,qo,Ea,ti,bo;return v=new da({}),Me=new da({}),Se=new I({props:{code:`from transformers import DistilBertConfig

config = DistilBertConfig()
print(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>config = DistilBertConfig()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(config)
DistilBertConfig {
  <span class="hljs-string">&quot;activation&quot;</span>: <span class="hljs-string">&quot;gelu&quot;</span>,
  <span class="hljs-string">&quot;attention_dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;dim&quot;</span>: <span class="hljs-number">768</span>,
  <span class="hljs-string">&quot;dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;hidden_dim&quot;</span>: <span class="hljs-number">3072</span>,
  <span class="hljs-string">&quot;initializer_range&quot;</span>: <span class="hljs-number">0.02</span>,
  <span class="hljs-string">&quot;max_position_embeddings&quot;</span>: <span class="hljs-number">512</span>,
  <span class="hljs-string">&quot;model_type&quot;</span>: <span class="hljs-string">&quot;distilbert&quot;</span>,
  <span class="hljs-string">&quot;n_heads&quot;</span>: <span class="hljs-number">12</span>,
  <span class="hljs-string">&quot;n_layers&quot;</span>: <span class="hljs-number">6</span>,
  <span class="hljs-string">&quot;pad_token_id&quot;</span>: <span class="hljs-number">0</span>,
  <span class="hljs-string">&quot;qa_dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;seq_classif_dropout&quot;</span>: <span class="hljs-number">0.2</span>,
  <span class="hljs-string">&quot;sinusoidal_pos_embds&quot;</span>: false,
  <span class="hljs-string">&quot;transformers_version&quot;</span>: <span class="hljs-string">&quot;4.16.2&quot;</span>,
  <span class="hljs-string">&quot;vocab_size&quot;</span>: <span class="hljs-number">30522</span>
}`}}),We=new I({props:{code:`my_config = DistilBertConfig(activation="relu", attention_dropout=0.4)
print(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig(activation=<span class="hljs-string">&quot;relu&quot;</span>, attention_dropout=<span class="hljs-number">0.4</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(my_config)
DistilBertConfig {
  <span class="hljs-string">&quot;activation&quot;</span>: <span class="hljs-string">&quot;relu&quot;</span>,
  <span class="hljs-string">&quot;attention_dropout&quot;</span>: <span class="hljs-number">0.4</span>,
  <span class="hljs-string">&quot;dim&quot;</span>: <span class="hljs-number">768</span>,
  <span class="hljs-string">&quot;dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;hidden_dim&quot;</span>: <span class="hljs-number">3072</span>,
  <span class="hljs-string">&quot;initializer_range&quot;</span>: <span class="hljs-number">0.02</span>,
  <span class="hljs-string">&quot;max_position_embeddings&quot;</span>: <span class="hljs-number">512</span>,
  <span class="hljs-string">&quot;model_type&quot;</span>: <span class="hljs-string">&quot;distilbert&quot;</span>,
  <span class="hljs-string">&quot;n_heads&quot;</span>: <span class="hljs-number">12</span>,
  <span class="hljs-string">&quot;n_layers&quot;</span>: <span class="hljs-number">6</span>,
  <span class="hljs-string">&quot;pad_token_id&quot;</span>: <span class="hljs-number">0</span>,
  <span class="hljs-string">&quot;qa_dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;seq_classif_dropout&quot;</span>: <span class="hljs-number">0.2</span>,
  <span class="hljs-string">&quot;sinusoidal_pos_embds&quot;</span>: false,
  <span class="hljs-string">&quot;transformers_version&quot;</span>: <span class="hljs-string">&quot;4.16.2&quot;</span>,
  <span class="hljs-string">&quot;vocab_size&quot;</span>: <span class="hljs-number">30522</span>
}`}}),Re=new I({props:{code:'my_config = DistilBertConfig.from_pretrained("distilbert-base-uncased", activation="relu", attention_dropout=0.4)',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>, activation=<span class="hljs-string">&quot;relu&quot;</span>, attention_dropout=<span class="hljs-number">0.4</span>)'}}),Le=new I({props:{code:'my_config.save_pretrained(save_directory="./your_model_save_path")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>my_config.save_pretrained(save_directory=<span class="hljs-string">&quot;./your_model_save_path&quot;</span>)'}}),Qe=new I({props:{code:'my_config = DistilBertConfig.from_pretrained("./your_model_save_path/my_config.json")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;./your_model_save_path/my_config.json&quot;</span>)'}}),_e=new Lo({props:{$$slots:{default:[yn]},$$scope:{ctx:S}}}),Ue=new da({}),ve=new kn({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Bn],pytorch:[Pn]},$$scope:{ctx:S}}}),Xe=new da({}),be=new kn({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Mn],pytorch:[On]},$$scope:{ctx:S}}}),Ke=new da({}),we=new Lo({props:{warning:!0,$$slots:{default:[Sn]},$$scope:{ctx:S}}}),Ze=new I({props:{code:`from transformers import DistilBertTokenizer

my_tokenizer = DistilBertTokenizer(vocab_file="my_vocab_file.txt", do_lower_case=False, padding_side="left")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>my_tokenizer = DistilBertTokenizer(vocab_file=<span class="hljs-string">&quot;my_vocab_file.txt&quot;</span>, do_lower_case=<span class="hljs-literal">False</span>, padding_side=<span class="hljs-string">&quot;left&quot;</span>)`}}),ea=new I({props:{code:`from transformers import DistilBertTokenizer

slow_tokenizer = DistilBertTokenizer.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>slow_tokenizer = DistilBertTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),aa=new I({props:{code:`from transformers import DistilBertTokenizerFast

fast_tokenizer = DistilBertTokenizerFast.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertTokenizerFast

<span class="hljs-meta">&gt;&gt;&gt; </span>fast_tokenizer = DistilBertTokenizerFast.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),Ce=new Lo({props:{$$slots:{default:[Nn]},$$scope:{ctx:S}}}),sa=new da({}),oa=new I({props:{code:`from transformers import ViTFeatureExtractor

vit_extractor = ViTFeatureExtractor()
print(vit_extractor)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> ViTFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>vit_extractor = ViTFeatureExtractor()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(vit_extractor)
ViTFeatureExtractor {
  <span class="hljs-string">&quot;do_normalize&quot;</span>: true,
  <span class="hljs-string">&quot;do_resize&quot;</span>: true,
  <span class="hljs-string">&quot;feature_extractor_type&quot;</span>: <span class="hljs-string">&quot;ViTFeatureExtractor&quot;</span>,
  <span class="hljs-string">&quot;image_mean&quot;</span>: [
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>
  ],
  <span class="hljs-string">&quot;image_std&quot;</span>: [
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>
  ],
  <span class="hljs-string">&quot;resample&quot;</span>: <span class="hljs-number">2</span>,
  <span class="hljs-string">&quot;size&quot;</span>: <span class="hljs-number">224</span>
}`}}),Te=new Lo({props:{$$slots:{default:[In]},$$scope:{ctx:S}}}),ta=new I({props:{code:`from transformers import ViTFeatureExtractor

my_vit_extractor = ViTFeatureExtractor(resample="PIL.Image.BOX", do_normalize=False, image_mean=[0.3, 0.3, 0.3])
print(my_vit_extractor)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> ViTFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>my_vit_extractor = ViTFeatureExtractor(resample=<span class="hljs-string">&quot;PIL.Image.BOX&quot;</span>, do_normalize=<span class="hljs-literal">False</span>, image_mean=[<span class="hljs-number">0.3</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.3</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(my_vit_extractor)
ViTFeatureExtractor {
  <span class="hljs-string">&quot;do_normalize&quot;</span>: false,
  <span class="hljs-string">&quot;do_resize&quot;</span>: true,
  <span class="hljs-string">&quot;feature_extractor_type&quot;</span>: <span class="hljs-string">&quot;ViTFeatureExtractor&quot;</span>,
  <span class="hljs-string">&quot;image_mean&quot;</span>: [
    <span class="hljs-number">0.3</span>,
    <span class="hljs-number">0.3</span>,
    <span class="hljs-number">0.3</span>
  ],
  <span class="hljs-string">&quot;image_std&quot;</span>: [
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>
  ],
  <span class="hljs-string">&quot;resample&quot;</span>: <span class="hljs-string">&quot;PIL.Image.BOX&quot;</span>,
  <span class="hljs-string">&quot;size&quot;</span>: <span class="hljs-number">224</span>
}`}}),ra=new I({props:{code:`from transformers import Wav2Vec2FeatureExtractor

w2v2_extractor = Wav2Vec2FeatureExtractor()
print(w2v2_extractor)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2FeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>w2v2_extractor = Wav2Vec2FeatureExtractor()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(w2v2_extractor)
Wav2Vec2FeatureExtractor {
  <span class="hljs-string">&quot;do_normalize&quot;</span>: true,
  <span class="hljs-string">&quot;feature_extractor_type&quot;</span>: <span class="hljs-string">&quot;Wav2Vec2FeatureExtractor&quot;</span>,
  <span class="hljs-string">&quot;feature_size&quot;</span>: <span class="hljs-number">1</span>,
  <span class="hljs-string">&quot;padding_side&quot;</span>: <span class="hljs-string">&quot;right&quot;</span>,
  <span class="hljs-string">&quot;padding_value&quot;</span>: <span class="hljs-number">0.0</span>,
  <span class="hljs-string">&quot;return_attention_mask&quot;</span>: false,
  <span class="hljs-string">&quot;sampling_rate&quot;</span>: <span class="hljs-number">16000</span>
}`}}),ia=new da({}),na=new I({props:{code:`from transformers import Wav2Vec2FeatureExtractor

feature_extractor = Wav2Vec2FeatureExtractor(padding_value=1.0, do_normalize=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2FeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = Wav2Vec2FeatureExtractor(padding_value=<span class="hljs-number">1.0</span>, do_normalize=<span class="hljs-literal">True</span>)`}}),la=new I({props:{code:`from transformers import Wav2Vec2CTCTokenizer

tokenizer = Wav2Vec2CTCTokenizer(vocab_file="my_vocab_file.txt")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2CTCTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = Wav2Vec2CTCTokenizer(vocab_file=<span class="hljs-string">&quot;my_vocab_file.txt&quot;</span>)`}}),pa=new I({props:{code:`from transformers import Wav2Vec2Processor

processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2Processor

<span class="hljs-meta">&gt;&gt;&gt; </span>processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)`}}),{c(){m=r("meta"),g=c(),u=r("h1"),_=r("a"),q=r("span"),j(v.$$.fragment),$=c(),y=r("span"),E=o("Criar uma arquitetura customizada"),N=c(),C=r("p"),M=o("Uma "),B=r("a"),O=r("code"),T=o("AutoClass"),V=o(" automaticamente infere a arquitetura do modelo e baixa configura\xE7\xF5es e pesos pr\xE9-treinados. Geralmente, n\xF3s recomendamos usar uma "),h=r("code"),F=o("AutoClass"),R=o(" para produzir um c\xF3digo independente de checkpoints. Mas usu\xE1rios que querem mais contole sobre par\xE2metros espec\xEDficos do modelo pode criar um modelo customizado \u{1F917} Transformers a partir de algumas classes bases. Isso pode ser particulamente \xFAtil para algu\xE9m que est\xE1 interessado em estudar, treinar ou fazer experimentos com um modelo \u{1F917} Transformers. Nesse tutorial, ser\xE1 explicado como criar um modelo customizado sem uma "),A=r("code"),L=o("AutoClass"),d=o(". Aprenda como:"),P=c(),W=r("ul"),H=r("li"),se=o("Carregar e customizar a configura\xE7\xE3o de um modelo."),oe=c(),wa=r("li"),Ho=o("Criar a arquitetura de um modelo."),Go=c(),za=r("li"),Jo=o("Criar um tokenizer r\xE1pido e devagar para textos."),Xo=c(),xa=r("li"),Ko=o("Criar extrator de features para tarefas envolvendo audio e imagem."),Yo=c(),Da=r("li"),Zo=o("Criar um processador para tarefas multimodais."),ks=c(),te=r("h2"),ue=r("a"),Ca=r("span"),j(Me.$$.fragment),et=c(),ya=r("span"),at=o("configuration"),ws=c(),U=r("p"),st=o("A "),ca=r("a"),ot=o("configuration"),tt=o(" refere-se a atributos espec\xEDficos de um modelo. Cada configura\xE7\xE3o de modelo tem atributos diferentes; por exemplo, todos modelo de PLN possuem os atributos "),Ta=r("code"),rt=o("hidden_size"),it=o(", "),Pa=r("code"),nt=o("num_attention_heads"),lt=o(", "),Fa=r("code"),pt=o("num_hidden_layers"),mt=o(" e "),Ba=r("code"),ut=o("vocab_size"),dt=o(" em comum. Esse atributos especificam o numero de \u2018attention heads\u2019 ou \u2018hidden layers\u2019 para construir um modelo."),zs=c(),Y=r("p"),ct=o("D\xEA uma olhada a mais em "),fa=r("a"),ft=o("DistilBERT"),ht=o(" acessando "),Aa=r("code"),_t=o("DistilBertConfig"),gt=o(" para observar esses atributos:"),xs=c(),j(Se.$$.fragment),Ds=c(),re=r("p"),Oa=r("code"),vt=o("DistilBertConfig"),$t=o(" mostra todos os atributos padr\xF5es usados para construir um "),Va=r("code"),qt=o("DistilBertModel"),bt=o(" base. Todos atributos s\xE3o customiz\xE1veis, o que cria espa\xE7o para experimentos. Por exemplo, voc\xEA pode customizar um modelo padr\xE3o para:"),Cs=c(),de=r("ul"),Ne=r("li"),Et=o("Tentar uma fun\xE7\xE3o de ativa\xE7\xE3o diferente com o par\xE2metro "),Ma=r("code"),jt=o("activation"),kt=o("."),wt=c(),Ie=r("li"),zt=o("Usar uma taxa de desist\xEAncia maior para as probabilidades de \u2018attention\u2019 com o par\xE2metro "),Sa=r("code"),xt=o("attention_dropout"),Dt=o("."),ys=c(),j(We.$$.fragment),Ts=c(),ce=r("p"),Ct=o("Atributos de um modelo pr\xE9-treinado podem ser modificados na fun\xE7\xE3o "),Na=r("code"),yt=o("from_pretrained()"),Tt=o(":"),Ps=c(),j(Re.$$.fragment),Fs=c(),fe=r("p"),Pt=o("Uma vez que voc\xEA est\xE1 satisfeito com as configura\xE7\xF5es do seu modelo, voc\xEA consegue salvar elas com "),Ia=r("code"),Ft=o("save_pretrained()"),Bt=o(". Seu arquivo de configura\xE7\xF5es est\xE1 salvo como um arquivo JSON no diret\xF3rio especificado:"),Bs=c(),j(Le.$$.fragment),As=c(),he=r("p"),At=o("Para reusar o arquivo de configura\xE7\xF5es, carregue com "),Wa=r("code"),Ot=o("from_pretrained()"),Vt=o(":"),Os=c(),j(Qe.$$.fragment),Vs=c(),j(_e.$$.fragment),Ms=c(),ie=r("h2"),ge=r("a"),Ra=r("span"),j(Ue.$$.fragment),Mt=c(),La=r("span"),St=o("Modelo"),Ss=c(),Q=r("p"),Nt=o("O pr\xF3ximo passo \xE9 criar um "),ha=r("a"),It=o("model"),Wt=o(". O modelo - tamb\xE9m vagamente referido como arquitetura - define o que cada camada est\xE1 fazendo e quais opera\xE7\xF5es est\xE3o acontecendo. Atributos como "),Qa=r("code"),Rt=o("num_hidden_layers"),Lt=o(" das configura\xE7\xF5es s\xE3o utilizados para definir a arquitetura. Todo modelo compartilha a classe base "),Ua=r("code"),Qt=o("PreTrainedModel"),Ut=o(" e alguns m\xE9todos em comum como redimensionar o tamanho dos embeddings de entrada e podar as \u2018self-attention heads\u2019. Al\xE9m disso, todos os modelos tamb\xE9m s\xE3o subclasses de "),He=r("a"),Ha=r("code"),Ht=o("torch.nn.Module"),Gt=o(", "),Ge=r("a"),Ga=r("code"),Jt=o("tf.keras.Model"),Xt=o(" ou "),Je=r("a"),Ja=r("code"),Kt=o("flax.linen.Module"),Yt=o(". Isso significa que os modelos s\xE3o compat\xEDveis com cada respectivo uso de framework."),Ns=c(),j(ve.$$.fragment),Is=c(),ne=r("h3"),$e=r("a"),Xa=r("span"),j(Xe.$$.fragment),Zt=c(),Ka=r("span"),er=o("Heads do modelo"),Ws=c(),qe=r("p"),ar=o("Neste ponto, voc\xEA tem um modelo b\xE1sico do DistilBERT que gera os "),Ya=r("em"),sr=o("estados ocultos"),or=o(". Os estados ocultos s\xE3o passados como entrada para a head do moelo para produzir a sa\xEDda final. \u{1F917} Transformers fornece uma head de modelo diferente para cada tarefa desde que o modelo suporte essa tarefa (por exemplo, voc\xEA n\xE3o consegue utilizar o modelo DistilBERT para uma tarefa de \u2018sequence-to-sequence\u2019 como tradu\xE7\xE3o)."),Rs=c(),j(be.$$.fragment),Ls=c(),le=r("h2"),Ee=r("a"),Za=r("span"),j(Ke.$$.fragment),tr=c(),es=r("span"),rr=o("Tokenizer"),Qs=c(),je=r("p"),ir=o("A \xFAtlima classe base que voc\xEA precisa antes de usar um modelo para dados textuais \xE9 a "),_a=r("a"),nr=o("tokenizer"),lr=o(" para converter textos originais para tensores. Existem dois tipos de tokenizers que voc\xEA pode usar com \u{1F917} Transformers:"),Us=c(),ke=r("ul"),ga=r("li"),as=r("code"),pr=o("PreTrainedTokenizer"),mr=o(": uma implementa\xE7\xE3o em Python de um tokenizer."),ur=c(),Z=r("li"),ss=r("code"),dr=o("PreTrainedTokenizerFast"),cr=o(": um tokenizer da nossa biblioteca "),Ye=r("a"),fr=o("\u{1F917} Tokenizer"),hr=o(" baseada em Rust. Esse tipo de tokenizer \xE9 significantemente mais rapido - especialmente durante tokenization de codifica\xE7\xE3o - devido a implementa\xE7\xE3o em Rust. O tokenizer r\xE1pido tambem oferece m\xE9todos adicionais como "),os=r("em"),_r=o("offset mapping"),gr=o(" que mapeia tokens para suar palavras ou caracteres originais."),Hs=c(),va=r("p"),vr=o("Os dois tokenizers suporta m\xE9todos comuns como os de codificar e decodificar, adicionar novos tokens, e gerenciar tokens especiais."),Gs=c(),j(we.$$.fragment),Js=c(),ze=r("p"),$r=o("Se voc\xEA treinou seu pr\xF3rpio tokenizer, voc\xEA pode criar um a partir do seu arquivo "),ts=r("em"),qr=o("vocabulary"),br=o(":"),Xs=c(),j(Ze.$$.fragment),Ks=c(),xe=r("p"),Er=o("\xC9 importante lembrar que o vocabul\xE1rio de um tokenizer customizado ser\xE1 diferente de um vocabul\xE1rio gerado pelo tokenizer de um modelo pr\xE9 treinado. Voc\xEA precisa usar o vocabul\xE1rio de um modelo pr\xE9 treinado se voc\xEA estiver usando um modelo pr\xE9 treinado, caso contr\xE1rio as entradas n\xE3o far\xE3o sentido. Criando um tokenizer com um vocabul\xE1rio de um modelo pr\xE9 treinado com a classe "),rs=r("code"),jr=o("DistilBertTokenizer"),kr=o(":"),Ys=c(),j(ea.$$.fragment),Zs=c(),De=r("p"),wr=o("Criando um \u2018fast tokenizer\u2019 com a classe "),is=r("code"),zr=o("DistilBertTokenizerFast"),xr=o(":"),eo=c(),j(aa.$$.fragment),ao=c(),j(Ce.$$.fragment),so=c(),pe=r("h2"),ye=r("a"),ns=r("span"),j(sa.$$.fragment),Dr=c(),ls=r("span"),Cr=o("Extrator de features"),oo=c(),J=r("p"),yr=o("Um extrator de features processa entradas de imagem ou \xE1udio. Ele herda da classe base "),ps=r("code"),Tr=o("FeatureExtractionMixin"),Pr=o(", e pode tamb\xE9m herdar da classe "),ms=r("code"),Fr=o("ImageFeatureExtractionMixin"),Br=o(" para processamento de features de imagem ou da classe "),us=r("code"),Ar=o("SequenceFeatureExtractor"),Or=o(" para processamento de entradas de \xE1udio."),to=c(),ee=r("p"),Vr=o("Dependendo do que voc\xEA est\xE1 trabalhando em um audio ou uma tarefa de vis\xE3o, crie um estrator de features associado com o modelo que voc\xEA est\xE1 usando. Por exemplo, crie um "),ds=r("code"),Mr=o("ViTFeatureExtractor"),Sr=o(" padr\xE3o se voc\xEA estiver usando "),$a=r("a"),Nr=o("ViT"),Ir=o(" para classifica\xE7\xE3o de imagens:"),ro=c(),j(oa.$$.fragment),io=c(),j(Te.$$.fragment),no=c(),Pe=r("p"),Wr=o("Modifique qualquer par\xE2metro dentre os "),cs=r("code"),Rr=o("ViTFeatureExtractor"),Lr=o(" para criar seu extrator de features customizado."),lo=c(),j(ta.$$.fragment),po=c(),Fe=r("p"),Qr=o("Para entradas de \xE1utio, voc\xEA pode criar um "),fs=r("code"),Ur=o("Wav2Vec2FeatureExtractor"),Hr=o(" e customizar os par\xE2metros de uma forma similar:"),mo=c(),j(ra.$$.fragment),uo=c(),me=r("h2"),Be=r("a"),hs=r("span"),j(ia.$$.fragment),Gr=c(),_s=r("span"),Jr=o("Processor"),co=c(),Ae=r("p"),Xr=o("Para modelos que suportam tarefas multimodais, \u{1F917} Transformers oferece uma classe processadora que convenientemente cobre um extrator de features e tokenizer dentro de um \xFAnico objeto. Por exemplo, vamos usar o "),gs=r("code"),Kr=o("Wav2Vec2Processor"),Yr=o(" para uma tarefa de reconhecimento de fala autom\xE1tica (ASR). ASR transcreve \xE1udio para texto, ent\xE3o voc\xEA ir\xE1 precisar de um extrator de um features e um tokenizer."),fo=c(),qa=r("p"),Zr=o("Crie um extrator de features para lidar com as entradas de \xE1udio."),ho=c(),j(na.$$.fragment),_o=c(),ba=r("p"),ei=o("Crie um tokenizer para lidar com a entrada de textos:"),go=c(),j(la.$$.fragment),vo=c(),Oe=r("p"),ai=o("Combine o extrator de features e o tokenizer no "),vs=r("code"),si=o("Wav2Vec2Processor"),oi=o(":"),$o=c(),j(pa.$$.fragment),qo=c(),Ea=r("p"),ti=o("Com duas classes b\xE1sicas - configura\xE7\xE3o e modelo - e um preprocessamento de classe adicional (tokenizer, extrator de features, ou processador), voc\xEA pode criar qualquer modelo que suportado por \u{1F917} Transformers. Qualquer uma dessas classes base s\xE3o configur\xE1veis, te permitindo usar os atributos espec\xEDficos que voc\xEA queira. Voc\xEA pode facilmente preparar um modelo para treinamento ou modificar um modelo pr\xE9-treinado com poucas mudan\xE7as."),this.h()},l(e){const l=Dn('[data-svelte="svelte-1phssyn"]',document.head);m=i(l,"META",{name:!0,content:!0}),l.forEach(s),g=f(e),u=i(e,"H1",{class:!0});var ma=n(u);_=i(ma,"A",{id:!0,class:!0,href:!0});var $s=n(_);q=i($s,"SPAN",{});var qs=n(q);k(v.$$.fragment,qs),qs.forEach(s),$s.forEach(s),$=f(ma),y=i(ma,"SPAN",{});var bs=n(y);E=t(bs,"Criar uma arquitetura customizada"),bs.forEach(s),ma.forEach(s),N=f(e),C=i(e,"P",{});var K=n(C);M=t(K,"Uma "),B=i(K,"A",{href:!0});var Es=n(B);O=i(Es,"CODE",{});var ii=n(O);T=t(ii,"AutoClass"),ii.forEach(s),Es.forEach(s),V=t(K," automaticamente infere a arquitetura do modelo e baixa configura\xE7\xF5es e pesos pr\xE9-treinados. Geralmente, n\xF3s recomendamos usar uma "),h=i(K,"CODE",{});var ni=n(h);F=t(ni,"AutoClass"),ni.forEach(s),R=t(K," para produzir um c\xF3digo independente de checkpoints. Mas usu\xE1rios que querem mais contole sobre par\xE2metros espec\xEDficos do modelo pode criar um modelo customizado \u{1F917} Transformers a partir de algumas classes bases. Isso pode ser particulamente \xFAtil para algu\xE9m que est\xE1 interessado em estudar, treinar ou fazer experimentos com um modelo \u{1F917} Transformers. Nesse tutorial, ser\xE1 explicado como criar um modelo customizado sem uma "),A=i(K,"CODE",{});var li=n(A);L=t(li,"AutoClass"),li.forEach(s),d=t(K,". Aprenda como:"),K.forEach(s),P=f(e),W=i(e,"UL",{});var ae=n(W);H=i(ae,"LI",{});var pi=n(H);se=t(pi,"Carregar e customizar a configura\xE7\xE3o de um modelo."),pi.forEach(s),oe=f(ae),wa=i(ae,"LI",{});var mi=n(wa);Ho=t(mi,"Criar a arquitetura de um modelo."),mi.forEach(s),Go=f(ae),za=i(ae,"LI",{});var ui=n(za);Jo=t(ui,"Criar um tokenizer r\xE1pido e devagar para textos."),ui.forEach(s),Xo=f(ae),xa=i(ae,"LI",{});var di=n(xa);Ko=t(di,"Criar extrator de features para tarefas envolvendo audio e imagem."),di.forEach(s),Yo=f(ae),Da=i(ae,"LI",{});var ci=n(Da);Zo=t(ci,"Criar um processador para tarefas multimodais."),ci.forEach(s),ae.forEach(s),ks=f(e),te=i(e,"H2",{class:!0});var Eo=n(te);ue=i(Eo,"A",{id:!0,class:!0,href:!0});var fi=n(ue);Ca=i(fi,"SPAN",{});var hi=n(Ca);k(Me.$$.fragment,hi),hi.forEach(s),fi.forEach(s),et=f(Eo),ya=i(Eo,"SPAN",{});var _i=n(ya);at=t(_i,"configuration"),_i.forEach(s),Eo.forEach(s),ws=f(e),U=i(e,"P",{});var X=n(U);st=t(X,"A "),ca=i(X,"A",{href:!0});var gi=n(ca);ot=t(gi,"configuration"),gi.forEach(s),tt=t(X," refere-se a atributos espec\xEDficos de um modelo. Cada configura\xE7\xE3o de modelo tem atributos diferentes; por exemplo, todos modelo de PLN possuem os atributos "),Ta=i(X,"CODE",{});var vi=n(Ta);rt=t(vi,"hidden_size"),vi.forEach(s),it=t(X,", "),Pa=i(X,"CODE",{});var $i=n(Pa);nt=t($i,"num_attention_heads"),$i.forEach(s),lt=t(X,", "),Fa=i(X,"CODE",{});var qi=n(Fa);pt=t(qi,"num_hidden_layers"),qi.forEach(s),mt=t(X," e "),Ba=i(X,"CODE",{});var bi=n(Ba);ut=t(bi,"vocab_size"),bi.forEach(s),dt=t(X," em comum. Esse atributos especificam o numero de \u2018attention heads\u2019 ou \u2018hidden layers\u2019 para construir um modelo."),X.forEach(s),zs=f(e),Y=i(e,"P",{});var ja=n(Y);ct=t(ja,"D\xEA uma olhada a mais em "),fa=i(ja,"A",{href:!0});var Ei=n(fa);ft=t(Ei,"DistilBERT"),Ei.forEach(s),ht=t(ja," acessando "),Aa=i(ja,"CODE",{});var ji=n(Aa);_t=t(ji,"DistilBertConfig"),ji.forEach(s),gt=t(ja," para observar esses atributos:"),ja.forEach(s),xs=f(e),k(Se.$$.fragment,e),Ds=f(e),re=i(e,"P",{});var js=n(re);Oa=i(js,"CODE",{});var ki=n(Oa);vt=t(ki,"DistilBertConfig"),ki.forEach(s),$t=t(js," mostra todos os atributos padr\xF5es usados para construir um "),Va=i(js,"CODE",{});var wi=n(Va);qt=t(wi,"DistilBertModel"),wi.forEach(s),bt=t(js," base. Todos atributos s\xE3o customiz\xE1veis, o que cria espa\xE7o para experimentos. Por exemplo, voc\xEA pode customizar um modelo padr\xE3o para:"),js.forEach(s),Cs=f(e),de=i(e,"UL",{});var jo=n(de);Ne=i(jo,"LI",{});var ko=n(Ne);Et=t(ko,"Tentar uma fun\xE7\xE3o de ativa\xE7\xE3o diferente com o par\xE2metro "),Ma=i(ko,"CODE",{});var zi=n(Ma);jt=t(zi,"activation"),zi.forEach(s),kt=t(ko,"."),ko.forEach(s),wt=f(jo),Ie=i(jo,"LI",{});var wo=n(Ie);zt=t(wo,"Usar uma taxa de desist\xEAncia maior para as probabilidades de \u2018attention\u2019 com o par\xE2metro "),Sa=i(wo,"CODE",{});var xi=n(Sa);xt=t(xi,"attention_dropout"),xi.forEach(s),Dt=t(wo,"."),wo.forEach(s),jo.forEach(s),ys=f(e),k(We.$$.fragment,e),Ts=f(e),ce=i(e,"P",{});var zo=n(ce);Ct=t(zo,"Atributos de um modelo pr\xE9-treinado podem ser modificados na fun\xE7\xE3o "),Na=i(zo,"CODE",{});var Di=n(Na);yt=t(Di,"from_pretrained()"),Di.forEach(s),Tt=t(zo,":"),zo.forEach(s),Ps=f(e),k(Re.$$.fragment,e),Fs=f(e),fe=i(e,"P",{});var xo=n(fe);Pt=t(xo,"Uma vez que voc\xEA est\xE1 satisfeito com as configura\xE7\xF5es do seu modelo, voc\xEA consegue salvar elas com "),Ia=i(xo,"CODE",{});var Ci=n(Ia);Ft=t(Ci,"save_pretrained()"),Ci.forEach(s),Bt=t(xo,". Seu arquivo de configura\xE7\xF5es est\xE1 salvo como um arquivo JSON no diret\xF3rio especificado:"),xo.forEach(s),Bs=f(e),k(Le.$$.fragment,e),As=f(e),he=i(e,"P",{});var Do=n(he);At=t(Do,"Para reusar o arquivo de configura\xE7\xF5es, carregue com "),Wa=i(Do,"CODE",{});var yi=n(Wa);Ot=t(yi,"from_pretrained()"),yi.forEach(s),Vt=t(Do,":"),Do.forEach(s),Os=f(e),k(Qe.$$.fragment,e),Vs=f(e),k(_e.$$.fragment,e),Ms=f(e),ie=i(e,"H2",{class:!0});var Co=n(ie);ge=i(Co,"A",{id:!0,class:!0,href:!0});var Ti=n(ge);Ra=i(Ti,"SPAN",{});var Pi=n(Ra);k(Ue.$$.fragment,Pi),Pi.forEach(s),Ti.forEach(s),Mt=f(Co),La=i(Co,"SPAN",{});var Fi=n(La);St=t(Fi,"Modelo"),Fi.forEach(s),Co.forEach(s),Ss=f(e),Q=i(e,"P",{});var G=n(Q);Nt=t(G,"O pr\xF3ximo passo \xE9 criar um "),ha=i(G,"A",{href:!0});var Bi=n(ha);It=t(Bi,"model"),Bi.forEach(s),Wt=t(G,". O modelo - tamb\xE9m vagamente referido como arquitetura - define o que cada camada est\xE1 fazendo e quais opera\xE7\xF5es est\xE3o acontecendo. Atributos como "),Qa=i(G,"CODE",{});var Ai=n(Qa);Rt=t(Ai,"num_hidden_layers"),Ai.forEach(s),Lt=t(G," das configura\xE7\xF5es s\xE3o utilizados para definir a arquitetura. Todo modelo compartilha a classe base "),Ua=i(G,"CODE",{});var Oi=n(Ua);Qt=t(Oi,"PreTrainedModel"),Oi.forEach(s),Ut=t(G," e alguns m\xE9todos em comum como redimensionar o tamanho dos embeddings de entrada e podar as \u2018self-attention heads\u2019. Al\xE9m disso, todos os modelos tamb\xE9m s\xE3o subclasses de "),He=i(G,"A",{href:!0,rel:!0});var Vi=n(He);Ha=i(Vi,"CODE",{});var Mi=n(Ha);Ht=t(Mi,"torch.nn.Module"),Mi.forEach(s),Vi.forEach(s),Gt=t(G,", "),Ge=i(G,"A",{href:!0,rel:!0});var Si=n(Ge);Ga=i(Si,"CODE",{});var Ni=n(Ga);Jt=t(Ni,"tf.keras.Model"),Ni.forEach(s),Si.forEach(s),Xt=t(G," ou "),Je=i(G,"A",{href:!0,rel:!0});var Ii=n(Je);Ja=i(Ii,"CODE",{});var Wi=n(Ja);Kt=t(Wi,"flax.linen.Module"),Wi.forEach(s),Ii.forEach(s),Yt=t(G,". Isso significa que os modelos s\xE3o compat\xEDveis com cada respectivo uso de framework."),G.forEach(s),Ns=f(e),k(ve.$$.fragment,e),Is=f(e),ne=i(e,"H3",{class:!0});var yo=n(ne);$e=i(yo,"A",{id:!0,class:!0,href:!0});var Ri=n($e);Xa=i(Ri,"SPAN",{});var Li=n(Xa);k(Xe.$$.fragment,Li),Li.forEach(s),Ri.forEach(s),Zt=f(yo),Ka=i(yo,"SPAN",{});var Qi=n(Ka);er=t(Qi,"Heads do modelo"),Qi.forEach(s),yo.forEach(s),Ws=f(e),qe=i(e,"P",{});var To=n(qe);ar=t(To,"Neste ponto, voc\xEA tem um modelo b\xE1sico do DistilBERT que gera os "),Ya=i(To,"EM",{});var Ui=n(Ya);sr=t(Ui,"estados ocultos"),Ui.forEach(s),or=t(To,". Os estados ocultos s\xE3o passados como entrada para a head do moelo para produzir a sa\xEDda final. \u{1F917} Transformers fornece uma head de modelo diferente para cada tarefa desde que o modelo suporte essa tarefa (por exemplo, voc\xEA n\xE3o consegue utilizar o modelo DistilBERT para uma tarefa de \u2018sequence-to-sequence\u2019 como tradu\xE7\xE3o)."),To.forEach(s),Rs=f(e),k(be.$$.fragment,e),Ls=f(e),le=i(e,"H2",{class:!0});var Po=n(le);Ee=i(Po,"A",{id:!0,class:!0,href:!0});var Hi=n(Ee);Za=i(Hi,"SPAN",{});var Gi=n(Za);k(Ke.$$.fragment,Gi),Gi.forEach(s),Hi.forEach(s),tr=f(Po),es=i(Po,"SPAN",{});var Ji=n(es);rr=t(Ji,"Tokenizer"),Ji.forEach(s),Po.forEach(s),Qs=f(e),je=i(e,"P",{});var Fo=n(je);ir=t(Fo,"A \xFAtlima classe base que voc\xEA precisa antes de usar um modelo para dados textuais \xE9 a "),_a=i(Fo,"A",{href:!0});var Xi=n(_a);nr=t(Xi,"tokenizer"),Xi.forEach(s),lr=t(Fo," para converter textos originais para tensores. Existem dois tipos de tokenizers que voc\xEA pode usar com \u{1F917} Transformers:"),Fo.forEach(s),Us=f(e),ke=i(e,"UL",{});var Bo=n(ke);ga=i(Bo,"LI",{});var ri=n(ga);as=i(ri,"CODE",{});var Ki=n(as);pr=t(Ki,"PreTrainedTokenizer"),Ki.forEach(s),mr=t(ri,": uma implementa\xE7\xE3o em Python de um tokenizer."),ri.forEach(s),ur=f(Bo),Z=i(Bo,"LI",{});var ua=n(Z);ss=i(ua,"CODE",{});var Yi=n(ss);dr=t(Yi,"PreTrainedTokenizerFast"),Yi.forEach(s),cr=t(ua,": um tokenizer da nossa biblioteca "),Ye=i(ua,"A",{href:!0,rel:!0});var Zi=n(Ye);fr=t(Zi,"\u{1F917} Tokenizer"),Zi.forEach(s),hr=t(ua," baseada em Rust. Esse tipo de tokenizer \xE9 significantemente mais rapido - especialmente durante tokenization de codifica\xE7\xE3o - devido a implementa\xE7\xE3o em Rust. O tokenizer r\xE1pido tambem oferece m\xE9todos adicionais como "),os=i(ua,"EM",{});var en=n(os);_r=t(en,"offset mapping"),en.forEach(s),gr=t(ua," que mapeia tokens para suar palavras ou caracteres originais."),ua.forEach(s),Bo.forEach(s),Hs=f(e),va=i(e,"P",{});var an=n(va);vr=t(an,"Os dois tokenizers suporta m\xE9todos comuns como os de codificar e decodificar, adicionar novos tokens, e gerenciar tokens especiais."),an.forEach(s),Gs=f(e),k(we.$$.fragment,e),Js=f(e),ze=i(e,"P",{});var Ao=n(ze);$r=t(Ao,"Se voc\xEA treinou seu pr\xF3rpio tokenizer, voc\xEA pode criar um a partir do seu arquivo "),ts=i(Ao,"EM",{});var sn=n(ts);qr=t(sn,"vocabulary"),sn.forEach(s),br=t(Ao,":"),Ao.forEach(s),Xs=f(e),k(Ze.$$.fragment,e),Ks=f(e),xe=i(e,"P",{});var Oo=n(xe);Er=t(Oo,"\xC9 importante lembrar que o vocabul\xE1rio de um tokenizer customizado ser\xE1 diferente de um vocabul\xE1rio gerado pelo tokenizer de um modelo pr\xE9 treinado. Voc\xEA precisa usar o vocabul\xE1rio de um modelo pr\xE9 treinado se voc\xEA estiver usando um modelo pr\xE9 treinado, caso contr\xE1rio as entradas n\xE3o far\xE3o sentido. Criando um tokenizer com um vocabul\xE1rio de um modelo pr\xE9 treinado com a classe "),rs=i(Oo,"CODE",{});var on=n(rs);jr=t(on,"DistilBertTokenizer"),on.forEach(s),kr=t(Oo,":"),Oo.forEach(s),Ys=f(e),k(ea.$$.fragment,e),Zs=f(e),De=i(e,"P",{});var Vo=n(De);wr=t(Vo,"Criando um \u2018fast tokenizer\u2019 com a classe "),is=i(Vo,"CODE",{});var tn=n(is);zr=t(tn,"DistilBertTokenizerFast"),tn.forEach(s),xr=t(Vo,":"),Vo.forEach(s),eo=f(e),k(aa.$$.fragment,e),ao=f(e),k(Ce.$$.fragment,e),so=f(e),pe=i(e,"H2",{class:!0});var Mo=n(pe);ye=i(Mo,"A",{id:!0,class:!0,href:!0});var rn=n(ye);ns=i(rn,"SPAN",{});var nn=n(ns);k(sa.$$.fragment,nn),nn.forEach(s),rn.forEach(s),Dr=f(Mo),ls=i(Mo,"SPAN",{});var ln=n(ls);Cr=t(ln,"Extrator de features"),ln.forEach(s),Mo.forEach(s),oo=f(e),J=i(e,"P",{});var Ve=n(J);yr=t(Ve,"Um extrator de features processa entradas de imagem ou \xE1udio. Ele herda da classe base "),ps=i(Ve,"CODE",{});var pn=n(ps);Tr=t(pn,"FeatureExtractionMixin"),pn.forEach(s),Pr=t(Ve,", e pode tamb\xE9m herdar da classe "),ms=i(Ve,"CODE",{});var mn=n(ms);Fr=t(mn,"ImageFeatureExtractionMixin"),mn.forEach(s),Br=t(Ve," para processamento de features de imagem ou da classe "),us=i(Ve,"CODE",{});var un=n(us);Ar=t(un,"SequenceFeatureExtractor"),un.forEach(s),Or=t(Ve," para processamento de entradas de \xE1udio."),Ve.forEach(s),to=f(e),ee=i(e,"P",{});var ka=n(ee);Vr=t(ka,"Dependendo do que voc\xEA est\xE1 trabalhando em um audio ou uma tarefa de vis\xE3o, crie um estrator de features associado com o modelo que voc\xEA est\xE1 usando. Por exemplo, crie um "),ds=i(ka,"CODE",{});var dn=n(ds);Mr=t(dn,"ViTFeatureExtractor"),dn.forEach(s),Sr=t(ka," padr\xE3o se voc\xEA estiver usando "),$a=i(ka,"A",{href:!0});var cn=n($a);Nr=t(cn,"ViT"),cn.forEach(s),Ir=t(ka," para classifica\xE7\xE3o de imagens:"),ka.forEach(s),ro=f(e),k(oa.$$.fragment,e),io=f(e),k(Te.$$.fragment,e),no=f(e),Pe=i(e,"P",{});var So=n(Pe);Wr=t(So,"Modifique qualquer par\xE2metro dentre os "),cs=i(So,"CODE",{});var fn=n(cs);Rr=t(fn,"ViTFeatureExtractor"),fn.forEach(s),Lr=t(So," para criar seu extrator de features customizado."),So.forEach(s),lo=f(e),k(ta.$$.fragment,e),po=f(e),Fe=i(e,"P",{});var No=n(Fe);Qr=t(No,"Para entradas de \xE1utio, voc\xEA pode criar um "),fs=i(No,"CODE",{});var hn=n(fs);Ur=t(hn,"Wav2Vec2FeatureExtractor"),hn.forEach(s),Hr=t(No," e customizar os par\xE2metros de uma forma similar:"),No.forEach(s),mo=f(e),k(ra.$$.fragment,e),uo=f(e),me=i(e,"H2",{class:!0});var Io=n(me);Be=i(Io,"A",{id:!0,class:!0,href:!0});var _n=n(Be);hs=i(_n,"SPAN",{});var gn=n(hs);k(ia.$$.fragment,gn),gn.forEach(s),_n.forEach(s),Gr=f(Io),_s=i(Io,"SPAN",{});var vn=n(_s);Jr=t(vn,"Processor"),vn.forEach(s),Io.forEach(s),co=f(e),Ae=i(e,"P",{});var Wo=n(Ae);Xr=t(Wo,"Para modelos que suportam tarefas multimodais, \u{1F917} Transformers oferece uma classe processadora que convenientemente cobre um extrator de features e tokenizer dentro de um \xFAnico objeto. Por exemplo, vamos usar o "),gs=i(Wo,"CODE",{});var $n=n(gs);Kr=t($n,"Wav2Vec2Processor"),$n.forEach(s),Yr=t(Wo," para uma tarefa de reconhecimento de fala autom\xE1tica (ASR). ASR transcreve \xE1udio para texto, ent\xE3o voc\xEA ir\xE1 precisar de um extrator de um features e um tokenizer."),Wo.forEach(s),fo=f(e),qa=i(e,"P",{});var qn=n(qa);Zr=t(qn,"Crie um extrator de features para lidar com as entradas de \xE1udio."),qn.forEach(s),ho=f(e),k(na.$$.fragment,e),_o=f(e),ba=i(e,"P",{});var bn=n(ba);ei=t(bn,"Crie um tokenizer para lidar com a entrada de textos:"),bn.forEach(s),go=f(e),k(la.$$.fragment,e),vo=f(e),Oe=i(e,"P",{});var Ro=n(Oe);ai=t(Ro,"Combine o extrator de features e o tokenizer no "),vs=i(Ro,"CODE",{});var En=n(vs);si=t(En,"Wav2Vec2Processor"),En.forEach(s),oi=t(Ro,":"),Ro.forEach(s),$o=f(e),k(pa.$$.fragment,e),qo=f(e),Ea=i(e,"P",{});var jn=n(Ea);ti=t(jn,"Com duas classes b\xE1sicas - configura\xE7\xE3o e modelo - e um preprocessamento de classe adicional (tokenizer, extrator de features, ou processador), voc\xEA pode criar qualquer modelo que suportado por \u{1F917} Transformers. Qualquer uma dessas classes base s\xE3o configur\xE1veis, te permitindo usar os atributos espec\xEDficos que voc\xEA queira. Voc\xEA pode facilmente preparar um modelo para treinamento ou modificar um modelo pr\xE9-treinado com poucas mudan\xE7as."),jn.forEach(s),this.h()},h(){b(m,"name","hf:doc:metadata"),b(m,"content",JSON.stringify(Rn)),b(_,"id","criar-uma-arquitetura-customizada"),b(_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(_,"href","#criar-uma-arquitetura-customizada"),b(u,"class","relative group"),b(B,"href","model_doc/auto"),b(ue,"id","configuration"),b(ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(ue,"href","#configuration"),b(te,"class","relative group"),b(ca,"href","main_classes/configuration"),b(fa,"href","model_doc/distilbert"),b(ge,"id","modelo"),b(ge,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(ge,"href","#modelo"),b(ie,"class","relative group"),b(ha,"href","main_classes/models"),b(He,"href","https://pytorch.org/docs/stable/generated/torch.nn.Module.html"),b(He,"rel","nofollow"),b(Ge,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),b(Ge,"rel","nofollow"),b(Je,"href","https://flax.readthedocs.io/en/latest/flax.linen.html#module"),b(Je,"rel","nofollow"),b($e,"id","heads-do-modelo"),b($e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b($e,"href","#heads-do-modelo"),b(ne,"class","relative group"),b(Ee,"id","tokenizer"),b(Ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(Ee,"href","#tokenizer"),b(le,"class","relative group"),b(_a,"href","main_classes/tokenizer"),b(Ye,"href","https://huggingface.co/docs/tokenizers/python/latest/"),b(Ye,"rel","nofollow"),b(ye,"id","extrator-de-features"),b(ye,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(ye,"href","#extrator-de-features"),b(pe,"class","relative group"),b($a,"href","model_doc/vit"),b(Be,"id","processor"),b(Be,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(Be,"href","#processor"),b(me,"class","relative group")},m(e,l){a(document.head,m),p(e,g,l),p(e,u,l),a(u,_),a(_,q),w(v,q,null),a(u,$),a(u,y),a(y,E),p(e,N,l),p(e,C,l),a(C,M),a(C,B),a(B,O),a(O,T),a(C,V),a(C,h),a(h,F),a(C,R),a(C,A),a(A,L),a(C,d),p(e,P,l),p(e,W,l),a(W,H),a(H,se),a(W,oe),a(W,wa),a(wa,Ho),a(W,Go),a(W,za),a(za,Jo),a(W,Xo),a(W,xa),a(xa,Ko),a(W,Yo),a(W,Da),a(Da,Zo),p(e,ks,l),p(e,te,l),a(te,ue),a(ue,Ca),w(Me,Ca,null),a(te,et),a(te,ya),a(ya,at),p(e,ws,l),p(e,U,l),a(U,st),a(U,ca),a(ca,ot),a(U,tt),a(U,Ta),a(Ta,rt),a(U,it),a(U,Pa),a(Pa,nt),a(U,lt),a(U,Fa),a(Fa,pt),a(U,mt),a(U,Ba),a(Ba,ut),a(U,dt),p(e,zs,l),p(e,Y,l),a(Y,ct),a(Y,fa),a(fa,ft),a(Y,ht),a(Y,Aa),a(Aa,_t),a(Y,gt),p(e,xs,l),w(Se,e,l),p(e,Ds,l),p(e,re,l),a(re,Oa),a(Oa,vt),a(re,$t),a(re,Va),a(Va,qt),a(re,bt),p(e,Cs,l),p(e,de,l),a(de,Ne),a(Ne,Et),a(Ne,Ma),a(Ma,jt),a(Ne,kt),a(de,wt),a(de,Ie),a(Ie,zt),a(Ie,Sa),a(Sa,xt),a(Ie,Dt),p(e,ys,l),w(We,e,l),p(e,Ts,l),p(e,ce,l),a(ce,Ct),a(ce,Na),a(Na,yt),a(ce,Tt),p(e,Ps,l),w(Re,e,l),p(e,Fs,l),p(e,fe,l),a(fe,Pt),a(fe,Ia),a(Ia,Ft),a(fe,Bt),p(e,Bs,l),w(Le,e,l),p(e,As,l),p(e,he,l),a(he,At),a(he,Wa),a(Wa,Ot),a(he,Vt),p(e,Os,l),w(Qe,e,l),p(e,Vs,l),w(_e,e,l),p(e,Ms,l),p(e,ie,l),a(ie,ge),a(ge,Ra),w(Ue,Ra,null),a(ie,Mt),a(ie,La),a(La,St),p(e,Ss,l),p(e,Q,l),a(Q,Nt),a(Q,ha),a(ha,It),a(Q,Wt),a(Q,Qa),a(Qa,Rt),a(Q,Lt),a(Q,Ua),a(Ua,Qt),a(Q,Ut),a(Q,He),a(He,Ha),a(Ha,Ht),a(Q,Gt),a(Q,Ge),a(Ge,Ga),a(Ga,Jt),a(Q,Xt),a(Q,Je),a(Je,Ja),a(Ja,Kt),a(Q,Yt),p(e,Ns,l),w(ve,e,l),p(e,Is,l),p(e,ne,l),a(ne,$e),a($e,Xa),w(Xe,Xa,null),a(ne,Zt),a(ne,Ka),a(Ka,er),p(e,Ws,l),p(e,qe,l),a(qe,ar),a(qe,Ya),a(Ya,sr),a(qe,or),p(e,Rs,l),w(be,e,l),p(e,Ls,l),p(e,le,l),a(le,Ee),a(Ee,Za),w(Ke,Za,null),a(le,tr),a(le,es),a(es,rr),p(e,Qs,l),p(e,je,l),a(je,ir),a(je,_a),a(_a,nr),a(je,lr),p(e,Us,l),p(e,ke,l),a(ke,ga),a(ga,as),a(as,pr),a(ga,mr),a(ke,ur),a(ke,Z),a(Z,ss),a(ss,dr),a(Z,cr),a(Z,Ye),a(Ye,fr),a(Z,hr),a(Z,os),a(os,_r),a(Z,gr),p(e,Hs,l),p(e,va,l),a(va,vr),p(e,Gs,l),w(we,e,l),p(e,Js,l),p(e,ze,l),a(ze,$r),a(ze,ts),a(ts,qr),a(ze,br),p(e,Xs,l),w(Ze,e,l),p(e,Ks,l),p(e,xe,l),a(xe,Er),a(xe,rs),a(rs,jr),a(xe,kr),p(e,Ys,l),w(ea,e,l),p(e,Zs,l),p(e,De,l),a(De,wr),a(De,is),a(is,zr),a(De,xr),p(e,eo,l),w(aa,e,l),p(e,ao,l),w(Ce,e,l),p(e,so,l),p(e,pe,l),a(pe,ye),a(ye,ns),w(sa,ns,null),a(pe,Dr),a(pe,ls),a(ls,Cr),p(e,oo,l),p(e,J,l),a(J,yr),a(J,ps),a(ps,Tr),a(J,Pr),a(J,ms),a(ms,Fr),a(J,Br),a(J,us),a(us,Ar),a(J,Or),p(e,to,l),p(e,ee,l),a(ee,Vr),a(ee,ds),a(ds,Mr),a(ee,Sr),a(ee,$a),a($a,Nr),a(ee,Ir),p(e,ro,l),w(oa,e,l),p(e,io,l),w(Te,e,l),p(e,no,l),p(e,Pe,l),a(Pe,Wr),a(Pe,cs),a(cs,Rr),a(Pe,Lr),p(e,lo,l),w(ta,e,l),p(e,po,l),p(e,Fe,l),a(Fe,Qr),a(Fe,fs),a(fs,Ur),a(Fe,Hr),p(e,mo,l),w(ra,e,l),p(e,uo,l),p(e,me,l),a(me,Be),a(Be,hs),w(ia,hs,null),a(me,Gr),a(me,_s),a(_s,Jr),p(e,co,l),p(e,Ae,l),a(Ae,Xr),a(Ae,gs),a(gs,Kr),a(Ae,Yr),p(e,fo,l),p(e,qa,l),a(qa,Zr),p(e,ho,l),w(na,e,l),p(e,_o,l),p(e,ba,l),a(ba,ei),p(e,go,l),w(la,e,l),p(e,vo,l),p(e,Oe,l),a(Oe,ai),a(Oe,vs),a(vs,si),a(Oe,oi),p(e,$o,l),w(pa,e,l),p(e,qo,l),p(e,Ea,l),a(Ea,ti),bo=!0},p(e,[l]){const ma={};l&2&&(ma.$$scope={dirty:l,ctx:e}),_e.$set(ma);const $s={};l&2&&($s.$$scope={dirty:l,ctx:e}),ve.$set($s);const qs={};l&2&&(qs.$$scope={dirty:l,ctx:e}),be.$set(qs);const bs={};l&2&&(bs.$$scope={dirty:l,ctx:e}),we.$set(bs);const K={};l&2&&(K.$$scope={dirty:l,ctx:e}),Ce.$set(K);const Es={};l&2&&(Es.$$scope={dirty:l,ctx:e}),Te.$set(Es)},i(e){bo||(z(v.$$.fragment,e),z(Me.$$.fragment,e),z(Se.$$.fragment,e),z(We.$$.fragment,e),z(Re.$$.fragment,e),z(Le.$$.fragment,e),z(Qe.$$.fragment,e),z(_e.$$.fragment,e),z(Ue.$$.fragment,e),z(ve.$$.fragment,e),z(Xe.$$.fragment,e),z(be.$$.fragment,e),z(Ke.$$.fragment,e),z(we.$$.fragment,e),z(Ze.$$.fragment,e),z(ea.$$.fragment,e),z(aa.$$.fragment,e),z(Ce.$$.fragment,e),z(sa.$$.fragment,e),z(oa.$$.fragment,e),z(Te.$$.fragment,e),z(ta.$$.fragment,e),z(ra.$$.fragment,e),z(ia.$$.fragment,e),z(na.$$.fragment,e),z(la.$$.fragment,e),z(pa.$$.fragment,e),bo=!0)},o(e){x(v.$$.fragment,e),x(Me.$$.fragment,e),x(Se.$$.fragment,e),x(We.$$.fragment,e),x(Re.$$.fragment,e),x(Le.$$.fragment,e),x(Qe.$$.fragment,e),x(_e.$$.fragment,e),x(Ue.$$.fragment,e),x(ve.$$.fragment,e),x(Xe.$$.fragment,e),x(be.$$.fragment,e),x(Ke.$$.fragment,e),x(we.$$.fragment,e),x(Ze.$$.fragment,e),x(ea.$$.fragment,e),x(aa.$$.fragment,e),x(Ce.$$.fragment,e),x(sa.$$.fragment,e),x(oa.$$.fragment,e),x(Te.$$.fragment,e),x(ta.$$.fragment,e),x(ra.$$.fragment,e),x(ia.$$.fragment,e),x(na.$$.fragment,e),x(la.$$.fragment,e),x(pa.$$.fragment,e),bo=!1},d(e){s(m),e&&s(g),e&&s(u),D(v),e&&s(N),e&&s(C),e&&s(P),e&&s(W),e&&s(ks),e&&s(te),D(Me),e&&s(ws),e&&s(U),e&&s(zs),e&&s(Y),e&&s(xs),D(Se,e),e&&s(Ds),e&&s(re),e&&s(Cs),e&&s(de),e&&s(ys),D(We,e),e&&s(Ts),e&&s(ce),e&&s(Ps),D(Re,e),e&&s(Fs),e&&s(fe),e&&s(Bs),D(Le,e),e&&s(As),e&&s(he),e&&s(Os),D(Qe,e),e&&s(Vs),D(_e,e),e&&s(Ms),e&&s(ie),D(Ue),e&&s(Ss),e&&s(Q),e&&s(Ns),D(ve,e),e&&s(Is),e&&s(ne),D(Xe),e&&s(Ws),e&&s(qe),e&&s(Rs),D(be,e),e&&s(Ls),e&&s(le),D(Ke),e&&s(Qs),e&&s(je),e&&s(Us),e&&s(ke),e&&s(Hs),e&&s(va),e&&s(Gs),D(we,e),e&&s(Js),e&&s(ze),e&&s(Xs),D(Ze,e),e&&s(Ks),e&&s(xe),e&&s(Ys),D(ea,e),e&&s(Zs),e&&s(De),e&&s(eo),D(aa,e),e&&s(ao),D(Ce,e),e&&s(so),e&&s(pe),D(sa),e&&s(oo),e&&s(J),e&&s(to),e&&s(ee),e&&s(ro),D(oa,e),e&&s(io),D(Te,e),e&&s(no),e&&s(Pe),e&&s(lo),D(ta,e),e&&s(po),e&&s(Fe),e&&s(mo),D(ra,e),e&&s(uo),e&&s(me),D(ia),e&&s(co),e&&s(Ae),e&&s(fo),e&&s(qa),e&&s(ho),D(na,e),e&&s(_o),e&&s(ba),e&&s(go),D(la,e),e&&s(vo),e&&s(Oe),e&&s($o),D(pa,e),e&&s(qo),e&&s(Ea)}}}const Rn={local:"criar-uma-arquitetura-customizada",sections:[{local:"configuration",title:"configuration"},{local:"modelo",sections:[{local:"heads-do-modelo",title:"Heads do modelo"}],title:"Modelo"},{local:"tokenizer",title:"Tokenizer"},{local:"extrator-de-features",title:"Extrator de features"},{local:"processor",title:"Processor"}],title:"Criar uma arquitetura customizada"};function Ln(S){return Cn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Xn extends wn{constructor(m){super();zn(this,m,Ln,Wn,xn,{})}}export{Xn as default,Rn as metadata};
