import{S as yp,i as Cp,s as zp,e as n,k as d,w as E,t as r,M as Pp,c as i,d as t,m as $,a as p,x as k,h as l,b,G as a,g as c,y as w,q as j,o as A,B as q,v as Op,L as ye}from"../chunks/vendor-hf-doc-builder.js";import{T as vt}from"../chunks/Tip-hf-doc-builder.js";import{Y as xp}from"../chunks/Youtube-hf-doc-builder.js";import{I as fa}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as L}from"../chunks/CodeBlock-hf-doc-builder.js";import{D as Mp}from"../chunks/DocNotebookDropdown-hf-doc-builder.js";import{F as gt,M as _e}from"../chunks/Markdown-hf-doc-builder.js";function Dp(P){let s,u;return{c(){s=n("p"),u=r("Todos os exemplos de c\xF3digo apresentados na documenta\xE7\xE3o t\xEAm um bot\xE3o no canto superior direito para escolher se voc\xEA deseja ocultar ou mostrar o c\xF3digo no Pytorch ou no TensorFlow. Caso contr\xE1rio, \xE9 esperado que funcione para ambos back-ends sem nenhuma altera\xE7\xE3o.")},l(o){s=i(o,"P",{});var f=p(s);u=l(f,"Todos os exemplos de c\xF3digo apresentados na documenta\xE7\xE3o t\xEAm um bot\xE3o no canto superior direito para escolher se voc\xEA deseja ocultar ou mostrar o c\xF3digo no Pytorch ou no TensorFlow. Caso contr\xE1rio, \xE9 esperado que funcione para ambos back-ends sem nenhuma altera\xE7\xE3o."),f.forEach(t)},m(o,f){c(o,s,f),a(s,u)},d(o){o&&t(s)}}}function Sp(P){let s,u,o,f,h,g,C,M;return{c(){s=n("p"),u=r("Para mais detalhes sobre a "),o=n("code"),f=r("pipeline()"),h=r(" e tarefas associadas, siga a documenta\xE7\xE3o "),g=n("a"),C=r("aqui"),M=r("."),this.h()},l(x){s=i(x,"P",{});var O=p(s);u=l(O,"Para mais detalhes sobre a "),o=i(O,"CODE",{});var S=p(o);f=l(S,"pipeline()"),S.forEach(t),h=l(O," e tarefas associadas, siga a documenta\xE7\xE3o "),g=i(O,"A",{href:!0});var I=p(g);C=l(I,"aqui"),I.forEach(t),M=l(O,"."),O.forEach(t),this.h()},h(){b(g,"href","./main_classes/pipelines")},m(x,O){c(x,s,O),a(s,u),a(s,o),a(o,f),a(s,h),a(s,g),a(g,C),a(s,M)},d(x){x&&t(s)}}}function Ip(P){let s,u;return s=new L({props:{code:"pip install torch",highlighted:"pip install torch"}}),{c(){E(s.$$.fragment)},l(o){k(s.$$.fragment,o)},m(o,f){w(s,o,f),u=!0},p:ye,i(o){u||(j(s.$$.fragment,o),u=!0)},o(o){A(s.$$.fragment,o),u=!1},d(o){q(s,o)}}}function Fp(P){let s,u;return s=new _e({props:{$$slots:{default:[Ip]},$$scope:{ctx:P}}}),{c(){E(s.$$.fragment)},l(o){k(s.$$.fragment,o)},m(o,f){w(s,o,f),u=!0},p(o,f){const h={};f&2&&(h.$$scope={dirty:f,ctx:o}),s.$set(h)},i(o){u||(j(s.$$.fragment,o),u=!0)},o(o){A(s.$$.fragment,o),u=!1},d(o){q(s,o)}}}function Np(P){let s,u;return s=new L({props:{code:"pip install tensorflow",highlighted:"pip install tensorflow"}}),{c(){E(s.$$.fragment)},l(o){k(s.$$.fragment,o)},m(o,f){w(s,o,f),u=!0},p:ye,i(o){u||(j(s.$$.fragment,o),u=!0)},o(o){A(s.$$.fragment,o),u=!1},d(o){q(s,o)}}}function Up(P){let s,u;return s=new _e({props:{$$slots:{default:[Np]},$$scope:{ctx:P}}}),{c(){E(s.$$.fragment)},l(o){k(s.$$.fragment,o)},m(o,f){w(s,o,f),u=!0},p(o,f){const h={};f&2&&(h.$$scope={dirty:f,ctx:o}),s.$set(h)},i(o){u||(j(s.$$.fragment,o),u=!0)},o(o){A(s.$$.fragment,o),u=!1},d(o){q(s,o)}}}function Hp(P){let s,u,o,f,h,g,C,M,x,O,S,I,F,U;return F=new L({props:{code:`from transformers import AutoTokenizer, AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(model_name)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`}}),{c(){s=n("p"),u=r("Use o "),o=n("code"),f=r("AutoModelForSequenceClassification"),h=r(" e "),g=n("code"),C=r("AutoTokenizer"),M=r(" para carregar o modelo pr\xE9-treinado e seu tokenizer associado (mais em "),x=n("code"),O=r("AutoClass"),S=r(" abaixo):"),I=d(),E(F.$$.fragment)},l(z){s=i(z,"P",{});var _=p(s);u=l(_,"Use o "),o=i(_,"CODE",{});var y=p(o);f=l(y,"AutoModelForSequenceClassification"),y.forEach(t),h=l(_," e "),g=i(_,"CODE",{});var D=p(g);C=l(D,"AutoTokenizer"),D.forEach(t),M=l(_," para carregar o modelo pr\xE9-treinado e seu tokenizer associado (mais em "),x=i(_,"CODE",{});var W=p(x);O=l(W,"AutoClass"),W.forEach(t),S=l(_," abaixo):"),_.forEach(t),I=$(z),k(F.$$.fragment,z)},m(z,_){c(z,s,_),a(s,u),a(s,o),a(o,f),a(s,h),a(s,g),a(g,C),a(s,M),a(s,x),a(x,O),a(s,S),c(z,I,_),w(F,z,_),U=!0},p:ye,i(z){U||(j(F.$$.fragment,z),U=!0)},o(z){A(F.$$.fragment,z),U=!1},d(z){z&&t(s),z&&t(I),q(F,z)}}}function Lp(P){let s,u;return s=new _e({props:{$$slots:{default:[Hp]},$$scope:{ctx:P}}}),{c(){E(s.$$.fragment)},l(o){k(s.$$.fragment,o)},m(o,f){w(s,o,f),u=!0},p(o,f){const h={};f&2&&(h.$$scope={dirty:f,ctx:o}),s.$set(h)},i(o){u||(j(s.$$.fragment,o),u=!0)},o(o){A(s.$$.fragment,o),u=!1},d(o){q(s,o)}}}function Rp(P){let s,u,o,f,h,g,C,M,x,O,S,I,F,U;return F=new L({props:{code:`from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

model = TFAutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(model_name)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`}}),{c(){s=n("p"),u=r("Use o "),o=n("code"),f=r("TFAutoModelForSequenceClassification"),h=r(" and "),g=n("code"),C=r("AutoTokenizer"),M=r(" para carregar o modelo pr\xE9-treinado e o tokenizer associado (mais em "),x=n("code"),O=r("TFAutoClass"),S=r(" abaixo):"),I=d(),E(F.$$.fragment)},l(z){s=i(z,"P",{});var _=p(s);u=l(_,"Use o "),o=i(_,"CODE",{});var y=p(o);f=l(y,"TFAutoModelForSequenceClassification"),y.forEach(t),h=l(_," and "),g=i(_,"CODE",{});var D=p(g);C=l(D,"AutoTokenizer"),D.forEach(t),M=l(_," para carregar o modelo pr\xE9-treinado e o tokenizer associado (mais em "),x=i(_,"CODE",{});var W=p(x);O=l(W,"TFAutoClass"),W.forEach(t),S=l(_," abaixo):"),_.forEach(t),I=$(z),k(F.$$.fragment,z)},m(z,_){c(z,s,_),a(s,u),a(s,o),a(o,f),a(s,h),a(s,g),a(g,C),a(s,M),a(s,x),a(x,O),a(s,S),c(z,I,_),w(F,z,_),U=!0},p:ye,i(z){U||(j(F.$$.fragment,z),U=!0)},o(z){A(F.$$.fragment,z),U=!1},d(z){z&&t(s),z&&t(I),q(F,z)}}}function Wp(P){let s,u;return s=new _e({props:{$$slots:{default:[Rp]},$$scope:{ctx:P}}}),{c(){E(s.$$.fragment)},l(o){k(s.$$.fragment,o)},m(o,f){w(s,o,f),u=!0},p(o,f){const h={};f&2&&(h.$$scope={dirty:f,ctx:o}),s.$set(h)},i(o){u||(j(s.$$.fragment,o),u=!0)},o(o){A(s.$$.fragment,o),u=!1},d(o){q(s,o)}}}function Vp(P){let s,u;return s=new L({props:{code:`pt_batch = tokenizer(
    ["We are very happy to show you the \u{1F917} transformers library.", "We hope you don't hate it."],
    padding=True,
    truncation=True,
    max_length=512,
    return_tensors="pt",
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_batch = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} transformers library.&quot;</span>, <span class="hljs-string">&quot;We hope you don&#x27;t hate it.&quot;</span>],
<span class="hljs-meta">... </span>    padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    max_length=<span class="hljs-number">512</span>,
<span class="hljs-meta">... </span>    return_tensors=<span class="hljs-string">&quot;pt&quot;</span>,
<span class="hljs-meta">... </span>)`}}),{c(){E(s.$$.fragment)},l(o){k(s.$$.fragment,o)},m(o,f){w(s,o,f),u=!0},p:ye,i(o){u||(j(s.$$.fragment,o),u=!0)},o(o){A(s.$$.fragment,o),u=!1},d(o){q(s,o)}}}function Gp(P){let s,u;return s=new _e({props:{$$slots:{default:[Vp]},$$scope:{ctx:P}}}),{c(){E(s.$$.fragment)},l(o){k(s.$$.fragment,o)},m(o,f){w(s,o,f),u=!0},p(o,f){const h={};f&2&&(h.$$scope={dirty:f,ctx:o}),s.$set(h)},i(o){u||(j(s.$$.fragment,o),u=!0)},o(o){A(s.$$.fragment,o),u=!1},d(o){q(s,o)}}}function Bp(P){let s,u;return s=new L({props:{code:`tf_batch = tokenizer(
    ["We are very happy to show you the \u{1F917} Transformers library.", "We hope you don't hate it."],
    padding=True,
    truncation=True,
    max_length=512,
    return_tensors="tf",
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_batch = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>, <span class="hljs-string">&quot;We hope you don&#x27;t hate it.&quot;</span>],
<span class="hljs-meta">... </span>    padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    max_length=<span class="hljs-number">512</span>,
<span class="hljs-meta">... </span>    return_tensors=<span class="hljs-string">&quot;tf&quot;</span>,
<span class="hljs-meta">... </span>)`}}),{c(){E(s.$$.fragment)},l(o){k(s.$$.fragment,o)},m(o,f){w(s,o,f),u=!0},p:ye,i(o){u||(j(s.$$.fragment,o),u=!0)},o(o){A(s.$$.fragment,o),u=!1},d(o){q(s,o)}}}function Yp(P){let s,u;return s=new _e({props:{$$slots:{default:[Bp]},$$scope:{ctx:P}}}),{c(){E(s.$$.fragment)},l(o){k(s.$$.fragment,o)},m(o,f){w(s,o,f),u=!0},p(o,f){const h={};f&2&&(h.$$scope={dirty:f,ctx:o}),s.$set(h)},i(o){u||(j(s.$$.fragment,o),u=!0)},o(o){A(s.$$.fragment,o),u=!1},d(o){q(s,o)}}}function Jp(P){let s,u,o,f,h,g,C,M;return{c(){s=n("p"),u=r("Veja o "),o=n("a"),f=r("sum\xE1rio de tarefas"),h=r(" para qual classe de "),g=n("code"),C=r("AutoModel"),M=r(" usar para cada tarefa."),this.h()},l(x){s=i(x,"P",{});var O=p(s);u=l(O,"Veja o "),o=i(O,"A",{href:!0});var S=p(o);f=l(S,"sum\xE1rio de tarefas"),S.forEach(t),h=l(O," para qual classe de "),g=i(O,"CODE",{});var I=p(g);C=l(I,"AutoModel"),I.forEach(t),M=l(O," usar para cada tarefa."),O.forEach(t),this.h()},h(){b(o,"href","./task_summary")},m(x,O){c(x,s,O),a(s,u),a(s,o),a(o,f),a(s,h),a(s,g),a(g,C),a(s,M)},d(x){x&&t(s)}}}function Qp(P){let s,u,o,f,h,g,C,M,x,O,S,I,F,U,z,_,y,D,W,R,oe,Y,ee,J,V,X,Q,K,ue,re,de,le,ae,ne,$e,T,N,ie;return _=new L({props:{code:`from transformers import AutoModelForSequenceClassification

model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)`}}),D=new vt({props:{$$slots:{default:[Jp]},$$scope:{ctx:P}}}),X=new L({props:{code:"pt_outputs = pt_model(**pt_batch)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_outputs = pt_model(**pt_batch)'}}),N=new L({props:{code:`from torch import nn

pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)
print(pt_predictions)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn

<span class="hljs-meta">&gt;&gt;&gt; </span>pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(pt_predictions)
tensor([[<span class="hljs-number">0.0021</span>, <span class="hljs-number">0.0018</span>, <span class="hljs-number">0.0115</span>, <span class="hljs-number">0.2121</span>, <span class="hljs-number">0.7725</span>],
        [<span class="hljs-number">0.2084</span>, <span class="hljs-number">0.1826</span>, <span class="hljs-number">0.1969</span>, <span class="hljs-number">0.1755</span>, <span class="hljs-number">0.2365</span>]], grad_fn=&lt;SoftmaxBackward0&gt;)`}}),{c(){s=n("p"),u=r("\u{1F917} Transformers fornecem uma maneira simples e unificada de carregar inst\xE2ncias pr\xE9-treinadas. Isso significa que voc\xEA pode carregar um "),o=n("code"),f=r("AutoModel"),h=r(" como carregaria um "),g=n("code"),C=r("AutoTokenizer"),M=r(". A \xFAnica diferen\xE7a \xE9 selecionar o "),x=n("code"),O=r("AutoModel"),S=r(" correto para a tarefa. Como voc\xEA est\xE1 fazendo classifica\xE7\xE3o de texto ou sequ\xEAncia, carregue "),I=n("code"),F=r("AutoModelForSequenceClassification"),U=r(":"),z=d(),E(_.$$.fragment),y=d(),E(D.$$.fragment),W=d(),R=n("p"),oe=r("Agora voc\xEA pode passar seu grupo de entradas pr\xE9-processadas diretamente para o modelo. Voc\xEA apenas tem que descompactar o dicion\xE1rio usando "),Y=n("code"),ee=r("**"),J=r(":"),V=d(),E(X.$$.fragment),Q=d(),K=n("p"),ue=r("O modelo gera as ativa\xE7\xF5es finais no atributo "),re=n("code"),de=r("logits"),le=r(". Aplique a fun\xE7\xE3o softmax aos "),ae=n("code"),ne=r("logits"),$e=r(" para recuperar as probabilidades:"),T=d(),E(N.$$.fragment)},l(v){s=i(v,"P",{});var H=p(s);u=l(H,"\u{1F917} Transformers fornecem uma maneira simples e unificada de carregar inst\xE2ncias pr\xE9-treinadas. Isso significa que voc\xEA pode carregar um "),o=i(H,"CODE",{});var me=p(o);f=l(me,"AutoModel"),me.forEach(t),h=l(H," como carregaria um "),g=i(H,"CODE",{});var Ce=p(g);C=l(Ce,"AutoTokenizer"),Ce.forEach(t),M=l(H,". A \xFAnica diferen\xE7a \xE9 selecionar o "),x=i(H,"CODE",{});var fe=p(x);O=l(fe,"AutoModel"),fe.forEach(t),S=l(H," correto para a tarefa. Como voc\xEA est\xE1 fazendo classifica\xE7\xE3o de texto ou sequ\xEAncia, carregue "),I=i(H,"CODE",{});var ge=p(I);F=l(ge,"AutoModelForSequenceClassification"),ge.forEach(t),U=l(H,":"),H.forEach(t),z=$(v),k(_.$$.fragment,v),y=$(v),k(D.$$.fragment,v),W=$(v),R=i(v,"P",{});var pe=p(R);oe=l(pe,"Agora voc\xEA pode passar seu grupo de entradas pr\xE9-processadas diretamente para o modelo. Voc\xEA apenas tem que descompactar o dicion\xE1rio usando "),Y=i(pe,"CODE",{});var Fe=p(Y);ee=l(Fe,"**"),Fe.forEach(t),J=l(pe,":"),pe.forEach(t),V=$(v),k(X.$$.fragment,v),Q=$(v),K=i(v,"P",{});var ve=p(K);ue=l(ve,"O modelo gera as ativa\xE7\xF5es finais no atributo "),re=i(ve,"CODE",{});var Ba=p(re);de=l(Ba,"logits"),Ba.forEach(t),le=l(ve,". Aplique a fun\xE7\xE3o softmax aos "),ae=i(ve,"CODE",{});var da=p(ae);ne=l(da,"logits"),da.forEach(t),$e=l(ve," para recuperar as probabilidades:"),ve.forEach(t),T=$(v),k(N.$$.fragment,v)},m(v,H){c(v,s,H),a(s,u),a(s,o),a(o,f),a(s,h),a(s,g),a(g,C),a(s,M),a(s,x),a(x,O),a(s,S),a(s,I),a(I,F),a(s,U),c(v,z,H),w(_,v,H),c(v,y,H),w(D,v,H),c(v,W,H),c(v,R,H),a(R,oe),a(R,Y),a(Y,ee),a(R,J),c(v,V,H),w(X,v,H),c(v,Q,H),c(v,K,H),a(K,ue),a(K,re),a(re,de),a(K,le),a(K,ae),a(ae,ne),a(K,$e),c(v,T,H),w(N,v,H),ie=!0},p(v,H){const me={};H&2&&(me.$$scope={dirty:H,ctx:v}),D.$set(me)},i(v){ie||(j(_.$$.fragment,v),j(D.$$.fragment,v),j(X.$$.fragment,v),j(N.$$.fragment,v),ie=!0)},o(v){A(_.$$.fragment,v),A(D.$$.fragment,v),A(X.$$.fragment,v),A(N.$$.fragment,v),ie=!1},d(v){v&&t(s),v&&t(z),q(_,v),v&&t(y),q(D,v),v&&t(W),v&&t(R),v&&t(V),q(X,v),v&&t(Q),v&&t(K),v&&t(T),q(N,v)}}}function Kp(P){let s,u;return s=new _e({props:{$$slots:{default:[Qp]},$$scope:{ctx:P}}}),{c(){E(s.$$.fragment)},l(o){k(s.$$.fragment,o)},m(o,f){w(s,o,f),u=!0},p(o,f){const h={};f&2&&(h.$$scope={dirty:f,ctx:o}),s.$set(h)},i(o){u||(j(s.$$.fragment,o),u=!0)},o(o){A(s.$$.fragment,o),u=!1},d(o){q(s,o)}}}function Zp(P){let s,u,o,f,h,g,C,M;return{c(){s=n("p"),u=r("Veja o "),o=n("a"),f=r("sum\xE1rio de tarefas"),h=r(" para qual classe de "),g=n("code"),C=r("AutoModel"),M=r(" usar para cada tarefa."),this.h()},l(x){s=i(x,"P",{});var O=p(s);u=l(O,"Veja o "),o=i(O,"A",{href:!0});var S=p(o);f=l(S,"sum\xE1rio de tarefas"),S.forEach(t),h=l(O," para qual classe de "),g=i(O,"CODE",{});var I=p(g);C=l(I,"AutoModel"),I.forEach(t),M=l(O," usar para cada tarefa."),O.forEach(t),this.h()},h(){b(o,"href","./task_summary")},m(x,O){c(x,s,O),a(s,u),a(s,o),a(o,f),a(s,h),a(s,g),a(g,C),a(s,M)},d(x){x&&t(s)}}}function Xp(P){let s,u,o,f,h,g,C,M,x,O,S,I,F,U,z,_,y,D,W,R,oe,Y,ee,J,V,X,Q,K,ue,re,de,le,ae,ne,$e;return _=new L({props:{code:`from transformers import TFAutoModelForSequenceClassification

model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)`}}),D=new vt({props:{$$slots:{default:[Zp]},$$scope:{ctx:P}}}),ee=new L({props:{code:"tf_outputs = tf_model(tf_batch)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_outputs = tf_model(tf_batch)'}}),ne=new L({props:{code:`import tensorflow as tf

tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-1)
tf_predictions`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_predictions`}}),{c(){s=n("p"),u=r("\u{1F917} Transformers fornecem uma maneira simples e unificada de carregar inst\xE2ncias pr\xE9-treinadas. Isso significa que voc\xEA pode carregar um "),o=n("code"),f=r("TFAutoModel"),h=r(" como carregaria um "),g=n("code"),C=r("AutoTokenizer"),M=r(". A \xFAnica diferen\xE7a \xE9 selecionar o "),x=n("code"),O=r("TFAutoModel"),S=r(" correto para a tarefa. Como voc\xEA est\xE1 fazendo classifica\xE7\xE3o de texto ou sequ\xEAncia, carregue "),I=n("code"),F=r("TFAutoModelForSequenceClassification"),U=r(":"),z=d(),E(_.$$.fragment),y=d(),E(D.$$.fragment),W=d(),R=n("p"),oe=r("Agora voc\xEA pode passar seu grupo de entradas pr\xE9-processadas diretamente para o modelo atrav\xE9s da passagem de chaves de dicion\xE1rios ao tensor."),Y=d(),E(ee.$$.fragment),J=d(),V=n("p"),X=r("O modelo gera as ativa\xE7\xF5es finais no atributo "),Q=n("code"),K=r("logits"),ue=r(". Aplique a fun\xE7\xE3o softmax aos "),re=n("code"),de=r("logits"),le=r(" para recuperar as probabilidades:"),ae=d(),E(ne.$$.fragment)},l(T){s=i(T,"P",{});var N=p(s);u=l(N,"\u{1F917} Transformers fornecem uma maneira simples e unificada de carregar inst\xE2ncias pr\xE9-treinadas. Isso significa que voc\xEA pode carregar um "),o=i(N,"CODE",{});var ie=p(o);f=l(ie,"TFAutoModel"),ie.forEach(t),h=l(N," como carregaria um "),g=i(N,"CODE",{});var v=p(g);C=l(v,"AutoTokenizer"),v.forEach(t),M=l(N,". A \xFAnica diferen\xE7a \xE9 selecionar o "),x=i(N,"CODE",{});var H=p(x);O=l(H,"TFAutoModel"),H.forEach(t),S=l(N," correto para a tarefa. Como voc\xEA est\xE1 fazendo classifica\xE7\xE3o de texto ou sequ\xEAncia, carregue "),I=i(N,"CODE",{});var me=p(I);F=l(me,"TFAutoModelForSequenceClassification"),me.forEach(t),U=l(N,":"),N.forEach(t),z=$(T),k(_.$$.fragment,T),y=$(T),k(D.$$.fragment,T),W=$(T),R=i(T,"P",{});var Ce=p(R);oe=l(Ce,"Agora voc\xEA pode passar seu grupo de entradas pr\xE9-processadas diretamente para o modelo atrav\xE9s da passagem de chaves de dicion\xE1rios ao tensor."),Ce.forEach(t),Y=$(T),k(ee.$$.fragment,T),J=$(T),V=i(T,"P",{});var fe=p(V);X=l(fe,"O modelo gera as ativa\xE7\xF5es finais no atributo "),Q=i(fe,"CODE",{});var ge=p(Q);K=l(ge,"logits"),ge.forEach(t),ue=l(fe,". Aplique a fun\xE7\xE3o softmax aos "),re=i(fe,"CODE",{});var pe=p(re);de=l(pe,"logits"),pe.forEach(t),le=l(fe," para recuperar as probabilidades:"),fe.forEach(t),ae=$(T),k(ne.$$.fragment,T)},m(T,N){c(T,s,N),a(s,u),a(s,o),a(o,f),a(s,h),a(s,g),a(g,C),a(s,M),a(s,x),a(x,O),a(s,S),a(s,I),a(I,F),a(s,U),c(T,z,N),w(_,T,N),c(T,y,N),w(D,T,N),c(T,W,N),c(T,R,N),a(R,oe),c(T,Y,N),w(ee,T,N),c(T,J,N),c(T,V,N),a(V,X),a(V,Q),a(Q,K),a(V,ue),a(V,re),a(re,de),a(V,le),c(T,ae,N),w(ne,T,N),$e=!0},p(T,N){const ie={};N&2&&(ie.$$scope={dirty:N,ctx:T}),D.$set(ie)},i(T){$e||(j(_.$$.fragment,T),j(D.$$.fragment,T),j(ee.$$.fragment,T),j(ne.$$.fragment,T),$e=!0)},o(T){A(_.$$.fragment,T),A(D.$$.fragment,T),A(ee.$$.fragment,T),A(ne.$$.fragment,T),$e=!1},d(T){T&&t(s),T&&t(z),q(_,T),T&&t(y),q(D,T),T&&t(W),T&&t(R),T&&t(Y),q(ee,T),T&&t(J),T&&t(V),T&&t(ae),q(ne,T)}}}function em(P){let s,u;return s=new _e({props:{$$slots:{default:[Xp]},$$scope:{ctx:P}}}),{c(){E(s.$$.fragment)},l(o){k(s.$$.fragment,o)},m(o,f){w(s,o,f),u=!0},p(o,f){const h={};f&2&&(h.$$scope={dirty:f,ctx:o}),s.$set(h)},i(o){u||(j(s.$$.fragment,o),u=!0)},o(o){A(s.$$.fragment,o),u=!1},d(o){q(s,o)}}}function am(P){let s,u,o,f,h;return{c(){s=n("p"),u=r("Todos os modelos de \u{1F917} Transformers (PyTorch ou TensorFlow) geram tensores "),o=n("em"),f=r("antes"),h=r(" da fun\xE7\xE3o de ativa\xE7\xE3o final (como softmax) pois essa fun\xE7\xE3o algumas vezes \xE9 fundida com a perda.")},l(g){s=i(g,"P",{});var C=p(s);u=l(C,"Todos os modelos de \u{1F917} Transformers (PyTorch ou TensorFlow) geram tensores "),o=i(C,"EM",{});var M=p(o);f=l(M,"antes"),M.forEach(t),h=l(C," da fun\xE7\xE3o de ativa\xE7\xE3o final (como softmax) pois essa fun\xE7\xE3o algumas vezes \xE9 fundida com a perda."),C.forEach(t)},m(g,C){c(g,s,C),a(s,u),a(s,o),a(o,f),a(s,h)},d(g){g&&t(s)}}}function tm(P){let s,u,o,f,h;return{c(){s=n("p"),u=r(`As sa\xEDdas do modelo \u{1F917} Transformers s\xE3o classes de dados especiais para que seus atributos sejam preenchidos automaticamente em um IDE.
As sa\xEDdas do modelo tamb\xE9m se comportam como uma tupla ou um dicion\xE1rio (por exemplo, voc\xEA pode indexar com um inteiro, uma parte ou uma string), caso em que os atributos `),o=n("code"),f=r("None"),h=r(" s\xE3o ignorados.")},l(g){s=i(g,"P",{});var C=p(s);u=l(C,`As sa\xEDdas do modelo \u{1F917} Transformers s\xE3o classes de dados especiais para que seus atributos sejam preenchidos automaticamente em um IDE.
As sa\xEDdas do modelo tamb\xE9m se comportam como uma tupla ou um dicion\xE1rio (por exemplo, voc\xEA pode indexar com um inteiro, uma parte ou uma string), caso em que os atributos `),o=i(C,"CODE",{});var M=p(o);f=l(M,"None"),M.forEach(t),h=l(C," s\xE3o ignorados."),C.forEach(t)},m(g,C){c(g,s,C),a(s,u),a(s,o),a(o,f),a(s,h)},d(g){g&&t(s)}}}function sm(P){let s,u,o,f,h,g,C,M,x,O,S,I,F,U,z,_;return C=new L({props:{code:`pt_save_directory = "./pt_save_pretrained"
tokenizer.save_pretrained(pt_save_directory)
pt_model.save_pretrained(pt_save_directory)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_save_directory = <span class="hljs-string">&quot;./pt_save_pretrained&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(pt_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model.save_pretrained(pt_save_directory)`}}),z=new L({props:{code:'pt_model = AutoModelForSequenceClassification.from_pretrained("./pt_save_pretrained")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./pt_save_pretrained&quot;</span>)'}}),{c(){s=n("p"),u=r("Uma vez que seu modelo estiver afinado, voc\xEA pode salv\xE1-lo com seu Tokenizer usando "),o=n("code"),f=r("PreTrainedModel.save_pretrained()"),h=r(":"),g=d(),E(C.$$.fragment),M=d(),x=n("p"),O=r("Quando voc\xEA estiver pronto para us\xE1-lo novamente, recarregue com "),S=n("code"),I=r("PreTrainedModel.from_pretrained()"),F=r(":"),U=d(),E(z.$$.fragment)},l(y){s=i(y,"P",{});var D=p(s);u=l(D,"Uma vez que seu modelo estiver afinado, voc\xEA pode salv\xE1-lo com seu Tokenizer usando "),o=i(D,"CODE",{});var W=p(o);f=l(W,"PreTrainedModel.save_pretrained()"),W.forEach(t),h=l(D,":"),D.forEach(t),g=$(y),k(C.$$.fragment,y),M=$(y),x=i(y,"P",{});var R=p(x);O=l(R,"Quando voc\xEA estiver pronto para us\xE1-lo novamente, recarregue com "),S=i(R,"CODE",{});var oe=p(S);I=l(oe,"PreTrainedModel.from_pretrained()"),oe.forEach(t),F=l(R,":"),R.forEach(t),U=$(y),k(z.$$.fragment,y)},m(y,D){c(y,s,D),a(s,u),a(s,o),a(o,f),a(s,h),c(y,g,D),w(C,y,D),c(y,M,D),c(y,x,D),a(x,O),a(x,S),a(S,I),a(x,F),c(y,U,D),w(z,y,D),_=!0},p:ye,i(y){_||(j(C.$$.fragment,y),j(z.$$.fragment,y),_=!0)},o(y){A(C.$$.fragment,y),A(z.$$.fragment,y),_=!1},d(y){y&&t(s),y&&t(g),q(C,y),y&&t(M),y&&t(x),y&&t(U),q(z,y)}}}function om(P){let s,u;return s=new _e({props:{$$slots:{default:[sm]},$$scope:{ctx:P}}}),{c(){E(s.$$.fragment)},l(o){k(s.$$.fragment,o)},m(o,f){w(s,o,f),u=!0},p(o,f){const h={};f&2&&(h.$$scope={dirty:f,ctx:o}),s.$set(h)},i(o){u||(j(s.$$.fragment,o),u=!0)},o(o){A(s.$$.fragment,o),u=!1},d(o){q(s,o)}}}function rm(P){let s,u,o,f,h,g,C,M,x,O,S,I,F,U,z;return C=new L({props:{code:`tf_save_directory = "./tf_save_pretrained"
tokenizer.save_pretrained(tf_save_directory)
tf_model.save_pretrained(tf_save_directory)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_save_directory = <span class="hljs-string">&quot;./tf_save_pretrained&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(tf_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model.save_pretrained(tf_save_directory)`}}),U=new L({props:{code:'tf_model = TFAutoModelForSequenceClassification.from_pretrained("./tf_save_pretrained")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./tf_save_pretrained&quot;</span>)'}}),{c(){s=n("p"),u=r("Uma vez que seu modelo estiver afinado, voc\xEA pode salv\xE1-lo com seu Tokenizer usando "),o=n("code"),f=r("TFPreTrainedModel.save_pretrained()"),h=r(":"),g=d(),E(C.$$.fragment),M=d(),x=n("p"),O=r("Quando voc\xEA estiver pronto para us\xE1-lo novamente, recarregue com "),S=n("code"),I=r("TFPreTrainedModel.from_pretrained()"),F=d(),E(U.$$.fragment)},l(_){s=i(_,"P",{});var y=p(s);u=l(y,"Uma vez que seu modelo estiver afinado, voc\xEA pode salv\xE1-lo com seu Tokenizer usando "),o=i(y,"CODE",{});var D=p(o);f=l(D,"TFPreTrainedModel.save_pretrained()"),D.forEach(t),h=l(y,":"),y.forEach(t),g=$(_),k(C.$$.fragment,_),M=$(_),x=i(_,"P",{});var W=p(x);O=l(W,"Quando voc\xEA estiver pronto para us\xE1-lo novamente, recarregue com "),S=i(W,"CODE",{});var R=p(S);I=l(R,"TFPreTrainedModel.from_pretrained()"),R.forEach(t),W.forEach(t),F=$(_),k(U.$$.fragment,_)},m(_,y){c(_,s,y),a(s,u),a(s,o),a(o,f),a(s,h),c(_,g,y),w(C,_,y),c(_,M,y),c(_,x,y),a(x,O),a(x,S),a(S,I),c(_,F,y),w(U,_,y),z=!0},p:ye,i(_){z||(j(C.$$.fragment,_),j(U.$$.fragment,_),z=!0)},o(_){A(C.$$.fragment,_),A(U.$$.fragment,_),z=!1},d(_){_&&t(s),_&&t(g),q(C,_),_&&t(M),_&&t(x),_&&t(F),q(U,_)}}}function lm(P){let s,u;return s=new _e({props:{$$slots:{default:[rm]},$$scope:{ctx:P}}}),{c(){E(s.$$.fragment)},l(o){k(s.$$.fragment,o)},m(o,f){w(s,o,f),u=!0},p(o,f){const h={};f&2&&(h.$$scope={dirty:f,ctx:o}),s.$set(h)},i(o){u||(j(s.$$.fragment,o),u=!0)},o(o){A(s.$$.fragment,o),u=!1},d(o){q(s,o)}}}function nm(P){let s,u;return s=new L({props:{code:`from transformers import AutoModel

tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)
pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=<span class="hljs-literal">True</span>)`}}),{c(){E(s.$$.fragment)},l(o){k(s.$$.fragment,o)},m(o,f){w(s,o,f),u=!0},p:ye,i(o){u||(j(s.$$.fragment,o),u=!0)},o(o){A(s.$$.fragment,o),u=!1},d(o){q(s,o)}}}function im(P){let s,u;return s=new _e({props:{$$slots:{default:[nm]},$$scope:{ctx:P}}}),{c(){E(s.$$.fragment)},l(o){k(s.$$.fragment,o)},m(o,f){w(s,o,f),u=!0},p(o,f){const h={};f&2&&(h.$$scope={dirty:f,ctx:o}),s.$set(h)},i(o){u||(j(s.$$.fragment,o),u=!0)},o(o){A(s.$$.fragment,o),u=!1},d(o){q(s,o)}}}function pm(P){let s,u;return s=new L({props:{code:`from transformers import TFAutoModel

tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)
tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=<span class="hljs-literal">True</span>)`}}),{c(){E(s.$$.fragment)},l(o){k(s.$$.fragment,o)},m(o,f){w(s,o,f),u=!0},p:ye,i(o){u||(j(s.$$.fragment,o),u=!0)},o(o){A(s.$$.fragment,o),u=!1},d(o){q(s,o)}}}function mm(P){let s,u;return s=new _e({props:{$$slots:{default:[pm]},$$scope:{ctx:P}}}),{c(){E(s.$$.fragment)},l(o){k(s.$$.fragment,o)},m(o,f){w(s,o,f),u=!0},p(o,f){const h={};f&2&&(h.$$scope={dirty:f,ctx:o}),s.$set(h)},i(o){u||(j(s.$$.fragment,o),u=!0)},o(o){A(s.$$.fragment,o),u=!1},d(o){q(s,o)}}}function cm(P){let s,u,o,f,h,g,C,M,x,O,S,I,F,U,z,_,y,D,W,R,oe,Y,ee,J,V,X,Q,K,ue,re,de,le,ae,ne,$e,T,N,ie,v,H,me,Ce,fe,ge,pe,Fe,ve,Ba,da,G,bt,Zo,Xo,Et,er,ar,kt,tr,sr,wt,or,rr,jt,lr,nr,At,ir,pr,qt,mr,cr,Tt,ur,Ts,$a,xt,fr,dr,xs,be,yt,$r,hr,Ct,_r,gr,zt,vr,ys,ha,Pt,br,Er,Cs,Ne,Ot,kr,wr,Mt,jr,zs,Ue,Ps,ze,He,Dt,_a,Ar,St,qr,Os,Le,Tr,It,xr,yr,Ms,Ya,Cr,Ds,Re,Ss,We,zr,Ft,Pr,Or,Is,ga,Fs,Ee,Mr,va,Dr,Sr,Nt,Ir,Fr,Ns,ba,Us,Ve,Nr,Ut,Ur,Hr,Hs,Ea,Ls,ke,Lr,Ht,Rr,Wr,ka,Vr,Gr,Rs,wa,Ws,Ge,Br,Lt,Yr,Jr,Vs,ja,Gs,we,Qr,Aa,Kr,Zr,qa,Xr,el,Bs,Ta,Ys,Ja,al,Js,xa,Qs,Be,tl,Rt,sl,ol,Ks,ya,Zs,Ye,rl,Qa,ll,nl,Xs,Pe,Je,Wt,Ca,il,Vt,pl,eo,he,ml,Gt,cl,ul,za,fl,dl,Pa,$l,hl,ao,Oa,to,Qe,so,je,_l,Bt,gl,vl,Yt,bl,El,oo,Ma,ro,Ae,kl,Ka,wl,jl,Za,Al,ql,lo,Oe,Ke,Jt,Da,Tl,Qt,xl,no,Sa,io,Z,yl,Kt,Cl,zl,Zt,Pl,Ol,Xt,Ml,Dl,Xa,Sl,Il,es,Fl,Nl,as,Ul,Hl,po,qe,Ll,ts,Rl,Wl,ss,Vl,Gl,mo,Me,Ze,os,Ia,Bl,rs,Yl,co,Te,Jl,ls,Ql,Kl,et,Zl,Xl,uo,Xe,en,ns,an,tn,fo,Fa,$o,ea,sn,is,on,rn,ho,at,ln,_o,Na,go,tt,nn,vo,aa,st,ot,pn,mn,cn,rt,lt,un,fn,bo,ta,dn,ps,$n,hn,Eo,sa,ko,oa,_n,nt,gn,vn,wo,De,ra,ms,Ua,bn,cs,En,jo,la,Ao,na,qo,B,kn,Ha,us,wn,jn,fs,An,qn,La,Tn,xn,ds,yn,Cn,$s,zn,Pn,Ra,On,Mn,it,Dn,Sn,To,ia,xo,Se,pa,hs,Wa,In,_s,Fn,yo,ma,Co,xe,Nn,gs,Un,Hn,vs,Ln,Rn,zo,ca,Po;return g=new fa({}),S=new Mp({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/pt/quicktour.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/pt/pytorch/quicktour.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/pt/tensorflow/quicktour.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/pt/quicktour.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/pt/pytorch/quicktour.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/pt/tensorflow/quicktour.ipynb"}]}}),Y=new vt({props:{$$slots:{default:[Dp]},$$scope:{ctx:P}}}),Q=new fa({}),N=new xp({props:{id:"tiZFewofSLM"}}),Ue=new vt({props:{$$slots:{default:[Sp]},$$scope:{ctx:P}}}),_a=new fa({}),Re=new gt({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Up],pytorch:[Fp]},$$scope:{ctx:P}}}),ga=new L({props:{code:`from transformers import pipeline

classifier = pipeline("sentiment-analysis")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>classifier = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>)`}}),ba=new L({props:{code:'classifier("We are very happy to show you the \u{1F917} Transformers library.")',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>classifier(<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;POSITIVE&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9998</span>}]`}}),Ea=new L({props:{code:`results = classifier(["We are very happy to show you the \u{1F917} Transformers library.", "We hope you don't hate it."])
for result in results:
    print(f"label: {result['label']}, with score: {round(result['score'], 4)}")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>results = classifier([<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>, <span class="hljs-string">&quot;We hope you don&#x27;t hate it.&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> result <span class="hljs-keyword">in</span> results:
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;label: <span class="hljs-subst">{result[<span class="hljs-string">&#x27;label&#x27;</span>]}</span>, with score: <span class="hljs-subst">{<span class="hljs-built_in">round</span>(result[<span class="hljs-string">&#x27;score&#x27;</span>], <span class="hljs-number">4</span>)}</span>&quot;</span>)
label: POSITIVE, <span class="hljs-keyword">with</span> score: <span class="hljs-number">0.9998</span>
label: NEGATIVE, <span class="hljs-keyword">with</span> score: <span class="hljs-number">0.5309</span>`}}),wa=new L({props:{code:"pip install datasets ",highlighted:"pip install datasets "}}),ja=new L({props:{code:`import torch
from transformers import pipeline

speech_recognizer = pipeline("automatic-speech-recognition", model="facebook/wav2vec2-base-960h")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>speech_recognizer = pipeline(<span class="hljs-string">&quot;automatic-speech-recognition&quot;</span>, model=<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)`}}),Ta=new L({props:{code:`from datasets import load_dataset, Audio

dataset = load_dataset("PolyAI/minds14", name="en-US", split="train")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Audio

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;PolyAI/minds14&quot;</span>, name=<span class="hljs-string">&quot;en-US&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`}}),xa=new L({props:{code:'dataset = dataset.cast_column("audio", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))'}}),ya=new L({props:{code:`result = speech_recognizer(dataset[:4]["audio"])
print([d["text"] for d in result])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>result = speech_recognizer(dataset[:<span class="hljs-number">4</span>][<span class="hljs-string">&quot;audio&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>([d[<span class="hljs-string">&quot;text&quot;</span>] <span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> result])
[<span class="hljs-string">&#x27;I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT&#x27;</span>, <span class="hljs-string">&quot;FONDERING HOW I&#x27;D SET UP A JOIN TO HET WITH MY WIFE AND WHERE THE AP MIGHT BE&quot;</span>, <span class="hljs-string">&quot;I I&#x27;D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I&#x27;M NOT SEEING THE OPTION TO DO IT ON THE APSO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AND I&#x27;M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS&quot;</span>, <span class="hljs-string">&#x27;HOW DO I TURN A JOIN A COUNT&#x27;</span>]`}}),Ca=new fa({}),Oa=new L({props:{code:'model_name = "nlptown/bert-base-multilingual-uncased-sentiment"',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>'}}),Qe=new gt({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Wp],pytorch:[Lp]},$$scope:{ctx:P}}}),Ma=new L({props:{code:`classifier = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)
classifier("Nous sommes tr\xE8s heureux de vous pr\xE9senter la biblioth\xE8que \u{1F917} Transformers.")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>classifier = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>, model=model, tokenizer=tokenizer)
<span class="hljs-meta">&gt;&gt;&gt; </span>classifier(<span class="hljs-string">&quot;Nous sommes tr\xE8s heureux de vous pr\xE9senter la biblioth\xE8que \u{1F917} Transformers.&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;5 stars&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.7273</span>}]`}}),Da=new fa({}),Sa=new xp({props:{id:"AhChOFRegn4"}}),Ia=new fa({}),Fa=new L({props:{code:`from transformers import AutoTokenizer

model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
tokenizer = AutoTokenizer.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`}}),Na=new L({props:{code:`encoding = tokenizer("We are very happy to show you the \u{1F917} Transformers library.")
print(encoding)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>encoding = tokenizer(<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoding)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">11312</span>, <span class="hljs-number">10320</span>, <span class="hljs-number">12495</span>, <span class="hljs-number">19308</span>, <span class="hljs-number">10114</span>, <span class="hljs-number">11391</span>, <span class="hljs-number">10855</span>, <span class="hljs-number">10103</span>, <span class="hljs-number">100</span>, <span class="hljs-number">58263</span>, <span class="hljs-number">13299</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>],
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`}}),sa=new gt({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Yp],pytorch:[Gp]},$$scope:{ctx:P}}}),Ua=new fa({}),la=new gt({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[em],pytorch:[Kp]},$$scope:{ctx:P}}}),na=new vt({props:{$$slots:{default:[am]},$$scope:{ctx:P}}}),ia=new vt({props:{$$slots:{default:[tm]},$$scope:{ctx:P}}}),Wa=new fa({}),ma=new gt({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[lm],pytorch:[om]},$$scope:{ctx:P}}}),ca=new gt({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[mm],pytorch:[im]},$$scope:{ctx:P}}}),{c(){s=n("meta"),u=d(),o=n("h1"),f=n("a"),h=n("span"),E(g.$$.fragment),C=d(),M=n("span"),x=r("Tour r\xE1pido"),O=d(),E(S.$$.fragment),I=d(),F=n("p"),U=r("Comece a trabalhar com \u{1F917} Transformers! Comece usando "),z=n("code"),_=r("pipeline()"),y=r(" para r\xE1pida infer\xEAncia e facilmente carregue um modelo pr\xE9-treinado e um tokenizer com "),D=n("a"),W=r("AutoClass"),R=r(" para resolver tarefas de texto, vis\xE3o ou \xE1udio."),oe=d(),E(Y.$$.fragment),ee=d(),J=n("h2"),V=n("a"),X=n("span"),E(Q.$$.fragment),K=d(),ue=n("span"),re=r("Pipeline"),de=d(),le=n("p"),ae=n("code"),ne=r("pipeline()"),$e=r(" \xE9 a maneira mais f\xE1cil de usar um modelo pr\xE9-treinado para uma dada tarefa."),T=d(),E(N.$$.fragment),ie=d(),v=n("p"),H=r("A "),me=n("code"),Ce=r("pipeline()"),fe=r(" apoia diversas tarefas fora da caixa:"),ge=d(),pe=n("p"),Fe=n("strong"),ve=r("Texto"),Ba=r(":"),da=d(),G=n("ul"),bt=n("li"),Zo=r("An\xE1lise sentimental: classifica a polaridade de um texto."),Xo=d(),Et=n("li"),er=r("Gera\xE7\xE3o de texto (em Ingl\xEAs): gera texto a partir de uma entrada."),ar=d(),kt=n("li"),tr=r("Reconhecimento de entidade mencionada: legenda cada palavra com uma classe que a representa (pessoa, data, local, etc\u2026)"),sr=d(),wt=n("li"),or=r("Respostas: extrai uma resposta dado algum contexto e uma quest\xE3o"),rr=d(),jt=n("li"),lr=r("M\xE1scara de preenchimento: preenche o espa\xE7o, dado um texto com m\xE1scaras de palavras."),nr=d(),At=n("li"),ir=r("Sumariza\xE7\xE3o: gera o resumo de um texto longo ou documento."),pr=d(),qt=n("li"),mr=r("Tradu\xE7\xE3o: traduz texto para outra l\xEDngua."),cr=d(),Tt=n("li"),ur=r("Extra\xE7\xE3o de caracter\xEDsticas: cria um tensor que representa o texto."),Ts=d(),$a=n("p"),xt=n("strong"),fr=r("Imagem"),dr=r(":"),xs=d(),be=n("ul"),yt=n("li"),$r=r("Classifica\xE7\xE3o de imagens: classifica uma imagem."),hr=d(),Ct=n("li"),_r=r("Segmenta\xE7\xE3o de imagem: classifica cada pixel da imagem."),gr=d(),zt=n("li"),vr=r("Detec\xE7\xE3o de objetos: detecta objetos em uma imagem."),ys=d(),ha=n("p"),Pt=n("strong"),br=r("Audio"),Er=r(":"),Cs=d(),Ne=n("ul"),Ot=n("li"),kr=r("Classfica\xE7\xE3o de \xE1udio: legenda um trecho de \xE1udio fornecido."),wr=d(),Mt=n("li"),jr=r("Reconhecimento de fala autom\xE1tico: transcreve audio em texto."),zs=d(),E(Ue.$$.fragment),Ps=d(),ze=n("h3"),He=n("a"),Dt=n("span"),E(_a.$$.fragment),Ar=d(),St=n("span"),qr=r("Uso da pipeline"),Os=d(),Le=n("p"),Tr=r("No exemplo a seguir, voc\xEA usar\xE1 "),It=n("code"),xr=r("pipeline()"),yr=r(" para an\xE1lise sentimental."),Ms=d(),Ya=n("p"),Cr=r("Instale as seguintes depend\xEAncias se voc\xEA ainda n\xE3o o fez:"),Ds=d(),E(Re.$$.fragment),Ss=d(),We=n("p"),zr=r("Importe "),Ft=n("code"),Pr=r("pipeline()"),Or=r(" e especifique a tarefa que deseja completar:"),Is=d(),E(ga.$$.fragment),Fs=d(),Ee=n("p"),Mr=r("A pipeline baixa and armazena um "),va=n("a"),Dr=r("modelo pr\xE9-treinado"),Sr=r(" padr\xE3o e tokenizer para an\xE1lise sentimental. Agora voc\xEA pode usar "),Nt=n("code"),Ir=r("classifier"),Fr=r(" no texto alvo:"),Ns=d(),E(ba.$$.fragment),Us=d(),Ve=n("p"),Nr=r("Para mais de uma senten\xE7a, passe uma lista para a "),Ut=n("code"),Ur=r("pipeline()"),Hr=r(", a qual retornar\xE1 uma lista de dicion\xE1rios:"),Hs=d(),E(Ea.$$.fragment),Ls=d(),ke=n("p"),Lr=r("A "),Ht=n("code"),Rr=r("pipeline()"),Wr=r(" tamb\xE9m pode iterar sobre um Dataset inteiro. Comece instalando a biblioteca de "),ka=n("a"),Vr=r("\u{1F917} Datasets"),Gr=r(":"),Rs=d(),E(wa.$$.fragment),Ws=d(),Ge=n("p"),Br=r("Crie uma "),Lt=n("code"),Yr=r("pipeline()"),Jr=r(" com a tarefa que deseja resolver e o modelo que deseja usar."),Vs=d(),E(ja.$$.fragment),Gs=d(),we=n("p"),Qr=r("A seguir, carregue uma base de dados (confira a \u{1F917} "),Aa=n("a"),Kr=r("Inicia\xE7\xE3o em Datasets"),Zr=r(" para mais detalhes) que voc\xEA gostaria de iterar sobre. Por exemplo, vamos carregar o dataset "),qa=n("a"),Xr=r("MInDS-14"),el=r(":"),Bs=d(),E(Ta.$$.fragment),Ys=d(),Ja=n("p"),al=r("Precisamos garantir que a taxa de amostragem do conjunto de dados corresponda \xE0 taxa de amostragem em que o facebook/wav2vec2-base-960h foi treinado."),Js=d(),E(xa.$$.fragment),Qs=d(),Be=n("p"),tl=r("Os arquivos de \xE1udio s\xE3o carregados e re-amostrados automaticamente ao chamar a coluna "),Rt=n("code"),sl=r('"audio"'),ol=r(`.
Vamos extrair as arrays de formas de onda originais das primeiras 4 amostras e pass\xE1-las como uma lista para o pipeline:`),Ks=d(),E(ya.$$.fragment),Zs=d(),Ye=n("p"),rl=r("Para um conjunto de dados maior onde as entradas s\xE3o maiores (como em fala ou vis\xE3o), ser\xE1 necess\xE1rio passar um gerador em vez de uma lista que carregue todas as entradas na mem\xF3ria. Consulte a "),Qa=n("a"),ll=r("documenta\xE7\xE3o do pipeline"),nl=r(" para mais informa\xE7\xF5es."),Xs=d(),Pe=n("h3"),Je=n("a"),Wt=n("span"),E(Ca.$$.fragment),il=d(),Vt=n("span"),pl=r("Use outro modelo e tokenizer na pipeline"),eo=d(),he=n("p"),ml=r("A "),Gt=n("code"),cl=r("pipeline()"),ul=r(" pode acomodar qualquer modelo do "),za=n("a"),fl=r("Model Hub"),dl=r(", facilitando sua adapta\xE7\xE3o para outros casos de uso. Por exemplo, se voc\xEA quiser um modelo capaz de lidar com texto em franc\xEAs, use as tags no Model Hub para filtrar um modelo apropriado. O principal resultado filtrado retorna um "),Pa=n("a"),$l=r("modelo BERT"),hl=r(" bil\xEDngue ajustado para an\xE1lise de sentimentos. \xD3timo, vamos usar este modelo!"),ao=d(),E(Oa.$$.fragment),to=d(),E(Qe.$$.fragment),so=d(),je=n("p"),_l=r("Ent\xE3o voc\xEA pode especificar o modelo e o tokenizador na "),Bt=n("code"),gl=r("pipeline()"),vl=r(" e aplicar o "),Yt=n("code"),bl=r("classifier"),El=r(" no seu texto alvo:"),oo=d(),E(Ma.$$.fragment),ro=d(),Ae=n("p"),kl=r("Se voc\xEA n\xE3o conseguir achar um modelo para o seu caso de uso, precisar\xE1 usar fine-tune em um modelo pr\xE9-treinado nos seus dados. Veja nosso "),Ka=n("a"),wl=r("tutorial de fine-tuning"),jl=r(" para descobrir como. Finalmente, depois que voc\xEA tiver usado esse processo em seu modelo, considere compartilh\xE1-lo conosco (veja o tutorial "),Za=n("a"),Al=r("aqui"),ql=r(") na plataforma Model Hub afim de democratizar NLP! \u{1F917}"),lo=d(),Oe=n("h2"),Ke=n("a"),Jt=n("span"),E(Da.$$.fragment),Tl=d(),Qt=n("span"),xl=r("AutoClass"),no=d(),E(Sa.$$.fragment),io=d(),Z=n("p"),yl=r("Por baixo dos panos, as classes "),Kt=n("code"),Cl=r("AutoModelForSequenceClassification"),zl=r(" e "),Zt=n("code"),Pl=r("AutoTokenizer"),Ol=r(" trabalham juntas para fortificar o "),Xt=n("code"),Ml=r("pipeline()"),Dl=r(". Um "),Xa=n("a"),Sl=r("AutoClass"),Il=r(" \xE9 um atalho que automaticamente recupera a arquitetura de um modelo pr\xE9-treinado a partir de seu nome ou caminho. Basta selecionar a "),es=n("code"),Fl=r("AutoClass"),Nl=r(" apropriada para sua tarefa e seu tokenizer associado com "),as=n("code"),Ul=r("AutoTokenizer"),Hl=r("."),po=d(),qe=n("p"),Ll=r("Vamos voltar ao nosso exemplo e ver como voc\xEA pode usar a "),ts=n("code"),Rl=r("AutoClass"),Wl=r(" para replicar os resultados do "),ss=n("code"),Vl=r("pipeline()"),Gl=r("."),mo=d(),Me=n("h3"),Ze=n("a"),os=n("span"),E(Ia.$$.fragment),Bl=d(),rs=n("span"),Yl=r("AutoTokenizer"),co=d(),Te=n("p"),Jl=r("Um tokenizer \xE9 respons\xE1vel por pr\xE9-processar o texto em um formato que seja compreens\xEDvel para o modelo. Primeiro, o tokenizer dividir\xE1 o texto em palavras chamadas "),ls=n("em"),Ql=r("tokens"),Kl=r(". Existem v\xE1rias regras que regem o processo de tokeniza\xE7\xE3o, incluindo como dividir uma palavra e em que n\xEDvel (saiba mais sobre tokeniza\xE7\xE3o "),et=n("a"),Zl=r("aqui"),Xl=r("). A coisa mais importante a lembrar, por\xE9m, \xE9 que voc\xEA precisa instanciar o tokenizer com o mesmo nome do modelo para garantir que est\xE1 usando as mesmas regras de tokeniza\xE7\xE3o com as quais um modelo foi pr\xE9-treinado."),uo=d(),Xe=n("p"),en=r("Carregue um tokenizer com "),ns=n("code"),an=r("AutoTokenizer"),tn=r(":"),fo=d(),E(Fa.$$.fragment),$o=d(),ea=n("p"),sn=r("Em seguida, o tokenizer converte os tokens em n\xFAmeros para construir um tensor como entrada para o modelo. Isso \xE9 conhecido como o "),is=n("em"),on=r("vocabul\xE1rio"),rn=r(" do modelo."),ho=d(),at=n("p"),ln=r("Passe o texto para o tokenizer:"),_o=d(),E(Na.$$.fragment),go=d(),tt=n("p"),nn=r("O tokenizer retornar\xE1 um dicion\xE1rio contendo:"),vo=d(),aa=n("ul"),st=n("li"),ot=n("a"),pn=r("input_ids"),mn=r(": representa\xE7\xF5es num\xE9ricas de seus tokens."),cn=d(),rt=n("li"),lt=n("a"),un=r("atttention_mask"),fn=r(": indica quais tokens devem ser atendidos."),bo=d(),ta=n("p"),dn=r("Assim como o "),ps=n("code"),$n=r("pipeline()"),hn=r(", o tokenizer aceitar\xE1 uma lista de entradas. Al\xE9m disso, o tokenizer tamb\xE9m pode preencher e truncar o texto para retornar um lote com comprimento uniforme:"),Eo=d(),E(sa.$$.fragment),ko=d(),oa=n("p"),_n=r("Leia o tutorial de "),nt=n("a"),gn=r("pr\xE9-processamento"),vn=r(" para obter mais detalhes sobre tokeniza\xE7\xE3o."),wo=d(),De=n("h3"),ra=n("a"),ms=n("span"),E(Ua.$$.fragment),bn=d(),cs=n("span"),En=r("AutoModel"),jo=d(),E(la.$$.fragment),Ao=d(),E(na.$$.fragment),qo=d(),B=n("p"),kn=r("Os modelos s\xE3o um standard "),Ha=n("a"),us=n("code"),wn=r("torch.nn.Module"),jn=r(" ou um ["),fs=n("code"),An=r("tf.keras.Model"),qn=r("](https: //"),La=n("a"),Tn=r("www.tensorflow.org/api_docs/python/tf/keras/Model"),xn=r(") para que voc\xEA possa us\xE1-los em seu loop de treinamento habitual. No entanto, para facilitar as coisas, \u{1F917} Transformers fornece uma classe "),ds=n("code"),yn=r("Trainer"),Cn=r(" para PyTorch que adiciona funcionalidade para treinamento distribu\xEDdo, precis\xE3o mista e muito mais. Para o TensorFlow, voc\xEA pode usar o m\xE9todo "),$s=n("code"),zn=r("fit"),Pn=r(" de "),Ra=n("a"),On=r("Keras"),Mn=r(". Consulte o "),it=n("a"),Dn=r("tutorial de treinamento"),Sn=r(" para obter mais detalhes."),To=d(),E(ia.$$.fragment),xo=d(),Se=n("h3"),pa=n("a"),hs=n("span"),E(Wa.$$.fragment),In=d(),_s=n("span"),Fn=r("Salvar um modelo"),yo=d(),E(ma.$$.fragment),Co=d(),xe=n("p"),Nn=r("Um recurso particularmente interessante dos \u{1F917} Transformers \xE9 a capacidade de salvar um modelo e recarreg\xE1-lo como um modelo PyTorch ou TensorFlow. Use "),gs=n("code"),Un=r("from_pt"),Hn=r(" ou "),vs=n("code"),Ln=r("from_tf"),Rn=r(" para converter o modelo de um framework para outro:"),zo=d(),E(ca.$$.fragment),this.h()},l(e){const m=Pp('[data-svelte="svelte-1phssyn"]',document.head);s=i(m,"META",{name:!0,content:!0}),m.forEach(t),u=$(e),o=i(e,"H1",{class:!0});var Va=p(o);f=i(Va,"A",{id:!0,class:!0,href:!0});var bs=p(f);h=i(bs,"SPAN",{});var Es=p(h);k(g.$$.fragment,Es),Es.forEach(t),bs.forEach(t),C=$(Va),M=i(Va,"SPAN",{});var ks=p(M);x=l(ks,"Tour r\xE1pido"),ks.forEach(t),Va.forEach(t),O=$(e),k(S.$$.fragment,e),I=$(e),F=i(e,"P",{});var Ie=p(F);U=l(Ie,"Comece a trabalhar com \u{1F917} Transformers! Comece usando "),z=i(Ie,"CODE",{});var ws=p(z);_=l(ws,"pipeline()"),ws.forEach(t),y=l(Ie," para r\xE1pida infer\xEAncia e facilmente carregue um modelo pr\xE9-treinado e um tokenizer com "),D=i(Ie,"A",{href:!0});var js=p(D);W=l(js,"AutoClass"),js.forEach(t),R=l(Ie," para resolver tarefas de texto, vis\xE3o ou \xE1udio."),Ie.forEach(t),oe=$(e),k(Y.$$.fragment,e),ee=$(e),J=i(e,"H2",{class:!0});var Ga=p(J);V=i(Ga,"A",{id:!0,class:!0,href:!0});var As=p(V);X=i(As,"SPAN",{});var qs=p(X);k(Q.$$.fragment,qs),qs.forEach(t),As.forEach(t),K=$(Ga),ue=i(Ga,"SPAN",{});var Qn=p(ue);re=l(Qn,"Pipeline"),Qn.forEach(t),Ga.forEach(t),de=$(e),le=i(e,"P",{});var Wn=p(le);ae=i(Wn,"CODE",{});var Kn=p(ae);ne=l(Kn,"pipeline()"),Kn.forEach(t),$e=l(Wn," \xE9 a maneira mais f\xE1cil de usar um modelo pr\xE9-treinado para uma dada tarefa."),Wn.forEach(t),T=$(e),k(N.$$.fragment,e),ie=$(e),v=i(e,"P",{});var Oo=p(v);H=l(Oo,"A "),me=i(Oo,"CODE",{});var Zn=p(me);Ce=l(Zn,"pipeline()"),Zn.forEach(t),fe=l(Oo," apoia diversas tarefas fora da caixa:"),Oo.forEach(t),ge=$(e),pe=i(e,"P",{});var Vn=p(pe);Fe=i(Vn,"STRONG",{});var Xn=p(Fe);ve=l(Xn,"Texto"),Xn.forEach(t),Ba=l(Vn,":"),Vn.forEach(t),da=$(e),G=i(e,"UL",{});var te=p(G);bt=i(te,"LI",{});var ei=p(bt);Zo=l(ei,"An\xE1lise sentimental: classifica a polaridade de um texto."),ei.forEach(t),Xo=$(te),Et=i(te,"LI",{});var ai=p(Et);er=l(ai,"Gera\xE7\xE3o de texto (em Ingl\xEAs): gera texto a partir de uma entrada."),ai.forEach(t),ar=$(te),kt=i(te,"LI",{});var ti=p(kt);tr=l(ti,"Reconhecimento de entidade mencionada: legenda cada palavra com uma classe que a representa (pessoa, data, local, etc\u2026)"),ti.forEach(t),sr=$(te),wt=i(te,"LI",{});var si=p(wt);or=l(si,"Respostas: extrai uma resposta dado algum contexto e uma quest\xE3o"),si.forEach(t),rr=$(te),jt=i(te,"LI",{});var oi=p(jt);lr=l(oi,"M\xE1scara de preenchimento: preenche o espa\xE7o, dado um texto com m\xE1scaras de palavras."),oi.forEach(t),nr=$(te),At=i(te,"LI",{});var ri=p(At);ir=l(ri,"Sumariza\xE7\xE3o: gera o resumo de um texto longo ou documento."),ri.forEach(t),pr=$(te),qt=i(te,"LI",{});var li=p(qt);mr=l(li,"Tradu\xE7\xE3o: traduz texto para outra l\xEDngua."),li.forEach(t),cr=$(te),Tt=i(te,"LI",{});var ni=p(Tt);ur=l(ni,"Extra\xE7\xE3o de caracter\xEDsticas: cria um tensor que representa o texto."),ni.forEach(t),te.forEach(t),Ts=$(e),$a=i(e,"P",{});var Gn=p($a);xt=i(Gn,"STRONG",{});var ii=p(xt);fr=l(ii,"Imagem"),ii.forEach(t),dr=l(Gn,":"),Gn.forEach(t),xs=$(e),be=i(e,"UL",{});var pt=p(be);yt=i(pt,"LI",{});var pi=p(yt);$r=l(pi,"Classifica\xE7\xE3o de imagens: classifica uma imagem."),pi.forEach(t),hr=$(pt),Ct=i(pt,"LI",{});var mi=p(Ct);_r=l(mi,"Segmenta\xE7\xE3o de imagem: classifica cada pixel da imagem."),mi.forEach(t),gr=$(pt),zt=i(pt,"LI",{});var ci=p(zt);vr=l(ci,"Detec\xE7\xE3o de objetos: detecta objetos em uma imagem."),ci.forEach(t),pt.forEach(t),ys=$(e),ha=i(e,"P",{});var Bn=p(ha);Pt=i(Bn,"STRONG",{});var ui=p(Pt);br=l(ui,"Audio"),ui.forEach(t),Er=l(Bn,":"),Bn.forEach(t),Cs=$(e),Ne=i(e,"UL",{});var Mo=p(Ne);Ot=i(Mo,"LI",{});var fi=p(Ot);kr=l(fi,"Classfica\xE7\xE3o de \xE1udio: legenda um trecho de \xE1udio fornecido."),fi.forEach(t),wr=$(Mo),Mt=i(Mo,"LI",{});var di=p(Mt);jr=l(di,"Reconhecimento de fala autom\xE1tico: transcreve audio em texto."),di.forEach(t),Mo.forEach(t),zs=$(e),k(Ue.$$.fragment,e),Ps=$(e),ze=i(e,"H3",{class:!0});var Do=p(ze);He=i(Do,"A",{id:!0,class:!0,href:!0});var $i=p(He);Dt=i($i,"SPAN",{});var hi=p(Dt);k(_a.$$.fragment,hi),hi.forEach(t),$i.forEach(t),Ar=$(Do),St=i(Do,"SPAN",{});var _i=p(St);qr=l(_i,"Uso da pipeline"),_i.forEach(t),Do.forEach(t),Os=$(e),Le=i(e,"P",{});var So=p(Le);Tr=l(So,"No exemplo a seguir, voc\xEA usar\xE1 "),It=i(So,"CODE",{});var gi=p(It);xr=l(gi,"pipeline()"),gi.forEach(t),yr=l(So," para an\xE1lise sentimental."),So.forEach(t),Ms=$(e),Ya=i(e,"P",{});var vi=p(Ya);Cr=l(vi,"Instale as seguintes depend\xEAncias se voc\xEA ainda n\xE3o o fez:"),vi.forEach(t),Ds=$(e),k(Re.$$.fragment,e),Ss=$(e),We=i(e,"P",{});var Io=p(We);zr=l(Io,"Importe "),Ft=i(Io,"CODE",{});var bi=p(Ft);Pr=l(bi,"pipeline()"),bi.forEach(t),Or=l(Io," e especifique a tarefa que deseja completar:"),Io.forEach(t),Is=$(e),k(ga.$$.fragment,e),Fs=$(e),Ee=i(e,"P",{});var mt=p(Ee);Mr=l(mt,"A pipeline baixa and armazena um "),va=i(mt,"A",{href:!0,rel:!0});var Ei=p(va);Dr=l(Ei,"modelo pr\xE9-treinado"),Ei.forEach(t),Sr=l(mt," padr\xE3o e tokenizer para an\xE1lise sentimental. Agora voc\xEA pode usar "),Nt=i(mt,"CODE",{});var ki=p(Nt);Ir=l(ki,"classifier"),ki.forEach(t),Fr=l(mt," no texto alvo:"),mt.forEach(t),Ns=$(e),k(ba.$$.fragment,e),Us=$(e),Ve=i(e,"P",{});var Fo=p(Ve);Nr=l(Fo,"Para mais de uma senten\xE7a, passe uma lista para a "),Ut=i(Fo,"CODE",{});var wi=p(Ut);Ur=l(wi,"pipeline()"),wi.forEach(t),Hr=l(Fo,", a qual retornar\xE1 uma lista de dicion\xE1rios:"),Fo.forEach(t),Hs=$(e),k(Ea.$$.fragment,e),Ls=$(e),ke=i(e,"P",{});var ct=p(ke);Lr=l(ct,"A "),Ht=i(ct,"CODE",{});var ji=p(Ht);Rr=l(ji,"pipeline()"),ji.forEach(t),Wr=l(ct," tamb\xE9m pode iterar sobre um Dataset inteiro. Comece instalando a biblioteca de "),ka=i(ct,"A",{href:!0,rel:!0});var Ai=p(ka);Vr=l(Ai,"\u{1F917} Datasets"),Ai.forEach(t),Gr=l(ct,":"),ct.forEach(t),Rs=$(e),k(wa.$$.fragment,e),Ws=$(e),Ge=i(e,"P",{});var No=p(Ge);Br=l(No,"Crie uma "),Lt=i(No,"CODE",{});var qi=p(Lt);Yr=l(qi,"pipeline()"),qi.forEach(t),Jr=l(No," com a tarefa que deseja resolver e o modelo que deseja usar."),No.forEach(t),Vs=$(e),k(ja.$$.fragment,e),Gs=$(e),we=i(e,"P",{});var ut=p(we);Qr=l(ut,"A seguir, carregue uma base de dados (confira a \u{1F917} "),Aa=i(ut,"A",{href:!0,rel:!0});var Ti=p(Aa);Kr=l(Ti,"Inicia\xE7\xE3o em Datasets"),Ti.forEach(t),Zr=l(ut," para mais detalhes) que voc\xEA gostaria de iterar sobre. Por exemplo, vamos carregar o dataset "),qa=i(ut,"A",{href:!0,rel:!0});var xi=p(qa);Xr=l(xi,"MInDS-14"),xi.forEach(t),el=l(ut,":"),ut.forEach(t),Bs=$(e),k(Ta.$$.fragment,e),Ys=$(e),Ja=i(e,"P",{});var yi=p(Ja);al=l(yi,"Precisamos garantir que a taxa de amostragem do conjunto de dados corresponda \xE0 taxa de amostragem em que o facebook/wav2vec2-base-960h foi treinado."),yi.forEach(t),Js=$(e),k(xa.$$.fragment,e),Qs=$(e),Be=i(e,"P",{});var Uo=p(Be);tl=l(Uo,"Os arquivos de \xE1udio s\xE3o carregados e re-amostrados automaticamente ao chamar a coluna "),Rt=i(Uo,"CODE",{});var Ci=p(Rt);sl=l(Ci,'"audio"'),Ci.forEach(t),ol=l(Uo,`.
Vamos extrair as arrays de formas de onda originais das primeiras 4 amostras e pass\xE1-las como uma lista para o pipeline:`),Uo.forEach(t),Ks=$(e),k(ya.$$.fragment,e),Zs=$(e),Ye=i(e,"P",{});var Ho=p(Ye);rl=l(Ho,"Para um conjunto de dados maior onde as entradas s\xE3o maiores (como em fala ou vis\xE3o), ser\xE1 necess\xE1rio passar um gerador em vez de uma lista que carregue todas as entradas na mem\xF3ria. Consulte a "),Qa=i(Ho,"A",{href:!0});var zi=p(Qa);ll=l(zi,"documenta\xE7\xE3o do pipeline"),zi.forEach(t),nl=l(Ho," para mais informa\xE7\xF5es."),Ho.forEach(t),Xs=$(e),Pe=i(e,"H3",{class:!0});var Lo=p(Pe);Je=i(Lo,"A",{id:!0,class:!0,href:!0});var Pi=p(Je);Wt=i(Pi,"SPAN",{});var Oi=p(Wt);k(Ca.$$.fragment,Oi),Oi.forEach(t),Pi.forEach(t),il=$(Lo),Vt=i(Lo,"SPAN",{});var Mi=p(Vt);pl=l(Mi,"Use outro modelo e tokenizer na pipeline"),Mi.forEach(t),Lo.forEach(t),eo=$(e),he=i(e,"P",{});var ua=p(he);ml=l(ua,"A "),Gt=i(ua,"CODE",{});var Di=p(Gt);cl=l(Di,"pipeline()"),Di.forEach(t),ul=l(ua," pode acomodar qualquer modelo do "),za=i(ua,"A",{href:!0,rel:!0});var Si=p(za);fl=l(Si,"Model Hub"),Si.forEach(t),dl=l(ua,", facilitando sua adapta\xE7\xE3o para outros casos de uso. Por exemplo, se voc\xEA quiser um modelo capaz de lidar com texto em franc\xEAs, use as tags no Model Hub para filtrar um modelo apropriado. O principal resultado filtrado retorna um "),Pa=i(ua,"A",{href:!0,rel:!0});var Ii=p(Pa);$l=l(Ii,"modelo BERT"),Ii.forEach(t),hl=l(ua," bil\xEDngue ajustado para an\xE1lise de sentimentos. \xD3timo, vamos usar este modelo!"),ua.forEach(t),ao=$(e),k(Oa.$$.fragment,e),to=$(e),k(Qe.$$.fragment,e),so=$(e),je=i(e,"P",{});var ft=p(je);_l=l(ft,"Ent\xE3o voc\xEA pode especificar o modelo e o tokenizador na "),Bt=i(ft,"CODE",{});var Fi=p(Bt);gl=l(Fi,"pipeline()"),Fi.forEach(t),vl=l(ft," e aplicar o "),Yt=i(ft,"CODE",{});var Ni=p(Yt);bl=l(Ni,"classifier"),Ni.forEach(t),El=l(ft," no seu texto alvo:"),ft.forEach(t),oo=$(e),k(Ma.$$.fragment,e),ro=$(e),Ae=i(e,"P",{});var dt=p(Ae);kl=l(dt,"Se voc\xEA n\xE3o conseguir achar um modelo para o seu caso de uso, precisar\xE1 usar fine-tune em um modelo pr\xE9-treinado nos seus dados. Veja nosso "),Ka=i(dt,"A",{href:!0});var Ui=p(Ka);wl=l(Ui,"tutorial de fine-tuning"),Ui.forEach(t),jl=l(dt," para descobrir como. Finalmente, depois que voc\xEA tiver usado esse processo em seu modelo, considere compartilh\xE1-lo conosco (veja o tutorial "),Za=i(dt,"A",{href:!0});var Hi=p(Za);Al=l(Hi,"aqui"),Hi.forEach(t),ql=l(dt,") na plataforma Model Hub afim de democratizar NLP! \u{1F917}"),dt.forEach(t),lo=$(e),Oe=i(e,"H2",{class:!0});var Ro=p(Oe);Ke=i(Ro,"A",{id:!0,class:!0,href:!0});var Li=p(Ke);Jt=i(Li,"SPAN",{});var Ri=p(Jt);k(Da.$$.fragment,Ri),Ri.forEach(t),Li.forEach(t),Tl=$(Ro),Qt=i(Ro,"SPAN",{});var Wi=p(Qt);xl=l(Wi,"AutoClass"),Wi.forEach(t),Ro.forEach(t),no=$(e),k(Sa.$$.fragment,e),io=$(e),Z=i(e,"P",{});var ce=p(Z);yl=l(ce,"Por baixo dos panos, as classes "),Kt=i(ce,"CODE",{});var Vi=p(Kt);Cl=l(Vi,"AutoModelForSequenceClassification"),Vi.forEach(t),zl=l(ce," e "),Zt=i(ce,"CODE",{});var Gi=p(Zt);Pl=l(Gi,"AutoTokenizer"),Gi.forEach(t),Ol=l(ce," trabalham juntas para fortificar o "),Xt=i(ce,"CODE",{});var Bi=p(Xt);Ml=l(Bi,"pipeline()"),Bi.forEach(t),Dl=l(ce,". Um "),Xa=i(ce,"A",{href:!0});var Yi=p(Xa);Sl=l(Yi,"AutoClass"),Yi.forEach(t),Il=l(ce," \xE9 um atalho que automaticamente recupera a arquitetura de um modelo pr\xE9-treinado a partir de seu nome ou caminho. Basta selecionar a "),es=i(ce,"CODE",{});var Ji=p(es);Fl=l(Ji,"AutoClass"),Ji.forEach(t),Nl=l(ce," apropriada para sua tarefa e seu tokenizer associado com "),as=i(ce,"CODE",{});var Qi=p(as);Ul=l(Qi,"AutoTokenizer"),Qi.forEach(t),Hl=l(ce,"."),ce.forEach(t),po=$(e),qe=i(e,"P",{});var $t=p(qe);Ll=l($t,"Vamos voltar ao nosso exemplo e ver como voc\xEA pode usar a "),ts=i($t,"CODE",{});var Ki=p(ts);Rl=l(Ki,"AutoClass"),Ki.forEach(t),Wl=l($t," para replicar os resultados do "),ss=i($t,"CODE",{});var Zi=p(ss);Vl=l(Zi,"pipeline()"),Zi.forEach(t),Gl=l($t,"."),$t.forEach(t),mo=$(e),Me=i(e,"H3",{class:!0});var Wo=p(Me);Ze=i(Wo,"A",{id:!0,class:!0,href:!0});var Xi=p(Ze);os=i(Xi,"SPAN",{});var ep=p(os);k(Ia.$$.fragment,ep),ep.forEach(t),Xi.forEach(t),Bl=$(Wo),rs=i(Wo,"SPAN",{});var ap=p(rs);Yl=l(ap,"AutoTokenizer"),ap.forEach(t),Wo.forEach(t),co=$(e),Te=i(e,"P",{});var ht=p(Te);Jl=l(ht,"Um tokenizer \xE9 respons\xE1vel por pr\xE9-processar o texto em um formato que seja compreens\xEDvel para o modelo. Primeiro, o tokenizer dividir\xE1 o texto em palavras chamadas "),ls=i(ht,"EM",{});var tp=p(ls);Ql=l(tp,"tokens"),tp.forEach(t),Kl=l(ht,". Existem v\xE1rias regras que regem o processo de tokeniza\xE7\xE3o, incluindo como dividir uma palavra e em que n\xEDvel (saiba mais sobre tokeniza\xE7\xE3o "),et=i(ht,"A",{href:!0});var sp=p(et);Zl=l(sp,"aqui"),sp.forEach(t),Xl=l(ht,"). A coisa mais importante a lembrar, por\xE9m, \xE9 que voc\xEA precisa instanciar o tokenizer com o mesmo nome do modelo para garantir que est\xE1 usando as mesmas regras de tokeniza\xE7\xE3o com as quais um modelo foi pr\xE9-treinado."),ht.forEach(t),uo=$(e),Xe=i(e,"P",{});var Vo=p(Xe);en=l(Vo,"Carregue um tokenizer com "),ns=i(Vo,"CODE",{});var op=p(ns);an=l(op,"AutoTokenizer"),op.forEach(t),tn=l(Vo,":"),Vo.forEach(t),fo=$(e),k(Fa.$$.fragment,e),$o=$(e),ea=i(e,"P",{});var Go=p(ea);sn=l(Go,"Em seguida, o tokenizer converte os tokens em n\xFAmeros para construir um tensor como entrada para o modelo. Isso \xE9 conhecido como o "),is=i(Go,"EM",{});var rp=p(is);on=l(rp,"vocabul\xE1rio"),rp.forEach(t),rn=l(Go," do modelo."),Go.forEach(t),ho=$(e),at=i(e,"P",{});var lp=p(at);ln=l(lp,"Passe o texto para o tokenizer:"),lp.forEach(t),_o=$(e),k(Na.$$.fragment,e),go=$(e),tt=i(e,"P",{});var np=p(tt);nn=l(np,"O tokenizer retornar\xE1 um dicion\xE1rio contendo:"),np.forEach(t),vo=$(e),aa=i(e,"UL",{});var Bo=p(aa);st=i(Bo,"LI",{});var Yn=p(st);ot=i(Yn,"A",{href:!0});var ip=p(ot);pn=l(ip,"input_ids"),ip.forEach(t),mn=l(Yn,": representa\xE7\xF5es num\xE9ricas de seus tokens."),Yn.forEach(t),cn=$(Bo),rt=i(Bo,"LI",{});var Jn=p(rt);lt=i(Jn,"A",{href:!0});var pp=p(lt);un=l(pp,"atttention_mask"),pp.forEach(t),fn=l(Jn,": indica quais tokens devem ser atendidos."),Jn.forEach(t),Bo.forEach(t),bo=$(e),ta=i(e,"P",{});var Yo=p(ta);dn=l(Yo,"Assim como o "),ps=i(Yo,"CODE",{});var mp=p(ps);$n=l(mp,"pipeline()"),mp.forEach(t),hn=l(Yo,", o tokenizer aceitar\xE1 uma lista de entradas. Al\xE9m disso, o tokenizer tamb\xE9m pode preencher e truncar o texto para retornar um lote com comprimento uniforme:"),Yo.forEach(t),Eo=$(e),k(sa.$$.fragment,e),ko=$(e),oa=i(e,"P",{});var Jo=p(oa);_n=l(Jo,"Leia o tutorial de "),nt=i(Jo,"A",{href:!0});var cp=p(nt);gn=l(cp,"pr\xE9-processamento"),cp.forEach(t),vn=l(Jo," para obter mais detalhes sobre tokeniza\xE7\xE3o."),Jo.forEach(t),wo=$(e),De=i(e,"H3",{class:!0});var Qo=p(De);ra=i(Qo,"A",{id:!0,class:!0,href:!0});var up=p(ra);ms=i(up,"SPAN",{});var fp=p(ms);k(Ua.$$.fragment,fp),fp.forEach(t),up.forEach(t),bn=$(Qo),cs=i(Qo,"SPAN",{});var dp=p(cs);En=l(dp,"AutoModel"),dp.forEach(t),Qo.forEach(t),jo=$(e),k(la.$$.fragment,e),Ao=$(e),k(na.$$.fragment,e),qo=$(e),B=i(e,"P",{});var se=p(B);kn=l(se,"Os modelos s\xE3o um standard "),Ha=i(se,"A",{href:!0,rel:!0});var $p=p(Ha);us=i($p,"CODE",{});var hp=p(us);wn=l(hp,"torch.nn.Module"),hp.forEach(t),$p.forEach(t),jn=l(se," ou um ["),fs=i(se,"CODE",{});var _p=p(fs);An=l(_p,"tf.keras.Model"),_p.forEach(t),qn=l(se,"](https: //"),La=i(se,"A",{href:!0,rel:!0});var gp=p(La);Tn=l(gp,"www.tensorflow.org/api_docs/python/tf/keras/Model"),gp.forEach(t),xn=l(se,") para que voc\xEA possa us\xE1-los em seu loop de treinamento habitual. No entanto, para facilitar as coisas, \u{1F917} Transformers fornece uma classe "),ds=i(se,"CODE",{});var vp=p(ds);yn=l(vp,"Trainer"),vp.forEach(t),Cn=l(se," para PyTorch que adiciona funcionalidade para treinamento distribu\xEDdo, precis\xE3o mista e muito mais. Para o TensorFlow, voc\xEA pode usar o m\xE9todo "),$s=i(se,"CODE",{});var bp=p($s);zn=l(bp,"fit"),bp.forEach(t),Pn=l(se," de "),Ra=i(se,"A",{href:!0,rel:!0});var Ep=p(Ra);On=l(Ep,"Keras"),Ep.forEach(t),Mn=l(se,". Consulte o "),it=i(se,"A",{href:!0});var kp=p(it);Dn=l(kp,"tutorial de treinamento"),kp.forEach(t),Sn=l(se," para obter mais detalhes."),se.forEach(t),To=$(e),k(ia.$$.fragment,e),xo=$(e),Se=i(e,"H3",{class:!0});var Ko=p(Se);pa=i(Ko,"A",{id:!0,class:!0,href:!0});var wp=p(pa);hs=i(wp,"SPAN",{});var jp=p(hs);k(Wa.$$.fragment,jp),jp.forEach(t),wp.forEach(t),In=$(Ko),_s=i(Ko,"SPAN",{});var Ap=p(_s);Fn=l(Ap,"Salvar um modelo"),Ap.forEach(t),Ko.forEach(t),yo=$(e),k(ma.$$.fragment,e),Co=$(e),xe=i(e,"P",{});var _t=p(xe);Nn=l(_t,"Um recurso particularmente interessante dos \u{1F917} Transformers \xE9 a capacidade de salvar um modelo e recarreg\xE1-lo como um modelo PyTorch ou TensorFlow. Use "),gs=i(_t,"CODE",{});var qp=p(gs);Un=l(qp,"from_pt"),qp.forEach(t),Hn=l(_t," ou "),vs=i(_t,"CODE",{});var Tp=p(vs);Ln=l(Tp,"from_tf"),Tp.forEach(t),Rn=l(_t," para converter o modelo de um framework para outro:"),_t.forEach(t),zo=$(e),k(ca.$$.fragment,e),this.h()},h(){b(s,"name","hf:doc:metadata"),b(s,"content",JSON.stringify(um)),b(f,"id","tour-rpido"),b(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(f,"href","#tour-rpido"),b(o,"class","relative group"),b(D,"href","./model_doc/auto"),b(V,"id","pipeline"),b(V,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(V,"href","#pipeline"),b(J,"class","relative group"),b(He,"id","uso-da-pipeline"),b(He,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(He,"href","#uso-da-pipeline"),b(ze,"class","relative group"),b(va,"href","https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english"),b(va,"rel","nofollow"),b(ka,"href","https://huggingface.co/docs/datasets/"),b(ka,"rel","nofollow"),b(Aa,"href","https://huggingface.co/docs/datasets/quickstart.html"),b(Aa,"rel","nofollow"),b(qa,"href","https://huggingface.co/datasets/PolyAI/minds14"),b(qa,"rel","nofollow"),b(Qa,"href","./main_classes/pipelines"),b(Je,"id","use-outro-modelo-e-tokenizer-na-pipeline"),b(Je,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(Je,"href","#use-outro-modelo-e-tokenizer-na-pipeline"),b(Pe,"class","relative group"),b(za,"href","https://huggingface.co/models"),b(za,"rel","nofollow"),b(Pa,"href","https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment"),b(Pa,"rel","nofollow"),b(Ka,"href","./training"),b(Za,"href","./model_sharing"),b(Ke,"id","autoclass"),b(Ke,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(Ke,"href","#autoclass"),b(Oe,"class","relative group"),b(Xa,"href","./model_doc/auto"),b(Ze,"id","autotokenizer"),b(Ze,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(Ze,"href","#autotokenizer"),b(Me,"class","relative group"),b(et,"href","./tokenizer_summary"),b(ot,"href","./glossary#input-ids"),b(lt,"href",".glossary#attention-mask"),b(nt,"href","./pr%C3%A9-processamento"),b(ra,"id","automodel"),b(ra,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(ra,"href","#automodel"),b(De,"class","relative group"),b(Ha,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),b(Ha,"rel","nofollow"),b(La,"href","http://www.tensorflow.org/api_docs/python/tf/keras/Model"),b(La,"rel","nofollow"),b(Ra,"href","https://keras.io/"),b(Ra,"rel","nofollow"),b(it,"href","./training"),b(pa,"id","salvar-um-modelo"),b(pa,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(pa,"href","#salvar-um-modelo"),b(Se,"class","relative group")},m(e,m){a(document.head,s),c(e,u,m),c(e,o,m),a(o,f),a(f,h),w(g,h,null),a(o,C),a(o,M),a(M,x),c(e,O,m),w(S,e,m),c(e,I,m),c(e,F,m),a(F,U),a(F,z),a(z,_),a(F,y),a(F,D),a(D,W),a(F,R),c(e,oe,m),w(Y,e,m),c(e,ee,m),c(e,J,m),a(J,V),a(V,X),w(Q,X,null),a(J,K),a(J,ue),a(ue,re),c(e,de,m),c(e,le,m),a(le,ae),a(ae,ne),a(le,$e),c(e,T,m),w(N,e,m),c(e,ie,m),c(e,v,m),a(v,H),a(v,me),a(me,Ce),a(v,fe),c(e,ge,m),c(e,pe,m),a(pe,Fe),a(Fe,ve),a(pe,Ba),c(e,da,m),c(e,G,m),a(G,bt),a(bt,Zo),a(G,Xo),a(G,Et),a(Et,er),a(G,ar),a(G,kt),a(kt,tr),a(G,sr),a(G,wt),a(wt,or),a(G,rr),a(G,jt),a(jt,lr),a(G,nr),a(G,At),a(At,ir),a(G,pr),a(G,qt),a(qt,mr),a(G,cr),a(G,Tt),a(Tt,ur),c(e,Ts,m),c(e,$a,m),a($a,xt),a(xt,fr),a($a,dr),c(e,xs,m),c(e,be,m),a(be,yt),a(yt,$r),a(be,hr),a(be,Ct),a(Ct,_r),a(be,gr),a(be,zt),a(zt,vr),c(e,ys,m),c(e,ha,m),a(ha,Pt),a(Pt,br),a(ha,Er),c(e,Cs,m),c(e,Ne,m),a(Ne,Ot),a(Ot,kr),a(Ne,wr),a(Ne,Mt),a(Mt,jr),c(e,zs,m),w(Ue,e,m),c(e,Ps,m),c(e,ze,m),a(ze,He),a(He,Dt),w(_a,Dt,null),a(ze,Ar),a(ze,St),a(St,qr),c(e,Os,m),c(e,Le,m),a(Le,Tr),a(Le,It),a(It,xr),a(Le,yr),c(e,Ms,m),c(e,Ya,m),a(Ya,Cr),c(e,Ds,m),w(Re,e,m),c(e,Ss,m),c(e,We,m),a(We,zr),a(We,Ft),a(Ft,Pr),a(We,Or),c(e,Is,m),w(ga,e,m),c(e,Fs,m),c(e,Ee,m),a(Ee,Mr),a(Ee,va),a(va,Dr),a(Ee,Sr),a(Ee,Nt),a(Nt,Ir),a(Ee,Fr),c(e,Ns,m),w(ba,e,m),c(e,Us,m),c(e,Ve,m),a(Ve,Nr),a(Ve,Ut),a(Ut,Ur),a(Ve,Hr),c(e,Hs,m),w(Ea,e,m),c(e,Ls,m),c(e,ke,m),a(ke,Lr),a(ke,Ht),a(Ht,Rr),a(ke,Wr),a(ke,ka),a(ka,Vr),a(ke,Gr),c(e,Rs,m),w(wa,e,m),c(e,Ws,m),c(e,Ge,m),a(Ge,Br),a(Ge,Lt),a(Lt,Yr),a(Ge,Jr),c(e,Vs,m),w(ja,e,m),c(e,Gs,m),c(e,we,m),a(we,Qr),a(we,Aa),a(Aa,Kr),a(we,Zr),a(we,qa),a(qa,Xr),a(we,el),c(e,Bs,m),w(Ta,e,m),c(e,Ys,m),c(e,Ja,m),a(Ja,al),c(e,Js,m),w(xa,e,m),c(e,Qs,m),c(e,Be,m),a(Be,tl),a(Be,Rt),a(Rt,sl),a(Be,ol),c(e,Ks,m),w(ya,e,m),c(e,Zs,m),c(e,Ye,m),a(Ye,rl),a(Ye,Qa),a(Qa,ll),a(Ye,nl),c(e,Xs,m),c(e,Pe,m),a(Pe,Je),a(Je,Wt),w(Ca,Wt,null),a(Pe,il),a(Pe,Vt),a(Vt,pl),c(e,eo,m),c(e,he,m),a(he,ml),a(he,Gt),a(Gt,cl),a(he,ul),a(he,za),a(za,fl),a(he,dl),a(he,Pa),a(Pa,$l),a(he,hl),c(e,ao,m),w(Oa,e,m),c(e,to,m),w(Qe,e,m),c(e,so,m),c(e,je,m),a(je,_l),a(je,Bt),a(Bt,gl),a(je,vl),a(je,Yt),a(Yt,bl),a(je,El),c(e,oo,m),w(Ma,e,m),c(e,ro,m),c(e,Ae,m),a(Ae,kl),a(Ae,Ka),a(Ka,wl),a(Ae,jl),a(Ae,Za),a(Za,Al),a(Ae,ql),c(e,lo,m),c(e,Oe,m),a(Oe,Ke),a(Ke,Jt),w(Da,Jt,null),a(Oe,Tl),a(Oe,Qt),a(Qt,xl),c(e,no,m),w(Sa,e,m),c(e,io,m),c(e,Z,m),a(Z,yl),a(Z,Kt),a(Kt,Cl),a(Z,zl),a(Z,Zt),a(Zt,Pl),a(Z,Ol),a(Z,Xt),a(Xt,Ml),a(Z,Dl),a(Z,Xa),a(Xa,Sl),a(Z,Il),a(Z,es),a(es,Fl),a(Z,Nl),a(Z,as),a(as,Ul),a(Z,Hl),c(e,po,m),c(e,qe,m),a(qe,Ll),a(qe,ts),a(ts,Rl),a(qe,Wl),a(qe,ss),a(ss,Vl),a(qe,Gl),c(e,mo,m),c(e,Me,m),a(Me,Ze),a(Ze,os),w(Ia,os,null),a(Me,Bl),a(Me,rs),a(rs,Yl),c(e,co,m),c(e,Te,m),a(Te,Jl),a(Te,ls),a(ls,Ql),a(Te,Kl),a(Te,et),a(et,Zl),a(Te,Xl),c(e,uo,m),c(e,Xe,m),a(Xe,en),a(Xe,ns),a(ns,an),a(Xe,tn),c(e,fo,m),w(Fa,e,m),c(e,$o,m),c(e,ea,m),a(ea,sn),a(ea,is),a(is,on),a(ea,rn),c(e,ho,m),c(e,at,m),a(at,ln),c(e,_o,m),w(Na,e,m),c(e,go,m),c(e,tt,m),a(tt,nn),c(e,vo,m),c(e,aa,m),a(aa,st),a(st,ot),a(ot,pn),a(st,mn),a(aa,cn),a(aa,rt),a(rt,lt),a(lt,un),a(rt,fn),c(e,bo,m),c(e,ta,m),a(ta,dn),a(ta,ps),a(ps,$n),a(ta,hn),c(e,Eo,m),w(sa,e,m),c(e,ko,m),c(e,oa,m),a(oa,_n),a(oa,nt),a(nt,gn),a(oa,vn),c(e,wo,m),c(e,De,m),a(De,ra),a(ra,ms),w(Ua,ms,null),a(De,bn),a(De,cs),a(cs,En),c(e,jo,m),w(la,e,m),c(e,Ao,m),w(na,e,m),c(e,qo,m),c(e,B,m),a(B,kn),a(B,Ha),a(Ha,us),a(us,wn),a(B,jn),a(B,fs),a(fs,An),a(B,qn),a(B,La),a(La,Tn),a(B,xn),a(B,ds),a(ds,yn),a(B,Cn),a(B,$s),a($s,zn),a(B,Pn),a(B,Ra),a(Ra,On),a(B,Mn),a(B,it),a(it,Dn),a(B,Sn),c(e,To,m),w(ia,e,m),c(e,xo,m),c(e,Se,m),a(Se,pa),a(pa,hs),w(Wa,hs,null),a(Se,In),a(Se,_s),a(_s,Fn),c(e,yo,m),w(ma,e,m),c(e,Co,m),c(e,xe,m),a(xe,Nn),a(xe,gs),a(gs,Un),a(xe,Hn),a(xe,vs),a(vs,Ln),a(xe,Rn),c(e,zo,m),w(ca,e,m),Po=!0},p(e,[m]){const Va={};m&2&&(Va.$$scope={dirty:m,ctx:e}),Y.$set(Va);const bs={};m&2&&(bs.$$scope={dirty:m,ctx:e}),Ue.$set(bs);const Es={};m&2&&(Es.$$scope={dirty:m,ctx:e}),Re.$set(Es);const ks={};m&2&&(ks.$$scope={dirty:m,ctx:e}),Qe.$set(ks);const Ie={};m&2&&(Ie.$$scope={dirty:m,ctx:e}),sa.$set(Ie);const ws={};m&2&&(ws.$$scope={dirty:m,ctx:e}),la.$set(ws);const js={};m&2&&(js.$$scope={dirty:m,ctx:e}),na.$set(js);const Ga={};m&2&&(Ga.$$scope={dirty:m,ctx:e}),ia.$set(Ga);const As={};m&2&&(As.$$scope={dirty:m,ctx:e}),ma.$set(As);const qs={};m&2&&(qs.$$scope={dirty:m,ctx:e}),ca.$set(qs)},i(e){Po||(j(g.$$.fragment,e),j(S.$$.fragment,e),j(Y.$$.fragment,e),j(Q.$$.fragment,e),j(N.$$.fragment,e),j(Ue.$$.fragment,e),j(_a.$$.fragment,e),j(Re.$$.fragment,e),j(ga.$$.fragment,e),j(ba.$$.fragment,e),j(Ea.$$.fragment,e),j(wa.$$.fragment,e),j(ja.$$.fragment,e),j(Ta.$$.fragment,e),j(xa.$$.fragment,e),j(ya.$$.fragment,e),j(Ca.$$.fragment,e),j(Oa.$$.fragment,e),j(Qe.$$.fragment,e),j(Ma.$$.fragment,e),j(Da.$$.fragment,e),j(Sa.$$.fragment,e),j(Ia.$$.fragment,e),j(Fa.$$.fragment,e),j(Na.$$.fragment,e),j(sa.$$.fragment,e),j(Ua.$$.fragment,e),j(la.$$.fragment,e),j(na.$$.fragment,e),j(ia.$$.fragment,e),j(Wa.$$.fragment,e),j(ma.$$.fragment,e),j(ca.$$.fragment,e),Po=!0)},o(e){A(g.$$.fragment,e),A(S.$$.fragment,e),A(Y.$$.fragment,e),A(Q.$$.fragment,e),A(N.$$.fragment,e),A(Ue.$$.fragment,e),A(_a.$$.fragment,e),A(Re.$$.fragment,e),A(ga.$$.fragment,e),A(ba.$$.fragment,e),A(Ea.$$.fragment,e),A(wa.$$.fragment,e),A(ja.$$.fragment,e),A(Ta.$$.fragment,e),A(xa.$$.fragment,e),A(ya.$$.fragment,e),A(Ca.$$.fragment,e),A(Oa.$$.fragment,e),A(Qe.$$.fragment,e),A(Ma.$$.fragment,e),A(Da.$$.fragment,e),A(Sa.$$.fragment,e),A(Ia.$$.fragment,e),A(Fa.$$.fragment,e),A(Na.$$.fragment,e),A(sa.$$.fragment,e),A(Ua.$$.fragment,e),A(la.$$.fragment,e),A(na.$$.fragment,e),A(ia.$$.fragment,e),A(Wa.$$.fragment,e),A(ma.$$.fragment,e),A(ca.$$.fragment,e),Po=!1},d(e){t(s),e&&t(u),e&&t(o),q(g),e&&t(O),q(S,e),e&&t(I),e&&t(F),e&&t(oe),q(Y,e),e&&t(ee),e&&t(J),q(Q),e&&t(de),e&&t(le),e&&t(T),q(N,e),e&&t(ie),e&&t(v),e&&t(ge),e&&t(pe),e&&t(da),e&&t(G),e&&t(Ts),e&&t($a),e&&t(xs),e&&t(be),e&&t(ys),e&&t(ha),e&&t(Cs),e&&t(Ne),e&&t(zs),q(Ue,e),e&&t(Ps),e&&t(ze),q(_a),e&&t(Os),e&&t(Le),e&&t(Ms),e&&t(Ya),e&&t(Ds),q(Re,e),e&&t(Ss),e&&t(We),e&&t(Is),q(ga,e),e&&t(Fs),e&&t(Ee),e&&t(Ns),q(ba,e),e&&t(Us),e&&t(Ve),e&&t(Hs),q(Ea,e),e&&t(Ls),e&&t(ke),e&&t(Rs),q(wa,e),e&&t(Ws),e&&t(Ge),e&&t(Vs),q(ja,e),e&&t(Gs),e&&t(we),e&&t(Bs),q(Ta,e),e&&t(Ys),e&&t(Ja),e&&t(Js),q(xa,e),e&&t(Qs),e&&t(Be),e&&t(Ks),q(ya,e),e&&t(Zs),e&&t(Ye),e&&t(Xs),e&&t(Pe),q(Ca),e&&t(eo),e&&t(he),e&&t(ao),q(Oa,e),e&&t(to),q(Qe,e),e&&t(so),e&&t(je),e&&t(oo),q(Ma,e),e&&t(ro),e&&t(Ae),e&&t(lo),e&&t(Oe),q(Da),e&&t(no),q(Sa,e),e&&t(io),e&&t(Z),e&&t(po),e&&t(qe),e&&t(mo),e&&t(Me),q(Ia),e&&t(co),e&&t(Te),e&&t(uo),e&&t(Xe),e&&t(fo),q(Fa,e),e&&t($o),e&&t(ea),e&&t(ho),e&&t(at),e&&t(_o),q(Na,e),e&&t(go),e&&t(tt),e&&t(vo),e&&t(aa),e&&t(bo),e&&t(ta),e&&t(Eo),q(sa,e),e&&t(ko),e&&t(oa),e&&t(wo),e&&t(De),q(Ua),e&&t(jo),q(la,e),e&&t(Ao),q(na,e),e&&t(qo),e&&t(B),e&&t(To),q(ia,e),e&&t(xo),e&&t(Se),q(Wa),e&&t(yo),q(ma,e),e&&t(Co),e&&t(xe),e&&t(zo),q(ca,e)}}}const um={local:"tour-rpido",sections:[{local:"pipeline",sections:[{local:"uso-da-pipeline",title:"Uso da pipeline"},{local:"use-outro-modelo-e-tokenizer-na-pipeline",title:"Use outro modelo e tokenizer na pipeline"}],title:"Pipeline"},{local:"autoclass",sections:[{local:"autotokenizer",title:"AutoTokenizer"},{local:"automodel",title:"AutoModel"},{local:"salvar-um-modelo",title:"Salvar um modelo"}],title:"AutoClass"}],title:"Tour r\xE1pido"};function fm(P){return Op(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Em extends yp{constructor(s){super();Cp(this,s,fm,cm,zp,{})}}export{Em as default,um as metadata};
