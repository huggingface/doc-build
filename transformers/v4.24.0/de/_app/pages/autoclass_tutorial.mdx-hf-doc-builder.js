import{S as mr,i as hr,s as br,e as i,k as m,w as L,t as s,M as kr,c as o,d as r,m as h,a as l,x as B,h as a,b as $,G as t,g as f,y as O,q as K,o as N,B as V,v as gr,L as vr}from"../chunks/vendor-hf-doc-builder.js";import{T as pr}from"../chunks/Tip-hf-doc-builder.js";import{I as Re}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as ge}from"../chunks/CodeBlock-hf-doc-builder.js";import{F as $r,M as cr}from"../chunks/Markdown-hf-doc-builder.js";function wr(J){let n,A,d,k,E,v,y,x;return{c(){n=i("p"),A=s("Denken Sie daran, dass sich die Architektur auf das Skelett des Modells bezieht und die Checkpoints die Gewichte f\xFCr eine bestimmte Architektur sind. Zum Beispiel ist "),d=i("a"),k=s("BERT"),E=s(" eine Architektur, w\xE4hrend "),v=i("code"),y=s("bert-base-uncased"),x=s(" ein Checkpoint ist. Modell ist ein allgemeiner Begriff, der entweder Architektur oder Pr\xFCfpunkt bedeuten kann."),this.h()},l(z){n=o(z,"P",{});var M=l(n);A=a(M,"Denken Sie daran, dass sich die Architektur auf das Skelett des Modells bezieht und die Checkpoints die Gewichte f\xFCr eine bestimmte Architektur sind. Zum Beispiel ist "),d=o(M,"A",{href:!0,rel:!0});var F=l(d);k=a(F,"BERT"),F.forEach(r),E=a(M," eine Architektur, w\xE4hrend "),v=o(M,"CODE",{});var P=l(v);y=a(P,"bert-base-uncased"),P.forEach(r),x=a(M," ein Checkpoint ist. Modell ist ein allgemeiner Begriff, der entweder Architektur oder Pr\xFCfpunkt bedeuten kann."),M.forEach(r),this.h()},h(){$(d,"href","https://huggingface.co/bert-base-uncased"),$(d,"rel","nofollow")},m(z,M){f(z,n,M),t(n,A),t(n,d),t(d,k),t(n,E),t(n,v),t(v,y),t(n,x)},d(z){z&&r(n)}}}function Ar(J){let n,A,d,k,E,v,y,x,z,M,F,P,S,H,T,G,R,j,q,_,I,w,c,g,u,b,D,W,Q,X,te,re;return{c(){n=i("p"),A=s("F\xFCr PyTorch-Modelle verwendet die Methode "),d=i("code"),k=s("from_pretrained()"),E=m(),v=i("code"),y=s("torch.load()"),x=s(", die intern "),z=i("code"),M=s("pickle"),F=s(" verwendet und als unsicher bekannt ist. Generell sollte man niemals ein Modell laden, das aus einer nicht vertrauensw\xFCrdigen Quelle stammen k\xF6nnte, oder das manipuliert worden sein k\xF6nnte. Dieses Sicherheitsrisiko wird f\xFCr \xF6ffentliche Modelle, die auf dem Hugging Face Hub gehostet werden, teilweise gemildert, da diese bei jeder \xDCbertragung "),P=i("a"),S=s("auf Malware"),H=s(" gescannt werden. Siehe die "),T=i("a"),G=s("Hub-Dokumentation"),R=s(" f\xFCr Best Practices wie "),j=i("a"),q=s("signierte Commit-Verifizierung"),_=s(" mit GPG."),I=m(),w=i("p"),c=s("TensorFlow- und Flax-Checkpoints sind nicht betroffen und k\xF6nnen in PyTorch-Architekturen mit den Kwargs "),g=i("code"),u=s("from_tf"),b=s(" und "),D=i("code"),W=s("from_flax"),Q=s(" f\xFCr die Methode "),X=i("code"),te=s("from_pretrained"),re=s(" geladen werden, um dieses Problem zu umgehen."),this.h()},l(U){n=o(U,"P",{});var C=l(n);A=a(C,"F\xFCr PyTorch-Modelle verwendet die Methode "),d=o(C,"CODE",{});var ie=l(d);k=a(ie,"from_pretrained()"),ie.forEach(r),E=h(C),v=o(C,"CODE",{});var Fe=l(v);y=a(Fe,"torch.load()"),Fe.forEach(r),x=a(C,", die intern "),z=o(C,"CODE",{});var ve=l(z);M=a(ve,"pickle"),ve.forEach(r),F=a(C," verwendet und als unsicher bekannt ist. Generell sollte man niemals ein Modell laden, das aus einer nicht vertrauensw\xFCrdigen Quelle stammen k\xF6nnte, oder das manipuliert worden sein k\xF6nnte. Dieses Sicherheitsrisiko wird f\xFCr \xF6ffentliche Modelle, die auf dem Hugging Face Hub gehostet werden, teilweise gemildert, da diese bei jeder \xDCbertragung "),P=o(C,"A",{href:!0,rel:!0});var Y=l(P);S=a(Y,"auf Malware"),Y.forEach(r),H=a(C," gescannt werden. Siehe die "),T=o(C,"A",{href:!0,rel:!0});var ee=l(T);G=a(ee,"Hub-Dokumentation"),ee.forEach(r),R=a(C," f\xFCr Best Practices wie "),j=o(C,"A",{href:!0,rel:!0});var oe=l(j);q=a(oe,"signierte Commit-Verifizierung"),oe.forEach(r),_=a(C," mit GPG."),C.forEach(r),I=h(U),w=o(U,"P",{});var Z=l(w);c=a(Z,"TensorFlow- und Flax-Checkpoints sind nicht betroffen und k\xF6nnen in PyTorch-Architekturen mit den Kwargs "),g=o(Z,"CODE",{});var Se=l(g);u=a(Se,"from_tf"),Se.forEach(r),b=a(Z," und "),D=o(Z,"CODE",{});var le=l(D);W=a(le,"from_flax"),le.forEach(r),Q=a(Z," f\xFCr die Methode "),X=o(Z,"CODE",{});var Te=l(X);te=a(Te,"from_pretrained"),Te.forEach(r),re=a(Z," geladen werden, um dieses Problem zu umgehen."),Z.forEach(r),this.h()},h(){$(P,"href","https://huggingface.co/docs/hub/security-malware"),$(P,"rel","nofollow"),$(T,"href","https://huggingface.co/docs/hub/security"),$(T,"rel","nofollow"),$(j,"href","https://huggingface.co/docs/hub/security-gpg#signing-commits-with-gpg"),$(j,"rel","nofollow")},m(U,C){f(U,n,C),t(n,A),t(n,d),t(d,k),t(n,E),t(n,v),t(v,y),t(n,x),t(n,z),t(z,M),t(n,F),t(n,P),t(P,S),t(n,H),t(n,T),t(T,G),t(n,R),t(n,j),t(j,q),t(n,_),f(U,I,C),f(U,w,C),t(w,c),t(w,g),t(g,u),t(w,b),t(w,D),t(D,W),t(w,Q),t(w,X),t(X,te),t(w,re)},d(U){U&&r(n),U&&r(I),U&&r(w)}}}function _r(J){let n,A,d,k,E,v,y,x,z,M,F,P,S,H,T,G,R,j,q,_,I,w,c,g;return S=new ge({props:{code:`from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),j=new ge({props:{code:`from transformers import AutoModelForTokenClassification

model = AutoModelForTokenClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),_=new pr({props:{warning:!0,$$slots:{default:[Ar]},$$scope:{ctx:J}}}),{c(){n=i("p"),A=s("Mit den "),d=i("code"),k=s("AutoModelFor"),E=s("-Klassen k\xF6nnen Sie schlie\xDFlich ein vortrainiertes Modell f\xFCr eine bestimmte Aufgabe laden (siehe "),v=i("a"),y=s("hier"),x=s(" f\xFCr eine vollst\xE4ndige Liste der verf\xFCgbaren Aufgaben). Laden Sie zum Beispiel ein Modell f\xFCr die Sequenzklassifikation mit "),z=i("code"),M=s("AutoModelForSequenceClassification.from_pretrained()"),F=s(":"),P=m(),L(S.$$.fragment),H=m(),T=i("p"),G=s("Sie k\xF6nnen denselben Pr\xFCfpunkt problemlos wiederverwenden, um eine Architektur f\xFCr eine andere Aufgabe zu laden:"),R=m(),L(j.$$.fragment),q=m(),L(_.$$.fragment),I=m(),w=i("p"),c=s("Im Allgemeinen empfehlen wir die Verwendung der Klasse \u201CAutoTokenizer\u201D und der Klasse \u201CAutoModelFor\u201D, um trainierte Instanzen von Modellen zu laden. Dadurch wird sichergestellt, dass Sie jedes Mal die richtige Architektur laden. Im n\xE4chsten [Tutorial] (Vorverarbeitung) erfahren Sie, wie Sie Ihren neu geladenen Tokenizer, Feature Extractor und Prozessor verwenden, um einen Datensatz f\xFCr die Feinabstimmung vorzuverarbeiten."),this.h()},l(u){n=o(u,"P",{});var b=l(n);A=a(b,"Mit den "),d=o(b,"CODE",{});var D=l(d);k=a(D,"AutoModelFor"),D.forEach(r),E=a(b,"-Klassen k\xF6nnen Sie schlie\xDFlich ein vortrainiertes Modell f\xFCr eine bestimmte Aufgabe laden (siehe "),v=o(b,"A",{href:!0});var W=l(v);y=a(W,"hier"),W.forEach(r),x=a(b," f\xFCr eine vollst\xE4ndige Liste der verf\xFCgbaren Aufgaben). Laden Sie zum Beispiel ein Modell f\xFCr die Sequenzklassifikation mit "),z=o(b,"CODE",{});var Q=l(z);M=a(Q,"AutoModelForSequenceClassification.from_pretrained()"),Q.forEach(r),F=a(b,":"),b.forEach(r),P=h(u),B(S.$$.fragment,u),H=h(u),T=o(u,"P",{});var X=l(T);G=a(X,"Sie k\xF6nnen denselben Pr\xFCfpunkt problemlos wiederverwenden, um eine Architektur f\xFCr eine andere Aufgabe zu laden:"),X.forEach(r),R=h(u),B(j.$$.fragment,u),q=h(u),B(_.$$.fragment,u),I=h(u),w=o(u,"P",{});var te=l(w);c=a(te,"Im Allgemeinen empfehlen wir die Verwendung der Klasse \u201CAutoTokenizer\u201D und der Klasse \u201CAutoModelFor\u201D, um trainierte Instanzen von Modellen zu laden. Dadurch wird sichergestellt, dass Sie jedes Mal die richtige Architektur laden. Im n\xE4chsten [Tutorial] (Vorverarbeitung) erfahren Sie, wie Sie Ihren neu geladenen Tokenizer, Feature Extractor und Prozessor verwenden, um einen Datensatz f\xFCr die Feinabstimmung vorzuverarbeiten."),te.forEach(r),this.h()},h(){$(v,"href","model_doc/auto")},m(u,b){f(u,n,b),t(n,A),t(n,d),t(d,k),t(n,E),t(n,v),t(v,y),t(n,x),t(n,z),t(z,M),t(n,F),f(u,P,b),O(S,u,b),f(u,H,b),f(u,T,b),t(T,G),f(u,R,b),O(j,u,b),f(u,q,b),O(_,u,b),f(u,I,b),f(u,w,b),t(w,c),g=!0},p(u,b){const D={};b&2&&(D.$$scope={dirty:b,ctx:u}),_.$set(D)},i(u){g||(K(S.$$.fragment,u),K(j.$$.fragment,u),K(_.$$.fragment,u),g=!0)},o(u){N(S.$$.fragment,u),N(j.$$.fragment,u),N(_.$$.fragment,u),g=!1},d(u){u&&r(n),u&&r(P),V(S,u),u&&r(H),u&&r(T),u&&r(R),V(j,u),u&&r(q),V(_,u),u&&r(I),u&&r(w)}}}function Er(J){let n,A;return n=new cr({props:{$$slots:{default:[_r]},$$scope:{ctx:J}}}),{c(){L(n.$$.fragment)},l(d){B(n.$$.fragment,d)},m(d,k){O(n,d,k),A=!0},p(d,k){const E={};k&2&&(E.$$scope={dirty:k,ctx:d}),n.$set(E)},i(d){A||(K(n.$$.fragment,d),A=!0)},o(d){N(n.$$.fragment,d),A=!1},d(d){V(n,d)}}}function zr(J){let n,A,d,k,E,v,y,x,z,M,F,P,S,H,T,G,R,j,q,_,I,w;return S=new ge({props:{code:`from transformers import TFAutoModelForSequenceClassification

model = TFAutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),j=new ge({props:{code:`from transformers import TFAutoModelForTokenClassification

model = TFAutoModelForTokenClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),{c(){n=i("p"),A=s("Mit den Klassen "),d=i("code"),k=s("TFAutoModelFor"),E=s(" schlie\xDFlich k\xF6nnen Sie ein vortrainiertes Modell f\xFCr eine bestimmte Aufgabe laden (siehe "),v=i("a"),y=s("hier"),x=s(" f\xFCr eine vollst\xE4ndige Liste der verf\xFCgbaren Aufgaben). Laden Sie zum Beispiel ein Modell f\xFCr die Sequenzklassifikation mit "),z=i("code"),M=s("TFAutoModelForSequenceClassification.from_pretrained()"),F=s(":"),P=m(),L(S.$$.fragment),H=m(),T=i("p"),G=s("Sie k\xF6nnen denselben Pr\xFCfpunkt problemlos wiederverwenden, um eine Architektur f\xFCr eine andere Aufgabe zu laden:"),R=m(),L(j.$$.fragment),q=m(),_=i("p"),I=s("Im Allgemeinen empfehlen wir, die Klasse \u201CAutoTokenizer\u201D und die Klasse \u201CTFAutoModelFor\u201D zu verwenden, um vortrainierte Instanzen von Modellen zu laden. Dadurch wird sichergestellt, dass Sie jedes Mal die richtige Architektur laden. Im n\xE4chsten [Tutorial] (Vorverarbeitung) erfahren Sie, wie Sie Ihren neu geladenen Tokenizer, Feature Extractor und Prozessor verwenden, um einen Datensatz f\xFCr die Feinabstimmung vorzuverarbeiten."),this.h()},l(c){n=o(c,"P",{});var g=l(n);A=a(g,"Mit den Klassen "),d=o(g,"CODE",{});var u=l(d);k=a(u,"TFAutoModelFor"),u.forEach(r),E=a(g," schlie\xDFlich k\xF6nnen Sie ein vortrainiertes Modell f\xFCr eine bestimmte Aufgabe laden (siehe "),v=o(g,"A",{href:!0});var b=l(v);y=a(b,"hier"),b.forEach(r),x=a(g," f\xFCr eine vollst\xE4ndige Liste der verf\xFCgbaren Aufgaben). Laden Sie zum Beispiel ein Modell f\xFCr die Sequenzklassifikation mit "),z=o(g,"CODE",{});var D=l(z);M=a(D,"TFAutoModelForSequenceClassification.from_pretrained()"),D.forEach(r),F=a(g,":"),g.forEach(r),P=h(c),B(S.$$.fragment,c),H=h(c),T=o(c,"P",{});var W=l(T);G=a(W,"Sie k\xF6nnen denselben Pr\xFCfpunkt problemlos wiederverwenden, um eine Architektur f\xFCr eine andere Aufgabe zu laden:"),W.forEach(r),R=h(c),B(j.$$.fragment,c),q=h(c),_=o(c,"P",{});var Q=l(_);I=a(Q,"Im Allgemeinen empfehlen wir, die Klasse \u201CAutoTokenizer\u201D und die Klasse \u201CTFAutoModelFor\u201D zu verwenden, um vortrainierte Instanzen von Modellen zu laden. Dadurch wird sichergestellt, dass Sie jedes Mal die richtige Architektur laden. Im n\xE4chsten [Tutorial] (Vorverarbeitung) erfahren Sie, wie Sie Ihren neu geladenen Tokenizer, Feature Extractor und Prozessor verwenden, um einen Datensatz f\xFCr die Feinabstimmung vorzuverarbeiten."),Q.forEach(r),this.h()},h(){$(v,"href","model_doc/auto")},m(c,g){f(c,n,g),t(n,A),t(n,d),t(d,k),t(n,E),t(n,v),t(v,y),t(n,x),t(n,z),t(z,M),t(n,F),f(c,P,g),O(S,c,g),f(c,H,g),f(c,T,g),t(T,G),f(c,R,g),O(j,c,g),f(c,q,g),f(c,_,g),t(_,I),w=!0},p:vr,i(c){w||(K(S.$$.fragment,c),K(j.$$.fragment,c),w=!0)},o(c){N(S.$$.fragment,c),N(j.$$.fragment,c),w=!1},d(c){c&&r(n),c&&r(P),V(S,c),c&&r(H),c&&r(T),c&&r(R),V(j,c),c&&r(q),c&&r(_)}}}function jr(J){let n,A;return n=new cr({props:{$$slots:{default:[zr]},$$scope:{ctx:J}}}),{c(){L(n.$$.fragment)},l(d){B(n.$$.fragment,d)},m(d,k){O(n,d,k),A=!0},p(d,k){const E={};k&2&&(E.$$scope={dirty:k,ctx:d}),n.$set(E)},i(d){A||(K(n.$$.fragment,d),A=!0)},o(d){N(n.$$.fragment,d),A=!1},d(d){V(n,d)}}}function Mr(J){let n,A,d,k,E,v,y,x,z,M,F,P,S,H,T,G,R,j,q,_,I,w,c,g,u,b,D,W,Q,X,te,re,U,C,ie,Fe,ve,Y,ee,oe,Z,Se,le,Te,Ze,Pe,kt,Qe,ue,gt,Ie,vt,$t,Ue,$e,Je,Ce,wt,We,we,Xe,ne,de,De,Ae,At,Le,_t,Ye,xe,Et,et,fe,zt,Be,jt,Mt,tt,_e,rt,se,pe,Oe,Ee,Ft,Ke,St,nt,ce,Tt,ye,Pt,Ct,st,me,xt,Ne,yt,qt,at,ze,it,ae,he,Ve,je,It,He,Dt,ot,be,lt;return v=new Re({}),_=new pr({props:{$$slots:{default:[wr]},$$scope:{ctx:J}}}),Z=new Re({}),$e=new ge({props:{code:`from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)`}}),we=new ge({props:{code:`sequence = "In a hole in the ground there lived a hobbit."
print(tokenizer(sequence))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>sequence = <span class="hljs-string">&quot;In a hole in the ground there lived a hobbit.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(tokenizer(sequence))
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">1999</span>, <span class="hljs-number">1037</span>, <span class="hljs-number">4920</span>, <span class="hljs-number">1999</span>, <span class="hljs-number">1996</span>, <span class="hljs-number">2598</span>, <span class="hljs-number">2045</span>, <span class="hljs-number">2973</span>, <span class="hljs-number">1037</span>, <span class="hljs-number">7570</span>, <span class="hljs-number">10322</span>, <span class="hljs-number">4183</span>, <span class="hljs-number">1012</span>, <span class="hljs-number">102</span>], 
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`}}),Ae=new Re({}),_e=new ge({props:{code:`from transformers import AutoFeatureExtractor

feature_extractor = AutoFeatureExtractor.from_pretrained(
    "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition"
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition&quot;</span>
<span class="hljs-meta">... </span>)`}}),Ee=new Re({}),ze=new ge({props:{code:`from transformers import AutoProcessor

processor = AutoProcessor.from_pretrained("microsoft/layoutlmv2-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;microsoft/layoutlmv2-base-uncased&quot;</span>)`}}),je=new Re({}),be=new $r({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[jr],pytorch:[Er]},$$scope:{ctx:J}}}),{c(){n=i("meta"),A=m(),d=i("h1"),k=i("a"),E=i("span"),L(v.$$.fragment),y=m(),x=i("span"),z=s("Vortrainierte Instanzen mit einer AutoClass laden"),M=m(),F=i("p"),P=s("Bei so vielen verschiedenen Transformator-Architekturen kann es eine Herausforderung sein, eine f\xFCr Ihren Checkpoint zu erstellen. Als Teil der \u{1F917} Transformers Kernphilosophie, die Bibliothek leicht, einfach und flexibel nutzbar zu machen, leitet eine "),S=i("code"),H=s("AutoClass"),T=s(" automatisch die richtige Architektur aus einem gegebenen Checkpoint ab und l\xE4dt sie. Mit der Methode "),G=i("code"),R=s("from_pretrained()"),j=s(" kann man schnell ein vortrainiertes Modell f\xFCr eine beliebige Architektur laden, so dass man keine Zeit und Ressourcen aufwenden muss, um ein Modell von Grund auf zu trainieren. Die Erstellung dieser Art von Checkpoint-agnostischem Code bedeutet, dass Ihr Code, wenn er f\xFCr einen Checkpoint funktioniert, auch mit einem anderen Checkpoint funktionieren wird - solange er f\xFCr eine \xE4hnliche Aufgabe trainiert wurde - selbst wenn die Architektur unterschiedlich ist."),q=m(),L(_.$$.fragment),I=m(),w=i("p"),c=s("In dieser Anleitung lernen Sie, wie man:"),g=m(),u=i("ul"),b=i("li"),D=s("Einen vortrainierten Tokenizer l\xE4dt."),W=m(),Q=i("li"),X=s("Einen vortrainierten Merkmalsextraktor l\xE4dt."),te=m(),re=i("li"),U=s("Einen vortrainierten Prozessor l\xE4dt."),C=m(),ie=i("li"),Fe=s("Ein vortrainiertes Modell l\xE4dt."),ve=m(),Y=i("h2"),ee=i("a"),oe=i("span"),L(Z.$$.fragment),Se=m(),le=i("span"),Te=s("AutoTokenizer"),Ze=m(),Pe=i("p"),kt=s("Nahezu jede NLP-Aufgabe beginnt mit einem Tokenizer. Ein Tokenizer wandelt Ihre Eingabe in ein Format um, das vom Modell verarbeitet werden kann."),Qe=m(),ue=i("p"),gt=s("Laden Sie einen Tokenizer mit "),Ie=i("code"),vt=s("AutoTokenizer.from_pretrained()"),$t=s(":"),Ue=m(),L($e.$$.fragment),Je=m(),Ce=i("p"),wt=s("Dann tokenisieren Sie Ihre Eingabe wie unten gezeigt:"),We=m(),L(we.$$.fragment),Xe=m(),ne=i("h2"),de=i("a"),De=i("span"),L(Ae.$$.fragment),At=m(),Le=i("span"),_t=s("AutoFeatureExtractor"),Ye=m(),xe=i("p"),Et=s("F\xFCr Audio- und Bildverarbeitungsaufgaben verarbeitet ein Merkmalsextraktor das Audiosignal oder Bild in das richtige Eingabeformat."),et=m(),fe=i("p"),zt=s("Laden Sie einen Merkmalsextraktor mit "),Be=i("code"),jt=s("AutoFeatureExtractor.from_pretrained()"),Mt=s(":"),tt=m(),L(_e.$$.fragment),rt=m(),se=i("h2"),pe=i("a"),Oe=i("span"),L(Ee.$$.fragment),Ft=m(),Ke=i("span"),St=s("AutoProcessor"),nt=m(),ce=i("p"),Tt=s("Multimodale Aufgaben erfordern einen Prozessor, der zwei Arten von Vorverarbeitungswerkzeugen kombiniert. Das Modell "),ye=i("a"),Pt=s("LayoutLMV2"),Ct=s(" beispielsweise ben\xF6tigt einen Feature-Extraktor f\xFCr Bilder und einen Tokenizer f\xFCr Text; ein Prozessor kombiniert beide."),st=m(),me=i("p"),xt=s("Laden Sie einen Prozessor mit "),Ne=i("code"),yt=s("AutoProcessor.from_pretrained()"),qt=s(":"),at=m(),L(ze.$$.fragment),it=m(),ae=i("h2"),he=i("a"),Ve=i("span"),L(je.$$.fragment),It=m(),He=i("span"),Dt=s("AutoModel"),ot=m(),L(be.$$.fragment),this.h()},l(e){const p=kr('[data-svelte="svelte-1phssyn"]',document.head);n=o(p,"META",{name:!0,content:!0}),p.forEach(r),A=h(e),d=o(e,"H1",{class:!0});var Me=l(d);k=o(Me,"A",{id:!0,class:!0,href:!0});var Ge=l(k);E=o(Ge,"SPAN",{});var Lt=l(E);B(v.$$.fragment,Lt),Lt.forEach(r),Ge.forEach(r),y=h(Me),x=o(Me,"SPAN",{});var Bt=l(x);z=a(Bt,"Vortrainierte Instanzen mit einer AutoClass laden"),Bt.forEach(r),Me.forEach(r),M=h(e),F=o(e,"P",{});var qe=l(F);P=a(qe,"Bei so vielen verschiedenen Transformator-Architekturen kann es eine Herausforderung sein, eine f\xFCr Ihren Checkpoint zu erstellen. Als Teil der \u{1F917} Transformers Kernphilosophie, die Bibliothek leicht, einfach und flexibel nutzbar zu machen, leitet eine "),S=o(qe,"CODE",{});var Ot=l(S);H=a(Ot,"AutoClass"),Ot.forEach(r),T=a(qe," automatisch die richtige Architektur aus einem gegebenen Checkpoint ab und l\xE4dt sie. Mit der Methode "),G=o(qe,"CODE",{});var Kt=l(G);R=a(Kt,"from_pretrained()"),Kt.forEach(r),j=a(qe," kann man schnell ein vortrainiertes Modell f\xFCr eine beliebige Architektur laden, so dass man keine Zeit und Ressourcen aufwenden muss, um ein Modell von Grund auf zu trainieren. Die Erstellung dieser Art von Checkpoint-agnostischem Code bedeutet, dass Ihr Code, wenn er f\xFCr einen Checkpoint funktioniert, auch mit einem anderen Checkpoint funktionieren wird - solange er f\xFCr eine \xE4hnliche Aufgabe trainiert wurde - selbst wenn die Architektur unterschiedlich ist."),qe.forEach(r),q=h(e),B(_.$$.fragment,e),I=h(e),w=o(e,"P",{});var Nt=l(w);c=a(Nt,"In dieser Anleitung lernen Sie, wie man:"),Nt.forEach(r),g=h(e),u=o(e,"UL",{});var ke=l(u);b=o(ke,"LI",{});var Vt=l(b);D=a(Vt,"Einen vortrainierten Tokenizer l\xE4dt."),Vt.forEach(r),W=h(ke),Q=o(ke,"LI",{});var Ht=l(Q);X=a(Ht,"Einen vortrainierten Merkmalsextraktor l\xE4dt."),Ht.forEach(r),te=h(ke),re=o(ke,"LI",{});var Gt=l(re);U=a(Gt,"Einen vortrainierten Prozessor l\xE4dt."),Gt.forEach(r),C=h(ke),ie=o(ke,"LI",{});var Rt=l(ie);Fe=a(Rt,"Ein vortrainiertes Modell l\xE4dt."),Rt.forEach(r),ke.forEach(r),ve=h(e),Y=o(e,"H2",{class:!0});var ut=l(Y);ee=o(ut,"A",{id:!0,class:!0,href:!0});var Zt=l(ee);oe=o(Zt,"SPAN",{});var Qt=l(oe);B(Z.$$.fragment,Qt),Qt.forEach(r),Zt.forEach(r),Se=h(ut),le=o(ut,"SPAN",{});var Ut=l(le);Te=a(Ut,"AutoTokenizer"),Ut.forEach(r),ut.forEach(r),Ze=h(e),Pe=o(e,"P",{});var Jt=l(Pe);kt=a(Jt,"Nahezu jede NLP-Aufgabe beginnt mit einem Tokenizer. Ein Tokenizer wandelt Ihre Eingabe in ein Format um, das vom Modell verarbeitet werden kann."),Jt.forEach(r),Qe=h(e),ue=o(e,"P",{});var dt=l(ue);gt=a(dt,"Laden Sie einen Tokenizer mit "),Ie=o(dt,"CODE",{});var Wt=l(Ie);vt=a(Wt,"AutoTokenizer.from_pretrained()"),Wt.forEach(r),$t=a(dt,":"),dt.forEach(r),Ue=h(e),B($e.$$.fragment,e),Je=h(e),Ce=o(e,"P",{});var Xt=l(Ce);wt=a(Xt,"Dann tokenisieren Sie Ihre Eingabe wie unten gezeigt:"),Xt.forEach(r),We=h(e),B(we.$$.fragment,e),Xe=h(e),ne=o(e,"H2",{class:!0});var ft=l(ne);de=o(ft,"A",{id:!0,class:!0,href:!0});var Yt=l(de);De=o(Yt,"SPAN",{});var er=l(De);B(Ae.$$.fragment,er),er.forEach(r),Yt.forEach(r),At=h(ft),Le=o(ft,"SPAN",{});var tr=l(Le);_t=a(tr,"AutoFeatureExtractor"),tr.forEach(r),ft.forEach(r),Ye=h(e),xe=o(e,"P",{});var rr=l(xe);Et=a(rr,"F\xFCr Audio- und Bildverarbeitungsaufgaben verarbeitet ein Merkmalsextraktor das Audiosignal oder Bild in das richtige Eingabeformat."),rr.forEach(r),et=h(e),fe=o(e,"P",{});var pt=l(fe);zt=a(pt,"Laden Sie einen Merkmalsextraktor mit "),Be=o(pt,"CODE",{});var nr=l(Be);jt=a(nr,"AutoFeatureExtractor.from_pretrained()"),nr.forEach(r),Mt=a(pt,":"),pt.forEach(r),tt=h(e),B(_e.$$.fragment,e),rt=h(e),se=o(e,"H2",{class:!0});var ct=l(se);pe=o(ct,"A",{id:!0,class:!0,href:!0});var sr=l(pe);Oe=o(sr,"SPAN",{});var ar=l(Oe);B(Ee.$$.fragment,ar),ar.forEach(r),sr.forEach(r),Ft=h(ct),Ke=o(ct,"SPAN",{});var ir=l(Ke);St=a(ir,"AutoProcessor"),ir.forEach(r),ct.forEach(r),nt=h(e),ce=o(e,"P",{});var mt=l(ce);Tt=a(mt,"Multimodale Aufgaben erfordern einen Prozessor, der zwei Arten von Vorverarbeitungswerkzeugen kombiniert. Das Modell "),ye=o(mt,"A",{href:!0});var or=l(ye);Pt=a(or,"LayoutLMV2"),or.forEach(r),Ct=a(mt," beispielsweise ben\xF6tigt einen Feature-Extraktor f\xFCr Bilder und einen Tokenizer f\xFCr Text; ein Prozessor kombiniert beide."),mt.forEach(r),st=h(e),me=o(e,"P",{});var ht=l(me);xt=a(ht,"Laden Sie einen Prozessor mit "),Ne=o(ht,"CODE",{});var lr=l(Ne);yt=a(lr,"AutoProcessor.from_pretrained()"),lr.forEach(r),qt=a(ht,":"),ht.forEach(r),at=h(e),B(ze.$$.fragment,e),it=h(e),ae=o(e,"H2",{class:!0});var bt=l(ae);he=o(bt,"A",{id:!0,class:!0,href:!0});var ur=l(he);Ve=o(ur,"SPAN",{});var dr=l(Ve);B(je.$$.fragment,dr),dr.forEach(r),ur.forEach(r),It=h(bt),He=o(bt,"SPAN",{});var fr=l(He);Dt=a(fr,"AutoModel"),fr.forEach(r),bt.forEach(r),ot=h(e),B(be.$$.fragment,e),this.h()},h(){$(n,"name","hf:doc:metadata"),$(n,"content",JSON.stringify(Fr)),$(k,"id","vortrainierte-instanzen-mit-einer-autoclass-laden"),$(k,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),$(k,"href","#vortrainierte-instanzen-mit-einer-autoclass-laden"),$(d,"class","relative group"),$(ee,"id","autotokenizer"),$(ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),$(ee,"href","#autotokenizer"),$(Y,"class","relative group"),$(de,"id","autofeatureextractor"),$(de,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),$(de,"href","#autofeatureextractor"),$(ne,"class","relative group"),$(pe,"id","autoprocessor"),$(pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),$(pe,"href","#autoprocessor"),$(se,"class","relative group"),$(ye,"href","model_doc/layoutlmv2"),$(he,"id","automodel"),$(he,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),$(he,"href","#automodel"),$(ae,"class","relative group")},m(e,p){t(document.head,n),f(e,A,p),f(e,d,p),t(d,k),t(k,E),O(v,E,null),t(d,y),t(d,x),t(x,z),f(e,M,p),f(e,F,p),t(F,P),t(F,S),t(S,H),t(F,T),t(F,G),t(G,R),t(F,j),f(e,q,p),O(_,e,p),f(e,I,p),f(e,w,p),t(w,c),f(e,g,p),f(e,u,p),t(u,b),t(b,D),t(u,W),t(u,Q),t(Q,X),t(u,te),t(u,re),t(re,U),t(u,C),t(u,ie),t(ie,Fe),f(e,ve,p),f(e,Y,p),t(Y,ee),t(ee,oe),O(Z,oe,null),t(Y,Se),t(Y,le),t(le,Te),f(e,Ze,p),f(e,Pe,p),t(Pe,kt),f(e,Qe,p),f(e,ue,p),t(ue,gt),t(ue,Ie),t(Ie,vt),t(ue,$t),f(e,Ue,p),O($e,e,p),f(e,Je,p),f(e,Ce,p),t(Ce,wt),f(e,We,p),O(we,e,p),f(e,Xe,p),f(e,ne,p),t(ne,de),t(de,De),O(Ae,De,null),t(ne,At),t(ne,Le),t(Le,_t),f(e,Ye,p),f(e,xe,p),t(xe,Et),f(e,et,p),f(e,fe,p),t(fe,zt),t(fe,Be),t(Be,jt),t(fe,Mt),f(e,tt,p),O(_e,e,p),f(e,rt,p),f(e,se,p),t(se,pe),t(pe,Oe),O(Ee,Oe,null),t(se,Ft),t(se,Ke),t(Ke,St),f(e,nt,p),f(e,ce,p),t(ce,Tt),t(ce,ye),t(ye,Pt),t(ce,Ct),f(e,st,p),f(e,me,p),t(me,xt),t(me,Ne),t(Ne,yt),t(me,qt),f(e,at,p),O(ze,e,p),f(e,it,p),f(e,ae,p),t(ae,he),t(he,Ve),O(je,Ve,null),t(ae,It),t(ae,He),t(He,Dt),f(e,ot,p),O(be,e,p),lt=!0},p(e,[p]){const Me={};p&2&&(Me.$$scope={dirty:p,ctx:e}),_.$set(Me);const Ge={};p&2&&(Ge.$$scope={dirty:p,ctx:e}),be.$set(Ge)},i(e){lt||(K(v.$$.fragment,e),K(_.$$.fragment,e),K(Z.$$.fragment,e),K($e.$$.fragment,e),K(we.$$.fragment,e),K(Ae.$$.fragment,e),K(_e.$$.fragment,e),K(Ee.$$.fragment,e),K(ze.$$.fragment,e),K(je.$$.fragment,e),K(be.$$.fragment,e),lt=!0)},o(e){N(v.$$.fragment,e),N(_.$$.fragment,e),N(Z.$$.fragment,e),N($e.$$.fragment,e),N(we.$$.fragment,e),N(Ae.$$.fragment,e),N(_e.$$.fragment,e),N(Ee.$$.fragment,e),N(ze.$$.fragment,e),N(je.$$.fragment,e),N(be.$$.fragment,e),lt=!1},d(e){r(n),e&&r(A),e&&r(d),V(v),e&&r(M),e&&r(F),e&&r(q),V(_,e),e&&r(I),e&&r(w),e&&r(g),e&&r(u),e&&r(ve),e&&r(Y),V(Z),e&&r(Ze),e&&r(Pe),e&&r(Qe),e&&r(ue),e&&r(Ue),V($e,e),e&&r(Je),e&&r(Ce),e&&r(We),V(we,e),e&&r(Xe),e&&r(ne),V(Ae),e&&r(Ye),e&&r(xe),e&&r(et),e&&r(fe),e&&r(tt),V(_e,e),e&&r(rt),e&&r(se),V(Ee),e&&r(nt),e&&r(ce),e&&r(st),e&&r(me),e&&r(at),V(ze,e),e&&r(it),e&&r(ae),V(je),e&&r(ot),V(be,e)}}}const Fr={local:"vortrainierte-instanzen-mit-einer-autoclass-laden",sections:[{local:"autotokenizer",title:"AutoTokenizer"},{local:"autofeatureextractor",title:"AutoFeatureExtractor"},{local:"autoprocessor",title:"AutoProcessor"},{local:"automodel",title:"AutoModel"}],title:"Vortrainierte Instanzen mit einer AutoClass laden"};function Sr(J){return gr(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class qr extends mr{constructor(n){super();hr(this,n,Sr,Mr,br,{})}}export{qr as default,Fr as metadata};
