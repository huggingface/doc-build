import{S as Zs,i as er,s as lr,e as o,k as d,w as c,t as n,M as tr,c as a,d as t,m as u,a as i,x as g,h as s,b as p,G as l,g as m,y as f,L as or,q as h,o as _,B as v,v as ar}from"../chunks/vendor-hf-doc-builder.js";import{I as se}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as x}from"../chunks/CodeBlock-hf-doc-builder.js";import{D as ir}from"../chunks/DocNotebookDropdown-hf-doc-builder.js";function nr(xn){let q,ct,I,S,dl,re,qo,ul,Io,gt,me,ft,y,Po,pl,To,Co,de,Do,Ao,ht,P,B,cl,ue,Oo,gl,Xo,_t,qe,So,vt,T,R,fl,pe,Bo,hl,Ro,bt,Ie,No,zt,b,Pe,_l,Fo,Ho,Qo,Te,vl,Wo,Go,Uo,Ce,bl,Jo,Ko,Vo,De,zl,Yo,Zo,ea,Ae,kl,la,ta,oa,Oe,El,aa,ia,na,Xe,$l,sa,ra,kt,E,ma,Ml,da,ua,wl,pa,ca,xl,ga,fa,Et,N,ha,yl,_a,va,$t,ce,Mt,F,ba,Ll,za,ka,wt,ge,xt,Se,Ea,yt,fe,Lt,$,$a,jl,Ma,wa,ql,xa,ya,Il,La,ja,jt,he,qt,H,qa,Pl,Ia,Pa,It,_e,Pt,L,Ta,ve,Ca,Da,Tl,Aa,Oa,Tt,C,Q,Cl,be,Xa,Dl,Sa,Ct,Be,Ba,Dt,W,Re,Al,Ra,Na,Fa,Ne,Ol,Ha,Qa,At,Fe,Wa,Ot,D,G,Xl,ze,Ga,Sl,Ua,Xt,He,Ja,St,U,Qe,Bl,Ka,Va,Ya,We,Rl,Za,ei,Bt,Ge,li,Rt,A,J,Nl,ke,ti,Fl,oi,Nt,Ue,ai,Ft,K,Je,Hl,ii,ni,si,Ke,Ql,ri,mi,Ht,Ve,di,Qt,O,V,Wl,Ee,ui,Gl,pi,Wt,Ye,ci,Gt,Y,Ze,Ul,gi,fi,hi,el,Jl,_i,vi,Ut,Z,bi,Kl,zi,ki,Jt,$e,Kt,ll,Ei,Vt,Me,Yt,M,$i,Vl,Mi,wi,Yl,xi,yi,Zl,Li,ji,Zt,we,eo,X,ee,et,xe,qi,lt,Ii,lo,tl,Pi,to,z,ol,tt,Ti,Ci,Di,al,ot,Ai,Oi,Xi,il,at,Si,Bi,Ri,nl,it,Ni,Fi,Hi,nt,st,Qi,oo,le,Wi,rt,Gi,Ui,ao,ye,io,sl,Ji,no,Le,so,w,Ki,mt,Vi,Yi,dt,Zi,en,ut,ln,tn,ro,je,mo,te,on,pt,an,nn,uo;return re=new se({}),me=new ir({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/multilingual.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/pytorch/multilingual.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/tensorflow/multilingual.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/multilingual.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/pytorch/multilingual.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/tensorflow/multilingual.ipynb"}]}}),ue=new se({}),pe=new se({}),ce=new x({props:{code:`import torch
from transformers import XLMTokenizer, XLMWithLMHeadModel

tokenizer = XLMTokenizer.from_pretrained("xlm-clm-enfr-1024")
model = XLMWithLMHeadModel.from_pretrained("xlm-clm-enfr-1024")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> XLMTokenizer, XLMWithLMHeadModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = XLMTokenizer.from_pretrained(<span class="hljs-string">&quot;xlm-clm-enfr-1024&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = XLMWithLMHeadModel.from_pretrained(<span class="hljs-string">&quot;xlm-clm-enfr-1024&quot;</span>)`}}),ge=new x({props:{code:"print(tokenizer.lang2id)",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(tokenizer.lang2id)
{<span class="hljs-string">&#x27;en&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;fr&#x27;</span>: <span class="hljs-number">1</span>}`}}),fe=new x({props:{code:'input_ids = torch.tensor([tokenizer.encode("Wikipedia was used to")])  # batch size of 1',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>input_ids = torch.tensor([tokenizer.encode(<span class="hljs-string">&quot;Wikipedia was used to&quot;</span>)])  <span class="hljs-comment"># batch size of 1</span>'}}),he=new x({props:{code:`language_id = tokenizer.lang2id["en"]  # 0
langs = torch.tensor([language_id] * input_ids.shape[1])  # torch.tensor([0, 0, 0, ..., 0])

# We reshape it to be of size (batch_size, sequence_length)
langs = langs.view(1, -1)  # is now of shape [1, sequence_length] (we have a batch size of 1)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>language_id = tokenizer.lang2id[<span class="hljs-string">&quot;en&quot;</span>]  <span class="hljs-comment"># 0</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>langs = torch.tensor([language_id] * input_ids.shape[<span class="hljs-number">1</span>])  <span class="hljs-comment"># torch.tensor([0, 0, 0, ..., 0])</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># We reshape it to be of size (batch_size, sequence_length)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>langs = langs.view(<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)  <span class="hljs-comment"># is now of shape [1, sequence_length] (we have a batch size of 1)</span>`}}),_e=new x({props:{code:"outputs = model(input_ids, langs=langs)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(input_ids, langs=langs)'}}),be=new se({}),ze=new se({}),ke=new se({}),Ee=new se({}),$e=new x({props:{code:`from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer

en_text = "Do not meddle in the affairs of wizards, for they are subtle and quick to anger."
chinese_text = "\u4E0D\u8981\u63D2\u624B\u5DEB\u5E2B\u7684\u4E8B\u52D9, \u56E0\u70BA\u4ED6\u5011\u662F\u5FAE\u5999\u7684, \u5F88\u5FEB\u5C31\u6703\u767C\u6012."

tokenizer = M2M100Tokenizer.from_pretrained("facebook/m2m100_418M", src_lang="zh")
model = M2M100ForConditionalGeneration.from_pretrained("facebook/m2m100_418M")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> M2M100ForConditionalGeneration, M2M100Tokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>en_text = <span class="hljs-string">&quot;Do not meddle in the affairs of wizards, for they are subtle and quick to anger.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>chinese_text = <span class="hljs-string">&quot;\u4E0D\u8981\u63D2\u624B\u5DEB\u5E2B\u7684\u4E8B\u52D9, \u56E0\u70BA\u4ED6\u5011\u662F\u5FAE\u5999\u7684, \u5F88\u5FEB\u5C31\u6703\u767C\u6012.&quot;</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = M2M100Tokenizer.from_pretrained(<span class="hljs-string">&quot;facebook/m2m100_418M&quot;</span>, src_lang=<span class="hljs-string">&quot;zh&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = M2M100ForConditionalGeneration.from_pretrained(<span class="hljs-string">&quot;facebook/m2m100_418M&quot;</span>)`}}),Me=new x({props:{code:'encoded_zh = tokenizer(chinese_text, return_tensors="pt")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_zh = tokenizer(chinese_text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)'}}),we=new x({props:{code:`generated_tokens = model.generate(**encoded_zh, forced_bos_token_id=tokenizer.get_lang_id("en"))
tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generated_tokens = model.generate(**encoded_zh, forced_bos_token_id=tokenizer.get_lang_id(<span class="hljs-string">&quot;en&quot;</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.batch_decode(generated_tokens, skip_special_tokens=<span class="hljs-literal">True</span>)
<span class="hljs-string">&#x27;Do not interfere with the matters of the witches, because they are delicate and will soon be angry.&#x27;</span>`}}),xe=new se({}),ye=new x({props:{code:`from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

en_text = "Do not meddle in the affairs of wizards, for they are subtle and quick to anger."
fi_text = "\xC4l\xE4 sekaannu velhojen asioihin, sill\xE4 ne ovat hienovaraisia ja nopeasti vihaisia."

tokenizer = AutoTokenizer.from_pretrained("facebook/mbart-large-50-many-to-many-mmt", src_lang="fi_FI")
model = AutoModelForSeq2SeqLM.from_pretrained("facebook/mbart-large-50-many-to-many-mmt")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span>en_text = <span class="hljs-string">&quot;Do not meddle in the affairs of wizards, for they are subtle and quick to anger.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>fi_text = <span class="hljs-string">&quot;\xC4l\xE4 sekaannu velhojen asioihin, sill\xE4 ne ovat hienovaraisia ja nopeasti vihaisia.&quot;</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;facebook/mbart-large-50-many-to-many-mmt&quot;</span>, src_lang=<span class="hljs-string">&quot;fi_FI&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;facebook/mbart-large-50-many-to-many-mmt&quot;</span>)`}}),Le=new x({props:{code:'encoded_en = tokenizer(en_text, return_tensors="pt")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_en = tokenizer(en_text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)'}}),je=new x({props:{code:`generated_tokens = model.generate(**encoded_en, forced_bos_token_id=tokenizer.lang_code_to_id("en_XX"))
tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generated_tokens = model.generate(**encoded_en, forced_bos_token_id=tokenizer.lang_code_to_id(<span class="hljs-string">&quot;en_XX&quot;</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.batch_decode(generated_tokens, skip_special_tokens=<span class="hljs-literal">True</span>)
<span class="hljs-string">&quot;Don&#x27;t interfere with the wizard&#x27;s affairs, because they are subtle, will soon get angry.&quot;</span>`}}),{c(){q=o("meta"),ct=d(),I=o("h1"),S=o("a"),dl=o("span"),c(re.$$.fragment),qo=d(),ul=o("span"),Io=n("Modelli multilingue per l'inferenza"),gt=d(),c(me.$$.fragment),ft=d(),y=o("p"),Po=n("Ci sono diversi modelli multilingue in \u{1F917} Transformers, e il loro utilizzo per l\u2019inferenza differisce da quello dei modelli monolingua. Non "),pl=o("em"),To=n("tutti"),Co=n(" gli utilizzi dei modelli multilingue sono per\xF2 diversi. Alcuni modelli, come "),de=o("a"),Do=n("bert-base-multilingual-uncased"),Ao=n(", possono essere usati come un modello monolingua. Questa guida ti mostrer\xE0 come utilizzare modelli multilingue che utilizzano un modo diverso per fare l\u2019inferenza."),ht=d(),P=o("h2"),B=o("a"),cl=o("span"),c(ue.$$.fragment),Oo=d(),gl=o("span"),Xo=n("XLM"),_t=d(),qe=o("p"),So=n("XLM ha dieci diversi checkpoint, di cui solo uno \xE8 monolingua. I nove checkpoint rimanenti possono essere suddivisi in due categorie: i checkpoint che utilizzano i language embeddings e quelli che non li utilizzano."),vt=d(),T=o("h3"),R=o("a"),fl=o("span"),c(pe.$$.fragment),Bo=d(),hl=o("span"),Ro=n("XLM con language embeddings"),bt=d(),Ie=o("p"),No=n("I seguenti modelli XLM utilizzano gli embeddings linguistici per specificare la lingua utilizzata per l\u2019inferenza:"),zt=d(),b=o("ul"),Pe=o("li"),_l=o("code"),Fo=n("xlm-mlm-ende-1024"),Ho=n(" (Modellazione mascherata del linguaggio (Masked language modeling, in inglese), Inglese-Tedesco)"),Qo=d(),Te=o("li"),vl=o("code"),Wo=n("xlm-mlm-enfr-1024"),Go=n(" (Modellazione mascherata del linguaggio, Inglese-Francese)"),Uo=d(),Ce=o("li"),bl=o("code"),Jo=n("xlm-mlm-enro-1024"),Ko=n(" (Modellazione mascherata del linguaggio, Inglese-Rumeno)"),Vo=d(),De=o("li"),zl=o("code"),Yo=n("xlm-mlm-xnli15-1024"),Zo=n(" (Modellazione mascherata del linguaggio, lingue XNLI)"),ea=d(),Ae=o("li"),kl=o("code"),la=n("xlm-mlm-tlm-xnli15-1024"),ta=n(" (Modellazione mascherata del linguaggio + traduzione, lingue XNLI)"),oa=d(),Oe=o("li"),El=o("code"),aa=n("xlm-clm-enfr-1024"),ia=n(" (Modellazione causale del linguaggio, Inglese-Francese)"),na=d(),Xe=o("li"),$l=o("code"),sa=n("xlm-clm-ende-1024"),ra=n(" (Modellazione causale del linguaggio, Inglese-Tedesco)"),kt=d(),E=o("p"),ma=n("Gli embeddings linguistici sono rappresentati come un tensore delle stesse dimensioni dell\u2019 "),Ml=o("code"),da=n("input_ids"),ua=n(" passato al modello. I valori in questi tensori dipendono dal linguaggio usato e sono identificati dagli attributi "),wl=o("code"),pa=n("lang2id"),ca=n(" e "),xl=o("code"),ga=n("id2lang"),fa=n(" del tokenizer."),Et=d(),N=o("p"),ha=n("In questo esempio, carica il checkpoint "),yl=o("code"),_a=n("xlm-clm-enfr-1024"),va=n(" (Modellazione causale del linguaggio, Inglese-Francese):"),$t=d(),c(ce.$$.fragment),Mt=d(),F=o("p"),ba=n("L\u2019attributo "),Ll=o("code"),za=n("lang2id"),ka=n(" del tokenizer mostra il linguaggio del modello e il suo ids:"),wt=d(),c(ge.$$.fragment),xt=d(),Se=o("p"),Ea=n("Poi, crea un esempio di input:"),yt=d(),c(fe.$$.fragment),Lt=d(),$=o("p"),$a=n("Imposta l\u2019id del linguaggio a "),jl=o("code"),Ma=n('"en"'),wa=n(" e usalo per definire il language embedding. Il language embedding \xE8 un tensore riempito con "),ql=o("code"),xa=n("0"),ya=n(" perch\xE9 questo \xE8 il language id per l\u2019inglese. Questo tensore dovrebbe avere la stessa dimensione di "),Il=o("code"),La=n("input_ids"),ja=n("."),jt=d(),c(he.$$.fragment),qt=d(),H=o("p"),qa=n("Adesso puoi inserire "),Pl=o("code"),Ia=n("input_ids"),Pa=n(" e language embedding nel modello:"),It=d(),c(_e.$$.fragment),Pt=d(),L=o("p"),Ta=n("Lo script "),ve=o("a"),Ca=n("run_generation.py"),Da=n(" pu\xF2 generare testo tramite i language embeddings usando i checkpoints "),Tl=o("code"),Aa=n("xlm-clm"),Oa=n("."),Tt=d(),C=o("h3"),Q=o("a"),Cl=o("span"),c(be.$$.fragment),Xa=d(),Dl=o("span"),Sa=n("XLM senza language embeddings"),Ct=d(),Be=o("p"),Ba=n("I seguenti modelli XLM non richiedono l\u2019utilizzo dei language embeddings per fare inferenza:"),Dt=d(),W=o("ul"),Re=o("li"),Al=o("code"),Ra=n("xlm-mlm-17-1280"),Na=n(" (Modellazione mascherata del linguaggio, 17 lingue)"),Fa=d(),Ne=o("li"),Ol=o("code"),Ha=n("xlm-mlm-100-1280"),Qa=n(" (Modellazione mascherata del linguaggio, 100 lingue)"),At=d(),Fe=o("p"),Wa=n("Questi modelli sono utilizzati per rappresentazioni generiche di frasi, a differenza dei precedenti checkpoints XML."),Ot=d(),D=o("h2"),G=o("a"),Xl=o("span"),c(ze.$$.fragment),Ga=d(),Sl=o("span"),Ua=n("BERT"),Xt=d(),He=o("p"),Ja=n("Il seguente modello BERT pu\xF2 essere usato per compiti multilingue:"),St=d(),U=o("ul"),Qe=o("li"),Bl=o("code"),Ka=n("bert-base-multilingual-uncased"),Va=n(" (Modellazione mascherata del linguaggio + Previsione della prossima frase, 102 lingue)"),Ya=d(),We=o("li"),Rl=o("code"),Za=n("bert-base-multilingual-cased"),ei=n(" (Modellazione mascherata del linguaggio + Previsione della prossima frase, 104 lingue)"),Bt=d(),Ge=o("p"),li=n("Questi modelli non richiedono language embeddings per fare inferenza. Riescono ad identificare il linguaggio dal contesto e inferire di conseguenza."),Rt=d(),A=o("h2"),J=o("a"),Nl=o("span"),c(ke.$$.fragment),ti=d(),Fl=o("span"),oi=n("XLM-RoBERTa"),Nt=d(),Ue=o("p"),ai=n("Il seguente modello XLM-RoBERTa pu\xF2 essere usato per compiti multilingue:"),Ft=d(),K=o("ul"),Je=o("li"),Hl=o("code"),ii=n("xlm-roberta-base"),ni=n(" (Modellazione mascherata del linguaggio, 100 lingue)"),si=d(),Ke=o("li"),Ql=o("code"),ri=n("xlm-roberta-large"),mi=n(" (Modellazione mascherata del linguaggio, 100 lingue)"),Ht=d(),Ve=o("p"),di=n("XLM-RoBERTa \xE8 stato addestrato su 2.5TB di dati CommonCrawl appena creati e puliti in 100 lingue. Offre notevoli vantaggi rispetto ai modelli multilingue rilasciati in precedenza, come mBERT o XLM, in compiti come la classificazione, l\u2019etichettatura delle sequenze e la risposta alle domande."),Qt=d(),O=o("h2"),V=o("a"),Wl=o("span"),c(Ee.$$.fragment),ui=d(),Gl=o("span"),pi=n("M2M100"),Wt=d(),Ye=o("p"),ci=n("Il seguente modello M2M100 pu\xF2 essere usato per compiti multilingue:"),Gt=d(),Y=o("ul"),Ze=o("li"),Ul=o("code"),gi=n("facebook/m2m100_418M"),fi=n(" (Traduzione)"),hi=d(),el=o("li"),Jl=o("code"),_i=n("facebook/m2m100_1.2B"),vi=n(" (Traduzione)"),Ut=d(),Z=o("p"),bi=n("In questo esempio, carica il checkpoint "),Kl=o("code"),zi=n("facebook/m2m100_418M"),ki=n("  per tradurre dal cinese all\u2019inglese. Puoi impostare la lingua di partenza nel tokenizer:"),Jt=d(),c($e.$$.fragment),Kt=d(),ll=o("p"),Ei=n("Applica il tokenizer al testo:"),Vt=d(),c(Me.$$.fragment),Yt=d(),M=o("p"),$i=n("M2M100 forza l\u2019id della lingua obiettivo come primo token generato per tradurre nella lingua obiettivo. Imposta il parametro "),Vl=o("code"),Mi=n("forced_bos_token_id"),wi=n(" a "),Yl=o("code"),xi=n("en"),yi=n(" nel metodo "),Zl=o("code"),Li=n("generate"),ji=n(" per tradurre in inglese:"),Zt=d(),c(we.$$.fragment),eo=d(),X=o("h2"),ee=o("a"),et=o("span"),c(xe.$$.fragment),qi=d(),lt=o("span"),Ii=n("MBart"),lo=d(),tl=o("p"),Pi=n("Il seguente modello MBart pu\xF2 essere usato per compiti multilingue:"),to=d(),z=o("ul"),ol=o("li"),tt=o("code"),Ti=n("facebook/mbart-large-50-one-to-many-mmt"),Ci=n(" (Traduzione automatica multilingue uno-a-molti, 50 lingue)"),Di=d(),al=o("li"),ot=o("code"),Ai=n("facebook/mbart-large-50-many-to-many-mmt"),Oi=n(" (Traduzione automatica multilingue molti-a-molti, 50 lingue)"),Xi=d(),il=o("li"),at=o("code"),Si=n("facebook/mbart-large-50-many-to-one-mmt"),Bi=n(" (Traduzione automatica multilingue molti-a-uno, 50 lingue)"),Ri=d(),nl=o("li"),it=o("code"),Ni=n("facebook/mbart-large-50"),Fi=n(" (Traduzione multilingue, 50 lingue)"),Hi=d(),nt=o("li"),st=o("code"),Qi=n("facebook/mbart-large-cc25"),oo=d(),le=o("p"),Wi=n("In questo esempio, carica il checkpoint "),rt=o("code"),Gi=n("facebook/mbart-large-50-many-to-many-mmt"),Ui=n(" per tradurre dal finlandese all\u2019inglese. Puoi impostare la lingua di partenza nel tokenizer:"),ao=d(),c(ye.$$.fragment),io=d(),sl=o("p"),Ji=n("Applica il tokenizer sul testo:"),no=d(),c(Le.$$.fragment),so=d(),w=o("p"),Ki=n("MBart forza l\u2019id della lingua obiettivo come primo token generato per tradurre nella lingua obiettivo. Imposta il parametro "),mt=o("code"),Vi=n("forced_bos_token_id"),Yi=n(" a "),dt=o("code"),Zi=n("en"),en=n(" nel metodo "),ut=o("code"),ln=n("generate"),tn=n(" per tradurre in inglese:"),ro=d(),c(je.$$.fragment),mo=d(),te=o("p"),on=n("Se stai usando il checkpoint "),pt=o("code"),an=n("facebook/mbart-large-50-many-to-one-mmt"),nn=n(", non hai bisogno di forzare l\u2019id della lingua obiettivo come primo token generato altrimenti l\u2019uso \xE8 lo stesso."),this.h()},l(e){const r=tr('[data-svelte="svelte-1phssyn"]',document.head);q=a(r,"META",{name:!0,content:!0}),r.forEach(t),ct=u(e),I=a(e,"H1",{class:!0});var po=i(I);S=a(po,"A",{id:!0,class:!0,href:!0});var yn=i(S);dl=a(yn,"SPAN",{});var Ln=i(dl);g(re.$$.fragment,Ln),Ln.forEach(t),yn.forEach(t),qo=u(po),ul=a(po,"SPAN",{});var jn=i(ul);Io=s(jn,"Modelli multilingue per l'inferenza"),jn.forEach(t),po.forEach(t),gt=u(e),g(me.$$.fragment,e),ft=u(e),y=a(e,"P",{});var rl=i(y);Po=s(rl,"Ci sono diversi modelli multilingue in \u{1F917} Transformers, e il loro utilizzo per l\u2019inferenza differisce da quello dei modelli monolingua. Non "),pl=a(rl,"EM",{});var qn=i(pl);To=s(qn,"tutti"),qn.forEach(t),Co=s(rl," gli utilizzi dei modelli multilingue sono per\xF2 diversi. Alcuni modelli, come "),de=a(rl,"A",{href:!0,rel:!0});var In=i(de);Do=s(In,"bert-base-multilingual-uncased"),In.forEach(t),Ao=s(rl,", possono essere usati come un modello monolingua. Questa guida ti mostrer\xE0 come utilizzare modelli multilingue che utilizzano un modo diverso per fare l\u2019inferenza."),rl.forEach(t),ht=u(e),P=a(e,"H2",{class:!0});var co=i(P);B=a(co,"A",{id:!0,class:!0,href:!0});var Pn=i(B);cl=a(Pn,"SPAN",{});var Tn=i(cl);g(ue.$$.fragment,Tn),Tn.forEach(t),Pn.forEach(t),Oo=u(co),gl=a(co,"SPAN",{});var Cn=i(gl);Xo=s(Cn,"XLM"),Cn.forEach(t),co.forEach(t),_t=u(e),qe=a(e,"P",{});var Dn=i(qe);So=s(Dn,"XLM ha dieci diversi checkpoint, di cui solo uno \xE8 monolingua. I nove checkpoint rimanenti possono essere suddivisi in due categorie: i checkpoint che utilizzano i language embeddings e quelli che non li utilizzano."),Dn.forEach(t),vt=u(e),T=a(e,"H3",{class:!0});var go=i(T);R=a(go,"A",{id:!0,class:!0,href:!0});var An=i(R);fl=a(An,"SPAN",{});var On=i(fl);g(pe.$$.fragment,On),On.forEach(t),An.forEach(t),Bo=u(go),hl=a(go,"SPAN",{});var Xn=i(hl);Ro=s(Xn,"XLM con language embeddings"),Xn.forEach(t),go.forEach(t),bt=u(e),Ie=a(e,"P",{});var Sn=i(Ie);No=s(Sn,"I seguenti modelli XLM utilizzano gli embeddings linguistici per specificare la lingua utilizzata per l\u2019inferenza:"),Sn.forEach(t),zt=u(e),b=a(e,"UL",{});var k=i(b);Pe=a(k,"LI",{});var sn=i(Pe);_l=a(sn,"CODE",{});var Bn=i(_l);Fo=s(Bn,"xlm-mlm-ende-1024"),Bn.forEach(t),Ho=s(sn," (Modellazione mascherata del linguaggio (Masked language modeling, in inglese), Inglese-Tedesco)"),sn.forEach(t),Qo=u(k),Te=a(k,"LI",{});var rn=i(Te);vl=a(rn,"CODE",{});var Rn=i(vl);Wo=s(Rn,"xlm-mlm-enfr-1024"),Rn.forEach(t),Go=s(rn," (Modellazione mascherata del linguaggio, Inglese-Francese)"),rn.forEach(t),Uo=u(k),Ce=a(k,"LI",{});var mn=i(Ce);bl=a(mn,"CODE",{});var Nn=i(bl);Jo=s(Nn,"xlm-mlm-enro-1024"),Nn.forEach(t),Ko=s(mn," (Modellazione mascherata del linguaggio, Inglese-Rumeno)"),mn.forEach(t),Vo=u(k),De=a(k,"LI",{});var dn=i(De);zl=a(dn,"CODE",{});var Fn=i(zl);Yo=s(Fn,"xlm-mlm-xnli15-1024"),Fn.forEach(t),Zo=s(dn," (Modellazione mascherata del linguaggio, lingue XNLI)"),dn.forEach(t),ea=u(k),Ae=a(k,"LI",{});var un=i(Ae);kl=a(un,"CODE",{});var Hn=i(kl);la=s(Hn,"xlm-mlm-tlm-xnli15-1024"),Hn.forEach(t),ta=s(un," (Modellazione mascherata del linguaggio + traduzione, lingue XNLI)"),un.forEach(t),oa=u(k),Oe=a(k,"LI",{});var pn=i(Oe);El=a(pn,"CODE",{});var Qn=i(El);aa=s(Qn,"xlm-clm-enfr-1024"),Qn.forEach(t),ia=s(pn," (Modellazione causale del linguaggio, Inglese-Francese)"),pn.forEach(t),na=u(k),Xe=a(k,"LI",{});var cn=i(Xe);$l=a(cn,"CODE",{});var Wn=i($l);sa=s(Wn,"xlm-clm-ende-1024"),Wn.forEach(t),ra=s(cn," (Modellazione causale del linguaggio, Inglese-Tedesco)"),cn.forEach(t),k.forEach(t),kt=u(e),E=a(e,"P",{});var oe=i(E);ma=s(oe,"Gli embeddings linguistici sono rappresentati come un tensore delle stesse dimensioni dell\u2019 "),Ml=a(oe,"CODE",{});var Gn=i(Ml);da=s(Gn,"input_ids"),Gn.forEach(t),ua=s(oe," passato al modello. I valori in questi tensori dipendono dal linguaggio usato e sono identificati dagli attributi "),wl=a(oe,"CODE",{});var Un=i(wl);pa=s(Un,"lang2id"),Un.forEach(t),ca=s(oe," e "),xl=a(oe,"CODE",{});var Jn=i(xl);ga=s(Jn,"id2lang"),Jn.forEach(t),fa=s(oe," del tokenizer."),oe.forEach(t),Et=u(e),N=a(e,"P",{});var fo=i(N);ha=s(fo,"In questo esempio, carica il checkpoint "),yl=a(fo,"CODE",{});var Kn=i(yl);_a=s(Kn,"xlm-clm-enfr-1024"),Kn.forEach(t),va=s(fo," (Modellazione causale del linguaggio, Inglese-Francese):"),fo.forEach(t),$t=u(e),g(ce.$$.fragment,e),Mt=u(e),F=a(e,"P",{});var ho=i(F);ba=s(ho,"L\u2019attributo "),Ll=a(ho,"CODE",{});var Vn=i(Ll);za=s(Vn,"lang2id"),Vn.forEach(t),ka=s(ho," del tokenizer mostra il linguaggio del modello e il suo ids:"),ho.forEach(t),wt=u(e),g(ge.$$.fragment,e),xt=u(e),Se=a(e,"P",{});var Yn=i(Se);Ea=s(Yn,"Poi, crea un esempio di input:"),Yn.forEach(t),yt=u(e),g(fe.$$.fragment,e),Lt=u(e),$=a(e,"P",{});var ae=i($);$a=s(ae,"Imposta l\u2019id del linguaggio a "),jl=a(ae,"CODE",{});var Zn=i(jl);Ma=s(Zn,'"en"'),Zn.forEach(t),wa=s(ae," e usalo per definire il language embedding. Il language embedding \xE8 un tensore riempito con "),ql=a(ae,"CODE",{});var es=i(ql);xa=s(es,"0"),es.forEach(t),ya=s(ae," perch\xE9 questo \xE8 il language id per l\u2019inglese. Questo tensore dovrebbe avere la stessa dimensione di "),Il=a(ae,"CODE",{});var ls=i(Il);La=s(ls,"input_ids"),ls.forEach(t),ja=s(ae,"."),ae.forEach(t),jt=u(e),g(he.$$.fragment,e),qt=u(e),H=a(e,"P",{});var _o=i(H);qa=s(_o,"Adesso puoi inserire "),Pl=a(_o,"CODE",{});var ts=i(Pl);Ia=s(ts,"input_ids"),ts.forEach(t),Pa=s(_o," e language embedding nel modello:"),_o.forEach(t),It=u(e),g(_e.$$.fragment,e),Pt=u(e),L=a(e,"P",{});var ml=i(L);Ta=s(ml,"Lo script "),ve=a(ml,"A",{href:!0,rel:!0});var os=i(ve);Ca=s(os,"run_generation.py"),os.forEach(t),Da=s(ml," pu\xF2 generare testo tramite i language embeddings usando i checkpoints "),Tl=a(ml,"CODE",{});var as=i(Tl);Aa=s(as,"xlm-clm"),as.forEach(t),Oa=s(ml,"."),ml.forEach(t),Tt=u(e),C=a(e,"H3",{class:!0});var vo=i(C);Q=a(vo,"A",{id:!0,class:!0,href:!0});var is=i(Q);Cl=a(is,"SPAN",{});var ns=i(Cl);g(be.$$.fragment,ns),ns.forEach(t),is.forEach(t),Xa=u(vo),Dl=a(vo,"SPAN",{});var ss=i(Dl);Sa=s(ss,"XLM senza language embeddings"),ss.forEach(t),vo.forEach(t),Ct=u(e),Be=a(e,"P",{});var rs=i(Be);Ba=s(rs,"I seguenti modelli XLM non richiedono l\u2019utilizzo dei language embeddings per fare inferenza:"),rs.forEach(t),Dt=u(e),W=a(e,"UL",{});var bo=i(W);Re=a(bo,"LI",{});var gn=i(Re);Al=a(gn,"CODE",{});var ms=i(Al);Ra=s(ms,"xlm-mlm-17-1280"),ms.forEach(t),Na=s(gn," (Modellazione mascherata del linguaggio, 17 lingue)"),gn.forEach(t),Fa=u(bo),Ne=a(bo,"LI",{});var fn=i(Ne);Ol=a(fn,"CODE",{});var ds=i(Ol);Ha=s(ds,"xlm-mlm-100-1280"),ds.forEach(t),Qa=s(fn," (Modellazione mascherata del linguaggio, 100 lingue)"),fn.forEach(t),bo.forEach(t),At=u(e),Fe=a(e,"P",{});var us=i(Fe);Wa=s(us,"Questi modelli sono utilizzati per rappresentazioni generiche di frasi, a differenza dei precedenti checkpoints XML."),us.forEach(t),Ot=u(e),D=a(e,"H2",{class:!0});var zo=i(D);G=a(zo,"A",{id:!0,class:!0,href:!0});var ps=i(G);Xl=a(ps,"SPAN",{});var cs=i(Xl);g(ze.$$.fragment,cs),cs.forEach(t),ps.forEach(t),Ga=u(zo),Sl=a(zo,"SPAN",{});var gs=i(Sl);Ua=s(gs,"BERT"),gs.forEach(t),zo.forEach(t),Xt=u(e),He=a(e,"P",{});var fs=i(He);Ja=s(fs,"Il seguente modello BERT pu\xF2 essere usato per compiti multilingue:"),fs.forEach(t),St=u(e),U=a(e,"UL",{});var ko=i(U);Qe=a(ko,"LI",{});var hn=i(Qe);Bl=a(hn,"CODE",{});var hs=i(Bl);Ka=s(hs,"bert-base-multilingual-uncased"),hs.forEach(t),Va=s(hn," (Modellazione mascherata del linguaggio + Previsione della prossima frase, 102 lingue)"),hn.forEach(t),Ya=u(ko),We=a(ko,"LI",{});var _n=i(We);Rl=a(_n,"CODE",{});var _s=i(Rl);Za=s(_s,"bert-base-multilingual-cased"),_s.forEach(t),ei=s(_n," (Modellazione mascherata del linguaggio + Previsione della prossima frase, 104 lingue)"),_n.forEach(t),ko.forEach(t),Bt=u(e),Ge=a(e,"P",{});var vs=i(Ge);li=s(vs,"Questi modelli non richiedono language embeddings per fare inferenza. Riescono ad identificare il linguaggio dal contesto e inferire di conseguenza."),vs.forEach(t),Rt=u(e),A=a(e,"H2",{class:!0});var Eo=i(A);J=a(Eo,"A",{id:!0,class:!0,href:!0});var bs=i(J);Nl=a(bs,"SPAN",{});var zs=i(Nl);g(ke.$$.fragment,zs),zs.forEach(t),bs.forEach(t),ti=u(Eo),Fl=a(Eo,"SPAN",{});var ks=i(Fl);oi=s(ks,"XLM-RoBERTa"),ks.forEach(t),Eo.forEach(t),Nt=u(e),Ue=a(e,"P",{});var Es=i(Ue);ai=s(Es,"Il seguente modello XLM-RoBERTa pu\xF2 essere usato per compiti multilingue:"),Es.forEach(t),Ft=u(e),K=a(e,"UL",{});var $o=i(K);Je=a($o,"LI",{});var vn=i(Je);Hl=a(vn,"CODE",{});var $s=i(Hl);ii=s($s,"xlm-roberta-base"),$s.forEach(t),ni=s(vn," (Modellazione mascherata del linguaggio, 100 lingue)"),vn.forEach(t),si=u($o),Ke=a($o,"LI",{});var bn=i(Ke);Ql=a(bn,"CODE",{});var Ms=i(Ql);ri=s(Ms,"xlm-roberta-large"),Ms.forEach(t),mi=s(bn," (Modellazione mascherata del linguaggio, 100 lingue)"),bn.forEach(t),$o.forEach(t),Ht=u(e),Ve=a(e,"P",{});var ws=i(Ve);di=s(ws,"XLM-RoBERTa \xE8 stato addestrato su 2.5TB di dati CommonCrawl appena creati e puliti in 100 lingue. Offre notevoli vantaggi rispetto ai modelli multilingue rilasciati in precedenza, come mBERT o XLM, in compiti come la classificazione, l\u2019etichettatura delle sequenze e la risposta alle domande."),ws.forEach(t),Qt=u(e),O=a(e,"H2",{class:!0});var Mo=i(O);V=a(Mo,"A",{id:!0,class:!0,href:!0});var xs=i(V);Wl=a(xs,"SPAN",{});var ys=i(Wl);g(Ee.$$.fragment,ys),ys.forEach(t),xs.forEach(t),ui=u(Mo),Gl=a(Mo,"SPAN",{});var Ls=i(Gl);pi=s(Ls,"M2M100"),Ls.forEach(t),Mo.forEach(t),Wt=u(e),Ye=a(e,"P",{});var js=i(Ye);ci=s(js,"Il seguente modello M2M100 pu\xF2 essere usato per compiti multilingue:"),js.forEach(t),Gt=u(e),Y=a(e,"UL",{});var wo=i(Y);Ze=a(wo,"LI",{});var zn=i(Ze);Ul=a(zn,"CODE",{});var qs=i(Ul);gi=s(qs,"facebook/m2m100_418M"),qs.forEach(t),fi=s(zn," (Traduzione)"),zn.forEach(t),hi=u(wo),el=a(wo,"LI",{});var kn=i(el);Jl=a(kn,"CODE",{});var Is=i(Jl);_i=s(Is,"facebook/m2m100_1.2B"),Is.forEach(t),vi=s(kn," (Traduzione)"),kn.forEach(t),wo.forEach(t),Ut=u(e),Z=a(e,"P",{});var xo=i(Z);bi=s(xo,"In questo esempio, carica il checkpoint "),Kl=a(xo,"CODE",{});var Ps=i(Kl);zi=s(Ps,"facebook/m2m100_418M"),Ps.forEach(t),ki=s(xo,"  per tradurre dal cinese all\u2019inglese. Puoi impostare la lingua di partenza nel tokenizer:"),xo.forEach(t),Jt=u(e),g($e.$$.fragment,e),Kt=u(e),ll=a(e,"P",{});var Ts=i(ll);Ei=s(Ts,"Applica il tokenizer al testo:"),Ts.forEach(t),Vt=u(e),g(Me.$$.fragment,e),Yt=u(e),M=a(e,"P",{});var ie=i(M);$i=s(ie,"M2M100 forza l\u2019id della lingua obiettivo come primo token generato per tradurre nella lingua obiettivo. Imposta il parametro "),Vl=a(ie,"CODE",{});var Cs=i(Vl);Mi=s(Cs,"forced_bos_token_id"),Cs.forEach(t),wi=s(ie," a "),Yl=a(ie,"CODE",{});var Ds=i(Yl);xi=s(Ds,"en"),Ds.forEach(t),yi=s(ie," nel metodo "),Zl=a(ie,"CODE",{});var As=i(Zl);Li=s(As,"generate"),As.forEach(t),ji=s(ie," per tradurre in inglese:"),ie.forEach(t),Zt=u(e),g(we.$$.fragment,e),eo=u(e),X=a(e,"H2",{class:!0});var yo=i(X);ee=a(yo,"A",{id:!0,class:!0,href:!0});var Os=i(ee);et=a(Os,"SPAN",{});var Xs=i(et);g(xe.$$.fragment,Xs),Xs.forEach(t),Os.forEach(t),qi=u(yo),lt=a(yo,"SPAN",{});var Ss=i(lt);Ii=s(Ss,"MBart"),Ss.forEach(t),yo.forEach(t),lo=u(e),tl=a(e,"P",{});var Bs=i(tl);Pi=s(Bs,"Il seguente modello MBart pu\xF2 essere usato per compiti multilingue:"),Bs.forEach(t),to=u(e),z=a(e,"UL",{});var j=i(z);ol=a(j,"LI",{});var En=i(ol);tt=a(En,"CODE",{});var Rs=i(tt);Ti=s(Rs,"facebook/mbart-large-50-one-to-many-mmt"),Rs.forEach(t),Ci=s(En," (Traduzione automatica multilingue uno-a-molti, 50 lingue)"),En.forEach(t),Di=u(j),al=a(j,"LI",{});var $n=i(al);ot=a($n,"CODE",{});var Ns=i(ot);Ai=s(Ns,"facebook/mbart-large-50-many-to-many-mmt"),Ns.forEach(t),Oi=s($n," (Traduzione automatica multilingue molti-a-molti, 50 lingue)"),$n.forEach(t),Xi=u(j),il=a(j,"LI",{});var Mn=i(il);at=a(Mn,"CODE",{});var Fs=i(at);Si=s(Fs,"facebook/mbart-large-50-many-to-one-mmt"),Fs.forEach(t),Bi=s(Mn," (Traduzione automatica multilingue molti-a-uno, 50 lingue)"),Mn.forEach(t),Ri=u(j),nl=a(j,"LI",{});var wn=i(nl);it=a(wn,"CODE",{});var Hs=i(it);Ni=s(Hs,"facebook/mbart-large-50"),Hs.forEach(t),Fi=s(wn," (Traduzione multilingue, 50 lingue)"),wn.forEach(t),Hi=u(j),nt=a(j,"LI",{});var Qs=i(nt);st=a(Qs,"CODE",{});var Ws=i(st);Qi=s(Ws,"facebook/mbart-large-cc25"),Ws.forEach(t),Qs.forEach(t),j.forEach(t),oo=u(e),le=a(e,"P",{});var Lo=i(le);Wi=s(Lo,"In questo esempio, carica il checkpoint "),rt=a(Lo,"CODE",{});var Gs=i(rt);Gi=s(Gs,"facebook/mbart-large-50-many-to-many-mmt"),Gs.forEach(t),Ui=s(Lo," per tradurre dal finlandese all\u2019inglese. Puoi impostare la lingua di partenza nel tokenizer:"),Lo.forEach(t),ao=u(e),g(ye.$$.fragment,e),io=u(e),sl=a(e,"P",{});var Us=i(sl);Ji=s(Us,"Applica il tokenizer sul testo:"),Us.forEach(t),no=u(e),g(Le.$$.fragment,e),so=u(e),w=a(e,"P",{});var ne=i(w);Ki=s(ne,"MBart forza l\u2019id della lingua obiettivo come primo token generato per tradurre nella lingua obiettivo. Imposta il parametro "),mt=a(ne,"CODE",{});var Js=i(mt);Vi=s(Js,"forced_bos_token_id"),Js.forEach(t),Yi=s(ne," a "),dt=a(ne,"CODE",{});var Ks=i(dt);Zi=s(Ks,"en"),Ks.forEach(t),en=s(ne," nel metodo "),ut=a(ne,"CODE",{});var Vs=i(ut);ln=s(Vs,"generate"),Vs.forEach(t),tn=s(ne," per tradurre in inglese:"),ne.forEach(t),ro=u(e),g(je.$$.fragment,e),mo=u(e),te=a(e,"P",{});var jo=i(te);on=s(jo,"Se stai usando il checkpoint "),pt=a(jo,"CODE",{});var Ys=i(pt);an=s(Ys,"facebook/mbart-large-50-many-to-one-mmt"),Ys.forEach(t),nn=s(jo,", non hai bisogno di forzare l\u2019id della lingua obiettivo come primo token generato altrimenti l\u2019uso \xE8 lo stesso."),jo.forEach(t),this.h()},h(){p(q,"name","hf:doc:metadata"),p(q,"content",JSON.stringify(sr)),p(S,"id","modelli-multilingue-per-linferenza"),p(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(S,"href","#modelli-multilingue-per-linferenza"),p(I,"class","relative group"),p(de,"href","https://huggingface.co/bert-base-multilingual-uncased"),p(de,"rel","nofollow"),p(B,"id","xlm"),p(B,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(B,"href","#xlm"),p(P,"class","relative group"),p(R,"id","xlm-con-language-embeddings"),p(R,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(R,"href","#xlm-con-language-embeddings"),p(T,"class","relative group"),p(ve,"href","https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-generation/run_generation.py"),p(ve,"rel","nofollow"),p(Q,"id","xlm-senza-language-embeddings"),p(Q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Q,"href","#xlm-senza-language-embeddings"),p(C,"class","relative group"),p(G,"id","bert"),p(G,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(G,"href","#bert"),p(D,"class","relative group"),p(J,"id","xlmroberta"),p(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(J,"href","#xlmroberta"),p(A,"class","relative group"),p(V,"id","m2m100"),p(V,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(V,"href","#m2m100"),p(O,"class","relative group"),p(ee,"id","mbart"),p(ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(ee,"href","#mbart"),p(X,"class","relative group")},m(e,r){l(document.head,q),m(e,ct,r),m(e,I,r),l(I,S),l(S,dl),f(re,dl,null),l(I,qo),l(I,ul),l(ul,Io),m(e,gt,r),f(me,e,r),m(e,ft,r),m(e,y,r),l(y,Po),l(y,pl),l(pl,To),l(y,Co),l(y,de),l(de,Do),l(y,Ao),m(e,ht,r),m(e,P,r),l(P,B),l(B,cl),f(ue,cl,null),l(P,Oo),l(P,gl),l(gl,Xo),m(e,_t,r),m(e,qe,r),l(qe,So),m(e,vt,r),m(e,T,r),l(T,R),l(R,fl),f(pe,fl,null),l(T,Bo),l(T,hl),l(hl,Ro),m(e,bt,r),m(e,Ie,r),l(Ie,No),m(e,zt,r),m(e,b,r),l(b,Pe),l(Pe,_l),l(_l,Fo),l(Pe,Ho),l(b,Qo),l(b,Te),l(Te,vl),l(vl,Wo),l(Te,Go),l(b,Uo),l(b,Ce),l(Ce,bl),l(bl,Jo),l(Ce,Ko),l(b,Vo),l(b,De),l(De,zl),l(zl,Yo),l(De,Zo),l(b,ea),l(b,Ae),l(Ae,kl),l(kl,la),l(Ae,ta),l(b,oa),l(b,Oe),l(Oe,El),l(El,aa),l(Oe,ia),l(b,na),l(b,Xe),l(Xe,$l),l($l,sa),l(Xe,ra),m(e,kt,r),m(e,E,r),l(E,ma),l(E,Ml),l(Ml,da),l(E,ua),l(E,wl),l(wl,pa),l(E,ca),l(E,xl),l(xl,ga),l(E,fa),m(e,Et,r),m(e,N,r),l(N,ha),l(N,yl),l(yl,_a),l(N,va),m(e,$t,r),f(ce,e,r),m(e,Mt,r),m(e,F,r),l(F,ba),l(F,Ll),l(Ll,za),l(F,ka),m(e,wt,r),f(ge,e,r),m(e,xt,r),m(e,Se,r),l(Se,Ea),m(e,yt,r),f(fe,e,r),m(e,Lt,r),m(e,$,r),l($,$a),l($,jl),l(jl,Ma),l($,wa),l($,ql),l(ql,xa),l($,ya),l($,Il),l(Il,La),l($,ja),m(e,jt,r),f(he,e,r),m(e,qt,r),m(e,H,r),l(H,qa),l(H,Pl),l(Pl,Ia),l(H,Pa),m(e,It,r),f(_e,e,r),m(e,Pt,r),m(e,L,r),l(L,Ta),l(L,ve),l(ve,Ca),l(L,Da),l(L,Tl),l(Tl,Aa),l(L,Oa),m(e,Tt,r),m(e,C,r),l(C,Q),l(Q,Cl),f(be,Cl,null),l(C,Xa),l(C,Dl),l(Dl,Sa),m(e,Ct,r),m(e,Be,r),l(Be,Ba),m(e,Dt,r),m(e,W,r),l(W,Re),l(Re,Al),l(Al,Ra),l(Re,Na),l(W,Fa),l(W,Ne),l(Ne,Ol),l(Ol,Ha),l(Ne,Qa),m(e,At,r),m(e,Fe,r),l(Fe,Wa),m(e,Ot,r),m(e,D,r),l(D,G),l(G,Xl),f(ze,Xl,null),l(D,Ga),l(D,Sl),l(Sl,Ua),m(e,Xt,r),m(e,He,r),l(He,Ja),m(e,St,r),m(e,U,r),l(U,Qe),l(Qe,Bl),l(Bl,Ka),l(Qe,Va),l(U,Ya),l(U,We),l(We,Rl),l(Rl,Za),l(We,ei),m(e,Bt,r),m(e,Ge,r),l(Ge,li),m(e,Rt,r),m(e,A,r),l(A,J),l(J,Nl),f(ke,Nl,null),l(A,ti),l(A,Fl),l(Fl,oi),m(e,Nt,r),m(e,Ue,r),l(Ue,ai),m(e,Ft,r),m(e,K,r),l(K,Je),l(Je,Hl),l(Hl,ii),l(Je,ni),l(K,si),l(K,Ke),l(Ke,Ql),l(Ql,ri),l(Ke,mi),m(e,Ht,r),m(e,Ve,r),l(Ve,di),m(e,Qt,r),m(e,O,r),l(O,V),l(V,Wl),f(Ee,Wl,null),l(O,ui),l(O,Gl),l(Gl,pi),m(e,Wt,r),m(e,Ye,r),l(Ye,ci),m(e,Gt,r),m(e,Y,r),l(Y,Ze),l(Ze,Ul),l(Ul,gi),l(Ze,fi),l(Y,hi),l(Y,el),l(el,Jl),l(Jl,_i),l(el,vi),m(e,Ut,r),m(e,Z,r),l(Z,bi),l(Z,Kl),l(Kl,zi),l(Z,ki),m(e,Jt,r),f($e,e,r),m(e,Kt,r),m(e,ll,r),l(ll,Ei),m(e,Vt,r),f(Me,e,r),m(e,Yt,r),m(e,M,r),l(M,$i),l(M,Vl),l(Vl,Mi),l(M,wi),l(M,Yl),l(Yl,xi),l(M,yi),l(M,Zl),l(Zl,Li),l(M,ji),m(e,Zt,r),f(we,e,r),m(e,eo,r),m(e,X,r),l(X,ee),l(ee,et),f(xe,et,null),l(X,qi),l(X,lt),l(lt,Ii),m(e,lo,r),m(e,tl,r),l(tl,Pi),m(e,to,r),m(e,z,r),l(z,ol),l(ol,tt),l(tt,Ti),l(ol,Ci),l(z,Di),l(z,al),l(al,ot),l(ot,Ai),l(al,Oi),l(z,Xi),l(z,il),l(il,at),l(at,Si),l(il,Bi),l(z,Ri),l(z,nl),l(nl,it),l(it,Ni),l(nl,Fi),l(z,Hi),l(z,nt),l(nt,st),l(st,Qi),m(e,oo,r),m(e,le,r),l(le,Wi),l(le,rt),l(rt,Gi),l(le,Ui),m(e,ao,r),f(ye,e,r),m(e,io,r),m(e,sl,r),l(sl,Ji),m(e,no,r),f(Le,e,r),m(e,so,r),m(e,w,r),l(w,Ki),l(w,mt),l(mt,Vi),l(w,Yi),l(w,dt),l(dt,Zi),l(w,en),l(w,ut),l(ut,ln),l(w,tn),m(e,ro,r),f(je,e,r),m(e,mo,r),m(e,te,r),l(te,on),l(te,pt),l(pt,an),l(te,nn),uo=!0},p:or,i(e){uo||(h(re.$$.fragment,e),h(me.$$.fragment,e),h(ue.$$.fragment,e),h(pe.$$.fragment,e),h(ce.$$.fragment,e),h(ge.$$.fragment,e),h(fe.$$.fragment,e),h(he.$$.fragment,e),h(_e.$$.fragment,e),h(be.$$.fragment,e),h(ze.$$.fragment,e),h(ke.$$.fragment,e),h(Ee.$$.fragment,e),h($e.$$.fragment,e),h(Me.$$.fragment,e),h(we.$$.fragment,e),h(xe.$$.fragment,e),h(ye.$$.fragment,e),h(Le.$$.fragment,e),h(je.$$.fragment,e),uo=!0)},o(e){_(re.$$.fragment,e),_(me.$$.fragment,e),_(ue.$$.fragment,e),_(pe.$$.fragment,e),_(ce.$$.fragment,e),_(ge.$$.fragment,e),_(fe.$$.fragment,e),_(he.$$.fragment,e),_(_e.$$.fragment,e),_(be.$$.fragment,e),_(ze.$$.fragment,e),_(ke.$$.fragment,e),_(Ee.$$.fragment,e),_($e.$$.fragment,e),_(Me.$$.fragment,e),_(we.$$.fragment,e),_(xe.$$.fragment,e),_(ye.$$.fragment,e),_(Le.$$.fragment,e),_(je.$$.fragment,e),uo=!1},d(e){t(q),e&&t(ct),e&&t(I),v(re),e&&t(gt),v(me,e),e&&t(ft),e&&t(y),e&&t(ht),e&&t(P),v(ue),e&&t(_t),e&&t(qe),e&&t(vt),e&&t(T),v(pe),e&&t(bt),e&&t(Ie),e&&t(zt),e&&t(b),e&&t(kt),e&&t(E),e&&t(Et),e&&t(N),e&&t($t),v(ce,e),e&&t(Mt),e&&t(F),e&&t(wt),v(ge,e),e&&t(xt),e&&t(Se),e&&t(yt),v(fe,e),e&&t(Lt),e&&t($),e&&t(jt),v(he,e),e&&t(qt),e&&t(H),e&&t(It),v(_e,e),e&&t(Pt),e&&t(L),e&&t(Tt),e&&t(C),v(be),e&&t(Ct),e&&t(Be),e&&t(Dt),e&&t(W),e&&t(At),e&&t(Fe),e&&t(Ot),e&&t(D),v(ze),e&&t(Xt),e&&t(He),e&&t(St),e&&t(U),e&&t(Bt),e&&t(Ge),e&&t(Rt),e&&t(A),v(ke),e&&t(Nt),e&&t(Ue),e&&t(Ft),e&&t(K),e&&t(Ht),e&&t(Ve),e&&t(Qt),e&&t(O),v(Ee),e&&t(Wt),e&&t(Ye),e&&t(Gt),e&&t(Y),e&&t(Ut),e&&t(Z),e&&t(Jt),v($e,e),e&&t(Kt),e&&t(ll),e&&t(Vt),v(Me,e),e&&t(Yt),e&&t(M),e&&t(Zt),v(we,e),e&&t(eo),e&&t(X),v(xe),e&&t(lo),e&&t(tl),e&&t(to),e&&t(z),e&&t(oo),e&&t(le),e&&t(ao),v(ye,e),e&&t(io),e&&t(sl),e&&t(no),v(Le,e),e&&t(so),e&&t(w),e&&t(ro),v(je,e),e&&t(mo),e&&t(te)}}}const sr={local:"modelli-multilingue-per-linferenza",sections:[{local:"xlm",sections:[{local:"xlm-con-language-embeddings",title:"XLM con language embeddings"},{local:"xlm-senza-language-embeddings",title:"XLM senza language embeddings"}],title:"XLM"},{local:"bert",title:"BERT"},{local:"xlmroberta",title:"XLM-RoBERTa"},{local:"m2m100",title:"M2M100"},{local:"mbart",title:"MBart"}],title:"Modelli multilingue per l'inferenza"};function rr(xn){return ar(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class cr extends Zs{constructor(q){super();er(this,q,rr,nr,lr,{})}}export{cr as default,sr as metadata};
