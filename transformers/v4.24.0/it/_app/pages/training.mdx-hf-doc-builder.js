import{S as ns,i as ps,s as cs,e as o,k as m,w as b,t as p,M as ds,c as l,d as e,m as f,a as i,x as w,h as c,b as u,G as t,g as n,y as j,q as k,o as E,B as z,v as ms}from"../chunks/vendor-hf-doc-builder.js";import{T as qa}from"../chunks/Tip-hf-doc-builder.js";import{Y as Aa}from"../chunks/Youtube-hf-doc-builder.js";import{I as Nt}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as K}from"../chunks/CodeBlock-hf-doc-builder.js";import{D as fs}from"../chunks/DocNotebookDropdown-hf-doc-builder.js";import{F as is,M as Ca}from"../chunks/Markdown-hf-doc-builder.js";import"../chunks/IconTensorflow-hf-doc-builder.js";function us(Le){let g,P;return{c(){g=o("p"),P=p("Potresti vedere un warning dato che alcuni dei pesi pre-addestrati non sono stati utilizzati e altri pesi sono stati inizializzati casualmente. Non preoccuparti, \xE8 completamente normale! L\u2019head pre-addestrata del modello BERT viene scartata e rimpiazzata da una classification head inizializzata casualmente. Farai il fine-tuning di questa nuova head del modello sul tuo compito di classificazione, trasferendogli la conoscenza del modello pre-addestrato.")},l(h){g=l(h,"P",{});var y=i(g);P=c(y,"Potresti vedere un warning dato che alcuni dei pesi pre-addestrati non sono stati utilizzati e altri pesi sono stati inizializzati casualmente. Non preoccuparti, \xE8 completamente normale! L\u2019head pre-addestrata del modello BERT viene scartata e rimpiazzata da una classification head inizializzata casualmente. Farai il fine-tuning di questa nuova head del modello sul tuo compito di classificazione, trasferendogli la conoscenza del modello pre-addestrato."),y.forEach(e)},m(h,y){n(h,g,y),t(g,P)},d(h){h&&e(g)}}}function hs(Le){let g,P,h,y,A,I,Q,q,S,O,x,J,X,Me,He,L,xe,ue,Z,te,he,ye,ae,Xe,le,Ze,W,it,F,N,V,G,nt,Re,ie,pt,At,Pe,ge,bt,Fe,M,Ve,C,H,ne,pe,Be,Te,_e,et,D,Ae,qe,R,ce,$e,Ie,B,ve,tt,wt,se,de,Ue,d,T,Y,re,Ce,be,U,ct,Oe,we,ee,je,We,Ge,oe,De,jt,Ne,me,Ye,fe,dt,at,Wt,qt,mt,ke,Ee,Ke,ze,Lt,ft,Gt,st,Ct,ut,ht,rt,Dt,Ft,kt,Et,zt,gt,Qe,_t,yt,Yt,$t,ot,s,_;return g=new Aa({props:{id:"nvBXf7s7vTI"}}),ue=new K({props:{code:`from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=5)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, num_labels=<span class="hljs-number">5</span>)`}}),te=new qa({props:{$$slots:{default:[us]},$$scope:{ctx:Le}}}),le=new Nt({}),M=new K({props:{code:`from transformers import TrainingArguments

training_args = TrainingArguments(output_dir="test_trainer")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments

<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(output_dir=<span class="hljs-string">&quot;test_trainer&quot;</span>)`}}),pe=new Nt({}),Ce=new K({props:{code:`import numpy as np
from datasets import load_metric

metric = load_metric("accuracy")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_metric

<span class="hljs-meta">&gt;&gt;&gt; </span>metric = load_metric(<span class="hljs-string">&quot;accuracy&quot;</span>)`}}),me=new K({props:{code:`def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_pred</span>):
<span class="hljs-meta">... </span>    logits, labels = eval_pred
<span class="hljs-meta">... </span>    predictions = np.argmax(logits, axis=-<span class="hljs-number">1</span>)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> metric.compute(predictions=predictions, references=labels)`}}),ke=new K({props:{code:`from transformers import TrainingArguments, Trainer

training_args = TrainingArguments(output_dir="test_trainer", evaluation_strategy="epoch")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments, Trainer

<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(output_dir=<span class="hljs-string">&quot;test_trainer&quot;</span>, evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>)`}}),ft=new Nt({}),zt=new K({props:{code:`trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=small_train_dataset,
    eval_dataset=small_eval_dataset,
    compute_metrics=compute_metrics,
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>trainer = Trainer(
<span class="hljs-meta">... </span>    model=model,
<span class="hljs-meta">... </span>    args=training_args,
<span class="hljs-meta">... </span>    train_dataset=small_train_dataset,
<span class="hljs-meta">... </span>    eval_dataset=small_eval_dataset,
<span class="hljs-meta">... </span>    compute_metrics=compute_metrics,
<span class="hljs-meta">... </span>)`}}),s=new K({props:{code:"trainer.train()",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.train()'}}),{c(){b(g.$$.fragment),P=m(),h=o("p"),y=p("\u{1F917} Transformers mette a disposizione la classe "),A=o("code"),I=p("Trainer"),Q=p(" ottimizzata per addestrare modelli \u{1F917} Transformers, rendendo semplice iniziare l\u2019addestramento senza scrivere manualmente il tuo ciclo di addestramento. L\u2019API "),q=o("code"),S=p("Trainer"),O=p(" supporta un\u2019ampia gamma di opzioni e funzionalit\xE0 di addestramento come logging, gradient accumulation e mixed precision."),x=m(),J=o("p"),X=p("Inizia caricando il tuo modello e specificando il numero di etichette (labels) attese. Nel dataset Yelp Review "),Me=o("a"),He=p("dataset card"),L=p(", sai che ci sono cinque etichette:"),xe=m(),b(ue.$$.fragment),Z=m(),b(te.$$.fragment),he=m(),ye=o("h3"),ae=o("a"),Xe=o("span"),b(le.$$.fragment),Ze=m(),W=o("span"),it=p("Iperparametri per il training"),F=m(),N=o("p"),V=p("Successivamente, crea una classe "),G=o("code"),nt=p("TrainingArguments"),Re=p(" contenente tutti gli iperparametri che si possono regore nonch\xE9 le variabili per attivare le differenti opzioni di addestramento. Per questa esercitazione puoi iniziare con gli "),ie=o("a"),pt=p("iperparametri"),At=p(" di ddestramento predefiniti, ma sentiti libero di sperimentare per trovare la configurazione ottimale per te."),Pe=m(),ge=o("p"),bt=p("Specifica dove salvare i checkpoints del tuo addestramento:"),Fe=m(),b(M.$$.fragment),Ve=m(),C=o("h3"),H=o("a"),ne=o("span"),b(pe.$$.fragment),Be=m(),Te=o("span"),_e=p("Metriche"),et=m(),D=o("p"),Ae=o("code"),qe=p("Trainer"),R=p(" non valuta automaticamente le performance del modello durante l\u2019addestramento. Dovrai passare a "),ce=o("code"),$e=p("Trainer"),Ie=p(" una funzione che calcola e restituisce le metriche. La libreria \u{1F917} Datasets mette a disposizione una semplice funzione "),B=o("a"),ve=o("code"),tt=p("accuracy"),wt=p(" che puoi caricare con la funzione "),se=o("code"),de=p("load_metric"),Ue=p(" (guarda questa "),d=o("a"),T=p("esercitazione"),Y=p(" per maggiori informazioni):"),re=m(),b(Ce.$$.fragment),be=m(),U=o("p"),ct=p("Richiama "),Oe=o("code"),we=p("compute"),ee=p(" su "),je=o("code"),We=p("metric"),Ge=p(" per calcolare l\u2019accuratezza delle tue previsioni. Prima di passare le tue previsioni a "),oe=o("code"),De=p("compute"),jt=p(", hai bisogno di convertirle in logits (ricorda che tutti i modelli \u{1F917} Transformers restituiscono logits):"),Ne=m(),b(me.$$.fragment),Ye=m(),fe=o("p"),dt=p("Se preferisci monitorare le tue metriche di valutazione durante il fine-tuning, specifica il parametro "),at=o("code"),Wt=p("evaluation_strategy"),qt=p(" nei tuoi training arguments per restituire le metriche di valutazione ad ogni epoca di addestramento:"),mt=m(),b(ke.$$.fragment),Ee=m(),Ke=o("h3"),ze=o("a"),Lt=o("span"),b(ft.$$.fragment),Gt=m(),st=o("span"),Ct=p("Trainer"),ut=m(),ht=o("p"),rt=p("Crea un oggetto "),Dt=o("code"),Ft=p("Trainer"),kt=p(" col tuo modello, training arguments, dataset di training e test, e funzione di valutazione:"),Et=m(),b(zt.$$.fragment),gt=m(),Qe=o("p"),_t=p("Poi metti a punto il modello richiamando "),yt=o("code"),Yt=p("train()"),$t=p(":"),ot=m(),b(s.$$.fragment),this.h()},l(r){w(g.$$.fragment,r),P=f(r),h=l(r,"P",{});var v=i(h);y=c(v,"\u{1F917} Transformers mette a disposizione la classe "),A=l(v,"CODE",{});var Kt=i(A);I=c(Kt,"Trainer"),Kt.forEach(e),Q=c(v," ottimizzata per addestrare modelli \u{1F917} Transformers, rendendo semplice iniziare l\u2019addestramento senza scrivere manualmente il tuo ciclo di addestramento. L\u2019API "),q=l(v,"CODE",{});var ta=i(q);S=c(ta,"Trainer"),ta.forEach(e),O=c(v," supporta un\u2019ampia gamma di opzioni e funzionalit\xE0 di addestramento come logging, gradient accumulation e mixed precision."),v.forEach(e),x=f(r),J=l(r,"P",{});var Pt=i(J);X=c(Pt,"Inizia caricando il tuo modello e specificando il numero di etichette (labels) attese. Nel dataset Yelp Review "),Me=l(Pt,"A",{href:!0,rel:!0});var Mt=i(Me);He=c(Mt,"dataset card"),Mt.forEach(e),L=c(Pt,", sai che ci sono cinque etichette:"),Pt.forEach(e),xe=f(r),w(ue.$$.fragment,r),Z=f(r),w(te.$$.fragment,r),he=f(r),ye=l(r,"H3",{class:!0});var vt=i(ye);ae=l(vt,"A",{id:!0,class:!0,href:!0});var ia=i(ae);Xe=l(ia,"SPAN",{});var na=i(Xe);w(le.$$.fragment,na),na.forEach(e),ia.forEach(e),Ze=f(vt),W=l(vt,"SPAN",{});var aa=i(W);it=c(aa,"Iperparametri per il training"),aa.forEach(e),vt.forEach(e),F=f(r),N=l(r,"P",{});var Je=i(N);V=c(Je,"Successivamente, crea una classe "),G=l(Je,"CODE",{});var sa=i(G);nt=c(sa,"TrainingArguments"),sa.forEach(e),Re=c(Je," contenente tutti gli iperparametri che si possono regore nonch\xE9 le variabili per attivare le differenti opzioni di addestramento. Per questa esercitazione puoi iniziare con gli "),ie=l(Je,"A",{href:!0,rel:!0});var St=i(ie);pt=c(St,"iperparametri"),St.forEach(e),At=c(Je," di ddestramento predefiniti, ma sentiti libero di sperimentare per trovare la configurazione ottimale per te."),Je.forEach(e),Pe=f(r),ge=l(r,"P",{});var It=i(ge);bt=c(It,"Specifica dove salvare i checkpoints del tuo addestramento:"),It.forEach(e),Fe=f(r),w(M.$$.fragment,r),Ve=f(r),C=l(r,"H3",{class:!0});var Ht=i(C);H=l(Ht,"A",{id:!0,class:!0,href:!0});var xt=i(H);ne=l(xt,"SPAN",{});var pa=i(ne);w(pe.$$.fragment,pa),pa.forEach(e),xt.forEach(e),Be=f(Ht),Te=l(Ht,"SPAN",{});var Rt=i(Te);_e=c(Rt,"Metriche"),Rt.forEach(e),Ht.forEach(e),et=f(r),D=l(r,"P",{});var lt=i(D);Ae=l(lt,"CODE",{});var ra=i(Ae);qe=c(ra,"Trainer"),ra.forEach(e),R=c(lt," non valuta automaticamente le performance del modello durante l\u2019addestramento. Dovrai passare a "),ce=l(lt,"CODE",{});var Tt=i(ce);$e=c(Tt,"Trainer"),Tt.forEach(e),Ie=c(lt," una funzione che calcola e restituisce le metriche. La libreria \u{1F917} Datasets mette a disposizione una semplice funzione "),B=l(lt,"A",{href:!0,rel:!0});var Xt=i(B);ve=l(Xt,"CODE",{});var Zt=i(ve);tt=c(Zt,"accuracy"),Zt.forEach(e),Xt.forEach(e),wt=c(lt," che puoi caricare con la funzione "),se=l(lt,"CODE",{});var ca=i(se);de=c(ca,"load_metric"),ca.forEach(e),Ue=c(lt," (guarda questa "),d=l(lt,"A",{href:!0,rel:!0});var da=i(d);T=c(da,"esercitazione"),da.forEach(e),Y=c(lt," per maggiori informazioni):"),lt.forEach(e),re=f(r),w(Ce.$$.fragment,r),be=f(r),U=l(r,"P",{});var Se=i(U);ct=c(Se,"Richiama "),Oe=l(Se,"CODE",{});var Vt=i(Oe);we=c(Vt,"compute"),Vt.forEach(e),ee=c(Se," su "),je=l(Se,"CODE",{});var ma=i(je);We=c(ma,"metric"),ma.forEach(e),Ge=c(Se," per calcolare l\u2019accuratezza delle tue previsioni. Prima di passare le tue previsioni a "),oe=l(Se,"CODE",{});var fa=i(oe);De=c(fa,"compute"),fa.forEach(e),jt=c(Se,", hai bisogno di convertirle in logits (ricorda che tutti i modelli \u{1F917} Transformers restituiscono logits):"),Se.forEach(e),Ne=f(r),w(me.$$.fragment,r),Ye=f(r),fe=l(r,"P",{});var Ot=i(fe);dt=c(Ot,"Se preferisci monitorare le tue metriche di valutazione durante il fine-tuning, specifica il parametro "),at=l(Ot,"CODE",{});var Bt=i(at);Wt=c(Bt,"evaluation_strategy"),Bt.forEach(e),qt=c(Ot," nei tuoi training arguments per restituire le metriche di valutazione ad ogni epoca di addestramento:"),Ot.forEach(e),mt=f(r),w(ke.$$.fragment,r),Ee=f(r),Ke=l(r,"H3",{class:!0});var Qt=i(Ke);ze=l(Qt,"A",{id:!0,class:!0,href:!0});var a=i(ze);Lt=l(a,"SPAN",{});var $=i(Lt);w(ft.$$.fragment,$),$.forEach(e),a.forEach(e),Gt=f(Qt),st=l(Qt,"SPAN",{});var Ut=i(st);Ct=c(Ut,"Trainer"),Ut.forEach(e),Qt.forEach(e),ut=f(r),ht=l(r,"P",{});var oa=i(ht);rt=c(oa,"Crea un oggetto "),Dt=l(oa,"CODE",{});var ea=i(Dt);Ft=c(ea,"Trainer"),ea.forEach(e),kt=c(oa," col tuo modello, training arguments, dataset di training e test, e funzione di valutazione:"),oa.forEach(e),Et=f(r),w(zt.$$.fragment,r),gt=f(r),Qe=l(r,"P",{});var la=i(Qe);_t=c(la,"Poi metti a punto il modello richiamando "),yt=l(la,"CODE",{});var Jt=i(yt);Yt=c(Jt,"train()"),Jt.forEach(e),$t=c(la,":"),la.forEach(e),ot=f(r),w(s.$$.fragment,r),this.h()},h(){u(Me,"href","https://huggingface.co/datasets/yelp_review_full#data-fields"),u(Me,"rel","nofollow"),u(ae,"id","iperparametri-per-il-training"),u(ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ae,"href","#iperparametri-per-il-training"),u(ye,"class","relative group"),u(ie,"href","https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments"),u(ie,"rel","nofollow"),u(H,"id","metriche"),u(H,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(H,"href","#metriche"),u(C,"class","relative group"),u(B,"href","https://huggingface.co/metrics/accuracy"),u(B,"rel","nofollow"),u(d,"href","https://huggingface.co/docs/datasets/metrics.html"),u(d,"rel","nofollow"),u(ze,"id","trainer"),u(ze,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ze,"href","#trainer"),u(Ke,"class","relative group")},m(r,v){j(g,r,v),n(r,P,v),n(r,h,v),t(h,y),t(h,A),t(A,I),t(h,Q),t(h,q),t(q,S),t(h,O),n(r,x,v),n(r,J,v),t(J,X),t(J,Me),t(Me,He),t(J,L),n(r,xe,v),j(ue,r,v),n(r,Z,v),j(te,r,v),n(r,he,v),n(r,ye,v),t(ye,ae),t(ae,Xe),j(le,Xe,null),t(ye,Ze),t(ye,W),t(W,it),n(r,F,v),n(r,N,v),t(N,V),t(N,G),t(G,nt),t(N,Re),t(N,ie),t(ie,pt),t(N,At),n(r,Pe,v),n(r,ge,v),t(ge,bt),n(r,Fe,v),j(M,r,v),n(r,Ve,v),n(r,C,v),t(C,H),t(H,ne),j(pe,ne,null),t(C,Be),t(C,Te),t(Te,_e),n(r,et,v),n(r,D,v),t(D,Ae),t(Ae,qe),t(D,R),t(D,ce),t(ce,$e),t(D,Ie),t(D,B),t(B,ve),t(ve,tt),t(D,wt),t(D,se),t(se,de),t(D,Ue),t(D,d),t(d,T),t(D,Y),n(r,re,v),j(Ce,r,v),n(r,be,v),n(r,U,v),t(U,ct),t(U,Oe),t(Oe,we),t(U,ee),t(U,je),t(je,We),t(U,Ge),t(U,oe),t(oe,De),t(U,jt),n(r,Ne,v),j(me,r,v),n(r,Ye,v),n(r,fe,v),t(fe,dt),t(fe,at),t(at,Wt),t(fe,qt),n(r,mt,v),j(ke,r,v),n(r,Ee,v),n(r,Ke,v),t(Ke,ze),t(ze,Lt),j(ft,Lt,null),t(Ke,Gt),t(Ke,st),t(st,Ct),n(r,ut,v),n(r,ht,v),t(ht,rt),t(ht,Dt),t(Dt,Ft),t(ht,kt),n(r,Et,v),j(zt,r,v),n(r,gt,v),n(r,Qe,v),t(Qe,_t),t(Qe,yt),t(yt,Yt),t(Qe,$t),n(r,ot,v),j(s,r,v),_=!0},p(r,v){const Kt={};v&2&&(Kt.$$scope={dirty:v,ctx:r}),te.$set(Kt)},i(r){_||(k(g.$$.fragment,r),k(ue.$$.fragment,r),k(te.$$.fragment,r),k(le.$$.fragment,r),k(M.$$.fragment,r),k(pe.$$.fragment,r),k(Ce.$$.fragment,r),k(me.$$.fragment,r),k(ke.$$.fragment,r),k(ft.$$.fragment,r),k(zt.$$.fragment,r),k(s.$$.fragment,r),_=!0)},o(r){E(g.$$.fragment,r),E(ue.$$.fragment,r),E(te.$$.fragment,r),E(le.$$.fragment,r),E(M.$$.fragment,r),E(pe.$$.fragment,r),E(Ce.$$.fragment,r),E(me.$$.fragment,r),E(ke.$$.fragment,r),E(ft.$$.fragment,r),E(zt.$$.fragment,r),E(s.$$.fragment,r),_=!1},d(r){z(g,r),r&&e(P),r&&e(h),r&&e(x),r&&e(J),r&&e(xe),z(ue,r),r&&e(Z),z(te,r),r&&e(he),r&&e(ye),z(le),r&&e(F),r&&e(N),r&&e(Pe),r&&e(ge),r&&e(Fe),z(M,r),r&&e(Ve),r&&e(C),z(pe),r&&e(et),r&&e(D),r&&e(re),z(Ce,r),r&&e(be),r&&e(U),r&&e(Ne),z(me,r),r&&e(Ye),r&&e(fe),r&&e(mt),z(ke,r),r&&e(Ee),r&&e(Ke),z(ft),r&&e(ut),r&&e(ht),r&&e(Et),z(zt,r),r&&e(gt),r&&e(Qe),r&&e(ot),z(s,r)}}}function gs(Le){let g,P;return g=new Ca({props:{$$slots:{default:[hs]},$$scope:{ctx:Le}}}),{c(){b(g.$$.fragment)},l(h){w(g.$$.fragment,h)},m(h,y){j(g,h,y),P=!0},p(h,y){const A={};y&2&&(A.$$scope={dirty:y,ctx:h}),g.$set(A)},i(h){P||(k(g.$$.fragment,h),P=!0)},o(h){E(g.$$.fragment,h),P=!1},d(h){z(g,h)}}}function _s(Le){let g,P,h,y,A,I,Q;return{c(){g=o("p"),P=o("code"),h=p("Trainer"),y=p(" usa "),A=o("code"),I=p("DataCollatorWithPadding"),Q=p(" in maniera predefinita in modo da non dover specificare esplicitamente un collettore di dati.")},l(q){g=l(q,"P",{});var S=i(g);P=l(S,"CODE",{});var O=i(P);h=c(O,"Trainer"),O.forEach(e),y=c(S," usa "),A=l(S,"CODE",{});var x=i(A);I=c(x,"DataCollatorWithPadding"),x.forEach(e),Q=c(S," in maniera predefinita in modo da non dover specificare esplicitamente un collettore di dati."),S.forEach(e)},m(q,S){n(q,g,S),t(g,P),t(P,h),t(g,y),t(g,A),t(A,I),t(g,Q)},d(q){q&&e(g)}}}function $s(Le){let g,P,h,y,A,I,Q,q,S,O,x,J,X,Me,He,L,xe,ue,Z,te,he,ye,ae,Xe,le,Ze,W,it,F,N,V,G,nt,Re,ie,pt,At,Pe,ge,bt,Fe,M,Ve,C,H,ne,pe,Be,Te,_e,et,D,Ae,qe,R,ce,$e,Ie,B,ve,tt,wt,se,de,Ue;return h=new Aa({props:{id:"rnTGBy2ax1c"}}),x=new Nt({}),le=new K({props:{code:`from transformers import DefaultDataCollator

data_collator = DefaultDataCollator(return_tensors="tf")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DefaultDataCollator

<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DefaultDataCollator(return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`}}),W=new qa({props:{$$slots:{default:[_s]},$$scope:{ctx:Le}}}),M=new K({props:{code:`tf_train_dataset = small_train_dataset.to_tf_dataset(
    columns=["attention_mask", "input_ids", "token_type_ids"],
    label_cols=["labels"],
    shuffle=True,
    collate_fn=data_collator,
    batch_size=8,
)

tf_validation_dataset = small_eval_dataset.to_tf_dataset(
    columns=["attention_mask", "input_ids", "token_type_ids"],
    label_cols=["labels"],
    shuffle=False,
    collate_fn=data_collator,
    batch_size=8,
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_train_dataset = small_train_dataset.to_tf_dataset(
<span class="hljs-meta">... </span>    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>],
<span class="hljs-meta">... </span>    label_cols=[<span class="hljs-string">&quot;labels&quot;</span>],
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">8</span>,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_validation_dataset = small_eval_dataset.to_tf_dataset(
<span class="hljs-meta">... </span>    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>],
<span class="hljs-meta">... </span>    label_cols=[<span class="hljs-string">&quot;labels&quot;</span>],
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">False</span>,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">8</span>,
<span class="hljs-meta">... </span>)`}}),pe=new Nt({}),R=new K({props:{code:`import tensorflow as tf
from transformers import TFAutoModelForSequenceClassification

model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=5)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, num_labels=<span class="hljs-number">5</span>)`}}),de=new K({props:{code:`model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=tf.metrics.SparseCategoricalAccuracy(),
)

model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=3)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">compile</span>(
<span class="hljs-meta">... </span>    optimizer=tf.keras.optimizers.Adam(learning_rate=<span class="hljs-number">5e-5</span>),
<span class="hljs-meta">... </span>    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="hljs-literal">True</span>),
<span class="hljs-meta">... </span>    metrics=tf.metrics.SparseCategoricalAccuracy(),
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=<span class="hljs-number">3</span>)`}}),{c(){g=o("a"),P=m(),b(h.$$.fragment),y=m(),A=o("p"),I=p("I modelli \u{1F917} Transformers supportano anche l\u2019addestramento in TensorFlow usando l\u2019API di Keras."),Q=m(),q=o("h3"),S=o("a"),O=o("span"),b(x.$$.fragment),J=m(),X=o("span"),Me=p("Convertire dataset nel formato per TensorFlow"),He=m(),L=o("p"),xe=p("Il "),ue=o("code"),Z=p("DefaultDataCollator"),te=p(" assembla tensori in lotti su cui il modello si addestrer\xE0. Assicurati di specificare di restituire tensori per TensorFlow in "),he=o("code"),ye=p("return_tensors"),ae=p(":"),Xe=m(),b(le.$$.fragment),Ze=m(),b(W.$$.fragment),it=m(),F=o("p"),N=p("Successivamente, converti i datasets tokenizzati in TensorFlow datasets con il metodo "),V=o("a"),G=o("code"),nt=p("to_tf_dataset"),Re=p(". Specifica il tuo input in "),ie=o("code"),pt=p("columns"),At=p(" e le tue etichette in "),Pe=o("code"),ge=p("label_cols"),bt=p(":"),Fe=m(),b(M.$$.fragment),Ve=m(),C=o("h3"),H=o("a"),ne=o("span"),b(pe.$$.fragment),Be=m(),Te=o("span"),_e=p("Compilazione e addestramento"),et=m(),D=o("p"),Ae=p("Carica un modello TensorFlow col numero atteso di etichette:"),qe=m(),b(R.$$.fragment),ce=m(),$e=o("p"),Ie=p("Poi compila e fai il fine-tuning del tuo modello usando "),B=o("a"),ve=o("code"),tt=p("fit"),wt=p(" come faresti con qualsiasi altro modello di Keras:"),se=m(),b(de.$$.fragment),this.h()},l(d){g=l(d,"A",{id:!0}),i(g).forEach(e),P=f(d),w(h.$$.fragment,d),y=f(d),A=l(d,"P",{});var T=i(A);I=c(T,"I modelli \u{1F917} Transformers supportano anche l\u2019addestramento in TensorFlow usando l\u2019API di Keras."),T.forEach(e),Q=f(d),q=l(d,"H3",{class:!0});var Y=i(q);S=l(Y,"A",{id:!0,class:!0,href:!0});var re=i(S);O=l(re,"SPAN",{});var Ce=i(O);w(x.$$.fragment,Ce),Ce.forEach(e),re.forEach(e),J=f(Y),X=l(Y,"SPAN",{});var be=i(X);Me=c(be,"Convertire dataset nel formato per TensorFlow"),be.forEach(e),Y.forEach(e),He=f(d),L=l(d,"P",{});var U=i(L);xe=c(U,"Il "),ue=l(U,"CODE",{});var ct=i(ue);Z=c(ct,"DefaultDataCollator"),ct.forEach(e),te=c(U," assembla tensori in lotti su cui il modello si addestrer\xE0. Assicurati di specificare di restituire tensori per TensorFlow in "),he=l(U,"CODE",{});var Oe=i(he);ye=c(Oe,"return_tensors"),Oe.forEach(e),ae=c(U,":"),U.forEach(e),Xe=f(d),w(le.$$.fragment,d),Ze=f(d),w(W.$$.fragment,d),it=f(d),F=l(d,"P",{});var we=i(F);N=c(we,"Successivamente, converti i datasets tokenizzati in TensorFlow datasets con il metodo "),V=l(we,"A",{href:!0,rel:!0});var ee=i(V);G=l(ee,"CODE",{});var je=i(G);nt=c(je,"to_tf_dataset"),je.forEach(e),ee.forEach(e),Re=c(we,". Specifica il tuo input in "),ie=l(we,"CODE",{});var We=i(ie);pt=c(We,"columns"),We.forEach(e),At=c(we," e le tue etichette in "),Pe=l(we,"CODE",{});var Ge=i(Pe);ge=c(Ge,"label_cols"),Ge.forEach(e),bt=c(we,":"),we.forEach(e),Fe=f(d),w(M.$$.fragment,d),Ve=f(d),C=l(d,"H3",{class:!0});var oe=i(C);H=l(oe,"A",{id:!0,class:!0,href:!0});var De=i(H);ne=l(De,"SPAN",{});var jt=i(ne);w(pe.$$.fragment,jt),jt.forEach(e),De.forEach(e),Be=f(oe),Te=l(oe,"SPAN",{});var Ne=i(Te);_e=c(Ne,"Compilazione e addestramento"),Ne.forEach(e),oe.forEach(e),et=f(d),D=l(d,"P",{});var me=i(D);Ae=c(me,"Carica un modello TensorFlow col numero atteso di etichette:"),me.forEach(e),qe=f(d),w(R.$$.fragment,d),ce=f(d),$e=l(d,"P",{});var Ye=i($e);Ie=c(Ye,"Poi compila e fai il fine-tuning del tuo modello usando "),B=l(Ye,"A",{href:!0,rel:!0});var fe=i(B);ve=l(fe,"CODE",{});var dt=i(ve);tt=c(dt,"fit"),dt.forEach(e),fe.forEach(e),wt=c(Ye," come faresti con qualsiasi altro modello di Keras:"),Ye.forEach(e),se=f(d),w(de.$$.fragment,d),this.h()},h(){u(g,"id","keras"),u(S,"id","convertire-dataset-nel-formato-per-tensorflow"),u(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(S,"href","#convertire-dataset-nel-formato-per-tensorflow"),u(q,"class","relative group"),u(V,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.to_tf_dataset"),u(V,"rel","nofollow"),u(H,"id","compilazione-e-addestramento"),u(H,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(H,"href","#compilazione-e-addestramento"),u(C,"class","relative group"),u(B,"href","https://keras.io/api/models/model_training_apis/"),u(B,"rel","nofollow")},m(d,T){n(d,g,T),n(d,P,T),j(h,d,T),n(d,y,T),n(d,A,T),t(A,I),n(d,Q,T),n(d,q,T),t(q,S),t(S,O),j(x,O,null),t(q,J),t(q,X),t(X,Me),n(d,He,T),n(d,L,T),t(L,xe),t(L,ue),t(ue,Z),t(L,te),t(L,he),t(he,ye),t(L,ae),n(d,Xe,T),j(le,d,T),n(d,Ze,T),j(W,d,T),n(d,it,T),n(d,F,T),t(F,N),t(F,V),t(V,G),t(G,nt),t(F,Re),t(F,ie),t(ie,pt),t(F,At),t(F,Pe),t(Pe,ge),t(F,bt),n(d,Fe,T),j(M,d,T),n(d,Ve,T),n(d,C,T),t(C,H),t(H,ne),j(pe,ne,null),t(C,Be),t(C,Te),t(Te,_e),n(d,et,T),n(d,D,T),t(D,Ae),n(d,qe,T),j(R,d,T),n(d,ce,T),n(d,$e,T),t($e,Ie),t($e,B),t(B,ve),t(ve,tt),t($e,wt),n(d,se,T),j(de,d,T),Ue=!0},p(d,T){const Y={};T&2&&(Y.$$scope={dirty:T,ctx:d}),W.$set(Y)},i(d){Ue||(k(h.$$.fragment,d),k(x.$$.fragment,d),k(le.$$.fragment,d),k(W.$$.fragment,d),k(M.$$.fragment,d),k(pe.$$.fragment,d),k(R.$$.fragment,d),k(de.$$.fragment,d),Ue=!0)},o(d){E(h.$$.fragment,d),E(x.$$.fragment,d),E(le.$$.fragment,d),E(W.$$.fragment,d),E(M.$$.fragment,d),E(pe.$$.fragment,d),E(R.$$.fragment,d),E(de.$$.fragment,d),Ue=!1},d(d){d&&e(g),d&&e(P),z(h,d),d&&e(y),d&&e(A),d&&e(Q),d&&e(q),z(x),d&&e(He),d&&e(L),d&&e(Xe),z(le,d),d&&e(Ze),z(W,d),d&&e(it),d&&e(F),d&&e(Fe),z(M,d),d&&e(Ve),d&&e(C),z(pe),d&&e(et),d&&e(D),d&&e(qe),z(R,d),d&&e(ce),d&&e($e),d&&e(se),z(de,d)}}}function vs(Le){let g,P;return g=new Ca({props:{$$slots:{default:[$s]},$$scope:{ctx:Le}}}),{c(){b(g.$$.fragment)},l(h){w(g.$$.fragment,h)},m(h,y){j(g,h,y),P=!0},p(h,y){const A={};y&2&&(A.$$scope={dirty:y,ctx:h}),g.$set(A)},i(h){P||(k(g.$$.fragment,h),P=!0)},o(h){E(g.$$.fragment,h),P=!1},d(h){z(g,h)}}}function bs(Le){let g,P,h,y,A,I,Q,q;return{c(){g=o("p"),P=p("Ottieni l\u2019accesso gratuito a una GPU sul cloud se non ne possiedi una usando un notebook sul web come "),h=o("a"),y=p("Colaboratory"),A=p(" o "),I=o("a"),Q=p("SageMaker StudioLab"),q=p("."),this.h()},l(S){g=l(S,"P",{});var O=i(g);P=c(O,"Ottieni l\u2019accesso gratuito a una GPU sul cloud se non ne possiedi una usando un notebook sul web come "),h=l(O,"A",{href:!0,rel:!0});var x=i(h);y=c(x,"Colaboratory"),x.forEach(e),A=c(O," o "),I=l(O,"A",{href:!0,rel:!0});var J=i(I);Q=c(J,"SageMaker StudioLab"),J.forEach(e),q=c(O,"."),O.forEach(e),this.h()},h(){u(h,"href","https://colab.research.google.com/"),u(h,"rel","nofollow"),u(I,"href","https://studiolab.sagemaker.aws/"),u(I,"rel","nofollow")},m(S,O){n(S,g,O),t(g,P),t(g,h),t(h,y),t(g,A),t(g,I),t(I,Q),t(g,q)},d(S){S&&e(g)}}}function ws(Le){let g,P,h,y,A,I,Q,q,S,O,x,J,X,Me,He,L,xe,ue,Z,te,he,ye,ae,Xe,le,Ze,W,it,F,N,V,G,nt,Re,ie,pt,At,Pe,ge,bt,Fe,M,Ve,C,H,ne,pe,Be,Te,_e,et,D,Ae,qe,R,ce,$e,Ie,B,ve,tt,wt,se,de,Ue,d,T,Y,re,Ce,be,U,ct,Oe,we,ee,je,We,Ge,oe,De,jt,Ne,me,Ye,fe,dt,at,Wt,qt,mt,ke,Ee,Ke,ze,Lt,ft,Gt,st,Ct,ut,ht,rt,Dt,Ft,kt,Et,zt,gt,Qe,_t,yt,Yt,$t,ot,s,_,r,v,Kt,ta,Pt,Mt,vt,ia,na,aa,Je,sa,St,It,Ht,xt,pa,Rt,lt,ra,Tt,Xt,Zt,ca,da,Se,Vt,ma,fa,Ot,Bt,Qt;return g=new Aa({props:{id:"Dh9CL8fyG80"}}),x=new K({props:{code:`del model
del pytorch_model
del trainer
torch.cuda.empty_cache()`,highlighted:`<span class="hljs-keyword">del</span> model
<span class="hljs-keyword">del</span> pytorch_model
<span class="hljs-keyword">del</span> trainer
torch.cuda.empty_cache()`}}),W=new K({props:{code:'tokenized_datasets = tokenized_datasets.remove_columns(["text"])',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_datasets = tokenized_datasets.remove_columns([<span class="hljs-string">&quot;text&quot;</span>])'}}),M=new K({props:{code:'tokenized_datasets = tokenized_datasets.rename_column("label", "labels")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_datasets = tokenized_datasets.rename_column(<span class="hljs-string">&quot;label&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>)'}}),Be=new K({props:{code:'tokenized_datasets.set_format("torch")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_datasets.set_format(<span class="hljs-string">&quot;torch&quot;</span>)'}}),Ae=new K({props:{code:`small_train_dataset = tokenized_datasets["train"].shuffle(seed=42).select(range(1000))
small_eval_dataset = tokenized_datasets["test"].shuffle(seed=42).select(range(1000))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>small_train_dataset = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>small_eval_dataset = tokenized_datasets[<span class="hljs-string">&quot;test&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))`}}),Ie=new Nt({}),re=new K({props:{code:`from torch.utils.data import DataLoader

train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=8)
eval_dataloader = DataLoader(small_eval_dataset, batch_size=8)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader

<span class="hljs-meta">&gt;&gt;&gt; </span>train_dataloader = DataLoader(small_train_dataset, shuffle=<span class="hljs-literal">True</span>, batch_size=<span class="hljs-number">8</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>eval_dataloader = DataLoader(small_eval_dataset, batch_size=<span class="hljs-number">8</span>)`}}),Oe=new K({props:{code:`from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=5)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, num_labels=<span class="hljs-number">5</span>)`}}),Ge=new Nt({}),mt=new K({props:{code:`from torch.optim import AdamW

optimizer = AdamW(model.parameters(), lr=5e-5)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> AdamW

<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer = AdamW(model.parameters(), lr=<span class="hljs-number">5e-5</span>)`}}),st=new K({props:{code:`from transformers import get_scheduler

num_epochs = 3
num_training_steps = num_epochs * len(train_dataloader)
lr_scheduler = get_scheduler(
    name="linear", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> get_scheduler

<span class="hljs-meta">&gt;&gt;&gt; </span>num_epochs = <span class="hljs-number">3</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>num_training_steps = num_epochs * <span class="hljs-built_in">len</span>(train_dataloader)
<span class="hljs-meta">&gt;&gt;&gt; </span>lr_scheduler = get_scheduler(
<span class="hljs-meta">... </span>    name=<span class="hljs-string">&quot;linear&quot;</span>, optimizer=optimizer, num_warmup_steps=<span class="hljs-number">0</span>, num_training_steps=num_training_steps
<span class="hljs-meta">... </span>)`}}),Et=new K({props:{code:`import torch

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
model.to(device)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span>) <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> torch.device(<span class="hljs-string">&quot;cpu&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.to(device)`}}),gt=new qa({props:{$$slots:{default:[bs]},$$scope:{ctx:Le}}}),_=new Nt({}),Je=new K({props:{code:`from tqdm.auto import tqdm

progress_bar = tqdm(range(num_training_steps))

model.train()
for epoch in range(num_epochs):
    for batch in train_dataloader:
        batch = {k: v.to(device) for k, v in batch.items()}
        outputs = model(**batch)
        loss = outputs.loss
        loss.backward()

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> tqdm.auto <span class="hljs-keyword">import</span> tqdm

<span class="hljs-meta">&gt;&gt;&gt; </span>progress_bar = tqdm(<span class="hljs-built_in">range</span>(num_training_steps))

<span class="hljs-meta">&gt;&gt;&gt; </span>model.train()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_dataloader:
<span class="hljs-meta">... </span>        batch = {k: v.to(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}
<span class="hljs-meta">... </span>        outputs = model(**batch)
<span class="hljs-meta">... </span>        loss = outputs.loss
<span class="hljs-meta">... </span>        loss.backward()

<span class="hljs-meta">... </span>        optimizer.step()
<span class="hljs-meta">... </span>        lr_scheduler.step()
<span class="hljs-meta">... </span>        optimizer.zero_grad()
<span class="hljs-meta">... </span>        progress_bar.update(<span class="hljs-number">1</span>)`}}),xt=new Nt({}),Bt=new K({props:{code:`metric = load_metric("accuracy")
model.eval()
for batch in eval_dataloader:
    batch = {k: v.to(device) for k, v in batch.items()}
    with torch.no_grad():
        outputs = model(**batch)

    logits = outputs.logits
    predictions = torch.argmax(logits, dim=-1)
    metric.add_batch(predictions=predictions, references=batch["labels"])

metric.compute()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>metric = load_metric(<span class="hljs-string">&quot;accuracy&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">eval</span>()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> eval_dataloader:
<span class="hljs-meta">... </span>    batch = {k: v.to(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}
<span class="hljs-meta">... </span>    <span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>        outputs = model(**batch)

<span class="hljs-meta">... </span>    logits = outputs.logits
<span class="hljs-meta">... </span>    predictions = torch.argmax(logits, dim=-<span class="hljs-number">1</span>)
<span class="hljs-meta">... </span>    metric.add_batch(predictions=predictions, references=batch[<span class="hljs-string">&quot;labels&quot;</span>])

<span class="hljs-meta">&gt;&gt;&gt; </span>metric.compute()`}}),{c(){b(g.$$.fragment),P=m(),h=o("p"),y=o("code"),A=p("Trainer"),I=p(" si occupa del ciclo di addestramento e ti consente di mettere a punto un modello con una sola riga di codice. Per chi preferisse scrivere un proprio ciclo di addestramento personale, puoi anche fare il fine-tuning di un modello \u{1F917} Transformers in PyTorch nativo."),Q=m(),q=o("p"),S=p("A questo punto, potresti avere bisogno di riavviare il tuo notebook o eseguire il seguente codice per liberare un po\u2019 di memoria:"),O=m(),b(x.$$.fragment),J=m(),X=o("p"),Me=p("Successivamente, postprocessa manualmente il "),He=o("code"),L=p("tokenized_dataset"),xe=p(" per prepararlo ad essere allenato."),ue=m(),Z=o("ol"),te=o("li"),he=o("p"),ye=p("Rimuovi la colonna "),ae=o("code"),Xe=p("text"),le=p(" perch\xE9 il modello non accetta testo grezzo come input:"),Ze=m(),b(W.$$.fragment),it=m(),F=o("li"),N=o("p"),V=p("Rinomina la colonna "),G=o("code"),nt=p("label"),Re=p(" in "),ie=o("code"),pt=p("labels"),At=p(" perch\xE9 il modello si aspetta che questo argomento si chiami "),Pe=o("code"),ge=p("labels"),bt=p(":"),Fe=m(),b(M.$$.fragment),Ve=m(),C=o("li"),H=o("p"),ne=p("Imposta il formato del dataset per farti restituire tensori di PyTorch all\u2019interno delle liste:"),pe=m(),b(Be.$$.fragment),Te=m(),_e=o("p"),et=p("Poi crea un piccolo sottocampione del dataset come visto precedentemente per velocizzare il fine-tuning:"),D=m(),b(Ae.$$.fragment),qe=m(),R=o("h3"),ce=o("a"),$e=o("span"),b(Ie.$$.fragment),B=m(),ve=o("span"),tt=p("DataLoader"),wt=m(),se=o("p"),de=p("Crea un "),Ue=o("code"),d=p("DataLoader"),T=p(" per i tuoi datasets di train e test cos\xEC puoi iterare sui lotti di dati:"),Y=m(),b(re.$$.fragment),Ce=m(),be=o("p"),U=p("Carica il tuo modello con il numero atteso di etichette:"),ct=m(),b(Oe.$$.fragment),we=m(),ee=o("h3"),je=o("a"),We=o("span"),b(Ge.$$.fragment),oe=m(),De=o("span"),jt=p("Ottimizzatore e learning rate scheduler"),Ne=m(),me=o("p"),Ye=p("Crea un ottimizzatore e il learning rate scheduler per fare il fine-tuning del modello. Usa l\u2019ottimizzatore "),fe=o("a"),dt=o("code"),at=p("AdamW"),Wt=p(" di PyTorch:"),qt=m(),b(mt.$$.fragment),ke=m(),Ee=o("p"),Ke=p("Crea il learning rate scheduler predefinito da "),ze=o("code"),Lt=p("Trainer"),ft=p(":"),Gt=m(),b(st.$$.fragment),Ct=m(),ut=o("p"),ht=p("Infine specifica come "),rt=o("code"),Dt=p("device"),Ft=p(" da usare una GPU se ne hai una. Altrimenti, l\u2019addestramento su una CPU pu\xF2 richiedere diverse ore invece di un paio di minuti."),kt=m(),b(Et.$$.fragment),zt=m(),b(gt.$$.fragment),Qe=m(),_t=o("p"),yt=p("Ottimo, adesso possiamo addestrare! \u{1F973}"),Yt=m(),$t=o("h3"),ot=o("a"),s=o("span"),b(_.$$.fragment),r=m(),v=o("span"),Kt=p("Training loop"),ta=m(),Pt=o("p"),Mt=p("Per tenere traccia dei tuoi progressi durante l\u2019addestramento, usa la libreria "),vt=o("a"),ia=p("tqdm"),na=p(" per aggiungere una progress bar sopra il numero dei passi di addestramento:"),aa=m(),b(Je.$$.fragment),sa=m(),St=o("h3"),It=o("a"),Ht=o("span"),b(xt.$$.fragment),pa=m(),Rt=o("span"),lt=p("Metriche"),ra=m(),Tt=o("p"),Xt=p("Proprio come \xE8 necessario aggiungere una funzione di valutazione del "),Zt=o("code"),ca=p("Trainer"),da=p(", \xE8 necessario fare lo stesso quando si scrive il proprio ciclo di addestramento. Ma invece di calcolare e riportare la metrica alla fine di ogni epoca, questa volta accumulerai tutti i batch con "),Se=o("a"),Vt=o("code"),ma=p("add_batch"),fa=p(" e calcolerai la metrica alla fine."),Ot=m(),b(Bt.$$.fragment),this.h()},l(a){w(g.$$.fragment,a),P=f(a),h=l(a,"P",{});var $=i(h);y=l($,"CODE",{});var Ut=i(y);A=c(Ut,"Trainer"),Ut.forEach(e),I=c($," si occupa del ciclo di addestramento e ti consente di mettere a punto un modello con una sola riga di codice. Per chi preferisse scrivere un proprio ciclo di addestramento personale, puoi anche fare il fine-tuning di un modello \u{1F917} Transformers in PyTorch nativo."),$.forEach(e),Q=f(a),q=l(a,"P",{});var oa=i(q);S=c(oa,"A questo punto, potresti avere bisogno di riavviare il tuo notebook o eseguire il seguente codice per liberare un po\u2019 di memoria:"),oa.forEach(e),O=f(a),w(x.$$.fragment,a),J=f(a),X=l(a,"P",{});var ea=i(X);Me=c(ea,"Successivamente, postprocessa manualmente il "),He=l(ea,"CODE",{});var la=i(He);L=c(la,"tokenized_dataset"),la.forEach(e),xe=c(ea," per prepararlo ad essere allenato."),ea.forEach(e),ue=f(a),Z=l(a,"OL",{});var Jt=i(Z);te=l(Jt,"LI",{});var ua=i(te);he=l(ua,"P",{});var ga=i(he);ye=c(ga,"Rimuovi la colonna "),ae=l(ga,"CODE",{});var Da=i(ae);Xe=c(Da,"text"),Da.forEach(e),le=c(ga," perch\xE9 il modello non accetta testo grezzo come input:"),ga.forEach(e),Ze=f(ua),w(W.$$.fragment,ua),ua.forEach(e),it=f(Jt),F=l(Jt,"LI",{});var $a=i(F);N=l($a,"P",{});var ha=i(N);V=c(ha,"Rinomina la colonna "),G=l(ha,"CODE",{});var Sa=i(G);nt=c(Sa,"label"),Sa.forEach(e),Re=c(ha," in "),ie=l(ha,"CODE",{});var xa=i(ie);pt=c(xa,"labels"),xa.forEach(e),At=c(ha," perch\xE9 il modello si aspetta che questo argomento si chiami "),Pe=l(ha,"CODE",{});var Fa=i(Pe);ge=c(Fa,"labels"),Fa.forEach(e),bt=c(ha,":"),ha.forEach(e),Fe=f($a),w(M.$$.fragment,$a),$a.forEach(e),Ve=f(Jt),C=l(Jt,"LI",{});var va=i(C);H=l(va,"P",{});var Ia=i(H);ne=c(Ia,"Imposta il formato del dataset per farti restituire tensori di PyTorch all\u2019interno delle liste:"),Ia.forEach(e),pe=f(va),w(Be.$$.fragment,va),va.forEach(e),Jt.forEach(e),Te=f(a),_e=l(a,"P",{});var Oa=i(_e);et=c(Oa,"Poi crea un piccolo sottocampione del dataset come visto precedentemente per velocizzare il fine-tuning:"),Oa.forEach(e),D=f(a),w(Ae.$$.fragment,a),qe=f(a),R=l(a,"H3",{class:!0});var ba=i(R);ce=l(ba,"A",{id:!0,class:!0,href:!0});var Na=i(ce);$e=l(Na,"SPAN",{});var La=i($e);w(Ie.$$.fragment,La),La.forEach(e),Na.forEach(e),B=f(ba),ve=l(ba,"SPAN",{});var Ma=i(ve);tt=c(Ma,"DataLoader"),Ma.forEach(e),ba.forEach(e),wt=f(a),se=l(a,"P",{});var wa=i(se);de=c(wa,"Crea un "),Ue=l(wa,"CODE",{});var Ha=i(Ue);d=c(Ha,"DataLoader"),Ha.forEach(e),T=c(wa," per i tuoi datasets di train e test cos\xEC puoi iterare sui lotti di dati:"),wa.forEach(e),Y=f(a),w(re.$$.fragment,a),Ce=f(a),be=l(a,"P",{});var Ra=i(be);U=c(Ra,"Carica il tuo modello con il numero atteso di etichette:"),Ra.forEach(e),ct=f(a),w(Oe.$$.fragment,a),we=f(a),ee=l(a,"H3",{class:!0});var ja=i(ee);je=l(ja,"A",{id:!0,class:!0,href:!0});var Ba=i(je);We=l(Ba,"SPAN",{});var Ua=i(We);w(Ge.$$.fragment,Ua),Ua.forEach(e),Ba.forEach(e),oe=f(ja),De=l(ja,"SPAN",{});var Wa=i(De);jt=c(Wa,"Ottimizzatore e learning rate scheduler"),Wa.forEach(e),ja.forEach(e),Ne=f(a),me=l(a,"P",{});var ka=i(me);Ye=c(ka,"Crea un ottimizzatore e il learning rate scheduler per fare il fine-tuning del modello. Usa l\u2019ottimizzatore "),fe=l(ka,"A",{href:!0,rel:!0});var Ga=i(fe);dt=l(Ga,"CODE",{});var Ya=i(dt);at=c(Ya,"AdamW"),Ya.forEach(e),Ga.forEach(e),Wt=c(ka," di PyTorch:"),ka.forEach(e),qt=f(a),w(mt.$$.fragment,a),ke=f(a),Ee=l(a,"P",{});var Ea=i(Ee);Ke=c(Ea,"Crea il learning rate scheduler predefinito da "),ze=l(Ea,"CODE",{});var Ka=i(ze);Lt=c(Ka,"Trainer"),Ka.forEach(e),ft=c(Ea,":"),Ea.forEach(e),Gt=f(a),w(st.$$.fragment,a),Ct=f(a),ut=l(a,"P",{});var za=i(ut);ht=c(za,"Infine specifica come "),rt=l(za,"CODE",{});var Qa=i(rt);Dt=c(Qa,"device"),Qa.forEach(e),Ft=c(za," da usare una GPU se ne hai una. Altrimenti, l\u2019addestramento su una CPU pu\xF2 richiedere diverse ore invece di un paio di minuti."),za.forEach(e),kt=f(a),w(Et.$$.fragment,a),zt=f(a),w(gt.$$.fragment,a),Qe=f(a),_t=l(a,"P",{});var Ja=i(_t);yt=c(Ja,"Ottimo, adesso possiamo addestrare! \u{1F973}"),Ja.forEach(e),Yt=f(a),$t=l(a,"H3",{class:!0});var ya=i($t);ot=l(ya,"A",{id:!0,class:!0,href:!0});var Xa=i(ot);s=l(Xa,"SPAN",{});var Za=i(s);w(_.$$.fragment,Za),Za.forEach(e),Xa.forEach(e),r=f(ya),v=l(ya,"SPAN",{});var Va=i(v);Kt=c(Va,"Training loop"),Va.forEach(e),ya.forEach(e),ta=f(a),Pt=l(a,"P",{});var Pa=i(Pt);Mt=c(Pa,"Per tenere traccia dei tuoi progressi durante l\u2019addestramento, usa la libreria "),vt=l(Pa,"A",{href:!0,rel:!0});var es=i(vt);ia=c(es,"tqdm"),es.forEach(e),na=c(Pa," per aggiungere una progress bar sopra il numero dei passi di addestramento:"),Pa.forEach(e),aa=f(a),w(Je.$$.fragment,a),sa=f(a),St=l(a,"H3",{class:!0});var Ta=i(St);It=l(Ta,"A",{id:!0,class:!0,href:!0});var ts=i(It);Ht=l(ts,"SPAN",{});var as=i(Ht);w(xt.$$.fragment,as),as.forEach(e),ts.forEach(e),pa=f(Ta),Rt=l(Ta,"SPAN",{});var ss=i(Rt);lt=c(ss,"Metriche"),ss.forEach(e),Ta.forEach(e),ra=f(a),Tt=l(a,"P",{});var _a=i(Tt);Xt=c(_a,"Proprio come \xE8 necessario aggiungere una funzione di valutazione del "),Zt=l(_a,"CODE",{});var rs=i(Zt);ca=c(rs,"Trainer"),rs.forEach(e),da=c(_a,", \xE8 necessario fare lo stesso quando si scrive il proprio ciclo di addestramento. Ma invece di calcolare e riportare la metrica alla fine di ogni epoca, questa volta accumulerai tutti i batch con "),Se=l(_a,"A",{href:!0,rel:!0});var os=i(Se);Vt=l(os,"CODE",{});var ls=i(Vt);ma=c(ls,"add_batch"),ls.forEach(e),os.forEach(e),fa=c(_a," e calcolerai la metrica alla fine."),_a.forEach(e),Ot=f(a),w(Bt.$$.fragment,a),this.h()},h(){u(ce,"id","dataloader"),u(ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ce,"href","#dataloader"),u(R,"class","relative group"),u(je,"id","ottimizzatore-e-learning-rate-scheduler"),u(je,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(je,"href","#ottimizzatore-e-learning-rate-scheduler"),u(ee,"class","relative group"),u(fe,"href","https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html"),u(fe,"rel","nofollow"),u(ot,"id","training-loop"),u(ot,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ot,"href","#training-loop"),u($t,"class","relative group"),u(vt,"href","https://tqdm.github.io/"),u(vt,"rel","nofollow"),u(It,"id","metriche"),u(It,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(It,"href","#metriche"),u(St,"class","relative group"),u(Se,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html?highlight=add_batch#datasets.Metric.add_batch"),u(Se,"rel","nofollow")},m(a,$){j(g,a,$),n(a,P,$),n(a,h,$),t(h,y),t(y,A),t(h,I),n(a,Q,$),n(a,q,$),t(q,S),n(a,O,$),j(x,a,$),n(a,J,$),n(a,X,$),t(X,Me),t(X,He),t(He,L),t(X,xe),n(a,ue,$),n(a,Z,$),t(Z,te),t(te,he),t(he,ye),t(he,ae),t(ae,Xe),t(he,le),t(te,Ze),j(W,te,null),t(Z,it),t(Z,F),t(F,N),t(N,V),t(N,G),t(G,nt),t(N,Re),t(N,ie),t(ie,pt),t(N,At),t(N,Pe),t(Pe,ge),t(N,bt),t(F,Fe),j(M,F,null),t(Z,Ve),t(Z,C),t(C,H),t(H,ne),t(C,pe),j(Be,C,null),n(a,Te,$),n(a,_e,$),t(_e,et),n(a,D,$),j(Ae,a,$),n(a,qe,$),n(a,R,$),t(R,ce),t(ce,$e),j(Ie,$e,null),t(R,B),t(R,ve),t(ve,tt),n(a,wt,$),n(a,se,$),t(se,de),t(se,Ue),t(Ue,d),t(se,T),n(a,Y,$),j(re,a,$),n(a,Ce,$),n(a,be,$),t(be,U),n(a,ct,$),j(Oe,a,$),n(a,we,$),n(a,ee,$),t(ee,je),t(je,We),j(Ge,We,null),t(ee,oe),t(ee,De),t(De,jt),n(a,Ne,$),n(a,me,$),t(me,Ye),t(me,fe),t(fe,dt),t(dt,at),t(me,Wt),n(a,qt,$),j(mt,a,$),n(a,ke,$),n(a,Ee,$),t(Ee,Ke),t(Ee,ze),t(ze,Lt),t(Ee,ft),n(a,Gt,$),j(st,a,$),n(a,Ct,$),n(a,ut,$),t(ut,ht),t(ut,rt),t(rt,Dt),t(ut,Ft),n(a,kt,$),j(Et,a,$),n(a,zt,$),j(gt,a,$),n(a,Qe,$),n(a,_t,$),t(_t,yt),n(a,Yt,$),n(a,$t,$),t($t,ot),t(ot,s),j(_,s,null),t($t,r),t($t,v),t(v,Kt),n(a,ta,$),n(a,Pt,$),t(Pt,Mt),t(Pt,vt),t(vt,ia),t(Pt,na),n(a,aa,$),j(Je,a,$),n(a,sa,$),n(a,St,$),t(St,It),t(It,Ht),j(xt,Ht,null),t(St,pa),t(St,Rt),t(Rt,lt),n(a,ra,$),n(a,Tt,$),t(Tt,Xt),t(Tt,Zt),t(Zt,ca),t(Tt,da),t(Tt,Se),t(Se,Vt),t(Vt,ma),t(Tt,fa),n(a,Ot,$),j(Bt,a,$),Qt=!0},p(a,$){const Ut={};$&2&&(Ut.$$scope={dirty:$,ctx:a}),gt.$set(Ut)},i(a){Qt||(k(g.$$.fragment,a),k(x.$$.fragment,a),k(W.$$.fragment,a),k(M.$$.fragment,a),k(Be.$$.fragment,a),k(Ae.$$.fragment,a),k(Ie.$$.fragment,a),k(re.$$.fragment,a),k(Oe.$$.fragment,a),k(Ge.$$.fragment,a),k(mt.$$.fragment,a),k(st.$$.fragment,a),k(Et.$$.fragment,a),k(gt.$$.fragment,a),k(_.$$.fragment,a),k(Je.$$.fragment,a),k(xt.$$.fragment,a),k(Bt.$$.fragment,a),Qt=!0)},o(a){E(g.$$.fragment,a),E(x.$$.fragment,a),E(W.$$.fragment,a),E(M.$$.fragment,a),E(Be.$$.fragment,a),E(Ae.$$.fragment,a),E(Ie.$$.fragment,a),E(re.$$.fragment,a),E(Oe.$$.fragment,a),E(Ge.$$.fragment,a),E(mt.$$.fragment,a),E(st.$$.fragment,a),E(Et.$$.fragment,a),E(gt.$$.fragment,a),E(_.$$.fragment,a),E(Je.$$.fragment,a),E(xt.$$.fragment,a),E(Bt.$$.fragment,a),Qt=!1},d(a){z(g,a),a&&e(P),a&&e(h),a&&e(Q),a&&e(q),a&&e(O),z(x,a),a&&e(J),a&&e(X),a&&e(ue),a&&e(Z),z(W),z(M),z(Be),a&&e(Te),a&&e(_e),a&&e(D),z(Ae,a),a&&e(qe),a&&e(R),z(Ie),a&&e(wt),a&&e(se),a&&e(Y),z(re,a),a&&e(Ce),a&&e(be),a&&e(ct),z(Oe,a),a&&e(we),a&&e(ee),z(Ge),a&&e(Ne),a&&e(me),a&&e(qt),z(mt,a),a&&e(ke),a&&e(Ee),a&&e(Gt),z(st,a),a&&e(Ct),a&&e(ut),a&&e(kt),z(Et,a),a&&e(zt),z(gt,a),a&&e(Qe),a&&e(_t),a&&e(Yt),a&&e($t),z(_),a&&e(ta),a&&e(Pt),a&&e(aa),z(Je,a),a&&e(sa),a&&e(St),z(xt),a&&e(ra),a&&e(Tt),a&&e(Ot),z(Bt,a)}}}function js(Le){let g,P;return g=new Ca({props:{$$slots:{default:[ws]},$$scope:{ctx:Le}}}),{c(){b(g.$$.fragment)},l(h){w(g.$$.fragment,h)},m(h,y){j(g,h,y),P=!0},p(h,y){const A={};y&2&&(A.$$scope={dirty:y,ctx:h}),g.$set(A)},i(h){P||(k(g.$$.fragment,h),P=!0)},o(h){E(g.$$.fragment,h),P=!1},d(h){z(g,h)}}}function ks(Le){let g,P,h,y,A,I,Q,q,S,O,x,J,X,Me,He,L,xe,ue,Z,te,he,ye,ae,Xe,le,Ze,W,it,F,N,V,G,nt,Re,ie,pt,At,Pe,ge,bt,Fe,M,Ve,C,H,ne,pe,Be,Te,_e,et,D,Ae,qe,R,ce,$e,Ie,B,ve,tt,wt,se,de,Ue,d,T,Y,re,Ce,be,U,ct,Oe,we,ee,je,We,Ge,oe,De,jt,Ne,me,Ye,fe,dt,at,Wt,qt,mt,ke,Ee,Ke,ze,Lt,ft,Gt,st,Ct,ut,ht,rt,Dt,Ft,kt,Et,zt,gt,Qe,_t,yt,Yt,$t,ot;return I=new Nt({}),x=new fs({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/training.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/pytorch/training.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/tensorflow/training.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/training.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/pytorch/training.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/tensorflow/training.ipynb"}]}}),Re=new Nt({}),ge=new Aa({props:{id:"_BZearw7f0w"}}),_e=new K({props:{code:`from datasets import load_dataset

dataset = load_dataset("yelp_review_full")
dataset["train"][100]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;yelp_review_full&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">100</span>]
{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\&#x27;s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\&#x27;s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\&quot;serving off their orders\\\\&quot; when they didn\\&#x27;t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\&#x27;t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\&#x27;ve eaten at various McDonalds restaurants for over 30 years. I\\&#x27;ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!&#x27;</span>}`}}),B=new K({props:{code:`from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")


def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)


tokenized_datasets = dataset.map(tokenize_function, batched=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> tokenizer(examples[<span class="hljs-string">&quot;text&quot;</span>], padding=<span class="hljs-string">&quot;max_length&quot;</span>, truncation=<span class="hljs-literal">True</span>)


<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_datasets = dataset.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>)`}}),de=new K({props:{code:`small_train_dataset = tokenized_datasets["train"].shuffle(seed=42).select(range(1000))
small_eval_dataset = tokenized_datasets["test"].shuffle(seed=42).select(range(1000))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>small_train_dataset = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>small_eval_dataset = tokenized_datasets[<span class="hljs-string">&quot;test&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))`}}),be=new Nt({}),ee=new is({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[vs],pytorch:[gs]},$$scope:{ctx:Le}}}),Ne=new Nt({}),at=new is({props:{pytorch:!0,tensorflow:!1,jax:!1,$$slots:{pytorch:[js]},$$scope:{ctx:Le}}}),ze=new Nt({}),{c(){g=o("meta"),P=m(),h=o("h1"),y=o("a"),A=o("span"),b(I.$$.fragment),Q=m(),q=o("span"),S=p("Fine-tuning di un modello pre-addestrato"),O=m(),b(x.$$.fragment),J=m(),X=o("p"),Me=p("Ci sono benefici significativi nell\u2019usare un modello pre-addestrato. Si riducono i costi computazionali, l\u2019impronta di carbonio e ti consente di usare modelli stato dell\u2019arte senza doverli addestrare da zero. \u{1F917} Transformers consente l\u2019accesso a migliaia di modelli pre-addestrati per un\u2019ampia gamma di compiti. Quando usi un modello pre-addestrato, lo alleni su un dataset specifico per il tuo compito. Questo \xE8 conosciuto come fine-tuning, una tecnica di addestramento incredibilmente potente. In questa esercitazione, potrai fare il fine-tuning di un modello pre-addestrato, con un framework di deep learning a tua scelta:"),He=m(),L=o("ul"),xe=o("li"),ue=p("Fine-tuning di un modello pre-addestrato con \u{1F917} Transformers "),Z=o("code"),te=p("Trainer"),he=p("."),ye=m(),ae=o("li"),Xe=p("Fine-tuning di un modello pre-addestrato in TensorFlow con Keras."),le=m(),Ze=o("li"),W=p("Fine-tuning di un modello pre-addestrato con PyTorch."),it=m(),F=o("a"),N=m(),V=o("h2"),G=o("a"),nt=o("span"),b(Re.$$.fragment),ie=m(),pt=o("span"),At=p("Preparare un dataset"),Pe=m(),b(ge.$$.fragment),bt=m(),Fe=o("p"),M=p("Prima di poter fare il fine-tuning di un modello pre-addestrato, scarica un dataset e preparalo per l\u2019addestramento. La precedente esercitazione ti ha mostrato come processare i dati per l\u2019addestramento e adesso hai l\u2019opportunit\xE0 di metterti alla prova!"),Ve=m(),C=o("p"),H=p("Inizia caricando il dataset "),ne=o("a"),pe=p("Yelp Reviews"),Be=p(":"),Te=m(),b(_e.$$.fragment),et=m(),D=o("p"),Ae=p("Come gi\xE0 sai, hai bisogno di un tokenizer per processare il testo e includere una strategia di padding e truncation per gestire sequenze di lunghezza variabile. Per processare il dataset in un unico passo, usa il metodo "),qe=o("a"),R=o("code"),ce=p("map"),$e=p(" di \u{1F917} Datasets che applica la funzione di preprocessing all\u2019intero dataset:"),Ie=m(),b(B.$$.fragment),ve=m(),tt=o("p"),wt=p("Se vuoi, puoi creare un sottoinsieme pi\xF9 piccolo del dataset per il fine-tuning cos\xEC da ridurre il tempo necessario:"),se=m(),b(de.$$.fragment),Ue=m(),d=o("a"),T=m(),Y=o("h2"),re=o("a"),Ce=o("span"),b(be.$$.fragment),U=m(),ct=o("span"),Oe=p("Addestramento"),we=m(),b(ee.$$.fragment),je=m(),We=o("a"),Ge=m(),oe=o("h2"),De=o("a"),jt=o("span"),b(Ne.$$.fragment),me=m(),Ye=o("span"),fe=p("Addestramento in PyTorch nativo"),dt=m(),b(at.$$.fragment),Wt=m(),qt=o("a"),mt=m(),ke=o("h2"),Ee=o("a"),Ke=o("span"),b(ze.$$.fragment),Lt=m(),ft=o("span"),Gt=p("Altre risorse"),st=m(),Ct=o("p"),ut=p("Per altri esempi sul fine-tuning, fai riferimento a:"),ht=m(),rt=o("ul"),Dt=o("li"),Ft=o("p"),kt=o("a"),Et=p("\u{1F917} Transformers Examples"),zt=p(" include scripts per addestrare compiti comuni di NLP in PyTorch e TensorFlow."),gt=m(),Qe=o("li"),_t=o("p"),yt=o("a"),Yt=p("\u{1F917} Transformers Notebooks"),$t=p(" contiene diversi notebooks su come mettere a punto un modello per compiti specifici in PyTorch e TensorFlow."),this.h()},l(s){const _=ds('[data-svelte="svelte-1phssyn"]',document.head);g=l(_,"META",{name:!0,content:!0}),_.forEach(e),P=f(s),h=l(s,"H1",{class:!0});var r=i(h);y=l(r,"A",{id:!0,class:!0,href:!0});var v=i(y);A=l(v,"SPAN",{});var Kt=i(A);w(I.$$.fragment,Kt),Kt.forEach(e),v.forEach(e),Q=f(r),q=l(r,"SPAN",{});var ta=i(q);S=c(ta,"Fine-tuning di un modello pre-addestrato"),ta.forEach(e),r.forEach(e),O=f(s),w(x.$$.fragment,s),J=f(s),X=l(s,"P",{});var Pt=i(X);Me=c(Pt,"Ci sono benefici significativi nell\u2019usare un modello pre-addestrato. Si riducono i costi computazionali, l\u2019impronta di carbonio e ti consente di usare modelli stato dell\u2019arte senza doverli addestrare da zero. \u{1F917} Transformers consente l\u2019accesso a migliaia di modelli pre-addestrati per un\u2019ampia gamma di compiti. Quando usi un modello pre-addestrato, lo alleni su un dataset specifico per il tuo compito. Questo \xE8 conosciuto come fine-tuning, una tecnica di addestramento incredibilmente potente. In questa esercitazione, potrai fare il fine-tuning di un modello pre-addestrato, con un framework di deep learning a tua scelta:"),Pt.forEach(e),He=f(s),L=l(s,"UL",{});var Mt=i(L);xe=l(Mt,"LI",{});var vt=i(xe);ue=c(vt,"Fine-tuning di un modello pre-addestrato con \u{1F917} Transformers "),Z=l(vt,"CODE",{});var ia=i(Z);te=c(ia,"Trainer"),ia.forEach(e),he=c(vt,"."),vt.forEach(e),ye=f(Mt),ae=l(Mt,"LI",{});var na=i(ae);Xe=c(na,"Fine-tuning di un modello pre-addestrato in TensorFlow con Keras."),na.forEach(e),le=f(Mt),Ze=l(Mt,"LI",{});var aa=i(Ze);W=c(aa,"Fine-tuning di un modello pre-addestrato con PyTorch."),aa.forEach(e),Mt.forEach(e),it=f(s),F=l(s,"A",{id:!0}),i(F).forEach(e),N=f(s),V=l(s,"H2",{class:!0});var Je=i(V);G=l(Je,"A",{id:!0,class:!0,href:!0});var sa=i(G);nt=l(sa,"SPAN",{});var St=i(nt);w(Re.$$.fragment,St),St.forEach(e),sa.forEach(e),ie=f(Je),pt=l(Je,"SPAN",{});var It=i(pt);At=c(It,"Preparare un dataset"),It.forEach(e),Je.forEach(e),Pe=f(s),w(ge.$$.fragment,s),bt=f(s),Fe=l(s,"P",{});var Ht=i(Fe);M=c(Ht,"Prima di poter fare il fine-tuning di un modello pre-addestrato, scarica un dataset e preparalo per l\u2019addestramento. La precedente esercitazione ti ha mostrato come processare i dati per l\u2019addestramento e adesso hai l\u2019opportunit\xE0 di metterti alla prova!"),Ht.forEach(e),Ve=f(s),C=l(s,"P",{});var xt=i(C);H=c(xt,"Inizia caricando il dataset "),ne=l(xt,"A",{href:!0,rel:!0});var pa=i(ne);pe=c(pa,"Yelp Reviews"),pa.forEach(e),Be=c(xt,":"),xt.forEach(e),Te=f(s),w(_e.$$.fragment,s),et=f(s),D=l(s,"P",{});var Rt=i(D);Ae=c(Rt,"Come gi\xE0 sai, hai bisogno di un tokenizer per processare il testo e includere una strategia di padding e truncation per gestire sequenze di lunghezza variabile. Per processare il dataset in un unico passo, usa il metodo "),qe=l(Rt,"A",{href:!0,rel:!0});var lt=i(qe);R=l(lt,"CODE",{});var ra=i(R);ce=c(ra,"map"),ra.forEach(e),lt.forEach(e),$e=c(Rt," di \u{1F917} Datasets che applica la funzione di preprocessing all\u2019intero dataset:"),Rt.forEach(e),Ie=f(s),w(B.$$.fragment,s),ve=f(s),tt=l(s,"P",{});var Tt=i(tt);wt=c(Tt,"Se vuoi, puoi creare un sottoinsieme pi\xF9 piccolo del dataset per il fine-tuning cos\xEC da ridurre il tempo necessario:"),Tt.forEach(e),se=f(s),w(de.$$.fragment,s),Ue=f(s),d=l(s,"A",{id:!0}),i(d).forEach(e),T=f(s),Y=l(s,"H2",{class:!0});var Xt=i(Y);re=l(Xt,"A",{id:!0,class:!0,href:!0});var Zt=i(re);Ce=l(Zt,"SPAN",{});var ca=i(Ce);w(be.$$.fragment,ca),ca.forEach(e),Zt.forEach(e),U=f(Xt),ct=l(Xt,"SPAN",{});var da=i(ct);Oe=c(da,"Addestramento"),da.forEach(e),Xt.forEach(e),we=f(s),w(ee.$$.fragment,s),je=f(s),We=l(s,"A",{id:!0}),i(We).forEach(e),Ge=f(s),oe=l(s,"H2",{class:!0});var Se=i(oe);De=l(Se,"A",{id:!0,class:!0,href:!0});var Vt=i(De);jt=l(Vt,"SPAN",{});var ma=i(jt);w(Ne.$$.fragment,ma),ma.forEach(e),Vt.forEach(e),me=f(Se),Ye=l(Se,"SPAN",{});var fa=i(Ye);fe=c(fa,"Addestramento in PyTorch nativo"),fa.forEach(e),Se.forEach(e),dt=f(s),w(at.$$.fragment,s),Wt=f(s),qt=l(s,"A",{id:!0}),i(qt).forEach(e),mt=f(s),ke=l(s,"H2",{class:!0});var Ot=i(ke);Ee=l(Ot,"A",{id:!0,class:!0,href:!0});var Bt=i(Ee);Ke=l(Bt,"SPAN",{});var Qt=i(Ke);w(ze.$$.fragment,Qt),Qt.forEach(e),Bt.forEach(e),Lt=f(Ot),ft=l(Ot,"SPAN",{});var a=i(ft);Gt=c(a,"Altre risorse"),a.forEach(e),Ot.forEach(e),st=f(s),Ct=l(s,"P",{});var $=i(Ct);ut=c($,"Per altri esempi sul fine-tuning, fai riferimento a:"),$.forEach(e),ht=f(s),rt=l(s,"UL",{});var Ut=i(rt);Dt=l(Ut,"LI",{});var oa=i(Dt);Ft=l(oa,"P",{});var ea=i(Ft);kt=l(ea,"A",{href:!0,rel:!0});var la=i(kt);Et=c(la,"\u{1F917} Transformers Examples"),la.forEach(e),zt=c(ea," include scripts per addestrare compiti comuni di NLP in PyTorch e TensorFlow."),ea.forEach(e),oa.forEach(e),gt=f(Ut),Qe=l(Ut,"LI",{});var Jt=i(Qe);_t=l(Jt,"P",{});var ua=i(_t);yt=l(ua,"A",{href:!0});var ga=i(yt);Yt=c(ga,"\u{1F917} Transformers Notebooks"),ga.forEach(e),$t=c(ua," contiene diversi notebooks su come mettere a punto un modello per compiti specifici in PyTorch e TensorFlow."),ua.forEach(e),Jt.forEach(e),Ut.forEach(e),this.h()},h(){u(g,"name","hf:doc:metadata"),u(g,"content",JSON.stringify(Es)),u(y,"id","finetuning-di-un-modello-preaddestrato"),u(y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(y,"href","#finetuning-di-un-modello-preaddestrato"),u(h,"class","relative group"),u(F,"id","data-processing"),u(G,"id","preparare-un-dataset"),u(G,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(G,"href","#preparare-un-dataset"),u(V,"class","relative group"),u(ne,"href","https://huggingface.co/datasets/yelp_review_full"),u(ne,"rel","nofollow"),u(qe,"href","https://huggingface.co/docs/datasets/process.html#map"),u(qe,"rel","nofollow"),u(d,"id","trainer"),u(re,"id","addestramento"),u(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(re,"href","#addestramento"),u(Y,"class","relative group"),u(We,"id","pytorch_native"),u(De,"id","addestramento-in-pytorch-nativo"),u(De,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(De,"href","#addestramento-in-pytorch-nativo"),u(oe,"class","relative group"),u(qt,"id","additional-resources"),u(Ee,"id","altre-risorse"),u(Ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(Ee,"href","#altre-risorse"),u(ke,"class","relative group"),u(kt,"href","https://github.com/huggingface/transformers/tree/main/examples"),u(kt,"rel","nofollow"),u(yt,"href","notebooks")},m(s,_){t(document.head,g),n(s,P,_),n(s,h,_),t(h,y),t(y,A),j(I,A,null),t(h,Q),t(h,q),t(q,S),n(s,O,_),j(x,s,_),n(s,J,_),n(s,X,_),t(X,Me),n(s,He,_),n(s,L,_),t(L,xe),t(xe,ue),t(xe,Z),t(Z,te),t(xe,he),t(L,ye),t(L,ae),t(ae,Xe),t(L,le),t(L,Ze),t(Ze,W),n(s,it,_),n(s,F,_),n(s,N,_),n(s,V,_),t(V,G),t(G,nt),j(Re,nt,null),t(V,ie),t(V,pt),t(pt,At),n(s,Pe,_),j(ge,s,_),n(s,bt,_),n(s,Fe,_),t(Fe,M),n(s,Ve,_),n(s,C,_),t(C,H),t(C,ne),t(ne,pe),t(C,Be),n(s,Te,_),j(_e,s,_),n(s,et,_),n(s,D,_),t(D,Ae),t(D,qe),t(qe,R),t(R,ce),t(D,$e),n(s,Ie,_),j(B,s,_),n(s,ve,_),n(s,tt,_),t(tt,wt),n(s,se,_),j(de,s,_),n(s,Ue,_),n(s,d,_),n(s,T,_),n(s,Y,_),t(Y,re),t(re,Ce),j(be,Ce,null),t(Y,U),t(Y,ct),t(ct,Oe),n(s,we,_),j(ee,s,_),n(s,je,_),n(s,We,_),n(s,Ge,_),n(s,oe,_),t(oe,De),t(De,jt),j(Ne,jt,null),t(oe,me),t(oe,Ye),t(Ye,fe),n(s,dt,_),j(at,s,_),n(s,Wt,_),n(s,qt,_),n(s,mt,_),n(s,ke,_),t(ke,Ee),t(Ee,Ke),j(ze,Ke,null),t(ke,Lt),t(ke,ft),t(ft,Gt),n(s,st,_),n(s,Ct,_),t(Ct,ut),n(s,ht,_),n(s,rt,_),t(rt,Dt),t(Dt,Ft),t(Ft,kt),t(kt,Et),t(Ft,zt),t(rt,gt),t(rt,Qe),t(Qe,_t),t(_t,yt),t(yt,Yt),t(_t,$t),ot=!0},p(s,[_]){const r={};_&2&&(r.$$scope={dirty:_,ctx:s}),ee.$set(r);const v={};_&2&&(v.$$scope={dirty:_,ctx:s}),at.$set(v)},i(s){ot||(k(I.$$.fragment,s),k(x.$$.fragment,s),k(Re.$$.fragment,s),k(ge.$$.fragment,s),k(_e.$$.fragment,s),k(B.$$.fragment,s),k(de.$$.fragment,s),k(be.$$.fragment,s),k(ee.$$.fragment,s),k(Ne.$$.fragment,s),k(at.$$.fragment,s),k(ze.$$.fragment,s),ot=!0)},o(s){E(I.$$.fragment,s),E(x.$$.fragment,s),E(Re.$$.fragment,s),E(ge.$$.fragment,s),E(_e.$$.fragment,s),E(B.$$.fragment,s),E(de.$$.fragment,s),E(be.$$.fragment,s),E(ee.$$.fragment,s),E(Ne.$$.fragment,s),E(at.$$.fragment,s),E(ze.$$.fragment,s),ot=!1},d(s){e(g),s&&e(P),s&&e(h),z(I),s&&e(O),z(x,s),s&&e(J),s&&e(X),s&&e(He),s&&e(L),s&&e(it),s&&e(F),s&&e(N),s&&e(V),z(Re),s&&e(Pe),z(ge,s),s&&e(bt),s&&e(Fe),s&&e(Ve),s&&e(C),s&&e(Te),z(_e,s),s&&e(et),s&&e(D),s&&e(Ie),z(B,s),s&&e(ve),s&&e(tt),s&&e(se),z(de,s),s&&e(Ue),s&&e(d),s&&e(T),s&&e(Y),z(be),s&&e(we),z(ee,s),s&&e(je),s&&e(We),s&&e(Ge),s&&e(oe),z(Ne),s&&e(dt),z(at,s),s&&e(Wt),s&&e(qt),s&&e(mt),s&&e(ke),z(ze),s&&e(st),s&&e(Ct),s&&e(ht),s&&e(rt)}}}const Es={local:"finetuning-di-un-modello-preaddestrato",sections:[{local:"preparare-un-dataset",title:"Preparare un dataset"},{local:"addestramento",sections:[{local:"iperparametri-per-il-training",title:"Iperparametri per il training"},{local:"metriche",title:"Metriche"},{local:"trainer",title:"Trainer"},{local:"convertire-dataset-nel-formato-per-tensorflow",title:"Convertire dataset nel formato per TensorFlow"},{local:"compilazione-e-addestramento",title:"Compilazione e addestramento"}],title:"Addestramento"},{local:"addestramento-in-pytorch-nativo",sections:[{local:"dataloader",title:"DataLoader"},{local:"ottimizzatore-e-learning-rate-scheduler",title:"Ottimizzatore e learning rate scheduler"},{local:"training-loop",title:"Training loop"},{local:"metriche",title:"Metriche"}],title:"Addestramento in PyTorch nativo"},{local:"altre-risorse",title:"Altre risorse"}],title:"Fine-tuning di un modello pre-addestrato"};function zs(Le){return ms(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class xs extends ns{constructor(g){super();ps(this,g,zs,ks,cs,{})}}export{xs as default,Es as metadata};
