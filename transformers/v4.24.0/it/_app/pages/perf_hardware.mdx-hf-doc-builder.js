import{S as Wn,i as Qn,s as Yn,e as n,k as c,w as P,t as r,M as Fn,c as o,d as a,m as d,a as l,x as _,h as p,b as u,G as t,g as s,y as b,L as Zn,q as w,o as z,B as E,v as Jn}from"../chunks/vendor-hf-doc-builder.js";import{I as oa}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as la}from"../chunks/CodeBlock-hf-doc-builder.js";function Kn(ji){let k,sa,U,g,Ie,B,pt,ye,ct,ra,A,dt,T,ut,mt,pa,oe,ft,ca,N,I,Ve,H,vt,Se,ht,da,le,Pt,ua,C,y,De,q,_t,Le,bt,ma,se,wt,fa,O,xe,zt,Et,va,re,kt,ha,pe,Ut,Pa,ce,Nt,_a,de,Ct,ba,ue,Gt,wa,me,$t,za,X,je,gt,At,Ea,fe,It,ka,ve,yt,Ua,he,Vt,Na,G,V,Be,M,St,Te,Dt,Ca,Pe,Lt,Ga,R,$a,_e,xt,ga,W,Aa,be,jt,Ia,Q,ya,we,Bt,Va,Y,Sa,h,Tt,He,Ht,qt,qe,Ot,Xt,Da,ze,Mt,La,Ee,Rt,xa,$,S,Oe,F,Wt,Xe,Qt,ja,Z,J,Yt,Ft,Ba,D,Zt,K,Jt,Kt,Ta,ke,Me,ei,Ha,f,ai,Re,ti,ii,We,ni,oi,Qe,li,si,qa,Ue,ri,Oa,Ne,pi,Xa,L,Ye,ee,Fe,ci,di,Ce,ui,mi,ae,te,Ze,fi,vi,Ge,hi,Pi,ie,Je,_i,bi,$e,wi,Ma,x,zi,Ke,Ei,ki,Ra,ge,Ui,Wa,ne,Qa,m,Ni,ea,Ci,Gi,aa,$i,gi,ta,Ai,Ii,ia,yi,Vi,na,Si,Ya;return B=new oa({}),H=new oa({}),q=new oa({}),M=new oa({}),R=new la({props:{code:"nvidia-smi topo -m",highlighted:'<span class="hljs-symbol">nvidia</span>-<span class="hljs-keyword">smi</span> topo -m'}}),W=new la({props:{code:`        GPU0    GPU1    CPU Affinity    NUMA Affinity
GPU0     X      NV2     0-23            N/A
GPU1    NV2      X      0-23            N/A`,highlighted:`        <span class="hljs-attribute">GPU0</span>    GPU1    CPU Affinity    NUMA Affinity
<span class="hljs-attribute">GPU0</span>     X      NV2     <span class="hljs-number">0</span>-<span class="hljs-number">23</span>            N/A
<span class="hljs-attribute">GPU1</span>    NV2      X      <span class="hljs-number">0</span>-<span class="hljs-number">23</span>            N/A`}}),Q=new la({props:{code:`        GPU0    GPU1    CPU Affinity    NUMA Affinity
GPU0     X      PHB     0-11            N/A
GPU1    PHB      X      0-11            N/A`,highlighted:`        <span class="hljs-attribute">GPU0</span>    GPU1    CPU Affinity    NUMA Affinity
<span class="hljs-attribute">GPU0</span>     X      PHB     <span class="hljs-number">0</span>-<span class="hljs-number">11</span>            N/A
<span class="hljs-attribute">GPU1</span>    PHB      X      <span class="hljs-number">0</span>-<span class="hljs-number">11</span>            N/A`}}),Y=new la({props:{code:`  X    = Self
  SYS  = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)
  NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node
  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)
  PXB  = Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)
  PIX  = Connection traversing at most a single PCIe bridge
  NV#  = Connection traversing a bonded set of # NVLinks`,highlighted:`  X    = Self
  SYS  = Connection traversing PCIe <span class="hljs-keyword">as</span> well <span class="hljs-keyword">as</span> <span class="hljs-keyword">the</span> SMP interconnect between NUMA nodes (e.g., QPI/UPI)
  NODE = Connection traversing PCIe <span class="hljs-keyword">as</span> well <span class="hljs-keyword">as</span> <span class="hljs-keyword">the</span> interconnect between PCIe Host Bridges <span class="hljs-keyword">within</span> <span class="hljs-keyword">a</span> NUMA node
  PHB  = Connection traversing PCIe <span class="hljs-keyword">as</span> well <span class="hljs-keyword">as</span> <span class="hljs-keyword">a</span> PCIe Host Bridge (typically <span class="hljs-keyword">the</span> CPU)
  PXB  = Connection traversing multiple PCIe bridges (<span class="hljs-keyword">without</span> traversing <span class="hljs-keyword">the</span> PCIe Host Bridge)
  PIX  = Connection traversing <span class="hljs-keyword">at</span> most <span class="hljs-keyword">a</span> single PCIe bridge
  NV<span class="hljs-comment">#  = Connection traversing a bonded set of # NVLinks</span>`}}),F=new oa({}),ne=new la({props:{code:`# DDP w/ NVLink

rm -r /tmp/test-clm; CUDA_VISIBLE_DEVICES=0,1 python -m torch.distributed.launch \\
--nproc_per_node 2 examples/pytorch/language-modeling/run_clm.py --model_name_or_path gpt2 \\
--dataset_name wikitext --dataset_config_name wikitext-2-raw-v1 --do_train \\
--output_dir /tmp/test-clm --per_device_train_batch_size 4 --max_steps 200

{'train_runtime': 101.9003, 'train_samples_per_second': 1.963, 'epoch': 0.69}

# DDP w/o NVLink

rm -r /tmp/test-clm; CUDA_VISIBLE_DEVICES=0,1 NCCL_P2P_DISABLE=1 python -m torch.distributed.launch \\
--nproc_per_node 2 examples/pytorch/language-modeling/run_clm.py --model_name_or_path gpt2 \\
--dataset_name wikitext --dataset_config_name wikitext-2-raw-v1 --do_train
--output_dir /tmp/test-clm --per_device_train_batch_size 4 --max_steps 200

{'train_runtime': 131.4367, 'train_samples_per_second': 1.522, 'epoch': 0.69}`,highlighted:`<span class="hljs-comment"># DDP w/ NVLink</span>

<span class="hljs-built_in">rm</span> -r /tmp/test-clm; CUDA_VISIBLE_DEVICES=0,1 python -m torch.distributed.launch \\
--nproc_per_node 2 examples/pytorch/language-modeling/run_clm.py --model_name_or_path gpt2 \\
--dataset_name wikitext --dataset_config_name wikitext-2-raw-v1 --do_train \\
--output_dir /tmp/test-clm --per_device_train_batch_size 4 --max_steps 200

{<span class="hljs-string">&#x27;train_runtime&#x27;</span>: 101.9003, <span class="hljs-string">&#x27;train_samples_per_second&#x27;</span>: 1.963, <span class="hljs-string">&#x27;epoch&#x27;</span>: 0.69}

<span class="hljs-comment"># DDP w/o NVLink</span>

<span class="hljs-built_in">rm</span> -r /tmp/test-clm; CUDA_VISIBLE_DEVICES=0,1 NCCL_P2P_DISABLE=1 python -m torch.distributed.launch \\
--nproc_per_node 2 examples/pytorch/language-modeling/run_clm.py --model_name_or_path gpt2 \\
--dataset_name wikitext --dataset_config_name wikitext-2-raw-v1 --do_train
--output_dir /tmp/test-clm --per_device_train_batch_size 4 --max_steps 200

{<span class="hljs-string">&#x27;train_runtime&#x27;</span>: 131.4367, <span class="hljs-string">&#x27;train_samples_per_second&#x27;</span>: 1.522, <span class="hljs-string">&#x27;epoch&#x27;</span>: 0.69}`}}),{c(){k=n("meta"),sa=c(),U=n("h1"),g=n("a"),Ie=n("span"),P(B.$$.fragment),pt=c(),ye=n("span"),ct=r("Hardware ottimizzato per l'addestramento"),ra=c(),A=n("p"),dt=r("L\u2019hardware utilizzato per eseguire l\u2019addestramento del modello e l\u2019inferenza pu\xF2 avere un grande effetto sulle prestazioni. Per un analisi approfondita delle GPUs, assicurati di dare un\u2019occhiata all\u2019eccellente "),T=n("a"),ut=r("blog post"),mt=r(" di Tim Dettmer."),pa=c(),oe=n("p"),ft=r("Diamo un\u2019occhiata ad alcuni consigli pratici per la configurazione della GPU."),ca=c(),N=n("h2"),I=n("a"),Ve=n("span"),P(H.$$.fragment),vt=c(),Se=n("span"),ht=r("GPU"),da=r(`

Quando si addestrano modelli pi\xF9 grandi ci sono essenzialmente tre opzioni:
- GPUs piu' grandi
- Piu' GPUs
- Piu' CPU e piu' NVMe (scaricato da [DeepSpeed-Infinity](main_classes/deepspeed#nvme-support))
`),le=n("p"),Pt=r("Iniziamo dal caso in cui ci sia una singola GPU."),ua=c(),C=n("h3"),y=n("a"),De=n("span"),P(q.$$.fragment),_t=c(),Le=n("span"),bt=r("Potenza e Raffreddamento"),ma=c(),se=n("p"),wt=r("Se hai acquistato una costosa GPU di fascia alta, assicurati di darle la potenza corretta e un raffreddamento sufficiente."),fa=c(),O=n("p"),xe=n("strong"),zt=r("Potenza"),Et=r(":"),va=c(),re=n("p"),kt=r("Alcune schede GPU consumer di fascia alta hanno 2 e talvolta 3 prese di alimentazione PCI-E a 8 pin. Assicurati di avere tanti cavi PCI-E a 8 pin indipendenti da 12 V collegati alla scheda quante sono le prese. Non utilizzare le 2 fessure a un\u2019estremit\xE0 dello stesso cavo (noto anche come cavo a spirale). Cio\xE8 se hai 2 prese sulla GPU, vuoi 2 cavi PCI-E a 8 pin che vanno dall\u2019alimentatore alla scheda e non uno che abbia 2 connettori PCI-E a 8 pin alla fine! In caso contrario, non otterrai tutte le prestazioni ufficiali."),ha=c(),pe=n("p"),Ut=r("Ciascun cavo di alimentazione PCI-E a 8 pin deve essere collegato a una guida da 12 V sul lato dell\u2019alimentatore e pu\xF2 fornire fino a 150 W di potenza."),Pa=c(),ce=n("p"),Nt=r("Alcune altre schede possono utilizzare connettori PCI-E a 12 pin e questi possono fornire fino a 500-600 W di potenza."),_a=c(),de=n("p"),Ct=r("Le schede di fascia bassa possono utilizzare connettori a 6 pin, che forniscono fino a 75 W di potenza."),ba=c(),ue=n("p"),Gt=r("Inoltre vuoi un alimentatore (PSU) di fascia alta che abbia una tensione stabile. Alcuni PSU di qualit\xE0 inferiore potrebbero non fornire alla scheda la tensione stabile di cui ha bisogno per funzionare al massimo."),wa=c(),me=n("p"),$t=r("E ovviamente l\u2019alimentatore deve avere abbastanza Watt inutilizzati per alimentare la scheda."),za=c(),X=n("p"),je=n("strong"),gt=r("Raffreddamento"),At=r(":"),Ea=c(),fe=n("p"),It=r("Quando una GPU si surriscalda, inizier\xE0 a rallentare e non fornir\xE0 le prestazioni mssimali e potrebbe persino spegnersi se diventasse troppo calda."),ka=c(),ve=n("p"),yt=r("\xC8 difficile dire l\u2019esatta temperatura migliore a cui aspirare quando una GPU \xE8 molto caricata, ma probabilmente qualsiasi cosa al di sotto di +80\xB0C va bene, ma pi\xF9 bassa \xE8 meglio - forse 70-75\xB0C \xE8 un intervallo eccellente in cui trovarsi. \xC8 probabile che il rallentamento inizi a circa 84-90\xB0C. Ma oltre alla limitazione delle prestazioni, una temperatura molto elevata prolungata \xE8 probabile che riduca la durata di una GPU."),Ua=c(),he=n("p"),Vt=r("Diamo quindi un\u2019occhiata a uno degli aspetti pi\xF9 importanti quando si hanno pi\xF9 GPU: la connettivit\xE0."),Na=c(),G=n("h3"),V=n("a"),Be=n("span"),P(M.$$.fragment),St=c(),Te=n("span"),Dt=r("Connettivit\xE0 multi-GPU"),Ca=c(),Pe=n("p"),Lt=r("Se utilizzi pi\xF9 GPU, il modo in cui le schede sono interconnesse pu\xF2 avere un enorme impatto sul tempo totale di allenamento. Se le GPU si trovano sullo stesso nodo fisico, puoi eseguire:"),Ga=c(),P(R.$$.fragment),$a=c(),_e=n("p"),xt=r("e ti dir\xE0 come sono interconnesse le GPU. Su una macchina con doppia GPU e collegata a NVLink, molto probabilmente vedrai qualcosa del tipo:"),ga=c(),P(W.$$.fragment),Aa=c(),be=n("p"),jt=r("su una macchina diversa senza NVLink potremmo vedere:"),Ia=c(),P(Q.$$.fragment),ya=c(),we=n("p"),Bt=r("Il rapporto include questa legenda:"),Va=c(),P(Y.$$.fragment),Sa=c(),h=n("p"),Tt=r("Quindi il primo rapporto "),He=n("code"),Ht=r("NV2"),qt=r(" ci dice che le GPU sono interconnesse con 2 NVLinks e nel secondo report "),qe=n("code"),Ot=r("PHB"),Xt=r(" abbiamo una tipica configurazione PCIe+Bridge a livello di consumatore."),Da=c(),ze=n("p"),Mt=r("Controlla che tipo di connettivit\xE0 hai sulla tua configurazione. Alcuni di questi renderanno la comunicazione tra le carte pi\xF9 veloce (es. NVLink), altri pi\xF9 lenta (es. PHB)."),La=c(),Ee=n("p"),Rt=r("A seconda del tipo di soluzione di scalabilit\xE0 utilizzata, la velocit\xE0 di connettivit\xE0 potrebbe avere un impatto maggiore o minore. Se le GPU devono sincronizzarsi raramente, come in DDP, l\u2019impatto di una connessione pi\xF9 lenta sar\xE0 meno significativo. Se le GPU devono scambiarsi messaggi spesso, come in ZeRO-DP, una connettivit\xE0 pi\xF9 veloce diventa estremamente importante per ottenere un addestramento pi\xF9 veloce."),xa=c(),$=n("h4"),S=n("a"),Oe=n("span"),P(F.$$.fragment),Wt=c(),Xe=n("span"),Qt=r("NVlink"),ja=c(),Z=n("p"),J=n("a"),Yt=r("NVLink"),Ft=r(" \xE8 un collegamento di comunicazione a corto raggio multilinea seriale basato su cavo sviluppato da Nvidia."),Ba=c(),D=n("p"),Zt=r("Ogni nuova generazione fornisce una larghezza di banda pi\xF9 veloce, ad es. ecco una citazione da "),K=n("a"),Jt=r("Nvidia Ampere GA102 GPU Architecture"),Kt=r(":"),Ta=c(),ke=n("blockquote"),Me=n("p"),ei=r(`Third-Generation NVLink\xAE
GA102 GPUs utilize NVIDIA\u2019s third-generation NVLink interface, which includes four x4 links,
with each link providing 14.0625 GB/sec bandwidth in each direction between two GPUs. Four
links provide 56.25 GB/sec bandwidth in each direction, and 112.5 GB/sec total bandwidth
between two GPUs. Two RTX 3090 GPUs can be connected together for SLI using NVLink.
(Note that 3-Way and 4-Way SLI configurations are not supported.)`),Ha=c(),f=n("p"),ai=r("Quindi pi\xF9 "),Re=n("code"),ti=r("X"),ii=r(" si ottiene nel rapporto di "),We=n("code"),ni=r("NVX"),oi=r(" nell\u2019output di "),Qe=n("code"),li=r("nvidia-smi topo -m"),si=r(", meglio \xE8. La generazione dipender\xE0 dall\u2019architettura della tua GPU."),qa=c(),Ue=n("p"),ri=r("Confrontiamo l\u2019esecuzione di un training del modello di linguaggio gpt2 su un piccolo campione di wikitext"),Oa=c(),Ne=n("p"),pi=r("I risultati sono:"),Xa=c(),L=n("table"),Ye=n("thead"),ee=n("tr"),Fe=n("th"),ci=r("NVlink"),di=c(),Ce=n("th"),ui=r("Time"),mi=c(),ae=n("tbody"),te=n("tr"),Ze=n("td"),fi=r("Y"),vi=c(),Ge=n("td"),hi=r("101s"),Pi=c(),ie=n("tr"),Je=n("td"),_i=r("N"),bi=c(),$e=n("td"),wi=r("131s"),Ma=c(),x=n("p"),zi=r("Puoi vedere che NVLink completa l\u2019addestramento circa il 23% pi\xF9 velocemente. Nel secondo benchmark utilizziamo "),Ke=n("code"),Ei=r("NCCL_P2P_DISABLE=1"),ki=r(" per dire alle GPU di non utilizzare NVLink."),Ra=c(),ge=n("p"),Ui=r("Ecco il codice benchmark completo e gli output:"),Wa=c(),P(ne.$$.fragment),Qa=c(),m=n("p"),Ni=r("Hardware: 2x TITAN RTX 24GB each + NVlink with 2 NVLinks ("),ea=n("code"),Ci=r("NV2"),Gi=r(" in "),aa=n("code"),$i=r("nvidia-smi topo -m"),gi=r(`)
Software: `),ta=n("code"),Ai=r("pytorch-1.8-to-be"),Ii=r(" + "),ia=n("code"),yi=r("cuda-11.0"),Vi=r(" / "),na=n("code"),Si=r("transformers==4.3.0.dev0"),this.h()},l(e){const i=Fn('[data-svelte="svelte-1phssyn"]',document.head);k=o(i,"META",{name:!0,content:!0}),i.forEach(a),sa=d(e),U=o(e,"H1",{class:!0});var Fa=l(U);g=o(Fa,"A",{id:!0,class:!0,href:!0});var Bi=l(g);Ie=o(Bi,"SPAN",{});var Ti=l(Ie);_(B.$$.fragment,Ti),Ti.forEach(a),Bi.forEach(a),pt=d(Fa),ye=o(Fa,"SPAN",{});var Hi=l(ye);ct=p(Hi,"Hardware ottimizzato per l'addestramento"),Hi.forEach(a),Fa.forEach(a),ra=d(e),A=o(e,"P",{});var Za=l(A);dt=p(Za,"L\u2019hardware utilizzato per eseguire l\u2019addestramento del modello e l\u2019inferenza pu\xF2 avere un grande effetto sulle prestazioni. Per un analisi approfondita delle GPUs, assicurati di dare un\u2019occhiata all\u2019eccellente "),T=o(Za,"A",{href:!0,rel:!0});var qi=l(T);ut=p(qi,"blog post"),qi.forEach(a),mt=p(Za," di Tim Dettmer."),Za.forEach(a),pa=d(e),oe=o(e,"P",{});var Oi=l(oe);ft=p(Oi,"Diamo un\u2019occhiata ad alcuni consigli pratici per la configurazione della GPU."),Oi.forEach(a),ca=d(e),N=o(e,"H2",{class:!0});var Ja=l(N);I=o(Ja,"A",{id:!0,class:!0,href:!0});var Xi=l(I);Ve=o(Xi,"SPAN",{});var Mi=l(Ve);_(H.$$.fragment,Mi),Mi.forEach(a),Xi.forEach(a),vt=d(Ja),Se=o(Ja,"SPAN",{});var Ri=l(Se);ht=p(Ri,"GPU"),Ri.forEach(a),Ja.forEach(a),da=p(e,`

Quando si addestrano modelli pi\xF9 grandi ci sono essenzialmente tre opzioni:
- GPUs piu' grandi
- Piu' GPUs
- Piu' CPU e piu' NVMe (scaricato da [DeepSpeed-Infinity](main_classes/deepspeed#nvme-support))
`),le=o(e,"P",{});var Wi=l(le);Pt=p(Wi,"Iniziamo dal caso in cui ci sia una singola GPU."),Wi.forEach(a),ua=d(e),C=o(e,"H3",{class:!0});var Ka=l(C);y=o(Ka,"A",{id:!0,class:!0,href:!0});var Qi=l(y);De=o(Qi,"SPAN",{});var Yi=l(De);_(q.$$.fragment,Yi),Yi.forEach(a),Qi.forEach(a),_t=d(Ka),Le=o(Ka,"SPAN",{});var Fi=l(Le);bt=p(Fi,"Potenza e Raffreddamento"),Fi.forEach(a),Ka.forEach(a),ma=d(e),se=o(e,"P",{});var Zi=l(se);wt=p(Zi,"Se hai acquistato una costosa GPU di fascia alta, assicurati di darle la potenza corretta e un raffreddamento sufficiente."),Zi.forEach(a),fa=d(e),O=o(e,"P",{});var Di=l(O);xe=o(Di,"STRONG",{});var Ji=l(xe);zt=p(Ji,"Potenza"),Ji.forEach(a),Et=p(Di,":"),Di.forEach(a),va=d(e),re=o(e,"P",{});var Ki=l(re);kt=p(Ki,"Alcune schede GPU consumer di fascia alta hanno 2 e talvolta 3 prese di alimentazione PCI-E a 8 pin. Assicurati di avere tanti cavi PCI-E a 8 pin indipendenti da 12 V collegati alla scheda quante sono le prese. Non utilizzare le 2 fessure a un\u2019estremit\xE0 dello stesso cavo (noto anche come cavo a spirale). Cio\xE8 se hai 2 prese sulla GPU, vuoi 2 cavi PCI-E a 8 pin che vanno dall\u2019alimentatore alla scheda e non uno che abbia 2 connettori PCI-E a 8 pin alla fine! In caso contrario, non otterrai tutte le prestazioni ufficiali."),Ki.forEach(a),ha=d(e),pe=o(e,"P",{});var en=l(pe);Ut=p(en,"Ciascun cavo di alimentazione PCI-E a 8 pin deve essere collegato a una guida da 12 V sul lato dell\u2019alimentatore e pu\xF2 fornire fino a 150 W di potenza."),en.forEach(a),Pa=d(e),ce=o(e,"P",{});var an=l(ce);Nt=p(an,"Alcune altre schede possono utilizzare connettori PCI-E a 12 pin e questi possono fornire fino a 500-600 W di potenza."),an.forEach(a),_a=d(e),de=o(e,"P",{});var tn=l(de);Ct=p(tn,"Le schede di fascia bassa possono utilizzare connettori a 6 pin, che forniscono fino a 75 W di potenza."),tn.forEach(a),ba=d(e),ue=o(e,"P",{});var nn=l(ue);Gt=p(nn,"Inoltre vuoi un alimentatore (PSU) di fascia alta che abbia una tensione stabile. Alcuni PSU di qualit\xE0 inferiore potrebbero non fornire alla scheda la tensione stabile di cui ha bisogno per funzionare al massimo."),nn.forEach(a),wa=d(e),me=o(e,"P",{});var on=l(me);$t=p(on,"E ovviamente l\u2019alimentatore deve avere abbastanza Watt inutilizzati per alimentare la scheda."),on.forEach(a),za=d(e),X=o(e,"P",{});var Li=l(X);je=o(Li,"STRONG",{});var ln=l(je);gt=p(ln,"Raffreddamento"),ln.forEach(a),At=p(Li,":"),Li.forEach(a),Ea=d(e),fe=o(e,"P",{});var sn=l(fe);It=p(sn,"Quando una GPU si surriscalda, inizier\xE0 a rallentare e non fornir\xE0 le prestazioni mssimali e potrebbe persino spegnersi se diventasse troppo calda."),sn.forEach(a),ka=d(e),ve=o(e,"P",{});var rn=l(ve);yt=p(rn,"\xC8 difficile dire l\u2019esatta temperatura migliore a cui aspirare quando una GPU \xE8 molto caricata, ma probabilmente qualsiasi cosa al di sotto di +80\xB0C va bene, ma pi\xF9 bassa \xE8 meglio - forse 70-75\xB0C \xE8 un intervallo eccellente in cui trovarsi. \xC8 probabile che il rallentamento inizi a circa 84-90\xB0C. Ma oltre alla limitazione delle prestazioni, una temperatura molto elevata prolungata \xE8 probabile che riduca la durata di una GPU."),rn.forEach(a),Ua=d(e),he=o(e,"P",{});var pn=l(he);Vt=p(pn,"Diamo quindi un\u2019occhiata a uno degli aspetti pi\xF9 importanti quando si hanno pi\xF9 GPU: la connettivit\xE0."),pn.forEach(a),Na=d(e),G=o(e,"H3",{class:!0});var et=l(G);V=o(et,"A",{id:!0,class:!0,href:!0});var cn=l(V);Be=o(cn,"SPAN",{});var dn=l(Be);_(M.$$.fragment,dn),dn.forEach(a),cn.forEach(a),St=d(et),Te=o(et,"SPAN",{});var un=l(Te);Dt=p(un,"Connettivit\xE0 multi-GPU"),un.forEach(a),et.forEach(a),Ca=d(e),Pe=o(e,"P",{});var mn=l(Pe);Lt=p(mn,"Se utilizzi pi\xF9 GPU, il modo in cui le schede sono interconnesse pu\xF2 avere un enorme impatto sul tempo totale di allenamento. Se le GPU si trovano sullo stesso nodo fisico, puoi eseguire:"),mn.forEach(a),Ga=d(e),_(R.$$.fragment,e),$a=d(e),_e=o(e,"P",{});var fn=l(_e);xt=p(fn,"e ti dir\xE0 come sono interconnesse le GPU. Su una macchina con doppia GPU e collegata a NVLink, molto probabilmente vedrai qualcosa del tipo:"),fn.forEach(a),ga=d(e),_(W.$$.fragment,e),Aa=d(e),be=o(e,"P",{});var vn=l(be);jt=p(vn,"su una macchina diversa senza NVLink potremmo vedere:"),vn.forEach(a),Ia=d(e),_(Q.$$.fragment,e),ya=d(e),we=o(e,"P",{});var hn=l(we);Bt=p(hn,"Il rapporto include questa legenda:"),hn.forEach(a),Va=d(e),_(Y.$$.fragment,e),Sa=d(e),h=o(e,"P",{});var Ae=l(h);Tt=p(Ae,"Quindi il primo rapporto "),He=o(Ae,"CODE",{});var Pn=l(He);Ht=p(Pn,"NV2"),Pn.forEach(a),qt=p(Ae," ci dice che le GPU sono interconnesse con 2 NVLinks e nel secondo report "),qe=o(Ae,"CODE",{});var _n=l(qe);Ot=p(_n,"PHB"),_n.forEach(a),Xt=p(Ae," abbiamo una tipica configurazione PCIe+Bridge a livello di consumatore."),Ae.forEach(a),Da=d(e),ze=o(e,"P",{});var bn=l(ze);Mt=p(bn,"Controlla che tipo di connettivit\xE0 hai sulla tua configurazione. Alcuni di questi renderanno la comunicazione tra le carte pi\xF9 veloce (es. NVLink), altri pi\xF9 lenta (es. PHB)."),bn.forEach(a),La=d(e),Ee=o(e,"P",{});var wn=l(Ee);Rt=p(wn,"A seconda del tipo di soluzione di scalabilit\xE0 utilizzata, la velocit\xE0 di connettivit\xE0 potrebbe avere un impatto maggiore o minore. Se le GPU devono sincronizzarsi raramente, come in DDP, l\u2019impatto di una connessione pi\xF9 lenta sar\xE0 meno significativo. Se le GPU devono scambiarsi messaggi spesso, come in ZeRO-DP, una connettivit\xE0 pi\xF9 veloce diventa estremamente importante per ottenere un addestramento pi\xF9 veloce."),wn.forEach(a),xa=d(e),$=o(e,"H4",{class:!0});var at=l($);S=o(at,"A",{id:!0,class:!0,href:!0});var zn=l(S);Oe=o(zn,"SPAN",{});var En=l(Oe);_(F.$$.fragment,En),En.forEach(a),zn.forEach(a),Wt=d(at),Xe=o(at,"SPAN",{});var kn=l(Xe);Qt=p(kn,"NVlink"),kn.forEach(a),at.forEach(a),ja=d(e),Z=o(e,"P",{});var xi=l(Z);J=o(xi,"A",{href:!0,rel:!0});var Un=l(J);Yt=p(Un,"NVLink"),Un.forEach(a),Ft=p(xi," \xE8 un collegamento di comunicazione a corto raggio multilinea seriale basato su cavo sviluppato da Nvidia."),xi.forEach(a),Ba=d(e),D=o(e,"P",{});var tt=l(D);Zt=p(tt,"Ogni nuova generazione fornisce una larghezza di banda pi\xF9 veloce, ad es. ecco una citazione da "),K=o(tt,"A",{href:!0,rel:!0});var Nn=l(K);Jt=p(Nn,"Nvidia Ampere GA102 GPU Architecture"),Nn.forEach(a),Kt=p(tt,":"),tt.forEach(a),Ta=d(e),ke=o(e,"BLOCKQUOTE",{});var Cn=l(ke);Me=o(Cn,"P",{});var Gn=l(Me);ei=p(Gn,`Third-Generation NVLink\xAE
GA102 GPUs utilize NVIDIA\u2019s third-generation NVLink interface, which includes four x4 links,
with each link providing 14.0625 GB/sec bandwidth in each direction between two GPUs. Four
links provide 56.25 GB/sec bandwidth in each direction, and 112.5 GB/sec total bandwidth
between two GPUs. Two RTX 3090 GPUs can be connected together for SLI using NVLink.
(Note that 3-Way and 4-Way SLI configurations are not supported.)`),Gn.forEach(a),Cn.forEach(a),Ha=d(e),f=o(e,"P",{});var j=l(f);ai=p(j,"Quindi pi\xF9 "),Re=o(j,"CODE",{});var $n=l(Re);ti=p($n,"X"),$n.forEach(a),ii=p(j," si ottiene nel rapporto di "),We=o(j,"CODE",{});var gn=l(We);ni=p(gn,"NVX"),gn.forEach(a),oi=p(j," nell\u2019output di "),Qe=o(j,"CODE",{});var An=l(Qe);li=p(An,"nvidia-smi topo -m"),An.forEach(a),si=p(j,", meglio \xE8. La generazione dipender\xE0 dall\u2019architettura della tua GPU."),j.forEach(a),qa=d(e),Ue=o(e,"P",{});var In=l(Ue);ri=p(In,"Confrontiamo l\u2019esecuzione di un training del modello di linguaggio gpt2 su un piccolo campione di wikitext"),In.forEach(a),Oa=d(e),Ne=o(e,"P",{});var yn=l(Ne);pi=p(yn,"I risultati sono:"),yn.forEach(a),Xa=d(e),L=o(e,"TABLE",{});var it=l(L);Ye=o(it,"THEAD",{});var Vn=l(Ye);ee=o(Vn,"TR",{});var nt=l(ee);Fe=o(nt,"TH",{});var Sn=l(Fe);ci=p(Sn,"NVlink"),Sn.forEach(a),di=d(nt),Ce=o(nt,"TH",{align:!0});var Dn=l(Ce);ui=p(Dn,"Time"),Dn.forEach(a),nt.forEach(a),Vn.forEach(a),mi=d(it),ae=o(it,"TBODY",{});var ot=l(ae);te=o(ot,"TR",{});var lt=l(te);Ze=o(lt,"TD",{});var Ln=l(Ze);fi=p(Ln,"Y"),Ln.forEach(a),vi=d(lt),Ge=o(lt,"TD",{align:!0});var xn=l(Ge);hi=p(xn,"101s"),xn.forEach(a),lt.forEach(a),Pi=d(ot),ie=o(ot,"TR",{});var st=l(ie);Je=o(st,"TD",{});var jn=l(Je);_i=p(jn,"N"),jn.forEach(a),bi=d(st),$e=o(st,"TD",{align:!0});var Bn=l($e);wi=p(Bn,"131s"),Bn.forEach(a),st.forEach(a),ot.forEach(a),it.forEach(a),Ma=d(e),x=o(e,"P",{});var rt=l(x);zi=p(rt,"Puoi vedere che NVLink completa l\u2019addestramento circa il 23% pi\xF9 velocemente. Nel secondo benchmark utilizziamo "),Ke=o(rt,"CODE",{});var Tn=l(Ke);Ei=p(Tn,"NCCL_P2P_DISABLE=1"),Tn.forEach(a),ki=p(rt," per dire alle GPU di non utilizzare NVLink."),rt.forEach(a),Ra=d(e),ge=o(e,"P",{});var Hn=l(ge);Ui=p(Hn,"Ecco il codice benchmark completo e gli output:"),Hn.forEach(a),Wa=d(e),_(ne.$$.fragment,e),Qa=d(e),m=o(e,"P",{});var v=l(m);Ni=p(v,"Hardware: 2x TITAN RTX 24GB each + NVlink with 2 NVLinks ("),ea=o(v,"CODE",{});var qn=l(ea);Ci=p(qn,"NV2"),qn.forEach(a),Gi=p(v," in "),aa=o(v,"CODE",{});var On=l(aa);$i=p(On,"nvidia-smi topo -m"),On.forEach(a),gi=p(v,`)
Software: `),ta=o(v,"CODE",{});var Xn=l(ta);Ai=p(Xn,"pytorch-1.8-to-be"),Xn.forEach(a),Ii=p(v," + "),ia=o(v,"CODE",{});var Mn=l(ia);yi=p(Mn,"cuda-11.0"),Mn.forEach(a),Vi=p(v," / "),na=o(v,"CODE",{});var Rn=l(na);Si=p(Rn,"transformers==4.3.0.dev0"),Rn.forEach(a),v.forEach(a),this.h()},h(){u(k,"name","hf:doc:metadata"),u(k,"content",JSON.stringify(eo)),u(g,"id","hardware-ottimizzato-per-laddestramento"),u(g,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(g,"href","#hardware-ottimizzato-per-laddestramento"),u(U,"class","relative group"),u(T,"href","https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/"),u(T,"rel","nofollow"),u(I,"id","gpu"),u(I,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(I,"href","#gpu"),u(N,"class","relative group"),u(y,"id","potenza-e-raffreddamento"),u(y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(y,"href","#potenza-e-raffreddamento"),u(C,"class","relative group"),u(V,"id","connettivit-multigpu"),u(V,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(V,"href","#connettivit-multigpu"),u(G,"class","relative group"),u(S,"id","nvlink"),u(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(S,"href","#nvlink"),u($,"class","relative group"),u(J,"href","https://en.wikipedia.org/wiki/NVLink"),u(J,"rel","nofollow"),u(K,"href","https://www.nvidia.com/content/dam/en-zz/Solutions/geforce/ampere/pdf/NVIDIA-ampere-GA102-GPU-Architecture-Whitepaper-V1.pdf"),u(K,"rel","nofollow"),u(Ce,"align","right"),u(Ge,"align","right"),u($e,"align","right")},m(e,i){t(document.head,k),s(e,sa,i),s(e,U,i),t(U,g),t(g,Ie),b(B,Ie,null),t(U,pt),t(U,ye),t(ye,ct),s(e,ra,i),s(e,A,i),t(A,dt),t(A,T),t(T,ut),t(A,mt),s(e,pa,i),s(e,oe,i),t(oe,ft),s(e,ca,i),s(e,N,i),t(N,I),t(I,Ve),b(H,Ve,null),t(N,vt),t(N,Se),t(Se,ht),s(e,da,i),s(e,le,i),t(le,Pt),s(e,ua,i),s(e,C,i),t(C,y),t(y,De),b(q,De,null),t(C,_t),t(C,Le),t(Le,bt),s(e,ma,i),s(e,se,i),t(se,wt),s(e,fa,i),s(e,O,i),t(O,xe),t(xe,zt),t(O,Et),s(e,va,i),s(e,re,i),t(re,kt),s(e,ha,i),s(e,pe,i),t(pe,Ut),s(e,Pa,i),s(e,ce,i),t(ce,Nt),s(e,_a,i),s(e,de,i),t(de,Ct),s(e,ba,i),s(e,ue,i),t(ue,Gt),s(e,wa,i),s(e,me,i),t(me,$t),s(e,za,i),s(e,X,i),t(X,je),t(je,gt),t(X,At),s(e,Ea,i),s(e,fe,i),t(fe,It),s(e,ka,i),s(e,ve,i),t(ve,yt),s(e,Ua,i),s(e,he,i),t(he,Vt),s(e,Na,i),s(e,G,i),t(G,V),t(V,Be),b(M,Be,null),t(G,St),t(G,Te),t(Te,Dt),s(e,Ca,i),s(e,Pe,i),t(Pe,Lt),s(e,Ga,i),b(R,e,i),s(e,$a,i),s(e,_e,i),t(_e,xt),s(e,ga,i),b(W,e,i),s(e,Aa,i),s(e,be,i),t(be,jt),s(e,Ia,i),b(Q,e,i),s(e,ya,i),s(e,we,i),t(we,Bt),s(e,Va,i),b(Y,e,i),s(e,Sa,i),s(e,h,i),t(h,Tt),t(h,He),t(He,Ht),t(h,qt),t(h,qe),t(qe,Ot),t(h,Xt),s(e,Da,i),s(e,ze,i),t(ze,Mt),s(e,La,i),s(e,Ee,i),t(Ee,Rt),s(e,xa,i),s(e,$,i),t($,S),t(S,Oe),b(F,Oe,null),t($,Wt),t($,Xe),t(Xe,Qt),s(e,ja,i),s(e,Z,i),t(Z,J),t(J,Yt),t(Z,Ft),s(e,Ba,i),s(e,D,i),t(D,Zt),t(D,K),t(K,Jt),t(D,Kt),s(e,Ta,i),s(e,ke,i),t(ke,Me),t(Me,ei),s(e,Ha,i),s(e,f,i),t(f,ai),t(f,Re),t(Re,ti),t(f,ii),t(f,We),t(We,ni),t(f,oi),t(f,Qe),t(Qe,li),t(f,si),s(e,qa,i),s(e,Ue,i),t(Ue,ri),s(e,Oa,i),s(e,Ne,i),t(Ne,pi),s(e,Xa,i),s(e,L,i),t(L,Ye),t(Ye,ee),t(ee,Fe),t(Fe,ci),t(ee,di),t(ee,Ce),t(Ce,ui),t(L,mi),t(L,ae),t(ae,te),t(te,Ze),t(Ze,fi),t(te,vi),t(te,Ge),t(Ge,hi),t(ae,Pi),t(ae,ie),t(ie,Je),t(Je,_i),t(ie,bi),t(ie,$e),t($e,wi),s(e,Ma,i),s(e,x,i),t(x,zi),t(x,Ke),t(Ke,Ei),t(x,ki),s(e,Ra,i),s(e,ge,i),t(ge,Ui),s(e,Wa,i),b(ne,e,i),s(e,Qa,i),s(e,m,i),t(m,Ni),t(m,ea),t(ea,Ci),t(m,Gi),t(m,aa),t(aa,$i),t(m,gi),t(m,ta),t(ta,Ai),t(m,Ii),t(m,ia),t(ia,yi),t(m,Vi),t(m,na),t(na,Si),Ya=!0},p:Zn,i(e){Ya||(w(B.$$.fragment,e),w(H.$$.fragment,e),w(q.$$.fragment,e),w(M.$$.fragment,e),w(R.$$.fragment,e),w(W.$$.fragment,e),w(Q.$$.fragment,e),w(Y.$$.fragment,e),w(F.$$.fragment,e),w(ne.$$.fragment,e),Ya=!0)},o(e){z(B.$$.fragment,e),z(H.$$.fragment,e),z(q.$$.fragment,e),z(M.$$.fragment,e),z(R.$$.fragment,e),z(W.$$.fragment,e),z(Q.$$.fragment,e),z(Y.$$.fragment,e),z(F.$$.fragment,e),z(ne.$$.fragment,e),Ya=!1},d(e){a(k),e&&a(sa),e&&a(U),E(B),e&&a(ra),e&&a(A),e&&a(pa),e&&a(oe),e&&a(ca),e&&a(N),E(H),e&&a(da),e&&a(le),e&&a(ua),e&&a(C),E(q),e&&a(ma),e&&a(se),e&&a(fa),e&&a(O),e&&a(va),e&&a(re),e&&a(ha),e&&a(pe),e&&a(Pa),e&&a(ce),e&&a(_a),e&&a(de),e&&a(ba),e&&a(ue),e&&a(wa),e&&a(me),e&&a(za),e&&a(X),e&&a(Ea),e&&a(fe),e&&a(ka),e&&a(ve),e&&a(Ua),e&&a(he),e&&a(Na),e&&a(G),E(M),e&&a(Ca),e&&a(Pe),e&&a(Ga),E(R,e),e&&a($a),e&&a(_e),e&&a(ga),E(W,e),e&&a(Aa),e&&a(be),e&&a(Ia),E(Q,e),e&&a(ya),e&&a(we),e&&a(Va),E(Y,e),e&&a(Sa),e&&a(h),e&&a(Da),e&&a(ze),e&&a(La),e&&a(Ee),e&&a(xa),e&&a($),E(F),e&&a(ja),e&&a(Z),e&&a(Ba),e&&a(D),e&&a(Ta),e&&a(ke),e&&a(Ha),e&&a(f),e&&a(qa),e&&a(Ue),e&&a(Oa),e&&a(Ne),e&&a(Xa),e&&a(L),e&&a(Ma),e&&a(x),e&&a(Ra),e&&a(ge),e&&a(Wa),E(ne,e),e&&a(Qa),e&&a(m)}}}const eo={local:"hardware-ottimizzato-per-laddestramento",sections:[{local:"gpu",sections:[{local:"potenza-e-raffreddamento",title:"Potenza e Raffreddamento"},{local:"connettivit-multigpu",sections:[{local:"nvlink",title:"NVlink"}],title:"Connettivit\xE0 multi-GPU"}],title:"GPU"}],title:"Hardware ottimizzato per l'addestramento"};function ao(ji){return Jn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class oo extends Wn{constructor(k){super();Qn(this,k,ao,Kn,Yn,{})}}export{oo as default,eo as metadata};
