import{S as jl,i as kl,s as wl,e as o,k as f,w as E,t as s,M as Dl,c as r,d as a,m,a as l,x as j,h as i,b,G as t,g as p,y as k,q as w,o as D,B as C,v as Cl,L as Ws}from"../chunks/vendor-hf-doc-builder.js";import{T as Ns}from"../chunks/Tip-hf-doc-builder.js";import{I as dt}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as L}from"../chunks/CodeBlock-hf-doc-builder.js";import{F as El,M as Rs}from"../chunks/Markdown-hf-doc-builder.js";import"../chunks/IconTensorflow-hf-doc-builder.js";function yl(V){let c,_,u,g,z;return{c(){c=o("p"),_=s("Puoi anche salvare il file di configurazione come dizionario oppure come la differenza tra gli attributi della tua configurazione personalizzata e gli attributi della configurazione predefinita! Guarda la documentazione "),u=o("a"),g=s("configuration"),z=s(" per pi\xF9 dettagli."),this.h()},l($){c=r($,"P",{});var v=l(c);_=i(v,"Puoi anche salvare il file di configurazione come dizionario oppure come la differenza tra gli attributi della tua configurazione personalizzata e gli attributi della configurazione predefinita! Guarda la documentazione "),u=r(v,"A",{href:!0});var T=l(u);g=i(T,"configuration"),T.forEach(a),z=i(v," per pi\xF9 dettagli."),v.forEach(a),this.h()},h(){b(u,"href","main_classes/configuration")},m($,v){p($,c,v),t(c,_),t(c,u),t(u,g),t(c,z)},d($){$&&a(c)}}}function Tl(V){let c,_,u,g,z,$,v,T,q,I,y,S,x,O,P,M,h,B,N,A,W;return g=new L({props:{code:`from transformers import DistilBertModel

my_config = DistilBertConfig.from_pretrained("./your_model_save_path/my_config.json")
model = DistilBertModel(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertModel

<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;./your_model_save_path/my_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertModel(my_config)`}}),P=new L({props:{code:'model = DistilBertModel.from_pretrained("distilbert-base-uncased")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)'}}),A=new L({props:{code:'model = DistilBertModel.from_pretrained("distilbert-base-uncased", config=my_config)',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>, config=my_config)'}}),{c(){c=o("p"),_=s("Carica gli attributi della tua configurazione personalizzata nel modello:"),u=f(),E(g.$$.fragment),z=f(),$=o("p"),v=s("Questo crea modelli con valori casuali invece di pesi pre-allenati. Non sarai in grado di usare questo modello per niente di utile finch\xE9 non lo alleni. L\u2019allenamento \xE8 un processo costoso e che richiede tempo . Generalmente \xE8 meglio usare un modello pre-allenato per ottenere risultati migliori velocemente, utilizzando solo una frazione delle risorse neccesarie per l\u2019allenamento."),T=f(),q=o("p"),I=s("Crea un modello pre-allenato con "),y=o("code"),S=s("from_pretrained()"),x=s(":"),O=f(),E(P.$$.fragment),M=f(),h=o("p"),B=s("Quando carichi pesi pre-allenati, la configurazione del modello predefinito \xE8 automaticamente caricata se il modello \xE8 fornito da \u{1F917} Transformers. Tuttavia, puoi ancora sostituire gli attributi - alcuni o tutti - di configurazione del modello predefinito con i tuoi se lo desideri:"),N=f(),E(A.$$.fragment)},l(d){c=r(d,"P",{});var F=l(c);_=i(F,"Carica gli attributi della tua configurazione personalizzata nel modello:"),F.forEach(a),u=m(d),j(g.$$.fragment,d),z=m(d),$=r(d,"P",{});var Q=l($);v=i(Q,"Questo crea modelli con valori casuali invece di pesi pre-allenati. Non sarai in grado di usare questo modello per niente di utile finch\xE9 non lo alleni. L\u2019allenamento \xE8 un processo costoso e che richiede tempo . Generalmente \xE8 meglio usare un modello pre-allenato per ottenere risultati migliori velocemente, utilizzando solo una frazione delle risorse neccesarie per l\u2019allenamento."),Q.forEach(a),T=m(d),q=r(d,"P",{});var G=l(q);I=i(G,"Crea un modello pre-allenato con "),y=r(G,"CODE",{});var ae=l(y);S=i(ae,"from_pretrained()"),ae.forEach(a),x=i(G,":"),G.forEach(a),O=m(d),j(P.$$.fragment,d),M=m(d),h=r(d,"P",{});var se=l(h);B=i(se,"Quando carichi pesi pre-allenati, la configurazione del modello predefinito \xE8 automaticamente caricata se il modello \xE8 fornito da \u{1F917} Transformers. Tuttavia, puoi ancora sostituire gli attributi - alcuni o tutti - di configurazione del modello predefinito con i tuoi se lo desideri:"),se.forEach(a),N=m(d),j(A.$$.fragment,d)},m(d,F){p(d,c,F),t(c,_),p(d,u,F),k(g,d,F),p(d,z,F),p(d,$,F),t($,v),p(d,T,F),p(d,q,F),t(q,I),t(q,y),t(y,S),t(q,x),p(d,O,F),k(P,d,F),p(d,M,F),p(d,h,F),t(h,B),p(d,N,F),k(A,d,F),W=!0},p:Ws,i(d){W||(w(g.$$.fragment,d),w(P.$$.fragment,d),w(A.$$.fragment,d),W=!0)},o(d){D(g.$$.fragment,d),D(P.$$.fragment,d),D(A.$$.fragment,d),W=!1},d(d){d&&a(c),d&&a(u),C(g,d),d&&a(z),d&&a($),d&&a(T),d&&a(q),d&&a(O),C(P,d),d&&a(M),d&&a(h),d&&a(N),C(A,d)}}}function Pl(V){let c,_;return c=new Rs({props:{$$slots:{default:[Tl]},$$scope:{ctx:V}}}),{c(){E(c.$$.fragment)},l(u){j(c.$$.fragment,u)},m(u,g){k(c,u,g),_=!0},p(u,g){const z={};g&2&&(z.$$scope={dirty:g,ctx:u}),c.$set(z)},i(u){_||(w(c.$$.fragment,u),_=!0)},o(u){D(c.$$.fragment,u),_=!1},d(u){C(c,u)}}}function Fl(V){let c,_,u,g,z,$,v,T,q,I,y,S,x,O,P,M,h,B,N,A,W;return g=new L({props:{code:`from transformers import TFDistilBertModel

my_config = DistilBertConfig.from_pretrained("./your_model_save_path/my_config.json")
tf_model = TFDistilBertModel(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFDistilBertModel

<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;./your_model_save_path/my_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertModel(my_config)`}}),P=new L({props:{code:'tf_model = TFDistilBertModel.from_pretrained("distilbert-base-uncased")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)'}}),A=new L({props:{code:'tf_model = TFDistilBertModel.from_pretrained("distilbert-base-uncased", config=my_config)',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>, config=my_config)'}}),{c(){c=o("p"),_=s("Carica gli attributi di configurazione personalizzati nel modello:"),u=f(),E(g.$$.fragment),z=f(),$=o("p"),v=s("Questo crea modelli con valori casuali invece di pesi pre-allenati. Non sarai in grado di usare questo modello per niente di utile finch\xE9 non lo alleni. L\u2019allenamento \xE8 un processo costoso e che richiede tempo . Generalmente \xE8 meglio usare un modello pre-allenato per ottenere risultati migliori velocemente, utilizzando solo una frazione delle risorse neccesarie per l\u2019allenamento."),T=f(),q=o("p"),I=s("Crea un modello pre-allenoto con "),y=o("code"),S=s("from_pretrained()"),x=s(":"),O=f(),E(P.$$.fragment),M=f(),h=o("p"),B=s("Quando carichi pesi pre-allenati, la configurazione del modello predefinito \xE8 automaticamente caricato se il modello \xE8 fornito da \u{1F917} Transformers. Tuttavia, puoi ancora sostituire gli attributi - alcuni o tutti - di configurazione del modello predefinito con i tuoi se lo desideri:"),N=f(),E(A.$$.fragment)},l(d){c=r(d,"P",{});var F=l(c);_=i(F,"Carica gli attributi di configurazione personalizzati nel modello:"),F.forEach(a),u=m(d),j(g.$$.fragment,d),z=m(d),$=r(d,"P",{});var Q=l($);v=i(Q,"Questo crea modelli con valori casuali invece di pesi pre-allenati. Non sarai in grado di usare questo modello per niente di utile finch\xE9 non lo alleni. L\u2019allenamento \xE8 un processo costoso e che richiede tempo . Generalmente \xE8 meglio usare un modello pre-allenato per ottenere risultati migliori velocemente, utilizzando solo una frazione delle risorse neccesarie per l\u2019allenamento."),Q.forEach(a),T=m(d),q=r(d,"P",{});var G=l(q);I=i(G,"Crea un modello pre-allenoto con "),y=r(G,"CODE",{});var ae=l(y);S=i(ae,"from_pretrained()"),ae.forEach(a),x=i(G,":"),G.forEach(a),O=m(d),j(P.$$.fragment,d),M=m(d),h=r(d,"P",{});var se=l(h);B=i(se,"Quando carichi pesi pre-allenati, la configurazione del modello predefinito \xE8 automaticamente caricato se il modello \xE8 fornito da \u{1F917} Transformers. Tuttavia, puoi ancora sostituire gli attributi - alcuni o tutti - di configurazione del modello predefinito con i tuoi se lo desideri:"),se.forEach(a),N=m(d),j(A.$$.fragment,d)},m(d,F){p(d,c,F),t(c,_),p(d,u,F),k(g,d,F),p(d,z,F),p(d,$,F),t($,v),p(d,T,F),p(d,q,F),t(q,I),t(q,y),t(y,S),t(q,x),p(d,O,F),k(P,d,F),p(d,M,F),p(d,h,F),t(h,B),p(d,N,F),k(A,d,F),W=!0},p:Ws,i(d){W||(w(g.$$.fragment,d),w(P.$$.fragment,d),w(A.$$.fragment,d),W=!0)},o(d){D(g.$$.fragment,d),D(P.$$.fragment,d),D(A.$$.fragment,d),W=!1},d(d){d&&a(c),d&&a(u),C(g,d),d&&a(z),d&&a($),d&&a(T),d&&a(q),d&&a(O),C(P,d),d&&a(M),d&&a(h),d&&a(N),C(A,d)}}}function Bl(V){let c,_;return c=new Rs({props:{$$slots:{default:[Fl]},$$scope:{ctx:V}}}),{c(){E(c.$$.fragment)},l(u){j(c.$$.fragment,u)},m(u,g){k(c,u,g),_=!0},p(u,g){const z={};g&2&&(z.$$scope={dirty:g,ctx:u}),c.$set(z)},i(u){_||(w(c.$$.fragment,u),_=!0)},o(u){D(c.$$.fragment,u),_=!1},d(u){C(c,u)}}}function xl(V){let c,_,u,g,z,$,v,T,q,I,y,S,x,O,P,M;return v=new L({props:{code:`from transformers import DistilBertForSequenceClassification

model = DistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),P=new L({props:{code:`from transformers import DistilBertForQuestionAnswering

model = DistilBertForQuestionAnswering.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),{c(){c=o("p"),_=s("Per esempio, "),u=o("code"),g=s("DistilBertForSequenceClassification"),z=s(" \xE8 un modello DistilBERT base con una testa di classificazione per sequenze. La sequenza di classificazione head \xE8 uno strato lineare sopra gli output ragruppati."),$=f(),E(v.$$.fragment),T=f(),q=o("p"),I=s("Riutilizza facilmente questo checkpoint per un\u2019altra attivit\xE0 passando ad un model head differente. Per un attivit\xE0 di risposta alle domande, utilizzerai il model head "),y=o("code"),S=s("DistilBertForQuestionAnswering"),x=s(". La head per compiti di question answering \xE8 simile alla classificazione di sequenza head tranne per il fatto che \xE8 uno strato lineare sopra l\u2019output degli stati nascosti (hidden states in inglese)"),O=f(),E(P.$$.fragment)},l(h){c=r(h,"P",{});var B=l(c);_=i(B,"Per esempio, "),u=r(B,"CODE",{});var N=l(u);g=i(N,"DistilBertForSequenceClassification"),N.forEach(a),z=i(B," \xE8 un modello DistilBERT base con una testa di classificazione per sequenze. La sequenza di classificazione head \xE8 uno strato lineare sopra gli output ragruppati."),B.forEach(a),$=m(h),j(v.$$.fragment,h),T=m(h),q=r(h,"P",{});var A=l(q);I=i(A,"Riutilizza facilmente questo checkpoint per un\u2019altra attivit\xE0 passando ad un model head differente. Per un attivit\xE0 di risposta alle domande, utilizzerai il model head "),y=r(A,"CODE",{});var W=l(y);S=i(W,"DistilBertForQuestionAnswering"),W.forEach(a),x=i(A,". La head per compiti di question answering \xE8 simile alla classificazione di sequenza head tranne per il fatto che \xE8 uno strato lineare sopra l\u2019output degli stati nascosti (hidden states in inglese)"),A.forEach(a),O=m(h),j(P.$$.fragment,h)},m(h,B){p(h,c,B),t(c,_),t(c,u),t(u,g),t(c,z),p(h,$,B),k(v,h,B),p(h,T,B),p(h,q,B),t(q,I),t(q,y),t(y,S),t(q,x),p(h,O,B),k(P,h,B),M=!0},p:Ws,i(h){M||(w(v.$$.fragment,h),w(P.$$.fragment,h),M=!0)},o(h){D(v.$$.fragment,h),D(P.$$.fragment,h),M=!1},d(h){h&&a(c),h&&a($),C(v,h),h&&a(T),h&&a(q),h&&a(O),C(P,h)}}}function Al(V){let c,_;return c=new Rs({props:{$$slots:{default:[xl]},$$scope:{ctx:V}}}),{c(){E(c.$$.fragment)},l(u){j(c.$$.fragment,u)},m(u,g){k(c,u,g),_=!0},p(u,g){const z={};g&2&&(z.$$scope={dirty:g,ctx:u}),c.$set(z)},i(u){_||(w(c.$$.fragment,u),_=!0)},o(u){D(c.$$.fragment,u),_=!1},d(u){C(c,u)}}}function Ol(V){let c,_,u,g,z,$,v,T,q,I,y,S,x,O,P,M;return v=new L({props:{code:`from transformers import TFDistilBertForSequenceClassification

tf_model = TFDistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFDistilBertForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),P=new L({props:{code:`from transformers import TFDistilBertForQuestionAnswering

tf_model = TFDistilBertForQuestionAnswering.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFDistilBertForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),{c(){c=o("p"),_=s("Per esempio, "),u=o("code"),g=s("TFDistilBertForSequenceClassification"),z=s(" \xE8 un modello DistilBERT base con classificazione di sequenza head. La classificazione di sequenza head \xE8 uno strato lineare sopra gli output raggruppati."),$=f(),E(v.$$.fragment),T=f(),q=o("p"),I=s("Riutilizza facilmente questo checkpoint per un altra attivit\xE0 passando ad un modello head diverso. Per un attivit\xE0 di risposta alle domande, utilizzerai il model head "),y=o("code"),S=s("TFDistilBertForQuestionAnswering"),x=s(". Il head di risposta alle domande \xE8 simile alla sequenza di classificazione head tranne per il fatto che \xE8 uno strato lineare sopra l\u2019output degli stati nascosti (hidden states in inglese)"),O=f(),E(P.$$.fragment)},l(h){c=r(h,"P",{});var B=l(c);_=i(B,"Per esempio, "),u=r(B,"CODE",{});var N=l(u);g=i(N,"TFDistilBertForSequenceClassification"),N.forEach(a),z=i(B," \xE8 un modello DistilBERT base con classificazione di sequenza head. La classificazione di sequenza head \xE8 uno strato lineare sopra gli output raggruppati."),B.forEach(a),$=m(h),j(v.$$.fragment,h),T=m(h),q=r(h,"P",{});var A=l(q);I=i(A,"Riutilizza facilmente questo checkpoint per un altra attivit\xE0 passando ad un modello head diverso. Per un attivit\xE0 di risposta alle domande, utilizzerai il model head "),y=r(A,"CODE",{});var W=l(y);S=i(W,"TFDistilBertForQuestionAnswering"),W.forEach(a),x=i(A,". Il head di risposta alle domande \xE8 simile alla sequenza di classificazione head tranne per il fatto che \xE8 uno strato lineare sopra l\u2019output degli stati nascosti (hidden states in inglese)"),A.forEach(a),O=m(h),j(P.$$.fragment,h)},m(h,B){p(h,c,B),t(c,_),t(c,u),t(u,g),t(c,z),p(h,$,B),k(v,h,B),p(h,T,B),p(h,q,B),t(q,I),t(q,y),t(y,S),t(q,x),p(h,O,B),k(P,h,B),M=!0},p:Ws,i(h){M||(w(v.$$.fragment,h),w(P.$$.fragment,h),M=!0)},o(h){D(v.$$.fragment,h),D(P.$$.fragment,h),M=!1},d(h){h&&a(c),h&&a($),C(v,h),h&&a(T),h&&a(q),h&&a(O),C(P,h)}}}function Ml(V){let c,_;return c=new Rs({props:{$$slots:{default:[Ol]},$$scope:{ctx:V}}}),{c(){E(c.$$.fragment)},l(u){j(c.$$.fragment,u)},m(u,g){k(c,u,g),_=!0},p(u,g){const z={};g&2&&(z.$$scope={dirty:g,ctx:u}),c.$set(z)},i(u){_||(w(c.$$.fragment,u),_=!0)},o(u){D(c.$$.fragment,u),_=!1},d(u){C(c,u)}}}function Sl(V){let c,_,u,g,z;return{c(){c=o("p"),_=s("Non tutti i modelli supportano un tokenizer veloce. Dai un\u2019occhiata a questo "),u=o("a"),g=s("tabella"),z=s(" per verificare se un modello ha il supporto per tokenizer veloce."),this.h()},l($){c=r($,"P",{});var v=l(c);_=i(v,"Non tutti i modelli supportano un tokenizer veloce. Dai un\u2019occhiata a questo "),u=r(v,"A",{href:!0});var T=l(u);g=i(T,"tabella"),T.forEach(a),z=i(v," per verificare se un modello ha il supporto per tokenizer veloce."),v.forEach(a),this.h()},h(){b(u,"href","index#supported-frameworks")},m($,v){p($,c,v),t(c,_),t(c,u),t(u,g),t(c,z)},d($){$&&a(c)}}}function Vl(V){let c,_,u,g,z,$,v,T,q,I,y;return{c(){c=o("p"),_=s("Per l\u2019impostazione predefinita, "),u=o("code"),g=s("AutoTokenizer"),z=s(" prover\xE0 a caricare un tokenizer veloce. Puoi disabilitare questo comportamento impostando "),$=o("code"),v=s("use_fast=False"),T=s(" in "),q=o("code"),I=s("from_pretrained"),y=s(".")},l(S){c=r(S,"P",{});var x=l(c);_=i(x,"Per l\u2019impostazione predefinita, "),u=r(x,"CODE",{});var O=l(u);g=i(O,"AutoTokenizer"),O.forEach(a),z=i(x," prover\xE0 a caricare un tokenizer veloce. Puoi disabilitare questo comportamento impostando "),$=r(x,"CODE",{});var P=l($);v=i(P,"use_fast=False"),P.forEach(a),T=i(x," in "),q=r(x,"CODE",{});var M=l(q);I=i(M,"from_pretrained"),M.forEach(a),y=i(x,"."),x.forEach(a)},m(S,x){p(S,c,x),t(c,_),t(c,u),t(u,g),t(c,z),t(c,$),t($,v),t(c,T),t(c,q),t(q,I),t(c,y)},d(S){S&&a(c)}}}function Il(V){let c,_,u,g,z;return{c(){c=o("p"),_=s("Se non stai cercando alcuna personalizzazione, usa il metodo "),u=o("code"),g=s("from_pretrained"),z=s(" per caricare i parametri di default dell\u2019estrattore di caratteristiche di un modello.")},l($){c=r($,"P",{});var v=l(c);_=i(v,"Se non stai cercando alcuna personalizzazione, usa il metodo "),u=r(v,"CODE",{});var T=l(u);g=i(T,"from_pretrained"),T.forEach(a),z=i(v," per caricare i parametri di default dell\u2019estrattore di caratteristiche di un modello."),v.forEach(a)},m($,v){p($,c,v),t(c,_),t(c,u),t(u,g),t(c,z)},d($){$&&a(c)}}}function Ll(V){let c,_,u,g,z,$,v,T,q,I,y,S,x,O,P,M,h,B,N,A,W,d,F,Q,G,ae,se,kt,Us,Gs,wt,Hs,Js,Dt,Xs,Ks,Ct,Ys,ja,ie,ue,yt,Se,Zs,Tt,ei,ka,U,ti,ft,ai,si,Pt,ii,oi,Ft,ri,li,Bt,ni,pi,xt,ci,ui,wa,Y,di,mt,fi,mi,At,hi,gi,Da,Ve,Ca,oe,Ot,_i,$i,Mt,vi,zi,ya,de,Ie,bi,St,qi,Ei,ji,Le,ki,Vt,wi,Di,Ta,Qe,Pa,fe,Ci,It,yi,Ti,Fa,Ne,Ba,me,Pi,Lt,Fi,Bi,xa,We,Aa,he,xi,Qt,Ai,Oi,Oa,Re,Ma,ge,Sa,re,_e,Nt,Ue,Mi,Wt,Si,Va,R,Vi,ht,Ii,Li,Rt,Qi,Ni,Ut,Wi,Ri,Ge,Gt,Ui,Gi,He,Ht,Hi,Ji,Je,Jt,Xi,Ki,Ia,$e,La,le,ve,Xt,Xe,Yi,Kt,Zi,Qa,ze,eo,Yt,to,ao,Na,be,Wa,ne,qe,Zt,Ke,so,ea,io,Ra,Ee,oo,gt,ro,lo,Ua,je,_t,ta,no,po,co,Z,aa,uo,fo,Ye,mo,ho,sa,go,_o,Ga,$t,$o,Ha,ke,Ja,we,vo,ia,zo,bo,Xa,Ze,Ka,De,qo,oa,Eo,jo,Ya,et,Za,Ce,ko,ra,wo,Do,es,tt,ts,ye,as,pe,Te,la,at,Co,na,yo,ss,J,To,pa,Po,Fo,ca,Bo,xo,ua,Ao,Oo,is,ee,Mo,da,So,Vo,vt,Io,Lo,os,st,rs,Pe,ls,Fe,Qo,fa,No,Wo,ns,it,ps,Be,Ro,ma,Uo,Go,cs,ot,us,ce,xe,ha,rt,Ho,ga,Jo,ds,Ae,Xo,_a,Ko,Yo,fs,zt,Zo,ms,lt,hs,bt,er,gs,nt,_s,Oe,tr,$a,ar,sr,$s,pt,vs,qt,ir,zs;return $=new dt({}),Se=new dt({}),Ve=new L({props:{code:`from transformers import DistilBertConfig

config = DistilBertConfig()
print(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>config = DistilBertConfig()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(config)
DistilBertConfig {
  <span class="hljs-string">&quot;activation&quot;</span>: <span class="hljs-string">&quot;gelu&quot;</span>,
  <span class="hljs-string">&quot;attention_dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;dim&quot;</span>: <span class="hljs-number">768</span>,
  <span class="hljs-string">&quot;dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;hidden_dim&quot;</span>: <span class="hljs-number">3072</span>,
  <span class="hljs-string">&quot;initializer_range&quot;</span>: <span class="hljs-number">0.02</span>,
  <span class="hljs-string">&quot;max_position_embeddings&quot;</span>: <span class="hljs-number">512</span>,
  <span class="hljs-string">&quot;model_type&quot;</span>: <span class="hljs-string">&quot;distilbert&quot;</span>,
  <span class="hljs-string">&quot;n_heads&quot;</span>: <span class="hljs-number">12</span>,
  <span class="hljs-string">&quot;n_layers&quot;</span>: <span class="hljs-number">6</span>,
  <span class="hljs-string">&quot;pad_token_id&quot;</span>: <span class="hljs-number">0</span>,
  <span class="hljs-string">&quot;qa_dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;seq_classif_dropout&quot;</span>: <span class="hljs-number">0.2</span>,
  <span class="hljs-string">&quot;sinusoidal_pos_embds&quot;</span>: false,
  <span class="hljs-string">&quot;transformers_version&quot;</span>: <span class="hljs-string">&quot;4.16.2&quot;</span>,
  <span class="hljs-string">&quot;vocab_size&quot;</span>: <span class="hljs-number">30522</span>
}`}}),Qe=new L({props:{code:`my_config = DistilBertConfig(activation="relu", attention_dropout=0.4)
print(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig(activation=<span class="hljs-string">&quot;relu&quot;</span>, attention_dropout=<span class="hljs-number">0.4</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(my_config)
DistilBertConfig {
  <span class="hljs-string">&quot;activation&quot;</span>: <span class="hljs-string">&quot;relu&quot;</span>,
  <span class="hljs-string">&quot;attention_dropout&quot;</span>: <span class="hljs-number">0.4</span>,
  <span class="hljs-string">&quot;dim&quot;</span>: <span class="hljs-number">768</span>,
  <span class="hljs-string">&quot;dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;hidden_dim&quot;</span>: <span class="hljs-number">3072</span>,
  <span class="hljs-string">&quot;initializer_range&quot;</span>: <span class="hljs-number">0.02</span>,
  <span class="hljs-string">&quot;max_position_embeddings&quot;</span>: <span class="hljs-number">512</span>,
  <span class="hljs-string">&quot;model_type&quot;</span>: <span class="hljs-string">&quot;distilbert&quot;</span>,
  <span class="hljs-string">&quot;n_heads&quot;</span>: <span class="hljs-number">12</span>,
  <span class="hljs-string">&quot;n_layers&quot;</span>: <span class="hljs-number">6</span>,
  <span class="hljs-string">&quot;pad_token_id&quot;</span>: <span class="hljs-number">0</span>,
  <span class="hljs-string">&quot;qa_dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;seq_classif_dropout&quot;</span>: <span class="hljs-number">0.2</span>,
  <span class="hljs-string">&quot;sinusoidal_pos_embds&quot;</span>: false,
  <span class="hljs-string">&quot;transformers_version&quot;</span>: <span class="hljs-string">&quot;4.16.2&quot;</span>,
  <span class="hljs-string">&quot;vocab_size&quot;</span>: <span class="hljs-number">30522</span>
}`}}),Ne=new L({props:{code:'my_config = DistilBertConfig.from_pretrained("distilbert-base-uncased", activation="relu", attention_dropout=0.4)',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>, activation=<span class="hljs-string">&quot;relu&quot;</span>, attention_dropout=<span class="hljs-number">0.4</span>)'}}),We=new L({props:{code:'my_config.save_pretrained(save_directory="./your_model_save_path")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>my_config.save_pretrained(save_directory=<span class="hljs-string">&quot;./your_model_save_path&quot;</span>)'}}),Re=new L({props:{code:'my_config = DistilBertConfig.from_pretrained("./your_model_save_path/my_config.json")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;./your_model_save_path/my_config.json&quot;</span>)'}}),ge=new Ns({props:{$$slots:{default:[yl]},$$scope:{ctx:V}}}),Ue=new dt({}),$e=new El({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Bl],pytorch:[Pl]},$$scope:{ctx:V}}}),Xe=new dt({}),be=new El({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Ml],pytorch:[Al]},$$scope:{ctx:V}}}),Ke=new dt({}),ke=new Ns({props:{warning:!0,$$slots:{default:[Sl]},$$scope:{ctx:V}}}),Ze=new L({props:{code:`from transformers import DistilBertTokenizer

my_tokenizer = DistilBertTokenizer(vocab_file="my_vocab_file.txt", do_lower_case=False, padding_side="left")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>my_tokenizer = DistilBertTokenizer(vocab_file=<span class="hljs-string">&quot;my_vocab_file.txt&quot;</span>, do_lower_case=<span class="hljs-literal">False</span>, padding_side=<span class="hljs-string">&quot;left&quot;</span>)`}}),et=new L({props:{code:`from transformers import DistilBertTokenizer

slow_tokenizer = DistilBertTokenizer.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>slow_tokenizer = DistilBertTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),tt=new L({props:{code:`from transformers import DistilBertTokenizerFast

fast_tokenizer = DistilBertTokenizerFast.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertTokenizerFast

<span class="hljs-meta">&gt;&gt;&gt; </span>fast_tokenizer = DistilBertTokenizerFast.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),ye=new Ns({props:{$$slots:{default:[Vl]},$$scope:{ctx:V}}}),at=new dt({}),st=new L({props:{code:`from transformers import ViTFeatureExtractor

vit_extractor = ViTFeatureExtractor()
print(vit_extractor)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> ViTFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>vit_extractor = ViTFeatureExtractor()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(vit_extractor)
ViTFeatureExtractor {
  <span class="hljs-string">&quot;do_normalize&quot;</span>: true,
  <span class="hljs-string">&quot;do_resize&quot;</span>: true,
  <span class="hljs-string">&quot;feature_extractor_type&quot;</span>: <span class="hljs-string">&quot;ViTFeatureExtractor&quot;</span>,
  <span class="hljs-string">&quot;image_mean&quot;</span>: [
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>
  ],
  <span class="hljs-string">&quot;image_std&quot;</span>: [
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>
  ],
  <span class="hljs-string">&quot;resample&quot;</span>: <span class="hljs-number">2</span>,
  <span class="hljs-string">&quot;size&quot;</span>: <span class="hljs-number">224</span>
}`}}),Pe=new Ns({props:{$$slots:{default:[Il]},$$scope:{ctx:V}}}),it=new L({props:{code:`from transformers import ViTFeatureExtractor

my_vit_extractor = ViTFeatureExtractor(resample="PIL.Image.BOX", do_normalize=False, image_mean=[0.3, 0.3, 0.3])
print(my_vit_extractor)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> ViTFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>my_vit_extractor = ViTFeatureExtractor(resample=<span class="hljs-string">&quot;PIL.Image.BOX&quot;</span>, do_normalize=<span class="hljs-literal">False</span>, image_mean=[<span class="hljs-number">0.3</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.3</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(my_vit_extractor)
ViTFeatureExtractor {
  <span class="hljs-string">&quot;do_normalize&quot;</span>: false,
  <span class="hljs-string">&quot;do_resize&quot;</span>: true,
  <span class="hljs-string">&quot;feature_extractor_type&quot;</span>: <span class="hljs-string">&quot;ViTFeatureExtractor&quot;</span>,
  <span class="hljs-string">&quot;image_mean&quot;</span>: [
    <span class="hljs-number">0.3</span>,
    <span class="hljs-number">0.3</span>,
    <span class="hljs-number">0.3</span>
  ],
  <span class="hljs-string">&quot;image_std&quot;</span>: [
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>
  ],
  <span class="hljs-string">&quot;resample&quot;</span>: <span class="hljs-string">&quot;PIL.Image.BOX&quot;</span>,
  <span class="hljs-string">&quot;size&quot;</span>: <span class="hljs-number">224</span>
}`}}),ot=new L({props:{code:`from transformers import Wav2Vec2FeatureExtractor

w2v2_extractor = Wav2Vec2FeatureExtractor()
print(w2v2_extractor)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2FeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>w2v2_extractor = Wav2Vec2FeatureExtractor()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(w2v2_extractor)
Wav2Vec2FeatureExtractor {
  <span class="hljs-string">&quot;do_normalize&quot;</span>: true,
  <span class="hljs-string">&quot;feature_extractor_type&quot;</span>: <span class="hljs-string">&quot;Wav2Vec2FeatureExtractor&quot;</span>,
  <span class="hljs-string">&quot;feature_size&quot;</span>: <span class="hljs-number">1</span>,
  <span class="hljs-string">&quot;padding_side&quot;</span>: <span class="hljs-string">&quot;right&quot;</span>,
  <span class="hljs-string">&quot;padding_value&quot;</span>: <span class="hljs-number">0.0</span>,
  <span class="hljs-string">&quot;return_attention_mask&quot;</span>: false,
  <span class="hljs-string">&quot;sampling_rate&quot;</span>: <span class="hljs-number">16000</span>
}`}}),rt=new dt({}),lt=new L({props:{code:`from transformers import Wav2Vec2FeatureExtractor

feature_extractor = Wav2Vec2FeatureExtractor(padding_value=1.0, do_normalize=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2FeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = Wav2Vec2FeatureExtractor(padding_value=<span class="hljs-number">1.0</span>, do_normalize=<span class="hljs-literal">True</span>)`}}),nt=new L({props:{code:`from transformers import Wav2Vec2CTCTokenizer

tokenizer = Wav2Vec2CTCTokenizer(vocab_file="my_vocab_file.txt")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2CTCTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = Wav2Vec2CTCTokenizer(vocab_file=<span class="hljs-string">&quot;my_vocab_file.txt&quot;</span>)`}}),pt=new L({props:{code:`from transformers import Wav2Vec2Processor

processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2Processor

<span class="hljs-meta">&gt;&gt;&gt; </span>processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)`}}),{c(){c=o("meta"),_=f(),u=o("h1"),g=o("a"),z=o("span"),E($.$$.fragment),v=f(),T=o("span"),q=s("Crea un'architettura personalizzata"),I=f(),y=o("p"),S=s("Una "),x=o("a"),O=o("code"),P=s("AutoClass"),M=s(" deduce automaticamente il modello dell\u2019architettura e scarica la configurazione e i pesi pre-allenati. Generalmente, noi consigliamo di usare un "),h=o("code"),B=s("AutoClass"),N=s(" per produrre un codice indipendente dal checkpoint. Ma gli utenti che desiderano un controllo maggiore su parametri specifici del modello possono creare un modello \u{1F917} Transformers personalizzato da poche classi base. Questo potrebbe essere particolarmente utile per qualunque persona sia interessata nel studiare, allenare o sperimentare con un modello \u{1F917} Transformers. In questa guida, approfondisci la creazione di un modello personalizzato senza "),A=o("code"),W=s("AutoClass"),d=s(". Impara come:"),F=f(),Q=o("ul"),G=o("li"),ae=s("Caricare e personalizzare una configurazione del modello."),se=f(),kt=o("li"),Us=s("Creare un\u2019architettura modello."),Gs=f(),wt=o("li"),Hs=s("Creare un tokenizer lento e veloce per il testo."),Js=f(),Dt=o("li"),Xs=s("Creare un estrattore di caratteristiche per attivit\xE0 riguardanti audio o immagini."),Ks=f(),Ct=o("li"),Ys=s("Creare un processore per attivit\xE0 multimodali."),ja=f(),ie=o("h2"),ue=o("a"),yt=o("span"),E(Se.$$.fragment),Zs=f(),Tt=o("span"),ei=s("Configurazione"),ka=f(),U=o("p"),ti=s("Una "),ft=o("a"),ai=s("configurazione"),si=s(" si riferisce agli attributi specifici di un modello. Ogni configurazione del modello ha attributi diversi; per esempio, tutti i modelli npl hanno questi attributi in comune "),Pt=o("code"),ii=s("hidden_size"),oi=s(", "),Ft=o("code"),ri=s("num_attention_heads"),li=s(", "),Bt=o("code"),ni=s("num_hidden_layers"),pi=s(" e "),xt=o("code"),ci=s("vocab_size"),ui=s(". Questi attributi specificano il numero di attention heads o strati nascosti con cui costruire un modello."),wa=f(),Y=o("p"),di=s("Dai un\u2019occhiata pi\xF9 da vicino a "),mt=o("a"),fi=s("DistilBERT"),mi=s(" accedendo a "),At=o("code"),hi=s("DistilBertConfig"),gi=s(" per ispezionare i suoi attributi:"),Da=f(),E(Ve.$$.fragment),Ca=f(),oe=o("p"),Ot=o("code"),_i=s("DistilBertConfig"),$i=s(" mostra tutti gli attributi predefiniti usati per costruire una base "),Mt=o("code"),vi=s("DistilBertModel"),zi=s(". Tutti gli attributi sono personalizzabili, creando uno spazio per sperimentare. Per esempio, puoi configurare un modello predefinito per:"),ya=f(),de=o("ul"),Ie=o("li"),bi=s("Provare un funzione di attivazione diversa con il parametro "),St=o("code"),qi=s("activation"),Ei=s("."),ji=f(),Le=o("li"),ki=s("Utilizzare tasso di drop out pi\xF9 elevato per le probalit\xE0 di attention con il parametro "),Vt=o("code"),wi=s("attention_dropout"),Di=s("."),Ta=f(),E(Qe.$$.fragment),Pa=f(),fe=o("p"),Ci=s("Nella funzione "),It=o("code"),yi=s("from_pretrained()"),Ti=s(" possono essere modificati gli attributi del modello pre-allenato:"),Fa=f(),E(Ne.$$.fragment),Ba=f(),me=o("p"),Pi=s("Quando la configurazione del modello ti soddisfa, la puoi salvare con "),Lt=o("code"),Fi=s("save_pretrained()"),Bi=s(". Il file della tua configurazione \xE8 memorizzato come file JSON nella save directory specificata:"),xa=f(),E(We.$$.fragment),Aa=f(),he=o("p"),xi=s("Per riutilizzare la configurazione del file, caricalo con "),Qt=o("code"),Ai=s("from_pretrained()"),Oi=s(":"),Oa=f(),E(Re.$$.fragment),Ma=f(),E(ge.$$.fragment),Sa=f(),re=o("h2"),_e=o("a"),Nt=o("span"),E(Ue.$$.fragment),Mi=f(),Wt=o("span"),Si=s("Modello"),Va=f(),R=o("p"),Vi=s("Il prossimo passo e di creare "),ht=o("a"),Ii=s("modello"),Li=s(". Il modello - vagamente riferito anche come architettura - definisce cosa ogni strato deve fare e quali operazioni stanno succedendo. Attributi come "),Rt=o("code"),Qi=s("num_hidden_layers"),Ni=s(" provenienti dalla configurazione sono usati per definire l\u2019architettura. Ogni modello condivide la classe base "),Ut=o("code"),Wi=s("PreTrainedModel"),Ri=s(" e alcuni metodi comuni come il ridimensionamento degli input embeddings e la soppressione delle self-attention heads . Inoltre, tutti i modelli sono la sottoclasse di "),Ge=o("a"),Gt=o("code"),Ui=s("torch.nn.Module"),Gi=s(", "),He=o("a"),Ht=o("code"),Hi=s("tf.keras.Model"),Ji=s(" o "),Je=o("a"),Jt=o("code"),Xi=s("flax.linen.Module"),Ki=s(". Cio significa che i modelli sono compatibili con l\u2019uso di ciascun di framework."),Ia=f(),E($e.$$.fragment),La=f(),le=o("h3"),ve=o("a"),Xt=o("span"),E(Xe.$$.fragment),Yi=f(),Kt=o("span"),Zi=s("Model head"),Qa=f(),ze=o("p"),eo=s("A questo punto, hai un modello DistilBERT base i cui output sono gli "),Yt=o("em"),to=s("hidden states"),ao=s(" (in italiano stati nascosti). Gli stati nascosti sono passati come input a un model head per produrre l\u2019output finale. \u{1F917} Transformers fornisce un model head diverso per ogni attivit\xE0 fintanto che il modello supporta l\u2019attivit\xE0  (i.e., non puoi usare DistilBERT per un attivit\xE0 sequence-to-sequence come la traduzione)."),Na=f(),E(be.$$.fragment),Wa=f(),ne=o("h2"),qe=o("a"),Zt=o("span"),E(Ke.$$.fragment),so=f(),ea=o("span"),io=s("Tokenizer"),Ra=f(),Ee=o("p"),oo=s("L\u2019ultima classe base di cui hai bisogno prima di utilizzare un modello per i dati testuali \xE8 un "),gt=o("a"),ro=s("tokenizer"),lo=s(" per convertire il testo grezzo in tensori. Ci sono due tipi di tokenizer che puoi usare con \u{1F917} Transformers:"),Ua=f(),je=o("ul"),_t=o("li"),ta=o("code"),no=s("PreTrainedTokenizer"),po=s(": un\u2019implementazione Python di un tokenizer."),co=f(),Z=o("li"),aa=o("code"),uo=s("PreTrainedTokenizerFast"),fo=s(": un tokenizer dalla nostra libreria "),Ye=o("a"),mo=s("\u{1F917} Tokenizer"),ho=s(" basata su Rust. Questo tipo di tokenizer \xE8 significativamente pi\xF9 veloce, specialmente durante la batch tokenization, grazie alla sua implementazione Rust. Il tokenizer veloce offre anche metodi aggiuntivi come "),sa=o("em"),go=s("offset mapping"),_o=s(" che associa i token alle loro parole o caratteri originali."),Ga=f(),$t=o("p"),$o=s("Entrambi i tokenizer supportano metodi comuni come la codifica e la decodifica, l\u2019aggiunta di nuovi token e la gestione di token speciali."),Ha=f(),E(ke.$$.fragment),Ja=f(),we=o("p"),vo=s("Se hai addestrato il tuo tokenizer, puoi crearne uno dal tuo file "),ia=o("em"),zo=s("vocabolario"),bo=s(":"),Xa=f(),E(Ze.$$.fragment),Ka=f(),De=o("p"),qo=s("\xC8 importante ricordare che il vocabolario di un tokenizer personalizzato sar\xE0 diverso dal vocabolario generato dal tokenizer di un modello preallenato. \xC8 necessario utilizzare il vocabolario di un modello preallenato se si utilizza un modello preallenato, altrimenti gli input non avranno senso. Crea un tokenizer con il vocabolario di un modello preallenato con la classe "),oa=o("code"),Eo=s("DistilBertTokenizer"),jo=s(":"),Ya=f(),E(et.$$.fragment),Za=f(),Ce=o("p"),ko=s("Crea un tokenizer veloce con la classe "),ra=o("code"),wo=s("DistilBertTokenizerFast"),Do=s(":"),es=f(),E(tt.$$.fragment),ts=f(),E(ye.$$.fragment),as=f(),pe=o("h2"),Te=o("a"),la=o("span"),E(at.$$.fragment),Co=f(),na=o("span"),yo=s("Estrattore Di Feature"),ss=f(),J=o("p"),To=s("Un estrattore di caratteristiche (feature in inglese) elabora input audio o immagini. Eredita dalla classe "),pa=o("code"),Po=s("FeatureExtractionMixin"),Fo=s(" base e pu\xF2 anche ereditare dalla classe "),ca=o("code"),Bo=s("ImageFeatureExtractionMixin"),xo=s(" per l\u2019elaborazione delle caratteristiche dell\u2019immagine o dalla classe "),ua=o("code"),Ao=s("SequenceFeatureExtractor"),Oo=s(" per l\u2019elaborazione degli input audio."),is=f(),ee=o("p"),Mo=s("A seconda che tu stia lavorando a un\u2019attivit\xE0 audio o visiva, crea un estrattore di caratteristiche associato al modello che stai utilizzando. Ad esempio, crea un "),da=o("code"),So=s("ViTFeatureExtractor"),Vo=s(" predefinito se stai usando "),vt=o("a"),Io=s("ViT"),Lo=s(" per la classificazione delle immagini:"),os=f(),E(st.$$.fragment),rs=f(),E(Pe.$$.fragment),ls=f(),Fe=o("p"),Qo=s("Modifica uno qualsiasi dei parametri "),fa=o("code"),No=s("ViTFeatureExtractor"),Wo=s(" per creare il tuo estrattore di caratteristiche personalizzato:"),ns=f(),E(it.$$.fragment),ps=f(),Be=o("p"),Ro=s("Per gli input audio, puoi creare un "),ma=o("code"),Uo=s("Wav2Vec2FeatureExtractor"),Go=s(" e personalizzare i parametri in modo simile:"),cs=f(),E(ot.$$.fragment),us=f(),ce=o("h2"),xe=o("a"),ha=o("span"),E(rt.$$.fragment),Ho=f(),ga=o("span"),Jo=s("Processore"),ds=f(),Ae=o("p"),Xo=s("Per modelli che supportano attivit\xE0 multimodali, \u{1F917} Transformers offre una classe di processore che racchiude comodamente un estrattore di caratteristiche e un tokenizer in un unico oggetto. Ad esempio, utilizziamo "),_a=o("code"),Ko=s("Wav2Vec2Processor"),Yo=s(" per un\u2019attivit\xE0 di riconoscimento vocale automatico (ASR). ASR trascrive l\u2019audio in testo, quindi avrai bisogno di un estrattore di caratteristiche e di un tokenizer."),fs=f(),zt=o("p"),Zo=s("Crea un estrattore di feature per gestire gli input audio:"),ms=f(),E(lt.$$.fragment),hs=f(),bt=o("p"),er=s("Crea un tokenizer per gestire gli input di testo:"),gs=f(),E(nt.$$.fragment),_s=f(),Oe=o("p"),tr=s("Combinare l\u2019estrattore di caratteristiche e il tokenizer in "),$a=o("code"),ar=s("Wav2Vec2Processor"),sr=s(":"),$s=f(),E(pt.$$.fragment),vs=f(),qt=o("p"),ir=s("Con due classi di base - configurazione e modello - e una classe di preelaborazione aggiuntiva (tokenizer, estrattore di caratteristiche o processore), puoi creare qualsiasi modello supportato da \u{1F917} Transformers. Ognuna di queste classi base \xE8 configurabile, consentendoti di utilizzare gli attributi specifici che desideri. \xC8 possibile impostare facilmente un modello per l\u2019addestramento o modificare un modello preallenato esistente per la messa a punto."),this.h()},l(e){const n=Dl('[data-svelte="svelte-1phssyn"]',document.head);c=r(n,"META",{name:!0,content:!0}),n.forEach(a),_=m(e),u=r(e,"H1",{class:!0});var ct=l(u);g=r(ct,"A",{id:!0,class:!0,href:!0});var va=l(g);z=r(va,"SPAN",{});var za=l(z);j($.$$.fragment,za),za.forEach(a),va.forEach(a),v=m(ct),T=r(ct,"SPAN",{});var ba=l(T);q=i(ba,"Crea un'architettura personalizzata"),ba.forEach(a),ct.forEach(a),I=m(e),y=r(e,"P",{});var K=l(y);S=i(K,"Una "),x=r(K,"A",{href:!0});var qa=l(x);O=r(qa,"CODE",{});var rr=l(O);P=i(rr,"AutoClass"),rr.forEach(a),qa.forEach(a),M=i(K," deduce automaticamente il modello dell\u2019architettura e scarica la configurazione e i pesi pre-allenati. Generalmente, noi consigliamo di usare un "),h=r(K,"CODE",{});var lr=l(h);B=i(lr,"AutoClass"),lr.forEach(a),N=i(K," per produrre un codice indipendente dal checkpoint. Ma gli utenti che desiderano un controllo maggiore su parametri specifici del modello possono creare un modello \u{1F917} Transformers personalizzato da poche classi base. Questo potrebbe essere particolarmente utile per qualunque persona sia interessata nel studiare, allenare o sperimentare con un modello \u{1F917} Transformers. In questa guida, approfondisci la creazione di un modello personalizzato senza "),A=r(K,"CODE",{});var nr=l(A);W=i(nr,"AutoClass"),nr.forEach(a),d=i(K,". Impara come:"),K.forEach(a),F=m(e),Q=r(e,"UL",{});var te=l(Q);G=r(te,"LI",{});var pr=l(G);ae=i(pr,"Caricare e personalizzare una configurazione del modello."),pr.forEach(a),se=m(te),kt=r(te,"LI",{});var cr=l(kt);Us=i(cr,"Creare un\u2019architettura modello."),cr.forEach(a),Gs=m(te),wt=r(te,"LI",{});var ur=l(wt);Hs=i(ur,"Creare un tokenizer lento e veloce per il testo."),ur.forEach(a),Js=m(te),Dt=r(te,"LI",{});var dr=l(Dt);Xs=i(dr,"Creare un estrattore di caratteristiche per attivit\xE0 riguardanti audio o immagini."),dr.forEach(a),Ks=m(te),Ct=r(te,"LI",{});var fr=l(Ct);Ys=i(fr,"Creare un processore per attivit\xE0 multimodali."),fr.forEach(a),te.forEach(a),ja=m(e),ie=r(e,"H2",{class:!0});var bs=l(ie);ue=r(bs,"A",{id:!0,class:!0,href:!0});var mr=l(ue);yt=r(mr,"SPAN",{});var hr=l(yt);j(Se.$$.fragment,hr),hr.forEach(a),mr.forEach(a),Zs=m(bs),Tt=r(bs,"SPAN",{});var gr=l(Tt);ei=i(gr,"Configurazione"),gr.forEach(a),bs.forEach(a),ka=m(e),U=r(e,"P",{});var X=l(U);ti=i(X,"Una "),ft=r(X,"A",{href:!0});var _r=l(ft);ai=i(_r,"configurazione"),_r.forEach(a),si=i(X," si riferisce agli attributi specifici di un modello. Ogni configurazione del modello ha attributi diversi; per esempio, tutti i modelli npl hanno questi attributi in comune "),Pt=r(X,"CODE",{});var $r=l(Pt);ii=i($r,"hidden_size"),$r.forEach(a),oi=i(X,", "),Ft=r(X,"CODE",{});var vr=l(Ft);ri=i(vr,"num_attention_heads"),vr.forEach(a),li=i(X,", "),Bt=r(X,"CODE",{});var zr=l(Bt);ni=i(zr,"num_hidden_layers"),zr.forEach(a),pi=i(X," e "),xt=r(X,"CODE",{});var br=l(xt);ci=i(br,"vocab_size"),br.forEach(a),ui=i(X,". Questi attributi specificano il numero di attention heads o strati nascosti con cui costruire un modello."),X.forEach(a),wa=m(e),Y=r(e,"P",{});var Et=l(Y);di=i(Et,"Dai un\u2019occhiata pi\xF9 da vicino a "),mt=r(Et,"A",{href:!0});var qr=l(mt);fi=i(qr,"DistilBERT"),qr.forEach(a),mi=i(Et," accedendo a "),At=r(Et,"CODE",{});var Er=l(At);hi=i(Er,"DistilBertConfig"),Er.forEach(a),gi=i(Et," per ispezionare i suoi attributi:"),Et.forEach(a),Da=m(e),j(Ve.$$.fragment,e),Ca=m(e),oe=r(e,"P",{});var Ea=l(oe);Ot=r(Ea,"CODE",{});var jr=l(Ot);_i=i(jr,"DistilBertConfig"),jr.forEach(a),$i=i(Ea," mostra tutti gli attributi predefiniti usati per costruire una base "),Mt=r(Ea,"CODE",{});var kr=l(Mt);vi=i(kr,"DistilBertModel"),kr.forEach(a),zi=i(Ea,". Tutti gli attributi sono personalizzabili, creando uno spazio per sperimentare. Per esempio, puoi configurare un modello predefinito per:"),Ea.forEach(a),ya=m(e),de=r(e,"UL",{});var qs=l(de);Ie=r(qs,"LI",{});var Es=l(Ie);bi=i(Es,"Provare un funzione di attivazione diversa con il parametro "),St=r(Es,"CODE",{});var wr=l(St);qi=i(wr,"activation"),wr.forEach(a),Ei=i(Es,"."),Es.forEach(a),ji=m(qs),Le=r(qs,"LI",{});var js=l(Le);ki=i(js,"Utilizzare tasso di drop out pi\xF9 elevato per le probalit\xE0 di attention con il parametro "),Vt=r(js,"CODE",{});var Dr=l(Vt);wi=i(Dr,"attention_dropout"),Dr.forEach(a),Di=i(js,"."),js.forEach(a),qs.forEach(a),Ta=m(e),j(Qe.$$.fragment,e),Pa=m(e),fe=r(e,"P",{});var ks=l(fe);Ci=i(ks,"Nella funzione "),It=r(ks,"CODE",{});var Cr=l(It);yi=i(Cr,"from_pretrained()"),Cr.forEach(a),Ti=i(ks," possono essere modificati gli attributi del modello pre-allenato:"),ks.forEach(a),Fa=m(e),j(Ne.$$.fragment,e),Ba=m(e),me=r(e,"P",{});var ws=l(me);Pi=i(ws,"Quando la configurazione del modello ti soddisfa, la puoi salvare con "),Lt=r(ws,"CODE",{});var yr=l(Lt);Fi=i(yr,"save_pretrained()"),yr.forEach(a),Bi=i(ws,". Il file della tua configurazione \xE8 memorizzato come file JSON nella save directory specificata:"),ws.forEach(a),xa=m(e),j(We.$$.fragment,e),Aa=m(e),he=r(e,"P",{});var Ds=l(he);xi=i(Ds,"Per riutilizzare la configurazione del file, caricalo con "),Qt=r(Ds,"CODE",{});var Tr=l(Qt);Ai=i(Tr,"from_pretrained()"),Tr.forEach(a),Oi=i(Ds,":"),Ds.forEach(a),Oa=m(e),j(Re.$$.fragment,e),Ma=m(e),j(ge.$$.fragment,e),Sa=m(e),re=r(e,"H2",{class:!0});var Cs=l(re);_e=r(Cs,"A",{id:!0,class:!0,href:!0});var Pr=l(_e);Nt=r(Pr,"SPAN",{});var Fr=l(Nt);j(Ue.$$.fragment,Fr),Fr.forEach(a),Pr.forEach(a),Mi=m(Cs),Wt=r(Cs,"SPAN",{});var Br=l(Wt);Si=i(Br,"Modello"),Br.forEach(a),Cs.forEach(a),Va=m(e),R=r(e,"P",{});var H=l(R);Vi=i(H,"Il prossimo passo e di creare "),ht=r(H,"A",{href:!0});var xr=l(ht);Ii=i(xr,"modello"),xr.forEach(a),Li=i(H,". Il modello - vagamente riferito anche come architettura - definisce cosa ogni strato deve fare e quali operazioni stanno succedendo. Attributi come "),Rt=r(H,"CODE",{});var Ar=l(Rt);Qi=i(Ar,"num_hidden_layers"),Ar.forEach(a),Ni=i(H," provenienti dalla configurazione sono usati per definire l\u2019architettura. Ogni modello condivide la classe base "),Ut=r(H,"CODE",{});var Or=l(Ut);Wi=i(Or,"PreTrainedModel"),Or.forEach(a),Ri=i(H," e alcuni metodi comuni come il ridimensionamento degli input embeddings e la soppressione delle self-attention heads . Inoltre, tutti i modelli sono la sottoclasse di "),Ge=r(H,"A",{href:!0,rel:!0});var Mr=l(Ge);Gt=r(Mr,"CODE",{});var Sr=l(Gt);Ui=i(Sr,"torch.nn.Module"),Sr.forEach(a),Mr.forEach(a),Gi=i(H,", "),He=r(H,"A",{href:!0,rel:!0});var Vr=l(He);Ht=r(Vr,"CODE",{});var Ir=l(Ht);Hi=i(Ir,"tf.keras.Model"),Ir.forEach(a),Vr.forEach(a),Ji=i(H," o "),Je=r(H,"A",{href:!0,rel:!0});var Lr=l(Je);Jt=r(Lr,"CODE",{});var Qr=l(Jt);Xi=i(Qr,"flax.linen.Module"),Qr.forEach(a),Lr.forEach(a),Ki=i(H,". Cio significa che i modelli sono compatibili con l\u2019uso di ciascun di framework."),H.forEach(a),Ia=m(e),j($e.$$.fragment,e),La=m(e),le=r(e,"H3",{class:!0});var ys=l(le);ve=r(ys,"A",{id:!0,class:!0,href:!0});var Nr=l(ve);Xt=r(Nr,"SPAN",{});var Wr=l(Xt);j(Xe.$$.fragment,Wr),Wr.forEach(a),Nr.forEach(a),Yi=m(ys),Kt=r(ys,"SPAN",{});var Rr=l(Kt);Zi=i(Rr,"Model head"),Rr.forEach(a),ys.forEach(a),Qa=m(e),ze=r(e,"P",{});var Ts=l(ze);eo=i(Ts,"A questo punto, hai un modello DistilBERT base i cui output sono gli "),Yt=r(Ts,"EM",{});var Ur=l(Yt);to=i(Ur,"hidden states"),Ur.forEach(a),ao=i(Ts," (in italiano stati nascosti). Gli stati nascosti sono passati come input a un model head per produrre l\u2019output finale. \u{1F917} Transformers fornisce un model head diverso per ogni attivit\xE0 fintanto che il modello supporta l\u2019attivit\xE0  (i.e., non puoi usare DistilBERT per un attivit\xE0 sequence-to-sequence come la traduzione)."),Ts.forEach(a),Na=m(e),j(be.$$.fragment,e),Wa=m(e),ne=r(e,"H2",{class:!0});var Ps=l(ne);qe=r(Ps,"A",{id:!0,class:!0,href:!0});var Gr=l(qe);Zt=r(Gr,"SPAN",{});var Hr=l(Zt);j(Ke.$$.fragment,Hr),Hr.forEach(a),Gr.forEach(a),so=m(Ps),ea=r(Ps,"SPAN",{});var Jr=l(ea);io=i(Jr,"Tokenizer"),Jr.forEach(a),Ps.forEach(a),Ra=m(e),Ee=r(e,"P",{});var Fs=l(Ee);oo=i(Fs,"L\u2019ultima classe base di cui hai bisogno prima di utilizzare un modello per i dati testuali \xE8 un "),gt=r(Fs,"A",{href:!0});var Xr=l(gt);ro=i(Xr,"tokenizer"),Xr.forEach(a),lo=i(Fs," per convertire il testo grezzo in tensori. Ci sono due tipi di tokenizer che puoi usare con \u{1F917} Transformers:"),Fs.forEach(a),Ua=m(e),je=r(e,"UL",{});var Bs=l(je);_t=r(Bs,"LI",{});var or=l(_t);ta=r(or,"CODE",{});var Kr=l(ta);no=i(Kr,"PreTrainedTokenizer"),Kr.forEach(a),po=i(or,": un\u2019implementazione Python di un tokenizer."),or.forEach(a),co=m(Bs),Z=r(Bs,"LI",{});var ut=l(Z);aa=r(ut,"CODE",{});var Yr=l(aa);uo=i(Yr,"PreTrainedTokenizerFast"),Yr.forEach(a),fo=i(ut,": un tokenizer dalla nostra libreria "),Ye=r(ut,"A",{href:!0,rel:!0});var Zr=l(Ye);mo=i(Zr,"\u{1F917} Tokenizer"),Zr.forEach(a),ho=i(ut," basata su Rust. Questo tipo di tokenizer \xE8 significativamente pi\xF9 veloce, specialmente durante la batch tokenization, grazie alla sua implementazione Rust. Il tokenizer veloce offre anche metodi aggiuntivi come "),sa=r(ut,"EM",{});var el=l(sa);go=i(el,"offset mapping"),el.forEach(a),_o=i(ut," che associa i token alle loro parole o caratteri originali."),ut.forEach(a),Bs.forEach(a),Ga=m(e),$t=r(e,"P",{});var tl=l($t);$o=i(tl,"Entrambi i tokenizer supportano metodi comuni come la codifica e la decodifica, l\u2019aggiunta di nuovi token e la gestione di token speciali."),tl.forEach(a),Ha=m(e),j(ke.$$.fragment,e),Ja=m(e),we=r(e,"P",{});var xs=l(we);vo=i(xs,"Se hai addestrato il tuo tokenizer, puoi crearne uno dal tuo file "),ia=r(xs,"EM",{});var al=l(ia);zo=i(al,"vocabolario"),al.forEach(a),bo=i(xs,":"),xs.forEach(a),Xa=m(e),j(Ze.$$.fragment,e),Ka=m(e),De=r(e,"P",{});var As=l(De);qo=i(As,"\xC8 importante ricordare che il vocabolario di un tokenizer personalizzato sar\xE0 diverso dal vocabolario generato dal tokenizer di un modello preallenato. \xC8 necessario utilizzare il vocabolario di un modello preallenato se si utilizza un modello preallenato, altrimenti gli input non avranno senso. Crea un tokenizer con il vocabolario di un modello preallenato con la classe "),oa=r(As,"CODE",{});var sl=l(oa);Eo=i(sl,"DistilBertTokenizer"),sl.forEach(a),jo=i(As,":"),As.forEach(a),Ya=m(e),j(et.$$.fragment,e),Za=m(e),Ce=r(e,"P",{});var Os=l(Ce);ko=i(Os,"Crea un tokenizer veloce con la classe "),ra=r(Os,"CODE",{});var il=l(ra);wo=i(il,"DistilBertTokenizerFast"),il.forEach(a),Do=i(Os,":"),Os.forEach(a),es=m(e),j(tt.$$.fragment,e),ts=m(e),j(ye.$$.fragment,e),as=m(e),pe=r(e,"H2",{class:!0});var Ms=l(pe);Te=r(Ms,"A",{id:!0,class:!0,href:!0});var ol=l(Te);la=r(ol,"SPAN",{});var rl=l(la);j(at.$$.fragment,rl),rl.forEach(a),ol.forEach(a),Co=m(Ms),na=r(Ms,"SPAN",{});var ll=l(na);yo=i(ll,"Estrattore Di Feature"),ll.forEach(a),Ms.forEach(a),ss=m(e),J=r(e,"P",{});var Me=l(J);To=i(Me,"Un estrattore di caratteristiche (feature in inglese) elabora input audio o immagini. Eredita dalla classe "),pa=r(Me,"CODE",{});var nl=l(pa);Po=i(nl,"FeatureExtractionMixin"),nl.forEach(a),Fo=i(Me," base e pu\xF2 anche ereditare dalla classe "),ca=r(Me,"CODE",{});var pl=l(ca);Bo=i(pl,"ImageFeatureExtractionMixin"),pl.forEach(a),xo=i(Me," per l\u2019elaborazione delle caratteristiche dell\u2019immagine o dalla classe "),ua=r(Me,"CODE",{});var cl=l(ua);Ao=i(cl,"SequenceFeatureExtractor"),cl.forEach(a),Oo=i(Me," per l\u2019elaborazione degli input audio."),Me.forEach(a),is=m(e),ee=r(e,"P",{});var jt=l(ee);Mo=i(jt,"A seconda che tu stia lavorando a un\u2019attivit\xE0 audio o visiva, crea un estrattore di caratteristiche associato al modello che stai utilizzando. Ad esempio, crea un "),da=r(jt,"CODE",{});var ul=l(da);So=i(ul,"ViTFeatureExtractor"),ul.forEach(a),Vo=i(jt," predefinito se stai usando "),vt=r(jt,"A",{href:!0});var dl=l(vt);Io=i(dl,"ViT"),dl.forEach(a),Lo=i(jt," per la classificazione delle immagini:"),jt.forEach(a),os=m(e),j(st.$$.fragment,e),rs=m(e),j(Pe.$$.fragment,e),ls=m(e),Fe=r(e,"P",{});var Ss=l(Fe);Qo=i(Ss,"Modifica uno qualsiasi dei parametri "),fa=r(Ss,"CODE",{});var fl=l(fa);No=i(fl,"ViTFeatureExtractor"),fl.forEach(a),Wo=i(Ss," per creare il tuo estrattore di caratteristiche personalizzato:"),Ss.forEach(a),ns=m(e),j(it.$$.fragment,e),ps=m(e),Be=r(e,"P",{});var Vs=l(Be);Ro=i(Vs,"Per gli input audio, puoi creare un "),ma=r(Vs,"CODE",{});var ml=l(ma);Uo=i(ml,"Wav2Vec2FeatureExtractor"),ml.forEach(a),Go=i(Vs," e personalizzare i parametri in modo simile:"),Vs.forEach(a),cs=m(e),j(ot.$$.fragment,e),us=m(e),ce=r(e,"H2",{class:!0});var Is=l(ce);xe=r(Is,"A",{id:!0,class:!0,href:!0});var hl=l(xe);ha=r(hl,"SPAN",{});var gl=l(ha);j(rt.$$.fragment,gl),gl.forEach(a),hl.forEach(a),Ho=m(Is),ga=r(Is,"SPAN",{});var _l=l(ga);Jo=i(_l,"Processore"),_l.forEach(a),Is.forEach(a),ds=m(e),Ae=r(e,"P",{});var Ls=l(Ae);Xo=i(Ls,"Per modelli che supportano attivit\xE0 multimodali, \u{1F917} Transformers offre una classe di processore che racchiude comodamente un estrattore di caratteristiche e un tokenizer in un unico oggetto. Ad esempio, utilizziamo "),_a=r(Ls,"CODE",{});var $l=l(_a);Ko=i($l,"Wav2Vec2Processor"),$l.forEach(a),Yo=i(Ls," per un\u2019attivit\xE0 di riconoscimento vocale automatico (ASR). ASR trascrive l\u2019audio in testo, quindi avrai bisogno di un estrattore di caratteristiche e di un tokenizer."),Ls.forEach(a),fs=m(e),zt=r(e,"P",{});var vl=l(zt);Zo=i(vl,"Crea un estrattore di feature per gestire gli input audio:"),vl.forEach(a),ms=m(e),j(lt.$$.fragment,e),hs=m(e),bt=r(e,"P",{});var zl=l(bt);er=i(zl,"Crea un tokenizer per gestire gli input di testo:"),zl.forEach(a),gs=m(e),j(nt.$$.fragment,e),_s=m(e),Oe=r(e,"P",{});var Qs=l(Oe);tr=i(Qs,"Combinare l\u2019estrattore di caratteristiche e il tokenizer in "),$a=r(Qs,"CODE",{});var bl=l($a);ar=i(bl,"Wav2Vec2Processor"),bl.forEach(a),sr=i(Qs,":"),Qs.forEach(a),$s=m(e),j(pt.$$.fragment,e),vs=m(e),qt=r(e,"P",{});var ql=l(qt);ir=i(ql,"Con due classi di base - configurazione e modello - e una classe di preelaborazione aggiuntiva (tokenizer, estrattore di caratteristiche o processore), puoi creare qualsiasi modello supportato da \u{1F917} Transformers. Ognuna di queste classi base \xE8 configurabile, consentendoti di utilizzare gli attributi specifici che desideri. \xC8 possibile impostare facilmente un modello per l\u2019addestramento o modificare un modello preallenato esistente per la messa a punto."),ql.forEach(a),this.h()},h(){b(c,"name","hf:doc:metadata"),b(c,"content",JSON.stringify(Ql)),b(g,"id","crea-unarchitettura-personalizzata"),b(g,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(g,"href","#crea-unarchitettura-personalizzata"),b(u,"class","relative group"),b(x,"href","model_doc/auto"),b(ue,"id","configurazione"),b(ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(ue,"href","#configurazione"),b(ie,"class","relative group"),b(ft,"href","main_classes/configuration"),b(mt,"href","model_doc/distilbert"),b(_e,"id","modello"),b(_e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(_e,"href","#modello"),b(re,"class","relative group"),b(ht,"href","main_classes/models"),b(Ge,"href","https://pytorch.org/docs/stable/generated/torch.nn.Module.html"),b(Ge,"rel","nofollow"),b(He,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),b(He,"rel","nofollow"),b(Je,"href","https://flax.readthedocs.io/en/latest/flax.linen.html#module"),b(Je,"rel","nofollow"),b(ve,"id","model-head"),b(ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(ve,"href","#model-head"),b(le,"class","relative group"),b(qe,"id","tokenizer"),b(qe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(qe,"href","#tokenizer"),b(ne,"class","relative group"),b(gt,"href","main_classes/tokenizer"),b(Ye,"href","https://huggingface.co/docs/tokenizers/python/latest/"),b(Ye,"rel","nofollow"),b(Te,"id","estrattore-di-feature"),b(Te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(Te,"href","#estrattore-di-feature"),b(pe,"class","relative group"),b(vt,"href","model_doc/vit"),b(xe,"id","processore"),b(xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(xe,"href","#processore"),b(ce,"class","relative group")},m(e,n){t(document.head,c),p(e,_,n),p(e,u,n),t(u,g),t(g,z),k($,z,null),t(u,v),t(u,T),t(T,q),p(e,I,n),p(e,y,n),t(y,S),t(y,x),t(x,O),t(O,P),t(y,M),t(y,h),t(h,B),t(y,N),t(y,A),t(A,W),t(y,d),p(e,F,n),p(e,Q,n),t(Q,G),t(G,ae),t(Q,se),t(Q,kt),t(kt,Us),t(Q,Gs),t(Q,wt),t(wt,Hs),t(Q,Js),t(Q,Dt),t(Dt,Xs),t(Q,Ks),t(Q,Ct),t(Ct,Ys),p(e,ja,n),p(e,ie,n),t(ie,ue),t(ue,yt),k(Se,yt,null),t(ie,Zs),t(ie,Tt),t(Tt,ei),p(e,ka,n),p(e,U,n),t(U,ti),t(U,ft),t(ft,ai),t(U,si),t(U,Pt),t(Pt,ii),t(U,oi),t(U,Ft),t(Ft,ri),t(U,li),t(U,Bt),t(Bt,ni),t(U,pi),t(U,xt),t(xt,ci),t(U,ui),p(e,wa,n),p(e,Y,n),t(Y,di),t(Y,mt),t(mt,fi),t(Y,mi),t(Y,At),t(At,hi),t(Y,gi),p(e,Da,n),k(Ve,e,n),p(e,Ca,n),p(e,oe,n),t(oe,Ot),t(Ot,_i),t(oe,$i),t(oe,Mt),t(Mt,vi),t(oe,zi),p(e,ya,n),p(e,de,n),t(de,Ie),t(Ie,bi),t(Ie,St),t(St,qi),t(Ie,Ei),t(de,ji),t(de,Le),t(Le,ki),t(Le,Vt),t(Vt,wi),t(Le,Di),p(e,Ta,n),k(Qe,e,n),p(e,Pa,n),p(e,fe,n),t(fe,Ci),t(fe,It),t(It,yi),t(fe,Ti),p(e,Fa,n),k(Ne,e,n),p(e,Ba,n),p(e,me,n),t(me,Pi),t(me,Lt),t(Lt,Fi),t(me,Bi),p(e,xa,n),k(We,e,n),p(e,Aa,n),p(e,he,n),t(he,xi),t(he,Qt),t(Qt,Ai),t(he,Oi),p(e,Oa,n),k(Re,e,n),p(e,Ma,n),k(ge,e,n),p(e,Sa,n),p(e,re,n),t(re,_e),t(_e,Nt),k(Ue,Nt,null),t(re,Mi),t(re,Wt),t(Wt,Si),p(e,Va,n),p(e,R,n),t(R,Vi),t(R,ht),t(ht,Ii),t(R,Li),t(R,Rt),t(Rt,Qi),t(R,Ni),t(R,Ut),t(Ut,Wi),t(R,Ri),t(R,Ge),t(Ge,Gt),t(Gt,Ui),t(R,Gi),t(R,He),t(He,Ht),t(Ht,Hi),t(R,Ji),t(R,Je),t(Je,Jt),t(Jt,Xi),t(R,Ki),p(e,Ia,n),k($e,e,n),p(e,La,n),p(e,le,n),t(le,ve),t(ve,Xt),k(Xe,Xt,null),t(le,Yi),t(le,Kt),t(Kt,Zi),p(e,Qa,n),p(e,ze,n),t(ze,eo),t(ze,Yt),t(Yt,to),t(ze,ao),p(e,Na,n),k(be,e,n),p(e,Wa,n),p(e,ne,n),t(ne,qe),t(qe,Zt),k(Ke,Zt,null),t(ne,so),t(ne,ea),t(ea,io),p(e,Ra,n),p(e,Ee,n),t(Ee,oo),t(Ee,gt),t(gt,ro),t(Ee,lo),p(e,Ua,n),p(e,je,n),t(je,_t),t(_t,ta),t(ta,no),t(_t,po),t(je,co),t(je,Z),t(Z,aa),t(aa,uo),t(Z,fo),t(Z,Ye),t(Ye,mo),t(Z,ho),t(Z,sa),t(sa,go),t(Z,_o),p(e,Ga,n),p(e,$t,n),t($t,$o),p(e,Ha,n),k(ke,e,n),p(e,Ja,n),p(e,we,n),t(we,vo),t(we,ia),t(ia,zo),t(we,bo),p(e,Xa,n),k(Ze,e,n),p(e,Ka,n),p(e,De,n),t(De,qo),t(De,oa),t(oa,Eo),t(De,jo),p(e,Ya,n),k(et,e,n),p(e,Za,n),p(e,Ce,n),t(Ce,ko),t(Ce,ra),t(ra,wo),t(Ce,Do),p(e,es,n),k(tt,e,n),p(e,ts,n),k(ye,e,n),p(e,as,n),p(e,pe,n),t(pe,Te),t(Te,la),k(at,la,null),t(pe,Co),t(pe,na),t(na,yo),p(e,ss,n),p(e,J,n),t(J,To),t(J,pa),t(pa,Po),t(J,Fo),t(J,ca),t(ca,Bo),t(J,xo),t(J,ua),t(ua,Ao),t(J,Oo),p(e,is,n),p(e,ee,n),t(ee,Mo),t(ee,da),t(da,So),t(ee,Vo),t(ee,vt),t(vt,Io),t(ee,Lo),p(e,os,n),k(st,e,n),p(e,rs,n),k(Pe,e,n),p(e,ls,n),p(e,Fe,n),t(Fe,Qo),t(Fe,fa),t(fa,No),t(Fe,Wo),p(e,ns,n),k(it,e,n),p(e,ps,n),p(e,Be,n),t(Be,Ro),t(Be,ma),t(ma,Uo),t(Be,Go),p(e,cs,n),k(ot,e,n),p(e,us,n),p(e,ce,n),t(ce,xe),t(xe,ha),k(rt,ha,null),t(ce,Ho),t(ce,ga),t(ga,Jo),p(e,ds,n),p(e,Ae,n),t(Ae,Xo),t(Ae,_a),t(_a,Ko),t(Ae,Yo),p(e,fs,n),p(e,zt,n),t(zt,Zo),p(e,ms,n),k(lt,e,n),p(e,hs,n),p(e,bt,n),t(bt,er),p(e,gs,n),k(nt,e,n),p(e,_s,n),p(e,Oe,n),t(Oe,tr),t(Oe,$a),t($a,ar),t(Oe,sr),p(e,$s,n),k(pt,e,n),p(e,vs,n),p(e,qt,n),t(qt,ir),zs=!0},p(e,[n]){const ct={};n&2&&(ct.$$scope={dirty:n,ctx:e}),ge.$set(ct);const va={};n&2&&(va.$$scope={dirty:n,ctx:e}),$e.$set(va);const za={};n&2&&(za.$$scope={dirty:n,ctx:e}),be.$set(za);const ba={};n&2&&(ba.$$scope={dirty:n,ctx:e}),ke.$set(ba);const K={};n&2&&(K.$$scope={dirty:n,ctx:e}),ye.$set(K);const qa={};n&2&&(qa.$$scope={dirty:n,ctx:e}),Pe.$set(qa)},i(e){zs||(w($.$$.fragment,e),w(Se.$$.fragment,e),w(Ve.$$.fragment,e),w(Qe.$$.fragment,e),w(Ne.$$.fragment,e),w(We.$$.fragment,e),w(Re.$$.fragment,e),w(ge.$$.fragment,e),w(Ue.$$.fragment,e),w($e.$$.fragment,e),w(Xe.$$.fragment,e),w(be.$$.fragment,e),w(Ke.$$.fragment,e),w(ke.$$.fragment,e),w(Ze.$$.fragment,e),w(et.$$.fragment,e),w(tt.$$.fragment,e),w(ye.$$.fragment,e),w(at.$$.fragment,e),w(st.$$.fragment,e),w(Pe.$$.fragment,e),w(it.$$.fragment,e),w(ot.$$.fragment,e),w(rt.$$.fragment,e),w(lt.$$.fragment,e),w(nt.$$.fragment,e),w(pt.$$.fragment,e),zs=!0)},o(e){D($.$$.fragment,e),D(Se.$$.fragment,e),D(Ve.$$.fragment,e),D(Qe.$$.fragment,e),D(Ne.$$.fragment,e),D(We.$$.fragment,e),D(Re.$$.fragment,e),D(ge.$$.fragment,e),D(Ue.$$.fragment,e),D($e.$$.fragment,e),D(Xe.$$.fragment,e),D(be.$$.fragment,e),D(Ke.$$.fragment,e),D(ke.$$.fragment,e),D(Ze.$$.fragment,e),D(et.$$.fragment,e),D(tt.$$.fragment,e),D(ye.$$.fragment,e),D(at.$$.fragment,e),D(st.$$.fragment,e),D(Pe.$$.fragment,e),D(it.$$.fragment,e),D(ot.$$.fragment,e),D(rt.$$.fragment,e),D(lt.$$.fragment,e),D(nt.$$.fragment,e),D(pt.$$.fragment,e),zs=!1},d(e){a(c),e&&a(_),e&&a(u),C($),e&&a(I),e&&a(y),e&&a(F),e&&a(Q),e&&a(ja),e&&a(ie),C(Se),e&&a(ka),e&&a(U),e&&a(wa),e&&a(Y),e&&a(Da),C(Ve,e),e&&a(Ca),e&&a(oe),e&&a(ya),e&&a(de),e&&a(Ta),C(Qe,e),e&&a(Pa),e&&a(fe),e&&a(Fa),C(Ne,e),e&&a(Ba),e&&a(me),e&&a(xa),C(We,e),e&&a(Aa),e&&a(he),e&&a(Oa),C(Re,e),e&&a(Ma),C(ge,e),e&&a(Sa),e&&a(re),C(Ue),e&&a(Va),e&&a(R),e&&a(Ia),C($e,e),e&&a(La),e&&a(le),C(Xe),e&&a(Qa),e&&a(ze),e&&a(Na),C(be,e),e&&a(Wa),e&&a(ne),C(Ke),e&&a(Ra),e&&a(Ee),e&&a(Ua),e&&a(je),e&&a(Ga),e&&a($t),e&&a(Ha),C(ke,e),e&&a(Ja),e&&a(we),e&&a(Xa),C(Ze,e),e&&a(Ka),e&&a(De),e&&a(Ya),C(et,e),e&&a(Za),e&&a(Ce),e&&a(es),C(tt,e),e&&a(ts),C(ye,e),e&&a(as),e&&a(pe),C(at),e&&a(ss),e&&a(J),e&&a(is),e&&a(ee),e&&a(os),C(st,e),e&&a(rs),C(Pe,e),e&&a(ls),e&&a(Fe),e&&a(ns),C(it,e),e&&a(ps),e&&a(Be),e&&a(cs),C(ot,e),e&&a(us),e&&a(ce),C(rt),e&&a(ds),e&&a(Ae),e&&a(fs),e&&a(zt),e&&a(ms),C(lt,e),e&&a(hs),e&&a(bt),e&&a(gs),C(nt,e),e&&a(_s),e&&a(Oe),e&&a($s),C(pt,e),e&&a(vs),e&&a(qt)}}}const Ql={local:"crea-unarchitettura-personalizzata",sections:[{local:"configurazione",title:"Configurazione"},{local:"modello",sections:[{local:"model-head",title:"Model head"}],title:"Modello"},{local:"tokenizer",title:"Tokenizer"},{local:"estrattore-di-feature",title:"Estrattore Di Feature"},{local:"processore",title:"Processore"}],title:"Crea un'architettura personalizzata "};function Nl(V){return Cl(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Xl extends jl{constructor(c){super();kl(this,c,Nl,Ll,wl,{})}}export{Xl as default,Ql as metadata};
