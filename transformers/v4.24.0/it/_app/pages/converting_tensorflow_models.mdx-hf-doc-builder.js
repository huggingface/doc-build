import{S as Fl,i as Ul,s as jl,e as r,k as f,w as d,t as n,M as zl,c as l,d as t,m as _,a as i,x as u,h as a,b as c,G as o,g as p,y as m,q as v,o as E,B as T,v as ql}from"../chunks/vendor-hf-doc-builder.js";import{T as Kl}from"../chunks/Tip-hf-doc-builder.js";import{I as z}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as _e}from"../chunks/CodeBlock-hf-doc-builder.js";function Ml($t){let h,q,$,O,R,y,N,H,S,K,k;return{c(){h=r("p"),q=n("A partire dalla versione 2.3.0 lo script di conversione \xE8 parte di transformers CLI ("),$=r("strong"),O=n("transformers-cli"),R=n(`), disponibile in ogni installazione
di transformers >=2.3.0.`),y=f(),N=r("p"),H=n("La seguente documentazione riflette il formato dei comandi di "),S=r("strong"),K=n("transformers-cli convert"),k=n(".")},l(A){h=l(A,"P",{});var b=i(h);q=a(b,"A partire dalla versione 2.3.0 lo script di conversione \xE8 parte di transformers CLI ("),$=l(b,"STRONG",{});var Xe=i($);O=a(Xe,"transformers-cli"),Xe.forEach(t),R=a(b,`), disponibile in ogni installazione
di transformers >=2.3.0.`),b.forEach(t),y=_(A),N=l(A,"P",{});var M=i(N);H=a(M,"La seguente documentazione riflette il formato dei comandi di "),S=l(M,"STRONG",{});var he=i(S);K=a(he,"transformers-cli convert"),he.forEach(t),k=a(M,"."),M.forEach(t)},m(A,b){p(A,h,b),o(h,q),o(h,$),o($,O),o(h,R),p(A,y,b),p(A,N,b),o(N,H),o(N,S),o(S,K),o(N,k)},d(A){A&&t(h),A&&t(y),A&&t(N)}}}function Yl($t){let h,q,$,O,R,y,N,H,S,K,k,A,b,Xe,M,he,Y,At,x,Q,Me,de,Po,Ye,$o,bt,I,Ao,ue,bo,go,me,Oo,yo,gt,P,No,Qe,ko,wo,Je,Io,Co,Ve,Lo,Ro,Fe,Ho,So,ve,xo,Do,Ot,g,Bo,We,Go,Xo,Ze,Fo,Uo,et,jo,zo,tt,qo,Ko,yt,J,Mo,ot,Yo,Qo,Nt,V,Jo,rt,Vo,Wo,kt,Ee,wt,W,Zo,Te,er,tr,It,D,Z,lt,Pe,or,it,rr,Ct,ee,lr,$e,ir,nr,Lt,C,ar,nt,sr,pr,at,cr,fr,Rt,te,_r,st,hr,dr,Ht,Ae,St,oe,ur,be,mr,vr,xt,B,re,pt,ge,Er,ct,Tr,Dt,le,Pr,Oe,$r,Ar,Bt,ye,Gt,G,ie,ft,Ne,br,_t,gr,Xt,ne,Or,ke,yr,Nr,Ft,we,Ut,X,ae,ht,Ie,kr,dt,wr,jt,se,Ir,Ce,Cr,Lr,zt,Le,qt,F,pe,ut,Re,Rr,mt,Hr,Kt,Ue,Sr,Mt,He,Yt,U,ce,vt,Se,xr,Et,Dr,Qt,je,Br,Jt,xe,Vt,j,fe,Tt,De,Gr,Pt,Xr,Wt,ze,Fr,Zt,Be,eo;return y=new z({}),Y=new Kl({props:{$$slots:{default:[Ml]},$$scope:{ctx:$t}}}),de=new z({}),Ee=new _e({props:{code:`export BERT_BASE_DIR=/path/to/bert/uncased_L-12_H-768_A-12
transformers-cli convert --model_type bert \\
  --tf_checkpoint $BERT_BASE_DIR/bert_model.ckpt \\
  --config $BERT_BASE_DIR/bert_config.json \\
  --pytorch_dump_output $BERT_BASE_DIR/pytorch_model.bin`,highlighted:`<span class="hljs-built_in">export</span> BERT_BASE_DIR=/path/to/bert/uncased_L-12_H-768_A-12
transformers-cli convert --model_type bert \\
  --tf_checkpoint <span class="hljs-variable">$BERT_BASE_DIR</span>/bert_model.ckpt \\
  --config <span class="hljs-variable">$BERT_BASE_DIR</span>/bert_config.json \\
  --pytorch_dump_output <span class="hljs-variable">$BERT_BASE_DIR</span>/pytorch_model.bin`}}),Pe=new z({}),Ae=new _e({props:{code:`export ALBERT_BASE_DIR=/path/to/albert/albert_base
transformers-cli convert --model_type albert \\
  --tf_checkpoint $ALBERT_BASE_DIR/model.ckpt-best \\
  --config $ALBERT_BASE_DIR/albert_config.json \\
  --pytorch_dump_output $ALBERT_BASE_DIR/pytorch_model.bin`,highlighted:`<span class="hljs-built_in">export</span> ALBERT_BASE_DIR=/path/to/albert/albert_base
transformers-cli convert --model_type albert \\
  --tf_checkpoint <span class="hljs-variable">$ALBERT_BASE_DIR</span>/model.ckpt-best \\
  --config <span class="hljs-variable">$ALBERT_BASE_DIR</span>/albert_config.json \\
  --pytorch_dump_output <span class="hljs-variable">$ALBERT_BASE_DIR</span>/pytorch_model.bin`}}),ge=new z({}),ye=new _e({props:{code:`export OPENAI_GPT_CHECKPOINT_FOLDER_PATH=/path/to/openai/pretrained/numpy/weights
transformers-cli convert --model_type gpt \\
  --tf_checkpoint $OPENAI_GPT_CHECKPOINT_FOLDER_PATH \\
  --pytorch_dump_output $PYTORCH_DUMP_OUTPUT \\
  [--config OPENAI_GPT_CONFIG] \\
  [--finetuning_task_name OPENAI_GPT_FINETUNED_TASK] \\`,highlighted:`<span class="hljs-built_in">export</span> OPENAI_GPT_CHECKPOINT_FOLDER_PATH=/path/to/openai/pretrained/numpy/weights
transformers-cli convert --model_type gpt \\
  --tf_checkpoint <span class="hljs-variable">$OPENAI_GPT_CHECKPOINT_FOLDER_PATH</span> \\
  --pytorch_dump_output <span class="hljs-variable">$PYTORCH_DUMP_OUTPUT</span> \\
  [--config OPENAI_GPT_CONFIG] \\
  [--finetuning_task_name OPENAI_GPT_FINETUNED_TASK] \\`}}),Ne=new z({}),we=new _e({props:{code:`export OPENAI_GPT2_CHECKPOINT_PATH=/path/to/gpt2/pretrained/weights
transformers-cli convert --model_type gpt2 \\
  --tf_checkpoint $OPENAI_GPT2_CHECKPOINT_PATH \\
  --pytorch_dump_output $PYTORCH_DUMP_OUTPUT \\
  [--config OPENAI_GPT2_CONFIG] \\
  [--finetuning_task_name OPENAI_GPT2_FINETUNED_TASK]`,highlighted:`<span class="hljs-built_in">export</span> OPENAI_GPT2_CHECKPOINT_PATH=/path/to/gpt2/pretrained/weights
transformers-cli convert --model_type gpt2 \\
  --tf_checkpoint <span class="hljs-variable">$OPENAI_GPT2_CHECKPOINT_PATH</span> \\
  --pytorch_dump_output <span class="hljs-variable">$PYTORCH_DUMP_OUTPUT</span> \\
  [--config OPENAI_GPT2_CONFIG] \\
  [--finetuning_task_name OPENAI_GPT2_FINETUNED_TASK]`}}),Ie=new z({}),Le=new _e({props:{code:`export TRANSFO_XL_CHECKPOINT_FOLDER_PATH=/path/to/transfo/xl/checkpoint
transformers-cli convert --model_type transfo_xl \\
  --tf_checkpoint $TRANSFO_XL_CHECKPOINT_FOLDER_PATH \\
  --pytorch_dump_output $PYTORCH_DUMP_OUTPUT \\
  [--config TRANSFO_XL_CONFIG] \\
  [--finetuning_task_name TRANSFO_XL_FINETUNED_TASK]`,highlighted:`<span class="hljs-built_in">export</span> TRANSFO_XL_CHECKPOINT_FOLDER_PATH=/path/to/transfo/xl/checkpoint
transformers-cli convert --model_type transfo_xl \\
  --tf_checkpoint <span class="hljs-variable">$TRANSFO_XL_CHECKPOINT_FOLDER_PATH</span> \\
  --pytorch_dump_output <span class="hljs-variable">$PYTORCH_DUMP_OUTPUT</span> \\
  [--config TRANSFO_XL_CONFIG] \\
  [--finetuning_task_name TRANSFO_XL_FINETUNED_TASK]`}}),Re=new z({}),He=new _e({props:{code:`export TRANSFO_XL_CHECKPOINT_PATH=/path/to/xlnet/checkpoint
export TRANSFO_XL_CONFIG_PATH=/path/to/xlnet/config
transformers-cli convert --model_type xlnet \\
  --tf_checkpoint $TRANSFO_XL_CHECKPOINT_PATH \\
  --config $TRANSFO_XL_CONFIG_PATH \\
  --pytorch_dump_output $PYTORCH_DUMP_OUTPUT \\
  [--finetuning_task_name XLNET_FINETUNED_TASK] \\`,highlighted:`<span class="hljs-built_in">export</span> TRANSFO_XL_CHECKPOINT_PATH=/path/to/xlnet/checkpoint
<span class="hljs-built_in">export</span> TRANSFO_XL_CONFIG_PATH=/path/to/xlnet/config
transformers-cli convert --model_type xlnet \\
  --tf_checkpoint <span class="hljs-variable">$TRANSFO_XL_CHECKPOINT_PATH</span> \\
  --config <span class="hljs-variable">$TRANSFO_XL_CONFIG_PATH</span> \\
  --pytorch_dump_output <span class="hljs-variable">$PYTORCH_DUMP_OUTPUT</span> \\
  [--finetuning_task_name XLNET_FINETUNED_TASK] \\`}}),Se=new z({}),xe=new _e({props:{code:`export XLM_CHECKPOINT_PATH=/path/to/xlm/checkpoint
transformers-cli convert --model_type xlm \\
  --tf_checkpoint $XLM_CHECKPOINT_PATH \\
  --pytorch_dump_output $PYTORCH_DUMP_OUTPUT
 [--config XML_CONFIG] \\
 [--finetuning_task_name XML_FINETUNED_TASK]`,highlighted:`<span class="hljs-built_in">export</span> XLM_CHECKPOINT_PATH=/path/to/xlm/checkpoint
transformers-cli convert --model_type xlm \\
  --tf_checkpoint <span class="hljs-variable">$XLM_CHECKPOINT_PATH</span> \\
  --pytorch_dump_output <span class="hljs-variable">$PYTORCH_DUMP_OUTPUT</span>
 [--config XML_CONFIG] \\
 [--finetuning_task_name XML_FINETUNED_TASK]`}}),De=new z({}),Be=new _e({props:{code:`export T5=/path/to/t5/uncased_L-12_H-768_A-12
transformers-cli convert --model_type t5 \\
  --tf_checkpoint $T5/t5_model.ckpt \\
  --config $T5/t5_config.json \\
  --pytorch_dump_output $T5/pytorch_model.bin`,highlighted:`<span class="hljs-built_in">export</span> T5=/path/to/t5/uncased_L-12_H-768_A-12
transformers-cli convert --model_type t5 \\
  --tf_checkpoint <span class="hljs-variable">$T5</span>/t5_model.ckpt \\
  --config <span class="hljs-variable">$T5</span>/t5_config.json \\
  --pytorch_dump_output <span class="hljs-variable">$T5</span>/pytorch_model.bin`}}),{c(){h=r("meta"),q=f(),$=r("h1"),O=r("a"),R=r("span"),d(y.$$.fragment),N=f(),H=r("span"),S=n("Convertire checkpoint di Tensorflow"),K=f(),k=r("p"),A=n(`\xC8 disponibile un\u2019interfaccia a linea di comando per convertire gli originali checkpoint di Bert/GPT/GPT-2/Transformer-XL/XLNet/XLM
in modelli che possono essere caricati utilizzando i metodi `),b=r("code"),Xe=n("from_pretrained"),M=n(" della libreria."),he=f(),d(Y.$$.fragment),At=f(),x=r("h2"),Q=r("a"),Me=r("span"),d(de.$$.fragment),Po=f(),Ye=r("span"),$o=n("BERT"),bt=f(),I=r("p"),Ao=n(`Puoi convertire qualunque checkpoint Tensorflow di BERT (in particolare
`),ue=r("a"),bo=n("i modeli pre-allenati rilasciati da Google"),go=n(`)
in un file di salvataggio Pytorch utilizzando lo script
`),me=r("a"),Oo=n("convert_bert_original_tf_checkpoint_to_pytorch.py"),yo=n("."),gt=f(),P=r("p"),No=n("Questo CLI prende come input un checkpoint di Tensorflow (tre files che iniziano con "),Qe=r("code"),ko=n("bert_model.ckpt"),wo=n(`) ed il relativo
file di configurazione (`),Je=r("code"),Io=n("bert_config.json"),Co=n(`), crea un modello Pytorch per questa configurazione, carica i pesi dal
checkpoint di Tensorflow nel modello di Pytorch e salva il modello che ne risulta in un file di salvataggio standard di Pytorch che
pu\xF2 essere importato utilizzando `),Ve=r("code"),Lo=n("from_pretrained()"),Ro=n(` (vedi l\u2019esempio nel
`),Fe=r("a"),Ho=n("quicktour"),So=n(" , "),ve=r("a"),xo=n("run_glue.py"),Do=n(" )."),Ot=f(),g=r("p"),Bo=n("Devi soltanto lanciare questo script di conversione "),We=r("strong"),Go=n("una volta"),Xo=n(` per ottenere un modello Pytorch. Dopodich\xE8, potrai tralasciare
il checkpoint di Tensorflow (i tre files che iniziano con `),Ze=r("code"),Fo=n("bert_model.ckpt"),Uo=n(`), ma assicurati di tenere il file di configurazione
(`),et=r("code"),jo=n("bert_config.json"),zo=n(") ed il file di vocabolario ("),tt=r("code"),qo=n("vocab.txt"),Ko=n(") in quanto queste componenti sono necessarie anche per il modello di Pytorch."),yt=f(),J=r("p"),Mo=n(`Per lanciare questo specifico script di conversione avrai bisogno di un\u2019installazione di Tensorflow e di Pytorch
(`),ot=r("code"),Yo=n("pip install tensorflow"),Qo=n("). Il resto della repository richiede soltanto Pytorch."),Nt=f(),V=r("p"),Jo=n("Questo \xE8 un esempio del processo di conversione per un modello "),rt=r("code"),Vo=n("BERT-Base Uncased"),Wo=n(" pre-allenato:"),kt=f(),d(Ee.$$.fragment),wt=f(),W=r("p"),Zo=n("Puoi scaricare i modelli pre-allenati di Google per la conversione "),Te=r("a"),er=n("qua"),tr=n("."),It=f(),D=r("h2"),Z=r("a"),lt=r("span"),d(Pe.$$.fragment),or=f(),it=r("span"),rr=n("ALBERT"),Ct=f(),ee=r("p"),lr=n(`Per il modello ALBERT, converti checkpoint di Tensoflow in Pytorch utilizzando lo script
`),$e=r("a"),ir=n("convert_albert_original_tf_checkpoint_to_pytorch.py"),nr=n("."),Lt=f(),C=r("p"),ar=n("Il CLI prende come input un checkpoint di Tensorflow (tre files che iniziano con "),nt=r("code"),sr=n("model.ckpt-best"),pr=n(`) e i relativi file di
configurazione (`),at=r("code"),cr=n("albert_config.json"),fr=n(`), dopodich\xE8 crea e salva un modello Pytorch. Per lanciare questa conversione
avrai bisogno di un\u2019installazione di Tensorflow e di Pytorch.`),Rt=f(),te=r("p"),_r=n("Ecco un esempio del procedimento di conversione di un modello "),st=r("code"),hr=n("ALBERT Base"),dr=n(" pre-allenato:"),Ht=f(),d(Ae.$$.fragment),St=f(),oe=r("p"),ur=n("Puoi scaricare i modelli pre-allenati di Google per la conversione "),be=r("a"),mr=n("qui"),vr=n("."),xt=f(),B=r("h2"),re=r("a"),pt=r("span"),d(ge.$$.fragment),Er=f(),ct=r("span"),Tr=n("OpenAI GPT"),Dt=f(),le=r("p"),Pr=n(`Ecco un esempio del processo di conversione di un modello OpenAI GPT pre-allenato, assumendo che il tuo checkpoint di NumPy
sia salvato nello stesso formato dei modelli pre-allenati OpenAI (vedi `),Oe=r("a"),$r=n("qui"),Ar=n("):"),Bt=f(),d(ye.$$.fragment),Gt=f(),G=r("h2"),ie=r("a"),ft=r("span"),d(Ne.$$.fragment),br=f(),_t=r("span"),gr=n("OpenAI GPT-2"),Xt=f(),ne=r("p"),Or=n("Ecco un esempio del processo di conversione di un modello OpenAI GPT-2 pre-allenato (vedi "),ke=r("a"),yr=n("qui"),Nr=n("):"),Ft=f(),d(we.$$.fragment),Ut=f(),X=r("h2"),ae=r("a"),ht=r("span"),d(Ie.$$.fragment),kr=f(),dt=r("span"),wr=n("Transformer-XL"),jt=f(),se=r("p"),Ir=n(`Ecco un esempio del processo di conversione di un modello Transformer-XL pre-allenato
(vedi `),Ce=r("a"),Cr=n("qui"),Lr=n("):"),zt=f(),d(Le.$$.fragment),qt=f(),F=r("h2"),pe=r("a"),ut=r("span"),d(Re.$$.fragment),Rr=f(),mt=r("span"),Hr=n("XLNet"),Kt=f(),Ue=r("p"),Sr=n("Ecco un esempio del processo di conversione di un modello XLNet pre-allenato:"),Mt=f(),d(He.$$.fragment),Yt=f(),U=r("h2"),ce=r("a"),vt=r("span"),d(Se.$$.fragment),xr=f(),Et=r("span"),Dr=n("XLM"),Qt=f(),je=r("p"),Br=n("Ecco un esempio del processo di conversione di un modello XLM pre-allenato:"),Jt=f(),d(xe.$$.fragment),Vt=f(),j=r("h2"),fe=r("a"),Tt=r("span"),d(De.$$.fragment),Gr=f(),Pt=r("span"),Xr=n("T5"),Wt=f(),ze=r("p"),Fr=n("Ecco un esempio del processo di conversione di un modello T5 pre-allenato:"),Zt=f(),d(Be.$$.fragment),this.h()},l(e){const s=zl('[data-svelte="svelte-1phssyn"]',document.head);h=l(s,"META",{name:!0,content:!0}),s.forEach(t),q=_(e),$=l(e,"H1",{class:!0});var Ge=i($);O=l(Ge,"A",{id:!0,class:!0,href:!0});var Ur=i(O);R=l(Ur,"SPAN",{});var jr=i(R);u(y.$$.fragment,jr),jr.forEach(t),Ur.forEach(t),N=_(Ge),H=l(Ge,"SPAN",{});var zr=i(H);S=a(zr,"Convertire checkpoint di Tensorflow"),zr.forEach(t),Ge.forEach(t),K=_(e),k=l(e,"P",{});var to=i(k);A=a(to,`\xC8 disponibile un\u2019interfaccia a linea di comando per convertire gli originali checkpoint di Bert/GPT/GPT-2/Transformer-XL/XLNet/XLM
in modelli che possono essere caricati utilizzando i metodi `),b=l(to,"CODE",{});var qr=i(b);Xe=a(qr,"from_pretrained"),qr.forEach(t),M=a(to," della libreria."),to.forEach(t),he=_(e),u(Y.$$.fragment,e),At=_(e),x=l(e,"H2",{class:!0});var oo=i(x);Q=l(oo,"A",{id:!0,class:!0,href:!0});var Kr=i(Q);Me=l(Kr,"SPAN",{});var Mr=i(Me);u(de.$$.fragment,Mr),Mr.forEach(t),Kr.forEach(t),Po=_(oo),Ye=l(oo,"SPAN",{});var Yr=i(Ye);$o=a(Yr,"BERT"),Yr.forEach(t),oo.forEach(t),bt=_(e),I=l(e,"P",{});var qe=i(I);Ao=a(qe,`Puoi convertire qualunque checkpoint Tensorflow di BERT (in particolare
`),ue=l(qe,"A",{href:!0,rel:!0});var Qr=i(ue);bo=a(Qr,"i modeli pre-allenati rilasciati da Google"),Qr.forEach(t),go=a(qe,`)
in un file di salvataggio Pytorch utilizzando lo script
`),me=l(qe,"A",{href:!0,rel:!0});var Jr=i(me);Oo=a(Jr,"convert_bert_original_tf_checkpoint_to_pytorch.py"),Jr.forEach(t),yo=a(qe,"."),qe.forEach(t),gt=_(e),P=l(e,"P",{});var w=i(P);No=a(w,"Questo CLI prende come input un checkpoint di Tensorflow (tre files che iniziano con "),Qe=l(w,"CODE",{});var Vr=i(Qe);ko=a(Vr,"bert_model.ckpt"),Vr.forEach(t),wo=a(w,`) ed il relativo
file di configurazione (`),Je=l(w,"CODE",{});var Wr=i(Je);Io=a(Wr,"bert_config.json"),Wr.forEach(t),Co=a(w,`), crea un modello Pytorch per questa configurazione, carica i pesi dal
checkpoint di Tensorflow nel modello di Pytorch e salva il modello che ne risulta in un file di salvataggio standard di Pytorch che
pu\xF2 essere importato utilizzando `),Ve=l(w,"CODE",{});var Zr=i(Ve);Lo=a(Zr,"from_pretrained()"),Zr.forEach(t),Ro=a(w,` (vedi l\u2019esempio nel
`),Fe=l(w,"A",{href:!0});var el=i(Fe);Ho=a(el,"quicktour"),el.forEach(t),So=a(w," , "),ve=l(w,"A",{href:!0,rel:!0});var tl=i(ve);xo=a(tl,"run_glue.py"),tl.forEach(t),Do=a(w," )."),w.forEach(t),Ot=_(e),g=l(e,"P",{});var L=i(g);Bo=a(L,"Devi soltanto lanciare questo script di conversione "),We=l(L,"STRONG",{});var ol=i(We);Go=a(ol,"una volta"),ol.forEach(t),Xo=a(L,` per ottenere un modello Pytorch. Dopodich\xE8, potrai tralasciare
il checkpoint di Tensorflow (i tre files che iniziano con `),Ze=l(L,"CODE",{});var rl=i(Ze);Fo=a(rl,"bert_model.ckpt"),rl.forEach(t),Uo=a(L,`), ma assicurati di tenere il file di configurazione
(`),et=l(L,"CODE",{});var ll=i(et);jo=a(ll,"bert_config.json"),ll.forEach(t),zo=a(L,") ed il file di vocabolario ("),tt=l(L,"CODE",{});var il=i(tt);qo=a(il,"vocab.txt"),il.forEach(t),Ko=a(L,") in quanto queste componenti sono necessarie anche per il modello di Pytorch."),L.forEach(t),yt=_(e),J=l(e,"P",{});var ro=i(J);Mo=a(ro,`Per lanciare questo specifico script di conversione avrai bisogno di un\u2019installazione di Tensorflow e di Pytorch
(`),ot=l(ro,"CODE",{});var nl=i(ot);Yo=a(nl,"pip install tensorflow"),nl.forEach(t),Qo=a(ro,"). Il resto della repository richiede soltanto Pytorch."),ro.forEach(t),Nt=_(e),V=l(e,"P",{});var lo=i(V);Jo=a(lo,"Questo \xE8 un esempio del processo di conversione per un modello "),rt=l(lo,"CODE",{});var al=i(rt);Vo=a(al,"BERT-Base Uncased"),al.forEach(t),Wo=a(lo," pre-allenato:"),lo.forEach(t),kt=_(e),u(Ee.$$.fragment,e),wt=_(e),W=l(e,"P",{});var io=i(W);Zo=a(io,"Puoi scaricare i modelli pre-allenati di Google per la conversione "),Te=l(io,"A",{href:!0,rel:!0});var sl=i(Te);er=a(sl,"qua"),sl.forEach(t),tr=a(io,"."),io.forEach(t),It=_(e),D=l(e,"H2",{class:!0});var no=i(D);Z=l(no,"A",{id:!0,class:!0,href:!0});var pl=i(Z);lt=l(pl,"SPAN",{});var cl=i(lt);u(Pe.$$.fragment,cl),cl.forEach(t),pl.forEach(t),or=_(no),it=l(no,"SPAN",{});var fl=i(it);rr=a(fl,"ALBERT"),fl.forEach(t),no.forEach(t),Ct=_(e),ee=l(e,"P",{});var ao=i(ee);lr=a(ao,`Per il modello ALBERT, converti checkpoint di Tensoflow in Pytorch utilizzando lo script
`),$e=l(ao,"A",{href:!0,rel:!0});var _l=i($e);ir=a(_l,"convert_albert_original_tf_checkpoint_to_pytorch.py"),_l.forEach(t),nr=a(ao,"."),ao.forEach(t),Lt=_(e),C=l(e,"P",{});var Ke=i(C);ar=a(Ke,"Il CLI prende come input un checkpoint di Tensorflow (tre files che iniziano con "),nt=l(Ke,"CODE",{});var hl=i(nt);sr=a(hl,"model.ckpt-best"),hl.forEach(t),pr=a(Ke,`) e i relativi file di
configurazione (`),at=l(Ke,"CODE",{});var dl=i(at);cr=a(dl,"albert_config.json"),dl.forEach(t),fr=a(Ke,`), dopodich\xE8 crea e salva un modello Pytorch. Per lanciare questa conversione
avrai bisogno di un\u2019installazione di Tensorflow e di Pytorch.`),Ke.forEach(t),Rt=_(e),te=l(e,"P",{});var so=i(te);_r=a(so,"Ecco un esempio del procedimento di conversione di un modello "),st=l(so,"CODE",{});var ul=i(st);hr=a(ul,"ALBERT Base"),ul.forEach(t),dr=a(so," pre-allenato:"),so.forEach(t),Ht=_(e),u(Ae.$$.fragment,e),St=_(e),oe=l(e,"P",{});var po=i(oe);ur=a(po,"Puoi scaricare i modelli pre-allenati di Google per la conversione "),be=l(po,"A",{href:!0,rel:!0});var ml=i(be);mr=a(ml,"qui"),ml.forEach(t),vr=a(po,"."),po.forEach(t),xt=_(e),B=l(e,"H2",{class:!0});var co=i(B);re=l(co,"A",{id:!0,class:!0,href:!0});var vl=i(re);pt=l(vl,"SPAN",{});var El=i(pt);u(ge.$$.fragment,El),El.forEach(t),vl.forEach(t),Er=_(co),ct=l(co,"SPAN",{});var Tl=i(ct);Tr=a(Tl,"OpenAI GPT"),Tl.forEach(t),co.forEach(t),Dt=_(e),le=l(e,"P",{});var fo=i(le);Pr=a(fo,`Ecco un esempio del processo di conversione di un modello OpenAI GPT pre-allenato, assumendo che il tuo checkpoint di NumPy
sia salvato nello stesso formato dei modelli pre-allenati OpenAI (vedi `),Oe=l(fo,"A",{href:!0,rel:!0});var Pl=i(Oe);$r=a(Pl,"qui"),Pl.forEach(t),Ar=a(fo,"):"),fo.forEach(t),Bt=_(e),u(ye.$$.fragment,e),Gt=_(e),G=l(e,"H2",{class:!0});var _o=i(G);ie=l(_o,"A",{id:!0,class:!0,href:!0});var $l=i(ie);ft=l($l,"SPAN",{});var Al=i(ft);u(Ne.$$.fragment,Al),Al.forEach(t),$l.forEach(t),br=_(_o),_t=l(_o,"SPAN",{});var bl=i(_t);gr=a(bl,"OpenAI GPT-2"),bl.forEach(t),_o.forEach(t),Xt=_(e),ne=l(e,"P",{});var ho=i(ne);Or=a(ho,"Ecco un esempio del processo di conversione di un modello OpenAI GPT-2 pre-allenato (vedi "),ke=l(ho,"A",{href:!0,rel:!0});var gl=i(ke);yr=a(gl,"qui"),gl.forEach(t),Nr=a(ho,"):"),ho.forEach(t),Ft=_(e),u(we.$$.fragment,e),Ut=_(e),X=l(e,"H2",{class:!0});var uo=i(X);ae=l(uo,"A",{id:!0,class:!0,href:!0});var Ol=i(ae);ht=l(Ol,"SPAN",{});var yl=i(ht);u(Ie.$$.fragment,yl),yl.forEach(t),Ol.forEach(t),kr=_(uo),dt=l(uo,"SPAN",{});var Nl=i(dt);wr=a(Nl,"Transformer-XL"),Nl.forEach(t),uo.forEach(t),jt=_(e),se=l(e,"P",{});var mo=i(se);Ir=a(mo,`Ecco un esempio del processo di conversione di un modello Transformer-XL pre-allenato
(vedi `),Ce=l(mo,"A",{href:!0,rel:!0});var kl=i(Ce);Cr=a(kl,"qui"),kl.forEach(t),Lr=a(mo,"):"),mo.forEach(t),zt=_(e),u(Le.$$.fragment,e),qt=_(e),F=l(e,"H2",{class:!0});var vo=i(F);pe=l(vo,"A",{id:!0,class:!0,href:!0});var wl=i(pe);ut=l(wl,"SPAN",{});var Il=i(ut);u(Re.$$.fragment,Il),Il.forEach(t),wl.forEach(t),Rr=_(vo),mt=l(vo,"SPAN",{});var Cl=i(mt);Hr=a(Cl,"XLNet"),Cl.forEach(t),vo.forEach(t),Kt=_(e),Ue=l(e,"P",{});var Ll=i(Ue);Sr=a(Ll,"Ecco un esempio del processo di conversione di un modello XLNet pre-allenato:"),Ll.forEach(t),Mt=_(e),u(He.$$.fragment,e),Yt=_(e),U=l(e,"H2",{class:!0});var Eo=i(U);ce=l(Eo,"A",{id:!0,class:!0,href:!0});var Rl=i(ce);vt=l(Rl,"SPAN",{});var Hl=i(vt);u(Se.$$.fragment,Hl),Hl.forEach(t),Rl.forEach(t),xr=_(Eo),Et=l(Eo,"SPAN",{});var Sl=i(Et);Dr=a(Sl,"XLM"),Sl.forEach(t),Eo.forEach(t),Qt=_(e),je=l(e,"P",{});var xl=i(je);Br=a(xl,"Ecco un esempio del processo di conversione di un modello XLM pre-allenato:"),xl.forEach(t),Jt=_(e),u(xe.$$.fragment,e),Vt=_(e),j=l(e,"H2",{class:!0});var To=i(j);fe=l(To,"A",{id:!0,class:!0,href:!0});var Dl=i(fe);Tt=l(Dl,"SPAN",{});var Bl=i(Tt);u(De.$$.fragment,Bl),Bl.forEach(t),Dl.forEach(t),Gr=_(To),Pt=l(To,"SPAN",{});var Gl=i(Pt);Xr=a(Gl,"T5"),Gl.forEach(t),To.forEach(t),Wt=_(e),ze=l(e,"P",{});var Xl=i(ze);Fr=a(Xl,"Ecco un esempio del processo di conversione di un modello T5 pre-allenato:"),Xl.forEach(t),Zt=_(e),u(Be.$$.fragment,e),this.h()},h(){c(h,"name","hf:doc:metadata"),c(h,"content",JSON.stringify(Ql)),c(O,"id","convertire-checkpoint-di-tensorflow"),c(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(O,"href","#convertire-checkpoint-di-tensorflow"),c($,"class","relative group"),c(Q,"id","bert"),c(Q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Q,"href","#bert"),c(x,"class","relative group"),c(ue,"href","https://github.com/google-research/bert#pre-trained-models"),c(ue,"rel","nofollow"),c(me,"href","https://github.com/huggingface/transformers/tree/main/src/transformers/models/bert/convert_bert_original_tf_checkpoint_to_pytorch.py"),c(me,"rel","nofollow"),c(Fe,"href","quicktour"),c(ve,"href","https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-classification/run_glue.py"),c(ve,"rel","nofollow"),c(Te,"href","https://github.com/google-research/bert#pre-trained-models"),c(Te,"rel","nofollow"),c(Z,"id","albert"),c(Z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z,"href","#albert"),c(D,"class","relative group"),c($e,"href","https://github.com/huggingface/transformers/tree/main/src/transformers/models/albert/convert_albert_original_tf_checkpoint_to_pytorch.py"),c($e,"rel","nofollow"),c(be,"href","https://github.com/google-research/albert#pre-trained-models"),c(be,"rel","nofollow"),c(re,"id","openai-gpt"),c(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(re,"href","#openai-gpt"),c(B,"class","relative group"),c(Oe,"href","https://github.com/openai/finetune-transformer-lm"),c(Oe,"rel","nofollow"),c(ie,"id","openai-gpt2"),c(ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ie,"href","#openai-gpt2"),c(G,"class","relative group"),c(ke,"href","https://github.com/openai/gpt-2"),c(ke,"rel","nofollow"),c(ae,"id","transformerxl"),c(ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ae,"href","#transformerxl"),c(X,"class","relative group"),c(Ce,"href","https://github.com/kimiyoung/transformer-xl/tree/master/tf#obtain-and-evaluate-pretrained-sota-models"),c(Ce,"rel","nofollow"),c(pe,"id","xlnet"),c(pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(pe,"href","#xlnet"),c(F,"class","relative group"),c(ce,"id","xlm"),c(ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ce,"href","#xlm"),c(U,"class","relative group"),c(fe,"id","t5"),c(fe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(fe,"href","#t5"),c(j,"class","relative group")},m(e,s){o(document.head,h),p(e,q,s),p(e,$,s),o($,O),o(O,R),m(y,R,null),o($,N),o($,H),o(H,S),p(e,K,s),p(e,k,s),o(k,A),o(k,b),o(b,Xe),o(k,M),p(e,he,s),m(Y,e,s),p(e,At,s),p(e,x,s),o(x,Q),o(Q,Me),m(de,Me,null),o(x,Po),o(x,Ye),o(Ye,$o),p(e,bt,s),p(e,I,s),o(I,Ao),o(I,ue),o(ue,bo),o(I,go),o(I,me),o(me,Oo),o(I,yo),p(e,gt,s),p(e,P,s),o(P,No),o(P,Qe),o(Qe,ko),o(P,wo),o(P,Je),o(Je,Io),o(P,Co),o(P,Ve),o(Ve,Lo),o(P,Ro),o(P,Fe),o(Fe,Ho),o(P,So),o(P,ve),o(ve,xo),o(P,Do),p(e,Ot,s),p(e,g,s),o(g,Bo),o(g,We),o(We,Go),o(g,Xo),o(g,Ze),o(Ze,Fo),o(g,Uo),o(g,et),o(et,jo),o(g,zo),o(g,tt),o(tt,qo),o(g,Ko),p(e,yt,s),p(e,J,s),o(J,Mo),o(J,ot),o(ot,Yo),o(J,Qo),p(e,Nt,s),p(e,V,s),o(V,Jo),o(V,rt),o(rt,Vo),o(V,Wo),p(e,kt,s),m(Ee,e,s),p(e,wt,s),p(e,W,s),o(W,Zo),o(W,Te),o(Te,er),o(W,tr),p(e,It,s),p(e,D,s),o(D,Z),o(Z,lt),m(Pe,lt,null),o(D,or),o(D,it),o(it,rr),p(e,Ct,s),p(e,ee,s),o(ee,lr),o(ee,$e),o($e,ir),o(ee,nr),p(e,Lt,s),p(e,C,s),o(C,ar),o(C,nt),o(nt,sr),o(C,pr),o(C,at),o(at,cr),o(C,fr),p(e,Rt,s),p(e,te,s),o(te,_r),o(te,st),o(st,hr),o(te,dr),p(e,Ht,s),m(Ae,e,s),p(e,St,s),p(e,oe,s),o(oe,ur),o(oe,be),o(be,mr),o(oe,vr),p(e,xt,s),p(e,B,s),o(B,re),o(re,pt),m(ge,pt,null),o(B,Er),o(B,ct),o(ct,Tr),p(e,Dt,s),p(e,le,s),o(le,Pr),o(le,Oe),o(Oe,$r),o(le,Ar),p(e,Bt,s),m(ye,e,s),p(e,Gt,s),p(e,G,s),o(G,ie),o(ie,ft),m(Ne,ft,null),o(G,br),o(G,_t),o(_t,gr),p(e,Xt,s),p(e,ne,s),o(ne,Or),o(ne,ke),o(ke,yr),o(ne,Nr),p(e,Ft,s),m(we,e,s),p(e,Ut,s),p(e,X,s),o(X,ae),o(ae,ht),m(Ie,ht,null),o(X,kr),o(X,dt),o(dt,wr),p(e,jt,s),p(e,se,s),o(se,Ir),o(se,Ce),o(Ce,Cr),o(se,Lr),p(e,zt,s),m(Le,e,s),p(e,qt,s),p(e,F,s),o(F,pe),o(pe,ut),m(Re,ut,null),o(F,Rr),o(F,mt),o(mt,Hr),p(e,Kt,s),p(e,Ue,s),o(Ue,Sr),p(e,Mt,s),m(He,e,s),p(e,Yt,s),p(e,U,s),o(U,ce),o(ce,vt),m(Se,vt,null),o(U,xr),o(U,Et),o(Et,Dr),p(e,Qt,s),p(e,je,s),o(je,Br),p(e,Jt,s),m(xe,e,s),p(e,Vt,s),p(e,j,s),o(j,fe),o(fe,Tt),m(De,Tt,null),o(j,Gr),o(j,Pt),o(Pt,Xr),p(e,Wt,s),p(e,ze,s),o(ze,Fr),p(e,Zt,s),m(Be,e,s),eo=!0},p(e,[s]){const Ge={};s&2&&(Ge.$$scope={dirty:s,ctx:e}),Y.$set(Ge)},i(e){eo||(v(y.$$.fragment,e),v(Y.$$.fragment,e),v(de.$$.fragment,e),v(Ee.$$.fragment,e),v(Pe.$$.fragment,e),v(Ae.$$.fragment,e),v(ge.$$.fragment,e),v(ye.$$.fragment,e),v(Ne.$$.fragment,e),v(we.$$.fragment,e),v(Ie.$$.fragment,e),v(Le.$$.fragment,e),v(Re.$$.fragment,e),v(He.$$.fragment,e),v(Se.$$.fragment,e),v(xe.$$.fragment,e),v(De.$$.fragment,e),v(Be.$$.fragment,e),eo=!0)},o(e){E(y.$$.fragment,e),E(Y.$$.fragment,e),E(de.$$.fragment,e),E(Ee.$$.fragment,e),E(Pe.$$.fragment,e),E(Ae.$$.fragment,e),E(ge.$$.fragment,e),E(ye.$$.fragment,e),E(Ne.$$.fragment,e),E(we.$$.fragment,e),E(Ie.$$.fragment,e),E(Le.$$.fragment,e),E(Re.$$.fragment,e),E(He.$$.fragment,e),E(Se.$$.fragment,e),E(xe.$$.fragment,e),E(De.$$.fragment,e),E(Be.$$.fragment,e),eo=!1},d(e){t(h),e&&t(q),e&&t($),T(y),e&&t(K),e&&t(k),e&&t(he),T(Y,e),e&&t(At),e&&t(x),T(de),e&&t(bt),e&&t(I),e&&t(gt),e&&t(P),e&&t(Ot),e&&t(g),e&&t(yt),e&&t(J),e&&t(Nt),e&&t(V),e&&t(kt),T(Ee,e),e&&t(wt),e&&t(W),e&&t(It),e&&t(D),T(Pe),e&&t(Ct),e&&t(ee),e&&t(Lt),e&&t(C),e&&t(Rt),e&&t(te),e&&t(Ht),T(Ae,e),e&&t(St),e&&t(oe),e&&t(xt),e&&t(B),T(ge),e&&t(Dt),e&&t(le),e&&t(Bt),T(ye,e),e&&t(Gt),e&&t(G),T(Ne),e&&t(Xt),e&&t(ne),e&&t(Ft),T(we,e),e&&t(Ut),e&&t(X),T(Ie),e&&t(jt),e&&t(se),e&&t(zt),T(Le,e),e&&t(qt),e&&t(F),T(Re),e&&t(Kt),e&&t(Ue),e&&t(Mt),T(He,e),e&&t(Yt),e&&t(U),T(Se),e&&t(Qt),e&&t(je),e&&t(Jt),T(xe,e),e&&t(Vt),e&&t(j),T(De),e&&t(Wt),e&&t(ze),e&&t(Zt),T(Be,e)}}}const Ql={local:"convertire-checkpoint-di-tensorflow",sections:[{local:"bert",title:"BERT"},{local:"albert",title:"ALBERT"},{local:"openai-gpt",title:"OpenAI GPT"},{local:"openai-gpt2",title:"OpenAI GPT-2"},{local:"transformerxl",title:"Transformer-XL"},{local:"xlnet",title:"XLNet"},{local:"xlm",title:"XLM"},{local:"t5",title:"T5"}],title:"Convertire checkpoint di Tensorflow"};function Jl($t){return ql(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ti extends Fl{constructor(h){super();Ul(this,h,Jl,Yl,jl,{})}}export{ti as default,Ql as metadata};
