import{S as dr,i as hr,s as $r,e as l,k as d,w as y,t as o,M as vr,c as n,d as t,m as h,a as c,x as M,h as s,b as _,G as r,g as u,y as S,q as N,o as I,B as O,v as _r,L as mr}from"../chunks/vendor-hf-doc-builder.js";import{T as kr}from"../chunks/Tip-hf-doc-builder.js";import{I as Re}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as ke}from"../chunks/CodeBlock-hf-doc-builder.js";import{F as br,M as fr}from"../chunks/Markdown-hf-doc-builder.js";import"../chunks/IconTensorflow-hf-doc-builder.js";function zr(Y){let i,z,p,v,A,k,L,q;return{c(){i=l("p"),z=o("Ricorda, con architettura ci si riferisce allo scheletro del modello e con checkpoint ai pesi di una determinata architettura. Per esempio, "),p=l("a"),v=o("BERT"),A=o(" \xE8 un\u2019architettura, mentre "),k=l("code"),L=o("bert-base-uncased"),q=o(" \xE8 un checkpoint. Modello \xE8 un termine generale che pu\xF2 significare sia architettura che checkpoint."),this.h()},l(E){i=n(E,"P",{});var w=c(i);z=s(w,"Ricorda, con architettura ci si riferisce allo scheletro del modello e con checkpoint ai pesi di una determinata architettura. Per esempio, "),p=n(w,"A",{href:!0,rel:!0});var j=c(p);v=s(j,"BERT"),j.forEach(t),A=s(w," \xE8 un\u2019architettura, mentre "),k=n(w,"CODE",{});var D=c(k);L=s(D,"bert-base-uncased"),D.forEach(t),q=s(w," \xE8 un checkpoint. Modello \xE8 un termine generale che pu\xF2 significare sia architettura che checkpoint."),w.forEach(t),this.h()},h(){_(p,"href","https://huggingface.co/bert-base-uncased"),_(p,"rel","nofollow")},m(E,w){u(E,i,w),r(i,z),r(i,p),r(p,v),r(i,A),r(i,k),r(k,L),r(i,q)},d(E){E&&t(i)}}}function gr(Y){let i,z,p,v,A,k,L,q,E,w,j,D,C,G,x,R,B,P,H,$,W,F,Z,X,g,U,ee,T,V,te,J;return C=new ke({props:{code:`from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),P=new ke({props:{code:`from transformers import AutoModelForTokenClassification

model = AutoModelForTokenClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),{c(){i=l("p"),z=o("Infine, le classi "),p=l("code"),v=o("AutoModelFor"),A=o(" ti permettono di caricare un modello pre-allenato per un determinato compito (guarda "),k=l("a"),L=o("qui"),q=o(" per una lista completa di compiti presenti). Per esempio, carica un modello per la classificazione di sequenze con "),E=l("code"),w=o("AutoModelForSequenceClassification.from_pretrained()"),j=o(":"),D=d(),y(C.$$.fragment),G=d(),x=l("p"),R=o("Semplicemente utilizza lo stesso checkpoint per caricare un\u2019architettura per un task differente:"),B=d(),y(P.$$.fragment),H=d(),$=l("p"),W=o("Generalmente, raccomandiamo di utilizzare la classe "),F=l("code"),Z=o("AutoTokenizer"),X=o(" e la classe "),g=l("code"),U=o("AutoModelFor"),ee=o(" per caricare istanze pre-allenate dei modelli. Questo ti assicurer\xE0 di aver caricato la corretta architettura ogni volta. Nel prossimo "),T=l("a"),V=o("tutorial"),te=o(", imparerai come utilizzare il tokenizer, il feature extractor e il processore per elaborare un dataset per il fine-tuning."),this.h()},l(a){i=n(a,"P",{});var f=c(i);z=s(f,"Infine, le classi "),p=n(f,"CODE",{});var se=c(p);v=s(se,"AutoModelFor"),se.forEach(t),A=s(f," ti permettono di caricare un modello pre-allenato per un determinato compito (guarda "),k=n(f,"A",{href:!0});var re=c(k);L=s(re,"qui"),re.forEach(t),q=s(f," per una lista completa di compiti presenti). Per esempio, carica un modello per la classificazione di sequenze con "),E=n(f,"CODE",{});var ie=c(E);w=s(ie,"AutoModelForSequenceClassification.from_pretrained()"),ie.forEach(t),j=s(f,":"),f.forEach(t),D=h(a),M(C.$$.fragment,a),G=h(a),x=n(a,"P",{});var oe=c(x);R=s(oe,"Semplicemente utilizza lo stesso checkpoint per caricare un\u2019architettura per un task differente:"),oe.forEach(t),B=h(a),M(P.$$.fragment,a),H=h(a),$=n(a,"P",{});var b=c($);W=s(b,"Generalmente, raccomandiamo di utilizzare la classe "),F=n(b,"CODE",{});var Q=c(F);Z=s(Q,"AutoTokenizer"),Q.forEach(t),X=s(b," e la classe "),g=n(b,"CODE",{});var ae=c(g);U=s(ae,"AutoModelFor"),ae.forEach(t),ee=s(b," per caricare istanze pre-allenate dei modelli. Questo ti assicurer\xE0 di aver caricato la corretta architettura ogni volta. Nel prossimo "),T=n(b,"A",{href:!0});var K=c(T);V=s(K,"tutorial"),K.forEach(t),te=s(b,", imparerai come utilizzare il tokenizer, il feature extractor e il processore per elaborare un dataset per il fine-tuning."),b.forEach(t),this.h()},h(){_(k,"href","model_doc/auto"),_(T,"href","preprocessing")},m(a,f){u(a,i,f),r(i,z),r(i,p),r(p,v),r(i,A),r(i,k),r(k,L),r(i,q),r(i,E),r(E,w),r(i,j),u(a,D,f),S(C,a,f),u(a,G,f),u(a,x,f),r(x,R),u(a,B,f),S(P,a,f),u(a,H,f),u(a,$,f),r($,W),r($,F),r(F,Z),r($,X),r($,g),r(g,U),r($,ee),r($,T),r(T,V),r($,te),J=!0},p:mr,i(a){J||(N(C.$$.fragment,a),N(P.$$.fragment,a),J=!0)},o(a){I(C.$$.fragment,a),I(P.$$.fragment,a),J=!1},d(a){a&&t(i),a&&t(D),O(C,a),a&&t(G),a&&t(x),a&&t(B),O(P,a),a&&t(H),a&&t($)}}}function Ar(Y){let i,z;return i=new fr({props:{$$slots:{default:[gr]},$$scope:{ctx:Y}}}),{c(){y(i.$$.fragment)},l(p){M(i.$$.fragment,p)},m(p,v){S(i,p,v),z=!0},p(p,v){const A={};v&2&&(A.$$scope={dirty:v,ctx:p}),i.$set(A)},i(p){z||(N(i.$$.fragment,p),z=!0)},o(p){I(i.$$.fragment,p),z=!1},d(p){O(i,p)}}}function Er(Y){let i,z,p,v,A,k,L,q,E,w,j,D,C,G,x,R,B,P,H,$,W,F,Z,X,g,U,ee,T,V,te,J;return C=new ke({props:{code:`from transformers import TFAutoModelForSequenceClassification

model = TFAutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),P=new ke({props:{code:`from transformers import TFAutoModelForTokenClassification

model = TFAutoModelForTokenClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),{c(){i=l("p"),z=o("Infine, le classi "),p=l("code"),v=o("TFAutoModelFor"),A=o(" ti permettono di caricare un modello pre-allenato per un determinato compito (guarda "),k=l("a"),L=o("qui"),q=o(" per una lista completa di compiti presenti). Per esempio, carica un modello per la classificazione di sequenze con "),E=l("code"),w=o("TFAutoModelForSequenceClassification.from_pretrained()"),j=o(":"),D=d(),y(C.$$.fragment),G=d(),x=l("p"),R=o("Semplicemente utilizza lo stesso checkpoint per caricare un\u2019architettura per un task differente:"),B=d(),y(P.$$.fragment),H=d(),$=l("p"),W=o("Generalmente, raccomandiamo di utilizzare la classe "),F=l("code"),Z=o("AutoTokenizer"),X=o(" e la classe "),g=l("code"),U=o("TFAutoModelFor"),ee=o(" per caricare istanze pre-allenate dei modelli. Questo ti assicurer\xE0 di aver caricato la corretta architettura ogni volta. Nel prossimo "),T=l("a"),V=o("tutorial"),te=o(", imparerai come utilizzare il tokenizer, il feature extractor e il processore per elaborare un dataset per il fine-tuning."),this.h()},l(a){i=n(a,"P",{});var f=c(i);z=s(f,"Infine, le classi "),p=n(f,"CODE",{});var se=c(p);v=s(se,"TFAutoModelFor"),se.forEach(t),A=s(f," ti permettono di caricare un modello pre-allenato per un determinato compito (guarda "),k=n(f,"A",{href:!0});var re=c(k);L=s(re,"qui"),re.forEach(t),q=s(f," per una lista completa di compiti presenti). Per esempio, carica un modello per la classificazione di sequenze con "),E=n(f,"CODE",{});var ie=c(E);w=s(ie,"TFAutoModelForSequenceClassification.from_pretrained()"),ie.forEach(t),j=s(f,":"),f.forEach(t),D=h(a),M(C.$$.fragment,a),G=h(a),x=n(a,"P",{});var oe=c(x);R=s(oe,"Semplicemente utilizza lo stesso checkpoint per caricare un\u2019architettura per un task differente:"),oe.forEach(t),B=h(a),M(P.$$.fragment,a),H=h(a),$=n(a,"P",{});var b=c($);W=s(b,"Generalmente, raccomandiamo di utilizzare la classe "),F=n(b,"CODE",{});var Q=c(F);Z=s(Q,"AutoTokenizer"),Q.forEach(t),X=s(b," e la classe "),g=n(b,"CODE",{});var ae=c(g);U=s(ae,"TFAutoModelFor"),ae.forEach(t),ee=s(b," per caricare istanze pre-allenate dei modelli. Questo ti assicurer\xE0 di aver caricato la corretta architettura ogni volta. Nel prossimo "),T=n(b,"A",{href:!0});var K=c(T);V=s(K,"tutorial"),K.forEach(t),te=s(b,", imparerai come utilizzare il tokenizer, il feature extractor e il processore per elaborare un dataset per il fine-tuning."),b.forEach(t),this.h()},h(){_(k,"href","model_doc/auto"),_(T,"href","preprocessing")},m(a,f){u(a,i,f),r(i,z),r(i,p),r(p,v),r(i,A),r(i,k),r(k,L),r(i,q),r(i,E),r(E,w),r(i,j),u(a,D,f),S(C,a,f),u(a,G,f),u(a,x,f),r(x,R),u(a,B,f),S(P,a,f),u(a,H,f),u(a,$,f),r($,W),r($,F),r(F,Z),r($,X),r($,g),r(g,U),r($,ee),r($,T),r(T,V),r($,te),J=!0},p:mr,i(a){J||(N(C.$$.fragment,a),N(P.$$.fragment,a),J=!0)},o(a){I(C.$$.fragment,a),I(P.$$.fragment,a),J=!1},d(a){a&&t(i),a&&t(D),O(C,a),a&&t(G),a&&t(x),a&&t(B),O(P,a),a&&t(H),a&&t($)}}}function wr(Y){let i,z;return i=new fr({props:{$$slots:{default:[Er]},$$scope:{ctx:Y}}}),{c(){y(i.$$.fragment)},l(p){M(i.$$.fragment,p)},m(p,v){S(i,p,v),z=!0},p(p,v){const A={};v&2&&(A.$$scope={dirty:v,ctx:p}),i.$set(A)},i(p){z||(N(i.$$.fragment,p),z=!0)},o(p){I(i.$$.fragment,p),z=!1},d(p){O(i,p)}}}function jr(Y){let i,z,p,v,A,k,L,q,E,w,j,D,C,G,x,R,B,P,H,$,W,F,Z,X,g,U,ee,T,V,te,J,a,f,se,re,ie,oe,b,Q,ae,K,ht,ye,$t,Be,Pe,vt,Ue,pe,_t,Me,kt,bt,Ve,be,Je,Fe,zt,Ke,ze,We,le,ue,Se,ge,gt,Ne,At,Xe,qe,Et,Ye,me,wt,Ie,jt,Ct,Ze,Ae,et,ne,fe,Oe,Ee,Pt,De,Ft,tt,de,qt,xe,xt,Tt,rt,he,yt,Le,Mt,St,at,we,ot,ce,$e,He,je,Nt,Qe,It,st,ve,it;return k=new Re({}),$=new kr({props:{$$slots:{default:[zr]},$$scope:{ctx:Y}}}),K=new Re({}),be=new ke({props:{code:`from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("xlm-roberta-base")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;xlm-roberta-base&quot;</span>)`}}),ze=new ke({props:{code:`sequenza = "In un buco nel terreno viveva uno Hobbit."
print(tokenizer(sequenza))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>sequenza = <span class="hljs-string">&quot;In un buco nel terreno viveva uno Hobbit.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(tokenizer(sequenza))
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">360</span>, <span class="hljs-number">51</span>, <span class="hljs-number">373</span>, <span class="hljs-number">587</span>, <span class="hljs-number">1718</span>, <span class="hljs-number">54644</span>, <span class="hljs-number">22597</span>, <span class="hljs-number">330</span>, <span class="hljs-number">3269</span>, <span class="hljs-number">2291</span>, <span class="hljs-number">22155</span>, <span class="hljs-number">18</span>, <span class="hljs-number">5</span>, <span class="hljs-number">2</span>],
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`}}),ge=new Re({}),Ae=new ke({props:{code:`from transformers import AutoFeatureExtractor

feature_extractor = AutoFeatureExtractor.from_pretrained(
    "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition"
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition&quot;</span>
<span class="hljs-meta">... </span>)`}}),Ee=new Re({}),we=new ke({props:{code:`from transformers import AutoProcessor

processor = AutoProcessor.from_pretrained("microsoft/layoutlmv2-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;microsoft/layoutlmv2-base-uncased&quot;</span>)`}}),je=new Re({}),ve=new br({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[wr],pytorch:[Ar]},$$scope:{ctx:Y}}}),{c(){i=l("meta"),z=d(),p=l("h1"),v=l("a"),A=l("span"),y(k.$$.fragment),L=d(),q=l("span"),E=o("Carica istanze pre-allenate con AutoClass"),w=d(),j=l("p"),D=o("Con cos\xEC tante architetture Transformer differenti, pu\xF2 essere sfidante crearne una per il tuo checkpoint. Come parte della filosofia centrale di \u{1F917} Transformers per rendere la libreria facile, semplice e flessibile da utilizzare, una "),C=l("code"),G=o("AutoClass"),x=o(" inferisce e carica automaticamente l\u2019architettura corretta da un dato checkpoint. Il metodo "),R=l("code"),B=o("from_pretrained"),P=o(" ti permette di caricare velocemente un modello pre-allenato per qualsiasi architettura, cos\xEC non devi utilizzare tempo e risorse per allenare un modello da zero. Produrre questo codice agnostico ai checkpoint significa che se il tuo codice funziona per un checkpoint, funzioner\xE0 anche per un altro checkpoint, purch\xE9 sia stato allenato per un compito simile, anche se l\u2019architettura \xE8 differente."),H=d(),y($.$$.fragment),W=d(),F=l("p"),Z=o("In questo tutorial, imparerai a:"),X=d(),g=l("ul"),U=l("li"),ee=o("Caricare un tokenizer pre-allenato."),T=d(),V=l("li"),te=o("Caricare un estrattore di caratteristiche (feature extractor, in inglese) pre-allenato."),J=d(),a=l("li"),f=o("Caricare un processore pre-allenato."),se=d(),re=l("li"),ie=o("Caricare un modello pre-allenato."),oe=d(),b=l("h2"),Q=l("a"),ae=l("span"),y(K.$$.fragment),ht=d(),ye=l("span"),$t=o("AutoTokenizer"),Be=d(),Pe=l("p"),vt=o("Quasi tutti i compiti di NLP iniziano con un tokenizer. Un tokenizer converte il tuo input in un formato che possa essere elaborato dal modello."),Ue=d(),pe=l("p"),_t=o("Carica un tokenizer con "),Me=l("code"),kt=o("AutoTokenizer.from_pretrained()"),bt=o(":"),Ve=d(),y(be.$$.fragment),Je=d(),Fe=l("p"),zt=o("Poi tokenizza il tuo input come mostrato in seguito:"),Ke=d(),y(ze.$$.fragment),We=d(),le=l("h2"),ue=l("a"),Se=l("span"),y(ge.$$.fragment),gt=d(),Ne=l("span"),At=o("AutoFeatureExtractor"),Xe=d(),qe=l("p"),Et=o("Per compiti inerenti a audio e video, un feature extractor processa il segnale audio o l\u2019immagine nel formato di input corretto."),Ye=d(),me=l("p"),wt=o("Carica un feature extractor con "),Ie=l("code"),jt=o("AutoFeatureExtractor.from_pretrained()"),Ct=o(":"),Ze=d(),y(Ae.$$.fragment),et=d(),ne=l("h2"),fe=l("a"),Oe=l("span"),y(Ee.$$.fragment),Pt=d(),De=l("span"),Ft=o("AutoProcessor"),tt=d(),de=l("p"),qt=o("Compiti multimodali richiedono un processore che combini i due tipi di strumenti di elaborazione. Per esempio, il modello "),xe=l("a"),xt=o("LayoutLMV2"),Tt=o(" richiede un feature extractor per gestire le immagine e un tokenizer per gestire il testo; un processore li combina entrambi."),rt=d(),he=l("p"),yt=o("Carica un processore con "),Le=l("code"),Mt=o("AutoProcessor.from_pretrained()"),St=o(":"),at=d(),y(we.$$.fragment),ot=d(),ce=l("h2"),$e=l("a"),He=l("span"),y(je.$$.fragment),Nt=d(),Qe=l("span"),It=o("AutoModel"),st=d(),y(ve.$$.fragment),this.h()},l(e){const m=vr('[data-svelte="svelte-1phssyn"]',document.head);i=n(m,"META",{name:!0,content:!0}),m.forEach(t),z=h(e),p=n(e,"H1",{class:!0});var Ce=c(p);v=n(Ce,"A",{id:!0,class:!0,href:!0});var Ge=c(v);A=n(Ge,"SPAN",{});var Ot=c(A);M(k.$$.fragment,Ot),Ot.forEach(t),Ge.forEach(t),L=h(Ce),q=n(Ce,"SPAN",{});var Dt=c(q);E=s(Dt,"Carica istanze pre-allenate con AutoClass"),Dt.forEach(t),Ce.forEach(t),w=h(e),j=n(e,"P",{});var Te=c(j);D=s(Te,"Con cos\xEC tante architetture Transformer differenti, pu\xF2 essere sfidante crearne una per il tuo checkpoint. Come parte della filosofia centrale di \u{1F917} Transformers per rendere la libreria facile, semplice e flessibile da utilizzare, una "),C=n(Te,"CODE",{});var Lt=c(C);G=s(Lt,"AutoClass"),Lt.forEach(t),x=s(Te," inferisce e carica automaticamente l\u2019architettura corretta da un dato checkpoint. Il metodo "),R=n(Te,"CODE",{});var Ht=c(R);B=s(Ht,"from_pretrained"),Ht.forEach(t),P=s(Te," ti permette di caricare velocemente un modello pre-allenato per qualsiasi architettura, cos\xEC non devi utilizzare tempo e risorse per allenare un modello da zero. Produrre questo codice agnostico ai checkpoint significa che se il tuo codice funziona per un checkpoint, funzioner\xE0 anche per un altro checkpoint, purch\xE9 sia stato allenato per un compito simile, anche se l\u2019architettura \xE8 differente."),Te.forEach(t),H=h(e),M($.$$.fragment,e),W=h(e),F=n(e,"P",{});var Qt=c(F);Z=s(Qt,"In questo tutorial, imparerai a:"),Qt.forEach(t),X=h(e),g=n(e,"UL",{});var _e=c(g);U=n(_e,"LI",{});var Gt=c(U);ee=s(Gt,"Caricare un tokenizer pre-allenato."),Gt.forEach(t),T=h(_e),V=n(_e,"LI",{});var Rt=c(V);te=s(Rt,"Caricare un estrattore di caratteristiche (feature extractor, in inglese) pre-allenato."),Rt.forEach(t),J=h(_e),a=n(_e,"LI",{});var Bt=c(a);f=s(Bt,"Caricare un processore pre-allenato."),Bt.forEach(t),se=h(_e),re=n(_e,"LI",{});var Ut=c(re);ie=s(Ut,"Caricare un modello pre-allenato."),Ut.forEach(t),_e.forEach(t),oe=h(e),b=n(e,"H2",{class:!0});var lt=c(b);Q=n(lt,"A",{id:!0,class:!0,href:!0});var Vt=c(Q);ae=n(Vt,"SPAN",{});var Jt=c(ae);M(K.$$.fragment,Jt),Jt.forEach(t),Vt.forEach(t),ht=h(lt),ye=n(lt,"SPAN",{});var Kt=c(ye);$t=s(Kt,"AutoTokenizer"),Kt.forEach(t),lt.forEach(t),Be=h(e),Pe=n(e,"P",{});var Wt=c(Pe);vt=s(Wt,"Quasi tutti i compiti di NLP iniziano con un tokenizer. Un tokenizer converte il tuo input in un formato che possa essere elaborato dal modello."),Wt.forEach(t),Ue=h(e),pe=n(e,"P",{});var nt=c(pe);_t=s(nt,"Carica un tokenizer con "),Me=n(nt,"CODE",{});var Xt=c(Me);kt=s(Xt,"AutoTokenizer.from_pretrained()"),Xt.forEach(t),bt=s(nt,":"),nt.forEach(t),Ve=h(e),M(be.$$.fragment,e),Je=h(e),Fe=n(e,"P",{});var Yt=c(Fe);zt=s(Yt,"Poi tokenizza il tuo input come mostrato in seguito:"),Yt.forEach(t),Ke=h(e),M(ze.$$.fragment,e),We=h(e),le=n(e,"H2",{class:!0});var ct=c(le);ue=n(ct,"A",{id:!0,class:!0,href:!0});var Zt=c(ue);Se=n(Zt,"SPAN",{});var er=c(Se);M(ge.$$.fragment,er),er.forEach(t),Zt.forEach(t),gt=h(ct),Ne=n(ct,"SPAN",{});var tr=c(Ne);At=s(tr,"AutoFeatureExtractor"),tr.forEach(t),ct.forEach(t),Xe=h(e),qe=n(e,"P",{});var rr=c(qe);Et=s(rr,"Per compiti inerenti a audio e video, un feature extractor processa il segnale audio o l\u2019immagine nel formato di input corretto."),rr.forEach(t),Ye=h(e),me=n(e,"P",{});var pt=c(me);wt=s(pt,"Carica un feature extractor con "),Ie=n(pt,"CODE",{});var ar=c(Ie);jt=s(ar,"AutoFeatureExtractor.from_pretrained()"),ar.forEach(t),Ct=s(pt,":"),pt.forEach(t),Ze=h(e),M(Ae.$$.fragment,e),et=h(e),ne=n(e,"H2",{class:!0});var ut=c(ne);fe=n(ut,"A",{id:!0,class:!0,href:!0});var or=c(fe);Oe=n(or,"SPAN",{});var sr=c(Oe);M(Ee.$$.fragment,sr),sr.forEach(t),or.forEach(t),Pt=h(ut),De=n(ut,"SPAN",{});var ir=c(De);Ft=s(ir,"AutoProcessor"),ir.forEach(t),ut.forEach(t),tt=h(e),de=n(e,"P",{});var mt=c(de);qt=s(mt,"Compiti multimodali richiedono un processore che combini i due tipi di strumenti di elaborazione. Per esempio, il modello "),xe=n(mt,"A",{href:!0});var lr=c(xe);xt=s(lr,"LayoutLMV2"),lr.forEach(t),Tt=s(mt," richiede un feature extractor per gestire le immagine e un tokenizer per gestire il testo; un processore li combina entrambi."),mt.forEach(t),rt=h(e),he=n(e,"P",{});var ft=c(he);yt=s(ft,"Carica un processore con "),Le=n(ft,"CODE",{});var nr=c(Le);Mt=s(nr,"AutoProcessor.from_pretrained()"),nr.forEach(t),St=s(ft,":"),ft.forEach(t),at=h(e),M(we.$$.fragment,e),ot=h(e),ce=n(e,"H2",{class:!0});var dt=c(ce);$e=n(dt,"A",{id:!0,class:!0,href:!0});var cr=c($e);He=n(cr,"SPAN",{});var pr=c(He);M(je.$$.fragment,pr),pr.forEach(t),cr.forEach(t),Nt=h(dt),Qe=n(dt,"SPAN",{});var ur=c(Qe);It=s(ur,"AutoModel"),ur.forEach(t),dt.forEach(t),st=h(e),M(ve.$$.fragment,e),this.h()},h(){_(i,"name","hf:doc:metadata"),_(i,"content",JSON.stringify(Cr)),_(v,"id","carica-istanze-preallenate-con-autoclass"),_(v,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(v,"href","#carica-istanze-preallenate-con-autoclass"),_(p,"class","relative group"),_(Q,"id","autotokenizer"),_(Q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Q,"href","#autotokenizer"),_(b,"class","relative group"),_(ue,"id","autofeatureextractor"),_(ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(ue,"href","#autofeatureextractor"),_(le,"class","relative group"),_(fe,"id","autoprocessor"),_(fe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(fe,"href","#autoprocessor"),_(ne,"class","relative group"),_(xe,"href","model_doc/layoutlmv2"),_($e,"id","automodel"),_($e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_($e,"href","#automodel"),_(ce,"class","relative group")},m(e,m){r(document.head,i),u(e,z,m),u(e,p,m),r(p,v),r(v,A),S(k,A,null),r(p,L),r(p,q),r(q,E),u(e,w,m),u(e,j,m),r(j,D),r(j,C),r(C,G),r(j,x),r(j,R),r(R,B),r(j,P),u(e,H,m),S($,e,m),u(e,W,m),u(e,F,m),r(F,Z),u(e,X,m),u(e,g,m),r(g,U),r(U,ee),r(g,T),r(g,V),r(V,te),r(g,J),r(g,a),r(a,f),r(g,se),r(g,re),r(re,ie),u(e,oe,m),u(e,b,m),r(b,Q),r(Q,ae),S(K,ae,null),r(b,ht),r(b,ye),r(ye,$t),u(e,Be,m),u(e,Pe,m),r(Pe,vt),u(e,Ue,m),u(e,pe,m),r(pe,_t),r(pe,Me),r(Me,kt),r(pe,bt),u(e,Ve,m),S(be,e,m),u(e,Je,m),u(e,Fe,m),r(Fe,zt),u(e,Ke,m),S(ze,e,m),u(e,We,m),u(e,le,m),r(le,ue),r(ue,Se),S(ge,Se,null),r(le,gt),r(le,Ne),r(Ne,At),u(e,Xe,m),u(e,qe,m),r(qe,Et),u(e,Ye,m),u(e,me,m),r(me,wt),r(me,Ie),r(Ie,jt),r(me,Ct),u(e,Ze,m),S(Ae,e,m),u(e,et,m),u(e,ne,m),r(ne,fe),r(fe,Oe),S(Ee,Oe,null),r(ne,Pt),r(ne,De),r(De,Ft),u(e,tt,m),u(e,de,m),r(de,qt),r(de,xe),r(xe,xt),r(de,Tt),u(e,rt,m),u(e,he,m),r(he,yt),r(he,Le),r(Le,Mt),r(he,St),u(e,at,m),S(we,e,m),u(e,ot,m),u(e,ce,m),r(ce,$e),r($e,He),S(je,He,null),r(ce,Nt),r(ce,Qe),r(Qe,It),u(e,st,m),S(ve,e,m),it=!0},p(e,[m]){const Ce={};m&2&&(Ce.$$scope={dirty:m,ctx:e}),$.$set(Ce);const Ge={};m&2&&(Ge.$$scope={dirty:m,ctx:e}),ve.$set(Ge)},i(e){it||(N(k.$$.fragment,e),N($.$$.fragment,e),N(K.$$.fragment,e),N(be.$$.fragment,e),N(ze.$$.fragment,e),N(ge.$$.fragment,e),N(Ae.$$.fragment,e),N(Ee.$$.fragment,e),N(we.$$.fragment,e),N(je.$$.fragment,e),N(ve.$$.fragment,e),it=!0)},o(e){I(k.$$.fragment,e),I($.$$.fragment,e),I(K.$$.fragment,e),I(be.$$.fragment,e),I(ze.$$.fragment,e),I(ge.$$.fragment,e),I(Ae.$$.fragment,e),I(Ee.$$.fragment,e),I(we.$$.fragment,e),I(je.$$.fragment,e),I(ve.$$.fragment,e),it=!1},d(e){t(i),e&&t(z),e&&t(p),O(k),e&&t(w),e&&t(j),e&&t(H),O($,e),e&&t(W),e&&t(F),e&&t(X),e&&t(g),e&&t(oe),e&&t(b),O(K),e&&t(Be),e&&t(Pe),e&&t(Ue),e&&t(pe),e&&t(Ve),O(be,e),e&&t(Je),e&&t(Fe),e&&t(Ke),O(ze,e),e&&t(We),e&&t(le),O(ge),e&&t(Xe),e&&t(qe),e&&t(Ye),e&&t(me),e&&t(Ze),O(Ae,e),e&&t(et),e&&t(ne),O(Ee),e&&t(tt),e&&t(de),e&&t(rt),e&&t(he),e&&t(at),O(we,e),e&&t(ot),e&&t(ce),O(je),e&&t(st),O(ve,e)}}}const Cr={local:"carica-istanze-preallenate-con-autoclass",sections:[{local:"autotokenizer",title:"AutoTokenizer"},{local:"autofeatureextractor",title:"AutoFeatureExtractor"},{local:"autoprocessor",title:"AutoProcessor"},{local:"automodel",title:"AutoModel"}],title:"Carica istanze pre-allenate con AutoClass"};function Pr(Y){return _r(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Sr extends dr{constructor(i){super();hr(this,i,Pr,jr,$r,{})}}export{Sr as default,Cr as metadata};
