import{S as ns,i as ps,s as cs,e as r,k as m,w as v,t as n,M as ds,c as o,d as e,m as u,a as l,x as b,h as p,b as f,G as t,g as c,y as w,q as k,o as j,B as E,v as ms}from"../chunks/vendor-hf-doc-builder.js";import{T as Da}from"../chunks/Tip-hf-doc-builder.js";import{Y as Ca}from"../chunks/Youtube-hf-doc-builder.js";import{I as Rt}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as X}from"../chunks/CodeBlock-hf-doc-builder.js";import{D as us}from"../chunks/DocNotebookDropdown-hf-doc-builder.js";import{F as is,M as Sa}from"../chunks/Markdown-hf-doc-builder.js";import"../chunks/IconTensorflow-hf-doc-builder.js";function fs(Fe){let g,P;return{c(){g=r("p"),P=n("Potresti vedere un\u2019allerta dato che alcuni dei pesi pre-addestrati non sono stati utilizzati e altri pesi sono stati inizializzati casualmente. Non preoccuparti, \xE8 completamente normale! La testa pre-allenata del modello BERT viene scartata, e rimpiazzata da una testa per la classificazione inizializzata casualmente. Tu metterai a punto la nuova testa del modello sulla tua sequenza per il compito di classificazione, trasferendogli la conoscenza del modello pre-allenato.")},l(h){g=o(h,"P",{});var z=l(g);P=p(z,"Potresti vedere un\u2019allerta dato che alcuni dei pesi pre-addestrati non sono stati utilizzati e altri pesi sono stati inizializzati casualmente. Non preoccuparti, \xE8 completamente normale! La testa pre-allenata del modello BERT viene scartata, e rimpiazzata da una testa per la classificazione inizializzata casualmente. Tu metterai a punto la nuova testa del modello sulla tua sequenza per il compito di classificazione, trasferendogli la conoscenza del modello pre-allenato."),z.forEach(e)},m(h,z){c(h,g,z),t(g,P)},d(h){h&&e(g)}}}function hs(Fe){let g,P,h,z,T,I,Z,A,q,O,C,V,G,Le,Ae,ue,$t,ie,F,H,fe,ne,he,Qe,pe,Je,Q,vt,M,L,qe,te,bt,be,B,lt,Re,Ce,De,Pt,Xe,N,Ze,D,Y,Se,U,He,ae,Ve,it,S,ee,et,R,ce,J,we,de,ke,wt,xe,se,ge,tt,d,y,je,_e,Ie,re,x,nt,oe,Ee,$e,ze,pt,me,Be,Ue,Tt,ve,W,We,K,kt,At,Xt,Ht,ye,ct,Oe,at,le,st,dt,jt,mt,xt,ut,ft,Et,Bt,Yt,ht,rt,Ge,Pe,gt,It,Ut,Ot,Me,Ne,_t,zt;return g=new Ca({props:{id:"nvBXf7s7vTI"}}),ie=new X({props:{code:`from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=5)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, num_labels=<span class="hljs-number">5</span>)`}}),H=new Da({props:{$$slots:{default:[fs]},$$scope:{ctx:Fe}}}),pe=new Rt({}),N=new X({props:{code:`from transformers import TrainingArguments

training_args = TrainingArguments(output_dir="test_trainer")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments

<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(output_dir=<span class="hljs-string">&quot;test_trainer&quot;</span>)`}}),U=new Rt({}),Ie=new X({props:{code:`import numpy as np
from datasets import load_metric

metric = load_metric("accuracy")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_metric

<span class="hljs-meta">&gt;&gt;&gt; </span>metric = load_metric(<span class="hljs-string">&quot;accuracy&quot;</span>)`}}),W=new X({props:{code:`def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_pred</span>):
<span class="hljs-meta">... </span>    logits, labels = eval_pred
<span class="hljs-meta">... </span>    predictions = np.argmax(logits, axis=-<span class="hljs-number">1</span>)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> metric.compute(predictions=predictions, references=labels)`}}),ct=new X({props:{code:`from transformers import TrainingArguments, Trainer

training_args = TrainingArguments(output_dir="test_trainer", evaluation_strategy="epoch")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments, Trainer

<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(output_dir=<span class="hljs-string">&quot;test_trainer&quot;</span>, evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>)`}}),dt=new Rt({}),Ge=new X({props:{code:`trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=small_train_dataset,
    eval_dataset=small_eval_dataset,
    compute_metrics=compute_metrics,
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>trainer = Trainer(
<span class="hljs-meta">... </span>    model=model,
<span class="hljs-meta">... </span>    args=training_args,
<span class="hljs-meta">... </span>    train_dataset=small_train_dataset,
<span class="hljs-meta">... </span>    eval_dataset=small_eval_dataset,
<span class="hljs-meta">... </span>    compute_metrics=compute_metrics,
<span class="hljs-meta">... </span>)`}}),_t=new X({props:{code:"trainer.train()",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.train()'}}),{c(){v(g.$$.fragment),P=m(),h=r("p"),z=n("\u{1F917} Transformers mette a disposizione la classe "),T=r("code"),I=n("Trainer"),Z=n(" ottimizzata per addestrare modelli \u{1F917} Transformers, rendendo semplice iniziare l\u2019addestramento senza scrivere manualmente il tuo ciclo di allenamento. L\u2019API "),A=r("code"),q=n("Trainer"),O=n(" supporta un\u2019ampia gamma di opzioni e funzionalit\xE0 di addestramento come logging, gradient accumulation, e mixed precision."),C=m(),V=r("p"),G=n("Inizia caricando il tuo modello e specificando il numero di etichette attese. Nel dataset Yelp Review "),Le=r("a"),Ae=n("dataset card"),ue=n(", sai che ci sono cinque etichette:"),$t=m(),v(ie.$$.fragment),F=m(),v(H.$$.fragment),fe=m(),ne=r("h3"),he=r("a"),Qe=r("span"),v(pe.$$.fragment),Je=m(),Q=r("span"),vt=n("Addestrare gli iperparametri"),M=m(),L=r("p"),qe=n("Successivamente, crea una classe "),te=r("code"),bt=n("TrainingArguments"),be=n(" contenente tutti gli iperparametri che si possono calibrare nonch\xE9 le variabili per attivare le differenti opzioni di addestramento. Per questa esercitazione puoi iniziare con gli "),B=r("a"),lt=n("iperparametri"),Re=n(" di allenamento predefiniti, ma sentiti libero di sperimentare per trovare la configurazione ottimale per te."),Ce=m(),De=r("p"),Pt=n("Specifica dove salvare i checkpoints del tuo addestramento:"),Xe=m(),v(N.$$.fragment),Ze=m(),D=r("h3"),Y=r("a"),Se=r("span"),v(U.$$.fragment),He=m(),ae=r("span"),Ve=n("Metriche"),it=m(),S=r("p"),ee=r("code"),et=n("Trainer"),R=n(" non valuta automaticamente le performance del modello durante l\u2019addestramento. Dovrai passare a "),ce=r("code"),J=n("Trainer"),we=n(" una funzione che calcola e restituisce le metriche. La libreria \u{1F917} Datasets mette a disposizione una semplice funzione "),de=r("a"),ke=r("code"),wt=n("accuracy"),xe=n(" che puoi caricare con la funzione "),se=r("code"),ge=n("load_metric"),tt=n(" (guarda questa "),d=r("a"),y=n("esercitazione"),je=n(" per maggiori informazioni):"),_e=m(),v(Ie.$$.fragment),re=m(),x=r("p"),nt=n("Richiama "),oe=r("code"),Ee=n("compute"),$e=n(" su "),ze=r("code"),pt=n("metric"),me=n(" per calcolare l\u2019accuratezza delle tue previsioni. Prima di passare le tue previsioni a "),Be=r("code"),Ue=n("compute"),Tt=n(", hai bisogno di convertirle in logits (ricorda che tutti i modelli \u{1F917} Transformers restituiscono logits):"),ve=m(),v(W.$$.fragment),We=m(),K=r("p"),kt=n("Se preferisci monitorare le tue metriche di valutazione durante il fine-tuning, specifica il parametro "),At=r("code"),Xt=n("evaluation_strategy"),Ht=n(" nei tuoi training arguments per restituire le metriche di valutazione ad ogni epoca di addestramento:"),ye=m(),v(ct.$$.fragment),Oe=m(),at=r("h3"),le=r("a"),st=r("span"),v(dt.$$.fragment),jt=m(),mt=r("span"),xt=n("Trainer"),ut=m(),ft=r("p"),Et=n("Crea un oggetto "),Bt=r("code"),Yt=n("Trainer"),ht=n(" col tuo modello, training arguments, dataset di training e test, e funzione di valutazione:"),rt=m(),v(Ge.$$.fragment),Pe=m(),gt=r("p"),It=n("Poi metti a punto il modello richiamando "),Ut=r("code"),Ot=n("train()"),Me=n(":"),Ne=m(),v(_t.$$.fragment),this.h()},l(i){b(g.$$.fragment,i),P=u(i),h=o(i,"P",{});var a=l(h);z=p(a,"\u{1F917} Transformers mette a disposizione la classe "),T=o(a,"CODE",{});var $=l(T);I=p($,"Trainer"),$.forEach(e),Z=p(a," ottimizzata per addestrare modelli \u{1F917} Transformers, rendendo semplice iniziare l\u2019addestramento senza scrivere manualmente il tuo ciclo di allenamento. L\u2019API "),A=o(a,"CODE",{});var qt=l(A);q=p(qt,"Trainer"),qt.forEach(e),O=p(a," supporta un\u2019ampia gamma di opzioni e funzionalit\xE0 di addestramento come logging, gradient accumulation, e mixed precision."),a.forEach(e),C=u(i),V=o(i,"P",{});var Ye=l(V);G=p(Ye,"Inizia caricando il tuo modello e specificando il numero di etichette attese. Nel dataset Yelp Review "),Le=o(Ye,"A",{href:!0,rel:!0});var na=l(Le);Ae=p(na,"dataset card"),na.forEach(e),ue=p(Ye,", sai che ci sono cinque etichette:"),Ye.forEach(e),$t=u(i),b(ie.$$.fragment,i),F=u(i),b(H.$$.fragment,i),fe=u(i),ne=o(i,"H3",{class:!0});var Ct=l(ne);he=o(Ct,"A",{id:!0,class:!0,href:!0});var Zt=l(he);Qe=o(Zt,"SPAN",{});var pa=l(Qe);b(pe.$$.fragment,pa),pa.forEach(e),Zt.forEach(e),Je=u(Ct),Q=o(Ct,"SPAN",{});var Mt=l(Q);vt=p(Mt,"Addestrare gli iperparametri"),Mt.forEach(e),Ct.forEach(e),M=u(i),L=o(i,"P",{});var Ke=l(L);qe=p(Ke,"Successivamente, crea una classe "),te=o(Ke,"CODE",{});var ra=l(te);bt=p(ra,"TrainingArguments"),ra.forEach(e),be=p(Ke," contenente tutti gli iperparametri che si possono calibrare nonch\xE9 le variabili per attivare le differenti opzioni di addestramento. Per questa esercitazione puoi iniziare con gli "),B=o(Ke,"A",{href:!0,rel:!0});var Dt=l(B);lt=p(Dt,"iperparametri"),Dt.forEach(e),Re=p(Ke," di allenamento predefiniti, ma sentiti libero di sperimentare per trovare la configurazione ottimale per te."),Ke.forEach(e),Ce=u(i),De=o(i,"P",{});var Nt=l(De);Pt=p(Nt,"Specifica dove salvare i checkpoints del tuo addestramento:"),Nt.forEach(e),Xe=u(i),b(N.$$.fragment,i),Ze=u(i),D=o(i,"H3",{class:!0});var St=l(D);Y=o(St,"A",{id:!0,class:!0,href:!0});var Wt=l(Y);Se=o(Wt,"SPAN",{});var ca=l(Se);b(U.$$.fragment,ca),ca.forEach(e),Wt.forEach(e),He=u(St),ae=o(St,"SPAN",{});var Vt=l(ae);Ve=p(Vt,"Metriche"),Vt.forEach(e),St.forEach(e),it=u(i),S=o(i,"P",{});var ot=l(S);ee=o(ot,"CODE",{});var Kt=l(ee);et=p(Kt,"Trainer"),Kt.forEach(e),R=p(ot," non valuta automaticamente le performance del modello durante l\u2019addestramento. Dovrai passare a "),ce=o(ot,"CODE",{});var yt=l(ce);J=p(yt,"Trainer"),yt.forEach(e),we=p(ot," una funzione che calcola e restituisce le metriche. La libreria \u{1F917} Datasets mette a disposizione una semplice funzione "),de=o(ot,"A",{href:!0,rel:!0});var ea=l(de);ke=o(ea,"CODE",{});var ta=l(ke);wt=p(ta,"accuracy"),ta.forEach(e),ea.forEach(e),xe=p(ot," che puoi caricare con la funzione "),se=o(ot,"CODE",{});var da=l(se);ge=p(da,"load_metric"),da.forEach(e),tt=p(ot," (guarda questa "),d=o(ot,"A",{href:!0,rel:!0});var ma=l(d);y=p(ma,"esercitazione"),ma.forEach(e),je=p(ot," per maggiori informazioni):"),ot.forEach(e),_e=u(i),b(Ie.$$.fragment,i),re=u(i),x=o(i,"P",{});var Te=l(x);nt=p(Te,"Richiama "),oe=o(Te,"CODE",{});var aa=l(oe);Ee=p(aa,"compute"),aa.forEach(e),$e=p(Te," su "),ze=o(Te,"CODE",{});var ua=l(ze);pt=p(ua,"metric"),ua.forEach(e),me=p(Te," per calcolare l\u2019accuratezza delle tue previsioni. Prima di passare le tue previsioni a "),Be=o(Te,"CODE",{});var fa=l(Be);Ue=p(fa,"compute"),fa.forEach(e),Tt=p(Te,", hai bisogno di convertirle in logits (ricorda che tutti i modelli \u{1F917} Transformers restituiscono logits):"),Te.forEach(e),ve=u(i),b(W.$$.fragment,i),We=u(i),K=o(i,"P",{});var Ft=l(K);kt=p(Ft,"Se preferisci monitorare le tue metriche di valutazione durante il fine-tuning, specifica il parametro "),At=o(Ft,"CODE",{});var Gt=l(At);Xt=p(Gt,"evaluation_strategy"),Gt.forEach(e),Ht=p(Ft," nei tuoi training arguments per restituire le metriche di valutazione ad ogni epoca di addestramento:"),Ft.forEach(e),ye=u(i),b(ct.$$.fragment,i),Oe=u(i),at=o(i,"H3",{class:!0});var Qt=l(at);le=o(Qt,"A",{id:!0,class:!0,href:!0});var s=l(le);st=o(s,"SPAN",{});var _=l(st);b(dt.$$.fragment,_),_.forEach(e),s.forEach(e),jt=u(Qt),mt=o(Qt,"SPAN",{});var sa=l(mt);xt=p(sa,"Trainer"),sa.forEach(e),Qt.forEach(e),ut=u(i),ft=o(i,"P",{});var oa=l(ft);Et=p(oa,"Crea un oggetto "),Bt=o(oa,"CODE",{});var la=l(Bt);Yt=p(la,"Trainer"),la.forEach(e),ht=p(oa," col tuo modello, training arguments, dataset di training e test, e funzione di valutazione:"),oa.forEach(e),rt=u(i),b(Ge.$$.fragment,i),Pe=u(i),gt=o(i,"P",{});var ia=l(gt);It=p(ia,"Poi metti a punto il modello richiamando "),Ut=o(ia,"CODE",{});var Lt=l(Ut);Ot=p(Lt,"train()"),Lt.forEach(e),Me=p(ia,":"),ia.forEach(e),Ne=u(i),b(_t.$$.fragment,i),this.h()},h(){f(Le,"href","https://huggingface.co/datasets/yelp_review_full#data-fields"),f(Le,"rel","nofollow"),f(he,"id","addestrare-gli-iperparametri"),f(he,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(he,"href","#addestrare-gli-iperparametri"),f(ne,"class","relative group"),f(B,"href","https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments"),f(B,"rel","nofollow"),f(Y,"id","metriche"),f(Y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(Y,"href","#metriche"),f(D,"class","relative group"),f(de,"href","https://huggingface.co/metrics/accuracy"),f(de,"rel","nofollow"),f(d,"href","https://huggingface.co/docs/datasets/metrics.html"),f(d,"rel","nofollow"),f(le,"id","trainer"),f(le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(le,"href","#trainer"),f(at,"class","relative group")},m(i,a){w(g,i,a),c(i,P,a),c(i,h,a),t(h,z),t(h,T),t(T,I),t(h,Z),t(h,A),t(A,q),t(h,O),c(i,C,a),c(i,V,a),t(V,G),t(V,Le),t(Le,Ae),t(V,ue),c(i,$t,a),w(ie,i,a),c(i,F,a),w(H,i,a),c(i,fe,a),c(i,ne,a),t(ne,he),t(he,Qe),w(pe,Qe,null),t(ne,Je),t(ne,Q),t(Q,vt),c(i,M,a),c(i,L,a),t(L,qe),t(L,te),t(te,bt),t(L,be),t(L,B),t(B,lt),t(L,Re),c(i,Ce,a),c(i,De,a),t(De,Pt),c(i,Xe,a),w(N,i,a),c(i,Ze,a),c(i,D,a),t(D,Y),t(Y,Se),w(U,Se,null),t(D,He),t(D,ae),t(ae,Ve),c(i,it,a),c(i,S,a),t(S,ee),t(ee,et),t(S,R),t(S,ce),t(ce,J),t(S,we),t(S,de),t(de,ke),t(ke,wt),t(S,xe),t(S,se),t(se,ge),t(S,tt),t(S,d),t(d,y),t(S,je),c(i,_e,a),w(Ie,i,a),c(i,re,a),c(i,x,a),t(x,nt),t(x,oe),t(oe,Ee),t(x,$e),t(x,ze),t(ze,pt),t(x,me),t(x,Be),t(Be,Ue),t(x,Tt),c(i,ve,a),w(W,i,a),c(i,We,a),c(i,K,a),t(K,kt),t(K,At),t(At,Xt),t(K,Ht),c(i,ye,a),w(ct,i,a),c(i,Oe,a),c(i,at,a),t(at,le),t(le,st),w(dt,st,null),t(at,jt),t(at,mt),t(mt,xt),c(i,ut,a),c(i,ft,a),t(ft,Et),t(ft,Bt),t(Bt,Yt),t(ft,ht),c(i,rt,a),w(Ge,i,a),c(i,Pe,a),c(i,gt,a),t(gt,It),t(gt,Ut),t(Ut,Ot),t(gt,Me),c(i,Ne,a),w(_t,i,a),zt=!0},p(i,a){const $={};a&2&&($.$$scope={dirty:a,ctx:i}),H.$set($)},i(i){zt||(k(g.$$.fragment,i),k(ie.$$.fragment,i),k(H.$$.fragment,i),k(pe.$$.fragment,i),k(N.$$.fragment,i),k(U.$$.fragment,i),k(Ie.$$.fragment,i),k(W.$$.fragment,i),k(ct.$$.fragment,i),k(dt.$$.fragment,i),k(Ge.$$.fragment,i),k(_t.$$.fragment,i),zt=!0)},o(i){j(g.$$.fragment,i),j(ie.$$.fragment,i),j(H.$$.fragment,i),j(pe.$$.fragment,i),j(N.$$.fragment,i),j(U.$$.fragment,i),j(Ie.$$.fragment,i),j(W.$$.fragment,i),j(ct.$$.fragment,i),j(dt.$$.fragment,i),j(Ge.$$.fragment,i),j(_t.$$.fragment,i),zt=!1},d(i){E(g,i),i&&e(P),i&&e(h),i&&e(C),i&&e(V),i&&e($t),E(ie,i),i&&e(F),E(H,i),i&&e(fe),i&&e(ne),E(pe),i&&e(M),i&&e(L),i&&e(Ce),i&&e(De),i&&e(Xe),E(N,i),i&&e(Ze),i&&e(D),E(U),i&&e(it),i&&e(S),i&&e(_e),E(Ie,i),i&&e(re),i&&e(x),i&&e(ve),E(W,i),i&&e(We),i&&e(K),i&&e(ye),E(ct,i),i&&e(Oe),i&&e(at),E(dt),i&&e(ut),i&&e(ft),i&&e(rt),E(Ge,i),i&&e(Pe),i&&e(gt),i&&e(Ne),E(_t,i)}}}function gs(Fe){let g,P;return g=new Sa({props:{$$slots:{default:[hs]},$$scope:{ctx:Fe}}}),{c(){v(g.$$.fragment)},l(h){b(g.$$.fragment,h)},m(h,z){w(g,h,z),P=!0},p(h,z){const T={};z&2&&(T.$$scope={dirty:z,ctx:h}),g.$set(T)},i(h){P||(k(g.$$.fragment,h),P=!0)},o(h){j(g.$$.fragment,h),P=!1},d(h){E(g,h)}}}function _s(Fe){let g,P,h,z,T,I,Z;return{c(){g=r("p"),P=r("code"),h=n("Trainer"),z=n(" usa "),T=r("code"),I=n("DataCollatorWithPadding"),Z=n(" in maniera predefinita in modo da non dover specificare esplicitamente un collettore di dati.")},l(A){g=o(A,"P",{});var q=l(g);P=o(q,"CODE",{});var O=l(P);h=p(O,"Trainer"),O.forEach(e),z=p(q," usa "),T=o(q,"CODE",{});var C=l(T);I=p(C,"DataCollatorWithPadding"),C.forEach(e),Z=p(q," in maniera predefinita in modo da non dover specificare esplicitamente un collettore di dati."),q.forEach(e)},m(A,q){c(A,g,q),t(g,P),t(P,h),t(g,z),t(g,T),t(T,I),t(g,Z)},d(A){A&&e(g)}}}function $s(Fe){let g,P,h,z,T,I,Z,A,q,O,C,V,G,Le,Ae,ue,$t,ie,F,H,fe,ne,he,Qe,pe,Je,Q,vt,M,L,qe,te,bt,be,B,lt,Re,Ce,De,Pt,Xe,N,Ze,D,Y,Se,U,He,ae,Ve,it,S,ee,et,R,ce,J,we,de,ke,wt,xe,se,ge,tt;return h=new Ca({props:{id:"rnTGBy2ax1c"}}),C=new Rt({}),pe=new X({props:{code:`from transformers import DefaultDataCollator

data_collator = DefaultDataCollator(return_tensors="tf")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DefaultDataCollator

<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DefaultDataCollator(return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`}}),Q=new Da({props:{$$slots:{default:[_s]},$$scope:{ctx:Fe}}}),N=new X({props:{code:`tf_train_dataset = small_train_dataset.to_tf_dataset(
    columns=["attention_mask", "input_ids", "token_type_ids"],
    label_cols=["labels"],
    shuffle=True,
    collate_fn=data_collator,
    batch_size=8,
)

tf_validation_dataset = small_eval_dataset.to_tf_dataset(
    columns=["attention_mask", "input_ids", "token_type_ids"],
    label_cols=["labels"],
    shuffle=False,
    collate_fn=data_collator,
    batch_size=8,
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_train_dataset = small_train_dataset.to_tf_dataset(
<span class="hljs-meta">... </span>    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>],
<span class="hljs-meta">... </span>    label_cols=[<span class="hljs-string">&quot;labels&quot;</span>],
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">8</span>,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_validation_dataset = small_eval_dataset.to_tf_dataset(
<span class="hljs-meta">... </span>    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>],
<span class="hljs-meta">... </span>    label_cols=[<span class="hljs-string">&quot;labels&quot;</span>],
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">False</span>,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">8</span>,
<span class="hljs-meta">... </span>)`}}),U=new Rt({}),R=new X({props:{code:`import tensorflow as tf
from transformers import TFAutoModelForSequenceClassification

model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=5)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, num_labels=<span class="hljs-number">5</span>)`}}),ge=new X({props:{code:`model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=tf.metrics.SparseCategoricalAccuracy(),
)

model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=3)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">compile</span>(
<span class="hljs-meta">... </span>    optimizer=tf.keras.optimizers.Adam(learning_rate=<span class="hljs-number">5e-5</span>),
<span class="hljs-meta">... </span>    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="hljs-literal">True</span>),
<span class="hljs-meta">... </span>    metrics=tf.metrics.SparseCategoricalAccuracy(),
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=<span class="hljs-number">3</span>)`}}),{c(){g=r("a"),P=m(),v(h.$$.fragment),z=m(),T=r("p"),I=n("I modelli \u{1F917} Transformers supportano anche l\u2019addestramento in TensorFlow usando l\u2019API di Keras."),Z=m(),A=r("h3"),q=r("a"),O=r("span"),v(C.$$.fragment),V=m(),G=r("span"),Le=n("Convertire dataset nel formato per TensorFlow"),Ae=m(),ue=r("p"),$t=n("Il "),ie=r("code"),F=n("DefaultDataCollator"),H=n(" assembla tensori in lotti su cui il modello si addestrer\xE0. Assicurati di specificare di restituire tensori per TensorFlow in "),fe=r("code"),ne=n("return_tensors"),he=n(":"),Qe=m(),v(pe.$$.fragment),Je=m(),v(Q.$$.fragment),vt=m(),M=r("p"),L=n("Successivamente, converti i datasets tokenizzati in TensorFlow datasets con il metodo "),qe=r("a"),te=r("code"),bt=n("to_tf_dataset"),be=n(". Specifica il tuo input in "),B=r("code"),lt=n("columns"),Re=n(", e le tue etichette in "),Ce=r("code"),De=n("label_cols"),Pt=n(":"),Xe=m(),v(N.$$.fragment),Ze=m(),D=r("h3"),Y=r("a"),Se=r("span"),v(U.$$.fragment),He=m(),ae=r("span"),Ve=n("Compilazione e addestramento"),it=m(),S=r("p"),ee=n("Carica un modello TensorFlow col numero atteso di etichette:"),et=m(),v(R.$$.fragment),ce=m(),J=r("p"),we=n("Poi compila e metti a punto il tuo modello usando "),de=r("a"),ke=r("code"),wt=n("fit"),xe=n(" come si farebbe con qualsiasi altro modello di Keras:"),se=m(),v(ge.$$.fragment),this.h()},l(d){g=o(d,"A",{id:!0}),l(g).forEach(e),P=u(d),b(h.$$.fragment,d),z=u(d),T=o(d,"P",{});var y=l(T);I=p(y,"I modelli \u{1F917} Transformers supportano anche l\u2019addestramento in TensorFlow usando l\u2019API di Keras."),y.forEach(e),Z=u(d),A=o(d,"H3",{class:!0});var je=l(A);q=o(je,"A",{id:!0,class:!0,href:!0});var _e=l(q);O=o(_e,"SPAN",{});var Ie=l(O);b(C.$$.fragment,Ie),Ie.forEach(e),_e.forEach(e),V=u(je),G=o(je,"SPAN",{});var re=l(G);Le=p(re,"Convertire dataset nel formato per TensorFlow"),re.forEach(e),je.forEach(e),Ae=u(d),ue=o(d,"P",{});var x=l(ue);$t=p(x,"Il "),ie=o(x,"CODE",{});var nt=l(ie);F=p(nt,"DefaultDataCollator"),nt.forEach(e),H=p(x," assembla tensori in lotti su cui il modello si addestrer\xE0. Assicurati di specificare di restituire tensori per TensorFlow in "),fe=o(x,"CODE",{});var oe=l(fe);ne=p(oe,"return_tensors"),oe.forEach(e),he=p(x,":"),x.forEach(e),Qe=u(d),b(pe.$$.fragment,d),Je=u(d),b(Q.$$.fragment,d),vt=u(d),M=o(d,"P",{});var Ee=l(M);L=p(Ee,"Successivamente, converti i datasets tokenizzati in TensorFlow datasets con il metodo "),qe=o(Ee,"A",{href:!0,rel:!0});var $e=l(qe);te=o($e,"CODE",{});var ze=l(te);bt=p(ze,"to_tf_dataset"),ze.forEach(e),$e.forEach(e),be=p(Ee,". Specifica il tuo input in "),B=o(Ee,"CODE",{});var pt=l(B);lt=p(pt,"columns"),pt.forEach(e),Re=p(Ee,", e le tue etichette in "),Ce=o(Ee,"CODE",{});var me=l(Ce);De=p(me,"label_cols"),me.forEach(e),Pt=p(Ee,":"),Ee.forEach(e),Xe=u(d),b(N.$$.fragment,d),Ze=u(d),D=o(d,"H3",{class:!0});var Be=l(D);Y=o(Be,"A",{id:!0,class:!0,href:!0});var Ue=l(Y);Se=o(Ue,"SPAN",{});var Tt=l(Se);b(U.$$.fragment,Tt),Tt.forEach(e),Ue.forEach(e),He=u(Be),ae=o(Be,"SPAN",{});var ve=l(ae);Ve=p(ve,"Compilazione e addestramento"),ve.forEach(e),Be.forEach(e),it=u(d),S=o(d,"P",{});var W=l(S);ee=p(W,"Carica un modello TensorFlow col numero atteso di etichette:"),W.forEach(e),et=u(d),b(R.$$.fragment,d),ce=u(d),J=o(d,"P",{});var We=l(J);we=p(We,"Poi compila e metti a punto il tuo modello usando "),de=o(We,"A",{href:!0,rel:!0});var K=l(de);ke=o(K,"CODE",{});var kt=l(ke);wt=p(kt,"fit"),kt.forEach(e),K.forEach(e),xe=p(We," come si farebbe con qualsiasi altro modello di Keras:"),We.forEach(e),se=u(d),b(ge.$$.fragment,d),this.h()},h(){f(g,"id","keras"),f(q,"id","convertire-dataset-nel-formato-per-tensorflow"),f(q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(q,"href","#convertire-dataset-nel-formato-per-tensorflow"),f(A,"class","relative group"),f(qe,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.to_tf_dataset"),f(qe,"rel","nofollow"),f(Y,"id","compilazione-e-addestramento"),f(Y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(Y,"href","#compilazione-e-addestramento"),f(D,"class","relative group"),f(de,"href","https://keras.io/api/models/model_training_apis/"),f(de,"rel","nofollow")},m(d,y){c(d,g,y),c(d,P,y),w(h,d,y),c(d,z,y),c(d,T,y),t(T,I),c(d,Z,y),c(d,A,y),t(A,q),t(q,O),w(C,O,null),t(A,V),t(A,G),t(G,Le),c(d,Ae,y),c(d,ue,y),t(ue,$t),t(ue,ie),t(ie,F),t(ue,H),t(ue,fe),t(fe,ne),t(ue,he),c(d,Qe,y),w(pe,d,y),c(d,Je,y),w(Q,d,y),c(d,vt,y),c(d,M,y),t(M,L),t(M,qe),t(qe,te),t(te,bt),t(M,be),t(M,B),t(B,lt),t(M,Re),t(M,Ce),t(Ce,De),t(M,Pt),c(d,Xe,y),w(N,d,y),c(d,Ze,y),c(d,D,y),t(D,Y),t(Y,Se),w(U,Se,null),t(D,He),t(D,ae),t(ae,Ve),c(d,it,y),c(d,S,y),t(S,ee),c(d,et,y),w(R,d,y),c(d,ce,y),c(d,J,y),t(J,we),t(J,de),t(de,ke),t(ke,wt),t(J,xe),c(d,se,y),w(ge,d,y),tt=!0},p(d,y){const je={};y&2&&(je.$$scope={dirty:y,ctx:d}),Q.$set(je)},i(d){tt||(k(h.$$.fragment,d),k(C.$$.fragment,d),k(pe.$$.fragment,d),k(Q.$$.fragment,d),k(N.$$.fragment,d),k(U.$$.fragment,d),k(R.$$.fragment,d),k(ge.$$.fragment,d),tt=!0)},o(d){j(h.$$.fragment,d),j(C.$$.fragment,d),j(pe.$$.fragment,d),j(Q.$$.fragment,d),j(N.$$.fragment,d),j(U.$$.fragment,d),j(R.$$.fragment,d),j(ge.$$.fragment,d),tt=!1},d(d){d&&e(g),d&&e(P),E(h,d),d&&e(z),d&&e(T),d&&e(Z),d&&e(A),E(C),d&&e(Ae),d&&e(ue),d&&e(Qe),E(pe,d),d&&e(Je),E(Q,d),d&&e(vt),d&&e(M),d&&e(Xe),E(N,d),d&&e(Ze),d&&e(D),E(U),d&&e(it),d&&e(S),d&&e(et),E(R,d),d&&e(ce),d&&e(J),d&&e(se),E(ge,d)}}}function vs(Fe){let g,P;return g=new Sa({props:{$$slots:{default:[$s]},$$scope:{ctx:Fe}}}),{c(){v(g.$$.fragment)},l(h){b(g.$$.fragment,h)},m(h,z){w(g,h,z),P=!0},p(h,z){const T={};z&2&&(T.$$scope={dirty:z,ctx:h}),g.$set(T)},i(h){P||(k(g.$$.fragment,h),P=!0)},o(h){j(g.$$.fragment,h),P=!1},d(h){E(g,h)}}}function bs(Fe){let g,P,h,z,T,I,Z,A;return{c(){g=r("p"),P=n("Ottieni l\u2019accesso gratuito a una GPU sul cloud se non ne possiedi una usando un notebook sul web come "),h=r("a"),z=n("Colaboratory"),T=n(" o "),I=r("a"),Z=n("SageMaker StudioLab"),A=n("."),this.h()},l(q){g=o(q,"P",{});var O=l(g);P=p(O,"Ottieni l\u2019accesso gratuito a una GPU sul cloud se non ne possiedi una usando un notebook sul web come "),h=o(O,"A",{href:!0,rel:!0});var C=l(h);z=p(C,"Colaboratory"),C.forEach(e),T=p(O," o "),I=o(O,"A",{href:!0,rel:!0});var V=l(I);Z=p(V,"SageMaker StudioLab"),V.forEach(e),A=p(O,"."),O.forEach(e),this.h()},h(){f(h,"href","https://colab.research.google.com/"),f(h,"rel","nofollow"),f(I,"href","https://studiolab.sagemaker.aws/"),f(I,"rel","nofollow")},m(q,O){c(q,g,O),t(g,P),t(g,h),t(h,z),t(g,T),t(g,I),t(I,Z),t(g,A)},d(q){q&&e(g)}}}function ws(Fe){let g,P,h,z,T,I,Z,A,q,O,C,V,G,Le,Ae,ue,$t,ie,F,H,fe,ne,he,Qe,pe,Je,Q,vt,M,L,qe,te,bt,be,B,lt,Re,Ce,De,Pt,Xe,N,Ze,D,Y,Se,U,He,ae,Ve,it,S,ee,et,R,ce,J,we,de,ke,wt,xe,se,ge,tt,d,y,je,_e,Ie,re,x,nt,oe,Ee,$e,ze,pt,me,Be,Ue,Tt,ve,W,We,K,kt,At,Xt,Ht,ye,ct,Oe,at,le,st,dt,jt,mt,xt,ut,ft,Et,Bt,Yt,ht,rt,Ge,Pe,gt,It,Ut,Ot,Me,Ne,_t,zt,i,a,$,qt,Ye,na,Ct,Zt,pa,Mt,Ke,ra,Dt,Nt,St,Wt,ca,Vt,ot,Kt,yt,ea,ta,da,ma,Te,aa,ua,fa,Ft,Gt,Qt;return g=new Ca({props:{id:"Dh9CL8fyG80"}}),C=new X({props:{code:`del model
del pytorch_model
del trainer
torch.cuda.empty_cache()`,highlighted:`<span class="hljs-keyword">del</span> model
<span class="hljs-keyword">del</span> pytorch_model
<span class="hljs-keyword">del</span> trainer
torch.cuda.empty_cache()`}}),Q=new X({props:{code:'tokenized_datasets = tokenized_datasets.remove_columns(["text"])',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_datasets = tokenized_datasets.remove_columns([<span class="hljs-string">&quot;text&quot;</span>])'}}),N=new X({props:{code:'tokenized_datasets = tokenized_datasets.rename_column("label", "labels")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_datasets = tokenized_datasets.rename_column(<span class="hljs-string">&quot;label&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>)'}}),He=new X({props:{code:'tokenized_datasets.set_format("torch")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_datasets.set_format(<span class="hljs-string">&quot;torch&quot;</span>)'}}),ee=new X({props:{code:`small_train_dataset = tokenized_datasets["train"].shuffle(seed=42).select(range(1000))
small_eval_dataset = tokenized_datasets["test"].shuffle(seed=42).select(range(1000))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>small_train_dataset = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>small_eval_dataset = tokenized_datasets[<span class="hljs-string">&quot;test&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))`}}),we=new Rt({}),_e=new X({props:{code:`from torch.utils.data import DataLoader

train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=8)
eval_dataloader = DataLoader(small_eval_dataset, batch_size=8)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader

<span class="hljs-meta">&gt;&gt;&gt; </span>train_dataloader = DataLoader(small_train_dataset, shuffle=<span class="hljs-literal">True</span>, batch_size=<span class="hljs-number">8</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>eval_dataloader = DataLoader(small_eval_dataset, batch_size=<span class="hljs-number">8</span>)`}}),oe=new X({props:{code:`from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=5)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, num_labels=<span class="hljs-number">5</span>)`}}),me=new Rt({}),ye=new X({props:{code:`from torch.optim import AdamW

optimizer = AdamW(model.parameters(), lr=5e-5)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> AdamW

<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer = AdamW(model.parameters(), lr=<span class="hljs-number">5e-5</span>)`}}),mt=new X({props:{code:`from transformers import get_scheduler

num_epochs = 3
num_training_steps = num_epochs * len(train_dataloader)
lr_scheduler = get_scheduler(
    name="linear", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> get_scheduler

<span class="hljs-meta">&gt;&gt;&gt; </span>num_epochs = <span class="hljs-number">3</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>num_training_steps = num_epochs * <span class="hljs-built_in">len</span>(train_dataloader)
<span class="hljs-meta">&gt;&gt;&gt; </span>lr_scheduler = get_scheduler(
<span class="hljs-meta">... </span>    name=<span class="hljs-string">&quot;linear&quot;</span>, optimizer=optimizer, num_warmup_steps=<span class="hljs-number">0</span>, num_training_steps=num_training_steps
<span class="hljs-meta">... </span>)`}}),rt=new X({props:{code:`import torch

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
model.to(device)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span>) <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> torch.device(<span class="hljs-string">&quot;cpu&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.to(device)`}}),Pe=new Da({props:{$$slots:{default:[bs]},$$scope:{ctx:Fe}}}),zt=new Rt({}),Ke=new X({props:{code:`from tqdm.auto import tqdm

progress_bar = tqdm(range(num_training_steps))

model.train()
for epoch in range(num_epochs):
    for batch in train_dataloader:
        batch = {k: v.to(device) for k, v in batch.items()}
        outputs = model(**batch)
        loss = outputs.loss
        loss.backward()

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> tqdm.auto <span class="hljs-keyword">import</span> tqdm

<span class="hljs-meta">&gt;&gt;&gt; </span>progress_bar = tqdm(<span class="hljs-built_in">range</span>(num_training_steps))

<span class="hljs-meta">&gt;&gt;&gt; </span>model.train()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_dataloader:
<span class="hljs-meta">... </span>        batch = {k: v.to(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}
<span class="hljs-meta">... </span>        outputs = model(**batch)
<span class="hljs-meta">... </span>        loss = outputs.loss
<span class="hljs-meta">... </span>        loss.backward()

<span class="hljs-meta">... </span>        optimizer.step()
<span class="hljs-meta">... </span>        lr_scheduler.step()
<span class="hljs-meta">... </span>        optimizer.zero_grad()
<span class="hljs-meta">... </span>        progress_bar.update(<span class="hljs-number">1</span>)`}}),Wt=new Rt({}),Gt=new X({props:{code:`metric = load_metric("accuracy")
model.eval()
for batch in eval_dataloader:
    batch = {k: v.to(device) for k, v in batch.items()}
    with torch.no_grad():
        outputs = model(**batch)

    logits = outputs.logits
    predictions = torch.argmax(logits, dim=-1)
    metric.add_batch(predictions=predictions, references=batch["labels"])

metric.compute()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>metric = load_metric(<span class="hljs-string">&quot;accuracy&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">eval</span>()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> eval_dataloader:
<span class="hljs-meta">... </span>    batch = {k: v.to(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}
<span class="hljs-meta">... </span>    <span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>        outputs = model(**batch)

<span class="hljs-meta">... </span>    logits = outputs.logits
<span class="hljs-meta">... </span>    predictions = torch.argmax(logits, dim=-<span class="hljs-number">1</span>)
<span class="hljs-meta">... </span>    metric.add_batch(predictions=predictions, references=batch[<span class="hljs-string">&quot;labels&quot;</span>])

<span class="hljs-meta">&gt;&gt;&gt; </span>metric.compute()`}}),{c(){v(g.$$.fragment),P=m(),h=r("p"),z=r("code"),T=n("Trainer"),I=n(" si occupa del ciclo di addestramento e ti consente di mettere a punto un modello con una sola riga di codice. Per chi preferisse scrivere un proprio ciclo di addestramento personale, puoi anche mettere a punto un modello \u{1F917} Transformers in PyTorch nativo."),Z=m(),A=r("p"),q=n("A questo punto, potresti avere bisogno di riavviare il tuo notebook o eseguire il seguente codice per liberare un po\u2019 di memoria:"),O=m(),v(C.$$.fragment),V=m(),G=r("p"),Le=n("Successivamente, postprocessa manualmente il "),Ae=r("code"),ue=n("tokenized_dataset"),$t=n(" per prepararlo ad essere allenato."),ie=m(),F=r("ol"),H=r("li"),fe=r("p"),ne=n("Rimuovi la colonna "),he=r("code"),Qe=n("text"),pe=n(" perch\xE9 il modello non accetta testo grezzo come input:"),Je=m(),v(Q.$$.fragment),vt=m(),M=r("li"),L=r("p"),qe=n("Rinomina la colonna "),te=r("code"),bt=n("label"),be=n(" in "),B=r("code"),lt=n("labels"),Re=n(" perch\xE9 il modello si aspetta che questo argomento si chiami "),Ce=r("code"),De=n("labels"),Pt=n(":"),Xe=m(),v(N.$$.fragment),Ze=m(),D=r("li"),Y=r("p"),Se=n("Imposta il formato del dataset per farti restituire tensori di PyTorch all\u2019interno delle liste:"),U=m(),v(He.$$.fragment),ae=m(),Ve=r("p"),it=n("Poi crea un piccolo sottocampione del dataset come visto precedentemente per velocizzare il fine-tuning:"),S=m(),v(ee.$$.fragment),et=m(),R=r("h3"),ce=r("a"),J=r("span"),v(we.$$.fragment),de=m(),ke=r("span"),wt=n("DataLoader"),xe=m(),se=r("p"),ge=n("Crea un "),tt=r("code"),d=n("DataLoader"),y=n(" per i tuoi datasets di train e test cos\xEC puoi iterare sui lotti di dati:"),je=m(),v(_e.$$.fragment),Ie=m(),re=r("p"),x=n("Carica il tuo modello con il numero atteso di etichette:"),nt=m(),v(oe.$$.fragment),Ee=m(),$e=r("h3"),ze=r("a"),pt=r("span"),v(me.$$.fragment),Be=m(),Ue=r("span"),Tt=n("Ottimizzatore e pianificatore del tasso di apprendimento"),ve=m(),W=r("p"),We=n("Crea un ottimizzatore e pianificatore del tasso di apprendimento per mettere a punto il modello. Usa l\u2019ottimizzatore "),K=r("a"),kt=r("code"),At=n("AdamW"),Xt=n(" di PyTorch:"),Ht=m(),v(ye.$$.fragment),ct=m(),Oe=r("p"),at=n("Crea il pianificatore del tasso di apprendimento predefinito da "),le=r("code"),st=n("Trainer"),dt=n(":"),jt=m(),v(mt.$$.fragment),xt=m(),ut=r("p"),ft=n("Infine, specifica come "),Et=r("code"),Bt=n("device"),Yt=n(" da usare una GPU se ne hai una. Altrimenti, l\u2019addestramento su una CPU pu\xF2 richiedere diverse ore invece di un paio di minuti."),ht=m(),v(rt.$$.fragment),Ge=m(),v(Pe.$$.fragment),gt=m(),It=r("p"),Ut=n("Ottimo, adesso possiamo addestrare! \u{1F973}"),Ot=m(),Me=r("h3"),Ne=r("a"),_t=r("span"),v(zt.$$.fragment),i=m(),a=r("span"),$=n("Training loop"),qt=m(),Ye=r("p"),na=n("Per tenere traccia dei tuoi progressi durante l\u2019addestramento, usa la libreria "),Ct=r("a"),Zt=n("tqdm"),pa=n(" per aggiungere una progress bar sopra il numero dei passi di addestramento:"),Mt=m(),v(Ke.$$.fragment),ra=m(),Dt=r("h3"),Nt=r("a"),St=r("span"),v(Wt.$$.fragment),ca=m(),Vt=r("span"),ot=n("Metriche"),Kt=m(),yt=r("p"),ea=n("Proprio come \xE8 necessario aggiungere una funzione di valutazione del "),ta=r("code"),da=n("Trainer"),ma=n(", \xE8 necessario fare lo stesso quando si scrive il proprio ciclo di allenamento. Ma invece di calcolare e riportare la metrica alla fine di ogni epoca, questa volta accumulerai tutti i batch con "),Te=r("a"),aa=r("code"),ua=n("add_batch"),fa=n(" e calcolerai la metrica alla fine."),Ft=m(),v(Gt.$$.fragment),this.h()},l(s){b(g.$$.fragment,s),P=u(s),h=o(s,"P",{});var _=l(h);z=o(_,"CODE",{});var sa=l(z);T=p(sa,"Trainer"),sa.forEach(e),I=p(_," si occupa del ciclo di addestramento e ti consente di mettere a punto un modello con una sola riga di codice. Per chi preferisse scrivere un proprio ciclo di addestramento personale, puoi anche mettere a punto un modello \u{1F917} Transformers in PyTorch nativo."),_.forEach(e),Z=u(s),A=o(s,"P",{});var oa=l(A);q=p(oa,"A questo punto, potresti avere bisogno di riavviare il tuo notebook o eseguire il seguente codice per liberare un po\u2019 di memoria:"),oa.forEach(e),O=u(s),b(C.$$.fragment,s),V=u(s),G=o(s,"P",{});var la=l(G);Le=p(la,"Successivamente, postprocessa manualmente il "),Ae=o(la,"CODE",{});var ia=l(Ae);ue=p(ia,"tokenized_dataset"),ia.forEach(e),$t=p(la," per prepararlo ad essere allenato."),la.forEach(e),ie=u(s),F=o(s,"OL",{});var Lt=l(F);H=o(Lt,"LI",{});var ga=l(H);fe=o(ga,"P",{});var ha=l(fe);ne=p(ha,"Rimuovi la colonna "),he=o(ha,"CODE",{});var va=l(he);Qe=p(va,"text"),va.forEach(e),pe=p(ha," perch\xE9 il modello non accetta testo grezzo come input:"),ha.forEach(e),Je=u(ga),b(Q.$$.fragment,ga),ga.forEach(e),vt=u(Lt),M=o(Lt,"LI",{});var _a=l(M);L=o(_a,"P",{});var Jt=l(L);qe=p(Jt,"Rinomina la colonna "),te=o(Jt,"CODE",{});var ba=l(te);bt=p(ba,"label"),ba.forEach(e),be=p(Jt," in "),B=o(Jt,"CODE",{});var xa=l(B);lt=p(xa,"labels"),xa.forEach(e),Re=p(Jt," perch\xE9 il modello si aspetta che questo argomento si chiami "),Ce=o(Jt,"CODE",{});var Ia=l(Ce);De=p(Ia,"labels"),Ia.forEach(e),Pt=p(Jt,":"),Jt.forEach(e),Xe=u(_a),b(N.$$.fragment,_a),_a.forEach(e),Ze=u(Lt),D=o(Lt,"LI",{});var wa=l(D);Y=o(wa,"P",{});var Oa=l(Y);Se=p(Oa,"Imposta il formato del dataset per farti restituire tensori di PyTorch all\u2019interno delle liste:"),Oa.forEach(e),U=u(wa),b(He.$$.fragment,wa),wa.forEach(e),Lt.forEach(e),ae=u(s),Ve=o(s,"P",{});var Ma=l(Ve);it=p(Ma,"Poi crea un piccolo sottocampione del dataset come visto precedentemente per velocizzare il fine-tuning:"),Ma.forEach(e),S=u(s),b(ee.$$.fragment,s),et=u(s),R=o(s,"H3",{class:!0});var ka=l(R);ce=o(ka,"A",{id:!0,class:!0,href:!0});var Na=l(ce);J=o(Na,"SPAN",{});var Fa=l(J);b(we.$$.fragment,Fa),Fa.forEach(e),Na.forEach(e),de=u(ka),ke=o(ka,"SPAN",{});var La=l(ke);wt=p(La,"DataLoader"),La.forEach(e),ka.forEach(e),xe=u(s),se=o(s,"P",{});var ja=l(se);ge=p(ja,"Crea un "),tt=o(ja,"CODE",{});var Ra=l(tt);d=p(Ra,"DataLoader"),Ra.forEach(e),y=p(ja," per i tuoi datasets di train e test cos\xEC puoi iterare sui lotti di dati:"),ja.forEach(e),je=u(s),b(_e.$$.fragment,s),Ie=u(s),re=o(s,"P",{});var Ha=l(re);x=p(Ha,"Carica il tuo modello con il numero atteso di etichette:"),Ha.forEach(e),nt=u(s),b(oe.$$.fragment,s),Ee=u(s),$e=o(s,"H3",{class:!0});var Ea=l($e);ze=o(Ea,"A",{id:!0,class:!0,href:!0});var Ba=l(ze);pt=o(Ba,"SPAN",{});var Ua=l(pt);b(me.$$.fragment,Ua),Ua.forEach(e),Ba.forEach(e),Be=u(Ea),Ue=o(Ea,"SPAN",{});var Wa=l(Ue);Tt=p(Wa,"Ottimizzatore e pianificatore del tasso di apprendimento"),Wa.forEach(e),Ea.forEach(e),ve=u(s),W=o(s,"P",{});var za=l(W);We=p(za,"Crea un ottimizzatore e pianificatore del tasso di apprendimento per mettere a punto il modello. Usa l\u2019ottimizzatore "),K=o(za,"A",{href:!0,rel:!0});var Ga=l(K);kt=o(Ga,"CODE",{});var Ya=l(kt);At=p(Ya,"AdamW"),Ya.forEach(e),Ga.forEach(e),Xt=p(za," di PyTorch:"),za.forEach(e),Ht=u(s),b(ye.$$.fragment,s),ct=u(s),Oe=o(s,"P",{});var ya=l(Oe);at=p(ya,"Crea il pianificatore del tasso di apprendimento predefinito da "),le=o(ya,"CODE",{});var Ka=l(le);st=p(Ka,"Trainer"),Ka.forEach(e),dt=p(ya,":"),ya.forEach(e),jt=u(s),b(mt.$$.fragment,s),xt=u(s),ut=o(s,"P",{});var Pa=l(ut);ft=p(Pa,"Infine, specifica come "),Et=o(Pa,"CODE",{});var Qa=l(Et);Bt=p(Qa,"device"),Qa.forEach(e),Yt=p(Pa," da usare una GPU se ne hai una. Altrimenti, l\u2019addestramento su una CPU pu\xF2 richiedere diverse ore invece di un paio di minuti."),Pa.forEach(e),ht=u(s),b(rt.$$.fragment,s),Ge=u(s),b(Pe.$$.fragment,s),gt=u(s),It=o(s,"P",{});var Ja=l(It);Ut=p(Ja,"Ottimo, adesso possiamo addestrare! \u{1F973}"),Ja.forEach(e),Ot=u(s),Me=o(s,"H3",{class:!0});var Ta=l(Me);Ne=o(Ta,"A",{id:!0,class:!0,href:!0});var Xa=l(Ne);_t=o(Xa,"SPAN",{});var Za=l(_t);b(zt.$$.fragment,Za),Za.forEach(e),Xa.forEach(e),i=u(Ta),a=o(Ta,"SPAN",{});var Va=l(a);$=p(Va,"Training loop"),Va.forEach(e),Ta.forEach(e),qt=u(s),Ye=o(s,"P",{});var Aa=l(Ye);na=p(Aa,"Per tenere traccia dei tuoi progressi durante l\u2019addestramento, usa la libreria "),Ct=o(Aa,"A",{href:!0,rel:!0});var es=l(Ct);Zt=p(es,"tqdm"),es.forEach(e),pa=p(Aa," per aggiungere una progress bar sopra il numero dei passi di addestramento:"),Aa.forEach(e),Mt=u(s),b(Ke.$$.fragment,s),ra=u(s),Dt=o(s,"H3",{class:!0});var qa=l(Dt);Nt=o(qa,"A",{id:!0,class:!0,href:!0});var ts=l(Nt);St=o(ts,"SPAN",{});var as=l(St);b(Wt.$$.fragment,as),as.forEach(e),ts.forEach(e),ca=u(qa),Vt=o(qa,"SPAN",{});var ss=l(Vt);ot=p(ss,"Metriche"),ss.forEach(e),qa.forEach(e),Kt=u(s),yt=o(s,"P",{});var $a=l(yt);ea=p($a,"Proprio come \xE8 necessario aggiungere una funzione di valutazione del "),ta=o($a,"CODE",{});var rs=l(ta);da=p(rs,"Trainer"),rs.forEach(e),ma=p($a,", \xE8 necessario fare lo stesso quando si scrive il proprio ciclo di allenamento. Ma invece di calcolare e riportare la metrica alla fine di ogni epoca, questa volta accumulerai tutti i batch con "),Te=o($a,"A",{href:!0,rel:!0});var os=l(Te);aa=o(os,"CODE",{});var ls=l(aa);ua=p(ls,"add_batch"),ls.forEach(e),os.forEach(e),fa=p($a," e calcolerai la metrica alla fine."),$a.forEach(e),Ft=u(s),b(Gt.$$.fragment,s),this.h()},h(){f(ce,"id","dataloader"),f(ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(ce,"href","#dataloader"),f(R,"class","relative group"),f(ze,"id","ottimizzatore-e-pianificatore-del-tasso-di-apprendimento"),f(ze,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(ze,"href","#ottimizzatore-e-pianificatore-del-tasso-di-apprendimento"),f($e,"class","relative group"),f(K,"href","https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html"),f(K,"rel","nofollow"),f(Ne,"id","training-loop"),f(Ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(Ne,"href","#training-loop"),f(Me,"class","relative group"),f(Ct,"href","https://tqdm.github.io/"),f(Ct,"rel","nofollow"),f(Nt,"id","metriche"),f(Nt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(Nt,"href","#metriche"),f(Dt,"class","relative group"),f(Te,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html?highlight=add_batch#datasets.Metric.add_batch"),f(Te,"rel","nofollow")},m(s,_){w(g,s,_),c(s,P,_),c(s,h,_),t(h,z),t(z,T),t(h,I),c(s,Z,_),c(s,A,_),t(A,q),c(s,O,_),w(C,s,_),c(s,V,_),c(s,G,_),t(G,Le),t(G,Ae),t(Ae,ue),t(G,$t),c(s,ie,_),c(s,F,_),t(F,H),t(H,fe),t(fe,ne),t(fe,he),t(he,Qe),t(fe,pe),t(H,Je),w(Q,H,null),t(F,vt),t(F,M),t(M,L),t(L,qe),t(L,te),t(te,bt),t(L,be),t(L,B),t(B,lt),t(L,Re),t(L,Ce),t(Ce,De),t(L,Pt),t(M,Xe),w(N,M,null),t(F,Ze),t(F,D),t(D,Y),t(Y,Se),t(D,U),w(He,D,null),c(s,ae,_),c(s,Ve,_),t(Ve,it),c(s,S,_),w(ee,s,_),c(s,et,_),c(s,R,_),t(R,ce),t(ce,J),w(we,J,null),t(R,de),t(R,ke),t(ke,wt),c(s,xe,_),c(s,se,_),t(se,ge),t(se,tt),t(tt,d),t(se,y),c(s,je,_),w(_e,s,_),c(s,Ie,_),c(s,re,_),t(re,x),c(s,nt,_),w(oe,s,_),c(s,Ee,_),c(s,$e,_),t($e,ze),t(ze,pt),w(me,pt,null),t($e,Be),t($e,Ue),t(Ue,Tt),c(s,ve,_),c(s,W,_),t(W,We),t(W,K),t(K,kt),t(kt,At),t(W,Xt),c(s,Ht,_),w(ye,s,_),c(s,ct,_),c(s,Oe,_),t(Oe,at),t(Oe,le),t(le,st),t(Oe,dt),c(s,jt,_),w(mt,s,_),c(s,xt,_),c(s,ut,_),t(ut,ft),t(ut,Et),t(Et,Bt),t(ut,Yt),c(s,ht,_),w(rt,s,_),c(s,Ge,_),w(Pe,s,_),c(s,gt,_),c(s,It,_),t(It,Ut),c(s,Ot,_),c(s,Me,_),t(Me,Ne),t(Ne,_t),w(zt,_t,null),t(Me,i),t(Me,a),t(a,$),c(s,qt,_),c(s,Ye,_),t(Ye,na),t(Ye,Ct),t(Ct,Zt),t(Ye,pa),c(s,Mt,_),w(Ke,s,_),c(s,ra,_),c(s,Dt,_),t(Dt,Nt),t(Nt,St),w(Wt,St,null),t(Dt,ca),t(Dt,Vt),t(Vt,ot),c(s,Kt,_),c(s,yt,_),t(yt,ea),t(yt,ta),t(ta,da),t(yt,ma),t(yt,Te),t(Te,aa),t(aa,ua),t(yt,fa),c(s,Ft,_),w(Gt,s,_),Qt=!0},p(s,_){const sa={};_&2&&(sa.$$scope={dirty:_,ctx:s}),Pe.$set(sa)},i(s){Qt||(k(g.$$.fragment,s),k(C.$$.fragment,s),k(Q.$$.fragment,s),k(N.$$.fragment,s),k(He.$$.fragment,s),k(ee.$$.fragment,s),k(we.$$.fragment,s),k(_e.$$.fragment,s),k(oe.$$.fragment,s),k(me.$$.fragment,s),k(ye.$$.fragment,s),k(mt.$$.fragment,s),k(rt.$$.fragment,s),k(Pe.$$.fragment,s),k(zt.$$.fragment,s),k(Ke.$$.fragment,s),k(Wt.$$.fragment,s),k(Gt.$$.fragment,s),Qt=!0)},o(s){j(g.$$.fragment,s),j(C.$$.fragment,s),j(Q.$$.fragment,s),j(N.$$.fragment,s),j(He.$$.fragment,s),j(ee.$$.fragment,s),j(we.$$.fragment,s),j(_e.$$.fragment,s),j(oe.$$.fragment,s),j(me.$$.fragment,s),j(ye.$$.fragment,s),j(mt.$$.fragment,s),j(rt.$$.fragment,s),j(Pe.$$.fragment,s),j(zt.$$.fragment,s),j(Ke.$$.fragment,s),j(Wt.$$.fragment,s),j(Gt.$$.fragment,s),Qt=!1},d(s){E(g,s),s&&e(P),s&&e(h),s&&e(Z),s&&e(A),s&&e(O),E(C,s),s&&e(V),s&&e(G),s&&e(ie),s&&e(F),E(Q),E(N),E(He),s&&e(ae),s&&e(Ve),s&&e(S),E(ee,s),s&&e(et),s&&e(R),E(we),s&&e(xe),s&&e(se),s&&e(je),E(_e,s),s&&e(Ie),s&&e(re),s&&e(nt),E(oe,s),s&&e(Ee),s&&e($e),E(me),s&&e(ve),s&&e(W),s&&e(Ht),E(ye,s),s&&e(ct),s&&e(Oe),s&&e(jt),E(mt,s),s&&e(xt),s&&e(ut),s&&e(ht),E(rt,s),s&&e(Ge),E(Pe,s),s&&e(gt),s&&e(It),s&&e(Ot),s&&e(Me),E(zt),s&&e(qt),s&&e(Ye),s&&e(Mt),E(Ke,s),s&&e(ra),s&&e(Dt),E(Wt),s&&e(Kt),s&&e(yt),s&&e(Ft),E(Gt,s)}}}function ks(Fe){let g,P;return g=new Sa({props:{$$slots:{default:[ws]},$$scope:{ctx:Fe}}}),{c(){v(g.$$.fragment)},l(h){b(g.$$.fragment,h)},m(h,z){w(g,h,z),P=!0},p(h,z){const T={};z&2&&(T.$$scope={dirty:z,ctx:h}),g.$set(T)},i(h){P||(k(g.$$.fragment,h),P=!0)},o(h){j(g.$$.fragment,h),P=!1},d(h){E(g,h)}}}function js(Fe){let g,P,h,z,T,I,Z,A,q,O,C,V,G,Le,Ae,ue,$t,ie,F,H,fe,ne,he,Qe,pe,Je,Q,vt,M,L,qe,te,bt,be,B,lt,Re,Ce,De,Pt,Xe,N,Ze,D,Y,Se,U,He,ae,Ve,it,S,ee,et,R,ce,J,we,de,ke,wt,xe,se,ge,tt,d,y,je,_e,Ie,re,x,nt,oe,Ee,$e,ze,pt,me,Be,Ue,Tt,ve,W,We,K,kt,At,Xt,Ht,ye,ct,Oe,at,le,st,dt,jt,mt,xt,ut,ft,Et,Bt,Yt,ht,rt,Ge,Pe,gt,It,Ut,Ot,Me,Ne,_t,zt,i;return I=new Rt({}),C=new us({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/training.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/pytorch/training.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/tensorflow/training.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/training.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/pytorch/training.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/tensorflow/training.ipynb"}]}}),Re=new Rt({}),N=new Ca({props:{id:"_BZearw7f0w"}}),ee=new X({props:{code:`from datasets import load_dataset

dataset = load_dataset("yelp_review_full")
dataset["train"][100]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;yelp_review_full&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">100</span>]
{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\&#x27;s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\&#x27;s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\&quot;serving off their orders\\\\&quot; when they didn\\&#x27;t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\&#x27;t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\&#x27;ve eaten at various McDonalds restaurants for over 30 years. I\\&#x27;ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!&#x27;</span>}`}}),xe=new X({props:{code:`from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")


def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)


tokenized_datasets = dataset.map(tokenize_function, batched=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> tokenizer(examples[<span class="hljs-string">&quot;text&quot;</span>], padding=<span class="hljs-string">&quot;max_length&quot;</span>, truncation=<span class="hljs-literal">True</span>)


<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_datasets = dataset.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>)`}}),y=new X({props:{code:`small_train_dataset = tokenized_datasets["train"].shuffle(seed=42).select(range(1000))
small_eval_dataset = tokenized_datasets["test"].shuffle(seed=42).select(range(1000))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>small_train_dataset = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>small_eval_dataset = tokenized_datasets[<span class="hljs-string">&quot;test&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))`}}),oe=new Rt({}),me=new is({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[vs],pytorch:[gs]},$$scope:{ctx:Fe}}}),K=new Rt({}),ye=new is({props:{pytorch:!0,tensorflow:!1,jax:!1,$$slots:{pytorch:[ks]},$$scope:{ctx:Fe}}}),jt=new Rt({}),{c(){g=r("meta"),P=m(),h=r("h1"),z=r("a"),T=r("span"),v(I.$$.fragment),Z=m(),A=r("span"),q=n("Mettere a punto un modello pre-addestrato"),O=m(),v(C.$$.fragment),V=m(),G=r("p"),Le=n("Ci sono benefici significativi nell\u2019usare un modello pre-allenato. Riduce i costi computazionali, la tua impronta di carbonio, e ti consente di usare lo stato dell\u2019arte dei modelli senza doverli addestrare da zero. \u{1F917} Transformers consente l\u2019accesso a migliaia di modelli pre-addestrati per un\u2019ampia gamma di compiti. Quando usi un modello pre-addestrato, lo alleni su un dataset specifico per il tuo compito. Questo \xE8 conosciuto come messa a punto (in inglese "),Ae=r("em"),ue=n("fine-tuning"),$t=n("),una tecnica di addestramento incredibilmente potente. In questa esercitazione, potrai mettere a punto un modello pre-addestrato con un framework di deep learning a tua scelta:"),ie=m(),F=r("ul"),H=r("li"),fe=n("Messa a punto di un modello pre-addestrato con \u{1F917} Transformers "),ne=r("code"),he=n("Trainer"),Qe=n("."),pe=m(),Je=r("li"),Q=n("Messa a punto di un modello pre-addestrato in TensorFlow con Keras."),vt=m(),M=r("li"),L=n("Messa a punto di un modello pre-addestrato con PyTorch."),qe=m(),te=r("a"),bt=m(),be=r("h2"),B=r("a"),lt=r("span"),v(Re.$$.fragment),Ce=m(),De=r("span"),Pt=n("Preparare un dataset"),Xe=m(),v(N.$$.fragment),Ze=m(),D=r("p"),Y=n("Prima di poter mettere a punto un modello pre-addestrato, scarica un dataset e preparalo per l\u2019addestramento. La precedente esercitazione ti mostra come processare i dati per l\u2019addestramento, e adesso hai l\u2019opportunit\xE0 di provare queste capacit\xE0 sul test!"),Se=m(),U=r("p"),He=n("Inizia caricando il dataset "),ae=r("a"),Ve=n("Yelp Reviews"),it=n(":"),S=m(),v(ee.$$.fragment),et=m(),R=r("p"),ce=n("Come gi\xE0 sai, hai bisogno di un tokenizer per processare il testo e includere una strategia di padding e truncation per gestire sequenze di lunghezza variabile. Per processare il dataset in un unico passo, usa il metodo "),J=r("a"),we=r("code"),de=n("map"),ke=n(" di \u{1F917} Datasets che applica la funzione di preprocessamento all\u2019intero dataset:"),wt=m(),v(xe.$$.fragment),se=m(),ge=r("p"),tt=n("If you like, you can create a smaller subset of the full dataset to fine-tune on to reduce the time it takes:"),d=m(),v(y.$$.fragment),je=m(),_e=r("a"),Ie=m(),re=r("h2"),x=r("a"),nt=r("span"),v(oe.$$.fragment),Ee=m(),$e=r("span"),ze=n("Addestramento"),pt=m(),v(me.$$.fragment),Be=m(),Ue=r("a"),Tt=m(),ve=r("h2"),W=r("a"),We=r("span"),v(K.$$.fragment),kt=m(),At=r("span"),Xt=n("Addestramento in PyTorch nativo"),Ht=m(),v(ye.$$.fragment),ct=m(),Oe=r("a"),at=m(),le=r("h2"),st=r("a"),dt=r("span"),v(jt.$$.fragment),mt=m(),xt=r("span"),ut=n("Altre risorse"),ft=m(),Et=r("p"),Bt=n("Per altri esempi sul fine-tuning, fai riferimento a:"),Yt=m(),ht=r("ul"),rt=r("li"),Ge=r("p"),Pe=r("a"),gt=n("\u{1F917} Transformers Examples"),It=n(" include scripts per addestrare compiti comuni di NLP in PyTorch e TensorFlow."),Ut=m(),Ot=r("li"),Me=r("p"),Ne=r("a"),_t=n("\u{1F917} Transformers Notebooks"),zt=n(" contiene diversi notebooks su come mettere a punto un modello per compiti specifici in PyTorch e TensorFlow."),this.h()},l(a){const $=ds('[data-svelte="svelte-1phssyn"]',document.head);g=o($,"META",{name:!0,content:!0}),$.forEach(e),P=u(a),h=o(a,"H1",{class:!0});var qt=l(h);z=o(qt,"A",{id:!0,class:!0,href:!0});var Ye=l(z);T=o(Ye,"SPAN",{});var na=l(T);b(I.$$.fragment,na),na.forEach(e),Ye.forEach(e),Z=u(qt),A=o(qt,"SPAN",{});var Ct=l(A);q=p(Ct,"Mettere a punto un modello pre-addestrato"),Ct.forEach(e),qt.forEach(e),O=u(a),b(C.$$.fragment,a),V=u(a),G=o(a,"P",{});var Zt=l(G);Le=p(Zt,"Ci sono benefici significativi nell\u2019usare un modello pre-allenato. Riduce i costi computazionali, la tua impronta di carbonio, e ti consente di usare lo stato dell\u2019arte dei modelli senza doverli addestrare da zero. \u{1F917} Transformers consente l\u2019accesso a migliaia di modelli pre-addestrati per un\u2019ampia gamma di compiti. Quando usi un modello pre-addestrato, lo alleni su un dataset specifico per il tuo compito. Questo \xE8 conosciuto come messa a punto (in inglese "),Ae=o(Zt,"EM",{});var pa=l(Ae);ue=p(pa,"fine-tuning"),pa.forEach(e),$t=p(Zt,"),una tecnica di addestramento incredibilmente potente. In questa esercitazione, potrai mettere a punto un modello pre-addestrato con un framework di deep learning a tua scelta:"),Zt.forEach(e),ie=u(a),F=o(a,"UL",{});var Mt=l(F);H=o(Mt,"LI",{});var Ke=l(H);fe=p(Ke,"Messa a punto di un modello pre-addestrato con \u{1F917} Transformers "),ne=o(Ke,"CODE",{});var ra=l(ne);he=p(ra,"Trainer"),ra.forEach(e),Qe=p(Ke,"."),Ke.forEach(e),pe=u(Mt),Je=o(Mt,"LI",{});var Dt=l(Je);Q=p(Dt,"Messa a punto di un modello pre-addestrato in TensorFlow con Keras."),Dt.forEach(e),vt=u(Mt),M=o(Mt,"LI",{});var Nt=l(M);L=p(Nt,"Messa a punto di un modello pre-addestrato con PyTorch."),Nt.forEach(e),Mt.forEach(e),qe=u(a),te=o(a,"A",{id:!0}),l(te).forEach(e),bt=u(a),be=o(a,"H2",{class:!0});var St=l(be);B=o(St,"A",{id:!0,class:!0,href:!0});var Wt=l(B);lt=o(Wt,"SPAN",{});var ca=l(lt);b(Re.$$.fragment,ca),ca.forEach(e),Wt.forEach(e),Ce=u(St),De=o(St,"SPAN",{});var Vt=l(De);Pt=p(Vt,"Preparare un dataset"),Vt.forEach(e),St.forEach(e),Xe=u(a),b(N.$$.fragment,a),Ze=u(a),D=o(a,"P",{});var ot=l(D);Y=p(ot,"Prima di poter mettere a punto un modello pre-addestrato, scarica un dataset e preparalo per l\u2019addestramento. La precedente esercitazione ti mostra come processare i dati per l\u2019addestramento, e adesso hai l\u2019opportunit\xE0 di provare queste capacit\xE0 sul test!"),ot.forEach(e),Se=u(a),U=o(a,"P",{});var Kt=l(U);He=p(Kt,"Inizia caricando il dataset "),ae=o(Kt,"A",{href:!0,rel:!0});var yt=l(ae);Ve=p(yt,"Yelp Reviews"),yt.forEach(e),it=p(Kt,":"),Kt.forEach(e),S=u(a),b(ee.$$.fragment,a),et=u(a),R=o(a,"P",{});var ea=l(R);ce=p(ea,"Come gi\xE0 sai, hai bisogno di un tokenizer per processare il testo e includere una strategia di padding e truncation per gestire sequenze di lunghezza variabile. Per processare il dataset in un unico passo, usa il metodo "),J=o(ea,"A",{href:!0,rel:!0});var ta=l(J);we=o(ta,"CODE",{});var da=l(we);de=p(da,"map"),da.forEach(e),ta.forEach(e),ke=p(ea," di \u{1F917} Datasets che applica la funzione di preprocessamento all\u2019intero dataset:"),ea.forEach(e),wt=u(a),b(xe.$$.fragment,a),se=u(a),ge=o(a,"P",{});var ma=l(ge);tt=p(ma,"If you like, you can create a smaller subset of the full dataset to fine-tune on to reduce the time it takes:"),ma.forEach(e),d=u(a),b(y.$$.fragment,a),je=u(a),_e=o(a,"A",{id:!0}),l(_e).forEach(e),Ie=u(a),re=o(a,"H2",{class:!0});var Te=l(re);x=o(Te,"A",{id:!0,class:!0,href:!0});var aa=l(x);nt=o(aa,"SPAN",{});var ua=l(nt);b(oe.$$.fragment,ua),ua.forEach(e),aa.forEach(e),Ee=u(Te),$e=o(Te,"SPAN",{});var fa=l($e);ze=p(fa,"Addestramento"),fa.forEach(e),Te.forEach(e),pt=u(a),b(me.$$.fragment,a),Be=u(a),Ue=o(a,"A",{id:!0}),l(Ue).forEach(e),Tt=u(a),ve=o(a,"H2",{class:!0});var Ft=l(ve);W=o(Ft,"A",{id:!0,class:!0,href:!0});var Gt=l(W);We=o(Gt,"SPAN",{});var Qt=l(We);b(K.$$.fragment,Qt),Qt.forEach(e),Gt.forEach(e),kt=u(Ft),At=o(Ft,"SPAN",{});var s=l(At);Xt=p(s,"Addestramento in PyTorch nativo"),s.forEach(e),Ft.forEach(e),Ht=u(a),b(ye.$$.fragment,a),ct=u(a),Oe=o(a,"A",{id:!0}),l(Oe).forEach(e),at=u(a),le=o(a,"H2",{class:!0});var _=l(le);st=o(_,"A",{id:!0,class:!0,href:!0});var sa=l(st);dt=o(sa,"SPAN",{});var oa=l(dt);b(jt.$$.fragment,oa),oa.forEach(e),sa.forEach(e),mt=u(_),xt=o(_,"SPAN",{});var la=l(xt);ut=p(la,"Altre risorse"),la.forEach(e),_.forEach(e),ft=u(a),Et=o(a,"P",{});var ia=l(Et);Bt=p(ia,"Per altri esempi sul fine-tuning, fai riferimento a:"),ia.forEach(e),Yt=u(a),ht=o(a,"UL",{});var Lt=l(ht);rt=o(Lt,"LI",{});var ga=l(rt);Ge=o(ga,"P",{});var ha=l(Ge);Pe=o(ha,"A",{href:!0,rel:!0});var va=l(Pe);gt=p(va,"\u{1F917} Transformers Examples"),va.forEach(e),It=p(ha," include scripts per addestrare compiti comuni di NLP in PyTorch e TensorFlow."),ha.forEach(e),ga.forEach(e),Ut=u(Lt),Ot=o(Lt,"LI",{});var _a=l(Ot);Me=o(_a,"P",{});var Jt=l(Me);Ne=o(Jt,"A",{href:!0});var ba=l(Ne);_t=p(ba,"\u{1F917} Transformers Notebooks"),ba.forEach(e),zt=p(Jt," contiene diversi notebooks su come mettere a punto un modello per compiti specifici in PyTorch e TensorFlow."),Jt.forEach(e),_a.forEach(e),Lt.forEach(e),this.h()},h(){f(g,"name","hf:doc:metadata"),f(g,"content",JSON.stringify(Es)),f(z,"id","mettere-a-punto-un-modello-preaddestrato"),f(z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(z,"href","#mettere-a-punto-un-modello-preaddestrato"),f(h,"class","relative group"),f(te,"id","data-processing"),f(B,"id","preparare-un-dataset"),f(B,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(B,"href","#preparare-un-dataset"),f(be,"class","relative group"),f(ae,"href","https://huggingface.co/datasets/yelp_review_full"),f(ae,"rel","nofollow"),f(J,"href","https://huggingface.co/docs/datasets/process.html#map"),f(J,"rel","nofollow"),f(_e,"id","trainer"),f(x,"id","addestramento"),f(x,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(x,"href","#addestramento"),f(re,"class","relative group"),f(Ue,"id","pytorch_native"),f(W,"id","addestramento-in-pytorch-nativo"),f(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(W,"href","#addestramento-in-pytorch-nativo"),f(ve,"class","relative group"),f(Oe,"id","additional-resources"),f(st,"id","altre-risorse"),f(st,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(st,"href","#altre-risorse"),f(le,"class","relative group"),f(Pe,"href","https://github.com/huggingface/transformers/tree/main/examples"),f(Pe,"rel","nofollow"),f(Ne,"href","notebooks")},m(a,$){t(document.head,g),c(a,P,$),c(a,h,$),t(h,z),t(z,T),w(I,T,null),t(h,Z),t(h,A),t(A,q),c(a,O,$),w(C,a,$),c(a,V,$),c(a,G,$),t(G,Le),t(G,Ae),t(Ae,ue),t(G,$t),c(a,ie,$),c(a,F,$),t(F,H),t(H,fe),t(H,ne),t(ne,he),t(H,Qe),t(F,pe),t(F,Je),t(Je,Q),t(F,vt),t(F,M),t(M,L),c(a,qe,$),c(a,te,$),c(a,bt,$),c(a,be,$),t(be,B),t(B,lt),w(Re,lt,null),t(be,Ce),t(be,De),t(De,Pt),c(a,Xe,$),w(N,a,$),c(a,Ze,$),c(a,D,$),t(D,Y),c(a,Se,$),c(a,U,$),t(U,He),t(U,ae),t(ae,Ve),t(U,it),c(a,S,$),w(ee,a,$),c(a,et,$),c(a,R,$),t(R,ce),t(R,J),t(J,we),t(we,de),t(R,ke),c(a,wt,$),w(xe,a,$),c(a,se,$),c(a,ge,$),t(ge,tt),c(a,d,$),w(y,a,$),c(a,je,$),c(a,_e,$),c(a,Ie,$),c(a,re,$),t(re,x),t(x,nt),w(oe,nt,null),t(re,Ee),t(re,$e),t($e,ze),c(a,pt,$),w(me,a,$),c(a,Be,$),c(a,Ue,$),c(a,Tt,$),c(a,ve,$),t(ve,W),t(W,We),w(K,We,null),t(ve,kt),t(ve,At),t(At,Xt),c(a,Ht,$),w(ye,a,$),c(a,ct,$),c(a,Oe,$),c(a,at,$),c(a,le,$),t(le,st),t(st,dt),w(jt,dt,null),t(le,mt),t(le,xt),t(xt,ut),c(a,ft,$),c(a,Et,$),t(Et,Bt),c(a,Yt,$),c(a,ht,$),t(ht,rt),t(rt,Ge),t(Ge,Pe),t(Pe,gt),t(Ge,It),t(ht,Ut),t(ht,Ot),t(Ot,Me),t(Me,Ne),t(Ne,_t),t(Me,zt),i=!0},p(a,[$]){const qt={};$&2&&(qt.$$scope={dirty:$,ctx:a}),me.$set(qt);const Ye={};$&2&&(Ye.$$scope={dirty:$,ctx:a}),ye.$set(Ye)},i(a){i||(k(I.$$.fragment,a),k(C.$$.fragment,a),k(Re.$$.fragment,a),k(N.$$.fragment,a),k(ee.$$.fragment,a),k(xe.$$.fragment,a),k(y.$$.fragment,a),k(oe.$$.fragment,a),k(me.$$.fragment,a),k(K.$$.fragment,a),k(ye.$$.fragment,a),k(jt.$$.fragment,a),i=!0)},o(a){j(I.$$.fragment,a),j(C.$$.fragment,a),j(Re.$$.fragment,a),j(N.$$.fragment,a),j(ee.$$.fragment,a),j(xe.$$.fragment,a),j(y.$$.fragment,a),j(oe.$$.fragment,a),j(me.$$.fragment,a),j(K.$$.fragment,a),j(ye.$$.fragment,a),j(jt.$$.fragment,a),i=!1},d(a){e(g),a&&e(P),a&&e(h),E(I),a&&e(O),E(C,a),a&&e(V),a&&e(G),a&&e(ie),a&&e(F),a&&e(qe),a&&e(te),a&&e(bt),a&&e(be),E(Re),a&&e(Xe),E(N,a),a&&e(Ze),a&&e(D),a&&e(Se),a&&e(U),a&&e(S),E(ee,a),a&&e(et),a&&e(R),a&&e(wt),E(xe,a),a&&e(se),a&&e(ge),a&&e(d),E(y,a),a&&e(je),a&&e(_e),a&&e(Ie),a&&e(re),E(oe),a&&e(pt),E(me,a),a&&e(Be),a&&e(Ue),a&&e(Tt),a&&e(ve),E(K),a&&e(Ht),E(ye,a),a&&e(ct),a&&e(Oe),a&&e(at),a&&e(le),E(jt),a&&e(ft),a&&e(Et),a&&e(Yt),a&&e(ht)}}}const Es={local:"mettere-a-punto-un-modello-preaddestrato",sections:[{local:"preparare-un-dataset",title:"Preparare un dataset"},{local:"addestramento",sections:[{local:"addestrare-gli-iperparametri",title:"Addestrare gli iperparametri"},{local:"metriche",title:"Metriche"},{local:"trainer",title:"Trainer"},{local:"convertire-dataset-nel-formato-per-tensorflow",title:"Convertire dataset nel formato per TensorFlow"},{local:"compilazione-e-addestramento",title:"Compilazione e addestramento"}],title:"Addestramento"},{local:"addestramento-in-pytorch-nativo",sections:[{local:"dataloader",title:"DataLoader"},{local:"ottimizzatore-e-pianificatore-del-tasso-di-apprendimento",title:"Ottimizzatore e pianificatore del tasso di apprendimento"},{local:"training-loop",title:"Training loop"},{local:"metriche",title:"Metriche"}],title:"Addestramento in PyTorch nativo"},{local:"altre-risorse",title:"Altre risorse"}],title:"Mettere a punto un modello pre-addestrato"};function zs(Fe){return ms(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class xs extends ns{constructor(g){super();ps(this,g,zs,js,cs,{})}}export{xs as default,Es as metadata};
