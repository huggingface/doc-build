import{S as Gu,i as Ru,s as Ju,e as r,k as c,w as b,t as s,M as Xu,c as i,d as a,m,a as o,x as w,h as l,b as p,G as t,g as u,y,q as P,o as x,B as A,v as Bu,L as io}from"../chunks/vendor-hf-doc-builder.js";import{I as ae}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as H}from"../chunks/CodeBlock-hf-doc-builder.js";import{F as Qu,M as oo}from"../chunks/Markdown-hf-doc-builder.js";import"../chunks/IconTensorflow-hf-doc-builder.js";function Ku(Q){let f,$,d,v,I,z,O,j,U,M,k,C,T,S,N,q,F,E,g,G;return g=new H({props:{code:`python examples/pytorch/summarization/run_summarization.py \\
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config "3.0.0" \\
    --source_prefix "summarize: " \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`,highlighted:`python examples/pytorch/summarization/run_summarization.py \\
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`}}),{c(){f=r("p"),$=s("Lo script di esempio scarica e pre-processa un dataset dalla libreria \u{1F917} "),d=r("a"),v=s("Datasets"),I=s(". Successivamente, lo script esegue il fine-tuning su un dataset usando il "),z=r("a"),O=s("Trainer"),j=s(" su un\u2019architettura che supporta la summarization. Il seguente esempio mostra come eseguire il fine-tuning di "),U=r("a"),M=s("T5-small"),k=s(" sul dataset "),C=r("a"),T=s("CNN/DailyMail"),S=s(". Il modello T5 richiede un parametro addizionale "),N=r("code"),q=s("source_prefix"),F=s(" a causa del modo in cui \xE8 stato addestrato. Questo prefisso permette a T5 di sapere che si tratta di un task di summarization."),E=c(),b(g.$$.fragment),this.h()},l(D){f=i(D,"P",{});var L=o(f);$=l(L,"Lo script di esempio scarica e pre-processa un dataset dalla libreria \u{1F917} "),d=i(L,"A",{href:!0,rel:!0});var J=o(d);v=l(J,"Datasets"),J.forEach(a),I=l(L,". Successivamente, lo script esegue il fine-tuning su un dataset usando il "),z=i(L,"A",{href:!0,rel:!0});var Et=o(z);O=l(Et,"Trainer"),Et.forEach(a),j=l(L," su un\u2019architettura che supporta la summarization. Il seguente esempio mostra come eseguire il fine-tuning di "),U=i(L,"A",{href:!0,rel:!0});var De=o(U);M=l(De,"T5-small"),De.forEach(a),k=l(L," sul dataset "),C=i(L,"A",{href:!0,rel:!0});var R=o(C);T=l(R,"CNN/DailyMail"),R.forEach(a),S=l(L,". Il modello T5 richiede un parametro addizionale "),N=i(L,"CODE",{});var zt=o(N);q=l(zt,"source_prefix"),zt.forEach(a),F=l(L," a causa del modo in cui \xE8 stato addestrato. Questo prefisso permette a T5 di sapere che si tratta di un task di summarization."),L.forEach(a),E=m(D),w(g.$$.fragment,D),this.h()},h(){p(d,"href","https://huggingface.co/docs/datasets/"),p(d,"rel","nofollow"),p(z,"href","https://huggingface.co/docs/transformers/main_classes/trainer"),p(z,"rel","nofollow"),p(U,"href","https://huggingface.co/t5-small"),p(U,"rel","nofollow"),p(C,"href","https://huggingface.co/datasets/cnn_dailymail"),p(C,"rel","nofollow")},m(D,L){u(D,f,L),t(f,$),t(f,d),t(d,v),t(f,I),t(f,z),t(z,O),t(f,j),t(f,U),t(U,M),t(f,k),t(f,C),t(C,T),t(f,S),t(f,N),t(N,q),t(f,F),u(D,E,L),y(g,D,L),G=!0},p:io,i(D){G||(P(g.$$.fragment,D),G=!0)},o(D){x(g.$$.fragment,D),G=!1},d(D){D&&a(f),D&&a(E),A(g,D)}}}function Vu(Q){let f,$;return f=new oo({props:{$$slots:{default:[Ku]},$$scope:{ctx:Q}}}),{c(){b(f.$$.fragment)},l(d){w(f.$$.fragment,d)},m(d,v){y(f,d,v),$=!0},p(d,v){const I={};v&2&&(I.$$scope={dirty:v,ctx:d}),f.$set(I)},i(d){$||(P(f.$$.fragment,d),$=!0)},o(d){x(f.$$.fragment,d),$=!1},d(d){A(f,d)}}}function Yu(Q){let f,$,d,v,I,z,O,j,U,M,k,C,T,S,N,q,F;return q=new H({props:{code:`python examples/tensorflow/summarization/run_summarization.py  \\
    --model_name_or_path t5-small \\
    --dataset_name cnn_dailymail \\
    --dataset_config "3.0.0" \\
    --output_dir /tmp/tst-summarization  \\
    --per_device_train_batch_size 8 \\
    --per_device_eval_batch_size 16 \\
    --num_train_epochs 3 \\
    --do_train \\
    --do_eval`,highlighted:`python examples/tensorflow/summarization/run_summarization.py  \\
    --model_name_or_path t5-small \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --output_dir /tmp/tst-summarization  \\
    --per_device_train_batch_size 8 \\
    --per_device_eval_batch_size 16 \\
    --num_train_epochs 3 \\
    --do_train \\
    --do_eval`}}),{c(){f=r("p"),$=s("Lo script di esempio scarica e pre-processa un dataset dalla libreria \u{1F917} "),d=r("a"),v=s("Datasets"),I=s(". Successivamente, lo script esegue il fine-tuning su un dataset usando Keras su un\u2019architettura che supporta la summarization. Il seguente esempio mostra come eseguire il fine-tuning di "),z=r("a"),O=s("T5-small"),j=s(" sul dataset "),U=r("a"),M=s("CNN/DailyMail"),k=s(". Il modello T5 richiede un parametro addizionale "),C=r("code"),T=s("source_prefix"),S=s(" a causa del modo in cui \xE8 stato addestrato. Questo prefisso permette a T5 di sapere che si tratta di un task di summarization."),N=c(),b(q.$$.fragment),this.h()},l(E){f=i(E,"P",{});var g=o(f);$=l(g,"Lo script di esempio scarica e pre-processa un dataset dalla libreria \u{1F917} "),d=i(g,"A",{href:!0,rel:!0});var G=o(d);v=l(G,"Datasets"),G.forEach(a),I=l(g,". Successivamente, lo script esegue il fine-tuning su un dataset usando Keras su un\u2019architettura che supporta la summarization. Il seguente esempio mostra come eseguire il fine-tuning di "),z=i(g,"A",{href:!0,rel:!0});var D=o(z);O=l(D,"T5-small"),D.forEach(a),j=l(g," sul dataset "),U=i(g,"A",{href:!0,rel:!0});var L=o(U);M=l(L,"CNN/DailyMail"),L.forEach(a),k=l(g,". Il modello T5 richiede un parametro addizionale "),C=i(g,"CODE",{});var J=o(C);T=l(J,"source_prefix"),J.forEach(a),S=l(g," a causa del modo in cui \xE8 stato addestrato. Questo prefisso permette a T5 di sapere che si tratta di un task di summarization."),g.forEach(a),N=m(E),w(q.$$.fragment,E),this.h()},h(){p(d,"href","https://huggingface.co/docs/datasets/"),p(d,"rel","nofollow"),p(z,"href","https://huggingface.co/t5-small"),p(z,"rel","nofollow"),p(U,"href","https://huggingface.co/datasets/cnn_dailymail"),p(U,"rel","nofollow")},m(E,g){u(E,f,g),t(f,$),t(f,d),t(d,v),t(f,I),t(f,z),t(z,O),t(f,j),t(f,U),t(U,M),t(f,k),t(f,C),t(C,T),t(f,S),u(E,N,g),y(q,E,g),F=!0},p:io,i(E){F||(P(q.$$.fragment,E),F=!0)},o(E){x(q.$$.fragment,E),F=!1},d(E){E&&a(f),E&&a(N),A(q,E)}}}function Wu(Q){let f,$;return f=new oo({props:{$$slots:{default:[Yu]},$$scope:{ctx:Q}}}),{c(){b(f.$$.fragment)},l(d){w(f.$$.fragment,d)},m(d,v){y(f,d,v),$=!0},p(d,v){const I={};v&2&&(I.$$scope={dirty:v,ctx:d}),f.$set(I)},i(d){$||(P(f.$$.fragment,d),$=!0)},o(d){x(f.$$.fragment,d),$=!1},d(d){A(f,d)}}}function Zu(Q){let f,$,d,v,I,z,O,j,U,M,k,C,T,S,N,q,F;return q=new H({props:{code:`python xla_spawn.py --num_cores 8 \\
    summarization/run_summarization.py \\
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config "3.0.0" \\
    --source_prefix "summarize: " \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`,highlighted:`python xla_spawn.py --num_cores 8 \\
    summarization/run_summarization.py \\
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`}}),{c(){f=r("p"),$=s("Le Tensor Processing Units (TPU) sono state progettate per migliorare le prestazioni. PyTorch supporta le TPU con il compilatore per deep learning "),d=r("a"),v=s("XLA"),I=s(" (guarda "),z=r("a"),O=s("questo link"),j=s(" per maggiori dettagli). Per usare una TPU, avvia lo script "),U=r("code"),M=s("xla_spawn.py"),k=s(" e usa l\u2019argomento "),C=r("code"),T=s("num_cores"),S=s(" per impostare il numero di core TPU che intendi usare."),N=c(),b(q.$$.fragment),this.h()},l(E){f=i(E,"P",{});var g=o(f);$=l(g,"Le Tensor Processing Units (TPU) sono state progettate per migliorare le prestazioni. PyTorch supporta le TPU con il compilatore per deep learning "),d=i(g,"A",{href:!0,rel:!0});var G=o(d);v=l(G,"XLA"),G.forEach(a),I=l(g," (guarda "),z=i(g,"A",{href:!0,rel:!0});var D=o(z);O=l(D,"questo link"),D.forEach(a),j=l(g," per maggiori dettagli). Per usare una TPU, avvia lo script "),U=i(g,"CODE",{});var L=o(U);M=l(L,"xla_spawn.py"),L.forEach(a),k=l(g," e usa l\u2019argomento "),C=i(g,"CODE",{});var J=o(C);T=l(J,"num_cores"),J.forEach(a),S=l(g," per impostare il numero di core TPU che intendi usare."),g.forEach(a),N=m(E),w(q.$$.fragment,E),this.h()},h(){p(d,"href","https://www.tensorflow.org/xla"),p(d,"rel","nofollow"),p(z,"href","https://github.com/pytorch/xla/blob/master/README.md"),p(z,"rel","nofollow")},m(E,g){u(E,f,g),t(f,$),t(f,d),t(d,v),t(f,I),t(f,z),t(z,O),t(f,j),t(f,U),t(U,M),t(f,k),t(f,C),t(C,T),t(f,S),u(E,N,g),y(q,E,g),F=!0},p:io,i(E){F||(P(q.$$.fragment,E),F=!0)},o(E){x(q.$$.fragment,E),F=!1},d(E){E&&a(f),E&&a(N),A(q,E)}}}function ec(Q){let f,$;return f=new oo({props:{$$slots:{default:[Zu]},$$scope:{ctx:Q}}}),{c(){b(f.$$.fragment)},l(d){w(f.$$.fragment,d)},m(d,v){y(f,d,v),$=!0},p(d,v){const I={};v&2&&(I.$$scope={dirty:v,ctx:d}),f.$set(I)},i(d){$||(P(f.$$.fragment,d),$=!0)},o(d){x(f.$$.fragment,d),$=!1},d(d){A(f,d)}}}function tc(Q){let f,$,d,v,I,z,O,j,U,M,k,C;return k=new H({props:{code:`python run_summarization.py  \\
    --tpu name_of_tpu_resource \\
    --model_name_or_path t5-small \\
    --dataset_name cnn_dailymail \\
    --dataset_config "3.0.0" \\
    --output_dir /tmp/tst-summarization  \\
    --per_device_train_batch_size 8 \\
    --per_device_eval_batch_size 16 \\
    --num_train_epochs 3 \\
    --do_train \\
    --do_eval`,highlighted:`python run_summarization.py  \\
    --tpu name_of_tpu_resource \\
    --model_name_or_path t5-small \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --output_dir /tmp/tst-summarization  \\
    --per_device_train_batch_size 8 \\
    --per_device_eval_batch_size 16 \\
    --num_train_epochs 3 \\
    --do_train \\
    --do_eval`}}),{c(){f=r("p"),$=s("Le Tensor Processing Units (TPU) sono state progettate per migliorare le prestazioni. Gli script TensorFlow utilizzano una "),d=r("a"),v=r("code"),I=s("TPUStrategy"),z=s(" per eseguire l\u2019addestramento su TPU. Per usare una TPU, passa il nome della risorsa TPU all\u2019argomento "),O=r("code"),j=s("tpu"),U=s("."),M=c(),b(k.$$.fragment),this.h()},l(T){f=i(T,"P",{});var S=o(f);$=l(S,"Le Tensor Processing Units (TPU) sono state progettate per migliorare le prestazioni. Gli script TensorFlow utilizzano una "),d=i(S,"A",{href:!0,rel:!0});var N=o(d);v=i(N,"CODE",{});var q=o(v);I=l(q,"TPUStrategy"),q.forEach(a),N.forEach(a),z=l(S," per eseguire l\u2019addestramento su TPU. Per usare una TPU, passa il nome della risorsa TPU all\u2019argomento "),O=i(S,"CODE",{});var F=o(O);j=l(F,"tpu"),F.forEach(a),U=l(S,"."),S.forEach(a),M=m(T),w(k.$$.fragment,T),this.h()},h(){p(d,"href","https://www.tensorflow.org/guide/distributed_training#tpustrategy"),p(d,"rel","nofollow")},m(T,S){u(T,f,S),t(f,$),t(f,d),t(d,v),t(v,I),t(f,z),t(f,O),t(O,j),t(f,U),u(T,M,S),y(k,T,S),C=!0},p:io,i(T){C||(P(k.$$.fragment,T),C=!0)},o(T){x(k.$$.fragment,T),C=!1},d(T){T&&a(f),T&&a(M),A(k,T)}}}function ac(Q){let f,$;return f=new oo({props:{$$slots:{default:[tc]},$$scope:{ctx:Q}}}),{c(){b(f.$$.fragment)},l(d){w(f.$$.fragment,d)},m(d,v){y(f,d,v),$=!0},p(d,v){const I={};v&2&&(I.$$scope={dirty:v,ctx:d}),f.$set(I)},i(d){$||(P(f.$$.fragment,d),$=!0)},o(d){x(f.$$.fragment,d),$=!1},d(d){A(f,d)}}}function rc(Q){let f,$,d,v,I,z,O,j,U,M,k,C,T,S,N,q,F,E,g,G,D,L,J,Et,De,R,zt,Ne,so,lo,Oe,no,po,Dr,bt,uo,Nr,K,co,je,mo,fo,Me,_o,ho,Or,V,vo,Fe,go,$o,He,Eo,zo,jr,re,me,_a,Qe,bo,ha,wo,Mr,fe,yo,va,Po,xo,Fr,Ge,Hr,wt,Ao,Qr,de,ga,ko,To,_,$a,yt,Io,qo,Ea,Pt,Lo,Uo,za,xt,Co,So,ba,At,Do,No,wa,kt,Oo,jo,ya,Tt,Mo,Fo,Pa,It,Ho,Qo,xa,qt,Go,Ro,Aa,Lt,Jo,Xo,ka,Ut,Bo,Ko,Ta,Ct,Vo,Yo,Ia,St,Wo,Zo,qa,Dt,es,ts,La,Nt,as,rs,Ua,Ot,is,os,Ca,jt,ss,ls,Sa,Mt,ns,ps,Da,Ft,us,cs,Na,Ht,ms,fs,Oa,Qt,ds,_s,ja,Gt,hs,vs,Ma,Rt,gs,$s,Fa,Jt,Es,zs,Ha,Xt,bs,ws,Qa,Bt,ys,Ps,Ga,Kt,xs,As,Ra,Vt,ks,Gr,Yt,Ts,Rr,Re,Jr,Wt,Is,Xr,Je,Br,ie,_e,Ja,Xe,qs,Xa,Ls,Kr,he,Vr,oe,ve,Ba,Be,Us,Ka,Cs,Yr,ge,Ss,Ke,Ds,Ns,Wr,$e,Ve,Os,Va,js,Ms,Fs,Ye,Hs,Ya,Qs,Gs,Zr,We,ei,Ee,Rs,Ze,Wa,Js,Xs,ti,se,ze,Za,et,Bs,er,Ks,ai,be,ri,le,we,tr,tt,Vs,ar,Ys,ii,ye,Ws,at,Zs,el,oi,Pe,rr,tl,al,rt,si,X,rl,ir,il,ol,or,sl,ll,sr,nl,pl,li,it,ni,Zt,ul,pi,ot,ui,ea,cl,ci,st,mi,ne,xe,lr,lt,ml,nr,fl,fi,ta,dl,di,Y,Ae,pr,_l,hl,ur,vl,gl,$l,aa,cr,El,zl,bl,ra,mr,wl,yl,_i,ia,Pl,hi,nt,vi,pe,ke,fr,pt,xl,dr,Al,gi,oa,kl,$i,W,_r,hr,Tl,Il,vr,gr,ql,Ll,$r,Er,Ul,Ei,ut,zi,Z,Cl,zr,Sl,Dl,br,Nl,Ol,bi,ct,wi,ue,Te,wr,mt,jl,yr,Ml,yi,sa,Fl,Pi,B,Hl,Pr,Ql,Gl,xr,Rl,Jl,Ar,Xl,Bl,xi,ft,Ai,Ie,Kl,kr,Vl,Yl,ki,dt,Ti,ce,qe,Tr,_t,Wl,Ir,Zl,Ii,Le,en,ht,tn,an,qi,vt,Li,ee,rn,qr,on,sn,Lr,ln,nn,Ui,Ue,pn,Ur,un,cn,Ci,la,mn,Si,gt,Di;return z=new ae({}),Qe=new ae({}),Ge=new H({props:{code:`git clone https://github.com/huggingface/transformers
cd transformers
pip install .`,highlighted:`git <span class="hljs-built_in">clone</span> https://github.com/huggingface/transformers
<span class="hljs-built_in">cd</span> transformers
pip install .`}}),Re=new H({props:{code:"git checkout tags/v3.5.1",highlighted:"git checkout tags/v3.5.1"}}),Je=new H({props:{code:"pip install -r requirements.txt",highlighted:"pip install -r requirements.txt"}}),Xe=new ae({}),he=new Qu({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Wu],pytorch:[Vu]},$$scope:{ctx:Q}}}),Be=new ae({}),We=new H({props:{code:`python -m torch.distributed.launch \\
    --nproc_per_node 8 pytorch/summarization/run_summarization.py \\
    --fp16 \\
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config "3.0.0" \\
    --source_prefix "summarize: " \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`,highlighted:`python -m torch.distributed.launch \\
    --nproc_per_node 8 pytorch/summarization/run_summarization.py \\
    --fp16 \\
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`}}),et=new ae({}),be=new Qu({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[ac],pytorch:[ec]},$$scope:{ctx:Q}}}),tt=new ae({}),rt=new H({props:{code:"pip install git+https://github.com/huggingface/accelerate",highlighted:"pip install git+https://github.com/huggingface/accelerate"}}),it=new H({props:{code:"accelerate config",highlighted:"accelerate config"}}),ot=new H({props:{code:"accelerate test",highlighted:'accelerate <span class="hljs-built_in">test</span>'}}),st=new H({props:{code:`accelerate launch run_summarization_no_trainer.py \\
    --model_name_or_path t5-small \\
    --dataset_name cnn_dailymail \\
    --dataset_config "3.0.0" \\
    --source_prefix "summarize: " \\
    --output_dir ~/tmp/tst-summarization`,highlighted:`accelerate launch run_summarization_no_trainer.py \\
    --model_name_or_path t5-small \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir ~/tmp/tst-summarization`}}),lt=new ae({}),nt=new H({props:{code:`python examples/pytorch/summarization/run_summarization.py \\
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --train_file path_to_csv_or_jsonlines_file \\
    --validation_file path_to_csv_or_jsonlines_file \\
    --text_column text_column_name \\
    --summary_column summary_column_name \\
    --source_prefix "summarize: " \\
    --output_dir /tmp/tst-summarization \\
    --overwrite_output_dir \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --predict_with_generate`,highlighted:`python examples/pytorch/summarization/run_summarization.py \\
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --train_file path_to_csv_or_jsonlines_file \\
    --validation_file path_to_csv_or_jsonlines_file \\
    --text_column text_column_name \\
    --summary_column summary_column_name \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --overwrite_output_dir \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --predict_with_generate`}}),pt=new ae({}),ut=new H({props:{code:`python examples/pytorch/summarization/run_summarization.py \\
    --model_name_or_path t5-small \\
    --max_train_samples 50 \\
    --max_eval_samples 50 \\
    --max_predict_samples 50 \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config "3.0.0" \\
    --source_prefix "summarize: " \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`,highlighted:`python examples/pytorch/summarization/run_summarization.py \\
    --model_name_or_path t5-small \\
    --max_train_samples 50 \\
    --max_eval_samples 50 \\
    --max_predict_samples 50 \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`}}),ct=new H({props:{code:"examples/pytorch/summarization/run_summarization.py -h",highlighted:"examples/pytorch/summarization/run_summarization.py -h"}}),mt=new ae({}),ft=new H({props:{code:`python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config "3.0.0" \\
    --source_prefix "summarize: " \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --output_dir previous_output_dir \\
    --predict_with_generate`,highlighted:`python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --output_dir previous_output_dir \\
    --predict_with_generate`}}),dt=new H({props:{code:`python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config "3.0.0" \\
    --source_prefix "summarize: " \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --resume_from_checkpoint path_to_specific_checkpoint \\
    --predict_with_generate`,highlighted:`python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --resume_from_checkpoint path_to_specific_checkpoint \\
    --predict_with_generate`}}),_t=new ae({}),vt=new H({props:{code:"huggingface-cli login",highlighted:"huggingface-cli login"}}),gt=new H({props:{code:`python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config "3.0.0" \\
    --source_prefix "summarize: " \\
    --push_to_hub \\
    --push_to_hub_model_id finetuned-t5-cnn_dailymail \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`,highlighted:`python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --push_to_hub \\
    --push_to_hub_model_id finetuned-t5-cnn_dailymail \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`}}),{c(){f=r("meta"),$=c(),d=r("h1"),v=r("a"),I=r("span"),b(z.$$.fragment),O=c(),j=r("span"),U=s("Addestramento con script"),M=c(),k=r("p"),C=s("Insieme ai "),T=r("a"),S=s("notebooks"),N=s(" \u{1F917} Transformers, ci sono anche esempi di script che dimostrano come addestrare un modello per un task con "),q=r("a"),F=s("PyTorch"),E=s(", "),g=r("a"),G=s("TensorFlow"),D=s(", o "),L=r("a"),J=s("JAX/Flax"),Et=s("."),De=c(),R=r("p"),zt=s("Troverai anche script che abbiamo usato nei nostri "),Ne=r("a"),so=s("progetti di ricerca"),lo=s(" e "),Oe=r("a"),no=s("precedenti esempi"),po=s(" a cui contribuisce per lo pi\xF9 la comunit\xE0. Questi script non sono attivamente mantenuti e richiedono una specifica versione di \u{1F917} Transformers che sar\xE0 molto probabilmente incompatibile con l\u2019ultima versione della libreria."),Dr=c(),bt=r("p"),uo=s("Non \xE8 dato per scontato che gli script di esempio funzionino senza apportare modifiche per ogni problema, bens\xEC potrebbe essere necessario adattare lo script al tuo caso specifico. Per aiutarti in ci\xF2, la maggioranza degli script espone le modalit\xE0 di pre-processamento dei dati, consentendoti di modificare lo script come preferisci."),Nr=c(),K=r("p"),co=s("Per qualsiasi feature che vorresti implementare in uno script d\u2019esempio, per favore discutine nel "),je=r("a"),mo=s("forum"),fo=s(" o in un\u2019"),Me=r("a"),_o=s("issue"),ho=s(" prima di inviare una Pull Request. Mentre accogliamo con piacere la correzione di bug, \xE8 pi\xF9 improbabile che faremo la stessa con una PR che aggiunge funzionalit\xE0 sacrificando la leggibilit\xE0."),Or=c(),V=r("p"),vo=s("Questa guida ti mostrer\xE0 come eseguire uno script di esempio relativo al task di summarization in "),Fe=r("a"),go=s("PyTorch"),$o=s(" e "),He=r("a"),Eo=s("TensorFlow"),zo=s(". Tutti gli esempi funzioneranno con entrambi i framework a meno che non sia specificato altrimenti."),jr=c(),re=r("h2"),me=r("a"),_a=r("span"),b(Qe.$$.fragment),bo=c(),ha=r("span"),wo=s("Installazione"),Mr=c(),fe=r("p"),yo=s("Per eseguire con successo l\u2019ultima versione degli script di esempio, devi "),va=r("strong"),Po=s("installare \u{1F917} Transformers dalla fonte"),xo=s(" in un nuovo ambiente virtuale:"),Fr=c(),b(Ge.$$.fragment),Hr=c(),wt=r("p"),Ao=s("Per le precedenti versioni degli script di esempio, clicca sul pulsante di seguito:"),Qr=c(),de=r("details"),ga=r("summary"),ko=s("Esempi per versioni precedenti di \u{1F917} Transformers"),To=c(),_=r("ul"),$a=r("li"),yt=r("a"),Io=s("v4.5.1"),qo=c(),Ea=r("li"),Pt=r("a"),Lo=s("v4.4.2"),Uo=c(),za=r("li"),xt=r("a"),Co=s("v4.3.3"),So=c(),ba=r("li"),At=r("a"),Do=s("v4.2.2"),No=c(),wa=r("li"),kt=r("a"),Oo=s("v4.1.1"),jo=c(),ya=r("li"),Tt=r("a"),Mo=s("v4.0.1"),Fo=c(),Pa=r("li"),It=r("a"),Ho=s("v3.5.1"),Qo=c(),xa=r("li"),qt=r("a"),Go=s("v3.4.0"),Ro=c(),Aa=r("li"),Lt=r("a"),Jo=s("v3.3.1"),Xo=c(),ka=r("li"),Ut=r("a"),Bo=s("v3.2.0"),Ko=c(),Ta=r("li"),Ct=r("a"),Vo=s("v3.1.0"),Yo=c(),Ia=r("li"),St=r("a"),Wo=s("v3.0.2"),Zo=c(),qa=r("li"),Dt=r("a"),es=s("v2.11.0"),ts=c(),La=r("li"),Nt=r("a"),as=s("v2.10.0"),rs=c(),Ua=r("li"),Ot=r("a"),is=s("v2.9.1"),os=c(),Ca=r("li"),jt=r("a"),ss=s("v2.8.0"),ls=c(),Sa=r("li"),Mt=r("a"),ns=s("v2.7.0"),ps=c(),Da=r("li"),Ft=r("a"),us=s("v2.6.0"),cs=c(),Na=r("li"),Ht=r("a"),ms=s("v2.5.1"),fs=c(),Oa=r("li"),Qt=r("a"),ds=s("v2.4.0"),_s=c(),ja=r("li"),Gt=r("a"),hs=s("v2.3.0"),vs=c(),Ma=r("li"),Rt=r("a"),gs=s("v2.2.0"),$s=c(),Fa=r("li"),Jt=r("a"),Es=s("v2.1.1"),zs=c(),Ha=r("li"),Xt=r("a"),bs=s("v2.0.0"),ws=c(),Qa=r("li"),Bt=r("a"),ys=s("v1.2.0"),Ps=c(),Ga=r("li"),Kt=r("a"),xs=s("v1.1.0"),As=c(),Ra=r("li"),Vt=r("a"),ks=s("v1.0.0"),Gr=c(),Yt=r("p"),Ts=s("Successivamente, cambia la tua attuale copia di \u{1F917} Transformers specificandone la versione, ad esempio v3.5.1:"),Rr=c(),b(Re.$$.fragment),Jr=c(),Wt=r("p"),Is=s("Dopo aver configurato correttamente la versione della libreria, naviga nella cartella degli esempi di tua scelta e installa i requisiti:"),Xr=c(),b(Je.$$.fragment),Br=c(),ie=r("h2"),_e=r("a"),Ja=r("span"),b(Xe.$$.fragment),qs=c(),Xa=r("span"),Ls=s("Esegui uno script"),Kr=c(),b(he.$$.fragment),Vr=c(),oe=r("h2"),ve=r("a"),Ba=r("span"),b(Be.$$.fragment),Us=c(),Ka=r("span"),Cs=s("Addestramento distribuito e precisione mista"),Yr=c(),ge=r("p"),Ss=s("Il "),Ke=r("a"),Ds=s("Trainer"),Ns=s(" supporta l\u2019addestramento distribuito e la precisione mista, che significa che puoi anche usarla in uno script. Per abilitare entrambe le funzionalit\xE0:"),Wr=c(),$e=r("ul"),Ve=r("li"),Os=s("Aggiunto l\u2019argomento "),Va=r("code"),js=s("fp16"),Ms=s(" per abilitare la precisione mista."),Fs=c(),Ye=r("li"),Hs=s("Imposta un numero di GPU da usare con l\u2019argomento "),Ya=r("code"),Qs=s("nproc_per_node"),Gs=s("."),Zr=c(),b(We.$$.fragment),ei=c(),Ee=r("p"),Rs=s("Gli script TensorFlow utilizzano una "),Ze=r("a"),Wa=r("code"),Js=s("MirroredStrategy"),Xs=s(" per il training distribuito e non devi aggiungere alcun argomento addizionale allo script di training. Lo script TensorFlow user\xE0 multiple GPU in modo predefinito se quest\u2019ultime sono disponibili:"),ti=c(),se=r("h2"),ze=r("a"),Za=r("span"),b(et.$$.fragment),Bs=c(),er=r("span"),Ks=s("Esegui uno script su TPU"),ai=c(),b(be.$$.fragment),ri=c(),le=r("h2"),we=r("a"),tr=r("span"),b(tt.$$.fragment),Vs=c(),ar=r("span"),Ys=s("Esegui uno script con \u{1F917} Accelerate"),ii=c(),ye=r("p"),Ws=s("\u{1F917} "),at=r("a"),Zs=s("Accelerate"),el=s(" \xE8 una libreria compatibile solo con PyTorch che offre un metodo unificato per addestrare modelli su diverse tipologie di configurazioni (CPU, multiple GPU, TPU) mantenendo una completa visibilit\xE0 rispetto al ciclo di training di PyTorch. Assicurati di aver effettuato l\u2019installazione di \u{1F917} Accelerate, nel caso non lo avessi fatto:"),oi=c(),Pe=r("blockquote"),rr=r("p"),tl=s("Nota: dato che Accelerate \xE8 in rapido sviluppo, \xE8 necessario installare la versione proveniente da git per eseguire gli script:"),al=c(),b(rt.$$.fragment),si=c(),X=r("p"),rl=s("Invece che usare lo script "),ir=r("code"),il=s("run_summarization.py"),ol=s(", devi usare lo script "),or=r("code"),sl=s("run_summarization_no_trainer.py"),ll=s(". Gli script supportati in \u{1F917} Accelerate avranno un file chiamato "),sr=r("code"),nl=s("task_no_trainer.py"),pl=s(" nella rispettiva cartella. Per iniziare, esegui il seguente comando per creare e salvare un file di configurazione:"),li=c(),b(it.$$.fragment),ni=c(),Zt=r("p"),ul=s("Testa la tua configurazione per assicurarti della sua correttezza:"),pi=c(),b(ot.$$.fragment),ui=c(),ea=r("p"),cl=s("Ora sei pronto per avviare l\u2019addestramento:"),ci=c(),b(st.$$.fragment),mi=c(),ne=r("h2"),xe=r("a"),lr=r("span"),b(lt.$$.fragment),ml=c(),nr=r("span"),fl=s("Uso di un dataset personalizzato"),fi=c(),ta=r("p"),dl=s("Lo script di summarization supporta dataset personalizzati purch\xE9 siano file CSV o JSON Line. Quando usi il tuo dataset, devi specificare diversi argomenti aggiuntivi:"),di=c(),Y=r("ul"),Ae=r("li"),pr=r("code"),_l=s("train_file"),hl=s(" e "),ur=r("code"),vl=s("validation_file"),gl=s(" specificano dove si trovano i file di addestramento e validazione."),$l=c(),aa=r("li"),cr=r("code"),El=s("text_column"),zl=s(" \xE8 il file di input da riassumere."),bl=c(),ra=r("li"),mr=r("code"),wl=s("summary_column"),yl=s(" \xE8 il file di destinazione per l\u2019output."),_i=c(),ia=r("p"),Pl=s("Uno script di summarization usando un dataset personalizzato sarebbe simile a questo:"),hi=c(),b(nt.$$.fragment),vi=c(),pe=r("h2"),ke=r("a"),fr=r("span"),b(pt.$$.fragment),xl=c(),dr=r("span"),Al=s("Testare uno script"),gi=c(),oa=r("p"),kl=s("\xC8 spesso una buona idea avviare il tuo script su un numero inferiore di esempi tratti dal dataset, per assicurarti che tutto funzioni come previsto prima di eseguire lo script sull\u2019intero dataset, che potrebbe necessitare di ore. Usa i seguenti argomenti per limitare il dataset ad un massimo numero di esempi:"),$i=c(),W=r("ul"),_r=r("li"),hr=r("code"),Tl=s("max_train_samples"),Il=c(),vr=r("li"),gr=r("code"),ql=s("max_eval_samples"),Ll=c(),$r=r("li"),Er=r("code"),Ul=s("max_predict_samples"),Ei=c(),b(ut.$$.fragment),zi=c(),Z=r("p"),Cl=s("Non tutti gli esempi di script supportano l\u2019argomento "),zr=r("code"),Sl=s("max_predict_samples"),Dl=s(". Se non sei sicuro circa il supporto di questo argomento da parte del tuo script, aggiungi l\u2019argomento "),br=r("code"),Nl=s("-h"),Ol=s(" per controllare:"),bi=c(),b(ct.$$.fragment),wi=c(),ue=r("h2"),Te=r("a"),wr=r("span"),b(mt.$$.fragment),jl=c(),yr=r("span"),Ml=s("Riavviare addestramento da un checkpoint"),yi=c(),sa=r("p"),Fl=s("Un\u2019altra utile opzione \xE8 riavviare un addestramento da un checkpoint precedente. Questo garantir\xE0 che tu possa riprendere da dove hai interrotto senza ricominciare se l\u2019addestramento viene interrotto. Ci sono due metodi per riavviare l\u2019addestramento da un checkpoint:"),Pi=c(),B=r("p"),Hl=s("Il primo metodo usa l\u2019argomento "),Pr=r("code"),Ql=s("output_dir previous_output_dir"),Gl=s(" per riavviare l\u2019addestramento dall\u2019ultima versione del checkpoint contenuto in "),xr=r("code"),Rl=s("output_dir"),Jl=s(". In questo caso, dovresti rimuovere "),Ar=r("code"),Xl=s("overwrite_output_dir"),Bl=s(":"),xi=c(),b(ft.$$.fragment),Ai=c(),Ie=r("p"),Kl=s("Il secondo metodo usa l\u2019argomento "),kr=r("code"),Vl=s("resume_from_checkpoint path_to_specific_checkpoint"),Yl=s(" per riavviare un addestramento da una specifica cartella di checkpoint."),ki=c(),b(dt.$$.fragment),Ti=c(),ce=r("h2"),qe=r("a"),Tr=r("span"),b(_t.$$.fragment),Wl=c(),Ir=r("span"),Zl=s("Condividi il tuo modello"),Ii=c(),Le=r("p"),en=s("Tutti gli script possono caricare il tuo modello finale al "),ht=r("a"),tn=s("Model Hub"),an=s(". Prima di iniziare, assicurati di aver effettuato l\u2019accesso su Hugging Face:"),qi=c(),b(vt.$$.fragment),Li=c(),ee=r("p"),rn=s("Poi, aggiungi l\u2019argomento "),qr=r("code"),on=s("push_to_hub"),sn=s(" allo script. Questo argomento consentir\xE0 di creare un repository con il tuo username Hugging Face e la cartella specificata in "),Lr=r("code"),ln=s("output_dir"),nn=s("."),Ui=c(),Ue=r("p"),pn=s("Per dare uno specifico nome al repository, usa l\u2019argomento "),Ur=r("code"),un=s("push_to_hub_model_id"),cn=s(". Il repository verr\xE0 automaticamente elencata sotto al tuo namespace."),Ci=c(),la=r("p"),mn=s("Il seguente esempio mostra come caricare un modello specificando il nome del repository:"),Si=c(),b(gt.$$.fragment),this.h()},l(e){const n=Xu('[data-svelte="svelte-1phssyn"]',document.head);f=i(n,"META",{name:!0,content:!0}),n.forEach(a),$=m(e),d=i(e,"H1",{class:!0});var $t=o(d);v=i($t,"A",{id:!0,class:!0,href:!0});var Cr=o(v);I=i(Cr,"SPAN",{});var _n=o(I);w(z.$$.fragment,_n),_n.forEach(a),Cr.forEach(a),O=m($t),j=i($t,"SPAN",{});var hn=o(j);U=l(hn,"Addestramento con script"),hn.forEach(a),$t.forEach(a),M=m(e),k=i(e,"P",{});var te=o(k);C=l(te,"Insieme ai "),T=i(te,"A",{href:!0});var vn=o(T);S=l(vn,"notebooks"),vn.forEach(a),N=l(te," \u{1F917} Transformers, ci sono anche esempi di script che dimostrano come addestrare un modello per un task con "),q=i(te,"A",{href:!0,rel:!0});var gn=o(q);F=l(gn,"PyTorch"),gn.forEach(a),E=l(te,", "),g=i(te,"A",{href:!0,rel:!0});var $n=o(g);G=l($n,"TensorFlow"),$n.forEach(a),D=l(te,", o "),L=i(te,"A",{href:!0,rel:!0});var En=o(L);J=l(En,"JAX/Flax"),En.forEach(a),Et=l(te,"."),te.forEach(a),De=m(e),R=i(e,"P",{});var na=o(R);zt=l(na,"Troverai anche script che abbiamo usato nei nostri "),Ne=i(na,"A",{href:!0,rel:!0});var zn=o(Ne);so=l(zn,"progetti di ricerca"),zn.forEach(a),lo=l(na," e "),Oe=i(na,"A",{href:!0,rel:!0});var bn=o(Oe);no=l(bn,"precedenti esempi"),bn.forEach(a),po=l(na," a cui contribuisce per lo pi\xF9 la comunit\xE0. Questi script non sono attivamente mantenuti e richiedono una specifica versione di \u{1F917} Transformers che sar\xE0 molto probabilmente incompatibile con l\u2019ultima versione della libreria."),na.forEach(a),Dr=m(e),bt=i(e,"P",{});var wn=o(bt);uo=l(wn,"Non \xE8 dato per scontato che gli script di esempio funzionino senza apportare modifiche per ogni problema, bens\xEC potrebbe essere necessario adattare lo script al tuo caso specifico. Per aiutarti in ci\xF2, la maggioranza degli script espone le modalit\xE0 di pre-processamento dei dati, consentendoti di modificare lo script come preferisci."),wn.forEach(a),Nr=m(e),K=i(e,"P",{});var pa=o(K);co=l(pa,"Per qualsiasi feature che vorresti implementare in uno script d\u2019esempio, per favore discutine nel "),je=i(pa,"A",{href:!0,rel:!0});var yn=o(je);mo=l(yn,"forum"),yn.forEach(a),fo=l(pa," o in un\u2019"),Me=i(pa,"A",{href:!0,rel:!0});var Pn=o(Me);_o=l(Pn,"issue"),Pn.forEach(a),ho=l(pa," prima di inviare una Pull Request. Mentre accogliamo con piacere la correzione di bug, \xE8 pi\xF9 improbabile che faremo la stessa con una PR che aggiunge funzionalit\xE0 sacrificando la leggibilit\xE0."),pa.forEach(a),Or=m(e),V=i(e,"P",{});var ua=o(V);vo=l(ua,"Questa guida ti mostrer\xE0 come eseguire uno script di esempio relativo al task di summarization in "),Fe=i(ua,"A",{href:!0,rel:!0});var xn=o(Fe);go=l(xn,"PyTorch"),xn.forEach(a),$o=l(ua," e "),He=i(ua,"A",{href:!0,rel:!0});var An=o(He);Eo=l(An,"TensorFlow"),An.forEach(a),zo=l(ua,". Tutti gli esempi funzioneranno con entrambi i framework a meno che non sia specificato altrimenti."),ua.forEach(a),jr=m(e),re=i(e,"H2",{class:!0});var Ni=o(re);me=i(Ni,"A",{id:!0,class:!0,href:!0});var kn=o(me);_a=i(kn,"SPAN",{});var Tn=o(_a);w(Qe.$$.fragment,Tn),Tn.forEach(a),kn.forEach(a),bo=m(Ni),ha=i(Ni,"SPAN",{});var In=o(ha);wo=l(In,"Installazione"),In.forEach(a),Ni.forEach(a),Mr=m(e),fe=i(e,"P",{});var Oi=o(fe);yo=l(Oi,"Per eseguire con successo l\u2019ultima versione degli script di esempio, devi "),va=i(Oi,"STRONG",{});var qn=o(va);Po=l(qn,"installare \u{1F917} Transformers dalla fonte"),qn.forEach(a),xo=l(Oi," in un nuovo ambiente virtuale:"),Oi.forEach(a),Fr=m(e),w(Ge.$$.fragment,e),Hr=m(e),wt=i(e,"P",{});var Ln=o(wt);Ao=l(Ln,"Per le precedenti versioni degli script di esempio, clicca sul pulsante di seguito:"),Ln.forEach(a),Qr=m(e),de=i(e,"DETAILS",{});var ji=o(de);ga=i(ji,"SUMMARY",{});var Un=o(ga);ko=l(Un,"Esempi per versioni precedenti di \u{1F917} Transformers"),Un.forEach(a),To=m(ji),_=i(ji,"UL",{});var h=o(_);$a=i(h,"LI",{});var Cn=o($a);yt=i(Cn,"A",{href:!0});var Sn=o(yt);Io=l(Sn,"v4.5.1"),Sn.forEach(a),Cn.forEach(a),qo=m(h),Ea=i(h,"LI",{});var Dn=o(Ea);Pt=i(Dn,"A",{href:!0});var Nn=o(Pt);Lo=l(Nn,"v4.4.2"),Nn.forEach(a),Dn.forEach(a),Uo=m(h),za=i(h,"LI",{});var On=o(za);xt=i(On,"A",{href:!0});var jn=o(xt);Co=l(jn,"v4.3.3"),jn.forEach(a),On.forEach(a),So=m(h),ba=i(h,"LI",{});var Mn=o(ba);At=i(Mn,"A",{href:!0});var Fn=o(At);Do=l(Fn,"v4.2.2"),Fn.forEach(a),Mn.forEach(a),No=m(h),wa=i(h,"LI",{});var Hn=o(wa);kt=i(Hn,"A",{href:!0});var Qn=o(kt);Oo=l(Qn,"v4.1.1"),Qn.forEach(a),Hn.forEach(a),jo=m(h),ya=i(h,"LI",{});var Gn=o(ya);Tt=i(Gn,"A",{href:!0});var Rn=o(Tt);Mo=l(Rn,"v4.0.1"),Rn.forEach(a),Gn.forEach(a),Fo=m(h),Pa=i(h,"LI",{});var Jn=o(Pa);It=i(Jn,"A",{href:!0});var Xn=o(It);Ho=l(Xn,"v3.5.1"),Xn.forEach(a),Jn.forEach(a),Qo=m(h),xa=i(h,"LI",{});var Bn=o(xa);qt=i(Bn,"A",{href:!0});var Kn=o(qt);Go=l(Kn,"v3.4.0"),Kn.forEach(a),Bn.forEach(a),Ro=m(h),Aa=i(h,"LI",{});var Vn=o(Aa);Lt=i(Vn,"A",{href:!0});var Yn=o(Lt);Jo=l(Yn,"v3.3.1"),Yn.forEach(a),Vn.forEach(a),Xo=m(h),ka=i(h,"LI",{});var Wn=o(ka);Ut=i(Wn,"A",{href:!0});var Zn=o(Ut);Bo=l(Zn,"v3.2.0"),Zn.forEach(a),Wn.forEach(a),Ko=m(h),Ta=i(h,"LI",{});var ep=o(Ta);Ct=i(ep,"A",{href:!0});var tp=o(Ct);Vo=l(tp,"v3.1.0"),tp.forEach(a),ep.forEach(a),Yo=m(h),Ia=i(h,"LI",{});var ap=o(Ia);St=i(ap,"A",{href:!0});var rp=o(St);Wo=l(rp,"v3.0.2"),rp.forEach(a),ap.forEach(a),Zo=m(h),qa=i(h,"LI",{});var ip=o(qa);Dt=i(ip,"A",{href:!0});var op=o(Dt);es=l(op,"v2.11.0"),op.forEach(a),ip.forEach(a),ts=m(h),La=i(h,"LI",{});var sp=o(La);Nt=i(sp,"A",{href:!0});var lp=o(Nt);as=l(lp,"v2.10.0"),lp.forEach(a),sp.forEach(a),rs=m(h),Ua=i(h,"LI",{});var np=o(Ua);Ot=i(np,"A",{href:!0});var pp=o(Ot);is=l(pp,"v2.9.1"),pp.forEach(a),np.forEach(a),os=m(h),Ca=i(h,"LI",{});var up=o(Ca);jt=i(up,"A",{href:!0});var cp=o(jt);ss=l(cp,"v2.8.0"),cp.forEach(a),up.forEach(a),ls=m(h),Sa=i(h,"LI",{});var mp=o(Sa);Mt=i(mp,"A",{href:!0});var fp=o(Mt);ns=l(fp,"v2.7.0"),fp.forEach(a),mp.forEach(a),ps=m(h),Da=i(h,"LI",{});var dp=o(Da);Ft=i(dp,"A",{href:!0});var _p=o(Ft);us=l(_p,"v2.6.0"),_p.forEach(a),dp.forEach(a),cs=m(h),Na=i(h,"LI",{});var hp=o(Na);Ht=i(hp,"A",{href:!0});var vp=o(Ht);ms=l(vp,"v2.5.1"),vp.forEach(a),hp.forEach(a),fs=m(h),Oa=i(h,"LI",{});var gp=o(Oa);Qt=i(gp,"A",{href:!0});var $p=o(Qt);ds=l($p,"v2.4.0"),$p.forEach(a),gp.forEach(a),_s=m(h),ja=i(h,"LI",{});var Ep=o(ja);Gt=i(Ep,"A",{href:!0});var zp=o(Gt);hs=l(zp,"v2.3.0"),zp.forEach(a),Ep.forEach(a),vs=m(h),Ma=i(h,"LI",{});var bp=o(Ma);Rt=i(bp,"A",{href:!0});var wp=o(Rt);gs=l(wp,"v2.2.0"),wp.forEach(a),bp.forEach(a),$s=m(h),Fa=i(h,"LI",{});var yp=o(Fa);Jt=i(yp,"A",{href:!0});var Pp=o(Jt);Es=l(Pp,"v2.1.1"),Pp.forEach(a),yp.forEach(a),zs=m(h),Ha=i(h,"LI",{});var xp=o(Ha);Xt=i(xp,"A",{href:!0});var Ap=o(Xt);bs=l(Ap,"v2.0.0"),Ap.forEach(a),xp.forEach(a),ws=m(h),Qa=i(h,"LI",{});var kp=o(Qa);Bt=i(kp,"A",{href:!0});var Tp=o(Bt);ys=l(Tp,"v1.2.0"),Tp.forEach(a),kp.forEach(a),Ps=m(h),Ga=i(h,"LI",{});var Ip=o(Ga);Kt=i(Ip,"A",{href:!0});var qp=o(Kt);xs=l(qp,"v1.1.0"),qp.forEach(a),Ip.forEach(a),As=m(h),Ra=i(h,"LI",{});var Lp=o(Ra);Vt=i(Lp,"A",{href:!0});var Up=o(Vt);ks=l(Up,"v1.0.0"),Up.forEach(a),Lp.forEach(a),h.forEach(a),ji.forEach(a),Gr=m(e),Yt=i(e,"P",{});var Cp=o(Yt);Ts=l(Cp,"Successivamente, cambia la tua attuale copia di \u{1F917} Transformers specificandone la versione, ad esempio v3.5.1:"),Cp.forEach(a),Rr=m(e),w(Re.$$.fragment,e),Jr=m(e),Wt=i(e,"P",{});var Sp=o(Wt);Is=l(Sp,"Dopo aver configurato correttamente la versione della libreria, naviga nella cartella degli esempi di tua scelta e installa i requisiti:"),Sp.forEach(a),Xr=m(e),w(Je.$$.fragment,e),Br=m(e),ie=i(e,"H2",{class:!0});var Mi=o(ie);_e=i(Mi,"A",{id:!0,class:!0,href:!0});var Dp=o(_e);Ja=i(Dp,"SPAN",{});var Np=o(Ja);w(Xe.$$.fragment,Np),Np.forEach(a),Dp.forEach(a),qs=m(Mi),Xa=i(Mi,"SPAN",{});var Op=o(Xa);Ls=l(Op,"Esegui uno script"),Op.forEach(a),Mi.forEach(a),Kr=m(e),w(he.$$.fragment,e),Vr=m(e),oe=i(e,"H2",{class:!0});var Fi=o(oe);ve=i(Fi,"A",{id:!0,class:!0,href:!0});var jp=o(ve);Ba=i(jp,"SPAN",{});var Mp=o(Ba);w(Be.$$.fragment,Mp),Mp.forEach(a),jp.forEach(a),Us=m(Fi),Ka=i(Fi,"SPAN",{});var Fp=o(Ka);Cs=l(Fp,"Addestramento distribuito e precisione mista"),Fp.forEach(a),Fi.forEach(a),Yr=m(e),ge=i(e,"P",{});var Hi=o(ge);Ss=l(Hi,"Il "),Ke=i(Hi,"A",{href:!0,rel:!0});var Hp=o(Ke);Ds=l(Hp,"Trainer"),Hp.forEach(a),Ns=l(Hi," supporta l\u2019addestramento distribuito e la precisione mista, che significa che puoi anche usarla in uno script. Per abilitare entrambe le funzionalit\xE0:"),Hi.forEach(a),Wr=m(e),$e=i(e,"UL",{});var Qi=o($e);Ve=i(Qi,"LI",{});var Gi=o(Ve);Os=l(Gi,"Aggiunto l\u2019argomento "),Va=i(Gi,"CODE",{});var Qp=o(Va);js=l(Qp,"fp16"),Qp.forEach(a),Ms=l(Gi," per abilitare la precisione mista."),Gi.forEach(a),Fs=m(Qi),Ye=i(Qi,"LI",{});var Ri=o(Ye);Hs=l(Ri,"Imposta un numero di GPU da usare con l\u2019argomento "),Ya=i(Ri,"CODE",{});var Gp=o(Ya);Qs=l(Gp,"nproc_per_node"),Gp.forEach(a),Gs=l(Ri,"."),Ri.forEach(a),Qi.forEach(a),Zr=m(e),w(We.$$.fragment,e),ei=m(e),Ee=i(e,"P",{});var Ji=o(Ee);Rs=l(Ji,"Gli script TensorFlow utilizzano una "),Ze=i(Ji,"A",{href:!0,rel:!0});var Rp=o(Ze);Wa=i(Rp,"CODE",{});var Jp=o(Wa);Js=l(Jp,"MirroredStrategy"),Jp.forEach(a),Rp.forEach(a),Xs=l(Ji," per il training distribuito e non devi aggiungere alcun argomento addizionale allo script di training. Lo script TensorFlow user\xE0 multiple GPU in modo predefinito se quest\u2019ultime sono disponibili:"),Ji.forEach(a),ti=m(e),se=i(e,"H2",{class:!0});var Xi=o(se);ze=i(Xi,"A",{id:!0,class:!0,href:!0});var Xp=o(ze);Za=i(Xp,"SPAN",{});var Bp=o(Za);w(et.$$.fragment,Bp),Bp.forEach(a),Xp.forEach(a),Bs=m(Xi),er=i(Xi,"SPAN",{});var Kp=o(er);Ks=l(Kp,"Esegui uno script su TPU"),Kp.forEach(a),Xi.forEach(a),ai=m(e),w(be.$$.fragment,e),ri=m(e),le=i(e,"H2",{class:!0});var Bi=o(le);we=i(Bi,"A",{id:!0,class:!0,href:!0});var Vp=o(we);tr=i(Vp,"SPAN",{});var Yp=o(tr);w(tt.$$.fragment,Yp),Yp.forEach(a),Vp.forEach(a),Vs=m(Bi),ar=i(Bi,"SPAN",{});var Wp=o(ar);Ys=l(Wp,"Esegui uno script con \u{1F917} Accelerate"),Wp.forEach(a),Bi.forEach(a),ii=m(e),ye=i(e,"P",{});var Ki=o(ye);Ws=l(Ki,"\u{1F917} "),at=i(Ki,"A",{href:!0,rel:!0});var Zp=o(at);Zs=l(Zp,"Accelerate"),Zp.forEach(a),el=l(Ki," \xE8 una libreria compatibile solo con PyTorch che offre un metodo unificato per addestrare modelli su diverse tipologie di configurazioni (CPU, multiple GPU, TPU) mantenendo una completa visibilit\xE0 rispetto al ciclo di training di PyTorch. Assicurati di aver effettuato l\u2019installazione di \u{1F917} Accelerate, nel caso non lo avessi fatto:"),Ki.forEach(a),oi=m(e),Pe=i(e,"BLOCKQUOTE",{});var Vi=o(Pe);rr=i(Vi,"P",{});var eu=o(rr);tl=l(eu,"Nota: dato che Accelerate \xE8 in rapido sviluppo, \xE8 necessario installare la versione proveniente da git per eseguire gli script:"),eu.forEach(a),al=m(Vi),w(rt.$$.fragment,Vi),Vi.forEach(a),si=m(e),X=i(e,"P",{});var Ce=o(X);rl=l(Ce,"Invece che usare lo script "),ir=i(Ce,"CODE",{});var tu=o(ir);il=l(tu,"run_summarization.py"),tu.forEach(a),ol=l(Ce,", devi usare lo script "),or=i(Ce,"CODE",{});var au=o(or);sl=l(au,"run_summarization_no_trainer.py"),au.forEach(a),ll=l(Ce,". Gli script supportati in \u{1F917} Accelerate avranno un file chiamato "),sr=i(Ce,"CODE",{});var ru=o(sr);nl=l(ru,"task_no_trainer.py"),ru.forEach(a),pl=l(Ce," nella rispettiva cartella. Per iniziare, esegui il seguente comando per creare e salvare un file di configurazione:"),Ce.forEach(a),li=m(e),w(it.$$.fragment,e),ni=m(e),Zt=i(e,"P",{});var iu=o(Zt);ul=l(iu,"Testa la tua configurazione per assicurarti della sua correttezza:"),iu.forEach(a),pi=m(e),w(ot.$$.fragment,e),ui=m(e),ea=i(e,"P",{});var ou=o(ea);cl=l(ou,"Ora sei pronto per avviare l\u2019addestramento:"),ou.forEach(a),ci=m(e),w(st.$$.fragment,e),mi=m(e),ne=i(e,"H2",{class:!0});var Yi=o(ne);xe=i(Yi,"A",{id:!0,class:!0,href:!0});var su=o(xe);lr=i(su,"SPAN",{});var lu=o(lr);w(lt.$$.fragment,lu),lu.forEach(a),su.forEach(a),ml=m(Yi),nr=i(Yi,"SPAN",{});var nu=o(nr);fl=l(nu,"Uso di un dataset personalizzato"),nu.forEach(a),Yi.forEach(a),fi=m(e),ta=i(e,"P",{});var pu=o(ta);dl=l(pu,"Lo script di summarization supporta dataset personalizzati purch\xE9 siano file CSV o JSON Line. Quando usi il tuo dataset, devi specificare diversi argomenti aggiuntivi:"),pu.forEach(a),di=m(e),Y=i(e,"UL",{});var ca=o(Y);Ae=i(ca,"LI",{});var Sr=o(Ae);pr=i(Sr,"CODE",{});var uu=o(pr);_l=l(uu,"train_file"),uu.forEach(a),hl=l(Sr," e "),ur=i(Sr,"CODE",{});var cu=o(ur);vl=l(cu,"validation_file"),cu.forEach(a),gl=l(Sr," specificano dove si trovano i file di addestramento e validazione."),Sr.forEach(a),$l=m(ca),aa=i(ca,"LI",{});var fn=o(aa);cr=i(fn,"CODE",{});var mu=o(cr);El=l(mu,"text_column"),mu.forEach(a),zl=l(fn," \xE8 il file di input da riassumere."),fn.forEach(a),bl=m(ca),ra=i(ca,"LI",{});var dn=o(ra);mr=i(dn,"CODE",{});var fu=o(mr);wl=l(fu,"summary_column"),fu.forEach(a),yl=l(dn," \xE8 il file di destinazione per l\u2019output."),dn.forEach(a),ca.forEach(a),_i=m(e),ia=i(e,"P",{});var du=o(ia);Pl=l(du,"Uno script di summarization usando un dataset personalizzato sarebbe simile a questo:"),du.forEach(a),hi=m(e),w(nt.$$.fragment,e),vi=m(e),pe=i(e,"H2",{class:!0});var Wi=o(pe);ke=i(Wi,"A",{id:!0,class:!0,href:!0});var _u=o(ke);fr=i(_u,"SPAN",{});var hu=o(fr);w(pt.$$.fragment,hu),hu.forEach(a),_u.forEach(a),xl=m(Wi),dr=i(Wi,"SPAN",{});var vu=o(dr);Al=l(vu,"Testare uno script"),vu.forEach(a),Wi.forEach(a),gi=m(e),oa=i(e,"P",{});var gu=o(oa);kl=l(gu,"\xC8 spesso una buona idea avviare il tuo script su un numero inferiore di esempi tratti dal dataset, per assicurarti che tutto funzioni come previsto prima di eseguire lo script sull\u2019intero dataset, che potrebbe necessitare di ore. Usa i seguenti argomenti per limitare il dataset ad un massimo numero di esempi:"),gu.forEach(a),$i=m(e),W=i(e,"UL",{});var ma=o(W);_r=i(ma,"LI",{});var $u=o(_r);hr=i($u,"CODE",{});var Eu=o(hr);Tl=l(Eu,"max_train_samples"),Eu.forEach(a),$u.forEach(a),Il=m(ma),vr=i(ma,"LI",{});var zu=o(vr);gr=i(zu,"CODE",{});var bu=o(gr);ql=l(bu,"max_eval_samples"),bu.forEach(a),zu.forEach(a),Ll=m(ma),$r=i(ma,"LI",{});var wu=o($r);Er=i(wu,"CODE",{});var yu=o(Er);Ul=l(yu,"max_predict_samples"),yu.forEach(a),wu.forEach(a),ma.forEach(a),Ei=m(e),w(ut.$$.fragment,e),zi=m(e),Z=i(e,"P",{});var fa=o(Z);Cl=l(fa,"Non tutti gli esempi di script supportano l\u2019argomento "),zr=i(fa,"CODE",{});var Pu=o(zr);Sl=l(Pu,"max_predict_samples"),Pu.forEach(a),Dl=l(fa,". Se non sei sicuro circa il supporto di questo argomento da parte del tuo script, aggiungi l\u2019argomento "),br=i(fa,"CODE",{});var xu=o(br);Nl=l(xu,"-h"),xu.forEach(a),Ol=l(fa," per controllare:"),fa.forEach(a),bi=m(e),w(ct.$$.fragment,e),wi=m(e),ue=i(e,"H2",{class:!0});var Zi=o(ue);Te=i(Zi,"A",{id:!0,class:!0,href:!0});var Au=o(Te);wr=i(Au,"SPAN",{});var ku=o(wr);w(mt.$$.fragment,ku),ku.forEach(a),Au.forEach(a),jl=m(Zi),yr=i(Zi,"SPAN",{});var Tu=o(yr);Ml=l(Tu,"Riavviare addestramento da un checkpoint"),Tu.forEach(a),Zi.forEach(a),yi=m(e),sa=i(e,"P",{});var Iu=o(sa);Fl=l(Iu,"Un\u2019altra utile opzione \xE8 riavviare un addestramento da un checkpoint precedente. Questo garantir\xE0 che tu possa riprendere da dove hai interrotto senza ricominciare se l\u2019addestramento viene interrotto. Ci sono due metodi per riavviare l\u2019addestramento da un checkpoint:"),Iu.forEach(a),Pi=m(e),B=i(e,"P",{});var Se=o(B);Hl=l(Se,"Il primo metodo usa l\u2019argomento "),Pr=i(Se,"CODE",{});var qu=o(Pr);Ql=l(qu,"output_dir previous_output_dir"),qu.forEach(a),Gl=l(Se," per riavviare l\u2019addestramento dall\u2019ultima versione del checkpoint contenuto in "),xr=i(Se,"CODE",{});var Lu=o(xr);Rl=l(Lu,"output_dir"),Lu.forEach(a),Jl=l(Se,". In questo caso, dovresti rimuovere "),Ar=i(Se,"CODE",{});var Uu=o(Ar);Xl=l(Uu,"overwrite_output_dir"),Uu.forEach(a),Bl=l(Se,":"),Se.forEach(a),xi=m(e),w(ft.$$.fragment,e),Ai=m(e),Ie=i(e,"P",{});var eo=o(Ie);Kl=l(eo,"Il secondo metodo usa l\u2019argomento "),kr=i(eo,"CODE",{});var Cu=o(kr);Vl=l(Cu,"resume_from_checkpoint path_to_specific_checkpoint"),Cu.forEach(a),Yl=l(eo," per riavviare un addestramento da una specifica cartella di checkpoint."),eo.forEach(a),ki=m(e),w(dt.$$.fragment,e),Ti=m(e),ce=i(e,"H2",{class:!0});var to=o(ce);qe=i(to,"A",{id:!0,class:!0,href:!0});var Su=o(qe);Tr=i(Su,"SPAN",{});var Du=o(Tr);w(_t.$$.fragment,Du),Du.forEach(a),Su.forEach(a),Wl=m(to),Ir=i(to,"SPAN",{});var Nu=o(Ir);Zl=l(Nu,"Condividi il tuo modello"),Nu.forEach(a),to.forEach(a),Ii=m(e),Le=i(e,"P",{});var ao=o(Le);en=l(ao,"Tutti gli script possono caricare il tuo modello finale al "),ht=i(ao,"A",{href:!0,rel:!0});var Ou=o(ht);tn=l(Ou,"Model Hub"),Ou.forEach(a),an=l(ao,". Prima di iniziare, assicurati di aver effettuato l\u2019accesso su Hugging Face:"),ao.forEach(a),qi=m(e),w(vt.$$.fragment,e),Li=m(e),ee=i(e,"P",{});var da=o(ee);rn=l(da,"Poi, aggiungi l\u2019argomento "),qr=i(da,"CODE",{});var ju=o(qr);on=l(ju,"push_to_hub"),ju.forEach(a),sn=l(da," allo script. Questo argomento consentir\xE0 di creare un repository con il tuo username Hugging Face e la cartella specificata in "),Lr=i(da,"CODE",{});var Mu=o(Lr);ln=l(Mu,"output_dir"),Mu.forEach(a),nn=l(da,"."),da.forEach(a),Ui=m(e),Ue=i(e,"P",{});var ro=o(Ue);pn=l(ro,"Per dare uno specifico nome al repository, usa l\u2019argomento "),Ur=i(ro,"CODE",{});var Fu=o(Ur);un=l(Fu,"push_to_hub_model_id"),Fu.forEach(a),cn=l(ro,". Il repository verr\xE0 automaticamente elencata sotto al tuo namespace."),ro.forEach(a),Ci=m(e),la=i(e,"P",{});var Hu=o(la);mn=l(Hu,"Il seguente esempio mostra come caricare un modello specificando il nome del repository:"),Hu.forEach(a),Si=m(e),w(gt.$$.fragment,e),this.h()},h(){p(f,"name","hf:doc:metadata"),p(f,"content",JSON.stringify(ic)),p(v,"id","addestramento-con-script"),p(v,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(v,"href","#addestramento-con-script"),p(d,"class","relative group"),p(T,"href","./noteboks/README"),p(q,"href","https://github.com/huggingface/transformers/tree/main/examples/pytorch"),p(q,"rel","nofollow"),p(g,"href","https://github.com/huggingface/transformers/tree/main/examples/tensorflow"),p(g,"rel","nofollow"),p(L,"href","https://github.com/huggingface/transformers/tree/main/examples/flax"),p(L,"rel","nofollow"),p(Ne,"href","https://github.com/huggingface/transformers/tree/main/examples/research_projects"),p(Ne,"rel","nofollow"),p(Oe,"href","https://github.com/huggingface/transformers/tree/main/examples/legacy"),p(Oe,"rel","nofollow"),p(je,"href","https://discuss.huggingface.co/"),p(je,"rel","nofollow"),p(Me,"href","https://github.com/huggingface/transformers/issues"),p(Me,"rel","nofollow"),p(Fe,"href","https://github.com/huggingface/transformers/tree/main/examples/pytorch/summarization"),p(Fe,"rel","nofollow"),p(He,"href","https://github.com/huggingface/transformers/tree/main/examples/tensorflow/summarization"),p(He,"rel","nofollow"),p(me,"id","installazione"),p(me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(me,"href","#installazione"),p(re,"class","relative group"),p(yt,"href","https://github.com/huggingface/transformers/tree/v4.5.1/examples"),p(Pt,"href","https://github.com/huggingface/transformers/tree/v4.4.2/examples"),p(xt,"href","https://github.com/huggingface/transformers/tree/v4.3.3/examples"),p(At,"href","https://github.com/huggingface/transformers/tree/v4.2.2/examples"),p(kt,"href","https://github.com/huggingface/transformers/tree/v4.1.1/examples"),p(Tt,"href","https://github.com/huggingface/transformers/tree/v4.0.1/examples"),p(It,"href","https://github.com/huggingface/transformers/tree/v3.5.1/examples"),p(qt,"href","https://github.com/huggingface/transformers/tree/v3.4.0/examples"),p(Lt,"href","https://github.com/huggingface/transformers/tree/v3.3.1/examples"),p(Ut,"href","https://github.com/huggingface/transformers/tree/v3.2.0/examples"),p(Ct,"href","https://github.com/huggingface/transformers/tree/v3.1.0/examples"),p(St,"href","https://github.com/huggingface/transformers/tree/v3.0.2/examples"),p(Dt,"href","https://github.com/huggingface/transformers/tree/v2.11.0/examples"),p(Nt,"href","https://github.com/huggingface/transformers/tree/v2.10.0/examples"),p(Ot,"href","https://github.com/huggingface/transformers/tree/v2.9.1/examples"),p(jt,"href","https://github.com/huggingface/transformers/tree/v2.8.0/examples"),p(Mt,"href","https://github.com/huggingface/transformers/tree/v2.7.0/examples"),p(Ft,"href","https://github.com/huggingface/transformers/tree/v2.6.0/examples"),p(Ht,"href","https://github.com/huggingface/transformers/tree/v2.5.1/examples"),p(Qt,"href","https://github.com/huggingface/transformers/tree/v2.4.0/examples"),p(Gt,"href","https://github.com/huggingface/transformers/tree/v2.3.0/examples"),p(Rt,"href","https://github.com/huggingface/transformers/tree/v2.2.0/examples"),p(Jt,"href","https://github.com/huggingface/transformers/tree/v2.1.0/examples"),p(Xt,"href","https://github.com/huggingface/transformers/tree/v2.0.0/examples"),p(Bt,"href","https://github.com/huggingface/transformers/tree/v1.2.0/examples"),p(Kt,"href","https://github.com/huggingface/transformers/tree/v1.1.0/examples"),p(Vt,"href","https://github.com/huggingface/transformers/tree/v1.0.0/examples"),p(_e,"id","esegui-uno-script"),p(_e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(_e,"href","#esegui-uno-script"),p(ie,"class","relative group"),p(ve,"id","addestramento-distribuito-e-precisione-mista"),p(ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(ve,"href","#addestramento-distribuito-e-precisione-mista"),p(oe,"class","relative group"),p(Ke,"href","https://huggingface.co/docs/transformers/main_classes/trainer"),p(Ke,"rel","nofollow"),p(Ze,"href","https://www.tensorflow.org/guide/distributed_training#mirroredstrategy"),p(Ze,"rel","nofollow"),p(ze,"id","esegui-uno-script-su-tpu"),p(ze,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(ze,"href","#esegui-uno-script-su-tpu"),p(se,"class","relative group"),p(we,"id","esegui-uno-script-con-accelerate"),p(we,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(we,"href","#esegui-uno-script-con-accelerate"),p(le,"class","relative group"),p(at,"href","https://huggingface.co/docs/accelerate/index.html"),p(at,"rel","nofollow"),p(xe,"id","uso-di-un-dataset-personalizzato"),p(xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(xe,"href","#uso-di-un-dataset-personalizzato"),p(ne,"class","relative group"),p(ke,"id","testare-uno-script"),p(ke,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(ke,"href","#testare-uno-script"),p(pe,"class","relative group"),p(Te,"id","riavviare-addestramento-da-un-checkpoint"),p(Te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Te,"href","#riavviare-addestramento-da-un-checkpoint"),p(ue,"class","relative group"),p(qe,"id","condividi-il-tuo-modello"),p(qe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(qe,"href","#condividi-il-tuo-modello"),p(ce,"class","relative group"),p(ht,"href","https://huggingface.co/models"),p(ht,"rel","nofollow")},m(e,n){t(document.head,f),u(e,$,n),u(e,d,n),t(d,v),t(v,I),y(z,I,null),t(d,O),t(d,j),t(j,U),u(e,M,n),u(e,k,n),t(k,C),t(k,T),t(T,S),t(k,N),t(k,q),t(q,F),t(k,E),t(k,g),t(g,G),t(k,D),t(k,L),t(L,J),t(k,Et),u(e,De,n),u(e,R,n),t(R,zt),t(R,Ne),t(Ne,so),t(R,lo),t(R,Oe),t(Oe,no),t(R,po),u(e,Dr,n),u(e,bt,n),t(bt,uo),u(e,Nr,n),u(e,K,n),t(K,co),t(K,je),t(je,mo),t(K,fo),t(K,Me),t(Me,_o),t(K,ho),u(e,Or,n),u(e,V,n),t(V,vo),t(V,Fe),t(Fe,go),t(V,$o),t(V,He),t(He,Eo),t(V,zo),u(e,jr,n),u(e,re,n),t(re,me),t(me,_a),y(Qe,_a,null),t(re,bo),t(re,ha),t(ha,wo),u(e,Mr,n),u(e,fe,n),t(fe,yo),t(fe,va),t(va,Po),t(fe,xo),u(e,Fr,n),y(Ge,e,n),u(e,Hr,n),u(e,wt,n),t(wt,Ao),u(e,Qr,n),u(e,de,n),t(de,ga),t(ga,ko),t(de,To),t(de,_),t(_,$a),t($a,yt),t(yt,Io),t(_,qo),t(_,Ea),t(Ea,Pt),t(Pt,Lo),t(_,Uo),t(_,za),t(za,xt),t(xt,Co),t(_,So),t(_,ba),t(ba,At),t(At,Do),t(_,No),t(_,wa),t(wa,kt),t(kt,Oo),t(_,jo),t(_,ya),t(ya,Tt),t(Tt,Mo),t(_,Fo),t(_,Pa),t(Pa,It),t(It,Ho),t(_,Qo),t(_,xa),t(xa,qt),t(qt,Go),t(_,Ro),t(_,Aa),t(Aa,Lt),t(Lt,Jo),t(_,Xo),t(_,ka),t(ka,Ut),t(Ut,Bo),t(_,Ko),t(_,Ta),t(Ta,Ct),t(Ct,Vo),t(_,Yo),t(_,Ia),t(Ia,St),t(St,Wo),t(_,Zo),t(_,qa),t(qa,Dt),t(Dt,es),t(_,ts),t(_,La),t(La,Nt),t(Nt,as),t(_,rs),t(_,Ua),t(Ua,Ot),t(Ot,is),t(_,os),t(_,Ca),t(Ca,jt),t(jt,ss),t(_,ls),t(_,Sa),t(Sa,Mt),t(Mt,ns),t(_,ps),t(_,Da),t(Da,Ft),t(Ft,us),t(_,cs),t(_,Na),t(Na,Ht),t(Ht,ms),t(_,fs),t(_,Oa),t(Oa,Qt),t(Qt,ds),t(_,_s),t(_,ja),t(ja,Gt),t(Gt,hs),t(_,vs),t(_,Ma),t(Ma,Rt),t(Rt,gs),t(_,$s),t(_,Fa),t(Fa,Jt),t(Jt,Es),t(_,zs),t(_,Ha),t(Ha,Xt),t(Xt,bs),t(_,ws),t(_,Qa),t(Qa,Bt),t(Bt,ys),t(_,Ps),t(_,Ga),t(Ga,Kt),t(Kt,xs),t(_,As),t(_,Ra),t(Ra,Vt),t(Vt,ks),u(e,Gr,n),u(e,Yt,n),t(Yt,Ts),u(e,Rr,n),y(Re,e,n),u(e,Jr,n),u(e,Wt,n),t(Wt,Is),u(e,Xr,n),y(Je,e,n),u(e,Br,n),u(e,ie,n),t(ie,_e),t(_e,Ja),y(Xe,Ja,null),t(ie,qs),t(ie,Xa),t(Xa,Ls),u(e,Kr,n),y(he,e,n),u(e,Vr,n),u(e,oe,n),t(oe,ve),t(ve,Ba),y(Be,Ba,null),t(oe,Us),t(oe,Ka),t(Ka,Cs),u(e,Yr,n),u(e,ge,n),t(ge,Ss),t(ge,Ke),t(Ke,Ds),t(ge,Ns),u(e,Wr,n),u(e,$e,n),t($e,Ve),t(Ve,Os),t(Ve,Va),t(Va,js),t(Ve,Ms),t($e,Fs),t($e,Ye),t(Ye,Hs),t(Ye,Ya),t(Ya,Qs),t(Ye,Gs),u(e,Zr,n),y(We,e,n),u(e,ei,n),u(e,Ee,n),t(Ee,Rs),t(Ee,Ze),t(Ze,Wa),t(Wa,Js),t(Ee,Xs),u(e,ti,n),u(e,se,n),t(se,ze),t(ze,Za),y(et,Za,null),t(se,Bs),t(se,er),t(er,Ks),u(e,ai,n),y(be,e,n),u(e,ri,n),u(e,le,n),t(le,we),t(we,tr),y(tt,tr,null),t(le,Vs),t(le,ar),t(ar,Ys),u(e,ii,n),u(e,ye,n),t(ye,Ws),t(ye,at),t(at,Zs),t(ye,el),u(e,oi,n),u(e,Pe,n),t(Pe,rr),t(rr,tl),t(Pe,al),y(rt,Pe,null),u(e,si,n),u(e,X,n),t(X,rl),t(X,ir),t(ir,il),t(X,ol),t(X,or),t(or,sl),t(X,ll),t(X,sr),t(sr,nl),t(X,pl),u(e,li,n),y(it,e,n),u(e,ni,n),u(e,Zt,n),t(Zt,ul),u(e,pi,n),y(ot,e,n),u(e,ui,n),u(e,ea,n),t(ea,cl),u(e,ci,n),y(st,e,n),u(e,mi,n),u(e,ne,n),t(ne,xe),t(xe,lr),y(lt,lr,null),t(ne,ml),t(ne,nr),t(nr,fl),u(e,fi,n),u(e,ta,n),t(ta,dl),u(e,di,n),u(e,Y,n),t(Y,Ae),t(Ae,pr),t(pr,_l),t(Ae,hl),t(Ae,ur),t(ur,vl),t(Ae,gl),t(Y,$l),t(Y,aa),t(aa,cr),t(cr,El),t(aa,zl),t(Y,bl),t(Y,ra),t(ra,mr),t(mr,wl),t(ra,yl),u(e,_i,n),u(e,ia,n),t(ia,Pl),u(e,hi,n),y(nt,e,n),u(e,vi,n),u(e,pe,n),t(pe,ke),t(ke,fr),y(pt,fr,null),t(pe,xl),t(pe,dr),t(dr,Al),u(e,gi,n),u(e,oa,n),t(oa,kl),u(e,$i,n),u(e,W,n),t(W,_r),t(_r,hr),t(hr,Tl),t(W,Il),t(W,vr),t(vr,gr),t(gr,ql),t(W,Ll),t(W,$r),t($r,Er),t(Er,Ul),u(e,Ei,n),y(ut,e,n),u(e,zi,n),u(e,Z,n),t(Z,Cl),t(Z,zr),t(zr,Sl),t(Z,Dl),t(Z,br),t(br,Nl),t(Z,Ol),u(e,bi,n),y(ct,e,n),u(e,wi,n),u(e,ue,n),t(ue,Te),t(Te,wr),y(mt,wr,null),t(ue,jl),t(ue,yr),t(yr,Ml),u(e,yi,n),u(e,sa,n),t(sa,Fl),u(e,Pi,n),u(e,B,n),t(B,Hl),t(B,Pr),t(Pr,Ql),t(B,Gl),t(B,xr),t(xr,Rl),t(B,Jl),t(B,Ar),t(Ar,Xl),t(B,Bl),u(e,xi,n),y(ft,e,n),u(e,Ai,n),u(e,Ie,n),t(Ie,Kl),t(Ie,kr),t(kr,Vl),t(Ie,Yl),u(e,ki,n),y(dt,e,n),u(e,Ti,n),u(e,ce,n),t(ce,qe),t(qe,Tr),y(_t,Tr,null),t(ce,Wl),t(ce,Ir),t(Ir,Zl),u(e,Ii,n),u(e,Le,n),t(Le,en),t(Le,ht),t(ht,tn),t(Le,an),u(e,qi,n),y(vt,e,n),u(e,Li,n),u(e,ee,n),t(ee,rn),t(ee,qr),t(qr,on),t(ee,sn),t(ee,Lr),t(Lr,ln),t(ee,nn),u(e,Ui,n),u(e,Ue,n),t(Ue,pn),t(Ue,Ur),t(Ur,un),t(Ue,cn),u(e,Ci,n),u(e,la,n),t(la,mn),u(e,Si,n),y(gt,e,n),Di=!0},p(e,[n]){const $t={};n&2&&($t.$$scope={dirty:n,ctx:e}),he.$set($t);const Cr={};n&2&&(Cr.$$scope={dirty:n,ctx:e}),be.$set(Cr)},i(e){Di||(P(z.$$.fragment,e),P(Qe.$$.fragment,e),P(Ge.$$.fragment,e),P(Re.$$.fragment,e),P(Je.$$.fragment,e),P(Xe.$$.fragment,e),P(he.$$.fragment,e),P(Be.$$.fragment,e),P(We.$$.fragment,e),P(et.$$.fragment,e),P(be.$$.fragment,e),P(tt.$$.fragment,e),P(rt.$$.fragment,e),P(it.$$.fragment,e),P(ot.$$.fragment,e),P(st.$$.fragment,e),P(lt.$$.fragment,e),P(nt.$$.fragment,e),P(pt.$$.fragment,e),P(ut.$$.fragment,e),P(ct.$$.fragment,e),P(mt.$$.fragment,e),P(ft.$$.fragment,e),P(dt.$$.fragment,e),P(_t.$$.fragment,e),P(vt.$$.fragment,e),P(gt.$$.fragment,e),Di=!0)},o(e){x(z.$$.fragment,e),x(Qe.$$.fragment,e),x(Ge.$$.fragment,e),x(Re.$$.fragment,e),x(Je.$$.fragment,e),x(Xe.$$.fragment,e),x(he.$$.fragment,e),x(Be.$$.fragment,e),x(We.$$.fragment,e),x(et.$$.fragment,e),x(be.$$.fragment,e),x(tt.$$.fragment,e),x(rt.$$.fragment,e),x(it.$$.fragment,e),x(ot.$$.fragment,e),x(st.$$.fragment,e),x(lt.$$.fragment,e),x(nt.$$.fragment,e),x(pt.$$.fragment,e),x(ut.$$.fragment,e),x(ct.$$.fragment,e),x(mt.$$.fragment,e),x(ft.$$.fragment,e),x(dt.$$.fragment,e),x(_t.$$.fragment,e),x(vt.$$.fragment,e),x(gt.$$.fragment,e),Di=!1},d(e){a(f),e&&a($),e&&a(d),A(z),e&&a(M),e&&a(k),e&&a(De),e&&a(R),e&&a(Dr),e&&a(bt),e&&a(Nr),e&&a(K),e&&a(Or),e&&a(V),e&&a(jr),e&&a(re),A(Qe),e&&a(Mr),e&&a(fe),e&&a(Fr),A(Ge,e),e&&a(Hr),e&&a(wt),e&&a(Qr),e&&a(de),e&&a(Gr),e&&a(Yt),e&&a(Rr),A(Re,e),e&&a(Jr),e&&a(Wt),e&&a(Xr),A(Je,e),e&&a(Br),e&&a(ie),A(Xe),e&&a(Kr),A(he,e),e&&a(Vr),e&&a(oe),A(Be),e&&a(Yr),e&&a(ge),e&&a(Wr),e&&a($e),e&&a(Zr),A(We,e),e&&a(ei),e&&a(Ee),e&&a(ti),e&&a(se),A(et),e&&a(ai),A(be,e),e&&a(ri),e&&a(le),A(tt),e&&a(ii),e&&a(ye),e&&a(oi),e&&a(Pe),A(rt),e&&a(si),e&&a(X),e&&a(li),A(it,e),e&&a(ni),e&&a(Zt),e&&a(pi),A(ot,e),e&&a(ui),e&&a(ea),e&&a(ci),A(st,e),e&&a(mi),e&&a(ne),A(lt),e&&a(fi),e&&a(ta),e&&a(di),e&&a(Y),e&&a(_i),e&&a(ia),e&&a(hi),A(nt,e),e&&a(vi),e&&a(pe),A(pt),e&&a(gi),e&&a(oa),e&&a($i),e&&a(W),e&&a(Ei),A(ut,e),e&&a(zi),e&&a(Z),e&&a(bi),A(ct,e),e&&a(wi),e&&a(ue),A(mt),e&&a(yi),e&&a(sa),e&&a(Pi),e&&a(B),e&&a(xi),A(ft,e),e&&a(Ai),e&&a(Ie),e&&a(ki),A(dt,e),e&&a(Ti),e&&a(ce),A(_t),e&&a(Ii),e&&a(Le),e&&a(qi),A(vt,e),e&&a(Li),e&&a(ee),e&&a(Ui),e&&a(Ue),e&&a(Ci),e&&a(la),e&&a(Si),A(gt,e)}}}const ic={local:"addestramento-con-script",sections:[{local:"installazione",title:"Installazione"},{local:"esegui-uno-script",title:"Esegui uno script"},{local:"addestramento-distribuito-e-precisione-mista",title:"Addestramento distribuito e precisione mista"},{local:"esegui-uno-script-su-tpu",title:"Esegui uno script su TPU"},{local:"esegui-uno-script-con-accelerate",title:"Esegui uno script con \u{1F917} Accelerate"},{local:"uso-di-un-dataset-personalizzato",title:"Uso di un dataset personalizzato"},{local:"testare-uno-script",title:"Testare uno script"},{local:"riavviare-addestramento-da-un-checkpoint",title:"Riavviare addestramento da un checkpoint"},{local:"condividi-il-tuo-modello",title:"Condividi il tuo modello"}],title:"Addestramento con script"};function oc(Q){return Bu(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class cc extends Gu{constructor(f){super();Ru(this,f,oc,rc,Ju,{})}}export{cc as default,ic as metadata};
