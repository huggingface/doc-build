import{S as sa,i as aa,s as la,e as o,k as c,w,t as a,M as ia,c as n,d as s,m as f,a as p,x as _,h as l,b as h,G as t,g as r,y as v,L as oa,q as y,o as b,B as k,v as na}from"../chunks/vendor-hf-doc-builder.js";import{I as ks}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as D}from"../chunks/CodeBlock-hf-doc-builder.js";function pa($s){let q,Oe,S,O,pe,F,ft,z,ht,re,dt,ut,Ie,d,mt,ce,wt,_t,fe,vt,yt,he,bt,kt,B,$t,xt,W,jt,Et,Le,C,I,de,H,gt,ue,Pt,Ne,L,qt,U,St,Ct,Ae,V,Me,N,Tt,me,Dt,Ot,Fe,Y,ze,u,It,we,Lt,Nt,_e,At,Mt,ve,Ft,zt,ye,Bt,Wt,Be,G,We,$,Ht,be,Ut,Vt,ke,Yt,Gt,He,J,Ue,x,Jt,$e,Rt,Kt,xe,Qt,Xt,Ve,T,A,je,R,Zt,Ee,es,Ye,j,ts,ge,ss,as,Pe,ls,is,Ge,K,Je,E,os,qe,ns,ps,Se,rs,cs,Re,Q,Ke,g,fs,Ce,hs,ds,Te,us,ms,Qe,X,Xe,te,ws,Ze,Z,et,M,_s,De,vs,ys,tt,ee,st,se,bs,at;return F=new ks({}),H=new ks({}),V=new D({props:{code:`from datasets import load_dataset

ds = load_dataset("imdb")`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

ds = load_dataset(<span class="hljs-string">&quot;imdb&quot;</span>)`}}),Y=new D({props:{code:`from sklearn.pipeline import Pipeline
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction.text import CountVectorizer

text_clf = Pipeline([
        ('vect', CountVectorizer()),
        ('tfidf', TfidfTransformer()),
        ('clf', MultinomialNB()),
])

text_clf.fit(ds["train"]["text"], ds["train"]["label"])`,highlighted:`<span class="hljs-keyword">from</span> sklearn.pipeline <span class="hljs-keyword">import</span> Pipeline
<span class="hljs-keyword">from</span> sklearn.naive_bayes <span class="hljs-keyword">import</span> MultinomialNB
<span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> TfidfTransformer
<span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> CountVectorizer

text_clf = Pipeline([
        (<span class="hljs-string">&#x27;vect&#x27;</span>, CountVectorizer()),
        (<span class="hljs-string">&#x27;tfidf&#x27;</span>, TfidfTransformer()),
        (<span class="hljs-string">&#x27;clf&#x27;</span>, MultinomialNB()),
])

text_clf.fit(ds[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-string">&quot;text&quot;</span>], ds[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-string">&quot;label&quot;</span>])`}}),G=new D({props:{code:`class ScikitEvalPipeline:
    def __init__(self, pipeline):
        self.pipeline = pipeline
        self.task = "text-classification"

    def __call__(self, input_texts, **kwargs):
        return [{"label": p} for p in self.pipeline.predict(input_texts)]

pipe = ScikitEvalPipeline(text_clf)`,highlighted:`<span class="hljs-keyword">class</span> <span class="hljs-title class_">ScikitEvalPipeline</span>:
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, pipeline</span>):
        self.pipeline = pipeline
        self.task = <span class="hljs-string">&quot;text-classification&quot;</span>

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, input_texts, **kwargs</span>):
        <span class="hljs-keyword">return</span> [{<span class="hljs-string">&quot;label&quot;</span>: p} <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.pipeline.predict(input_texts)]

pipe = ScikitEvalPipeline(text_clf)`}}),J=new D({props:{code:`

{'accuracy': 0.82956}`,highlighted:`<span class="hljs-keyword">from</span> evaluate <span class="hljs-keyword">import</span> evaluator

<span class="hljs-built_in">eval</span> = evaluator(<span class="hljs-string">&quot;text-classification&quot;</span>)
<span class="hljs-built_in">eval</span>.compute(pipe, ds[<span class="hljs-string">&quot;test&quot;</span>], <span class="hljs-string">&quot;accuracy&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>{<span class="hljs-string">&#x27;accuracy&#x27;</span>: <span class="hljs-number">0.82956</span>}`}}),R=new ks({}),K=new D({props:{code:`pip install spacytextblob
python -m textblob.download_corpora
python -m spacy download en_core_web_sm`,highlighted:`pip install spacytextblob
python -m textblob.download_corpora
python -m spacy download en_core_web_sm`}}),Q=new D({props:{code:`import spacy

nlp = spacy.load('en_core_web_sm')
nlp.add_pipe('spacytextblob')`,highlighted:`<span class="hljs-keyword">import</span> spacy

nlp = spacy.load(<span class="hljs-string">&#x27;en_core_web_sm&#x27;</span>)
nlp.add_pipe(<span class="hljs-string">&#x27;spacytextblob&#x27;</span>)`}}),X=new D({props:{code:`texts = ["This movie is horrible", "This movie is awesome"]
results = nlp.pipe(texts)

for txt, res in zip(texts, results):
    print(f"{text} | Polarity: {res._.blob.polarity}")`,highlighted:`texts = [<span class="hljs-string">&quot;This movie is horrible&quot;</span>, <span class="hljs-string">&quot;This movie is awesome&quot;</span>]
results = nlp.pipe(texts)

<span class="hljs-keyword">for</span> txt, res <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(texts, results):
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">{text}</span> | Polarity: <span class="hljs-subst">{res._.blob.polarity}</span>&quot;</span>)`}}),Z=new D({props:{code:`class SpacyEvalPipeline:
    def __init__(self, nlp):
        self.nlp = nlp
        self.task = "text-classification"

    def __call__(self, input_texts, **kwargs):
        results =[]
        for p in self.nlp.pipe(input_texts):
            if p._.blob.polarity>=0:
                results.append({"label": 1})
            else:
                results.append({"label": 0})
        return results

pipe = SpacyEvalPipeline(nlp)`,highlighted:`<span class="hljs-keyword">class</span> <span class="hljs-title class_">SpacyEvalPipeline</span>:
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, nlp</span>):
        self.nlp = nlp
        self.task = <span class="hljs-string">&quot;text-classification&quot;</span>

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, input_texts, **kwargs</span>):
        results =[]
        <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.nlp.pipe(input_texts):
            <span class="hljs-keyword">if</span> p._.blob.polarity&gt;=<span class="hljs-number">0</span>:
                results.append({<span class="hljs-string">&quot;label&quot;</span>: <span class="hljs-number">1</span>})
            <span class="hljs-keyword">else</span>:
                results.append({<span class="hljs-string">&quot;label&quot;</span>: <span class="hljs-number">0</span>})
        <span class="hljs-keyword">return</span> results

pipe = SpacyEvalPipeline(nlp)`}}),ee=new D({props:{code:"{'accuracy': 0.6914}",highlighted:`<span class="hljs-built_in">eval</span>.compute(pipe, ds[<span class="hljs-string">&quot;test&quot;</span>], <span class="hljs-string">&quot;accuracy&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>{<span class="hljs-string">&#x27;accuracy&#x27;</span>: <span class="hljs-number">0.6914</span>}`}}),{c(){q=o("meta"),Oe=c(),S=o("h1"),O=o("a"),pe=o("span"),w(F.$$.fragment),ft=c(),z=o("span"),ht=a("Using the "),re=o("code"),dt=a("evaluator"),ut=a(" with custom models"),Ie=c(),d=o("p"),mt=a("The evaluator is designed to work with "),ce=o("code"),wt=a("transformer"),_t=a(" pipelines out-of-the-box. However, in many cases you might have a model or pipeline that\u2019s not part of the "),fe=o("code"),vt=a("transformer"),yt=a(" ecosystem. You can still use "),he=o("code"),bt=a("evaluator"),kt=a(" to easily compute metrics them. In this guide we show how to do this for a Scikit-Learn "),B=o("a"),$t=a("pipeline"),xt=a(" and a Spacy "),W=o("a"),jt=a("pipeline"),Et=a(". Let\u2019s start with the Scikit-Learn case."),Le=c(),C=o("h2"),I=o("a"),de=o("span"),w(H.$$.fragment),gt=c(),ue=o("span"),Pt=a("Scikit-Learn"),Ne=c(),L=o("p"),qt=a("First we need to train a model. We\u2019ll train a simple text classifier on the "),U=o("a"),St=a("IMDb dataset"),Ct=a(", so let\u2019s start by downloading the dataset:"),Ae=c(),w(V.$$.fragment),Me=c(),N=o("p"),Tt=a("Then we can build a simple TF-IDF preprocessor and Naive Bayes classifier wrapped in a "),me=o("code"),Dt=a("Pipeline"),Ot=a(":"),Fe=c(),w(Y.$$.fragment),ze=c(),u=o("p"),It=a("Following the convention in the "),we=o("code"),Lt=a("TextClassificationPipeline"),Nt=a(" of "),_e=o("code"),At=a("transformers"),Mt=a(" our pipeline should be callable and return a list of dictionaries. In addition we use the "),ve=o("code"),Ft=a("task"),zt=a(" attribute to check if the pipeline is compatible with the "),ye=o("code"),Bt=a("evaluator"),Wt=a(". We can write a small wrapper class for that purpose:"),Be=c(),w(G.$$.fragment),We=c(),$=o("p"),Ht=a("We can now pass this "),be=o("code"),Ut=a("pipeline"),Vt=a(" to the "),ke=o("code"),Yt=a("evaluator"),Gt=a(":"),He=c(),w(J.$$.fragment),Ue=c(),x=o("p"),Jt=a("Implementing that simple wrapper is all that\u2019s needed to use any model from any framework with the "),$e=o("code"),Rt=a("evaluator"),Kt=a(". In the "),xe=o("code"),Qt=a("__call__"),Xt=a(" you can implement all logic necessary for efficient forward passes through your model."),Ve=c(),T=o("h2"),A=o("a"),je=o("span"),w(R.$$.fragment),Zt=c(),Ee=o("span"),es=a("Spacy"),Ye=c(),j=o("p"),ts=a("We\u2019ll use the "),ge=o("code"),ss=a("polarity"),as=a(" feature of the "),Pe=o("code"),ls=a("spacytextblob"),is=a(" project to get a simple sentiment analyzer. First you\u2019ll need to install the project and download the resources:"),Ge=c(),w(K.$$.fragment),Je=c(),E=o("p"),os=a("Then we can simply load the "),qe=o("code"),ns=a("nlp"),ps=a(" pipeline and add the "),Se=o("code"),rs=a("spacytextblob"),cs=a(" pipeline:"),Re=c(),w(Q.$$.fragment),Ke=c(),g=o("p"),fs=a("This snippet shows how we can use the "),Ce=o("code"),hs=a("polarity"),ds=a(" feature added with "),Te=o("code"),us=a("spacytextblob"),ms=a(" to get the sentiment of a text:"),Qe=c(),w(X.$$.fragment),Xe=c(),te=o("p"),ws=a("Now we can wrap it in a simple wrapper class like in the Scikit-Learn example before. It just has to return a list of dictionaries with the predicted lables. If the polarity is larger than 0 we\u2019ll predict positive sentiment and negative otherwise:"),Ze=c(),w(Z.$$.fragment),et=c(),M=o("p"),_s=a("That class is compatible with the "),De=o("code"),vs=a("evaluator"),ys=a(" and we can use the same instance from the previous examlpe along with the IMDb test set:"),tt=c(),w(ee.$$.fragment),st=c(),se=o("p"),bs=a("This will take a little longer than the Scikit-Learn example but after roughly 10-15min you will have the evaluation results!"),this.h()},l(e){const i=ia('[data-svelte="svelte-1phssyn"]',document.head);q=n(i,"META",{name:!0,content:!0}),i.forEach(s),Oe=f(e),S=n(e,"H1",{class:!0});var lt=p(S);O=n(lt,"A",{id:!0,class:!0,href:!0});var xs=p(O);pe=n(xs,"SPAN",{});var js=p(pe);_(F.$$.fragment,js),js.forEach(s),xs.forEach(s),ft=f(lt),z=n(lt,"SPAN",{});var it=p(z);ht=l(it,"Using the "),re=n(it,"CODE",{});var Es=p(re);dt=l(Es,"evaluator"),Es.forEach(s),ut=l(it," with custom models"),it.forEach(s),lt.forEach(s),Ie=f(e),d=n(e,"P",{});var m=p(d);mt=l(m,"The evaluator is designed to work with "),ce=n(m,"CODE",{});var gs=p(ce);wt=l(gs,"transformer"),gs.forEach(s),_t=l(m," pipelines out-of-the-box. However, in many cases you might have a model or pipeline that\u2019s not part of the "),fe=n(m,"CODE",{});var Ps=p(fe);vt=l(Ps,"transformer"),Ps.forEach(s),yt=l(m," ecosystem. You can still use "),he=n(m,"CODE",{});var qs=p(he);bt=l(qs,"evaluator"),qs.forEach(s),kt=l(m," to easily compute metrics them. In this guide we show how to do this for a Scikit-Learn "),B=n(m,"A",{href:!0,rel:!0});var Ss=p(B);$t=l(Ss,"pipeline"),Ss.forEach(s),xt=l(m," and a Spacy "),W=n(m,"A",{href:!0,rel:!0});var Cs=p(W);jt=l(Cs,"pipeline"),Cs.forEach(s),Et=l(m,". Let\u2019s start with the Scikit-Learn case."),m.forEach(s),Le=f(e),C=n(e,"H2",{class:!0});var ot=p(C);I=n(ot,"A",{id:!0,class:!0,href:!0});var Ts=p(I);de=n(Ts,"SPAN",{});var Ds=p(de);_(H.$$.fragment,Ds),Ds.forEach(s),Ts.forEach(s),gt=f(ot),ue=n(ot,"SPAN",{});var Os=p(ue);Pt=l(Os,"Scikit-Learn"),Os.forEach(s),ot.forEach(s),Ne=f(e),L=n(e,"P",{});var nt=p(L);qt=l(nt,"First we need to train a model. We\u2019ll train a simple text classifier on the "),U=n(nt,"A",{href:!0,rel:!0});var Is=p(U);St=l(Is,"IMDb dataset"),Is.forEach(s),Ct=l(nt,", so let\u2019s start by downloading the dataset:"),nt.forEach(s),Ae=f(e),_(V.$$.fragment,e),Me=f(e),N=n(e,"P",{});var pt=p(N);Tt=l(pt,"Then we can build a simple TF-IDF preprocessor and Naive Bayes classifier wrapped in a "),me=n(pt,"CODE",{});var Ls=p(me);Dt=l(Ls,"Pipeline"),Ls.forEach(s),Ot=l(pt,":"),pt.forEach(s),Fe=f(e),_(Y.$$.fragment,e),ze=f(e),u=n(e,"P",{});var P=p(u);It=l(P,"Following the convention in the "),we=n(P,"CODE",{});var Ns=p(we);Lt=l(Ns,"TextClassificationPipeline"),Ns.forEach(s),Nt=l(P," of "),_e=n(P,"CODE",{});var As=p(_e);At=l(As,"transformers"),As.forEach(s),Mt=l(P," our pipeline should be callable and return a list of dictionaries. In addition we use the "),ve=n(P,"CODE",{});var Ms=p(ve);Ft=l(Ms,"task"),Ms.forEach(s),zt=l(P," attribute to check if the pipeline is compatible with the "),ye=n(P,"CODE",{});var Fs=p(ye);Bt=l(Fs,"evaluator"),Fs.forEach(s),Wt=l(P,". We can write a small wrapper class for that purpose:"),P.forEach(s),Be=f(e),_(G.$$.fragment,e),We=f(e),$=n(e,"P",{});var ae=p($);Ht=l(ae,"We can now pass this "),be=n(ae,"CODE",{});var zs=p(be);Ut=l(zs,"pipeline"),zs.forEach(s),Vt=l(ae," to the "),ke=n(ae,"CODE",{});var Bs=p(ke);Yt=l(Bs,"evaluator"),Bs.forEach(s),Gt=l(ae,":"),ae.forEach(s),He=f(e),_(J.$$.fragment,e),Ue=f(e),x=n(e,"P",{});var le=p(x);Jt=l(le,"Implementing that simple wrapper is all that\u2019s needed to use any model from any framework with the "),$e=n(le,"CODE",{});var Ws=p($e);Rt=l(Ws,"evaluator"),Ws.forEach(s),Kt=l(le,". In the "),xe=n(le,"CODE",{});var Hs=p(xe);Qt=l(Hs,"__call__"),Hs.forEach(s),Xt=l(le," you can implement all logic necessary for efficient forward passes through your model."),le.forEach(s),Ve=f(e),T=n(e,"H2",{class:!0});var rt=p(T);A=n(rt,"A",{id:!0,class:!0,href:!0});var Us=p(A);je=n(Us,"SPAN",{});var Vs=p(je);_(R.$$.fragment,Vs),Vs.forEach(s),Us.forEach(s),Zt=f(rt),Ee=n(rt,"SPAN",{});var Ys=p(Ee);es=l(Ys,"Spacy"),Ys.forEach(s),rt.forEach(s),Ye=f(e),j=n(e,"P",{});var ie=p(j);ts=l(ie,"We\u2019ll use the "),ge=n(ie,"CODE",{});var Gs=p(ge);ss=l(Gs,"polarity"),Gs.forEach(s),as=l(ie," feature of the "),Pe=n(ie,"CODE",{});var Js=p(Pe);ls=l(Js,"spacytextblob"),Js.forEach(s),is=l(ie," project to get a simple sentiment analyzer. First you\u2019ll need to install the project and download the resources:"),ie.forEach(s),Ge=f(e),_(K.$$.fragment,e),Je=f(e),E=n(e,"P",{});var oe=p(E);os=l(oe,"Then we can simply load the "),qe=n(oe,"CODE",{});var Rs=p(qe);ns=l(Rs,"nlp"),Rs.forEach(s),ps=l(oe," pipeline and add the "),Se=n(oe,"CODE",{});var Ks=p(Se);rs=l(Ks,"spacytextblob"),Ks.forEach(s),cs=l(oe," pipeline:"),oe.forEach(s),Re=f(e),_(Q.$$.fragment,e),Ke=f(e),g=n(e,"P",{});var ne=p(g);fs=l(ne,"This snippet shows how we can use the "),Ce=n(ne,"CODE",{});var Qs=p(Ce);hs=l(Qs,"polarity"),Qs.forEach(s),ds=l(ne," feature added with "),Te=n(ne,"CODE",{});var Xs=p(Te);us=l(Xs,"spacytextblob"),Xs.forEach(s),ms=l(ne," to get the sentiment of a text:"),ne.forEach(s),Qe=f(e),_(X.$$.fragment,e),Xe=f(e),te=n(e,"P",{});var Zs=p(te);ws=l(Zs,"Now we can wrap it in a simple wrapper class like in the Scikit-Learn example before. It just has to return a list of dictionaries with the predicted lables. If the polarity is larger than 0 we\u2019ll predict positive sentiment and negative otherwise:"),Zs.forEach(s),Ze=f(e),_(Z.$$.fragment,e),et=f(e),M=n(e,"P",{});var ct=p(M);_s=l(ct,"That class is compatible with the "),De=n(ct,"CODE",{});var ea=p(De);vs=l(ea,"evaluator"),ea.forEach(s),ys=l(ct," and we can use the same instance from the previous examlpe along with the IMDb test set:"),ct.forEach(s),tt=f(e),_(ee.$$.fragment,e),st=f(e),se=n(e,"P",{});var ta=p(se);bs=l(ta,"This will take a little longer than the Scikit-Learn example but after roughly 10-15min you will have the evaluation results!"),ta.forEach(s),this.h()},h(){h(q,"name","hf:doc:metadata"),h(q,"content",JSON.stringify(ra)),h(O,"id","using-the-evaluator-with-custom-models"),h(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(O,"href","#using-the-evaluator-with-custom-models"),h(S,"class","relative group"),h(B,"href","https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline"),h(B,"rel","nofollow"),h(W,"href","https://spacy.io"),h(W,"rel","nofollow"),h(I,"id","scikitlearn"),h(I,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(I,"href","#scikitlearn"),h(C,"class","relative group"),h(U,"href","https://huggingface.co/datasets/imdb"),h(U,"rel","nofollow"),h(A,"id","spacy"),h(A,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(A,"href","#spacy"),h(T,"class","relative group")},m(e,i){t(document.head,q),r(e,Oe,i),r(e,S,i),t(S,O),t(O,pe),v(F,pe,null),t(S,ft),t(S,z),t(z,ht),t(z,re),t(re,dt),t(z,ut),r(e,Ie,i),r(e,d,i),t(d,mt),t(d,ce),t(ce,wt),t(d,_t),t(d,fe),t(fe,vt),t(d,yt),t(d,he),t(he,bt),t(d,kt),t(d,B),t(B,$t),t(d,xt),t(d,W),t(W,jt),t(d,Et),r(e,Le,i),r(e,C,i),t(C,I),t(I,de),v(H,de,null),t(C,gt),t(C,ue),t(ue,Pt),r(e,Ne,i),r(e,L,i),t(L,qt),t(L,U),t(U,St),t(L,Ct),r(e,Ae,i),v(V,e,i),r(e,Me,i),r(e,N,i),t(N,Tt),t(N,me),t(me,Dt),t(N,Ot),r(e,Fe,i),v(Y,e,i),r(e,ze,i),r(e,u,i),t(u,It),t(u,we),t(we,Lt),t(u,Nt),t(u,_e),t(_e,At),t(u,Mt),t(u,ve),t(ve,Ft),t(u,zt),t(u,ye),t(ye,Bt),t(u,Wt),r(e,Be,i),v(G,e,i),r(e,We,i),r(e,$,i),t($,Ht),t($,be),t(be,Ut),t($,Vt),t($,ke),t(ke,Yt),t($,Gt),r(e,He,i),v(J,e,i),r(e,Ue,i),r(e,x,i),t(x,Jt),t(x,$e),t($e,Rt),t(x,Kt),t(x,xe),t(xe,Qt),t(x,Xt),r(e,Ve,i),r(e,T,i),t(T,A),t(A,je),v(R,je,null),t(T,Zt),t(T,Ee),t(Ee,es),r(e,Ye,i),r(e,j,i),t(j,ts),t(j,ge),t(ge,ss),t(j,as),t(j,Pe),t(Pe,ls),t(j,is),r(e,Ge,i),v(K,e,i),r(e,Je,i),r(e,E,i),t(E,os),t(E,qe),t(qe,ns),t(E,ps),t(E,Se),t(Se,rs),t(E,cs),r(e,Re,i),v(Q,e,i),r(e,Ke,i),r(e,g,i),t(g,fs),t(g,Ce),t(Ce,hs),t(g,ds),t(g,Te),t(Te,us),t(g,ms),r(e,Qe,i),v(X,e,i),r(e,Xe,i),r(e,te,i),t(te,ws),r(e,Ze,i),v(Z,e,i),r(e,et,i),r(e,M,i),t(M,_s),t(M,De),t(De,vs),t(M,ys),r(e,tt,i),v(ee,e,i),r(e,st,i),r(e,se,i),t(se,bs),at=!0},p:oa,i(e){at||(y(F.$$.fragment,e),y(H.$$.fragment,e),y(V.$$.fragment,e),y(Y.$$.fragment,e),y(G.$$.fragment,e),y(J.$$.fragment,e),y(R.$$.fragment,e),y(K.$$.fragment,e),y(Q.$$.fragment,e),y(X.$$.fragment,e),y(Z.$$.fragment,e),y(ee.$$.fragment,e),at=!0)},o(e){b(F.$$.fragment,e),b(H.$$.fragment,e),b(V.$$.fragment,e),b(Y.$$.fragment,e),b(G.$$.fragment,e),b(J.$$.fragment,e),b(R.$$.fragment,e),b(K.$$.fragment,e),b(Q.$$.fragment,e),b(X.$$.fragment,e),b(Z.$$.fragment,e),b(ee.$$.fragment,e),at=!1},d(e){s(q),e&&s(Oe),e&&s(S),k(F),e&&s(Ie),e&&s(d),e&&s(Le),e&&s(C),k(H),e&&s(Ne),e&&s(L),e&&s(Ae),k(V,e),e&&s(Me),e&&s(N),e&&s(Fe),k(Y,e),e&&s(ze),e&&s(u),e&&s(Be),k(G,e),e&&s(We),e&&s($),e&&s(He),k(J,e),e&&s(Ue),e&&s(x),e&&s(Ve),e&&s(T),k(R),e&&s(Ye),e&&s(j),e&&s(Ge),k(K,e),e&&s(Je),e&&s(E),e&&s(Re),k(Q,e),e&&s(Ke),e&&s(g),e&&s(Qe),k(X,e),e&&s(Xe),e&&s(te),e&&s(Ze),k(Z,e),e&&s(et),e&&s(M),e&&s(tt),k(ee,e),e&&s(st),e&&s(se)}}}const ra={local:"using-the-evaluator-with-custom-models",sections:[{local:"scikitlearn",title:"Scikit-Learn"},{local:"spacy",title:"Spacy"}],title:"Using the `evaluator` with custom models"};function ca($s){return na(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ua extends sa{constructor(q){super();aa(this,q,ca,pa,la,{})}}export{ua as default,ra as metadata};
