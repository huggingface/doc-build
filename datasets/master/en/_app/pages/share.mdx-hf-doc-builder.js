import{S as hl,i as pl,s as ul,e as o,k as h,w as d,t as n,M as dl,c as r,d as t,m as p,a as l,x as c,h as f,b as u,G as a,g as i,y as m,q as y,o as v,B as w,v as cl}from"../chunks/vendor-hf-doc-builder.js";import{T as ml}from"../chunks/Tip-hf-doc-builder.js";import{I as X}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as D}from"../chunks/CodeBlock-hf-doc-builder.js";function yl(Mt){let g,T;return{c(){g=o("p"),T=n("The distinction between a Hub dataset and a dataset from GitHub only comes from the legacy sharing workflow. It does not involve any ranking, decisioning, or opinion regarding the contents of the dataset itself.")},l(_){g=r(_,"P",{});var b=l(g);T=f(b,"The distinction between a Hub dataset and a dataset from GitHub only comes from the legacy sharing workflow. It does not involve any ranking, decisioning, or opinion regarding the contents of the dataset itself."),b.forEach(t)},m(_,b){i(_,g,b),a(g,T)},d(_){_&&t(g)}}}function vl(Mt){let g,T,_,b,et,ee,ts,tt,as,zt,Se,ss,Zt,De,os,Rt,$,at,rs,ls,st,is,ns,ot,fs,hs,rt,ps,us,lt,ds,Ut,Te,cs,Yt,xe,Jt,j,x,it,te,ms,nt,ys,Bt,qe,vs,Vt,Ce,ws,Wt,q,gs,ft,_s,$s,Kt,Ne,bs,Qt,Oe,Es,Xt,C,ht,ks,Hs,pt,js,ea,N,As,Ge,Ps,Ls,ta,A,O,ut,ae,Fs,dt,Is,aa,k,Ss,se,Ds,Ts,oe,xs,qs,sa,Me,ct,Cs,oa,re,ra,le,mt,Ns,la,ie,ia,G,Os,yt,Gs,Ms,na,ne,fa,P,M,vt,fe,zs,wt,Zs,ha,he,pe,Rs,ue,Us,Ys,pa,de,ua,z,Js,gt,Bs,Vs,da,L,Z,_t,ce,Ws,$t,Ks,ca,me,bt,Qs,ma,E,Et,R,kt,Xs,eo,ze,to,ao,so,Ht,ye,oo,Ze,ro,lo,io,jt,U,At,no,fo,Re,ho,po,uo,Pt,Ue,Lt,co,mo,ya,F,Y,Ft,ve,yo,It,vo,va,Ye,wo,wa,we,ge,go,St,_o,$o,ga,_e,_a,$e,Dt,bo,$a,be,ba,Ee,Tt,Eo,Ea,ke,ka,Je,ko,Ha,He,ja,I,J,xt,je,Ho,qt,jo,Aa,B,Ao,Ae,Po,Lo,Pa,Be,Fo,La,Pe,Fa,Ve,Io,Ia,S,V,Ct,Le,So,Nt,Do,Sa,We,To,Da,W,Ta,Ke,xo,xa,Qe,qo,qa,K,Co,Fe,No,Oo,Ca;return ee=new X({}),te=new X({}),ae=new X({}),re=new D({props:{code:"huggingface-cli login",highlighted:'huggingface-<span class="hljs-keyword">cli</span> login'}}),ie=new D({props:{code:"huggingface-cli repo create your_dataset_name --type dataset",highlighted:'huggingface-cli repo <span class="hljs-keyword">create</span> your_dataset_name --<span class="hljs-built_in">type</span> <span class="hljs-keyword">dataset</span>'}}),ne=new D({props:{code:"huggingface-cli repo create your_dataset_name --type dataset --organization your-org-name",highlighted:'huggingface-cli repo <span class="hljs-keyword">create</span> your_dataset_name --<span class="hljs-built_in">type</span> <span class="hljs-keyword">dataset</span> --organization your-org-name'}}),fe=new X({}),de=new D({props:{code:"",highlighted:`<span class="hljs-comment"># Make sure you have git-lfs installed</span>
<span class="hljs-comment"># (https://git-lfs.github.com/)</span>
git lfs install

git clone https:<span class="hljs-regexp">//</span>huggingface.co<span class="hljs-regexp">/datasets/</span>namespace/your_dataset_name`}}),ce=new X({}),ve=new X({}),_e=new D({props:{code:`cp /somewhere/data/*.json .
git lfs track *.json
git add .gitattributes
git add *.json
git commit -m "add json files"`,highlighted:`cp <span class="hljs-string">/somewhere/data/</span>*<span class="hljs-string">.json</span> .
git lfs track *<span class="hljs-string">.json</span>
git add <span class="hljs-string">.gitattributes</span>
git add *<span class="hljs-string">.json</span>
git commit -m <span class="hljs-string">&quot;add json files&quot;</span>`}}),be=new D({props:{code:`cp /somewhere/data/dataset_infos.json .
cp /somewhere/data/load_script.py .
git add --all`,highlighted:`<span class="hljs-title">cp</span> /somewhere/<span class="hljs-class"><span class="hljs-keyword">data</span>/dataset_infos.json .</span>
<span class="hljs-title">cp</span> /somewhere/<span class="hljs-class"><span class="hljs-keyword">data</span>/load_script.py .</span>
<span class="hljs-title">git</span> add <span class="hljs-comment">--all</span>`}}),ke=new D({props:{code:`git status
git commit -m "First version of the your_dataset_name dataset."
git push`,highlighted:`git <span class="hljs-built_in">status</span>
git commit -m <span class="hljs-string">&quot;First version of the your_dataset_name dataset.&quot;</span>
git <span class="hljs-built_in">push</span>`}}),He=new D({props:{code:'dataset = load_dataset("namespace/your_dataset_name")',highlighted:'<span class="hljs-attribute">dataset</span> <span class="hljs-operator">=</span> load_dataset(<span class="hljs-string">&quot;namespace/your_dataset_name&quot;</span>)'}}),je=new X({}),Pe=new D({props:{code:`



`,highlighted:`<span class="hljs-comment"># Dataset rewiew request for &lt;Dataset name&gt;</span>

<span class="hljs-comment">## Description</span>

<span class="hljs-variable">&lt;brief description of the dataset&gt;</span>

<span class="hljs-comment">## Files to review</span>

- file1
- file2
- ...

cc <span class="hljs-meta">@lhoestq</span> <span class="hljs-meta">@polinaeterna</span> <span class="hljs-meta">@mariosasko</span> <span class="hljs-meta">@albertvillanova</span>`}}),Le=new X({}),W=new ml({props:{$$slots:{default:[yl]},$$scope:{ctx:Mt}}}),{c(){g=o("meta"),T=h(),_=o("h1"),b=o("a"),et=o("span"),d(ee.$$.fragment),ts=h(),tt=o("span"),as=n("Share"),zt=h(),Se=o("p"),ss=n("At Hugging Face, we are on a mission to democratize good Machine Learning and we believe in the value of open source. That\u2019s why we designed \u{1F917} Datasets so that anyone can share a dataset with the greater ML community. There are currently thousands of datasets in over 100 languages in the Hugging Face Hub, and the Hugging Face team always welcomes new contributions!"),Zt=h(),De=o("p"),os=n("Dataset repositories offer features such as:"),Rt=h(),$=o("ul"),at=o("li"),rs=n("Free dataset hosting"),ls=h(),st=o("li"),is=n("Dataset versioning"),ns=h(),ot=o("li"),fs=n("Commit history and diffs"),hs=h(),rt=o("li"),ps=n("Metadata for discoverability"),us=h(),lt=o("li"),ds=n("Dataset cards for documentation, licensing, limitations, etc."),Ut=h(),Te=o("p"),cs=n("This guide will show you how to share a dataset that can be easily accessed by anyone."),Yt=h(),xe=o("a"),Jt=h(),j=o("h2"),x=o("a"),it=o("span"),d(te.$$.fragment),ms=h(),nt=o("span"),ys=n("Add a dataset"),Bt=h(),qe=o("p"),vs=n(`You can share your dataset with the community with a dataset repository on the Hugging Face Hub.
It can also be a private dataset if you want to control who has access to it.`),Vt=h(),Ce=o("p"),ws=n("In a dataset repository, you can either host all your data files and/or use a dataset script."),Wt=h(),q=o("p"),gs=n(`The dataset script is optional if your dataset is in one of the following formats: CSV, JSON, JSON lines, text or Parquet.
The script also supports many kinds of compressed file types such as: GZ, BZ2, LZ4, LZMA or ZSTD.
For example, your dataset can be made of `),ft=o("code"),_s=n(".json.gz"),$s=n(" files."),Kt=h(),Ne=o("p"),bs=n("On the other hand, if your dataset is not in a supported format or if you want more control over how your dataset is loaded, you can write your own dataset script."),Qt=h(),Oe=o("p"),Es=n("When loading a dataset from the Hub:"),Xt=h(),C=o("ul"),ht=o("li"),ks=n("If there\u2019s no dataset script, all the files in the supported formats are loaded."),Hs=h(),pt=o("li"),js=n("If there\u2019s a dataset script, it is downloaded and executed to download and prepare the dataset."),ea=h(),N=o("p"),As=n("For more information on how to load a dataset from the Hub, see how to load from the "),Ge=o("a"),Ps=n("load-from-the-hub"),Ls=n("."),ta=h(),A=o("h3"),O=o("a"),ut=o("span"),d(ae.$$.fragment),Fs=h(),dt=o("span"),Is=n("Create the repository"),aa=h(),k=o("p"),Ss=n("Sharing a community dataset will require you to create an account on "),se=o("a"),Ds=n("hf.co"),Ts=n(` if you don\u2019t have one yet.
You can directly create a `),oe=o("a"),xs=n("new dataset repository"),qs=n(" from your account on the Hugging Face Hub, but this guide will show you how to upload a dataset from the terminal."),sa=h(),Me=o("ol"),ct=o("li"),Cs=n("Make sure you are in the virtual environment where you installed Datasets, and run the following command:"),oa=h(),d(re.$$.fragment),ra=h(),le=o("ol"),mt=o("li"),Ns=n("Login using your Hugging Face Hub credentials, and create a new dataset repository:"),la=h(),d(ie.$$.fragment),ia=h(),G=o("p"),Os=n("Add the "),yt=o("code"),Gs=n("-organization"),Ms=n(" flag to create a repository under a specific organization:"),na=h(),d(ne.$$.fragment),fa=h(),P=o("h3"),M=o("a"),vt=o("span"),d(fe.$$.fragment),zs=h(),wt=o("span"),Zs=n("Clone the repository"),ha=h(),he=o("ol"),pe=o("li"),Rs=n("Install "),ue=o("a"),Us=n("Git LFS"),Ys=n(" and clone your repository:"),pa=h(),d(de.$$.fragment),ua=h(),z=o("p"),Js=n("Here the "),gt=o("code"),Bs=n("namespace"),Vs=n(" is either your username or your organization name."),da=h(),L=o("h3"),Z=o("a"),_t=o("span"),d(ce.$$.fragment),Ws=h(),$t=o("span"),Ks=n("Prepare your files"),ca=h(),me=o("ol"),bt=o("li"),Qs=n("Now is a good time to check your directory to ensure the only files you\u2019re uploading are:"),ma=h(),E=o("ul"),Et=o("li"),R=o("p"),kt=o("code"),Xs=n("README.md"),eo=n(" is a Dataset card that describes the datasets contents, creation, and usage. To write a Dataset card, see the "),ze=o("a"),to=n("dataset card"),ao=n(" page."),so=h(),Ht=o("li"),ye=o("p"),oo=n("The raw data files of the dataset (optional, if they are hosted elsewhere you can specify the URLs in the dataset script). If you don\u2019t need a dataset script, you can take a look at "),Ze=o("a"),ro=n("how to structure your dataset repository for your data files"),lo=n("."),io=h(),jt=o("li"),U=o("p"),At=o("code"),no=n("your_dataset_name.py"),fo=n(" is your dataset loading script (optional if your data files are already in the supported formats csv/jsonl/json/parquet/txt). To create a dataset script, see the "),Re=o("a"),ho=n("dataset script"),po=n(" page."),uo=h(),Pt=o("li"),Ue=o("p"),Lt=o("code"),co=n("dataset_infos.json"),mo=n(" contains metadata about the dataset (required only if you have a dataset script, or if you want to specify custom feature types)."),ya=h(),F=o("h3"),Y=o("a"),Ft=o("span"),d(ve.$$.fragment),yo=h(),It=o("span"),vo=n("Upload your files"),va=h(),Ye=o("p"),wo=n("You can directly upload your files from your repository on the Hugging Face Hub, but this guide will show you how to upload the files from the terminal."),wa=h(),we=o("ol"),ge=o("li"),go=n("It is important to add the large data files first with "),St=o("code"),_o=n("git lfs track"),$o=n(" or else you will encounter an error later when you push your files:"),ga=h(),d(_e.$$.fragment),_a=h(),$e=o("ol"),Dt=o("li"),bo=n("Add the dataset loading script and metadata file:"),$a=h(),d(be.$$.fragment),ba=h(),Ee=o("ol"),Tt=o("li"),Eo=n("Verify the files have been correctly staged. Then you can commit and push your files:"),Ea=h(),d(ke.$$.fragment),ka=h(),Je=o("p"),ko=n("Congratulations, your dataset has now been uploaded to the Hugging Face Hub where anyone can load it in a single line of code! \u{1F973}"),Ha=h(),d(He.$$.fragment),ja=h(),I=o("h3"),J=o("a"),xt=o("span"),d(je.$$.fragment),Ho=h(),qt=o("span"),jo=n("Ask for a help and reviews"),Aa=h(),B=o("p"),Ao=n("If you need help with a dataset script, feel free to check the "),Ae=o("a"),Po=n("datasets forum"),Lo=n(": it\u2019s possible that someone had similar issues and shared how they managed to fix them."),Pa=h(),Be=o("p"),Fo=n("Then if your script is ready and if you wish your dataset script to be reviewed by the Hugging Face team, you can open a discussion in the Community tab of your dataset with this message:"),La=h(),d(Pe.$$.fragment),Fa=h(),Ve=o("p"),Io=n("Members of the Hugging Face team will be happy to review your dataset script and give you advice."),Ia=h(),S=o("h2"),V=o("a"),Ct=o("span"),d(Le.$$.fragment),So=h(),Nt=o("span"),Do=n("Datasets on GitHub (legacy)"),Sa=h(),We=o("p"),To=n(`Datasets used to be hosted on our GitHub repository, but all datasets have now been migrated to the Hugging Face Hub.
The legacy GitHub datasets were added originally on our GitHub repository and therefore don\u2019t have a namespace: \u201Csquad\u201D, \u201Cglue\u201D, etc. unlike the other datasets that are named \u201Cusername/dataset_name\u201D or \u201Corg/dataset_name\u201D.
Those datasets are still maintained on GitHub, and if you\u2019d like to edit them, please open a Pull Request on the huggingface/datasets repository.
Sharing your dataset to the Hub is the recommended way of adding a dataset.`),Da=h(),d(W.$$.fragment),Ta=h(),Ke=o("p"),xo=n("The code of these datasets are reviewed by the Hugging Face team, and they require test data in order to be regularly tested."),xa=h(),Qe=o("p"),qo=n("In some rare cases it makes more sense to open a PR on GitHub. For example when you are not the author of the dataset and there is no clear organization / namespace that you can put the dataset under."),qa=h(),K=o("p"),Co=n("For more info, please take a look at the documentation on "),Fe=o("a"),No=n("How to add a new dataset in the huggingface/datasets repository"),Oo=n("."),this.h()},l(e){const s=dl('[data-svelte="svelte-1phssyn"]',document.head);g=r(s,"META",{name:!0,content:!0}),s.forEach(t),T=p(e),_=r(e,"H1",{class:!0});var Ie=l(_);b=r(Ie,"A",{id:!0,class:!0,href:!0});var Mo=l(b);et=r(Mo,"SPAN",{});var zo=l(et);c(ee.$$.fragment,zo),zo.forEach(t),Mo.forEach(t),ts=p(Ie),tt=r(Ie,"SPAN",{});var Zo=l(tt);as=f(Zo,"Share"),Zo.forEach(t),Ie.forEach(t),zt=p(e),Se=r(e,"P",{});var Ro=l(Se);ss=f(Ro,"At Hugging Face, we are on a mission to democratize good Machine Learning and we believe in the value of open source. That\u2019s why we designed \u{1F917} Datasets so that anyone can share a dataset with the greater ML community. There are currently thousands of datasets in over 100 languages in the Hugging Face Hub, and the Hugging Face team always welcomes new contributions!"),Ro.forEach(t),Zt=p(e),De=r(e,"P",{});var Uo=l(De);os=f(Uo,"Dataset repositories offer features such as:"),Uo.forEach(t),Rt=p(e),$=r(e,"UL",{});var H=l($);at=r(H,"LI",{});var Yo=l(at);rs=f(Yo,"Free dataset hosting"),Yo.forEach(t),ls=p(H),st=r(H,"LI",{});var Jo=l(st);is=f(Jo,"Dataset versioning"),Jo.forEach(t),ns=p(H),ot=r(H,"LI",{});var Bo=l(ot);fs=f(Bo,"Commit history and diffs"),Bo.forEach(t),hs=p(H),rt=r(H,"LI",{});var Vo=l(rt);ps=f(Vo,"Metadata for discoverability"),Vo.forEach(t),us=p(H),lt=r(H,"LI",{});var Wo=l(lt);ds=f(Wo,"Dataset cards for documentation, licensing, limitations, etc."),Wo.forEach(t),H.forEach(t),Ut=p(e),Te=r(e,"P",{});var Ko=l(Te);cs=f(Ko,"This guide will show you how to share a dataset that can be easily accessed by anyone."),Ko.forEach(t),Yt=p(e),xe=r(e,"A",{id:!0}),l(xe).forEach(t),Jt=p(e),j=r(e,"H2",{class:!0});var Na=l(j);x=r(Na,"A",{id:!0,class:!0,href:!0});var Qo=l(x);it=r(Qo,"SPAN",{});var Xo=l(it);c(te.$$.fragment,Xo),Xo.forEach(t),Qo.forEach(t),ms=p(Na),nt=r(Na,"SPAN",{});var er=l(nt);ys=f(er,"Add a dataset"),er.forEach(t),Na.forEach(t),Bt=p(e),qe=r(e,"P",{});var tr=l(qe);vs=f(tr,`You can share your dataset with the community with a dataset repository on the Hugging Face Hub.
It can also be a private dataset if you want to control who has access to it.`),tr.forEach(t),Vt=p(e),Ce=r(e,"P",{});var ar=l(Ce);ws=f(ar,"In a dataset repository, you can either host all your data files and/or use a dataset script."),ar.forEach(t),Wt=p(e),q=r(e,"P",{});var Oa=l(q);gs=f(Oa,`The dataset script is optional if your dataset is in one of the following formats: CSV, JSON, JSON lines, text or Parquet.
The script also supports many kinds of compressed file types such as: GZ, BZ2, LZ4, LZMA or ZSTD.
For example, your dataset can be made of `),ft=r(Oa,"CODE",{});var sr=l(ft);_s=f(sr,".json.gz"),sr.forEach(t),$s=f(Oa," files."),Oa.forEach(t),Kt=p(e),Ne=r(e,"P",{});var or=l(Ne);bs=f(or,"On the other hand, if your dataset is not in a supported format or if you want more control over how your dataset is loaded, you can write your own dataset script."),or.forEach(t),Qt=p(e),Oe=r(e,"P",{});var rr=l(Oe);Es=f(rr,"When loading a dataset from the Hub:"),rr.forEach(t),Xt=p(e),C=r(e,"UL",{});var Ga=l(C);ht=r(Ga,"LI",{});var lr=l(ht);ks=f(lr,"If there\u2019s no dataset script, all the files in the supported formats are loaded."),lr.forEach(t),Hs=p(Ga),pt=r(Ga,"LI",{});var ir=l(pt);js=f(ir,"If there\u2019s a dataset script, it is downloaded and executed to download and prepare the dataset."),ir.forEach(t),Ga.forEach(t),ea=p(e),N=r(e,"P",{});var Ma=l(N);As=f(Ma,"For more information on how to load a dataset from the Hub, see how to load from the "),Ge=r(Ma,"A",{href:!0});var nr=l(Ge);Ps=f(nr,"load-from-the-hub"),nr.forEach(t),Ls=f(Ma,"."),Ma.forEach(t),ta=p(e),A=r(e,"H3",{class:!0});var za=l(A);O=r(za,"A",{id:!0,class:!0,href:!0});var fr=l(O);ut=r(fr,"SPAN",{});var hr=l(ut);c(ae.$$.fragment,hr),hr.forEach(t),fr.forEach(t),Fs=p(za),dt=r(za,"SPAN",{});var pr=l(dt);Is=f(pr,"Create the repository"),pr.forEach(t),za.forEach(t),aa=p(e),k=r(e,"P",{});var Xe=l(k);Ss=f(Xe,"Sharing a community dataset will require you to create an account on "),se=r(Xe,"A",{href:!0,rel:!0});var ur=l(se);Ds=f(ur,"hf.co"),ur.forEach(t),Ts=f(Xe,` if you don\u2019t have one yet.
You can directly create a `),oe=r(Xe,"A",{href:!0,rel:!0});var dr=l(oe);xs=f(dr,"new dataset repository"),dr.forEach(t),qs=f(Xe," from your account on the Hugging Face Hub, but this guide will show you how to upload a dataset from the terminal."),Xe.forEach(t),sa=p(e),Me=r(e,"OL",{});var cr=l(Me);ct=r(cr,"LI",{});var mr=l(ct);Cs=f(mr,"Make sure you are in the virtual environment where you installed Datasets, and run the following command:"),mr.forEach(t),cr.forEach(t),oa=p(e),c(re.$$.fragment,e),ra=p(e),le=r(e,"OL",{start:!0});var yr=l(le);mt=r(yr,"LI",{});var vr=l(mt);Ns=f(vr,"Login using your Hugging Face Hub credentials, and create a new dataset repository:"),vr.forEach(t),yr.forEach(t),la=p(e),c(ie.$$.fragment,e),ia=p(e),G=r(e,"P",{});var Za=l(G);Os=f(Za,"Add the "),yt=r(Za,"CODE",{});var wr=l(yt);Gs=f(wr,"-organization"),wr.forEach(t),Ms=f(Za," flag to create a repository under a specific organization:"),Za.forEach(t),na=p(e),c(ne.$$.fragment,e),fa=p(e),P=r(e,"H3",{class:!0});var Ra=l(P);M=r(Ra,"A",{id:!0,class:!0,href:!0});var gr=l(M);vt=r(gr,"SPAN",{});var _r=l(vt);c(fe.$$.fragment,_r),_r.forEach(t),gr.forEach(t),zs=p(Ra),wt=r(Ra,"SPAN",{});var $r=l(wt);Zs=f($r,"Clone the repository"),$r.forEach(t),Ra.forEach(t),ha=p(e),he=r(e,"OL",{start:!0});var br=l(he);pe=r(br,"LI",{});var Ua=l(pe);Rs=f(Ua,"Install "),ue=r(Ua,"A",{href:!0,rel:!0});var Er=l(ue);Us=f(Er,"Git LFS"),Er.forEach(t),Ys=f(Ua," and clone your repository:"),Ua.forEach(t),br.forEach(t),pa=p(e),c(de.$$.fragment,e),ua=p(e),z=r(e,"P",{});var Ya=l(z);Js=f(Ya,"Here the "),gt=r(Ya,"CODE",{});var kr=l(gt);Bs=f(kr,"namespace"),kr.forEach(t),Vs=f(Ya," is either your username or your organization name."),Ya.forEach(t),da=p(e),L=r(e,"H3",{class:!0});var Ja=l(L);Z=r(Ja,"A",{id:!0,class:!0,href:!0});var Hr=l(Z);_t=r(Hr,"SPAN",{});var jr=l(_t);c(ce.$$.fragment,jr),jr.forEach(t),Hr.forEach(t),Ws=p(Ja),$t=r(Ja,"SPAN",{});var Ar=l($t);Ks=f(Ar,"Prepare your files"),Ar.forEach(t),Ja.forEach(t),ca=p(e),me=r(e,"OL",{start:!0});var Pr=l(me);bt=r(Pr,"LI",{});var Lr=l(bt);Qs=f(Lr,"Now is a good time to check your directory to ensure the only files you\u2019re uploading are:"),Lr.forEach(t),Pr.forEach(t),ma=p(e),E=r(e,"UL",{});var Q=l(E);Et=r(Q,"LI",{});var Fr=l(Et);R=r(Fr,"P",{});var Ot=l(R);kt=r(Ot,"CODE",{});var Ir=l(kt);Xs=f(Ir,"README.md"),Ir.forEach(t),eo=f(Ot," is a Dataset card that describes the datasets contents, creation, and usage. To write a Dataset card, see the "),ze=r(Ot,"A",{href:!0});var Sr=l(ze);to=f(Sr,"dataset card"),Sr.forEach(t),ao=f(Ot," page."),Ot.forEach(t),Fr.forEach(t),so=p(Q),Ht=r(Q,"LI",{});var Dr=l(Ht);ye=r(Dr,"P",{});var Ba=l(ye);oo=f(Ba,"The raw data files of the dataset (optional, if they are hosted elsewhere you can specify the URLs in the dataset script). If you don\u2019t need a dataset script, you can take a look at "),Ze=r(Ba,"A",{href:!0});var Tr=l(Ze);ro=f(Tr,"how to structure your dataset repository for your data files"),Tr.forEach(t),lo=f(Ba,"."),Ba.forEach(t),Dr.forEach(t),io=p(Q),jt=r(Q,"LI",{});var xr=l(jt);U=r(xr,"P",{});var Gt=l(U);At=r(Gt,"CODE",{});var qr=l(At);no=f(qr,"your_dataset_name.py"),qr.forEach(t),fo=f(Gt," is your dataset loading script (optional if your data files are already in the supported formats csv/jsonl/json/parquet/txt). To create a dataset script, see the "),Re=r(Gt,"A",{href:!0});var Cr=l(Re);ho=f(Cr,"dataset script"),Cr.forEach(t),po=f(Gt," page."),Gt.forEach(t),xr.forEach(t),uo=p(Q),Pt=r(Q,"LI",{});var Nr=l(Pt);Ue=r(Nr,"P",{});var Go=l(Ue);Lt=r(Go,"CODE",{});var Or=l(Lt);co=f(Or,"dataset_infos.json"),Or.forEach(t),mo=f(Go," contains metadata about the dataset (required only if you have a dataset script, or if you want to specify custom feature types)."),Go.forEach(t),Nr.forEach(t),Q.forEach(t),ya=p(e),F=r(e,"H3",{class:!0});var Va=l(F);Y=r(Va,"A",{id:!0,class:!0,href:!0});var Gr=l(Y);Ft=r(Gr,"SPAN",{});var Mr=l(Ft);c(ve.$$.fragment,Mr),Mr.forEach(t),Gr.forEach(t),yo=p(Va),It=r(Va,"SPAN",{});var zr=l(It);vo=f(zr,"Upload your files"),zr.forEach(t),Va.forEach(t),va=p(e),Ye=r(e,"P",{});var Zr=l(Ye);wo=f(Zr,"You can directly upload your files from your repository on the Hugging Face Hub, but this guide will show you how to upload the files from the terminal."),Zr.forEach(t),wa=p(e),we=r(e,"OL",{start:!0});var Rr=l(we);ge=r(Rr,"LI",{});var Wa=l(ge);go=f(Wa,"It is important to add the large data files first with "),St=r(Wa,"CODE",{});var Ur=l(St);_o=f(Ur,"git lfs track"),Ur.forEach(t),$o=f(Wa," or else you will encounter an error later when you push your files:"),Wa.forEach(t),Rr.forEach(t),ga=p(e),c(_e.$$.fragment,e),_a=p(e),$e=r(e,"OL",{start:!0});var Yr=l($e);Dt=r(Yr,"LI",{});var Jr=l(Dt);bo=f(Jr,"Add the dataset loading script and metadata file:"),Jr.forEach(t),Yr.forEach(t),$a=p(e),c(be.$$.fragment,e),ba=p(e),Ee=r(e,"OL",{start:!0});var Br=l(Ee);Tt=r(Br,"LI",{});var Vr=l(Tt);Eo=f(Vr,"Verify the files have been correctly staged. Then you can commit and push your files:"),Vr.forEach(t),Br.forEach(t),Ea=p(e),c(ke.$$.fragment,e),ka=p(e),Je=r(e,"P",{});var Wr=l(Je);ko=f(Wr,"Congratulations, your dataset has now been uploaded to the Hugging Face Hub where anyone can load it in a single line of code! \u{1F973}"),Wr.forEach(t),Ha=p(e),c(He.$$.fragment,e),ja=p(e),I=r(e,"H3",{class:!0});var Ka=l(I);J=r(Ka,"A",{id:!0,class:!0,href:!0});var Kr=l(J);xt=r(Kr,"SPAN",{});var Qr=l(xt);c(je.$$.fragment,Qr),Qr.forEach(t),Kr.forEach(t),Ho=p(Ka),qt=r(Ka,"SPAN",{});var Xr=l(qt);jo=f(Xr,"Ask for a help and reviews"),Xr.forEach(t),Ka.forEach(t),Aa=p(e),B=r(e,"P",{});var Qa=l(B);Ao=f(Qa,"If you need help with a dataset script, feel free to check the "),Ae=r(Qa,"A",{href:!0,rel:!0});var el=l(Ae);Po=f(el,"datasets forum"),el.forEach(t),Lo=f(Qa,": it\u2019s possible that someone had similar issues and shared how they managed to fix them."),Qa.forEach(t),Pa=p(e),Be=r(e,"P",{});var tl=l(Be);Fo=f(tl,"Then if your script is ready and if you wish your dataset script to be reviewed by the Hugging Face team, you can open a discussion in the Community tab of your dataset with this message:"),tl.forEach(t),La=p(e),c(Pe.$$.fragment,e),Fa=p(e),Ve=r(e,"P",{});var al=l(Ve);Io=f(al,"Members of the Hugging Face team will be happy to review your dataset script and give you advice."),al.forEach(t),Ia=p(e),S=r(e,"H2",{class:!0});var Xa=l(S);V=r(Xa,"A",{id:!0,class:!0,href:!0});var sl=l(V);Ct=r(sl,"SPAN",{});var ol=l(Ct);c(Le.$$.fragment,ol),ol.forEach(t),sl.forEach(t),So=p(Xa),Nt=r(Xa,"SPAN",{});var rl=l(Nt);Do=f(rl,"Datasets on GitHub (legacy)"),rl.forEach(t),Xa.forEach(t),Sa=p(e),We=r(e,"P",{});var ll=l(We);To=f(ll,`Datasets used to be hosted on our GitHub repository, but all datasets have now been migrated to the Hugging Face Hub.
The legacy GitHub datasets were added originally on our GitHub repository and therefore don\u2019t have a namespace: \u201Csquad\u201D, \u201Cglue\u201D, etc. unlike the other datasets that are named \u201Cusername/dataset_name\u201D or \u201Corg/dataset_name\u201D.
Those datasets are still maintained on GitHub, and if you\u2019d like to edit them, please open a Pull Request on the huggingface/datasets repository.
Sharing your dataset to the Hub is the recommended way of adding a dataset.`),ll.forEach(t),Da=p(e),c(W.$$.fragment,e),Ta=p(e),Ke=r(e,"P",{});var il=l(Ke);xo=f(il,"The code of these datasets are reviewed by the Hugging Face team, and they require test data in order to be regularly tested."),il.forEach(t),xa=p(e),Qe=r(e,"P",{});var nl=l(Qe);qo=f(nl,"In some rare cases it makes more sense to open a PR on GitHub. For example when you are not the author of the dataset and there is no clear organization / namespace that you can put the dataset under."),nl.forEach(t),qa=p(e),K=r(e,"P",{});var es=l(K);Co=f(es,"For more info, please take a look at the documentation on "),Fe=r(es,"A",{href:!0,rel:!0});var fl=l(Fe);No=f(fl,"How to add a new dataset in the huggingface/datasets repository"),fl.forEach(t),Oo=f(es,"."),es.forEach(t),this.h()},h(){u(g,"name","hf:doc:metadata"),u(g,"content",JSON.stringify(wl)),u(b,"id","share"),u(b,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(b,"href","#share"),u(_,"class","relative group"),u(xe,"id","upload_dataset_repo"),u(x,"id","add-a-dataset"),u(x,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(x,"href","#add-a-dataset"),u(j,"class","relative group"),u(Ge,"href","#load-from-the-hub"),u(O,"id","create-the-repository"),u(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(O,"href","#create-the-repository"),u(A,"class","relative group"),u(se,"href","https://huggingface.co/join"),u(se,"rel","nofollow"),u(oe,"href","https://huggingface.co/login?next=%2Fnew-dataset"),u(oe,"rel","nofollow"),u(le,"start","2"),u(M,"id","clone-the-repository"),u(M,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(M,"href","#clone-the-repository"),u(P,"class","relative group"),u(ue,"href","https://git-lfs.github.com/"),u(ue,"rel","nofollow"),u(he,"start","3"),u(Z,"id","prepare-your-files"),u(Z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(Z,"href","#prepare-your-files"),u(L,"class","relative group"),u(me,"start","4"),u(ze,"href","dataset_card"),u(Ze,"href","repository_structure"),u(Re,"href","dataset_script"),u(Y,"id","upload-your-files"),u(Y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(Y,"href","#upload-your-files"),u(F,"class","relative group"),u(we,"start","5"),u($e,"start","6"),u(Ee,"start","7"),u(J,"id","ask-for-a-help-and-reviews"),u(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(J,"href","#ask-for-a-help-and-reviews"),u(I,"class","relative group"),u(Ae,"href","https://discuss.huggingface.co/c/datasets/10"),u(Ae,"rel","nofollow"),u(V,"id","datasets-on-github-legacy"),u(V,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(V,"href","#datasets-on-github-legacy"),u(S,"class","relative group"),u(Fe,"href","https://github.com/huggingface/datasets/blob/master/ADD_NEW_DATASET.md"),u(Fe,"rel","nofollow")},m(e,s){a(document.head,g),i(e,T,s),i(e,_,s),a(_,b),a(b,et),m(ee,et,null),a(_,ts),a(_,tt),a(tt,as),i(e,zt,s),i(e,Se,s),a(Se,ss),i(e,Zt,s),i(e,De,s),a(De,os),i(e,Rt,s),i(e,$,s),a($,at),a(at,rs),a($,ls),a($,st),a(st,is),a($,ns),a($,ot),a(ot,fs),a($,hs),a($,rt),a(rt,ps),a($,us),a($,lt),a(lt,ds),i(e,Ut,s),i(e,Te,s),a(Te,cs),i(e,Yt,s),i(e,xe,s),i(e,Jt,s),i(e,j,s),a(j,x),a(x,it),m(te,it,null),a(j,ms),a(j,nt),a(nt,ys),i(e,Bt,s),i(e,qe,s),a(qe,vs),i(e,Vt,s),i(e,Ce,s),a(Ce,ws),i(e,Wt,s),i(e,q,s),a(q,gs),a(q,ft),a(ft,_s),a(q,$s),i(e,Kt,s),i(e,Ne,s),a(Ne,bs),i(e,Qt,s),i(e,Oe,s),a(Oe,Es),i(e,Xt,s),i(e,C,s),a(C,ht),a(ht,ks),a(C,Hs),a(C,pt),a(pt,js),i(e,ea,s),i(e,N,s),a(N,As),a(N,Ge),a(Ge,Ps),a(N,Ls),i(e,ta,s),i(e,A,s),a(A,O),a(O,ut),m(ae,ut,null),a(A,Fs),a(A,dt),a(dt,Is),i(e,aa,s),i(e,k,s),a(k,Ss),a(k,se),a(se,Ds),a(k,Ts),a(k,oe),a(oe,xs),a(k,qs),i(e,sa,s),i(e,Me,s),a(Me,ct),a(ct,Cs),i(e,oa,s),m(re,e,s),i(e,ra,s),i(e,le,s),a(le,mt),a(mt,Ns),i(e,la,s),m(ie,e,s),i(e,ia,s),i(e,G,s),a(G,Os),a(G,yt),a(yt,Gs),a(G,Ms),i(e,na,s),m(ne,e,s),i(e,fa,s),i(e,P,s),a(P,M),a(M,vt),m(fe,vt,null),a(P,zs),a(P,wt),a(wt,Zs),i(e,ha,s),i(e,he,s),a(he,pe),a(pe,Rs),a(pe,ue),a(ue,Us),a(pe,Ys),i(e,pa,s),m(de,e,s),i(e,ua,s),i(e,z,s),a(z,Js),a(z,gt),a(gt,Bs),a(z,Vs),i(e,da,s),i(e,L,s),a(L,Z),a(Z,_t),m(ce,_t,null),a(L,Ws),a(L,$t),a($t,Ks),i(e,ca,s),i(e,me,s),a(me,bt),a(bt,Qs),i(e,ma,s),i(e,E,s),a(E,Et),a(Et,R),a(R,kt),a(kt,Xs),a(R,eo),a(R,ze),a(ze,to),a(R,ao),a(E,so),a(E,Ht),a(Ht,ye),a(ye,oo),a(ye,Ze),a(Ze,ro),a(ye,lo),a(E,io),a(E,jt),a(jt,U),a(U,At),a(At,no),a(U,fo),a(U,Re),a(Re,ho),a(U,po),a(E,uo),a(E,Pt),a(Pt,Ue),a(Ue,Lt),a(Lt,co),a(Ue,mo),i(e,ya,s),i(e,F,s),a(F,Y),a(Y,Ft),m(ve,Ft,null),a(F,yo),a(F,It),a(It,vo),i(e,va,s),i(e,Ye,s),a(Ye,wo),i(e,wa,s),i(e,we,s),a(we,ge),a(ge,go),a(ge,St),a(St,_o),a(ge,$o),i(e,ga,s),m(_e,e,s),i(e,_a,s),i(e,$e,s),a($e,Dt),a(Dt,bo),i(e,$a,s),m(be,e,s),i(e,ba,s),i(e,Ee,s),a(Ee,Tt),a(Tt,Eo),i(e,Ea,s),m(ke,e,s),i(e,ka,s),i(e,Je,s),a(Je,ko),i(e,Ha,s),m(He,e,s),i(e,ja,s),i(e,I,s),a(I,J),a(J,xt),m(je,xt,null),a(I,Ho),a(I,qt),a(qt,jo),i(e,Aa,s),i(e,B,s),a(B,Ao),a(B,Ae),a(Ae,Po),a(B,Lo),i(e,Pa,s),i(e,Be,s),a(Be,Fo),i(e,La,s),m(Pe,e,s),i(e,Fa,s),i(e,Ve,s),a(Ve,Io),i(e,Ia,s),i(e,S,s),a(S,V),a(V,Ct),m(Le,Ct,null),a(S,So),a(S,Nt),a(Nt,Do),i(e,Sa,s),i(e,We,s),a(We,To),i(e,Da,s),m(W,e,s),i(e,Ta,s),i(e,Ke,s),a(Ke,xo),i(e,xa,s),i(e,Qe,s),a(Qe,qo),i(e,qa,s),i(e,K,s),a(K,Co),a(K,Fe),a(Fe,No),a(K,Oo),Ca=!0},p(e,[s]){const Ie={};s&2&&(Ie.$$scope={dirty:s,ctx:e}),W.$set(Ie)},i(e){Ca||(y(ee.$$.fragment,e),y(te.$$.fragment,e),y(ae.$$.fragment,e),y(re.$$.fragment,e),y(ie.$$.fragment,e),y(ne.$$.fragment,e),y(fe.$$.fragment,e),y(de.$$.fragment,e),y(ce.$$.fragment,e),y(ve.$$.fragment,e),y(_e.$$.fragment,e),y(be.$$.fragment,e),y(ke.$$.fragment,e),y(He.$$.fragment,e),y(je.$$.fragment,e),y(Pe.$$.fragment,e),y(Le.$$.fragment,e),y(W.$$.fragment,e),Ca=!0)},o(e){v(ee.$$.fragment,e),v(te.$$.fragment,e),v(ae.$$.fragment,e),v(re.$$.fragment,e),v(ie.$$.fragment,e),v(ne.$$.fragment,e),v(fe.$$.fragment,e),v(de.$$.fragment,e),v(ce.$$.fragment,e),v(ve.$$.fragment,e),v(_e.$$.fragment,e),v(be.$$.fragment,e),v(ke.$$.fragment,e),v(He.$$.fragment,e),v(je.$$.fragment,e),v(Pe.$$.fragment,e),v(Le.$$.fragment,e),v(W.$$.fragment,e),Ca=!1},d(e){t(g),e&&t(T),e&&t(_),w(ee),e&&t(zt),e&&t(Se),e&&t(Zt),e&&t(De),e&&t(Rt),e&&t($),e&&t(Ut),e&&t(Te),e&&t(Yt),e&&t(xe),e&&t(Jt),e&&t(j),w(te),e&&t(Bt),e&&t(qe),e&&t(Vt),e&&t(Ce),e&&t(Wt),e&&t(q),e&&t(Kt),e&&t(Ne),e&&t(Qt),e&&t(Oe),e&&t(Xt),e&&t(C),e&&t(ea),e&&t(N),e&&t(ta),e&&t(A),w(ae),e&&t(aa),e&&t(k),e&&t(sa),e&&t(Me),e&&t(oa),w(re,e),e&&t(ra),e&&t(le),e&&t(la),w(ie,e),e&&t(ia),e&&t(G),e&&t(na),w(ne,e),e&&t(fa),e&&t(P),w(fe),e&&t(ha),e&&t(he),e&&t(pa),w(de,e),e&&t(ua),e&&t(z),e&&t(da),e&&t(L),w(ce),e&&t(ca),e&&t(me),e&&t(ma),e&&t(E),e&&t(ya),e&&t(F),w(ve),e&&t(va),e&&t(Ye),e&&t(wa),e&&t(we),e&&t(ga),w(_e,e),e&&t(_a),e&&t($e),e&&t($a),w(be,e),e&&t(ba),e&&t(Ee),e&&t(Ea),w(ke,e),e&&t(ka),e&&t(Je),e&&t(Ha),w(He,e),e&&t(ja),e&&t(I),w(je),e&&t(Aa),e&&t(B),e&&t(Pa),e&&t(Be),e&&t(La),w(Pe,e),e&&t(Fa),e&&t(Ve),e&&t(Ia),e&&t(S),w(Le),e&&t(Sa),e&&t(We),e&&t(Da),w(W,e),e&&t(Ta),e&&t(Ke),e&&t(xa),e&&t(Qe),e&&t(qa),e&&t(K)}}}const wl={local:"share",sections:[{local:"add-a-dataset",sections:[{local:"create-the-repository",title:"Create the repository"},{local:"clone-the-repository",title:"Clone the repository"},{local:"prepare-your-files",title:"Prepare your files"},{local:"upload-your-files",title:"Upload your files"},{local:"ask-for-a-help-and-reviews",title:"Ask for a help and reviews"}],title:"Add a dataset"},{local:"datasets-on-github-legacy",title:"Datasets on GitHub (legacy)"}],title:"Share"};function gl(Mt){return cl(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class kl extends hl{constructor(g){super();pl(this,g,gl,vl,ul,{})}}export{kl as default,wl as metadata};
