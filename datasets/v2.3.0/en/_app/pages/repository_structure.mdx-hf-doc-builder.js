import{S as La,i as qa,s as Va,e as r,k as f,w as _,t as l,M as Ya,c as i,d as e,m as h,a as o,x as y,h as n,b as c,G as s,g as p,y as $,q as E,o as w,B as g,v as Wa}from"../chunks/vendor-hf-doc-builder.js";import{T as Ba}from"../chunks/Tip-hf-doc-builder.js";import{I as Et}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as ot}from"../chunks/CodeBlock-hf-doc-builder.js";function Ua(Kt){let u,D;return{c(){u=r("p"),D=l("The following examples use CSV files, but you can use any supported format (text, JSON, JSON Lines, CSV, Parquet).")},l(d){u=i(d,"P",{});var x=o(u);D=n(x,"The following examples use CSV files, but you can use any supported format (text, JSON, JSON Lines, CSV, Parquet)."),x.forEach(e)},m(d,x){p(d,u,x),s(u,D)},d(d){d&&e(u)}}}function za(Kt){let u,D,d,x,wt,W,Ge,gt,Ce,Qt,pt,Fe,Xt,O,Je,ft,Le,qe,Zt,H,Ve,ht,Ye,We,te,I,ee,P,G,xt,B,Be,bt,Ue,se,b,ze,At,Ke,Qe,jt,Xe,Ze,ae,A,ts,St,es,ss,ct,as,rs,re,U,le,M,C,kt,z,ls,Pt,is,ie,F,ns,Mt,os,ps,ne,J,K,fs,Nt,hs,cs,us,Q,ds,Rt,ms,vs,oe,L,_s,Tt,ys,$s,pe,X,fe,N,q,Dt,Z,Es,Ot,ws,he,j,gs,Ht,xs,bs,It,As,js,ce,tt,ue,m,Ss,Gt,ks,Ps,Ct,Ms,Ns,Ft,Rs,Ts,Jt,Ds,Os,de,ut,Hs,me,et,ve,R,V,Lt,st,Is,qt,Gs,_e,v,Cs,Vt,Fs,Js,Yt,Ls,qs,Wt,Vs,Ys,Bt,Ws,Bs,ye,at,$e,T,Y,Ut,rt,Us,zt,zs,Ee,dt,Ks,we,mt,Qs,ge,lt,xe,vt,Xs,be,it,Ae;return W=new Et({}),I=new Ba({props:{$$slots:{default:[Ua]},$$scope:{ctx:Kt}}}),B=new Et({}),U=new ot({props:{code:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u251C\u2500\u2500 train.csv
\u2514\u2500\u2500 test.csv`,highlighted:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u251C\u2500\u2500 train.<span class="hljs-built_in">csv</span>
\u2514\u2500\u2500 test.<span class="hljs-built_in">csv</span>`}}),z=new Et({}),X=new ot({props:{code:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u2514\u2500\u2500 data/
    \u251C\u2500\u2500 train.csv
    \u251C\u2500\u2500 test.csv
    \u2514\u2500\u2500 valid.csv`,highlighted:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u2514\u2500\u2500 data/
    \u251C\u2500\u2500 train.<span class="hljs-built_in">csv</span>
    \u251C\u2500\u2500 test.<span class="hljs-built_in">csv</span>
    \u2514\u2500\u2500 valid.<span class="hljs-built_in">csv</span>`}}),Z=new Et({}),tt=new ot({props:{code:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u251C\u2500\u2500 train_0.csv
\u251C\u2500\u2500 train_1.csv
\u251C\u2500\u2500 train_2.csv
\u251C\u2500\u2500 train_3.csv
\u251C\u2500\u2500 test_0.csv
\u2514\u2500\u2500 test_1.csv`,highlighted:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u251C\u2500\u2500 train_0.<span class="hljs-built_in">csv</span>
\u251C\u2500\u2500 train_1.<span class="hljs-built_in">csv</span>
\u251C\u2500\u2500 train_2.<span class="hljs-built_in">csv</span>
\u251C\u2500\u2500 train_3.<span class="hljs-built_in">csv</span>
\u251C\u2500\u2500 test_0.<span class="hljs-built_in">csv</span>
\u2514\u2500\u2500 test_1.<span class="hljs-built_in">csv</span>`}}),et=new ot({props:{code:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u2514\u2500\u2500 data/
    \u251C\u2500\u2500 train/
    \u2502   \u251C\u2500\u2500 shard_0.csv
    \u2502   \u251C\u2500\u2500 shard_1.csv
    \u2502   \u251C\u2500\u2500 shard_2.csv
    \u2502   \u2514\u2500\u2500 shard_3.csv
    \u2514\u2500\u2500 test/
        \u251C\u2500\u2500 shard_0.csv
        \u2514\u2500\u2500 shard_1.csv`,highlighted:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u2514\u2500\u2500 data/
    \u251C\u2500\u2500 train/
    \u2502   \u251C\u2500\u2500 shard_0.<span class="hljs-built_in">csv</span>
    \u2502   \u251C\u2500\u2500 shard_1.<span class="hljs-built_in">csv</span>
    \u2502   \u251C\u2500\u2500 shard_2.<span class="hljs-built_in">csv</span>
    \u2502   \u2514\u2500\u2500 shard_3.<span class="hljs-built_in">csv</span>
    \u2514\u2500\u2500 test/
        \u251C\u2500\u2500 shard_0.<span class="hljs-built_in">csv</span>
        \u2514\u2500\u2500 shard_1.<span class="hljs-built_in">csv</span>`}}),st=new Et({}),at=new ot({props:{code:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u2514\u2500\u2500 data/
    \u251C\u2500\u2500 train-00000-of-00003.csv
    \u251C\u2500\u2500 train-00001-of-00003.csv
    \u251C\u2500\u2500 train-00002-of-00003.csv
    \u251C\u2500\u2500 test-00000-of-00001.csv
    \u251C\u2500\u2500 random-00000-of-00003.csv
    \u251C\u2500\u2500 random-00001-of-00003.csv
    \u2514\u2500\u2500 random-00002-of-00003.csv`,highlighted:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u2514\u2500\u2500 data/
    \u251C\u2500\u2500 train<span class="hljs-string">-00000</span>-of<span class="hljs-string">-00003</span>.csv
    \u251C\u2500\u2500 train<span class="hljs-string">-00001</span>-of<span class="hljs-string">-00003</span>.csv
    \u251C\u2500\u2500 train<span class="hljs-string">-00002</span>-of<span class="hljs-string">-00003</span>.csv
    \u251C\u2500\u2500 test<span class="hljs-string">-00000</span>-of<span class="hljs-string">-00001</span>.csv
    \u251C\u2500\u2500 random<span class="hljs-string">-00000</span>-of<span class="hljs-string">-00003</span>.csv
    \u251C\u2500\u2500 random<span class="hljs-string">-00001</span>-of<span class="hljs-string">-00003</span>.csv
    \u2514\u2500\u2500 random<span class="hljs-string">-00002</span>-of<span class="hljs-string">-00003</span>.csv`}}),rt=new Et({}),lt=new ot({props:{code:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u251C\u2500\u2500 en/
\u2502   \u251C\u2500\u2500 train.csv
\u2502   \u2514\u2500\u2500 test.csv
\u2514\u2500\u2500 fr/
    \u251C\u2500\u2500 train.csv
    \u2514\u2500\u2500 test.csv`,highlighted:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u251C\u2500\u2500 en/
\u2502   \u251C\u2500\u2500 train.<span class="hljs-built_in">csv</span>
\u2502   \u2514\u2500\u2500 test.<span class="hljs-built_in">csv</span>
\u2514\u2500\u2500 fr/
    \u251C\u2500\u2500 train.<span class="hljs-built_in">csv</span>
    \u2514\u2500\u2500 test.<span class="hljs-built_in">csv</span>`}}),it=new ot({props:{code:`my_dataset_repository/
\u251C\u2500\u2500 README.md
\u251C\u2500\u2500 en/
\u2502   \u251C\u2500\u2500 train/
\u2502   \u2502   \u251C\u2500\u2500 shard_0.csv
\u2502   \u2502   \u2514\u2500\u2500 shard_1.csv
\u2502   \u2514\u2500\u2500 test/
\u2502       \u251C\u2500\u2500 shard_0.csv
\u2502       \u2514\u2500\u2500 shard_1.csv
\u2514\u2500\u2500 fr/
    \u251C\u2500\u2500 train/
    \u2502   \u251C\u2500\u2500 shard_0.csv
    \u2502   \u2514\u2500\u2500 shard_1.csv
    \u2514\u2500\u2500 test/
        \u251C\u2500\u2500 shard_0.csv
        \u2514\u2500\u2500 shard_1.csv`,highlighted:`my_dataset_repository/
\u251C\u2500\u2500 README<span class="hljs-selector-class">.md</span>
\u251C\u2500\u2500 en/
\u2502   \u251C\u2500\u2500 train/
\u2502   \u2502   \u251C\u2500\u2500 shard_0<span class="hljs-selector-class">.csv</span>
\u2502   \u2502   \u2514\u2500\u2500 shard_1<span class="hljs-selector-class">.csv</span>
\u2502   \u2514\u2500\u2500 test/
\u2502       \u251C\u2500\u2500 shard_0<span class="hljs-selector-class">.csv</span>
\u2502       \u2514\u2500\u2500 shard_1<span class="hljs-selector-class">.csv</span>
\u2514\u2500\u2500 fr/
    \u251C\u2500\u2500 train/
    \u2502   \u251C\u2500\u2500 shard_0<span class="hljs-selector-class">.csv</span>
    \u2502   \u2514\u2500\u2500 shard_1<span class="hljs-selector-class">.csv</span>
    \u2514\u2500\u2500 test/
        \u251C\u2500\u2500 shard_0<span class="hljs-selector-class">.csv</span>
        \u2514\u2500\u2500 shard_1.csv`}}),{c(){u=r("meta"),D=f(),d=r("h1"),x=r("a"),wt=r("span"),_(W.$$.fragment),Ge=f(),gt=r("span"),Ce=l("Structure your repository"),Qt=f(),pt=r("p"),Fe=l("To host and share your dataset, you can create a dataset repository on the Hugging Face Dataset Hub and upload your data files."),Xt=f(),O=r("p"),Je=l(`This guide will show you how to structure your dataset repository when you upload it.
A dataset with a supported structure can be loaded automatically with `),ft=r("a"),Le=l("load_dataset()"),qe=l(", and it will have a preview on its dataset page on the Hub."),Zt=f(),H=r("p"),Ve=l("Note that you can also include a "),ht=r("a"),Ye=l("python script"),We=l(" to define your dataset, for more flexibility."),te=f(),_(I.$$.fragment),ee=f(),P=r("h2"),G=r("a"),xt=r("span"),_(B.$$.fragment),Be=f(),bt=r("span"),Ue=l("Main use-case"),se=f(),b=r("p"),ze=l("The simplest dataset structure has two files: "),At=r("em"),Ke=l("train.csv"),Qe=l(" and "),jt=r("em"),Xe=l("test.csv"),Ze=l("."),ae=f(),A=r("p"),ts=l("Your repository will also contain a "),St=r("em"),es=l("README.md"),ss=l(" file, the "),ct=r("a"),as=l("dataset card"),rs=l(" displayed on your dataset page."),re=f(),_(U.$$.fragment),le=f(),M=r("h2"),C=r("a"),kt=r("span"),_(z.$$.fragment),ls=f(),Pt=r("span"),is=l("Splits and file names"),ie=f(),F=r("p"),ns=l(`\u{1F917} Datasets automatically infers the train/validation/test splits of your dataset from the file names.
All the files that contain `),Mt=r("strong"),os=l("train"),ps=l(" in their names are considered part of the train split. The same idea applies to the test and validation split:"),ne=f(),J=r("ul"),K=r("li"),fs=l("All the files that contain "),Nt=r("strong"),hs=l("test"),cs=l(" in their names are considered part of the test split."),us=f(),Q=r("li"),ds=l("All the files that contain "),Rt=r("strong"),ms=l("valid"),vs=l(" in their names are considered part of the validation split."),oe=f(),L=r("p"),_s=l("Here is an example where all the files are placed into a directory named "),Tt=r("em"),ys=l("data"),$s=l(":"),pe=f(),_(X.$$.fragment),fe=f(),N=r("h2"),q=r("a"),Dt=r("span"),_(Z.$$.fragment),Es=f(),Ot=r("span"),ws=l("Multiple files per split"),he=f(),j=r("p"),gs=l(`If one of your splits comprises several files, \u{1F917} Datasets can still infer whether it is the train/validation/ test split from the file name.
For example, if your `),Ht=r("strong"),xs=l("train"),bs=l(" and "),It=r("strong"),As=l("test"),js=l(" splits span several files:"),ce=f(),_(tt.$$.fragment),ue=f(),m=r("p"),Ss=l("Just make sure that all the files of your "),Gt=r("strong"),ks=l("train"),Ps=l(" set have "),Ct=r("strong"),Ms=l("train"),Ns=l(` in their names (same for test and validation).
It doesn\u2019t matter if you add a prefix or suffix to `),Ft=r("strong"),Rs=l("train"),Ts=l(" in the file name (like "),Jt=r("em"),Ds=l("my_train_file_00001.csv"),Os=l(`, for example).
\u{1F917} Datasets can still infer the appropriate split.`),de=f(),ut=r("p"),Hs=l("For convenience, you can also place your data files into different directories. In this case, the split name is inferred from the directory name."),me=f(),_(et.$$.fragment),ve=f(),R=r("h2"),V=r("a"),Lt=r("span"),_(st.$$.fragment),Is=f(),qt=r("span"),Gs=l("Custom split names"),_e=f(),v=r("p"),Cs=l(`If you have other data files in addition to the traditional train/validation/test sets, you must use the following structure.
Follow the file name format exactly for this type of structure: `),Vt=r("em"),Fs=l("data/<split_name>-xxxxx-of-xxxxx.csv"),Js=l(`.
Here is an example with three splits: `),Yt=r("strong"),Ls=l("train"),qs=l(", "),Wt=r("strong"),Vs=l("test"),Ys=l(", and "),Bt=r("strong"),Ws=l("random"),Bs=l(":"),ye=f(),_(at.$$.fragment),$e=f(),T=r("h2"),Y=r("a"),Ut=r("span"),_(rt.$$.fragment),Us=f(),zt=r("span"),zs=l("Multiple configuration (WIP)"),Ee=f(),dt=r("p"),Ks=l("You can specify different configurations of your dataset (for example, if a dataset contains different languages) with one directory per configuration."),we=f(),mt=r("p"),Qs=l("These structures are not supported yet, but are a work in progress:"),ge=f(),_(lt.$$.fragment),xe=f(),vt=r("p"),Xs=l("Or with one directory per split:"),be=f(),_(it.$$.fragment),this.h()},l(t){const a=Ya('[data-svelte="svelte-1phssyn"]',document.head);u=i(a,"META",{name:!0,content:!0}),a.forEach(e),D=h(t),d=i(t,"H1",{class:!0});var nt=o(d);x=i(nt,"A",{id:!0,class:!0,href:!0});var Zs=o(x);wt=i(Zs,"SPAN",{});var ta=o(wt);y(W.$$.fragment,ta),ta.forEach(e),Zs.forEach(e),Ge=h(nt),gt=i(nt,"SPAN",{});var ea=o(gt);Ce=n(ea,"Structure your repository"),ea.forEach(e),nt.forEach(e),Qt=h(t),pt=i(t,"P",{});var sa=o(pt);Fe=n(sa,"To host and share your dataset, you can create a dataset repository on the Hugging Face Dataset Hub and upload your data files."),sa.forEach(e),Xt=h(t),O=i(t,"P",{});var je=o(O);Je=n(je,`This guide will show you how to structure your dataset repository when you upload it.
A dataset with a supported structure can be loaded automatically with `),ft=i(je,"A",{href:!0});var aa=o(ft);Le=n(aa,"load_dataset()"),aa.forEach(e),qe=n(je,", and it will have a preview on its dataset page on the Hub."),je.forEach(e),Zt=h(t),H=i(t,"P",{});var Se=o(H);Ve=n(Se,"Note that you can also include a "),ht=i(Se,"A",{href:!0});var ra=o(ht);Ye=n(ra,"python script"),ra.forEach(e),We=n(Se," to define your dataset, for more flexibility."),Se.forEach(e),te=h(t),y(I.$$.fragment,t),ee=h(t),P=i(t,"H2",{class:!0});var ke=o(P);G=i(ke,"A",{id:!0,class:!0,href:!0});var la=o(G);xt=i(la,"SPAN",{});var ia=o(xt);y(B.$$.fragment,ia),ia.forEach(e),la.forEach(e),Be=h(ke),bt=i(ke,"SPAN",{});var na=o(bt);Ue=n(na,"Main use-case"),na.forEach(e),ke.forEach(e),se=h(t),b=i(t,"P",{});var _t=o(b);ze=n(_t,"The simplest dataset structure has two files: "),At=i(_t,"EM",{});var oa=o(At);Ke=n(oa,"train.csv"),oa.forEach(e),Qe=n(_t," and "),jt=i(_t,"EM",{});var pa=o(jt);Xe=n(pa,"test.csv"),pa.forEach(e),Ze=n(_t,"."),_t.forEach(e),ae=h(t),A=i(t,"P",{});var yt=o(A);ts=n(yt,"Your repository will also contain a "),St=i(yt,"EM",{});var fa=o(St);es=n(fa,"README.md"),fa.forEach(e),ss=n(yt," file, the "),ct=i(yt,"A",{href:!0});var ha=o(ct);as=n(ha,"dataset card"),ha.forEach(e),rs=n(yt," displayed on your dataset page."),yt.forEach(e),re=h(t),y(U.$$.fragment,t),le=h(t),M=i(t,"H2",{class:!0});var Pe=o(M);C=i(Pe,"A",{id:!0,class:!0,href:!0});var ca=o(C);kt=i(ca,"SPAN",{});var ua=o(kt);y(z.$$.fragment,ua),ua.forEach(e),ca.forEach(e),ls=h(Pe),Pt=i(Pe,"SPAN",{});var da=o(Pt);is=n(da,"Splits and file names"),da.forEach(e),Pe.forEach(e),ie=h(t),F=i(t,"P",{});var Me=o(F);ns=n(Me,`\u{1F917} Datasets automatically infers the train/validation/test splits of your dataset from the file names.
All the files that contain `),Mt=i(Me,"STRONG",{});var ma=o(Mt);os=n(ma,"train"),ma.forEach(e),ps=n(Me," in their names are considered part of the train split. The same idea applies to the test and validation split:"),Me.forEach(e),ne=h(t),J=i(t,"UL",{});var Ne=o(J);K=i(Ne,"LI",{});var Re=o(K);fs=n(Re,"All the files that contain "),Nt=i(Re,"STRONG",{});var va=o(Nt);hs=n(va,"test"),va.forEach(e),cs=n(Re," in their names are considered part of the test split."),Re.forEach(e),us=h(Ne),Q=i(Ne,"LI",{});var Te=o(Q);ds=n(Te,"All the files that contain "),Rt=i(Te,"STRONG",{});var _a=o(Rt);ms=n(_a,"valid"),_a.forEach(e),vs=n(Te," in their names are considered part of the validation split."),Te.forEach(e),Ne.forEach(e),oe=h(t),L=i(t,"P",{});var De=o(L);_s=n(De,"Here is an example where all the files are placed into a directory named "),Tt=i(De,"EM",{});var ya=o(Tt);ys=n(ya,"data"),ya.forEach(e),$s=n(De,":"),De.forEach(e),pe=h(t),y(X.$$.fragment,t),fe=h(t),N=i(t,"H2",{class:!0});var Oe=o(N);q=i(Oe,"A",{id:!0,class:!0,href:!0});var $a=o(q);Dt=i($a,"SPAN",{});var Ea=o(Dt);y(Z.$$.fragment,Ea),Ea.forEach(e),$a.forEach(e),Es=h(Oe),Ot=i(Oe,"SPAN",{});var wa=o(Ot);ws=n(wa,"Multiple files per split"),wa.forEach(e),Oe.forEach(e),he=h(t),j=i(t,"P",{});var $t=o(j);gs=n($t,`If one of your splits comprises several files, \u{1F917} Datasets can still infer whether it is the train/validation/ test split from the file name.
For example, if your `),Ht=i($t,"STRONG",{});var ga=o(Ht);xs=n(ga,"train"),ga.forEach(e),bs=n($t," and "),It=i($t,"STRONG",{});var xa=o(It);As=n(xa,"test"),xa.forEach(e),js=n($t," splits span several files:"),$t.forEach(e),ce=h(t),y(tt.$$.fragment,t),ue=h(t),m=i(t,"P",{});var S=o(m);Ss=n(S,"Just make sure that all the files of your "),Gt=i(S,"STRONG",{});var ba=o(Gt);ks=n(ba,"train"),ba.forEach(e),Ps=n(S," set have "),Ct=i(S,"STRONG",{});var Aa=o(Ct);Ms=n(Aa,"train"),Aa.forEach(e),Ns=n(S,` in their names (same for test and validation).
It doesn\u2019t matter if you add a prefix or suffix to `),Ft=i(S,"STRONG",{});var ja=o(Ft);Rs=n(ja,"train"),ja.forEach(e),Ts=n(S," in the file name (like "),Jt=i(S,"EM",{});var Sa=o(Jt);Ds=n(Sa,"my_train_file_00001.csv"),Sa.forEach(e),Os=n(S,`, for example).
\u{1F917} Datasets can still infer the appropriate split.`),S.forEach(e),de=h(t),ut=i(t,"P",{});var ka=o(ut);Hs=n(ka,"For convenience, you can also place your data files into different directories. In this case, the split name is inferred from the directory name."),ka.forEach(e),me=h(t),y(et.$$.fragment,t),ve=h(t),R=i(t,"H2",{class:!0});var He=o(R);V=i(He,"A",{id:!0,class:!0,href:!0});var Pa=o(V);Lt=i(Pa,"SPAN",{});var Ma=o(Lt);y(st.$$.fragment,Ma),Ma.forEach(e),Pa.forEach(e),Is=h(He),qt=i(He,"SPAN",{});var Na=o(qt);Gs=n(Na,"Custom split names"),Na.forEach(e),He.forEach(e),_e=h(t),v=i(t,"P",{});var k=o(v);Cs=n(k,`If you have other data files in addition to the traditional train/validation/test sets, you must use the following structure.
Follow the file name format exactly for this type of structure: `),Vt=i(k,"EM",{});var Ra=o(Vt);Fs=n(Ra,"data/<split_name>-xxxxx-of-xxxxx.csv"),Ra.forEach(e),Js=n(k,`.
Here is an example with three splits: `),Yt=i(k,"STRONG",{});var Ta=o(Yt);Ls=n(Ta,"train"),Ta.forEach(e),qs=n(k,", "),Wt=i(k,"STRONG",{});var Da=o(Wt);Vs=n(Da,"test"),Da.forEach(e),Ys=n(k,", and "),Bt=i(k,"STRONG",{});var Oa=o(Bt);Ws=n(Oa,"random"),Oa.forEach(e),Bs=n(k,":"),k.forEach(e),ye=h(t),y(at.$$.fragment,t),$e=h(t),T=i(t,"H2",{class:!0});var Ie=o(T);Y=i(Ie,"A",{id:!0,class:!0,href:!0});var Ha=o(Y);Ut=i(Ha,"SPAN",{});var Ia=o(Ut);y(rt.$$.fragment,Ia),Ia.forEach(e),Ha.forEach(e),Us=h(Ie),zt=i(Ie,"SPAN",{});var Ga=o(zt);zs=n(Ga,"Multiple configuration (WIP)"),Ga.forEach(e),Ie.forEach(e),Ee=h(t),dt=i(t,"P",{});var Ca=o(dt);Ks=n(Ca,"You can specify different configurations of your dataset (for example, if a dataset contains different languages) with one directory per configuration."),Ca.forEach(e),we=h(t),mt=i(t,"P",{});var Fa=o(mt);Qs=n(Fa,"These structures are not supported yet, but are a work in progress:"),Fa.forEach(e),ge=h(t),y(lt.$$.fragment,t),xe=h(t),vt=i(t,"P",{});var Ja=o(vt);Xs=n(Ja,"Or with one directory per split:"),Ja.forEach(e),be=h(t),y(it.$$.fragment,t),this.h()},h(){c(u,"name","hf:doc:metadata"),c(u,"content",JSON.stringify(Ka)),c(x,"id","structure-your-repository"),c(x,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(x,"href","#structure-your-repository"),c(d,"class","relative group"),c(ft,"href","/docs/datasets/v2.3.0/en/package_reference/loading_methods#datasets.load_dataset"),c(ht,"href","dataset_script"),c(G,"id","main-usecase"),c(G,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(G,"href","#main-usecase"),c(P,"class","relative group"),c(ct,"href","dataset_card"),c(C,"id","splits-and-file-names"),c(C,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C,"href","#splits-and-file-names"),c(M,"class","relative group"),c(q,"id","multiple-files-per-split"),c(q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(q,"href","#multiple-files-per-split"),c(N,"class","relative group"),c(V,"id","custom-split-names"),c(V,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(V,"href","#custom-split-names"),c(R,"class","relative group"),c(Y,"id","multiple-configuration-wip"),c(Y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Y,"href","#multiple-configuration-wip"),c(T,"class","relative group")},m(t,a){s(document.head,u),p(t,D,a),p(t,d,a),s(d,x),s(x,wt),$(W,wt,null),s(d,Ge),s(d,gt),s(gt,Ce),p(t,Qt,a),p(t,pt,a),s(pt,Fe),p(t,Xt,a),p(t,O,a),s(O,Je),s(O,ft),s(ft,Le),s(O,qe),p(t,Zt,a),p(t,H,a),s(H,Ve),s(H,ht),s(ht,Ye),s(H,We),p(t,te,a),$(I,t,a),p(t,ee,a),p(t,P,a),s(P,G),s(G,xt),$(B,xt,null),s(P,Be),s(P,bt),s(bt,Ue),p(t,se,a),p(t,b,a),s(b,ze),s(b,At),s(At,Ke),s(b,Qe),s(b,jt),s(jt,Xe),s(b,Ze),p(t,ae,a),p(t,A,a),s(A,ts),s(A,St),s(St,es),s(A,ss),s(A,ct),s(ct,as),s(A,rs),p(t,re,a),$(U,t,a),p(t,le,a),p(t,M,a),s(M,C),s(C,kt),$(z,kt,null),s(M,ls),s(M,Pt),s(Pt,is),p(t,ie,a),p(t,F,a),s(F,ns),s(F,Mt),s(Mt,os),s(F,ps),p(t,ne,a),p(t,J,a),s(J,K),s(K,fs),s(K,Nt),s(Nt,hs),s(K,cs),s(J,us),s(J,Q),s(Q,ds),s(Q,Rt),s(Rt,ms),s(Q,vs),p(t,oe,a),p(t,L,a),s(L,_s),s(L,Tt),s(Tt,ys),s(L,$s),p(t,pe,a),$(X,t,a),p(t,fe,a),p(t,N,a),s(N,q),s(q,Dt),$(Z,Dt,null),s(N,Es),s(N,Ot),s(Ot,ws),p(t,he,a),p(t,j,a),s(j,gs),s(j,Ht),s(Ht,xs),s(j,bs),s(j,It),s(It,As),s(j,js),p(t,ce,a),$(tt,t,a),p(t,ue,a),p(t,m,a),s(m,Ss),s(m,Gt),s(Gt,ks),s(m,Ps),s(m,Ct),s(Ct,Ms),s(m,Ns),s(m,Ft),s(Ft,Rs),s(m,Ts),s(m,Jt),s(Jt,Ds),s(m,Os),p(t,de,a),p(t,ut,a),s(ut,Hs),p(t,me,a),$(et,t,a),p(t,ve,a),p(t,R,a),s(R,V),s(V,Lt),$(st,Lt,null),s(R,Is),s(R,qt),s(qt,Gs),p(t,_e,a),p(t,v,a),s(v,Cs),s(v,Vt),s(Vt,Fs),s(v,Js),s(v,Yt),s(Yt,Ls),s(v,qs),s(v,Wt),s(Wt,Vs),s(v,Ys),s(v,Bt),s(Bt,Ws),s(v,Bs),p(t,ye,a),$(at,t,a),p(t,$e,a),p(t,T,a),s(T,Y),s(Y,Ut),$(rt,Ut,null),s(T,Us),s(T,zt),s(zt,zs),p(t,Ee,a),p(t,dt,a),s(dt,Ks),p(t,we,a),p(t,mt,a),s(mt,Qs),p(t,ge,a),$(lt,t,a),p(t,xe,a),p(t,vt,a),s(vt,Xs),p(t,be,a),$(it,t,a),Ae=!0},p(t,[a]){const nt={};a&2&&(nt.$$scope={dirty:a,ctx:t}),I.$set(nt)},i(t){Ae||(E(W.$$.fragment,t),E(I.$$.fragment,t),E(B.$$.fragment,t),E(U.$$.fragment,t),E(z.$$.fragment,t),E(X.$$.fragment,t),E(Z.$$.fragment,t),E(tt.$$.fragment,t),E(et.$$.fragment,t),E(st.$$.fragment,t),E(at.$$.fragment,t),E(rt.$$.fragment,t),E(lt.$$.fragment,t),E(it.$$.fragment,t),Ae=!0)},o(t){w(W.$$.fragment,t),w(I.$$.fragment,t),w(B.$$.fragment,t),w(U.$$.fragment,t),w(z.$$.fragment,t),w(X.$$.fragment,t),w(Z.$$.fragment,t),w(tt.$$.fragment,t),w(et.$$.fragment,t),w(st.$$.fragment,t),w(at.$$.fragment,t),w(rt.$$.fragment,t),w(lt.$$.fragment,t),w(it.$$.fragment,t),Ae=!1},d(t){e(u),t&&e(D),t&&e(d),g(W),t&&e(Qt),t&&e(pt),t&&e(Xt),t&&e(O),t&&e(Zt),t&&e(H),t&&e(te),g(I,t),t&&e(ee),t&&e(P),g(B),t&&e(se),t&&e(b),t&&e(ae),t&&e(A),t&&e(re),g(U,t),t&&e(le),t&&e(M),g(z),t&&e(ie),t&&e(F),t&&e(ne),t&&e(J),t&&e(oe),t&&e(L),t&&e(pe),g(X,t),t&&e(fe),t&&e(N),g(Z),t&&e(he),t&&e(j),t&&e(ce),g(tt,t),t&&e(ue),t&&e(m),t&&e(de),t&&e(ut),t&&e(me),g(et,t),t&&e(ve),t&&e(R),g(st),t&&e(_e),t&&e(v),t&&e(ye),g(at,t),t&&e($e),t&&e(T),g(rt),t&&e(Ee),t&&e(dt),t&&e(we),t&&e(mt),t&&e(ge),g(lt,t),t&&e(xe),t&&e(vt),t&&e(be),g(it,t)}}}const Ka={local:"structure-your-repository",sections:[{local:"main-usecase",title:"Main use-case"},{local:"splits-and-file-names",title:"Splits and file names"},{local:"multiple-files-per-split",title:"Multiple files per split"},{local:"custom-split-names",title:"Custom split names"},{local:"multiple-configuration-wip",title:"Multiple configuration (WIP)"}],title:"Structure your repository"};function Qa(Kt){return Wa(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class sr extends La{constructor(u){super();qa(this,u,Qa,za,Va,{})}}export{sr as default,Ka as metadata};
